1
00:00:01,770 --> 00:00:04,446
Hello, everyone. It is June 9, 2022,

2
00:00:04,468 --> 00:00:08,560
and it's chapter three,

3
00:00:09,170 --> 00:00:12,426
week one, and it's the first cohort

4
00:00:12,458 --> 00:00:15,486
of the textbook group. We're going to go

5
00:00:15,508 --> 00:00:18,382
to the questions. There weren't any

6
00:00:18,436 --> 00:00:21,022
ideas added for three, but if people

7
00:00:21,076 --> 00:00:23,246
have any key themes or any ideas that

8
00:00:23,268 --> 00:00:25,446
they picked up on with three, they can

9
00:00:25,468 --> 00:00:28,390
add them here. Otherwise we'll go to the

10
00:00:28,460 --> 00:00:33,030
questions. And also

11
00:00:33,100 --> 00:00:34,834
if people have questions in the chat,

12
00:00:34,882 --> 00:00:37,522
or it would be also great just to take

13
00:00:37,596 --> 00:00:40,426
notes or add questions and continue to

14
00:00:40,448 --> 00:00:42,646
upload them. And then next week we'll

15
00:00:42,678 --> 00:00:45,274
continue the discussion on three. So

16
00:00:45,472 --> 00:00:48,106
this is just the opening set of

17
00:00:48,128 --> 00:00:53,066
questions, maybe just the first ideas

18
00:00:53,098 --> 00:00:56,446
of the book. Turning to questions, now

19
00:00:56,468 --> 00:00:59,774
that we've at least gone through

20
00:00:59,812 --> 00:01:01,994
chapter two once and part of chapter

21
00:01:02,042 --> 00:01:03,486
three, or the whole thing of chapter

22
00:01:03,518 --> 00:01:06,398
three, what is the high road to active

23
00:01:06,414 --> 00:01:07,250
inference?

24
00:01:18,740 --> 00:01:20,496
What does anyone think about the high

25
00:01:20,518 --> 00:01:24,080
road to active inference or about this

26
00:01:24,150 --> 00:01:28,208
low road high road construct

27
00:01:28,384 --> 00:01:30,950
that is used in chapters two and three?

28
00:01:34,220 --> 00:01:36,296
Just broadly, how did the approach of

29
00:01:36,318 --> 00:01:37,736
chapter three feel different than the

30
00:01:37,758 --> 00:01:40,990
approach or the topics of chapter two?

31
00:01:52,160 --> 00:01:53,900
JF and then Ali.

32
00:01:55,620 --> 00:01:57,596
I just want. To make the Joe comment

33
00:01:57,628 --> 00:02:00,864
that the. High road approach is what

34
00:02:00,982 --> 00:02:03,296
first grabbed. Me when I encountered the

35
00:02:03,318 --> 00:02:05,920
free energy principle. That what really

36
00:02:05,990 --> 00:02:08,916
fascinated me, that there. Was an

37
00:02:08,938 --> 00:02:11,556
attempt at a unifying answer.

38
00:02:11,658 --> 00:02:14,420
To self organization,

39
00:02:15,720 --> 00:02:16,820
cognition.

40
00:02:20,380 --> 00:02:22,536
That this could. All be brought together

41
00:02:22,718 --> 00:02:24,760
around some relatively.

42
00:02:25,740 --> 00:02:28,664
Sparse number of concepts. That's what

43
00:02:28,702 --> 00:02:30,472
grabbed me much more than the lower

44
00:02:30,526 --> 00:02:34,270
road. Thank you,

45
00:02:34,640 --> 00:02:36,300
Ali and then Ben?

46
00:02:39,040 --> 00:02:40,972
Well, yeah, reading chapter three

47
00:02:41,026 --> 00:02:44,728
actually clarified my previously held,

48
00:02:44,904 --> 00:02:49,096
in fact wrong belief that previously

49
00:02:49,128 --> 00:02:52,510
I thought that a low road was a kind of

50
00:02:52,880 --> 00:02:55,472
bottom off approach and the high road is

51
00:02:55,606 --> 00:02:58,692
top down approach. But now I see

52
00:02:58,746 --> 00:03:02,832
that low road was basically tackling

53
00:03:02,896 --> 00:03:06,004
the problem of active inference from the

54
00:03:06,042 --> 00:03:08,852
inferential point of view and from the

55
00:03:08,986 --> 00:03:10,936
statistical and inferential point of

56
00:03:10,958 --> 00:03:14,792
view. But in the high road we have

57
00:03:14,846 --> 00:03:18,824
a much more generalized and much

58
00:03:18,862 --> 00:03:24,140
more, let's say, all encompassing view

59
00:03:24,210 --> 00:03:26,456
to tackle the problem of active

60
00:03:26,488 --> 00:03:30,104
inference, namely by way of defining

61
00:03:30,152 --> 00:03:33,320
markup blankets and all the properties

62
00:03:33,400 --> 00:03:35,790
of living organisms and so on.

63
00:03:36,800 --> 00:03:39,872
Awesome. Thank you, Ben. And then anyone

64
00:03:39,926 --> 00:03:42,096
else who raises their hand. And also you

65
00:03:42,118 --> 00:03:43,744
can take notes on this idea of the book,

66
00:03:43,782 --> 00:03:46,544
like high road generally. Ben and then

67
00:03:46,582 --> 00:03:49,936
Mike. Yeah, I think for

68
00:03:49,958 --> 00:03:51,956
me as well, this chapter three and the

69
00:03:51,978 --> 00:03:55,044
high road has been an easier road in.

70
00:03:55,082 --> 00:03:56,708
And the thing that I noticed about it

71
00:03:56,714 --> 00:03:58,916
was, it seems to me, so they say in the

72
00:03:58,938 --> 00:04:00,696
introduction, that active inference is a

73
00:04:00,718 --> 00:04:04,024
normative theory. I feel like the high

74
00:04:04,062 --> 00:04:05,864
road, to me, feels there's much more

75
00:04:05,902 --> 00:04:08,776
normativity in the high road. It's an

76
00:04:08,798 --> 00:04:11,480
account of what organisms have to do.

77
00:04:11,550 --> 00:04:14,564
And I think compared to the previous

78
00:04:14,612 --> 00:04:16,924
chapter, I think chapter two felt a lot

79
00:04:16,962 --> 00:04:19,724
more descriptive for me. I'm not sure

80
00:04:19,762 --> 00:04:21,436
other people would. Maybe that's just

81
00:04:21,458 --> 00:04:23,564
the way that I was reading it, but it

82
00:04:23,602 --> 00:04:25,264
felt like chapter three was a lot more

83
00:04:25,302 --> 00:04:27,296
kind of it had a more normative force to

84
00:04:27,318 --> 00:04:29,200
it that I really enjoyed.

85
00:04:30,420 --> 00:04:31,840
Thank you, Mike.

86
00:04:41,430 --> 00:04:45,026
There we go. Sorry, my computer was not

87
00:04:45,048 --> 00:04:48,374
responding. So I went through a similar

88
00:04:48,492 --> 00:04:50,534
experience as Ollie described in terms

89
00:04:50,572 --> 00:04:52,498
of going into it, thinking about bottoms

90
00:04:52,514 --> 00:04:54,534
up and top down and coming out of it,

91
00:04:54,572 --> 00:04:55,910
thinking about it differently.

92
00:04:57,710 --> 00:04:59,318
I feel like in chapter three there's

93
00:04:59,334 --> 00:05:01,366
still a lot to unpack around the Markov

94
00:05:01,398 --> 00:05:05,354
blanket. So that is still capturing this

95
00:05:05,392 --> 00:05:08,874
inferential nature of things. It still

96
00:05:08,912 --> 00:05:11,198
has a Bayesian quality like what we saw

97
00:05:11,284 --> 00:05:14,526
in chapter two. But it

98
00:05:14,548 --> 00:05:16,478
also, for me at least, it still feels a

99
00:05:16,484 --> 00:05:18,880
bit opaque at this point in terms of

100
00:05:20,210 --> 00:05:22,286
this sort of indirect influence that's

101
00:05:22,318 --> 00:05:24,930
taking place across the Markov blanket.

102
00:05:26,950 --> 00:05:30,770
Awesome. Okay, any other

103
00:05:30,840 --> 00:05:32,466
comments? Otherwise we're going to go to

104
00:05:32,488 --> 00:05:34,438
the questions and we'll approach many of

105
00:05:34,444 --> 00:05:35,430
those topics.

106
00:05:40,340 --> 00:05:41,090
Okay,

107
00:05:50,930 --> 00:05:54,686
first question regarding the

108
00:05:54,708 --> 00:05:57,534
Markov blanket explanation. On page 43

109
00:05:57,572 --> 00:06:00,866
and box 3.1, they write,

110
00:06:00,968 --> 00:06:02,738
no additional information about the

111
00:06:02,744 --> 00:06:04,482
future is gained by finding out about

112
00:06:04,536 --> 00:06:06,658
the past. Assuming we know the present,

113
00:06:06,744 --> 00:06:08,694
how can this be true? That's one

114
00:06:08,732 --> 00:06:13,286
question they

115
00:06:13,308 --> 00:06:17,478
define regarding the Markov blanket as

116
00:06:17,644 --> 00:06:19,862
the set of variables that mediate all

117
00:06:19,916 --> 00:06:21,546
statistical interactions between a

118
00:06:21,568 --> 00:06:23,706
system and its environment. What is a

119
00:06:23,728 --> 00:06:25,126
statistical rather than a non

120
00:06:25,158 --> 00:06:26,570
statistical interaction?

121
00:06:30,110 --> 00:06:31,862
They write that they've supplemented

122
00:06:31,926 --> 00:06:33,434
conditional independencies with

123
00:06:33,472 --> 00:06:36,234
dynamical constraints so that the flows

124
00:06:36,282 --> 00:06:37,966
do not depend upon states on the

125
00:06:37,988 --> 00:06:40,494
opposite side of the blanket. Why does

126
00:06:40,532 --> 00:06:42,078
independence between the flows on the

127
00:06:42,084 --> 00:06:44,640
two sides of the blanket matter so much?

128
00:06:45,910 --> 00:06:50,434
All right, great. So who

129
00:06:50,472 --> 00:06:52,146
would like to give a thought on this?

130
00:06:52,168 --> 00:06:54,898
First question? How can it be true about

131
00:06:54,984 --> 00:06:57,834
Marco blankets that no additional

132
00:06:57,902 --> 00:06:59,426
information about the future is gained

133
00:06:59,458 --> 00:07:01,000
by finding out about the past?

134
00:07:12,790 --> 00:07:15,046
So I added a note in there. You can tell

135
00:07:15,068 --> 00:07:18,262
me if this is correct or not with regard

136
00:07:18,316 --> 00:07:20,950
to Markov chains that as I understand

137
00:07:21,020 --> 00:07:24,406
the Markov chain in its present state is

138
00:07:24,428 --> 00:07:25,846
effectively capturing all the

139
00:07:25,868 --> 00:07:29,414
information about the past. So I assume

140
00:07:29,462 --> 00:07:31,770
that translates into the Markov blanket.

141
00:07:32,670 --> 00:07:36,166
Yes. Great comment. And a Markov chain

142
00:07:36,198 --> 00:07:39,710
is used very

143
00:07:39,780 --> 00:07:43,134
broadly. And just to give one

144
00:07:43,172 --> 00:07:45,806
example, it's like the current state of

145
00:07:45,828 --> 00:07:48,926
the chessboard, knowing more about

146
00:07:49,028 --> 00:07:52,382
previous moves doesn't tell you more

147
00:07:52,436 --> 00:07:54,478
about the future. And so it's like it's

148
00:07:54,494 --> 00:07:57,074
a one Markov chain because the

149
00:07:57,112 --> 00:07:59,394
dependency is only about that one time

150
00:07:59,432 --> 00:08:02,162
step. Now if it were to violate that

151
00:08:02,216 --> 00:08:05,426
condition of being a one Markov blanket

152
00:08:05,538 --> 00:08:08,262
through time and have like a three

153
00:08:08,316 --> 00:08:10,566
Markov blanket, that would mean that the

154
00:08:10,588 --> 00:08:13,206
same board position, depending on what

155
00:08:13,228 --> 00:08:16,230
move happened three before, was still

156
00:08:16,300 --> 00:08:18,250
having some influence on how the system

157
00:08:18,320 --> 00:08:20,666
evolved. That wouldn't violate the

158
00:08:20,688 --> 00:08:23,146
Markovian property, it would just make

159
00:08:23,168 --> 00:08:25,930
it a different kind of Markov chain.

160
00:08:26,430 --> 00:08:28,918
And that is commonly used in the

161
00:08:28,944 --> 00:08:31,674
temporal modeling, like in time series

162
00:08:31,722 --> 00:08:34,846
modeling and in transitions of

163
00:08:34,868 --> 00:08:38,298
stochastic processes. The Markov blanket

164
00:08:38,394 --> 00:08:42,082
is abstracting. It from this

165
00:08:42,216 --> 00:08:45,298
time sequence idea. Like the now is a

166
00:08:45,304 --> 00:08:47,218
blanket between the past and the future.

167
00:08:47,384 --> 00:08:50,690
And we could think about spatial systems

168
00:08:52,310 --> 00:08:54,354
like a Newton's cradle or something like

169
00:08:54,392 --> 00:08:57,266
that, as well as spatial temporal

170
00:08:57,298 --> 00:09:00,390
systems or just abstract causal systems.

171
00:09:00,890 --> 00:09:03,334
So how can this be true? It's true by

172
00:09:03,372 --> 00:09:04,726
definition because that's what the

173
00:09:04,748 --> 00:09:06,840
definition of a Markov blanket is.

174
00:09:07,230 --> 00:09:11,210
Whether that description is adequate or

175
00:09:11,280 --> 00:09:13,638
maps on to carving, nature of the joints

176
00:09:13,654 --> 00:09:15,434
and all these other things are

177
00:09:15,632 --> 00:09:18,122
respectively statistical model

178
00:09:18,176 --> 00:09:20,822
comparison and ontological philosophical

179
00:09:20,886 --> 00:09:22,982
questions. But it's true by definition

180
00:09:23,046 --> 00:09:27,274
about Markov blankets. Lyle yeah,

181
00:09:27,392 --> 00:09:29,006
I think actually you just pretty much

182
00:09:29,028 --> 00:09:30,366
covered it. But I would just say this is

183
00:09:30,388 --> 00:09:32,462
the same condition if you're building RL

184
00:09:32,526 --> 00:09:35,134
models of different kinds of autonomous

185
00:09:35,182 --> 00:09:37,982
systems, this is the same restriction.

186
00:09:38,126 --> 00:09:41,934
I think your comment about the nested

187
00:09:42,062 --> 00:09:44,726
blankets is interesting because in the

188
00:09:44,748 --> 00:09:47,766
RL space we typically don't have that

189
00:09:47,788 --> 00:09:50,470
kind of richness. But what we do then

190
00:09:50,540 --> 00:09:53,062
would be, for example, we want to know

191
00:09:53,116 --> 00:09:56,982
the distance. And in that case

192
00:09:57,036 --> 00:10:00,266
we would just create, basically create a

193
00:10:00,288 --> 00:10:06,074
state variable, which is the

194
00:10:06,112 --> 00:10:09,106
history of the state transition.

195
00:10:09,158 --> 00:10:11,294
So we fudge it a little bit. But your

196
00:10:11,332 --> 00:10:14,654
explanation that in this

197
00:10:14,692 --> 00:10:17,082
conception with nested Markov blankets,

198
00:10:17,146 --> 00:10:19,982
then that would be the more

199
00:10:20,036 --> 00:10:22,320
comprehensive solution to that issue.

200
00:10:23,570 --> 00:10:25,522
Thanks. Just to kind of clarify, there

201
00:10:25,576 --> 00:10:28,274
like one hack or workaround would be

202
00:10:28,312 --> 00:10:30,866
like you make the list of all of the

203
00:10:30,888 --> 00:10:33,586
last possible three moves and then you

204
00:10:33,608 --> 00:10:37,430
make a one Markov blanket with all the

205
00:10:37,500 --> 00:10:39,906
last combinations of three. That's

206
00:10:39,938 --> 00:10:41,686
right. So it still uses the machinery of

207
00:10:41,708 --> 00:10:43,638
a one Markov chain, which has the

208
00:10:43,644 --> 00:10:46,514
simplest transition matrix, but it could

209
00:10:46,572 --> 00:10:48,858
encompass the last states. But it sort

210
00:10:48,864 --> 00:10:51,126
of compresses them into a one Markov

211
00:10:51,158 --> 00:10:54,140
chain format. Yeah, I mean, very often

212
00:10:56,510 --> 00:10:59,740
you want to know the average of the last

213
00:11:00,190 --> 00:11:03,454
20 time steps. You're just trying to

214
00:11:03,572 --> 00:11:06,334
smooth something, right. And it's just

215
00:11:06,372 --> 00:11:07,934
way too much work to build all that

216
00:11:07,972 --> 00:11:11,646
machinery in there. So you

217
00:11:11,668 --> 00:11:13,538
make that average. Actually a present

218
00:11:13,624 --> 00:11:17,554
variable is what you do. Great example.

219
00:11:17,672 --> 00:11:19,906
If something really does depend on the

220
00:11:19,928 --> 00:11:22,274
last 20 time steps, or you want to do

221
00:11:22,312 --> 00:11:24,358
model comparison as to whether it's a

222
00:11:24,364 --> 00:11:26,518
better model that is conditioned on the

223
00:11:26,524 --> 00:11:30,502
last 15 or 20 or 30, you can just

224
00:11:30,636 --> 00:11:32,854
condense it with summary statistics and

225
00:11:32,892 --> 00:11:35,762
descriptions. Again into this one Markov

226
00:11:35,826 --> 00:11:38,246
framework. Otherwise the combinatorics

227
00:11:38,278 --> 00:11:41,050
of how the 20 influence each other is

228
00:11:41,120 --> 00:11:44,746
vast. Brock I

229
00:11:44,768 --> 00:11:47,286
guess that's related to what my comment

230
00:11:47,318 --> 00:11:49,294
was just going to be. That the way they

231
00:11:49,332 --> 00:11:52,954
worded it. If you're not rigidly

232
00:11:53,002 --> 00:11:55,626
thinking about a singular Markov

233
00:11:55,658 --> 00:11:56,430
blanket,

234
00:12:00,770 --> 00:12:04,082
just practically speaking, finding about

235
00:12:04,136 --> 00:12:07,826
the past usually does give you

236
00:12:07,848 --> 00:12:09,438
information about the future. If you're

237
00:12:09,454 --> 00:12:11,774
talking about outside of a singular

238
00:12:11,822 --> 00:12:13,540
Markov blanket. Right.

239
00:12:16,150 --> 00:12:19,502
Adding the words no additional

240
00:12:19,566 --> 00:12:23,302
information about

241
00:12:23,356 --> 00:12:24,966
the future of the Markov blanket is

242
00:12:24,988 --> 00:12:26,502
gained by finding out about the past.

243
00:12:26,556 --> 00:12:29,578
The Markov blanket kind of balance that.

244
00:12:29,664 --> 00:12:33,290
But in the case of the machine learning

245
00:12:33,360 --> 00:12:35,046
example and comparing models, you're

246
00:12:35,158 --> 00:12:36,662
necessarily talking about a much larger

247
00:12:36,726 --> 00:12:38,346
markup blanket than just a singular one

248
00:12:38,368 --> 00:12:42,080
there, right? Yes, same thing.

249
00:12:42,930 --> 00:12:45,246
Yes. And just like many concepts have

250
00:12:45,268 --> 00:12:47,866
like a broader conversational, informal

251
00:12:47,898 --> 00:12:49,790
sense in a narrow, more technical sense,

252
00:12:49,860 --> 00:12:52,474
assuming we know the present means fully

253
00:12:52,522 --> 00:12:54,366
knowing the present, fully knowing the

254
00:12:54,388 --> 00:12:56,626
blanket. So it's like but I could still

255
00:12:56,648 --> 00:12:58,526
learn things about the past. So that's

256
00:12:58,558 --> 00:13:00,142
not to say that there isn't novel

257
00:13:00,206 --> 00:13:01,982
information that you could discover

258
00:13:02,046 --> 00:13:04,066
about the past. Like you could still go

259
00:13:04,088 --> 00:13:05,858
back in that chess game and learn

260
00:13:05,944 --> 00:13:07,606
information. So it's not that there

261
00:13:07,628 --> 00:13:10,086
isn't information in the past. It's not

262
00:13:10,108 --> 00:13:11,974
that it wouldn't even be interesting.

263
00:13:12,172 --> 00:13:14,614
It's that for the purposes of how the

264
00:13:14,652 --> 00:13:17,434
present goes into the next time step the

265
00:13:17,472 --> 00:13:20,406
present blanket in this temporal Markov

266
00:13:20,438 --> 00:13:21,994
chain, which is like a blanket through

267
00:13:22,032 --> 00:13:25,386
time, it contains the information you

268
00:13:25,408 --> 00:13:28,170
need for the transition frequencies.

269
00:13:30,290 --> 00:13:33,694
Okay. They define that it's the set

270
00:13:33,732 --> 00:13:36,606
of variables that mediate. And also the

271
00:13:36,628 --> 00:13:40,750
Markov blanket using last names,

272
00:13:42,230 --> 00:13:45,682
personal opinion is not helpful because

273
00:13:45,736 --> 00:13:47,790
not only are there multiple Markovs,

274
00:13:47,870 --> 00:13:49,986
but the Markovian property is not

275
00:13:50,008 --> 00:13:51,854
something that's technical or defined.

276
00:13:51,982 --> 00:13:55,174
So maybe someday we'll have better ways

277
00:13:55,212 --> 00:13:56,966
to describe and be more specific that

278
00:13:56,988 --> 00:13:59,990
don't involve invoking ambiguity around

279
00:14:00,060 --> 00:14:03,974
names. That being said, it was worked

280
00:14:04,012 --> 00:14:07,802
out analytically by Markov and sun and

281
00:14:07,856 --> 00:14:11,030
others, but most recently it was Pearl

282
00:14:11,110 --> 00:14:14,374
1988 and causal inference with Bayesian

283
00:14:14,422 --> 00:14:16,266
perspective. So this is not like an

284
00:14:16,288 --> 00:14:19,142
active inference, ism it's? Drawing upon

285
00:14:19,206 --> 00:14:22,330
a total Bayesian statistical framework,

286
00:14:22,490 --> 00:14:24,426
any Bayes graph that's not fully

287
00:14:24,458 --> 00:14:27,114
connected is going to have some nodes

288
00:14:27,242 --> 00:14:29,406
that intermediate. So that's going to

289
00:14:29,428 --> 00:14:31,418
relate to this question. So what is a

290
00:14:31,444 --> 00:14:32,974
statistical rather than a non

291
00:14:33,022 --> 00:14:34,610
statistical interaction?

292
00:14:37,190 --> 00:14:39,186
Ali and then anyone else who would like

293
00:14:39,208 --> 00:14:40,500
to address that?

294
00:14:42,710 --> 00:14:44,934
Well, I think it has something to do

295
00:14:44,972 --> 00:14:47,814
with the way these interactions are

296
00:14:47,852 --> 00:14:50,054
parameterized and modeled. Because, you

297
00:14:50,092 --> 00:14:53,142
see, every phenomena can be

298
00:14:53,276 --> 00:14:57,462
parameterized and modeled from many

299
00:14:57,516 --> 00:15:01,282
various perspectives and frameworks

300
00:15:01,346 --> 00:15:04,986
within various frameworks. And the

301
00:15:05,008 --> 00:15:07,622
reason I think they put the term

302
00:15:07,686 --> 00:15:10,254
statistical in parentheses is that they

303
00:15:10,292 --> 00:15:13,934
mean that these variables mediate all

304
00:15:14,052 --> 00:15:16,334
interactions that have been

305
00:15:16,372 --> 00:15:20,046
parameterized statistically. So I

306
00:15:20,068 --> 00:15:23,710
think it refers to the nature

307
00:15:23,870 --> 00:15:26,754
of parameterizing and modeling these

308
00:15:26,792 --> 00:15:30,020
interactions as opposed to

309
00:15:30,550 --> 00:15:34,310
distinguishing between statistical and

310
00:15:34,380 --> 00:15:37,030
non statistical interactions.

311
00:15:42,610 --> 00:15:45,386
All right, so anyone else can raise

312
00:15:45,418 --> 00:15:46,782
their hand, but just here's a few

313
00:15:46,836 --> 00:15:49,802
thoughts on that. A statistical

314
00:15:49,866 --> 00:15:53,102
interaction is the edge in a causal

315
00:15:53,166 --> 00:15:56,386
Bayes graph. And people might

316
00:15:56,408 --> 00:15:58,034
be more familiar or have seen like

317
00:15:58,072 --> 00:16:00,162
structural equation modeling, where

318
00:16:00,216 --> 00:16:02,686
nodes are variables and edges are the

319
00:16:02,728 --> 00:16:05,910
correlation between or among variables.

320
00:16:06,970 --> 00:16:09,334
Conditioning on the structure of the

321
00:16:09,372 --> 00:16:13,186
graph. In the causal Bayes graph,

322
00:16:13,298 --> 00:16:15,294
the nodes are variables and the edges

323
00:16:15,362 --> 00:16:18,666
are statistical causal influences. So

324
00:16:18,848 --> 00:16:21,802
causality and statistics is not always

325
00:16:21,856 --> 00:16:24,186
the same as what people mean by cause in

326
00:16:24,208 --> 00:16:26,390
the real world. But like granger

327
00:16:26,470 --> 00:16:29,482
causality and just this notion of like

328
00:16:29,536 --> 00:16:31,120
coarse graining and cause.

329
00:16:32,850 --> 00:16:36,830
It may line up with the

330
00:16:36,900 --> 00:16:39,114
sort of narrative natural language

331
00:16:39,162 --> 00:16:42,014
description that somebody has between

332
00:16:42,212 --> 00:16:43,618
when they're speaking. It might be

333
00:16:43,624 --> 00:16:44,978
narrower than that, it might be a

334
00:16:44,984 --> 00:16:46,018
different thing than that. It might be

335
00:16:46,024 --> 00:16:47,380
more general than that.

336
00:16:49,830 --> 00:16:52,270
What would a non statistical interaction

337
00:16:52,350 --> 00:16:52,980
be?

338
00:16:55,290 --> 00:16:57,638
There's various ways to approach that.

339
00:16:57,724 --> 00:16:59,766
It's kind of pointing towards some sort

340
00:16:59,788 --> 00:17:02,994
of like a touch could be an interaction.

341
00:17:03,122 --> 00:17:04,726
But what if things are touching but

342
00:17:04,748 --> 00:17:07,866
those variables don't change as a

343
00:17:07,888 --> 00:17:10,874
function of their touching? Then do

344
00:17:10,912 --> 00:17:14,314
those things interact or not? That's one

345
00:17:14,352 --> 00:17:17,162
question. And then cause there's like

346
00:17:17,216 --> 00:17:20,014
just tremendous real world and

347
00:17:20,052 --> 00:17:21,914
philosophy questions like what causes

348
00:17:21,962 --> 00:17:23,310
what, what's the difference making

349
00:17:23,380 --> 00:17:24,926
cause? What's the cause that makes a

350
00:17:24,948 --> 00:17:28,346
difference? Necessity and sufficiency.

351
00:17:28,538 --> 00:17:31,522
There's so many questions in this like

352
00:17:31,576 --> 00:17:34,194
causal philosophy and this is

353
00:17:34,232 --> 00:17:36,386
highlighting. We're talking about the

354
00:17:36,408 --> 00:17:38,850
model. We made a Bayes graph with

355
00:17:38,920 --> 00:17:42,162
height, weight and shirt color and here

356
00:17:42,216 --> 00:17:44,786
are the statistical effectors. And so

357
00:17:44,808 --> 00:17:45,998
we're not saying that there's no

358
00:17:46,024 --> 00:17:47,718
interaction between this and that in the

359
00:17:47,724 --> 00:17:49,798
real world. Now we're within the model

360
00:17:49,964 --> 00:17:51,714
and we're talking about the causal

361
00:17:51,762 --> 00:17:54,226
graph. And again, unless the Bayes graph

362
00:17:54,258 --> 00:17:56,650
is fully connected, there's going to be

363
00:17:56,720 --> 00:18:00,266
some partitioning scheme that

364
00:18:00,288 --> 00:18:03,290
will result in some set of nodes being

365
00:18:03,360 --> 00:18:04,842
conditionally independent from another

366
00:18:04,896 --> 00:18:07,786
set of nodes when conditioned upon a

367
00:18:07,808 --> 00:18:09,998
blanket. So it's not like features of

368
00:18:10,004 --> 00:18:11,918
the real world or even variables in a

369
00:18:11,924 --> 00:18:13,886
statistical equation can just be

370
00:18:13,908 --> 00:18:16,686
unilaterally tagged as blanket states.

371
00:18:16,868 --> 00:18:18,782
It's always a partition that

372
00:18:18,836 --> 00:18:21,970
coinstantiates two sides,

373
00:18:22,710 --> 00:18:24,658
internal and external. But there's a

374
00:18:24,664 --> 00:18:27,986
symmetry and the blanket. So it's not

375
00:18:28,008 --> 00:18:29,714
like features of the world or even

376
00:18:29,752 --> 00:18:31,790
features of the model are intrinsically,

377
00:18:31,870 --> 00:18:34,310
internal, external or blanket states.

378
00:18:34,460 --> 00:18:36,854
But that's a partitioning scheme that

379
00:18:36,892 --> 00:18:39,910
can be applied to Bayes graphs of like a

380
00:18:39,980 --> 00:18:43,554
vast various structures

381
00:18:43,602 --> 00:18:46,474
of Bayes graphs. And Bayes graphs can be

382
00:18:46,512 --> 00:18:48,922
applied to a vast number of real world

383
00:18:48,976 --> 00:18:52,838
situations. And many, many papers

384
00:18:52,854 --> 00:18:55,754
and live streams discuss sort of like

385
00:18:55,792 --> 00:18:59,066
all encompassing Markovian monism Markov

386
00:18:59,098 --> 00:19:00,826
blankets all the way down nested Markov

387
00:19:00,858 --> 00:19:03,454
blankets. Are the world ranging to the

388
00:19:03,492 --> 00:19:07,290
critical perspectives, not necessarily

389
00:19:07,370 --> 00:19:09,022
detractors, but just those who believe

390
00:19:09,076 --> 00:19:13,106
that the usage of the concept is out

391
00:19:13,128 --> 00:19:15,586
of alignment with ways that people have

392
00:19:15,688 --> 00:19:19,220
used it. Mike and then anyone else.

393
00:19:21,910 --> 00:19:24,082
Does it make sense to think of a Markov

394
00:19:24,146 --> 00:19:27,346
blanket in the context of an internal

395
00:19:27,378 --> 00:19:29,714
agent state and an external environment?

396
00:19:29,842 --> 00:19:32,294
Is the Markov blanket serving as this

397
00:19:32,332 --> 00:19:35,250
kind of a decoupling component because

398
00:19:35,340 --> 00:19:38,438
of the way that things are conditionally

399
00:19:38,534 --> 00:19:42,054
independent based on the variables

400
00:19:42,102 --> 00:19:43,370
inside the blanket?

401
00:19:51,090 --> 00:19:52,400
What do people think?

402
00:19:56,210 --> 00:19:56,960
Yes.

403
00:20:00,130 --> 00:20:02,046
I mean, for the internal state to be

404
00:20:02,068 --> 00:20:03,842
different than the external state or

405
00:20:03,896 --> 00:20:06,366
have some other equilibrium other non

406
00:20:06,398 --> 00:20:08,798
equilibrium state that the external

407
00:20:08,894 --> 00:20:11,666
environment is in, you would have to

408
00:20:11,688 --> 00:20:15,366
necessarily have I'm

409
00:20:15,388 --> 00:20:16,726
not sure if decoupling is the right

410
00:20:16,748 --> 00:20:18,230
word, but some sort of conditional,

411
00:20:18,810 --> 00:20:22,418
dependent and independent sort of zone

412
00:20:22,514 --> 00:20:25,190
that separates those two regions.

413
00:20:26,330 --> 00:20:28,950
So here's figure 31. Thank you, Brock.

414
00:20:29,290 --> 00:20:32,226
The active in the sensory states compose

415
00:20:32,338 --> 00:20:36,310
the blanket now in various

416
00:20:36,670 --> 00:20:39,066
live streams and papers, the history of

417
00:20:39,088 --> 00:20:40,938
the concept again from the analytical

418
00:20:41,034 --> 00:20:44,170
pre computational phrasing of insulation

419
00:20:44,250 --> 00:20:47,326
of fluctuation of random variables to

420
00:20:47,428 --> 00:20:50,138
Pearl's Bayesian and computational

421
00:20:50,234 --> 00:20:53,086
framing. However, Pearl's Markov blanket

422
00:20:53,118 --> 00:20:55,954
concept doesn't have a delineation of

423
00:20:55,992 --> 00:20:58,914
active and sensory states. It's only

424
00:20:58,952 --> 00:21:02,114
like there's one kind of fabric in that

425
00:21:02,152 --> 00:21:04,740
blanket. It's just blanket states.

426
00:21:05,290 --> 00:21:09,110
Friston maybe this also will be

427
00:21:09,180 --> 00:21:11,926
shown to be traced to other places and

428
00:21:11,948 --> 00:21:14,726
ways. But one of the core things that

429
00:21:14,748 --> 00:21:16,758
Friston at all have brought into the

430
00:21:16,764 --> 00:21:19,866
picture was interpreting within the

431
00:21:19,888 --> 00:21:22,362
blanket states the states that have

432
00:21:22,416 --> 00:21:24,346
incoming dependencies to the system of

433
00:21:24,368 --> 00:21:27,162
interest as sensory and then the states

434
00:21:27,216 --> 00:21:29,098
that have outgoing dependencies from the

435
00:21:29,104 --> 00:21:32,800
system of interest as active states. So

436
00:21:33,490 --> 00:21:36,366
people may already see challenges and

437
00:21:36,388 --> 00:21:39,066
complexities that arise with the arrows

438
00:21:39,098 --> 00:21:41,646
and the directions. And a lot of that is

439
00:21:41,668 --> 00:21:43,586
addressed in the how particular is the

440
00:21:43,608 --> 00:21:46,820
free energy principle of Aguilera et al.

441
00:21:49,190 --> 00:21:50,802
We're going to continue talking about

442
00:21:50,856 --> 00:21:54,094
this entity partitioning Ali

443
00:21:54,142 --> 00:21:55,250
and then Lyle.

444
00:21:57,770 --> 00:22:01,320
Well, I think we should point to a very

445
00:22:01,690 --> 00:22:05,046
important typographical error in

446
00:22:05,068 --> 00:22:08,794
this picture here because in this

447
00:22:08,912 --> 00:22:12,074
figure, active states are expressed in

448
00:22:12,112 --> 00:22:15,014
terms of external states and markup

449
00:22:15,062 --> 00:22:17,546
blankets and sensory states are

450
00:22:17,568 --> 00:22:20,202
expressed in terms of internal states

451
00:22:20,256 --> 00:22:22,826
and markup blankets. But it should be

452
00:22:22,848 --> 00:22:25,482
vice versa. I mean, the flows of

453
00:22:25,536 --> 00:22:27,342
internal and active states are

454
00:22:27,396 --> 00:22:30,094
independent of external states and the

455
00:22:30,132 --> 00:22:33,394
flows of external and sensory states do

456
00:22:33,432 --> 00:22:36,786
not depend on internal states. So we

457
00:22:36,808 --> 00:22:40,946
should change x and mu in those

458
00:22:41,128 --> 00:22:42,370
two equations.

459
00:22:43,750 --> 00:22:48,034
Yes, sometimes with a possible typo

460
00:22:48,082 --> 00:22:52,230
like that, it's so Egregious blatant

461
00:22:52,570 --> 00:22:54,694
that it's challenging to even know. But

462
00:22:54,732 --> 00:22:58,054
we can absolutely ask the authors. But

463
00:22:58,092 --> 00:23:00,214
just to read the equation and think

464
00:23:00,252 --> 00:23:03,430
about why it is that way. The dot

465
00:23:03,510 --> 00:23:05,754
is the rate of change of a variable. So

466
00:23:05,792 --> 00:23:07,978
the internal states are mu and so this

467
00:23:07,984 --> 00:23:09,158
is the rate of change of internal

468
00:23:09,174 --> 00:23:10,998
states, rate of change of external

469
00:23:11,014 --> 00:23:13,758
states x and the rate of change of u,

470
00:23:13,844 --> 00:23:15,914
the active states and y the sensory

471
00:23:15,962 --> 00:23:18,702
states. So we're looking at how these

472
00:23:18,756 --> 00:23:21,226
partitioned states in a Bayes graph

473
00:23:21,418 --> 00:23:24,434
change through time. The states that are

474
00:23:24,472 --> 00:23:27,010
the blanket and the internal are the

475
00:23:27,080 --> 00:23:29,806
particular states. Those are referring

476
00:23:29,838 --> 00:23:31,282
to the particle that's like figure

477
00:23:31,336 --> 00:23:33,086
versus ground, the particle that's

478
00:23:33,118 --> 00:23:35,166
moving around the curious particle. The

479
00:23:35,208 --> 00:23:38,022
active entity is the particular states

480
00:23:38,156 --> 00:23:40,280
that is partitioning the thing,

481
00:23:40,650 --> 00:23:44,550
literally the thing away from the niche.

482
00:23:44,970 --> 00:23:46,886
Then there's the blanket states that are

483
00:23:46,908 --> 00:23:49,146
intermediating that interface. And then

484
00:23:49,168 --> 00:23:51,322
we'll also talk about autonomous states

485
00:23:51,456 --> 00:23:53,306
which are just the internal and the

486
00:23:53,328 --> 00:23:56,602
active states. So the equation is saying

487
00:23:56,656 --> 00:23:59,082
the rate of change in, for example,

488
00:23:59,216 --> 00:24:02,414
active states is a flow function

489
00:24:02,532 --> 00:24:05,040
F and a noise function.

490
00:24:05,490 --> 00:24:08,334
Both the flow and the noise function the

491
00:24:08,372 --> 00:24:10,862
subscript is referring to like that one.

492
00:24:10,916 --> 00:24:13,554
It's kind of like IPSO in Latin like,

493
00:24:13,592 --> 00:24:16,420
it's the flow on Mu and the noise on Mu,

494
00:24:17,350 --> 00:24:20,226
the flow, which is what the principle of

495
00:24:20,248 --> 00:24:23,394
least action converges us towards in the

496
00:24:23,432 --> 00:24:26,114
limit, when the statistical fluctuations

497
00:24:26,162 --> 00:24:30,294
from the Omega are low, is a function of

498
00:24:30,412 --> 00:24:33,638
certain variables. And so this is saying

499
00:24:33,724 --> 00:24:37,866
the flow of active states is

500
00:24:37,888 --> 00:24:41,930
a function of external sensory

501
00:24:42,910 --> 00:24:46,058
and active states. However,

502
00:24:46,224 --> 00:24:49,894
as Ali has pointed to, the arguments

503
00:24:49,942 --> 00:24:52,734
that should be guiding the flow of

504
00:24:52,772 --> 00:24:55,706
active states are actually the blanket

505
00:24:55,738 --> 00:24:59,306
states and internal states, not external

506
00:24:59,338 --> 00:25:02,362
states. And then analogously sensory

507
00:25:02,426 --> 00:25:04,366
states should have a flow that's defined

508
00:25:04,398 --> 00:25:08,286
in terms of blanket states and external

509
00:25:08,318 --> 00:25:10,500
states, not internal states.

510
00:25:12,390 --> 00:25:16,834
Lyle and then Ali yeah.

511
00:25:16,872 --> 00:25:18,326
So actually I think you're getting right

512
00:25:18,348 --> 00:25:19,798
right at the question I had because I

513
00:25:19,804 --> 00:25:22,562
was confused about the bi directional

514
00:25:22,626 --> 00:25:24,866
arrows, particularly between internal

515
00:25:24,898 --> 00:25:26,840
states and active states. Right?

516
00:25:28,410 --> 00:25:31,542
And I think you're drilling right into

517
00:25:31,596 --> 00:25:33,350
that. I still don't completely

518
00:25:33,420 --> 00:25:35,014
understand what that picture should look

519
00:25:35,052 --> 00:25:40,042
like. But I have trouble conceptually

520
00:25:40,146 --> 00:25:41,646
I sort of get a conceptually, I feel

521
00:25:41,668 --> 00:25:43,582
like I get the Markov blanket, but that

522
00:25:43,636 --> 00:25:45,182
representation. I have trouble working

523
00:25:45,236 --> 00:25:46,880
through the details on that.

524
00:25:48,130 --> 00:25:51,134
Cool. So, guest stream number seven.

525
00:25:51,332 --> 00:25:53,298
How particular is the physics of the

526
00:25:53,304 --> 00:25:56,558
free energy principle? It explores

527
00:25:56,654 --> 00:26:00,910
different entity niche

528
00:26:00,990 --> 00:26:03,842
causal relationships. Like,

529
00:26:03,896 --> 00:26:06,550
for example, we could imagine a simple

530
00:26:06,620 --> 00:26:09,174
around the clock entity model.

531
00:26:09,372 --> 00:26:11,702
External states induce sensory states.

532
00:26:11,756 --> 00:26:14,502
One directional arrow, sensory goes into

533
00:26:14,556 --> 00:26:16,854
internal, internal to active, active to

534
00:26:16,892 --> 00:26:18,794
external, like an UDA loop or something

535
00:26:18,832 --> 00:26:21,366
like that, but just an around the clock,

536
00:26:21,478 --> 00:26:23,574
no bi directionality, no connection

537
00:26:23,622 --> 00:26:26,634
between active and sensory. Given this

538
00:26:26,672 --> 00:26:28,858
partitioning, one could imagine that

539
00:26:28,944 --> 00:26:32,442
topology of cause, one could imagine

540
00:26:32,506 --> 00:26:34,606
all kinds of topologies of cause, some

541
00:26:34,628 --> 00:26:36,586
that violate the Markov blanket

542
00:26:36,618 --> 00:26:38,766
condition, like internal states and

543
00:26:38,788 --> 00:26:41,854
external states that are no longer

544
00:26:41,972 --> 00:26:43,538
internal and external because they would

545
00:26:43,544 --> 00:26:45,806
have a causal link. But even preserving

546
00:26:45,838 --> 00:26:48,386
the Markov blanket condition, we could

547
00:26:48,408 --> 00:26:50,802
imagine different topologies, different

548
00:26:50,856 --> 00:26:53,154
sparsities of couplings between these

549
00:26:53,192 --> 00:26:56,382
different states. A bi directional arrow

550
00:26:56,446 --> 00:26:58,258
is kind of like there would be a non

551
00:26:58,274 --> 00:27:01,238
zero cause. And in the other side of the

552
00:27:01,244 --> 00:27:03,670
matrix, it would also be a non zero

553
00:27:03,740 --> 00:27:05,986
cause versus a unidirectional

554
00:27:06,018 --> 00:27:08,738
relationship where like variable two has

555
00:27:08,764 --> 00:27:10,394
a causal influence on three, but three

556
00:27:10,432 --> 00:27:14,506
doesn't have it on two. In this paper in

557
00:27:14,528 --> 00:27:16,906
Guest Room 7.1 and that paper and

558
00:27:16,928 --> 00:27:20,170
further line of research, they explore

559
00:27:20,530 --> 00:27:23,710
what sparse coupling structures,

560
00:27:24,130 --> 00:27:28,010
causal architectures of the entity niche

561
00:27:28,170 --> 00:27:31,338
relationship and interface would grant

562
00:27:31,434 --> 00:27:37,394
different statistical capacities. So I

563
00:27:37,432 --> 00:27:40,046
could be wrong on this, but active

564
00:27:40,078 --> 00:27:42,530
inference is not a commitment to this

565
00:27:42,600 --> 00:27:46,290
specific coupling architecture.

566
00:27:46,450 --> 00:27:49,010
It may be possible to design or describe

567
00:27:49,090 --> 00:27:51,798
or imagine systems that have different

568
00:27:51,884 --> 00:27:55,830
causal architectures, maybe even

569
00:27:55,980 --> 00:27:59,370
true at this basal most kernel loop,

570
00:28:00,190 --> 00:28:02,234
but certainly true when we start

571
00:28:02,272 --> 00:28:04,922
thinking about nested structures and

572
00:28:04,976 --> 00:28:08,170
cognitive structures and so on. So yes,

573
00:28:08,240 --> 00:28:10,800
it is a little unfortunate about this.

574
00:28:11,490 --> 00:28:15,294
However, this is just

575
00:28:15,332 --> 00:28:18,142
thinking about causal relationships of

576
00:28:18,196 --> 00:28:25,394
the particular partition and

577
00:28:25,432 --> 00:28:26,878
we're describing statistical

578
00:28:26,974 --> 00:28:29,714
relationships here causal influence, as

579
00:28:29,752 --> 00:28:31,522
inferred from like, time series data

580
00:28:31,576 --> 00:28:34,078
with Granger causality or other methods

581
00:28:34,254 --> 00:28:37,606
on specific random variables. So this is

582
00:28:37,628 --> 00:28:40,198
not the conversational notion of cause,

583
00:28:40,364 --> 00:28:42,802
but what I'm thinking is eventually

584
00:28:42,866 --> 00:28:44,726
resulting in things happening in the

585
00:28:44,748 --> 00:28:47,254
outside world, or aren't things in the

586
00:28:47,292 --> 00:28:49,654
outside world eventually changing

587
00:28:49,702 --> 00:28:51,898
things? Yes, but just like the

588
00:28:51,904 --> 00:28:55,610
chessboard through time, the blanket is

589
00:28:55,680 --> 00:28:58,570
statistically intermediating. And again,

590
00:28:58,640 --> 00:29:01,214
that's why it gets so messy with the

591
00:29:01,252 --> 00:29:03,914
application of like well, the retina

592
00:29:03,962 --> 00:29:05,920
must be the sense states.

593
00:29:09,090 --> 00:29:12,480
If one can read that example and

594
00:29:13,110 --> 00:29:15,778
not fall into the quicksand, it could be

595
00:29:15,784 --> 00:29:19,790
didactic. But to tag retina

596
00:29:19,870 --> 00:29:23,266
as sense state is like the tip of the

597
00:29:23,288 --> 00:29:26,840
iceberg of a partially specified model,

598
00:29:28,010 --> 00:29:29,686
often one where the measurements have

599
00:29:29,708 --> 00:29:32,486
not actually occurred and so on. So then

600
00:29:32,668 --> 00:29:34,918
that can be extremely difficult for

601
00:29:35,004 --> 00:29:36,598
those with less familiarity with a

602
00:29:36,604 --> 00:29:39,466
formalism to generalize accurately from,

603
00:29:39,648 --> 00:29:41,574
because shouldn't it be like retina

604
00:29:41,622 --> 00:29:43,386
sense states and then the arm is the

605
00:29:43,408 --> 00:29:46,166
active state, but it's a partitioning

606
00:29:46,198 --> 00:29:48,330
that coinstantiates and it's model

607
00:29:48,400 --> 00:29:51,018
dependent, it's not describing features

608
00:29:51,034 --> 00:29:54,030
of the real world. Ollie?

609
00:29:57,830 --> 00:30:03,374
Yeah, I just wanted to .1 of Ramset

610
00:30:03,422 --> 00:30:06,534
at All's recent fascinating paper

611
00:30:06,572 --> 00:30:08,966
on Bayesian mechanics, which I put the

612
00:30:08,988 --> 00:30:12,374
link in the chat. And in that paper,

613
00:30:12,492 --> 00:30:15,254
especially in section three, they have a

614
00:30:15,292 --> 00:30:18,582
very illuminating discussion

615
00:30:18,646 --> 00:30:21,580
about these whole business of

616
00:30:22,350 --> 00:30:25,274
partitioning and markup blankets. And

617
00:30:25,392 --> 00:30:28,618
one sentence that's pretty relevant to

618
00:30:28,624 --> 00:30:30,654
our discussion here is that the key

619
00:30:30,692 --> 00:30:32,414
point to note is that the flow of

620
00:30:32,452 --> 00:30:35,486
internal and active components I e.

621
00:30:35,508 --> 00:30:37,406
Their trajectory through state space

622
00:30:37,508 --> 00:30:39,658
does not depend upon external

623
00:30:39,834 --> 00:30:42,606
components. And reciprocally, the flow

624
00:30:42,638 --> 00:30:45,310
of external and sensory states or paths

625
00:30:45,470 --> 00:30:48,082
does not depend upon internal states or

626
00:30:48,136 --> 00:30:52,020
paths. From page 15. So yeah,

627
00:30:52,870 --> 00:30:56,246
if you refer to that article, it has

628
00:30:56,268 --> 00:30:59,430
been elaborated much explicitly.

629
00:31:00,410 --> 00:31:04,294
Also, in four days we will have

630
00:31:04,492 --> 00:31:07,086
Dalton and Maxwell et al. For a guest

631
00:31:07,138 --> 00:31:10,202
stream. The paper just came out.

632
00:31:10,256 --> 00:31:12,854
Now we'll be able to have a discussion

633
00:31:12,902 --> 00:31:16,074
with them and learn and ask them

634
00:31:16,112 --> 00:31:18,534
questions. So if people have suggestions

635
00:31:18,582 --> 00:31:21,294
for guest streams, that can be

636
00:31:21,332 --> 00:31:22,766
accomplished. If people want to

637
00:31:22,788 --> 00:31:24,414
facilitate or participate in different

638
00:31:24,452 --> 00:31:26,302
streams, if they have questions for

639
00:31:26,356 --> 00:31:28,942
different streams. Being there live,

640
00:31:28,996 --> 00:31:31,562
but especially getting involved eagerly

641
00:31:31,626 --> 00:31:33,934
and actively and early is the biggest

642
00:31:33,982 --> 00:31:36,354
leverage point because that allows us to

643
00:31:36,392 --> 00:31:38,194
design the material so that it's, like

644
00:31:38,232 --> 00:31:40,354
permanently useful rather than

645
00:31:40,392 --> 00:31:42,926
potentially ad hoc questions that arise

646
00:31:42,958 --> 00:31:45,720
during which can be super important and

647
00:31:46,090 --> 00:31:48,374
hopefully people can see some

648
00:31:48,492 --> 00:31:50,582
affordances for participation and

649
00:31:50,636 --> 00:31:53,542
development. Let's just get to this last

650
00:31:53,596 --> 00:31:56,630
question and we have other questions,

651
00:31:56,700 --> 00:31:59,226
but these are essential and it's one of

652
00:31:59,248 --> 00:32:02,570
the opening formalisms of the chapter.

653
00:32:04,590 --> 00:32:06,954
Just to conclude here though, why does

654
00:32:06,992 --> 00:32:08,538
independence between the flows on the

655
00:32:08,544 --> 00:32:10,640
two sides of the blanket matter so much?

656
00:32:22,210 --> 00:32:24,894
These are good things to think about.

657
00:32:25,092 --> 00:32:27,390
Just one short thought would be without

658
00:32:27,460 --> 00:32:29,966
independence between the flows, there is

659
00:32:29,988 --> 00:32:31,794
no distinguishing one thing from

660
00:32:31,832 --> 00:32:34,450
another. Ali.

661
00:32:37,380 --> 00:32:41,104
And also I think it relates to what

662
00:32:41,142 --> 00:32:44,792
we read in chapter two about hidden

663
00:32:44,876 --> 00:32:47,828
states because that's what the word

664
00:32:47,914 --> 00:32:51,156
hidden probably refers to. I mean,

665
00:32:51,258 --> 00:32:54,116
internal state does not have direct

666
00:32:54,218 --> 00:32:56,096
access to external states and vice

667
00:32:56,128 --> 00:32:59,064
versa. So that Markup Blanket pretty

668
00:32:59,102 --> 00:33:03,000
much formalizes this hiddenness,

669
00:33:04,380 --> 00:33:07,732
yes, awesome. And partially

670
00:33:07,796 --> 00:33:11,560
observable models of the Bayesian

671
00:33:11,640 --> 00:33:14,344
type which are used in partially

672
00:33:14,392 --> 00:33:16,920
observable Markov decision processes,

673
00:33:17,080 --> 00:33:19,516
expectation maximization, any kind of

674
00:33:19,538 --> 00:33:21,884
Bayesian priors and hyper priors and so

675
00:33:21,922 --> 00:33:26,060
on. All of these have Bayes graphs

676
00:33:26,220 --> 00:33:28,476
that reflect conditionally independent

677
00:33:28,508 --> 00:33:30,892
variables. So it's not that they're

678
00:33:30,956 --> 00:33:34,144
independent in a conversational way,

679
00:33:34,182 --> 00:33:36,292
like they don't have any way of

680
00:33:36,426 --> 00:33:39,140
communicating, it's that they are

681
00:33:39,210 --> 00:33:41,296
specifically involved in a causal

682
00:33:41,328 --> 00:33:42,752
network that has conditional

683
00:33:42,816 --> 00:33:45,072
independence. But we'll hopefully

684
00:33:45,136 --> 00:33:47,184
develop more answers and notes here.

685
00:33:47,322 --> 00:33:52,020
We'll move on. What is the differences

686
00:33:52,100 --> 00:33:54,116
between and among the terms Bayesian

687
00:33:54,148 --> 00:33:56,932
brain hypothesis, predictive processing,

688
00:33:56,996 --> 00:33:59,204
predictive coding and active inference?

689
00:33:59,332 --> 00:34:01,192
Might you be able to suggest references

690
00:34:01,256 --> 00:34:02,556
or resources for where these

691
00:34:02,578 --> 00:34:05,964
distinctions are delineated? Sure, so

692
00:34:06,002 --> 00:34:08,108
anyone can add more. But here's, I think

693
00:34:08,194 --> 00:34:11,324
two key resources here. The first is

694
00:34:11,362 --> 00:34:14,720
live stream 43. In 430,

695
00:34:14,870 --> 00:34:18,060
Maria gave a really excellent overview

696
00:34:18,220 --> 00:34:20,636
of predictive processing and predictive

697
00:34:20,668 --> 00:34:23,084
coding from a historical perspective.

698
00:34:23,212 --> 00:34:25,124
And briefly, she proposed that

699
00:34:25,162 --> 00:34:27,108
predictive coding can refer to a

700
00:34:27,114 --> 00:34:30,084
unidirectional data encoding scheme of

701
00:34:30,122 --> 00:34:31,296
the kind that we see in signal

702
00:34:31,328 --> 00:34:33,892
processing, video compression, so on,

703
00:34:34,026 --> 00:34:36,452
whereas predictive processing is

704
00:34:36,506 --> 00:34:38,404
referring to a bi directional

705
00:34:38,452 --> 00:34:41,672
architecture where predictive coding is

706
00:34:41,726 --> 00:34:45,272
implemented in this ongoing top down,

707
00:34:45,326 --> 00:34:48,772
bottom up way. Bayesian brain

708
00:34:48,836 --> 00:34:51,396
hypothesis was also touched on and we

709
00:34:51,438 --> 00:34:53,196
connected this to active inference. But

710
00:34:53,218 --> 00:34:56,540
43.0 is a long technical review paper,

711
00:34:56,610 --> 00:34:58,220
but we have three discussions on it

712
00:34:58,290 --> 00:34:59,752
predictive coding, theoretical,

713
00:34:59,816 --> 00:35:03,104
experimental review, recent paper,

714
00:35:03,302 --> 00:35:07,740
very good source for the predictive

715
00:35:07,820 --> 00:35:10,156
processing encoding. And predictive

716
00:35:10,188 --> 00:35:12,544
processing encoding initially was more

717
00:35:12,582 --> 00:35:15,192
of about a sensory framework.

718
00:35:15,356 --> 00:35:18,644
However, at the end of that paper they

719
00:35:18,682 --> 00:35:20,164
show, okay, now we're going to do

720
00:35:20,202 --> 00:35:22,176
predictive processing on action. It's

721
00:35:22,208 --> 00:35:25,184
active inference. So predictive

722
00:35:25,232 --> 00:35:29,832
processing about action is six

723
00:35:29,886 --> 00:35:32,440
of one and half dozen of another within

724
00:35:32,510 --> 00:35:35,320
a margin of reasonable approximation,

725
00:35:36,140 --> 00:35:38,216
similar, but there's also some key

726
00:35:38,318 --> 00:35:41,660
differences like reliance on different

727
00:35:41,810 --> 00:35:43,996
formalisms. But these are all things for

728
00:35:44,018 --> 00:35:46,268
us to explore and unpack as we work on

729
00:35:46,274 --> 00:35:47,870
the ontology and so on.

730
00:35:50,240 --> 00:35:52,716
Specifically, predictive coding active

731
00:35:52,748 --> 00:35:55,296
inference in the Bayesian brain. This is

732
00:35:55,318 --> 00:35:58,348
an interview that a departed colleague

733
00:35:58,444 --> 00:36:02,752
and I did with Karl Friston in 2018 and

734
00:36:02,806 --> 00:36:05,468
we specifically asked the Bayesian brain

735
00:36:05,484 --> 00:36:07,248
hypothesis, predictive coding and the

736
00:36:07,254 --> 00:36:09,184
free energy principle are often equated

737
00:36:09,232 --> 00:36:11,396
with one another. You yourself have

738
00:36:11,418 --> 00:36:13,044
suggested that the three frameworks are

739
00:36:13,082 --> 00:36:15,440
variations of the same basic mechanisms.

740
00:36:15,600 --> 00:36:17,990
So 2018 was a very different time.

741
00:36:18,620 --> 00:36:21,124
Active inference had not been delineated

742
00:36:21,252 --> 00:36:24,664
from FEP in the same way that it is

743
00:36:24,702 --> 00:36:27,064
coming to be now. And there was a lot of

744
00:36:27,102 --> 00:36:30,396
other differences between then and now.

745
00:36:30,498 --> 00:36:33,836
But he gives an extended answer. So for

746
00:36:33,858 --> 00:36:36,012
people who want to learn about that,

747
00:36:36,146 --> 00:36:39,560
his extended answer and Martin's

748
00:36:39,640 --> 00:36:41,496
Restatement of the Bayesian brain

749
00:36:41,528 --> 00:36:43,984
hypothesis are still some of the best

750
00:36:44,022 --> 00:36:46,210
places to find clarity on that issue.

751
00:36:48,100 --> 00:36:50,176
Does anyone have any other thoughts or

752
00:36:50,198 --> 00:36:51,250
questions on this?

753
00:36:55,000 --> 00:36:56,756
Just one other note, while anyone can

754
00:36:56,778 --> 00:36:58,704
raise their hand, is like the Bayesian

755
00:36:58,752 --> 00:37:02,756
brain hypothesis sometimes could

756
00:37:02,778 --> 00:37:06,532
be used in a very instrumentalist way.

757
00:37:06,666 --> 00:37:08,888
We're using Bayesian statistics to do

758
00:37:08,974 --> 00:37:12,824
neurobehavioral research. It might be a

759
00:37:12,862 --> 00:37:15,972
realist implementational claim,

760
00:37:16,036 --> 00:37:18,132
like the brain is doing Bayesian

761
00:37:18,196 --> 00:37:20,096
statistics or something like Bayesian

762
00:37:20,148 --> 00:37:22,968
statistics. So this hypothesis floats

763
00:37:23,064 --> 00:37:25,480
kind of among the layers of Mars

764
00:37:25,560 --> 00:37:27,928
analysis, like implementational

765
00:37:28,024 --> 00:37:29,820
algorithmic, computational.

766
00:37:31,600 --> 00:37:33,552
And people do use it to mean different

767
00:37:33,606 --> 00:37:37,116
things. And in Bayesian

768
00:37:37,148 --> 00:37:39,216
graphs, in Bayesian statistics, it can

769
00:37:39,238 --> 00:37:41,616
be about perception or it could be about

770
00:37:41,718 --> 00:37:44,204
action. So Bayesian brain hypothesis,

771
00:37:44,252 --> 00:37:46,932
depending on how somebody frames it and

772
00:37:46,986 --> 00:37:48,564
what specific models they're talking

773
00:37:48,602 --> 00:37:51,556
about, might include, for example, all

774
00:37:51,578 --> 00:37:54,256
of these, because these might be applied

775
00:37:54,368 --> 00:37:56,324
in a Bayesian framework to talk about

776
00:37:56,362 --> 00:37:58,840
the brain. Ben.

777
00:38:01,580 --> 00:38:03,928
Yeah, I think you've covered it really

778
00:38:04,014 --> 00:38:06,760
well, but I wish I'd have had access or

779
00:38:06,830 --> 00:38:09,544
knowledge of the result, the talk that

780
00:38:09,582 --> 00:38:11,656
you just mentioned. Because trying to

781
00:38:11,678 --> 00:38:13,384
differentiate predictive processing from

782
00:38:13,422 --> 00:38:14,876
active inference has been a kind of

783
00:38:14,898 --> 00:38:16,796
source of pain and confusion for me over

784
00:38:16,818 --> 00:38:19,532
the last few months. And I thought

785
00:38:19,586 --> 00:38:21,064
another way of putting it, perhaps

786
00:38:21,112 --> 00:38:22,312
because I think I know the difference

787
00:38:22,386 --> 00:38:25,776
now is essentially some

788
00:38:25,958 --> 00:38:28,092
presentations of predictive processing

789
00:38:28,156 --> 00:38:30,656
are active inference in the sense that

790
00:38:30,678 --> 00:38:33,280
they're highly embodied, inactive,

791
00:38:33,620 --> 00:38:35,888
embedded. And so if you have a

792
00:38:35,894 --> 00:38:37,856
predictive processing that draws on

793
00:38:37,878 --> 00:38:39,716
these Fourier accounts of cognition, it

794
00:38:39,738 --> 00:38:41,616
tends to just that just is active

795
00:38:41,648 --> 00:38:43,284
inference. Active inference is kind of

796
00:38:43,322 --> 00:38:46,516
necessarily inactive and embodied. And

797
00:38:46,538 --> 00:38:49,336
there's a paper I should say there's a

798
00:38:49,358 --> 00:38:51,956
paper by I believe it's called Wilding

799
00:38:51,988 --> 00:38:54,276
the Predictive Brain. It's by Andy

800
00:38:54,308 --> 00:38:58,436
Clark, Kate Nave, Mark Miller and George

801
00:38:58,468 --> 00:39:01,372
Dean, I think, which basically takes

802
00:39:01,426 --> 00:39:04,172
predictive processing as a theory of

803
00:39:04,306 --> 00:39:07,260
neural processing and weaves in these

804
00:39:07,330 --> 00:39:09,804
kind of cognitive, these four E

805
00:39:09,842 --> 00:39:11,628
narratives really, really well and kind

806
00:39:11,634 --> 00:39:13,976
of fleshes out a much more active

807
00:39:14,008 --> 00:39:16,364
inferencey picture. The paper brings

808
00:39:16,412 --> 00:39:17,916
predictive process and active inference

809
00:39:17,948 --> 00:39:19,490
together really nicely, I think.

810
00:39:20,420 --> 00:39:23,952
Thanks. Great suggestion. And just

811
00:39:24,006 --> 00:39:25,684
without going into too much detail, if

812
00:39:25,722 --> 00:39:28,244
this is the causal graph architecture of

813
00:39:28,282 --> 00:39:31,204
a predictive processing system, one can

814
00:39:31,242 --> 00:39:35,188
imagine that, like, Mu is being a

815
00:39:35,194 --> 00:39:37,044
Markov blanket with respect to these two

816
00:39:37,082 --> 00:39:39,956
epsilons or so on. So predictive

817
00:39:39,988 --> 00:39:43,096
processing doesn't highlight as much the

818
00:39:43,118 --> 00:39:45,476
Markov blanket. Formalism predictive

819
00:39:45,508 --> 00:39:47,544
processing is not a physics for

820
00:39:47,582 --> 00:39:51,676
particular systems like FEP is,

821
00:39:51,858 --> 00:39:55,932
but it's not incompatible. So maybe

822
00:39:55,986 --> 00:39:57,816
they're just different fingers pointing

823
00:39:57,848 --> 00:39:59,596
at similar or different parts of the

824
00:39:59,618 --> 00:40:03,300
moon. So there isn't an incompatibility,

825
00:40:03,480 --> 00:40:05,890
especially as over the recent years,

826
00:40:06,500 --> 00:40:08,764
active inference implemented predictive

827
00:40:08,812 --> 00:40:10,800
architectures and approaches, and

828
00:40:10,870 --> 00:40:13,452
predictive processing started to undergo

829
00:40:13,516 --> 00:40:16,772
that Pragmatic, inactive, four E, five

830
00:40:16,826 --> 00:40:21,860
E, whatever, infusion which

831
00:40:21,930 --> 00:40:25,076
led to them modeling action as a

832
00:40:25,098 --> 00:40:28,136
variable. And so all they did was they

833
00:40:28,158 --> 00:40:29,752
just made it. So instead of the free

834
00:40:29,806 --> 00:40:31,812
energy being only about sensory

835
00:40:31,876 --> 00:40:33,976
observations. And expectations. They

836
00:40:33,998 --> 00:40:38,116
just tucked action in and it doesn't

837
00:40:38,308 --> 00:40:41,144
radically restructure the architecture.

838
00:40:41,272 --> 00:40:43,624
It just means that action is a variable

839
00:40:43,672 --> 00:40:48,460
in these equations. So 43.1

840
00:40:48,610 --> 00:40:50,616
or zero, one and two are all good places

841
00:40:50,648 --> 00:40:52,190
to look. Okay,

842
00:40:54,800 --> 00:40:56,288
this was just a short question.

843
00:40:56,374 --> 00:40:58,064
Internal state and external state were

844
00:40:58,102 --> 00:41:00,144
added to the ontology. But sometimes,

845
00:41:00,342 --> 00:41:02,208
like, if you have a quotation mark and

846
00:41:02,214 --> 00:41:04,210
then an at, it won't bring it up.

847
00:41:05,080 --> 00:41:07,124
So sometimes you have to type it with an

848
00:41:07,162 --> 00:41:08,390
at first.

849
00:41:10,440 --> 00:41:14,564
Okay, in our last 15

850
00:41:14,682 --> 00:41:15,350
minutes,

851
00:41:18,880 --> 00:41:21,536
okay, these two are good. Maybe we could

852
00:41:21,558 --> 00:41:23,216
do a first pass on them and then in the

853
00:41:23,238 --> 00:41:25,552
coming week, like add notes and more

854
00:41:25,606 --> 00:41:29,356
questions to discuss. They wrote,

855
00:41:29,468 --> 00:41:31,664
if one defines preferred states as

856
00:41:31,702 --> 00:41:33,796
expected states, then one can say that

857
00:41:33,818 --> 00:41:35,636
living organisms must minimize the

858
00:41:35,658 --> 00:41:38,020
surprise of their sensory observations.

859
00:41:38,600 --> 00:41:41,764
I'm not clear on the ontology here. Is

860
00:41:41,802 --> 00:41:43,584
it that preference is the same as

861
00:41:43,642 --> 00:41:46,904
expectation or that formally we can use

862
00:41:46,942 --> 00:41:48,552
them in the same equation or something

863
00:41:48,606 --> 00:41:51,784
else? Does active inference make

864
00:41:51,822 --> 00:41:54,552
ontological claims like preference is

865
00:41:54,606 --> 00:41:56,664
actually expectation, just as heat is

866
00:41:56,702 --> 00:41:59,100
actually the excitation of molecules

867
00:41:59,600 --> 00:42:01,308
more generally? Is the free energy and

868
00:42:01,314 --> 00:42:03,068
physics just an analogy or is it an

869
00:42:03,074 --> 00:42:06,316
ontological assertion? Who would like to

870
00:42:06,338 --> 00:42:08,044
approach one of the aspects of this

871
00:42:08,082 --> 00:42:08,670
question?

872
00:42:21,720 --> 00:42:23,652
I would like to take a stop, but again,

873
00:42:23,706 --> 00:42:27,352
I guess guess yes, please. I guess

874
00:42:27,486 --> 00:42:29,864
it's not saying that they're the same,

875
00:42:30,062 --> 00:42:34,072
but that if we're minimizing free

876
00:42:34,126 --> 00:42:36,644
energy, we're trying to make it the

877
00:42:36,702 --> 00:42:39,768
same. But if they're surprised,

878
00:42:39,864 --> 00:42:42,696
they won't be the same. I guess the goal

879
00:42:42,728 --> 00:42:45,230
is to get them as close as possible.

880
00:42:47,280 --> 00:42:51,024
That will be my guess on this. Thank

881
00:42:51,062 --> 00:42:54,384
you. Good insight. I'll also point to

882
00:42:54,422 --> 00:42:56,880
two ways that expectation is

883
00:42:56,950 --> 00:43:00,524
conversationally used. The expectation

884
00:43:00,652 --> 00:43:04,304
with the fancy e is the expected

885
00:43:04,352 --> 00:43:06,704
mean of a distribution. Like, expected

886
00:43:06,752 --> 00:43:09,076
returns might be about the future, but

887
00:43:09,098 --> 00:43:10,836
it's actually referring to the mean

888
00:43:10,938 --> 00:43:13,796
estimate of a distribution. In the

889
00:43:13,818 --> 00:43:15,976
Gaussian case, the mean and the mode are

890
00:43:15,998 --> 00:43:18,564
the same. Mode seeking and mean seeking

891
00:43:18,612 --> 00:43:20,648
are equivalent. There can also be a

892
00:43:20,654 --> 00:43:23,432
variance estimator and so on. So the

893
00:43:23,486 --> 00:43:25,672
expectation of a Gaussian is like

894
00:43:25,726 --> 00:43:29,080
tremendously informative. Expectation

895
00:43:29,160 --> 00:43:32,760
can also mean things that are predicted

896
00:43:32,840 --> 00:43:33,950
about the future.

897
00:43:37,040 --> 00:43:38,556
That's a conversational. What do you

898
00:43:38,578 --> 00:43:41,984
expect it to be tomorrow? Both can be

899
00:43:42,022 --> 00:43:44,768
conjoined. Like what do you expect the

900
00:43:44,774 --> 00:43:47,376
temperature to be tomorrow? Is the

901
00:43:47,398 --> 00:43:49,936
expectation of a distribution of the

902
00:43:49,958 --> 00:43:51,084
uncertainty of the temperature

903
00:43:51,132 --> 00:43:53,460
distribution at the time point tomorrow.

904
00:43:54,040 --> 00:43:56,704
So they're not exclusive definitions.

905
00:43:56,832 --> 00:43:59,492
It just has to be understood what this

906
00:43:59,546 --> 00:44:01,924
means because it'd be like, well, if our

907
00:44:01,962 --> 00:44:05,224
predictions about the future are our

908
00:44:05,262 --> 00:44:07,176
preferences, then there's all kinds of

909
00:44:07,198 --> 00:44:10,410
tangles that one might find himself in.

910
00:44:11,660 --> 00:44:15,370
Also the

911
00:44:20,450 --> 00:44:24,320
I'm not remembering which number it was,

912
00:44:24,850 --> 00:44:28,858
but the dual usage

913
00:44:29,034 --> 00:44:32,114
of the same term to reflect the

914
00:44:32,152 --> 00:44:36,180
organism's preferred states and also

915
00:44:37,110 --> 00:44:40,834
the centering of the distribution at

916
00:44:40,872 --> 00:44:42,434
that time point and at other time

917
00:44:42,472 --> 00:44:43,774
points. And then just like jessica

918
00:44:43,822 --> 00:44:47,190
mentioned, this operation of free energy

919
00:44:47,260 --> 00:44:50,162
minimization is in service of reducing

920
00:44:50,226 --> 00:44:52,994
the divergence between the preferred

921
00:44:53,042 --> 00:44:56,778
state and the expectation of

922
00:44:56,784 --> 00:44:59,914
the preferred state, which could be set

923
00:44:59,952 --> 00:45:03,414
or learned, and then the observations

924
00:45:03,462 --> 00:45:06,922
that are coming in. So in one

925
00:45:06,976 --> 00:45:09,626
equation, it leans more towards the

926
00:45:09,648 --> 00:45:11,162
English description of a preference.

927
00:45:11,226 --> 00:45:14,400
Like the organism prefers to be at 72.

928
00:45:15,170 --> 00:45:17,534
And in the other sense, that is like the

929
00:45:17,572 --> 00:45:20,494
expectation of a distribution. And

930
00:45:20,532 --> 00:45:22,850
there's some observation distribution

931
00:45:23,350 --> 00:45:26,802
with a minimization of a divergence such

932
00:45:26,856 --> 00:45:31,410
that if the observations were

933
00:45:31,480 --> 00:45:34,094
realizing preferences, then those

934
00:45:34,152 --> 00:45:35,750
distributions would be aligned.

935
00:45:37,850 --> 00:45:39,000
So, yes,

936
00:45:42,090 --> 00:45:44,214
these terms are more like phenomena or

937
00:45:44,252 --> 00:45:47,514
natural language tags. Also,

938
00:45:47,552 --> 00:45:50,890
it'll be awesome. In the last two weeks

939
00:45:50,960 --> 00:45:54,458
of June, in 46,

940
00:45:54,544 --> 00:45:55,866
active inference models do not

941
00:45:55,888 --> 00:45:58,314
contradict folk psychology. This will be

942
00:45:58,352 --> 00:46:00,714
extended, extended discussions on,

943
00:46:00,752 --> 00:46:03,630
like, wanting beliefs, intentions.

944
00:46:04,050 --> 00:46:06,862
Which variables in active are

945
00:46:06,916 --> 00:46:09,246
appropriate for being described that

946
00:46:09,268 --> 00:46:11,826
way? Does it contradict one or the

947
00:46:11,848 --> 00:46:13,774
other? Those are like things that we'll

948
00:46:13,822 --> 00:46:17,026
explore. So the

949
00:46:17,048 --> 00:46:19,634
equations are just what they are. And

950
00:46:19,672 --> 00:46:22,130
then in some usages,

951
00:46:23,030 --> 00:46:26,146
a variable is like the organism's

952
00:46:26,178 --> 00:46:27,814
preferred states, what it's trying to

953
00:46:27,852 --> 00:46:30,982
reduce its divergence between. And also

954
00:46:31,116 --> 00:46:33,446
that is like, where it expects to be.

955
00:46:33,548 --> 00:46:35,862
And that's what licenses the use of

956
00:46:35,916 --> 00:46:39,530
surprise and minimizing. Surprise

957
00:46:42,590 --> 00:46:45,178
because an observation right at the

958
00:46:45,184 --> 00:46:46,982
center of the Gaussian is minimally

959
00:46:47,046 --> 00:46:48,906
surprising. We talked about that in

960
00:46:48,928 --> 00:46:50,826
chapter two. An observation that's

961
00:46:50,858 --> 00:46:52,874
outside of the Gaussian is highly

962
00:46:52,922 --> 00:46:56,334
surprising. So if we have some sort

963
00:46:56,372 --> 00:47:00,362
of distribution of outcomes,

964
00:47:00,506 --> 00:47:02,546
we could ask how closely are they

965
00:47:02,568 --> 00:47:05,746
aligned with our preferences in terms of

966
00:47:05,768 --> 00:47:09,410
surprise due to this dual use

967
00:47:09,480 --> 00:47:11,250
of the same variables?

968
00:47:12,870 --> 00:47:14,946
Does active inference make ontological

969
00:47:14,978 --> 00:47:18,454
claims? Do theories make claims? Do

970
00:47:18,492 --> 00:47:21,126
people make claims? E. G preference is

971
00:47:21,148 --> 00:47:22,886
actually expectation, just as heat is

972
00:47:22,908 --> 00:47:24,870
actually excitation of molecules.

973
00:47:27,070 --> 00:47:29,660
Anyone can raise their hand at any time.

974
00:47:32,510 --> 00:47:35,254
We'll talk about that in the folk

975
00:47:35,302 --> 00:47:37,098
psychology. But it's an interesting

976
00:47:37,184 --> 00:47:41,254
question. Ben yeah, I wonder

977
00:47:41,312 --> 00:47:43,790
if it seems to me like these questions

978
00:47:43,860 --> 00:47:45,578
are taking us maybe into the map

979
00:47:45,674 --> 00:47:49,018
territory debate that I think we spoke

980
00:47:49,034 --> 00:47:53,902
about last time, about how realist

981
00:47:53,966 --> 00:47:59,106
or concrete should we think about the

982
00:47:59,208 --> 00:48:01,166
kind of ontological claims of active

983
00:48:01,198 --> 00:48:03,954
inference? It's certainly the last part

984
00:48:03,992 --> 00:48:05,510
of that question, I think, about whether

985
00:48:05,580 --> 00:48:07,430
we should take it as an analogy.

986
00:48:08,890 --> 00:48:10,214
So, yeah, I think it's quite a big

987
00:48:10,252 --> 00:48:11,800
question, but I don't know.

988
00:48:15,770 --> 00:48:18,534
Okay, I won't find the slide here, but

989
00:48:18,652 --> 00:48:20,314
is the free energy in physics an

990
00:48:20,352 --> 00:48:22,474
analogy? Not sure if this is saying,

991
00:48:22,512 --> 00:48:24,454
like, the Gibbs free energy or if that's

992
00:48:24,502 --> 00:48:26,166
actually talking about the variational

993
00:48:26,198 --> 00:48:28,250
free energy or the expected free energy,

994
00:48:28,400 --> 00:48:31,406
which are statistical so I don't know if

995
00:48:31,428 --> 00:48:34,282
it's an analogy or an ontological

996
00:48:34,346 --> 00:48:38,782
assertion other than just

997
00:48:38,836 --> 00:48:40,958
to connect it to a linear model with a

998
00:48:40,964 --> 00:48:43,586
Gaussian Error distribution. Is that an

999
00:48:43,608 --> 00:48:45,458
ontological assertion that there is a

1000
00:48:45,464 --> 00:48:47,186
Gaussian Error distribution in the

1001
00:48:47,208 --> 00:48:49,140
world? No.

1002
00:48:49,750 --> 00:48:52,622
So are statistical quantities

1003
00:48:52,686 --> 00:48:54,760
ontological assertions about the world?

1004
00:48:56,570 --> 00:48:58,514
Maybe there's some nuance, but broadly

1005
00:48:58,562 --> 00:48:59,720
speaking, no.

1006
00:49:03,690 --> 00:49:06,262
And also, just like on the Math learning

1007
00:49:06,316 --> 00:49:09,926
group, we've expanded our operation due

1008
00:49:09,958 --> 00:49:13,514
to many active participants. So just

1009
00:49:13,552 --> 00:49:17,174
note that the meetings are at 19 UTC

1010
00:49:17,222 --> 00:49:18,794
on Monday, Tuesday, Wednesday and

1011
00:49:18,832 --> 00:49:21,130
Thursday. And they're in the discord

1012
00:49:21,210 --> 00:49:24,480
voice chat, not in this gather. But

1013
00:49:25,730 --> 00:49:29,166
we've been working on the resources on

1014
00:49:29,188 --> 00:49:32,062
the notation, basic and background

1015
00:49:32,126 --> 00:49:34,306
questions, as well as overviews of the

1016
00:49:34,328 --> 00:49:36,274
math for different chapters, like

1017
00:49:36,312 --> 00:49:39,060
basically just summarizing and then

1018
00:49:40,790 --> 00:49:42,962
several people, and this is an example

1019
00:49:43,016 --> 00:49:44,466
of the broken link. So, like

1020
00:49:44,488 --> 00:49:46,534
variational, free energy is deleted. So

1021
00:49:46,572 --> 00:49:48,166
just one time somebody has to come

1022
00:49:48,188 --> 00:49:51,526
through and just add it back in. But

1023
00:49:51,548 --> 00:49:53,510
these are natural language descriptions

1024
00:49:54,010 --> 00:49:57,802
that will be very easy to transmute into

1025
00:49:57,856 --> 00:49:59,494
computer code and translate amongst

1026
00:49:59,542 --> 00:50:02,266
human languages and provides a lot of

1027
00:50:02,288 --> 00:50:05,706
legibility and comprehensibility. So a

1028
00:50:05,728 --> 00:50:07,510
lot of the math group has been modifying

1029
00:50:07,590 --> 00:50:10,462
the equations and everybody is welcome

1030
00:50:10,516 --> 00:50:13,838
to join those discord sessions and

1031
00:50:13,924 --> 00:50:15,934
contribute with questions or with

1032
00:50:15,972 --> 00:50:17,694
knowledge and expertise. Like, no matter

1033
00:50:17,732 --> 00:50:19,406
where somebody is in learning or

1034
00:50:19,428 --> 00:50:21,858
discussing these equations, they are the

1035
00:50:21,864 --> 00:50:23,858
essence of active inference. So

1036
00:50:23,944 --> 00:50:25,774
questions, random notes, related

1037
00:50:25,822 --> 00:50:28,350
thoughts, expertise are all essential

1038
00:50:28,430 --> 00:50:29,934
for us improving our shared

1039
00:50:29,982 --> 00:50:32,802
understanding. And then just in the last

1040
00:50:32,856 --> 00:50:36,934
five minutes, page 42, they wrote in

1041
00:50:36,972 --> 00:50:39,222
Advanced organisms, preferred states can

1042
00:50:39,276 --> 00:50:41,730
also extend to learned cognitive goals

1043
00:50:41,810 --> 00:50:44,018
and go on to say that advanced organisms

1044
00:50:44,034 --> 00:50:47,174
like humans, can achieve preferred

1045
00:50:47,222 --> 00:50:50,202
states by increasingly abstract social

1046
00:50:50,256 --> 00:50:51,706
and cultural strategies. Like they

1047
00:50:51,728 --> 00:50:54,202
talked about thermoregulation and then

1048
00:50:54,256 --> 00:50:55,354
all the way up to, like, air

1049
00:50:55,392 --> 00:50:58,346
conditioning distribution systems. My

1050
00:50:58,368 --> 00:51:01,758
question is, if they are cast in

1051
00:51:01,764 --> 00:51:05,246
terms of active inference, must all of

1052
00:51:05,268 --> 00:51:07,166
these preferred states and strategies be

1053
00:51:07,188 --> 00:51:08,686
ultimately linked to survival in some

1054
00:51:08,708 --> 00:51:11,830
way? Or in the case of advanced

1055
00:51:11,850 --> 00:51:13,874
organisms, can free energy be related to

1056
00:51:13,912 --> 00:51:15,490
something other than survival?

1057
00:51:19,440 --> 00:51:21,470
Mike and then anyone else?

1058
00:51:23,520 --> 00:51:26,320
Yeah, it feels like this notion of

1059
00:51:26,390 --> 00:51:28,192
survival and preferred states gets

1060
00:51:28,246 --> 00:51:31,650
conflated in a sort of odd way.

1061
00:51:32,260 --> 00:51:33,964
Not everything is about survival.

1062
00:51:34,012 --> 00:51:37,344
Right? And so you might have some

1063
00:51:37,382 --> 00:51:40,708
measurement of surprise if you're in a

1064
00:51:40,714 --> 00:51:43,120
temperature that's 120 degrees, but it's

1065
00:51:43,200 --> 00:51:45,140
survivable for a period of time,

1066
00:51:45,210 --> 00:51:46,772
whereas if you're in a temperature of

1067
00:51:46,826 --> 00:51:50,996
300 degrees Fahrenheit, not survivable.

1068
00:51:51,108 --> 00:51:54,536
Right. But if you contrast that with

1069
00:51:54,558 --> 00:51:56,020
other things that could be equally

1070
00:51:56,100 --> 00:51:58,228
surprising or outside the distribution,

1071
00:51:58,324 --> 00:52:02,036
as you described it earlier, the notion

1072
00:52:02,068 --> 00:52:04,216
of that all swans are white, but then

1073
00:52:04,238 --> 00:52:07,448
you find a black swan. And so you'd

1074
00:52:07,464 --> 00:52:09,244
never conceived that there might be a

1075
00:52:09,282 --> 00:52:11,404
black swan before that lives outside

1076
00:52:11,602 --> 00:52:13,516
your distribution and creates a

1077
00:52:13,538 --> 00:52:15,352
surprise, but it's not necessarily

1078
00:52:15,416 --> 00:52:16,780
survival rated.

1079
00:52:18,560 --> 00:52:21,164
Thank you. There's sort of a missing

1080
00:52:21,212 --> 00:52:23,040
severity in there somewhere.

1081
00:52:24,580 --> 00:52:27,120
Okay. Thank you, Ollie. And then Lyle.

1082
00:52:29,140 --> 00:52:32,944
I think Live here is used somehow

1083
00:52:32,992 --> 00:52:36,820
in a more direct way, meaning system

1084
00:52:36,890 --> 00:52:39,620
that resists dispersion and energy

1085
00:52:39,690 --> 00:52:42,736
dissipation. So it's not necessarily

1086
00:52:42,848 --> 00:52:44,740
biological survival.

1087
00:52:46,620 --> 00:52:49,032
Yes, great point. Systems that fail to

1088
00:52:49,086 --> 00:52:52,216
persist, survive, will not continue to

1089
00:52:52,238 --> 00:52:55,116
be that thing. And that's just in like a

1090
00:52:55,138 --> 00:52:57,224
physical sense, repeated measurements

1091
00:52:57,272 --> 00:52:59,084
are only enabled by systems that are

1092
00:52:59,122 --> 00:53:01,260
persistent at that timescale, not

1093
00:53:01,330 --> 00:53:04,076
eternally. And so when we want to have a

1094
00:53:04,098 --> 00:53:06,528
theory or a framework or a physics for

1095
00:53:06,614 --> 00:53:10,272
things, then they have to look

1096
00:53:10,326 --> 00:53:12,720
as if they are minimizing free energy.

1097
00:53:12,870 --> 00:53:14,944
Otherwise they will simply not be that

1098
00:53:14,982 --> 00:53:17,840
thing. Ben and then lyle.

1099
00:53:21,720 --> 00:53:23,924
This was my question. I suppose just to

1100
00:53:23,962 --> 00:53:25,510
kind of clarify it quickly.

1101
00:53:27,080 --> 00:53:29,076
One of the things I wonder most about

1102
00:53:29,098 --> 00:53:30,648
active inferences. It seems to me, at

1103
00:53:30,654 --> 00:53:33,528
least in my life, I'm quite often making

1104
00:53:33,614 --> 00:53:35,752
decisions and having preferences that

1105
00:53:35,806 --> 00:53:39,284
seem so abstracted from my attunement

1106
00:53:39,332 --> 00:53:41,444
with my environment or my continued

1107
00:53:41,492 --> 00:53:43,784
viability as a system. Like my

1108
00:53:43,822 --> 00:53:45,756
preference for which mug I'm going to

1109
00:53:45,778 --> 00:53:48,284
drink coffee out of in the morning. It

1110
00:53:48,322 --> 00:53:51,788
seems in some sense removed from

1111
00:53:51,954 --> 00:53:54,124
my free energy the way that free energy

1112
00:53:54,162 --> 00:53:56,240
is described in the literature.

1113
00:53:57,140 --> 00:53:58,800
That's kind of what I meant.

1114
00:54:00,340 --> 00:54:03,628
Great. In yesterday's

1115
00:54:03,724 --> 00:54:07,152
45.2 we asked specifically, like,

1116
00:54:07,206 --> 00:54:10,852
how can all behavior be optimal when

1117
00:54:10,986 --> 00:54:13,028
mistakes are made? Or I'll be asked the

1118
00:54:13,034 --> 00:54:14,208
question, like, what about when there's

1119
00:54:14,224 --> 00:54:16,960
like sacrificial or altruistic behavior?

1120
00:54:17,120 --> 00:54:20,548
And there's a great answer

1121
00:54:20,634 --> 00:54:24,104
in 45.2, but suffice to say that with

1122
00:54:24,142 --> 00:54:26,456
different priors, all behavior can be

1123
00:54:26,478 --> 00:54:28,616
cast as optimal behavior. So the

1124
00:54:28,638 --> 00:54:31,512
normativity isn't referring to what

1125
00:54:31,566 --> 00:54:33,768
should be done or what is best, but it's

1126
00:54:33,784 --> 00:54:36,860
rather like a process normativity. Lyle

1127
00:54:38,080 --> 00:54:41,276
right, yeah. This for me tees up the

1128
00:54:41,298 --> 00:54:43,116
question I continue to have about the

1129
00:54:43,138 --> 00:54:46,716
approach, which is how does the concept

1130
00:54:46,748 --> 00:54:50,050
of novelty, which some

1131
00:54:51,380 --> 00:54:54,400
organisms would pursue,

1132
00:54:54,820 --> 00:54:58,176
fit into this concept of I mean,

1133
00:54:58,198 --> 00:55:00,244
how would it even be represented here?

1134
00:55:00,362 --> 00:55:03,232
And novelty is not just a human trait,

1135
00:55:03,296 --> 00:55:05,540
but you would see it across all kinds of

1136
00:55:05,610 --> 00:55:09,092
creatures that would seek out

1137
00:55:09,146 --> 00:55:12,392
novel and surprising experience, not

1138
00:55:12,446 --> 00:55:15,736
expected. So for me, it's kind of an

1139
00:55:15,758 --> 00:55:17,604
open question about how that's captured

1140
00:55:17,652 --> 00:55:20,036
in this framework. Yes, the beginning

1141
00:55:20,068 --> 00:55:23,900
and ending of 45.2 carl's focus

1142
00:55:23,970 --> 00:55:27,576
was on curiosity and there's

1143
00:55:27,608 --> 00:55:32,008
various ways to approach it. And it's

1144
00:55:32,024 --> 00:55:33,836
an excellent question about novelty of

1145
00:55:33,858 --> 00:55:36,752
different types and scales. And within

1146
00:55:36,806 --> 00:55:39,360
the hierarchical modeling, one can

1147
00:55:39,430 --> 00:55:41,884
understand novelty of different kinds.

1148
00:55:42,012 --> 00:55:44,140
And this again is just like the kernel.

1149
00:55:44,220 --> 00:55:45,644
This is like the single linear

1150
00:55:45,692 --> 00:55:48,132
regression. And then there's like model

1151
00:55:48,186 --> 00:55:50,256
selection across hierarchically nested

1152
00:55:50,288 --> 00:55:53,824
linear models, much development beyond

1153
00:55:53,872 --> 00:55:56,260
the kernel. But this is like a kernel.

1154
00:55:56,600 --> 00:55:58,292
And especially when thinking about

1155
00:55:58,346 --> 00:56:01,624
expected free energy, a path can move

1156
00:56:01,662 --> 00:56:05,336
to a novel area because it's part

1157
00:56:05,358 --> 00:56:07,320
of an expected trajectory that does

1158
00:56:07,390 --> 00:56:10,650
reduce risk and ambiguity and so on. So

1159
00:56:11,660 --> 00:56:13,276
that's the deflationary approach to

1160
00:56:13,298 --> 00:56:16,424
novelty pursuit. Jessica and then we'll

1161
00:56:16,472 --> 00:56:18,060
end the discussion.

1162
00:56:23,650 --> 00:56:27,134
At the end. You mentioned it. I guess I

1163
00:56:27,172 --> 00:56:30,126
see novelty as sort of like the

1164
00:56:30,148 --> 00:56:33,794
epistemic origin. And so it's like

1165
00:56:33,912 --> 00:56:38,450
you are seeking new

1166
00:56:38,520 --> 00:56:41,862
information, new things, in order to

1167
00:56:41,916 --> 00:56:44,790
minimize that uncertainty.

1168
00:56:45,610 --> 00:56:49,170
Not so much that novelty is uncertainty,

1169
00:56:49,330 --> 00:56:53,438
because if we look at Nova's

1170
00:56:53,474 --> 00:56:55,722
thinking that, oh, it's new and

1171
00:56:55,776 --> 00:56:59,610
therefore it's going to be surprising

1172
00:57:00,430 --> 00:57:03,420
and so we want to minimize those things

1173
00:57:03,950 --> 00:57:07,054
then yes. Or also if we look at

1174
00:57:07,172 --> 00:57:09,566
uncertainty equal to risk, we can say

1175
00:57:09,588 --> 00:57:13,482
like novelty is because of the unknown

1176
00:57:13,626 --> 00:57:15,802
represented risk and if we're minimizing

1177
00:57:15,866 --> 00:57:17,882
uncertainty, we're trying to minimize

1178
00:57:17,946 --> 00:57:20,766
risk. But from what I saw a little bit

1179
00:57:20,788 --> 00:57:24,078
on chapter two, it's sort of like we're

1180
00:57:24,094 --> 00:57:26,526
not necessarily trying to minimize risk

1181
00:57:26,638 --> 00:57:30,130
or the unknown.

1182
00:57:31,210 --> 00:57:33,430
Depending on our preferences, we might

1183
00:57:33,500 --> 00:57:36,306
tolerate high risk. And what we're

1184
00:57:36,338 --> 00:57:38,822
trying to minimize is the surprise of

1185
00:57:38,876 --> 00:57:43,114
what we expect. If I'm in finance, and I

1186
00:57:43,152 --> 00:57:45,942
expect very high risk in an investment,

1187
00:57:46,006 --> 00:57:50,490
but I already know that and

1188
00:57:50,560 --> 00:57:52,140
high risk comes back.

1189
00:57:53,870 --> 00:57:56,586
My uncertainty was minimized, even

1190
00:57:56,608 --> 00:57:58,526
though there was a lot of risk or there

1191
00:57:58,548 --> 00:58:01,834
were a lot of unknowns or novelty

1192
00:58:01,882 --> 00:58:03,310
and things like that. But it was already

1193
00:58:03,380 --> 00:58:05,534
in my expectation of what was going to

1194
00:58:05,572 --> 00:58:08,826
happen. So I was already minimizing

1195
00:58:08,858 --> 00:58:11,090
that, even though in reality it may look

1196
00:58:11,160 --> 00:58:15,566
like that there was a lot of uncertainty

1197
00:58:15,758 --> 00:58:19,874
in actuality, but in my model there

1198
00:58:19,912 --> 00:58:22,486
isn't. So that's kind of like how I

1199
00:58:22,508 --> 00:58:25,446
explained that to me a little bit and in

1200
00:58:25,468 --> 00:58:28,520
terms of novelty for adventure and

1201
00:58:30,250 --> 00:58:32,262
curiosity and things like that, I

1202
00:58:32,316 --> 00:58:35,706
equated more to epistemic foraging as a

1203
00:58:35,728 --> 00:58:37,546
weight of learning and updating the

1204
00:58:37,568 --> 00:58:39,740
model and that's why we're doing it.

1205
00:58:40,510 --> 00:58:42,810
Thanks, Jessica. I'll just add one

1206
00:58:42,880 --> 00:58:45,366
closing note on that. I would argue that

1207
00:58:45,408 --> 00:58:49,210
it's the pragmatic absolutism,

1208
00:58:49,290 --> 00:58:51,230
the reinforcement and reward learning

1209
00:58:51,300 --> 00:58:54,282
centrism that has curtailed an effective

1210
00:58:54,346 --> 00:58:57,360
theory of novelty or curiosity because

1211
00:58:57,810 --> 00:58:59,514
radically different kinds of actions

1212
00:58:59,562 --> 00:59:01,138
have to be coerced into a value

1213
00:59:01,224 --> 00:59:03,314
framework, whether it's deep Q learning

1214
00:59:03,432 --> 00:59:05,426
or reinforcement or anything like that.

1215
00:59:05,528 --> 00:59:07,570
There has to be like a novelty bonus or

1216
00:59:07,640 --> 00:59:10,046
all these other ad hoc unprincipled

1217
00:59:10,078 --> 00:59:11,574
approaches. They might be super

1218
00:59:11,612 --> 00:59:12,774
technical, they might be super

1219
00:59:12,812 --> 00:59:15,062
effective, but they're not driven from

1220
00:59:15,116 --> 00:59:18,454
first principles in variational free

1221
00:59:18,492 --> 00:59:21,206
energy f and expected free energy g.

1222
00:59:21,388 --> 00:59:24,298
There's this minimum of two with

1223
00:59:24,384 --> 00:59:27,434
pragmatic value which is to bring

1224
00:59:27,472 --> 00:59:29,306
alignment between the preferences and

1225
00:59:29,328 --> 00:59:32,762
the observations and the epistemic value

1226
00:59:32,896 --> 00:59:36,670
associated with what is casually called

1227
00:59:36,740 --> 00:59:39,534
novelty or curiosity. At that scale of

1228
00:59:39,572 --> 00:59:41,854
potentially a hierarchical model, So

1229
00:59:41,972 --> 00:59:44,110
active inference does provide

1230
00:59:44,260 --> 00:59:47,438
partitioning and an imperative that

1231
00:59:47,524 --> 00:59:49,426
helps us address the phenomena of

1232
00:59:49,448 --> 00:59:52,562
curiosity and of novelty in a way that

1233
00:59:52,616 --> 00:59:55,486
is quite disparate from trying to coerce

1234
00:59:55,518 --> 00:59:58,190
it into a value of curiosity.

1235
00:59:58,270 --> 01:00:02,114
Is expected pragmatic value or the value

1236
01:00:02,152 --> 01:00:04,366
of basic research is the expected

1237
01:00:04,398 --> 01:00:07,106
utility that it could bring. But these

1238
01:00:07,128 --> 01:00:09,554
are all really awesome and open and

1239
01:00:09,592 --> 01:00:13,050
ongoing questions. So we will close the

1240
01:00:13,120 --> 01:00:15,254
recording and then have just a 1 minute

1241
01:00:15,302 --> 01:00:18,026
break. Then in this room we'll continue

1242
01:00:18,128 --> 01:00:21,386
with tools, organizational unit and if

1243
01:00:21,408 --> 01:00:22,874
anybody wants to talk about something

1244
01:00:22,912 --> 01:00:25,302
else, they can go to a different gather

1245
01:00:25,366 --> 01:00:27,546
room. So thanks everybody and see you

1246
01:00:27,568 --> 01:00:28,380
next week.


