
00:01 Daniel:
Hello everyone. Thanks for joining the second meeting where we're going to be discussing chapter one. It's the active Textbook group and it's May 12, 2022. You can click on my screen and that will show you the full screen. We updated the live meeting page a bit and it's just like all these other pages, a work in progress, but hopefully this will be a structure where we'll be able to hear everyone's perspective and leave the coda in a better place than we found it. So what we'll do in the live meetings, which from here on out, or at least for here for the next two and a half months or so, are going to be driven by the material in the chapters and in the appendices. We're going to go to the questions page and we're going to look at the questions that have been asked for that week for that theme, and we're just going to start with the most upvoted questions.
01:06 And then we're going to be taking notes in the answers, in the discourse, and we'll go into a little bit more detail when we flip to that page. And then after addressing questions for probably most of the time and discussing that, we'll go pull back a little bit more broadly like ideas for that week. And then in the last minutes we can just see if there's been any changes to the project ideas and start to see what people are excited about applying active inference to. And then we'll end at the top of the hour and take a quick break. And then there'll be a Tools organizational unit meeting following for those who want to just listen or participate in tools. So let's head over to Questions and I'm going to hide the sidebar because we're going to be mostly here in Questions. Okay, so it's awesome. And also Control and plus minus or Control and scroll is like a good way to resize how it looks.
02:10 So this is our first week with this format and anyone's welcome to suggest a variant or a different way to carry this out. But the co organizers of the textbook group kind of thought we could do something along these lines. The questions we're going to be looking at are in chapter one. So that's the chapter we're discussing today and we're going to start with the ones that have the most upvotes in the interesting and just spend a couple of minutes on each of the questions. And at any point there are the affordances of just listening and also, of course re watching this recording. There's also the affordance in gather to raise your hand if you'd like to share on that question that we're going to have up. And additionally by clicking on the answers in discourse, that will pull up a focused view on that question and everybody can collaboratively edit the answers and discourse.
03:20 And so it's better to add and be noisy even if it's a bullet point list or an incomplete sentence or there's incoherence or it's contradictory. Those are all fine. It just adds information and perspectives to the question. So, yeah, we're going to go to each question, open up the answers and discourse, read the question, see what has already been contributed in the answers and discourse. And then also if people want to share other thoughts that they're having, that's awesome. And then also if anybody wants to be taking other notes, just things that are coming to mind that they don't want to share in a speaking way or just taking some notes on what other people are saying. So let's just go into it. And I'll be just keeping an eye for the raised hand in gather for anybody who wants to speak. So starting with this first question, maybe we can have addressed during recording or something like that.
04:29 How do you understand the distinction between the high road and the low road to active inference? What do you think is interesting or useful about this distinction? So does anybody want to just summarize how they were thinking about the high and the low road? Or we can look at what others have already written here. What is the difference between the high road and the low road? Are there other roads? Are there high and low roads to other theories? What is this metaphor with the roads?
05:30 So let's check out yes. Ali and then Mallory.

05:38 Ali:
Well, I believe it's just another term for top down or bottom up approach in a kind of way. And well, the high road, I believe, starts from the actualized mind itself and tries to derive the underlying mechanisms or underlying principles. But the bottom up approach, or in other words, low road, tries to start from the elements, tries to start from the unorganized elements, let's say, and derive the higher mechanisms or higher order mechanisms actualizing the mind itself.

06:32 Daniel:
Thank you. Awesome. Mallory.

06:38 Mallory:
Yeah. I was just going to maybe recapitulate, I guess, what I wrote in the comments, and I see now that I probably should have written straight in the Answers in Discourse section. So sorry about that. But I really appreciated this schematic because I've read papers that I think come at active inference from both of these angles. And in trying to understand. I don't. Know, the framework, I think it wasn't super clear to me how all of these different terms that are really nicely outlined in this figure, Figure 1.2, are related to one another. So just to have it, I think, laid out like this, it was really very helpful and I think still being kind of new to the concepts and such.
07:39 I liked the way they framed it in terms of kind of the high road describing the kind of what and why and the low road being more about the how. I thought that was really very useful. So, yeah, I loved it and I saved it and will probably reference it quite often.

08:08 Daniel:
Yeah, agreed. It's really useful. And it touches on Aristotle's multiple whys, where some of the whys are more like hows or they're sort of proximate mechanisms or more ultimate mechanisms. And we can look at Figure 1.2. So active inference is in the middle and the high road. I guess this is the starting train stop here with a free energy principle, which some later questions also might invoke. And then it kind of goes down to active inference, whereas starting with Bayes theorem also gets us to sentient behavior, sentient being like sensing and feeling and acting not as much on the qualia and experiential side. So what else do we have in the answers? So high road, what and why that is starting with sort of the organismal imperative, or like Ali, I think, said, there the actualized mind.
09:18 And then what are the underlying principles that make adaptive behavioral systems working down the castle in the sky is the adaptive behavior and intelligent cognitive behavior, what is under it? And then the low road doesn't begin with that imperative. It starts with the elements, like the low road, starting with Bayes. None of these necessarily have to be, or at least maybe until you get to Bayesian brain. These don't have to be adaptive. A generative model doesn't have to be resisting entropy. So it's sort of like here's where we see a lot of the elements in the machinery and then on the top is more of the self organization resistance to dissipation autopoiesis. How are you going to get there? You have to be minimizing your surprise. What does that actually entail? And then active inference is like this intermediate stop.
10:18 And again, maybe there's other roads or there's other paths. Any other thoughts on high road and low road? Or we'll continue to the next question. This is just being introduced in chapter one because the following chapters two and three, which we're going to get to after the appendix A and B are going to detail the low road and the high road. So this is kind of like a map for some of the next steps that we're going to be engaging in. Okay, next question. The concept of organisms minimizing surprise is introduced on page six. How are prior assumptions or beliefs established when the organism is in new or novel environments? So anyone can raise their hand or take a note here Mallory or Ali with raised hands.
11:52 One helpful approach might be to think about like the question is asking about new and novel environments. So are we dealing with categorical novelty or with quantitative novelty? Like, I was measuring the temperature and then I'm in a new environment where the temperature is different. That's one type of novelty. But there might also be like this novelty at an even higher level with like I was looking at previously, I was looking at temperature, and now I'm in a place where I'm having priors about smell. So that's like a sort of intermodal or like a different type of thing that's being tracked. So that's a categorical novelty as opposed to just updating the temperature parameter in a different temperature room, whether the person who asked it is here or not.
12:53 Oh, yes. Okay. Ali and Mike, go for it.

13:01 Ali:
Yeah. Well, again, if we're talking about the human mind from the priors, we can infer that well, it's something that's kind of innate in human minds, something wired, and I mean, perhaps genetically or in any other biologically hardwired way, but well, again, yes, the definition of a novel situation varies according to what we're exactly referring to. And if a novel situation is something that the organism hasn't ever presented with, well, in that case, these priors or these innate tendencies won't help it very much.
14:08 So in that case, it should probably go along the way of constructing posteriors, more actively, I believe, than in any regular situation.

14:26 Daniel:
Thank you, Ali. Jessica; and then Mike; and then Steve.

14:33 Jessica:
Hi. I think maybe like, in this situation, even though the agent might be encountering something that hasn't experienced before, they might use something as proxy that they already know and sort of like, project those understanding into the new situation. And then it's through action, et cetera. Then they're going to be updating like, okay, how true is it or isn't to what they understand; but they might be making some kind of projection based on what they already know and things that look similar to that new experience.

15:11 Daniel:
Awesome. Thank you. Mike and Steven.

15:14 Mike:
Yeah, I was just going to comment. In the case where the organism is brand new and has no experience, I think Ali's comments covered this a bit, that it will have to be updating its priors fairly rapidly and presumably starting with sort of a wider distribution.

15:40 Daniel:
Great. Steven?

15:50 Steven:
Yes. Along the lines of what Jessica was saying. There has been some work in systematizing that as case based reasoning. Not necessarily in a Bayesian framework here, but as a derivative of expert systems, where when you get a new scenario, you try to match that against previous scenarios that you've already seen and adapt it however necessary to meet the new observations. So that might be a place to look for inspiration.

16:38 Daniel:
Thanks. Yeah. And in the ontology work, and in a lot of these questions, there's often like a narrow answer and then a broader answer. Like the narrow answer would be well, again, if all your Bayesian model is doing is looking at the thermometer reading and then doing a calm and filter and inferring the temperature in the room, well, then the answer of what happens when you put it underwater or what happens when you ask it to predict scent. It's kind of like a trivial answer, which is it's just not a parameter. In that script, nothing happens. And then that's like the narrower answer, which is often very deflationary or like, very trivial answers. And then there's also a broader question, like in the ecological context or in the organismal context, in the expert applied context, what happens when there are these different qualitative and quantitative types of novelty?
17:39 And so sometimes it's like, there we are in the middle again with the deflationary or the narrow being too obvious and too simple to be brought into action. And then the bigger question, like how do experts in medicine or some other field, how do they handle different types of novelty? That's its own research question and agenda. Awesome. Any other thoughts on this question about priors? And it's also very important note that surprise is always relative to expectations which are priors in the Bayesian context, and those are granted by the Generative model. So surprise is not just free floating, it's in relationship to the outcomes as expected by an organism, for example, jessica, your hands raised, otherwise we'll go to the next question.
18:43 Awesome. This question, I think, is pretty similar to the previous one. So if anybody wants to give a thought otherwise, no worries. Are the high road and low road the only roads to active inference? Or my active be like Rome, which I guess we can unpack a little bit, many all roads leading to it's. J-F.

19:15 J-F:
Yes, it's more of a general question. For example, if what you're trying to understand is race cars, right? And you develop a mathematical framework given a number of measurements, like the weight of the car, the length of the car, the torque of the engine, the adhesion of the tires, the friction, and whatnot, you're able to predict how well the race car is going to perform in different conditions. And whatnot does that mean that you're an expert in race cars? Does that explain the race car? Could you engineer a race car based on this knowledge? So, talking about multiple different roads, one road through the free energy principle, I think is an analytical road that looks at the outcomes of the machinery of the living beings that try to maintain homeostasis.
20:15 But how much does it say about the implementation of those organisms? Um, it says many things, but does it say everything that we deem might deem interesting? So what are the limitations of this framework, the active inference framework defined by.

20:42 Daniel:
The free energy principle?

20:43 J-F:
What are its limitations on top of what it given its capabilities, which are which are, I think, enormous. But there are limitations. And and if there are limitations, that means there are there must be other roads that can be taken to circumvent these limitations.

21:06 Daniel:
Thank you. Great comment, Ali.

21:13 Ali:
Well, duluzan Gatavi in 1000 Plateaus has laid out the concept of Rhizome. I don't know if you're familiar with the concept of Rhizome as opposed to an arborescent structure. Well, basically, the concept of Rhizome expounds a knowledge structure in which every concept can potentially be connected to every other concept without having to go through a principal trunk of a knowledge tree, let's say, but in an arborescent structure and not arborescent knowledge structure, everything branches up from a principal trunk, from a principal, let's say, base. And I believe that in active inference, a Rhizomatic approach can also be explored not only by approaching to different concepts via the high road or the low road main or principal trunk.
22:39 It can potentially be approached from seemingly unrelated concepts too.

22:50 Daniel:
Awesome to maybe even approach a limitation or a seemingly unrelated concept. Both the high and the low road in this textbook are formal, and they're both grounded in, like, mathematical symbols. So are there qualitative or non mathematical roads? Maybe some of the early roads are mathematical, but is it possible that a future road or path or tunnel or choose your travel metaphor might not be that case? And then thanks for sharing. That the resource there, because this is another interesting angle which various people have traced this evolution of visual metaphor where it's like, things are ladder like and scalar, and then there's more of a bifurcating tree, and then that becomes critiqued or complexified into more of a network, like with integration among species, for example.
23:59 So there's sort of this movement from linear through a tree, like a directed acyclic graph towards something that's more networked. So that's a lot of interesting ideas. Anything else that people want to add or we'll continue on. Okay, on page ten, they write, creatures engaging in active inference actively seek out salient sensory observations that resolve their uncertainty. So what is the relationship between salience and the kind of observation that reduces uncertainty? Why is the relationship between salience observation and uncertainty this way? How does active inference frame this relationship similarly or different from which other specific frameworks? So someone wrote, I like this question a lot, eager to get a better understanding of what constitutes salience. Is salience referencing information that is self evidence or information that is precise and surprising or dot dot, dot?
25:05 Yes. I think attention and salience is addressed more in papers on active inference than at least just from a preliminary pass of the book. So attention and metacognitive mechanisms are not going to be a core feature in the book. However, there's again been a lot of interesting work on the neurobiology and the computational aspects of salience and attention. We can click on the word and see a definition, but this is not like the final definition. This is just what some have gotten to. Salience is the extent to which a queue or an observation commands the attention of an agent, given their regime of attention. So potentially a little bit tautological, like a salient observation is something that is grabbing attention.
26:05 A salient cue is something that commands attention. Steven.

26:15 Steven:
Yes, I would say that, especially if we're defining it in that way, that there are two elements to salience, and one is what was pointed out in the question, I guess, that you are reducing uncertainty. But there is also the question of what uncertainty is worth reducing, and that gets into utility and where it makes sense to explore. I don't know if we want to choose to change the definition of salience to just be the second of those or leave it as having both of those elements.

27:03 Daniel:
Thanks! Mallory?

27:07 Mallory:
I think something I don't necessarily understand, which I would appreciate maybe somebody speaking to a little bit, is this is related actually to a question I put in earlier about the distinction between perception and learning, but something that grabs attention. Are we distinguishing? So that would say that something is I like the point that was just made. Something is salient if it reduces uncertainty, if we're also attending to things in order to actively construct a niche that is consistent with our model of the world, would we not consider that something like that object as attracting attention as opposed to our how do we distinguish, I guess, between active sampling and attending?
28:07 And how is that related to salient? So something salient either if it is surprising or if it is serving the purpose of kind of like fulfilling a prediction. I'm not sure I understand that kind of distinction.

28:31 Daniel:
I'm not sure that makes sense, but awesome question. And this is one reason why looking at the formalisms and how they're framed will help us, because in the purely English linguistic realm, we could imagine sentences of any type. So in the active inference formalisms, what are being tagged with salience? Which variables are said to reflect salience? And then are they or in what ways are they related to this concept of surprise, which we're going to get to in a question soon, versus utility? And this is also speaking to the way that expectations and preferences in active inference are framed differently than in certain other frameworks.

29:28 Joe:
Can I jump in and just ask another question about this question rather than an answer, which is, wouldn't some data be salient even if it's sensible? Like we might have two levels of salience. So I just put this quote in about the notion of a, umvelt being a more or less broad series of elements called carriers of significance or marks, which are the only things that interest the animal. Now, interest the animal is one thing, but even just perceiving those marks as existing, I mean, active inference does have room for that in terms of each agent having some sensory data. So you could say, well, since I can't see infrared light, it's not salient to me when I'm out in a field of flowers, but a bee can see that, I think. It can see infrared or ultraviolet. I can't remember which one. So it may be a salient concept for me as a thinking agent, but it's not one that's salient for me when I'm navigating a field of flowers.

30:27 Daniel:
Basically. Nice thanks for bringing in, umvelt, and a lot of ecological psychology terms do make their way to active. And so then you brought up like levels of perception and salience. For example, there's things that are outside of the wavelength that can be perceived. So photons are not going to be perceived at that wavelength, but then there might be within the visible range novel arrangements like there's something moving there or there might be something that is static yet commands attention, like the Mona Lisa. So what is happening when somebody's regime of attention is fixated on static artifact versus something where they're being fixated on something that's rapidly changing, like a movie mallory in the chat you wrote, can folks recommend papers?
31:30 So definitely people can recommend papers anywhere they see fit. And one place to check out is in the bottom of our coda. In the live streams, under the live stream tab, you'll find like 45 papers that we've relatively extensively discussed. And so these are not like the only or the canonical papers or anything, but there's a lot of important ones in there. So especially if you're interested in looking at papers where people in the lab might have familiarity or there's some things to listen to or watch about it, then these are some good places to start. All right, awesome. Next question. All right, this is a contextualization question. This is not a metadata contextualizing sentence. On page nine and ten they talk about differences from alternative frameworks.
32:31 For example, in contrast with other frameworks, policy selection in active inference automatically balances exploration and exploitation. And later, active inference extends the inferential approach to domains of cognition that are rarely considered. What are five to seven examples, names in a sentence of other theories and frameworks that active inference improves upon or updates. Anyone can raise their hand. This is an excellent homework collaborative stigma gqueston because even if each person only thought of one novel answer here with a link and a name or somebody improved what somebody else had already brought very quickly as a textbook group, we could have quite a coherent and comprehensive list. The idea of balancing exploration and exploitation, so called, is going to be a key theme.
33:37 And the way that active inference does handle this trade off, not through the use of an exploratory mode or exploitative mode or some parameter that is like governing the handoff. There like some sort of x times exploration plus one minus x of exploitation. That is like one approach that's commonly used, but it would be a question of which citations use that type of an approach and it's going to come to the epistemic and pragmatic value. Whereas when there's little epistemic value to be gleaned, little informational uncertainty to resolve, then pragmatic value can be pursued, which is reducing the surprise about outcomes in relationship to preferences. And then on the other hand, when there's a lot of uncertainty, exploratory behavior might be engaged in because there isn't enough certainty around how to pursue those pragmatic aims.
34:49 And these are going to come into play with the Tmaz mouse model that's going to be later in the book. But this is a great question. So anyone want to just give an example of some other theory or framework or some other approach to thinking about exploration exploitation? One starting reading, if anyone is interested, there is a 2015 paper that is looking at exploration and exploitation trade offs in different domains. Ali.

35:35 Ali:
Well, I don't know if it necessarily improves upon, but certainly an alternative approach to this theory can be Steven Grossberg's art theory, the adaptive resonance theory that we talked about previous session. In that theory, the problem of learning and cognition is attacked from the viewpoint of solving the stability plasticity dilemma. And in this context, in the context of art or adaptive resonance theory, well or let's say the difference between the active imprint one of the main differences between the active imperence or any predictive coding schemes from adaptive resonance theory is that in Bayesian models generally, the fully suppressive matching circuits I mean, the the circuits that can propagate the information.
36:54 It cannot solve the stability plasticity dilemma as opposed to the art or adaptive Bresnan's theory.

37:07 Daniel:
So plasticity being more exploratory and openness to updates and stability being more like parametric lock in more exploitative within a certain realm.

37:21 Ali:
Yeah, the plasticity refers to a system that doesn't have catastrophic forgetfulness.

37:37 Daniel:
Awesome cool. So we can just have this question up and check back and people can add things. We'll just look at a few more questions. So on page eight they write the high road perspective is useful to understand the normative nature of active inference, what the living organisms must do to face their fundamental existential challenges. Minimize free energy. And why? The what and the why in the high road why to vicariously minimize the surprise of their sensory observations? What does it mean to minimize surprise vicariously? So someone has written interesting choice of words. Here are two possible answers. Also, the authors or the readers participants may have something else in mind. Vicarious might refer to the point on page six that agents cannot tractably minimize surprise as the authors technically defined it in chapter two coming up.
38:44 So instead they're going to minimize an approximation to surprise, which is variational free energy. However, I'm not sure if they're referring to the two types of surprise that are going to be approached in chapter two, which is the marginal surprise like informational surprise and then the Bayesian surprise or both. So one option is surprise as defined one way or the other, or both cannot be directly calculated or it's not tractable to pursue. And so the vicarious could mean like indirect or via a proxy. And in that case something like variational free energy is being vicariously minimized and then that is going to be used to get at the surprise minimization and the second option the person has written vicarious might refer to the point that agents minimize free energy not only in response to real sensory observations, but in anticipation of them.
39:44 Those anticipations could come from internal simulations, by subroutines or other modules, or memory from recall of past observed events. Page 32, which is probably in chapter two. The author seemed to be referring to engaging models vicariously in a counterfactual sense, dealing with imagined surprise at presumed observations. So these are really important comments. We have the indirect minimization of surprise using a proxy. So some type of heuristic to minimizing surprise now. And so that is vicarious but contemporary. And then the second sense is whether we're using a proxy or not is referring to observations that haven't occurred so anticipated or expected observations.
40:57 Hopefully we'll come back to in chapter two. But these are important questions and it's going to speak to like variational free energy and expected free energy and free energy of the expected future, a few other constructs. Steven and yeah, I put that last comment in.

41:18 Steven:
I was just thinking that should probably go under number two there. I guess that would be evidence of that second interpretation.

41:28 Daniel:
Thank you. So we'll maybe return to this in chapter two. Okay, let's just see if we can look up just a few of these questions. It's awesome, like how many there are and of course anyone can always read and contribute asynchronously. All right, the subtitle of the book is the free energy principle in Mind, Brain and Behavior. What is the relevant distinction between mind and brain in the context of the free energy principle? Someone has written really appreciate how the researchers have started proposing biological implementations of Active in the brain. But it's not clear to me how this maps onto related psychological concepts like colloquial, surprise predictions, salience, arousal.
42:28 Yeah, awesome. And there's been some recent work and some work that we're going to be looking at in Live Stream 46 on active inference and folk psychology about connecting some of the formalisms to folk psychological concepts. So that's one place we'll be looking at that. But how does or does active approach this mind brain question? Whether the Cartesian dualist question, hard problem of consciousness, intentional stance of dennett. Why is the subtitle of the book that way, Jessica?
43:29 And then anyone else with the raised hand?

43:31 Jessica:
Yes. I mean, I don't know the answer, but if I make a guess, I think maybe the mind will be more the cognition and the brain looking at the physiology and then looking at behaviors. That would be my guess.

43:53 Daniel:
Yeah. Awesome. Bacterium does not have a brain, but does it have a mind also? Great questions. We'll just continue just these questions with fewer upvotes because there's a bunch just so we can get them in. So generative model is used in the singular or is used in the singular as in the generative model or in the. Plural, as in hierarchical generative models. Is a generative model composed of generative models? I e. Is it structurally fractal? Someone has written personally, I think the answer is yes. Or it's possible to answer yes via referencing a paper that talks about blankets of blankets, Markov Blankets life. This paper definitely does think about the nesting of multi scale complex systems in terms of nested generative models that then are constituting yes, that are then constituting generative models at a higher level.
45:06 So, like, there's people with their generative model and then the team has a generative model of a different type.

45:12 J-F:
JF yes, but even an individual myself yourself, can be characterized as having a generative model composed of other general models dealing with less abstract umvelt, for example. So I think yes, I think almost trivially in the sense of a collective, but in the sense of an individual, does an individual also can be said to possess a generative model that is itself composed of sub generative models?

45:54 Daniel:
Awesome point. And we've in several live streams and settings discussed. Like, there's one sense where nesting is used to refer to systems that are potentially even physically nested. And then we also see the nesting architecture. For example, here it's live stream number 25 when we discussed it. But this is a nesting of attentional and cognitive models. So this is even of a so called individual. So what is it about model nesting when sometimes it can refer to physical enclosure and other times it is something that enables counterfactual reasoning, attention and metacognition. So what is the nesting? And if someone is just seeing this kind of a notation or this kind of a graph for the first time, we're going to totally go into it. But it's going to be one of the core formalisms.
46:57 And also this paper is going to deal with nested models and other papers do. The textbook is going to spend almost all the time on just one level. So just sort of the kernel or the essence or the archetype or the essential motif of this partially observable Markov decision process. And the textbook is going to focus on juxtaposing the discrete time partially observable Markov decision process with a continuous time. But it will deal less with hierarchical nesting. But it does bring it up, but it's not going to be focused on, okay, what is the information content of a prediction? I'm just going to read these ones just so that those who are listening can see the kinds of questions that they could be adding or addressing. This question has to do with the relationship between active inference and pleasant surprises, potentially even love languages receiving money on the pavement. Page five is speaking to the author's rhetoric around theory proliferation and integration where basically they are saying well, we could have a dedicated explanation for every neurotransmitter, for every synaptic junction, every unique behavior, every cognitive phenomena or we could somehow utilize first principles, whatever those are, to result in theory integration.
48:24 And that gets mapped onto the scruffies and the needs. Is it really helpful to redefine terms such as probability and surprise to sometimes mean utility and divergence from utility if that's what the authors are doing? There appears to be an unhealthy ambiguity in how they use these terms. This is where the formalisms are going to really come into play. And also the live stream on Free Energy A User's Guide 37 deals with this dual interpretation of expectations and preferences. And this is like one of the most essential differences between active inference and reward learning or reinforcement learning frameworks is a dual deployment of the same variable in formalisms to represent preferred states as well as expected states like homeostatic range is expected and preferred.
49:28 It's where one wants to be found and it's where one expects to be found. And so one can realize those preferences by reducing their surprise about the observations rather than saying, well, homeostatic states are valuable and we're going to pursue maximum value. How might an acceptable state space relate to the idea of a comfort zone? It seems the acceptable state space for an organism is necessary for it to persist, whereas a comfort zone seems to be a less necessary state repertoire which if exceeded, may only indicate to an organism that it's at risk of leaving the acceptable state space. Interesting. And then the last written question here, looking ahead into part two. Have people been looking into the computational complexity of the active inference model and how far are we in terms of making this computable and the reference 2019 paper computational Resource Demands of the Predictive Bayesian Brain?
50:33 Excellent and important question to understand, like the analytical computational complexity, like the Big O notation, does nesting a model make it two or is it log the number of levels or is it number of levels to the sum exponent? And then also in practice, like using active block for instance, or Pi MDP, what is the actual runtime of different algorithms? So this is awesome with the questions that everyone's added to one. We're going to keep on returning to chapter one, just like we're going to keep on returning to the ideas, but people can fold it and continue to add to two and to the appendices which we're going to go to next week. So just as a reminder, next week we're going to be approaching appendix A and B, which are mathematical. And so just a few thoughts on that before we return back to the ideas on the book. In appendix A, you can see that all the equations have already been added.
51:36 So if anyone wants to reference, what does equation A point 44 mean? And obviously like there's 60 equations and you could get your PH. D. Learning about some sub function of just one. So we're just trying to familiarize and get a first coat of paint. So for those with different mathematical backgrounds. If somebody can derive the proof, amazing. Let's take some notes on it. And if somebody is just going to be asking beginner questions that's also very important. So that will be in next week's questions and discussions. But let's just look at what ideas people wrote and then see if there's any ideas percolating. So having addressed some specific uncertainties I get with the questions we can think about what are some impressions that people were having and what was exciting ideas. So if Ben or Mike want to speak to this or if anybody else wants to share something JF and then anyone else JF and then Ben or is your hand raised?

52:48 J-F:
No, my hand was not raised.

52:50 Daniel:
Okay. Sorry, Ben. Go for it.

52:53 Ben:
Yeah, thanks. Can you hear me?

52:55 Daniel:
Yes.

52:56 Ben:
Cool.

52:57 Daniel:
Yeah.

52:57 Ben:
Maybe I should have posed this as a question. Actually I just thought it was interesting, this connection between perception and learning as essentially the same process unfolding over different timescales. Because on the one hand, this makes sense to me because one example of learning might be you can imagine an agent moving to a new city with which they're completely unfamiliar and the agent could sit at a fixed point in the city or walk around the city and just perceive the city and they would learn over a longer time scale. They would observe certain regularities or certain occurrences and clearly that's one form of learning. But then there's maybe another example where my mathematical background is fairly weak. And so if I were to try and learn the kind of fundamentals of the equations that we were just looking at no matter how for how long I kind of perceive those equations I'm not going to learn them. I have no access to kind, there's no information gained there.
53:58 It seems like to learn certain things we need to scaffold perception in certain ways. And I suppose my question would be when somebody teaches us something that we don't understand, is that merely a kind of scaffolded perception or is that kind of learning underwritten by distinct cognitive processing completely separate from perception?

54:22 Daniel:
Great question, thanks for unpacking that. And to give one thought, let's imagine a ball moving across the visual fields. It seems like a canonical example of perception. We're perceiving the ball but it could also be understood as parameter updating or parameter learning of the location of the ball. And then that's one approach. But then also you pointed towards this deeper sense of learning referring to the underlying structures like in the ball movement examples. It seems like learning and perception are the same but then learning might also refer to something deeper like the tendencies of how balls move. Or one could, as probably many of us have, look at these symbols and perceive them visually. But because we wouldn't have learnt the underlying generative model that gives rise to these pixels, we could continually be surprised.
55:23 So what is happening when there's perception and learning seemingly happening hand in hand. And then other times where somebody's speaking a language you don't understand, you certainly hear it. You may even be paying attention to it, yet the next phoneme may still continually surprise you. So it's a really important question. Then Mike wrote yes, please. Go for it, Mike.

55:52 Mike:
Yeah, so I think these are straightforward but foundational concepts that the dependence of sensory input on action and vice versa creates a framework where we can have feedback and then the mathematical constructs let us think about how we model that and simulate it.

56:12 Daniel:
Thanks for this. Also, a central point in active inference, there isn't a perception and inference module that passes the perceptions to the learning module, and the learning module passes it to the decision making module and the decision making module to the action model. The inference is conditioned upon policy selection and action, and that is going to approach this nexus of perception, cognition and action in an integrated way that not that may differ from other frameworks, which was also to the point of that previous question. So this was an awesome session. Everyone really appreciated it. I'll upload the video recording following the meeting next week. At the same time, we'll be looking at questions and ideas from appendix A and B. So just approach those however you'd like and annotate the coda. And also, if anybody wants to specify another time when they just want to discuss or cowork that can be added, or in the active lab discord, people can join and we can have a voice like a study hour or just a time to talk about stuff or write down the questions we have.
57:30 So awesome work, everybody. Thanks a lot.
