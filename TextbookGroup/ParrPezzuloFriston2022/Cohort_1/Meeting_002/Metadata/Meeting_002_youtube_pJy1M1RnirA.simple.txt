SPEAKER_01:
Hello everyone.

Thanks for joining the second meeting where we're going to be discussing chapter one.

It's the Act-Inf textbook group and it's May 12th, 2022.

You can click on my screen and that will show you the full screen.

We updated the live meeting page a bit and it's just like all these other pages, a work in progress, but hopefully this will be a structure where

be able to hear everyone's perspective and leave the coda in a better place than we found it so what we'll do in the live meetings which from here on out or at least for here for the next two and a half months or so are going to be like driven by the material in the chapters and in the appendices

we're going to go to the questions page and we're going to look at the questions that have been asked for that week for that theme and we're just going to start with the most upvoted questions and then we're going to be taking notes in the answers in the discourse and we'll go into a little bit more detail when we flip to that page and then after addressing questions for probably most of the time and discussing that

We'll go pull back a little bit more broadly, like ideas for that week.

And then in the last minutes, we can just see if there's been any changes to the project ideas and start to see what people are excited about applying active inference to.

And then we'll end at the top of the hour and take a quick break.

And then there'll be a tools organizational unit meeting following for those who want to just like listen or participate in .tools.

So let's head over to questions and I'm going to hide the sidebar because we're going to be mostly here in questions.

Okay.

So it's awesome.

And also control and plus minus or control and scroll is like a good way to resize how it looks.

So this is our first week with this format.

And anyone's welcome to suggest a variant or a different way to carry this out.

But the co-organizers of the textbook group kind of thought we could do something along these lines.

The questions we're going to be looking at are in chapter one.

So that's the chapter we're discussing today.

And we're going to start with the ones that have the most upvotes in the interesting and just

spend a couple minutes on each of the questions and at any point there are the affordances of just listening and also of course re-watching this recording there's also the affordance in gather to raise your hand if you'd like to share on that question that we're going to have up and additionally in the um by clicking on the answers in discourse

that will pull up like a focused view on that question and everybody can collaboratively edit the answers and discourse and so it's better to like add and be noisy even if it's a bullet point list or an incomplete sentence or there's incoherence or it's contradictory those are all fine it just like adds information and perspectives to the question so yeah we're gonna go to each question open up the answers and discourse

read the question see what has already been contributed in the answers and discourse and then also like if people want to share other thoughts that they're having that's awesome and then also if anybody wants to be like taking other notes just things that are coming to mind that they don't want to share in a speaking way or just taking some notes on what other people are saying um so let's just

go into it and i'll be just keeping an eye for the raised hand in gather for anybody who wants to speak so um starting with this first question uh maybe we can have like a like addressed during recording or something like that but so how do you understand the distinction between the high road and the low road to active inference

What do you think is interesting or useful about this distinction?

So does anybody want to just summarize how they were thinking about the high and the low road?

Or we can look at what others have already written here.

what is the difference between the high road and the low road are there other roads are there high and low roads to other theories what is this metaphor with the roads

So let's check out, yes, Ali and then Mallory.


SPEAKER_07:
Well, I believe it's just another term for top-down or bottom-up approach in a kind of way.

And well, the high road, I believe, starts from...

the actualized mind itself and tries to derive the underlying mechanisms or underlying principles but the barma approach or the in other words low road tries to start from the elements tries to start from the unorganized elements let's say and

uh, derive the higher mechanisms or higher order mechanisms, uh, actualizing the mind itself.

Thank you.


SPEAKER_01:
Awesome.

Valerie?


SPEAKER_02:
Um, yeah, I was just gonna maybe recapitulate, I guess what I wrote in the comments and I see now that I probably should have written straight in the answers and discourse section.

So sorry about that.

Um,

But I really appreciated this schematic because I've read papers that I think come at active inference from both of these angles and in trying to understand, I don't know, the framework, I think it wasn't super clear to me how all of these different terms that are like really nicely outlined in this figure

figure 1.2 are related to one another.

So just to have it, I think, laid out like this, it was really very, very helpful.

And I think still being kind of new to the concepts and such, I liked the way they framed it in terms of kind of the high road describing

the kind of what and why and the low road being more about the how.

I thought that was really very useful.

So yeah, I really, I loved it and I saved it and we'll probably reference it quite often.


SPEAKER_01:
yeah agreed it's it's really uh useful and it it touches on aristotle's multiple y's where some of the y's are are more like hows um or they're sort of proximate mechanisms or more ultimate mechanisms um and and we can like look at figure 1.2 so active inference is in the middle

and the high road i guess this is the starting train stop here with a free energy principle which some later questions also might invoke and then it kind of goes down to active inference whereas starting with bayes theorem also gets us to sentience behavior sentient being like sensing and feeling and acting not as much on the um qualia and experiential side

um so what else do we have in the answers so high road what and why that is starting with sort of the organismal imperative or or like um ali i think said there that the actualized mind and then what are the underlying principles that make adaptive behavior adaptive behavioral systems

working down you know the castle in the sky is the adaptive behavior and intelligent cognitive behavior what is under it and then the low road doesn't begin with that imperative it starts with like the elements like the low road starting with bees

none of these necessarily have to be or at least maybe until you get to like bayesian brain these don't have to be adaptive a generative model doesn't have to be resisting entropy so it's sort of like here's where we see a lot of the elements in the machinery and then on the top is more of the self-organization resistance to dissipation autopoiesis how are you going to get there you have to be minimizing your surprise

what does that actually entail and then active inference is like this intermediate stop and again maybe there's other roads or there's other paths um yeah so any other thoughts on high road and low road or we'll continue to the next question

This is just being introduced in chapter one because the following chapters two and three, which we're gonna get to after the appendix A and B are going to detail the low road and the high road.

So this is kind of like a map for some of the next steps that we're gonna be engaging in.


UNKNOWN:
Okay.


SPEAKER_01:
Next question.

The concept

of organisms minimizing surprise is introduced on page six.

How are prior assumptions or beliefs established when the organism is in new or novel environments?

So anyone can raise their hand or take a note here.

Mallory or Ali with raised hands?

One helpful approach might be to think about like the questions asking about new and novel environments.

So are we dealing with categorical novelty or with like quantitative novelty?

Like I was measuring the temperature and then I'm in a new environment where the temperature is different.

that's one type of novelty, but there might also be like this like novelty at an even higher level with like, I was looking at, previously I was looking at temperature and now I'm in a place where I'm having priors about smell.

So that's like a sort of intermodal or like a different type of thing that's being tracked.

So that's a categorical novelty.

as opposed to just updating the temperature parameter in a different temperature room.

Whether the person who asked it is here or not... Oh yes, Ali and Mike, go for it.


SPEAKER_07:
Yeah, well, again, if we're talking about the human mind, I mean, from the priors, we can infer that, well, it's something that's kind of innate in human minds, something wired in.

I mean, perhaps genetically or in any other biologically hardwired way.

But, well, again, yes, the definition of novel situation varies according to what we're exactly referring to.

And if a novel situation is something that the organism hasn't

ever presented with, well, in that case, these priors or these innate tendencies won't help it very much.

So in that case, it should probably go along the way of constructing posteriors more actively, I believe, than in any regular situation.


SPEAKER_01:
Thank you, Ali.

Jessica, and then Mike, and then Steve.


SPEAKER_08:
Hi.

I think maybe in this situation, even though

The agent might be encountering something that has an experience before.

They might use something as proxy that they already know and sort of like project those understanding into that new situation.

And then it's through action, et cetera, then they're going to be updating like, okay, how true is it or isn't to what they understand.

But they might be making some kind of projection based on what they already know and things that look similar to that new experience.


SPEAKER_01:
Awesome, thank you.

Mike and Steven.


SPEAKER_00:
Yeah, I was just going to comment.

In the case where the organism is brand new and has no experience, I think Ali's comments covered this a bit, that it will have to be updating its priors fairly rapidly and presumably starting with sort of a wider distribution.


SPEAKER_01:
Great.

Steven?


SPEAKER_06:
Yes.

Along the lines of what Jessica was saying, there has been some work in systematizing that as case-based reasoning, not necessarily in a

Bayesian framework here, but as a derivative of expert systems where when you get a new scenario, you try to match that against previous scenarios that you've already seen and adapt it however necessary to meet the new observations.

So that might be a place to look for inspiration.


SPEAKER_01:
thanks yeah and in in the ontology work and in a lot of these questions there's often like a narrow answer and then a broader answer like the narrow answer would be well again if all your bayesian model is doing is looking at the thermometer reading and then doing a kalman filter and inferring the temperature in the room

Well, then the answer of what happens when you put it underwater or what happens when you ask it to predict scent, it's kind of like a trivial answer, which is it's just not a parameter in that script.

Nothing happens.

And then that's like the narrower answer, which is often very deflationary or like very trivial answers.

And then there's also a broader question, like in the ecological context or in the organismal context, in the expert applied context.

what happens when there are these different qualitative and quantitative types of novelty and so sometimes it's like um there we are in the middle again with the deflationary or the narrow being too obvious and too simple to be brought into action and then the bigger question like how do experts in medicine or

some other field, how do they handle different types of novelty?

That's its own research question and agenda.

Awesome.

Any other thoughts on this question about priors?

And it's also a very important note that surprise is always relative to expectations.

which are priors in the bayesian context and those are granted by the generative model so surprise is not just free floating it's in relationship to the outcomes as expected by an organism for example jessica your hands raised otherwise we'll go to the next question awesome okay this question i think is pretty similar to the previous

So if anybody wants to give a thought, otherwise, no worries.

Are the high road and low road the only roads to active inference, or might Act-Inf be like Rome?

Which I guess we can unpack a little bit.

Many slash all roads leading to it.

J.F.?


SPEAKER_05:
Yes, it's more of a general question.

For example, if what you're trying to understand is race cars, and you develop a mathematical framework, given a number of measurements like the weight of the car, the length of the car, the torque of the engine, the adhesion of the tires, the friction and whatnot, you're able to predict how well the race car is going to perform in different conditions and whatnot.

Does that mean that you're an expert in race cars?

Does that explain the race car?

Could you engineer a race car

based on this knowledge.

So talking about multiple different roads, one road through the free energy principle, I think, is an analytical road that looks at the outcomes of the machinery of the living beings that try to maintain homeostasis.

But how much does it say about the implementation

of those organisms?

It says many things, but does it say everything that we might deem interesting?

So what are the limitations of this framework, the active inference framework defined by the free energy principle?

What are its limitations on top of what

given its capabilities, which are, I think, enormous.

But there are limitations.

And if there are limitations, that means there must be other roads that can be taken to circumvent these limitations.


SPEAKER_01:
Thank you.

Great comment.

Ali?


SPEAKER_07:
Well, Deleuze and Guattari in A Thousand Plateaus has laid out the concept of rhizome.

I don't know if you're familiar with the concept of rhizome as opposed to an arborescent structure.

Well, basically, the concept of rhizome

expounds a structure, a knowledge structure in which every concept can potentially be connected to every other concept without having to go through a principal trunk

of a knowledge tree, let's say.

But in an arborescent structure, an arborescent knowledge structure, everything branches from a principal trunk, from a principal

let's say, base.

And I believe that in active inference, a rhizomatic approach can also be explored.

And I mean, not only by approaching two different concepts via the high road or the low road main or principal trunk.

it can potentially be approached from seemingly unrelated concepts too.


SPEAKER_01:
Awesome.

To maybe even approach a limitation or a seemingly unrelated concept, both the high and the low road in this textbook are formal, and they're both grounded in mathematical symbols.

so are there qualitative or non-mathematical roads maybe some of the early roads are mathematical but is it possible that a future road or path or tunnel or

choose your travel metaphor might not be that case and then then thanks for sharing that um the resource there because um this is another interesting angle which um various people have traced this evolution of visual metaphor where it's like things are ladder-like and scalar and then there's more of a bifurcating tree and then that becomes um critiqued or complexified into more of a network

like with integration among species for example so there's sort of this movement from linear through a tree like a directed acyclic graph towards something that's more networked so that's um a lot of interesting ideas anything else that people want to add or we'll continue on okay

On page 10, they write, creatures engaging in active inference actively seek out salient sensory observations that resolve their uncertainty.

So what is the relationship between salience and the kind of observation that reduces uncertainty?

Why is the relationship between salience, observation, and uncertainty this way?

How does active inference frame this relationship similarly or different from which other specific frameworks?

so someone wrote I like this question a lot eager to get a better understanding of what constitutes salience is salience referencing information that is self-evidence or information that is precise and surprising or dot dot dot yes I think um attention and salience is addressed more in papers on active inference

than at least just from a preliminary pass of the book so attention and metacognitive mechanisms are not going to be um a core feature in the book however there's again been a lot of interesting work on like the neurobiology and the computational aspects of salience and attention

We can click on the word and see a definition, but this is not like the final definition.

This is just what some have gotten to.

Salience is the extent to which a cue or an observation commands the attention of an agent given their regime of attention.

So potentially a little bit tautological, like a salient observation is something that is grabbing attention.

A salient cue is something that commands attention.

Steven?


SPEAKER_06:
Yes, I would say that, especially if we're defining it in that way, that there are two elements to salience.

And one is what was pointed out in the question, I guess, that you are reducing...

uncertainty, but there is also the question of what uncertainty is worth reducing.

And that gets into utility and where it makes sense to explore.

So I don't know if we want to choose to change the definition of salience to just be the second of those or leave it as having both of those elements.


SPEAKER_01:
Thanks.

Mallory?


SPEAKER_02:
I think something I don't necessarily understand, which I would appreciate maybe somebody speaking to a little bit is, and this is related actually to a question I've put in earlier about the distinction between perception and learning, but something that grabs attention

Are we distinguishing, so that would say that something is, like the point that was just made, something is salient if it reduces uncertainty.

If we're also attending to things in order to actively construct a niche that is consistent with our model of the world, would we not consider that something

like that object as attracting attention as opposed to our, like, how do we distinguish, I guess, between active sampling and attending?

Um, and how is that related to salient?

So something salient, either if it, um, is surprising or if it is like, um,

serving the purpose of kind of like fulfilling a prediction.

I'm not sure I understand that kind of distinction.

I'm not sure that makes sense, but.


SPEAKER_01:
Awesome question.

And this is one reason why looking at the formalisms and how they're framed will help us because in the purely English linguistic realm,

We could imagine sentences of any type.

So in the active inference formalisms, what are being tagged with salience?

Which variables are said to reflect salience?

And then are they, or in what ways are they related to this concept of surprise, which we're gonna get to in a question soon, versus utility?

And this is also speaking to the way that expectations and preferences in active inference are framed differently than in certain other frameworks.


SPEAKER_04:
Can I jump in and just ask another question about this question rather than an answer, which is...

Wouldn't some data be salient even if it's sensible?

We might have two levels of salience.

So I just put this quote in about the notion of a umfeldt being a more or less broad series of elements called carriers of significance or marks, which are the only things that interest the animal.

Now, interest the animal is one thing, but even just perceiving those marks as existing, I mean, active inference does have room for that.

in terms of each agent having some sensory data.

So you could say, well, since I can't see infrared light, it's not salient to me when I'm out in a field of flowers.

But a bee can see that.

I think it can see infrared or ultraviolet.

I can't remember which one.

So it may be a salient concept for me as a thinking agent, but it's not one that's salient for me when I'm navigating a field of flowers, basically.


SPEAKER_01:
Nice.

Thanks for bringing in umwelt.

And a lot of ecological psychology terms do make their way to act-inf.

And so then you brought up like levels of perception salience.

For example, there's things that are outside of the wavelength that can be perceived.

So photons are not going to be perceived at that wavelength.

But then there might be within the visible range novel arrangements.

There's something moving there.

Or there might be something that is static yet commands attention, like the Mona Lisa.

So what is happening when somebody's regime of attention is fixated on a static artifact versus something where they're being fixated on something that's rapidly changing, like a movie?

Mallory, in the chat you wrote, can folks recommend papers?

So definitely people can recommend papers anywhere they see fit.

And one place to check out is in the bottom of our coda in the live streams.

Under the live stream tab, you'll find like 45 papers that we've relatively extensively discussed.

And so these are not like the only or the canonical papers or anything, but there's a lot of important ones in there.

So especially if you're interested in looking at papers where people in the lab might have familiarity or there's some things to listen to or watch about it, then these are some good places to start.

All right.

Awesome.

Next question.

All right.

This is a contextualization question.

This is not a metadata contextualizing sentence.

On page 9 and 10, they talk about differences from alternative frameworks.

For example, in contrast with other frameworks, policy selection in active inference automatically balances exploration and exploitation.

And later, active inference extends the inferential approach to domains of cognition that are rarely considered.

What are five to seven examples, names in a sentence, of other theories and frameworks that active inference improves upon or updates?

Anyone can raise their hand.

This is an excellent homework slash collaborative StigmaG question.

Because even if each person only thought of one novel answer here with a link and a name, or somebody improved what somebody else had already brought, very quickly, as a textbook group, we could have quite a coherent and comprehensive list.

The idea of balancing exploration and exploitation, so-called, is going to be a key theme.

And the way that Active Inference does handle this trade-off

not through the use of like an exploratory mode or exploitative mode or some parameter that is like governing the the handoff there like some sort of you know x times exploration plus one minus x of exploitation that is like one approach that's commonly used but it would be um a question of like where you know what citations use that type of an approach and it's going to come

to the epistemic and pragmatic value whereas um when there's little epistemic value to be gleaned little informational uncertainty result to resolve then pragmatic value can be pursued which is reducing the surprise about outcomes in relationship to preferences and then on the other hand when there's a lot of uncertainty

exploratory behavior might be engaged in because there isn't enough certainty around how to pursue those pragmatic aims and these are going to come into play with like the teammates mouse model that's going to be later in the book but this is a great question so anyone want to like just give an example of some other theory or framework or some other approach to thinking about exploration exploitation

One starting reading if anyone is interested there is a 2015 paper that is looking at exploration and exploitation trade-offs in different domains.

Ali?


SPEAKER_07:
Well, I don't know if it necessarily improves upon, but certainly an alternative approach to this theory can be Steven Grossberg's art theory, the adaptive resonance theory that we talked about in the previous session.

In that theory, the problem of learning and cognition

is attacked from the viewpoint of solving the stability slash plasticity dilemma.

And in this context, in the context of art or adaptive resonance theory, well, or let's say the difference between the active inference, one of the main differences between the active inference or any predictive coding schemes from adaptive resonance theory is that

In Bayesian models, generally, the fully suppressive matching circuits, I mean, the circuits that can propagate the information, it cannot solve the stability slash plasticity dilemma as opposed to the ART or adaptive resonance theory.


SPEAKER_01:
So plasticity being more exploratory and openness to updates and stability being more like parametric lock-in, more exploitative within a certain realm.


SPEAKER_07:
Yeah, the plasticity refers to a system that doesn't have catastrophic forgetfulness.


SPEAKER_01:
Awesome.

Cool.

So we can just, you know, have this question up and check back and people can add things.

We'll just look at a few more questions.

So on page eight, they write, the high road perspective is useful to understand the normative nature of active inference.

what the living organisms must do to face their fundamental existential challenges minimize free energy and why the what and the why in the high road why to vicariously minimize the surprise of their sensory observations what does it mean to minimize surprise vicariously

So someone has written, interesting choice of words.

Here are two possible answers.

Also the authors or the readers, participants may have something else in mind.

Vicarious might refer to the point on page six that agents cannot tractably minimize surprise as the authors technically defined it in chapter two coming up.

So instead they're gonna minimize an approximation to surprise, which is variational free energy.

However, I'm not sure if they're referring to the two types of surprise that are going to be approached in chapter two, which is the marginal surprise, like informational surprise, and then the Bayesian surprise, or both.

So one option is surprise as defined, one way or the other or both, cannot be directly

calculated or it's not tractable to to pursue and so the vicarious could mean like indirect or via a proxy and in that case something like variational free energy is being vicariously minimized and then that is going to be used to get at the surprise minimization and the second option the person has written vicarious might refer to the point that agents minimize free energy not only in response to real sensory observations but in anticipation of them

Those anticipations could come from internal simulations by subroutines or other modules or memory from recall of past observed events.

Page 32, which is probably in chapter two, the author seemed to be referring to engaging models vicariously in a counterfactual sense, dealing with imagined surprise at presumed observations.

So these are really important comments.

have the indirect minimization of surprise using a proxy so some type of heuristic to minimizing surprise now and so that is vicarious but contemporary and then the second sense is whether we're using a proxy or not is referring to um

observations that haven't occurred so anticipated or expected observations some of these hopefully we'll come back to in chapter two

But these are important questions.

And it's going to speak to variational free energy and expected free energy and free energy of the expected future, a few other constructs.

Stephen?

And then I'll leave.


SPEAKER_06:
Yeah, I put that last comment in.

I was just thinking that should probably go under number two there.

I guess that would be evidence of that second interpretation.


SPEAKER_01:
Thank you.

Okay, so we'll maybe return to this in chapter two.

Okay, let's just see if we can look up just a few of these questions.

It's awesome, like how many there are.

And of course, anyone can always read and contribute asynchronously.

All right.

subtitle of the book is the free energy principle in mind brain and behavior what is the relevant distinction between mind and brain in the context of the free energy principle someone has written really appreciate how the researchers have started proposing biological implementations of active in the brain

it's not clear to me how this maps onto related psychological concepts like colloquial surprise prediction salience arousal yeah awesome and there's been some recent work and some work that we're going to be looking at in um live stream 46 on active inference and folk psychology

about connecting some of the formalisms to to folks psychological concepts so that's one place we'll be looking at that but um how does or does active approach this mind brain question whether the Cartesian dualist question hard problem of Consciousness intentional stance of Dennett

Why is the subtitle of the book that way?

Jessica, and then anyone else with a raised hand.


SPEAKER_08:
Um, yes.

I mean, I don't know the answer, but I, I guess make a guess.

I think maybe the, um, mine would be more the cognition and the brain looking at the physiology.

Um, and then, you know, looking at behaviors, that would be my guess.


SPEAKER_01:
Yeah.

Awesome.

The bacterium does not have a brain, but does it have a mind?

also great questions we'll just continue just um these questions with fewer upvotes because there's a bunch just so we can get them in so generative model is used in the singular or is using the singular as in the generative model or in the plural as in hierarchical generative models is a generative model composed of generative models i.e is it structurally fractal

Someone has written, personally, I think the answer is yes, or it's possible to answer yes, via referencing a paper that talks about blankets of blankets, Markov Blankets Life.

This paper definitely does think about the nesting of multi-scale complex systems in terms of like nested generative models that then are constituting, yes.

that are then constituting generative models at a higher level.

So there's people with their generative model, and then the team has a generative model of a different type, JF.


SPEAKER_05:
Yes, but even an individual, myself, yourself, could be characterized as having a generative model composed of other generative models dealing with less abstract umwelt, for example.

So I think, yes, almost trivially in the sense of a collective, but in the sense of an individual, does an individual also can be said to possess a generative model that is itself composed of sub generative models?


SPEAKER_01:
awesome point and we've in several live streams and settings discussed like there's one sense where nesting is used to refer to systems that are like potentially even physically nested and then we also see the nesting architecture for example here it's live stream number 25. when we discussed it but this is a nesting of attentional and cognitive models

so this is even of a so-called individual so what is it about model nesting when sometimes it can refer to physical enclosure and other times it is something that enables counterfactual reasoning attention and metacognition

So what is the nesting?

And if someone is just seeing this kind of a notation or this kind of a graph for the first time, we're gonna totally go into it, but it's gonna be one of the core formalisms.

And also this paper is gonna deal with nested models and other papers do.

The textbook is gonna spend almost all the time

um on just one level so just sort of the kernel or the essence or the archetype or the essential motif of this partially observable markov decision process and the textbook is going to focus on juxtaposing the discrete time partially observable markov decision process with the continuous time but it will deal less with hierarchical nesting but it does bring it up but it's not going to be focused on okay

what is the information content of a prediction I'm just going to read these ones just so that those who are listening can see like the kinds of questions that they could be adding or addressing this question has to do with the relationship between active inference and pleasant surprises potentially even love languages receiving money on the pavement page five

is speaking to the author's rhetoric around theory, proliferation, and integration, where basically they are saying, well, we could have a dedicated explanation for every neurotransmitter, for every synaptic junction, every unique behavior, every cognitive phenomena, or we could somehow utilize first principles, whatever those are, to result in theory integration.

And that gets mapped onto the scruffies and the neats

is it really helpful to redefine terms such as probability and surprise to sometimes mean utility and diversions from utility if that's what the authors are doing there appears to be an unhealthy ambiguity in how they use these terms this is where the formalisms are going to really come into play um and also the um

The live stream on Free Energy, a user's guide 37 deals with this dual interpretation of expectations and preferences.

And this is like one of the most essential differences between active inference and reward learning or reinforcement learning frameworks is a dual deployment of the same variable in formalisms to represent preferred states as well as expected states.

like homeostatic range is expected and preferred.

It's where one wants to be found and it's where one expects to be found.

And so one can realize those preferences by reducing their surprise about the observations rather than saying, well, homeostatic states are valuable and we're gonna pursue maximum value.

How might an acceptable state space relate to the idea of a comfort zone?

seems the acceptable state space for an organism is necessary for it to persist whereas a comfort zone seems to be a less necessary state repertoire which if exceeded may only indicate to an organism that it's at risk of leaving the acceptable state space interesting and then the last written question here looking ahead into part two have people been looking in the computational complexity of the active inference model and how far are we in terms of making this computable

and the reference 2019 paper computational resource demands of the predictive bayesian brain excellent and important question to understand like the analytical computational complexity like the big o notation does nesting a model make it two or is it you know log the number of levels or is it number of levels to the some exponents

And then also in practice, like using active block for ints or PyMDP, what is the actual runtime of different algorithms?

so um this is awesome with the questions that everyone's added to one like we're going to keep on returning to chapter one just like we're going to keep on returning to ideas but people can fold it and continue to add to two and to the appendices which we're gonna go to next week um so just as a reminder next week we're going to be approaching appendix a and b which are mathematical and so just a few thoughts on that before we return back to the ideas in the book

in appendix a you can see that all the equations have already been added so if anyone like wants to reference like what does equation a point 44 mean um and obviously like there's 60 equations and you could get your phd learning about some sub function of just one so we're just trying to familiarize and get a first coat of paint so for those with different mathematical backgrounds if somebody can derive the proof

amazing let's take some notes on it and if somebody is just going to be asking beginner questions that's also very important so um that will be in next week's questions and discussions but let's just look at what ideas people wrote and then see if there's any ideas percolating so um

having addressed some specific uncertainties, I get with the questions, we can think about like, what are some impressions that people were having?

And like, what was exciting ideas?

So if Ben or Mike want to speak to this, or if anybody else like wants to share something, JF, and then anyone else?

Yeah, JF, and then Ben, or is your hand raised?

No, my hand was not raised.

Ben, go for it.


SPEAKER_03:
Yeah, thanks.

Can you hear me?

Yep.

Cool.

Yeah, maybe I should have posed this as a question, actually.

I just thought it was interesting, this connection between perception and learning as essentially the same process unfolding over different timescales.

Because on the one hand, this makes sense to me, because one example of learning might be, you can imagine an agent moving to a new city,

with which they're completely unfamiliar.

And the agent could sit at a fixed point in the city or walk around the city and just perceive the city.

And they would learn over a longer timescale.

They would observe certain regularities or certain occurrences.

And clearly that's one form of learning.

But then there's maybe another example where, you know, my mathematical background's fairly weak.

And so if I were to try and learn the kind of fundamentals of the equations that we were just looking at,

No matter how, for how long I kind of perceive those equations, I'm not going to learn them.

There's going to be that I have no access to kind of, there's no information gain there.

It seems like to learn certain things, we need to scaffold perception in certain ways.

And so I suppose my question would be when somebody teaches us something that we don't understand, is that merely a kind of scaffolded perception of,

Or is that kind of learning underwritten by distinct cognitive processing completely separate from perception?


SPEAKER_01:
Great question.

Thanks for unpacking that.

And to give one thought, let's imagine a ball moving across the visual fields.

It seems like a canonical example of perception.

We're perceiving the ball.

But it could also be understood as parameter updating or parameter learning of...

the location of the ball.

And then that's one approach, but then also you pointed towards like this deeper sense of learning, referring to like the underlying structures.

Like in the ball movement examples, it seems like learning and perception are the same, but then learning might also refer to something deeper, like the tendencies of how balls move.

Or one could, as probably many of us have, look at these symbols and perceive them visually

But because we wouldn't have learnt the underlying generative model that gives rise to these pixels, we could continually be surprised.

So what is happening when there's perception and learning seemingly happening hand in hand, and then other times where somebody's speaking a language you don't understand, you certainly hear it, you may even be paying attention to it, yet the next phoneme may still continually surprise you.

So it's a really important question.

And then Mike wrote, yes, please go for it, Mike.


SPEAKER_00:
Yeah, so I think these are straightforward but foundational concepts that the dependence of sensory input on action and vice versa creates a framework where we can have feedback.

And then the mathematical constructs let us think about how we model that and simulate it.


SPEAKER_01:
Thanks for this also essential point.

In active inference, there isn't a perception and inference module that passes the perceptions to the learning module and the learning module passes it to the decision-making module and the decision-making module to the action model.

The inference is conditioned upon policy selection and action.

and that is going to approach this nexus of perception cognition and action in an integrated way that not that may differ from other frameworks which was also to the point of that um previous question so

This was an awesome session, everyone.

Really appreciated it.

I'll upload the video recording following the meeting.

Next week at the same time, we'll be looking at questions and ideas from Appendix A and B. So just approach those however you'd like and annotate the coda.

And also, if anybody wants to specify another time when they just want to discuss or co-work,

that can be added or in the act in flab discord people can like join and we can have like a voice like a study hour or just a time to talk about stuff or write down the questions we have so awesome work everybody thanks a lot