start	end	paragNum	speaker	confidence	startTime	wordCount	text
650	28550	1	A	0.45805	00:00	54	You. Hello everyone. It is June 2, 2022 and we're in week five of textbook group cohort one. We're having our second discussion on chapter two and we will get right to the questions. First, just wanted to highlight the Math learning group, especially for those who are not regularly attending the meetings yet.
28620	48860	2	A	1.0	00:28	52	The meetings are on 19 UTC on Wednesdays. But just with everything, don't let the synchronous time dissuade you. We can set up other synchronous times if people want to cowork. And also the resources and the modifications are all asynchronous. So we've been doing several things in the Math learning group.
49550	89850	3	A	1.0	00:49	116	First, we've been sharing important resources and categorizing them. So if somebody wants to look at a video on something or find a textbook on something, or if you come across something useful, just add it here. And then if you feel like leveraging the resources that you or other people have added, then you can categorize it in the table and just add a few pieces of information on it. We have a notation table that we'll be building, especially as we get into the continuous time active inference. We have some questions, less so questions about the textbook and more so, just cool math questions that people are raising as they're discussing the material.
90350	109898	4	A	0.91	01:30	55	And then we're building a math oriented overview. So we've gotten up to equation 2.5 in chapter two and this is just sort of like point by point, like what are the formalisms doing? Where are the figures coming into play? How are some things related? And any and all note taking can be added.
109994	136162	5	A	0.88721	01:49	76	You can always add it to like unsorted notes or erota and then we can categorize it later. But this is how we develop a shared epistemic resource that's useful for everyone. And we're going to come to this in the questions. So we won't go into detail right now, but equation 2.5 is the variational free energy. 2.6 is about expected free energy, the G, and this is a key equation and set of equations.
136306	174658	6	A	0.99995	02:16	72	So yesterday with Blue, Brock, Jessica Jakub, we went through and line by line we went with examples, natural language readings, questions, interpretations, and then Yaakob added some derivations. Like how are those three lines in 2.5 related to each other? How do we go from the energy and entropy formulation to the complexity accuracy formulation? So this is the essence of understanding the equations. It's an infinite learning journey for everyone.
174744	202206	7	A	0.99994	02:54	66	So whatever level, whether you want to. Be. Catching up to what has been written here, or whether you see ways to reorganize it and go beyond and add more connections, every single background and level of math familiarity can contribute in this way. But we'll come to the more details on 2.5 in the questions. Any just preliminary thoughts that people would like to share?
202388	227030	8	A	0.99963	03:22	68	They can raise their hand or write in the chat at any time. Is there anything that anybody wants to share before we start going through the questions, starting with the most upvoted ones that we haven't addressed, but we'll just pause for a few seconds. Tune into the chapter two regime of attention upvote any questions that you'd like to see addressed? Post anything in the chat?
232640	266720	9	A	0.99998	03:52	81	Yes, Jose? Yeah, I'd like to ask if there's a recording of the math sessions which you had. No, we record Stick mergically with the traces in the notes and we had this conversation like about whether it should be recorded or et cetera. If there's enough desire, we could do something like have some unrecorded and some recorded. This session is obviously recorded and rewatchable here and we do many live streams and there is a lot of recorded material.
266880	294400	10	A	0.99	04:26	80	And so we want to also hold a space for people who don't want to speak on a recorded version, even though everything's recorded in universe and in each other's minds. But yes, if there's enough interest in people who want to record sessions, we absolutely will do it. We also just wanted to make sure that there was a total open math learning space where people wouldn't even have that cross their horizon. But we did discuss that yesterday.
297220	300400	11	A	0.9996	04:57	6	Thank you. Yeah. Any other comments?
302740	326730	12	A	0.99999	05:02	58	People can just raise their hand with six in gather or right in the chat. So we're going to just go to the questions and there's still time to upvote, like during the discussions and we're just going to upvote the ones once we've discussed them. So we'll start with the first question that we haven't discussed yet.
329840	345970	13	A	0.98202	05:29	39	Okay, this is from page 32. Policy dependent outcomes are not immediately available, but they can be predicted by chaining together two components of the generative model. The first is our beliefs about how hidden states change their time.
350340	355590	14	A	0.91569	05:50	9	Just want to find what the second part was.
360520	363300	15	A	0.86	06:00	7	The second component is the likelihood distribution.
370250	389660	16	A	0.99947	06:10	54	What really changes as a result of policy selection, the hidden states or the outcomes? Bringing a jacket doesn't necessarily change the temperature hidden state but instead changes my observation perception of whether it's cold or not. Can we actually change hidden states with policy selection? And what would be an example of this?
391970	411614	17	A	0.99913	06:31	45	Does anyone want to raise their hand and give a thought on this question? What really changes as a result of policy selection? The hidden states are the outcomes while people are raising their hand. I'll give one possible thought. The answer is both slash.
411662	448170	18	A	1.0	06:51	98	It depends. So bringing a jacket does change the temperature around you. It's not just changing your perception of temperature. So one example of changing a hidden state with temperature, hidden state of temperature with policy selection would be like changing the setting on the thermostat that is intervening into the causal process, the generative process that's giving rise to temperature, which is giving rise to your perceptions of temperature. And so assuming that your temperature perception is accurate, you are able to change both the temperature in the room or the temperature around you with the jacket.
448330	457170	19	A	0.65	07:28	18	And thus because temperatures are giving rise to observations of temperature, also you end up changing both blue.
460550	503210	20	D	0.99395	07:40	114	So this is my question and I think Karl kind of possibly started to answer it on the live stream yesterday. I need to think about it more and unpack it a little bit more. But we change the temperature around ourselves, but we're not going to change the thermometer reading by bringing a jacket. Right, but anyway, what Karl said and what might be beneficial for others to hear is that when you think about what's changing, it's like really, when you think about a hidden state, there's a causal chain underlying that hidden state. And the same thing, like when you think about an observation, there's a causal chain underlying that observation.
503370	534890	21	D	0.99	08:23	93	So like, no, I'm not going to change what my eyes tell me the temperature is, but I'm going to change what my body tells me the temperature is. And so it depends because it's a multisensory observation, right? So which sense is going to change not my visual reading on the thermometer, but my physical perception of cold. Also yesterday on the live stream, thomas Parr and Karl Friston joined So that was really awesome and a great one to watch. 45.1 and we can continue on this Ali and then Mike.
538270	582090	22	E	0.99914	08:58	78	Yeah, I think that's what meant by the word hidden in the statement because if it was transparency observation to any kind of perception or observation, I don't think it would be called a hidden state. I believe that the reason it's called this, it's called as such is because it's opaque to any kind of perception or observation. So it's kind of inherent to the universe and probably not amenable to any change or action. Thanks Mike.
586440	628508	23	B	0.53075	09:46	89	Yeah, I'm not sure if I'm thinking about it the right way, but intuitively. I was thinking that policy selection would update the expected conditions or the expected state, so maybe adjusting the priors in evasion sense. Thanks. So we'll come to this later, but the answer based upon the partially observable Markov decision process, discrete and continuous time versions, policies pi intervene in between hidden states and how they change their time. Different hidden states, should they be giving rise to different observations, will result in different observations.
628684	671324	24	A	0.99996	10:28	107	So changing the thermometer policy selection is intervening in the causal process of temperature changing through time in the room hidden state. And if the temperature in the room is associated through the a matrix with your observations of temperature, then you will be changing your observations. And then just like Mike said, that is reflected based upon the expectations that the individual has about the observations of temperature. So they're both changing because the hidden states and the observations are linked. That's what it means to have a generative model or for there to be a partially observable model with hidden states and observables hierarchical models.
671452	695860	25	A	1.0	11:11	69	A given state could be in emission from a higher state and emitting a lower state. And that's kind of like how the current moment is like a consequence of the past, but it's a cause of the future. So this is related to Bayesian modeling, but using this architecture, we can say that policy intervenes only in between hidden states. We don't directly intervene in how observations appear.
700360	703670	26	A	0.99991	11:40	8	Any other thoughts or questions on this question?
712070	712820	27	A	0.94034	11:52	1	Okay.
719530	720440	28	A	0.79449	11:59	2	All right.
723790	755340	29	A	0.78474	12:03	61	In Figure 2.2 figure 2.2 they write x, Star, and X. So that's going to be generative process and generative model. Latent variables. Hidden states do not necessarily live in the same space of measurement. It might be the case that hidden states in the external world take on values that lie outside the space of explanations available to the brain.
755680	789130	30	A	0.99995	12:35	83	Conversely, it might be that the brain's explanations include variables that do not exist in the outside world. For example, the former could be five dimensional and the latter two dimensional. Or one could be continuous and the other could be categorical. So what are examples people can think of where the dimensionality of the generative model, the cognitive entity, is the same as the generative process, the niche process giving rise to observations, passing them to the generative model. That's one question.
790780	825184	31	A	1.0	13:10	65	Second question how does this approach or framing speak up to the map territory debate hashtag, instrumentalism and realism? What papers or live streams best characterize how active inference models the action, cognition perception loop? And what other possibilities or models are there for the action, cognition perception loop? What would be the different strengths and limitations of these different framings and partitionings? Thanks, Joe.
825232	860516	32	A	0.72	13:45	107	And then Blue and then anyone else who raises their hand. I was just thinking a nice case where you could say dimensionality is pretty obvious is board games. If I was trying to anticipate what my opponent is going to play in a board game, they have a limited number of possible moves and I'm assuming I'm playing the same game, I'm expecting them to make some move on the same board. So me, that sounds like the dimensionality is the same because you're in this limited world, I don't have to know what they're thinking. I don't have to know what they had for breakfast.
860648	865840	33	F	0.99	14:20	19	I don't have to know a lot of stuff. I'm just thinking, and I might be wrong. What movement?
868740	870450	34	A	0.99956	14:28	4	Great. Thanks for that.
873800	920044	35	A	0.93012	14:33	127	So with the same dimensionality, it's like if we're playing the same game, then we're playing a game where we're tracking a little cursor on the screen. The movement space within that is just the x and the y value or just two dimensions. And so the observation is like the location in two dimensions, and then that is the same dimensionality that inference is occurring on. But as an I'm thinking just to add a little bit to more of my comment, if I wanted to enrich it and say oh, but I'm starting to think strategically and anticipating their next move or anticipating maybe they're bluffing or maybe I'm bluffing and I want to see if they know that I'm bluffing. We add more dimensionality.
920092	940292	36	F	1.0	15:20	59	And I guess in principle, again, you could still add that dimensionality in somehow in parity with parts of the hidden states. You see what I mean? That I'm thinking, oh, they think they know I'm bluffing or I think they're bluffing. You're talking again about the same thing. You don't have to know what they had for breakfast.
940356	975248	37	F	0.99989	15:40	65	You're just talking about this extra information which isn't in the board itself, but that gets a bit more complicated. Yes, thanks. So that is a good answer. Other ones that people have written thermostat is having the same dimensionality, like it's a temperature value, it's a dimensionality of one. And so then the person's generative model is also on this one dimensional temperature axis.
975424	1000190	38	A	1.0	16:15	61	And then they mentioned that it could be like categorical versus continuous. So without going too many rabbit holes deep, we could just say temperature in the room is a continuous variable. It's like taking on a number. It could be a decimal point number between any number, zero to infinity. The person's model might be the same dimensionality like one.
1000560	1023090	39	A	1.0	16:40	49	But then they might be trying to make a categorical estimate. Is this livable or unlivable? Is it hot, neutral or cold? That'd be like a three state categorical model. So the generative process doesn't have to have the same dimensionality or continuous versus discreteness of the generative model.
1027480	1064444	40	A	1.0	17:07	90	Second answer for same dimensionality. Controls for a car have two degrees physical degrees of freedom the acceleration, the speed, whether you can hit the gas or the brake and the direction of the front wheels controlled by the steering wheel. So there's like a speed dimension and then there's a turning angle dimension. This is the model that people use when controlling a car at some level about abstraction. And then the acceleration dimension can be acted upon through policy selections like stepping on the gas and the brakes.
1064492	1096516	41	A	0.99	17:44	72	And then it's like, well, those are two categorically different affordances and then there's continuous variables inside of that categorical difference. And we'll talk about like hybrid control models with both categorical and continuous aspects in play. And in this case, the speed of the car in the speed axis is the hidden state. The observable would be the speedometer. So again, the gas and the brake are policy selections that modify.
1096628	1126092	42	A	0.99958	18:16	65	Let's say we're thinking about a train. No turning policy selection is influencing how speed changes through time. And if you have a speedometer that's accurate, even if it's noisy, it's giving rise to observations reflecting those changes in speed. But gas and brake do not change the speedometer directly. They're changing a hidden cause, which is the speed different dimensionality rain comes from clouds.
1126156	1133510	43	A	0.99169	18:46	20	Simple mental model is that the darker the clouds, the more there will be. That's a two dimensional generative model.
1135580	1159308	44	A	0.69077	18:55	56	So how much rain, how dark the clouds? And this also is going to speak to this map territory. Someone could say, well, there's the size of the cloud and there's also the humidity. So that's like maps with increasing amounts of variables. So no one's denying the territory of the actual chaos of the cloud.
1159474	1210468	45	A	0.83173	19:19	101	It's just a question of how much detail and what data we're actually treating as observables. And what sophistication is being taken with unobserved variables with hidden states which are modeled in the computer or on paper, but they're not directly observed, then the mental model can be decomposed even more and then add infinitem. On the reality side, the actual generative process for weather is including all the butterflies. So that's a cognitive model that is two dimensional. In this case, how much rain is expected and how dark is the cloud, that one could make increasingly nuanced cognitive models.
1210664	1234820	46	A	0.99985	20:10	53	But whatever cognitive model is being proposed, the generative process is something that's like totally different. Cognitive model generative. Model map generative process niche territory. Plants do better when they have water and fertilizer. Generative mental Model leaf droopiness is a sign of moisture, but leaf size and color are signs for nutrients.
1235720	1270320	47	A	0.99896	20:35	82	So one could imagine like a causal graph where there's like moisture level is unobserved, but it is emitting leaf droopiness as a state. But we're observing leaf droopiness and we're using that to infer moisture, whereas nutrient is an unobserved state to the visual gardener. And then they're using two dimensions, leaf size and color. So this is a three dimensional cognitive model leaf droopiness, leaf size and color are observables. And then there's two unobserved cognitive states, nutrients and moisture.
1271700	1314320	48	A	0.99635	21:11	114	But whatever map gets constructed, that's not the plant. Now, the gardener might then want to take an informative experiment being an optimal Bayesian gardener, and then measure something, take something that was an unobserved in the initial model and then measure using LiDAR, like using some sort of sensor to understand. And then that would make that data point an outcome related through some a matrix, which we're going to get to later of the hidden state being like the true levels of copper. And then if we have an accurate test, we can start using the outcomes of the observed levels of copper and start flushing out our model that way. Joe.
1317380	1336748	49	F	0.99	21:57	59	I chucked in a comment below. I hope it's showing up just that. The other part of the question was asking about the map territory debate. And here's from the person who kind of came up with that dichotomy in the way we usually talk about it. He says that the map and territory should have a similar structure.
1336784	1359980	50	F	1.0	22:16	73	And I think that's really interesting to think about. If I'm making again moves in a board game, I might make a reduction of their mental state. Maybe I'm playing against a computer for example. So I don't know that they have a mental state or maybe I'm playing against a person I happen to know as a beginner. So I know they're likely to make naive mistakes or whatever, something like that.
1360130	1394570	51	F	0.99814	22:40	93	But I was just thinking like with regard to the leaf droopiness thing, you could have all kinds of really badly structured models of plant health. Maybe it relates to how recently you watered it or something. Well, that sounds good in general, but if it's a cactus, maybe that's like a defeater to your system. So the point being it seemed interesting that your map should maybe if it doesn't have exactly the same dimensionality, should still be a nice reduction of the thing you're trying to model, whatever that means. Thanks.
1396460	1448840	52	A	1.0	23:16	110	One aspect on this is evolution, natural selection, dissipation in our world, sweeping off the table entities that are failing to at least be adequate. So in a dissipative situation that we're in, the map has to be at least good enough, otherwise the entity will fail to exist. So that sort of closes the loop and is like we're seeing the persistent entities that are acting good enough to navigate. And it's just interesting like how many the allegory of the cave to the blind people and the elephant and realism instrumentalism and we've had many live streams on this especially. Check out number 14 on Mel Andrew's paper.
1448990	1479584	53	A	1.0	24:08	86	The math is not the territory. So this one sort of explicitly jumps in right there and tackles this issue with the FEP front and center. So this is a great series of live streams. The dot zeros are background and context where we just go over the paper in a small group, like one person or two or three people and then the dot one and the dot two. We usually have more of an open participatory discussion and the authors sometimes to usually join.
1479632	1521692	54	A	0.99991	24:39	113	So everybody's welcome to participate in contributing to dot zeros as well as enjoying the dot one and the dot two. But just so you know, when you're looking in the live stream table, the dot zero is a good one to watch first because it has the background and overview on the paper. But then like yesterday in 45.1, we had Friston and Par join to discuss just so that people can navigate the live streams a little better. So we can continue asynchronously adding more thoughts on like map territory and what papers and live streams and what other possibilities for the action perception loop. But these are big fun areas.
1521756	1561064	55	A	0.99996	25:21	90	But we're going to continue with the questions on the notion of surprise. Is the agent's perception not only affected by the influence of not only its environment but also an agent's peers? So perhaps to restate, how is an agent's perception affected by its direct perception and its assessment of peers? So the agent's peers are updating their beliefs in a collaborative fashion. What would be the extent of the update to an agent's generative model of perception if the agent witnesses the annihilation of one of its peers.
1561112	1582950	56	A	1.0	26:01	53	For example, something like this, okay, will to be from bird box. Not going to open any video links, but perhaps we'll observe some annihilation like some animal attacks one of the wild beast on the right, but then the other one learns. So this is a great video. Definitely good to watch.
1585080	1618320	57	A	0.99998	26:25	79	So far in the textbook and indeed for the textbook it's focusing on just like we saw in figure two two, it's like one entity in the niche. The niche can consist of others like me. Other entities that I expect are similar to myself in terms of like the coarse grained cognitive architecture they have or their preferences, their affordances. They're able to do similar things, they want similar things. They have a similar history to some extent.
1619460	1657260	58	A	0.99371	26:59	85	So that is sometimes called thinking through other minds. Ttom and just to give one thought and then anyone can raise their hand. If we were to accurately observe another peer taking some action and then failing to exist, we're driving on the highway, and then we observe somebody taking a policy to go off the highway, and then we see them fail to exist, we could use that information to update our beliefs about the consequences of the action to drive off the highway.
1659600	1687640	59	A	0.9203	27:39	48	So I believe it would be possible to implement every variation of direct perception, direct perception of peers thinking through other minds, theory of mind learning by example, imitation, contrarianism. Every phenomena could be modeled as just has to be whatever the specific model is actually about. Ali.
1692050	1746510	60	E	1.0	28:12	90	I have a related question about 2.5 and 2.6. Well, correct me if I'm wrong, but I understand that these equations describe the behavior of a kind of rational behavior or the kind of behavior of a rational agent. Where does irrationality comes into this? Or let me put it this way can irrationality be a parameter? In order to qualify these two equations, 2.5 and 2.6, or seen from the other side, can we use these two equations to measure the extent of rationality as a measurement of rationality?
1747890	1754980	61	A	0.99807	29:07	19	Good question. Here's one quote. And we'll come to equation 2.5 and six as well because those are important.
1757750	1781658	62	A	0.74147	29:17	60	Distinguishing the generative model and the generative process is really important. That's the difference between the entity and the niche. It's important to distinguish them to contextualize psychological claims about the optimality of inference. To the extent these claims are valid on a Bayesian view is always contingent on the organism's resource. So don't want to step out too far.
1781744	1799754	63	A	1.0	29:41	47	But rationality and irrationality. It's rational to believe in X. It is irrational to believe in X is always subjective. From that speaker's perspective, given the priors and the update rules, all there is is rationality. Which is to say this is just the Bayesian updating process.
1799892	1837840	64	A	0.99994	29:59	82	So there are maladaptive priors ones that trend towards dissolution of the entity. But there aren't irrational priors. There just is what it is and how it updates. And then that could be inadequate, it could be any number of other things and these are like getting into relatively complex cognitive phenomena where there could be like multiple layered models. But I would say rationality in the Bayes process is like the cognition is Bayes optimal or modeled with a Bayesian process.
1838770	1849520	65	A	0.67	30:38	26	And then sometimes the interaction of the generative model and the generative process as appropriately defined specifically is going to result in what it results in.
1852550	1883660	66	A	0.84335	30:52	81	But we will come to 2.5 and 2.6. Okay here. Suffice to say, yes, social learning and collective behavior and emergent outcomes at the group level is something that's important. But we haven't addressed it so far in the textbook, and multi agent models are not really addressed in the textbook that much because there's so much to understand about the kernel of the perception cognition action loop that even though it's so important for real systems, it's not brought up.
1893970	1905890	67	A	0.99781	31:33	20	Okay, wanting to go to the equation, the dark room problem for many years, many Papes firing back and forth.
1909130	1937760	68	A	0.99985	31:49	49	But let's go to the equations for our let me check the chat here. Yes, variational free energy is minimized through two different possible approaches minimizing divergence of Q and P, changing mind and maximizing evidence, taking action, changing perception. This is done based upon prior and present information.
1942130	1997340	69	A	0.99976	32:22	95	Equation 2.5 variational free energy to plan best actions, generative models and internal policies produce simulated outcomes that can be used to estimate expected free energy as the average of the log probability of outcomes. Equation 2.6 expected free energy and there's other variants in the context of planning, planning as inference. Equation 2.6 provides a view of EFE that establishes consistency in measurement units of exploration, exploitation. The relative balance between these terms determines whether behavior is predominantly explorative or exploitative. 34 in other words, dissolving the classic explore exploit dilemma in behavioral psychology.
1998820	2007250	70	A	0.99994	33:18	17	What causes this balance to change? I e. What controls this balance? Very important and interesting question.
2009720	2043528	71	A	0.95156	33:29	69	Perhaps we can come to equation 2.5 first and then we can come to equation 2.6. So where we're going is the future. The future has several sources of, in principle and in practice uncertainty. Observations in the future have not happened. Actions in the future have not happened and the causes of future outcomes and hidden states actions as well as the generative processes endogenous changes haven't occurred.
2043624	2094984	72	A	0.99997	34:03	93	So there are several fundamental and in practice limitations of the kind of precision that you can get on the future. That's planning as inference, it's prospective in contrast and that's expected free energy because it's about the free energy of an expected future. Variational free energy f expected free energy is g variational free energy F is in equation 2.5. Variational free energy as the question says, is based upon present and prior information. So variational free energy is like now casting and verging into something kind of like memory as inference.
2095112	2125464	73	A	0.99993	34:55	63	We're integrating the past in the sense of our priors and the present incoming data point why? And it's like a snapshot evaluation of optimal perception in the purely sensory case. And if we include action within variational free energy, it's taking one step optimal actions. But those are not necessarily like the ones that's not planning. That's just like snapshot decision making.
2125662	2141630	74	A	0.99973	35:25	28	In contrast, 2.6 will explicitly consider policies. It is a function of policy pi and so it is including planning as inference. But first let's look at 2.5.
2148580	2157840	75	A	0.24228	35:48	17	Yaakov or anyone else. Would you like to just describe one pass? What is equation 2.5 showing?
2171220	2207810	76	B	0.56	36:11	68	I guess if you mean like describing, say, the first line or the lines in a bit more detail, essentially the energy term is just the expectation of the log of the joint probability of the data and the observation. So I don't understand quite why they changed the notation from appendix B, but Y would essentially be the S, I think, and X would be the O.
2212140	2249380	77	A	0.99981	36:52	86	Yes, anyone could be taking more notes on this, but Y is the observable data and X is the hidden state in the POMDP that we're going to be getting to later x out there, the hidden state is S and O are observations. So this is using more of a regression familiar framework and variable notation. But this could also be written LNP of O comma S observations and states that's the joint distribution. Joint distribution with a comma conditional distributions with a vertical pipe.
2253610	2286286	78	B	0.90248	37:33	76	Yeah. And so we are also taking the entropy term is only based on the beliefs of our hidden states. So people were saying before that the hidden states are unobservable. The only thing that we can say about the hidden states are the beliefs about the hidden states. I don't think that the hidden states X can ever really appear on their own because we always need to have some kind of belief about them.
2286388	2381360	79	B	0.62	38:06	173	And this was also related to a discussion we were having yesterday that's interesting that they kind of switched between the notation of entropy with H as the functional and just the pure expectation with the E, because the actual definition of entropy is the expectation of the negative log of whatever is in is the variable, which in this case is Q of X. And that's actually how we get to the other two expressions with complexity and accuracy and divergence and evidence. And there's also a link I think might be wrong with to theoretical physics where free energy is essentially the kind of cognitive statistical equivalent of the Lagrangian, which is defined as kinetic energy minus potential energy. So we were discussing yesterday what that means in terms of the energy and entropy in this case, whether the energy is perhaps kind of the immediate cognitive kinetic energy and then the entropy is like. The potential energy or vice versa might be going off on a tangent at this point.
2382290	2396850	80	A	0.5914	39:42	31	Awesome. Let me just add in a few other notes. The variables f is a function. It's the variational free energy function. The arguments that it is taking in are Q.
2397000	2410600	81	A	0.99988	39:57	35	That's the variational distribution that we control. That's what makes it a variational free energy. Q is the one that we control. P is the actual probability distribution out there. Y is the data point.
2410970	2451890	82	A	0.99802	40:10	98	So we have on the left side of the equation, variational free energy is a function of Q and Y. On the right side, we have three equal signs and these are three values, three ways to phrase this one function. In the bottom here, Yaakov has shown how this energy minus entropy can result. In the second line, complexity minus accuracy, and in the third line, divergence minus evidence. So that was like one really interesting thing, is it's not like this is how it is and this is a transformation and then this is the transformation.
2452390	2500114	83	A	0.94639	40:52	110	Even though in a sense that was also true, it is also probably helpful to think about this energy minus entropy formalism for what it is, which is the closest to a physics framing of free energy. And then think about these two more statistical ontology ways of framing it, complexity minus accuracy, which is like very commonly brought up in the context of model fitting and divergence minus evidence also. And yeah, great. So Blue, if that sounds like a very helpful norm in the description, we'll try to have like a description of the equation. The first row says this, this people can type it however they want.
2500152	2548930	84	A	0.94	41:40	99	And then of course, we can replace terms that are in the ontology with the special at sign. And that will facilitate finding equations that mention those terms and it will facilitate translating these equations and also the descriptions into different languages, computer languages and human languages. So then we can work on it in this ontological space and then make sure that it's accessible to different languages. For example, then we thought about this example of like a ball and its location in a bowl. So there's a true location of where it is in the bowl X.
2549080	2589070	85	A	0.99	42:29	94	And then there's an observation of where we're observing the ball to be. And this also speaks to the quantum to classical handoff. If the bowl is a swimming pool and the ball is a bowling ball, after enough time, it's going to be at the bottom and not moving. If the bowl is like a molecular well and the ball is like an electron or like one atom, then repeated measurement is going to be entirely different. And as the ball in the bowl become more massive, it approaches like a classical limit.
2590870	2634030	86	A	0.99853	43:10	102	Little hints at the continuity between classical statistical and quantum and thermophysics. But we thought about this ball being in the bowl. So we looked at two different cases, which is when the ball is being observed in the bottom of the bowl, it's like, given the generative model of the shape of the bowl and gravity, which is like a potential energy function, observing the ball at the center of the bowl is, like, strictly the most likely thing that could have happened. And then observing it up on a side is like a less likely observation. Eric and then blue.
2639570	2658594	87	G	0.95882	43:59	52	Yeah. So you mentioned that F is a function. And as they put it, it's a function of a function, which is a functional. So the way I think about this is that the function that it's a function of is the Q. So the Q is a distribution over your beliefs.
2658722	2689406	88	G	0.99788	44:18	80	So I think of that as being a function that you're trying to optimize. You're trying to say, well, how do I adjust my internal belief state the Q. And that's what I'm optimizing in this equation. And the functional says that's what I'm trying to optimize is that function and distribution. And then it breaks down into the two parts, which is your generative Model P, which says well, P says for any there's the joint probability of X.
2689588	2731200	89	G	0.71	44:49	105	X is the internal state variable that you have a distribution over that's Q. And so how do your Observables and your internal states go together? And then you have the entropy term, which is well, you want to have maximum uncertainty so that if you're not constrained by your observations, you want to be as agnostic as possible about what the possible values are of your internal states or make that queue as flat as possible. As flat as possible under the constraints of the observations going through your generative Model P. So I guess that's the way I talk through this first line.
2732130	2744420	90	A	0.99995	45:32	29	Awesome. Thank you, eric blue and then Brock. So, Eric, that was super helpful. I've been since yesterday trying to figure out what exactly is meant by Q. Here.
2744790	2773050	91	D	0.92	45:44	60	I get later on we're going to talk about Q as representing beliefs. But as it's given, as it's laid out in chapter two, they don't actually define Q at all. So I am having a hard time up here. They describe it right before they get into that box. They describe Q in Section 2.6 as an approximate posterior.
2773390	2797466	92	D	0.69441	46:13	52	So approximate posterior of what? And should we denote Q as the function of beliefs here? Even though it's like they're skipping ahead and looping back at the same time? It seems like, or feels like to. Me, q is the variational distribution where the form of the posterior has been chosen.
2797658	2880346	93	A	0.99988	46:37	203	So exact bays using matrix multiplication, basically, or sampling based approaches to approximate Bayesian computation, like Monte Carlo, Markov chain, those try to recapitulate the actual form of P. So if P is truly bimodal, then exact Bayes or sampling based approaches would try to reconstruct that distribution. In contrast, the variational approach gains tractability because you're choosing a posterior, approximate posterior, a Q of a form that you know is going to have a tractable optimization scheme and there's message passing algorithms that can do it computationally. So if you choose Q to be a gaussian, then depending on how you parameterize it, it's either going to be seeking the mode and go to the hump that's bigger and center around that with a variance, or it'll just spread out a lot and go over and try to cover as much probability density as it can by covering both humps. Okay, so the variation of free energy function F as a function of the function representing the approximate posterior Q and the data Y is equal to the negative expectation of Q given the observations x times the natural log of the probability of the joint distribution of the data and observations.
2880458	2895700	94	D	0.79792	48:00	39	Is that the English translation of that equation? I think I got it finally, after. Like two days minus close, I would. Say one thing I would say slightly different. It's the expectation over Q, not expectation of Q.
2897830	2906120	95	A	0.78567	48:17	18	We actually talked about that a little bit. Like here we had negative expectation over Q and yes.
2908330	2931040	96	A	0.74139	48:28	51	Okay, blue then. Brock yeah, sorry, the ontology terms don't match the terms that are given in the book. And I put in a request in the questions here. If we can append the ontology because they use data is the same as observations. Those are different words, but they're similar.
2932930	2963470	97	D	0.92895	48:52	85	Yeah, there's a lot of synonyms or synonymous use, and so I would hate to step on them. But also the terms aren't in the ontology at all. So maybe we should update the ontology to reflect the terms. We will absolutely add terms into the supplemental or eventually into the core terms if that's required. But just leave a comment or email activeinference at gmail to add terms to the ontology if there's a term that you want to tag that's not being tagged.
2963650	2964410	98	A	0.64298	49:23	1	Frock.
2968190	2983360	99	C	0.56	49:28	31	I feel like you may have indirectly answered this just now, but in the math discussion yesterday, we were talking about specifically about the Q, the distribution of beliefs over there.
2986290	3016780	100	C	0.99995	49:46	47	If X is this uncertainty term, this hidden state, like, what what value could it possibly have? Where is it coming from? Or is that so Q? Is this property of distribution of beliefs? Is X the belief value and that's being generated in the previous step?
3019230	3049986	101	C	0.5	50:19	75	I think we in the Bowl Marble thing. Like my question was, or I was just pointing out, I guess that the hidden state is changing however it wants, perhaps below our threshold of observation. That's not reflected in the equation for obvious reasons, but then maybe it crosses a threshold and then we update or whatever. But where is that X coming from if it's a hidden state? Do you see what I'm saying?
3050008	3065560	102	C	0.46478	50:50	47	Is kind of an ontological problem there. I'm trying to solve it's like it's a hidden state. How can have a value or be a variable if it's hidden? Yes, Eric, I'll take a stab at that. So, as shown in the pictures, there's two hidden states.
3066190	3087470	103	G	0.99994	51:06	56	There's a hidden state of the real world, and then there's a hidden state of your generative model. And the generative model is whatever the model is. And that's however the model was built. So once you have the parameters X, then that's what you're working with until you change your model. That was my yes.
3087620	3124410	104	A	0.97	51:27	93	And over evolutionary or developmental times, you get swept off the table if there isn't adequacy, at least. But in a simulation environment, you could make the X and the X star to be anything but. The hidden state is as modeled by the generative model of the cognitive entity. So in the cognitive model of the entity, in the bowl example, they're modeling an unobservable, which is the location of the ball, and they're modeling an observable, which is the observation of location. So both of those are in the generative model.
3124560	3166666	105	A	1.0	52:04	85	And then the generative process would be like there's somebody with a magnet who's moving the ball around or something, or it could be anything. We're going to have five more minutes before we close this session. So what does anyone see in 2.4? What is free energy minimization doing? And what does it mean that variational free energy is an upper bound on the negative log evidence, just one quick qualitative read is that this is what we would actually like to be minimizing.
3166778	3197530	106	A	0.94631	52:46	61	This is the floor we truly want to reach would be unsurprised about observations. However, that is intractable because we don't have access to the form or the parameterization of the true generative process. What is attractable approximation? Approximate Bayesian computation is variational Bayesian inference. So here's f q of y q and y and then this is a KL divergence.
3198910	3245098	107	A	1.0	53:18	104	One vertical pipe means conditioned on like X conditioned on Y x given Y. Here probability of a hidden state being the case given a data or the other flipping, which would be the probability of given data point given a hidden state. Two vertical lines is in divergence notation. And that's the divergence between this and that between Q of X and between P of X given Y. So that reducing this divergence, which has very nice properties in terms of its implementation, is bringing us to lower our upper bound on what we really want to be minimizing in a tractable way.
3245184	3281250	108	A	0.92069	54:05	89	So that's one aspect on free energy minimization. And then here is reframing the two ways that free energy, variational free energy can be minimized through perception, the updating of beliefs. And we'll talk more about the continuity between perception and learning. Like if one observes the ball moving across the visual field, is that perception or is it parameter learning updating the location of the ball? That depends on the timescale and such or action can be taken so that the expected observations are changed to maximize evidence.
3282170	3298150	109	A	0.93	54:42	25	And then in the last minutes, Ali asked, can a hidden state be an unquantifiable quality, like a qualia quality or like an unquantifiable quantity?
3303980	3327570	110	E	0.98654	55:03	42	Well, of course most qualities can be parameterized, but well, perhaps we can think of a hidden state as a pure quality that cannot be fundamentally unquantifiable and we cannot parameterize it. I mean, can we think of such a hidden state?
3332340	3356712	111	C	0.83271	55:32	46	Brock, I was just going to say probably the quantifiable way to state that question is are there intractable hidden states? Which the answer to that is like, obviously yes. Can we get some estimate on it? Yes. But then is that commensurate with the idea?
3356846	3390656	112	C	0.97	55:56	89	And then does that mean it's a quality and not a quantity? I don't know. And also to the earlier discussion about the dimensionality of the generative model and the generative process. The unquantifiable part could be like the baby's happiness, but then we're able to still have an inference on the happiness as a parameter x, the underlying state that's giving rise to the different sounds without necessarily knowing the distributional form of happiness. But we have to have a distributional form for the variational approximation of happiness.
3390768	3419950	113	F	0.99486	56:30	101	Joe, I was just going to say, I think that this qualitative versus quantitative distinction is interesting. If you're thinking about like a light source, it's a source of electrons. Well, you could count the number of electrons, but whether or not there is a light source, there a source of electrons in this framework I'm proposing, you're not counting that, you're just saying there is a light source or some other dimensions. That's the thing we've been calling dimensions. Yes, you can count the number of dimensions, but given that they're all different, they're not really relatable to each other.
3421140	3462332	114	A	0.91767	57:01	79	Thanks. Yes, very interesting. So in our final seconds, we'll just point towards 2.6, which is expected free energy g and its prospective, which is going to enable inference conditioned on action x hidden states, the world conditioned on policy selection. And that is what is going to allow comparison of different policies, which are sequences of actions over a given time horizon. So minimizing the divergence between two things minus some things, reframing it as a few things.
3462466	3520124	115	A	0.9177	57:42	154	So we didn't go as much into 2.6 as we did into 2.5 because 2.5 is an important precursor and simpler cousin of 2.6, but it's like super important and especially to those who are here and those who are not here. We would really love over multiple cohorts when everybody will hopefully be able to join and rejoin as participant, as facilitator, to be able to annotate all the equations with what they mean, because what is there to be said about expected free energy without some understanding of what this is actually discussing? What variables go in, what is it doing, how are some of them being related? So we want to learn this and we can do it collaboratively. If people just pick and choose affordances, they see annotate some things and then they can highlight it and say I'm not sure about this, but I just wanted to add it.
3520162	3528530	116	A	0.99852	58:40	26	Can somebody improve it? And so on. Like we're all there to help each other learn and improve our epistemic. Niche 2.6 is expected. Free energy.
3528900	3557032	117	A	0.82577	58:48	66	There's further discussion on Expected free energy, showing how it's composed of these five sections, and that by leaving some out you get different special cases that are quite important. For example, leaving out this, you get this leaving out just one, you get 2345 and so on. Figure two six. And then there's a summary of the low road to active inference. That's chapter two.
3557166	3586420	118	A	0.99992	59:17	80	So this concludes chapter two and our discussion in cohort one. In the coming two weeks we're going to be discussing chapter three, the High Road to Active Inference. It's going to take another tack and we will go through it in the coming two weeks and be addressing people's questions. But hopefully we can continue answering and addressing just wherever we see fit. No one's going to do it all, but we do need everybody to do some hopefully.
3588040	3609980	119	A	0.99866	59:48	64	We're going to now close recording. We'll then take a 1 minute break and then in this room we're going to continue with Dot tools. If you want to continue discussing the textbook or anything else, then head up to a room up and to the left. But in this room in 1 minute we're going to continue with Dot tools. So thanks everybody.
3610050	3610990	120	A	0.99942	1:00:10	3	See you soon.
