1
00:00:01,280 --> 00:00:05,279
hello everyone it's june 23 2022

2
00:00:05,279 --> 00:00:06,640
and we are

3
00:00:06,640 --> 00:00:08,639
in week eight

4
00:00:08,639 --> 00:00:12,719
of the textbook group cohort one

5
00:00:12,719 --> 00:00:13,679
we're

6
00:00:13,679 --> 00:00:15,759
starting chapter

7
00:00:15,759 --> 00:00:18,000
and we'll be continuing the chapter 4

8
00:00:18,000 --> 00:00:20,480
next week

9
00:00:20,480 --> 00:00:22,320
we're more than halfway

10
00:00:22,320 --> 00:00:23,519
done

11
00:00:23,519 --> 00:00:25,119
with the time

12
00:00:25,119 --> 00:00:26,400
and with the

13
00:00:26,400 --> 00:00:28,080
chapters that we're going through in the

14
00:00:28,080 --> 00:00:30,560
first half of the book

15
00:00:30,560 --> 00:00:32,079
so let's go to

16
00:00:32,079 --> 00:00:34,079
chapter four and just raise your hand

17
00:00:34,079 --> 00:00:36,239
and gather or write in the chat if you

18
00:00:36,239 --> 00:00:39,600
have anything that you want to address

19
00:00:39,600 --> 00:00:41,360
so the

20
00:00:41,360 --> 00:00:43,600
i'm going first to the math overviews

21
00:00:43,600 --> 00:00:45,920
page where i've written some overviews

22
00:00:45,920 --> 00:00:48,399
for the previous chapters

23
00:00:48,399 --> 00:00:51,520
of varying levels of completeness but

24
00:00:51,520 --> 00:00:52,399
this

25
00:00:52,399 --> 00:00:54,960
is very important as we set off into

26
00:00:54,960 --> 00:00:56,559
chapter 4.

27
00:00:56,559 --> 00:00:58,879
so on page 64.

28
00:00:58,879 --> 00:01:00,399
this chapter is more technical than

29
00:01:00,399 --> 00:01:03,120
chapters one through three appealing to

30
00:01:03,120 --> 00:01:04,879
linear algebra differentiation and a

31
00:01:04,879 --> 00:01:08,000
taylor series expansion

32
00:01:08,400 --> 00:01:10,159
those readers interested in the details

33
00:01:10,159 --> 00:01:13,040
may turn to the appendices appendages

34
00:01:13,040 --> 00:01:14,720
those who do not want to delve into the

35
00:01:14,720 --> 00:01:16,720
theoretical underpinnings may skip this

36
00:01:16,720 --> 00:01:19,119
chapter

37
00:01:19,200 --> 00:01:20,159
so

38
00:01:20,159 --> 00:01:23,680
keep that in mind as we continue on

39
00:01:23,680 --> 00:01:25,439
and

40
00:01:25,439 --> 00:01:28,240
it can be an area of discussion and

41
00:01:28,240 --> 00:01:31,119
learning and such

42
00:01:31,119 --> 00:01:34,159
but let's approach these

43
00:01:34,159 --> 00:01:37,280
themes and formalisms

44
00:01:37,280 --> 00:01:38,840
with the

45
00:01:38,840 --> 00:01:41,759
authors forewarning

46
00:01:41,759 --> 00:01:43,600
that this is

47
00:01:43,600 --> 00:01:45,360
something we can

48
00:01:45,360 --> 00:01:48,159
look for more detail in the appendixes

49
00:01:48,159 --> 00:01:49,520
as well as

50
00:01:49,520 --> 00:01:52,079
skip this chapter

51
00:01:52,079 --> 00:01:54,399
even if we

52
00:01:54,399 --> 00:01:57,200
might disagree of course

53
00:01:57,200 --> 00:01:58,320
okay

54
00:01:58,320 --> 00:01:59,520
any other

55
00:01:59,520 --> 00:02:02,719
overall comments on chapter four

56
00:02:02,719 --> 00:02:04,560
just for whomever

57
00:02:04,560 --> 00:02:07,600
read it even a part of it what was there

58
00:02:07,600 --> 00:02:10,479
overall perspective on chapter four what

59
00:02:10,479 --> 00:02:12,959
was it trying to do

60
00:02:12,959 --> 00:02:16,920
what approach did they take

61
00:02:32,800 --> 00:02:36,920
yeah ali and then anyone else

62
00:02:38,000 --> 00:02:40,319
i think if we take uh the materials in

63
00:02:40,319 --> 00:02:44,400
chapters one two through three as uh the

64
00:02:44,400 --> 00:02:46,879
foundational materials on which

65
00:02:46,879 --> 00:02:50,959
uh the active inference theory uh

66
00:02:50,959 --> 00:02:53,360
is supposed to build uh well this

67
00:02:53,360 --> 00:02:56,560
chapter four is uh one of the first

68
00:02:56,560 --> 00:02:58,159
steps uh

69
00:02:58,159 --> 00:03:01,920
toward uh building the actual uh theory

70
00:03:01,920 --> 00:03:03,599
and uh

71
00:03:03,599 --> 00:03:05,920
i mean going beyond just the basics of

72
00:03:05,920 --> 00:03:09,280
foundational materials so using the tool

73
00:03:09,280 --> 00:03:12,159
the tools and foundations uh established

74
00:03:12,159 --> 00:03:14,159
in previous chapters

75
00:03:14,159 --> 00:03:15,920
we are now

76
00:03:15,920 --> 00:03:19,280
uh perhaps ready to tackle the problem

77
00:03:19,280 --> 00:03:20,159
of

78
00:03:20,159 --> 00:03:22,720
actually constructing the generative

79
00:03:22,720 --> 00:03:27,440
models in uh two different

80
00:03:27,440 --> 00:03:29,840
in two different situations as discrete

81
00:03:29,840 --> 00:03:31,200
time

82
00:03:31,200 --> 00:03:35,599
models and as continuous one

83
00:03:35,840 --> 00:03:37,519
awesome thanks

84
00:03:37,519 --> 00:03:38,480
yes

85
00:03:38,480 --> 00:03:40,480
in the chapters

86
00:03:40,480 --> 00:03:42,640
page

87
00:03:42,640 --> 00:03:45,200
we can recall back to

88
00:03:45,200 --> 00:03:47,360
chapter 1

89
00:03:47,360 --> 00:03:49,280
that just laid out the structure of the

90
00:03:49,280 --> 00:03:50,480
book

91
00:03:50,480 --> 00:03:52,400
chapter 2 provided the low road to

92
00:03:52,400 --> 00:03:53,760
active inference

93
00:03:53,760 --> 00:03:56,799
which began with bayesian inference

94
00:03:56,799 --> 00:03:58,840
and talked about a few

95
00:03:58,840 --> 00:04:03,040
other prerequisite or preliminary themes

96
00:04:03,040 --> 00:04:05,439
including introducing

97
00:04:05,439 --> 00:04:08,080
variational and expected free energy

98
00:04:08,080 --> 00:04:08,879
as

99
00:04:08,879 --> 00:04:10,319
imperatives

100
00:04:10,319 --> 00:04:12,239
in the sense that they're

101
00:04:12,239 --> 00:04:16,160
able to be bounding surprise

102
00:04:16,160 --> 00:04:18,000
chapter three introduced the high road

103
00:04:18,000 --> 00:04:20,000
to active inference which was starting

104
00:04:20,000 --> 00:04:21,680
not from the

105
00:04:21,680 --> 00:04:24,639
mechanistic kind of nucleus of the bayes

106
00:04:24,639 --> 00:04:27,520
equation but rather from the imperative

107
00:04:27,520 --> 00:04:30,720
for survival and persistence

108
00:04:30,720 --> 00:04:33,759
also introducing in a first pass the

109
00:04:33,759 --> 00:04:35,600
markov blanket

110
00:04:35,600 --> 00:04:38,800
concept and partitioning

111
00:04:41,120 --> 00:04:43,680
chapter four is indeed when we start to

112
00:04:43,680 --> 00:04:44,960
get into

113
00:04:44,960 --> 00:04:47,120
many details that were not

114
00:04:47,120 --> 00:04:49,040
covered in

115
00:04:49,040 --> 00:04:51,120
earlier sections

116
00:04:51,120 --> 00:04:53,520
it's gonna

117
00:04:53,520 --> 00:04:56,479
first begin by bringing us

118
00:04:56,479 --> 00:04:58,160
closer to this connection between

119
00:04:58,160 --> 00:05:00,080
bayesian inference and the free energy

120
00:05:00,080 --> 00:05:02,000
evaluation

121
00:05:02,000 --> 00:05:04,000
and then the central idea of a

122
00:05:04,000 --> 00:05:05,360
generative model

123
00:05:05,360 --> 00:05:08,240
is discussed

124
00:05:08,240 --> 00:05:10,560
that is going to be described in

125
00:05:10,560 --> 00:05:12,160
discrete time

126
00:05:12,160 --> 00:05:16,000
specifically using the pomdp formalism

127
00:05:16,000 --> 00:05:17,840
partially observable markov decision

128
00:05:17,840 --> 00:05:19,120
process

129
00:05:19,120 --> 00:05:20,240
and then

130
00:05:20,240 --> 00:05:23,840
as well as in continuous time

131
00:05:23,840 --> 00:05:26,639
then there's going to be some

132
00:05:26,639 --> 00:05:28,479
very interesting figures and formalisms

133
00:05:28,479 --> 00:05:30,960
and discussions on

134
00:05:30,960 --> 00:05:32,479
what generative models underlie

135
00:05:32,479 --> 00:05:33,919
predictive coding

136
00:05:33,919 --> 00:05:36,479
and motor reflexes which is moving us

137
00:05:36,479 --> 00:05:38,880
towards chapter five

138
00:05:38,880 --> 00:05:41,199
which is going to have some empirical

139
00:05:41,199 --> 00:05:43,600
work mainly cited out

140
00:05:43,600 --> 00:05:45,759
and some discussion on the plausible

141
00:05:45,759 --> 00:05:48,160
neurobiologies

142
00:05:48,160 --> 00:05:50,720
that can be implementing or modeled as

143
00:05:50,720 --> 00:05:53,360
implementing or modeled with

144
00:05:53,360 --> 00:05:55,600
the kinds of generative models of which

145
00:05:55,600 --> 00:05:56,720
have been

146
00:05:56,720 --> 00:05:59,199
prepared for in chapters two and three

147
00:05:59,199 --> 00:06:00,720
motivated in chapters two and three

148
00:06:00,720 --> 00:06:01,680
really

149
00:06:01,680 --> 00:06:03,600
and then described

150
00:06:03,600 --> 00:06:07,840
in their essence in chapter four

151
00:06:08,479 --> 00:06:10,800
also just a reminder that

152
00:06:10,800 --> 00:06:13,440
in the math group activities but we're

153
00:06:13,440 --> 00:06:16,080
all in the math group we're all in this

154
00:06:16,080 --> 00:06:18,479
learning journey together we've been

155
00:06:18,479 --> 00:06:20,479
striving to make the natural language

156
00:06:20,479 --> 00:06:21,600
descriptions

157
00:06:21,600 --> 00:06:23,680
for equations

158
00:06:23,680 --> 00:06:24,880
so

159
00:06:24,880 --> 00:06:26,880
that would be extremely extremely

160
00:06:26,880 --> 00:06:28,000
helpful

161
00:06:28,000 --> 00:06:30,400
every annotation that people can make

162
00:06:30,400 --> 00:06:33,360
is helpful people shouldn't feel abashed

163
00:06:33,360 --> 00:06:34,720
or ashamed to make any kind of

164
00:06:34,720 --> 00:06:37,880
contribution it can always be

165
00:06:37,880 --> 00:06:41,759
re-ordered or edited by others but

166
00:06:41,759 --> 00:06:44,000
this is how we're going to create those

167
00:06:44,000 --> 00:06:46,160
like natural language descriptions of

168
00:06:46,160 --> 00:06:48,400
equations and ask questions about them

169
00:06:48,400 --> 00:06:49,520
even just

170
00:06:49,520 --> 00:06:51,280
copying and pasting what does this mean

171
00:06:51,280 --> 00:06:53,280
what does this mean they're all

172
00:06:53,280 --> 00:06:55,520
helpful contributions

173
00:06:55,520 --> 00:06:56,800
because this is

174
00:06:56,800 --> 00:06:58,000
very

175
00:06:58,000 --> 00:06:59,280
technical

176
00:06:59,280 --> 00:07:00,880
and

177
00:07:00,880 --> 00:07:03,440
it's not immediately apparent how

178
00:07:03,440 --> 00:07:04,880
for example

179
00:07:04,880 --> 00:07:07,360
these copious equations in chapter 4

180
00:07:07,360 --> 00:07:08,639
relate to some of the broader

181
00:07:08,639 --> 00:07:11,599
discussions from the earlier chapters

182
00:07:11,599 --> 00:07:15,159
but look at that

183
00:07:16,560 --> 00:07:18,319
okay

184
00:07:18,319 --> 00:07:19,520
if anyone

185
00:07:19,520 --> 00:07:20,800
has

186
00:07:20,800 --> 00:07:23,039
more questions to add

187
00:07:23,039 --> 00:07:24,560
they can do that or if they want to

188
00:07:24,560 --> 00:07:28,319
upvote questions feel free to do that

189
00:07:28,319 --> 00:07:30,240
it's motivating for other people when

190
00:07:30,240 --> 00:07:31,840
they see that their questions are like

191
00:07:31,840 --> 00:07:33,199
being improved or other people are

192
00:07:33,199 --> 00:07:35,199
paying attention to their questions

193
00:07:35,199 --> 00:07:37,120
so that's always something free and

194
00:07:37,120 --> 00:07:40,560
helpful that people can engage in

195
00:07:42,840 --> 00:07:47,840
um are beliefs policy or state

196
00:07:47,840 --> 00:07:50,000
if the person who asked it is here they

197
00:07:50,000 --> 00:07:53,840
can feel free to address it

198
00:07:54,160 --> 00:07:57,280
because it's a very short

199
00:07:57,280 --> 00:07:58,800
partially formed

200
00:07:58,800 --> 00:08:00,879
question

201
00:08:00,879 --> 00:08:02,479
i also wasn't sure whether this was

202
00:08:02,479 --> 00:08:05,599
using the cad cad ontology

203
00:08:05,599 --> 00:08:07,280
which uses policy and state in a

204
00:08:07,280 --> 00:08:09,520
slightly different way

205
00:08:09,520 --> 00:08:10,400
but

206
00:08:10,400 --> 00:08:12,960
beliefs in a general sense

207
00:08:12,960 --> 00:08:15,120
coming from the bayesian ontology

208
00:08:15,120 --> 00:08:17,759
are referring to any

209
00:08:17,759 --> 00:08:20,479
distributional expression

210
00:08:20,479 --> 00:08:22,720
bayesian beliefs

211
00:08:22,720 --> 00:08:24,800
those are

212
00:08:24,800 --> 00:08:27,360
states

213
00:08:27,360 --> 00:08:30,879
policies in the actin phontology

214
00:08:30,879 --> 00:08:33,120
which you can just mouse over and find

215
00:08:33,120 --> 00:08:34,000
out

216
00:08:34,000 --> 00:08:37,200
it's a sequence of actions

217
00:08:37,200 --> 00:08:39,679
and policies are constructed or

218
00:08:39,679 --> 00:08:41,599
enumerated

219
00:08:41,599 --> 00:08:42,399
by

220
00:08:42,399 --> 00:08:45,599
the affordances the e

221
00:08:45,760 --> 00:08:46,800
vector

222
00:08:46,800 --> 00:08:49,120
that the generative model has

223
00:08:49,120 --> 00:08:51,360
over a given time horizon

224
00:08:51,360 --> 00:08:54,240
so if it's able to go left to right over

225
00:08:54,240 --> 00:08:56,560
two time steps all the policies are left

226
00:08:56,560 --> 00:09:00,240
left left right right right right left

227
00:09:00,240 --> 00:09:02,480
um

228
00:09:02,880 --> 00:09:04,320
does anyone else just want to add

229
00:09:04,320 --> 00:09:06,080
anything else to this short

230
00:09:06,080 --> 00:09:09,080
question

231
00:09:11,680 --> 00:09:13,760
otherwise it's a fine clarifying

232
00:09:13,760 --> 00:09:15,920
question

233
00:09:15,920 --> 00:09:18,920
okay

234
00:09:25,200 --> 00:09:27,360
in the discussion of active inference in

235
00:09:27,360 --> 00:09:28,959
pomdps

236
00:09:28,959 --> 00:09:30,320
the authors write

237
00:09:30,320 --> 00:09:34,000
to update beliefs about policies

238
00:09:34,000 --> 00:09:36,880
we find the posterior that minimizes the

239
00:09:36,880 --> 00:09:38,480
free energy

240
00:09:38,480 --> 00:09:40,720
does the posterior at time t

241
00:09:40,720 --> 00:09:44,800
become a prior at time t plus one

242
00:09:45,040 --> 00:09:48,760
what does anyone think

243
00:10:01,760 --> 00:10:03,440
i guess it depends on the

244
00:10:03,440 --> 00:10:05,040
um

245
00:10:05,040 --> 00:10:07,360
specific posterior and prior because

246
00:10:07,360 --> 00:10:08,800
that can

247
00:10:08,800 --> 00:10:11,519
mean multiple things but in the context

248
00:10:11,519 --> 00:10:14,640
of figure 4.3

249
00:10:15,040 --> 00:10:18,320
i'd say it does

250
00:10:18,320 --> 00:10:20,320
because we are updating our prior which

251
00:10:20,320 --> 00:10:22,000
becomes at the end of a time step

252
00:10:22,000 --> 00:10:24,320
becomes the posterior probability

253
00:10:24,320 --> 00:10:28,079
which then is fed back as the prior

254
00:10:28,079 --> 00:10:31,040
thanks totally agree with that uh there

255
00:10:31,040 --> 00:10:33,680
needs to be an initiating prior

256
00:10:33,680 --> 00:10:34,560
d

257
00:10:34,560 --> 00:10:37,120
which is shown with a three here

258
00:10:37,120 --> 00:10:38,880
in the discrete time

259
00:10:38,880 --> 00:10:42,399
and that is like the initial prior

260
00:10:42,399 --> 00:10:43,760
and then

261
00:10:43,760 --> 00:10:46,160
prior and posterior are referring to

262
00:10:46,160 --> 00:10:48,959
what incoming data

263
00:10:48,959 --> 00:10:51,360
so after the data at

264
00:10:51,360 --> 00:10:53,360
point one comes in

265
00:10:53,360 --> 00:10:55,680
the updated posterior

266
00:10:55,680 --> 00:10:57,920
is now playing the functional role of

267
00:10:57,920 --> 00:11:00,079
the prior for the next data point coming

268
00:11:00,079 --> 00:11:02,239
in

269
00:11:06,959 --> 00:11:10,640
okay then here's sort of a related

270
00:11:11,600 --> 00:11:12,880
question

271
00:11:12,880 --> 00:11:15,839
well

272
00:11:17,920 --> 00:11:20,240
we've addressed this

273
00:11:20,240 --> 00:11:22,959
question in the narrow sense but

274
00:11:22,959 --> 00:11:24,160
it would be very

275
00:11:24,160 --> 00:11:26,320
helpful to look through

276
00:11:26,320 --> 00:11:28,560
the order in which different topics are

277
00:11:28,560 --> 00:11:30,320
addressed in chapter four

278
00:11:30,320 --> 00:11:31,360
because

279
00:11:31,360 --> 00:11:33,279
these are um

280
00:11:33,279 --> 00:11:34,640
some questions that are invoking things

281
00:11:34,640 --> 00:11:36,480
that are much later

282
00:11:36,480 --> 00:11:37,519
and

283
00:11:37,519 --> 00:11:39,460
we don't assume that people have um

284
00:11:39,460 --> 00:11:40,720
[Music]

285
00:11:40,720 --> 00:11:42,560
high or low comprehension of this

286
00:11:42,560 --> 00:11:44,640
chapter yet

287
00:11:44,640 --> 00:11:48,079
but many of these questions

288
00:11:48,320 --> 00:11:50,240
it's really important that we understand

289
00:11:50,240 --> 00:11:52,639
like why we're bringing them up so let's

290
00:11:52,639 --> 00:11:54,639
just walk through very quickly

291
00:11:54,639 --> 00:11:57,600
the chapter to see why they're bringing

292
00:11:57,600 --> 00:12:00,800
up things in a different order

293
00:12:00,800 --> 00:12:02,480
in terms of looking at the figures in

294
00:12:02,480 --> 00:12:04,959
formalism

295
00:12:04,959 --> 00:12:06,160
4.1

296
00:12:06,160 --> 00:12:09,600
is returning to bayes

297
00:12:09,839 --> 00:12:11,040
and

298
00:12:11,040 --> 00:12:12,959
uh i think this is a really nice

299
00:12:12,959 --> 00:12:14,560
representation

300
00:12:14,560 --> 00:12:16,720
here's the joint distribution of x and y

301
00:12:16,720 --> 00:12:19,360
the hidden states and the observables

302
00:12:19,360 --> 00:12:23,440
and it's like it gets split up

303
00:12:23,440 --> 00:12:25,519
into

304
00:12:25,519 --> 00:12:28,399
y condition.x and x

305
00:12:28,399 --> 00:12:29,839
so this is like the probability the

306
00:12:29,839 --> 00:12:31,680
joint distribution of the coin flip and

307
00:12:31,680 --> 00:12:33,360
the die

308
00:12:33,360 --> 00:12:35,519
is

309
00:12:35,519 --> 00:12:38,560
the distribution of the coin flip

310
00:12:38,560 --> 00:12:40,880
conditioned upon the die and the die

311
00:12:40,880 --> 00:12:41,920
itself

312
00:12:41,920 --> 00:12:43,680
so it's just separating out a joint

313
00:12:43,680 --> 00:12:45,200
distribution

314
00:12:45,200 --> 00:12:49,040
and that's the heart of bayes theorem

315
00:12:50,480 --> 00:12:52,800
this is a key move to move an

316
00:12:52,800 --> 00:12:54,560
integration problem

317
00:12:54,560 --> 00:12:56,480
a sum in the discrete case or an

318
00:12:56,480 --> 00:12:58,160
integration problem in the continuous

319
00:12:58,160 --> 00:13:00,959
case into an optimization problem

320
00:13:00,959 --> 00:13:03,440
which permits incremental

321
00:13:03,440 --> 00:13:06,720
solutions of improving quality unlike an

322
00:13:06,720 --> 00:13:08,160
integration problem

323
00:13:08,160 --> 00:13:09,120
which

324
00:13:09,120 --> 00:13:10,800
you might just be tallying up numbers

325
00:13:10,800 --> 00:13:14,240
and not necessarily moving closer

326
00:13:14,240 --> 00:13:16,000
to knowing when you're done with that

327
00:13:16,000 --> 00:13:18,480
integral

328
00:13:19,040 --> 00:13:22,880
they introduced jensen's uh inequality

329
00:13:22,880 --> 00:13:24,880
which is the log of the average is

330
00:13:24,880 --> 00:13:26,720
always greater or equal to the average

331
00:13:26,720 --> 00:13:27,920
of a log

332
00:13:27,920 --> 00:13:30,800
and that's true for any

333
00:13:30,800 --> 00:13:32,959
shape that has this kind of a

334
00:13:32,959 --> 00:13:35,279
curve anything where there's a

335
00:13:35,279 --> 00:13:38,240
decreasing curve

336
00:13:38,240 --> 00:13:41,440
and here's where that gets applied

337
00:13:41,440 --> 00:13:43,040
above

338
00:13:43,040 --> 00:13:44,160
we had

339
00:13:44,160 --> 00:13:45,519
this

340
00:13:45,519 --> 00:13:47,680
taking this joint distribution

341
00:13:47,680 --> 00:13:50,160
multi multiplying it by an arbitrary

342
00:13:50,160 --> 00:13:52,480
distribution divided by itself

343
00:13:52,480 --> 00:13:54,639
so that's one

344
00:13:54,639 --> 00:13:56,800
whatever q is

345
00:13:56,800 --> 00:14:00,560
later q will play a more specific role

346
00:14:00,560 --> 00:14:01,519
and then

347
00:14:01,519 --> 00:14:02,399
here

348
00:14:02,399 --> 00:14:05,519
the expectation is inside the log

349
00:14:05,519 --> 00:14:08,399
here the expectation is over the log

350
00:14:08,399 --> 00:14:10,560
itself

351
00:14:10,560 --> 00:14:11,519
so

352
00:14:11,519 --> 00:14:14,079
the one that we'd really want

353
00:14:14,079 --> 00:14:14,959
would be

354
00:14:14,959 --> 00:14:18,240
like the joint distribution

355
00:14:18,240 --> 00:14:19,040
um

356
00:14:19,040 --> 00:14:20,959
would be like the expectation

357
00:14:20,959 --> 00:14:24,160
of the joint distribution

358
00:14:24,320 --> 00:14:26,240
divided by some

359
00:14:26,240 --> 00:14:28,800
function q

360
00:14:28,880 --> 00:14:30,560
jensen's inequality

361
00:14:30,560 --> 00:14:33,199
allows us to

362
00:14:33,199 --> 00:14:35,760
make this

363
00:14:35,760 --> 00:14:37,120
uh instead of

364
00:14:37,120 --> 00:14:39,199
an equal sign make it a greater than an

365
00:14:39,199 --> 00:14:40,560
equal sign

366
00:14:40,560 --> 00:14:44,160
and then pull the expectation out

367
00:14:44,160 --> 00:14:46,079
and utilize that

368
00:14:46,079 --> 00:14:48,720
as the negative free energy

369
00:14:48,720 --> 00:14:51,440
which is going to be bounding us

370
00:14:51,440 --> 00:14:54,639
on this one that we would truly want

371
00:14:54,639 --> 00:14:56,880
but going about it

372
00:14:56,880 --> 00:14:58,880
by using this

373
00:14:58,880 --> 00:15:00,480
um

374
00:15:00,480 --> 00:15:03,839
nice feature of the natural log

375
00:15:06,560 --> 00:15:10,320
base theorem in the logarithmic form

376
00:15:10,320 --> 00:15:12,079
anyone can totally raise their hand and

377
00:15:12,079 --> 00:15:12,959
add

378
00:15:12,959 --> 00:15:15,439
details

379
00:15:21,680 --> 00:15:24,320
allows rearrangement

380
00:15:24,320 --> 00:15:26,959
into this form

381
00:15:26,959 --> 00:15:29,440
which is already recalling

382
00:15:29,440 --> 00:15:31,680
the free energy that we saw from

383
00:15:31,680 --> 00:15:32,959
variational free energy from from

384
00:15:32,959 --> 00:15:35,759
equation 2.5

385
00:15:35,759 --> 00:15:37,839
more details to be filled in and that's

386
00:15:37,839 --> 00:15:39,759
why we want to be annotating these

387
00:15:39,759 --> 00:15:42,639
equations and so on

388
00:15:44,639 --> 00:15:46,480
generative models is the name of this

389
00:15:46,480 --> 00:15:48,320
chapter

390
00:15:48,320 --> 00:15:49,839
to calculate free energy we need three

391
00:15:49,839 --> 00:15:51,839
things data variational distribution

392
00:15:51,839 --> 00:15:54,320
family and a generative model which at

393
00:15:54,320 --> 00:15:56,880
minimum is composing of the prior and

394
00:15:56,880 --> 00:15:59,040
likelihood

395
00:15:59,040 --> 00:16:00,240
they're going to be describing two

396
00:16:00,240 --> 00:16:03,279
different kinds of generative models

397
00:16:03,279 --> 00:16:05,839
this is a really nice and intuitive

398
00:16:05,839 --> 00:16:07,360
graphic

399
00:16:07,360 --> 00:16:09,199
for those who might have

400
00:16:09,199 --> 00:16:11,839
different familiarity with statistical

401
00:16:11,839 --> 00:16:14,639
representations

402
00:16:16,320 --> 00:16:19,040
the circles are random variables

403
00:16:19,040 --> 00:16:20,480
and the squares are probability

404
00:16:20,480 --> 00:16:24,399
distributions describing relationships

405
00:16:24,560 --> 00:16:26,800
these are some

406
00:16:26,800 --> 00:16:28,720
bayes graphs

407
00:16:28,720 --> 00:16:30,639
that are simpler

408
00:16:30,639 --> 00:16:33,839
and less action-involved

409
00:16:33,839 --> 00:16:35,279
than

410
00:16:35,279 --> 00:16:37,120
this

411
00:16:37,120 --> 00:16:40,079
canonical octave representation where pi

412
00:16:40,079 --> 00:16:41,279
is policy

413
00:16:41,279 --> 00:16:42,399
and so

414
00:16:42,399 --> 00:16:46,079
uh yayakaburo um three is the b matrix

415
00:16:46,079 --> 00:16:47,839
yes it is

416
00:16:47,839 --> 00:16:49,040
there's like

417
00:16:49,040 --> 00:16:52,560
three these threes are the b matrix

418
00:16:52,560 --> 00:16:55,120
but this is the d

419
00:16:55,120 --> 00:16:57,440
letter

420
00:16:57,920 --> 00:16:58,800
so

421
00:16:58,800 --> 00:17:00,800
i i agree though

422
00:17:00,800 --> 00:17:02,639
um

423
00:17:02,639 --> 00:17:04,799
sorry which one is the d letter

424
00:17:04,799 --> 00:17:06,000
the first three

425
00:17:06,000 --> 00:17:08,240
yeah

426
00:17:08,240 --> 00:17:10,480
because they're playing similar roles

427
00:17:10,480 --> 00:17:12,319
but they're a little bit i mean or what

428
00:17:12,319 --> 00:17:14,319
do you think about that

429
00:17:14,319 --> 00:17:16,000
yeah i guess

430
00:17:16,000 --> 00:17:18,400
i mean i was thinking about it as this

431
00:17:18,400 --> 00:17:21,520
being just one snapshot of

432
00:17:21,520 --> 00:17:23,679
like an infinite um

433
00:17:23,679 --> 00:17:26,480
factor graph so

434
00:17:26,480 --> 00:17:29,440
i mean just the fact that it's um

435
00:17:29,440 --> 00:17:33,919
assigned the p of s tau plus one given s

436
00:17:33,919 --> 00:17:36,559
tau and pi

437
00:17:37,200 --> 00:17:40,880
uh i i understand what you mean by um by

438
00:17:40,880 --> 00:17:42,720
saying that it's kind of like it plays

439
00:17:42,720 --> 00:17:43,559
the

440
00:17:43,559 --> 00:17:47,639
role um

441
00:17:49,280 --> 00:17:50,720
yeah i'm not i'm not entirely sure

442
00:17:50,720 --> 00:17:52,960
though

443
00:17:53,360 --> 00:17:54,799
look we'll come back to this because

444
00:17:54,799 --> 00:17:56,640
there's actually a few other interesting

445
00:17:56,640 --> 00:17:57,760
notes

446
00:17:57,760 --> 00:17:58,720
um

447
00:17:58,720 --> 00:18:03,280
so this is kind of the simplest

448
00:18:03,280 --> 00:18:05,600
uh of the

449
00:18:05,600 --> 00:18:08,799
graphs that they describe

450
00:18:09,039 --> 00:18:10,960
this is like one variable influencing

451
00:18:10,960 --> 00:18:14,000
another variable

452
00:18:14,000 --> 00:18:15,679
this is like two

453
00:18:15,679 --> 00:18:20,320
factors z and x influencing y

454
00:18:20,320 --> 00:18:21,919
so

455
00:18:21,919 --> 00:18:23,360
two

456
00:18:23,360 --> 00:18:24,640
is like a

457
00:18:24,640 --> 00:18:26,240
little factory

458
00:18:26,240 --> 00:18:29,039
that outputs y conditioned upon the

459
00:18:29,039 --> 00:18:32,160
state of x and z

460
00:18:32,160 --> 00:18:33,280
so

461
00:18:33,280 --> 00:18:34,320
knowing

462
00:18:34,320 --> 00:18:36,080
this notation

463
00:18:36,080 --> 00:18:39,200
and how to read these directed

464
00:18:39,200 --> 00:18:41,360
graphs

465
00:18:41,360 --> 00:18:42,480
is

466
00:18:42,480 --> 00:18:44,480
relatively essential for interpreting

467
00:18:44,480 --> 00:18:47,120
more complex graphs that involve actions

468
00:18:47,120 --> 00:18:49,760
and so on

469
00:18:49,840 --> 00:18:51,360
here's x

470
00:18:51,360 --> 00:18:54,720
as like a upstream hidden cause

471
00:18:54,720 --> 00:18:57,200
that influences two downstream variables

472
00:18:57,200 --> 00:18:59,919
that don't influence each other

473
00:18:59,919 --> 00:19:01,520
and here is like

474
00:19:01,520 --> 00:19:04,720
a hierarchical model where v influences

475
00:19:04,720 --> 00:19:08,160
x and x influences y

476
00:19:08,160 --> 00:19:09,600
does anyone have like thoughts or

477
00:19:09,600 --> 00:19:12,559
questions about this

478
00:19:21,679 --> 00:19:24,080
this is a graphical probabilistic model

479
00:19:24,080 --> 00:19:27,440
the variables are stochastic or they're

480
00:19:27,440 --> 00:19:29,520
statistical random variables

481
00:19:29,520 --> 00:19:32,000
and it's a graph it's consisting of

482
00:19:32,000 --> 00:19:35,400
nodes and edges

483
00:19:38,559 --> 00:19:41,120
4.3 is going to

484
00:19:41,120 --> 00:19:43,600
introduce these two basic forms of the

485
00:19:43,600 --> 00:19:46,000
generative model dynamic through time

486
00:19:46,000 --> 00:19:48,160
used in active

487
00:19:48,160 --> 00:19:52,440
in the factor graph form

488
00:19:54,080 --> 00:19:56,559
does anyone want to describe what they

489
00:19:56,559 --> 00:20:00,280
see in this figure

490
00:20:09,039 --> 00:20:13,120
the top is in the discrete time case

491
00:20:13,120 --> 00:20:14,159
s

492
00:20:14,159 --> 00:20:16,320
is the hidden state

493
00:20:16,320 --> 00:20:18,240
temperature of the room

494
00:20:18,240 --> 00:20:21,280
o are the observations the thermometer

495
00:20:21,280 --> 00:20:23,200
readings

496
00:20:23,200 --> 00:20:24,880
the two

497
00:20:24,880 --> 00:20:27,360
is the relationship between

498
00:20:27,360 --> 00:20:29,280
the temperature in the room and the

499
00:20:29,280 --> 00:20:31,760
readings of the thermometer

500
00:20:31,760 --> 00:20:33,039
three

501
00:20:33,039 --> 00:20:36,559
is how the temperature is changing

502
00:20:36,559 --> 00:20:39,039
through time

503
00:20:39,280 --> 00:20:41,600
and then it is just like jakob said it's

504
00:20:41,600 --> 00:20:43,200
kind of like here we can think of this

505
00:20:43,200 --> 00:20:46,159
as being like a little bit of a snippet

506
00:20:46,159 --> 00:20:48,480
from this infinite sequence

507
00:20:48,480 --> 00:20:51,200
of temperatures through time

508
00:20:51,200 --> 00:20:53,039
but

509
00:20:53,039 --> 00:20:54,480
in practice

510
00:20:54,480 --> 00:20:58,559
there has to be an initiating prior

511
00:20:59,120 --> 00:21:00,400
pi

512
00:21:00,400 --> 00:21:01,200
are

513
00:21:01,200 --> 00:21:02,880
policies

514
00:21:02,880 --> 00:21:06,159
policies are sequences of actions

515
00:21:06,159 --> 00:21:07,679
sequences of affordances that are

516
00:21:07,679 --> 00:21:10,159
concatenated over some time horizon

517
00:21:10,159 --> 00:21:11,840
that's what we're evaluating like

518
00:21:11,840 --> 00:21:14,080
expected free energy on

519
00:21:14,080 --> 00:21:14,840
and

520
00:21:14,840 --> 00:21:16,400
policies

521
00:21:16,400 --> 00:21:19,679
represent causal impact in the world

522
00:21:19,679 --> 00:21:22,080
and we can look at this graph which is

523
00:21:22,080 --> 00:21:24,080
why this is an important

524
00:21:24,080 --> 00:21:26,159
prerequisite to understand

525
00:21:26,159 --> 00:21:28,000
because the way in which policies

526
00:21:28,000 --> 00:21:31,520
influence the worlds isn't like by

527
00:21:31,520 --> 00:21:32,799
taking the temperature and like just

528
00:21:32,799 --> 00:21:34,880
changing it to a different value

529
00:21:34,880 --> 00:21:36,720
it's changing

530
00:21:36,720 --> 00:21:38,880
three which is how the temperature

531
00:21:38,880 --> 00:21:42,360
changes through time

532
00:21:45,200 --> 00:21:46,960
any thoughts on the discrete time

533
00:21:46,960 --> 00:21:49,600
formalism

534
00:21:53,840 --> 00:21:57,158
yes mike

535
00:21:59,760 --> 00:22:02,240
so as represented in this figure

536
00:22:02,240 --> 00:22:04,320
the policy is not changing over time is

537
00:22:04,320 --> 00:22:06,879
that correct

538
00:22:07,280 --> 00:22:10,559
the set of policies

539
00:22:11,520 --> 00:22:13,520
in this figure

540
00:22:13,520 --> 00:22:16,639
is not changing

541
00:22:19,679 --> 00:22:22,480
it's not that it can't this is just

542
00:22:22,480 --> 00:22:23,679
only showing

543
00:22:23,679 --> 00:22:25,280
two steps of

544
00:22:25,280 --> 00:22:27,600
some policy being applied yeah just the

545
00:22:27,600 --> 00:22:30,400
way it is in this figure so if

546
00:22:30,400 --> 00:22:32,960
if we were to maybe extend this figure

547
00:22:32,960 --> 00:22:34,000
um

548
00:22:34,000 --> 00:22:35,440
with

549
00:22:35,440 --> 00:22:38,159
two more of the the bottom section we

550
00:22:38,159 --> 00:22:40,640
could also extend policy and have that

551
00:22:40,640 --> 00:22:45,039
changing over time and feeding into that

552
00:22:45,600 --> 00:22:48,559
yes and that's actually one of the

553
00:22:48,559 --> 00:22:50,480
amazing and interesting things about

554
00:22:50,480 --> 00:22:53,120
this graphical representation

555
00:22:53,120 --> 00:22:55,039
is we can say okay well let's carry out

556
00:22:55,039 --> 00:22:58,720
this s to five more time steps

557
00:22:58,799 --> 00:23:00,480
and then let's have

558
00:23:00,480 --> 00:23:02,799
pi one implemented here and then let's

559
00:23:02,799 --> 00:23:04,799
have a do pi two here

560
00:23:04,799 --> 00:23:06,720
and it's kind of like if you can draw it

561
00:23:06,720 --> 00:23:08,640
you can do it

562
00:23:08,640 --> 00:23:10,320
and that's very

563
00:23:10,320 --> 00:23:13,120
important work from devry's and fristen

564
00:23:13,120 --> 00:23:14,480
and par

565
00:23:14,480 --> 00:23:16,400
from around five years ago

566
00:23:16,400 --> 00:23:18,159
was demonstrating that

567
00:23:18,159 --> 00:23:20,799
if the bayes graph

568
00:23:20,799 --> 00:23:22,640
can be drawn

569
00:23:22,640 --> 00:23:24,799
that there's a forney factor graph

570
00:23:24,799 --> 00:23:26,799
representation

571
00:23:26,799 --> 00:23:28,720
and where there's the 40 factor graph

572
00:23:28,720 --> 00:23:30,080
representation

573
00:23:30,080 --> 00:23:31,200
there's

574
00:23:31,200 --> 00:23:33,840
a attractable variational message

575
00:23:33,840 --> 00:23:37,399
passing approximation

576
00:23:38,320 --> 00:23:40,080
i don't know exactly what the guide

577
00:23:40,080 --> 00:23:42,559
rails are for like are there graphs that

578
00:23:42,559 --> 00:23:44,240
can't

579
00:23:44,240 --> 00:23:46,960
be amenable to message passing and etc

580
00:23:46,960 --> 00:23:49,760
but just at a first pass

581
00:23:49,760 --> 00:23:50,480
four

582
00:23:50,480 --> 00:23:52,880
graphs that look

583
00:23:52,880 --> 00:23:55,360
like this

584
00:23:55,360 --> 00:23:57,279
they can be

585
00:23:57,279 --> 00:23:59,120
drawn and more variables can be added

586
00:23:59,120 --> 00:24:01,200
and so on so it's kind of like a visual

587
00:24:01,200 --> 00:24:02,840
code

588
00:24:02,840 --> 00:24:07,600
for probabilistic graphical models

589
00:24:09,279 --> 00:24:11,520
so maybe that's a fun exercise is like

590
00:24:11,520 --> 00:24:12,799
to think about

591
00:24:12,799 --> 00:24:14,960
causal inference in our

592
00:24:14,960 --> 00:24:16,000
day

593
00:24:16,000 --> 00:24:17,679
like the temperature in my room is being

594
00:24:17,679 --> 00:24:19,039
influenced by like

595
00:24:19,039 --> 00:24:20,240
whether the air conditioner is running

596
00:24:20,240 --> 00:24:21,760
in the other room and the temperature

597
00:24:21,760 --> 00:24:23,200
outside

598
00:24:23,200 --> 00:24:25,360
which one of these scenarios does it

599
00:24:25,360 --> 00:24:27,520
model onto

600
00:24:27,520 --> 00:24:29,039
and just kind of

601
00:24:29,039 --> 00:24:31,120
taking scenarios that are

602
00:24:31,120 --> 00:24:33,120
familiar to us and then separating them

603
00:24:33,120 --> 00:24:34,799
in terms of

604
00:24:34,799 --> 00:24:36,159
how are the hidden states changing

605
00:24:36,159 --> 00:24:38,400
through time what are the observations

606
00:24:38,400 --> 00:24:40,159
what policies influence how hidden

607
00:24:40,159 --> 00:24:41,760
states change their time

608
00:24:41,760 --> 00:24:42,640
but

609
00:24:42,640 --> 00:24:44,880
this is going to be

610
00:24:44,880 --> 00:24:47,279
an interesting different

611
00:24:47,279 --> 00:24:49,200
view on the bottom here with the

612
00:24:49,200 --> 00:24:52,320
continuous time model

613
00:24:52,320 --> 00:24:53,919
does anyone want to describe the

614
00:24:53,919 --> 00:24:55,120
continuous time

615
00:24:55,120 --> 00:24:58,120
variant

616
00:25:05,039 --> 00:25:06,799
also one interesting

617
00:25:06,799 --> 00:25:08,400
piece here is in the live streams that

618
00:25:08,400 --> 00:25:11,679
we just did over the last few weeks 46

619
00:25:11,679 --> 00:25:13,360
they make it clear distinguishing

620
00:25:13,360 --> 00:25:15,919
between dai decision active inference

621
00:25:15,919 --> 00:25:19,120
and mai motor active inference

622
00:25:19,120 --> 00:25:21,039
and beyond just modeling cognitive

623
00:25:21,039 --> 00:25:24,799
decision making versus motor reflex arcs

624
00:25:24,799 --> 00:25:26,880
they also highlight how the dai is a

625
00:25:26,880 --> 00:25:28,559
discrete type model that's using the

626
00:25:28,559 --> 00:25:29,760
pomdp

627
00:25:29,760 --> 00:25:32,720
while the motor models tended to use

628
00:25:32,720 --> 00:25:34,320
continuous time

629
00:25:34,320 --> 00:25:35,679
so

630
00:25:35,679 --> 00:25:38,159
they're laying out

631
00:25:38,159 --> 00:25:38,880
and

632
00:25:38,880 --> 00:25:41,520
also kind of generalizing

633
00:25:41,520 --> 00:25:43,919
to show the similarities

634
00:25:43,919 --> 00:25:46,559
between these two different variants

635
00:25:46,559 --> 00:25:48,559
and we can use the notation concordance

636
00:25:48,559 --> 00:25:49,760
table

637
00:25:49,760 --> 00:25:51,360
to like highlight some of those

638
00:25:51,360 --> 00:25:53,840
parallels

639
00:25:54,000 --> 00:25:55,279
this is where the taylor series

640
00:25:55,279 --> 00:25:57,120
approximation comes in and the

641
00:25:57,120 --> 00:25:58,720
generalized coordinates of motion though

642
00:25:58,720 --> 00:26:00,400
they can also be applied to the discrete

643
00:26:00,400 --> 00:26:01,919
time

644
00:26:01,919 --> 00:26:03,279
here

645
00:26:03,279 --> 00:26:05,120
we have we have um

646
00:26:05,120 --> 00:26:07,200
x

647
00:26:07,200 --> 00:26:10,080
x prime and x double prime

648
00:26:10,080 --> 00:26:12,080
the prime notation indicates temporal

649
00:26:12,080 --> 00:26:15,600
derivatives and second derivatives

650
00:26:16,240 --> 00:26:17,760
if anyone has a thought on that feel

651
00:26:17,760 --> 00:26:20,240
free because this is not

652
00:26:20,240 --> 00:26:22,480
doing time series prediction

653
00:26:22,480 --> 00:26:25,520
in the same way that the pomdp is

654
00:26:25,520 --> 00:26:27,360
the pomdp

655
00:26:27,360 --> 00:26:28,320
is

656
00:26:28,320 --> 00:26:30,799
in the memory of the program

657
00:26:30,799 --> 00:26:32,640
there's a value at the previous state

658
00:26:32,640 --> 00:26:34,159
the current state and the next state and

659
00:26:34,159 --> 00:26:35,679
however many other states in the time

660
00:26:35,679 --> 00:26:37,840
horizon

661
00:26:37,840 --> 00:26:40,080
way that a continuous time

662
00:26:40,080 --> 00:26:42,799
taylor series approximation is dealing

663
00:26:42,799 --> 00:26:44,960
with reduction of uncertainty about

664
00:26:44,960 --> 00:26:46,480
future data

665
00:26:46,480 --> 00:26:48,640
is quite different than the way that

666
00:26:48,640 --> 00:26:52,720
these discrete time models are doing so

667
00:26:52,720 --> 00:26:54,240
what's happening here

668
00:26:54,240 --> 00:26:55,840
is

669
00:26:55,840 --> 00:26:58,960
the the value of the function at

670
00:26:58,960 --> 00:27:00,000
now

671
00:27:00,000 --> 00:27:01,600
is being

672
00:27:01,600 --> 00:27:04,480
estimated or provided

673
00:27:04,480 --> 00:27:05,520
then

674
00:27:05,520 --> 00:27:08,480
the first derivative is calculated

675
00:27:08,480 --> 00:27:09,600
so here

676
00:27:09,600 --> 00:27:12,159
three has the same structure but whereas

677
00:27:12,159 --> 00:27:14,000
this is the hidden state at the next

678
00:27:14,000 --> 00:27:15,120
time point

679
00:27:15,120 --> 00:27:17,200
conditioned upon the hidden state at

680
00:27:17,200 --> 00:27:21,039
this time point and the policy

681
00:27:21,039 --> 00:27:22,000
here's

682
00:27:22,000 --> 00:27:24,559
the derivative of x

683
00:27:24,559 --> 00:27:27,679
conditioned upon x and the policy

684
00:27:27,679 --> 00:27:29,679
v

685
00:27:29,679 --> 00:27:30,880
v also has a slightly different

686
00:27:30,880 --> 00:27:33,679
interpretation because it's not

687
00:27:33,679 --> 00:27:36,000
sequence of events either

688
00:27:36,000 --> 00:27:37,760
and analogously for the second

689
00:27:37,760 --> 00:27:41,120
derivative and the higher derivatives

690
00:27:41,120 --> 00:27:43,919
so they're still emitting observations

691
00:27:43,919 --> 00:27:46,720
but these are not observations at future

692
00:27:46,720 --> 00:27:48,799
time points in the same way

693
00:27:48,799 --> 00:27:50,159
and that

694
00:27:50,159 --> 00:27:52,799
is visualized

695
00:27:52,799 --> 00:27:55,600
in this box 4.2

696
00:27:55,600 --> 00:27:58,640
so here is x of t

697
00:27:58,640 --> 00:28:00,399
at time t so this is like the way that

698
00:28:00,399 --> 00:28:02,799
the time series is going to go

699
00:28:02,799 --> 00:28:04,320
x of t

700
00:28:04,320 --> 00:28:08,399
is just this value here you know 5.

701
00:28:08,960 --> 00:28:11,120
the first

702
00:28:11,120 --> 00:28:13,200
term being added in the taylor series

703
00:28:13,200 --> 00:28:14,399
expansion

704
00:28:14,399 --> 00:28:16,399
is the first derivative

705
00:28:16,399 --> 00:28:20,480
rate of change at that x zero

706
00:28:20,480 --> 00:28:23,039
that's giving you a better approximation

707
00:28:23,039 --> 00:28:24,559
through time

708
00:28:24,559 --> 00:28:26,159
then the second derivative adds this

709
00:28:26,159 --> 00:28:28,159
quadratic feature

710
00:28:28,159 --> 00:28:30,640
and so taylor series

711
00:28:30,640 --> 00:28:32,960
converge

712
00:28:32,960 --> 00:28:35,919
closer and closer

713
00:28:35,919 --> 00:28:38,480
moving further and further away from the

714
00:28:38,480 --> 00:28:40,480
target points

715
00:28:40,480 --> 00:28:42,840
as they include higher and higher

716
00:28:42,840 --> 00:28:45,279
derivatives but there isn't

717
00:28:45,279 --> 00:28:46,080
and

718
00:28:46,080 --> 00:28:47,360
um

719
00:28:47,360 --> 00:28:49,919
there isn't an explicit calculation

720
00:28:49,919 --> 00:28:51,679
in the taylor series

721
00:28:51,679 --> 00:28:53,200
of like let's just say this is like you

722
00:28:53,200 --> 00:28:55,120
know one two three

723
00:28:55,120 --> 00:28:56,399
time steps

724
00:28:56,399 --> 00:28:59,200
it's not like well what is

725
00:28:59,200 --> 00:29:00,960
gonna happen at three time steps from

726
00:29:00,960 --> 00:29:02,159
now

727
00:29:02,159 --> 00:29:04,080
the taylor series could then be plugged

728
00:29:04,080 --> 00:29:06,000
in with three

729
00:29:06,000 --> 00:29:08,559
to calculate that

730
00:29:08,559 --> 00:29:10,080
however

731
00:29:10,080 --> 00:29:13,200
this is not um

732
00:29:13,200 --> 00:29:14,880
calculating

733
00:29:14,880 --> 00:29:17,440
x x prime x double prime at t equals

734
00:29:17,440 --> 00:29:18,559
three

735
00:29:18,559 --> 00:29:22,159
it's calculating it for x sub zero

736
00:29:22,159 --> 00:29:24,420
and then using this expansion

737
00:29:24,420 --> 00:29:25,679
[Music]

738
00:29:25,679 --> 00:29:26,399
to

739
00:29:26,399 --> 00:29:28,880
achieve reduction of uncertainty of more

740
00:29:28,880 --> 00:29:32,159
and more distal points

741
00:29:34,480 --> 00:29:36,559
so that's quite interesting

742
00:29:36,559 --> 00:29:38,640
and it's again it's an extremely

743
00:29:38,640 --> 00:29:40,799
different way of doing time series

744
00:29:40,799 --> 00:29:42,320
prediction

745
00:29:42,320 --> 00:29:45,520
in the continuous time framework

746
00:29:45,520 --> 00:29:48,799
than this kind of explicit consideration

747
00:29:48,799 --> 00:29:51,520
of past present future

748
00:29:51,520 --> 00:29:54,918
state values

749
00:29:55,919 --> 00:29:58,399
okay any other thoughts on 4.3

750
00:29:58,399 --> 00:30:00,159
because this is one of the most key

751
00:30:00,159 --> 00:30:02,320
figures

752
00:30:02,320 --> 00:30:03,360
but

753
00:30:03,360 --> 00:30:07,799
the things we can explore and ask ali

754
00:30:08,320 --> 00:30:12,080
uh about this figure on page 69 it says

755
00:30:12,080 --> 00:30:14,000
the relationship between a state and its

756
00:30:14,000 --> 00:30:16,480
temporal derivative here depends on

757
00:30:16,480 --> 00:30:18,720
slowly varying causes

758
00:30:18,720 --> 00:30:22,559
uh nu uh uh i just want to to make sure

759
00:30:22,559 --> 00:30:24,399
uh does this mean

760
00:30:24,399 --> 00:30:28,080
this slowly varying causes uh here is

761
00:30:28,080 --> 00:30:29,360
used uh

762
00:30:29,360 --> 00:30:32,480
to account for the fluctuations or it

763
00:30:32,480 --> 00:30:33,279
has

764
00:30:33,279 --> 00:30:35,039
some different meaning

765
00:30:35,039 --> 00:30:38,640
yes slowly varying causes

766
00:30:43,279 --> 00:30:44,320
so

767
00:30:44,320 --> 00:30:46,880
policies

768
00:30:46,880 --> 00:30:50,559
are influencing the causal unfolding

769
00:30:50,559 --> 00:30:52,720
of states

770
00:30:52,720 --> 00:30:56,320
in this discrete formalization

771
00:30:56,960 --> 00:30:57,840
here

772
00:30:57,840 --> 00:31:00,880
in the continuous time setting

773
00:31:00,880 --> 00:31:04,000
the very the cause slowly varying causes

774
00:31:04,000 --> 00:31:06,240
more slowly than

775
00:31:06,240 --> 00:31:08,159
these changes

776
00:31:08,159 --> 00:31:12,000
play a similar role to policies above

777
00:31:15,519 --> 00:31:16,720
so these are

778
00:31:16,720 --> 00:31:19,120
these causes intervene in how the

779
00:31:19,120 --> 00:31:22,479
derivatives are calculated

780
00:31:27,519 --> 00:31:30,000
uh no i mean uh here

781
00:31:30,000 --> 00:31:33,039
in the discrete time uh well obviously

782
00:31:33,039 --> 00:31:35,519
uh we have uh

783
00:31:35,519 --> 00:31:38,159
we can say stable policies uh that

784
00:31:38,159 --> 00:31:39,919
doesn't uh

785
00:31:39,919 --> 00:31:43,200
that don't change through time but uh in

786
00:31:43,200 --> 00:31:45,440
the continuous time

787
00:31:45,440 --> 00:31:46,559
uh well

788
00:31:46,559 --> 00:31:48,159
i don't know at least that was my

789
00:31:48,159 --> 00:31:51,840
understanding that uh the policies can

790
00:31:51,840 --> 00:31:53,440
slightly change

791
00:31:53,440 --> 00:31:54,240
uh

792
00:31:54,240 --> 00:31:57,600
but the change can be some somewhat

793
00:31:57,600 --> 00:32:00,880
somehow negligible and uh well that's

794
00:32:00,880 --> 00:32:04,480
because of the the additional uh term uh

795
00:32:04,480 --> 00:32:07,840
for fluctuations in the equations uh and

796
00:32:07,840 --> 00:32:11,279
uh they don't necessarily uh affect uh

797
00:32:11,279 --> 00:32:12,480
the main

798
00:32:12,480 --> 00:32:16,720
the main the components of the equations

799
00:32:18,640 --> 00:32:21,760
one could set it up so that

800
00:32:21,760 --> 00:32:24,240
the policies are ineffectual

801
00:32:24,240 --> 00:32:27,840
so that the state changes through time

802
00:32:27,840 --> 00:32:29,039
are

803
00:32:29,039 --> 00:32:31,120
with their own endogenous dynamics not

804
00:32:31,120 --> 00:32:33,279
influenced by policy

805
00:32:33,279 --> 00:32:34,799
or one could imagine a situation where

806
00:32:34,799 --> 00:32:36,399
the states don't change it all through

807
00:32:36,399 --> 00:32:38,480
time and their changes are entirely

808
00:32:38,480 --> 00:32:41,600
driven by policy and i think analogously

809
00:32:41,600 --> 00:32:43,279
there could be a setting

810
00:32:43,279 --> 00:32:46,480
in which the derivative of x

811
00:32:46,480 --> 00:32:50,240
is hardly influenced by these v

812
00:32:50,240 --> 00:32:52,640
slowly varying causes

813
00:32:52,640 --> 00:32:54,399
or v might

814
00:32:54,399 --> 00:32:57,840
entirely describe

815
00:32:58,000 --> 00:33:01,919
the derivatives of x

816
00:33:03,360 --> 00:33:05,200
but i'm not sure if just at this level

817
00:33:05,200 --> 00:33:07,600
of generality

818
00:33:07,600 --> 00:33:09,120
we can

819
00:33:09,120 --> 00:33:12,080
allocate importance

820
00:33:12,080 --> 00:33:14,559
to kind of the endogenous dynamics or

821
00:33:14,559 --> 00:33:16,320
like sort of the policy independent

822
00:33:16,320 --> 00:33:18,799
changes

823
00:33:18,880 --> 00:33:20,480
just the way that those

824
00:33:20,480 --> 00:33:22,320
states are changing or analogously

825
00:33:22,320 --> 00:33:25,840
derivatives are calculated

826
00:33:26,960 --> 00:33:29,279
but that's a great question um lyle and

827
00:33:29,279 --> 00:33:31,679
then mike

828
00:33:31,679 --> 00:33:34,080
yeah this might be just slightly off

829
00:33:34,080 --> 00:33:35,519
topic but

830
00:33:35,519 --> 00:33:37,760
the tools

831
00:33:37,760 --> 00:33:40,159
if you if you're using a multi-mode

832
00:33:40,159 --> 00:33:42,320
simulation tool

833
00:33:42,320 --> 00:33:43,200
then

834
00:33:43,200 --> 00:33:45,919
it can handle both

835
00:33:45,919 --> 00:33:47,360
in some sense it's going to try and

836
00:33:47,360 --> 00:33:50,000
solve both continuous formulations and

837
00:33:50,000 --> 00:33:52,640
discrete time formulations so one they

838
00:33:52,640 --> 00:33:54,240
would typically call

839
00:33:54,240 --> 00:33:56,720
agent based and the other would be

840
00:33:56,720 --> 00:33:59,120
ode-based or something like that

841
00:33:59,120 --> 00:33:59,919
just

842
00:33:59,919 --> 00:34:02,880
the way that they do that is a little

843
00:34:02,880 --> 00:34:04,640
bit of sleight of hand because of course

844
00:34:04,640 --> 00:34:07,440
they're not solving the equations per se

845
00:34:07,440 --> 00:34:09,599
they're estimating the solutions

846
00:34:09,599 --> 00:34:11,760
and they always if you have that then if

847
00:34:11,760 --> 00:34:13,440
you have a slowly

848
00:34:13,440 --> 00:34:15,599
changing set of parameters like you

849
00:34:15,599 --> 00:34:18,639
might model with the discrete case

850
00:34:18,639 --> 00:34:19,679
then

851
00:34:19,679 --> 00:34:20,960
then you

852
00:34:20,960 --> 00:34:23,119
you know you've got a uh

853
00:34:23,119 --> 00:34:25,679
an event q and those events are however

854
00:34:25,679 --> 00:34:27,520
far apart they need to be

855
00:34:27,520 --> 00:34:30,079
then to estimate the continuous form

856
00:34:30,079 --> 00:34:33,199
they simply set that delta t delta t

857
00:34:33,199 --> 00:34:34,800
goes to zero

858
00:34:34,800 --> 00:34:36,879
in some says never goes in the software

859
00:34:36,879 --> 00:34:39,119
exactly to zero but then you you

860
00:34:39,119 --> 00:34:41,599
compress that delta t down to very small

861
00:34:41,599 --> 00:34:43,199
time slices

862
00:34:43,199 --> 00:34:45,199
and then you have estimated your

863
00:34:45,199 --> 00:34:47,119
continuous form

864
00:34:47,119 --> 00:34:48,800
and so by

865
00:34:48,800 --> 00:34:51,440
by doing that you can really have

866
00:34:51,440 --> 00:34:53,040
a pretty

867
00:34:53,040 --> 00:34:55,520
comprehensive way to represent both

868
00:34:55,520 --> 00:34:58,160
cases in the same

869
00:34:58,160 --> 00:35:01,119
modeling environment so

870
00:35:01,119 --> 00:35:02,800
yes

871
00:35:02,800 --> 00:35:05,920
great point um numerical approximations

872
00:35:05,920 --> 00:35:08,800
to continuous processes can be done

873
00:35:08,800 --> 00:35:10,000
through

874
00:35:10,000 --> 00:35:12,079
breaking them down into discrete

875
00:35:12,079 --> 00:35:13,359
processes

876
00:35:13,359 --> 00:35:15,520
and then making sure that as your delta

877
00:35:15,520 --> 00:35:17,760
t is getting smaller and smaller

878
00:35:17,760 --> 00:35:19,040
that you're getting a convergent

879
00:35:19,040 --> 00:35:21,520
estimator

880
00:35:21,520 --> 00:35:23,280
the approach that's taken analytically

881
00:35:23,280 --> 00:35:24,560
here

882
00:35:24,560 --> 00:35:28,480
is to use a taylor series approximation

883
00:35:28,720 --> 00:35:31,280
mike

884
00:35:31,280 --> 00:35:34,640
and so in thinking about how we should

885
00:35:34,640 --> 00:35:36,640
build the mental model of the taylor

886
00:35:36,640 --> 00:35:38,560
series approximation or incorporate that

887
00:35:38,560 --> 00:35:41,440
in our model um that's one example of

888
00:35:41,440 --> 00:35:43,599
how you might capture the time series

889
00:35:43,599 --> 00:35:45,280
structure

890
00:35:45,280 --> 00:35:47,760
and you could potentially substitute in

891
00:35:47,760 --> 00:35:50,560
other approaches to maybe capture finer

892
00:35:50,560 --> 00:35:52,160
detail or

893
00:35:52,160 --> 00:35:54,079
discrete events that might occur on the

894
00:35:54,079 --> 00:35:57,079
series

895
00:35:58,000 --> 00:36:00,400
like what

896
00:36:00,400 --> 00:36:02,320
uh like uh

897
00:36:02,320 --> 00:36:05,040
lois decomposition or something like

898
00:36:05,040 --> 00:36:06,560
that where you're taking apart

899
00:36:06,560 --> 00:36:08,560
components of the time series things

900
00:36:08,560 --> 00:36:11,200
like trend seasonality um discrete

901
00:36:11,200 --> 00:36:13,680
events

902
00:36:13,680 --> 00:36:16,079
yes i think the analytical comparisons

903
00:36:16,079 --> 00:36:18,240
would be um

904
00:36:18,240 --> 00:36:21,040
tight or loose but kalman filter

905
00:36:21,040 --> 00:36:23,119
generalized bayesian filtering

906
00:36:23,119 --> 00:36:25,440
splines

907
00:36:25,440 --> 00:36:28,000
uh time series decomposition

908
00:36:28,000 --> 00:36:30,640
these are all in the category or like in

909
00:36:30,640 --> 00:36:32,800
the genre

910
00:36:32,800 --> 00:36:35,440
of this

911
00:36:35,440 --> 00:36:37,839
ollie

912
00:36:39,200 --> 00:36:40,640
uh by the way

913
00:36:40,640 --> 00:36:43,200
thanks uh for the clarification that was

914
00:36:43,200 --> 00:36:45,520
really helpful uh uh

915
00:36:45,520 --> 00:36:48,480
well uh to ask my question uh more

916
00:36:48,480 --> 00:36:52,480
explicitly uh on page 78 uh

917
00:36:52,480 --> 00:36:55,520
equation 4.15

918
00:36:55,520 --> 00:36:57,119
we have

919
00:36:57,119 --> 00:36:58,240
uh

920
00:36:58,240 --> 00:37:00,480
some additional omega

921
00:37:00,480 --> 00:37:01,599
terms

922
00:37:01,599 --> 00:37:03,760
which are defined as

923
00:37:03,760 --> 00:37:06,480
stochastic fluctuations my question was

924
00:37:06,480 --> 00:37:07,359
that

925
00:37:07,359 --> 00:37:09,920
is the term slightly varying

926
00:37:09,920 --> 00:37:10,640
uh

927
00:37:10,640 --> 00:37:13,079
somehow related to these stochastic

928
00:37:13,079 --> 00:37:16,560
fluctuations or not

929
00:37:16,800 --> 00:37:19,680
yes i believe that the slowly varying

930
00:37:19,680 --> 00:37:22,880
is in relationship to it being included

931
00:37:22,880 --> 00:37:24,880
with the flow

932
00:37:24,880 --> 00:37:26,400
component

933
00:37:26,400 --> 00:37:29,359
rather than with the um at that time

934
00:37:29,359 --> 00:37:30,480
scale

935
00:37:30,480 --> 00:37:31,920
stochastic

936
00:37:31,920 --> 00:37:35,040
more thermal like vibration

937
00:37:35,040 --> 00:37:37,200
and that was explored in like live

938
00:37:37,200 --> 00:37:39,040
stream 45

939
00:37:39,040 --> 00:37:40,720
with free energy principle made simpler

940
00:37:40,720 --> 00:37:42,640
but not too simple

941
00:37:42,640 --> 00:37:43,440
um

942
00:37:43,440 --> 00:37:44,560
with this

943
00:37:44,560 --> 00:37:46,400
idea of

944
00:37:46,400 --> 00:37:48,640
the length of n

945
00:37:48,640 --> 00:37:50,240
and how physics and mechanics are

946
00:37:50,240 --> 00:37:52,000
predicated upon the separation into

947
00:37:52,000 --> 00:37:55,359
flow-like actions

948
00:37:55,359 --> 00:37:57,119
at a given scale

949
00:37:57,119 --> 00:37:59,520
and then stochastic

950
00:37:59,520 --> 00:38:02,079
non-flow aligned

951
00:38:02,079 --> 00:38:03,119
changes

952
00:38:03,119 --> 00:38:05,440
and the path of least action is when

953
00:38:05,440 --> 00:38:08,480
the the the limit of the

954
00:38:08,480 --> 00:38:12,640
the stochastic term going to zero

955
00:38:12,640 --> 00:38:15,440
but let's let's come there um

956
00:38:15,440 --> 00:38:17,200
yeah as people can see even though it's

957
00:38:17,200 --> 00:38:19,119
like we could totally read this like 20

958
00:38:19,119 --> 00:38:20,240
times

959
00:38:20,240 --> 00:38:23,040
and it still is like

960
00:38:23,040 --> 00:38:24,800
why is the next word there why is the

961
00:38:24,800 --> 00:38:26,640
next equation there but okay

962
00:38:26,640 --> 00:38:28,640
they're introducing these two

963
00:38:28,640 --> 00:38:30,640
types of generative models

964
00:38:30,640 --> 00:38:32,720
that have like kind of tantalizing

965
00:38:32,720 --> 00:38:35,520
isomorphisms but also very interesting

966
00:38:35,520 --> 00:38:37,359
differences

967
00:38:37,359 --> 00:38:38,560
they're going to first focus on the

968
00:38:38,560 --> 00:38:41,200
discrete time

969
00:38:43,440 --> 00:38:45,680
the partially observable markov decision

970
00:38:45,680 --> 00:38:47,040
process

971
00:38:47,040 --> 00:38:49,760
formalism is used someone asked like why

972
00:38:49,760 --> 00:38:52,480
is the categorical notation used it just

973
00:38:52,480 --> 00:38:55,520
allows it it makes it easy to look at a

974
00:38:55,520 --> 00:38:57,839
matrix and to interpret the matrix as

975
00:38:57,839 --> 00:39:00,320
like a confusion matrix not just a

976
00:39:00,320 --> 00:39:02,480
matrix that is confusing like they can

977
00:39:02,480 --> 00:39:04,880
be but one that has to do with like a

978
00:39:04,880 --> 00:39:06,480
coin flip

979
00:39:06,480 --> 00:39:08,480
so categorical outcomes

980
00:39:08,480 --> 00:39:08,750
um

981
00:39:08,750 --> 00:39:11,860
[Music]

982
00:39:11,920 --> 00:39:14,800
the uh three nodes

983
00:39:14,800 --> 00:39:17,359
are the transition function

984
00:39:17,359 --> 00:39:20,560
here in the categorical context

985
00:39:20,560 --> 00:39:23,119
between different states

986
00:39:23,119 --> 00:39:24,720
that's this b

987
00:39:24,720 --> 00:39:26,880
and here's where we see the d

988
00:39:26,880 --> 00:39:29,359
the prior over the initial state

989
00:39:29,359 --> 00:39:31,119
and b

990
00:39:31,119 --> 00:39:32,800
and together these account for the three

991
00:39:32,800 --> 00:39:35,680
nodes in figure 4.3

992
00:39:35,680 --> 00:39:38,000
they play a functionally similar role

993
00:39:38,000 --> 00:39:41,720
here's where they get distinguished

994
00:39:43,280 --> 00:39:47,119
selecting between models of behavior

995
00:39:47,119 --> 00:39:48,079
and that was another question which

996
00:39:48,079 --> 00:39:49,600
maybe we could get to um

997
00:39:49,600 --> 00:39:51,040
[Music]

998
00:39:51,040 --> 00:39:52,480
requires

999
00:39:52,480 --> 00:39:54,720
selection amongst these categorically

1000
00:39:54,720 --> 00:39:57,760
discrete plans

1001
00:39:57,760 --> 00:39:59,119
and then

1002
00:39:59,119 --> 00:40:00,880
the softmax

1003
00:40:00,880 --> 00:40:02,880
normalizes

1004
00:40:02,880 --> 00:40:05,040
and ensures that the probability over

1005
00:40:05,040 --> 00:40:08,319
those policies is normalized so that

1006
00:40:08,319 --> 00:40:10,560
they can be understood

1007
00:40:10,560 --> 00:40:13,119
as a probability distribution

1008
00:40:13,119 --> 00:40:15,040
okay a categorical probability

1009
00:40:15,040 --> 00:40:17,680
distribution

1010
00:40:18,000 --> 00:40:20,319
here's the expected free energy

1011
00:40:20,319 --> 00:40:23,880
that we've seen before

1012
00:40:28,880 --> 00:40:30,160
more

1013
00:40:30,160 --> 00:40:32,319
on

1014
00:40:32,319 --> 00:40:35,359
expected free energy

1015
00:40:35,359 --> 00:40:38,560
specifically on how this kl divergence

1016
00:40:38,560 --> 00:40:41,520
term which as we talked about last week

1017
00:40:41,520 --> 00:40:42,960
was about

1018
00:40:42,960 --> 00:40:43,920
how

1019
00:40:43,920 --> 00:40:45,520
the preferred states

1020
00:40:45,520 --> 00:40:49,079
are realized

1021
00:40:53,440 --> 00:40:55,920
active inference uses f and g

1022
00:40:55,920 --> 00:40:57,359
they're related but they play different

1023
00:40:57,359 --> 00:40:58,800
roles

1024
00:40:58,800 --> 00:41:00,560
vfe f

1025
00:41:00,560 --> 00:41:02,400
is the primary quantity minimized over

1026
00:41:02,400 --> 00:41:03,839
time

1027
00:41:03,839 --> 00:41:07,280
that was interesting to read because

1028
00:41:07,280 --> 00:41:08,640
efe

1029
00:41:08,640 --> 00:41:11,359
is what is minimized prospectively

1030
00:41:11,359 --> 00:41:13,920
through time

1031
00:41:14,079 --> 00:41:16,480
whereas here the claim is that

1032
00:41:16,480 --> 00:41:18,720
variational free energy is what is

1033
00:41:18,720 --> 00:41:21,760
minimized over time

1034
00:41:21,760 --> 00:41:25,119
in relationship to generative model

1035
00:41:25,119 --> 00:41:26,400
so

1036
00:41:26,400 --> 00:41:30,160
again more more could be explored there

1037
00:41:30,240 --> 00:41:31,440
they're going to focus on a

1038
00:41:31,440 --> 00:41:34,800
rearrangement of equation 2.6 here

1039
00:41:34,800 --> 00:41:37,359
with the ambiguity and risk

1040
00:41:37,359 --> 00:41:39,359
being juxtaposed with the informational

1041
00:41:39,359 --> 00:41:42,480
value information gain infomax

1042
00:41:42,480 --> 00:41:46,200
and pragmatic value

1043
00:41:49,920 --> 00:41:51,359
they then

1044
00:41:51,359 --> 00:41:53,119
move

1045
00:41:53,119 --> 00:41:54,560
into the

1046
00:41:54,560 --> 00:41:56,880
linear algebraic form

1047
00:41:56,880 --> 00:42:00,680
where the bolds

1048
00:42:04,319 --> 00:42:06,560
okay

1049
00:42:07,119 --> 00:42:10,480
i don't know if bold is used in the same

1050
00:42:10,480 --> 00:42:12,240
way in this

1051
00:42:12,240 --> 00:42:14,319
appendix

1052
00:42:14,319 --> 00:42:18,160
as it is in these equations

1053
00:42:18,160 --> 00:42:20,799
does anyone

1054
00:42:21,520 --> 00:42:23,359
know about what bold means here it could

1055
00:42:23,359 --> 00:42:25,440
mean the vector

1056
00:42:25,440 --> 00:42:27,760
ali

1057
00:42:29,280 --> 00:42:32,079
yes i also think uh bold the

1058
00:42:32,079 --> 00:42:36,160
most probably means vector matrix

1059
00:42:36,160 --> 00:42:37,920
yes

1060
00:42:37,920 --> 00:42:39,920
it it gets pretty subtle though

1061
00:42:39,920 --> 00:42:41,359
sometimes because there's times where

1062
00:42:41,359 --> 00:42:43,680
there's italics bold and neutral being

1063
00:42:43,680 --> 00:42:44,400
used

1064
00:42:44,400 --> 00:42:46,560
uh very closely

1065
00:42:46,560 --> 00:42:48,400
um it's like it's when they're used

1066
00:42:48,400 --> 00:42:50,240
closely it can be confusing and then

1067
00:42:50,240 --> 00:42:52,240
when they're used not closely it's hard

1068
00:42:52,240 --> 00:42:53,680
to juxtapose

1069
00:42:53,680 --> 00:42:54,720
so

1070
00:42:54,720 --> 00:42:56,880
um

1071
00:42:56,880 --> 00:42:59,200
more

1072
00:42:59,200 --> 00:43:02,240
expected free energy rewriting

1073
00:43:02,240 --> 00:43:04,400
within the linear algebraic

1074
00:43:04,400 --> 00:43:05,760
form

1075
00:43:05,760 --> 00:43:08,319
softmax

1076
00:43:08,400 --> 00:43:12,119
bringing back the logs

1077
00:43:12,880 --> 00:43:14,560
variational inference rests upon

1078
00:43:14,560 --> 00:43:16,640
factorization that's related to the

1079
00:43:16,640 --> 00:43:21,118
sparsity of the bayes graph moritz

1080
00:43:22,160 --> 00:43:26,960
hey uh so just going to 410 again um i

1081
00:43:26,960 --> 00:43:28,480
was wondering what's the use of the

1082
00:43:28,480 --> 00:43:30,560
categorical distribution here because

1083
00:43:30,560 --> 00:43:31,520
like

1084
00:43:31,520 --> 00:43:33,520
maybe i miss it but it's not really

1085
00:43:33,520 --> 00:43:35,680
explained in the text

1086
00:43:35,680 --> 00:43:37,599
what what they use it for like there's

1087
00:43:37,599 --> 00:43:41,520
one sentence saying like oh yeah uh

1088
00:43:41,520 --> 00:43:43,359
the fifth line shows that the prior

1089
00:43:43,359 --> 00:43:44,960
belief about observation is a

1090
00:43:44,960 --> 00:43:47,040
categorical distribution

1091
00:43:47,040 --> 00:43:49,680
like what is it for what does it do i i

1092
00:43:49,680 --> 00:43:54,040
i've never seen it before

1093
00:43:58,960 --> 00:44:03,280
i don't know if it has to be categorical

1094
00:44:03,280 --> 00:44:05,680
i like a preference distribution could

1095
00:44:05,680 --> 00:44:07,280
be a continuous

1096
00:44:07,280 --> 00:44:09,359
function

1097
00:44:09,359 --> 00:44:11,520
but here

1098
00:44:11,520 --> 00:44:11,840
um

1099
00:44:11,840 --> 00:44:13,359
[Music]

1100
00:44:13,359 --> 00:44:14,400
it's

1101
00:44:14,400 --> 00:44:15,440
just

1102
00:44:15,440 --> 00:44:17,280
simpler

1103
00:44:17,280 --> 00:44:20,880
perhaps to show it as a categorical

1104
00:44:20,880 --> 00:44:23,280
like there's two outcomes having the

1105
00:44:23,280 --> 00:44:26,240
food and not having the food

1106
00:44:26,240 --> 00:44:28,480
so then that's a categorical

1107
00:44:28,480 --> 00:44:31,280
distribution of preferences and of

1108
00:44:31,280 --> 00:44:33,760
observations

1109
00:44:33,760 --> 00:44:35,359
so they're just modeling a situation

1110
00:44:35,359 --> 00:44:37,520
where there's categorical

1111
00:44:37,520 --> 00:44:38,880
differences

1112
00:44:38,880 --> 00:44:42,000
that are being preferred

1113
00:44:42,160 --> 00:44:45,119
as opposed to like

1114
00:44:45,119 --> 00:44:46,800
a preference over some continuous

1115
00:44:46,800 --> 00:44:49,800
distribution

1116
00:44:50,400 --> 00:44:51,520
does that

1117
00:44:51,520 --> 00:44:53,440
address it they're just modeling a

1118
00:44:53,440 --> 00:44:55,200
situation where there's a cont where

1119
00:44:55,200 --> 00:44:57,680
there's a categorical difference

1120
00:44:57,680 --> 00:45:00,480
with observations and with preferences

1121
00:45:00,480 --> 00:45:02,160
just because like

1122
00:45:02,160 --> 00:45:04,400
mathematically it's easier now to to

1123
00:45:04,400 --> 00:45:06,640
start with that or like

1124
00:45:06,640 --> 00:45:08,560
yeah i think didactically it's a lot

1125
00:45:08,560 --> 00:45:11,200
clearer because you can see like a two

1126
00:45:11,200 --> 00:45:12,640
by two matrix

1127
00:45:12,640 --> 00:45:14,400
did i observe the food or not

1128
00:45:14,400 --> 00:45:16,480
did i get the food or not

1129
00:45:16,480 --> 00:45:18,560
instead of like a distribution of

1130
00:45:18,560 --> 00:45:20,319
temperature

1131
00:45:20,319 --> 00:45:21,520
preference

1132
00:45:21,520 --> 00:45:25,599
and a distribution of observations

1133
00:45:26,880 --> 00:45:29,200
i'd expect that the formalism will work

1134
00:45:29,200 --> 00:45:30,480
out the same in the sense that you're

1135
00:45:30,480 --> 00:45:33,839
still minimizing your surprisal

1136
00:45:33,839 --> 00:45:35,599
and you're still performing distribution

1137
00:45:35,599 --> 00:45:36,960
matching

1138
00:45:36,960 --> 00:45:38,160
but also

1139
00:45:38,160 --> 00:45:40,400
this is like a distribution matching in

1140
00:45:40,400 --> 00:45:42,480
a categorical context that has an

1141
00:45:42,480 --> 00:45:44,240
interpretation of almost like false

1142
00:45:44,240 --> 00:45:47,839
positive and false negative

1143
00:45:50,000 --> 00:45:52,160
all right okay i will go with it thank

1144
00:45:52,160 --> 00:45:53,760
you for the explanation

1145
00:45:53,760 --> 00:45:56,560
yeah it's a it's a good question

1146
00:45:56,560 --> 00:45:57,839
and i mean

1147
00:45:57,839 --> 00:45:59,440
yeah

1148
00:45:59,440 --> 00:46:01,200
it

1149
00:46:01,200 --> 00:46:02,960
the the matrices

1150
00:46:02,960 --> 00:46:06,079
help connect to the linear algebra

1151
00:46:06,079 --> 00:46:07,599
and the matlab

1152
00:46:07,599 --> 00:46:09,440
representations

1153
00:46:09,440 --> 00:46:12,319
and also just to like sort of

1154
00:46:12,319 --> 00:46:15,200
match or no match like in 46 the example

1155
00:46:15,200 --> 00:46:17,359
had to do with like wanting ice cream

1156
00:46:17,359 --> 00:46:21,200
and then they observed ice cream or not

1157
00:46:23,599 --> 00:46:25,520
okay

1158
00:46:25,520 --> 00:46:29,599
pmdp and also like where does this eta

1159
00:46:29,599 --> 00:46:31,040
we'll we'll come back to the another

1160
00:46:31,040 --> 00:46:32,400
time but just to kind of get through it

1161
00:46:32,400 --> 00:46:34,400
all the first pass

1162
00:46:34,400 --> 00:46:39,280
um more details on a pomdp

1163
00:46:40,560 --> 00:46:43,599
s and v

1164
00:46:43,599 --> 00:46:45,280
auxiliary variable

1165
00:46:45,280 --> 00:46:48,720
i don't think this is the v

1166
00:46:49,599 --> 00:46:51,839
here

1167
00:46:52,560 --> 00:46:57,000
because we're in the pomdp setting

1168
00:46:57,119 --> 00:47:00,079
so it's just an auxiliary variable used

1169
00:47:00,079 --> 00:47:01,920
as sort of a

1170
00:47:01,920 --> 00:47:05,200
analytical convenience

1171
00:47:07,599 --> 00:47:09,200
that concludes their discussion of the

1172
00:47:09,200 --> 00:47:11,839
discrete time

1173
00:47:12,000 --> 00:47:13,760
model

1174
00:47:13,760 --> 00:47:16,079
into continuous time but first they

1175
00:47:16,079 --> 00:47:18,640
describe again markov blankets

1176
00:47:18,640 --> 00:47:21,920
and take kind of a second pass

1177
00:47:22,000 --> 00:47:25,599
the blankets are the causes of x

1178
00:47:25,599 --> 00:47:28,880
upstream which are parents

1179
00:47:28,880 --> 00:47:30,960
and the children

1180
00:47:30,960 --> 00:47:33,040
and the parents of the children the kind

1181
00:47:33,040 --> 00:47:36,279
of co-influencers

1182
00:47:38,160 --> 00:47:39,760
of course there's more to

1183
00:47:39,760 --> 00:47:42,960
say but that's what the um pearl

1184
00:47:42,960 --> 00:47:45,920
definition is

1185
00:47:46,319 --> 00:47:48,720
how that gets mapped to sense and action

1186
00:47:48,720 --> 00:47:50,640
states and what influences what what's

1187
00:47:50,640 --> 00:47:53,200
in the blanket on the blanket etc

1188
00:47:53,200 --> 00:47:54,960
those are model specific

1189
00:47:54,960 --> 00:47:57,599
and then here are two common

1190
00:47:57,599 --> 00:47:58,400
um

1191
00:47:58,400 --> 00:48:00,640
message passing schemes that are used

1192
00:48:00,640 --> 00:48:04,000
for approximate inference

1193
00:48:04,000 --> 00:48:05,920
unless the base graph is fully connected

1194
00:48:05,920 --> 00:48:09,520
there is a markov partitioning

1195
00:48:09,520 --> 00:48:13,119
here this is pretty funny nb no te penne

1196
00:48:13,119 --> 00:48:16,559
good note good note to note

1197
00:48:16,559 --> 00:48:18,480
the slightly non-standard use of the

1198
00:48:18,480 --> 00:48:21,040
expectation operator perhaps by

1199
00:48:21,040 --> 00:48:23,119
overloading it

1200
00:48:23,119 --> 00:48:26,000
with a massive subscript

1201
00:48:26,000 --> 00:48:27,920
but it's unclear what

1202
00:48:27,920 --> 00:48:30,880
exactly they meant there

1203
00:48:31,200 --> 00:48:32,160
is

1204
00:48:32,160 --> 00:48:34,720
showing alignment between these two

1205
00:48:34,720 --> 00:48:37,280
different schemes but there's definitely

1206
00:48:37,280 --> 00:48:39,760
citations to go into more into detail on

1207
00:48:39,760 --> 00:48:41,520
like belief propagation and message

1208
00:48:41,520 --> 00:48:43,440
passing inactive

1209
00:48:43,440 --> 00:48:47,200
and then we see several of these

1210
00:48:47,440 --> 00:48:49,839
um

1211
00:48:50,000 --> 00:48:52,400
figures

1212
00:48:58,880 --> 00:49:00,480
personally

1213
00:49:00,480 --> 00:49:02,480
i think it's slightly challenging to

1214
00:49:02,480 --> 00:49:05,040
understand whether this is being used

1215
00:49:05,040 --> 00:49:07,280
illustratively

1216
00:49:07,280 --> 00:49:11,839
or whether these specific topologies

1217
00:49:11,839 --> 00:49:15,599
are as directly interpretable

1218
00:49:15,599 --> 00:49:19,280
as these topologies are

1219
00:49:22,000 --> 00:49:24,319
but here we see kind of

1220
00:49:24,319 --> 00:49:26,800
if you uh blur your eyes

1221
00:49:26,800 --> 00:49:29,440
here's policy at the top

1222
00:49:29,440 --> 00:49:32,400
here's the observations

1223
00:49:32,400 --> 00:49:34,880
here's time minus one

1224
00:49:34,880 --> 00:49:37,280
here's s minus t minus one

1225
00:49:37,280 --> 00:49:39,520
t and t plus one

1226
00:49:39,520 --> 00:49:41,520
so we can see

1227
00:49:41,520 --> 00:49:43,760
some

1228
00:49:43,760 --> 00:49:45,839
resonances

1229
00:49:45,839 --> 00:49:48,640
with 4.3

1230
00:49:48,640 --> 00:49:52,240
but now we're in the continuous time

1231
00:49:52,800 --> 00:49:56,480
motor active inference from 46

1232
00:49:56,480 --> 00:49:58,319
is justifying the use of continuous time

1233
00:49:58,319 --> 00:50:01,440
based upon the um continuous unrolling

1234
00:50:01,440 --> 00:50:05,920
aspect of sensory input and motor output

1235
00:50:07,920 --> 00:50:09,760
they're going to start in a different

1236
00:50:09,760 --> 00:50:11,440
place than they did with the po mdp

1237
00:50:11,440 --> 00:50:13,280
model

1238
00:50:13,280 --> 00:50:14,480
in this case

1239
00:50:14,480 --> 00:50:16,960
we have much more of a physics

1240
00:50:16,960 --> 00:50:18,640
grounding

1241
00:50:18,640 --> 00:50:21,119
again check out live stream number 45

1242
00:50:21,119 --> 00:50:23,440
to see about the langven and how this is

1243
00:50:23,440 --> 00:50:24,559
connected

1244
00:50:24,559 --> 00:50:27,200
but this is a much more physics based

1245
00:50:27,200 --> 00:50:28,480
grounding

1246
00:50:28,480 --> 00:50:30,319
in terms of like a flow

1247
00:50:30,319 --> 00:50:33,359
operator and a stochastic term at a

1248
00:50:33,359 --> 00:50:36,240
given time scale

1249
00:50:36,880 --> 00:50:38,480
the um

1250
00:50:38,480 --> 00:50:41,040
stochastic

1251
00:50:41,040 --> 00:50:42,880
term

1252
00:50:42,880 --> 00:50:43,760
is

1253
00:50:43,760 --> 00:50:46,079
assumed to have a normal distribution

1254
00:50:46,079 --> 00:50:47,440
and that kind of relates like what mike

1255
00:50:47,440 --> 00:50:49,280
said about de-trending

1256
00:50:49,280 --> 00:50:51,760
like one can think of this stochastic

1257
00:50:51,760 --> 00:50:52,720
term

1258
00:50:52,720 --> 00:50:54,000
as being what happens when you've

1259
00:50:54,000 --> 00:50:55,920
de-trended all of the signal that's

1260
00:50:55,920 --> 00:50:57,839
non-gaussian out

1261
00:50:57,839 --> 00:51:00,640
you're left with like the residuals

1262
00:51:00,640 --> 00:51:03,680
which have a gaussian

1263
00:51:03,680 --> 00:51:05,839
uh

1264
00:51:06,400 --> 00:51:08,960
nature

1265
00:51:08,960 --> 00:51:12,160
precision is capital pi

1266
00:51:12,160 --> 00:51:14,000
and that's the inverse of the

1267
00:51:14,000 --> 00:51:15,520
fluctuation

1268
00:51:15,520 --> 00:51:17,040
and so that's they're going to connect

1269
00:51:17,040 --> 00:51:20,240
that to the common filtering

1270
00:51:20,960 --> 00:51:23,359
here we return again to the generalized

1271
00:51:23,359 --> 00:51:25,680
coordinates motion

1272
00:51:25,680 --> 00:51:27,919
um

1273
00:51:29,359 --> 00:51:31,760
coming from this taylor series

1274
00:51:31,760 --> 00:51:33,119
approximation

1275
00:51:33,119 --> 00:51:34,240
route

1276
00:51:34,240 --> 00:51:36,079
so if somebody said i have 10 numbers

1277
00:51:36,079 --> 00:51:37,440
and we need to predict 10 years in the

1278
00:51:37,440 --> 00:51:38,720
future

1279
00:51:38,720 --> 00:51:40,640
the discrete time way would be like well

1280
00:51:40,640 --> 00:51:42,480
let's try to predict it at each of those

1281
00:51:42,480 --> 00:51:43,839
10 years

1282
00:51:43,839 --> 00:51:46,319
and that those will be your 10 numbers

1283
00:51:46,319 --> 00:51:48,480
the generalized coordinates of motions

1284
00:51:48,480 --> 00:51:49,440
approach

1285
00:51:49,440 --> 00:51:52,880
which we explored the most in

1286
00:51:52,880 --> 00:51:54,880
livestream number 26

1287
00:51:54,880 --> 00:51:56,240
with decosta

1288
00:51:56,240 --> 00:51:57,599
at all

1289
00:51:57,599 --> 00:52:00,480
in bayesian mechanics

1290
00:52:00,480 --> 00:52:02,800
the 10 numbers could be like

1291
00:52:02,800 --> 00:52:05,119
the value today

1292
00:52:05,119 --> 00:52:06,800
and the derivative today the second

1293
00:52:06,800 --> 00:52:08,079
derivative and the third and the fourth

1294
00:52:08,079 --> 00:52:10,079
and the fifth up however many that's the

1295
00:52:10,079 --> 00:52:12,240
generalized coordinates of motion

1296
00:52:12,240 --> 00:52:14,240
so it's like a snapshot

1297
00:52:14,240 --> 00:52:16,839
of the process and all of its higher

1298
00:52:16,839 --> 00:52:18,960
derivatives and so the generalized

1299
00:52:18,960 --> 00:52:20,640
coordinates of motion are very similar

1300
00:52:20,640 --> 00:52:22,800
to taylor series approximations

1301
00:52:22,800 --> 00:52:25,359
in how they represent centered at a

1302
00:52:25,359 --> 00:52:28,480
certain point x naught

1303
00:52:28,480 --> 00:52:30,800
how one expects

1304
00:52:30,800 --> 00:52:33,359
as movement happens away from that x

1305
00:52:33,359 --> 00:52:35,040
naught

1306
00:52:35,040 --> 00:52:37,760
reducing surprise and so here is like

1307
00:52:37,760 --> 00:52:41,599
x with a um dot on top is the change in

1308
00:52:41,599 --> 00:52:43,680
x and then this is like the derivative

1309
00:52:43,680 --> 00:52:46,960
of the change in x and so on

1310
00:52:46,960 --> 00:52:49,520
here the tilde notation is used for the

1311
00:52:49,520 --> 00:52:53,200
generalized coordinates of motion

1312
00:52:53,440 --> 00:52:55,599
so we see this

1313
00:52:55,599 --> 00:52:57,119
equation

1314
00:52:57,119 --> 00:53:00,160
which was just for one

1315
00:53:00,160 --> 00:53:02,000
value

1316
00:53:02,000 --> 00:53:03,839
like

1317
00:53:03,839 --> 00:53:06,880
where you are on the freeway you know

1318
00:53:06,880 --> 00:53:08,319
and then this is the generalized

1319
00:53:08,319 --> 00:53:11,279
coordinates of motion

1320
00:53:12,960 --> 00:53:16,240
the free energy is written down

1321
00:53:16,240 --> 00:53:18,480
for

1322
00:53:18,480 --> 00:53:20,640
this

1323
00:53:20,640 --> 00:53:23,200
generalized coordinates of motion

1324
00:53:23,200 --> 00:53:25,040
with precision

1325
00:53:25,040 --> 00:53:26,319
here

1326
00:53:26,319 --> 00:53:28,000
the closest that we came to exploring it

1327
00:53:28,000 --> 00:53:30,720
was in 43

1328
00:53:30,720 --> 00:53:33,759
on predictive coding

1329
00:53:38,160 --> 00:53:40,960
there's some more details on gaussian

1330
00:53:40,960 --> 00:53:43,839
the relationship between like gaussian

1331
00:53:43,839 --> 00:53:46,640
uh processes

1332
00:53:46,640 --> 00:53:48,240
and uh

1333
00:53:48,240 --> 00:53:51,280
also i think lyle brought up this um

1334
00:53:51,280 --> 00:53:52,400
like sort of

1335
00:53:52,400 --> 00:53:53,359
mode

1336
00:53:53,359 --> 00:53:57,480
and multi-mode simulations

1337
00:53:59,599 --> 00:54:02,800
this is modeling a single mode

1338
00:54:02,800 --> 00:54:05,280
not that it can't model a bimodal

1339
00:54:05,280 --> 00:54:06,800
distribution

1340
00:54:06,800 --> 00:54:07,839
but

1341
00:54:07,839 --> 00:54:09,760
this is where the laplace approximation

1342
00:54:09,760 --> 00:54:12,480
comes into play

1343
00:54:12,559 --> 00:54:15,920
this is potentially even unnecessarily

1344
00:54:15,920 --> 00:54:18,000
complex

1345
00:54:18,000 --> 00:54:19,920
but it's there

1346
00:54:19,920 --> 00:54:21,520
and the

1347
00:54:21,520 --> 00:54:23,599
laplace approximation

1348
00:54:23,599 --> 00:54:26,640
is fitting

1349
00:54:26,720 --> 00:54:29,839
um a quadratic

1350
00:54:30,160 --> 00:54:32,160
distribution

1351
00:54:32,160 --> 00:54:33,680
that tracks

1352
00:54:33,680 --> 00:54:36,240
the mode

1353
00:54:36,319 --> 00:54:38,880
so like the the highest point

1354
00:54:38,880 --> 00:54:40,559
on the distribution

1355
00:54:40,559 --> 00:54:42,319
and then it fits

1356
00:54:42,319 --> 00:54:45,599
a parabola around that

1357
00:54:50,559 --> 00:54:51,839
here

1358
00:54:51,839 --> 00:54:54,799
is more details on the hierarchical

1359
00:54:54,799 --> 00:54:57,119
nature

1360
00:54:57,119 --> 00:54:59,760
and the kind of multi-time scale nature

1361
00:54:59,760 --> 00:55:02,720
that's implied

1362
00:55:02,880 --> 00:55:04,240
um

1363
00:55:04,240 --> 00:55:07,839
ultimately by the lengthen

1364
00:55:09,119 --> 00:55:10,880
and then

1365
00:55:10,880 --> 00:55:13,520
there's uh

1366
00:55:14,319 --> 00:55:16,319
it'd be good to juxtapose figure four

1367
00:55:16,319 --> 00:55:18,839
six and four

1368
00:55:18,839 --> 00:55:21,680
four to see how they're similar and

1369
00:55:21,680 --> 00:55:23,599
different

1370
00:55:23,599 --> 00:55:25,280
but here we see message passing

1371
00:55:25,280 --> 00:55:27,119
happening on the generalized predictive

1372
00:55:27,119 --> 00:55:28,640
coding architecture

1373
00:55:28,640 --> 00:55:30,559
and that was like explored a lot more

1374
00:55:30,559 --> 00:55:32,720
not with this exact figure but this was

1375
00:55:32,720 --> 00:55:34,240
explored more from like an analytical

1376
00:55:34,240 --> 00:55:38,160
and empirical perspective in 43.

1377
00:55:41,440 --> 00:55:42,799
then

1378
00:55:42,799 --> 00:55:46,599
there's an abrupt ending

1379
00:55:48,720 --> 00:55:50,720
but the following chapters are going to

1380
00:55:50,720 --> 00:55:53,040
appeal to the formalisms

1381
00:55:53,040 --> 00:55:55,759
and apply them

1382
00:56:00,400 --> 00:56:02,880
so any

1383
00:56:02,880 --> 00:56:05,839
thoughts or ideas on chapter four as we

1384
00:56:05,839 --> 00:56:08,079
close out

1385
00:56:08,079 --> 00:56:11,520
and hopefully next week we can have um

1386
00:56:11,520 --> 00:56:13,760
a lot of questions and things like that

1387
00:56:13,760 --> 00:56:16,640
even basic questions it's like if the if

1388
00:56:16,640 --> 00:56:18,480
you read it and you understood it

1389
00:56:18,480 --> 00:56:20,000
then it'd be awesome to contribute a

1390
00:56:20,000 --> 00:56:20,960
question

1391
00:56:20,960 --> 00:56:22,799
that would explore someone else's

1392
00:56:22,799 --> 00:56:24,079
understanding

1393
00:56:24,079 --> 00:56:24,799
or

1394
00:56:24,799 --> 00:56:26,720
prompt towards how you thought about it

1395
00:56:26,720 --> 00:56:28,640
in a way that made sense for you

1396
00:56:28,640 --> 00:56:30,400
and if you don't understand it

1397
00:56:30,400 --> 00:56:34,359
then just ask the question

1398
00:56:44,240 --> 00:56:47,439
ali and then anyone else

1399
00:56:48,480 --> 00:56:51,040
i just wanted to briefly mention an

1400
00:56:51,040 --> 00:56:53,359
additional point related to

1401
00:56:53,359 --> 00:56:55,440
the question about

1402
00:56:55,440 --> 00:56:56,880
the reason behind

1403
00:56:56,880 --> 00:56:59,440
using the categorical distribution

1404
00:56:59,440 --> 00:57:02,480
on page 74

1405
00:57:02,559 --> 00:57:05,040
it says uh

1406
00:57:05,040 --> 00:57:06,480
the fifth line shows that the prior

1407
00:57:06,480 --> 00:57:08,000
belief about the observations is the

1408
00:57:08,000 --> 00:57:09,599
categorical distribution whose

1409
00:57:09,599 --> 00:57:12,079
sufficient statistics are given in the c

1410
00:57:12,079 --> 00:57:13,680
vector i think here sufficient

1411
00:57:13,680 --> 00:57:16,079
statistics is the key term uh to

1412
00:57:16,079 --> 00:57:17,839
understand the reason behind using

1413
00:57:17,839 --> 00:57:20,960
categorical distributions because uh for

1414
00:57:20,960 --> 00:57:23,920
sufficient insufficient statistics

1415
00:57:23,920 --> 00:57:25,520
we don't

1416
00:57:25,520 --> 00:57:28,720
necessarily use the exact

1417
00:57:28,720 --> 00:57:32,160
the exact modeling or distributions

1418
00:57:32,160 --> 00:57:35,839
instead we use a substituted statistics

1419
00:57:35,839 --> 00:57:38,559
that is simple enough to calculate and

1420
00:57:38,559 --> 00:57:39,440
also

1421
00:57:39,440 --> 00:57:42,799
close enough to the uh to the actual

1422
00:57:42,799 --> 00:57:44,480
data so

1423
00:57:44,480 --> 00:57:45,920
i think

1424
00:57:45,920 --> 00:57:47,839
that can help

1425
00:57:47,839 --> 00:57:49,920
in understanding the reason behind that

1426
00:57:49,920 --> 00:57:52,920
decision

1427
00:57:55,040 --> 00:57:57,280
good point

1428
00:57:57,280 --> 00:57:58,480
and

1429
00:57:58,480 --> 00:57:59,839
this is definitely a

1430
00:57:59,839 --> 00:58:01,280
a technical

1431
00:58:01,280 --> 00:58:04,480
note but um is it fair to say that like

1432
00:58:04,480 --> 00:58:06,319
the mean and the variance are sufficient

1433
00:58:06,319 --> 00:58:09,839
statistics for a gaussian distribution

1434
00:58:11,359 --> 00:58:14,640
uh yes i think so

1435
00:58:15,119 --> 00:58:16,160
so like

1436
00:58:16,160 --> 00:58:18,960
that's one of the

1437
00:58:19,440 --> 00:58:22,480
perhaps proximate mechanisms by which

1438
00:58:22,480 --> 00:58:25,119
the laplace approximation and

1439
00:58:25,119 --> 00:58:28,960
variational inference more generally

1440
00:58:28,960 --> 00:58:31,359
are able to

1441
00:58:31,359 --> 00:58:35,680
deal with arbitrary true distributions

1442
00:58:35,680 --> 00:58:36,880
by fitting

1443
00:58:36,880 --> 00:58:40,000
a family of distributions that have

1444
00:58:40,000 --> 00:58:42,880
um tractable optimization structure

1445
00:58:42,880 --> 00:58:45,040
and a vastly reduced set of sufficient

1446
00:58:45,040 --> 00:58:46,480
statistics

1447
00:58:46,480 --> 00:58:48,559
if you had even just a simple bimodal

1448
00:58:48,559 --> 00:58:50,319
distribution while there would be like

1449
00:58:50,319 --> 00:58:52,640
the location of the two peaks the

1450
00:58:52,640 --> 00:58:54,880
relative heights of the two peaks the

1451
00:58:54,880 --> 00:58:56,880
skewedness and all the you can have many

1452
00:58:56,880 --> 00:59:00,400
many parameters needed to describe it

1453
00:59:00,400 --> 00:59:02,799
in contrast the laplace approximation

1454
00:59:02,799 --> 00:59:05,920
only requires the location of the mode

1455
00:59:05,920 --> 00:59:08,079
and the variance estimate

1456
00:59:08,079 --> 00:59:10,480
and so

1457
00:59:10,720 --> 00:59:12,880
where that's adequate

1458
00:59:12,880 --> 00:59:15,680
it's simple and fast

1459
00:59:15,680 --> 00:59:17,440
where it's inadequate

1460
00:59:17,440 --> 00:59:19,520
you'll at least know

1461
00:59:19,520 --> 00:59:22,319
because you'll continue to be surprised

1462
00:59:22,319 --> 00:59:26,400
at new observations coming in

1463
00:59:29,599 --> 00:59:32,640
okay any final comments on this

1464
00:59:32,640 --> 00:59:35,680
chapter four part one

1465
00:59:40,400 --> 00:59:42,880
definitely a challenging

1466
00:59:42,880 --> 00:59:44,799
though interesting

1467
00:59:44,799 --> 00:59:47,799
chapter

1468
00:59:49,599 --> 00:59:52,559
and it really is at the heart of

1469
00:59:52,559 --> 00:59:55,119
active

1470
00:59:55,680 --> 00:59:57,200
and as we hopefully explored a little

1471
00:59:57,200 --> 01:00:00,000
bit today it includes like basic

1472
01:00:00,000 --> 01:00:03,040
intuition pumps

1473
01:00:04,000 --> 01:00:06,319
as well as

1474
01:00:06,319 --> 01:00:10,640
some rosetta stone like representations

1475
01:00:10,640 --> 01:00:12,559
and many many

1476
01:00:12,559 --> 01:00:14,319
equations

1477
01:00:14,319 --> 01:00:17,040
which i hope we can unpack

1478
01:00:17,040 --> 01:00:18,720
so could someone explain it in simple

1479
01:00:18,720 --> 01:00:19,920
words

1480
01:00:19,920 --> 01:00:22,079
it's what we've been asking for every

1481
01:00:22,079 --> 01:00:24,240
single equation

1482
01:00:24,240 --> 01:00:25,760
and it's something that everyone can

1483
01:00:25,760 --> 01:00:27,520
contribute to

1484
01:00:27,520 --> 01:00:29,040
all right well

1485
01:00:29,040 --> 01:00:31,040
looking forward to people's

1486
01:00:31,040 --> 01:00:34,000
edits over the coming week and

1487
01:00:34,000 --> 01:00:35,760
editions

1488
01:00:35,760 --> 01:00:37,760
and uh

1489
01:00:37,760 --> 01:00:39,760
we'll come back in

1490
01:00:39,760 --> 01:00:43,839
one week for part two on four

