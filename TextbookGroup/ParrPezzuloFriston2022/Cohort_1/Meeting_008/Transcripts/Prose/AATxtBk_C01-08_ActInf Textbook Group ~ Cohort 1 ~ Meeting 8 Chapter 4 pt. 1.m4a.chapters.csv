start	end	startTime	summary	headline	gist
1450	116260	00:01	It's June 23, 2022 and we are in week eight of the textbook group cohort one. This chapter is more technical than chapters one through three, appealing to linear algebra, differentiation and a Taylor series expansion. Those who do not want to delve into the theoretical underpinnings may skip this chapter.	We're starting chapter four of the textbook group cohort one	Cohazard 1, Chapter 4
117190	554430	01:57	 chapter four is one of the first steps toward building the actual theory of active inference. The central idea of a generative model is discussed in discrete time and continuous time. If anyone has more questions to add, they can do that.	Ali: Chapter four is one of the first steps toward building the active inference theory	A review of chapter 4
555920	660870	09:15	Do a posterior at time T become a prior at timeT plus one? I guess it depends on the specific posterior and prior because that can mean multiple things. But in the context of Figure 4.3, I'd say it does because we are updating our prior.	Figure 4.3 shows how posterior and prior interact in active inference	Inactive Inference 4.3
666900	941280	11:06	4.1 is returning to Bayes theorem. This is a key move to move an integration problem into an optimization problem. It would be very helpful to look through the order in which different topics are addressed in chapter four. Some questions are invoking things that are much later.	Some questions in chapter four are invoking things that are much later	Bayes Theorem and the optimization problem
944610	1792980	15:44	Generative Models is the name of this chapter. To calculate free energy we need three things data variational, distribution, family, and a generative model. Figure 4.3 describes two different kinds of generative models. Knowing how to read these directed graphs is relatively essential for interpreting more complex graphs that involve actions.	Generative Models is the name of this chapter. To calculate free energy we need three things	Generative Models and the Graphs
1795980	2204390	29:55	The relationship between a state and its temporal derivative here depends on slowly varying causes. These causes intervene in how the derivatives are calculated in the discrete time. If you're using a multimode simulation tool, then it's going to try and solve both continuous formulations and discrete time formulations.	The relationship between a state and its temporal derivative depends on slowly varying causes	Neuroscience 4.3: The Law of Slowly varying Causes
2205530	2573590	36:45	Ali: Is the term slightly varying somehow related to these stochastic fluctuations or not? He says the slowly varying is in relationship to it being included with the flow component. Ali: More on expected free energy, specifically on how this KL divergence term is realized.	Ali: Is term slightly varying somehow related to stochastic fluctuations	Bayesian inference with variational and non-parametric weights
2576890	2823590	42:56	More expected free energy rewriting within the linear algebraic form. Variational inference rests upon factorization that's related to the sparsity of the Bayes graph. First pass more details on a POMDP, S, and V auxiliary variable.	The fifth line shows that the prior belief about observations is a categorical distribution	Categorical inference from the Bayes graph
2827630	3078840	47:07	That concludes their discussion of the discrete time model into continuous time. But first they describe again Markov blankets and take kind of a second pass. Active inference from 46 is justifying the use of continuous time based upon the continuous unrolling aspect of sensory input and motor output.	That concludes their discussion of the discrete time model into continuous time	Inventing the Continuous Time Motor
3081020	3406090	51:21	The generalized coordinates of motion's approach which we explored the most in live stream number 26. The closest that we came to exploring it was in 43 on predictive coding. Here is more details on the hierarchical nature and the kind of multi timescale nature. Any thoughts or ideas on chapter four as we close out?	The generalized coordinates of motion are very similar to a Taylor Series approximation	Bayesian Mechanics: Generalized Coordinates of Motion (4)
3408460	3565040	56:48	Is it fair to say that the mean and the variance are sufficient statistics for a Gaussian distribution? Yes, I think so. Where that's adequate, it's simple and fast. Where it's inadequate, you'll at least know.	For insufficient statistics, we use substituted statistics that are close enough to actual data	Inference under the LaPlace approximation with categorical distributions
3569570	3642506	59:29	 Chapter four, part one. Definitely a challenging, though interesting chapter, and it really is at the heart of active. Could someone explain it in simple words? It's what we've been asking for every single equation. Looking forward to people's edits over the coming week and additions.	This is chapter four of active. Definitely a challenging, though interesting chapter	Chapter 4, The Intuition Pump
