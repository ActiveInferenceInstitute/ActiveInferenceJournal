start	end	paragNum	speaker	confidence	startTime	wordCount	text
1450	21280	1	A	0.76001	00:01	41	Hello, everyone. It's May 26, 2022. It's the fourth week of the first cohort of the active textbook group. We're in our first discussion of chapter two today. We're going to go over the questions that are posted for chapter two.
21810	50678	2	A	0.99998	00:21	67	Then we'll see where that takes us and what ID of the book have been explored. And that'll be the main focus. Also, just a note on the math learning group, those meetings have been occurring on 19 UTC on Wednesdays. And so in the math learning group, you'll find information about how to participate. You'll find and be able to edit resources on learning different topics.
50854	91606	3	A	0.9995	00:50	106	So this is a really helpful activity if people want to share the resources that help them learn about different ideas and that'll help people search for a video about this. We have a notation table that will help us as we start to look at the notation more. There's some math learning basic questions, like around math, anything related to the textbook content can go in the main questions. Math learning group is part of the real textbook group. So these are not the questions to be answered like the other ones that we're going to go to are, but this is just about math.
91718	121410	4	A	1.0	01:31	73	And then also there's some math oriented overviews. Like, I wrote this summary of the first two thirds of chapter two. So if people want to be like, continuing to distill and represent what they're learning and what they're asking, that's all good. Okay, any other notes that anybody wants to add before we start to go into the questions? You can raise your hand or you can type it in the chat.
125450	139960	5	A	0.99527	02:05	30	Okay, so we're in the first week of discussing chapter two, the low Road to active inference. So just to kind of warm us up, what is the low road?
174160	226188	6	B	0.5678	02:54	84	Got? A low road is the Bayesian Brain approach. Right here is the Proximate next big concept, I guess previous, but it's kind of based on I guess. Yeah, I mean, you can see right in the picture, it's based on basing it's like mathematical. The way I conceptualize it is like literally the low road, meaning very primitive, very mathematical, very hyper analytical, foundational, kind of an analysis way of looking at it, I guess that's not necessarily living or anything like that.
226274	226910	7	B	0.89024	03:46	1	Right?
231690	236280	8	B	0.53878	03:51	14	Whereas the high road is kind of more about the other side of that.
239850	278814	9	B	0.86	03:59	92	All right. Okay, so we're going to be learning about the high road and low road. Those are the two paths that are offered in chapter two and three of the book. So hopefully, again, it would be awesome to have as many people as possible speak and feel welcome to share their views during this session. So everyone is especially encouraged to put questions or comments in the chat or raise their hand to speak or find other times to have synchronous communications and especially to make contributions to the coda.
278862	306560	10	A	0.7826	04:38	77	But really appreciate that everyone has come out to go through these discussion questions. So we're going to now go to the questions that have been placed into the questions table. And just the more questions, the better they can be super short. It can be anything that you're having uncertainty about. If you come across a table or a figure or a sentence in the text and you have a question, please write the question down.
307010	348618	11	A	0.99996	05:07	106	It will be extremely, extremely helpful. It doesn't have to be with extensive references or citations. It can just be what does this mean if you're uncertain about something and then if you were certain about it, you could still write a question like what would you ask somebody to test or to understand what they understood about it? Okay, so we're going to start with this first most upvoted question. But there's still time in this session and also till next week in our next session on chapter two, to add more questions if you wrote them down somewhere else and also to upvote questions.
348704	352540	12	A	0.99822	05:48	12	But we're just going to start with the most interestingly voted questions.
355970	365200	13	A	0.66498	05:55	17	What is the relevance of the support and surprise for the different probability distributions in table 2.1?
368070	390140	14	A	0.54224	06:08	17	So what does anyone see in table 2.1 and what are support and surprise people? Mike yes.
394430	420740	15	C	0.91491	06:34	50	So table 2.1 looks to me like a guide for selecting distributions. If you're building out one of these models with support saying what set of numbers would fit within this distribution selection? And then if you chose this distribution, how would you look at the support equation for it?
423590	433000	16	A	0.99871	07:03	23	Can you unpack with a surprise part? Yeah. If you chose this distribution, how would you look at the surprise component of it?
442360	489280	17	A	0.98	07:22	85	And we're going to get to surprise and Bayesian surprise in the coming questions. So support using the definition pulled here from Wikipedia, the support of the function is the subset of the x axis, like the domain where there's a y value that's not zero. So it's where the function is nonzero defined. The Gaussian, the normal Belker of distribution, has nonzero support at all numbers. Fancy r and then other distributions have different variable, different values that they're having non zero values at.
489350	537920	18	A	0.99893	08:09	109	Like the gamma distribution is defined over the interval from zero to infinity. So if it was like how many of this thing do you have that might be a reason to use a distribution that's only positive numbers? Or if you were wanting something that could have positive or negative numbers of any size, the Gaussian is a distribution and then another one that's like a relevant support difference would be like the deer Schlee being defined only within the zero to one interval, which helps connect it to probabilities. So the support is where that function, that distribution family is defined. And then what is the surprise?
557450	588560	19	A	0.84739	09:17	24	Does anyone know the name of the little squiggle they are using to represent surprise? I think it's called Fracture i, aka fancy eye.
598200	645250	20	A	0.99657	09:58	107	We're going to come to the definition of surprise in a coming question and without going into every variable and trying to overlearn something, the surprise of a given observation, like a data point, let's just think about the Gaussian. X is the observed data point and Mu is like the mean of that normal distribution, which is also the mode. So it's like the center of that distribution. And then this capital pi is a variance estimator, I believe here. So how surprised one should be by a new data point coming in is related to the difference between that new data point and the mean.
646100	689090	21	A	0.99986	10:46	121	So if the new data point were exactly on the center of the distribution, this whole term is going to go to zero. So one should not be surprised at all by exact data points on the mean of the distribution. But any data point that has not exactly on the mean is going to have some non zero value and so it's going to be a function of how far the data point is from the mean and some scaling by the variance. So if we were expecting 100 with a variance of ten versus 100 with a variance of one in one case, like getting 101 is like a one sigma event. It has a z score of one.
689620	699620	22	A	1.0	11:29	22	Just speaking loosely here, whereas in the case of it having a variance that's very small, then that might be more surprising.
705130	738180	23	A	0.99987	11:45	56	Any other comments that people have on Table 2.1? I have a question. Yeah. So while I was reading through the chapter going back to section 2.2, right, perception as inference. So when he says, when they say that the brain is a predictive machine or a statistical organ, that infers external states of the world.
739830	764060	24	D	0.99758	12:19	50	Okay, here's my question, because I'm primarily from a telecom background. So most of our things are to get messages crossed between two distant transmitters receiver, right? So we build noise models. So without any noise you don't get signal. So you need to know what noise model looks like.
766670	792146	25	D	1.0	12:46	69	For example, if the power spectrum of the signal is what you expect from, let's say we are using a Gaussian distribution of noise, right? So if it's the same as you expect from the Gaussian, you do nothing. So that's just noise. So you don't classify the data point that's coming in. If it is more than this, then okay, so there might be something interesting about this.
792168	832478	26	D	0.99989	13:12	96	There might be some signal here. So we define that signal to noise ratio. A lot of this chapter seems to be dealing with the fact that we by default know what the signal looks like. So there's no attempt to build a noise model here. That would be like, okay, so maybe the sensor in this case, our eyes for example, has some parameters it can detect between, say, a bandwidth, okay, so it can detect light between certain frequency ranges, but maybe it performs very well in a certain frequency range and not others.
832564	857800	27	D	0.72615	13:52	59	There's more error in other frequency ranges, right? So the noise model should incorporate such things, imperfections in the sensor, imperfections in the connections between the sensor and processing equipment. But there's no attempt to do that in this entire chapter. So I'm just curious as to what exactly is the predictive machine here? What is being predicted here?
858810	883194	28	A	0.99994	14:18	57	Great question. And in general, every question that people have, they're going to be 100 times more impactful if they can be written down. This is just the second chapter. It's introducing us to the essence of starting with just Bayes equation. It's the first equation here, starting with the foundation of increasingly advanced noise filtering approaches.
883242	934334	29	A	0.9999	14:43	121	So check out Livestream 43 to see how colman filter and advanced multilevel Bayesian filtering schemes are used and learned and fit with free energy, minimization and so on. But you're right, that is not approached in this chapter because it's starting with the essence of Bayes equation and then going to build towards another kernel, which is going to be the kernel of the variational free energy. And then that in this one layer case is going to be able to be elaborated and parameterized and fit within nested models to accommodate, like, learning on hyperparameters, learning of noise models and so on. But it is not in this chapter. Okay, yeah, I'm sorry if I threw us off track.
934452	946530	30	A	0.99703	15:34	32	No, it's perfect. But they're good questions. And then Jacob asked, what do you think of the surprise, the distributions involving a sum product of the project, probability distributions, except for gamma.
951990	995120	31	E	0.99807	15:51	78	Actually, I guess the Gaussian kind of as well. Yeah, maybe I'm thinking about this wrong, but I thought that the surprise was like the information gain or equivalent. And so for the Gaussian and the gamma distributions, it's always for one single element of the distribution for one x. But for the multinomial and derivative lay, there's something over all of the possible probabilities, which makes it, I guess, an entropy function. But is there a difference?
1004440	1030590	32	A	1.0	16:44	61	For example, one could have a multidimensional Gaussian, a two dimensional Gaussian, and then the surprise for the two dimensional Gaussian would be represented as a sum over the different dimensions. So they've shown the Gaussian and the gamma in the uni dimensional case and the multinomial and the zero schlay in a multidimensional case. So in that case, is it.
1033280	1055190	33	A	1.0	17:13	55	I. Thought that x was just one element of the domain. So x is just if we think of the Gaussian as this kind of bell shaped curve on the x and y axis, we really want the f of x value to get like the Gaussian value, but x is just the input value.
1057720	1074670	34	E	0.87314	17:37	46	Is that correct? Believe I. That is accurate because, yes, x is the domain of the function and then the sum is over eyes. So if we had a multinomial Gaussian or multi dimensional Gaussian in I dimensions, then it would have a sum over eyes.
1077360	1128504	35	E	0.91608	17:57	94	Yeah, I guess I still have uncertainty about why we don't do that for the single dimensional Gaussian as well. Because if we take just one point on the Gaussian, I understand why that would have a certain surprise. But then in the same way, if we take one point in the Dirichlet distribution, shouldn't that also have an equivalent equation for surprise? Why in the Dirichlet distribution are we summing over all the eyes, but in the Gaussian we are considering just one point on the probability distribution? Or maybe Derishley is multidimensional.
1128552	1139970	36	A	1.0	18:48	22	And that's the reason I think the uni dimensional case would be just without this sigma I. It would just be this.
1142740	1152470	37	A	0.99999	19:02	29	But if anyone has any other thoughts, especially if they want to contribute them in writing to improve our understanding, that'd be awesome. Let's continue to the next question.
1155400	1183100	38	A	0.78435	19:15	65	In Section 2.4 they write we now introduce the simple but fundamental advance offered by active inference. This starts from the same inferential perspective discussed above, but extends it to consider action as inference. In your own words, what is the simple but fundamental advance offered by active inference? So what would anyone write or like to share? What is the advance of active inference?
1197660	1235960	39	F	0.74832	19:57	79	Sorry, is it just bringing action into the equation? So predictive coding and Bayesian brain are specifically about perception, visual perception. I think the key thing with active inference is that it's well, it's not just that it brings action into the equation, it's that it treats them as essentially the same thing, that they're kind of united as part of the same process, which I think is kind of a new development. Thanks for the awesome answer, Ali.
1240050	1286990	40	G	0.99677	20:40	70	Yeah, I think Alan Bartheau, or Bartho's in the brain's sense of movement, has a particularly relevant description of action and perception. And he writes that perception is simulated action. And I think that really speaks to the advance made by active inference. I mean the integration of action and perception. Or in other words, as Bartheau claims, the simulation of action and perception is, I guess, really novel development.
1290930	1319160	41	F	0.88	21:30	62	I think I read something, but I can't remember where I read it, but I think it was roughly that. On these existing Bayesian brain theories, an agent perceives in order to act, whereas under active inference an agent acts. Action kind of precedes perception. So active inference essentially flips this traditional schema in terms of which one feeds into the other.
1321550	1329020	42	B	0.98098	22:01	19	Yeah, I was just going to say that adding on to bringing action into the equation, it flips it.
1332430	1355460	43	B	0.99986	22:12	51	Where do your priorities come from? Where do the hyper parameters get specified? Where does the model start? Where is the agency kind of in all of these other models, really no affordance for that or it's hard to very emergent as here it's very explicitly specified. Some affordance for that.
1356150	1386480	44	A	0.99994	22:36	75	Thanks brock, Mike and then anyone else who raises their hand. Yeah, so I'm thinking if you have priors you have some prior assumptions, then do you necessarily need to take action in order to sort of envision what your perception might be? So it's almost like getting into imagination or something like that. You have a set of priors that can drive what you imagine your perception to be before any action is taken.
1392010	1394230	45	A	0.77295	23:12	3	Great question, Blue.
1397930	1421230	46	H	0.91714	23:17	39	So I think that this was elaborated on a lot in Section 2.7 when they talk about pursuing a policy because there's consequences when we're planning and making predictions, that has consequences for both our perception and our action.
1424610	1465040	47	H	0.99875	23:44	94	Even in a conversation when someone says, oh, have a nice day is expected at the end of that, but have a nice rabbit would be like, what? You're not expecting that to come at the end of that sentence. So when you plan, it interferes with your perception because you didn't plan for them to say have a nice rabbit. Right, but it also interferes with your action. And so I think the novelty or enhanced aspect of active inference loops into the fact that perception and action are continually impacting one another.
1467970	1470270	48	A	0.91	24:27	3	Yes. Thanks, Blue.
1472770	1496866	49	A	0.99984	24:32	59	These are some of the core memes and themes, and it really is important to understand how active inference is similar and different than other work in this area. Like variational. Bayesian inference is not introduced by active inference. Bayesian models of perception is not introduced by active inference. Bayesian models of action is not introduced by active inference.
1497058	1577570	50	A	0.9999	24:57	165	So it's about finding what has been done to understand what is being offered and then whether one chooses to take this, like, history of science, development of science view or we kind of just want to state plainly what it is without wondering what the advance relative to other frameworks is. These are all really critical ideas. Like the signal processing framework was brought up earlier and predictive processing, predictive coding, anticipatory systems are often purely about sense. And just to give one thought on that, it kind of makes sense for a video encoding algorithm, for example, because every piece of the camera is in focus, but vision requires action. And so that's where we're going to be bringing in all these other important concepts like attention, sensory attenuation, and the active decision making component of vision to resolve uncertainty, which is what gives rise to a generative visual field that seems like there's color everywhere and seems like there's high resolution everywhere.
1578070	1628210	51	A	0.99954	26:18	101	Though that is not the incoming sensory information. So by fully taking this generative modeling perspective on perception, which in live stream number 43.0, maria did an awesome job of connecting this even before Helmholtz and Kant. It's Plato's cave and it's part of this long discussion about perception. And action could be a variable. So there's perceiving and then if action is a variable, then active inference is providing not just a unified framework, like a Bayesian graph framework, for some variables that are interpreted as perception and some variables that can be interpreted as action selection or policy planning.
1630470	1660890	52	A	0.9958	27:10	60	But there's a tractable approximation by shifting from the in reading this answer, by shifting from an exact solution to the mathematical problem Bayesian inference to an approximate solution variational free energy, which is going to provide a bound on some quantity that might be intractable to compute. So it's going to give a heuristic for the action perception cycle.
1664050	1683250	53	A	0.99264	27:44	53	But this is a really great question. So people can continue to return to it because people will probably ask us for a long time to come, how is this different than blank? Or what is active inference? These are some of the things that we would want to have in mind. Ali.
1686230	1744070	54	G	0.99225	28:06	96	Yeah, again, going back to Bartheau and his definition of perception as simulated action, I think it also relates nicely to Merlopanti's phenomenology. Merlopanti has a famous statement and has a famous insight as vision is the brain's way of touching. And so you see, for instance, as we move around space, as we construct our sense of spatiality or our sense of temporality or everything else, we don't just begin with the representation of space or time. I mean, the image of movement constructs because we move and not as a consequence of our movement.
1746330	1775890	55	A	0.99993	29:06	62	Thanks. And we'll continue with the questions, but that's an awesome area to go into with phenomenology with four E cognition extended, embedded in culture, et cetera, et cetera. And many, many of the live streams and papers have been on those areas. So it's cool. It's a bridge from formal models of perception, cognition, and action into qualitative and philosophical areas.
1776550	1777300	56	A	0.99471	29:36	1	Okay.
1783590	1810730	57	A	0.9	29:43	54	And then oh, thanks, Morris, for adding that the idea of interrelated action and perception has been around in cognitive science for a long time, like dynamical systems theory and inactivism emphasize that. But active inference brings a coherent formalism to the table, which is a nice advance. Well said. Next question. Figure 2.2.
1819820	1828830	58	A	0.99976	30:19	22	Figure two. Two point illustrates Y as a result of an internal generative model X and an external generative process x star.
1833940	1847700	59	A	0.99936	30:33	36	In order to measure surprise, wouldn't we need another value of Y-I-E-A separate Y that encodes prior beliefs, if Y can be objectively measured from external signals? Is there a third Y that's considered the observation?
1855400	1922280	60	A	0.96	30:55	159	First, I'd like to actually go to this question about two notions of surprise because they might come to bear on this action perception loop. Once we move from just Bayes equation and calculating surprise on parametric distributions to thinking about prior updating and cognitive entities with a generative model that constitutes a prior, with incoming information coming in, we're going to start to see why this notion of surprise and Bayesian surprise are similar and different. So using the apple frog example so the unobserved hidden state, the latent state of the world, is whether there is an apple or a frog in a bag, for example, or just in this person's area. And then what can be observed, just speaking coarsely, is it can jump or not, and we can totally go down the rabbit hole with what is truly observed and things like that. But this is just what are in the context of this model.
1922350	1956736	61	A	0.96	32:02	88	The unobserved state is the actual identity of the object and the observation is going to be the action or not. We take the opportunity to unpack two different notions of surprise, both of which are important. The first we refer to simply as surprise. It's the negative log evidence where evidence is the marginal probability of observations. So we saw that first sense of surprise with the fracture I in the previous table we looked at the second notion of surprise is referred to as Bayesian Surprise.
1956928	2002230	62	A	0.8855	32:36	87	This is a measure of how much we have to update our beliefs following an observation. In other words, Bayesian Surprise quantifies the difference between a prior and a posterior of probability. What are the similarities and differences between the two notions of surprise? Okay, we'll see what has been said and then hear what other people are thinking. So, page 20, they wrote that Bayesian Surprise scores the amount of belief updating as opposed to surprise, which is simply how unlikely or likely that observation was.
2004760	2030030	63	A	0.99942	33:24	65	So in that Gaussian case, the surprise is like about one data point coming in. Given how the distribution is parameterized right now, how surprising was that one data point? And then Bayesian Surprise is going to be about how much that distribution is updated after processing that data point. Similarities? They both depend on how well the Agent's Generative model matches the external world.
2030640	2056720	64	A	1.0	33:50	64	And they're both measuring Surprise or Bayesian Surprise in the same units, which are information theoretic quantities of information, i, e. Nats or bits. Differences. Plain Surprise marginalizes over all the model's degrees of freedom under the model's prior distribution over its adjustable parameters that would be great for someone to unpack. What does it mean to marginalize over the model's degrees of freedoms?
2056880	2096096	65	A	1.0	34:16	78	And then Bayesian Surprise lets the model choose the best set of parameters it can to fit the observed data and then measures how much of an update that was Mike and then Blue and then Ali. Yeah. Under the first similarity, I'm wondering if it's this dependency on how well the Agents Generative model matches their perception of the external world as opposed to matches the external world. Agree with that. Great addition blue and then Ali.
2096208	2099540	66	E	0.95836	34:56	13	Okay. I think my hand was just left over. Left up. Okay. Ali?
2104040	2145940	67	G	0.99998	35:04	73	Well, I believe that the plain Surprise is a kind of raw statistical surprise, but Bayesian Surprise is a kind of surprise is a kind of processed surprise. Or I'm not sure if I'm right in saying that plain Surprise can probably be described as an objective surprise as opposed to Bayesian surprise prized as a subjective surprise. But as I said, I'm not sure about the plausibility of these descriptions. Great comments.
2147960	2173740	68	A	0.99996	35:47	49	Even the surprise alone still depends on the parameters of the generative model. So it still is within a processing or a filtering frame, albeit a fixed one. So they talk about like, let's look at the figure where there's a graphical overview of this apple and the frog.
2177200	2201344	69	A	0.67	36:17	66	And this is kind of giving some graphics and words to fill in this apple frog example. So initially the person has this likelihood model in the back of their head where they have beliefs about how likely apples are to jump. They do it 1% of the time and how likely frogs are to jump. They do it 81% of the time. That's the likelihood.
2201472	2230860	70	A	0.99995	36:41	66	That's about how observations depend on hidden states of the world. Their prior beliefs are that there's a 10% chance that the entity is a frog and these are mutually exclusive options. There's no third option here. That would be like another category model structure learning on the model. So we're staying within this model for now and they sum to one because they're a probability.
2231200	2251910	71	A	1.0	37:11	44	Then there's an observation which is jumping and then the posterior reflects the updated beliefs about what the entity is. And so it's like, it's so much overwhelmingly more likely that frogs jump that seeing something jump updates the prior from here to here.
2255080	2298710	72	A	0.99973	37:35	91	So in this case, one can calculate the surprise of the observation without doing any updating at all. One could just stay fixed in their prior belief and then could describe how surprised they are in Nats by given observation. In this full Bayesian cycle, there is an updating of the prior to the posterior and then that updating can be described in terms of how much the prior was updated. And so that's like here, the model is updated to the observed data. This is now the best fitting model.
2299800	2328430	73	A	1.0	38:19	57	And then we're calculating the difference between these two distributions. So regular surprise being zero means the data point was exactly as you expected. Bayesian surprise being zero means the distribution was not updated. High surprise means that the data point was extremely unpredicted. It was extremely unlikely whether or not you update your model at all.
2328880	2337680	74	A	0.97936	38:48	19	High Bayesian surprise means that the distribution was changed a lot as a function of seeing that happen. Ali.
2340260	2368920	75	G	0.8318	39:00	52	Well, perhaps I didn't understand it correctly, but isn't it the case that in the plain surprise or more generally in the Bayesian formulation of the probability of events, the likelihood and both the likelihood and the priors are somehow inherent to the phenomena inherent to the events, independent of the observers?
2371990	2418830	76	A	0.53056	39:31	102	Yeah, great question. I hope I'm not going off on a branch here, but this is related to the difference between frequentist and Bayesian approaches to statistics. So Frequentism does have viewed from the Bayesian perspective, frequentism does have priors. They're uniform priors, which are not uninformative priors, they just are uniform. And so in frequentism we come across like the maximum likelihood solution or the maximum likelihood parameter, which is just like, well, if all outcomes were equally a priori likely uniform prior, then we would just need to evaluate the likelihood and find the model with the maximum likelihood solution.
2419650	2468320	77	A	0.71352	40:19	110	Bayesian offers another degree of freedom and says, well, sure, you could pick a uniform prior that would give you the maximum likelihood solution. Or you might want to have a prior distribution over that space so that if something is twice as likely a priori and then you observe less than two X evidence for it, you still might want like the Bayes factor or your posterior to reflect that one rather than just jumping instantly to a different maximum likelihood solution. So yes, priors and likelihood are implicit, but they're using a different ontology than Bayesian statistics. But we're in the bays or the post bays area now.
2471830	2498620	78	A	0.99978	41:11	52	But there's so many connections to classical statistics and in SPM, the textbook there is parametric classical statistics, non parametric classical statistics, and Bayesian statistics. So they're more similar than not. It just is about seeing where one of them is like a special case of another or a generalization of another.
2505070	2511870	79	A	0.70426	41:45	15	Okay, let's see if we can do one or two more questions during this session.
2514050	2550890	80	A	0.99272	41:54	73	Okay, so let's return to the previous question. So we're looking at figure two, which is something we're going to see different representations of this entity as generative model, world or niche as generative process. And then here the hidden states are those that are unobserved as data. Y is referring to data points that are observed as data. There's a cognitive hidden state which is like a prior in this generative model.
2551040	2578782	81	A	0.7	42:31	57	And then there's some hidden state x star. But it could have been any letter or any shape about the hidden state in the world. The observation is going to everything that happens in between. Here is cognition, like the sandwich model, like sense, think, act. That type of model is just referring to that little boomerang.
2578846	2604780	82	A	0.99999	42:58	45	Data come in cognitive processing, action selection. So we're in that figure. The question was, in order to measure surprise, wouldn't we need another value of Y-I-E-A separate Y that enclose prior belief? Great question. Let's just assume that there is a Gaussian generative model.
2605150	2640600	83	A	0.99984	43:25	67	So the entity has like two parameters in its cognitive model, the mean and the variance. Then Y comes in and given the parameterization of the generative model, all that's needed is the data point to come in for the surprise to be calculated. So another value is needed. But whether we call it ABC XYZ is just a mathematical abstraction. So yes, prior beliefs are important.
2641130	2686778	84	A	1.0	44:01	92	The prior beliefs that can be interpreted as the parameterizations of the cognitive model are required if Y can be objectively measured from external signals. Is there a third Y. That is considered the observation. So one could imagine a lot of like, real world scenarios where a more complex model would be required, two people looking at the thermometer or all these different sorts of situations. But unless somebody can unpack this a little more or explain what they were asking about, then I don't think a third why is required.
2686874	2718840	85	C	0.99971	44:46	72	Mike yeah, it was my question, so I can try and unpack it. And so sticking with the thermometer example at the heart of that last question is, if we have a thermometer that's registering the temperature, can we consider that as sort of the true observation that is the actual Y as measured by this instrument? And then therefore we can compare our sort of internal Y with the actual Y?
2723070	2759410	86	H	0.95421	45:23	83	Okay, so I have a really similar and related question that's like two questions down, but it's in a different section. But let me just place some things on here and it goes back to what we were saying about what exactly is the hidden state. So is the hidden state the temperature and the data is reading from the thermometer that's like the data Y, right? Like this Y in the middle. But then what is how I feel hot or cold?
2759750	2781194	87	H	0.74461	45:59	76	I'm perfectly positioned to be at 75 all the time. So I know if it's like one degree too cold or one degree too hot, I've got to turn up the heat or turn it down or whatever. But my registration, my sensory input is not at 75 degrees. My sensory input is I'm hot or I'm cold. And so this is like where I mean, we were talking about this yesterday in the math group.
2781312	2795040	88	H	0.9819	46:21	48	There's this really fuzzy line for me. I would love for someone to clarify that. So I do get what you mean about this. Shouldn't there be another why? There's the why out there in the world, 75 degrees and then there's how I feel about that why.
2796850	2828518	89	A	0.94012	46:36	67	Okay, thanks. So variables are not like, innately tagged with being observables or hidden states. It's a model specific framing of what is going to be modeled as generated data and what is going to be modeled as a Bayesian prior. In multilevel Bayesian modeling, the priors themselves are generated from a higher or deeper level of the. So one can be serving, in fact, multiple roles.
2828614	2862870	90	A	0.64823	47:08	78	This is the minimal prior generated data expectation maximization type, single layer Bayesian kernel. So we're going to think about this temperature example. There's a hidden state of the generative process which is going to be the temperature of the world latent unmodeled. So this isn't even claiming that there is such a thing as temperature. This is just a latent unobserved temperature that is giving rise to thermometer readings, which might have, like, different sorts of noise.
2864090	2875210	91	A	0.99998	47:44	18	Then there's another hidden state, which is the evaluation of temperature. And so this is just a schematic.
2877230	2902020	92	A	0.99	47:57	51	And also, whether one is labeled x or Y or L or triangle is like a norm and a convenience. But the letter doesn't matter itself. It will be used mostly consistently within the textbook. But there's only so many letters and there's not a lot of coherence on notation use.
2908740	2911010	93	A	1.0	48:28	6	What else could be explored here?
2914680	2916820	94	A	0.99867	48:34	5	Yeah. Mike and then Ali.
2919320	2960384	95	C	0.90809	48:39	106	So as I keep ruminating on this, which is probably more than I should, it seems like there can be infinite wise, right? So to the extent that you are taking action which will change your perception, then you are as a result triggering potentially new Y's in the system, right? So you just have this infinite potential for what Y can be. This speaks to the composability and the flexibility of active inference. So like Y could be one pixel of visual input, it could be a 4K video, y could be smell and a 4K video, y could be LiDAR and this and that.
2960422	2990350	96	A	0.93678	49:20	80	So Y is just the generalized input of sense and then action might be related to this in a very direct way. Like Y could be visual input and action could be your eye movement. So that case is going to be explored a lot in the book. However, it could also be you're getting something in and then the actions are just totally unrelated. Maybe they don't affect the hidden state, the causal process in the world at all.
2990880	3008800	97	A	1.0	49:50	27	Or maybe actions enable different wise to enter the picture. This is just the total essence kernel and then even trivial cases require some more apparatus. Ali?
3011460	3042780	98	A	0.99616	50:11	49	Yeah. I have a question. Is it correct to say that the minimization of variation of free energy, aka the Surprise is exactly equivalent to the maximization of expectation, the wholly linear relationship between these two? Or possibly we have some kind of plateaued areas between these two extremes?
3046130	3080454	99	A	0.99743	50:46	69	Great question. So this is something that we'll come to next week in our discussions on chapter two. So we have not even discussed variational free energy yet today. We talked about starting with a low road on some of the atomic calculations that are going to come into play, like Surprise and Bayesian. Surprise in a Bayesian framework and beginning to partition active entities and their action perception.
3080502	3109682	100	A	0.99982	51:20	66	Loops in terms of a Bayesian graph that's going to be amenable to flexible modeling of perceptive, cognitive active and out there in the world variables. Variables with those interpretations. And then variational free energy is going to come into play as a way to bound surprise. So let's have some questions and discourse and we'll come to it next week. But it's an awesome question.
3109816	3110850	101	A	0.96892	51:49	1	Jessica?
3113430	3166982	102	I	0.9801	51:53	111	Hi. Yes, I have a question, I guess related to this figure 2.2, let's say, in regards to how we interpret what we observe. So I understand you have a prior that might you're anticipating something like some other people's behavior or how things should be that might be different from what you actually observe. But a lot of times, at least in terms of when we're thinking like human beings, an action in the world, how you interpret it has to do a lot with your own views or your own experiences. And maybe that connects to the priors, but the interpretation might be very different from people to people.
3167036	3213170	103	I	1.0	52:47	87	The interpretation will vary a lot because everybody has different experiences. So those could be encoded, I guess, in the priors, but it's not connected per se to the prediction part. Or maybe it is. So I'm trying to kind of connect that idea of our personal interpretation based on our experiences, which could be priors, make us see what's happening in the world differently than other people. So that why will look very different for you than for me, just because we have lived different experiences.
3213830	3225560	104	I	0.99984	53:33	25	So it's not like an actual why. You cannot really say this is a fact because it's an interpretation. At the end of the day.
3228830	3266690	105	A	0.99863	53:48	70	Great question and points. Yeah. Understanding how the individual setup of a given entity is related to its past experiences and how that could be modeled by priors is an important area. And some of those rich dynamics are not in this minimal nucleus. But it'll be awesome to start to think about what does have to be in the box here to give rise to those kinds of dynamics.
3270170	3302062	106	A	0.99639	54:30	60	So that's going to end this discussion next week. We will also be staying in chapter two and taking it more towards variational free energy and expected free energy. So that should be fun. We're going to in this room transfer immediately to the Tools meeting. So if you want to join for active Lab Tools meeting, everyone is welcome.
3302116	3327710	107	A	1.0	55:02	72	And there's no prerequisites or anything like that. If you want to hang around and join Tools, stay in this exact gather space. If you want to continue talking with other people about the book or anything else, just head up into one of the rooms above. And if anyone who wants to can just continue any discussion that they want. But in this space we're going to continue now with Tools.
3327870	3330550	108	A	0.99614	55:27	4	So thanks everyone. Bye.
