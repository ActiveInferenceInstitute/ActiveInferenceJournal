start	end	sentNum	speaker	confidence	text
1450	2254	1	A	0.76001	Hello, everyone.
2372	4990	2	A	0.58249	It's May 26, 2022.
5060	10238	3	A	0.99381	It's the fourth week of the first cohort of the active textbook group.
10404	15710	4	A	0.99843	We're in our first discussion of chapter two today.
15780	21280	5	A	0.9911	We're going to go over the questions that are posted for chapter two.
21810	27826	6	A	0.99998	Then we'll see where that takes us and what ID of the book have been explored.
28018	30520	7	A	0.63	And that'll be the main focus.
31450	39286	8	A	0.99999	Also, just a note on the math learning group, those meetings have been occurring on 19 UTC on Wednesdays.
39478	44170	9	A	1.0	And so in the math learning group, you'll find information about how to participate.
45870	50678	10	A	0.99767	You'll find and be able to edit resources on learning different topics.
50854	61840	11	A	0.9995	So this is a really helpful activity if people want to share the resources that help them learn about different ideas and that'll help people search for a video about this.
62790	69220	12	A	0.99998	We have a notation table that will help us as we start to look at the notation more.
69910	81878	13	A	0.97443	There's some math learning basic questions, like around math, anything related to the textbook content can go in the main questions.
81964	84854	14	A	0.89076	Math learning group is part of the real textbook group.
84972	91606	15	A	0.99998	So these are not the questions to be answered like the other ones that we're going to go to are, but this is just about math.
91718	95414	16	A	1.0	And then also there's some math oriented overviews.
95542	99798	17	A	0.99787	Like, I wrote this summary of the first two thirds of chapter two.
99984	108560	18	A	0.99849	So if people want to be like, continuing to distill and represent what they're learning and what they're asking, that's all good.
108930	117140	19	A	0.99769	Okay, any other notes that anybody wants to add before we start to go into the questions?
118470	121410	20	A	0.99638	You can raise your hand or you can type it in the chat.
125450	133858	21	A	0.99527	Okay, so we're in the first week of discussing chapter two, the low Road to active inference.
134034	139960	22	A	0.94448	So just to kind of warm us up, what is the low road?
174160	174524	23	B	0.5678	Got?
174562	179740	24	B	0.98	A low road is the Bayesian Brain approach.
179820	192164	25	B	0.99795	Right here is the Proximate next big concept, I guess previous, but it's kind of based on I guess.
192202	196080	26	B	0.86254	Yeah, I mean, you can see right in the picture, it's based on basing it's like mathematical.
196240	226188	27	B	1.0	The way I conceptualize it is like literally the low road, meaning very primitive, very mathematical, very hyper analytical, foundational, kind of an analysis way of looking at it, I guess that's not necessarily living or anything like that.
226274	226910	28	B	0.89024	Right?
231690	236280	29	B	0.53878	Whereas the high road is kind of more about the other side of that.
239850	240760	30	B	0.86	All right.
242490	247322	31	A	0.90633	Okay, so we're going to be learning about the high road and low road.
247376	251594	32	A	0.99968	Those are the two paths that are offered in chapter two and three of the book.
251712	264430	33	A	0.56531	So hopefully, again, it would be awesome to have as many people as possible speak and feel welcome to share their views during this session.
264850	278814	34	A	0.99831	So everyone is especially encouraged to put questions or comments in the chat or raise their hand to speak or find other times to have synchronous communications and especially to make contributions to the coda.
278862	284280	35	A	0.7826	But really appreciate that everyone has come out to go through these discussion questions.
284810	291186	36	A	0.99833	So we're going to now go to the questions that have been placed into the questions table.
291378	296274	37	A	1.0	And just the more questions, the better they can be super short.
296412	299178	38	A	0.99862	It can be anything that you're having uncertainty about.
299344	306560	39	A	0.99999	If you come across a table or a figure or a sentence in the text and you have a question, please write the question down.
307010	310030	40	A	0.99996	It will be extremely, extremely helpful.
311410	317898	41	A	0.99999	It doesn't have to be with extensive references or citations.
317994	329774	42	A	0.99999	It can just be what does this mean if you're uncertain about something and then if you were certain about it, you could still write a question like what would you ask somebody to test or to understand what they understood about it?
329912	337222	43	A	0.99554	Okay, so we're going to start with this first most upvoted question.
337356	348618	44	A	0.97949	But there's still time in this session and also till next week in our next session on chapter two, to add more questions if you wrote them down somewhere else and also to upvote questions.
348704	352540	45	A	0.99822	But we're just going to start with the most interestingly voted questions.
355970	365200	46	A	0.66498	What is the relevance of the support and surprise for the different probability distributions in table 2.1?
368070	388978	47	A	0.54224	So what does anyone see in table 2.1 and what are support and surprise people?
389084	390140	48	A	0.90517	Mike yes.
394430	403050	49	C	0.91491	So table 2.1 looks to me like a guide for selecting distributions.
403210	415054	50	C	0.99999	If you're building out one of these models with support saying what set of numbers would fit within this distribution selection?
415102	420740	51	C	1.0	And then if you chose this distribution, how would you look at the support equation for it?
423590	427222	52	A	0.99871	Can you unpack with a surprise part?
427356	428040	53	C	0.55946	Yeah.
428730	433000	54	C	0.99998	If you chose this distribution, how would you look at the surprise component of it?
442360	447430	55	A	0.98	And we're going to get to surprise and Bayesian surprise in the coming questions.
448040	463464	56	A	0.67988	So support using the definition pulled here from Wikipedia, the support of the function is the subset of the x axis, like the domain where there's a y value that's not zero.
463582	467080	57	A	0.99999	So it's where the function is nonzero defined.
468060	478844	58	A	1.0	The Gaussian, the normal Belker of distribution, has nonzero support at all numbers.
479042	489280	59	A	0.56147	Fancy r and then other distributions have different variable, different values that they're having non zero values at.
489350	494424	60	A	0.99893	Like the gamma distribution is defined over the interval from zero to infinity.
494572	503270	61	A	0.99904	So if it was like how many of this thing do you have that might be a reason to use a distribution that's only positive numbers?
503960	526460	62	A	1.0	Or if you were wanting something that could have positive or negative numbers of any size, the Gaussian is a distribution and then another one that's like a relevant support difference would be like the deer Schlee being defined only within the zero to one interval, which helps connect it to probabilities.
526880	534156	63	A	0.9997	So the support is where that function, that distribution family is defined.
534348	537920	64	A	1.0	And then what is the surprise?
557450	561510	65	A	0.84739	Does anyone know the name of the little squiggle they are using to represent surprise?
562330	588560	66	A	0.99	I think it's called Fracture i, aka fancy eye.
598200	615080	67	A	0.99657	We're going to come to the definition of surprise in a coming question and without going into every variable and trying to overlearn something, the surprise of a given observation, like a data point, let's just think about the Gaussian.
615740	626152	68	A	1.0	X is the observed data point and Mu is like the mean of that normal distribution, which is also the mode.
626216	628780	69	A	0.99533	So it's like the center of that distribution.
629200	635296	70	A	1.0	And then this capital pi is a variance estimator, I believe here.
635478	645250	71	A	0.99989	So how surprised one should be by a new data point coming in is related to the difference between that new data point and the mean.
646100	653428	72	A	0.99986	So if the new data point were exactly on the center of the distribution, this whole term is going to go to zero.
653594	659920	73	A	0.99999	So one should not be surprised at all by exact data points on the mean of the distribution.
660000	674620	74	A	0.99998	But any data point that has not exactly on the mean is going to have some non zero value and so it's going to be a function of how far the data point is from the mean and some scaling by the variance.
675040	687392	75	A	0.99984	So if we were expecting 100 with a variance of ten versus 100 with a variance of one in one case, like getting 101 is like a one sigma event.
687446	689090	76	A	0.99998	It has a z score of one.
689620	699620	77	A	1.0	Just speaking loosely here, whereas in the case of it having a variance that's very small, then that might be more surprising.
705130	710940	78	A	0.99987	Any other comments that people have on Table 2.1?
712270	714140	79	D	1.0	I have a question.
715310	716060	80	A	0.97193	Yeah.
717550	729150	81	D	0.84396	So while I was reading through the chapter going back to section 2.2, right, perception as inference.
729570	738180	82	D	0.99718	So when he says, when they say that the brain is a predictive machine or a statistical organ, that infers external states of the world.
739830	744850	83	D	0.99758	Okay, here's my question, because I'm primarily from a telecom background.
745190	755094	84	D	0.99349	So most of our things are to get messages crossed between two distant transmitters receiver, right?
755212	757106	85	D	0.74602	So we build noise models.
757138	760806	86	D	0.99555	So without any noise you don't get signal.
760918	764060	87	D	0.99996	So you need to know what noise model looks like.
766670	775454	88	D	1.0	For example, if the power spectrum of the signal is what you expect from, let's say we are using a Gaussian distribution of noise, right?
775572	781182	89	D	0.99988	So if it's the same as you expect from the Gaussian, you do nothing.
781236	782202	90	D	0.99773	So that's just noise.
782266	785040	91	D	0.99999	So you don't classify the data point that's coming in.
785890	792146	92	D	0.99999	If it is more than this, then okay, so there might be something interesting about this.
792168	793234	93	D	0.99989	There might be some signal here.
793272	795810	94	D	0.96353	So we define that signal to noise ratio.
796470	805800	95	D	0.57	A lot of this chapter seems to be dealing with the fact that we by default know what the signal looks like.
806250	809240	96	D	0.99995	So there's no attempt to build a noise model here.
809630	832478	97	D	0.6833	That would be like, okay, so maybe the sensor in this case, our eyes for example, has some parameters it can detect between, say, a bandwidth, okay, so it can detect light between certain frequency ranges, but maybe it performs very well in a certain frequency range and not others.
832564	836498	98	D	0.72615	There's more error in other frequency ranges, right?
836584	847006	99	D	0.99995	So the noise model should incorporate such things, imperfections in the sensor, imperfections in the connections between the sensor and processing equipment.
847198	849826	100	D	0.99993	But there's no attempt to do that in this entire chapter.
849858	855734	101	D	0.99817	So I'm just curious as to what exactly is the predictive machine here?
855932	857800	102	D	0.99994	What is being predicted here?
858810	859686	103	A	0.99994	Great question.
859788	866700	104	A	0.98	And in general, every question that people have, they're going to be 100 times more impactful if they can be written down.
867870	869622	105	A	0.99992	This is just the second chapter.
869686	874666	106	A	0.96601	It's introducing us to the essence of starting with just Bayes equation.
874858	883194	107	A	0.99921	It's the first equation here, starting with the foundation of increasingly advanced noise filtering approaches.
883242	894754	108	A	0.9999	So check out Livestream 43 to see how colman filter and advanced multilevel Bayesian filtering schemes are used and learned and fit with free energy, minimization and so on.
894792	911100	109	A	1.0	But you're right, that is not approached in this chapter because it's starting with the essence of Bayes equation and then going to build towards another kernel, which is going to be the kernel of the variational free energy.
912670	926878	110	A	1.0	And then that in this one layer case is going to be able to be elaborated and parameterized and fit within nested models to accommodate, like, learning on hyperparameters, learning of noise models and so on.
926964	928830	111	A	0.99997	But it is not in this chapter.
929890	934334	112	D	0.99724	Okay, yeah, I'm sorry if I threw us off track.
934452	935860	113	A	0.99703	No, it's perfect.
936310	937922	114	A	0.53975	But they're good questions.
937976	946530	115	A	0.92	And then Jacob asked, what do you think of the surprise, the distributions involving a sum product of the project, probability distributions, except for gamma.
951990	955140	116	E	0.99807	Actually, I guess the Gaussian kind of as well.
956950	970290	117	E	0.73508	Yeah, maybe I'm thinking about this wrong, but I thought that the surprise was like the information gain or equivalent.
970450	982506	118	E	0.97	And so for the Gaussian and the gamma distributions, it's always for one single element of the distribution for one x.
982688	990560	119	E	0.99999	But for the multinomial and derivative lay, there's something over all of the possible probabilities, which makes it, I guess, an entropy function.
991330	995120	120	E	0.83289	But is there a difference?
1004440	1019396	121	A	1.0	For example, one could have a multidimensional Gaussian, a two dimensional Gaussian, and then the surprise for the two dimensional Gaussian would be represented as a sum over the different dimensions.
1019508	1027790	122	A	0.99996	So they've shown the Gaussian and the gamma in the uni dimensional case and the multinomial and the zero schlay in a multidimensional case.
1028320	1030590	123	E	0.96773	So in that case, is it.
1033280	1033596	124	A	1.0	I.
1033618	1037100	125	E	0.91349	Thought that x was just one element of the domain.
1038320	1055190	126	E	0.58636	So x is just if we think of the Gaussian as this kind of bell shaped curve on the x and y axis, we really want the f of x value to get like the Gaussian value, but x is just the input value.
1057720	1058356	127	E	0.87314	Is that correct?
1058362	1058600	128	A	0.91045	Believe I.
1058670	1065210	129	A	0.99999	That is accurate because, yes, x is the domain of the function and then the sum is over eyes.
1066700	1074670	130	A	0.99983	So if we had a multinomial Gaussian or multi dimensional Gaussian in I dimensions, then it would have a sum over eyes.
1077360	1088144	131	E	0.91608	Yeah, I guess I still have uncertainty about why we don't do that for the single dimensional Gaussian as well.
1088182	1097824	132	E	0.99986	Because if we take just one point on the Gaussian, I understand why that would have a certain surprise.
1097872	1109860	133	E	0.9999	But then in the same way, if we take one point in the Dirichlet distribution, shouldn't that also have an equivalent equation for surprise?
1110760	1122780	134	E	0.99924	Why in the Dirichlet distribution are we summing over all the eyes, but in the Gaussian we are considering just one point on the probability distribution?
1123600	1128504	135	E	1.0	Or maybe Derishley is multidimensional.
1128552	1137090	136	A	1.0	And that's the reason I think the uni dimensional case would be just without this sigma I.
1138420	1139970	137	A	0.99975	It would just be this.
1142740	1150468	138	A	0.99999	But if anyone has any other thoughts, especially if they want to contribute them in writing to improve our understanding, that'd be awesome.
1150634	1152470	139	A	0.99839	Let's continue to the next question.
1155400	1160948	140	A	0.78435	In Section 2.4 they write we now introduce the simple but fundamental advance offered by active inference.
1161044	1166920	141	A	0.9506	This starts from the same inferential perspective discussed above, but extends it to consider action as inference.
1167980	1172700	142	A	0.99891	In your own words, what is the simple but fundamental advance offered by active inference?
1174240	1179470	143	A	0.87945	So what would anyone write or like to share?
1180800	1183100	144	A	0.99999	What is the advance of active inference?
1197660	1201176	145	F	0.74832	Sorry, is it just bringing action into the equation?
1201368	1210700	146	F	0.98569	So predictive coding and Bayesian brain are specifically about perception, visual perception.
1211940	1229540	147	F	1.0	I think the key thing with active inference is that it's well, it's not just that it brings action into the equation, it's that it treats them as essentially the same thing, that they're kind of united as part of the same process, which I think is kind of a new development.
1231420	1235960	148	A	0.9993	Thanks for the awesome answer, Ali.
1240050	1254702	149	G	0.99677	Yeah, I think Alan Bartheau, or Bartho's in the brain's sense of movement, has a particularly relevant description of action and perception.
1254846	1259746	150	G	1.0	And he writes that perception is simulated action.
1259938	1267634	151	G	1.0	And I think that really speaks to the advance made by active inference.
1267682	1272170	152	G	1.0	I mean the integration of action and perception.
1272510	1286990	153	G	0.67	Or in other words, as Bartheau claims, the simulation of action and perception is, I guess, really novel development.
1290930	1297874	154	F	0.88	I think I read something, but I can't remember where I read it, but I think it was roughly that.
1297992	1308050	155	F	0.99987	On these existing Bayesian brain theories, an agent perceives in order to act, whereas under active inference an agent acts.
1308410	1311106	156	F	0.99027	Action kind of precedes perception.
1311298	1319160	157	F	0.99987	So active inference essentially flips this traditional schema in terms of which one feeds into the other.
1321550	1329020	158	B	0.98098	Yeah, I was just going to say that adding on to bringing action into the equation, it flips it.
1332430	1333626	159	B	0.99986	Where do your priorities come from?
1333648	1335754	160	B	0.9998	Where do the hyper parameters get specified?
1335882	1338590	161	B	0.99935	Where does the model start?
1338740	1352610	162	B	0.99999	Where is the agency kind of in all of these other models, really no affordance for that or it's hard to very emergent as here it's very explicitly specified.
1353830	1355460	163	B	0.99894	Some affordance for that.
1356150	1359880	164	A	0.99994	Thanks brock, Mike and then anyone else who raises their hand.
1361690	1375738	165	C	0.9969	Yeah, so I'm thinking if you have priors you have some prior assumptions, then do you necessarily need to take action in order to sort of envision what your perception might be?
1375824	1378426	166	C	0.91578	So it's almost like getting into imagination or something like that.
1378448	1386480	167	C	0.99869	You have a set of priors that can drive what you imagine your perception to be before any action is taken.
1392010	1394230	168	A	0.77295	Great question, Blue.
1397930	1421230	169	H	0.91714	So I think that this was elaborated on a lot in Section 2.7 when they talk about pursuing a policy because there's consequences when we're planning and making predictions, that has consequences for both our perception and our action.
1424610	1434740	170	H	0.99875	Even in a conversation when someone says, oh, have a nice day is expected at the end of that, but have a nice rabbit would be like, what?
1435270	1439890	171	H	0.99989	You're not expecting that to come at the end of that sentence.
1440050	1446434	172	H	0.89755	So when you plan, it interferes with your perception because you didn't plan for them to say have a nice rabbit.
1446482	1450374	173	H	0.99638	Right, but it also interferes with your action.
1450422	1465040	174	H	1.0	And so I think the novelty or enhanced aspect of active inference loops into the fact that perception and action are continually impacting one another.
1467970	1468814	175	A	0.91	Yes.
1469012	1470270	176	A	0.99979	Thanks, Blue.
1472770	1482978	177	A	0.99984	These are some of the core memes and themes, and it really is important to understand how active inference is similar and different than other work in this area.
1483064	1484366	178	A	0.99927	Like variational.
1484398	1488050	179	A	0.99837	Bayesian inference is not introduced by active inference.
1488570	1492674	180	A	0.92185	Bayesian models of perception is not introduced by active inference.
1492802	1496866	181	A	0.9926	Bayesian models of action is not introduced by active inference.
1497058	1519262	182	A	0.9999	So it's about finding what has been done to understand what is being offered and then whether one chooses to take this, like, history of science, development of science view or we kind of just want to state plainly what it is without wondering what the advance relative to other frameworks is.
1519396	1521418	183	A	0.99999	These are all really critical ideas.
1521514	1535860	184	A	0.99781	Like the signal processing framework was brought up earlier and predictive processing, predictive coding, anticipatory systems are often purely about sense.
1536550	1551050	185	A	1.0	And just to give one thought on that, it kind of makes sense for a video encoding algorithm, for example, because every piece of the camera is in focus, but vision requires action.
1551870	1577570	186	A	1.0	And so that's where we're going to be bringing in all these other important concepts like attention, sensory attenuation, and the active decision making component of vision to resolve uncertainty, which is what gives rise to a generative visual field that seems like there's color everywhere and seems like there's high resolution everywhere.
1578070	1581540	187	A	0.99954	Though that is not the incoming sensory information.
1582150	1598338	188	A	0.78693	So by fully taking this generative modeling perspective on perception, which in live stream number 43.0, maria did an awesome job of connecting this even before Helmholtz and Kant.
1598514	1604970	189	A	0.9007	It's Plato's cave and it's part of this long discussion about perception.
1605310	1608170	190	A	0.53	And action could be a variable.
1608830	1628210	191	A	0.74612	So there's perceiving and then if action is a variable, then active inference is providing not just a unified framework, like a Bayesian graph framework, for some variables that are interpreted as perception and some variables that can be interpreted as action selection or policy planning.
1630470	1655450	192	A	0.9958	But there's a tractable approximation by shifting from the in reading this answer, by shifting from an exact solution to the mathematical problem Bayesian inference to an approximate solution variational free energy, which is going to provide a bound on some quantity that might be intractable to compute.
1655950	1660890	193	A	0.97071	So it's going to give a heuristic for the action perception cycle.
1664050	1667214	194	A	0.99264	But this is a really great question.
1667412	1677006	195	A	0.93006	So people can continue to return to it because people will probably ask us for a long time to come, how is this different than blank?
1677118	1679214	196	A	1.0	Or what is active inference?
1679342	1682306	197	A	0.99997	These are some of the things that we would want to have in mind.
1682408	1683250	198	A	0.83677	Ali.
1686230	1699746	199	G	0.99225	Yeah, again, going back to Bartheau and his definition of perception as simulated action, I think it also relates nicely to Merlopanti's phenomenology.
1699778	1709610	200	G	0.43242	Merlopanti has a famous statement and has a famous insight as vision is the brain's way of touching.
1710270	1733540	201	G	0.82	And so you see, for instance, as we move around space, as we construct our sense of spatiality or our sense of temporality or everything else, we don't just begin with the representation of space or time.
1733910	1744070	202	G	0.96	I mean, the image of movement constructs because we move and not as a consequence of our movement.
1746330	1746934	203	A	0.99993	Thanks.
1747052	1761046	204	A	0.68	And we'll continue with the questions, but that's an awesome area to go into with phenomenology with four E cognition extended, embedded in culture, et cetera, et cetera.
1761238	1765754	205	A	1.0	And many, many of the live streams and papers have been on those areas.
1765882	1766654	206	A	0.88801	So it's cool.
1766692	1775890	207	A	0.38879	It's a bridge from formal models of perception, cognition, and action into qualitative and philosophical areas.
1776550	1777300	208	A	0.99471	Okay.
1783590	1801220	209	A	0.9	And then oh, thanks, Morris, for adding that the idea of interrelated action and perception has been around in cognitive science for a long time, like dynamical systems theory and inactivism emphasize that.
1801290	1805428	210	A	0.99984	But active inference brings a coherent formalism to the table, which is a nice advance.
1805604	1806570	211	A	0.99759	Well said.
1807660	1808824	212	A	0.97877	Next question.
1809022	1810730	213	A	0.97696	Figure 2.2.
1819820	1820427	214	A	0.99976	Figure two.
1820427	1828830	215	A	1.0	Two point illustrates Y as a result of an internal generative model X and an external generative process x star.
1833940	1844944	216	A	0.99936	In order to measure surprise, wouldn't we need another value of Y-I-E-A separate Y that encodes prior beliefs, if Y can be objectively measured from external signals?
1844992	1847700	217	A	0.99996	Is there a third Y that's considered the observation?
1855400	1870404	218	A	0.96	First, I'd like to actually go to this question about two notions of surprise because they might come to bear on this action perception loop.
1870452	1893936	219	A	0.99999	Once we move from just Bayes equation and calculating surprise on parametric distributions to thinking about prior updating and cognitive entities with a generative model that constitutes a prior, with incoming information coming in, we're going to start to see why this notion of surprise and Bayesian surprise are similar and different.
1894038	1908470	220	A	0.96596	So using the apple frog example so the unobserved hidden state, the latent state of the world, is whether there is an apple or a frog in a bag, for example, or just in this person's area.
1908920	1919128	221	A	1.0	And then what can be observed, just speaking coarsely, is it can jump or not, and we can totally go down the rabbit hole with what is truly observed and things like that.
1919214	1922280	222	A	0.99997	But this is just what are in the context of this model.
1922350	1929116	223	A	0.96	The unobserved state is the actual identity of the object and the observation is going to be the action or not.
1929298	1933810	224	A	0.99998	We take the opportunity to unpack two different notions of surprise, both of which are important.
1934500	1937840	225	A	0.82	The first we refer to simply as surprise.
1938180	1943836	226	A	0.99972	It's the negative log evidence where evidence is the marginal probability of observations.
1944028	1956736	227	A	0.99997	So we saw that first sense of surprise with the fracture I in the previous table we looked at the second notion of surprise is referred to as Bayesian Surprise.
1956928	1962920	228	A	0.8855	This is a measure of how much we have to update our beliefs following an observation.
1963340	1968920	229	A	0.85308	In other words, Bayesian Surprise quantifies the difference between a prior and a posterior of probability.
1970000	1973500	230	A	0.99997	What are the similarities and differences between the two notions of surprise?
1975440	1980830	231	A	0.98348	Okay, we'll see what has been said and then hear what other people are thinking.
1982740	2002230	232	A	0.9779	So, page 20, they wrote that Bayesian Surprise scores the amount of belief updating as opposed to surprise, which is simply how unlikely or likely that observation was.
2004760	2010152	233	A	0.99942	So in that Gaussian case, the surprise is like about one data point coming in.
2010286	2016792	234	A	0.99976	Given how the distribution is parameterized right now, how surprising was that one data point?
2016926	2025116	235	A	1.0	And then Bayesian Surprise is going to be about how much that distribution is updated after processing that data point.
2025298	2026024	236	A	0.99987	Similarities?
2026072	2030030	237	A	0.99996	They both depend on how well the Agent's Generative model matches the external world.
2030640	2039152	238	A	1.0	And they're both measuring Surprise or Bayesian Surprise in the same units, which are information theoretic quantities of information, i, e.
2039206	2040524	239	A	0.8627	Nats or bits.
2040652	2041292	240	A	0.76232	Differences.
2041356	2052784	241	A	0.70221	Plain Surprise marginalizes over all the model's degrees of freedom under the model's prior distribution over its adjustable parameters that would be great for someone to unpack.
2052832	2056720	242	A	1.0	What does it mean to marginalize over the model's degrees of freedoms?
2056880	2072600	243	A	1.0	And then Bayesian Surprise lets the model choose the best set of parameters it can to fit the observed data and then measures how much of an update that was Mike and then Blue and then Ali.
2073520	2073932	244	A	0.9981	Yeah.
2073986	2086690	245	C	0.99906	Under the first similarity, I'm wondering if it's this dependency on how well the Agents Generative model matches their perception of the external world as opposed to matches the external world.
2088260	2089072	246	A	1.0	Agree with that.
2089126	2096096	247	A	0.9996	Great addition blue and then Ali.
2096208	2096532	248	E	0.95836	Okay.
2096586	2097844	249	H	1.0	I think my hand was just left over.
2097882	2098324	250	H	0.97926	Left up.
2098362	2098708	251	A	0.99906	Okay.
2098794	2099540	252	A	0.68425	Ali?
2104040	2117300	253	G	0.99998	Well, I believe that the plain Surprise is a kind of raw statistical surprise, but Bayesian Surprise is a kind of surprise is a kind of processed surprise.
2117380	2133772	254	G	0.95	Or I'm not sure if I'm right in saying that plain Surprise can probably be described as an objective surprise as opposed to Bayesian surprise prized as a subjective surprise.
2133916	2142800	255	G	0.99992	But as I said, I'm not sure about the plausibility of these descriptions.
2144340	2145940	256	A	0.99846	Great comments.
2147960	2156150	257	A	0.99996	Even the surprise alone still depends on the parameters of the generative model.
2156600	2163610	258	A	0.63795	So it still is within a processing or a filtering frame, albeit a fixed one.
2164620	2173740	259	A	0.97053	So they talk about like, let's look at the figure where there's a graphical overview of this apple and the frog.
2177200	2184252	260	A	0.67	And this is kind of giving some graphics and words to fill in this apple frog example.
2184386	2193420	261	A	0.99737	So initially the person has this likelihood model in the back of their head where they have beliefs about how likely apples are to jump.
2193580	2197216	262	A	0.99986	They do it 1% of the time and how likely frogs are to jump.
2197248	2199110	263	A	0.99995	They do it 81% of the time.
2199960	2201344	264	A	0.54676	That's the likelihood.
2201472	2207110	265	A	0.99995	That's about how observations depend on hidden states of the world.
2208860	2217720	266	A	0.82289	Their prior beliefs are that there's a 10% chance that the entity is a frog and these are mutually exclusive options.
2217790	2219768	267	A	0.99999	There's no third option here.
2219934	2224940	268	A	0.99988	That would be like another category model structure learning on the model.
2225010	2230860	269	A	0.99995	So we're staying within this model for now and they sum to one because they're a probability.
2231200	2241248	270	A	1.0	Then there's an observation which is jumping and then the posterior reflects the updated beliefs about what the entity is.
2241414	2251910	271	A	0.61	And so it's like, it's so much overwhelmingly more likely that frogs jump that seeing something jump updates the prior from here to here.
2255080	2263464	272	A	0.99973	So in this case, one can calculate the surprise of the observation without doing any updating at all.
2263582	2273820	273	A	0.57	One could just stay fixed in their prior belief and then could describe how surprised they are in Nats by given observation.
2275200	2289840	274	A	0.99997	In this full Bayesian cycle, there is an updating of the prior to the posterior and then that updating can be described in terms of how much the prior was updated.
2290820	2296820	275	A	1.0	And so that's like here, the model is updated to the observed data.
2296890	2298710	276	A	1.0	This is now the best fitting model.
2299800	2303860	277	A	1.0	And then we're calculating the difference between these two distributions.
2305000	2313240	278	A	0.9995	So regular surprise being zero means the data point was exactly as you expected.
2313900	2318120	279	A	0.64501	Bayesian surprise being zero means the distribution was not updated.
2319020	2323256	280	A	0.99973	High surprise means that the data point was extremely unpredicted.
2323288	2328430	281	A	0.55183	It was extremely unlikely whether or not you update your model at all.
2328880	2335810	282	A	0.97936	High Bayesian surprise means that the distribution was changed a lot as a function of seeing that happen.
2336740	2337680	283	A	0.87412	Ali.
2340260	2368920	284	G	0.8318	Well, perhaps I didn't understand it correctly, but isn't it the case that in the plain surprise or more generally in the Bayesian formulation of the probability of events, the likelihood and both the likelihood and the priors are somehow inherent to the phenomena inherent to the events, independent of the observers?
2371990	2373042	285	A	0.53056	Yeah, great question.
2373096	2381118	286	A	1.0	I hope I'm not going off on a branch here, but this is related to the difference between frequentist and Bayesian approaches to statistics.
2381294	2389538	287	A	0.99688	So Frequentism does have viewed from the Bayesian perspective, frequentism does have priors.
2389714	2395026	288	A	0.74592	They're uniform priors, which are not uninformative priors, they just are uniform.
2395218	2418830	289	A	1.0	And so in frequentism we come across like the maximum likelihood solution or the maximum likelihood parameter, which is just like, well, if all outcomes were equally a priori likely uniform prior, then we would just need to evaluate the likelihood and find the model with the maximum likelihood solution.
2419650	2429810	290	A	0.71352	Bayesian offers another degree of freedom and says, well, sure, you could pick a uniform prior that would give you the maximum likelihood solution.
2430390	2456170	291	A	1.0	Or you might want to have a prior distribution over that space so that if something is twice as likely a priori and then you observe less than two X evidence for it, you still might want like the Bayes factor or your posterior to reflect that one rather than just jumping instantly to a different maximum likelihood solution.
2456670	2464058	292	A	0.80329	So yes, priors and likelihood are implicit, but they're using a different ontology than Bayesian statistics.
2464234	2468320	293	A	0.99979	But we're in the bays or the post bays area now.
2471830	2486950	294	A	0.99978	But there's so many connections to classical statistics and in SPM, the textbook there is parametric classical statistics, non parametric classical statistics, and Bayesian statistics.
2487690	2491560	295	A	0.99883	So they're more similar than not.
2492090	2498620	296	A	0.8058	It just is about seeing where one of them is like a special case of another or a generalization of another.
2505070	2511870	297	A	0.70426	Okay, let's see if we can do one or two more questions during this session.
2514050	2516560	298	A	0.99272	Okay, so let's return to the previous question.
2517010	2532580	299	A	0.99881	So we're looking at figure two, which is something we're going to see different representations of this entity as generative model, world or niche as generative process.
2533770	2539240	300	A	1.0	And then here the hidden states are those that are unobserved as data.
2539930	2543800	301	A	0.63	Y is referring to data points that are observed as data.
2545210	2550890	302	A	0.99993	There's a cognitive hidden state which is like a prior in this generative model.
2551040	2554394	303	A	0.7	And then there's some hidden state x star.
2554592	2561040	304	A	0.99999	But it could have been any letter or any shape about the hidden state in the world.
2562210	2566574	305	A	1.0	The observation is going to everything that happens in between.
2566612	2574980	306	A	0.99983	Here is cognition, like the sandwich model, like sense, think, act.
2575430	2578782	307	A	0.99934	That type of model is just referring to that little boomerang.
2578846	2583650	308	A	0.99999	Data come in cognitive processing, action selection.
2584330	2585960	309	A	0.99938	So we're in that figure.
2587050	2596350	310	A	1.0	The question was, in order to measure surprise, wouldn't we need another value of Y-I-E-A separate Y that enclose prior belief?
2596530	2598060	311	A	0.99977	Great question.
2599550	2604780	312	A	0.51862	Let's just assume that there is a Gaussian generative model.
2605150	2611390	313	A	0.99984	So the entity has like two parameters in its cognitive model, the mean and the variance.
2612610	2625326	314	A	0.99985	Then Y comes in and given the parameterization of the generative model, all that's needed is the data point to come in for the surprise to be calculated.
2625518	2628500	315	A	0.92379	So another value is needed.
2629190	2636818	316	A	0.99994	But whether we call it ABC XYZ is just a mathematical abstraction.
2636994	2640600	317	A	0.9999	So yes, prior beliefs are important.
2641130	2653370	318	A	1.0	The prior beliefs that can be interpreted as the parameterizations of the cognitive model are required if Y can be objectively measured from external signals.
2654590	2655946	319	A	1.0	Is there a third Y.
2656048	2658010	320	A	0.99999	That is considered the observation.
2658510	2672446	321	A	0.98284	So one could imagine a lot of like, real world scenarios where a more complex model would be required, two people looking at the thermometer or all these different sorts of situations.
2672638	2686778	322	A	0.9716	But unless somebody can unpack this a little more or explain what they were asking about, then I don't think a third why is required.
2686874	2692240	323	C	0.99971	Mike yeah, it was my question, so I can try and unpack it.
2692930	2713346	324	C	0.91	And so sticking with the thermometer example at the heart of that last question is, if we have a thermometer that's registering the temperature, can we consider that as sort of the true observation that is the actual Y as measured by this instrument?
2713458	2718840	325	C	0.97	And then therefore we can compare our sort of internal Y with the actual Y?
2723070	2734726	326	H	0.95421	Okay, so I have a really similar and related question that's like two questions down, but it's in a different section.
2734758	2742510	327	H	0.99993	But let me just place some things on here and it goes back to what we were saying about what exactly is the hidden state.
2742660	2753822	328	H	0.99866	So is the hidden state the temperature and the data is reading from the thermometer that's like the data Y, right?
2753876	2756050	329	H	0.68957	Like this Y in the middle.
2756200	2759410	330	H	0.62971	But then what is how I feel hot or cold?
2759750	2762434	331	H	0.74461	I'm perfectly positioned to be at 75 all the time.
2762472	2768760	332	H	0.9874	So I know if it's like one degree too cold or one degree too hot, I've got to turn up the heat or turn it down or whatever.
2769210	2774162	333	H	1.0	But my registration, my sensory input is not at 75 degrees.
2774226	2776658	334	H	0.99996	My sensory input is I'm hot or I'm cold.
2776754	2781194	335	H	0.99	And so this is like where I mean, we were talking about this yesterday in the math group.
2781312	2783898	336	H	0.9819	There's this really fuzzy line for me.
2783984	2785930	337	H	1.0	I would love for someone to clarify that.
2786000	2788240	338	H	0.59014	So I do get what you mean about this.
2788850	2790286	339	H	0.73132	Shouldn't there be another why?
2790388	2795040	340	H	0.99909	There's the why out there in the world, 75 degrees and then there's how I feel about that why.
2796850	2797920	341	A	0.94012	Okay, thanks.
2798550	2806322	342	A	0.6737	So variables are not like, innately tagged with being observables or hidden states.
2806456	2817190	343	A	0.9984	It's a model specific framing of what is going to be modeled as generated data and what is going to be modeled as a Bayesian prior.
2817530	2825290	344	A	0.99998	In multilevel Bayesian modeling, the priors themselves are generated from a higher or deeper level of the.
2825360	2828518	345	A	0.97295	So one can be serving, in fact, multiple roles.
2828614	2839162	346	A	0.64823	This is the minimal prior generated data expectation maximization type, single layer Bayesian kernel.
2839306	2841760	347	A	0.99999	So we're going to think about this temperature example.
2842610	2850302	348	A	0.99997	There's a hidden state of the generative process which is going to be the temperature of the world latent unmodeled.
2850366	2853102	349	A	0.99892	So this isn't even claiming that there is such a thing as temperature.
2853166	2862870	350	A	0.99998	This is just a latent unobserved temperature that is giving rise to thermometer readings, which might have, like, different sorts of noise.
2864090	2868950	351	A	0.99998	Then there's another hidden state, which is the evaluation of temperature.
2870570	2875210	352	A	0.57	And so this is just a schematic.
2877230	2885370	353	A	0.99	And also, whether one is labeled x or Y or L or triangle is like a norm and a convenience.
2886370	2891760	354	A	0.99978	But the letter doesn't matter itself.
2893250	2896618	355	A	0.99997	It will be used mostly consistently within the textbook.
2896794	2902020	356	A	0.90766	But there's only so many letters and there's not a lot of coherence on notation use.
2908740	2911010	357	A	1.0	What else could be explored here?
2914680	2915284	358	A	0.99867	Yeah.
2915402	2916820	359	A	0.99297	Mike and then Ali.
2919320	2926912	360	C	0.90809	So as I keep ruminating on this, which is probably more than I should, it seems like there can be infinite wise, right?
2926986	2940650	361	C	0.6134	So to the extent that you are taking action which will change your perception, then you are as a result triggering potentially new Y's in the system, right?
2941760	2944988	362	C	0.99879	So you just have this infinite potential for what Y can be.
2945154	2949032	363	A	0.99998	This speaks to the composability and the flexibility of active inference.
2949096	2960384	364	A	0.99446	So like Y could be one pixel of visual input, it could be a 4K video, y could be smell and a 4K video, y could be LiDAR and this and that.
2960422	2970580	365	A	0.93678	So Y is just the generalized input of sense and then action might be related to this in a very direct way.
2970650	2975024	366	A	0.99992	Like Y could be visual input and action could be your eye movement.
2975152	2978330	367	A	0.99998	So that case is going to be explored a lot in the book.
2978940	2985044	368	A	1.0	However, it could also be you're getting something in and then the actions are just totally unrelated.
2985172	2990350	369	A	0.99999	Maybe they don't affect the hidden state, the causal process in the world at all.
2990880	2995100	370	A	1.0	Or maybe actions enable different wise to enter the picture.
2996240	3006800	371	A	0.99998	This is just the total essence kernel and then even trivial cases require some more apparatus.
3007860	3008800	372	A	0.8604	Ali?
3011460	3011824	373	A	0.99616	Yeah.
3011862	3012930	374	G	1.0	I have a question.
3013860	3033610	375	G	0.99971	Is it correct to say that the minimization of variation of free energy, aka the Surprise is exactly equivalent to the maximization of expectation, the wholly linear relationship between these two?
3033980	3042780	376	G	1.0	Or possibly we have some kind of plateaued areas between these two extremes?
3046130	3047360	377	A	0.99743	Great question.
3047730	3054210	378	A	0.99959	So this is something that we'll come to next week in our discussions on chapter two.
3054280	3061506	379	A	0.99904	So we have not even discussed variational free energy yet today.
3061608	3071954	380	A	0.60438	We talked about starting with a low road on some of the atomic calculations that are going to come into play, like Surprise and Bayesian.
3072002	3080454	381	A	0.99764	Surprise in a Bayesian framework and beginning to partition active entities and their action perception.
3080502	3093690	382	A	0.99982	Loops in terms of a Bayesian graph that's going to be amenable to flexible modeling of perceptive, cognitive active and out there in the world variables.
3093770	3095550	383	A	0.60476	Variables with those interpretations.
3096130	3103710	384	A	1.0	And then variational free energy is going to come into play as a way to bound surprise.
3104150	3108514	385	A	0.90331	So let's have some questions and discourse and we'll come to it next week.
3108552	3109682	386	A	0.99999	But it's an awesome question.
3109816	3110850	387	A	0.96892	Jessica?
3113430	3113794	388	I	0.9801	Hi.
3113832	3126674	389	I	1.0	Yes, I have a question, I guess related to this figure 2.2, let's say, in regards to how we interpret what we observe.
3126722	3142858	390	I	0.90806	So I understand you have a prior that might you're anticipating something like some other people's behavior or how things should be that might be different from what you actually observe.
3143034	3159534	391	I	0.99994	But a lot of times, at least in terms of when we're thinking like human beings, an action in the world, how you interpret it has to do a lot with your own views or your own experiences.
3159662	3166982	392	I	0.92	And maybe that connects to the priors, but the interpretation might be very different from people to people.
3167036	3173778	393	I	1.0	The interpretation will vary a lot because everybody has different experiences.
3173874	3182570	394	I	0.98409	So those could be encoded, I guess, in the priors, but it's not connected per se to the prediction part.
3182640	3183962	395	I	1.0	Or maybe it is.
3184096	3204980	396	I	0.99965	So I'm trying to kind of connect that idea of our personal interpretation based on our experiences, which could be priors, make us see what's happening in the world differently than other people.
3205350	3213170	397	I	0.9964	So that why will look very different for you than for me, just because we have lived different experiences.
3213830	3217160	398	I	0.99984	So it's not like an actual why.
3217610	3223842	399	I	0.99995	You cannot really say this is a fact because it's an interpretation.
3223906	3225560	400	I	1.0	At the end of the day.
3228830	3231034	401	A	0.99863	Great question and points.
3231232	3231642	402	A	0.62103	Yeah.
3231696	3245760	403	A	0.88483	Understanding how the individual setup of a given entity is related to its past experiences and how that could be modeled by priors is an important area.
3246370	3254190	404	A	1.0	And some of those rich dynamics are not in this minimal nucleus.
3255190	3266690	405	A	0.75028	But it'll be awesome to start to think about what does have to be in the box here to give rise to those kinds of dynamics.
3270170	3276502	406	A	0.99639	So that's going to end this discussion next week.
3276556	3285900	407	A	0.9998	We will also be staying in chapter two and taking it more towards variational free energy and expected free energy.
3286510	3289740	408	A	0.99969	So that should be fun.
3290590	3297498	409	A	0.99824	We're going to in this room transfer immediately to the Tools meeting.
3297594	3302062	410	A	0.99993	So if you want to join for active Lab Tools meeting, everyone is welcome.
3302116	3304914	411	A	1.0	And there's no prerequisites or anything like that.
3305032	3311074	412	A	0.99951	If you want to hang around and join Tools, stay in this exact gather space.
3311272	3319730	413	A	0.99966	If you want to continue talking with other people about the book or anything else, just head up into one of the rooms above.
3320070	3324500	414	A	1.0	And if anyone who wants to can just continue any discussion that they want.
3324870	3327710	415	A	0.99897	But in this space we're going to continue now with Tools.
3327870	3329740	416	A	0.99614	So thanks everyone.
3330270	3330550	417	A	0.50213	Bye.
