start	end	speaker	confidence	text
1450	189280	A	0.937799087837837	Okay, it is May 19, 2022 and it's week three of the textbook group first cohort. We're in week three discussing appendix A and B and there are some notes in the sections of the book. In the chapters. There are also some ideas and questions that people have raised. So we'll go to the questions and then start with the most upvoted. So feel free to add more upvotes if you want to discuss it, like even in this discussion. And then hopefully if people are available to take notes in this section, that will help add their thoughts in and also capture what the speakers are saying. And then we'll look at the question and then try to come to different answers and just add more information that people can add more structure to later. Okay, the first question says appendix A is described as the mathematical background. So maybe question one for the authors or for you. What is the process of determining what is figuring ground for the formalisms of active? What other math concepts and formalisms are important for learning and applying active inference? And then three, what are some resources and approaches for learning math that help us learn what is useful for active inference? Anyone can raise their hand or we can just start to add some annotations here, like what should be included in the primary regime of attention with a reading of a book, either linearly, like some books are, or in a maybe moving around the sections. So what should be in the chapters? What should be in the appendix? What is not in the appendix? What did people expect would be in the chapter in the appendix? Not covered. Yeah, Jessica and then anyone else?
191650	216790	B	0.9328044999999999	Yeah, I was wondering about the multiplication of the matrices that we covered yesterday. Which equations have the multiplication of the matrices? A couple of examples just so I can play around with them. In the actual active inference equations.
221270	329780	A	0.8969901098901102	Does anyone know? One, this is referencing the way that the appendix A is starting with linear algebra and then introducing this operation of multiplying two matrices. Or to get a product if someone can find like an equation that we already seen or some other equation while I'm typing up that question, that would be helpful. Could anyone just describe what they thought the intention was of starting with linear algebra and using 8.1 as the first equation of the appendix? Or we'll return to just the more general questions.
339560	345780	C	0.8387266666666666	Yeah, I mean, learning our algebra is kind of the most discreet.
348220	348648	A	0.94417	I don't.
348654	386570	C	0.8825795833333335	Want to say fundamental, but like practical and comprehensive way of kind of working with a large space of data, I guess, together and computing on it. So it's kind of the basis for the discrete parts and maybe easier than the nondiscrete parts. Good reason it started.
397850	447990	D	0.8954984615384612	I guess if the question was where is linear algebra used in the active inference math? When you go to appendix b. Then you've got the equations of active inference and these are all expressed in terms of large vector spaces of variables, so probability of distributions. And so for example, on page 245, you've got this dot notation which is the expectation of a value. So that goes directly back to that first section of appendix A is what does that mean in terms of how do you take an expectation of a large vector of things? How do you express that compactly?
450490	493750	A	0.9349935802469133	Thanks. Could you unpack we looked at the dot notation a little bit yesterday and they were mentioning how well, I think it was actually one of the questions too. Let's just see if someone asks this, okay? They say the dot operator in a three, the dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed. So what is the relationship with expectation? How does expectation for anyone, how does expectation relate to linear algebra?
506160	549400	D	0.9311854999999998	Yeah, expectation is the probability of a value, the average probability of some value. So you're going to take all the possible values and you're going to multiply them by the probability of that value and then divide by the sum of the probability of normal is to one. So that will be the expectation. So if you have a whole array or a vector in your distribution, you can express that all in compact notation by saying with this simple way of saying we're going to take every one of these terms and we're going to multiply it by the probability of that term and the probability is some to one. So then that will be your average overall.
551340	734780	A	0.9435295532646042	Awesome, thanks for that answer. Okay, thanks for that awesome answer. Does anyone have any other thoughts on just this first question and then we'll continue. So what is figuring ground? We're learning active inference in the chapters. That's why the chapters are there. The appendix is there to somehow lightly supplement that. Like they describe it as an introduction or a refresher to the basic mathematical techniques. And linear algebra is the first section, a two that is discussing a lot of important things like derivatives and Probabilities taylor series variational calculus and Stochastic dynamics are going to come in in the coming chapters, but the linear algebra is important for the upcoming chapters. Okay, so this question asked in a three. They say the dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed, which is flipped like it's the operation in Google Sheets or Excel right click paste transpose. They say that in the case of column matrices, this is equivalent to the dot product. So the dot operator here is like a generalization of the vector dot operator, the sum of the products of the corresponding entries of the two sequences of numbers. So the questions here were what is interpretation, implication or use of a dot product of vectors? And then what is an interpretation, implication or use of a more generalized dot product. And there looks like there's an awesome answer. What would be a situation where if anyone can think of one, like the Dot product would be applied. We're trying to do this in this situation. This is the operation that we needed. We wanted to compute matrix A on something of something. We used B dot C.
742990	780670	C	0.9016680851063829	Continue eric's description from the probability like you have expectation probability and you wanted to kind of see the error or whatever the difference, I guess between observation and the expectation, then a Dot product would give you that answer or it's a probability density of it.
787930	841190	A	0.944311648351648	What are some ways to compute differences? Like if there are scalars you can subtract like five minus three or something, then it was mentioned of cosine similarity. Does anyone think of or imagine another way that you could compute the difference between two different kinds of features of different dimensions. Like another example is divergence because that's like measuring the differences between these two distributions and there's different divergences. The KL is one of them. What other things are in this space that might be just tractable possible distance measures?
843850	867280	D	0.9014897727272732	Well, these are the same dimensionality in all these cases. But another very popular one is the sum squared difference, sum squared error. And then you can have absolute different value difference. So these are called different norms. I think that's the right word.
867730	868480	A	0.99981	Yes.
868850	878530	E	0.8118706666666667	There's also the Ginny index, the Jacard index, euclidean distances like sample to sample distances.
907910	918150	A	0.9038525	So could anyone talk about L zero, l one and L two, et cetera norms? While I'm adding some links.
933520	953664	D	0.9047217999999999	If I have the right numbers here l two norm would be the square root of the sum of squares. L one norm would be the average of the absolute absolute value differences and L zero. I don't know what that is. I don't think it's a difference, is it?
953862	955760	A	0.9841619999999999	It's like a presence absence.
956680	957430	D	1.0	Okay.
960520	1008310	A	0.9342510891089104	That kind of encoding is used in a lot of different algorithms and then the L two norm is the sum of squares. So the L two norm is what is used like in at least squares regression, classical statistics, ttest inova that's a lot driven by the L two norm. And all of that is like in the genre of what the A three notation is describing. But depending on what the B and the C are and what the A is, et cetera, there's just the dimensions of everything and other operations that are happening before or after it.
1013190	1025510	D	0.9706097142857142	Later on they mentioned the quadratic, which is the L two norm. So that's where you have the same term as multiplied by itself. Or if you have cross terms, then you get the covariance.
1028780	1262464	A	0.9343016915422885	And that's going to be used later with the LaPlace approximation and other approximation techniques. Any other comments on a three or dot product? Or just like this kind of linear algebra topic? Linear algebra the basics, the trace and the determinant, which are probably less important than the dot product but still come into play, the derivatives, how things change with respect to each other, possibly time, possibly some other surface, and then probabilities. So does anyone have any other comments or thoughts on that whole section? Like anything that they read or like had uncertainty around up to equation A 22? Great. That no one has uncertainty around any of the equations up to A 22? Yeah, obviously there is a lot to learn and to understand and we're not going to. It's just I don't know people who want to think about that. Like, what are we learning in Appendix A? Why is appendix A there? Hopefully we can start to understand some of this in Math Learning Group. The people who want to be really engaged with the math questioning and process and also connecting it to computer science into the applications has been happening and then hopefully everyone can benefit from this, like finding the resources and stuff. Because the relationships between the terms, relationships amongst the terms are driven by formalisms. Like the way that preferences and expectations are framed in active inference is related to equations, not only a conceptual linkage. Maybe here we can just write Math Learning Group and copy this to the resources. Okay, so what kinds of examples do you think would be useful for learning the equations and concepts in Appendix A? If the equations felt too general and not applying to anything in particular, what example or scenario or would have made sense or you felt would have made that clearer? Like, we're running a business and first this person wants to do this and then this person wants to do that? Or what example or what would somebody have expected to have found or wanted to have found that would have made it clear? Examples or other exercises or a format? This is kind of like a math lecture. It's kind of directional versus like, what other things could happen where you would feel like you were understanding and learning this and engaging with it. Yes. Thanks, Brock.
1262592	1346950	C	0.8995491911764701	I was kind of reminded of a video that Karl A presentation where he in real time demonstrates and helps you work through a pattern of red. Like it's like three dots sort of that are moving around red, green and pattern. And so understanding just a simple visual example of how active inference would work that doesn't require the formalism to just surface level kind of pattern recognized, that would be like ideal maybe of then bringing in the math for this part and that part and some scaffolding. But yeah, I'm not sure the appendix, I'm not sure it was meant to be bred in. I'm not sure there's a great way to read one order or another there because you kind of need it, but you kind of it's a lot too, right?
1348200	1539060	A	0.9428988621444211	Yeah, great point. And the organizing team for the textbook group which was open to everybody who wanted to join the and the comms weekly meetings. So for future cohorts, people could totally be involved with planning it, communicating it, doing anything for future cohorts as a co organizer or other role. But we talked a lot about the reading order. Would it make sense to read them in without appendix or putting the appendix last or somewhere else? One was short and hopefully the one week of regime of attention on appendix A and B is like we're just skimming it in a week. We're not getting a PhD in math, we're not generating these equations on a blank piece of paper. We're just like seeing the forms that will be used and then some of the key areas in the order that the authors thought that those background topics were important. So like for appendix A, linear algebra, which is what we talked the most about, because it's going to come into play most quickly, especially with these notions of expectation and differences which is going to come into play with everything that's going to happen. Taylor series variational calculus and Stochastic dynamics we talked less about. They happened in a later order within the appendix, but hopefully there will still be many questions on them because they're probably also areas with a lot to learn and to clarify. And also appendix A is like not the final resource of it diffusing into us. Like something that was really important that came up in the math learning group. Is there's not like a glossary of variables or table of variables so that's something we can work on with notation is connecting the variables to natural language ontology terms and then also things like this what do we even look up or a symbol or what does it mean when there's a double arrow? There's a lot of things that like a lot of dots that could be connected if people ask them and then we can probably get a response like what was the double arrow in a three? Does it mean anything that they're offset? Or what are the parts of this shape that are mattering for the background of learning? Active inference, anyone can ask like any question. If it's coming to mind as an uncertainty, then writing it down just anywhere is really helpful. Because then on the first pass through learning or a primary branch of learning, we can just go, okay, here's what a one shows, and then have that in a way that reduces uncertainty more rapidly than how any of us would just give an ad hoc explanation.
1545160	1576990	D	0.9651430232558138	Moritz wrote one thing that I always find useful in thinking about matrix, linear algebra matrices is to write out pictures of the matrices in their dimensions because often the notation, you've got these I's and J's and K's and stuff going around, but you don't know how that maps out into the actual elements of the matrix. So those illustrations are always helpful that could be added into this book. They're in a few places, but not that much. There you go. Things like that.
1579120	1644580	A	0.9305119553072626	Yeah. And also connecting the programming experience that people might have even in no code tools like Excel Google Sheet, you have rows and columns, ones have numbers and ones have letters, but they can be other things. And then anyone who's used something like Python or R or even just doing some statistical calculations, like if you put two lists of numbers into the t test, that would be vector versus vector something, and then you would address the fifth element of the list. And then if it was in Excel, you would need to address two numbers to say where you were in the matrix. And then the tensor is just any number of more than three dimensions, which is sometimes like it's like, oh, but how spatially are we going to see it? But then we're familiar with working with spreadsheets and data sets that are larger than two by two or larger than two dimensions, and that will come into play a lot. And the numbers can be representing probabilities or be used for probabilities.
1646840	1670350	E	0.9040694642857142	I also Daniel in the chat shared a link to a Python notebook that is a link, and it shows kind of the operations on matrices. And you can see both the mathematical yeah, there you go. So you can see the actual matrix and you can actually run code too, there. So that particular awesome.
1670800	1974410	A	0.9252301474201473	So I pasted the link in here and then we can fill out the rest of the row. But then someone could be looking for a guide on matrix or programming and matrix or something before this state. So then each person, if they find it and add it here, will have a lot to share and learn. Okay, does anybody want to like, if they were the one who asked it this question, I i think it's probably referring to long equations that that probably none of us are ready to give answers to at this point. Unless somebody wants to contextualize this question. I'm hoping a read of chapter four will elucidate when the time comes. Just exploring the formal foundations here. Okay. Okay. Does anyone have a favorite or recommended textbook that it contains the KL divergence and Dearsley distribution in the index. This is for the math learning group. Okay. Maybe we could tag some questions too, and so then we can know which ones they can look at. Wikipedia is good. The Kale divergence is approachable. The deerish lay is tougher. The links take you to definitions that enable you to put the pieces together. Okay, any comments on KL and Dear schley from someone who is familiar? Otherwise it sounds very technical and we don't need to go into it right now. What is up with dividing by sigma in a 31? Also detail, but we'll just see if there's any questions that are not going to be specific details because math is very hard to understand sometimes on the fly and there's definitely a space for the interactive discussions around math that are unrecorded which are important. However, this is a little bit of a different format, which is how I'm hopefully interpreting people's activity rather than their disengagements because they are here and hopefully have at least scanned these chapters. Anyone can raise their hand at any time or add questions or upload things. Mean field mode, equation nine, equation 16 probability resource, statistical question, appendix B just to see if there was any. Also seem like all details. So we have 23 minutes. What does anybody want to ask now? Or is there some question here like the most upvoted one or some other one that's far less challenging that they would like to address for the next 20 minutes? Did anyone read Appendix A or B visually?
1982990	1985182	E	0.9092362499999999	Did you just ask if anyone read it?
1985316	1988240	A	0.990245	Yes. What would anyone like to share about reading it?
1989650	2022540	E	0.9279340000000001	I totally read it with a highlighter and made several notes in the margin in my physical book. It was challenging. A lot of the notation I feel like is crazy, even just independence b was it the very first thing? Are they using O for observations or are they using O for outcomes? I was totally unclear on that.
2023070	2023820	F	0.99998	Completely.
2024270	2115270	E	0.9278162025316453	So like state inference, Markov decision processes like the states that influence outcomes O, right? Literally. That's what it says on the top of page 244. So it says that the variable O is an outcome. Is an outcome and observation. Are those the same thing? Are they interchangeable? I've always thought O was observations. I put that question in there in the past. It's already there and then the question right before it. This is a really tricky section. Right? So the two questions that are in Appendix B that are together, it says the likelihood of observations given a policy is not straightforward to compute. This is because POMDP problem is structured so that policies pi influence trajectories indicated by tilde of states S that influence outcomes o without a direct influence of policies on outcomes. The problem then involves the sum over trajectories of states to marginalize these out and find a marginal likelihood of observations given policies. Like what does that these even refer to? If you look in the questions in Appendix B, they're there in the questions already listed. I felt like it was very obscure and not super clear. And also the notation gets crazy and I'm really a stickler for defining every single variable and symbol in an equation to understand the math so that I can actually read it in English. So I was a little bit lost.
2117690	2121554	A	0.8523	Totally agree. Thanks for sharing it, Eric.
2121602	2150180	D	0.9061881690140843	Just with respect to that particular question, I think that these refers to the trajectories of states and you can see that because the sum is over the tilde s. So the tilde s is the trajectories of states. So you sum over all the trajectories of states to try to figure out, well, what are we going to get if we apply a given policy? That's my intuition about that.
2150710	2175210	A	0.9391754545454546	And I suspect also that observations are outcomes. They're sensory outcomes. They're the outcome of a generative model or a generative process, but they're the outcome that is observed. How many dots we need to actually unpack and connect for unsighted grammatically vague sentences.
2175550	2187280	E	0.9376364864864865	Right. So thank you. My uncertainty has been reduced substantially just by figuring that out. But I felt like that the whole time I was reading the appendix, I was like, what is even going on here?
2188690	2189440	A	0.99	Yeah.
2192290	2248020	D	0.9493915675675674	Sir, the way I view it is like exercising. You're not going to run a marathon the first time you set out, but the more you stretch and warm up and I think that's how I kind of view this. Going through the appendix is kind of refreshing on what you used to know about math, at least for me. And so that's like stretching and doing a little bit of exercise last week. And then every time you go through it, every time you see the notation, you've slept on it some more, it becomes more and more familiar. And so you can start to put together bigger, bigger chunks. Some vaguely you can map to the notation and the math. Other ones it's still going to be dangling, but that's okay because there's fewer dangling things that you're groping with at any given moment. So I think it's great to go through these dependencies and see it all through one pass and all right, so I didn't run a marathon, but that's okay. I ran 2 miles. That's pretty good for first start.
2249430	2254530	A	0.8562290909090908	Thanks, Eric. Another metaphor is just like, oh, yes, please. Jakub.
2256470	2325080	G	0.9253657432432429	Yeah, I was just going to comment on what Blue said with some confusion about the notation because I asked the question about the marginalizing of state. But then I was also confused about the O notation because in equation B one, it seems that it's a trajectory over outcomes. But then there's also an O without a tilde on it. So does that mean that it's an outcome at a particular point in time? But then there's also a bold o, which implies that it's kind of a vector. But if it's a trajectory of outcomes, that also seems to be a vector. Like a trajectory for me implies some kind of vector form because it's a sequence of outcomes given a policy. But then what does that bold O mean if not trajectories over outcomes? So just to kind of add to the confusion, I guess.
2326170	2331660	E	0.930961875	Thanks, Jacob. I'm glad we're groking we're on the same page, you and I for sure.
2334690	2399880	A	0.9405969090909087	It would be awesome for description or any notes. What is the reading or a reading in language? The this of this conditioned on that is this over that of these two things. The first thing is this. The second one is that an example of that is in this situation, here's the script, here's the graphical abstract, here's the paper, here's the person you could ask, which one of these do you think is going to be interesting? Okay, so Mike asked, and I'll copy this in for those who have read the entire book. Did you find the appendices useful as you went along through the chapters? Ali.
2404300	2424620	F	0.9333802777777778	Yeah. I also think that if the materials in these two appendices were to be integrated in the linear narrative of the whole book, it would be much more useful than separating out as separate appendices.
2424700	2425330	A	0.96723	Because.
2427700	2451320	F	0.8913461224489795	As we see, that's my own experience. Well, reading the chapters independently and in isolation of the narrative doesn't give me a sense of their concrete applications and I don't know how to use them and how to use all of these equations, and everything becomes much more fuzzy.
2461800	2592750	A	0.9417722727272722	I hope this is not controversial. That linear reading of the appendix as something that you look through is extremely confusing or extremely imprecise because there's many symbols introduced that might have been introduced earlier, like O is probably discussed earlier, but then it's briefly just sort of mentioned. And then there's a lot of symbology that's not mentioned. What it is. So it's hard to read the appendix without prior knowledge. Yet, ostensibly, Appendix A is the introduction refresher. So is this the introduction offering? They hope so. They expect and prefer perhaps the appendix to go some way towards remedying it being the maths required to understand this not complicated basis. The multidisciplinary basis means it is often difficult to find resources that bring together the necessary prerequisites they're going some way. So this is like one kind of plank out there from their point of view, from the chapters. This is stuff. Ali I also kind of agree on what ordering these are really interesting questions. So then what is the next connector that picks up here with this artifact? Because someone mentioned how Moritz mentioned you could basically do a whole course on deep learning to apply most of the matrix operations and whole courses on the math of them so they can't go into all this detail. They can't spend 1 hour or like multiple coda pages on just what this means. So there has to be some kind of compromise, but then there's not going to be one specific perfect compromise, especially with like, length and audience considered.
2596390	2650370	E	0.9334495945945946	I undertook a very detailed linear reading of the book because that's just kind of how I am, of the appendixes at least. But I think for many people that I've been there before, where you're staring at math equations like this is gibberish. Just to read the text and to read it and go through it, it's helpful to know that it's there. So if nothing else, at least you can be reading the book and then be like, oh, I remember kind of reading about Taylor series expansion in the appendix. And so then you can just go back and just having access to it or the refresh recall access, even though it is confusing. I agree to try to a linear read of the appendix. I think skimming over it or deeply reading it and then being able to refer back to it is useful.
2651270	2953390	A	0.9298636346863471	Thanks, Blue. So in next week, we're going next two weeks. So the pace of one section per week might be like whatever it was for you, however much time you put in, et cetera. The coming chapters are going to be very different because one didn't have any formalisms or figures really, just the kind of overview figures. But we're going to have two weeks for two. So no need to rush it. Read a couple of pages and then just go back to the beginning and just restart the same pages. That's like the multiple coats of paint in a mural. Like the low road to active inference. That's where they're going to pick up in that high road, low road dialectic that we talked about last time. Let's just see what figures, what equations might happen. Okay. Lot of terms that hopefully are in the ontology already. Like you can use the at symbol hopefully to call most of them, but if something's not there, we can add it to supplemental or entailed. Okay, so what figures and figures and equations will we might see? Here's a box 2.1 about probability. Here's an equation that's the Bayesian kernel and it's going to be talking about this example of a frog and an apple and jumping or not jumping. And that example is going to play a current role. But then some likelihoods are shown in a specific example of like frogs and jumping or not and apples. There's a work through example of exact Bayesian inference. Here's a table on statistical distributions. It would be really interesting, like to hear what support and surprise mean and what are these district? Are these all the distributions? Are there other ones? Or like why these ones? Or why are they useful? Where have they been used? What does it even mean? Here's where the KL divergence is introduced and then some more analysis from a surprise perspective. Bayesian surprise with the KL divergence. There's the box on expectations, which is also what we talked about a little bit today. And that was really interesting to connect it to the matrices. A figure of the generative process and the generative model is the caption a figure both perception and action minimize discrepancy between model and world free energy. Variational free energy as an upper bound on negative log evidence the figure but with equations in it. Very common format figure complementary roles of perception and action in the minimization of variational free energy. Big act, imp theme and like something kind of a common fristinism like perception and. Action, being in the same game or being in the same service of the same objective function. Planning but no specific equations but probably citations. Just introducing expected free energy, which Yaakob and others can probably go into a lot more detail on. Expected free energy about a future where the outcomes haven't happened. Expected free energy figure with equations, the end of the low road. Introducing the two key terms variational free energy, expected free energy summary does anybody, like, want to, like, add or what was something cool or whether they read it already or not? What does anyone Ali? Yes, please.
2958180	3008480	F	0.8929623958333338	Well, I've noticed the dispersion of some sidebar boxes like box 2.1 or in this chapter. I don't know the distinction between the purpose of these boxes and I mean, what's the function of these boxes as compared to what we see in the appendices? Because presumably these boxes cover the concepts that could be skipped over if one is familiar with these mathematical concepts. So do you have any idea about the reason behind this decision? I mean, covering some basic concepts, basic mathematical concepts in these sidebar boxes and some others in the appendices?
3018910	3117750	A	0.9493579185520359	That's a great question. A box could reflect like, okay, expectations. Got it. Or like, okay, some product rule. All right. But it's kind of like you might want to read that. Or is this introductory highlighting it? This is the 101 on probability. Or is it saying this is a total skippable unit? If you want to learn about how the lizard does it, here's where you look. It can sometimes mean both. And the format of the book is also relatively austere, though in a concise tone. It's in black and white, which especially in some later sections make some visualizations where it's like it's hard to understand what curves are doing what it's a black and white image, so what is there to see with the color? But it also might predispose towards more simple or visually accessible material. So what is going to be accessible and the order. So those are all really important questions. So we can just take notes on it in the weeks that we're going to continue to do this because we only have limited live time. How about in the last like 3 minutes? What does anybody think about the opening quotations or specifically this quotation? My thinking is first and last and always for the sake of my doing. William James.
3123060	3127250	D	0.9238611764705882	I thought the guy was a philosopher, so I guess you just abused me of that one.
3129490	3130240	B	0.38	I.
3137210	3197720	A	0.9387800000000002	Yeah, these would be really nice areas to look into for people who like the history part. Blue and I and others are working on some different kinds of ways to reference papers and just up cool paper. Sensation perception. We have those terms. We could just link the paper somewhere. So if anyone's like, interested in that kind of architectures or that kind of philosophy question the literature right now. Is small enough to know what has and hasn't been done in a lot of areas that are philosophical and applied and technical. But just from, like, the first principles, what does this seem to mean.
3200330	3282290	C	0.9299721830985915	That shared that other group that we're kind of both a part of Daniel Liminal dow thing. That's not really a dow. I don't know what it is, but there's this debate for some reason that's going on there about different ways of knowing and being and doing and a bunch of stuff that is kind of a mix of philosophy and linguistic fallacies. But if thinking is actually a physical process, which I think anyone here is going to argue against, then it is something necessarily that is being done. However, I guess, small, you want to draw that Markov blanket. And then however large, whether that's your physical body actions or some extended thinking, it's literally what you're doing. It's not just for the sake of your actions, but they are your actions. They're just another set of your actions.
3283670	3286754	D	0.9496755555555555	All right. I'll offer a different take on it.
3286952	3287314	A	0.92	Yeah.
3287352	3317500	D	0.9421422580645161	Awesome. William James was a great visionary, and he foresaw Mark's Mark Zuckerberg's metaverse 120 years ago or whatever, and he said, no, I don't want to live just inside my mind, inside the metaverse. I want to be out in the world, interact with real people and real things. So he was a meta or Facebook skeptic way before his time.
3321010	3326334	A	0.982234	Okay. Thank you, Ali. Yeah.
3326372	3386580	F	0.9236906818181818	As Brock mentioned, I think it relates to an epistemological distinction between propositional knowledge and how to knowledge. And I think this statement by this statement here tries to blur this distinction, blurs the line between propositional knowledge and know how knowledge. Because especially in analytical school of philosophy, there's always been a very, let's say not a heated debate, but there's a long standing debate about the distinction between these two kinds of knowledge and whether in fact they can be distinguished from each other or not.
3388790	3397000	A	0.9436266666666666	Thank you. Could you just unpack what are the two kinds of knowledge again, and what are just they referring to?
3397530	3466010	F	0.9261136206896551	Sure. Well, about propositional knowledge well, an example of propositional knowledge is to know the exact mechanisms of walking. I mean, which muscles contract and which I mean, in what angles. The whole thing about the biomechanics of walking, the whole knowledge about the biomechanics of knowledge can constitute this kind of propositional knowledge. And it's totally different from knowing how to walk. I mean, a three or four year old year old child has a know how knowledge of walking, but not necessarily where he or she doesn't know anything about the biomechanics of walking. So the biomechanics of walking is the propositional knowledge. Actually, knowing how to walk constitutes the know how of walking.
3474340	3654070	A	0.9177579279279265	So when people say things like active inference is integrating perception, cognition, and action, maybe it is rethinking some of these long held mental frameworks for distinguishing or operating differently on action and perception. Like, one fascinating recent example from me and working with Eric was in the area of ant pheromone modeling. Without going into too many details, people often modeled preference as a function of the absolute amount of pheromone on trails because that's what the exponential, like, decay is on. That's what can be manipulated rather than the perceived intensity, which might have a different scaling relationship. So it's like a dim room, you can detect a small change. Bright room, you can't detect a small change. So that kind of psychophysics of perception gets ignored implicitly because of calls for measurability, because the cognitive can't be measured directly. Even if you potentially had an electrical measurement or something like that happening, then these are awesome questions. Can you think without acting or is thinking in action? This active paper, which was on a live stream, so we can provide the link to it. Models like perception and action in the sort of like kernel level, just the autonomous sensing sentient bot level. And then attention and metacognition are both related as actions to the lower level, which is like why the paper is relating computational phenomenology with mental action. Again, just to have a look at the kinds of models that can happen. And then now does making any model, fitting any data well enough and saying, well, we modeled it as action. So is thinking in action? Will that model that says, yeah, it's consistent with that, will that ever constitute positive evidence for saying thinking is action? Or why even say that? Or what does it mean to say it? And then here's a funny meme. Here's the generative model and the generative the partially observable Markov decision process. Here's Karl, Friston, Jessica and then anyone else.
3656600	3751590	B	0.9068180701754381	Yes. I guess it's like a beginning understanding of this. I tend to think that there's like a bias towards action in active inference. I think the first chapter is saying even if you want to sense or perceive, you have to do some kind of action in order to gain the information. And this quote is basically saying like, okay, even though the whole field is trying to understand cognition, what we decide to do and the thinking that we go through in order to determine our policy is to determine our actions. And then it sort of feed into the thinking itself. So maybe that's why there's like the bias to action because our actions is what it's going to be allowing the thinking. But when we update our models or trying to come up with the policies that we're going to be doing, like, we have to be processing things. So the thinking is in as a service to action. That's sort of like what I was thinking. I don't know, it's a little bit like the chicken and the egg, but I kind of tend to think of it. It's like, yes, we have to act in order to understand, but the understanding which will be coming from the thinking is what determines our next action. Yeah, that's kind of what I was thinking.
3756260	3758320	A	0.8879933333333333	Matthew. Thanks, Jessica.
3760740	3827510	H	0.9440131901840486	Yeah, it kind of seems to me like we're stuck in a little bit of a linguistic Godellian loop of some sort because thinking is essentially a verb and verbs tend to imply, in a linguistic emergent term, actions. And so we have to then pop outside of that and try to consider with our internal mental processes how to disentangle these concepts. But I see no reason to think, ironically, that internal mental states aren't also conscious parameterizations of processes in the brain and our ability to grasp control of that to some extent. And so it seems very strange to me to try to separate those linguistically from our current vantage point, even though I understand why, historically, working only with language, it might have made sense. So those kind of quotes like James strike me as somewhat antiquated or just operating on dichotomies that don't seem to make sense given that we've unpacked these processes to the degree we have.
3830520	3861376	A	0.8871795833333332	Thank you, Matthew. Very deep points. Like you mentioned, thinking as a verb implies action. And then just to kind of complete that thought is like the word for the noun form of this one. So then what does that imply? And then also, like Jessica mentioned, to.
3861398	3867404	H	0.9741438461538462	Some extent that we can only express processes through their discretization via symbols.
3867452	3868050	A	0.98164	Right.
3869300	3892890	H	0.9511296551724135	The idea that there's this process, there's a flow, there's something that can't necessarily be separated, obviously, from the rest of the flows around it. But to reference it, to point to it, to describe it, communicate it to another agent, we have to nounize it kind of like which is the opposite of verbalizing, so to speak.
3895440	3901740	A	0.9757599999999998	Wow. Thank you, Matthew. Again. These are yes. Eric.
3910030	3911162	D	0.99956	Sorry, I didn't have anything.
3911216	4004970	A	0.8956635087719295	I didn't have the hand was yeah. So Karl Friston had an influential 2019 paper. Long paper. The free energy principle for a particular physics. That was in 2019. So it's been several years since then. And like, particular allegedly accidentally or intentionally is a pun. So it can mean specific, like a physics for the specific systems that we're modeling. Or it could be specific, like this is a specific approach. Another interpretation is like it's for particulate entities when we define thing and the partition, which is going to coinstantiate, like the generative model and the generative process and then the Markov blanket or the interface that's separating them, that is separating the figure from ground. It's separating, like, the entity from the niche. It's separating what from what? What can it represent? The separation of something from all possible separations, some separations. And then, Matthew, you mentioned, like yeah, verbalizing speech, but it feels like we're speaking nouns sometimes. Yet verbalization is a process, especially dialogue. Yes. Matthew.
4007630	4045990	H	0.9483619444444442	Could I ask a question that brings in a little bit of content from the other chapters of the book is that yeah, sure. I'm just kind of curious because when you're talking about those, you're talking about the Markov blankets and integrating it into this idea of how we draw boundaries. I'm kind of curious. Is it fair to say that to the extent we've drawn our boundaries and do see a reduction of free energy in this system, it reinforces the idea that there's something to that boundary structure as an entity in the world, that there's a reality to that? Is that a fair interpretation?
4050440	4084720	A	0.8929387142857141	I think many people would have a lot to say and add. This touches on the question of reification of scientific models and the ability for identified statistical model to be like transcending itself and used in a realist way, like ontologically real about true joints of the world. And I'm going to go to live stream table and find several of those who explained their research on this topic.
4085860	4105784	H	0.913852340425532	But even short of trying to claim it's real, does that ability like once we've drawn a boundary using these Markov blankets and we do see that it seems to be, let's say, using information to self evidence, do we? Think that that's I mean, it seems.
4105822	4106410	A	1.0	Like.
4108700	4120380	H	0.9724411428571431	This paradigm of thought is predicated on the idea that to the extent that that occurs and reduces free energy, it should attract, or further attract attention, at the very least, for examination or investigation.
4122720	4129010	A	0.8833995000000001	Yes. So, great questions, Jacob. Do you have something to add on that or is it a slightly different area?
4130420	4243590	G	0.9235063888888889	I guess it's kind of related to the Markov blanket discussion. This may be completely wrong, but it seems to me like with that, this kind of discretization of the Markov blankets forces us to a specific kind of discrete thinking. But I feel like that just this model of a Markov blanket. I think of it as a kind of classical model, but I presume that the reality is more something like a schrodinger Markov blanket where we can't really draw boundaries between thinking and observing a generative process. In the same way that we can think of, say, electrons as balls bouncing off each other, but we can think of them as classical particles and that will help us to an extent, but then we can also observe the process of thinking. So thinking is also kind of entangled with the generative process. So even though the Markov blanket is a useful formalism, I think that there are definitely certain scenarios that in which it's more like a probabilistic. Well, it's already probabilistic, but in the sense that the entity that's performing inference also in its own inference loop performs inference on itself and therefore thinking is at the same time an action, but at the same time it's part of the generative process.
4250850	4353940	A	0.9070467117117115	Another angle on this thanks Jacob, is what Dean T often talks about with active inference as a framework or a filter. These are just sort of like different distinctions that might be transiently useful in some axis, like fitting something to a framework. It's kind of the procrusty's bed. Stretch it out so that this perception and then active as a filter, was reminding me of what Matthew was saying, like going out and discovering divergences from expectation of there not being metabolic activity on a planet. And then there is some statistical deviation. And so, like, in the classical statistical framework, that might be like it's a one sigma difference in the Bayesian framework, well, there's a base factor of two. And here for this evidence, and there's other ways to talk about detection of novel entities that might be part of, like, a reification process of the extended cognition of the modelers. Then, like, one philosophical angle on that. And then also anyone who wants to read, then Ali is this book by Helen Longineau which talks about methodological pluralism and about how there can be, like, disciplinary rigor and the ways in which often unstated, like social priors can be the substance of what becomes understood to be science as, like, a complex phenomena. Ali and then Brock.
4355880	4452980	F	0.8708585211267607	Adding to what Yakov said, I think the concept of Markov blanket emanates from the Plutonian way of thinking, specifically hylomorphism school of thought as opposed to hylozoism. The distinction between hylomorphism and hylozoism is that, well, in hylomorphism, everything is disconnected. Every concept is disconnected and with every other concept. And so there's a discontinuity, metaphysical discontinuity between the concepts. But in hylozoism, the philosophers advocating this school of thought, well, they claim that hylomorphism fails at answering the question of what it is adequately, and they even rephrase the question. And they claim that the right question to ask is not what it is, it's what it can do. So that's basically the distinction between hylomorphism and hylozoism. But I think the mark of blanket is a way of formalizing this hylomorphic way of thinking. At least that's my opinion.
4455760	4480830	A	0.8992016666666667	Thanks a lot for that, Ollie. Eric? Sorry, I'm not hearing Eric. Can others hear Eric? Maybe I need to reload. Can you hear me? Okay, I'm going to reload.
4500250	4501250	E	0.99846	Can you hear me?
4501340	4503162	A	0.895425	Yeah, I can hear blue. Okay.
4503296	4504954	E	0.9706033333333334	You're still not hearing Eric, though?
4505072	4521584	A	0.858088125	No, sorry. Yeah, I just did, like, a small disrupt. Okay, wait, eric, try again. Okay.
4521622	4522192	D	0.9912299999999999	How about now?
4522246	4524740	A	0.9492050000000001	Yeah, now I can see you in here again. Okay.
4524890	4528660	D	0.9577314285714286	How about everyone else who's the audience?
4529240	4533430	A	0.9177225000000001	Okay. Wow. Disrupt on the high low field.
4533740	4631130	D	0.9366180092592589	It's happened before. I just throw in my two cent about my interpretation of a markup blanket. It's about trying to perform simplifications that make computation tractable. If you have everything interacting with everything else, then we can't do computing on that. So we apply compartmentalization and build objects and interfaces for how the objects interact with one another, and those become tractable. That's what a Bay's net does, is it says what are independent and what are dependent variables on each other. And that works well when those abstractions, the objects and relations, nouns and verbs are a good fit to how the world actually operates. So that is a driver for learning or building representations that will use these Markov blankets and put the compartments where they actually are faithful to the compartmentalization that we can abstract over the way the world parts in the world operate. So things that are distant, that separate, that interact only weekly, we try to maybe factor those out, pretend they don't interact at all, or use some other intermediate variables to represent the interaction in order to simplify things so we can do computation. So that's how I think Marco blankets and we'll see if the math tells us that later on when we get to it.
4632060	4651180	A	0.7966591666666667	Awesome. Brock ethanoli. Okay. I'm like not hearing Brock, unfortunately. Do you?
4651890	4655166	E	0.9292750000000001	Yes, we all hear Brock. Brock is reloading, I think now. Again.
4655268	4669250	A	0.9622857575757575	Okay. Yeah. Gather does this sometimes, but I don't know if it's because we have 15 people. Yeah, but like Matthew said, I don't hear him. It's just like there's different drop offs.
4671990	4675538	E	0.94377625	I can hear you, but I still think Daniel can't hear you. Daniel, you can't wait.
4675624	4678438	A	0.95333	Now you're back. Go for it. Okay, continue.
4678604	4680598	C	0.9901519999999999	Interesting. Can you hear me?
4680684	4681222	A	0.77	Yeah.
4681356	4682520	C	0.7849999999999999	Oh, okay.
4683770	4684518	A	0.98	Yeah.
4684684	4756800	C	0.9346414782608693	This is just this ongoing thing that I don't know, we just keeps coming up about. Yeah, well, okay, maybe they exist, maybe they don't. Markov blankets, really? But how would they form in any how would they form an evolving collapse? Presumably there is some point in that process, this evolution part where the Markov blanket is extremely poorly defined relative to the system and that's basically these sort of underexplored areas. It was also in relation to Matthew's question also about the free energy minimization thing where there's systems like non equilibrium systems basically, where still something interesting worthy of study is happening, but perhaps is not free energy minimizing in that state.
4758770	4876850	A	0.9340760995850618	Thanks for sharing it. Just a few thoughts. Let's just say some sort of meso scale or global as that's called, but that doesn't mean about the whole world, but some sort of global free energy minimization in the joint model is achieved like in a conversation that isn't the same thing as the local disconnected free energy minimization. Otherwise fitting high parameter models optimally would be simply reducing to fitting single dimensional models alone. If we could just do the linear optimization on the standalone variables, then why would we ever need the larger dimensional methods? And then think of this textbook maybe with where things could be in the coming years. The Markov membrane is like the linear algebra. And then Jacob mentioned that this is classical model. It is kind of classical in a sense, in the timeless classic sense. So the one layer Markov blanket when thinking about the rise and fall of civilization is not the end all that's. Like I think maybe analogous to a linear regression y equals MX plus B and then you have all these hundred years of development on the linear regression model and all these techniques and applications and pipelines. So the Markov blanket one layer potentially over interpreting it as already presenting with strengths or weaknesses in certain situations when not being just like empirically demonstrated. In the general case, we'll see what could be said and when. Matthew.
4879130	4903840	H	0.9279157352941173	Yeah, along those lines, I was kind of curious. I've seen that there's been a decent amount of work on the sort of hierarchical or fractal composition of these models. I'm curious if that implies that there's a fractality to the boundary by default or if there needs there any specific work on sort of hierarchical composition of the boundaries of that so called membrane. As you said.
4907570	5081960	A	0.9346247340425536	With better annotation, we could have better answers because there's many papers that we've discussed in a guest stream or a paper and there's also like many other papers obviously, that we don't have that kind of annotations of because it's quite common to see nested models in the context of nesting of cognitive processes. Like in that San Fed Smith paper, which was I think, number 25. That was about cognition as mental action. So that was nested and the nesting was interpreted as cognitive actions and counterfactuals, basically. And then sometimes nesting is used to refer to actual, like, well, the state is inside of the country and then the region is inside of the state. It's implied that the map is mapping onto the territory, maybe even spatially, the cell is inside of the tissue. And that's like answering Schrodinger's question. Everything happening with the planetary scale analyses, cellular level. And then this is hopefully what is spoken to with the composability of active inference. And sometimes that's framed in terms of the lateral composability of you could have three ants interacting or 300 ants and then the nested composability, you could have the fifth and the 7th and all those layers with computational trade offs, maybe with no extra information to be gleaned. And then learning the structure of the generative model or just the structure of the partition more broadly and like what the variables are and everything that's the structure. Learning challenge and cognition as structured learning. Hashtag synergetics geometry of thought is what Friston has and others have raised as like a total open area because there's the parameter fine tuning once you have the Bayes graph. So then you're now inside of the ability to reify or not that model. You're just doing parameter optimization. We used two factors in this linear regression and then we optimized it with the L two norm. Two is the best number of factors, but it couldn't be set at that scale. You could say in a two parameter model, this is the best parameters with this norm, but then you couldn't pull back another level. And so that's like meta scientific and metabasian analyses, which they're going to talk about later.
5083450	5121780	H	0.9469295689655167	Okay, I guess I'm also kind of wondering if there are any examples that come to mind of something like a system that is structured. Such as the clearest or simplest example that comes to mind is like, let's say that you have a nation and a state within that nation and there is a port and there is an overlap of sort of that port interface to an outside structure that is shared by both the national and overlapping national and state interests and decision processes. And so I'm kind of curious if there are examples of demonstrating that kind of composability of generative models or if that's something that's still just new and open.
5123830	5209360	A	0.9195812222222224	Those are awesome questions. If people know any some areas to investigate, like in the phenomena that you're overlapping interests informally, there would be like shared regimes of attention. There's the question of synchrony and that doesn't mean like synchronization identically but generalized synchrony. Then there's like coordination of affordances. We're not going to do this because of that. So that's like in an area that Yaako and others have been working on is just describing that situation as an affordance on an affordance or like E sub E. It's not in the textbook. But if people are staying this long then this is just kind of some ways that some people are thinking about it. And these are the areas where people can also do research and learning with us. But affordances on affordances, the safety could be on or off. So then there's like an affordance that modifies another affordance and could those have compositionality just like some of these other generalization affordances for generalization basically, what are those? And then isn't it like discovering what those are?
5217150	5249762	C	0.9207701785714283	Just I think it's kind of also related to that question of this formation evolution, collapse of markup blankets is when does the observation and actions of one system map to the preferences of another and vice versa? How does that come into being existence? How does that start to happen and how does it unhappy?
5249906	5328590	A	0.9314078494623661	I don't know. Awesome question. Thank you. And another angle on that, let me just check and then Ali is like this is a graph that we're going to look at a ton and we will interpret what all of it means. What is the OASB, pi, g, et cetera. But this is a basing graph like Eric mentioned. And the edges are like dependencies, not causal influences in the world, but apparent potentially or different interpretations. Is this the only skeleton? No, this is the Y equals MX plus b of skeletons. And there's the linear regression in the first equation in the textbook of the stats textbook. And then there's all these accessory tests. Then there's like creation and destruction as applied. Maybe there can just be a loop that's not active inference, just checking every day if something's within an arbitrary threshold. So there could be some liminal or gray area like an interface. I think steven Solette mentioned it as like a nail bed or something, like an interface between more particulate and then less particulate, more field versus the particle. Ali.
5331830	5399846	F	0.9039652941176469	Well, as a little side note, there's a popular science book coming out, I think in June, namely The Romance of Reality by Bobby Azerian, which touches on the emergence of Markup blankets, the dynamics of emergence of Markup blankets. And it attacks it from many different angles, evolutionary angle, I mean, from a cosmic, even perspective. And it even goes as far as well, considering the whole cosmos, the whole universe, as, let's say, a kind of Metamark of blanket, so to speak. And well, I think that could be an interesting thought put forward by Bob Yadarian in this book.
5399868	5400118	A	0.819995	All right.
5400124	5401110	H	0.873345	Thanks, Daniel.
5402970	5429390	A	0.9245664705882353	Thanks. In fact, he gave part one of what was intended and may still be like a multiple part discussion, but this was him giving that presentation. So we were in contact is definitely an interesting view. And it's going to take all kinds of research and education and communication. Jessica.
5432930	5536980	B	0.9136026760563378	Yes. I guess first, join the lab. Some of the ideas that helped me a little bit to start even conceptualizing this, in addition to the filter that you mentioned before, Daniel, and how it could be more like porous or more hard and allow things in and out, but it was also about it could be like just grouping of relationships and interactions. So, like, the closer like a relationship, like different things are, maybe that's more like on biological systems, I don't know if they're closely related or they have more interactions, even though they might be different, but grouping it in those sense and maybe that relates to what Eric said from the calculational part. But that was sort of like some of the things where I started connecting Marco blankets to. Okay, if items or different objects and things like they're closely related, you can start putting a blanket around and maybe go through with the idea of wrapping things from some of the definitions. But, yeah, those are kind of like the kind of visual ideas that started helping me a little bit and I still don't understand properly, but those are the things I was like, okay, so relationships, filters, kind of like connecting interactions between things.
5539990	5869804	A	0.9333236000000018	Awesome. Thanks a lot for that. Like interacting entities. So you could have the edges representing some interaction, like when people are fitting a linear model. Interacting variables. So there's this whole discussion topic of whether the interactions are like the two ants bumping into each other, whatever that means in the, quote, real world. And then there's like the statistical interaction. So then defining certain variables in statistical models. So leaving that debate behind us and just talking about the statistical models that we have, Bayesian graphs, some variables have edges between them that could be either designed to be there or not. Or you could do some sort of like thresholding. Approach and explore that your thresholding parameter was acceptable. But the more of a loose interaction you allow, the more challenge there is to fit that statistical model. And you may not have enough data to fit like the ten variable by ten variable with all the interaction terms which is like why when doing linear modeling in a health population example they would like do model selection on what their statistical power is with that data set to resolve certain kinds of effects and correlations and non sphericities. And that is addressed a lot in the SPM textbook and Kristen's earlier pre active work. But then you mentioned how to be engaged with that process of the wrapping or the seeing the clusters and then knowing where is there going to be maybe generative models arising that are consisting of other generative models or other generative processes? And then some things interact more with others statistically in a model as by design or just as an outcome of whatever. So there's sparse connectivity amongst the variables. They're not like all by all connected. And then that sparse connectivity simplifies a lot of things that's also related to like a Lasso regression and also to the below l two norms and then a sparse model can be factorized. And that is what allows for the variational Bayesian inference, which is like doing Bayesian model fitting on a factorized because it's sparsely connected graph and so a lot of these discussions are quite downstream of a lot of the philosophy of map and territory. But it's still a super important conversation. However, within the model inference, with a model inference using a model, a lot of these questions are very technical and downstream of importance qualitative things that are also important to keep in mind but of a different type, jessica or anyone else. Yeah. Wow, very interesting. Here's one other question I guess we can discuss. Like as the as it currently stands, there's a 1 hour meeting and then at the end of the hour, the very next hour begins the Tools regular organizational unit meeting. It is the people who are here now but hopefully others would be listening to it if they're not able to make this time. But what will help people with the synchronous and Asynchronous make the most of the next few months? Do people appreciate having a longer discussion for this? Do people think that the main versus the math group? Is there another subgroup, like a philosophy discussion, that people want to kind of really do this? Because we're experimenting with open endedness on our first cohort and in these early phases of the book and people can probably imagine various of the things we want to balance, like respecting everyone's time and different backgrounds, respecting their preferences for how much they want to learn about different topics. Being realistic about how much asynchronous and synchronous, direct and peripheral time makes sense. But also being realistic like there isn't a two minute video for a process. So how do people think about that, those who have stayed this far? Mike and then anyone else? Can you hear me? Yes.
5870002	5870750	I	0.85	Okay.
5872240	5872652	A	0.98	Yeah.
5872706	5950170	I	0.9507542771084337	I think that as noted earlier in the discussion, there are just so many themes that run through this that there are opportunities to pull on any of a number of threads in the course of discussion. And so today's discussion was interesting and I stayed for this part of the discussion simply because of the interesting threads that were being pulled. Certainly a contrast with the first part of the discussion around math and I think a lot of uncertainty amongst the attendees about how to engage with the mathematical aspects. Maybe to try and put a point on it, from my perspective, learning about what is active inference and how can active inference be applied in real world situations is a motivator for me participating. Obviously there are also sort of philosophical and maybe more scientific discussions that can take place. Any meeting could touch on any of those aspects as well as some of the asynchronous interaction could pick those up as well.
5951980	5953130	A	0.96327	Thanks a lot.
5954780	5955192	F	0.79	Okay.
5955246	6181504	A	0.9363237209302334	Anyone can raise their hand here's just a few other options. Like if somebody here's something that's interesting to them, we can in the discord make a channel that is relate or people can participate in the regular channels just like questions that's going to potentially be seen and interacted with by people more broadly. Like what if we posted questions that we're having we're in the cohort one of the text and we had this question do you know that's one option? Another, and this is like to Mike's expression that applied active inference is a motivator epistemic and pragmatic value, expected epistemic value. We expect to learn a lot by like staying in these sometimes challenging or oblique or whatever discussions. But then there's also expected pragmatic value with applying active inference, learning and applying active inference. So then maybe that is a group we can partition, like an applied active inference group. So then we can be clear about what the focal artifact is because also we want to not all groups at all times will be able to have nor is it useful to have open ended discussions of any discursion length. So like knowing how far and in what ways and how many minutes of people's linear time. Ali yes, the meetings, just one note on the organizational unit meetings. The organization units in the active lab like comms and tools for education, communication and tools are like directory 1 hour lab meetings or group meetings because we're not doing the education work necessarily in that 1 hour. But some groups sometimes it's possible to do some stuff, but it's like increasingly moving towards sharing updates from people who want to commit in Asynchronous work or smaller groups that want to commit to doing something like that. So then educational related projects, that's their opportunity to ask for help, share updates and so on. But earlier on there was more topical material, but then through particularization and operations and other approaches, it becomes more like Pragmatic and less discovery and less mixed media role specification, all these processes. So people sticking around is sort of the and being engaged and like seeing an affordance and then just making that contribution, wanting to be a facilitator for a certain project or wanting to contribute actively or just even connect with another participant. You can email them if they've provided their information, just some random things. But we want to have the applied angle, the philosophical loop and how to even partition that discussion. Like we couldn't just overgo every math, every philosophy, every applied question and have the judge and the jury and all this apparatus. So how can we scaffold that conversation around applied active inference for the people who are like super excited and motivated? Mike? Yeah.
6181542	6230530	I	0.9434121666666666	I just want to add there's an interesting duality related to what you just said in that we can't go into fine detail in all of the content and at the same time, I've found this group to be remarkable at unpacking things and sort of really getting into what do we mean when we say that? Types of discussions and what does this term mean not taking things for granted as going through the text. There's a balance to be struck in taking that approach of asking what do we mean when we're talking about this and putting nouns on things and relating it to language and not going too far over into getting into fine detail about things.
6237130	6390504	A	0.9385023011363639	Thank you, Lyle. And then I'll leave with your question. Yeah, this firstly great session, really great conversation, I really enjoy it. Most of this is new material for me and so I'm really enjoying the breadth of the conversation and I'm cognizant of this aspect you're digging into is how much do we sort of separate out the pieces and go deep dive in different places versus more of touching on multiple threads and their interactions? For me, while I understand there is a balance to be struck there, I'm really enjoying the challenge of relating as an example, the math to the philosophy, to all these different threads together because they are linked. Right. I do understand that some of those areas need a separate group that you can drill down into for me personally. And so this may be not the same as other people in the group. I'm really enjoying understanding the connections, the philosophy, how these different thought process came to be through history and get that depth of understanding. Thank you, Lyle. And for those who want to listen or view, these live streams have many, many themes. So check if there's papers that you're interested in here. The live streams is about papers, so there's 46 papers. Guest streams are not driven by a paper. Sometimes the person is sharing a paper. But these are like presentations, hearing from different perspectives. And if anybody wants to help organize these, that's what we do in comms. If they want to facilitate and participate in these discussions, if they want to contact authors, recommend papers, these are all distributed tasks that are leverage points for people who care to just do a ton of amazing things. Like if somebody's interested to connect it to a given community and make an artifact or a live stream co organize that, we can catalyze it at the lab scale for individuals who know about the affordance but then want to take that affordance to just have really leveraged impacts in the active ecosystem. So, ali's question and then jessica sorry.
6390542	6392456	F	0.9437185714285714	I don't have any questions you asked.
6392478	6400552	A	0.9911020000000001	About the timetable for the meetings, like what specific times are they occurring at? Sure.
6400606	6401064	F	1.0	Yeah.
6401182	6465680	A	0.9299743046357613	Okay. They are on Mondays at 13 and 23 UTC. There's two meetings to reflect, like education being the primary mission of ActInf lab, and then that spreads them out by time zones. But if somebody really wants to contribute to an area, the organizational unit meeting is not the rate limiting step. Anyone who has attention to contribute will be able to find a regime of attention that is connected to a task that's meaningful. The rate limiting step is not people's availability for a 1 hour meeting. It's however much time people want to contribute. Whatever practices and things will find something that works for people who want to be engaged. So don't take these meeting times as being like when we're doing it, when we're deciding. Even anybody who wants to can email or contact just the lab email address and be started on figuring that out. Jessica.
6468340	6546490	B	0.9240746198830408	Yes. This was related to the question about applied projects. I was thinking that maybe one thing that we could do is on the project ideas to have a table where people can briefly share what they want to do or just say, okay, I'm interested in machine learning and apply active inference and maybe this specific topic. Who will be interested in discussing this or exploring what to do and then adding the names of the people who will be interested in that. So the person who started the project, then they can start maybe contacting those people and see what time they can meet and start creating their own subgroups. So maybe that's something that we could do to facilitate that in a simple way. So just start saying, this is what I would like to do. Apply active inference while also studying the course. And we like to connect with people here who might share the same interest and see what kind of feedback that person can get.
6547740	6790856	A	0.934283911439115	Thanks. And just connecting and building trust and having like a buddy system or small groups or just people who are on the relatively long path to apply active inference on teams. We don't have the speed dating hot swap activation protocol but connecting with people. And then however it's authentic in that relationship. Seeing what you're interested in in three months will be in a pretty different situation, but we still won't have even gone through the second half of the book on the application of the textbook. So there's a lot of time for us to develop ideas and to connect with each other. So thanks for sharing that a lot. Jessica and I tagged you so that we can create a table with the right way or do it however is the right way because it helps enable connections for people who want to connect around applying. And also it helps us remember these are the specific reference points in the text that are like our attractor regime of attention for this textbook group. Like the textbook group isn't all of active flap. If people want to apply active inference, it doesn't have to be from the ground up, but it totally could be. But there's many ways to apply that are just in different codas that people can get involved in immediately. So if somebody feels like doing things, I hope they feel like they have the agency to do that. Okay, any final thoughts on this interesting semi pattern breaking? And also yes, one final thought for me is we would have had tools organizational unit meeting at this time, which is why near the end I asked if you want to do different scheduling because in general it's probably not good practice or ways of working to go overtime to respect everyone's time and all of these types of things. But also in the future we're in gather so people who want to keep discussing the textbook could go there into a different room. People who want to do Tools can go into another place. So we need to figure out how to do that through the people who want to be there, like these people and the feedback that everybody has in the ways they want to co create it. Tim and then anyone else who has like last thoughts? Hey. Yeah, I was just going to say this is generally way more interesting than the Tools meeting generally is. Cross pollination shows great potential already, I would say. Yeah, sounds good. I just wanted to add to that conversation, though, about someone even mentioned Plato, Socrates and all that and that whole sort of recursive involution of that raification thing you were talking about and sort of the thought processes maybe being almost like a recapitulation of the structure learning and the Kreptasian factor graphs and all that kind of thing you were talking about there. Plato had like a concept of knowledge which he referred to as recollection and this idea way, way back where all learning and knowledge is actually an act of recollecting what we already know. And I just wanted to point out there's kind of maybe just more of.
6790878	6792650	I	0.969255	An interesting.
6796860	6831470	A	0.9374291891891889	Illusion or connection, I guess between those two where there seems like what's old is new again. Or what have you covered? Thanks, Tim. Anyone else who hasn't spoken or who would like to add anything? Okay.
