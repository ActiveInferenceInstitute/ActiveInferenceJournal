SPEAKER_12:
okay it is may 19th 2022 and it's week three of the textbook group first cohort we're in week three discussing appendix a and b and uh there are some notes in the sections of the book in the chapters

there are also some ideas and questions that people have raised.

So we'll go to the questions and then start with the most upvoted.

So feel free to add more upvotes if you want to discuss it, like even in this discussion.

and then hopefully if people are available to take notes in this section that will help add their thoughts in and also capture what the speakers are saying and then we'll look at the question and then try to come to different answers and just add more information that people can add more structure to later okay the first question says appendix a is described as the mathematical background

so maybe question one for the authors or for you what is the process of determining what is figuring ground for the formalisms of active what other math concepts and formalisms are important for learning and applying active inference and then three what are some resources and approaches for learning math that help us learn what is what is useful for active inference

anyone can raise their hand or we can just start to add some annotations here like what should be included in the primary regime of attention with the reading of a book either linearly like some books are or in a maybe moving around the sections so what should be in the chapters what should be in the appendix what is not in the appendix

what did people expect would be in the chapter, in the appendix, not covered?

Yeah, Jessica, and then anyone else?


SPEAKER_08:
Yeah, I was wondering about the multiplication of the matrices that we covered yesterday.

Which equations have the multiplication of the matrices?

A couple of examples, just so I can play around with them.

In the actual active inference equations.


SPEAKER_12:
Does anyone know one?

This is referencing the way that the Appendix A is starting with linear algebra and then introducing this operation of multiplying two matrices to get a product.

If someone can find an equation that we've already seen or some other equation while I'm typing up that question, that would be helpful.

Could anyone just describe what they thought the intention was of starting with linear algebra and using 8.1 as the first equation of the appendix?

Or we'll return to just the more general questions.


SPEAKER_05:
I mean, linear algebra is kind of the most

discrete, I don't want to say fundamental, but like, practical and comprehensive way of kind of working with a large space of data, I guess, together and computing on it.

So it's kind of the basis for the discrete parts.

and maybe easier than the non-discrete parts.

Good reason to start.


SPEAKER_07:
I guess if the question was, where is linear algebra used in the active inference

um math um when you go to appendix b then the equations of active inference and these are all expressed in terms of large vector spaces of

variables, so probability distributions.

And so, for example, on page 245, you've got this dot notation, which is the expectation of a value.

So that that goes directly back to that first section of Appendix A is what does that mean in terms of how do you take an expectation of a large vector of things?

How do you express that compactly?


SPEAKER_12:
Thanks.

Could you unpack?

We looked at the dot notation a little bit yesterday, and they were mentioning how, well, I think it was actually one of the questions too, but just see if someone asked this.

Okay.

They say the dot operator in A3.

The dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed.

So what is the relationship with expectation?

How does expectation relate to linear algebra?


SPEAKER_07:
Yeah, expectation is the probability of a value, the average probability of some value.

So you're going to take all the possible values and you're going to multiply them by the probability of that value and then divide by the sum of the probability of normals to one.

So that will be the expectation.

So if you have a whole array or a vector of, you know, in your distribution, you can express that all in compact notation by saying with this simple way of saying, we're going to take every one of these terms and we're going to multiply it by the probability of that term.

And the probability sum to one.

So then that will be your average overall.


SPEAKER_12:
Awesome.

Thanks for that answer.

okay thanks for that awesome answer does anyone have any other thoughts on just this first question and then we'll continue so what is figuring ground we're learning active inference in the chapters that's why the chapters are there the appendix is there to somehow lightly supplement that like they describe it as

introduction or a refresher to the basic basic mathematical techniques and linear algebra is the first section a2 that is discussing a lot of important things like derivatives and probabilities Taylor series variational calculus and stochastic dynamics are going to come in in the coming chapters but the linear algebra is is a important for the upcoming chapters

Okay, so this question asked, in A3, they say the dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed, which is flipped, like it's the operation in Google Sheets or Excel, right click, paste, transpose.

They say that in the case of column matrices,

This is equivalent to the dot product.

So the dot operator here is like a generalization of the vector dot operator, the sum of the products of the corresponding entries of the two sequences of numbers.

So the questions here were, what is interpretation, implication, or use of the dot product of vectors?

And then what is an interpretation, implication, or use of a more generalized dot product?

And it looks like there's an awesome answer.

would be a situation where if anyone can think of one like the dot product would be applied like you know we're just we're trying to do this in this situation this is the operation that we needed we wanted to compute matrix a on something of something we used b dot c


SPEAKER_05:
I'll just continue Eric's description of probability.

Like, you have expectation probability, and you wanted to kind of see the error or whatever the difference, I guess, between observation and the expectation, then a dot product would give you


SPEAKER_12:
it's a probability density of it what are some ways to compute differences like you can if there are scalars you can subtract like five minus three or something then it was mentioned of cosine similarity

Does anyone think of or imagine another way that you could compute the difference between two different kinds of features of different dimensions?

Another example is divergence, because that's measuring the differences between these two distributions.

And there's different divergences.

The KL is one of them.

What other things are in this space that might be just tractable possible distance measures?


SPEAKER_07:
Well, I mean, these are the same dimensionality in all these cases, but another very popular one is the sum squared difference, sum squared error.

And then you can have absolute different value difference.

So these are called different norms.

I think that's the right word.

Yes.


SPEAKER_10:
There's also the Gini index, the Jacquard index, Euclidean distances, like sample to sample distances.


SPEAKER_12:
So could anyone talk about L0, L1, and L2, et cetera norms while I'm adding some links?


SPEAKER_07:
If I have the right numbers here, L2 norm would be the square root of the sum of squares.

L1 norm would be the average of absolute value differences.

And L0, I don't know what that is.

I don't think it's a difference, is it?


SPEAKER_12:
It's like a presence absence.


SPEAKER_07:
Okay.

Okay.


SPEAKER_12:
So that kind of encoding is used in a lot of different algorithms.

And then the L2 norm is the sum of squares.

So the L2 norm is what is used in a least squares regression, classical statistics, t-test, ANOVA.

That's a lot driven by the L2 norm.

and all of that is like in the genre of what the a3 notation is describing and there but depending on what the b and the c are and what the a is etc there's just and the dimensions of everything and other operations that are happening before or after it


SPEAKER_07:
Later on, they mentioned the quadratic, which is the L2 norm.

So that's where you have the same term as multiplied by itself.

Or if you have cross terms, then you get the covariance.


SPEAKER_12:
And that's going to be used later with the Laplace approximation and other approximation techniques.

any other comments on a3 or dot product or just like this like kind of linear algebra topic linear algebra the basics

the trace and the determinant, which are probably less important than the dot product, but still come into play, the derivatives, how things change with respect to each other, possibly time, possibly some other surface, and then probabilities.

so does anyone have any other comments or thoughts on that whole section like anything that they read or like had uncertainty around up to equation a22 great that no one has uncertainty around any of the equations up to a22

yeah i mean obviously there is a lot to like learn and to understand and we're not going to it's just i don't know people who want to think about that like what are we learning in appendix a why is appendix a there that hopefully we can start to understand some of this in math learning group the people who want to be really engaged with the math questioning and process

and then and also connecting it to computer science into the applications like has been happening and then hopefully everyone can can benefit from this like finding the resources and stuff because the relationships between the terms relationships amongst the terms are driven by formalisms like the way that preferences and expectations are framed in active inference is related to equations not

only a conceptual linkage.

Okay.

Maybe here we can just write math learning group and copy this to the resources.

Okay.

So what kinds of examples

do you think would be useful for learning the equations and concepts in Appendix A?

If the equations felt too general and not applying to anything in particular, what example or scenario would have made sense or you felt would have made that clearer?

like we're running a business and first this person wants to do this and then this person wants to do that or what example or what would somebody have expected to have found or wanted to have found that would have made it clear examples or other exercises


SPEAKER_05:
or a format this is kind of like a math lecture it's kind of directional versus like what other things could happen where you would feel like you were understanding and learning this and engaging with it yes thanks brock i was kind of reminded of a video that carl um a presentation um where he like in real time demonstrates uh and helps you

work through like a pattern of red, like it's like three dots sort of that are moving around red, green and this pattern.

And so understanding like just a simple visual example of how active inference would work that doesn't, you know, require the formalism to

just surface level kind of pattern recognize.

That would be ideal, maybe, of then bringing in the map for this part and that part and some scaffolding.

But yeah, I'm not sure the appendix, I'm not sure it was meant to be bred in...

I'm not sure there's a great way to read one order or another there, because you kind of need it, but you kind of, yeah.

It's a lot, too, right?


SPEAKER_12:
Yeah.

Great point and like the organizing team for the textbook group, which was open to everybody who wanted to join the EDU and the comms weekly meetings.

So for future cohorts, people could totally be involved with planning it, communicating it, doing anything for future cohorts as a co-organizer or other role.

But we talked a lot about the reading order.

would it make sense to read them in without appendix or putting the appendix last or somewhere else um one was short and hopefully the one week of regime of attention on appendix a and b is like we're just skimming it in a week we're not getting a phd in math

We're not generating these equations on a blank piece of paper.

We're just like seeing the forms that will be used.

And then some of the key areas in the order that the authors thought that those background topics were important.

So like for Appendix A,

linear algebra, which is what we talked the most about because it's gonna come into play most quickly, especially with these notions of like expectation and differences, which is gonna come into play with everything that's gonna happen.

Taylor series, variational calculus and stochastic dynamics, we talked less about.

They happened in a later order within the appendix, but hopefully there will still be many questions on them

because they're probably also areas with a lot to learn and to clarify.

And also Appendix A is like not the final resource of it diffusing into us.

Like something that was really important that came up in the math learning group is there's not like a glossary of variables or table of variables.

So that's something we can work on with notation is connecting the variables to natural language ontology terms.

And then also things like this.

What do we even look up?

Or a symbol, or what does it mean when there's a double arrow?

There's a lot of things that, like a lot of dots that could be connected if people ask them.

And then we can probably get a response like, what was the double arrow in A3?

What does it mean anything that they're offset or what is, what are the parts of this shape that are mattering for the background of learning active inference?

Anyone can ask like any question, if it's coming to mind as an uncertainty, then writing it down just anywhere is really helpful because then on the first pass through learning or a primary branch of learning, we can just go, okay, here's what A1 shows.

and then have that in a way that reduces uncertainty more rapidly than how any of us would just give an ad hoc explanation.

Moritz wrote.


SPEAKER_07:
Yeah, one thing that I always find useful in thinking about matrix, you know, linear algebra matrices is to write out pictures of the matrices and their dimensions.

Because often the notation, you've got these I's and J's and K's and stuff going around, but you don't know how that maps out into the actual elements of the matrix.

So those illustrations are always helpful that could be added into this book.

They're in a few places, but not that much.

There you go.

Things like that.


SPEAKER_12:
Yeah, and also connecting the programming experience that people might have, even in no-code tools like Excel, Google Sheet.

You have rows and columns.

Ones have numbers and ones have letters, but they can be other things.

And then anyone who's used something like Python or R, or even just doing some statistical calculations, if you put two lists of numbers into the t-test,

that would be vector versus vector something.

And then you would address the fifth element of the list.

And then if it was in Excel, you would need to address two numbers to say where you were in the matrix.

And then the tensor is just any number of more than

three dimensions which is sometimes like it's like oh but how spatially are we going to see it but then we're familiar with working with spreadsheets and data sets that are larger than two by two or but larger than two dimensions so like you could and that will come into play a lot and the numbers can be representing probabilities or be used for probabilities


SPEAKER_01:
I also, Daniel shared in the chat, shared a link to a Python notebook that has, there's a link and it shows kind of the operations on matrices and kind of, you know, you can see both the mathematical, yeah, there you go.

And so you can see the actual matrix and you can actually run code to there.

So that particular...


SPEAKER_12:
awesome so I pasted the link in here and then we'll just well you can fill out the rest of the row but then someone could be looking for a guide on Matrix or programming and Matrix or something before this state so then each person if they find it and add it here we'll have a lot to share and learn

okay does anybody want to like if they were the one who asked it this question I think it's probably referring to long equations that that probably none of us are ready to give answers to at this point unless somebody wants to contextualize this question

Okay, I'm hoping a read of chapter four will elucidate when the time comes.

Just exploring the formal foundations here.

Okay.

Okay.

Does anyone have a favorite or recommended textbook that contains the KL divergence and Dirichlet distribution in the index?

This is for the math learning group.

Okay.

Maybe we could tag some questions too.

And so then we can know which ones they can look at.

Wikipedia is good.

The KL divergence is approachable.

The Dirichlet is tougher.

The links take you to definitions that enable you to put the pieces together.

Okay.

Any comments on KL and Dirichlet from someone who is familiar?

Otherwise, it sounds very technical and we don't need to go into it right now.

What is up with dividing by sigma in A31?

also a detail but we'll just see if there's any questions that are not going to be specific details because math is very hard to it like understand sometimes on the fly and there's definitely a space for the interactive discussions around math that are unrecorded which are important however this is a little bit of a different format so

which is how I'm hopefully interpreting people's activity rather than their disengagements because they are here and hopefully have at least scanned these chapters.

Anyone can raise their hand at any time or add questions or upload things.

Mean field, mode, equation nine, equation 16, probability, resource, statistical question.

Appendix B, just to see if there was any, also seemed like all details.

So we have 23 minutes.

What does anybody want to ask now?

Or is there some question here, like the most upvoted one or some other one that's far less challenging that they would like to address for the next 20 minutes?

Did anyone read Appendix A or B visually?


SPEAKER_09:
Did you just ask if anyone read it?


SPEAKER_12:
Yes, what would anyone like to share about reading it?


SPEAKER_09:
I totally read it with a highlighter and made several notes in the margin in my physical book.

It was challenging.

A lot of the notation, I feel like...

is like crazy like like um i mean even just in appendix b like the very is was it the very first thing like are they using o for observations are they using o for outcomes like i was totally unclear on that um completely so like state inference markov decision processes like

Um, the states that influence outcomes.

Oh, right.

Like literally that's what it says on the top of page two 44.

So it says that the variable O is an outcome.

Is an outcome and observation.

Are those the same thing?

Are they interchangeable?

Like I've always thought it was observations.

Um, that I put that question in there.

It's already there.

Um,

And then the question right before it, like this is a really tricky section, right?

So there's the two questions that are in Appendix B that are together.

It says the likelihood of observations given a policy is not straightforward to compute.

This is because POMDP problem is structured so that policies pi influence trajectories indicated by tilde of states S that influence outcomes O without a direct influence of policies on outcomes.

The problem then involves a sum over trajectories of states to marginalize these out and find a marginal likelihood of observations given policies.

What does that these even refer to?

If you look in the questions in Appendix B, they're there in the questions already listed.

I felt like it was very obscure and not super clear, and also the notation gets crazy.

And I'm like really a stickler for like defining every single variable and symbol in an equation to understand the math so that I can actually read it in English.

So I was a little bit lost.


SPEAKER_12:
Totally agree.

Thanks for sharing it.

Eric?


SPEAKER_07:
Just with respect to that particular question, I think that these refers to the trajectories of states.

And you can see that because the sum is over the tilde S. So the tilde S is the trajectories of states.

So you sum over all the trajectories of states to try to figure out, well, what are we going to get if we apply a given policy?

That's my intuition about that.


SPEAKER_12:
And I suspect also that observations are outcomes.

They're sensory outcomes.

They're the outcome of a generative model or a generative process, but they're the outcome that is observed.

But this is just showing how many dots we need to actually unpack and connect for unsighted, grammatically vague sentences.


SPEAKER_09:
Right.

So thank you.

My uncertainty has been reduced substantially just by figuring that out.

But I felt like that the whole time I was reading the appendix.

I was like, what is even going on here?


SPEAKER_12:
Yeah.

So in this... Yes, sir.


SPEAKER_07:
The way I view it is like exercising.

You're not going to run a marathon the first time you set out, but...

You know, the more you stretch and warm up, and that's kind of, I think, that's how I kind of view this going through the appendix is kind of refreshing on what you used to know about math, or at least for me.

And so that's like stretching and doing a little bit of exercise the last week.

And then every time you go through it, every time you see the notation, you've slept on it some more.

It becomes more and more familiar.

And so you can start to put together bigger and bigger chunks.

Some vaguely you can map to the notation and the math.

Other ones, it's still going to be dangling, but that's OK because there's fewer dangling things that you're groping with at any given moment.

So I think it's great to go through these dependencies and see it all through one pass.

And all right, so I didn't run a marathon, but that's okay.

I ran two miles.

That's pretty good for a start.


SPEAKER_12:
Thanks, Eric.

Another, like, metaphor is just like, oh, yes, please, Jakob.


SPEAKER_06:
Yeah, I was just going to comment on what Blue said with kind of some confusion about the notation because I asked the question about the

marginalizing of states but then i was also confused about the o notation because um in the in equation b b.1 it kind of it it seems that it's a trajectory over outcomes but then there's also an o without a tilde on it so does that mean that it's an outcome at a particular point in time but then there's also a bold o

which implies that it's kind of a vector.

But if it's a trajectory of outcomes, that also seems to be a vector.

A trajectory, for me, implies some kind of vector form because it's a sequence of outcomes given a policy.

But then what does that bold O mean if not trajectories over outcomes?

So just to kind of add to the confusion, I guess.


SPEAKER_09:
Thanks, Jakob.

I'm glad, like, we're grokking.

We're on the same page, you and I. For sure.


SPEAKER_12:
It would be awesome for a description or any notes.

What is the reading or a reading in language?

The this of this conditioned on that.

Is this over that of these two things?

The first thing is this, the second one is that.

An example of that is in this situation.

Here's the script.

Here's the graphical abstract.

Here's the paper.

Here's the person you could ask.

Which one of these do you think is going to be interesting?

Okay, so Mike asked, and I'll copy this in.

For those who have read the entire book, did you find the appendices useful as you went along through the chapters?

Ali?


SPEAKER_00:
Yeah, I also think that if the materials in these two appendices were to be integrated in the linear

narrative of the whole book it would be much more useful than separating out as I mean separate appendices because as we see I mean that's my own experience well reading the chapters independently and in isolation of the narrative doesn't give me a sense of their

uh concrete applications and i don't know how to use them and how to use these for all of these equations and everything becomes much more fuzzy


SPEAKER_12:
i hope this is not controversial that linear reading of the appendix as something that you look through is extremely confusing or extremely imprecise because there's many symbols introduced that might have been introduced earlier like oh is probably discussed earlier but then it's briefly just sort of mentioned and then there's a lot of symbology that's not mentioned what it is

So it's hard to read the appendix without prior knowledge, yet ostensibly Appendix A is the introduction refresher.

So is this the introduction offering?

They hope, so they expect and prefer perhaps, the appendix to go some way towards remedying it

being the maths required to understand this not complicated basis.

The multidisciplinary basis means it is often difficult to find resources that bring together the necessary prerequisites.

They're going some way.

so this is like one kind of plank out there from their point of view from the chapters this is stuff and ali i also kind of agree like on what what ordering these are really interesting questions so then what is the next connector that picks up here with this artifact because um like someone mentioned how um

more it's mentioned you could basically do a whole course on deep learning to apply most of the matrix operations and whole courses on like the math of them so they can't go into all this detail they can't spend one hour or like multiple coda pages on just what this means so there has to be some kind of compromise but then there's not going to be one specific perfect compromise

with, especially with like length and audience considered?


SPEAKER_09:
So I think like, I mean, I undertook like a very detailed linear reading of the book because that's just kind of how I am of the appendixes at least.

But I think for many people that like, I mean, I've been there before, like where you're staring at math equations, like this is gibberish, but like, so just to read the text, you know, and like to read it and go through it, it's helpful to know that it's there.

So if nothing else, at least you can be reading the book and then be like, oh, I remember kind of reading about, you know,

Taylor series expansion in the appendix.

And so then you can just go back and just having access to it or the refresh recall access.

Even though it is confusing, I agree to try a linear read of the appendix.

I think skimming over it or deeply reading it and then being able to refer back to it is useful.


SPEAKER_12:
Thanks, Blue.

So in next week...

are going the next two weeks so the pace of one section per week might be like whatever it was for you however much time you put in etc the coming chapters are going to be very different because one didn't have any formalisms or figures really just the kind of overview figures but we're gonna have two weeks for two so

no need to rush it read a couple pages and then just go back to the beginning and just restart the same pages like that's like the multiple coats of paint in a mural like the low road to active inference that's where they're going to pick up in that high road low road um dialectic that we talked about last time let's just see like what figures what equations might happen okay a lot of terms

that hopefully are in the ontology already.

Like you can use the at symbol, hopefully to call most of them.

But if something's not there, we can add it to supplemental or entailed.

Okay, so what figures and equations we might see.

Here's a box, 2.1, about probability.

here's an equation that's the Bayesian kernel and it's going to be talking about this example of a frog and an apple and jumping or not jumping and that example is going to play a current role but then some likelihoods are shown in a specific example of like frogs and jumping or not and apples

There's a work through example of exact Bayesian inference.

Here's a table on statistical distributions.

It would be really interesting like to hear what support and surprise mean.

And why, what are these, are these all the distributions?

Are there other ones or like why these ones or why are they useful?

Where have they been used?

What does it even mean?

Here's where the KL divergence is introduced.

And then some more analysis from a surprise perspective, Bayesian surprise with the KL divergence.

There's the box on expectations, which is also what we talked about a little bit today.

And that was like really interesting to connect it to the matrices.

A figure.

of the generative process and the generative model is the caption.

A figure.

Both perception and action minimize discrepancy between model and world.

Variational free energy.

variational free energy as an upper bound on negative log evidence the figure but with equations in it very common format bigger complementary roles of perception and action in the minimization of variational free energy big active theme and like something kind of a common fristinism

like perception and action being in the same game or being in the same service of the same objective function.

Planning, but no specific equations, but probably citations.

Just introducing expected free energy, which Jakob and others can probably go into a lot more detail on.

expected free energy about a future where the outcomes haven't happened expected free energy figure with equations the end of the low road introducing the two key terms variational free energy expected free energy summary

does anybody like want to like add or what was something cool or whether they read it already or not what does anyone oh ali yes please


SPEAKER_00:
Well, I've noticed the dispersion of some sidebar boxes like box 2.1 or in this chapter.

I don't know the distinction between the purpose of these boxes and, I mean, what's the function of these boxes as compared to what we see in the appendices, because presumably these

Boxes cover the concepts that could be skipped over if one is familiar with these mathematical concepts.

So, do you have any idea about the reason behind this decision?

I mean, covering some basic concepts, basic mathematical concepts in these sidebar boxes and some others in the appendices?


SPEAKER_12:
that's a great question a box could reflect like okay expectations got it or like okay some product rule all right but it's kind of like you might want to read that or is this introductory highlighting it this is the 101 on probability or is it saying this is a total skippable unit if you want to learn about how the lizard does it here's where you look

It can sometimes mean both.

The format of the book is also relatively austere, though in a concise tone.

It's in black and white, which, especially in some later sections, makes some visualizations where it's hard to understand what curves are doing what.

a black and white image so what is there to see with the color i mean but it also might predispose towards more simple or visually accessible material so what is going to be accessible

the order so those are all really important questions so we can just take notes on it you know in the weeks that we're going to continue to do this because we only have limited live time how about in the last like three minutes what does anybody think about the opening quotations or specifically this quotation my thinking is first and last and always for the sake of my doing william james


SPEAKER_07:
You know, I thought the guy was a philosopher, so I guess you disabused me of that one.


SPEAKER_12:
Yeah.

These would be really nice areas to look into for people who like the history part.

Blue and I and others are working on some different kinds of ways to reference papers and just, oh, cool paper.

Sensation, perception.

We have those terms.

We could just link the paper somewhere.

So if anyone's interested in that kind of architectures or that kind of philosophy question, those are

the literature right now is small enough to know what has and hasn't been done in a lot of areas that are philosophical and applied and technical but just from like a first principles what does this seem to mean uh that shared that other group that were kind of both a part of Daniel um


SPEAKER_05:
liminal Tao thing that's not really a Tao I don't know what it is but there's this debate for some reason that's going on there about you know different ways of knowing and being and doing and a bunch of stuff that is kind of

a mix of philosophy and linguistic fallacies.

But if thinking is actually a physical process, which I think, you know, I don't think anyone here is going to argue against, then it is something necessarily that is being done.

And so however, I guess, small, you want to draw that Markov blanket, and then however large, whether that's your physical body actions or some extended thinking, it's literally what you're doing.

It's not just for the sake of your actions, but they are your actions.

Like, they're just another set of your actions.


SPEAKER_07:
All right.

I'll offer a different take on it.

Yeah, awesome.

William James was a great visionary.

And he foresaw Mark Zuckerberg's metaverse 120 years ago or whatever.

And he said, no.

I don't want to live just inside my mind, inside the metaverse.

I want to be out in the world, interact with real people and real things.

So he was a meta or Facebook skeptic way before his time.


SPEAKER_12:
Okay, thank you, Ali.


SPEAKER_00:
As Brock mentioned, I think it relates to an epistemological distinction between propositional knowledge and how-to knowledge.

And I think this statement here tries to blur this distinction, blurs the line between

propositional knowledge and know-how knowledge, because especially in analytical school of philosophy, there's always been a very, let's say, not heated debate, but there's a longstanding debate about the distinction between these

two kinds of knowledge and whether they're in fact they can be distinguished from each other or not thank you could you just unpack what are the two kinds of knowledge again and what are just they referring to

Sure.

Well, about propositional knowledge, well, an example of propositional knowledge is to know the exact mechanisms of walking.

I mean, which muscles contract and which, I mean, in what angles.

I mean, the whole thing about the...

Biomechanics of walking, the whole knowledge about the biomechanics of knowledge can constitute this kind of propositional knowledge.

And it's totally different from knowing how to walk.

I mean, a three or four year old child has a know-how knowledge.

of walking but not necessarily where he or she doesn't know anything about the biomechanics of walking.

So the biomechanics of walking is the propositional knowledge.

Actually knowing how to walk constitutes the know-how of walking.


SPEAKER_12:
so when people say things like active inference is integrating perception cognition and action maybe it is rethinking some of these long-held mental frameworks for distinguishing or operating differently on action and perception like one fascinating recent example from me was and working with eric was

In the area of ant pheromone modeling, without going into too many details, people often modeled preference as a function of the absolute amount of pheromone on trails.

Because that's what the exponential light decay is on, that's what can be manipulated, rather than the perceived intensity.

which might have a different scaling relationship.

So it's like a dim room, you can detect a small change.

Bright room, you can't detect a small change.

So that kind of psychophysics of perception gets ignored implicitly because of calls for measurability, because the cognitive can't be measured directly, even if you potentially had a electrical measurement or something like that happening.

then these are awesome questions can you think without acting or is thinking in action this active paper which was on a live stream so we can provide the link to

it models like perception and action in the sort of like kernel level just the autonomous sensing sentient bot level and then attention and metacognition are both related as actions to the lower level which is like why the paper is relating computational phenomenology with mental action

Again, just to have like a look at the kinds of models that can happen.

And then now, does making any model fitting any data well enough and saying, well, we modeled it as action.

So is thinking an action?

Will that model that says, yeah, it's consistent with that, will that ever constitute positive evidence for saying thinking is action?

Or why even say that?

Or what does it mean to say it?

And then here's a funny meme.

Here's the generative model and the generative, the partially observable Markov decision process.

Here's Carl Friston.

Jessica, and then anyone else?


SPEAKER_08:
Yes.

I guess it's sort of like a beginning understanding of this is that

I tend to think that there's like a bias towards action in active inference.

I think like the first chapter is saying like, you know, even if you want to like sense or like perceive, you have to do some kind of action in order to gain the information.

And this like, you know, quote is basically saying like, okay, even though the whole field is trying to understand cognition, it's sort of like

what we decide to do and the thinking that we go through in order to determine our policy is to determine our actions.

And then it sort of like feed into, um, the thinking itself.

So maybe that's why there's like the bias to action.

Um, because like our actions is what it's going to be allowing the thinking, but, um,

when we update our models or like, you know, trying to come up with like the policies that we're going to be doing, like we have to be processing things.

So, you know, the thinking is in like as a service to action.

And that's sort of like what I was thinking.

I don't know.

It's a little bit like, you know, with the chicken and the egg, but yeah,

You know, I kind of tend to think of it as like, yes, we have to act in order to understand, but like the understanding which will be coming from the thinking is what determines our next action.

Yeah, that's kind of what I was thinking.


SPEAKER_12:
Matthew?

Thanks, Jessica.


SPEAKER_11:
yeah i mean it kind of seems to me like we're stuck in a little bit of a linguistic godelian loop of some sort because you know thinking is you know essentially a verb and verbs tend to imply in like a linguistic emergent term actions and so we have to then pop outside of that and try to consider with our internal mental processes how to disentangle these concepts but i see no reason to think

that to think ironically, that internal mental states aren't also conscious parameterizations of processes in the brain and our ability to grasp control of that to some extent.

And so it seems very strange to me to try to separate those linguistically from our current vantage point, even though I understand why historically working only with language, it might have made sense.

So those kind of quotes like James's strike me as somewhat antiquated or just operating on dichotomies that don't seem to make sense given that we've unpacked these processes to the degree we have.


SPEAKER_12:
Thank you, Matthew.

Very deep points.

Like you mentioned, thinking as a verb implies action.

And then just to kind of complete that, thought is like the word or the noun form of this one.

So then what does that imply?


SPEAKER_11:
And then also, like Jessica mentioned... To some extent, we can only express processes through their discretization via symbols, right?

The idea that there's this process, there's a flow, there's something that can't necessarily be separated, obviously, from the rest of the flows around it, but to reference it, to point to it, to describe it, communicate it to another agent, we have to nounize it

kind of like, which is the opposite of verbalizing, so to speak.


SPEAKER_12:
Wow, thank you, Matthew.

Again, these are, yes, Eric?

sorry i didn't have anything i didn't do it okay the hand was yeah so um carl friston had a influential 2019 uh paper long paper

the free energy principle for a particular physics so that was in 2019 so it's been several years since then and like particular allegedly slash accidentally or intentionally is a pun so it can mean specific like a physics for the specific systems that we're modeling or it could be specific like this is a specific approach

Another interpretation is it's for particulate entities.

When we define thing and the partition, which is going to co-instantiate the generative model and the generative process, and then the Markov blanket or the interface that's separating them, that is separating the figure from ground.

It's separating the entity from the niche.

It's separating what from what?

what what can it represent the separation of something from all possible separations some separations and then Matthew you mentioned like yeah verbalizing speech but it feels like we're speaking that's sometimes yet verbalization is a process especially um dialogue yes Matthew


SPEAKER_11:
Could I ask a question that brings in a little bit of content from the other chapters of the book?

Yeah, sure.

I'm just kind of curious, because when you're talking about the Markov blankets and integrating it into this idea of how we draw boundaries, I'm kind of curious.

Is it fair to say that to the extent we've drawn our boundaries and do see a reduction of free energy in this system, it reinforces the idea that there's something to that

boundary structure as an entity in the world, that there's a reality to that.

Is that a fair interpretation?


SPEAKER_12:
I think many people would have a lot to say and add.

This touches on the question of reification of scientific models.

and the ability for a identified statistical model to be like transcending itself and used in a realist way like ontologically real about true joints of the world and um i'm gonna go to live stream table and find several of the of those who explained their research on this topic


SPEAKER_11:
But even short of trying to claim it's real, like, is it just, does that ability, like once we've drawn a boundary using these Markov blankets, and we do see that it seems to be, let's say, using information to self-evidence, do we think that that's, I mean, it seems like this paradigm of thought is predicated on the idea that

to the extent that that occurs and reduces free energy, it should attract or further attract attention, at the very least, for examination or investigation.


SPEAKER_12:
Yes, so great questions.

Jakob, do you have something to add on that?

Or is it a slightly different area?


SPEAKER_06:
I guess it's kind of related to the Markov blanket discussion.

This may be completely wrong, but it seems to me like with

Um, that this kind of discretization of the Markov blankets forces us to a specific kind of discrete thinking.

But I feel like that just this model of a, of a Markov blanket, I think of it as a kind of classical model, but I presume that the reality is more something like a Schrodinger Markov blanket where it's not, we can't really draw boundaries between

thinking and observing and generative process in the same way that we can think of say electrons as balls bouncing off each other but they're not really we can think of them as classical particles and that will help us to an extent but then we can also observe the process of thinking so thinking is also kind of entangled with the generative process so there's

So even though the Markov blanket is a useful formalism, I think that there are definitely certain scenarios in which it's more like a probabilistic, well, it's already probabilistic, but in the sense that the entity that's performing inference also in its own inference loop

performs inference on itself, and therefore thinking is at the same time an action, but at the same time it's part of the generative process.


SPEAKER_12:
Okay, another...

angle on this, thanks Jacob, is what Dean T. often talks about with like active inference as a framework or a filter.

These are just sort of like, you know, different distinctions that might be transiently useful in some axis, like fitting something to a framework.

It's kind of the Procrustes bed.

Stretch it out so that this perception and then active as a filter was reminding me of what Matthew was saying, like going out and discovering

divergences from expectation of there not being metabolic activity on a planet and then there is some statistical deviation and so like in the classical statistical framework that might be like it's a one sigma difference in the bayesian framework well there's a base factor of two and here for this evidence

there's other ways to like talk about detection of novel entities that might be part of like a reification process of the extended cognition of the modelers and then like one philosophical angle on that and then also anyone who who um wants to then ali is um this book by helen longino which talks about methodological pluralism

about how there can be like disciplinary rigor and the ways in which often unstated like social priors can be the substance of what becomes understood to be science as like a complex phenomena um ali and then brock


SPEAKER_00:
Adding to what Yakov said, I think the concept of Markov blanket emanates from the Platonian way of thinking, specifically the hylomorphism school of thought as opposed to hylozoism.

The distinction between hylomorphism and hylozoism is that in hylomorphism,

Everything is disconnected.

Every concept is disconnected with every other concept.

And so there's a discontinuity, a metaphysical discontinuity between the concepts.

But in hylozoism, the philosophers advocating this school of thought, well, they claim that hylomorphism is

fails at answering the question of what it is adequately.

And they even rephrase the question and they claim that the right question to ask is not what it is, it's what it can do.

So that's basically the distinction between hylomorphism and hylozoism.

But I think the Markov blanket

is a way of formalizing this hylomorphic way of thinking.

At least that's my opinion.


SPEAKER_12:
Thanks a lot for that, Ali.

Eric?

Sorry, I'm not hearing Eric.

Can others hear Eric?

Maybe I need to reload.

Okay, I'm going to reload.


SPEAKER_09:
Dando, can you hear me?


SPEAKER_12:
Yeah, no, I can hear Blue.

Okay, you're still not hearing Eric, though.

No, sorry.

Yeah, I just did like a small disrupt.

Okay, I'm gonna... Okay, wait, Eric, try again.

Okay, how about now?

Now I can see you in here again, okay.


SPEAKER_07:
How about everyone else?

Who's the audience...


SPEAKER_12:
Okay, wow.

Disrupt on the high-low field.


SPEAKER_07:
It's happened before.

I would just throw in my two cents about my interpretation of a Markov blanket.

It's about trying to perform simplifications that make computation tractable.

If you have everything interacting with everything else, then we can't do computing on that.

So we apply...

compartmentalization and build objects and interfaces for how the objects interact with one another.

And those become tractable.

That's what, you know, what a Bayes net does is it says what are independent and what are dependent variables on each other.

And that works well when those abstractions, the objects and relations of nouns or verbs are a good fit to how the world actually operates.

So that is a driver for learning or building representations that will use these Markov blankets in

and put the compartments where they actually are faithful to the compartmentalization that we can abstract over the way the parts in the world operate.

So things that are distant, that interact only weekly, we try to maybe factor those out, pretend they don't interact at all, or use some other intermediate variables to represent the interaction in order to simplify things so we can do computation.

So that's how I think Markov blankets.

And we'll see if the math tells us that later on when we get to it.


SPEAKER_12:
Awesome.

Brock?

And then Nellie.

Okay, I'm, like, not hearing Brock, unfortunately.

Do you?


SPEAKER_09:
Yes, we all hear Brock.

Brock is reloading, I think, now again.


SPEAKER_12:
Okay.

Yather does this sometimes...

But I don't know if it's because we have 15 people.

Yeah, but it's, yeah, like Matthew said, I don't hear him.

It's just like there's different drop-offs.


SPEAKER_09:
I can hear you, but I still think Daniel can't hear you.

Daniel, you can't hear Brock.


SPEAKER_05:
Wait, Brock, now you're back.

Go for it.

Okay, continue.

Interesting.

Can you hear me?


SPEAKER_12:
Yeah.


SPEAKER_05:
Oh, okay.

Yeah, no, this is just this ongoing thing that I don't know, we just keep keeps coming up about.

Yeah, well, okay, maybe they exist.

Maybe they don't markup blankets, really.

But like, how would they form in any?

How would they form and evolve and collapse?

Presumably there is some point in that process, this evolution part, where the Markov blanket is extremely poorly defined relative to the system.

And that's basically these sort of underexplored areas.

It was also in relation to Matthew's question also about the free energy minimization thing, where there's systems like non-equilibrium systems, basically, where still something interesting worthy of study is happening, but perhaps is not...

free energy minimizing in that state.


SPEAKER_12:
Thanks for sharing it.

Just a few thoughts.

Let's just say some sort of mesoscale or global, as that's called, but that doesn't mean about the whole world, but some sort of global free energy minimization in the joint model is achieved, like in a conversation.

That isn't the same thing as the local disconnected free energy minimization.

Otherwise fitting high parameter models optimally would be simply reducing to fitting single dimensional models alone.

If we could just do the linear optimization on the standalone variables, then why would we ever need the larger dimensional methods?

And then like think of this textbook

maybe with where things could be in the coming years, the Markov membrane is like the linear algebra.

And then Jakob mentioned that this is classical model.

It is kind of classical in a sense, in the timeless classic sense.

So the one layer Markov blanket, when thinking about like the rise and fall of civilization is not,

to end all.

That's like, I think maybe analogous to a linear regression, Y equals MX plus B. And then you have like the high, all these hundred years of development on the linear regression model and all these techniques and applications and pipelines.

So the Markov blanket one layer, potentially over-interpreting it as already presenting with strengths or weaknesses

in certain situations when not being just like empirically demonstrated in the general case we'll see what could be said and when matthew


SPEAKER_11:
Yeah, along those lines, I was kind of curious.

I've seen that there's been a decent amount of work on the sort of hierarchical or fractal composition of these models.

I'm curious if that implies that there's a fractality to the boundary by default, or is there any specific work on sort of hierarchical composition of the boundaries of that so-called membrane, as you said?


SPEAKER_12:
with better annotation we could have better answers because there's many papers that we've discussed in a guest stream or a paper and there's also like many other papers obviously that that we don't have that kind of annotations of um because it's quite common to see nested models in the context of

nesting of cognitive processes like in that sanford smith paper which was i think number 25 that was about cognition as mental uh action so that was nested and the nesting was interpreted as cognitive actions and counterfactuals basically and then sometimes nesting is used to refer to actual like well the state is inside of the country and then the region is inside of the state like it's a it's implied that the map is mapping on to the territory

maybe even spatially the cell is inside of the tissue and that's like answering schrodinger's question everything happening with the planetary scale analyses cellular level um and then this is hopefully what is uh spoken to with like the composability of active inference and sometimes that's framed in terms of like the the lateral composability

of like how you could have three ants interacting or 300 ants and then the the nested composability you could have the fifth and the seventh and all those layers

with computational trade-offs, maybe with no extra information to be gleaned, and then learning the structure of the generative model or just the structure of the partition more broadly and like what the variables are and everything, that's the structured learning challenge.

And cognition as structured learning, hashtag synergetics, geometry of thought, is what Fristin has,

and others have raised as like a total open area because there's the parameter fine tuning once you have the Bayes graph.

So then you're now inside of the ability to reify or not that model.

You're just doing parameter optimization.

We used two factors in this linear regression and then we optimized it with the L2 norm.

Two is the best number of factors.

But it couldn't be said at that scale.

You could say in a two parameter model, this is the best parameters with this norm, but then you couldn't pull back another level.

And so that's like meta-scientific and meta-Bayesian analyses, which they're going to talk about later.


SPEAKER_11:
OK, I guess I'm also kind of wondering if there are any examples that come to mind of something like a system that is structured such as the clearest or simplest example that comes to mind is like, let's say that you have a nation and a state within that nation and there is a port and there is an overlap of sort of that port interface to an outside structure that is shared by both the national and overlapping national and state.

interests and decision processes.

And so I'm kind of curious if there are examples of demonstrating that kind of composability of generative models, or if that's something that's still new and open.


SPEAKER_12:
Those are awesome questions, if people know any.

Some areas to investigate, like in the phenomena that you're overlapping interests informally,

there would be like shared regimes of attention there's the question of synchrony and that doesn't mean like um synchronization identically but generalized synchrony then there's like coordination of affordances we're not going to do this because of that so that's like

and an area that Jakob and others have been working on is just describing that situation as an affordance on an affordance or like E sub E. It's not in the textbook, but if people are staying this long, then this is just kind of some ways that some people are thinking about it.

And these are the areas where people can also do research and learning with us.

But like affordances on affordances.

safety could be on or off so then there's like an affordance that modifies another affordance and could those have compositionality just like some of these other um generalization affordances for generalization basically what are those and then isn't it like discovering what those are


SPEAKER_05:
Just really, I think, it's kind of also related to that question of this formation, evolution, collapse of Markov blankets is when, when does the observation actions of one system map to the, to the preferences of another and vice versa?

How does that come in to


SPEAKER_12:
being existence how does that start to happen and how does it unhappen i don't know awesome question thank you and and another like angle on that let me just check it um and then ali is like this is a graph that we're going to look at a ton and we will interpret what all of it means what is the o a s b pi g etc but

This is a Bayesian graph, like Eric mentioned, and the edges are like dependencies, not causal influences in the world, but apparent potentially or different interpretations.

Is this the only skeleton?

No, this is the y equals mx plus b of skeletons.

And there's the linear regression in the first equation in the textbook of the stats textbook.

And then there's all these accessory tests.

Then there's like creation and destruction as applied.

Maybe there can just be a loop that's not active inference, just checking every day if something's within an arbitrary threshold.

So there could be some liminal or gray area

Like an interface, I think Steven Silette mentioned it as like a nail bed or something.

Like an interface between more particulate and then less particulate, more field versus the particle.

Ali?


SPEAKER_00:
Well, as a little side note, there's a popular science book coming out, I think, in June, namely The Romance of Reality by Bobby Azarian, which touches on the emergence of markup blankets, the dynamics of emergence of markup blankets, and it attacks...

It attacks it from many different angles, evolutionary angle, I mean from a cosmic even perspective and it even goes as far as, well, considering the whole cosmos, the whole universe

as, let's say, a kind of meta-Markov blanket, so to speak.

And, well, I think that could be an interesting thought put forward by Bobby Zarin in this book.


SPEAKER_12:
All right.

Thanks, Daniel.

Thanks.

In fact, he gave part one of what was intended and may still be like a multiple part discussion.

This was him giving that presentation.

So we were in contact.

It's definitely, you know, it's an interesting view.

And it's going to take all kinds of research and education and communication.

Jessica?


UNKNOWN:
Yes.


SPEAKER_08:
Yes, I mean, I guess when I first joined the lab, some of the ideas that helped me a little bit to start even conceptualizing this, I mean, in addition to the filter that you mentioned before, Daniel, and how

It could be more porous or more hard and allow things in and out.

But it was also about... It could be just grouping of relationships and interaction.

So the closer a relationship... Different things are... Maybe that's more on biological systems.

I don't know.

If they're closely related or they have more interactions, even though they might be different, but...

grouping it in those sense.

And maybe that's relates to what Eric said and from the calculation of part, but that was sort of like, you know, some of the things like where I started connecting on Mark of Blankets to sort of like, okay, if, you know, items or like different objects and things like they're closely related, you can start like putting on like a blanket around

And maybe it goes with the idea of wrapping things from some of the definitions.

But yeah, those are kind of the kind of visual ideas that started helping me a little bit.

And I still don't understand properly, but those are the things I was like, okay, so relationships, filters, kind of like connecting interactions between things.


SPEAKER_12:
Awesome.

Thanks a lot for that.

Like interacting entities.

So you could have the edges representing some interaction.

like when people are fitting a linear model, interacting variables.

So there's this whole discussion topic of whether the interactions are like the two ants bumping into each other, whatever that means in the quote real world.

And then there's like the statistical interaction.

So then defining certain variables in statistical models.

So leaving that debate behind us and just talking about the statistical models that we have Bayesian graphs.

some variables have edges between them that could be either designed to be there or not, or you could do some sort of thresholding approach and explore that your thresholding parameter was acceptable.

But the more of a loose interaction you allow, the more challenge there is to fit that statistical model.

and you may not have enough data to fit the 10 variable by 10 variable with all the interaction terms, which is why when doing linear modeling in a health population example, they would do model selection on what their statistical power is with that data set to resolve certain kinds of effects and correlations and non-sphericities.

And that is addressed a lot in the SPM textbook.

and for instance earlier like pre-act-inf work but then you mentioned like how to like be engaged with that process of like the wrapping or the seeing the clusters and then knowing like where is there going to be like maybe generative models arising that are consisting of other generative models or other generative processes and then like some things interact more with others

statistically in the model as by design or just as an outcome of whatever.

So there's sparse connectivity amongst the variables.

They're not like all by all connected.

And then that sparse connectivity simplifies a lot of things.

That's also related to like a lasso regression and also to the below L2 norms.

And then a sparse model can be factorized.

And that is what allows for the variational Bayesian inference, which is like doing Bayesian model fitting on a factorized because it's sparsely connected graph.

And so a lot of these discussions are quite downstream of a lot of the philosophy of map and territory, but it's still super important conversation.

However, within the model, inference with a model, inference using a model,

a lot of these questions are are very technical and downstream of importance qualitative things that are also important to keep in mind but of a different type jessica or anyone else yeah wow very interesting

one other question i guess we can discuss like as the as it currently stands there's a one hour meeting and then at the end of the hour the very next hour begins the dot tools regular organizational unit meeting so is there i mean it is the people who are here now but hopefully others would be listening to it if they're not able to make this time but like

what will help people with the synchronous and asynchronous make the most of the next few months do people appreciate having a longer discussion for this do people think that the main versus the math group like is there another subgroup like a philosophy discussion that people want to like kind of really do this

because we're not like we don't we're experimenting with open-endedness on our first cohort and in these early phases of the book and people can probably imagine various of like the things we want to balance like respecting everyone's time and different backgrounds respecting their preferences for how much they want to learn about different topics being realistic about how much asynchronous and synchronous

direct and peripheral time makes sense but also being realistic like there isn't a two minute video or a process so how do people think about like that those who have stayed this far

Mike, and then anyone else.


SPEAKER_13:
Can you hear me?


SPEAKER_03:
Yes.

Okay.

Yeah, I think that, as noted earlier in the discussion, there are just so many themes that run through this that there are opportunities to pull on any of a number of threads in the course of discussion.

And so today's discussion was interesting, and I stayed...

for this part of the discussion, simply because of the interesting threads that were being pulled.

Certainly a contrast with the first part of the discussion around math, and I think a lot of uncertainty amongst the attendees about how to engage with the mathematical aspects.

And so maybe to try and put a point on it, from my perspective,

Learning about what is active inference and how can active inference be applied in real world situations is a motivator for me participating.

obviously, there are also sort of philosophical and maybe more scientific discussions that can take place.

And so any, any meeting could touch on any of those aspects, as well as some of the asynchronous interaction could pick those up as well.

Thanks a lot.


SPEAKER_12:
Okay, anyone can raise their hand.

Here's just a few other options.

Like if somebody, here's something that's interesting to them.

We can, in the Discord, make a channel that is related, or people can participate in the regular channels, just like questions, like, or, and that's going to potentially be seen and interacted with by people more broadly.

Like, what if we posted questions that we're having?

We're in the cohort, one of the techs, and we now had this question.

you know that's one option another um and this is like to mike's um expression that applied active inference is a motivator epistemic and pragmatic value expected epistemic value we expect to learn a lot by like staying in these sometimes

challenging or oblique or whatever discussions but then there's also expected pragmatic value with applying active inference learning and applying active inference so then maybe that is a group we can partition like an applied active inference group so then we can be clear about what the focal artifact is because also we want to like not

all groups at all times will be able to have uh nor is it useful to have open-ended discussions of any discussion length so like knowing how far and in what ways and how many minutes of people's linear time um ali yes

the edu meetings well just one note on the organizational unit meetings the organization units in the act info lab like edu comms and tools for education communication and tools are like directory one hour

lab meetings or group meetings because we're not doing the education work necessarily in that one hour but some groups sometimes it's possible to do some stuff but it's like increasingly moving towards sharing updates from people who want to commit in asynchronous work or smaller groups that want to commit to doing something like that so then

educational related projects, that's their opportunity to ask for help, share updates, and so on.

But earlier on, there was more topical material

But then through particularization and operations and other approaches, it becomes more like pragmatic and less discovery and less mixed media role specification, all these processes.

So people sticking around is sort of the, and being engaged and like seeing an affordance and then just making that contribution

wanting to be a facilitator for a certain project or wanting to contribute actively or just even connect with another participant like you can email them if they've provided their information just some random things but like we want to have the applied angle the philosophical loop and how to even partition that discussion

we couldn't just over go every math every philosophy every applied question and have the judge and the jury and all this apparatus so how can we scaffold that conversation around applied active inference for the people who are like super excited and motivated mike


SPEAKER_03:
Yeah, I just wanted to add, there's an interesting duality related to what you just said in that we can't go into fine detail in all of the content.

And at the same time, I've found this group to be remarkable at unpacking things and sort of...

really getting into what do we mean when we say that types of discussions and what does this term mean?

Not taking things for granted as going through the text.

And so there's a balance to be struck in taking that approach of asking what do we mean when we're talking about this and putting nouns on things and relating it to language and not going too far over into getting into fine detail about things.


SPEAKER_12:
Thank you, Lyle.

And then I'll leave it to your question.


SPEAKER_04:
Yeah, this has been personally a great session, really great conversation.

I really enjoy it.

This is new.

Much of this, most of this is new material for me.

And so I'm really enjoying the breadth of the conversation and I'm cognizant of this aspect you're digging into is, you know, how much do we sort of separate out the pieces and go deep dive in different places versus more of a, you know, touching on multiple threads and their interactions.

Uh, for me, while I understand there is a balance to be struck there, I'm really enjoying the challenge of relating as an example, the math to the philosophy, to all these different threads together because they are linked.

Right.

And, and so I do understand that you can't, some of those, some of those areas

need a separate group that you can drill down into for me personally and so this may be not the same as other people in the group i'm really enjoying understanding the connections the philosophy how these different thought processes came to be through history and get that depth of understanding thank you um lyle and for those who want to like listen or view these live streams have many many themes


SPEAKER_12:
So check if there's papers that you're interested in here.

The live streams is about papers.

So there's 46 papers.

Guest streams are not driven by a paper.

Sometimes the person's sharing a paper, but these are like presentations.

hearing from different perspectives.

And if anybody wants to help organize these, that's what we do in comms.

If they want to facilitate and participate in these discussions, if they want to contact authors, recommend papers, these are all distributed tasks that are leverage points for people who care to just do a ton of amazing things.

Like if somebody's interested to connect it to a given community and make an artifact or a live stream, co-organize that.

we can catalyze it at the lab scale for individuals who know about the affordance but then want to take that affordance to just have really leveraged impacts in the active ecosystem so ali's question and then jessica sorry i don't have any questions

asked about the timetable for the edu meetings like what specific times are they occurring at sure yeah exactly okay they are on mondays at 13 and 23 utc

There's two EDU meetings to reflect like education being the primary mission of Act Inflab, and then that spreads them out by time zones.

But if somebody really wants to contribute to an area, the organizational unit meeting is not the rate limiting step.

anyone who has attention to contribute will be able to find a regime of attention that is like connected to a task that's meaningful the rate limiting step is not people's availability for a one hour meeting it's however much time people want to contribute whatever practices and things will find something that works for people who want to be engaged so don't take these meeting times as being like when we're doing it when we're deciding even

Anybody who wants to can email or contact just the lab email address and be started on figuring that out.

Jessica?


SPEAKER_08:
Yes, this was related to the question about applied projects.

I was thinking that maybe one thing that we could do is on the project ideas section to have a table where people can, like,

you know, briefly share what they want to do or like, you know, just say like, okay, I'm interested in machine learning and apply, you know, like active inference and maybe this specific topic.

Who will be interested in discussing this or exploring what to do?

And then like adding the names of the people who will be interested in that.

And so the person who started the, you know, seeded the project, then they can be, you know,

can start maybe contacting those people and see what time they can meet and start creating their own subgroups.

So maybe that's something that we could do to facilitate that in a simple way.

Yeah, so just start saying, this is what I would like to do, apply active inference while also studying the course.

And you know, we like to connect with people here who might share the same interests on and, you know, see what kind of feedback on that person can get.


SPEAKER_12:
Thanks.

And just connecting and building trust and having like a buddy system or small groups or just people who are on the relatively long path to apply active inference on teams.

we don't have the speed dating hot swap active application protocol but connecting with people and then however it's authentic in that relationship seeing what you're interested in in three months will be in a pretty different situation but we still won't have even gone through the second half of the book

on the application of the textbook.

So there's a lot of time for us to develop ideas and to connect with each other.

So thanks for sharing that a lot, Jessica.

And I tagged you so that we can create a table with the right way or do it however is the right way, because it helps enable connections for people who want to.

connect around applying.

And also it helps us remember these are the specific reference points in the text that are like our attractor regime of attention for this textbook group.

Like the textbook group isn't all of act and flap.

If people want to apply active inference, it doesn't have to be from the ground up, but it totally could be.

there's many ways to apply that are just in different codas that people get can get involved in immediately so if somebody feels like doing things i hope they feel like they have the agency to do that okay any final thoughts on this interesting semi-pattern breaking

and also um yes one final thought for me is uh we would have had dot tools organizational unit meeting at this time which is why near the end like I asked if you wanted to do different scheduling because um in general it's probably not good practice or ways of working to like go over time

to respect everyone's time and all of these types of things.

But also in the future, we're in Gather.

So people who want to keep discussing the textbook could go there into a different room.

People who want to do tools can go into another place.

So we need to figure out how to do that through the people who want to be there, like these people and the feedback that everybody has and the ways they want to co-create it.

Tim, and then anyone else who has like last thoughts.


SPEAKER_02:
Hey, yeah, I was just going to say this is generally way more interesting than the tools meeting generally is.

So this cross-pollination shows great potential already, I would say.

Yeah, sounds good.

I just wanted to add to that conversation, though, about someone even mentioned Plato and Socrates and all that, and that whole sort of recursive involution of the sort of that sort of reification thing you were talking about and sort of the

the thought processes maybe being almost like a recapitulation of the, of the, of that, of the structure learning and that, and the correct Bayesian factor graphs and all that kind of thing you were talking about there.

Plato had like a concept of knowledge, which, which he referred to as recollection.

And, and this idea way, way back where all, all learning and knowledge is actually an act of recollecting what we already know.

And I just wanted to point out, there's kind of a, maybe just more of a,

interesting uh illusion or connection i guess between those two where there seems like a old new what's what's old is new again or what have you covered thanks tim anyone else who hasn't spoken or who would like to add anything


UNKNOWN:
Okay.