start	end	speaker	sentiment	confidence	text
1450	11018	A	0.8920162320137024	Okay, it is May 19, 2022 and it's week three of the textbook group first cohort.
11194	23262	A	0.914579451084137	We're in week three discussing appendix A and B and there are some notes in the sections of the book.
23316	24270	A	0.7668224573135376	In the chapters.
25370	29090	A	0.8664910197257996	There are also some ideas and questions that people have raised.
29250	35026	A	0.8687799572944641	So we'll go to the questions and then start with the most upvoted.
35058	43130	A	0.636127769947052	So feel free to add more upvotes if you want to discuss it, like even in this discussion.
44030	54606	A	0.5761833786964417	And then hopefully if people are available to take notes in this section, that will help add their thoughts in and also capture what the speakers are saying.
54788	65680	A	0.8305841684341431	And then we'll look at the question and then try to come to different answers and just add more information that people can add more structure to later.
67970	73010	A	0.839307963848114	Okay, the first question says appendix A is described as the mathematical background.
74150	78534	A	0.8373443484306335	So maybe question one for the authors or for you.
78572	83670	A	0.9036664366722107	What is the process of determining what is figuring ground for the formalisms of active?
86840	92388	A	0.8544638156890869	What other math concepts and formalisms are important for learning and applying active inference?
92564	101880	A	0.8360185027122498	And then three, what are some resources and approaches for learning math that help us learn what is useful for active inference?
127200	145920	A	0.8726230263710022	Anyone can raise their hand or we can just start to add some annotations here, like what should be included in the primary regime of attention with a reading of a book, either linearly, like some books are, or in a maybe moving around the sections.
146500	148800	A	0.8732766509056091	So what should be in the chapters?
149880	151344	A	0.8576412796974182	What should be in the appendix?
151392	152900	A	0.6663411855697632	What is not in the appendix?
156690	160538	A	0.7664481401443481	What did people expect would be in the chapter in the appendix?
160634	161790	A	0.5903052091598511	Not covered.
186930	189280	A	0.8351176381111145	Yeah, Jessica and then anyone else?
191650	197230	B	0.878967821598053	Yeah, I was wondering about the multiplication of the matrices that we covered yesterday.
197890	204430	B	0.8595127463340759	Which equations have the multiplication of the matrices?
205910	210420	B	0.8069615364074707	A couple of examples just so I can play around with them.
213530	216790	B	0.8160721659660339	In the actual active inference equations.
221270	223522	A	0.7816735506057739	Does anyone know?
223576	238482	A	0.900628924369812	One, this is referencing the way that the appendix A is starting with linear algebra and then introducing this operation of multiplying two matrices.
238546	248410	A	0.5082108974456787	Or to get a product if someone can find like an equation that we already seen or some other equation while I'm typing up that question, that would be helpful.
315250	325902	A	0.8506543636322021	Could anyone just describe what they thought the intention was of starting with linear algebra and using 8.1 as the first equation of the appendix?
326046	329780	A	0.8442736268043518	Or we'll return to just the more general questions.
339560	345780	C	0.6926739811897278	Yeah, I mean, learning our algebra is kind of the most discreet.
348220	348648	A	0.495963990688324	I don't.
348654	362780	C	0.7605979442596436	Want to say fundamental, but like practical and comprehensive way of kind of working with a large space of data, I guess, together and computing on it.
362850	384280	C	0.4965590238571167	So it's kind of the basis for the discrete parts and maybe easier than the nondiscrete parts.
385180	386570	C	0.6315295100212097	Good reason it started.
397850	409290	D	0.8208309412002563	I guess if the question was where is linear algebra used in the active inference math?
410910	413740	D	0.8158361315727234	When you go to appendix b.
414270	426282	D	0.8590819835662842	Then you've got the equations of active inference and these are all expressed in terms of large vector spaces of variables, so probability of distributions.
426426	434658	D	0.863002598285675	And so for example, on page 245, you've got this dot notation which is the expectation of a value.
434824	445846	D	0.8566327691078186	So that goes directly back to that first section of appendix A is what does that mean in terms of how do you take an expectation of a large vector of things?
445948	447990	D	0.7997244596481323	How do you express that compactly?
450490	451240	A	0.6283750534057617	Thanks.
451690	464426	A	0.8134228587150574	Could you unpack we looked at the dot notation a little bit yesterday and they were mentioning how well, I think it was actually one of the questions too.
464448	467740	A	0.8743926286697388	Let's just see if someone asks this, okay?
468930	482366	A	0.8741331100463867	They say the dot operator in a three, the dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed.
482558	485970	A	0.7855283617973328	So what is the relationship with expectation?
487910	493750	A	0.8313784003257751	How does expectation for anyone, how does expectation relate to linear algebra?
506160	513036	D	0.8461489081382751	Yeah, expectation is the probability of a value, the average probability of some value.
513138	524736	D	0.8616991639137268	So you're going to take all the possible values and you're going to multiply them by the probability of that value and then divide by the sum of the probability of normal is to one.
524838	526572	D	0.7619513869285583	So that will be the expectation.
526716	545592	D	0.8532190322875977	So if you have a whole array or a vector in your distribution, you can express that all in compact notation by saying with this simple way of saying we're going to take every one of these terms and we're going to multiply it by the probability of that term and the probability is some to one.
545646	549400	D	0.8576951026916504	So then that will be your average overall.
551340	553550	A	0.9815172553062439	Awesome, thanks for that answer.
559200	561724	A	0.9790598154067993	Okay, thanks for that awesome answer.
561922	567760	A	0.8965652585029602	Does anyone have any other thoughts on just this first question and then we'll continue.
567910	572400	A	0.8281549215316772	So what is figuring ground?
572900	575436	A	0.6697540879249573	We're learning active inference in the chapters.
575548	577152	A	0.8286921381950378	That's why the chapters are there.
577286	582404	A	0.8753613829612732	The appendix is there to somehow lightly supplement that.
582602	591052	A	0.873741626739502	Like they describe it as an introduction or a refresher to the basic mathematical techniques.
591216	612380	A	0.594646692276001	And linear algebra is the first section, a two that is discussing a lot of important things like derivatives and Probabilities taylor series variational calculus and Stochastic dynamics are going to come in in the coming chapters, but the linear algebra is important for the upcoming chapters.
616580	621730	A	0.8038949370384216	Okay, so this question asked in a three.
627460	639700	A	0.7860323786735535	They say the dot operator is equivalent to standard matrix multiplication where the first matrix has been transposed, which is flipped like it's the operation in Google Sheets or Excel right click paste transpose.
640200	645464	A	0.8658826351165771	They say that in the case of column matrices, this is equivalent to the dot product.
645662	654350	A	0.8822481036186218	So the dot operator here is like a generalization of the vector dot operator, the sum of the products of the corresponding entries of the two sequences of numbers.
655280	662600	A	0.8537026047706604	So the questions here were what is interpretation, implication or use of a dot product of vectors?
662760	667760	A	0.8471941351890564	And then what is an interpretation, implication or use of a more generalized dot product.
667830	670290	A	0.9350199103355408	And there looks like there's an awesome answer.
711750	719350	A	0.8247025609016418	What would be a situation where if anyone can think of one, like the Dot product would be applied.
721610	723640	A	0.7790857553482056	We're trying to do this in this situation.
724810	726940	A	0.579957902431488	This is the operation that we needed.
727870	731740	A	0.8865509629249573	We wanted to compute matrix A on something of something.
732430	734780	A	0.8696709871292114	We used B dot C.
742990	780670	C	0.8484299182891846	Continue eric's description from the probability like you have expectation probability and you wanted to kind of see the error or whatever the difference, I guess between observation and the expectation, then a Dot product would give you that answer or it's a probability density of it.
787930	790550	A	0.889121413230896	What are some ways to compute differences?
792010	803150	A	0.8769294619560242	Like if there are scalars you can subtract like five minus three or something, then it was mentioned of cosine similarity.
803490	815730	A	0.8601468801498413	Does anyone think of or imagine another way that you could compute the difference between two different kinds of features of different dimensions.
823970	831950	A	0.7859311103820801	Like another example is divergence because that's like measuring the differences between these two distributions and there's different divergences.
832030	833540	A	0.7105389833450317	The KL is one of them.
834710	841190	A	0.879472017288208	What other things are in this space that might be just tractable possible distance measures?
843850	848834	D	0.650304913520813	Well, these are the same dimensionality in all these cases.
848882	855610	D	0.5051771998405457	But another very popular one is the sum squared difference, sum squared error.
856430	861114	D	0.7640477418899536	And then you can have absolute different value difference.
861312	864190	D	0.816055178642273	So these are called different norms.
865730	867280	D	0.7439170479774475	I think that's the right word.
867730	868480	A	0.46103888750076294	Yes.
868850	878530	E	0.8828911781311035	There's also the Ginny index, the Jacard index, euclidean distances like sample to sample distances.
907910	915794	A	0.8014879822731018	So could anyone talk about L zero, l one and L two, et cetera norms?
915922	918150	A	0.8593990802764893	While I'm adding some links.
933520	939992	D	0.8539767861366272	If I have the right numbers here l two norm would be the square root of the sum of squares.
940056	948592	D	0.8531558513641357	L one norm would be the average of the absolute absolute value differences and L zero.
948646	950370	D	0.5431254506111145	I don't know what that is.
951700	953664	D	0.5110417604446411	I don't think it's a difference, is it?
953862	955760	A	0.5486562848091125	It's like a presence absence.
956680	957430	D	0.584351658821106	Okay.
960520	971640	A	0.8602985739707947	That kind of encoding is used in a lot of different algorithms and then the L two norm is the sum of squares.
972140	985630	A	0.8642295002937317	So the L two norm is what is used like in at least squares regression, classical statistics, ttest inova that's a lot driven by the L two norm.
988880	996400	A	0.8344511389732361	And all of that is like in the genre of what the A three notation is describing.
998820	1008310	A	0.8511292338371277	But depending on what the B and the C are and what the A is, et cetera, there's just the dimensions of everything and other operations that are happening before or after it.
1013190	1017506	D	0.8842276930809021	Later on they mentioned the quadratic, which is the L two norm.
1017608	1021922	D	0.7387501001358032	So that's where you have the same term as multiplied by itself.
1022056	1025510	D	0.8445580005645752	Or if you have cross terms, then you get the covariance.
1028780	1036440	A	0.8668553829193115	And that's going to be used later with the LaPlace approximation and other approximation techniques.
1039760	1043470	A	0.9107950329780579	Any other comments on a three or dot product?
1044320	1048780	A	0.6732109189033508	Or just like this kind of linear algebra topic?
1061240	1083820	A	0.760019838809967	Linear algebra the basics, the trace and the determinant, which are probably less important than the dot product but still come into play, the derivatives, how things change with respect to each other, possibly time, possibly some other surface, and then probabilities.
1088320	1092424	A	0.8305469155311584	So does anyone have any other comments or thoughts on that whole section?
1092472	1097170	A	0.7613153457641602	Like anything that they read or like had uncertainty around up to equation A 22?
1109860	1110368	A	0.7671424746513367	Great.
1110454	1115010	A	0.7506336569786072	That no one has uncertainty around any of the equations up to A 22?
1118600	1125590	A	0.659381091594696	Yeah, obviously there is a lot to learn and to understand and we're not going to.
1128200	1130964	A	0.5748900175094604	It's just I don't know people who want to think about that.
1131002	1133288	A	0.7816084623336792	Like, what are we learning in Appendix A?
1133454	1135210	A	0.6417471170425415	Why is appendix A there?
1137420	1141210	A	0.5066928863525391	Hopefully we can start to understand some of this in Math Learning Group.
1141740	1159170	A	0.8595112562179565	The people who want to be really engaged with the math questioning and process and also connecting it to computer science into the applications has been happening and then hopefully everyone can benefit from this, like finding the resources and stuff.
1159780	1167440	A	0.8200076818466187	Because the relationships between the terms, relationships amongst the terms are driven by formalisms.
1169320	1178820	A	0.8427850604057312	Like the way that preferences and expectations are framed in active inference is related to equations, not only a conceptual linkage.
1190120	1195800	A	0.8597978949546814	Maybe here we can just write Math Learning Group and copy this to the resources.
1199100	1208924	A	0.8917907476425171	Okay, so what kinds of examples do you think would be useful for learning the equations and concepts in Appendix A?
1209122	1222640	A	0.6863312125205994	If the equations felt too general and not applying to anything in particular, what example or scenario or would have made sense or you felt would have made that clearer?
1227020	1232952	A	0.6301312446594238	Like, we're running a business and first this person wants to do this and then this person wants to do that?
1233086	1240670	A	0.8645257353782654	Or what example or what would somebody have expected to have found or wanted to have found that would have made it clear?
1242480	1251932	A	0.8704939484596252	Examples or other exercises or a format?
1251996	1253948	A	0.7724595665931702	This is kind of like a math lecture.
1254124	1261140	A	0.7415931224822998	It's kind of directional versus like, what other things could happen where you would feel like you were understanding and learning this and engaging with it.
1261210	1261492	A	0.46103888750076294	Yes.
1261546	1262464	A	0.766993522644043	Thanks, Brock.
1262592	1281912	C	0.5498940944671631	I was kind of reminded of a video that Karl A presentation where he in real time demonstrates and helps you work through a pattern of red.
1281966	1287336	C	0.8454529047012329	Like it's like three dots sort of that are moving around red, green and pattern.
1287368	1321620	C	0.6246517300605774	And so understanding just a simple visual example of how active inference would work that doesn't require the formalism to just surface level kind of pattern recognized, that would be like ideal maybe of then bringing in the math for this part and that part and some scaffolding.
1322460	1334064	C	0.5098157525062561	But yeah, I'm not sure the appendix, I'm not sure it was meant to be bred in.
1334262	1346950	C	0.4752965569496155	I'm not sure there's a great way to read one order or another there because you kind of need it, but you kind of it's a lot too, right?
1348200	1350392	A	0.8269913196563721	Yeah, great point.
1350446	1360948	A	0.5726847052574158	And the organizing team for the textbook group which was open to everybody who wanted to join the and the comms weekly meetings.
1361044	1371740	A	0.633503794670105	So for future cohorts, people could totally be involved with planning it, communicating it, doing anything for future cohorts as a co organizer or other role.
1372240	1375330	A	0.7512122392654419	But we talked a lot about the reading order.
1376260	1387090	A	0.7559322118759155	Would it make sense to read them in without appendix or putting the appendix last or somewhere else?
1388920	1398070	A	0.5904123187065125	One was short and hopefully the one week of regime of attention on appendix A and B is like we're just skimming it in a week.
1399160	1406024	A	0.7383961081504822	We're not getting a PhD in math, we're not generating these equations on a blank piece of paper.
1406222	1418124	A	0.838573157787323	We're just like seeing the forms that will be used and then some of the key areas in the order that the authors thought that those background topics were important.
1418242	1436450	A	0.6898411512374878	So like for appendix A, linear algebra, which is what we talked the most about, because it's going to come into play most quickly, especially with these notions of expectation and differences which is going to come into play with everything that's going to happen.
1436920	1444772	A	0.7318857312202454	Taylor series variational calculus and Stochastic dynamics we talked less about.
1444906	1455160	A	0.5525128245353699	They happened in a later order within the appendix, but hopefully there will still be many questions on them because they're probably also areas with a lot to learn and to clarify.
1455660	1461784	A	0.6875889301300049	And also appendix A is like not the final resource of it diffusing into us.
1461902	1465740	A	0.791400671005249	Like something that was really important that came up in the math learning group.
1465890	1489004	A	0.7816075682640076	Is there's not like a glossary of variables or table of variables so that's something we can work on with notation is connecting the variables to natural language ontology terms and then also things like this what do we even look up or a symbol or what does it mean when there's a double arrow?
1489132	1500150	A	0.8317248225212097	There's a lot of things that like a lot of dots that could be connected if people ask them and then we can probably get a response like what was the double arrow in a three?
1500860	1502964	A	0.7480801343917847	Does it mean anything that they're offset?
1503092	1509304	A	0.9120030999183655	Or what are the parts of this shape that are mattering for the background of learning?
1509422	1512860	A	0.8434113264083862	Active inference, anyone can ask like any question.
1512930	1519576	A	0.6226642727851868	If it's coming to mind as an uncertainty, then writing it down just anywhere is really helpful.
1519768	1539060	A	0.6224472522735596	Because then on the first pass through learning or a primary branch of learning, we can just go, okay, here's what a one shows, and then have that in a way that reduces uncertainty more rapidly than how any of us would just give an ad hoc explanation.
1545160	1564744	D	0.5289376974105835	Moritz wrote one thing that I always find useful in thinking about matrix, linear algebra matrices is to write out pictures of the matrices in their dimensions because often the notation, you've got these I's and J's and K's and stuff going around, but you don't know how that maps out into the actual elements of the matrix.
1564792	1571788	D	0.939663827419281	So those illustrations are always helpful that could be added into this book.
1571874	1573950	D	0.7543485164642334	They're in a few places, but not that much.
1574880	1575804	D	0.5282925367355347	There you go.
1575922	1576990	D	0.7143372297286987	Things like that.
1579120	1579640	A	0.5491447448730469	Yeah.
1579730	1594004	A	0.7776365280151367	And also connecting the programming experience that people might have even in no code tools like Excel Google Sheet, you have rows and columns, ones have numbers and ones have letters, but they can be other things.
1594202	1612408	A	0.8543357253074646	And then anyone who's used something like Python or R or even just doing some statistical calculations, like if you put two lists of numbers into the t test, that would be vector versus vector something, and then you would address the fifth element of the list.
1612574	1618264	A	0.7487033009529114	And then if it was in Excel, you would need to address two numbers to say where you were in the matrix.
1618312	1626416	A	0.8028844594955444	And then the tensor is just any number of more than three dimensions, which is sometimes like it's like, oh, but how spatially are we going to see it?
1626438	1639430	A	0.8220266699790955	But then we're familiar with working with spreadsheets and data sets that are larger than two by two or larger than two dimensions, and that will come into play a lot.
1640280	1644580	A	0.8621312975883484	And the numbers can be representing probabilities or be used for probabilities.
1646840	1657412	E	0.7644943594932556	I also Daniel in the chat shared a link to a Python notebook that is a link, and it shows kind of the operations on matrices.
1657476	1663496	E	0.6736814975738525	And you can see both the mathematical yeah, there you go.
1663678	1667372	E	0.7618243098258972	So you can see the actual matrix and you can actually run code too, there.
1667426	1670350	E	0.9233896136283875	So that particular awesome.
1670800	1677680	A	0.9055322408676147	So I pasted the link in here and then we can fill out the rest of the row.
1679060	1693520	A	0.8910391330718994	But then someone could be looking for a guide on matrix or programming and matrix or something before this state.
1694210	1699760	A	0.5517682433128357	So then each person, if they find it and add it here, will have a lot to share and learn.
1705340	1725860	A	0.5617122054100037	Okay, does anybody want to like, if they were the one who asked it this question, I i think it's probably referring to long equations that that probably none of us are ready to give answers to at this point.
1727270	1730980	A	0.7845054268836975	Unless somebody wants to contextualize this question.
1738320	1741072	A	0.5026452541351318	I'm hoping a read of chapter four will elucidate when the time comes.
1741126	1743170	A	0.8974234461784363	Just exploring the formal foundations here.
1745140	1745890	A	0.584351658821106	Okay.
1751470	1752220	A	0.584351658821106	Okay.
1756370	1765630	A	0.9291349053382874	Does anyone have a favorite or recommended textbook that it contains the KL divergence and Dearsley distribution in the index.
1768230	1769762	A	0.8906916379928589	This is for the math learning group.
1769816	1770034	A	0.584351658821106	Okay.
1770072	1774340	A	0.8980361819267273	Maybe we could tag some questions too, and so then we can know which ones they can look at.
1775350	1776900	A	0.8710033297538757	Wikipedia is good.
1778230	1780094	A	0.5262753367424011	The Kale divergence is approachable.
1780142	1781750	A	0.7647536993026733	The deerish lay is tougher.
1782730	1786280	A	0.7176803350448608	The links take you to definitions that enable you to put the pieces together.
1788490	1796902	A	0.9073226451873779	Okay, any comments on KL and Dear schley from someone who is familiar?
1796966	1801500	A	0.4953070878982544	Otherwise it sounds very technical and we don't need to go into it right now.
1816590	1820700	A	0.523228108882904	What is up with dividing by sigma in a 31?
1824390	1847580	A	0.650346040725708	Also detail, but we'll just see if there's any questions that are not going to be specific details because math is very hard to understand sometimes on the fly and there's definitely a space for the interactive discussions around math that are unrecorded which are important.
1848350	1867150	A	0.548198938369751	However, this is a little bit of a different format, which is how I'm hopefully interpreting people's activity rather than their disengagements because they are here and hopefully have at least scanned these chapters.
1875910	1880820	A	0.8373980522155762	Anyone can raise their hand at any time or add questions or upload things.
1882390	1902540	A	0.8949809670448303	Mean field mode, equation nine, equation 16 probability resource, statistical question, appendix B just to see if there was any.
1904270	1906410	A	0.7695698142051697	Also seem like all details.
1906990	1909918	A	0.8027111887931824	So we have 23 minutes.
1910084	1914560	A	0.7932949066162109	What does anybody want to ask now?
1915010	1928580	A	0.5265573263168335	Or is there some question here like the most upvoted one or some other one that's far less challenging that they would like to address for the next 20 minutes?
1970350	1974410	A	0.8295193910598755	Did anyone read Appendix A or B visually?
1982990	1985182	E	0.7714467644691467	Did you just ask if anyone read it?
1985316	1985662	A	0.46103888750076294	Yes.
1985716	1988240	A	0.927741289138794	What would anyone like to share about reading it?
1989650	1997620	E	0.5719709396362305	I totally read it with a highlighter and made several notes in the margin in my physical book.
1998070	1999278	E	0.6142335534095764	It was challenging.
1999374	2014038	E	0.7255752682685852	A lot of the notation I feel like is crazy, even just independence b was it the very first thing?
2014204	2019330	E	0.8509758710861206	Are they using O for observations or are they using O for outcomes?
2019410	2022540	E	0.5135660767555237	I was totally unclear on that.
2023070	2023820	F	0.5225085616111755	Completely.
2024270	2033660	E	0.8503797054290771	So like state inference, Markov decision processes like the states that influence outcomes O, right?
2034030	2034534	E	0.649185299873352	Literally.
2034582	2036960	E	0.8405448198318481	That's what it says on the top of page 244.
2037650	2040510	E	0.8157978653907776	So it says that the variable O is an outcome.
2040850	2042442	E	0.8345329761505127	Is an outcome and observation.
2042506	2043454	E	0.8155454397201538	Are those the same thing?
2043492	2044910	E	0.7939507961273193	Are they interchangeable?
2045410	2047550	E	0.7111987471580505	I've always thought O was observations.
2048210	2051002	E	0.7314620614051819	I put that question in there in the past.
2051156	2056802	E	0.8262507319450378	It's already there and then the question right before it.
2056856	2059374	E	0.5505493879318237	This is a really tricky section.
2059422	2059874	E	0.7360090017318726	Right?
2059992	2067970	E	0.6493042707443237	So the two questions that are in Appendix B that are together, it says the likelihood of observations given a policy is not straightforward to compute.
2068050	2080646	E	0.6483161449432373	This is because POMDP problem is structured so that policies pi influence trajectories indicated by tilde of states S that influence outcomes o without a direct influence of policies on outcomes.
2080838	2089850	E	0.714139461517334	The problem then involves the sum over trajectories of states to marginalize these out and find a marginal likelihood of observations given policies.
2089930	2091918	E	0.5839281678199768	Like what does that these even refer to?
2092004	2096990	E	0.8650401830673218	If you look in the questions in Appendix B, they're there in the questions already listed.
2098050	2101470	E	0.7511274218559265	I felt like it was very obscure and not super clear.
2101540	2112514	E	0.46497029066085815	And also the notation gets crazy and I'm really a stickler for defining every single variable and symbol in an equation to understand the math so that I can actually read it in English.
2112642	2115270	E	0.6150370836257935	So I was a little bit lost.
2117690	2118998	A	0.570740818977356	Totally agree.
2119164	2121554	A	0.9225513339042664	Thanks for sharing it, Eric.
2121602	2134666	D	0.851780116558075	Just with respect to that particular question, I think that these refers to the trajectories of states and you can see that because the sum is over the tilde s.
2134848	2138000	D	0.799271285533905	So the tilde s is the trajectories of states.
2139570	2147280	D	0.8190876841545105	So you sum over all the trajectories of states to try to figure out, well, what are we going to get if we apply a given policy?
2148390	2150180	D	0.8253641724586487	That's my intuition about that.
2150710	2154526	A	0.7694873809814453	And I suspect also that observations are outcomes.
2154558	2156094	A	0.6775193810462952	They're sensory outcomes.
2156142	2163510	A	0.8502539396286011	They're the outcome of a generative model or a generative process, but they're the outcome that is observed.
2168090	2175210	A	0.5337302684783936	How many dots we need to actually unpack and connect for unsighted grammatically vague sentences.
2175550	2176106	E	0.5664746165275574	Right.
2176208	2176954	E	0.9191112518310547	So thank you.
2176992	2181930	E	0.5354283452033997	My uncertainty has been reduced substantially just by figuring that out.
2182000	2187280	E	0.5970795154571533	But I felt like that the whole time I was reading the appendix, I was like, what is even going on here?
2188690	2189440	A	0.5491447448730469	Yeah.
2192290	2194842	D	0.8220922350883484	Sir, the way I view it is like exercising.
2194986	2207074	D	0.7937262058258057	You're not going to run a marathon the first time you set out, but the more you stretch and warm up and I think that's how I kind of view this.
2207192	2212290	D	0.7839937806129456	Going through the appendix is kind of refreshing on what you used to know about math, at least for me.
2212440	2216342	D	0.8489894270896912	And so that's like stretching and doing a little bit of exercise last week.
2216476	2223442	D	0.6222718358039856	And then every time you go through it, every time you see the notation, you've slept on it some more, it becomes more and more familiar.
2223506	2226294	D	0.5130141377449036	And so you can start to put together bigger, bigger chunks.
2226422	2230742	D	0.8471937775611877	Some vaguely you can map to the notation and the math.
2230806	2237578	D	0.6856387853622437	Other ones it's still going to be dangling, but that's okay because there's fewer dangling things that you're groping with at any given moment.
2237664	2245134	D	0.8991066813468933	So I think it's great to go through these dependencies and see it all through one pass and all right, so I didn't run a marathon, but that's okay.
2245172	2245994	D	0.7738329768180847	I ran 2 miles.
2246042	2248020	D	0.9805928468704224	That's pretty good for first start.
2249430	2250670	A	0.816527783870697	Thanks, Eric.
2250830	2253570	A	0.5097653865814209	Another metaphor is just like, oh, yes, please.
2253640	2254530	A	0.6687629222869873	Jakub.
2256470	2273274	G	0.6419088840484619	Yeah, I was just going to comment on what Blue said with some confusion about the notation because I asked the question about the marginalizing of state.
2273312	2285686	G	0.5640959739685059	But then I was also confused about the O notation because in equation B one, it seems that it's a trajectory over outcomes.
2285798	2289230	G	0.7094951868057251	But then there's also an O without a tilde on it.
2289380	2292974	G	0.8452376127243042	So does that mean that it's an outcome at a particular point in time?
2293012	2298622	G	0.8647376298904419	But then there's also a bold o, which implies that it's kind of a vector.
2298686	2303038	G	0.8671309947967529	But if it's a trajectory of outcomes, that also seems to be a vector.
2303134	2311400	G	0.8786917328834534	Like a trajectory for me implies some kind of vector form because it's a sequence of outcomes given a policy.
2312010	2319154	G	0.7159443497657776	But then what does that bold O mean if not trajectories over outcomes?
2319282	2325080	G	0.5884213447570801	So just to kind of add to the confusion, I guess.
2326170	2327170	E	0.7961676716804504	Thanks, Jacob.
2327250	2331660	E	0.9543656706809998	I'm glad we're groking we're on the same page, you and I for sure.
2334690	2338750	A	0.9501896500587463	It would be awesome for description or any notes.
2339170	2343390	A	0.8221741318702698	What is the reading or a reading in language?
2344850	2352226	A	0.8209169507026672	The this of this conditioned on that is this over that of these two things.
2352328	2353282	A	0.7697184085845947	The first thing is this.
2353336	2367640	A	0.7470724582672119	The second one is that an example of that is in this situation, here's the script, here's the graphical abstract, here's the paper, here's the person you could ask, which one of these do you think is going to be interesting?
2373790	2378890	A	0.7353655695915222	Okay, so Mike asked, and I'll copy this in for those who have read the entire book.
2378960	2382970	A	0.8594149947166443	Did you find the appendices useful as you went along through the chapters?
2398940	2399880	A	0.6077884435653687	Ali.
2404300	2404712	F	0.5491447448730469	Yeah.
2404766	2424620	F	0.6111738681793213	I also think that if the materials in these two appendices were to be integrated in the linear narrative of the whole book, it would be much more useful than separating out as separate appendices.
2424700	2425330	A	0.6113757491111755	Because.
2427700	2430864	F	0.854573667049408	As we see, that's my own experience.
2431062	2451320	F	0.8005211353302002	Well, reading the chapters independently and in isolation of the narrative doesn't give me a sense of their concrete applications and I don't know how to use them and how to use all of these equations, and everything becomes much more fuzzy.
2461800	2463472	A	0.710770308971405	I hope this is not controversial.
2463536	2485004	A	0.6462442874908447	That linear reading of the appendix as something that you look through is extremely confusing or extremely imprecise because there's many symbols introduced that might have been introduced earlier, like O is probably discussed earlier, but then it's briefly just sort of mentioned.
2485122	2488124	A	0.51478511095047	And then there's a lot of symbology that's not mentioned.
2488242	2489310	A	0.5684058666229248	What it is.
2490100	2493040	A	0.5241734385490417	So it's hard to read the appendix without prior knowledge.
2494260	2500720	A	0.7259675860404968	Yet, ostensibly, Appendix A is the introduction refresher.
2505020	2508280	A	0.8853445053100586	So is this the introduction offering?
2509900	2511096	A	0.643086314201355	They hope so.
2511118	2524780	A	0.7594729661941528	They expect and prefer perhaps the appendix to go some way towards remedying it being the maths required to understand this not complicated basis.
2527550	2537280	A	0.5193864703178406	The multidisciplinary basis means it is often difficult to find resources that bring together the necessary prerequisites they're going some way.
2537810	2543102	A	0.8017195463180542	So this is like one kind of plank out there from their point of view, from the chapters.
2543246	2544210	A	0.5691881775856018	This is stuff.
2544360	2548820	A	0.8997099995613098	Ali I also kind of agree on what ordering these are really interesting questions.
2549270	2556770	A	0.8274269104003906	So then what is the next connector that picks up here with this artifact?
2558550	2573850	A	0.7012540698051453	Because someone mentioned how Moritz mentioned you could basically do a whole course on deep learning to apply most of the matrix operations and whole courses on the math of them so they can't go into all this detail.
2573920	2580220	A	0.5654940605163574	They can't spend 1 hour or like multiple coda pages on just what this means.
2581250	2592750	A	0.5635405778884888	So there has to be some kind of compromise, but then there's not going to be one specific perfect compromise, especially with like, length and audience considered.
2596390	2604242	E	0.5795732140541077	I undertook a very detailed linear reading of the book because that's just kind of how I am, of the appendixes at least.
2604376	2612710	E	0.7581108212471008	But I think for many people that I've been there before, where you're staring at math equations like this is gibberish.
2613770	2619162	E	0.6977904438972473	Just to read the text and to read it and go through it, it's helpful to know that it's there.
2619296	2631014	E	0.6263765692710876	So if nothing else, at least you can be reading the book and then be like, oh, I remember kind of reading about Taylor series expansion in the appendix.
2631142	2639466	E	0.7442259192466736	And so then you can just go back and just having access to it or the refresh recall access, even though it is confusing.
2639498	2642830	E	0.7307474613189697	I agree to try to a linear read of the appendix.
2644310	2650370	E	0.7100158929824829	I think skimming over it or deeply reading it and then being able to refer back to it is useful.
2651270	2652530	A	0.7864034175872803	Thanks, Blue.
2653670	2658934	A	0.8449138402938843	So in next week, we're going next two weeks.
2659052	2667510	A	0.8973327875137329	So the pace of one section per week might be like whatever it was for you, however much time you put in, et cetera.
2668090	2676614	A	0.7778022289276123	The coming chapters are going to be very different because one didn't have any formalisms or figures really, just the kind of overview figures.
2676742	2678906	A	0.8188140988349915	But we're going to have two weeks for two.
2679088	2681514	A	0.7525633573532104	So no need to rush it.
2681552	2685898	A	0.8081510663032532	Read a couple of pages and then just go back to the beginning and just restart the same pages.
2686074	2689162	A	0.6388583779335022	That's like the multiple coats of paint in a mural.
2689306	2691546	A	0.7527582049369812	Like the low road to active inference.
2691738	2699458	A	0.7908525466918945	That's where they're going to pick up in that high road, low road dialectic that we talked about last time.
2699624	2702402	A	0.8559520840644836	Let's just see what figures, what equations might happen.
2702456	2702770	A	0.584351658821106	Okay.
2702840	2709062	A	0.600246787071228	Lot of terms that hopefully are in the ontology already.
2709196	2721158	A	0.8354722261428833	Like you can use the at symbol hopefully to call most of them, but if something's not there, we can add it to supplemental or entailed.
2721334	2727180	A	0.9094428420066833	Okay, so what figures and figures and equations will we might see?
2727550	2732590	A	0.8842259049415588	Here's a box 2.1 about probability.
2734770	2750290	A	0.8595991730690002	Here's an equation that's the Bayesian kernel and it's going to be talking about this example of a frog and an apple and jumping or not jumping.
2750630	2754558	A	0.86355060338974	And that example is going to play a current role.
2754654	2761590	A	0.8524906635284424	But then some likelihoods are shown in a specific example of like frogs and jumping or not and apples.
2763210	2768330	A	0.8592866659164429	There's a work through example of exact Bayesian inference.
2770750	2773770	A	0.8514621257781982	Here's a table on statistical distributions.
2776350	2783138	A	0.8417304158210754	It would be really interesting, like to hear what support and surprise mean and what are these district?
2783174	2784426	A	0.8271308541297913	Are these all the distributions?
2784458	2785518	A	0.8492003083229065	Are there other ones?
2785604	2786782	A	0.6119986772537231	Or like why these ones?
2786836	2788346	A	0.5410539507865906	Or why are they useful?
2788538	2789838	A	0.7696006894111633	Where have they been used?
2789924	2791280	A	0.5536388754844666	What does it even mean?
2794550	2802894	A	0.8956741094589233	Here's where the KL divergence is introduced and then some more analysis from a surprise perspective.
2802942	2806230	A	0.6315743923187256	Bayesian surprise with the KL divergence.
2807290	2812502	A	0.8293918967247009	There's the box on expectations, which is also what we talked about a little bit today.
2812556	2816310	A	0.9567134380340576	And that was really interesting to connect it to the matrices.
2819930	2845390	A	0.8601897358894348	A figure of the generative process and the generative model is the caption a figure both perception and action minimize discrepancy between model and world free energy.
2850200	2857556	A	0.8669394850730896	Variational free energy as an upper bound on negative log evidence the figure but with equations in it.
2857738	2868010	A	0.788701057434082	Very common format figure complementary roles of perception and action in the minimization of variational free energy.
2869100	2875804	A	0.8685162663459778	Big act, imp theme and like something kind of a common fristinism like perception and.
2875842	2881870	A	0.8380972146987915	Action, being in the same game or being in the same service of the same objective function.
2886180	2892400	A	0.8644557595252991	Planning but no specific equations but probably citations.
2894820	2902870	A	0.6436274647712708	Just introducing expected free energy, which Yaakob and others can probably go into a lot more detail on.
2903960	2909430	A	0.6746535897254944	Expected free energy about a future where the outcomes haven't happened.
2911740	2917130	A	0.8406760692596436	Expected free energy figure with equations, the end of the low road.
2917500	2937090	A	0.6577281355857849	Introducing the two key terms variational free energy, expected free energy summary does anybody, like, want to, like, add or what was something cool or whether they read it already or not?
2951280	2952536	A	0.7949573993682861	What does anyone Ali?
2952568	2953390	A	0.6413175463676453	Yes, please.
2958180	2965600	F	0.8607960939407349	Well, I've noticed the dispersion of some sidebar boxes like box 2.1 or in this chapter.
2967700	2979780	F	0.5617882609367371	I don't know the distinction between the purpose of these boxes and I mean, what's the function of these boxes as compared to what we see in the appendices?
2981100	2990772	F	0.8280665278434753	Because presumably these boxes cover the concepts that could be skipped over if one is familiar with these mathematical concepts.
2990836	2998136	F	0.8540112972259521	So do you have any idea about the reason behind this decision?
2998248	3008480	F	0.8937221169471741	I mean, covering some basic concepts, basic mathematical concepts in these sidebar boxes and some others in the appendices?
3018910	3020380	A	0.8635595440864563	That's a great question.
3021230	3025350	A	0.814497172832489	A box could reflect like, okay, expectations.
3025430	3025786	A	0.5088188648223877	Got it.
3025808	3027606	A	0.7499876022338867	Or like, okay, some product rule.
3027638	3028310	A	0.4896697998046875	All right.
3028480	3031150	A	0.7561596632003784	But it's kind of like you might want to read that.
3031220	3034622	A	0.7599629759788513	Or is this introductory highlighting it?
3034756	3037470	A	0.8687038421630859	This is the 101 on probability.
3038050	3040846	A	0.7187345027923584	Or is it saying this is a total skippable unit?
3040878	3044900	A	0.8049871921539307	If you want to learn about how the lizard does it, here's where you look.
3045510	3047682	A	0.7800962924957275	It can sometimes mean both.
3047736	3056790	A	0.5748485326766968	And the format of the book is also relatively austere, though in a concise tone.
3059770	3076518	A	0.5670942664146423	It's in black and white, which especially in some later sections make some visualizations where it's like it's hard to understand what curves are doing what it's a black and white image, so what is there to see with the color?
3076704	3086430	A	0.5749232769012451	But it also might predispose towards more simple or visually accessible material.
3087330	3091678	A	0.8231735825538635	So what is going to be accessible and the order.
3091764	3093700	A	0.5475381016731262	So those are all really important questions.
3094550	3101582	A	0.812289297580719	So we can just take notes on it in the weeks that we're going to continue to do this because we only have limited live time.
3101736	3103190	A	0.8963044881820679	How about in the last like 3 minutes?
3103260	3109750	A	0.8447824716567993	What does anybody think about the opening quotations or specifically this quotation?
3111850	3116422	A	0.5443633794784546	My thinking is first and last and always for the sake of my doing.
3116556	3117750	A	0.76463383436203	William James.
3123060	3127250	D	0.6387722492218018	I thought the guy was a philosopher, so I guess you just abused me of that one.
3129490	3130240	B	0.54979008436203	I.
3137210	3149340	A	0.950842022895813	Yeah, these would be really nice areas to look into for people who like the history part.
3150350	3160240	A	0.7564669251441956	Blue and I and others are working on some different kinds of ways to reference papers and just up cool paper.
3161010	3162762	A	0.7633455395698547	Sensation perception.
3162906	3164142	A	0.7438855171203613	We have those terms.
3164276	3166830	A	0.8307011723518372	We could just link the paper somewhere.
3167490	3179442	A	0.9001660943031311	So if anyone's like, interested in that kind of architectures or that kind of philosophy question the literature right now.
3179496	3188070	A	0.6875643134117126	Is small enough to know what has and hasn't been done in a lot of areas that are philosophical and applied and technical.
3193830	3197720	A	0.7861543893814087	But just from, like, the first principles, what does this seem to mean.
3200330	3212394	C	0.9172444939613342	That shared that other group that we're kind of both a part of Daniel Liminal dow thing.
3212432	3213446	C	0.6117048263549805	That's not really a dow.
3213478	3233310	C	0.5682551860809326	I don't know what it is, but there's this debate for some reason that's going on there about different ways of knowing and being and doing and a bunch of stuff that is kind of a mix of philosophy and linguistic fallacies.
3233390	3249240	C	0.7290729880332947	But if thinking is actually a physical process, which I think anyone here is going to argue against, then it is something necessarily that is being done.
3252410	3256062	C	0.8400763869285583	However, I guess, small, you want to draw that Markov blanket.
3256146	3268700	C	0.8276798129081726	And then however large, whether that's your physical body actions or some extended thinking, it's literally what you're doing.
3272930	3278030	C	0.8148003220558167	It's not just for the sake of your actions, but they are your actions.
3279250	3282290	C	0.576848030090332	They're just another set of your actions.
3283670	3284450	D	0.4896697998046875	All right.
3284600	3286754	D	0.8529865741729736	I'll offer a different take on it.
3286952	3287314	A	0.5491447448730469	Yeah.
3287352	3287986	D	0.918424665927887	Awesome.
3288168	3307574	D	0.4696427285671234	William James was a great visionary, and he foresaw Mark's Mark Zuckerberg's metaverse 120 years ago or whatever, and he said, no, I don't want to live just inside my mind, inside the metaverse.
3307702	3311610	D	0.7988296747207642	I want to be out in the world, interact with real people and real things.
3311680	3317500	D	0.6452171802520752	So he was a meta or Facebook skeptic way before his time.
3321010	3321470	A	0.584351658821106	Okay.
3321540	3322750	A	0.8810703158378601	Thank you, Ali.
3325970	3326334	A	0.5491447448730469	Yeah.
3326372	3341166	F	0.8869304656982422	As Brock mentioned, I think it relates to an epistemological distinction between propositional knowledge and how to knowledge.
3341278	3354274	F	0.49319106340408325	And I think this statement by this statement here tries to blur this distinction, blurs the line between propositional knowledge and know how knowledge.
3354322	3386580	F	0.743873655796051	Because especially in analytical school of philosophy, there's always been a very, let's say not a heated debate, but there's a long standing debate about the distinction between these two kinds of knowledge and whether in fact they can be distinguished from each other or not.
3388790	3389442	A	0.8529649972915649	Thank you.
3389496	3397000	A	0.8122367262840271	Could you just unpack what are the two kinds of knowledge again, and what are just they referring to?
3397530	3398326	F	0.4753468930721283	Sure.
3398508	3411130	F	0.8738976120948792	Well, about propositional knowledge well, an example of propositional knowledge is to know the exact mechanisms of walking.
3411550	3419370	F	0.8416486978530884	I mean, which muscles contract and which I mean, in what angles.
3422930	3434782	F	0.8980355858802795	The whole thing about the biomechanics of walking, the whole knowledge about the biomechanics of knowledge can constitute this kind of propositional knowledge.
3434926	3439060	F	0.6560968160629272	And it's totally different from knowing how to walk.
3439670	3454498	F	0.7044786214828491	I mean, a three or four year old year old child has a know how knowledge of walking, but not necessarily where he or she doesn't know anything about the biomechanics of walking.
3454594	3459210	F	0.893568754196167	So the biomechanics of walking is the propositional knowledge.
3459710	3466010	F	0.8367704749107361	Actually, knowing how to walk constitutes the know how of walking.
3474340	3493220	A	0.8030075430870056	So when people say things like active inference is integrating perception, cognition, and action, maybe it is rethinking some of these long held mental frameworks for distinguishing or operating differently on action and perception.
3494920	3504276	A	0.9188348054885864	Like, one fascinating recent example from me and working with Eric was in the area of ant pheromone modeling.
3504308	3515404	A	0.693454921245575	Without going into too many details, people often modeled preference as a function of the absolute amount of pheromone on trails because that's what the exponential, like, decay is on.
3515442	3523964	A	0.7185649275779724	That's what can be manipulated rather than the perceived intensity, which might have a different scaling relationship.
3524082	3526544	A	0.8036890625953674	So it's like a dim room, you can detect a small change.
3526582	3529136	A	0.5600124597549438	Bright room, you can't detect a small change.
3529318	3544740	A	0.718560516834259	So that kind of psychophysics of perception gets ignored implicitly because of calls for measurability, because the cognitive can't be measured directly.
3545480	3555272	A	0.8838998079299927	Even if you potentially had an electrical measurement or something like that happening, then these are awesome questions.
3555326	3557960	A	0.799890398979187	Can you think without acting or is thinking in action?
3564880	3575040	A	0.790090799331665	This active paper, which was on a live stream, so we can provide the link to it.
3575110	3584050	A	0.8763073682785034	Models like perception and action in the sort of like kernel level, just the autonomous sensing sentient bot level.
3584660	3601400	A	0.7743368148803711	And then attention and metacognition are both related as actions to the lower level, which is like why the paper is relating computational phenomenology with mental action.
3603260	3608570	A	0.8726792931556702	Again, just to have a look at the kinds of models that can happen.
3609100	3616460	A	0.7697471976280212	And then now does making any model, fitting any data well enough and saying, well, we modeled it as action.
3616800	3618540	A	0.8641271591186523	So is thinking in action?
3619440	3626556	A	0.725986123085022	Will that model that says, yeah, it's consistent with that, will that ever constitute positive evidence for saying thinking is action?
3626748	3630064	A	0.5934970378875732	Or why even say that?
3630182	3632050	A	0.7974776029586792	Or what does it mean to say it?
3634580	3636400	A	0.6133493781089783	And then here's a funny meme.
3638360	3644916	A	0.903489887714386	Here's the generative model and the generative the partially observable Markov decision process.
3645098	3654070	A	0.8955345153808594	Here's Karl, Friston, Jessica and then anyone else.
3656600	3657350	B	0.46103888750076294	Yes.
3658440	3662330	B	0.8322431445121765	I guess it's like a beginning understanding of this.
3663740	3670168	B	0.554718017578125	I tend to think that there's like a bias towards action in active inference.
3670264	3681010	B	0.8405541181564331	I think the first chapter is saying even if you want to sense or perceive, you have to do some kind of action in order to gain the information.
3682420	3699744	B	0.7624228000640869	And this quote is basically saying like, okay, even though the whole field is trying to understand cognition, what we decide to do and the thinking that we go through in order to determine our policy is to determine our actions.
3699792	3703368	B	0.740654468536377	And then it sort of feed into the thinking itself.
3703454	3712250	B	0.6910943984985352	So maybe that's why there's like the bias to action because our actions is what it's going to be allowing the thinking.
3712940	3723452	B	0.8189492225646973	But when we update our models or trying to come up with the policies that we're going to be doing, like, we have to be processing things.
3723586	3728620	B	0.7881898283958435	So the thinking is in as a service to action.
3729920	3731404	B	0.831120491027832	That's sort of like what I was thinking.
3731442	3737744	B	0.8281092643737793	I don't know, it's a little bit like the chicken and the egg, but I kind of tend to think of it.
3737782	3748340	B	0.8187766075134277	It's like, yes, we have to act in order to understand, but the understanding which will be coming from the thinking is what determines our next action.
3749560	3751590	B	0.7860162854194641	Yeah, that's kind of what I was thinking.
3756260	3757036	A	0.7000425457954407	Matthew.
3757148	3758320	A	0.7834749221801758	Thanks, Jessica.
3760740	3776240	H	0.6001526117324829	Yeah, it kind of seems to me like we're stuck in a little bit of a linguistic Godellian loop of some sort because thinking is essentially a verb and verbs tend to imply, in a linguistic emergent term, actions.
3776400	3784724	H	0.8651621341705322	And so we have to then pop outside of that and try to consider with our internal mental processes how to disentangle these concepts.
3784852	3800264	H	0.5754116177558899	But I see no reason to think, ironically, that internal mental states aren't also conscious parameterizations of processes in the brain and our ability to grasp control of that to some extent.
3800392	3811888	H	0.5529508590698242	And so it seems very strange to me to try to separate those linguistically from our current vantage point, even though I understand why, historically, working only with language, it might have made sense.
3812054	3827510	H	0.6781819462776184	So those kind of quotes like James strike me as somewhat antiquated or just operating on dichotomies that don't seem to make sense given that we've unpacked these processes to the degree we have.
3830520	3831444	A	0.8965508937835693	Thank you, Matthew.
3831492	3833770	A	0.7285284996032715	Very deep points.
3834860	3838360	A	0.8423570990562439	Like you mentioned, thinking as a verb implies action.
3839100	3847884	A	0.8513004183769226	And then just to kind of complete that thought is like the word for the noun form of this one.
3848082	3849900	A	0.7714705467224121	So then what does that imply?
3856900	3861376	A	0.8986420631408691	And then also, like Jessica mentioned, to.
3861398	3867404	H	0.8096176385879517	Some extent that we can only express processes through their discretization via symbols.
3867452	3868050	A	0.5664746165275574	Right.
3869300	3879108	H	0.6833449006080627	The idea that there's this process, there's a flow, there's something that can't necessarily be separated, obviously, from the rest of the flows around it.
3879194	3892890	H	0.6060669422149658	But to reference it, to point to it, to describe it, communicate it to another agent, we have to nounize it kind of like which is the opposite of verbalizing, so to speak.
3895440	3895948	A	0.7093686461448669	Wow.
3896034	3897340	A	0.8965508937835693	Thank you, Matthew.
3899760	3900172	A	0.4667980670928955	Again.
3900226	3900972	A	0.8183016180992126	These are yes.
3901026	3901740	A	0.6499149203300476	Eric.
3910030	3911162	D	0.7313318848609924	Sorry, I didn't have anything.
3911216	3913646	A	0.6987004280090332	I didn't have the hand was yeah.
3913748	3921920	A	0.6907050013542175	So Karl Friston had an influential 2019 paper.
3922610	3923680	A	0.7172448039054871	Long paper.
3924050	3927550	A	0.8313453793525696	The free energy principle for a particular physics.
3927710	3929566	A	0.8041807413101196	That was in 2019.
3929678	3932242	A	0.7683706283569336	So it's been several years since then.
3932376	3938770	A	0.6623786091804504	And like, particular allegedly accidentally or intentionally is a pun.
3938930	3945090	A	0.870623767375946	So it can mean specific, like a physics for the specific systems that we're modeling.
3945250	3948630	A	0.8855477571487427	Or it could be specific, like this is a specific approach.
3949870	3971994	A	0.8821531534194946	Another interpretation is like it's for particulate entities when we define thing and the partition, which is going to coinstantiate, like the generative model and the generative process and then the Markov blanket or the interface that's separating them, that is separating the figure from ground.
3972042	3974950	A	0.8165960907936096	It's separating, like, the entity from the niche.
3975130	3977540	A	0.7432618141174316	It's separating what from what?
3978790	3980334	A	0.8360393047332764	What can it represent?
3980382	3987570	A	0.7882721424102783	The separation of something from all possible separations, some separations.
3988890	3998280	A	0.8066913485527039	And then, Matthew, you mentioned, like yeah, verbalizing speech, but it feels like we're speaking nouns sometimes.
3999290	4003846	A	0.8520917296409607	Yet verbalization is a process, especially dialogue.
4003878	4004122	A	0.46103888750076294	Yes.
4004176	4004970	A	0.7000425457954407	Matthew.
4007630	4014460	H	0.8168159127235413	Could I ask a question that brings in a little bit of content from the other chapters of the book is that yeah, sure.
4014910	4023754	H	0.8653807640075684	I'm just kind of curious because when you're talking about those, you're talking about the Markov blankets and integrating it into this idea of how we draw boundaries.
4023882	4025298	H	0.7387775778770447	I'm kind of curious.
4025464	4044374	H	0.8155174255371094	Is it fair to say that to the extent we've drawn our boundaries and do see a reduction of free energy in this system, it reinforces the idea that there's something to that boundary structure as an entity in the world, that there's a reality to that?
4044412	4045990	H	0.749934196472168	Is that a fair interpretation?
4050440	4053560	A	0.7931684255599976	I think many people would have a lot to say and add.
4053630	4074430	A	0.7888566255569458	This touches on the question of reification of scientific models and the ability for identified statistical model to be like transcending itself and used in a realist way, like ontologically real about true joints of the world.
4074800	4084720	A	0.6556385159492493	And I'm going to go to live stream table and find several of those who explained their research on this topic.
4085860	4104808	H	0.7363879680633545	But even short of trying to claim it's real, does that ability like once we've drawn a boundary using these Markov blankets and we do see that it seems to be, let's say, using information to self evidence, do we?
4104814	4105784	H	0.7178604602813721	Think that that's I mean, it seems.
4105822	4106410	A	0.6127299070358276	Like.
4108700	4120380	H	0.8200805187225342	This paradigm of thought is predicated on the idea that to the extent that that occurs and reduces free energy, it should attract, or further attract attention, at the very least, for examination or investigation.
4122720	4123180	A	0.46103888750076294	Yes.
4123250	4125416	A	0.8657680153846741	So, great questions, Jacob.
4125448	4129010	A	0.9230889678001404	Do you have something to add on that or is it a slightly different area?
4130420	4134640	G	0.8881269693374634	I guess it's kind of related to the Markov blanket discussion.
4137540	4150756	G	0.6355969905853271	This may be completely wrong, but it seems to me like with that, this kind of discretization of the Markov blankets forces us to a specific kind of discrete thinking.
4150938	4157092	G	0.7996233105659485	But I feel like that just this model of a Markov blanket.
4157236	4174190	G	0.7147189974784851	I think of it as a kind of classical model, but I presume that the reality is more something like a schrodinger Markov blanket where we can't really draw boundaries between thinking and observing a generative process.
4174880	4193060	G	0.7477511763572693	In the same way that we can think of, say, electrons as balls bouncing off each other, but we can think of them as classical particles and that will help us to an extent, but then we can also observe the process of thinking.
4193130	4198550	G	0.7697508931159973	So thinking is also kind of entangled with the generative process.
4200520	4216088	G	0.6357335448265076	So even though the Markov blanket is a useful formalism, I think that there are definitely certain scenarios that in which it's more like a probabilistic.
4216264	4243590	G	0.8514366745948792	Well, it's already probabilistic, but in the sense that the entity that's performing inference also in its own inference loop performs inference on itself and therefore thinking is at the same time an action, but at the same time it's part of the generative process.
4250850	4260382	A	0.9139803051948547	Another angle on this thanks Jacob, is what Dean T often talks about with active inference as a framework or a filter.
4260526	4267890	A	0.5754494667053223	These are just sort of like different distinctions that might be transiently useful in some axis, like fitting something to a framework.
4268230	4270310	A	0.814926028251648	It's kind of the procrusty's bed.
4270460	4286070	A	0.8538143038749695	Stretch it out so that this perception and then active as a filter, was reminding me of what Matthew was saying, like going out and discovering divergences from expectation of there not being metabolic activity on a planet.
4286230	4290870	A	0.6439709067344666	And then there is some statistical deviation.
4291030	4300670	A	0.8595629334449768	And so, like, in the classical statistical framework, that might be like it's a one sigma difference in the Bayesian framework, well, there's a base factor of two.
4300740	4316130	A	0.8660935759544373	And here for this evidence, and there's other ways to talk about detection of novel entities that might be part of, like, a reification process of the extended cognition of the modelers.
4319420	4321880	A	0.8500381112098694	Then, like, one philosophical angle on that.
4321950	4351620	A	0.8256734609603882	And then also anyone who wants to read, then Ali is this book by Helen Longineau which talks about methodological pluralism and about how there can be, like, disciplinary rigor and the ways in which often unstated, like social priors can be the substance of what becomes understood to be science as, like, a complex phenomena.
4352360	4353940	A	0.8149458765983582	Ali and then Brock.
4355880	4378140	F	0.8798734545707703	Adding to what Yakov said, I think the concept of Markov blanket emanates from the Plutonian way of thinking, specifically hylomorphism school of thought as opposed to hylozoism.
4379040	4388332	F	0.6519516706466675	The distinction between hylomorphism and hylozoism is that, well, in hylomorphism, everything is disconnected.
4388396	4394044	F	0.5058159828186035	Every concept is disconnected and with every other concept.
4394092	4400528	F	0.6787118315696716	And so there's a discontinuity, metaphysical discontinuity between the concepts.
4400704	4424828	F	0.7223880290985107	But in hylozoism, the philosophers advocating this school of thought, well, they claim that hylomorphism fails at answering the question of what it is adequately, and they even rephrase the question.
4424914	4433584	F	0.6639062166213989	And they claim that the right question to ask is not what it is, it's what it can do.
4433702	4438988	F	0.8148446679115295	So that's basically the distinction between hylomorphism and hylozoism.
4439164	4450310	F	0.8256503343582153	But I think the mark of blanket is a way of formalizing this hylomorphic way of thinking.
4451160	4452980	F	0.7471066117286682	At least that's my opinion.
4455760	4457304	A	0.9730676412582397	Thanks a lot for that, Ollie.
4457352	4458060	A	0.7154882550239563	Eric?
4468500	4470108	A	0.7542548775672913	Sorry, I'm not hearing Eric.
4470204	4471840	A	0.8784692883491516	Can others hear Eric?
4474910	4476570	A	0.5649140477180481	Maybe I need to reload.
4478050	4479358	A	0.8097810745239258	Can you hear me?
4479524	4480830	A	0.7330771684646606	Okay, I'm going to reload.
4500250	4501250	E	0.8097810745239258	Can you hear me?
4501340	4502614	A	0.719106137752533	Yeah, I can hear blue.
4502662	4503162	A	0.584351658821106	Okay.
4503296	4504954	E	0.6184083819389343	You're still not hearing Eric, though?
4505072	4506060	A	0.5217278003692627	No, sorry.
4506750	4509370	A	0.8158944845199585	Yeah, I just did, like, a small disrupt.
4517700	4521152	A	0.7106539011001587	Okay, wait, eric, try again.
4521286	4521584	A	0.584351658821106	Okay.
4521622	4522192	D	0.8266733288764954	How about now?
4522246	4524164	A	0.5789976119995117	Yeah, now I can see you in here again.
4524202	4524740	A	0.584351658821106	Okay.
4524890	4528660	D	0.7963943481445312	How about everyone else who's the audience?
4529240	4529700	A	0.584351658821106	Okay.
4529770	4530484	A	0.7093686461448669	Wow.
4530682	4533430	A	0.6975860595703125	Disrupt on the high low field.
4533740	4535050	D	0.6871730089187622	It's happened before.
4537420	4541816	D	0.6906832456588745	I just throw in my two cent about my interpretation of a markup blanket.
4541848	4550248	D	0.645156979560852	It's about trying to perform simplifications that make computation tractable.
4550424	4555312	D	0.584725022315979	If you have everything interacting with everything else, then we can't do computing on that.
4555446	4571504	D	0.5715630650520325	So we apply compartmentalization and build objects and interfaces for how the objects interact with one another, and those become tractable.
4571552	4581850	D	0.86748868227005	That's what a Bay's net does, is it says what are independent and what are dependent variables on each other.
4582220	4593112	D	0.7206287980079651	And that works well when those abstractions, the objects and relations, nouns and verbs are a good fit to how the world actually operates.
4593256	4610348	D	0.7675979733467102	So that is a driver for learning or building representations that will use these Markov blankets and put the compartments where they actually are faithful to the compartmentalization that we can abstract over the way the world parts in the world operate.
4610444	4625568	D	0.762487530708313	So things that are distant, that separate, that interact only weekly, we try to maybe factor those out, pretend they don't interact at all, or use some other intermediate variables to represent the interaction in order to simplify things so we can do computation.
4625664	4631130	D	0.9172186851501465	So that's how I think Marco blankets and we'll see if the math tells us that later on when we get to it.
4632060	4632856	A	0.918424665927887	Awesome.
4633038	4635560	A	0.8107353448867798	Brock ethanoli.
4647630	4647994	A	0.584351658821106	Okay.
4648032	4650150	A	0.8382160663604736	I'm like not hearing Brock, unfortunately.
4650310	4651180	A	0.6829060912132263	Do you?
4651890	4653274	E	0.751392126083374	Yes, we all hear Brock.
4653322	4654766	E	0.9210900068283081	Brock is reloading, I think now.
4654788	4655166	E	0.4667980670928955	Again.
4655268	4655870	A	0.584351658821106	Okay.
4656020	4656478	A	0.5491447448730469	Yeah.
4656564	4663360	A	0.6767932772636414	Gather does this sometimes, but I don't know if it's because we have 15 people.
4664210	4666946	A	0.5353236198425293	Yeah, but like Matthew said, I don't hear him.
4666968	4669250	A	0.6144368052482605	It's just like there's different drop offs.
4671990	4674354	E	0.6488280296325684	I can hear you, but I still think Daniel can't hear you.
4674392	4675538	E	0.7304677367210388	Daniel, you can't wait.
4675624	4676520	A	0.6634221076965332	Now you're back.
4676970	4677558	A	0.4859413802623749	Go for it.
4677564	4678438	A	0.737429141998291	Okay, continue.
4678604	4679414	C	0.7792782783508301	Interesting.
4679612	4680598	C	0.8097810745239258	Can you hear me?
4680684	4681222	A	0.5491447448730469	Yeah.
4681356	4682520	C	0.5817292928695679	Oh, okay.
4683770	4684518	A	0.5491447448730469	Yeah.
4684684	4689722	C	0.5657380223274231	This is just this ongoing thing that I don't know, we just keeps coming up about.
4689856	4692998	C	0.5916227102279663	Yeah, well, okay, maybe they exist, maybe they don't.
4693094	4694490	C	0.7047955989837646	Markov blankets, really?
4694560	4703178	C	0.6985606551170349	But how would they form in any how would they form an evolving collapse?
4703354	4726690	C	0.5852049589157104	Presumably there is some point in that process, this evolution part where the Markov blanket is extremely poorly defined relative to the system and that's basically these sort of underexplored areas.
4726770	4756800	C	0.5086836218833923	It was also in relation to Matthew's question also about the free energy minimization thing where there's systems like non equilibrium systems basically, where still something interesting worthy of study is happening, but perhaps is not free energy minimizing in that state.
4758770	4760206	A	0.9237832427024841	Thanks for sharing it.
4760228	4761630	A	0.8057330846786499	Just a few thoughts.
4765170	4783746	A	0.7252084612846375	Let's just say some sort of meso scale or global as that's called, but that doesn't mean about the whole world, but some sort of global free energy minimization in the joint model is achieved like in a conversation that isn't the same thing as the local disconnected free energy minimization.
4783938	4793702	A	0.6122281551361084	Otherwise fitting high parameter models optimally would be simply reducing to fitting single dimensional models alone.
4793766	4801450	A	0.7302298545837402	If we could just do the linear optimization on the standalone variables, then why would we ever need the larger dimensional methods?
4801970	4810880	A	0.826169490814209	And then think of this textbook maybe with where things could be in the coming years.
4812770	4816762	A	0.8461319208145142	The Markov membrane is like the linear algebra.
4816906	4819920	A	0.8798633813858032	And then Jacob mentioned that this is classical model.
4820390	4826260	A	0.7732690572738647	It is kind of classical in a sense, in the timeless classic sense.
4826970	4837538	A	0.8312039375305176	So the one layer Markov blanket when thinking about the rise and fall of civilization is not the end all that's.
4837554	4854110	A	0.809261679649353	Like I think maybe analogous to a linear regression y equals MX plus B and then you have all these hundred years of development on the linear regression model and all these techniques and applications and pipelines.
4854850	4868770	A	0.7244836091995239	So the Markov blanket one layer potentially over interpreting it as already presenting with strengths or weaknesses in certain situations when not being just like empirically demonstrated.
4869190	4875300	A	0.8755763173103333	In the general case, we'll see what could be said and when.
4875910	4876850	A	0.7000425457954407	Matthew.
4879130	4881794	H	0.7537181973457336	Yeah, along those lines, I was kind of curious.
4881842	4888654	H	0.6341755390167236	I've seen that there's been a decent amount of work on the sort of hierarchical or fractal composition of these models.
4888802	4902906	H	0.8543243408203125	I'm curious if that implies that there's a fractality to the boundary by default or if there needs there any specific work on sort of hierarchical composition of the boundaries of that so called membrane.
4902938	4903840	H	0.6002307534217834	As you said.
4907570	4932722	A	0.4984826147556305	With better annotation, we could have better answers because there's many papers that we've discussed in a guest stream or a paper and there's also like many other papers obviously, that we don't have that kind of annotations of because it's quite common to see nested models in the context of nesting of cognitive processes.
4932786	4936406	A	0.9088654518127441	Like in that San Fed Smith paper, which was I think, number 25.
4936588	4939682	A	0.8324800133705139	That was about cognition as mental action.
4939826	4946218	A	0.7111191153526306	So that was nested and the nesting was interpreted as cognitive actions and counterfactuals, basically.
4946384	4954990	A	0.8281900882720947	And then sometimes nesting is used to refer to actual, like, well, the state is inside of the country and then the region is inside of the state.
4955140	4963790	A	0.8919786810874939	It's implied that the map is mapping onto the territory, maybe even spatially, the cell is inside of the tissue.
4964210	4967060	A	0.7235174775123596	And that's like answering Schrodinger's question.
4967670	4973140	A	0.8727407455444336	Everything happening with the planetary scale analyses, cellular level.
4976870	4984418	A	0.5059942603111267	And then this is hopefully what is spoken to with the composability of active inference.
4984594	5005962	A	0.8483175039291382	And sometimes that's framed in terms of the lateral composability of you could have three ants interacting or 300 ants and then the nested composability, you could have the fifth and the 7th and all those layers with computational trade offs, maybe with no extra information to be gleaned.
5006106	5016574	A	0.8849949836730957	And then learning the structure of the generative model or just the structure of the partition more broadly and like what the variables are and everything that's the structure.
5016622	5022900	A	0.784766674041748	Learning challenge and cognition as structured learning.
5023830	5039750	A	0.8854628801345825	Hashtag synergetics geometry of thought is what Friston has and others have raised as like a total open area because there's the parameter fine tuning once you have the Bayes graph.
5040510	5047260	A	0.8695830702781677	So then you're now inside of the ability to reify or not that model.
5047710	5049930	A	0.6378287076950073	You're just doing parameter optimization.
5050670	5055440	A	0.8268545269966125	We used two factors in this linear regression and then we optimized it with the L two norm.
5055970	5061850	A	0.5924443602561951	Two is the best number of factors, but it couldn't be set at that scale.
5061930	5070580	A	0.5527295470237732	You could say in a two parameter model, this is the best parameters with this norm, but then you couldn't pull back another level.
5071270	5081960	A	0.8906943202018738	And so that's like meta scientific and metabasian analyses, which they're going to talk about later.
5083450	5090434	H	0.7450789213180542	Okay, I guess I'm also kind of wondering if there are any examples that come to mind of something like a system that is structured.
5090482	5110670	H	0.831066906452179	Such as the clearest or simplest example that comes to mind is like, let's say that you have a nation and a state within that nation and there is a port and there is an overlap of sort of that port interface to an outside structure that is shared by both the national and overlapping national and state interests and decision processes.
5111330	5121780	H	0.8437073826789856	And so I'm kind of curious if there are examples of demonstrating that kind of composability of generative models or if that's something that's still just new and open.
5123830	5125218	A	0.9482669234275818	Those are awesome questions.
5125304	5139106	A	0.8043044805526733	If people know any some areas to investigate, like in the phenomena that you're overlapping interests informally, there would be like shared regimes of attention.
5139298	5148490	A	0.719778835773468	There's the question of synchrony and that doesn't mean like synchronization identically but generalized synchrony.
5149630	5152810	A	0.8550578355789185	Then there's like coordination of affordances.
5154690	5157694	A	0.77782142162323	We're not going to do this because of that.
5157812	5171760	A	0.9009237289428711	So that's like in an area that Yaako and others have been working on is just describing that situation as an affordance on an affordance or like E sub E.
5172450	5173694	A	0.5311813950538635	It's not in the textbook.
5173742	5178498	A	0.681284487247467	But if people are staying this long then this is just kind of some ways that some people are thinking about it.
5178584	5182774	A	0.5568318963050842	And these are the areas where people can also do research and learning with us.
5182892	5189350	A	0.8290124535560608	But affordances on affordances, the safety could be on or off.
5189420	5206318	A	0.8130146861076355	So then there's like an affordance that modifies another affordance and could those have compositionality just like some of these other generalization affordances for generalization basically, what are those?
5206484	5209360	A	0.8348549008369446	And then isn't it like discovering what those are?
5217150	5240382	C	0.845909059047699	Just I think it's kind of also related to that question of this formation evolution, collapse of markup blankets is when does the observation and actions of one system map to the preferences of another and vice versa?
5240446	5245794	C	0.7366418838500977	How does that come into being existence?
5245842	5249762	C	0.684795081615448	How does that start to happen and how does it unhappy?
5249906	5250920	A	0.566673219203949	I don't know.
5252410	5253446	A	0.9212267398834229	Awesome question.
5253548	5254102	A	0.8529649972915649	Thank you.
5254156	5264586	A	0.8841167688369751	And another angle on that, let me just check and then Ali is like this is a graph that we're going to look at a ton and we will interpret what all of it means.
5264768	5269050	A	0.8330346941947937	What is the OASB, pi, g, et cetera.
5269470	5273518	A	0.8290728330612183	But this is a basing graph like Eric mentioned.
5273604	5280590	A	0.8016572594642639	And the edges are like dependencies, not causal influences in the world, but apparent potentially or different interpretations.
5281190	5283170	A	0.8431368470191956	Is this the only skeleton?
5284710	5288850	A	0.7764755487442017	No, this is the Y equals MX plus b of skeletons.
5289670	5295386	A	0.7231811881065369	And there's the linear regression in the first equation in the textbook of the stats textbook.
5295518	5298290	A	0.5607361793518066	And then there's all these accessory tests.
5298450	5302230	A	0.6240829229354858	Then there's like creation and destruction as applied.
5302970	5309526	A	0.8051170706748962	Maybe there can just be a loop that's not active inference, just checking every day if something's within an arbitrary threshold.
5309718	5316422	A	0.835538387298584	So there could be some liminal or gray area like an interface.
5316566	5327546	A	0.8673633933067322	I think steven Solette mentioned it as like a nail bed or something, like an interface between more particulate and then less particulate, more field versus the particle.
5327738	5328590	A	0.6077884435653687	Ali.
5331830	5355010	F	0.5461146235466003	Well, as a little side note, there's a popular science book coming out, I think in June, namely The Romance of Reality by Bobby Azerian, which touches on the emergence of Markup blankets, the dynamics of emergence of Markup blankets.
5355090	5368070	F	0.7240580916404724	And it attacks it from many different angles, evolutionary angle, I mean, from a cosmic, even perspective.
5368230	5389618	F	0.8278859853744507	And it even goes as far as well, considering the whole cosmos, the whole universe, as, let's say, a kind of Metamark of blanket, so to speak.
5389704	5399846	F	0.9062607884407043	And well, I think that could be an interesting thought put forward by Bob Yadarian in this book.
5399868	5400118	A	0.4896697998046875	All right.
5400124	5401110	H	0.7800779342651367	Thanks, Daniel.
5402970	5403720	A	0.6283750534057617	Thanks.
5404170	5415210	A	0.8444120287895203	In fact, he gave part one of what was intended and may still be like a multiple part discussion, but this was him giving that presentation.
5416830	5421454	A	0.9466348886489868	So we were in contact is definitely an interesting view.
5421652	5427790	A	0.7678646445274353	And it's going to take all kinds of research and education and communication.
5428210	5429390	A	0.6628338694572449	Jessica.
5432930	5433582	B	0.46103888750076294	Yes.
5433716	5438594	B	0.8547446727752686	I guess first, join the lab.
5438712	5467462	B	0.57283616065979	Some of the ideas that helped me a little bit to start even conceptualizing this, in addition to the filter that you mentioned before, Daniel, and how it could be more like porous or more hard and allow things in and out, but it was also about it could be like just grouping of relationships and interactions.
5467526	5490340	B	0.8585859537124634	So, like, the closer like a relationship, like different things are, maybe that's more like on biological systems, I don't know if they're closely related or they have more interactions, even though they might be different, but grouping it in those sense and maybe that relates to what Eric said from the calculational part.
5491030	5497300	B	0.9022655487060547	But that was sort of like some of the things where I started connecting Marco blankets to.
5498330	5518374	B	0.9035341739654541	Okay, if items or different objects and things like they're closely related, you can start putting a blanket around and maybe go through with the idea of wrapping things from some of the definitions.
5518422	5536980	B	0.6197426915168762	But, yeah, those are kind of like the kind of visual ideas that started helping me a little bit and I still don't understand properly, but those are the things I was like, okay, so relationships, filters, kind of like connecting interactions between things.
5539990	5540498	A	0.918424665927887	Awesome.
5540584	5542050	A	0.9644525647163391	Thanks a lot for that.
5542120	5544130	A	0.7966902256011963	Like interacting entities.
5544650	5552454	A	0.8857290744781494	So you could have the edges representing some interaction, like when people are fitting a linear model.
5552572	5554290	A	0.7023724317550659	Interacting variables.
5554450	5564234	A	0.8331435322761536	So there's this whole discussion topic of whether the interactions are like the two ants bumping into each other, whatever that means in the, quote, real world.
5564352	5566970	A	0.7683340311050415	And then there's like the statistical interaction.
5567390	5572234	A	0.8450464606285095	So then defining certain variables in statistical models.
5572282	5585700	A	0.8466015458106995	So leaving that debate behind us and just talking about the statistical models that we have, Bayesian graphs, some variables have edges between them that could be either designed to be there or not.
5586070	5588206	A	0.8925144672393799	Or you could do some sort of like thresholding.
5588238	5592654	A	0.8023151159286499	Approach and explore that your thresholding parameter was acceptable.
5592782	5599990	A	0.5343417525291443	But the more of a loose interaction you allow, the more challenge there is to fit that statistical model.
5600140	5623290	A	0.5610745549201965	And you may not have enough data to fit like the ten variable by ten variable with all the interaction terms which is like why when doing linear modeling in a health population example they would like do model selection on what their statistical power is with that data set to resolve certain kinds of effects and correlations and non sphericities.
5623450	5632640	A	0.8523800373077393	And that is addressed a lot in the SPM textbook and Kristen's earlier pre active work.
5633010	5650210	A	0.8959737420082092	But then you mentioned how to be engaged with that process of the wrapping or the seeing the clusters and then knowing where is there going to be maybe generative models arising that are consisting of other generative models or other generative processes?
5650370	5659820	A	0.8830750584602356	And then some things interact more with others statistically in a model as by design or just as an outcome of whatever.
5660430	5663462	A	0.6909447312355042	So there's sparse connectivity amongst the variables.
5663526	5665878	A	0.49297839403152466	They're not like all by all connected.
5666054	5679150	A	0.7581261396408081	And then that sparse connectivity simplifies a lot of things that's also related to like a Lasso regression and also to the below l two norms and then a sparse model can be factorized.
5679730	5699394	A	0.8199357986450195	And that is what allows for the variational Bayesian inference, which is like doing Bayesian model fitting on a factorized because it's sparsely connected graph and so a lot of these discussions are quite downstream of a lot of the philosophy of map and territory.
5699522	5701910	A	0.6924073100090027	But it's still a super important conversation.
5702330	5728080	A	0.8086127638816833	However, within the model inference, with a model inference using a model, a lot of these questions are very technical and downstream of importance qualitative things that are also important to keep in mind but of a different type, jessica or anyone else.
5731270	5731730	A	0.5491447448730469	Yeah.
5731800	5733060	A	0.9658089280128479	Wow, very interesting.
5738550	5740994	A	0.8745536804199219	Here's one other question I guess we can discuss.
5741112	5753510	A	0.9042450189590454	Like as the as it currently stands, there's a 1 hour meeting and then at the end of the hour, the very next hour begins the Tools regular organizational unit meeting.
5756650	5762394	A	0.6134569644927979	It is the people who are here now but hopefully others would be listening to it if they're not able to make this time.
5762432	5771920	A	0.7977357506752014	But what will help people with the synchronous and Asynchronous make the most of the next few months?
5773250	5778160	A	0.7963181138038635	Do people appreciate having a longer discussion for this?
5778930	5783220	A	0.7944498062133789	Do people think that the main versus the math group?
5784070	5791700	A	0.8268538117408752	Is there another subgroup, like a philosophy discussion, that people want to kind of really do this?
5792950	5814570	A	0.594901442527771	Because we're experimenting with open endedness on our first cohort and in these early phases of the book and people can probably imagine various of the things we want to balance, like respecting everyone's time and different backgrounds, respecting their preferences for how much they want to learn about different topics.
5815230	5823760	A	0.5508624315261841	Being realistic about how much asynchronous and synchronous, direct and peripheral time makes sense.
5824370	5829360	A	0.7230172157287598	But also being realistic like there isn't a two minute video for a process.
5830770	5839140	A	0.8573229908943176	So how do people think about that, those who have stayed this far?
5862720	5864590	A	0.8453531861305237	Mike and then anyone else?
5868000	5868956	A	0.8097810745239258	Can you hear me?
5869058	5869804	A	0.46103888750076294	Yes.
5870002	5870750	I	0.584351658821106	Okay.
5872240	5872652	A	0.5491447448730469	Yeah.
5872706	5884732	I	0.5062692165374756	I think that as noted earlier in the discussion, there are just so many themes that run through this that there are opportunities to pull on any of a number of threads in the course of discussion.
5884796	5898020	I	0.9836791157722473	And so today's discussion was interesting and I stayed for this part of the discussion simply because of the interesting threads that were being pulled.
5898780	5910440	I	0.5680002570152283	Certainly a contrast with the first part of the discussion around math and I think a lot of uncertainty amongst the attendees about how to engage with the mathematical aspects.
5911840	5929040	I	0.6569002270698547	Maybe to try and put a point on it, from my perspective, learning about what is active inference and how can active inference be applied in real world situations is a motivator for me participating.
5930660	5937350	I	0.7798824906349182	Obviously there are also sort of philosophical and maybe more scientific discussions that can take place.
5941880	5950170	I	0.8248001933097839	Any meeting could touch on any of those aspects as well as some of the asynchronous interaction could pick those up as well.
5951980	5953130	A	0.915550708770752	Thanks a lot.
5954780	5955192	F	0.584351658821106	Okay.
5955246	5958280	A	0.6767846941947937	Anyone can raise their hand here's just a few other options.
5958350	5975148	A	0.698949933052063	Like if somebody here's something that's interesting to them, we can in the discord make a channel that is relate or people can participate in the regular channels just like questions that's going to potentially be seen and interacted with by people more broadly.
5975244	5985088	A	0.8683061003684998	Like what if we posted questions that we're having we're in the cohort one of the text and we had this question do you know that's one option?
5985174	5998100	A	0.8747453093528748	Another, and this is like to Mike's expression that applied active inference is a motivator epistemic and pragmatic value, expected epistemic value.
5998170	6007236	A	0.564009964466095	We expect to learn a lot by like staying in these sometimes challenging or oblique or whatever discussions.
6007428	6014460	A	0.7642989158630371	But then there's also expected pragmatic value with applying active inference, learning and applying active inference.
6014880	6023872	A	0.8942134380340576	So then maybe that is a group we can partition, like an applied active inference group.
6024006	6042580	A	0.7316897511482239	So then we can be clear about what the focal artifact is because also we want to not all groups at all times will be able to have nor is it useful to have open ended discussions of any discursion length.
6043560	6049050	A	0.7952947616577148	So like knowing how far and in what ways and how many minutes of people's linear time.
6050220	6058468	A	0.8418888449668884	Ali yes, the meetings, just one note on the organizational unit meetings.
6058564	6077600	A	0.6687740683555603	The organization units in the active lab like comms and tools for education, communication and tools are like directory 1 hour lab meetings or group meetings because we're not doing the education work necessarily in that 1 hour.
6077670	6092596	A	0.5890645384788513	But some groups sometimes it's possible to do some stuff, but it's like increasingly moving towards sharing updates from people who want to commit in Asynchronous work or smaller groups that want to commit to doing something like that.
6092778	6100810	A	0.7302660942077637	So then educational related projects, that's their opportunity to ask for help, share updates and so on.
6101900	6121992	A	0.7140002846717834	But earlier on there was more topical material, but then through particularization and operations and other approaches, it becomes more like Pragmatic and less discovery and less mixed media role specification, all these processes.
6122136	6136960	A	0.5540965795516968	So people sticking around is sort of the and being engaged and like seeing an affordance and then just making that contribution, wanting to be a facilitator for a certain project or wanting to contribute actively or just even connect with another participant.
6137720	6146276	A	0.8653483390808105	You can email them if they've provided their information, just some random things.
6146378	6156120	A	0.871929943561554	But we want to have the applied angle, the philosophical loop and how to even partition that discussion.
6157820	6168620	A	0.5221241116523743	Like we couldn't just overgo every math, every philosophy, every applied question and have the judge and the jury and all this apparatus.
6170560	6178204	A	0.801135241985321	So how can we scaffold that conversation around applied active inference for the people who are like super excited and motivated?
6178332	6179120	A	0.6604843139648438	Mike?
6181140	6181504	A	0.5491447448730469	Yeah.
6181542	6204330	I	0.8351997137069702	I just want to add there's an interesting duality related to what you just said in that we can't go into fine detail in all of the content and at the same time, I've found this group to be remarkable at unpacking things and sort of really getting into what do we mean when we say that?
6204860	6212910	I	0.7909736633300781	Types of discussions and what does this term mean not taking things for granted as going through the text.
6214400	6230530	I	0.8216886520385742	There's a balance to be struck in taking that approach of asking what do we mean when we're talking about this and putting nouns on things and relating it to language and not going too far over into getting into fine detail about things.
6237130	6238630	A	0.9147727489471436	Thank you, Lyle.
6238970	6240586	A	0.7522189021110535	And then I'll leave with your question.
6240688	6244860	A	0.9907387495040894	Yeah, this firstly great session, really great conversation, I really enjoy it.
6246270	6266930	A	0.941454291343689	Most of this is new material for me and so I'm really enjoying the breadth of the conversation and I'm cognizant of this aspect you're digging into is how much do we sort of separate out the pieces and go deep dive in different places versus more of touching on multiple threads and their interactions?
6268150	6286210	A	0.9364696741104126	For me, while I understand there is a balance to be struck there, I'm really enjoying the challenge of relating as an example, the math to the philosophy, to all these different threads together because they are linked.
6286290	6286920	A	0.5664746165275574	Right.
6288910	6299286	A	0.8417035937309265	I do understand that some of those areas need a separate group that you can drill down into for me personally.
6299318	6302254	A	0.4945455491542816	And so this may be not the same as other people in the group.
6302372	6312990	A	0.9711874127388	I'm really enjoying understanding the connections, the philosophy, how these different thought process came to be through history and get that depth of understanding.
6314390	6316270	A	0.9147727489471436	Thank you, Lyle.
6316430	6324050	A	0.5219493508338928	And for those who want to listen or view, these live streams have many, many themes.
6324390	6327400	A	0.7896203994750977	So check if there's papers that you're interested in here.
6328010	6333190	A	0.8720148205757141	The live streams is about papers, so there's 46 papers.
6333530	6335862	A	0.6589825749397278	Guest streams are not driven by a paper.
6335916	6337526	A	0.8198575377464294	Sometimes the person is sharing a paper.
6337628	6341334	A	0.8227741122245789	But these are like presentations, hearing from different perspectives.
6341382	6345702	A	0.7763250470161438	And if anybody wants to help organize these, that's what we do in comms.
6345766	6359614	A	0.7839345932006836	If they want to facilitate and participate in these discussions, if they want to contact authors, recommend papers, these are all distributed tasks that are leverage points for people who care to just do a ton of amazing things.
6359732	6381794	A	0.5296382308006287	Like if somebody's interested to connect it to a given community and make an artifact or a live stream co organize that, we can catalyze it at the lab scale for individuals who know about the affordance but then want to take that affordance to just have really leveraged impacts in the active ecosystem.
6381922	6390504	A	0.7188887596130371	So, ali's question and then jessica sorry.
6390542	6392456	F	0.6170418858528137	I don't have any questions you asked.
6392478	6398010	A	0.925738513469696	About the timetable for the meetings, like what specific times are they occurring at?
6400140	6400552	A	0.4753468930721283	Sure.
6400606	6401064	F	0.5491447448730469	Yeah.
6401182	6401812	A	0.584351658821106	Okay.
6401966	6407740	A	0.9293442964553833	They are on Mondays at 13 and 23 UTC.
6408320	6418620	A	0.8363329172134399	There's two meetings to reflect, like education being the primary mission of ActInf lab, and then that spreads them out by time zones.
6418780	6426800	A	0.7179483771324158	But if somebody really wants to contribute to an area, the organizational unit meeting is not the rate limiting step.
6426950	6434288	A	0.7708368301391602	Anyone who has attention to contribute will be able to find a regime of attention that is connected to a task that's meaningful.
6434384	6439700	A	0.5683184862136841	The rate limiting step is not people's availability for a 1 hour meeting.
6440200	6442164	A	0.7963202595710754	It's however much time people want to contribute.
6442212	6447556	A	0.573790967464447	Whatever practices and things will find something that works for people who want to be engaged.
6447668	6453512	A	0.6583860516548157	So don't take these meeting times as being like when we're doing it, when we're deciding.
6453576	6463470	A	0.8061431646347046	Even anybody who wants to can email or contact just the lab email address and be started on figuring that out.
6464580	6465680	A	0.6628338694572449	Jessica.
6468340	6468752	B	0.46103888750076294	Yes.
6468806	6473520	B	0.8884083032608032	This was related to the question about applied projects.
6474020	6498040	B	0.526539146900177	I was thinking that maybe one thing that we could do is on the project ideas to have a table where people can briefly share what they want to do or just say, okay, I'm interested in machine learning and apply active inference and maybe this specific topic.
6498380	6508828	B	0.7963576912879944	Who will be interested in discussing this or exploring what to do and then adding the names of the people who will be interested in that.
6508994	6522028	B	0.8985066413879395	So the person who started the project, then they can start maybe contacting those people and see what time they can meet and start creating their own subgroups.
6522124	6527890	B	0.5065515637397766	So maybe that's something that we could do to facilitate that in a simple way.
6529460	6532692	B	0.7532237768173218	So just start saying, this is what I would like to do.
6532746	6535910	B	0.8715883493423462	Apply active inference while also studying the course.
6536520	6546490	B	0.7985705137252808	And we like to connect with people here who might share the same interest and see what kind of feedback that person can get.
6547740	6548490	A	0.6283750534057617	Thanks.
6548940	6564620	A	0.5574129819869995	And just connecting and building trust and having like a buddy system or small groups or just people who are on the relatively long path to apply active inference on teams.
6565540	6574912	A	0.6884986758232117	We don't have the speed dating hot swap activation protocol but connecting with people.
6575046	6580036	A	0.700431227684021	And then however it's authentic in that relationship.
6580218	6596200	A	0.5416256785392761	Seeing what you're interested in in three months will be in a pretty different situation, but we still won't have even gone through the second half of the book on the application of the textbook.
6596620	6604510	A	0.7489256858825684	So there's a lot of time for us to develop ideas and to connect with each other.
6607440	6609084	A	0.9526431560516357	So thanks for sharing that a lot.
6609122	6624320	A	0.8210879564285278	Jessica and I tagged you so that we can create a table with the right way or do it however is the right way because it helps enable connections for people who want to connect around applying.
6625220	6641204	A	0.569347620010376	And also it helps us remember these are the specific reference points in the text that are like our attractor regime of attention for this textbook group.
6641322	6643524	A	0.730692446231842	Like the textbook group isn't all of active flap.
6643572	6650040	A	0.6503333449363708	If people want to apply active inference, it doesn't have to be from the ground up, but it totally could be.
6650190	6655980	A	0.5182891488075256	But there's many ways to apply that are just in different codas that people can get involved in immediately.
6657280	6666930	A	0.6564247012138367	So if somebody feels like doing things, I hope they feel like they have the agency to do that.
6670180	6677200	A	0.6607252955436707	Okay, any final thoughts on this interesting semi pattern breaking?
6678760	6706508	A	0.6793841123580933	And also yes, one final thought for me is we would have had tools organizational unit meeting at this time, which is why near the end I asked if you want to do different scheduling because in general it's probably not good practice or ways of working to go overtime to respect everyone's time and all of these types of things.
6706674	6714204	A	0.7927900552749634	But also in the future we're in gather so people who want to keep discussing the textbook could go there into a different room.
6714322	6717970	A	0.7613515853881836	People who want to do Tools can go into another place.
6718740	6730172	A	0.7847124338150024	So we need to figure out how to do that through the people who want to be there, like these people and the feedback that everybody has in the ways they want to co create it.
6730246	6732880	A	0.8727396726608276	Tim and then anyone else who has like last thoughts?
6733040	6733412	A	0.5456083416938782	Hey.
6733466	6738470	A	0.8886798620223999	Yeah, I was just going to say this is generally way more interesting than the Tools meeting generally is.
6741260	6744970	A	0.9479339718818665	Cross pollination shows great potential already, I would say.
6745580	6746664	A	0.9498600363731384	Yeah, sounds good.
6746702	6771810	A	0.8753376007080078	I just wanted to add to that conversation, though, about someone even mentioned Plato, Socrates and all that and that whole sort of recursive involution of that raification thing you were talking about and sort of the thought processes maybe being almost like a recapitulation of the structure learning and the Kreptasian factor graphs and all that kind of thing you were talking about there.
6772580	6786900	A	0.8615019917488098	Plato had like a concept of knowledge which he referred to as recollection and this idea way, way back where all learning and knowledge is actually an act of recollecting what we already know.
6787050	6790856	A	0.8127188086509705	And I just wanted to point out there's kind of maybe just more of.
6790878	6792650	I	0.6163046360015869	An interesting.
6796860	6803064	A	0.8269460201263428	Illusion or connection, I guess between those two where there seems like what's old is new again.
6803102	6804600	A	0.8478401303291321	Or what have you covered?
6806540	6807530	A	0.7275791764259338	Thanks, Tim.
6809740	6813690	A	0.8495757579803467	Anyone else who hasn't spoken or who would like to add anything?
6831220	6831470	A	0.584351658821106	Okay.
