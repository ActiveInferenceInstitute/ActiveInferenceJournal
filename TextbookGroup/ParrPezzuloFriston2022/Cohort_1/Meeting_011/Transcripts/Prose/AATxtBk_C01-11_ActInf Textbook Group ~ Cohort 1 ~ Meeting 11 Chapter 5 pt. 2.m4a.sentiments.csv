start	end	speaker	sentiment	confidence	text
2570	3646	A	0.5380696654319763	Alright, hello everyone.
3748	16750	A	0.9042671918869019	It is week eleven and we're in chapter five, part two of the active textbook group first cohort.
17890	29160	A	0.8440116047859192	We'll be now turning to some of the more direct questions on chapter five after having more of an overview last week.
30250	40540	A	0.8839032649993896	We'll also be concluding our regular chapter discussions for the first part of this book.
41150	66180	A	0.7300965785980225	And in the coming two weeks, we'll be having some review and synthesis and connecting some dots, asking overarching questions, returning to questions that were based in a specific chapter and hopefully people like on their own or wherever else they're seeing as relevant or requesting new pages if they see something that they want.
67030	73666	A	0.8877730369567871	Providing some synthesis on this first half of the textbook, which is the epistemic half.
73768	87970	A	0.8894338011741638	And then for people who want to continue in the textbook group, go to the onboarding page and there's two columns there's.
88130	91530	A	0.8719888925552368	Yes, for part two of cohort one, chapter six through ten.
91680	106270	A	0.8038756251335144	So check that box if you want to be included in starting in September going through chapters six through ten, which has like the recipe for active models and that's when we're going to be getting more hands on with modeling.
107570	118050	A	0.9179367423057556	Also, everyone is welcome to join for part one, chapters one through five, cohort two also starting in September.
119190	147606	A	0.9394524097442627	So it could be a fun experience just to get another coat of paint on the material, play a more active role, ask another set of questions informed by what you've seen in the first cohort so feel free to check those boxes and then also keep incubating as we head into chapter six and beyond.
147718	176150	A	0.7842087149620056	In the second half of the textbook, like the project ideas, several of the project ideas like related to what Mike and Noah have added, we've started to address and explore in the active block, for instance, meetings on Wednesday, especially related to cyber, physical systems, simulations, taxonomies for governance, these kinds of ideas.
176970	185720	A	0.8427397012710571	Brock's added some great notes about what is the ramp that gets someone to the low road or the high road.
186410	194330	A	0.8759874105453491	And then I've recorded the first chapter and the first segments as an audiobook.
195390	215158	A	0.7236576676368713	The first chapter doesn't have any equations so it's straightforward to read, but the subsequent chapters do have equations, which is motivating having the natural language representations of the equations.
215354	222802	A	0.806412935256958	So there's still a ton of discourse questions that can be asked why things are one way, why things are a different way.
222936	227366	A	0.9061472415924072	If it can be placed into the equation itself, that's great.
227468	238314	A	0.6475335359573364	If it needs to be somewhere else, hopefully the space exists and people can request, if not, but for example, when reading the textbook, the equations can be read this way.
238432	253994	A	0.8276607394218445	So those are just some of the projects that people can look forward to and the affordances to continue on, which is again going to the onboarding and participating in first five chapters.
254042	258366	A	0.9323963522911072	Again cohort two or going to continue?
258468	279490	A	0.545570969581604	On with chapters six through ten starting in September for both of these so that we can complete one pass of the book by the end of the year and also probably make a lot of progress on different project ideas and project ideas arising as we start to see and build templates for the models.
279990	287880	A	0.9875434637069702	And also Ali has some nice interactive notebooks, so there will be a lot of great things coming together.
289790	292780	A	0.5361513495445251	If anyone wants to raise their hand, of course, just go for it.
294350	301840	A	0.8539547324180603	Otherwise we will be continuing with the questions asked about Chapter Five.
303170	312334	A	0.9290632009506226	Before we go to the questions, is there any general comment that somebody wants to add about Chapter Five?
312532	317220	A	0.8925088047981262	Their reading of it, their rereading of it, listening to the video from last week?
318710	332440	A	0.863079309463501	How is chapter Five hitting them today's?
341260	345790	A	0.8878551125526428	To kind of maybe bring that one step closer to a specific question.
347120	360000	A	0.8313128352165222	I'm not going to read this whole quote, but this question says in the preface they wrote in Chapter Five, we will move from formal treatments to biological implications of active inference.
361860	372260	A	0.873637855052948	This AIDS in mapping the abstract computational principles of active inference to specific neural computations that can be executed by physiological substrates.
373480	379940	A	0.5478605628013611	This is important in forming hypotheses under this framework and ensures that these are answerable to measure data.
380090	384680	A	0.8940562605857849	In other words, Chapter Five sets out the process theory associated with active inference.
385820	389610	A	0.8480489253997803	Is this how people saw chapter five?
389980	393484	A	0.8533413410186768	Do they feel like it did something different?
393602	406400	A	0.8863146901130676	Did it succeed at making the abstract computational principles linked or mapped to specific neural computations executed by physiological substrates?
424480	424892	A	0.46103888750076294	Yes.
424946	427812	B	0.5536060929298401	Eric, first of all, I have to apologize.
427896	438530	B	0.7942313551902771	Only watched half of last week's discussion, so I may be talking about ground that's been covered before.
440840	459450	B	0.8413054943084717	It just seems to me that I've seen many, many papers trying to map theories onto brain circuitry and physiology, and I'm not well enough.
460940	466036	B	0.5501209497451782	I'm only loosely associated with neuroscience and don't follow it very closely.
466068	469484	B	0.5009830594062805	So it's hard for me to cite specific instances along the way.
469522	473852	B	0.8672506213188171	I know you mentioned no Menta, which is one of the more recent ones.
473906	478030	B	0.7136023044586182	It's trying to say these are what the layers are doing.
478900	501908	B	0.6182869076728821	So this chapter to me didn't seem any very qualitatively different from anybody else's very hand wavy way to say here's what the computations are all about and here's how they map to what brain circuitry could map to what brain circuitry might be doing.
502074	514330	B	0.6991041302680969	It's all quite hand wavy, I find, and I guess plausible, but it's certainly not definitive, nothing close to that.
518220	531360	B	0.8645378351211548	Maybe one other comment I would say is, again, in this chapter, they use this word prediction in a way that conforms to the theory.
531860	549060	B	0.8497572541236877	But to say that what's happening in, say, motor control, where top down signals from the cortex go down to the ganglia in the spinal cord in order to invoke motor patterns.
550520	573950	B	0.5527393817901611	To call that a prediction is, to me, a kind of well, that's taking extreme measures to map the concepts of the theory onto what neurons are doing and if the theory works out to be very useful in some way and that's what you have to do to make that happen.
574640	592550	B	0.5976845026016235	Okay, I guess I can use that language, but Operaria just does not seem like the right language to use to say, yeah, we're trying to set up some motor patterns, set up some context and situations for what we want the local reflexes to be doing.
593560	597588	B	0.6940453052520752	But to cast that as a prediction just seems a little unnatural to me.
597754	600980	B	0.8802822828292847	So those are my two reactions to this chapter.
601800	604090	A	0.8529649376869202	Thank you.
605740	607850	A	0.87897789478302	Anyone else with a raised hand?
613580	630400	A	0.847528874874115	This is a really good point about what the linkage or mapping is between without going into, like, you know, is anything physical or, et cetera, like physical brains in their niche and any type of equations.
631140	635504	A	0.8305061459541321	Would a well fitting linear model say that the brain is a linear model?
635702	640480	A	0.8154377341270447	Does a well fitting Bayes graph imply that the brain is a Bayes graph?
641060	652324	A	0.7360281348228455	Does a well fitting Bayes graph plus a philosophical belief that we're just making a map, we're not describing the territory equate to what beyond a linear model or a verbal model.
652442	653380	A	0.7415806651115417	Rohan.
655260	655672	C	0.5491447448730469	Yeah.
655726	658170	C	0.7356173396110535	Building on the previous point right.
659340	677404	C	0.48932453989982605	I'm still unsure about what Active inference is, considering a signal, there's no effective well, there's no noise model or it doesn't specify that here's, because if you say that I'm predicting something, right.
677442	687484	C	0.8116381168365479	So there must be something that is substantially different, statistically different from some noise distribution that you can differentiate.
687532	688080	C	0.5664745569229126	Right.
688230	697220	C	0.5752870440483093	So it's basically trying to estimate some hidden probabilities, which is not really a signal.
698360	699428	C	0.7228710055351257	Does that make sense?
699514	712760	C	0.8160545825958252	Because even the internal states, unless they're actually instantiated prior, like when we set up the model, we say, okay, these are the only states that you can actually traverse.
715600	720620	C	0.7099725604057312	You still have to infer the states from your measurements of reality.
724080	725070	A	0.8529649376869202	Thank you.
730660	731836	A	0.6984319686889648	Jacob?
732028	732384	D	0.5491447448730469	Yeah.
732422	764068	D	0.7833266258239746	I just want to ask if the noise isn't kind of implied in the POMDP formalism, like, I think in Figure 5.4, where it shows the direct and indirect pathways of message passing, it describes Active and the basic ganglia as a POMDP generative model.
764234	766584	D	0.7912881374359131	So it's partially observable.
766632	769260	D	0.6601868271827698	Doesn't that imply some kind of noise?
772480	778944	C	0.5998331308364868	My counter to this would be that is missing information that needs to be filled out.
778982	780652	C	0.6808043122291565	That's not really noise.
780716	781232	C	0.5664745569229126	Right.
781366	791730	C	0.5918896198272705	So noise would be something let's not use this.
793080	813924	C	0.9022167325019836	So we have returns of a stock, and looking at the distribution of the prior returns, we know what the spread is, and in case we want to measure whether your portfolio is substantially different from this distribution, that's where we would have some sort of, like, sharp ratio or a signal noise ratio.
814052	821630	C	0.8151625394821167	Noise ratio being the complete set of distributions that are possible, the set of ranges that are possible.
823680	827788	C	0.5988073945045471	That is not really here, because that is missing information.
827874	839436	C	0.6539771556854248	So we can only observe the fact that we have only partial observations does not excuse the fact that we don't have even noise models of the sensors.
839468	842230	C	0.7581480145454407	So how good are the sensors, for example?
843480	845990	C	0.8669517636299133	Do we have some idea of that?
847400	847812	D	0.46103888750076294	Yes.
847866	851460	A	0.8886712789535522	Yaku, but then I'll add a point about the Espasian terminology.
852120	852870	D	0.5491447448730469	Yeah.
859500	882080	D	0.5370560884475708	What's the practical difference between partial observation where the noise implies some kind of information that is missing, versus a distribution that's added to full observation that adds noise to the sensory processing?
885140	885890	D	0.7671424746513367	Great.
889220	897364	C	0.9099612832069397	So if I use an actual physical sensor, right, it would be something like what are the ranges of values that it can go up to?
897402	905960	C	0.8438993692398071	Because we've designed the sensor, so we basically know what the bias is, what the variance of the sensor is under different conditions.
907900	911716	C	0.8743013143539429	There are actual physical processes implied in that measurement.
911828	922424	C	0.879661500453949	So in the case of ultrasonic sensor, it's probably like some current value or some voltage value that's being measured by some circuitry somewhere.
922552	924430	C	0.816379964351654	So there are ranges for that.
924800	927788	C	0.8028473258018494	So there's no missing information there.
927954	933616	C	0.6777188777923584	So you basically know it's already a prior in this system, right.
933638	935888	C	0.7978956699371338	So you know what the ranges of values are going to be.
935974	939952	C	0.735139787197113	And from there you need to infer the sum state in the world.
940006	942870	C	0.6956976652145386	So is there an obstacle in the way or is there?
946200	950692	A	0.8295558094978333	Okay, let me just make a comment about some basing terminology then.
950826	955844	A	0.9139071106910706	Jessica and Brock so let's look at figure 4.3.
955882	961224	A	0.9291159510612488	This is the partially observable Markov decision process that Jacob talked about.
961262	971928	A	0.8410396575927734	But we're going to be just talking about the perceptive part, not the action intervention into how things are changing, yet just focusing on this motif on the left, like step by step guide uses.
972104	976280	A	0.6681761145591736	So you mentioned about the bias related to measurements.
976360	1008490	A	0.862162709236145	So if the measurables are the observable sense states, then the bias and the covariance and the variance about how the reading on the thermometer relates to the underlying variable, the hidden state, the temperature of the room, it's embodied in the a matrix because that is actually the learned or fixed variable that is playing a role of a noise model.
1009260	1020380	A	0.8728577494621277	Then you mentioned when talking about returns on stocks, testing whether there's like a substantial difference from some null expectation, like is there a signal that's different from the noise?
1021360	1023464	A	0.7997079491615295	This is like a frequentist approach.
1023592	1027820	A	0.9090288281440735	It's based upon determining whether there's some statistically significant level.
1027890	1040640	A	0.8152815699577332	Doesn't have to be, it's not the only way to do it, but one can do like a p value on whether a given signal is statistically different from given a noise model, different from noise.
1041160	1045264	A	0.8084083199501038	And then like, the sharp ratio and other types of things are like summary statistics.
1045312	1047140	A	0.7015682458877563	They're like descriptive statistics.
1050520	1072536	A	0.8770079016685486	Noisy measurements are addressed in the context of the POMDP by having an a matrix that accommodates some of the features of denoising a signal and then precision variables and those precisions can again be learned or fixed.
1072728	1087004	A	0.8299199938774109	But like the functional aspects of what is being referred to as noisy measurements are accommodated within this kind of Bayesian approach.
1087052	1108792	A	0.8514270186424255	Which is why common filtering, generalized Bayesian filtering, why these techniques are used because we can have a Bayesian update scheme implemented with variational approaches, message passing, sampling, all these things that does denoise signal, and it does embody a noise model and a signal model.
1108926	1113400	A	0.8424126505851746	And that's all part of the generative model of the cognitive entity.
1113820	1118910	A	0.6417257189750671	So it just isn't being addressed from a frequentist statistics or.
1121120	1123704	C	0.6880820989608765	Yeah, I shouldn't have brought up the Sharp ratio.
1123752	1125132	C	0.7789733409881592	Maybe that's not the best.
1125266	1133664	C	0.7955464720726013	But the Sharp ratio is effectively some way to say that some portfolio choice is different from others.
1133782	1138800	C	0.8836820125579834	Or in communication systems you would use something like EB over N zero.
1138950	1151024	C	0.8167771100997925	That's the signal to noise ratio for any sort of communication system, but they're not necessarily only frequentist.
1151072	1151284	C	0.5664745569229126	Right.
1151322	1155092	C	0.8687741756439209	So there are patient ways to estimate these things.
1155146	1163044	C	0.749315083026886	In fact, that's pretty much how we do it in practice, is we don't assume that we know the complete distribution.
1163092	1166040	C	0.9087396264076233	We update priors in each of these cases.
1170160	1173372	C	0.8835371136665344	Coming back to your point that the A matrix does address this.
1173426	1182160	C	0.8832431435585022	The A matrix would be something that you said it would denoise and filter out some stray observations.
1182580	1193430	C	0.8073118329048157	But okay, the question still remains is when you're saying prediction, is it prediction of the signal over here?
1194280	1197488	C	0.8794037699699402	As in what is the future state of the sensor?
1197664	1208536	C	0.8762368559837341	But I think there, it seems seem to indicate that the prediction relates to the free energy minimization itself.
1208638	1208904	C	0.5664745569229126	Right.
1208942	1230728	C	0.6715502142906189	So you choose policies that would minimize your free energy and keep yourself into some set point, which means that there should be some sort of an idea of what ranges are there for this value or how far can these go before you're not in that set point anymore?
1230904	1235472	C	0.8292108774185181	So even if you, if you do want to make that prediction, it's, it's not just the signal value.
1235526	1240988	C	0.8774634003639221	So signal values effectively through the Marco blanket, they affect some internal state.
1241174	1246196	C	0.8156670331954956	And I'm assuming that's what we are trying to predict, that the trajectory of.
1246218	1257450	A	0.7468457221984863	The future internal states actually the expectation that's being minimized is over outcome observations, not about internal states.
1258380	1258792	C	0.7123861312866211	Okay?
1258846	1259160	C	0.5491447448730469	Yeah.
1259230	1260090	C	0.6455479264259338	I'm sorry.
1262460	1278350	C	0.7530577778816223	Even then, the signals may have well defined precision and bias, but the entire system itself doesn't have any sort of well, it doesn't know how wrong it can go.
1278880	1280824	C	0.7284554839134216	It doesn't have any error estimate.
1280952	1282956	C	0.7859116792678833	So there's no noise model.
1283058	1298420	C	0.9071154594421387	As such, we would have to assume that there is some distribution of states and then then use something like lee squares or some other optimization routine to actually bring this in practice.
1300040	1300500	A	0.7671424746513367	Great.
1300570	1301670	A	0.5519260168075562	Totally possible.
1302360	1315988	A	0.7110116481781006	It would be interesting to sketch out a Bayes graph for what you believe a signal to noise or some type of noise model would embody and maybe we will see some analogies or some mappings.
1316164	1317880	A	0.8589619994163513	Jessica and then Brock.
1320620	1321332	E	0.5325649380683899	Hi.
1321486	1328620	E	0.825080394744873	I think someone like what I was going to say probably already been covered by both you and Rohan in the new comments.
1328700	1339250	E	0.7801237106323242	But I was going to say that with this filtering and a lot of the biases and things, I kind of made sense of it.
1341880	1344644	E	0.8936998248100281	I think it was like chapter two or something like that.
1344842	1362410	E	0.7512590885162354	So the why is this quote unquote thing that we can observe from the hidden state or the process of something that we don't know for everybody.
1362860	1368900	E	0.8445040583610535	We can see the same thing, but how we process it internally is going to vary.
1369060	1370484	E	0.80381840467453	It's going to be very subjective.
1370532	1376920	E	0.6009397506713867	So the why is going to look different for Daniel than it's going to look for me based on all this filtering.
1377080	1392370	E	0.7561456561088562	And so the blanket states, I imagine, sort of like what have those filters that encode the biases and other things that allow us to process things differently than our generative model.
1393780	1414520	E	0.7866889834403992	It's going to be updated differently, also encoded, I think in the general model will be a lot of cures and things like that that embody, I think, probably a lot of biases and things of how we understand things which also influence how we interpret what we observe.
1416400	1420504	E	0.7500573992729187	So for me, it's like a lot of these things are there in terms of statistics.
1420632	1431868	E	0.691489577293396	I don't know how much, but that's how conceptually, I understood a lot of these things.
1432034	1438000	E	0.6047282814979553	Basically, in the blanket days of the Marco blanket, it would have a lot of disfaltering.
1439860	1440610	E	0.46103888750076294	Yes.
1442040	1462040	E	0.6506254076957703	If you're going to try to, let's say you observe something that's different than what you predicted in your model, then you would take action and to forage and find information and to figure it out, okay, what am I missing?
1462540	1474024	E	0.5273166298866272	Why did I make this mistake or like this error in my prediction so that I can have more information and update the model so that it aligns more closely?
1474072	1485090	E	0.8757456541061401	So then you will basically take action to the noise and basically get closer to the reality that's out there.
1485780	1486192	E	0.5491447448730469	Yeah.
1486246	1491316	E	0.5622816681861877	I don't know if this official lightning, but that's how it kind of makes sense to me.
1491498	1493300	A	0.7252618074417114	Thanks, Jessica Brock.
1496280	1510000	F	0.8705220222473145	Yeah, I just wanted to, I guess, speak to this sensor noise model in practice.
1510080	1531664	F	0.8604653477668762	In reality, when we're talking about sensors, like in a physical system, like, like a digital signal processing kind of context, like, the sensors are tested under some conditions for things like jitter and spurious kind of noise conditions and stuff like that.
1531702	1544470	F	0.5531717538833618	But they're tested under some conditions, meaning that there's never ever going to be a time when you have an actual model.
1545160	1553530	F	0.861510157585144	You're just going to have an approximation whether that's expressed in a frequentness or Bayesian way.
1553980	1566732	F	0.7337533235549927	There's going to be some uncertainty in the model and especially if you start connecting it up to a larger system doing the same.
1566786	1586770	F	0.873604953289032	Kind of like is the jitter in that sensor the same when it's completely isolated as it is when it's on a six x nine PCB board with 12 volts on one side and an oscillator next to that.
1590020	1591430	F	0.7957186102867126	Is it the same thing?
1593000	1598550	F	0.8939417600631714	You have to do these sort of electromagnetic compatibility resonance sort of testing on it.
1601640	1617710	F	0.7984141111373901	In practice it's Bayesian like you're doing the same sort of bounding and belief testing and finding your errors and correcting them.
1618640	1620060	F	0.7619234919548035	Even in practice.
1622560	1646224	F	0.7499271631240845	I don't see how you could possibly have, even physically a system that could exist where you had a noise model that you could write down that was actually the noise model under all conditions or yeah, it doesn't seem like a approachable.
1646352	1646932	F	0.5666733384132385	I don't know.
1646986	1651510	F	0.9435118436813354	It's not even not tractable, but just a wrong thing to do.
1653340	1654600	A	0.766993522644043	Thanks, Brock.
1656220	1666012	A	0.7742725610733032	In the case of engineering and designing models, it's up to the designer or the engineering team to understand what is adequate or not.
1666066	1672840	A	0.5368893146514893	And for natural systems outside of their bounds, natural selection sweeps them off the table.
1673000	1694100	A	0.5241265892982483	So some of the adequacy questions are either based upon specified or implicit human standards or the failure to resist dissipation and therefore the failure to realize repeated measurement of oneself or from the external.
1694520	1700870	A	0.6900209188461304	And then that system is no longer let's just continue to move through some of the questions.
1701880	1702656	A	0.688754141330719	Yes, Rohan.
1702688	1703510	A	0.4859412908554077	Go for it.
1705420	1709192	C	0.7636550068855286	Yeah, I completely agree with what Brock said.
1709246	1709512	C	0.5664745569229126	Right.
1709566	1730424	C	0.8493306636810303	But my point was, when you say that you're predicting something, it means that you either know the quantity that you're trying to predict and it corresponds to so in this case, some action results in some reward.
1730552	1735810	C	0.5587401390075684	I guess you could predict the reward, but without knowing how wrong you're going to be in the future.
1736180	1744096	C	0.7796557545661926	So where exactly any living system would have to be aware of its own bounds.
1744128	1744516	C	0.7360090017318726	Right?
1744618	1747732	C	0.8006049394607544	That's what I meant by noise model.
1747786	1762292	C	0.9020882844924927	So it has to know that it has to stay within some bounds and as it starts coming closer to one of the upper or lower bounds, there should be something like pulling it back down or some feedback mechanism.
1762436	1771964	C	0.5691123008728027	But that is not very clear from what I've read so far on active inferences, how exactly it would estimate that.
1772162	1774780	C	0.7998005151748657	You can just say free energy minimization.
1775920	1780680	C	0.8233022689819336	But what is a minimum in this case that would be different for different systems?
1780760	1785344	C	0.8008959293365479	It should have some idea of where the surface is of whichever local surface it's lying on.
1785382	1786690	C	0.7541833519935608	That was my point.
1787380	1789404	A	0.7906203866004944	So for sure it's different for different systems.
1789452	1792710	A	0.8059237599372864	It's different as every single generative model is.
1793480	1797264	A	0.7972168922424316	And then you mentioned like a pullback attractor.
1797392	1818120	A	0.8687835931777954	And so this has been treated extensively in the context of physiological measurements and then again where those priors on the physiological measurements are, the Tolerable range are either provided by the human engineering team or through evolution by natural selection and then the quantity.
1818640	1843632	A	0.8645984530448914	Another related topic would be expectation maximization models, which is what is happening essentially in the dialectic between the observation and the hidden state update is an expectation maximization like process where it's like given the hyper priors or we can just simplify, given the priors on S, what are the most likely or the distribution of observables.
1843776	1850128	A	0.8703898191452026	And then given the observables, what should be updated about the hidden state priors.
1850304	1867516	A	0.8480284214019775	And when those are at convergence, the model is stationary and then as things change, either from the top via learning or context shift or through changed measurements, the expectation maximization algorithm is just able to track those changes.
1867618	1873340	A	0.861472487449646	And that can, in the context of a fixed prior, have the function of a pullback attractor.
1875120	1878476	A	0.7962469458580017	Okay, and that's even before getting into action specifically.
1878508	1894448	A	0.7762685418128967	But yes, definitely considering the role of comparing future plans of action and which plans of actions will have the least expected free energy based upon their pragmatic and Epistemic value.
1894614	1907008	A	0.8162407875061035	Like the Epistemic just being clarity around how it's going to be achieved and the pragmatic value being that KL divergence between the expectation slash preferences and the expected observations.
1907184	1920140	A	0.684948205947876	So if we expect slash preferred to be in homeostasis, the pragmatic value is going to come or be loaded onto policies that keep us in homeostasis, even if some other one is super informative.
1920640	1926248	A	0.8550431728363037	How that model gets tuned is quite literally the details of how the model is trained.
1926344	1926988	C	0.5664745569229126	Right.
1927154	1930044	C	0.515886664390564	My point was that active inference doesn't help us find this.
1930082	1938770	C	0.857001006603241	We have to find this ourselves and then hopefully once we have instantiated these bounds, I think active inference works very well to keep it within this.
1939300	1951792	C	0.5916060209274292	If you can't discover this de novo, I can't have what you'd say table or asset type system, like a blank slate system, go out in the world and discover your bounds.
1951936	1953432	C	0.7299950122833252	That's not going to happen.
1953486	1957288	C	0.844897449016571	But this kind of method is what I was making it out.
1957374	1966644	C	0.8501291871070862	Whereas taking something equivalent without any so deep learning is another method.
1966692	1966856	C	0.7360090017318726	Right?
1966878	1970172	C	0.7575206756591797	So you just feed it a lot of data, it doesn't have to know anything about the data.
1970226	1977468	C	0.9129645824432373	Eventually it forms some opinion about the data it's seen and then it's able to do some classification depending on how much data it's seen.
1977554	1980524	C	0.7483750581741333	So it's able to build certain amount of bounds.
1980652	1984016	C	0.7966797947883606	Whether that's generalizable is a different question.
1984118	1995108	C	0.6352765560150146	But here the learning part does not say much about how exactly it goes about discovering where its limits are.
1995194	1996356	C	0.6943380236625671	That's my point.
1996538	1997028	A	0.4753468334674835	Sure.
1997114	1997940	A	0.8529649376869202	Thank you.
1998090	1998900	A	0.6499149203300476	Eric.
2002280	2020856	B	0.7305375933647156	I would love to dive just a little bit more into the thing you were just talking about, how expectation maximization is a mathematical formulation for how to infer belief states from observations.
2021048	2037916	B	0.9084757566452026	Because you basically go through this iterative process of trying to find alignment between the states of the belief and the observables and then you contract that over time between that concept and the concept of message passing.
2038108	2058344	B	0.8903557658195496	When I think of message passing, I think of some sort of a distributed system where you have some local computation and then it sends and you have again either synchronous or asynchronous process for communicating between these kind of different centers of belief state.
2058542	2064200	B	0.7036327123641968	And then again, through message passing, you have often an iterative process of convergence.
2064540	2066984	B	0.6356773376464844	So those are not the same thing.
2067022	2078444	B	0.8799533247947693	And I think message passing, to my understanding, would be an Em algorithm under certain types of messages and states at each of the nodes that you're sending the messages around.
2078642	2083100	B	0.7158145308494568	But not all message passing is going to be an Em algorithm.
2083180	2086204	B	0.7051170468330383	And similarly, when I think of Em, I don't think about message passing.
2086252	2104940	B	0.8861663937568665	I think about making an arrays of belief and matrices between mapping between belief and observations and then trying to compute an expectation for what my predictions would be and then making this iterative convergence.
2104960	2106692	B	0.6403912901878357	So I don't think of that in terms of message passing.
2106756	2112410	B	0.9267804026603699	So I just love to hear other people's ideas about how to tie these two ideas together.
2113740	2118760	A	0.8499342799186707	Yeah, Brock, if your hand is still raised.
2120160	2121996	A	0.5028268694877625	Okay, sorry.
2122098	2123470	A	0.8631657361984253	Yeah, all good.
2126800	2129090	A	0.8354120254516602	Does anyone have thoughts on this?
2130420	2136172	A	0.8169187903404236	There's a lot to say about the expectation maximization algorithms.
2136316	2141990	A	0.9067674279212952	And just to kind of give a little context, this is the step by step paper.
2142680	2147700	A	0.8841588497161865	So this is the model stream one, it's four parts.
2148680	2154840	A	0.8904213905334473	And this is like really a quite relevant figure, which is not in the textbook but helps a lot.
2154990	2160932	A	0.8637652397155762	Like this is the essence of the partially observable Bayesian inference.
2160996	2171916	A	0.887387752532959	There's a prior D and then there's an a ambiguity matrix that is mapping in a generative capacity between hidden states s and observation measurements O.
2172018	2184624	A	0.8557414412498474	This is the tail of two densities because O through A can give you the most likely S and S through A can give you the most likely O.
2184822	2196720	A	0.7046859264373779	And it turns out that by alternating those procedures in a Bayesian update context, that two stroke engine is called expectation maximization.
2196880	2214440	A	0.7970820665359497	Again, because given expectations on the summary statistics of A distribution, the expected sensory observations can be generated and then given those observations, a likelihood function can be maximized that then updates the hidden states.
2214590	2226300	A	0.9013912081718445	So this motif, this kind of elbow motif is then extended into a caterpillar with this be, which is how the hidden state changes through time.
2226450	2232576	A	0.765102207660675	So importantly, note what's not there, which is like the observations being chained through time.
2232758	2237216	A	0.808896541595459	So it's not that the temperature reading at one moment influences the temperature reading at the next moment.
2237318	2247030	A	0.8697518706321716	The temperature readings are continually linked, synchronously like in one time slice to their hidden states.
2247400	2260564	A	0.7430942058563232	So then when action gets into the picture, we've talked about like several sources that's like the equation 2.5 to equation 2.6 phase change, because action brings in several kinds of uncertainty.
2260692	2266510	A	0.6917750239372253	First off, you're reducing your uncertainty about observations which haven't happened yet.
2266960	2271340	A	0.5806430578231812	You're also having the unknown consequences of your actions.
2271760	2284800	A	0.871069073677063	And in order to have action selection that's relevant, one has to have a preference distribution over what kinds of observations they would like to be seeing so that action can guide it in that direction.
2285700	2288352	A	0.6030203104019165	Okay then.
2288486	2299540	A	0.8542397618293762	So that's the expectation maximization two stroke engine is basically graphically proposed here.
2299610	2316350	A	0.8148751258850098	D is just the initiating set of parameters and then in a one shot way, like you can have a folder with a thousand images and do expectation maximization on it, or you could have something that's dynamical and do that type of expectation maximization through time.
2321280	2327684	A	0.8860122561454773	Eric asked how is it related to message passing on graphs?
2327832	2341204	A	0.7271562814712524	So I'm not familiar with all the details of this model, but you basically said it, which was that certain message passing systems implement Em.
2341402	2344900	A	0.7321019172668457	But of course not all message passing architectures implement Em.
2344970	2347956	A	0.6899893283843994	So message passing is more general than Em.
2348138	2368540	A	0.8473484516143799	Also, Em wouldn't have to be implemented through message passing, but there's like an area of intersection where the Em algorithm can be seen as a type of message passing under certain compute rules in a factor graph.
2369120	2374060	A	0.8466253876686096	And Em, at least from here, may be used to break cycles in a factor graph.
2375760	2383970	A	0.8193120360374451	So it's always like how close to the kernel and the Platonic ideal of active inference are we talking?
2384580	2392870	A	0.7893700003623962	And then how many heuristics and just ways of connecting things are possible.
2393640	2398980	A	0.8619377017021179	So I will now read the chat.
2406610	2408394	F	0.8476735353469849	That'S from previous context.
2408522	2410000	A	0.7883908748626709	Okay, thank you.
2413750	2417742	A	0.8467783331871033	The statistical Parametric mapping textbook and documentation.
2417806	2433114	A	0.5648139119148254	SPM has a lot on Em variational inference and a lot of the parts that bring one to understand this a lot better.
2433232	2439622	A	0.5009541511535645	SPM is like almost like it doesn't include action that much because it's a neuroimaging.
2439686	2446430	A	0.8325493335723877	So the observations are neuroimaging, sensor fusion, different error modalities, like the whole monopoly.
2447810	2472390	A	0.6054219007492065	And then SPM started to incorporate participant actions in this partially observable metabasian way and potentially that is what led Friston and colleagues towards a grander synthesis of inference and action under a statistically principled framework.
2476090	2494762	A	0.7669543623924255	Let's just see if there's any other these are all important questions and there's a lot to get up to them and then there's like a lot to go from the question, but these are all important things to raise if anyone has a thought on this.
2494816	2499386	A	0.8457223773002625	How should we think about redundancy in neural systems in the context of active inference?
2499578	2509714	A	0.7196958065032959	So redundancy would be like if there's something that's playing a functional role but its removal is not damaging the function of the system.
2509912	2516766	A	0.7194983959197998	There's ten pillars knocking out one of them, the building stays up, so there's redundancy in the pillars.
2516958	2520550	A	0.8756791949272156	What about the cases where the same neural circuits serve multiple functions?
2522010	2540922	A	0.5619137287139893	So how do we deal with the fact that there's like a many to many potentially or a complex mapping between system elements and system functions where sometimes removing node one does nothing, but removing node one and two does a lot of things, but then removing one, two and three and it's going back to being fine.
2541056	2542090	A	0.6628338694572449	Jessica.
2544990	2551502	E	0.8617505431175232	I guess my comment is more like a question and maybe like ask Blue about it because this is what I feel.
2551556	2555262	E	0.8166555166244507	But this question made me think.
2555316	2555726	E	0.6950032114982605	About.
2555828	2576950	E	0.5718668699264526	It's not only like that the brain has this redundancy of things, but it's like if you have some kind of damage to your brain, another part of your brain that maybe was not used for something would develop that capacity and so it would create that ability.
2578250	2584842	E	0.7496680021286011	Neuroplasticity brand new even though it was not a redundancy to begin with.
2584976	2588170	E	0.7104752063751221	So I guess I'm more curious to understand this.
2588320	2593660	E	0.863003671169281	So other people who know more like Blue and stuff about this.
2594130	2599840	E	0.7644026875495911	Basically that's kind of what this question made me think about and kind of wanting to understand more.
2602050	2602558	A	0.7344964742660522	Nice.
2602644	2603726	A	0.6243525743484497	Good question.
2603828	2604094	A	0.5491447448730469	Yeah.
2604132	2605774	A	0.8467771410942078	Blue wrote, Depends on your age.
2605892	2613890	A	0.8382365703582764	Different neuroplasticity mechanisms are differentially available throughout life for different organisms.
2615430	2622758	A	0.7805675268173218	Just one thought on this would be like the same neural circuits serving multiple functions might be totally the case.
2622844	2630978	A	0.876429557800293	For example, and is the function of the heart to provide one pound of weight to the torso.
2631154	2633180	A	0.7849367260932922	It is a function of the heart.
2633870	2638954	A	0.8899067640304565	So identifying what function is being modeled is what's being done here.
2638992	2641740	A	0.8727287650108337	So let's just go to the example of figure five three.
2642430	2657746	A	0.5452633500099182	This neuron modifying it like a loss of function experiment or having it injured might influence more things than just the lower motor neuron descending message.
2657928	2661330	A	0.8230651617050171	So that'd be a case where it serves multiple functions.
2665810	2673570	A	0.8331314921379089	This is just one statistical model of this function, of this circuit.
2673910	2686242	A	0.6851369142532349	And that returns to the earliest comments of Eric with like, okay, this is like Tantalizingly seeming like it's actually going to be describing the neuroanatomy.
2686386	2691350	A	0.6078200936317444	But then they say things like note the absence of dot dot dot dot dot dot dot.
2691930	2698570	A	0.7065284252166748	Note that there's a discrepancy between, for example, the reality of the anatomy and the base graph.
2699630	2704970	A	0.5262371897697449	This highlights that the connections implied by message passing schemes may not manifest as single synapses.
2707910	2713394	A	0.6870960593223572	So, okay, there's kind of false positives and false negatives.
2713522	2716310	A	0.8168849349021912	The Bayes graph isn't just the anatomy.
2716810	2717960	A	0.6264714002609253	That's fine.
2718570	2722854	A	0.7061144709587097	The linear regression between height and weight isn't the actual relationship between height and weight.
2722982	2730566	A	0.5850028991699219	And the structural equation model of inequality is not the generator of inequality.
2730758	2735430	A	0.5080670714378357	So it's totally fair and shouldn't be expected to be otherwise.
2735590	2744298	A	0.49649837613105774	That the Bayes graph, the best fitting Bayes graph, the most didactic bays graph, the simplest Bayes graph, none of those recapitulate the anatomy.
2744394	2750370	A	0.6116350889205933	And the Bayes graph that recapitulates the anatomy would not necessarily even be the best fitting.
2750950	2752766	A	0.7427281737327576	It's map and territory.
2752958	2761574	A	0.7469787001609802	And if somebody has a special equation to break through that blanket, everybody would love to see it.
2761772	2774482	A	0.6227999925613403	However, sometimes it's easy to gloss over that in principle challenge of mapping formalisms to biological systems.
2774626	2780614	A	0.8197321891784668	Because we see the cell and then the blanket is the membrane and we see the brain and it's like vision and action.
2780662	2793390	A	0.5140076279640198	And it seems like it maps onto the physical or the anatomical structure of the world or the causal structure of the world, and it doesn't.
2794850	2806020	A	0.7042847871780396	So I hope people can add more thoughts about how we consider redundancy because it's a great question, but we'll leave it there.
2808310	2812310	A	0.8773285746574402	How are reflexes modeled in active inference?
2813050	2817314	A	0.9110691547393799	Would they exist in an active inference module that is distinct from proprioception?
2817442	2819830	A	0.8907665610313416	Would they operate on different timescales?
2820810	2850434	A	0.9248753190040588	If anybody wants to add some context on it, a reflex arc relating to where reflex is defined as a function that is being relayed through the spinal cord of a mammal and not passing.
2850482	2858246	A	0.8002529144287109	Like you could have a nerve block in the cervical vertebra and it still is able to implement that's one definition of reflex.
2858438	2869818	A	0.764284074306488	Often it's also used slightly more broadly to mean like stimulus action, reproducible outcomes, but not every reflex has a perfect reproducibility, et cetera, et cetera.
2869994	2871630	A	0.7664414644241333	So it's kind of a continuum.
2872370	2876690	A	0.8427923321723938	Yes, it would involve proprioceptive input.
2877350	2891190	A	0.6057012677192688	That proprioceptive input would be combined or juxtaposed with the descending prediction, resulting in an error.
2892090	2897910	A	0.746307373046875	And then that directionality and magnitude of the error in this model drives the reflex.
2899450	2904940	A	0.8155664205551147	There can also be multiple timescales, but we haven't seen any nested modeling yet.
2905790	2908700	A	0.6211704015731812	This is just the one layer model.
2913490	2920746	A	0.911483645439148	The schematic on the left in figure five, one shows that layer five of cortex projects to spinal parameter neurons.
2920778	2923150	A	0.8387598395347595	And this can be interpreted as a prediction.
2925190	2960570	A	0.6399913430213928	Okay, so this is this one helpful context, and it relates to this earlier highlighted section, which is like it's the interpretation, the interpretive link between some anatomical or biological feature phenotype and some parametric resonance with a model.
2963530	2975930	A	0.6577857732772827	The validity of that ranges from pretty clear, pretty uncontroversial, pretty useful, pretty effective, to none of the above.
2977250	2984400	A	0.5764338374137878	And it's hard to know what given interpretive links are doing.
2985250	2997342	A	0.8988815546035767	Like saying that this edge on this base graph can be interpreted as a descending excitatory connection or that might be used to generate specific testable hypotheses.
2997486	3007830	A	0.8595205545425415	Like if we measured it during a period of excitation the activity of this neuron, we expect it to be increased, whereas if it was a descending inhibitory connection, et cetera.
3009210	3027260	A	0.805685818195343	That's a great example of active inference being used in in a proactive way to generate hypotheses about biological systems that are going to be, as they said in the preface, answerable to measured data.
3029570	3039550	A	0.8354358673095703	By grounding in a computational model that is related to the neuroanatomy but isn't trying to be like a digital twin of the neuroanatomy.
3039890	3046050	A	0.806013286113739	We can generate predictions about gain, loss of function, different measurements to make if they don't already exist.
3046470	3056550	A	0.7667564749717712	And then that can be used to increase our confidence or reliability or falsify even a specific generative model as proposed.
3058330	3074010	A	0.6790609359741211	So there's so much discourse like continuing to the present day and surely beyond, as like all these questions and recently posted in the Discord about active inference or free energy principle isn't falsifiable.
3074750	3078426	A	0.5509654879570007	Now, the funny link is it's not falsifiable.
3078538	3084826	A	0.7069334983825684	So it's been falsified, it can't be falsified, so it's incorrect.
3085018	3087502	A	0.9159653782844543	That's an interesting connection that some people make.
3087636	3089626	A	0.6347717642784119	But a linear model cannot be falsified.
3089738	3091806	A	0.5080386400222778	A base graph cannot be falsified.
3091998	3105670	A	0.8741558790206909	Once any given linear model is presented in a context with constraints for a certain data type, then it's an empirical question of its accuracy and adequacy relative to other models.
3106970	3115820	A	0.5749763250350952	But at the abstract level of a neural network or linear model or active inference, falsification simply doesn't apply.
3120880	3138800	A	0.6738258600234985	But there's a lot that could be clarified about what are the utilities and some of the pitfalls of mapping biological or cyberphysical systems to active inference models.
3140020	3152950	A	0.7885337471961975	If it's a purely digital system or potentially even a cyberphysical system that's been designed a really certain way, it might be compatible with activ like essentially by fiat or by design.
3154440	3161000	A	0.8162622451782227	One could make an artificial creature like an infer ant that is implementing active inference.
3162300	3171870	A	0.8842633962631226	One could also model an ant in the field using a linear model or a levee flight or some other model or an active inference model.
3172800	3174712	A	0.7427217960357666	But those are two very different settings.
3174776	3188560	A	0.8808820247650146	One in which sort of the rabbit was placed into the hat and then we have a rabbit analyzer and the other one being like we don't know what's in the hat, but we have a rabbit analyzer that we think applies to what is in this hat.
3200840	3207744	A	0.9252617359161377	Chapter five includes some evidence presented on different neurotransmitters.
3207792	3223560	A	0.6079959273338318	So it'd be interesting to see like, what other frameworks are able to be compatible or even provide unique explanations, predictions, et cetera, related to neurochemistry.
3224160	3232540	A	0.9089189767837524	Have neural networks ever been used to derive unique predictions or found compatibility with neurohormones neurochemicals?
3234400	3265140	A	0.8545336127281189	And then again, they have a final figure in chapter five that's like a graphical overview of several of the systems that are described in the chapter specifically relating to the cortical cognitive functions and then the dialectic between habit and free energy driven planning here with Dopamine as a precision modulator with extensive further modeling presented in other papers.
3265300	3278410	A	0.8707714676856995	And this even more basal motor selection mechanism based upon reflex arcs and proprioceptive error minimization and all of that.
3282140	3289100	A	0.8894339203834534	We raised these questions not to offer any answers, but to highlight some of the exciting avenues of future research in theoretical neurobiology.
3289260	3303216	A	0.8405319452285767	So a lot of the questions that are asked here in this paragraph, but also above, at the very beginning they said we're not saying how it is, we're just giving like the current process model understanding.
3303328	3308710	A	0.5655390620231628	And then especially at the end, they raise even more speculative questions.
3309080	3314490	A	0.8806644678115845	So that takes us to the end of chapter five.
3315660	3317368	A	0.8601597547531128	That's the first half of the book.
3317454	3320890	A	0.8816072940826416	That's the epistemic component of the book.
3321900	3326620	A	0.7683141231536865	Well, a lot of it is epistemic, but that's the first five chapters.
3329440	3338320	A	0.8581255674362183	The second five chapters, which are longer partially because of having more figures and things like that.
3338390	3349280	A	0.746006429195404	But you can see there's more pages slightly in the second part of the book, though we've also read at least some of the appendices.
3351240	3362372	A	0.5842069983482361	That's where we're heading, which is picking up on chapter six in just a few weeks with a recipe for designing active inference models.
3362436	3375420	A	0.8303561210632324	So for those who stuck with the uncertainty for the first five chapters and stay in the game, more will become clear when the recipe for the dish is seen.
3375570	3387708	A	0.8809585571289062	And then more will be clarified when the dish is prepared, and then when you cut the vegetables, and then when you design the dish and the recipe and all of that.
3387794	3390592	A	0.7970331907272339	And that's like a journey that we're all going to be on.
3390726	3395372	A	0.7217808961868286	The tools are not finalized and the kitchen is not completed, et cetera, et cetera, et cetera.
3395516	3414730	A	0.754879891872406	So it's just a call for us to go to Onboarding and indicate our interest in continuing with one or the other cohort or sharing with any colleagues who you think might like to jump in to the second cohort of part one.
3415180	3427116	A	0.8511888980865479	And then in the coming two weeks, we'll be able to take a step back, look over the chapter questions, but also think about more general questions that we're having.
3427298	3448080	A	0.6166524291038513	Basic questions, meso questions, advanced questions, research avenues, and also turn to the project ideas where multiple of these are already active and there's spaces for people who want to facilitate or catalyze some other direction.
3448420	3454876	A	0.9757916927337646	So fun meeting everyone's.
3454908	3465016	A	0.8917816877365112	Welcome to stay on for Tools or head up to a room above if they just want to talk to other people about anything else.
3465198	3471400	A	0.9713035821914673	So thanks again for joining and see you in just a few minutes for Tools.
