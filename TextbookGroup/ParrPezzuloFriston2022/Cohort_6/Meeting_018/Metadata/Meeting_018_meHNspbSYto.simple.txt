SPEAKER_01:
okay we're back in cohort six for chapter eight first meeting so andrew however you wanna do it nice sounds good um yes so welcome today we're talking about chapter eight in the 2022 active inference textbook by kristen parr and kazuo and uh

chapter eight is following chapter seven where we discuss discrete state space models um as we know the second half of the textbook is largely centered around actually designing your own active inference models as opposed to primarily verbal descriptions of the theory in the first half

So in Chapter 8, which complements Chapter 7, we turn to continuous state-space models, which the authors state are well-suited for modeling physical fluctuations impinging on sensory receptors and for the continuous motion of the effectors, e.g.

muscles, we use to change the world around us.

We're presented with model examples for the dynamical systems involved in motor control, as well as the concept of generalized synchrony.

And finally, constructing hybrid models for combining discrete and continuous variables at differing levels.

Section 8.2 moves on to movement control.

We're introduced to some notation for the stochastic equations involved in continuous time models.

You'll notice they're a little bit different from those in Chapter 7.

And then we also differentiate the symbols between those of the generative model and those of the generative process, which is also a reminder that oftentimes we produce models whose construction is actually rather similar equation-wise to those of the generative process.

An example for motor control and reflex arcs viewed as descending proprioceptive signals is given, which describes how state predictions can be pulled towards these signals like point detractors.

We also see how action is involved in true state changes in the generative process to bring outcomes closer to what the model expects.

And further, how more complex forms of these equations are used in more typical use cases.

As with discrete time models, continuous time generative models are used to draw inferences about the causes of sensations in the Bayesian brain.

And then some simple nomenclature.

So in continuous state space models, usually it's X is the new stand-in to refer to states.

Y is now for observations or incoming sensory data.

William Newburry, Ph.D.

: There are different ways of doing it, but we also have like, for example, you can use an Omega to to represent.

William Newburry, Ph.D.

: Another aspect like different kinds of fluctuations it actually starts so one of the equations starts to look like a like a linear equation model so like a y equals G of X plus Omega.

William Newburry, Ph.D.

: So kind of like a y equals X plus B or or an error term for Omega.

William Newburry, Ph.D.

: and

There's quite a bit in this chapter, so I'll just give a bit of a summation of the rest.

8.3, we're introduced to different kinds of dynamical systems, which better kind of illustrate the idea of how attractors come to play in continuous models.

We're showing the Lotka-Volterra dynamics, which follow from

predator-prey dynamics researched in, say, ecology or zoology with an example of three different populations, plants, herbivores, and carnivores, showing a kind of oscillatory pattern between their populations, the idea being that carnivores eat the herbivores who eat the plants.

And so they're all kind of dependent upon one another, and they start to show these kind of non-equilibrium, like steady state kind of dynamics that arise over time.

And it's as if it's kind of attracting points that they arrive around but never actually land and settle there.

We also have Lorenz systems.

We're talking about things like criticality.

Then we'll skip ahead a little bit section 8.4 very significant concepts in active inferences generalized synchrony they use a bird song example for modeling.

To illustrate generalized synchrony so the bird song example for modeling communication and multi agent inference problems.

uh they're uh the songbirds uh take turns singing so it's a kind of turn taking problem and it's as if they're singing from the same hymn sheet two birds with similar models learn each other's model parameters over time they start to synchronize with one another over time so their internal states and state predictions come to resemble one another reflecting a primitive kind of theory of mind

The dynamics are modeled by a higher level whose state predictions evolve according to a slow Lorenz system, impact the parameters of a faster Lorenz system at the lower level, again with action, here the birds are singing, to minimize prediction errors arising when no song is heard.

As the Lorenz systems evolve, modeling chaos, the birds' synchronization brings about what the authors call an identical synchronization of chaos.

This also involves sensory attenuation, another very significant concept.

The birds alternate between attention to sensory data and sensory attenuation to carry out actions.

This back and forth with two agents becomes a kind of conversation between them with a generally linear dynamic in their predictions arising in a lower dimensional space.

Generalized synchrony can be applied to a range of diverse phenomena, from the synchronization between internal and external states, such as the agent and its environment, to communication, social behavior, and multi-agent settings, like the songbird example, where agents' internal states start to sort of mirror those of each other.

And then Section 8.5 kind of concludes with discussing hybrid models

which very well could have deserved its own chapter.

But, you know, the idea is you could have models that say are hierarchical for one layer, perhaps a lower level as in figure 8.6 as Daniel has brought up.

The lower layer could, for example, take in continuous data and try and model that and send up whatever kinds of predictions it makes in a different kind of form to a higher level, which then makes some kind of, you know,

Chris Wanner, discrete state space inference about that continuous data and it makes some kind of inference about it, which then is set back down to the lower level to affect its its its decision making and actions so.

Chris Wanner, I think that's a good enough summary to stop there.

Chris Wanner, Now I will open the floor for questions or points of conversation.


SPEAKER_00:
Whenever it was introducing having a smooth space instead of a discrete space, like the last chapter said, it kind of introduced it just like, oh, yeah, this is what you use whenever the other one's impractical.

This is a little bit empirical, but have you guys found that you want to use discrete more than anything, as it kind of implies in this chapter?

Or do you guys find that you just pick the one that seems to be right for the data, and then you run with it?

Is there a preference, or is there a norm that we use?


SPEAKER_01:
Good question.

I mean, if it's in the form of like a personal question, like personal experience, I've largely just worked with discrete state spaces.

I'm coming from kind of a particular like social sciences agent-based modeling sort of background where things are presumed to occur in discrete time steps where, you know, ideally your data effectively is just like, you know,

discrete logs in a spreadsheet or something like that.

And so, like, most of the time, I sort of default to thinking about discrete state spaces.

That said, though, I mean, I've worked with neuroimaging data, I'd love to make some kind of synthetic, like hybrid model that actually pulls in neuroimaging data, and I would absolutely switch to a continuous state space setting for

For that right basically just.

I would probably focus on what kind of data is that that your agent is receiving in the format and then take that approach, as opposed to getting too creative from the start.

yeah.


SPEAKER_02:
Yeah, another practical aspect is that PyMDP only has discrete time setting.

So to use that at this point, you're kind of bound there.

And also separate out the state spaces from the time handling.

So here in this chapter, they kind of bring both the continuous time handling and the continuous date space like they go really well together.

But you also could have like a continuous variable, like just between zero and one, any number in the discrete time.

However, then it's like, if you think about that, it's like the matrix math that we looked at in chapter seven doesn't apply.

So if we just had four locations, but location could have been a continuous variable.

So I think the fullest slash most technologically enabled would be to go with the data type

If you're collecting from an analog sensor, then like EEG or a continuous reading or the continuous location of something.

However, even continuous measurements at some point on digital hardware are getting sliced up.

And so then it's like, okay, how much do you want a coarse grain?

That influences a lot of the handling.

It's just simpler with discrete state space and discrete time.


SPEAKER_00:
Okay, cool.

Thank you.

That kind of reminds me back in college, we would talk about scraping electrons off of CCDs and actually extracting that information and how it all is digital at that level.

It gives me nightmares.

I also wanted to ask, could you talk a little bit more about the Lorentz part after the Volterra thing?

I didn't quite understand that as well as I understood the Volterra explanation.


SPEAKER_01:
And that is rather, I almost feel like, despite how central the bird song example is used in this chapter, I actually think it's the Lorenz system that shows so much more complexity, the kind of complexity involved in some of these kinds of models.

I'll go for it.

Go for it.

If you had something, sorry, I'm just like getting back.


SPEAKER_02:
Yeah.

So, okay.

So the Lorenz is kind of a classic chaotic system.

It's kind of the grandparents chaotic system.

And that was Lorenz studying the weather and saying, wait, even closely related trajectories diverge.

That's the Lyapunov exponent, all of that.

How it's being used in the chapter is to give a buy stability to turn taking.

So it's like here, if all you knew was the X value, you'd find, okay, I'm staying negative,

And then it's like, whoop, now there was a phase change into being positive.

So that like sort of by stable nature of the Lorenz attractor system is being used to be a chaotic switch on turn taking in birds.

um it's also kind of relevant like the birds are not sharing new information with each other so it's not exactly like turn taking in say a normal person conversation it's more like they're just wanting and preferring that the song remains the same that the song is played out and then it's like as soon as it's being listened to and then when the listening

It's like, wait, there's a missing note.

Then the other bird steps in.

That's, yeah.

Go for it.


SPEAKER_00:
Okay.

No, I'm sorry.

I was just going to say that that's what they, now it makes sense that they were talking about the synchronization of chaos.

That really clicks for me now.


SPEAKER_02:
Yes.

this is all the since like 2015 when i think the frith and friston bird song comes out it's been used a lot um this 32.3 or 32 series one of the rare ones with a dot three um this paper goes into more detail let's just look at a few of the key pieces here so

Here's sampling from a Lorenz attractor.

So you can have a continuous, smooth, differentiable, chaotic system, meaning sensitivity to small inputs, highly operative exponents.

And then you could sample probabilistically from that.

So you're getting sampling that's like kind of speckling, approximating that smooth curve.

What is done with the smooth curve?

So is separate out on this landscape of attraction, where's the gradients from higher to lower density?

And then what is the solenoidal flow that goes on an iso contour?

So then this is another key aspect of the continuous time.

In discrete time, to look any time steps into the future, you need to do these explicit model-based rollouts, like actually considering future time steps and all the combinatoric explosions that accompany that.

Huh?


SPEAKER_00:
Could you please remind me what an isocontour is?


SPEAKER_02:
Okay, isocontour is like when you're hiking a line around the hill at the same elevation.

Okay.

So it's just orthogonal to the gradient of steepest elevation is like putting a ruler on the steepest possible, you're on a place on the hill, steepest possible gradient, and then you have orthogonal to that you have around the map.

Okay.

The Taylor series expansion is when you can take, the first order of approximation is just the value.

Second is the slope, the red line.

Third, so as you take these higher and higher approximations, you can approximate arbitrary functions going out.

Here, they couple two chaotic systems.

They have them and then they like in that state space that's described by the movements of them, they show that you can apply that Helmholtz decomposition and say like, what are the circulatory flows

And then what are the gradient flows?

This is what the system looks like.

So this is the two birds, so to speak.

Here's their interface.

So system A and system B.

And then these kinds of plots are verifying like, yeah, some states like the third and the sixth, their correlation drops to zero, whereas other states remain correlated.

So the whole reason why they have Lorenz is just show you can put any smooth curve in the continuous.

It doesn't have to be just like a sinusoid or anything like that.

You can have any kind of smooth differentiable curve and sample probabilistically from it.

So you could generate point data from an underlying curve.

And you could take sampled point data and then regress essentially against and get to a smooth differentiable setting.

Which one of those directions is useful just depends on what kind of data input you have.


SPEAKER_00:
Okay, cool.

That reminds me a lot of very classical machine learning.

Whenever you consider your data points to be, you know, just points on a manifold and you're trying to learn the shape of that manifold.

That's okay.

That's kind of familiar to me.


SPEAKER_02:
Yes.

And so then sampling-based approaches are trying to make a smooth, differentiable landscape from the speckles.

Because with a smooth landscape, you can do gradient descent.

But you couldn't do gradient descent on just a cloud of points.

Yes, absolutely.

Well, not well.

Yeah, you can jump from point to point.

so that's what is getting played with i mean on a bigger scale in the second half of the book but then explicitly in the last part of chapter eight when they come together in the hybrid models is like

And then as Andrew highlighted, like temperature in the world may be a continuous variable, but you could model it with integers or you can model it with a 0.1, like one significant figure of decimal precision.

So then those are all modeling choices.

And that's the kind of infinite branching paths of how you model something.

Okay.

Cool.

Thank you.

It's also in the communication style models.

So kind of birdsong, epistemic communities, like the kind of Twitter hashtag version, Andrew's social science simulation.

What becomes really interesting is like what rails are put in and then what is actually the semantics of what is communicated?


SPEAKER_00:
I'm not going to lie.

Oh, I'm sorry.

Yeah, go ahead.

That's exactly what I was thinking about whenever you said like how you divide up temperature, like specifically how you divide it up seems like it would directly go into how you are going to interpret the results.

So for the bird songs and stuff like that, like just jumping into what frequencies you're naturally attuned to focusing on, what axioms are naturally put into the system, they are going to represent what you are going to more easily represent.


SPEAKER_02:
was a poorly worded sentence but it's going to lead you to learn certain things easier which seems like it would help with the uh synchronization of chaos specifically yeah what will be like forever beyond that model's horizon like if you're only doing temperature by the tens that perceiving it by the tens like one significant figure

then there won't be it won't be able to capture at the one's place whereas if you had a model that was at the decimal point maybe it could kind of do something at a or like what what kind of communication amongst agents

is being set up like if you just say if you have put everything in place so it's like zero means go left and one means go right well then they're just going to be sending ones and zeros and using that to coordinate their movements but then how would you actually make a kind of packet that conveys move left but without putting the rabbit in the hat so it's unfair so that they're just kind of hinting each other what they already know

versus are you trying to explain the sort of heuristic signaling amongst agents that already have a shared semantics?

Or on the other extreme end, are you trying to model the emergence of shared communication semantics from some kind of a simpler substrate?

or like the birds like they already have the hymn sheet so they're keeping up the duty of the song being played

And then you can show really interesting phenomena like in the papers where they'll show, okay, bird one will transfer its parameters to two.

Then you remove one, you add three.

And then two can transfer to three.

So you can say there's a propagation of the fine tuning in this kind of genetic context where it knows the song.

But then that model couldn't be used to address how does the song change within or between generations.


SPEAKER_01:
Yeah.

This is a little... We might have discussed it the last time we discussed this chapter in a previous cohort.

So on page 164,

Still with the example, there's a figure 8.5 that represent like the synchronization and communication process.

And on the left, we have the generative model and the attractor system.

Yeah.

Then on the right, synchronization manifold.

So so the upper graph is supposed to represent like this.

It's a little bit more chaotic.

I don't want to use the word chaotic, but it's a little less coordinated.

But then after learning, there is organization where it's as if, you know, the Y axis, that's the second bird.

X axis is the first bird.

And so there's this kind of secretion such that, you know, it looks like a linear, it's positive correlation.

But what's interesting to me is simply that the values

the value range of the X and Y axis are much larger in the second graph.

And, you know, I would need to know much more about parameter settings, et cetera.

But I was trying to figure out, like, if the birds are like further expanding their exploration of the state space as they continue to learn.

Right.

Because if I don't know why that would expand outward,

And I might just be missing something very simply, but it's just kind of interesting that it's such a smaller state space that they're awkwardly exploring before learning.

And then after learning, it's broader.


SPEAKER_02:
Yeah, also in both cases, it goes further to the right.

like here it never you know it never goes below 50.

I mean it never goes below negative 20 but then it way overshoots um there might be something like a conservation of like inertia so it's like if you had no synchronization you'd have a circle I mean the path would be traced within a circle

And then if you have total synchronization, it's almost like that's kind of like making this ellipse that might project out further.

But what are these really about?

Well, they're second level expectations.

Why is the sensory data?

That's the actual note that's played into the environment.

Level one, I believe, is the vocal cord of the bird.

That's like the warbling of the vocal cord control.

I don't know if it's a two note song.

I don't know if there's any auditory representation of these songs.

That would be pretty fun too.

Level two then would probably represent like who's supposed to be singing and maybe the zero point is the switch over.

So then this represents an extreme belief like that it's plus 60.

like 60 to one odds or e to the 60th or something that the second bird is singing but yeah these these big blocks kind of get thrown out and it's like what are they

Duet for one, kind of the classic.

This gets to the predictive coding question.

So I guess the first layer is the neural control of warbling.

And then the second layer is higher vocal center.

And then it's kind of interesting like,

you know is the audio um is there like a mirror neuron thing where you're responding to your own generation of speech I mean there has to be because you kind of confirm that you're speaking as you expect but then this was going to be my question for you Andrew was why do you think there's sensory attenuation during action

Why not just keep my attention on the sensory inputs while you're acting?


SPEAKER_01:
Sure.

My sense of that from what I've understood, because that's one of the most seemingly counterintuitive concepts that I've found in active inference, at least kind of like in the ways presented in the textbook.

the way i kind of imagine the logic of it in a more colloquial sense is like if i if i am absolutely certain that my arm is exactly in the position that it's in and i maintain that sort of belief uh perpetually it's going to be very hard to change my mind that it is or could be anywhere else right there's a kind of like like by sort of

by attenuating that incoming sensory evidence that it's exactly where it is right now, that allows me to kind of like put on pause, so to speak, the feeding of that sensory information into reconfirming a belief I have that is there, such that now I can actually move it.

What I need to happen is to believe that it's actually where I want it to be, rather than where it currently is, such that I can actually realize that sort of expectation.


SPEAKER_02:
um i don't know if any of that tracks but that's kind of you know in a simple sense like kind of how i've been understanding sensory attenuation yeah i mean i remember we had many fun conversations about getting out of the chair and about disorders of initiating and terminating movement

it's kind of like discrepancy is resolved by changing your mind or changing the world so updating belief states or updating action states if we had complete total rigid confidence that and this also relates to a like a key multiple role for the expectations about sensory input they're both

trying to be veridical like representing sensory inputs otherwise it's just it's just off kilter and and deceptive so on one hand the expectations have to be

um at least tracking real world changes like we're experiencing the visual generated expectations hence the color and the sharpness and the periphery all that so from a first pass like sense making perspective you want that visual expectation to be accurate but then if you had total precision on what that were you wouldn't have the openness or the flexibility to take in new or different information but that's just on the sense making now we get into the action

So then if you had, because there's also this role for expectations in pragmatic value, because they're also the preferences about sensory inputs.

So if we're getting confirmatory proprioceptive input that the arm's in position one, then there's no discrepancy to even resolve.

We expect it where it is.

We prefer it where it is.

So the best, the most vertical and the highest pragmatic policy is to do nothing.

So then there has to be this like transient alleviation of the precision to even enable the possibility that

counterfactual about where the arm could be and the proprioception that accompanies that like for that to even be plausible the precision has to be widened to include it so making things significantly less precise on on reading your incoming sensory data um


SPEAKER_01:
that said, not completely gone, I almost imagined like a sort of intermittent, like, almost like a blinking light is like, you know, as opposed to a completely continuous intake of the proprioceptive signal of where your arm is, it's like, kind of almost have to like, loosely check and make sure it's going in the direction you want it to not to imply that any of this is necessarily like a conscious process.

But

But it's as if you need to kind of intermittently check that it's going the way you want it to and is in the position you want it to be in.

I could imagine that getting a little haywire if the entire process were paused for the entire duration of the movement.

But I might be off base here with how you're describing it.

But I do see this as the mislead end of talking about decision.


SPEAKER_02:
Yeah, I mean, it's so well integrated with fixed eye gaze, which is what the example that comes up again at the end of the chapter, just briefly.

Fixed eye gaze, high precision, and then it's like you're driving on a windy road.

It's like pull off the precision, make the move, but you don't see a blurry set of, you don't see the blur.

It's like you're just not paying attention while the cicade is happening.

And then as soon as it's fixed again, then the precision is re-engaged and it looks clear.

And then shorts from memory kind of like just irons out the gap.


SPEAKER_01:
With your expectations, I suppose.

Yeah.

Yeah.

It's such a, I don't know.

It's such a, almost like a fun concept to like wrap your head around.

Um,

But it does make, I mean, it makes sense to me as far as the other aspects of like the theoretical aspects of the active inference go.

It's like if you just, yeah, if you're fully fixed on a particular belief that you have about, say, the position of your arm or where your eyes are, et cetera, the idea is, I mean, you would be self-evidencing.

You would not act to change like the location that you're looking at.

So it's coherent despite the kind of seeming like, you know, what is that?

How does it work when first presented with it?

And it does track to me.


SPEAKER_00:
The way that I understand it, and please let me know if you guys like agree or disagree because I might be misunderstanding, is whenever I read that, I kind of got the impression that like,

Inside of us, there are multiple systems, or at least this is the way I imagine it.

There's multiple systems.

There's like the proprioceptive system.

There's like my eyes telling my head where my arm is.

And there's a whole bunch of things.

So every time I take an action, there's going to be all of these systems which are engaged.

And these systems want to have a lot of harmony with each other.

So there's going to be constant checks.

Every time there's going to be an action, we want to use this attenuation to make sure, okay, are all the gears shifting as they should?

Is this transmission moving in step?

So all of these systems are going to align themselves with every action.

So there's going to be some model in my head of the world that I see that is going to be built up by the things that I touch and feel, especially through proprioception, through sensory stuff, throughout my eyes, like my retinas actually take in.

I think we went two chapters ago.

about how the eyes get like such small amounts of information and we actually build up the world around that and a few other things which are going to be a system of things.

And then the connection of the systems are going to build up this world model that I have in my head.

And that world model that I have in my head is the thing that we're using the free energy principle with.

That's the thing that we're minimizing a surprise with.

So does that kind of read that like you want to constantly have this attenuation to have these checks, these systems are in stability, in harmony?


SPEAKER_02:
Yeah.

I mean, the free energy minimization process applies within a modality and in the composition of modalities.

So you're right that for a real organism, there's also these cross calibration checks that might do a lot of the work where in a single modality,

it doesn't need to be as resilient within a single modality because you can like double check.

You could look at something and then you could like move it to double, or you could see what it appears to be and then touch it to get confirmatory evidence from a different.

And then if something is showing up coherently across modalities, it's like multiple confirmatory lines of evidence.


SPEAKER_00:
Absolutely, yeah.

And this actually leads into another question I had, which is not so related to chapter eight, but it's in chapter eight.

So I'm going to bring it up.

It's the question of what do you guys think about like having multiple ideas on the same thing, kind of the superposition of ideas and just kind of picking out, just whispering out the one that makes the most sense in this chapter, it talks about the accurate belief that I am not moving.

in order to predict the sensory consequences of movement, blah, blah, blah.

But I find that really interesting because it just says the accurate belief that I am not moving.

And that could mean a few things.

That depends on the frame of reference which I'm putting it.

That depends on the context for the actual place that I want to apply that free energy.

Because I'm not using it right now, but I'm standing on a treadmill.

So I could be moving.

But at the same time, relative to my desk, I'm not moving.

But then again, relative to the sun, I'm absolutely moving.

But then whenever you think about all these other things, there's going to be this kind of like, which place do I want to put my sensory input in?

My sensory input is not just my sensory input.

It's the sensory input with the context of the environment I'm building it around, where the environment I'm building around right now is this funny little idea of I am not moving with respect to what?

Do you guys have any thoughts on that?

Is that as deep as it goes?

Is that just like I read a sentence too hard or...


SPEAKER_01:
This is precisely the kind of, you know, the kind of conundrum that I was trying to express when I first started speaking about sensory attenuation.

You know, it's so, I keep saying seemingly counterintuitive because at this point, there's something intuitive in my brain that's telling me, I think I get it now.

But really, I mean, it's tough with, I mean, to be on a treadmill, the difficulty with that example is that, like,

If you're just standing on a treadmill, let's maybe go with an escalator.

If you're just standing there, you're not moving.

You're moving, and that's accurate.

In a kind of external, you're moving in the world's

you know xyz coordinate 3d world sense but you're not taking action you know so if your mark-off blanket is you and you're not taking the actions to move your body and at least in the way that we're saying that and so it's i mean it's not going to be i don't know if this necessarily plays into that however if you're you know standing in place and you want to move right then like

the idea of sensory attenuation is that you would have to sort of down tune or widen the precision

uh or or otherwise uh regarding your sensory observations of standing in place at least to some you know degree or intermittently or however you know how it's your choice how you want to actually model that uh and try to get at that but however it is the idea is you have to kind of put on pause this idea that you're just standing in place lest you just kind of reconfirm the belief that you're just standing in place you'll

even if you like want to move uh that's not gonna sit well with like the rest of your like so-called beliefs as as an agent right the rest of your beliefs are telling you well both of my legs are neither of them are moving and like in terms of all my senses i appear to not be moving um self-evidencing like you're gonna stay there um you know even if you consciously have some beliefs that you want to move

mean i i think it'd be i think it's interesting to look at that from a kind of you know psychiatric standpoint as well or looking at you know kind of phantom pain or or things like that um but uh so

So you kind of, I mean, I think the way that Daniel put it earlier too with the saccades, I think that was really good actually.

Like you're not actually noticing the blur necessarily whenever you move your eyes, right?

It's kind of like, like, you know, we'd,

Predictive coding that was sort of think of it as like the higher the higher order is just kind of like Descending and put like expectations like kind of fills in the gap whenever you move your eyes around, but you're not Focusing on that player you're really down to any kind of that sensory information You'd otherwise be taken in because you're not focused on all my eyes are exactly and you know position two point two one

uh or 2.1 by 3.1 now they're in 2.0 by 3.0 like you're not necessarily trapping every incremental bit that you move right you're just i'm looking here i want to look here um everything in between is just like a kind of skip and your your mind fills in the blanks so that's not too terribly jarring in that everyday experience right


SPEAKER_02:
Also, the treadmill separates, not necessarily an evolutionarily prevalent stimulus, separates out two senses of I am.

There's I am making movement, which could be proprioceptive change.

So rate of proprioceptive change is I am making movement.

Then there's I am moving distance, which would relate, like you said, a lot to the reference frame.

And then those two might have, it's like if you were in a dream and you felt like you were running, but you felt like you were moving slow, that could be like a gear differential between the proprioceptive that you felt like you were like working harder than the visual that you weren't.

And then that would be interpreted as like a salient differential.


SPEAKER_00:
Yes, absolutely.

And also I think dreams are just deeply fascinating in the realm of active inference.

That's just amazing to me.


SPEAKER_02:
The dreams will be super fun to explore and like on the lucid dreaming.

Yes.

can they control and reduce their agency level?

Like, can they submerge or can they can they control their attention?

Or could they, you know, what aspects of the generative model are being are being modified?

And what are the bounds of the lucid agency?

What are they reducing or increasing their precision on?

And then what, then are there different like subtypes where, where somebody might be able to remember more, but they can't have agency over wanting to remember more or something like that.

I don't know.


SPEAKER_00:
Oh, that's, that's a really, really cool idea.

How much of the, cause you are the environment in that case.

There's no,

the separation between, you know, the self and the environment, you're in a dream.

It's just, it's all you.

So that is such a fascinating angle to go down.


SPEAKER_01:
Yeah.

But at the same time, the way you're processing that, it's as if you're a Marcon blanket instead of a Marco blanket.

You're, you know, you're, you're still distinct from,

you uh the world that your mind's creating i always wonder if there's a if a dream is just some kind of like residue of offline structure learning right it's just there's some kind of mashing around of different you know model parameters or however you want to say it and suddenly you have this visual scene where you get to like move around and there are affordances and at some point you might just notice that you have more control than what you think you do

I don't know, fun conversation we had around dreams always.


SPEAKER_02:
The hybrid model at the end, that was kind of most recently unpacked in the Active Inference Does Not Contradict Folk Psychology.

a nice, careful title, not that it's that it supports or verifies any kind of, but just that it that it isn't wrong.

I'll fix that later.

But just that it's that it doesn't contradict.

And then the belief, desire, intention, folk, psychological model.

And so just like.

Can.

If all things can be modeled

inactive inference then that would include these other kinds of experiential situations and other things so then like then again that kind of reflects what what is it that allows us to describe anything are there things outside of our modeling scope

Or are there just situations that are just empirically very challenging to assess?

Like you couldn't get a verbal self-report from somebody in a lucid dream or just something like that.

Like there's situations where you couldn't get a data point, but you could model where you could get a data point.


SPEAKER_00:
Yeah.

I'm personally of the mindset that our tools can lead us to places way outside of how creative we can be.

Because whenever we're like building these things, you know, we have a very serious, like we have our math hats on.

And I think of physics whenever they found like black holes and stuff like that and the big bang.

And whenever they looked at it, they said, that's completely ridiculous.

There's no way that's true.

And I think that with a lot of tools, we see very similar things where we didn't realize


SPEAKER_01:
will it led to very unintuitive results yeah yeah i uh i'm gonna you know i think it'd be new to apply active inference in certain areas that i'd like to you know apply it to but uh like a follow-up point on that is that you know uh so like

like for centuries, models that really simplify the idea of what is human behavior or something like utility or profit maximizers, you know, and the kind of outcomes model that using computational tools, usually what happens is being very identical to one another.

It's kind of a zero-sum game.

because people are so identical they don't have their own preferences they don't really trade things with one another it's just a very flat simple environment and uh suddenly once you once you include things like like uh you know allow for more complexity suddenly you you end up

having agents who trade with one another in ways that leads to market volatility and crashes and bubbles and all of these other kinds of things.

So what's interesting to me is like, on the one hand, I do agree with you.

I think that these kinds of tools lead to all kinds of like crazy new discoveries that I mean, that's one of the greatest as the combination of like epistemic and pragmatic value there is doing research to make new discoveries.

At the same time, it's like sometimes I think these tools will actually help us understand

already existing phenomena, but now we actually know how to recreate them and now better understand what their initial causes are too.

So just coming at it from kind of the other angle as well.


SPEAKER_00:
No, I completely agree.

Feeling like you get to see something from a new angle using a new tool is actually one of the most satisfying things I think you can experience.


SPEAKER_02:
And now cognitive science is moving that.

It's not just, we're taking a picture of like our elbow that we couldn't have seen.

It's like, oh, that's what my elbow looks like from that angle.

If it's like, that's what my mind looks like from that angle, or if that's a view of a mind that hasn't existed, then that is just so strange, loopy and trippy.

Absolutely.

Yeah.


SPEAKER_01:
I'm trying to remember, there's some famous quote from, I don't know if it was Richard Feynman or who, but some quote, like, if I can't create it, then I don't understand it.

It was like a kind of words by a modeler.

If I cannot create it, I don't understand it.

So trying to understand things.


SPEAKER_02:
Dr. Sutton.

That's where we're at.


SPEAKER_01:
I wonder where I got that from.


SPEAKER_02:
We understand creating the discrete time models.

I think it's fair to say at this time we understand creating the discrete time models more.

Not like some fundamental aspect of them, just that we've had a lot more experience with PyMDP and the discrete time.

Maths are a little clearer.

But then the continuous time, especially with RX and fur, it'll be very cool to kind of flip in and out and make both and nest them and just really start to see like how and where they can be.

We could just do a continuous and a discrete time or state space for like every single situation and just kind of have like two models in parallel and then just recombine them as needed.


SPEAKER_01:
Yeah, yeah, absolutely.

I imagine like, you know, I was thinking about how to model like, for example, agents who do have access to some kind of, you know, some kind of continuously measured resource.

And like, what's important is to be actually actually be able to measure if something is like higher or lower, like actually having that kind of like order, ordinal scale or otherwise.

Because that isn't that kind of an issue with trying to take some continuous value and then bending it such that becomes discrete choices that you also have to have to somehow include the logic that the range of zero to 10 is necessarily less than the range of 11 to 20.

If you have a model that doesn't quite get that, then it might make very odd-looking associations between what it needs to be in 0 to 10 versus 11 to 20.

Anyway, maybe a conversation for another time.


SPEAKER_02:
Well, next time we explore more 8, maybe we'll look at and possibly add some questions.

Eight's getting, you know, eighth inning.

It's after the seventh inning stretch.

Some have left the stadium.

But then we head back into the data-oriented nine and the closing 10.

So, cool.

Thank you, fellows.

See you next time.

Wonderful talking to you guys.

Thanks, folks.

Peace, bye.


SPEAKER_00:
Take care.