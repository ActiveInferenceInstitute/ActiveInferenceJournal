SPEAKER_03:
All right, welcome back.

It's March 4th, the only day that's a command, March 4th.

So as we head into chapter three, does anyone want to begin with any thoughts or questions or remarks about three?

Or where is it in the context of the book?

What do they remember from it?

Or what's a quote that was interesting or just a point to jump in from?


SPEAKER_02:
I personally found it really interesting that the Markov blanket is just an intermediary.

It's just a barrier between two things, the external and the internal state.

It reminded me of my physics classes talking about a ball rolling down the hill in the sense that you could take it from the perspective of the ball and the universe is moving around it, or the universe is still and the ball is moving down the hill.

That freedom for


SPEAKER_03:
that kind of reference surprised me yeah interesting stable hill moving ball and stable ball moving hill that that is that it zach absolutely yeah yeah

That kind of similar topic came up yesterday in the discussion with Lachlan Kent and Anna C. Unica on mental gravity.

on like kind of there's a reference frame where the earth like spaceship earth is the egocentric navigation that's like our visual reality like objects coming closer and then there's kind of a third person sun centrism there's other reference points that can be chosen but that's definitely a very i don't know how would you connect that to markup blanket or to active

Or how does the Markov blanket allow us to do it this way?


SPEAKER_02:
Wait, I'm sorry.

Perhaps I don't understand.

Are you saying they posed that question?

Are you asking that question?


SPEAKER_03:
Oh, just asking.

Like, what made you think about this ball moving down the hill from the Markov blanket?


SPEAKER_02:
Oh, because of the KL divergence.

It's not exactly perfect, but it seems as if you can move X

the actual like external world is going to stay still but the queue is going to be the thing that's changing however it seems to where your choice as the ball as the thing moving down the hill is kind of arbitrary if you assume that the kale divergence is not going to change if you change up the order it was just a thought that i had that i found to be interesting the kind of relative relationship between the two perhaps there's not much to it


SPEAKER_01:
I'm seeing maybe the Lagrange points as being somewhat orillary.

What are those points?

So when you have an orbit, when you have two bodies in orbit, there are certain points where there's an equilibrium between the gravity fields between those two bodies.

So the Lagrange point is actually a place of stasis

And in a way, because it's an absence of both of those bodies and the influence of both of those bodies, it's actually a separate virtual body in and of itself.

So our virtual point, excuse me.


SPEAKER_03:
That's very interesting.

Lachlan, in this kind of mental gravity discussion, which maybe people can look at for more detail, it's like he did discuss the center of gravity.

Those topics came up with the Bayesian mechanics and Dalton's activity of L. Like you have a distribution and then you have a center of mass, center of gravity.

That's like the central tendency of a distribution.

So Bayesian mechanics is kind of

something like a gravitational interpretation of the Bayesian updating process like big distribution heavy prior light low attention uh sensory input not going to move the prior that much and then the um Lagrange point is kind of like the the stationarity if you're there like a non-equilibrium and stationary point

like uh the person in the frog and the uh jumping out of the hand example the textbook they could reach like a long-term stationarity where they were just estimating something that where they're kind of they've reached like a steady point with what their environment was providing so it's kind of like one gravity from the environment one gravity from the um agent with their prior and then also that the the um

P is stable, like the true distribution of temperature stable.

Q is changing.

Beliefs are changing.

Or beliefs are stable.

True distributions are changing.

And that kind of maps to the change the world, change the mind possibility.

Like belief updating.

and fixed belief, world state changing.

So nice, a lot of great comments here.


SPEAKER_00:
Thomas, then yeah.

Yeah, two points.

One is, I found really fascinating the reliance on temporal dimensionality, or a lot of the argumentation here.

So for example,

the argument of basically the hierarchical generative model, for example, in the illustration of sentences, right, composed of words, their hierarchical orientation is based on a nature of duration.

Things are taking longer than others.

That's a really, basically things are taking a rapidness of movement versus a duration, longer period of time.

As the argumentation for like what gives an ordering to things.

I think that's incredibly fascinating.

Another dimension related to this idea of emotional, like we're talking about this kind of psychological aspect of gravity.

There's a line where the idea of temporal depth is directly correlated with psychological depth of a person.

And that's really interesting on a couple of grounds.

One is I'm attached to the ideas of the kind of fact pools and trajectories and policies argumentation that's been presented so far.

They were saw the really fascinating line metaphysics about rational action activity uses a very particular example of a rock a rock is irrational activity of a rock dropping is not rational, because it has it's compelled by necessity to have to go down.

The point versus rational actions there's a composite a power of choice, a power of derivative of either the do X or not do X, so the counterfactual point example we use in Arizona physics is medicine right to heal or not to heal, for example.

Or that actor, basically the agent, throwing the rock or not throwing the rock.

Again, the drawing of rational activity to be that power of choice, of temporal optionality, basically.

I saw some correspondence notes like that.

I've always found that very interesting.

Aristotle talks about that as the derivative, his explicit definition of what rational activity is, which has this kind of potentiality, temporal nature to it.

I thought that was really fascinating.

The other note, it's a classic problem.

This is from the scholastic Aquinas models of psychology.

The chasm between the phantasms and the intellectual activity.

In scholastic traditions, it's considered a mystery.

They don't know what's allowing the conversion of sense data into what's called the phantasms, which I guess in this kind of mapping logic would be the active states.

The explanation is kind of obscure.

Especially, the problem is our sense datum is on particulars.

A particular dog or a particular expression of light, if you're looking at it in a room, for example.

How do we do the cognizant action of universals to get the idea of this quantum that's in front of me is the dog?

There's a whole thing about that in scholastic etymology about that.

What's relevant to this group is

I'm a little unconvinced that this argument of the blanket is solving that problem, I say that because they're what exactly is the cat like so if if there's like three variables that are basically being interchanged with.

active states, external states, sense states, and internal states.

Obviously, I see the correspondence of the variables between active states and external states and sense states to internal states.

Totally get it.

I could see how this maps.

But between the variable x and mu,

What is that, how is that connected?

I'm not, I didn't see anything in the documents, in the literature, so in this chapter so far to give that explanation of how that conversion is happening.

I might be, I may have misread that and I'd completely be a mistake, but this is just in my mind, I just know this is a traditional problem in epistemology of basically the application of universals of perception and cognitional activity.

There's no one really knows how to explain given account for that so that's why the chapter caught my attention and i'm a little profitable about this.

Because they eventually is drawn down to be yeah unit you base of the variables become you and why.

When really new and X are seem to be the question mark of what that is the thing of translation between the sense internal states in the active external states.

How is that happening?

I don't see that happening.

Okay, those are just my general notes.

Again, I might be wildly wrong about this, so I'm happy to be corrected on that more strongly stated second point.

But also that first point on specifically the temporal nature of arrangement of generative hierarchies and synchronicity coming in is a very important factor.

I saw, I read that, I actually had that down in my notes.

Let's see, what was that?

Yes, that the internal states have an appearance of representing external states so mute that is representing appropriately X dot by the synchronicity of the active state in the sense state dot y dot dot dot you.

that's why I got Thank you.


SPEAKER_03:
thank you for the great comments so to the second one first that's a very perceptive comment which is that the um particular partition which is the starting point for a free energy principle active inference and not necessarily a starting point to get to any phenomenological or metaphysical point potentially only as a starting point just to do something empirical so first up

a failure or a delta to a philosophical explanation may just be like a permanent open question for a lot of other reasons so but but just to the kind of philosophical implication part the edges which represent what basically can happen it's basically all the edges can happen except for two kinds of things no backwards action

No backwards perception.

But the other arrows are like, in principle, double-sided.

That doesn't mean in any given situation they're of equal relevance.

Also, this is a map, not a territory.

So like, just drawing a line here between, you know,

the the north and the south side of the city that that that line on the map is like it's literally not describing what the materiality is of the connection so that's going to come back like again and again obviously the map non-territory question so first category thing that doesn't happen

that reverse sensation i don't have my thumb on the scale of sensation or it's modeled like um part of the sparsity of the models that it just can't happen and the other thing that can't happen is that action can't be controlled externally action is under um one the autonomous control this is not like just pick it up and paste it on to like an agent as complex as a human

because as we'll get into like even in a teammates we'll see how limited it can be so this is just a starting point or kind of like the the like one plus one Lego block that then more sophisticated models especially with internal sophistication arise um but the other kind of thing that doesn't happen other than the backwards action backwards sensation is the no telepathy no um telekinesis I guess like

no no communication from the outside except through sensation no action effect on the exit outside out except for through action so that kind of begets this question of like um how but isn't what we actually care about the coupling between the systems which is like the the edge that would connect these two I think the um

It's not what the Connor hand was twenty-six um basing mechanics for stationary processes that kind of comes back to this um Lagrange point.

This one talks about the blanket.

So here's before partitioning the blanket out into incoming sensory and outgoing action.

So this is just the initial Markov blanket concept on the undirected graph.

So both of these edges are bidirectional.

So this is kind of the simpler version of this, where the blanket is broken out into two.

Then...

they study this the locking of the mapping the actual stationarity in the tracking is between the internal and the external state that is one that is the stationarity that is the kind of good regulator like stationarity so it captures both the um intervention of the blanket state

And the I just don't remember exactly which paper has the the Sigma mapping between maybe someone else remembers.

But the Sigma mapping is is the one that describes between the internal and external state.

So there is like an it's like an image or a map, and it maps between the internal and external states.

But it's a but it's a

it's another projection, but this only describes the causal connections.

Jeff?


SPEAKER_01:
Yeah, I just had a thought that I really haven't seen much in the literature until very recently about magnetoreception.

And also, we know that we're also sensitive to gravity, but I haven't really seen that modeled as a sense that we actively participate in as well.

So maybe there's something there when you're talking about so-called telekinesis, where it's actually just a natural phenomenon.

that that that may be because we know for example birds right birds navigate using the Earth's magnetic field we know that um we know that different different types of animals have different sensitivity to gravity fields we know that when for example when we go scuba diving we lose our sense of gravity right um so maybe maybe that's just something to to just stick in your your file cabinet I don't know yeah definitely this live stream from yesterday is a rare Sunday live stream


SPEAKER_03:
like it it links to neurobiology and a lot of other things and we we couldn't think of a linguistic example that didn't convey um that wasn't concordant with like a gravitational like metaphor being applied in a certain way zach


SPEAKER_02:
Hi, so can you say a little bit about, so there's no telekinesis, yeah, but what if control over one specific variable is in like one Markov blanket and another is in another Markov blanket?

Would the separate Markov blankets under some other hierarchical Markov blanket be considered an external state, or would those all be inside of one big blanket that you just call the set of internal states, if that makes sense?


SPEAKER_03:
Yeah.

Though in this like minimal form, they're labeled this way.

They're all relative to each other, and that's all relative to the choice of which one is chosen by the map drawer as the internal state.

So it's not like aspects of the world are like, oh, this one's a sensory state.

Now we can move on.

It's like in this model where this is the internal state and this is the external state, then they have this directionality.

There's an interesting question.

I think it's in chapter two or three.

And it kind of highlights how the textbook talks a lot about generative model and generative process.

But then it has Ali.

And then, but more recently, they just described the entire statistical model as the generative model.

So that's the way that many people talk about generative modeling now.

Gareth J. That, although there are agents that are defined by like the causal connections of the blanket and the internal states so like you can have an agent based model as as you could with net logo or any other kind of modeling framework um.

there's no need to talk about specific variables as being intrinsically like an active state or a sensory state because if it was like a communication setting then the active for one is the sensory the other so as soon as you're even in a two-agent setting or anything that's um like blurring the line with uh basal cognition or anything you just build the program and use the structure of the syntax of the

of the system that you're building the model in like we can look at pi mdp and look at the code as it's kind of rendered for some people that is helpful to see that these are really just the variables that are defined in their relationships um and then when you start linking them up they're they're they if you had another

you know extension it's always a question that that we haven't and I don't know if there's a specific total answer which is like okay it's a wiring diagram like this um and this was the kind of core critique or or line of um inquiry by this like how particular it's like okay the FEP has these properties but

does it retain those properties as you change the topology of the action perception niche?

If you don't have this double-edged arrow, or if you just had around the clock, only one, two, three, four, what properties does that coupling have?

Can that one synchronize across the blanket?

I don't think it's totally resolved.

But it can be explored how different connectivity is.

And of course, different parameterizations within a connectivity relates like different functions.

And especially when getting into internal states that can have dynamic structure.

So you'd say, okay, the temperature in the room is going to just be like, it is what it is.

And then the thermometer and the air conditioner kind of also are what they are.

But we have an agent who can create higher order abstractions about temperature through structure alert.

So a lot of the change happens like already blanketed off from the sensory environment, which I think kind of touches on Thomas's problem slash questions too.


SPEAKER_02:
Awesome.

Thank you so much.


SPEAKER_03:
Pretty interesting figure.

Cool visualization could probably be used more broadly or like something like that, like some using different colors and types.

Oh, here's the mapping.

Here's Sigma mapping.

X, Y, and blanket.

So X and Y, and then sense and action.

Let's see.

past time point, current time point.

So here's just describing X maps to action and itself.

Internal states are action selection and have their own recurrent dynamics.

And like, okay, analogously.

Two, solenoidal coupling.

um I mean we can explore these more in the paper I don't think this is the same queue but I think this reflects that kind of like um kind of like Lagrange point like non-equilibrium steady state something about how they're like you know something like they're circulating in some way three is the blanket condition saying it's this set composed of sense and action summarized with this one node

And then the assumptions, some other kind of conditional independence, like that they all have this one other, here they look more connected.

Here's the sigma mapping.

Here's something else about this, observations or something.

Pretty cool.

I don't know how much more graphical, but the category theory is also taking it very graphically.

This is still within the Bayesian graph like visualization approach, but the category theory work probably has a lot of visualization.

That's also more formal argumentation.

Anyone else, just any other angle, or we can go to some questions.

Also, people can upvote the questions, but let's just look at

Does anyone want to look at a specific written 1 or a new 1 or should we just look at the most uploaded once?

Mark blanket explanation page 43 box 3.

1.

So here's the Markov blanket in time concept, which is sometimes called the Markovian property.

Like as has kind of been discussed before, the last names don't really add any information because there's like multiple Markovs and there's multiple senses and all these things.

So sometimes just using the descriptors more informative, but

the Markovian assumption like it just broadly in statistics like talking about like a Markovian model or hidden Markov model is where the past time step influences the next time step and then that influences the future time step so the past only influences the future through this kind of retained one step present um how can this be true

It doesn't have to be a true fact ontologically about a system.

It could just be a statistical approximation or designed feature like a program.

What if we don't know the present?

Well, that's a super broad question.

um by even sketching out like a few nodes on a piece of paper or thinking a little bit about a specific system like what like what system not knowing what about the presence just sketching that out moves along on that question but the general form is probably pretty big question they define Marco blanket well they define it locally but it's also

prior defined, the set of variables that mediate all statistical interactions between a system and environment.

What's a statistical rather than a non-statistical interaction?

Here maybe in the broader sense, it's saying like, it's about the statistics of the map, not the actual territory.

So we're already in the domain of statistics

another um way to read it would be like it's kind of a probabilistic like across like many similar or comparable examples that it's not necessarily seeking to give like for example a mechanistic account or a constructivist account of how one thing happens it's giving a observational

empirical, numerical approach to modeling like categories of events, just like anyone would doing statistics or AI or machine learning.

Thomas?


SPEAKER_00:
I'm blending questions one and two together.

What's the relationship of hidden states with this?

Because I remember the model from the low roadmap chapter.

There was a discussion about hidden states being part of the basic calculation.

So just my question of not, obviously the point of not having all full information is covered by the fact that there's hidden states that are being accounted for.

As I recall that from the chapter on chapter two in the low road process.

So is that a part of that relationship here?

One of the ways that we can connect the two questions?


SPEAKER_03:
Yeah, like beliefs about hidden states do come into play.

in the variational free energy, and then also in prospective planning and action selection.

Like in this book, anytime you see X tilde, that's beliefs about hidden states are always more uncertain than beliefs about measurements.

So these two forms of expected free energy

expect like also always good to just kind of like threshold that not all things necessarily do this kind of policy selection process like a rock doesn't have to be modeled with a policy selection process or just a trivial one but then getting into this like adaptive action setting then here's like

the uncertainty about how actions relate to world states is always greater than the uncertainty about how actions map onto observations.

Best case, they're equivalent, like in chess, where there's a one-to-one mapping between the observation and the hidden state of the piece on the board.

That's like a fully observable game.

Not say that the opponent's mind is fully observable like but that's the whole modeling process.

Those are very few aspects of it.

But what else what what.

What are the kind of key aspects, do you think, and how maybe it's been approached philosophically otherwise like.


SPEAKER_00:
Oh, yeah.


SPEAKER_03:
Or just like, yeah, kind of, this is a statistical model, but not all thinking on this issue has been statistical.

So how, just as kind of open question, but maybe if you have any thoughts of any pre-statistical thinkers and how they approach like boundary.


SPEAKER_00:
I mean, it'd be normally an argument by definition.

So the idea of an essence is defined by its definition, which is a specie in genera with a differentia basically combination.

If you use Plato's in the Mino, he talks about that using a necessary kind of property to define limit and thus use it to define color and figure and all that.

So those are not statistical probabilities to define basically some observation.

In fact, actually from a more ethics normative point of view, the idea of exemplars is basically the exact opposite, that the best representation of reality is the exemplar versus a statistical average, right?

So that would be kind of the broadest kind of answer, but I agree that broadest difference between a statistical model and a non-statistical is this use of definition and essence from a traditional classic point of view.


SPEAKER_01:
cool.

Really cool.


SPEAKER_03:
Yeah, that's awesome.

Thank you.

This is like the n equals one and the example.

And the a priori, non empirical.

And then the statistical, like, or then the instrumental would kind of which is just describing basically using it as a statistical model.

Like people often talk about this, this is the whole, not the whole, but a lot of the discussion around like,

do we do the organism are they a generic model do they have one are we just modeling it as such that's this instrumentalism realism question I mean if no claims are being made about the territory then you know one can always retreat to just pure map making but then there are stronger guarantees of the once you've retreated to map making

But then that has fundamentally given up certain territory relating to like how individual things happen.

It's just a different kind of approach.

And I know there's some connections with the frequentist and the Bayesian statistics.

And like, how does frequentists view chance?

How does Bayesian view chance?

There's probably a lot to go in there too.


SPEAKER_00:
It just to build on that this, I mean, just by the way, it wasn't like Aristotle did not know about chance.

It was discussed.

It's a no, it was a known thing.

The, I think the big difference just to clear, I mean, this drawing on this point is that science epistome was supposed to be about universals.

Like this idea of kind of do you use a chance to kind of observe and find reality is that's the part where it's probably a huge schism difference.

Um, just from recitalian point, uh, epistemology or investigation.

James Forrest, Norcal PTACC, there's some difference, it was like you know they knew a chance existed and they definitely acknowledge that certain things do apply to that, but it wouldn't be part of the science, it wouldn't be the way you would use to come to find the universal says through.

James Forrest, Norcal PTACC, Random chance.


SPEAKER_03:
James Forrest, Norcal PTACC, yeah yeah and the role of abduction and induction deduction and kind of which ones are given what epidemic statuses.

Does anyone want to go to any written question or, or any new one?

here's no answer but this lagrangian again that's the last the last name is points like it's it's hard enough is this Lagrange point it could be but it might be totally unrelated it could be different person different work or it could be exactly the same but like a point attractor or something like that gives more information okay let's do let's just see how many from the top

Trying to understand better how figure 3.2 was produced exactly what it means.

Okay.

so there are the variables that are going to be used this is kind of the simple blanket setting there's going to be three variables x mu and b so this is just in the underacted graph setting before splitting out sense and action which is what kind of transposed it into the cybernetics context but just one blanket state um and then these are kind of three

projections down there's a cube of statistical outcomes in the um like variables taking on a number in the x y and z direction but it's in the x b and mu directions and then here are three projections from the cube on each of the faces down onto each of the faces um just comparing two different variables

so uh there's a positive relationship between just a linear regression between x and b and then you can condition on b

like you could kind of zero out like you could talk about how many um standard deviations each X was away from the conditioned expectation on B so like this one would be this one would be lower in standard deviations than this one just be it's like the residual from the regression so this is just statistical methods

and there's other relationships that are drawn so these just describe the like conditional dependencies like kind of the this is like a statistical Edge like but not as drawn that is saying the scatter plot has a significant explanatory power um but it's not exactly tested like with the p-value as such but just saying that that's the slope is like the the causal effect

If the causal edge were one, then all the points would just be on a line.

Like knowing one would be like 100%, like we just won in statistics.

Everything's kind of scaled to one.

Everything happens on the zero to one interval.

Eric?

Or Thomas?

And then anyone else?


SPEAKER_00:
To follow up on basic my my question about what what brings the what pulls the X and move out value variable together like this graph seems to actually I had in my notes.

I forgot to talk about that right because what happens is looks like it's using the blanket be to that's the that third graph on the bottom left is the combination right.

of the two very of those two investigations or two measurements and then that fourth graph is the probability mapping of x given uh look at the note yeah probably given the expected probability of mu given b conditioned on you i think i best understand or read it


SPEAKER_03:
Yeah, great.

That adds a lot, definitely.

So like these two describe the conditional dependencies between X and mu, so internal and external states on blanket.

And then here is that mapping.

So it's more variable.

Like let's just say that there's a 0.8 relationship between the temperature in the room and the thermometer, noisy thermometer, 80% good thermometer.

And then there's a 0.8 fidelity between me looking at the numbers on the thermometer.

so just coarsely it's like then there's going to be a 0.64 relationship Sigma de facto like around the horn because of correlations amongst variables so yet there's no direct causal effect between the hidden state and the or the external state and the internal state so that that describes both like the the intermediation and the kind of ultimate correlation

And so this is like structural equation modeling is commonly used like in population health or the earlier, or it's in chapter four.

Here's like some kind of, here's one hidden factor causing one observation.

Here's one, here's lightning.

And then here's the light part and the sound part, two observations from one underlying state.

Here's two causal factors that combine to influence one outcome.

These kinds of Bayesian graphical methods are used from knowledge database systems to health modeling, all these different kinds of things.

If one defines these preferred states as expected states,

Then one can say that living organisms must minimize the surprise of their sensory observations.

Is it that preference is the same as expectation or formally we can use them in the same equation or something else?

Does active inference make ontological claims, e.g.

preference is actually expectation just as heat is actually excitation of molecules?

More generally, is the free energy principle, free energy in physics, just an analogy or is it an ontological circumstance?

Okay, one important thing to note is that there's two senses of expectation.

So in everyday usage, the meaning or the connotation is like what we expect to happen.

Like what we expect will be the weather tomorrow.

However, also when we see the fancy E, the big E expectation of, or the sum of something divided by N data points, which is the same as the, that's also called the expectation.

also known as like the central tendency or the mean so the expectation of a distribution it's like the expected returns but that's a situation that's both about an uncertain future moment and it has to do with the moment with the central um tendency so um

Even within statistics, those are just clear based on the context or what variable is going to play.

Inactive inference, preferences.

So four things that are choosing actions that are exerting their preferences.

Let's look to chapter...

So here's a model where there's no preferences involved.

That helps calibrate some of these statistical questions about like the prior, the relationship between the hidden state inference and the observations through time, through the A matrix and like the B matrix in how the hidden state is inferred to change through time.

But there's no action exerted in this model.

But that brings out a lot of these questions about like observation, hidden state, how things change in the world, all these things like that.

Then that bottom structure is still exactly the same.

And then here's this action selection part.

That invokes this variable C, which is called preference.

It's not a reward function.

It's a preference function that's a distribution over observations.

so it'll again come up in um like chapter seven and before what what its structure is but this is one of the core pieces of active inference models that the preference component of the action selection which is going to come into play in expected free energy in the pragmatic value so this is going to define pragmatic value for that variable

that is defined in terms of observations sensory observations let's return to the question see if there is more to it but that's kind of the key piece they're not that preferences are not about future points preferences come into they're not using that future um unknown outcome sense of expectation

But you could imagine a planning agent that also has preferences about future states or their preferences right now, see right now, comes into play in deciding action that matters for future events.

But that's preferences over sensory outcomes now having influence on action selection.

not like a betting market on what an observation is going to be at a future time point per se

So is preference the same as expectation?

No, but it'll be especially clear when you just even sketch out a table or a list of what is being described, because this is a very general, this is like at the level of definitions of words.

Formally, we can use them in the same equation.

There are situations where it's an equation where you could describe it in English using either of those words, but there's other situations where you couldn't.

So they're not simply swappable.

For that reason, this can't be really described.

Also, I don't know about this heat is actually excitation molecules.

Kind of interesting metaphor, but maybe write more about it and then let's explore it.

Is free energy in physics just an analogy?

Or is it an ontological assertion?

Can analogies be ontological assertions?

I don't know.

There's probably a lot of things to say on that question, but we'll go on.

What's the difference between the terms or does anyone have another, you know, like 10 minutes or we can just look up like a few more of these or anyone can ask or say anything else?

Okay.

What's the difference between the terms?


SPEAKER_00:
Thomas, go for it.

Hey, sorry.

I mean, I...

The idea of the generative model, hierarchical generative models based on time, could we clarify that a little bit more?

Because that does sound like the fact of a hierarchy, right?

Basically, for example, again, the classical model of a chain of being, that thing that entities have a certain ontological reality-oriented hierarchy, right?

That rocks are not the same as animals, animals are not the same as humans, humans and God.

There's a kind of ontological hierarchy given on that.

of some orientation of how things are arranged this chapter seems to talk about and that's the time duration as that ordering property could you get some more clarity about that or just like how strong of a statement is that or what the implications are are that yeah great question okay few pieces on this so um when you brought up the first time let's just say that we're gonna have planning over 100 years


SPEAKER_03:
Tom Preston- One kind of model would be like a model where every year from one to 100 is represented like a timeline or there can be a model where there's 10 decades and then each decade has 10 points and so it's kind of like you could have.

Tom Preston- Thinner models that are nested structurally so that, like the tree sweeps out all the possibilities still.

And so there's multiple different kinds of like hierarchical models that could be built.

You could have, you know, 11s within a 20, within a 30 is like, that doesn't make sense.

Maybe it's not the most statistically optimal, but that's, that's not outside the space of statistical models that you can build because these are just statistical models.

However, also people have gone, I think a lot further in arguing for like time phenomenology.

An example here's from 2,018 in interview with Carl Friston from Alias with Martin Forcher.

So there's a question about that temporal depth.

So we asked basically, well, you're highlighting temporal depth a lot like whether like thickness through time.

So is it enough for a computer program to do it?

And then if an ant colony is able to persist over longer time scales than other things like it, then doesn't it have more thickness too?

It returns to this kind of he brings up a lot of different components.

I think it like kind of remains to a very careful analysis, like which which claims he he brings out to respond to it.

because it includes like questions about meta awareness the depth of the model in terms of the counterfactuals


SPEAKER_00:
Like for example, like, um, using economic model, the idea of, of time discounting, for example, and financial modeling, the idea that a hundred dollars today has more value than that a hundred dollars, 10 years from now, because of properties like inflation, for example.

Um, so yeah, absolutely.

There's that kind of self referencing quality, like kind of agents having self-awareness question, but also this, like this temporal time dynamic has kind of external reality qualities.

if we consider time preferencing of value itself being a variable here or being an area of consideration.


SPEAKER_03:
Yeah, I think the deeper philosophy is to be explored.

Here's what it looks like in the code.

Policy length equals 4.

that's the time depth of that agent four time steps like that lets you estimate how many um how big the policy vector is going to be if there's four times if there's four um affordances or let's say five affordances like up down left right and wait at each time step then policy length of four is just every sequence of those five affordances so five to the fourth

And then that's like tree search for policy, just like early chess algorithms.

And then there's all of these methods that are different.

But the starting point is just like the model defines the temporal depth of the plane.

Now, what does this say about the actuality of time?

That's probably pretty open.

Thank you yeah, thank you, thank you for the question yeah and and then like that is what motivates always okay well now, how about inference on policy life and all the other things like it's just about starting with a model iterating with it, seeing what phenomena, the real system still are are unaccounted.

That that gets for.

Okay, and last minutes any.

Questions.

Okay, let's see.

So that was the first discussion.

Yeah, Eric?


SPEAKER_02:
I'm sorry.

This might be a little straightforward to some, but whenever we were talking about x dot, whenever we were talking about the dynamics of internal, external, as well as boundary states,

Did that mean with respect to the derivative of the actual boundary variable?

Or was that with respect to time?

Now I'm kind of questioning myself.


SPEAKER_03:
Great question.

No, explain it, explain it.


SPEAKER_02:
Oh, I was just going to say, if that would take us over time, we can discuss it afterwards in the questions.


SPEAKER_03:
Yes, I think at a first reading, the dot on these are the derivative of the variable so that the value when it's zero, that is a stationarity of that variable.

So, but the dynamics of the variable are defined in terms of a function of those other states plus a noise parameter, which is what makes it amenable to like all of these kind of stochastic calculus physics approaches, because this like separation into a signal and a noise term on a flow is the basis of a lot of other formalisms.

And it's always hard to also, I think, jump between.

This is like the physics formalism, like physics of particular systems, flows, Lagrangian, all of that.

But then when we're actually doing the modeling in a discrete setting, it's like, where's the Markov blanket here?

because here it's just a partially observable Markov decision process but people have had that for decades so clearly they didn't need the particular physics to do a pomdp so that's kind of an interesting thing to explore too okay next week at the later time second part of three otherwise in

The other cohort, we're in chapter eight, which is continuous time models, but seven is on discrete time.

So thank you all.

See you next time.