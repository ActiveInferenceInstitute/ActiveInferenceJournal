SPEAKER_02:
All right.

Welcome back, Cohort 6.

Andrew, however you want to begin this discussion on Chapter 2, go for it.


SPEAKER_05:
Sure.

Probably pulling up the textbook might be a good move.

I know that this is Week 2 of Chapter 2, so I don't want to

uh reintroduce the entire chapters if you haven't already spent a week on it but i thought it'd be nice for anyone who wasn't able to attend last week to just kind of quickly skim what's going on um so yeah this is chapter two the low road to active inference in chapter one we were introduced to the idea that there's a high and low road to inference so um the low road is more about the um

sort of the what or the how of active inference and as opposed to the high road where there will be more discussion on the why and the why of like, why is this happening?

Why are agents doing this?

How do they survive?

That's kind of the questions getting at here.

This is getting much more into sort of something like the mechanics of the process.

And it picks up with the Helmholtzian perspective, which is a 19th century, late 19th century tradition that just began on viewing perception as unconscious inference.

This idea is picked up more in ideas such as the Bayesian brain hypothesis later on.

in the 20th century and from just an active active inference perspective we're treating not just perception but also action planning and learning all as bayesian inference problems as well as deriving a variational approximation for these problems to overcome intractability problems

with the Helmholtzian tradition, the kind of distinction about this versus other historical cognitive science traditions is that rather than viewing perception as only a bottom-up process of sensory states being fed into, being turned into internal representations of the outside or some such thing like that, instead,

Dr. J. Corey A. perception is viewed as an inferential process that combines top down prior information about the most likely causes of sensations with bottom up sensory stimuli so we actually have this as opposed to.

Dr. J. Corey A. perception being more of an outside in process it's more of a it's it's both right it's bi directional.

We're introduced to Bayes' rule, which is just incredibly crucial to active inference, as well as just many other kinds of probability problems.

I strongly recommend those who are wanting to get into the maths to kind of work on just kind of understanding Bayes' rule almost as like a sort of cornerstone from which to begin.

It can be viewed as a posterior equaling and

a fraction that is the numerator is a prior and a likelihood and then your denominator is evidence and so what can happen is that you can update any of these quantities in order to solve for another quantity right so this this this can be updated over time by taking in new information

that then updates everything else you can update your priors your your posteriors which are your beliefs at the end like at the end of the process um and so what's nice is that we can actually map all of these quantities uh onto the modeling process in active inference it's so a generative model in our case like an agent um it could be a human being it could be

some other biological organism or otherwise, the generative model is just a combination of priors and likelihood mappings.

So priors would be something like probability of X in the textbook.

Oftentimes, notation can also be like probability of S, which stands for latent states or hidden states.

Likelihoods are probability of Y given X. So Y condition on X or in other literature can be viewed as observations O conditioned on S in latent states.

And so we have these other quantities involved.

And, you know, all of those are updated using Bayes' rule.

We have some additional information in that section box 2.1 goes over gives a brief refresher on probabilistic reasoning some role and product rules for anyone who wants a little bit of a who's completely you know coming into this or or maybe took a probability course some.

but maybe the knowledge is no longer there and need a bit of a refresher.

We have a nice example of an agent who confronts a frog or an apple.

And those are kind of two example like hidden states in that particular problem, right?

So the agent has its own beliefs about the probability it will see a frog, that it will see an apple.

It's given a new observation in the moment.

Whatever the thing is it's looking at, it jumps.

And so that's an observation.

versus the S, the X, the hidden states, which are a frog or an apple.

And so those get mapped, those get linked together through the likelihood in Bayes' rule as we mapped a moment ago.

And so the agent basically updates its beliefs about what it's seeing based on the observation it just took in.

Not sure what the thing is.

It could be a frog.

Could be an apple.

Took in a new observation.

It jumped.

It has its own likelihood mappings.

Oh, if it jumped, then excuse me,

yeah, then it will draw inference from there.

So we're also introduced to other concepts like surprise, Bayesian surprise, KL divergence, importance of biological plausibility.

Many of these theories are being drawn from

Neuroscience.

And so there's there's an emphasis on things like cognitive costs of computation.

There's only so much one's brain can do.

And so whenever you consider how many computations would be involved in any example beyond what we just looked at, like two hidden states, apples, frogs.

can imagine in practice immensely more than that are being computed, presumably at any given moment.

So that's where we end up looking at quantities like variational free energy, as well as expected free energy by the end of the chapter.

And this chapter, I would say,

This one's a really good cornerstone for just like really getting familiar with a lot of what's going on in active inference.

It's a pretty lengthy chapter compared to the rest.

So spending some time with the different terms that are all kind of quickly being introduced here is a good idea.

So I guess I'll kind of leave it off there and ask, is anyone curious about anything or more specific questions about what are going on in this chapter?

It is a lot to say again.


SPEAKER_03:
Yeah.

So did the low road and high road come together, came, did it come about like simultaneously or is it like, is it just like worked on like, like separately and then they both just came in at the same time?


SPEAKER_05:
um i do think uh daniel would have a lot more knowledge on this but as far as i'm aware there's there yeah these are coming from various traditions and are kind of a synthesis of different um yeah different traditions or otherwise over time and then a lot of it is kind of uh composed primarily by carl frist and one of the co-authors of the textbook


SPEAKER_02:
Yeah, that's a good answer.

A few other thoughts.

The rhetorical device or the metaphor was introduced by Friston in this like beyond the desert landscape paper.

It's referenced somewhere in the coda.

Any model that exists is going to have a low road, so to speak, because there's always a how, otherwise it's not being, it's just a framework being discussed.

And then any kind of axiomatic starting point is its own kind of high road.

so low and high road can apply different to to probably to frameworks other than active inference yeah um like kind of by analogy like to almost to dennett's cranes and sky hooks and like that kind of bottom up and top down theory and empiricism so i think it kind of describes that generally and then the special thing about the low road

uh constructions in that lead to active inference or like that are represented by the active inference general model is exactly what Andrew said which is that the Bayes rule is embodied totally by the generative model and that describes this like broad class of of constructable but then compatible with in this case free energy principle and not necessarily something else


SPEAKER_03:
I guess my thinking was that it came from two minds or was it from one mind using two different perspectives to think about a solution to the problem.


SPEAKER_02:
I think it was many more than two overall.

Like many people have raised many different good points about how something like has to be to persist, for example, in cybernetics.

And then obviously many people have proposed different architectures and there's multiple ways to do active.

So it's kind of, I think that, you know, maybe get towards higher resolution maps for the low, the high road and other things like that.


SPEAKER_03:
Yep.

Okay.

All right.

Thank you.


SPEAKER_04:
Yeah.

David, then Susan.

yeah so similarly along those lines if you go back to uh the image 2.1 I think it was um between the percentage uh frogs and apples I think it was a comparison so in terms of that likelihood at what point are we talking about the same thing in terms of like if you have a belief structure of you know what percentage of apples believe they're frogs

couldn't you wouldn't it be commutative in the same way where frogs would also have that same belief structure of apples that makes sense in terms of you know the occupying the same space so self-inferential are you a frog or are you an apple your priors still need to be updated in terms of that correct but there would still be that percentage would that percentage not go away despite you know replacing those priors in that sense


SPEAKER_02:
that's very interesting question so in this case this likelihood model is the a matrix in figure point three because it's describing the mapping between okay and apple or and what is the observation so this is kind of an exteroceptive a matrix

however the metacognitive models treat like ascending observations as observations of metacognitive observers so in that case that could refer to like interoceptive

data coming in, interoceptive observations or introspective observations mapping to unobserved states about what kind of thing is generating those observations.

Like, am I hungry given the stomach sensation?

So it could be applied internally as well to maybe some of the things you're talking about.


SPEAKER_04:
yeah i guess i was speaking more also in terms of uh what how it just said in terms of uh you know of one mind or of you know more than two minds as you had mentioned okay thanks susan so as far as um describing the low road and the high road would it be


SPEAKER_00:
incorrect to use a colloquial term like tactical for low road tactical moves anyone think yeah go for it yeah it's an interesting question um i mean you know on the one hand i'm not so


SPEAKER_05:
I'm not so sure if that can be answered expressly.

Maybe that's the kind of thing that I think someone might have to kind of do their own write up on justifying that as kind of maybe like part of the active inference ontology is to view it as tactical.

I mean, if you were thinking to just the context, just within the confines of this chapter,

and you're thinking about an agent being tactical,

I would say the stuff relating actually to maybe planning that we see in later sections that might be more directly linked just conceptually with the word tactical in the sense of an agent is comparing potential sequences of actions or policies that it could take.

It is scoring those based on the expected free energy for each policy.

You end up going with the one that has the lowest expected free energy.

right so that's a kind of like what should i do here are a series of paths i could take here's the one that is least surprising or at least is expected to have the least amount of free energy returned take that path right so it's almost like strategizing now that that itself is still kind of a loose analogy and that you know uh yeah yeah i can see that yeah so let me ask you another question that may relate it relates to it one one thought susan on that


SPEAKER_02:
Andrew, that's a good answer.

Doing the evaluation and the search is the how.

And then there's other attributes of planning that would make up the high road of planning.

And I think the stream to look at is 42.

um so this is also very useful for nested modeling and understanding the composability of the nested modeling so here it was like analogy to strategy tactics control the center as being a higher order simpler less tactical less operational side and then their model of a robot in a warehouse has this finer scale

that is like tactical that described the posture of the robot and then a higher courser scale that was like the location of it now this model itself could be interpreted from a low road perspective because even though this higher order is about the location of the robot it is still constructed so it's probably yeah to look at it or to think about it especially if you


SPEAKER_00:
worked it out yes actually I think I think you know you got strategic and tactical on both ends of action and perception I mean that's what kind of came to mind when he was he was talking and and and so and I don't know if this relates directly or not but when we talk about high road and low road policies that do they do they have distinctly different policies


SPEAKER_05:
no they're meeting an active inference because you only build the active inference shattered model that's actually doing the inference so they just come together in that constructed model yeah i think if it's useful um i've almost wanted to bring this up from an earlier question but uh figure 1.2 in the chap in the textbook which is actually in chapter one page seven um this is just to illustrate like

Gareth J. With active inference in the Center right like these are the high and low roads to active inference like it's not so much that they're entirely distinct.

Gareth J. You know things it's more about conceptually, these are two paths that you could.

Gareth J. kind of take to kind of move towards understanding active inference right so it's like the low road is kind of we're starting from base there and we're starting from.

Matt Kallroos- Statistics numbers calculation valuations so on and that's what this chapter is about meanwhile the high road is more about the free energy principles and now we're more expressly talking about things like.

Matt Kallroos- Like with perception everything we've talked about so far and seeing Chapter two we don't really see so much actually about like an agent trying to survive right we don't we don't quite see that this is just like math.

It's just doing stuff.

It's only near the end that we get mentions of it has preferences that go into planning and things like that.

But really, this is just the mechanical aspect.

The high road will give us much more context and I also think it makes active inference so much more interesting when trying to think about how to apply it to different situations.


SPEAKER_03:
So I guess one of the purposes of active influence is so that we don't have to manually choose the priors, right?


SPEAKER_02:
Choose priors or choose what?


SPEAKER_03:
Because in, I guess, in real life with organisms, you know, there's many hidden priors in your we.

we don't know that lead to, you know, the perceptions and decisions that, you know, they, they have, um, you know, and it'll be too much for us to, to try and emulate or simulate.

Um, I mean, do we still have to generate the prize beforehand for an agent?


SPEAKER_05:
So that is something about active inference that there's been many conversations about this.

could totally branch out much bigger philosophical questions but active inference doesn't necessarily have any guarantee of what a prior should be it doesn't you know it's not very good whenever it comes to origin stories I suppose is one way of stating it it's more about this is how things happen this is why things happen I will say if you're coming from more of like a computational modeling or coding perspective

And you'll see this much later in the textbook in like chapter 7, for example.

But oftentimes what's done is you'll establish some kind of vector of priors over initial states.

So you do kind of have to hard code those.

The thing is, you can have the agent interact with its environment, running trials, and then it can, in fact, from trial to trial, update its own priors.

So it's kind of like once you get the motion moving, it kind of moves on its own, so to speak.

Furthermore, a lot of examples, whenever it comes to modeling, many people just start with uniform priors.

There's not something there necessarily that says you have to have some very,

domain knowledge specific priors or something like unleash the agent with uniform priors.

It doesn't know what's going on, but presumably it will, you know, as the low road mechanics play out, it will readjust its own priors.

It kind of depends on the use case is the simplest answer.


SPEAKER_03:
Yep.

So it can,

It's on price, you know, if it's given, you know, like observations of like RGB, you know, an RGB camera and maybe, yeah, I don't know.

I guess it's just some sort of, you know, sensory input.


SPEAKER_02:
Sure.

Yeah.

It is not.

widely or simply available that just because like you made a active inference agent it's going to do arbitrary like infinite generalization structure learning etc like those are very exciting directions to consider the kind of beginning state and the procedures for agents that could do things like modify the number of observations they received or understand different policy spaces

So that's definitely to be explored and then play around with the different components of that

separately and then bring them together and see how things go.

But if you just look at like a PyMDP tutorial, that is not going to do like open-ended structure learning.

Whereas maybe a certain kind of wrapper around the recent structure learning paper would have that kind of capacity, but then not necessarily like affect or attention or something else that's explored in a different paper.

So it's always very situational which capacities are actually brought in because unless there's like some kind of


SPEAKER_03:
open-ended or metaprogramming element it's not gonna do something that is not described by the generative models form it's is that like a big goal of active influence because I I mean it feels like you know without that it would just be nearly impossible to to emulate you know the same fires that you know living organisms would have because you know we


SPEAKER_02:
organisms would have a lot of fire so i like almost you know from our perspective almost an infinite amount of fires yes and depending on the niche but definitely some people that's similar to

what they might be interested in like developing generalization capacities through metacognitive um nesting or through observers with higher complexity that might be something kind of related to how wolfram is approaching it like with the observer theory and all of that and like computational capacity david


SPEAKER_04:
Yeah, just an observation.

Can you go back to the branch map that you had with Bayesian and Friston?

It was related to what Susan was asking.

It had Bayes theorem at the bottom, and it had active inference at the top, I believe.

It was a tree map.

figure one with the high and low road yes yes all right yes so sorry uh so yeah FEP so I guess just like visually I construct it this way where could you consider this if you linked phase with free energy principle that that would you know cover a surface so in that case if you could do that

would you have bays over free energy or would it be free energy over bays or would it be commutative if you can see the structure there?


SPEAKER_02:
Maybe write it down, like write it out as a question for the chapter and let's return to it, but it sounds interesting.

Yeah, it's outside of the bounds of what we're covering, so thanks.

It's just hard to process in real time, but it sounds interesting.

Okay.

Yeah.

Anyone else?

We can go totally any...

Direction with.

To or look ahead or look to some other part.

one more thought on the um question about where like the priors come from this is coming up later in chapter nine but chapter nine is about integrating real data so that kind of addresses some of the questions that come up about how to integrate with real systems because like it seems like pretty clearly one kind of thing to just write out a model or like sketch it out

just propose it and then it's another thing to connect it to data and and use it in like empirical settings so here's kind of that model that is constructed of like the rat in the teammates and then that's a map of the rat's cognitive territory it's not claiming to be a total description of the rat's physiology just the teammates decision as analyzed a certain way

um so it's the observer or the experimenter who's passing what become observations to the rat but their actions from the scientist and then the admitted actions of the rat are observations for the scientists so it is it is possible to understand like our role around like building the generative model in terms of this kind of laboratory setting

kind of consistent with the origins and the behavioral analysis and SPM.

Like in a laboratory making a cognitive map, then that map is a map of the environments.

And then that was kind of explored in a really,

clear and interesting way by this paper with Ramstead, Sachdeva, Develd, and Friston.

I'll put it in the live chat.

But they make very strong claims about that kind of relationship.

Essentially saying, if this is how you see the situation, then FEP is the best descriptor of it.

So people could dissent from their conclusions or from their setup of the problem or other features.

But it's a very strong claim within this setting.

And then the fallacy fallacy, like the map territory fallacy, is very commonly discussed.

The map of San Francisco is not the actual land or the territory of San Francisco.

And there's like the Borges story about the one-to-one map and how that becomes not useful because it's kind of like wrapped over the real world.

So maps are always kind of motivated by the right core screenings.

And then map territory fallacy is falsely or inappropriately articulating the map territory relationship.

but then they are responding to what they perceived is a criticism of active FEP which is um once it's acknowledged as a cognitive modeling technique then people say well then it is just a map we want the real territory description and we want the real thing

then that's like the fallacy fallacy is their kind of term for the overshoot it's like okay well then it doesn't describe anything because you can just construct whatever map you want it's like yes you can construct whatever map you want of san francisco i thought what so that's kind of interesting angle that they brought out even a few years ago david


SPEAKER_04:
yeah so in terms of that i'm just trying to think of how to how to rephrase it um in terms of the mapping itself i mean obviously like through periodic time change and everything but if you created the map itself like if you i'm thinking in terms of like wave function collapse right if you're if you're observing something directly it will collapse the wave function just you know as a basic overview of it but if it's

Blake Fitzpatrick's iPhone & Oblique to your perspective, but it's still within your it's not necessarily necessarily in your priors or it might have been dissolved from your priors into something else.

Blake Fitzpatrick's iPhone & That's kind of your own inferential map which are not collapsing, but you're utilizing without having to, you know, use that extra energy or any extra energy beyond, you know, just that distilled information that you have.

That's kind of how I Blake Fitzpatrick's iPhone & reinterpreted that.


SPEAKER_02:
That sounds very interesting.

Like there's like a primary sensory mapping that's like dealing with a collapse over like primary observations or something, but then.


SPEAKER_04:
Right.

So instead of like a singular viewpoint of the map and all of its other points, the viewpoint comes from, you know, a different perspective that you're not particularly aware of at the time of your inferential connection to the map itself.

So the map still exists, but you're not using any energy to look at it directly.

So it kind of Mercatus itself over your own perspective.


SPEAKER_02:
Okay, cool.

Add more, but it sounds interesting.

Cheryl.


SPEAKER_01:
Yes.

Hi.

Um, I've been, um,

As you know, I'm new to this, but I am very much interested in the way cognition is defined.

So my first question is, does the active inference then just focus on observable behaviors?

Because so much of what the brain does is implicit and is not going to actually show up as a sign.

something that an outsider could even observe.

So I'll stop with that question before I go on.


SPEAKER_02:
It's a great question.

So I wouldn't say it models only observable behaviors, but rather it is made clear what is observable and what is not.

So you can make a model that's fully observable, like a chessboard, where there is no difference between the observations in the hidden state, like of the piece on the board.

So it's like a fully observable system.

Or you can have a system where the only observation is a binary state, and then there's like very complex internal dynamics.

And another angle on that is from this paper with Bongard Levin.

So here they talk about this like poly computing, which is that the observer.

is doing inference on what kind of computation a material is doing so if like there was an encrypted communication to an observer who didn't know it would look like noise that's why the observer's um situatedness is so important because we we shouldn't just assume that just because it was noise to one observer doesn't mean that there isn't something in that

information stream but it was their relationship of it that it was perceived to be doing just noise generation whereas in a different reference frame that could have other information that can't be ruled out even from from any kind of noise pattern so like i would say it's it's a big philosophical and empirical question how you model

like the priors and the hyper priors and all of this of observers.

And that just like empirically, there are techniques that Bayesian researchers use to address some of these things, like testing the influence of different prior distributions or building the initial priors from empirical data.

But certainly there's a lot of expressivity and probably a lot of complexity to what you're asking about.


SPEAKER_01:
Right okay that that's helpful so active inference does not claim to be the way that this works, but a way.


SPEAKER_02:
Yes, it's totally true.

That's why it's often helpful to differentiate between like, when are we talking about like active inference as is versus with how it can be, which is improving and learning active inference or active inference versus an alternative account of the same phenomena, something that like Ryan Smith and other researchers do do and hopefully will happen more.

That's one kind of comparative mode.

which is a totally valid and important mode because it's important um for certain questions and situations and everything like to know like does reinforcement learning fit better than active inference in this setting there's other times there's kind of epistemic value even with just developing along just an active model but it's always useful to have even really radically different models like is this predictor even better than just a coin flip

And then that helps calibrate it to like more reference points than just parameters within the active model.

Which then doesn't allow you to make points about that in relationship to something that wasn't actually explored.


SPEAKER_01:
Hmm.

So I just have a question about where to put questions.

Because you're right, I think I need to write this out to get a better idea of what it is that I'm even asking you.

But it has something to do with the difference between implicit and explicit.

So where would I kind of think this through?


SPEAKER_02:
right you could add a new row and like add to this table or you could like literally just add it anywhere anywhere okay and then do that like active inference Institute and then it's just if you add it anywhere you type it okay yeah okay great all right thank you but yeah these are interesting questions like does the implicit and explicit map on to observations and hidden states


SPEAKER_01:
correct and then is there another implicit explicit for modeling is that the same one described by the internal oh by the hidden states in the by the observations not necessarily right because at one point I'm going to ask you about neurons and neural development and the the way that the brain actually um in in

in embryos grows together, myelination, how these things, it doesn't seem like a Bayesian thing.

And because they don't all come out different in a normal curve.

Most human beings have their brains developed along the same lines.

And so I just would like to know how active inference

What part does it play as you go down levels of analyses or way up in levels of analyses past just agents?


SPEAKER_02:
All great questions on the development line, like the canalization of development, like the regularity across individuals.

That's definitely a big topic.

Like Mike Levin and other researchers especially have looked at that, like Waddington's epigenetic landscape and understanding how like cells come to have morphology.

And then, I mean, you brought up other things as well, but yeah, those are like, those are all great questions.


SPEAKER_01:
All right.

Thank you so much.


SPEAKER_00:
Anyone else just go for it.

Yes, go for it.


SPEAKER_03:
I thought we have a section for cohort six questions.

Yeah.

When I was waiting for the textbook, I do like to put down my thoughts in there as well.


SPEAKER_02:
Awesome.

Let's look at some right now.

They do all go to the same underlying thing, but if you want it to be tagged with cohort six, thank you for suggesting that you put it in here.

And I'll make a chapter three one.

Okay.

Yes.

What happens if you just update the prior with the posterior instead of using KL divergence?

Do you mean like what happens if you update your belief just like to last observation super simply instead of calculating anything more complex than that?


SPEAKER_03:
Yeah, without using the supplies and I guess this to me kind of feels like a learning rate kind of thing.


SPEAKER_02:
um is it is it like that yeah like um it's also related to kalman filter and smoothing so it's like if we're um getting noisy thermometer measurements i mean we could just update our belief just to the noisiness of the thermometer measurement

and just treat it like perfect measurement of a underlying process, but the dynamics of the underlying process, like we might be able to get a way better model by just saying, well, it's a sinusoid hidden state, and then we're just sampling from it.


SPEAKER_03:
So, I guess it makes sense from that perspective, but from the perspective of, you know, whether it's a fog on apple, you see an apple jump, it kind of feels like, oh,


SPEAKER_02:
like it's um much it could be a much stronger update that oh it is not an apple it's actually a phone now yeah like in this world there's a one percent chance that apples jump so you're totally right that if this was uh apples never jump like a heuristic encoded as um a column in this matrix yeah then it would go 100 so it's like

in practice you can do things like that that truncate or just like start with no noise on a certain thing um zach data yeah great question it's um one that also came up actually earlier so look at the cohort five um video on like reinforcement learning

But the key difference is that in active inference, we're directly talking about the joint distribution and the likelihood of the generative model.

And preferences, so pragmatic value, the way that they come into the picture in decision making is by checking the difference between the preferences and the observations coming in.

Whereas in reinforcement learning, there's a secondary reward distribution that's proposed on top of the observations.

Like 37 degrees body temperature is rewarding, and then you pursue rewarding policies.

Versus in active inference, 37 is expected and preferred, C, and then likely policies are sampled.

doesn't mean any given active model is as good or better or anything at all at all so it's totally situational which one is more useful which one you're more comfortable with and so on but that's the difference i heard someone susan said i heard someone say active is based on causality not correlation

Well, you can use it to study correlations amongst variables.

You could also use it like a Bayesian causal graph to study so-called causation amongst variables.

So then you could engage in the whole, is the causative map, the territories causation, that's a whole area like Mel Andrews and others have explored some of that philosophy.

um and judith pearl kind of and other people delman in the statistical causal modeling question with um dynamic causal modeling like if there's a causal relationship identified in the hidden state between two brain regions in the fmri study does that mean they have a causal relationship like those are questions that there's a lot of discussion on david


SPEAKER_04:
Yeah, along those lines, how would that relate to like a co-causal state?


SPEAKER_02:
Co-causal state could be like, here there's two distributions.

Here's temperature and humidity, and then the output is the dew point.

So two things that jointly cause a third thing.


SPEAKER_04:
Right.

I'm also thinking in terms of like a third that causes still a singular in terms of like a XOR, if you were thinking in terms of like a gated where it's not a choice, but rather it's, you know, you have two individuals making separate decisions.

One person is the patient in the, you know, the case we're talking about here, right.

In terms of the patient being doing EEG scan or something with the doctors priors, you know, at, you know, going down to that point,


SPEAKER_02:
01 right that one percent apple frog you know at what point is it co-causal then does it become a zor or does it become still an overstate or joint co-state very interesting i think look at this guest stream 67 if you haven't which talks about like noisy independent experts and about how like with sensor arrays that having more noisy uncorrelated which is to say noisy

Bruce Sutherland, components, whereas like if all the experts agreed on a test you actually have low precision relative to one with an uncorrelated error profile.


SPEAKER_04:
Bruce Sutherland, Okay perfect i'll check that out, thank you.


SPEAKER_02:
Bruce Sutherland, Someone else had their hand raised.

Okay, just to clarify, we want variational free energy to be as small as possible, approaching zero or negative infinity.

In practice, approaching some number value that's in arbitrary units.

There was like a discussion on the Discord general about this that people could look at.

But like the free energy values itself is going to converge to some value.

James Forrest, Norcal PTAC.

: situation specific minimal value, just like if you were doing least squares like some squares minimization for linear regression the best fit regression would converge to like some sum of squares.

So just a number sum across the squared error differences from the linear regression.

But then that value is depending on the number of data points and the units and all this other random stuff.

Not really random stuff, but it does depend on those things.

So that's why delta free energy and the gradient of free energy is used.

and all of the physics grounding is actually about the gradient around the free energy and that's why it's like incrementally optimizable because there's a surface that gradients on free energy can be taken on so it's like a landscape like a free energy landscape there's an elevation at that point that's like the actual score of like Q and given Y

and then there's the local slopes that are used for optimization and then the simplest optimization heuristic is just go in the direction that it's going to be lower but that doesn't really matter what the absolute value is and then when it's when the change in free energy is zero the model is like converged to a stable point could be local could be global that's the whole challenge with like modeling

yeah this is a great question I think maybe some people have put things people outside of active inference have written about like so-called conspiracy theories in Bayesian belief updating um also definitely some of these topics people have looked at like people can add links but let's continue all the other questions um

generating prayers i mean in practice they're specified by the person who's making the generative model there should be many priors and policies yet to make the quote whole iguana so this is in chapter 10 but chapter 10 is a lot like chapter one so um

This is like in contrast to the research program of like let's study, which is also a very useful research program, but kind of two paths diverging.

One of them is like studying really narrow components, like let's study mechanotransduction in this brain region of Drosophila fruit fly.

And then understand very narrow features very deeply.

but scattered across the animal and non-animal species.

And then in contrast, this alternative holistic approach is model the whole iguana, which is like, how about not just super good on the homeostasis of temperature on the iguana, then we know nothing about this other component, but think totally about it.

so yeah it is very challenging to make multimodal models because it's easy to make a single like an ant colony model with just foraging is easy but then if it's like foraging and nest construction it's hard to do that David yeah so in terms of that wouldn't it wouldn't that come back then to context-free grammars and being able to


SPEAKER_04:
um compute better in that context because at what point you know when you start using frog iguana Apple I mean isn't that giving context to the measurement itself to begin with yeah very interesting question I think in the pedagogical context you could replace it with like any


SPEAKER_02:
other it could be the whole onion so like in that sense it doesn't like it's not a specific just to be really clear um but like yes the reason why that makes sense or how somebody would know what to do is reflective of their I guess I guess that's kind of how I'm seeing it is in terms of like if you remove all the context from everything you're if you have the statistics remaining you could apply it to


SPEAKER_04:
you know, your own inference in terms of, you know, seeing that statistical dynamic amongst two other things that are named something else, you know, that have the same exact end values that might end up, you know, then being, if you remove the context from it, you know, the statistical correlation still exists.


SPEAKER_02:
Yeah.

There's, there's a lot of things that say about that.


SPEAKER_04:
I mean, there are priors, I suppose that you're bringing into that as well.


SPEAKER_02:
boom let's explore it more but yes it sounds interesting all right thanks thomas for the live streams on the noisy experts that was 67.1 67.1 and tqr susan asked is degrees of freedom computed and active and not reinforcement

That is not the case.

Degrees of freedom are in play anytime statistics is being used.

So even if you were to use linear regression or reinforcement learning or neural network or LLM, transformer, any of those statistical settings, degrees of freedom are in play.

ANOVA, t-test, every single statistic setting with the meaning of what they describe the degrees of freedom of.

Not sure if I'm using the right term.

Are these equations proven either mathematically or empirically, or are they useful approximations?

It's a complex question.

In one sense, all of the consistent spaces in math, subspaces and so on, by virtue of the equal sign, they're all describing tautologies.

all of them could be reduced to like one equals one, which could come back to like the axioms of how we are gonna be defining like numbers and equality.

So there's an intrinsic logic to the equations that describes like the fact that it really is possible as for example, Jakob and some other people have done, like with equation 2.5, you really can go

and look how the different decompositions really of free energy and expected energy really are related to each other formally so there's an internal consistency similar to the status of all other like mathematical statistics or like mathematical physics does that provide an empirical validity is a totally interesting question

it certainly does not provide situational validity or adequacy but then it's like a different interesting question does it like what are we looking for when we say empirically and like the live stream from just a few days ago with Ryan Smith um on the empirical status is super relevant as I'm sure the insights that is going to be like later in the week with Ryan Smith

so like and he talked a little bit about like his philosophy background in this stream it was really cool because most of his work is very clinical and like has to do with with like scientifically clinical empirical okay any last question

So this was chapter two, low road, the what slash how.

Chapter three kind of refreshes and picks up on the high road with more about the like transcendental imperatives side that are not necessarily architecture dependent.

So I think like in that, the robotics work of J.F.

Cloutier at the Institute, he's used symbolic programming to develop kind of an alternative low road that's not distributional belief based, but it has the same high road imperatives.

So just kind of an example of how there can be like the same why.

Same teleos, same ends could be done with different low roads.

Kind of interesting topics that like come out through chapter three.

Then having approached Actim from the two sides, chapter four goes into the formal details of the generative model.

That's the central artifact.

That's like what is constructed.

And then chapter five gives a bunch of

studies and reviews on one of the systems that's been the most studied, which is like the mammalian nervous system.

So kind of just showing here's what constructing system specific models and linking them up looks like.

And here's what it looks like in the several decades of study that people have done in the mammal nervous system.

Just as kind of like a review slash jumping off point.

Any last like comments or thoughts?


SPEAKER_03:
I watched a video with Dr. Jeff Beck.

And I'm not sure if I'm remembering this properly, but they were saying there are some people trying to implement the transform architecture within active influence.

Like, does that make sense at all?

Or maybe I'm remembering wrong.


SPEAKER_02:
There's projects that are doing everything from like act inf wrappers around transformers to transform wrappers around LLMs to transformers or neural networks, replacing specific matrices in generative models.

like using a neural network for a instead of just a matrix with the dimensions of observations by hidden states so there's many possible combinations I don't know what back discussion it was but um he did talk with Darius and they like talked about Markov blanket and brought up like a lot of useful questions and comments on this does that address it cool cool yep all right thank you

Bye.