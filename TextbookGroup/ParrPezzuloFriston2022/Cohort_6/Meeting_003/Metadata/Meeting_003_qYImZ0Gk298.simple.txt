SPEAKER_00:
All right, welcome everyone.

It's cohort six and our second discussion of chapter one.

So Andrew and Ali, thanks for facilitating.

Just take it from here, wherever you want to pick up.


SPEAKER_06:
Andrew, would you mind taking the lead on this one?

Sure.


SPEAKER_03:
yeah so i know um yeah absolutely so welcome cohort six this is week two that we're spending on chapter one of the textbook um i'm not sure what was discussed at the last meeting but i thought it might be worthwhile for some of the folks who are unable to attend the morning meetings to maybe just quickly move through um the sections of the textbook um

just to quickly get a bit of a recap or overview.

Yeah, the overview, we began with a nice brief introduction describing what's going to be happening in this chapter.

We already get off the bat that active inference is a normative perspective.

It's starting from first principles.

Move on to section 1.2.

It's some quick explanations regarding the relationships between things like actions and sensory observations.

Specifically, the living organisms can only maintain their bodily integrity by exerting adaptive control over the action perception loop.

This means acting to solicit sensory observations that either correspond to desired outcomes or goals,

such as the sensations that accompany secure nutrients and shelter for simple organisms or friends and jobs for more complex ones or help in making sense of the world.

This is carried out through there's a rather recursive nature to this cycle of action perception loops.

Also, whenever we move on to looking at more complex organisms, there's the assumption that organisms can increasingly use more complex adaptive strategies to adjust to their environment.

section 1.3 still more on um first principles get an introduction to this uh this kind of i don't want to call it ad hoc because i think these conversations have been had before but it's a little light-hearted i suppose this meets versus scruffy's uh division that's made right and so um

scruffies being like, these are folks who will approach these kinds of problems, but maybe from within their particular field or subfield, they don't want to, you know, forego any kind of

kind of idiosyncrasies or specificities to their objective study.

So maybe not so quick to jump to some kind of broader unifying framework to analyze things whenever you might let go of some of the specificity of the problem you're looking at.

J. Sam Hurley, Ph.D.

: In anthropologists will have disagreements with sociologists and so on, about what what defines like a society or culture or otherwise.

J. Sam Hurley, Ph.D.

: Nonetheless, needs are those who do seek unification beyond heterogeneity of brain and mind phenomena.

And that is the perspective that active inference takes.

It does, in fact, attempt a kind of unified framework at looking at diverse scenarios and organisms ranging from human beings and entire cultures who are operating at different time scales of the way, at fast time scales of what they're immediately observing and perceiving, all the way up to slower time scales of planning, learning,

Joe Trumpey, organizing with a group development of institutions and so on.

Joe Trumpey, Section 1.4 is a good overview kind of structure of the book.

Joe Trumpey, um.

1.4.1 active inference in theory.

We get more about surprise minimization.

We're also introduced to variational free energy in the next paragraph there.

they keep it short in describing why we might look at variational free energy as opposed to surprise, which seems like a much more intuitive concept for one to be surprised at unexpected phenomena or observations or incoming sensory signals.

But to put it quickly, variational free energy is basically an upper bound on surprise that is done because computationally,

we find this issue of intractability in computation.

Whenever you break down the math, you find like, oh, in order to actually precisely compute, surprisingly, you would need something like an entire history of an organism's memory, every observation it's come across, every potential hidden state it would estimate.

And you can imagine that the mathematics to that, the kind of formula that would be involved in that would be

just untenable from a computational perspective.

And you can imagine the same thing for an actual human brain, making snap judgments based on its entire history of what it's learned and so on.

So variational free energy is very important in order to overcome this kind of intractability problem.

Everything is somewhat approximate with the goal being to

minimized free energy as much as you can such as surprises also minimize as much as possible.

There will be much more on that in the textbook.

We're only in chapter one.

So stepping forward from that, we do have this nice figure 1.2, which describes how to reach active inference from two different routes.

uh the low road and the high road we can say that the low road is kind of the the how of active inference how an organism maintains its own integrity um just before we started this meeting there were certain uh mentions of autopoiesis and so on like this is the how and and so it relies heavily upon base's theorem uh we work up to

generative models and using Bayes' theorem in order to find relationships between different variables in the model.

That's the mechanics, it's the how.

But from the high road, alternatively, this is where things become a little bit more verbose, which is that this is what and why organisms are doing what they're doing as far as their behavior goes and attempting to explain what is happening here.

they're minimizing free energy.

And so we begin with the free energy principle, right?

So then we can start to understand living organisms or other kinds of systems that we attempt to model using these kinds of tools.

On the one hand, they're trying to minimize free energy.

On the other hand, how are they doing it?

They're doing it through something like Bayesian statistics and mechanics.

We'll get much more on both of those roads to active inference in chapters two and three, each of which are dedicated to

one route, one route each.

Following that, learn that yourself when we look at the structure of the book as it's described from there.

To keep it a little bit shorter, I'll just say the first half of the book is predominantly dedicated to a lot of the more theoretical aspects of active inference.

There will be explanation of other aspects, such as the mathematics involved, although you'll find much more in the details of that math in the appendix.

The Active Inference Institute also, if you view the coda, you'll find references to the maths.

You'll see there's an ongoing project right now.

it's being streamed regarding the mathematics of active inference so there are plenty of resources outside of this textbook um for those who are more interested or or feel like they're not getting a sufficient amount of explanation from the textbook um and then we'll also later in this first part of the book we'll also get references to uh the kind of the more neurobiological aspects of the theory of course it was um

largely initially devised by Carl Friston as a neuroscientist and neurobiologist.

And so all of this is heavily based within preceding work and looking at how to understand the mind and the brain.

So with that said,

I think beyond that, keywords include active inferences of process theory.

We're looking at different kinds of models, discrete and continuous models.

We're getting references to just a variety of things that this is connected to, hybrid models.

I think that might be fair enough.

We're trying to introduce the chapter.

We're already nearly a quarter of the way through.

So I'd like to ask if there's any, are there any questions that anyone has about the textbook or anything that they've kind of been chewing on for some time and you'd like to discuss?


SPEAKER_05:
So can supplies be seen as the difference between expected observations and actual observations?


SPEAKER_03:
Yeah, I'm sorry.

I missed just the first couple of words of what you said.

Could you repeat that for me, please?


SPEAKER_05:
So I was asking, can surprise be seen as the difference between expected observations and actual observations?


SPEAKER_03:
That's right.

So active inference kind of relies upon this idea that you can think about it as

like a set point, for example, in control theory or looking at a thermostat.

So you set the thermostat to a particular temperature.

There's a signal that's being read about the temperature in the room.

Here's what you want the temperature to be.

Here is what it actually is.

And then the idea is you'd want a heating or cooling system that could then take action here.

to bring the temperature that it's reading in line with the expected set point temperature that you want.

And you can quickly see like, yeah, you're minimizing the difference between expected and actual.

It's a kind of classic machine learning perspective or otherwise.

So yeah, you'd be effectively minimizing surprise in that sense.


SPEAKER_05:
Mathematically, it's easier to minimize variational free energy than it is to try and minimize the area directly, right?


SPEAKER_03:
That's right.

The textbook will get much more into that, but that itself is also very much based upon mathematics.

It's not an arbitrary decision, but it has to do with Jensen's inequality.

The idea that...

basically a particular quantity is always necessarily greater than or equal to another one, given certain conditions.

And so that's how we end up there.

Thank you.


SPEAKER_04:
Can I ask something?

Sorry, can you hear me?

Yes.

A lot of things hinge on the generative model that an agent or an organism has and I often wonder it like and yeah when I read further in the book, then I see that the generative model is considered given somehow you you seem to.

it's considered that you have access to it.

So then I wonder, where does that model come from?

Who chooses what model is there?

The parameters seem to be updated through message passing and that kind of stuff.

But the model itself, it's the P and not the Q, but where does it...

Yeah, where does it come from?

Or how should one think about that?


SPEAKER_03:
Before I give an answer, I was just wondering if anyone else wants to chime in on that thought, because it is a big question.


SPEAKER_07:
It's, um, I guess, uh, does the free end.

Oh, I'm sorry.

People are raising their hands.

Uh, let them go first.


SPEAKER_03:
Yeah.

Ali.

Anna, did you have a question?


SPEAKER_02:
Oh, yeah.

But Adley was going to go first.

He was first.


SPEAKER_06:
Okay.

So what I wanted to comment on was a bit unrelated to this current question.

So, Eric, would you please go on about what you were talking about before?

Thanks.


SPEAKER_07:
Oh, I was just going to say, I think is his like how the model is updated.

is is that um is that really addressed directly by the free energy principle or is it kind of like mysterious right because um it seems like uh you kept on you keep on getting this phrasing from uh friston like this is how uh an organism has to behave if you know um so uh um i don't know coming from a neuroscience

perspective i'm not sure we quite understand how it works but we could see that the brain seems to be doing it something like this i don't know if that's a good answer but you know that just makes a lot of sense i mean it's so to i mean come at to come at any kind of


SPEAKER_03:
and this is just me speaking, but to come at any kind of phenomena, I presume you have to, you know, you start with some kind of framework or you attempt to like kind of structure things and then, and then as far as living organisms and the behavior goes, yeah, it's, I mean, all of this is sort of, um,

you know, the map is not the territory.

We're just attempting to understand the organisms, right?

And so active inference is like attempting to provide that.

So just to comment on how you phrased it is like, it's as if it is undertaking free energy minimization.

I think that's a just fine way of saying it.

So as far as defining a generative model, I suppose it depends on what kind of perspective you want to take.

So there are many people at the Institute who are more focused on the modeling and the programming, right?

And so they want to construct like a model themselves.

Maybe it's to simulate something like an agent, it's an environment.

In that case, you would want to rely upon things like domain knowledge in conjunction with a lot of the principles of active inference and Bayesian mechanics, which, as we mentioned earlier, is kind of the low road to active inference.

That's already your starting point.

You already assume that the agent is attempting to minimize free energy, and it's doing it through a variety of principles all

related back to Bayes' theorem.

So that's kind of the top-down normative framework that's being used here.

And then from there, it's sort of up to you as far as how you want to continue constructing that model.

So if there are certain actions that are available to the model or not that it can take.

Adrian Holovaty, What are the different kinds of states, it already expects to see what are the the priors is this is the kind of language that will get more deeply into is the textbook and you know as we continue reading through the chapters.

Adrian Holovaty, From another perspective, if you're not modeling but rather just kind of going through the theory here, I mean it's.

there can be bigger philosophical questions about the structure of an agent and why it is the way it is.

I think that there are many people who study active inference who kind of follow the line of something along the lines of

natural selection or perhaps more nuanced versions of that theory since its initial conception.

And so I don't want to say too much here, but has that at all been helpful in trying to answer the initial question yours?


SPEAKER_04:
Yeah, I see that this is not an easy question, but I understand that there is, for a modeler, there is a lot of room for creative filling in of the structure of the model, at least it seems.

While, yeah, if I get you right, it's not something that is necessarily derived from

a normative point of view or something.


SPEAKER_03:
Yeah, I mean, of course, like with any kind of scholarly pursuit, I mean, whenever there's already work that's been done, whenever there's already secondary literature to draw from and so on, of course, folks will build upon one another's models and

test things out and oftentimes you'll construct one model and then eventually realize like it's behavior, despite the fact that it's minimizing free energy, the way you might've set up the variables in the model, like the behavior it elicits doesn't actually match any kind of real world phenomena that you're actually, you might be attempting to simulate for example.

In that case, it can be a trial and error process.

It can involve discovering something that you didn't expect to find when you realize there's a missing variable here.

Those are many of the general trials and errors of model construction, I suppose.

Thank you.


SPEAKER_02:
um Anna I did want to come back around to you yeah um okay so actually my question um is relevant to the previous question I think um so on page six of the book um there is you know this sentence that I'm going to read it says active inference is a normative

framework to characterize space optimal behavior and cognition in living organisms, and so I was wondering if you could give us an overview or some ideas to start thinking around the

what does a Bayesian model optimize?

And so, because that's the Bayesian optimization is a tool that allows us to think about the world.

And so I'm curious about things like what utilities are optimized in Bayesian models

Is that, are the utilities specific to the phenomena that you're working with?

And if you could connect and discuss, you know, the utility to the probability functions that are used in Bayesian statistics.


SPEAKER_03:
So again, this time I do want to open the floor if anyone has any thoughts on this or otherwise to maybe see if we can get into this question that Anne has posed.


SPEAKER_00:
Go for it, Aaron.


SPEAKER_08:
Oh, well, I had my hand raised from to ask independent thing, but I guess like in terms of I can try to take a stab at this one.

So I would I would phrase it as Bayesian models don't on their own optimize for anything.

But the model itself states the relationship between variables that is assumed.

And under those assumptions, one can, in light of new evidence,

express a posterior distribution which describes one's beliefs.

And I think classically that's like fully separate from how we think about utility utility functions and sort of given my posterior distribution about the world, I can then choose to act depending on what my preferences are.


SPEAKER_02:
Can you can you add to your example like

are you some you know what what is the currency that's being optimized it just I understand that the modeler decides what currency is being optimized so when you say when you're talking about beliefs updating beliefs and so on what are we optimizing there

So how do we translate the natural language updating beliefs?

What does that look like in a model and can


SPEAKER_08:
So one way that I would, anyone feel free to derail me on this, one way that I think about Bayesian updating, and I think the currency that's at play here is units of surprise, so bits or nots.

And I think the textbook doesn't really talk about this.

I feel like other sources are better about grounding bits or nots as a unit for surprise.

But if you were to have a lot of observations from a distribution,

and you want to communicate those to some other party efficiently literally how many bits do you need per per observation that's the kind of thing that is reduced as your model of the source of the data is improved so if you're if you're constantly surprised then you're going to take more bits per observation to communicate what you're observing and if your model is pretty well

explaining what you're seeing then you'll need many fewer bits per observation to to report or communicate um and I guess make maybe communication comes like loaded with some expectations of like between agents but I think also that can be between components within an agent in in some cases but yeah that bits or nats are like actually an expression of

uh perplexity surprise um on average I suppose um that can be uh reduced by updating appropriately thank you okay and I I do want to add to that to um


SPEAKER_03:
I think it was well said, Erin, and pointing to, yeah, it's frequently understated what the units of measurement here are whenever we're looking at something like surprisal.

That said, if we want to look at it in terms of active inference, I mean, some some things that you're going to see are commonalities throughout the textbook is we're going to be looking at particular variables.

And so we're going to be looking at priors, which can be viewed as something like prior predictions, what you think is going to happen.

or is happening, i.e.

your hidden state that you're estimating.

And then you'll have sensory observations, which is new information that's coming in.

This is where we get into things like predictive coding or processing, at least.

where there is a continuous process of comparison between what information you're getting versus what you thought would happen.

This kind of harkens back a little bit to the general idea of

You know here's the expected observations here's the actual ones, like the thermostat examples and it's through kind of starting with basis theorem as a sort of foundation like that's the how of reducing surprise right so.

um given some new information exactly i mean i don't want to rehash what aaron said because i think he put it much more eloquently than what i'm prepared to but um yeah it's to um

to minimize surprise via taking in new information, updating what you thought you knew before, suddenly your predictions perhaps come more into line with what you see out in the environment.

It's much more complex than that, depending on the situation, but that's an attempt at getting closer to describing, you know, here's what we're doing, whatever we're minimizing surprise.

Aaron, you've had your hand up for some time, so I'd like to allow you to speak on your original question.


SPEAKER_08:
Yeah, so one thing that I struggled to get my head around here is the generative model is supposed to generate

all of your sensory data or is like supposed to like go all the way out to like, you know, the, the margins of the Markov, like, or whatever, the things that are coming in from the exterior world.

Um, and how plausible is that really?

Like there's lots of cases where you can see a complicated situation and not be able to predict most of it.

Um, and a lot of the things that the, the details that may be surprising possibly aren't going to be relevant to any action.

Uh, you know, you look at, um,

a whole bunch of birds flocking together.

You don't know where any particular one of them is, but it kind of doesn't matter.

If you look at a TV screen with a bunch of static, you can't predict what color any pixel is going to be in the next millisecond, but you can predict like derived features about a scenario.

And so I'm wondering sort of there should be some intermediate layer that is more relevant for our generative model to populate than like the actual sense data coming in.


SPEAKER_03:
Does anyone have any thoughts on that?


SPEAKER_06:
Actually, this is directly relevant to John Verbeke's relevance realization, because in that framework, it's not possible for an organism to encode every single bit of information about its environment.

I mean, with sufficient precision.

So it needs to only encode only the information which is relevant to the situation which it's dealing with currently.

One way to do that is to encode those information probabilistically instead of deterministically, because in our traditional algorithmic formulation of cognitivism, for example, we deal with well-defined situation in which the parameters are pretty much clear cut and we can encode them with arbitrary precision if you want, but

Uh, in one of the selling points of predictive processing frameworks is that, uh, it's not necessary to, uh, to encode those information with any, uh, kind of precision at all.

Uh, you can even start from, uh, I mean, in principle, you can start from a, uh, from an arbitrary precision or from an arbitrary distribution and then, uh, and then move your way.

in an optimization scenario.

So for instance, you can do a gradient descent on the VFE landscape and reach the extrema or the minimum of the variation of free energy.

And that's one of the fundamental differences between

active inference or predictive processing frameworks from the other traditional cognitivist frameworks.

Because as this recent paper, Naturalizing Relevance Realization shows,

In real world situations, cognition might be fundamentally uncomputable, but we can get around this obstacle by somehow encoding that generative model probabilistically and only encode the information that are relevant to us.


SPEAKER_03:
Yeah, I think there have been arguments that have been made, especially just a brief tangent that, you know, living organisms,

living organisms who necessarily have metabolic rules to keep in place and homeostasis to maintain, there's a tendency to, we can view this as one potential explanation for something like only paying attention to what is surprising and meanwhile trying to put on the back end all the processes involved in

J Lenz, D.B.A.

: Determining like what is the new information here, and what is not the new information do we need to know the position of every single seagull in the flock as it moves by to be able to comprehend that this is a flock of sequels right and.

know that i i think it just it kind of hits on the aspect of of active inference but it doesn't even necessarily have to be active inference like the importance of something like a having a variational dynamic that allows for things like dimensionality reduction and increase from there compressing information and just kind of keeping things a little bit more efficient um


SPEAKER_05:
any case um i would like to give others a chance to ask questions uh how do apologies if i um yeah thanks for that um yes so i guess you know i guess coming from machine learning as well i i tried to i guess

um compartmentalize my my learning here and um you know does active influence if influence use um newer networks gradient descent um and you're like back propagation or is it like a just you know different


SPEAKER_00:
I'll give a quick answer to this.

There's an essential analytical form that is just matrix multiplication.

So what we see in the textbook is just matrix multiplication.

However, a lot of the modern examples have used neural networks as kind of like plug and play for different things.

Like instead of a massive A matrix, you can have a neural network.

and there's also deeper theoretical connections in live stream 51 with takuya isomura this discusses the monotonic relationship between the variational free energy and the neural network loss function

And then Livestream 52 or like anything with Lance DaCosta is super informative about how accelerated optimization methods are used with variational free energy.

Some of which are generally accessible to any variational method.

Others are especially enabled by Acton for FEP.


SPEAKER_05:
Interesting.

So it can use neural networks, but it doesn't need to?

Exactly.

Oh, okay.

Um, Oh, I had a question, but I've lost it.

Um, yeah, thanks for the answer, by the way.


SPEAKER_03:
Uh, Thomas.


SPEAKER_01:
Yeah, I mean, just kind of, I want to build on some of the questions and looking for examples on that generative model point.

I remember the Fristin article on aesthetic experience, order and chaos.

There was a note in it about the nature of absences.

So there's like visuals basically of a square with a piece cut off.

And there was a comment in the caption that talked about absences are meaningful as obstacles or prediction error.

So I think that's really interesting because it's pointing out that a kind of absence

it's almost like where's the grounding, like where's the gender of model come from?

It seems to be, and I relate to the other parts of that essay where it talks about this kind of epistemic promise that our reason we engage in artistic experiences because there's been a promise that we're gonna get some kind of payoff of epistemic basic clarity or resolution of some kind.

There's a lot more nuance in that, but just to kind of build on this point, where is the generative model bottom-up thing coming from?

Absences or lacks, basically, that are pointing out that that's a kind of course, basically, either there's an objective you're trying to achieve that's being hindered, so there's an obstacle in that mode, or there's basically a difference between the prediction model in your head versus the reality of interfacing with it.

I think that's interesting.

It's kind of, that was an interesting, just building point on where potentially a generative model comes from.

Um, also there's other idea, like where I'm thinking in my head, I was looking, reading this piece and where this comes from concretely as an example, it's like, you got a gallon of milk in the fridge.

You think it's full, you're not paying attention.

So you recruit way too much energy.

Boom.

And you pull, you put, you yank it out with way more force than expected, uh,

That difference basically is a surprise, I mean that's what i'm thinking as a concrete example of.

So in that case what's the currency being manipulated years is calories basically to basically recruit the energy required for the muscles to contract and move on that example does he doesn't want to share.


SPEAKER_03:
Yeah, no good points for sharing those.

I mean, yeah, again, with the, you know, expecting a much heavier, you know, jug of milk is another very quick, intuitive example of, you know, here's the difference between what you predict is currently going on in the state of the world.

Like, I have a full jug of milk.

What actually happens is much less milk in there.

You end up yanking it out way too quickly.

There's excessive metabolic expenditure there.

Those are all ways of for sure thinking about it.

And at some point in the textbook, we'll see explanations of things like arc reflexes.

and proprioception where it'll describe things like, for example, you can move on from that example you gave to imagining the arm will adjust, right?

Well, we hope it does anyway.

The arm will not just immediately fling out.

It will maybe halfway through a quarter of the way through the movement start to pick up like, oh, this is actually

not heavy enough to justify this amount of force there'll be some kind of change in the action sequence right like suddenly you're not hopefully you're no longer going to fling it sorry it's kind of a silly example isn't it but um but you see the point it's like error correction right so so there's

Jake Hamilton, What you expect there's what's you're actually observing and then there's an action can then be used to try and correct for that error, which ultimately presumably minimizes free energy along the way.

Jake Hamilton, Eric.


SPEAKER_07:
Um, yes, I was just gonna also add, um, to the question raised earlier that maybe part of the answer to the question about whether, um, the model really has to, um, model every century detail is just that there's, there's actually many models that are working together, um, in, in, in an organic system.

So, um, they don't all have to model everything.

Um,

and uh like if i understand uh provecky's take um i think he believes that like the um task task centered network and the default mode network which kind of take turns right when you're um when you're doing various activities that you know the um the default default mode network is basically

aspectualizing different things in the world and um like offering them up to the task focus network which is selecting some of them um and that they're constantly mutually modeling each other so that the organism can move through a salience landscape

But, you know, we tend to reduce organisms, you know, being conscious creatures.

We tend to think of the model as, oh, it's me, the conscious me, right?

But there's all these, my understanding is that there's all these generative models, right, working beneath

my consciousness um allowing some things to appear in others you know um so maybe that's part of um how it works efficiently because there's many different models hopefully that's coherent


SPEAKER_03:
Yeah, no, it makes a lot of sense to me.

And I think, um, you know, it's where we start to see a little bit more relationship with, um, yeah, as you described break these theories, as well as, you know, if anyone's familiar with like global workspace theory, basically this, the idea that you can have a kind of, uh, like multiple systems within a single system or nested systems.

And, um,

We're already in chapter one briefly introduced to the idea of a Markov blanket.

But as the textbook continues, there will be some more regarding Markov blankets and what what separates in this sense.

Does it also statistically separates a system from another system?

And then also recognizing that there can be nested systems within systems or systems who appear to be working cooperatively together.

And so in the context of a human being, we only need a quick example, someone who is a cigarette smoker or something.

Someone who, on the one hand, and decides to quit.

But sorry, I'll keep it more brief than that.

Someone who decides they want to quit.

top level hierarchical like higher order decision i want to quit i want to be done with this um this is good like that's what i want to do that's a higher order decision on the other hand uh you know give them you know roughly 15 minutes and they start experiencing a craving and as that time continues we have you know withdrawal symptoms and so on um suddenly the person will become potentially more ambivalent um

there are different systems in the body that are expecting that nicotine uh to to come in right um and so you can have like multiple systems within a single human being or a single system that are potentially in conflict with one another cooperating with one another um

It's really about what is the phenomena you're interested in whenever it comes to active inference and applying it as a framework.

What is the system of interest for you?

And you have to decide what defines those boundaries.

What behavior am I expecting to see?

What system am I trying to simulate here?

what potential nested systems are within that broader system.

So at risk of over speaking, I'll give the floor back.

But no, I think those are all great questions and things to think about.

Ali?


SPEAKER_06:
Yeah, I just wanted to add to what

Thomas just mentioned about, I mean, the absence of information, because that's exactly the premise of Terence Deacon's incomplete nature, because in his magnum opus, he develops theory of absentialism, and he tries to somehow derive a kind of teleodynamics based exactly on those

uh what he calls absentials so uh in one of our works with uh mao and i uh which is uh info interaction inference uh we uh we initially developed uh an account of uh the interaction between the organism and the environment based on possibility spaces so uh

very briefly, any system with a given state space would have a form of the possibility space based on the definition or the collection of

It's tendencies and capacities and and the structure of this possibility space can be described or defined as a multiplicity as a delusion multiplicity so by multiplicity.

What we mean is a nested set of vector fields which are related to each other hierarchically by symmetry breaking bifurcations.

and which together they constitute a collection of distributions of attractors which define each of their subsequent or embedded levels.

In other words, the idea of essentialism is already embedded in these spaces of possibilities or the multiplicities because

those are exactly what constitute the structure of the space of possibility as the attractors of the multiplicities.

So in one of our recent papers, we're trying to develop this connection a bit more explicitly.

And yes, I agree that those absentials are

quite essential for any kind of representational framework or generative models.


SPEAKER_02:
so i have a question ali about absentialism and sure uh yeah so how can i ask this um so invasive statistics we are using

probability distributions to get at understanding something about reality.

Can you define essentialism in the context of probability theory or is it completely unrelated?


SPEAKER_06:
Okay.

So, uh, first of all, as, um, as a side note, uh, Terence Deacon actually, uh, doesn't use the term absentialism in his book.

And, uh, he even rejects, uh, this word explicitly, but, um, in any case, in all of the literature related to, uh, incomplete nature, uh, they've used the word absentialism.

So, uh, it's pretty much, um,

widely accepted.

So by essentialism, he means something that's not physically realized yet.

Or in other words, as Duluth would call it, it's not actual, but a virtual possibility of the system.

So, for instance, as a very simple example,

You can think of the capacity of a knife to cut, to kill, or I don't know, to poke something.

All of these are capacities of the knife, which are not always actualized.

They reside as its virtualities.

in its space of possibilities, right?

And the knife may or may not ever actualize these virtualities, but it doesn't make it any less real.

So by absential concepts,

or as a another related term of deacon intentional concepts he means something similar a kind of possibility or potentiality which is not actualized or realized yet but it is real and it constitutes uh i mean the

the internal dynamics of the system as its capacities and tendencies.

So I'm not sure if we can characterize absentialism in terms of probabilities because although it

it can be said that some of those virtualities are more probable than others to be actualized.

But it needs a much more rigorous work on that to derive these kinds of probabilistic landscape over those multiplicities.

But in any case, that multiplicity exists as a

kind of reality of the system or the agent, again, whether, I mean, regardless of whether it actualizes those possibilities or virtualities or not.


SPEAKER_02:
So would it be incorrect to say that

there are states that are virtually or have a potential that they exist in some virtual representation somewhere and and that those states are not uh accessible to us for whatever reasons for to the observer at some point in time

But to me that translates, let's see, I'm trying to see if this is making any sense.

To me that translates into, in order for me to even think about that thing that's absent, I, the observer, need to have some sense of what could possibly be absent.

So I, as the observer, have to also have a virtual version of the thing that's absent.

And would that thing that's absent not have a probability distribution?


SPEAKER_06:
So you see, these absentials kind of reside

in the space of possibility of the system.

But in order to actualize those possibilities, of course, they can be prioritized based on the probabilities of those absentials to be actualized.

As I mentioned earlier, some of those virtualities can occur

with a higher frequency than others.

But this is a very subtle point in active inference, which is to say that you see in recent years, beginning from 2022, there is this attempt to somehow

blur the line between the observer and the observed by showing a complete symmetry and duality between FEP and CMAP, which is the constrained maximum entropy principle, right?

So in other words, what the recent formalism of active inference or rather FEP shows is this complete symmetry and duality

between these two perceptions these two i mean distinctions between observed and the observer so every time we draw a mark of blanket a statistical boundary between a system or between the observer and the observed

it can basically be treated as a kind of arbitrary boundary.

We can switch that observed and observer perspective

And the formalism will help perfectly.

So yes, there is this duality and perfect symmetry between observer and observed, which is shown formally in recent work by Dalton, Sack, Divadibel, and others.

And especially from the viewpoint of category theoretical perspective, it can be shown much more eloquently through those category theoretical formulation as well, such as the work of Toby Smyth and others.


SPEAKER_02:
Thank you.

Appreciate it.


SPEAKER_03:
unfortunately i see we're just about out of time here it's been we've run through the the whole hour and for uh i will say for a discussion on chapter one of a textbook this got rather deep uh very interesting stuff though i'm very happy to hear everyone share their their thoughts and uh i would you know of course everyone here is coming from their own distinct perspective and

and interest, so I would say if you are coming from a certain angle, certainly don't hesitate to ask questions.

I think that's what will kind of pull you into active inference a little bit more quickly in a way that is a little bit more fluent for a lot of people, because it can be a lot of material at one time.

But thanks, Ali, for facilitating, and you're very

your very thorough responses.

I always end up learning something new about active inferences history and sub theories that makes me want to read more.

And thanks everyone else for attending per usual.

There will be another meeting next week.

We'll be going over chapter two, which is where we'll get into the low road to active inference, a lot more on Bayesian statistics and mechanics.

get maybe a clearer view of what optimality means or optimal behavior and inference.

We'll also get a couple of perspectives on things like different time scales, such as inference at a very quick moment by moment scale, all the way up to planning and agents who actually have the capacity for planning their next move or constructing goals that will take a series of steps to carry out, not just taking a breath in the moment because you need it.

um daniel do you have anything to to add or announcements no great all right thank you everyone farewell thanks everyone thanks everyone bye