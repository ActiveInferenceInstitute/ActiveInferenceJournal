[
  {
    "start": 2.107,
    "end": 9.516,
    "text": " All right, well, thank you for that very interesting discussion on latter textbook groups.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 9.576,
    "end": 14.022,
    "text": "I hope that we can continue from that first few minutes that we had.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 14.783,
    "end": 19.068,
    "text": "Okay, this is the last recorded discussion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 20.47,
    "end": 22.512,
    "text": "Feel free to come next week for...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 23.504,
    "end": 28.473,
    "text": " The other cohorts also unrecorded discussion will again we'll kind of like look over what has been written.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 28.513,
    "end": 35.426,
    "text": "Think about what we want to do with textbook group and everything kind of continuing so.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 35.446,
    "end": 36.508,
    "text": "But here's Chapter five.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 37.91,
    "end": 41.597,
    "text": "And or like anything on the first half of the book.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 49.272,
    "end": 68.357,
    "text": " Like anyone could go any part from five or first half, or we could look at the questions and look at which ones or spend a minute and upvote questions that we're interested in and then look at which ones have been upvoted a lot, but not answered for the first time.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 72.402,
    "end": 73.423,
    "text": "Sure, questions sound good.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 76.323,
    "end": 105.621,
    "text": " okay in chapter five anyone can just people can be clicking the thumb and then we'll just go in these or raise your hand and like go for anything else but anything in chapter five that anybody wants to go to first um table 5.1 with the neurotransmitters um i think it's page 98 yep that's the one",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 107.069,
    "end": 125.28,
    "text": " So is what we stated here so much saying that dopamine is increasing the precision of the brain's, I guess what the brain understands of policies.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 130.39,
    "end": 137.461,
    "text": " So it's saying these policies are more precise if a neuron or a group of neurons is getting more dopamine.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 142.589,
    "end": 142.889,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 143.43,
    "end": 157.832,
    "text": "So to kind of like pull back on the table, this is going to be linking specific molecules and roles they play in mechanisms in the brain to specific variables in generative models.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 157.93,
    "end": 184.512,
    "text": " then the table is like describing well here's some sheer anatomical facts these are empirical measurements and then also describing and citing some studies that might have studied um the relationship between like the activity level or the amount or the signaling of some neurotransmitter to some aspect of a generative model",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 184.897,
    "end": 195.109,
    "text": " And then that could be more correlative evidence, like the size of a brain region or changes in the functional fMRI.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 196.27,
    "end": 203.78,
    "text": " Or it can be more causative with like giving a manipulation and then showing the two things start changing together.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 203.8,
    "end": 212.932,
    "text": "So it doesn't mean it's the only function it does or its whole role or anything, but it's just saying these parameters are being identified are not just like weird statistical artifacts.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 213.413,
    "end": 215.856,
    "text": "They map on to like natural components of behavior.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 218.119,
    "end": 223.847,
    "text": "So it's proposing to some connection between, you know, dopamine and the policies that the brain is building.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 229.43,
    "end": 240.842,
    "text": " David Price- there's to really look at this in the dopamine case, thankfully, which is actually cool because most most things like the kind of case for pluralism has not always been.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 241.883,
    "end": 245.928,
    "text": "David Price- written out this is okay we'll just go in here, but in this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 249.632,
    "end": 252.855,
    "text": "David Price- This papers they specifically are looking at the.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 254.962,
    "end": 257.206,
    "text": " mesocorticolymic dopamine.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 257.807,
    "end": 273.814,
    "text": "So this is something like what is shown in the figures in chapter five with dopamine controlling the balance between the habit-based policy selection and the expected free energy-based policy selection.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 274.115,
    "end": 280.961,
    "text": " So that's kind of, that's the computational function that is being posited in the model that's in the chapter.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 281.021,
    "end": 287.568,
    "text": "And it's what it's being identified on for, um, in the table.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 289.089,
    "end": 300.78,
    "text": "And then this paper is like philosophers of biology and saying, well, people have modeled dopamine in terms of the hedonia, the salience and the reward prediction error, basically free energy.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 303.055,
    "end": 325.941,
    "text": " and they say well there's already evidence to support pluralism for that system but you could make probably analogous arguments like every brain region every gene Etc but that's the whole thing with the maps and the territories it's like okay it's a subway map of this city but it's not an everything map",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 359.401,
    "end": 359.842,
    "text": " Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 359.862,
    "end": 366.49,
    "text": "Any other random part of five or one of these questions someone wants to think about?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 369.634,
    "end": 369.894,
    "text": "Sure.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 369.914,
    "end": 373.819,
    "text": "Just to follow up on that last question and point really quickly.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 373.839,
    "end": 376.162,
    "text": "I think there's a good example.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 376.222,
    "end": 377.644,
    "text": "This is an older paper.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 377.664,
    "end": 383.772,
    "text": "I think it's called Dopamine Reward Learning and Active Inference.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 384.258,
    "end": 391.674,
    "text": " it looks at a lot of aspects of dopaminergic function in the brain as interpreted through active inference models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 392.336,
    "end": 397.667,
    "text": "One I think is kind of particularly interesting is freezing of gait in Parkinson's.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 397.688,
    "end": 403.38,
    "text": "I'm not sure if folks are familiar with that, but long story short, people with Parkinson's sometimes get this thing where",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 403.36,
    "end": 410.014,
    "text": " Like you get up from a park bench and you try to walk across the lawn and the person will kind of freeze.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 411.016,
    "end": 416.627,
    "text": "And there haven't been really great explanations about what that's about and why it happens.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 417.552,
    "end": 428.363,
    "text": " But one of the things that I guess kind of emerges from this paper, if I recall right, is the idea that there are basically a bunch of different action policies that you can take to navigate the park.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 428.403,
    "end": 430.305,
    "text": "You can cross the space in a number of different ways.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 431.166,
    "end": 441.417,
    "text": "And basically, if you have low dopamine levels like people do in Parkinson's, then you can have a low potential precision that's assigned to any one of those given action plans.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 441.397,
    "end": 452.603,
    "text": " And so with no ability to sort of assign high precision to one plan or another, you have kind of this series of low confidence plans and the brain can't kind of like select one on that basis.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 452.664,
    "end": 453.846,
    "text": "And so you kind of just lock up.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 454.849,
    "end": 458.798,
    "text": "And there are like techniques that people with Parkinson's learn to do where they learn to like",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 458.778,
    "end": 473.648,
    "text": " intentionally choose like okay I'm gonna walk in sort of a crescent pattern around this area so they basically like make a different decision that kind of like jolts the system out of out of the kind of lock state that it gets caught in and you know ultimately I don't know about like",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 474.269,
    "end": 477.715,
    "text": " Are there experimental results that really support this kind of thing?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 477.735,
    "end": 482.984,
    "text": "I'm not totally sure, but at least I found it to be a really interesting way to think about this kind of thing.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 483.004,
    "end": 491.518,
    "text": "And I haven't found another sort of explanation that I think is sort of equally as elegant.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 492.376,
    "end": 493.439,
    "text": " That's kind of interesting.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 494.182,
    "end": 504.715,
    "text": "From an app perspective, it's like using the brain's plasticity to overcome just errors in its own system as it ages.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 508.711,
    "end": 510.093,
    "text": " Yeah, great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 510.774,
    "end": 511.295,
    "text": "Comments?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 512.877,
    "end": 525.634,
    "text": "Just in terms of research agenda, this is like a preliminary stage where you can take the extant data and then make a model that fits the variance patterns better and or has fewer parameters.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 526.375,
    "end": 529.96,
    "text": "So it's a better model just by the normal criterion.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 530.564,
    "end": 533.568,
    "text": " So that's a computational one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 533.928,
    "end": 540.376,
    "text": "And then with that model, which can be argued to be like better or simpler than alternatives.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 540.976,
    "end": 553.691,
    "text": "It's like, well, that's the leading candidate to then design experiments that would differentiate and maybe even let the model, um, show like new predictions or explanations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 556.535,
    "end": 558.377,
    "text": "But it's interesting, like it's 2015.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 559.893,
    "end": 575.032,
    "text": " And it's a very similar figure to figure 4.3 with some more details, including about that gamma in the table.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 577.935,
    "end": 587.487,
    "text": "Well, so this is kind of interesting, like without the textbook seven years before the textbook, every paper has a lot of the background equations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 590.892,
    "end": 606.468,
    "text": " Whereas now it's clear which parts are referenceable to just the textbook, and then which parts still might be highlighted in the paper, like the focus on the policy and the role document policy.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 614.276,
    "end": 615.778,
    "text": "Yeah, interesting paper.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 617.56,
    "end": 618.621,
    "text": "Maybe it's cited in here.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 621.487,
    "end": 629.524,
    "text": " Maybe it's... That's this one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 632.55,
    "end": 634.333,
    "text": "Or maybe it's another one by the same authors, right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 636.378,
    "end": 637.039,
    "text": "Or no.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 637.059,
    "end": 637.921,
    "text": "This is only three of them.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 638.282,
    "end": 639.023,
    "text": "Anyways.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 645.668,
    "end": 651.595,
    "text": " Any other just random thought or upvote questions if you have the coda up?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 683.35,
    "end": 695.115,
    "text": " This is kind of like the theory theorizing around like relationship between the function and the anatomy for the brain or the function in the genome like there's kind of a simpler.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 696.428,
    "end": 721.778,
    "text": " one gene one protein one function or like one in an anatomical region one function one computational role but of course that's not how any biological system is so it's kind of a straw hypothesis to merely disprove",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 722.99,
    "end": 732.865,
    "text": " Because there's so few things that are with such straightforward causation, but those are the interesting ones in some ways, but they're also not representative of other cases.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 757.634,
    "end": 762.284,
    "text": " Here's one Mike Levin paper to more recent and Josh Vanguard.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 767.075,
    "end": 772.808,
    "text": "I'll just copy it in, but it kind of talks about like the overloaded nature of the biological systems.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 783.554,
    "end": 790.285,
    "text": " Whereas a computational system, you could engineer it to not be overloaded.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 790.325,
    "end": 808.515,
    "text": "Like you could make a, which is kind of part of the reason why they don't capture those biological dynamics because the Bayesian graph, like it's just kind of not overloaded among other things.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 817.996,
    "end": 818.723,
    "text": " Thank you, Cheryl.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 820.924,
    "end": 821.307,
    "text": "Welcome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 848.81,
    "end": 868.05,
    "text": " yeah one book that speaks to um what a little bit of what you described like the amygdala and like social events is um this book by helen longino about some charged slash relevant topics and how pluralism",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 870.443,
    "end": 895.236,
    "text": " gets complex but also like very important you know billboards it's in our dna and all those kinds of things those are part of the cultural milieu that the scientific facts even to the extent that they're empirical slash factual those are mobilized and that's the whole discussion got it",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 900.278,
    "end": 911.691,
    "text": " And she talks about complex systems and like developmental systems theory as a way to link different scales of analysis so it's kind of like Mike levin's work like if you could look at the morphology of.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 912.832,
    "end": 925.527,
    "text": "organism growing and then over slower time scales, you have like structural factors, but they're having a different time scale so neither like the development of the organism or struck like structural slower factors.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 928.122,
    "end": 930.104,
    "text": " could explain what the other one does.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 933.067,
    "end": 953.708,
    "text": "There's, there's a lot more, I think, in that direction, that would be awesome to explore on, like kind of some of the broader tangents like Ali and the other people bring up with a very contextual but very rich points about like reductionism and holism.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 954.869,
    "end": 976.202,
    "text": " pretty well all these other more psychological things too but also a lot of scientific um epistem slash discussion Susan um yeah you know it's mentioned kind of um offhand",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 976.84,
    "end": 983.407,
    "text": " in a number of places as far as the cybernetics and the viable systems model.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 984.208,
    "end": 992.117,
    "text": "And yeah, it'd be hard for me to understand this if I didn't have a good understanding of cybernetics.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 992.577,
    "end": 1006.813,
    "text": "And yeah, there's a, to your point about it being reductionist, Cheryl, there's, yeah, you do kind of hear that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1006.979,
    "end": 1009.302,
    "text": " in terms of how people are approaching it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1010.083,
    "end": 1014.089,
    "text": "Um, and, but the same thing I think is, is true of cybernetics.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1014.129,
    "end": 1024.384,
    "text": "The original cybernetics was very mechanical, um, but they've since, you know, embedded it and infused it with, uh, with more of a, of a nature's approach.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1024.444,
    "end": 1028.07,
    "text": "So it's, it's kind of everything's evolving.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1028.17,
    "end": 1035.58,
    "text": "So, you know, if we look at it through a static lens, we're kind of already gonna be stuck because it's all moving.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1035.6,
    "end": 1036.682,
    "text": "It's all flowing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1037.135,
    "end": 1046.464,
    "text": " And that's kind of where we're trying to grasp something, but it's flowing away from us, which I think is fascinating about the topic.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1047.004,
    "end": 1067.023,
    "text": "But I also think that understanding the different levels of ambiguity and abstraction is hard to grasp with that in terms of how do you contain the conversation to go deep when there's so many avenues to jump on",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1067.307,
    "end": 1087.729,
    "text": " Um, in fact, a question that I had, um, in terms of Markov blankets, um, which, uh, it might sound like I'm going off on a tangent, but there is actually connection is, is there in Markov blankets, um, what would be the, uh, the interdependencies?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1087.79,
    "end": 1097.28,
    "text": "How would you, how do you describe the interdependencies or are Markov blankets essentially",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1098.087,
    "end": 1124.837,
    "text": " boundary interdependencies anyone want to give a thought on that okay one way to think about it maybe narrower or whatever but",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1125.948,
    "end": 1130.334,
    "text": " Since the base graph is a causal graph, it's a map of determinants.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1132.517,
    "end": 1139.166,
    "text": "Complexity around what is a determinant, but that's how variables determine the influence affect each other.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1139.566,
    "end": 1141.129,
    "text": "That's what the edge on the console graph is.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1141.89,
    "end": 1144.573,
    "text": "So what's there are the determinants.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1145.314,
    "end": 1148.919,
    "text": "But what isn't there, which is what makes the internal external state separated.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1148.959,
    "end": 1154.807,
    "text": "If they had an edge between them, that would be, then that would change the shape of the graph.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1162.027,
    "end": 1164.055,
    "text": " Another thought related to this is like,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1165.3,
    "end": 1184.237,
    "text": " This may be a very coarse first approximation, but just to reduce some of it to categories, a lot of the questions relate to questions about modeling at all, as well as some other very general topics like predicting at all, acting at all.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1185.759,
    "end": 1192.725,
    "text": "And then there's also finer scale questions about how active inference formalism is related to reinforcement learning.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1194.173,
    "end": 1203.194,
    "text": " So those are very different contexts, but one that many people in the textbook group are totally more than adept at.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1203.214,
    "end": 1204.036,
    "text": "So that's part of the fun.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1204.056,
    "end": 1211.052,
    "text": "Also though, that may be harder context shifting, but it's also a real context shifting",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1211.926,
    "end": 1231.017,
    "text": " So it's not to be like removed, but knowing how to approach more of this, like what can numbers and maps have to do with systems at all, which is very helpful to have people with some shared background on.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1231.077,
    "end": 1233.681,
    "text": "And then also.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1235.18,
    "end": 1264.09,
    "text": " some will then get to more of a level of resolution of differentiating active inference versus adjacencies in like perceptual control theory reinforcement learning everything that's basically discussed in chapter 10 like from a theory perspective and then also alternative mathematical models for like the mammalian nervous system in chapter five because it's easy to be skeptical and bring up many general points about the models presented in chapter five",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1264.677,
    "end": 1277.213,
    "text": " And it's also relevant if one really wants to go into it to contrast not having a model versus not having a model, but what are two models for the computational role of dopamine?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1278.154,
    "end": 1285.643,
    "text": "And then which one of those are more plausible and tractable and general and so on.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1285.663,
    "end": 1291.731,
    "text": "But that's a very different discussion than should we make a map of policy selection at all?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1293.23,
    "end": 1297.035,
    "text": " or what could ever be said about a biological organism with math.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1309.171,
    "end": 1314.759,
    "text": "This is like one of those kind of philosophy quotes that ends up being very influential for a very long time.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1314.799,
    "end": 1319.946,
    "text": "This quote by Kant, there will never be a Newton of the blade of grass.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1324.55,
    "end": 1326.415,
    "text": " People debated still debate.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1334.896,
    "end": 1335.117,
    "text": "Cool."
  },
  {
    "start": 1355.65,
    "end": 1362.087,
    "text": " Very good discussions very great points and things that I think a lot of people could enter into though very deep within.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1362.147,
    "end": 1366.86,
    "text": "philosophy texts and kind of niche.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1369.767,
    "end": 1370.79,
    "text": "But this sounds awesome.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1385.873,
    "end": 1396.565,
    "text": " I mean, like even just the title of the paper, and we can read later, but I mean, this is kind of this is philosophical context for any mathematical work like Act Dymph.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1406.237,
    "end": 1406.537,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1410.582,
    "end": 1414.446,
    "text": "Any other part of five or the first part of the book or like any other thoughts?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1415.54,
    "end": 1416.923,
    "text": " Or I mean, what else?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1428.206,
    "end": 1431.793,
    "text": "I had a question about the degree to which",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1432.887,
    "end": 1448.972,
    "text": " Their description of the math being implemented in the actual neural system implies something about what I would normally think of as",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1449.172,
    "end": 1467.113,
    "text": " modeling assumptions about parametricity um being sort of baked into the mechanics um so in particular right there's like all this focus on uh precision and i understand why that's important um but like in other contexts like there are other",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1467.667,
    "end": 1474.153,
    "text": " statistics or later moments that we might care about that are important to understanding the shape of a distribution, for example.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1475.074,
    "end": 1489.608,
    "text": "Normally, I'm used to seeing when there's an assumption in some paper that something is Gaussian, that that is a modeling convenience rather than a statement about a biological reality.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1489.628,
    "end": 1496.374,
    "text": "I guess when precision is hypothesized to be an actual thing that's communicated",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1496.354,
    "end": 1519.273,
    "text": " in in particular systems in the brain does that kind of imply that like particular behaviors can't learn things that are dependent on like the shapes of tails of the distributions that are being communicated about rather than just like their broadness versus or uncertainty around an estimate",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1525.447,
    "end": 1527.774,
    "text": " Yeah, a lot of great questions in there.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1527.834,
    "end": 1533.31,
    "text": "Two different pieces.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1533.351,
    "end": 1536.199,
    "text": "There's like this discussion of the support",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1537.158,
    "end": 1543.629,
    "text": " Benji Carlson- Early in the textbook it's kind of like why and then it's it's kind of like what you brought up like, but then the Gaussian goes off to very low.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1544.55,
    "end": 1558.052,
    "text": "Benji Carlson- So does that mean there's like an infinitely low probability of learning something infinitely rare and, like all these different questions so then like that is the statistical question is like how should it reflect.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1560.293,
    "end": 1569.792,
    "text": " If it's a Gaussian situation and not one parameter will do fine capture all the variants, but then, if it's anything different than that, which is basically everything then.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1570.513,
    "end": 1573.9,
    "text": "And then not also reminds me of.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1577.266,
    "end": 1580.833,
    "text": "The discussion in this paper slash live stream.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1583.598,
    "end": 1597.472,
    "text": " And so here they were summarizing neural networks, not like just with a mean and variance, but summarizing them with more of like a latent space that could be larger or smaller.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1597.952,
    "end": 1603.718,
    "text": "So it's basically what a variational autoencoder is, but they were doing that as like this kind of meta representation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1604.439,
    "end": 1608.863,
    "text": "And it was like very interesting what he shared.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1608.843,
    "end": 1610.925,
    "text": " But this is basically the trade-off.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1611.466,
    "end": 1630.328,
    "text": "If you only have two parameters, if you only have one parameter to distill the information projected down to, then some common choices are like the median, the mean, arithmetic or geometric mean, or like the waiting time for a single parameter model.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1630.747,
    "end": 1642.221,
    "text": " Then with two parameters mean and variance like the measure of central tendency in the first one movement and then the more parameters, you have the more expressive you can be.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1643.463,
    "end": 1643.623,
    "text": "But.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1644.884,
    "end": 1647.287,
    "text": "that's the whole question with these large parameter models.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1651.272,
    "end": 1653.615,
    "text": "So you can make it and and what a.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1655.536,
    "end": 1667.753,
    "text": " what Ryota discussed in this was actually like kind of to the consciousness point was like, so there's the global workspace, like the ignition across different sensory modalities.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1668.174,
    "end": 1670.357,
    "text": "So that's the kind of binding of the consciousness.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1671.339,
    "end": 1675.525,
    "text": "And previously it was studied like, does it happen or not?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1676.806,
    "end": 1679.11,
    "text": "Or like, was the shape perceived or not?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1679.19,
    "end": 1684.277,
    "text": "Was the stimuli perceived or not as a kind of conscious to not conscious?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1685.962,
    "end": 1699.8,
    "text": " But then once you're in the space of things that have been perceived, then there's a need for a richer differentiation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1699.82,
    "end": 1702.383,
    "text": "Because they don't just differ in that one is not the other.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1703.144,
    "end": 1707.97,
    "text": "So then he talked about how you can have richer representations than all or none.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1718.48,
    "end": 1745.061,
    "text": " another um more statistical answer is uh there's probably a lot of this is you can compose gaussian distributions to approximate any distribution like basically so it's not just two parameters in the actual papers but that's kind of the minimal explainable component like spm",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1750.205,
    "end": 1764.341,
    "text": " Like in the end, it's going to result in this map of the brain with statistical, with one value per voxel, which is like basically the statistical test on whether it's different.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1766.143,
    "end": 1774.852,
    "text": "But there's a ton of parameters upstream of distilling down to one statistic.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1774.872,
    "end": 1777.495,
    "text": "There's very active SPM discussions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1778.943,
    "end": 1781.747,
    "text": " Like they have a mailing list and there's trainings and things like this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1783.909,
    "end": 1788.195,
    "text": "I don't know if anyone has done the text has done this SPM work, but it may be relevant for the textbook.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1790.478,
    "end": 1792.861,
    "text": "SPM deals less with the action selection.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1792.881,
    "end": 1798.268,
    "text": "And philosophy and more with the statistics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1800.003,
    "end": 1805.935,
    "text": " Sanjeev's textbook is probably more direct way to learn the statistics specifically.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1805.975,
    "end": 1809.322,
    "text": "However, this is still informative statistics.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1813.13,
    "end": 1817.539,
    "text": "Just to orient myself, SPM is the thing that first made first and famous.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1818.346,
    "end": 1818.727,
    "text": " Yes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1818.987,
    "end": 1829.04,
    "text": "So SPM is a MATLAB toolbox for modeling the functional FMRI dynamic time series data and like including other neural sensors.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1829.341,
    "end": 1843.64,
    "text": "So basically sensor fusion in neuroimaging and hence being mega-sighted slash being the bread and butter and the method of the Princeton lab.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1845.302,
    "end": 1847.205,
    "text": "Then early in the 2000s,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1848.738,
    "end": 1861.559,
    "text": " This kind of general just take formal approaches to perception cognition action also started to come out with some of the first principles and the physics of cognition and sentience and things like that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1863.602,
    "end": 1866.747,
    "text": "So this type of a statistical framework.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1868.06,
    "end": 1870.302,
    "text": " is not focused on action on first past.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1870.843,
    "end": 1877.229,
    "text": "It's just modeling observables, the sensor data, and then the hidden state, which is the neural activity.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1878.49,
    "end": 1882.734,
    "text": "So it's like an A matrix and a B matrix in the textbook.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1883.935,
    "end": 1884.936,
    "text": "No policy selection.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1885.456,
    "end": 1892.403,
    "text": "It's just kind of, or it's kind of like the figure 9.1, like you're viewing the outside.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1892.983,
    "end": 1897.948,
    "text": "So it's like, what kind of modeling can you do if all you have is neuroimaging data and behavioral data?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1898.992,
    "end": 1903.278,
    "text": " And information on the people, their, you know, other details about them.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1907.063,
    "end": 1910.949,
    "text": "And it's very use oriented, like all the citations to this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1915.635,
    "end": 1916.076,
    "text": "Let's see.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1919.661,
    "end": 1920.042,
    "text": "SPM.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1922.385,
    "end": 1922.745,
    "text": "SPM.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1922.765,
    "end": 1927.412,
    "text": "2010 paper being kind of a landmark FEP paper.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1930.413,
    "end": 1937.363,
    "text": " SPM DCM dynamic causal modeling, looking at the dynamical causal relationships.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1937.403,
    "end": 1945.333,
    "text": "So then like to test whether attention is engaged in a given moment, it's like, okay, well, the attentional network connects these nodes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1945.434,
    "end": 1947.917,
    "text": "And then when it's not attentive, it disconnects these nodes.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1948.898,
    "end": 1952.643,
    "text": "And then we're going to test whether this or that model explains this or that behavior.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1956.869,
    "end": 1958.952,
    "text": "Very foundational statistical.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1960.535,
    "end": 1969.093,
    "text": " work about like correcting for noise and variance patterns and fMRI like slower and faster noise like variances and deviations.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1971.031,
    "end": 1977.737,
    "text": " Then also first and all have the clinical psychology background.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1978.097,
    "end": 1988.107,
    "text": "So then using the MATLAB toolkit, they have a lot of math papers on the toolkit.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1988.467,
    "end": 2000.498,
    "text": "And then also like looking at specific, like the stuff that we saw on the table 5.1 with like specific brain regions in specific behaviors.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2004.73,
    "end": 2007.534,
    "text": " And many people who still do fmri when they use this toolkit.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2015.206,
    "end": 2016.067,
    "text": "Let's see the first one.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2016.127,
    "end": 2016.788,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2018.551,
    "end": 2019.473,
    "text": "First active inference.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2027.485,
    "end": 2029.167,
    "text": "Fristin Pizzulo.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2031.872,
    "end": 2032.172,
    "text": "Kind of.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2033.992,
    "end": 2037.44,
    "text": " This is probably similar to the textbook, but five years earlier.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2046.98,
    "end": 2047.782,
    "text": "Pretty interesting.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2057.228,
    "end": 2064.079,
    "text": " But that's all, every field has more papers to read than slash order what to do them in and all of this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2072.111,
    "end": 2076.118,
    "text": "But it does really emphasize that more of a path-based approach is relevant.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2078.521,
    "end": 2083.489,
    "text": "And also augmented with mega new tools for like processing all of it and so on.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2091.805,
    "end": 2097.956,
    "text": " Susan?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2097.976,
    "end": 2098.597,
    "text": "Yes.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2098.617,
    "end": 2104.427,
    "text": "Can you say anything about the page on active inference model recipe?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2104.727,
    "end": 2105.489,
    "text": "That's pretty cool.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2106.931,
    "end": 2109.055,
    "text": "It's under Chapter six.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2123.783,
    "end": 2142.822,
    "text": " this is kind of their general layout of the book chapter one through five the epistemic and then chapter six through ten the um pragmatic okay that specific page okay yeah this may have been gone through this is just taking the questions that were in the chapter",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2144.185,
    "end": 2148.332,
    "text": " And then that's the ones that are basically just explained in the subsections.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2149.574,
    "end": 2152.699,
    "text": "We also use a language model to ask for more detail on all the sections.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2153.36,
    "end": 2167.965,
    "text": "And then this was, I believe, with Michael Carl, who later presented some of the work on a stream, actually, it was very cool, about the data set that they had, which was related to translators.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2167.945,
    "end": 2190.949,
    "text": " actions like with eye gaze so where they were looking in the text and then what they were typing and deleting and then just doing descriptive statistics like of course you could categorize different categories of translators that would be like you could use a simpler statistical approach or like a deep learning approach because you have the data",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2191.773,
    "end": 2215.842,
    "text": " Or, and or, what does it look like to make an active inference cognitive model that describes a generative process of the translation process, which is a complement to the descriptive statistics, like generating synthetic data for models that could then be descriptively describing that output.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2215.862,
    "end": 2217.944,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2217.964,
    "end": 2221.729,
    "text": "So, is this assuming that",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2222.333,
    "end": 2235.029,
    "text": " Yeah, there is an observer and an observed or in terms of, you know, because it's like the question of, whoop, you know, what must be observed?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2236.15,
    "end": 2240.335,
    "text": "Could that be, could that be, you know, self-modeling?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2242.498,
    "end": 2243.039,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2243.119,
    "end": 2248.105,
    "text": "I'm not going to know what I'm observing other than what I'm observing if I'm the observer versus the subject.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2250.262,
    "end": 2251.803,
    "text": " Yeah, it's a very interesting question.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2251.843,
    "end": 2256.688,
    "text": "Like definitely cells have some private access to certain things.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2257.909,
    "end": 2264.575,
    "text": "But in the case of the translating, like Professor Carl was, it was his laboratory.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2265.376,
    "end": 2267.778,
    "text": "So he knew exactly what the stimuli were.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2267.798,
    "end": 2272.142,
    "text": "They were the observations for the translators, the strings of texts.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2272.622,
    "end": 2278.007,
    "text": "And then he knew what measurements, the actions of the translator were being observed.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2278.949,
    "end": 2285.717,
    "text": " And this is the kind of like in SPM, it was initially with FMRI, with the MRI imaging time series.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2286.218,
    "end": 2293.367,
    "text": "And then also they're able to combine that with MEG and EEG and probably other neuroimaging techniques.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2293.387,
    "end": 2294.829,
    "text": "It doesn't even matter what the acronyms are.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2295.249,
    "end": 2303.199,
    "text": "The point is you can have different sensor sets and merge sensor sets with deeper and deeper generative models.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2304.401,
    "end": 2308.045,
    "text": "So if they also had the translators like heart rate,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2309.442,
    "end": 2331.855,
    "text": " that would be the question okay how do we bring the heart rate in but that doesn't change the affordances but then let's just say also you start looking at their foot tapping then that would be like okay now that's a new affordance to model so that's kind of the interoperability of the active inference models with deep learning some of these models do have multimodal",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2332.308,
    "end": 2339.216,
    "text": " capacities, like the ones that can take in text or images as an output, like text or images.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2340.638,
    "end": 2342.76,
    "text": "So it's not that other models can't do that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2344.622,
    "end": 2353.432,
    "text": "It's just, there's a lot of other things to say about that, like the interpretability or the reliability of adding a new modality, all these different features.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2358.198,
    "end": 2358.518,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2358.886,
    "end": 2366.977,
    "text": " But to make a pedagogical fun exploratory model, but those considerations are not going to be.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2367.017,
    "end": 2368.9,
    "text": "hindrances.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2370.602,
    "end": 2373.907,
    "text": "So hence Chapter six I think that would be something fun like.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2375.088,
    "end": 2380.135,
    "text": "that's kind of the pacing that we can figure out, not necessarily two weeks on six but.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2382.055,
    "end": 2392.788,
    "text": " As I mean, Susan and others know, like once we start getting it down in this basically chapter six format, then we're in feedback with what we have.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2393.669,
    "end": 2395.591,
    "text": "It's easier to communicate, easier to build on it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2396.272,
    "end": 2406.865,
    "text": "Also, the technologies for applying it, given even like this level of detail are far more advanced than they were like one or two or more years ago.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2408.532,
    "end": 2416.829,
    "text": " So it's not like exactly like you could just copy in this little and get a script today, but it's not so far away.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2419.134,
    "end": 2420.256,
    "text": "But it wouldn't even matter if it were.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2420.496,
    "end": 2427.25,
    "text": "There would still be going deeper and being more expressive and having in our own generative models more of an understanding",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2427.652,
    "end": 2434.98,
    "text": " And yet also like you can use the GPU and deep learning without knowing all the GPU like Linux kernel details.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2435.961,
    "end": 2438.264,
    "text": "So that's like levels of abstraction in the modeling.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2438.284,
    "end": 2439.545,
    "text": "Those are just different experiences.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2439.605,
    "end": 2442.308,
    "text": "Somebody wanting to just run the software.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2442.328,
    "end": 2455.363,
    "text": "I mean, look at the report, run the software, run the kind of fully investigatable version, understand the minimal unit, like understanding the minimal unit of a neural network, those kinds of things.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2462.228,
    "end": 2467.816,
    "text": " Okay, well, next week, it'll be the last part of this interval.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2469.479,
    "end": 2470.68,
    "text": "Come to this or the other time.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2471.642,
    "end": 2476.829,
    "text": "And then we'll see how people want to continue six.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2477.931,
    "end": 2485.422,
    "text": "And like, also, we could explore how we want to interact it with seven, you know, different things we could talk about.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2485.642,
    "end": 2485.882,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2487.285,
    "end": 2487.645,
    "text": "Thank you.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2491.844,
    "end": 2492.54,
    "text": " Take care everyone.",
    "speaker": "SPEAKER_03"
  }
]