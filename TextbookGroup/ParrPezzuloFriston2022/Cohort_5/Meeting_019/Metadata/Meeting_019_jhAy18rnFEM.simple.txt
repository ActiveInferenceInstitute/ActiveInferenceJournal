SPEAKER_03:
All right, welcome cohort five it's march 11 and Andrew thanks for taking us on to Chapter eight part two so go for it.


SPEAKER_01:
Okay, it's our second week on chapter eight.

And just a brief refresher that this chapter is in the second part of the textbook.

And so we're now focusing more upon building our own models and getting a sense of how to draw relationships between phenomena of interest and how to actually map them to

variables and active inference models.

Chapter seven, we saw discrete state space models.

And so we were looking at POMDPs and now chapter eight now transitions to continuous state space models, which are sort of the foundation, the starting point for historically for developing active inference models, a lot of the earlier work.

of Fristen, Parr and others was on continuous models first.

So here we're looking at continuous state space models, which are well suited for modeling, let's say physical fluctuations impinging on sensory receptors and for the continuous motion of the effectors or muscles we use to change the world around us is a quote from the chapter.

um here we have model examples for dynamical systems involved in motor control as well as the concept of generalized synchrony with the birdsong example and finally constructing hybrid models near the end which would actually

combine discrete and continuous variables so kind of almost add mixture of what we confronted in chapter seven now with continuous variables being situated as well for example at a lower level of the model

Since it's our second week from there, I think we could just jump in.

Does anyone have any thoughts on this chapter?

Any questions, anything they're still kind of crunching through in their mind about how a lot of this works?


SPEAKER_03:
I'll add one point.

Thank you, Andrew, for the quick opening.

I think it's an interesting point that, like you said, it was initially with the earlier Friston and Parr models in continuous time.

And now the continuous time is being revisited in the Bayesian mechanics setting.

So it's kind of like a purely dynamical systems justification.

which is very similar to the SPM textbook, so kind of classical equations of motion, which kind of turns out to be like the classical Newtonian-Bayesian mechanic.

Mm-hmm.

So the kind of pre-2015 continuous time, which is where most of this chapter is focused, like including just the differential equations, including the chaotic deterministic systems.

That's just the kind of pure dynamical systems

approach.

Again, very similar to SPM.

And then this textbook doesn't really go into Bayesian mechanics because this textbook was published March 2022.

So probably was written between Princeton's 2019 free energy principle for a particular physics and then obviously the book being published 2022.

So

It's mentioned, but many of the works that made it clear are only after the book, just to kind of give a little more context on the continuous time.


SPEAKER_01:
Yeah.

So we start with continuous, we move to discrete, and then we're back to continuous, but it's kind of using what's been developed since then.

And also being able to combine the two as well.


SPEAKER_03:
Yeah, and the nested hybrid model at the end of Chapter 8 is basically picked up on by this paper, which we discussed in Livestream 46.

And they basically pick up on that exact

hybrid model i don't know if they use a figure let's see the hybrid model on page 166 oh sorry sorry yeah yeah you're looking at the paper yeah just the the but i don't know they didn't include it there but uh

yeah figure 8.6 so here continuous time on the bottom because of the derivatives and then discrete time on the top because of the transition Matrix and the explicit time and then in this paper they say okay with a belief desire intention like BDI model

Including discussion of like whether that is folk psychology etc, etc, but within that commonly used like, can you talk about belief desires and intentions and all these things they it it's not that it does better or any different even per se it just it's non contradictory.

So it's kind of an interesting first way to put it.

hey ollie.


SPEAKER_01:
Is that particular paper, does it discuss much like?

Well, I'm not sure how deeply you want to go into that or maybe another example, but it seems like maybe a nice way of like finding them for week two here, like another application of what we find in chapter eight.

What's what's going on in that paper as far as like distinguishing

discrete from continuous variables, do you have a recollection of like the model set up there?


SPEAKER_03:
Let's look at another time, but I think they all they mainly explored like differences in the belief, desire, intention, not into the model and not sure how much they focused on that sensory motor part.

But yeah.


SPEAKER_01:
Yeah, Prakash.


SPEAKER_00:
Yes, sorry.

Could you please go to that desire part which they're mentioning in that paper, the desire thing?

Yeah.

Can you please spend some time on this?


SPEAKER_01:
Yeah, I think you noticed it in the figure, probably.

Let's see.


SPEAKER_03:
Yeah, DAI, they're using for discrete.

And MAI, I think, for motor AI.

So here they're looking at the C preference distribution, which is a distribution over observables.

And then contrasting the observation of tasting ice cream and not tasting ice cream.

So these two alternative ways you could parameterize that, like in a program or an equation, here's 0.7.3, like a coin flip, 0.7.3.

70% of the time I expect to be tasting ice cream.

Here it's 99% expecting to be tasting ice cream.

So then that C is stronger.

And so it entails a stronger motivational force through pragmatic value in EFE.

So that's one way to kind of look at it.

And then there's the other, the way that the textbook kind of talked about it is with the C scaling.

But so depending on the program, sometimes you're working in the scaled C or unscaled.

Scaled meaning to the statistical distribution or like here.

So that here, ice cream versus no is being described summing to one, like a coin flip, like a real distribution.

So then you could have 99.99999999.

Or that could be represented as like 1 million to 1.

So it just depends on the exact situation, whether you're working in the kind of setting where you can learn by counting through experience or do other modifications.

And then when that's used as a distribution for pragmatic value, it's transformed into something that sums to 1.


SPEAKER_00:
Rafal Dittwald, Ph.D.

: Could you please send a link to this paper in the chat box.


SPEAKER_03:
Rafal Dittwald, Ph.D.

: yeah just be on chapter eight page.

Rafal Dittwald, Ph.D.

: yeah i'll put there to.


SPEAKER_01:
so if there are no um anyone please feel free to bring up any other questions you might have along the way or you know toggle the reaction to raise your hand um but so in in this chapter along the way where we're introduced to things like attractors um

were introduced as well to the concept of generalized synchrony comes up a bit later.

And that's a particular notion that

As we know, active inference agents are attempting to model the hidden states of the environment.

So they're attempting to model their environment, what's going on around them.

Generalized synchrony is this notion that the agent is basically their internal states are modeling or in certain ways beginning to synchronize with

the states around them.

We have no proof, of course, like the agent itself has no pure objective proof that it's somehow perfectly understanding the environment and all variables around it.

But nonetheless, there's a kind of synchronizing going on.

And this can be applied to a kind of multi-agent setting.

And so here,

later on in the chapter, we're given this like birdsong example, which, you know, the textbook is published in 2022, but the birdsong example goes back to at least 2015 and potentially sooner.

But there are a couple of 2015 papers by Friston and Parr who are basically investigating using continuous variables

um they simulate uh two songbirds singing songs right and what they do is that um

there's a we start to see this kind of emergent phenomena, of course, with with active inference models, one of the big aims here of doing modeling is to like set up your variables set up your model.

run a simulation and then see what kind of emergent phenomena arise with the bird summit song example.

they first set up two birds that have identical models.

So not too not too surprising to find, okay, they have identical models, they have the two songbirds, like quote, unquote, within earshot, like they can the two songbirds have actions where they can sing.

And then they can take in sensory observations, that being of continuous auditory signals.

And so it's like the birds are singing to each other and listening to each other.

The emergent phenomena that begins to happen is we start to see them taking turns.

It's as if they're singing from the same hymn sheet or the same script.

And the generalized synchrony

Interestingly, even occurs whenever they set up the model, the simulation a second time around where the birds actually have different starting models.

So the birds start in different spots as far as they're like state space, like coordinates go.

And over time, the birds models actually began through perceptual learning to to mirror one another.

So even though we start off with two different agents, they start to synchronize.

Now they're seeing the same hem sheet again, even though they're two, you know, very different birds as far as starting points go.

The way that's modeled is through using attractors and a Lawrence system.

And so in this case, there's something that's called a synchronization of chaos, which is rather interesting.

Because with a chaotic system, if you have two chaotic systems, presumably, even if you put them at the same starting point,

um their trajectories will very quickly diverge um you know with infinite infinitesimally small chance that they will just magically line up but whenever you have two agents who are able to act um and listen uh to one another and they start to do this thing where they're following the same hymn sheet suddenly you have a kind of synchronization of these two chaotic systems and we see those kinds of um

dynamics illustrated in the in the chapter is kind of orbiting on figures 8.4 and 8.5.

And so yeah, kind of a lining up between different agents.

I think it's interesting for anyone who's curious about

Matt Pinyan, Trying to set up systems or do multi agent settings where they're trying to see you know how a joint action begins to play out between agents saying how agents can work together to.

ultimately minimize their own distinct you know free energy um but by in order to do that they actually have to like yeah entrainment is a good word like one of them entrains the other um

so that they can stay on the same page, minimize prediction errors.

And it's fascinating because there are all kinds of rich behaviors and dynamics that occur.

Like the songs that are being sung, presumably they have like vocal glides and brief pauses.

So it's not just a super simple behavior that's being synchronized here.

But nonetheless, it occurs.


SPEAKER_00:
Let's see.


UNKNOWN:
Hmm.


SPEAKER_01:
the birdsong also.

I like how this chapter brings up.

Oh, Prakash, is that your hand up again?


SPEAKER_00:
Yeah, sorry.

I may be wrong, actually, but just correct me.

So for synchrony, there needs to be some kind of a coupling.

I'm just wondering, is it anyway related with the generative process and the generative models, like the

like we have the like the generative process is in a way uh complementary to the generative model is it possible that that plays an impact sure so so in this example there's not too much going on in terms of uh


SPEAKER_01:
So just as a starting point.

So with modeling, you're going to be defining a generative model and you're going to be defining a generative process.

In this example, there's not too much distinct going on whenever a generative process is defined.

In fact, here it's like we have two generative models, so two agents.

And they're coming into contact with each other.

So it's like for bird number one, its model is itself.

Its process that it's coming into contact with is just the other bird.

So you can think about the observations that bird number one is taking in.

They're all being generated by by bird number two as part of the environment, the process that's around it.

Does that make sense?


SPEAKER_00:
I think you're right.

I think instead of thinking in terms of generative process altogether, like two different agents, and they have like similar kind of internal models, and that is kind of causing some kind of coupling mechanism.

And so over a long period of time,

uh they may start to have behaviors which are similar to each other no like you mentioned that hymn sheet right so one person may say the starting lines and then after some time the second person will say the second thing then the third will say first we'll say third like that observations might happen yeah it's like a pendulum example which i think uh was mentioned last week like we have these two pendulums which are swinging and over a very long period of time they'll kind of

Um, oscillate together.

No.


SPEAKER_01:
Yeah.

yeah no that's exactly right and uh that's that's also referenced in the birdsong paper so yeah just basically being able to start two different in that yeah in that case your pendulums are kind of like your agents um and yeah via you know via physics via the the general logic that we're looking at here like attractors yeah they begin to

kind of move towards attracting points but they're acting as each other's attracting points so to speak um such that yeah their their behaviors start to to synchronize and so with the the birds the bird song is an interesting example versus the pendulums because the pendulums they just like continue moving for the birds um we have this turn taking dynamic that begins to occur

Because the birds are trying to, in terms of active inference and the free energy principle, they're actively trying to minimize their prediction error.

And the way they do that here is that they want to hear a song, like they want to take in

uh sensory observations that show that are realizing the preference of hearing a song and the two ways they can do that of course are perception changing their mind their own mind or uh action which is changing the world and so this turn-taking dynamic involves a combination of sensory attention and sensory attenuation uh is how it's phrased here and these are also

um interesting mechanics that we find in in just about any active inference model where action is involved um you have to so the birds take turns because like how do you keep a song going well one uh you need to hear that it's going on so they attenuate or or kind of like pause um their um their incoming sensory signals

uh to uh commit actions that realize hearing the song it's like oh I don't hear a song I need to sing that's that's realizing my preference um okay I've sung um now I pause I hear the other birds singing I take that in as a sensory signal

The other bird begins to sing.

Maybe it sings notes that I expect.

Great.

Maybe it sings notes that I don't.

Now we have prediction error starting to jump up.

Yeah.

And so whenever that happens, of course, the bird number one has to minimize its prediction error.

And so it starts to sing itself again.

And because these two birds are basically doing this back and forth, there's a kind of synchrony, because they're both trying to minimize the prediction error, the way that they sing, the actions that they take, the specific ways that they sing, they start to synchronize.

They start to match notes, start matching expectations.

And that's the kind of thing that we see playing out in the graphs and the figures and the

textbook, especially figure 8.5.

On the right, the authors here, you know, Friston and everyone, they're trying to show like a before learning and after learning for these two birds.

On the left-hand side, it's like, okay, these are the dynamics playing out.

Here are the dynamical equations.

And then on the right, you can see the upper graph before learning.

These are kind of like the state spaces of each bird's expectations.

They're top-down predictions.

And then a little bit more all over the place.

Whenever they start, they begin to synchronize so that, you know, whenever...

Whenever bird one and recall these are continuous state spaces, which is why we are able to do this as coordinates rather than having to look at like discrete.

Point masses or something.

So where bird number ones, or excuse me, yeah, the first bird's expectations in that lower right graph, whenever they're around 10, you know, whenever we plot them, the second bird's expectations are also around a value of 10.

Whenever bird number one's expectations or predictions are around 50, same case for the second bird.

So that's what they're trying to get at with these graphs is, yeah, they begin to,

even though they're dynamically shifting around, we're never always at zero.

We could be at 50 this moment, we could be at negative five this moment.

The important point is that the first bird's predictions and the second bird's predictions are basically both lining up at just about any given moment.


SPEAKER_03:
One interesting thing I hadn't seen before is like here it's going between at least 60.

But here it's only going to 40.


SPEAKER_01:
Yeah, presumably.

I mean, we have before learning and after learning.

So presumably they maybe just before learning haven't explored quite as much of the state space yet, right?

Like we have this much more exploration after learning.

You've run more trials or at least extended the time horizon.

And then, here they are like starting to sync up singing new notes that they'd never sung before or however you'd like to phrase that and yeah the scale starts expanding because they're trying new things.


SPEAKER_03:
Not sure nice nice interpretation.


SPEAKER_01:
Yeah, it's it's it's a thought in any case and I also notice it looks on the after learning graph.

It looks slightly more chaotic or just messy, not quite as synced up once you get past 50 on the after learning.

My guess is that like oh, this is a new the new terrain that they're exploring here.


SPEAKER_03:
Yeah, these little micro little micro densities.


SPEAKER_01:
Yeah.

So presumably after more trials, like we'll see an even finer kind of line or syncing up between them.


SPEAKER_03:
We should find them at lab.

It might, it may even be an SPM example.

There's also a kind of mini standalone SPM.

Like while it is a MATLAB package, there's a, uh, kind of like compiled standalone SPM, all the, or, or other people like it's worth a try.


SPEAKER_01:
Yeah.


SPEAKER_03:
And the bird song, I, I, I could check or we could check together because it's kind of been around long enough to probably be included in the DEM demo.


SPEAKER_01:
Yeah, actually, that's right.

I was just having a look at the paper.

I think I dropped in the chat there.

But yeah, just about any of these Friston co-authored papers, at least prior to maybe the past couple of years, it's like go into a paper, Control-F, SPM, see if they

you know, have a script there that they're, you know, they'll always mention in the paper, of course, there you go.

And yeah, it looks like it is contained in there.

yeah for for better or worse of course matlab still requires um a license to use but but i myself have downloaded the the spm standalone before um you just you know unfortunately of course you cannot run dot m matlab scripts if you don't have matlab so spm is nice as far as like you get this

Um, this like graphical system with all of these different options of demos, you can click, you can look at the graphical outputs and yeah, it looks like this one, um, is included in there.

It's like that, um, bird song underscore, um, Oh no, D E M underscore demo underscore duet.

Um, so it can run.

Scott Luxenberg- dot m scripts in the background, you just can't hop in and access them and modify them yourself to tweak the parameters or anything like that, unfortunately.

Scott Luxenberg- But yeah it's nice it's like they're they're like literally dozens of pre loaded scripts in there, if you just download the SPM standalone you just click one and.

Scott Luxenberg- You can you can watch what kind of graphical outputs it comes up with.

yeah and we can also explore bringing it into rx infer and everything yeah yeah definitely um for anyone here who's not familiar um the institute has an ongoing project thursday mornings well sorry i'm in the us some advice to that but um

early on Thursdays.

There's an RX inferred project for anyone who's interested in adapting the logic of active inference that we're reading about here to direct application in the Julia programming language and

Right now we're going over different examples that are already provided by the developers, BIAS Labs, of this RxInfer package.

But we'll be expanding from there.

Different people are proposing their own community projects, different kinds of use cases they're coming up with, and that we could try emulating as a group.

And then another focus is that we would like to be able to reproduce some of these existing projects or topics.

For example, here we could try and take the MATLAB script for the birdsong example and recreate it in Julia.

And finally, just final note, is the

Julia programming language, as well as the way that bias labs is developing the arcs and for package it's just it's nice that it's it's using this more.

kind of sophisticated but also highly efficient.

method for the computation and message passing, as we saw in the textbook back around chapter five, to really just like being able to scale up these kinds of processes and being able to just basically better use your computational resources, save on some time, efficiency, all that good stuff that we in the programming world care about.

Yeah, Francis, you have your hand up.


SPEAKER_02:
Yeah, I just wondered if there's two questions, actually.

Firstly, if there's likely to be any support for a PyMDP group, because I'm already having to learn Python.

I can't really commit to learning a second programming, new programming language from scratch at the same time.

So I've been kind of slowly working through that nice

PyMDP tutorial book running it on the, is it Colab?

And the other question is, is there anything to be learnt or is it not a really helpful parallel between the idea of the birdsong example as a kind of

autocomplete and how does Active Inference's success here compare in any way to LLM's success at GPT-4, the world's smartest autocomplete?


SPEAKER_03:
Thanks.

Just to quickly address it.

So right now, we do not have any active PyMDP specific group.

We could do a similar kind of thing.

Right now, the Rx and Fur is really, it is kind of interesting.

It's just from knowing PyMDP to medium degree, it is different syntactically.

however like it is it's very different and it's a more general than pi mdp in several ways not to say that that that one can't have other you know things the other doesn't have but just the that um RX and fur pulls way back like to the coin flip

which was really helpful and then builds up.

Whereas PyMDP wraps, it focuses on just kind of getting you to the discrete time active agent POMDP as fast as possible.

Because that's like not every use case, but that's like many use cases.

And then it can kind of be modularized from there.

But RxInfer is...

it's a it's a very promising effort that's a lot broader so i i think it's a good way to go i'm kind of excited to learn it a lot ollie is very good at it oh then the second piece about the the um llms well one

we we um we haven't had a a streamer discussion on with these authors but this is one interesting paper recently um and then yeah like it's almost like a question of what what is perceived as a um computing benchmark especially if other considerations like interpretability or energy it's like

is it a challenge is it a computing advance to open a larger file with a computer with more ram it's like yes but maybe it's not proportionally or differently a kind of benchmark so then what what are benchmarks for active models

And like, or even kind of in another setting, like with the morph streamed with Sarah Hamburg, different guests, it's been interesting to like hear how they talk about like the different characteristics of the biomimetic computing systems, because they are not, it's not simply just like the CPU, RAM,


SPEAKER_02:
descriptions thanks so much that's so it looks like a really um interesting uh paper um yeah and only six pages oh no comments of six pages yes yeah it's a short it's definitely a starter so I and I think that they and many other people are interested and and a big um um like


SPEAKER_03:
of course the models are different if you look at the transformer architecture um or um but there's some interesting with the state space models like the mamba there's there's a few people like matt perkowski who have um talked a little bit about the relationship between the state space models and active inference so that may be actually a closer relationship but um just in terms of how the transformers are different than active inference models i mean in the textbook group

Matthew T Brooks, St.

Paul MN, He, These chapters are showing us what the active model is you can then just look at the transformer architecture and just see how they are different architecturally but then.

Matthew T Brooks, St.

Paul MN, He, In in this paper they kind of highlight this kind of.

Matthew T Brooks, St.

Paul MN, He, Ongoing there's various aspects to highlight there's the epistemic value there's the um.

reinforcement and but there's also a lot of overlaps as these are just large statistical models yeah oh thanks that's great oh and this is another good one where um

they talk about how in active inference, you can construct the causal graph to be like that there is an uncertainty parameter or like a temperature parameter on some other parameter, or there's like introspective access that using the classic Lars live stream 28 figures with a meta awareness.

So if you construct the model to be this way,

then this parameter actually has that role in the system.

Whereas if you ask a prompt, no matter what you ask or how you ask it to a transformer architecture, what is it like to be you and all these kinds of questions that people are very interested in,

it's only ever giving that semantic space, fuzzy statistics of words answer.

So it could say, I'm very sure that it's this way, or very sure it's that way, or I'm not sure, or I feel this way when it's that way.

But those are all just words generated from texts, statistics of texts.

So they will never approach an actual introspection.

So here they raise the possibility of the actual introspection.


SPEAKER_02:
That's very interesting.

A totally different author list.

Can we have that link on the encoder as well?

Thank you so much.


SPEAKER_01:
This is all interesting with the comparison to LLMs, because I'm no expert on that topic, but I've been looking into it more myself.

And yeah, there is this kind of notion that, OK, LLMs are great as far as performance goes with accuracy.

and all of the computation there.

And nonetheless, yeah, major, the kind of criticisms and the sort of debate or contrasting between LLMs and ACT-INF is just more generally like, oh, it takes a ton of computational resources to train an LLM.

And then once you're kind of finished training it, it's like, OK, well, there it is.

It's not conceived as an agent who's

who's able to engage in action.

The idea would be you'd have to have an LLM that had the capacity to actually go and explore information itself, and then presumably it'd have from an active inference take, it would have to have its own preferences of how to

that it wants to realize, so to speak, or a C matrix or a C vector in the POMDP scheme or however you would like to think of it.

And so it boils down to the idea that an LLM is passive.

It can't go explore, it can't update information and expand its state space dynamically or

or do things that maybe a more active uh agent could um it's kind of like okay well once you've trained it like that's what you've got uh nonetheless i'm very curious about the paper that yeah because that looks like it it's it's actually saying no llms are not entirely passive but let's talk about it yeah that that's all true and also what's really interesting though is the um i mean


SPEAKER_03:
what what we might call ecosystems of shared intelligence or just the multi-agents prompting they're like when you on perplexity ai or on um any internet enabled like cloud provider um or even if even in the uh local retrieval augmented generation

where it's like you have a library of documents and then the it pre um assembles into the context window what's relevant like that's an information forging so this is kind of like um is it active inference like low road like has it been constructed according to chapter six using like forked code from an active repo or is it just being described as

in terms of having particular states, like figure 9.1 with the kind of rat in the maze, like making a cognitive model of another language model.

That doesn't mean it will be useful to do that, but these models are prompting each other in ways that makes them have epistemic value.

like they do do web searches even if one language model locally doesn't have certain properties so there's a lot of thumb interactions which is kind of only to be expected and even these other these systems are are basically multi-agent models like like the large ones that are closed source

but not in the kind of spatial mobility way probably, just like in the combining inputs.


SPEAKER_01:
Gotcha.

I was actually personally not familiar with the fact that these are technically multi-agent setups.

That's really interesting.

It also makes an immense amount of sense actually.

Yeah, yeah.

And they're working off of one another.

I'm not trying to over relate, but just given this is the textbook group, of course, it's like, you know, we had the bird song example where the birds are trying to help each other, so to speak.

Not, you can't, that's an interpretation to say that they're trying to help each other.

But the point being that they're both trying to minimize their prediction errors.

And so they're

playing off of one another sharing information with one another or in this case a song i guess with ellen llms in a certain sense of course i'm being constructed very differently we're talking about this right now that they're kind of working off of one another too yeah yeah i think another good uh point there in the context of building the models is like


SPEAKER_03:
it's not necessarily about building like one Megatron agent that has every property it's about like what things are there and then starting to describe their interfaces which are usually less ambiguous and then describing the things and and their interfaces and interactions then maybe all you need is a oscillator

versus like a lot of times the kind of speculation about very advanced kinds of models but as we're putting on rx and fur like which is awesome too the um the the philosophy far outruns simple models

so depending on what we're really trying to explore just you know describing and then having and then having the modularity of the model so we could start with a pendulum but then know that the interface would be described like in a stable way in rx infer so that would have made large progress towards different kinds of phenomena without necessarily getting caught up in trying to locate it

too early in a given architecture for a single agent.


SPEAKER_02:
Can I do one more question?

Does this idea of the synchronization refer back to the phrase you used earlier about, was it community of something or a shared?


SPEAKER_03:
something yeah yeah i think here's here's a good citation okay good this one's that it was on archive for some time and then it was published here here's the ecosystems of intelligence or share intelligence and this kind of lays out i guess other people can also give their summaries i see it it doesn't make any technical advances or descriptions there's only one figure

um it's just laying out this idea of the interacting things through message passing this is the figure here's some manifolds and then belief updating interesting reading format and then um then they just talk about how message passing amongst diverse intelligences in ecosystems of shared intelligence

That's kind of the frame.

Then they describe these stages of development.

Kind of an interesting read in terms of their timelines, descriptors, et cetera.


SPEAKER_01:
Wow.

Yeah.

Thank you very much.

So it looks like in that paper they're describing like certain aspects of one agent's own model act as points of reference for other agents and vice versa so that you end up with this kind of like ecology of belief sharing.

A kind of collective intelligent intelligence resting on shared narratives and goals.

Again, not to to over relate everything here, but with the bird song example.

I had actually this past week took some time to actually read that paper itself, the birdsong one, not just its briefer description in the textbook.

And there's a lot of interesting things actually going on in that 2015 birdsong paper.

In some ways, this might be

is designing ecosystems of intelligence for first principles more than likely has some relationship there because the birdsong example, it's not just of course, it's not just about trying to talk about distinctly birds and songbirds and like, you know, as interesting as that could be from a biological or zoological or otherwise standpoint, it's really trying to get at something like how do agents

share information with one another and kind of entrain one another?

How and why do we see things like convergence of beliefs?

As far as biological organisms go, we can see synchronization of things beyond the words.

We can see whenever two people are talking to each other, the rate of their speech tends to begin to converge over time or exhibit near identical characteristics.

The kind of vocabulary that people use tends to kind of sync over time as well.

And then, yeah, there's so there's this kind of shared narrative, a kind of, you know, from a single agent perspective, the single agent is starting to model the behavior of the world around it, the process as well as its own.

two agents might start to model each other and in a sense uh they're the birdsong paper claims it's not just that once you get to this multi-agent setting where where the agents are in training one another and starting to show identical behaviors and internal model mappings and

modeling of the world of each other.

It's not just that they're modeling the other bird's behavior or their own behavior.

They phrase it as they're beginning to model like our behavior, like there's a kind of collective behavior on the horizon here that they're starting to model.

Yeah, I just think that's a very, very interesting and potentially one of the core aspects of trying to

to get into this kind of collective intelligence synchronization kind of logic here.

Yeah.

Yeah.


SPEAKER_03:
Great point.

I mean, when it's on a one dimensional manifold, like in the extreme case or even just as a heuristic, like if 80% of the variability is captured by one number,

like you're on a one-dimensional manifold on the two-dimensional space that's the that's what a manifold is and then yeah you're totally right this is not really a uh it's not an ornithology paper in the traditional sense because it is about hermeneutics and it is with this other joint paper that they reference that's like a twin paper

And so it's totally interesting that it has a lot to do, like you said, with narrative and with interpretation.

Here, they take a dynamical systems approach to interpretation.

Later, that is also expanded and complemented by the quantum reference frame, Chris Field's syntax and semantics work.

but this is like a perception action grounded dynamical hermeneutics.

So not addressing all semantic or semiotic questions, but like how dynamical systems can have general synchrony, which doesn't mean doing the same thing.

It can mean mutual information increases

through differences like or in um in the chris fields setting like the the principle of unitarity and likes that systems um come into entanglement with each other and then that was discussed like does that mean that they go to the same states like no not necessarily can i say as a counselor


SPEAKER_02:
who goes into conversations with people where they know their world, but maybe they're stuck.

And I don't know their world, but I have models of how to get unstuck.

Wow.

Very, very, very interesting.

Thank you.


SPEAKER_01:
yeah no super super interesting, I mean, I think.

I think there's enough to go off of here at least theoretically that potentially one of the key.

aspects of.

counseling as well as other things, clinical therapy and so on, is that just basically a so-called talking cure or some such things for someone who's having a kind of repetitive

uh you know behaviors or thoughts or you know whether you want to view them from a symptomatic perspective in the cases of like i don't know depressive rumination or a variety of other kind of things that come up like in one sense from an active inference perspective it might be that someone is having something like difficulty with belief updating and that by talking

like actually just talking with another human being, you might see the person who's who's the client.

You might start to see them like, you know, not not to be too theoretical or kind of philosophical here, but there's almost a kind of potential sinking to some degree of what we might call their internal states or their behaviors or otherwise with that of the counselor or the therapist, you know.

whole different set of questions and and research to be done or research that's already been done just try and claim like that that can have a long-term impact of course like in counseling or therapy like there are regular sessions so you're getting like repeated instances of these these temporary sinking uh syncing up episodes going on and then another aspect of course is that the counselor or therapist they don't want to actually themselves


SPEAKER_02:
imitate um the behaviors being seen by the client they want to help not match um but yeah just you know just try and extrapolate a little bit here that's why we have a fairly precise definition of empathy it's as if we were feeling the same as our client as if we were in their world but not actually being in their world


SPEAKER_03:
i have to leave thank you so much all right sure next time towards chapter nine thank you andrew so see you all next time bye take care