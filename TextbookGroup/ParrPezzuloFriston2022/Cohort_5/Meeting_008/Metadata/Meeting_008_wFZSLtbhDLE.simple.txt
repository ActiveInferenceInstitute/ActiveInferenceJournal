SPEAKER_00:
All right.

Hello, everyone.

Cohort 5, it's our first discussion on Chapter 4.

So, does anyone want to give just any thought on 4 overall?

Just any aspect of what they expected or got from it or however far they got or some section that was...

Just interesting to them.


SPEAKER_04:
I have a question.

So.

One kind of generative model that I am familiar with is one way of representing a generative model is using Markov decision process or partially observable Markov decision process.

This is for discrete, the discrete case of generative modeling.

I'm wondering,

What else what other what are other very popular or common structures that are used to.

write down or express gender models.


SPEAKER_00:
Anyone want to give a thought.

I would say one alternative way to write down parts of generative models is the continuous time.

But are you asking, is there another way to represent discrete time generative models other than with a POMDP?


SPEAKER_04:
Right, to begin with, because of course there's the whole other area of continuous time, but...

There's one important aspect to the whole question of Bayesian inference, which is, or some agent, some organism that's implementing Bayesian inferences.

How does it not only learn the parameters of a generative model, but how does it also learn the structure?

of that model.

And this is connected, for example, to questions about nature versus nurture and development in humans or animals, like what are the initial conditions, what kind of either inductive priors or like

um structure biases does our neural architecture uh provide us with from the very beginning and whatever it doesn't provide us with how how do we figure out what kinds of structure is appropriate for for modeling a particular domain


SPEAKER_00:
Paul, do you have any thoughts?


SPEAKER_07:
Well, first of all, about the initial states of any system that I mean, it doesn't always in active inference modeling, we don't always assume

Any agent like Tabula Rasa, I mean, we don't always begin from scratch.

So in most cases, we necessarily impose some initial conditions in order to make it more efficient to model the exact behavior or phenomenon of interest, because otherwise

we won't be able to model the whole process.

I mean, all the emergent properties that the agents have acquired through their lifespan.

So it is...

it wouldn't be feasible to try to put everything in such an encapsulated form of generative model in order to encompass the agents

uh entire uh i mean experience and lifespan so it is necessarily uh more focused than that and it addresses a specific problem uh we're trying to uh we're trying to model so uh

I guess it's not something a priori, and it isn't any prerequisite to model any situation.

But when it comes to how an agent acquires those initial learnings, those initial states, well, obviously, there are many, many ways to

Kaveh Khoshnood, address that problem.

Kaveh Khoshnood, With with various perspectives, but.

Kaveh Khoshnood, Of course, FAP or active inference, in my opinion, is not.

Kaveh Khoshnood, A theory or a framework that can answer.

every question regarding to the behaviour of the agent in every possible situation.

So we need to look for other granular problems in order to account for the lifespan experience of an agent.


SPEAKER_04:
Got it.

Thank you.

So just to kind of reiterate and clarify this response for myself.

In my mind, I kind of related a bit to the one hand, this distinction we we often need to make and keep in mind between and a realist interpretation, active inference and a instrumentalist one where

the latter is us taking this mindset of like, okay, there are agents out there in the world, there are things out there in the world, and they do stuff.

We can't be completely sure of exactly what they're implementing mechanistically, but we can develop a framework.

for making some sense of it for ourselves and part of the way that we make some progress on that making sense project is to use our own suspicions use our own power knowledge to to write down or express or postulate some some structure to postulate some generative model uh and then we can we can

active references or templates where we can input that generative model, perform inference on it, and then perhaps eventually make some predictions about the behavior of the system and compare that to what the system is actually doing.

But something that you're pointing out is that within the context of the framework, there isn't necessarily some

uh procedure for figuring out okay if you didn't have this uh these priors about what what it is that the generative model could look like uh and and

I suspect we suspect that, for example, humans don't come with all of the structure that they need embedded from the moment they're born in order to model the world.

Maybe they have some structure built in, but they acquire more of it and learn more of it over time.

What's active reference is is not doesn't have all the tools.

To perform that learning of the structure you that's also an area of work that's.

You can do, but it's not.

explicitly.

Part of active reference.


SPEAKER_07:
Just to clear up a little bit here, because you see, even in the very fabric of the first principles of active inference, namely the free energy principle.

So the free energy principle assumes the existence of code-uncode things, and then try to characterize what would the existence of those things constitute.

Okay, so it doesn't necessarily provide an account for, I mean, how the existence occurred, how those emergent properties arise from

Um, uh, from, uh, from lower causalities, uh, of course it can describe, uh, those causes relationships by assuming that those, uh, uh, emergent phenomena.

uh have happened uh already so uh it takes as the very first as the very first step and as an initial uh as an initial uh state the very existence of those things right uh so when it comes to uh modeling um

an agent's behavior within active inference framework i believe the same mindset applies here as well so it doesn't necessarily account for the how questions but rather to it it tries to characterize the what questions

I'm not sure if it clears up your question here or not, but it's not an account that tries to, let me put it this way.

if we have this system at our disposal that we we try to understand the its mechanism or or the way it behaves active inference provides a comprehensive tool to write down the behavior of the agent

within specific mathematical technology but it doesn't necessarily account for the emergence of that agent it doesn't necessarily account for how that agent emerged at the first place so that's one of the misconceptions about free energy principle

and active inference, because some people think that free energy principle being the theory of every code unquote thing would necessarily entail accounting for the emergence of those ontological entities.

But it's it was never the claim of free energy principle.

So

Yeah, it takes the existence of those things as the given and then try to describe those behavior.


SPEAKER_00:
Thank you.

Inks, then Andrew.


SPEAKER_01:
Hi, I have a separate question, but now I got involved in this so, but I do want to understand, so if we were to model like super deep seek temporal modeling.

of a person as they're born and they go through their life if someone was sitting there active inferencing everything that they're doing that would account for the development of the faster prior updating of priors and the slower updating of generative models right that would somehow build like a human with their understanding of the world not build but model how they become themselves


SPEAKER_00:
I mean, to the coarsest approximation, yeah, you could make a generative model that included decades.

Would that mean it would give useful insights or interface with empirical data?

Not at that coarse graining.

Could it be developed to be richer and more useful and meaningful?

Interesting question, but I don't know.

Does anyone else want to give a thought on that?


SPEAKER_01:
Well, I would find it useful.

I do have another question though.


SPEAKER_00:
That was just... Okay, yeah.


SPEAKER_01:
Okay, sorry.

So this is from the book, page 77, where the figure 4-4 describes the Bayesian message passing.

So my question there is the black circle one,

the one that says intuitively current beliefs about states under each policy at each time are compared with those that would be predicted given beliefs about states at other times.

So this is the statistician inferring by comparing different predicted states at different times.

Does that mean?

is basically time flowing left to right and you're trying all these different policy policies or are these alternative policies about something you can do right now and you can do different things about it and you're trying them out in your mind is this time flowing left to right or are these in my mind like if i do this this will happen if i do this this will happen


SPEAKER_07:
and i compare them in my mind almost barely like they are counterfactuals to each other thank you yes ali uh okay so there's a distinction in active interest literature between uh the time as uh

T as the letter T and tau.

So more often than not, when active inference researchers use the letter T for time, they mean the flow of time as we know it.

I mean, the intuitive time or our perceived time.

But when they use tau, it doesn't necessarily refer to the flow of time, but rather

uh to uh to the steps uh that an agent uh would take in order to achieve a goal so uh tau in a spec in a particular moment is not necessarily uh

I mean, the time interval between two taus are not necessarily equal, right?

So it tries to model the specific steps of the decision-making or the action taken to achieve a particular goal.


SPEAKER_00:
Thank you.

That's one aspect.

I think, does anyone else want to give another thought on this?


SPEAKER_01:
Can I clarify, my question is, are there counterfactual policies that only one will get implemented or is it step after step of of enacting like a project of long a strategy of many policies so.


SPEAKER_00:
in the pseudo code usually as implemented during the policy updating so going from the policy prior to the policy posterior that's using the expected free energy so that's when different policies are being considered so policy however long it is it's going to start with your next action and then include that many steps out

So then if there's four options at each step, four affordances, so you're going to do policies of step two.

So there's 16.

So then in the pseudocode, there's 16 policies, and then there's the prior.

So if they're all equally likely, then they'll be all even.

Then all of them are iterated over in a loop.

And then while each one's getting iterated over, it is rolled out.

And then they're all compared at the end, resulting in the updated distribution.

And then so let's just say it's 80% for the first option, and then 10, and then five, and then a few.

So then you could draw from that distribution and choose to do that, or you could pick just like the best option.

Which is actually something that Magnus discussed in this live stream 55.1, which is about this message passing.

Because it's kind of a lot to it, but also it's a very important relationship and also one that's not really addressed in the textbook just a few times kind of dropped in.


SPEAKER_05:
uh okay andrew and then anyone else yeah i just wanted to give my stab at uh the prior question um it seemed to be asking what active or the free energy principle is or isn't and um to me it it's a set of constraints it's it's telling you what open functions and functors

namely your C's and your Q's, if I am correct, can and cannot do if they are to be an entity that persists spatial temporarily.

So it doesn't tell you what those functions are.

It leaves them as three variables, but it constrains their behavior.

So I guess it's a different way of thinking about things than thinking about like what is force equals mass times acceleration.

It's not showing transfer of energy.

It's saying where energy is constrained to go if something is to persist over time.


SPEAKER_00:
yeah that's very interesting um also this this is one one paper the title kind of summarizes this very simple yet perplexing argument by Axel constant it's not about what it takes it's about what took you there so it's pretty interesting um raw


SPEAKER_04:
yeah can you elaborate what's your interpretation of that pedal is.


SPEAKER_00:
Of what is.


SPEAKER_04:
Of this title it's not about what it takes it's about what took you there.


SPEAKER_00:
I think here is said really well.

So just to generalize it, if something exists right now under the right conditions, it's because it's done something like minimizing its free energy.

So it's as if it's used variational free energy.

However, the question of whether it will exist tomorrow cannot be settled purely by resorting to the fact that it will minimize its free energy to get there.

So something could just,

All just you know it's I don't it may also be like saying like past results is not future performance or something like things could change in the niche.

So it's it.

Including it minimizing free energy right to the end.

So there's kind of a few other aspects but but um.

yeah and related to as Ali mentioned earlier like conditioning on a thing existing by by choosing that kind of boundary of framework then there's questions that aren't being addressed and ones that are but yeah right so just to clarify my original question um


SPEAKER_04:
So definitely we in order to be able to apply any of this of these ideas, we take for granted.

We take as as assumed the existence of Markov blanket, which is what gives our definition of a thing.

my question is about uh so already assuming that a thing exists and it has its its boundary uh internally it is representing is encoding some uh model of the generative process that's going on outside uh in the world and it's um

uses perception and action to make sure that that model is as consistent as possible with its observations in the world.

So my question is about what's inside that generative model.

For example, in the case of a POMDP, which is one way of representing

a discrete time generative model, there's some structure to what that POMDP looks like.

The way that we write it down and what are the parameters.

And I need to become more familiar with the actual degrees of freedom, so to speak, the different things that you can add or take away to construct different varieties of a model.

But let's just take that POMDP.

Christopher McConkey- category as an example, and the way that I am thinking about it right now.

What what you have is, as you're

incorporating this this generative model, you have some parameters, and over time you update the parameters of the perception.

You update the parameters of that dinner model to be more consistent to reduce your free energy to minimize your free energy.

but my question is about the structure of that generative model, not just the parameters, but, for example, if it's a Bayesian network that is describing the causal links between some hidden variables, some causes, causes in the world and the observations that you're receiving,

that Bayesian network has some structure.

There are different nodes and connections between that.

And somehow you have to figure out what should that network look like?

What should the connections between nodes be?

And what should each node represent?

And so I'm wondering if within the context of active inference, there is

there's a procedure there's procedure for exploring that structure or for given a thing that already exists, how does it the its general model evolve, not only in terms of its parameters.

But more.

Generally, in terms of its structure, maybe this is related to the idea of hierarchical models which I haven't learned much about yet but.


SPEAKER_00:
yeah maybe i hope that to clarify a bit more of my question yeah two short answers first there's structure learning that is the whole question of modeling and but that's what the question of modeling is that's why it's just not done just by thinking about it because you have to fit the base graph to be capturing whatever factors you're modeling but also this paper and some other ones in that area approach the structure learning

And also in live stream 54 with the learning structure versus structure learning discussion that Toby uses.


SPEAKER_04:
Excellent.

Thank you.

Did you link these somewhere?

Oh, yeah.


SPEAKER_00:
Just in where the notes are.


SPEAKER_04:
notes for chapter four four thank you so much yeah all right any other like thoughts on four or some section that some one found interesting if no one else has a question about four i have a question about

uh inference algorithms but but I want to give everyone a chance to to answer questions does anyone have like any overall thought on four yeah okay Andrew


SPEAKER_06:
Sure.

I was still kind of reflecting on the question earlier about message passing.

And I feel like I'm going to mix some things up here.

But so that's back on figure 4.4.

And I was just thinking about the question of counterfactuals.

Because, I mean, if an agent were to, and you'd have to, of course, like model them, you'd have to construct them in such a way that they were able to engage in planning.

Adrian Holovaty, Which I suppose would involve minimizing expected free energy G. Adrian Holovaty, So in that in that case, whenever one is engaging in.

Adrian Holovaty, You know, planning, we could model that.

Adrian Holovaty, Then I guess is someone I mean they'd be comparing counterfactual in that case right they'd be comparing different potential policies that they have not already engaged in or.

potentially are already underway um in some way but like you know maybe you're so far along the way in your series sequence of actions associated with a particular policy or you haven't started it yet and then from there the idea is you would go with the policy that has the highest

Michael Prast- Probability is it right you'd basically you'd go with the policy that minimizes expected free energy, which would also like whenever we look at that in terms of a distribution over policies and be the policy that has the highest.

Michael Prast- probability which you end up necessarily going for.

i'm just trying to because i'm slowly learning how important it is to specify when you're modeling like all these factors and things can get a little blurry whenever we start speaking a little bit more philosophically or from real life experience i'm just i don't know if all of that made sense right but uh just throwing that out there just a quick uh clarification


SPEAKER_04:
question uh you brought up counterfactuals in relation to action planning and then daniel wrote down here planning considering future time steps is all counterfactual uh what that brings to my mind is that the way that

um we're thinking about inference sorry planning inactive references uh imagining the outcomes of different policies uh and rolling those out into the future and then computing the expected free energy over those rollouts for each policy um

And then you kind of score the different policies according to their expected free energy.

And this kind of gives you a distribution over which policy you expect to take or which policy you believe

you're you're going to take um but but it seems like you you maybe like you sample from that distribution so it's not like you you just uh take the um the policy with with the the lowest expected free energy if that's not true please someone uh dispel that


SPEAKER_00:
yeah right yeah all planning is that's one kind of counterfactual counterfactual just being um considering something that is not a factual like observable so anything about the future time steps is counterfactual um or like alternative pasts but then considering the future it's all counterfactuals and then this is also kind of from figure 5.4

this is that section of taking in habit and then either passing habit through the policy prior or updating it according to expected free energy.

But whether habit is passed through or there's an update, then the most likely path

results or that distribution is sampled from yeah Jesse these are two yeah these are two possible selection methods either maximum posterior or sampling those are two methods of policy selection given a policy posterior


SPEAKER_02:
i guess for me uh what i'm attempting to do is i mean because quite frankly it's all a little bit over my head but um trying to pull this back from like a lot of this conversation you know we're we're trying to apply this to conscious processes which i think makes it a little bit more difficult in some respects because there's so much you know

it's philosophical baggage um and so in the last section of this chapter even though I don't really understand the uh application of like a little um no I'm sorry it wasn't the Laplacian uh approximate yeah the Laplace approximation uh on same motor reflexes and trying to think about

this like even thinking about the the message passing framework uh in a purely physiological paradigm where the message passing is say you know the sensory response from the you know the doctor hits your you know under your knee with a little rubber hammer and either you're going to have a reflex response or you're not

And so in that respect, if I try to look at the counterfactuals or the policies, not as some conscious process, but as a purely physiological one, it just kind of, I think for me, makes it a little bit, and maybe I'm on the wrong path and just misunderstanding it, but for me, it's just making it a little bit

more simplistic, I guess, to deal with all the symbolisms and the idea of gradients and the idea of, it's not like we're consciously always doing this and undergoing the statistical process, but this is essentially a way of understanding the probability that given certain factors and parameters, your knee gets hit with a little rubber hammer and

you kick or you don't.

So I guess I just wanted to kind of throw that out there for possible direction.


SPEAKER_00:
Yeah, I mean, it's very true and relevant that that not not everything maps or just people may have wildly different maps of what features or psychological experiences they mapped like different intuitions about these concepts.

So it's a huge space.

Andrew, then Ra.


SPEAKER_06:
I don't want to be redundant.

Daniel pretty much summed up my point, but it's, yeah, I think it's more about just thinking about it as far as like,

like take the perspective of someone who's modeling.

Think of like, you could produce a model of like a person or some other phenomena, whatever agent you're looking at, and you could include planning as like an entire sort of dimension, so to speak, or layer to,

your model but that could just entirely be foregone i imagine most people who are trying to model you know uh reflex arcs and looking at yeah the movement of joints in response to you know the pressure at this particular spot probably from an active inference approach i imagine would not include planning in the modeling process meanwhile of course if you're trying to model

someone thinking and consciousness or however close you want to come to that.

I think last week we discussed the neuro phenomenology paper.

I could drop a link to that again, but like that kind of modeling, certainly you could include planning as a dimension.

And I bring this up again because it's just that's what I'm slowly learning with active inference is like, while I enjoy the philosophical discussion, I think it's super important to just think about like from a modeler's perspective, even though that kind of like can remove some of the magic of of the process.

But it's it's you choose what you're going to include or not include in the model, I suppose.

Right.

um i think i i just hope that that clarifies anything it was clarifying to me to start to understand yeah just to connect to um thomas parr's guest stream


SPEAKER_00:
um and like a little bit of the development of different generative models because chapter four is where the generative models being described seven and eight will go into more detail into the discrete and the continuous time but chapter four is kind of like just considering generative models um generally so the early implementations were in continuous time then people were thinking about how to get sequential Dynamics

that's discussed in this textbook with these predator prey type models so that is like where there was repetitive cursive writing so it was doing like repetitive structures

but it was in a continuous state space of time um then they started going more into the explicit planning explicit like the pomdps kind of tied back to the earlier discussions that we had so um and then

later um the continuous models were used at the more like sensory motor layer and then the discrete state space models at higher levels of decision making just want to make that point thomas explains more but yeah

Any other thoughts on 4?


SPEAKER_03:
Yeah, I'd like to chime in just a bit.

So I think it's worth noting that this whole active inference is still very much in its infancy.

And

you know, there's a lot to work out.

I mean, you know, when we talk about, um, and you know, to Jesse's point is that, you know, there, there is no authority here.

I mean, we're talking about how humans model their lives.

And so, um, yeah, the assumptions that not only the modeler has, but I'll say the person has is going to, um, you know, bear

on the counterfactuals and so you know to produce a model of a person you know we can't really discount the fact that what they're perceiving is not reality so

I hear a lot of assumptions.

So I question these assumptions, and maybe it's because I'm coming out of worldly mapping, but there's just a lot of assumptions that bring up questions for me as to the accuracy, which is the intent of the whole project is to become more accurate.


SPEAKER_00:
Thank you, Susan.

one approach there because I I really agree with with a lot of what you raised um by using similar terms and just being clear about what terms we're using then some expressions can be evaluated and then and just sort of like very carefully understood

And then different people may still make different claims about the same topics.

Certainly, that's what discourse is.


SPEAKER_04:
Right, that's a very interesting aspect of this cohort and the Institute more broadly, which is, as I mentioned, Susan, this is a very stair of the art, a young kind of project.

um and the institute is part of the group of people who like everyone here and i'm just trying to understand the framework is participating in developing it and carrying it forward but also something that i know that the institute is really um

working on and keeping in mind is how to optimize this process of doing the science of thinking about the ideas collectively.

And as Daniel just mentioned, part of that is to the extent that we engage with each other more often and have these discussions together and use

the most precise language that we can, the ontology and become more familiar with the ontology.

Then we start to become kind of like,

almost an approximation.

I have like a mathematical approach to thinking about it, because in math you have very clear definitions for everything that you're working with.

So this is very helpful that we're becoming more familiar with the concept and the terms and then using them in a shared way.

where that hopefully makes sense to as many people as possible in every session.

But it's also really excellent to have people who are maybe less familiar with some of the technical details, because then you can stop

uh others and say like hey that's um isn't completely clear to me or i'm thinking of it from this more intuitive perspective can you uh explain how my intuition lapses into your hands to the terms that you're using yeah thank you um andrew


SPEAKER_05:
Yeah, quick follow on to that point.

I was hoping the ontology on our, what do you call it?

Our epistemological space had a lookup table for the equation symbology.

And I didn't find that, but it'd be really helpful if there was like words or something I could do for lookup cards

to help embed that ontology built into the active inference textbooks equation into my brain.


SPEAKER_00:
It's a great idea.

Definitely something we've considered.

There's several steps that we know we'd have to do.

So like in our literature analysis from the end of 2022, we annotated the number of equations in each paper for several hundred papers.

Obviously, we have that information for textbooks.

So determine where the equations are.

Then, just like we have for some of the equations, but not all of them,

develop the natural language descriptions using the ontology terms, that natural language description would be including all of the terms that you need to include, make the mapping between the symbols and the ontology terms.

I mean, it's a project that the ontology will include and other features pending slash admitting people who want to do it.


SPEAKER_05:
Thanks for pointing that out.


SPEAKER_00:
Yeah, but it would be epic.

And if you want a subpage or if you want a form to do it in, let's figure out how to do it.

Yeah, Susan?


SPEAKER_03:
So if I'm premature in asking this question, just say so and we move on.

But before equations would

become accurate, wouldn't it be a matter of pattern languages that would be more of a broad scope to be able to audit the equations by?


SPEAKER_00:
That's a very interesting question.

yeah a lot of ways you could say it the equations are being evaluated according to kind of standard math so if we consider that as a pattern language like math is a pattern symbol set then and also the equations equations are usually trivially true

because they're codifications of assumptions basically yeah they're manipulations of of what is brought in to the formalism right so then that has a certain epistemic status it's not nothing there are theoretical and mathematical findings that that are they are real findings but that that doesn't justify or or imply direct application to anything of anything


SPEAKER_03:
Okay.

Thank you.


SPEAKER_00:
Yeah, like making it more like a living textbook with re-rendering equations with the natural language or making the variables compatible or using the computer variables.

of those could help a lot otherwise there's a lot of variability in which notation are used and to what extent notation is described like hopefully to a limited extent in a textbook

But still there's a lot of notation in the textbook and it kind of like shifts among the chapters, just bringing in more variables, not necessarily like using one core set of variables, which would be hard to do, but that's not what they do.


SPEAKER_03:
So one more question.

Since we're at the top of the, um,

would it be premature to announce that we're we have a special guest that might challenge our assumptions on um physics Daniel I mean we'll we'll announce it when it's organized but yeah that sounds good


SPEAKER_00:
anyone like have any thoughts on chapter four or like or what they want to ask about next week

Anyone have any other thoughts on 4?

Yeah, Inks?


SPEAKER_01:
I just want to say I love this...

They're not equations, but the ones that look like waterfalls that go in different patterns.

It's very inspiring to see them.

And just to express gratitude for you guys.

You are saints to do this with us.

To just sit here, Danielle, and try to figure out what the hell I mean when I say that and want to help us understand.

I don't know that you guys get enough appreciation and gratitude.

So just saying that.


SPEAKER_00:
Thank you.

Yeah, it's awesome that people come out and care and it's interesting topics.

And even without even understanding only at this level of zoomed out.

It still is pretty cool.


SPEAKER_05:
I want to second that.

Thank you, Daniel.

Yeah, thank you.


SPEAKER_02:
A hundred percent.

It's amazing.

All you guys.


SPEAKER_00:
Yeah.

Everyone updating generative models, learning about it.

We can only do like the tiniest amount in the synchronous times, but you know, yeah.

Okay, cool.

See you all next time for part two on chapter four.


SPEAKER_04:
Thank you.

Thanks, everyone.

Great to see you.

Bye.