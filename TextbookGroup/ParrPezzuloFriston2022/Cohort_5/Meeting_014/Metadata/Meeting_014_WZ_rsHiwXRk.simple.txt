SPEAKER_00:
All right, it's February 5th, 2024.

We're in the 1st discussion on chapter 6 for cohort 5. so, Andrew, thank you for.

Facilitating everyone feel free to raise your hand and everything and Andrew go for it.


SPEAKER_03:
Sure, so chapter.

6, we're beginning part 2 of the textbook.

Mike Wilberg , The Capacity Collective, This is basically yeah it's describing a recipe for designing active inference models we get, as we know from part one specifically Chapter four especially we're already been introduced to.

partially observable Markov decision-making processes as a discrete time version of kind of one of the sort of exemplar active inference models that's used in a variety of behavioral experiments, as well as the continuous models in continuous time.

And so this is kind of just getting into more of like, how do we actually begin

like given in part one, we've been introduced to a lot of the main principles and kind of the framework of active inference.

Now we're being introduced to how to actually construct the models ourselves.

So let's see.

So yeah, the first part we have,

the introduction crucial to find when designing an active inference model.

You want to specify your system of interest.

For me personally, it was easy coming into active inference to have big ideas of what to apply active inference to.

because, of course, it can be applied to a variety of living organisms or other systems.

But really, whenever you want to design your own project, you do need to specify a system of interest.

What is the problem?

Some other thoughts are like, what are the expectations you have of what kind of behavioral

like emergent behaviors you might see or expect to see versus what ends up happening whenever you put your model together.

So really, one take on it is to really just start from basic principles.

Like we have part one of the book.

We know much more about something like how active inference works.

Now start to use that as a tool for, yeah, kind of shaping your project or your experiment you want to put together.

So you kind of simplify and grow outwards from there.

Section 6.2, there's a very nice brief like designing an active inference model in four steps.

Again, number one immediately, it's which system are we modeling in the context of like statistical Markov blankets, like how do we define

the generative model versus the generative process.

What is the agent you're trying to model and what defines it and how do you distinguish it from the environment or the process that's occurring around it in which it is operating?

What is the most appropriate form of the model?

Are you looking at, for example, some experiment that involves eye saccades?

um like continuous movements arc reflexes those kinds of things in which case you might be um going for more of a continuous time model or are you looking at like are you attempting to model uh an animal or a human uh operating in its environment in which case it might be um

It might be making discrete choices, in which case you're looking at more of a discrete time model or more than likely a POMDP.

If the agent's going to be choosing its actions and has a time horizon and you're including things like expected free energy, not just variational free energy.

step three, how to set up the generative model, choosing what are the appropriate variables, what are the priors, it's where you kind of get into the, you know, the meat of the modeling process, like what are all the specifications here we need to make in order to simulate your experiment that you're going for.

Michael Prast- And number four again the same thing, but now, how do we set up the generative process because, in the same way that you have to set up the model, you also have to set up the process in which it's it's operating kind of interacting with.

Michael Prast- So 6.3.

deeper discussion, what defines a model?

What defines the process?

Where do we draw the line?

What are the internal states, the model?

What is it inferring about the process?

What are the hidden states it's attempting to infer from the environment around it?

Because as we know, it has no direct

It has no direct access right to the environment around it, it can only infer.

get some nice further discussion in that section thing other things to consider nested blankets.

How the organism might use or your agent might use.

if you're modeling an agent in an environment in which it's moving around or acting like what kinds of objects are in the environment that it might use as potential affordances.

Moving on to section 6.4, what is the most appropriate form?

We get a little bit more discussion of things like time scales throughout 6.4, that's a bit more of a lengthy section with subsections in it.

You'll want to consider things like temporal depth.

They go into more detail in 6.4.3.

in which case, yeah, so for temporal depth, it's like, for example, you might have a POMDP where at the lowest level, you'll have, for example, say you have an agent in its environment.

At the lowest level, it's taking in sensory observations

very quick, the quickest pace, the quickest time scale.

And as it's doing that, those sensory observations, of course, are generating prediction errors as it interacts with the upper layers that might be happening at a slower time scale.

You could have nested levels, in which case, maybe at a higher level, the agent has various parameters that are being tuned.

They're then descending.

Those predictions are interacting with the ascending signals based on the incoming sensory observations.

Those are all things to consider.

Remembering from Chapter 5, you can have multiple timescales operating the same.

model, some things happen very quick, some things happen much slower.

And they kind of sink over time.

It's a lot of the remaining sections generally get into much of what I've already discussed here, we start getting into the difference between inference and

Learning tends to happen at slower time scales.

Those would be beliefs about parameters as opposed to hidden states.

So what do you believe the predictability of a state is?

For example, it gets into things like precision modulation,

Yeah.

Wraps up with talking about more detail on defining the generative process.

And then final section on just a very brief mention of how later in the textbook it will get into model-based data analysis.

they save going into too much detail about, okay, now you've set up the simulation per chapter six.

Maybe you've got some more additional details on how to do that in chapter seven or eight, depending on your use case.

And finally, chapter nine, data analysis, where you actually, how do we interpret these results if you're using MATLAB and SPM?

what do the, and you use a standard routine, which is freely available from the software package that Kristen at all released, like, what do these graphs mean that we're seeing once we run the simulation?

How do we do individual versus group level analysis?

So, yeah.

I feel like that was hopefully a holistic enough starting point for the discussion here.

Oh, thank you, Susan.

Yeah, first, first time doing that.

So happy to be here.

Yep.

Does anyone have any questions that they're thinking about anything that's maybe come up?

Like, or any particular topics or something they wanted to point to in the textbook, a certain page?


SPEAKER_05:
I have a question, can you hear me.

Yes, okay.

I wonder if you could talk a little bit about in the process of selecting a model.

How do you go about deciding what your markup blanket is going to be so.

From the modeling perspective, and you just elaborate on the markup blanket choice.

I'm very curious about that.


SPEAKER_03:
Yeah.

So maybe a good quick question.

Like, do you have an example of maybe, like, just anything you'd like to look at a particular phenomena or something that you want to understand better that you might try and make an experiment to try and study?

Anything we could start from there, maybe?


SPEAKER_05:
Um, I guess I'm, I'm too stuck in a conceptual space right now.

And I can't really do that.


SPEAKER_03:
But um, yeah, no.


SPEAKER_05:
Let me just say that from a very abstract perspective, from my question is, what is a node?

what is an edge in your in the models and where does a mark of blanket come in into the picture and how do you decide on the states that uh on the states that you choose if i understand this correctly about marco blankets that define the mark of blanket

And if I'm incorrect in my language, the way I'm describing these things, just let me know.


SPEAKER_03:
Sure.

I think all those terms are very relevant.

Edges, nodes.

We're kind of getting into the language of graphical models.

That's many of the models that this textbook gets into, especially in all these nice

um the figures of the pomdp for example those are all you know technically graphical models um so nodes you know i don't know if um i don't know if daniel would be possible maybe to pull up one of the figures in the in the textbook yeah just mention it and go for it and then maybe yeah which one

yeah um they don't have any in this chapter but i know that in the next chapter it gets into pomdps so there might be just uh find it and then put in the chat and then ali go for a first pass to magdalena's question yeah go for it


SPEAKER_02:
Yes, so thanks for asking the question because I remember asking the exact same question from Maxwell Hempstead about two years ago.

How can we identify markup blankets in modeling processes?

And I remember his answer was something to the effect that it's a very non-trivial process, and it depends very much on the situation of interest and on the specificity of the kind of modeling or the kind of questions you try to answer in each modeling scenario.

There was this paper by Ryan Smith Smith at all, I think it was from 2023 or 22 I guess towards the end of 2022 in which they used a very creative approach to constructing.

a kind of markup blanket in order to investigate the basically to model the function of the heart based on active inference.

Let me pull up the exact title of the paper, but I think it's a very instructive example

as to about how can we identify uh markup blankets even creatively in every modeling scenario because i think it's nothing algorithmic or formulaic about it it requires a bit of out of box out of the box thinking and creativity in order to

To identify suitable boundaries in the in the state space of the market blanket you're trying to.

you're trying to construct for each modeling scenario so i'll put the link in the chat.


SPEAKER_05:
Great Thank you.


SPEAKER_00:
Thank you.

I'll try to give another way in here.

So figure 4.2 shows some motifs in this Bayesian graph representational format.

So to your question about the nodes and the edges,

the nodes like the circles those are variables they could be fixed or they could be variable and and dynamic or not and they could be different types could be an integer it could be float and so on this is just very schematic and the arrows are like causal relationships that are here directed so then this kind of maps to x like hidden temperature in the room observable on the thermometer

Here, it's like there's two factors that influence the thermometer readings.

Here, one latent cause and two observables.

And here's like something that influences something that influences.

And so to select, to generate structural hypotheses and to select,

the different models and evaluate their differences like which ones are just like explaining the most variants but adding more variables always explains more variants so then there's these other constraints that are applied to the model like you want to explain the most variants parsimoniously like bayesian information criterion or you might have a fixed number of variables to work with there are all these other situational constraints

But because this is a mapping exercise and Markov blankets are just a feature of the map, like X being a blanketing state between B and Y, not carrying any philosophical implication beyond just its insulating role on the graph, which is the map, not the territory.

So there's a lot of techniques to identify, and it was very wise of Andrew to start with kind of starting with a specific system of interest.

um also the general inquiry is really interesting, but in practice, starting with the specific phenomena or system.

is like the starting point on iterating on something more specific.

which helps bring it a little bit more into the practical like which variables you're realistically going to take into account and which ones are like beyond the current scope of that modeling approach.


SPEAKER_06:
Thank you so much.


SPEAKER_05:
And if you could elaborate on what you just said about the, the, in that, on that figure that you were just showing is, I don't know if you can, yeah.

Okay.

So V and Y you said are blanketing X.

can you give me an example from models that you've worked on or other people where you know tell me what their x look like and what the v how the b and the y blanketed that x i'll give one short answer then andrew will look forward to your response so this motif


SPEAKER_00:
is very commonly used to constrain the structure of time.

So this is if X is the present moment,

This is like saying the past only influences the future through the present.

This is like the Markovian property for time series.

Because in principle, if you had 100 time steps in a model, you could have time step 11 influence time step 21 and try to learn a statistical parameter there, but then you'd end up with so many parameters.

So instead, under the Markovian

simplifying assumption that basically the present kind of like filters through like a bottleneck information bottleneck that simplifies it to only having to learn one parameter which is like the b matrix thank you thanks for that it helps a lot yeah


SPEAKER_03:
And actually, Daniel, I think this figure 4.2 is maybe even a better start versus what I recommended, just because in addition to trying to describe the specificities related to markup blankets, maybe just giving

um kind of an ex like a concrete example of the the graph in the upper left corner which the the textbook describes there um it's so we have right so we have um

the one impacting with a with an edge pointing towards the node that is the x and then uh the two is like so basically you can see that there's like a causal relationship here going down like one impacts x impacts two impacts y in in

very simplistic terms.

So we already know from earlier in the textbook, like a core part of a generative model is to have priors, which is the one, it's our P of X distribution over hidden states, your beliefs about X. Then one impacts what kind of, what do you think is going on right now?

What is the hidden state right now?

That's the X that you're inferring or your agent is inferring or your model is inferring.

And then that has a relationship with two, which is your likelihood matrix, right?

It's the probability of the incoming sensory observations conditioned upon or given the hidden state that you're inferring.

So basically with nodes and edges, as Daniel heavily covered, it's really just trying to figure out like, okay, what would be the causal relationships between the different things going on in your experiment?

And what are those things in the first place?

what are the particular hidden states?

Perhaps you have an example of a mouse navigating a maze.

The mouse might be taking in new sensory observations from multiple modalities.

It might be it can see where it's navigating.

It might feel certain things.

It might smell certain things.

But those are all things that you'd want to consider when constructing a model.

So those are all different variables that end up being their own nodes and what you end up building out into what could become a rather complex graphical model.

Similarly, what are the states?

Like maybe the mouse is trying to figure out

where it is maybe it's trying to figure out oh what is the source of that smell is it a reward is it well i'm pointing towards this example in particular because we'll see it in chapter seven i believe and also just to

Just I hope you can worry less knowing that chapter seven and chapter eight will get into much more concrete examples of different models as well.

And it'll maybe become a little bit easier to kind of tie the knot between all of the conceptual considerations and like an actual experiment that you want to set up.

But that's just trying to give a little bit more

on maybe how you would construct a model and knowing that we do have to understand graphical models prior to that.

It's just a big web of associations, right?

And they all lead to a series of computations.

And again, it's active inference.

And so the key part of this entire process being a series of computations in order to minimize free energy.


SPEAKER_05:
I think that's very helpful.

Appreciate that.


SPEAKER_04:
I have a question about the construction of models.

I think my confusion may be that I'm new to this process and it's early on, but this is the chapter that I want to most understand because I came to Active Inference with this desire to create a model.

for a long standing social science intervention.

My question is, when I first come to a problem, you don't always know the variables of interest.

And so that's part of why you're doing the experiment.

Is that not true in this case?


SPEAKER_03:
Yeah.

I mean it to actually any anyone I've had a discussion with who's worked on putting together, whether it be active inference models or any other model that might relate to another framework and reinforcement learning or doing other kinds of experiments.

Yeah, it's sometimes it can just be a very

Iterative process.

More often than not, most people, yeah, they don't know what all the variables are.

You might have a strong hunch about what they are, or you can, of course, relate them to like domain knowledge and secondary literature.

But more often than not, you may want to construct a model that uses what you know or think is highly likely that this is how this works.

Have a look at the results.

Look at what's going on.

If you're able to run the simulation, see what the output is, see if it makes any kind of

kind of sense um uh i have a social sciences background and so things like causal inference where we're like okay well what are the variables here uh what are the confounding variables here what are we leaving out what are the things that cannot be observed

If you start seeing what defines an odd observation is very context specific, but if you do start seeing results, it might point to the idea that you might very well be leaving something out.

Then you may want to also double check the complexity of your model.

say there's something at the lower level that you've defined everything makes sense it's at this time scale etc maybe there's a variable that's left been left out at another level maybe there's something else that's impacting all of this that's been left out that that isn't even occurring at the lower level that we've been focused on it's been at a higher level this whole time um

A lot of my explanation there might be might be a little vague, but again yeah it's just very context.

context sensitive, I almost want to say so.


SPEAKER_04:
No, thank you.


SPEAKER_00:
I'll add a few more notes on this.

So in the symbolic actin space and an institute participant, JF, his Lego robots using a logical program rather than statistical distributions, but the idea is basically the same.

It's like rather than a causal graph, which is like we're talking about the textbook, it's a causal theory.

And here he talks a lot about that incremental proposal

so you ask are the actual variables where they hypothesize latent they are actually hypothesized so they're enacted in their hypothesizing which is abductive inference

which is so generation of hypotheses and then evaluation of hypotheses so that's been analyzed as kind of like itself an active inference process because which hypotheses to propose and then given the hypotheses which actions to take for their to uniquely resolve and learn those are all questions that can be approached in active and then just one last technical note is this relatively recent

preprint with Friston et al.

This talks about a statistical problem called structure learning.

So here it's in the context of the digit MNIST data set.

This is a very familiar problem and data set to look across different handwriting styles and identify the digits.

And this work, which we could probably discuss more in a future time, goes into a lot of detail with the structure learning, which is like when you have 11 handwriting styles, should you propose an 11th cluster?

And then you evaluate whether the 11 cluster model or the 10 cluster model is better explaining the data.

It's like doing better on that Pareto optimal front.

And then like 11 is accepted.

And then like there's a proposal to basically to increase the number or decrease the number of latent factors and then there's a criterion for like accepting or rejecting those kinds of model updates.

And so that's a capacity that's existed for statistical models outside of active to kind of like adaptively dial up or dial down the dimensionality.

But it's not a totally solved problem, and it's not totally implemented in Act-Inf.

But in principle, a system wouldn't need to know the dimensionality of its environment because it might just have a... And it doesn't ever need to.

It could just be too cold, just right, too warm.

And then that doesn't mean that it ever needs to learn the richness of the continuous distribution of the temperature in the room.


SPEAKER_04:
Yeah.


SPEAKER_00:
that might be good enough for the air conditioner just to have three states or something.


SPEAKER_04:
Right, right, right.

Okay, thank you so much.


SPEAKER_03:
I guess I did want to add, there's a nice paper for anyone who's more interested in social science research or something along those lines.

There's been a very nice

series of papers put out by a researcher, Ryan Smith.

We have several live streams of him giving a tutorial on active inference with the Institute and specifically how to construct models in MATLAB for anyone who's familiar with that or interested.

I bring that up because he has this paper on simulating

what's called exposure therapy.

So this is research that is intended to aid interventions for psychotherapists.

Like, can we simulate, for example, a client who is suffering from some kind of avoidance or anxious disorder that's stimulated by something?

Say they have a very strong phobia of something.

um computationally it could be anything it could be a spider it could be you know seeing a car accident a variety of things and i so bringing it up like they had to construct a model of like how do you simulate exposure therapy

So we already know we have a client that we're trying to simulate.

We want to simulate them going through exposure therapy, being exposed to the thing that produces the fear and then to see like

this is a safe environment that we're simulating in order to test things out, as opposed to jumping immediately to empirical research that there are too many ethical considerations to just playing around with showing people things that trigger them.

So when constructing this model, you have to model, here's the agent.

You have to figure out what defines the agent.

In their case, the agent experiences affect or something like emotion.

compose that as a distribution, like what are the emotions?

They keep it very simple.

They go with something in psychology referred to as valence.

So you have a nice like positive negative scale.

There's been a lot of nice work on emotion in general from an active inference perspective that yeah, valence seems to hold up pretty well in certain contexts.

So they go with that.

And then you have, you know,

How does the agent deem the stimulus that they're being shown?

In this case, let's say the agent has a fear of the spider.

So they might interpret it as dangerous as opposed to safe.

So now again, we have another kind of sliding scale.

These are all what could be viewed as like continuous distributions, right?

Like they can be viewed as a number that moves into the positive, the negative.

Then you can take those kinds of things, view them as variables

then put them in the model.

In this case, we would hope that the agent being exposed to, say, a spider that ultimately is safe.

Again, bear with me that it might come off as a silly example, but say it's a fake spider.

This is exposure therapy.

We're not going to show them around a spider.

But to get the agent to slowly become more comfortable with being around the spider,

like we want those parameters, those beliefs about how dangerous the spider is to change over time.

So that also means you have to, we're defining the generative process, the spiders there, it's a safe spider, the agent is interacting with it.

over time as we run more trials we can see how do the agents beliefs begin to change do they change rapidly does the situation become worse are they being exposed to the spider and it's just freaking them out more they've become they're concerned that it's even more dangerous um and I'll quickly realize I haven't shared the link for that paper so I've just shared that

um anyway so without going into too much more detail because it takes some time um but you know if this paper interests you go for it um the whole idea here yeah is to to just you know thinking through what what is a variable what is considered as a variable and a lot of it centers around defining your agent defining the environment or process around them

and then trying to find the linkage between all the conceptual ideas.

Like I said earlier, affect is that there's plenty of domain knowledge on that in psychology.

How do you make a one-to-one ratio between a little node or variable in a graph with

Matt Kallroos- Research that's been done by your you know the field you're working from or interest in like in psychology, how do we make those connections that we can build out a model from there.

Matt Kallroos- yeah.

And so, yeah, Daniel's pulled it up.

There are different ways that people attempt to show their models.

This one, the notation is certainly different from the textbook, but I think it's more explanatory, right?

Like we have an agent who's being exposed to a safe stimulus or a dangerous stimulus, like a spider.

We have their beliefs about its safety or how dangerous it is.

They also have an arousal level.

You can include things like with psychological research and things like that.

We care a lot about physiological signals.

It's the agents like heart rate increasing, which by the way, you'd want to consider that probably to be a continuous variable because this is happening very quickly over time.

Whereas belief context, safe versus dangerous, that could be viewed as discreet.

We have two options there.

So those are also big concerns.

Like you figure out your variables.

Are they discreet?

Are they continuous?

Do they happen at quick time scales, moment by moment?

Like the agent very quickly is feeling their heart rate change.

And yet over time, as we run more trials with more exposure therapy sessions at a slower time scale, their beliefs start to change to ideally a situation where we can find, maybe use this model to find some insight into how to improve intervention for people suffering from phobias or anxiety that's generated by a particular stimulus.

So yeah, I hope that that provides some more insight into how to take a lot of this abstract or conceptual material and then relate it more directly to concrete situations and problems of interest.

Daniel.


SPEAKER_00:
Thanks.

This is a great paper to show.

And I think the figure here shows like this is like the semantic level, like not worrying about how big the variable is.

And so it's kind of like a little template that could be adopted just thinking about this situation of the exposure.

And then what is the thing that one is modeling?

And then what other phenomena do they need to further include?

Like planning is not here.

And then the bottom is actually the shape of the variables themselves.

The A, the B, C, and D of this agent, just like the POMDPs in the generative model and described in model stream one.

And these are the actual shapes of the variables and even their types ranging from this continuous belief to two by twos, affordance matrices,

with context preferences, what a flat preference looks like versus a sharp preference.

It's all kind of syntactically displayed in this flat lay.


SPEAKER_03:
Nicholas Matsakis, So anyone else have any other thoughts or things that you know they're kind of pondering right now regarding this chapter.

do we have any other questions that have already been maybe asked in the coda


SPEAKER_00:
What do you think are good small experiments to do between the first and the second discussion on chapter six, given what anyone has experienced or tried?

We could also look at a notebook, like look at an executable code right now, like a PMDP example, or we could talk about what, um, else could help supplement chapter six.


SPEAKER_01:
I think let's look at a pyMDP example, if it's okay.


SPEAKER_00:
Okay.

I'll put the link in the chat, but here's pyMDP documentation.

So this is the Python package by Connor Heinz, Alex Shantz, Daphne Namekis, et cetera.

There are several tutorials and demos in this open source package.

The simpler one, our tutorial one and two, then the team maze is most like the textbook and the epistemic chaining demonstrates.

It's kind of like a team maze, but with like a little bit more of an epistemic or a slightly different epistemic component.

And each of these tutorials very nicely provided by the authors.

There's like a co-lab notebook.

so just going to this and you can you can make a copy right from there um i'll kind of give it back to andrew to continue and then maybe next week we could prepare to execute something just so that we're not like needing to execute on the fly but suffice to say like these notebooks do work and you see a similar specification a b c d

That's what defines the POMDP, those variables.

They're representable in terms of this grayscale heat map visualization.

Sometimes black or white is one or zero.

You just have to look at the graphical settings.

But they describe how the variables are shaped.

And so it can help to just see like okay here's block by block here's all the variables that need to be defined here's what the different slices and the variables are.

Yes, copy and pasting images or screenshots or code blocks into language models is super helpful as they're very adept at this kind of classical.

basic code explanation.

And these notebooks just go through, define A, B, C. Let's see if we can collapse it and just look at the sections.

D, so A, mapping between hidden states and observations, ambiguity matrix.

B, transition matrix for the hidden states.

That's how the hidden states are inferred to change through time in this action-dependent way.

And then policy selections like selecting which slice from B is going to be used in the time evolution.

C, preference over observations.

D, the prior on the hidden state, which kind of kicks off the chain.

But after D is used once, then it's just B and the hidden state S unfolding through time.

So then to specify the agent, it's just taking in these exact four variables.

So adapting active inference in the PMDP setting to whatever it is that you're trying to model, it does come down to making the right shape A, B, C, and D. It's specified like this.

Here is a class object for the game itself.

So here's like where the rules of the game, like the slot machine or whatever, it turns out those at like, or if it's prisoner's dilemma, those are parameterized in something like this.

So it's like we defined the whole agent, general model, then the context, the environment that it kind of plays in.

And then here's the active inference loop.

And here's the pseudocode basically for that OODA loop, like observe, orient, decide, act.

It's basically like that kind of pseudocode invoking the specific game and the agent and the interface.

So this is not like what high throughput production active generative models look like.

But each of these tutorials are super informative because they do work and they are forkable and they do like capture all that's needed.

And so that can help demystify it a lot.

It's not like an infinite parameter fishing investigation.

It's like build ABCD underscore one and then try underscore two like a variant and just try recombining them

And it's about building like a portfolio of different a B's and C's and D's and agents and visualizations and diagnostics and summary statistics for the simulation.

And these notebooks go a long, long way.

And until you're using like large data sets or anything like that, PO lab will have enough computational resources.

Susan.


SPEAKER_06:
Thank you, wonderful.

So, yes, this, you know, in terms of defining an agent, and this kind of is somewhat inspired by Cheryl's question in terms of goals, roles, and context.

And, you know, what I find rather elusive and

intriguing is the overall objective of whether that be generative modeling or the generative process is are we seeking certainty or are we seeking insights?

And so in terms of

how I perceive, and quite frankly, I'm going to do a plug for my Thursday at 11 a.m.

foraging insight, because what I'm trying to do is really focus on how people self-model versus how we're trying to predict how people are going to react, which is

different than trying to program something.

So although definitely we want to be able to use technology to augment agency, this comes down to how do we help people discover their own agency and affordances within certain parameters?

How do we translate that into understanding the textbook?

Does that make sense to anyone?


SPEAKER_04:
I really like that distinction, insight versus certainty.

I've never heard that made that way before, but that's so clear.

Thank you so much.

So I can see a real problem when you enter

you know, an experiment, thinking that you're looking for certainty and you're actually looking for insight.

I mean, I can see how one could confuse those things when they're not distinct.


SPEAKER_06:
Yeah, like the whole risk management industry.


SPEAKER_00:
But to kind of go to equation 2.6 and then Prakash, this really does map to when we're selecting which experiment to design policy to undertake, the certainty is finding observations that align with our expectations slash preferences, sampling the homeostatic body temperature, like pursuing certainty about our homeostasis for temperature, and then literally the insight or information gain

and so and then this ties on this is a big topic so we won't go into it right now but different um scientific epistemologies like does science prove does it disprove oh well they confirmed this in an experiment so they found what they were looking for or they were shocked by this so then what did they expect and then our experiments for falsifying or confirming or neither


SPEAKER_06:
Barbara Kirby- And how we hold on to beliefs that may not be.

Barbara Kirby- prudent.

Barbara Kirby- But you know why we know why that's a surprise versus.

Barbara Kirby- You know, being able to belief update, so you know this really calls into question, you know what is learning, I mean that might be good good start is is what is learning.

because is learning consuming information or is it digesting it and taking action on it?

And learning from the action.

I mean, I'll borrow from something Daniel said earlier as is, and you might have to reiterate it Daniel, but yeah, moving the pebbles, moving the pebbles, that's what matters.

And until we actually act on the world, we're not moving the pedals.

We're just regurgitating and fall into rumination.

Wow.


SPEAKER_03:
I actually just shared I personally coming from like a computational psychiatry sort of background slash that's my current field of interest and I just shared this actually since you mentioned the word rumination and there's another paper elsewhere on

attempting to simulate rumination as a kind of cognitive process that can arise based on certain circumstances.

I shared this one in particular because it's one of the papers that I've seen so far that best tries to describe

um in a more kind of human relatable view um like what it is to self-model in one's environment because as we know like one of the bases of active inference is free energy principle

an agent needs to have an understanding of what separates itself from its environment in order to maintain itself.

Otherwise, however we want to phrase it from a physics point of view, the environment is entropy.

You dissipate if you just give in to everything that's around you.

You have to breathe in oxygen, you have to do a variety of things that maintain what is you versus what is outside of you.

It's really crucial.

I like this paper because it describes a little bit more in-depth for a human being what might be required or involved in self-modeling, how important it is to have a model of oneself, the role of things like sensory attenuation, which is another big aspect of active inference.

in order to move your arm you need to like be able to briefly put simply you need to forget that your arm is in one spot you need to believe that you can move it to the place you want to move it to so what you're doing is you're attenuating or kind of ignoring where it is right now you're in motion you're trying to be in motion right so if you overly believe like you keep that that belief fixed that your arm is in one spot it's going to stay there you have to move it um

That becomes really important when self modeling too, in order to operate in the bigger world around you.

So, so just all these finer details and aspects of self modeling.

I think it's a fascinating topic though, for sure.


SPEAKER_06:
So is, is that the paper that Andrew shared?

Is that the overthinking?

Is it covered in that?

Okay.


SPEAKER_03:
Yeah.

Yeah.


SPEAKER_06:
That's sharing.

Yeah.


SPEAKER_03:
Andrew Tucci, Norcal PTACC, he doesn't get into the its specific topic of interest is depersonalization disorder, but I think the first half of it is really broad and I just you know I think it's a nice introduction to just thinking about self modeling in general, regardless if you're interested in psychiatry or not.


SPEAKER_06:
cool yeah.

Thank you.


SPEAKER_00:
Paul Haney, For kosh.

Paul Haney, Andrew you can kind of end it, however, you want.


SPEAKER_01:
Yeah, Daniel, I have a basic question.

I was wondering the PyMDP which you showed, can it also handle hierarchical models?


SPEAKER_00:
Yeah, it can.


SPEAKER_01:
Okay.


SPEAKER_00:
I don't know if there's a tutorial on it, but we can ask the authors, but we can look through the literature and so on.

But yes, it can.


SPEAKER_01:
Okay, thank you.

Thank you.


SPEAKER_03:
I also mentioned that Daniel just put in the coda there.

I shared the Ryan Smith tutorials.

And while those use MATLAB, a lot of the PyMDP stuff, the coding, it's based upon a lot of what goes on.

Basically, active inference modeling generally started with MATLAB and SPM, which is what Ryan Smith

and everyone else covers.

And then Connor Hines and a variety of other researchers put together PyMDP, much of it being based on the prior work in MATLAB.

And so at least for a verbal explanation of hierarchical modeling, I believe it's either the second or the third video of the series with Ryan Smith.

If you

So I guess that would be like model stream 001.3 versus the one that's on the code of 001.1.

Just if you want like a more verbal explanation of kind of how that can work in a more direct coding setting as a programmer.

Yeah, just wanted to mention that.

And yeah.

I don't know.

I think we're just about out of time here, but just a brief recap.

This was chapter six, our recipe for putting together models.

Potentially it provokes more questions than it answers.

But I think it basically brings up all the questions that you need to be concerned with whenever you're putting together a model.

What is the agent?

What defines the process?

What are the variables?

Are they discrete?

Are they continuous?

do they work together how do we relate them to domain knowledge um and and actually translate between you know the the language of bayesian statistics and mechanics with uh if you're a social scientist or or um an engineer

And so, yeah, kicks off part two of the book overall.

The next chapter will get into continuous models.

And I think that's, it might be the case that for a good deal of people here who are interested in modeling, it might be the case that you'll be looking at

Jake Hamilton, A P m dp.

Jake Hamilton, Like that's what's used most frequently with trying to model like human beings in their environments.

Jake Hamilton, Animals as well, but they're used they they involve including things like planning a time horizon.

They don't have to, but they can.

And yeah, hopefully it'll give you much more concrete examples of thinking through like how do we translate between a model and what we're actually trying to do here.

Hopefully chapter seven basically will clear up some questions you might've had from chapter six.


SPEAKER_00:
Thank you.

Awesome work, Andrew.

Thank you, everybody.

See you next time.


SPEAKER_02:
Thanks, everyone.


SPEAKER_00:
Bye.