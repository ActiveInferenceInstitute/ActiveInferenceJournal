SPEAKER_07:
Welcome back, everyone.

It's February 12th and second discussion of chapter six for cohort five.

So any thoughts or feelings on where to begin with chapter six?

Like any thought or quote or question.


SPEAKER_00:
I have one.


SPEAKER_07:
Yes, please.


SPEAKER_00:
I'm not so sure it's in this chapter, but can you go into more detail in terms of the difference between the high road and the low road?


SPEAKER_07:
Yes.

Would anyone like to give a thought on high road and low road in the chapter six?

So really getting to the recipe and the cooking?

What are the high road and the low road?

Well, one thought is chapter six is a recipe for actually walking on the low road, because this is where the generative model is constructed and specified.

So it kind of starts from having nothing.

I don't know how deep we have or need to go into the food.

Maybe it's somewhere here.

I mean, what are the ingredients?

What's the kitchen?

What needs to be done in what order?

that's the low road of building any model there could be a chapter six for a recipe for designing SPM analysis or designing linear regression analysis as thousands of other guidebooks for modeling are out there so in that sense that all modeling and uh

John Gierkemaier, construction like this is low road because it's actually putting.

John Gierkemaier, model down that's what's similar about Chapter six and another recipe for basing modeling and then the difference with active inferences the connection through the high road to the free energy principle.


SPEAKER_00:
Janet Callahan, So that's in so relative to if I were to translate that.

And the model that I'm building is more of a self modeling, not trying to build a software LLM model.

So in terms of the low road is imagining the pathway and the high road would be taking the pathway.

Would that be a way to contrast them in a simplistic form?


SPEAKER_07:
What would someone else say?

Yes, Ali, and then anyone else who raises their hand.


SPEAKER_04:
Okay, so the high road can be described as a kind of top-down approach to active inference, which starts by asking some

very fundamental questions about what's required for any code-unquote thing to exist and what are its necessary properties.

So by beginning from a kind of, as Friston himself would call it, a near existential nihilism, it gradually begins to build some framework which can account for any sentient behavior

that agent must possess in order for it to possess its integrity and to persist through time.

So that's basically the premise of high road.

But on the other hand, for low road,

begins by asking it begins by the premise of uh the existence of the mind so here uh the the existence of the agent or rather the predictive agent is presupposed and then it begins to formulate or describe what kind of mechanisms

uh it can realistically describe uh its predictive behavior and it's uh i don't know brain activity uh or rather

the way that the brain constructs the inner model or, in other words, its generative models.

So that's basically beginning from the premise of the existence of mind and to describe what kind of mechanisms that

particular mind should possess in order for it to uh to do both inference and action in a changing environment but ultimately they uh they achieve a similar goal but uh as

Uh, the, I, I mean, the name of these approaches would suggest, uh, only the approach to achieve that same goal, uh, is different, but then again, uh, they basically try to, uh, I mean, describe the same kind of behavior.


SPEAKER_00:
So you threw me out with the near existential nihilism would, uh, would that, um, would that correlate with let's just assume they have agency.


SPEAKER_04:
Okay.

So, uh, all right.

So yes, agency is a kind of, uh, I mean, central presupposition for any kind of, um, any kind of thing that can meaningfully, uh, navigate through its environment and to have any kind of goal directed behavior.

So in other words, agency is a kind of synonym for a goal directed behavior.

It can be obviously, I mean, argued whether agency really equates goal-directed behavior, but that's basically, as far as I understand, that's the meaning of agency in active inference literature, or at least in the majority of active inference literature.


SPEAKER_07:
Thank you.

Christoph, then Andrew.


SPEAKER_05:
Jan-Willem Wasmann, yeah just want to say that for me to.

Jan-Willem Wasmann, kind of enlightening perspective on the on the long road is to simply derive the.

Jan-Willem Wasmann, uh.

an equation that features a free energy, essentially, from Bayes' rule.

So you can take the Bayes' rule, write it in such a way that you substitute another distribution for the posterior distribution, which is not generally known, with an approximate posterior, and say, OK, since I cannot know the true posterior, I'm going to approximate the true posterior of an approximate posterior using some kind of variational methods.

essentially using just the probability of ensemble probabilities and rearranging those equations a little bit, you effectively get to the point where you have a quantity that is mathematically isomorphic to free energy in thermodynamics.

So that's a kind of a very mechanical, mathematical way of teasing the concept of free energy out of, essentially out of nowhere, right?

Because you start with an equation that's true, Bayes rule, and then you make it sleight of hand where you just simply substitute, you know, Q for P and say, like, this is a slightly different kind of thing.

because I'm going to have a bunch of parameters that define what that Q thing is, and those parameters I can somehow tweak to find how good my approximate posterior is.

But because for simple mechanical substitutions like that, you can derive effectively an equation that looks like free energy, that's how you just get all the way from Bayes' theorem to the free energy principle effectively.

So that's kind of like why it's bottom up.

You sort of construct it this way.


SPEAKER_07:
Amazing.

Thank you.

Andrew?

Wait, I'm here, Andrew.


SPEAKER_03:
Just a cute analogy, I would say that Plato would always try to start with the high road, while Aristotle would see what he's got available and start with the low road.

And since we're trying to implement something, we gotta use the tools we have.

Rob Geddes, Accessible and so chapter six is seeing what we've got there and taking the low road to.

Rob Geddes, implement something that.

Rob Geddes, shows active inference.


SPEAKER_07:
awesome.

yeah great great comments here's figure one two it's a nice evocative figure also the the it's not like there's a strict sequence or like there's any it's like um some subway stations but it's not very strict and it's not like all or necessary sufficient or anything like that um but

it is situating active inference generative models as, on one hand, implementing Bayes' theorem, giving what Christoph provided, this kind of unrecognized

relationship between statistical principles of least action which we now call the basic mechanics and the free energy principle and how that's like an extension of other physics and information and thermal physics and yet all of that kind of like theory aside chapter six doesn't have any equations

chapter six is like actually the sequence although they um make clear like it's more about a checklist um than a kind of ordered sequence here

um but this is the theory um light sequence of questions that's actually procedural like a catechism to work towards doing a generative model to working in active inference into realizing the synthetic active inference agents whether it's about oneself um what that's human a system of interest or whether it's about some other system um

That's chapter six.

It's with only, it looks like that one figure and not any of these connections that have been brought up, which are super great and well said about the Bayesian mechanics.

So chapter six on the low road, but if you build it this way,

then by making an active inference model from the low road, it would be, you could run it in PyMDP.

So it would be kind of concordant with free energy principle.

And we have many examples we can look at.

We can look at the tutorials of PyMDP.

We can also talk more about the recipe of chapter six, but that's kind of the big idea of six

Anyone can raise their hand or.


SPEAKER_02:
Yes, I have a question.


SPEAKER_07:
Yes, go for it.


SPEAKER_02:
Yes, I wrote it in the chat.

What is meant by the first step, the identification of boundaries?

And then it says IE Markov blanket.

But I just want to say thank you so much for this very elucidating explanation for high load and low load.

I've read it several times and this is the best or finally it clicked.

So thank you.


SPEAKER_07:
Thank you.

So, great question.

Ali, want to go for it?

Or how does it come into play in the process of building a generative model?

Yes, please.


SPEAKER_04:
Yeah, I just wrote it in the chat as well.

So markup blanket is a kind of statistical boundary in the state space of the agent.

So in other words, it can manifest itself as a spatial temporal boundary or not.

So in some cases, for example, in

Roozbeh Gharakhloo, I don't know cell boundaries or cell membranes it actually manifests as real spatial temporal boundary but it's not necessarily so, and it can I mean markup blanket can be expressed.

variously in different forms for different situations, but basically it kind of provides a necessary statistical boundary in the state space of the agent in order for the agent to be statistically separated from its so-called environment.

So if there wasn't any Markov blanket delineating this boundary, then the behavior, the internal behavior of the agent would be identical to the behavior of the environment in which it's embedded.

So yeah, that's a necessary presupposition for doing any kind of active inference modeling around that system.


SPEAKER_02:
So may I ask a follow-up question?


SPEAKER_04:
Yeah, sure.


SPEAKER_02:
So in the case of swarms or plasmoids where an individual agent is impacted by the whole group, so would the same principles apply in characterizing the agent as the group?


SPEAKER_04:
Yeah, that's a very great question.

So you see marker plant blanket can be can be described in multiple scales.

So for instance, even for

So let's take the brain as an example.

We can draw a marker blanket around single neurons or around, I don't know, particular circuits, neural circuits, or around the whole brain, and even further than that, around the whole organism.

And there are some works that have been used for

they've used active inference for modeling the whole, some of the social and cultural behavior of whole communities or societies.

So in those cases, markup blankets can be drawn around a whole community or society.

So basically it depends on the system of interest.

It's not something predefined.


SPEAKER_07:
thank you i'll give one other example just because this swarm modeling topic um is a great one and to give a specific example so when we were simulating an ant colony and there was the chapter six but this is the result of the chapter six this is the specification of the environment a team maze where there could be movement

And then this is the generative model that was specified, like the generative model of the nestmate was the ABCDE and the kind of active inference loop that it implemented at each time step.

So in that sense, it was an agent based simulation, much like NetLogo.

or using any other agent-based simulation, except that the Bayesian graph of the structure that it was implementing was like the figure 4.3 graph.

So specification of the environment, specification of the generative model,

including the boundary in space and time like having the ability to receive um uh in a one square perimeter so we didn't a priori set a blanket on the colony

But you could imagine if you said, okay, well, I'm going to look down from the top and enclose another blanket around the total space that the colony encloses, which might be meaningful or might not be.

But from the modeling perspective, all that was needed to specify was the nestmate, but then summary statistics could be made about areas covered.

So there's a lot of other analogous examples with multi-agent simulations.

To a first approximation, what you specify is the agents, just like any other agent-based model.

And then people are looking into, as Ali mentioned, like integrating true multi-scale systems modeling, like multi-agent models of neurons constituting circuits and so on.

Andrew and then Prakash.


SPEAKER_03:
Yeah just a quick note that the Markov blanket is best thought of as a

computationally meaningful parameter, not necessarily something that you will be able to pin down in physical space.

So, for example, like if you think of your Markov blanket, it's associated with the sensing and action

modalities you have available.

Even though there's physical spaces going through you in a certain way and you are regenerating in terms of

your particles at a certain rate.

It's related to how you as a computational agent are associating with your environment.

And so you can think of that both from the intrinsic perspective I just described as well as if you are modeling something

you get to pick what is the data going into and being processed by your statistical model and what is the data going out and being processed and transformed into physical phenomena.


SPEAKER_02:
Got it.

Thank you.


SPEAKER_01:
Thank you.


SPEAKER_07:
Prakash, and then Christoph.


SPEAKER_01:
Yes, thank you.

Daniel, I have a question for you.

Like in the ant model which you showed, I was imagining that if we have, say, multiple ants and they want to form a group by themselves, so will you be able to create like kind of a Markov model, like a blanket dynamically?

Am I correct or incorrect?


SPEAKER_07:
Well, a few things to say on that.

So first, as the blankets are features of the maps, not the territories, it could be possible, you could say, again, I'm taking a top-down view of the movement, and I'm going to draw little enclosures, and I'm going to have a thresholding parameter for when I declare these three to be a separate cluster.

But at that point, that's not really what the nestmate is doing, which this whole time hasn't changed from just as specified.

So there's a lot of higher order clustering and partitioning methods that aren't exactly the base level specification of the generative model, which is often pretty small and simple.

um and then another thing to say on it is like as with many agent-based model like here all they could do was um move and uh put down one pheromone there wasn't like an option for them to have a second pheromone or to do nursing or uh other kinds of behaviors so um there's always kind of a limited zone of of the

like emergence or phenomena that are displayed from a simulation if it's really printed down to be simple and then to make um richer like more more whole iguana simulations that's what is exciting about active inference uh one one follow-up question on this uh so basically you are designing it through policies which you have or it's like more higher order stuff

This one, the only policies that you could take, there's no planning, was just moving in a grid, like a grid world.

But as with any active inference generative model, like Chapter 6 describes, all the aspects of the model are specified.

The input, sensory, any higher order beliefs that it entertains, like the cognitive states, and the affordances it has, how it does policy selection, whether it does planning, whether it has any of these other features like attention,

So figure 4.3, which is basically what is here, is just the minimal kernel motif in discrete time.

And then there's all of these kind of like features.

And this is a very simple framework with the goal, as most of the published models are.

And then that's why there's so many opportunities now to connect the different systems of interests with the kernel, with the motifs that are arising.

Okay, Francis.

Yeah, thank you, Francis.

Oh, sorry, Christoph, and then Francis, then Tanner.


SPEAKER_05:
I just want to add one thing to the mark of blanket concept.

Slightly different perspective that comes from something that Stephen Wolfram is working on, the observer theory, which is he's kind of rediscovering very similar thing to active inference, but on slightly different basis.

So he talks about what's necessary for something to be an observer.

And in some sense, you need to have more computation going

going on on the inside of the observer than, you know, that's going on on the outside, what is being observed.

So this Markov blanket, the statistical definition of a Markov blanket to me is kind of very confusing, right?

Like there's this statistical, what does the statistical independence really mean?

Well, it really means that you, you know, the observer or the agent is going to do something internally

that you can readily predict from just looking at it without it actually responding somehow to the event.

So it has to, you know, some information is coming in.

It has to process it in some way.

And it, you know, it will react, react in the eventually in the environment.

And as long as it's doing enough computation on the inside, then the

it will basically become statistically independent because you can no longer using simple statistics or any kind of statistics really model what is it really doing internally.

Mateusz Piorkowski- And these things kind of seem to arise naturally as any kind of complex systems interact so So these are kind of boundaries that, on one hand, we can we can draw them somewhat arbitrarily sometimes, on the other hand, they're they're kind of naturally arising in interactions of any kind of.

Mateusz Piorkowski- Any kind of computational systems.

I hope this is very helpful for me, but I'm not sure it makes any sense in this context here.


SPEAKER_07:
Yeah, it's awesome.

Like you're right, they can absolutely be proposed out of nothing.

Like you could just draw an arbitrary base graph and just say, here's the blanket.

But they also do arise naturally, seemingly, or maps with this character describe complex systems.

A simple example of which being space or time.

like things kind of propagating outwards in space and things not teleporting through space, like a bubble expanding outwards, not like skipping a shell because it's like propagating locally in space.

So that kind of captures that property too, as well as the, I guess, as Wolfram is looking into more of the computational parts of like measuring and observing.

Francis, then Tanner and Ali.


SPEAKER_06:
Hi, so my first stab at understanding Markov blankets was from my programming background.

I thought, okay, so this is a bit like having a function or an object where you pass parameters in, which might be the goals, and then leave it to get on with this.

And then maybe if something goes wrong, it'll send an exception up.

to, so that can go up the perception, the exceptions go up the perception tray hierarchy.

And then I picked up the references to the environment and I'm starting to think of a Markov blanket as being something which

uh because things are hidden from the environment they're not part of the environment therefore they can have a is the internal state and it can be the internal state which as an into the intent that to the extent that it's an agent the internal state that it is trying to preserve

at stake what it is um at it being uh i guess anything which has a mark of blanket um actually i what what is the answer to that question what is it that can have that mark off blankets uh inactive inference okay thank you


SPEAKER_07:
Thank you.

Tanner, then Ollie.


SPEAKER_08:
OK, so I do have a question that I want to ask.

But first, I want to respond to the last participant's query.

I think the issue that a lot of people have when trying to understand what Markov blankets and Markov boundaries are is they make it too agential in the sense of the words that they use just become agent identified.

The way that I understand it is that Markov boundaries are agents, right?

So we say, but it's important to understand that Markov blankets aren't actually extant in material reality.

They're just ideas, right?

They're like, this is the boundary.

So you can sort of understand this if you think about it and you're like, so I see a spider, right?

And I'm like, that's a spider.

That's an individual.

But is it like you just kind of made that definition, right?

You, you assigned that you drew the line in the sand, right?

You, you know, circled the spider and we're like, that's, that's the entity right there.

That's the agent with identified active awareness doing the inferential, you know, stuff.

It's kind of arbitrary.

So Markov blankets are like defined in this

know more holistic way like they are they are emergent properties that do exist like they do they exist in a qualitative sense um you know most the time i'm existing as as a person in a body but in a state of meditation you can sort of start to exist with a larger or just different markov blanket that includes maybe other people the room etc so that's that's all i wanted to say about that it's not

It's not one-to-one, right?

There's a whole spectrum to these things.

Anyway, my question was about spiders.

So you have these models that you were presenting about ants.

And my curiosity is, ants have this, as I understand, largely two-dimensional kind of experience, where it's like left, right.

They're not really moving up, down.

It's very much so just like follow the pheromone trail.

and you can correct me if i'm wrong because you know much much more about this idea but my my question was like if you were trying to extend that uh this model that you've created to a spider which is something that exists in in a very three-dimensional way and even in in some sense in like a four-dimensional way because the whole concept of building a web is like

working with a plan that is a long-term plan to catch and exist right it builds a home for itself that's not something a drone ant is doing i don't think so just curious what you kind of think about that idea if you just take like a classical like field spider as an example um and and i would i would love to hear your thoughts on that in comparison to your model so


SPEAKER_07:
Okay, just very briefly, the Markov blanket is definitely not associated with just the agent environment interface.

Like this node is a blanket between X and Y. So the Markov blanket can be identified between any nodes.

But one kind of interest is this agentic and definitely it's like very

um observer dependent like all observation is how agentic different boundaries are seen as and um to the spider I mean this is what chapter six is about please

look through chapter six and make a spider model and then next week let's look at it and look further along and maybe we can even you know go from there but that's exactly what chapter six is about yeah um do you have a recommendation of a particular species i should look at or i can find one

I mean, from the beginning of when you're feeling curious about the phenomena on through the active inference model, you make just document it and then it'll be done.


SPEAKER_08:
Okay, cool.

Thank you, Daniel.


SPEAKER_07:
Thank you.


SPEAKER_04:
Uh, so, uh, a little bit, I think, uh, a more sophisticated, uh, version of, uh, Markov blanket.

I'm not sure if it's directly.

inspired by the concept of marker blankets, or not, may or may not be.

But there's this important paper by Michael Levin, one of its, I believe, one of the most highly cited ones, the computational boundary of a cell from 2019, in which he develops the concept of scale free cognition.

And the idea is that there's this computational boundary, or as, as he describes it in this paper,

a kind of light cone a cognitive light cone that can define the scale of the agent's cognition i mean through various scales and various limits of the cognition so it's not restricted to even a single scale of interest uh it can be uh

modeled in a true hierarchical way to include various scales and various limitations of cognition, even if we want to investigate the interaction between or among

the various scales of cognition.

The other related conception was developed by David Krakauer et al in their 2020 paper, The Information Theory of Individuality, in which they again describe a information theoretical conception of what it means to be a biological individual.

uh this information theory of individuality uh enables uh the identification of of the agents at uh any level of organization i mean from uh even molecular uh molecular level to even the cultural ones uh so uh these recent cons uh concepts

can be seen as kind of update on the, or we can look at them as kind of Markov blanket 2.0, but I believe familiarity with these newer concepts can even help us to understand the nature of Markov blanket

I mean, more clearly than just looking at the active inference literature, because I agree that this concept can seem a little bit vague for newcomers or even for experts as well.

So I highly recommend those two papers as well.


SPEAKER_07:
Thank you, Lee.

Yeah, a few comments on that.

Like the Markov blanket concept comes from the causal Bayesian modeling literature.

And then there's various extensions and kind of analogous, the blanket index, all these other things to kind of, I mean, bring it to a more low road building.

Does anyone want to look at the questions?

or share some of their modeling experiences, or we could look at the PyMDP tutorials.

Because the end of chapter six, not like it only has to be about this chapter, but the end of chapter six doesn't necessarily leave one further along or scratching their head about these multi-scale systems, except through the construction

and often like going through and talking through and building through a system gets really far and then even the theory questions from there are more informed so it's not like the theory has to be resolved like before one builds anything okay got it that's useful

Like the pie MDP tutorials are, are we, or, or does anyone want to look at, or what would be helpful in our last bit?


SPEAKER_01:
I think like, yeah, we should, uh, if everybody agrees by MDP.


SPEAKER_07:
Yeah.

Um, so like, let's do it.

There are some, uh, I think a model stream 7.1 and two with Connor Heinz and Daphne Demekas.

Um, like, but those are long videos and, um, also contain a lot more of like the, the background on PI MDP.

Um, so I just put it into the chapter six.

Okay.

So, um, I mean, what,

the big picture on what's going to happen here and how this is different than chapter 6. this is not um this notebook itself is not um a supplemental dish to chapter 6. however with some very slight tweaks it could be so just to kind of set set the scene like chapter 6 is a sequence of questions it's a catechism basically

for going from your curiosity to the constructive model so what system are we modeling are we modeling

one spider, three spiders, three spiders in a web, three spiders in two webs, five spiders on n-webs, two trees, you know, just that is not a trivial question.

What are you modeling?

And so figuring this out is what they have this first question.

Then what's the appropriate form of the generative model?

One big distinction being like figure 4.3, discrete time or continuous time.

And all the strengths and weaknesses of these different techniques.

Also is like, only for discrete time models right now.

But there's other approaches for continuous time modeling.

Then what's the structure of the generative model?

Is it an estimate that can move two squares forward or one square at the side or this way diagonally?

Or how many pheromones and how many doesn't have attention?

And if it doesn't have those features, it's not going to have them.

If it doesn't have three-step time horizon planning, your generative model will not have that feature.

Like if it doesn't have planning in the code, it will not do planning.

Now that doesn't mean it won't give behavior that looks very interesting in other ways, but actually that's a feature because you can say through the fully synthetic nature of the model, it doesn't do planning and yet this is happening.

Or it doesn't have a preference for this and yet this is happening.

And then what they leave for last is like how to set up the generative process.

However, as Ali and asked,

Maxwell Ramstad on in the guest stream they have kind of moved away that group of modelers not saying this is the only the best way they moved away from distinguishing so much between generative model and process because in the end they're co-defined and in like complex systems it's not so simple it's like which one's the agent which one's the environment it's like well there's two agents communicating so you know why not just

all the generative model.

Okay, so chapter 6 gets us to writing the pseudocode, basically, that we're going to look at the Python code for.

What they were going for here, their goal was, if we were to apply the chapter 6 question, is to model an agent that moves in this 3x3 maze grid world

and has a preference for a certain location.

And you can copy the code.

This package that they have written is called pyMDP.

And it also is bringing in just a few math packages.

This box, this is tutorial one.

This box has some kind of just purely visualization-based functions like plotting likelihoods.

This is not like an active inference box.

Also, as some of my friends have remarked from computer science, it's like there's some pros and cons to notebooks on one hand.

they can be copied really easily and run in the cloud like on a Chromebook but at the same time it can like lead to a lot of like okay I thought we're gonna do active inference but then now it's like this other thing is happening first so it's not always clear what's what's happening even what because it's so linearized um okay

here they're just showing what this function does and plotting a categorical distribution so it's it's kind of built it's like a little step by step this is not building the agent yet then from just doing this is like a three-sided coin flip now the other kind of key piece of the base formula is going to come into play which is conditional probabilities

and they show doing some conditional probabilities, just to show in PyMDP, like, what we're doing is probabilities and conditional probabilities.

Like, the joint distribution of the Nesme is just the joint distribution of A, B, C, and D. That totally describes the Nesme.

There's no other information about the Nesme.

And then conditional probabilities become really important because, like, we're often interested in conditional distributions, like the distribution of action conditioned upon this observation, other things like that.

Okay, so that was all, like, kind of preliminary, like, PyMDP information.

utilities and just demonstrating what the syntax kind of now they're going to go into grid world okay the grid is specified it's a three by three grid that's specified as this um set of ordered pairs and then it's visualized with their graphing functions

So that's the generative process.

That's basically the environment is being specified.

Now, just like for other discrete time active inference agents, what there is to specify is A, B, C, and D. So just to the figure or chapter seven, which is the next chapter, which goes into more detail on the discrete time model.

So A, B, C, and D. A, B, C, going into G. Here's C. Because policy distribution is conditioned upon preference and habit, so it's just kind of getting wrapped into this G visualization.

A, B, C.

First, they generate A. A is the conditional distribution that is basically mapping between observations and hidden states.

So in this world, each of these locations is going to just it's basically labeled like with its location.

So it has like a perfect GPS.

So the dimensionality of A is set.

The dimensionality of A is basically like observations mapping to hidden states.

It's a matrix that describes that mapping.

And so they're the same in this case.

Then it's made out with zeros just to initiate it.

And then it's filled on the diagonal with ones, which corresponds to perfect mapping of states.

If the A matrix were flat, there'd be no information about the world coming in.

etc here it's the identity matrix so it's just a noiseless mapping that's what it looks like so here white square is one likelihood block square is zero likelihood and then it's mapping from the nine observations to the nine hidden states and it looks exactly this like if you see a three it always maps to being in state three here and then um

They make a noisy A with some different noise patterns.

So here, observation zero is ambiguous whether it maps to zero, one, or three.

So following in the grand SPM tradition, even very large generative models can be specified, like with these grayscale heat maps, it's actually really cool.

Two ambiguous locations, now six is ambiguous as well.

Okay, so that's A. So we have a few different A matrices.

As with other modeling, it's never just about one perfect model that describes like the spider.

it's about like having multi-scale portfolios of a matrices and composing them and and displaying like like this one has this behavior and things because this but actually here's this other model that shows that it's not so it's not just about making one it's about like doing a lot of models and sweeping across them

Now they go on to B. B is the hidden state transition.

Each slice of B is going to describe the mapping from one world state at past time point to the next time point.

And then different slices of B get selected based upon the policy selection.

so b is the critical variable in active inference this is where the action dependent world model is specified and like this is really the variable that explodes a lot with model complexity

because the D variable is just a prior on world states.

So it's just a vector that kicks the chain off one time with like an initial distribution on room temperature.

And A is a sensory mapping from thermometer reading to the hidden state.

And then C is just a preference over thermometer readings.

So all of the work in the model with the action dependent causality, all of it is in B. It's basically the only place it can go.

just in practice so bees created these are the affordances they're called actions in this script um there are five of them up down left right stay um a few pieces are uh just visualized

and just checking through that they can advance the next state and then take the action and move from here and then move right one square to here, then move down to here.

So that's B. Then C.

They zero it out.

C has the same length as observations because it's a distribution over observations.

And here it's given a value of one for eight and zeros for the rest.

And then D has a length of the number of world states.

And it's a distribution of our world states.

And that's just how it is.

So that's the ABCD specification.

So at every single time point, all that the agent simulation is, one agent or multi-agent, it's just A, B, C, and D for each agent in this most simple example.

then they make some um functions in first state that's like the sense making part and this just describes a pseudocode for going from the observations combining that with the prior and returning um Q of hidden state that we discussed Q of X earlier today they do a time step of just the sense making inference

including with ambiguous priors.

So that's the sensemaking part.

Then action selection.

This is the action part.

Some more functions are introduced.

Pretty cool to see the entropy and the KL divergence just defined so shortly.

They just kind of replot things and just kind of refresh where it's all at.

Change the preference to five.

Add a few print statements.

Compare the expected free energy for moving left versus moving right.

Classical approach.

You have your affordances that are being considered here, just those two, just for clarity in the tutorial.

And then EFE G is calculated for those two.

And then a softmax is applied such that the units of G are normalized to probability distribution.

And then here is the whole grid world.

And then they all wrap it together.

And then they just output how it happens.

they add planning at the end but everything above this point is no planning and then from this point you you start to see the planning I hope that's useful um and that people make also other tutorials or maybe contribute edits to pi mdp because there's a lot of experience with modeling that people have that that could really help

And it's really fun with the theory, but also it's a very specific modeling possibility.

And we have the... So for those with computer experience, many of these will be accessible.

For people with less coding experience, like...

it will be really helpful to figure out and like co-learn what approaches um are exciting for you because this is the low road a low road it's a simple model but it kind of is it helps calibrate and benchmark

Like if this is a big pill, then simulating 500 social agents with memory is probably a really challenging project for you.

If this is very simple and understandable, then you can probably start to benchmark what kinds of models you'll be able to understand or at least iterate on starting tomorrow.

okay any questions in the last five minutes or thoughts on like this modeling topic as that's kind of chapter six yes precaution anyone else


SPEAKER_01:
Yes, I was, actually, I think, first thing I will, what I'll have to do is I'll have to just do this tutorial once, like, it's very nice to have given a brief summary of it, so it'll be very helpful if we do it today or tomorrow.

And I was, I was thinking, like, if, if the, if the matrices what you mentioned over here, if that is, like, we have various concepts, like, various class data structures, we know very well.

So, similarly, if you know these matrices quite well, then I think things will just flow.

That's what I understand out of it.


SPEAKER_07:
Right.

Thank you.

Yes, totally.

And also the model presented here is a pretty common P. O. Mdp.

That's what gives the continuity with the computer science and the base graph and everything like that.

But it is just a P. O. Mdp.

Basically.

And yeah, it's about that motif.

and then about understanding it in a single agent case, and then just kind of building from there.

So like a lot of the work and the challenge in application, I look forward to everyone also sharing their experiences on this, is like even building one agent

And then there's like the, just like create the environment with Ben, but also people are making amazing toolkits to help facilitate multi-agent act of simulations.

So just like everyone keep learning and exploring and the tools really are getting better fast.

Susan.


SPEAKER_00:
Um, so, um, um, you know, my head's around.

to integrate this with the constructor law and i'm wondering where um degrees of freedom show up in this particular chapter you're pointing to yes in the narrow not necessarily the software but i mean in the real world oh


SPEAKER_07:
I mean, the chapter describes several of the mega degrees, total degrees of freedom.

Like what is the system we're modeling and who are we doing it for and why?

I mean, these are the ultimate degrees of modular freedom.

And then these distributions have their own statistical degrees of freedom.


SPEAKER_00:
Okay.

So it really is the construct of freedom is, is kind of underlying

It's kind of, you know, under the soil, we might say, of the blanket.

So the perception of someone's freedom may actually correlate with where they see their boundaries, where they see their market boundaries.

I almost want to say that if I were to translate the

market the markov blankets you know to a you know a okay metaphor it's not perfect but an okay metaphor it would almost be the protective boundaries that we um that we perceive in the world which has a lot to do with you know our perception of freedom would that be however you feel


SPEAKER_07:
right yeah trying to stay with the rigor um so i don't want to use something that doesn't it's completely off like i love that you added it i don't know if they talk about freedom at all in the book so in in the letter of the book no but i really like what you have so okay thank you thank you everyone

peace see you next week also feel free to do the tutorials add questions add notes and like your experiences if you were familiar with the code or not and all of this could be really fun so see you next time bye thank you everyone thank you that was great