SPEAKER_07:
All right, greetings everyone welcome back it's Halloween 23 and we're in our second discussion on Chapter three, so we will look at the cohort five questions on Chapter three um so.

I encourage people to add even now questions directly to cohort five questions or there's all this other questions.

So maybe people added directly to the table and so it doesn't have the cohort five tag.

But before we go to any questions, does anyone just want to bring up some piece of chapter three that stuck with them or highlight some other topic or...

share a little bit about how they're seeing the low road and the high road now that we're getting to our second discussion on the high road yeah Susan then anyone else who raises their hand so does the low road and the high road are they differentiated

by active inference versus active learning no active learning was the term used by that one paper just to sort of

spin the fastball a little bit different to highlight kind of like a regime that an active inference agent can be in instead of a purely conform confirmatory sensory mode rather a mode that that reduces uncertainty maximally about world states but active inference is the bigger circle which what the authors characterized as active learning is a smaller subset within


SPEAKER_02:
which incorporates it.

And so Dean brought up that active inference was a process of provisioning.

Can you speak to that?

This was in private conversation.

we'd have to know a little more about what he meant um but it's a very evocative yeah so that but that kind of brought the question of differentiating active learning from active inference versus police updating say because learning would involve belief updating right


SPEAKER_07:
Yeah, as with a huge number of the topics that we hear about, belief updating, attention, learning, anticipation, there's often a narrower technical sense.

Like belief updating is just any Bayesian parameter updating at all.

so belief updating doesn't always refer to a human with a psyche undergoing some kind of like narrative development it can be a lot more narrow and small and less loaded with like philosophical or cultural baggage than if we were to say hey when's the last time you had a belief updating most people aren't going to say well when one of my proprioceptors in my arm

you know did something different um so sometimes yeah the narrow sense or the technical sense of a term and then the the broader um um scope of what it might evoke and and so these are all good comments um christoph then anyone else raised their hand


SPEAKER_03:
I just want to say that the high road and the road to active inference through this ideas of self-organization and self-evidencing, that really reminded me of some work that I'm not familiar with deeply mathematically, but conceptually it seems very similar.

That's Jeremy England's work on the thermodynamic origin of life.

He kind of, in his work, he has shown that if you have a system that's receiving an energy from external source and it has a place to dissipate that energy, and there are certain other conditions that need to be met, then the system will necessarily organize itself in such a way to take advantage of that energy source.

So it will start creating structures.

that will allow it to utilize that energy.

And in his talk, I think that was at MIT a couple of years ago, at the very end of the talk, he makes this offhand remark that probably

when the energy coming in has some kind of temporal structure that may eventually lead to the emergence of intelligence or something like that.

That kind of made me, when he said that in the talk, made me think about, you know, Faraday speculating about the electromagnetic nature of light.

He's probably right.

And I'm pretty sure that he's, I'm quite sure because he started with thermodynamics with his work, that it can be reconciled with active inference.

So it's also kind of fascinating that there is this very close but slightly different view that kind of arrives at pretty much the same kind of conclusion from, you know, quite different set of assumptions, but related.


SPEAKER_07:
Yeah, very interesting.

Dr. Einstein, then anyone else?


SPEAKER_09:
This isn't

Aaron Ostrowski- Low road high road specific So do you want to.

Aaron Ostrowski- shelf it for a second, but I was curious about something on page 52 that goes back to the conversation we were having here.

Aaron Ostrowski- Two weeks ago in the in the morning group or wherever you guys are.

Aaron Ostrowski- And it's about the idea of perception is action.

Aaron Ostrowski- And we were getting into that.

And on 52, you know, they, um, use this example of you're hungry and your, your glucose is low.

So you have a hunger response.

And so, you know, there is this line that says, um, perception cannot go further than to reduce your surprise.

And it got me thinking about like, if anybody here has ever fasted.

for example, you know, you'll be really hungry the first day or whatever.

And then by the second day, your hunger is just dissipated.

And that got me thinking about that conversation we were having here regarding perception as action, because, you know, what is it in terms of this

field i mean obviously that's like a belief updating about your need to eat or something but what what would be the mechanism you know uh according to this theory that would cause your hunger to dissipate because there's been no act there's been no action in the external world to reduce your hunger it seems like it would be purely just a matter of perception


SPEAKER_01:
so when when they have that one line that perception you know can go no further than to reduce the surprise i yeah it just made me think about that kind of as a thought experiment cool yeah francis i know a little bit about that this is okay go for it go for it yeah there there is action going on your body's metabolism is changing and um there is a yeah there's

there's essentially external states that are functioning on your mind um in that transition between day one and day two on fasting that makes it not a completely internal state derived activity i mean would that count as taking an action though i mean because you're not consciously you know changing your external environment


SPEAKER_07:
I think that if you sketch it according to the act in fontology, it'll bring it into the rails.

If you sketch out what's being observed, what are the hidden states being inferred, it will clarify a lot of pieces.

Because otherwise, I mean, we could go infinitely into the actual biomolecular processes that happen in human fasting.

but to kind of return to my question yeah yeah but that's everything is how how do we take that situation of interest with its particularities and approach it from the high road Francis and then and then Christoph so uh from a counseling background I'd say that you have to look at the whole self the part of you that needs the need for food is one of your needs


SPEAKER_06:
You have other needs, maybe the need to fit in with your group, whatever need is driving you to fast.

So you have to look at the perceptions, the goals of the whole self and how these balance out.

You're always dealing with conflict, inner conflict.

We have multiple needs at any one time.

Um, so, uh, uh, yeah.

Um, and how that would work at the active inference level.

I'm not entirely sure.

Maybe it would, uh, reinforce the, uh, uh, strengthen, uh, the expectations in such a way that, uh, you ignore the, um, evidence against.

I don't have a sufficiently good, strong understanding to propose the mechanism.

That's what I wanted to say.

It's the whole self.


SPEAKER_07:
cool mark miller has explored this kind of like multi-drive balancing and about well-being as optimizing well across multiple domains because you can't just like optimize your blood glucose and not your blood oxygen you die um and then also internal or covert action as attention to simply disattend or to attenuate from the grumbling of the stomach

helps make it an unsurprising path of policy selection not to order something at the restaurant or put the fork in the mouth or whatever it may be.

Andrew, then Christoph.


SPEAKER_08:
sure uh not just a general thought of um regarding the active inference framework I mean could we say something like um you know someone is making a decision to fast is a sort of like a higher order decision but nonetheless on the day today if they're not used to fasting or even if they have in the past but you know have not been for say the past week

such that they are very used to and therefore expecting to eat at regular time intervals on the day-to-day that despite the fact that they've made this kind of higher order decision to not eat, nonetheless, like their body and other processes are expecting food.

They are in fact not receiving food because of the fasting.

And so there's a higher level of something, like there's an increase of something like surprisal

or or uncertainty that is like even though i can kind of consciously think like oh no i could eat food i'm just choosing not to my body is still experiencing physiological shifts and changes because i'm not eating that is generating a lot of like um

kind of uncertainty in my body, you know, this is different, this is not usual, this is not realizing my typical set of preferences.

And then over time is the body kind of adjust to that.

Suddenly, the need, you know, hunger, other

um kind of sensations of surprises or otherwise might start to reduce is you the body starts to realize like oh no i'm fine like my my homeostasis is not exactly in danger here even though you know it was kind of a shock initially to start experiencing the um you know the the the difficulties of fasting uh in the first place on day one right


SPEAKER_07:
Yeah, here we have the glucose observations, and then you can infer what the hidden state is.

Again, it's the modeler's choice, map, not territory, but this could be risk of death.

So it might be a matrix learning.

Oh, actually, I don't have a high risk of dying, even when it's at this value or not.

Then you've mentioned like habits.

I mean, oh, it's 5 p.m.

So the generative model is in the business of the path of least action, doing the likeliest thing.

So if 99% of the last 1,005 PMs you did something, your prior's high on simply doing it as a matter of habit or of having a preference for a high glucose would then lead to the selection of policies that make those observations unsurprising.

So once you start to kind of take a figure or some formalism and go beyond just associating components of territory,

to bringing them in to stitching together a total generative model, you find that there's many generative models you can draw, sometimes with convergence insights, other times that highlight different features.

And that's part of the iterated process of modeling is like developing a portfolio of generative models, like many maps of the city, and then finding out, well, where are these special cases or generalizations of each other?

What's the kind of measurement or experiment that as a modeler is going to help me differentiate amongst these two different structural hypotheses?

Christophe, then anyone else?


SPEAKER_03:
You kind of beat me to the punch because I was about to say that it's all about tuning.

Well, it's not all about, but it's largely about tuning precision parameters.

So if you do an experiment where you fast regularly, like say every week, you're going to find that even though you're starting from effectively the same starting point, so it's a somewhat reproducible experiment, week after week after week after week, it's becoming easier and easier and easier to fast.

And also, I'm not an adept meditator, but I have some level of skill.

And in my case, I can easily distinguish between two kinds of hunger.

There's an intellectual craving for novelty, which I derive quite a lot of novelty from food.

It's a pretty easy source of novelty.

And a lot of people, I think, their feeling of hunger is kind of virtual that way.

And there is a physiological hunger that's a very distinct and different kind of feeling.

And most of the time I actually know that my body does not need food, even though I feel like I would like to eat something because I'm creating this intellectual novelty.

And I think there's an interesting way to actually experience this very directly, like how this process of tuning precision parameters happens, is that if you take a big exhale and empty your lungs and hold your breath for as long as you can,

At some point, your body will force you to take a breath.

You can't really just suffocate that way because amygdala will kick in and they will trigger this kind of panic fight or flight response that will kick you into taking a big breath.

But if you do it again and again and again and again, very quickly, you just get used to it and you're no longer reacting to that with panic and you can hold your breath for much longer and so on and so forth.

And you can actually experience some really nice effects of

saturating your blood with CO2, which is extremely relaxing.

And it pushes O2 deeper into the cells and actually helps to pry oxygen away from red blood cells and so on.

And it's entirely controlled by amygdala.

And that's why it comes with this fascinating reaction.

And you can observe yourself tuning that parameter.

and very quickly you can get used to much higher concentrations of CO2 in your blood, and it's not a problem at all.


SPEAKER_07:
Okay, cool.

Just to sort of look ahead to the kinds of generative models that make up doing active inference modeling, we see this all the time.

Figure 4.3, we're going to revisit Chapter 7.

So this is the partially observable Markov decision process.

Now, as shown here, there are no precision parameters.

But then quickly after, they show, well, yeah, you can actually have another parameter kind of on top of each of them, little d on top of the d prior, little a on top of the a, little b on top of the b, and so on.

And this speaks to the extensibility or the modularity of building

generative models using Bayes graphs is in the kind of plain first level model, you just have a fixed A matrix.

And then you can say, well, what about having a variance on the A matrix, like a kind of precision on A?

Well, if that helps you get at the phenomena that you're interested in, that might be something to try.

You could also continue to even develop further.

So what if we had policies on which attention we wanted to have on A?

No one's stopping you.

It's just map building.

And especially if it's being done as a kind of thought experiment outside of

reconnecting with the empirical measurements then yeah there's basically no end to speculating about where you could it's just like building Lego constructions because you could you could have another variable connected to here and here and here and here and so

Hence, it can be kind of an open-ended and aesthetic journey to make these kinds of glyphs.

But then if you want to reconnect it back to the empirical data, which is discussed most in Chapter 9, then you kind of have a divergent, convergent, iterative process

where you expand the portfolio of generative models you have, and then you use some experiments or measurements to then select or do Bayesian model selection to go back down to a smaller subset of them, and then you can kind of diversify from there, select them back down.

Any other thoughts or we can look at some of the most upvoted questions or any other questions that people want to look to?

Any other thoughts or just remarks on the low road and the high road?


SPEAKER_08:
um I did just kind of want to throw it out there like near the end of the high road like box 3.3 they're describing entropy minimization and open-ended behavior

And I guess just I just want to mention generally the topic of like, how does an agent within a fluctuating environment?

On the one hand, find means of like adapting to that environment like that is how does it act in order to maintain something like homeostasis or allostasis, but at the same time not become too rigid, like not

repeatedly make the same exact decisions purely to maintain its homeostasis and instead allow for something like improvisation or like they phrase it as an open-ended repertoire of novel behaviors, creativity or something like that can arise.

So just that question of like behavior being like too rigid in an environment versus like actually being able to change, being able to

come up with new things unexpected things even things that haven't been tested so you would expect that like why would you do that that would probably bring higher surprise uh even more uncertainty so that just those kinds of questions balancing those things yeah the the there's there's a ton to say there um


SPEAKER_07:
well what one aspect is in expected free energy so in the criterion used for prospective selection of action there's an information gain or epistemic value term so

surprising information informative information is actively sought after because policies that lead to information gain are directly chosen so that's one kind of prospective looking

answer um that holds up both seeking observations that that accord with um preferences that's loaded onto pragmatic value and seeking out informative information that's the information game and that's um referenced here at the end of the box um

another piece to it is it's kind of like all these different seesaws epistemic and pragmatic value or underfitting and overfitting active inference isn't saying there is a specific answer to that but it gives us the the canvas that we could then do the balancing within like you can make an agent that

only undertakes epistemic action or conversely under only undertakes pragmatic action so it's not that just framing it with an active inference gives you an adaptive agents it's just that this is an expressive enough framework for generative modeling that you can find those special regions or manifolds within state space that might have those kind of like flexible or adaptive properties

So it's not that something works and does balance informational and pragmatic value just because it's using expected free energy.

It has to be kind of tuned to sit at that special place.

Dr. Einstein, then anyone else?

Okay, you're a minute.


SPEAKER_09:
I never expected these computers, you know, still learning curve since I hopped in the time machine.

But yeah, I think last week we we.

Towards the end of the session, got to that line in box 3.3.

This could be understood as the imperative to explain things as accurately as possible, but also keep options open and avoid committing to any specific explanation unless this is necessary.

That's the maximum entropy principle.

I mean, yeah, that's such a curve ball.

They kind of sneak in there.

At the end, I'm still trying to reconcile that because it makes sense intuitively in respect to like information forging behavior, the necessity to calculate surprise beyond just simply minimizing it or in respect to expected free energy rather than variational free energy.

So it's kind of, I guess, it's an epistemically interesting question as far as what is the conception of truth in the active inference framework.

I mean, it seems that it implies that everything, you know, any agent has to simply view the world and truths in the world through a probabilistic framework.

and um there can be no absolute you know a priori truth in in this or am i i mean these are huge huge philosophical questions yeah


SPEAKER_07:
suffice to say that it's not about what the territory is or does however we may take a probabilistic approach to modeling a system that has deterministic or probabilistic characters and then whether or not we think this or that about this or that and whether it thinks this or that any one of those could be right or wrong or literally whatever

so I think it's it's a jumping off point for some larger philosophical questions but certainly it's not at the fundamental layer of the framework to to have an opinion on stances that even with little familiarity we can see one could jump one way or the other um Andrew oh yeah sorry just a follow-up on that um and then


SPEAKER_09:
My question would be is, you know, how would you, how do you, and maybe I just need to research more, but how to reconcile, you know, that forging imperative or maximum entropy imperative with the Hamiltonian, you know, gradient of least action, right?

Is there a, I mean, is there a statistical means of reconciling?


SPEAKER_07:
reconciling those concepts yeah great great question the path of behaviors that the agent undergoes is being conceptualized as a path of least action most likely thing that the generative model could do so depending on the generative models set up the most likely thing for it to do might be engage in exploratory behavior


SPEAKER_01:
um Andrew then call it yeah um we had the what is the low road versus the high road question earlier um and I thought I'd give my stab at it um nice the low road is the fundamental question is what's the nature of inference and the high road the fundamental question is what is the nature of identity

That's my stab.

I have some for follow-on questions.

I voted up a couple that I thought are interesting and were questions I had.

Hopefully they rise to the top, but that's all.


SPEAKER_07:
Cool.

That's awesome.

Because inference could be about anything.

It doesn't have to be about identity.

So we could do Bayes' theorem, Bayesian statistics.

It doesn't have to be about a cybernetic, autopoetic entity.

And then identity, especially if we're going to be talking about persistence of identity and self-organization in a dissipative niche and all of this, it doesn't tell us how.

So I think this is an awesome dyad.

Colin, then Pablo.


SPEAKER_00:
I was just stimulated to think from looking again at the explanation of expected free energy as a balance between information gain and pragmatic value.

And I found all of these formula were interesting in that they all represent a kind of balancing of two things, one of which you could prioritize more, but only

by reducing the other.

And it just seemed to me that we're prescribing the right way in which these two things are to be balanced against each other when active inference is done.

And we were kind of saying, therefore, that this is the way it must happen.

but I was wondering why is it not possible to take a step back and say, well, my model about how I decide what to do is I could give greater priority to information gain and less to pragmatic value.

And is it not a reasonable thing that people could make choices to do it differently in what way is forbidden or made difficult by active inference theory?

Does that make sense?


SPEAKER_07:
Yeah, these are great questions.

Very nice insight that there's like two pieces broken out in each of these framings.

Don't get hit with the equal time fallacy.

When you actually calculate this for real policies, this one might, depending on how the numbers are, this might equal 0.1 and this might equal a million.

So policy selection might be driven by one or the other.

Just because there's two terms doesn't mean that it's 50-50.

So if the C vector, to be more concrete here, is very large, and we'll see this later in the textbook, if the C vector has a large size, then pragmatic value dominates expected free energy.

if the C value is small relative to uncertainties, then information gain dominates pragmatic considerations.

And so again, this is like a seesaw and then adaptivity is like the seesaw being balanced, but just the seesaw itself is not balanced because that's kind of, there's no one on it.

But when you actually build the generative model and parameterize it,


SPEAKER_00:
then you'll start to play around and see oh maybe something needs to change because it's only doing information forging it's never going for the pragmatic outcome um i was thinking more in a situation where they were they were closely balanced and that one that that there was a fine tuning of moving more more more waiting one more than the other

It seemed like it's been prescribed here how you should weight them in that situation.

And should I spend time getting results or should I abandon getting results and go and get more information?

Sometimes we actually face that choice.

Do I do more research or do I start writing now?

And both seem attractive.

So both have the similar weight, as it were, in the decision making context.


SPEAKER_07:
yeah this is a uh articulation but not a waiting and there are policies and niches where maybe a given policy has high pragmatic and informational value so just it it really if you sketched out the generative model of doing research as some have and when to start or stop or move to a different resource

Then this articulation would help at least kind of reckon with that.

And then if it turns out that there's two policies that have a similar expected free energy, because one of them is really informative and one is pragmatic, then they would have similar posterior probabilities of being selected.

And that agent would potentially switch between those policies.

Pablo, then Susan.


SPEAKER_04:
Yes, this chapter, it makes me think about that we live in an entropy universe, but active agents are like entropy fighters.

That's kind of right.


SPEAKER_07:
Yeah, anything that's being repeatedly measured at least has to weather the storm, even if it's just an inert particle.

and then things that are active seem to go even beyond that like they reconstitute themselves and they persist even more than you'd expect for just something and being inert and weathering the storm what does that make you think about


SPEAKER_04:
It's fun.

It's like we are like, as far as we know, not many of these agents on the universe.

So I wonder why it's like entropy all around us.

And we are trying to like, we want it or not, fight against it.

And it's cool.

Okay.


SPEAKER_07:
Yeah, that's classical high road.

That's kind of the mystery of persistence or of just perpetuation.

And then why active inference is in the middle is we have a first principles persistence imperative.

with an implementable process theory coming from the low road and that's why the active inference generative model can be used to address those kinds of situations of persistence and it also has a tractable way otherwise it's just a description of the problem of persistence without a way to generate any kind of agent to actually do it um susan then christoph


SPEAKER_02:
um see I like the distinction between um the nature of identity and nature of inference and that kind of brings me to how to understand and yeah the probability versus possibility kind of comes into my frame of reference because if I'm looking at the high road through the nature of identity

then that's going to lead to my preferences and my perceived affordances.

So how does that change my Markov blanket?

How does what change it?

If I'm moving between

Barbara Kirby- You know what i'm what i'm interpreting here is that, if I look at the high road as the nature of identity, then that for me has more to do with.

Barbara Kirby- The area of possibility, or you know going back to a statement made I think last week in terms of action starts with an imagined imaginative process or predictive representation.

so that's going to that's going to drive my perceived affordances right yes what what what


SPEAKER_07:
There's a lot of different ways to say it for something that's simpler or more sophisticated.

But yeah, what actions can I select from?

What are my affordances such that I'm in the business of finding out what I am or confirming what I am?

And confirming what I am might be I'm the kind that goes and finds out new information.

That's the information foraging piece.

So just self-evidencing doesn't mean just navel gazing.

or just um shutting down sensory input as people for years have kind of repeatedly raised so evidencing can be broader than just seeking confirmation of sensory evidence in a short term right and and so how would that would that not you know let's say that I recognize that you know hey I can be this way too so I basically um

invoked or updated my beliefs about what my affordances are would that not change my markov blanket expand it or am i not thinking again it's a little it's a little understated because a markup blanket in what sense i mean the sensory apparatus

is not going to change.

So let's just say someone says, I'm not the kind of person who goes to parties.

If it were at a party, it wouldn't be me.

So that's the kind of identity and what something expects to be.

But then if someone has a different internal model says, I'm the kind of person that sometimes is at a party and sometimes isn't, then they could self-evidence in either of those settings.

But in either of those settings, they would still have visual input and hands.

So their markup blanket wouldn't change or a generative modeler modeling the person going to the party or not.

It doesn't need to entail a difference, but you could make a situation where the markup blanket does change.

Like I'm the kind of person who does or doesn't use neural link or does or doesn't take on this extra sensory technology because that is a more structural modification of the interface of the agent with the niche.


SPEAKER_02:
and that has a more vital relationship with the blanket and with the objects um sense of self perhaps so can I ask one more question does that so does that lead me to the boundary of my Markov blanket if I'm updating my affordances


SPEAKER_07:
get you out the space and see what it looks like and sketch what is the about what is the bound and what's what's inside and what's outside because Markov blankets very general any base graph is going to have Markov blankets aplenty so that it can be helpful to clarify are we talking about like what kinds of spaces okay um that's the modeling part right yeah yeah go for


SPEAKER_05:
Hey, Susan, so your question about the nature of identity and how can the Markov blanket of an agent shift around reminds me of some ideas that I was thinking about recently.

And this is maybe a bit more of a psychological and philosophical perspective.

but thinking about maybe two kinds of organisms, let's say biological cells and then also people, humans that are in a relationship.

So the question is about what do we consider at any given moment to be me?

What is it that I...

say or have in my mind, this is what counts as me.

And I think you can notice if you get into a very serious relationship, romantic relationship, or even having a child, I imagine, and I think I experienced this as well, that boundary between what I think of as myself begins to extend and begins to wrap around

the other person.

And to the extent that we begin to have the same shared goals and beliefs, that extension of the boundary becomes more well-defined and more robust.

And the other way that I was thinking about this is in cells, in biological cells, how it seems to be that

for example, in cancer.

Cancer cells are cells that have separated from the parallel organism, have become alienated in a sense, and no longer share the same goal or know what's the same, have the same instructions as the rest of the cells in the organism have.

So they see the rest of

their environments as external environments.

Whereas usually yourselves, even though each of them are individuals, they kind of have this synergy because they're all integrated and have the same sort of objective.

But when a cancer cell gets alienated and it starts to have the same

intentions and goals as a cell that's what is not part of an organism, just kind of an individual cell up in the wild would have, which is to find as much nutrition as possible and then start to spread.

And then that's where you have excessive growth of the cell.

so the connection I make there is how biological cells also have need to be able to figure out this process of redefining what do they think of how do they think of as themselves and they manage to do that and that's how you end up having a multicellular organism that is composed of many

uh individual cells that would otherwise have their own um notion of of what they have to do in order to persist as individuals thank you yes self-organization is described in the kind of kernel


SPEAKER_07:
here but then there could be composite self-organization with multiple layers so thank you um christoph and andrew quickly and then we'll look at it try to look at a few questions before we end


SPEAKER_03:
I just want to make two very quick points.

One, Susan, when you were talking about this notion of identity, just somehow the serenity prayer popped into my head.

God grant me the serenity to accept the things I cannot change, the courage to change the things I can, and the wisdom to know the difference.

So what exactly constitutes your identity?

It's a very good question.

And if you start looking for it, the answer is really not obvious.

And in my view, we draw these Markov blankets around parts of the graph.

And you say there was some statistical independence of certain variables from certain variables.

And that's a useful distinction, but it's not actually, it's a kind of, in some sense, a virtual distinction.

Basically, Markov blanket is a perspective, and that perspective can simply be changed from one perspective, because there's always some kind of hierarchical nested structure, and we can adjust it as needed.

So the notion of identity,

is is very fluid and a lot of traditions um you know like like Buddhist traditions for instance um teach you how to look for your identity and you will find that there is no such thing as identity that boundary cannot be really drawn um and you know the the goal of of a lot of these practices to simply lead you to the realization that we're all interconnected

at some incredibly deep level.

And if you're trying to draw the boundary, you're always going to find some kind of way in which the boundary doesn't hold.

But it's still nevertheless kind of useful.

And to go back to the previous point about this information gain versus epistemic value, the way I started seeing free energy principle is that we start with Bayes' theorem.

And which is kind of like this kind of non-computable in the general case piece of mathematics.

And then we use it to almost pretty much, not almost, but tautologically carve up that belief updating in all kinds of different ways to give us a different perspective on what's going on.

But it's not an implementation approach.

It's a certain kind of myopic view for the lens of probability distributions and base theorem and so on and so forth, kind of geometric view on the world and how it's actually implemented, whether there is some kind of parameter that weighs information looking for epistemic value versus

um the other term um that's that that's still you know that's kind of hidden by the by the formalism and that's necessarily hidden because the formalism kind of comes up from basically making this distinction up out of nowhere right we just we just take the posterior expand it through base theorem carve it up however we like it group some terms and say like well this is this and this is that and the distinction is in some sense

imposed on something where that that doesn't necessarily uh you know um it's it's not inherent in the object it's it's it's an imposed point of view okay thank you yes Andrew and Dr Einstein very quickly and then let's see if we can go to a question


SPEAKER_01:
Yeah, I just have a couple thoughts on some previous points.

One, I forget who it was, but the comment about entropy and us kind of being entropy fighting machines.

I just had a thought that we've probably all been embedded in this milieu that treats the second law of thermodynamics as like universally inevitable.

And I think there's some good evidence due to like cosmic expansion and some arguments that contemporary thinkers are making that actually order might be more likely.

The second law only applies when you have a closed container.

uh that you'll reach kind of heat death and most of our evidence in terms of the universe is we are in open systems all the way around and closed containers are actually the exception not the rule um i'm going to post a couple links to books that sort of talk about that uh what i i first found it from julian barbeau um who's kind of a

oddball physicist.

He's got a book called The Janus Point that he talks about the relevance for that in terms of time.

And also, I believe Alicia Girarro has been, her name pops up in the CODA, our textbook group.

The context changes everything.

And she's got some interesting arguments that kind of touch on that and also touch on the whole Markov blanket

uh dialogue we're having here um I believe you can get her book for free it's unlocked I'm currently looking at it and highly recommend it so far um and finally the whole um related to this entropy question um there's some uh debate going around on a new theory called assembly theory um that some people think is just utter balderdash but it's got a new interesting take on uh

the the nature of order and worth taking a look at um so yeah and oh one final thing Markov blankets um I I believe in your Markov blanket changes if uh you've ever used a hammer before and um you just

hammer and a nail.

The change between where the blanket ends and begins and your body, there's evidence that your mind incorporates a tool from a car to a hammer to anything in between.

And spectacles will change your Markov blanket as well.


SPEAKER_07:
Thank you.

Yes, indeed.

That's why there's so much discussion of the extended embedded cognitive processes, because we can both hold up what the thing is and understand how tools and so on change it cognitively.

Dr. Einstein, quickly, and then we'll look at one question.


SPEAKER_09:
Yeah, just real quickly.

I posted a link in the chat to a conversation in his Hippolyto head on converging dialogues.

And just on that notion of embodiment, she does a really thorough overview of some of the philosophical underpinnings of the High Road as it relates to embodiment in the work of Merleau-Ponty and Heidegger, Andy Clark.

So I really, really recommend it, even for non-philosophers.

It's very accessible.

And she really touches on that, the need of, or yeah, the relationship of the body and the environment, you know, as an agent for gathering information and model updating, respect to Andy Clark's work.

So check that out, guys.

Cool.


SPEAKER_07:
In our last minutes, first, if you feel like you have more to say, or you have more questions than answers, more answers than questions,

I so heavily and hardly encourage you to modify the coda.

Please, please add the links there.

That's how we move together as a niche.

If you add questions, if you add links, if you improve links, you will learn, you will help others learn.

It's really super important and special.

There's a ton of questions, of course, that we didn't get to, but just even highlighting some of the questions in red,

These are like epic things that people have asked.

And again, there's a lot of improvable discourse in a lot of these topics.

So I know it's a lot to look at and discuss.

We're like all just kind of forging through this massive niche, but no one's going to read all of this.

So we're always just kind of like finding and leaving things forward from each other.

That's part of the fun.

Let's just look ahead to what's going to happen.

This was our second discussion on chapter three.

We're going to be heading next into chapter four.

Chapter four is where we get to the generative models of active inference.

Chapter one, just background.

Two and three were like the roads into town.

Chapter four is the town.

This is active inference.

Chapter five is going to discuss what's happening in that town in the mammalian neuroscience district.

Just focusing on a few human or mammal type neuroscience cases where generative models have been deployed.

that'll take us basically to the end of the year um people can add their different ideas and and so on but that's kind of what the first half of the book the epistemic half of the book ends up looking like and then the second half is bringing closer to the modeling and the hands-on and so on with the recipe starting in chapter six but um

yeah it's quite a journey and the low road and the high road definitely invoke very different regimes of attention chapter four um is going to be longer and with some more analytical details than the previous chapters so

I encourage people to read it lightly, which may be slowly, but there are some formalisms and so on that are not vital for understanding.

In fact, they even suggest like you can like skip over this chapter, which is very funny that they say that.

But we will return next week.

I'll be really looking forward to the notes and the questions that people have.

So thank you, everybody.

See you next time.

Thanks a lot, guys.


SPEAKER_08:
Happy Halloween.