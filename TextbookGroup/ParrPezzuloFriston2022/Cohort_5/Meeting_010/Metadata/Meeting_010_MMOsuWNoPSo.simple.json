[
  {
    "start": 2.242,
    "end": 10.873,
    "text": " Thank you for joining everyone it's 1121 and we're in our first discussion for cohort five chapter five.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 12.435,
    "end": 14.657,
    "text": "Before we go to any specific questions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 16.64,
    "end": 27.473,
    "text": "Where does anybody want to begin or just any anywhere chapter five related or adjacent that they want to just begin with.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 63.143,
    "end": 91.243,
    "text": " any thoughts on the chapter overall or like where it sits in the book or just any anything else at the whole textbook level or chapter five level um yeah i just this is a little specific but so far i think this might be the chapter that goes the most into",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 91.865,
    "end": 121.433,
    "text": " precision and that's kind of a I don't know that it's such a key concept it seems an active inference that I just find that really interesting here I especially find the discussion of like like getting more into the neurobiological aspect of like different neurotransmitters corresponding to tuning like different precisions like dopamine policies and",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 121.97,
    "end": 125.677,
    "text": " nor adrenaline transitions and so on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 130.806,
    "end": 131.147,
    "text": "Yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 132.549,
    "end": 132.87,
    "text": "Yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 135.014,
    "end": 136.857,
    "text": "Whereas often the",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 138.136,
    "end": 161.376,
    "text": " material aspects of the brain are linked to the kind of estimate of the mean like with rate coding here it's a connection between neurotransmitters or or sometimes called neuromodulators because through precision modulation they're influencing how different things happen",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 161.356,
    "end": 190.907,
    "text": " of course recognizing that like even the same molecule because of the receptor being different and the downstream processing and the context being different like it's not even like one neurotransmitter does one thing even in one species brain so of course this is painting with a broad brush but still these are real research programs that have benefited from unifying different experimental results related to a neurotransmitter",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 190.887,
    "end": 205.352,
    "text": " under the umbrella of like a model parameter specifically precision parameters precision and and variants just kind of being like two ways to describe it like how thin or how wide it's like the same thing you're talking about",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 214.462,
    "end": 237.28,
    "text": " and in chapter five being where any empirical evidence even comes in or any specific non-toy example comes in oh chapter one overview low and high road chapter four just the math and the details of the generative model so here's the first time that we're even talking about a real specific system",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 238.593,
    "end": 265.41,
    "text": " which gives a flavor of like the kind of experiments that people have done kind of framings that people take towards the mammalian nervous system human nervous system not to say that's the only system that active applies to or anything like that but just that that's where the most empirical work to date has happened so to provide just one more chapter in between chapter four describing the generative model",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 265.508,
    "end": 267.631,
    "text": " And chapter six, how to build your own.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 268.271,
    "end": 279.565,
    "text": "Chapter five is just like this kind of empirical waypoint to show here's what some research programs involving chapters one through four look like.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 280.827,
    "end": 286.133,
    "text": "Okay, now chapter six, here's how you would do that in this system or in a different system.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 317.467,
    "end": 328.862,
    "text": " This first paragraph has an important idea about the sparsity of the statistical model and then the sparsity of the anatomy of the system.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 329.884,
    "end": 337.534,
    "text": "And in the brain where those two sparsities kind of coexist, but having a sparser statistical model means that",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 337.514,
    "end": 348.402,
    "text": " variables tend to only influence a few other variables and that can make things easier to compute or easier to interpret statistically.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 350.018,
    "end": 357.454,
    "text": " Now, obviously, you can simplify it or sparsify it to a point where you're missing out important factors, then you've sparsified too much.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 358.196,
    "end": 363.989,
    "text": "But to the right extent, model sparsification makes it more computable, more interpretable.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 364.63,
    "end": 368.078,
    "text": "And the second sparsity is like the anatomical sparsity.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 368.058,
    "end": 390.454,
    "text": " which is the fact that although there are a lot of connections in the brain with the dendrites and the neurons and all of this and cells really are connected to a lot of other cells in the body they're not connected to all cells and so to the extent that not all things are connected to all things most directly or in a given way that's the morphological sparsity",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 392.847,
    "end": 406.992,
    "text": " And the kind of neuromorphic hypothesis is that the sparsity of the substrate has an interplay with the sparsity of the algorithm such that it can be carried out in an energy efficient way.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 420.134,
    "end": 428.906,
    "text": " In terms of the overall structure of the chapter, just please raise your hand or write in the chat if you have a question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 429.727,
    "end": 432.671,
    "text": "The overall structure of the chapter pretty much builds up to figure 5.5.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 432.951,
    "end": 440.221,
    "text": "Figure 5.5 represents these three neural systems or these three motifs.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 441.402,
    "end": 449.533,
    "text": "One of them is this kind of canonical cortical microcircuitry, the sort of thousand brains structure.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 450.256,
    "end": 456.183,
    "text": " Hawkins-Numenta-type cortical microcolumn in the prefrontal cortex.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 457.324,
    "end": 465.574,
    "text": "The second neural system considered, and then that's discussed in the context of a hierarchical predictive processing architecture.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 466.916,
    "end": 474.525,
    "text": "The second neural system discussed is the dopaminergic",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 474.505,
    "end": 493.628,
    "text": " see-saw in some of the dopaminergic regions of the of the brain and the basal ganglia and so on this balance between on one hand habit driven policy selection where the policy posterior is basically just passing forward the policy prior e",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 494.333,
    "end": 509.457,
    "text": " And on the other hand, the expected free energy updated policy posterior, where the policy prior gets like updated with G. And then policies are selected from either the best or drawn from G.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 509.437,
    "end": 525.066,
    "text": " that expected free energy updated uh policy space and then the third neural system considered is this spinal reflex arc this is like a cut across a spinal column",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 525.232,
    "end": 544.817,
    "text": " with sensory proprioceptive data coming in and a sort of error differential being calculated between descending prediction, incoming sensory data, and then that differential, basically the sign and the magnitude of that differential can be resolved locally through motor action.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 545.918,
    "end": 553.568,
    "text": "So it's kind of broadly sketching out a type of symbolic understanding or hierarchical prediction, a",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 555.202,
    "end": 583.892,
    "text": " motor and policy selection apparatus that can have different temperature values and then once the policy has been selected it is used in a kind of set point calculation and then the differential between the set point and the actual is used to enact the policy so the chapter kind of goes through those three different neural systems and sites work that goes into more in depth",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 585.239,
    "end": 600.75,
    "text": " But it's an example about how a subsystem motif is created, and then also how they can be composed and assembled to start to get to these more composite synthetic architectures.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 613.117,
    "end": 616.882,
    "text": " Anyone have like a thought or a question or a quote they want to go to, or we can look to the questions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 627.276,
    "end": 638.07,
    "text": "I had a question like in that 5.5 in the figure, which is short, what were the, what are the elements in the, in the bottom half of it?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 639.632,
    "end": 639.732,
    "text": "Like,",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 641.585,
    "end": 666.293,
    "text": " like yeah this this Pi three this is all this third yeah this this areas yeah um do you want to look at this the basal ganglia section in the chapter uh-huh okay okay yeah but yeah let's let's look so first part is that cortical motif",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 667.893,
    "end": 672.451,
    "text": " Second part is that the sensory motor.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 672.471,
    "end": 673.997,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 674.017,
    "end": 678.696,
    "text": "Then here's where we get to the dopamine part, the subcortical structures.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 685.392,
    "end": 700.65,
    "text": " first they're introducing some of the empirical gross and fine histology like which actual parts of the brain are connected to what and expressing what subclasses of dopamine receptors",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 702.233,
    "end": 727.633,
    "text": " Because of the biosemiotic interpretation of what different anatomical connections map to, like if it's coming from a proprioceptor, we're just going to call that a proprioceptive input, they use some of those empirical structurings to associate with different aspects of the model.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 736.237,
    "end": 764.32,
    "text": " um it just they're like discussing even though the the images later down yeah yeah that so they describe it then they talk a little bit about parkinson's and about time scales in terms of what um that image is showing",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 766.291,
    "end": 776.42,
    "text": " And those images are like anatomically representative of the basal ganglia or the striatum, something like that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 778.322,
    "end": 779.824,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 779.844,
    "end": 780.925,
    "text": "Yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 780.945,
    "end": 786.59,
    "text": "I'm going to go to a figure where the beta and gamma are shown clearly.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 789.072,
    "end": 789.492,
    "text": "Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 789.512,
    "end": 792.555,
    "text": "So here's a step-by-step tutorial from Ryan Smith.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 792.655,
    "end": 795.538,
    "text": "This is model stream, discussing model stream one.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 797.02,
    "end": 822.336,
    "text": " um okay so um this step by step builds up to the model at the bottom right from first static perception so prior hidden state mapping between states and observations observations thermometer in the room truth true underlying hidden temperature prior on temperature mapping between thermometer and the temperature in the room",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 824.071,
    "end": 826.395,
    "text": " Then the B matrix is introduced.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 826.735,
    "end": 832.043,
    "text": "This is a different pedagogical path than the textbook takes, which is why it's a good complementary resource.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 832.965,
    "end": 837.592,
    "text": "Then from here, we have the same L. Then B is the transition matrix.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 837.852,
    "end": 842.599,
    "text": "So that's how the temperature in the room actually changes time to time as modeled.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 843.781,
    "end": 846.565,
    "text": "Could stay the same, could change.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 846.585,
    "end": 848.448,
    "text": "This is still a passive inference problem.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 848.729,
    "end": 853.015,
    "text": "And this is like the music listening example from Chapter 7 in the textbook.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 853.417,
    "end": 857.543,
    "text": " Then the upstairs control component is introduced.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 858.023,
    "end": 858.905,
    "text": "Pi is policy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 859.586,
    "end": 862.61,
    "text": "Policy intervenes in the transition matrix.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 862.69,
    "end": 866.335,
    "text": "It basically selects a transition matrix to use.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 866.976,
    "end": 880.875,
    "text": "So as many policies as there are, they're like index cards, and then one of them is selected out, and that's the matrix that's used for the transition under that policy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 881.497,
    "end": 887.935,
    "text": " policy selected by this expected free energy calculation on the policy prior.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 887.955,
    "end": 892.789,
    "text": "And part of that, the pragmatic value component is driven by the preference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 894.322,
    "end": 899.691,
    "text": " And then finally, on the bottom right, it's kind of like a slightly fuller version.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 899.832,
    "end": 905.542,
    "text": "Now, there's no fullest version because you could continue to add uncertainties and all these other things to all the parameters.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 905.582,
    "end": 906.964,
    "text": "So it's not like the stopping point.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 906.984,
    "end": 914.237,
    "text": "But here, it's more explicit that the policy is driven not just by...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 914.217,
    "end": 937.828,
    "text": " expected free energy based evaluation but but also it's driven by the prior on policy here it's just being shown more clearly and then here's that like variance on policy and it's just saying that that gamma is like one over beta so just saying whether you think of it as like being high precision or low variance",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 938.028,
    "end": 960.289,
    "text": " or high variance slash low precision those are the same it's like saying how light is this how heavy is this it's like you're getting the same value so what that variance or precision on policy is doing is it's taking the g updated policy posterior this is what functionally what it's doing",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 960.505,
    "end": 969.456,
    "text": " And it's sharpening or flattening that resulting distribution of policy likelihoods.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 970.578,
    "end": 981.552,
    "text": "So under the high temperature setting, low precision, high variance policy sampling setting, then differences amongst policies are blurred.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 981.734,
    "end": 994.854,
    "text": " So that's one dimension that policy selections control that, is whether differences amongst policies are blurred or in the low temperature setting, whether the policy that's slightly more likely is always selected.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 995.615,
    "end": 997.377,
    "text": "So that's the temperature component.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 998.058,
    "end": 1001.143,
    "text": "And then there's within...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1002.406,
    "end": 1019.014,
    "text": " Let's just say lower temperature decision-making, there's this question of how much does G sharpen pi, ranging from none at all, policy prior just getting passed through, to high level.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1020.293,
    "end": 1049.743,
    "text": " sharpening it a lot so a policy with even a little bit more or a little bit better expected free energy a little bit more expected um pragmatic or epistemic value becomes like greatly differentiated from other policies sanjeev's textbook has some really good visualizations of like how these different features influence each other nikos",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1051.58,
    "end": 1076.794,
    "text": " uh what was that textbook and uh also have a question about one of the diagrams um sanjeev namjoshi's active inference textbook like kind of in preparation if anybody wants to see it then then then email and let us know um but but he has some new new ways to lay out some of the spaces of those like that kind of space of policy like high and low temperature and then like all those things",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1078.175,
    "end": 1081.701,
    "text": " But those are like some of the knobs that exist.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1084.906,
    "end": 1090.055,
    "text": "On that diagram that you had before, I think it was of the PMDPs with increasing complexity.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1091.457,
    "end": 1091.718,
    "text": "Yeah.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1091.778,
    "end": 1098.529,
    "text": "So just to confirm, so are these, each letter is representing an expectation matrix or some,",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1101.749,
    "end": 1112.485,
    "text": " Those are all matrices, and that would be, I guess I'm trying to understand if all of these are internal to the system that's doing the modeling.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1112.505,
    "end": 1113.246,
    "text": "Good question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1114.448,
    "end": 1117.152,
    "text": "The environment is not shown here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1118.154,
    "end": 1120.998,
    "text": "These are all describing the agent itself.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1122.2,
    "end": 1127.588,
    "text": "And then the difference between the square and the circle, they're all variables in the computer program.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1127.872,
    "end": 1136.441,
    "text": " So, but however, as shown, the squares are kind of like the ones that tend to be kind of stated and fixed.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1137.602,
    "end": 1144.369,
    "text": "And then the circles are the ones that are getting, like that are being, where inference is happening, like state inference is happening on them.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1146.351,
    "end": 1147.612,
    "text": "But that's not an in principle thing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1147.892,
    "end": 1150.395,
    "text": "It's actually just sort of an implicit graphical style.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1152.256,
    "end": 1153.778,
    "text": "They might describe it in the caption.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1156.205,
    "end": 1157.667,
    "text": " But ultimately they're all just variables.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1159.03,
    "end": 1159.35,
    "text": "Okay.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1159.37,
    "end": 1159.651,
    "text": "Got it.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1159.671,
    "end": 1159.911,
    "text": "Thanks.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1180.084,
    "end": 1180.464,
    "text": "Yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1180.484,
    "end": 1180.845,
    "text": "Thanks.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1182.597,
    "end": 1201.652,
    "text": " the lowest level i think those were sigmas little tiny sigmas isn't when it's observation doesn't it touch on the environment or it's still we consider it still it was on the previous picture you were showing bigger like those the lowest the the",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1202.56,
    "end": 1227.437,
    "text": " yeah observations yes the o's yes like this is the thermometer reading at time point one two and three so it's it's on the robot but it does relate to the environment so you're right it is coming from the environment this is kind of the where um these are the sense states so to speak but they're on board they're not this is not modeling the environment yeah",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1227.94,
    "end": 1240.183,
    "text": " And can I ask something, where DeVry was mentioning common filters, would that be that area that you were just showing, the observations, like kind of be modeled as a common filter?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1240.243,
    "end": 1249.02,
    "text": "Or am I off track here?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1250.772,
    "end": 1277.185,
    "text": " yeah it's a great so here's from 7.1 it's the only place I see where um common filters mentioned in this coda so like here's the bottom left there here's the seven figure 7.1 so it's same exact thing so Coleman filter um like we could look it up and there's a ton of things to go into but a common filter is basically solving the inference problem how much decay should the signal have",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1278.16,
    "end": 1304.775,
    "text": " much time averaging and how should the signal decay through time so that we're not like over under smoothing so it's very related to to generalized filtering it's just like how much should we smooth this signal to do optimal reconstruction on it so you could interpret you you could interpret this as doing a coleman",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1305.278,
    "end": 1323.287,
    "text": " estimation through time probably getting in a sequence of observations and needing to do an underlying state estimate through them that's smoother we're getting noisy estimates from the thermometer and then we're gonna like draw a line of best fit basically through them",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1326.44,
    "end": 1332.046,
    "text": " Or you could interpret these, that would be over a very fast, that would be like a fast timescale.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1332.306,
    "end": 1339.755,
    "text": "Or maybe we're talking about the hidden state every minute.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1339.775,
    "end": 1340.916,
    "text": "And now it's slower.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1341.837,
    "end": 1352.869,
    "text": "And now we're just thinking, okay, the A matrix summarizes a kind of smoothing so that we're not, you know, there's probably different ways to do it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1360.983,
    "end": 1362.244,
    "text": " Let's see if it's in the textbook.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1369.512,
    "end": 1370.112,
    "text": "Chapter four.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1380.643,
    "end": 1386.069,
    "text": "Part of smoothing, part of optimal smoothing is estimating how variable it is.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1387.39,
    "end": 1390.213,
    "text": "So that's another connection with the precision estimate.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1393.467,
    "end": 1398.255,
    "text": " If it's highly variable, you need to do a lot of smoothing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1400.278,
    "end": 1404.285,
    "text": "If it's low variability, you don't need to smooth that much.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1408.652,
    "end": 1416.825,
    "text": "And then there's some technical points about whether like the fluctuations of the stochastic process are this way or that way.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1452.192,
    "end": 1463.208,
    "text": " Here's one case where the precision on policy matters that they bring up on page 92.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1464.891,
    "end": 1473.323,
    "text": "So here there's two policies that are possible, like staying seated and being standing, just to simplify.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1473.978,
    "end": 1477.483,
    "text": " And if we're seated, then we're getting sensory input that we're seated.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1477.603,
    "end": 1478.885,
    "text": "We're getting confirmatory evidence.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1478.905,
    "end": 1483.012,
    "text": "We have high precision on everything is kind of lined up.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1484.714,
    "end": 1486.557,
    "text": "The ball is kind of at the bottom of the bowl.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1487.458,
    "end": 1498.635,
    "text": "But how do we consider the adjacent possible sensory data that we would get from being standing?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1499.527,
    "end": 1525.703,
    "text": " such that that movement to standing can can actually be realized the reward learning approach there's there's different approaches so not not not to oversimplify but would be something like you have to switch something in the model so that standing is more rewarding and then learn or decide upon a policy by which that more rewarding policy is selected",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1526.425,
    "end": 1536.458,
    "text": " kind of just pushes up a question to how do you come to assign that standing state with higher reward?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1538.52,
    "end": 1551.377,
    "text": "Here, which is discussed in the context of standing and seating, it's also discussed in the context of isocating and precision on the sensory input.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1552.538,
    "end": 1555.622,
    "text": "And also, especially in literature,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1555.72,
    "end": 1581.103,
    "text": " precision on like more um cognitive parameters is associated with the wide range but the the movement and the saccadic are these are kind of like gross versions and it's kind of this common pattern where um in advance of a movement being made there's an attenuation of precision on the sensory input",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1582.062,
    "end": 1603.817,
    "text": " and then that enables it to become plausible that um the sensor data are this alternative way like the variability of the of the estimate on the incoming sense data includes both how it actually is and how it could be and then from that kind of like foot in the door possibility",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1604.303,
    "end": 1628.59,
    "text": " that is leveraged to actually select that possibility like the the the select the action shift is made while the foot's in the door and then as the precision is clamped back down it's like oh yeah it's totally likely impossible and confirmatory now that we're standing so that's this kind of sensory attenuation phenomena",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1628.992,
    "end": 1630.574,
    "text": " So that's kind of like attentional focusing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1631.054,
    "end": 1643.288,
    "text": "And then attenuation is like the opposite of attention or just describing like the diffusion or the suppression of attention, which is to say increasing the variance.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1643.308,
    "end": 1656.923,
    "text": "But that's an example about how, whether it's like a precision on sensory or precision on policy, like there's a lot of different knobs to play with, even without the kind of reward or habit",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1658.287,
    "end": 1688.142,
    "text": " or learning knobs but just in the precision knobs a lot of phenomena can arise but these are kind of the core statistical elements we return to estimates like expectations Center tendencies distributions variances and differentials like here",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1690.433,
    "end": 1690.693,
    "text": " Thanks.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1693.137,
    "end": 1694.199,
    "text": "That's a silly comment.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1694.219,
    "end": 1703.595,
    "text": "But I was thinking if someone can make a board game where we block out different the different knobs, and we only play with some knobs, that would be cool.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1704.757,
    "end": 1707.902,
    "text": "Yeah, if we can just play with it and see what happens.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1712.219,
    "end": 1715.885,
    "text": " Yeah, I hope we do have physical and digital games.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1716.226,
    "end": 1731.973,
    "text": "I have several times experienced when people doing somewhat like a guided thought journey with the goal to increase or reduce precision on different things.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1733.456,
    "end": 1737.062,
    "text": "Are there digital games that do this?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1739.827,
    "end": 1759.135,
    "text": " like none that I specifically know of there's Pablo et al's digital game related to active that they presented at the the symposium but but that wasn't explicitly like a psycho technology modulating precision but let's find out and add to this list",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1760.6,
    "end": 1788.497,
    "text": " with all the strengths and weaknesses in caveats of kind of entering at the phenomenological level like just our experiences on any given moment are not equivalent to the technical definition of some variance estimator but again it gives us a really good experience and sometimes it really does line up and like it does point to to really important phenomena",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1790.333,
    "end": 1792.376,
    "text": " Nicholas Alberson- And it helps help yeah nico's.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1796.282,
    "end": 1799.046,
    "text": "Nicholas Alberson- Sorry to interrupt I was just.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1799.407,
    "end": 1801.71,
    "text": "Nicholas Alberson- going to ask about figure 5.1.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1801.871,
    "end": 1811.786,
    "text": "Nicholas Alberson- That was pretty dense I was wondering if you could skim over it and, in particular.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1812.447,
    "end": 1817.995,
    "text": "Nicholas Alberson- Just highlight again the distinction between the subscript V and X.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1821.063,
    "end": 1822.827,
    "text": " in the middle column.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1824.17,
    "end": 1824.271,
    "text": "Okay.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1836.058,
    "end": 1837.722,
    "text": "Anyone want to give a thought on this first?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1852.737,
    "end": 1855.778,
    "text": " I'm just going to bring it in here so we can see it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1881.07,
    "end": 1905.323,
    "text": " okay so there's the six cortical layers just just so that people see the histological part of it there are these these six kind of semi-morphologically defined layers in the cortex this is not a six-layer hierarchical predictive processing architecture",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1906.619,
    "end": 1929.657,
    "text": " actually all six of them implement like one hierarchical node which is then associated laterally into something like higher order bayesian um nested models just to be clear we're talking about like a six layer integrated unit not a six layer hierarchical model but they are layers",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1929.89,
    "end": 1957.416,
    "text": " um okay the left side summarizes these literature cited and um the cell types are described like with SS SP and this is just describing the actual cell populations and their connections the middle message passing that underwrites hierarchical predictive coding so there's two um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1958.712,
    "end": 1962.497,
    "text": " Matt Bolian- kinds of nodes here there's mu for.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1962.898,
    "end": 1970.307,
    "text": "Matt Bolian- let's let's double check, but I believe tilda is representing as it usually does through time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1970.327,
    "end": 1977.497,
    "text": "Matt Bolian- or generalized coordinates i'm not sure.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1978.818,
    "end": 1981.862,
    "text": "Matt Bolian- um.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1981.882,
    "end": 1982.323,
    "text": "Matt Bolian- V and X.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1991.078,
    "end": 1993.782,
    "text": " I just want to find where X is defined or used in the text.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2000.771,
    "end": 2003.715,
    "text": "I think the last time I saw it was back in chapter four.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2003.735,
    "end": 2006.659,
    "text": "I don't know if he restated it.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2010.124,
    "end": 2011.907,
    "text": "Yeah, where X and V were used.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2015.772,
    "end": 2016.613,
    "text": "Yeah, I...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2019.31,
    "end": 2029.567,
    "text": " I would go with the mu and X and V definitions from four, unless it looks like they're being changed.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2032.853,
    "end": 2044.592,
    "text": "X in this situation, so here in 4.15 is kind of a classical SPM style two equation setup.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2045.905,
    "end": 2050.674,
    "text": " The second line is our neuroimaging device.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2051.436,
    "end": 2068.909,
    "text": "We're getting sensor data Y, real scientist sensor data Y. It's a function of underlying neural activity and V, this kind of control, unobserved control state plus sensor noise.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2069.125,
    "end": 2092.737,
    "text": " then change in the neural activity through time is defined by um its state at the current moment and then then this causal force v plus a variability associated with with it what would an example of a causal force be like the attentional state",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2094.117,
    "end": 2122.453,
    "text": " as far as i understand this from spm so this would be like the neural activity at a given time so here's the bold signal or the um eeg signal x would be the the um the actual neuronal activity which is what what um synchronously connects to a given sensor measurement and then this would be like the like attention or no attention unfoldings of that system okay",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2122.838,
    "end": 2126.703,
    "text": " I believe this is accurate.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2126.743,
    "end": 2127.484,
    "text": "Now let's return here.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2127.544,
    "end": 2134.614,
    "text": "But we should confirm and we should annotate the figure.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2135.055,
    "end": 2142.805,
    "text": "If someone puts in the research and feels confident, then please annotate the figure so that we don't need to do ad hoc.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2144.135,
    "end": 2166.092,
    "text": " interpretation because I'd like to have the ontology based just simple description of this to actually go to rather than need to Forge for it it's it's an interesting progression that they go through because on the right",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2167.507,
    "end": 2182.613,
    "text": " is where we see the kind of o and s pomdp type um variables whereas in the middle is the message passing more chapter four like variables",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2186.474,
    "end": 2197.744,
    "text": " And it would be good to understand if if where are one to one assertions or concordance is being claims and what would the interpretation of that be.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2202.989,
    "end": 2204.991,
    "text": "We can look to the papers to see more.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2212.918,
    "end": 2214.439,
    "text": "But on the incoming.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2216.866,
    "end": 2245.405,
    "text": " our sensory areas, our information flow is coming in and then kind of policy relevant action information is coming out modeled by the A matrix and the hidden states coming in and the, um,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2247.511,
    "end": 2248.693,
    "text": " at a lower level.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2249.314,
    "end": 2253.881,
    "text": "So this is the kind of hierarchical logic, lower level state estimates coming in.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2253.901,
    "end": 2263.336,
    "text": "And then at the ith level, the state estimates being done here, influencing policy selection.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2265.66,
    "end": 2273.012,
    "text": "But a lot more remains to be connected about how these are how this is formally linked to to, you know, for and elsewhere.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2275.54,
    "end": 2277.743,
    "text": " Do you mind if I take a stab at it?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2277.763,
    "end": 2278.645,
    "text": "Yeah, please.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2278.665,
    "end": 2280.548,
    "text": "Let me know if it is in the ballpark.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2282.751,
    "end": 2300.738,
    "text": "X could be maybe, for example, like glucose metabolism or how cells are regulating their glucose metabolism, and V would be some underlying maybe thought process.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2302.473,
    "end": 2316.527,
    "text": " Governing where attention and I guess thought process that is being influenced by, you know, some deeper dynamics going on in a nervous system.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2319.791,
    "end": 2321.612,
    "text": "Would that be kind of an accurate?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2321.652,
    "end": 2331.062,
    "text": "So those are, those processes are both happening in the cortex, but they're representing two different",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2332.105,
    "end": 2337.517,
    "text": " physical processes that are influencing each other?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2342.167,
    "end": 2342.568,
    "text": "Perhaps.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2345.194,
    "end": 2349.523,
    "text": "Hard to evaluate just in the moment, but it would be cool to flesh it out.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2350.706,
    "end": 2350.806,
    "text": "Okay.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2354.009,
    "end": 2362.433,
    "text": " cool thanks yeah thank you no it's good we we we should have good accounts of all the figures because",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2366.952,
    "end": 2385.921,
    "text": " Yeah, I just was trying to understand the diagram, and they were also mentioning that information is flowing from lower cortical areas, and this directionality, it's like this information is going to layer four, and then from three, it's going to higher layers.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2385.941,
    "end": 2389.947,
    "text": "So we have that flow of information, which can also help us in understanding that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2393.613,
    "end": 2393.933,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2394.554,
    "end": 2395.576,
    "text": "Just wanted to point that out.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2395.596,
    "end": 2395.896,
    "text": "That's it.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2404.465,
    "end": 2431.705,
    "text": " yeah here's where a three a three layer Bayesian model is being shown and kind of the lower the middle and the higher level and each of these levels they're sending up um observations that are being juxtaposed with the descending predictions within a column and for each X",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2433.457,
    "end": 2441.611,
    "text": " And for V, there is a mu and there's a mean and a differential estimators.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2450.527,
    "end": 2452.731,
    "text": "It could be the mean and the variance.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2461.402,
    "end": 2487.325,
    "text": " and that's not even incompatible with it being um the um neural activity and the regime of attention under the model that that the variance is what is controllable high and low variance condition which is exactly this kind of neuromodulator as internal policy saying well this is the knob that you can control",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2488.402,
    "end": 2502.546,
    "text": " you can release or or not release and you know modify the sensitivity of the postsynaptic neuron and the downstream receptor and all that but you can't just be like well this neural population is firing at",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2503.673,
    "end": 2533.613,
    "text": " intensity four let's just make its intensity nine because there isn't a way for the postsynaptic neuron necessarily to send back and and to know what to ask for or to make that retrograde ask on the right time scale so different synaptic mechanisms modify the precision so that different neural messages can be tuned in and tuned out",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2539.685,
    "end": 2567.38,
    "text": " brain's a complex system even as as mentioned in 56.2 today um like even the nematode and the fully mapped nervous systems of the fruit fly and the honeybee have a lot of sophistication not that it's like a ladder of complexity or anything like that but just these are big big",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2569.317,
    "end": 2591.511,
    "text": " evocative simplified models however they are really developed out and used in precision neural settings and where there are important critiques and and um extensions those are literally research and development Advances",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2603.337,
    "end": 2631.471,
    "text": " but the chapter tries to represent like a little bit of a higher symbolic generalized a little bit of a more basal or elementary cognitive reflux arc and then the kind of like in between with the dopaminergic policy selection um Andrew um yeah just for like I guess like clarification and maybe there's not enough information here to",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2631.873,
    "end": 2633.194,
    "text": " be able to fully answer it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2633.335,
    "end": 2642.385,
    "text": "But like on 98, with back to the different neurotransmitters, or I guess neuromodulators.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2643.085,
    "end": 2654.238,
    "text": "So like, for example, with serotonin there at the bottom of the list, and preferences, or interoceptive likelihood being like the precision that's that it's being modulated.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2654.258,
    "end": 2656.48,
    "text": "And that case would like a",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2656.898,
    "end": 2662.267,
    "text": " a way we could say that is that serotonin is changing the.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2665.492,
    "end": 2671.161,
    "text": "So it's modulating the precision, meaning it's like adjusting.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2671.201,
    "end": 2673.905,
    "text": "Basically.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2673.945,
    "end": 2681.758,
    "text": "How how confident one can be in",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2682.886,
    "end": 2706.582,
    "text": " in the interoceptive likelihood such as someone is currently experiencing i don't know like a increased heart rate and there's like a signal coming in like informing them of that or their breathing is faster or you know they're hungry right now or something um a higher precision like if this is really simplifying everything but like",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2706.832,
    "end": 2736.282,
    "text": " say serotonin were the key lever here that says okay the serotonin is released it modulates the precision of a hunger signal such that you now pay more attention i suppose to that hunger signal or it appears stronger or rather the the likelihood or precision of like i'm feeling this sensation uh i'm certain i'm like very confident that it means i am hungry like",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2736.869,
    "end": 2760.345,
    "text": " that kind of how that is playing out in some way if that wasn't too much that's a good question also they mentioned preferences or interoceptive likelihood but of course they're not the same thing but let's let's think about what that would be yeah to have a precise preference distribution would be like",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2760.325,
    "end": 2764.972,
    "text": " I really want the die to come up as one and I really don't like two through six.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2765.733,
    "end": 2768.917,
    "text": "Imprecise would be like kind of flat across preference distributions.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2769.618,
    "end": 2776.187,
    "text": "So what would it be like to have the flat or sharp interoceptive likelihood distribution?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2776.988,
    "end": 2783.838,
    "text": "Well, if it were totally flat, I'm getting ambiguous signals from interoception.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2785.14,
    "end": 2785.32,
    "text": "I'm not",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2786.65,
    "end": 2794.584,
    "text": " I'm not getting useful or epistemically meaningful information about whether my heart rate is high or low.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2796.226,
    "end": 2806.324,
    "text": "High precision, I'm super sure that I know what my interoceptive state is.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2808.468,
    "end": 2811.072,
    "text": "Could be a false precision on the extreme case too.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2814.376,
    "end": 2823.444,
    "text": " But if this is dealing with the parameter, I don't even think they're using, at least not in this chapter.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2831.572,
    "end": 2834.334,
    "text": "One reason why the precisions matter.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2834.374,
    "end": 2842.982,
    "text": "Hmm.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2844.228,
    "end": 2846.73,
    "text": " Okay, so here's figure 7.10.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2847.832,
    "end": 2852.596,
    "text": "So here's the kind of figure 4.3 that we usually see, POMDP.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2853.677,
    "end": 2868.071,
    "text": "And now the A, B, C, D, and E, the variables that you specify, like in chapter six, to have the agent, those all have these lowercase distributions on top of them.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2868.172,
    "end": 2872.716,
    "text": "There are priors on the other distribution.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2874.383,
    "end": 2880.562,
    "text": " And so that prior distribution, so like, let's just say it's a coin flip setting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2880.582,
    "end": 2884.615,
    "text": "We could say, I have my prior is like one, zero.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2884.936,
    "end": 2887.363,
    "text": "It started on heads, period.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2887.462,
    "end": 2910.702,
    "text": " or your prior could be 50 50 0.5 0.5 like um I I'm equally confident that it started on one or the other state that's without the lowercase d so now we add in say we're gonna draw our prior on D across trials we're gonna draw that from 0.5 0.5 plus or minus 0.1",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2911.07,
    "end": 2918.14,
    "text": " So then one trial, you start with a prior 0.6, 0.4, then 0.4, 0.6, and 0.5, 0.5, and so on.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2918.26,
    "end": 2925.711,
    "text": "So you're drawing from a prior about D. And then that could be narrow or it could be tight.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2927.613,
    "end": 2936.706,
    "text": "And then just like in any other Bayesian statistical setting, like when a distribution is wider, it can be moved more.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2937.277,
    "end": 2948.118,
    "text": " The distributions narrow even incredible evidence is going to be basically systematically down weighted so severely that the distributional is going to move a little bit.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2950.202,
    "end": 2950.543,
    "text": "um.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2952.211,
    "end": 2979.653,
    "text": " even though the evidence may repeatedly be signaling that it's off in the extreme case if you have like the Delta distribution just like a spike you say no the average um height of the children in the classroom is five feet plus or minus zero then even getting other values doesn't update your distribution but these are like variance parameters you can think of on the other ones",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2980.662,
    "end": 3008.087,
    "text": " because these are basically again to return to those simple statistical motifs we can basically be talking about the central tendency of a distribution like the the median or the mean the average expectation Laplacian approximation all these things so central tendency mean variance or variability those are kind of the two parameters as part of like the generalized Gaussian scheme",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3008.337,
    "end": 3034.902,
    "text": " and then a simple motif is like a differential between two means but a big part of the simplicity of the hierarchical predictive processing architecture is all it does is calculate means variances and differentials and that there's no parameter that's loaded up with like Mega significance",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3036.215,
    "end": 3044.424,
    "text": " and taking on like too much more than just describing a mean variance or differential for a given model feature.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3046.686,
    "end": 3047.026,
    "text": "Nikos?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3049.249,
    "end": 3065.125,
    "text": "So just to clarify, were you saying that the variance in, for example, a normal distribution is equivalent to the precision in this sense?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3065.577,
    "end": 3090.319,
    "text": " um the the like just just it's in the spirit of I know that there might be like a little bit of technical detail if it's like a covariance or something like that but yes the the standard deviation a larger standard deviation is larger variance but I know there's like standard deviation and variance but yes at a broad scale just talking about how fuzzy versus Sharpa distribution is",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3093.134,
    "end": 3097.259,
    "text": " High precision Gaussian, low variance, low standard deviation.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3099.561,
    "end": 3102.945,
    "text": "Low precision, high variance, big standard deviation.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3104.087,
    "end": 3117.522,
    "text": "In the flatter the curves, basically, the more leeway you have in picking whatever the policy, whatever the curve represents, policies or beliefs or whatever.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3118.143,
    "end": 3143.104,
    "text": " yeah limit case uniform distribution like everything's equally likely then like whatever data point you get is like as good is the best one that you have yeah the other limit case the Delta distribution whatever data point you get you go with what you already thought can you go back to the diagram that you had up just a second ago um just had a quick question about that was it",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3143.759,
    "end": 3149.184,
    "text": " I think it was the POMDP with the ABCD.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3150.506,
    "end": 3151.467,
    "text": "Oh, OK, OK.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3157.553,
    "end": 3163.058,
    "text": "And this is just to really try to understand this model a little bit better.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3163.098,
    "end": 3167.303,
    "text": "Is there any particular point in this model?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3168.023,
    "end": 3171.707,
    "text": "And I know it's a little bit different for the one with the squiggly lines",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3172.278,
    "end": 3173.861,
    "text": " Chapter 4.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3174.241,
    "end": 3182.396,
    "text": "But is there any particular point in here where variational or expected free energy is being calculated that we could point to?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3183.237,
    "end": 3189.308,
    "text": "Yes, 100% of those calculations are of expected free energy are happening at the G.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3189.76,
    "end": 3218.063,
    "text": " g is a functional it's a node that's taking in habit and preference and policy prior and it's outputting the policy posterior the whole upstairs is the decision making apparatus the whole downstairs is just hidden state observations mapping prior so expected free energy never enters into the downstairs component but that downstairs sense making could be described by variational free energy",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3219.562,
    "end": 3220.744,
    "text": " Okay, got it.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3220.764,
    "end": 3223.969,
    "text": "So that's really helpful.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3224.109,
    "end": 3231.4,
    "text": "And is there some implied intuition here that there's a feedback loop going on?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3231.42,
    "end": 3234.484,
    "text": "I guess that just happens during message passing iterations.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3235.365,
    "end": 3236.968,
    "text": "Feedback loop what?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3239.692,
    "end": 3246.582,
    "text": "You know, there's a lot of diagrams, especially earlier in the book, that are going from perception to action, perception to action.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3247.237,
    "end": 3272.805,
    "text": " yeah great great point great point here the policy selection it just kind of selects an internal index card and then it's like but then that's actually chosen and admitted to the niche and then that results in the next observation coming in differently or not but yes that is not shown the like the markov blanket or the relationship between the agent and the niece are not shown that's helpful",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3273.241,
    "end": 3296.262,
    "text": " yeah and and again Sanjeev's textbook I I I hope so he'll share some of these images or people can can look into it because he has some different representations that that dispel a lot of the inertia of how things were visualized not all of it but but helped a lot um inks and then any other like last thoughts people have",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3298.705,
    "end": 3323.464,
    "text": " i'm turning us back i think to precision modulation i was thinking of last time andrew was saying these are just constraints and i was trying to imagine what constraints would look like with precision modulation but i was imagining this game i don't know if you have it in america like warm warmer warmer hot cool colder like as you're approaching an object right like",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3323.714,
    "end": 3331.412,
    "text": " Like I imagine the dopamine is doing that, like giving you a warm, warm, warmer towards how right you are about something you're predicting.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3333.029,
    "end": 3334.931,
    "text": " That's awesome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3334.951,
    "end": 3345.081,
    "text": "That's very much like the kind of valence in the sophisticated active inference that modeled valence, like psychological valence, positive or negative.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3345.421,
    "end": 3348.244,
    "text": "They associated that exactly with precision estimates.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3348.905,
    "end": 3353.069,
    "text": "If things are as variable as you expect them to be, you have neutral valence.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3353.81,
    "end": 3357.954,
    "text": "If things are more precise than you expect them to be, you have positive valence.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3358.074,
    "end": 3360.336,
    "text": "If things are more surprising...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3360.316,
    "end": 3381.261,
    "text": " then you expect them to have negative valence and anxiety and then it's like the signal that that is given by by valence which is like the top level you know which way is the wind blowing of the whole body is like is it getting warmer am I getting warmer or not is my free energy on the right track",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3382.507,
    "end": 3387.873,
    "text": " on the lukewarm expected or whatever someone wants to calibrate their bath to.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3388.834,
    "end": 3393.299,
    "text": "And that's why they were positing multiple axes of positive and negative valence, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3393.359,
    "end": 3394.821,
    "text": "It's not positive to negative.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3394.961,
    "end": 3399.085,
    "text": "It's precision evaluating different predictions you have.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3399.105,
    "end": 3406.654,
    "text": "So I imagine sometimes you're predicting something you're not happy about, but the precision is kind of making you, oh, I'm right.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3407.134,
    "end": 3410.758,
    "text": "So there's like a bad positive valence there.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3411.852,
    "end": 3434.873,
    "text": " oh yeah um I'm I'm I'm as expected that I'm the kind of person who sees scary movies that surprised me but I'm not surprised in that I'm surprised that I feel this way I mean those are the higher order um yarns to unwrap these are just the elemental",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3435.899,
    "end": 3464.016,
    "text": " kind of legos thank you everybody beautiful thank you this is fun times as we kind of as as the as the niche continues to evolve around us and we come close to our last discussion and the end of the year so thank you fellow see you next time bye thank you",
    "speaker": "SPEAKER_00"
  }
]