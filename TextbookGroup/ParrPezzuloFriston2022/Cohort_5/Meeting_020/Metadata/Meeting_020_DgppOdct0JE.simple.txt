SPEAKER_01:
All right.

Welcome.

Thanks for joining.

We're in cohort five in the first discussion of chapter nine.

In terms of the book.

We made our way through the epistemic first half, the recipe for making a generative model in chapter six, then the discrete and the continuous time generative models in seven and eight.

Now we get to chapter nine, which is the data-driven component.

So pretty much up to this point, everything has been like, you think of it conceptually, you create the model, and then it generates synthetic data.

that's using a generative model in the direction that's usually called generative.

It's generating data.

The other direction of use for an active inference model or statistical model is as a recognition model.

So that's taking in empirical data and then fitting parameters that recognize the patterns in the empirical data.

So chapter nine highlights that kind of back and forth.

about designing generative models that take in data that's being emitted by empirical experiments, like behavioral experiments in lab.

So that's what chapter nine is about.

You, if you want to ask the question that you had first, and then we can like jump in there, explore empirical data, look at some PyMDP and empirical code, just see what happens.

But what was your question before we begin?


SPEAKER_03:
Oh, I have no specific question.

It's just I noticed a lot of people have commented on that paper.

So I suspect it's something completely new direction in the field.

So yes.

So could you comment on the main point of this paper?


SPEAKER_01:
Yes.

Yeah.

Great.

So this was the paper path integrals, particular kinds and strange things.

It was first uploaded to archive in 2022, and then it was submitted to this journal called Physics of Life Reviews.

So Physics of Life Reviews has a very interesting scope.

If you look at the structure of this journal, they publish like regular research as well as comments on research.

And so during the process of this paper being like kind of undergoing peer review from the archive version,

They also, once they get to basically the final version, they solicit from a pretty broad and open community these short comment papers.

So like Ali and I wrote a paper commenting on this, just like a two-page paper.

Those comment papers are not peer-reviewed exactly.

They're more like editorially overviewed.

um so i mean we see many many names that we know because it's kind of like an easy and fun way to be part of a bigger discussion get a citation pump up the citations to the target paper um so that's kind of the the meta um on this okay so as for the contents itself

um it is not entirely new it builds on especially the 2019 first in work free energy principle for a particular physics um to connect it to the textbook all throughout the 2022 textbook like we're talking about the continuous time and the discrete time models so um let's look at figure 4.3

So in the discrete time setting, we have a transition operator that basically jumps you forward a discrete time step.

In the continuous time setting, the way that we've been discussing it in the textbook is in terms of the Taylor series approximation.

So starting with a point, evaluating at the point, then taking the first derivative around the point, and then the second derivative around the point, and so on.

So that is in a continuous setting.

That idea of like doing active inference in a continuous setting

is is generalized and formalized by framing the free energy principle not just in terms of the transition probabilities in a discrete model not just in terms of the taylor series approximation or the generalized state space of continuous time model but actually in a path integral formation so that's kind of like there's like a thread

that's like the likeliest thing to happen, that's the path of least action, like the baseball doing a parabola.

Like whether you knew about it right at the beginning with the initial conditions or whether you had tracked the whole baseball, it's like it does do a parabola.

That's classical movement, but still.

And then it's kind of like there's like a sheath around that trace with paths that the baseball could have taken that are just exponentially less and less likely.

Like it could have hit just a bunch of molecules in a certain way at this one point and kind of diverted off course.

But because the baseball is very large relative to air molecules, it follows like a classical trajectory.

So the first thing they do is they kind of reconsolidate the free energy principle in terms of half integrals.

which can then be like dropped back down into the continuous time that we talk about in the textbook or the discrete time.

But like, especially with maybe the ways that they're taking it even further, like the path integral is kind of like the richest formalization.

Like if you go back to the variational calculus origins with Richard Feynman, they have to do with path integrals for particles.

So it's kind of like coming full circle in a way, because the Feynman diagram was developed in the setting of those exact questions.

Now they're applying it to cognitive particles.

And then, so that's one, that's kind of like the consolidation of the formalism component.

And then the second major contribution, and this is also the piece I think that Ollie and I focused on in our commentary, is like,

Previously, people had always talked about, well, active inference can apply from kind of simpler inert systems to simpler active systems all the way on through complex systems.

And people had introduced this notion of mirror versus active inference for something that a mirror active inference system is something you could model as doing active inference, but it might be kind of simple or boring.

Like, yeah, you could model that rock as...

flying but choosing not to fly but you've kind of brought out a big apparatus to model something that's not moving and so here with this figure and the discussion they brought a lot more clarity to these kind of classifications systems that don't evidence active states in an interesting way to a given observer not to say they don't right map and territory then systems that have activity

but the activity is kind of classical or conservative.

I don't know if a bacterium is really the right image here.

I think something like a pendulum might be clearer because bacteria can also have rich behavior.

All the way on through what they want to highlight here, which is like a metacognitive or a strange particle.

And that's also what Lars and Lancelot highlighted in their comment.

was about the Bayesian mechanics, not just across the partition, but okay, do the partition.

And now in the internal states, partition those again, as if those internal states have metacognition.

So it was a big paper for consolidating the formalism and for clarifying some of the different scopes


SPEAKER_03:
I see.


SPEAKER_01:
Yeah.


SPEAKER_03:
So it's one of the top down approach to look at active inference.


SPEAKER_01:
Yeah, I think so.

I mean,

It doesn't start from modeling a particular system.

It starts from more axiomatic considerations.

So in that kind of like physics based free energy principle side, whereas like active inference isn't mentioned in the abstract.

so it's like path integral formulation of the free energy principle systems that do that are active inference systems but here they're highlighting that that High Road formulation you see there might be other pieces too and I think I mean the commentaries are I haven't read them all but they're probably

People always do funny titles that suggest what they're about.

So maybe we can review them.

But in terms of getting diverse comments,

on a major piece of work this format which physics of life reviews does and a few other journals is really useful and like carl and others have used it multiple times well um we can look at any part of nine look at any questions also i have um

by MDP up in cursor.

So we could explore with language slash code models, like how you incorporate empirical data with the generative models.

Depends on whatever people want to do.

i think looking at codes would be great okay okay okay um okay we'll we'll see what we can do without um

I, I didn't like prepare anything specific, so we might have to debug a little bit or have a little fun, but, um, let's, uh, see, okay.

Um, just, just for context, PMDP documentation and the, uh, package itself.

infractively slash py mdp so this i just cloned in that repo so everything that's in the github i just pulled that in um okay so what do we want to look at or make a model of

Or is there an empirical data set that we want to connect it to or type of empirical data that we want to connect it to?


SPEAKER_03:
I have nothing specific in mind.


SPEAKER_01:
Let's do a discrete time model of

We could try to recapitulate one of the examples in the textbook, like the listening to music from chapter seven, or if there's some other like structure or type of data or kind of action selection that people want to explore, we might be able to do it.


SPEAKER_03:
Music is great.


SPEAKER_01:
Okay.

Okay.

Here, just, just, um, there's a lot of ways to, um, go, go into this, but, um, okay.

Okay.

Let's start with, um, let's just, if this all runs, then it'll be good to go.

Okay.

So agent agent demo.

So let's just see where, where it is in the documents.

Um,

I just want to find one that already has some visualizations.

And then we can see how it's built and how we can modify it.

Okay.

Okay.

Maybe the teammates.

Let's look at the TMAs and go through it and then see where the empirical data come into play.

But then we could... It doesn't have to be a spatial model.

Maybe we can see if it's possible or what would need to happen to modify the TMAs to be more like a music example or something.

I mean, this is...

In chapter nine, when they overview, here are the key figures, then we'll go to the code.

First, it's taking everything that was looked at before with a generative model.

And it's saying like, okay, we were making a map of the rat in the T maze.

Now let's zoom out to having the laboratory that encloses that rat in a T maze.

So we're choosing experimental stimuli and passing them to the rat.

Those are given the label O because they're observations for the subject.

And then the actions of the subject are our observations in the lab setting.

So this kind of, you can have another layer outside of the laboratory too, but this is just with focus on the system of interest.

This is like what the cognitive model is enclosed in.

9.2 shows kind of the process of like kind of what you need to get for empirical results in a paper where you have a team ace, build a POMDP, which we'll look at the code in a second.

Then chapter nine is, which I don't think will exist in the code so that we can try building that part out.

um you go from empirical data and you kind of invert the model to run it backwards so that then you could test like five different rats and look at the statistics of how they differ five different treatments of of a drug okay so

first just to kind of play with cursor i just said explain this notebook so right now for coding in active inference it's like literally the most exciting it's ever been because of tools like this way way beyond most people's coding potential

in a moment, certainly far beyond mind is the ability to actually use cursor and other tools to have a conversation with the material.

So there's a lot of questions that people might be like kind of having burning inside of them or like wanting to ask another person that are very possible to just ask through language models of the code itself.

Here is

importing the kind of general packages that are needed, and then specifically importing the pieces of PI MDP that are needed.

That's imports.

Um, here's the environment.

The environment is going to be like where the game or the setting is defined.

We're, we're in the discrete time setting.

Um,

interestingly it's it's not 100 like when when the setting is like right arm wins it still is 98 and two so there's a little stochasticity even when the the context is like it you know when when the it's on the left arm of the right arm um maybe that's just to keep keep it kind of a little bit more interesting and noisy

Um, just if you, if you want to highlight the kind of auction of its uncertainty, then, you know, you could just change this to one and zero, but, but, um, keeping it this way highlights the uncertainty part and here they call a teammates environment function.

Searching the code base.

describing what this teammates environment call makes, but it stores what's needed for the teammates and puts it into environment.

That method is in another file.

Okay.

Here's gonna be the hidden state to outcome mapping.

That's the, quote, collection of probabilistic relationships called the A matrix.

This is the mapping between hidden state and observation.

That's a likelihood function.

And here, there's, we can say, output the A

And it will provide us, but, but this is basically showing, um, there's no reward.

Yes.

Reward.

And, uh, uh, there's, there's the, the null state, like with respect to whether you're observing, getting the food or not, let's just call it food.

Um, but let's just call it reward because they call it reward.

Um,

The top row, the columns represent the locations that you could be in.

The top row represents not tasting anything.

The middle row represents tasting the reward.

And then the bottom row represents tasting like the opposite of the reward, like the other arm.

So this is saying like the starting and the queue location, hidden states map on to not tasting anything.

The right maps on to tasting the reward, hidden state.

And then the left arm in this case maps on to tasting the opposite.

The queue mapping.

So we were in...

slice one of the a so the first kind of type of a matrix that comes into play is the one between location and taste there's also a second a which is going to be just a two by two and this represents the mapping between the observed q in the bottom of the teammates

and what context you're in.

So in this setting, it's kind of like an honest Q saying, if the Q is saying that you're in the left better context, it's accurate.

But you could flip that to make like a deceptive Q. So that defines the two components of the A matrix.

Now we're gonna just go through literally A, B, C, D. B is the transition dynamics.

So here they start with kind of the simpler B, which is gonna be the transition dynamics of what context you're in.

So this one corresponds to the smaller two by two A. This is saying when you're in left better context

as a true hidden state that stays that way whereas if it was like a situation where the context was shifting between time steps within a trial you would have an off diagonal now those are uncontrollable Dynamics now they're going to get to controllable transition Dynamics

This is really the key piece in active inference, because when all we have is the downstairs part, this is just a partially observable Markov process.

That's just the A matrix and the B matrix being inferred, but there's no policy selection.

So to get into the policy selection,

that is equivalent to making B not just a singular transition matrix, but B has like multiple files or slices.

And then pi selects, choosing a policy, choosing an affordance is equivalent to selecting which B matrix is gonna be applied to the continuation of the hidden state transition.

So it's called controllable because there's a policy selection possibility

for choosing which slice of B is applied.

Whereas if you were just like listening to a song, then you could infer the B matrix, but you wouldn't be able to choose the B matrix.

It's sometimes unintuitive, the structure of these variables.

But again, through printing them and asking, you can get pretty far.

And they're formulaically laid out.

And also a lot of development effort, like in the open and the closed source spaces, has to do with making the specification of generative models overall, and especially the B matrix, a little bit more intuitive.

So that it can be like, make it so that

this action does that at this point you kind of have to look at the matrix and and encode how that works so here this is like we're looking at the um controllable components of those two modalities so we can't control the context left or right better but we can control location so we're going from hidden state to hidden state at the next time step there's four locations going to mapping to the four locations

In this case, because the center is reachable from all locations, you can choose to move to the center from anywhere.

Similarly, they're just laying out these movement options.

So those are the slices.

These slice one, two, and three on B, those are the affordances.

Okay.

They copy in, they copy in the variables, they kind of defined them just by themselves.

And now they're going to copy them into this underscore GM format.

It's not necessary that the generative models of radical representation of the generative process at this point, we were just defining a and B like the vertical a and B. But we've just copied them in to be the eight part of the agent's generative model, but it doesn't have to be that way.

You could have the generative model of the agents having a different structure than the structure of like the map and the game, but that's just wouldn't take more code and everything.

Um,

Now they're going to continue with the agent class.

PyMDP is like the major method is the agent class.

PyMDP is built to get to being able to build the discrete time agents as fast as possible, essentially, and make easy methods for calling that once it's there.

So we're defining just zero is the controllable index because here B zero, the first B zero indexed is the controllable one, but then the uncontrollable one, it was B one.

So the second type of B tensor.

This is just telling as we work towards building the agent,

that zero is the one that's under control whereas if it believed they could control the context at the at the very best case you'd be wasting computational resources on computing that um here the agent is defined in terms of just the a the b and um the control indices

Now it gets defaults for everything else.

And those are going to be kind of like investigated a little bit.

It starts out with a flat prior for the hidden state.

It starts out with a flat, so it doesn't know where it is in the beginning.

It has an equal belief across the four possibilities of locations.

And that's plotting D0 corresponding to location.

That's the controllable index.

So D0 corresponds to the prior on hidden state.

B0 corresponds to transitions of hidden state.

A0 corresponds to hidden state and observations.

And then the context is that second modality.

And so here it has an even prior on which context it is.

Then they modify it.

so that it has a precise and accurate belief one hot just means a variable with a one in one location and then the rest of them are zeros so they've modified that to now um look like a strong belief that it's in the zeroth position um okay now they get to see so after having done this

they will have defined A, B, C, and D. Then that will have basically constructed the agent.

So they're going to go to that reward modality.

There's some interesting discussion about like, how do you actually connect up like an observation to be incentivizing?

And here's the C preference variables.

Okay, that was it defining the teammates ABCD of the agents here's the active inference loop.

So.

let's do something like.

doesn't always work on the one shot, but a shocking percentage of the time it does fine.

It literally did it.

It literally did it.

So here's three or here's four times steps.

That's funny.

You know, it's the half time steps obviously don't matter.

So here it's, um, these plots represent that active inference simulation.

So it's like, that's always, what's super interesting is defining the agent, like the kind of scaffold or the template of the agent is really just the beginning, because then there's a ton of methods to describe, like to visualize the outputs of the agent and to sweep across different parameter combinations.

Okay.

They're kind of now plotting, um, they're kind of inspecting the beliefs, plotting the updated beliefs.

And then earlier I was just, I didn't really make any, but just started to visualize a few things.

Okay.

Let's copy this again.

So here we'll do the, the chapter nine thing and bring in empirical data.

So it's just some, some it's doing a few, just minor, um, just formatting, but these lines are not being changed, but green means it's adding in line red.

It's leading you.


SPEAKER_03:
yeah uh i want to ask about the gpt4 does it actually read the paper and the documentation why does it understand yeah good good question like in this case um well


SPEAKER_01:
First off, if, if you were just using like the chat interface for GPT or like whatever cloud three, et cetera, um, you could just copy in code and then say like, improve this script.

And then it would, you know, based upon the statistics of all the code it had seen, it would update that script.

Purser takes that a lot further because, um,

it does code base indexing.

So when you type in a prompt to GPT, first, it tokenizes your input, converts the words into tokens.

Then those tokens are calculated in terms of their embeddings in the semantic spaces.

then like that embedding can be used to then generate more things in that semantic neighborhood shortly.

The cheap part of using a transformal model is actually going from the tokens to the embeddings.

Whereas going from the embeddings to generating new synthetic material is costly.

And then obviously fine tuning it and training it is even more costly.

So what cursor does is in the folder that you're in, it, it indexes the code.

So it runs all the code through the first part to embed it.

And then when you do a request, it like, um,

So control enter.

So here it's scanning across, here GPT is going to be tokenizing and then checking the embeddings of this prompt I wrote.

Then it uses basically what's called retrieval augmented generation, RAG.

You might be using that in some other variants to find which sections in the code itself actually have relevant information.

terms of having a similar embedding so like if you had pdfs of a bunch of different disciplines and then you said well like what reacts with methane and then it would look for where methane had been introduced or methane is similar to butane if that if there was a paper that said methane is like butane then it would to a lesser extent draw on papers that talked about butane so this is not co-pilot

No, you can use co-pilot as well in this setting, but this is cursor.sh.

Cursor.sh.

Okay.

Got it.

Thank you.

Yeah.

It's a VS code fork.

And, and, and even if you've been away from it for like a few days, you should download a new version of it because like the changing is very rapid.

Um, so, okay.

Let's, let's see how well this did.

Here's what it wrote for visualizing a teammates.

So it's like, it didn't output anything.

I'm not seeing anything.

So there's the side chat mode

Where you can chat with the code base and then there's kind of this in line editing mode and there's also a kind of a tab auto complete mode that's more like the co pilot.

But this in line version.

Is it like.

There's probably so many in its training data set, so many simple code examples, like just checking if there's a folder like this kind of logic.

Accept the changes.


SPEAKER_00:
Let's see.


SPEAKER_01:
teammates too.

So that's kind of the danger sometimes to an extent is like, it's really easy sometimes to like be spinning your wheels with, with code that can be like kind of overwhelming and look relevant.

And the code might not be like bad by itself, but then like you start stacking all this code and then like the maintenance and interpretability costs can be very high.

Like it's fun also just like, this is where we're at.

I mean, this is the chapter nine, you know, this is kind of where we're at as we continue.

And other people continue to first off ask GPT about active inference.

And it includes more and more recent checkpoints in its training.

And of course, web enabled search like perplexity and all this, like it gets better at doing active inference.

A second huge piece is gonna be, um,

more and more actual examples of active inference code especially for like higher reliability settings it's cool that there are pi mdp demos at the same time like i know that the community has more than just a couple notebooks but they're not in the pi mdp repo so then the cursor only has a couple of examples to go off of

So adding more working examples, updated language models with internet access and better code scoping, fine tuning language models on transcripts from the active inference journal, from like our live streams and model streams and the textbook group, questions that people ask getting folded back in to fine tuning and to RAG and model scope.

If we pulled in the active inference journal

transcripts for all the live streams then we could say something like um make it into continuous time and then maybe in several discussions somebody said like well what's the difference between discrete and continuous time and then that was addressed and then it could go off of those questions to actually inform it

So, especially for a field like active inference, where it's like, this is the domain expertise.

So that being invoked will help a lot.

But just for doing things like improve and generalize and professionalize this code.


SPEAKER_03:
So to pulling data from active journal, does it require fine tuning?


SPEAKER_01:
Like, we're not totally set up to do it today.

But yeah, in principle, you could pull in the GitHub repository for the active inference journal.

And then it would have the transcripts in the plain text, but there might be a bunch of redundant stuff.

Like we might have four different versions of the plain text or different translations or something like that.

But yeah, we could, we would prepare a kind of rendering flag, like output a single version of every transcript with no time steps and have that.

And then, and, and also have papers and more code examples and all of this.

So like even just playing around with where it's at helps calibrate.

Um, we can say generate.

So with these kinds of functions, like here, this is not, it's not outputting the data exactly like we need it to be.

So even just playing with these, like it's, it's really some of the most and fastest fun I've ever had using active inference.


SPEAKER_03:
Because let's say, yeah, go ahead.

Uh, so as long as I don't, uh, exceed the context length, I can just pulling whatever repo I want.


SPEAKER_01:
Actually, you can pull in repos that are way beyond the context length.

So let's just say that the context length was 100.

Just make it simple.

And you pulled in a repository that was 1,000.

So the first thing that would happen is the 1,000 lines of code would be embedded.

That's the syncing of the embeddings.

Then let's just say you did a prompt of length 20.

So you've used up 20 of the hundred of the context window with your prompt.

Then that is going to get embedded in dispatch to cursor.

And then cursor is going to do its best to fill the other 80 of the context window with the most relevant 80 from the code base.

That's this part where it's scanning the code base and then pulling in the context.

So then the final execution from cursor is your 20 prompt plus the 80 most relevant that rag obtains.

So it may pull in like misleading examples, but to the extent that the macros and the patterns do exist in the code base, it's basically effective.

then the less that what you're asking for exists in the code base, the less, of course, it can rely on it.

And so then the more it's just relying on the overall statistics of the language model.

Another thing is that Cursor, you can set... I don't know where it moved the setting to, but you can force it to call...

another you can force it to call a different endpoint for the language model so then you can use like jan.ai or lmstudio.ai or another one to have a local language model so then cursor is dispatching to a local language model and these are also including code enabled and so on so it's like kind of interesting because it's like

It's not the math of active inference, but as that gets brought in, and then for the equations, like we already have every equation in the latex form.

So this is highly readable by the models.

Many can also look at images too, but what it's going to do when it gets an image is basically OCR and try to revert it to LaTeX anyway.

So it's enormously costly.

So there could be some repos, like maybe the textbook group repo, that just have like all the equations in LaTeX or the whole text in plain text stripped of some, you know,

just spaces and kind of cleaned up a little bit.

And then those kinds of plain text files can be brought in with one line in Git.

And then you functionally would have the textbook material because it's not only looking at code when it's doing its scoping.

Like here, it looked into just plain text.

So, you know, long-lived digital stigmergy, contributions and questions that people make really do matter, even if they're a starting place for being improved and corrected.

It, it really, it really does have compounding effects on the total active ecosystem.

Like we could have a function to generate synthetic TMAs data.

So that might be one step would be, okay, we made the TMAs generative model.

Now let's make a generate synthetic data.

And then let's do chapter nine, kind of get this pairing between the generated synthetic data and the generative model.

Then you build another function to go from video data to the same format as the synthetic data.

But you already established that that synthetic data format was able to be parametrically useful for the GM.

And you could have already developed the visualization, sweeping, other methods.

So it can be quite a large code base and you can write like thousands of lines in a day because it just spills out these functions.

So I think a lot of the previous discussions in chapter nine and the textbook, like they're, they're either philosophical or analytical, I mean, or both.

And, um, yet the applying is very much like computer engineering and statistics.

And as the models and the programs get better, like

In six months, I think a lot of these will be even better.


SPEAKER_03:
One more question.

Agent-based modeling, I wonder if that's a field suitable for active inference?


SPEAKER_01:
Yes.

I mean, that's why PyMDP, the central type, is the agent.

Active inference is agent-based modeling.

Agent-based modeling, whether you do it at NetLogo or any other kind, has always had the kind of incoming perceptual and outgoing action selection.

So that kind of cybernetic framing of single and multi-agents ecosystems of shared intelligence is not new to active inference.

Really the essential piece is that that entire generative model of the agent is being understood in a unified way, right?

Memory, attention, et cetera, et cetera, et cetera.

All the diverse cognitive phenomena are being approached in a unified manner and with a unified loss or fitting function, free energy, under the free energy principle.

But you'll find other agent-based models that have a perception and action component.


SPEAKER_03:
If I just look at NetLogo, it's not explicitly done in the language of active inference, right?


SPEAKER_01:
Correct.


SPEAKER_03:
I wonder if there is value to be added if you bring the active inference discipline into that field.


SPEAKER_01:
Yes, certainly.


SPEAKER_03:
Yes.


SPEAKER_01:
Yeah.

Like going to the classic net logo simulations, rewriting them to be more active inference.

And like, it's a two way street people in net logo then can compare active inference.

You can make, um, portfolios or models that have active and non active agents in net logo.

And then it's instead of like, oh, well you need to learn this like other software.

It just brings active inference into whatever software is being used.

And it might be like as simple as just using a different loss function.


SPEAKER_00:
So my, oh, sorry.


SPEAKER_03:
Yeah, sorry.

Okay, I just finished my question.

I wonder if that's a good topic for a master thesis.


SPEAKER_01:
I think it could be.

I mean, like in terms of the implementations we have, I've never seen a net logo.

So it could be interesting.


SPEAKER_00:
You know, something else that my advisor works on is mutant agents.

And I haven't really seen anything in the literature so far on active inference about mutation.

Like between generations?


SPEAKER_01:
Yes.

Yeah, that could be really interesting.

Like just lock in the schema and the understanding for the teammates and then do lifetime where it does a hundred team mazes and that's the fitness function and then have recombination.

I mean, I, I, I don't, I'm not set up to run that net logo exactly right now, but this looks like net logo.

So this just gets super far.

This gets like past 80% in a few minutes in terms of getting somewhere.

So that's mega exciting for, for a lot of reasons, but I mean, sorry, did, did Jeff, what, uh, did Jeff mention mutation agents?

Yeah.

is there a paper somewhere yes i can link it give me a second cool but yeah fun um fun times interesting chapter nine um discussions one interesting meta repo would be if we made a repo that just i mean like literally i may do this tomorrow just brings in all these other repos

But then at that point it might start like pulling context from like across repositories and it's not useful again.

So there's a lot of meta programming work and documentation that will make it more accessible and useful and, and, and vastly more unexplored than explored.


SPEAKER_03:
I see.


SPEAKER_01:
There's the paper.

Cool.


SPEAKER_03:
Yeah, thanks.


SPEAKER_01:
Sometimes I like just clicking through.

Okay, so it's on the screen for two frames for a tenth of a second or half a second or whatever it is.

Future screenshotters will do better.

Cool.

All right.


SPEAKER_02:
that was the first discussion on chapter nine yep susan uh yeah yeah my brain's yeah going 100 miles a minute and so the the existing models that's in there are um

Where would you say the level of sophistication... What would be the next level of sophistication that's not there yet?


SPEAKER_01:
In PyMDP?


SPEAKER_02:
Yeah, in terms of the artifacts that are there now in terms of...

Barbara Kirby, Go you get going up into levels of abstraction, for example.

Barbara Kirby, modeling.

Barbara Kirby, agents negotiating.

Barbara Kirby, You know which i'm assuming you know we're not even close to there yet but.

Barbara Kirby, But.

Barbara Kirby, So beyond the the rat in the maze, what do you, what do you see will be the next step in evolution of the models.


SPEAKER_01:
Yeah, like, currently the main pyMdp package only has these several documentations and simple examples.

Like, I know there's a thousand x more work not in the repo.

So I would like to see the next consolidating step to be many, many diverse, successful, simple examples.

And then the introduction of motifs like metacognition and other things like that.

And then that provides like the palettes.

to be recomposed into these more composite simulations.

So we're in the game.

It's all happening.

And saying and asking and writing is more than enough.

So thank you all for this fun time.

See you next time.


SPEAKER_03:
Thank you.

Bye.