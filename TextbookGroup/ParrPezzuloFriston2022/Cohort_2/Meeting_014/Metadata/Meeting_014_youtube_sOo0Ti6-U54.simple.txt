SPEAKER_00:
hello welcome thanks everyone it's february 1st 2023 we're in meeting 14 cohort 2 of the par at all textbook we're on chapter 6. so today we can look over

any and all of the questions on chapter six that have been raised we can also go to the text but just to begin does anyone want to bring up any quote or topic or or anything about chapter six or any section from the text or question that someone wants to go to first or a general point about chapter six

from Ali and then anyone else.


SPEAKER_03:
Well, I think now that the white paper from Versus Lab is published, it might be a good idea to read Designing Ecosystems white paper along with chapter six, because it can provide a much wider perspective and see how

how the research in developing these kinds of active inference-based AI is currently developing and to see how the plan for the future developments have already been discussed, especially in the case for sympathetic and shared intelligence, which is kind of

long-term plan to develop those kinds of intelligence systems.

So yeah, I think this paper can immensely help to see the big picture related for designing these kinds of active-imprint space models.


SPEAKER_00:
Awesome.

thanks yeah the the first 20 pages of the paper have great points but just to jump to the the timeline part it's 2023 this was released at the end of 22 and in the coming years here are some doubling timelines that we might expect or prefer

So that does help set the stage for chapter six.

Anyone else, just unmute or just raise your hand.

chapter six is a recipe for building active inference models so it's not the uh fast food restaurant yet but it's a recipe for the home and potentially industrial chef it covers the essential steps to design an effective model

And that is going to be taken in like a staged way.

And starts on page 105 in the textbook.

So shall we look at the questions?

Does anyone have a specific question they would like to jump to or any general points?

Otherwise, let's look at the recipe and then see if there's things that we can add.

And then in this active inference model recipe, let's see if we can flesh it out with what we're seeing and learning from doing modeling.

And also how it's similar and different.

from other modeling recipes.

How different is this than doing a linear regression model?

How different is it than doing some other type of modeling or analysis?

Give me six chapters to model active inference and I'll spend the first four on the generative model.

Carl Lincoln.

Which system are we modeling?

What is the appropriate form for the generative model?

How to set up the generative model?

How to set up the generative process?

So those have been copied out here.

Does anyone just want to give some

comments on these stages or how would one just briefly summarize what each of these four stages are and what they do or just any feature about these four steps


SPEAKER_04:
I guess one thing is they need to be discrete, these steps.

And that's already a decision that needs to be made.


SPEAKER_00:
Do you mean the steps are separate from each other?


SPEAKER_04:
Yeah.

And we need to have categories that's

If we have these hidden states in the Markov model, these are separate states.

And I guess that's kind of a problem and a restriction also.


SPEAKER_00:
Are there other modeling approaches that you think don't have such restriction?


SPEAKER_04:
Yeah, for instance, neural networks.

We use transformer models where you can type in a whole picture, for instance, or something like this.


SPEAKER_05:
I may be wrong, so maybe there's categories too.


SPEAKER_00:
Yes, well, maybe a related question is when we specify what is a hidden state and what is an observation in our generative model, are we kind of locked into that?

Or is it possible for

something like a pre-POMDP that describes structure potentially this is between steps two and three like the hidden state is going to be an image and then it gets set up with a certain dimensionality

Anyone can raise their hand.

Let's just look through the questions, see what we can bring into the modeling page and which ones are remaining to be needed.

Why is modeling of the generative process a necessary step for building an active inference model?

Okay.

We have a lot of notes on here.

What would somebody just give on a first pass?

Why is the generative process a necessary step for building active inference model?


SPEAKER_01:
I guess on a very high level, because the generative model is ultimately creating a representation of the generative process, if we want to create that model, we have to allow for the generative model to be able to model the generative process.

So we also need to model the generative process.


SPEAKER_00:
Yeah.

one aspect there is the generative model is or the generative process is providing the observations and then the sort of the second layer on that is the generative model

is working with or is building representations or is a good regulator of or is needing to maintain the requisite diversity to deal with the generative process so it would be like asking why is modeling of the grid important in a netlogo agent-based simulation it's like well you got two kinds of things the agents moving around the grid and you have the grid

so in this active inference particular partition we have the generative model that's the active entity and then we have the generative process which could be another active entity or it can have any structure so like in model stream 7.2 the generative model was an active agent the generative process was just an if then logic


SPEAKER_02:
Ali?


SPEAKER_03:
I also think that these distinctive steps that have been outlined here in this chapter as a recipe to designing any active inference model are not specifically distinct or even sequential steps because

For example, in the first step, it says, which system are we modeling?

But on the other hand, the choice of the system that we are modeling would inevitably have an effect on the type of the generative model or the type of the generative process we're dealing with.

So in a sense, all of these steps are kind of

intertwined into each other and they're not necessarily have to be seen as a kind of in a sequential order but rather in a kind of from a hierarchical point of view we just need to have which component of the modeling process are we dealing with so

For example, we can possibly begin by identifying the generative process and then look at how we can optimally represent the generative process by a suitable generative model.

so what i'm saying is these four steps are not necessarily something uh that uh to be taken on the face level they are just uh laying out the the territorial map of modeling those systems and we might begin from uh each one and each one of them and then proceed to any other depending on

the situation we're involved in.


SPEAKER_00:
Yeah, thank you.

It may be seen as an atemporal partition, not necessarily the order that a traditional recipe would have.

let's let's continue on and so we can just touch on on each of the questions okay what are the four steps some of this material we moved over to this distinct model recipe page just so that we can develop that um in its own section um okay what are the four steps that are being addressed on that page in figure 6.1 what do the uni-directional and bi-directional arrows mean

What's the thought anyone has on this?

So

In a Bayesian graph, the nodes represent random variables and the edges represent statistical influences.

Those can be represented in an undirected fashion if there's no arrowheads.

And that's a lot like a structural equation model.

Like if we were dealing with linear notions of correlation, Pearson correlation, we could make a structural equation model.

And then the edges would be like correlations between two variables, which are undirected, of course.

In a Bayesian causality framework, like Judea Pearl et al., it is possible to have a bidirectional arrow, which is a lot like an undirected arrow.

but also you can have a unidirectional arrow such that changes in one variable cause changes in another, but not asymmetrically, especially if you consider time series information.

In the work of Aguilera et al., How Particular Work, I think there are several papers and a stream on it, they analyze which topologies of the action-perception loop have which properties, right?

so one can imagine like a simple cybernetic action perception loop like which we could just call like around the clock so no line in the middle just internal states only influence action no no backwards zero action only influences internal internal on sense sense on internal and all the self loops

um that's like a simple around the clock topology of the action perception Loop so then we can ask all right so from that around the clock uh causal framing what extra edges and arrowheads exist in the way that it's shown in figure 6.1

there are three there's the connection between active and sensory states so the blanket states have an additional relationship and there's this somewhat interesting symmetry where active states have an arrow back to internal states and sensory states have an arrow back to external states

frankly I am not sure to what extent people are just showing representations of the way that previous models have shown it which could be in a graphical representation like this or you could think of this as the adjacency Matrix of the causal influence of the four states on each other

Like that could be a fully connected matrix with a value in every cell, or it could be like just the identity matrix would be like four states that are independently evolving and not influencing each other.

Different topologies of this particular partition are going to have different properties.

And I think the most general approach would be to do structure learning and Bayesian model selection on different topologies for the action perception loop.

So what do they mean?

Well, they mean that you are comparing models

with the constraint or the availability for that parameter value to be non-zero if you delete the arrowhead of a certain kind then you're basically testing models within a restricted class where that parameter has been fixed at zero so if you want to fix the effect of sensory states on external states to zero maybe you think that's quote unrealistic so you want to fix that to zero

so that you have increased statistical power to resolve other parameters that's valid although one of the most intuitive um reasons to do so which is like but sensory states don't influence external states in the real world it's like yes but that's the map territory fallacy this isn't the causal structure of reality Ali or anyone else


SPEAKER_03:
Actually, it might be helpful to look at figure two from the paper Path Integrals, Particular Kinds and Strange Things, and especially the different typologies of the particular kinds provided there, being inert particles, active particles, conservative and strange particles.

So briefly, they define inert particles as the kind of particles or systems with no active states.

And in the order of increasing complexity, one step further or one level up would be the active particles.

which is a particle with a non-empty set of active states.

But then, ultimately, and also the conservative particle is an active particle whose particular states follow paths of least action.

But ultimately, we reach a kind of

definition, I believe for the first time, for strange particles which are defined as conservative particles whose active states do not directly influence internal states.

So this paper claims that only this fourth type of particles, namely the strange particles, have the capacity to

be a kind of sentient agent or any kind of intelligent agent, depending on how we define intelligence or sentience.

But in any case, all of these kind of, this strange particle somehow subsumes all the other kinds of particles, but with varying levels of complexity assigned to each of them.


SPEAKER_00:
thank you yes good connection here we see um so interestingly we don't see the backwards arrow here we see the around the clock and the intra blanket connections but we're we don't have the backwards edge


SPEAKER_03:
Yeah, that's because these kinds of strange particles have not been

developed into fully sentient agents yet.

So to be fully sentient is to be able to actively influence all the active and sensory states.

So I believe that's why we don't have those bidirectionality in this picture for strange particles yet.


SPEAKER_00:
Thank you.

yes it's almost like this is one circuit diagram it's like we have four cpus on our circuit board that's the particular partition and then how we wire up the topology of the particular partition is like the hardware of our circuit board and then what the dynamics are is like the software of our circuit board

Once we start mixing in these taxonomies of particles of increasing sentience and cognitive complexity, and then we start mixing in the blanket index, it's a big space, but also it's a very semantic space.

And one advantage of FEP and active modeling is we can develop special or reduced cases of particular things that are sub-cognitive, but they're still broadly considered within a cognitivist framework.

Whereas something like thousand brains, it may be a super effective architecture for inference or generalization or any other number of advanced cognitive tasks.

However, it cannot be constrained or projected down to the case of like a ball rolling down a slope.

Whereas Bayesian mechanics, Bayesian physics, and this taxonomy of particles helps us bridge the continuum with expressive modeling framework that spans the simplest, least active particles to open-ended complexity and intelligence.

Michael?


SPEAKER_04:
Yeah, I also had a little bit of problems with understanding this Markov blanket loop and what that could mean.

So there's somehow unmediated

action that does not have an impact on the environment and the sensation action loop, I have problems really to understand what that is, what that could be.

I mean, I can see that one can have a system that produces something like this, but I have problems to understand.

So I was thinking whether this was meant to be, for instance, a reflex.

You hit on the knee, and then the leg does some kind of movement, but without going to the brain.

the nerve ends in the spine somewhere, and then this action is produced by a place in the spine, and then it doesn't go to.

But I mean, it depends on what you call an internal state, right?

So if the spine.

that triggers this reaction not part of an internal state?

Well, I'm a little bit lost in understanding how we can understand that.


SPEAKER_00:
Yeah, thank you for the comment.

So super important point, like it depends what is internal states.

It's not like states even within a fixed, like these are the only variables on the table.

Whether one is internal or external is, of course, whether we're choosing to model it as the generative model or generative process, like which side of the blanket, and there's a symmetry there.

And then it's not just like this variable is an internal state.

It's always like the fourfold particular partition comes into being internally.

in the same time like the blanket states are those that make internal and external states conditionally independent so but that blanket state with respect to x and mu it might be an internal state with respect to something else so it does definitely depend on it and i think now to the question of the connection here's from emperor's new markov blankets by bernberg um

I think the edge may have to do with just the... The fact that there is an arrowhead doesn't mean that the parameter value is non-zero.

It just means that we're describing families of models where there can be a non-zero influence.

not a priori fixing it to zero but you could conceivably remove this edge and just fit the simple around the clock or around the clock with the two backwards edges so because we're making models not um of maps not territories we um don't need to be constrained to a physical

anatomical realism with respect to what these edges are.

And so it's easy to sort of contrast the plausibility of these edges with anatomical realism, but these are not anatomical edges.

So it's just opening up the family of models under consideration to a non-zero statistical influence between these states.

And it also may inherit from the question of co-parents and also the developments of what people call a frist and blanket.

Whereas the Markov blanket formalism by Pearl was initially characterized on an undirected graph and there was only one kind of blanket state.

It was just the set of nodes that make internal and external states conditionally independent.

And you could imagine a sort of clean frist and blanket with like a clean division of labor where there's some of the nodes of that blanket set are strictly outgoing and some of the nodes are strictly incoming.

so that could happen you could buy dictate design systems that have that characteristic and that may map onto a anatomical realism but also you might want to consider parameterizations of models that don't have such a clean partitioning like there's a dual functional node

that has an incoming and an outgoing statistical dependency.

And that doesn't have to map on to any actual sensor or actuator in the world.

It's just a statistical note.


SPEAKER_04:
Hmm.

But isn't, okay, I can see that one can design such a system, but does it make sense?

I mean, if there's an infinite loop between active states and sensory states that mutually manipulate themselves, but they have neither an impact on an external world, not on an internal world,

Of course, we can assume this, but what is the reasoning there?

I mean, does it make sense?

If something happens and we cannot see it, not outside, not inside, what is the point?

It's just like a full Turing machine that generates a derivation tree with huge number of internal nodes that just disappear, and one has not a track of what happens there.


SPEAKER_00:
Yes.

Thank you for the comment.

So I think one way to think about this

topology this wiring of the particular partition here's from that um uh path integrals particular kind strange things paper this is how we're modeling flows over states in the fep

we have the flow over the total particular partition X is like a tuple.

It's a four unit, four length vector over internal, external sense and action states.

And the flows of each of these nodes are a function of if it were all by all connected.

So if there was like an edge here,

then you could just like the fully connected model would be each of the flows would be a function of all four other variables and and you can you could write that out if you wanted but importantly in these bottom two the action and the internal or the autonomous states

don't have a direct reliance on external states.

Eta is not in the bottom two.

And then importantly, the external and the sense states don't have a direct, they're not taking as an argument internal states directly.

That is like the minimal cybernetic constraint.

we might be then interested in constraining further but um and it FEP may be general it may apply to the to the um all by all case as well but this is the minimal constraint that allows autonomous states active and internal

to be under um perceptual and action selection imperatives we don't want to have our finger on the scale on external states or sensory states directly except through action so in any given case the topology

itself could be a structure learning question or given a fixed topology parameterizing it is is going to be the question but does it make sense it's like saying does a given structural equation model make sense it just is a function of what data you have

Let's see if we can just touch upon subsequent questions.

Is there a common good representation or rubric for evaluating GMGP?

Does anyone have any thoughts?

Well, one approach that's not even ACT-INF specific is using the Bayesian Information Criterion or its cousin, the AIC, the Aikiki Information Criterion.

And the BIC and basically the AIC reward good fit and they penalize models with more parameters.

So the BIC is widely used to establish

the Pareto optimal trade-off of model complexity and model accuracy.

So if one is interested in like what is a good generative model, generative process fit, if you just want the sheer fitness, you're going to end up on the slippery slope towards high dimensional generative models, because adding new parameters

appropriately, strictly increases model likelihood because new parameters are always sucking up variance that was left unexplained in the noise term by whatever you had previously.

So we don't just want to simply increase the likelihood blind to all other factors.

We want some sort of balanced measure that penalizes adding more parameters.

So that's one approach for model evaluation in the Bayesian space.

And another that is commonly used is a Bayes factor, which is a relative measure of bit amongst multiple Bayesian models.

so the Bayes factor is a ratio between two Bayesian models and so it can be used people have kind of heuristics just like there are heuristics for p-values not even going into the whole question about p-values here but there are also heuristics for Bayes factors

whether the evidence of one model over another is like substantial strong decisive etc and Bayes factor allow any models to be compared with each other whereas if we were in the parametric modeling space we would only be able to test using the hierarchical ratio likelihood ratio test the HLRT for parametric models

So for parametric models, you can only test nested models.

Like if you're doing an ANOVA, you can test an effective A, an effective B, and then you can compare that with whether there's an interaction between A and B. But you would have a hard time testing a model with A and B versus a model with B and C, unless you put that into a nested parametric framework.

Bayesian statistics gives us a lot more flexibility to compare models.

so model selection evaluation comparison those are big areas short answer we're using Bayesian statistics so we have the most modern tools for evaluating that in the specifics it's always going to be the specifics but in terms of the tools for model selection Bayesian statistics has the best tools

All right, how does the particular partition, so 6.1, which we were looking at earlier, or the sort of proto-particular partition, the dyadic partition here, informal, relate to the POMDP in figure 4.3?

What would anyone say?

These are two common figures that we see, but I don't see x, mu, u, and y here.

Though interestingly, the x and the y in the continuous time representation, they actually do map on

to the particular partition and um kind of with a v whereas the discrete time pomdp does not use this exact notation what would anyone say why do we have this closed

cybernetic partition but then it looks like we're moving into a pomdp model with a different topology


SPEAKER_04:
I guess in the POMDP model, there should be also an arrow going backwards to the beginning of the.

So if we are in a state on the right side, there should be somehow a loop back to the beginning, which is here implicit somehow.


SPEAKER_00:
That?

is called sophisticated active inference, where in the past, present, and future, there can be an inference over the past, present, and future.


SPEAKER_05:
Okay, yeah.


SPEAKER_00:
So it is possible, but it's not the base case.


SPEAKER_04:
Yeah, no, yes.

So this is unrolled in time, no?


SPEAKER_00:
Exactly, exactly.

This has no time.

the particular partitions are not defined in time they're defined as functions of other states in the partition because what a Bayes causal graph represents is not as a function of time so it has to be put into

a form that allows us to explicitly enumerate time and then in chapter four and then again we'll see in chapter seven and eight we have two ways to deal with time broadly discrete time continuous time discrete time actually models discrete slices of time sequentially

and generates parameterizations for like hidden states and observations at different explicit time points in contrast the continuous time generative model which is being shown like with these one twos and threes instead of the d b and a they're being shown juxtaposed in figure four three to emphasize their structural similarities however

Whereas the discrete time model is explicitly predicting states and observations at different time points, the continuous time model, its B matrix equivalent, is not the next state but rather the derivative of the state.

And so the continuous time model has more in common with a Taylor expansion or a Volterra expansion or generalized coordinates of motion.

So in either case, POMDPs help us focus our statistical and informational power on constrained sets of models

that are uh not too restrictive if we're willing to abide by certain uh standard modeling practices like that the past can't influence the future except through the present or that like a derivative can't have an influence on its second derivative without influencing the first derivative first

so under those standard modeling assumptions that uh reduce the state space vastly like one can imagine if there was 10 time points or 10 derivatives and you did all by all you'd end up with a lot of edges but if you constrain it to time points can only influence next time points and derivatives can only influence the next derivatives then

your model scales linearly with time points or derivatives rather than supra linearly so POMTP is one implementation architecture that generates generative models which are compatible with the continuous flow Bayesian physics underlying

like you might have some flow or field equations for electromagnetics and then you have some discrete time realization in your simulation that is the relationship i i have a question huh


SPEAKER_04:
So if you say it's like a Taylor series, then this is somehow deterministic, isn't it?

I mean, in the beginning, in the Taylor series, you say what functions you want to decompose, and then all the parts are a little bit deterministic.

But is it what we are trying to model here?

Or am I completely wrong?

I mean, a series you already, I mean, it's maybe infinite, but you know from the beginning what the individual components are.


SPEAKER_00:
Anyone else want to give a thought on that, or I can add something?

Well, it can be deterministic.

So you could have a model where, for example, there's an identity matrix for A, so hidden states are fully observable.

Or you could have one where the state transitions are fully deterministic as well in the discrete time case.

Okay, now in the continuous case.

um is it deterministic well from a given hidden state you could have a deterministic or non-deterministic emission of observations you can have probabilistic action selection that influences how states change through time

And the way that they change through time could be sampled, hence also not deterministic.

And I think the Taylor series and variational inference have a lot in common in that you do have to commit to like a given family of distributions that you're wanting to fit.

but then within a given variational family, so you have some data set and you say, and now I'm going to fit this type of distribution to it, you might fit that with the stochastic gradient descent, or there might be a deterministic algorithm to fit it, but it's a little bit too broad of a brush

to think about the bigger picture of using these models and simply say that they're deterministic or non-deterministic.

I hope that makes sense, because it is a very subtle question.


SPEAKER_04:
Yeah, okay.

Yeah, thanks.


SPEAKER_00:
Like, I'm wondering if you could have a non-deterministic... Can a function have a stochastic derivative?


SPEAKER_04:
Well, I don't know, but I mean, somehow if you think of the environment that produces new input and we don't know that environment, then somehow an undeterministic factor is there, right?


SPEAKER_00:
Yes, the generative process is not shown here.

The generative process, external states, is handing observations in.

So the GM, to kind of bring you back to the question, it unrolls and it shows the agent's perspective.

This is necessary and sufficient to define the agent.

But here's the great unknown that's handing the observations to the agent.

so the GM can be seen as like the cognitive architecture of the agent it is not describing the total scenario that the particular partition is showing so that's one other difference this S is not the actual external states

This is the agent's variational estimate of external states.

Ali?


SPEAKER_03:
I think the remark on page 24 of Pat Integral's paper might help to understand this.

issue a little bit better, especially the second paragraph, which says that from the perspective of an observer, behavior will appear to be fulfilling the epistemic and pragmatic imperatives afforded by expected free energy.

So it's basically the control versus planning or homeostasis versus allostasis when we look at the inference from the point of view of the internal states of the agent.

and because only the from that perspective can we talk about reducing the generalized free energy right so there's a fundamental difference between looking at this agent from its internal states point of view and looking at it from the external from the point of view of an external observer i don't know if it makes sense but

although they're complementary to each other, but in a sense, they're fundamentally different.


SPEAKER_00:
Thank you.

And just to look ahead to 9, though I wonder if this might be useful to see in 6, and it relates to the map territory.

question so here's figure 4.3 is in the middle we're parameterizing a pomdp with real computers about a rat in a tea maze or an ant in a colony or a cyber physical entity so we're parameterizing this pomdp but that pomdp is in a parameterized environment as well

and six kind of brings us to that but it would be awesome to see more connective tissue between the particular partition which is where the physics is inheriting from flows on the particular partition

and how that relates to this view from the inside of a cognitive agent okay in the final minutes of this chapter six

Okay, last week, I think we explored a little bit about how B and A are two different variables.

They're not directly connected to each other, but they kind of work as a team.

Like B increments the hidden state along, and then the hidden state emits an observation.

Good regulator.

We talked a little bit with Bronwyn at office hours.

We explored good regulator theorem and cybernetics and requisite diversity.

We talked about what happens to bad regulators.

Um, we explored also in the office hours last week, a little bit of the discussion around the blanket trick and about how affordance is handled in ACT-INF and some similarities and contrasts with how it is handled in, um, other areas of like other threads of thinking in ecological psychology.

Um,

in the coming second discussion on chapter six we can return to these bottom three questions temporal depth cognitive systems outside the brain and similarities and differences with active inference and other modeling any final remarks on this

All right, awesome.

I will stop recording.

Let us take a two minute break and then we will begin for cohort three.

Thank you all.