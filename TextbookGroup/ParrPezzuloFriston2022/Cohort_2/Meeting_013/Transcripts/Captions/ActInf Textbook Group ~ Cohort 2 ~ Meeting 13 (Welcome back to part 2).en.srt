1
00:00:00,840 --> 00:00:05,520
hello it is January 25th 2023

2
00:00:05,520 --> 00:00:10,940
and we are in covert 2 of the par at all

3
00:00:10,940 --> 00:00:15,000
textbook Rune meeting 13.

4
00:00:15,000 --> 00:00:18,119
today we are going to

5
00:00:18,119 --> 00:00:21,359
jump back in start our seconds interval

6
00:00:21,359 --> 00:00:24,020
of activities

7
00:00:24,240 --> 00:00:26,400
there are a few ways we can go we can

8
00:00:26,400 --> 00:00:29,599
just review structural aspects of Dakota

9
00:00:29,599 --> 00:00:32,040
and accommodate anyone's like

10
00:00:32,040 --> 00:00:33,960
suggestions or notes on some things that

11
00:00:33,960 --> 00:00:36,180
could be interesting to develop with in

12
00:00:36,180 --> 00:00:39,840
this one or an aside little sandbox

13
00:00:39,840 --> 00:00:45,239
then we will look to the textbook itself

14
00:00:45,239 --> 00:00:48,600
and we will look at

15
00:00:48,600 --> 00:00:51,480
where the first five chapters

16
00:00:51,480 --> 00:00:53,280
got us

17
00:00:53,280 --> 00:00:56,100
and where we're going with the second

18
00:00:56,100 --> 00:00:59,820
half of the book which has a different

19
00:00:59,820 --> 00:01:02,579
Form and Function then the first half of

20
00:01:02,579 --> 00:01:03,359
the book

21
00:01:03,359 --> 00:01:08,420
so first off anyone want to just

22
00:01:08,640 --> 00:01:10,260
adony

23
00:01:10,260 --> 00:01:15,439
General comment how now that it's 2023

24
00:01:15,780 --> 00:01:19,200
where are they in their Active Learning

25
00:01:19,200 --> 00:01:21,180
and application Journey

26
00:01:21,180 --> 00:01:23,939
how is our Niche similar or different

27
00:01:23,939 --> 00:01:26,340
than it was

28
00:01:26,340 --> 00:01:28,920
in September

29
00:01:28,920 --> 00:01:31,740
through November when we worked through

30
00:01:31,740 --> 00:01:34,880
the first five chapters

31
00:01:49,799 --> 00:01:51,720
any thoughts or or we can continue on

32
00:01:51,720 --> 00:01:53,640
just want to

33
00:01:53,640 --> 00:01:56,600
leave that space

34
00:02:00,720 --> 00:02:02,040
okay

35
00:02:02,040 --> 00:02:03,600
feel free to raise your hand or just

36
00:02:03,600 --> 00:02:05,159
unmute or put in the chat or anything

37
00:02:05,159 --> 00:02:06,840
like that

38
00:02:06,840 --> 00:02:07,380
um

39
00:02:07,380 --> 00:02:08,699
broadly

40
00:02:08,699 --> 00:02:10,560
the layout

41
00:02:10,560 --> 00:02:14,400
is the similar

42
00:02:14,400 --> 00:02:16,680
textbook group overview has information

43
00:02:16,680 --> 00:02:19,680
on our live meetings

44
00:02:19,680 --> 00:02:21,060
and

45
00:02:21,060 --> 00:02:22,260
um

46
00:02:22,260 --> 00:02:23,580
that's where you can download the

47
00:02:23,580 --> 00:02:25,739
textbook

48
00:02:25,739 --> 00:02:29,420
the textbook section itself

49
00:02:29,420 --> 00:02:32,760
contains different types of things that

50
00:02:32,760 --> 00:02:35,640
are in the textbook such as the

51
00:02:35,640 --> 00:02:37,920
equations

52
00:02:37,920 --> 00:02:39,660
which have all been brought out with

53
00:02:39,660 --> 00:02:42,060
images and page at least

54
00:02:42,060 --> 00:02:44,099
but there's a lot of improvements that

55
00:02:44,099 --> 00:02:47,220
we could make to the descriptions and

56
00:02:47,220 --> 00:02:48,840
the tagging

57
00:02:48,840 --> 00:02:51,180
similarly with figures we have all

58
00:02:51,180 --> 00:02:53,580
figures brought out

59
00:02:53,580 --> 00:02:56,099
but there's a lot of contributions that

60
00:02:56,099 --> 00:02:57,120
can be made

61
00:02:57,120 --> 00:03:00,239
to um descriptions and tagging

62
00:03:00,239 --> 00:03:03,239
boxes and tables

63
00:03:03,239 --> 00:03:04,980
similar

64
00:03:04,980 --> 00:03:08,180
code implementations

65
00:03:08,180 --> 00:03:09,840
we

66
00:03:09,840 --> 00:03:12,420
um I'll add a link to block prints so if

67
00:03:12,420 --> 00:03:13,800
anybody

68
00:03:13,800 --> 00:03:15,000
um

69
00:03:15,000 --> 00:03:18,000
which is what we've one thing that we've

70
00:03:18,000 --> 00:03:19,860
worked on last few months we have about

71
00:03:19,860 --> 00:03:23,879
uh 40 or 50 implementations of active

72
00:03:23,879 --> 00:03:28,500
in Python C plus plus Julia Matlab

73
00:03:28,500 --> 00:03:30,000
so

74
00:03:30,000 --> 00:03:33,060
um accessible from here

75
00:03:33,060 --> 00:03:35,280
um and we can for those who want to

76
00:03:35,280 --> 00:03:37,019
start

77
00:03:37,019 --> 00:03:39,480
um getting more into the code

78
00:03:39,480 --> 00:03:42,420
and I'll just show one more piece that

79
00:03:42,420 --> 00:03:44,879
we worked on earlier today in the block

80
00:03:44,879 --> 00:03:46,980
fronts meeting

81
00:03:46,980 --> 00:03:50,459
in model stream 7.2

82
00:03:50,459 --> 00:03:51,239
um

83
00:03:51,239 --> 00:03:53,700
a notebook was used

84
00:03:53,700 --> 00:03:56,640
in epistemic contextual multi-armed

85
00:03:56,640 --> 00:03:59,819
Bandit simulation was provided by Connor

86
00:03:59,819 --> 00:04:01,920
Heights

87
00:04:01,920 --> 00:04:04,200
um just works perfectly no no tweaking

88
00:04:04,200 --> 00:04:05,459
is needed

89
00:04:05,459 --> 00:04:08,580
uses octave Loop defines Etc

90
00:04:08,580 --> 00:04:11,099
and what we did today was we took the

91
00:04:11,099 --> 00:04:13,560
active ontology

92
00:04:13,560 --> 00:04:16,858
and we then said how is this set up in

93
00:04:16,858 --> 00:04:19,199
the contextual Bandit how do they set up

94
00:04:19,199 --> 00:04:24,240
B okay here are here's how B is set up

95
00:04:24,240 --> 00:04:27,560
one can click this

96
00:04:28,740 --> 00:04:32,280
and then in a plain text

97
00:04:32,280 --> 00:04:35,599
paste in the whole script

98
00:04:38,280 --> 00:04:40,080
so

99
00:04:40,080 --> 00:04:41,880
this is not the only way that we're

100
00:04:41,880 --> 00:04:42,840
going to be

101
00:04:42,840 --> 00:04:44,820
working towards modeling but as the

102
00:04:44,820 --> 00:04:46,860
second half of the textbook is about

103
00:04:46,860 --> 00:04:48,780
building a generative model in the

104
00:04:48,780 --> 00:04:51,479
process the recipe

105
00:04:51,479 --> 00:04:53,280
we have like

106
00:04:53,280 --> 00:04:56,880
multiple functions in this cohort too as

107
00:04:56,880 --> 00:04:58,259
we go through

108
00:04:58,259 --> 00:05:00,120
chapter six or ten

109
00:05:00,120 --> 00:05:01,320
one

110
00:05:01,320 --> 00:05:04,320
function will be to

111
00:05:04,320 --> 00:05:06,900
to the extent that we want to develop

112
00:05:06,900 --> 00:05:08,100
our own

113
00:05:08,100 --> 00:05:11,280
generative model and simulation

114
00:05:11,280 --> 00:05:13,560
just didactically just to have something

115
00:05:13,560 --> 00:05:15,780
that we increment along to help us

116
00:05:15,780 --> 00:05:16,979
understand

117
00:05:16,979 --> 00:05:20,100
or if there's some outcome that people

118
00:05:20,100 --> 00:05:21,960
want to pursue

119
00:05:21,960 --> 00:05:24,720
research or application oriented like

120
00:05:24,720 --> 00:05:28,139
second half of the textbook is

121
00:05:28,139 --> 00:05:31,800
um the time to do it and

122
00:05:31,800 --> 00:05:35,639
even relative to last September we have

123
00:05:35,639 --> 00:05:39,180
significantly better tools

124
00:05:39,180 --> 00:05:41,580
so there's totally an approach to go

125
00:05:41,580 --> 00:05:44,940
from a natural language understanding

126
00:05:44,940 --> 00:05:48,600
of these ontology terms

127
00:05:48,600 --> 00:05:49,740
two

128
00:05:49,740 --> 00:05:53,100
how to do it in pi mdp

129
00:05:53,100 --> 00:05:55,440
and it's pretty reasonable that somebody

130
00:05:55,440 --> 00:05:57,780
who wants to pursue this direction we

131
00:05:57,780 --> 00:06:00,000
could just add another column copy it

132
00:06:00,000 --> 00:06:01,800
over make the tweak and there's a few

133
00:06:01,800 --> 00:06:02,539
other

134
00:06:02,539 --> 00:06:04,800
pieces but a lot of that is going to

135
00:06:04,800 --> 00:06:08,400
come up in chapter six

136
00:06:08,520 --> 00:06:11,639
um in chapter notes and questions we

137
00:06:11,639 --> 00:06:13,380
have the chapters themselves

138
00:06:13,380 --> 00:06:17,039
and a detailed table of contents

139
00:06:17,039 --> 00:06:20,639
and then each chapter has subset view of

140
00:06:20,639 --> 00:06:21,900
the questions so if you have a question

141
00:06:21,900 --> 00:06:24,240
within a given chapter

142
00:06:24,240 --> 00:06:27,360
or you want to help improve and curate

143
00:06:27,360 --> 00:06:29,100
the discourse

144
00:06:29,100 --> 00:06:31,380
please just like add a row

145
00:06:31,380 --> 00:06:34,919
in the questions section or just make

146
00:06:34,919 --> 00:06:36,539
improvements to the answers and

147
00:06:36,539 --> 00:06:39,120
discourse

148
00:06:39,120 --> 00:06:40,620
um

149
00:06:40,620 --> 00:06:43,620
so we'll um

150
00:06:43,620 --> 00:06:46,139
continue to work with questions as well

151
00:06:46,139 --> 00:06:51,360
as whatever notes people add uh

152
00:06:51,360 --> 00:06:53,520
to just whatever anything else they want

153
00:06:53,520 --> 00:06:55,800
to highlight

154
00:06:55,800 --> 00:06:58,020
um into the more discourse sections

155
00:06:58,020 --> 00:06:59,580
here's the home of the questions table

156
00:06:59,580 --> 00:07:03,240
but it's shown in the chapters as well

157
00:07:03,240 --> 00:07:05,880
um ideas and insights people are always

158
00:07:05,880 --> 00:07:08,660
welcome to add just sort of

159
00:07:08,660 --> 00:07:11,160
nuggets or summaries

160
00:07:11,160 --> 00:07:13,440
for what

161
00:07:13,440 --> 00:07:15,840
they're updating their models with what

162
00:07:15,840 --> 00:07:17,699
they're coming away from from these

163
00:07:17,699 --> 00:07:19,380
sections

164
00:07:19,380 --> 00:07:22,080
math learning group has no

165
00:07:22,080 --> 00:07:23,280
current

166
00:07:23,280 --> 00:07:26,220
um live activities but there's a huge

167
00:07:26,220 --> 00:07:27,660
amount of

168
00:07:27,660 --> 00:07:30,900
uh resources and and some summaries that

169
00:07:30,900 --> 00:07:32,520
are written

170
00:07:32,520 --> 00:07:34,620
but there's always

171
00:07:34,620 --> 00:07:36,419
many things for people to do with

172
00:07:36,419 --> 00:07:40,740
testing out math learning

173
00:07:40,740 --> 00:07:41,520
um

174
00:07:41,520 --> 00:07:43,440
project ideas

175
00:07:43,440 --> 00:07:45,720
we can return to but that's kind of

176
00:07:45,720 --> 00:07:47,400
where we left off with in the last

177
00:07:47,400 --> 00:07:48,360
meeting

178
00:07:48,360 --> 00:07:50,819
of the first half

179
00:07:50,819 --> 00:07:53,400
um future textbook groups we organized

180
00:07:53,400 --> 00:07:55,080
that

181
00:07:55,080 --> 00:07:57,900
at the end of last interval but as

182
00:07:57,900 --> 00:07:59,039
always if people are having like

183
00:07:59,039 --> 00:08:01,199
thoughts or they want to

184
00:08:01,199 --> 00:08:02,759
give

185
00:08:02,759 --> 00:08:05,699
comments or have ideas for

186
00:08:05,699 --> 00:08:07,319
just it can provide the feedback here

187
00:08:07,319 --> 00:08:09,360
directly or

188
00:08:09,360 --> 00:08:12,500
um other notes

189
00:08:12,500 --> 00:08:15,479
and Errata which have been shared with

190
00:08:15,479 --> 00:08:16,979
the authors

191
00:08:16,979 --> 00:08:21,800
I'll also note that um on

192
00:08:26,300 --> 00:08:30,240
J February 27th

193
00:08:30,240 --> 00:08:33,360
Thomas Parr is going to join for a live

194
00:08:33,360 --> 00:08:35,159
stream

195
00:08:35,159 --> 00:08:39,659
so if anyone is um

196
00:08:39,659 --> 00:08:42,240
oh let me just check the UTC time right

197
00:08:42,240 --> 00:08:43,919
now

198
00:08:43,919 --> 00:08:48,740
but if anybody wants to it'll be

199
00:08:50,339 --> 00:08:53,839
17 UTC

200
00:08:54,839 --> 00:08:57,600
17 UTC

201
00:08:57,600 --> 00:09:00,980
on February 27th

202
00:09:02,820 --> 00:09:05,760
so it'll be in Zoom just like this

203
00:09:05,760 --> 00:09:07,140
um

204
00:09:07,140 --> 00:09:09,420
and

205
00:09:09,420 --> 00:09:12,060
we have one month before then

206
00:09:12,060 --> 00:09:14,279
to

207
00:09:14,279 --> 00:09:15,959
prepare

208
00:09:15,959 --> 00:09:17,580
some

209
00:09:17,580 --> 00:09:21,420
questions that we want to highlight and

210
00:09:21,420 --> 00:09:22,920
ask

211
00:09:22,920 --> 00:09:25,399
so

212
00:09:25,740 --> 00:09:26,760
um

213
00:09:26,760 --> 00:09:29,940
those are just some overview Coda

214
00:09:29,940 --> 00:09:32,339
elements and some updates that have

215
00:09:32,339 --> 00:09:34,200
happened in the broader

216
00:09:34,200 --> 00:09:38,459
modeling space over the last few weeks

217
00:09:38,459 --> 00:09:40,939
and months

218
00:09:42,720 --> 00:09:43,980
any

219
00:09:43,980 --> 00:09:48,680
just general or comments on that

220
00:09:53,459 --> 00:09:55,880
is

221
00:09:55,980 --> 00:09:57,600
a

222
00:09:57,600 --> 00:09:59,339
um over a paper or is it going to be

223
00:09:59,339 --> 00:10:01,500
over the textbook or is he just joining

224
00:10:01,500 --> 00:10:03,480
to the question or what is the subject

225
00:10:03,480 --> 00:10:04,440
matter

226
00:10:04,440 --> 00:10:06,959
it's this textbook also your audio is

227
00:10:06,959 --> 00:10:09,000
very off

228
00:10:09,000 --> 00:10:12,320
but yes this textbook

229
00:10:22,080 --> 00:10:24,980
okay any other

230
00:10:25,260 --> 00:10:29,160
daughter questions or we'll turn to look

231
00:10:29,160 --> 00:10:30,540
at the

232
00:10:30,540 --> 00:10:33,079
book

233
00:10:54,000 --> 00:10:55,800
okay

234
00:10:55,800 --> 00:10:58,860
well anyone who has been in cohort one

235
00:10:58,860 --> 00:11:03,000
or otherwise how would they characterize

236
00:11:03,000 --> 00:11:06,000
chapters one through five

237
00:11:06,000 --> 00:11:10,160
as opposed to Chapters six through ten

238
00:11:19,860 --> 00:11:24,480
is any better no not at all okay then I

239
00:11:24,480 --> 00:11:25,140
won't

240
00:11:25,140 --> 00:11:27,360
okay just you can type it or just add it

241
00:11:27,360 --> 00:11:28,620
in the coda

242
00:11:28,620 --> 00:11:32,060
um Ali go for it as anyone else

243
00:11:33,120 --> 00:11:36,600
I think uh chapter one through five was

244
00:11:36,600 --> 00:11:40,740
um basically for a building the the

245
00:11:40,740 --> 00:11:45,060
requisite fundamentals for uh designing

246
00:11:45,060 --> 00:11:47,279
and maybe

247
00:11:47,279 --> 00:11:49,220
uh

248
00:11:49,220 --> 00:11:53,660
applying those Concepts in a much more

249
00:11:53,660 --> 00:11:56,820
a practical way to some real world

250
00:11:56,820 --> 00:11:59,820
situations that we deal we'll deal with

251
00:11:59,820 --> 00:12:01,920
in the second part of the book second

252
00:12:01,920 --> 00:12:05,519
half of the book uh but uh in my opinion

253
00:12:05,519 --> 00:12:08,880
uh even more than this dichotomy between

254
00:12:08,880 --> 00:12:11,760
the fundamentals or application oriented

255
00:12:11,760 --> 00:12:13,860
approaches between the second between

256
00:12:13,860 --> 00:12:17,180
the two halves of the book uh the very

257
00:12:17,180 --> 00:12:20,640
structure of those chapters I mean the

258
00:12:20,640 --> 00:12:22,860
pedagogical structures of those chapters

259
00:12:22,860 --> 00:12:26,279
are very different because uh as much as

260
00:12:26,279 --> 00:12:28,740
in the first chapter we're dealing with

261
00:12:28,740 --> 00:12:30,200
some general

262
00:12:30,200 --> 00:12:33,480
propositions and some general structures

263
00:12:33,480 --> 00:12:37,079
and Frameworks in order to frame the

264
00:12:37,079 --> 00:12:41,700
theory in a comprehensive and

265
00:12:41,700 --> 00:12:44,300
a kind of uh

266
00:12:44,300 --> 00:12:48,540
layered structure in the second half of

267
00:12:48,540 --> 00:12:52,500
the book we're much more in a case of

268
00:12:52,500 --> 00:12:55,620
study based approach and we're dealing

269
00:12:55,620 --> 00:13:00,720
with uh some uh solved examples so to

270
00:13:00,720 --> 00:13:03,660
speak and in some other cases even some

271
00:13:03,660 --> 00:13:07,980
open questions that we can uh we can try

272
00:13:07,980 --> 00:13:10,100
our hands on later

273
00:13:10,100 --> 00:13:13,579
after well learning the basic

274
00:13:13,579 --> 00:13:16,440
fundamental approach to solving these

275
00:13:16,440 --> 00:13:18,300
kind of problems in active inference

276
00:13:18,300 --> 00:13:23,820
framework but in my opinion those these

277
00:13:23,820 --> 00:13:24,600
two

278
00:13:24,600 --> 00:13:28,860
halves of the book are can can even be

279
00:13:28,860 --> 00:13:32,519
uh seen as two separate books uh because

280
00:13:32,519 --> 00:13:36,120
of their uh fundamental differences in

281
00:13:36,120 --> 00:13:39,440
in every aspect

282
00:13:41,880 --> 00:13:45,440
very interesting thank you

283
00:13:45,440 --> 00:13:48,980
anyone else just what are your thoughts

284
00:13:48,980 --> 00:13:52,380
how have chapters one through five sat

285
00:13:52,380 --> 00:13:54,839
with you now that you've

286
00:13:54,839 --> 00:13:57,540
read it and digested it

287
00:13:57,540 --> 00:14:01,200
and then if you have looked at six

288
00:14:01,200 --> 00:14:02,700
through ten

289
00:14:02,700 --> 00:14:04,800
how would you contrast it with chapters

290
00:14:04,800 --> 00:14:07,139
one through five and then we'll look

291
00:14:07,139 --> 00:14:10,519
more in fine grain

292
00:14:15,420 --> 00:14:18,959
I would say one two five was like the

293
00:14:18,959 --> 00:14:20,639
blanket

294
00:14:20,639 --> 00:14:24,660
and six through ten is like the hidden

295
00:14:24,660 --> 00:14:25,800
States

296
00:14:25,800 --> 00:14:28,079
ah

297
00:14:28,079 --> 00:14:30,138
a

298
00:14:30,360 --> 00:14:31,980
awesome

299
00:14:31,980 --> 00:14:34,200
keep the keep the octane fontology 100

300
00:14:34,200 --> 00:14:36,500
percent

301
00:14:38,760 --> 00:14:41,880
a great metaphor

302
00:14:41,880 --> 00:14:43,320
yep

303
00:14:43,320 --> 00:14:45,480
observations one through five

304
00:14:45,480 --> 00:14:48,180
observations six or ten hidden State

305
00:14:48,180 --> 00:14:50,719
inference

306
00:14:52,380 --> 00:14:54,980
Neil

307
00:14:55,199 --> 00:14:58,380
yeah so the first half I I didn't get as

308
00:14:58,380 --> 00:15:01,139
much out of it as I would like to have

309
00:15:01,139 --> 00:15:05,459
it's it's still very mathematical

310
00:15:06,060 --> 00:15:08,459
um but that maths didn't really lead to

311
00:15:08,459 --> 00:15:10,860
insights

312
00:15:10,860 --> 00:15:14,279
um I've I've gone ahead and had a look

313
00:15:14,279 --> 00:15:16,920
through chapters seven

314
00:15:16,920 --> 00:15:18,839
uh and eight

315
00:15:18,839 --> 00:15:21,240
and they look uh

316
00:15:21,240 --> 00:15:25,500
well a lot more like their applications

317
00:15:25,500 --> 00:15:28,860
that I I get I seem to be getting more

318
00:15:28,860 --> 00:15:30,000
from that

319
00:15:30,000 --> 00:15:31,500
than

320
00:15:31,500 --> 00:15:35,120
so that's that's looking good

321
00:15:35,880 --> 00:15:39,300
thank you yes some sometimes it helps to

322
00:15:39,300 --> 00:15:42,480
do the the applications before the

323
00:15:42,480 --> 00:15:44,220
theory

324
00:15:44,220 --> 00:15:48,079
um to give you some sort of Direction

325
00:15:49,260 --> 00:15:51,980
yes

326
00:15:57,300 --> 00:15:59,639
anyone else want to add a comment or all

327
00:15:59,639 --> 00:16:01,079
add a general comment on the chapters

328
00:16:01,079 --> 00:16:03,180
and then we'll go to the subsections and

329
00:16:03,180 --> 00:16:05,599
so on

330
00:16:10,459 --> 00:16:13,740
uh Ali

331
00:16:13,740 --> 00:16:16,620
I also agree with Neil that maybe some

332
00:16:16,620 --> 00:16:19,320
of uh the contents of the second half of

333
00:16:19,320 --> 00:16:22,380
the book uh might work better if they

334
00:16:22,380 --> 00:16:24,420
were interspersed with the material from

335
00:16:24,420 --> 00:16:28,199
the first chapter uh to uh have a much

336
00:16:28,199 --> 00:16:32,160
more goal-oriented vision in mind or and

337
00:16:32,160 --> 00:16:35,360
to not lose the big picture

338
00:16:35,360 --> 00:16:39,360
uh for the coming chapters

339
00:16:39,360 --> 00:16:41,959
yeah

340
00:16:42,120 --> 00:16:44,399
we have with a lot to

341
00:16:44,399 --> 00:16:47,220
infer and do with the pedagogical

342
00:16:47,220 --> 00:16:49,920
ordering and respecting all different

343
00:16:49,920 --> 00:16:53,160
learning preferences and paths

344
00:16:53,160 --> 00:16:53,820
um

345
00:16:53,820 --> 00:16:56,579
we're going to be heading into chapter

346
00:16:56,579 --> 00:16:59,759
six in the coming

347
00:16:59,759 --> 00:17:02,339
um two weeks in our cohort

348
00:17:02,339 --> 00:17:04,020
and here's from the summary of chapter

349
00:17:04,020 --> 00:17:06,179
six

350
00:17:06,179 --> 00:17:07,500
um in this chapter

351
00:17:07,500 --> 00:17:09,720
they're outlining design choices and

352
00:17:09,720 --> 00:17:12,119
they provide a four-step recipe

353
00:17:12,119 --> 00:17:14,819
which we're going to spend a lot of time

354
00:17:14,819 --> 00:17:17,400
working on because like that is our

355
00:17:17,400 --> 00:17:19,559
you know we're all Sous chefs in the

356
00:17:19,559 --> 00:17:23,280
kitchen this is our recipe structure

357
00:17:23,280 --> 00:17:26,699
that every single time a sous chef gives

358
00:17:26,699 --> 00:17:29,640
their input on how to improve it or how

359
00:17:29,640 --> 00:17:31,260
to make something that's a little bit

360
00:17:31,260 --> 00:17:35,520
tacit or implicit into a

361
00:17:35,520 --> 00:17:37,020
checklist

362
00:17:37,020 --> 00:17:39,840
or a template or an automation every

363
00:17:39,840 --> 00:17:41,640
time a sous chef sees that opportunity

364
00:17:41,640 --> 00:17:46,080
the recipe gets better

365
00:17:46,080 --> 00:17:47,940
um this sets up the remainder of the

366
00:17:47,940 --> 00:17:50,280
book which is again what we're going to

367
00:17:50,280 --> 00:17:51,840
be working through in the next three

368
00:17:51,840 --> 00:17:54,419
months putting these ideas into practice

369
00:17:54,419 --> 00:17:57,240
through illustrative examples

370
00:17:57,240 --> 00:17:59,580
which ali

371
00:17:59,580 --> 00:18:01,440
um referred to as like solved examples

372
00:18:01,440 --> 00:18:03,900
and basically they are they might be

373
00:18:03,900 --> 00:18:07,080
trivially solved but whereas what we saw

374
00:18:07,080 --> 00:18:09,240
in terms of solved examples in chapters

375
00:18:09,240 --> 00:18:11,520
one through five was like the frog

376
00:18:11,520 --> 00:18:13,860
jumping out of the hand which is kind of

377
00:18:13,860 --> 00:18:16,559
a solved example of Bayesian inference

378
00:18:16,559 --> 00:18:18,840
now we're going to see some solved

379
00:18:18,840 --> 00:18:20,160
examples

380
00:18:20,160 --> 00:18:22,020
of the type

381
00:18:22,020 --> 00:18:24,900
the active inference models are like

382
00:18:24,900 --> 00:18:26,820
with a partially observable Markov

383
00:18:26,820 --> 00:18:28,320
decision process

384
00:18:28,320 --> 00:18:29,820
in the second half of the book is

385
00:18:29,820 --> 00:18:31,500
designed to showcase the theoretical

386
00:18:31,500 --> 00:18:33,600
principles presented in the first half

387
00:18:33,600 --> 00:18:35,340
of the book

388
00:18:35,340 --> 00:18:38,820
so let's look back to the first chapters

389
00:18:38,820 --> 00:18:41,160
and then see how that is going to be

390
00:18:41,160 --> 00:18:42,720
showcased

391
00:18:42,720 --> 00:18:46,860
chapter one is like an introduction and

392
00:18:46,860 --> 00:18:48,480
on the other side of the bookshelf

393
00:18:48,480 --> 00:18:50,520
chapter 10 is going to be like a summary

394
00:18:50,520 --> 00:18:53,400
recap so that's kind of like the opening

395
00:18:53,400 --> 00:18:54,780
and the closing

396
00:18:54,780 --> 00:18:57,419
bookmarks

397
00:18:57,419 --> 00:18:58,380
um

398
00:18:58,380 --> 00:19:01,860
chapter 2 and 3 cover the low road and

399
00:19:01,860 --> 00:19:03,360
the high road to active inference we're

400
00:19:03,360 --> 00:19:05,880
not going to uh or don't need to go into

401
00:19:05,880 --> 00:19:08,580
it in a lot of detail right now but

402
00:19:08,580 --> 00:19:11,520
those are the two paths that are laid

403
00:19:11,520 --> 00:19:15,059
out to get two active inference

404
00:19:15,059 --> 00:19:18,539
and chapter four puts us squarely in

405
00:19:18,539 --> 00:19:21,960
active inference with a focus on what is

406
00:19:21,960 --> 00:19:23,400
at the heart of active inference

407
00:19:23,400 --> 00:19:27,059
modeling which are generative models

408
00:19:27,059 --> 00:19:31,860
chapter 5 then focuses on one of the

409
00:19:31,860 --> 00:19:33,840
areas where active inference models have

410
00:19:33,840 --> 00:19:37,020
been most applied and applicable which

411
00:19:37,020 --> 00:19:39,900
is in neurobiology and so chapter five

412
00:19:39,900 --> 00:19:43,620
looks at several neurobiological systems

413
00:19:43,620 --> 00:19:45,539
in detail

414
00:19:45,539 --> 00:19:47,760
and how active inference is applied and

415
00:19:47,760 --> 00:19:50,700
then has some tables that show more

416
00:19:50,700 --> 00:19:52,860
broadly where those models have been

417
00:19:52,860 --> 00:19:53,760
applied

418
00:19:53,760 --> 00:19:56,220
so introduction

419
00:19:56,220 --> 00:19:58,320
on what the book is about and its

420
00:19:58,320 --> 00:20:00,419
overall Framing and structure

421
00:20:00,419 --> 00:20:03,539
the two roads to active inference

422
00:20:03,539 --> 00:20:06,179
from the mechanistic and the Bayesian in

423
00:20:06,179 --> 00:20:07,440
the low road

424
00:20:07,440 --> 00:20:09,900
and from the imperative for survival and

425
00:20:09,900 --> 00:20:11,460
the free energy principle on the high

426
00:20:11,460 --> 00:20:12,600
road

427
00:20:12,600 --> 00:20:16,260
chapter 4 describing the structure of

428
00:20:16,260 --> 00:20:17,760
the essence of what this kind of

429
00:20:17,760 --> 00:20:20,340
modeling entails at least in the style

430
00:20:20,340 --> 00:20:22,559
as the authors are laying it out

431
00:20:22,559 --> 00:20:23,940
and then

432
00:20:23,940 --> 00:20:27,360
immediately jumping into examples and

433
00:20:27,360 --> 00:20:30,919
somewhat of a literature review overview

434
00:20:30,919 --> 00:20:34,559
on some of the systems where it's been

435
00:20:34,559 --> 00:20:36,419
most applied

436
00:20:36,419 --> 00:20:38,039
that

437
00:20:38,039 --> 00:20:40,200
are the theoretical principles presented

438
00:20:40,200 --> 00:20:42,480
in the first half of the book

439
00:20:42,480 --> 00:20:44,400
low road High Road

440
00:20:44,400 --> 00:20:46,980
what the model is itself

441
00:20:46,980 --> 00:20:49,380
and how we see it applied in

442
00:20:49,380 --> 00:20:52,160
neurobiology

443
00:20:52,799 --> 00:20:54,960
in the second half of the book

444
00:20:54,960 --> 00:20:57,299
chapter six is going to start us off

445
00:20:57,299 --> 00:20:59,820
with a recipe

446
00:20:59,820 --> 00:21:01,620
and um

447
00:21:01,620 --> 00:21:05,460
this question what are the four steps

448
00:21:05,460 --> 00:21:07,020
previously we had a lot of good

449
00:21:07,020 --> 00:21:08,220
discussion on these and a few other

450
00:21:08,220 --> 00:21:11,280
questions so improving the discourse as

451
00:21:11,280 --> 00:21:14,460
always adding questions

452
00:21:14,460 --> 00:21:16,980
is super helpful

453
00:21:16,980 --> 00:21:18,419
just

454
00:21:18,419 --> 00:21:20,640
checking people's understanding checking

455
00:21:20,640 --> 00:21:22,320
your own understanding

456
00:21:22,320 --> 00:21:24,660
everyone adding one question per week

457
00:21:24,660 --> 00:21:27,360
would result in

458
00:21:27,360 --> 00:21:30,299
a quantity and quality of questions that

459
00:21:30,299 --> 00:21:32,159
would be transformative truly one

460
00:21:32,159 --> 00:21:33,720
question per week even if it seems

461
00:21:33,720 --> 00:21:35,640
trivial or it's a speculative question

462
00:21:35,640 --> 00:21:40,080
so questions are huge and in chapter six

463
00:21:40,080 --> 00:21:44,039
we're focusing on this four-step recipe

464
00:21:44,039 --> 00:21:45,900
it's about how to design active

465
00:21:45,900 --> 00:21:48,539
inference models and

466
00:21:48,539 --> 00:21:51,780
we'll have a lot of space and time

467
00:21:51,780 --> 00:21:54,059
to connect it to

468
00:21:54,059 --> 00:21:58,080
The Cutting Edge work in pi mdp

469
00:21:58,080 --> 00:22:00,900
and approaches that we're using

470
00:22:00,900 --> 00:22:03,360
with the active inference ontology

471
00:22:03,360 --> 00:22:05,580
so that we can have a pathway from a

472
00:22:05,580 --> 00:22:08,100
natural language understanding

473
00:22:08,100 --> 00:22:11,039
of a given system of Interest

474
00:22:11,039 --> 00:22:13,380
on through the kind of state space

475
00:22:13,380 --> 00:22:15,299
representations that are required for pi

476
00:22:15,299 --> 00:22:18,059
mdp so that's what chapter 6 is about

477
00:22:18,059 --> 00:22:20,400
the recipe and the structure as the

478
00:22:20,400 --> 00:22:21,900
authors are laying it out

479
00:22:21,900 --> 00:22:24,480
and also keeping in mind

480
00:22:24,480 --> 00:22:27,059
um not sure exactly which um moment this

481
00:22:27,059 --> 00:22:30,539
was said but the audience for this

482
00:22:30,539 --> 00:22:34,500
textbook I believe Carl said

483
00:22:34,500 --> 00:22:36,720
the audience is something like a

484
00:22:36,720 --> 00:22:39,840
master's students in computational

485
00:22:39,840 --> 00:22:42,539
Psychiatry looking to apply this to

486
00:22:42,539 --> 00:22:44,520
their own research

487
00:22:44,520 --> 00:22:45,900
so

488
00:22:45,900 --> 00:22:48,720
that is like

489
00:22:48,720 --> 00:22:51,419
squarely what this chapter is oriented

490
00:22:51,419 --> 00:22:52,260
to

491
00:22:52,260 --> 00:22:53,880
after

492
00:22:53,880 --> 00:22:56,340
um again all he said like chapters one

493
00:22:56,340 --> 00:22:58,080
through five were about building those

494
00:22:58,080 --> 00:23:00,000
requisite fundamentals

495
00:23:00,000 --> 00:23:01,140
all right

496
00:23:01,140 --> 00:23:03,960
then chapter seven and eight kind of

497
00:23:03,960 --> 00:23:05,940
like the cousins of two and three are

498
00:23:05,940 --> 00:23:07,320
gonna present

499
00:23:07,320 --> 00:23:08,580
uh

500
00:23:08,580 --> 00:23:10,380
duality

501
00:23:10,380 --> 00:23:13,020
or some other kind of minimum two system

502
00:23:13,020 --> 00:23:15,360
chapter seven is gonna look at acronym

503
00:23:15,360 --> 00:23:19,080
in discrete time d a i discrete active

504
00:23:19,080 --> 00:23:22,080
inference which is often affiliated with

505
00:23:22,080 --> 00:23:24,360
decision making cognition

506
00:23:24,360 --> 00:23:26,159
and then

507
00:23:26,159 --> 00:23:28,260
chapter 8 is going to present active

508
00:23:28,260 --> 00:23:30,780
inference in continuous time also

509
00:23:30,780 --> 00:23:33,780
sometimes called m a i or motor active

510
00:23:33,780 --> 00:23:37,679
inference because it can be and has been

511
00:23:37,679 --> 00:23:42,539
used to describe continuous motor reflex

512
00:23:42,539 --> 00:23:46,860
and actuation processes like joints and

513
00:23:46,860 --> 00:23:48,360
movements

514
00:23:48,360 --> 00:23:50,520
so there's many

515
00:23:50,520 --> 00:23:53,880
flavors and variants of active inference

516
00:23:53,880 --> 00:23:55,679
every time we see like an adjective

517
00:23:55,679 --> 00:23:58,140
active inference deep affective

518
00:23:58,140 --> 00:23:59,880
sophisticated

519
00:23:59,880 --> 00:24:03,000
branching time all of these flavors and

520
00:24:03,000 --> 00:24:04,679
adjectives

521
00:24:04,679 --> 00:24:08,460
there's a whole growing Zoo

522
00:24:08,460 --> 00:24:11,460
Wildlife Preserve but one of the most

523
00:24:11,460 --> 00:24:15,360
important and also didactic differences

524
00:24:15,360 --> 00:24:17,700
amongst active inference models are

525
00:24:17,700 --> 00:24:20,640
their treatment of time

526
00:24:20,640 --> 00:24:23,100
along the lines of many other simulation

527
00:24:23,100 --> 00:24:25,020
approaches the difference between

528
00:24:25,020 --> 00:24:28,440
discrete time and continuous time where

529
00:24:28,440 --> 00:24:31,080
the discrete time is more like taking a

530
00:24:31,080 --> 00:24:34,320
sum over finite sets and the continuous

531
00:24:34,320 --> 00:24:38,700
time is a lot more like doing calculus

532
00:24:38,700 --> 00:24:41,340
in chapter 9

533
00:24:41,340 --> 00:24:44,039
knowing what we now know about how

534
00:24:44,039 --> 00:24:46,799
active models can be

535
00:24:46,799 --> 00:24:48,720
cooked up

536
00:24:48,720 --> 00:24:53,880
and about two major classes of

537
00:24:53,880 --> 00:24:55,679
generative models discrete and

538
00:24:55,679 --> 00:24:57,600
continuous time

539
00:24:57,600 --> 00:25:02,159
we'll look at model based data analysis

540
00:25:02,159 --> 00:25:03,360
so

541
00:25:03,360 --> 00:25:05,100
um

542
00:25:05,100 --> 00:25:07,799
I'll just show one figure to um

543
00:25:07,799 --> 00:25:10,919
highlight here's figure 7.1 so

544
00:25:10,919 --> 00:25:14,700
we have a prior hidden States s b is how

545
00:25:14,700 --> 00:25:17,280
the hidden States change their time a is

546
00:25:17,280 --> 00:25:18,960
the mapping between hidden States and

547
00:25:18,960 --> 00:25:21,299
observations

548
00:25:21,299 --> 00:25:23,940
this relationship between the hidden

549
00:25:23,940 --> 00:25:26,700
States and observations

550
00:25:26,700 --> 00:25:28,559
is sometimes called the tale of two

551
00:25:28,559 --> 00:25:30,419
densities

552
00:25:30,419 --> 00:25:31,020
um

553
00:25:31,020 --> 00:25:33,720
just Loosely slash poetically

554
00:25:33,720 --> 00:25:36,539
because this a matrix

555
00:25:36,539 --> 00:25:40,080
can be used to take a hidden state

556
00:25:40,080 --> 00:25:43,740
and generate data What observations

557
00:25:43,740 --> 00:25:45,600
would we expect

558
00:25:45,600 --> 00:25:49,440
given the hidden State and a or you can

559
00:25:49,440 --> 00:25:52,679
take observations and through a do

560
00:25:52,679 --> 00:25:55,320
inference on hidden States

561
00:25:55,320 --> 00:25:59,820
that is using a generative model

562
00:25:59,820 --> 00:26:03,120
in its generative capacity

563
00:26:03,120 --> 00:26:05,520
which is from the hidden states to

564
00:26:05,520 --> 00:26:08,100
generate observations or in its

565
00:26:08,100 --> 00:26:11,340
recognition density from empirical data

566
00:26:11,340 --> 00:26:13,799
back to Hidden State inference of

567
00:26:13,799 --> 00:26:16,020
unobservables

568
00:26:16,020 --> 00:26:19,220
so in chapter 9

569
00:26:19,620 --> 00:26:24,020
um that type of data based uh modeling

570
00:26:24,020 --> 00:26:26,580
is described

571
00:26:26,580 --> 00:26:29,760
whereas in the previous examples

572
00:26:29,760 --> 00:26:33,240
uh things were more oriented towards

573
00:26:33,240 --> 00:26:35,820
like just what is the structure of the

574
00:26:35,820 --> 00:26:37,140
generative model

575
00:26:37,140 --> 00:26:39,960
chapter 9 is going to bring us to

576
00:26:39,960 --> 00:26:42,539
confront this question of with empirical

577
00:26:42,539 --> 00:26:43,799
data

578
00:26:43,799 --> 00:26:47,760
how can we then do state inference which

579
00:26:47,760 --> 00:26:50,100
is a task that starts to look a lot more

580
00:26:50,100 --> 00:26:54,299
like what day-to-day research and

581
00:26:54,299 --> 00:26:56,880
Analysis looks like

582
00:26:56,880 --> 00:26:58,140
and then

583
00:26:58,140 --> 00:27:00,059
quickly as we begun

584
00:27:00,059 --> 00:27:01,860
chapter 10.

585
00:27:01,860 --> 00:27:03,559
is an overview

586
00:27:03,559 --> 00:27:06,179
summarizes the structure of the book

587
00:27:06,179 --> 00:27:07,799
again

588
00:27:07,799 --> 00:27:11,580
gives a quick recap of each section

589
00:27:11,580 --> 00:27:15,380
and provide some closing articulations

590
00:27:15,380 --> 00:27:19,940
and next steps

591
00:27:19,980 --> 00:27:22,220
so again they've laid out the book

592
00:27:22,220 --> 00:27:25,200
broadly into sections

593
00:27:25,200 --> 00:27:28,799
the first half gets as quickly as one

594
00:27:28,799 --> 00:27:31,620
can two the heart

595
00:27:31,620 --> 00:27:33,480
of active inference modeling the

596
00:27:33,480 --> 00:27:34,679
generative model

597
00:27:34,679 --> 00:27:37,919
then reminds us of some of the central

598
00:27:37,919 --> 00:27:40,500
applications over the previous years in

599
00:27:40,500 --> 00:27:43,080
neurobiology also using that as an

600
00:27:43,080 --> 00:27:45,260
opportunity to discuss message passing

601
00:27:45,260 --> 00:27:47,760
which doesn't

602
00:27:47,760 --> 00:27:50,520
centrally feature but is something that

603
00:27:50,520 --> 00:27:53,760
one can imagine will be developed more

604
00:27:53,760 --> 00:27:55,020
then

605
00:27:55,020 --> 00:27:57,240
chapter six or ten what we're going to

606
00:27:57,240 --> 00:28:00,240
be focusing on in this second interval

607
00:28:00,240 --> 00:28:02,400
of activity for cohort 2

608
00:28:02,400 --> 00:28:04,380
we're going to start with a math free

609
00:28:04,380 --> 00:28:06,059
chapter

610
00:28:06,059 --> 00:28:08,159
where we um

611
00:28:08,159 --> 00:28:11,279
are just looking at this recipe

612
00:28:11,279 --> 00:28:14,340
that they're going to lay out which

613
00:28:14,340 --> 00:28:16,320
it's going to be just super exciting

614
00:28:16,320 --> 00:28:17,940
discussions

615
00:28:17,940 --> 00:28:20,260
and there's a lot that

616
00:28:20,260 --> 00:28:20,580
[Music]

617
00:28:20,580 --> 00:28:21,299
um

618
00:28:21,299 --> 00:28:23,400
everyone will be able to contribute on

619
00:28:23,400 --> 00:28:24,299
this

620
00:28:24,299 --> 00:28:27,659
because we'll be able to

621
00:28:27,659 --> 00:28:29,600
come to a lot of

622
00:28:29,600 --> 00:28:31,919
intersubjective clarity about how they

623
00:28:31,919 --> 00:28:33,299
are laying out

624
00:28:33,299 --> 00:28:35,760
the modeling approach

625
00:28:35,760 --> 00:28:38,159
in active inference again according to

626
00:28:38,159 --> 00:28:40,740
par Zulu and friston

627
00:28:40,740 --> 00:28:43,080
and also use that as a starting point

628
00:28:43,080 --> 00:28:44,960
for

629
00:28:44,960 --> 00:28:49,580
specifying what they've proposed

630
00:28:49,620 --> 00:28:52,020
asking questions that aren't addressed

631
00:28:52,020 --> 00:28:54,179
in these short texts

632
00:28:54,179 --> 00:28:56,419
and then connecting to our experience

633
00:28:56,419 --> 00:29:02,100
with modeling whether we've used

634
00:29:02,100 --> 00:29:05,419
programming languages or data analysis

635
00:29:05,419 --> 00:29:10,880
or indifference disciplines and settings

636
00:29:11,580 --> 00:29:14,460
all right so I was just giving a little

637
00:29:14,460 --> 00:29:17,820
overview on the chapters and the

638
00:29:17,820 --> 00:29:21,240
sections anyone have any comments you'd

639
00:29:21,240 --> 00:29:22,500
like to add

640
00:29:22,500 --> 00:29:25,200
on structure

641
00:29:25,200 --> 00:29:28,740
or chapters M Carl

642
00:29:28,740 --> 00:29:30,960
yeah um

643
00:29:30,960 --> 00:29:33,539
I have a question I'm not so sure

644
00:29:33,539 --> 00:29:35,220
whether this uh

645
00:29:35,220 --> 00:29:38,159
is a little bit off but if you're so bad

646
00:29:38,159 --> 00:29:41,520
show this this model this hidden Markov

647
00:29:41,520 --> 00:29:43,919
model that you just showed with the

648
00:29:43,919 --> 00:29:48,000
hidden States and and the observations

649
00:29:48,000 --> 00:29:51,360
I am wondering so so I I would like

650
00:29:51,360 --> 00:29:54,120
maybe I can just say this briefly you

651
00:29:54,120 --> 00:29:55,679
already read to

652
00:29:55,679 --> 00:29:59,100
what my research is about uh Daniel I

653
00:29:59,100 --> 00:30:01,740
think you know so so I have a no I can't

654
00:30:01,740 --> 00:30:03,779
I may have but please feel free just for

655
00:30:03,779 --> 00:30:05,700
everyone's context whatever you like to

656
00:30:05,700 --> 00:30:09,360
add go for it okay so so I have a huge

657
00:30:09,360 --> 00:30:11,640
amount of data and I'm wondering whether

658
00:30:11,640 --> 00:30:15,059
this um so behavioral data actually and

659
00:30:15,059 --> 00:30:16,860
I was wondering whether this could be

660
00:30:16,860 --> 00:30:19,919
the right approach to model this and my

661
00:30:19,919 --> 00:30:23,700
question here is so the Matrix is a and

662
00:30:23,700 --> 00:30:27,320
b are I guess independent

663
00:30:27,320 --> 00:30:32,340
and so if there is a decision on this

664
00:30:32,340 --> 00:30:35,820
hidden States as s

665
00:30:35,820 --> 00:30:38,940
and the emission of the observation

666
00:30:38,940 --> 00:30:42,539
through an a matrix

667
00:30:42,539 --> 00:30:46,440
this is um somehow independent from the

668
00:30:46,440 --> 00:30:50,220
successive State observation right so I

669
00:30:50,220 --> 00:30:53,580
or is it or is there a possibility to

670
00:30:53,580 --> 00:30:55,220
to

671
00:30:55,220 --> 00:30:59,700
tell the system that the success so that

672
00:30:59,700 --> 00:31:02,399
the emission of one observation from a

673
00:31:02,399 --> 00:31:03,200
state

674
00:31:03,200 --> 00:31:06,240
depends a little bit or the successive

675
00:31:06,240 --> 00:31:08,940
State depends on what the previous state

676
00:31:08,940 --> 00:31:11,159
has emitted what observation was

677
00:31:11,159 --> 00:31:12,659
produced

678
00:31:12,659 --> 00:31:15,600
I understand my question so it looks

679
00:31:15,600 --> 00:31:16,320
like

680
00:31:16,320 --> 00:31:19,620
uh the the transitions are independent

681
00:31:19,620 --> 00:31:24,600
from the emissions and I'm not so sure

682
00:31:24,600 --> 00:31:28,380
uh what this actually implies in the

683
00:31:28,380 --> 00:31:31,760
modeling of my data

684
00:31:32,520 --> 00:31:35,100
um does that question make sense

685
00:31:35,100 --> 00:31:37,740
awesome thank you so there's a few

686
00:31:37,740 --> 00:31:39,539
pieces

687
00:31:39,539 --> 00:31:41,760
anyone want to give a first thought and

688
00:31:41,760 --> 00:31:44,279
then this is like again it's an example

689
00:31:44,279 --> 00:31:45,899
of what we can

690
00:31:45,899 --> 00:31:49,380
add as a question you don't have to go

691
00:31:49,380 --> 00:31:51,179
and tag everything with the active

692
00:31:51,179 --> 00:31:53,100
fontology if you want but certainly one

693
00:31:53,100 --> 00:31:55,080
could because you use a lot of active

694
00:31:55,080 --> 00:31:57,360
ontology terms

695
00:31:57,360 --> 00:31:58,679
but

696
00:31:58,679 --> 00:32:00,779
regardless of how fully formed or

697
00:32:00,779 --> 00:32:03,059
appropriate one thinks like adding the

698
00:32:03,059 --> 00:32:05,820
question to these tables

699
00:32:05,820 --> 00:32:07,860
is one of the most helpful ways that

700
00:32:07,860 --> 00:32:10,020
those insights that we do want to share

701
00:32:10,020 --> 00:32:15,020
in this space can have like

702
00:32:15,020 --> 00:32:18,480
extremely highly leveraged impact even

703
00:32:18,480 --> 00:32:20,220
without large language models being

704
00:32:20,220 --> 00:32:21,960
trained on these documents which will

705
00:32:21,960 --> 00:32:23,880
surely happen

706
00:32:23,880 --> 00:32:26,880
these are important questions

707
00:32:26,880 --> 00:32:29,220
so I'm just going to try to take notes

708
00:32:29,220 --> 00:32:31,020
as people discuss this

709
00:32:31,020 --> 00:32:34,500
on this questions and topics page so

710
00:32:34,500 --> 00:32:37,760
Giuseppe and anyone else

711
00:32:43,380 --> 00:32:47,820
so if I can answer my own question or a

712
00:32:47,820 --> 00:32:49,380
thought at least

713
00:32:49,380 --> 00:32:52,919
so one could add at the output a kind of

714
00:32:52,919 --> 00:32:55,880
a language model

715
00:32:56,940 --> 00:33:00,059
um or maybe and I don't know are there

716
00:33:00,059 --> 00:33:03,659
are there such tweaks that are

717
00:33:03,659 --> 00:33:06,659
um possible in this whole model

718
00:33:06,659 --> 00:33:09,539
so if we if we say that the one

719
00:33:09,539 --> 00:33:11,760
observation does not only depend on the

720
00:33:11,760 --> 00:33:13,799
state which has emitted it but also on

721
00:33:13,799 --> 00:33:16,740
the previous observation

722
00:33:16,740 --> 00:33:19,559
how can we model I mean one way to model

723
00:33:19,559 --> 00:33:21,960
this would be to have a language model

724
00:33:21,960 --> 00:33:26,700
that runs over the over maybe

725
00:33:26,700 --> 00:33:28,140
um

726
00:33:28,140 --> 00:33:29,240
um

727
00:33:29,240 --> 00:33:33,000
alternative possible observations and

728
00:33:33,000 --> 00:33:35,760
then decide which

729
00:33:35,760 --> 00:33:39,299
chain of sequence of observations one

730
00:33:39,299 --> 00:33:42,779
has the highest likelihood this is

731
00:33:42,779 --> 00:33:45,419
or how could some something like this be

732
00:33:45,419 --> 00:33:47,820
modeled is this uh

733
00:33:47,820 --> 00:33:52,919
is this taken account to uh in some ways

734
00:33:52,919 --> 00:33:56,220
yeah great questions Giuseppe then Neil

735
00:33:56,220 --> 00:33:58,760
than anyone else

736
00:34:04,740 --> 00:34:08,239
I don't hear you Giuseppe

737
00:34:11,040 --> 00:34:12,480
um yes I do

738
00:34:12,480 --> 00:34:16,560
okay uh so I was thinking although the

739
00:34:16,560 --> 00:34:18,780
the transition in my understanding the

740
00:34:18,780 --> 00:34:21,119
transition matrices are pre-specified

741
00:34:21,119 --> 00:34:23,219
then

742
00:34:23,219 --> 00:34:27,839
at the at the moment of learning in a

743
00:34:27,839 --> 00:34:29,639
sense

744
00:34:29,639 --> 00:34:33,179
the the matrices are updated so to

745
00:34:33,179 --> 00:34:34,379
reflect

746
00:34:34,379 --> 00:34:36,719
the observations

747
00:34:36,719 --> 00:34:40,260
so but but they're not immediately I

748
00:34:40,260 --> 00:34:41,460
guess and they're not immediately

749
00:34:41,460 --> 00:34:43,580
updated on the basis of the last

750
00:34:43,580 --> 00:34:46,440
observation is that

751
00:34:46,440 --> 00:34:49,320
is that correct

752
00:34:49,320 --> 00:34:52,520
yeah I'll just briefly directly respond

753
00:34:52,520 --> 00:34:56,520
in the simplest possible framing of this

754
00:34:56,520 --> 00:34:58,320
partially observable Markov decision

755
00:34:58,320 --> 00:35:01,440
process there's no learning or parameter

756
00:35:01,440 --> 00:35:04,320
updating at all A and B are fixed

757
00:35:04,320 --> 00:35:07,080
however we're in the Bayesian statistics

758
00:35:07,080 --> 00:35:09,240
World we're in the Bayes area so

759
00:35:09,240 --> 00:35:11,760
everything can be learnable

760
00:35:11,760 --> 00:35:14,640
for example in this Pi mdp script first

761
00:35:14,640 --> 00:35:16,140
there was an active inference Loop

762
00:35:16,140 --> 00:35:18,780
specified and then the kind of cousin

763
00:35:18,780 --> 00:35:21,240
function was specified where the B

764
00:35:21,240 --> 00:35:23,700
Matrix was learnable

765
00:35:23,700 --> 00:35:27,200
so one can have every variable here

766
00:35:27,200 --> 00:35:29,940
fixed or learnable

767
00:35:29,940 --> 00:35:32,280
it just depends how you actually do the

768
00:35:32,280 --> 00:35:34,260
modeling and that's again what chapter 6

769
00:35:34,260 --> 00:35:36,420
is going to confront us with

770
00:35:36,420 --> 00:35:38,160
one can imagine that if you have a fixed

771
00:35:38,160 --> 00:35:40,079
a matrix all you have to do is specify

772
00:35:40,079 --> 00:35:42,359
the a matrix if you want to have

773
00:35:42,359 --> 00:35:43,619
learning

774
00:35:43,619 --> 00:35:45,720
the state space and the dimensionality

775
00:35:45,720 --> 00:35:49,320
of your model has vastly increased

776
00:35:49,320 --> 00:35:51,599
so that may be worth it in certain

777
00:35:51,599 --> 00:35:52,859
situations

778
00:35:52,859 --> 00:35:55,440
but now you're dealing with Decay rates

779
00:35:55,440 --> 00:35:56,640
and

780
00:35:56,640 --> 00:35:58,560
learning constants and critical

781
00:35:58,560 --> 00:36:00,780
forgetting and just there's all these

782
00:36:00,780 --> 00:36:02,220
features that you're just not dealing

783
00:36:02,220 --> 00:36:05,040
with with the more reduced fixed model

784
00:36:05,040 --> 00:36:06,300
so

785
00:36:06,300 --> 00:36:09,660
all the parameters can be fixed or not

786
00:36:09,660 --> 00:36:11,820
okay and then was there a second aspect

787
00:36:11,820 --> 00:36:15,140
or on to Neil

788
00:36:15,300 --> 00:36:18,440
yeah thank you

789
00:36:19,110 --> 00:36:20,339
[Music]

790
00:36:20,339 --> 00:36:23,700
okay my so I'm not

791
00:36:23,700 --> 00:36:26,400
really I don't really understand this

792
00:36:26,400 --> 00:36:27,780
but my

793
00:36:27,780 --> 00:36:30,359
feeling is if if a and b are

794
00:36:30,359 --> 00:36:32,640
interdependent does that mean that it's

795
00:36:32,640 --> 00:36:36,180
not a matter of decision process

796
00:36:36,180 --> 00:36:40,260
uh and if you've got a system where it's

797
00:36:40,260 --> 00:36:43,980
where the current state is not just

798
00:36:43,980 --> 00:36:47,220
dependent on the previous state but on

799
00:36:47,220 --> 00:36:49,980
on the States before that then that's

800
00:36:49,980 --> 00:36:53,040
that's not a a mark of

801
00:36:53,040 --> 00:36:55,759
process

802
00:36:56,099 --> 00:36:59,400
awesome yes that was the the

803
00:36:59,400 --> 00:37:03,540
Direction I was going to add so from a

804
00:37:03,540 --> 00:37:06,720
pure empirical perspective

805
00:37:06,720 --> 00:37:09,720
the observations may have a strong

806
00:37:09,720 --> 00:37:11,940
correlation so if you did a descriptive

807
00:37:11,940 --> 00:37:14,579
statistical approach like

808
00:37:14,579 --> 00:37:18,540
arima or just time series modeling you'd

809
00:37:18,540 --> 00:37:20,280
find that like

810
00:37:20,280 --> 00:37:22,500
there was a statistical correlation

811
00:37:22,500 --> 00:37:25,260
amongst similar observations again we're

812
00:37:25,260 --> 00:37:26,940
just thinking of some

813
00:37:26,940 --> 00:37:29,579
you know temperature in a room hidden

814
00:37:29,579 --> 00:37:31,500
State thermometer readings and the

815
00:37:31,500 --> 00:37:32,940
observations there's some like time

816
00:37:32,940 --> 00:37:34,859
autocorrelation

817
00:37:34,859 --> 00:37:38,579
what the markovian property is even the

818
00:37:38,579 --> 00:37:40,079
last names aren't informative this is

819
00:37:40,079 --> 00:37:42,420
just what is called a markovian property

820
00:37:42,420 --> 00:37:46,140
is that the presence is a Markov blanket

821
00:37:46,140 --> 00:37:49,020
between the past and the future

822
00:37:49,020 --> 00:37:51,599
in other words this is a map this isn't

823
00:37:51,599 --> 00:37:54,720
the territory this is a map that helps

824
00:37:54,720 --> 00:37:57,180
us reduce the dimensionality of all

825
00:37:57,180 --> 00:37:59,700
possible models by considering those

826
00:37:59,700 --> 00:38:02,960
that have this one very important

827
00:38:02,960 --> 00:38:05,220
simplifying feature

828
00:38:05,220 --> 00:38:07,740
which is that the past only influences

829
00:38:07,740 --> 00:38:10,680
the future through the present

830
00:38:10,680 --> 00:38:14,460
so yes observations might be the same

831
00:38:14,460 --> 00:38:15,900
across different time points or they

832
00:38:15,900 --> 00:38:17,760
might be correlated from a Time series

833
00:38:17,760 --> 00:38:19,079
perspective

834
00:38:19,079 --> 00:38:21,720
but architecturally

835
00:38:21,720 --> 00:38:24,540
from the Bayesian graph model that we're

836
00:38:24,540 --> 00:38:25,859
going to use

837
00:38:25,859 --> 00:38:28,740
the way that we're going to model

838
00:38:28,740 --> 00:38:32,099
those observations through a Time

839
00:38:32,099 --> 00:38:35,099
is by having the observations

840
00:38:35,099 --> 00:38:37,560
emitted or received

841
00:38:37,560 --> 00:38:40,140
Tale of Two densities

842
00:38:40,140 --> 00:38:43,020
by a hidden state which undergoes time

843
00:38:43,020 --> 00:38:45,440
evolution

844
00:38:45,900 --> 00:38:50,220
so there's no direct Edge between the

845
00:38:50,220 --> 00:38:51,960
observation at T minus 1 and the

846
00:38:51,960 --> 00:38:54,960
observation at T

847
00:38:54,960 --> 00:38:57,960
the a matrix could be the same if it's a

848
00:38:57,960 --> 00:39:00,540
fixed a or the a matrix may have even

849
00:39:00,540 --> 00:39:04,140
changed if it's learnable a

850
00:39:04,140 --> 00:39:07,440
but the key feature that makes this

851
00:39:07,440 --> 00:39:09,119
partially observable

852
00:39:09,119 --> 00:39:12,240
is the fact that some parts of the model

853
00:39:12,240 --> 00:39:14,940
are observable like data observations

854
00:39:14,940 --> 00:39:16,859
and some parts are not observable hidden

855
00:39:16,859 --> 00:39:18,420
States so that's the partially

856
00:39:18,420 --> 00:39:20,700
observable po part

857
00:39:20,700 --> 00:39:24,780
and then what makes it a Markov process

858
00:39:24,780 --> 00:39:27,960
is this present acting as the blanket

859
00:39:27,960 --> 00:39:29,640
between the past and the future

860
00:39:29,640 --> 00:39:31,500
and then what makes it a decision

861
00:39:31,500 --> 00:39:33,300
process

862
00:39:33,300 --> 00:39:36,060
is that we're inter this is just a

863
00:39:36,060 --> 00:39:39,839
partially observable Markov process

864
00:39:39,839 --> 00:39:42,480
in figure 7.1

865
00:39:42,480 --> 00:39:44,040
partially observable hidden State

866
00:39:44,040 --> 00:39:47,520
observations markovian property current

867
00:39:47,520 --> 00:39:49,560
moments interleaving between the past

868
00:39:49,560 --> 00:39:50,880
and the future

869
00:39:50,880 --> 00:39:54,320
what makes it a Markov decision process

870
00:39:54,320 --> 00:39:57,000
is that it has the markovian property

871
00:39:57,000 --> 00:39:58,079
and

872
00:39:58,079 --> 00:40:01,020
we are embedding action

873
00:40:01,020 --> 00:40:04,980
into the Markov process how by having

874
00:40:04,980 --> 00:40:07,079
evaluation

875
00:40:07,079 --> 00:40:09,240
of alternative policies

876
00:40:09,240 --> 00:40:12,060
and how they intervene

877
00:40:12,060 --> 00:40:15,200
at the B Matrix

878
00:40:15,480 --> 00:40:16,980
so that's why this is a partially

879
00:40:16,980 --> 00:40:20,579
observable Markov decision process it

880
00:40:20,579 --> 00:40:23,220
has all of those attributes

881
00:40:23,220 --> 00:40:26,760
and there's justifications for why we

882
00:40:26,760 --> 00:40:28,200
want it to be partially observable why

883
00:40:28,200 --> 00:40:30,119
we want it to be markovian and why we

884
00:40:30,119 --> 00:40:32,760
want it to be a decision process

885
00:40:32,760 --> 00:40:35,160
and if somebody has some other modeling

886
00:40:35,160 --> 00:40:36,780
scenario in mind

887
00:40:36,780 --> 00:40:39,119
then

888
00:40:39,119 --> 00:40:40,920
some of those adjectives might have to

889
00:40:40,920 --> 00:40:42,480
change or you might add

890
00:40:42,480 --> 00:40:45,140
adjectives

891
00:40:47,760 --> 00:40:48,660
um

892
00:40:48,660 --> 00:40:52,220
Ali and then anyone else

893
00:40:53,040 --> 00:40:55,740
uh yes adding to which what you just

894
00:40:55,740 --> 00:40:59,040
explained even when uh defining the B

895
00:40:59,040 --> 00:41:04,140
Matrix uh we just add the indices based

896
00:41:04,140 --> 00:41:05,700
on the state factors that are

897
00:41:05,700 --> 00:41:09,119
controllable that are controllable or

898
00:41:09,119 --> 00:41:10,160
um

899
00:41:10,160 --> 00:41:14,099
because in that case uh with each action

900
00:41:14,099 --> 00:41:18,359
the B Matrix would be different so this

901
00:41:18,359 --> 00:41:21,200
means that we would need an index

902
00:41:21,200 --> 00:41:24,300
specifying which action is actually

903
00:41:24,300 --> 00:41:28,140
taken but for other contextual states

904
00:41:28,140 --> 00:41:30,180
which are not in the under the control

905
00:41:30,180 --> 00:41:33,000
of the agent we don't need any

906
00:41:33,000 --> 00:41:34,980
additional

907
00:41:34,980 --> 00:41:37,740
a transition probabilities for each

908
00:41:37,740 --> 00:41:41,880
action so yeah even in defining the

909
00:41:41,880 --> 00:41:44,640
structure of the B Matrix we distinguish

910
00:41:44,640 --> 00:41:46,800
between the states that are controllable

911
00:41:46,800 --> 00:41:50,460
and the contextual states that are out

912
00:41:50,460 --> 00:41:53,700
of the control of the agents

913
00:41:53,700 --> 00:41:57,540
awesome thank you yeah and and as we go

914
00:41:57,540 --> 00:41:58,980
through chapter six in the coming two

915
00:41:58,980 --> 00:41:59,940
weeks

916
00:41:59,940 --> 00:42:02,160
which is a qualitative chapter

917
00:42:02,160 --> 00:42:05,579
and then also look towards exactly how

918
00:42:05,579 --> 00:42:08,400
these are set up in pi mdp

919
00:42:08,400 --> 00:42:11,220
like this is a movement up down left

920
00:42:11,220 --> 00:42:12,900
right or this is just a Left Right

921
00:42:12,900 --> 00:42:15,119
movement or stay

922
00:42:15,119 --> 00:42:17,460
these

923
00:42:17,460 --> 00:42:20,280
affordances and transition probabilities

924
00:42:20,280 --> 00:42:22,260
and everything like that

925
00:42:22,260 --> 00:42:25,740
they get encoded in matrices

926
00:42:25,740 --> 00:42:30,060
and these operations are like linear

927
00:42:30,060 --> 00:42:31,380
algebra

928
00:42:31,380 --> 00:42:34,320
like arrays or tensors or matrices

929
00:42:34,320 --> 00:42:35,520
kind of

930
00:42:35,520 --> 00:42:38,880
being collided with each other

931
00:42:38,880 --> 00:42:40,800
the circles and the squares are

932
00:42:40,800 --> 00:42:43,260
variables they're variables of slightly

933
00:42:43,260 --> 00:42:45,540
different types but they are all

934
00:42:45,540 --> 00:42:46,800
variables

935
00:42:46,800 --> 00:42:49,680
and then the edges reflect like which

936
00:42:49,680 --> 00:42:52,440
we're going to combine

937
00:42:52,440 --> 00:42:55,560
and so each given variable

938
00:42:55,560 --> 00:42:57,599
has a semantics

939
00:42:57,599 --> 00:42:59,940
which we associate with an active

940
00:42:59,940 --> 00:43:03,180
inference ontology term

941
00:43:03,180 --> 00:43:07,020
D prior s hidden State a ambiguity

942
00:43:07,020 --> 00:43:08,160
Matrix

943
00:43:08,160 --> 00:43:11,700
oh observations B transition Matrix

944
00:43:11,700 --> 00:43:14,000
Pi policy

945
00:43:14,000 --> 00:43:17,900
policy is just the set of possible

946
00:43:17,900 --> 00:43:22,140
actions that are evaluated by the agent

947
00:43:22,140 --> 00:43:25,200
e is used for affordances

948
00:43:25,200 --> 00:43:27,420
which is like the action possibilities

949
00:43:27,420 --> 00:43:30,960
in one moment up down left right and

950
00:43:30,960 --> 00:43:32,220
then pi

951
00:43:32,220 --> 00:43:35,700
is affordances considered over the given

952
00:43:35,700 --> 00:43:39,599
time Horizon so over one time step depth

953
00:43:39,599 --> 00:43:42,359
so not a deep model

954
00:43:42,359 --> 00:43:44,819
affordances are the same as policies

955
00:43:44,819 --> 00:43:46,920
because it's just the list of

956
00:43:46,920 --> 00:43:48,780
affordances whereas if you were doing

957
00:43:48,780 --> 00:43:51,839
like a depth of three in time

958
00:43:51,839 --> 00:43:53,160
then

959
00:43:53,160 --> 00:43:54,839
you would have

960
00:43:54,839 --> 00:43:58,140
affordances to the third power that

961
00:43:58,140 --> 00:44:00,359
number

962
00:44:00,359 --> 00:44:01,140
um

963
00:44:01,140 --> 00:44:03,180
how are

964
00:44:03,180 --> 00:44:05,760
policies evaluated

965
00:44:05,760 --> 00:44:09,240
using free energy calculations how are

966
00:44:09,240 --> 00:44:10,859
policies selected free energy

967
00:44:10,859 --> 00:44:13,560
minimization what does that look like in

968
00:44:13,560 --> 00:44:16,260
code here's the active inference Loop

969
00:44:16,260 --> 00:44:19,020
the heart of the octave inference Loop

970
00:44:19,020 --> 00:44:20,280
is

971
00:44:20,280 --> 00:44:23,400
inference on States

972
00:44:23,400 --> 00:44:26,280
that is taking in observations

973
00:44:26,280 --> 00:44:28,740
and doing hidden State inference

974
00:44:28,740 --> 00:44:32,040
then inference on policy

975
00:44:32,040 --> 00:44:36,119
what am I updating my policy posterior

976
00:44:36,119 --> 00:44:37,560
to be

977
00:44:37,560 --> 00:44:40,560
and then sampling from your policy

978
00:44:40,560 --> 00:44:42,480
posterior

979
00:44:42,480 --> 00:44:45,839
this is like observe and Orient

980
00:44:45,839 --> 00:44:49,560
this is like decide and act

981
00:44:49,560 --> 00:44:52,079
but what pi mdp has done an incredible

982
00:44:52,079 --> 00:44:53,640
job of

983
00:44:53,640 --> 00:44:57,960
is making it so that the a b c d are

984
00:44:57,960 --> 00:45:00,300
defined you have to Define what those

985
00:45:00,300 --> 00:45:02,760
are here's how C is defined

986
00:45:02,760 --> 00:45:07,220
and then you define an agent

987
00:45:08,760 --> 00:45:11,760
as a b c and d my agent

988
00:45:11,760 --> 00:45:14,940
a is a b is b c is c d is d

989
00:45:14,940 --> 00:45:16,859
we Define the agent that's the

990
00:45:16,859 --> 00:45:18,119
generative model

991
00:45:18,119 --> 00:45:20,099
we Define the environment that's the

992
00:45:20,099 --> 00:45:21,660
generative process

993
00:45:21,660 --> 00:45:24,780
and then we write the loop

994
00:45:24,780 --> 00:45:26,760
that connects the generative model and

995
00:45:26,760 --> 00:45:29,599
the generative process

996
00:45:30,540 --> 00:45:33,200
Giuseppe

997
00:45:33,240 --> 00:45:36,420
yes uh so you you talked about the E

998
00:45:36,420 --> 00:45:38,579
Matrix and you called it the Matrix of

999
00:45:38,579 --> 00:45:40,619
affordances

1000
00:45:40,619 --> 00:45:42,180
um

1001
00:45:42,180 --> 00:45:44,940
I think I remember in the book it was it

1002
00:45:44,940 --> 00:45:47,220
was more like the habits was it is it

1003
00:45:47,220 --> 00:45:48,839
correct

1004
00:45:48,839 --> 00:45:53,819
yes this is the same thing yes so

1005
00:45:53,819 --> 00:45:57,180
um affordance I I you know I'm thinking

1006
00:45:57,180 --> 00:46:02,220
about uh gibsonian uh affordances but

1007
00:46:02,220 --> 00:46:06,480
is it this I maybe I don't see the links

1008
00:46:06,480 --> 00:46:07,740
uh

1009
00:46:07,740 --> 00:46:12,180
all right great I'm gonna go for um

1010
00:46:12,180 --> 00:46:15,300
a short answer and then a more

1011
00:46:15,300 --> 00:46:17,160
um something that connects us to some

1012
00:46:17,160 --> 00:46:19,740
ongoing debates in the area

1013
00:46:19,740 --> 00:46:22,980
the E Matrix both describes the

1014
00:46:22,980 --> 00:46:24,599
affordances in terms of the action

1015
00:46:24,599 --> 00:46:28,200
possibilities as well as to what extent

1016
00:46:28,200 --> 00:46:31,020
they're habitual and so like let's just

1017
00:46:31,020 --> 00:46:33,540
say that there's four um we can go up

1018
00:46:33,540 --> 00:46:35,040
down left right

1019
00:46:35,040 --> 00:46:40,200
so if there's um a one one one one for

1020
00:46:40,200 --> 00:46:42,540
up down left right that's like saying

1021
00:46:42,540 --> 00:46:44,460
you can go up down left right and

1022
00:46:44,460 --> 00:46:46,680
they're all equally likely to happen

1023
00:46:46,680 --> 00:46:49,560
if it were like one one one nine

1024
00:46:49,560 --> 00:46:51,540
then it's like you can go up down left

1025
00:46:51,540 --> 00:46:55,380
right but this one has a higher prior

1026
00:46:55,380 --> 00:46:59,300
probability on policy

1027
00:46:59,400 --> 00:47:02,280
if this were like one one zero nine it's

1028
00:47:02,280 --> 00:47:05,160
like this cannot happen as well as

1029
00:47:05,160 --> 00:47:07,619
things that aren't listed can't happen

1030
00:47:07,619 --> 00:47:09,980
so the E Matrix

1031
00:47:09,980 --> 00:47:13,260
describes action possibilities

1032
00:47:13,260 --> 00:47:15,420
and by doing so

1033
00:47:15,420 --> 00:47:17,880
whatever is included in the list is an

1034
00:47:17,880 --> 00:47:20,339
is at least there is a prior on that

1035
00:47:20,339 --> 00:47:22,140
action happening

1036
00:47:22,140 --> 00:47:25,440
and then quantitatively the value of the

1037
00:47:25,440 --> 00:47:28,319
E Matrix describes the habitualness and

1038
00:47:28,319 --> 00:47:30,300
then like in chapter five

1039
00:47:30,300 --> 00:47:33,859
we saw about how like dopamine

1040
00:47:33,859 --> 00:47:37,740
mediates or is modeled to mediate

1041
00:47:37,740 --> 00:47:39,980
the handoff

1042
00:47:39,980 --> 00:47:43,079
between more habit-guided

1043
00:47:43,079 --> 00:47:45,119
here habit just gets passed through

1044
00:47:45,119 --> 00:47:47,400
actions are selected more based upon

1045
00:47:47,400 --> 00:47:50,099
what one has already acted upon in the

1046
00:47:50,099 --> 00:47:53,400
past whereas here we can see free energy

1047
00:47:53,400 --> 00:47:55,800
evaluation

1048
00:47:55,800 --> 00:47:59,040
as sharpening your policy prior

1049
00:47:59,040 --> 00:48:01,800
into a policy posterior that you then

1050
00:48:01,800 --> 00:48:04,079
sample from

1051
00:48:04,079 --> 00:48:07,380
come on so free energy minimization is

1052
00:48:07,380 --> 00:48:08,760
then like kind of like that type 2

1053
00:48:08,760 --> 00:48:10,740
Thinking where we're sharpening our

1054
00:48:10,740 --> 00:48:12,660
policy distribution so that we can make

1055
00:48:12,660 --> 00:48:15,060
a decision that has a lower expected

1056
00:48:15,060 --> 00:48:16,440
free energy

1057
00:48:16,440 --> 00:48:18,420
even if that's not the one that we would

1058
00:48:18,420 --> 00:48:21,300
have gone to from habit and then just to

1059
00:48:21,300 --> 00:48:24,839
connect it to um some recent

1060
00:48:24,839 --> 00:48:26,280
um discussions I'll put this in the chat

1061
00:48:26,280 --> 00:48:29,280
so request um access if if you want on

1062
00:48:29,280 --> 00:48:33,180
the gibsonian note there is this paper

1063
00:48:33,180 --> 00:48:35,460
um trick or treat and long story long

1064
00:48:35,460 --> 00:48:38,280
story but there is like a Markov blanket

1065
00:48:38,280 --> 00:48:41,700
trick paper by these authors and then a

1066
00:48:41,700 --> 00:48:43,200
bunch of commentaries

1067
00:48:43,200 --> 00:48:45,480
and then just a few days ago they made a

1068
00:48:45,480 --> 00:48:47,180
comeback

1069
00:48:47,180 --> 00:48:50,160
summarizing the commentaries and going

1070
00:48:50,160 --> 00:48:51,599
further and

1071
00:48:51,599 --> 00:48:52,560
um

1072
00:48:52,560 --> 00:48:54,780
basically their

1073
00:48:54,780 --> 00:48:58,140
main issue is

1074
00:48:58,140 --> 00:49:01,079
the fep affordance concept isn't the

1075
00:49:01,079 --> 00:49:03,720
gibsonian affordance direct perception

1076
00:49:03,720 --> 00:49:06,660
of action possibilities concept

1077
00:49:06,660 --> 00:49:09,660
ergo

1078
00:49:09,900 --> 00:49:12,780
read the paper to find out more but we

1079
00:49:12,780 --> 00:49:15,300
had very fun discussions and it spoke

1080
00:49:15,300 --> 00:49:18,000
exactly to the gibsonian question

1081
00:49:18,000 --> 00:49:20,640
okay well thank you very very clear

1082
00:49:20,640 --> 00:49:23,819
thank you awesome

1083
00:49:23,819 --> 00:49:27,540
okay in our last just like few minutes

1084
00:49:27,540 --> 00:49:31,500
any other notes

1085
00:49:39,060 --> 00:49:41,880
awesome so um

1086
00:49:41,880 --> 00:49:44,839
we're gonna be

1087
00:49:47,220 --> 00:49:51,359
in chapter six for the next two weeks

1088
00:49:51,359 --> 00:49:55,098
chapter six is not that long

1089
00:49:55,260 --> 00:49:57,060
um

1090
00:49:57,060 --> 00:49:59,160
so this will be a good

1091
00:49:59,160 --> 00:50:00,660
time

1092
00:50:00,660 --> 00:50:02,099
to

1093
00:50:02,099 --> 00:50:04,260
make

1094
00:50:04,260 --> 00:50:07,859
this process of active modeling

1095
00:50:07,859 --> 00:50:09,359
our own

1096
00:50:09,359 --> 00:50:11,339
and customize it

1097
00:50:11,339 --> 00:50:13,619
provide templates

1098
00:50:13,619 --> 00:50:15,480
connect it to the work that's already

1099
00:50:15,480 --> 00:50:18,119
happening in pi mdp

1100
00:50:18,119 --> 00:50:20,960
explore ways that we can

1101
00:50:20,960 --> 00:50:23,040
go from

1102
00:50:23,040 --> 00:50:26,640
vision of the scenarios that people want

1103
00:50:26,640 --> 00:50:28,200
to model

1104
00:50:28,200 --> 00:50:29,940
into

1105
00:50:29,940 --> 00:50:32,640
the kinds of models that will have

1106
00:50:32,640 --> 00:50:36,799
pragmatic and epistemic value for us

1107
00:50:37,980 --> 00:50:39,839
any last comments or I will close the

1108
00:50:39,839 --> 00:50:41,400
recording

1109
00:50:41,400 --> 00:50:44,280
quick question uh because I haven't I

1110
00:50:44,280 --> 00:50:49,079
haven't watched the the p y p y MVP uh

1111
00:50:49,079 --> 00:50:53,099
talk yet but is a like all the codes

1112
00:50:53,099 --> 00:50:57,059
that are in the in the book are actually

1113
00:50:57,059 --> 00:50:59,520
been reward are reworked and are

1114
00:50:59,520 --> 00:51:02,420
available in in Python

1115
00:51:02,420 --> 00:51:05,940
no that is not the case yet but with

1116
00:51:05,940 --> 00:51:08,460
some automated and semi-automated work

1117
00:51:08,460 --> 00:51:10,440
it could be

1118
00:51:10,440 --> 00:51:13,319
um in model stream 7.2 which you can

1119
00:51:13,319 --> 00:51:15,059
find from live streams

1120
00:51:15,059 --> 00:51:17,520
um in the video description is that is

1121
00:51:17,520 --> 00:51:19,619
this notebook

1122
00:51:19,619 --> 00:51:21,000
so

1123
00:51:21,000 --> 00:51:24,420
um but we don't have um notebooks for

1124
00:51:24,420 --> 00:51:27,059
the Matlab code let alone python trans

1125
00:51:27,059 --> 00:51:29,460
uh formations but if somebody wants to

1126
00:51:29,460 --> 00:51:30,480
do that

1127
00:51:30,480 --> 00:51:33,300
let's do that

1128
00:51:33,300 --> 00:51:37,440
okay thank you yep and in the code

1129
00:51:37,440 --> 00:51:38,640
page

1130
00:51:38,640 --> 00:51:41,700
there's there's a GitHub repo

1131
00:51:41,700 --> 00:51:45,180
so if some it just if somebody

1132
00:51:45,180 --> 00:51:48,000
wants to add the code just

1133
00:51:48,000 --> 00:51:49,500
feel free

1134
00:51:49,500 --> 00:51:52,260
all right so see you

1135
00:51:52,260 --> 00:51:54,420
um cohort too thanks for continuing on

1136
00:51:54,420 --> 00:51:57,300
see you future weeks at this time and

1137
00:51:57,300 --> 00:51:59,339
also there's the optional like in like

1138
00:51:59,339 --> 00:52:01,260
eight or ten hours or something like the

1139
00:52:01,260 --> 00:52:04,079
Discord office hours we'll just chill

1140
00:52:04,079 --> 00:52:06,180
and um

1141
00:52:06,180 --> 00:52:08,220
just there will be people from different

1142
00:52:08,220 --> 00:52:09,540
cohorts

1143
00:52:09,540 --> 00:52:11,760
and we'll just

1144
00:52:11,760 --> 00:52:14,220
go where people want to go so thank you

1145
00:52:14,220 --> 00:52:17,819
feel free to stay on for um cohort 2

1146
00:52:17,819 --> 00:52:19,500
beginning in just a minute all right

1147
00:52:19,500 --> 00:52:23,000
thank you thank you

