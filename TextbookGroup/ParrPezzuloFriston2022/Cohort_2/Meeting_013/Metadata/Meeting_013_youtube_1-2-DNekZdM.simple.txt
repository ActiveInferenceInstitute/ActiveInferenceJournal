SPEAKER_06:
hello it is january 25th 2023 and we are in cohort two of the par at all textbook we're in meeting 13. today we are going to jump back in start our second interval of activities

there are a few ways we can go we can just review structural aspects of the coda and accommodate anyone's like suggestions or notes on some things that could be interesting to develop with in this one or an aside little sandbox then we will look to the textbook itself and we will look at where the first five chapters got us

and where we're going with the second half of the book which has a different form and function than the first half of the book so first off anyone want to just add any general comment how now that it's 2023

Where are they in their act-inf learning and application journey?

How is our niche similar or different than it was in September through November when we worked through the first five chapters?

Any thoughts?

Or we can continue on.

Just wanted to leave that space.

Okay, feel free to raise your hand or just unmute or put in the chat or anything like that.

Broadly, the layout is similar.

Textbook group overview has information on our live meetings and that's where you can download the textbook.

The textbook section itself

contains different types of things that are in the textbook such as the equations which have all been brought out with images and page at least but there's a lot of improvements that we could make to the descriptions and the tagging similarly with figures we have all figures brought out

but there's a lot of contributions that can be made to descriptions and tagging.

Boxes and tables, similar.

Code implementations.

I'll add a link to Blockference.

So if anybody, which is one thing that we've worked on the last few months, we have about 40 or 50 implementations of Act-Inf.

in Python, C++, Julia, MATLAB.

So accessible from here.

And we can, for those who want to start getting more into the code, and I'll just show one more piece that we worked on earlier today in the Blockference meeting.

In Model Stream 7.2, a notebook was used.

an epistemic contextual multi-armed bandit simulation was provided by Conor Hines.

Just works perfectly, no tweaking is needed.

Uses actin, floop, defines, etc.

And what we did today was we took the actin fontology and we then said, how is this set up in the contextual bandit?

How do they set up B?

Okay, here's how B is set up.

one can click this and then in a plain text paste in the whole script so this is not the only way that we're going to be working towards modeling but as the second half of the textbook is about building a generative model and the process the recipe

we have like multiple functions in this cohort two as we go through chapter six or ten one function will be to to the extent that we want to develop our own generative model and simulation

just didactically just to have something that we increment along to help us understand or if there's some outcome that people want to pursue research or application oriented like second half of the textbook is um the time to do it and even relative to last September we have significantly better tools

So there's totally an approach to go from a natural language understanding of these ontology terms to how to do it in PyMDP.

And it's pretty reasonable that somebody who wants to pursue this direction, we could just add another column, copy it over, make the tweak.

And there's a few other pieces, but a lot of that is going to come up in chapter six.

In chapter notes and questions, we have the chapters themselves.

and a detailed table of contents and then each chapter has subset view of the questions so if you have a question within a given chapter or you want to help uh improve and curate the discourse please just like add a row in the questions section or just make improvements to the answers and discourse um so we'll um

continue to work with questions as well as whatever notes people add uh to just what or anything else they want to highlight um into the more discourse sections here's the home of the questions table but it's shown in the chapters as well ideas and insights people are always welcome to add just sort of nuggets or summaries for what

they're updating their models with, what they're coming away from, from these sections.

Math Learning Group has no current live activities, but there's a huge amount of resources and some summaries that are written.

But there's always many things for people to do with testing out math learning.

Project ideas.

can return to but that's kind of where we left off within the last meeting of the first half um future textbook groups we organized that at the end of last interval but as always if people are having like thoughts or they want to give comments or have ideas for

I can provide the feedback here directly or other notes and errata, which have been shared with the authors.

I'll also note that on February 27th, Thomas Parr is going to join for a live stream.

So if anyone is, let me just check the UTC time right now.

But if anybody wants to, it'll be 17 UTC, 17 UTC on February 27th.

So it'll be in Zoom just like this.

And we have one month before then to...

prepare some questions that we want to highlight and ask so um those are just some overview Coda elements and some updates that have happened in the broader modeling space over the last few weeks and months

Any just general or comments on that?


SPEAKER_03:
Is the Thomas Power live stream going to be over a paper or is it going to be over the textbook?

Or is he just joining to field questions?

Or what is the subject matter?


SPEAKER_06:
It's this textbook.

Also, your audio is very off.

But yes, this textbook.

okay any other thoughts or questions or we'll turn to look at the book

Okay.

Well, anyone who has been in Cohort 1 or otherwise, how would they characterize chapters 1 through 5 as opposed to chapters 6 through 10?


SPEAKER_03:
Is my audio any better?


SPEAKER_06:
No, not at all.


SPEAKER_01:
okay just you can type it or just add it in the coda Ali go for it and anyone else I think chapter one through five was basically for building the requisite fundamentals for designing and maybe applying those concepts in a much more uh

practical way to some real world situations that we will deal with in the second part of the book, second half of the book.

But in my opinion, even more than the dichotomy between the fundamentals or application oriented approaches between the two halves of the book,

The very structure of those chapters, I mean, the pedagogical structures of those chapters are very different because as much as in the first chapter, we're dealing with some general propositions and some general structures and frameworks in order to frame the theory in a comprehensive and a kind of...

layered structure.

In the second half of the book, we're much more in a case of study-based approach, and we're dealing with some solved examples, so to speak, and in some other cases, even some open questions that we can try our hands on later after

while learning the basic fundamental approach to solving these kinds of problems in active inference framework.

But in my opinion, these two halves of the book can even be seen as two separate books because of their fundamental differences in every aspect.


SPEAKER_06:
Very interesting.

Thank you.

Anyone else?

Just what are your thoughts?

How have chapters 1 through 5 sat with you now that you've read it and digested it?

And then if you have looked at 6 through 10, how would you contrast it with chapters 1 through 5?

And then we'll look more in fine grains.


SPEAKER_05:
i would say one through five was like the blanket and six through ten is like the hidden state awesome keep the keep the active ontology 100 a great metaphor yep


SPEAKER_04:
observations one through five observations six or ten hidden state inference neil yeah so the first half i i didn't get as much out of it as i would like to if it's it's still very mathematical um but that maths didn't really lead to insight um i've

I've gone ahead and had a look through chapters seven and eight, and they look a lot more like their applications.

I guess I seem to be getting more from that.

So that's looking good.

Thank you.

Yes.

Sometimes it helps to do the applications before the theory to give you some sort of direction.

Yes.


SPEAKER_06:
Anyone else want to add a comment or I'll add a general comment on the chapters and then we'll go to the subsections and so on.


SPEAKER_01:
Ali?

I also agree with Neil that maybe some of the contents of the second half of the book might work better if they were interspersed with the material from the first chapter to have a much more goal-oriented vision in mind and to not lose the big picture for the coming chapters.


SPEAKER_06:
Yeah.

Yeah.

have we have a lot to infer and do with the pedagogical ordering and respecting all different learning preferences and paths um we're going to be heading into chapter six in the coming um two weeks in our cohort and here's from the summary of chapter six um in this chapter they're outlining design choices and they provide a four-step recipe

which we're going to spend a lot of time working on because like that is our you know we're all sous chefs in the kitchen this is our recipe structure that every single time a sous chef gives their input on how to improve it or how to make something that's a little bit tacit or implicit into a checklist

a template or an automation every time a sous chef sees that opportunity the recipe gets better um this sets up the remainder of the book which is again what we're going to be working through in the next three months putting these ideas into practice through illustrative examples

which Ali referred to as like solved examples, and basically they are.

They might be trivially solved, but whereas what we saw in terms of solved examples in chapters one through five was like the frog jumping out of the hand, which is kind of a solved example of Bayesian inference, now we're going to see some solved examples

of the type that active inference models are like with a partially observable markov decision process and the second half of the book is designed to showcase the theoretical principles presented in the first half of the book so let's look back to the first chapters and then see how that is going to be showcased chapter one is like an introduction

and on the other side of the bookshelf chapter 10 is going to be like a summary recap so that's kind of like the opening and the closing bookmarks chapter two and three cover the low road and the high road to active inference we're not gonna or don't need to go into it in a lot of detail right now but those are the two paths that are laid out to get to active inference

and chapter four puts us squarely in active inference with a focus on what is at the heart of active inference modeling which are generative models

Chapter five then focuses on one of the areas where active inference models have been most applied and applicable, which is in neurobiology.

And so chapter five looks at several neurobiological systems in detail,

how active inference is applied and then has some tables that show more broadly where those models have been applied so introduction on what the book is about and its overall framing and structure the two roads to active inference from the mechanistic and the bayesian in the low road and from the imperative for survival and the free energy principle on the high road

chapter four describing the structure of the essence of what this kind of modeling entails at least in the style as the authors are laying it out and then immediately jumping into examples and somewhat of a literature review overview on some of the systems where it's been most applied that are the theoretical principles presented in the first half of the book

low road high road what the model is itself and how we see it applied in neurobiology in the second half of the book chapter six is going to start us off with a recipe and um this question what are the four steps

previously we had a lot of good discussion on these and a few other questions so improving the discourse as always adding questions is super helpful just checking people's understanding checking your own understanding everyone adding one question per week would result in

a quantity and quality of questions that would be transformative truly one question per week even if it seems trivial or is a speculative question so questions are huge and in chapter six we're focusing on this four-step recipe it's about how to design active inference models and we'll have a lot of space and time to connect it to

the cutting edge work in PyMDP and approaches that we're using with the active inference ontology so that we can have a pathway from a natural language understanding

of a given system of interest on through the kind of states-based representations that are required for PyMDP.

So that's what chapter six is about, the recipe and the structure as the authors are laying it out.

And also keeping in mind, not sure exactly which moment this was said, but the audience for this textbook, I believe Carl said,

the audience is something like a master student in computational psychiatry looking to apply this to their own research so that is like squarely what this chapter is oriented to after um again as ali said like chapters one through five were about building those requisite fundamentals all right

Then chapter seven and eight, kind of like the cousins of two and three, are going to present duality or some other kind of minimum two system.

Chapter seven is going to look at active in discrete time, DAI, discrete active inference, which is often affiliated with decision-making cognition.

And then chapter

Chapter eight is going to present active inference in continuous time, also sometimes called MAI or motor active inference, because it can be and has been used to describe continuous motor reflex and actuation processes like joints and movement.

So there's many flavors and variants of active inference.

every time we see like an adjective active inference deep affective sophisticated branching time all of these flavors and adjectives there's a whole growing zoo wildlife preserve but one of the most important and also didactic differences amongst active inference models are their treatment of time

along the lines of many other simulation approaches.

The difference between discrete time and continuous time, where the discrete time is more like taking a sum over finite sets, and the continuous time is a lot more like doing calculus.

In chapter 9, knowing what we now know about how active models can be cooked up,

and about two major classes of generative models discrete and continuous time we'll look at model based data analysis so um

i'll just show one figure to um highlight here's figure 7.1 so we have a prior hidden states s b is how the hidden states change their time a is the mapping between hidden states and observations this relationship between the hidden states and observations is sometimes called the tale of two densities

just loosely slash poetically because this a matrix can be used to take a hidden state and generate data what observations would we expect given the hidden state and a or you can take observations and through a do inference on hidden states that is using a generative model

in its generative capacity which is from the hidden states to generate observations or in its recognition density from empirical data back to hidden state inference of unobservables so in chapter 9 that type of data-based modeling is described whereas in the previous examples

things were more oriented towards like just what is the structure of the generative model?

Chapter nine is going to bring us to confront this question of with empirical data,

how can we then do state inference which is a task that starts to look a lot more like what day-to-day research and analysis looks like and then quickly as we begun chapter 10 is an overview summarizes the structure of the book again

gives a quick recap of each section and provides some closing articulations and next steps so again they've laid out the book broadly into sections

the first half gets as quickly as one can to the heart of active inference modeling the generative model then reminds us of some of the central applications over the previous years in neurobiology also using that as an opportunity to discuss message passing which doesn't

centrally feature but is something that one can imagine will be developed more then chapter six or ten what we're going to be focusing on in this second interval of activity for cohort two we're going to start with a math free chapter where we um are just looking at this recipe that they're going to lay out which

going to be just super exciting discussions and there's a lot that um everyone will be able to contribute on this because we'll be able to come to a lot of intersubjective clarity about how they are laying out the modeling approach in active inference again according to par zulo and friston

And also use that as a starting point for specifying what they've proposed, asking questions that aren't addressed in these short texts, and then connecting to our experience with modeling, whether we've used programming languages or data analysis or in different disciplines and settings.

All right, so I was just giving a little overview on the chapters and the sections.

Anyone have any comments they'd like to add on structure or chapters?

M. Carl.


SPEAKER_00:
Yeah, I have a question.

I'm not so sure whether this is a little bit off.

But if you show this model, this hidden Markov model that you just showed with the hidden states and the observations,

I'm wondering, so I would like, maybe I can just say this briefly.

You already read what my research is about, Daniel, I think.


SPEAKER_06:
I may have, but please feel free, just for everyone's context, whatever you'd like to add, go for it.


SPEAKER_00:
OK, so I have a huge amount of data.

And I'm wondering whether this is behavioral data, actually.

And I was wondering whether this could be the right approach to model this.

And my question here is, so the matrixes A and B are, I guess, independent.

And so if there is a decision on these hidden states,

S and the emission of the observation through an A matrix.

This is somehow independent from the successive observation, right?

So is there a possibility to tell the system that the emission of one observation from a state depends a little bit, or the successive state depends on what the previous state has emitted, what observation was produced?

I understand my question.

So it looks like the transitions are independent from the emissions.

And I'm not so sure what this actually implies in the modeling of my data.

Does that question make sense?


SPEAKER_06:
Awesome.

Thank you.

So there's a few pieces.

anyone want to give a first thought and then this is like again it's an example of what we can add as a question you don't have to go and tag everything with the actin fontology if you want but certainly one could because you use a lot of actin fontology terms but regardless of how fully formed or appropriate one thinks like adding the question to these tables

is one of the most helpful ways that those insights that we do want to share in this space can have like extremely highly leveraged impact even without large language models being trained on these documents which will assuredly happen these are important questions so i'm just going to try to take notes as people discuss this on this questions and topics page so giuseppe and anyone else


SPEAKER_00:
So if I can answer my own question, or a thought at least.

So one could add at the output a kind of a language model

Or maybe, I don't know, are there such tweaks that are possible in this whole model?

So if we say that one observation does not only depend on the state which has emitted it, but also on the previous observation,

How can we model?

I mean, one way to model this would be to have a language model that runs over maybe

alternative possible observations and then decide which chain of sequence of observations one has the highest likelihood.

Or how could something like this be modeled?

Is this taken account to in some ways?


SPEAKER_06:
Yeah, great questions, Giuseppe, then Neil, then anyone else.

I don't hear you, Giuseppe.

Yes, I do.


SPEAKER_02:
Okay.

So I was thinking, although the transition, in my understanding, the transition matrices are pre-specified, then at the moment of learning, in a sense, the mean matrices are updated so to reflect

observations so but but they're not immediately i guess and they're not immediately updated on the basis of the last observation is that is that correct yeah i'll just briefly directly respond


SPEAKER_06:
In the simplest possible framing of this partially observable Markov decision process, there's no learning or parameter updating at all.

A and B are fixed.

However, we're in the Bayesian statistics world, we're in the Bayes area, so everything can be learnable.

For example, in this PyMDP script, first there was an active inference loop specified, and then a kind of cousin function was specified where the B matrix was learnable.

So one can have every variable here fixed or learnable.

It just depends how you actually do the modeling.

And that's, again, what chapter six is going to confront us with.

One can imagine that if you have a fixed A matrix, all you have to do is specify the A matrix.

If you want to have learning, the state space and the dimensionality of your model has vastly increased.

So that may be worth it in certain situations, but now you're dealing with decay rates and learning constants and critical forgetting, and just there's all these features that you're just not dealing with with the more reduced fixed model.

So all the parameters can be fixed or not.

Okay, and then was there a second aspect or onto Neil?


SPEAKER_02:
Yeah, thank you.


SPEAKER_04:
I don't really understand this, but my feeling is if A and B are interdependent, does that mean that it's not a Markov decision process?

And if you've got a system where the current state is not just dependent on the previous state, but on states before that, then that's not a Markov process.


SPEAKER_06:
Awesome.

Yes, that was the direction I was going to add.

So from a pure empirical perspective,

observations may have a strong correlation so if you did a descriptive statistical approach like arima or just time series modeling you'd find that like there was a statistical correlation amongst similar observations again we're just thinking of some you know temperature in a room hidden state thermometer readings in the observations there's some like time auto correlation

what the markovian property is even though last names aren't informative this is just what is called a markovian property is that the present is a markov blanket between the past and the future in other words this is a map this isn't the territory this is a map that helps us reduce the dimensionality of all possible models by considering those that have

this one very important simplifying feature, which is that the past only influences the future through the present.

So yes, observations might be the same across different time points, or they might be correlated from a time series perspective, but architecturally from the Bayesian graph model that we're going to use, the way that we're going to model

those observations through time is by having the observations emitted or received hashtag tail of two densities by a hidden state which undergoes time evolution so there's no direct edge between the observation at t minus one and the observation at t

The A matrix could be the same if it's a fixed A, or the A matrix may have even changed if it's a learnable A. But the key feature that makes this partially observable is the fact that some parts of the model are observable, like data observations, and some parts are not observable, hidden states.

So that's the partially observable PO part.

And then what makes it a Markov process

is this present acting as the blanket between the past and the future and then what makes it a decision process is that we're inter this is just a partially observable markov process in figure 7.1 partially observable hidden state observations markovian property current moment interleaving between the past and the future

What makes it a Markov decision process is that it has the Markovian property and we are embedding action into the Markov process.

How?

By having evaluation of alternative policies and how they intervene at the B matrix.

So that's why this is a partially observable Markov decision process.

It has all of those attributes.

And there's justifications for why we want it to be partially observable, why we want it to be Markovian, and why we want it to be a decision process.

And if somebody has some other modeling scenario in mind, then some of those adjectives might have to change or you might add adjectives.

Ali, and then anyone else.


SPEAKER_01:
Yes, adding to what you just explained, even when defining the B matrix, we just add the indices based on the state factors that are controllable or

Because in that case, with each action, the B matrix would be different.

So this means that we would need an index specifying which action is actually taken.

But for other contextual states, which are not under the control of the agent, we don't need any additional action.

a transition probabilities for each action.

So yeah, even in defining the structure of the B matrix, we distinguish between the states that are controllable and the contextual states that are out of the control of the agents.


SPEAKER_06:
awesome thank you yeah and and as we go through chapter six in the coming two weeks which is a qualitative chapter and then also look towards exactly how these are set up in pi mdp like this is a movement up down left right or this is just a left right movement or stay these affordances and transition probabilities and everything like that

they get encoded in matrices and these operations are like linear algebra like arrays or tensors or matrices kind of being collided with each other the circles and the squares are variables they're variables of slightly different types but they are all variables and then the edges reflect like which we're going to combine

and so each given variable has a semantics which we associate with an active inference ontology term d prior s hidden state a ambiguity matrix o observations b transition matrix pi policy policy is just the set of possible actions that are evaluated by the agent

e is used for affordances which is like the action possibilities in one moment up down left right and then pi is affordances considered over the given time horizon so over one time step depth so not a deep model affordances are the same as policies because it's just the list of affordances whereas if you were doing like a depth of three in time

then you would have affordances to the third power that number um how are policies evaluated using free energy calculations how are policies selected free energy minimization what does that look like in code here's the active inference loop the heart of the active inference loop

is inference on states that is taking in observations and doing hidden state inference then inference on policy what am i updating my policy posterior to be and then sampling from your policy posterior this is like observe and orient this is like decide and act

But what PyMVP has done an incredible job of is making it so that the A, B, C, D are defined.

You have to define what those are.

Here's how C is defined.

And then you define an agent as A, B, C, and D. My agent.

A is A, B is B, C is C, D is D.

We define the agent, that's the generative model.

We define the environment, that's the generative process.

And then we write the loop that connects the generative model and the generative process.

Giuseppe?


SPEAKER_02:
Yes.

So you, you talked about the E matrix, and you called it the matrix of affordances.

I think I remember in the book, it was, it was more like the habits.

Was it?

Is it correct?

Yes, the same thing.


SPEAKER_06:
Yes.


SPEAKER_02:
So I afford us I, you know, I'm thinking about Gibsonian affordances, but

is it this i maybe i don't see the links uh all right great i'm gonna go for um


SPEAKER_06:
a short answer and then a more um something that connects us to some ongoing debates in the area the e-matrix both describes the affordances in terms of the action possibilities as well as to what extent they're habitual and so like let's just say that there's four um we can go up down left right so if

there's um a one one one one for up down left right that's like saying you can go up down left right and they're all equally likely to happen if it were like one one one nine then it's like you can go up down left right but this one has a higher prior probability on policy

if this were like 1 1 0 9 it's like this cannot happen as well as things that aren't listed can't happen so the e-matrix describes action possibilities and by doing so whatever is included in the list is at least there is a prior on that action happening

And then quantitatively, the value of the E matrix describes the habitualness.

And then like in chapter five, we saw about how like dopamine,

mediates or is modeled to mediate the handoff between more habit guided.

Here, habit just gets passed through.

Actions are selected more based upon what one has already acted upon in the past.

Whereas here, we can see free energy evaluation as sharpening your policy prior into a policy posterior that you then sample from.

So free energy minimization is then kind of like that type two thinking where we're sharpening our policy distribution so that we can make a decision that has a lower expected free energy

even if that's not the one that we would have gone to from habit and then just to connect it to um some recent um discussions i'll put this in the chat so request um access if if you want on the gibsonian note there is this paper um trick or treat and long story long story but there is like a markov blanket trick paper by these authors and then a bunch of commentaries and then just a few days ago they made a comeback

summarizing the commentaries and going further and um basically their main issue is the fep affordance concept isn't the gibsonian affordance direct perception of action possibilities concept ergo read the paper to find out more but we had very fun discussions and it it spoke exactly to the gibsonian question

okay well thank you very very clear thank you awesome okay in our last just like few minutes any other notes awesome so um we're gonna be

in chapter six for the next two weeks chapter six is not that long um so this will be a good time to make this process of active modeling our own and customize it provide templates connect it to the work that's already happening in pyMDP

explore ways that we can go from vision of the scenarios that people want to model into the kinds of models that will have pragmatic and epistemic value for us.

Any last comments or I will close the recording.


SPEAKER_02:
Quick question, because I haven't watched the PYMVP talk yet, but is it like all the codes that are in the book are actually being reworked and are available in Python?


SPEAKER_06:
No, that is not the case yet, but with some automated and semi-automated work, it could be.

In model stream 7.2, which you can find from live streams, in the video description is this notebook.

But we don't have notebooks for the MATLAB code, let alone Python transformations.

But if somebody wants to do that, let's do that.

okay thank you yep and in the code page there's there's a github repo so if some just if somebody

wants to add the code, just feel free.

All right.

So see you cohort two.

Thanks for continuing on.

See you future weeks at this time.

And also there's the optional, like in like eight or 10 hours or something like the discord office hours, we'll just chill.

And just there'll be people from different cohorts and we'll just,

go where people want to go.

So thank you.

Feel free to stay on for cohort two beginning in just a minute.


SPEAKER_02:
All right.


SPEAKER_06:
Thank you.


SPEAKER_02:
Thank you.