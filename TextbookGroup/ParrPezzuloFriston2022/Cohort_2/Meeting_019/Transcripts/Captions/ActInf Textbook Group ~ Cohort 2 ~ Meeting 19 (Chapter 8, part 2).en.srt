1
00:00:01,439 --> 00:00:06,000
hello it is cohort two

2
00:00:06,000 --> 00:00:09,059
March 8 2023

3
00:00:09,059 --> 00:00:12,660
we're in meeting 19 and we're in our

4
00:00:12,660 --> 00:00:16,199
second discussion on chapter eight

5
00:00:16,199 --> 00:00:18,539
we will look over the questions on

6
00:00:18,539 --> 00:00:20,279
chapter eight

7
00:00:20,279 --> 00:00:22,199
and talk about any sections of chapter

8
00:00:22,199 --> 00:00:23,699
eight

9
00:00:23,699 --> 00:00:25,859
and we will

10
00:00:25,859 --> 00:00:28,439
um also probably take a preview look

11
00:00:28,439 --> 00:00:30,960
towards Nye

12
00:00:30,960 --> 00:00:32,220
so

13
00:00:32,220 --> 00:00:36,960
just at the outset does anyone have any

14
00:00:36,960 --> 00:00:39,180
um comments or questions

15
00:00:39,180 --> 00:00:42,260
on a

16
00:00:42,480 --> 00:00:44,399
anything else that they've come across

17
00:00:44,399 --> 00:00:47,820
or learned over the last week

18
00:00:47,820 --> 00:00:50,640
that puts continuous time models in a

19
00:00:50,640 --> 00:00:53,420
different context

20
00:00:54,180 --> 00:00:57,120
any other thoughts on

21
00:00:57,120 --> 00:01:00,739
continuous and discrete

22
00:01:01,260 --> 00:01:03,120
or we'll look over the questions and

23
00:01:03,120 --> 00:01:04,440
make sure that we've at least touched

24
00:01:04,440 --> 00:01:05,939
upon each of the questions from the

25
00:01:05,939 --> 00:01:08,839
previous cohorts

26
00:01:10,680 --> 00:01:13,979
yeah I'll let you go for it

27
00:01:13,979 --> 00:01:15,080
foreign

28
00:01:15,080 --> 00:01:18,960
actually based on uh some of the claims

29
00:01:18,960 --> 00:01:21,840
especially in amazing mechanics paper

30
00:01:21,840 --> 00:01:27,200
and also in this recent path integrals

31
00:01:27,200 --> 00:01:30,180
yeah path into girls paper

32
00:01:30,180 --> 00:01:31,020
um

33
00:01:31,020 --> 00:01:33,439
they they claim that

34
00:01:33,439 --> 00:01:38,159
fep formulation at least from about 2012

35
00:01:38,159 --> 00:01:42,439
to 2019 was largely

36
00:01:42,439 --> 00:01:44,840
focused on

37
00:01:44,840 --> 00:01:46,400
developing

38
00:01:46,400 --> 00:01:49,619
density Over States mathematics or you

39
00:01:49,619 --> 00:01:52,159
know the words the first two types of

40
00:01:52,159 --> 00:01:55,159
fpp path tracking and

41
00:01:55,159 --> 00:01:58,799
paths matching and path mode dynamic

42
00:01:58,799 --> 00:01:59,840
split

43
00:01:59,840 --> 00:02:03,299
uh I'm sorry mode matching and mode

44
00:02:03,299 --> 00:02:06,320
tracking Dynamics but in recent years

45
00:02:06,320 --> 00:02:09,840
they've concentrated more on developing

46
00:02:09,840 --> 00:02:14,280
the path integral formulation uh I'm not

47
00:02:14,280 --> 00:02:19,160
sure which direction this

48
00:02:19,160 --> 00:02:22,379
textbook leans toward because in some

49
00:02:22,379 --> 00:02:27,000
places it seems like it is the

50
00:02:27,000 --> 00:02:31,260
tension of the previous developmental

51
00:02:31,260 --> 00:02:36,680
trajectories but especially in chapter 8

52
00:02:36,680 --> 00:02:39,860
it gets more into

53
00:02:39,860 --> 00:02:43,260
this recent formulation of uh

54
00:02:43,260 --> 00:02:46,280
formulating the path integral

55
00:02:46,280 --> 00:02:50,220
mathematics but then again even in

56
00:02:50,220 --> 00:02:56,120
chapter 8 we see discussions about the

57
00:03:06,500 --> 00:03:10,980
previous years and this year and also

58
00:03:10,980 --> 00:03:12,180
um yeah

59
00:03:12,180 --> 00:03:15,060
how the textbook leans

60
00:03:15,060 --> 00:03:19,159
Maps into that dichotomy

61
00:03:19,379 --> 00:03:21,000
yeah thank you

62
00:03:21,000 --> 00:03:28,080
good um points Thomas overviewed as such

63
00:03:28,080 --> 00:03:31,080
and

64
00:03:31,620 --> 00:03:33,780
this

65
00:03:33,780 --> 00:03:38,220
par textbook seems to be more heavily

66
00:03:38,220 --> 00:03:41,760
on the mode matching and mode tracking

67
00:03:41,760 --> 00:03:46,140
however the continuous time

68
00:03:46,140 --> 00:03:47,940
it's kind of like the more things change

69
00:03:47,940 --> 00:03:49,739
the more they stay the same

70
00:03:49,739 --> 00:03:52,920
so looking at Thomas's overview

71
00:03:52,920 --> 00:03:56,220
of the um history the early

72
00:03:56,220 --> 00:03:59,099
implementations as he noted

73
00:03:59,099 --> 00:04:02,220
um we're in continuous time

74
00:04:02,220 --> 00:04:06,900
and then in order to bring on

75
00:04:06,900 --> 00:04:07,819
um

76
00:04:07,819 --> 00:04:10,099
explicit planning

77
00:04:10,099 --> 00:04:12,420
discrete cognitive decision making

78
00:04:12,420 --> 00:04:15,299
symbolic State spaces and so on

79
00:04:15,299 --> 00:04:17,459
sequential Behavior

80
00:04:17,459 --> 00:04:19,560
they actually

81
00:04:19,560 --> 00:04:21,660
um pivoted to the discrete time

82
00:04:21,660 --> 00:04:24,240
formalism

83
00:04:24,240 --> 00:04:26,820
and that that left the continuous time

84
00:04:26,820 --> 00:04:29,820
lock of Volterra uh generalized

85
00:04:29,820 --> 00:04:31,740
dynamical systems

86
00:04:31,740 --> 00:04:35,759
uh phrasings behind

87
00:04:35,759 --> 00:04:38,040
then

88
00:04:38,040 --> 00:04:39,720
um

89
00:04:39,720 --> 00:04:42,120
now we have a

90
00:04:42,120 --> 00:04:44,639
a fusion

91
00:04:44,639 --> 00:04:48,180
of the continuous and the discrete times

92
00:04:48,180 --> 00:04:53,340
with uh typified by the figure 8.6

93
00:04:53,340 --> 00:04:55,800
where through hierarchical nested models

94
00:04:55,800 --> 00:04:59,940
we can include features of um discrete

95
00:04:59,940 --> 00:05:02,759
decision making as well as continuous

96
00:05:02,759 --> 00:05:04,979
perception and action

97
00:05:04,979 --> 00:05:08,960
uh also discussed in live stream 46

98
00:05:08,960 --> 00:05:11,520
octave does not contradict folk

99
00:05:11,520 --> 00:05:14,820
psychology with kefir ramstead and Smith

100
00:05:14,820 --> 00:05:18,120
which discuss essentially this model

101
00:05:18,120 --> 00:05:21,660
as the folk psychological scaffold

102
00:05:21,660 --> 00:05:24,240
that there's a motor active inference

103
00:05:24,240 --> 00:05:28,139
layer that's perceptual and active in

104
00:05:28,139 --> 00:05:30,180
continuous space and time

105
00:05:30,180 --> 00:05:34,020
and then we can propose these symbolic

106
00:05:34,020 --> 00:05:37,080
discrete explicit planning oriented

107
00:05:37,080 --> 00:05:39,840
cognitive models

108
00:05:39,840 --> 00:05:44,460
as uh Collective models I guess

109
00:05:44,460 --> 00:05:46,380
so it's funny that so there's that's one

110
00:05:46,380 --> 00:05:47,400
return

111
00:05:47,400 --> 00:05:50,100
from the uh

112
00:05:50,100 --> 00:05:53,280
earliest early 2000s continuous time

113
00:05:53,280 --> 00:05:55,620
then the focused move to discrete time

114
00:05:55,620 --> 00:05:58,199
and then there's the Hybrid models

115
00:05:58,199 --> 00:06:01,139
and then as you pointed to it even goes

116
00:06:01,139 --> 00:06:04,500
deeper because

117
00:06:04,500 --> 00:06:05,340
um

118
00:06:05,340 --> 00:06:08,639
the discrete time formalism is perfectly

119
00:06:08,639 --> 00:06:11,220
suited for the first two phases of

120
00:06:11,220 --> 00:06:13,320
Bayesian mechanics

121
00:06:13,320 --> 00:06:15,780
which and the non-equilibrium steady

122
00:06:15,780 --> 00:06:17,280
state and the state space

123
00:06:17,280 --> 00:06:19,080
representations

124
00:06:19,080 --> 00:06:22,560
whereas for the truly path tracking

125
00:06:22,560 --> 00:06:25,860
Bayesian mechanics and probably G Theory

126
00:06:25,860 --> 00:06:28,380
chaos and all of this

127
00:06:28,380 --> 00:06:32,100
continuous time is like

128
00:06:32,100 --> 00:06:36,180
your starter position

129
00:06:36,180 --> 00:06:37,800
before

130
00:06:37,800 --> 00:06:43,020
it even goes further afield into gauge

131
00:06:43,020 --> 00:06:46,319
and the fibers and sheaths

132
00:06:46,319 --> 00:06:48,419
and all of these other

133
00:06:48,419 --> 00:06:51,060
formalisms

134
00:06:51,060 --> 00:06:54,720
so it's almost like there's a sequence

135
00:06:54,720 --> 00:06:57,180
because the discrete time and the matrix

136
00:06:57,180 --> 00:06:59,100
multiplication

137
00:06:59,100 --> 00:07:03,060
are very straightforward

138
00:07:03,479 --> 00:07:06,360
then when we look at figure 4.3 and

139
00:07:06,360 --> 00:07:08,340
figure 8.6 we kind of see some

140
00:07:08,340 --> 00:07:10,500
similarities between continuous and

141
00:07:10,500 --> 00:07:12,479
discrete time

142
00:07:12,479 --> 00:07:15,240
and then from The Continuous time we can

143
00:07:15,240 --> 00:07:18,900
take another jump into the gauge

144
00:07:18,900 --> 00:07:20,819
setting

145
00:07:20,819 --> 00:07:25,280
which does seem to be the the

146
00:07:25,380 --> 00:07:27,960
at least in principle

147
00:07:27,960 --> 00:07:31,560
the most modern representations we have

148
00:07:31,560 --> 00:07:35,479
of Bayesian mechanics Michael

149
00:07:36,419 --> 00:07:42,419
yeah and in figure 8.6 we have in the

150
00:07:42,419 --> 00:07:45,900
top the discrete time and embedded

151
00:07:45,900 --> 00:07:48,660
The Continuous time I was wondering

152
00:07:48,660 --> 00:07:51,660
whether this can also be reversed

153
00:07:51,660 --> 00:07:54,720
we have in the top continuous time and

154
00:07:54,720 --> 00:07:57,419
then inside there we have sequences of

155
00:07:57,419 --> 00:07:59,220
discrete time

156
00:07:59,220 --> 00:08:01,919
so for instance if you

157
00:08:01,919 --> 00:08:05,759
I mean we have a Statistics over how

158
00:08:05,759 --> 00:08:07,759
long a certain

159
00:08:07,759 --> 00:08:10,979
activity lasts and that can be broken

160
00:08:10,979 --> 00:08:13,380
down into a sequence of several other

161
00:08:13,380 --> 00:08:15,780
activities

162
00:08:15,780 --> 00:08:17,479
um

163
00:08:17,479 --> 00:08:20,520
could that be modeled in this way that

164
00:08:20,520 --> 00:08:23,120
so for instance for this overall

165
00:08:23,120 --> 00:08:26,759
activity we have we know that it takes I

166
00:08:26,759 --> 00:08:29,340
don't know two minutes or 20 seconds or

167
00:08:29,340 --> 00:08:32,599
so and then the next

168
00:08:32,599 --> 00:08:36,059
action comes and each is broken down

169
00:08:36,059 --> 00:08:39,599
into several smaller steps

170
00:08:39,599 --> 00:08:43,799
that can be that are discrete

171
00:08:43,799 --> 00:08:45,420
uh

172
00:08:45,420 --> 00:08:48,060
can that be viewed in this way and then

173
00:08:48,060 --> 00:08:50,760
how for instance if we have

174
00:08:50,760 --> 00:08:53,880
a constraint over a time for instance

175
00:08:53,880 --> 00:08:56,279
there we have this uh what is this Tau

176
00:08:56,279 --> 00:08:59,459
one this first state which could be

177
00:08:59,459 --> 00:09:03,360
maybe uh yeah if this if this was if one

178
00:09:03,360 --> 00:09:06,360
of those States was was constrained by a

179
00:09:06,360 --> 00:09:08,880
time and then this constraint would be

180
00:09:08,880 --> 00:09:13,080
somehow handed down to the embedded

181
00:09:13,080 --> 00:09:15,420
processes which Each of which could not

182
00:09:15,420 --> 00:09:17,820
take longer

183
00:09:17,820 --> 00:09:21,240
um then the constraint in the state

184
00:09:21,240 --> 00:09:22,740
above

185
00:09:22,740 --> 00:09:25,860
yeah very interesting I've never

186
00:09:25,860 --> 00:09:30,600
seen that such architecture

187
00:09:30,600 --> 00:09:32,100
but

188
00:09:32,100 --> 00:09:34,740
it's uh in principle possible it's very

189
00:09:34,740 --> 00:09:37,440
interesting and this kind of notion of

190
00:09:37,440 --> 00:09:42,300
uh scheduling attentional scheduling

191
00:09:42,300 --> 00:09:45,979
and time constraints

192
00:09:46,080 --> 00:09:49,260
one way it might or kind of setting

193
00:09:49,260 --> 00:09:50,940
where it could apply is this is again

194
00:09:50,940 --> 00:09:52,680
brought up in the folk psychology paper

195
00:09:52,680 --> 00:09:56,220
because the continuous time lower level

196
00:09:56,220 --> 00:10:01,560
model Maps well to our uh proprioception

197
00:10:01,560 --> 00:10:05,160
and muscular action and then this uh

198
00:10:05,160 --> 00:10:07,339
discrete time model Maps well to

199
00:10:07,339 --> 00:10:10,920
sequential explicit planning

200
00:10:10,920 --> 00:10:13,740
so let's imagine it was inverted

201
00:10:13,740 --> 00:10:16,620
the lower level model might be a

202
00:10:16,620 --> 00:10:19,800
computer doing a dispatch

203
00:10:19,800 --> 00:10:22,200
in discrete time

204
00:10:22,200 --> 00:10:24,540
and the higher level is like the human

205
00:10:24,540 --> 00:10:26,820
operator

206
00:10:26,820 --> 00:10:28,680
and then they might also have another

207
00:10:28,680 --> 00:10:31,440
discrete above them

208
00:10:31,440 --> 00:10:35,899
so no need to stop at just two layers

209
00:10:36,720 --> 00:10:39,120
I think it's very uh that's the exciting

210
00:10:39,120 --> 00:10:42,120
Direction in question is to to build

211
00:10:42,120 --> 00:10:45,180
these towers of nested models

212
00:10:45,180 --> 00:10:48,360
and then lateral connections

213
00:10:48,360 --> 00:10:50,700
for Collective Behavior

214
00:10:50,700 --> 00:10:52,380
to

215
00:10:52,380 --> 00:10:55,920
describe and specify the ecosystems of

216
00:10:55,920 --> 00:10:58,320
shared intelligence so we can understand

217
00:10:58,320 --> 00:11:00,420
how different

218
00:11:00,420 --> 00:11:03,899
uh causal and cognitive phenomena

219
00:11:03,899 --> 00:11:07,019
arise from interactions within and

220
00:11:07,019 --> 00:11:10,459
across generative models

221
00:11:12,060 --> 00:11:13,260
yeah

222
00:11:13,260 --> 00:11:16,140
and and would there be a how could that

223
00:11:16,140 --> 00:11:18,240
be modeled if if we have a temporal

224
00:11:18,240 --> 00:11:21,240
constrained further down in the embedded

225
00:11:21,240 --> 00:11:24,899
processes which are formulated by the

226
00:11:24,899 --> 00:11:26,100
above

227
00:11:26,100 --> 00:11:31,120
uh boxes or States uh it's their way to

228
00:11:31,120 --> 00:11:32,459
[Music]

229
00:11:32,459 --> 00:11:35,279
to notify the embedded processes that

230
00:11:35,279 --> 00:11:37,440
they should stop eventually or something

231
00:11:37,440 --> 00:11:39,980
like this

232
00:11:41,279 --> 00:11:44,339
yeah it's uh

233
00:11:44,339 --> 00:11:46,860
I mean otherwise how is this message

234
00:11:46,860 --> 00:11:49,019
passed through through the only

235
00:11:49,019 --> 00:11:50,940
connection is there are these matrices

236
00:11:50,940 --> 00:11:53,760
which is the a matrix right

237
00:11:53,760 --> 00:11:57,480
and this a matrix what they need to

238
00:11:57,480 --> 00:12:00,959
determine somehow

239
00:12:00,959 --> 00:12:04,320
that the embedded processes follow those

240
00:12:04,320 --> 00:12:06,440
constraints

241
00:12:06,440 --> 00:12:11,000
yeah yes so let's let's look at that so

242
00:12:11,000 --> 00:12:14,220
uh the a matrix is the tale of two

243
00:12:14,220 --> 00:12:15,360
densities

244
00:12:15,360 --> 00:12:17,220
so it can be used as a recognition

245
00:12:17,220 --> 00:12:20,279
density from the observations or a

246
00:12:20,279 --> 00:12:21,899
generative density to generate

247
00:12:21,899 --> 00:12:23,399
observations from hidden States just

248
00:12:23,399 --> 00:12:24,959
looking at the top

249
00:12:24,959 --> 00:12:26,640
the o

250
00:12:26,640 --> 00:12:33,199
is a Markov blanket between s and V

251
00:12:33,240 --> 00:12:35,160
again Mark all blankets they don't have

252
00:12:35,160 --> 00:12:37,860
anything to do a priori with the Asian

253
00:12:37,860 --> 00:12:39,660
environment boundary

254
00:12:39,660 --> 00:12:41,880
though we can identify and construct

255
00:12:41,880 --> 00:12:44,100
Markov blankets associated with agent

256
00:12:44,100 --> 00:12:45,480
boundaries

257
00:12:45,480 --> 00:12:47,459
this is just using Markov blanket to

258
00:12:47,459 --> 00:12:50,160
mean the node or nodes

259
00:12:50,160 --> 00:12:52,740
upon which two other sets of states are

260
00:12:52,740 --> 00:12:54,779
conditionally independent

261
00:12:54,779 --> 00:12:58,560
so the O is like the interface

262
00:12:58,560 --> 00:13:01,279
it's handy it's a generative density

263
00:13:01,279 --> 00:13:03,180
speaking with respect to the higher

264
00:13:03,180 --> 00:13:06,240
model it's a generative density passing

265
00:13:06,240 --> 00:13:08,279
observations down

266
00:13:08,279 --> 00:13:13,860
to V the slowly varying causes which

267
00:13:13,860 --> 00:13:16,079
modify how the derivatives are

268
00:13:16,079 --> 00:13:18,300
constructed in continuous time so this

269
00:13:18,300 --> 00:13:20,220
is kind of like a modifier on the Taylor

270
00:13:20,220 --> 00:13:21,779
series expansion

271
00:13:21,779 --> 00:13:23,160
and then

272
00:13:23,160 --> 00:13:26,820
it is also um coming back up thinking

273
00:13:26,820 --> 00:13:29,279
about this in a predictive processing

274
00:13:29,279 --> 00:13:31,260
um like bi-directional

275
00:13:31,260 --> 00:13:32,639
way

276
00:13:32,639 --> 00:13:35,160
also it's changes in the continuous time

277
00:13:35,160 --> 00:13:38,160
setting lower level nested model that

278
00:13:38,160 --> 00:13:41,760
percolate up and modify

279
00:13:41,760 --> 00:13:44,760
in a perceptual like way

280
00:13:44,760 --> 00:13:47,940
higher level States so then you ask how

281
00:13:47,940 --> 00:13:51,180
could constraints be modeled

282
00:13:51,180 --> 00:13:53,899
there certainly could be a lot of like

283
00:13:53,899 --> 00:13:57,480
engineering type Solutions

284
00:13:57,480 --> 00:14:00,980
like just sort of uh for loops and

285
00:14:00,980 --> 00:14:04,399
virtualization emulation

286
00:14:04,399 --> 00:14:06,240
parallelization distributed

287
00:14:06,240 --> 00:14:08,880
computational processes dispatch

288
00:14:08,880 --> 00:14:11,339
architectures a lot of different things

289
00:14:11,339 --> 00:14:13,139
like aren't

290
00:14:13,139 --> 00:14:16,920
clean base graph only just in practice

291
00:14:16,920 --> 00:14:18,480
you would end up implementing some of

292
00:14:18,480 --> 00:14:20,220
these strategies

293
00:14:20,220 --> 00:14:22,019
um but but like it's interesting to

294
00:14:22,019 --> 00:14:24,180
think about well how could we really in

295
00:14:24,180 --> 00:14:26,339
a principled way include time

296
00:14:26,339 --> 00:14:28,139
constraints

297
00:14:28,139 --> 00:14:29,760
and then

298
00:14:29,760 --> 00:14:30,779
um

299
00:14:30,779 --> 00:14:33,600
when the top level is discrete how how

300
00:14:33,600 --> 00:14:36,660
would time constraints be achieved

301
00:14:36,660 --> 00:14:38,100
and then when the top level is

302
00:14:38,100 --> 00:14:40,980
continuous like you're asking about how

303
00:14:40,980 --> 00:14:44,480
would time constraints be achieved

304
00:14:44,760 --> 00:14:46,019
so

305
00:14:46,019 --> 00:14:47,519
either way it's kind of like there's

306
00:14:47,519 --> 00:14:49,079
like a window like let's just say this

307
00:14:49,079 --> 00:14:51,120
is the real time

308
00:14:51,120 --> 00:14:53,399
well okay here here's one more Dimension

309
00:14:53,399 --> 00:14:55,740
whether or not the top or the bottom is

310
00:14:55,740 --> 00:14:57,300
continuous or discrete so this could be

311
00:14:57,300 --> 00:14:58,800
discrete discrete or continuous

312
00:14:58,800 --> 00:15:02,300
continuous or any combination

313
00:15:02,579 --> 00:15:03,540
um

314
00:15:03,540 --> 00:15:08,880
one frame is real time is happening on

315
00:15:08,880 --> 00:15:10,139
the top

316
00:15:10,139 --> 00:15:12,180
and so this is like what we've seen in

317
00:15:12,180 --> 00:15:14,579
sophisticated inference sophisticated

318
00:15:14,579 --> 00:15:16,920
affective inference here's real time

319
00:15:16,920 --> 00:15:19,079
this is the real simulation time

320
00:15:19,079 --> 00:15:23,339
1201 1202 1203 and at each time point in

321
00:15:23,339 --> 00:15:24,600
the real time

322
00:15:24,600 --> 00:15:26,160
there's this

323
00:15:26,160 --> 00:15:26,699
um

324
00:15:26,699 --> 00:15:28,620
speculation of the past present and

325
00:15:28,620 --> 00:15:30,800
future

326
00:15:31,279 --> 00:15:35,579
or this can be the real-time model

327
00:15:35,579 --> 00:15:37,860
in the lower model

328
00:15:37,860 --> 00:15:40,500
and the higher order can be a

329
00:15:40,500 --> 00:15:43,579
speculative planning

330
00:15:44,399 --> 00:15:46,800
or a combination where there's a

331
00:15:46,800 --> 00:15:48,360
real-time layer

332
00:15:48,360 --> 00:15:51,500
that has both a faster

333
00:15:51,500 --> 00:15:55,459
speculative exploitation

334
00:15:55,500 --> 00:15:57,600
layer

335
00:15:57,600 --> 00:16:01,019
as well as a slower nested planning

336
00:16:01,019 --> 00:16:04,339
layer above real time

337
00:16:05,220 --> 00:16:07,320
I think there's many

338
00:16:07,320 --> 00:16:10,260
disparate

339
00:16:10,260 --> 00:16:12,360
once we're in the space of nested

340
00:16:12,360 --> 00:16:14,339
architectures

341
00:16:14,339 --> 00:16:18,720
to capture complex cognitive phenomena

342
00:16:18,720 --> 00:16:22,260
it's a really open space

343
00:16:22,260 --> 00:16:23,880
which is why it's so important to have

344
00:16:23,880 --> 00:16:25,740
the structured learning and the

345
00:16:25,740 --> 00:16:28,800
statistical power testing and the

346
00:16:28,800 --> 00:16:30,839
ability to describe and understand the

347
00:16:30,839 --> 00:16:33,420
semantics of these models

348
00:16:33,420 --> 00:16:35,279
because I think that they're going to

349
00:16:35,279 --> 00:16:37,860
get out of control visually

350
00:16:37,860 --> 00:16:40,759
very quickly

351
00:16:42,060 --> 00:16:44,759
but but you're you're saying that

352
00:16:44,759 --> 00:16:47,639
there's not only information going from

353
00:16:47,639 --> 00:16:50,279
top to bottom but also the other way

354
00:16:50,279 --> 00:16:52,440
around so the under the embedded

355
00:16:52,440 --> 00:16:55,740
processes can inform the upper ones

356
00:16:55,740 --> 00:16:58,259
about some outcomes

357
00:16:58,259 --> 00:17:00,720
well yeah in principle so like just like

358
00:17:00,720 --> 00:17:03,959
oh just only looking at the top layer o

359
00:17:03,959 --> 00:17:07,260
via a could update s

360
00:17:07,260 --> 00:17:10,919
or S via a could produce o

361
00:17:10,919 --> 00:17:13,740
that's the Tail of Two density so

362
00:17:13,740 --> 00:17:16,579
um the base graph

363
00:17:16,579 --> 00:17:19,859
depending on which parameters are

364
00:17:19,859 --> 00:17:22,140
established as fixed

365
00:17:22,140 --> 00:17:24,119
and which ones are established as

366
00:17:24,119 --> 00:17:25,619
learnable

367
00:17:25,619 --> 00:17:27,900
and so on

368
00:17:27,900 --> 00:17:31,080
then yes

369
00:17:31,080 --> 00:17:35,100
if you allow us to be learnable

370
00:17:35,100 --> 00:17:37,200
then it will learn

371
00:17:37,200 --> 00:17:39,360
so that it's unsurprised about the

372
00:17:39,360 --> 00:17:43,380
incoming observations of

373
00:17:43,380 --> 00:17:45,720
slowly varying causes

374
00:17:45,720 --> 00:17:49,679
whereas if you fix s and you only allow

375
00:17:49,679 --> 00:17:52,559
V to be learnable then

376
00:17:52,559 --> 00:17:55,160
etc etc

377
00:17:57,539 --> 00:17:59,400
and that's like the kind of information

378
00:17:59,400 --> 00:18:01,500
that's actually not shown on this graph

379
00:18:01,500 --> 00:18:02,880
other than this line which we know is

380
00:18:02,880 --> 00:18:05,760
missing but like as um

381
00:18:05,760 --> 00:18:08,700
Toby Sinclair Smith's dissertation on

382
00:18:08,700 --> 00:18:11,700
category theory has been

383
00:18:11,700 --> 00:18:15,120
kind of sharing and motivating

384
00:18:15,120 --> 00:18:17,940
there's actually information that's not

385
00:18:17,940 --> 00:18:20,700
this is not necessary and sufficient to

386
00:18:20,700 --> 00:18:22,620
replicate a full model

387
00:18:22,620 --> 00:18:24,240
especially if you're going to start

388
00:18:24,240 --> 00:18:26,580
talking about learning and all these

389
00:18:26,580 --> 00:18:29,240
other features

390
00:18:29,299 --> 00:18:32,299
this is like a um

391
00:18:32,299 --> 00:18:35,240
it's a

392
00:18:35,240 --> 00:18:36,799
quasi-formal

393
00:18:36,799 --> 00:18:40,799
diagrammatic mnemonic

394
00:18:41,700 --> 00:18:45,360
but not quite the necessary and complete

395
00:18:45,360 --> 00:18:48,020
representation

396
00:18:51,660 --> 00:18:55,020
but it's a super strong motivator

397
00:18:55,020 --> 00:18:57,480
and helps us think about like you're a

398
00:18:57,480 --> 00:18:59,160
great question about you know

399
00:18:59,160 --> 00:19:01,799
continuous time on top and we should

400
00:19:01,799 --> 00:19:05,059
definitely look into that and see if

401
00:19:05,280 --> 00:19:07,919
those models have been used I think part

402
00:19:07,919 --> 00:19:10,320
of it is people have just

403
00:19:10,320 --> 00:19:11,160
um

404
00:19:11,160 --> 00:19:13,799
seen a natural affinity

405
00:19:13,799 --> 00:19:16,760
for continuous time models

406
00:19:16,760 --> 00:19:21,240
and bodily perception bodily action

407
00:19:21,240 --> 00:19:24,840
discrete time models explicit planning

408
00:19:24,840 --> 00:19:28,620
so not just common commonly held

409
00:19:28,620 --> 00:19:31,020
perspectives so then in that situation

410
00:19:31,020 --> 00:19:34,280
it's natural to do it like this

411
00:19:35,400 --> 00:19:38,780
but doesn't mean it can't be otherwise

412
00:19:39,240 --> 00:19:41,720
okay

413
00:19:45,120 --> 00:19:46,679
I'm not sure if these thumbs up were

414
00:19:46,679 --> 00:19:49,679
from our own time last

415
00:19:49,679 --> 00:19:51,740
um

416
00:19:55,460 --> 00:19:58,559
okay this was I think from a from Office

417
00:19:58,559 --> 00:20:00,860
hours

418
00:20:02,880 --> 00:20:04,559
we talked about figure eight point five

419
00:20:04,559 --> 00:20:06,059
point two

420
00:20:06,059 --> 00:20:07,740
predictive coding

421
00:20:07,740 --> 00:20:10,559
message passing

422
00:20:10,559 --> 00:20:14,059
and 8.4

423
00:20:14,640 --> 00:20:17,059
okay

424
00:20:18,480 --> 00:20:22,260
generalized synchrony chaotic systems

425
00:20:22,260 --> 00:20:24,120
can we

426
00:20:24,120 --> 00:20:25,260
um

427
00:20:25,260 --> 00:20:27,720
model that with these

428
00:20:27,720 --> 00:20:31,460
predictive coding architectures

429
00:20:31,620 --> 00:20:33,900
the answer is yes we can it just depends

430
00:20:33,900 --> 00:20:36,860
on how you specify it

431
00:20:37,440 --> 00:20:38,220
um

432
00:20:38,220 --> 00:20:41,100
but that's not to say all Lorenz coupled

433
00:20:41,100 --> 00:20:42,900
Lorenz attractors

434
00:20:42,900 --> 00:20:44,520
are using a predictive processing

435
00:20:44,520 --> 00:20:46,200
architecture nor that predictive

436
00:20:46,200 --> 00:20:48,480
processing architectures acip Lorenz

437
00:20:48,480 --> 00:20:50,039
attract their behavior but just you

438
00:20:50,039 --> 00:20:51,720
could make a system

439
00:20:51,720 --> 00:20:54,539
that happens to have both of those

440
00:20:54,539 --> 00:20:57,379
features

441
00:21:04,640 --> 00:21:09,780
this is another difference between

442
00:21:10,679 --> 00:21:12,679
um

443
00:21:12,720 --> 00:21:15,840
The Continuous and the discrete time

444
00:21:15,840 --> 00:21:19,580
that I don't think we've emphasized

445
00:21:28,880 --> 00:21:33,980
action is absent from equation 8.1

446
00:21:34,620 --> 00:21:36,900
this is because

447
00:21:36,900 --> 00:21:39,059
action is part of the generative process

448
00:21:39,059 --> 00:21:42,260
not the generative model

449
00:21:44,940 --> 00:21:47,299
okay

450
00:21:49,799 --> 00:21:51,720
degenerative model only deals with those

451
00:21:51,720 --> 00:21:53,760
variables directly influenced by States

452
00:21:53,760 --> 00:21:57,620
external to a markout blanket

453
00:21:58,559 --> 00:22:02,480
but those are only the sense States

454
00:22:06,840 --> 00:22:09,419
and other and external states which

455
00:22:09,419 --> 00:22:11,280
directly influence themselves through

456
00:22:11,280 --> 00:22:13,980
latent causes

457
00:22:13,980 --> 00:22:16,020
but doesn't the generative model also

458
00:22:16,020 --> 00:22:20,000
include cognitive and internal States

459
00:22:22,320 --> 00:22:24,179
so one could argue that the the

460
00:22:24,179 --> 00:22:26,520
realization of action or the selection

461
00:22:26,520 --> 00:22:28,260
of action

462
00:22:28,260 --> 00:22:32,120
is part of the generative process

463
00:22:33,240 --> 00:22:36,179
but can't we say that the generative

464
00:22:36,179 --> 00:22:40,280
model includes planning as inference

465
00:22:42,539 --> 00:22:45,320
is this

466
00:22:45,539 --> 00:22:50,059
only in the case of the continuous time

467
00:23:07,080 --> 00:23:08,820
I'm not sure if this is like a general

468
00:23:08,820 --> 00:23:11,400
point or if this is just referring a

469
00:23:11,400 --> 00:23:13,559
little bit to the different way that

470
00:23:13,559 --> 00:23:16,140
action is modeled in the continuous time

471
00:23:16,140 --> 00:23:17,840
setting

472
00:23:17,840 --> 00:23:22,320
whereas action in the discrete setting

473
00:23:22,320 --> 00:23:25,440
is modeled in this standard policy

474
00:23:25,440 --> 00:23:27,780
selection

475
00:23:27,780 --> 00:23:29,880
way

476
00:23:29,880 --> 00:23:35,039
V are actually like not as much

477
00:23:35,039 --> 00:23:38,400
even described as policies that can be

478
00:23:38,400 --> 00:23:40,200
selected because it doesn't make as much

479
00:23:40,200 --> 00:23:44,280
sense to talk about counterfactuals on V

480
00:23:44,280 --> 00:23:47,039
they're described as just slowly varying

481
00:23:47,039 --> 00:23:51,440
causes in the generative process

482
00:23:54,360 --> 00:23:57,360
basically contingencies or dependencies

483
00:23:57,360 --> 00:23:59,580
upon which

484
00:23:59,580 --> 00:24:02,340
the Taylor series approximation

485
00:24:02,340 --> 00:24:05,899
is impinged on by

486
00:24:07,140 --> 00:24:09,600
that's like a very oblique way of

487
00:24:09,600 --> 00:24:13,380
talking about the consequences of action

488
00:24:13,380 --> 00:24:17,460
it's almost like an a differential

489
00:24:17,460 --> 00:24:22,039
angle on action Michael

490
00:24:22,919 --> 00:24:25,980
yeah so I'm I'm wondering whether this

491
00:24:25,980 --> 00:24:28,500
Taylor series decomposition this

492
00:24:28,500 --> 00:24:30,360
different different derivations that you

493
00:24:30,360 --> 00:24:33,919
have there whether this is only one view

494
00:24:33,919 --> 00:24:37,620
on uh on continuous time series or

495
00:24:37,620 --> 00:24:41,900
whether there is also other views

496
00:24:41,900 --> 00:24:45,240
that do not imply

497
00:24:45,240 --> 00:24:47,840
a derivation of

498
00:24:47,840 --> 00:24:50,940
decomposition of one function into

499
00:24:50,940 --> 00:24:53,940
several derivations I'm not sure when I

500
00:24:53,940 --> 00:24:56,840
understand this correctly

501
00:24:56,840 --> 00:24:59,520
but um

502
00:24:59,520 --> 00:25:01,679
but couldn't it be that

503
00:25:01,679 --> 00:25:05,280
um that time constraints

504
00:25:05,280 --> 00:25:07,740
are related

505
00:25:07,740 --> 00:25:11,299
without derivations

506
00:25:12,179 --> 00:25:14,580
I'm just wondering whether yeah one way

507
00:25:14,580 --> 00:25:17,880
of seeing it are is it

508
00:25:17,880 --> 00:25:20,640
the only one

509
00:25:20,640 --> 00:25:22,260
yeah good question

510
00:25:22,260 --> 00:25:24,779
um yeah it's not exactly a Taylor series

511
00:25:24,779 --> 00:25:29,279
I think it it's though it's it's it has

512
00:25:29,279 --> 00:25:31,919
Taylor series like nature because it is

513
00:25:31,919 --> 00:25:33,900
dealing with successive derivative

514
00:25:33,900 --> 00:25:35,460
approximations with their own

515
00:25:35,460 --> 00:25:36,720
coefficients

516
00:25:36,720 --> 00:25:39,360
but I think the more physics framing is

517
00:25:39,360 --> 00:25:41,400
the generalized coordinates

518
00:25:41,400 --> 00:25:43,559
so position

519
00:25:43,559 --> 00:25:47,159
um momentum acceleration jerk

520
00:25:47,159 --> 00:25:49,020
Etc

521
00:25:49,020 --> 00:25:52,440
is there a way to talk about

522
00:25:52,440 --> 00:25:54,360
time constraints and multiple time

523
00:25:54,360 --> 00:25:56,279
scales

524
00:25:56,279 --> 00:25:59,900
in continuous time

525
00:26:01,020 --> 00:26:06,080
other than by taking derivatives

526
00:26:09,480 --> 00:26:11,100
I mean we can definitely explore it but

527
00:26:11,100 --> 00:26:12,360
like the first thought that comes to

528
00:26:12,360 --> 00:26:13,559
mind is

529
00:26:13,559 --> 00:26:15,779
when faced with a field of continuous

530
00:26:15,779 --> 00:26:17,340
time

531
00:26:17,340 --> 00:26:20,039
two approaches that are taken one of

532
00:26:20,039 --> 00:26:22,980
them is to discretize time

533
00:26:22,980 --> 00:26:24,779
at which point you'd be using a discrete

534
00:26:24,779 --> 00:26:26,100
type model

535
00:26:26,100 --> 00:26:28,020
and if you're not going to discretize

536
00:26:28,020 --> 00:26:30,120
time you're going to leave it as a

537
00:26:30,120 --> 00:26:32,039
smooth continuum

538
00:26:32,039 --> 00:26:35,700
then a general approach is to utilize

539
00:26:35,700 --> 00:26:38,700
physics-based

540
00:26:39,360 --> 00:26:43,639
generalized coordinates of motion Ali

541
00:26:45,299 --> 00:26:48,080
uh well yeah actually Michael

542
00:26:48,080 --> 00:26:51,440
Silverstein and William Starkey

543
00:26:51,440 --> 00:26:56,659
has been arguing for another approach to

544
00:26:56,659 --> 00:26:58,220
formalize

545
00:26:58,220 --> 00:27:01,400
cognition time

546
00:27:01,400 --> 00:27:06,299
and other so-called dynamical aspects of

547
00:27:06,299 --> 00:27:10,039
a system using a dynamical

548
00:27:10,039 --> 00:27:12,659
mathematics so for instance in their

549
00:27:12,659 --> 00:27:14,460
paper rethinking the world with neutral

550
00:27:14,460 --> 00:27:15,740
monosome

551
00:27:15,740 --> 00:27:18,059
removing the boundaries between mind

552
00:27:18,059 --> 00:27:20,419
matter and space-time

553
00:27:20,419 --> 00:27:22,980
they have proposed an alternative

554
00:27:22,980 --> 00:27:24,840
approach

555
00:27:24,840 --> 00:27:29,340
uh which is uh somehow uh which is

556
00:27:29,340 --> 00:27:34,260
expanded uh more I mean in detail in

557
00:27:34,260 --> 00:27:36,179
their beyond the dynamical universe uh

558
00:27:36,179 --> 00:27:37,500
book but

559
00:27:37,500 --> 00:27:39,600
um in this case they

560
00:27:39,600 --> 00:27:44,220
um so very briefly they conceptualize a

561
00:27:44,220 --> 00:27:47,940
system as a kind of a stationary system

562
00:27:47,940 --> 00:27:52,080
that just moves from uh

563
00:27:52,080 --> 00:27:55,799
um sorry that just has the first initial

564
00:27:55,799 --> 00:27:58,260
position and the ending ultimate

565
00:27:58,260 --> 00:28:02,460
position and we can uh by um

566
00:28:02,460 --> 00:28:04,799
using this kind of a dynamical

567
00:28:04,799 --> 00:28:06,740
mathematics

568
00:28:06,740 --> 00:28:10,860
remove the time from the equation and

569
00:28:10,860 --> 00:28:12,840
just uh

570
00:28:12,840 --> 00:28:15,840
actually look at the system in a kind of

571
00:28:15,840 --> 00:28:19,799
a block Universe way without actually

572
00:28:19,799 --> 00:28:22,740
taking into consideration the flow of

573
00:28:22,740 --> 00:28:26,340
the system through time so yeah there is

574
00:28:26,340 --> 00:28:29,159
definitely other approaches to

575
00:28:29,159 --> 00:28:30,000
um

576
00:28:30,000 --> 00:28:32,640
model these kinds of system and even

577
00:28:32,640 --> 00:28:36,419
they argue in this paper and also in

578
00:28:36,419 --> 00:28:39,960
their book that this new approach can

579
00:28:39,960 --> 00:28:41,360
somehow

580
00:28:41,360 --> 00:28:44,240
overcome some of the long-standing

581
00:28:44,240 --> 00:28:46,820
issues in

582
00:28:46,820 --> 00:28:50,340
theoretical physics and or even in the

583
00:28:50,340 --> 00:28:53,159
philosophy of physics

584
00:28:53,159 --> 00:28:58,799
yep very um interesting this kind of

585
00:28:58,799 --> 00:29:00,120
um

586
00:29:00,120 --> 00:29:02,880
well writing out the the ontological

587
00:29:02,880 --> 00:29:04,799
reality of time in the world is

588
00:29:04,799 --> 00:29:06,779
definitely a complex topic so it's

589
00:29:06,779 --> 00:29:08,279
always good to know that with these

590
00:29:08,279 --> 00:29:09,659
discussions about time we're talking

591
00:29:09,659 --> 00:29:13,020
about map time about like how we want to

592
00:29:13,020 --> 00:29:15,059
uh model time

593
00:29:15,059 --> 00:29:17,159
and in that setting

594
00:29:17,159 --> 00:29:20,360
um both 8.1 and 8.2

595
00:29:20,360 --> 00:29:25,140
have a um Timeless data generating

596
00:29:25,140 --> 00:29:27,059
function

597
00:29:27,059 --> 00:29:30,360
why observations is simply a function of

598
00:29:30,360 --> 00:29:33,480
latent States on hidden States so you

599
00:29:33,480 --> 00:29:36,360
know why observational States is a

600
00:29:36,360 --> 00:29:40,100
function of latent States X plus some

601
00:29:40,100 --> 00:29:44,600
sensor variance why

602
00:29:44,760 --> 00:29:46,260
and then

603
00:29:46,260 --> 00:29:48,960
there's a field

604
00:29:48,960 --> 00:29:51,960
or space in which latent states have

605
00:29:51,960 --> 00:29:54,659
their own flow

606
00:29:54,659 --> 00:29:57,960
that is defined again without reference

607
00:29:57,960 --> 00:30:00,559
to time

608
00:30:00,659 --> 00:30:03,000
but as a um

609
00:30:03,000 --> 00:30:08,820
derivative fields in a hamiltonian sets

610
00:30:08,820 --> 00:30:12,000
so even if your Y data stream is an EEG

611
00:30:12,000 --> 00:30:16,200
or fmri time series data

612
00:30:16,200 --> 00:30:19,020
it's actually like

613
00:30:19,020 --> 00:30:22,020
where's the time

614
00:30:22,020 --> 00:30:25,580
oh where does the time go

615
00:30:29,399 --> 00:30:32,279
not seeing any T's in these continuous

616
00:30:32,279 --> 00:30:35,000
time models

617
00:30:35,279 --> 00:30:38,940
so it's almost like we

618
00:30:38,940 --> 00:30:41,820
lean so hard

619
00:30:41,820 --> 00:30:44,419
into the um

620
00:30:44,419 --> 00:30:47,840
continuity of time

621
00:30:48,779 --> 00:30:52,559
and continuity is is at least

622
00:30:52,559 --> 00:30:54,559
synonymous with or or

623
00:30:54,559 --> 00:30:57,480
adjacent to differentiable

624
00:30:57,480 --> 00:30:59,220
those two

625
00:30:59,220 --> 00:31:02,159
are they're not exactly exactly the same

626
00:31:02,159 --> 00:31:04,080
but

627
00:31:04,080 --> 00:31:05,580
we work with continuous functions

628
00:31:05,580 --> 00:31:06,720
because we want them to be

629
00:31:06,720 --> 00:31:08,399
differentiable

630
00:31:08,399 --> 00:31:10,200
we have to discretize them but the

631
00:31:10,200 --> 00:31:12,480
biggest issue with discrete functions

632
00:31:12,480 --> 00:31:16,159
is that they're non-differentiable

633
00:31:17,039 --> 00:31:19,640
Ollie

634
00:31:19,640 --> 00:31:23,460
yeah I think uh the more precise term

635
00:31:23,460 --> 00:31:28,159
for uh the mathematical condition for

636
00:31:28,159 --> 00:31:31,440
modeling these systems is that they need

637
00:31:31,440 --> 00:31:33,860
to be in weiner spaces

638
00:31:33,860 --> 00:31:37,679
so the wiener space is just a

639
00:31:37,679 --> 00:31:41,960
generalizes space that contains all the

640
00:31:41,960 --> 00:31:44,539
continuous and differentiable

641
00:31:44,539 --> 00:31:49,440
functions and also I just wanted to

642
00:31:49,440 --> 00:31:52,679
point it out that that's exactly the

643
00:31:52,679 --> 00:31:55,440
point or at least one of the points of

644
00:31:55,440 --> 00:31:59,720
using generalized coordinate systems in

645
00:31:59,720 --> 00:32:04,559
path integral formulation of fep uh by I

646
00:32:04,559 --> 00:32:08,279
mean by removing the time from

647
00:32:08,279 --> 00:32:09,919
the equations

648
00:32:09,919 --> 00:32:13,919
it is possible to talk about the

649
00:32:13,919 --> 00:32:16,260
behavior of the system purely in terms

650
00:32:16,260 --> 00:32:17,899
of their

651
00:32:17,899 --> 00:32:23,299
space their the space of possible paths

652
00:32:23,299 --> 00:32:26,760
instead of just looking at instead of

653
00:32:26,760 --> 00:32:31,940
just following the time developmental

654
00:32:31,940 --> 00:32:34,260
aspect of

655
00:32:34,260 --> 00:32:34,820
um

656
00:32:34,820 --> 00:32:39,240
of the particular States

657
00:32:39,240 --> 00:32:41,960
awesome

658
00:32:45,000 --> 00:32:48,600
yeah it's like

659
00:32:48,600 --> 00:32:51,360
uh the difference between uh

660
00:32:51,360 --> 00:32:54,179
putting a drop of of uh food coloring in

661
00:32:54,179 --> 00:32:57,659
the cloud and tracing that one path

662
00:32:57,659 --> 00:32:59,640
as it flows

663
00:32:59,640 --> 00:33:01,080
and then there's definitely there's this

664
00:33:01,080 --> 00:33:03,299
discussion oh should we model that one

665
00:33:03,299 --> 00:33:05,880
path of the Tracer

666
00:33:05,880 --> 00:33:09,840
as a path with continuous State space or

667
00:33:09,840 --> 00:33:11,940
should we discretize it

668
00:33:11,940 --> 00:33:14,779
and do a discrete time model of that one

669
00:33:14,779 --> 00:33:17,940
realized Trace

670
00:33:17,940 --> 00:33:21,840
or should we step back describe the

671
00:33:21,840 --> 00:33:24,720
topology of the mountain

672
00:33:24,720 --> 00:33:26,640
and then

673
00:33:26,640 --> 00:33:29,100
the realized Trace

674
00:33:29,100 --> 00:33:31,679
will be a path of least action on that

675
00:33:31,679 --> 00:33:33,480
landscape

676
00:33:33,480 --> 00:33:35,760
but we'll also be able to talk about

677
00:33:35,760 --> 00:33:38,279
counterfactuals

678
00:33:38,279 --> 00:33:40,380
and alternative starting conditions

679
00:33:40,380 --> 00:33:41,820
initial conditions and boundary

680
00:33:41,820 --> 00:33:43,320
conditions

681
00:33:43,320 --> 00:33:45,840
and um

682
00:33:45,840 --> 00:33:48,480
and and ask what if questions on the

683
00:33:48,480 --> 00:33:51,500
landscape whereas any descriptive

684
00:33:51,500 --> 00:33:55,080
historical model

685
00:33:55,080 --> 00:33:57,899
will not

686
00:33:57,899 --> 00:33:59,899
um

687
00:34:00,080 --> 00:34:02,340
natively or simply

688
00:34:02,340 --> 00:34:05,640
enable counterfactual comparisons if you

689
00:34:05,640 --> 00:34:07,620
just have the path descriptor

690
00:34:07,620 --> 00:34:10,679
in continuous time or in discrete time

691
00:34:10,679 --> 00:34:12,839
then you don't even know what the

692
00:34:12,839 --> 00:34:16,199
adjacent possibles are slash could have

693
00:34:16,199 --> 00:34:18,379
been

694
00:34:21,780 --> 00:34:23,940
Michael

695
00:34:23,940 --> 00:34:27,899
yeah I'm I'm not sure I understand uh

696
00:34:27,899 --> 00:34:30,899
this is is this possible because we

697
00:34:30,899 --> 00:34:34,520
assume that the the time

698
00:34:34,520 --> 00:34:38,520
goes in regular interval so if it's a

699
00:34:38,520 --> 00:34:42,300
regular interval we can just ignore it

700
00:34:42,300 --> 00:34:45,119
or what is the underlying

701
00:34:45,119 --> 00:34:49,440
idea to abstract away from time because

702
00:34:49,440 --> 00:34:51,659
time seems such a crucial kind of an

703
00:34:51,659 --> 00:34:53,099
element in

704
00:34:53,099 --> 00:34:56,960
all our daily lives right

705
00:34:58,080 --> 00:35:01,880
yeah Ali go for it

706
00:35:01,920 --> 00:35:04,500
uh well yeah it definitely is an

707
00:35:04,500 --> 00:35:08,400
essential component but uh I mean the

708
00:35:08,400 --> 00:35:11,820
point here is that you see so for

709
00:35:11,820 --> 00:35:14,640
instance uh In classical mechanics we

710
00:35:14,640 --> 00:35:17,640
have at least three different uh

711
00:35:17,640 --> 00:35:20,280
formulations one is the Newtonian

712
00:35:20,280 --> 00:35:22,619
mechanic formulations uh the other one

713
00:35:22,619 --> 00:35:27,619
is the lagrangian and also Auditorium

714
00:35:28,700 --> 00:35:33,060
formulation definitely needs uh time as

715
00:35:33,060 --> 00:35:36,960
an explicit variable and parameter but

716
00:35:36,960 --> 00:35:40,020
going uh from Newtonian formulation to

717
00:35:40,020 --> 00:35:41,940
lagrangian and Hamilton

718
00:35:41,940 --> 00:35:43,260
Ian

719
00:35:43,260 --> 00:35:45,000
especially in the hamiltonian

720
00:35:45,000 --> 00:35:50,339
formulation uh we can rearrange or or

721
00:35:50,339 --> 00:35:53,400
derive those formulations from the

722
00:35:53,400 --> 00:35:57,540
classical Newtonian formulation without

723
00:35:57,540 --> 00:36:01,560
um accounting for time as an explicit

724
00:36:01,560 --> 00:36:05,579
variable so time it actually implicit in

725
00:36:05,579 --> 00:36:08,520
those formulations so all three of those

726
00:36:08,520 --> 00:36:10,680
formulations are equivalent and they can

727
00:36:10,680 --> 00:36:12,780
be recovered from each other and they

728
00:36:12,780 --> 00:36:15,599
can be derived from each other but it's

729
00:36:15,599 --> 00:36:17,880
just a matter of which parameters are

730
00:36:17,880 --> 00:36:20,760
explicit and which are implicit so yeah

731
00:36:20,760 --> 00:36:22,099
we don't

732
00:36:22,099 --> 00:36:26,660
get rid of time

733
00:36:26,780 --> 00:36:31,380
entirely we just use time as as a kind

734
00:36:31,380 --> 00:36:34,380
of implicit parameter that doesn't need

735
00:36:34,380 --> 00:36:38,420
to be explicitly defined

736
00:36:39,480 --> 00:36:43,079
yeah very um just and also you said the

737
00:36:43,079 --> 00:36:44,880
Assumption time is in regular intervals

738
00:36:44,880 --> 00:36:47,579
but that's a discrete time model

739
00:36:47,579 --> 00:36:48,660
and that's the question of

740
00:36:48,660 --> 00:36:50,160
discretization of time which we're

741
00:36:50,160 --> 00:36:51,839
actually like exploring in live stream

742
00:36:51,839 --> 00:36:53,400
53

743
00:36:53,400 --> 00:36:55,140
which is again not the ontological

744
00:36:55,140 --> 00:36:58,440
reality of the time the time click of

745
00:36:58,440 --> 00:37:01,859
the world or whatever but in modeling

746
00:37:01,859 --> 00:37:04,460
spaces

747
00:37:04,680 --> 00:37:07,099
um how to retain

748
00:37:07,099 --> 00:37:10,680
the the elegance and the

749
00:37:10,680 --> 00:37:13,920
uh analytical advantages that continuous

750
00:37:13,920 --> 00:37:16,260
models provide

751
00:37:16,260 --> 00:37:18,240
in terms of generalized coordinates of

752
00:37:18,240 --> 00:37:19,560
motion

753
00:37:19,560 --> 00:37:22,200
um physics grounded energy-based

754
00:37:22,200 --> 00:37:23,880
learning

755
00:37:23,880 --> 00:37:27,540
uh convergence guarantees around free

756
00:37:27,540 --> 00:37:31,520
energy minimization those are all about

757
00:37:31,520 --> 00:37:34,980
continuous differentiable spaces which

758
00:37:34,980 --> 00:37:36,720
is why they're grounded in information

759
00:37:36,720 --> 00:37:40,500
geometry and functional analysis

760
00:37:40,500 --> 00:37:43,339
whereas discretization

761
00:37:43,339 --> 00:37:45,300
we want to make sure that the

762
00:37:45,300 --> 00:37:47,160
discretization techniques that are used

763
00:37:47,160 --> 00:37:50,099
don't

764
00:37:50,099 --> 00:37:51,599
um solely

765
00:37:51,599 --> 00:37:53,400
or

766
00:37:53,400 --> 00:37:55,920
um lose those properties of the

767
00:37:55,920 --> 00:37:59,660
underlying continuous distribution

768
00:38:03,900 --> 00:38:06,380
Michael

769
00:38:07,040 --> 00:38:12,359
yeah I'm I'm digesting this it's a bit

770
00:38:12,359 --> 00:38:15,260
so so so actually

771
00:38:15,260 --> 00:38:19,859
a derivation is takes the takes the role

772
00:38:19,859 --> 00:38:22,380
of time so it's only derivable because

773
00:38:22,380 --> 00:38:24,420
we assume there is some kind of a

774
00:38:24,420 --> 00:38:26,400
continuation or some kind of time

775
00:38:26,400 --> 00:38:30,540
underlying yeah like let's let's uh pull

776
00:38:30,540 --> 00:38:32,700
back to a description so if we wanted a

777
00:38:32,700 --> 00:38:35,640
time this description of a car

778
00:38:35,640 --> 00:38:37,740
we could describe its position at every

779
00:38:37,740 --> 00:38:40,380
time and so arguably one could say well

780
00:38:40,380 --> 00:38:42,000
that described like everything about

781
00:38:42,000 --> 00:38:44,099
that car's trajectory what you need to

782
00:38:44,099 --> 00:38:46,260
know is its position at every time

783
00:38:46,260 --> 00:38:48,660
all right well you could also use the

784
00:38:48,660 --> 00:38:50,760
generalized coordinates of motion

785
00:38:50,760 --> 00:38:53,579
and so for each time

786
00:38:53,579 --> 00:38:55,619
you could also have the car's position

787
00:38:55,619 --> 00:38:58,140
in X and Y but also you could have the

788
00:38:58,140 --> 00:39:01,560
car's acceleration and and and so on so

789
00:39:01,560 --> 00:39:03,119
those are the derivatives of the

790
00:39:03,119 --> 00:39:04,380
position

791
00:39:04,380 --> 00:39:08,880
and uh it's not like extra information

792
00:39:08,880 --> 00:39:11,040
like with the whole trajectory you could

793
00:39:11,040 --> 00:39:13,079
recalculate the generalized coordinates

794
00:39:13,079 --> 00:39:16,260
of motion from the position

795
00:39:16,260 --> 00:39:18,359
but you also might want your data

796
00:39:18,359 --> 00:39:22,140
structure to be that Vector at each time

797
00:39:22,140 --> 00:39:24,300
step with the generalized coordinates

798
00:39:24,300 --> 00:39:26,160
motion

799
00:39:26,160 --> 00:39:27,900
um so you know it's here and it's going

800
00:39:27,900 --> 00:39:29,700
50 kilometers an hour and it's slowing

801
00:39:29,700 --> 00:39:31,380
down by two kilometers per hour per

802
00:39:31,380 --> 00:39:33,900
second and its acceleration is changing

803
00:39:33,900 --> 00:39:35,540
by you know

804
00:39:35,540 --> 00:39:37,980
positive one kilometer per second

805
00:39:37,980 --> 00:39:39,119
squared

806
00:39:39,119 --> 00:39:40,920
and so on

807
00:39:40,920 --> 00:39:45,500
uh another angle would be to describe

808
00:39:45,500 --> 00:39:50,339
that um that space upon which there are

809
00:39:50,339 --> 00:39:52,980
trajectories of the generalized

810
00:39:52,980 --> 00:39:54,060
coordinates

811
00:39:54,060 --> 00:39:55,920
now there's some generalized coordinates

812
00:39:55,920 --> 00:39:58,680
locations that are just ridiculous like

813
00:39:58,680 --> 00:40:01,079
well it's not moving at all

814
00:40:01,079 --> 00:40:05,660
but its fourth derivative is super high

815
00:40:05,700 --> 00:40:08,220
well any state space can be used to

816
00:40:08,220 --> 00:40:10,200
describe certain points in that state

817
00:40:10,200 --> 00:40:11,760
space that aren't

818
00:40:11,760 --> 00:40:14,700
like feasible or

819
00:40:14,700 --> 00:40:15,780
um

820
00:40:15,780 --> 00:40:16,920
you know

821
00:40:16,920 --> 00:40:19,140
realizable by a different physical

822
00:40:19,140 --> 00:40:21,720
system obviously systems spend their

823
00:40:21,720 --> 00:40:23,220
time in in

824
00:40:23,220 --> 00:40:25,980
sometimes highly constrained subspaces

825
00:40:25,980 --> 00:40:27,359
manifolds

826
00:40:27,359 --> 00:40:30,780
of these bigger State spaces

827
00:40:30,780 --> 00:40:31,320
[Music]

828
00:40:31,320 --> 00:40:32,160
um

829
00:40:32,160 --> 00:40:34,500
but when you describe when you say okay

830
00:40:34,500 --> 00:40:36,599
well then let's make the

831
00:40:36,599 --> 00:40:40,200
um generalized coordinates of motion

832
00:40:40,200 --> 00:40:42,480
are fundamental State space so instead

833
00:40:42,480 --> 00:40:44,579
of x y z t

834
00:40:44,579 --> 00:40:47,760
as our fundamental State space

835
00:40:47,760 --> 00:40:49,500
and then that is and then we're going to

836
00:40:49,500 --> 00:40:52,500
derive all of our other questions from

837
00:40:52,500 --> 00:40:53,460
there

838
00:40:53,460 --> 00:40:55,320
it's like saying well let's have the

839
00:40:55,320 --> 00:40:56,820
generalized coordinates be our state

840
00:40:56,820 --> 00:40:58,320
space

841
00:40:58,320 --> 00:41:01,700
but then you don't need t

842
00:41:02,760 --> 00:41:05,579
of course real trajectories unfold in

843
00:41:05,579 --> 00:41:08,359
quote time

844
00:41:09,300 --> 00:41:11,820
pending future understandings of what

845
00:41:11,820 --> 00:41:13,680
time is

846
00:41:13,680 --> 00:41:17,460
but you don't need tea

847
00:41:17,460 --> 00:41:20,280
in the hamiltonian

848
00:41:20,280 --> 00:41:22,020
which again just to connect back to the

849
00:41:22,020 --> 00:41:23,700
textbook

850
00:41:23,700 --> 00:41:27,240
is that is what we're seeing in these

851
00:41:27,240 --> 00:41:29,460
representations

852
00:41:29,460 --> 00:41:31,800
that basically partitions signal from

853
00:41:31,800 --> 00:41:34,099
noise

854
00:41:34,740 --> 00:41:37,920
without explicit reference

855
00:41:37,920 --> 00:41:41,099
to T as a variable

856
00:41:41,099 --> 00:41:44,640
however amenable to fitting empirical

857
00:41:44,640 --> 00:41:47,900
time series data

858
00:41:52,680 --> 00:41:54,119
I don't think we resolved this question

859
00:41:54,119 --> 00:41:55,560
about like action being in the

860
00:41:55,560 --> 00:41:57,480
generative process what exactly is meant

861
00:41:57,480 --> 00:41:58,740
by that

862
00:41:58,740 --> 00:42:00,480
because action itself is part of the

863
00:42:00,480 --> 00:42:03,140
generative process

864
00:42:03,480 --> 00:42:05,640
we could say the consequences of action

865
00:42:05,640 --> 00:42:07,680
or the embodiment of

866
00:42:07,680 --> 00:42:09,359
but

867
00:42:09,359 --> 00:42:12,180
um is this claim about regenerative

868
00:42:12,180 --> 00:42:16,020
models in general or is this just saying

869
00:42:16,020 --> 00:42:19,520
something about continuous time

870
00:42:22,560 --> 00:42:25,578
okay precision

871
00:42:32,720 --> 00:42:36,300
in our office hours last week we had

872
00:42:36,300 --> 00:42:39,240
some good conversations about

873
00:42:39,240 --> 00:42:42,078
precision

874
00:42:42,480 --> 00:42:45,240
some on the more applied side with

875
00:42:45,240 --> 00:42:48,200
perception and pain some on the more

876
00:42:48,200 --> 00:42:52,380
conceptual side with the bird song

877
00:42:52,380 --> 00:42:54,900
and the sensory attenuation and the role

878
00:42:54,900 --> 00:42:58,400
of precision and action selection

879
00:42:59,880 --> 00:43:01,380
from the perspective active inference

880
00:43:01,380 --> 00:43:05,359
precision and attention are synonyms

881
00:43:05,520 --> 00:43:08,599
thank you

882
00:43:21,980 --> 00:43:25,500
here was the discussion from

883
00:43:25,500 --> 00:43:28,319
um the office hours

884
00:43:28,319 --> 00:43:32,819
so this is It's related to chapter eight

885
00:43:32,819 --> 00:43:35,099
so we were talking about

886
00:43:35,099 --> 00:43:37,200
um okay so in the examples first we have

887
00:43:37,200 --> 00:43:39,180
just general lock of Volterra winnerless

888
00:43:39,180 --> 00:43:41,660
competition

889
00:43:43,440 --> 00:43:47,520
um that is then deployed in a

890
00:43:47,520 --> 00:43:50,040
handwriting example

891
00:43:50,040 --> 00:43:52,619
showing how lockable terra-like models

892
00:43:52,619 --> 00:43:56,819
can account for sequential and reactive

893
00:43:56,819 --> 00:43:58,980
Behavior

894
00:43:58,980 --> 00:44:01,740
without explicit planning

895
00:44:01,740 --> 00:44:04,500
so in the discrete time it'd be like I'm

896
00:44:04,500 --> 00:44:06,660
here

897
00:44:06,660 --> 00:44:09,740
I'm likely to go

898
00:44:10,260 --> 00:44:14,099
whereas in the continuous time setting

899
00:44:14,099 --> 00:44:16,099
it's just like a dynamical attractor

900
00:44:16,099 --> 00:44:18,119
that doesn't have an explicit

901
00:44:18,119 --> 00:44:20,099
representation of where it's going to go

902
00:44:20,099 --> 00:44:22,319
in the attractor

903
00:44:22,319 --> 00:44:25,200
it's just flowing in the attractor

904
00:44:25,200 --> 00:44:28,020
and so then we describe the state space

905
00:44:28,020 --> 00:44:29,700
of the attractor

906
00:44:29,700 --> 00:44:32,299
Ali

907
00:44:33,300 --> 00:44:37,200
yeah uh you're just talking about the

908
00:44:37,200 --> 00:44:39,359
synonymous terms uh actually it's

909
00:44:39,359 --> 00:44:41,520
interesting that marks Holmes in his

910
00:44:41,520 --> 00:44:43,640
book The Hidden string spring spring

911
00:44:43,640 --> 00:44:47,220
also somehow uses the word the term

912
00:44:47,220 --> 00:44:52,260
Consciousness as a kind of synonym for

913
00:44:52,260 --> 00:44:56,520
the Precision optimization which is one

914
00:44:56,520 --> 00:44:58,980
of the Moines one of the points that

915
00:44:58,980 --> 00:45:03,720
Anil Seth is strongly critical of and he

916
00:45:03,720 --> 00:45:07,560
believes that we cannot simply Define uh

917
00:45:07,560 --> 00:45:10,500
Consciousness as a kind of precision

918
00:45:10,500 --> 00:45:11,780
optimization

919
00:45:11,780 --> 00:45:18,540
and so in one of their recent papers

920
00:45:18,540 --> 00:45:19,400
um

921
00:45:19,400 --> 00:45:21,599
I think it was called from General to

922
00:45:21,599 --> 00:45:24,119
models to generative passages a

923
00:45:24,119 --> 00:45:25,560
computational approach to neural

924
00:45:25,560 --> 00:45:29,460
phenomenology uh Kristen Seth and others

925
00:45:29,460 --> 00:45:32,880
Max ramstead at all

926
00:45:32,880 --> 00:45:35,640
actually uses

927
00:45:35,640 --> 00:45:39,920
a generative model as a computational

928
00:45:39,920 --> 00:45:45,240
basis for a phenomenological definition

929
00:45:45,240 --> 00:45:47,460
of Consciousness which deviates

930
00:45:47,460 --> 00:45:50,700
significantly from psalms's perception

931
00:45:50,700 --> 00:45:55,259
uh conception of consciousness

932
00:45:56,180 --> 00:45:59,160
Bob thank you yeah I haven't read this

933
00:45:59,160 --> 00:46:00,680
one in depth

934
00:46:00,680 --> 00:46:03,020
this day

935
00:46:03,020 --> 00:46:05,960
in in the blockference

936
00:46:05,960 --> 00:46:08,460
we uh

937
00:46:08,460 --> 00:46:10,260
so there was there was the original

938
00:46:10,260 --> 00:46:11,940
paper there was a guest stream with

939
00:46:11,940 --> 00:46:14,760
Brett Kagan and Adil razi on the dish

940
00:46:14,760 --> 00:46:16,020
brain

941
00:46:16,020 --> 00:46:19,040
and of course the uh the sentience

942
00:46:19,040 --> 00:46:22,740
fuhrer that arose

943
00:46:22,740 --> 00:46:24,839
leading to

944
00:46:24,839 --> 00:46:27,359
um multiple and apparently ongoing

945
00:46:27,359 --> 00:46:31,220
sequences of short letters

946
00:46:31,920 --> 00:46:33,960
there's a lot of interesting stuff in

947
00:46:33,960 --> 00:46:36,140
here

948
00:46:37,680 --> 00:46:40,920
the big contention is with the terms

949
00:46:40,920 --> 00:46:43,319
active ontology sentience goal direct

950
00:46:43,319 --> 00:46:45,240
Behavior embodiment uncertainty

951
00:46:45,240 --> 00:46:47,460
intelligence

952
00:46:47,460 --> 00:46:50,099
and their call

953
00:46:50,099 --> 00:46:51,720
is

954
00:46:51,720 --> 00:46:53,579
um

955
00:46:53,579 --> 00:46:56,720
for glossaries

956
00:47:01,260 --> 00:47:03,180
and then this paper

957
00:47:03,180 --> 00:47:05,899
also

958
00:47:07,260 --> 00:47:09,420
all right

959
00:47:09,420 --> 00:47:13,099
come develop the glossaries

960
00:47:13,500 --> 00:47:15,359
but this was just they're in the block

961
00:47:15,359 --> 00:47:16,800
I'll put it in the chat as well for

962
00:47:16,800 --> 00:47:19,500
people who want to see that

963
00:47:19,500 --> 00:47:21,500
um

964
00:47:23,099 --> 00:47:27,359
like this meta on being able to separate

965
00:47:27,359 --> 00:47:30,119
the technical role

966
00:47:30,119 --> 00:47:32,339
it's not just map territory but I know

967
00:47:32,339 --> 00:47:33,720
we bring it up all the time and it comes

968
00:47:33,720 --> 00:47:36,119
up again and again

969
00:47:36,119 --> 00:47:38,880
but or maybe it is all just simply that

970
00:47:38,880 --> 00:47:40,740
issue

971
00:47:40,740 --> 00:47:43,380
or just something about using natural

972
00:47:43,380 --> 00:47:45,119
terms

973
00:47:45,119 --> 00:47:49,160
especially day-to-day terms

974
00:47:49,740 --> 00:47:53,579
to refer to technical parts or outcomes

975
00:47:53,579 --> 00:47:57,140
or descriptors of models

976
00:48:06,060 --> 00:48:08,460
so it's all good to just accept this and

977
00:48:08,460 --> 00:48:09,900
say well it's an assertion by the

978
00:48:09,900 --> 00:48:13,020
authors just verbally that

979
00:48:13,020 --> 00:48:15,780
uh dollar sign term one and dollar sign

980
00:48:15,780 --> 00:48:18,300
term two are synonymous

981
00:48:18,300 --> 00:48:20,819
that's all good to just have as a

982
00:48:20,819 --> 00:48:23,700
neutral rhetorical assertion but if we

983
00:48:23,700 --> 00:48:25,560
want to start latching that into our

984
00:48:25,560 --> 00:48:28,440
understanding of the world then

985
00:48:28,440 --> 00:48:32,359
seems like we need to

986
00:48:34,079 --> 00:48:36,859
I don't know

987
00:48:37,440 --> 00:48:40,380
Michael just added you to the um

988
00:48:40,380 --> 00:48:43,619
document Shield accessor all right let's

989
00:48:43,619 --> 00:48:45,900
um in our closing few minutes here

990
00:48:45,900 --> 00:48:47,880
I think we talked about eight a fair

991
00:48:47,880 --> 00:48:51,500
amount also eight is not that long

992
00:48:51,540 --> 00:48:54,420
slash not that

993
00:48:54,420 --> 00:48:57,599
of course one could go very deep

994
00:48:57,599 --> 00:48:59,040
into

995
00:48:59,040 --> 00:49:03,000
the mathematics of the continuous or the

996
00:49:03,000 --> 00:49:05,280
Hybrid models but we we

997
00:49:05,280 --> 00:49:06,420
um

998
00:49:06,420 --> 00:49:08,940
and we could go into the other examples

999
00:49:08,940 --> 00:49:10,319
and so on but

1000
00:49:10,319 --> 00:49:12,300
um you know

1001
00:49:12,300 --> 00:49:14,339
just to first pass there

1002
00:49:14,339 --> 00:49:17,700
okay so that is the end of chapter eight

1003
00:49:17,700 --> 00:49:20,099
let's just quickly in the last few

1004
00:49:20,099 --> 00:49:23,099
minutes look ahead to nine

1005
00:49:23,099 --> 00:49:25,079
just because we have the best Hammer

1006
00:49:25,079 --> 00:49:26,880
does not mean that every problem is a

1007
00:49:26,880 --> 00:49:29,000
nail

1008
00:49:30,000 --> 00:49:32,280
models are useful if they can answer

1009
00:49:32,280 --> 00:49:34,560
scientific questions

1010
00:49:34,560 --> 00:49:37,500
chapter 9 focuses on active inference in

1011
00:49:37,500 --> 00:49:40,260
the context of empirical data

1012
00:49:40,260 --> 00:49:44,040
section 9.2 is on metabayesian methods

1013
00:49:44,040 --> 00:49:46,440
and it's going to talk about the setting

1014
00:49:46,440 --> 00:49:48,720
of cognitive modeling with active

1015
00:49:48,720 --> 00:49:51,180
inference in the setting of Behavioral

1016
00:49:51,180 --> 00:49:54,119
or ethological experimentation

1017
00:49:54,119 --> 00:49:55,800
and so it's not just going to be a proof

1018
00:49:55,800 --> 00:49:59,520
of principle like we constructed a t

1019
00:49:59,520 --> 00:50:03,319
Maze and a simulated rat

1020
00:50:03,540 --> 00:50:04,859
um

1021
00:50:04,859 --> 00:50:07,140
there's two reasons to fit a

1022
00:50:07,140 --> 00:50:09,180
computational model to observed Behavior

1023
00:50:09,180 --> 00:50:11,220
the first reason is to estimate

1024
00:50:11,220 --> 00:50:14,240
parameters of Interest

1025
00:50:14,460 --> 00:50:16,200
the second reason is to compare

1026
00:50:16,200 --> 00:50:18,780
alternative hypotheses

1027
00:50:18,780 --> 00:50:20,760
they recap base theorem and they're

1028
00:50:20,760 --> 00:50:22,740
going to be discussing Bayes theorem in

1029
00:50:22,740 --> 00:50:25,560
the context of scientists scientific

1030
00:50:25,560 --> 00:50:27,359
epistemology

1031
00:50:27,359 --> 00:50:30,500
and a really Bayesian epistemology

1032
00:50:30,500 --> 00:50:34,319
as the behavioral investigator

1033
00:50:34,319 --> 00:50:38,160
that lends itself to this key figure 9.1

1034
00:50:38,160 --> 00:50:40,800
that characterizes the metabasian view

1035
00:50:40,800 --> 00:50:43,740
so in the inner dashed box we have the

1036
00:50:43,740 --> 00:50:45,599
cognitive model that we're constructing

1037
00:50:45,599 --> 00:50:48,119
of the ant

1038
00:50:48,119 --> 00:50:51,540
so map territory level one

1039
00:50:51,540 --> 00:50:55,260
then we're in our own dashed box

1040
00:50:55,260 --> 00:50:58,319
because we are providing what for us our

1041
00:50:58,319 --> 00:51:01,079
action selections and parameters of the

1042
00:51:01,079 --> 00:51:03,960
experiment drawn from distributions of

1043
00:51:03,960 --> 00:51:06,599
experiments and stimuli

1044
00:51:06,599 --> 00:51:09,960
and presenting it to the ant

1045
00:51:09,960 --> 00:51:12,720
then potentially with errors and

1046
00:51:12,720 --> 00:51:15,960
variance Etc observing Behavior so this

1047
00:51:15,960 --> 00:51:18,059
is the metabasian view view from the

1048
00:51:18,059 --> 00:51:19,079
outside

1049
00:51:19,079 --> 00:51:21,900
and viewed from the inside now there is

1050
00:51:21,900 --> 00:51:23,940
a view from the inside

1051
00:51:23,940 --> 00:51:26,460
but this is a map of the view of the

1052
00:51:26,460 --> 00:51:28,140
inside

1053
00:51:28,140 --> 00:51:31,920
and this is our schema of our control

1054
00:51:31,920 --> 00:51:35,180
framework from the outside

1055
00:51:35,700 --> 00:51:38,700
so all the talking about sweeping over

1056
00:51:38,700 --> 00:51:41,040
families of cognitive models of ants and

1057
00:51:41,040 --> 00:51:42,480
rats and stuff like that that's all

1058
00:51:42,480 --> 00:51:44,940
happening in this dashed box but in the

1059
00:51:44,940 --> 00:51:46,500
outer loop

1060
00:51:46,500 --> 00:51:49,500
um we are exploring different maximally

1061
00:51:49,500 --> 00:51:52,319
informative cognitive modeling settings

1062
00:51:52,319 --> 00:51:55,020
and observations to observe

1063
00:51:55,020 --> 00:51:56,700
and again like the imperative being

1064
00:51:56,700 --> 00:51:58,380
maximally informative information

1065
00:51:58,380 --> 00:52:01,440
through experiments not some kind of

1066
00:52:01,440 --> 00:52:03,480
falsificationist

1067
00:52:03,480 --> 00:52:07,079
accept or reject dialectic but putting

1068
00:52:07,079 --> 00:52:09,300
it more into a base Factor

1069
00:52:09,300 --> 00:52:12,079
continuous

1070
00:52:12,079 --> 00:52:15,119
juxtaposition of portfolios of

1071
00:52:15,119 --> 00:52:17,819
hypotheses rather than like a p-value

1072
00:52:17,819 --> 00:52:21,599
frequentist except a reject framework

1073
00:52:21,599 --> 00:52:22,800
um

1074
00:52:22,800 --> 00:52:24,359
it's going to be like

1075
00:52:24,359 --> 00:52:26,579
of active inference

1076
00:52:26,579 --> 00:52:29,760
in multiple ways

1077
00:52:29,760 --> 00:52:33,119
okay turn away from that sort of

1078
00:52:33,119 --> 00:52:36,300
ethological view to some technical

1079
00:52:36,300 --> 00:52:40,760
details on the variational LaPlace

1080
00:52:44,339 --> 00:52:45,359
um

1081
00:52:45,359 --> 00:52:48,900
section 9.4 parametric empirical Bays

1082
00:52:48,900 --> 00:52:52,319
PEB is a way that you can start with a

1083
00:52:52,319 --> 00:52:54,660
real data set and kind of use the first

1084
00:52:54,660 --> 00:52:56,880
instantiation of the whole data set or

1085
00:52:56,880 --> 00:53:00,180
part of the data set to jump start you

1086
00:53:00,180 --> 00:53:01,680
or like

1087
00:53:01,680 --> 00:53:06,480
um parachute drop you into a reasonable

1088
00:53:06,480 --> 00:53:09,540
area of phase space

1089
00:53:09,540 --> 00:53:11,940
and that facilitates expectation

1090
00:53:11,940 --> 00:53:14,339
maximization type algorithms and

1091
00:53:14,339 --> 00:53:16,500
empirical applications of Bayesian

1092
00:53:16,500 --> 00:53:19,200
statistics like we're going to fit our

1093
00:53:19,200 --> 00:53:21,960
prior on this fifth grade classroom's

1094
00:53:21,960 --> 00:53:24,900
Heights from

1095
00:53:24,900 --> 00:53:26,819
a bigger data set of heights that were

1096
00:53:26,819 --> 00:53:28,559
collected from first through eighth

1097
00:53:28,559 --> 00:53:30,480
grade and that's going to be our prior

1098
00:53:30,480 --> 00:53:33,000
for this fifth grade classroom or we're

1099
00:53:33,000 --> 00:53:34,260
just going to take the measurements we

1100
00:53:34,260 --> 00:53:35,400
did get

1101
00:53:35,400 --> 00:53:37,619
and then summary statistics of that

1102
00:53:37,619 --> 00:53:40,680
distribution we're going to use as our

1103
00:53:40,680 --> 00:53:42,300
prior

1104
00:53:42,300 --> 00:53:44,460
then 9.5 it's kind of like a little bit

1105
00:53:44,460 --> 00:53:47,339
like a chapter six a recipe but here the

1106
00:53:47,339 --> 00:53:49,559
recipe is about collecting data

1107
00:53:49,559 --> 00:53:51,839
formulating a model

1108
00:53:51,839 --> 00:53:54,480
as in chapter 7 or in chapter six if you

1109
00:53:54,480 --> 00:53:57,420
want to pull back even more generally

1110
00:53:57,420 --> 00:54:00,540
specify likelihood priors solve for

1111
00:54:00,540 --> 00:54:03,540
probabilities and evidences and then

1112
00:54:03,540 --> 00:54:06,240
perform statistical analyzes and that's

1113
00:54:06,240 --> 00:54:08,160
actually where descriptive statistics

1114
00:54:08,160 --> 00:54:12,119
can come into play like we did in Anova

1115
00:54:12,119 --> 00:54:15,540
on these cognitive modeling parameters

1116
00:54:15,540 --> 00:54:18,660
and then they have a um summary figure

1117
00:54:18,660 --> 00:54:20,160
9.2

1118
00:54:20,160 --> 00:54:22,020
so here we're like really bringing

1119
00:54:22,020 --> 00:54:23,900
together a lot of sections of the book

1120
00:54:23,900 --> 00:54:27,660
in slide one is the teammates

1121
00:54:27,660 --> 00:54:30,000
here's the generative process and

1122
00:54:30,000 --> 00:54:31,319
generative model that could have been

1123
00:54:31,319 --> 00:54:33,599
written before

1124
00:54:33,599 --> 00:54:35,700
Blends the likelihood function that

1125
00:54:35,700 --> 00:54:38,280
allows this invertible model such that

1126
00:54:38,280 --> 00:54:40,800
you can use the generative model to

1127
00:54:40,800 --> 00:54:44,280
generate synthetic data or you can take

1128
00:54:44,280 --> 00:54:46,619
data of that structure and do

1129
00:54:46,619 --> 00:54:49,559
statistical inference on so we did five

1130
00:54:49,559 --> 00:54:51,119
conditions and it turns out condition

1131
00:54:51,119 --> 00:54:54,059
four and five with this p-value are

1132
00:54:54,059 --> 00:54:55,980
significantly higher or this base Factor

1133
00:54:55,980 --> 00:54:59,000
than there

1134
00:54:59,819 --> 00:55:02,819
and some examples of generative models

1135
00:55:02,819 --> 00:55:05,160
some models of false inference a long

1136
00:55:05,160 --> 00:55:06,240
table

1137
00:55:06,240 --> 00:55:08,220
in a summary

1138
00:55:08,220 --> 00:55:09,660
all right

1139
00:55:09,660 --> 00:55:10,920
thank you

1140
00:55:10,920 --> 00:55:12,119
that

1141
00:55:12,119 --> 00:55:15,839
um concludes chapter 8 will return in

1142
00:55:15,839 --> 00:55:17,940
one minute or two minutes with um

1143
00:55:17,940 --> 00:55:22,640
beginning of uh next door thank you

