SPEAKER_00:
Hello, it is cohort two, March 8th, 2023.

We're in meeting 19 and we're in our second discussion on chapter eight.

We will look over the questions on chapter eight and talk about any sections of chapter eight.

And we will, um, also probably take a preview look towards nine.

So just at the outset, does anyone have any, um, comments or questions on eight, anything else that they've come across or learned over the last week that puts continuous time models in a different context?

Any other thoughts on continuous and discrete?

Or we'll look over the questions and make sure that we've at least touched upon each of the questions from the previous cohorts.

Yeah, Ali, go for it.


SPEAKER_01:
Actually, based on...

Some of the claims, especially in a Bayesian Mechanics paper and also in this recent Path Integrals paper, they claim that FEP formulation, at least from about 2012 to 2019, was largely focused on developing

density over states mathematics or, in other words, the first two types of FEP path tracking and path matching and path mode dynamics.

I'm sorry, mode matching and mode tracking dynamics.

But in recent years, they've concentrated more in developing the path integral formulation.

I'm not sure which direction this textbook leans toward because in some places it seems like it is the extension of...

the previous developmental trajectories, but especially in chapter eight, it gets more into this recent formulation of formulating the path integral mathematics.

But then again, even in chapter eight, we see discussions about the

previous years and this year, and also how the textbook leans maps into that dichotomy.


SPEAKER_00:
yeah thank you good um points thomas overviewed as such and this par textbook seems to be more heavily on the mode matching and mode tracking however the continuous time

It's kind of like the more things change, the more they stay the same.

So looking at Thomas's overview of the history, the early implementations, as he noted, were in continuous time.

And then in order to bring on explicit planning, discrete cognitive decision-making, symbolic state spaces and so on, sequential behavior, they actually pivoted to the discrete time formalism.

And that left the continuous time, Locke of Volterra, generalized dynamical systems,

phrasings behind then um now we have a uh a fusion of the continuous and the discrete times with uh typified by the figure 8.6

where through hierarchical nested models, we can include features of discrete decision-making as well as continuous perception and action.

Also discussed in Livestream 46, ACNIMF does not contradict folk psychology with Kiefer, Ramstad, and Smith, which discuss essentially this model as the folk psychological scaffold.

that there's a motor active inference layer that's perceptual and active in continuous space and time and then we can propose these symbolic discrete explicit planning oriented cognitive models as uh cognitive models I guess so it's funny that so there's that's one return from the uh

earliest early 2000s continuous time then the focused move to discrete time and then there's the hybrid models and then as you pointed to it even goes deeper because um the discrete time formalism is perfectly suited for the first two faces of bayesian mechanics which and the non-equilibrium steady state and the state space representations

Whereas for the truly path-tracking Bayesian mechanics and probably g-theory chaos and all of this, continuous time is like your starter position before it even goes further afield into gauge and the fibers and sheaths and all of these other

formalisms so it's almost like there's a sequence because the discrete time and the matrix multiplication are very straightforward then when we look at figure 4.3 and figure 8.6 we kind of see some similarities between continuous and discrete time and then from the continuous time we can take another jump

into the gauge setting which does seem to be the the at least in principle the most modern representations we have of bayesian mechanics michael


SPEAKER_02:
Yeah, and in figure 8.6, we have in the top the discrete time and embedded the continuous time.

I was wondering whether this can also be reversed.

We have in the top a continuous time, and then inside there, we have sequences of discrete time.

So for instance, we have statistics over how long a certain activity lasts.

And that can be broken down into a sequence of several other activities.

Could that be modeled in this way?

So for instance, for this overall activity, we know that it takes, I don't know, two minutes or 20 seconds or so.

And then the next action comes.

And each is broken down into several smaller steps that are discrete.

Can that be viewed in this way?

And then how, for instance, if we have a constraint over a time, for instance, there we have this, what is this, tau 1, this first state, which could be maybe

Yeah, if one of those states was constrained by a time, and then this constraint would be somehow handed down to the embedded processes, each of which could not take longer than the constraint in the state above.


SPEAKER_00:
Yeah, very interesting.

I've never seen such architecture.

but it's in principle possible.

It's very interesting.

And this kind of notion of scheduling, attentional scheduling and time constraints

one way it might or kind of setting where it could apply is this is again brought up in the folk psychology paper because the continuous time lower level model maps well to our uh proprioception and muscular action and then this discrete time model maps well to sequential explicit planning so let's imagine it was inverted

the lower level model might be a computer doing a dispatch in discrete time and the higher level is like the human operator and then they might also have another discrete above them so no need to stop at just two layers

I think that's the exciting direction in question is to build these towers of nested models and then lateral connections for collective behavior to describe and specify the ecosystems of shared intelligence so we can understand how different

causal and cognitive phenomena arise from interactions within and across generative models.


SPEAKER_02:
Yeah.

And how could that be modeled if we have a temporal constraint further down in the embedded processes, which are formulated by the above boxes or states?

Is there a way to notify the embedded processes that they should stop eventually or something like this?


SPEAKER_00:
Yeah.


SPEAKER_02:
I mean, otherwise, how is this message passed through?

The only connection is there are these matrices, which is the A matrix, right?

And this A matrix, what they need to determine somehow that the embedded processes follow those constraints.


SPEAKER_00:
yeah yes so let's let's look at that so uh the a matrix is the tail of two densities so it can be used as a recognition density from the observations or a generative density to generate observations from hidden states just looking at the top the o is a markov blanket between s and v

Again, Markov blankets, they don't have anything to do a priori with the agent environment boundary, though we can identify and construct Markov blankets associated with agent boundaries.

This is just using Markov blanket to mean the node or nodes upon which two other sets of states are conditionally independent.

So the O is like the interface

it's a generative density, speaking with respect to the higher model, it's a generative density passing observations down to v, the slowly varying causes, which modify how the derivatives are constructed in continuous time.

So this is kind of like a modifier on the Taylor series expansion.

And then

is also um coming back up thinking about this in a predictive processing um like bi-directional way also it's changes in the continuous time setting lower level nested model that percolate up and modify in a perceptual like way higher level states so then you ask how could constraints be modeled

there um certainly could be a lot of like engineering type solutions like just sort of uh four loops and virtualization emulation uh parallelization distributed computational processes dispatch architectures a lot of different things that like aren't

clean base graph only.

Just in practice, you would end up implementing some of these strategies.

But it's interesting to think about, well, how could we really, in a principled way, include time constraints?

And then when the top level is discrete, how would time constraints be achieved?

And then when the top level is continuous, like you're asking about how would time constraints be achieved?

So either way, it's kind of like there's like a window, like let's just say this is the real time.

Well, okay, here's one more dimension, whether or not the top or the bottom is continuous or discrete.

So this could be discrete, discrete, or continuous, continuous, or any combination.

One frame is real time is happening on the top.

And so this is like what we've seen in sophisticated inference, sophisticated affective inference.

Here's real time.

This is the real simulation time.


UNKNOWN:
12.01, 12.02, 12.03.


SPEAKER_00:
And at each time point in the real time, there's this speculation of the past, present, and future.

Or this can be the real time model in the lower model

and the higher order can be a speculative planning or a combination where there's a real-time layer that has both a faster speculative exploitation layer as well as a slower nested planning layer above real-time

I think there's many disparate, once we're in the space of nested architectures to capture complex cognitive phenomena, it's a really open space, which is why it's so important to have the structured learning and the statistical power testing and the ability to describe and understand the semantics of these models.

because I think that they're going to get out of control visually very quickly.


SPEAKER_02:
But you're saying that there's not only information going from top to bottom, but also the other way around.

So the embedded processes can inform the upper ones about some outcomes.


SPEAKER_00:
Well, yeah, in principle.

So just like O, just only looking at the top layer, O via A could update S, or S via A could produce O. That's the Taylor 2 density.

So the Bayes graph, depending on which parameters are established as fixed and which ones are established as learnable and so on,

then yes.

If you allow S to be learnable, then it will learn so that it's unsurprised about the incoming observations of slowly varying causes.

Whereas if you fix S and you only allow V to be learnable, then et cetera, et cetera.

Hmm.

And that's like the kind of information that's actually not shown on this graph other than this line, which we know is missing.

But like, as Toby Sinclair Smith's dissertation on category theory has been kind of sharing and motivating, there's actually information that's not, this is not necessary and sufficient to replicate a full model, especially if you're going to start talking about learning and all these other features.

so at best this is like a um it's a quasi-formal diagrammatic mnemonic but not quite the necessary and complete representation okay but it's a super strong motivator and helps us think about like like you're a great question about you know

continuous time on top and we should definitely look into that and see if those models have been used i think part of it is people have just um seen a natural affinity for continuous time models and bodily perception bodily action discrete time models explicit planning

so that's just common commonly held perspectives so then in that situation it's natural to do it like this but doesn't mean it can't be otherwise okay i'm not sure if these thumbs up were from our own time last um

Okay.

This was, I think, from office hours.

We talked about figure 5.2, predictive coding, message passing, and 8.4.

Okay.

Generalized synchrony, chaotic systems.

Can we...

model that with these predictive coding architectures the answer is yes we can it just depends on how you specify it um but that's not to say all lorenz coupled lorenz attractors are using a predictive processing architecture nor that predictive processing architectures exhibit lorenz attractor behavior but just you could make a system

that happens to have both of those features this is another difference between um the continuous and the discrete time that i don't think we've emphasized

Action is absent from equation 8.1.

This is because action is part of the generative process, not the generative model.

Okay.

The generative model only deals with those variables directly influenced by states external to a Markov blanket.

but those are only the sense states and external states which directly influence themselves through latent causes.

But doesn't the generative model also include cognitive and internal states?

So one could argue that the realization of action or the selection of action,

is part of the generative process.

But can't we say that the generative model includes planning as inference?

Is this only in the case of the continuous time?

not sure if this is like a general point or if this is just referring a little bit to the different way that action is modeled in the continuous time setting whereas action in the discrete setting is modeled in this standard policy selection way v are actually like not as much

even described as policies that can be selected because it doesn't make as much sense to talk about counterfactuals on v they're described as just slowly varying causes in the generative process basically contingencies or dependencies upon which the taylor series approximation is impinged on by

That's like a very oblique way of talking about the consequences of action.

It's almost like a differential angle on action.

Michael?


SPEAKER_02:
yeah so i'm wondering whether this Taylor series decomposition this different different derivations that you have there, whether this is only one view on on continuous time series or whether there's also other views.

That do not imply.

a decomposition of one function into several derivations.

I'm not sure whether I understand this correctly.

But couldn't it be that time constraints are related without derivations?


SPEAKER_00:
i'm just wondering whether this is only one way of seeing it or is it the only one yeah good question um yeah it's not exactly a taylor series i think it it's though it it's it's it has a taylor series like nature because it is dealing with successive derivative approximations with their own coefficients

But I think the more physics framing is the generalized coordinates.

So position, momentum, acceleration, jerk, et cetera.

Is there a way to talk about time constraints and multiple timescales in continuous time other than by taking derivatives?

Yes.

I mean, we can definitely explore it, but the first thought that comes to mind is when faced with a field of continuous time, two approaches that are taken, one of them is to discretize time, at which point you'd be using a discrete time model.

And if you're not going to discretize time, you're going to leave it as a smooth continuum.

Then a general approach is to utilize physics-based

generalised coordinates of motion.

Ali?


SPEAKER_01:
Well, yeah, actually, Michael Silberstein and William Stokke has been arguing for another approach to formalise cognition, time, and other

so-called dynamical aspects of the system using a dynamical mathematics so for instance in their paper rethinking the world with neutral monosome removing the boundaries between mind matter and space time they've proposed an alternative approach

which is somehow, which is expanded more, I mean, in detail in their Beyond the Dynamical Universe book.

But in this case, they, so very briefly, they conceptualize a system as a kind of a stationary system that just moves from, sorry, that just has

the first initial position and the ending ultimate position.

And we can, by using this kind of a dynamical mathematics, remove the time from the equation and just

actually look at the system in a kind of a block universe way without actually taking into consideration the flow of the system through time.

So yeah, there is definitely other approaches to model these kinds of system.

And even they argue in this paper and also in their book that

uh this new approach can somehow overcome some of the long-standing issues in theoretical physics and or even in the philosophy of physics yep very um interesting this kind of um


SPEAKER_00:
Well, the ontological reality of time in the world is definitely a complex topic.

So it's always good to know that with these discussions about time, we're talking about map time, about how we want to model time.

And in that setting, both 8.1 and 8.2 have a timeless data generating function.

y observations is simply a function of latent states on hidden states so you know y observational states is a function of latent states x plus some sensor variance y and then there's a field or space in which latent states have their own flow

that is defined again without reference to time but as a derivative field in a hamiltonian sense so even if your y data stream is an eeg or fmri time series data it's actually like where's the time oh where does the time go

not seeing any t's in these continuous time models so it's almost like we lean so hard into the continuity of time and continuity is at least synonymous with or adjacent to differentiable those two

They're not exactly exactly the same, but we work with continuous functions because we want them to be differentiable.

We have to discretize them, but the biggest issue with discrete functions is that they're non-differentiable.

Ali?


SPEAKER_01:
I think the more precise term for the mathematical condition for

modeling these systems is that they need to be in Wiener spaces.

So Wiener space is just a generalized space that contains all the continuous and differentiable functions.

And also,

I just wanted to point it out that that's exactly the point, or at least one of the points of using generalized coordinate systems in path integral formulation of FEP by removing the time from

the equations, it is possible to talk about the behavior of the system purely in terms of the space of possible paths, instead of just following the time developmental aspect of the particular states.

Awesome.


SPEAKER_00:
Yeah, it's like the difference between putting a drop of food coloring in the cloud and tracing that one path as it flows.

And then there's definitely this discussion, oh, should we model that one path of the tracer as a path with continuous state space?

Or should we discretize it and do a discrete time model of that one realized trace?

Or should we step back, describe the topology of the mountain, and then the realized trace

will be a path of least action on that landscape but will also be able to talk about counterfactuals and alternative starting conditions initial conditions and boundary conditions and um and and ask what if questions on the landscape whereas any descriptive historical model will not um

natively or simply enable counterfactual comparisons if you just have the path descriptor in continuous time or in discrete time then you don't even know what the adjacent possibles are slash could have been michael


SPEAKER_02:
Yeah, I'm not sure I understand this.

Is this possible because we assume that the time goes in regular intervals?

So if it's a regular interval, we can just ignore it?

Or what is the underlying

idea to abstract away from time, because time seems such a crucial kind of an element in all our daily lives, right?


SPEAKER_01:
Yeah, Olli, go for it.

Well, yeah, it definitely is an essential component.

But I mean, the point here is that you see, so for instance, in classical mechanics, we have at least three different formulations.

One is the Newtonian mechanic formulations.

The other one is the Lagrangian and also the Newtonian.

Newtonian formulation definitely needs time as an explicit variable and parameter.

But going from Newtonian formulation to Lagrangian and Hamiltonian, especially in the Hamiltonian formulation,

we can rearrange or derive those formulations from the classical Newtonian formulation without

accounting for time as an explicit variable so time is actually implicit in those formulations so all three of those formulations are equivalent and they can be recovered from each other and they can be derived from each other but it's just a matter of which parameters are explicit and which are implicit so yeah we don't uh get rid of time um

entirely, we just use time as a kind of implicit parameter that doesn't need to be explicitly defined.


SPEAKER_00:
Yeah, very interesting.

And also, you said the assumption time is in regular intervals, well, that's a discrete time model.

And that's the question of discretization of time, which we're actually exploring in Livestream 53.

which is, again, not the ontological reality of the time click of the world or whatever, but in modeling spaces, how to retain the elegance and the analytical advantages that continuous models provide in terms of generalized coordinates of motion, physics grounded, energy-based learning,

convergence guarantees around free energy minimization, those are all about continuous differentiable spaces, which is why they're grounded in information geometry and functional analysis.

Whereas discretization, we want to make sure that the discretization techniques that are used don't

solely or lose those properties of the underlying continuous distribution Michael


SPEAKER_02:
Yeah, I'm digesting this.

So actually, derivation takes the role of time.

So it's only derivable because we assume there is some kind of a continuation or some kind of time underlying.


SPEAKER_00:
yeah like let's let's uh pull back to a description so if we wanted a time description of a car we could describe its position at every time and so arguably one could say well that described like everything about that car's trajectory what you need to know is its position at every time all right well you could also use the generalized coordinates of motion and so for each time

could also have the car's position in x and y but also you could have the car's acceleration and and and so on so those are the derivatives of the position and uh it's not like extra information like with the whole trajectory you could recalculate the generalized coordinates of motion from the position

but you also might want your data structure to be that vector at each time step with the generalized coordinates motion.

So it's here and it's going 50 kilometers an hour and it's slowing down by two kilometers per hour per second and its acceleration is changing by positive one kilometer per second squared.

and so on.

Another angle would be to describe that space upon which there are trajectories of the generalized coordinates.

Now there's some generalized coordinates locations that are just ridiculous.

Like, well, it's not moving at all, but its fourth derivative is super high.

Well, any state space can be used to describe certain points in that state space that aren't feasible or realizable by a different physical system.

Obviously, systems spend their time in sometimes highly constrained subspaces, manifolds of these bigger state spaces.

But when you say, okay, well, then let's make the generalized coordinates of motion our fundamental state space.

So instead of X, Y, Z, T as our fundamental state space, and then we're going to derive all of our other questions from there, it's like saying, well, let's have the generalized coordinates be our state space, but then you don't need T.

course real trajectories unfold in quote time pending future understandings of what time is but you don't need t in the hamiltonian which again just to connect back to the textbook is that is what we're seeing in these representations that basically partition signal from noise

without explicit reference to t as a variable however amenable to fitting empirical time series data i don't think we resolve this question about like action being in the generative process what exactly is meant by that because action itself is part of the generative process

could say the consequences of action or the embodiment of but um is this claim about generative models in general or is this just saying something about continuous time okay precision

In our office hours last week, we had some good conversations about precision, some on the more applied side with perception and pain, some on the more conceptual side with the bird song and the sensory attenuation and the role of precision and action selection.

the perspective active inference precision and attention are synonyms here was the discussion from um the office hours

so this is a it's related to chapter eight so we were talking about um okay so in the examples first we have just general lock of Volterra winterless competition um that is then deployed in a handwriting example showing how lock of Volterra like models can account for sequential and reactive behavior

without explicit planning so in the discrete time it'd be like i'm here i'm likely to go whereas in the continuous time setting it's just like a dynamical attractor that doesn't have an explicit representation of where it's going to go in the attractor it's just flowing in the attractor

And so then we describe the state space of the attractor.

Ali?


SPEAKER_01:
You're just talking about the synonymous terms.

Actually, it's interesting that Mark Solms in his book, The Hidden Spring, also somehow uses the term consciousness as a kind of synonym for the precision optimizations.

which is one of the points that Anil Seth is strongly critical of, and he believes that we cannot simply define consciousness as a kind of precision optimization.

And so in one of their recent papers,

I think it was called From Generative Models to Generative Passages, a Computational Approach to Neurophenomenology.

Friston, Seth, and others, Max Ramstad et al.

actually uses a generative model as a computational basis for a phenomenological approach


SPEAKER_00:
definition of consciousness which deviates significantly from songs as perception their conception of consciousness hmm Wow thank you yeah I haven't read this one in depth this day in in the block friends we

So there was the original paper.

It was a guest stream with Brett Kagan and Adil Razi on the Dish Brain.

And of course, the sentience furor that arose leading to multiple and apparently ongoing sequences of short letters.

There's a lot of interesting stuff in here.

Contention is with the terms, act and fontology, sentience, goal-directed behavior, embodiment, uncertainty, intelligence.

And their call is for glossaries.

And then this paper also.

All right.

come develop the glossaries but this was just they're in the block I'll put it in the chat as well for people who want to see that um like this meta on being able to separate the technical role it's not just map territory but I know we bring it up all the time and it comes up again and again

but or maybe it is all just simply that issue or just something about using natural terms especially day-to-day terms to refer to technical parts or outcomes or descriptors of models

So it's all good to just accept this and say, well, it's an assertion by the authors just verbally that dollar sign term one and dollar sign term two are synonymous.

That's all good to just have as a neutral rhetorical assertion.

But if we want to start latching that into our understanding of the world, then seems like we need to, I don't know,

michael just added you to the um document seal of access there all right let's um in our closing few minutes here i think we talked about eight a fair amount also eight is not that long slash not that of course one could go very deep into the mathematics of the continuous or the hybrid models but we we um

we could go into the other examples and so on but um you know just first pass there okay so that is the end of chapter eight let's just quickly in the last few minutes look ahead to nine just because we have the best hammer does not mean that every problem is a nail

Models are useful if they can answer scientific questions.

Chapter 9 focuses on active inference in the context of empirical data.

Section 9.2 is on Metabasian methods, and it's going to talk about the setting of cognitive modeling with active inference in the setting of behavioral or ethological experimentation.

so it's not just going to be a proof of principle like we constructed a t maze and a simulated rat there's two reasons to fit a computational model to observed behavior the first reason is to estimate parameters of interest the second reason is to compare alternative hypotheses

recap bayes theorem and they're going to be discussing bayes theorem in the context of scientists scientific epistemology and a really bayesian epistemology as the behavioral investigator that lends itself to this key figure 9.1 that characterizes the meta bayesian view so in the inner dashed box we have the cognitive model that we're constructing of the ant

So map territory, level one.

Then we're in our own dashed box because we are providing what for us are action selections and parameters of the experiment drawn from distributions of experiments and stimuli and presenting it to the ant

then potentially with errors and variants etc observing behavior so this is the meta bayesian view view from the outside and view from the inside now there is a view from the inside but this is a map of the view of the inside and this is our schema of our control framework from the outside

So all the talking about sweeping over families of cognitive models of ants and rats and stuff like that, that's all happening in this dashed box.

But in the outer loop, we are exploring different maximally informative cognitive modeling settings and observations to observe.

And again, like the imperative being maximally informative information through experiments, not some kind of falsificationist theory

accept or reject dialectic but putting it more into a base factor continuous uh juxtaposition of portfolios of hypotheses rather than like a p-value frequentist accept or reject framework um it's going to be like of active inference in multiple ways

Okay, turn away from that sort of ethological view to some technical details on the variational Laplace.

Section 9.4, parametric empirical Bayes.

PEB is a way that you can start with a real data set and kind of use the first instantiation of the whole data set or a part of the data set to jumpstart you or like parachute drop you into a reasonable area of phase space.

And that facilitates expectation maximization type algorithms and empirical applications of Bayesian statistics.

Like we're gonna fit our prior on this fifth grade classroom's heights from a bigger data set of heights that were collected from first through eighth grade.

And that's gonna be our prior for this fifth grade classroom.

Or we're just gonna take the measurements we did get

then summary statistics of that distribution we're going to use as our prior then 9.5 it's kind of like a little bit like a chapter 6 a recipe but here the recipe is about collecting data formulating a model as in chapter 7 or in chapter 6 if you want to pull back even more generally

specify likelihood priors solve for probabilities and evidences and then perform statistical analyses and that's actually where descriptive statistics can come into play like we did in ANOVA on these cognitive modeling parameters and then they have a summary figure 9.2

So here we're like really bringing together a lot of sections of the book.

In slide one is the TMAs.

Here's the generative process and generative model that could have been written before.

lends a likelihood function that allows this invertible model such that you can use the generative model to generate synthetic data, or you can take data of that structure and do statistical inference on, so we did five conditions and it turns out condition four and five with this p-value are significantly higher or this Bayes factor than there.

and some examples of generative models, some models of false inference, a long table, and a summary.

All right.

Thank you.

That concludes chapter eight.

We'll return in one minute or two minutes with beginning of next cohort.

Thank you.