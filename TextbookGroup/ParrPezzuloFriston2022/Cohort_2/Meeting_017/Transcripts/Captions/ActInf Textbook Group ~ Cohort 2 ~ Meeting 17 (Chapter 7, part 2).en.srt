1
00:00:00,840 --> 00:00:06,000
hello it's February 22nd 2023

2
00:00:06,000 --> 00:00:08,940
223

3
00:00:08,940 --> 00:00:11,400
and we're in the second discussion

4
00:00:11,400 --> 00:00:13,440
of chapter seven

5
00:00:13,440 --> 00:00:15,719
in cohort two

6
00:00:15,719 --> 00:00:18,600
before we go to the questions of chapter

7
00:00:18,600 --> 00:00:20,880
seven and then at the end to look ahead

8
00:00:20,880 --> 00:00:23,460
to chapter eight

9
00:00:23,460 --> 00:00:26,699
we are going to have Thomas Parr joined

10
00:00:26,699 --> 00:00:29,640
for a live stream in five days

11
00:00:29,640 --> 00:00:32,880
and so anybody if they would like to

12
00:00:32,880 --> 00:00:34,380
raise

13
00:00:34,380 --> 00:00:38,899
an area of questions could be conceptual

14
00:00:39,120 --> 00:00:42,239
or it could just be a general

15
00:00:42,239 --> 00:00:45,120
textbook level or personal question so

16
00:00:45,120 --> 00:00:46,559
of course feel free to add anything but

17
00:00:46,559 --> 00:00:48,960
just while we're here any thought or

18
00:00:48,960 --> 00:00:50,879
like kind of General

19
00:00:50,879 --> 00:00:53,039
piece that people are thinking that

20
00:00:53,039 --> 00:00:54,719
Thomas could reduce our uncertainty

21
00:00:54,719 --> 00:00:56,899
about

22
00:01:06,960 --> 00:01:10,619
all right just of course

23
00:01:10,619 --> 00:01:14,420
add it when you see fit

24
00:01:15,479 --> 00:01:16,979
okay

25
00:01:16,979 --> 00:01:20,420
um there were several

26
00:01:20,880 --> 00:01:23,520
questions that we've already looked at

27
00:01:23,520 --> 00:01:25,500
from seven

28
00:01:25,500 --> 00:01:28,380
and several more

29
00:01:28,380 --> 00:01:31,860
we can also look a little bit more

30
00:01:31,860 --> 00:01:36,420
just again we we looked at the first

31
00:01:36,420 --> 00:01:40,259
sections of

32
00:01:40,680 --> 00:01:42,900
the chapter itself

33
00:01:42,900 --> 00:01:45,380
so

34
00:01:46,500 --> 00:01:50,759
does anyone have a chapter 7 question

35
00:01:50,759 --> 00:01:53,159
that they want to go to or ADD

36
00:01:53,159 --> 00:01:54,479
or

37
00:01:54,479 --> 00:01:58,340
do they prefer to walk through

38
00:01:58,439 --> 00:02:01,820
the sections in the textbook

39
00:02:16,319 --> 00:02:19,739
let's look at equation 7.4

40
00:02:19,739 --> 00:02:21,599
see if we have anything

41
00:02:21,599 --> 00:02:24,980
annotated for it

42
00:02:29,280 --> 00:02:31,200
okay we don't have the natural language

43
00:02:31,200 --> 00:02:33,619
yet

44
00:02:39,000 --> 00:02:41,879
so let's just look a little let's pick

45
00:02:41,879 --> 00:02:43,019
back up

46
00:02:43,019 --> 00:02:48,060
with the um rat in the Maze example

47
00:02:48,060 --> 00:02:49,560
go through it connect it to the

48
00:02:49,560 --> 00:02:52,500
equations and then return to some to

49
00:02:52,500 --> 00:02:55,519
several of the um

50
00:02:55,519 --> 00:02:58,440
uh questions down here

51
00:02:58,440 --> 00:03:01,760
in seven

52
00:03:03,540 --> 00:03:04,680
um

53
00:03:04,680 --> 00:03:06,900
so in the earliest part of chapter seven

54
00:03:06,900 --> 00:03:09,780
was a passive inference with the example

55
00:03:09,780 --> 00:03:12,180
of listening to music

56
00:03:12,180 --> 00:03:13,440
now

57
00:03:13,440 --> 00:03:16,019
the upstairs action selection part is

58
00:03:16,019 --> 00:03:18,800
going to come into play

59
00:03:19,379 --> 00:03:22,379
the imperative for Action selection is

60
00:03:22,379 --> 00:03:25,640
going to be G

61
00:03:26,280 --> 00:03:29,940
like we saw in chapter 5

62
00:03:29,940 --> 00:03:32,819
takes the action prior

63
00:03:32,819 --> 00:03:36,840
the prior on different policies

64
00:03:36,840 --> 00:03:40,019
which can be understood as like habit

65
00:03:40,019 --> 00:03:42,120
and then

66
00:03:42,120 --> 00:03:44,519
sharpens it

67
00:03:44,519 --> 00:03:47,879
according to just qualitatively

68
00:03:47,879 --> 00:03:51,180
provide epistemic and pragmatic value

69
00:03:51,180 --> 00:03:53,040
and quantitatively

70
00:03:53,040 --> 00:03:58,340
as described in equation 2.6 and 7.4

71
00:03:59,280 --> 00:04:02,519
does anyone want to give a reading or a

72
00:04:02,519 --> 00:04:05,040
thought on 7.4

73
00:04:05,040 --> 00:04:07,019
just what is it saying

74
00:04:07,019 --> 00:04:09,659
in and of itself

75
00:04:09,659 --> 00:04:11,099
and or

76
00:04:11,099 --> 00:04:15,120
how does or might this relate to in

77
00:04:15,120 --> 00:04:17,279
their words the resolution of the

78
00:04:17,279 --> 00:04:21,260
exploration exploitation dilemma

79
00:04:27,120 --> 00:04:30,360
yeah I'll go for it

80
00:04:30,360 --> 00:04:33,139
foreign

81
00:04:33,380 --> 00:04:39,000
we saw before in chapter two I guess

82
00:04:39,000 --> 00:04:42,740
um but I think it was in a more

83
00:04:42,740 --> 00:04:46,460
comprehensive terms but here we only

84
00:04:46,460 --> 00:04:50,400
have a part of that equation which

85
00:04:50,400 --> 00:04:53,340
basically deals with the trade-off

86
00:04:53,340 --> 00:04:55,680
between a negative

87
00:04:55,680 --> 00:04:57,419
um I mean epistemic value and the

88
00:04:57,419 --> 00:04:59,220
pragmatic value

89
00:04:59,220 --> 00:05:01,500
and how they relate to each other

90
00:05:01,500 --> 00:05:02,880
because

91
00:05:02,880 --> 00:05:06,020
um as we saw in Chapter 2

92
00:05:06,020 --> 00:05:09,000
the trade-off or the Dilemma between

93
00:05:09,000 --> 00:05:12,300
exploration and exploitation

94
00:05:12,300 --> 00:05:14,660
um is basically

95
00:05:14,660 --> 00:05:18,440
uh one of the fundamental requirements

96
00:05:18,440 --> 00:05:20,960
for any

97
00:05:20,960 --> 00:05:25,680
sentient behavior for any sentient agent

98
00:05:25,680 --> 00:05:29,460
because as long as

99
00:05:29,460 --> 00:05:31,940
the agent

100
00:05:31,940 --> 00:05:35,120
tries to uh

101
00:05:35,120 --> 00:05:41,100
ex wants to explore the environment in

102
00:05:41,100 --> 00:05:43,199
order to

103
00:05:43,199 --> 00:05:44,460
um

104
00:05:44,460 --> 00:05:48,960
informally discover a new

105
00:05:48,960 --> 00:05:54,120
um new let's say opportunities or new uh

106
00:05:54,120 --> 00:05:57,180
resources be it uh I don't know food

107
00:05:57,180 --> 00:06:00,660
resource or any other resource necessary

108
00:06:00,660 --> 00:06:04,560
for its survival in the environment it

109
00:06:04,560 --> 00:06:08,039
needs to somehow have a trade-off

110
00:06:08,039 --> 00:06:11,960
between this kind of having

111
00:06:11,960 --> 00:06:15,320
the pragmatic value on one hand namely

112
00:06:15,320 --> 00:06:18,360
to survive in the environment and on the

113
00:06:18,360 --> 00:06:19,460
other hand

114
00:06:19,460 --> 00:06:24,060
to ex to discover new resources for its

115
00:06:24,060 --> 00:06:24,919
survival

116
00:06:24,919 --> 00:06:27,900
which basically relates to

117
00:06:27,900 --> 00:06:31,620
the pragmatic value but

118
00:06:31,620 --> 00:06:36,300
either of those two requirements

119
00:06:36,300 --> 00:06:41,280
um if taken to uh to its extreme far uh

120
00:06:41,280 --> 00:06:44,400
would probably result in the demise of

121
00:06:44,400 --> 00:06:46,860
the agent because

122
00:06:46,860 --> 00:06:51,120
um so take for instance an agent uh

123
00:06:51,120 --> 00:06:53,880
residing in an environment but

124
00:06:53,880 --> 00:06:57,380
for a specific a certain

125
00:06:57,380 --> 00:07:00,539
period of time it can't survive in that

126
00:07:00,539 --> 00:07:04,039
environment using the pre-known

127
00:07:04,039 --> 00:07:07,620
resources there but uh when the

128
00:07:07,620 --> 00:07:10,860
resources is about to

129
00:07:10,860 --> 00:07:11,600
um

130
00:07:11,600 --> 00:07:13,740
is about

131
00:07:13,740 --> 00:07:18,900
um to diminish then that agent need to

132
00:07:18,900 --> 00:07:21,360
explore a little bit a little bit

133
00:07:21,360 --> 00:07:24,960
further in order to discover some new uh

134
00:07:24,960 --> 00:07:27,539
resources and

135
00:07:27,539 --> 00:07:30,300
continue it's persistent Through Time

136
00:07:30,300 --> 00:07:33,080
word survival

137
00:07:36,840 --> 00:07:38,940
yeah great

138
00:07:38,940 --> 00:07:40,199
yes Michael

139
00:07:40,199 --> 00:07:44,460
oh yeah yeah so so I'm I'm a little bit

140
00:07:44,460 --> 00:07:50,039
wondering the the in this epistemic

141
00:07:50,039 --> 00:07:51,440
um considerations

142
00:07:51,440 --> 00:07:53,639
uh only

143
00:07:53,639 --> 00:07:56,400
things can be considered that the

144
00:07:56,400 --> 00:08:00,300
agent actually already knows about right

145
00:08:00,300 --> 00:08:01,259
um

146
00:08:01,259 --> 00:08:03,419
and and then I'm

147
00:08:03,419 --> 00:08:06,539
wondering why at several places I think

148
00:08:06,539 --> 00:08:09,599
it said this in chapter two and here in

149
00:08:09,599 --> 00:08:13,800
this chapter also seven two also that um

150
00:08:13,800 --> 00:08:17,900
that one would like to find the most

151
00:08:17,900 --> 00:08:20,280
unlikely path

152
00:08:20,280 --> 00:08:24,840
or one would like to uh to to increase

153
00:08:24,840 --> 00:08:28,979
the information value means when yeah

154
00:08:28,979 --> 00:08:31,199
um that's what I understood so the past

155
00:08:31,199 --> 00:08:33,659
that should be searched for would be the

156
00:08:33,659 --> 00:08:37,380
path that maximizes uh information which

157
00:08:37,380 --> 00:08:40,320
is uh means it's the the most uncertain

158
00:08:40,320 --> 00:08:42,419
path

159
00:08:42,419 --> 00:08:45,360
um and

160
00:08:45,360 --> 00:08:47,360
um

161
00:08:47,600 --> 00:08:49,279
correct

162
00:08:49,279 --> 00:08:51,720
there's there's aspects that I think are

163
00:08:51,720 --> 00:08:53,459
are correct but I just want to draw that

164
00:08:53,459 --> 00:08:57,480
out so actually what is being selected

165
00:08:57,480 --> 00:08:59,399
for policy

166
00:08:59,399 --> 00:09:03,000
are the most likely paths what is an

167
00:09:03,000 --> 00:09:05,940
agent like me most likely to do we're

168
00:09:05,940 --> 00:09:08,220
sampling our actions from the action

169
00:09:08,220 --> 00:09:09,600
posterior

170
00:09:09,600 --> 00:09:12,779
so rather than scaling policies by their

171
00:09:12,779 --> 00:09:15,480
reward and ranking them by the reward

172
00:09:15,480 --> 00:09:18,120
in reward learning and choosing sampling

173
00:09:18,120 --> 00:09:20,339
from the reward posterior for example

174
00:09:20,339 --> 00:09:23,100
we're going to be sampling from an

175
00:09:23,100 --> 00:09:27,060
action posterior so

176
00:09:27,060 --> 00:09:28,920
um in the sense that our actions are

177
00:09:28,920 --> 00:09:31,440
selected based upon their posterior

178
00:09:31,440 --> 00:09:33,420
likelihood we're actually pursuing the

179
00:09:33,420 --> 00:09:35,700
most likely path of action indeed the

180
00:09:35,700 --> 00:09:38,580
path of least action however we are

181
00:09:38,580 --> 00:09:41,160
seeking in the epistemic component

182
00:09:41,160 --> 00:09:43,880
especially

183
00:09:44,060 --> 00:09:47,240
maximally informative

184
00:09:47,240 --> 00:09:50,700
sequences of future observations

185
00:09:50,700 --> 00:09:52,740
so in the special case where pragmatic

186
00:09:52,740 --> 00:09:54,779
value doesn't matter

187
00:09:54,779 --> 00:09:57,000
like we have no preference over outcomes

188
00:09:57,000 --> 00:09:59,040
we don't we don't we don't care if our

189
00:09:59,040 --> 00:10:00,660
bank account goes up or down

190
00:10:00,660 --> 00:10:04,519
then we Implement a pure info Max

191
00:10:04,519 --> 00:10:06,480
novelty search

192
00:10:06,480 --> 00:10:09,120
in a situation that's totally

193
00:10:09,120 --> 00:10:12,240
um known there's no epistemic value to

194
00:10:12,240 --> 00:10:13,740
be obtained

195
00:10:13,740 --> 00:10:17,240
we have a special case of pure utility

196
00:10:17,240 --> 00:10:18,959
pragmatic value

197
00:10:18,959 --> 00:10:22,140
however in cases where both utility

198
00:10:22,140 --> 00:10:26,040
pragmatic and epistemic are on the table

199
00:10:26,040 --> 00:10:27,660
G

200
00:10:27,660 --> 00:10:31,140
is proposed to resolve this dilemma

201
00:10:31,140 --> 00:10:34,140
by adjusting the action prior into an

202
00:10:34,140 --> 00:10:38,160
action posterior that respects

203
00:10:38,160 --> 00:10:39,899
the importance of both of those

204
00:10:39,899 --> 00:10:42,620
imperatives

205
00:10:44,519 --> 00:10:47,640
that's the unified imperative of

206
00:10:47,640 --> 00:10:50,959
action and inference

207
00:10:51,240 --> 00:10:54,260
yeah so so so

208
00:10:54,260 --> 00:10:56,760
I'm I'm not sure how I should understand

209
00:10:56,760 --> 00:10:59,820
this so for instance I want to go to the

210
00:10:59,820 --> 00:11:01,980
bakery and buy some bread

211
00:11:01,980 --> 00:11:05,339
and then the most informative I mean the

212
00:11:05,339 --> 00:11:07,380
more unlikely thing is actually that I

213
00:11:07,380 --> 00:11:11,579
go to the barber and cut my hairs so I

214
00:11:11,579 --> 00:11:14,519
would con I would because that has more

215
00:11:14,519 --> 00:11:16,320
information and going to the Baker and

216
00:11:16,320 --> 00:11:18,600
considering what kind of bread I'm going

217
00:11:18,600 --> 00:11:22,320
to buy I I I I I I go to the barber

218
00:11:22,320 --> 00:11:25,440
because that is more that is more

219
00:11:25,440 --> 00:11:28,500
informative I'm not sure I understand

220
00:11:28,500 --> 00:11:30,860
how I should understand this

221
00:11:30,860 --> 00:11:33,899
these values are calculated about

222
00:11:33,899 --> 00:11:37,740
generative models not about territories

223
00:11:37,740 --> 00:11:41,160
so we again it's it's natural intuitive

224
00:11:41,160 --> 00:11:43,500
to want to be like

225
00:11:43,500 --> 00:11:45,839
directly mapping from an equation or

226
00:11:45,839 --> 00:11:48,660
calculation to a real world territory

227
00:11:48,660 --> 00:11:50,399
situation

228
00:11:50,399 --> 00:11:53,579
but keep in mind these are

229
00:11:53,579 --> 00:11:56,040
um ultimately numerical values

230
00:11:56,040 --> 00:11:58,440
calculated for generative model it

231
00:11:58,440 --> 00:11:59,640
doesn't make sense to talk about free

232
00:11:59,640 --> 00:12:02,579
energy being minimized like for example

233
00:12:02,579 --> 00:12:04,860
if a person doing translation simply or

234
00:12:04,860 --> 00:12:07,740
of an ant simply foraging it's of the

235
00:12:07,740 --> 00:12:09,959
generative model that these values are

236
00:12:09,959 --> 00:12:12,060
being calculated on

237
00:12:12,060 --> 00:12:15,060
and so if one proposes a generative

238
00:12:15,060 --> 00:12:17,420
model of location

239
00:12:17,420 --> 00:12:20,399
Behavior so kind of in a previous

240
00:12:20,399 --> 00:12:22,200
discussion we had like a higher order

241
00:12:22,200 --> 00:12:24,360
like what location am I going to Barber

242
00:12:24,360 --> 00:12:28,260
home Baker you know and then we have a

243
00:12:28,260 --> 00:12:30,480
lower level model with our footsteps so

244
00:12:30,480 --> 00:12:31,860
that's kind of analogous to the live

245
00:12:31,860 --> 00:12:35,820
stream 42 slam robotics example

246
00:12:35,820 --> 00:12:37,980
then in that situation

247
00:12:37,980 --> 00:12:41,519
one could ask how different policy

248
00:12:41,519 --> 00:12:43,079
selections

249
00:12:43,079 --> 00:12:45,660
were being influenced

250
00:12:45,660 --> 00:12:47,700
by their respective epistemic or

251
00:12:47,700 --> 00:12:50,760
pragmatic value but it is not the case

252
00:12:50,760 --> 00:12:53,820
that we can directly draw from a

253
00:12:53,820 --> 00:12:55,019
variable

254
00:12:55,019 --> 00:12:57,360
to the territory

255
00:12:57,360 --> 00:12:59,880
these are like summary variables or

256
00:12:59,880 --> 00:13:02,940
re-weightings on our map and it only

257
00:13:02,940 --> 00:13:04,920
makes sense to talk about these

258
00:13:04,920 --> 00:13:09,680
summaries on maps not territories Ali

259
00:13:10,639 --> 00:13:13,440
actually Michael Levin has an excellent

260
00:13:13,440 --> 00:13:17,279
paper from 2019 the computational

261
00:13:17,279 --> 00:13:19,160
boundary of a self

262
00:13:19,160 --> 00:13:23,600
in which he has an interesting diagram

263
00:13:23,600 --> 00:13:25,760
showing the

264
00:13:25,760 --> 00:13:30,899
cognitive sphere or cognitive light

265
00:13:30,899 --> 00:13:34,860
comes if you will of each cognitive or

266
00:13:34,860 --> 00:13:39,899
intelligent agent in which it can have

267
00:13:39,899 --> 00:13:42,740
an effect and it's

268
00:13:42,740 --> 00:13:47,339
of a more or less a

269
00:13:47,339 --> 00:13:51,899
it's concerned so uh it also integrates

270
00:13:51,899 --> 00:13:54,000
the yeah that's it

271
00:13:54,000 --> 00:13:57,660
so uh so for example

272
00:13:57,660 --> 00:14:02,399
um for humans uh because of uh well or

273
00:14:02,399 --> 00:14:05,639
highly intelligent uh species or agents

274
00:14:05,639 --> 00:14:08,639
uh because of the complexity of its

275
00:14:08,639 --> 00:14:12,180
goal-directed activity and agency it

276
00:14:12,180 --> 00:14:15,600
results in a kind of larger cognitive

277
00:14:15,600 --> 00:14:22,079
boundaries and for uh somewhat uh let's

278
00:14:22,079 --> 00:14:25,980
say quote-unquote simpler agents that

279
00:14:25,980 --> 00:14:29,160
would result in a much smaller light

280
00:14:29,160 --> 00:14:33,120
cone area of cognitive boundaries uh so

281
00:14:33,120 --> 00:14:34,700
yeah

282
00:14:34,700 --> 00:14:38,519
depending on the complexity of the tasks

283
00:14:38,519 --> 00:14:42,320
that the agent is capable of doing that

284
00:14:42,320 --> 00:14:45,300
territory of

285
00:14:45,300 --> 00:14:50,060
its cognitive effectivity would vary

286
00:14:50,060 --> 00:14:52,980
according to the complexity of the

287
00:14:52,980 --> 00:14:55,139
thesis

288
00:14:55,139 --> 00:14:57,000
yeah

289
00:14:57,000 --> 00:14:59,540
so

290
00:15:00,600 --> 00:15:02,339
these are

291
00:15:02,339 --> 00:15:05,040
G is a functional

292
00:15:05,040 --> 00:15:07,620
that is going to sharpen our action

293
00:15:07,620 --> 00:15:09,360
prior

294
00:15:09,360 --> 00:15:12,839
according to such and such

295
00:15:12,839 --> 00:15:15,720
if we just wanted to pass through habit

296
00:15:15,720 --> 00:15:19,560
we would just pass through habit and

297
00:15:19,560 --> 00:15:23,000
um in chapter 5

298
00:15:23,100 --> 00:15:26,459
in the nervous system example

299
00:15:26,459 --> 00:15:28,860
this is what's reflected in the bottom

300
00:15:28,860 --> 00:15:31,560
here with this dopaminergic circuitry

301
00:15:31,560 --> 00:15:34,920
where on the left side of this basal

302
00:15:34,920 --> 00:15:37,139
ganglia or whatever mammalian tissue it

303
00:15:37,139 --> 00:15:38,519
happens to be

304
00:15:38,519 --> 00:15:40,980
on the left side there's kind of like a

305
00:15:40,980 --> 00:15:44,880
habit pass through like e the prior on

306
00:15:44,880 --> 00:15:48,600
affordance is basically passed through

307
00:15:48,600 --> 00:15:51,300
whereas in G I'm sorry on the right side

308
00:15:51,300 --> 00:15:52,380
G

309
00:15:52,380 --> 00:15:54,540
is sharpening

310
00:15:54,540 --> 00:15:56,820
the policy distribution so if we just

311
00:15:56,820 --> 00:15:58,680
want to pass through have it we don't

312
00:15:58,680 --> 00:16:00,360
even need to apply G

313
00:16:00,360 --> 00:16:03,060
however if we want to sharpen

314
00:16:03,060 --> 00:16:06,899
our action selection the moment to

315
00:16:06,899 --> 00:16:10,019
respect expected free energy in a

316
00:16:10,019 --> 00:16:13,740
prospective planning like fashion then

317
00:16:13,740 --> 00:16:15,420
we want to calculate

318
00:16:15,420 --> 00:16:18,540
um G so what is being calculated with G

319
00:16:18,540 --> 00:16:20,699
again this is an equation 2.6 but also

320
00:16:20,699 --> 00:16:22,920
here we're taking another look at it so

321
00:16:22,920 --> 00:16:25,199
there's two terms

322
00:16:25,199 --> 00:16:29,579
looking first at the pragmatic value

323
00:16:29,579 --> 00:16:31,560
and the special cases were already

324
00:16:31,560 --> 00:16:34,680
mentioned and elsewhere about when one

325
00:16:34,680 --> 00:16:37,680
of these or the other is zero okay so

326
00:16:37,680 --> 00:16:41,880
fancy e it's an expectation

327
00:16:41,880 --> 00:16:45,180
regarding RQ variational distribution

328
00:16:45,180 --> 00:16:46,980
that we control

329
00:16:46,980 --> 00:16:48,420
of

330
00:16:48,420 --> 00:16:51,540
otilda observation sequence conditioned

331
00:16:51,540 --> 00:16:53,279
upon policy

332
00:16:53,279 --> 00:16:55,139
so we're going to see that both terms

333
00:16:55,139 --> 00:16:57,480
are conditioned upon policy

334
00:16:57,480 --> 00:17:00,779
so if there's only two affordances

335
00:17:00,779 --> 00:17:03,420
then we're only going to compute two

336
00:17:03,420 --> 00:17:06,000
different G's so this is how we kind of

337
00:17:06,000 --> 00:17:08,520
prevent like spiraling and Computing

338
00:17:08,520 --> 00:17:10,980
like all possible World futures

339
00:17:10,980 --> 00:17:13,679
we're conditioning on action

340
00:17:13,679 --> 00:17:15,660
and we're interested in we're reducing

341
00:17:15,660 --> 00:17:17,280
our uncertainty about which actions to

342
00:17:17,280 --> 00:17:18,660
take

343
00:17:18,660 --> 00:17:20,459
so that's what this first part is saying

344
00:17:20,459 --> 00:17:22,799
so expectation of the variational

345
00:17:22,799 --> 00:17:24,660
distribution

346
00:17:24,660 --> 00:17:27,500
of upcoming observation sequences

347
00:17:27,500 --> 00:17:30,179
conditioned upon actions policies that

348
00:17:30,179 --> 00:17:31,140
we can take

349
00:17:31,140 --> 00:17:33,600
and

350
00:17:33,600 --> 00:17:35,820
it is going to be

351
00:17:35,820 --> 00:17:36,720
um

352
00:17:36,720 --> 00:17:40,080
a natural log to help facilitate just

353
00:17:40,080 --> 00:17:42,020
all kinds of things that logs facilitate

354
00:17:42,020 --> 00:17:45,539
but it's it's a monotonic relationship

355
00:17:45,539 --> 00:17:46,740
with

356
00:17:46,740 --> 00:17:49,260
what is being described here

357
00:17:49,260 --> 00:17:50,960
and this is about

358
00:17:50,960 --> 00:17:53,940
observations conditioned on preferences

359
00:17:53,940 --> 00:17:55,380
C

360
00:17:55,380 --> 00:17:58,500
so where observations

361
00:17:58,500 --> 00:18:01,280
are close to preferences

362
00:18:01,280 --> 00:18:04,200
pragmatic value is high

363
00:18:04,200 --> 00:18:06,900
where are observations are different

364
00:18:06,900 --> 00:18:09,840
than our preferences pragmatic value is

365
00:18:09,840 --> 00:18:11,340
low

366
00:18:11,340 --> 00:18:13,860
rather than associating pragmatic value

367
00:18:13,860 --> 00:18:16,799
with a reward function

368
00:18:16,799 --> 00:18:19,080
we're associating it with bounding our

369
00:18:19,080 --> 00:18:20,700
surprise

370
00:18:20,700 --> 00:18:22,280
natural log

371
00:18:22,280 --> 00:18:25,200
self-information surprisal

372
00:18:25,200 --> 00:18:30,200
of our preference slash expectation

373
00:18:32,280 --> 00:18:35,340
the epistemic value component

374
00:18:35,340 --> 00:18:37,440
which can be kind of seen as like a sub

375
00:18:37,440 --> 00:18:41,580
function with like a negative I

376
00:18:41,580 --> 00:18:42,539
um

377
00:18:42,539 --> 00:18:44,400
but it's interesting that also that this

378
00:18:44,400 --> 00:18:47,460
is kind of a surprisal like

379
00:18:47,460 --> 00:18:50,520
um like even pragmatic value

380
00:18:50,520 --> 00:18:53,780
enters into an information theoretic

381
00:18:53,780 --> 00:18:57,480
surprise like formulation

382
00:18:57,480 --> 00:18:59,580
so even our pragmatic value is still

383
00:18:59,580 --> 00:19:01,919
informational

384
00:19:01,919 --> 00:19:03,299
it's not

385
00:19:03,299 --> 00:19:04,980
you know

386
00:19:04,980 --> 00:19:07,700
tokens

387
00:19:07,799 --> 00:19:10,919
here we see again an expectation over

388
00:19:10,919 --> 00:19:13,679
our variational distribution but here

389
00:19:13,679 --> 00:19:15,240
rather than on the sequence of

390
00:19:15,240 --> 00:19:17,820
observations through time otilda it's

391
00:19:17,820 --> 00:19:19,440
the sequence of hidden States Through

392
00:19:19,440 --> 00:19:20,820
Time

393
00:19:20,820 --> 00:19:22,620
so this is

394
00:19:22,620 --> 00:19:25,140
um now looking at

395
00:19:25,140 --> 00:19:27,720
underlying latent States conditioned

396
00:19:27,720 --> 00:19:29,400
upon policy

397
00:19:29,400 --> 00:19:33,000
and there's two there's a difference of

398
00:19:33,000 --> 00:19:36,480
two entropies

399
00:19:36,480 --> 00:19:39,720
then here's P which is like the the kind

400
00:19:39,720 --> 00:19:42,179
of actual distribution and then Q the

401
00:19:42,179 --> 00:19:45,179
distribution we control

402
00:19:45,179 --> 00:19:48,120
now within the parentheses o tilde in

403
00:19:48,120 --> 00:19:49,919
both case

404
00:19:49,919 --> 00:19:53,100
o tilde conditioned upon States

405
00:19:53,100 --> 00:19:57,059
minus o tilde conditioned upon policies

406
00:19:57,059 --> 00:19:58,679
so there's definitely a few ways to

407
00:19:58,679 --> 00:20:01,620
unpack it and I think we've we've um

408
00:20:01,620 --> 00:20:04,020
explored sum

409
00:20:04,020 --> 00:20:06,419
but um

410
00:20:06,419 --> 00:20:08,460
broadly

411
00:20:08,460 --> 00:20:11,220
if the policy

412
00:20:11,220 --> 00:20:15,600
is not further reducing your uncertainty

413
00:20:15,600 --> 00:20:18,600
about this relationship

414
00:20:18,600 --> 00:20:22,260
the epistemic value is low

415
00:20:22,260 --> 00:20:24,299
if the policy

416
00:20:24,299 --> 00:20:26,940
is reducing your uncertainty

417
00:20:26,940 --> 00:20:28,919
about s

418
00:20:28,919 --> 00:20:31,200
via o

419
00:20:31,200 --> 00:20:35,600
then there's epistemic value

420
00:20:35,640 --> 00:20:37,020
I think there's like a lot of open

421
00:20:37,020 --> 00:20:41,039
questions that are pretty contextual

422
00:20:41,039 --> 00:20:44,720
like how do these implicit or tacit

423
00:20:44,720 --> 00:20:47,280
understandings like how does the rat

424
00:20:47,280 --> 00:20:51,000
know that going to that Q location is

425
00:20:51,000 --> 00:20:52,980
going to reduce its uncertainty

426
00:20:52,980 --> 00:20:55,500
how does it know the semantics of the

427
00:20:55,500 --> 00:20:57,600
left versus the right cue

428
00:20:57,600 --> 00:20:59,820
how does it know what you know

429
00:20:59,820 --> 00:21:02,400
this is not the whole story

430
00:21:02,400 --> 00:21:04,320
but within the context of doing

431
00:21:04,320 --> 00:21:07,440
variational inference on a structurally

432
00:21:07,440 --> 00:21:10,380
determined model

433
00:21:10,380 --> 00:21:15,000
this is the basis of the separation

434
00:21:15,000 --> 00:21:18,240
between pragmatic value defined as

435
00:21:18,240 --> 00:21:20,100
alignment between observations and

436
00:21:20,100 --> 00:21:21,240
preferences

437
00:21:21,240 --> 00:21:24,360
and epistemic value defined as reduction

438
00:21:24,360 --> 00:21:27,660
of uncertainty which is to say entropy

439
00:21:27,660 --> 00:21:29,940
of how policies sharpen our

440
00:21:29,940 --> 00:21:31,980
understanding of the relationship

441
00:21:31,980 --> 00:21:33,720
between hidden States and observations

442
00:21:33,720 --> 00:21:36,440
Michael

443
00:21:37,740 --> 00:21:40,260
yeah so so both of these are

444
00:21:40,260 --> 00:21:42,720
expectations so that

445
00:21:42,720 --> 00:21:43,260
um

446
00:21:43,260 --> 00:21:46,500
that is with respect to Future

447
00:21:46,500 --> 00:21:49,140
things that might happen

448
00:21:49,140 --> 00:21:51,299
both these expectations are actually in

449
00:21:51,299 --> 00:21:53,820
the used in a sense of a mean the time

450
00:21:53,820 --> 00:21:57,840
Horizon is implicit within pi

451
00:21:57,840 --> 00:22:00,000
whether that is being calculated whether

452
00:22:00,000 --> 00:22:02,640
G is being calculated over Pi of length

453
00:22:02,640 --> 00:22:04,740
one two three Etc in the discrete time

454
00:22:04,740 --> 00:22:07,559
formalization but these expectations are

455
00:22:07,559 --> 00:22:10,620
actually like center of gravity LaPlace

456
00:22:10,620 --> 00:22:13,760
approximation Central limit theorem

457
00:22:13,760 --> 00:22:17,340
think expectation of a distribution even

458
00:22:17,340 --> 00:22:19,380
though it's like about the future

459
00:22:19,380 --> 00:22:21,179
we're actually Computing like the center

460
00:22:21,179 --> 00:22:22,919
of gravity

461
00:22:22,919 --> 00:22:25,740
or policies of different times but we're

462
00:22:25,740 --> 00:22:28,320
not funny enough like like we are but we

463
00:22:28,320 --> 00:22:31,020
aren't talking about future time

464
00:22:31,020 --> 00:22:33,960
okay so what I maybe don't really

465
00:22:33,960 --> 00:22:35,460
understand here is the difference

466
00:22:35,460 --> 00:22:39,480
between p and Q I I was of the

467
00:22:39,480 --> 00:22:41,820
understanding that P is something that

468
00:22:41,820 --> 00:22:42,780
we

469
00:22:42,780 --> 00:22:45,419
uh that is present in the in the

470
00:22:45,419 --> 00:22:48,539
presence that we experience and Pew is

471
00:22:48,539 --> 00:22:51,059
something that happens in the future

472
00:22:51,059 --> 00:22:55,559
now I'm a little bit confused because p

473
00:22:55,559 --> 00:22:58,020
and Q both relate here in this equation

474
00:22:58,020 --> 00:23:01,919
to the Future right so how can this be

475
00:23:01,919 --> 00:23:04,400
understood

476
00:23:06,659 --> 00:23:08,820
um the difference between p and Q is not

477
00:23:08,820 --> 00:23:11,100
between the present and the future

478
00:23:11,100 --> 00:23:14,220
p is like the underlying

479
00:23:14,220 --> 00:23:17,039
distribution and Q is our variational

480
00:23:17,039 --> 00:23:19,940
approximation

481
00:23:21,720 --> 00:23:24,480
so this is like the actual entropy of

482
00:23:24,480 --> 00:23:25,799
the relationship

483
00:23:25,799 --> 00:23:29,940
between observations and hidden States

484
00:23:29,940 --> 00:23:33,419
whereas this is the relationship of the

485
00:23:33,419 --> 00:23:35,340
entropy

486
00:23:35,340 --> 00:23:39,600
um the entropy of the variational

487
00:23:39,600 --> 00:23:42,000
generative models relationship between

488
00:23:42,000 --> 00:23:45,020
those two Ali

489
00:23:46,080 --> 00:23:49,220
uh yeah I think uh equation

490
00:23:49,220 --> 00:23:54,659
2.3 might tell to somehow clarify that

491
00:23:54,659 --> 00:23:59,460
ambiguity between p and Q because in

492
00:23:59,460 --> 00:24:01,440
equation 2.3

493
00:24:01,440 --> 00:24:02,900
um yeah that's it

494
00:24:02,900 --> 00:24:07,500
the KL Divergence between

495
00:24:07,500 --> 00:24:11,880
q and P is defined as the expectation

496
00:24:11,880 --> 00:24:14,580
between the surprisal of Q and so the

497
00:24:14,580 --> 00:24:18,179
surprise Loop p and one interesting

498
00:24:18,179 --> 00:24:23,539
thing about equation 7.4 is that the

499
00:24:23,539 --> 00:24:27,179
epistemic value is the expectation with

500
00:24:27,179 --> 00:24:31,140
respect to the hidden States but the

501
00:24:31,140 --> 00:24:34,080
pragmatic value is the expectation with

502
00:24:34,080 --> 00:24:36,860
respect to the observations

503
00:24:36,860 --> 00:24:41,100
so we need to keep both of them in mind

504
00:24:41,100 --> 00:24:45,780
because here as Daniel just mentioned p

505
00:24:45,780 --> 00:24:48,179
is just the

506
00:24:48,179 --> 00:24:53,039
uh Q is the variational

507
00:24:53,039 --> 00:24:57,539
um I mean the free energy but p is the

508
00:24:57,539 --> 00:25:00,240
standard posterior the the standard

509
00:25:00,240 --> 00:25:04,080
probability function we apply to a

510
00:25:04,080 --> 00:25:08,039
random variable uh so that's why uh they

511
00:25:08,039 --> 00:25:11,760
have distinguished between those two

512
00:25:11,760 --> 00:25:15,000
um those two functions uh because a q

513
00:25:15,000 --> 00:25:17,340
has uh some

514
00:25:17,340 --> 00:25:19,700
um a specific

515
00:25:19,700 --> 00:25:22,260
definition so for example in equation

516
00:25:22,260 --> 00:25:28,860
2.2 uh the probability of P without any

517
00:25:28,860 --> 00:25:32,419
uh yeah that's it that's just the simple

518
00:25:32,419 --> 00:25:36,840
derivation of the probability of uh a

519
00:25:36,840 --> 00:25:39,020
random variable being

520
00:25:39,020 --> 00:25:42,380
of a specific value is calculated

521
00:25:42,380 --> 00:25:46,799
without uh taken into account cues or

522
00:25:46,799 --> 00:25:49,679
other parameters servers

523
00:25:49,679 --> 00:25:52,799
nice yes the fact that pragmatic value

524
00:25:52,799 --> 00:25:54,960
is associated with outcomes

525
00:25:54,960 --> 00:25:57,900
is what ties closely to perceptual

526
00:25:57,900 --> 00:25:59,940
control theory

527
00:25:59,940 --> 00:26:02,460
and the fact that epistemic value is

528
00:26:02,460 --> 00:26:04,980
associated with hidden States is related

529
00:26:04,980 --> 00:26:06,179
to

530
00:26:06,179 --> 00:26:08,100
the

531
00:26:08,100 --> 00:26:09,059
um

532
00:26:09,059 --> 00:26:12,299
avoidal of overfitting

533
00:26:12,299 --> 00:26:14,340
we're not reducing our epistemic value

534
00:26:14,340 --> 00:26:16,740
on observations

535
00:26:16,740 --> 00:26:19,140
observations are being evaluated for

536
00:26:19,140 --> 00:26:21,360
their pragmatic value hidden State

537
00:26:21,360 --> 00:26:25,620
inferences are being evaluated and and

538
00:26:25,620 --> 00:26:28,320
through them policies are being

539
00:26:28,320 --> 00:26:31,020
evaluated for their epistemic value

540
00:26:31,020 --> 00:26:33,500
Michael

541
00:26:37,200 --> 00:26:39,299
yeah so

542
00:26:39,299 --> 00:26:43,740
I'm a little bit confused about about

543
00:26:43,740 --> 00:26:47,580
this you said that cure relates to the

544
00:26:47,580 --> 00:26:49,799
variational free energy

545
00:26:49,799 --> 00:26:52,919
but the variation of free energy I mean

546
00:26:52,919 --> 00:26:56,120
we made this distinction between the G

547
00:26:56,120 --> 00:26:59,700
which is the expected free energy and

548
00:26:59,700 --> 00:27:01,679
the F which is the variation of free

549
00:27:01,679 --> 00:27:04,980
energy and now inside that expected free

550
00:27:04,980 --> 00:27:08,460
energy is a variational free energy and

551
00:27:08,460 --> 00:27:12,120
so yeah just to be clear cues the

552
00:27:12,120 --> 00:27:14,640
variational distribution this is the guy

553
00:27:14,640 --> 00:27:15,720
we control

554
00:27:15,720 --> 00:27:17,940
accuse the guy we control

555
00:27:17,940 --> 00:27:21,240
P we don't mind your p's and q's Q is

556
00:27:21,240 --> 00:27:22,980
the one we control

557
00:27:22,980 --> 00:27:25,140
variational free energy

558
00:27:25,140 --> 00:27:28,140
is a real-time functional

559
00:27:28,140 --> 00:27:30,360
that's a function of

560
00:27:30,360 --> 00:27:33,539
our variational density q and incoming

561
00:27:33,539 --> 00:27:37,460
data it doesn't engage with planning

562
00:27:37,460 --> 00:27:39,659
expected free energy

563
00:27:39,659 --> 00:27:41,039
and

564
00:27:41,039 --> 00:27:45,419
a host of cousins like free energy of

565
00:27:45,419 --> 00:27:47,940
the expected future that Baron millage

566
00:27:47,940 --> 00:27:49,260
and others have proposed so this is not

567
00:27:49,260 --> 00:27:50,880
like the only way to even do this

568
00:27:50,880 --> 00:27:53,760
energy-based method in the future

569
00:27:53,760 --> 00:27:54,419
um

570
00:27:54,419 --> 00:27:58,679
this is rather than a function of

571
00:27:58,679 --> 00:28:01,980
um taking in only q and Y as arguments

572
00:28:01,980 --> 00:28:06,419
here the primary argument is the policy

573
00:28:06,419 --> 00:28:08,220
prior vector

574
00:28:08,220 --> 00:28:10,860
and then the computation of this

575
00:28:10,860 --> 00:28:13,860
functional involves

576
00:28:13,860 --> 00:28:17,779
Q the variational distribution

577
00:28:18,659 --> 00:28:20,520
but like Q could be a gaussian

578
00:28:20,520 --> 00:28:21,900
distribution

579
00:28:21,900 --> 00:28:24,059
so we'd be looking to parameterize the

580
00:28:24,059 --> 00:28:26,520
variational parameters you know the

581
00:28:26,520 --> 00:28:29,340
median and the variance

582
00:28:29,340 --> 00:28:32,700
the two parameters of a gaussian

583
00:28:32,700 --> 00:28:35,039
and the true

584
00:28:35,039 --> 00:28:38,700
generative process may not be gaussian

585
00:28:38,700 --> 00:28:41,400
but we would be looking just like in a

586
00:28:41,400 --> 00:28:43,020
linear regression we'd be looking to

587
00:28:43,020 --> 00:28:45,299
minimize the sum of squares with the L2

588
00:28:45,299 --> 00:28:46,679
Norm

589
00:28:46,679 --> 00:28:49,380
in this variational inference setting

590
00:28:49,380 --> 00:28:51,900
we'd be looking to fit the best gaussian

591
00:28:51,900 --> 00:28:55,640
mean and variance

592
00:28:55,799 --> 00:28:57,960
given the the family of the variational

593
00:28:57,960 --> 00:29:01,700
distributions that we had chosen

594
00:29:03,179 --> 00:29:06,140
foreign

595
00:29:08,299 --> 00:29:13,200
yeah so one other angle can be e is

596
00:29:13,200 --> 00:29:15,900
actually the actual posterior

597
00:29:15,900 --> 00:29:21,120
probability uh that uh is calculated uh

598
00:29:21,120 --> 00:29:24,899
according to the actual States

599
00:29:24,899 --> 00:29:28,740
um we have at our disposal but Q is the

600
00:29:28,740 --> 00:29:31,320
approximate posterior so it's not the

601
00:29:31,320 --> 00:29:33,919
exact posterior

602
00:29:33,919 --> 00:29:38,220
that has been calculated in P but yeah Q

603
00:29:38,220 --> 00:29:41,460
is related to variation of free energy

604
00:29:41,460 --> 00:29:44,159
in the sense that it's deployed in

605
00:29:44,159 --> 00:29:46,140
calculating the variation of free energy

606
00:29:46,140 --> 00:29:48,679
because

607
00:29:48,679 --> 00:29:53,399
for the in order for the free energy to

608
00:29:53,399 --> 00:29:58,220
be uh attractable parameter uh to be

609
00:29:58,220 --> 00:30:01,919
I mean implementable in a computational

610
00:30:01,919 --> 00:30:05,520
task we need to use this approximate

611
00:30:05,520 --> 00:30:07,320
variation of free energy because

612
00:30:07,320 --> 00:30:12,659
otherwise we don't have uh either all

613
00:30:12,659 --> 00:30:16,799
the information we need to calculate the

614
00:30:16,799 --> 00:30:21,720
exact posteriors or it's too intractable

615
00:30:21,720 --> 00:30:24,419
to compute so that's the reason behind

616
00:30:24,419 --> 00:30:27,299
using approximate variational free

617
00:30:27,299 --> 00:30:29,600
energy

618
00:30:30,000 --> 00:30:33,120
great and I think one kind of as a

619
00:30:33,120 --> 00:30:35,340
valiant this idea of like probably

620
00:30:35,340 --> 00:30:38,340
approximately correct

621
00:30:38,340 --> 00:30:39,480
which is kind of like when they say

622
00:30:39,480 --> 00:30:40,799
almost surely

623
00:30:40,799 --> 00:30:44,880
in math but more on the statistics side

624
00:30:44,880 --> 00:30:46,799
if it's probably approximately correct

625
00:30:46,799 --> 00:30:50,419
it's like actually within the context of

626
00:30:50,419 --> 00:30:53,100
approximate Bays

627
00:30:53,100 --> 00:30:55,020
that is what

628
00:30:55,020 --> 00:30:57,240
is going to be

629
00:30:57,240 --> 00:30:59,220
not just good enough but like as good as

630
00:30:59,220 --> 00:31:01,919
you can kind of aim for

631
00:31:01,919 --> 00:31:02,460
um

632
00:31:02,460 --> 00:31:03,740
okay

633
00:31:03,740 --> 00:31:07,620
matrices are defined

634
00:31:07,620 --> 00:31:10,919
a has two slices

635
00:31:10,919 --> 00:31:13,860
A1 and A2 are we going to give it as two

636
00:31:13,860 --> 00:31:16,140
modalities of a

637
00:31:16,140 --> 00:31:18,419
and the dimensionality

638
00:31:18,419 --> 00:31:20,220
is

639
00:31:20,220 --> 00:31:23,880
clear in the Matlab implementations it's

640
00:31:23,880 --> 00:31:26,220
clear in the pi mdp it's not exactly

641
00:31:26,220 --> 00:31:28,559
exactly the same syntax but like the

642
00:31:28,559 --> 00:31:30,000
structure

643
00:31:30,000 --> 00:31:32,640
of these matrices in principle are the

644
00:31:32,640 --> 00:31:33,720
same

645
00:31:33,720 --> 00:31:35,899
foreign

646
00:31:37,380 --> 00:31:39,840
is describing

647
00:31:39,840 --> 00:31:41,840
um

648
00:31:42,480 --> 00:31:44,399
the probabilistic mapping from location

649
00:31:44,399 --> 00:31:47,279
to exteroceptive cues

650
00:31:47,279 --> 00:31:51,059
so it's not exactly an identity Matrix

651
00:31:51,059 --> 00:31:53,520
but basically this is the accurate GPS

652
00:31:53,520 --> 00:31:56,580
sensor when it's at this location start

653
00:31:56,580 --> 00:31:59,279
location it knows exactly where it is

654
00:31:59,279 --> 00:32:00,539
so again you can be like well how does

655
00:32:00,539 --> 00:32:02,520
it get this implicit knowledge of where

656
00:32:02,520 --> 00:32:03,899
it is

657
00:32:03,899 --> 00:32:06,899
right that's part of the complexity of

658
00:32:06,899 --> 00:32:09,659
cognitive modeling but suffice to say

659
00:32:09,659 --> 00:32:12,360
that we're in a setting where the

660
00:32:12,360 --> 00:32:15,120
location is known without error

661
00:32:15,120 --> 00:32:17,340
but one can imagine that there would be

662
00:32:17,340 --> 00:32:20,279
different outcomes and the need to do

663
00:32:20,279 --> 00:32:22,200
different parameterizations if like

664
00:32:22,200 --> 00:32:25,200
there were off diagonal elements

665
00:32:25,200 --> 00:32:26,640
A2

666
00:32:26,640 --> 00:32:29,159
is the um

667
00:32:29,159 --> 00:32:30,779
probability

668
00:32:30,779 --> 00:32:33,899
so they sum across to one

669
00:32:33,899 --> 00:32:36,120
um or I'm sorry they they call them sum

670
00:32:36,120 --> 00:32:37,860
to one

671
00:32:37,860 --> 00:32:38,760
um

672
00:32:38,760 --> 00:32:40,200
about

673
00:32:40,200 --> 00:32:43,440
the the food location

674
00:32:43,440 --> 00:32:45,720
the the between the spatial location and

675
00:32:45,720 --> 00:32:47,279
then the outcome of food

676
00:32:47,279 --> 00:32:49,860
so semantically this represents beliefs

677
00:32:49,860 --> 00:32:52,679
about food location

678
00:32:52,679 --> 00:32:55,140
in the a

679
00:32:55,140 --> 00:32:56,279
here

680
00:32:56,279 --> 00:32:59,399
7.5 is the same as 7.4 it's just that

681
00:32:59,399 --> 00:33:01,500
here it's like two in the upper left 98

682
00:33:01,500 --> 00:33:02,880
on the off

683
00:33:02,880 --> 00:33:05,159
here we see 98 on the upper left two on

684
00:33:05,159 --> 00:33:06,899
the off

685
00:33:06,899 --> 00:33:09,840
here we have one in the third row empty

686
00:33:09,840 --> 00:33:12,000
on the second here those two rows have

687
00:33:12,000 --> 00:33:14,640
been flipped to represent the block on

688
00:33:14,640 --> 00:33:15,779
the left side

689
00:33:15,779 --> 00:33:18,360
versus the block on the right side

690
00:33:18,360 --> 00:33:19,559
so

691
00:33:19,559 --> 00:33:21,179
the food can be either on the left or

692
00:33:21,179 --> 00:33:22,320
the right side

693
00:33:22,320 --> 00:33:25,500
the rat can either make the move

694
00:33:25,500 --> 00:33:27,899
to go to the left or the right side or

695
00:33:27,899 --> 00:33:30,659
can go to the Q

696
00:33:30,659 --> 00:33:34,080
if it decides to go for the Q

697
00:33:34,080 --> 00:33:37,320
um not the Q letter but the c-u-e

698
00:33:37,320 --> 00:33:38,640
if it decides to receive an

699
00:33:38,640 --> 00:33:40,200
informational cue

700
00:33:40,200 --> 00:33:42,059
then

701
00:33:42,059 --> 00:33:42,600
um

702
00:33:42,600 --> 00:33:45,240
it will find out where the food is again

703
00:33:45,240 --> 00:33:47,820
check out model stream 7.2 with the

704
00:33:47,820 --> 00:33:49,740
epistemic foraging and all of that sort

705
00:33:49,740 --> 00:33:54,080
of um stuff okay

706
00:33:54,240 --> 00:33:56,039
these

707
00:33:56,039 --> 00:33:58,140
slices of B

708
00:33:58,140 --> 00:34:02,519
are describing movement affordances

709
00:34:02,519 --> 00:34:04,679
because again with respect to the hidden

710
00:34:04,679 --> 00:34:08,699
State being location B describes how

711
00:34:08,699 --> 00:34:11,760
different policy selection

712
00:34:11,760 --> 00:34:13,980
Bears upon hidden States changing

713
00:34:13,980 --> 00:34:16,339
Through Time

714
00:34:17,879 --> 00:34:23,399
C is describing the relative preference

715
00:34:23,399 --> 00:34:26,699
for different outcomes

716
00:34:26,699 --> 00:34:28,379
so

717
00:34:28,379 --> 00:34:29,399
um

718
00:34:29,399 --> 00:34:31,440
the C1 vector

719
00:34:31,440 --> 00:34:34,020
is about the first modality

720
00:34:34,020 --> 00:34:36,418
five of them that's the locations and

721
00:34:36,418 --> 00:34:37,679
there's a negative for the starting

722
00:34:37,679 --> 00:34:39,000
location

723
00:34:39,000 --> 00:34:40,440
so that's like a little bit of like a

724
00:34:40,440 --> 00:34:43,080
like a kind of get going

725
00:34:43,080 --> 00:34:44,399
because if it preferred to start

726
00:34:44,399 --> 00:34:46,800
location it might just stay there

727
00:34:46,800 --> 00:34:49,320
then in the second modality

728
00:34:49,320 --> 00:34:52,199
that's referring to this shorter Vector

729
00:34:52,199 --> 00:34:55,859
of these one two three and that's these

730
00:34:55,859 --> 00:34:58,639
one two three

731
00:34:59,220 --> 00:35:00,900
um

732
00:35:00,900 --> 00:35:03,480
in various modeling settings we've

733
00:35:03,480 --> 00:35:06,480
already started to see that like the C

734
00:35:06,480 --> 00:35:09,420
scaling matters a lot

735
00:35:09,420 --> 00:35:12,180
and so that's one reason why I think

736
00:35:12,180 --> 00:35:14,940
it's tentative or hypothetical to say

737
00:35:14,940 --> 00:35:17,880
that simply like equation 7.4 resolves

738
00:35:17,880 --> 00:35:19,680
explore exploit

739
00:35:19,680 --> 00:35:24,240
because it sets up the space for explore

740
00:35:24,240 --> 00:35:28,079
exploit to be framed absolutely it does

741
00:35:28,079 --> 00:35:29,700
however

742
00:35:29,700 --> 00:35:31,920
depending on how the variables are

743
00:35:31,920 --> 00:35:33,599
parameterized

744
00:35:33,599 --> 00:35:35,760
you can end up with an agent who still

745
00:35:35,760 --> 00:35:38,280
goes for the pragmatic value every time

746
00:35:38,280 --> 00:35:39,720
or who still goes for the information

747
00:35:39,720 --> 00:35:41,520
value every time

748
00:35:41,520 --> 00:35:44,640
so in terms of outcomes it's not simply

749
00:35:44,640 --> 00:35:48,300
resolved by knowing what equation 2.5 is

750
00:35:48,300 --> 00:35:51,359
but rather this opens up a space of

751
00:35:51,359 --> 00:35:52,920
modeling

752
00:35:52,920 --> 00:35:55,859
in which adaptive Solutions can be

753
00:35:55,859 --> 00:35:59,220
reached so if this was six thousand

754
00:35:59,220 --> 00:36:00,920
then

755
00:36:00,920 --> 00:36:04,859
zero six thousand zero it's like reward

756
00:36:04,859 --> 00:36:06,420
is so good

757
00:36:06,420 --> 00:36:08,700
it's going to be pursued if this was

758
00:36:08,700 --> 00:36:11,460
flat zero zero zero then it would be

759
00:36:11,460 --> 00:36:13,619
pure epistemic information

760
00:36:13,619 --> 00:36:16,200
so that's why it's so important that we

761
00:36:16,200 --> 00:36:18,900
develop statistical power methods

762
00:36:18,900 --> 00:36:21,240
and parameter sweeps across simulations

763
00:36:21,240 --> 00:36:24,480
because just making one teammates

764
00:36:24,480 --> 00:36:26,220
and saying like Oh look The Rat does

765
00:36:26,220 --> 00:36:27,839
this or that it's kind of like

766
00:36:27,839 --> 00:36:30,380
okay

767
00:36:30,960 --> 00:36:32,400
d

768
00:36:32,400 --> 00:36:35,760
also is described for the two modalities

769
00:36:35,760 --> 00:36:37,260
and um

770
00:36:37,260 --> 00:36:39,060
it um

771
00:36:39,060 --> 00:36:43,560
describes the priors on the two

772
00:36:43,560 --> 00:36:44,940
there's a belief about the first

773
00:36:44,940 --> 00:36:46,320
location

774
00:36:46,320 --> 00:36:49,380
I'm actually just just I'm a little bit

775
00:36:49,380 --> 00:36:51,720
curious why there's five elements here

776
00:36:51,720 --> 00:36:55,819
but only four elements here

777
00:36:56,400 --> 00:36:58,619
and then in the second modality there

778
00:36:58,619 --> 00:37:00,119
which again is referring maybe this is

779
00:37:00,119 --> 00:37:03,960
like a a minus there's one fewer

780
00:37:03,960 --> 00:37:05,760
um element here because there's only two

781
00:37:05,760 --> 00:37:07,800
here

782
00:37:07,800 --> 00:37:10,560
um here's like reflecting an equal prior

783
00:37:10,560 --> 00:37:12,540
over where the food is

784
00:37:12,540 --> 00:37:16,740
so a priori is 50 50 left or right

785
00:37:16,740 --> 00:37:20,339
so do you go do a 50 50 bet left or

786
00:37:20,339 --> 00:37:21,720
right on the food

787
00:37:21,720 --> 00:37:26,820
or do you go to get the epistemic cue

788
00:37:26,820 --> 00:37:28,740
which of course reduces your uncertainty

789
00:37:28,740 --> 00:37:31,380
about where the food is

790
00:37:31,380 --> 00:37:32,700
now we're going to dive a little bit

791
00:37:32,700 --> 00:37:36,540
deeper into epistemic value itself so in

792
00:37:36,540 --> 00:37:39,060
7.4

793
00:37:39,060 --> 00:37:40,800
they're saying we're going to go ahead

794
00:37:40,800 --> 00:37:41,760
and call

795
00:37:41,760 --> 00:37:44,000
just the epistemic value

796
00:37:44,000 --> 00:37:47,160
decomposition term

797
00:37:47,160 --> 00:37:49,640
I

798
00:37:54,480 --> 00:37:57,000
equation 7.8

799
00:37:57,000 --> 00:38:00,119
so here is just a separation of our as

800
00:38:00,119 --> 00:38:03,119
it was written in the prior equation

801
00:38:03,119 --> 00:38:06,240
that is going to be Rewritten

802
00:38:06,240 --> 00:38:10,399
in terms of a KL Divergence

803
00:38:12,900 --> 00:38:16,200
q s and Pi q and s and Pi they're the

804
00:38:16,200 --> 00:38:18,420
same on both sides

805
00:38:18,420 --> 00:38:23,359
here's POS here's q o pi

806
00:38:23,520 --> 00:38:26,520
and it's it's definitely worthwhile I

807
00:38:26,520 --> 00:38:29,280
think for us to write out what these

808
00:38:29,280 --> 00:38:31,920
verbally mean because they have very

809
00:38:31,920 --> 00:38:35,119
I think interesting

810
00:38:35,160 --> 00:38:38,040
um implications for again like what is

811
00:38:38,040 --> 00:38:40,800
the epistemic value

812
00:38:40,800 --> 00:38:44,579
and then here is um with this

813
00:38:44,579 --> 00:38:46,859
semicolon being noted

814
00:38:46,859 --> 00:38:49,200
this is reflecting a pure Information

815
00:38:49,200 --> 00:38:52,020
Gain salience Bayesian surprise

816
00:38:52,020 --> 00:38:54,740
imperative

817
00:38:56,339 --> 00:38:59,420
here's some simulations

818
00:38:59,520 --> 00:39:02,640
showing at like time two it goes to the

819
00:39:02,640 --> 00:39:04,560
to the get the information and then it

820
00:39:04,560 --> 00:39:08,339
proceeds to the left Ali

821
00:39:08,339 --> 00:39:11,160
uh yeah just about your previous remark

822
00:39:11,160 --> 00:39:15,839
about uh why C has the five elements and

823
00:39:15,839 --> 00:39:19,619
D the C is four elements because uh C

824
00:39:19,619 --> 00:39:23,040
actually uh corresponds with the the

825
00:39:23,040 --> 00:39:27,060
elements of a matrices so because a

826
00:39:27,060 --> 00:39:32,520
matrices uh actually describe uh the uh

827
00:39:32,520 --> 00:39:36,359
the hidden the states that the

828
00:39:36,359 --> 00:39:37,920
environment

829
00:39:37,920 --> 00:39:43,160
um uh is dealing with but because D is

830
00:39:43,160 --> 00:39:47,040
corresponds with B Matrix and uh because

831
00:39:47,040 --> 00:39:49,980
B Matrix is a transition Matrix uh

832
00:39:49,980 --> 00:39:54,420
that's why uh we don't need to have a

833
00:39:54,420 --> 00:39:57,900
redundant additional element for that so

834
00:39:57,900 --> 00:40:03,359
D being priors yet Maps unto B Matrix

835
00:40:03,359 --> 00:40:06,119
thanks and right now like you have to

836
00:40:06,119 --> 00:40:08,040
like specify the tensor dimensionality

837
00:40:08,040 --> 00:40:09,599
and add some labels but they're

838
00:40:09,599 --> 00:40:11,579
developing a lot of functions in pi mdp

839
00:40:11,579 --> 00:40:13,320
and people who work with it can

840
00:40:13,320 --> 00:40:15,300
definitely have a lot of feedback

841
00:40:15,300 --> 00:40:19,680
on slightly more intuitive

842
00:40:19,680 --> 00:40:21,780
and scalable ways to specify

843
00:40:21,780 --> 00:40:23,940
dimensionality which is currently one of

844
00:40:23,940 --> 00:40:26,760
the rate limiting steps in pi mdp

845
00:40:26,760 --> 00:40:28,260
application

846
00:40:28,260 --> 00:40:29,520
okay

847
00:40:29,520 --> 00:40:31,380
just getting through seven and then just

848
00:40:31,380 --> 00:40:33,359
so we can look ahead to eight continuous

849
00:40:33,359 --> 00:40:37,500
time so Precision at negative entropy

850
00:40:37,500 --> 00:40:39,960
neg entropy this is the high temperature

851
00:40:39,960 --> 00:40:41,960
and low temperature high temperature

852
00:40:41,960 --> 00:40:45,480
differences are erased

853
00:40:45,480 --> 00:40:47,520
low precision

854
00:40:47,520 --> 00:40:50,460
low temperature absolute zero High

855
00:40:50,460 --> 00:40:51,839
precision

856
00:40:51,839 --> 00:40:55,520
differences are accentuated

857
00:40:55,920 --> 00:40:59,280
that has technical

858
00:40:59,280 --> 00:41:01,859
usage

859
00:41:01,859 --> 00:41:04,320
especially

860
00:41:04,320 --> 00:41:08,480
in certain statistical distributions

861
00:41:11,400 --> 00:41:17,420
isocate paradigm par and Frist in 2017.

862
00:41:18,359 --> 00:41:21,180
isicating is

863
00:41:21,180 --> 00:41:24,000
while our eyes may dwell on what we may

864
00:41:24,000 --> 00:41:27,859
associate with pragmatically valuable

865
00:41:28,920 --> 00:41:32,460
broadly speaking isocating is driven by

866
00:41:32,460 --> 00:41:35,359
Information Gain

867
00:41:35,940 --> 00:41:40,040
so it's a great place to study how

868
00:41:40,040 --> 00:41:44,040
pragmatic semantics

869
00:41:44,760 --> 00:41:47,839
at a higher level

870
00:41:48,180 --> 00:41:50,160
are in a predictive processing type

871
00:41:50,160 --> 00:41:51,960
relationship

872
00:41:51,960 --> 00:41:56,160
with isicating at a lower mechanical

873
00:41:56,160 --> 00:41:58,020
level

874
00:41:58,020 --> 00:42:01,079
with this level almost surely being

875
00:42:01,079 --> 00:42:04,520
driven by Information Gain

876
00:42:05,220 --> 00:42:07,800
learning a novelty here

877
00:42:07,800 --> 00:42:09,300
um one kind of question that was arising

878
00:42:09,300 --> 00:42:11,460
was like why is our dashed line between

879
00:42:11,460 --> 00:42:13,020
only here

880
00:42:13,020 --> 00:42:14,220
but

881
00:42:14,220 --> 00:42:16,079
apart from that

882
00:42:16,079 --> 00:42:18,200
um

883
00:42:18,300 --> 00:42:21,420
priors are being provided

884
00:42:21,420 --> 00:42:23,700
On A and B

885
00:42:23,700 --> 00:42:25,980
so that's sort of like the con again

886
00:42:25,980 --> 00:42:27,960
it's like a little bit like wise B over

887
00:42:27,960 --> 00:42:31,020
here so it's about the topology not not

888
00:42:31,020 --> 00:42:35,180
the geometry in this situation

889
00:42:35,700 --> 00:42:38,460
what's happening is that a prior is

890
00:42:38,460 --> 00:42:40,440
being provided

891
00:42:40,440 --> 00:42:42,599
on a

892
00:42:42,599 --> 00:42:45,780
so that these A and B in principle can

893
00:42:45,780 --> 00:42:46,980
be learnable

894
00:42:46,980 --> 00:42:48,300
how that plays out and how that

895
00:42:48,300 --> 00:42:50,160
influences the pseudocode of the action

896
00:42:50,160 --> 00:42:51,480
perception Loop

897
00:42:51,480 --> 00:42:55,339
Pi mdp is very clear about that

898
00:42:55,619 --> 00:42:58,460
um conjugate priors this is facilitating

899
00:42:58,460 --> 00:43:02,220
like amongst other

900
00:43:02,220 --> 00:43:03,720
um abilities

901
00:43:03,720 --> 00:43:06,720
the the dirichlet conjugate prior for

902
00:43:06,720 --> 00:43:08,940
the categorical distribution so if we

903
00:43:08,940 --> 00:43:10,380
have probability distribution over

904
00:43:10,380 --> 00:43:13,020
categorical outcomes is it hot or cold

905
00:43:13,020 --> 00:43:16,560
then the dear shlay can be used in an

906
00:43:16,560 --> 00:43:18,599
earn counting way

907
00:43:18,599 --> 00:43:21,240
like every time you observe a warm day

908
00:43:21,240 --> 00:43:23,220
or a cold day you just put in a ball of

909
00:43:23,220 --> 00:43:25,200
that color into the urn

910
00:43:25,200 --> 00:43:26,640
and then

911
00:43:26,640 --> 00:43:29,339
it could be 2 and 2 and then the next

912
00:43:29,339 --> 00:43:31,079
ball is very influential it could be a

913
00:43:31,079 --> 00:43:32,339
thousand and a thousand and then the

914
00:43:32,339 --> 00:43:35,460
next ball is not so influential and that

915
00:43:35,460 --> 00:43:37,380
turns out to be what's called a

916
00:43:37,380 --> 00:43:39,839
conjugate prior that enables the

917
00:43:39,839 --> 00:43:42,180
categorical distribution

918
00:43:42,180 --> 00:43:45,060
to stay as a classical probability

919
00:43:45,060 --> 00:43:47,300
distribution

920
00:43:47,300 --> 00:43:49,500
axioms and all of that

921
00:43:49,500 --> 00:43:51,780
while also allowing the conjugate prior

922
00:43:51,780 --> 00:43:54,839
to have this like counting or learning

923
00:43:54,839 --> 00:43:56,220
by Counting

924
00:43:56,220 --> 00:43:59,060
strategy

925
00:43:59,760 --> 00:44:02,220
um inferential approach to learning

926
00:44:02,220 --> 00:44:04,380
this is a difference with many other

927
00:44:04,380 --> 00:44:07,200
areas

928
00:44:07,200 --> 00:44:10,740
they're proposing learning schemes

929
00:44:10,740 --> 00:44:11,880
um

930
00:44:11,880 --> 00:44:14,220
that may or may not be biologically

931
00:44:14,220 --> 00:44:16,440
relevant

932
00:44:16,440 --> 00:44:19,400
whereas a lot of work has gone into

933
00:44:19,400 --> 00:44:22,740
understanding how the perceptual or fast

934
00:44:22,740 --> 00:44:26,099
inference and learning or slower

935
00:44:26,099 --> 00:44:30,680
parameter learning processes are unified

936
00:44:30,680 --> 00:44:33,420
but of distinct time scales and active

937
00:44:33,420 --> 00:44:35,839
inference

938
00:44:36,839 --> 00:44:38,839
um

939
00:44:39,359 --> 00:44:43,859
here in 7 11 equation they are going to

940
00:44:43,859 --> 00:44:48,839
delve more into like learning as active

941
00:44:48,839 --> 00:44:50,280
yes

942
00:44:50,280 --> 00:44:52,619
it's about policy everything's being

943
00:44:52,619 --> 00:44:55,440
conditioned upon policy

944
00:44:55,440 --> 00:44:57,720
there's a lot that one can say about the

945
00:44:57,720 --> 00:45:00,180
integration of action so this maze

946
00:45:00,180 --> 00:45:02,220
learning task

947
00:45:02,220 --> 00:45:05,280
is fundamentally intertwined

948
00:45:05,280 --> 00:45:08,579
with the action selection

949
00:45:08,579 --> 00:45:11,300
the agents updating of their likelihood

950
00:45:11,300 --> 00:45:13,980
is related to their action selection

951
00:45:13,980 --> 00:45:16,020
amidst uncertainty

952
00:45:16,020 --> 00:45:18,420
they're not seen as like two separated

953
00:45:18,420 --> 00:45:20,460
phases

954
00:45:20,460 --> 00:45:21,300
um

955
00:45:21,300 --> 00:45:24,000
here's where they just drop some kind of

956
00:45:24,000 --> 00:45:25,680
threads

957
00:45:25,680 --> 00:45:28,020
and further literature maybe further

958
00:45:28,020 --> 00:45:29,520
versions of the textbook are going to

959
00:45:29,520 --> 00:45:31,260
come into more detail hierarchical deep

960
00:45:31,260 --> 00:45:34,380
inference nested modeling

961
00:45:34,380 --> 00:45:36,359
um something that people talk and think

962
00:45:36,359 --> 00:45:37,619
about a lot

963
00:45:37,619 --> 00:45:39,960
but here we see the figure 4.3 or figure

964
00:45:39,960 --> 00:45:41,280
7.3

965
00:45:41,280 --> 00:45:42,960
the rake and the policy selection

966
00:45:42,960 --> 00:45:46,980
fractal it's a rake of rakes

967
00:45:46,980 --> 00:45:48,119
and

968
00:45:48,119 --> 00:45:49,920
structure learning and Bayesian model

969
00:45:49,920 --> 00:45:51,180
reduction

970
00:45:51,180 --> 00:45:53,940
just some model comparison and Analysis

971
00:45:53,940 --> 00:45:55,680
techniques that support Bayesian

972
00:45:55,680 --> 00:45:57,839
statistics

973
00:45:57,839 --> 00:45:59,339
um

974
00:45:59,339 --> 00:46:01,020
another example

975
00:46:01,020 --> 00:46:03,200
involving a hierarchical inference model

976
00:46:03,200 --> 00:46:05,640
is described

977
00:46:05,640 --> 00:46:08,099
and that has been used in the context of

978
00:46:08,099 --> 00:46:13,079
reading and other visual inference tasks

979
00:46:13,079 --> 00:46:15,599
that's chapter seven let's quickly look

980
00:46:15,599 --> 00:46:17,099
to chapter eight

981
00:46:17,099 --> 00:46:19,680
chapter seven was discrete time

982
00:46:19,680 --> 00:46:22,380
generative models chapter 8 is going to

983
00:46:22,380 --> 00:46:26,160
be continuous time generative models

984
00:46:26,160 --> 00:46:28,260
the main setting in which discrete time

985
00:46:28,260 --> 00:46:31,440
models have been studied is

986
00:46:31,440 --> 00:46:33,599
Central or cognitive decision making

987
00:46:33,599 --> 00:46:35,940
categorical decision making

988
00:46:35,940 --> 00:46:38,880
in contrast the major setting in which

989
00:46:38,880 --> 00:46:40,980
continuous time active inference models

990
00:46:40,980 --> 00:46:43,800
to this time have been used in is in

991
00:46:43,800 --> 00:46:46,920
continuous movement or motor control

992
00:46:46,920 --> 00:46:50,819
tasks so like in live stream 46 active

993
00:46:50,819 --> 00:46:52,800
models do not contradict folk psychology

994
00:46:52,800 --> 00:46:55,859
with Alex Kiefer Ryan Smith and Maxwell

995
00:46:55,859 --> 00:46:58,859
ramstead they talk about like motor AI

996
00:46:58,859 --> 00:47:03,900
Mai and decision active inference Dai

997
00:47:03,900 --> 00:47:05,579
um

998
00:47:05,579 --> 00:47:06,960
here

999
00:47:06,960 --> 00:47:11,000
there's going to be a um

1000
00:47:11,280 --> 00:47:14,160
Proto Bayesian physics like

1001
00:47:14,160 --> 00:47:17,220
representation that's going to enable us

1002
00:47:17,220 --> 00:47:20,400
to do continuous things

1003
00:47:20,400 --> 00:47:24,359
specifically the separation of a data

1004
00:47:24,359 --> 00:47:25,859
observation

1005
00:47:25,859 --> 00:47:27,180
sequence

1006
00:47:27,180 --> 00:47:28,980
in terms

1007
00:47:28,980 --> 00:47:31,619
of an underlying

1008
00:47:31,619 --> 00:47:32,760
um

1009
00:47:32,760 --> 00:47:35,160
function and a fluctuation stochastic

1010
00:47:35,160 --> 00:47:36,300
term

1011
00:47:36,300 --> 00:47:38,040
and then

1012
00:47:38,040 --> 00:47:40,400
um a latent States

1013
00:47:40,400 --> 00:47:44,339
derivative with a little Dot

1014
00:47:44,339 --> 00:47:46,859
change in latent States as a function of

1015
00:47:46,859 --> 00:47:48,420
the current status of the Hidden State

1016
00:47:48,420 --> 00:47:51,599
and slowly varying causes which are

1017
00:47:51,599 --> 00:47:54,839
going to be playing the role of policies

1018
00:47:54,839 --> 00:47:57,599
in continuous time formulization and

1019
00:47:57,599 --> 00:47:59,819
again partitioning out of our stochastic

1020
00:47:59,819 --> 00:48:02,819
fluctuations so actually this part is

1021
00:48:02,819 --> 00:48:04,920
allowed is this part is guaranteed to

1022
00:48:04,920 --> 00:48:06,900
have zero mean and that's what

1023
00:48:06,900 --> 00:48:08,520
facilitates like Bayesian mechanics a

1024
00:48:08,520 --> 00:48:10,740
lot of other statistics

1025
00:48:10,740 --> 00:48:11,640
um

1026
00:48:11,640 --> 00:48:13,740
again just like quickly looking through

1027
00:48:13,740 --> 00:48:19,200
it this is y g x and F relationships

1028
00:48:19,200 --> 00:48:21,720
continue to be built up

1029
00:48:21,720 --> 00:48:24,119
to again talk and this is very SPM like

1030
00:48:24,119 --> 00:48:26,220
here's our actual sensor readers

1031
00:48:26,220 --> 00:48:30,240
readings from the EEG fmri Meg

1032
00:48:30,240 --> 00:48:32,460
their function of neural activity

1033
00:48:32,460 --> 00:48:35,700
neural activity is a hidden latent state

1034
00:48:35,700 --> 00:48:37,680
it is a function of current neural

1035
00:48:37,680 --> 00:48:42,319
activity and attention for example

1036
00:48:42,839 --> 00:48:44,839
um

1037
00:48:45,540 --> 00:48:48,599
that physics analogy in the continuous

1038
00:48:48,599 --> 00:48:50,579
State space

1039
00:48:50,579 --> 00:48:52,500
can be extended

1040
00:48:52,500 --> 00:48:57,359
into Newtonian Dynamics and as Dalton

1041
00:48:57,359 --> 00:49:00,660
and Bayesian mechanics have

1042
00:49:00,660 --> 00:49:03,660
laid out in the last year or two it goes

1043
00:49:03,660 --> 00:49:06,119
way way further than this

1044
00:49:06,119 --> 00:49:09,240
but this is a spring so this is hooke's

1045
00:49:09,240 --> 00:49:12,599
law as an as a mere active inference

1046
00:49:12,599 --> 00:49:13,680
entity

1047
00:49:13,680 --> 00:49:16,920
this is like a boring active entity that

1048
00:49:16,920 --> 00:49:18,900
just dampens

1049
00:49:18,900 --> 00:49:21,599
but it's just to show that we can

1050
00:49:21,599 --> 00:49:23,460
understand the generalized coordinates

1051
00:49:23,460 --> 00:49:24,839
of motion

1052
00:49:24,839 --> 00:49:27,720
which is to say polish position velocity

1053
00:49:27,720 --> 00:49:29,000
acceleration

1054
00:49:29,000 --> 00:49:31,619
snap crackle pop

1055
00:49:31,619 --> 00:49:33,359
Etc et cetera et cetera generalized

1056
00:49:33,359 --> 00:49:36,180
coordinates of motion within this

1057
00:49:36,180 --> 00:49:39,140
continuous time

1058
00:49:39,300 --> 00:49:41,119
framework

1059
00:49:41,119 --> 00:49:43,200
dynamical systems

1060
00:49:43,200 --> 00:49:45,599
often which are conditioned to be smooth

1061
00:49:45,599 --> 00:49:47,099
and differentiable

1062
00:49:47,099 --> 00:49:50,400
are amenable to continuous time

1063
00:49:50,400 --> 00:49:52,920
formalizations

1064
00:49:52,920 --> 00:49:55,380
in the discrete time we'd say well we

1065
00:49:55,380 --> 00:49:58,079
have you know one two and three and then

1066
00:49:58,079 --> 00:49:59,760
we're going to be moving to one of the

1067
00:49:59,760 --> 00:50:01,380
locations in the grid world

1068
00:50:01,380 --> 00:50:03,000
and we have a transition Matrix over

1069
00:50:03,000 --> 00:50:04,380
grid world

1070
00:50:04,380 --> 00:50:07,560
in the continuous time setting here this

1071
00:50:07,560 --> 00:50:11,099
is the spinal cord of the butterfly

1072
00:50:11,099 --> 00:50:15,420
here's the sensory data coming in why

1073
00:50:15,420 --> 00:50:18,960
and then a descending hidden State

1074
00:50:18,960 --> 00:50:20,700
inference

1075
00:50:20,700 --> 00:50:25,079
and uh error deviation that's being

1076
00:50:25,079 --> 00:50:28,500
resolved through policy selection in the

1077
00:50:28,500 --> 00:50:30,060
continuous space

1078
00:50:30,060 --> 00:50:32,280
so this is hearkening back to chapter 5

1079
00:50:32,280 --> 00:50:34,500
and the spinal cord reflex

1080
00:50:34,500 --> 00:50:37,140
how continuous time generative models

1081
00:50:37,140 --> 00:50:41,400
can can be applied to continuous spinal

1082
00:50:41,400 --> 00:50:44,280
motor reflexes as opposed to the usually

1083
00:50:44,280 --> 00:50:47,280
more centrally Associated discrete

1084
00:50:47,280 --> 00:50:51,540
categorical decision-making Dai

1085
00:50:51,540 --> 00:50:54,000
there's a sidebar on Precision attention

1086
00:50:54,000 --> 00:50:57,020
and attenuation

1087
00:50:57,839 --> 00:51:00,660
there's the discussion of lock Volterra

1088
00:51:00,660 --> 00:51:03,599
which is also called Predator prey or

1089
00:51:03,599 --> 00:51:06,359
winner list Dynamics like

1090
00:51:06,359 --> 00:51:09,119
you can't win in this ecology there's

1091
00:51:09,119 --> 00:51:11,040
also there are ecologies that collapse

1092
00:51:11,040 --> 00:51:14,819
of course but activity Dynamics amongst

1093
00:51:14,819 --> 00:51:16,319
brain regions

1094
00:51:16,319 --> 00:51:18,839
have been modeled for decades as these

1095
00:51:18,839 --> 00:51:21,300
winnerless competitions also called

1096
00:51:21,300 --> 00:51:22,980
neural Darwinism

1097
00:51:22,980 --> 00:51:26,280
and that's relating to friston's

1098
00:51:26,280 --> 00:51:29,819
lineage with Edelman

1099
00:51:29,819 --> 00:51:32,579
more examples of how these kinds of

1100
00:51:32,579 --> 00:51:34,500
winnerless competitions

1101
00:51:34,500 --> 00:51:36,839
can be used in the context of continuous

1102
00:51:36,839 --> 00:51:39,000
time generative models to generate

1103
00:51:39,000 --> 00:51:41,940
smooth action sequences like this sort

1104
00:51:41,940 --> 00:51:45,680
of gibberish cursive writing

1105
00:51:46,260 --> 00:51:49,859
learning is approached in a continuous

1106
00:51:49,859 --> 00:51:52,098
model

1107
00:51:52,260 --> 00:51:54,859
everything in chapter 8 is kind of being

1108
00:51:54,859 --> 00:51:57,720
contrasted or juxtaposed with what we

1109
00:51:57,720 --> 00:52:01,399
saw at chapter 7 in the discrete time

1110
00:52:01,800 --> 00:52:05,880
they introduced the Lorenz attractor

1111
00:52:05,880 --> 00:52:08,819
which is unpacked in significantly more

1112
00:52:08,819 --> 00:52:13,440
detail in live stream 32 on Markov

1113
00:52:13,440 --> 00:52:16,920
blankets and stochastic chaos

1114
00:52:16,920 --> 00:52:18,900
it is basically this example with the

1115
00:52:18,900 --> 00:52:20,460
Lorenz attractor

1116
00:52:20,460 --> 00:52:21,900
which is showing that generalized

1117
00:52:21,900 --> 00:52:24,240
synchrony which isn't lockstep but

1118
00:52:24,240 --> 00:52:26,579
rather Mutual information amongst couple

1119
00:52:26,579 --> 00:52:28,740
dynamical systems

1120
00:52:28,740 --> 00:52:31,740
can happen even when those coupled

1121
00:52:31,740 --> 00:52:34,980
dynamical systems are Lorenz attractors

1122
00:52:34,980 --> 00:52:37,680
they don't have to be like both like

1123
00:52:37,680 --> 00:52:40,200
simple linear systems

1124
00:52:40,200 --> 00:52:43,079
um so that's like good to know and

1125
00:52:43,079 --> 00:52:46,559
they've used that to simulate Bird song

1126
00:52:46,559 --> 00:52:49,440
where before learning they're kind of

1127
00:52:49,440 --> 00:52:51,599
like on and off a synchronization

1128
00:52:51,599 --> 00:52:53,940
manifold and then after learning they've

1129
00:52:53,940 --> 00:52:55,079
sharpened

1130
00:52:55,079 --> 00:52:57,359
their their um

1131
00:52:57,359 --> 00:52:59,819
joint distribution

1132
00:52:59,819 --> 00:53:02,220
again this begs further questions how do

1133
00:53:02,220 --> 00:53:03,720
they know the semantics of a song and

1134
00:53:03,720 --> 00:53:05,220
how do they learn the song but this is

1135
00:53:05,220 --> 00:53:07,319
just an example

1136
00:53:07,319 --> 00:53:10,680
at this level of complexity

1137
00:53:10,680 --> 00:53:14,640
um 8.5 Hybrid models here we have the

1138
00:53:14,640 --> 00:53:16,260
rake within a rake

1139
00:53:16,260 --> 00:53:19,440
but notice that the outer rake there

1140
00:53:19,440 --> 00:53:21,900
should be a line connecting this G to Pi

1141
00:53:21,900 --> 00:53:25,859
the outer rake is Dai here we see hidden

1142
00:53:25,859 --> 00:53:28,380
States Through Time T minus one now

1143
00:53:28,380 --> 00:53:30,540
future Tale of Two densities

1144
00:53:30,540 --> 00:53:33,359
observations Through Time classic Dai

1145
00:53:33,359 --> 00:53:35,760
chapter 7 up top

1146
00:53:35,760 --> 00:53:37,740
but the nested model

1147
00:53:37,740 --> 00:53:40,980
has the same structure figure 4.3 but

1148
00:53:40,980 --> 00:53:44,520
here we see the position

1149
00:53:44,520 --> 00:53:47,640
velocity acceleration generalized

1150
00:53:47,640 --> 00:53:50,819
coordinates pattern occurring

1151
00:53:50,819 --> 00:53:53,160
so this is called a hybrid model because

1152
00:53:53,160 --> 00:53:57,180
the discrete time model is nesting a

1153
00:53:57,180 --> 00:53:58,740
continuous time model

1154
00:53:58,740 --> 00:54:00,300
so this has been used to model things

1155
00:54:00,300 --> 00:54:02,339
like where do I want to look from a

1156
00:54:02,339 --> 00:54:05,040
categorical perspective and then here's

1157
00:54:05,040 --> 00:54:07,619
the oculomotor cicades at a continuous

1158
00:54:07,619 --> 00:54:11,180
model that's nested within that

1159
00:54:13,260 --> 00:54:15,300
more equations

1160
00:54:15,300 --> 00:54:18,440
isucade model

1161
00:54:19,440 --> 00:54:21,599
more equations

1162
00:54:21,599 --> 00:54:24,780
summary and key advances in continuous

1163
00:54:24,780 --> 00:54:27,000
time models

1164
00:54:27,000 --> 00:54:29,819
end of the chapter all right thank you

1165
00:54:29,819 --> 00:54:32,220
we'll take a break and then begin with

1166
00:54:32,220 --> 00:54:35,720
the next cohort in just two minutes

