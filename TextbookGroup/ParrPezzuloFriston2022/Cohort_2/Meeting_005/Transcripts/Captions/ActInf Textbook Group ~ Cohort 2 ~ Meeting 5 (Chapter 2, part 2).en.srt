1
00:00:00,599 --> 00:00:04,580
hello everyone it is

2
00:00:04,620 --> 00:00:08,940
September 30th 2022 and we're in cohort

3
00:00:08,940 --> 00:00:11,820
2 meeting number five we're having our

4
00:00:11,820 --> 00:00:16,199
second discussion on the chapter two of

5
00:00:16,199 --> 00:00:17,400
the textbook

6
00:00:17,400 --> 00:00:18,660
so

7
00:00:18,660 --> 00:00:21,840
um we'll jump in shortly to the

8
00:00:21,840 --> 00:00:23,100
questions

9
00:00:23,100 --> 00:00:25,920
but first just wanted to um

10
00:00:25,920 --> 00:00:27,960
highlight a stream that'll be happening

11
00:00:27,960 --> 00:00:29,160
later today

12
00:00:29,160 --> 00:00:33,120
which is number 49.0 and I'll I'll share

13
00:00:33,120 --> 00:00:36,680
in the chat here

14
00:00:37,440 --> 00:00:39,660
um or you can find it through the live

15
00:00:39,660 --> 00:00:41,879
stream page

16
00:00:41,879 --> 00:00:46,140
this is uh with Ali and Jacob who are

17
00:00:46,140 --> 00:00:48,960
here and the upcoming two weeks will

18
00:00:48,960 --> 00:00:51,480
have Dalton sakti of the devil

19
00:00:51,480 --> 00:00:54,600
coming to discuss the paper and this

20
00:00:54,600 --> 00:00:58,140
paper is um it's quite an opus

21
00:00:58,140 --> 00:01:02,280
and we we had a lot of fun preparing for

22
00:01:02,280 --> 00:01:04,460
it

23
00:01:05,640 --> 00:01:07,860
all right

24
00:01:07,860 --> 00:01:11,760
so we'll go to the questions and I think

25
00:01:11,760 --> 00:01:15,119
these are all just great beginning

26
00:01:15,119 --> 00:01:18,900
points is there anyone who wants to

27
00:01:18,900 --> 00:01:20,520
point to a question that they're

28
00:01:20,520 --> 00:01:23,640
interested to begin with

29
00:01:23,640 --> 00:01:25,799
or a question that they asked or one

30
00:01:25,799 --> 00:01:28,020
that they feel has like a a natural

31
00:01:28,020 --> 00:01:30,740
starting point

32
00:01:31,200 --> 00:01:35,119
otherwise I can pick one

33
00:01:37,680 --> 00:01:40,020
uh Daniel the um the question on

34
00:01:40,020 --> 00:01:42,380
thinking between cognition

35
00:01:42,380 --> 00:01:45,840
and thinking was one that I put there it

36
00:01:45,840 --> 00:01:47,280
was just from the the beginning of the

37
00:01:47,280 --> 00:01:48,299
chapter

38
00:01:48,299 --> 00:01:51,180
um a little quote

39
00:01:51,180 --> 00:01:53,220
um my thinking is first and last and

40
00:01:53,220 --> 00:01:55,380
always for the sake of my doing

41
00:01:55,380 --> 00:01:56,820
it's just when you read I always get

42
00:01:56,820 --> 00:01:58,979
confused between cognition and thinking

43
00:01:58,979 --> 00:02:01,320
and knowing and all those sort of

44
00:02:01,320 --> 00:02:04,860
uh words and uh their relationships to

45
00:02:04,860 --> 00:02:06,299
each other so I was just wondering if we

46
00:02:06,299 --> 00:02:07,860
could just sort of clarify that a little

47
00:02:07,860 --> 00:02:10,038
bit

48
00:02:10,318 --> 00:02:12,599
all right what does anyone think

49
00:02:12,599 --> 00:02:16,260
are these terms synonymous

50
00:02:16,260 --> 00:02:19,860
or are different things being pointed at

51
00:02:19,860 --> 00:02:23,459
with different um

52
00:02:23,459 --> 00:02:26,480
terms like this

53
00:02:28,440 --> 00:02:31,800
well I would maybe say that thinking

54
00:02:31,800 --> 00:02:35,780
could be interpreted as action

55
00:02:38,459 --> 00:02:40,800
and no knowing maybe

56
00:02:40,800 --> 00:02:42,360
um

57
00:02:42,360 --> 00:02:45,780
could be a consequence well

58
00:02:45,780 --> 00:02:47,300
knowing could be the specific

59
00:02:47,300 --> 00:02:51,060
representation of beliefs

60
00:02:51,060 --> 00:02:53,900
in the brain

61
00:02:54,060 --> 00:02:56,340
and then cognition is

62
00:02:56,340 --> 00:03:00,300
I see that as the kind of uh

63
00:03:00,300 --> 00:03:03,980
overarching blanket

64
00:03:09,060 --> 00:03:12,620
well thinking is Ali

65
00:03:14,840 --> 00:03:17,940
you know actually there are many

66
00:03:17,940 --> 00:03:20,099
different angles that we can

67
00:03:20,099 --> 00:03:23,220
uh tackle uh the conceptual differences

68
00:03:23,220 --> 00:03:26,400
between these three terms I'm going to

69
00:03:26,400 --> 00:03:30,659
start from the last term knowing uh well

70
00:03:30,659 --> 00:03:32,700
in epistemology the standard definition

71
00:03:32,700 --> 00:03:37,099
for knowing is Justified true belief so

72
00:03:37,099 --> 00:03:41,099
if we take that as a definition of

73
00:03:41,099 --> 00:03:43,400
knowing then we can go to

74
00:03:43,400 --> 00:03:48,720
thinking as the act of gaining that

75
00:03:48,720 --> 00:03:52,379
justified true belief as Jakob has

76
00:03:52,379 --> 00:03:55,099
mentioned some people

77
00:03:55,099 --> 00:03:59,400
describe thinking in terms of action and

78
00:03:59,400 --> 00:04:02,120
then cognition is a kind of

79
00:04:02,120 --> 00:04:06,299
uh a conscious state in which the

80
00:04:06,299 --> 00:04:10,200
thinking happens uh I mean if it's not

81
00:04:10,200 --> 00:04:13,860
the action of thinking per se it's uh

82
00:04:13,860 --> 00:04:16,738
the blank it's the situation or uh the

83
00:04:16,738 --> 00:04:19,199
state in which these kind of thinkings

84
00:04:19,199 --> 00:04:21,358
and knowings happen

85
00:04:21,358 --> 00:04:24,840
but uh obviously the this is a very

86
00:04:24,840 --> 00:04:27,840
simplistic uh distinction between them

87
00:04:27,840 --> 00:04:31,139
they're very nuanced uh discussions

88
00:04:31,139 --> 00:04:33,720
going on in the philosophy of mind uh

89
00:04:33,720 --> 00:04:38,280
about the differences between whether uh

90
00:04:38,280 --> 00:04:44,100
are there are these three concepts

91
00:04:44,100 --> 00:04:47,280
mutually exclusive or they can be

92
00:04:47,280 --> 00:04:49,800
related in a kind of hierarchical way to

93
00:04:49,800 --> 00:04:52,639
each other so

94
00:04:57,300 --> 00:05:01,940
awesome very uh deep answers

95
00:05:02,160 --> 00:05:05,580
one other take would be thinking is uh

96
00:05:05,580 --> 00:05:08,820
gerund verb it's a process

97
00:05:08,820 --> 00:05:12,900
whereas cognition is a

98
00:05:12,900 --> 00:05:15,300
noun

99
00:05:15,300 --> 00:05:19,440
and just from a sentiment perspective

100
00:05:19,440 --> 00:05:22,500
thinking seems to imply like a process

101
00:05:22,500 --> 00:05:27,060
and perhaps the experiencer

102
00:05:27,060 --> 00:05:29,940
like the subconscious regulation of

103
00:05:29,940 --> 00:05:32,240
blood pressure might not be considered

104
00:05:32,240 --> 00:05:35,039
thoughtful or thinking

105
00:05:35,039 --> 00:05:37,979
whereas especially

106
00:05:37,979 --> 00:05:41,639
um as cognitive theories

107
00:05:41,639 --> 00:05:44,039
are kind of pervading

108
00:05:44,039 --> 00:05:46,080
all areas

109
00:05:46,080 --> 00:05:49,740
in a in a type of like pan cognitivism

110
00:05:49,740 --> 00:05:52,320
then cognition is a bit more neutral

111
00:05:52,320 --> 00:05:54,419
with respect to

112
00:05:54,419 --> 00:05:57,180
phenomenology and awareness

113
00:05:57,180 --> 00:05:59,280
so one could say a computer is doing a

114
00:05:59,280 --> 00:06:01,919
type of cognition the sand pile is doing

115
00:06:01,919 --> 00:06:04,800
a type of cognitive process

116
00:06:04,800 --> 00:06:07,440
um this membrane is doing cognition it's

117
00:06:07,440 --> 00:06:09,600
equalizing the temperature like those

118
00:06:09,600 --> 00:06:12,539
can all be described cognitively

119
00:06:12,539 --> 00:06:15,300
and especially as we take active

120
00:06:15,300 --> 00:06:17,520
inference which is a framework derived

121
00:06:17,520 --> 00:06:19,320
in the neurosciences

122
00:06:19,320 --> 00:06:22,380
where these terms might have the least

123
00:06:22,380 --> 00:06:24,419
space between them

124
00:06:24,419 --> 00:06:26,340
but then the question of whether a

125
00:06:26,340 --> 00:06:30,020
computer is doing thinking or knowing

126
00:06:30,479 --> 00:06:33,060
is perhaps a further afield whereas to

127
00:06:33,060 --> 00:06:34,740
say that a computer is doing cognitive

128
00:06:34,740 --> 00:06:37,800
process or information processing

129
00:06:37,800 --> 00:06:41,180
might be less controversial

130
00:06:43,199 --> 00:06:45,660
like extended cognition

131
00:06:45,660 --> 00:06:47,759
but then I guess we just don't hear as

132
00:06:47,759 --> 00:06:50,759
much about extended thinking or extended

133
00:06:50,759 --> 00:06:53,240
knowing

134
00:06:54,120 --> 00:06:56,280
but when they're all

135
00:06:56,280 --> 00:07:00,060
um in our body you know then

136
00:07:00,060 --> 00:07:02,039
these seem to have like the most

137
00:07:02,039 --> 00:07:04,940
synonymy

138
00:07:11,100 --> 00:07:13,680
my cognition is first and last always

139
00:07:13,680 --> 00:07:16,759
for the sake of my doing

140
00:07:17,880 --> 00:07:20,220
okay any other like thoughts or comments

141
00:07:20,220 --> 00:07:22,819
on this question

142
00:07:28,500 --> 00:07:30,360
all right let's kind of can oh yeah

143
00:07:30,360 --> 00:07:32,160
Roman

144
00:07:32,160 --> 00:07:33,960
I just want to just say it so it sounds

145
00:07:33,960 --> 00:07:35,220
as if it's something that's sort of

146
00:07:35,220 --> 00:07:37,139
still in a

147
00:07:37,139 --> 00:07:39,599
in evolution or in just under discussion

148
00:07:39,599 --> 00:07:42,240
is it really still

149
00:07:42,240 --> 00:07:45,000
under investigation or attempting to

150
00:07:45,000 --> 00:07:49,520
find Clarity in these in this language

151
00:07:49,979 --> 00:07:52,500
I mean I like I like that I like that

152
00:07:52,500 --> 00:07:54,900
thinking's the verb and that's that's

153
00:07:54,900 --> 00:07:57,360
sort of where I was uh the direction

154
00:07:57,360 --> 00:07:58,740
that I was

155
00:07:58,740 --> 00:08:00,780
was having with thinking that it's a

156
00:08:00,780 --> 00:08:02,880
that it's an act

157
00:08:02,880 --> 00:08:05,400
uh that's that's my sort of take on it

158
00:08:05,400 --> 00:08:07,919
and cognition is more of the overriding

159
00:08:07,919 --> 00:08:09,539
blanket

160
00:08:09,539 --> 00:08:11,460
um so yeah so thank you for that that's

161
00:08:11,460 --> 00:08:13,380
good

162
00:08:13,380 --> 00:08:14,819
yeah

163
00:08:14,819 --> 00:08:17,160
and um we might be able to find

164
00:08:17,160 --> 00:08:19,560
coherence like in our own understandings

165
00:08:19,560 --> 00:08:22,560
or within the active inference ontology

166
00:08:22,560 --> 00:08:24,560
but the

167
00:08:24,560 --> 00:08:28,139
a larger scale historical Arc around

168
00:08:28,139 --> 00:08:31,580
these topics as well as like

169
00:08:31,580 --> 00:08:35,179
non-english versions of related topics

170
00:08:35,179 --> 00:08:37,979
that's probably more like a

171
00:08:37,979 --> 00:08:39,479
philosophical or maybe even like

172
00:08:39,479 --> 00:08:41,760
theological domain kind of just Trails

173
00:08:41,760 --> 00:08:46,800
off but within these terms as used

174
00:08:46,800 --> 00:08:48,899
in active inference

175
00:08:48,899 --> 00:08:50,820
it may be possible to have a lot more

176
00:08:50,820 --> 00:08:52,800
clarity

177
00:08:52,800 --> 00:08:55,560
especially around like cognition

178
00:08:55,560 --> 00:08:57,180
you know for the purposes of this model

179
00:08:57,180 --> 00:08:59,100
we're defining cognition as the

180
00:08:59,100 --> 00:09:01,500
information processing between input and

181
00:09:01,500 --> 00:09:02,880
output not saying that's the only

182
00:09:02,880 --> 00:09:04,740
definition just like if if one is to say

183
00:09:04,740 --> 00:09:06,660
that's what I mean by cognition

184
00:09:06,660 --> 00:09:08,399
there doesn't need to be

185
00:09:08,399 --> 00:09:10,620
um a qualia

186
00:09:10,620 --> 00:09:12,180
but then somebody else if their

187
00:09:12,180 --> 00:09:14,580
definition of thinking or knowing is

188
00:09:14,580 --> 00:09:16,860
going to be related to equalia

189
00:09:16,860 --> 00:09:20,640
and not like information processing

190
00:09:20,640 --> 00:09:23,339
then that's going to be verging into a

191
00:09:23,339 --> 00:09:24,660
different area

192
00:09:24,660 --> 00:09:27,260
mm-hmm

193
00:09:27,779 --> 00:09:28,920
okay

194
00:09:28,920 --> 00:09:31,860
so let's kind of continue on this

195
00:09:31,860 --> 00:09:35,399
uh broad an important theme

196
00:09:35,399 --> 00:09:38,100
how does active inference fit in with

197
00:09:38,100 --> 00:09:39,959
neuroscience

198
00:09:39,959 --> 00:09:42,300
does anyone who asked the question or

199
00:09:42,300 --> 00:09:44,339
provided some of this

200
00:09:44,339 --> 00:09:46,500
answers and discourse want to give a

201
00:09:46,500 --> 00:09:48,620
thought

202
00:09:51,240 --> 00:09:54,779
okay yeah I asked I asked the question

203
00:09:54,779 --> 00:09:55,440
um

204
00:09:55,440 --> 00:09:59,399
great this is yes what are we actually

205
00:09:59,399 --> 00:10:02,519
doing here are we doing Neuroscience or

206
00:10:02,519 --> 00:10:05,640
are we doing machine learning

207
00:10:05,640 --> 00:10:06,800
um

208
00:10:06,800 --> 00:10:09,839
I think it's some sort of combination of

209
00:10:09,839 --> 00:10:11,820
both but when we when we're talking

210
00:10:11,820 --> 00:10:13,440
about things

211
00:10:13,440 --> 00:10:15,660
do we have a

212
00:10:15,660 --> 00:10:18,060
we have some guidance of what we're what

213
00:10:18,060 --> 00:10:19,680
we're talking about

214
00:10:19,680 --> 00:10:21,120
uh

215
00:10:21,120 --> 00:10:22,500
it seems as though the original

216
00:10:22,500 --> 00:10:25,380
variation of free energy

217
00:10:25,380 --> 00:10:27,720
fits in with the biology there's there's

218
00:10:27,720 --> 00:10:30,600
some correspondence with the physical

219
00:10:30,600 --> 00:10:33,180
of the brain

220
00:10:33,180 --> 00:10:37,140
um related to superficial pyramidal

221
00:10:37,140 --> 00:10:39,779
cells or whatever

222
00:10:39,779 --> 00:10:43,019
um the expected free energy seems so

223
00:10:43,019 --> 00:10:46,200
much like reinforcement learning and

224
00:10:46,200 --> 00:10:50,360
quite away from the neuroscience

225
00:10:52,260 --> 00:10:55,140
great thanks for the comments and ideas

226
00:10:55,140 --> 00:10:56,880
does anyone wanna

227
00:10:56,880 --> 00:10:58,680
add

228
00:10:58,680 --> 00:11:01,019
or or speak to these

229
00:11:01,019 --> 00:11:04,880
faces Ali thank you

230
00:11:04,920 --> 00:11:07,219
yeah

231
00:11:07,380 --> 00:11:11,220
let's say uh about I mean FTP literature

232
00:11:11,220 --> 00:11:16,560
before 2019 uh was mainly concerned with

233
00:11:16,560 --> 00:11:19,740
uh the neuroscientific descriptions of

234
00:11:19,740 --> 00:11:23,579
the mind uh using this active inference

235
00:11:23,579 --> 00:11:27,060
framework but from around 2019 things

236
00:11:27,060 --> 00:11:31,260
have changed and a lot of research are

237
00:11:31,260 --> 00:11:32,360
going on

238
00:11:32,360 --> 00:11:34,920
which try to relate

239
00:11:34,920 --> 00:11:35,640
um

240
00:11:35,640 --> 00:11:37,920
active inference framework to other

241
00:11:37,920 --> 00:11:43,740
areas in physics in economics in even

242
00:11:43,740 --> 00:11:47,279
climatology or other kinds of phenomena

243
00:11:47,279 --> 00:11:51,180
which can be modeled using fvp slash

244
00:11:51,180 --> 00:11:56,339
active inference framework so uh I I'd

245
00:11:56,339 --> 00:11:58,620
say that in the currently the active

246
00:11:58,620 --> 00:11:59,700
inference

247
00:11:59,700 --> 00:12:05,700
framework is just uh is or at least it

248
00:12:05,700 --> 00:12:09,600
converges to be a kind of modeling

249
00:12:09,600 --> 00:12:11,700
framework or a kind of mathematical

250
00:12:11,700 --> 00:12:16,640
structure which would Encompass all can

251
00:12:16,640 --> 00:12:19,320
potentially encompass

252
00:12:19,320 --> 00:12:22,220
many different modeling Frameworks in it

253
00:12:22,220 --> 00:12:26,519
so uh yeah that's the current uh status

254
00:12:26,519 --> 00:12:29,640
of the research

255
00:12:29,640 --> 00:12:32,640
an active inference it's not solely

256
00:12:32,640 --> 00:12:35,160
focused on neuroscientific descriptions

257
00:12:35,160 --> 00:12:37,320
of the Mind

258
00:12:37,320 --> 00:12:41,300
awesome thanks Jacob

259
00:12:41,700 --> 00:12:45,660
yeah I would maybe uh add to the point

260
00:12:45,660 --> 00:12:48,720
that Neil mentioned that

261
00:12:48,720 --> 00:12:50,220
um sometimes it feels like it's

262
00:12:50,220 --> 00:12:51,720
neuroscience and sometimes it feels like

263
00:12:51,720 --> 00:12:55,579
it's reinforcement learning I think

264
00:12:55,860 --> 00:12:56,760
um

265
00:12:56,760 --> 00:12:58,800
I would think more about active

266
00:12:58,800 --> 00:13:02,820
inference as a kind of on the on the

267
00:13:02,820 --> 00:13:04,920
same level as like thermodynamics and

268
00:13:04,920 --> 00:13:08,420
physics where the specific model is not

269
00:13:08,420 --> 00:13:11,760
necessarily that important although we

270
00:13:11,760 --> 00:13:13,200
are assuming we are in this kind of

271
00:13:13,200 --> 00:13:15,959
Bayesian scheme but reinforcement

272
00:13:15,959 --> 00:13:18,380
learning has also been applied to

273
00:13:18,380 --> 00:13:22,440
modeling uh the role of dopamine in the

274
00:13:22,440 --> 00:13:25,440
brain so in a sense we could say if we

275
00:13:25,440 --> 00:13:27,480
if we put it in the in that context we

276
00:13:27,480 --> 00:13:28,920
could say that reinforcement learning is

277
00:13:28,920 --> 00:13:31,440
also related to Neuroscience even though

278
00:13:31,440 --> 00:13:34,019
it's uh

279
00:13:34,019 --> 00:13:37,500
also used in other contexts so

280
00:13:37,500 --> 00:13:38,760
I guess

281
00:13:38,760 --> 00:13:41,339
I'd say that active is

282
00:13:41,339 --> 00:13:43,320
again this kind of overarching blanket

283
00:13:43,320 --> 00:13:47,760
that covers multiple areas

284
00:13:47,760 --> 00:13:50,339
um but it's not necessarily one or the

285
00:13:50,339 --> 00:13:52,519
other

286
00:13:53,760 --> 00:13:54,839
awesome

287
00:13:54,839 --> 00:13:56,399
all right I'll add a few more thoughts

288
00:13:56,399 --> 00:13:58,200
and then anyone who

289
00:13:58,200 --> 00:14:01,320
that's a comment so first this is going

290
00:14:01,320 --> 00:14:04,920
to be a slide from later today uh in

291
00:14:04,920 --> 00:14:06,839
live stream 49.

292
00:14:06,839 --> 00:14:10,079
and it's a Maxwell ramstead tweet thread

293
00:14:10,079 --> 00:14:13,980
you know hashtag scholarship in 2022.

294
00:14:13,980 --> 00:14:16,920
and Maxwell describes first wave free

295
00:14:16,920 --> 00:14:19,500
energy models which didn't have policy

296
00:14:19,500 --> 00:14:22,200
per policy selection per se

297
00:14:22,200 --> 00:14:23,940
the Dynamics of internal and active

298
00:14:23,940 --> 00:14:25,980
States also known as particular States

299
00:14:25,980 --> 00:14:28,079
because that's like the moving particle

300
00:14:28,079 --> 00:14:30,420
it's like the internal States and the

301
00:14:30,420 --> 00:14:32,760
blanket make up the particle and then

302
00:14:32,760 --> 00:14:34,860
the autonomous states are the internal

303
00:14:34,860 --> 00:14:36,480
States and the action States those are

304
00:14:36,480 --> 00:14:39,120
the ones like under Direct Control

305
00:14:39,120 --> 00:14:41,459
whereas you can't directly control your

306
00:14:41,459 --> 00:14:42,779
sensory States but they're still part of

307
00:14:42,779 --> 00:14:44,699
your particle so

308
00:14:44,699 --> 00:14:46,620
there was a gradient descent happening

309
00:14:46,620 --> 00:14:48,540
on the autonomous States

310
00:14:48,540 --> 00:14:51,480
so it was kind of a one-step model and

311
00:14:51,480 --> 00:14:53,100
hence couldn't really be said to

312
00:14:53,100 --> 00:14:54,860
entertain policy selection

313
00:14:54,860 --> 00:14:57,060
counterfactuals planning as inference

314
00:14:57,060 --> 00:14:58,560
and so that was like very much a

315
00:14:58,560 --> 00:15:02,160
variational free energy framing

316
00:15:02,160 --> 00:15:05,699
and that's totally consistent with a

317
00:15:05,699 --> 00:15:08,699
wide range of previous Bayesian work on

318
00:15:08,699 --> 00:15:11,000
gradient descent variational

319
00:15:11,000 --> 00:15:13,199
autoencoders the variational Bayesian

320
00:15:13,199 --> 00:15:16,139
methods all of that area

321
00:15:16,139 --> 00:15:18,300
second wave models starting around 2012

322
00:15:18,300 --> 00:15:20,579
equipped agents with beliefs about State

323
00:15:20,579 --> 00:15:22,260
transitions especially sensory

324
00:15:22,260 --> 00:15:24,540
consequences of movement

325
00:15:24,540 --> 00:15:28,019
the emphasis on the sensory outcomes of

326
00:15:28,019 --> 00:15:29,040
action

327
00:15:29,040 --> 00:15:31,920
has been linked by others to perceptual

328
00:15:31,920 --> 00:15:33,660
control theory

329
00:15:33,660 --> 00:15:38,579
and also Bridges towards embodiment

330
00:15:38,579 --> 00:15:40,740
this enables the design of models with

331
00:15:40,740 --> 00:15:43,320
proper policy selection that evaluated

332
00:15:43,320 --> 00:15:45,839
average free energy expected under each

333
00:15:45,839 --> 00:15:47,519
policy

334
00:15:47,519 --> 00:15:49,920
then third wave models use recursive

335
00:15:49,920 --> 00:15:52,560
expected free energy functional which

336
00:15:52,560 --> 00:15:54,839
enables some more advanced

337
00:15:54,839 --> 00:15:56,760
uh

338
00:15:56,760 --> 00:16:00,720
modeling tools like counterfactuals

339
00:16:00,720 --> 00:16:03,240
so that is one angle

340
00:16:03,240 --> 00:16:05,760
another angle and and so the the

341
00:16:05,760 --> 00:16:07,380
question was spot on with kind of

342
00:16:07,380 --> 00:16:10,260
beginning with Neuroscience if we go to

343
00:16:10,260 --> 00:16:15,360
Carl friston's Google Scholar page

344
00:16:15,360 --> 00:16:18,240
his most cited work and

345
00:16:18,240 --> 00:16:20,699
the work that makes him the most cited

346
00:16:20,699 --> 00:16:23,579
neuroscientist alive slash ever

347
00:16:23,579 --> 00:16:26,279
you'll find although the free energy

348
00:16:26,279 --> 00:16:29,100
principle 2010 paper

349
00:16:29,100 --> 00:16:31,680
has been cited as like a keystone

350
00:16:31,680 --> 00:16:33,959
Fe paper

351
00:16:33,959 --> 00:16:36,480
almost all these several tens of

352
00:16:36,480 --> 00:16:37,800
thousands

353
00:16:37,800 --> 00:16:40,620
are related to methods

354
00:16:40,620 --> 00:16:42,660
related to statistical parametric

355
00:16:42,660 --> 00:16:44,579
mapping SPM

356
00:16:44,579 --> 00:16:48,139
which is arising from the welcome

357
00:16:48,139 --> 00:16:51,600
Imaging Center at the University College

358
00:16:51,600 --> 00:16:55,680
in London and the Decades of Carl and

359
00:16:55,680 --> 00:16:59,940
others work in neuroimaging

360
00:16:59,940 --> 00:17:02,339
basic research and the tool development

361
00:17:02,339 --> 00:17:04,559
around it

362
00:17:04,559 --> 00:17:07,199
so coming out of this framework where

363
00:17:07,199 --> 00:17:08,699
they were doing

364
00:17:08,699 --> 00:17:11,459
uh time series modeling like dynamical

365
00:17:11,459 --> 00:17:13,799
modeling on

366
00:17:13,799 --> 00:17:17,040
hidden State inferences on spatial data

367
00:17:17,040 --> 00:17:19,500
like you're getting the MRI data but

368
00:17:19,500 --> 00:17:21,059
then you're inferring the neural

369
00:17:21,059 --> 00:17:23,880
activation that gives rise to this

370
00:17:23,880 --> 00:17:26,640
as mediated by like sensor and various

371
00:17:26,640 --> 00:17:28,559
sources of

372
00:17:28,559 --> 00:17:31,520
stochasticity

373
00:17:31,860 --> 00:17:34,980
the generality of that framework

374
00:17:34,980 --> 00:17:37,679
especially in light of some

375
00:17:37,679 --> 00:17:39,900
philosophical contributions

376
00:17:39,900 --> 00:17:41,100
by

377
00:17:41,100 --> 00:17:42,539
uh well

378
00:17:42,539 --> 00:17:46,620
in in some ways since 2010 since 2005 to

379
00:17:46,620 --> 00:17:48,539
2010

380
00:17:48,539 --> 00:17:50,460
Kristin was already going for this sort

381
00:17:50,460 --> 00:17:51,419
of

382
00:17:51,419 --> 00:17:55,380
across domain applications of free

383
00:17:55,380 --> 00:17:57,360
energy and so

384
00:17:57,360 --> 00:17:59,400
um

385
00:17:59,400 --> 00:18:01,620
another

386
00:18:01,620 --> 00:18:03,720
um kind of related

387
00:18:03,720 --> 00:18:05,520
like potentially extremely formally

388
00:18:05,520 --> 00:18:07,620
related but just in its scope is like

389
00:18:07,620 --> 00:18:10,919
the constructal law by Adrian Bajan and

390
00:18:10,919 --> 00:18:13,260
other works like that like looking for

391
00:18:13,260 --> 00:18:15,600
patterns across systems

392
00:18:15,600 --> 00:18:17,039
um

393
00:18:17,039 --> 00:18:21,720
and then as Ali mentions that scope Was

394
00:18:21,720 --> 00:18:24,240
Then followed up on with people working

395
00:18:24,240 --> 00:18:26,100
towards specific applications in

396
00:18:26,100 --> 00:18:27,780
different areas

397
00:18:27,780 --> 00:18:29,640
and then now that there's been such

398
00:18:29,640 --> 00:18:31,679
developments with the software packages

399
00:18:31,679 --> 00:18:34,020
and mathematical advances and and

400
00:18:34,020 --> 00:18:35,940
formalisms

401
00:18:35,940 --> 00:18:39,240
that's where we see the encompassing of

402
00:18:39,240 --> 00:18:43,200
a lot of different modeling Frameworks

403
00:18:43,200 --> 00:18:45,960
this is a great question too how should

404
00:18:45,960 --> 00:18:47,520
we be thinking of active inferences

405
00:18:47,520 --> 00:18:49,500
relationship with the way we think the

406
00:18:49,500 --> 00:18:51,840
brain actually works

407
00:18:51,840 --> 00:18:54,600
chapter 5 is going to be

408
00:18:54,600 --> 00:18:55,500
um

409
00:18:55,500 --> 00:18:58,260
about that it's going to be focusing on

410
00:18:58,260 --> 00:19:01,080
specific neural systems like the spinal

411
00:19:01,080 --> 00:19:03,600
reflex arc and also like

412
00:19:03,600 --> 00:19:05,400
um uh

413
00:19:05,400 --> 00:19:07,380
cortical processing

414
00:19:07,380 --> 00:19:09,120
and

415
00:19:09,120 --> 00:19:11,460
there's some there's going to be a lot

416
00:19:11,460 --> 00:19:13,919
of fun discussions on that because

417
00:19:13,919 --> 00:19:15,500
there's kind of like a map territory

418
00:19:15,500 --> 00:19:18,720
issue like if you use a linear

419
00:19:18,720 --> 00:19:21,600
regression on the brain no one thinks

420
00:19:21,600 --> 00:19:23,520
the brain is a linear aggression

421
00:19:23,520 --> 00:19:26,520
but if you use octave inference on the

422
00:19:26,520 --> 00:19:28,500
brain

423
00:19:28,500 --> 00:19:30,480
what is it that makes people think that

424
00:19:30,480 --> 00:19:33,179
something is being done with the map

425
00:19:33,179 --> 00:19:36,720
that isn't just a neural model

426
00:19:36,720 --> 00:19:39,840
like in SPM no one said well the brain's

427
00:19:39,840 --> 00:19:41,460
a statistic parametric map because we

428
00:19:41,460 --> 00:19:43,500
use the SPM package

429
00:19:43,500 --> 00:19:46,980
yet it can feel like people are using an

430
00:19:46,980 --> 00:19:48,780
active inference model

431
00:19:48,780 --> 00:19:50,940
and the claims that they derive are this

432
00:19:50,940 --> 00:19:53,160
is the brain doing active inference

433
00:19:53,160 --> 00:19:55,020
but isn't that kind of like using the

434
00:19:55,020 --> 00:19:56,580
SPM package and then saying that the

435
00:19:56,580 --> 00:19:58,919
brain is doing SPM

436
00:19:58,919 --> 00:20:03,200
so these are really important questions

437
00:20:06,720 --> 00:20:08,760
one other note would be

438
00:20:08,760 --> 00:20:11,280
the um

439
00:20:11,280 --> 00:20:14,940
the structure of Neuroscience

440
00:20:14,940 --> 00:20:19,679
in terms of interacting and nested

441
00:20:19,679 --> 00:20:22,620
information processing units

442
00:20:22,620 --> 00:20:25,380
is a natural fit

443
00:20:25,380 --> 00:20:28,020
for how active inference enables

444
00:20:28,020 --> 00:20:31,140
modeling of interactions and nesting of

445
00:20:31,140 --> 00:20:35,240
information processing units

446
00:20:39,059 --> 00:20:40,380
any other

447
00:20:40,380 --> 00:20:44,360
thoughts or questions on this area

448
00:20:46,140 --> 00:20:49,320
all right yeah yeah thanks thanks uh for

449
00:20:49,320 --> 00:20:51,120
clearing that up I'm looking forward to

450
00:20:51,120 --> 00:20:54,720
chapter five then oh awesome yeah all

451
00:20:54,720 --> 00:20:55,500
right

452
00:20:55,500 --> 00:20:58,620
let's look at we so these look like

453
00:20:58,620 --> 00:21:00,900
there's some surprise

454
00:21:00,900 --> 00:21:03,799
related questions

455
00:21:05,580 --> 00:21:09,000
and then we have some questions on

456
00:21:09,000 --> 00:21:10,380
free energy

457
00:21:10,380 --> 00:21:11,880
Okay so

458
00:21:11,880 --> 00:21:13,919
are the conditions

459
00:21:13,919 --> 00:21:17,539
in conditional probabilities

460
00:21:17,940 --> 00:21:19,559
so regarding the conditions in

461
00:21:19,559 --> 00:21:21,660
conditional probabilities are they

462
00:21:21,660 --> 00:21:23,400
mostly subjective objective or something

463
00:21:23,400 --> 00:21:24,780
else

464
00:21:24,780 --> 00:21:27,960
we may have explored it last week

465
00:21:27,960 --> 00:21:29,220
um

466
00:21:29,220 --> 00:21:31,020
models in their construction are prior

467
00:21:31,020 --> 00:21:34,520
dependent even in figure 2.1

468
00:21:34,520 --> 00:21:36,240
requires are necessarily

469
00:21:36,240 --> 00:21:38,760
multi-perspectival

470
00:21:38,760 --> 00:21:40,380
is there anything anyone wants to like

471
00:21:40,380 --> 00:21:41,820
add

472
00:21:41,820 --> 00:21:45,179
the the conditions are conditioned upon

473
00:21:45,179 --> 00:21:47,640
by the modeler

474
00:21:47,640 --> 00:21:49,559
this is kind of like a map territory

475
00:21:49,559 --> 00:21:51,120
distinction

476
00:21:51,120 --> 00:21:54,480
like in the writing of the expression

477
00:21:54,480 --> 00:21:56,280
the vertical line means that the

478
00:21:56,280 --> 00:21:58,500
modeler's conditioning the first part

479
00:21:58,500 --> 00:22:00,539
upon the second part

480
00:22:00,539 --> 00:22:02,039
and then the question of in the Real

481
00:22:02,039 --> 00:22:04,320
Worlds whether something is conditioned

482
00:22:04,320 --> 00:22:06,120
upon

483
00:22:06,120 --> 00:22:08,280
is kind of the difference

484
00:22:08,280 --> 00:22:11,720
between the map and the territory

485
00:22:11,820 --> 00:22:13,500
but

486
00:22:13,500 --> 00:22:15,600
is there any other like area to explore

487
00:22:15,600 --> 00:22:17,840
here

488
00:22:23,940 --> 00:22:26,419
okay

489
00:22:28,320 --> 00:22:30,000
what are some examples of the difference

490
00:22:30,000 --> 00:22:32,700
between natural

491
00:22:32,700 --> 00:22:34,799
psychological surprise

492
00:22:34,799 --> 00:22:37,500
and Bayesian surprise

493
00:22:37,500 --> 00:22:39,120
okay

494
00:22:39,120 --> 00:22:43,020
so let's think about those two surprise

495
00:22:43,020 --> 00:22:45,980
definitions

496
00:22:47,880 --> 00:22:49,500
the first notion of surprise and they're

497
00:22:49,500 --> 00:22:51,080
both going to be measured in information

498
00:22:51,080 --> 00:22:54,559
theoretic units

499
00:22:54,780 --> 00:22:57,960
the first type of surprise

500
00:22:57,960 --> 00:23:01,740
is just the word Surprise by itself

501
00:23:01,740 --> 00:23:04,980
and it is how surprising a given

502
00:23:04,980 --> 00:23:06,720
observation is

503
00:23:06,720 --> 00:23:09,000
so if the classroom height is four feet

504
00:23:09,000 --> 00:23:11,039
plus or minus one you're going to be

505
00:23:11,039 --> 00:23:13,020
minimally surprised with four feet

506
00:23:13,020 --> 00:23:14,820
observations and you're going to get

507
00:23:14,820 --> 00:23:16,380
more and more surprised as the

508
00:23:16,380 --> 00:23:20,059
observations get further from four

509
00:23:20,159 --> 00:23:24,299
that is what is described in this column

510
00:23:24,299 --> 00:23:27,780
this takes in an observation

511
00:23:27,780 --> 00:23:30,860
and then it contrasts that observations

512
00:23:30,860 --> 00:23:33,720
difference with respect to the

513
00:23:33,720 --> 00:23:36,480
parameterization of whatever family of

514
00:23:36,480 --> 00:23:39,179
distribution is being modeled

515
00:23:39,179 --> 00:23:41,460
and then that tells you how surprising

516
00:23:41,460 --> 00:23:45,360
any given observation is given how a

517
00:23:45,360 --> 00:23:47,280
distribution is set

518
00:23:47,280 --> 00:23:49,260
the second notion of surprise is

519
00:23:49,260 --> 00:23:51,860
Bayesian surprise and that's referring

520
00:23:51,860 --> 00:23:55,700
not to how surprising a data point is

521
00:23:55,700 --> 00:23:58,799
but how far

522
00:23:58,799 --> 00:24:02,640
that data point updates the distribution

523
00:24:02,640 --> 00:24:04,799
so depending on how fixed you are in

524
00:24:04,799 --> 00:24:06,419
your priors you could imagine a super

525
00:24:06,419 --> 00:24:08,100
surprising data point

526
00:24:08,100 --> 00:24:10,559
with zero Bayesian surprise

527
00:24:10,559 --> 00:24:12,780
because it doesn't move the distribution

528
00:24:12,780 --> 00:24:15,900
at all but it was super surprising

529
00:24:15,900 --> 00:24:18,000
and then conversely you can imagine a

530
00:24:18,000 --> 00:24:21,659
data point that's not too surprising

531
00:24:21,659 --> 00:24:24,840
but it updates the priors to fit it

532
00:24:24,840 --> 00:24:27,379
exactly

533
00:24:27,659 --> 00:24:29,280
now the question

534
00:24:29,280 --> 00:24:32,520
asks about natural or psychological

535
00:24:32,520 --> 00:24:34,380
surprise

536
00:24:34,380 --> 00:24:36,900
so that is connecting to kind of a

537
00:24:36,900 --> 00:24:39,600
experiential or psychological

538
00:24:39,600 --> 00:24:42,080
question

539
00:24:43,500 --> 00:24:46,919
how would anyone relate these formal

540
00:24:46,919 --> 00:24:49,740
concepts of surprise and Bayesian

541
00:24:49,740 --> 00:24:51,360
surprise

542
00:24:51,360 --> 00:24:53,159
to

543
00:24:53,159 --> 00:24:57,320
um natural or psychological surprise

544
00:25:07,559 --> 00:25:10,158
Ali

545
00:25:11,159 --> 00:25:13,280
foreign

546
00:25:13,280 --> 00:25:16,020
interesting example that I think can

547
00:25:16,020 --> 00:25:18,360
illuminate the distinction between these

548
00:25:18,360 --> 00:25:20,580
two kind of surprises

549
00:25:20,580 --> 00:25:23,280
um is the Monty Hall problem uh because

550
00:25:23,280 --> 00:25:27,539
you see uh the result of uh I mean when

551
00:25:27,539 --> 00:25:30,559
we solve the Monty Hall problem

552
00:25:30,559 --> 00:25:33,720
the result is very surprising

553
00:25:33,720 --> 00:25:35,760
psychologically

554
00:25:35,760 --> 00:25:39,779
but not in a probabilistically or

555
00:25:39,779 --> 00:25:43,400
Bayesian terms so

556
00:25:43,400 --> 00:25:47,039
you see in Montreal problems actually is

557
00:25:47,039 --> 00:25:48,799
a very famous

558
00:25:48,799 --> 00:25:51,539
puzzle I'm not sure if everybody is

559
00:25:51,539 --> 00:25:53,039
familiar with that that I'm going to

560
00:25:53,039 --> 00:25:55,919
briefly sketch sketch it out suppose

561
00:25:55,919 --> 00:25:59,940
that we have three doors

562
00:25:59,940 --> 00:26:05,039
uh behind one of which is a prize so and

563
00:26:05,039 --> 00:26:09,020
uh the moderator of the competition

564
00:26:09,020 --> 00:26:10,740
opens up

565
00:26:10,740 --> 00:26:15,179
a non-surprised non-price door and asks

566
00:26:15,179 --> 00:26:18,659
us if we want to change our initial

567
00:26:18,659 --> 00:26:20,120
choice

568
00:26:20,120 --> 00:26:24,419
of which door we want to open so our

569
00:26:24,419 --> 00:26:27,179
intuition says that uh

570
00:26:27,179 --> 00:26:29,940
regardless of

571
00:26:29,940 --> 00:26:32,880
uh before the opening that door and the

572
00:26:32,880 --> 00:26:35,520
after the opening opening the door our

573
00:26:35,520 --> 00:26:38,880
choice would be just one half of the

574
00:26:38,880 --> 00:26:40,980
probability of being a

575
00:26:40,980 --> 00:26:44,220
the price behind one of those doors but

576
00:26:44,220 --> 00:26:47,100
uh if we look at it in terms of the

577
00:26:47,100 --> 00:26:49,919
Bayesian uh Bayesian inference or

578
00:26:49,919 --> 00:26:53,159
Bayesian probability uh we can see that

579
00:26:53,159 --> 00:26:56,039
it's not actually one half but it's

580
00:26:56,039 --> 00:27:00,059
one-third so we would have a month

581
00:27:00,059 --> 00:27:03,779
much a double we can double our chances

582
00:27:03,779 --> 00:27:06,840
of winning if we change our choice after

583
00:27:06,840 --> 00:27:10,320
the moderator opens uh that non-price

584
00:27:10,320 --> 00:27:13,340
door but this is actually a very

585
00:27:13,340 --> 00:27:17,400
surprising conclusion into I mean in the

586
00:27:17,400 --> 00:27:20,640
sense of psychologically surprising and

587
00:27:20,640 --> 00:27:24,360
it has even uh confused uh some of the

588
00:27:24,360 --> 00:27:26,600
most greatest math some of the greatest

589
00:27:26,600 --> 00:27:30,799
mathematicians for example

590
00:27:30,799 --> 00:27:34,500
didn't accept this but finally after

591
00:27:34,500 --> 00:27:37,039
some uh after seeing some computer

592
00:27:37,039 --> 00:27:40,440
simulations of this problem uh he

593
00:27:40,440 --> 00:27:45,659
finally uh well accepted this result but

594
00:27:45,659 --> 00:27:50,220
the point here is uh to Define surprise

595
00:27:50,220 --> 00:27:53,059
in terms of its uh Bayesian

596
00:27:53,059 --> 00:27:57,120
inference is just a kind of mathematical

597
00:27:57,120 --> 00:28:00,120
uh

598
00:28:00,120 --> 00:28:02,039
the price or it's a kind of

599
00:28:02,039 --> 00:28:04,679
probabilistic concept and it doesn't

600
00:28:04,679 --> 00:28:08,700
necessarily Maps uh Isis isomorphically

601
00:28:08,700 --> 00:28:11,279
or one to one to our psychological

602
00:28:11,279 --> 00:28:13,919
surprise

603
00:28:13,919 --> 00:28:16,380
yeah awesome and this is going to come

604
00:28:16,380 --> 00:28:19,200
up again and again in the textbook and

605
00:28:19,200 --> 00:28:21,960
in our work in active inference like

606
00:28:21,960 --> 00:28:24,299
there'll be a variance parameter and

607
00:28:24,299 --> 00:28:25,559
they'll say this is the anxiety

608
00:28:25,559 --> 00:28:27,779
parameter well

609
00:28:27,779 --> 00:28:30,779
is that one in the same

610
00:28:30,779 --> 00:28:32,400
you know does that parameter value

611
00:28:32,400 --> 00:28:35,340
translate and um it's it's a very

612
00:28:35,340 --> 00:28:37,980
general issue in

613
00:28:37,980 --> 00:28:40,980
parametric cognitive modeling

614
00:28:40,980 --> 00:28:43,799
and also about interpretability of

615
00:28:43,799 --> 00:28:45,900
parameterized models

616
00:28:45,900 --> 00:28:47,640
but it's an important one

617
00:28:47,640 --> 00:28:48,960
so

618
00:28:48,960 --> 00:28:50,940
um one could imagine some ways in a

619
00:28:50,940 --> 00:28:53,100
situation specific way

620
00:28:53,100 --> 00:28:56,240
to address this like if you have

621
00:28:56,240 --> 00:28:58,860
participants in an experiment

622
00:28:58,860 --> 00:29:00,900
uh you're you're making a parametric

623
00:29:00,900 --> 00:29:03,000
cognitive model of they're looking at

624
00:29:03,000 --> 00:29:04,559
the screen and stuff

625
00:29:04,559 --> 00:29:06,539
and so you're able to calculate given

626
00:29:06,539 --> 00:29:07,799
what you believe their cognitive

627
00:29:07,799 --> 00:29:09,240
parameters to be

628
00:29:09,240 --> 00:29:11,279
the surprise and the Bayesian surprise

629
00:29:11,279 --> 00:29:13,260
of different stimuli

630
00:29:13,260 --> 00:29:16,380
and then you could ask them just purely

631
00:29:16,380 --> 00:29:19,679
emotionally how surprising

632
00:29:19,679 --> 00:29:21,840
would you say that was

633
00:29:21,840 --> 00:29:23,460
and then you could do some sort of

634
00:29:23,460 --> 00:29:25,860
correlation between the self-reported

635
00:29:25,860 --> 00:29:28,080
psychological surprise

636
00:29:28,080 --> 00:29:29,760
and

637
00:29:29,760 --> 00:29:32,520
the values that you inferred but one can

638
00:29:32,520 --> 00:29:33,659
already see that there's like some

639
00:29:33,659 --> 00:29:36,179
complexity there

640
00:29:36,179 --> 00:29:38,700
for example around the enculturation of

641
00:29:38,700 --> 00:29:41,159
the communication or understanding of

642
00:29:41,159 --> 00:29:43,320
what psychological surprise is

643
00:29:43,320 --> 00:29:46,860
so on the pro side this is a very

644
00:29:46,860 --> 00:29:48,779
tangible and accessible experience that

645
00:29:48,779 --> 00:29:51,000
people basically get what does it mean

646
00:29:51,000 --> 00:29:52,380
to be surprised you know you open the

647
00:29:52,380 --> 00:29:55,080
box and it's not what you thought

648
00:29:55,080 --> 00:29:56,820
how does that relate to Technical and

649
00:29:56,820 --> 00:29:58,980
formal definitions sometimes it's clear

650
00:29:58,980 --> 00:30:02,360
sometimes it's a little unclear

651
00:30:05,460 --> 00:30:07,559
all right and one more surprise related

652
00:30:07,559 --> 00:30:11,220
question all right table two one

653
00:30:11,220 --> 00:30:14,640
why does gaussian surprise not contain a

654
00:30:14,640 --> 00:30:16,260
variance parameter

655
00:30:16,260 --> 00:30:18,659
why a pi product

656
00:30:18,659 --> 00:30:21,659
why not surprise perhaps equals natural

657
00:30:21,659 --> 00:30:23,880
log of the normal distribution of the

658
00:30:23,880 --> 00:30:25,140
mean

659
00:30:25,140 --> 00:30:29,880
of the um the data point observed mu

660
00:30:29,880 --> 00:30:32,340
commonly used for the mean and sigma

661
00:30:32,340 --> 00:30:35,658
commonly used for the variance

662
00:30:38,159 --> 00:30:40,279
um

663
00:30:42,000 --> 00:30:44,159
I think there's a few

664
00:30:44,159 --> 00:30:47,840
ways to explore this

665
00:30:48,720 --> 00:30:52,200
Pi is also sometimes used as a variance

666
00:30:52,200 --> 00:30:54,000
parameter

667
00:30:54,000 --> 00:30:57,419
so this can be seen as like and it's

668
00:30:57,419 --> 00:30:59,460
multiplied I don't think this is pi as

669
00:30:59,460 --> 00:31:02,460
like a um it's not a big pie it's not a

670
00:31:02,460 --> 00:31:04,260
multiplicative

671
00:31:04,260 --> 00:31:06,539
um product like this Sigma is a big

672
00:31:06,539 --> 00:31:11,460
Sigma and so it's a sum over dot dot dot

673
00:31:11,460 --> 00:31:14,340
whereas a lowercase Sigma smaller font

674
00:31:14,340 --> 00:31:17,460
is used as like a parameter so I believe

675
00:31:17,460 --> 00:31:20,700
that the parameterization that the the

676
00:31:20,700 --> 00:31:22,260
notation that they're using for the

677
00:31:22,260 --> 00:31:24,600
gaussian someone please correct if this

678
00:31:24,600 --> 00:31:25,820
is not true

679
00:31:25,820 --> 00:31:29,460
mu is the mean of the gaussian

680
00:31:29,460 --> 00:31:33,419
Pi is the variance

681
00:31:33,419 --> 00:31:37,220
it's Precision yes

682
00:31:37,399 --> 00:31:41,220
yeah and so by using the pie it alludes

683
00:31:41,220 --> 00:31:43,799
to the p and so this is a Precision

684
00:31:43,799 --> 00:31:45,179
weighted

685
00:31:45,179 --> 00:31:47,100
difference

686
00:31:47,100 --> 00:31:49,919
between the observation and the

687
00:31:49,919 --> 00:31:52,320
parametric mean so we do have both of

688
00:31:52,320 --> 00:31:55,980
the parameters of the gaussian

689
00:31:55,980 --> 00:31:59,820
if the observation is the mean

690
00:31:59,820 --> 00:32:01,919
then it's going to be minimally

691
00:32:01,919 --> 00:32:04,980
surprising as the the residual the

692
00:32:04,980 --> 00:32:07,620
difference between the observation and

693
00:32:07,620 --> 00:32:09,360
the mean increases

694
00:32:09,360 --> 00:32:12,059
then it gets

695
00:32:12,059 --> 00:32:15,020
um more surprising

696
00:32:19,080 --> 00:32:23,159
is there more to add on this

697
00:32:23,159 --> 00:32:28,080
I what I I was expecting to see uh any

698
00:32:28,080 --> 00:32:31,080
quote where there's there's a normal uh

699
00:32:31,080 --> 00:32:34,140
the normal normal function is e to the

700
00:32:34,140 --> 00:32:37,380
minus x minus mu over Sigma squared

701
00:32:37,380 --> 00:32:39,840
whatever oh

702
00:32:39,840 --> 00:32:44,220
I would have thought the surprise was

703
00:32:44,220 --> 00:32:47,520
the negative log probability of that

704
00:32:47,520 --> 00:32:49,620
which actually might come out as x minus

705
00:32:49,620 --> 00:32:51,779
mu

706
00:32:51,779 --> 00:32:54,240
I'm talking through to the answer yeah X

707
00:32:54,240 --> 00:32:58,260
to x minus mu over variance

708
00:32:58,260 --> 00:33:00,480
which is x minus mu times Precision

709
00:33:00,480 --> 00:33:03,179
isn't it so yeah now that makes sense

710
00:33:03,179 --> 00:33:06,059
okay just to just to um ask or clarify

711
00:33:06,059 --> 00:33:07,860
does it have to do with the fact that

712
00:33:07,860 --> 00:33:09,600
the surprise

713
00:33:09,600 --> 00:33:12,600
um fancy eye fancy J whatever however

714
00:33:12,600 --> 00:33:13,980
you want to look at it

715
00:33:13,980 --> 00:33:17,100
um fans uh is in

716
00:33:17,100 --> 00:33:21,299
a natural logged scale

717
00:33:21,299 --> 00:33:24,480
so we don't see a natural log or

718
00:33:24,480 --> 00:33:26,760
anything in

719
00:33:26,760 --> 00:33:28,260
the representation because we're already

720
00:33:28,260 --> 00:33:31,380
in that space

721
00:33:31,380 --> 00:33:34,460
yeah yeah uh I think

722
00:33:34,460 --> 00:33:38,460
me trying to explain myself I answered

723
00:33:38,460 --> 00:33:40,919
the question there I think I think it's

724
00:33:40,919 --> 00:33:43,919
because it's yeah you're taking the log

725
00:33:43,919 --> 00:33:47,100
of an exponent so it just yeah and with

726
00:33:47,100 --> 00:33:49,679
pi now being Precision that will make

727
00:33:49,679 --> 00:33:51,179
sense

728
00:33:51,179 --> 00:33:52,860
awesome

729
00:33:52,860 --> 00:33:55,980
that's great yeah cool

730
00:33:55,980 --> 00:33:59,580
okay now let's move to talking about the

731
00:33:59,580 --> 00:34:02,399
generative model and then at the end

732
00:34:02,399 --> 00:34:04,860
we'll explore

733
00:34:04,860 --> 00:34:06,840
what expected and variational free

734
00:34:06,840 --> 00:34:09,000
energy are with respect to generative

735
00:34:09,000 --> 00:34:11,099
models

736
00:34:11,099 --> 00:34:13,980
so are these ideas

737
00:34:13,980 --> 00:34:15,839
about the fit between the internal

738
00:34:15,839 --> 00:34:18,899
generative model and observations

739
00:34:18,899 --> 00:34:21,839
which is variational free energy that's

740
00:34:21,839 --> 00:34:23,460
equation 2.5

741
00:34:23,460 --> 00:34:26,699
and expected free energy that's 2.6

742
00:34:26,699 --> 00:34:28,859
applicable to States other than ordinary

743
00:34:28,859 --> 00:34:30,359
waking States

744
00:34:30,359 --> 00:34:33,000
so Altered States of cognition or

745
00:34:33,000 --> 00:34:34,859
Consciousness such as sleep dreams

746
00:34:34,859 --> 00:34:36,359
sensory deprivation seemingly

747
00:34:36,359 --> 00:34:38,399
disembodied States

748
00:34:38,399 --> 00:34:40,679
sometimes sensation doesn't seem to play

749
00:34:40,679 --> 00:34:44,119
a large role in experience

750
00:34:48,119 --> 00:34:50,580
there's probably a whole

751
00:34:50,580 --> 00:34:52,800
host of

752
00:34:52,800 --> 00:34:55,980
ways to go here

753
00:34:55,980 --> 00:34:58,020
foreign

754
00:34:58,020 --> 00:35:01,859
so one of them is that the modeling of a

755
00:35:01,859 --> 00:35:03,599
generative model

756
00:35:03,599 --> 00:35:06,720
as being continually engaged in

757
00:35:06,720 --> 00:35:09,720
perception cognition action is

758
00:35:09,720 --> 00:35:12,900
applicable whether the input is boring

759
00:35:12,900 --> 00:35:15,900
or what or not

760
00:35:15,900 --> 00:35:17,280
just one note

761
00:35:17,280 --> 00:35:20,160
another one is while sensory deprivation

762
00:35:20,160 --> 00:35:23,339
it doesn't mean your senses are off

763
00:35:23,339 --> 00:35:26,760
it just means that the novelty or the

764
00:35:26,760 --> 00:35:29,940
diversity of stimuli is reduced or

765
00:35:29,940 --> 00:35:31,020
deprived

766
00:35:31,020 --> 00:35:34,760
but you're still having observations

767
00:35:34,760 --> 00:35:37,320
like the camera if it's on is still

768
00:35:37,320 --> 00:35:39,480
getting observations even when the lens

769
00:35:39,480 --> 00:35:40,980
cover is on

770
00:35:40,980 --> 00:35:44,040
there might be boring or not informative

771
00:35:44,040 --> 00:35:45,900
but

772
00:35:45,900 --> 00:35:47,579
um in the sense that we're talking about

773
00:35:47,579 --> 00:35:49,140
observations

774
00:35:49,140 --> 00:35:51,540
one cannot be deprived of observations

775
00:35:51,540 --> 00:35:56,520
without having that sense just removed

776
00:35:56,520 --> 00:35:58,640
um

777
00:35:58,920 --> 00:36:00,180
okay

778
00:36:00,180 --> 00:36:03,420
sleep in dreams if the modeler chose to

779
00:36:03,420 --> 00:36:05,760
do it that way then I don't see any

780
00:36:05,760 --> 00:36:08,119
reason why not and um

781
00:36:08,119 --> 00:36:12,780
sometimes primary sensation

782
00:36:12,780 --> 00:36:15,240
may not seem to play a large role in

783
00:36:15,240 --> 00:36:16,500
experience

784
00:36:16,500 --> 00:36:17,640
however

785
00:36:17,640 --> 00:36:19,320
it's actually Altered States Of

786
00:36:19,320 --> 00:36:21,780
Consciousness that people have used to

787
00:36:21,780 --> 00:36:24,240
explore the role of the generative model

788
00:36:24,240 --> 00:36:26,339
in perception

789
00:36:26,339 --> 00:36:29,640
so an example of that might be the Albus

790
00:36:29,640 --> 00:36:30,660
paper

791
00:36:30,660 --> 00:36:33,540
by Adam saffron

792
00:36:33,540 --> 00:36:35,579
there's there's this one image it's like

793
00:36:35,579 --> 00:36:37,680
it's like very funny

794
00:36:37,680 --> 00:36:39,580
um

795
00:36:39,580 --> 00:36:40,920
[Music]

796
00:36:40,920 --> 00:36:43,380
it's going to start with a person

797
00:36:43,380 --> 00:36:45,240
um like doing a cup of tea

798
00:36:45,240 --> 00:36:46,560
and then they're going to start talking

799
00:36:46,560 --> 00:36:48,900
to aliens

800
00:36:48,900 --> 00:36:51,300
maybe it's in a later paper by

801
00:36:51,300 --> 00:36:53,720
um saffron

802
00:36:56,160 --> 00:36:58,320
uh so okay so here's different brain

803
00:36:58,320 --> 00:37:00,300
regions and the person's like okay I'm

804
00:37:00,300 --> 00:37:01,920
seeing the Apple here's an affordance

805
00:37:01,920 --> 00:37:03,720
these brain regions are being activated

806
00:37:03,720 --> 00:37:06,180
in a certain way and then I look down at

807
00:37:06,180 --> 00:37:08,040
my foot there's my foot

808
00:37:08,040 --> 00:37:10,500
and then that was the that's the medium

809
00:37:10,500 --> 00:37:12,839
or that's the threshold dose of a of a

810
00:37:12,839 --> 00:37:15,420
psychotropic something

811
00:37:15,420 --> 00:37:18,720
then in the in the medium dose

812
00:37:18,720 --> 00:37:22,320
activation patterns are altering the

813
00:37:22,320 --> 00:37:23,880
vividness

814
00:37:23,880 --> 00:37:26,579
and the association amongst different

815
00:37:26,579 --> 00:37:29,000
ideas

816
00:37:29,040 --> 00:37:30,599
um and then

817
00:37:30,599 --> 00:37:33,180
in the extreme doses this is like

818
00:37:33,180 --> 00:37:35,220
there's like

819
00:37:35,220 --> 00:37:37,320
um

820
00:37:37,320 --> 00:37:39,540
different patterns of linking

821
00:37:39,540 --> 00:37:42,300
that are leading to experiences that on

822
00:37:42,300 --> 00:37:44,220
one hand somebody could say Well they're

823
00:37:44,220 --> 00:37:45,540
they're lifted from the sensory

824
00:37:45,540 --> 00:37:47,040
observations

825
00:37:47,040 --> 00:37:50,099
but another way to put it is the ongoing

826
00:37:50,099 --> 00:37:53,040
flow of sensory observations

827
00:37:53,040 --> 00:37:54,660
is being

828
00:37:54,660 --> 00:37:55,260
um

829
00:37:55,260 --> 00:37:57,240
integrated and processed differently

830
00:37:57,240 --> 00:37:58,260
it's leading to a different

831
00:37:58,260 --> 00:38:01,280
self-organized harmonic mode in the

832
00:38:01,280 --> 00:38:04,079
language of saffron

833
00:38:04,079 --> 00:38:06,839
such that the perception the experience

834
00:38:06,839 --> 00:38:09,000
which is what we have

835
00:38:09,000 --> 00:38:11,339
is different

836
00:38:11,339 --> 00:38:14,940
and one like little piece of lore around

837
00:38:14,940 --> 00:38:18,180
the Albus is Carhart Harris who's a

838
00:38:18,180 --> 00:38:20,760
psychedelics researcher in friston wrote

839
00:38:20,760 --> 00:38:24,420
this paper Rebus relaxed beliefs under

840
00:38:24,420 --> 00:38:27,540
psychedelics just relax

841
00:38:27,540 --> 00:38:32,760
and then Adam followed with this paper

842
00:38:32,760 --> 00:38:36,060
Albus it's like well it's not simply

843
00:38:36,060 --> 00:38:38,280
relaxed beliefs

844
00:38:38,280 --> 00:38:41,820
in fact in the hierarchical predictive

845
00:38:41,820 --> 00:38:43,619
processing architecture

846
00:38:43,619 --> 00:38:46,920
some beliefs might be strengthened

847
00:38:46,920 --> 00:38:49,619
like top-down priors

848
00:38:49,619 --> 00:38:52,740
might be strengthened in their impact

849
00:38:52,740 --> 00:38:55,140
and that's why the priors might be seen

850
00:38:55,140 --> 00:38:58,260
like in a in a static field

851
00:38:58,260 --> 00:39:00,960
you still like there might be ways in

852
00:39:00,960 --> 00:39:03,000
which actually top-down beliefs are

853
00:39:03,000 --> 00:39:04,859
sharpened and that's why

854
00:39:04,859 --> 00:39:07,200
sounds could be heard from water

855
00:39:07,200 --> 00:39:08,460
bubbling

856
00:39:08,460 --> 00:39:11,220
or images could be seen

857
00:39:11,220 --> 00:39:14,700
in the static or in the tea leaves

858
00:39:14,700 --> 00:39:17,460
so it's not just like relaxed beliefs

859
00:39:17,460 --> 00:39:21,740
simply it just more generally altered

860
00:39:25,740 --> 00:39:28,380
and that sets up perfectly to go through

861
00:39:28,380 --> 00:39:31,020
equation two five and two six and this

862
00:39:31,020 --> 00:39:33,740
related question

863
00:39:34,200 --> 00:39:36,799
all right

864
00:39:37,079 --> 00:39:38,820
so

865
00:39:38,820 --> 00:39:40,800
we're going to look at equation 2.5 and

866
00:39:40,800 --> 00:39:42,240
2.6

867
00:39:42,240 --> 00:39:47,180
and explore how tractable they are

868
00:39:50,280 --> 00:39:51,599
let's

869
00:39:51,599 --> 00:39:54,660
recall equation 2 5 and 2 6. so first

870
00:39:54,660 --> 00:39:56,640
as always thanks for the Epic work to

871
00:39:56,640 --> 00:40:01,020
the people who who added derivations

872
00:40:01,020 --> 00:40:02,280
and

873
00:40:02,280 --> 00:40:06,560
the natural language descriptions

874
00:40:06,839 --> 00:40:08,160
okay

875
00:40:08,160 --> 00:40:12,420
so what is happening in equation 2.5

876
00:40:12,420 --> 00:40:14,520
what variables are coming into the

877
00:40:14,520 --> 00:40:15,420
picture

878
00:40:15,420 --> 00:40:17,940
and how are they being processed

879
00:40:17,940 --> 00:40:19,920
what is this

880
00:40:19,920 --> 00:40:22,859
F describing

881
00:40:22,859 --> 00:40:25,260
what's the situation where f is Big

882
00:40:25,260 --> 00:40:29,599
what's the situation where f is low

883
00:40:30,359 --> 00:40:34,520
does anyone want to give a thought first

884
00:40:46,500 --> 00:40:48,839
also in these descriptions

885
00:40:48,839 --> 00:40:51,780
the letters are connected to the

886
00:40:51,780 --> 00:40:54,420
ontology terms so just a few that are

887
00:40:54,420 --> 00:40:57,780
important to know is X are the hidden

888
00:40:57,780 --> 00:40:58,800
States

889
00:40:58,800 --> 00:41:02,040
why are the observations

890
00:41:02,040 --> 00:41:05,280
that's one important one

891
00:41:05,280 --> 00:41:05,940
um

892
00:41:05,940 --> 00:41:10,500
another important one is that P and Q

893
00:41:10,500 --> 00:41:13,320
are two distributions

894
00:41:13,320 --> 00:41:15,480
Q is like the posterior updated

895
00:41:15,480 --> 00:41:18,140
distribution

896
00:41:20,840 --> 00:41:22,380
[Music]

897
00:41:22,380 --> 00:41:24,060
does anyone want to add anything on two

898
00:41:24,060 --> 00:41:27,060
five or two six or like

899
00:41:27,060 --> 00:41:27,780
um

900
00:41:27,780 --> 00:41:29,400
we can start to think about what it's

901
00:41:29,400 --> 00:41:33,079
actually doing or calculating

902
00:41:34,380 --> 00:41:39,200
okay so some pieces to note

903
00:41:39,240 --> 00:41:41,339
variational free energy

904
00:41:41,339 --> 00:41:44,339
is not prospective

905
00:41:44,339 --> 00:41:48,000
it's dealing with the real-time

906
00:41:48,000 --> 00:41:51,420
flow of data a single data point in the

907
00:41:51,420 --> 00:41:52,680
presence

908
00:41:52,680 --> 00:41:56,940
and then how that data points

909
00:41:56,940 --> 00:41:59,160
can be evaluated

910
00:41:59,160 --> 00:42:04,220
with respect to the current

911
00:42:04,740 --> 00:42:07,140
parameterization

912
00:42:07,140 --> 00:42:09,660
of that data point

913
00:42:09,660 --> 00:42:13,140
so this is like a function f variational

914
00:42:13,140 --> 00:42:15,060
free energy and it's going to be

915
00:42:15,060 --> 00:42:17,820
bringing two arguments in

916
00:42:17,820 --> 00:42:20,099
those two arguments like the two things

917
00:42:20,099 --> 00:42:22,260
that we need to combine

918
00:42:22,260 --> 00:42:25,440
which they happen to be functions Q is a

919
00:42:25,440 --> 00:42:26,460
function

920
00:42:26,460 --> 00:42:29,099
and so f is called a functional because

921
00:42:29,099 --> 00:42:31,560
it's like a function of a function

922
00:42:31,560 --> 00:42:33,720
so what we need to know to calculate key

923
00:42:33,720 --> 00:42:36,180
to calculate f is

924
00:42:36,180 --> 00:42:39,300
um this variational distribution and the

925
00:42:39,300 --> 00:42:42,079
incoming data point

926
00:42:42,420 --> 00:42:43,859
um

927
00:42:43,859 --> 00:42:45,420
one other thing to keep in mind before

928
00:42:45,420 --> 00:42:48,660
we jump into it is

929
00:42:48,660 --> 00:42:51,240
we talk about like minimizing free

930
00:42:51,240 --> 00:42:53,820
energy but with a negative sign

931
00:42:53,820 --> 00:42:56,760
minimizing and maximizing are the same

932
00:42:56,760 --> 00:42:58,440
so

933
00:42:58,440 --> 00:43:00,599
um we can just think about as minimizing

934
00:43:00,599 --> 00:43:02,160
or maximizing as just like a

935
00:43:02,160 --> 00:43:04,680
relativization procedure

936
00:43:04,680 --> 00:43:07,380
and it turns out that

937
00:43:07,380 --> 00:43:09,839
in this minimization framework free

938
00:43:09,839 --> 00:43:11,700
energy minimization expected free energy

939
00:43:11,700 --> 00:43:13,680
minimization

940
00:43:13,680 --> 00:43:15,839
um are like

941
00:43:15,839 --> 00:43:19,980
the less surprising ones

942
00:43:19,980 --> 00:43:21,780
which are going to be understood to be

943
00:43:21,780 --> 00:43:23,339
the better ones

944
00:43:23,339 --> 00:43:25,380
or more preferable because they're more

945
00:43:25,380 --> 00:43:27,599
consistent with being that kind of a

946
00:43:27,599 --> 00:43:29,160
thing

947
00:43:29,160 --> 00:43:33,440
those are going to have lower values

948
00:43:35,160 --> 00:43:37,339
okay

949
00:43:37,619 --> 00:43:40,800
now just some of the like

950
00:43:40,800 --> 00:43:43,140
um sub functions

951
00:43:43,140 --> 00:43:44,819
fancy e

952
00:43:44,819 --> 00:43:48,240
is an expectation of so we talked about

953
00:43:48,240 --> 00:43:50,339
it previously but this is not like a

954
00:43:50,339 --> 00:43:52,619
future expectation like expected Returns

955
00:43:52,619 --> 00:43:54,960
on investments this is like the

956
00:43:54,960 --> 00:43:58,319
expectation of a gaussian with a mean of

957
00:43:58,319 --> 00:44:00,119
four and a variance of one the

958
00:44:00,119 --> 00:44:01,920
expectation is four

959
00:44:01,920 --> 00:44:04,859
so this is like an average

960
00:44:04,859 --> 00:44:08,779
of some other distribution

961
00:44:08,940 --> 00:44:14,579
in contrast H is an entropy function

962
00:44:14,579 --> 00:44:17,480
the entropy is taking in a distribution

963
00:44:17,480 --> 00:44:19,920
and then

964
00:44:19,920 --> 00:44:24,000
um it is calculating how dispersed that

965
00:44:24,000 --> 00:44:26,280
distribution is

966
00:44:26,280 --> 00:44:30,800
how disordered that distribution is

967
00:44:30,839 --> 00:44:34,319
Ln is the natural log so that's a

968
00:44:34,319 --> 00:44:36,540
logarithm and then the only other kind

969
00:44:36,540 --> 00:44:39,000
of like wrapper here

970
00:44:39,000 --> 00:44:42,420
is this KL Divergence

971
00:44:42,420 --> 00:44:44,880
and so KL Divergence we talked about it

972
00:44:44,880 --> 00:44:48,180
last time as well the two lines are like

973
00:44:48,180 --> 00:44:50,579
the two distributions that the KL

974
00:44:50,579 --> 00:44:52,859
Divergence is contrasting

975
00:44:52,859 --> 00:44:56,640
okay so if we're taking expectations

976
00:44:56,640 --> 00:44:57,780
then

977
00:44:57,780 --> 00:45:00,420
the higher the value

978
00:45:00,420 --> 00:45:02,400
the higher the expectation is this is

979
00:45:02,400 --> 00:45:04,200
just like the average height in the

980
00:45:04,200 --> 00:45:05,760
classroom expectation of the height of

981
00:45:05,760 --> 00:45:07,440
the class

982
00:45:07,440 --> 00:45:10,079
higher expectation

983
00:45:10,079 --> 00:45:14,099
higher internally goes to higher here

984
00:45:14,099 --> 00:45:18,000
for entropy more dispersed is higher

985
00:45:18,000 --> 00:45:20,480
entropy

986
00:45:20,760 --> 00:45:23,819
for natural log it's a transformation of

987
00:45:23,819 --> 00:45:25,619
a number

988
00:45:25,619 --> 00:45:29,700
but they're monotonically related so as

989
00:45:29,700 --> 00:45:31,319
the number gets bigger the natural log

990
00:45:31,319 --> 00:45:34,319
gets bigger too it slows down in how

991
00:45:34,319 --> 00:45:37,619
fast it gets bigger but a bigger number

992
00:45:37,619 --> 00:45:39,900
on the number line is always going to

993
00:45:39,900 --> 00:45:42,900
have a higher natural log

994
00:45:42,900 --> 00:45:44,460
just keep in mind that there's like a

995
00:45:44,460 --> 00:45:46,680
minus sign so it's actually like

996
00:45:46,680 --> 00:45:49,020
the other the other way and then lastly

997
00:45:49,020 --> 00:45:50,579
the KL Divergence if these two

998
00:45:50,579 --> 00:45:52,980
distributions are the same their

999
00:45:52,980 --> 00:45:54,900
Divergence is zero

1000
00:45:54,900 --> 00:45:57,780
and when the distributions are

1001
00:45:57,780 --> 00:46:00,720
increasingly different this KL term

1002
00:46:00,720 --> 00:46:02,880
becomes bigger

1003
00:46:02,880 --> 00:46:03,900
okay

1004
00:46:03,900 --> 00:46:08,000
anyone want to add a comment in here

1005
00:46:09,599 --> 00:46:12,079
yes Ali

1006
00:46:12,079 --> 00:46:15,060
and then Giuseppe

1007
00:46:15,060 --> 00:46:18,720
uh yeah I just wanted to mention that uh

1008
00:46:18,720 --> 00:46:21,540
for I mean for the expected or a

1009
00:46:21,540 --> 00:46:23,339
variation of free energy and the

1010
00:46:23,339 --> 00:46:26,520
expected free energy uh computations are

1011
00:46:26,520 --> 00:46:30,480
not that costly but uh when we come

1012
00:46:30,480 --> 00:46:31,099
to

1013
00:46:31,099 --> 00:46:35,339
uh Computing uh the priors over over all

1014
00:46:35,339 --> 00:46:38,520
the uh policies up to a specific time

1015
00:46:38,520 --> 00:46:42,300
Horizon uh that would increase the

1016
00:46:42,300 --> 00:46:44,640
complexity I mean it has an exponential

1017
00:46:44,640 --> 00:46:48,060
complexity class so that's why some

1018
00:46:48,060 --> 00:46:51,480
people have experimented with

1019
00:46:51,480 --> 00:46:53,220
um proposing some alternative

1020
00:46:53,220 --> 00:46:57,020
implementations for active inference

1021
00:46:57,020 --> 00:47:00,480
for example one of which is branching

1022
00:47:00,480 --> 00:47:02,819
in time active inference which reduces

1023
00:47:02,819 --> 00:47:06,000
this complexity significantly or the

1024
00:47:06,000 --> 00:47:08,760
work by Baron millage and so on uh but

1025
00:47:08,760 --> 00:47:10,099
yes

1026
00:47:10,099 --> 00:47:13,440
I mean the expected free energy or the

1027
00:47:13,440 --> 00:47:15,200
variation of free energy

1028
00:47:15,200 --> 00:47:17,060
uh

1029
00:47:17,060 --> 00:47:21,300
I mean they're not costly per uh by

1030
00:47:21,300 --> 00:47:23,520
themselves but

1031
00:47:23,520 --> 00:47:24,480
um

1032
00:47:24,480 --> 00:47:27,420
when the policy comes along uh that's a

1033
00:47:27,420 --> 00:47:29,220
different story

1034
00:47:29,220 --> 00:47:31,500
yeah just one quick note and then

1035
00:47:31,500 --> 00:47:36,240
Giuseppe um the variational framework is

1036
00:47:36,240 --> 00:47:37,940
attractability

1037
00:47:37,940 --> 00:47:39,960
increasing move

1038
00:47:39,960 --> 00:47:41,700
from the outset

1039
00:47:41,700 --> 00:47:44,339
we have a factorized model so it's not

1040
00:47:44,339 --> 00:47:46,140
like every variable influences every

1041
00:47:46,140 --> 00:47:49,440
variable and what variational inference

1042
00:47:49,440 --> 00:47:53,720
does is it actually uses specific

1043
00:47:53,720 --> 00:47:57,060
optimizable families of distributions

1044
00:47:57,060 --> 00:47:59,400
that are set by the modeler

1045
00:47:59,400 --> 00:48:03,060
and takes into account the sparsity of

1046
00:48:03,060 --> 00:48:05,640
the variables how they're related and it

1047
00:48:05,640 --> 00:48:07,859
turns out that that's actually

1048
00:48:07,859 --> 00:48:10,500
um for what it is a very tractable

1049
00:48:10,500 --> 00:48:11,520
approach

1050
00:48:11,520 --> 00:48:12,900
then

1051
00:48:12,900 --> 00:48:15,180
within this variational inference

1052
00:48:15,180 --> 00:48:16,380
framework

1053
00:48:16,380 --> 00:48:19,380
the F variational free energy is going

1054
00:48:19,380 --> 00:48:20,579
to be like

1055
00:48:20,579 --> 00:48:22,560
far more computable because all it's

1056
00:48:22,560 --> 00:48:24,780
doing is taking in one data point and

1057
00:48:24,780 --> 00:48:26,880
then comparing it with the priors

1058
00:48:26,880 --> 00:48:28,920
basically

1059
00:48:28,920 --> 00:48:31,500
whereas expected free energy is

1060
00:48:31,500 --> 00:48:33,560
conditioned upon

1061
00:48:33,560 --> 00:48:36,180
counterfactual policies

1062
00:48:36,180 --> 00:48:38,040
and so that requires enumerating

1063
00:48:38,040 --> 00:48:40,680
policies of a given time Horizon

1064
00:48:40,680 --> 00:48:43,200
and then evaluating them relative to

1065
00:48:43,200 --> 00:48:44,099
each other

1066
00:48:44,099 --> 00:48:47,819
and so while each given consideration is

1067
00:48:47,819 --> 00:48:50,280
not that computationally challenging as

1068
00:48:50,280 --> 00:48:52,740
Ali mentions the space of possible

1069
00:48:52,740 --> 00:48:55,680
policies can be vast so if one has like

1070
00:48:55,680 --> 00:48:57,960
four affordances like four you can go up

1071
00:48:57,960 --> 00:49:00,119
down left right and you want to consider

1072
00:49:00,119 --> 00:49:02,040
a Time Horizon of two

1073
00:49:02,040 --> 00:49:05,520
you have 16 policies of time step length

1074
00:49:05,520 --> 00:49:06,420
too

1075
00:49:06,420 --> 00:49:08,160
but if you wanted to consider policies

1076
00:49:08,160 --> 00:49:10,319
of time step length 100

1077
00:49:10,319 --> 00:49:11,700
you would have

1078
00:49:11,700 --> 00:49:13,800
of course an exponentially increasing

1079
00:49:13,800 --> 00:49:16,380
number of possible ways to look and

1080
00:49:16,380 --> 00:49:18,300
that's what motivates

1081
00:49:18,300 --> 00:49:21,839
um not just the variational approach

1082
00:49:21,839 --> 00:49:24,300
which like does kind of as well as we

1083
00:49:24,300 --> 00:49:28,440
can within a given policy but also tree

1084
00:49:28,440 --> 00:49:30,599
search and selection strategies not

1085
00:49:30,599 --> 00:49:33,060
unlike chess playing computers in the

1086
00:49:33,060 --> 00:49:34,140
80s

1087
00:49:34,140 --> 00:49:35,880
where it was like well we can't just

1088
00:49:35,880 --> 00:49:38,760
consider every Branch but if we prune a

1089
00:49:38,760 --> 00:49:40,319
branch just because there's one move

1090
00:49:40,319 --> 00:49:42,420
that doesn't look awesome we're going to

1091
00:49:42,420 --> 00:49:44,700
be doing just local optimization and so

1092
00:49:44,700 --> 00:49:46,980
it's always this balance with using

1093
00:49:46,980 --> 00:49:50,160
generative models to explore branches

1094
00:49:50,160 --> 00:49:54,060
more comprehensively and deeply but not

1095
00:49:54,060 --> 00:49:56,400
prune them preemptively in case there's

1096
00:49:56,400 --> 00:49:58,859
like you know a sacrifice of a pawn and

1097
00:49:58,859 --> 00:50:00,660
then it gets you a castle

1098
00:50:00,660 --> 00:50:03,540
so you don't want to discard that move

1099
00:50:03,540 --> 00:50:06,240
but as those get more and more sparse

1100
00:50:06,240 --> 00:50:08,760
will you sacrifice upon in 200 moves

1101
00:50:08,760 --> 00:50:10,740
later you get the castle

1102
00:50:10,740 --> 00:50:12,240
it's hard to imagine just from

1103
00:50:12,240 --> 00:50:14,700
information Theory perspective how that

1104
00:50:14,700 --> 00:50:16,020
needle in the haystack is going to be

1105
00:50:16,020 --> 00:50:16,800
found

1106
00:50:16,800 --> 00:50:19,400
Giuseppe

1107
00:50:20,819 --> 00:50:24,900
um yes now just just a couple of um

1108
00:50:24,900 --> 00:50:27,060
of details for the people that are not

1109
00:50:27,060 --> 00:50:31,619
too too versed mathematically that the

1110
00:50:31,619 --> 00:50:34,520
in the in the equation 2.5

1111
00:50:34,520 --> 00:50:38,300
uh one thing to to

1112
00:50:38,300 --> 00:50:41,220
highlight is that the expectation of

1113
00:50:41,220 --> 00:50:45,140
what is in in square brackets is always

1114
00:50:45,140 --> 00:50:48,059
expectation with respect to a specific

1115
00:50:48,059 --> 00:50:50,700
probability which is in this case the

1116
00:50:50,700 --> 00:50:55,500
the approximate posterior QX so it's a

1117
00:50:55,500 --> 00:50:58,940
kind of a if you want a weighted average

1118
00:50:58,940 --> 00:51:02,099
but with the weights provided by that

1119
00:51:02,099 --> 00:51:05,700
specific probability

1120
00:51:06,660 --> 00:51:09,780
so it's an integral but and and also

1121
00:51:09,780 --> 00:51:12,780
that entropy is basically the

1122
00:51:12,780 --> 00:51:16,640
the average surprise

1123
00:51:18,720 --> 00:51:22,260
awesome very nice Point entropy

1124
00:51:22,260 --> 00:51:26,160
is average surprise

1125
00:51:26,760 --> 00:51:29,940
or we can say it's the expectation of

1126
00:51:29,940 --> 00:51:31,440
surprise

1127
00:51:31,440 --> 00:51:34,079
um yes yes yeah

1128
00:51:34,079 --> 00:51:36,839
so and and this is kind of where we

1129
00:51:36,839 --> 00:51:38,400
start to see

1130
00:51:38,400 --> 00:51:42,359
some of these um like make it fit well

1131
00:51:42,359 --> 00:51:44,280
but don't fit too well

1132
00:51:44,280 --> 00:51:47,700
if we can bound you can say I have what

1133
00:51:47,700 --> 00:51:49,140
I believe to be

1134
00:51:49,140 --> 00:51:51,900
the just all things considered the best

1135
00:51:51,900 --> 00:51:52,920
model

1136
00:51:52,920 --> 00:51:56,220
because I'm expecting 10 plus or minus

1137
00:51:56,220 --> 00:51:57,359
one

1138
00:51:57,359 --> 00:52:00,599
and so even though not every single poll

1139
00:52:00,599 --> 00:52:02,700
is 10

1140
00:52:02,700 --> 00:52:05,640
so I'm getting a non-zero surprise as

1141
00:52:05,640 --> 00:52:10,859
I'm pulling you know 9.5 10.5 10.3 9.8

1142
00:52:10,859 --> 00:52:14,579
but my model of 10 with an expected

1143
00:52:14,579 --> 00:52:15,900
surprise

1144
00:52:15,900 --> 00:52:19,020
I wouldn't change a thing about it

1145
00:52:19,020 --> 00:52:22,140
that's where variational free energy can

1146
00:52:22,140 --> 00:52:24,500
get you

1147
00:52:27,619 --> 00:52:31,920
Jacob provided some derivations that

1148
00:52:31,920 --> 00:52:34,559
connect the first line

1149
00:52:34,559 --> 00:52:37,520
to the second line

1150
00:52:38,460 --> 00:52:41,160
so that's one interesting thing to

1151
00:52:41,160 --> 00:52:42,480
explore

1152
00:52:42,480 --> 00:52:45,180
and a really nice move here that's

1153
00:52:45,180 --> 00:52:46,559
highlighted

1154
00:52:46,559 --> 00:52:48,000
is

1155
00:52:48,000 --> 00:52:50,880
um using some of the the definitions of

1156
00:52:50,880 --> 00:52:54,300
the operations of natural logs

1157
00:52:54,300 --> 00:52:58,559
to separate them as basically like a a

1158
00:52:58,559 --> 00:53:01,800
sum of logs

1159
00:53:01,800 --> 00:53:04,680
and for logs adding them is

1160
00:53:04,680 --> 00:53:07,079
multiplication and subtracting them is

1161
00:53:07,079 --> 00:53:09,500
division

1162
00:53:10,260 --> 00:53:13,500
um so that's why like Ln of Q of x minus

1163
00:53:13,500 --> 00:53:16,020
Ln of P of X can be written as Ln of Q

1164
00:53:16,020 --> 00:53:17,520
over p

1165
00:53:17,520 --> 00:53:21,839
and then this the expectation

1166
00:53:21,839 --> 00:53:24,180
of the natural log

1167
00:53:24,180 --> 00:53:25,980
of a distribution divided by another

1168
00:53:25,980 --> 00:53:27,240
distribution

1169
00:53:27,240 --> 00:53:31,200
is the definition of the KL Divergence

1170
00:53:31,200 --> 00:53:32,880
so that's where the KL comes from

1171
00:53:32,880 --> 00:53:35,119
actually

1172
00:53:35,640 --> 00:53:38,160
um so that's one really nice

1173
00:53:38,160 --> 00:53:42,440
piece to um think about

1174
00:53:42,480 --> 00:53:46,020
and then with how line one

1175
00:53:46,020 --> 00:53:48,420
gets to line three

1176
00:53:48,420 --> 00:53:50,940
one can also Trace

1177
00:53:50,940 --> 00:53:53,339
how the variables are kind of being like

1178
00:53:53,339 --> 00:53:56,099
split and recombined

1179
00:53:56,099 --> 00:53:59,460
and each of these formalizations are

1180
00:53:59,460 --> 00:54:01,280
going to have like a slightly different

1181
00:54:01,280 --> 00:54:04,380
advantage in certain situations

1182
00:54:04,380 --> 00:54:07,440
like entropy you have a term that's only

1183
00:54:07,440 --> 00:54:10,920
dependent upon the hidden State expected

1184
00:54:10,920 --> 00:54:13,400
surprise

1185
00:54:14,040 --> 00:54:16,280
here you have a term with evidence

1186
00:54:16,280 --> 00:54:19,319
that's only dependent upon the

1187
00:54:19,319 --> 00:54:21,359
information coming in

1188
00:54:21,359 --> 00:54:24,960
so this can be seen as actually like

1189
00:54:24,960 --> 00:54:26,700
um a constant

1190
00:54:26,700 --> 00:54:29,400
with respect to your optimization of

1191
00:54:29,400 --> 00:54:32,640
beliefs about hidden States

1192
00:54:32,640 --> 00:54:34,440
and so that can even simplify some

1193
00:54:34,440 --> 00:54:37,520
optimizations further

1194
00:54:37,800 --> 00:54:39,800
um

1195
00:54:39,900 --> 00:54:42,660
equation six kind of rhymes with

1196
00:54:42,660 --> 00:54:46,040
equation 2.5

1197
00:54:47,220 --> 00:54:50,220
the partitionings are different

1198
00:54:50,220 --> 00:54:52,079
but you'll find that the operations

1199
00:54:52,079 --> 00:54:54,119
which are used

1200
00:54:54,119 --> 00:54:57,059
are analogous we see expectations over

1201
00:54:57,059 --> 00:55:00,180
belief distributions

1202
00:55:00,180 --> 00:55:03,420
we see KL divergences

1203
00:55:03,420 --> 00:55:07,819
and we see entropy terms

1204
00:55:10,020 --> 00:55:13,140
we also notice that the function or the

1205
00:55:13,140 --> 00:55:14,579
functional G

1206
00:55:14,579 --> 00:55:17,280
is over policies

1207
00:55:17,280 --> 00:55:19,440
because the arguments that are being

1208
00:55:19,440 --> 00:55:21,000
taken into account

1209
00:55:21,000 --> 00:55:23,880
for expected free energy have to be

1210
00:55:23,880 --> 00:55:26,700
the policies and beliefs about those

1211
00:55:26,700 --> 00:55:28,260
policies like their consequence on

1212
00:55:28,260 --> 00:55:29,220
sensory

1213
00:55:29,220 --> 00:55:31,319
um outcomes

1214
00:55:31,319 --> 00:55:34,800
and that's why almost everywhere you see

1215
00:55:34,800 --> 00:55:38,480
it's conditioning on policy

1216
00:55:38,640 --> 00:55:41,760
so it's like there's four options

1217
00:55:41,760 --> 00:55:43,859
we're going to calculate

1218
00:55:43,859 --> 00:55:46,559
a few things and and this will return to

1219
00:55:46,559 --> 00:55:48,359
it so

1220
00:55:48,359 --> 00:55:52,020
um but one of the key pieces is that

1221
00:55:52,020 --> 00:55:55,579
pragmatic value like kind of the the

1222
00:55:55,579 --> 00:55:59,099
imperative of pragmatism

1223
00:55:59,099 --> 00:56:01,859
is not the maximization

1224
00:56:01,859 --> 00:56:05,579
of a reward which is common in reward

1225
00:56:05,579 --> 00:56:08,099
maximization and reinforcement learning

1226
00:56:08,099 --> 00:56:12,300
but rather it's um going to be about the

1227
00:56:12,300 --> 00:56:15,119
reduction of difference

1228
00:56:15,119 --> 00:56:19,099
between preferences and observations

1229
00:56:22,740 --> 00:56:25,459
all right well

1230
00:56:28,200 --> 00:56:29,700
thanks for this

1231
00:56:29,700 --> 00:56:32,118
meeting

1232
00:56:34,920 --> 00:56:38,160
that was the end of chapter two

1233
00:56:38,160 --> 00:56:40,220
in the next two weeks we're going to be

1234
00:56:40,220 --> 00:56:43,619
heading into chapter three

1235
00:56:43,619 --> 00:56:46,800
that's going to be the high road to

1236
00:56:46,800 --> 00:56:48,540
active inference

1237
00:56:48,540 --> 00:56:50,400
so chapter two started with like the

1238
00:56:50,400 --> 00:56:53,040
Bayes theorem and the frog jumping out

1239
00:56:53,040 --> 00:56:54,599
of the hand

1240
00:56:54,599 --> 00:56:56,579
here we're going to introduce Markov

1241
00:56:56,579 --> 00:56:59,400
blanket formalism and talk about some

1242
00:56:59,400 --> 00:57:02,880
imperatives of surprise minimization and

1243
00:57:02,880 --> 00:57:04,440
the principle of least action and a few

1244
00:57:04,440 --> 00:57:07,619
other things so thank you everybody see

1245
00:57:07,619 --> 00:57:08,880
you soon

1246
00:57:08,880 --> 00:57:11,660
thank you Daniel

