SPEAKER_00:
Hello, everyone.

Thanks for joining or listening.

It's November 11th, 11-11-22, and we're in cohort two of the Active Textbook Group, having a discussion of chapter five, exploring some topics.

There are some questions that have been written in comments as well, and then

taking it wherever we want as we review the first half of the book.

That'll be today.

And then next week, we'll be taking an even further step back into

and more of a focus on like feedback, completing the feedback form, how can we improve and structure future textbook group cohorts, project ideas, and so on.

But for today, we're in chapter five.

So does anyone want to give any thoughts or comments or just initial questions to raise about chapter five?

all right then let's go into the written questions okay how does the simple hierarchy with one-to-one mapping between levels as shown in the left-hand side of figures four four or six

and 5.2 okay four four four six five two

relate to actual brain hierarchies such as the classic fellerman and van essen diagram from retinal ganglion cells up to hippocampus with many to many mapping between regional units ah i guess this is the famous diagram

well what do people think how do these seemingly skyscraper-like hierarchical models this one is laid out side to side but we can see ascending and descending so this could have been graphically laid out like this and then another one and then a third one on top of course top down bottom up are just spatial metaphors so um how do we reconcile

computational hierarchical models with the empirical structural connectivity of the brain, which has a wiring structure looking like this.

Ali?


SPEAKER_02:
between these two kinds of icons or kinds of maps, because on one hand, we have a kind of relational map.

And on the other hand, there is a kind of architectural slash functional mapping of the brain.

So for example, if we look at a circuit map of the of an electric circuit, there's, we have a relational map there, right.

But

when we want to implement that circuit, I mean, in terms of wiring and so on, we need to have another kind of map, which is architectural one.

So, of course, in some cases, there's a possibility of translating one map perfectly onto the other, but there isn't necessarily an isomorphism between


SPEAKER_00:
those two kinds of map and i think in this case we don't necessarily see that isomorphism here as well excellent great answer totally agreed these kinds of diagrams are often described as hierarchical or heterarchical or people use different um

words to describe it, but it's describing the anatomical connectivity of different brain regions.

Whereas the diagrams that are shown in these figures that were mentioned in the question are not anatomical regions.

They're statistical variables connected by edges.

This is the difference between structural and effective and functional connectivity.

Structural connectivity is what pieces are actually put together and through direct contact intermediating.

Whereas functional connectivity has to do with the statistical relationships in the system.

And those are not necessarily for a given set of measurements or spatial or temporal scale or experimental stimuli.

Those are not exactly the same thing.

There are cases where there are, but that doesn't mean that in general, they're the same thing.

So how do they relate to quote actual brain hierarchies?

They relate to each other in the way that Ali just described, similarly between architectural diagram and a functional diagram.

Does anyone have any other thoughts on this?

Yeah, Giuseppe?


SPEAKER_03:
Yeah, I think that is a very good explanation.

On the other hand, I think that at that stage of the description, the idea was to see how active inference could also provide a process theory.

So basically to see how this inferential mechanism may be

implemented in the neural circuits so yes the two are not completely the two descriptions are not isomorphic but i think there should be some degree of of agreement and in this case i think that what may be masking the the the similarities or the the potential overlap is that

you know, there's a big difference in the degree of complexity of the, so one is a very simple, the active inference diagram is a very simple sketch of a very simple microcircuit while this one is a big architecture with a lot of complexity and it's difficult to go in and say, you know, to map exactly

those kind of microcircuits within this large circuit scheme, probably there is going to be various microcircuits in there with the various degrees of hierarchical structure within that large scheme, I guess.


SPEAKER_00:
yeah um all great points the figures that were pointed to reflect like just simple illustrative examples

Whereas the whole brain or many of the regions of the brain, if one were to even just describe this with an active inference model, it wouldn't look as simple and narrow as these previous figures.

So it's a different type of diagram.

It's a different scale.

Yet through visual and prose-based argumentation, as well as the hopes and dreams of a field,

is that there is a relationship between the messages that are passed between different variables statistically, which as we discussed last time, you could arrange these in a hexagon.

It wouldn't change the topology and thus the function of the base graph.

However, it is being laid out in a specific way to demonstrate resonance with given cellular populations in a cortical column.

So it's kind of situational to what extent the structural neuroanatomy aligns with the Bayes graph as specified.

But we can definitely say that they're not the same thing, that they don't have to be the same thing.

But there's also situations where by graphical design,

Using that in multiple ways, meaning you could constrain your construction of the base graph such that it has some structural patterns with the anatomy.

And then also just in terms of like visual graphical design.

Like you can just lay it out visually because this is not, these aren't, it's not exactly like there's five and then three, like there's other things that are here that aren't shown here.

So like this is a course mapping.

Any other thoughts on this question asked?


SPEAKER_01:
just really briefly, I feel like the 30 millionth of view of the like structural constraints is that in the general case of a Bayes graph, you're well in active inference, we're talking about like a Markov chain or some blanket that is kind of ultimately the state space kind of, which is included in it.

Um,

If you're trying to map that to a brain or any kind of system with discrete units that are close sometimes and not so close, then the arrangement of those will constrain necessarily the Bayes graph to some degree.

If they're right next to each other, then

there's going to be a greater chance that they are independence, some sort of dependency relationship, even if we like disparate, you know, far away neurons are actually more strongly correlated, they will have to travel through those in some sense, the network there, right.

So

I'm not sure if that's clear, but what I'm saying is that the physical proximity and adjacencies in a physical system kind of partially correlate to something like a Markov blanket, like the constraints, the possible operation in the system.


SPEAKER_00:
yes it can and also this was a major topic in the recent 51 live streams like we talked about how different by like the pomdp structure partially observable markov decision process structure or just generally the active bayesian graph representation of a generative model that's not

the anatomy that would carry out that model you would need to make a neural network with a totally different connectivity to implement that model and so we discussed how do you get from a stated base graph to a neural network architecture that carries out that computation

which helps integrate it more closely with experimental results and also software packages and different kinds of computational heuristics.

And then how do you get from a neural network to a POMDP?

And so this paper 51 establishes this relationship

formally as well as empirically.

So it's extremely important reading slash listening in the space of beyond the more foundational points that have been made in the last several minutes, which is just simply these kinds of graphs are not these kinds of graphs.

That's just two different categories of visual representations that both use nodes and edges, but they're describing different things with nodes and edges.

And then to go deeper and to understand exactly how biological and artificial neural architectures implement the kinds of generative models specified by a Bayesian graph, then the paper discussed in 51 is the most recent and advanced discussion on it in the field.

Okay.

How are categories actually encoded in the brain?


SPEAKER_03:
Sorry, Daniel, can you add that reference there?


SPEAKER_00:
Oh, sure.


SPEAKER_03:
Thank you.


SPEAKER_00:
yeah and they've done work in in silico in vitro neurons and in vivo animals it seems like so funny there's fef free energy functional but it's definitely not that and there's been other

discussions of just structural versus effective and functional connectivity in the brain all right so how are categories actually encoded in the brain and neil added a comment

I understand that prediction errors are thought to be encoded as pulse density, i.e.

frequency modulated spike trains, as measured on single neurons.

This might lead us to think that categories are encoded in single neurons like the notorious grandmother and Jennifer Aniston neurons, which are neurons that have been reported in different studies to have an increased and sometimes like specific firing rate increase for a specific stimuli.

So they'll be measuring the thousands of neurons and some neurons fire when some image is brighter or darker and some neurons don't have any clear relationship with visual input, but then they'll find some neuron that fires for Jennifer Aniston, but not for other closely related stimuli.

And so hence the fame of the Jennifer Aniston neuron.

In this schema, are we really saying

One, as far as ACT-INF is concerned, it doesn't matter how categories are stored within a cortical column component.

We just need to model that they are with associate precisions.

Two, we suppose categories are stored statistically somehow collectively within a local population of neurons.

Would we not expect prediction errors to be represented in spike trains on many neurons coming into or going out of a cortical column?

All right, there's many ways to explore this question.

Who wants to give a first thought?

Waiting on you, Allie.

Yeah, go for it, Allie.


SPEAKER_02:
Actually, it's a very big question in the philosophy of mind and the philosophy of cognitive science.

I mean, the question of how brain represents the signs and the external object.

One theory is basically based on the taxonomy of signs.

I mean, as many are aware, a person

classifies the signs into three types of symbols, icons, and indices.

But when we apply this taxonomy in the representation mechanism of brain, basically what we need as a very first step is to understand how the brain represents indices

and icons as a kind of representation processes that would need minimal amount of consciousness right so uh for um indices and uh icons uh i mean the difference between indices and icons are that icons are a kind of structural structure preserving maps and indices

In indices, we have a kind of causal relationship between the signs and their reference.

So before representing the tokens of an object as an index of an external object, we need to have a kind of map or an icon in order to

map that token of index to our icon, right?

So one theory for doing that is so-called homuncular theory proposed by Daniel Dennett in which he proposes a hierarchy of subjects with decreasing levels of consciousness and

And on the bottom most level, we have basically non-conscious subjects.

who somehow grasps the icon in a kind of just representational map without interpreting it as a specific index, right?

But then again, it passes that representation into its higher levels of

homunculus with increasing their increasing consciousness until it reaches the subject quote-unquote subject which is basically our whole mind so yeah it's a very big subject and of course

It's impossible to summarize it in just a couple of minutes, but I would recommend a very interesting book on that subject if anyone wants to further explore that.

The first chapter of Materialist Phenomenology by Manuel de Landa explains it with a crystal clear prose what that kind of representation or how that mechanism would work.


SPEAKER_00:
Nice.

Great answers.

So a few more angles on this question.

First, the question of representation in ACT-INF and in neuroscience is a large area.

So

for something to be represented in the brain, it doesn't need to be what it is in the outside world, clearly, but that leads to like a lot of, of course, discussion about how representations actually do occur in the brain.

So the question was prediction errors are encoded as pulse density as measured on single neurons.

Well, the simple answer is it just simply does not have to be that way.

Prediction errors in a different cognitive system or region could be encoded as the autocorrelation function of the spike train, or there are neurons that are non-spiking, or it could be a brain region.

There's just no reason to uniquely associate the conveyance of prediction errors to the extent that statistical parameters are even conveyed in neuroanatomy at all, which one doesn't even have to agree with.

But to the extent we're even going to talk about neural phenomena as being related to statistical phenomena, it doesn't have to be the spiking density, nor does it have to be on single neurons.

Now, that being said, in the neural network discussion in 51,

there was a relationship that they are showing between the fast perceptual-like dynamics and spike firing rates and the slower dynamics and the neural plasticity at the synapses.

So as kind of before, like it could be, but just because it could be in some senses maybe doesn't mean that those are an identical mapping.

Then,

Categories are encoded in single neurons.

Well, if by that it is meant encoded by firing sensitivities in networks of neurons, then there is already more being taken into account.

It's kind of like figure and ground.

It's not like that neuron taken out of that network would still signal Jennifer Aniston.

The semantics of a given category

are associated with the inputs and outputs, even in cases where there is a statistically tight relationship between the firing activity of some neuron and some other category being identified, then are we really saying?

It doesn't matter how categories are stored.

We just need to model that they are.

So that is an instrumentalist perspective.

which is just saying whatever the neurological substrate is of how categories are enacted and represented in the brain, we're going to use a specific type of model that is super tractable, super composable, translates across systems and so on, hashtag act-inf, and we're not saying that's the architecture of the system.

So that's an easy instrumentalist position that can always be taken.

And we suppose that categories are stored statistically somehow collectively within a local population of neurons.

That's an empirical hypothesis.

One could test whether a population rate code or a area of activity or other aspects of neural function that aren't even as commonly discussed depending on the specific question come into play.

Would we not expect prediction errors to be represented on spike trains on many neurons coming into and going out of?

If you expect it, if that's your prior, then you expect it.

If it's not your prior, you don't expect it.

There might be anatomical or statistical reasons to scaffold the belief

that there would be a many input many output system or not but it can't be answered in the general those are just the examples of empirical neuro anatomical research to actually pursue um brock how do you see it related to for veiki um i mean relevance realization is uh i mean very roughly like opponent processing it's i mean it's


SPEAKER_01:
I don't really understand the fundamentals of precisely how that would work in a neurological, physiological sense.

But it's kind of GAN-like.

I guess you could anthropomorphize there.

Yeah, just that you're contrasting

like different fittedness, I guess, of in the live stream, he gave this, I guess, example of like a dog versus a four-legged animal versus a mammal or whatever.

Why did we say the dog ran by sort of thing?

Is that that has a good fit and that realized relevance is somehow related to

opponent processing.

So that's, I guess, a way in which it's related to categories or very crudely like general differentiation or something like this.

It's tangentially related, I don't know.


SPEAKER_00:
I don't know.


SPEAKER_01:
It's like a conceptual approach too.


SPEAKER_00:
Yeah, there's always different coarse grainings of categories that can be appealed to.

in speech or in the brain.

And so, um, outside of contrived, you know, sorting tasks in the more open-endedness of the niche that the systems have to engage with, um, the categorization is, has different characteristics than like a binary sorting task.

So that's what Vervaeke ties to relevance.

Okay.

Does anyone want to add another question or thought on Vive?

What other neural systems or behaviors are people interested in modeling?


SPEAKER_01:
There's always planning, but also in that diagram behind the window there, there's goals.

Goals, yeah.

Where did those come from?

Seems like, I guess you could do planning without goals, but it seems like a goal there would be kind of a reason to plan, a biological goal of homeostasis, allostasis.

There was a live stream you guys did recently on that.

And then some more subjective cultural thing.

Yeah, I don't know.


SPEAKER_00:
Yeah, well, here with a more narrow goal interpretation, the difference is between the direct and the indirect policy selection pathways in the stratum, which is mediated by gamma, the dopamine signaling.

And so here on this left side, the habits dominate policy selection.

So E represents the affordances, but it's not just like, affordances are not just like yes, no in the E vector.

They represent the prior probabilities of given actions.

So where an affordance is impossible, it is given a prior probability of zero, and therefore it's never selected.

Where the prior probability on some action or affordance being engaged in is high,

it's more likely to be undertaken.

So E is not just like a list of what you can choose from.

It's not like a menu.

It's like a menu of actions that's weighted by habit in this construction.

And so in the absence of any kind of pragmatic or epistemic value, which is to say free energy minimization,

behavior recapitulates the habit.

So there's a mode of policy selection, pi, where the entity is merely recapitulating probabilistically their history and habits.

That's shown on the left side of the stratum.

Then the right side of the stratum shows the cortical engagement

of seemingly more goal-directed, whether pragmatic goal-directed and or epistemic goal-directed, or as we think about it in active inference, the pragmatic and epistemic integration into a single imperative G. Like, let's just say I usually walk up and down, but I rarely go left and right, and I'm in a maze.

This left mode...

of policy selection is just going to be recapitulating the decisions previously made.

The right mode is going to ideally strike a balance between pragmatic and epistemic value, but any discussion of pragmatic and epistemic value, so pragmatic value, bringing alignment, reducing the divergence between your preferences and observations, getting what you want, getting what you expect,

and epistemic value, reducing your uncertainty, gaining information.

Any discussion of the relative merits of different policies in terms of their expected free energy, which again is to say their relative or relative pragmatic and epistemic value, any evaluation of policy is a different cognitive and computational process

than merely the recapitulation of habits which doesn't require any consideration of policies at all so this is kind of like walking forward walking into the future looking backwards i mean in some deeper sense aren't we always but this e mediated mode of decision making

does not require any evaluation of counterfactuals or comparison of alternative outcomes now where do habits and preferences come from because if under g the pragmatic value is going to be associated with prior probabilities on preferences

And epistemic information as well is going to be mediated by priors, which here are being shown as kind of cortically embodied.

Where do those parameters come from?

Evolution, ecology, development, and behavior over different timescales.

So the coarse-grained priors are inherited through the process of evolution.

and then finer and finer scale adjustments can occur via ecological and developmental processes, culminating in learning and at the very fastest scale, perception.

That's the deflationary approach, which would be evolution has put all those nested processes, evolution, ecology, development, behavior, learning, and then perception, put that entity's generative model in the context of a generative process into an adaptive position.

If it's not adaptive, that far from equilibrium system is going to quickly dissipate.

You just saw something in its last day.

or it's not its last day, and then the inference is going to continue.

Giuseppe?


SPEAKER_03:
Yes.

Something that is not too clear to me.

Habits are supposedly, they do refer to things that are learned during the lifetime of the agent, as opposed to being...

deposited through evolution for instance because one could say also that the the the policies with high pragmatic values that that are the one that preserve the phenotype of the agent are kind of habits but they pertain to the longer time scale of uh phylogenesis so to say so so is there

the distinction here like the specific of habits the characteristic of habits is that they have been learned they there are they come from statistical regularities that have been uh accrued and represented through the lifetime of the agent to the experience of the of the agent


SPEAKER_00:
I believe that it doesn't have to be only learned during the lifetime.

Like let's just say that there's a species of bird that flies at night.

It habitually flies at night.

And then you can zoom in more and say, now within that bird species, there are the early risers and the late risers.

And this one is habitually rising early and that one's habitually rising late.

Now that may be a genetic polymorphism that doesn't even have to be learned at all.

So I think, of course, in humans, we take a very developmental learning-based approach towards the habits and Aristotle, excellence is what we repeatedly do and all of that.

But when we just think about habit as what is habitually done, then it's a little bit clearer that it's not necessarily learned.


SPEAKER_03:
But then once you...

couldn't you uh subsume the like the the tendency to fly more at night as a as a preference that is within the within the yeah as a preference like within the same matrix yes and in some um convergent evolution scenario


SPEAKER_00:
we would see the habit distribution recapitulating the preference distribution increasingly mindlessly, offloading the cognitive work of evaluating policies and reducing divergence through free energy minimization.

We might expect some of that to become habitualized

and merely reflected through the affordances that can be taken or the probability of different affordances in terms of their prior preferences or prior probabilities on affordances rather than needing to be mediated through preference that's one answer and another kind of corollary answer is on one hand we can talk about preferences over any distribution but in the bird example um

the preference for flying at night might not be a category that's accessible to it.

But preferences that have to do with the amount of photons being detected

might interact synergistically with habits around like a circadian rhythm or habits around flapping your wings.

Like once the wing is flapped up, it always flaps down.

That doesn't even need to be computationally modeled as a policy decision because it could be relying on these regions of the brain or these kinds of pathways

that don't explicitly consider alternatives in the same way and i think again as we discussed at the beginning this isn't the literal interpretation of the neuroanatomy but it's kind of showing two extreme um ends of a continuum with um the least to the most explicit consideration

of future policies with all the pros and cons of turning the volume up, turning the volume down, and the volume is computationally analogous to the role of dopamine signaling in the striatum and in insects.

Ali?


SPEAKER_02:
Yeah, and another slightly different take on this subject is laid out by J. Scott Kelso in his book, Dynamic Patterns, The Self-Organization of Brain and Behavior, in which he says that because the state of all the possibilities are too complex to be calculated at each time and for each decision,

He lays out something like this, that if we look at it, look at the state of the possibilities in terms of its distribution of singularities and the basins and the well of those singularities or the attractors of the basin of attractors,

the policy making can be achieved by the effect of adjusting the parameter and the proximity of those wells or basins.

So for example, manipulating that parameter to make some wells or basins shallow with the result that the associated preferred state becomes less stable.

So in this condition,

random fluctuations actually can spontaneously somehow dislodge the system from that state and push it into another state.

So in this case, the habit can also be explained by the varying degrees of these kinds of parameter adjustments throughout all the state of possibility states.


SPEAKER_03:
awesome yeah yeah this is this is very interesting one one subject which I'm I'm interested in applying the active inference framework is on meditative practice and actually it has been one proposal is that

it may work exactly like that so that uh the the tractors that are very deep and are firmly consolidated through habits through meditative practice become shallower so that the range of possibilities of behavior and perception becomes larger because you you you are not constrained by this

deep wells of of of energy that have been established through your habits but the interesting thing here the intriguing part is that through a very uh repetitive practice kind of repetitive practice you are you somehow make your energy landscape more shallow at least at least at least during the practice

it's like it's interesting this paradoxical aspect how you you could somehow train with the very habitual practice to weaken your habits oh just going off of a tangent here but it's totally interesting and one could imagine


SPEAKER_00:
real practices or simulated computational agents that engage in repetitive actions and that just sharpens it doesn't open their mind a lot of meditation is not about expanding one's mind or changing one's behavior it's actually about converging to a certain regime of attention and sharpening distributions that exist during the practice and after the practice there are other cases where we can modulate our receptivity

through repetitive actions.

And being exposed to just merely novelty all the time doesn't necessarily breed novelty in us.

It might just confuse us.


SPEAKER_03:
Yeah.


SPEAKER_00:
Yeah, Brock, some habits are reciprocally narrowing, some are reciprocally opening.

Yeah.

Yeah, they can look very similar.

And without the ability to see the cognitive states of another, if somebody's just sitting quietly, maybe they're narrowing, maybe they're opening, maybe they're sleeping.


SPEAKER_01:
Well, to your point, I mean, about, you know, like some basic version of meditation of just like focus on your breathing is like sharpening and narrowing it.

But in doing that, over time, you kind of grow this capacity to modulate your attention more.

on other things, more intentionally, right?

So... Right.


SPEAKER_03:
Probably not... Perhaps this idea that by doing that, by deploying attention more on the sensory aspect, you kind of avoid a little bit, or bias the usual

drift of precision upwards toward more, like, superior layers of the hierarchy associated with mind-wandering, et cetera.


SPEAKER_00:
So this is... Bronwyn, would you like to add anything?

Okay.

Awesome.

I'm going to copy your comment in so we can read this.

I would put forward here the practice of Alexander technique where we optimize precision by repetitive action, i.e.

getting in and out of a chair whilst inhibiting and directing.

Yeah, it'd be interesting to with this three

region neuroanatomical model.

Yep.

Cortical, the most cognitive, most semantically accessible

the midbrain striatum, most dopaminergically associated with this continuum between habitual and goal-directed policy selection, and then action mediated in the peripheral nervous system through divergence minimization.

And then sketch out... I'm just going to...

And then sketch out, yeah, like in the Parkinson's case where there's a loss of dopaminergic signaling, which can in the extreme lead to like failures of initiating and planning action.

And then there was a Robin Williams movie

Awakenings.

This movie is about a early on, Oliver Sacks wrote the book, but then there's a Robin Williams movie.

And there was a floor of patients in a medical institution who were all suffering from basically these different symptoms that today could be recognized as like hypodopaminergic signaling.

And then...

the doctor goes to a conference, learns about L-DOPA, which is like a metabolic precursor of dopamine.

So dopamine does not cross the blood brain barrier in mammals.

However, L-DOPA does.

And then that like awakens people, but it shows like some of the motor and cognitive consequences of hypo and hyper dopaminergic signaling.

One question for me is where does reasoning fit into figure 5.5?

The gears of thought.

Where's the transmission in the carburetor?

Like those are great questions.

So there's probably many different angles to take on it.

One angle is like reasoning is a synonym of inference.

And so by pointing to reasoning, we are talking about families of inferential structures, right?

And so depending on what that reasoning is about, it could manifest in different ways.

And so like, yeah, Ali.


SPEAKER_02:
Actually, Helmholtz proposes that reasoning can, as you said, it can be done also unconsciously as inference.

So actually one of the starting points of this whole

area of Bayesian brain hypothesis and probably its origin is Helmholtz's essay, I forgot its exact name, from 1866 or something, in which he proposes a theory of unconscious inference or unconscious conclusion in which sometimes reasoning, actually most of the time, the majority of our reasoning processes

are not done in our conscious levels.

So yeah, I also agree with you that reasoning can be taken as a synonymous for these kind of inferences as well.


SPEAKER_00:
Yeah, but like on the experiential side, it is so fascinating and mysterious.

Stimuli are presented

Certainly there are unconscious inferences that facilitate even the initial understanding of a stimuli.

Like a visual stimuli, like seeing a letter as a letter.

Seeing a handle for grabbing is kind of the ecological and activist angle.

But seeing a symbol or sign, and that kind of invokes what Ali described earlier with a theory of semiosis.

But then we wait.

And we feel like we reason.

And we make decisions.

And so how to...

how to square the graphical models of inference, which is to say reasoning, with that.

Yeah, Brock?


SPEAKER_01:
I was just going to ask, I guess, where mental action fits into this on policy selection or habits or goals.

Yeah, I don't know.

Like, yeah, I think the vast majority of this is, yeah, that you get, like, this base unconscious inference.

But at some point, it feels like there's something conscious there about selecting between two things sometimes.

You're really intentional and thinking real hard.

So I wonder what that is, I guess.

Yeah.

Giuseppe?


SPEAKER_03:
something about going back to habits something that i just thought about um so usually habitual actions from the point of view from a psychological and phenomenological point of view are they seem to require much less mental energy or psychological energy so we can think about that in terms of

you know, the theory of System 1 and System 2 by the Nicanoman.

And I wonder if they seem to have some preferential low levels of free energy also, of expected free energy, the habitual policies compared to other policies that somehow mirrors their relatively


SPEAKER_00:
low investment of energy psychologically yeah well that's been a hotly debated topic and one of the most mystifying observations

is that the brain does not change in metabolic activity greatly, depending on the task.

And so there's all these amazing analogies between Freud and free energy and all these things that Solmes and Fristens and others have worked on.

And of course, the tantalizing connections between free energy minimization and energetic energy.

balance and the fMRI signal that's being studied is the brain oxygen levels changing bold signal.

And also people can study the glucose metabolism, but these levels of change are very small in brain metabolism and glucose usage.

they're not simply associated with like quote thinking hard and even necessarily cognitive demands and so it's it's like it's like i don't know if it's a hammer without a nail or nail without a hammer because empirically it doesn't change in energy use that much although although there was a recent paper and i think it's in it's in a big journal i can't remember if it's nature or or actually


SPEAKER_03:
There was, you know, they proposed some kind of approach similar to free energy minimization and that they were showing that actually the

the energy spent in synaptic communication was minimized.

And if I may look for it and I may post it here.

But I wonder more specifically in this idea of that habitual patterns of behavior, or let's say sequences of action gets shifted with practice

being processed from the cortex to the basal ganglia somehow there is uh there is actually well not not only not only like metabolic energy like in terms of glucose or

advantage but also in terms of really free energy so i don't know if that has been looked at uh specifically like for the basal ganglia or i don't know there must be something because it does seem that uh mental resources at least experientially are become much um


SPEAKER_00:
ma the required mental resources become much less once once you a task is automatized let's say yes just shortly to close this and and to address this uh final question when does passive become active inference and then planning well

we could look at from a Bayes graph perspective, is action involved?

If the task is merely perceptual, we can say that it's passive inference.

If ocular motor circadian is required.

So even if the person's in a chair, but they're moving their eyeballs, that could still be modeled as active inference.

And you'd want then a unified imperative for inference and action.

And then when is it planning?

Well, as we had some controversial discussions on in cohort one about the second half of the book, is it really planning?

Do we really see planning in this textbook?

as if planning would be behavior that looks like it's enacting a plan, like a chess player who's winning a game.

But the strict and narrow definition of planning might be explicit consideration of sequential actions and their consequences and preparation for those and evaluation of them.

And free energy reduction or minimization could be used in purely passive inference, which is where it's widely used in general as an evidence lower bound and in machine learning without action in the loop.

So the innovation of active inference is to bring action into the fold of inference and make a unified free energy functional imperative for perceptual learning and action inference.

All right.

Hope it's okay we went a few minutes over, but thanks.

Cohort two, next week we return.

for some overview and debrief, look at the project ideas, and also look forward to future textbook groups.

So feel free to fill out the feedback form and encourage others to do so as well.

And also take a look through some thoughts and add more thoughts on future groups, which we'll go over next week.

So thank you.

Talk to you soon.