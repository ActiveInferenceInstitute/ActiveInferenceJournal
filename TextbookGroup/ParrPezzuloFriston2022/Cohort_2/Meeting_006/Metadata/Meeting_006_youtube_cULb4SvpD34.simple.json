[
  {
    "start": 1.616,
    "end": 23.708,
    "text": " okay hello everyone it's october 7th 2022 we're in the sixth meeting for the second cohort of the textbook group today we're going to be discussing chapter three for the first time",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 27.475,
    "end": 47.122,
    "text": " So we have a few questions to explore on three, but before we do, would anyone like to just say hello or give any overview thoughts on chapter three before we go into more specific questions?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 51.083,
    "end": 55.125,
    "text": "You can raise your hand or just unmute and just go for it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 74.673,
    "end": 76.467,
    "text": " I'll wait for someone to make a comment on Chapter 3.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 123.959,
    "end": 124.159,
    "text": " Yep.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 137.252,
    "end": 145.22,
    "text": "To active inference with the principle of least action and the introduction of Markov blankets.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 151.095,
    "end": 151.916,
    "text": " Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 152.036,
    "end": 155.057,
    "text": "How does that differ from previous approaches or relative to what?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 158.92,
    "end": 178.792,
    "text": "Well, I guess instead of starting with... Instead of starting with the notion that you have some agent that's creating a representation of its world, you start with like an...",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 180.589,
    "end": 201.45,
    "text": " axiomatic view from physics that when applied to biological entities leads to at least the same conclusion as chapter two.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 205.933,
    "end": 206.213,
    "text": " All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 206.394,
    "end": 206.694,
    "text": "Awesome.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 206.754,
    "end": 207.114,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 208.536,
    "end": 210.858,
    "text": "Anyone can raise their hand or just go for it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 211.399,
    "end": 218.267,
    "text": "General thoughts on chapter three and or what is the high road to active inference?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 249.673,
    "end": 256.218,
    "text": " Having read chapters 2 and 3, how does anybody want to remark on figure 1.2?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 281.32,
    "end": 285.023,
    "text": " OK, I'll make a short remark.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 287.185,
    "end": 296.193,
    "text": "To me, this figure, I guess these elements, like surprise minimization, Markov blanket,",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 296.933,
    "end": 313.917,
    "text": " It looks like they are inserted in the pictures sequentially, but it doesn't seem to me that they actually represent a sequence for understanding the approach.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 313.997,
    "end": 319.759,
    "text": "They're just various aspects of either the physics approach or",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 321.036,
    "end": 349.578,
    "text": " in the lower part of the figure of the bayesian approach if i if i understood it correctly because at first i thought it was like a path you know starting from the free energy principle and then first to self-organization then surprise minimization mark of blanket predictive processing and i don't know if it's if it is actually a progression of concepts or actually i don't know",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 350.259,
    "end": 350.88,
    "text": " What do you think?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 353.384,
    "end": 355.707,
    "text": "Yeah, it's a great question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 355.788,
    "end": 357.03,
    "text": "Anyone can give a thought.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 357.971,
    "end": 361.476,
    "text": "What do the ordering of the terms mean?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 361.617,
    "end": 365.042,
    "text": "Are these train stops along the way, blue or child?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 367.967,
    "end": 387.601,
    "text": " So I just wanted to say that the live stream where Maria really gave a lot of background on predictive processing, predictive coding, like the difference between these two might be super helpful with regard to like a progression or just evaluating that lineage in more detail.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 391.564,
    "end": 392.465,
    "text": "Yeah, sure.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 392.585,
    "end": 393.566,
    "text": "I'll add link there.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 395.123,
    "end": 400.104,
    "text": " One option would be that these are historical, like this is the chronology of ideas.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 400.244,
    "end": 403.845,
    "text": "Another one would be that they're pedagogical, that this is a learning path.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 404.485,
    "end": 415.948,
    "text": "Another might be formal or technical, like one of the directions are dependencies or required, but not necessarily the most pedagogical path.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 416.328,
    "end": 416.568,
    "text": "Ali?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 420.209,
    "end": 422.85,
    "text": "I also think that the organization of this",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 424.007,
    "end": 432.943,
    "text": " particular figure is more like the branches of a tree than something sequential.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 433.524,
    "end": 435.608,
    "text": "So they might not represent any",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 436.469,
    "end": 462.328,
    "text": " specific preference to go through all of these steps in order to achieve a particular goal they're just try it just tries to lump together relevant concepts in two different branches so that's what I see it at least yes the tree",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 464.665,
    "end": 488.302,
    "text": " um FEP tree from uh 2010 with a lot of the early sort of directions and pointers towards areas of synthesis um it anyone else want to just add any other thoughts like what is the high road or how did they feel about chapter three overall",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 511.049,
    "end": 537.276,
    "text": " there's ample technical and specific questions to dive into but it's really important to understand chapter two and the low road and chapter three being the high road and the way that they're distinguished in terms of the low road beginning from a framework for doing statistics learning updating and so on but not necessarily an imperative for survival",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 538.479,
    "end": 566.893,
    "text": " contrast in the high road the beginning stance is around the imperative for survival which is kind of a biological way to frame it or the slightly even more deflationary imperative for repeated measurements which is more of a quantum or a physics way to be framing the issue in terms of stochastic processes and measurement theory",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 568.171,
    "end": 572.934,
    "text": " where if something cannot be measuring itself, it's not going to see itself around for long.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 573.575,
    "end": 583.481,
    "text": "And if something is not a thing to something else, it's not being measured over a given time scale within a given variance criterion, it also is going to be quote, not a thing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 584.281,
    "end": 593.988,
    "text": "So this imperative for persistence and finding manifolds of stability or bounded spaces",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 595.803,
    "end": 612.828,
    "text": " is an imperative that isn't intrinsically within bayesian theorem but active inference is being situated at the intersection of the bayesian methods and the imperative for persistence and or recurrent repeated measurements ali",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 617.545,
    "end": 635.518,
    "text": " Yes, one of the, I think, probably the most central concept of Chapter 3, on which all the other material seems to evolve, is the concept of Markov blanket.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 636.398,
    "end": 643.163,
    "text": "But in this particular chapter, I think the nature of Markov blanket has not made",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 646.486,
    "end": 667.133,
    "text": " quite explicit so I just wanted to emphasize a critical point about this whole concept which has caused a lot of lots of confusions and misunderstandings around it and namely some people think markup blanket is actually some kind of",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 668.451,
    "end": 671.292,
    "text": " of spatiotemporal boundary around the system.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 672.292,
    "end": 693.716,
    "text": "But as the paper on Bayesian mechanics makes clear, Markov blanket is actually a boundary on state space, and it doesn't necessarily or it doesn't always translate into any spatiotemporal boundary.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 693.856,
    "end": 694.676,
    "text": "In some cases,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 696.756,
    "end": 708.663,
    "text": " For example, in cells or organelles or things like that, we can see the spatio-temporal manifestation of Markov blanket, but that's not always the case.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 709.503,
    "end": 721.15,
    "text": "So yeah, that's one of the points I think is crucial to understanding this whole high road approach to active inference.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 723.919,
    "end": 753.251,
    "text": " thank you all the very interesting points so they do in the first box of the chapter and in the first non-introduction section discuss markov blankets so it's definitely something that we want to um follow on so let's we're done for now with a just general discussion around what the high road is",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 756.259,
    "end": 757.04,
    "text": " Yes, Giuseppe, please.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 759.484,
    "end": 770.841,
    "text": "Just on this topic, it's true that the Markov blanket is explained quite clearly, if succinctly, in that part, but",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 772.182,
    "end": 800.558,
    "text": " then i don't think it throughout the book is actually uh is actually used or described in details from the computational point of view that i i mean i think it's it's it's described it's it's defined there but then i to me it seems that doesn't",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 802.026,
    "end": 827.698,
    "text": " appear much in the in the more computational later parts of the book that there was my impression so the concept is quite clear but i'm not sure how it it applies then practically just just in laying out the model probably",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 828.737,
    "end": 837.052,
    "text": " in laying out the specifics of the model that defines by itself the relevant mark of blanket, probably.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 839.055,
    "end": 839.376,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 839.396,
    "end": 839.857,
    "text": "Ali?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 844.703,
    "end": 858.54,
    "text": " Yes, one reason for that might be, at least according to my personal communication with Maxwell Ramstad, you see, the problem of identifying markup blankets from data",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 860.562,
    "end": 872.31,
    "text": " is still an outstanding issue and problem among FEP researchers, on which Versus Lab is actively working on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 872.831,
    "end": 877.834,
    "text": "So that's not a resolved problem, I guess, yet.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 878.395,
    "end": 886.161,
    "text": "So that's, I think, one of the reasons they have not alluded to the concept of market blankets.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 887.208,
    "end": 888.571,
    "text": " so much throughout the rest of the book.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 888.591,
    "end": 890.856,
    "text": "The other reason is recent literature somehow tries to",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 899.479,
    "end": 906.904,
    "text": " reduce its dependence on this whole concept of markup blanket because of various reasons.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 908.524,
    "end": 921.212,
    "text": "So, yeah, these two reasons might be sufficient to explain its lack of appearance or at least explicit appearance in much of the book.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 922.853,
    "end": 923.173,
    "text": "Thank you.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 924.466,
    "end": 924.726,
    "text": " Great.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 924.746,
    "end": 929.232,
    "text": "Yeah, I think this this question will help us dive further into this question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 930.093,
    "end": 930.373,
    "text": "On page 43.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 932.54,
    "end": 957.145,
    "text": " they uh are writing so first off anyone who wanted to describe on a more technical note we can bring it up later or sooner what a markov blanket is because it is one of the core um terms in brief a markov blanket is the set of variables that mediate all statistical interactions between a system and environment and those parentheses cover a lot",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 957.785,
    "end": 964.389,
    "text": " That is not the same thing as the actual mechanical or material interactions between the system and the environments.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 965.17,
    "end": 969.292,
    "text": "That is the map territory fallacy or failure to distinguish.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 970.093,
    "end": 975.776,
    "text": "Although one can't also swing too far into the map territory fallacy fallacy area, which we've talked about earlier.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 979.538,
    "end": 983.341,
    "text": "This, the Markov blanket and what it does is,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 984.344,
    "end": 994.957,
    "text": " is a restatement of the classical action perception cycle, wherein an adaptive system and its environment can interact only through actions and observations respectively.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 996.279,
    "end": 1001.766,
    "text": "So, how is the Markov blanket a restatement of the classical action perception cycle?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1015.714,
    "end": 1036.052,
    "text": " I feel that this is an important question to understand to contextualize active inference within the history of models like cybernetics, control theory, ecological psychology, and qualitative and quantitative models of perception and action.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1037.614,
    "end": 1042.078,
    "text": "Kind of goes without saying, but it's a really important note.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1043.431,
    "end": 1059.418,
    "text": " and we see multiple representations of the action perception loop so figure three one shows the action perception loop along with the particular partition",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1060.987,
    "end": 1069.632,
    "text": " That's the one that's separated into internal and external states along with the blanket states, which makes internal and external conditionally independent.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1070.493,
    "end": 1082.52,
    "text": "And then the blanket states are further decomposed into active states, those with outgoing dependencies from the perspective of internal states, and sensory states, those with internal dependencies.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1083.516,
    "end": 1091.358,
    "text": " Although note some asterisks in the interpretation, for example, around which arrows have two directions and which ones don't.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1092.158,
    "end": 1092.879,
    "text": "So here's figure 3.1.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1094.359,
    "end": 1095.699,
    "text": "The Markov blanket, it's dynamic.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1095.719,
    "end": 1096.6,
    "text": "It's changing in time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1096.68,
    "end": 1097.84,
    "text": "The states are changing in time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1098.7,
    "end": 1104.642,
    "text": "Separating, partitioning, internal states, here the brain from the environment.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1105.662,
    "end": 1112.244,
    "text": "And all of the functions are described in terms of rates of change, X, U, Y, and mu.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1113.513,
    "end": 1128.92,
    "text": " the dot over the top is like the derivative so they're all being solved for in terms of how they change through time and they're all being described with these f functions that are themselves comprised of a deterministic component",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1130.236,
    "end": 1143.554,
    "text": " That's the average rate of change over these arguments coming into the deterministic component of the equation and omega, which is some sort of random fluctuation parameter.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1144.435,
    "end": 1146.799,
    "text": "So it's kind of like a signal to noise partitioning",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1148.146,
    "end": 1176.336,
    "text": " statistical variance within the change characteristics of a given state corresponding to particular partitioned variables but we've also seen other representations of the action perception loop so here's one of the simpler ones from figure one this is the first figure in the book and we can think about how like the active states even though they're coming up",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1177.446,
    "end": 1204.589,
    "text": " from the right here and they're coming kind of down from the left here in both situations it's like this is the engagement between the agent and the niche okay but then there are some other representations too like figure two two here we see a proto-blanket forming though not described as such and without like for example an arrow connecting",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1205.723,
    "end": 1231.196,
    "text": " these two nodes between observation and action and more of an emphasis on the way that hidden states are being either actually generative of the observations that's the generative process or that hidden states of the generative model are doing inference on the observations so that's one other um representation and then there's this representation",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1233.251,
    "end": 1261.592,
    "text": " where here action is coming out of discrepancy as is perception learning generative model change and we see observation coming into discrepancy so what is the action perception cycle and where do Markov blankets come into play in terms of even the classical ways of thinking about control systems",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1265.123,
    "end": 1292.186,
    "text": " if one looks up control loop they'll find all kinds of diagrams from cybernetics and control theory that can entirely be interpreted within a sort of entity getting input doing some sort of processing and having outputs so",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1294.093,
    "end": 1298.6,
    "text": " How is the Markov Blanket helping us approach this nexus of the entity and the niche?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1321.974,
    "end": 1336.967,
    "text": " Well, one thought or important piece to note is that some blanket states will exist for any Bayesian graph that isn't fully connected.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1338.028,
    "end": 1347.056,
    "text": "Anytime that you have a non-fully connected Bayes graph, so not every node is connected to every node, then there will be some other nodes",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1348.177,
    "end": 1352.619,
    "text": " upon which two other sets are conditionally independent.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1353.979,
    "end": 1371.326,
    "text": "That's just what the nodes and edges mean in this kind of a graphical model, which is if nodes are random variables and edges are statistical relationships, then nodes directly connected by an edge have a direct statistical relationship.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1371.966,
    "end": 1376.268,
    "text": "Again, not implying anything about the material or the causal nature of the world.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1377.321,
    "end": 1405.592,
    "text": " So then if two nodes do not have a statistical relationship, they're either part of two different graphs, which can be seen as basically partitioned from each other, or they're going to be part of a connected component of a graph, but there's some other nodes, one or more, that intermediate such that those two nodes of interest, which are arbitrarily called internal and external,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1406.533,
    "end": 1430.815,
    "text": " have conditional independencies that ends up simplifying and being important for a lot of the computation and it respects and reflects the sparse coupling of features in the world so it's always just important to like think back like where is something new coming in",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1433.666,
    "end": 1444.892,
    "text": " to active inference, people have been using partially observable Markov decision processes for many years for perception and control issues before active inference.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1446.493,
    "end": 1462.382,
    "text": "Those models also are imbued with Markov blankets, just like any other Markovian setting in time series analysis or any sort of partially observable model",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1464.542,
    "end": 1469.583,
    "text": " So, just an important question for discourse to continue on.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1471.024,
    "end": 1475.125,
    "text": "How is the Markov blanket restating the classical action perception cycle?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1475.285,
    "end": 1475.545,
    "text": "Ali?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1479.926,
    "end": 1489.789,
    "text": "Just as a side note, I wanted to point out again to, I think, an important error in this particular figure.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1490.918,
    "end": 1493.739,
    "text": " which I've included in the errata.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1494.219,
    "end": 1497.521,
    "text": "So yeah, and added a note there.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1498.861,
    "end": 1510.386,
    "text": "So if you could please open this data for this and open the notes there.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1510.586,
    "end": 1513.047,
    "text": "I've added the explanation for why.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1514.567,
    "end": 1514.967,
    "text": "Exactly.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1515.148,
    "end": 1515.348,
    "text": "Yes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1515.968,
    "end": 1516.308,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1518.246,
    "end": 1519.887,
    "text": " So let's just put this out there.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1519.907,
    "end": 1521.787,
    "text": "It makes sense.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1522.428,
    "end": 1522.628,
    "text": "What?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1522.648,
    "end": 1522.968,
    "text": "Giuseppe?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1522.988,
    "end": 1524.909,
    "text": "Yeah, it makes sense.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1525.569,
    "end": 1527.009,
    "text": "I think it's well-spotted.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 1528.19,
    "end": 1528.43,
    "text": "Yes.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1529.33,
    "end": 1531.311,
    "text": "There's many changes.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1532.572,
    "end": 1539.954,
    "text": "And so again, these are like why it's so important for everybody to make asynchronous contributions and questions if they can.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1540.975,
    "end": 1546.537,
    "text": "This is how we actually are going to move the needle on the textbook making sense and making impact.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1548.524,
    "end": 1574.88,
    "text": " know it's like an individual sense-making journey as well but also these kinds of questions like what does this mean and the discourse around them is gonna catalyze the actual use of this area like um do you want to summarize what the difference is between the existing equations and the replacement sure uh you see in the existing equation in the book",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1575.977,
    "end": 1594.342,
    "text": " the marginal flow of sensory states are expressed in terms of blanket states, namely u and y, and also the external state.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1594.982,
    "end": 1598.883,
    "text": "But it should be the other way around.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1598.943,
    "end": 1600.764,
    "text": "I mean, the marginal flow of sensory states",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1601.763,
    "end": 1605.69,
    "text": " should be expressed only in terms of external states and the blanket states.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1606.271,
    "end": 1610.679,
    "text": "And the marginal flow of active states should be expressed in terms of",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1612.023,
    "end": 1635.007,
    "text": " only internal states and the blanket states thank you so yeah just to restate that and also to build some intuition with what these flows are and how they relate so u and y constitute b the blanket states so sometimes u and y are both written or b is written",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1636.48,
    "end": 1663.712,
    "text": " describe the blanket state variables other times it might just be describing a subset at which point not the whole blanket is being described just for example the active states u or the sensory states y are being described then mu are internal states here and x you know find x hidden states external states with a note here that the variables are different in different presentations so um as it was written",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1664.841,
    "end": 1683.119,
    "text": " we can read that this is the change in U, which is the active states, is a function of first a stochastic parameter about U itself, but then the deterministic component here is a function of the blanket states and the hidden states.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1684.1,
    "end": 1688.904,
    "text": "And conversely, as written, why the change in observations through time",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1689.913,
    "end": 1712.238,
    "text": " is after accounting for a stochastic term a flow function on blanket states and internal states whereas it's actually exactly the opposite with x and mu being switched between these two because actions should reflect a flow over blanket and internal states",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1713.246,
    "end": 1718.609,
    "text": " sometimes called the particular states, because that's the particle that's moving around.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1719.149,
    "end": 1721.15,
    "text": "That's the Bayesian mechanical particle.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1722.17,
    "end": 1729.214,
    "text": "And then observations should reflect a flow on blanket states themselves and hidden states of the world.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1740.919,
    "end": 1741.199,
    "text": " All right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1743.741,
    "end": 1746.002,
    "text": "And that's very related to this other question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1746.662,
    "end": 1749.203,
    "text": "So what does figure 3.1 mean?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1749.264,
    "end": 1750.524,
    "text": "I think that's what we're looking at.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1752.585,
    "end": 1754.186,
    "text": "How is it different than figure 2.5?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1755.007,
    "end": 1760.87,
    "text": "And how is the agent's niche relationship described qualitatively and formally in active inference and other areas?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1761.03,
    "end": 1762.791,
    "text": "So I think we kind of explored that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1763.631,
    "end": 1768.194,
    "text": "People can add any more notes, but this is like a really important level to pull back to.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1769.315,
    "end": 1782.361,
    "text": " whether it's somebody who's having a question or even a well-intended or not criticism of active inference or a control theory, it can be useful.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1782.741,
    "end": 1786.403,
    "text": "Are they describing challenges of the world?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1787.338,
    "end": 1801.201,
    "text": " like the map territory difference, like the complexity of the world always transcending the structure and complexity of our own models, or referring to the fundamental issues of taking action amidst uncertainty.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1803.382,
    "end": 1814.945,
    "text": "Are people pointing to those issues and then part of the community describing the agent niche qualitatively and or formally?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1816.656,
    "end": 1839.837,
    "text": " or are they sort of suggesting or implying some kind of like hidden other way of thinking about how agents engage in the niche because there's a lot of questions that can arise but these framings although here the markov blanket gives that kind of a bayesian statistical and graphical um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1843.114,
    "end": 1870.065,
    "text": " stance on it and implementation opportunity space which includes an incredible number of computational affordances like message passing variational inference and so on this partitioning of the entity from the niche figure from ground is not diverging from the traditions of cybernetics and other areas",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1871.161,
    "end": 1872.441,
    "text": " So just kind of like interesting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1873.222,
    "end": 1879.764,
    "text": "Are people pointing to fundamental issues of perception and action, which in some senses is our field?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1881.725,
    "end": 1890.388,
    "text": "And are they part of the building and the sense-making around those scientific and meta-scientific models?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1891.768,
    "end": 1895.47,
    "text": "Or is it just a position of like, well, it's not possible to model this?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1898.391,
    "end": 1899.311,
    "text": "Kind of a random thought, but.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1906.437,
    "end": 1906.757,
    "text": " Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1907.257,
    "end": 1907.577,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1911.338,
    "end": 1911.818,
    "text": "Yes, Ali.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1915.019,
    "end": 1929.763,
    "text": "Sorry, just one other brief side note about the term you used there, the particle particular states, which you mentioned is the joint set of the blanket states and the internal states.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1930.553,
    "end": 1942.141,
    "text": " The other related term used in the literature is the autonomous state, which refers to the joint set of internal and active states.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1942.962,
    "end": 1950.908,
    "text": "Instead of the blanket states, we only take the internal and active states as the autonomous states or paths.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1951.548,
    "end": 1953.71,
    "text": "That's just... Yes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1955.211,
    "end": 1955.551,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1957.615,
    "end": 1967.942,
    "text": " This would kind of be a Fristen-esque phrasing, that the idea that these different sets are going to inherit from the particular partition.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1968.722,
    "end": 1977.308,
    "text": "So the first move is the Bayes graph to the particular partition, which is just this specific partition.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1978.683,
    "end": 1990.205,
    "text": " between internal and external states mediated by a Markov blanket, then sometimes it's useful to talk about specific subsets of the particular partition.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1990.765,
    "end": 2000.247,
    "text": "If we were only interested in one of these categories, we would just call it by name, like talking about just external states or external state 11, dimension 11.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2001.628,
    "end": 2002.948,
    "text": "But other times we want to talk about",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2004.79,
    "end": 2008.852,
    "text": " partitioned states, but still referred to more than one type of state.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2009.572,
    "end": 2013.573,
    "text": "And so Ali brought in this seconds clustering.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2014.473,
    "end": 2017.034,
    "text": "The particular states, that's the particle that's moving around.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2017.714,
    "end": 2021.076,
    "text": "That's the whole entity, internal states and blanket states.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2021.596,
    "end": 2030.699,
    "text": "And then also times it's important to consider the action in the internal states, because those are kind of the ones that can be thought of as",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2031.678,
    "end": 2053.194,
    "text": " in a total control situation they're the ones that are under direct control so like you can control your mind and you can control your action those are the autonomous states whereas you can't directly influence sensory states but you might be able to take actions that modify sensory states by changing where you look or by changing some aspect of the world",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2055.159,
    "end": 2056.84,
    "text": " So those are autonomous states.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2057.421,
    "end": 2062.065,
    "text": "And it relates to this question, can surprise only be diminished through action?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2069.091,
    "end": 2070.152,
    "text": "What does anyone think?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2078.119,
    "end": 2080.261,
    "text": "Here's the throwback to, yes, Ali first.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2083.152,
    "end": 2105.751,
    "text": " Yeah, I just wanted to point out to exact that same place in the text, which as far as I know, there are two basic ways to reduce the surprisal or minimize the surprisal, one of which is through the action, and the other one is through updating the generative model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2107.273,
    "end": 2108.874,
    "text": "Yep, this is the...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2111.485,
    "end": 2137.339,
    "text": " changed beliefs which is speaking more broadly than personally held convictions this is going to be pointing towards the continuum between perception learning and deeper belief states in generative models so perception is changing beliefs bayesian beliefs which is to say updating the generative model learning and perception on the other hand",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2138.598,
    "end": 2165.82,
    "text": " there's action which can change the world and so out of this discrepancy it can be dissipated two ways it's kind of like if there was like a Delta G a Gibbs free energy like something that was um combustible there's like a hill to go down energetically and so now we're in an informational space but they're still at the um clash of predictions and observations",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2167.305,
    "end": 2169.025,
    "text": " is a nonzero discrepancy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2170.366,
    "end": 2181.428,
    "text": "And from that discrepancy, there can be changes in the generative model parameters, reflecting beliefs, and also recourse to action.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2182.369,
    "end": 2192.331,
    "text": "And active inference is about how generative models, which include beliefs about action, resolve this kind of nexus.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2194.278,
    "end": 2200.322,
    "text": " through the flows on updating and action.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2200.342,
    "end": 2201.063,
    "text": "Go for blue.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2201.283,
    "end": 2201.983,
    "text": "Yep, go for blue.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2205.046,
    "end": 2206.226,
    "text": "Oh, sorry.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2206.987,
    "end": 2207.167,
    "text": "Yeah.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2208.408,
    "end": 2213.692,
    "text": "What is the difference between belief updating and mental action?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 2216.453,
    "end": 2218.615,
    "text": "I'll add it as a question, and then someone can give a thought.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2232.17,
    "end": 2232.57,
    "text": " Any thoughts?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2237.753,
    "end": 2248.859,
    "text": "Well, maybe mental action refers to the active states of a more nested Markov blanket.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2249.099,
    "end": 2249.539,
    "text": "So it's...",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2258.217,
    "end": 2284.359,
    "text": " it's an action it's a modulation of precision on the within the generative model and it's not a motor action you know through motor effectors so the blanket here is not it's not made of the actives and sensory states that actually communicate with the external world",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2286.039,
    "end": 2308.754,
    "text": " but it's still internal that's i don't know that's my take on it maybe wrong yeah very uh nice i think just more more discussion can be added so just giving a quick thought belief updating",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2309.554,
    "end": 2337.844,
    "text": " could refer to any kind of parametric updating at all it doesn't even have to be like a cognitive model belief updating is just any time that there's a prior that meets with an observation and gets updated into a posterior you have belief updating and we can use bayesian surprise to talk about belief updating and so on and then as pointed out mental action as it's used in the hierarchical models of it",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2338.903,
    "end": 2354.187,
    "text": " is referring to the policy selection process that's hinted in the action, but the policy selection process or module or archetype as oriented around mental variables.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2355.488,
    "end": 2355.648,
    "text": "So",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2356.79,
    "end": 2384.099,
    "text": " it is almost out of necessity requiring a nested or a hierarchical model because there has to be like a sort of base layer that is not mental action but then at the second level or above you can start to see the same kind of pi policy variables and the same way of thinking about affordances and free energy and expected free energy minimization processes in a second level or above",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2385.182,
    "end": 2403.676,
    "text": " where those action-like processes, or maybe even genuine action processes, are referring to cognitive states rather than a motor effector, as would be understood in the case of conventional motor action.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2405.097,
    "end": 2413.204,
    "text": "Whereas belief updating does not require a hierarchical model, it's just referring very, very broadly to Bayesian parametric change.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2415.902,
    "end": 2440.192,
    "text": " makes sense thank you all right so um can surprise be diminished um through action no not only like you're surprised you know you expect it to be 20 degrees um and you're observing it's 25.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2441.758,
    "end": 2456.469,
    "text": " You can either engage in action selection to change the thermometer under beliefs about how one's actions change the world, B matrix, or one can just update their model to that is now what I expect.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2457.57,
    "end": 2461.372,
    "text": "And of course, that's the fun discussion in active inference with expect and prefer.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2462.213,
    "end": 2466.816,
    "text": "Because if organisms are in the game of diminishing or bounding surprise,",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2468.01,
    "end": 2495.49,
    "text": " then there has to be this nuanced dance between what is being observed understanding it to be simply the most likely but you don't want to be on the likely train off the cliff so there has to also be a space for slightly or very stubborn prior preference distributions that enable",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2496.673,
    "end": 2524.834,
    "text": " increasingly intense policies to be implemented to actually shape the state of the world and oneself back towards that earlier expectation and preference rather than engaging in just purely cognitive updating that's just speaking about it generally but there's a lot to um unpack",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2526.607,
    "end": 2551.026,
    "text": " in a more um model specific way okay only shared link oh awesome awesome this looks like a good reference and also uh live stream 25 I believe was on mental action Sanford Smith",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2560.31,
    "end": 2560.55,
    "text": " Okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2565.633,
    "end": 2571.096,
    "text": "Let's look towards this question.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2573.277,
    "end": 2577.819,
    "text": "Does anyone want to just give an example that can clarify synchrony between internal and external states?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2586.163,
    "end": 2589.485,
    "text": "What's a situation where we can think of internal and external states synchronizing?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2605.745,
    "end": 2609.066,
    "text": " Well, I guess it depends on what we mean by synchrony.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2609.146,
    "end": 2618.407,
    "text": "I mean, synchrony like on a fast time scale or on a specific time scale.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2621.148,
    "end": 2634.41,
    "text": "Because the fact that the internal state reflects the causal dynamics of the environment does not imply that they are immediately synchronized, right?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 2637.11,
    "end": 2638.131,
    "text": " Yeah, you're absolutely right.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2638.171,
    "end": 2639.452,
    "text": "The timescale really matters.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2639.632,
    "end": 2643.255,
    "text": "And also it's important to note that synchrony doesn't mean lockstep.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2643.936,
    "end": 2648.98,
    "text": "It doesn't mean that there's like a thermometer inside and a thermometer outside and they're just following each other.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2650.181,
    "end": 2666.314,
    "text": "Synchrony can refer to the kind of coordination that's more like orchestrated in the sense that if you had two people sawing a tree, they're both going to be taking opposite actions",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2667.694,
    "end": 2676.577,
    "text": " but there still is high mutual information between those two action policies and they're able to be under general synchrony.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2678.118,
    "end": 2680.438,
    "text": "So we can just think of a few areas of examples.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2681.479,
    "end": 2686.521,
    "text": "Like one can always think of a computer example, because computers are clean.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2687.761,
    "end": 2690.362,
    "text": "Like you could just say, well, I have two servers",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2691.963,
    "end": 2693.925,
    "text": " And they're communicating on the time.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2695.126,
    "end": 2697.688,
    "text": "Or they're sending each other information back and forth.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2698.848,
    "end": 2700.99,
    "text": "Or they're tracking some feature about each other.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2702.731,
    "end": 2711.578,
    "text": "You could imagine a communication example where there's some kind of semantic coordination or synchrony.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2714.501,
    "end": 2720.045,
    "text": "You could also imagine some kind of a cellular or a physiological synchrony.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2721.451,
    "end": 2745.61,
    "text": " like the inside of the cell is being modeled as doing inference about insulin levels outside of the cell and then the insulin receptor is like the interface and so there's synchronization of cellular response to perceived or inferred insulin concentration and the external unobserved true circulating insulin concentration",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2746.391,
    "end": 2767.301,
    "text": " mediated through set states the binding kinetics of insulin on its receptors like these are just kind of qualitative examples but there's a lot to um drill down into more ali i think the word synchrony here uh",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2769.201,
    "end": 2776.326,
    "text": " might have been used in the technical term of the existence of a kind of synchrony map between the two coupling systems.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2777.087,
    "end": 2783.932,
    "text": "So in order for two systems to be coupled, there needs to be a synchrony map, namely sigma between them.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2784.593,
    "end": 2798.083,
    "text": "And the whole paper, a worked example paper by Dalton Sack-DeVadewell provides multiple physical examples for these kinds of systems coupled",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2799.561,
    "end": 2827.481,
    "text": " systems and the most extreme case of those coupled systems are the sparse coupled systems in which the Markov blanket is the strongest or as they call it the blanketedness or the blanket index is basically zero but in some other kinds of systems which in which",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2829.215,
    "end": 2841.084,
    "text": " the internal and external states are somehow more closely follow each other, the markup blanket tends to weaken and diminish.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2841.445,
    "end": 2847.249,
    "text": "So, yeah, I think that's the meaning of the word synchrony here.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2848.71,
    "end": 2849.671,
    "text": "Great point.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2851.673,
    "end": 2854.415,
    "text": "Yep, live stream 49.1 with Jakob and Ali this week.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2859.165,
    "end": 2880.984,
    "text": " recommended listen and it's um quite far ranging so that is the most state-of-the-art addressment of the issue a slightly older addressment of this issue and also um importantly coming back to what ellie mentioned about like the synchronization manifold",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2882.239,
    "end": 2904.897,
    "text": " here's the uh example of bird song that friston and friston and frith have worked on and uh this is some of the colorized versions of the trace diagrams that are seen in the textbook that are like a little bit difficult to tell what's happening when they're uncolored lines um but just to",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2906.246,
    "end": 2919.009,
    "text": " highlight the manifold there the x-axis and the y-axis are the first and the second birds belief states and so um to the extent that those",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2920.469,
    "end": 2945.576,
    "text": " pairs of beliefs at a given moment exist on the y equals x line they're believing the same thing at the same time whereas if you could imagine if they were believing opposite things at the same time you'd have like a negative regression and if there was like uncorrelated or unsynchronized belief updating you'd have just a scatter cloud that wouldn't have a significant regression slope",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2946.638,
    "end": 2954.446,
    "text": " And so this diagram is showing how before and after learning, the sharpness of the manifold increases.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2954.766,
    "end": 2959.331,
    "text": "And a manifold is a lower dimensional space within a higher dimensional space.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2960.011,
    "end": 2970.201,
    "text": "So like we have a two-dimensional space here with X and Y, and then there's activity only on this manifold",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2971.087,
    "end": 2978.055,
    "text": " which is being projected effectively, not completely, down into one dimension because it's like a number line.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2979.036,
    "end": 2983.681,
    "text": "Or you can imagine it was a three-dimensional space that was being projected into a two-dimensional manifold.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2984.402,
    "end": 2991.31,
    "text": "So a manifold is just some lower dimensional structure in a higher dimensional phase space.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2995.396,
    "end": 3007.887,
    "text": " And so synchrony, as Ollie mentioned, is referring quite particularly, technically, to the existence of synchronization manifolds.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3009.248,
    "end": 3013.031,
    "text": "And that is related to sparse coupling, blanket index, all these topics.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3013.752,
    "end": 3017.876,
    "text": "All right, so in our last couple minutes, we'll look at this question, about 3.4.1.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3017.916,
    "end": 3019.797,
    "text": "And then over the coming week, just...",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3023.345,
    "end": 3042.675,
    "text": " chill enjoy the week also add a few other questions or discourse so that we can come back to some of the latter sections of chapter three um next week so let's look at three four one in three four one",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3044.312,
    "end": 3073.904,
    "text": " that's the section variational free energy model evidence and surprise the authors look at the equivalence between variational free energy model evidence and surprise and formalize this relationship in equation 3.2 is it possible to unpack equation 3.2 to make these relationships easy to understand great question all right so let's go to equation 3.2 here's what the equation looks like then",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3076.681,
    "end": 3103.262,
    "text": " our extremely helpful annotation crew has gone through and provided this natural language unpacking so i'm just going to copy it down and then we can look at what it actually says and then see how that relates to the the question that was asked which was about unpacking the relationship",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3107.648,
    "end": 3128.224,
    "text": " okay so the surprise fracture i fancy i of the data y conditioned vertical line on the model m is equal to the negative natural log ln of the conditional probability that's p of the data y given m",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3131.274,
    "end": 3137.422,
    "text": " with its upper bound being, so this is a less than or equal to sign, so they could be equal.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3138.283,
    "end": 3140.706,
    "text": "These two, the first and the second one, are equal.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3142.148,
    "end": 3147.995,
    "text": "The second one and the third one could be equal, or the third term could be larger.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3149.901,
    "end": 3175.442,
    "text": " its upper bound being the KL divergence DKL between two lines, the approximate posterior of hidden states Q of X and the conditional probability P of hidden states X conditioned vertical line on the data and the model minus",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3177.25,
    "end": 3198.469,
    "text": " the natural log of the model evidence P of the Y given the model evidence for the data given the model okay so the question was what are the relationships between variational free energy that's the third term model evidence the second term and surprise the first term",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3203.035,
    "end": 3228.632,
    "text": " answer is not in the simple reading of the equation but that gets us to the discussion point so how are these terms related the three labeled terms on the bottom a related question is why do we use variational free energy",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3231.556,
    "end": 3236.176,
    "text": " what is effective or useful about energy measures at all.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3250.165,
    "end": 3276.504,
    "text": " i'll give one thought and then one or two other people could could add in which is um we don't want to be outside of our range of surprise and so by defining surprise in terms of data um and specifically within the natural log space of data which has some just nice properties um",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3278.447,
    "end": 3306.781,
    "text": " we want to stay bounded in the model evidence like we want to have high or the highest or at least adequate model evidence and that is equivalent to surprise we can see the same y given m now if we had that and had confidence without a doubt in our model and we knew how to calculate the likelihood function of the data",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3307.81,
    "end": 3309.691,
    "text": " then things would be easy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3310.111,
    "end": 3312.233,
    "text": "And there are situations where things are easy like that.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3313.353,
    "end": 3337.388,
    "text": "But there's other cases where we can bound our surprisal, which is to say bound our model evidence, evidence lower bound, the ELBO, E-L-B-O, and we can bound this intractable quantity model evidence with a divergence-based energy calculation.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3341.431,
    "end": 3358.806,
    "text": " And so we can do gradient descent, variational inference, message passing, active block inference, all these amazing things on the variational free energy, and just know that at best, we're going to converge to the model evidence.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3361.188,
    "end": 3369.195,
    "text": "So this is an optimization, an optimizable quantity of variational free energy.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3370.407,
    "end": 3373.008,
    "text": " Whereas model evidence is like, if you know it, you know it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3373.108,
    "end": 3375.469,
    "text": "But if you don't, you're kind of stuck.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3376.43,
    "end": 3378.11,
    "text": "Like how likely is this book?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3379.771,
    "end": 3384.693,
    "text": "And it's super hard to understand how changing one word would change the overall likelihood distribution.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3386.374,
    "end": 3399.06,
    "text": "And so that motivates approximate heuristics for Bayesian inference, especially those that are authorized by the sparsity of the data.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3401.517,
    "end": 3423.273,
    "text": " the variational free energy measure allows us to bound surprise with a tractable optimize optimizable function rather than needing to for example flesh out the total space of data likelihoods and model likelihoods which might be futile",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3429.451,
    "end": 3432.233,
    "text": " I'm sure there are other better ways to add things.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3439.6,
    "end": 3456.514,
    "text": "So... So one thing that... Like after reading it, after reading about...",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3458.233,
    "end": 3484.245,
    "text": " after reading the book and after reading other article it i kind of had an insight but i don't know if if it's correct so that the whole energy stuff of course comes from the physics and it's very legitimate to be a bit um a bit a bit confused because this formulation of uh with the",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3484.805,
    "end": 3492.192,
    "text": " Kolbe-Kleiber divergence is a purely statistical quantity.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3493.053,
    "end": 3498.458,
    "text": "So it's understandable that somebody says, what does energy have to do with that?",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3499.639,
    "end": 3509.248,
    "text": "It seems to me that the high road and the low road converge here because",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3510.731,
    "end": 3526.696,
    "text": " When you minimize, on one hand, you can say that the organism maintains its forms and function by minimizing surprise, and that is maximizing model evidence.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3527.576,
    "end": 3530.537,
    "text": "But on the other hand, if you do this,",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3533.684,
    "end": 3559.021,
    "text": " you're going to be able to compute the approximate posterior, a good approximate posterior about the states, the Q of X. So in a sense here, surprise minimization is also a way to compute a good posterior over the states.",
    "speaker": "SPEAKER_04"
  },
  {
    "start": 3562.142,
    "end": 3576.629,
    "text": " right great thanks for that no we'll return to this yes let's return to it pick up here and any other questions in next week so thank you see you all later thank you",
    "speaker": "SPEAKER_00"
  }
]