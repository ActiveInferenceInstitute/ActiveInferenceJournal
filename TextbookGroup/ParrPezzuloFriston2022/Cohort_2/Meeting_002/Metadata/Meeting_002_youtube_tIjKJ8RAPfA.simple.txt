SPEAKER_01:
So, okay.

Hello everyone.

Thanks for joining this second meeting of the second cohort of the Active Inference Textbook Group, where we're going to be discussing chapter one.

Today is September 9th, 2022.

So I'll minimize this and you guys can click on my screen and that will show you the full screen of what I am presenting.

So what we'll do in the live meetings here for the next two and a half months or so is totally going to be driven by the material that's in the chapters and in the appendices.

So we're going to go to the questions page, and we're going to look at the questions that have been asked for that week for that theme.

And we're just going to start with the most upvoted questions.

So here you can upvote a question like this by clicking thumbs up.

So we will start with the most upvoted questions.

And then we can take notes here in the answers and discourse.

And if you just click on that, it opens this page.

And anybody is free to write here.

And after addressing the questions, which is probably going to be most of the time and discussing them, then we will move on to maybe look at the ideas more broadly over here.

So we don't really have too many questions.

If anybody wants to jump in and write a question, we did send an email reminder that, because this was pretty empty over the course of the week, but hopefully thinking by writing in this way will be a structure where we'll be able to hear everyone's perspective and leave the coda in a better place than we found it.

So if anybody wants to jump in and write additional questions in the coda now would be a good time.

And then after looking at the questions, we will pull back and focus a little bit more broadly.

So maybe we'll go over here to touch on the ideas and insights of the chapter and then ideas for that week.

And then in the last minutes, we can just see if there's been any changes to the project ideas and start to see what people are excited about applying active inference to.

And then we will end at the top of the hour.

So let's just head over to the questions, the cohort two questions page, and take a couple minutes to put some questions in here.

So just so you guys know, Control plus and Control minus are good ways to scroll in and out to get the right view of the screen.

And then you can hide this little textbook bar over here.

So I'm going to hide that.

And just give everybody maybe like five minutes to put in a question or something they would maybe like to discuss from chapter one of the textbook.


UNKNOWN:
Thank you.


SPEAKER_09:
Bye.


SPEAKER_01:
So maybe we could just take like one more minute and wrap up these questions.

I just want to say to everyone at any point that there's always the affordance of just listening and also of just rewatching this recording.

There's also the affordance in Gather to raise your hand.

Let's see if I can show where that is.

Boy, it's been a long time.

Oh, right here.

There it is down at the bottom.

So there's this raise hand feature and lower hand.

And then if you would, you can raise your hand if you would like to share just on that particular question, and we're going to have them up in the coda.

And you can also pull up the answers in the discourse and that will pull up the focus view of the question.

And everybody is free to collaboratively like edit the answers here in the discourse.

It's better to really add and be noisy even if it's just like a bullet point list or an incomplete thought or if there's incoherence or if it's contradictory, those are all fine.

It just adds information and perspective on the question.

So yeah, we're going to open up each question, the answers in the discourse and read what has been read and already contributed in the answers.

And then also people want to share other thoughts that they're having, that's awesome.

And then if anybody also just wants to be taking notes, just things that are coming to mind or they don't want to share in a speaking way or just taking some notes on what other people are saying.

So this is really a participatory group and

So it just is what we make it here.

Okay, cool.

I'm just going to leave this little window open or I won't see anybody's hands and gather.

All right, let's see.

I need a double screen.

All right, let's see if I can do it in this small way.

Okay, cool.

All right, so let's get into it.

This first question, I'll pop it open.

And it says, let's check this.


UNKNOWN:
Here we go.


SPEAKER_01:
Uh-uh.

What is the difference between a stimulus response mapping and a state action policy?

So I don't know.

Does anybody have any ideas here?

I think that they're both kind of like an if this, then that.

But they're specific, I think, to machine learning.

So if anybody has any more depth or background in this area, that would be awesome to hear.


SPEAKER_05:
so i don't know the way i kind of think about it oh is that uh arun did you raise your hand uh yeah can you hear me yeah cool i can give a very i can give an attempt at an answer to that um which from my understanding and please tell me if i'm wrong um when you've got the stimulus response mapping you've you're con you've got 100 certainty on what the stimulus is

So with the states, you're then factoring in beliefs about you've got uncertainty.

So maybe you just at a simple form, you could be chucking a Gaussian distribution on every stimulus and then a Gaussian distribution on what your response is to go from stimulus response mapping to state action policy.

That's my intuitive understanding of what's going on.

But again, please tell me if I'm barking the wrong tree.


SPEAKER_01:
Yeah, that's awesome.

Thanks for sharing.

And I kind of think about it in the same way.

Like, I don't know.

I mean, this is probably totally wrong, but like I think like about the Roomba, like the little vacuum that cleans your house.

And so like if you turn it on, it turns on and moves like that's a stimulus, like you push the button and then it turns on.

and then um like it moves around because you pushed the power button like it's a very clear thing versus like the state action like if it's it's full like if the vacuum gets full then it like dumps out but like that state of fullness is like a right like a distribution right like so it can be like more or less full and it senses how far it is away from the the dump out bucket or whatever so that's like the state action like the state can be full but like what

Like what is too full for the Roomba?

Like, is it a certain weight that's in there or like a certain volume or sensor?

I don't know.

I have uncertainty about when the Roomba dumps itself out.

Cool.

Awesome.

So we can just write this in here.

And anyone is free to take notes and type in here.

Okay, cool.

All right.

So, yeah, and anyone's free to just get in here and jump in and do this.

All right, so let's look.

Let's look at this one.

All right, so this question says, is the brain trying to maximize qualia divergence and minimize encoding length?

Alik?


SPEAKER_03:
Sorry, I raised my hand before.

I just wanted to add some comments about the previous question, because I think it's a very important one.

You see, as we go on, specifically in the chapter four, when we encounter the concept of markup blanket,

I think we can see kind of more granular differences between those two concepts, between stimulus response mapping and state action policy.

But briefly, states are just representations of internal or external world.

And actions are specifically goal-oriented responses, and they just try to change the state of the system or the agent.

But when we're talking about just stimulus response mapping, I mean, response doesn't necessarily try to change the state of the agent.

As an example, if you touch a hot object, the pain you feel is just a response, right?

But if you move away your hand from that hot object, it's an action which tries to change the stimulus.

And one other important distinction here is

The term policy is used in a different sense in active inference literature as compared to reinforcement learning literature.

Namely, in reinforcement learning, this term is often used to refer to singular mappings or one-to-one mappings from states to actions.

But in active inference literature, policy usually refers to possible sequence of actions, not just singular actions.

So that's, I think, one important distinction we need to have in mind also.


SPEAKER_01:
Cool.

Awesome.

Thank you very much.

And I looked that up, actually.

So here, like, I think that when they talked about state action policies, they were using it in the machine learning case, because it says in the textbook, the goal directed character of action and active inference is in keeping with early cybernetic formulations, but distinct from most current theories that explain behavior.

Oh, sorry.

Someone's talking.

Could you please mute?

Thank you.

So it says, distinct from most current theories that explain behavior in terms of stimulus response mappings or state action policies.

So I think that this here, they're not talking about the active inference state action policies, but they're using it in the reinforcement learning way.

So it says also stimulus response or habitual behavior then comes a special case of a broader family of policies in active inference.

So I think that the way that they were talking about it in the textbook refers to the reinforcement learning way as opposed to the active inference way, which Ali is correct, it's definitely different.

Any other comments or thoughts on this question?

And thank you for whoever's taking notes in the coda, that's always super helpful.

Okay.

So we can move on and look at this question.

Is the brain trying to maximize qualia divergence and minimize encoding length?

Who has some thoughts here?


SPEAKER_06:
Just the idea of maximizing qualia divergence seems like at some point that's beyond schizophrenic, maybe.

So there's like some maybe threshold at which you would not want to go beyond.

And that seems to me to have something to do with epistemic value.

You can't just try to maximize your epistemic value forever.

You would get into a pragmatic problem with encoding length.

So I guess I'm wondering if maybe a different framing of the question or commensurate framing of the question is, what's the relationship between epistemic value and pragmatic value?

of their trade offs there.


SPEAKER_01:
Yeah, I scanned through chapter one and really didn't see a quality of divergence or encoding length there in the chapter.

So I'm not really, um, yeah, does, is this anyone's question?

Do you want to unpack this question a little bit more for us?


SPEAKER_02:
Maybe.

No volunteers.

Awesome.


SPEAKER_01:
Daniel, thanks for joining us.

I can officially pass the baton off to you and maybe you have some comments about maximizing qualia divergence or minimizing encoding length here.

But we got in and we wrote a few questions and we went through the first one.

We could also go back and touch on that if you've got comments on that as well.


SPEAKER_00:
That question just makes me wonder, what is being minimized?

What is being maximized?

And when is it some particular value that's being minimized or maximized?

And when is it the divergence between which other differences?

And in chapter one, there aren't any of the formalisms yet.

But we'll see a lot of double lines and KL divergences that will cue us towards where a divergence is being at least described.


SPEAKER_01:
Cool.

If you're ready, I can unshare my screen and you can take over.


SPEAKER_00:
Please continue.


SPEAKER_01:
OK.

um any more additional additional comments here i like this is oh yeah i didn't get to write this down but brock had mentioned qualia divergence schizophrenia beyond schizophrenia that was the term


SPEAKER_06:
Diversity, you can imagine, is necessary, and some more might be really healthy and useful, but at some point, I don't, then you're, you have multiple personalities or something, I don't.


SPEAKER_00:
That makes me think of the sense of normalcy, and what is experienced as normal, and how much of a

How much of a deviation from normal is perceived as like, what is perceived as normal?

And where is it perceived as creative and maybe even enjoyable novelty, like a guitar solo?

And then where is the quality of divergence too high and maybe uncomfortable?

And then what's the view from the inside with that actual experience, like what qualia brings in and then where, where is this being modeled from the outside with behavioral descriptions where we might not be able to directly address what the qualia are.


SPEAKER_01:
And Daniel, that reminds me like some of it might be, you said some of it might be normal and some of it might be uncomfortable and, or some of it might be, some divergence might be creative and some might be uncomfortable.

And there's actually like a huge degree of, um,

of like mental disorder associated with creativity.

Like, I mean, studies have been done and it's like, I mean, you're like, I mean, there's the classic, like, you know, songwriter singer who commits suicide and we hear this again and again, but there's actually like a great degree of mapping between the creative type and some kind of atypical mental state.

So maybe both of those are the same.

Yeah.


SPEAKER_04:
okay cool anybody have any comments i don't know if i can see everybody in my tiny screen go ahead sorry hello hi it's not clear to me what real what precisely it means quality divergence because divergence with respect to what i mean usually a kl divergence is a divergence of um like a measure of the difference between two distribution


SPEAKER_06:
so here what does exactly means maybe the person asking the question and clarify i'll also just note that oh go ahead brock sorry i was just i don't i don't know if they're here because already asked but to me it just seems like uh internal kind of population of one quality asset another quality asset

that are differentiable, like you can have divergence certainly of qualia, uh, in your own experience, if you just consider, you know, the various sensory kind of experiential states that you, you occupy, like, okay.


SPEAKER_04:
So that means that would mean, um, like, uh, expanding the range of, um,

of your phenomenology, something like that.


SPEAKER_06:
Yeah.


SPEAKER_04:
So.

Mm hmm.


SPEAKER_06:
Yeah.

So you could imagine a sense of space and self, you know, that's kind of

uh frequent and normative that if that starts to um maybe in a religious or spiritual setting or other kind of group team settings you know you kind of get a group flow going maybe like that that starts to change but but maybe if those two things greatly diverge that wouldn't be great so that maybe is related to the complexity of that part of the model that encodes


SPEAKER_04:
um a representation of the self uh so that would increase the complexity of the of the model which is one part one part of of the free energy minimization scheme so the

I guess, I mean, with each increase in the systemic import of of the of observation, then also complexity of the model, though, needs to be kept at bay within within some limit.


SPEAKER_06:
So inside your blanket.


SPEAKER_04:
So, yeah, so it's

Probably it's a trade-off between increasing the complexity of the model for what concerns the range of possible experiential qualia and their epistemic value, I guess.


SPEAKER_00:
I'll also just mention out of fairness that qualia is not mentioned in the textbook.

But it's totally awesome to consider what the formalisms entail for philosophy in many papers and many discussions do.

And it's an important area to explore.

But it's also not what is addressed.

And I think it's probably, even though these authors in other settings

tackle the problem head on.

The textbook is seemingly crafted to enable some discussions that might not require the consideration of the view from the inside or the phenomenology that qualia entail.

And that helps the generality of the applications across different systems.

and so understanding how they map onto our undeniable experience is a great area to explore sorry go ahead no no i was saying that overall the book doesn't


SPEAKER_04:
doesn't expand too much on the part of the model that represents the agent itself as an entity, like our own self-representation.

It mentions it, but does not really dwell onto it.

More about that is probably in the book of Jacob Howie.

There's a little bit more on that, but in this one, not so much.


SPEAKER_00:
Well, perhaps this connects to the following question on self-evidencing.


SPEAKER_01:
So before we jump forward, I just want to stay on this question for one second.

So I looked up the definition of qualia here and it's the individual instances of subjective conscious experience.

And I don't know, maybe in the question, which let's read it again, it says, is the brain trying to maximize qualia divergence and minimize encoding length?

Um, so I was wondering if this maybe is meant for a question, like in an evolutionary sense, like, is this what the brain is trying to do?

Um, across time, like in deep time from, you know, prehistory to now.

So, um, yeah, we can move on though.

Cause maybe, um, self-evidencing is, is, uh, more addressed in the book than qualia divergence.

Yeah.

So what does self-evidence and inactivism really mean?

Does anyone want to take a stab here?


SPEAKER_07:
Yeah, I asked the question because when I read up, my eyes just glaze over when I hit these words.

I can read them in sentences and it just doesn't stick in my head what is really meant, self-evidencing.

It just turns into something tautological.

I don't have any sort of...


SPEAKER_04:
real grasp at what is what is being said in these sentences i can take a stab at that because really it's a it's a it's quite a simple concept so if we think about the agent not as having a model of the world but being itself a model of its own environmental niche

Then minimizing free energy basically means working, acting so as to collect the observation that it expects, that is minimizing surprise.

So since you can say finding the evidence for its model of the world,

But since the agent is a model of the world, that becomes self-evidencing.

So basically, you could also see it as trying to find the sensory stimulation that makes your phenotype, your organism, viable.

that sustains you.

So that's evidencing, finding the observation, the sensory evidence that is more coherent with your makeup as an organism.


SPEAKER_00:
Thanks.

I'll add a few notes.

So inactivism is a long-lived thread in cognitive sciences that is

long existing before active inference and it is describing that systems with bodies

real particular things existing in the world ought to be having their cognition modeled as bodies engaging with the world rather than like them taking like a view from the outside or necessarily needing everything to be like symbolic communication

Whereas in digital systems or kind of abstractions of cognitive systems, it's very easy to get into some information and symbol passing discussions.

Whereas for real systems with biomechanics and embodiments, inactivism brought attention to the requirement of considering like the active engagement of an entity with its niche.

So maybe it's not a term that provides a huge cognitive model update because for many people, it's very natural to consider cognitive systems as inactive and embodied

embedded and cultured etc etc and sometimes that's called 4e cognition and those are all like in allegiance together but that's what inactive points towards and self-evidencing is describing that the imperative of systems as modeled under active inference is for them to accrue consistent observations

and find evidence for the kind of thing that they expect and prefer themselves to be.

And in the coming weeks, we'll explore this like expect and prefer and how can expectations be preferences?

And what about when we expect bad things to happen and uncertainty about expectations?

But we can contrast this imperative for finding consistent, self-consistent or self-evidencing observations

rather than pursuing rewarding observations.

So one can say, I expect and prefer to be at room temperature and then moving around the space or putting the jacket on or off to reduce surprise about what observations one is receiving, as opposed to needing to construct a reward framework in which room temperature is rewarding

And then it gets less rewarding.

And then what is being maximized is the reward of the cognitive system.

And again, in contrast, self-evidencing puts the imperative on the system's self-model and reducing surprise about its own observations, rather than seeing those observations as just proxy of reward states that have to be maximized.

Arun?


SPEAKER_05:
uh I found both of those answers really interesting and I have a question to each of those um so on the self-evidencing we have so maybe this is fast forwarding a little bit in the book but they talk about both generative models and generative processes and those are distinct ideas so when we're talking about an organism as a model in its niche

it's still distinct from the genitive process, right?

So that's something that I'm not 100% sure on.

And I also find the self-evidencing part a little bit circular, and I don't quite have a good understanding of that.

So in my mind, the genitive model and the genitive process are very distinct.

And yes, you're looking for you're an organism and you're in your niche and you want to succeed.

And by natural selection or whatever, we only really see organisms that succeed.

They're going to look for things that meet their priors, such as a nice homeostasis, food, reproduction, all of that sort of stuff.

That's sort of my understanding of that part.

But it's still an organism using a model to navigate the world rather than it is a model itself.

And then also on the idea of the role

minimizing free energy but also you know it's not a reward to me it sort of is a reward it's just a reward with respect to a prior distribution so yes you're minimizing free energy and it's not this and you know you have a prior preference of being at room temperature that's great but you're still you still have an object what an objective function or functional I think as the book calls it you're just subtracting the prior distribution of temperatures that your body likes

So I still see that as like, it's fundamentally an optimization problem.

It's just the units are a bit different and it's all statistical distributions and the differences between them rather than, I don't know, X minus X bar squared, that sort of thing.

So those are the areas that I'm not very clear on.

So I don't know if anybody could clear those up.

Thank you.


SPEAKER_07:
So can I follow up on that then?

So on the inactivism, I think the problem is knowing what the specific meaning of it is compared with embodied and embedded, because those Es are so often used together.

where would you say in activism rather than embodied?

And I think you touched on it by saying about it involving having a model maybe, whereas being embodied doesn't.


SPEAKER_00:
I would suggest that inactive calls the action into focus, whereas the embodiment and the embedded refer to just the materiality.

But the reason why they are allegianced as 4E, EEEE, et cetera, they're just fingers pointing at the moon.

They're just fingers pointing at real embodied organisms and some of the complexities of modeling them and framing them.

in contrast to disembodied approaches so um they're pointing at organisms and they're different theoretical vectors that have been taken and some of the synthesis amongst them has already been carried out


SPEAKER_04:
Yeah, and activism became popularized, the notion, with Francisco Varela, by Francisco Varela, actually.

And I think he was not too fond of the term, actually.

But anyway, the thing is that he wanted to stress the fact that cognition and consciousness emerges

the circularity between um sensation and action so that was uh it was was enacted in the circularity continuous circularity of action and sensation so

I also feel it's really close to the free energy approach and active influence, although there are some of the early champions of an activism like Evan Thompson and some other scholars that argue that there are actually crucial differences.

Anyway, for what concerns the...

the difference between the generative process and the generative model.

The generative process is basically the actual physical processes that turns causes into stimuli, that impinge on our sensory surfaces.

The generative model is the best guess that an organism

uh can make about that so they're not identical of course um the the organism tries to learn at its best the generative process but you know it's just a model um ali


SPEAKER_03:
Yes, and I also wanted to mention Jacob Howie's well-known paper, The Self-Evidencing Brain, which I believe is the seminal paper which introduced this concept of self-evidencing to active inference literature.

And in that paper, he also contrasts this term with inactivism, inactivists and all the other four e-cognition frameworks and theories.

But briefly, he believes that the self-evidencing brain, by putting a boundary, namely the Markov blanket,

as one of its essential components in order for it to be able to infer the states of the environment, it can retain its cognition within its inner statistical or generative model.

So that's one of the reasons the self-evidencing concept was deemed necessary to introduce at the first place.

So and self-evidencing is something that just is beyond the biological brain and it can refer more generally and more broadly to any agent which tries to learn about its environment as a one dynamical system which tries to perform inference about

the other dynamical system, which is the outside world, but with a particular aim of trying towards minimizing the error or performing the allostasis, so to speak.

So that's one of the main differences between inactivism and self-evidencing concept here.


SPEAKER_00:
It's also very illustrative to look at figure 1.2 and see where these terms are used in the context of the low road and the high road to active inference, which is one of the key

concepts in this chapter, and it's describing how the following chapters are going to be structured.

So we see self-evidencing on this upper branch of the subway system coming down from the high road.

And we see some of these other terms that people have been mentioning like generative model,

coming up from the low road.

And then in the same page that we were just discussing, I copied some sections from the text that are describing these high and low road.

They describe that the high road is starting from the question of how living systems persist and act adaptively in the world.

And so that is very resonant with self-organization, which is the first stop on that subway system from the high road.

And also Varela's work, autopoiesis, a lot of questions about how cognizant sentient systems persist.

The high road perspective is useful to understand what living organisms must do and why.

Why?

To be persistent?

via surprise minimization, not via reward maximization, and then what they have to do.

So it's the what and the why in response to the broader question of how complex systems persist.

That's the high road.

And we've had many discussions and fun for every person to also think about this high road, low road distinction.

But the high road is starting from a complex system

thriving or persisting in a complex niche we can think of.

And then the low road is starting from Bayes' theorem and continues up through the Bayesian brain, also motivating active inference from a different direction.

And it is describing the low road perspective is useful to illustrate how active inference agents minimize their free energy.

Well, they're not necessarily doing frequentist statistics.

They're doing something that we can describe as Bayesian.

And this textbook is going to introduce Bayes' theorem.

briefly in a box and it's a big area and some people will be familiar with thinking about priors and updating priors and the way that that's discussed in Bayesian statistics.

Some will be familiar, for some it might be novel, but this is describing kind of the atomic computational or statistical nucleus

that is going to describe how different systems can fulfill that imperative that we saw traced out by the high road.

And Ali, I know you have a lot to add on that.


SPEAKER_03:
I've also put a PDF to Carl Fristing's essay Beyond the Desert Landscape on the resources page and also on the chapter one questions and notes page.

I believe this essay is the most comprehensively articulated and, in my opinion, very beautifully, even poetically articulated

account of the high road and low road distinctions and the philosophical distinctions between them.

If you scroll down, I think you can find the paper I've attached there.

Yeah, right at the bottom of the page.

And I've also appended, yeah, that's it.

The Carl Fristons, no, below that, yeah.

beyond the desert landscape.

And I've also appended Andy Clark's reply to this essay because this chapter comes from this book called Andy Clark and Its Critics, which I think can help to understand

the real differences between those two concepts and why it's important to distinguish between them when we want to discuss and understand any active inference related concepts.


SPEAKER_08:
Thank you.


SPEAKER_01:
Awesome.

Thanks.

I'm going to just make note of that in here.


SPEAKER_04:
Maybe just a comment on the why.

If you, Daniel, like talking about the high road, is it why really?

Because my understanding really is the perspective or the nature of the free energy principle is really, as Carl says,

It's more tautological than teleological and why since the point to some sort of teleology.

So it's, go ahead, go ahead.


SPEAKER_00:
Yes, scientific or formal addressments of teleology or end or goal directedness are very interesting.

And another framework or theory, which is evolution, has also threaded the needle with tautology and teleology.

And so there's a lot to be said there about how

those two categories aren't necessarily disjoint do you believe they have to be disjoint or are you expecting or preferring that they are um if the if the imperative is to persist and survive and we simply don't observe systems that don't then that phenomena can be both tautological in the sense that it's self-describing

as well as teleological in that from a perspective's view, not speaking for the system itself, but from our view on the system,

it is acting as if it is trying to survive.

The bubble is acting as if it's trying to get to the surface of the water in the sense that it's not acting like it's trying to go deeper.

We don't need to entail any qualia or any sort of broader theological reason for that to occur.

We can describe something that is both teleological and tautological.


SPEAKER_04:
Yes, I think I agree.

I think that from what Carl often says that it's deflationary account is that basically the free energy principle basically describes a self-organizing system

just because it persists.

And so what characteristics does it need in order to persist?

And so in that sense is tautological.

So it's just, you know, if it persists, it must behave like that.

so you don't even need to put in any imperative to survive if it survives it must behave like that but of course as you said you can frame this self-organizing drive in a sense as some sort of imperative to to maintain its form and function of the organism so yeah


SPEAKER_00:
there's a lot of interesting things to say about that.

And also one note is sometimes we speak in a mode of like what the imperative is for the system as itself in terms of what it normatively should or imperatively must be doing.

But also we can just speak from ourselves as modelers of other things as what our modeling imperatives are.

And that is a slightly different question, and that's sometimes known as instrumentalism, which can be compatible with realism of various flavors, and it's been explored broadly.

However, from our perspective as observers, things that are not acting as to minimize their surprise relative to some area in space that makes us say it's that kind of a thing.

If it's not staying in that space, which we're defining as that kind of thing, it's not that thing.

If the tornado were not staying in some range of phase space that we call tornado, it wouldn't be a tornado to us.

And so sometimes that can be a more empirically grounded and less speculative stance to have two feet as us as modeling systems.

which is going to be consistent with the meta Bayesian approach that's discussed later in the book.

And it sidesteps or it preempts a lot of very thorny questions around speaking for what systems actually are or actually are doing.

And it's the difference between saying, well, the thing is a model of its niche.

Big if true.

We're going to model it as if it's a model of its niche.

It's irrefutable.

That's just a choice that we're taking.

And someone could say, well, I would have taken a different choice in modeling.

And you can say, great, what would your choice have been?

And there's actually a starting point instead of just this endless speculation around, well, what is the system really?

And especially when we think about our Markov blankets and our inability to make direct contact to hidden states.

it bolsters the justification of speaking as a modeler.


SPEAKER_01:
Very cool.

Anyone else with comments on this question, this self-evidencing and inactivism, which we could talk, I'm sure, all day about?


SPEAKER_07:
So if I just finish off that, I think possibly it's the language that's the problem.

Self-evidencing, it just sounds as though it's self-confirmatory.

All it's doing is looking for support for its existence, which is not a good strategy for survival.


SPEAKER_04:
Why you say that?


SPEAKER_07:
Well, if I only look for evidence of my existence rather than things that are a challenge to that, then

I mean, it's possibly related to the darkroom problem.

Yes, exactly.


SPEAKER_04:
Yeah.

So for the sake of long-term persistence,

it may be necessary to incur sometimes, transiently, into states that are surprising.

So there is no real... There's no real incoherence there, I think.


SPEAKER_07:
No, I agree.

I'm just challenging it as a language, a bit of a language barrier.


SPEAKER_00:
Yeah, great point.

And indeed, the natural language

is often heavily shading interpretations and people's conceptions of different terms, like around surprise, belief, expectation, preference, all these everyday terms, which are core in the active inference ontology.

It's really important to interrogate our understanding of them and check their alignment with formalisms.

This book is going to a large extent focus on the kernel of the active inference action perception loop.

Single agent, single level kernel.

And in that way, it's very analogous to like a single linear regression.

In practice, linear regression on large data sets does sweeps across families of models, and there's all kinds of things that come into play just for the linear regression.

That's the kernel.

And so in a nested model, one could reduce surprise and find confirmatory evidence.

I'm the kind of thing that seeks out novel information sources.

And therefore seeking out novel information sources is confirmatory evidence of that.

So once we step into multi-layer models, many of the absolutely valid limitations of the kernel in and of itself are addressed.

So those are like all the directions that people's questions on and written down are super important.

They're all the things that are,

direct adjacencies and relevant for applications.

And there's going to be things about real complex systems that the kernel does not describe totally.

So this isn't like the end of the active inference modeling of complex systems total book.

It really is just describing like the essence of the loop.


SPEAKER_01:
So I want to just give Arun the last comment because it's the top of the hour now.

So Arun.


SPEAKER_05:
Yeah, I just wanted to add to Neil's question again.

Like, I fully understand where you're coming from, Neil.

When I first read about the self-evidencing thing, I was like, that makes zero sense.

And exactly what you described, like, oh, OK, you're not going to look for predators as a basic thing.

That's not evidence of my existence.

That's evidence of my death.

But I think the way I've sort of come around to it is

It's all about the prior preferences and what you expect to see.

And yeah, this occupation of face space, I think, is quite important of you sort of get attracted to particular states where you're comfortable.

But you do need to know about the rest of the world anyway, and you have to plan for not being in those states sometimes.

And so looking for evidence of your existence

is all about matching those priors.

And those priors can be pretty flexible.

So yeah, I think that will, in my mind, that comes through a bit later on in the book, I think.

So I would say my advice to you is stick with it.

But it was very counterintuitive to me as well when I first came across it.