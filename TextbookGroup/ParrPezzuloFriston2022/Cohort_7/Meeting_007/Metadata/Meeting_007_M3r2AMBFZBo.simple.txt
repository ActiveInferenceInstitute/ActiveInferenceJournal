SPEAKER_03:
Okay, welcome back.

Parts of cohort seven.

Um, we're in three.

So beginning in three.

Is there anything that anybody wants to begin with?

Like any overall thought on three?

Or any any place to start?


SPEAKER_01:
I guess I was a bit slow with the recap of the chapter here, but one thing at least that I thought a bit about while reading it was, and I guess not unique to this chapter, but the preceding ones as well, is the interesting connection to other domains.

You mentioned the physics and the bioactivism and cybernetics and all of these different ideas, and also how it seems as if

Jone Peter Reistadler, Active in France has evolved over time and emerged from all of these ideas and, like the connection between it, which I. Jone Peter Reistadler, Think seems very.

Jone Peter Reistadler, I think it's very interesting and.

Jone Peter Reistadler, i'm just wondering if there are any resources with with someone that has like mapped up the connections and perhaps like evolution over.

of of the ideas over over in history and so that you can get like a good overview of of how this has evolved and it's connected to other areas and perhaps like even what different assumptions and applications go into it yeah that's a great suggestion I mean you mentioned kind of like a um


SPEAKER_03:
historiography like bibliography tracing but then also like the claims and the rhetorical assertions and understanding what which claims um transferred it also kind of reminded me of this um I'll I'll put it here but this in the complexity Sciences this one graph

I mean, even though it's just one partial representation, it becomes quite popular, even though it's just a subsample of the tip of the iceberg of one person's representation of one way to view it.

But then it does give some coherence, even just from chapters one and 10 of the textbook, it could be possible to pull out some of these kinds of threads

then what's that and it's like how different would it really be from active inference mathematics of complexity systems and complex systems network science cybernetics maybe there's information theory here somewhere artificial intelligence so agent-based modeling

So I think it would have a lot of similarities to this, but I agree.

Yeah.


SPEAKER_01:
Yeah, super cool.

I'll check that link out.

I guess he has some resources in the book, like the table 3.1, for instance, but also from chapter 2, the figure... Which one is it?


SPEAKER_03:
2.6 as well which i think have like quite nice connections too one um kind of uh history crossover moment from uh from last friday this uh

model stream 13 synthesizing the born rule with reinforcement learning so they're coming from a um quantum measurement empirical setting and then as they started to relax certain assumptions and try to generalize the born rule they got into the generalized sensory motor interface and the sort of generalized cognitive setting

So that's like a low road generalization.

And so we had some interesting crossover moments where they're in the laboratory measuring these quantum collapses, and then they've converged upon where from active inference, it generalized into the quantum over the last several years.

So there could be cool ways to go.

Any other random thoughts on three or the high road?

I mean, that's kind of what three is about.

One just opens the book, just like 10 closes the book.

Two took us on the low road.

Now three is going to start from up here.

and come back down to active inference so that we're we we get off the slide of chapter three and we end up right at chapter four where we finally see the active inference generative model but yeah any thoughts on high road three like just to kind of illustrate that um


SPEAKER_02:
Yeah, yeah, go ahead, go ahead.

But to me, I mean, it's almost like we're just creating a more granular structure around the Socratic method.


SPEAKER_00:
How so?


SPEAKER_02:
We've got agents in an environment and they're asking questions about the environment and receiving a response from their environment and then integrating that response into their internal model of the world and rinse and repeat.


SPEAKER_00:
Yes, interesting.


SPEAKER_03:
there's the there's the Socratic element on that there's the hegelian element on that and like all of these more like composite frameworks where like it doesn't seek to reduce situation down to just like a a a monad unity but to a dialectical unity

are there other aspects to the Socratic method wonder reflect refine and cross-examine restate repeat this this connects I mean to the active inference ontology what is surprise or you know these are these are the kinds of questions

And these are like a playbook.

What does the book mean by novelty?

Why would they think that the KL divergence is the way to do this?

Is the KL divergence the only way to do this?

There's a nice buildup towards three.

In chapter one, this is kind of the minimal agent niche figure ground, like two-part partition.

That gets nuanced into kind of like a four state

partition we have a true internal and external and then there's two aspects to the blanket or you can kind of collapse those two into one blanket and that's where the the Markov blanket concept

initially was was just like it was one blanketed node and then one of friston's novelties to adapt the markov blanket concept into the cybernetic setting was to kind of split that blanket or interface into an inbound and an outbound so that's where we get the four but here it's still framed as like they're just four variables like in a program

In chapter three, it picks up with those four, and now they're defined in terms of flows, like the dot being a derivative.

So now there's like four simultaneous flows on this fourfold partition.

So that is coming more from the Bayesian mechanics, but that just shows like it's like chapter one is the parent of both two and three.

And then chapter two goes more of like an engineering program way of doing this.

Like, well, what are the variables?

Like what are like, what's the local computer state, the remote computer state, and then the descending to and from state.

Here's more of that physics way to see it.

we can look at this figure in context but this is kind of like showing uh B is the blanket X is for external mu is for internal kind of like maybe mu for mind for M or something but it's like saying if you have like a um just just to make a big numbers if you have a 0.5 correlation between

um internal and blanket and a 0.5 correlation between blanket and external then you're going to end up with a 0.25 correlation between internal and external just because it's kind of like it's two hops and each one has a 0.5 correlation so that's kind of how you end up with correlations across blanket because of kind of like the chain rule of partial correlations

Any other random thoughts on three or we can look at the accident questions?


SPEAKER_00:
Or we can look at the text.

This is, oh yeah, go ahead, Jeff.


SPEAKER_02:
Um, the one thing that I think, and again, you know, we being stuck here in the, in the Ford era of time, um, Melvin Boston, um, has developed the theory of info dynamics, which is a, uh, corollary to thermodynamics.

And I feel that there's overlap here.

And I can't be more specific than that, but I can link the article.

And I don't know, maybe somebody wants to take this and run with it, or maybe I will at some point.


SPEAKER_03:
Okay, I remember Ali in a characteristically Ali-styled

Terrence Deacon has also has touched upon the info dynamics.

It's kind of like the the data information knowledge wisdom.

like kind of but but it's it's a little bit different than that but it's like what are sort of the um syntactic dynamics of of information like at the sensor processing level and then as you move into more semantic levels of information um how does and then and then deacon highlights that um those higher levels

they they are dealing more and more explicitly with like adjacent possibles rather than processing what is like immediately there like you can't understand the higher levels without also considering like this kind of like as yet unmanifest shell of which is kind of like when we get into action planning that's a classic example like most plans will not happen

yet the expected free energy still kind of considers them.

So in this question, we'll see if the actual, maybe the real questions will be addressed, but this image, this is from one of the earliest, like pre-2010 winged snowflake,

So here, temperature increasing is going down.

So it's colder higher up in this image.

And this is like the actual sky.

So it's like, it's colder higher up and then like closer to the ground, it's cooler.

So there's some critical temperature under which from an elevation perspective, like the snowflake is going to melt.

Above this level, it will persist as a snowflake.

so if it was a inactive snowflake and um then let's say you started with a cloud of like a bunch of snowflakes that were that were high up um then you just would have diffusion so you wouldn't need to propose any kind of action selection it would just be like um if there was laminar flow all the snowflakes would stay up here if it was going straight down all of them would fall down like that you wouldn't falsify the hypothesis that it was just like a particle

then what you see with like um life is you see action that that acts as if i mean if you came back millions of years later then you'd be seeing snowflakes that would be acting as if they were staying above that temperature threshold because the ones that didn't have kind of crashed out

so this is like showing up in a population of actual negantropic organisms and they've been fighting um death you know even without getting reproduction stuff like that but that was an early physics inspired way to think about survival but this this could be a blood sugar critical threshold temperature critical threshold

okay quick yeah that's that's a fun one of the early fun representations um when was that from um you know let's just look up what it's like maybe 2006 first in paper okay okay cool not that kind of snowflake

yeah this this 2006 paper with kilner and Harrison yeah here's the here's with a different notation but but we see a lot of the same input and output

then here's like three levels like this is kind of the fast inference layer then there's the slower attentional neuromodulation layer and then there's an even slower topological change neuronal connections so it's like already those kind of nested time scales of inference um because those were already being considered in the fmri spm setting let's see what else is in this paper

This kind of looks like a heat engine, kind of like a duty cycle on an engine.

Cortical columns.

It comes back in the book.

Generative and recognition directions.

from pixels to planning that's like the most recent um paper but I mean here we have pixels and still that same kind of um minimal case already kind of highlighting uh fmri and repetition suppression

And those are some of the robust EEG and the fMRI type findings like in different populations of people and then like, when the mismatch negativity and the 200 millisecond tone and all those kinds of things.

Yeah, pretty interesting.

Almost 20 years.


UNKNOWN:
Okay.


SPEAKER_03:
First question is about a Markov blanket in time.

Okay.

As usual, attaching a last name to something does not always add information because it doesn't do anything other than just make sort of a historical illusion.

But this is the Markovian property in time, which is basically that the past only influences the future through the present.

So it's like the current state of the program influences the next state.

And anything prior to that gets distilled or projected onto the present state.

That's the Markov chain.

And then if there are like two time states of time dependency, then it could be like a one Markov chain with two time steps.

Like if your last two moves were up, up, then here's where that transitions to.

So even if it is like multiple time steps in the simulation, you can still kind of model that as a one Markov chain, or you can model it with multiple time steps.

But then people also have broader questions like, you know, without knowledge of the present, what can you do?

Say two.

What is a statistical rather than a non-statistical interaction?

We're talking about a statistical model.

So all the interactions which look like edges on a Bayes graph are statistical interactions.

Then it's an interesting question.

What would make a non-statistical, maybe that's the real, quote, real interaction itself?

And then third question,

Why does independence between the flows and the two side of the blanket matter so much?

it's a complex question like matter so much relative to what internal and external states they can influence you can set it up so that they have total influence on each other so it isn't that it's that the blanket isolates it it defines how they articulate and then it could depend a lot or not but I think a key piece is that their random fluctuations are kind of buffered from each other

Like they're getting the noise is getting, at least the noise are orthogonal.

They're being like randomly sampled from noise, but that may or may not matter in a certain situation.

These are great questions.

There's kind of these cousins of closely related terms.

Like, of course, we have active inference, but then we also hear about Bayesian brain hypothesis.

That's in figure 1.2.

And then there's predictive processing, predictive coding.

This was a question that we asked of Friston in 2018.

And I think the answer has also kind of sharpened since then.

You could have a situation where all of these were in play.

could have an active inference system that was brain light being described by bayesian brain hypothesis where the processing that it was doing was based in terms of prediction and anticipation and and all of that and the messages being passed between layers reflected predictions and their discrepancies so all four of these could be in play

or you could have situations that kind of nuanced that um but they're more similar than not predictive processing highlights making predictions which is is almost without a space between with the bayesian brain hypothesis because that's kind of what a prior and observation are

predictive coding sometimes is used just equivalently to predictive processing other times and this is explored a little bit with Maria in um the live stream 43.0 and she studied some of the philosophy of the predictive processing predictive processing can refer to like

the fact that the whole cognitive stack does this predictive processing whereas predictive coding is more of a sub hypothesis that the messages being that are transpiring between layers are encoded in terms of the predictions but some other type of message format could be passed active inference amongst all of these highlights like the role of action

Whereas Bayesian brain hypothesis, it could be a passive Bayesian brain, but again, it could be an active one.

And predictive processing, predictive coding, a lot of those models were sense-making only.

But you could consider making predictions to be like a kind of internal action.

But then those types of models generally earlier were not considering like eye movements.

but once you get into the sense making for what the retina sees in a moment and the choice of not just what to predict at the next time step but where to move your eyes and what to predict when you move your eyes there then that gets more into the full active inference setting so yeah that that's a question I thought about many times so it's great to get some more meat on that but I specifically wondered about the


SPEAKER_01:
Like overview picture overview figure of the low road and the high road where predictive coding is specifically on the low road and the processing on the.

High road if I didn't mix them up now.

Could you explain why.


SPEAKER_03:
yeah why they're separated like that uh let's put some more meat on it sure no I mean it's it's a it's a great observation predictive coding down here yeah first off um unlike a subway map it's it's not that these are like strictly prerequisite in a certain order

So that's kind of interesting.

So it's not that this is the only final representation.

But predictive coding, it could be argued, it's an information optimal way to send messages about predictions within a system.

So...

when doing this kind of perceptual inference it's like let's just say that we were we were um we were um doing a measurement scale and uh we're measuring cars they're a thousand pounds we expect them to be a thousand pounds we could um perhaps most parsimoniously report like minus three if it was three below or plus seven

So it's like that's smaller than saying 997, 1,007.

So this could be as argued as kind of just like a model as a sort of like an intra model strategy for information, theoretic, optimal transmission of information about predictions.

Whereas predictive processing, which I don't think it'd be ill-fit on the low road, because we're talking about Bayesian brain and stuff, but one reason why it could be put on the high road, high road,

aims to start with minimal assumptions other than a persistence, either a self-observed persistence, like survival, or a sort of measurement type persistence, like experiments are observing something repeatedly.

So in that situation, you don't know what is happening necessarily amongst the elements of what you're observing.

you can say there it evinces behavior that it is doing something like um you know when when the nest mates come to the surface of the ground that in the morning just as the sun is dawning we don't know how they're sending out you know information within the colony but it's like they're predicting that it's about to be the right time to forage

So it's, or whatever this thing is, we don't know what it is, but it's acting like it's predicting what's happening.

Great, thanks.

The ordering, there's a lot of, it's like the slide, some game, I forget what it's called, but it's like where somebody else makes the slides for you and then you have to do like a lightning talk.


SPEAKER_01:
slides in a random order yeah yeah yeah because I definitely when I looked at it the first time I definitely read it as a subway map uh but yeah I I when I looked at it the more I was like a bit confused about the motivation between putting it like that here were some of the awesome slides from Maria with the history of the perception and about how how it's it's an ancient


SPEAKER_03:
from antiquity to the idea that pre-existing information structures sensory data, then where the book kind of picks up is with Helmholtz and that's sort of this like hypothesis testing.

Then that sort of like hypothesis testing idea

finds a more natural fit with Bayesian epistemology.

rather than for example scientific positivism or scientific falsification approach so it's not that we're just like seeking to lock in a fact about observation or seek to lock in the rejection of a hypothesis it's more that there's just this like envelope or portfolio or distribution that's getting updated and so that aligns more closely with the bayesian

methods than with um kind of rule it in positivism or rule it out falsificationism okay 3.2 i think it'd be a cool thing if we uh maybe now it'd be easier we could paste it into an llm and just say generate the code for this

but it's just showing that you can have chains of partial correlations.

Like of everybody where A happens, 50% B happens.

Of everybody where B happens, 50% C happens.

What percentage of A had C happen?

And then you can just multiply the probabilities like a chain.


SPEAKER_00:
Okay.


SPEAKER_03:
If one defines preferred states as expected states, this is from the book, then one can say living organisms must minimize the surprise of their sensory observations.

I'm not clear on the ontology here.

Is it that preference is the same as expectation, or formally we can use them in the same equation or something else?

Does active inference make ontological claims, e.g., preference is actually expectation, just as heat is actually excitation of molecules?

More generally, is free energy in physics just an analogy or an ontological assertion?

This was brought really nicely together in... I'm forgetting the first author, but... Stephen Francis Mann...

p as a measure of both probabilities and preferences that's where we get pragmatic value that's the clearest difference from reinforcement learning rather than the proposal of a totally ancillary secondary reward distribution that's like observations or observations plus actions like q learning rather than projecting those onto a reward

ranking and then using that reward ranking in this actionable way the observations directly are going to be compared with a preference distribution which is a prior over sensory observations and that does the pragmatic value work but some and then they kind of even talk about how like people will lean on one of those interpretations or another

but they're both equally viable.

Is there a minimal example of a thing defined by Markov blanket?

such as a cell or some subcellular element?

Is a thing persistence of Markov blanket?

Are all things non-equilibrium steady state processes?

Do we need to be more strict in saying these things are only self-evidencing things rather than things in the colloquial sense?

Some work towards that is from this...

particular kinds, path integrals, particular kinds, strange things paper, just showing that ranging from inert things to classical simple things to strange and self-reflective things, they all fit within this interface concept.

It's really just what is the modeler's system of interest.

that's also the first step of the chapter six recipe for modeling and it's non-trivial to identify the system of interest i mean if you're studying the heat transfer from the engine you could make an argument that the system of interest should be like the solar system or you could say okay but i'm only interested in the 99 heat um transfer threshold and then at that point you might even exclude some of the plastic on the engine

So it's not that there's like one kind of thing, or maybe you're interested in a specific thing-ness.


SPEAKER_02:
I'm reminded of Fields' course as well, Chris Fields' course.


SPEAKER_04:
Like in how?


SPEAKER_02:
The physics of information processing, right?

And how you have to define a thing and really going down to...

um bits being the fundamental construct of the universe um you know in um um shoot i've got i've got the i've got the article on my bookshelf behind me but um art wheeler you know john wheeler john archibald wheeler it from bit right so you know ultimately things are constructed from um blank units right so


SPEAKER_03:
yeah and the bit is like a collapse onto a yes or no question that's like the simplest question okay i'm even going to look up what these are hylomorphism every physical object is a compound of matter and form hylozoism doctrine all matter has life


SPEAKER_00:
Okay.


SPEAKER_03:
What is the analogy to friction in a cognitive system?

How strong is the analogy?

Okay, nothing here.

What would anyone say?

Like if we're thinking, okay, the baseball is going to go in the parabola path of least action.

Baseball's quite massive compared to the air molecules.

Still though, there is friction with the air.

Some of that energy is going to be lost to heat.

And then if it were in a vacuum, you would lose less energy to heat.

If it were in a very thick liquid, you would lose more energy to heat.

So this person's asking about how these equations might work well for like the frictionless assumption.

Like, you know, it's a collision on the frictionless billiard table and no energy is lost from hitting the sidewalls.

And then you get a certain play out.

But then if you do have friction on the table, it's like everything is getting slowed down because it's getting dissipated.

What do you think, Jeff?


SPEAKER_02:
I think the distribution curve is going to be wider, right?

I mean, if an agent is hungry...

or dehydrated or any other type of state that impairs a optimal band of processing capacity, then you're going to have a broader, yeah, you're going to have a broader distribution curve.

Like if I'm under the influence of drugs, you know, um, that, you know, make me hallucinate my ability to interact with my environment is going to be diminished.

Right.


SPEAKER_01:
But isn't, isn't friction just included in the oil or garage questions?

Like, isn't that just shaping the, the landscape of which you

find the path of least resistance.

Like it's about finding the equations of motions, right?

And if friction is part of your system, that is gonna be part of finding the path of least resistance.


SPEAKER_03:
Maybe with very high friction, does it break down?

Also, friction is so close to Friston.

It's a classic typo.

It's so funny also just reading these, like, okay, and there's the Helmholtz.

But we just saw Helmholtz from the perception as unconscious inference side.

But then here's Helmholtz's work from the flow dynamical side.

So it's like it was already right there.

You can modify the Euler-Lagrange equation by adding non-zero right-hand side to incorporate friction.

That's dissipation function.

Okay, let's keep it in mind.

One thought about the under the influence.

Are there any treatments or substances that reduce the variance on performance?

Or are...

is or do do interventions always or usually increase variance like if you did something just quote normally a hundred times and then okay now do it with one eye closed or do it like you know standing on one leg or do it when you're really tired maybe some of those or do it on caffeine

it's like it might be you might be better you might be worse on average but then would any of those have a tighter distribution or when we change something do we always make it more variable too seems like it would be very oh sorry go ahead jeff no go ahead go ahead seems like it will be very like dependent on the on the task um as well but i'm sure that certain


SPEAKER_01:
interventions would lead to both the higher and the lower variance like i don't know if you would take a sleeping pill that would like reduce the the balance of what you'll be doing the the next the next years but uh we'll probably increase the variance in your performance on certain tasks like i don't know reading a book or doing something that requires you to be awake


SPEAKER_02:
I'm coming down to instrumentation and augmentation.

If I'm in my natural state, in my body, I'm not going to be able to stay underwater and explore for a very long time.

But if I have a mask and a snorkel, then I'm going to be more adapted to the environment.

But it is a technological adaptation, not a biological adaptation.

And if I have a scuba tank, even more, right?

So that is tightening up the curve in terms of my performance in that environment.


SPEAKER_03:
yeah that's a great point too is the the off source i mean if you go on a ventilator or a pacemaker you could have lower variability in your heart rate or breathing or if you had an exoskeleton that was like drawing for you you would have lower variability but with kind of cascading externality


SPEAKER_02:
And this comes back to me again to the fields course where, you know, we've got this mezzo scale where we're naturally inclined to be able to understand and comprehend.

But when you look at, you know, things at the, you know, below the classical Newtonian scale, if you look at astrophysics or quantum physics, there is no conjoining or comprehension without instrumentation.

So we literally can't even explore those environments without augmentation.


SPEAKER_03:
Yeah.

Let's just say the baseballs are flying around in the dark room.

We can just put on a strobe light, take a picture.

We can say, well, the photons of our strobe light probably didn't influence the baseball that much.

That's why it's classical.

then yes when you get into things that are on that scale all of a sudden it's like it goes from not mattering not mattering barely barely barely barely barely and then all of a sudden it's like it overwhelms when you're studying things that are at that exact scale then your instrument becomes as big it's like your thermometer has a certain heat capacity if you dip it into a little to one molecule of water

In order to get an accurate read on that temperature, you would have had to already know the actual temperature.

Otherwise, you would be getting a compromise between the temperature that it really was and what you thought it was.

But you would know.

Yeah.


SPEAKER_02:
It's funny because I was just reading about from economics.

I was reading about Jevons paradox, which is that the more efficient a system becomes...

the more efficient you become in resource extraction from an environment, the more you're going to use that resource.

And then it could cause it to collapse.

I think an example is the EPA requires higher fuel efficiency on cars.

So because of the higher fuel efficiency,

you uh people wind up driving more because it's cheaper to drive and you're actually putting out more pollutants into the environment than you would have otherwise and then another car related one would be like adding a lane to the freeway


SPEAKER_03:
And then people think, oh, great.

Now there's more lanes.


SPEAKER_02:
Oh, yeah.

Capacity planning for highway.

It's huge, right?

Like you look at Houston or anywhere where they do widening and it just stays.

It just stays.

It's actually that they're incentivizing people to get in cars more and not realizing that it's going to cause, you know, friction or eventually collapse.

Right.

You know, in the end, you know, it's it's it's collapse building systems that have.

like if you look at how the Khmer civilization fell, it was because they created all this wonderful

um water um management systems and and it was very very brittle and as soon as they had a drought or a flood then it like it they didn't have water you know and then people literally just died from dehydration so and the other thing from a car perspective right we can look at it at many scales me driving my car independently

doesn't do much in terms of pollution right it's not really measurable in terms of the scale of of the earth's biosphere but everybody driving their cars has absolutely a measurable impact thank you all so much see you next time i've got another peace jeff frank you want to bring up anything


SPEAKER_03:
Last point on kind of the friction.

I mean, considering friction as energy that is used, that becomes converted to entropy and not like to work.

If we consider statistical work to be improvements in accuracy,

and then the entropy is just the variance estimator which could be overfit or it could be inflated so then it's like if a new observation comes in the sort of um 100 efficiency motor

It would take in one calorie of energy and it would translate it to one calorie of moving the car forward.

So that'd be 100% efficiency.

It wouldn't change the temperature of the environment at all.

Whereas if you just burnt the calorie, the car would go nowhere and you would have released one calorie perfectly as heat.

So there's probably some connections there with the information content of what the model is ingesting.

And then it's like, is that information getting like cleanly burnt into the best possible accuracy improvement?

Or is it just being like thrown away?

but then it's like what would it mean to throw it away like if it just what didn't pay attention to the new data point and it just deleted the file in the real world that would change the heat balance in the real world because of like the energy and and um information equivalences but I don't know if that's exactly the right angle there okay well

August is gone, almost.

If you return at this time next week, it'll be Chapter 8.

Oh, let's see.

This time next week, yeah, Chapter 8, Part 2, which everyone's welcome to join.

Otherwise, there'll be another three, and then we are on with it.

But any last...

comments or questions?


SPEAKER_04:
No, just saying, yeah, just thank you and see you next time.


SPEAKER_03:
Cool.

Thank you, Frank.

Yeah, thank you.

Yeah.


SPEAKER_04:
Thanks a lot, Daniel.

Bye.

Talk to you soon.

Bye-bye.