SPEAKER_01:
All right, welcome.

Thank you everyone for joining.

It is the first early session for cohort seven in this second phase of activity.

So anybody who wants to sort of just check in with

uh that i guess we could have done that before starting recording we just want to check in where are we at in this cohort as we head into the second half of this textbook in people's view or what would they like to do for this phase of activity for the kind of second half for this cohort and then we will turn to chapter six

Maybe Ali, and then anyone else who wants to raise their hand or just go for it.


SPEAKER_05:
Okay, so chapter six actually marks the beginning of the second part of the textbook.

As we probably already know, the book organized into two different chapters.

parts.

So part one is mainly theoretical, and part two basically deals with more practical applications of active inference.

So

As we saw in the first part of the textbook, the theoretical foundation of active inference is actually a work in progress.

So it's not something that that has been

completed in order to be applied as a kind of comprehensive modeling tool.

But at the same time, the second part of the textbook provides a very promising roadmaps to and towards how we can apply even these tentative

foundational work in order to build some real world models of the intelligent agents or cognitive agents.

So I think that's important to keep that in mind because in many textbook groups, I've seen people somehow raise this issue as to, well, it's not

as comprehensive as we thought as a modeling tool.

So since the publication of this book, obviously, active inference research has progressed a lot.

But even the theoretical foundations provided in the first part of the book, I believe, provides enough material to

at least build some toy models that can capture some of the real world elements of real, real world agents, or at least cognitive agents.


SPEAKER_01:
Thank you, Ali.

Great.

Anyone else want to share where they're at as in this as we head into this part of the textbook?


SPEAKER_06:
Yes.

So I think I would like to say that I missed the first half of this

uh group uh so i'm asking a question which belongs to chapter two i think or chapter three i don't know um and so my apologies for that and i don't want to hijack uh the discussion here uh and i've put my question also in the in the chat but basically comes down to um having understood the role of bias in

um active inference as having a dual role which is one kind of the intuitive role for me at least being vaguely familiar with patients inference is you know encoding prior beliefs

and also um having a kind of indicator rule of encoding preferences and i think this comes out of a discussion of oculomotor

behavior as well as other things and I was just wondering if you have discussed this at all and if I've yeah if a brief comment on this would be great but if you say well you should have you know attended the previous sessions and I'm fully happy with that as well and I will just tag along for the ride for now


SPEAKER_01:
Yes.

There's a slide in this point raised in this paper that points to

prior being used as a um preference to drive pragmatic behavior in lieu of for example what a reward function does for reinforcement learning because when things are framed in terms of likelihood directly rather than projecting onto a explicit reward or utility uh function only just working with a base joint distribution

um then the prior it can be seen as preference constraint so it's like the preference for blood sugar has a different connotation and and um function and everything than one's felt psychological preference for something or revealed or stated preference but um

at least um from a modeling perspective it's more similar than not okay so i'll i'll have a look at those resources thanks sorry okay jerry


SPEAKER_02:
Yeah, I think as we're going into at least my area of interest and my questions are, you know, based in my field of work, which is marketing and communications and just how to apply this to, you know, consumer behavior, you know, to actually build some models that use these principles and these frameworks so that we can have replicable studies within this type of a field.


SPEAKER_01:
Great.

Well, chapter six is a great place for that because it is a recipe set of questions with more in common than with just general statistical experiment planning and systems engineering and systems modeling broadly with a connection

In specific ways to get to the kind of generative models that are described in basically chapter four.

And there's a lot of distance between where the this current text from 2022 will get you and the code running in your hands.

uh but that's a ground that is also rapidly being more traversable too and uh and so building out examples so that they're specific uh just you know there's there's a big gap there but that is it represents um in in a sense just how many degrees of freedom there really are in probabilistic modeling


SPEAKER_02:
Yep, that makes sense.

And so yeah, I'm excited to dig into it.

It definitely seems like it's an area that is ready to be explored.


SPEAKER_01:
Cool.

So I wanted to share this one little experiment.

This is from earlier today.

It's linked in the chapter six page.

So I took the text of chapter six, just plain text, put it into this plain text repo, used cursor IDE to restructure it and obsidian link it

So now here it is with probably some light edits, but has these links out to all these other topics.

also this repo, you can just put a new file and say, write a POMDP type model for this because it has this whole knowledge scaffold that we can also all contribute to.

So I think as the years and the application niche changes,

The textbook in chapter six, like Ali said, it will always be interesting to consider how it's like, oh, yeah, just these matrices alone are kind of like a good representation of modeling this or that.

all the way on through however that gets friction and a lot of degrees of freedom in application when there are a few standardized open source methods and it's unclear how to necessarily implement just an equation into an actual program

Or there can be multiple, it just like, oh, why is there not just one KL divergence function?

Or like, why don't we just have a variational free energy function?

Sometimes it gets very data format specific, computational environment specific, MATLAB, Julia, all these like things that come up in the application.

So I think that's one of the biggest changes between 2022, as some will remember in terms of like, we'll think, okay, before RxInfer, PyMDP, MATLAB, now better augmented coding and knowledge engineering tools, code generation tools.

helping with some of that, especially if we can collaborate, I believe, and have some people working with these code and program synthesis approaches to the structure learning and kind of sketching out more of the tech tree of the spaces of generating different aspects of specific

generative modeling passages and then also people who are just like wanting to model or do inquiry into a specific like yeah do there have more squirrel crossing the bike path on tuesday those kinds of uh test experiments so um but

this is the application part it's almost like the textbook coming back to domain uh even though that kind of happens in chapter five to an extent so i hope that in this phase for what we can uh

possibly return to some of the code questions that have come up over the years like having code examples for um you know chapter seven and chapter eight uh

Some of which we already have more advanced things open source.

So it'd be a subsetting, not like a making, but also these things just from being specified can be made very quickly to a first pass.

So if we want to develop the code and also the questions around going through application,

that would be really useful.


SPEAKER_04:
Maybe I could share my project that I'm working on and then where it comes up relevant.

I'm Andrus from Lithuania, Andrus Kulikauskas.


SPEAKER_01:
Does anyone want to start with a specific question about chapter six or the book first?

And then let's do projects, but not...

begin with it.

Thank you, Edris.

what should we really do in synchronous and asynchronous for the textbook the 2022 textbook is a great artifact to understand and learn from i mean any section or any question can be useful um though really i am i just nice nice drawing


SPEAKER_02:
Daniel, at least if we're just asking questions there, like the one up there about affordances is always of interest to me as well as, you know, maybe how like variational scripting might come into play if that's applicable as well.

Yeah, what about it?

I mean, I think at least from my perspective, there was some stuff I'd read around creating fields of affordances, which I felt kind of tied from a consumerism perspective to how brands go out to market, for instance.

And so maybe the question is more around like not just affordance generally, but that idea of like how do organisms in this model or how would we test

how agents select between the field of importance is through those either i don't know if that's through policy selection there that's my assumption but um you know still newer to thinking through this from a like actual application perspective does anyone want to say something to that


SPEAKER_01:
Okay.

the first question in the four question recipe here is what system are we modeling?

And then if we were thinking about an individual mouse in a T maze, like what's gonna come up in chapter seven in discrete time, it's like, okay, are we gonna model it with four locations starting left, right and down?

Or are we gonna model its footsteps?

So if you model footsteps, then there's going to be the explicit, you can have some data structure that represents the footsteps location, like data about it and or simulated distributions about it.

But if you're going to just say, well,

It's not a footstep modeling project.

It's just a location for state, which is what's going to happen in Chapter 7.

So just from this sort of applied angle, which system are we modeling?

And that kind of reflects the earlier comment about this having more in common, especially early in this process with systems modeling and systems engineering.

it's just like okay the organism is a very complex locus person at a game machine or something but but um like the complexity of how hormones interact with uh

you know, sound and all this or something or microbiome.

Those are all part of the real environment slash situation slash system.

But you might be able to get away with a three by three matrix for just three states of vigilance, low, medium, high because those kinds of modeling

That's just all models, map territory, all those kinds of topics that come back.

It's a model of this.

It's an inferred parameter.

It's a risk factor for X, or it's just a mutual information estimate percentile on this in our model.

So that's why this whole process where chapter six actually gets one isn't necessarily some gestalt paradigm shift on their modeling view per se that you couldn't necessarily also have from doing a regular generalized linear modeling.

Which can also be very sophisticated and deal with higher order variance and causal relations.

It's kind of like generalized probabilistic modeling combined with cognitive systems approaches to systems engineering.


SPEAKER_02:
Okay.

Yeah, that makes sense.

And the footstep model, when you brought that up, I think that kind of resonates for me because we'll talk a lot about customer journeys.

And one thing I've been thinking about is just using the term consumerism.

I don't know that we think about it the right way in my industry and so I've been looking to biology a little bit for a better analogy and so like predatory behavior for instance like the process of identifying and detecting and consuming and then processing something I think is an interesting corollary to what we probably ought to be doing when we talk about

you know, communication and purchase and stuff like that.

So that's, that's interesting and helpful.

And maybe that's something I can dig a little bit more into is that idea of more modeling footsteps versus locations, which I think we tend to try to model the end the location when we ought to be modeling like the steps towards that.


SPEAKER_01:
Yeah.

So the hierarchical models, at least in principle, which is kind of where the second half of the textbook goes, is where you have slower inference models and then faster ones.

And then it's just a project or situation specific empirical question about how much compute and what kinds of specific models you're going to make.

So let's continue on as people if they want to bring in their, you know, how they're seeing that or some other section of the of six, or we can go to the questions, but just

Again, this first question is like, okay, you're modeling everything about the biometrics of the person or just this?

Those are such different questions.

But those are questions that are also just dealt with every day in animal behavior, cognitive modeling.

Okay, but here's where we start getting more into some of the technical analytical details of the structure of these models that relate to making some more committed modeling decisions.

Not just agreeing that, okay, we're just interested in this question about this system of interest.

So the next three questions are the three practical challenges.

These can be specified.

They go into more detail in chapter six.

And there's more sort of links and guides and experiences people can share and just try and explore.

through, but basically it's like keeping in mind that the textbook here uses generative model to describe the agent

type uh unit and the generative process to be the environment um whereas also generative model it can be used just to be the total um model specification basically the three areas of questions are how do you want to deal with time um model it discreetly

Or in continuous time?

These are questions common to other time series modeling approaches.

Even if you choose continuous time, how will time discretization, will that matter for your data or for your compute?

What is going to be the structure in hierarchy?

laterality like just message passing is it just like are you modeling one abstract decision maker making one sequential response to one input data just as an intuition pump or is it doing like this data to here and wanting this output so that's just sort of the um getting to specifics about the model structure

which can again just be either specified uh from simplicity like just be often the models are just a single uh pomdp partially observable markov decision process

and that that um can't necessarily be directly picked up to work on a large data set or something like that but for certain purposes it might be all the research question needs at that stage but um again that's kind of a separating like okay we know the systems have hierarchical depth

So which parts of multi-scale complexity are modeled?

So that's just a common modeling question.

And then what is the time?

How do these different agent or generative model specifications themselves deal with time?

So just some things that come up, but these are more in common with, at this point, like statistical modeling, causal inference, machine learning, AI, also these kinds of questions would come up.

Here is where it starts to get more into some of the,

Bayesian degrees of freedom of modeling.

Like, are you going to model a parameter as just fixed, like a spike in the probability space, like not learnable?

You know, how learnable, how variable?

And what are you going to do with how you specify and update and fix how learnable and how variable?

Are you just going to say from this previous study, we know the variance of this trait to be 10?

So we just fix the variance at 10 or we learned it.

But...

you know if everything is learnable there's just the looms a greater problem just like in uh uh reward learning when when they get into meta learning and all this how learning how fast to learn to learn that all this sort of things is um i mean the larger the state space and learnability of the the

of the kind of target model, you make an optimization challenge by making it so open-ended by dealing with large data, by dealing with complex data,

maybe there are some structures of probabilistic models that have excellent computational performance on certain situations but that's a hope and a preference and uh is not the case that that that uh

You know, any given probabilistic model would be performant in any given way on any given dataset.

However, there might be some that are really, really effective or the huge families that are adequate for certain processes.

But we're getting into statistical modeling

So it's kind of from coming to this from an empirical perspective,

biology behavioral modeling perspective and seeing how mostly here we're just talking about how some this could be said and probably many parts are said across different cognitive and behavioral modeling work

But it's working within a specific probabilistic modeling framework that has connections to the free energy principle sort of path of least action approach coming from the high road.

Chapter six sort of brings us back to the low road and building up the specific systems that

also have the extension into the implementation methods at least uh some as we sort of explored a little earlier but it um getting from the uh

questions about the specific system to the probability distributions and families and models that meet up in the middle with the sort of high road approach.

is basically where chapter six is.

But there's no it's like, these questions are all common to statistical modeling efforts.

And there's other things I'm sure people here to could add of just the sort of heuristics and pitfalls and important questions for interpretation of complex systems modeling.

Another sort of, I mean, another, uh, practical question is like, um, where, what is the, what, there's different ways to do projects and, and research and everything, but does someone want to just imagine a model where there's a 10 time horizon and a five of this, and it takes in this data, it's like, is it just being sketched as part of the thinking?

process or is this wanting to be used for doing statistical modeling?

Because the sometimes there's moves that are possible in just sort of drawing connections on paper that might be very there's that might be like hard within current implementation approaches.

So in the examples of the code, we kind of are building out specific motifs that are useful.

But the way that people are thinking about systems is often very nuanced.

And so I mean, I hope people can in the second

uh phase here like let let uh figure out how to make it useful also just discuss what do we really want to do with these meetings with recorded and unrecorded part because we we can figure out other um other ways to have our shared attention and work i don't want to uh feel like

Returning to this and just rerecording, going back to the same, if that's not the most useful format.


UNKNOWN:
Thank you.


SPEAKER_03:
to kind of break to that to kind of break the silence here i'm not really sure because like what um what what do you usually do like what is your usual um mode of like navigating uh the second half of the book like the practical part of the book

um like for instance someone uh like i think andreas was about to sorry i was about to talk about his project i think hearing about uh like the projects that people are working on like how they're implementing all this stuff that would definitely be sorry that would definitely be interesting for me um also for my own project like i don't

have anything specific yet before the coming meetings i think it would definitely be interesting to um to discuss the specifics of that but i'm not sure what other things you you would yourself suggest daniel or like what has worked for uh previous previous meetings but that would be interesting for me


SPEAKER_01:
thank you yes okay we can return that's a good suggestion for andreas um in terms of what has been useful people can look through the previous chapter six uh meetings but i i think what would be very useful is to uh

connect specific questions and ideas that people have two segments of the text, if only as an exercise in anchoring and and scaffolding off of the 2022 text, maybe just as a jumping off point in moving to other resources.

Then

uh working through these questions and figuring out what other questions they asked along the way to get to where they wanted to go with a probabilistic model that that they um

could share back and connect to implementations tables that we have to the textbook examples.

So sort of

If we want to make models and given domains, let's make them over these coming months according to this recipe and or making our own, but at least taking this recipe seriously or even as a subset of things that we do.

Andreas, how about just go for your question?

Let's see where it goes.


SPEAKER_04:
Yeah.

So to introduce myself, I'm Andris Kulikowskas from Lithuania.

I learned about active inference a year ago from Daniel, and I've had many conversations with him.

I've read the first six chapters, and so I'm attending at this time.

every week uh and so what i'm interested in modeling um i'll say generally and then specifically generally i have this uh i've been documenting my own experience uh as a conceptual language and so i'm uh one way that comes out is like i feel like i live my life through three minds there's an answering mind a questioning mind and investigating mind so like if i raise my hand

there's me that knows what to do.

And I just tell myself to raise it.

I don't have to think very much about how it's being raised or where it's being raised.

So and similarly, like there's all kinds of answers that come into my head.

So that's the unconscious, these answers.

And then

I have another part of my mind that's this chattering language, words or concepts, but I think of them as questions.

So when I think of the word horse, it's really a placeholder for what the answering mind might tell me as a horse.

And so I have this conceptual language.

And then I have this fledged consciousness, which I call the investigating mind, willful, cognizant, deliberate, which basically tries to...

line up the other two because it's the same information in two different forms so the unconscious knows all these things the unconscious doesn't know them and so can have the information the two and then like with condiments okay

i apologize can you hear me yeah continue on so i was talking about this investigatory mind which aligns the earth to what we know what we don't know and then like with daniel kahneman's thinking fast thinking slow

it's able to decide, hey, here, I should just think fast.

And where he is here, I should think rationally, you know, so go with my intuition or should go rationally.

I'm trying to model that.

So specifically, how could I model, especially, and I think there's a language for each of those.

So there's a language of how things come to matter for the unconscious.

There's a language of how meaning arises, like verbalization for the conscious.

And there's a language for how.


SPEAKER_01:
Okay.

Not sure if his connection staple.


SPEAKER_02:
Yeah, Danny, to the last part he was talking about, I think I have a question to maybe tack on to that about like when he's talking about system one system too.

Does that in some way tie to like how we would try to model novelty versus habit?

In terms of like.

You know, it's something I've been thinking about as well.

Like a lot of behavior that we notice in my field is habit.

But we're trying to catch attention, I think, through novelty to train something new in there.


SPEAKER_01:
Yeah, like, to that, and also a little bit about between habit and deliberation, which Andrews, I hope, will start to get at some of these points that we can continue to work on and develop in.

here in chapter five so not to go back but um chapter five reviews the some of the key model motifs from the mammalian neuroanatomy cognitive modeling literature um studying people's brains that being where friston and others have focused a lot of their work

um so as sort of like well this is sort of what it looks like to study a complex system uh like the brain on this so here are two different um extrema modes of how policy priors like how apt one is to do something before receiving the next observation and uh policy inference

getting to a policy posterior which action is sampled from.

So it's like the differencing of what was apt to happen before to what was apt to happen after for action.

And these are the distributions that are calculated during policy inference, planning as inference, actually implementing planning agents.

You will have one or the other.

Or a modulated blend of these, as it turns out to be for the brain, for policy inference.

On the left is a habit pass-through mode, which is like cached action preferences, which can be conditionally modified.

set.

On the right is the expected free energy calculation, which is discussed more in the first half of the book.

And we can look at implementations in PMDP or in other implementations in this phase of activity.

But this is where specific counterfactual policies

of a given temporal horizon are rolled out like policy tree search and evaluated in terms of expected free energy or free energy, the expected future.

So explicit policy rollout, reweighted energy based learning, consideration of epistemic plus pragmatic value of policies

large computational blow-up just like any other tree-based policy search.

So that's where secondary heuristics like boundary searches and policy switching and things like that come into play for making these models large.

But often, again, it's only a simple one with four policies being considered or something or 16 policies being considered.

But this has that sort of multi-computatoric computational complexity if explicit probabilistic, to the extent explicit probabilistic rollouts are used.

And then on the left is like basically just a pass through.

So broadly, that connects to the thinking fast and slow.

I think some papers have made some points, but it's just sort of a

it's a functional stratification in cognitive systems that and then that is being here modeled by one switching parameter map in the territory all that it's like could there be two switching parameters but that's the whole experimental biology question


SPEAKER_04:
And I would jump in to say like with marketing, there's very much the opportunity like you can sell to somebody's reflexes or you can sell to somebody's rationality.

And if you're a buyer, you know, you kind of want to have both satisfied.

You want to feel good instinctively and you want to feel good in terms of, you know, the rational judgment.

And so I apologize for my bad connection, but I wanted to say What I want to model specifically I think would be This language of how things come to have meaning which is relevant for the rational mind So because the mind that just works instinctively it just doesn't need to know all these things But once you introduce this second rational mind it needs to think both what you know has to kind of be aware of both ways and kind of do its best with this other mind and

So I thought, well, mathematics is something where things don't really matter, but the meaning arises all the time.

And I thought I would look in particular to a very narrow field, which would be triangle geometry.

And it turns out in that field, there's an encyclopedia of triangle centers.

And basically, like everything interesting about triangles is basically like a center of a circle.

So you can build that center of a triangle, so to speak, in triangles.

60,000 different ways.

But to focus on the very simplest way, if you put a circle in a triangle, it doesn't matter what the shape of the triangle is, but if you expand it to the maximum size,

there will be three points that it intersects, that it touches on the triangle.

And the property will be because the radius of the circle is fixed that from the center of the circle, it will be equally positioned, you know, distance wise to each of those three touching points.

So that's called the in circle.

So one way is to try to imagine these two minds as communicating that problem.

So the unconscious mind, I kind of imagine it places the circle in the triangle.

You know, you're giving a random triangle and you're kind of like blind.

So the unconscious mind places a circle in the triangle and it's allowed to expand the circle until it touches something and it has to stop.

mathematically it'll only touch one side basically like probabilistically it's impossible to touch more than one side at a time and then the conscious mind will say okay I want you to move but let's say it can't it can give an instruction to move but the motion will be random in some random direction so

or I guess it has to move away from the line.

It only has one direction.

If it doesn't want to, it has to move away from the line.

So it just moves away from the line at a certain speed, let's say that's based on the radius, proportional to the radius.

and then it will the conscious mind tells it how far to move like how many radii to move or more like percentage of radio and then it can expand again it knows how to expand the unconscious mind and it'll bump into something else maybe the same side maybe another side and so through this iterative process at a certain point it will have less and less room to move it'll never know what side it's bumping into because it doesn't have that information

but it'll just know that it's starting to bump in very often on you know which would presume that it's being closed in and so then the idea is that once you get within whatever accuracy you want because it never touches all three sides at once it only touches one side at a time um realistically but um

When you get within 1% or whatever you want, they say, okay, I'm happy, I'll stop.

And so then you can ask, for example, well, what can you deduce about the shape of the triangle based on the interactions that you had blind like this?

You can also have like a learning process, you know, then you can maybe compare that with the original triangle.

You can maybe also have a learning process where

the conscious part that decides um how far to go like how to how far how far to move this um it can um different policies can yield different results so it can maybe try to learn that so i don't know if that was like my initial attempt to try to come up with a way of thinking about this language and seeing like how active inference could kind of help to apply it


SPEAKER_02:
Yeah, at least I think that's interesting what you were saying.

And there's some stuff I was reading by Michael Levin around like an axis of persuasion with

different nested levels of intelligence that's kind of interesting to me that I think touches on what you're saying about different, I guess, lower levels of the system learning something and sending a signal out globally when there's some sort of an error.

But I've been thinking about that, those levels of persuasion, because I think it speaks to, from a communication perspective, the way that we communicate, we do it

Through unconscious associations, we do it more rationally.

We do it emotively from a cultural perspective.

But like, you know, I think when it's most effective, it's across all of those levels or that axis of persuasion that he's kind of talking about.


SPEAKER_01:
so is there such a thing as one of these models that's so simple it could be coded from a blank sheet of paper in i guess five minutes yes that's what the textbook level focuses on the textbook version is just five matrices with it in chapter seven that's what this is what you build up to

It's just starting from dynamic perception models, partially observable models, observations coming in.

This could be a single binary variable.

This could be a three-state variable.

This could be a continuous variable.

That's the work of modeling.

But then you have a hidden or latent state.

Temperature in the room, temperature on the thermometer.

mapping matrix, initial prior to kick the chain off, transition matrix.

Then that's equivalent to a Kalman filter like modeling.

Then you add in some element of policy selection.

is it just a binary uh with two fixed outcomes or do you want to model this or that uh conditionality or learning or or or uh affordance is state state space changing but you know those are sort of

Those are structures of models, families of models that you may on your intuition or fun or whatever, seek to just work within a given model family just because or not realize that you're within a given constraint.

But it's just what is it?

Is it just being analytically just here's like the space of all possible policies of the organism?

And I'm about to make a philosophical point.

or we chose to just model the blood sugar not engaging with other biomarkers but this is these are the matrices and the variables that you get to a b c d well i i'd sort of like to see this implemented in code uh is that available

yeah great question that's um again that's what chapter six gets to and I'll just link I I know it's in the textbook group um this is a table of of implementations if people want to add and curate more it would be awesome there's always uh

a lot we can add with these repos.

And if you get these are people who want to contribute open source resources, and or review them and annotate them.

with um like what features they have like which ones have planning which ones use this or that uh which ones have this coffee I just want like a really really simple one that you can figure out what it's doing by inspection yeah


SPEAKER_04:
Doesn't doesn't appendix C mention like the T thing that you were talking about the teammates?

Is there a code for that?


SPEAKER_01:
There is MATLAB code for that.

It's in the appendix C, but we haven't in a prior textbook group, ported it.

If people would like to work on that,

in the times between meetings and get it working or just share where they got to.

That could be awesome.

But making POMDP models and using expected free energy and variational free energy in the implementations and in this Subsidian repo, in the cognitive repo,

It's just POMDPs with VFE and EFE.

Also, this is the slide from the three Ps.

a distinct role for the distribution.

This is the same underlying prior distribution.

So if we were modeling like we're interested in the movement data of thermophilic bacteria, so we're modeling the distribution of their location with respect to some fixed wall.

So we're going to have some distribution for their location.

It is, in the first frame, the probability of their existing at that location at that measured time.

It's a latent distribution, smooth, analytically approximatable, et cetera, variational distribution, implementable with software tools for their location.

It is also from the cognitive behavioral bacterial side as their preference, like our expected pragmatic homeostatic firstness and tendency of certain variables to return to attractor states.

and it's the fitness in that it's the ecological sampling availability constituting differential persistence phenotypically or genotypically.

But that just, it's just, that's one, it's like we're doing a Poisson distribution from the wall.

Any closing comments?

If people want to think about what will make this early time slot in its alternating next week at this earlier time slot, we will go to chapter two.

So if people want to just stay at the same time, continuing in this way, we've done it or just

Do people have certain amounts of time they want to set aside or certain milestones they want to reach?

But then, I mean, I want it to be useful.

We can make generative guides and material

absurdly with people's feedback and help if they want to make certain kinds of models so it'd be it would be awesome to work on that um but if people have some other uh preference for for what would be good

Given that we all are here for this time, let's figure out.

So just like email or at the next meeting, add a note or we'll discuss it.


SPEAKER_00:
I'd just like to say I think some more like coding workshop type elements would be good.


SPEAKER_01:
Yeah, I totally agree.


SPEAKER_04:
I'll be trying to code what I'm doing.

So, and I'm interested to talk with others about, you know, how they code.


SPEAKER_01:
Yeah.

It's like the low road is like the show me the code road.

High road is like some is analytical, um, symbolic and analytical and axiomatic.

uh then sort of qualitative philosophical stances are included in that sort of combination and uh i think we can we can have some cool code models please just surface whichever uh desiderata you see and

Let's do it.


SPEAKER_04:
So I wanted to thank for the time.

I apologize for my connection.

And just to say, like, what I learned was that like, what am I trying to predict?

I'm predicting where I think the center of the triangle is.

And so when I move the circle from the edge, I have to make a prediction how far to move it.

And that prediction could be wrong, you know, and I get feedback from the perimeter of the circle.

So it's a conversation between the predictions for the center of the circle and then the feedback that you get from the boundary of the circle.

That's getting closer to, I think.

So, and I guess for active inference, you really need to understand, like, prediction error.

Like, what is the prediction?

What's the source of the error?


SPEAKER_00:
Just a random point about this circle triangle thing.

Wouldn't you want to, after it hits the wall, wouldn't you want to grow it in a particular direction rather than move it in a particular direction?


SPEAKER_04:
Well, I want to have that dialogue.

So the two steps are you can move, you can grow.

So the unconscious mind only knows how to execute this.

And it knows when it hits something, but it doesn't know anything really.

So this blind conscious mind has to have this communication.

That's what I want to model.


SPEAKER_00:
Might it be better to have grow from the center and grow in a particular direction?


SPEAKER_04:
Well, the point is that you don't know where the center is.

You're trying to find the center.

You're randomly inserted.


SPEAKER_00:
Wait, I thought you knew the center of the circle, just not the triangle.


SPEAKER_04:
Oh, the center of the circle, you know, right.

So you can only expand.

You can grow larger.


SPEAKER_00:
But you can also grow a circle in a single direction rather than from the center of the circle.

And I think that would be a faster implementation of what you're doing.


SPEAKER_04:
Yeah, I'm not trying to do it faster.

I'm trying to do it slower, so stupider.

Like, what's the stupidest implementation?

That's what I'm trying to do.

Most stupid and revealing.

Thanks, though.


SPEAKER_01:
Okay, thank you.

Bye.