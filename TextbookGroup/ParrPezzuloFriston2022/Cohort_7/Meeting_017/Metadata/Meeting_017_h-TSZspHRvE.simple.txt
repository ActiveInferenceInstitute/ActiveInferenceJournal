SPEAKER_02:
Welcome, fellows.

We're in the second discussion on Chapter 9 for Cohort 7.

So we could go to any part of Chapter 9 or jump in wherever you prefer.

What about the provocative first sentence?

Ultimately the models described in this book are only useful if they can answer scientific questions.


SPEAKER_00:
Yeah, I liked this whole chapter because of its... Well, because of the way that it inverts everything for the sake of applying this to science.

I think that it's interesting, the cognizance of it all, to realize, like, maybe what's been done so far is helpful as a model, but that doesn't really...

That's not the same as, let's say, a scientific, I guess, result.

And so, but to turn it around and say it is quite impressive if you can do it backwards so that if you can, if I understood this correctly,

if you can suppose that there's this model in a subject or maybe a group of subjects and then you can um given that supposition then maybe figure out what the parameters should be um or what the what the results should be and then work back to say okay well if these are the results then what are the initial beliefs you know between different

participants in a population.

And then if you can do that, then it's interesting, oh, that you have a, you know, potentially a scientific explanation of how these different individuals in a population differ and why and to be able to show the helpfulness of the model and as explanatory, and then you can correlate that with other information.

So that's how what I took from this.


SPEAKER_02:
Yeah, great points.

It has a lot to do with what makes a scientific account like any, let alone a satisfying or useful one.

And what is the relationship between empirical observables

like the brute fact of the data points and inferred latent states like causal attributions or unobserved features which are derived from empirical data but derived from empirical data does a lot of work because you could derive in in so many different directions from empirical data you could say that this art piece was derived from the weather data

And there's so many degrees of freedom with what weather data you took and what art piece you resulted in that somebody else might not be able to look at it and know that you used weather data at all.


SPEAKER_01:
Right.

Now I'm interpreting this statement to mean, I'm interpreting answer scientific questions to mean

make testable predictions.

That may not be everyone's interpretation, but I always thought models are only useful if they can make testable predictions.


SPEAKER_02:
Yeah, that's a great point.

That's related to, like,

falsificationism and the idea that we create secondary hypotheses that could then be either assessed to be true or false under the logic, like if what you learned from the answer didn't give any derivative product that could be deemed to be more or less valid, it was kind of a dead end answer.

because it doesn't give any consequences.

And then testable predictions is like the empiricist way of framing it.

And that can even be framed in staying within the active ontology, like answering scientific questions means reducing uncertainty about the scientific question.


SPEAKER_01:
I like that.

Now, alternatively,

pointing at the first part of what you just said, it's still useful if we're moved forward in our investigations, even if it doesn't have explicitly testable predictions.

If we're still developing the field of inquiry, that's still valuable.


SPEAKER_00:
And when you say testable predictions, I think that that comes at it from both ends that are necessary in science, because you want to have things related to data that's observed.

So if there's no data involved and there's no observations involved, then

That's a funky science.

But then also you want to have a theory.

So you want to have a model that is meaningfully breaking down or decomposing or structuring

These variables are questions or ideas and so that you can look at relationships.

And so if you have the testable prediction, it means that you have it from both ends and then you can apply it to a wider scope.

You know, you can look at new examples, et cetera.

But I think in the case of this chapter, it's about predictions of predictions, which is very sophisticated because you're basically predicting.

um well that you can figure out what's in another organism's mind you know what they're predicting let's say and then and if you're if your prediction's correct you'll be able to do that for a whole variety of individuals to say well they're predicting these different things and you'll be able to confirm that and then so the confirmation can also happen on both levels that

you can do that for more and more individuals but given an individual you can also get better and better validation for like well what exactly is that uh belief or prediction that they're making um so it's sophisticated again pointing to the process nature the dynamic nature the approach yeah


SPEAKER_02:
And talking about it this way, with chapter nine being so grounded with empirical data, it's kind of like the mirror symmetry of the book.

Chapter one and 10 are like these overview chapters.

Chapter two is the low road.

So when we got on that on-ramp, it was about building the model and the joint distribution and Bayesian statistics.

And now we're kind of exiting on an empirical low road because it's again, reconnecting us back to the observations.

Like this is a setting that's very familiar to a behavioral scientist.

And even when a paper doesn't, like a behavioral science paper,

doesn't explicitly use these techniques doesn't use a palm dp doesn't calculate variational free energy still basically the setting of this meta bayesian um setup is there

Like here, it's the temperature and the humidity in the laboratory.

And the experimenter is playing sequences of videos, or they're presenting symbols on cards, which are observations for the subject.

And then they're receiving the action output of the subject.

And then this just does so much interesting work with the subjective

because it is both subjective to them and it's the subject of the behavioral experiment.

And it's like, this is what a laboratory is like.

And then this solid box is like the kind of the veil of unknowing for the behavioral scientist in terms of they can set up what's in the room,

They can pass the stimuli to the subject and they can observe what comes out with biometrics or with whatever kind of measure.

And then what's inside is proposed.

So this structure is a really parsimonious way to just look at the behavioral scientific setting.

And it turns out it has a lot of structural congruence with the metacognitive phenomenology, like an observer observing within an organism, but that goes into a kind of a different direction than this like more behavioral laboratory scientific

very practical and and this and this does get really practical and the by number or by citation count most of friston's papers may be this kind of like this many subjects were put into the fmri for this many minutes exposed to these stimuli here was the statistical power here were the the um here was how the experiment happened um

So this gets to the most practical statistical power calculation-like parts of doing behavioral science, which kind of, in the Skinnerian area, like B.F.

Skinner, without going too much into this, that's kind of the whole debate.

Does that deny minds?

Does behaviorism exclude minds?

and the the cover of the book told us that we were going to be in for mind brain and behavior and we saw a brain in chapter five with the difference neural systems chapter nine really goes after behavior because it's not making psychological assertions

Um, or, or, um, philosophical assertions.

So mind is obviously a, a really complex and rich area with the first person and the second and the third person, all these, and all these different traditions and our own, uh, firsthand experiences of mind.

Uh, but nine zeros in on behavior.

which in a way gives the least contentious of the three.

That statement might be contentious to some, but the neural accounts, somebody might think, well, with molecular reductionism and genetics and systems biology and deep learning, we're doing better than chapter five on brain accounts.

But in terms of the structure of the behavioral environment,

this is really like a gem tucked in at the end of the book.


SPEAKER_01:
I like that perspective.

There are many traditions that say reality is what happens.

That's behavior.


SPEAKER_00:
Well, and I think for this chapter, I don't know if I entirely agree, but maybe I don't understand, but with Daniel, because a lot of these examples at the end have to do with psychological analyses, like, let's say, hallucinations, right, or delusions, right?

So that's partly behavioral, but that's partly...

their internal models right like and and i think one of the challenges with these experiments just thinking about uh what it would be like to do one is that with active inference

in its full glory, it has two outcomes, you could be updating your environment, or you could be updating your belief.

So then if you're doing an experiment, you want to capture that, I think that'd be like the whole glory of it, you know, you have to be on top of two different channels, you know, the external like the the behavior to be able to record Oh, you know, behavior updated the environment, let's say, but you also want to be able to capture well, oh, here, they updated their belief.

So that already is kind of like a double thing.


SPEAKER_02:
I don't know if that's... Yeah, great, great points and challenging ones.

So yeah, from the first half of the book, we have this two ways to dissipate free energy with update behavior or update belief.

Now, from the behavioral researcher's perspective, everything coming out of that

box is observed behavior whether it's an eeg trace um or whether it's a self-report or whether it's a motor behavior so from the outside everything that we're observing is behavioral and basically everything that is internal is being modeled as a belief that doesn't mean that it's like a um propositionally held sentiment

but it's being modeled as a Bayesian belief, which undergoes updating.

So you're totally right that if we want the full active inference account, we do want to be able to describe both the updating of behavior, but this is the updating of observables.

So if we only wanted to describe behavioral updating, we could just do descriptive statistics on sequences of actions.

And there might be a situation where that's totally fine.

But as soon as the behavioral researcher starts to suppose some latent factor that wasn't behaviorally observed, but is abduced to be relevant for the generation of behavioral sequences, they do start to kind of swim upstream into

cognitive states, which do get into minds.

Like, that's where this where those examples in the table, basically go from, they're grounded in self report, or I secade, or decision or game theory games, or trust games.

And then latent states are proposed, which make their way kind of up the low road towards the psychological and the cognitive.


SPEAKER_00:
but maybe just to emphasize what I think is scientific about this chapter compared to what we've seen before.

If somebody comes up with a computer model using active inference principles to explain how a hand reaches out and manages to gracefully pick up a chess piece and move it, so that there's this

model of how the muscles gracefully uh relax or or tense up and they do all that that model is uh interesting could be very slick uh it could be it would be it's always impressive but it's not convincing that that's scientifically you know really relevant in a sense because there could be many kind of slick ways to model that there could be many biological processes that explain that but like what this chapter is uh

portraying, I think, or suggesting, it's saying, look, if you have, let's say, a group of individuals and you're able to model their behavior, but then you're able to show, look, some of these individuals are applying a different strategy, they're having different beliefs, they're getting different results, you know, because... See, so that's a very discrete difference.

You're able to say, like, in these cases, it's one way.

In these cases, it's another way.

So scientifically, like, that becomes...

For somebody like me, that's very convincing that, oh, that may well be the right explanation.

Maybe I'm gullible to things like that, but I find that more...


SPEAKER_02:
Yeah.

Like, let's just say we do the rat and the teammates, like the chapter seven experiments.

So if we just wanted to say, we run a hundred mice for a hundred replicates each.

So if we just wanted to say, okay, we're making a leaderboard, which one got the highest percentages?

We just have that raw data tabulatable from description.

Or if we wanted to say just a simple correlation between the temperature in the room and the success rate, which mice did better when it was hot?

These are still basically you take two observables.

We have the observable temperature, observable successes, and we just basically there's our answer.

So that sort of doesn't appeal to any latent variables.

But then, like you're saying, if we were going to want to go beyond, so then we said, well, how likely do we feel that the leaderboard would be the same on the next replicates or if the conditions changed?

Or we want to study transfer learning into a different setting.

That's where, I mean, why go through all this work of making it, specifying a generative model with cognitive states, doing model inversion to get error bars on unobservables when if we just have the observables, let's just tabulate them.

And so again, that goes to sort of the depth and type of scientific account that one seeks.

If we just want to

summarized observables this whole apparatus could be overkill like if we were just trying to say we just want to know which cars are breaking the speed limit it's just like okay it's going over the speed limit boom there's the rule-based observable but if you wanted to say we want to be inferring something about the attention level or the cognitive state of drivers mm-hmm

and maybe want to have one model that's just speed, one is just speed and exposition or something like, and they have whole portfolios of models, portfolios of cognitive states, noisy or patchy data.

So it's a much more flexible modeling situation to be able to go from a custom sensor array to a custom cognitive unobservable suites

and then treat those unobserved inferred variables as downstream as observations for a downstream process like this could be a risk factor but the but a risk factor is never going to be a measurable feature of the world there could be an observation that's a good proxy for risk or something like that

But any kind of summary statistic or risk estimator, there's just all kinds of stuff that seems pretty obvious to want.

Like which one of these buildings is gonna be most likely to have this happen?

But that will never be revealed from just munching the data from observables down.


SPEAKER_00:
But even like with a risk factor, like risk factor is generally not a satisfactory causal explanation.

Well, I mean, it's maybe helpful and practical in some ways, but if you really wanna know the cause, right?

Like there's usually something direct.

And I think what this is offering is to say that like if different individuals have or organisms have different generative models,


SPEAKER_02:
they're going to have different causes to their behavior yeah again to like what makes a scientific account what if we say well this person uh this building was a high risk of falling why did it fall it had a high risk of falling

It's like, well, that's not really an explanation.

That might be very useful that you were able to have a calibrated risk assessments or which one of these cars is likeliest to speed.

So that gets into the testable useful hypotheses, but it's kind of like, that's an account in the investigator's minds

a utility oriented account but that's not even being proposed to be an actual natural account of like why the building fell right which might relate to like the total gravitational load and like the supportive ability or something like that but the design the design and the materials right also i guess i think you point to why uh active inference crops up in so much of the embodied and active


SPEAKER_01:
mind literature whether the internal models are updated or inaction is the is what's being updated they can't be separated they they interact with each other yeah like the the moot or the trivial system is just behavioral


SPEAKER_02:
So then there's no need to abduce a latent state.

So it's kind of like it can't update beliefs.

It can only update its action.

Yeah.

But once you start getting into anything, another important piece is the introduction of the Bayesian approach.

So if we do the mice studies and like 75% of them succeed.

And you say, well, what's your best estimate on mice succeeding?

Not how many mice succeeded in your experiment, but what is your best estimate on mice succeeding in this, if you were to run it next week, or if you were to have another student run it or something like that, the frequentist answer is 75.

You know, we flipped the coin 75, a hundred times, we got 75 heads.

So our best estimate is 75.

And that's like the maximum likelihood estimator.

Whereas with Bayesian statistics, we might have like a meta analysis of similar studies and say like, we have a pretty strong belief that it's about 50%.

So then on a given day, when we get a run and it gets 75 with attention,

full attention to the experimental results, we could say, we now believe that it is 75.

We believe the situation is rapidly changing and that now mice solve it 75% of the time.

Or we can say, this is just this many sigma.

It's a three sigma event.

One in 700 times, we expect to see that.

We have now seen it one in 700 times and we're not updating from 0.5 at all.


SPEAKER_00:
Mm-hmm.


SPEAKER_02:
Or it could be anywhere in between with like, yep, now our best posterior estimate is 52%.

So that's the part of this whole work of specifying the Bayes graph and doing this bidirectionality of like generating synthetic data or receiving empirical data is so that we can explicitly include a prior belief term

Because the, just the munch, the description, you know, munch, the data style describe the observations.

You don't really get a chance to include your prior.

Whereas Bayesian statistics is basically just including your prior as an observable or the analyst, and then, then making choices about how much to wait the prior.

versus the data coming in, which again is that kind of reflexive element because it's like, oh yeah, how much, how precision waiting on how much to do prior updating given the observation is the Bayesian statistics question.

And descriptive statistics,

lends itself you know not not not to weld things together too tightly but that lends itself to the p-value accept or reject falsification whereas the bayesian epistemology and and there's many like writings and explorations of this lends itself to more this continuous probability space updating style it's like well is the sun gonna rise tomorrow or not you know whatever will we come to see the sun tomorrow

And the frequentist could just say, yes, or I failed to reject that it didn't.

It's like all those kinds of expressions, as opposed to just having a very high posterior belief.

And you could make a Bayesian model that does give a discrete answer.

But if you don't constrain it that way, it's going to stay in the continuous probability spaces.

which have more agility.

Because it's like, okay, well, we shut the door on that hypothesis.

It was falsified.

But then part of the sometimes fallacious nature of the frequentist test is you're presented with two hypotheses and then either there's a rejection or a failure to reject one

And then the failure to reject is not the same as the acceptance.

And the rejection of one isn't the same as the acceptance of the other, because it can all be down this super contrived sequence of assumptions.

So it could be like, we tested to see whether eating eggs made a difference in cholesterol.

At this p-value, we didn't reject the null that it didn't.

But that's like, I don't know if it's like the contrapositive or something like that, but it's not the same as saying that it doesn't.

It's just saying that that study wasn't powered or sensitized to detect the rejection, which has a huge overlapping territory with it actually not.

making a difference.

So all of this is kind of like in practice, they might all give the same results.

If you're just testing for the difference in temperature between two rooms and the difference is big enough and clean enough, probably a huge number of methods are gonna get you the right actionable information.

But this is getting towards a more sophisticated accounting

that helps us embody all of these nuances that do come into play.


SPEAKER_01:
This brings us back to the great power necessitating careful model construction.

Sort of like in our other session,

It'd be worthwhile.

I'm looking for a course on modeling, the philosophy of models.


SPEAKER_00:
Well, I would talk about the model I'm thinking of.

This chapter kind of provoked me to think about, because I like to model human experience.

I've been working on that for decades.

And so our active inference is attractive.

and um but and so active interest is quite universal but but maybe not completely so an example of the type of problem i thought i would do i would like to know what are the languages by which for a human being things come to matter or let's say a language for how does meaning arise or how does a person

believe like an event happened.

I think that there's maybe some basic cognitive language for that.

So I needed data for that.

So the data I thought I would study is

triangle geometry that you can have triangles of different shapes and then you have these concepts of triangle centers which could be the simplest one is what's called an in-center you draw a circle inside a triangle and you make the circle as big as possible the center of that circle will be called the in-center of the triangle but you could do it with a center on the outside and there's all these

ways that you could make points given a triangle like you know you look at the medians you you intersect them things so but there's not that many ways and i suspect if you if i study that and there's an encyclopedia of triangle centers and if you study how it builds it builds a language a language like this or maybe any language will probably have six underlying actions uh which relates to let's say six cases uh daniel gave a um

talk about cases in language, let's say.

So something like that, these type of prepositional ways of thinking that nouns are, let's say, used in a language like Lithuanian or Russian or so on, or Latin.

So the point being that, okay, as far as active inference goes, it's kind of interesting that

it's possible to think of there is this kind of a coordination between two types of action.

One is, let's say, a physical continuous action like making a circle bigger.

The other one is saying there's like a conceptual point to say, I want to have a center of a circle.

So you do actions like you make a circle bigger.

It's not positioned well.

You kind of bump it over.

You keep doing it.

You would do a chain of actions.

You end up with something like that's a center.

Let's say that could make sense for a generative model saying this circle needs a center.

that i could focus on and maybe you can redo it for different triangle shapes um and do different types of triangles you get this whole kind of activity for language the problem with that based on this chapter is that yeah but is that ever going to be science you see like is that is that ever going to solve a scientific issue because you're just um studying um

you know, these triangles, it's not, in a certain sense, it's not really data from the real world in terms of experimental data.

On the other hand, it kind of is because you have this whole, you know, encyclopedia of triangle centers people came up with.

What does active inference say about an encyclopedia like that?

Like how to make sense of it?

Like, so if there was a modeling language or approach that could go into that data and say, hey, this is how to, this is what to do to understand it as a language.

Now, so the one thing I wanted to just conclude with is that what this chapter got me thinking, though, is that in order to make it to the next level where it's kind of more observable or it's more meaningful, you kind of need the system or the game to maybe like be communicating with another individual.

So, like, let's say there's two people playing this game of the triangle or maybe like, you know, you're just communicating with yourself.

you're replaying you know you're trying to get good at this you're trying to make sense of you know what is a triangle uh what helps me understand triangles see so when you model that and how those games are related and i think the reason being that like in the science of this what's impressive is when you have two different people with two different generative models and they get different behavior so if you can do that in a single person like with this type of game saying well

you can go into different modes or have different beliefs or they can change, or you can do that in communicating with somebody else, then I think that becomes the kind of thing we're trying to be able to model.


SPEAKER_02:
Yeah, very interesting.

Yeah, Stephen, please.


SPEAKER_01:
I think that's the essence of the human mind, that there are two generative models that are compared with each other.

There's an online sensory input and then there's the internal

representation of that sensory input.

And those get compared with each other.

And it's that comparison, I think, in the higher level cortical areas that is this really complex motor behavior that we call thought, a sense of self and motivation.

I wonder, so there's that.

I wanted to ask if you were using meaning in the sense of concept, like the formation of meaning is the formation of concepts.

I think there's a whole literature in what concepts are.

Well, of course there's a literature in what meaning is also, but I'm always approaching this from the standpoint of the actual architecture of the brain and the body and how this is implemented.

Neurons are Bayesian units themselves, and then they form Bayesian circuits.

It's the dynamic processes with these frequent rise and fall of these activations with different frequencies that allow signals to get through or not, that amplify or cancel signals.

You know, it's so hard for me to constantly translate Bayesian terminology like beliefs into a structural terminology like, you know, a circuit.


SPEAKER_00:
So what I find very helpful, what you said was like that you see generative models at both levels.

And I really hadn't thought about that, but maybe that's the way to go.

I have this model of the three minds, I call it.

So there's a mind that knows the answers.

which would be what you call like the sensory, then it knows them unconsciously.

But then you have a mind that does not know, but it consciously does not know.

So it's just like full of questions.

It's full of variables.

Like every word is a question.

So like the word horse really means like what is a horse?

And then the other mind gives you the answer what the horse is.

Maybe it gives you an image or something.

So in terms of meaning arising, it's like basically you have these two minds on autopilot.

You know, like one is just...

One is just feeding you all kinds of imagery like you're watching television.

The other one's just kind of chattering away, you know, and they just do their own thing.

But you have a third mind that's investigatory that tries to connect them to, you know, with each other to kind of like.

balance them so that the mind that knows and the mind that does not know they're able to say the same things in different ways because like the mind that knows it's like a hundred billion neurons are telling you one thing but there's like a hundred thousand concepts that that same information is being reduced and now so it's like this distinction between the brain and the mind you know like that is that neural well that's maybe not a very helpful way to look at it it's just some kind of conceptual structure out there

But they need to be linked.

So there's a third mind that kind of helps to punctuate or adjust ratios, parameters, whatever, to kind of emphasize, like to weave them together.

So on the one point of view, like with the conceptual mind, there's a certain point where like it's babbling and obviously, yeah, but this is meaningful and that is meaningful for this reason and for that reason.

Like, for example, this point at this circle is going to be meaningful that we're building.

whereas like the the points on the circle aren't meaningful at all but in terms of mattering like it's it matters to get the circle to the maximal size that matters that's a test to perform so i like that little language because you can see the difference between the two yeah i think the third mind falls out of the other two it's a consequence of the interaction between


SPEAKER_01:
i really like your framing there yeah and so it's both a consequence but then maybe it's steering it you see so like we have a will it's deliberate it's cognizant so it's a it's ambiguous it's ambiguous right like which is it in the process it changes one could say it changes the synaptic weights but the uh there's nothing static everything is constantly changing and when they meet

the interaction changes itself in the process of interacting.

I always think of it in terms of a synapse changes itself in the very action of transferring neurotransmitters.

The vesicles have proteins on them that merge with the synaptic membrane and now it's different than it was before.


SPEAKER_00:
So is that a helpful way to look at neuro... Is active inference and generative model... I mean, generative models, are they a helpful way of looking at the neural systems themselves?


SPEAKER_01:
It's rich enough to apply to the neural systems themselves.

Absolutely.

Yeah, it's quite appropriate, I think.


SPEAKER_02:
I think that's where it's really helpful to look at the SPM work, which is a whole toolkit ranging from like...

spike and fire models of single neurons to neural mass probability models to dynamic causal modeling all within this like ultra chapter nine empiricism with the sensor fusion of the eeg fmri data um so this and then in a way the the behavioral scientists model

can be seen as like a symbolic second mind of the primary embodiment of the mouse.

But let's say it was like an alien creature, or it's an unknown creature, but it has an embodiment, it has a firstness.

And then this is a symbolic projection onto that firstness from a pretty small diagrammatically defined perspective.

graphical toolkit.

And then there's a, to your point about the communication, then there's a two agents.

It's kind of like that.

Then the minds is kind of like the experimental setup and the experimenter.

And then there's the investigation is in the interplay.

And then you talked about communication of generative models across agents.

That's like the synchronic.

like joint that's that's like the space between two at or or more at once and then there's um replay and and pre-play which is like diachronic but that so that's like one self but but it's like is it a different self right if it's a di but you know just legally speaking it's the same person

But then that's also kind of like a space between some extant actuality, which is like the 100 million neurons, and then some symbolic condensation.

And then something happens in the space between, which in the Bayesian updating moment is given a causal power.

or you could just take the the bayesian posterior and just it could be treated as epiphenomenal like you could just continue to to collide streams of priors and observations and then just slough off the posteriors what do you mean by epiphenomenal what does that mean like you'd calculate a posterior and discard it like the the posterior is never given a causal re-entry into the system okay

Like what people arguing that consciousness is epiphenomenal, which is to say like it arises, but there's no causal arrow back.


SPEAKER_00:
It's like a side effect, but not really relevant.

It's a view.

It's not a participant.


SPEAKER_02:
And then the question is like, you know, without, you know, Descartes and all that, but how do you have something that reenters causally?

Is the third mind just like the sparks flying from interplay?

But then but do those sparks?

You know, can they or you know, you know, if whether it's at all those things that you know, do they re answer to modify either neural activity, or symbolic activity?


SPEAKER_00:
And so I'm writing this paper about this model and some of the things I write about, and I quote the textbook.

But, for example, there's an interesting paper about a window that says, you know, you have a stimulation of the brain.

Let's say you have preconscious...

uh time but let's say from 250 milliseconds to 700 milliseconds there's this rather long window of conscious access what they call and what the what they noted with the paper they did different situations where you could do task related or uh task free uh you know you're listening to music let's say maybe you're supposed to be hearing looking for something or maybe you're not but but they they look at the conscious access and what they notice is that the window stays open

for longer than you would think like there's room for playing around of the signal there's room for it to settle down so with regard to the three minds then that's very compatible in the sense that your first mind these this pre-conscious stage can suggest candidate action uh sensations it can give you it can give you information like that then your conscious mind is globally trying to figure out you know how to integrate this what to do

But the third mind, it's like acting as a break.

It's saying, wait, wait, you know, don't rush, don't rush.

I'll tell you when to hardwire when it's all right.

So the point being that the prolongation suggests that there could be something that's prolonging this, you know, like that's, you know, fighting against early resolve, the resolution.

But furthermore, you can have an idea go into your brain before you're conscious of it, of what you're going to do.

It's just a candidate, you know, decision.

so you get this paradoxical thing that oh what you thought you were going to do you already knew quote unquote before you but actually it was just a candidate you know that got confirmed i think that's the way to read it which then is affected by experience the more that happens the more likely yeah

But all three zones, like the meaning changes as you go through those three zones.

It was a candidate, it got kind of like worked out, and then it was affirmed, let's say.


SPEAKER_01:
And I think that points to a threshold effect, where if there is this practiced development of openness to intention, then if consciousness can ever be considered as anything other than epiphenomenon, it is in the realm of intention.


SPEAKER_00:
creating as you say uh a bias toward a particular candidate class yeah you can have a biased right and so that's a way of self affecting yourself is to have biases and so so i quote uh chapter five uh

about the basal ganglia because i say there's a lot of evidence uh i think mcgilchrist uh ian mcgilchrist wrote a book about left hemisphere versus right hemisphere so you get a lot of this you know a champion for both but i'm saying it's deeper than that if you go to chapter five about the basal ganglia uh even in arthropods uh you have this uh uh distinction between um

releasing and allowing the action as opposed to not allowing it there's this you know you have to play with both and i think that that's a sign of consciousness that uh you know you're able to do that uh and so dopamine is what triggers that and dopamine goes way back so that's just a mechanism another one i cite is uh immune systems you have two versions you have um the um

the one that's like inborn innate i guess they call it then the one that is able to learn and so the question is how do they not conflict so i think there's got to be some kind of harmony between them harmonizer between those two immune systems you talk about another principle of biological function uh the the best control system is one that is both


SPEAKER_01:
excitatory and inhibitory in constant tension.


SPEAKER_00:
Right, you want both, right.

So I have this quote, I said this thing, the second mind, it avoids the territory, because there's things you can't learn from, you know, you'll just die.

So you want to avoid the territory and embrace the matter.

uh and so that's why you want to for things you don't know you you know like the unlucky mind there's a mind when things are unlucky you don't want to try your luck we have a lucky mind and an unlucky mind so okay thank you and that they're awesome see you soon