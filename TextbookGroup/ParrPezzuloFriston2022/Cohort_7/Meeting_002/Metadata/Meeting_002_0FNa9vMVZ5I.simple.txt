SPEAKER_00:
All right, welcome back.

Cohort seven.

We're in our second onboarding slash chapter one slash etc.

And Andrew, go for it.

However you want to begin.


SPEAKER_05:
Yeah, great.

So I know that today, we're covering not just chapter one, but just a more general like introduction to

to the group and active inference sort of meeting.

I will kind of quickly give like a rundown of this first chapter.

It's not very long.

There's not too much to say, but that said, I thought it'd be useful just to kind of wrangle together all these different themes here that we're going to be seeing in chapter one, but also going forward for the rest of the textbook.

So in chapter one, we're very quickly introduced to this general idea that we have agents, which could be seen as living biological organisms or other kinds of self-organizing systems.

But they're conceptualized as agents.

And so agents take in sensory observations and elicit actions to either realize their desired outcomes or goals and or to make sense of their world by gaining information about it.

This leads to the development of adaptive behaviors or strategies that agents use for navigating their environment.

This process plays out in a recursive action perception cycle where observations inform agents' decision making regarding the next action they should take.

We also learned that this whole process occurs at various levels of complexity and differing timescales, ranging from the simple and rigid moment-by-moment strategies of nutrient-seeking bacteria up to the more complex and flexible strategies of humans engaging in planning to realize their goals in the future.

Active inference occurs at different physical scales as well, from microbiology to broad cultural and developmental learning in collectives or human societies.

One way to frame active inferences approach, for example, is through the Neitz versus Scruffy's discussion in this chapter.

While so-called Scruffy's lay emphasis on the idiosyncrasies and specificity of various phenomena of interest, for example, different biological adaptations, neuronal dynamics, or cognitive mechanisms, each deserving of their own separate bottom-up research from empirical data,

the so-called NEETs aspire to a set of first principles for explaining and relating these diverse phenomena in a more top-down fashion while still engaging in empirical analysis for validation.

And so active inference also identifies with NEETs as it lays the normative framework for understanding the brain and mind and their biological and cognitive implications alongside model design and testing for empirical analysis.

We're given a kind of general schematic with the rest of the book.

It's separated into two parts.

The first half will focus on theory, the second half on practice.

So I'm just going to speak about the rest of the first half.

The first half basically presents active inference as a normative framework with its distinct concepts and theories.

We're shown a kind of conceptual roadmap at how to arrive at active inference in your respective learning journey or however you would like to view that.

And there are kind of two roads to reach active inference.

There is a low road starting with Bayes' theorem, which basically supplies the mechanics of active inference in its relation to what would be called the Bayesian brain hypothesis.

It's basically a way of viewing

uh processes or computations in the brain is playing out via bayesian principles where there's prior information uh new observations come in there's some kind of likelihood that relates uh prior information with new information and then

produces a kind of posterior result, a prediction about what's going on in terms of inference, inferring what is going on based on what you thought before, as well as what new information you've received.

And then on the other hand, the high road in chapter three, coming much later, begins with the free energy principle or the necessity for agents to minimize free energy as a proxy or upper bound on surprisal in order for these agents to survive and adapt to their environment.

For the rest, chapter four, we'll just go a bit more into detail about basis theorem and will actually be presented with major kind of exemplar active inference models, those that are used for discrete time scenarios as well as continuous time scenarios.

Chapter five, the final chapter of this theory part of the book,

We'll then discuss the neural process theory of active inference, which again begins with the free energy principle, but then also relate how the specific quantities we find in active inference, like predictions, prediction errors, precision signals and so on, which we'll discuss much later, how all of these map to cognitive functions and their constituent physiological substrates and neuronal computations.

So through the course of the first part of this book, these first five chapters, we'll just repeatedly return to various themes, perception as changing one's mind, action is changing the world, learning as actually being very similar to perception, but operating at a slower timescale with longer term impact on the inference process going forward, thus learning.

Planning is a means of selecting actions and sequences to realize not just current but future goals by kind of predicting forward into the future to decide what you should do later, not just in the here and now.

Some other things like how to define exploratory versus exploitative behaviors.

It's a common distinction made in various sciences of behavior.

And I especially wanted to note those because an active inference claims to kind of include both kinds of behavior within the same optimization function for energy minimization, as opposed to treating them as separate and needing to be manually defined, as we'll find in many other kind of computational approaches, like in reinforcement learning agents, for example.

um and that is about everything that i kind of put together here for describing the first part of the book um you know feel free to obviously read the rest of the chapter it'll talk about all the uh other chapters in the book as well but just focusing on part one for today so um

I guess I'd like to open up the conversation.

I know that there are some introductions at the very beginning of the meeting, so I'm not sure if we want to go back into those.

But usually how we do it in the textbook is just anyone who has something of interest about this chapter or a question they have, they would just like to throw it out there.

We could take things from there.


SPEAKER_04:
There's things that I have to say, but I want to look in my note.

I make notes on my Trello board.

So if anybody else has anything to say before I get to the notes I've taken on this chat on, I guess they could feel free.

I'm just looking for my notes.


SPEAKER_05:
Sure.

Jorge, you have something?

yes basic question um what is free energy itself like not the principle but free energy itself yeah so it's uh for better or worse is somewhat uh complex concept but um it's it's basically it's you can relate it to information theory it's kind of like an information theoretic quantity if that makes any sense

Yeah, so it could be measured in mass, for example.

And kind of the importance of it here is that it acts as a kind of proxy, more specifically a kind of upper bound on another quantity that

organisms are theorized to be trying to minimize called surprisal and the reason why we're not saying it's surprisal minimization as opposed to free energy minimization so surprisal as far as kind of the bayesian computation that's being played out here surprisal is typically like intractable it's just a lot of kind of

factors that need to be marginalized along the way when when computing surprisal there can be kind of this issue with integrals and so on and so free energy in kind of mechanical terms is just yeah an upper bound on surprisal that is tractable so we can compute it then on the other hand um it still relates to something like something like a kind of biological realism that is you know

James Onley- Organisms have limited.

James Onley- Resources in the moment by moment inference processes that they undertake right so their biological and medical.

James Onley- kind of constraints on on what they're able to do.

James Onley- So hopefully that was helpful.


SPEAKER_00:
Yeah.

Let me add one more by analogy here.

So from chemistry, one free energy type that people might be familiar with is the Gibbs free energy.

So this is the thermodynamic free energy.

And so it's like ball rolls downhill is the Newtonian mechanical path of least action given gravity.

candles burn given the activation barrier is the thermodynamic equivalent so putting aside this the activation energy question going downhill means energy is dissipated as heat but then there's some floor where there's no more liberatable energy from that floor so free is not in terms like free like beer free like software free

a synonym for it is like liberatable or like releasable as heat.

So then 1900s are happening.

Information and thermodynamics are coming closer in info thermodynamics in a lot of different like kind of really mechanistic ways, like Landauer's limit, how much heat is related to like erasing one bit, but also like realizations that at even deeper levels

that there's these um way to think about information in terms of also a path to least action in an arbitrary state space that's called bayesian mechanics so the ball rolling downhill in this case is like explaining the data

better where better is given a specific like form of families of equations such that there's kind of a signal to noise and the signal is kind of like the floor and the noise is more like a heat or an entropy

So it's used as an approximator that bounds surprise.

Minimizing surprise is maximizing model evidence.

However, maximizing evidence, you don't know how high that mountain is gonna go, but minimizing surprise is often more tractable, but then it itself is intractable for another reason, which necessitates in the approximate Bayesian setting, the usage of variational methods, because that gives an analytical,

approach that's optimizable incrementally whereas an alternative approach to variational approximation is Monte Carlo or sampling based methods those are also limited in large state spaces but they don't require you to compute a free energy to balance appraisal you just sample from a distribution and then use that as your kind of empirical data David


SPEAKER_03:
uh yeah I was wondering if we could correlate it to to um free energy in in terms of trade-off so like how much how much weight is assigned to you know the predictive nature of trade-off itself and how much will you gain or lose by being right or wrong you know depending on the the data itself and how it's fit


SPEAKER_00:
the accuracy minus complexity decomposition of variational free energy energy energy minus entropy is kind of like the physics flavor accuracy minus complexity is the statistical flavor which is that you want to reward model fitting but penalize more parameters so now you're kind of your risk tolerance like whether you have a preference for smaller and you're willing to like your point of diminishing returns

is a smaller model or whether your point of diminishing returns is a larger model, there's like this Pareto optimality manifold where if you're off this manifold, you just could simply be doing better.

But then there's like a manifold frontier in terms of model fit where it's like a hyperparameter manifold where you're doing as well as you kind of could on that trade-off frontier.

But off that crease,

you're just leaving um explanatory power on the table with the parameters you have or from coming from the other side but that's kind of the statistical and then this is part of the whole theme with things the the most likely thing is what happens like things are doing what's likeliest

rather than what's most rewarding, because the proposal of a secondary reward function is not even something that seemingly advanced cognitive systems necessarily do.

But that's what gives unity with the dust particle and the rock and cognitive modeling.

But then the question is, how do you explain higher order behavior, teleological behavior, et cetera, in terms of novelty, aesthetics, in surprise minimization terms?

Right.


SPEAKER_03:
So, I mean, I guess, sorry, my, my approach to it, you know, in terms of like, I come from more of like the quantum side of things.

So I don't want to inject too much of that into it.

But if, you know, you have a coupling with like a bit flip, right.

If you have a coin with two heads, like if you're just going off the randomness of the coin flip, if you're a blind observer, you don't know, you know, heads or tails, what the trade-off is going to be.

I mean, if it's given the outcome is always going to be heads, right.


SPEAKER_00:
how can you then minimize that into free energy well if you're never getting an observation then you're never able to calculate a free energy because the free energy is cal equation 2.5 for variational free energy it's your beliefs and an incoming data point so if you don't have a data point you could do descriptive statistics on belief


SPEAKER_03:
but you wouldn't calculate a free energy quantity right so I guess the I guess the primary question there is if a system is determining how you're going to answer something because of you know learned in behavior due to an assumptive prerequisite doesn't that kind of end up being deterministic and becoming a trade-off in the long run


SPEAKER_04:
I'm sorry, can I make a comment?

Yeah, go for it.

The way I think about free energy and how it makes sense to me, I like to think about fields.

I'm assuming everybody here knows what a field is, and I think about the different combinations of ways that perception and action can unravel with respect to priors, thinking about fields from the physics point of view and translating that to the cognitive,

and behavioral or psychological point of view.

And you can get really more into the woods with this returns of like,

know mechanisms in the brain where neurotransmitter interactions are happening and neuromodulator interactions are happening but um i'll i'll get into like certain uh points that i made about comments i made about the chapter in a moment but i just figured that what makes sense to me about free energy and just thinking about like potential energy and it from from a

point of view of like how energy can be utilized force utilized and think about the degrees of freedom that's that's there and thinking about modeling agency and how organisms

engage their environment, but also a number, I've had a number of conversations regarding free energy being generalized beyond the scope of thinking about agents or organisms, but also inert objects and how they take up an environment and how you can estimate the space over time that's taken up by those objects.

And then you can encode the Markov blanket and what have you, have a feel.

you can develop a field of like the possible interactions that can happen even from inert objects to systems that are capable of agency that can actually properly occur and estimate over time their environment and their circumstances leveraging them.

So to me that that it makes sense from that point of view and not to not

Andrew Smith, Williamsburg Regional Library, he, him, delving too much into the details of the physics, but acknowledging okay.

Andrew Smith, Williamsburg Regional Library, he, him, there's the concept of fields and I could take that in the combinatorial options in which me as an agent can perceive and act on my surroundings and develop fires, but hopefully that that kind of.

Andrew Smith, Williamsburg Regional Library, he, him, is applicable to addressing this like potential energy and free energy so and what have you.

I don't mean to ramble too much, but I was like sitting on that thought for a few minutes and like, oh, I want to say something and hopefully it helps make more sense.


SPEAKER_05:
Yeah.

I mean, it's, I mean, not to heavily, I'm really just kind of simplifying and abstracting certain parts of what you said.

So apologies for that.

But I, to kind of bring it back, I think

I mean, if I understand David's question right, like I said, maybe part of the idea is like isn't supplying some kind of prior that's already heavily conditioning the process that ensues from there such that there's a kind of almost determinism based on your initial starting point because we're requiring that you have a starting point given this is like a Bayesian process where you have prior information necessarily involved.

And I mean, it's,

From my understanding, it's just kind of like a description of how the process plays out.

And I like the idea of a field, whenever we just look at it as like, this is the kind of space, like how you described like, like objects, or beings in their environment, or, you know, affordances within that space or field or environment.

and so on.

And it's like, well, if we were to study that, as scientists, researchers, however, like, we already have a lot of starting kind of prior information there, and we're going to start trying to model it to predict what will happen next.

So I mean, it's not to sound so abstract or conceptual, but it's like, we're always kind of working with, from our standpoint, kind of, you know, external

a position, a bunch of prior information, and we just kind of start there.

Just a couple of tangential points that when setting up an active inference model, you know, there's of course like fitting models to empirical data, but then there's also just during the testing phases, I mean, it's very common to just initialize with say very uniform priors, you know, basically entirely uninformative priors and it's through

the capacity for learning or updating model parameters that the agent can actually adapt to the situation.

And then its own parameters change such that it's kind of starting with new priors in the next round, so to speak, that may be better, hopefully, through free energy minimization, better match the environment around it, if any of that tracks.


SPEAKER_00:
yes and just like dynamical systems or linear regression you can pull back to like univariate linear regression or single sinusoidal oscillator dynamical system those are kind of like the doorway example

but then you might run a statistical script and it does a linear regression on thousands of data points, or it has more dimensions than a single dimensional form.

So the textbook, much as it is for, again, the kinds of topics that are addressed in the appendices, linear algebra, dynamical systems, probability information theory,

those are also like their principles are shown in the textbook but then when it really comes down to anything like a system of interest it's the shape and the specific variables you use so these are like some of the moves and some of the generic cues and then like it's all about making that jump or path from okay listening to music in chapter seven to here's this music data I have


SPEAKER_03:
yeah that makes sense I I guess I'm thinking in terms of weights as well like if we're waiting that data um like how can you avoid overfitting on something that's assumptive like for example like some of the things covered in chapter one like we do go into

I guess some of the some of the things I see as um like in terms of like not just trade-offs but in terms of how we approach as you were saying like just with sensory response right like our priors are also based on our limitations in terms of how we can measure how we can even understand to measure where you know there might be extra sensory kind of abilities that we have from a cognitive standpoint that we're not aware of in terms of even

just in the way our brain interacts with itself with neuron interaction right so um I guess it goes back kind of to the pheromone response as an example of something that we can't detect but should be able to be weighted in the data yeah I mean just as a brief like like one of the key


SPEAKER_05:
A key concept in in active inference whenever it comes to modeling is the notion of like precision as a kind of like inverse variance term and that that can kind of be viewed as.

A weight or waiting system that there are a variety of different kinds of decisions that are applied to different variables as far as the neural process theory goes they're kind of related to synaptic game and and neuro transmitter transmission.

um but uh yeah the general sense is that there's a kind of waiting process going on in addition to that again active inference uh agents who engage in learning like many things can be learned including like how to adjust those precisions uh in order to say weigh up weight or down weight

the impact of new incoming information.

There might be an agent who has a likelihood model that maps observations to its own beliefs about what's going on, it's a hidden state.

And so it might have a lot of really imprecise mappings like relations such that even though it receives new

a new observation, it kind of downweights the impact of that new observation because it can't find a good way of mapping it to a belief state such that it can confidently update that belief state given the new observation.

So there are these kind of mechanics, yeah.


SPEAKER_00:
great point with gain that can be thought of like people with audio editing experience probably have a very embodied sense of this but there's a way to tune the precision such that even a variable signal gets collapsed to basically the extreme case is the dirac delta function which is just like a line it's a it's a special distribution that is zero everywhere and then it's infinite in one spot

so there's a precision setting that'll take a range of values of thermometer readings the height of the children in the classroom and do something like collapse it down to its central tendency and then also there's gain settings that can take even closely related data points and flatten the distribution

So that's the hyper priors and some of the parameters that come into play in empirical Bayesian analysis.

And then like, unless otherwise specified, it's like the temperature's one.

But then sometimes you do write it out more fully and then learn or manipulate the hyper parameter related to the temperature.


SPEAKER_03:
then about action that's the shaky hands so it's kind of depending on where it is but but that does basically like sharpens or blurs okay yeah i mean that's how i was thinking of it in terms of like gradient descent um because those are some of the formulas that i've been you know working on where i also have run into a few things that i need to check where it is zero like you were mentioning but it also expands infinitely at that point and contracts infinitely at that point so that's kind of

my prior that I'm trying to work with in terms of like if the math is correct what imprints does that have if that collapse point will always be zero and one right you have a binomial distribution at that point where it's still a choice but if it's predetermined right you end up and I don't want to get too far into the woods on that but it's just something I wanted to kind of highlight from what you mentioned


SPEAKER_04:
I want to bring up, so there is one statement on page 10 that I think I have some confidence that the rest of the book kind of makes up for the generalization I found, which is the bullet, I think it's the second, it's the last bullet.


SPEAKER_01:
on page 10.

And it's the bullet that says, under active inference, both perception and learning are active processes.


SPEAKER_04:
And I quoted the part, the brain is essentially a predictive machine which constantly predicts incoming stimuli rather than passively waiting for them.

And the comment I made about this was that I thought it was kind of a naive assumption to assume that there's never a situation that the brain is passively engaging with certain stimuli instead of constantly predicting.

and this can help differentiate between noise and relevant stimulus to be interpreted as information so I think that the rest of the book gets into better detail about this but um I made a note of that as like kind of um a naive assumption made on page that I I found on page 10 that

Well, is the brain predicting everything coming in or out?

It's predicting relevant information, but I'm assuming that the book gets through.

It seems like I peaked that chapter two a little bit.

It seems like it does a better job at specifying.

And I think the overall chapter one does a good job providing a nice general overview, even though there's some assumptions made that I think are clarified better.

I also, sorry about that, but yeah.


SPEAKER_01:
Good point.


SPEAKER_04:
The point I made about what I found on regarding predictive processing happening in the brain.


SPEAKER_00:
Yeah.

Two quick things on this.

The first is, as so, so, so many times, there's slipping between realism and instrumentalism.

If they said, first, we choose to model the brain as a predictive machine, they couldn't be wrong because they're talking about their position to modeling.

But then it slips into what the brain is.

So that's one piece.

And the second thing is, it hinges on what is meant by a passively waiting.

That could be hanging out on the couch, but hanging out on the couch, even if your eyes weren't circading,

still you would be actively generating the periphery the sharpness and so on so in that sense there is this real time like now casting a vision even if it's not cicading and moving its head and all of that but then is that passive or active


SPEAKER_03:
Yeah, I mean, how does that speak to a dream state as well?

Where if you have a hyper real dream state, you know, where there's, you can affect your surroundings in the dream state, not realizing you're in the dream state, versus a waking state in the same kind of notion of sensory.


SPEAKER_05:
Yeah, well, that I mean, that's an interesting question.

I, the way I would

take them is that it's still be similar to a waking state and that you're still a bunch of sensory information is still kind of being delivered to you presumably there's something going on that is kind of actively leading you to make the decisions or inferences that you're making during the the dream um but i've never actually i've never really followed that full thought

through on thinking about how this works in a dreaming state.

But that's just my initial guess and an answer to that question.

I think for this particular quote, yeah, same point that Daniel made earlier, the flipping back and forth using instrumentalist language sometimes, other kinds of language other times.

But I just want to say I think it still relates back to kind of that you always have priors, right?

There's that kind of like you have priors there and then there's computation going on.

If you didn't have priors, then maybe it'd be easier to say like you could passively take something in.

But the idea is that you're coming to a situation figuratively with information that's gonna get computed.

So it's like you're involved in the process as it were.


SPEAKER_00:
And to make this like really clear and be clear about what the alternative hypothesis to Bayesian approach would be,

Frequentism would say, okay, we're getting this wave of photons hitting our retina, and we're going to do the maximum likelihood reconstruction.

So then we'll use interpolation, Gaussian blur, convolutional neural net, et cetera, et cetera, et cetera, all these techniques that are these inbound processing techniques to reconstruct a snapshot of the maximum likelihood image.

so that is implicitly saying all pixels have a uniform prior like I don't know anything and I'm just going to take one snapshot of pixels and then reconstruct the ml um the outcome but as soon as you start to leverage oh well but I think it should be like the prior one prior frame that's literally Bayesian analysis then that's the Kalman filter

where on one extreme, it is the special case where you're frame by frame doing a total re-estimation.

The other extreme case is you're just making a long-term running average, blurring over all the times.

So then you have this Bayesian hyperparameter search question, how responsive should my Kalman filter be?

And then you have another model in this portfolio, how fast should I be learning how fast to change that?

all of those bayesian models can be evaluated with bayesian model selection using accuracy minus complexity bayesian information criteria so it's like oh okay well i'm getting i'm still getting bang for the buck to three but four always you'll fit better and better but then you're past the point of diminishing returns

So that's like kind of the meta with Bayesian, which comes back in chapter nine as well, is selecting amongst Bayesian models, even with totally disparate architectures, is a Bayesian model selection question.

Whereas in frequentist parametric statistical methods, you can really only compare model likelihoods using strictly nested, the hierarchical likelihood ratio test, like ANOVA.

but you can't test non strictly nested models.

So for all the limitations and peculiarities of Bayesian analysis, it's super useful to compare it to frequentist and to non-parametric statistical approaches like bootstrap, jackknife, resampling.

But those are three of the major lineages in statistics overall

And those are some of the major toolkit areas as well.

And the SPM textbook earlier work by Friston goes into this and kind of compares the methods a lot.


SPEAKER_03:
So is the stacking kind of like logarithmic in a sense, or is there any point where it becomes exponential and then just falls back through the stack to the base?

What stack?

Well, so you were saying, like, if you're using Bayesian to calculate Bayesian, right, so you're still, you're kind of using an exponential formula in a way, right, but it must be within a certain range.

So once you hit a maximum, does it reduce back into the root, you know, it's still Bayesian inference, like you were saying, right, as a for function.

would it reduce all the other layers that you've gone through to iterate up into a certain point right back into the initial if there's no priors in the set okay


SPEAKER_00:
it is an interesting question so this is like asking what should your prior be over structurally variant models like I I can do the one layer temperature model just try to do a fit I could do a two layer temperature model three four but then am I a frequentist which is to say naive over structural parameters

So is it like, is the whole Bayesian game nested within a frequentist naivety about model structure?

And you could do that, or you could explicitly have a prior on structure learning.

then if you were saying i'm making structural models of this condition in the genome and i i think it's it's not possible for there to be fewer than five or more than fifty thousand loci and then here's my distribution of of structural parameters within five to fifty thousand it's uniform within five to fifty thousand or it's gaussian around this number

then your structure structurally differing models would be weighted intentionally by your prior distribution on that okay whereas if you have a uniform distribution across structurally different models that's like a fair test across them all okay that makes sense thanks yeah i had a


SPEAKER_01:
One more comment on the chapter on page 10, the second bullet, where it starts with various contrasts of active inference have plausible biological analogs in the brain.

it makes the claim that precision of policies corresponds to dopaminergic activity.


SPEAKER_04:
So I think, again, that that's a pretty big assumption.

And there's a lot going on with the regulation of neurotransmitters and other main modulators like norepinephrine and serotonin.

So the regulation of arousal in the brain and

the moments of coupling between serotonin and dopamine for different reward and learning circuits.

that are that are chained together as well.

So and I think this also relates to the capacity to become aware of and pass on stimuli as sensations and acting on those sensations that impacts perception and action and priors.

So I figured I'd throw that out there too.

But I'm not sure if other chapters in the book press on the importance and role of other neurotransmitters and neuromodulators from the top of the stack in terms of how cognition is regulated within the agent.


SPEAKER_00:
yeah here's table five one acetylcholine noradrenaline and it goes here's the citations with some other neurotransmitters and and um i agree it's like it's like but there's there's so many subtypes receptors downstream signaling it's like how could a single parameter

And it's like, it's a coarse graining, it's a map, it's not a territory, it's not that it is a parameter in the brain.

And then models that make unique predictions and explanations and have explanatory value, those are leading models.

And then when they are fit with one data set and then they have predictive value in a different paradigm, again, that's evidence for that it's capturing an informational aspect.


SPEAKER_03:
so yeah I mean thinking about that in terms of like descending versus ascending and deep versus superficial I mean that's kind of the coin flip again right where you have like at what point in that chain of the structure can you determine whether or not the deep has flipped to a superficial kind of state

if we're thinking of temperature right it's going to be a constant right or are we talking about interval in this case


SPEAKER_00:
temperature could be constant or just like from reinforcement learning and and other Bayesian approaches a common method is to have a high temperature beginning and then turn down the temperature and then people say well let's do multi-chain let's have them do let's do five parallel chains with different temperatures and then have them swap positions like then there's all these higher order questions

about how you best leverage your computing resources but that's not changing the analytical formalisms those are more like computer science and engineering methods to implement variational bayesian methods

that doesn't change the equation of 2.5 or 2.6 but like different approximators they may give different results but it's like that's like how many layers back do you pull back in your investigation right

question which what's the name of the book that you mentioned about by friston on the spm i think it was earlier today what's the name so the last um printed version as far as i understand was 2007. it's purple book okay but then there the the spm online documentation goes into 2012 and there's still a totally live community

with people doing fMRI imaging.

So I found this book to be extremely helpful background information for several reasons.

First off, it's like a speed course on the trifecta of classical parametric statistics, non-parametric statistics, Bayesian statistics.

So it gets all those in play all the time.

And it deals with what we might call the A matrix, the mapping between observations and hidden states in a setting where the observations are of a well-known form like EEG or fMRI sensors.

And then the hidden states are neural activity and the blood oxygen flow dependent signal, the bold fMRI signal or neural activity signals.

So it's like a defined system of interest and sensor type clarifies the setting.

It's not about multi-scale considerations, but there's some ways towards that.

So it really hammers down the statistical and the partially observable part.

And then action selection is just selecting a different index card in the transition operator and changing how the hidden state unfolds.

And that is kind of approached towards the end of the book and in certain analyses.

And it highlights the empirical basis.

From your workshop presentation, Andrew, what questions did you receive or what did you feel like, what would welcome people and what did people ask and what were they wondering when you showed them what you made?


SPEAKER_06:
Yeah, sure.

Yeah.

You know, it's so again, uh, the conference was, uh, it's, it was like the big, like international, uh, like computational social science conference.

And so many people, they're like familiar with machine learning and empirical data and so on, maybe not know so much, um, kind of like say foundations of concepts in physics, um, information theory and so on.

Um,

not in a way that they firmly needed.

Uh, and so I think a lot of it's just attempting to answer questions of like, why use active inference to try and explain human behavior?

Can we not approximate human behavior through, you know, a variety of other methods?

Um,

So it's a little different from the conversation we've been having, right?

Like, there's a lot of questions of, like, scalability, like, oh, how?

Okay, great.

One person, one individual entity is minimizing their free energy.

But how does that allow us to make claims about what's going on at, say, a more collective level, like 30 agents in a network or something like that?

So it's kind of just it's more about

of describing the mentality here of like okay we're creating something like an agent-based model that has an agent and its environment and then from there it's just you know as opposed to using like net logo which is a kind of traditional way for scientists social scientists to do this where

you have much more rules-based logic, like the agent does X if it observes Y, does Z if it observes A. Instead, it's kind of like we have models and a model.

So we have an agent-based model where each agent is its own generative model.

So yeah, it's just more like kind of conceptual in that sense, how to relate it to agent-based modeling, human behavior especially.

see what other you know it's per usual there there was a quick question about like okay so why is this a theory of consciousness etc you know that kind of open up into other discussions um let's see yeah i think sorry about those massive cells there but yeah those those outputs are like you know this is agents engaging in something like collective problem solving so exploring an nk

Jacob Plocher , landscape, where they can either explore, which is where they change a bit in their own solution, or they can exploit meaning take their.

Jacob Plocher , neighbors one of their network neighbors solutions, and so these are these are just like the output results for running that over T time steps right like how.

What's the best solution that they managed to collectively come up with?

Did all agents arrive at that solution?

Is it separate?

You could try and use this to study something like the diversity of ideas in a more general way, too, because there are fewer and fewer unique solutions if all agents are just jumping to stealing the best one.

um so that yeah falls over time and then what i was attempting to demonstrate that because this is recreating a simulation of the more famous kind of paradigm uh from a decade or so ago where they try and describe like team performance between

um you know within groups like a group of researchers or a group of you know employees or something all working collectively on a problem maybe it's a group of students right working on a group project um but what they don't you know because it's all done in this kind of like more traditional rules-based way we're not able to look at like okay well what about

agents who learn, you know, and actually adapt, right?

And I'm trying to demonstrate that whenever we include these agents as active inference agents who can learn actually like the impact of engaging in a project where you're able to just steal your neighbor's answer without doing much of the work yourself, like if that's kind of what you learn or adapt to, then

uh then over time like that's kind of where you'll start off your next group project potentially like your beliefs about what the optimal solution is will point you towards doing the easier thing and so it's just kind of trying to add a lot more nuance to those that traditional simulation it recreates the previous simulations dynamics it recreates the dynamics found in empirical literature of group uh dynamics of performance and yet this by

creating agents that have these kind of internal cognitive active inference parameters you're gonna actually you know the idea is to try and have proxies for like okay what how does this impact back on the agents themselves and the longevity of doing practices uh practices like these so

so those like those are just some animation plots that show like the distribution of beliefs of uh if it's basically mapping the likelihood of if i see myself like exploring coming up with my own answer you know how does that map to observations that are oh i'm getting a better answer so it's kind of like a personal efficacy um belief it's like oh how much do i associate exploring with

a better result a better solution in the end which then would condition your decisions uh over your actions like your posteriors over policies to continue exploring right so over time they all start off you know kind of low that's how i i set them up as priors but many of them just get lower and lower like they you know you just you have so many neighbors that you can kind of take the answer from so i could go on about this all day but it's just

You know the the slides get into some of the more kind of textbook formulas equations, etc, but the script here was really to try and demonstrate like what happens at a broader scale and how could you actually use this.

um you know to approach problems that we're already trying to get at like not throw a bunch of new stuff at people all at once um about here's a whole new set of problems you can now try and approach thanks to these methods instead it's like here's the value added of using these methods even whenever you try to approach um you know existing paradigms or problems so yeah that's my


SPEAKER_05:
I ask you a question.


SPEAKER_03:
I haven't had a chance, obviously, to look at the data, but you had mentioned, you know, like a group of like 30 people, for example, in a node.

If you consider that, you know, one company, right, let's say it's a department, a company, you're still connected to another node of, say, another if your end value remains 30 per department.

um if you had you know one individual in each of those nodes that wasn't conforming or wasn't you know kind of going with the same flow was there any correlation did you see it anywhere else in the topology that might have affected chains that aren't directly connected but would be through the network itself that's interesting um


SPEAKER_06:
So I didn't get quite that far, right?

Because this was basically just kind of put together as like a toy situation, right?

Just to demonstrate, but that's an interesting question.

I think you could attempt to get something like that.

Like, so this is basically just creating a single network, like a single, but you have two options, like the way I set up the function, you can either make a, like a random graph with like P,

connectivity that you can define yourself or you can set up as sub networks where the separate subnet, it's like five groups of four agents or however you want to define that, but they're completely separate from one another.

But what you could do is you could adjust that to where you do have connections between the sub networks

And then I wrote everything, you know, just in a very programmatic, like make all the agents have the same priors, but you could set up an agent who has, you know, very different priors from the rest, see how that plays out.

So I guess the simple answer is like, I'm not sure, but the, the, the, the tools are kind of there.

If one wanted to maybe approach and answer that question.


SPEAKER_03:
Great.


SPEAKER_00:
Thanks.


SPEAKER_05:
Sure.


SPEAKER_00:
Cool.

maybe a model stream maybe with somebody else who's um done it but you should post it in Discord and let's see if anyone plays with it and then let's do it because I think that's a great framework for playing around and linking it to the sections of the book sounds good yeah I'm I'm I'm someone who comes from a social science background so it's kind of like for me it was just kind of this plunge into talking about like um


SPEAKER_06:
statistical physics and so on that it's like it's super interesting once it starts to catch on but until that point so i'm just like thinking like how do i use this right so that's that's exactly what i'm trying to get but yeah no stream sounds really awesome so i'd be happy to do that cool okay thank you andrew and cool to hear the update thank you all for joining see you next time