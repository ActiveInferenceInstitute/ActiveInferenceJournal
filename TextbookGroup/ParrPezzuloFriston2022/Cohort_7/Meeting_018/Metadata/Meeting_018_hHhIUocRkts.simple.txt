SPEAKER_03:
All right.

Hello, everyone.

Welcome back to the Active Inference Institute's textbook reading group.

Today, this is cohort seven, wrapping up with chapter 10.

It's been quite a journey through the first part of the book, which, as we know, is a bit more focused on formalisms, on theory, on anything from Markov blankets to wrapping our heads around hierarchical variational message passing in microcortical circuits.

as well as looking at sort of a Bayesian framework for doing updating and then linking that to action and perception and action perception loops from the active inference framework perspective.

And then with the second part of the textbook, we saw a lot more in terms of application models.

We had a recipe for active inference ranging from defining

our generative models, our generative processes, considering different kinds of components for models, likelihood and state transition matrices, looking at the discrete case versus the continuous case and all the rest.

And then our last chapter for this cohort prior to chapter 10, chapter 9, we were looking at what happens whenever we want to actually fit models to empirical data, whenever we want to do group analysis, and kind of wrapping our heads around the idea of

composing the subjective model for our agents and having our own kind of model of the agent's model.

So something like metabasian modeling or analysis.

Now in chapter 10, which kind of sticks out a little bit, a bit of an outlier in the second part of the book, it's almost as if they could have written a third part of the book that would have been labeled something like active inference and its connections.

We saw in this chapter that we're actually

no longer directly talking about kind of the mechanical or sort of engineering aspects of creating or testing or fitting models.

Now we're just kind of wrapping up with looking at the interrelationships between active inference in a variety of other fields, both fields from which active inference kind of grew as well as fields to which it can contribute and those which fall within both of those prior categories.

So in the introduction,

to chapter 10 we're uh described uh it's described to us active inference is a complete solution to sentient organisms adaptive problems which attempts to provide a unified perspective on action selection perception attention and even emotion regulation that list could continue on and on actually for those of us who have kept up throughout the book um

And it's kind of reiterating, you know, we know that active inference is essentially a unified, it's a normative framework operating from first principles, brings back the old Neitz and Scruffy's argument or debate from the first chapter of the book where we are in the realm of the Neitz, although we certainly would not deny a Scruffy or two, especially to welcome them into the fold if they so chose.

In section 10.3, there's a pretty interesting quote from Daniel Dennett, the late Daniel Dennett, of course, and his suggestion to kind of model the whole iguana.

With active inference, we do something like that in an attempt to create proxies of reality, whether it be creating a model to simulate in silico or it be to fit a model to

a real-world organism or phenomenon or otherwise, where here free energy minimization acts as a kind of first principle by which we can derive implications about specific cognitive processes and their neuronal underpinnings.

So active inference takes a kind of inactive integrative approach to things like preference realization, self-evidencing, self-preservation.

We're reminded of

homeostasis or as well as allostasis or a kind of homeostasis of the future.

The idea that there's bounded rationality that organisms and agents and so on kind of exist within their immediate context.

They come with their own histories or memories and beliefs that they're actively kind of updating and also testing through action.

And then

We were reminded again of the self-evidencing aspect of action perception.

Both of these are self-evidencing in the sense that they both lead to the agent aligning its expectations given its generative model by either changing the world or changing its mind.

So memory and attention also are thought to be optimizing the same objective.

Long-term memory develops through learning model parameters.

remember that learning operates at a somewhat slower time scale than inference itself, which inference is usually seen as kind of a real-time moment-to-moment process, whereas learning could happen, you know, just slowly, or you could imagine, like, it's almost like a mouse in the tea maze, moment by moment, position from position, or to position in the tea maze as they move left or right, or

visit the informative queue at the speed of real-time inference, you might say, you know, perhaps after the entire trial, you know, they achieved the cheese or unfortunately they didn't and they, you know, obtained a negative stimulus.

In either case, it's kind of like maybe after the whole trial, that's where you kind of take in the whole experience as it were.

And maybe that's where learning happens, or maybe it happens at another time, or maybe it happens during sleep.

You know, which, which we certainly, uh, interestingly do, of course, our brains are never fully off.

Right.

So there's a variety of processes that occur during sleep and including, uh, the kind of modeling terms would be both parameter learning as well as structured learning.

You know, it's interesting to see what a night of sleep does you whenever you are working on a problem.

And then suddenly the next day, maybe you feel as if you've realized the answer or at least have found some kind of clarity that you didn't have prior.

See, we're also reminded of, you know, the deep relationship between.

active inference.

And when we're talking about action, perception, planning, all these kinds of things, they not just look at, you know, neuronal processes in the brain, but it also has heavy overlap with a lot of ideas from, of course, cognitive science, as well as kind of psychology in a broader sense.

You know, there are interesting papers for those who might be interested in psychology.

And, you know, there's a

um some interesting work that's been done on trying to relate you know the active inference though it is operating first principles that of course I mean the whole point of chapter 10 is not to say oh this is a first principles kind of framework and therefore we reject all else instead it is it is kind of opening doors to interdisciplinary um communication dialogue and so on and so it's

interesting work that's been done on trying to make the point that sometimes it's more of a matter of ontology.

Your terminology you use and your respective ontological take or what words are in your vocabulary for describing different kinds of processes or phenomena, or perhaps even the word process has a different meaning from one field to another, right?

But nonetheless, they do

kind of discuss some other things that I always kind of emphasize whenever I describe active inference to others, because with the kinds of work that can be done in active inference, say in psychology or something like precision psychiatry and, you know, the notion that

that a neurotransmitter might be modeled as a kind of precision or attention related or synaptic gain related parameter over a distribution in a model.

You know, we're finding, especially today, the relationship between a lot of these kind of cognitive science and kind of psychological sciences, like concepts and notions, but actually being able to find different ways to approximate them or even test them and fit them to

experimental data using modern machine learning, reinforcement learning, active inference in some ways can be interpreted as a kind of variation of reinforcement learning.

And so it's just kind of leveraging modern tools, technologies, and so on, not just to try and create the next kind of superhuman AI, but to actually find ways where possible to kind of

you know, model the dynamic or causal relationships in living organisms or in broader processes or modeling, you know, potentially entire societies in some way and looking at collective, emergent collective behavior or otherwise.

And so it's, I like to emphasize sort of the work of someone who collaborated with Carl Friston at one point in time, Yori Busaki, who's a,

took a lot of influence from.

He's done a lot of work in kind of like rhythmic processes in neuronal activity, looking at things like gamma versus beta and alpha frequency bands as kind of extracted through and engaged in with like spectral analysis when looking at neuroimaging data.

And he and many others have been making the point that the cognitive and psychological sciences should perhaps today be a little bit more wary of

of a really brilliant mind that was William James in the 19th century.

But we should maybe be wary of a lot of these inherited Jamesian categories, which, quote, despite their great heuristic value, may be quite arbitrary, or they may not correspond to separate cognitive and neural processes.

so the authors here again they reference pisaki as well for example whose work suggests a more critical stance towards using james as the theoretical springboard from which to kind of confine our empirical undertakings though james's work should not be neglected per se bisaki advised an inside out approach to neuroscience and neurobiology such that mechanisms and neural underpinnings are studied at or alongside if not prior to determining the supposed cognitive

mechanisms mechanisms in play it's you know there's a kind of um you know in an interview he said like oh we'll take any you know college level uh psychology class and look at a lot of the terminology that's being used then and then go to you know some of William James's classic work and have a look at the table of contents and you'll realize there's a lot of the same terms that we're using today right

But perception and perception is broken into so many different sorts of meanings and is used differently in their debates over what perception is.

And active inference kind of inserts itself into that debate to say, well, yeah, there's perception, but we don't just

passively perceived things, which is kind of a kind of artifact of the 19th century.

And it's its take on on something like what was emerging in a later called psychology, which is, you know, the idea that we're just kind of passively taking in sensory stimuli.

Instead, we're acting in the world, right?

And we pick up objects, we look at them from different angles, and we sort of test our beliefs, you know, and that's part of the learning and inferential process.

And again, that kind of bounded rationality notion, right?

We're in bodies and we're functioning.

So all this is to say, it's interesting, one, to kind of situate active inference within a broader historical context, one that is contending with sort of the history of psychology and the social and behavioral and cognitive sciences.

And also looking at it in the context of today, the world of AI, where you could effectively make an active inference agent who does a variety of things that anyone would want them to do as far as something like reinforcement learning goes, right?

Like they're taking in data or observations, and then they're doing different kinds of inferential processes, and then

emitting some kind of output, depending on what kind of actuators you connect to it.

So if you give it arms, then it can maybe move its arms and so on.

So the book, nonetheless, is trying to kind of rally together a lot of these different disciplines.

So we look at

anything from cybernetics and kind of control theory.

We look at its relation to more general notions of predictive processing, which is a rather broad category.

Also a relationship to predictive coding is a sort of subset or variation of predictive processing.

we're kind of re-re-reintroduced to the Bayesian brain hypothesis, which is heavily related, of course, the notion of the brain does something like, it's still a matter of debate if we're saying it expressly does this or if it does something like, but we could say at minimum for active inference, it does something like updating its beliefs using some kind of prior information in order to infer some sort of updated belief or a posterior belief.

We're looking at action control theory, ideomotor theory, reminded of proprioception and kind of motor commands and movement, utility and decision-making, which then can start to kind of actually look like something like economics.

And we know that there are these risk terms that are kind of interpreted from some variations of the expected free energy formula.

Again, behavior-bounded rationality,

Valence, emotion and motivation.

I've personally always kind of found that interesting and that touches kind of on psychology again and cognitive science.

But I've repeatedly shared this paper with others just because I think it's kind of enlightening for those who are kind of starting to get more deeply into active inference.

It seems like people commonly come across this one deeply felt affect, which is a few years old now.

But it just, you know,

lot of these kind of names on the paper are you know some of the kind of the early kind of who have done a lot of the the kind of heavy lifting with developing active inference and sort of finding ways to formalize it advance it uh teach it and uh who are still very active today and this is a nice like you know in some ways it falls in line with with in affective neuroscience uh the work of

Uh, there are some who would not like that.

I, I say this, but I still see the connection with, uh, with something like socially constructed affect or not affect, but rather emotion.

Whenever trying to talk about like, what is emotion?

What is, you know, what, what does that mean?

How does it work?

So we have, you know, in some variations we have like, um, and the idea that emotion can be broken into like, you know, seven or so discrete categories and then any kind of emotional.

know expression that you see someone have or they say they're feeling some kind of emotion it's going to be somewhere in the realm of of those seven categories as if they were like clusters that were extracting from a bunch of noisy data or something like that um you know that that would then be linked kind of to to the more archaic area of our of our brains and be related to evolution and we have this and then there are others who you know do this more socially constructed idea of emotion where actually

It aligns with active inference as far as my take on it goes, which is that the idea is that actually it's your body and interoception that generate a significant amount of signals that we can then observe.

So it's not that we start with feeling sad and then we feel a tightness in the stomach or some other kind of bodily feeling, a feeling of lowness or exhaustion or something.

instead it's the other way around it's like we start feeling the observations first then we start to infer like oh I must be sad right like that it's actually that kind of direction and and it's quite similar to active inference whenever we think of of state in uh state inference right because the idea is that you're taking in observations and then you infer a kind of hidden state of the world or belief including beliefs about one's own body and then of course we have you know human language is you know a way

or attempt to articulate what those feelings are.

And so actually it's saying you're sad is coming after all of that, right?

Is one take.

In any case, it's very interesting to see, like this is one example of kind of how using an active inference sort of framework can actually help us to interpret or reinterpret

a broad variety of phenomena, just by kind of relying on or sticking to some of these normative framework, like, you know, perspectives on what is what is hidden state inference?

And what does that say about about emotion or emotionality and then

Um, how do we, how do we construct those things and how do we, you know, how do we model them?

And so I just thought I'd spend an extra minute on this just because it's sort of an example of, you know, the many active inference papers that have been published.

It's like, well, yes, we can talk about these sort of everyday phenomena, seemingly everyday phenomena.

uh you know like like emotion or or affect but then what we can do is actually start to sort of formalize different kinds of models consider like okay well if we did have to make a model that was simple as possible but no simpler um what what does that look like in order to properly model emotion beyond just you know at some point the ideal is to fit it to empirical data but even getting you know even prior to that how do we how do we even start imagining this we've had questions in the past

from learners who say you know what what if you have bad what if you're modeling something what if your priors are just bad in the sense of like what if what if they don't work appropriately or what if they don't lead to the sort of the optimal or expected outcome that you know that we have um you know isn't that kind of a funny thing to you know include poor priors in the beginning and I mean

whenever we're getting started on modeling, we just don't, we don't know, right.

You use prior literature that's been published or developed and ideally, you know, peer reviewed and, and you move in the direction of, you know, you have a hypothesis and you, so you end up having your own hypothesis about the model.

And then, and then you, you kind of try different things and then you try to fit it to empirical data.

And, and that's sort of the interesting aspect of,

of active inference and other models that kind of work similarly is that, you know, you might start with bad priors, but over time, if the model engages in different kinds of inference and learning, you know, processes, then ideally it gets better in the same way that someone who doesn't know calculus can sit down and start studying calculus.

They have awful priors, presumably, because they haven't learned anything about it yet.

And over time, they learn it, right?

Hopefully.

So that's kind of the, you know, we find ourselves on the outside here.

We are constructing our own kind of objective model or almost think of it like we're creating an object out of, you know, an agent and then trying to understand them and kind of how they work on the inside, right?

So anything else?

I think I've largely covered a lot of this.

We also talked about

attention salience and epistemic dynamics which is uh an interesting piece you know and we didn't cover these terms too strongly in this in this uh particular run of the textbook but uh we know that that attention is related to to something like precision

So the idea of like kind of sharpening one's precision in the sense of, you know, how certain are you about your beliefs or how certain are you about the stimuli that you're receiving, what you're observing, right?

You imagine someone who's kind of sleepy and so they're not fully taking in what's going on in their visual field is kind of a crude, quick example, right?

Versus someone who's, you know, fully taking in sort of the moment, but these very kind of,

know everyday use of terms here um but but

We've already made it through a lot of the kind of mechanical aspects and formula and hurdles in the textbook up to this point.

So I'm just avoiding rehashing them.

Relationships with causal inference.

How do you establish causality in these kinds of models?

The nice thing is that whenever you construct a model like this, like we're constructing, if you can view a model kind of as a graph, and then you can kind of start to look at the flow of it,

Or whenever you look at hierarchical message message passing like we saw in Chapter five and you can actually see.

You know, we can start to look at these models it's like nodes and edges and with a kind of directedness in the in the edges right so passing matches messages from from one node to another or from one variable to some other.

piece of the model, whether it be, you know, some kind of equation or conditional probability distribution or otherwise that connects them and relates them and allows for inference or reaching kind of the end or a kind of like delta or clamp.

Essentially, I mean, it's, you know, sometimes modeling is as much an art as it is a science.

And I think many other people would be quite inclined to agree.

And then,

A few more things.

We already know that this is heavily related to machine learning.

We saw a lot of examples of other models in chapter four before we got to what eventually we understood to be the POMDP model.

It's like, yeah, you create a machine learning model or a linear regression model or something more simple.

But the idea of being able to take in values using some kind of transformation in order to

you know, elicit some kind of output that's a broader theme.

Robotics, which has been very, you know, very interesting to see, you know, the sort of developments in robotics.

I've spoken with a couple of recent learners who had interest in, excuse me, I'll find a better way to, but there is a,

And I just, I hope I can find this if I can't.

And if there's anyone who's interested in it, I'll, I'll share it again in future.

But, um, this is a few years ago, so there's going to be a lot more by now.

Um, active inference robotics.

Yeah.

So, I mean, there, there, you know, last year we did an entire symposium.

Robotics was a theme, um, you know, with the, with the Institute.

And then if you just kind of browse around, this is 2019.

And active inference for robot control and and there's this again 2019 so so it's just because because I think in the theme of Chapter 10 of kind of the breadth of what active inference can touch upon or cover.

or relate to or inform, this is just like looking at the breadth of, you know, these kinds of principles can be used like in real world settings for those who are interested in like, you know, business or enterprise or productions or something like that.

I mean, you can use them to create actual, you know, effective agents who operate within the world, right?

Whether it be some kind of, you know, real time,

online learning, you know, model that's, you know, repeatedly taking in data.

It could be, you know, robotics.

We know that from last year there was an active inference, like a drone that was built and showcased, though sadly there's no, there probably is a public video somewhere, but at the, yeah, yeah, directions of travel and active inference.

Anyway, I'm jumping around a little bit, but it's just to show that this can relate to a variety of fields.

And of course, many of the folks who started first in the rest are quite familiar with a lot of these other fields.

So it's just to say that active inference is more so start.

It's starting a conversation with other fields.

It's continuing conversations with other fields.

And all the while, it's kind of establishing its own normative framework, which, in my opinion, is highly interpretable because we have capacity for relating a variety of functionalities and formula and equations in models to actual terms like habits or planning or what is perception and these other kinds of things.

Is there anyone who would like to touch on anything in particular?

Yeah, John, please go for it.


SPEAKER_01:
Yeah, so I have some concerns about some of the wording in this chapter, and I'd like some clarification.

Let's see, I'm doing the control F thing.

What?

Oh, let's see.

Okay.

Sorry.

I thought I had this queued up.

To go through again.

So, okay.

So one of the things I have concerns about is it says that one benefit of active inference is that it provides a complete solution to the adaptive problems that a sentient organism have to solve.

What do you mean by that?

Because a formal system can't be complete and consistent, among other things, like

Normally, if I hear someone say they have a complete framework of everything that has to do with thought, it sounds a bit odd.

So I wonder what you mean by complete.


SPEAKER_03:
No, good.

No, good pointing that out.

And I am also rather suspicious whenever someone, you know, it almost sounds like a sales pitch or something to say that something's, you know, good.

before a complete solution, you know, end all be all.

So here, I mean, I've always interpreted that as it earlier on in the textbook, they, they, they give this explanation, you know, whether it's necessary or not, they give an explanation of what they call the, the needs versus scruffies needs always seek unification beyond the heterogeneity of brain and mind phenomena.

which usually corresponds to designing top down normative models to start from first principles.


SPEAKER_01:
Meanwhile, just because something's just because something's from first principles doesn't mean it's complete, right?

All math is from first principles.

No math can be complete.


SPEAKER_03:
Yeah.

Yeah.

It's so they're not, they're not necessarily saying,

they're not necessarily making some broad ontological or epistemological statement, I think, from my understanding of this.


SPEAKER_01:
It is kind of a weird thing to say, so I wonder what they mean by that.


SPEAKER_03:
Well, what it does do, what I do think they mean by it, or what kind of value there is to take away from that sentence, so I do kind of implicitly agree that maybe it could have been reworded to make it clearer on what they're going for, but

I brought up the neats versus scruffies bit because the scruffies idea is that there are a lot of, you know, it's kind of like imagine a lot of researchers who are sort of, you know, going against the grain and they're moving in their own kind of unique direction and they're going after, you know, whatever it is that's driving them or they're working with a team or, you know, have some kind of funding or otherwise.

whatever it is that's kind of drawing them towards wanting to hyper focus or specialize on a particular phenomena, potentially to the detriment of looking at other phenomena, then what happens is you can potentially end up with someone who's so terribly focused on perception.

that they leave out action or they're so focused on planning that they leave out attention.

And so my take on this is that it's trying to say a complete solution in the sense that the book is focused on something like sentient organisms.

What is the task that they're trying to solve?

Active inference as a framework where it's saying they're not trying to model necessarily the entire brain.

It's kind of focused on a sort of belief space framework where agents are trying to solve a problem or a task, whether it be as simple as the autonomic system who is breathing and regulating blood oxygen flow to a mouse in a tea maze or an entire society trying to function within an economic system.

and and so with that it's like well now we we have an understand it provides a kind of understanding or or solution for understanding all of these different phenomena right is it ever going to be fully complete i mean i that's you know well no that's mathematically impossible

Yeah, if you want to take that hard line assumption that this is about mathematics, but I don't know if this sentence is purely about mathematics is all I mean to say.

I think it's more about describing a kind of perspective, and that's the issue, right, with theory is that

we're dealing in words and in sentences and full you know pair things can get kind of meshy for lack of a better word it's it's about as ambiguous as i think this statement could be interpreted as if looked at from particular angles so okay but i have concerns about this other phrase too and it's sort of the same concern because they kind of go together it says


SPEAKER_01:
uh what does it say it says evolution appears to have discovered increasingly sophisticated design structures for brains and bodies that made organisms able to deal with and shape rich ecological niches fine but then it says modelers can reverse engineer this process and specify brains and bodies of the creature of interest in terms of generative models like really you know how to build a cat


SPEAKER_03:
it's so with that let's see let me just make sure i understand it in context complex pursuits yeah yeah yeah so i mean i mean in a sense yes to answer your question in a sense yeah i mean in so in chapter seven we look at the teammates example right like that's like a really simple thing though it's not like


SPEAKER_01:
You couldn't build a cat brain in the laboratory using that, or as far as I can tell, any of this.

The idea that you're reverse engineering, and that you can specify the designs for brains and bodies, that implies that you could make one.


SPEAKER_03:
Yeah.

I mean, it's not...

it's not contradicting like yeah yeah it it is kind of saying that in a sense you're still ultimately modeling it right but you're so you do have to make decisions but it kind of goes back to what i was saying earlier it says you can specify the designs for brains and bodies that that implies that you can design them because if you have a design you can design it right are you are you trying to point out the the the separation between actually modeling uh you know a

a cat's brain, for example, versus the reality?

And are you making an assumption that we'd never be able to do that?


SPEAKER_01:
Well, no, it doesn't matter if we'd ever be able to do it.

The problem is we can't do it now.

And so say modelers present tense can reverse engineer this process and specify present tense, the designs for brains and bodies, the creatures of interest.

That's it's a weird thing to say.

That's like Victor Frankenstein almost like I don't


SPEAKER_03:
Sorry, to be honest, I'm not really sure how to address this much further.

So just to stick to the textbook, Chapter 7, they make a mouse, right?

They model a mouse.

They model it in a T maze.

None of it's real.

So the formal technical term for that would be in silico.

And so that is what they do.

It's not the design of the brain and the body.


SPEAKER_01:
It's just a very simple model of one aspect of something that a mouse can do.

I believe in that model, which is very simple.

The brain of the mouse and the body of the mouse aren't even really in the model at all.

They are and they're not.


SPEAKER_03:
I agree that in a literal sense, no, they're not.

Uh, what are you trying to, sorry, John, in what we're trying to do with, with active inference is that we're just trying to model the, you know, it is expressly what the textbook states.

It's just trying to model the problem that the brain is trying to solve in that instance.

If you think that the problem.

That the organism is facing is much bigger, such as, you know, oh, it's not a mouse in a T maze.

It's a, it's a mouse.

you know, in, in the woods or something, you know, and to where, to where you have now, you have to create like a broader environment, maybe create other agents who are in there as well.

Maybe there's some kind of, you know, a world design where they, they have movement that goes beyond just moving left or right or moving to a queue.

Instead, it's a much more like a broad, like grid, discrete space, or maybe it's continuous space or, or otherwise.

But I mean, that's a temp, you know, that's in a sense, we are trying to,

anyone who's modeling something is trying to recreate its dynamics to better understand how it functions.

And so I just kind of quickly Googled like cancer modeling.

It's like this, the majority of research is being done on cancer is involving computational modeling of cancer.

So while I do, I think I do, I kind of sympathize and understand maybe the point that you're making, like, you know, but it's not to say that there's some kind of hubris of saying we're going to model the brain perfectly.

We're going to reverse engineer and we're, you know, just assume that we can just magically do that.

But it is making the point that like, this is, this is what most,

most people are doing in a sense that, you know, I, maybe it's not worded well, maybe it's a little bit clever to say like, oh, well, if, if, cause, cause they're relating it to other fields, right?

So we're looking at, you know, they relate it first to evolution.

It's kind of like saying, well, evolution is what's kind of producing the reality of, of the organisms that we find in the world around us.

But then from the other end, it's like a modeler is attempting to reverse engineer that they're attempting to kind of

create that or recreate that in kind of like the opposite direction.


SPEAKER_01:
I understand what modeling is, but I think my problem is really more with two words here, specify and designs.

Specify implies that it's specific.

It's not just some general vague thing that simulates some aspect, but the specific design for the brain and the body.

And then designs, of course, implies you can build one, but no one can build a cat.

So I'm just perplexed as to why it's like this.


SPEAKER_03:
Okay.

Yeah, I don't know.

I think we might have to kind of agree to disagree on this one a little bit because I don't fully, I mean, that is, you know, that is what we do.

If I sit down to kind of model, I don't know,

I don't wanna get too far away from the example we're talking about, but if I wanna model

like, I don't know, the end of day stock price from financial data, like I'm gonna have to make some decisions on how to do that, right?

I'm gonna have to specify some things and I'm gonna have to design some things in order to make that happen, right?

So I think these are rather broad terms.


SPEAKER_01:
Yeah, but you would specify the designs for plants, which is easy.

Specifying the design for a brain is not easy.

I don't think anyone can do it and it's,

not a thing I would say.


SPEAKER_03:
There has been some interesting work.

There's been some attempts to do this.

I think there are plenty of people who would still agree with you.

But I mean, there are folks who at least have the aspiration and are even, you know,


SPEAKER_01:
I know there's an aspiration, I sort of hear it myself, but to suggest that it's already been achieved is... Yeah, if I can jump in.


SPEAKER_03:
Yeah, please do, Steve.


SPEAKER_00:
I take John's part here.

I'm very sympathetic to what you're saying, John.

I also just assume there is so much not said or rather implied in the textbook

that I don't take it to a mathematical precision.

The words are an approximation of what is intended.

And I completely agree that this isn't a closed system.

And if it were a closed system, it could not be completely described without, I mean, consistently completely described.

And I really think what you're bringing up is worth bearing in mind always that a model is not the system itself.

It's a model of the system.

Designing, saying that the brain can be reverse engineered, I just assume that means

an approximation of the architecture.

can be created based on this framework.

I think too many people do have the assumption that, yeah, the brain can be created, can be re-represented.

And I just don't think that's possible.

The complexity is beyond the ability at this point in our technology.

But it's, I think,

intending to mean an approximation, always.

That's my take on it.


SPEAKER_03:
Yeah.


SPEAKER_01:
Well, yeah, so it would probably... Okay.


SPEAKER_03:
Sorry, I'm just seconding that.

I mean, that is essentially what's going on with the modeling, whether it be an active inference or otherwise, but it is made explicit.

I mean, I agree with you both.

The complexity of actually modeling the brain, and not only that, but what would be

You know, another question, a whole nother question that comes up is what would be the purpose of that?

I mean, we, we can maybe intuit like, oh, it would be interesting where we'd find some kind of realization, but it's, I mean, we start to get a little close to sci-fi, right?

It's like, well, once you create the brain, it does, it's not really a brain of any particular person.

It's its own thing.

Now it's going to go off on its own trajectory.

So now is it even reflected?

Is it going to be useful for simulating or studying anything?

If you, if it's, if that makes any kind of sense.


SPEAKER_00:
Well, you bring up a good point of why it's really useless to try to create AGI in the way we think of it.

I mean, to create artificial intelligence that thinks just like a human, you would have a human intelligence.

So wait, we have that already.

What's the point of that?


SPEAKER_03:
Right, right.

Exactly.

It's like, you know, it's, it's so superhuman immediately.


SPEAKER_00:
Then it wouldn't be what we think of as it would be something else.

That would be wonderful, but it would be something else.


SPEAKER_01:
I want to talk about this thing of modeling and approximation.

Cause like sort of everything in science is a model.

there are different kinds of things in science there are models that are precise enough to build stuff with and there are models that aren't really precise enough to build like real world things i'm not talking necessarily about computer programs um there are models that aren't really precise enough to build real world things and by saying that you can specify the design you're suggesting that you have enough precision to build real world things but i i haven't seen uh

i haven't even seen that claim or anything like it made anywhere else in this book uh like i don't know it's odd yeah it's it's a it has a different meaning than what i think you take it as or it has we have to assume it means something different otherwise it wouldn't make any sense just as you're pointing out yeah there is a i'm mostly asking for clarification i want to know what what what that what does that mean why would you write that


SPEAKER_03:
Yeah, it is a strong piece that they, you know, that was quite a choice, I guess, for lack of a better phrase.

I mean, they expressly say earlier in the textbook, like they are not trying to recreate or even emulate the entire brain piece by piece.

It's to find a generative model that describes the problem the brain is trying to solve.

And that might not be, you know, that might not be a particularly satisfying sort of, you know,

TAB, Mark McIntyre, that might not be a very satisfying take for those who are interested in doing something like trying to recreate the entire you know behavior the of the.


SPEAKER_01:
TAB, Mark McIntyre, Sorry.

TAB, Mark McIntyre, i'm all for it, if you can do it it just saying that you can do it when you can't do is.


SPEAKER_03:
Yeah, they, I think it's a, it's a mistake for them.

I think, well, I don't think that sentence should be read so literally.

Um, but that, that is, that's kind of my final word from myself on my opinion on that.

Cause I think we're, I'd just be belaboring if I tried to describing it more because the whole, I mean, if whenever I see that phrase, for example, complete solution,

You know, if I think about in terms of mathematics, it looks ignorant or just incorrect.

Like, why would you say that?

But if I look at it from the perspective of kind of the neat scruffies, but right where I mean, you do have a broad variety of different departments doing very different things who have very strong debates with one another.

if there were a way to model the brain, you know, piece by piece, as we were talking about earlier, I imagine it would at minimum take many more of these departments coming together and agreeing upon a few things in order to even get going with something like that, not to mention the kind of funding that might be necessary to realize something like that.

As long as fields stay broadly disparate, including how they use words, their ontologies,

You know, I think debates are fine, but but I do appreciate, in a sense, the attempt to make kind of a broader framework.

Is the word complete well used or even relevant here?


SPEAKER_01:
Probably not.

But the other thing is they do it twice.

So on page on page.

On page 196, they do it again.

They say it, that means active inference, starts by providing a complete solution to the problems that organisms have to solve.

So they say it twice.


SPEAKER_03:
To the problems that organisms have to, okay, sure.

Yeah, I don't know.

I think we're, I don't know.

I mean, they said what they said.

Sorry, go ahead, Stephen.


SPEAKER_00:
I mean just that statement then immediately brings up the question in one's mind, well, in what sense are we talking?

Complete solution.


SPEAKER_01:
That's why I'm mostly asking for clarification because I assume it can't mean what it says.


SPEAKER_00:
Yeah, I agree.


SPEAKER_02:
Yeah, that's like author's framing.

The book you write gets to have it how you think.

But I'm also thinking, does a wing and an engine provide a complete solution to the problems faced by flight?


SPEAKER_00:
Right.


SPEAKER_02:
Yes, but that doesn't mean that any given plane is going to fly or any given company is going to work.

It's not a guarantee, but it's like, but yes, between lift and thrust, between sensemaking and cognition and action,

it is like the scheme of a complete solution to the problems of the kind that they do face yes any given inquiry is going to be successful but but it it is like okay the complete meal is the main dish and the side dish doesn't mean you're going to have a successful restaurant but it is a complete approach to cooking dinner if it has those two components yeah


SPEAKER_03:
It's like the idea of, you know, perception without action, right?

So that was my attempt to kind of contextualize some of these things, which, you know, there's an entire subfield known as intellectual history, right?

That people try to like do this kind of hermeneutical or exegetical approach to the study of literature, including psychology or otherwise looking at the ontologies, extracting them, relating them to one another, contradictions and

and all of that.

And so it's kind of like active inference is kind of placing itself in a certain part of that trajectory.

And, you know, they have their own take and they're claiming, maybe they should use the phrase more complete.

I think that would get closer to maybe what they're actually going for.

You know, more complete than hyper-disparate.

Yeah, yeah.

But we're not the authors, so.

Yeah, so it goes, damn it.

Food for thought, but it's still, I mean, it's still a good question, right?

Because it does open up onto these bigger questions.

And, and, and, and also to Steven's point earlier, right?

Like at the end of the day, we're still making proxies.

So if you, if you quote unquote design or specify or design the brain of the mouse and the teammates, it's like, well,

No, you're not really.

But in a sense, you you are in this only in the sense of if active inference is making the claim that that the brain does something like perception action as we've described it and looked at state inference and policy inference and so on.

Then it kind of like you kind of are because the mouse is.

carrying out the the hypothetical in silico mouse is carrying out those processes right we're just kind of running the code that represents that well i thought it would just enter in the last um four minutes could you look at read isabella's question yes up in the chat and just give it first anyone can give the first thought on that and then we'll end in a few minutes yeah absolutely uh no and thanks for your question is about what is the relationship of active inference and autopoetic

uh systems it just occurred to me robots can perform active inference while not being autopoietic and there are living systems without central nervous systems like what does it mean about the relationship between active inference and life so let's just um we we do see

this term in the textbook but just to like get a quick like autoprocess self-making a system's ability to self-organize self-reproduce and self-maintain through its own internal processes so one interpretation of that is you know to ensure their own reproduction and maintenance well with robots yeah not so sure about the reproduction part maintenance

potentially right like like you could have a robot that maybe it doesn't necessarily reproduce but it might have actions that are available to it that it could then use to or or have available to it to take care of itself but i mean that's the that's kind of what separates the the the claim in the textbook about what evolution is led towards such as beings such as us who who who are

you know, able of not just reproducing, but also full maintenance versus a robot that, you know, if it doesn't have arms to reach for the power cord to plug itself in or something along those lines, right?

It's kind of a silly way of saying that, but in any case, but that is a broader philosophical question as well.

You know, what is the relationship between this and life?

There are, you know, there are many people who have made claims about things like panpsychism,

uh, things like, you know, well, if you, if really something like sentience or something like, you know, active inference related processes, uh, are just kind of like mathematical formalisms that are playing out before our eyes, thanks to, you know, the Hamiltonian path of least action, uh, or, or other kinds of physical processes, then.

Is it the case that many things that we didn't think of as sentient before in fact are?

Is it not the case that like a rock rolling down the hill because of a variety of, is it not doing some kind of state inference?

These are larger debates that one can engage in, but I personally, I don't really follow that line so much, but there has been some really kind of philosophy of mind, active inference,


SPEAKER_00:
yeah a reference in the chat that is related to that the the handbook of abductive cognition uh kind of gets at this whole epistemological issue of what are what is cognition uh how do we know what we know how why do we call something sentient and not other things uh you know a self

regulating system that is not even biological, you know, chemical processes.

We don't have to imbue any sentience to that.

It's just a natural process.

And just in the same way that biological systems are natural processes, but biological systems interact with the environment in

adaptive ways, self-generating, self-perpetuating adaptive ways.

I think Isabella's question is relevant in that active inference is a way of describing processes in any framework we want to place it.

If it is self-perpetuating or not, you know, evolutionarily,

versus in this closed timeframe, in this single environment, closed timeframe.

We're still talking about the same natural processes.

I think variational free energy is describing a system and we just decide what that system is that we're applying it to.


SPEAKER_02:
yeah and it's a great a great connection with the abductive logic and the pragmatism and the open-endedness of evolution because it's like the successive generations intergenerationally or successive beliefs or hypotheses intra-generationally like behavior they aren't just induction deduction

elevator rides they're moving laterally and generating new pieces and new compositions in the sort of open-ended reconfiguration and then the niche sweeps it off the table if it doesn't maintain autopoiesis in actuality but that doesn't mean that every map you make of that territory is describing its autopoiesis like in the teammates it's just taken for granted we're talking about a behaviorally alive mouse


SPEAKER_03:
yes we're not studying the autopoiesis of that mouse but that might be another inquiry yeah yeah it is a classic kind of phrasing that's been used in active inference and elsewhere but the idea of like you know the map is not the territory and that relates back to you know what we were talking about earlier with uh with modeling but anyway we got kind of you know broadened it's you know

In reference to that bit about overcoming old categories and 19th century kind of constructions, it's like the notion of sentience.

I'm not sure if going back to read William James or even something from the mid 20th century,

actually is going to align well with whatever it is that we're discovering in in modern science same thing for any notion of things like consciousness right i mean for some consciousness is literally just like you know you're going to put someone under anesthesia you need to make sure they're unconscious you use you know an eeg you know headset or or otherwise to try and measure quantum consciousness is like a quantitative signal and that's it right it's not even it's not a big broad philosophical category it's literally just a pragmatic

practical concept that is useful there in medicine.

Others will say, you know, dramatically different things.

So it's always an interesting conversation.

In any case, we're a few minutes over.

So thank you all so much for your questions.

Sorry, Isabella, for only getting to the question at the end, but I hope that

that kind of sub conversation was helpful in some kind of way.


SPEAKER_02:
Thanks.

Also just look at this book, $699 for the ebook.

Let's get it.

It's worth it.


SPEAKER_00:
It's hard to get copies.

I have to do library loan, you know, scan chapter at a time.


SPEAKER_02:
Wow.

Cool.

All right.

Thank you all.

Bye.

Thanks everyone.