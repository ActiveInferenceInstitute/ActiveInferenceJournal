SPEAKER_03:
Welcome everyone to the Active Inference Institute.

This is week one of running through cohort seven.

We're starting with chapter six of the textbook.

This is beginning the second half of the textbook.

As we know, in the first half, we're covering a lot of the fundamentals of active inference.

You know, we started with an introductory chapter.

environments, looking at a lot of basic fundamental principles behind ideas regarding behavior of sentience organisms and so on.

We're looking at neural process theories.

And so how is it that neuronal populations perhaps function in a way that leads to

different kinds of inferential processes such that uh you know beings kind of get around the world they update their beliefs uh they they make particular decisions and kind of weight those decisions amongst one another uh they they have things like attention uh we've been introduced to terms like

precision modulation that in the literature gets related to the idea of something like neurotransmitters and and in transmission and a variety of other topics that that you can you know have a look at uh we tend to publish these these textbook reading chapters like these um sessions that we do and so you can review those on on youtube under the active inference institute channel

and then uh we'll start quickly here this is the cohort for anyone who's uh new this is a cohort uh seven uh page of the coda so we use coda is kind of like this open uh platform and forum for anyone who's not familiar with it um you can like actually just go in here and depending on like as long as you've registered for the textbook you should be able to like edit particular things you can place um you know their pages for for communications

we have pages that involve like you know different equations figures that are within the textbook for quick look up and reference being able to index them to like a natural language description of what each of them are uh which has been incredibly helpful for people to just like you know rather than being stuck within a single chapter it helps to get a broader holistic sense of what's going on in the textbook and then um let's see this course

yeah questions these are sort of like major ongoing questions this is a kind of an overview this is not specific to any particular cohort right and so that allows for this kind of nestedness of you know

inter-cohort communication and kind of leaving each other in a stigmatic fashion, notes for one another, different things that people have been contending with in their minds, like what is surprise minimization?

What are these things like the high road and the low road to active inference that we get introduced to in chapters two and three?

Why are we phrasing things this way all the way down to like deeper?

A lot of topics in this book are kind of thought provoking for a lot of people.

It brings up a lot of questions about what is consciousness and what is life and panpsychism and all kinds of interesting additional topics that we may not cover directly in the textbook group.

but it it kind of begs the question for a lot of people some of these things so so it's a it's a very interesting useful kind of historical Archival most of questions about you know and then section into each chapter so that way you can kind of like see what else is you know going on in other people's minds and thoughts so uh we also

We previously were running a math learning group, I believe it's still ongoing, with someone who goes by the alias Octopus, but they're very smart.

And this has been very useful to a lot of people because a lot of people are coming in to active inference, not necessarily having a background in mathematics.

They don't necessarily have an intuitive sense of matrix operations or what a Taylor series approximation is and things like that.

So it's very useful to have kind of like these groups

sources that perhaps kind of spring up around the textbook without being confined to just the textbook itself.

So we have, you know, plenty of other things.

We have some resources regarding like telling you about like PyMDP I mentioned earlier.

uh you know there's coding documentation so it's a it's a very kind of open science environment where it's you know it's it's this is not a deep hierarchical uh structure that we have right so a lot of people contribute what they want to contribute and they kind of you know hope to to get out of it what they put into it and vice versa and um yeah so that that's it I would say that's a decent um introduction and then there's also the onboarding page I'll also mention that quickly where you can um

You know kind of gives you overview of what's going on in the coda, and then we can also get to like accessing the um

the textbook itself I want to mention that um like so the the textbook is freely available now uh as Daniel mentioned earlier it's been around for like nearly three years now so already to this day like there's been an immense amount of research that's been published since then um I would say that many many many of the core principles ideas even equations in

the textbook are still highly relevant today.

That's part of the utility of continuing to go over the textbook rather than treating it as if it were something that's already obsolete.

But then that said, I mean, for anyone who's come here because they saw Fristen's pixels to planning paper and renormalization,

uh generative models and and all the interesting the things that have come out much more recently that you won't find them in this textbook you will find many of the kind of guiding principles that went into the design of those models however so once again like you know

if there should be a central node for learning active inference I personally would argue that it should still be the textbook probably um so to move on from there uh so yeah we're looking at chapter six today um uh

Normally, I provide a very long summary, sometimes too long at the beginning of these sessions whenever I'm the one leading the session.

I'll try to keep it a little bit shorter, especially because in the same way that Chapter 1 was an introduction to Active Inference, the reason why we split things up this way is in part because when you start Chapter 6, it's actually like this is officially the second half of the book.

in the sense of it kind of has its own foci that it looks at so the second half of the book is going to be much more centered on modeling and directly modeling uh active inference agents and environments and and so on as opposed to many of the like kind of natural language descriptions core concepts you'll still find some in the second half of the textbook so it's worth reading the whole textbook uh whether you're

interested in cognitive modeling or you're interested in the philosophy or phenomenology of mind um so with i guess i'll get into it then with chapter six this is a very general kind of chapter

post to the rest of the book, maybe aside from chapter 10, which is just a broad overview of a variety of disciplines and how they relate to active inference.

So for anyone who's also new to active inference, actually jumping to the end of the book, chapter 10, where we suddenly get to see a clearer picture of how a variety of fields from like psychology, study of emotion and affect to robotics and cybernetics and

even economic theory, all have their own kind of interesting interrelationships with active inference.

That's actually at the end of the book.

So jump there if you're coming from maybe a different field and want to see how this relates to your own field.

chapter six is a recipe for designing active inference models uh and so this is really just kind of providing you something like a recipe or uh you know the second half of the book can be read almost like a cookbook uh in the sense of let's decide on uh just a couple of exemplar models that could be used in particular scenarios and then from there uh what are their core elements and then

Yet again, from there, you can start to figure out how to adapt them to your particular use case or phenomena of interest.

So with chapter six.

They tried to boil it down to something like a simple four step recipe.

This is one of the relatively shorter chapters in the book.

It's like an introduction in the second half.

I do want to point everyone out, point out to everyone this is I've always found this

rather interesting.

Unlike many other approaches to computational neuroscience, the challenge is not to emulate a brain piece by piece, but to find the generative model that describes the problem the brain is trying to solve.

Once the problem is appropriately formalized in terms of a generative model, the solution to the problem emerges under active inference with accompanying predictions about brains and minds.

So you can kind of see how, you know, as opposed to some sense of let's model some, you know, several billion neuron kind of brain model, this is more about trying to model a system for anyone who's read

the first half of the book, you've already become familiar with the notion of a Markov blanket.

And so it's kind of like, can you identify a particular system of interest?

It could be a person.

It could be just a particular region or substrate in the brain.

It could be an entire

like society and having nested markov blankets but the idea is that the yeah the markov blanket allows us to sort of delimit the particular thing uh or system that we're trying to model and understand and and so whenever it comes to like modeling let's say like a artificial or theoretical

person who has a brain the idea would be not so much that you need to model every single facet of them you're actually modeling just what is of interest what what holds well together what can be tested what has different kinds of physiological uh substrates and can be traced back to neurobiology so we make sure we're not running too far off into artifice land and um and so

very typical modeling concerns and problems that are found in data science or economics or machine learning.

Essentially, how do we model something and how do we do it in a way that is generalizable such that it can extend beyond itself?

I've created an agent

it can be in this situation it can be in that situation but then also we we needed to to hold to realism right and being able to trace it back to the literature and and testing refining going back and forth and so on so

that's kind of what chapter six is trying to set us up for um we're just looking at what what does it make sense to to model so that's that's why I've always found this interesting we're looking for a generative model that in a sense represents sort of the the mind if I keep going with this artificial person that we're modeling to use an example of that and we're looking for the the generative model that they kind of hold

uh say we model a person who is engaging in a behavioral task for example then what is the model that they would be using uh you know for that if they're if the task is to play some kind of card game then do we necessarily need to model a variety of like other facets of that like like do they have to be able to feel hungry or not or is that

not really relevant to the particular situation that we were modeling um and and it's there that that's what this chapter centers around in the sense of how do we choose uh what to include in our model and and starting with step one what even it what direction should we go and trying to decide what the model should be which system are you modeling right so I've kind of kind of loosely already covered

uh the sense of that we see um this may not be as simple as it seems it rests on the identification of the boundaries i.e markov blanket of that system and it might be useful actually now that i do have the coda it would be useful to have a look real quick this is a classic figure um you know move the um thank you

Oh, yeah.

Sorry, I'm not sure what it looks like on my screen.


SPEAKER_01:
Just the Zoom windows, I believe, the vertical and the horizontal bar.

Yeah.

Aren't grayed out, but it looks good now.

Thank you.


SPEAKER_03:
Okay.


SPEAKER_01:
I see.


SPEAKER_03:
So...

So in this case, when we're modeling a system of interest rate, it's kind of like on the left here.

This could represent our environment.

And then on the right, this could represent our agent.

The terminology is for an agent.

That's the generative model.

And then for the environment, it's the generative process.

I won't say that those terms are necessarily arbitrarily chosen, but it can, you know, for some people who are new, using the word generative very frequently, it might be a little confusing at first.

So I'll just say that for the agent, usually the agent that we are interested in modeling, and one way of phrasing it, someone else has phrased it this way, I believe it was Mark Soames, who's worked a lot with Carl Friston.

It's kind of like we're modeling a system of interest, that being our agent, or

And then the environment is kind of like the not system.

Sounds very informal or even colloquial, but the sense is, what is not your agent in this situation?

Being able to draw that kind of defining line.

And then what is it that actually allows your agent to interface with this environment or survive within it, if that's the kind of paradigm that you're looking at, or to interact with it in some kind of way?

And so it's it's here where the agent commits actions that then affect the environment.

It's not a direct one to one relationship.

It's kind of like we have this sort of vicarious relationship between the two where an agent commits an action, which is becomes kind of metaphorically an observation.

for the environment and then the environment takes that observation and itself then emits a new uh uh it's as if it's acting uh but that that action becomes an observation for the agent so there's this kind of reciprocal process occurring over the course of what could be conceptualized as an action perception loop where an agent receives through their sensory states and observation

uh that's perception and then through action they they may select an action or another term policy that they then commit which affects the environment and of course this can be formalized in a very discreet bit uh you know loop by loop way uh like over

you know, over T time steps or over, you know, T time steps within S trials or simulations.

But in terms of sort of the literature and the actual, the findings, we tend to view these things as very rapid, actually continuous processes, right?

And in terms of like a neural process theory.

So there's certainly different ways to look at it.

And then

Back to the textbook.

Other questions.

What is the most appropriate form for the generative model?

What should it be?

What should it look like?

We'll be introduced in Chapter 7 to discrete state-space models.

The POMDP, or partially observable Markov decision-making process, is sort of

one of the exemplar models for discrete state spaces, discrete state space for some people who are unfamiliar, as opposed to it being like a continuous, we're looking at values that are not continuously valued in the sense of like on a range of zero to one, you could have 0.111115,

like not that it's uh instead it's discrete state space so maybe there are three colors red blue and green um it'd be that kind of setting and that that's very useful whenever it comes to thinking of situations where maybe an agent has discrete options you know it eats the food it does not eat the food it moves left or it moves right um and so on and then how do how do you set up the model so that that's looking at things like varying time scales you have hierarchical models and agents

and so on and then how to set up the generative process which is essentially the environment you know the the not agent the not system um and and I want to briefly note that since someone mentioned um earlier that they're you know they're in an they're in their own environment where they're uh being confronted with reinforcement learning and and how that's being carried out to do cognitive modeling which is certainly uh you know if you're

fair approach and it's being it's being done and it's you know it's very interesting it's starting to be done in the social sciences as well which is sort of my personal like deeper background um and then that said uh there's still a lot of kind of missing um theoretical or cognitive components to that so actually it was it was last year that

talk that I gave where I kind of made the case that it's actually active inference that supplies a lot of the missing sort of empirical and well thought out sort of, you know, being able to trace all of these components of a POMTP actually back to the neurobiology and being able to say what each of these parameters is.

And then in addition to that, the sort of exploration exploitation problem in expected free energy, which kind of

You know, the quote in the textbook is that it gets naturally resolved or balanced through active inference, as opposed to certain kinds of aspects of reinforcement learning, where admittedly some of the approaches have been kind of arbitrary, such as, oh, the agent does something random with probability 0.1.

uh Epsilon greedy kind of uh for anyone who's familiar with that language so so all this is to say I I think active inference personally uh fills in a lot of spaces that that have yet to be really filled in or fully formalized within the reinforcement learning Paradigm for cognitive modeling it's like from chapter one in active inference like we already have a very large normative framework here that we can begin to apply and and test so um

I didn't even need to go to the figures it's already here um I think that we're already over halfway through the meeting so I will start to just open it up now um for anyone who has any kind of questions or or thoughts or curiosities this is just week one so I don't think there's any strong imperative to to to get too deep too quickly so

Anyone who wants to speak, please go for it.

Or they have a certain part of the textbook they want me to jump to and we could look at it together.

Yeah.


SPEAKER_02:
Yeah.

You have a specific example for the first cartoon figure you you showed the figure six point one.

You know, maybe something on hand that's very particular.


SPEAKER_03:
Hmm.

So so this is a very.

Yeah, sure.

And that's a good question.

So this is a very general kind of notion in in active inference.

Actually, the you know, as far as the figure goes, like the caption action perception loop between an adaptive system and the environment.

So this is kind of just a way of understanding, like,

our agent has its own internal states its own beliefs what it's trying to infer um and then it uses those in a sense that maybe use sounds a little too um uh

You know, that has its own nuance to it, but it kind of it's as if it those beliefs are being used to figure out what actions to take.

That's what's represented here in the active states.

And those are what influence the environment.

So, I mean,

um chapter seven uh after this we'll get into discrete state space models so pomdps there there's an example of like a t maze where it's um you know it's a very kind of classic simple experiment where where uh there's like a mouse and it has to navigate a t maze meaning there are two arms in the maze it can go left or it can go right

And then one of those arms will have what we assume to be like cheese, like essentially the reward that the agent seeks or wants or prefers.

And then in the other arm will be either something

uh innocuous or it'll be like uh like a shock or something negative something the agent uh does not want the mouse does not want and so the the agent has to kind of choose which way to go so what's going on within that agent is that it begins to model its environment uh you know in its beliefs and so it has beliefs about where it thinks the cheese is is it on the left or is it on the right

And as more trials continue, assuming that that agent has different kinds of adaptive capacities, which in reality, probably yes.

In terms of modeling, that's kind of up to the modeler to do their own research on how to to kind of evidentially back up the assumptions they're making when they set up their model.

but the that would be the sense like the so we have the mouse uh to the right um they they have a belief about where the cheese is uh it's on the left or the right so they choose to move uh as an action left or right and then by moving left or right that moves them through their environment and they get to now see the new observations of having gone left or right

And those observations are taken in by the sensorium of the agent.

You know, it could be a visual modality.

So they see the cheese or not.

Or it could be a more, you know, sense touch or feeling physical touch kind of modality.

And so it's maybe unfortunately it's the shock.

And so they feel that.

And that comes back to the agent.

So so the point is that the agent has beliefs about what's going on.

They act.

those actions then elicit new observations from the environment that the agent then senses and it updates its belief.

It was that helpful.


SPEAKER_02:
Yeah.

Yeah, I think so.

I'm just so the generative model is how the agent believes the data is creative and the generative process is how the data is actually created.

And I'm failing to be very creative here.

And I apologize for maybe this next example.

But if I consider myself as the agent, maybe my beliefs are that if I cut down on the amount of coffee I drink per week, I will get better sleep.

The process is actually going to be myself because I'm going to actively cut down on the amount of coffee I drink during the week.

And my body is going to give me information about whether I actually sleep well or not.

Is that kind of, it's the thing that came to my head right now, but I wonder if that's maybe okay.


SPEAKER_03:
It's a really good analogy, actually.

I mean, in the sense of, you know, whenever it comes to like learning difficult material, it's often useful to just make it familiar, right?

Like actually make it familiar quick from the beginning, because then you can kind of ease into the concepts.

And that's a really good example in the sense that, you know, you kind of have a belief or a hypothesis, let's say, about what kind of action you

should take or could take to change uh you know the observations that will be elicited from your environment uh towards something that you prefer or want you know such as oh I want to drink less caffeine I will be you know healthier

And then that's also, that's a solid insight regarding like, oh, my body is actually the process, right?

That brings us back to the sense of a Markov blanket.

If we were to model that, then it's in a sense, yeah, it's your own.

So, you know,

whenever it comes to the sensorium to having sensory receptors, and this is throughout a lot of the neuroscience literature, this is not specific to active, a lot of this isn't specific to active inference entirely.

But in neuroscience, you know,

you can have interoceptive modalities where you are sensing things from within your own body and so as far as having a generative model and beliefs it's as if like i actually have to model my own body to to understand the physiological symptoms or the symptoms the harsh word but signals that uh arise from it right so so actually that's a really good example and and i think it's a good heuristic and uh

Sorry, Daniel, you had your hand and then Steven.


SPEAKER_01:
Yeah, two short comments on this.

First off,

we see all these examples and kind of become familiar with mapping diagrams and graphics and formalisms and the analytical basis of active inference to situations.

So that's exactly what chapter six is about, giving one recipe for how do you go from being like, I care about self-driving cars, or I care about this person in this situation, or myself in this situation, to be like, what's an observation?

What is an action?

What is an internal state?

That is...

exactly what happens and then also just an important note is some people especially more recently describe generative model from the modeler's perspective to reflect the total situational understanding of all of the probabilistic relationships in the model that's being constructed and fewer people use generative process nowadays but when you get into the example and we will

Then whether you call it one thing or another in English or another language, there is a distinction between like, this is the agent's beliefs about what happens if they hit the light switch.

And then here's what actually happens when the agent hits the light switch.

So they are separate variables and there can be veridical or off kilter beliefs about consequences of actions or what observations map to.

So there's several variables.

It's just note that in more recent work, generative model sometimes is used a little bit more totalistically, whereas in the textbook, it's used to cleanly separate the generative model of the agent being the total description of the agent to the generative process, which is like the environment niche that generates observations and accepts the actions of the agent.


SPEAKER_03:
Justin Delacruz, Ph.D.

: Awesome.

Thanks, Daniel.

I just quickly jump to this figure just to kind of illustrate.

They themselves are aware of it in the textbook.

It's like here is the sort of here is the the subjective model that we assume, like maybe an agent has

then that said we are the modelers and so it's a very meta sort of perspective but it's very worthwhile taking into account it relates back to what i said like oh and machine learning data science reinforcement learning etc it's like we kind of are making our own deliberate decisions regarding how we're modeling uh sort of the thing in the first place so being able to maintain that sort of meta level perspective which is ultimately what's going to actually feed into producing better

research and being able to make that level of observation and comparison.

Anyway, so Stephen, yeah, go for it.


SPEAKER_05:
Yeah, I'd just like to nail down these concepts, if I can, from my perspective.

using like controlled by movements as an example where you have a certain you have six eye muscles that have to be controlled to move the eye so the default control of those eye muscles would be the subjective model is that right and uh so like the i'm gonna um if i have a target to move to a planned movement i have to move the eyes

send a motor signal to the eye muscles, the eye moves.

But if it doesn't reach the target, if there's an error, let's say a visual error, I don't see that represented in the figure you showed, but I'm assuming there's a way of

Obviously there are equations to incorporate that.

And then the motor command gets updated somehow to compensate for the default signal which wasn't correct.


SPEAKER_03:
Yes, I wanted to see if I could find it.

I wasn't necessarily prepped for it for this particular session, but there are various examples.

Not many, but there are at least a few examples of sort of like an ISACOD paradigm and recreating those kinds of simulations in active inference.

So, yeah, it's kind of like...

So you're modeling your agent.

In this case, they have eyes.

And so they're probably going to have some kind of control mechanism available to them that you sort of bake into the agent and the model.

So I'll return back to where we were.


SPEAKER_05:
Yeah.


SPEAKER_03:
So it's kind of like,

The agent may have their beliefs in the sense of maybe they have a belief about where they should look or if they should look somewhere in particular.


SPEAKER_05:
Sorry, so the word belief, I can just replace the word default command.


SPEAKER_01:
The belief is the state of any Bayesian parameter, especially an internal cognitive one or a perceptual one at a given time.

So like the actuality of the processes state that gives rise to given visual input is the orientation of the eye.

And then there's a belief that we can say about what would I see if I were to go there?

And that is where we continue on Andrew, but I, and I can add more about the isocate because this is a really important key.

It's kind of like a Drosophila situation for understanding perception and action.


SPEAKER_05:
Thank you.

Keep going.


SPEAKER_03:
Yeah, no, definitely.

Thanks, Daniel.

It's very helpful.

And yeah, I probably should have clarified that.

So, yeah, another term is like this sense of hidden states or hidden latent states of the environment.

So it's as if the agent is kind of modeling that in their mind.

And so that's where I'm using the word beliefs.

And that's how that arises.

And then from there,

then to active states this is kind of like these are the sort of action affordances that are available to the agent of what they can do so it it's kind of like with the agent there will be these dynamics that you know maybe they choose to do something and the dynamics play out kind of in in the previous example uh that that i think it was joe who gave uh regarding like oh my body is the

is the environment in this case in a certain way.

It's kind of like, oh, well, whenever I choose to move my eyes, actually, I can't change my physiology in a click of my fingers.

Instead, it's that I'm making decisions that I'm subject to the environmental limitations of

my eyes and their motor Dynamics and what they're capable of doing and how they're connected to you know and having retina and so on so so it's here in active states that like I actually choose something and then it you know it happens right and that's sort of this vicarious connection

that I have with the environment around me it's kind of like I have beliefs I act on those beliefs and then by acting it's moving my eyes and then from moving my eyes that brings about new observations for me from the environment um around me also just to the vision example it's um


SPEAKER_01:
it's not a simple single layer model so just four phenomena that are actually incredible entry points for understanding how our our qualia is generated not um recognized only but clarity in vision around the periphery as well as color where the density of receptors is low

The absence of a blind spot and the absence of a motor outside of just in standard vision and the saccade being not attended to, those are actually all very important phenomena that reflect that the primary sensory input to the retina is not what is being experienced as seen.

So it's like both the strength and the weakness of entering into a more complex cognitive phenomena.

It has a lot more tangibility and first-person experiential nature and our familiarity with it.

And yet you may need to invoke several...

nested models or interacting subsystems.

But that is the work of cognitive accounting for something like cicading.

It's just that like, the simple models that don't have attentional modulation are not going to capture that element of the cicade.

But they can they can be layered in


SPEAKER_00:
Hello.

So I once heard Daniel use the term OODA loop.

And so I see observation, I see action.

So my understanding would be the orientation would be the generative model and the decision would be the policy selection, right?


SPEAKER_01:
Basically, yes, UDA, Observe, Orient, Decide, Act is like a procedural parsing of this same system of interest.

here there's a simultaneous flow happening across all the states and there's a degree of model or freedom in which procedural order or if a procedural order is even used to describe it but yes observation comes in and is recognized where it intersects with the prior that's like observation orientation then there's policy inference which is like decision and then there's action selection which is action


SPEAKER_00:
Okay, so that was a setup.

So my real question is, so I was thinking that the generative model would be part of the internal states, and so would the policy selection, but it sounds like maybe the policy selection is actually the active states.


SPEAKER_01:
Policy inference in terms of beliefs about policy, beliefs about the consequences of action, evaluation of policies in terms of their epistemic and pragmatic value, those are beliefs that are internal states.

Action on the interface is like the selected actual action.

because it's the active state that's exposed to the environment.


SPEAKER_00:
Okay, so then would you say both the generative model and the policy selection are part of the internal states?


SPEAKER_01:
As per Little earlier, generative model is used in this textbook to describe

the blanket states and the internal states of the agents.

The generative model is the joint distribution of sense, internal and action that describes the agent totally.

That's the generative model.

And then internal states are the parameters or beliefs of whatever structure that are not on the interface.

So anything that's insulated from the environment directly is internal states.

And that can include nesting and metacognition and so on.

And the blanket states composing that action and the sense, but the actual action going out and the actual observation getting spiked in.


SPEAKER_03:
yeah I just just kind of second Daniel I mean it for anyone who's familiar with the sort of just programming loops I suppose um that would be a typical one way you could do it is uh you know often we use the phrase action perception loop but uh more simulations I've seen actually do more of a perception action Loop like they're they're the other way around so so the agent uh

I guess to put it in terms of like an OODA loop in a certain way, it'd be kind of like observe as the agent receives an observation.

And then orient could be to take that information into account to update your beliefs or these internal states that I stated and then decide.

uh relates to policy inference so you could you in fact you almost should view state inference and policy inferences kind of like two distinct props processes both of them involve minimizing free energy in different ways

um but uh so so to decide in a certain sense is like oh should i do x or y well let's back up a sec and go back to orient well what did i just see and then back up before that what observation was elicited to me that that i observed right so it's kind of like i take in an observation i update my beliefs in terms of internal states then i update my my beliefs about policies or actions

uh that's kind of the decide and then and then after that act is to actually carry out the the action right you could you could theoretically have an agent who can in first states and then after that uses that information to infer policies but then in the final stage they can't act because i don't know something happened or

uh or something silly like the model or just left out that line of code to to allow them to act on their belief about action so yeah there's state inference and there's policy inference and there are a lot of components within the agent that you know they relate the two they're not entirely um divorced processes but but in a sense they happen separately

And I wanna, I know that it's, there's a lot of conversation going on in the chat, but I could briefly speak on, and Daniel has answered the questions very well, but there was a question, is the generative model modeling the prior distribution, or are we learning the parameters like mean and variance of the distribution?

In a sense, we could say both, depending on how you set up the model.

And so a lot of the kind of general,

model parameters I pulled this up earlier which can be slightly overwhelming when you're not given any kind of context as to what it is but this this appears earlier in the textbook and then it's kind of the centerpiece of chapter seven later um but this is a this is sort of a pomdp which an architecture like this would look very similar for a pomdp and reinforcement learning

uh maybe some some particular pieces are not shown in this diagram that maybe sets it apart but in certain ways it's very similar to just a standard pomdp um and so like for a um that's kind of like

so the a matrix is like your likelihood it's very much related to just a general sense of perception you take in observations and you infer states so o observations conditioned on variety of different beliefs you could have right

and then b is state transitions and that's what adds a temporal dimension to these models in the sense of you now have an agent who has a sense of what could happen next and so that kind of counterfactual space is now available to them to have beliefs about oh you know if i if

if if I'm hungry and then I choose an action to eat this food then I will no longer be hungry like that can be a belief you hold and you could potentially have a very high probability of that belief as opposed to other combinations of the the distinct states or or factors within within that sort of state space um C would be your pro it's C D and E E is left out from this diagram

uh aside from being present within g but c is your prior over observations and so that's an interesting one because it's often framed as preferences in the sense of this is what i want to see and so many models in active inference are modeled in such a way that you could learn the c it could be updated over time

by uh updating it using a free energy uh free energy minimization rule that allows you to like kind of learn uh sort of a hyper parameter on C so in the sense of like oh I could learn to want something different than what I currently want or I could learn just learn to want an additional thing in addition to what

I already want.

So that's possible.

Or you can leave it static.

A lot of people do that whenever it comes to behavioral tasks in the sense of, oh, you assume during the course of a trial, someone's not going to dramatically change what they want in their life or in their physiology or something.

So it can be left static.

So that's prior.

D is the prior over states.

So as Daniel mentioned earlier, like just the three most general components of getting started with constructing just about any model are states, observations, and actions.

Once you've figured those out, then it's really just choosing what's the appropriate model to relate those three different things.

And so that's what we get in the case of a discrete state space POMDP.

Like A relates observation states, B relates states temporally plus along with actions.

Then C is your prior over observation.

D prior over states.

G, it's just your expected free energy term, which, you know, so that's that's using your prior beliefs about observations and actions here to figure out what policy to take.

And of course, there are breakdowns of this, you know, functionally.

But that's the general sense.

So so.

as opposed to getting overwhelmed it's really everything boils back down to what are the state's observations and actions of your model and I have just noticed the time and and we're nearly out so um I Daniel I don't know if you have any kind of uh in notes or final words you want to throw out there or um yeah


SPEAKER_01:
Chapter six is like the practical entry point.

Chapter one and also chapter 10 deal more with the theoretical aspects of active inference.

But before or after reading those, if you're like, how do we actually do cognitive modeling?

That's what chapter six is one attempt and one proposal for.

And the questions that are asked in chapter six about how do you go from

system of interest on through procedurally constructing a model it's there not every single nook and cranny is there but there plus asking in the institute discord and colleagues and looking at papers and code bases it is there so like for those who can code or prompt

generative ai or just are getting a first pass on this application it rounds out a lot of like the theoretical discussions some of which may just be perennially open but this is it is really applicable so i hope that

um you know whether you're gonna stay at this time slot or a different time slot or just however you uh jump around the textbook and wherever you're at in terms of like looking for more philosophical uh exploration to the code implementations and actually doing empirical inquiry um six is a good chapter and

write your questions in the coda if you have them or email them if you don't know where to put it or just put it anywhere and uh welcome to the next phase of activity for the textbook group and we'll have chill discussions at this time weekly yeah exactly great and and go through the prior ask questions and add some and and where you have uncertainties

You do a tremendous service by commenting and writing.


SPEAKER_04:
Sorry, Daniel.

My apologies for coming late.

Is there a particular section that we're focused on each week or what would be the best way to prepare for next week?


SPEAKER_01:
Yeah, if you look at the cohort seven and cohort eight live meeting pages, it'll have like the exact contents of each discussion.

So yeah, Andrew's going to it.

So here's where we're today at 23 UTC.

Next week at this exact time slot, cohort eight is going to be discussing chapter one.

And then just everyone's been added to the calendar events and just check which week or time, but the two cohorts alternate early and late time slots, but the two time slots stay the same every week.

So seven days from now, it'll be chapter one discussion.

Two weeks from now at this time slot, we'll be back in cohort seven discussing chapter seven.

So, but you can read and enjoy and write questions and add discourse to any section.

So doing and contributing anything, don't be limited to what's on the agenda, but this just sets a pace.

because we could spend two minutes on each chapter or we could spend two months on each chapter.

So it just keeps a pace rolling and gives time zone accessibility, but there's people who don't even join the live meetings and they're just looking to contribute asynchronously or on their own research.

So like, however it looks like for you to be learning and applying it, go for it.

And as Andrew said, like the 22 textbook is kind of a milestone work.

so it's a good place to ground and connecting it to specific figures equations quotes that gives you a shared touch point with other people as well as opposed to just free floating questions which also can be critically important it's just that they're they're sometimes coming out of left field from other people's view so

Thank you.

Farewell.

And I'll upload the recording as well.

So if you ever don't make it or you want to look at the prior cohorts and times, just check out the recordings.

Okay.

Farewell.

Bye.