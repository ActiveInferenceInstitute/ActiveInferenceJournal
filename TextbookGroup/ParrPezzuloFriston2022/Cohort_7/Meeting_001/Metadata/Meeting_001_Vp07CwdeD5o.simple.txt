SPEAKER_07:
all right hello cohort seven thank you everyone for all the introductions and and saying hello this is our first meeting so we've just all introduced ourselves and now we'll talk a little bit about chapter one slash anything active inference related kind of funneling into the textbook anything about the

positioning of the textbook overall the two years since the publication and any topics that people are like excited about to explore in that third week which will give us like a little rest from the rhythm otherwise um but let's go to chapter one and just like where does anyone want to begin or like what's a

any whether it's a quote or section from chapter one or it's just something about their approach to active inference or it's a it's a general question uh that they have where where would anyone like to begin


SPEAKER_01:
I'd like to ask.

Oh, yes, please.

Yes.

Yeah.

So there's a statement on page five, saying that active inference as a normative approach to understand brain and mind.

Can you explain to me what normative approach means?


SPEAKER_07:
great great question I was wondering the same thing yeah yeah this is one of this is this it this is a very important question I I'm just going to where I I knew that the question had been asked but um Ali or anyone does anyone want to give a thought what what does normative mean when we're talking about active inference and a normative theoretical perspective yes Ali


SPEAKER_00:
Well, yeah, there's an explanation for the use of this term normative in the notes, and specifically on page 267, I guess.

So the use of this term differs a little bit from its normal usage, for example, in philosophy literature or in

some other discourse.

So here the term normative basically refers to the way active inference modeling somehow works according to some evaluative standards.

So more precisely,

In active inference, we have a specific parameter, say, surprisal or free energy, which will get familiar more extensively in the coming chapters.

But there's this parameter around which all the other elements are evaluated and manipulated and modeled and so on.

So the word normative here actually refers to the framework of this theory, and it's not exactly used in the same meaning as used in, for example,

in ethics or in some, I don't know, in other usage.

It's used in a rather technical way here.


SPEAKER_07:
thank you Ali yeah I added a link here to the social sciences course from last year and Avell and Mao's work and Benz and friends too is discussing the social normativity social constraints and so that kind of like ought versus is and like what one ought or normed to do as Ali mentioned um but but it but it's


SPEAKER_06:
we've explored that from some other directions too like to what extent does this outline how one ought to model Michael sure um yeah it is moving on to a different subject um uh I was kind of wondering uh so

the agents or entities uh often have like a sort of highest preference the prior um i'm wondering if theoretically and or practically i suppose these policies are always kind of externally artificially injected as like sort of axioms or something like uh fine food say

Or if active inference is, I guess, I don't know if the word self-consistent, but if these priors manifest automatically by the, I suppose, perhaps, notion of minimizing surprise, or if the biased priors are artificially injected every time.


SPEAKER_07:
This is a great question.

Anyone have a thought on it?


SPEAKER_05:
Well, normative, even in this discussion, is sometimes used in a very strong sense.

The core body temperature of a mammal has to be between a certain minimum and a certain maximum, or that animal will stop moving.

That animal will die.

You have to have a certain amount of oxygen.

or you will stop moving and die uh there are some less violent impositions for instance anyone walking in public in a u.s city has to wear clothes and if you don't you will be taken away and therefore you will not be walking in a city anymore

So then you can get into much more optional things like people have to be minimally nice to one another or people stay away from you.

But there's a great range of uses, all of which have the sort of ordinary language sense of ought to or have to, must, must not.

I think any of those things are norms of one kind or another and can be thought of normatively.


SPEAKER_06:
cool yeah I guess um you know they kind of help kickstart and bootstrap the framing of a problem of interest anyways otherwise how do you you have to define boundaries at some point I suppose yeah


SPEAKER_07:
yes the system of interest choice and the boundary identification question in theory and practice this will come up a lot um Ali and then anyone else who raised their hand


SPEAKER_00:
Well, yeah, regarding Michael's question about how exactly prior slash preferences are implemented in the agent, well, I believe it's both.

I mean, it can be implemented purely artificially, in an artificial way, or it can arise from, as an activist would call, through sense-making.

So it can be pretty autonomous and it's not required to somehow implement those priors and preferences.

through some external implementation uh in self-organized in self-organized agents and specifically in the organisms that participate in the sense making i i use this term in the inactive inactivist sense those priors and preferences can arise from the very active sense making

So yeah, it can be, I mean, purely internal and autonomous as well.

Thanks.


SPEAKER_07:
Cool.

Yeah, there's so much to say on this.

Like in the textbook, we're learning about some of the Lego pieces and the building blocks and some of the names of the colors and like that level of fundamental.

And then we work in the second half of the textbook on some simple examples, like listening to music in anticipation, a rat in a tea maze, and some other kinds of simple mapped cases, like a pendulum swinging in physics.

and then the sophistication and the the complexity hierarchy is essentially open-ended because this is a cognitive modeling approach or systems modeling approach so when we're talking about complex territories then it's like a complex map so a lot of times there's this

movements or tendency to and and an effective one at that to kind of like ground in a more basic example or motif like something that we'll see in the textbook but then when we look at like a complex system like an organism or social setting then that's that's stretching the limits of our like mapping and modeling capacities and then we can kind of supplement that

movement from the simpler motif to the more complex system of interest supplement that but okay well what what what is this new recent Ryan Smith paper on interoception like how are they modeling it here and so that helps enter in like more modern and empirical work otherwise we can go very simple look at the sort of essentials

that's uh and then we can also take it to um strive to model more complex systems any question or thought we can just or we can also look at some of the top prior questions

So one feature that comes up in chapter one, well, there's two figures in chapter one.

This is the dyadic phrasing of agent and niche.

There's a deeper symmetry.

So it could be like agent, agent, niche, niche.

It's just often represented as like a mobile agent in a world.

However, the framework for interfaces, boundaries, blankets is more generic than that.

But this is kind of the two-part model with observation coming in, action going out.

And then that is going to get nuanced into more of a four-part model where there's two things coming in and then there's two things coming out.

But we'll get there.

So this is sort of just situating

active inference within the psychological psychological tradition the cybernetic of agent and niche and then we have the famous figure 1.2 which introduces and summarizes the low road and the high road this is a really important

distinction that was introduced lightly in some earlier work.

It's referenced in a few of the questions about the desert landscape.

And here we have active inference as it's kind of like a metro map.

It's a schematic Metro map.

So it's not like these are the only and the only ordering of terms along the way.

So don't commute with this map per se, but it does describe the low road and the high road so-called.

So does anyone just like wanna give any thought or overview?

How do they see the low road and the high road?

What distinguishes them?

How does this concept like come into play in the textbook?


SPEAKER_03:
I don't know if this is a dumb point, but I guess what interests me as somebody who doesn't know very much about Bayesianism at all but would like to, is that it's interesting that they are two separate directions.

I guess naively I would have thought that the free energy principle was quite reliant on Bayes' theorem because of the definition of surprise.

So I guess it's interesting to me the idea that there are two

roads and one doesn't kind of depend on the other but they meet at one place.


SPEAKER_07:
Interesting, thank you.

Leanne and then Frasier.


SPEAKER_01:
As I've looked into this I'll make a comment but it might be a question.

So my sort of take on things is that the low road is

perceptually based and that's distinctly different from the free energy principle side through predictive processing into active inference that is about um survival and resisting entropy and and that line of things so is that correct


SPEAKER_07:
Yeah, that's great.

Let's revisit this.

Frasier?


SPEAKER_04:
Yeah, just a thought on the low road and the high road.

To my mind, I mean, there is that great 15-minute video of Carl Friston talking about the low road and the high road.

As far as I can recall, the low road is perhaps, you know, we're starting with an idea about very, very small microstates of some system.

And we're going to perhaps, maybe this is a gas or something, and we want to have a look at how those microstates are interacting

And then through a kind of amalgamation of this, you know, the behavior of these microstates, we can maybe get out of that an abstraction, something like adaptive behavior.

Whereas the high road is a bit more like, okay, let's just take a bit more of a sort of an armchair approach and kind of, you know, conceptualize from a top down idea about what it would mean to be adaptive at all.

Kind of starting from an aggregate idea and then kind of going down and saying, okay, well, we have this aggregate idea.

How are the microstates then going to have to behave?

So that's kind of my thoughts on the low road and high road distinction.

The only other thing I would like to mention is on that initial figure you showed, the agent observation loop,

I have in various other parts of the literature, cybernetics, cognitive science, and so on, heard this referred to as the sensor motor loop.

I don't know if they actually use that terminology in the book.

I could be wrong.

It has been a little bit since I've actually read the book.

But that seems to be a relatively universal way to talk about this process of cyclical interaction between a system and its environment.

So I hope that's somewhat interesting.


SPEAKER_07:
Thank you.

Yeah.

So there's a lot of ways to talk about the low and the high road.

Does anyone else want to just give any other thought on low or high?

A textbook scale point to make is this sets up chapters two and three.

Chapter two is going to take us from the low road to active inference.

Chapter three is gonna take us from the high road to active inference.

And then chapter four is like the big, like here you are, here's the active inference generative model.

This is what you write in RX infer.

This is what you write on the napkin.

This is what you're sketching in the diagram.

Like that's the active inference generative model, which is both constructed along the low road path and compliant under the free energy principle umbrella.

So that's why the active inference generative model is sort of like the meeting point or the overlap, because it's both a manifest artifact, which is what allies it with these kinds of model architectures found all along the low road.

And it's a modeling output artifact, which is compliant with this free energy principle and the Bayesian mechanics.

So that's why sometimes people will talk about active inference as well.

It's a corollary.

It's like a downstream or it's a derivative of the free energy principle.

So it's like, this is how you take free energy principle, which we'll go into and apply that to persistent systems or adaptive or dynamic systems or taking the low road, like cobbling and tinkering together.

Like if you start with Bayes' theorem, now the last name does basically no work here.

Bayes' theorem is just about conditional probabilities, for example, between observations of data and abductive inferences to latent states.

But we have here, like if you wanted to build an architecture for perception and action, even the special case, like just a perceiver or just an actor,

If you wanted to do that in a fully synthetic setting, like in Silico, like building agentic AI or building an API call or something like that, or if you wanted to use this more of like an empirical cartography sense, like making a model of a sensory motor system, you're gonna start implementing these different kinds of modeling choices.

And so built things are all along the low road, which looks a lot in many cases like machine learning, artificial intelligence, these neural networks, linear algebra, stochastic dynamical processes, and building up.

towards artifacts that contain this unified approach to perception action and one note on that coming only from the low road here not bringing in FEP per se is

In signal processing, which is dealing with that inbound perception question, action is often neglected.

And then on the contrary, in control theory, like balancing the plate on the stick and mountain car, all that in control theory, the perceptual question is often neglected.

And so one piece of the low road approach here is taking a unifying approach to perception action, not erasing their differences, but having them as part of a unified imperative, evidence maximization, surprise minimization.

bounded by the variational free energy so that's kind of one element is having perception action in a unified model and then kind of a broader commitment to the unifying of all these diverse cognitive phenomena like attention memory learning anticipation all these different kinds of phenomena which otherwise it would be totally grab bag how would these be linked

And there can be like infinite pairwise combinations and models that might not survive having a third piece of the puzzle added.

But by taking this kind of broader unificationist perspective, the whole iguana perspective, like we're going to use an integrated toolkit to model the whole thing.

in its phenomena as it appears to the modeler that's what gives unity on the low road and then that's without getting into the free energy principle and and what it brings from that first principles perspective the end oh sorry or anyone else who wants to raise their hand or or give a thought


SPEAKER_02:
Um, yeah, I just add one thing to your, your comment on the grab bag of like attention and memory and everything like that.

Cause it's actually something we're working on within the marketing field right now.

Um, could you speak more to like how this, uh, this approach would help keep that from being that grab bag?

Cause that is basically the way it works in a practical sense, at least in my industry.


SPEAKER_07:
Yeah, great question.

What does it really look like or mean for active inference to be a unifying approach to modeling different cognitive phenomena?

What would anyone say?

Yeah, Frazier.


SPEAKER_04:
Hi.

Oh, I'll let someone else go.

I've talked already.

I heard someone.


SPEAKER_03:
Sorry, that was me.

Did you want to go, Tom?

Well, I guess I'm sure you'll have a smarter thing to say, but I guess my understanding of a lot of these sort of predictive processing models was that there's no difference really between a sort of

desire and a prediction and so the sort of this sort of classical psychology state where you have a want and you act on the world and you know what your desire is like and you know when you've kind of reached that goal because you're like what you observe the reality matches what your prediction was is sort of collapsed so that free energy sort of replaces

like through surprisal replaces this old distinction between like what a desire is and what a prediction about the world is.

So my understanding is that those are united there and the attention is seen more as a sort of, I guess, a process by which that's achieved as in when you attend to something, you're reweighting your priors about it.

But I could be wrong there.

That could all be nonsense.


SPEAKER_07:
Yeah, very sure.

Thank you, Tom.


SPEAKER_04:
I mean, yeah, that is, in essence, what I was going to recapitulate.

I mean, so the initial question was, how might activists bring a sort of unifying approach to cognitive phenomena in general?

I think that was the question.

I'm a very, very big fan of the work of Dr. John DeVakey at the University of Toronto.

He's a cognitive scientist.

So his kind of whole obsession in life is this idea of

how it is that we maintain adaptivity per se as an agent.

What makes us intelligent?

And he thinks it's this process called relevance realization.

We're able to zero in on the relevant information, essentially.

So all cognitive processes under this idea would have to do with our ability to zero in on the relevant information.

And what might that be?

Well, in this case, we have this framing of a sensor motor loop, this eco niche that we're constructing for ourselves to maintain

integrity across time.

So I guess in the, in the, in the broadest possible conceptualization, you know, active inference is a way of talking about how the adaptivity of that sensor motor loop is, is tuned, uh, in order to result in the perpetuation of the sensor motor loop.

So, and what you have to do, what that boils down to is what Tom said, basically is you have to have a, you have to embody a model of what your world is.


SPEAKER_07:
order to be able to uh match and be in sync with it so that you can you can avoid things that are deleterious to your your boundaries and you can you can take in things that are good for you and so on so i'll stop talking okay yeah there's a lot to say and i and i think we'll also be able to pick out some uh things that the that the authors the textbooks say i'll give kind of a a just a

uh a primer response on this which is to go to figure 4.3 so we're looking ahead to what an active inference generative model can look like in this model whether looking at it in the discrete time or in the continuous time setting

There aren't like advanced cognitive, there isn't self reflexivity.

There's not like material reconstruction.

So there are phenomena in the real world, in the real territory that are not in every single active inference map.

Part of the cool thing about active inference is you can apply it to a rock.

Not that it's the best tool, but you could.

You could apply it to a cloud as it kind of coalesces over a mountain or something like with a rain shadow.

So it doesn't need to apply to any given system or cognitive system.

and so because of that generality one way to think of it is active inference says less as a technique which enables people to say more and different about systems of interest so how does this relate to how different psychological phenomena cognitive phenomena get unified in practice

So let's just say that somebody says, well, I'm interested in the relationship between sensory precision, prior beliefs and agency and estimates of efficacy in the world.

Well, without a first principles approach, that could be just a mega open-ended literature search.

You're going to hit on every single paper and journal on all those.

And then, you know, what?

Another way would be to say, okay, well, I'm gonna associate sensory precision with the A matrix here.

I'm gonna associate prior beliefs and their possible differences with D. And with efficacy, I'll associate with B, and I'll do this and this and that.

And so I'll kind of compose my Legos together, and then I'll do model sweeps to explore the accuracy minus complexity of model fit, like model preference and efficacy,

for this empirical data set, which one of these synthetic models fits the data best?

Or maybe we just wanna do the big one and test something specific about

the biggest possible combinatoric model.

So even though this can initially feel like less of an answer, what enables it to actually be more of an answer through time is that active inference isn't opinionated on what it would even mean for attention to connect to agency.

But then in practice, when you see a paper that says by agency, we mean this, by attention, we mean this, and here's how we modeled their interactions.

So that's the unified compliant playground that allows modelers to actually specify and then have interoperability under the unified imperative.

So then models can be tested like with factor one, factor two, factor one and two.

And then there's actually a coherent way to say where one is more preferable and what data set they have what kind of performance on instead of getting into these like more ontological debates about, you know, well, how does it happen in the brain?

Well, then that's great to zoom in and study how it really might be happening in the brain, but that will never give a generic answer because now we're looking at a system of interest.

Tom?


SPEAKER_03:
Thank you.

This is a very basic question.

So this idea is like, you know, you might have like one matrix that means attention or mathematically instantiates this idea.

Does that mean you could create an organism

with some capabilities, like some kind of cognitive capabilities in the model that don't exist in the real world.

You know, so you're not, you don't say as a framework, you need to have some mathematical bit that does attention, some mathematical bit that does prediction, but that it's generic enough that you could instantiate really any kind of thing that you could conceive as a cognitive capacity.


SPEAKER_07:
Yeah, that's a great way to put it.

One thing that Maxwell Ramstad said in the Discord that I remembered a few weeks ago was the focus on agents has led people to underestimate the scope of free energy principle, Bayesian mechanics.

So not just is active inference unopinionated on cognitive architectures of any given agent, it's unopinionated on how one might distinguish or model or even need there to be agents.

You could just make a fabric of API calls, or you could make a fantasy subway map that doesn't need to have any resemblance to any known cognitive system or any extant system at all.

Again, will that be useful for this or that?

Will somebody pay you for this or that?

Will that startup work?

I mean, those are secondary questions, but when we see that, well, we're talking about like base graphs and then we're gonna associate incoming directionality with perception and outgoing with action, but that doesn't need to have any kind of

I'm not gonna say it's the limits of what can be said there, but that is the toolkit.

And then someone can make an architecture that has any kind of existence within an arbitrary niche.

especially if it's in an immortal setting like the mortal computing that's where it gets into the the strange Loop and the embodied and the survival and and that's a very interesting direction but especially in silico where the survival imperative is just the modelers whimsy you can make arbitrary things and making simple pedagogical things is often a totally critical step

like when we look at the the music modeling case in chapter seven this this isn't claiming to be a total model of aesthetics or of culture someone says yeah but also they they might have to breathe where's the oxygen in this model it's like it's it's just one facet or motif that makes sense thank you

yeah it's really fun to to explore like what are the limits and the constraints of modeling of formalization of experimentation and then within that how does active inference differ from near relative approaches so there's like kind of like a continent scale and then a more fine scale differentiation sometimes like are we comparing active inference

with some unnamed or named qualitative approach, which is a little bit like an apple and an orange comparison, which isn't necessarily a bad thing, just they're two different kinds of stances?

Or are we comparing active inference to a model where perception and action are not considered with a unified imperative?

But then let's see what that model is.

And then that's more of a model to model discussion.

be the difference between two competing hypotheses or two alternative models on a data set versus the question that's broader which is like should we model this data set at all cool well i hope this is a little flavor of chapter one and and some fun people who will be spending the coming months with

Again, if you want to join the 13 UTC, we'll be in chapter six, which is super fun and a great starting point as well, which is the recipe.

And that's the steps that we'll really go through to make active inference models in cohort six.

Or otherwise, we'll catch up and Andrew and or

Ali or maybe others will be facilitating but um in the time between people can add questions add and augment just if you want to do something and contribute to it and you don't know what again just let blanket know okay cool thank you till next time everyone bye thank you everyone thanks everyone