[
  {
    "start": 2.377,
    "end": 3.479,
    "text": " All right, welcome everyone.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 4.521,
    "end": 8.988,
    "text": "We're in cohort seven, the second discussion on chapter eight.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 10.971,
    "end": 12.694,
    "text": "So there's a few ways we can go.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 12.734,
    "end": 28.941,
    "text": "We can look at chapter eight in the context of the book in terms of continuous time modeling, following up on chapter seven from discrete time modeling.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 29.073,
    "end": 51.639,
    "text": " Also, after or just going to it, I can share some updates on continuous time modeling from this morning in the RxInfer group where we developed on the new example from the RxInfer team with the Lorenz attractor and an example with a neural network.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 51.879,
    "end": 57.105,
    "text": "So we could talk about that and modify it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 57.524,
    "end": 83.177,
    "text": " in the context of continuous time modeling um first though let us just go to the chapter does anyone want to just share a section of chapter eight or any question or quote or or image or anything like that i have a question oh okay andrews then john",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 84.17,
    "end": 99.772,
    "text": " Yeah, so they talk about this attractor, like this point that things tend to, but they seem to talk about it on two different levels, like one in reality and then one in the maybe the generative model, I guess.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 100.914,
    "end": 107.663,
    "text": "And so if you could clarify that distinction, how those work and what's their relation.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 107.683,
    "end": 108.424,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 108.444,
    "end": 111.949,
    "text": "So when you specify the entire simulation,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 113.718,
    "end": 138.949,
    "text": " you will have let's just say we're dealing with with some with temperature in the room we could have a situation where or just to get into this y is our observable x is going to be our latent state x dot is the rate the change landscape on the latent state so this is like the thermometer measurements coming in on y and the latent state on x and the change in the temperature um",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 140.077,
    "end": 143.702,
    "text": " you could have a room with a real attractor setting.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 144.223,
    "end": 153.596,
    "text": "Like there's actually a variable V such that when the true latent state is exactly V, the rate of change is zero.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 154.297,
    "end": 159.945,
    "text": "And when the room's temperature is higher, it drops back to the point attractor and vice versa for being lower.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 161.066,
    "end": 166.033,
    "text": "Then you have the agent's model of the external process.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 167.33,
    "end": 170.753,
    "text": " that could be built to be structurally identical.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 171.434,
    "end": 179.762,
    "text": "Like they're both dealing with a point detractor in which point the agent's model will tend to converge pretty simply to the correct parameters.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 180.382,
    "end": 185.687,
    "text": "But you could also have a situation where like the real room is on a limit cycle.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 186.028,
    "end": 189.071,
    "text": "So it's just oscillating or it's bi-stable.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 190.012,
    "end": 193.675,
    "text": "But the agent's belief is that there's a point detractor.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 194.498,
    "end": 199.044,
    "text": " So to answer it, this is just one example of attractors.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 199.104,
    "end": 203.73,
    "text": "There's point attractors, limit attractors, and so on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 204.651,
    "end": 218.228,
    "text": "And in practice, you end up specifying the actual generative process that gives rise to the agent's observations, and then you specify the agent's model of that process, and those can be structurally identical or not.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 219.305,
    "end": 237.313,
    "text": " so so the attractor is basically a construct of the eight of the organism in the way that you're describing it like it's something it would wish for you know like which may not exactly even exist there but may be useful nonetheless is that",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 238.61,
    "end": 251.162,
    "text": " Yeah, I mean, on multiple levels, there's the modeler making the temperature model of the room and possibly just choosing to use an attractor style dynamical model just as a map.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 251.903,
    "end": 259.03,
    "text": "And then there's the agent within the simulation using heuristics or constrained families to do variational inference in.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 260.512,
    "end": 263.875,
    "text": "And that could be simplified on up to any point.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 264.867,
    "end": 271.438,
    "text": " But the crucial thing is the attractor in the agent's mind, that there's something there they're chasing, like they're trying to tune into.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 272.781,
    "end": 281.796,
    "text": "And for me, that's very relevant because I'm trying to do this like two-mind thing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 281.776,
    "end": 305.556,
    "text": " uh dialogue where like you'll have a a continuous mind that's having some kind of affordance or ability and then the attractor would be like a concept and then that could feed into this like discrete mind let's say uh that you know has connections between concepts let's say but so it seems like an attractor can serve as what i would call a concept",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 305.671,
    "end": 311.867,
    "text": " And the process of approaching that would be like some kind of skill or ability or affordance",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 312.573,
    "end": 325.749,
    "text": " Well, yeah, I mean, in figure eight, six, this is like a classic hierarchical architecture where the lower level is a continuous time, continuous state space model and the higher levels of discrete time, discrete state space model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 326.17,
    "end": 331.917,
    "text": "So it could be like you have some sort of continuous time dynamic, whether it's Lorenz attractor or just some sort of oscillator.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 332.397,
    "end": 336.302,
    "text": "And then it's like there's a discretization, let's just say, into quadrants.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 337.008,
    "end": 346.12,
    "text": " So then even though there's this continuous two-dimensional state space at a lower level, it gets discretized into just a four-state discrete state space model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 346.701,
    "end": 348.203,
    "text": "That's basically digitization.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 348.623,
    "end": 351.066,
    "text": "So this corresponds to a variety of settings.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 351.527,
    "end": 357.435,
    "text": "It's really convenient for taking analog sensors and then discretizing the information.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 357.495,
    "end": 360.619,
    "text": "It's been applied to folk psychology.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 360.599,
    "end": 368.788,
    "text": " in terms of like embodied and interoceptive processes, which are continuous in their nature, leading to discretization and action selection.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 369.969,
    "end": 370.55,
    "text": "Okay, good.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 370.57,
    "end": 371.811,
    "text": "So that it has been done.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 371.991,
    "end": 373.052,
    "text": "That's okay.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 374.714,
    "end": 375.435,
    "text": "Cool.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 375.916,
    "end": 383.704,
    "text": "John, and then yeah, we can just go to any part on eight, or when we get to Lorenz, we'll look at kind of Lorenz 2025.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 384.072,
    "end": 411.801,
    "text": " well this is what i wanted to talk about actually because what i learned about the lorenza tractor or the lorenz system i should say i i learned that it was a very simple system that isn't even very good for modeling the weather uh and so i'm wondering how you could use this system in like all sorts of other uh other circumstances when it's not even that good at modeling the weather which is what it was made for",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 412.658,
    "end": 414.28,
    "text": " Yeah, great, great point.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 414.3,
    "end": 421.652,
    "text": "So I'm not sure if it was actually meant to be like the best possible weather forecasting model, though it was a meteorologist.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 421.952,
    "end": 429.483,
    "text": "But the point was the simple around it was just it was just meant to be a simple model that captured certain aspects of the system.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 429.984,
    "end": 430.225,
    "text": "Right.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 430.345,
    "end": 437.856,
    "text": "And kind of the breakthrough was that this deterministic dynamical model in continuous time exhibited chaotic behavior.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 437.836,
    "end": 441.468,
    "text": " So that showed that really simple models can have complex, chaotic.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 442.591,
    "end": 449.955,
    "text": "I don't think that was a breakthrough because, for example, Poig-Curie looked at systems like that around the turn of the 20th century.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 450.56,
    "end": 480.128,
    "text": " uh i think i think this though might have been the first use of the idea of an attractor but my question is if it's if it's not useful for what it was built for how can it be used to model even other things like um yeah yeah agreed lorenz definitely is building on different attractor concepts from point correct so let me just share a little bit from rx and fur",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 480.209,
    "end": 501.07,
    "text": " um this were some some updates that that I pushed this morning but based upon um examples that they brought in just a couple hours ago so six hours ago um so yeah it's not that the Lorenz uh model has just a few parameters",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 502.67,
    "end": 504.012,
    "text": " just here.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 504.793,
    "end": 509.521,
    "text": "So if you wanted performance, you might not necessarily use this exact model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 510.042,
    "end": 513.727,
    "text": "But conceptually, I bet made a weird problem with zoom.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 513.747,
    "end": 520.077,
    "text": "I like I only see like by my window, like in the main screen, I can't see what you're sharing.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 520.979,
    "end": 522.061,
    "text": "And someone helped me with this.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 523.062,
    "end": 524.745,
    "text": "Maybe like right click on.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 526.868,
    "end": 528.711,
    "text": "Can you see the shared window at all?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 532.657,
    "end": 534.019,
    "text": " I see something.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 534.079,
    "end": 538.227,
    "text": "It says Daniel Friedman screen, but I click on it and it's very small and I can't read it.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 542.294,
    "end": 543.095,
    "text": "You don't see it at all?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 543.295,
    "end": 546.882,
    "text": "No, I do see it, but it's very small and I can't read it.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 546.902,
    "end": 551.089,
    "text": "Maybe do a pin, right click and pin it.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 551.109,
    "end": 553.353,
    "text": "I'm right clicking, but it's not doing anything.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 553.733,
    "end": 554.074,
    "text": "Okay.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 555.607,
    "end": 582.508,
    "text": " try to figure this out yeah yeah it's all good but just it is there so it has these several parameters and and it's a it's a sort of proof of concept showing how with several parameters you can get this dynamical chaotic behavior so what this rx infer example did today so it's in rx infer examples dot jl in the advanced examples integrating neural networks with flux jail",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 582.488,
    "end": 588.393,
    "text": " So they uploaded this six hours ago as a notebook, which is really useful for web-based viewing.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 589.314,
    "end": 594.398,
    "text": "And then I modified it into a script and made some modifications.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 595.94,
    "end": 601.144,
    "text": "So what this script does, we'll just look at it in the context of this notebook.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 601.264,
    "end": 606.068,
    "text": "And then we can go over to Cursor and play around with it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 608.13,
    "end": 611.533,
    "text": "So first, they define the Lorenz.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 611.834,
    "end": 637.302,
    "text": " system this is going to be the underlying generative process so in in uh terms of chapter eight which will kind of go back and forth between chapter eight and this more recent work the underlying process is the x y are going to be the observations that are sampled from the lorenz system a data set is created with noisy samples coming from this lorenz system",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 637.855,
    "end": 638.756,
    "text": " So here's this image.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 639.557,
    "end": 641.92,
    "text": "This is kind of like the G\u00f6del-Escher book cover.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 641.98,
    "end": 647.367,
    "text": "We have a three-dimensional continuous time dynamical system with Lorenz dynamic.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 647.968,
    "end": 654.335,
    "text": "And then here are three of the projections onto each of the pairwise axes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 654.355,
    "end": 666.09,
    "text": "So it's like we have some insect flying around in a three-dimensional room, and these are the projections with a shadow on three of the walls.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 667.454,
    "end": 680.89,
    "text": " We're using this because the noisiness and the underlying chaotic nature of Lorentz system make it hard to find a convergent parametric estimate of the transition dynamics.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 681.157,
    "end": 694.517,
    "text": " So it's emblematic of complex adaptive systems like weather or biological systems that might dwell in a region and then have some kind of switching into another regime.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 695.259,
    "end": 704.132,
    "text": "Again, showing how that comes out from just a couple of equations which are deterministic, but the sampling from them is not.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 704.152,
    "end": 707.878,
    "text": "Any chaotic system is going to be like that, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 707.898,
    "end": 709.881,
    "text": "So why Lorentz?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 710.131,
    "end": 730.182,
    "text": " yeah because it's classic and there are other ones this is one with very very few parameters so like there's the double pendulum there's a variety of chaotic systems to study like empirically and analytically more of a metaphor no we're actually studying this model what do you mean well",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 731.107,
    "end": 743.743,
    "text": " If you have a chaotic system and you're representing it with the Lorentz system, that wouldn't be good unless it actually is modeled by the Lorentz system, right?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 743.763,
    "end": 745.566,
    "text": "Well, you can have a toy model, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 745.606,
    "end": 748.61,
    "text": "You can study a toy model just for lots of reasons.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 750.793,
    "end": 756.54,
    "text": "Yeah, there's the pure pedagogical element, which is like, if you don't have this Lego block in your grammar,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 757.634,
    "end": 781.212,
    "text": " you won't have a key piece of understanding how it works in this case and then if there's a different model that fits the data better when you're in like a data fitting situation like chapter nine right you might use a different model so is the reason you use lorenz because it data fits is that the is that the answer no because it's like",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 781.968,
    "end": 805.275,
    "text": " has a long history it's simple and it gives us an intuition on these chaotic switching Dynamics with a lot of um like Rich behaviors from a simple underlying just a couple equations which we can define in a few lines of code okay but so then there's like a world of active inference that works with chaotic models besides Lorenz and Lorenz is just in the textbook is that is that the thing",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 805.964,
    "end": 806.325,
    "text": " Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 806.926,
    "end": 814.098,
    "text": "If you put a different model here, the rest of the notebook, you could just, this is just an example.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 814.118,
    "end": 817.824,
    "text": "So if you have a different model or you want to change how, you can put a different model here.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 818.285,
    "end": 822.372,
    "text": "Just wait to understand what's happening in this notebook.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 822.392,
    "end": 831.448,
    "text": "A simple model just keeps things short and easier to, like Daniel said, if it's classic, then people understand that it's easier to communicate.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 832.593,
    "end": 852.863,
    "text": " yeah there's so and it is one of the simplest i mean it's just these three dimensions and three updates okay so here's noisy samples coming from lorenz attractor now we want to infer the latent state given the ob the observations so flipping to chapter eight",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 852.978,
    "end": 875.172,
    "text": " we are getting observables and we want to infer neural states or latent states like in spm statistical parametric mapping so kind of the precedent to fep and active inference you'd have like neural imaging data as your observables and you have underlying neural activity as latent states okay however",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 876.164,
    "end": 880.777,
    "text": " The hidden dynamics of Lorenz system exhibit nonlinearities and cannot be solved in a closed form.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 881.58,
    "end": 887.136,
    "text": "One manner of solving the problem is introducing a neural network to approximate the transition matrix of the Lorenz system.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 888.314,
    "end": 894.801,
    "text": " So note that the notation is different in this example than it is from the textbook.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 894.941,
    "end": 904.891,
    "text": "So in this example, A is gonna be the transition operator and B is gonna be like the ambiguity operator that maps between the latent states and the observations.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 905.232,
    "end": 907.214,
    "text": "Whereas in the textbook, it's like the other way around.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 907.394,
    "end": 913.18,
    "text": "B is the transition states in the latent space and A is the observation map.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 913.2,
    "end": 914.882,
    "text": "Okay.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 914.902,
    "end": 918.085,
    "text": "Flux.jl is used as a neural network.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 918.183,
    "end": 944.933,
    "text": " package in julia here's the rx infer probabilistic model we can return more of this or or people can learn more about rx infer or get involved in the project but this is a very simple state space model with just five variables um first the probabilistic model is used to extract parameters from the untrained neural network",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 946.313,
    "end": 975.915,
    "text": " and basically it does terribly like the untrained neural network doesn't predict the data at all um so it was just randomly initialized and so the probabilistic state space model also just this green line it has nothing to do with the data then the neural network is trained using a free energy objective which is how neural networks are trained um here's just neural network training code then",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 977.65,
    "end": 996.537,
    "text": " get here which is showing that we can use the probabilistic model the state space model like the explicitly defined rx infer model to recapitulate the parameters of the neural network and so i took that several steps further",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 996.736,
    "end": 1026.017,
    "text": " It's super, super exciting because this is showing a really critical design pattern, which is about fusing the complementary strengths and functionalities of the empirical data fitting, highly parameterized nature of like machine learning and neural networks with explicitly defined and constrained probabilistic models like in Rx and Furr.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1027.313,
    "end": 1031.298,
    "text": " So basically they have complimentary strengths.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1031.678,
    "end": 1034.482,
    "text": "Neural networks are universal function approximators.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1035.002,
    "end": 1040.589,
    "text": "They can interpolate any given function, given enough training and size and all of that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1042.071,
    "end": 1044.854,
    "text": "However, they have high computational resources.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1044.934,
    "end": 1047.437,
    "text": "They have challenges with interpretability and so on.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1047.497,
    "end": 1053.304,
    "text": "They don't have genuine uncertainty estimators, all of these different kinds of limitations.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1054.347,
    "end": 1068.448,
    "text": " Here's showing a way in which the parameters of the Lorenz can be inferred with a neural network and trained on the data, just like anything else in machine learning or just sort of computer science today.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1068.508,
    "end": 1081.047,
    "text": "And then we can infer transition parameters within a very, very tightly defined probabilistic model",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1081.162,
    "end": 1087.51,
    "text": " which is small enough to be defined within this at model block in RxInfer.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1090.354,
    "end": 1095.641,
    "text": "So this is kind of, it's, you know, things have happened since 2022.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1095.861,
    "end": 1098.144,
    "text": "This is one of them from just a couple hours ago.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1098.184,
    "end": 1110.24,
    "text": "And it's just really exciting because it shows, like, you can do pure end-to-end probabilistic programming on Bayes graphs.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1111.03,
    "end": 1115.238,
    "text": " to directly fit parameters of distributions from data.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1116.3,
    "end": 1117.342,
    "text": "And that may be adequate.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1117.422,
    "end": 1119.345,
    "text": "That might be direct and awesome.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1119.866,
    "end": 1133.511,
    "text": "But this is a super interesting pattern that can be added into a lot of extant machine learning pipelines, or language model pipelines, where you have some kind of reinforcement learning or neural network system.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1133.491,
    "end": 1146.904,
    "text": " And then you use explicit probabilistic modeling on top of that to gain interpretability, genuine uncertainty estimators and other kinds of benefits like lower compute resources for these probabilistic models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1148.185,
    "end": 1151.468,
    "text": "John.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1151.488,
    "end": 1159.616,
    "text": "So are you or is anyone familiar with Stephen Wolfram's concept of computational irreducibility?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1160.376,
    "end": 1161.778,
    "text": "Yeah.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1161.798,
    "end": 1162.198,
    "text": "So.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1162.668,
    "end": 1167.573,
    "text": " You said that the AI model can match any function.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1167.713,
    "end": 1175.701,
    "text": "Does that work with computational irreducibility, or are we rejecting computational irreducibility?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1175.721,
    "end": 1177.603,
    "text": "I didn't say match.",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1177.623,
    "end": 1179.825,
    "text": "I said interpolator or approximator.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1181.967,
    "end": 1187.933,
    "text": "Whatever the actual ontological computational irreducibility is of the weather,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1187.913,
    "end": 1190.136,
    "text": " you can train a linear model to approximate it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1190.697,
    "end": 1195.785,
    "text": "It might be a terrible approximator, your startup might fail, you might pick the wrong weather, you know, etc, etc, etc.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1195.825,
    "end": 1197.728,
    "text": "But you can approximate with a model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1199.07,
    "end": 1205.179,
    "text": "So those blobs of irreducibility in nature can be approximated",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1206.273,
    "end": 1207.675,
    "text": " using statistical models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1208.176,
    "end": 1217.731,
    "text": "So like to take this into sort of like the halting problem, like you can't know whether a computer script is gonna, like what its output is gonna be for some kinds of scripts.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1218.553,
    "end": 1226.205,
    "text": "But you could have a statistical estimator that says, I think there's an 80% chance this script is gonna halt without running it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1227.62,
    "end": 1236.374,
    "text": " or human behavior could have these elements of computation or irreducibility, but that doesn't mean you couldn't make a statistical model as a behavioral scientist.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1237.856,
    "end": 1243.845,
    "text": "So it's kind of like map territory, like irreducibility is about the territory, but you can always make statistical approximators.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1245.728,
    "end": 1249.574,
    "text": "Does it create a limit on how good the approximation can be?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 1249.614,
    "end": 1253.56,
    "text": "Right, like if the approximator becomes perfect,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1254.063,
    "end": 1276.392,
    "text": " then functionally there was computational reducibility because you could reduce the underlying process to something simpler but to the extent that the approximation is not perfect then that computation has not been reduced now whether it's in principle irreducible or just the modeler hasn't tried hard enough is a second question",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1278.987,
    "end": 1284.635,
    "text": " But like, here's an example of the advantages that you get from building this probabilistic model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1285.657,
    "end": 1289.002,
    "text": "So here is like on a given dimension.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1289.583,
    "end": 1302.582,
    "text": "So just for the X value or something of the Lorenz attractor, we get a moving posterior distribution with a mean and a variance, but the neural network won't give us a mean and a variance.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1303.684,
    "end": 1307.83,
    "text": "It's just giving us its best prediction of the location at the next step.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1307.928,
    "end": 1311.072,
    "text": " Whereas this gives us like a moving Bayesian credible interval.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1314.417,
    "end": 1318.502,
    "text": "So these kinds of methods are complimentary.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1318.522,
    "end": 1329.177,
    "text": "And I mean, just again, within the last hours, this has greatly expanded our toolkit.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1330.557,
    "end": 1344.212,
    "text": " because it gives us access to building probabilistic models on top of trained machine learning models, rather than needing to do end to end training only through the probabilistic model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1345.964,
    "end": 1364.149,
    "text": " So could you maybe expand on that point, like where you said with the mean and the variance that I guess you're getting this data coming in from a neural network and then you're able to use said, I think, statistically approximate that from the other end, like from top down or.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1365.891,
    "end": 1366.252,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1367.153,
    "end": 1367.453,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1367.974,
    "end": 1375.144,
    "text": "So, like, let's just say that that we have a language model and we're going to ask it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1375.597,
    "end": 1378.843,
    "text": " how many people live in X place?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1380.105,
    "end": 1385.114,
    "text": "And it is going to do this forward pass through billions of parameters.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1385.935,
    "end": 1391.946,
    "text": "And then it's going to say like 11 million, 10.5 million, 13 million, 17 million.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1392.046,
    "end": 1398.718,
    "text": "Like it just, it's outputting these numbers, which represents in that run with that temperature,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1398.817,
    "end": 1400.279,
    "text": " the likeliest outcome.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1400.7,
    "end": 1406.168,
    "text": "That's how it works with sampling the likeliest outcome, given some, some noise that's added back in.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1407.449,
    "end": 1417.304,
    "text": "We could take that sequence of observations and then fit a model that just fits a mean and a variance from the language models outputs.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1418.686,
    "end": 1427.338,
    "text": "So we kind of infer like the true value for its belief about the population of that region from sampling its outputs.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1428.128,
    "end": 1433.277,
    "text": " So it still could be wrong relative to the real reality.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1433.297,
    "end": 1437.323,
    "text": "Like let's just say all of its training data suggested that there was this amount, but then more people are there.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1437.824,
    "end": 1453.09,
    "text": "So this isn't to say that it's veridical in some future moments, but inferring the latent state and having an uncertainty estimator on the latent state is always gonna be more accurate than any given single measurements.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1453.171,
    "end": 1465.122,
    "text": " It's like the measurements of, you know, if we have the mean and the variance of the height of the children in the classroom, that's always a better number to work off of than just one measurement.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1465.777,
    "end": 1478.213,
    "text": " And I think that's a nice example of what this whole setup is that the statistics kind of makes this presumption that there's something meaningful that we call the mean and the variance.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1478.733,
    "end": 1482.058,
    "text": "But the reality might be that this neural network is just all over the place.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1482.158,
    "end": 1485.582,
    "text": "And that's just, there's no really, I mean, that means nothing.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1486.263,
    "end": 1491.97,
    "text": "But from a statistical point of view, in terms of corralling or shepherding, or like just trying to",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1492.642,
    "end": 1521.636,
    "text": " you know get get your hand our hands around this it's very useful and it is practically useful even though it from a meaning point of view it might not actually mean anything but it suggests what a meaningful meaning would be like that if it was if this is a meaning you're supposing hey like is this what you're talking about like is this what you mean the machine would say i don't know what you're talking about but that's how i'm thinking about it",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1522.274,
    "end": 1524.556,
    "text": " So MB, you mentioned balance.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1524.896,
    "end": 1528.5,
    "text": "Let's just see if Cursor will bless us today.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1529.341,
    "end": 1550.34,
    "text": "What's kind of a question that we could ask about balance and see if we could be dealing with almost this two minds paradigm of like a neural network that's fitting noisy proprioceptive data from a continuous date space and then like a conscious",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1551.181,
    "end": 1572.042,
    "text": " explicit mean and variance estimation from there but like mb what's an example of a setting like that or what would be a question that that relates to the vestibular cochlear yeah um could you help me understand that a bit better as i i'm yeah trying to follow uh",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1572.983,
    "end": 1574.769,
    "text": " And yeah, you can just call me Mark.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1575.27,
    "end": 1575.832,
    "text": "Okay, okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1576.214,
    "end": 1576.635,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1576.655,
    "end": 1578.1,
    "text": "MB's cool for Markov Blanket too.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1578.12,
    "end": 1578.822,
    "text": "Oh yeah, sorry.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1579.163,
    "end": 1582.013,
    "text": "I didn't say that my screen name is that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1582.133,
    "end": 1585.845,
    "text": "Me, Markov Blanket.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1587.884,
    "end": 1608.593,
    "text": " um yeah so basically like using um cursor as sort of this this um augmented coding setup just it it may not work within you know the the 30 minutes we have here but just just to see possibly um that's what these examples are great for is like starting with this structure",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1609.99,
    "end": 1633.77,
    "text": " and then modifying tweaking the example like the neural network could be flipped out for a more sophisticated neural network or here in this situation let's see if we could adapt it to study some question of interest with like a vestibular cochlear balance question yeah so are we sorry um",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1634.746,
    "end": 1639.481,
    "text": " Specifically, so we're trying to put data into this model, is that right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1639.501,
    "end": 1644.638,
    "text": "We're trying to build a model using this program, is that right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1645.36,
    "end": 1645.7,
    "text": " Correct.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1645.72,
    "end": 1646.441,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1646.461,
    "end": 1646.821,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1646.841,
    "end": 1662.497,
    "text": "Modify this, just the, the architecture of this model where we get noisy data from a continuous state space, you know, chapter eight, and then we're going to infer the, we're going to use a neural network to train on the parameters from this noisy state space.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1662.537,
    "end": 1674.388,
    "text": "That could be likened to our subconscious, you know, embodied predictive networks and then infer parameters from",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1675.837,
    "end": 1682.005,
    "text": " from a probabilistic model put on top of that neural network.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1682.025,
    "end": 1696.205,
    "text": "Okay, so if we're looking at some kind of data like, and tell me if I'm understanding this correctly, like postural sway, would that be one of the data that we're looking at?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1696.225,
    "end": 1696.325,
    "text": "Okay.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1698.308,
    "end": 1705.017,
    "text": "Okay, the noisy data are coming from proprioceptive continuous state spaces",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1706.093,
    "end": 1707.354,
    "text": " related to postural sway.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1713.9,
    "end": 1721.506,
    "text": "And that could be like modeled as Lorenz attractor with chaotic transitions between qualitatively different postures.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1722.607,
    "end": 1728.853,
    "text": "Like a three dimensional state space could be the three angles of your finger.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1731.955,
    "end": 1735.999,
    "text": "So then there's like a zone within that state space that the finger,",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1737.11,
    "end": 1753.532,
    "text": " fingers biomechanics are related so it's like and this again to kind of get to this like what's what's the distinction with active inference and these other neural network or other kinds of models what would be the approach to making biomechanically realistic finger movements",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1754.035,
    "end": 1768.841,
    "text": " Well, one approach would be we get hundreds of hours of movement of fingers and try and do end-to-end learning based upon recapitulating realistic looking videos of hands, for example.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1770.585,
    "end": 1778.659,
    "text": "But obviously, even with billions of hours of video, making images with realistic hands is still challenging.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1779.23,
    "end": 1787.1,
    "text": " Whereas this complimentary approach would be, you actually have this explicit parametrically defined model of the biomechanics of the hand.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1788.162,
    "end": 1794.129,
    "text": "And then you understand, well, here's the zones of state space within that defined model that the hand can be in.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1795.351,
    "end": 1809.169,
    "text": "And then we'll generate images of the hand from these biomechanically realistic postures versus just trying to recapitulate the appearance from",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1809.503,
    "end": 1836.372,
    "text": " real video and so so okay and then what what what kinds of question would we want to address with that kind of model so are you i mean i i could say something like you know one's uh conscious perception of threat you know some something like that would would that be",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1837.921,
    "end": 1866.983,
    "text": " is it fair to so this is all new to me right but but taking someone's uh you know conscious perceptions um and looking at the effect on on the other end of the you know entropic dimensions of their postural sway characteristics you know some something like that that would be i don't know if that's the the right kind of question to",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1868.212,
    "end": 1875.522,
    "text": " to ask for this type of exercise, but that would be an example of something that would be of interest.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 1876.227,
    "end": 1878.55,
    "text": " I'd like to add a related example.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1878.89,
    "end": 1884.056,
    "text": "I learned about when I went with my friend to his son's Aikido practice yesterday.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1884.076,
    "end": 1887.28,
    "text": "And there was a, he told me about Baguan Zhan.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1887.5,
    "end": 1891.524,
    "text": "So there's this martial arts, it's all about these different hand movements.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1891.544,
    "end": 1892.846,
    "text": "And he's like eight different ones.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1892.926,
    "end": 1895.068,
    "text": "So like they just cycle through them.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1895.168,
    "end": 1899.293,
    "text": "And so you can, so it's very much like these attractors.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1899.353,
    "end": 1903.618,
    "text": "Like you can think, okay, my hand's going to be grasping.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1903.598,
    "end": 1907.705,
    "text": " or my hand's going to be blocking, let's say, or my hand's going to be striking.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1908.607,
    "end": 1917.361,
    "text": "And so in each case, I kind of picture, I think they even kind of suggest that, like if your hand's grasping, you have a particular attractor that you're projecting.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1918.163,
    "end": 1923.632,
    "text": "And so as you move your hand, this attractor is guiding the grasping.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1923.612,
    "end": 1953.619,
    "text": " so that in that context you would you would be imagining this grasping and and you would be centered on that and it'll all work out but then in this kung in this school based on the iching eight trigrams then you might go to let's say striking you see and then you might go to let's say blocking so the context keeps changing for what you what is an attractor and you're just cycling through all these attractors it's it looks like bot periodicity i talk to daniel sometimes about but",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 1953.599,
    "end": 1982.863,
    "text": " that i thought that was kind of curious that wonder if like that could be connected here yeah like um this was uh it it relates to chapter chapter eight like in this page on uh this is we we did a book stream with thomas parr a couple years ago and uh this part right here relates to basically recurrent attractors and the continuous state space model",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 1983.147,
    "end": 2010.133,
    "text": " so initially the active inference models were more like generalized filtering then people wanted these sequential dynamics so that's like dealt with in chapter eight like cursive so then it was like there was models where it was like the limit attractor was like a cursive letter s so it's just kind of like drawing a cursive letter s and the continuous dynamics were basically like the arms joint mechanics on the table um but planning",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2010.35,
    "end": 2015.376,
    "text": " on digital computers is much easier with discrete state space models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2016.498,
    "end": 2037.083,
    "text": "And so that is what led to these hybrid architectures where there are mixed continuous and discrete state spaces because planning is more easily considered in the discretized setting like a chess planner.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2038.295,
    "end": 2066.614,
    "text": " um so it's like with eight hand postures um it's like that there's eight discrete options at this higher level and then action selection you know context switching attention which is modeled as internal or covert action meaning it's not observable from the outside attentional regime shifts within this discrete state space um",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2067.505,
    "end": 2095.842,
    "text": " issue a descending motor contact switch such that the body engages in a different limit attractor so like raise your leg now put your leg down now raise your leg now put your leg down so it's like there's a biomechanical continuous attractor in that case it would be basically like that would be the example from here",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2098.049,
    "end": 2126.773,
    "text": " move move your point okay point at the top corner of the room now point at the bottom corner of the room now point you know point over there then there's this transient dynamic a new set point is established and then um error error reduction with proprioceptive feedback no touch your right wrist and then well",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2127.108,
    "end": 2133.454,
    "text": " Once you do that, the proprioceptive error is zero when you're doing that.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2134.355,
    "end": 2149.209,
    "text": "The top-down attentional regime, I should be expecting proprioceptive feedback reflecting that I'm touching my wrist, and the ascending proprioceptive data have no error term, and that's a fixed point.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2150.49,
    "end": 2155.275,
    "text": "Or the fixed point could be oscillatory, like wave your arm like this.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2156.082,
    "end": 2159.145,
    "text": " So that's like an oscillatory attractor.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2161.828,
    "end": 2182.309,
    "text": "One thing I've come to understand is that as we, so, so use the example of moving your arm to a point in order to initiate, or actually to plan and conduct that movement, there has to be sensory assuming that's proprioceptive attenuation.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2184.263,
    "end": 2186.085,
    "text": " Is that right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2187.908,
    "end": 2211.418,
    "text": "So how do you then use the proprioceptive input to understand the movement in the model when I think what we do is, and you can absolutely correct me, is we turn the precision down as we attenuate the sensory input in order to overcome the evidence, right, that I'm not moving to use that.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2213.491,
    "end": 2232.597,
    "text": " example is does that make sense yeah sensory attenuation comes up in five chapter five as well but yeah exactly like modulating attention so what are the two ways to to reduce free energy there's change your mind and change the world you know",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2233.437,
    "end": 2260.288,
    "text": " updating beliefs that's changing the mind through learning and inference or updating action to to modify the world okay and what is going to control whether the agent engages in passively updating its parameters now parameter updating is its own kind of action but not gross action you know or changing through through action",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2260.403,
    "end": 2285.365,
    "text": " and that relates to the attention that's paid to the ascending predictions basically so that is is empirically observed in postural settings as well as like saccades which is like kind of like a micro postural I mean it's it's ocular postural um that basically in order to enable a move",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2286.475,
    "end": 2292.45,
    "text": " if you kept high precision, like for example, on my proprioceptive is that I'm seated in a chair.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2293.272,
    "end": 2297.262,
    "text": "So how is it that I can get out of the chair",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2297.343,
    "end": 2303.954,
    "text": " When it's like, no, and in reinforcement or reward learning, actions are selected based upon their expected reward.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2304.495,
    "end": 2308.702,
    "text": "Whereas in active inference, we're doing direct policy inference on the likelihood of action.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2309.343,
    "end": 2312.248,
    "text": "So it's not that standing up would be more rewarding for me.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2312.728,
    "end": 2315.393,
    "text": "It's I expect myself to be standing up.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2316.074,
    "end": 2321.663,
    "text": "So it's the fulfillment of likelihood rather than the maximization of reward.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2321.643,
    "end": 2328.153,
    "text": " But how could it be when it's an obvious counterfactual, how could it be likely for me to be standing up?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2328.173,
    "end": 2333.963,
    "text": "How could I be the kind of guy who's standing up when my veridical proprioception is that I'm not?",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2334.964,
    "end": 2344.68,
    "text": "And the answer is transient sensory attenuation makes it suppressing the proprioceptive input",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2345.453,
    "end": 2370.043,
    "text": " enabling there to be more ambiguity of which position I'm actually in, which creates a kind of like postural liminality, which then a top-down belief, no, actually I am standing up or I'm on the path to standing up, can sort of get the ball rolling over a critical threshold that then action fulfillment can take all the way.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2370.715,
    "end": 2386.662,
    "text": " That's been modeled in like situations with like hyper or hypo dopaminergic cases where like somebody may have challenges initiating movements, but once movement is initiated, it continues or they can initiate, but not complete a movement.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2388.625,
    "end": 2390.929,
    "text": "So it's just that transient suppression.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2390.969,
    "end": 2395.997,
    "text": "I think that was, that's the key is that it would to initiate and then you're on to.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2397.023,
    "end": 2404.993,
    "text": " at some level processing that proprioceptive feedback to help with the movement itself, right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2405.013,
    "end": 2409.98,
    "text": "When the movement's in process, there can't be this continuous suppression.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2410.0,
    "end": 2415.106,
    "text": "It has to be just, I picture it just kind of as a flicker, and then you're on to the movement.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2415.127,
    "end": 2417.91,
    "text": "Or as a gradient, a gradient of suppression.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2417.93,
    "end": 2418.671,
    "text": "Yeah, well said.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2419.272,
    "end": 2423.217,
    "text": "You become more and more demanding and more certain and more precise.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2424.074,
    "end": 2433.386,
    "text": " Yeah, or it's like driving on a windy road and it's like on a straight part, you want to accelerate, but then you relax off in order to update your vector.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2433.787,
    "end": 2439.234,
    "text": "So it's like when your gaze is fixed, you want to be having high attention to the visual input.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2439.734,
    "end": 2453.592,
    "text": "But then during volitional or sub-volitional eye movement, visual attenuation occurs, which is why we don't get motor, you know, don't get nauseous outside of like vertigo type settings.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2453.723,
    "end": 2481.52,
    "text": " with eye movements because when we look away like we get this attentional blink we're actually not accepting or paying attention to the visual input even though photons hit the retina at the same rate during the movement of the eyes so that's like kind of like it's like depressing the clutch on attention shifting into a different spot and then we re-engage the precision and now we're like getting information from over here",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2482.462,
    "end": 2495.826,
    "text": " So I'd say there's good evidence for folks who go on to have something like persistent dizziness is that there is not good sensory attenuation with movement.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2495.846,
    "end": 2506.765,
    "text": "In fact, there's this excessive precision that seems to be a theme among a variety of conditions.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2513.326,
    "end": 2538.962,
    "text": " yeah that like that is sort of like that is what precision psychiatry and all these kinds of approaches get towards which is like sometimes it's that there's a um it can be an uncertainty estimator that's too precise or not precise enough that leads to different behaviors so it's not a question of just like moving a variable up or down",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2540.208,
    "end": 2552.867,
    "text": " If I was to refine that question that you kindly asked me to try to formulate, I would say something like, what are the effects of excessive tension to postural sway?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2554.25,
    "end": 2559.438,
    "text": "Which would be the same thing that would probably occur during a perception of threat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2560.319,
    "end": 2563.684,
    "text": "But what are the effects on the natural sway parameters?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2563.917,
    "end": 2576.774,
    "text": " So, this just becomes this ongoing loop, and that would be something like to use the, you know, vestibular phraseology, like malady department, which is just like an excessive duration of something like sea legs.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2580.159,
    "end": 2584.845,
    "text": "Yeah, I don't know if that's something we could put into a model like this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2586.597,
    "end": 2594.515,
    "text": " like it's that's kind of that that is the exploratory modeling and inquiry is like okay so we have",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2594.765,
    "end": 2621.7,
    "text": " this model that's getting trained on proprioceptive data so you know in progress but then we could say something like well but let's just say somebody is acting based upon their parametric estimators of posture what would happen if their if the precision was low so let's just reduce let's have it let's have the the best fitting model and then let's simulate movement from someone whose precision is three times higher or three times lower",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2623.165,
    "end": 2628.67,
    "text": " And then that, you know... Yeah, Andrews, did you have a...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2629.578,
    "end": 2655.535,
    "text": " yeah i wanted to jump in with an idea that may actually be related to this but that i've been having in this situation where let's say you have this task that you're given a triangle and you're going to put in uh and you're kind of blind but you're gonna put in a little circle and you try to expand the circle until its maximum size you can never be perfect at that but you try what you get so you're given some triangle so",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2655.515,
    "end": 2661.221,
    "text": " In the beginning, when you do a task like that, you're going to be bumping into sides or whatever.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2661.381,
    "end": 2668.809,
    "text": "You don't know how to guess what would be the right amount to increase the radius, etc.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2669.55,
    "end": 2672.754,
    "text": "But at a certain point, you'll get the answer or something rather satisfactory.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2673.514,
    "end": 2676.998,
    "text": "And then I imagine there's like a replay, let's say, in your mind.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2677.038,
    "end": 2681.623,
    "text": "You say, look, okay, this is what it took for me to do this task.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2681.603,
    "end": 2701.857,
    "text": " but now that i know what the answer is where the center is i'm interested to learn from that by saying okay now that i know where i end up i would replay it in my mind to do that as efficiently as possible like i'd make the right guesses all along the way and so if you do the replay for the cases you've done before",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2701.938,
    "end": 2718.917,
    "text": " um you get much more efficient algorithms that you're developing so let's say you're getting you're given a whole bunch of different triangles and so they're different conditions and whatever but i think this notion of and i think it goes like to the statistical um interfacing that you were doing daniel saying okay",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2718.897,
    "end": 2725.483,
    "text": " It's not a particular answer, but you're going to get a statistical mean and a variance for what's optimal behavior.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2725.744,
    "end": 2727.185,
    "text": "What's optimal presumptions?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2727.405,
    "end": 2736.734,
    "text": "Where is this center of the triangle probably most likely going to be if I'm thrown into some kind of triangle?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2737.035,
    "end": 2737.375,
    "text": "Yeah.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2737.475,
    "end": 2747.605,
    "text": "This notion of replay, that you would want to replay and get your optimal strategy, and then you'd want to go into a new problem with that optimal strategy and keep improving it.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2748.53,
    "end": 2774.554,
    "text": " yeah so like live stream 51 series with isomura at all this is a really critical paper that shows that there's a monotonic relationship between the loss function used in neural network fitting and the variational gradient descent on the semantics of the base graph across the blanket and they use this postdictive learning strategy where basically at each time point",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2775.783,
    "end": 2800.373,
    "text": " you you minimize so that factor graph with fictive causality of factors so decision making to minimize the future risk so we want to minimize future risk for the unoccurred event and the way that's going to happen is by remembering our past sequence of actions and observations",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2800.673,
    "end": 2822.766,
    "text": " then reassessing what would have been the least regretful updated risk assessments given all that we've seen till now or given within this sliding window of what we've seen till now so then it's fictive causality is propagating backwards in time",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2823.826,
    "end": 2852.668,
    "text": " the sense of the the agent is saying if i would have done that given what i know about this now this is how i think it would have occurred and using those re-entries to reduce upcoming risk and it can be happening like very rapidly after the final solution so like with posture i can just imagine like let's say you feel wobbly and you kind of like regain your balance but you just say wait wait wait like i had it all wrong like this is what",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2852.648,
    "end": 2879.584,
    "text": " i should have been having in my mind so because so and if you don't have that you're going to be wobbling all the time and you're going to fall down but if you're wobbling a little bit you're able to re-parametrize well what is the my proprioceptric situation then you'll be you'll feel stable that was just a momentary thing somebody said something about about what",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2880.897,
    "end": 2885.324,
    "text": " I was just saying you could you could also do that on a false inference, right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2885.444,
    "end": 2903.731,
    "text": "Like like an over attribution of something like let's say you have a really and we see this in the clinic, you have a really kind of fluky circumstances around a fall, you know, that you couldn't possibly, you know, recreate a sort of a one off experience that somebody has.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2904.652,
    "end": 2909.419,
    "text": "And then they go through the process of it sounds like mitigating",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2909.821,
    "end": 2911.803,
    "text": " the likelihood that that will happen again.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2911.843,
    "end": 2918.972,
    "text": "And they do that to a level that is excessive, right?",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2918.992,
    "end": 2922.677,
    "text": "So then their subsequent movements become very constrained.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2923.237,
    "end": 2926.001,
    "text": "Like shuffling their feet or something.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 2926.021,
    "end": 2934.391,
    "text": "Yeah, for example, or they have a very tight, I guess you'd say, excursion of their postural sway.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2934.571,
    "end": 2935.793,
    "text": "So those kinds of things.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2935.853,
    "end": 2938.596,
    "text": "And at the same time, there's a greater",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2939.47,
    "end": 2959.369,
    "text": " conscious and this is what I'm interested in is like you know the the conscious overtuning of precision yeah like I mean that is is definitely where nested models would come into play like an injury occurs and then there's increased attention",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2960.429,
    "end": 2963.272,
    "text": " to the pain or there's modification.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2963.312,
    "end": 2969.578,
    "text": "And that sets up a new attention with descending and proprioception ascending.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2970.819,
    "end": 2979.087,
    "text": "And those can result in a new attractor with reduced mobility or whatever it may be.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 2980.028,
    "end": 2986.875,
    "text": "And that can generalize to other postures and even probably other circumstances.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 2988.695,
    "end": 3015.478,
    "text": " yeah like again that's sort of the toolkit and that's where the textbook gets us it's just like hey with with single layer models this is the there's already these richness of cognitive patterns to explore and that's what chapter seven and chapter eight are about so you know chapter six is the recipe these are the questions to consider like going through these is is qualitative initially",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3015.712,
    "end": 3018.657,
    "text": " And then chapter seven goes into the discrete time models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3019.158,
    "end": 3021.803,
    "text": "Chapter eight goes into continuous time models.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3021.883,
    "end": 3023.627,
    "text": "Chapter nine goes into data fitting.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3024.268,
    "end": 3029.918,
    "text": "But it's like that, that kind of is one structure of the process.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3031.321,
    "end": 3038.614,
    "text": "And then it's maybe you want the single best performing model for your deployment or, or for your paper.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3039.286,
    "end": 3060.241,
    "text": " Or there's also a lot of value in building these portfolios of models and looking how different features like modify, explain different components of the variants, especially if it's gonna be something involving people where there's like intersections of complex psychological phenomena.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3061.383,
    "end": 3065.31,
    "text": "So it may not be just a single layer model.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3065.527,
    "end": 3091.888,
    "text": " but this is some of the toolkit and knowing what what a single layer model can do helps give give some of the um motifs kind of like the rudiments for building more sophisticated models and I just it's an exciting day because the applicability of these probabilistic models to do parametric inference from neural network models which are just everywhere",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3093.151,
    "end": 3097.525,
    "text": " has increased markedly in the last like eight hours, which is pretty fun.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3100.087,
    "end": 3130.093,
    "text": " to jump in like to think of these two minds one continuous and one discrete and i think of like the continuous mind you know you want to extract the critical points so it could be like the peaks or the troughs or it could be like you know going up you're tensing your muscle you know and then going down you're relaxing it and so you have these different modes that then can become discrete and i guess what i learned today from you was that in the other direction it's like projecting these statistical",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3130.073,
    "end": 3147.525,
    "text": " presumptions like oh there's got to be a mean let's say there's got to be a variance that's attracting even if they don't actually you know exist in any real physical sense but they exist in a sense of trying to get a grip on what's what you you know getting a handle",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3149.21,
    "end": 3170.357,
    "text": " yeah i mean and and and this this like to the earlier questions like the structure of the generative model assumed by the agent does not have to be the same as the environments the environment could be like a bathtub probability distribution like it's either like dwelling low or dwelling high but then the agent could be trying to infer a gaussian",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3171.299,
    "end": 3182.777,
    "text": " So then they could having all these pathologies where first it's super tight low, and then it's super tight high, and then it's in the middle and it's super blurry and it's swapping between them or it's staying in one.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3182.817,
    "end": 3194.235,
    "text": "So it's like they're fitting ultra well when it's on the low with their high precision low estimate, but then they're completely confused when it flips to the high state.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3195.177,
    "end": 3203.196,
    "text": " So it's like, those are the kinds of diagnostics that you want to look at to understand whether you're dealing with the wrong family of variational distributions.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3204.931,
    "end": 3210.499,
    "text": " And it's like you could be walking uphill for a ways and then walking downhill for the ways like your posture is complete.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3210.519,
    "end": 3218.971,
    "text": "Like there's no average that it's a non-concept to say there's some kind of average there because it depends on where you're walking and you don't know where you're going to be walking.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3218.991,
    "end": 3230.668,
    "text": "But the idea that you have some kind of momentary balancing, you know, parameters that you're kind of guessing like that's they don't have to be real, but they could be meaningful, I think.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3231.222,
    "end": 3245.08,
    "text": " Yeah, and it comes back again to the precision modulation and attention, which is just over the papers in the years is always returned to as sort of a hallmark of intelligence.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3246.221,
    "end": 3252.129,
    "text": "You know, you want to be precise when it's good to be precise and to be open when it's good to be open.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3253.431,
    "end": 3256.875,
    "text": "But when to do that is the question.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3257.378,
    "end": 3279.589,
    "text": " that's that's like a third mind type of thing balancing those two minds i think exactly agreed with that um yeah just in our last minutes let's see how that um what this what it will do for its second output but anyone have any last comments or questions i have a question but it's not about chapter eight",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3283.163,
    "end": 3286.607,
    "text": " Is it possible to change your generative model?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3286.707,
    "end": 3289.049,
    "text": "Like, are there models that change models?",
    "speaker": "SPEAKER_02"
  },
  {
    "start": 3289.79,
    "end": 3290.09,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3290.431,
    "end": 3299.941,
    "text": "Yeah, that's called structure learning, is when the topology of the model, the structure of the model, is itself modeled.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3305.908,
    "end": 3306.328,
    "text": "So, yes.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3307.83,
    "end": 3310.993,
    "text": "So, any other...",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3316.272,
    "end": 3319.377,
    "text": " I'm glad, John, Mark, Daniel, to hear from everybody.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3319.477,
    "end": 3320.518,
    "text": "It was very helpful today.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3320.679,
    "end": 3321.039,
    "text": "Thank you.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3322.301,
    "end": 3322.602,
    "text": "Cool.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3324.244,
    "end": 3327.93,
    "text": "Thank you for allowing me to participate and learn.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3327.95,
    "end": 3328.57,
    "text": "This is great.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3328.951,
    "end": 3329.231,
    "text": "Cool.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3329.251,
    "end": 3334.7,
    "text": "Yeah, I'm also just really curious to see where this last training step will get us in the outputs.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3335.06,
    "end": 3344.254,
    "text": "I mean, it's not all about code, but starting with examples",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3344.47,
    "end": 3374.477,
    "text": " and modifying them and kind of staying on a ridge of functionality is super powerful right now like you can also this rx and for your active in this or um it's an open source project we have a product we meet weekly okay you are in this i mean it's lazy dynamics and uh reactive bays are the developers but like there's a lot of participants in the institute who also contribute and so and we're partnered with them",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3376.786,
    "end": 3380.51,
    "text": " But it's just using cursor or similar methods.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3380.53,
    "end": 3381.992,
    "text": "Again, so it isn't all about code.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3382.012,
    "end": 3383.193,
    "text": "It's not all about reducing it to code.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3385.055,
    "end": 3387.158,
    "text": "But I hope this shows a little bit.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3387.719,
    "end": 3389.541,
    "text": "And there's other places to see it as well.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3390.722,
    "end": 3393.005,
    "text": "With one prompt, you can get pretty far.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3393.946,
    "end": 3399.232,
    "text": "But modifying what's already functional is ridiculously powerful.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3401.675,
    "end": 3403.356,
    "text": "So that's one thing that's... Oh, sorry.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3403.437,
    "end": 3403.857,
    "text": "Yeah, go ahead.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3404.9,
    "end": 3411.589,
    "text": " I was just saying it's becoming a bit demystified as far as that was the one question I had coming in is like okay, how do you take something that's conceptual.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3412.049,
    "end": 3419.039,
    "text": "And then take real numbers and run it and it sounds like it's it's kind of like well you you just start with.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3419.359,
    "end": 3427.65,
    "text": "Something and then you say Okay, what if I increase the precision here or I changed the model there right that's kind of what we're getting at is you start to apply.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3428.221,
    "end": 3450.28,
    "text": " numbers in a in a relative sense is that right if the and if even better if there are real data but I don't know how you would give um you know Consciousness you know how you would give that numbers you know like like attention you just were playing with that zero to one as far as the precision of within the model is that what you're doing yeah I think like",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3451.036,
    "end": 3458.267,
    "text": " Obviously, consciousness, especially if it's defined as unobservable, is a perennial measurement issue in question.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3461.111,
    "end": 3473.93,
    "text": "Doing attentional modeling and more of these like just cognitive variables that aren't necessarily related to self-awareness or consciousness, those are more tractable.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3474.751,
    "end": 3477.195,
    "text": "Self-report is a classic.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3477.817,
    "end": 3483.802,
    "text": " So yeah, consciousness related modeling is often tried and very fraught.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3484.583,
    "end": 3488.226,
    "text": "But this is, I don't mind it being fraught.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3488.626,
    "end": 3496.493,
    "text": "So this distinction between the continuous and the discrete, and then realizing, like you were saying, Mark, that sometimes you shouldn't overthink it, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3496.513,
    "end": 3499.956,
    "text": "Like you should be doing, you know, your continuous movement.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3500.357,
    "end": 3504.18,
    "text": "Sometimes you should, it's just like your lucky mind, when everything's going well, just keep walking.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3504.54,
    "end": 3507.543,
    "text": "But you have the unlucky mind, like, hey, there's a hole, like, don't fall in, right?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3507.583,
    "end": 3507.823,
    "text": "So",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3507.803,
    "end": 3511.653,
    "text": " So do you use your lucky mind or your unlucky mind?",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3513.778,
    "end": 3523.703,
    "text": "That is what consciousness is all about, like to make sure they have the same information and then deciding, yeah, but here I shouldn't overthink it, but oh no, here I should be careful.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3523.683,
    "end": 3529.213,
    "text": " So I think and see to the things we're learning, like the relation between those two minds.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3529.714,
    "end": 3534.863,
    "text": "One is that like, oh, let go of the break in terms of certainty and pretend you don't know.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3534.963,
    "end": 3536.426,
    "text": "And then tighten, tighten, tighten, tighten.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3536.967,
    "end": 3547.986,
    "text": "So that shows you that process shows you the direction of those two minds that you're going from the continuous one that needs to be moving to the discrete one that needs to kind of like focus on some attractor.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3547.966,
    "end": 3571.83,
    "text": " so those types of things are indicators of um the consciousness in play i would say let's see if it will output the stick figure as requested but but you know these functions are only a couple uh",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3573.194,
    "end": 3577.74,
    "text": " So this could be like, this is pointing and like you're having your hand waver and point at something.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3577.8,
    "end": 3584.168,
    "text": "And then like, for example, blood sugar is related to the precision of the ability to point.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3585.329,
    "end": 3592.238,
    "text": "If somebody is having a blood sugar crisis, they're gonna have different precision of their movements.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3593.479,
    "end": 3596.383,
    "text": "That's something that's more empirically observable.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3597.684,
    "end": 3600.568,
    "text": "And then you could differentially parameterize",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3602.692,
    "end": 3631.467,
    "text": " more overt elements let's see if it if it did it absolutely hilarious oh these are stick figures yeah true posture proprioceptive perceived posture so that gets super interesting right like there's the real body",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3632.003,
    "end": 3653.843,
    "text": " then there's like these ghosts of like what we predict and what is and then you just say okay now modify it so that it's taking in this data instead of the simulated lorenz data so which what are the three the true the posture is the red one the proprioceptive signals are these noisier gray ones",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3654.059,
    "end": 3656.703,
    "text": " And then the perceived posture is the blue one.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3656.743,
    "end": 3660.207,
    "text": "That's exactly what people describe.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3660.448,
    "end": 3665.094,
    "text": "At some point, okay, I realize my postural sway is normal.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3665.114,
    "end": 3666.716,
    "text": "And that almost takes some convincing.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3668.579,
    "end": 3672.324,
    "text": "But it feels like I'm doing this.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3672.444,
    "end": 3674.407,
    "text": "And you've probably had that experience.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3674.467,
    "end": 3677.27,
    "text": "Coming off a boat.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3677.29,
    "end": 3680.435,
    "text": "Or even sometimes transiently coming off an elevator.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3680.475,
    "end": 3682.918,
    "text": "You perceive that experience.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3683.287,
    "end": 3712.855,
    "text": " excess and for some people there seems to be a difficulty attenuating that and and uh you know returning and to use your uh example you're walking up a hill and then you're walking flat but like when you made that transition you're still in a sense like running the program as if you're walking up the hill and now you have this this conflict yeah",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3713.999,
    "end": 3715.861,
    "text": " That's fascinating.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3715.901,
    "end": 3718.124,
    "text": "Looking at that, that's really exciting.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3718.965,
    "end": 3719.565,
    "text": "Yeah.",
    "speaker": "SPEAKER_01"
  },
  {
    "start": 3719.585,
    "end": 3725.732,
    "text": "A really great way to model it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3725.752,
    "end": 3725.972,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3726.593,
    "end": 3727.574,
    "text": "It's open source.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3727.995,
    "end": 3730.838,
    "text": "Take it and run slash walk with it.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3732.72,
    "end": 3734.182,
    "text": "Not too fast.",
    "speaker": "SPEAKER_00"
  },
  {
    "start": 3734.202,
    "end": 3735.783,
    "text": "Or stand and sway.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3735.803,
    "end": 3737.365,
    "text": "Yeah.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3737.826,
    "end": 3738.767,
    "text": "It's epic.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3738.787,
    "end": 3739.087,
    "text": "Okay.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3739.287,
    "end": 3739.828,
    "text": "Thank you all.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3739.848,
    "end": 3740.349,
    "text": "See you later.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3740.809,
    "end": 3741.029,
    "text": "Bye.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3741.049,
    "end": 3741.83,
    "text": "Thanks so much.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3742.01,
    "end": 3743.232,
    "text": "Great.",
    "speaker": "SPEAKER_03"
  },
  {
    "start": 3743.252,
    "end": 3743.432,
    "text": "Bye-bye.",
    "speaker": "SPEAKER_00"
  }
]