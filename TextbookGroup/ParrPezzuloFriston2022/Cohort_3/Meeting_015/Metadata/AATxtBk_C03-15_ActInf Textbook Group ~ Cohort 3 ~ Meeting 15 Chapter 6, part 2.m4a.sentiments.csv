start	end	speaker	sentiment	confidence	text
800	1350	A	0.546256959438324	You.
2920	3444	B	0.4896698594093323	All right.
3482	4550	A	0.8486202955245972	Greetings, everyone.
6120	8724	A	0.8379871845245361	It's June 20, 2023.
8842	12230	A	0.8994444012641907	We're in our second discussion on chapter six.
12760	17270	A	0.8836202025413513	So we'll first just have any general comments or anything.
17720	33100	A	0.8550606369972229	Then we'll turn to the questions table and look at what questions we didn't get to last time and just kind of revisit, maybe condense some questions or just see what we can do with what is here.
33170	39730	A	0.9000473022460938	So anyone just want to make any general comments on chapter six?
48750	52442	B	0.9135921001434326	I believe this is the second session on chapter six, right?
52576	53306	A	0.5871568918228149	Correct.
53488	55222	B	0.5993067026138306	Or maybe I lost.
55286	55802	A	0.584351658821106	Okay.
55936	56940	A	0.5981219410896301	Yeah, it is.
58690	59440	A	0.5491447448730469	Yeah.
60610	67710	A	0.6296496391296387	There was only one onboarding needed for the welcome back here, so we started one week faster into the rhythm.
69910	70610	A	0.584351658821106	Okay.
70760	78434	A	0.8051698207855225	So it looks like these were the questions I remember we left off with this one.
78552	84440	A	0.8447081446647644	Let's just develop this into what was into a question, and then we'll continue on.
97370	98120	A	0.584351658821106	Okay.
101130	121500	A	0.8814999461174011	Is there a common or good representation or rubric for evaluating Generative Model Generative process, which is change it to Generative Models and Generative Processes?
131210	135000	A	0.9060387015342712	Anyone want to give a first thought or just some other related question?
146310	147170	B	0.6922071576118469	Go on, please.
147240	147582	B	0.5092127919197083	Sorry.
147656	148600	A	0.5774939060211182	No, it's okay.
153560	176572	B	0.7938403487205505	Yeah, I'm not sure about what's the exact criteria for evaluating generative models or generative processes, but one thing is for sure that, well, I mean, one of the main at least when evaluating generative model one of our main.
176626	197440	B	0.8684254884719849	Criteria should be how closely it tracks our situation of interest and specifically how relevant it is for addressing the question we're trying to examine.
199320	204768	B	0.5459842085838318	I don't think it's something clear cut or, I don't know, written in stone.
204944	218490	B	0.845784068107605	And based on the context and the situation, the Evaluation Criteria rubric should be different, I suppose, both for generative Model and generative process.
224290	224894	A	0.5491447448730469	Yeah.
225012	241830	A	0.872063934803009	So again, we'll revisit this Generative Model Generative process question later, following the recent Livestream, but generative process working with generative process as the underlying process that gives rise to the observations.
242250	248070	A	0.5812659859657288	This would seem to be more adequate to the extent that it can better describe the measurements.
248570	263020	A	0.879633367061615	Generative Model, similarly, is being evaluated based upon its ability to fit to the generative process as well as phenomena of interest.
264910	278766	A	0.8121963739395142	So not just to fit visual data, but maybe to model something like some illusion in visual, then there's a wide range of more general statistical modeling techniques.
278798	284450	A	0.7483305931091309	So first is like the ultimate grab bag, which is just how relevant is the overall modeling.
285830	293330	A	0.8742427229881287	Then there are statistical evaluations of model adequacy and model selection.
293490	295330	A	0.7541698217391968	Ike information criterion.
295410	298550	A	0.7365099787712097	Bayesian information criterion, base factor.
299530	302182	A	0.8155889511108398	Hierarchical likelihood ratio test.
302316	307290	A	0.8472496867179871	If you have a parametric Model Bootstrap and non parametric statistics.
307630	327146	A	0.8078018426895142	Just general modeling, and then taking that more out of the statistics into the Engineering Model Lifecycle, then that's where you can think about validation, verification, validity, quality, et cetera.
327258	329410	A	0.7451397180557251	Systems engineering model lifecycle.
334980	337170	A	0.8362141847610474	Any other thoughts or questions on this?
343010	343760	A	0.584351658821106	Okay.
346450	365862	C	0.7132025957107544	I'm coming from kind of an early career data scientist background here, but as far as what I find attractive about active inference and doing things as generative models is the attempt to describe or explain what's going on in the data.
365916	378650	C	0.7334235310554504	And that being said, in terms of a lot of many applications of data science and machine learning, the emphasis is upon prediction.
378990	386514	C	0.8914344906806946	And so are these listed statistical metrics you have here base factor, BIC, et cetera?
386662	391834	C	0.7825712561607361	Are those basically like your error measurements?
391962	409700	C	0.844203531742096	Are they your, how to say, just attempt at measuring like accuracy of prediction or or is there some trade off between explainability and prediction, if that makes sense?
411930	416600	A	0.8097605109214783	Yeah, just to kind of summarize these.
417450	431238	A	0.8223148584365845	So when you have nested parametric models, then you can evaluate whether two models are better in terms of including or not some parametric factor and then testing for their likelihood ratios.
431414	437206	A	0.6375170946121216	So this is a pretty straightforward test, but it's pretty limited to just strictly nested parametric models.
437238	439310	A	0.7299123406410217	So just getting that out of the way.
439460	441930	A	0.8758727312088013	In general, we're in the Bayesian setting.
442090	454082	A	0.6815195679664612	And so one of the advantages of the Bayesian setting is that you can compare two different models that have totally different architectures on the same data set.
454216	461090	A	0.904682993888855	So one way that that's done is with this Ike information criterion or the Bayesian information criterion.
461530	468866	A	0.7270650267601013	Both of them do something very similar, which is they reward model fit and they penalize the number of parameters.
469058	476700	A	0.8591985702514648	So actually in that way it's a lot like equation 2.5.
479650	485360	A	0.6974108815193176	You want to reward the fit but penalize the complexity of the model.
486130	492510	A	0.8445845246315002	Base factor is kind of like the Hlrt, but it doesn't have to be ratios of nested models.
492590	497650	A	0.8533579111099243	You can just compare the relative evidence in favor of one model or another.
497800	510200	A	0.8285506367683411	So this is used in structure modeling and structure learning, but this is all kind of like testing amongst a portfolio of models, which ones are better?
510650	515100	A	0.7844527363777161	Then how do you really get into the space of like, well, how effective is this model?
516270	526398	A	0.8400777578353882	You could test on a new data set, you could do all the regular techniques like cross validation, leave one out, et cetera, or test on a new data set.
526564	534160	A	0.6289483904838562	But then the very interesting question is how do you establish the efficacy of an action model?
535650	540594	A	0.7897751927375793	Because it's not just a passive inference model.
540632	558150	A	0.8567543029785156	So there you would need to get into like benchmarks like the OpenAI gym and other other settings where you can actually test the efficacy of an action model against some test input, rather than just a recognition model in some input.
558570	569290	A	0.5597320795059204	But that gets so situational that there's not like general there's not as many general considerations there.
569440	582270	A	0.8593143820762634	Another strategy is actually to even if it seems like a passive inference problem, like the MNIST digit data set, you could frame that in terms of the labeling is an action.
584210	590500	A	0.6527917981147766	So sometimes you can then take what seems to be a passive inference problem and then frame it as an active inference problem.
591670	600850	A	0.7848685383796692	So then you don't need to worry about these kind of like out of sample novel context action models, you can just kind of use standard benchmarks.
605680	639916	B	0.6476130485534668	Also, as far as I know, probably the only serious work on benchmarking the performance of active inference models is the work of Theofi Champion and his colleagues branching time active inference, which is they have proposed several different variants of branching time active inference, each of which with increasing performance in terms of their benchmarks.
640048	651076	B	0.4813620150089264	And aside from that, I'm not aware of any other work that takes this benchmarking study seriously enough to be reliable.
651188	656830	A	0.7463903427124023	I guess, yeah, surely there's a lot of proprietary work in this area.
659040	664780	A	0.8935319781303406	The paper discussed in live stream eight scaling active inference.
665440	688180	A	0.7861676812171936	So here they used like the kind of several standard testing environments I forget the pendulum, the hopper, and then I think like the mountain car or maybe that's not this one, but they test the standard AI tests.
694810	700440	A	0.666896641254425	All right, just looking just going through the ones.
700890	701382	A	0.4896698594093323	All right.
701436	704550	A	0.8557334542274475	Are the transitions be independent from the emissions?
705290	715130	A	0.9120895266532898	So for context, we're talking about Figure 7.3, discrete time active inference.
715550	718006	A	0.8470661044120789	Are the transitions independent from the emissions?
718038	720560	A	0.8686074018478394	And what does the next observation depend on?
724140	728100	A	0.7096978425979614	Short answer yes, they're independent.
728260	730756	A	0.8505806922912598	That's the sparsity of the Bayes graph.
730868	733960	A	0.7333741784095764	So we can clarify and give it a cleaner textual answer.
734030	746380	A	0.6662606596946716	But yes, the conditional independencies, which is the sparsity of the base graph which allows us to do factorized variational inference and get all of these advantages.
746980	749090	A	0.7779099941253662	That's exactly what we're looking at.
750180	759920	A	0.85857093334198	So this visual graphical model is the sparsity architecture of the conditional independencies.
762360	768900	A	0.8444802165031433	So yes, A and B are conditionally independent.
772570	774858	A	0.7941670417785645	Conditionally independent based on what?
775024	776138	A	0.6246722936630249	Hidden state.
776304	778300	A	0.8457204103469849	That's how Markov blanket works.
778750	780742	A	0.7092196941375732	Conditionally dependent on the blanket.
780806	782490	A	0.8206677436828613	A and B are independent.
783630	786790	A	0.773398220539093	That's true of all Bayesian graphs.
786950	799330	A	0.8368622064590454	So without worrying about the Markov blanket and the interface and the cybernetic agent and all of that, just any node that intervenes between two other nodes is the Markov blanket in that setting.
799670	804178	A	0.671074390411377	And then some other node, something else is blanketing it from something else.
804344	806446	A	0.8178976774215698	But yes, they're conditionally independent.
806558	808770	A	0.8679711818695068	What does the next observation depend on?
808920	813970	A	0.8291842341423035	Well, a matrix is the emission matrix tail of two densities.
814050	818230	A	0.8600435256958008	It can emit from a hidden state or it can recognize from an observation.
818890	832410	A	0.8748620748519897	So any given observation is only dependent upon the hidden state at that time and the hidden state at the next time is only dependent upon the transition matrix.
832910	839840	A	0.8904719948768616	The transition matrix has a slice for every action that can be taken.
840450	844350	A	0.7341061234474182	Every policy makes a slice in the B tensor.
844690	852494	A	0.8473584651947021	So it's like temperature in the room, hidden state, thermometer observation turn on the heater or not?
852612	854834	A	0.8055453896522522	And there's some B matrix for the heater is on.
854872	857202	A	0.5527275800704956	And there's some B matrix for the heater is not on.
857256	859380	A	0.79234778881073	Those are two slices in the same object.
860230	867640	A	0.8401193618774414	And then policy selection means which submatrix of B, which slice of B?
868250	871480	A	0.899837076663971	Should we multiply this to get to the next time step.
872170	875260	A	0.720166802406311	And then what observation would I expect there?
890780	894650	A	0.4832403063774109	Good kind of standard question.
895900	903452	A	0.8792634010314941	Okay, what is the relevance of thinking about good regulator theorem for thinking about the generative model?
903586	911230	A	0.8273949027061462	So, from Cybernetics, good regulator theorem originally stated every good regulator of a system must be a model of that system.
912020	916850	A	0.8427574634552002	Or more accurately, every good regulator must contain a model of that system.
927550	929530	A	0.8964719176292419	Here's a few quotes from the textbook.
936470	937794	A	0.7358101606369019	One way to approach this.
937832	941750	A	0.6310868263244629	Again, these are all kind of vague questions, but we can just see them many times.
941900	943810	A	0.6901844143867493	What happens to bad regulators?
943890	952342	A	0.7431361079216003	Well, information processing, sense making, decision making has a non zero informational cost land hour limit.
952406	958362	A	0.7438000440597534	There's a certain amount of actual jewels it takes to write and erase a bit.
958496	962170	A	0.8953403234481812	It from bit Chris Fields, everything that is in that area.
962320	966080	A	0.5660966634750366	So information processing is never free.
966450	976770	A	0.5224536061286926	So in a dissipative and even adversarial universe, to fail to regulate is to fail to exist.
977670	981090	A	0.7954710125923157	How do we operationalize regulation in this setting?
981430	988100	A	0.8777909278869629	That's going to be revisiting some non equilibrium steady state.
988570	1003654	A	0.5611596703529358	So if we're an observer looking at a system, in order for us to measure it as signal relative to noise, it has to be persistently remeasurable over the background.
1003702	1012060	A	0.8420574069023132	So we have to repeatedly measure it or an organism, let's just say, can remeasure itself.
1012590	1018430	A	0.7640239596366882	So minimizing surprise about its homeostatic temperature is being adaptive.
1018850	1029300	A	0.4650097191333771	Now, if temperature were just flat and so you could be unsurprised at homeostasis by doing nothing, you'd get lazy agents.
1029670	1052490	A	0.8423988819122314	But if temperature was really variable and contextual and there was kind of these nonlinear cues in the environment and all of that, then in order to reduce surprise about temperature, you'd end up coming to effectively have a model of the causal nexus that gives rise to observations.
1053630	1057900	A	0.8385840058326721	So the structure of the generative model doesn't have to be the structure of the generative process.
1059150	1067150	A	0.8748304843902588	However, they may come to have certain isomorphisms with each other or at least statistical regularities.
1067570	1078020	A	0.8784804344177246	If there's actually a 24 hours cycle in temperature, then you're going to see some kind of oscillatory model in the generative model.
1080150	1084818	A	0.8501589298248291	So there's more to say there.
1084904	1086494	A	0.9434766173362732	But this is one good note.
1086542	1098722	A	0.4730002284049988	Perhaps rather than good or bad regulator, the language of morality or preference, the language should be accurate and inaccurate, effective, ineffective, viable inviable skillful, unskillful.
1098786	1101818	A	0.6094577312469482	So there's always many ways to see it.
1101824	1120800	A	0.4669385552406311	But basically, if the generative model in the limit case, it just totally knows the causal architecture of the world, that's the easiest way to be absolutely unsurprised and to have things as you expect prefer is literally know how they're going to play out.
1121170	1122698	A	0.8711053133010864	That's not plausible.
1122874	1128110	A	0.8827030658721924	We use course grading and approximations and heuristics like variational inference.
1128270	1135090	A	0.5486684441566467	So the best we can do is just iteratively optimize towards bounding surprisal.
1135430	1152570	A	0.6797512173652649	So it's kind of like an empirical optimizable heuristic for being a good regulator without getting too bogged down into the philosophy and the exactitude the point is the ones that do well enough to live, live ones that don't do well enough, don't.
1156750	1160118	A	0.8501923084259033	But active inference is in the lineage of cybernetics.
1160294	1162042	A	0.9267720580101013	So it's unsurprising that good.
1162096	1164538	A	0.7428520917892456	Regulator theorem requisite diversity.
1164714	1166590	A	0.6417373418807983	Viable systems models.
1167010	1170670	A	0.8430087566375732	A lot of things in the Cybernetics ontology have a natural home.
1170740	1177298	A	0.8216728568077087	In the active ontology, they're talking about the same territory adaptive agents.
1177384	1181860	A	0.6875224709510803	So it's not surprising that they don't invalidate each other or anything like that.
1187500	1200110	B	0.6992072463035583	And actually, I think it's one of the reasons cybernetics has experienced kind of revitalization in recent years, especially in the past couple of years.
1204320	1208000	A	0.5141161680221558	All right, how can organs other than the brain be making inferences?
1211480	1213670	A	0.826544463634491	So there's a few angles on this.
1214360	1218390	A	0.9098005890846252	The first angle or Ali or anyone else want to give a thought?
1223340	1258420	B	0.7857603430747986	One thing to point is this sense of kind of semi PANC computationalism that if not pan computationalism, but something that bestows inference not only to complex self organizing systems such as the brain, but even to very simple linear systems, even a system as simple as an inert rock.
1259400	1268672	B	0.8824329376220703	So basically, it covers a spectrum from the point of view of FEP.
1268736	1273396	B	0.6448012590408325	There isn't anything specifically unique about the brain.
1273588	1282540	B	0.8081623315811157	In other words, the same mathematical technology can be applied both to inert rocks as well as the brain.
1282960	1289196	B	0.7123642563819885	So in my opinion, this question should be turned on its head.
1289378	1314900	B	0.8095553517341614	And it's not that how does inference can be seen in other systems, other simpler systems, but rather, the relevant question should be how does active inference or the notion of inference, inactive inference literature applies to all of those situations.
1315560	1333150	B	0.8828778862953186	So one way to do that is to define a kind of sparse coupling between the environment and the agent and define variational density as the internal states of the system.
1333760	1344960	B	0.8465461730957031	And also, obviously, the external states of the environment would be the states that needs to be tracked by those variational densities.
1345380	1373496	B	0.7181496024131775	And in this case, there isn't anything inherently different between the way the brains or, I don't know, even sentient agents somehow undertake inference from the way that the inert rocks can partition their states into internal and external states.
1373678	1406400	B	0.7109085917472839	But the main difference would be the way the Markov blanket in those simpler systems can act as a kind of statistical boundary that allows for non causal relationships I'm sorry, nonlinear causal relationships as opposed to linear causal relationships as opposed to nonlinear causal relationships as observed in complex agents or systems.
1409720	1413910	B	0.8559650182723999	That's some of the main distinctions between those.
1415240	1415990	A	0.9184247851371765	Awesome.
1416840	1417300	A	0.5491447448730469	Yeah.
1417370	1425156	A	0.8866405487060547	And then the classic paper that we often return to, like Ollie mentioned, the inert rock.
1425348	1453130	A	0.8351708650588989	So this paper has the kind of visual taxonomy from simpler to more sophisticated agents that's by sometimes the papers are in white, sometimes they're in black.
1455840	1467970	A	0.8519192934036255	Here inert systems, active, classical conservative systems, strange systems with world models of their own and all of this.
1469620	1480070	A	0.7615898847579956	But this is a great response, which is in a pan computationalist or pan cognitive pan inferentialist world, then how does active inference apply?
1480440	1487264	A	0.7696136832237244	One other angle is like, let's just think about the liver or the pancreas and blood sugar.
1487312	1488790	A	0.8329877257347107	That's our system of interest.
1489880	1495588	A	0.7240418791770935	Realism is like, is the pancreas actually doing inference on blood sugar?
1495764	1500410	A	0.6548978686332703	And people can have a range of opinions, but in a pan cognitiveist world, the answer is yes.
1501580	1509020	A	0.8507111072540283	Or one can kind of pull back and just say, we're going to model the pancreas as doing inference on blood sugar.
1510000	1512156	A	0.680902361869812	So it is no different.
1512338	1517490	A	0.5979900360107422	It's just an interpretation of the same statistical apparatus, basically.
1518420	1523868	A	0.7593451142311096	But there might be a setting where scientific realism is more justified.
1523964	1526640	A	0.8465923070907593	There's multiple lines of converging evidence.
1527300	1542250	A	0.7186048626899719	The model is comprehensive and being used to generate unique explanations and predictions versus, like, we're just going to do a linear relationship between these two things in the public health.
1542860	1549524	A	0.7455289959907532	And so then we're not going to confuse the linear model with those with the actual causal architecture.
1549572	1561020	A	0.5767846703529358	But there are situations that you can design or analyze where the sparsity structure of the system, which as early points to is what grants it all these interesting properties.
1561360	1585620	A	0.5442802309989929	It is becoming known to an extent that within two or three or four sigma, it's like we're starting to talk about how it is not mistaking the map for the territory, that's the map territory fallacy, but also not doing some kind of map denialism, which is the map territory fallacy, fallacy.
1588390	1593460	A	0.8789050579071045	And that's the paper which I'll add into by Maxwell et al.
1596620	1604920	B	0.8915358781814575	And also, if I may add another point with regard to the distinction between realism and instrumentalism.
1606400	1620960	B	0.617916464805603	I believe, at least in the realism school, probably the most relevant or well situated stance to reframe active inference.
1622740	1630648	B	0.883267343044281	I mean, reframe its ontological status is structural realism, as argued by Majid.
1630684	1633940	B	0.8963346481323242	Benny and others in several papers.
1635080	1635830	A	0.7344964146614075	Nice.
1636520	1637270	A	0.46103888750076294	Yes.
1638040	1657416	A	0.7689291834831238	He's joined several discussions and it's great to okay, so there's some quotes from the book, but yes, basically, forget organs other than the brain, how could anything be doing inference?
1657608	1664060	A	0.6979178190231323	And then another angle to take is just like the way that a baseball computes a parabola.
1665600	1675760	A	0.7763351798057556	You don't need to think that it's doing it like a calculator, but that's kind of like naturalizing the computation.
1676100	1679410	A	0.6364052891731262	That's a path of least action in a spatial space.
1680020	1684070	A	0.7584553956985474	But also you could have a path of least action in a cognitive space.
1684440	1686260	A	0.7435149550437927	That's Bayesian Mechanics.
1689080	1692016	A	0.8486987352371216	And then you could have more of a realist or more of an instrumentalist angle.
1692048	1693030	A	0.5299542546272278	Yeah, please.
1694520	1695172	B	0.5092127919197083	Sorry.
1695306	1727020	B	0.6438215374946594	Just one thing that somehow I mean, gets confused is some sometimes people think FEP's claim is that, okay, so if a self organizing if FEP formalism applies to a self organizing system, then it should persist through time by preserving its markup blankets intact.
1727180	1732480	B	0.8628772497177124	But actually the claim of the FEP is the other way around.
1732630	1741476	B	0.8669036626815796	So its main assertion is that if anything persists through time, how does FEP applies to it?
1741578	1752456	B	0.5349717736244202	So in other sense, FEP doesn't provide any justification per se for describing the way that the system persists through time.
1752638	1771840	B	0.8967634439468384	But we take the persistence of the system through time as the premise and then apply FEP to somehow investigate the implications of that premise through Bayesian mechanics and FEP formalism.
1773460	1788630	A	0.5189229846000671	Yeah, without the implicit or explicit acknowledgment of the persistent existence of what you're measuring or yourself, you don't even have something to discuss.
1789720	1800680	A	0.5363028049468994	And a lot of times when people just start to specify what they mean by the nouns and the verbs and the adjectives they use, that's a deflationary approach.
1801420	1806956	A	0.530856192111969	What if there's something that comes into being so fast in between moments and it's not being measured and you can't detect it?
1806978	1808910	A	0.7360008358955383	It's like, well, then how do you know it's there?
1811580	1815220	A	0.5147039294242859	That's not within that statistical sensing apparatus.
1815380	1825940	A	0.8319806456565857	So you have to take the existence of the thing to be primary in modeling some thing.
1828150	1831560	A	0.8329514861106873	And Axle Constant has a lot of work in that area.
1835810	1844800	B	0.9319205284118652	Daniel, could you please pull up the path integral paper on page four, if I may?
1849830	1850580	B	0.5092127919197083	Sorry.
1851030	1853634	A	0.7271970510482788	Yep, here we nice.
1853672	1854082	B	0.8529649972915649	Thank you.
1854136	1855506	B	0.5885648131370544	Exactly right there.
1855688	1858100	B	0.88861083984375	The FTP addresses the following question.
1860250	1867974	A	0.6765320897102356	And it's like, well, if we're talking about something that exists even in a mental geometry, that's what we want.
1868012	1872950	A	0.7819031476974487	We want to start with if it exists, even hypothetically.
1874350	1876442	A	0.5500630736351013	So people say, can it really describe all things?
1876496	1880006	A	0.7546668648719788	It's like, well, all the things that exist or could exist.
1880198	1886490	A	0.7711866497993469	We could use this modeling approach to model and talk about what properties it must possess.
1887390	1897470	A	0.6660686135292053	But if you're willing to open the door to things that don't or can't exist, then of course the sky's the limit on what properties they do or don't possess, because they might.
1897620	1900430	A	0.6529256105422974	It's like the non elephant animals.
1900590	1904302	A	0.7979405522346497	Things might not exist for a huge variety of reasons.
1904446	1922700	A	0.8217557668685913	However, things that exist, either from an external measure measurement or from self measurement, they must be acting as if they're self evidencing, reducing surprise relative to a generative model path of least action through an information geometric space.
1924350	1927914	A	0.5584556460380554	If it isn't doing that, you're not going to observe it.
1928112	1935070	A	0.8585504293441772	And that's where we get the particular partition and the particular partition in the particular physics.
1935730	1951860	A	0.6186516284942627	Bayesian mechanics since Karl Friston's 2019 monograph, free Energy Principle for a Particular Physics, that was like a big inflection point in this line of research.
1953030	1980860	A	0.8126987218856812	Whereas in the 2016 to 2018, there's a lot of qualitative work and the philosophical work applying to multiscale and nested systems and self organization amidst other empirical simulations happening continually in all of this reading works of different times, like different pieces are kind of going to be made clear or not.
1988950	1992690	A	0.8897641897201538	What is the role of precision in nested models?
1999960	2014088	A	0.8044250011444092	Well, here and also by way of demonstrating the transferability of active inference generative models, these three figures are discussed in live stream 28 from the original paper.
2014174	2015000	A	0.808493435382843	Smith et al.
2015070	2016920	A	0.7126200795173645	Computational phenomenology.
2017340	2021160	A	0.8219553828239441	So this is a static perceptual Bayesian model.
2021310	2033250	A	0.898902177810669	We have hidden state observations and we hear as a modulator, literally a neuromodulator on the A matrix Taylor two densities recognition matrix generative model.
2033860	2035692	A	0.7298744916915894	You have the precision.
2035836	2038892	A	0.807371973991394	So precision is one over the temperature.
2038956	2049110	A	0.8185297250747681	So whether you think of it as like higher temperature is lower precision or lower or vice versa, they're the same.
2050040	2055990	A	0.6640841364860535	When your precision is low, your temperature is high, a gets blurred out.
2056540	2065640	A	0.8233247995376587	The high temperature limit is like A becomes flattened, whereas in the low temperature limit, A becomes sharpened.
2066060	2072216	A	0.8187041282653809	And so this is a common method in recognition modeling.
2072408	2073150	A	0.7123860716819763	Okay?
2073520	2077004	A	0.8266391158103943	Now they move into adding action in.
2077042	2078156	A	0.7098963260650635	So here there's the policy.
2078258	2082530	A	0.8900159597396851	Figure 4.3, figure 7.3, everything we've looked at.
2083220	2088800	A	0.7876394987106323	And then they move to this nested model.
2088950	2112490	A	0.8812196254730225	Now, in the Sandbed Smith paper, it was being mobilized in terms of basically phenomenology meditative experiences, direct sensory perception, visual perception and isocades attention, unreportable attention and then awareness at a third level, observing that.
2112860	2118896	A	0.7322189211845398	And so you can add an uncertainty, like a precision on any variable.
2119028	2121612	A	0.7134673595428467	You could have an uncertainty on your prior d.
2121746	2124076	A	0.5988618731498718	You could have uncertainty on all kinds of things.
2124098	2130700	A	0.6305115222930908	But sometimes uncertainties on specific variables become associated with certain cognitive phenomena.
2131300	2145620	A	0.8072936534881592	In this case, they're using it to describe introspective and explainable AI systems, taking the exact same figures, exact same formalisms, just moving them into the AI setting.
2146200	2151668	A	0.8374608159065247	So precision on A and here's that live stream 28 and the slides and everything.
2151834	2161176	A	0.7910485863685608	Precision on A is like sensory ambiguity, precision on G.
2161358	2176940	A	0.9013233184814453	So how precise are you on the free energy that is associated with the affect in this sophisticated affect?
2178240	2182240	A	0.9159750938415527	Here's some discussion on Embodiment and the Alexander technique.
2184020	2193712	A	0.692954421043396	So, suffice to say, precision and nested modeling is basically like the general precision concept, which is basically used everywhere.
2193776	2195872	A	0.8098817467689514	This is how we fit Bayesian models.
2196016	2199940	A	0.8616845011711121	We have some hyper prior distribution on a parameter.
2200440	2208516	A	0.684351921081543	And if that prior distribution is too sharp, then it's a pathology of the prior.
2208548	2209876	A	0.5660028457641602	It's too precise.
2210068	2216010	A	0.734264075756073	If it was too imprecise, you have an underfit model.
2216460	2217592	A	0.6047232747077942	So it's like that.
2217646	2225444	A	0.8644676208496094	And especially in nested models, precision plays a role in kind of gating.
2225572	2227404	A	0.8222227692604065	Just in this case, it's a general question.
2227442	2229068	A	0.7537050843238831	So you could make it do anything, basically.
2229154	2236450	A	0.7124598622322083	But here the precision on A is like gating, let's just say the first and the third level.
2237780	2245380	A	0.5231954455375671	So if there's no attention being paid to sensory input, don't be surprised that they don't come up to attention.
2246440	2259610	A	0.7878511548042297	But if this gating can be like super direct and forceful, then you'll have propagation of informational causality on this network up to the higher level.
2272740	2274800	A	0.8086069226264954	Page 113 in the textbook.
2284360	2287788	A	0.8485283255577087	All right, the decision this is about planning as inference.
2287824	2305234	A	0.8810392022132874	Which one of these questions was also about the decision whether to model alternative futures, counterfactual futures conditioned upon policy selection.
2305282	2307546	A	0.8384711742401123	How would the world change if I did this or that?
2307648	2319530	A	0.8342118859291077	Is largely tied up with the choice between discrete and continuous models because the idea of selecting between alternative futures defined by sequences of actions is more simply articulated using discrete time models.
2319690	2325760	A	0.7803249359130859	All right, so figure 4.3.
2330610	2333018	A	0.9119859337806702	Figure 4.3 is like the rosetta stone.
2333114	2339234	A	0.8573887944221497	It juxtaposes the discrete time continuous discrete time generative model and the continuous time generative model.
2339432	2341140	A	0.7767347693443298	So I'll just copy this.
2343270	2348934	A	0.8693757057189941	In the discrete time model, you have st minus one s of t, s of t plus one.
2349052	2355670	A	0.8526796698570251	So futures and pasts, if it's sophisticated, active inference, are being explicitly modeled.
2356010	2360986	A	0.8399403691291809	So it's like what would happen at 07:00 if I did this?
2361168	2366598	A	0.7370421886444092	That is explicitly addressable with a discrete time model of the correct time horizon.
2366774	2371190	A	0.886590838432312	So you have to explicitly say, I'm talking about an hourly model and seven depth.
2371350	2386770	A	0.7663916945457458	And so then in branching time active inference, just like a chess algorithm, it's dealing with the branching structure because if you have a lot of affordances and you have a lot of time depth, you can imagine this is a combinatorial explosion.
2388470	2404066	A	0.7611852288246155	In contrast, though these two generative models are shown here to emphasize their structural similarity, the continuous time generative model is actually not explicitly modeling past, present, future time steps.
2404258	2414250	A	0.8823195099830627	Rather, it's modeling the generalized coordinates of motion x hidden state x prime rate of change, x double prime second derivative.
2414750	2418518	A	0.7391529083251953	So in that way, it's a lot more like a Taylor series expansion.
2418694	2431200	A	0.597263753414154	So a Taylor series expansion, technically even a Taylor series expansion of depth one, it has an answer for every single point in the number line, but that doesn't mean it's a good one.
2432370	2449800	A	0.8683227300643921	And so continuous time models kind of trivially have something to say about all possible time steps just by analytic continuation of the Taylor series expansion in the generalized coordinates of motion way.
2450650	2456520	A	0.7157211303710938	However, you don't necessarily know how accurate it is for any given point.
2458110	2462970	A	0.603877604007721	It also doesn't have explicit counterfactuals.
2463630	2469900	A	0.8674812912940979	So if you do some Taylor series expansion, it says yeah, at x equals three over y is five.
2470750	2473326	A	0.8139492273330688	But then if you say, well, what if it were different?
2473508	2480320	A	0.842142641544342	The only way you could do that would be change the parameters of the Taylor series and recalculate it at that point.
2481650	2485634	A	0.7078807353973389	So the model itself is not exactly doing these.
2485672	2487780	A	0.7464728951454163	Like what would happen if I did that?
2491610	2515120	A	0.5349107384681702	So futures are explicit in discrete time models and interpretable explicitly, whereas in continuous time models, pasts and futures are kind of trivially predicted such that it doesn't really make sense to talk about counterfactuals in the same exact way.
2519090	2527780	A	0.8817878365516663	And these models can be hybridized and fused, which is in chapter eight.
2536400	2538984	A	0.8914074897766113	Can we generate a code of template?
2539032	2541890	A	0.5425959229469299	Looks like yes, but there's of course more information.
2542980	2545330	A	0.7914302349090576	But it's an important question.
2553510	2556414	A	0.8761419653892517	How is temporal depth specific to planning?
2556542	2559700	A	0.7088942527770996	Does temporal depth in perception make any sense?
2560250	2561910	A	0.8543217778205872	What is temporal depth?
2562490	2567480	A	0.868994951248169	So temporal depth is how many timesteps the model is considered in the discrete time case.
2568810	2571670	A	0.7997475266456604	Does temporal depth make sense in perception?
2572090	2576250	A	0.7515395879745483	Well, perception is always modeled as instantaneous.
2576590	2591422	A	0.889815092086792	However, depending on the temporal scale of a model, that perception may be instantaneous over a certain temporal thickness power.
2591476	2594190	A	0.6625608205795288	Why is temporal depth specific to planning?
2594930	2604020	A	0.8823782205581665	So in planning as inference, policy selection as inference, you're selecting or sampling from policies based upon their expected free energy.
2607230	2618000	A	0.8791353106498718	In order to plan over a given time horizon and actually evaluate the playouts, you need to have a temporal depth of that amount.
2620930	2639038	A	0.8919638395309448	Thomas Parr in his bookstream so early implementations were coming from the generalized filtering approach.
2639134	2641826	A	0.854534387588501	Maybe it wasn't generalized at that point, but particle filtering approach.
2641858	2644146	A	0.7792732119560242	And then quipped these models with action.
2644338	2647410	A	0.7890321612358093	Then people started thinking about how to get sequential dynamics.
2647490	2661500	A	0.8549882769584656	Predator prey lock of voltera models winnerless competition neural Darwinism in these situations, there's an emergence of sequential recurrent continuous dynamics, like a limit cycle of more than two.
2662990	2668110	A	0.8245631456375122	Then people wanted to model explicit long term planning.
2668450	2689650	A	0.5449823141098022	And so from around 2014 or something, there was a lot more development in the discrete state space model, which enabled the well understood, partially observed Markov decision process and a lot of the characterization of planning as inference explore exploit.
2692010	2697826	A	0.856605052947998	Then later developments supported nested models.
2697858	2701222	A	0.8383849263191223	Here there's a discrete time on top and a discrete time on the bottom.
2701276	2704860	A	0.8111037015914917	But also it could be continuous time on the bottom.
2705390	2706186	A	0.7541995048522949	Oh yes.
2706288	2715766	A	0.9044629335403442	Then continuous state models were reintroduced as the lower levels of higher level discrete time models.
2715958	2724430	A	0.8510016798973083	And that is kind of like the folk psychology Livestream 46 active inference does not contradict folk psychology.
2725330	2733886	A	0.8919677734375	Discrete time decision making up top, discrete time and discrete decisions and then more in the sensory motor.
2733918	2736370	A	0.8011518716812134	It's more like continuous time, continuous action.
2749580	2762720	A	0.8793132305145264	Okay, new question, figure 6.1.
2769870	2774410	A	0.7627190947532654	All right, particular partition.
2779200	2783452	A	0.8884432315826416	How is the mutual interaction between active states and sensory states meant in six one?
2783506	2793010	A	0.9055721163749695	So the bi directional line here, can they mutually change their states without impacting neither internal nor external states?
2793540	2794930	A	0.5112258195877075	Yes, they could.
2795380	2801730	A	0.871583878993988	You could have nodes that these nodes are in communication with each other.
2802100	2806404	A	0.6375734210014343	In general, this image, it's more important what it doesn't show.
2806522	2810912	A	0.8307371735572815	So there's no backwards arrow from external to active or from internal to sensory.
2810976	2816410	A	0.5925915241241455	You can't have your thumb on the scale and the symmetry of whatever that is from the outside.
2817420	2821572	A	0.7111478447914124	And the only other constraint is no telepathy.
2821636	2823080	A	0.7199854254722595	No telekinesis.
2823580	2827372	A	0.8464546799659729	The only way to receive information about external states is through sensory states.
2827426	2832476	A	0.8342446088790894	The only way to act on costly intervene on external states is through active states.
2832658	2839516	A	0.78177410364151	So no thumb on the scale and the mirror, no telepathy.
2839548	2840880	A	0.7199854254722595	No telekinesis.
2841220	2851440	A	0.7036452889442444	That doesn't mean that for any given model, these arrows are like all important or all relative or relatively of the same importance.
2852020	2867080	A	0.8120226263999939	So if you want to design a computer system where the sensory states comes in one computer, and this is a second computer and this is the third computer, so like there's no direct edge between sensory and active states, you can create that causal architecture.
2867500	2868296	A	0.7733469605445862	What is it supposed.
2868318	2869770	A	0.6088491678237915	To model nothing.
2870940	2876616	A	0.9228879809379578	Modeling of supposed things is done in chapter six and beyond.
2876808	2882910	A	0.6492162942886353	But in general, this is not trying to model any specific situation despite the brain in the world.
2883520	2890690	A	0.9378730654716492	Could they circle mutually modifying their states and then eventually arrive at a state where they change the external internal states?
2893540	2895744	A	0.7544695138931274	Yeah, maybe they have a faster timescale or something.
2895782	2907332	A	0.887299656867981	Or maybe they're in communication with each other and then active states, like sensory states ends up influencing internal states via active influencing it.
2907386	2909348	A	0.5577794313430786	And so yes, it could happen.
2909514	2913140	A	0.8798862099647522	Would that mean that we can model with this trick, any arbitrary behavior?
2914460	2917876	A	0.7620242834091187	It's not necessarily a trick, it's just a particular partition.
2918068	2921428	A	0.9093096852302551	Would that allow us to model Turing equivalents?
2921604	2930348	A	0.6208534240722656	I'm not sure if there's an understanding of what formally demonstrates Turing equivalents then, but I believe it's possible.
2930434	2940880	A	0.783099889755249	I think as a Turing architecture, as far as I understand it, abstracted from the von Neumann architecture is basically just saying, like, you can do a Turing tape.
2941300	2942770	A	0.6415949463844299	So I don't see why not.
2943380	2944850	A	0.5236160159111023	Why would we need that?
2946820	2949890	A	0.7930864691734314	512k ought to be enough for anyone, right?
2952440	2954324	A	0.6946390271186829	I don't know why we need it.
2954522	2955990	A	0.6781393885612488	We expect it.
2959160	2972200	A	0.8040958046913147	But yeah, these graphs in general are more like the space of the possible with the important caveats that were mentioned with the no thumb on the scale and the mirror and the no telepathy and no telkinesis.
2972700	2981020	A	0.8810810446739197	But how relevant these edges are or what systems have what behavior or what cognitive phenomena are granted by what dynamics on graphs.
2981680	2989090	A	0.6290502548217773	There's just no general answer to those things because if you do a graph for one setting, it's going to be different.
2994230	3017208	A	0.8790517449378967	What did you mean when you said that any entree could be ordered with any side dish like that in this recipe theme that we're in models that include continuous or discrete variables or both, what is meant by variable states or observations?
3017304	3022830	A	0.8056870102882385	How can states be continuous, as those here are probably familiar with?
3023920	3030412	A	0.8096836805343628	States or observations could be like discrete, like zero or one or any integer.
3030476	3032770	A	0.8086979985237122	Or it could be a continuous number.
3037510	3041780	A	0.8128252625465393	Computers discretize continuous functions to approximate them.
3043290	3055666	A	0.9223790764808655	But there's so many exciting directions with unconventional computing, analog computing, mem computing, et cetera, that there's more to it.
3055708	3059050	A	0.8085808753967285	But just simply it could be any type of variable.
3065130	3095170	A	0.8373656868934631	This new question, let's maybe look at this one in closing, if the external state is unknowable, how can we set up a generative process so that's what's generating the observations when our experience is based solely on the process of producing variational free energy based on predictions and sensory inputs across the markup blanket?
3097190	3099940	A	0.6496672630310059	This person has just described the challenge of life.
3101110	3103286	A	0.6742843389511108	I don't think that there is a specific answer to that.
3103308	3106870	A	0.65709388256073	I think this is literally a restatement of the particular partition.
3107770	3117130	A	0.756180465221405	If this was just said, the challenge is to given the unknowability, direct unknowability of internal states.
3117280	3129630	A	0.5909809470176697	The challenge and the opportunity is to set up a generative model based solely on the process of reducing free energy, based on predictions and sensory inputs across the blanket and adaptive action.
3131810	3145540	A	0.553551435470581	I'm not sure if they meant process or model here because setting up a generative process is something that the human modeler does when they're designing a simulation, but not like what the animal has to do.
3149080	3154330	A	0.7534607648849487	What I'm trying to get at here is we are making an assumption about the generator of sensory input when making the model.
3155020	3158948	A	0.8169206976890564	Yes, but that model can never be accurate.
3159124	3162132	A	0.6263205409049988	Well, it absolutely can be accurate.
3162276	3168600	A	0.6359990239143372	It's never going to be a one to one map is the territory, but of course it can be accurate.
3168680	3178030	A	0.691070556640625	We don't need to understand have an atomic simulation of the sun to have a generative process of how many photons are going to hit my window tomorrow at 07:00 a.m..
3179440	3183664	A	0.6460586786270142	So there's a core invalidity in the notion that we set up a generative process model.
3183862	3193892	A	0.5136401653289795	Not sure what ontology mixing is happening, but almost by definition we're introducing an error in the model by setting up the parameters for the generative process.
3193946	3201110	A	0.7388349175453186	The generative model, we remove the fundamental aspect of actin, which is the dynamical system has only one thing it can do and that's to reduce free energy.
3201820	3205210	A	0.6411086320877075	So there's some good points and some mixed things.
3207740	3210948	A	0.8577814102172852	What it does is the action it takes in the world variational.
3210964	3215000	A	0.7442874908447266	Free energy is just a tractable computational heuristic.
3215340	3229916	A	0.791353702545166	Yes, if you set up the generative process to be a number continuous number between one and ten and then the generative model to do the exact same, to kind of have pre structurally learnt the problem, then it's going to be a simple simulation.
3230108	3237170	A	0.7139102220535278	Whereas you could have a more sophisticated simulation that involves structured learning as part of the agent's generative model.
3238500	3244308	A	0.5689626336097717	Are we not introducing information to the model that would not be available in the real world if we actually defined the generative process?
3244474	3249380	A	0.5628236532211304	Yeah, you can give any model too much information, essentially.
3251260	3272616	A	0.6458654999732971	So if the model actually knows what is really happening, then if you were doing a video game and you had an agent with supervisory access to the other players inferences or even control their actions, yeah, that's not going to work in a tournament.
3272808	3278028	A	0.8771675229072571	But here with a particular partition, we can actually know the information encapsulation.
3278204	3282800	A	0.9228228330612183	And Majid Benny explores that in terms of the partial information encapsulation.
3283700	3287090	A	0.5519464015960693	So are we not introducing information to the model that would not be available?
3288100	3291936	A	0.8312174081802368	It's your restaurant, do whatever you got to do with the recipe.
3292048	3305716	A	0.5103828310966492	If you want a pedagogical example that just makes some clean graphs and is very straightforward and doesn't engage the complexities of like sophisticated cognitive structure learning, that model is not going to complain.
3305908	3317740	A	0.6760640740394592	If you want to do strange loop reflexive structure modeling for ambiguous inputs of unstructured multimodal data, et cetera, then that is your challenge.
3320460	3324308	A	0.5949538946151733	So for many people it's just one closing comment.
3324404	3325112	A	0.7131403088569641	In many people.
3325166	3330568	A	0.5873770117759705	This is the first time they've been exposed to statistical modeling, and iterative modeling formally.
3330744	3347760	A	0.7755203247070312	So that's why there are often questions that are, like, less about active inference, but sometimes crop up about basically using statistical modeling overall, which is a great thing because these are challenging and areas with a lot of implicit and tacit knowledge.
3350740	3352160	A	0.8675476312637329	Thank you, fellows.
3353240	3364564	A	0.9678346514701843	Looking forward to next discussions and into heading into chapter seven next week.
3364602	3371664	A	0.8090716600418091	Ali, maybe we'll do a maybe we'll do our zero for chapter seven and eight, but not in a hurry.
3371712	3372950	A	0.5973567366600037	But we'll figure it out.
3373880	3374630	B	0.4753468334674835	Sure.
3375240	3376500	B	0.9793016910552979	Thank you so much.
3376650	3377510	A	0.8529649972915649	Thank you.
3377920	3378812	C	0.8529649972915649	Thank you.
3378946	3379528	A	0.5137447118759155	Bye.
