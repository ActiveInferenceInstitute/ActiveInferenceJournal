start	end	sentNum	speaker	confidence	text
2920	3444	2	A	0.45	All right.
3482	4550	3	A	0.79777	Greetings, everyone.
6120	8724	4	A	0.98843	It's June 20, 2023.
8842	12230	5	A	0.52223	We're in our second discussion on chapter six.
12760	17270	6	A	0.70092	So we'll first just have any general comments or anything.
17720	33100	7	A	0.99978	Then we'll turn to the questions table and look at what questions we didn't get to last time and just kind of revisit, maybe condense some questions or just see what we can do with what is here.
33170	39730	8	A	0.95987	So anyone just want to make any general comments on chapter six?
48750	52442	9	B	0.68	I believe this is the second session on chapter six, right?
52576	53306	10	A	0.74277	Correct.
53488	55222	11	B	0.76604	Or maybe I lost.
55286	55802	12	A	0.99932	Okay.
55936	56940	13	A	0.58094	Yeah, it is.
58690	59440	14	A	0.78848	Yeah.
60610	67710	15	A	0.97579	There was only one onboarding needed for the welcome back here, so we started one week faster into the rhythm.
69910	70610	16	A	0.86957	Okay.
70760	78434	17	A	0.78392	So it looks like these were the questions I remember we left off with this one.
78552	84440	18	A	0.85772	Let's just develop this into what was into a question, and then we'll continue on.
97370	98120	19	A	0.80974	Okay.
101130	121500	20	A	1	Is there a common or good representation or rubric for evaluating Generative Model Generative process, which is change it to Generative Models and Generative Processes?
131210	135000	21	A	0.99992	Anyone want to give a first thought or just some other related question?
146310	147170	22	B	0.99858	Go on, please.
147240	147582	23	B	0.99988	Sorry.
147656	148600	24	A	0.64674	No, it's okay.
153560	176572	25	B	0.93383	Yeah, I'm not sure about what's the exact criteria for evaluating generative models or generative processes, but one thing is for sure that, well, I mean, one of the main at least when evaluating generative model one of our main.
176626	197440	26	B	0.36953	Criteria should be how closely it tracks our situation of interest and specifically how relevant it is for addressing the question we're trying to examine.
199320	204768	27	B	0.55	I don't think it's something clear cut or, I don't know, written in stone.
204944	218490	28	B	1	And based on the context and the situation, the Evaluation Criteria rubric should be different, I suppose, both for generative Model and generative process.
224290	224894	29	A	0.89955	Yeah.
225012	241830	30	A	0.68652	So again, we'll revisit this Generative Model Generative process question later, following the recent Livestream, but generative process working with generative process as the underlying process that gives rise to the observations.
242250	248070	31	A	0.99999	This would seem to be more adequate to the extent that it can better describe the measurements.
248570	263020	32	A	0.49016	Generative Model, similarly, is being evaluated based upon its ability to fit to the generative process as well as phenomena of interest.
264910	278766	33	A	0.99327	So not just to fit visual data, but maybe to model something like some illusion in visual, then there's a wide range of more general statistical modeling techniques.
278798	284450	34	A	0.99907	So first is like the ultimate grab bag, which is just how relevant is the overall modeling.
285830	293330	35	A	0.63777	Then there are statistical evaluations of model adequacy and model selection.
293490	295330	36	A	0.55443	Ike information criterion.
295410	298550	37	A	0.93447	Bayesian information criterion, base factor.
299530	302182	38	A	0.92595	Hierarchical likelihood ratio test.
302316	307290	39	A	0.99999	If you have a parametric Model Bootstrap and non parametric statistics.
307630	327146	40	A	0.99959	Just general modeling, and then taking that more out of the statistics into the Engineering Model Lifecycle, then that's where you can think about validation, verification, validity, quality, et cetera.
327258	329410	41	A	0.65443	Systems engineering model lifecycle.
334980	337170	42	A	0.99999	Any other thoughts or questions on this?
343010	343760	43	A	0.76508	Okay.
346450	365862	44	C	0.99065	I'm coming from kind of an early career data scientist background here, but as far as what I find attractive about active inference and doing things as generative models is the attempt to describe or explain what's going on in the data.
365916	378650	45	C	0.57	And that being said, in terms of a lot of many applications of data science and machine learning, the emphasis is upon prediction.
378990	386514	46	C	0.53	And so are these listed statistical metrics you have here base factor, BIC, et cetera?
386662	391834	47	C	0.99997	Are those basically like your error measurements?
391962	409700	48	C	0.99853	Are they your, how to say, just attempt at measuring like accuracy of prediction or or is there some trade off between explainability and prediction, if that makes sense?
411930	416600	49	A	0.98	Yeah, just to kind of summarize these.
417450	431238	50	A	0.99387	So when you have nested parametric models, then you can evaluate whether two models are better in terms of including or not some parametric factor and then testing for their likelihood ratios.
431414	437206	51	A	0.99969	So this is a pretty straightforward test, but it's pretty limited to just strictly nested parametric models.
437238	439310	52	A	0.9999	So just getting that out of the way.
439460	441930	53	A	0.99973	In general, we're in the Bayesian setting.
442090	454082	54	A	1	And so one of the advantages of the Bayesian setting is that you can compare two different models that have totally different architectures on the same data set.
454216	461090	55	A	0.99783	So one way that that's done is with this Ike information criterion or the Bayesian information criterion.
461530	468866	56	A	1	Both of them do something very similar, which is they reward model fit and they penalize the number of parameters.
469058	476700	57	A	0.81732	So actually in that way it's a lot like equation 2.5.
479650	485360	58	A	0.99956	You want to reward the fit but penalize the complexity of the model.
486130	492510	59	A	0.99699	Base factor is kind of like the Hlrt, but it doesn't have to be ratios of nested models.
492590	497650	60	A	0.99999	You can just compare the relative evidence in favor of one model or another.
497800	510200	61	A	0.99972	So this is used in structure modeling and structure learning, but this is all kind of like testing amongst a portfolio of models, which ones are better?
510650	515100	62	A	0.9981	Then how do you really get into the space of like, well, how effective is this model?
516270	526398	63	A	0.99993	You could test on a new data set, you could do all the regular techniques like cross validation, leave one out, et cetera, or test on a new data set.
526564	534160	64	A	0.99958	But then the very interesting question is how do you establish the efficacy of an action model?
535650	540594	65	A	0.99995	Because it's not just a passive inference model.
540632	558150	66	A	0.78306	So there you would need to get into like benchmarks like the OpenAI gym and other other settings where you can actually test the efficacy of an action model against some test input, rather than just a recognition model in some input.
558570	569290	67	A	0.99999	But that gets so situational that there's not like general there's not as many general considerations there.
569440	582270	68	A	0.9196	Another strategy is actually to even if it seems like a passive inference problem, like the MNIST digit data set, you could frame that in terms of the labeling is an action.
584210	590500	69	A	0.82318	So sometimes you can then take what seems to be a passive inference problem and then frame it as an active inference problem.
591670	600850	70	A	0.99997	So then you don't need to worry about these kind of like out of sample novel context action models, you can just kind of use standard benchmarks.
605680	639916	71	B	0.99941	Also, as far as I know, probably the only serious work on benchmarking the performance of active inference models is the work of Theofi Champion and his colleagues branching time active inference, which is they have proposed several different variants of branching time active inference, each of which with increasing performance in terms of their benchmarks.
640048	651076	72	B	0.97	And aside from that, I'm not aware of any other work that takes this benchmarking study seriously enough to be reliable.
651188	656830	73	A	1	I guess, yeah, surely there's a lot of proprietary work in this area.
659040	664780	74	A	0.98	The paper discussed in live stream eight scaling active inference.
665440	688180	75	A	0.83099	So here they used like the kind of several standard testing environments I forget the pendulum, the hopper, and then I think like the mountain car or maybe that's not this one, but they test the standard AI tests.
694810	700440	76	A	0.83	All right, just looking just going through the ones.
700890	701382	77	A	0.83	All right.
701436	704550	78	A	0.99903	Are the transitions be independent from the emissions?
705290	715130	79	A	0.99814	So for context, we're talking about Figure 7.3, discrete time active inference.
715550	718006	80	A	0.99993	Are the transitions independent from the emissions?
718038	720560	81	A	1	And what does the next observation depend on?
724140	728100	82	A	0.99998	Short answer yes, they're independent.
728260	730756	83	A	0.50176	That's the sparsity of the Bayes graph.
730868	733960	84	A	0.99999	So we can clarify and give it a cleaner textual answer.
734030	746380	85	A	0.97069	But yes, the conditional independencies, which is the sparsity of the base graph which allows us to do factorized variational inference and get all of these advantages.
746980	749090	86	A	0.81548	That's exactly what we're looking at.
750180	759920	87	A	0.99253	So this visual graphical model is the sparsity architecture of the conditional independencies.
762360	768900	88	A	0.91736	So yes, A and B are conditionally independent.
772570	774858	89	A	0.80833	Conditionally independent based on what?
775024	776138	90	A	0.99972	Hidden state.
776304	778300	91	A	0.98622	That's how Markov blanket works.
778750	780742	92	A	0.99714	Conditionally dependent on the blanket.
780806	782490	93	A	0.63	A and B are independent.
783630	786790	94	A	0.99857	That's true of all Bayesian graphs.
786950	799330	95	A	0.53609	So without worrying about the Markov blanket and the interface and the cybernetic agent and all of that, just any node that intervenes between two other nodes is the Markov blanket in that setting.
799670	804178	96	A	0.78	And then some other node, something else is blanketing it from something else.
804344	806446	97	A	1	But yes, they're conditionally independent.
806558	808770	98	A	1	What does the next observation depend on?
808920	813970	99	A	0.81708	Well, a matrix is the emission matrix tail of two densities.
814050	818230	100	A	0.99884	It can emit from a hidden state or it can recognize from an observation.
818890	832410	101	A	0.9975	So any given observation is only dependent upon the hidden state at that time and the hidden state at the next time is only dependent upon the transition matrix.
832910	839840	102	A	1	The transition matrix has a slice for every action that can be taken.
840450	844350	103	A	0.99997	Every policy makes a slice in the B tensor.
844690	852494	104	A	0.99976	So it's like temperature in the room, hidden state, thermometer observation turn on the heater or not?
852612	854834	105	A	0.94	And there's some B matrix for the heater is on.
854872	857202	106	A	1	And there's some B matrix for the heater is not on.
857256	859380	107	A	0.99991	Those are two slices in the same object.
860230	867640	108	A	1	And then policy selection means which submatrix of B, which slice of B?
868250	871480	109	A	0.99639	Should we multiply this to get to the next time step.
872170	875260	110	A	1	And then what observation would I expect there?
890780	894650	111	A	0.66831	Good kind of standard question.
895900	903452	112	A	0.99682	Okay, what is the relevance of thinking about good regulator theorem for thinking about the generative model?
903586	911230	113	A	0.6981	So, from Cybernetics, good regulator theorem originally stated every good regulator of a system must be a model of that system.
912020	916850	114	A	0.66422	Or more accurately, every good regulator must contain a model of that system.
927550	929530	115	A	0.97264	Here's a few quotes from the textbook.
936470	937794	116	A	1	One way to approach this.
937832	941750	117	A	0.99999	Again, these are all kind of vague questions, but we can just see them many times.
941900	943810	118	A	1	What happens to bad regulators?
943890	952342	119	A	0.99986	Well, information processing, sense making, decision making has a non zero informational cost land hour limit.
952406	958362	120	A	0.8907	There's a certain amount of actual jewels it takes to write and erase a bit.
958496	962170	121	A	0.90725	It from bit Chris Fields, everything that is in that area.
962320	966080	122	A	0.99929	So information processing is never free.
966450	976770	123	A	0.99995	So in a dissipative and even adversarial universe, to fail to regulate is to fail to exist.
977670	981090	124	A	1	How do we operationalize regulation in this setting?
981430	988100	125	A	0.99938	That's going to be revisiting some non equilibrium steady state.
988570	1003654	126	A	0.99852	So if we're an observer looking at a system, in order for us to measure it as signal relative to noise, it has to be persistently remeasurable over the background.
1003702	1012060	127	A	0.99999	So we have to repeatedly measure it or an organism, let's just say, can remeasure itself.
1012590	1018430	128	A	0.99998	So minimizing surprise about its homeostatic temperature is being adaptive.
1018850	1029300	129	A	1	Now, if temperature were just flat and so you could be unsurprised at homeostasis by doing nothing, you'd get lazy agents.
1029670	1052490	130	A	0.99999	But if temperature was really variable and contextual and there was kind of these nonlinear cues in the environment and all of that, then in order to reduce surprise about temperature, you'd end up coming to effectively have a model of the causal nexus that gives rise to observations.
1053630	1057900	131	A	0.99992	So the structure of the generative model doesn't have to be the structure of the generative process.
1059150	1067150	132	A	0.99999	However, they may come to have certain isomorphisms with each other or at least statistical regularities.
1067570	1078020	133	A	0.99999	If there's actually a 24 hours cycle in temperature, then you're going to see some kind of oscillatory model in the generative model.
1080150	1084818	134	A	0.92194	So there's more to say there.
1084904	1086494	135	A	0.62143	But this is one good note.
1086542	1098722	136	A	0.86124	Perhaps rather than good or bad regulator, the language of morality or preference, the language should be accurate and inaccurate, effective, ineffective, viable inviable skillful, unskillful.
1098786	1101818	137	A	0.82184	So there's always many ways to see it.
1101824	1120800	138	A	0.99995	But basically, if the generative model in the limit case, it just totally knows the causal architecture of the world, that's the easiest way to be absolutely unsurprised and to have things as you expect prefer is literally know how they're going to play out.
1121170	1122698	139	A	0.99993	That's not plausible.
1122874	1128110	140	A	0.99999	We use course grading and approximations and heuristics like variational inference.
1128270	1135090	141	A	0.90559	So the best we can do is just iteratively optimize towards bounding surprisal.
1135430	1152570	142	A	0.94562	So it's kind of like an empirical optimizable heuristic for being a good regulator without getting too bogged down into the philosophy and the exactitude the point is the ones that do well enough to live, live ones that don't do well enough, don't.
1156750	1160118	143	A	0.85956	But active inference is in the lineage of cybernetics.
1160294	1162042	144	A	0.99988	So it's unsurprising that good.
1162096	1164538	145	A	0.96163	Regulator theorem requisite diversity.
1164714	1166590	146	A	0.99525	Viable systems models.
1167010	1170670	147	A	0.5	A lot of things in the Cybernetics ontology have a natural home.
1170740	1177298	148	A	0.99946	In the active ontology, they're talking about the same territory adaptive agents.
1177384	1181860	149	A	0.84765	So it's not surprising that they don't invalidate each other or anything like that.
1187500	1200110	150	B	0.73	And actually, I think it's one of the reasons cybernetics has experienced kind of revitalization in recent years, especially in the past couple of years.
1204320	1208000	151	A	0.58	All right, how can organs other than the brain be making inferences?
1211480	1213670	152	A	0.99983	So there's a few angles on this.
1214360	1218390	153	A	0.65	The first angle or Ali or anyone else want to give a thought?
1223340	1258420	154	B	0.99	One thing to point is this sense of kind of semi PANC computationalism that if not pan computationalism, but something that bestows inference not only to complex self organizing systems such as the brain, but even to very simple linear systems, even a system as simple as an inert rock.
1259400	1268672	155	B	0.98334	So basically, it covers a spectrum from the point of view of FEP.
1268736	1273396	156	B	1	There isn't anything specifically unique about the brain.
1273588	1282540	157	B	0.83015	In other words, the same mathematical technology can be applied both to inert rocks as well as the brain.
1282960	1289196	158	B	0.90656	So in my opinion, this question should be turned on its head.
1289378	1314900	159	B	1	And it's not that how does inference can be seen in other systems, other simpler systems, but rather, the relevant question should be how does active inference or the notion of inference, inactive inference literature applies to all of those situations.
1315560	1333150	160	B	0.98256	So one way to do that is to define a kind of sparse coupling between the environment and the agent and define variational density as the internal states of the system.
1333760	1344960	161	B	1	And also, obviously, the external states of the environment would be the states that needs to be tracked by those variational densities.
1345380	1373496	162	B	0.54	And in this case, there isn't anything inherently different between the way the brains or, I don't know, even sentient agents somehow undertake inference from the way that the inert rocks can partition their states into internal and external states.
1373678	1406400	163	B	0.99996	But the main difference would be the way the Markov blanket in those simpler systems can act as a kind of statistical boundary that allows for non causal relationships I'm sorry, nonlinear causal relationships as opposed to linear causal relationships as opposed to nonlinear causal relationships as observed in complex agents or systems.
1409720	1413910	164	B	0.93993	That's some of the main distinctions between those.
1415240	1415990	165	A	0.9998	Awesome.
1416840	1417300	166	A	0.972	Yeah.
1417370	1425156	167	A	0.96	And then the classic paper that we often return to, like Ollie mentioned, the inert rock.
1425348	1453130	168	A	0.98488	So this paper has the kind of visual taxonomy from simpler to more sophisticated agents that's by sometimes the papers are in white, sometimes they're in black.
1455840	1467970	169	A	0.98665	Here inert systems, active, classical conservative systems, strange systems with world models of their own and all of this.
1469620	1480070	170	A	0.99932	But this is a great response, which is in a pan computationalist or pan cognitive pan inferentialist world, then how does active inference apply?
1480440	1487264	171	A	1	One other angle is like, let's just think about the liver or the pancreas and blood sugar.
1487312	1488790	172	A	0.99994	That's our system of interest.
1489880	1495588	173	A	0.93343	Realism is like, is the pancreas actually doing inference on blood sugar?
1495764	1500410	174	A	0.84	And people can have a range of opinions, but in a pan cognitiveist world, the answer is yes.
1501580	1509020	175	A	0.99999	Or one can kind of pull back and just say, we're going to model the pancreas as doing inference on blood sugar.
1510000	1512156	176	A	0.99667	So it is no different.
1512338	1517490	177	A	0.70456	It's just an interpretation of the same statistical apparatus, basically.
1518420	1523868	178	A	0.55174	But there might be a setting where scientific realism is more justified.
1523964	1526640	179	A	0.99988	There's multiple lines of converging evidence.
1527300	1542250	180	A	1	The model is comprehensive and being used to generate unique explanations and predictions versus, like, we're just going to do a linear relationship between these two things in the public health.
1542860	1549524	181	A	0.55	And so then we're not going to confuse the linear model with those with the actual causal architecture.
1549572	1561020	182	A	1	But there are situations that you can design or analyze where the sparsity structure of the system, which as early points to is what grants it all these interesting properties.
1561360	1585620	183	A	0.71573	It is becoming known to an extent that within two or three or four sigma, it's like we're starting to talk about how it is not mistaking the map for the territory, that's the map territory fallacy, but also not doing some kind of map denialism, which is the map territory fallacy, fallacy.
1588390	1593460	184	A	1	And that's the paper which I'll add into by Maxwell et al.
1596620	1604920	185	B	0.96	And also, if I may add another point with regard to the distinction between realism and instrumentalism.
1606400	1620960	186	B	0.69	I believe, at least in the realism school, probably the most relevant or well situated stance to reframe active inference.
1622740	1630648	187	B	0.64	I mean, reframe its ontological status is structural realism, as argued by Majid.
1630684	1633940	188	B	0.98601	Benny and others in several papers.
1635080	1635830	189	A	0.99815	Nice.
1636520	1637270	190	A	0.71796	Yes.
1638040	1657416	191	A	0.96913	He's joined several discussions and it's great to okay, so there's some quotes from the book, but yes, basically, forget organs other than the brain, how could anything be doing inference?
1657608	1664060	192	A	1	And then another angle to take is just like the way that a baseball computes a parabola.
1665600	1675760	193	A	0.81088	You don't need to think that it's doing it like a calculator, but that's kind of like naturalizing the computation.
1676100	1679410	194	A	0.67851	That's a path of least action in a spatial space.
1680020	1684070	195	A	0.99999	But also you could have a path of least action in a cognitive space.
1684440	1686260	196	A	0.73559	That's Bayesian Mechanics.
1689080	1692016	197	A	0.69	And then you could have more of a realist or more of an instrumentalist angle.
1692048	1693030	198	A	0.98696	Yeah, please.
1694520	1695172	199	B	0.9998	Sorry.
1695306	1727020	200	B	0.69725	Just one thing that somehow I mean, gets confused is some sometimes people think FEP's claim is that, okay, so if a self organizing if FEP formalism applies to a self organizing system, then it should persist through time by preserving its markup blankets intact.
1727180	1732480	201	B	0.99997	But actually the claim of the FEP is the other way around.
1732630	1741476	202	B	0.99977	So its main assertion is that if anything persists through time, how does FEP applies to it?
1741578	1752456	203	B	0.99966	So in other sense, FEP doesn't provide any justification per se for describing the way that the system persists through time.
1752638	1771840	204	B	0.99999	But we take the persistence of the system through time as the premise and then apply FEP to somehow investigate the implications of that premise through Bayesian mechanics and FEP formalism.
1773460	1788630	205	A	0.63541	Yeah, without the implicit or explicit acknowledgment of the persistent existence of what you're measuring or yourself, you don't even have something to discuss.
1789720	1800680	206	A	1	And a lot of times when people just start to specify what they mean by the nouns and the verbs and the adjectives they use, that's a deflationary approach.
1801420	1806956	207	A	0.99996	What if there's something that comes into being so fast in between moments and it's not being measured and you can't detect it?
1806978	1808910	208	A	0.99803	It's like, well, then how do you know it's there?
1811580	1815220	209	A	0.50673	That's not within that statistical sensing apparatus.
1815380	1825940	210	A	0.61268	So you have to take the existence of the thing to be primary in modeling some thing.
1828150	1831560	211	A	0.52	And Axle Constant has a lot of work in that area.
1835810	1844800	212	B	0.93567	Daniel, could you please pull up the path integral paper on page four, if I may?
1849830	1850580	213	B	0.99577	Sorry.
1851030	1853634	214	A	0.4158	Yep, here we nice.
1853672	1854082	215	B	0.99961	Thank you.
1854136	1855506	216	B	0.99998	Exactly right there.
1855688	1858100	217	B	0.86	The FTP addresses the following question.
1860250	1867974	218	A	1	And it's like, well, if we're talking about something that exists even in a mental geometry, that's what we want.
1868012	1872950	219	A	0.56895	We want to start with if it exists, even hypothetically.
1874350	1876442	220	A	0.716	So people say, can it really describe all things?
1876496	1880006	221	A	0.99991	It's like, well, all the things that exist or could exist.
1880198	1886490	222	A	0.99999	We could use this modeling approach to model and talk about what properties it must possess.
1887390	1897470	223	A	0.99995	But if you're willing to open the door to things that don't or can't exist, then of course the sky's the limit on what properties they do or don't possess, because they might.
1897620	1900430	224	A	0.99642	It's like the non elephant animals.
1900590	1904302	225	A	0.99989	Things might not exist for a huge variety of reasons.
1904446	1922700	226	A	1	However, things that exist, either from an external measure measurement or from self measurement, they must be acting as if they're self evidencing, reducing surprise relative to a generative model path of least action through an information geometric space.
1924350	1927914	227	A	0.98628	If it isn't doing that, you're not going to observe it.
1928112	1935070	228	A	1	And that's where we get the particular partition and the particular partition in the particular physics.
1935730	1951860	229	A	0.6946	Bayesian mechanics since Karl Friston's 2019 monograph, free Energy Principle for a Particular Physics, that was like a big inflection point in this line of research.
1953030	1980860	230	A	0.99962	Whereas in the 2016 to 2018, there's a lot of qualitative work and the philosophical work applying to multiscale and nested systems and self organization amidst other empirical simulations happening continually in all of this reading works of different times, like different pieces are kind of going to be made clear or not.
1988950	1992690	231	A	0.99972	What is the role of precision in nested models?
1999960	2014088	232	A	0.57371	Well, here and also by way of demonstrating the transferability of active inference generative models, these three figures are discussed in live stream 28 from the original paper.
2014174	2015000	233	A	0.99977	Smith et al.
2015070	2016920	234	A	0.99999	Computational phenomenology.
2017340	2021160	235	A	0.99995	So this is a static perceptual Bayesian model.
2021310	2033250	236	A	0.69097	We have hidden state observations and we hear as a modulator, literally a neuromodulator on the A matrix Taylor two densities recognition matrix generative model.
2033860	2035692	237	A	0.99998	You have the precision.
2035836	2038892	238	A	0.74705	So precision is one over the temperature.
2038956	2049110	239	A	0.99965	So whether you think of it as like higher temperature is lower precision or lower or vice versa, they're the same.
2050040	2055990	240	A	1	When your precision is low, your temperature is high, a gets blurred out.
2056540	2065640	241	A	1	The high temperature limit is like A becomes flattened, whereas in the low temperature limit, A becomes sharpened.
2066060	2072216	242	A	0.83	And so this is a common method in recognition modeling.
2072408	2073150	243	A	0.99854	Okay?
2073520	2077004	244	A	1	Now they move into adding action in.
2077042	2078156	245	A	0.99998	So here there's the policy.
2078258	2082530	246	A	0.9999	Figure 4.3, figure 7.3, everything we've looked at.
2083220	2088800	247	A	1	And then they move to this nested model.
2088950	2112490	248	A	0.54	Now, in the Sandbed Smith paper, it was being mobilized in terms of basically phenomenology meditative experiences, direct sensory perception, visual perception and isocades attention, unreportable attention and then awareness at a third level, observing that.
2112860	2118896	249	A	0.76	And so you can add an uncertainty, like a precision on any variable.
2119028	2121612	250	A	0.99998	You could have an uncertainty on your prior d.
2121746	2124076	251	A	0.99999	You could have uncertainty on all kinds of things.
2124098	2130700	252	A	0.95439	But sometimes uncertainties on specific variables become associated with certain cognitive phenomena.
2131300	2145620	253	A	0.99999	In this case, they're using it to describe introspective and explainable AI systems, taking the exact same figures, exact same formalisms, just moving them into the AI setting.
2146200	2151668	254	A	0.77444	So precision on A and here's that live stream 28 and the slides and everything.
2151834	2161176	255	A	0.99715	Precision on A is like sensory ambiguity, precision on G.
2161358	2176940	256	A	0.99496	So how precise are you on the free energy that is associated with the affect in this sophisticated affect?
2178240	2182240	257	A	0.95818	Here's some discussion on Embodiment and the Alexander technique.
2184020	2193712	258	A	0.80775	So, suffice to say, precision and nested modeling is basically like the general precision concept, which is basically used everywhere.
2193776	2195872	259	A	0.99999	This is how we fit Bayesian models.
2196016	2199940	260	A	0.99998	We have some hyper prior distribution on a parameter.
2200440	2208516	261	A	1	And if that prior distribution is too sharp, then it's a pathology of the prior.
2208548	2209876	262	A	0.98993	It's too precise.
2210068	2216010	263	A	0.99998	If it was too imprecise, you have an underfit model.
2216460	2217592	264	A	0.99936	So it's like that.
2217646	2225444	265	A	0.57	And especially in nested models, precision plays a role in kind of gating.
2225572	2227404	266	A	0.56552	Just in this case, it's a general question.
2227442	2229068	267	A	0.99999	So you could make it do anything, basically.
2229154	2236450	268	A	0.99999	But here the precision on A is like gating, let's just say the first and the third level.
2237780	2245380	269	A	0.99906	So if there's no attention being paid to sensory input, don't be surprised that they don't come up to attention.
2246440	2259610	270	A	0.99999	But if this gating can be like super direct and forceful, then you'll have propagation of informational causality on this network up to the higher level.
2272740	2274800	271	A	0.99653	Page 113 in the textbook.
2284360	2287788	272	A	0.96	All right, the decision this is about planning as inference.
2287824	2305234	273	A	0.99856	Which one of these questions was also about the decision whether to model alternative futures, counterfactual futures conditioned upon policy selection.
2305282	2307546	274	A	1	How would the world change if I did this or that?
2307648	2319530	275	A	0.99889	Is largely tied up with the choice between discrete and continuous models because the idea of selecting between alternative futures defined by sequences of actions is more simply articulated using discrete time models.
2319690	2325760	276	A	0.9	All right, so figure 4.3.
2330610	2333018	277	A	0.49885	Figure 4.3 is like the rosetta stone.
2333114	2339234	278	A	0.99251	It juxtaposes the discrete time continuous discrete time generative model and the continuous time generative model.
2339432	2341140	279	A	0.54082	So I'll just copy this.
2343270	2348934	280	A	0.99978	In the discrete time model, you have st minus one s of t, s of t plus one.
2349052	2355670	281	A	0.9998	So futures and pasts, if it's sophisticated, active inference, are being explicitly modeled.
2356010	2360986	282	A	0.99943	So it's like what would happen at 07:00 if I did this?
2361168	2366598	283	A	0.58186	That is explicitly addressable with a discrete time model of the correct time horizon.
2366774	2371190	284	A	0.99998	So you have to explicitly say, I'm talking about an hourly model and seven depth.
2371350	2386770	285	A	0.95	And so then in branching time active inference, just like a chess algorithm, it's dealing with the branching structure because if you have a lot of affordances and you have a lot of time depth, you can imagine this is a combinatorial explosion.
2388470	2404066	286	A	0.99996	In contrast, though these two generative models are shown here to emphasize their structural similarity, the continuous time generative model is actually not explicitly modeling past, present, future time steps.
2404258	2414250	287	A	1	Rather, it's modeling the generalized coordinates of motion x hidden state x prime rate of change, x double prime second derivative.
2414750	2418518	288	A	0.97587	So in that way, it's a lot more like a Taylor series expansion.
2418694	2431200	289	A	0.99908	So a Taylor series expansion, technically even a Taylor series expansion of depth one, it has an answer for every single point in the number line, but that doesn't mean it's a good one.
2432370	2449800	290	A	1	And so continuous time models kind of trivially have something to say about all possible time steps just by analytic continuation of the Taylor series expansion in the generalized coordinates of motion way.
2450650	2456520	291	A	0.99999	However, you don't necessarily know how accurate it is for any given point.
2458110	2462970	292	A	0.68896	It also doesn't have explicit counterfactuals.
2463630	2469900	293	A	0.9997	So if you do some Taylor series expansion, it says yeah, at x equals three over y is five.
2470750	2473326	294	A	1	But then if you say, well, what if it were different?
2473508	2480320	295	A	0.84	The only way you could do that would be change the parameters of the Taylor series and recalculate it at that point.
2481650	2485634	296	A	0.99865	So the model itself is not exactly doing these.
2485672	2487780	297	A	0.9	Like what would happen if I did that?
2491610	2515120	298	A	0.9377	So futures are explicit in discrete time models and interpretable explicitly, whereas in continuous time models, pasts and futures are kind of trivially predicted such that it doesn't really make sense to talk about counterfactuals in the same exact way.
2519090	2527780	299	A	0.75	And these models can be hybridized and fused, which is in chapter eight.
2536400	2538984	300	A	0.92793	Can we generate a code of template?
2539032	2541890	301	A	0.84605	Looks like yes, but there's of course more information.
2542980	2545330	302	A	0.99995	But it's an important question.
2553510	2556414	303	A	0.9999	How is temporal depth specific to planning?
2556542	2559700	304	A	0.99993	Does temporal depth in perception make any sense?
2560250	2561910	305	A	0.99935	What is temporal depth?
2562490	2567480	306	A	0.98574	So temporal depth is how many timesteps the model is considered in the discrete time case.
2568810	2571670	307	A	0.53903	Does temporal depth make sense in perception?
2572090	2576250	308	A	0.99998	Well, perception is always modeled as instantaneous.
2576590	2591422	309	A	1	However, depending on the temporal scale of a model, that perception may be instantaneous over a certain temporal thickness power.
2591476	2594190	310	A	0.53971	Why is temporal depth specific to planning?
2594930	2604020	311	A	0.77963	So in planning as inference, policy selection as inference, you're selecting or sampling from policies based upon their expected free energy.
2607230	2618000	312	A	0.99998	In order to plan over a given time horizon and actually evaluate the playouts, you need to have a temporal depth of that amount.
2620930	2639038	313	A	0.99792	Thomas Parr in his bookstream so early implementations were coming from the generalized filtering approach.
2639134	2641826	314	A	0.99997	Maybe it wasn't generalized at that point, but particle filtering approach.
2641858	2644146	315	A	1	And then quipped these models with action.
2644338	2647410	316	A	0.99998	Then people started thinking about how to get sequential dynamics.
2647490	2661500	317	A	0.99931	Predator prey lock of voltera models winnerless competition neural Darwinism in these situations, there's an emergence of sequential recurrent continuous dynamics, like a limit cycle of more than two.
2662990	2668110	318	A	1	Then people wanted to model explicit long term planning.
2668450	2689650	319	A	0.83	And so from around 2014 or something, there was a lot more development in the discrete state space model, which enabled the well understood, partially observed Markov decision process and a lot of the characterization of planning as inference explore exploit.
2692010	2697826	320	A	0.87929	Then later developments supported nested models.
2697858	2701222	321	A	0.99999	Here there's a discrete time on top and a discrete time on the bottom.
2701276	2704860	322	A	1	But also it could be continuous time on the bottom.
2705390	2706186	323	A	0.98	Oh yes.
2706288	2715766	324	A	0.60575	Then continuous state models were reintroduced as the lower levels of higher level discrete time models.
2715958	2724430	325	A	1	And that is kind of like the folk psychology Livestream 46 active inference does not contradict folk psychology.
2725330	2733886	326	A	0.99901	Discrete time decision making up top, discrete time and discrete decisions and then more in the sensory motor.
2733918	2736370	327	A	0.99979	It's more like continuous time, continuous action.
2749580	2762720	328	A	0.99766	Okay, new question, figure 6.1.
2769870	2774410	329	A	0.86	All right, particular partition.
2779200	2783452	330	A	0.99991	How is the mutual interaction between active states and sensory states meant in six one?
2783506	2793010	331	A	0.99987	So the bi directional line here, can they mutually change their states without impacting neither internal nor external states?
2793540	2794930	332	A	0.99982	Yes, they could.
2795380	2801730	333	A	0.99986	You could have nodes that these nodes are in communication with each other.
2802100	2806404	334	A	0.99996	In general, this image, it's more important what it doesn't show.
2806522	2810912	335	A	0.99989	So there's no backwards arrow from external to active or from internal to sensory.
2810976	2816410	336	A	0.99997	You can't have your thumb on the scale and the symmetry of whatever that is from the outside.
2817420	2821572	337	A	0.58	And the only other constraint is no telepathy.
2821636	2823080	338	A	0.99997	No telekinesis.
2823580	2827372	339	A	1	The only way to receive information about external states is through sensory states.
2827426	2832476	340	A	1	The only way to act on costly intervene on external states is through active states.
2832658	2839516	341	A	0.97799	So no thumb on the scale and the mirror, no telepathy.
2839548	2840880	342	A	0.99704	No telekinesis.
2841220	2851440	343	A	0.99996	That doesn't mean that for any given model, these arrows are like all important or all relative or relatively of the same importance.
2852020	2867080	344	A	0.99979	So if you want to design a computer system where the sensory states comes in one computer, and this is a second computer and this is the third computer, so like there's no direct edge between sensory and active states, you can create that causal architecture.
2867500	2868296	345	A	0.99999	What is it supposed.
2868318	2869770	346	A	0.74	To model nothing.
2870940	2876616	347	A	0.99921	Modeling of supposed things is done in chapter six and beyond.
2876808	2882910	348	A	1	But in general, this is not trying to model any specific situation despite the brain in the world.
2883520	2890690	349	A	0.99996	Could they circle mutually modifying their states and then eventually arrive at a state where they change the external internal states?
2893540	2895744	350	A	0.97399	Yeah, maybe they have a faster timescale or something.
2895782	2907332	351	A	1	Or maybe they're in communication with each other and then active states, like sensory states ends up influencing internal states via active influencing it.
2907386	2909348	352	A	0.99	And so yes, it could happen.
2909514	2913140	353	A	0.99916	Would that mean that we can model with this trick, any arbitrary behavior?
2914460	2917876	354	A	0.92914	It's not necessarily a trick, it's just a particular partition.
2918068	2921428	355	A	0.90181	Would that allow us to model Turing equivalents?
2921604	2930348	356	A	0.66851	I'm not sure if there's an understanding of what formally demonstrates Turing equivalents then, but I believe it's possible.
2930434	2940880	357	A	0.92	I think as a Turing architecture, as far as I understand it, abstracted from the von Neumann architecture is basically just saying, like, you can do a Turing tape.
2941300	2942770	358	A	0.99995	So I don't see why not.
2943380	2944850	359	A	0.99905	Why would we need that?
2946820	2949890	360	A	1	512k ought to be enough for anyone, right?
2952440	2954324	361	A	0.63	I don't know why we need it.
2954522	2955990	362	A	0.80584	We expect it.
2959160	2972200	363	A	0.96606	But yeah, these graphs in general are more like the space of the possible with the important caveats that were mentioned with the no thumb on the scale and the mirror and the no telepathy and no telkinesis.
2972700	2981020	364	A	0.99999	But how relevant these edges are or what systems have what behavior or what cognitive phenomena are granted by what dynamics on graphs.
2981680	2989090	365	A	0.99996	There's just no general answer to those things because if you do a graph for one setting, it's going to be different.
2994230	3017208	366	A	1	What did you mean when you said that any entree could be ordered with any side dish like that in this recipe theme that we're in models that include continuous or discrete variables or both, what is meant by variable states or observations?
3017304	3022830	367	A	1	How can states be continuous, as those here are probably familiar with?
3023920	3030412	368	A	1	States or observations could be like discrete, like zero or one or any integer.
3030476	3032770	369	A	0.99999	Or it could be a continuous number.
3037510	3041780	370	A	0.54901	Computers discretize continuous functions to approximate them.
3043290	3055666	371	A	0.99997	But there's so many exciting directions with unconventional computing, analog computing, mem computing, et cetera, that there's more to it.
3055708	3059050	372	A	0.99994	But just simply it could be any type of variable.
3065130	3095170	373	A	0.97034	This new question, let's maybe look at this one in closing, if the external state is unknowable, how can we set up a generative process so that's what's generating the observations when our experience is based solely on the process of producing variational free energy based on predictions and sensory inputs across the markup blanket?
3097190	3099940	374	A	1	This person has just described the challenge of life.
3101110	3103286	375	A	0.97	I don't think that there is a specific answer to that.
3103308	3106870	376	A	1	I think this is literally a restatement of the particular partition.
3107770	3117130	377	A	0.99983	If this was just said, the challenge is to given the unknowability, direct unknowability of internal states.
3117280	3129630	378	A	1	The challenge and the opportunity is to set up a generative model based solely on the process of reducing free energy, based on predictions and sensory inputs across the blanket and adaptive action.
3131810	3145540	379	A	0.99781	I'm not sure if they meant process or model here because setting up a generative process is something that the human modeler does when they're designing a simulation, but not like what the animal has to do.
3149080	3154330	380	A	0.99999	What I'm trying to get at here is we are making an assumption about the generator of sensory input when making the model.
3155020	3158948	381	A	0.60093	Yes, but that model can never be accurate.
3159124	3162132	382	A	0.99998	Well, it absolutely can be accurate.
3162276	3168600	383	A	0.8961	It's never going to be a one to one map is the territory, but of course it can be accurate.
3168680	3178030	384	A	0.99999	We don't need to understand have an atomic simulation of the sun to have a generative process of how many photons are going to hit my window tomorrow at 07:00 a.m..
3179440	3183664	385	A	0.68151	So there's a core invalidity in the notion that we set up a generative process model.
3183862	3193892	386	A	0.99996	Not sure what ontology mixing is happening, but almost by definition we're introducing an error in the model by setting up the parameters for the generative process.
3193946	3201110	387	A	0.66	The generative model, we remove the fundamental aspect of actin, which is the dynamical system has only one thing it can do and that's to reduce free energy.
3201820	3205210	388	A	0.99947	So there's some good points and some mixed things.
3207740	3210948	389	A	0.99997	What it does is the action it takes in the world variational.
3210964	3215000	390	A	1	Free energy is just a tractable computational heuristic.
3215340	3229916	391	A	0.99998	Yes, if you set up the generative process to be a number continuous number between one and ten and then the generative model to do the exact same, to kind of have pre structurally learnt the problem, then it's going to be a simple simulation.
3230108	3237170	392	A	0.99999	Whereas you could have a more sophisticated simulation that involves structured learning as part of the agent's generative model.
3238500	3244308	393	A	0.99999	Are we not introducing information to the model that would not be available in the real world if we actually defined the generative process?
3244474	3249380	394	A	0.99984	Yeah, you can give any model too much information, essentially.
3251260	3272616	395	A	0.99986	So if the model actually knows what is really happening, then if you were doing a video game and you had an agent with supervisory access to the other players inferences or even control their actions, yeah, that's not going to work in a tournament.
3272808	3278028	396	A	0.97869	But here with a particular partition, we can actually know the information encapsulation.
3278204	3282800	397	A	1	And Majid Benny explores that in terms of the partial information encapsulation.
3283700	3287090	398	A	0.99982	So are we not introducing information to the model that would not be available?
3288100	3291936	399	A	0.9309	It's your restaurant, do whatever you got to do with the recipe.
3292048	3305716	400	A	0.99928	If you want a pedagogical example that just makes some clean graphs and is very straightforward and doesn't engage the complexities of like sophisticated cognitive structure learning, that model is not going to complain.
3305908	3317740	401	A	0.99999	If you want to do strange loop reflexive structure modeling for ambiguous inputs of unstructured multimodal data, et cetera, then that is your challenge.
3320460	3324308	402	A	0.72949	So for many people it's just one closing comment.
3324404	3325112	403	A	0.98381	In many people.
3325166	3330568	404	A	0.99999	This is the first time they've been exposed to statistical modeling, and iterative modeling formally.
3330744	3347760	405	A	0.93521	So that's why there are often questions that are, like, less about active inference, but sometimes crop up about basically using statistical modeling overall, which is a great thing because these are challenging and areas with a lot of implicit and tacit knowledge.
3350740	3352160	406	A	0.99964	Thank you, fellows.
3353240	3364564	407	A	0.99927	Looking forward to next discussions and into heading into chapter seven next week.
3364602	3371664	408	A	0.42982	Ali, maybe we'll do a maybe we'll do our zero for chapter seven and eight, but not in a hurry.
3371712	3372950	409	A	0.99928	But we'll figure it out.
3373880	3374630	410	B	0.96209	Sure.
3375240	3376500	411	B	0.9983	Thank you so much.
3376650	3377510	412	A	0.99555	Thank you.
3377920	3378812	413	C	0.99943	Thank you.
3378946	3379528	414	A	0.98554	Bye.
