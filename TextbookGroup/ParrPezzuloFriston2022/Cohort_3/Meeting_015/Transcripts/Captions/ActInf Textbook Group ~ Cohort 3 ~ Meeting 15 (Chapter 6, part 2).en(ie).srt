1
00:00:03,000 --> 00:00:06,180
all right greetings everyone

2
00:00:06,180 --> 00:00:09,900
it's June 20th 2023 we're in our second

3
00:00:09,900 --> 00:00:12,719
discussion on chapter six

4
00:00:12,719 --> 00:00:14,099
so

5
00:00:14,099 --> 00:00:15,780
we'll first just have any general

6
00:00:15,780 --> 00:00:17,699
comments or anything

7
00:00:17,699 --> 00:00:20,160
then we'll turn to the questions table

8
00:00:20,160 --> 00:00:22,560
and look at what questions we didn't get

9
00:00:22,560 --> 00:00:24,840
to last time and just kind of revisit

10
00:00:24,840 --> 00:00:27,420
maybe condense

11
00:00:27,420 --> 00:00:30,900
um some questions or just see what we

12
00:00:30,900 --> 00:00:34,200
can do with with what is here so

13
00:00:34,200 --> 00:00:36,719
anyone just want to make any general

14
00:00:36,719 --> 00:00:41,420
comments on chapter six

15
00:00:48,480 --> 00:00:50,700
uh I believe this is the second session

16
00:00:50,700 --> 00:00:54,840
on chapter six right correct or maybe I

17
00:00:54,840 --> 00:00:58,399
must okay yes

18
00:00:58,680 --> 00:01:00,680
yeah

19
00:01:00,719 --> 00:01:03,899
there was only one onboarding needed for

20
00:01:03,899 --> 00:01:05,280
the welcome back here so we started one

21
00:01:05,280 --> 00:01:08,820
week like faster into the Rhythm

22
00:01:08,820 --> 00:01:10,020
um

23
00:01:10,020 --> 00:01:14,700
okay so it looks like these were the

24
00:01:14,700 --> 00:01:16,439
questions

25
00:01:16,439 --> 00:01:18,360
I remember we left off with this one

26
00:01:18,360 --> 00:01:21,180
let's just develop this into what was

27
00:01:21,180 --> 00:01:23,520
um into a question that will continue to

28
00:01:23,520 --> 00:01:26,060
continue on

29
00:01:37,380 --> 00:01:39,860
okay

30
00:01:39,900 --> 00:01:41,040
um

31
00:01:41,040 --> 00:01:43,979
is there a common or good representation

32
00:01:43,979 --> 00:01:45,540
or rubric

33
00:01:45,540 --> 00:01:47,939
for about evaluating generative model

34
00:01:47,939 --> 00:01:50,960
generative process

35
00:01:55,979 --> 00:01:59,939
which is two generative models and

36
00:01:59,939 --> 00:02:03,258
generative processes

37
00:02:11,160 --> 00:02:13,080
anyone want to give a first thought or

38
00:02:13,080 --> 00:02:16,819
just some other related questions

39
00:02:23,360 --> 00:02:26,040
yeah well uh

40
00:02:26,040 --> 00:02:30,260
go on please sorry no that's okay

41
00:02:33,360 --> 00:02:36,300
uh yeah uh I I don't know I'm not sure

42
00:02:36,300 --> 00:02:39,360
about uh what What's the exact criteria

43
00:02:39,360 --> 00:02:41,040
for evaluating generative models

44
00:02:41,040 --> 00:02:45,360
regenerative processes but uh one thing

45
00:02:45,360 --> 00:02:49,379
is for sure that uh well I mean one of

46
00:02:49,379 --> 00:02:51,140
the main right

47
00:02:51,140 --> 00:02:54,840
at least uh when evaluating generative

48
00:02:54,840 --> 00:02:57,840
model one of our main criteria should be

49
00:02:57,840 --> 00:03:01,700
how uh closely uh

50
00:03:01,700 --> 00:03:04,640
it tracks uh our

51
00:03:04,640 --> 00:03:07,519
situation of interest and specifically

52
00:03:07,519 --> 00:03:11,819
uh how relevant it is for addressing the

53
00:03:11,819 --> 00:03:13,980
question that we're trying to

54
00:03:13,980 --> 00:03:18,360
um I mean we're trying to examine so uh

55
00:03:18,360 --> 00:03:21,120
it's not I I don't think it's something

56
00:03:21,120 --> 00:03:24,120
a clear-cut or I don't know written

57
00:03:24,120 --> 00:03:27,480
Stone and based on the context and the

58
00:03:27,480 --> 00:03:28,640
situation

59
00:03:28,640 --> 00:03:33,420
uh the evaluation criteria rubric should

60
00:03:33,420 --> 00:03:35,940
be different I suppose both for

61
00:03:35,940 --> 00:03:40,340
regenerative model and generous process

62
00:03:44,159 --> 00:03:47,280
yeah so again we'll revisit this

63
00:03:47,280 --> 00:03:50,459
generative model generative process

64
00:03:50,459 --> 00:03:53,340
um question later following the recent

65
00:03:53,340 --> 00:03:56,159
live stream but General process

66
00:03:56,159 --> 00:03:58,379
working regenerative process as the

67
00:03:58,379 --> 00:04:00,840
underlying uh process that gives rise to

68
00:04:00,840 --> 00:04:02,159
the observations

69
00:04:02,159 --> 00:04:05,040
this would seem to be more adequate to

70
00:04:05,040 --> 00:04:06,900
the extent that it can better describe

71
00:04:06,900 --> 00:04:08,580
the measurements

72
00:04:08,580 --> 00:04:10,920
generative model

73
00:04:10,920 --> 00:04:14,819
similarly is being evaluated based upon

74
00:04:14,819 --> 00:04:17,418
its ability to to fit to the generative

75
00:04:17,418 --> 00:04:20,130
process as well as

76
00:04:20,130 --> 00:04:20,519
[Music]

77
00:04:20,519 --> 00:04:21,298
um

78
00:04:21,298 --> 00:04:24,620
phenomena of Interest

79
00:04:24,900 --> 00:04:27,000
so not just to

80
00:04:27,000 --> 00:04:29,400
um fit visual data but maybe to model

81
00:04:29,400 --> 00:04:31,740
something like some illusion in visual

82
00:04:31,740 --> 00:04:33,300
then

83
00:04:33,300 --> 00:04:36,680
um there's a wide range of more General

84
00:04:36,680 --> 00:04:39,240
statistical modeling techniques so first

85
00:04:39,240 --> 00:04:41,580
is like the ultimate grab bag which is

86
00:04:41,580 --> 00:04:43,380
just how relevant is the overall

87
00:04:43,380 --> 00:04:45,660
modeling

88
00:04:45,660 --> 00:04:49,100
um then there are statistical

89
00:04:49,100 --> 00:04:52,440
evaluations of model adequacy and model

90
00:04:52,440 --> 00:04:55,320
selection IQ information Criterion

91
00:04:55,320 --> 00:04:57,780
Bayesian information Criterion base

92
00:04:57,780 --> 00:04:59,460
Factor

93
00:04:59,460 --> 00:05:02,699
um hierarchical likelihood ratio test if

94
00:05:02,699 --> 00:05:04,500
you have a parametric model

95
00:05:04,500 --> 00:05:07,680
bootstrap and non-parametric statistics

96
00:05:07,680 --> 00:05:10,680
just general modeling and then

97
00:05:10,680 --> 00:05:12,840
taking that more out of the statistics

98
00:05:12,840 --> 00:05:15,479
into like the engineering

99
00:05:15,479 --> 00:05:19,139
uh uh model life cycle

100
00:05:19,139 --> 00:05:21,720
then that's where you can think about

101
00:05:21,720 --> 00:05:24,300
validation verification validity

102
00:05:24,300 --> 00:05:26,639
equality

103
00:05:26,639 --> 00:05:31,100
Etc systems engineering model life cycle

104
00:05:34,979 --> 00:05:38,659
any other thoughts or questions on this

105
00:05:42,960 --> 00:05:46,380
Okay so

106
00:05:46,380 --> 00:05:49,320
um I'm coming from um kind of an early

107
00:05:49,320 --> 00:05:51,780
career data scientist background here

108
00:05:51,780 --> 00:05:53,400
but um

109
00:05:53,400 --> 00:05:55,800
I mean as far as

110
00:05:55,800 --> 00:05:57,600
I mean what I find attractive about

111
00:05:57,600 --> 00:06:00,479
active inference and doing things as

112
00:06:00,479 --> 00:06:03,000
generative models is the attempt to you

113
00:06:03,000 --> 00:06:05,340
know describe or explain what's going on

114
00:06:05,340 --> 00:06:08,699
in the data and that being said um you

115
00:06:08,699 --> 00:06:10,680
know in terms of a lot of mini

116
00:06:10,680 --> 00:06:12,600
applications of like data science

117
00:06:12,600 --> 00:06:14,880
machine learning

118
00:06:14,880 --> 00:06:15,539
um

119
00:06:15,539 --> 00:06:19,680
the emphasis upon is upon prediction and

120
00:06:19,680 --> 00:06:22,680
so are these listed statistical metrics

121
00:06:22,680 --> 00:06:26,880
you have here base Factor Bic Etc I mean

122
00:06:26,880 --> 00:06:28,500
are those

123
00:06:28,500 --> 00:06:30,860
basically like your error

124
00:06:30,860 --> 00:06:33,660
measurements are they your

125
00:06:33,660 --> 00:06:34,259
um

126
00:06:34,259 --> 00:06:35,940
how to say

127
00:06:35,940 --> 00:06:39,479
just attempt at measuring like accuracy

128
00:06:39,479 --> 00:06:42,479
of prediction or

129
00:06:42,479 --> 00:06:44,360
or is there some trade-off between

130
00:06:44,360 --> 00:06:48,419
explainability and and prediction

131
00:06:48,419 --> 00:06:51,440
if that makes sense

132
00:06:51,780 --> 00:06:54,360
yeah

133
00:06:54,360 --> 00:06:57,180
just to kind of summarize these

134
00:06:57,180 --> 00:06:59,340
um so when you have nested parametric

135
00:06:59,340 --> 00:07:00,539
models

136
00:07:00,539 --> 00:07:03,780
then you can evaluate whether two models

137
00:07:03,780 --> 00:07:06,780
are better in terms of including or not

138
00:07:06,780 --> 00:07:09,000
some parametric factor and then testing

139
00:07:09,000 --> 00:07:11,520
for their likelihood ratios

140
00:07:11,520 --> 00:07:14,160
so this is a pretty straightforward test

141
00:07:14,160 --> 00:07:16,020
but it's pretty limited to just strictly

142
00:07:16,020 --> 00:07:17,819
nested parametric models so just just

143
00:07:17,819 --> 00:07:20,099
getting that out of the way in general

144
00:07:20,099 --> 00:07:22,979
we're in the Bayesian setting and so the

145
00:07:22,979 --> 00:07:24,419
one of the advantages of the Bayesian

146
00:07:24,419 --> 00:07:28,440
setting is that you can compare two

147
00:07:28,440 --> 00:07:30,539
different models

148
00:07:30,539 --> 00:07:31,919
that have totally different

149
00:07:31,919 --> 00:07:34,860
architectures on the same data set so

150
00:07:34,860 --> 00:07:37,440
one way that that's done is with this

151
00:07:37,440 --> 00:07:39,539
aikiki information Criterion or the

152
00:07:39,539 --> 00:07:41,520
Bayesian information Criterion

153
00:07:41,520 --> 00:07:43,319
both of them do something very similar

154
00:07:43,319 --> 00:07:46,560
which is they reward model fit and they

155
00:07:46,560 --> 00:07:49,440
penalize the number of parameters so

156
00:07:49,440 --> 00:07:53,000
actually in that way

157
00:07:53,099 --> 00:07:55,020
it's a lot like

158
00:07:55,020 --> 00:07:58,099
equation 2.5

159
00:07:59,699 --> 00:08:03,900
you want to reward the fit but penalize

160
00:08:03,900 --> 00:08:06,120
the complexity of the model

161
00:08:06,120 --> 00:08:09,300
base factor is kind of like the hlrt but

162
00:08:09,300 --> 00:08:11,940
it doesn't have to be ratios of nested

163
00:08:11,940 --> 00:08:14,099
models you can just compare the relative

164
00:08:14,099 --> 00:08:17,099
evidence in in favor of one a model or

165
00:08:17,099 --> 00:08:20,099
another so this is used in structure

166
00:08:20,099 --> 00:08:23,940
modeling and and uh structured learning

167
00:08:23,940 --> 00:08:25,919
then in terms of but this is all like

168
00:08:25,919 --> 00:08:27,960
kind of like testing amongst a portfolio

169
00:08:27,960 --> 00:08:30,660
of models which ones are better

170
00:08:30,660 --> 00:08:32,760
then how do you really get into the

171
00:08:32,760 --> 00:08:34,620
space of like well how effective is this

172
00:08:34,620 --> 00:08:36,299
model

173
00:08:36,299 --> 00:08:39,958
um you could test on a new data set you

174
00:08:39,958 --> 00:08:41,520
could do all the regular techniques like

175
00:08:41,520 --> 00:08:44,339
cross validation leave one out Etc

176
00:08:44,339 --> 00:08:47,339
or test on a new data set but then the

177
00:08:47,339 --> 00:08:49,980
very interesting question is how do you

178
00:08:49,980 --> 00:08:51,720
establish

179
00:08:51,720 --> 00:08:55,560
the efficacy of an action model

180
00:08:55,560 --> 00:08:57,300
because

181
00:08:57,300 --> 00:09:00,000
um you know it's it's not just a passive

182
00:09:00,000 --> 00:09:01,560
inference model so there you would need

183
00:09:01,560 --> 00:09:03,959
to get into like benchmarks like the

184
00:09:03,959 --> 00:09:06,000
open AI gym

185
00:09:06,000 --> 00:09:07,380
and other

186
00:09:07,380 --> 00:09:08,160
um

187
00:09:08,160 --> 00:09:09,899
other settings where you can actually

188
00:09:09,899 --> 00:09:12,180
test the efficacy of an action model

189
00:09:12,180 --> 00:09:14,880
against some test input

190
00:09:14,880 --> 00:09:17,279
rather than just a recognition model and

191
00:09:17,279 --> 00:09:18,600
some input

192
00:09:18,600 --> 00:09:21,600
but that gets so situational that there

193
00:09:21,600 --> 00:09:25,760
aren't as as there's not like General

194
00:09:26,100 --> 00:09:27,899
not there's not as many General

195
00:09:27,899 --> 00:09:31,260
considerations there another strategy is

196
00:09:31,260 --> 00:09:33,120
actually to even if it seems like a

197
00:09:33,120 --> 00:09:35,279
passive inference problem like the mnist

198
00:09:35,279 --> 00:09:37,140
digit data set

199
00:09:37,140 --> 00:09:40,140
you could frame that in terms of the the

200
00:09:40,140 --> 00:09:43,880
labeling is an action

201
00:09:44,399 --> 00:09:46,560
so sometimes you can then take what

202
00:09:46,560 --> 00:09:48,060
seems to be a passive inference problem

203
00:09:48,060 --> 00:09:49,860
and then frame it as an active inference

204
00:09:49,860 --> 00:09:51,720
problem

205
00:09:51,720 --> 00:09:53,339
so then you don't need to worry about

206
00:09:53,339 --> 00:09:55,500
these kind of like out-of-sample novel

207
00:09:55,500 --> 00:09:57,660
context action models

208
00:09:57,660 --> 00:09:59,880
you can just kind of use standard

209
00:09:59,880 --> 00:10:02,540
benchmarks

210
00:10:05,580 --> 00:10:08,220
and also as far as I know uh probably

211
00:10:08,220 --> 00:10:11,160
the only serious work on benchmarking

212
00:10:11,160 --> 00:10:12,720
the performance of active imprints

213
00:10:12,720 --> 00:10:14,880
models

214
00:10:14,880 --> 00:10:17,940
um is the work of

215
00:10:17,940 --> 00:10:21,240
um theophy champion and his colleagues

216
00:10:21,240 --> 00:10:25,500
branching time active inference which is

217
00:10:25,500 --> 00:10:29,360
uh they've proposed several different

218
00:10:29,360 --> 00:10:31,560
variants of branching time active

219
00:10:31,560 --> 00:10:35,480
inference Each of which I mean with

220
00:10:35,480 --> 00:10:38,760
increasing performance in terms of their

221
00:10:38,760 --> 00:10:42,360
benchmarks and aside from that I'm not

222
00:10:42,360 --> 00:10:45,019
aware of any other work that takes this

223
00:10:45,019 --> 00:10:49,860
benchmarking study seriously enough to

224
00:10:49,860 --> 00:10:52,740
to be reliable I guess

225
00:10:52,740 --> 00:10:55,500
yeah surely there's a lot of proprietary

226
00:10:55,500 --> 00:10:58,380
work in this area

227
00:10:58,380 --> 00:10:59,160
um

228
00:10:59,160 --> 00:11:02,040
the paper discussed in in um

229
00:11:02,040 --> 00:11:03,839
live stream eight scaling active

230
00:11:03,839 --> 00:11:05,459
inference

231
00:11:05,459 --> 00:11:08,339
so here they they use like the kind of

232
00:11:08,339 --> 00:11:11,820
um several standards

233
00:11:11,820 --> 00:11:14,100
um testing environments

234
00:11:14,100 --> 00:11:16,920
I forget what the pendulum

235
00:11:16,920 --> 00:11:18,899
the hopper and then I think like the

236
00:11:18,899 --> 00:11:20,880
mountain car or maybe maybe that's not

237
00:11:20,880 --> 00:11:21,959
this one

238
00:11:21,959 --> 00:11:23,220
but

239
00:11:23,220 --> 00:11:26,040
they test the standards um

240
00:11:26,040 --> 00:11:29,779
AI tests

241
00:11:34,800 --> 00:11:36,540
all right

242
00:11:36,540 --> 00:11:39,360
we're just looking just you know going

243
00:11:39,360 --> 00:11:40,920
through the ones

244
00:11:40,920 --> 00:11:42,720
all right are the transitions be

245
00:11:42,720 --> 00:11:45,300
independent from the emissions

246
00:11:45,300 --> 00:11:46,630
so for

247
00:11:46,630 --> 00:11:47,040
[Music]

248
00:11:47,040 --> 00:11:47,880
um

249
00:11:47,880 --> 00:11:50,760
uh context

250
00:11:50,760 --> 00:11:53,880
we're talking about figure 7.3 discrete

251
00:11:53,880 --> 00:11:55,620
time active inference

252
00:11:55,620 --> 00:11:57,540
are the transitions independent from the

253
00:11:57,540 --> 00:11:58,800
emissions and what is the next

254
00:11:58,800 --> 00:12:02,000
observation depend on

255
00:12:04,079 --> 00:12:05,880
short answer

256
00:12:05,880 --> 00:12:08,940
yes they're independent that's the

257
00:12:08,940 --> 00:12:11,519
sparsity of the base graph so we can

258
00:12:11,519 --> 00:12:13,620
clarify and give it a cleaner textual

259
00:12:13,620 --> 00:12:15,959
answer but yes the conditional

260
00:12:15,959 --> 00:12:18,180
independencies

261
00:12:18,180 --> 00:12:20,880
which is the sparsity of the base graph

262
00:12:20,880 --> 00:12:23,760
which allows us to do factorized

263
00:12:23,760 --> 00:12:25,560
variational inference and get all of

264
00:12:25,560 --> 00:12:26,880
these advantages

265
00:12:26,880 --> 00:12:30,120
that's exactly what we're looking at

266
00:12:30,120 --> 00:12:34,079
so this visual graphical model

267
00:12:34,079 --> 00:12:36,720
is the sparsity architecture of the

268
00:12:36,720 --> 00:12:37,980
conditional

269
00:12:37,980 --> 00:12:38,579
um

270
00:12:38,579 --> 00:12:41,540
independencies

271
00:12:42,360 --> 00:12:43,860
so

272
00:12:43,860 --> 00:12:46,519
yes

273
00:12:46,800 --> 00:12:50,540
A and B are conditionally independent

274
00:12:52,220 --> 00:12:55,019
conditionally independent based on what

275
00:12:55,019 --> 00:12:57,360
hitting the state that's how Markov

276
00:12:57,360 --> 00:12:58,740
blanket works

277
00:12:58,740 --> 00:13:01,139
conditionally appended on the blanket A

278
00:13:01,139 --> 00:13:03,600
and B are independent

279
00:13:03,600 --> 00:13:07,019
that's true of all Bayesian graphs

280
00:13:07,019 --> 00:13:08,940
so without worrying about the Markov

281
00:13:08,940 --> 00:13:10,380
blanket and the interface and the

282
00:13:10,380 --> 00:13:12,660
cybernetic agent and all of that

283
00:13:12,660 --> 00:13:13,860
just

284
00:13:13,860 --> 00:13:15,959
any node that intervenes between two

285
00:13:15,959 --> 00:13:18,420
other nodes is the Markov blanket in

286
00:13:18,420 --> 00:13:19,800
that setting

287
00:13:19,800 --> 00:13:21,480
and then some other node you know

288
00:13:21,480 --> 00:13:23,339
something else is blinking to get from

289
00:13:23,339 --> 00:13:24,360
something else

290
00:13:24,360 --> 00:13:25,800
but yes they're conditionally

291
00:13:25,800 --> 00:13:27,839
independent what is the next observation

292
00:13:27,839 --> 00:13:28,920
depend on

293
00:13:28,920 --> 00:13:30,240
well

294
00:13:30,240 --> 00:13:33,360
a matrix is the emission Matrix Tale of

295
00:13:33,360 --> 00:13:35,459
Two densities it can emit from a hidden

296
00:13:35,459 --> 00:13:37,320
state or it can recognize from an

297
00:13:37,320 --> 00:13:38,600
observation

298
00:13:38,600 --> 00:13:43,019
so any given observation is only

299
00:13:43,019 --> 00:13:45,000
dependent upon the hidden State at that

300
00:13:45,000 --> 00:13:46,260
time

301
00:13:46,260 --> 00:13:49,139
and the hidden State at the next time

302
00:13:49,139 --> 00:13:51,480
is only dependent upon the transition

303
00:13:51,480 --> 00:13:52,980
Matrix

304
00:13:52,980 --> 00:13:55,079
the transition Matrix

305
00:13:55,079 --> 00:13:58,980
is uh has a slice for every action that

306
00:13:58,980 --> 00:14:00,360
can be taken

307
00:14:00,360 --> 00:14:03,420
every policy makes a slice in the B

308
00:14:03,420 --> 00:14:04,740
tensor

309
00:14:04,740 --> 00:14:06,360
so it's like

310
00:14:06,360 --> 00:14:08,040
temperature in the room hidden State

311
00:14:08,040 --> 00:14:10,800
thermometer observation

312
00:14:10,800 --> 00:14:13,200
turn on the heater or not and there's

313
00:14:13,200 --> 00:14:15,060
some B Matrix for the heater is on and

314
00:14:15,060 --> 00:14:16,860
there's some B Matrix for the heater is

315
00:14:16,860 --> 00:14:18,720
not on those are two slices in the same

316
00:14:18,720 --> 00:14:20,279
object

317
00:14:20,279 --> 00:14:23,100
and then policy selection means which

318
00:14:23,100 --> 00:14:24,360
Matrix

319
00:14:24,360 --> 00:14:27,000
which sub Matrix would be which slice of

320
00:14:27,000 --> 00:14:28,260
B

321
00:14:28,260 --> 00:14:30,480
should we multiply this to get to the

322
00:14:30,480 --> 00:14:32,220
next time step

323
00:14:32,220 --> 00:14:34,320
and then what observation would I expect

324
00:14:34,320 --> 00:14:36,860
there

325
00:14:49,980 --> 00:14:52,800
okay good good

326
00:14:52,800 --> 00:14:55,800
um kind of standard question

327
00:14:55,800 --> 00:14:58,139
okay what is the relevance of thinking

328
00:14:58,139 --> 00:15:01,320
about good regulator theorem

329
00:15:01,320 --> 00:15:03,240
for thinking about the generative model

330
00:15:03,240 --> 00:15:05,940
so from cybernetics

331
00:15:05,940 --> 00:15:07,860
good regular theorem originally stated

332
00:15:07,860 --> 00:15:09,839
every good regulator of a system must be

333
00:15:09,839 --> 00:15:12,060
a model of that system

334
00:15:12,060 --> 00:15:14,699
or more accurately every good regulator

335
00:15:14,699 --> 00:15:18,500
must contain a model of that system

336
00:15:27,600 --> 00:15:31,220
here's a few quotes from a textbook

337
00:15:36,480 --> 00:15:38,399
one way to approach this again these are

338
00:15:38,399 --> 00:15:39,839
just all kind of big questions but we

339
00:15:39,839 --> 00:15:42,360
can just see them many times what

340
00:15:42,360 --> 00:15:44,820
happens to bad Regulators well

341
00:15:44,820 --> 00:15:46,920
information processing sense making

342
00:15:46,920 --> 00:15:49,560
decision making has a non-zero

343
00:15:49,560 --> 00:15:51,180
informational cost

344
00:15:51,180 --> 00:15:53,399
land hour limit there's a certain amount

345
00:15:53,399 --> 00:15:56,459
of actual joules it takes to write and

346
00:15:56,459 --> 00:15:57,600
erase

347
00:15:57,600 --> 00:16:00,300
a bit it from bit Chris Fields

348
00:16:00,300 --> 00:16:02,820
everything that is in that area so

349
00:16:02,820 --> 00:16:06,480
information processing is never free

350
00:16:06,480 --> 00:16:09,720
so in a dissipative and even adversarial

351
00:16:09,720 --> 00:16:11,699
universe

352
00:16:11,699 --> 00:16:15,000
to fail to regulate

353
00:16:15,000 --> 00:16:17,699
is to fail to exist

354
00:16:17,699 --> 00:16:20,459
how do we operationalize regulation in a

355
00:16:20,459 --> 00:16:21,300
setting

356
00:16:21,300 --> 00:16:23,459
that's going to be

357
00:16:23,459 --> 00:16:25,440
revisiting

358
00:16:25,440 --> 00:16:28,560
some non-equilibrium steady state

359
00:16:28,560 --> 00:16:31,800
so if we're an observer looking at a

360
00:16:31,800 --> 00:16:33,240
system

361
00:16:33,240 --> 00:16:35,880
in order for us to measure it as diff as

362
00:16:35,880 --> 00:16:38,759
signal relative to noise it has to be

363
00:16:38,759 --> 00:16:40,620
persistently

364
00:16:40,620 --> 00:16:42,720
re-measurable

365
00:16:42,720 --> 00:16:44,339
over the background so we have to

366
00:16:44,339 --> 00:16:46,259
repeatedly measure it

367
00:16:46,259 --> 00:16:50,220
or an organism let's just say

368
00:16:50,220 --> 00:16:52,620
can re-measure itself

369
00:16:52,620 --> 00:16:54,899
so minimizing surprise about its

370
00:16:54,899 --> 00:16:57,480
homeostatic temperature is being

371
00:16:57,480 --> 00:16:58,860
adaptive

372
00:16:58,860 --> 00:17:02,399
now if temperature were just flat and so

373
00:17:02,399 --> 00:17:05,220
you could be unsurprised at homeostasis

374
00:17:05,220 --> 00:17:06,660
by doing nothing

375
00:17:06,660 --> 00:17:08,040
you'd get

376
00:17:08,040 --> 00:17:11,040
lazy agents but if temperature was

377
00:17:11,040 --> 00:17:13,020
really variable and contextual and there

378
00:17:13,020 --> 00:17:15,059
was kind of these non-linear cues in the

379
00:17:15,059 --> 00:17:16,679
environment and all of that

380
00:17:16,679 --> 00:17:20,220
then in order to reduce surprise

381
00:17:20,220 --> 00:17:22,079
about temperature

382
00:17:22,079 --> 00:17:24,419
you'd end up

383
00:17:24,419 --> 00:17:26,819
coming to effectively

384
00:17:26,819 --> 00:17:30,840
have a model of the causal Nexus that

385
00:17:30,840 --> 00:17:33,720
gives rise to observations

386
00:17:33,720 --> 00:17:35,280
so the structure of the generative model

387
00:17:35,280 --> 00:17:36,780
doesn't have to be the structure of the

388
00:17:36,780 --> 00:17:39,120
generative process

389
00:17:39,120 --> 00:17:41,720
however they may come to have certain

390
00:17:41,720 --> 00:17:44,460
isomorphisms with each other

391
00:17:44,460 --> 00:17:47,580
or at least statistical regularities

392
00:17:47,580 --> 00:17:50,160
if there's actually a 24-hour cycle in

393
00:17:50,160 --> 00:17:52,440
temperature

394
00:17:52,440 --> 00:17:55,100
then you're going to see some kind of

395
00:17:55,100 --> 00:17:57,360
oscillatory model in the generative

396
00:17:57,360 --> 00:17:59,600
model

397
00:17:59,660 --> 00:18:01,260
so

398
00:18:01,260 --> 00:18:03,480
there's more to

399
00:18:03,480 --> 00:18:06,179
um say there but oh and this is one good

400
00:18:06,179 --> 00:18:07,799
note perhaps rather than good or bad

401
00:18:07,799 --> 00:18:10,860
regulator the language of morality

402
00:18:10,860 --> 00:18:12,240
or preference

403
00:18:12,240 --> 00:18:14,039
the language should be accurate and

404
00:18:14,039 --> 00:18:15,179
inaccurate

405
00:18:15,179 --> 00:18:17,340
in effective and effective viable and

406
00:18:17,340 --> 00:18:20,400
viable skillful unskillful so

407
00:18:20,400 --> 00:18:22,080
there's always many ways to see it but

408
00:18:22,080 --> 00:18:23,580
basically

409
00:18:23,580 --> 00:18:26,520
if the generative model in the in the

410
00:18:26,520 --> 00:18:29,100
limit case it just totally knows the

411
00:18:29,100 --> 00:18:31,440
causal architecture of the world that's

412
00:18:31,440 --> 00:18:33,480
the easiest way to be absolutely

413
00:18:33,480 --> 00:18:35,280
unsurprised

414
00:18:35,280 --> 00:18:37,500
and to have things as you expect slash

415
00:18:37,500 --> 00:18:39,840
prefer is literally know how they're

416
00:18:39,840 --> 00:18:41,160
going to play out

417
00:18:41,160 --> 00:18:43,860
that's not plausible we use course

418
00:18:43,860 --> 00:18:45,480
grading and approximations and

419
00:18:45,480 --> 00:18:48,299
heuristics like variational inference

420
00:18:48,299 --> 00:18:49,980
so the best we can do is just

421
00:18:49,980 --> 00:18:52,320
iteratively optimize

422
00:18:52,320 --> 00:18:55,559
towards bounding surprisal

423
00:18:55,559 --> 00:18:57,740
so it's kind of like an empirical

424
00:18:57,740 --> 00:19:00,059
optimizable heuristic for being a good

425
00:19:00,059 --> 00:19:01,919
regulator

426
00:19:01,919 --> 00:19:03,960
without getting too bogged down into

427
00:19:03,960 --> 00:19:06,780
like the philosophy and the exactitude

428
00:19:06,780 --> 00:19:08,520
the point is the ones that do well

429
00:19:08,520 --> 00:19:11,100
enough to live live ones that don't do

430
00:19:11,100 --> 00:19:14,120
well enough don't

431
00:19:16,919 --> 00:19:18,600
but active inference is in the lineage

432
00:19:18,600 --> 00:19:20,340
of cybernetics

433
00:19:20,340 --> 00:19:22,500
so it's unsurprising that good regulator

434
00:19:22,500 --> 00:19:25,320
theorem requisite diversity viable

435
00:19:25,320 --> 00:19:27,120
systems models

436
00:19:27,120 --> 00:19:28,799
a lot of things in the cybernetics

437
00:19:28,799 --> 00:19:31,200
ontology have a natural home in the

438
00:19:31,200 --> 00:19:33,240
active ontology

439
00:19:33,240 --> 00:19:35,160
that they're you know they're talking

440
00:19:35,160 --> 00:19:37,500
about the same territory adoptive agents

441
00:19:37,500 --> 00:19:39,480
so it's not surprising that like they

442
00:19:39,480 --> 00:19:41,039
don't invalidate each other or anything

443
00:19:41,039 --> 00:19:43,460
like that

444
00:19:47,580 --> 00:19:49,919
and actually I think uh it's one of the

445
00:19:49,919 --> 00:19:52,380
reasons cybernetics

446
00:19:52,380 --> 00:19:53,100
um

447
00:19:53,100 --> 00:19:55,380
that experienced kind of revitalization

448
00:19:55,380 --> 00:19:57,140
in recent years

449
00:19:57,140 --> 00:19:59,820
especially in the past couple of years

450
00:19:59,820 --> 00:20:01,559
so

451
00:20:01,559 --> 00:20:03,980
yeah

452
00:20:04,440 --> 00:20:06,480
all right how can organs others in the

453
00:20:06,480 --> 00:20:09,740
brain be making inferences

454
00:20:11,520 --> 00:20:14,340
so there's a few angles on this

455
00:20:14,340 --> 00:20:15,600
the first

456
00:20:15,600 --> 00:20:17,760
um or Ali or anyone else want to give a

457
00:20:17,760 --> 00:20:20,059
thought

458
00:20:21,900 --> 00:20:23,280
uh

459
00:20:23,280 --> 00:20:27,960
one thing to point uh is this sense of

460
00:20:27,960 --> 00:20:31,760
a kind of semi pan computationalism

461
00:20:31,760 --> 00:20:34,559
that's been

462
00:20:34,559 --> 00:20:35,299
um

463
00:20:35,299 --> 00:20:38,280
if not time computationalism but but

464
00:20:38,280 --> 00:20:42,418
something that bestows

465
00:20:42,780 --> 00:20:45,860
um inference not only to complex

466
00:20:45,860 --> 00:20:48,179
self-organizing systems such as the

467
00:20:48,179 --> 00:20:53,280
brain but even to very simple linear

468
00:20:53,280 --> 00:20:57,299
systems even a system as simple as an

469
00:20:57,299 --> 00:20:58,760
inert to rock

470
00:20:58,760 --> 00:21:03,000
uh so basically it's it it covers the

471
00:21:03,000 --> 00:21:07,440
Spectrum there isn't I mean from the

472
00:21:07,440 --> 00:21:09,299
point of view of fep there isn't

473
00:21:09,299 --> 00:21:11,820
anything that's specifically unique

474
00:21:11,820 --> 00:21:15,059
about the brain uh in other words the

475
00:21:15,059 --> 00:21:16,980
same mathematical technology can be

476
00:21:16,980 --> 00:21:20,340
applied uh both to inert rocks as well

477
00:21:20,340 --> 00:21:24,320
as the uh the brain so

478
00:21:24,320 --> 00:21:27,900
in my opinion this question should be

479
00:21:27,900 --> 00:21:32,179
turned on its head and it's not that

480
00:21:32,179 --> 00:21:36,559
how does inference can be seen in other

481
00:21:36,559 --> 00:21:39,120
systems that are simpler systems but

482
00:21:39,120 --> 00:21:40,320
rather

483
00:21:40,320 --> 00:21:42,900
it should be I mean the relevant

484
00:21:42,900 --> 00:21:46,080
question should be uh how does active

485
00:21:46,080 --> 00:21:48,659
inference or the notion of inference

486
00:21:48,659 --> 00:21:52,100
inactive inference literature applies to

487
00:21:52,100 --> 00:21:57,299
all of those situations uh so one way to

488
00:21:57,299 --> 00:22:03,120
do that is to define a kind of sparse

489
00:22:03,120 --> 00:22:06,120
coupling between the environment and the

490
00:22:06,120 --> 00:22:10,919
agent and define variational density as

491
00:22:10,919 --> 00:22:14,340
the internal states of the system and

492
00:22:14,340 --> 00:22:16,860
also obviously the external states of

493
00:22:16,860 --> 00:22:19,740
the environment

494
00:22:19,740 --> 00:22:21,900
would be the states that needs to be

495
00:22:21,900 --> 00:22:25,440
tracked by those variational densities

496
00:22:25,440 --> 00:22:29,000
and in this case there isn't anything

497
00:22:29,000 --> 00:22:31,919
inherently different between the way the

498
00:22:31,919 --> 00:22:35,100
brains uh or I don't know even sentient

499
00:22:35,100 --> 00:22:37,860
agents uh

500
00:22:37,860 --> 00:22:43,799
uh somehow undertake uh inference from

501
00:22:43,799 --> 00:22:48,120
the way that the inert rocks and

502
00:22:48,120 --> 00:22:51,840
partition and their states into internal

503
00:22:51,840 --> 00:22:54,720
and external States but the main

504
00:22:54,720 --> 00:22:58,140
difference would be the way the markup

505
00:22:58,140 --> 00:23:01,679
blanket in those simpler systems can act

506
00:23:01,679 --> 00:23:05,480
as as a kind of

507
00:23:05,480 --> 00:23:08,780
statistical boundary that allows for

508
00:23:08,780 --> 00:23:11,220
non-causal relationships I'm sorry

509
00:23:11,220 --> 00:23:14,880
non-linear causal relationships as

510
00:23:14,880 --> 00:23:16,400
opposed to

511
00:23:16,400 --> 00:23:19,440
as a sorry linear causal relationships

512
00:23:19,440 --> 00:23:21,480
as opposed to non-linear causal

513
00:23:21,480 --> 00:23:24,720
relationships as observed in complex

514
00:23:24,720 --> 00:23:26,640
agents or systems

515
00:23:26,640 --> 00:23:29,460
so

516
00:23:29,460 --> 00:23:32,340
yeah that's uh some of the main

517
00:23:32,340 --> 00:23:34,500
distinctions between those

518
00:23:34,500 --> 00:23:36,780
Michael awesome

519
00:23:36,780 --> 00:23:39,840
yeah and then the classic paper that we

520
00:23:39,840 --> 00:23:43,440
we often return to uh like Ali mentioned

521
00:23:43,440 --> 00:23:45,360
the inner Rock

522
00:23:45,360 --> 00:23:48,900
so this paper has the uh kind of visual

523
00:23:48,900 --> 00:23:50,460
taxonomy

524
00:23:50,460 --> 00:23:52,380
from simpler to more sophisticated

525
00:23:52,380 --> 00:23:53,700
agents

526
00:23:53,700 --> 00:23:55,700
um

527
00:24:10,380 --> 00:24:11,880
sometimes the papers are in white

528
00:24:11,880 --> 00:24:14,780
sometimes they're in Black

529
00:24:15,840 --> 00:24:18,179
here

530
00:24:18,179 --> 00:24:19,919
inert systems

531
00:24:19,919 --> 00:24:23,220
active classical conservative systems

532
00:24:23,220 --> 00:24:26,700
strange systems with World models of

533
00:24:26,700 --> 00:24:28,679
their own and all of this

534
00:24:28,679 --> 00:24:31,919
um just but but this is a great response

535
00:24:31,919 --> 00:24:35,340
which is in a pan pan computationalist

536
00:24:35,340 --> 00:24:36,840
or pan cognitivist or pain

537
00:24:36,840 --> 00:24:38,880
inferentialist world then how does

538
00:24:38,880 --> 00:24:40,320
active inference apply

539
00:24:40,320 --> 00:24:43,380
one other angle is like let's just think

540
00:24:43,380 --> 00:24:46,320
about the liver or the pancreas

541
00:24:46,320 --> 00:24:48,299
and blood sugar that's our system of

542
00:24:48,299 --> 00:24:49,799
Interest

543
00:24:49,799 --> 00:24:53,400
realism is like is the pancreas actually

544
00:24:53,400 --> 00:24:55,860
doing inference on blood sugar

545
00:24:55,860 --> 00:24:57,360
and people can have a range of opinions

546
00:24:57,360 --> 00:24:59,460
but in a pan cognitivist world the

547
00:24:59,460 --> 00:25:01,440
answer is yes

548
00:25:01,440 --> 00:25:04,260
or one can kind of pull back and just

549
00:25:04,260 --> 00:25:06,960
say we're going to model the pancreas as

550
00:25:06,960 --> 00:25:09,900
doing inference on blood sugar

551
00:25:09,900 --> 00:25:12,419
so it's it is no different

552
00:25:12,419 --> 00:25:14,520
it's just an interpretation of the same

553
00:25:14,520 --> 00:25:16,620
statistical apparatus

554
00:25:16,620 --> 00:25:18,539
basically

555
00:25:18,539 --> 00:25:21,000
but there might be a setting where

556
00:25:21,000 --> 00:25:23,400
um scientific realism is is more

557
00:25:23,400 --> 00:25:25,440
Justified there's multiple lines of

558
00:25:25,440 --> 00:25:27,539
conversion evidence

559
00:25:27,539 --> 00:25:29,220
um the model is is

560
00:25:29,220 --> 00:25:31,620
uh comprehensive

561
00:25:31,620 --> 00:25:34,740
and so and being used to generate unique

562
00:25:34,740 --> 00:25:37,320
explanations and predictions versus like

563
00:25:37,320 --> 00:25:38,640
we're just going to do a linear

564
00:25:38,640 --> 00:25:41,400
relationship between these two things in

565
00:25:41,400 --> 00:25:42,960
the public health

566
00:25:42,960 --> 00:25:44,700
and so then we're not going to confuse

567
00:25:44,700 --> 00:25:48,179
the linear model with those with the

568
00:25:48,179 --> 00:25:49,919
actual cause of architecture but there

569
00:25:49,919 --> 00:25:52,020
are situations that you can design or

570
00:25:52,020 --> 00:25:53,159
analyze

571
00:25:53,159 --> 00:25:55,919
where the sparsity structure of the

572
00:25:55,919 --> 00:25:56,880
system

573
00:25:56,880 --> 00:25:59,039
which necessarily points to is what

574
00:25:59,039 --> 00:26:00,240
grants to all these interesting

575
00:26:00,240 --> 00:26:03,659
properties is becoming known to an

576
00:26:03,659 --> 00:26:05,640
extent that Within

577
00:26:05,640 --> 00:26:08,400
two or three or four Sigma it's like

578
00:26:08,400 --> 00:26:11,580
we're starting to talk about how it is

579
00:26:11,580 --> 00:26:13,559
not mistaking the map for the territory

580
00:26:13,559 --> 00:26:16,740
that's the map territory fallacy

581
00:26:16,740 --> 00:26:20,580
but also not doing some kind of map

582
00:26:20,580 --> 00:26:22,500
denialism

583
00:26:22,500 --> 00:26:24,779
which is the map territory fallacy

584
00:26:24,779 --> 00:26:27,320
fallacy

585
00:26:28,380 --> 00:26:30,720
and that's the paper which I'll add into

586
00:26:30,720 --> 00:26:35,120
by Maxwell at all

587
00:26:36,299 --> 00:26:39,779
and also if I may add another point

588
00:26:39,779 --> 00:26:42,179
uh with regard to the distinction

589
00:26:42,179 --> 00:26:45,260
between uh realism and instrumentalism

590
00:26:45,260 --> 00:26:48,299
uh I believe

591
00:26:48,299 --> 00:26:53,279
at least in the realism School uh

592
00:26:53,279 --> 00:26:55,200
probably the most relevant or well

593
00:26:55,200 --> 00:26:58,880
situated stance to uh

594
00:26:58,880 --> 00:27:02,299
reframe active inference

595
00:27:02,299 --> 00:27:06,179
I mean uh reframe its ontological status

596
00:27:06,179 --> 00:27:10,740
is structural realism as argued by Majid

597
00:27:10,740 --> 00:27:14,940
Benny and others in several papers

598
00:27:14,940 --> 00:27:16,500
nice

599
00:27:16,500 --> 00:27:18,059
yes

600
00:27:18,059 --> 00:27:20,760
he's joined several discussions and it's

601
00:27:20,760 --> 00:27:23,539
it's great to

602
00:27:24,960 --> 00:27:27,080
um

603
00:27:27,299 --> 00:27:29,100
okay is there some quotes from a book

604
00:27:29,100 --> 00:27:32,100
but yes basically I

605
00:27:32,100 --> 00:27:35,340
um forget organs other than the brain

606
00:27:35,340 --> 00:27:36,900
how could anything be doing inference

607
00:27:36,900 --> 00:27:39,000
and every and and then another angle to

608
00:27:39,000 --> 00:27:41,159
take is just like the way that a

609
00:27:41,159 --> 00:27:44,460
baseball uh computes a parabola

610
00:27:44,460 --> 00:27:45,720
like

611
00:27:45,720 --> 00:27:47,460
you don't need to think that it's doing

612
00:27:47,460 --> 00:27:50,039
it like a calculator

613
00:27:50,039 --> 00:27:53,659
but it but that's kind of like

614
00:27:53,659 --> 00:27:56,760
naturalizing the computation that's a

615
00:27:56,760 --> 00:28:00,059
path of least action in a spatial space

616
00:28:00,059 --> 00:28:02,279
but also you could have a path of least

617
00:28:02,279 --> 00:28:04,440
action in a cognitive space

618
00:28:04,440 --> 00:28:07,940
that's Bayesian mechanics

619
00:28:08,940 --> 00:28:10,980
and then you could have more realist or

620
00:28:10,980 --> 00:28:12,480
more instrumentalist angle yeah yeah

621
00:28:12,480 --> 00:28:14,279
please

622
00:28:14,279 --> 00:28:18,179
uh sorry just one one thing that somehow

623
00:28:18,179 --> 00:28:20,340
uh

624
00:28:20,340 --> 00:28:23,340
I mean it gets confused is uh some

625
00:28:23,340 --> 00:28:25,279
sometimes people think

626
00:28:25,279 --> 00:28:29,159
FEPS claims that okay so if a

627
00:28:29,159 --> 00:28:31,100
self-organism

628
00:28:31,100 --> 00:28:32,880
I mean

629
00:28:32,880 --> 00:28:35,039
if fep

630
00:28:35,039 --> 00:28:38,340
formalism applies to a self-organizing

631
00:28:38,340 --> 00:28:42,360
system then it should persist Through

632
00:28:42,360 --> 00:28:46,200
Time by preserving its markup blankets

633
00:28:46,200 --> 00:28:48,299
intact but

634
00:28:48,299 --> 00:28:51,659
actually the claim of the fep is the

635
00:28:51,659 --> 00:28:54,419
other way around so its main assertion

636
00:28:54,419 --> 00:28:55,679
is that

637
00:28:55,679 --> 00:28:59,220
if anything persists Through Time

638
00:28:59,220 --> 00:29:02,580
how does fep applies to it so in other

639
00:29:02,580 --> 00:29:06,000
sense fep doesn't provide any

640
00:29:06,000 --> 00:29:09,900
justification per se for describing the

641
00:29:09,900 --> 00:29:11,760
way that the system persists through

642
00:29:11,760 --> 00:29:13,880
time but

643
00:29:13,880 --> 00:29:16,559
we take the Persistence of the system

644
00:29:16,559 --> 00:29:19,500
through time as the premise and then

645
00:29:19,500 --> 00:29:23,960
apply fep to somehow

646
00:29:23,960 --> 00:29:27,179
investigate the implications of that

647
00:29:27,179 --> 00:29:30,179
premise through Bayesian mechanics and

648
00:29:30,179 --> 00:29:33,419
fep formulas on

649
00:29:33,419 --> 00:29:35,580
yeah

650
00:29:35,580 --> 00:29:39,380
without the implicit or explicit

651
00:29:39,380 --> 00:29:41,640
acknowledgment of the persistent

652
00:29:41,640 --> 00:29:43,679
existence of what you're measuring or

653
00:29:43,679 --> 00:29:45,299
yourself

654
00:29:45,299 --> 00:29:49,860
you don't even have something to discuss

655
00:29:49,860 --> 00:29:52,080
and a lot of times when people just

656
00:29:52,080 --> 00:29:54,059
start to specify what they mean by like

657
00:29:54,059 --> 00:29:55,679
the nouns and the verbs and the

658
00:29:55,679 --> 00:29:58,320
adjectives they use

659
00:29:58,320 --> 00:30:00,960
that's a deflationary approach

660
00:30:00,960 --> 00:30:02,520
well what if there's something that

661
00:30:02,520 --> 00:30:04,380
comes into being so so fast in between

662
00:30:04,380 --> 00:30:06,179
moments and it's not being measured and

663
00:30:06,179 --> 00:30:07,620
you can't detect it it's like well then

664
00:30:07,620 --> 00:30:10,459
how do you know it's there

665
00:30:11,640 --> 00:30:13,679
that's not within that statistical

666
00:30:13,679 --> 00:30:15,539
sensing apparatus

667
00:30:15,539 --> 00:30:17,760
so you have to take the existence of the

668
00:30:17,760 --> 00:30:20,539
of the thing

669
00:30:21,960 --> 00:30:27,440
to to be Primary in modeling something

670
00:30:28,260 --> 00:30:30,840
an actual constant has a lot of work in

671
00:30:30,840 --> 00:30:33,260
that area

672
00:30:36,200 --> 00:30:39,000
could you please pull up The Path

673
00:30:39,000 --> 00:30:43,740
integral paper on page four

674
00:30:43,740 --> 00:30:46,520
if I may

675
00:30:49,740 --> 00:30:51,000
sorry

676
00:30:51,000 --> 00:30:52,860
yep

677
00:30:52,860 --> 00:30:55,799
very nice thank you exactly right there

678
00:30:55,799 --> 00:30:59,899
the fep addresses the following question

679
00:31:00,299 --> 00:31:02,340
and it's like well if we're talking

680
00:31:02,340 --> 00:31:04,080
about something that exists even in a

681
00:31:04,080 --> 00:31:06,720
mental geometry

682
00:31:06,720 --> 00:31:08,580
that's what we want we want to start

683
00:31:08,580 --> 00:31:09,779
with

684
00:31:09,779 --> 00:31:14,520
if it exists even hypothetically

685
00:31:14,520 --> 00:31:16,200
so people say can it really describe all

686
00:31:16,200 --> 00:31:17,640
things it's like well all the things

687
00:31:17,640 --> 00:31:21,000
that exist or could exist we could use

688
00:31:21,000 --> 00:31:23,820
this modeling approach to model

689
00:31:23,820 --> 00:31:25,679
and talk about what properties it must

690
00:31:25,679 --> 00:31:27,360
possess

691
00:31:27,360 --> 00:31:29,100
but

692
00:31:29,100 --> 00:31:30,480
if you're willing to open the door to

693
00:31:30,480 --> 00:31:33,179
things that don't or can't exist

694
00:31:33,179 --> 00:31:35,039
then of course this guy's limit on what

695
00:31:35,039 --> 00:31:36,419
properties they do or don't possess

696
00:31:36,419 --> 00:31:38,640
because they might it's like the you

697
00:31:38,640 --> 00:31:41,220
know non-elephant animals things might

698
00:31:41,220 --> 00:31:43,980
not exist for a huge variety of reasons

699
00:31:43,980 --> 00:31:46,919
however things that exist either from an

700
00:31:46,919 --> 00:31:49,500
external measure or measurement or from

701
00:31:49,500 --> 00:31:51,000
self measurements

702
00:31:51,000 --> 00:31:54,480
they must be acting as if they're

703
00:31:54,480 --> 00:31:56,460
self-evidencing

704
00:31:56,460 --> 00:31:58,620
reducing surprise relative to generative

705
00:31:58,620 --> 00:32:01,140
model path of least action through an

706
00:32:01,140 --> 00:32:04,340
information geometric space

707
00:32:04,380 --> 00:32:06,720
if it isn't doing that you're not going

708
00:32:06,720 --> 00:32:08,159
to observe it

709
00:32:08,159 --> 00:32:09,899
and that's where we get the particular

710
00:32:09,899 --> 00:32:11,640
partition

711
00:32:11,640 --> 00:32:13,679
and the particular partition in the in

712
00:32:13,679 --> 00:32:15,480
the particular physics

713
00:32:15,480 --> 00:32:18,240
slash Bayesian mechanics

714
00:32:18,240 --> 00:32:22,740
since Carl first since 2019 monograph a

715
00:32:22,740 --> 00:32:24,299
free energy principle for a particular

716
00:32:24,299 --> 00:32:27,779
physics that was like a big inflection

717
00:32:27,779 --> 00:32:29,100
point

718
00:32:29,100 --> 00:32:32,940
in this line of research

719
00:32:32,940 --> 00:32:36,140
whereas in the 2016 to 2018

720
00:32:36,140 --> 00:32:40,200
there's a lot of qualitative work and

721
00:32:40,200 --> 00:32:42,179
the philosophical work applying to

722
00:32:42,179 --> 00:32:44,220
multi-scale invested systems and and

723
00:32:44,220 --> 00:32:46,440
self-organization

724
00:32:46,440 --> 00:32:48,480
um amidst other empirical simulations

725
00:32:48,480 --> 00:32:52,100
happening continually in all of this

726
00:32:52,320 --> 00:32:54,840
so

727
00:32:54,840 --> 00:32:56,880
reading reading works of different times

728
00:32:56,880 --> 00:32:59,279
like different pieces are kind of going

729
00:32:59,279 --> 00:33:02,419
to be made clear or not

730
00:33:08,940 --> 00:33:11,820
what is the role of precision in nested

731
00:33:11,820 --> 00:33:14,299
models

732
00:33:19,919 --> 00:33:23,159
well here I'll uh and also by way of

733
00:33:23,159 --> 00:33:26,399
demonstrating the the uh transferability

734
00:33:26,399 --> 00:33:29,580
of active inference generative models

735
00:33:29,580 --> 00:33:31,860
these three figures are discussed in

736
00:33:31,860 --> 00:33:33,960
live stream 28 from the original paper

737
00:33:33,960 --> 00:33:37,440
Smith at all computational phenomenology

738
00:33:37,440 --> 00:33:40,559
so this is a static perceptual Bayesian

739
00:33:40,559 --> 00:33:41,399
model

740
00:33:41,399 --> 00:33:43,320
we have hidden State observations and we

741
00:33:43,320 --> 00:33:44,640
hear

742
00:33:44,640 --> 00:33:46,919
as a modulator literally a

743
00:33:46,919 --> 00:33:50,340
neuromodulator on the a matrix Tail of

744
00:33:50,340 --> 00:33:52,260
Two densities recognition Matrix

745
00:33:52,260 --> 00:33:53,820
generated model

746
00:33:53,820 --> 00:33:58,019
you have the Precision so Precision is

747
00:33:58,019 --> 00:33:59,880
one over the temperature so whether you

748
00:33:59,880 --> 00:34:01,039
think of it as like higher temperature

749
00:34:01,039 --> 00:34:05,340
is lower Precision or lower you know or

750
00:34:05,340 --> 00:34:07,080
vice versa

751
00:34:07,080 --> 00:34:10,020
they're they're the same

752
00:34:10,020 --> 00:34:12,300
when your Precision is low your

753
00:34:12,300 --> 00:34:13,739
temperature is high

754
00:34:13,739 --> 00:34:16,619
a gets blurred out

755
00:34:16,619 --> 00:34:19,379
the high temperature limit is like a is

756
00:34:19,379 --> 00:34:21,540
becomes flattened

757
00:34:21,540 --> 00:34:24,179
whereas in the low temperature limit a

758
00:34:24,179 --> 00:34:26,159
becomes sharpened

759
00:34:26,159 --> 00:34:30,300
and so this is a common method in uh

760
00:34:30,300 --> 00:34:33,540
recognition modeling okay

761
00:34:33,540 --> 00:34:35,760
now they move into

762
00:34:35,760 --> 00:34:37,800
adding action in so here there's the

763
00:34:37,800 --> 00:34:41,040
policy figure 4.3 figure 7.3

764
00:34:41,040 --> 00:34:43,260
everything we've looked at

765
00:34:43,260 --> 00:34:47,520
and then they move to this

766
00:34:47,520 --> 00:34:50,339
um nested model now in the Sanford Smith

767
00:34:50,339 --> 00:34:53,580
paper it was being mobilized in terms of

768
00:34:53,580 --> 00:34:55,980
basically phenomenology and meditative

769
00:34:55,980 --> 00:34:57,839
experiences

770
00:34:57,839 --> 00:35:00,420
direct sensory perception

771
00:35:00,420 --> 00:35:03,660
you know visual perception and isaacades

772
00:35:03,660 --> 00:35:05,780
attention

773
00:35:05,780 --> 00:35:09,180
unreportable attention

774
00:35:09,180 --> 00:35:11,040
and then awareness at a third level

775
00:35:11,040 --> 00:35:12,900
observing that

776
00:35:12,900 --> 00:35:15,180
and so the mo you you can add an

777
00:35:15,180 --> 00:35:18,119
uncertainty like a Precision on any

778
00:35:18,119 --> 00:35:20,339
variable you could have an uncertainty

779
00:35:20,339 --> 00:35:22,380
on your prior D you could have

780
00:35:22,380 --> 00:35:24,300
uncertainty on all kinds of things but

781
00:35:24,300 --> 00:35:26,160
sometimes uncertainties on specific

782
00:35:26,160 --> 00:35:27,660
variables

783
00:35:27,660 --> 00:35:29,400
become associated with like certain

784
00:35:29,400 --> 00:35:31,320
cognitive phenomena

785
00:35:31,320 --> 00:35:33,119
in this case they're using it to

786
00:35:33,119 --> 00:35:36,300
describe introspective

787
00:35:36,300 --> 00:35:40,500
and explainable AI systems

788
00:35:40,500 --> 00:35:43,079
taking the exact same figures exact same

789
00:35:43,079 --> 00:35:44,820
formalisms just moving them into the AI

790
00:35:44,820 --> 00:35:46,260
setting

791
00:35:46,260 --> 00:35:47,820
so

792
00:35:47,820 --> 00:35:49,920
um Precision on a and here's that live

793
00:35:49,920 --> 00:35:51,839
stream 28 and the slides and everything

794
00:35:51,839 --> 00:35:57,560
Precision on a is like sensory ambiguity

795
00:35:57,780 --> 00:35:59,400
um

796
00:35:59,400 --> 00:36:03,240
Precision on G so how how

797
00:36:03,240 --> 00:36:04,440
um

798
00:36:04,440 --> 00:36:06,720
precise are you on

799
00:36:06,720 --> 00:36:09,919
the the free energy

800
00:36:11,220 --> 00:36:14,640
um that is associated with the affect

801
00:36:14,640 --> 00:36:18,180
in this uh sophisticated affect

802
00:36:18,180 --> 00:36:20,820
here's some discussion on embodiment and

803
00:36:20,820 --> 00:36:24,000
the Alexander technique

804
00:36:24,000 --> 00:36:27,780
um so suffice to say

805
00:36:27,780 --> 00:36:29,940
precision and nested modeling is

806
00:36:29,940 --> 00:36:31,619
basically like the general Precision

807
00:36:31,619 --> 00:36:33,240
concept which is basically used

808
00:36:33,240 --> 00:36:35,099
everywhere this is how we fit Bayesian

809
00:36:35,099 --> 00:36:37,980
models we have some hyper prior prior

810
00:36:37,980 --> 00:36:40,440
Distribution on a parameter

811
00:36:40,440 --> 00:36:42,660
and if that prior distribution is too

812
00:36:42,660 --> 00:36:45,240
sharp then you're you're basically

813
00:36:45,240 --> 00:36:48,240
that's a it's a pathology of the of the

814
00:36:48,240 --> 00:36:50,099
prior it's too precise

815
00:36:50,099 --> 00:36:53,760
if it was too imprecise

816
00:36:53,760 --> 00:36:56,460
you have an underfit model

817
00:36:56,460 --> 00:36:59,880
so it's like that and especially in

818
00:36:59,880 --> 00:37:01,619
nested models

819
00:37:01,619 --> 00:37:05,400
Precision plays a role in kind of gating

820
00:37:05,400 --> 00:37:07,200
just in this case it's a general

821
00:37:07,200 --> 00:37:08,400
question so you could make it do

822
00:37:08,400 --> 00:37:10,980
anything basically but here the

823
00:37:10,980 --> 00:37:14,099
Precision on a is like gating

824
00:37:14,099 --> 00:37:15,780
let's just say the first and the third

825
00:37:15,780 --> 00:37:17,880
level

826
00:37:17,880 --> 00:37:20,520
so if there's no attention being paid to

827
00:37:20,520 --> 00:37:21,839
sensory input

828
00:37:21,839 --> 00:37:24,180
don't be surprised that they don't come

829
00:37:24,180 --> 00:37:26,460
up to attention

830
00:37:26,460 --> 00:37:29,099
but if the if this

831
00:37:29,099 --> 00:37:30,480
um gating

832
00:37:30,480 --> 00:37:33,359
can be like super direct and forceful

833
00:37:33,359 --> 00:37:35,940
then you'll have propagation of

834
00:37:35,940 --> 00:37:38,040
informational causality on this network

835
00:37:38,040 --> 00:37:41,240
up to the higher level

836
00:37:52,800 --> 00:37:56,420
h113 in the textbook

837
00:38:04,380 --> 00:38:06,720
all right the decision so this is about

838
00:38:06,720 --> 00:38:08,520
planning as inference which one of these

839
00:38:08,520 --> 00:38:10,440
questions

840
00:38:10,440 --> 00:38:13,099
um was also about

841
00:38:18,180 --> 00:38:19,500
the decision whether to model

842
00:38:19,500 --> 00:38:21,540
alternative futures

843
00:38:21,540 --> 00:38:24,420
counter factual features conditions upon

844
00:38:24,420 --> 00:38:26,160
policy selection how would the world

845
00:38:26,160 --> 00:38:28,380
change if I did this or that is largely

846
00:38:28,380 --> 00:38:30,359
tied up with the choice between discrete

847
00:38:30,359 --> 00:38:32,280
and continuous models

848
00:38:32,280 --> 00:38:34,020
because the idea of selecting between

849
00:38:34,020 --> 00:38:36,119
alternative Futures defined by sequences

850
00:38:36,119 --> 00:38:37,920
of actions is more simply articulated

851
00:38:37,920 --> 00:38:41,339
using discrete time models all right

852
00:38:41,339 --> 00:38:43,880
so

853
00:38:44,280 --> 00:38:47,480
figure 4.3

854
00:38:50,760 --> 00:38:53,460
figure 4.3 is like the Rosetta Stone it

855
00:38:53,460 --> 00:38:55,859
juxtaposes the discrete time continuous

856
00:38:55,859 --> 00:38:57,599
discrete time generative model and the

857
00:38:57,599 --> 00:38:59,640
continuous time generative model

858
00:38:59,640 --> 00:39:02,779
so I'll just copy this

859
00:39:03,240 --> 00:39:06,599
in the discrete time model you have S T

860
00:39:06,599 --> 00:39:09,960
minus 1 s of t s of t plus one so

861
00:39:09,960 --> 00:39:12,540
Futures and pasts if it's sophisticated

862
00:39:12,540 --> 00:39:14,760
active inference are being explicitly

863
00:39:14,760 --> 00:39:16,140
modeled

864
00:39:16,140 --> 00:39:18,960
so it's like what would happen at seven

865
00:39:18,960 --> 00:39:21,180
o'clock if I did this

866
00:39:21,180 --> 00:39:23,700
that is explicitly addressable with a

867
00:39:23,700 --> 00:39:25,740
discrete time model of the correct time

868
00:39:25,740 --> 00:39:26,880
Horizon

869
00:39:26,880 --> 00:39:28,380
so you have to explicitly say I'm

870
00:39:28,380 --> 00:39:30,359
talking about an hourly model and seven

871
00:39:30,359 --> 00:39:33,060
depth and so then you in branching time

872
00:39:33,060 --> 00:39:34,500
active inference just like a chess

873
00:39:34,500 --> 00:39:36,359
algorithm it's dealing with like the

874
00:39:36,359 --> 00:39:37,619
branching

875
00:39:37,619 --> 00:39:39,180
structure because if you have a lot of

876
00:39:39,180 --> 00:39:41,099
affordances

877
00:39:41,099 --> 00:39:43,020
then then you have and you have a lot of

878
00:39:43,020 --> 00:39:44,940
time depth you can imagine this this is

879
00:39:44,940 --> 00:39:47,820
a combinatorial explosion

880
00:39:47,820 --> 00:39:50,300
um in contrast

881
00:39:50,300 --> 00:39:53,400
though these two generative models are

882
00:39:53,400 --> 00:39:55,800
shown here to emphasize their structural

883
00:39:55,800 --> 00:39:57,300
similarity

884
00:39:57,300 --> 00:39:59,640
The Continuous time generative model is

885
00:39:59,640 --> 00:40:02,220
actually not explicitly modeling past

886
00:40:02,220 --> 00:40:04,140
present future time steps

887
00:40:04,140 --> 00:40:07,140
rather it's modeling the generalized

888
00:40:07,140 --> 00:40:10,380
coordinates of motion x hidden State X

889
00:40:10,380 --> 00:40:12,240
prime rate of change X double Prime

890
00:40:12,240 --> 00:40:14,820
second derivative

891
00:40:14,820 --> 00:40:16,920
so in that way it's a lot more like a

892
00:40:16,920 --> 00:40:18,780
Taylor series expansion

893
00:40:18,780 --> 00:40:21,000
so a Taylor series expansion technically

894
00:40:21,000 --> 00:40:22,859
even a Taylor series expansion of you

895
00:40:22,859 --> 00:40:24,119
know depth one

896
00:40:24,119 --> 00:40:27,720
it has an answer for every single point

897
00:40:27,720 --> 00:40:29,160
in the number line

898
00:40:29,160 --> 00:40:32,400
but that doesn't mean it's a good one

899
00:40:32,400 --> 00:40:35,520
um and so the continuous time models

900
00:40:35,520 --> 00:40:38,460
kind of trivially have something to say

901
00:40:38,460 --> 00:40:42,599
about all possible time steps

902
00:40:42,599 --> 00:40:45,900
just by analytic continuation of the

903
00:40:45,900 --> 00:40:47,880
Taylor series expansion in the

904
00:40:47,880 --> 00:40:50,579
generalized coordinates emotion away

905
00:40:50,579 --> 00:40:51,960
however

906
00:40:51,960 --> 00:40:54,060
you don't necessarily like know how

907
00:40:54,060 --> 00:40:58,020
accurate it is for any given points

908
00:40:58,020 --> 00:40:59,700
it also doesn't

909
00:40:59,700 --> 00:41:03,720
have explicit counterfactuals

910
00:41:03,720 --> 00:41:05,040
so if you do some Taylor series

911
00:41:05,040 --> 00:41:07,680
expansion it says yeah at x equals three

912
00:41:07,680 --> 00:41:10,800
over Y is 5.

913
00:41:10,800 --> 00:41:12,480
but then if you said well what if it

914
00:41:12,480 --> 00:41:13,500
were different

915
00:41:13,500 --> 00:41:15,720
the only way you could do that would be

916
00:41:15,720 --> 00:41:17,579
change the parameters of the Taylor

917
00:41:17,579 --> 00:41:21,720
series and recalculate it at that point

918
00:41:21,720 --> 00:41:25,380
so the model itself is not exactly doing

919
00:41:25,380 --> 00:41:27,180
these like what would happen if I did

920
00:41:27,180 --> 00:41:29,419
that

921
00:41:31,619 --> 00:41:35,940
so Futures are explicit

922
00:41:35,940 --> 00:41:38,640
in discrete time models

923
00:41:38,640 --> 00:41:42,119
and interpretable explicitly

924
00:41:42,119 --> 00:41:45,119
whereas in continuous time models pasts

925
00:41:45,119 --> 00:41:47,099
and Futures are kind of trivially

926
00:41:47,099 --> 00:41:48,960
predicted

927
00:41:48,960 --> 00:41:50,880
such that it doesn't really make sense

928
00:41:50,880 --> 00:41:53,940
to talk about just um counterfactuals in

929
00:41:53,940 --> 00:41:56,720
the same exact way

930
00:41:59,220 --> 00:42:01,619
and these models can be hybridized and

931
00:42:01,619 --> 00:42:04,640
and fused

932
00:42:05,099 --> 00:42:09,380
which is in um chapter eight

933
00:42:16,500 --> 00:42:19,380
can we generate a a code template looks

934
00:42:19,380 --> 00:42:21,300
like yes but there's of course more

935
00:42:21,300 --> 00:42:22,980
information

936
00:42:22,980 --> 00:42:26,960
but it's an important question

937
00:42:33,599 --> 00:42:35,760
how is temporal depth specific to

938
00:42:35,760 --> 00:42:38,099
planning does temporal depth in

939
00:42:38,099 --> 00:42:40,260
perception make any sense

940
00:42:40,260 --> 00:42:42,660
what is temporal depth

941
00:42:42,660 --> 00:42:44,700
so temporal depth is how many time steps

942
00:42:44,700 --> 00:42:46,380
are the models considered in the

943
00:42:46,380 --> 00:42:48,720
discrete time case

944
00:42:48,720 --> 00:42:50,760
um this temporal depth make sense in

945
00:42:50,760 --> 00:42:52,020
perception

946
00:42:52,020 --> 00:42:55,020
well perception is always modeled as

947
00:42:55,020 --> 00:42:56,579
instantaneous

948
00:42:56,579 --> 00:43:00,119
however depending on the temporal scale

949
00:43:00,119 --> 00:43:02,040
of of a model

950
00:43:02,040 --> 00:43:04,619
that perception may be instantaneous

951
00:43:04,619 --> 00:43:08,900
over a certain temporal thickness

952
00:43:11,040 --> 00:43:13,500
power Y is temporal depth specific to

953
00:43:13,500 --> 00:43:15,000
planning

954
00:43:15,000 --> 00:43:17,579
so in planning as inference policy

955
00:43:17,579 --> 00:43:20,940
selection is inference your selecting or

956
00:43:20,940 --> 00:43:22,859
sampling from policies based upon their

957
00:43:22,859 --> 00:43:25,640
expected free energy

958
00:43:27,180 --> 00:43:29,099
in order to plan over a given time

959
00:43:29,099 --> 00:43:32,400
Horizon and actually evaluate

960
00:43:32,400 --> 00:43:33,839
the um

961
00:43:33,839 --> 00:43:36,119
the play outs you need to have a

962
00:43:36,119 --> 00:43:39,800
temporal depth of that amount

963
00:43:40,859 --> 00:43:43,319
Thomas Parr in his

964
00:43:43,319 --> 00:43:46,040
um book stream

965
00:43:53,280 --> 00:43:56,460
so early implementations were coming

966
00:43:56,460 --> 00:43:58,200
from the filtering of a generalized

967
00:43:58,200 --> 00:43:59,700
filtering approach maybe it wasn't

968
00:43:59,700 --> 00:44:01,140
generalized at that point but particle

969
00:44:01,140 --> 00:44:02,819
filtering approach and I equipped these

970
00:44:02,819 --> 00:44:04,319
models with action

971
00:44:04,319 --> 00:44:06,060
then people started thinking about how

972
00:44:06,060 --> 00:44:08,339
to get sequential Dynamics Predator prey

973
00:44:08,339 --> 00:44:10,440
lock of Volterra models winnerless

974
00:44:10,440 --> 00:44:12,599
competition neural Darwinism

975
00:44:12,599 --> 00:44:14,819
in these situations there's in aversions

976
00:44:14,819 --> 00:44:16,260
of sequential

977
00:44:16,260 --> 00:44:19,079
recurrent continuous Dynamics like a

978
00:44:19,079 --> 00:44:22,920
limit cycle of more than two

979
00:44:22,920 --> 00:44:26,300
then people wanted to model explicit

980
00:44:26,300 --> 00:44:28,500
long-term planning

981
00:44:28,500 --> 00:44:30,780
and so from around

982
00:44:30,780 --> 00:44:32,359
you know

983
00:44:32,359 --> 00:44:34,980
2014 or something

984
00:44:34,980 --> 00:44:37,079
there was a lot more development in the

985
00:44:37,079 --> 00:44:39,960
discrete State space model which enabled

986
00:44:39,960 --> 00:44:42,300
the well understood partially observable

987
00:44:42,300 --> 00:44:44,760
bar composition process

988
00:44:44,760 --> 00:44:47,339
and a lot of the characterization of the

989
00:44:47,339 --> 00:44:50,940
planning as inference explore exploit

990
00:44:50,940 --> 00:44:51,960
um

991
00:44:51,960 --> 00:44:53,520
then

992
00:44:53,520 --> 00:44:56,640
later developments supported

993
00:44:56,640 --> 00:44:59,160
um nested models here there's a discrete

994
00:44:59,160 --> 00:45:00,900
time on top and a discrete time on the

995
00:45:00,900 --> 00:45:03,720
bottom but also it could be continuous

996
00:45:03,720 --> 00:45:05,339
time on the bottom

997
00:45:05,339 --> 00:45:09,240
oh yes then continuous State models were

998
00:45:09,240 --> 00:45:11,099
reintroduced

999
00:45:11,099 --> 00:45:14,160
as the lower levels of higher level

1000
00:45:14,160 --> 00:45:15,839
discrete time models

1001
00:45:15,839 --> 00:45:18,900
and um that is kind of like the folk

1002
00:45:18,900 --> 00:45:22,079
psychology live stream 46 active

1003
00:45:22,079 --> 00:45:23,700
inference does not contradict folk

1004
00:45:23,700 --> 00:45:25,319
psychology

1005
00:45:25,319 --> 00:45:28,380
discrete time decision making up top

1006
00:45:28,380 --> 00:45:30,900
you know discrete time and discrete

1007
00:45:30,900 --> 00:45:32,040
decisions

1008
00:45:32,040 --> 00:45:34,140
and then more on the sensory motor it's

1009
00:45:34,140 --> 00:45:35,640
more like continuous time continuous

1010
00:45:35,640 --> 00:45:38,000
action

1011
00:45:49,560 --> 00:45:52,040
okay

1012
00:45:52,920 --> 00:45:55,700
new question

1013
00:46:01,020 --> 00:46:04,220
figure 6.1

1014
00:46:09,900 --> 00:46:12,260
all right

1015
00:46:12,839 --> 00:46:15,980
particular partition

1016
00:46:19,260 --> 00:46:20,700
how is the mutual interaction between

1017
00:46:20,700 --> 00:46:22,920
active States and sensory States meant

1018
00:46:22,920 --> 00:46:25,380
in six one so the bi-directional line

1019
00:46:25,380 --> 00:46:27,020
here

1020
00:46:27,020 --> 00:46:29,280
can they mutually change their states

1021
00:46:29,280 --> 00:46:31,980
without impacting neither internal nor

1022
00:46:31,980 --> 00:46:33,540
external States

1023
00:46:33,540 --> 00:46:35,339
yes they could

1024
00:46:35,339 --> 00:46:36,839
you could have

1025
00:46:36,839 --> 00:46:39,000
um nodes that

1026
00:46:39,000 --> 00:46:40,859
are these nodes are in communication

1027
00:46:40,859 --> 00:46:42,060
with each other

1028
00:46:42,060 --> 00:46:44,520
in general this image it's more

1029
00:46:44,520 --> 00:46:46,140
important what it what it doesn't show

1030
00:46:46,140 --> 00:46:48,240
so there's no backwards Arrow from

1031
00:46:48,240 --> 00:46:50,460
external to octave or from internal to

1032
00:46:50,460 --> 00:46:52,020
sensory you can't have your thumb on the

1033
00:46:52,020 --> 00:46:53,160
scale

1034
00:46:53,160 --> 00:46:55,500
and the symmetry of whatever that is

1035
00:46:55,500 --> 00:46:57,359
from the outside

1036
00:46:57,359 --> 00:47:00,839
and the only other constraint is no

1037
00:47:00,839 --> 00:47:03,599
telepathy no telekinesis

1038
00:47:03,599 --> 00:47:05,280
the only way to receive information

1039
00:47:05,280 --> 00:47:07,200
about external States is through sensory

1040
00:47:07,200 --> 00:47:09,540
States the only way to act on costly

1041
00:47:09,540 --> 00:47:11,400
intervene on external States is through

1042
00:47:11,400 --> 00:47:14,220
active States so

1043
00:47:14,220 --> 00:47:18,480
no thumb on the scale and the mirror

1044
00:47:18,480 --> 00:47:21,180
no telepathy no telekinesis

1045
00:47:21,180 --> 00:47:23,520
that doesn't mean that for any given

1046
00:47:23,520 --> 00:47:26,520
model these arrows are like all

1047
00:47:26,520 --> 00:47:29,520
important or all relative uh or I mean

1048
00:47:29,520 --> 00:47:32,220
all relatively the same importance

1049
00:47:32,220 --> 00:47:33,540
so if you want to design a computer

1050
00:47:33,540 --> 00:47:35,400
system where the sensory States comes in

1051
00:47:35,400 --> 00:47:37,260
one computer and this is a second

1052
00:47:37,260 --> 00:47:38,640
computer and this is the third computer

1053
00:47:38,640 --> 00:47:41,040
so like there's no direct Edge between

1054
00:47:41,040 --> 00:47:43,440
sensory and active States

1055
00:47:43,440 --> 00:47:46,079
that's you can create that causal

1056
00:47:46,079 --> 00:47:47,579
architecture

1057
00:47:47,579 --> 00:47:50,819
what is it supposed to model nothing

1058
00:47:50,819 --> 00:47:55,079
modeling of supposed things is done in

1059
00:47:55,079 --> 00:47:57,960
chapter six and Beyond but in general

1060
00:47:57,960 --> 00:48:00,359
this is not trying to model any specific

1061
00:48:00,359 --> 00:48:03,540
situation despite the brain in the world

1062
00:48:03,540 --> 00:48:06,119
could they Circle Mutual mutually

1063
00:48:06,119 --> 00:48:07,740
modifying their states and then

1064
00:48:07,740 --> 00:48:08,880
eventually arrive at a state where they

1065
00:48:08,880 --> 00:48:12,380
change the external internal States

1066
00:48:13,619 --> 00:48:15,359
yeah maybe they have a faster time scale

1067
00:48:15,359 --> 00:48:16,560
or something or maybe they're in

1068
00:48:16,560 --> 00:48:18,300
communication with each other

1069
00:48:18,300 --> 00:48:20,940
and then active States ends or like

1070
00:48:20,940 --> 00:48:24,060
sensory States ends up influencing

1071
00:48:24,060 --> 00:48:27,119
internal States via active influencing

1072
00:48:27,119 --> 00:48:30,060
it and so yes it could happen would that

1073
00:48:30,060 --> 00:48:31,560
mean that we can model with this trick

1074
00:48:31,560 --> 00:48:34,560
any arbitrary Behavior

1075
00:48:34,560 --> 00:48:36,540
it's not necessarily a trick it's just a

1076
00:48:36,540 --> 00:48:38,099
particular partition

1077
00:48:38,099 --> 00:48:40,200
without allow us to model terrain

1078
00:48:40,200 --> 00:48:41,760
equivalence

1079
00:48:41,760 --> 00:48:43,079
I'm not sure

1080
00:48:43,079 --> 00:48:45,300
if there's an understanding of what

1081
00:48:45,300 --> 00:48:47,220
formally demonstrates turn equivalence

1082
00:48:47,220 --> 00:48:50,700
then I I but I believe it's possible I

1083
00:48:50,700 --> 00:48:53,339
think as a turing architecture as far as

1084
00:48:53,339 --> 00:48:56,040
I understand it abstracted from the Von

1085
00:48:56,040 --> 00:48:58,800
Neumann architecture is basically just

1086
00:48:58,800 --> 00:49:01,319
saying like you can do a touring tape

1087
00:49:01,319 --> 00:49:03,420
so I don't see why not

1088
00:49:03,420 --> 00:49:06,619
why would we need that

1089
00:49:06,859 --> 00:49:11,540
512k ought to be enough for anyone right

1090
00:49:12,599 --> 00:49:14,640
I don't know why we need it

1091
00:49:14,640 --> 00:49:17,540
we expect it

1092
00:49:19,140 --> 00:49:22,980
but yeah the these graphs in general are

1093
00:49:22,980 --> 00:49:23,880
more like

1094
00:49:23,880 --> 00:49:25,740
the space of the possible

1095
00:49:25,740 --> 00:49:27,780
with the important caveats of that were

1096
00:49:27,780 --> 00:49:29,220
mentioned with the no thumb on the scale

1097
00:49:29,220 --> 00:49:30,900
and the mirror and the natural empathy

1098
00:49:30,900 --> 00:49:32,700
note telekinesis

1099
00:49:32,700 --> 00:49:35,700
but how relevant these edges are or what

1100
00:49:35,700 --> 00:49:37,500
systems have what Behavior or what

1101
00:49:37,500 --> 00:49:39,540
cognitive phenomena are granted by what

1102
00:49:39,540 --> 00:49:41,460
Dynamics on graphs

1103
00:49:41,460 --> 00:49:43,800
there's just no General answer to those

1104
00:49:43,800 --> 00:49:46,980
things because if you do a graph

1105
00:49:46,980 --> 00:49:48,420
for one setting it's going to be

1106
00:49:48,420 --> 00:49:50,660
different

1107
00:49:54,240 --> 00:49:55,980
what did you mean

1108
00:49:55,980 --> 00:49:58,020
when you said that any entree could be

1109
00:49:58,020 --> 00:50:01,280
ordered with any side dish

1110
00:50:01,800 --> 00:50:05,280
like that in this recipe theme that

1111
00:50:05,280 --> 00:50:07,579
we're in

1112
00:50:10,619 --> 00:50:12,900
models that include continuous or

1113
00:50:12,900 --> 00:50:14,520
discrete variables or both

1114
00:50:14,520 --> 00:50:16,740
what is meant by variable States or

1115
00:50:16,740 --> 00:50:18,359
observations how can States be

1116
00:50:18,359 --> 00:50:19,680
continuous

1117
00:50:19,680 --> 00:50:23,940
as those here are probably familiar with

1118
00:50:23,940 --> 00:50:25,859
States or observations could be like

1119
00:50:25,859 --> 00:50:28,500
discrete like zero or one

1120
00:50:28,500 --> 00:50:31,319
or any integer or it could be a

1121
00:50:31,319 --> 00:50:34,400
continuous number

1122
00:50:37,500 --> 00:50:39,960
computers discretize continuous

1123
00:50:39,960 --> 00:50:43,260
functions to approximate them

1124
00:50:43,260 --> 00:50:45,359
but there's so many exciting directions

1125
00:50:45,359 --> 00:50:47,640
with unconventional Computing analog

1126
00:50:47,640 --> 00:50:51,480
Computing mem computing

1127
00:50:51,480 --> 00:50:52,380
Etc

1128
00:50:52,380 --> 00:50:54,780
that like

1129
00:50:54,780 --> 00:50:56,819
there's more to it but just simply it

1130
00:50:56,819 --> 00:51:00,680
could be any type of variable

1131
00:51:04,020 --> 00:51:06,780
okay like this new new question this is

1132
00:51:06,780 --> 00:51:08,220
this is um

1133
00:51:08,220 --> 00:51:12,500
let's maybe look at this one in closing

1134
00:51:17,460 --> 00:51:19,559
if the external state is unknowable how

1135
00:51:19,559 --> 00:51:22,200
can we set up a generative process

1136
00:51:22,200 --> 00:51:23,520
so that's what's generating the

1137
00:51:23,520 --> 00:51:26,220
observations when our experience is

1138
00:51:26,220 --> 00:51:28,760
based solely on

1139
00:51:28,760 --> 00:51:31,200
the process of reducing variational free

1140
00:51:31,200 --> 00:51:33,180
energy based on predictions and sensory

1141
00:51:33,180 --> 00:51:36,799
inputs across the markup blanket

1142
00:51:37,200 --> 00:51:39,000
this person has just described the

1143
00:51:39,000 --> 00:51:41,220
challenge of life

1144
00:51:41,220 --> 00:51:42,780
I don't think that there's a specific

1145
00:51:42,780 --> 00:51:44,160
answer to that I think this is literally

1146
00:51:44,160 --> 00:51:46,140
a restatement of the particular

1147
00:51:46,140 --> 00:51:47,819
partition

1148
00:51:47,819 --> 00:51:50,339
if this was just said

1149
00:51:50,339 --> 00:51:53,700
um the challenge is based is to given

1150
00:51:53,700 --> 00:51:55,920
the unknowability direct unknowability

1151
00:51:55,920 --> 00:51:58,619
of unturned States The Challenge and the

1152
00:51:58,619 --> 00:52:01,200
opportunity is to set up a generative

1153
00:52:01,200 --> 00:52:03,960
model based solely on the process of

1154
00:52:03,960 --> 00:52:06,119
reducing free energy based on

1155
00:52:06,119 --> 00:52:07,859
predictions and sensory inputs across a

1156
00:52:07,859 --> 00:52:11,240
blanket and adaptive action

1157
00:52:11,520 --> 00:52:13,680
I'm not sure if they meant process or

1158
00:52:13,680 --> 00:52:15,000
model here

1159
00:52:15,000 --> 00:52:16,559
because setting up a generative process

1160
00:52:16,559 --> 00:52:19,559
is something that the human modeler does

1161
00:52:19,559 --> 00:52:21,599
when they're designing a simulation but

1162
00:52:21,599 --> 00:52:24,059
not like what the um

1163
00:52:24,059 --> 00:52:27,140
animal has to do

1164
00:52:29,099 --> 00:52:31,020
what I'm trying to get at here is we are

1165
00:52:31,020 --> 00:52:32,220
making an assumption about the generator

1166
00:52:32,220 --> 00:52:34,980
sensory input when making the model

1167
00:52:34,980 --> 00:52:36,540
yes

1168
00:52:36,540 --> 00:52:39,059
but that model can never be accurate

1169
00:52:39,059 --> 00:52:42,780
well it absolutely can be accurate it's

1170
00:52:42,780 --> 00:52:44,880
never going to be a one-to-one map as

1171
00:52:44,880 --> 00:52:46,140
the territory

1172
00:52:46,140 --> 00:52:49,079
but of course it can be accurate we

1173
00:52:49,079 --> 00:52:50,520
don't need to understand I have an

1174
00:52:50,520 --> 00:52:53,220
atomic simulation of the sun to have a

1175
00:52:53,220 --> 00:52:54,900
generative process of how many photons

1176
00:52:54,900 --> 00:52:57,119
are going to hit my window tomorrow at

1177
00:52:57,119 --> 00:52:59,339
7am

1178
00:52:59,339 --> 00:53:01,380
so there's a core invalidity in the

1179
00:53:01,380 --> 00:53:02,400
notion that we set up a generative

1180
00:53:02,400 --> 00:53:03,900
process model

1181
00:53:03,900 --> 00:53:05,700
not sure what ontology mixing is

1182
00:53:05,700 --> 00:53:07,980
happening but almost by definition we're

1183
00:53:07,980 --> 00:53:09,540
introducing an error in the model by

1184
00:53:09,540 --> 00:53:12,140
setting up the parameters

1185
00:53:12,140 --> 00:53:14,280
for the generative process the general

1186
00:53:14,280 --> 00:53:15,720
model we remove the fundamental of

1187
00:53:15,720 --> 00:53:18,119
aspect of actin which is the dynamical

1188
00:53:18,119 --> 00:53:19,680
system has only one thing you can do and

1189
00:53:19,680 --> 00:53:21,839
that's to reduce free energy

1190
00:53:21,839 --> 00:53:24,240
so there's some some good points and

1191
00:53:24,240 --> 00:53:26,280
some mixed things so

1192
00:53:26,280 --> 00:53:27,000
um

1193
00:53:27,000 --> 00:53:29,400
it's not what it does is the action it

1194
00:53:29,400 --> 00:53:31,200
takes in the world variational free

1195
00:53:31,200 --> 00:53:33,900
energy is just a tractable computational

1196
00:53:33,900 --> 00:53:35,280
heuristic

1197
00:53:35,280 --> 00:53:37,380
yes if you set up

1198
00:53:37,380 --> 00:53:39,559
the generative process to be a number

1199
00:53:39,559 --> 00:53:41,700
continuous number between one and ten

1200
00:53:41,700 --> 00:53:44,040
and then the generative model to do the

1201
00:53:44,040 --> 00:53:45,260
exact same to kind of have

1202
00:53:45,260 --> 00:53:47,760
pre-structurally learned the problem

1203
00:53:47,760 --> 00:53:49,020
then it's going to be a simple

1204
00:53:49,020 --> 00:53:50,099
simulation

1205
00:53:50,099 --> 00:53:51,359
whereas you can have a more

1206
00:53:51,359 --> 00:53:53,640
sophisticated simulation that involves

1207
00:53:53,640 --> 00:53:55,800
structure learning as part of the

1208
00:53:55,800 --> 00:53:58,559
agent's generative model

1209
00:53:58,559 --> 00:54:00,300
are we not introducing information the

1210
00:54:00,300 --> 00:54:01,740
model that would not be available in the

1211
00:54:01,740 --> 00:54:03,420
real world if we actually defined the

1212
00:54:03,420 --> 00:54:06,540
generative process yeah you can give any

1213
00:54:06,540 --> 00:54:10,680
model too much information essentially

1214
00:54:11,280 --> 00:54:14,099
so if it has if the model actually knows

1215
00:54:14,099 --> 00:54:18,180
what is really happening then you know

1216
00:54:18,180 --> 00:54:21,359
like if you were doing a um video game

1217
00:54:21,359 --> 00:54:23,940
and it and you had a agent with

1218
00:54:23,940 --> 00:54:26,220
supervisory access to the other players

1219
00:54:26,220 --> 00:54:28,319
inferences or even control their actions

1220
00:54:28,319 --> 00:54:30,359
yeah

1221
00:54:30,359 --> 00:54:32,880
that's not going to work in a tournament

1222
00:54:32,880 --> 00:54:35,160
but here with a particular partition we

1223
00:54:35,160 --> 00:54:36,540
can actually know the information

1224
00:54:36,540 --> 00:54:38,280
encapsulation

1225
00:54:38,280 --> 00:54:40,440
and Majid Benny explores that in terms

1226
00:54:40,440 --> 00:54:43,800
of the partial information encapsulation

1227
00:54:43,800 --> 00:54:45,660
so are we not introducing information to

1228
00:54:45,660 --> 00:54:48,240
model that would not be available

1229
00:54:48,240 --> 00:54:50,040
it's your restaurant

1230
00:54:50,040 --> 00:54:51,359
do whatever you got to do with the

1231
00:54:51,359 --> 00:54:53,819
recipe if you want a pedagogical example

1232
00:54:53,819 --> 00:54:55,559
that just

1233
00:54:55,559 --> 00:54:57,599
make some clean graphs and is very

1234
00:54:57,599 --> 00:54:59,339
straightforward and doesn't engage the

1235
00:54:59,339 --> 00:55:00,960
complexities of like sophisticated

1236
00:55:00,960 --> 00:55:03,780
cognitive structure learning

1237
00:55:03,780 --> 00:55:06,420
that model is not going to complain if

1238
00:55:06,420 --> 00:55:07,859
you want to do

1239
00:55:07,859 --> 00:55:10,020
strange Loop reflexive structure

1240
00:55:10,020 --> 00:55:12,720
modeling for ambiguous inputs of

1241
00:55:12,720 --> 00:55:15,180
unstructured multimodal data Etc

1242
00:55:15,180 --> 00:55:19,220
then that is your challenge

1243
00:55:20,460 --> 00:55:23,339
so for many people it's just in one

1244
00:55:23,339 --> 00:55:25,380
closing comment and many people this is

1245
00:55:25,380 --> 00:55:27,240
the first time they've been exposed to

1246
00:55:27,240 --> 00:55:29,220
statistical modeling and iterative

1247
00:55:29,220 --> 00:55:30,780
modeling formally

1248
00:55:30,780 --> 00:55:32,760
so that's why there are often questions

1249
00:55:32,760 --> 00:55:34,800
that are like less about active

1250
00:55:34,800 --> 00:55:35,819
inference

1251
00:55:35,819 --> 00:55:38,339
but sometimes crop up about basically

1252
00:55:38,339 --> 00:55:40,920
using statistical modeling overall which

1253
00:55:40,920 --> 00:55:42,660
is a great thing because these are

1254
00:55:42,660 --> 00:55:45,000
challenging and and areas with a lot of

1255
00:55:45,000 --> 00:55:48,180
implicit and tacit knowledge

1256
00:55:48,180 --> 00:55:50,220
so

1257
00:55:50,220 --> 00:55:53,160
thank you fellows

1258
00:55:53,160 --> 00:55:55,319
looking forward to

1259
00:55:55,319 --> 00:56:00,359
uh next discussions and into uh heading

1260
00:56:00,359 --> 00:56:03,859
into chapter seven

1261
00:56:03,900 --> 00:56:06,960
next week Ali maybe we'll do a um

1262
00:56:06,960 --> 00:56:09,660
maybe we'll do our DOT zero for chapter

1263
00:56:09,660 --> 00:56:12,000
seven and eight but not in a hurry but

1264
00:56:12,000 --> 00:56:13,920
we'll figure it out

1265
00:56:13,920 --> 00:56:15,359
sure

1266
00:56:15,359 --> 00:56:18,300
thank you so much thank you thank you

1267
00:56:18,300 --> 00:56:21,300
bye

