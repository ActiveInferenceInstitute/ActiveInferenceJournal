SPEAKER_00:
All right, welcome everyone.

It's 7-11-23.

We're in cohort three in our first discussion of chapter eight.

So we'll head over to chapter eight and look at some questions and comments.

But first, does anyone want to bring up any

Uh, just general or thoughts or reflections on chapter eight.

Um, Ali.


SPEAKER_02:
Uh, well, yes, um, actually chapter eight, um, as obviously the title suggests, uh, is, uh, kind of complimentary to, uh, chapter seven.

in terms of being the continuous time counterpart to the active inference formulation of discrete time.

As we saw previously in Chapter 4, we have both continuous time version and discrete time version of active inference employing different mathematical technologies and techniques.

But of course, they can be regarded as kind of formulating the same or at least similar formulation just using different mathematical techniques.

So namely, in discrete time case, we use matrices

to represent states, transitions, and so on.

But in continuous time, we use generalized coordinates in order to describe the states and not just

I mean discrete matrices for states, and also the starting point of formalizing active inference in continuous time also differs a bit, because in continuous time version we begin with

a version or a variant of Ido's stochastic equation by representing a flow plus random variable and then trying to somehow formulate the flows in terms of increasingly granular wave and

Yeah, tracing the trajectory through the state space, continuous time state space, employing that, I mean, Taylor expansions and other mathematical technologies and so on.


SPEAKER_00:
Great.

Olivier?


SPEAKER_01:
Yeah, what do you mean by granular here?


SPEAKER_02:
So I mean it is a stochastic equation is a very general equation describing any kind of sorry differential stochastic phenomenon.

In this case, we focus on a particular kinds of state space with particular kinds of behaviors.

So especially in active inference, we focus on active agents as opposed to

a more general sense of the term, such as, I mean, describing the whole behavior of a self-organizing system or even a simple system that can be basically described with a simple statistical physics.

So the focus of active inference, as I said, is

the agents that don't have empty set of active states.

But of course, it can also be generalized to other agents with empty active states.

But the Active Inference Framework or FEP don't have anything particularly interesting to say about those other agents


SPEAKER_00:
uh that's uh what i meant uh of granular we focus on a subset of the systems that can be described through it was a stochastic um equation okay cool thank you we can come back to some of these uh and also ali we will be keeping in mind that we need to make the videos for seven eight nine

or five sure yeah whatever you whatever you want um um okay anyone else want to just have any general thought or question raising their hand or or in the chat on on eight on and continuous time

really like that chapters two and three give us the kind of uh two ways to get there to act inf the low road and the high road the how and the why and now it's like we're in the city and now there's two restaurants or there's like two doors to the restaurant with the discrete and the continuous time so it's another dyad of chapters with seven and eight

and another juxtaposition that gives us parallax and helps us understand more about each of these two methods by highlighting, on one hand, situations where they seem to apply more naturally,

For example, the discrete time formulation seems to be a natural fit for discrete decision-making tasks, like which slot machine are you going to pull?

Whereas the continuous time model seems to be a more natural fit for analog perception control systems like proprioception and sensory motor behavior.

And Chapter 8 is also going to get us to hybrid nested models.

For example, a model with two layers where the lower level is continuous time and the higher level is discrete time.

So that kind of represents like a decision-making central nervous system that's dispatching commands to a continuous time sensory motor body.

And that is also explored in the sort of folk psychological active inference work, where you can kind of get the synthesis of continuous and discrete time models.

Anyone else want to add a comment on 8 before we start to look through it?


SPEAKER_03:
Yeah, I have a question.

Wait, I'll just

Maybe it's nicer if I have my video on.

Let's see.

I was wondering if there are any good resources on applications of continuous active inference, because up until now, I've worked on two projects with active inference, but only working with discrete state-based models.

And I was wondering if there is any good papers on continuous active inference and its sort of representative application.


SPEAKER_00:
they in the citations yeah i think this table has some oh yeah yeah i'm so sorry for asking a redundant question no no it's it's it's all good these are not all the applications but let's just look at the topics that they have raised so the bird song is definitely a classic um single singing bird and uh two singing birds

Ocular motor behavior, reflex behavior, more eye behavior, different cognitive states, more eye behavior.

This is one of the few papers on mirror neurons.

Attention.

I believe this is attention being modeled in a slightly different approach.

Um, this is a continuous time attentional framework, whereas the, um, Sanved Smith paper uses, um, discrete time attention, hybrid and self-organizing, but, um,

There's other citations, and i'm sure you could come up with many more things, and also like one of the kind of model annotation tasks that I think would be super helpful in terms of meta analysis would be like for each paper.

How could?

How can we describe?

How can we describe the active inference models they used?

So then we could just like filter a table.

Where are the discrete time models?

Where are the continuous time models?

Where are the nested models?

Where are the models that use empirical data?

Yeah.

Yeah.


SPEAKER_03:
Yeah.

Thank you for the overview.


SPEAKER_00:
Cool.

Okay.

So from the figures,

Figure 4.3, recall that the discrete time and the continuous time generative models have some structural similarities.

At the same time, they have important differences.

And also partially this is signaled with a difference in notation so like hidden states are going to be reflected with X in continuous time not s observables are reflected with why not oh.

causal interventions in the system are reflected in v not pi and really the most important difference is that whereas in the discrete time you have past present and future explicit state predictions in the continuous time setting you're using the generalized coordinates of motion where x is the hidden state at a given time

And X prime is the derivative of the hidden state, how it's changing through time.

So the B matrix, which is the transition matrix in discrete time, describing how states go from one time step to another, how the hidden states change, here is describing kind of like the derivative or the integration function, because it's describing how derivatives are linked to each other.

and what causes do in the model is they influence how derivatives change through time here's the um Edo calculus type um equations that Ali spoke to first we have

observable states are a function g of hidden states that's the flow and some stochastic noise term about y sensor noise and then x dot rate of change in x is a function of the hidden state at the current time and the causal forces on the system at that time plus a fluctuation term on x

Action is absent in equation 8.1.

This is because action is part of the generative process, not the generative model.

Pending our definitions of generative process and generative model.

The generative model only deals with those variables directly influenced by states external to a Markov blanket.

What do you think about this, Ali?


SPEAKER_02:
Well, yeah, actually, this is one of the points that was kind of brought up in the discussion with Maxwell, because as we know, generative model, I mean, if we consider FEP as this kind of general framework or theoretical framework,

to describe the behavior of the things, quote-unquote things, that persist through time, we can theoretically describe the generative model as containing any kinds of different situations, both containing activist states, or in other words, with activist states, and also with empty set of activist states.

Uh, so, uh, but, uh, as I, uh, said before, um, I believe active inference, uh, is more concerned with the situations that have non-empty set of activist states.

In other words, they have the ability to perform or to undertake, um, or, uh, to put, uh, to put it in, um, uh, more.

rigorous terms to kind of engage in a causal intervention with the environment, both in terms of updating the generative model and also effectuating some changes in the environment that can fit better with their

generative models.

So yeah, that's, I mean, what's meant here by directly influenced by states external to a Markov blanket means the states from the environment that can dynamically act upon the Markov blanket in order to make it more suitable or more adapted to the environment


SPEAKER_00:
through the generation of the market blanket i'm sorry the generative model and also minimizing the free energy yeah thank you it it looks like the difference here between 8.1 and 8.2 other than the bolding of the um equations is like v a static variable

is replaced by a controllable action parameter.

So now a specific implementation of equations 8.1 and 8.2 are going to be described.

So now, Ali, go for it.


SPEAKER_02:
Sorry, I forgot to mention something.

There was a debate on Twitter a couple of days ago about whether or not FEP can be applied to inert objects such as rocks, which is one of the debates that's been going on for a long time now.

You see, theoretically, it can be applied to any kinds of object, even to a inert rock.

But the only difference here is that inert rock has an empty set of active states.

That's it.

So if we take a non-empty set of active states, such as, I don't know, biological organisms or sentience agents and so on,

that would also employ the same kind of mathematical technologies but the only difference would be uh the existence of non-empty set of activist states sure i i would almost also say though that it's not that the active states are empty for an inert or a classical or a conservative object


SPEAKER_00:
that they're just trivial.

For example, just outputting a stationary action state.

Okay, so now they're going to give a specific example of what this pair of equations looks like.

And there's a point attractor

So this is going to be kind of moving us towards a continuous time system where there's a fixed attracting point, where if the actuator is below the fixed point, it's going to go up.

And if it's above the fixed point, it's going to go down.

And so this is going to be the kind of model that's used for eye saccades and for like elbow movement and things like that.

generative process is specified.

The hidden state is basically just passed through and the action is basically just passed through.

V is in the generative model.

V. U is in the generative process.

this connects to the equilibrium point hypothesis again it relates to a proprioceptive prediction about expected proprioceptive feedback coming from for example the limbs or the eyes this enables action to be prediction fulfillment

rather than, for example, reward maximization or utility maximization directly.

This relates to an extensive discussion on forwards and inverse modeling and interactionism and instructionism.

And some of that was explored in the skillful performance live stream.

Now they're going to move from this fixed point attractor into a spring attractor.

So now there's going to be an oscillatory attraction with dampening.

And that is going to require not just a spring,

scalar description of the attractive point, but we're going to start moving into this generalized coordinate way of thinking where we're going to be tracking kind of a vector of position and velocity.

And generalized coordinates, you can think of they keep going, like you could have position, velocity, acceleration, and so on.

So they kind of just work through that and say, yeah, you could also just write down the generative model where not just the elbow wants to be at 90 degrees and it's at 80, so it extends out to 90, but now you could have one where it goes and it overshoots 90 and then dampens back to 90.

And you could continue to develop these generalized coordinate-based systems.

Or you could think about the fixed points being attractors in a generalized coordinate space.

this discussion connects us to consideration of dynamical systems more broadly

fixed point attractor the spring attractor those were both dynamical systems and so now we're kind of fully in this dynamical systems setting which is natural for continuous time discussions and stochastic differential equations and all of this some topics that are certainly relevant for the discrete time setting but are more naturally addressed in continuous time

So in chapter five, we looked at this spinal cord cross section, and it was discussed as a simple proprioceptive input descending fixed point prediction

And then the residual was being passed on, the error signal was being passed forward to engage bodily movement.

So like if the proprioceptive data and the descending prediction were identical, there's no discrepancy, no motion occurs.

Whereas when there is a discrepancy between the expectation of proprioception and the incoming proprioception, this triggers a discrepancy and that discrepancy is resolved through movement.

So now that example from chapter five is being re-approached using the formalisms and the continuous time setting that we see in chapter eight.

Here we have a box on precision, attention, and sensory attenuation.

This is going to cover several different topics.

First, precision and attention are described as synonymous.

That's a pretty general claim.

However, one can think of as something that's being attended to highly.

is giving precise inputs and therefore is salient it's relevant it updates the model a lot if something is not being attended to in the limit that is equivalent to something that has zero precision it's infinitely ambiguous and therefore it doesn't update the model because it's not salient it's not relevant so it's kind of a general point about precision and attention

And one way that this plays out in relationship to motor control and some extremely interesting and unique explanations and predictions arising about precision attention and motor control in a predictive processing setting is this topic of sensory attenuation in motor generation.

So attenuation means diminishment.

And in some ways, attenuation, even though it sounds like basically the same word, is like the opposite of attention.

It just means it's like dis-attention or like alleviation of attention.

Does anyone want to like give a thought or explanation about what is the role of sensory attenuation in motor initiation and fulfillment?

Okay, I'll just give a thought on it.

So, if one is sitting down in a chair, the accurate belief to have is I am sitting down.

How, without invoking goals or explicit predictions about future time points,

How do we go from having an accurate belief I am sitting down to having an accurate belief that I am standing up?

I mean, the transition between those two steps, basically two things have to happen.

You have to change your mind.

thinking you're sitting down to thinking that you're standing up and you have to change the world.

You actually have to go from sitting down to standing up, that's action.

And so how does that happen?

Well, the issue is that if you're sitting down and you have a high precision, accurate belief, I am sitting down, and then you change or you try to change your expectation or your preference or your fixed point or your set point to standing up,

It's going to be like, no, that's unlikely.

All of our proprioceptive evidence is telling us that we're sitting down.

And so in that way, like the body would kind of be like an anchor and it would pull the cognitive belief back to, no, actually we're sitting down.

So if you just try to be like, we're sitting down and we know that we're sitting down and you just try to say, okay, now we're standing up, but the body's still sitting down.

If you have high attention on the proprioceptive inputs, then that cognitive belief gets dragged back.

And so you end up not initiating motor movements.

And so the resolution of this challenge is you update your belief.

I am standing up while you're sitting down.

Meanwhile, you engage in sensory attenuation.

You release the attention on the proprioceptive input.

And during that alleviation of attention to proprioceptive input,

you can think about the distribution on proprioceptive inputs to actually include standing up.

So now that is a more viable hypothesis.

The posterior probability becomes higher.

then action selection can be engaged to fulfill that expectation about standing up.

And so voila, now you're standing up and you think you're standing up, and then you can re-engage precision so that now you can have that precise belief that you're standing up, whereas previously you had a precise belief that you were sitting down.

And the key step was kind of like you're driving on the road,

it's like attention is like the gas.

You pull off the gas, make the turn, and then re-engage the gas.

And another example of this is in our eye saccades.

When our gaze is fixed, we have high precision on our visual input.

When we do an eye saccade, transiently, it suppresses visual precision.

And that's why during saccades, which happens several times a second,

we don't see like a big blur because it's almost like a blink.

Now it's not your eyelids coming over your eyes, but it's actually an attentional blink when you do a saccade, which is why the highly dynamic input during a saccade is suppressed or not attended to

so that we end up having the generative experience of fixed high precision vision, and then we blink into another fixed high precision visual input with a suppression of attention during the saccade.

And different pathologies can be understood as challenges associated with initiating movements,

or with terminating movement or with continuing movement and so different different um pathologies have been associated with this so certain motor dyskinesias where somebody may have a challenge initiating a movement but once they are moving like they walk normally or on the other hand there are um different motor pathologies

Any thoughts or comments on this?

This is kind of an interesting topic.

Even just outside of this embodied or technical setting, just like this idea that in order for the possible to be actualized,

There has to be a relaxation on the actual to enable the movement to a different space.

And here's the cyclical precision.

And this has been associated heavily with differences in the neurophysiology of vision.

Okay.

Again, just raise your hand or write anything in the chat if you want.

A classic dynamical systems model from ecology is going to be introduced.

And this is the Locke-Volterra dynamics.

Sometimes it's called predator-prey dynamics, or especially in the context of neural Darwinism dynamics,

and dynamical systems in neuroscience.

Sometimes this is called winnerless competition, because as you can see here,

this ecological example like it's not that the herbivores are trying to defeat the plants in fact they have a relationship where if the herbivores are transiently succeeding in decreasing the plant numbers then they will have this like demographic collapse and so this is the winnerless competition is you have dynamical oscillations and so this describes ecological dynamics but also it describes activity um patterns amongst brain regions like two um

systems that have an oscillatory repressive consequence on each other a repressilator that will have this kind of winnerless competition dynamic so um this is just a classic dynamical system and in the spm textbook the lock of volterra is used to describe these winnerless competitions neural darwinist dynamics um

these three traces plant herbivore and carnivore you can think of them as like in this graph like a plot happening through time or you could imagine a cube with like the x the y and the z axis being plant herbivore carnivore dynamics and so this system can be represented as three traces along the x-axis here or you can imagine it as like a movement in a three-dimensional cube

And so if it was spending a lot of time up in this corner, you can think about what that would mean and so on.

And then on that cube, just like the GÃ¶del, Escher, Bach book cover, you can project from the three-dimensional cube down to a two-dimension.

And that would be like putting a camera on one side of the cube and just taking a picture.

So here we're looking at the herbivore by plant.

um projection of the cube and it has this kind of oscillatory cycle here it's approximately periodic because there's this dampening but you could design a system that has different behaviors now the lock of Volterra is going to be applied in a few different active inference contexts

The first is in the eye blink conditioning.

And so this is conditioned stimulus and unconditioned stimulus.

So this is kind of like a classical Skinnerian behaviorist paradigm of behavior, action, blinking associated with conditioned and unconditioned stimuli.

using this dynamical systems framework.

Whereas in the discrete time, we'd have, okay, time step one, do we get this stimulus or that stimulus or neither?

And then what do we do and how do we make the decision?

And then the next time step, this happens.

All of that is happening in this kind of continuous unfolding winnerless competition setting.

So that's the first example on the left side.

That's the blink.

The unconditioned stimulus produces a blink that's a learned association.

And the right example, which also listen to Thomas Parr's Bookstream 2.1 when he gives a little more of the history, or we...

We have a few in the Thomas Parr 227 page.

He gave some great history here talking about how the generalized filtering and continuous state space approach was early on being the most developed.

People started wanting to get sequential dynamics, so they developed the kind of model that we're going to see right here.

Like here, this is like sequential writing dynamics.

Clearly, there's a repetitive motif that's being repeated.

sequentially but then the desire to explicitly sequentially encode beliefs and to engage in explicit planning as inference motivated the work in discrete state space models where planning as inference is a more natural fit

of course by the end of the chapter we're going to be kind of merging these two different kinds of models together but here's an example of Locke-Volterra dynamical systems dynamics in a handwriting setting so it's kind of like a sequence of points that are being targeted and driven through sequentially by hand

short box 8.2 on learning in continuous models slightly technical note perhaps um Sanjeev's textbook will clarify some of these pieces um however using Laplace approximation so a quadratic approximator

We're able to use integrals on continuous distributions to specify the attention weighted evidence great gradients, but this is just kind of little encapsulated box.

Ali.


SPEAKER_02:
I just wanted to mention a small typo in box 8.2.

So the third line in the second block of equations should be minus ds mu theta.

So yeah, minus in front of d, I suppose, should be added.


SPEAKER_00:
Thank you.

Good.

Glad that we have this one.

Thank you.

All right.

Now we're going to move into a second class.

So just like the first, we saw like the simple point attractor and then the Hooke's law attractor, spring.

Now in this dynamical setting, we're going to have kind of two levels of sophistication of dynamical systems models.

The first one was the generalized Locke-Volterra system.

The second one is the Lorenz system, or Lorenz attractor, which is a canonical example of a complex or of a chaotic system.

And it's a super fascinating story with Lorenz and his work in weather prediction.

And that was, of course, one of the most important moments of the complexity and the computational chaos research of the last hundred years.

This is also explored a lot more in live stream 34 on Markov blankets and stochastic chaos, I believe, where solitary and coupled Lorenz attractors are modeled.

It's a super fascinating work.

um generalized synchrony is going to be unpacked in the setting of birdsong which was a friston frith paper maybe one slightly earlier than this but the 2015 is kind of the classic citation and this is seen as a kind of exemplar of multi-agent inference problems when they are quote singing from the same hymn sheet as Carl always says

And so the birdsong attractor is going to leverage the Lorenz attractor described above, and there's going to be two Lorenz attractors coupled through communication reflecting birdsong.

And some details of those attractors are going to be described and simulated.

And the kind of big takeaway here is that the generalized synchrony is accomplished through communication.

So here we have the first and the second bird on the X and on the Y axis.

We can think about this line, Y equals X line, as being a manifold.

that would reflect perfect synchrony so if you could describe movement on this two-dimensional plane by appealing only to movement along a single line you would have reduced a two-dimensional setting into a one-dimensional setting and that's like a dimensional reduction and that's called a statistical manifold

Before learning, while there is overall adherence towards this Y equals X line, we see that after learning, the manifold, the behavior is tightened immensely around the manifold that represents the learning to synchronize between these two birds.

the two birds joint trajectories confined to an almost one-dimensional subspace indicating synchronization also it's kind of a cool nod to fractal dimensions like if it was perfectly on this line you'd only need one dimension if it was purely covering the whole 2D space you would need two dimensions so then you can think about this as being slightly higher than one dimensional

this connects back to the earlier attention and attenuation and this alternation of listening and singing it's kind of like now this is not all communicative settings and there's more work on communications but it's kind of a fun Paradigm we're basically like the bird expects there to be singing both birds expect there to be singing it's like you know

Insert your favorite cultural singing moment.

If you're going to sing, my preferences will be fulfilled through perception.

And if I'm going to sing, my preferences are going to be fulfilled through action.

Fulfilling my preferences through action is going to reduce my sensory attention to perception until eventually it's like, whoa, I'm not sure what's happening.

I'm going to stop singing.

and then in that silence the other birds can go oh my preferences were being fulfilled by listening attentively I'm not hearing it anymore I better reduce this discrepancy by taking action because listening harder isn't going to help because that's not going to make the song happen and so that's singing from the same hymn sheet like Carl says um and it relates to um

Joint, you know, shared regimes of expectation and joint perception, action, and multi-agent systems.

And the generalized synchrony doesn't mean lockstep.

Generalized synchrony doesn't mean both birds are singing identically and then they're both silent.

Generalized synchrony means that there's mutual information between these two coupled systems and

such that there is an information geometric manifold that represents their joint movement.

But it doesn't have to be a lockstep, same behavior at the same time.

Turn-taking is also an example of generalized synchrony.

8.5 gets to hybrid, discrete, and continuous models.

So here we see a nested model.

There's a line that's supposed to be between pi and g, obviously.

And in the top level, we see the discrete time generative model.

T minus one, T and T plus one.

We see all the letters that we know and love from chapter seven, A, B, D. But then within each time step of the higher order model, we see the continuous time model with the generalized coordinates of motion.

And so this was unpacked in Livestream 46, active inference does not contradict folk psychology, where the top level was called decision active inference, or DAI, and the bottom was called motor active inference, or MAI, because somebody can think about the discrete decision-making on the top can be like, am I going to raise my left hand or raise my right hand?

that's a discrete decision there's no need to um make it an uh um analog but then with the descending command that it's going to be okay raise my right hand then we can engage that whole motor fixed point apparatus of the continuous time model

whether we do it with a Lock of Volterra or Lorenz Attractor or the Hook's Law or just a simple point attractor.

So all the kind of continuous time tools that we saw earlier in the chapter,

we can deploy in the setting of a nested model with a discrete time decision maker on top and a continuous time on the bottom, which may articulate better with the seemingly analog nature of perception and action in the last mile.

This is a little bit of machinery that helps map between the discrete selection of target locations into the continuous setting where those target locations can be realized.

And an example of this is using an isocate.

where there's a discrete movement of a target location followed by a continuous time trajectory of the eye circuiting to that.

Box 8.3, again, raises just some sort of super curt analysis of a sophisticated topic, which is a Gaussian mixture model.

And like we know the calcium we love the calcium and we know we contractively optimize it and so on and so on, it does an incredible job of approximating distributions that have a central mass tendency.

a lot of statistical tools work incredibly for Gaussian, but of course not all Gaussians are going to describe given complex distributions.

But the good news, whether you approach this from a Gaussian mixture model or a hierarchical Gaussian filter or just generalized filtering, is that it turns out that through composition of Gaussians, you can build complex distributions

that have almost arbitrary characteristics so that's kind of a way to get like the attractability of gaussians but also for example make a bimodal distribution or a trimodal distribution this engages the challenge of Bayesian model reduction Bayesian model selection structure learning

table 8.1 closes with some um discussion of continuous time model Advances and that ends the relatively short but pretty dense chapter eight does anyone yeah Olivier


SPEAKER_01:
Yeah, I have a question.

I'm not sure I can formulate it well, but the thing is, when we think in terms of discrete time model, usually we think in terms of regular time steps.

And with this mixed continuous and discrete time model, is that possible to model a behavior in continuous time and to have the discrete time step to arrive at different, I would say, after different duration within the continuous time model?

When you reach a criterion in the continuous time model, you get to a next step at the top level.


SPEAKER_00:
Okay, just one thought on that.

Are you referring to a model where the discrete time steps are actually inhomogeneous?


SPEAKER_01:
Yeah, so no regular in time.

So for example, you will imagine a search task happening in continuous time and you reach a criterion at some point.

And depending on the steps, you can reach that earlier or later.

But when you reach this criterion, you jump at the top level.

So you make your decision and you jump at the top level.


SPEAKER_00:
yes so one interesting question is how could that logic be encoded into the generative model another way to view that setting would be you'd have a generative model um that does have like a real um regular um chronology but then you're modeling samples potentially like plus on distributed samples

from a regular continuous or discrete timeline so the Delta T of the samples is not necessarily homogeneous but the underlying substrate of the model would be so observations are not coming in regularly actions are potentially not being taken regularly but there is a clock that has regularity

That would be the sort of sampling-based approach to dealing with this time heterogeneity.

Then the other approach would be somehow to figure out through composition of discrete and or continuous models, can you encode a temporal logic when this condition is met, then this happens?

Yeah, yeah, yeah.

yeah yeah it's an interesting area and i mean this this uh folk psychological or just nested um hybrid model i mean this is just a hint and so it would be really awesome i think to see the the the matlab or the other code implementations

So we could do, okay, now let's do, this is a two by two matrix.

And this one is that, um, spring attractor.

Okay.

Now this is a three by three matrix and this one's the lock of Volterra.

I think that if we could, um, unroll those systems a little bit, um, more clearly, I, I think we'd have some really, um, illustrative dynamics.


UNKNOWN:
Okay.


SPEAKER_00:
Awesome.

Well, next week, we will return for a second discussion on Chapter 8.

We'll just go straight to the questions, and Ali, I think we'll be ready to do our Chapter 8 review when the time is right.

Sure, yeah.

All right.

Thank you all.

See you next time.


SPEAKER_03:
Thank you.


SPEAKER_00:
Goodbye.

Thank you.