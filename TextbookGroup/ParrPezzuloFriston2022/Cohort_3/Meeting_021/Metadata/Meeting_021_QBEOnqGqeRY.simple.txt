SPEAKER_04:
hi everyone it's cohort three and august first we're in our second discussion on chapter nine so if either of you would like before we jump into some specific questions are are there any general comments or any other topics that that people want to address

Otherwise, we will probably look through some answers and curate and improve some discourse.


SPEAKER_02:
Yeah, nothing for me.

All right.

I added some questions at the end, but we can go through the other stuff first.


SPEAKER_04:
Perfect.

Okay.

And Esmail, thank you for your question.

um what does this text mean about epistemic value so so it let me know if it's okay to modify the question to what what is epistemic value if if that's what your question was or let me know okay let us uh


SPEAKER_02:
you added some of the new questions at the at the bottom here Neil yeah that's right all right it's it's one sort of big question really um which one let's do well um in a non-meta days in so that one and then all right awesome yeah all right let's start here all right so

so so my take on on the chapter is it's it's trying to fit active inference into a a framework of of what science is um the the new thing I think that the big idea for me

was the meta Bayesian inference, which I understand this trying to make a, so someone's trying to make inferences about something that has itself got beliefs.

So maybe I don't know if I got that.

Right.

Um,

so so the first part of that question is is what does what does this have chapter have to contribute when that isn't the case if if we're just trying to use it to understand something that can be modeled um and then uh the second part is would

the chapter talks about is thinking about it in the context of brains, so psychiatry, but it presumably can be applied to anything in which the system that's being modelled can in any way be said to be of having beliefs

And I've mentioned Dennett's intentional stance there, where we're not necessarily believing, we don't think there's any sentience there.

So you could think of, we could talk about a thermostat thinking it's too hot.

without actually saying anything about any sort of mental processes going on there.

So it seems to me that the Metabasian aspect could potentially be saying, could potentially be useful for this, to beyond psychiatry, psychology,

Ben Whiteman- yeah so so then skipping over the third question was question is, what is this actually being applied in outside of neuroscience and psychology, as it seems, particularly.

Ben Whiteman- What would be useful to be, including it in behavioral economics.


SPEAKER_00:
Ben Whiteman- and Ben Whiteman- And maybe in systems engineering I don't know.


SPEAKER_04:
Great, great questions.

We'll start with the first one.

Okay, I see.

The second one was here.

Also welcome, Molly.


SPEAKER_03:
Okay.


SPEAKER_04:
Thanks.

And

I put the link, but this upload of the textbook, it's a good starting point.

All right.

So the first thing that... Let's just start by recalling the meta-Bayesian...

approach in nine nine point one so i think you summarized it perfectly neil we're doing bayesian inference about something that has beliefs so it the aboutness of the subjective model is the environment which may be the laboratory or or the niche

um and and thus the aboutness of the scientific model is the rat in the maze which has an a model that has an aboutness of the maze so that's this kind of like nested or meta bayesian approach we're using bayesian approaches from the outside

But then when we get to the good stuff, it is also a Bayesian model with an aboutness of an environment.

So I think this is a great way to put it, trying to make inferences about something that has beliefs or trying to make inference about something that does inference.

So your first question was, what does the chapter contribute when that is not the case?

Here, I believe we can return to our favorite path integrals paper and point to the continuum where on the sophisticated end of the spectrum, we have a situation like that in this figure.

where here's us as scientists, here at the blanket states are the solid line.

And then we're inferring a cognitive model through, for example, structure learning or some other a priori constraints.

We're inferring the cognitive model that's looking back onto the outside.

So the Metabasian stance is required in the cognitive on cognitive setting.

Just to be clear that to model another cognitive entity outside of the Metabasian stance, I'm not exactly sure what the alternative approach would be.

But you asked, what do we get when this is not the case?

you could model an inert system accordingly here.

For example, maybe here it's a light switch or something, and it doesn't have any action selection of its own, or it's a passive inference object.

So what do we gain?

We gain continuity with those cases, thus grounding cognitive sciences.

we can discuss this more but but that to me feels like the big home run is continuity along this continuum of of uh sophistication from absolutely inert particles on through arbitrarily complex cognitive entities

So it's not to say that it's going to be uniquely explanatory or of predictive value.

It may be like getting out an extra apparatus that you don't necessarily need, which would be the same thing as saying you could have just started with a simpler model because you're bringing out this big apparatus that's just condensing down to a simpler model.

So do any of you think of any other advantages that are gained?


SPEAKER_01:
Steve Tombson, As you went to where is that figure from.

Steve Tombson, figure to that paper.

Steve Tombson, Right okay.


SPEAKER_04:
So it's creating a scaffolding for the observational encounter that allows us to have system of interest along this continuity.

It's absolutely required here.

You might be able to get away with a simpler perspective in a simpler setting.

but this is the most expressive way that we can dial it up arbitrarily um complicated and also dial it back down like maybe this just is a single node in this computational graph it just observations get passed in there's a single node and then it gets passed out but this frame but but the the scientists lab doesn't have to change whether they're studying the metronome

um or or the bird and i i i agree that it's important to connect it to these uh like to the standard stages the scientific process ali or anyone else want to just add more


SPEAKER_03:
If I may add some comments about, of course, I didn't hear the question from the beginning, but from what I heard, you see, I believe it's essential to always clarify our concepts and definitions in terms of what we're really talking about when we talk about

Uh, agency on one hand, um, I don't know.

cognition or consciousness or whatever, because all of these terms, they have lots of baggage coming along with them.

So we need to be careful what exactly we mean by agency or in this case, I want to emphasize more on agency because this is quite a controversial term because as we know,

at least in the mainstream biology, people don't want to bestow agency on inert objects or even some simple, quote-unquote, simple organism.

But on the other hand, there are some mechanical and naturalistic definitions of agency, the theory or from FEP and so on.

I don't know if you've seen this nice article by Philip Ball called, from a couple of months ago, Organisms as Agents of Evolution.

In this pretty much non-technical essay, he overviews some of the conceptions about agencies and he also

I think, yeah, he has mentioned FEP in quite an extensive detail, I mean, comparatively.

But the case here, I mean, Ball's case is that we still don't know how to model agency as naturalistically as, I don't know, some physical phenomenon.

of course there are possibilities to model agencies as purely physical trajectories through these or

probably is to think about and see.

But the point here I want to make is that this is not exactly what we always think when we try to trace the path of a physical system through a state space.

We don't usually think of, I don't know, a simple particle or an inert object as following a path of

or following a goal-directed motion, right?

But on the other hand, there was this recent interesting interview in Sean Carroll's Mindscape podcast with David Krakauer.

And it was quite an interesting podcast because for the first time I heard a definition of complex systems as something that can be directly applied to FEP.

Namely, he defined complex systems or even the complexity science as

uh the study of teleonomic matter right so obviously what he meant by teleonomic matter uh doesn't have anything to do with uh uh some extra material or the and or


SPEAKER_01:
uh these but what uh come along in asians see through from that the draw some we need


SPEAKER_04:
uh the essential sorry Ali it just it just it's through suspect 80. uh sorry just okay can you hear me now yeah just just back up to um telionomic systems it's not not an extra material cause it's what


SPEAKER_03:
Okay.

So, yeah, it allows for the definition of agency throughout a whole spectrum that encompasses both inert objects or simple organisms up to the most complex phenomenon we know of in the whole universe, namely the human brain.

uh so this defining characteristic of complex systems as a teleonomic matter i believe uh is a is quite an essential move here because uh this is this can be seen as some of the underlying assertions of fep as well because

um the same mathematical technology i mean if we take bayesian mechanics as uh something that can be applied both to a simple physical phenomena and to um

i don't know consciousness or a cognition or agency or whatever then we need to define some uh some essential parameter that can be um put in put onto and put onto continuous spectrum without um on the one hand limiting too much

and on the other without including or limiting too much.

These recent moves in both complexity science and some of the recent advances in biology seems interestingly convergent with some of the assertions of FEP.

And I hope in the future some interesting unifying perspectives can be gleaned from seeing these kinds of interconnectedness and interrelationship between all of these theories, and specifically by looking at how we define agency in the most naturalistically and mechanistic way possible.


SPEAKER_04:
nice great it's like saying like we can't have a framework that has a continuity of ice and liquid and gaseous water it's like well it's not saying that there's not face differences

um but we want to have something that that like you said doesn't over include or under include and doesn't appeal to extra material or extra systemic factors except credibly and then if we if we um create that uh measure

then uh we can we can um talk about the agency of um different systems okay so i hope but but you know in your question you wrote other than unifying ideas into a common framework so maybe one response is little other than that but that's the big deal


SPEAKER_02:
Um, yeah, I mean, it's, it's, so it's a big deal for me.

It's, yeah, it's, it's, it's a beautiful, uh, it fits in, you know, a nice bigger picture.

Um, and I, yeah, I feel as though there's, you know, a lot of, a lot of things that could come out of, of that framework thinking about it, but it's, it's not apparent to me what that is, uh, at the moment.


SPEAKER_04:
Yeah, I mean, even just the concept that some people may walk around feeling and projecting that there's a difference in kind, incommensurability difference between systems that compute or don't, or cognitive systems or not, agentic systems or not, adaptive systems or not, sentient systems or not.

And it's like, well, again, we can have ice and liquid.

So it's not like we're neutering our capacity to distinguish systems.

Literally the opposite.

Proponents, I'm not even saying anyone specifically is, but just allegorically, proponents of incommensurability are actually stymieing their own capacity to compare scientifically.

they may be able to perform qualitative comparison, which is totally legitimate.

It is what it is, though.

But you cannot have quantitative comparison.

It may not be as simple, simple, simple as like a scalar number.

And I think that's kind of the open space with category theory and different kinds of equality and sameness.

but we need to at least have the art articulations and and the framework just to scaffold these kinds of systems otherwise we're just begging for there to be a different framework i mean if this was the periodic table would we want a different framework for different particles or i i i'm sure we can think of other ways of where this brings a lot of unity um

Okay, next question that you added.

Metabasian inference maybe can be applied to understanding any system of interest in which the subject can be considered having beliefs and intentions.

Dan, it's intentional stance.

Yeah, including into the even, you have a thermostat, but not just a thermostat.

Here is a thermostat coupled to an actuator unit because you said it can act.

But you could say that, yeah, yeah, yeah, a heating system.

But this intentional stance goes even below where most of the intentional stance people would probably feel comfortable and say, like, that rock just wants to be there.

And so it's like, but that's not intention.

It's like, that's what I'm saying.

But either you're going to grant there to be a continuum of intentionality.

And then I think then whether that's realism, is there really a continuum of intentionality?

Take it or leave it.

But can we approach systems with a continuum of intentionality?

Absolutely.

And that at least topologically has to have a structure like this.

You could have a different model architecture inside of here.

But that model architecture doesn't even have to be what we would consider necessarily a cognitive model.

Why couldn't this be biological variables?

And here's the health record.

And then here's the outcomes of health.

So this is even more general than cognitive modeling per se, because rather it's just describing the informational relationship between the modeler and the models up to and including systems where the models


SPEAKER_02:
has an aboutness of the laboratory or of the communication itself I was interested in what I was saying what's the relationship between agency and belief because you could have that subjective model that has that could be said to have beliefs

But it might not have agency, it might just be medical records, for example, but those medical records could be said to embody a belief that the patient has whatever diagnosis.


SPEAKER_04:
I am sure both agency and belief have copious literature and semantics.

Just off-the-cuff belief having more to do with what we would associate with the perceptual sense-making side of active inference and agency having to do more with the...

policy selection aspects like and policy selection entailing a sentient or adaptive policy selection entailing some belief architecture you could have something that exhibits a lot of agency and has like minimal beliefs like it's just like flailing or babbling or thrashing potentially so it's it's exerting

efficacy which under some definitions of agency may qualify with limited belief potentially no justified true belief whereas in their kind of highest marriage we're talking about like beliefs about action planning as inference those kinds of areas


SPEAKER_02:
ACM Conference 29th, John Wilkinson, Agency implies action on the environment, I think, and, as you say, policies it's it's it's performing some action in a way that can then help it learn, as opposed to you can have something that just forms beliefs and that's just something doing passive inference.


SPEAKER_04:
ACM Conference 29th, John Wilkinson, um.

Is ACT-INF model-based analysis actually being applied

in areas outside of neuropsychopathy or psychopathology, behavioral economics, systems engineering.

So definitely we can bring in some papers by Henriksen on cognitive economics.

Now, not all cognitive economics is utilizing active inference, but some are.

this name it sounds familiar and i believe it may be using active inference little little but some um industrial systems engineering yes uh well robotics another area um industrial systems engineering

Ranging from the most logistical and operational like what versus and others are involved in.

On through like what Stephen Fox is involved in with.

social organization so here's this then here we have the.

Stephen Fox john boyk angle with socio technical systems.

um, Niagara ecology.

In fact, I, I, I'm gonna, I'm gonna go to another, um, this, this is a little, little peep into our, uh, into our, our open source, uh, ecosystems document.

Um, which of course, uh, uh, Ali and, and Neil, you're, you're welcome to be authors on just, just, uh, email me if you, if you don't have the information that you feel like you need.

Um,

This is our citation train.

I think we went from we go from Yeah, literally, citation 799.

So it's kind of a monster, cognitive neuroscience and cognitive philosophy, artificial intelligence and AI explainability, robotics, human health, clinical psychiatry, social developmental psychology, social sciences, mathematical physics, physics of life, consciousness studies, phenomenology, evolutionary ecology and development,

cyber and cognitive security mapping and modeling of information ecosystems ontology modeling and maintenance rhetorical analysis logistics and business intelligence theoretical and applied biology and ecology project management team science collective behavior military science if there are some other domains um we will literally add them in fact we probably should add um uh economics

I know that we cite some, though, but also I'll just write social sciences and economics.

Any thoughts on this list?

Or like what other domains would be exciting for you to see?


SPEAKER_02:
No, that's pretty good.


SPEAKER_04:
I'm just going to copy it into the chat, too.

That's too long.

It's too long.

I mean, but just I'm going to copy the...

the document there but but yeah of course we're the textbook group so i'm not gonna go down the rabbit hole with the open source ecosystems but um that's that's exactly what we've been thinking about and and also we didn't even like cite digital gaia versus and so on so um or thought forge or any of our other um colleagues in industry um

And that's kind of the idea with the ecosystem.

We have people who are working more on the theory and then it's not always so visible necessarily where the applications are happening.

But I think we can do a lot of work to improve like the discoverability.

And connect, you know, use the ontology to connect across settings and cases.

There's just a lot.

But again, another conversation.

All right.

All right.

Esmail asked, what is epistemic value?

Let's see where it comes up in chapter nine.

Otherwise, we can look to an earlier chapter as well.

Yeah.

Epistemic value is primarily discussed in chapter seven.

Ali, what's your take on epistemic value?

And Niels, let's just get some, looking from chapter nine, looking back to seven, what is epistemic value?


SPEAKER_03:
Okay, so epistemic value is one of the key terminology of active inference, which is also in parallel with, I mean, from

practical value because you see, sometimes when an agent tries to infer its best course of action within an environment, it's not always a trade-off between, I mean,

the thing that, or it's not a necessary trade-off between survival and also the explore-exploit phenomena.

So for example, in some of the cases, the agent needs to somehow gather information about the environment, and it actually prefers gathering the information about the environment and the

the situation in which it resides in order to take more suitable actions for it to preserve its persistence through time, or in other words, its survival.

So epistemic value is what

gives a kind of numerical value to this kind of exploring the environment and also how we can use this numerical value in a trade-off between what we gain informationally about the environment

and the course of actions we take through within that environment so sometimes it acts as a central essential goal or purpose for the agent to increase its epistemic value through its information seeking actions rather than just

uh changing the environment uh in order to better fit its generative model nice thank you neil what's your take oh you're muted if you're adding anything or or all


SPEAKER_02:
Sorry, I was thinking when I was talking, I think of the things like exploration, exploitation.

So in reinforcement learning, it's very much exploration is for direct impact on the policy.

But we as humans go through life collecting information and storing it with likely no future use of it.

So you could say we're epistemic.

We do epistemic gathering of stuff that has no apparent epistemic value.

But circumstances might change and it might become valuable.

um so I don't know if there's a distinction to be made between well yeah if bringing in this idea of a value of knowledge yeah that that's a very interesting point about like the pure value of information


SPEAKER_04:
at least with respect to its role in decision-making, like if we were thinking about people using social media applications and so on, or, or, or, or who knows what else, maybe even

just the the desire to to flip every rock over see if there's an ant colony underneath there like there are um uh expected free energy being composed of pragmatic and epistemic value

gives us extreme flexibility to model a diversity of settings and cases.

So this is summarized in figure 2.6.

On the left of the main equation, we have pragmatic value.

which is how surprising observations are with respect to preferences and on the right side we have the larger epistemic value which is a KL divergence hence can be attractive attractably optimized in the variational Bayesian framework and um three

and five are identical, whereas two and four differ.

And specifically four brings in the observations as conditioned upon that specific policy being enumerated or calculated for expected free energy.

So under a policy where the observations are not expected to add any value,

in terms of reducing uncertainty, that policy is not assigned a high epistemic value.

It may have a high pragmatic value or not.

Whereas a sequence of observations that a given policy provides, which do cause a divergence from what is understood other than through that action being taken, that would be informative.

Again, that may have a positive or a detrimental pragmatic value.

Like, I wonder what would happen if I did this.

but that may threaten homeostasis.

But having epistemic and pragmatic value unified under a singular decision-making imperative allows us to find these previously unappreciated concepts to be under the umbrella of expected free energy, which we utilize for policy selection.

But most briefly, epistemic value is the value of incoming information in terms of observations about hidden states, reducing uncertainty about the hidden states.

Chapter seven deals with it more.

One interesting question maybe for the future is like, how is epistemic value treated differently in the discrete and in the continuous case?

Like, do you need explicit planning, discrete, potentially maybe even symbolized planning in order to truly engage with the counterfactual value of information?

So how do we think about the epistemic value of continuous activity?

Like groping, I mean, there might be a connection there to optimal grasp.

and groping around in a sort of continuous reflexive way to gain a grip on an object.

But with that load on pragmatic value where optimal grip is preferred and or with that load on epistemic value where how to achieve optimal grasp or what it would feel like to have optimal grasp is not known.

what are the two related reasons for fitting a computational model to observed behavior i believe this is an exact quote yeah let's uh

Okay.

Let's see how well perplexity.ai does.

It's going to have to context switch a little bit.

It's going to have to change languages, but we all do.

I think this is also which more and more synthetic intelligences are going to now it's asking us us a question.

Now, how would it evaluate all the questions that it could ask us?

Which one should ask?

Well, active inference.

will it know what question to ask what path of action is going to be most relevant okay here we go here we go first estimate parameters of interest in terms of computational phenotyping the second is to compare alternative hypotheses

So like to give an example from botany, the first one would be like, we have a bunch of strains of corn and we want to know which one has a different growth rate, computational phenotyping.

The second one would be like, does corn growth rate depend on just humidity or humidity and genotype or humidity, genotype and temperature?

So the first one is parameter estimation.

Computational phenotyping is parameter estimation.

And the second reason, the comparison of alternative hypotheses is model comparison.

The synthetic intelligence here has provided a different set of answers that aren't terrible.

And it can't necessarily answer perfectly from the textbook.

Anyways.

9.1.

Wow.

Ollie, this looks like somewhat of a little side journey.

I don't remember it, but it seems like it happens.

Foundationalists, coherentists, infinitists.

That's good to have.

Upvote that.

This goes beyond proof of principle simulations we have seen in previous chapters instead exploits active inference and answering scientific questions, what does that mean.

This is a pretty concise answer previous chapters generated the model.

and played around with it.

EG used it to generate.

plausible data.

Now we are building the machinery to take in real data and fit that to data and fit that data to a model to slash with a model to uses on page 174.

Matt Robertson- map territory fallacy.

Matt Robertson- Not a full question, how does this work.

How does the work connect with the map territory fallacy in the context of Chapter 9 being about data analysis?

Does the work commit the map territory fallacy or rather help us articulate or evade being fallacious?

So let's think about Figure 9.1.

Some have criticized FEP by implying or suggesting it's guilty of making a fallacy that the map is the territory.

I mean, citations needed.

Also regarding generative process and generative model, we actually spoke with Maxwell in a scientific advisory board meeting.

It was really funny.

And of course, illuminating of high epistemic value.

Here's what he added this morning.

I, of course, pointed to Ali's question during the innerscreen stream.

And he said, there's one generative model.

It's the system level description.

It's our model of the whole environment agent system.

It is the entire causal connective tissue.

It's a joint density of the real model of the dependencies of the system.

If the generative model contains a Markov blanket via sparsity, and it does,

Then you get an additional density, the variational density, where internal states parameterize with an aboutness of external states.

And those internal states will look like they are tracking external things in the sense of the generalized synchrony.

Generative process refers to the dynamics that give rise to observations that are hard coded in.

And so he analogized that to the Newton's laws.

It is not the case that the generative model is a model of the generative process.

Philosophers are comfortable with approaches like the Helmholtz and the Boltzmann machine, and from there arose the distinction between the recognition and the generative density, the tailored to densities.

But that is not the sense in which generative model is being used here.

So just kind of a fun update to an ongoing discussion.

and Carl was there and endorsed and approved well time flies time flies like an arrow fruit flies like a banana as the famous quote said we are at the end of chapter nine now

In the coming weeks, we will be heading into chapter 10.

Then after two weeks on the text and concept heavy chapter 10, we will be closing this cohort.

So it's very exciting.

Presumably after this, we will...

wrap the transcripts of cohort one, two, and three, and publish those three together.

Anyone have any closing thoughts?


SPEAKER_02:
Good session.

And I suspect next time, chapter 10 looks good.


SPEAKER_04:
Awesome.

Yep.

Totally looking forward to it.

All right.

Thank you, fellas.

Till next time.

Thanks.


UNKNOWN:
Bye.