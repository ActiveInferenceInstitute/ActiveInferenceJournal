start	end	startTime	summary	headline	gist
560	229310	00:00	 chapter seven is basically the application of the first half of chapter four in terms of modeling discrete time situations. Chapter eight is on continuous time and hybrid modeling. Please upvote the questions that are interesting to you.	Discussion of chapter seven in cohort three focuses on discrete time modeling	Capella 7
231960	348800	03:51	 chapter seven begins with a quotation. What I cannot create, I do not understand. Richard Feigman, what do you think this means in the context of active inference? Anyone else want to add a comment on this?	You actually have to build the generative model to understand active inference	What I Cannot Understand About Active Inference (Chapter 7)
353340	581930	05:53	Michael: This choice speaks to the classical exploration exploitation dilemma and psychology. A dilemma that is resolved under active inference. Does anyone want to give a comment or a related question on how is active inference going to be approaching Explore exploit?	The exploration exploitation dilemma is resolved under active inference	Exploration Exploitation Dilemma under Active Inference
582080	708360	09:42	 chapter seven will focus on discrete time generative models. These are models where time clicks like one step at a time. Not a Markov decision process, just a hidden Markov model.	Chapter seven is concerned with examples of discrete time generative models	Generative Models 7, discrete time
710570	933984	11:50	The dilemma or unavoidable trade off is like over and under fitting perceptually. Action has a different set of challenges because it's related to selection of causal intervention in the world. The imperative for action is to have both epistemic value and pragmatic value.	You use the word compression to describe how you compress data	Inaction and the compression of the data
934102	1694230	15:34	How do you get flexible and rapid and adaptive switching between pragmatic oriented behavior and epistemic oriented behavior especially? How can that happen as new information are rolling in without necessarily retraining the model?	How do you get flexible and rapid switching between pragmatic and epistemic behavior	Exploring the epistemic and pragmatic behavior of humans
1696280	1847112	28:16	In a basic context of reinforcement learning, you will have somehow the first term within the second. It's kind of like converting everything to a pragmatic currency and then comparing the expected utility or the expected reward. This is one of the key topics and this is how policies are selected.	I find your last explanation really great and very enlightening	Reality 6, expected value based decision making
1847246	2325650	30:47	The approach of the resolution is putting different trajectories of behavior, action selection on a common footing. It unifies the epistemic and the pragmatic value of different actions. Changing the math to handle what is otherwise trivialized as external, too inconsequential to be attended to.	Having a unified imperative helps us adaptively approach dilemmas	Inactive Inference 6, The generative model
2329300	2529040	38:49	Chill 7.4 is going to go into a little bit more detail on this epistemic value of policies. The pragmatic value for a policy is identified with how close the expected observations are to the preferences. This is just showing what it looks like when the mouse undertakes an epistemic action.	The epistemic value of a policy is related to how close observations are	Epistemic Value of Policies 7.4
2531380	2733570	42:11	They move on to another of the settings that's been very well repeatedly studied in active inference which is the eye cicade setting the motion of the eyes. It's gaining information about the visual field and so that is why the epistemic visual search is a really useful intangible setting.	The epistemic visual search is about looking where there's light	Inactive Inference 6, The epistemic visual search
2734740	3301840	45:34	7.3 is a summary of a pretty advanced topic which is Bayesian model reduction and structure learning. Treating the question of what structure should the generative model have? Treating that question as a parametric inference problem. Here we see another difference with learning between active inference and many other machine learning approaches.	Bayesian model reduction and structure learning involves learning on different parameters	Inference with Bayesian Inference and Learning
3304840	3438202	55:04	Michael: Let's explore how the let's see how the the AI explanations did for chapter seven math explanations. Why would a high schooler be interested? Michael: Some of these look helpful. Some of them don't. So our work is to kind of refine that balance for ourselves.	Michael: Let's look at how AI explanations did for chapter seven math explanations	How the AI Explanations Did in Math
3438256	3453680	57:18	Well, next time, second discussion on chapter seven. So we'll return and look at what questions have been upvoted or asked. Farewell.	Next time we'll return with second discussion on chapter seven	Another Discussion on Chapter 7
