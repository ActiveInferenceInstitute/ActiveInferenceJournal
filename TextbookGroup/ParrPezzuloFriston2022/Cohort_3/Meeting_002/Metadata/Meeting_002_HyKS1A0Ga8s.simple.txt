SPEAKER_04:
all right hello everyone it's February 1st 2023 and we're in cohort three of the part all textbook group meeting number two we're having our first discussion on chapter one so would anybody like to just give any opening thoughts or comments

anything that they expected preferred enjoyed remembered about chapter one like what was something they were expecting and got or didn't or something that stuck with them about the experience of chapter one you can raise your hand or just go for it

How about, oh yes, please go for it, someone, or chance favors the prepared mind.


SPEAKER_10:
Go for it.

My sense was that it gave a kind of overview, but I spent my time looking at chapter two because it kind of gives this broad overview, but you feel the meat is in the rest of the book.

So I was bogged down in the maths of chapter two.


SPEAKER_04:
Awesome.

Yes, thank you.

And I'll copy your comment in, Jonathan.

Yes, rereading, taking another look and just letting it play out.

The first read and then coming back again and again and seeing more each time.

And a lot of the formalisms are not in chapter one.

So there is meat slash nutrition elsewhere.

but also there's interesting insights within the chapter, and I'm sure it sparked people to think about different things.

So anyone else, feel free to go for it.

Like just any sections of chapter one or any framings that you remembered or you highlighted or that stuck out to you.


SPEAKER_08:
I'm Jonathan Castle.

Welcome again.


SPEAKER_04:
In terms of what motivates or excites people about learning Act-Inf,

um they situate the question that actin seeks to address as how do living organisms persist while engaging in adaptive exchanges with their environment pretty interesting um is that the question that people thought active inference was going to seek to address do they think actin may address another question as well

okay as always just like feel free to raise your hand or write something in the chat or we'll just keep exploring along so i've not come across the neat scruffies dichotomy so that was a nice perspective let's look at that does anybody want to um summarize the neats and scruffies or give like what did they think neat scruffies means

or what was it doing at this part of the book?


SPEAKER_05:
I think my take on it, so I'm a physicist originally, and so looking at it from sort of building from the ground up, creating unified theories of things where everything is explainable within some framework versus those who try to look at the details and build from the details up to understand the phenomena.

That was kind of my perspective on it.


SPEAKER_02:
right Ali and then anyone else yeah well actually I recommend this um essay each time because I really like it um before in the book Andy Clark and his critics

There's a beautiful essay by Carl Fristel, namely Beyond the Desert Landscape, in which he explains in a very beautiful prose the difference between the low road and the high road.

and it goes into much further details about the significance of these two approaches and the pros and cons of which and also the importance of looking at the same phenomena call it intelligence, sentience or agency or whatever from these two perspectives and

What can we glean from looking at it from those two perspectives?

So I highly recommend reading this essay, which you can find a PDF for that essay on resources page as well.

Thanks.


SPEAKER_04:
Thank you.

High road.

Neat.

Unified imperatives.

scale free systems low road gets scruffy there's a lot of last miles in the low road because every generative model is different and they're complementary roads to meet in the middle with active kate or anyone else


SPEAKER_00:
This is still pertaining to the scruffies and needs.

It just occurred to me as I was both reading the introduction and now listening to this, how many of us here would be self-described needs and self-described scruffies?

I'm personally definitely a need.

I'm very much gravitating towards an underlying

common explanation for everything so which draws me to the active inference as such so i'm just wondering in the group of us where would we fall in that just out of curiosity awesome


SPEAKER_04:
very fun question yeah does anybody want to um dox themselves in terms of being a neat or a scruffy or some secret third thing and just share like why that resonates with them and how they might see learning active bolstering how they are or providing some other support blue and then anyone else


SPEAKER_01:
So definitely a scruffy.

And, you know, like, I mean, I strive towards neat, right?

Because I realize that like order is sometimes preferable.

I'm drawn to active inference because I really feel like it's,

a kind of a creative lens with which to view like everything so it's just another like set of rose-colored glasses that i put on um and like i also paint and do other things and so sometimes like i'll be staring at a person like i wonder how i would represent their nose in charcoal like so just it's like one of those things it's just a pair of glasses that i um put on but i do want to also

draw the connection between um what we were talking about yesterday on the book stream so i don't know who's watching that but um we had like you know they're talking about leadership styles and there's like the antagonistic neural network perspective where there are two um like

opposing not opposing maybe unifying neural networks one is called the task positive network and the other is the default mode network um with the task positive network being very like oriented at getting things done um it struck me as like a more orderly thing like maybe in in line with like the needs

And the direct or default mode network being more like, people centered and creativity focused.

And like, it's also like the difference between like, right and left brain.

I mean, we hear all these things all the time, right?

There's like the logical versus emotional.

And so perhaps like, it's maybe not neat or scruffy, but maybe it's both, right?

I don't know.


SPEAKER_04:
Thanks, Ali.

And then anyone else?


SPEAKER_02:
I also think that this distinction between needs and scruffies somehow relates to reductionism versus emergentism, which is pretty hot debate nowadays in the philosophy of science.

Well, of course, we know that science, for the most part, was basically a reductive endeavor and most scientists by large are reductivists.

But nowadays, especially from the mid-90s and the advent of the complexity theories and dynamical systems and so on, another viewpoint called emergentism

is actually emerging, no pun intended.

But there was always a debate between which one can provide the most insightful discussions in each particular situation.

But nowadays, some philosophers

kind of take the middle ground between those two, such as the contextual emergentism, which has been described in this recent book, Emergence in Context.

And I think active inference kind of maps

in my view, perfectly to this point of view of contextual emergentism.

And it's the best of two worlds.

In some sense, it's a purely reductive viewpoint.

And in another sense, it can be described as an emergentist viewpoint, at least the branch of emergentism called weak emergentism.


SPEAKER_04:
great lot of threads there and fun comments in the chat so maria i fail to see how one can work with details without some theory behind is it possible with active just anyone can give a thought um but i totally agree

implicitly always and explicitly often we do need some sort of combination and also it kind of maps just like even a little bit more loosely like industrial versus farmer's market or boutique and i think in the book um they uh basically say like

right before the neats and scruffies come okay here's the two perspectives one perspective is that just the incredible diversity of bio biological systems and neural processes each require a dedicated explanation so we're going to have a journal or a theory or an acronym or an undergraduate major for just serotonergic synapses

That's one option.

Every single phenomena is gonna have its own farmer's market bespoke scruffy theory.

That would lead to the proliferation of fields with little hope for unification.

The NEAT perspective is recognizing diverse manifestations

but asking whether those phenomena of broadly perception cognition and action from a lens of persistence and adaptation in life whether there might be some coherent explanations that again recognize the diversity of manifestations and then help us understand it Michael and then Jonathan

Maybe unmute or I can't see.

Michael or Jonathan?

I'm sorry.


SPEAKER_09:
Go ahead, Jonathan, I'll follow.


SPEAKER_05:
Just to say that perhaps this sort of dichotomy between a high road and a low road is kind of a matter of perspective in the sense that active inference itself, you know, it's a description of certain types of systems, but there are other types of systems out there.

And so if one wants to look at a higher level view, then in some sense, you know, active inference and the free energy principle are themselves the low road of some higher level principle.


SPEAKER_04:
um high level physics principle whatever it is you want very interesting roads all the way up slash down uh Michael


SPEAKER_09:
Yes, in this conversation, I may be saying that I thought I was neat and maybe I'm a scruffy.

I want to jump back for just a second to what is the key question.

I was troubled by that particular phrasing and I was like, what would I have possibly said?

And I'll put in the chat, but for me, the question is, how does life interrogate life?

There's this dance between poetry and plumbing, and that there's a lot of this conversation that is a plumbing conversation, and that part of the way consciousness makes sense and speaks is poetry, and that that's one of the things that

that is is the dance here of not not an either or which is a plumbing way of describing something but um opposites and paradoxes uh that are both um simultaneously considered and that um that uh consciousness supports um an active inference supports a way of both um

problem solving and contemplating mystery both concurrently and that this is part of the kind of uh there's something about not just the problem solving but the the the the being related in a way that is not um agentic if you will uh that I think is is missing in in in some of this


SPEAKER_04:
Thank you.

And that, that really ties in well with what blue brought up.

Like the task positive network is like the getting things done.

And the default mode is like the mind wandering and the receptivity.

And there's just an oscillation between those two modes in neural systems.

Nathan welcome.

And yes, please.

Anything you want to add?


SPEAKER_03:
Oh yeah.

So, I mean, you're talking about plumbing and poetry.

and you just were talking about TPN DM, where we're switching between these two modes of thinking.

And before that, we're talking about like higher and lower levels of, you know, thinking about this whole problem.

So are we making the claim that like active inference is like, are we making the claim that this is like the appropriate layer of abstraction to look at this problem?

Because when we usually look at,

big problems like this we have to pick a layer of abstraction where we're not losing like a lot of detail and resolution but um by going higher up in abstraction but obviously we don't want to get bogged down by the complexity of adding more detail and resolution very interesting question


SPEAKER_04:
guess just one very logistical way to address it is we're reading chapter one that's giving us an overview of the book then we're gonna have like a month

to talk about the low road to active inference and the high road to active inference and that's going to bring us to active inference itself so at least rhetorically or pedagogically

in terms of how to lay out an argument and or lay out an educational approach, it seems like the authors do believe that thinking about neats and scruffies and the resolution or the unification of them, not through homogenization, but by recognizing those two perspectives, that that is an important construct

in at the very least understanding and or learning actinf and then maybe that will bring us to the question of whether it's also the appropriate level of abstraction in application ali and then anyone else


SPEAKER_02:
Actually, I don't think we can associate a single level of abstraction to active inference framework, because as far as I understand it, active inference can equally be applied to multiple levels of abstractions and it's somehow

it's a scale-free framework or, in other words, a multiple-scale framework.

So even if we talk about temporal scales or even spatial scales, we can apply it to various scales and various levels of abstraction.

So, yeah, it's not...

a much more broader framework than we can associate with some other theories which specifically are limited to a particular level of abstraction.

We can see some of the examples for these different levels of abstractions, especially in the second part of the book.


SPEAKER_04:
awesome thanks so um let us turn to some of the questions that people prepared so does anyone see a question that they wrote that they would like to ask and we can explore or we'll go with the ones that people have uploaded

if anybody has like one that they wrote or just want to highlight let's go to it and also it's awesome like i saw a lot of people adding comments on the questions um all right let's just go to the most uploaded one bringing the question down into here so it's just a little more visible

okay on page six it refers to active inference as a normative framework there's some evaluative standard against which behavior can be scored which is free energy specifically the minimization of variational version thereof so just to plant the seed but we're gonna come back to it later

The two kinds of free energy that we're gonna be talking a lot about are variational and expected, but we're gonna come back to that.

For now, let's just think about free energy as a unified imperative for perception, cognition, and action.

Variational is in the present, and expected has to do with futures.

Then it refers to planning to achieve distal goals in humans.

Does this definition of normative mean that ACNF is agnostic about precisely what human's goal that might be?

One human may wish to save the world.

Another may wish to rule the world.

Both are essentially minimizing free energy.

I might be mixing up a few concepts here, but the gist is that ACNF models don't predict a socially normative course of action.

Would that be correct to say?

All right.

What would anybody like to add on normativity

of Act-Inf.

What does it mean to say that Act-Inf is a normative framework?

Does that refer to social norms or what kind of normativity is being described?


SPEAKER_02:
Ali, go for it.

I guess at the most fundamental level, the normativity admits the agent to be persist through time.

So one meaning of normativity can be seen from the most fundamental requirement of a system or

quote-unquote thing to actually exist or persist through time.

But of course, we can apply this concept onto some higher levels of conceptions, such as social normativity and so on.

But again, it applies to multiple levels of abstraction.

Thank you.

Jonathan?


SPEAKER_05:
Yeah, that sort of requirement for wanting to persist through time feels like an evolutionary imperative.

And there are other imperatives in terms of our sort of homeostatic set points and comfort and hunger and things like that, which then lead to the thing which has been evolutionarily sort of chosen through time.

So it feels like the two kind of have a, there's a balance between the two in terms of hierarchies of scales of time, I guess.


SPEAKER_04:
thank you thank you Scott for bringing that quote so I I often compare Act-Inf with linear regression

because they're both modeling frameworks that are quantitative.

And so sometimes it helps to be like, okay, is this statement true of linear regression?

And there's things that are true for both ACNF and linear regression.

Those like are just true of modeling or quantitative models.

And then there's things that are different between ACNF and linear regression.

Those are like the features that differentiate ACNF and linear regression.

So we might say that a linear regression

is normatively using this kind of imperative function, like to fit the least squares or the L2 norm.

And it's just saying this framework is gonna use this imperative to draw a straight line through points.

And kind of by analogy,

Ak-dimph is going to use an imperative.

Turns out it's a free energy functional that we're going to go into in the coming chapters.

It uses that unified imperative not to draw a straight line through points like a linear regression does, but to describe Bayes' optimal perception, cognition, and actions.

so it's doing something similar instead of having like one imperative for perception and then a different imperative for action it's a unified model of perception cognition and action that we can use this one imperative the free energy of a generative model and use that to guide the fine-tuning or the learning of that generative model

to return to the social question as we move forward no it is not like uh an ought it's not the is ought this is not an ethical framework just because there's a normative way to fit a linear aggression doesn't mean that it tells you what any given culture is going to be happy or upset or benefit from or anything like that

there's probably a lot there's other ways to say it but just the short answer is this is correct active is not in the kernel of active is not describing social normativity in the sense of like peer pressure or like what people will look at you weirdly if you do okay

next question living living organisms can only maintain their bodily Integrity by exerting adaptive control over the action perception Loop which they frame that adaptive control as the question that active seeks to address do generative models represent and thereby predict bodily Integrity

Or do these models predict the causes of their sensory inputs and via minimizing the prediction error, they achieve maintaining their bodily integrity without explicitly predicting bodily integrity?

How to best talk about what a generative model is predicting?

Great questions.

What does anyone want to add?

Well, I think one short answer, and then Ali, is that generative models fit whatever parameters they have.

So you could imagine making a generative model where there's like a hidden state that is bodily integrity, and then there's observations that help reduce uncertainty about bodily integrity.

So in that case, we'd say, yes, the generative model represents bodily integrity as a hidden state,

and therefore tries to do inference using that.

Or do these models predict the causes of their sensory input and via minimizing prediction error, they achieve maintaining their bodily integrity?

That's actually like another way to say something similar, which is that the hidden states are the latent causes of sensory observations.

And so by minimizing the prediction error with respect to observations, it is possible to achieve maintenance or homeostasis of those latent states, even though they are explicitly predicted or represented, but they're not observed.

Ali, anyone else?


SPEAKER_02:
Well, actually, in active inference, all the agents, or more technically, all the particular systems, all the particles, sorry, are kind of doing this kind of inference-making tasks in order to self-evidence.

And actually, this task of self-evidencing is the fundamental...

task that an agent needs to undertake in order to keep its homeostasis into action or doing that kind of homeostasis through allostasis because both of those terms are obviously related, one of which needs more active and more active

mediation to undertake the homeostasis task.

But in any case, the concept of self-evidencing exactly refers to this kind of integrity, maintaining

task that any inference-making agent needs to undertake to persist through time.

So I think this is the fundamental requirement of any agent modeled in Active Inference Framework.


SPEAKER_04:
Awesome.

Thank you.

And once we start into the subsequent chapters and we look at how preference

is used in active inference we'll have some awesome discussions like do we expect homeostatic temperatures or do we prefer them it's like on one hand i prefer it's what i like on the other hand it's what i expect because i wouldn't be surprised to find myself there so how does that play out um everett yes did you hear me okay uh-huh


SPEAKER_06:
Okay, so a good answer also depends on which level of the hierarchy you are talking.

So at the lowest of hierarchy, there's sensory stimuli that are being predicted.

And the more you move up, the more abstract models or predictions are taking place.

So higher up the hierarchy, I could have predictions about bodily integrity or predictions about my continuing existence.

And then lower down the hierarchy, you could have some physiological variable that's predicted, like nociception in the case of pain.

And then you can add all.


SPEAKER_04:
Awesome.

Okay, is that all?

Yes.

Okay, yes, totally agree.

Often people talk about like nested models or hierarchical models, multi-scale models.

And that's one of the strengths of taking, of at least bringing some neatness into play is like by using a level of neatness that lets us generalize across different cognitive phenomena, like what we might just conversationally call low level or high level,

it allows those models to be composed in an integrated way.

So in this textbook, there's not gonna be an emphasis on nested modeling.

It's gonna focus on like the kernel of active inference, which is like the single agent at the single level.

But then there's all of these elaborations, which are active areas of research and development

outside of the textbook.

Yes, thank you, Jana.

Could you clarify low and high level?


SPEAKER_06:
If I think about the cortical hierarchy, there's, I think, six layers.

And if I read the literature correctly, they talk about

different kind of predictions depending on which kind of cortical layer you are talking about.

And the active inference models are built in a way that also fits the anatomy of the brain.

So they talk about computational anatomy fitting the active inference models


SPEAKER_04:
Thank you.

Jonathan, and then Gianluigi.


SPEAKER_05:
Yeah, I think that's right.

I think another perspective is simply that low level is, for instance, the pure sensory inputs themselves.

We may be making predictions about a site that something that will come to our eyes.

Higher level might be some sort of more abstract.

idea of the thing that it is outside in the world that is giving us the sensory input.

And so there's a sort of hierarchy of time scales and physical scales that we might take in moment to moment and build up a bigger and bigger picture.


SPEAKER_04:
awesome so just to restate that and then Gianluigi the low level this is just one spatial metaphor is that the pure sensory inputs themselves like the low level is where the rubber hits the road and then the higher levels are abstract or synthesized representations about what are giving rise to those sensory data and that is also called a cause in the statistical sense Gianluigi and then


SPEAKER_08:
Yeah, I also believe that it really depends on how your generative model is set up.

I mean, a high level can also be a pretty straightforward sensory inference, so to say, between one observation and one hidden state.

and not something absolutely abstract or at least that's what i saw like i i agree that classically it has been like those cortical layers or the the lower levels are the most most um low level sensory uh inputs so so so to say and the higher levels are the more abstract ones but i do believe that they also uh that the distinction might also not be that uh strict


SPEAKER_04:
All right, and then effort.

Then there's a few more points to make.


SPEAKER_06:
Yeah, and this question about what is predicted also,

I think it also has to be seen from this instrumentalist and realist discussion.

Is it the modeler that is building an active influence model and tries to infer what the organism at whatever level is predicting?

And that's what I wonder.

You also read in the literature a lot of times that they talk with the terms as if, it looks as if the organism is minimizing this or that or predicting this or that.

So this as if language also makes me wonder, how do we know what an organism is predicting?


SPEAKER_04:
awesome this instrumentalist and realist and map territory we're going to return to a lot um on i want to bring a few more points on the nested models and then we'll return to the questions since um like nested modeling it's kind of like the active kernel is like one lego brick with like a bottom and a top part and then like it is very amenable and as soon as we have the legos we want to stack and put them lateral and build them

But the multi-level Lego structure is predicated on what that one is, at least understanding what it is.

So in Livestream 28 on Sandved Smith's paper, this is just one example of a nested model with three layers where the quote low level is sensory.

And then there's a level of attention and meta-awareness.

So there's not just one way to do nested models.

There's many nested models that one can make, but it's an example of how something that is like raw and exteroceptive can be seen as a low-level model nested within

other models that are quote higher but again that's just like a that's just like a cultural visual graphical layout there's no reason why it couldn't be from left to right or top to bottom or inside to out so it's like it's about what it is not just the spatial layout but that's what it is on the six levels of the brain so here's from um live stream 43 which was with maria um

yes there are six anatomical layers in parts of the mammal brain six layers that are defined like histologically like the tissues look different but it's really important to remember that is not the same thing as it's not six nested legos and we're gonna get to this more when we get to chapter five which is all about um the neuroscience

but here are those six layers so this is not six full nested models like here's three full nested models that are truly nested whereas the six histological layers actually are part of an integrated inference scheme it's not six nested models

But a lot of times people think, oh, multi-level models, hierarchical Bayesian modeling, hierarchical predictive coding architectures, six layers in the brain, six nested models.

That's not true, but that's a very common framing.

So what is the generative model predicting?

Whatever it is set up to predict.

These are maps, not territories.

Okay, I think, okay, great.

There was some awesome discourse here.

So can someone explain to me why the inferential problem is intractable?

Page eight.

It has to do with the marginal likelihood P of Y in the Bayes theorem.

So does anyone here who is in this discussion like want to summarize it or what their understanding of what is the tractability issue and how are we going to approach that?


SPEAKER_05:
Yeah, so the example I gave there was that if you see a flash of light, you want to know what's the probability that it is a particular thing, given that you've had some observation of the world.

But in order to do that, you need to sum up, in this case,

all of the different things that could have given rise to that particular flash of lights.

And that in itself is intractable.

So there are various terms within the Bayes equation, which in order to do it properly in a complex world would mean summing over an infinite number of things.

That was my thought there.


SPEAKER_04:
Great.

Great.

So

There's a lot of ways to talk about this, but you pointed to that several pieces are required to go from a stimuli to inference about a causal state of the world, like whether it was truly a tiger giving rise to the stimuli or whether it's something different.

you'd want to know a few things you'd want to know the probability of given that it's a tiger what is the probability it would look like that flash you saw but then also you want to know how likely is that flash from other possible hidden causes and so that is like the probability of the flash given that it's a tiger or given it's a chipmunk given it's all these other things

and that can be an open-ended sum so thanks for that great answer it is in essence an infinite sum of possible things and you'd have to know the probability to be able to say what you should really think

There's many notes.


SPEAKER_00:
Effort, go for it.


SPEAKER_06:
I also found in the book that they say for complex models, there may be many types of hidden states that all need marginalizing out, making the problem computationally intractable.

I thought you were saying that before.

But I also found that the marginalization operation might require analytically intractable integrals.

And I don't understand what that means.

Is it different than the answer you gave before?


SPEAKER_04:
It's very related.

So in a discrete setting, we are talking about sums.

Like sums, you know, 1, 2, 3, 4, 5.

Sum over 1, 2, 3, 4, 5.

In a continuous setting, we are talking about integrals.

So if something is being summed over a discrete range, that is analogous to it having an integral over a continuous range.

And so they're both beset with the same challenges of large and interacting spaces.

And then just one kind of note, because on a Bayesian and marginalization, this is like actually the margins of a piece of paper.

That's what it's referring to when there's kind of like actuarial tables back when statistics was done on spreadsheets.

So it's like if you have states of the world and then observations in a grid.

If each observation mapped onto one hidden state of the world, then you would just have like only on the diagonal would you have any numbers.

going to come back to these topics but then you can imagine that you might be interested in marginalizing a given row like summing across that row so saying okay how likely is this across all columns and that's called marginalization so why is it intractable


SPEAKER_06:
because it might just be requiring computational resources that are unrealistic or implausible i think uh this there was actually the the reason the whole reason for a variational free energy quantity uh this this marginal likelihood thing is that correct


SPEAKER_04:
yes it is it is free energy is going to help bound our surprise let's but let's come right to it so this one kind of goes in multiple different uh directions the central imperative is that organisms maintain their existence high road avoid surprising states

How can one explain different self harms or perceived self harms?

This is kind of like the social norms question in that we're not always going to get a neat answer from a human scale complex nested system where the generative model hasn't been stated.

this if that makes sense so like given a generative model one could describe how driving off a cliff is the is the generative model's most likely course of action like if the generative model is I always drive straight I'm likely to find myself driving straight that generative model may drive off a cliff

but to kind of not mention the generative model and just say well how is it possible that surprise is bounded by driving off cliffs is not a full um it's not fully making contact with what the surprise is because surprise is with respect to a generative model

so whether it's the extremely complex cases of humans or whether we're talking about something different then surprise and the bounding of surprise through free energy is with respect to a generative model everything is always in respect to generative model

There's no surprise minimization, free energy minimization outside of a generative model.

So surprise minimization, free energy minimization, those are qualities of a generative model.

Just like the least squares regression, the sum of squares is with respect to a linear regression model,

surprise bounding free energy is with respect to an active inference generative model and once the generative model is specified then one may find different actions as avoiding surprising states including addiction and different states that people have studied that we're going to come to but we need to fill out what generative model we're talking about before applying the imperative jonathan and then everett


SPEAKER_05:
Within that generative model, there are also the different desired states that the organism might want to be in.

And those desired states, they're not normative in the sociological sense.

We may have different desired states.

And so for some people, that may be very different from what another person wants and may lead to one of these outcomes.

Thank you.


SPEAKER_04:
An effort.


SPEAKER_06:
Yes, this example with suicide is also related to the high roads where the imperative is to maintain our existence, minimizing surprise necessary for survival.

so if I commit suicide then I would violate that core imperative but we do know that people commit suicide so how can we explain that through this framework and it also has to do with if I predict bodily integrity but for example I am someone who experiences chronic pain because that's the best explanation for my

prediction error that I have, will there be an update of the model that says, okay, now I'm not predicting any bodily integrity anymore, but threats to my bodily integrity.

And would that also then lead to eventually committing suicide?

Or just some thoughts, but I can't make any sense of this.


SPEAKER_04:
Thanks.

okay just in our final minutes to touch on one or two more all these discussions people can continue to engage and and develop add resources ask more questions like it doesn't stop here this is like the tip of the iceberg of us wanting to develop the state on these questions because they're things that we're all asking there's things that other people are going to be curious about and we can have

great answers and complex discourse and multiple perspectives here.

We're just going to do one more and then we'll end two minutes before the hour.

And again, these are also things we're going to return to in future weeks.

This is just our first week on chapter one.

Next week, we're going to do another chapter one session and we'll come through more questions, the second half of the questions on chapter one and anything else that people add and upvote.

So just in the last three minutes.

can someone explain why exploration and exploitation are automatically balanced through policy selection in active inference page 10 what does it mean to say both exploration exploitation are balanced jana thank you i will save this chat


SPEAKER_07:
Well, in my understanding, it would be that you only explore as much as necessary to exploit.

So exploration is an effort somehow, and you want to minimize this to get the maximum of exploitation.

That's my understanding, approximately.


SPEAKER_04:
Thanks.

One very hands-on way to explore this question is in Model Stream 7.2 from just a few days ago.

In the video description of Model Stream 7.2, there is

notebook that can be run in your browser without any more tweaking and it is going to have an agent that has the choice to do a few different things they can play either of two different slot machines one of which is like better than the other or they can get a hint and so um to have an imbalanced strategy

would be like to kind of zone into the first slot machine you go to and stay there.

To have a overly imbalanced strategy towards exploration that might look like just getting the hint every time, or just kind of moving around really rapidly in the space, but not ever like latching onto ones that have high utility.

And then a balanced strategy

which there's not just one single answer to this, but a balanced strategy in a given situation is an action policy selection.

It's a strategy or tactics that navigate or manage the tensions of the requirements between exploration and exploitation.

sometimes that's modeled what's called a multi-armed bandit where there's like a bunch of slot machines you want to win the most money but you don't know how good each of the slot machines are so you got to explore a little bit to find out like how good they are but then you want to spend most of your time on the best ones

to spend time proportional to how good they are but of course if you only spend time on what you perceive as the best things might be changing and so you might end up not being on the best machine soon so thank you everybody for joining we'll come back next week for the second discussion on chapter one and um please add comments and questions and discourse in the time till then but thanks everybody for the awesome discussion

Farewell.


SPEAKER_02:
Thanks everyone.