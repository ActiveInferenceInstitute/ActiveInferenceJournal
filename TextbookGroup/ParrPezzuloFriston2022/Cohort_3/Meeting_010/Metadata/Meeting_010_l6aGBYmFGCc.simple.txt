SPEAKER_00:
hello thanks everyone for joining it's March 29th 2023 we're in cohort 3 having our first discussion on chapter 5. so before we go into any questions or look at the text does anyone want to just provide any general reflection or thought on chapter 5 or just the first half of the book up till now

just unmute and go for it if you want to.

Okay.

Let's look to chapter five and then, um,

i'm sure people have many thoughts as we get going any general thoughts on five or on this opening quotation about plants and animals


SPEAKER_03:
Well, there are plants that move and there does seem to be some thought that there are interconnections between plants, that they have something that, while it is not an animal central nervous system, there are patterns within the architecture that have


SPEAKER_00:
similar functions and it's the timeline over which they operate is much longer I very much agree with that here's my PhD advisor Deborah and a paper from 1989 describing the plant behavior idea and then

I believe a more closer to our area is this 2017 paper on plant predictive processing with Friston.

So agreed.

This quote, it's a little bit of like timescale dependent.

It's just kind of like a, it's a fun first pass, but isn't that interesting that it's like,

actually not so stark or the plants that do respond like the venus fly catchers and everything but here in this chapter we're going to be focused on the mammalian nervous system and body not the morphology of the nervous system or like morphological development

okay yeah anyone please just raise your hand or or write something otherwise let's just go through chapter five and just look at some potentially interesting pieces this is an interesting concept that not every variable depends on every other variable and that's sparsity and so there's sparsity in the brain

are many connections but of the space of the possible it's quite sparse and similarly in statistical models the sparser they are the easier they are to fit doesn't mean that it's going to be better and a lot of modeling is about finding the trade-off point between like model complexity and model accuracy because if you enable every edge it's going to be a really laborious calculation

if you restrict edges that are actually important you might have a very rapidly fit model however it might not reflect some of the important true causal relationships amongst variables so that comes up in different ways let us take a step back from the technical material of chapter four everyone breathes a sigh

turn our attention to the process theories accompanying active inference here they point to the difference between a principle free energy principle which is that systems are described by their dynamics on free energy landscapes and that persistence is associated with reduction of free energy to the extent that agency is exerted

and a process theory about how any given system may actually implement those kinds of dynamics so a principle cannot be falsified and this is at the root of a lot of questions and commentary around like the falsification capacity for the free energy principle and the simplest thing as far as i've seen is neither can a linear regression be falsified

It's just not within the space of being confirmed or rejected or falsified by anything at all.

It's just a proposed model framework as a principle.

Now, any given linear regression, which is a specific hypothesis about how that principle of linear regression or the principle of the L2 norm might be implemented, that given linear model might be adequate or not.

more adequate or totally inadequate or however, but it is more subject and answerable to empirical data.

So free energy principle is not really in the space or the game of falsification or not, nor does it even engage with empirical data directly.

Whereas proposed and manifest models

are directly addressing empirical data and empirical data speak to their validity so none of the above chapters that we've read could be falsified by any observation in the world or they're just kind of theoretical whereas the models that are going to start to be shown in chapter 5

are going to be structural and computational hypotheses about models of the nervous system, and thus they're more addressable and answerable to real data.

Jonathan?


SPEAKER_01:
Would it be reasonable to say that it may or may not be true that the free energy principle is applicable to certain real world systems, but not that the principle itself is wrong, just that it's not applicable?


SPEAKER_00:
What does anyone want to add on that?

Ali, go for it.


SPEAKER_04:
Actually, I came across a situation that kind of contradicts some of the claims of Active Imprints or FEP about their scope of applicability recently.

I'm not sure if you're familiar with Stephan Ferner's, some of Stephan Ferner's recent work, but basically he claims that complex systems include a set of systems that are only non-Markovian and non-ergotic systems.

But on the other hand, we have this notion, we have this requirement for

any system that is to be modeled in active inference framework to be ergodic and Markovian systems.

Although in some recent literature, they have dropped this requirement for the system to be ergodic.

But again, I believe a kind of local ergodicity needs to be present in order for the system to be modeled in FEP or active inference framework.

So as far as I know,

The scope of applicability is

at least so far, not strictly defined or, let's say, it's not something that can be restricted in a definitional way, but there are degrees of applicabilities.

So, for instance, in Dalton Sack-DeVadevel's weak blankets paper,

He has this notion of degrees of blanketedness that helps us to distinguish between the systems that have effective markup blankets and the otherwise linear systems that doesn't contain any kind of

effective blanketedness.

So briefly, he claims that for higher dimensional and complex systems, we can apply these Bayesian mechanical framework, but for

linear systems although theoretically it is applicable for those systems as well but it wouldn't result in an interesting an interesting behavior because it would basically be a kind of trivial thing to apply these frameworks for a simple or simple in in the sense of being linear systems


SPEAKER_00:
Thank you, Olli, very deep answer.

Michael?


SPEAKER_02:
Yeah, I also read in some context that this would explain how a system can come into the steady state, but it cannot explain how it comes out, what triggers the system to go out of that steady state.

But this is constantly observed, right?

I mean, we are not always in a steady state, but also jump into other states.

So I don't know whether this is an implication exactly from what Ali said.

But I said that's why this free energy principle could not be applied to living systems even, I think.


SPEAKER_00:
yes thank you well a lot of perspectives let's like focus that kind of question on on the material of chapter five which is the mammalian nervous system and behavior so with copious citations and empirical evidence they're going to be talking about places where the fep and active have been applied

And so this is going to be much more empirical and tangible and anatomical than previous chapters.

So whereas the generative model proposed in chapter four and the high and the low road by which that generative model is reached in chapters three and two were kind of in principle, here we're going to see a lot more about what it looks like in practice

that's going to mean that it's in reference to a specific kind of system like specific brain regions and it's also going to mean that it's answerable to empirical data and that it's been published according to professional communication channels signifying that it had unique explanation or predictive power

So a lot of these are like fascinating questions about the hard and soft limits of applicability of different methods.

And we'll see in chapter five, how that plays out in practice.

So again, just write anything or raise your hand if you'd like to explore.

So this chapter is not intended as the final word on process theories.

It's simply the interpretation that seems most consistent with the currently available evidence and length constraints on the book.

Nor is our aim to endorse a specific process theory, but to illustrate how the ideas in the previous chapters may be put to work.

so if we were reading an anatomy textbook or a psychology textbook it would be like this is how it is the elbow is connected to this and this concept does this but the way that we're going to be looking at the coming examples are like representative of how models are constructed that do describe real systems of interest um

Jana, I'll bring your question into here and feel free to continue this or add any more information on what type of generalist tools might help.

Coda is certainly one generalist tool that helps.

And then there's many statistical approaches that are more technical.

So right now we're going to be approaching this just from the kind of like learning side, but the way that these models are implemented, the code is generally available.

And so those also provide some specific tools.

And there may be other tools also, but at least tools that we use for learning help us with Bayesian mechanics in our engagement with it.

And then the tools that actually implement those statistical models

then there may also be other tools as well which would be interesting to explore they describe the layout of the chapter which is going to be first focusing on one of the most well-studied neural systems which is the mammalian cortex architecture they're then going to expand into the um reflex arc

the spinal cord and that will help us look at the continuous time models of perception and action and then in section 5.4 talking about decision making all right so in the end of chapter four there were some representations that looked like this and this is showing two

related views on a generative model.

On the left is a hierarchical predictive processing model where there are, just as a graphical convention, top-down predictions and bottom-up sensory data.

And so this is represented as kind of like a skyscraper, just without reference to time.

The tilde means through time.

this in practice becomes unrolled through these message passing architectures and we talked a little bit about that last week here they're going to return to that idea so the skyscraper the kinds of ways in which hierarchical predictive processing architectures can be visualized or represented with a base graph

those schemes are going to be associated with stereotyped circuitry and there's like also coming from a long history of taking pictures of the brain and understanding of what the circuitry is in terms of synoptic connectivity and so on

they're going to describe a little bit about this cortical column and as an insect neuroscientist it's fun to read all this because i just think well this is one way it could be but certainly all of these anatomical details they don't even necessarily have to be that way for mammals but they definitely don't have to be that way outside of mammals

connecting it to the reality of what is empirically measured helps ground the theory and so figure 5.1 is going to be a side by side of the anatomy of the cortical layers

Has this mapping been done for the C. elegans?

The synaptic connectivity of the whatever it is, 302 neurons in the C. elegans for the most part has been completed.

So synaptic connectivity maps do exist.


SPEAKER_01:
I mean the relationship between that map and the message passing that we see here, the mapping between what we're seeing on the left and what we're seeing in the middle on the right.


SPEAKER_00:
It would be awesome.

As far as I know, there's not an explicit...

nematode or even fruit fly or any other type of mapping but I think that's very exciting work because there's like a whole nematode simulation and there are with brain and body and biomechanics and there are similar projects for the drosophila fly so the bulk of the work

of these authors friston at all and and building on the legacy of spm most of the work has been done in human neuroanatomy and so not many people were considering beyond like the human neuroimaging case until more recently so these six layers of the cortex are defined histologically

So just from a tissue definition, they have some morphological differences and they also have like some gene expression and protein expression differences.

And these edges represent physical structural connections amongst different regions.

It's juxtaposed and these are kind of the outputs, inputs and outputs

with these, the thalamus and so on, sending inputs into layer four, and then this kind of resonance processing happening within a columnar unit, and then the outputs of this layer five cell going on to the decision-making areas that are going to be discussed in section 5.4.

And it's juxtaposed in kind of a visual rhetorical style

with statistical representations about what these populations of cells might be doing so that is helping connect the semantics of these variables like this one is an error on this and this one's a variance estimator on that and this one's getting inputs about this

All those kinds of things that we want to talk about what a statistical variable is doing and mapping that onto empirically observed patterns of neuroanatomy.

Now, this is going to be kind of coarse grained.

This columnar unit, which is repeated thousands of times in the mammalian cortex, is going to be abstracted

the deep to the superficial so this is that layer um one two three four five six superficial towards the surface of the brain and then the deeper regions of the cortex so that is going to be like one unit in this figure 5.2 they have simplified what's happening within a cortical region

highlight what is happening amongst cortical regions and so there's processing happening within a column and also columns can serve as bottom up and top down for each other so they're interacting laterally from an anatomical perspective

However, in this representation, the one on the right is like sending top-down predictions to the one on the left.

And then bottom-up prediction errors or sensory inputs are coming up to the one on the right.

So this is showing that predictive processing architectures can be implemented laterally across cortical columns.

and this is at the root of a lot of current computational modeling efforts just we'll leave it there and we'll return to it


SPEAKER_03:
Can I ask, are they the Taylor series?

Is that what that is, the ascending prediction error?

I was trying to understand this Taylor series, and it seemed to be like a way of creating a set of predictions from a function.

So whenever I looked at this, I thought,


SPEAKER_00:
that's the taylor series am i wrong in that it it's a great insight and i think uh as with with many of these things it's like if you if you needed and want it to be you can connect those locations so for example here's figure 4.3 and um in the discrete time case we were making explicit predictions about the past present and future

the continuous time case rather than making explicit predictions about the past present and future we have the x hidden state variable first derivative second derivative and so on on x so that is like the taylor series coefficients now one could propose what if what this cortical column was doing was x

So it is getting sensory input.

This is going to be raw sensory input coming in or just from some other location.

And it is going to be doing the role of inference about X. And then it is going to be constrained and constraining the rate of change in X. So let's assign the computational function of this middle unit to like the derivative of X and this one to the second derivative of X.

So this architecture could implement something like a Taylor series approximation.

You can make it that way in Silico, and then you'll know.

Or if you're talking about real brains, of course, they're not actually doing a Taylor series approximation on the coefficients, but computationally, they might be doing something akin to it.

so thank you for that yeah thank you so figure 5.1 highlighted how layer 5 of the cortex is going to be projecting out here's layer 5 projecting out to some of these motor and decision-making regions

So now we're going to treat the descending prediction from that cortical region.

We're just going to have it up here, starting from the BET cells in layer five of the motor cortex.

So here's the BET cells.

Here's the motor cortex.

Here's like the brain.

Is sending a descending prediction to, in this case, a cross section of the spinal cord.

Sensory data is incoming to the spinal cord through proprioception.

Afferent means away from the sensor.

Efferent means to the sensor.

So proprioceptive data are coming away from the sensor and in the actual histology of the spinal cord, descending predictions about proprioception

how one is expected to feel, and then the incoming proprioceptive information are being juxtaposed in this discrepancy variable.

Subtracting the predictions from the incoming data, so just a simple differencing, results in an error that says how much muscle contraction would be required to meet the prediction.

So if the prediction is exactly what the incoming data are, the discrepancy is zero and no motor action is instigated.

If it's non-zero, motor action would be instigated.

Lower motor neurons then cause this muscle contraction or relaxation, ensuring that the resulting proprioceptive data match descending predictions.

so we can have continuous this is a an opportunity and where continuous time models have been studied a lot because the incoming sensory data are continuous for example perceived weight or just different tactile sensations and then the outgoing behavior can also be framed in a continuous setting

like the elbow angle and so this is like a simple statistical architecture that situates motor action as resolving the discrepancy between predictions incoming and data incoming

They move on to another region of the mammalian nervous system.

Cortical layer five targets several other structures beyond the spinal cord.

Amongst these is the striatum with these regions.

And a lot is known about that region in terms of gene expression and protein expression and neurophysiology.

they're describing some of the empirical neurophysiology neuroanatomy talking about figure 5.4 it's going to come up several pages later though so just keep that in mind they're going to be talking about policy selection in the context of expected free energy

so here we didn't need to talk about planning at all and continuous time models are very adept at describing these situations where no explicit planning is required but still adaptive action can occur and we revisit that in chapter 8 on continuous time models but now we're going to look at like decision making kind of classical psychologist type categorical decision making

especially thinking about explicit planning and then they're going to talk about how the architecture works but we'll talk about that when we see it dopamine tone is going to modulate the balance of the two sides of the figure and perturbations of dopamine are going to have some behavioral and cognitive consequences that are completely compatible with this model

just in general the anatomy of figure 5-4 is endorsed by evidence from both clinical pathology and cellular morphology so it's not the only map you can draw of the territory it isn't the territory itself but the map shown here is compatible with the complexity of the territory okay so now we're going to take those um

just like they started the section off on.

Outputs of cortical layer five are going to target other areas, not just the spinal cord.

So we are going to have one of those cortical outputs sending into this brain region.

there are going to be two pathways illustrated.

So one might be in effect or the other, and dopamine with this gamma variable is modulating the balance between the two.

So it's kind of like a rudder

computational role of dopamine is acting like a rudder with which one of these pathways is being deployed at a given time here are what those two pathways are and again this is going to be like a behavioral computational account but it's also consistent with the anatomy and with the clinical findings what's called the indirect pathway

is one where the E vector, which is our habit, the affordances are encoded in E. So different opportunities for action are enumerated in E and the numbers in each of those cells refer to their prior probability.

So if there's up, down, left, right, there's gonna be four elements in E.

And if it was 1, 1, 1, 1, it means all things are being equal.

There's no prior bias towards the direction to take.

Conversely, in that up, down, left, right case, what if it were 100, 1, 1, 1?

That would be equivalent to saying the prior probability on going up is much higher.

And so in this indirect pathway, the E affordance vector

is basically being passed on through to policy selection and so policy posterior pi is basically reflecting the policy prior so actions are being selected proportional to how they have been selected in the past the distributions of actions being selected in the indirect pathway

is being drawn from the same distribution as habit we can contrast that with what's called by the neurophysiologist the direct pathway here we see that same kind of input coming in but rather than passing e on to pi we have g so g

um is expected free energy functional so it's equation 2.6 and there's other representations and what g is doing is taking in the e which is like not shown but it does come into play so this is not exhaustively showing every variable just trying to only highlight the differences between them really

g sharpens the action prior into an action posterior so that is updating the policy prior into the posterior through expected free energy how does expected free energy sharpen or modify the action prior into the action posterior

it reweights policies according to their expected free energy.

What is expected free energy?

It's equation 2.6.

So there's different decompositions, no one of which is simply like how it is, but policies are going to be updated

in becoming to their posterior likelihood from which actions are actually sampled from and they're going to be sharpened or updated according to according to this top line the pragmatic value and the information gain of different policies michael


SPEAKER_02:
Yeah, one question.

So this posterior is still an expected posterior, and we also have in the variational free energy another kind of posterior.

Is that true?


SPEAKER_00:
Every variable in Bayesian statistics that's undergoing updating can be described as having a prior, and then data comes in, and then there's the posterior.

So here in particular, we're talking about the prior and the posterior on action policies, but also we talk about priors and posteriors for other kinds of variables.

Here, the focus is how descending information from the cerebral cortex shapes policy selection.

with a kind of neurophysiological hypothesis, not total expert, that habit is encoded or represented within this brain region, but cortical inputs shift the balance towards the direct pathway.

So this is where we see like deliberative decision-making because we end up sharpening policies according to their,

expected free energy.

So let's think about like the famous marshmallow example, where marshmallow is placed on the table and someone can be taking it or not.

And they're told about what it is or isn't or anything like that.

So if somebody had a habit of not taking the marshmallow, then this pathway would lead them to not take it.

If they had a habit of taking it, it would lead them to taking it.

In this case, in the direct pathway,

policies would be evaluated according to their epistemic and pragmatic value.

So in a model where pragmatic value was sugar and there was a preference for sugar, then policy selection would lead to the taking of the marshmallow.

If pragmatic value in that model were being defined as like conformity to the rules, then that conformity would be realized by not taking the marshmallow.

i know it's kind of like hard because we're talking on one hand about actual neurophysiology and behavioral patterns but on the other hand about these variables but they're um being juxtaposed here to to show how it really does come into play in empirical modeling yes michael


SPEAKER_02:
But all this is a planning.

This is not based on an observation at that moment, right?

And how does surprise come in there?

So surprise, how can we also expect surprise and take this into account in this expected free energy?


SPEAKER_00:
So this is showing just

a few distilled aspects of this graph this is not the full model observations are coming in and so in that sense surprise being about observations it could be understood to be happening here it's just not being like diagrammed

Yana, what happens when there are more options than a no-nutrient stimulant?

Yes, it always... That's where we get into the figure 9.1.

Not to look ahead, but depending on how the context is set up for the experiment.

Was it a two-choice experiment?

Was it a three-choice experiment?

And then that is the ethologist's challenge.

to develop the as if view from the inside the cognitive model of the subject parameterized by their objective behavior in this setting not the only way to use these models

here they uh point to how certain dopamine signals that famously incredibly famously look like reward prediction errors so one model of dopamine was like dopamine is the reward molecule and this schultz 1997 paper was like wait a minute

Yes, when more is received than expected, there's a dopamine spike.

And that was the pattern that people were associating with reward.

But if it's the exact amount that was expected, there's no dopamine spike.

And if it's less than expected, but still a reward, there's like another spike.

And so that was like, wait a minute.

So it's not just like a thermometer for reward.

maybe dopamine is doing something like tracking prediction errors.

So this is kind of like a proto Bayesian brain, proto predictive coding, empirical find it from the dopamine neurophysiology that we now have like much, much more resolution on.

And so active inference provides a specific alternative explanation.

to these phenomena where we don't need to make all these exceptions to a reward-based model.

Well, it's dopamine signaling reward, but then also it does that.

And also, I don't know why it does this.

We can have a unified perspective with active inference on empirical data.

Here, they're going to point to the idea that specific hypotheses can be formed

another reason to use active inference modeling for these kinds of cognitive or i mean ultimately neurophysiological settings is that there can be non-invasive measurement of precision parameters and that's called computational phenotyping and ryan smith and others have done a lot of work on that table 5.1 is going to list some of the important neurotransmitters

And then even though neurotransmitters do different things in different settings and they're not saying otherwise, they're going to kind of broadly associate it with a given computational function.

So they interact and there's neuropeptides and there's all this other stuff happening.

but broadly here are a bunch of lines of evidence that support an understanding of that neurotransmitter associated with precision acting on these things thanks for um sharing those yana it reminds me of this um

2016 paper they gave ants a choice between um sugar water and um some dopamine drug maybe morphine yeah morphine and they like showed that they could taper down the sugar and the morphine and change a few different things so that um there was like a persistent choice to go to the morphine

So, I mean, yes, many, many interesting things to explore.

But just to conclude on this part from above, computational phenotyping basically means probing a generative model, reducing our uncertainty about a generative model through peripheral measurements.

So for example, pupil diameter and eye movements

contain a lot of information on somebody's arousal and attention and so you don't need to have like an implantable neurotech per se you could use these non-invasive measurements and previously understood relationships like between pupil size and noradrenaline so that you could actually reduce your uncertainty about noradrenaline levels just by looking at the pupil

they talk about Hebbian plasticity and different statistical models 5.6 continuous and discrete hierarchies this is also um a topic that's um treated a lot more extensively in live stream 46. active inference models do not contradict folks psychology

but they highlight a move from continuous representations at low levels of a neural hierarchy, for example, continuous sensory input, to categorical variables at higher levels, especially associated with semantics, identification, and decision-making.

So we're able to hold categorical beliefs

and interface with continuously varying sensory receptors and effectors like muscle length or visual features that is just kind of brought up in these two short paragraphs in 5.6 and then in figure 8.6 this is an example of what the generative model looks like

So at the higher level, there's a missing line here, but at the higher level, we have a discrete time generative model, partially observable Markov decision process, POMDP.

How do we know?

Because it has the tau minus one, tau, tau plus one.

So this is making explicit predictions about the past, present, and future.

And in this case, it's also making categorical inferences.

So is it A or B or A and B, because those letters are also used here, but is it raining or is it sunny?

And we're just going to have a categorical difference between those two and have that estimate happening past, present and future.

But then at each time step, there's a continuous time model.

And so here we can recognize the continuous time model because we see that X, X prime, X double prime.

And so we have like this big rake,

big E pointing down and then here's a smaller one so it's kind of like figure 4.3 here's discrete time model E pointing down continuous time model E pointing down and then those are going to be grafted together so we have a higher order slower discrete time model and then a faster continuous time model

this could reflect and this is what they discuss in um livestream 46 with um alex keifer ryan smith and maxwell ramsted they discuss how decision making like should i go to the baker or to the barber is occurring in a discreet like way in this decision making model

but then the implementation of the decision-making model is happening in a continuous time model, which they call motor active inference, MAI.

So the good thing about figure 4.3 is these are enormously flexible methods

This is not like the one and only way an active inference model looks.

It's really almost bewilderingly the opposite of that.

This isn't like the zoo of what's out there.

These are showing some of the structural possibilities for cognitive modeling.

And there are many possibilities and there's many ways to model the same phenomena.

um yana asked how is the continuous hierarchy applied well you could add more information but one could make a hierarchical model where like the higher level was continuous and the output of a given like the y here we could graft another continuous time model right here

so these are like our our Lego kits these are a few Lego constructions that people have made that typify minimal skeletons of cognitive models but what's really important is that the cognitive models that we build are going to have tractable ways to do inference on them because of message passing

then they closed the chapter with this summary visualization so it's the three systems that we learned about in the chapter which is that cortical column the balance between the indirect and the direct pathways of policy selection in the basal ganglia midbrain and the action selection in that continuous time model happening via the spinal cord discrepancy detection

And so this is kind of reflective and compatible with the actual anatomical connectivity of the body.

So it's not like proposing a telepathic link between some cell in the brain and like the motor unit in the arm.

So it's compatible with the constraints that exist in the body.

It explains and predicts different phenomena that are observed

and those explanations come not from just trivial well if two things that are touching are influenced then one influences the other but rather with actually these statistical models that even help us understand the progression or different kinds of interventions in different conditions which is where these models have been used most so that's the end of that chapter five but they kind of close with um

a reminder that like neuroscience is a work in progress and um there are so many open questions from the super cellular level like where are the glia where's the immuno aspect to different kinds of everything they're just picking three examples

have been studied in previous papers by these authors and showing how alone and in combination we can use these kinds of models so yana asked so this is how sensory experiences can be modeled broadly

This could help us make sense of sensory experience.

This isn't like the one and only way to model sensory experience.

This is like one circuit board statistical model that can help with understanding how incoming proprioception results in outgoing action.

so it can be used in service of understanding sensory experience but this is not the the final model on sensory experience I hope that that's clear there can be other compositions yes so any other

Thoughts or comments on this first pass through five?

Michael?


SPEAKER_02:
Yeah, but in this figure 5.5 that you just showed, still the observation, the sensation is actually missing there, right?

So we have action, but not the observation.


SPEAKER_00:
Here, Y is the proprioceptive input, but other kinds like visual input is not shown here.

But that speaks to the composability of these models is like we could have an auditory stream and a visual stream and a proprioceptive stream.

And we can do model comparison and we can develop models that use any mixtures of those.

And on given computational hardware for a given dataset, for a given setting, for a given client, one of those models might be more useful than the other for you.

okay thank you yeah it's a fun chapter and i it's definitely a context switch because chapter four just goes so hard with the technical details and then 5.3 is really like about our bodies but in that contrast there's been a lot of great discussion so um next week we'll return for the second discussion on five

please feel free to ask your questions in the meanwhile.

So thank you, everybody.

See you next time.