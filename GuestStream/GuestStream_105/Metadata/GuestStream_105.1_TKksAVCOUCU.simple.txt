SPEAKER_00:
hello welcome everyone it is may 2nd 2025 we're in active guest stream 105.1 with paula de mayo discussing systemic deviation from systemic failures to systemic aberration we will first be playing a pre-recorded

lecture and then follow that with a discussion with paula and jeff shulman here so looking forward to everyone's comments in the live chat and here we go with the pre-recorded video annual at the active inference institute


SPEAKER_03:
and friends, Daniel and friends, to talk a little bit about my work and they picked a topic from one of my papers called systemic deviation and I've taken the opportunity to remind myself how this systemic deviation thing I wrote about some time ago applies today.

So in the process of reviewing the paper

which I wrote a few years ago on the topic.

Actually, I have updated it and realized that it's not only relevant, it also has this concept of systemic deviation has got like profound implication in helping us to understand a number of things which are going on today.

And so the new title for the topic systemic deviation is from systemic failures to systemic aberration.

it's a huge topic so thank you so much for bearing with me and uh the it's about 50 slides and i will try to go through them as quickly as possible but um because i don't like to hurry too much and speaking too fast although i've got so much to say in such a little time i think i recommend

The people listening to the talk will replay it at 1.5 speed so that all this pausing that I do while I'm reading doesn't slow you down.

So, systemic deviation refers to a behavioral and functional shift of a system from its intended purpose.

And it's particularly relevant in the context of intelligent and autonomous systems.

So what is systemic deviation?

A theory, a lens, a paradigm, a framework.

Just could be anything that you want it to be in a way.

And let's take it as a book concept at the moment.

So roughly, this is going to be the content of the talk.

Introduction, background, examples.

mitigation measures, systems.

And this table of contents, in fact, was written up before I finalized the slides, so we may deviate a little bit.

This is just indicative.

And about me, I'm a teacher, writer, traveler, interested in nature, complementary health, systems, metaphysics.

I'm asking myself the big questions all the time.

and eventually it wasn't easy for me to focus on an academic life because of my diversity of interest but then luckily in these recent years it's okay to be multidisciplinary

So my academic focus in the last 10 years after my PhD has been information technology, intelligent systems, knowledge representation.

I've got lots to say about this topic, interfaces, neuroscience, neuromodulation, meta science.

So basically we are trying to follow and gather insights into every little topic that matters today.

So

There was a paper called Systemic Deviation the Evil in the Machine which can be found online easily and it was published by the International Society for Systems.

It was a presentation I did at some conference and then

And it was a little bit like scratching the surface.

So this is a great opportunity.

Thank you, Daniel and Hector, who said, let's talk about this topic again, because it's really good to go back to it and see what does this tell us about what we are at really.

Then the other, if you want to know a little bit more, you go into psychological abuse and you say, why?

Oh, I'll tell you later.

But basically there is an interesting direction for the systemic deviation into the cognition and psychology of what this does to people.

So thanks to another opportunity, unrelated a couple of years ago, into looking at the

psychiatry rather it was but you know like there was something that system deviation does to people and so if you may be interested in that you can just click and eventually what we're getting at is systemic abuse institutional abuse is something that a systemic deviation can help us figure out what's happening so why psychological abuse and systemic abuse is because technical systems and socio-technical systems

can be designed to perpetrate systemic abuse.

Now, you never thought about that.

When you sit down to write a system or design a system or implement a system, you don't think, what is it going to do to people?

You think, does it do what it's supposed to do in terms of functionality?

You think of the engineering side.

But then ultimately, now that we are becoming so dependent on systems and we interact with systems at every level, every day,

they can be quite invasive systems as we as we are realizing with ai pervasive but also invasive so systemic deviation uh can be turned into abuse when it's turned into abuse can lead to psychological impairment so ultimately this is why uh i am uh matching the systemic abuse the systemic deviation which is more like a technical

a technical thing in relation to how systems cannot do what they're supposed to do, but it becomes relevant to socio-technical systems.

More importantly and more worryingly is that we cannot see and cannot, we like users or individuals or stakeholders, cannot see and cannot understand.

If we cannot understand the vision, we may not realize what is happening between the

It's important to understand that systemic deviation actually can have some consequences on cognition and psychology.

So in the title, as you can see, I put the word systemic aberration.

It wasn't there in the original work, but now that I've had the chance to see how things are progressing, I definitely say systemic deviation will lead to systemic aberration.

what we mean, aberration.

So actually, in science, it comes from a term coming from optics, the field of optics, and it's described as the failure of rays to converge at one focus because of a defect in the lens of a mirror.

We could say that systemic deviation is that defect.

If we use the optics analogy, systemic deviation is like some kind of defect that prevents us from getting the focus on whatever.

So, but also of course there is a systemic aberration, aberration is a term used in biology and more generically speaking is a departure from what is normal, usual or respected in a negative sense.

So, and we're seeing now how systemic deviation can lead to systemic aberration.

It's not a chance, it's not a mistake, it's designed.

I can see that.

i've started seeing that and this is the main message that this presentation gives then i figured it out and i'm sharing with people who are interested in looking into this possibility that we are all conditioned by systemic deviation when we're another so before moving on focusing on systemic deviation with a bit more attention i'd like to share this

table, which was in fact made by John and I, to which I'm grateful, that is comparing institutional abuse with systemic abuse.

So is this systemic deviation leading to some kind of aberration and abuse?

Abuse is also not particularly well understood.

We don't understand how it happens and what it does to people, but

In my work, I've had the chance to distinguish between the two and Gemini did a wonderful job at distinguishing the two using some categories, level, source of harm, scope, focus, perpetrator.

I don't know if I necessarily agree with these distinctions here, but it's very helpful to start as a starting point.

So institutional abuse, the level is micromissile or macro in systemic abuse, source of harm,

failures within the institutional abuse, the source of harm is failures within an institution, and systemic abuse is broader societal structures.

And here I would put socio-technical systems as well.

The source of harm is the poor system.

institutional abuse is localized, systemic abuse is widespread, focus on occurring inside the institution versus generated by the way the system is structured.

This is where our systemic deviation comes in really very clearly.

Perpetrator.

Individuals versus system structures.

So I think we're aiming, we're looking at this, but then very often the relationship.

So when the institution is a system or operates through a system, then the two overlap clearly.

So the purpose of this presentation is to identify and map issues critical to survival, ultimately to health or healthy survival.

Within the foundations of the paper, which I mentioned earlier, to see how this notion of systemic deviation, which I identified in 2016, has evolved and how does it apply today, we identify further examples.

So in this paper I gave you examples but things have moved on and we have a lot more examples today.

And to increase situation awareness analysis and find possible solutions and find some synergy with others who resonate with this topic.

So systemic failure, in the title somewhere there is also systemic failure.

So systemic deviation will lead to systemic failure.

It is a failure that happens in a deterministic, non-random, predictable fashion.

This is taken from some dictionary or definition.

a Google definition.

Predictable fashion failure that happens in a deterministic non-random predictable fashion from a certain cause which can only be eliminated by modification of the design of the manufacturing process of the process.

Let's forget manufacturing here.

Operational procedures, documentation or other relevant factors.

So it's very important to understand that very often when things go wrong is that because they were designed like that.

Systemic deviation can be a contributing factor.

I'm not saying that every case is like that.

And it results in a system not fulfilling its declared purpose or fulfilling opposing purpose, which is, you know, where the aberration takes place.

So to have a system that does not fit for purpose is kind of common, but to have a system that does exactly the opposite of what is designed to be is a blatant aberration.

Example of systemic failures.

In the paper, these examples are brought up.

I'm not going to spend too much time on it because you can read the paper, but basically, hospitals that kill patients by accident.

Very common.

Corruption in law enforcement agencies.

Very common.

States and governments run by insiders.

I'm sure you know all about that.

Democracies that are governed by or run by elites.

You can't see that, but you know it's there.

Media disseminating disinformation.

I'm sure you've heard that one.

Seemingly progressive movements that are actually set up to stir and drive repression.

This is very interesting when you see that, especially in industry, you say, oh, I didn't realize it for a long time.

You know, as a young girl, I was going into trade, learning about trade and marketing.

And then I realized that the consumer association is actually driven by the industry or set up.

It's like these are set up to deceive and to distort the consumer's view.

But you need to evolve the thinking and the awareness to be able to see that.

I didn't see that for a long time.

And when I did,

It did have a consequence on my ability to function, as in, you know, my psychology, really, on how do I perceive the world.

Open data initiative masterminded by secretive individuals?

I'm sure.

I mean, I've seen that.

Especially the open science.

Ships designed to sink?

I don't think that was the case with Titanic, but I don't think it was designed to sink, but it was definitely a design issue that sank it.

And how come?

How come something like the Titanic was not, the flaws in the Titanic design was not spotted?

You know?

I'm not sure, I don't think it was intentional in that case, but it was a terrible, terrible accident.

And probably there are more in the history.

And transparency initiatives designed and led by people and organizations who want to make transparent models fit.

That's very similar to the

open data so they're saying oh we want transparency and then they put the label transparency on the initiative but actually the initiative itself is completely opaque and this conflict between the label and what the thing that the system does is cause of disorientation in anyone who's looking at it so when we talk about abuse we're looking at cause of harm psychological and emotional manipulation systemic unfairness

Systemic unfairness is causing shifts in collective consciousness and possibly even genetic mutation.

This would be interesting to investigate.

Many levels, technical, socio-technical, organizational, societal, total misinformation, family, workplace, very complex multi-stakeholder scenarios.

So, abuse is not understood.

There is a lack of societal awareness.

problem it's almost because as I say in the presentation about psychological abuse is historical so schools families parents children relationship religion institutions they're all designed to inflict some kind of abuse so where abuse is perceived as good for you like discipline

very often abuse, discipline or good discipline is confused with abuse and therefore we are unable to distinguish this is abuse because we think that's the way things are and that's the way things work but I think we are trying to make progress towards a more compassionate and mindful society therefore we are becoming increasingly aware but at large in institutions it still ignores what abuse consists of

of harm are immense so what are we looking at again we're looking at shifting systems function behavior structure causing systemic failure where the system does not fulfill its declared goal purpose or becomes aberrated and it fulfills the opposing goal and then eventually will result in systemic abuse and aberration

So we're going to be looking at the mechanism of how this is happening and a little bit at the outcomes.

So the main outcome that we should be afraid of is the existential risk and then of course we're going to try to see if we can by raising or increasing our awareness we can

attempt to mitigate this phenomenon so we have defined systemic deviation and in particular i want to remind although this presentation focuses on psychology and cognition ultimately its application is the design of autonomous systems as they become more complex this deviation is increasingly hidden

And it's a little bit like what we discussed with explainability of AI, how do we make the black blocks transparent, more transparent, how do we know what's going on inside the system, how do we audit auditability, etc.

So this systemic deviation

applied were built into hidden into autonomous systems is relevant to complex systems social technical systems and intelligence systems so why is this topic important finally we're getting to the central point i think i have having illustrated what i'm talking about i can tell you why we're talking about it today and why i think is appreciate you listening because people are not listening and that's you know a bit of a worry but why is this topic important because

Systemic deviation is invisible.

You cannot see it at all unless you really look hard.

It's covert.

In fact, it's inconceivable.

It's counterintuitive.

And it's a mechanism that contributes to existential risks.

Existential risks resulting in technical and socio-technical malfunctions.

Loss of confidence in perception and judgment.

Mental and physical conditions.

So it actually makes people unwell.

I think it can even cause cancer, in fact, but I don't have the data to back it.

Lack of awareness, loss of cognition, widespread insanity, madness.

You can see a lot of that.

Socio-economic crisis, depletion of resources.

So the resources are there, but they're used not to achieve the declared purpose.

They're actually wasted so that the purpose is not achieved.

And this is like, ah, aberration, screaming aberration.

Yeah, depletion of resources.

ongoing conflicts, disagreements, wars, etc.

So systemic deviation is contributing to existential risks in a number of ways which are very alarming.

So when we talk about existential risks we think of the cosmic events like the asteroid is going to hit us, the black hole is going to swallow us.

This is not what I'm talking about because this kind of existential risks are not something anyone can do about.

Climate catastrophe we could

if we i don't know it's a bit late now sorry but it can be mitigated or we can attempt to avoid accelerating it if the risks are understood talking about global warming and all of that engineered pandemics by weapons nuclear war uncontrolled back and so we still could try to figure something out here but i'm talking about um something which is a bit closer to each of us and it's the misuse of technology

So we have industry standards which are failing to address the risks.

That is an existentialist.

So if the standard body that is supposed to identify and address the risks fails to do that, that is a way of the systemic deviation and the civilization apathy.

So people are actually becoming numb to this nonsense.

People are learning how to accept the systemic deviation as a fact of life.

And it will contribute to cognitive fog.

I don't have the time to go into this.

We'll be touching on what we mean by cognitive fog, but I'm sure you must have heard the topic.

People aren't figuring it out.

And eventually, possibly dementia, loss of cognition, misinformation, mastocytosis, brainwashing, all sorts of things.

So, existential risk.

not understanding, for me, the main closest existential risk to each of us is not understanding what is going on as a result of confounding, obfuscation, confusion, design, confusion by design.

And it means that people cannot react or make decisions appropriately to prevent whatever escalation of risk.

So the closest level of existential risk is information, knowledge, emotion, cognition.

What information we receive, how we process it, how we develop our knowledge and how that turns or stirs our emotions and impacts our cognition.

And then, of course, there's a number of other levels here we don't have time to look at, but they will be resulting in suffering and harm or loss of cognition or even loss of life.

So that existential risk is the reason why we're talking about systemic ideation.

In the previous slide and in the paper, these are the main categories identified.

We have already seen this in the paper and in the previous slide.

And now I'm picking up a few more examples that have

where systemic deviation has become applicable from the time the paper was written a few years ago to that, which is about 10 years almost now, 9 years.

But this is a figure which I wasn't sure about, but you know, we said hospital, you know, that you go to the hospital for it to be cured and then you die.

Okay?

So this is actually backed by figures.

Medical, yearly death.

This is only the US.

I don't know, I...

horrified to think what if this happens in the US I wonder how big the problem is at global level but basically medical error people die of medical error misdiagnosis and adverse prescription reaction these are three categories all called by some kind of systemic deviation and in fact they all belong to the category medical error misdiagnosis adverse prescription reaction they're all medical errors

but they don't receive attention so but when you there are measles like few cases for you they become like a big news people have died of measles these big news and this is a type of systemic negation there are two systemic negations here one

These figures show us that people are dying from the health system and it's showing us that information is misrepresenting the problem by putting a lot of attention on the small cases and not enough on the big causes.

So in AI, we are looking at the machine learning.

I'm not talking about knowledge-based AI, I'm talking about machine learning which is

the biggest type of AI used at the moment, which is causing all this interest because it can be very powerful.

But basically, the systemic deviation in machine learning happens when data is transformed.

You know these transformers, you must have heard of the transformers algorithm.

And the way the data is transformed can lead to the data become completely different from what it was at the beginning.

in more than one way.

So ultimately the AI may result in an outcome, the process carried out by machine learning can be false.

When we go and look at the standard to ensure that AI is operating safely, we see that the standard doesn't even contemplate truth maintenance.

Truth maintenance is a concept

in knowledge representation, which is one of the fields I'm working on.

And I'm working on this and saying, how come the standard in AI safety doesn't mention the truth maintenance?

Well, at least this was, now we're in 1st of May, 2nd of May, and this was true in February.

So, and I have raised the alarm.

I don't know if it has been taken.

There is a chance that it has been looked into, but they're not attributing this to me because this is what happened, unfortunately.

But I'm hoping somebody has picked up the message.

So the safety standards in AI are not adequately addressing the risks.

So there is a proliferation of ICT standards that does not address critical concepts such as treatment.

And then, of course, deepfakes.

So here, deepfake is an interesting case because it's a case where the software is designed to deliberately misrepresent the fact or the truth.

and it's built in.

So systemic deviation is actually, deepfakes is when people, so the software will produce some output which is fake, which is not real at all, with a lot of examples and a lot of adverse consequences, and it's a type of systemic deviation of course.

So in the moment, big drama here.

So I didn't look at this

Green Deal in the Obama era for a long time, I heard that there was a problem with the biofuels.

And I said, what's the problem with biofuels?

What problem can there be with biofuels?

And the problem is that they are, entire government programs are adopting biofuels which are clearly not right, not biofuels at all.

Like biofuels

The process of generating biofuel is supposed to be environmental friendly and creating free energy or is like non-consuming fossil fuel.

In some examples, and this was designed to happen like this, they made the biofuel dependent on fossil fuel.

because they designed it wrong.

And then they made the administration responsible for that, when the administration was actually probably a victim of an industry lobby that nominated the administration to sign off and accept a program which was clearly not working, because nobody in the program had control of what was happening, and nobody had enough competence to say this is wrong.

So the public could only see that it was wrong at the end, after billions were wasted, after biofuel became a joke, and after we realized that somebody in the system is making biofuel fail and is making the political administration, which is trying to go green, fail and make it look ridiculous, because they're really evil and they can do that, they have the power to do this.

And then this is another example of

the climate change conference in Brazil where they're cutting the trees down to make room for the climate change meeting.

This is, I don't know if you've heard of this, but this is, I just thought, oh my God, you know, this is really happening.

So they have the climate change conference and they're taking down the forest to accommodate for it.

Isn't this a case of systemic deviation?

For me, it is.

It's dramatic.

And so this was an interesting

example i was reading the papers the other day the atlantic and i don't have uh personal quibbles with uh anyone but they were saying you know here with the people who are losing this ability to figure out what's happening they're not just the common folks like you and i they are the people who are supposed to be in charge of big decisions so this article was telling of uh

you know the world's largest military was enveloped in a level of dysfunction that bordered with a comical now we have the top brass who is being misled so think of what happened with iraq one simple meeting by powell triggered years of war in the middle of war weapons of mass destruction that weren't there so here we have i'm not talking about i don't know about this guy i have no idea who this guy

whether it's fit for poster or nothing.

But what I know is that people who are making the big decisions, these are supposed to be the most rational, best informed decision makers who have big power to destroy the universe, or not to destroy the universe, and they are confused.

They're dysfunctional, they're misled, they're taking for a ride.

This is existentialism.

And then we're looking at psychological abuse in general and mind-wracking.

Now, when somebody told me this is mind-wracking, I couldn't figure out what we're talking about and then I figured it.

When we are misinformed and when we are given two versions of the truth simultaneously, people, cognition and consciousness become split with a split mind.

we are not able to make the best decision at all.

And this psychological abuse, this is a form of psychological abuse.

It's happening in the organization family schools, but it's happening at government level.

So, if somebody figures it out and says, okay, I worked it out, this is happening.

They're taking us for a ride.

This system is designed wrong.

It's designed to fail.

Now, when an expert will see it, they are psychologically abused.

So the people who identify the systemic deviation become harassed.

At best, they become psychologically abused and harassed.

At best.

At worst, they get murdered.

So the systemic failures in Boeing 747 are historical.

It's not secret.

There are a lot of

uh reports uh for decades there's been issues with some safety i'm saying boeing because it's the largest manufacturers but it could be that could be where there could be others so there are systemic failures in the safety of certain systems for example boeing seven percent and after seven for seven uh came running to in accidents safety caused by safety issues repeatedly

Increasingly, worryingly, systemically, the engineers, they started shouting, saying, I told you so.

I have reported this.

My report has been shoved under the carpet.

So people may have noticed that, you know, there are safety issues or some systemic deviation taking place at system design level or system manufacturer in some cases.

And they're killed.

Like this guy died accidentally by suicide.

It's a very long story, but you have to read it.

and it's unbelievable uh joan barnett joshua dean they're now suing but it's it's a dramatic so when we find out that there's something going on when we say it as a whistleblower or as a simple naive observer point the finger and say this is wrong and people become abused at best and they will become murdered and uh you know when the thing is when there is enough uh at stake

And this, you know, there is some lots of stuff.

There are some examples.

And then I'm looking at forensics.

I have a paper out which I can share with you.

Interesting stuff, but ultimately we have forensics is sometimes used to lead to wrongful conviction.

So we are using the most rigorous process for fact-finding to actually produce fabricated false.


SPEAKER_02:
false evidence.


SPEAKER_03:
Very common.

So why is this happening?

Motivation for systemic deviation, systemic failure can be found in... So some of it are genuine errors.

Okay, we accept that humans are not perfect, that systems, organizations are prone to failure, so we're okay.

But they can also be systematic.

So someone has figured out that they can play God

By injecting a systemic deviation into a system, an organization, a program, a hospital or two, we make money out of it again.

Which can mostly be money, but it could be a number of other things, including political power or personal power.

Power, money, profit.

So people are using some, you know, the more knowledgeable people who have figured out how to control a system.

These are the system control people.

They know how to control a system by designing it wrong.

And then they gain control or wealth or other whatever from this failure.

I would say so.

How can it happen?

Okay, so the mechanisms are misrepresentation, misalignment, and confounding.

By confounding here, I don't mean the statistical confounding factors that you find in statistics, which are mathematical.

confounding with data that doesn't belong and it makes the analysis of the data skewed, so the bias.

I'm talking about the tactics to confound, so deliberately seeding, misleading, decoying

signals into a message so that it takes a lot more intelligence and processing ability to decode the truth to clean up the truth what's happening really poor system design accidental so sometimes it's accidental sometimes it's deliberate and we need to figure out or both we need to learn how to distinguish when is this happening by accident or where is someone actually doing it

It happens to cognitive dissonance.

So when it's injected, it's because someone is designing a response into the individuals.

Very often these are the decision makers, the influencers, people who can call the shots.

They are deliberately misled to have dissonant cognition.

And this is where a lot of the people in power are actually psychopaths, which is kind of very worrying.

leading to alienation, conflicting emotions, and then of course, more general level, these conflicts in society can lead to mental health issues, autism, depression, disengagement, people say, okay, sorry, I can't cope with this, and I see you all on the beach.

Systematic aberration, so this is happening.

day in day out everything that we see what we do what we perceive is leading or going the same way and then we become confounded and i suspect it can cause mutations i have reason to believe that so there is a paper there is at least one paper there are probably more but it's saying mutations in human accelerated um regions in the brain region

So mutation in humans disrupt cognition.

There is an article with study.

So how mutation can impact cognition and social behavior.

But what I'm looking at is the opposite.

How can cognition and social behavior disrupt

cause or impact mutation.

I think it can, but I don't have the data for that.

That's another possible direction for study.

So, but what we know for a fact is that depression is leading to health decline, chronic stress and depressive-like behaviors associated with impairments of neuroplasticity.

People lose their ability to think creatively or positively sometimes.

Optimistically, people lose the ability to think altogether.

when they are stressed or depressed.

So all of this systemic deviation, which is causing confusion, people are losing their ability to control their own mind, their own cognitive process.

They don't understand what is going on.

We are all at the receiving end of someone doing something which obviously doesn't work or is wrong.

And that's very depressing.

And this is happening quite a lot.

It's a little bit what people are experiencing is cognitive fog and it's something that we should learn how to recognize a bit more.

still dissonant consequences, dissonant psychological-emotional dissociation, general stress, dysfunctions, reduction of free will.

We all become conditioned to function in a way that is reducing, minimizing harm and maximizing reward.

So ultimately, we are back to where the conditioning is taking place.

I have a presentation on free will, which I can share if people are interested.

And then, of course, that's where people become manipulated and unable to realize that they are being misled into something, into being part of something bigger, which is definitely wrong.

This is how people become like, you know, the horde behavior.

Because

because of the uncertainties there is certain safety going where everyone else is going and individuals, very few people have this ability to call out this phenomena of wrong and when they do their risk they become ridiculed and they become abused and they even murder and their families so it is easier

to say okay you know i've got children to think about uh i have heard so many times people are we want to worry about the end of the month paying the rent and sorry we cannot cope with this we have to just go with the flow so psychological and emotional trauma so this is where i think is happening that we are mutating this is all happening and we are mutating possibly cause of cancer and possibly we are becoming chimpanzees

I mean, you are becoming sheep, but they are becoming sheep.

I'm trying to develop my human discrimination at some cost.

So basically this trauma and this trauma are impacting evolution, okay?

That's important thing to remember as existential risk.

So what can we do?

We can first try to figure out what's going on, develop, raise awareness, recognize the risk of deviation, and become paranoid in the process, and become, how do you say, fairly petulant.

Like, you know, we have to pay attention to every little detail because deviation can be very subtle.

So you need to be able to look at the detail and

try to see is this little thing going to lead to a bigger problem later on down the line.

Knowledge representation, I'm sure I've got more slides on that.

So how can it be mitigated?

Logical integrity, important.

We need to be able to, we need to exercise our intellectual discrimination through logical integrity, whatever that is, whatever way you define.

Truth preservation, integrated systems design, causal loops,

stepping away this is more like a behavioral decision when things are wrong we cannot understand them walk walk as fast as you can walk away and sometimes we find ourselves into some desert you know into the jungle we say I had to walk away from this I had to walk away from that but eventually we will meet others who have walked away and develop better and maybe we have a chance to

reconsider and make an impact for the you know future and develop better systems obviously so they sort of cause loops for those of you it's a design way of somewhere here

there is a cause for the system to work as intended or the system to work not as intended, somewhere here.

And here is where the systemic deviation will hide.

As you can see, you need to apply a lot of attention to see where the deviation is taking place.

So in a previous

This is coming from other presentations, and basically, when I say knowledge presentation, it's important.

I have reason to do so, I've done a lot of work, but ultimately, in order to understand what is going on, so how to maintain logical integrity, we need to be able to identify concepts, to have an idea of how everything sticks together, what things are called, glossaries, how the...

these entities or things relate to each other in a process.

We use frame in AI.

So we have these and how they build a process or a function, algorithm, and how these are written up, so which syntax, notation, language, and then ultimately how these are encoded into a system.

So we need to learn about knowledge presentation because this is how the system is going to... By using a correct, adequate, valid, transparent knowledge presentation, that's the only way to figure out how the system is going to play out.

Then we have knowledge presentation as a shared mechanism to ensure...

the conceptualization of complexity, logical and functional integrity, risk reduction.

So we were looking at our risks and this is the only way we can ensure to reduce the risk is by understanding and implementing knowledge presentation correctly.

So to address the black box and the opacity and to improve reproducibility and predictability.

So mitigation, develop awareness, apply intelligent reasoning, devise better systems, develop cautionary measures, sometimes non-action.

So whenever we see that whatever we do is misused or misinterpreted or twisted or mischaracterized or misrepresented, then it's better

just to shut the heck up and walk away which is why many of us are ending up in some kind of monastery situation or retreats or isolation we need to collect ourselves and figure out if everything that we do is can be useful because there is a bigger evil out there then sometimes we take this spiritual

You know, I'm going to go to the beach or become an artist or just rather not do anything, which is a lot of people actually are taking this path.

And I understand why.

So, but of course, if we can, we should design properly.

We should develop ethical principles.

We should overcome our cognitive limitations.

understand and address systemic challenges.

So this is the system level.

I have a lot of papers on this.

We need to understand the system level and we need to do some joint optimization.

And I have a paper on that, which is something that happens naturally in functioning, how do you say, well-balanced ecosystems.

Joint optimization is a natural function of a healthy ecosystem.

But when this joint optimization is prevented by the wrong design, then equilibrium, self-equilibrium or self-correction cannot happen.

They're just discussing a different data.

So measures, again, mitigation, refine design principles, strengthen protocols, enhance awareness, address misuse, risks of misuse.

So the joint optimization is very important, because joint optimization means that the system should be designed to figure itself out, self-correct, but in the systemic deviated way, sometimes the ability to self-optimize is prevented completely.

This is done sometimes by bureaucracy or rules.

So very interesting stuff and a very big topic.

Purpose, structure, behavior, function, technical system.

Sociotechnical system has the human aspects like language, cognition.

We can design technical systems in a deterministic way, but we cannot determine how humans are going to interpret or react or adapt.

So, you know, we have some knowledge presentations somewhere in between there.

This again, these are slides from other talks and bias.

So I think systemic deviation is currently seen as a form of bias where all of these factors, systemic bias, epistemology, cognition, algorithms, function, representation, they all come together to develop the functionality.

But they can also equally be used by those very smart phones to develop this function.

And this is what we're seeing a lot, and this is what I'm trying to put across with the talk today mostly.

So, logical chains.

So now we're looking at, we're taking all this stuff together.

We have misalignment, misrepresentation, cognitive dissonance, loss of cognition, disengagement, decline, inability to take corrective action, possibly leading to catastrophe.

We are trying another way of looking at this, navigating all this information is looking at cognitive dissonance, psychological trauma, genetic mutation, leading to aberrations.

Possibly we are becoming monkeys, humans becoming monkeys.

Seeing that quite a lot and dissonance.

uh leading to dissociation and dysfunction uh some of it is visible very clearly in the health human social health poor system design can lead to logical disintegration big alert here alarm be careful let's be aware this is happening and this is a dual complexity again part of another

piece of work I did, and we're trying to break down where is the complexity.

People are saying things are becoming more complex, are they?

And here I was breaking down what is complexity made of, perceptual, cognitive, representational, epistemic, ontological, functional and systemic.

So this is what makes up our complexity, basically.

And I'm talking about this somewhere else.

And again, I place some emphasis on knowledge presentation and I identify some levels of knowledge presentation corresponding to as many levels of other levels, implementation, logical, epistemic, conceptual.

So system-level knowledge representation, you can look up the works, roughly consisting of cognitive and functional areas.

And I think systemic deviation is here.

but it could possibly also relate to here.

So I don't know.

I'm going to maybe redo this diagram.

I don't know where I got this tree from, but the systemic division could well be here.

So I don't know.

Research agenda, knowledge presentation more for the reasons that I discussed.

Ethical models addressing systemic challenges and a lot to be discussed of where this is going.

So misalignment between intent and action can be designed.

It can be accidental, but it can be designed to trigger failure.

This is what we should be very aware and very afraid of.

Systematic misrepresentation.

Intentional misalignment.

When designed and engineered properly, systems can be wonderful.

Self-equilibrium, self-correction, evolution, intelligence.

We all love this.

But then, when you leverage this ability to

pointed into the right direction of Han, then, you know, something to be obviously recognized and avoided.

And they're masked, when things are masked by misleading labels and false knowledge, so they're saying this is so and so, but actually you won't look and it ain't so at all.

And so this is where, unless people are paying full attention to the phenomenon, they will take

the label for good I mean to because we don't have the ability to process unlimited amount of information we are tired we are busy we are our attention is elsewhere in most days on the children on the survival on the paying the bills on other things which are more rewarding and more attractive like even you know everything that makes us happy we are looking paying attention to and all these misleading labels ah you know it's a headache

So to what extent can we actually go and check everything out and split every single hair?

And that's what I'm afraid we have to try to do more of.

So because when that happens, there is the divergence between the label and actually the fact.

when the label doesn't correspond to what the label describes at all that's where systemic division takes place and it's using adversarial tactics so it is a weapon actually and it's a weapon and the first level of target for the weapon is people's cognition and consciousness and so it's even considered smart you know people say oh yeah you know weapons it can be good because

you can win with them.

But when there is this disintegration of consciousness, then nobody wins, really.

I mean, a lot of people have worked it out.

So that's where I think we should be making the moral argument for, no, it's not smart to make people stupid or create disinformation.

Although there could be some short-term gains, in the long term, everybody's going to lose out.

And then, of course, this is another...

Big topic, deviated intelligence.

So we are using entire systems, organizations, rule sets, connections, networks to produce intelligence which is actually designed to mislead and dysfunction.

It's wrong.

Deeply wrong.

the paper on Forensics, which is going to come out shortly with Taylor Francis.

It was chapter of the book.

I have the opportunity to delve into Deviative Intelligence from a Forensics perspective, and I'd be happy to share the paper with anyone interested.

So we're looking at evil, okay?

If someone was wondering, or couldn't see, I couldn't see evil for a long time,

i thought everything was good you know and now i can see it and i see if you're asking me what is evil made of it's this is the stuff that evil is made of uh and there is probably a bit more but this is more or less so there is no right or wrong but there is systemic deviation we've looked at the examples mitigation

ethical considerations and research directions and thank you.

So yeah, I haven't managed to put in all the references.

I'm struggling to meet my deadline.

The deadline was let's try to get this done by the 2nd of May.

Today is the 1st of May.

Putting together the recording just to

make sure we've got something to talk about tomorrow, and I hope this thing has been recorded.

I want to thank Michael Walker who introduced me to Hector, Hector introduced me to Daniel, and now I think there is another guy here whose name I don't remember, who just came on board yesterday, and I hope everyone is going to look at this talk on YouTube, on the Active Inference Institute, and I am also trying to do a couple more slides specifically on the Active Inference

um before the second so thank you so much for listening to get in touch let's talk about this stuff let's talk more about this and see what can we do all right thank you for the recorded presentation paula are you back

Yes, I am.

Thank you so much for listening.

I'm sorry.

So what did you do wrong about the slides not being very visible?


SPEAKER_00:
I don't know.

They seemed fine to me.


SPEAKER_03:
You say fine because when I when I looked through the YouTube channel The slides were out of focus, but Jeff did you?

Could you manage to read the slide?


SPEAKER_00:
From YouTube from the live stream Yes, I was able to just fine.


SPEAKER_03:
Oh That's great for some reason my YouTube isn't showing but thank you so much for listening and I have I

uh i would like to perhaps suggest that we also link the original slides or recording to the youtube so that anyone having difficulties like i did they can watch um the original recording which seemed to be clear enough so thank you so much for listening cool yes um what do you make what do you make of all this what do you make of this tell me


SPEAKER_00:
Jeff, want to go first?

Or I can go?


SPEAKER_01:
Yeah, I can start.

Um, my first thought is about perspective and triangulation.

I'm looking at looking at the first bit of slides.

Actually, I took some notes here.

Let's see.

Um,

You know, from the first point of view, we have, you talked about explainability, and, you know, there are some tools that are out there from a modeling perspective that we can look at using, like SHAP and LIME for smaller, or for certain data sets.

I think the conversation about deepfakes

definitely warrants expanding on.

One of my research areas is dark patterns, which are deceptive user interface designs that people who create interactive systems intentionally place in these systems in order to take advantage of their users, primarily for monetary profit.

but for other reasons as well.

Um, how about we start with that?


SPEAKER_02:
Yeah, yeah, yeah, yeah.

Do you want to talk about it?


SPEAKER_01:
Yeah, yeah.

Um, so dark patterns.

Dark patterns are

very, very widely used.

They have significant economic impact.

There's an FBI report that came out of billions of dollars that are lost and time lost as well.

So the dilutive effect of people's attention being split is very corrupting.

in terms of people's ability to engender meaning in their lives and that's you know we we're working on a a user study right now to see how dark patterns affect the elderly population uh you know retirement age adults um i hear some clicking some keyboard clicking daniel is that you no paula please mute paula please mute when you're typing

got some morse code coming through um yeah so dark patterns um they divert your attention away from what you could be optimizing

and we see dark patterns all around us and we see deception in nature all around us as well and it's not unusual uh deception is can often be a feature uh in survival zebras have stripes um you know many insects uh use mimicry and

Deception necessarily isn't a good or bad thing.

It has to do with the intent and the will of the participants in that behavior.

That being said, we should absolutely optimize for wellbeing and wholesomeness and restoration wherever we can.

Another thing that I just took as a note here was your integration of optics.

That is very interesting to me.

I've also been considering how the evolution of language and sight are essential to our embodied experience.

and how gravity curves space-time for example and how sound you know travels at a different speed of light and how we evolved you know like as life on earth we evolved um touch and then sight or that's excuse me and then and then hearing um and then um

know smell and taste and then finally sight so that is that is i think something where there might be a correlation that can be explored

Um, from the perspective of, uh, control systems and, um, deliberate sabotage within a system, uh, we, I just submitted a paper, actually 24 of us just submitted a paper, uh, to a venue that's exploring that.

Um, and I believe that there is a way forward.

Um,

And it's going to be very Kahnian in how we experience it.

But I'm very hopeful because it's a bright future.

Something else that I wrote down was that, you know, crucibles have dual functions.

And, um, you know, they both, they both provide the form and the heat and they burn off, uh, the, the, the dross of the re in the refinement process.

So reframing some of these things as a more of a, um,

distillation uh could provide another perspective that might open up the door for uh alternative considerations um systemic aberrations um you know just like with cognitive pruning we have we have we must model

and embody and enact our experiences so we can make optimized choices.

Um, so having, you know, having a system where you're allowed to make mistakes, um, or, um, perceived mistakes that are really just, um, life lessons, uh, with guard rails is healthy.

Um,


SPEAKER_03:
do you think paula or daniel i i just laid out a couple of things there for the last 15 minutes or so thank you i i appreciate and agree and would like to look more into everything that you said but i didn't understand about the last point the healthy guardrails could you explain what you mean there a bit more so that i understand you properly


SPEAKER_01:
Absolutely.

So I think this goes in line with the POMDPs, the partially observable Markov decision processes that we use to model agents in active inference.

And when you're in a domain, an environment, and oh, you're clicking again.

And Paula, we're getting some more work.

You're sending secret signals.

Excuse me, Daniel, where was I at?


SPEAKER_00:
palm dp in active inference.


SPEAKER_01:
Oh, palm dp is an active inference.

Yes.

So partially observable Markov decision processes.

When you situate yourself in a domain, and

you have a boundary that you're doing an information exchange on with that environment.

You are not aware of the environment that that domain is nested in.

So when you have a second order connection, it can cause confusion if you don't have a translation mechanism

to be able to exchange information with a domain that you're not primarily connected to.


SPEAKER_03:
okay but why okay this is like this i understand that um i would like to um argue so to say that a user of a system who has a second order connection with it should be made aware of this hierarchy as a matter of ethics and transparency so that's that is a compression problem


SPEAKER_01:
um mathematically if i'm nested in a domain that uh for example i i'm a domain of of one and um i nest myself in a grid of uh 10 by 10 right and then i nest myself in a grid of a million by a million

If I extend into that second domain without first completely solving or sufficiently solving that first domain, it's going to disorient me.

And I'm going to be confused.

And I wonder if that maybe isn't the cause of some mental illness.

Is that you don't have a... Oh, go ahead.


SPEAKER_03:
It surely is.

So I can see why you're framing this challenge, so to speak, mathematically.

But from a systems design viewpoint, it needs to be, for me, the way I stand, unless it's adversarial, unless it's designed to confuse the user for whatever reason, then the setup should be declared.


SPEAKER_02:
It should be saying, okay, you're here, and these are the levels you're operating in, and now what you're looking at is a level one, and that's where you are.


SPEAKER_03:
And then you see, if you don't do that, you're, I think, abusing psychologically the user.

And so this is exactly the point that I insist on.

I'm not necessarily expect you or others agree, depending what kind of system you're designing.

But I'm glad you're picking up on the point exactly.

And that is where I think there is a difference in the sense of what kind of system you're designing.

Are you designing an adversarial system that you want to figure out how the user is moving, how they're thinking?

You're trying to learn.

what process is going into the user's brain by putting them into a grid that they don't know anything about and they have to figure it out and that you can see how the user is moving and how they're thinking or perceiving.

But that is absolutely not on.


SPEAKER_02:
For me, when I get into a system, unless you're telling me beforehand, I'm experimenting, I'm testing things.

the way your brain works, then I would say that is psychological abuse.


SPEAKER_01:
Well, I absolutely agree with you that the experience, the embodied experience should be commensurate with your capabilities.

May I ask a question?


SPEAKER_02:
of course let me just say for me it should be commensurate to the terms of engagement okay so you to trick a user to use a system without telling them what the system does and how it does it is not on please go ahead with your question are you currently um an instructor uh for a class yeah sometimes i at the moment i am and i this is one of the things i do


SPEAKER_01:
Do you use multiple-choice tests?


SPEAKER_02:
It's not my favorite way of testing, not at all, for a number of reasons.

But I know what you're suggesting, that could be a way of testing.

It could be sometimes, but it's not my favorite at all.


SPEAKER_01:
How do you design your curriculum?


SPEAKER_02:
It depends on what the goal of the class is.


SPEAKER_03:
Normally I set the intentions of what is this class for?

What is it trying to teach?

I'm very transparent.

In fact, my tests are very intuitive.

I tell the students beforehand what I'm going to test them on.

I said, this is the stuff you've got to learn, and this is the stuff I'm going to ask you to show me that you've understood or learned.

And that is because that's because I'm, you know, some people told me that I'm a little bit vanilla.

And I am in that sense.

Yeah, I think that's essential.

And I know that, you know, for example, those trick questions that people ask, I think they're like, designed to confuse the students.


SPEAKER_02:
They're really, I would not, I don't like them at all.


SPEAKER_01:
What classes?

What classes do you normally teach?


SPEAKER_02:
Mostly software engineering.


SPEAKER_01:
and now i'm doing i'm doing some machine learning and algorithms so um would you like to give me an example of um what an expectation is for a student when they um complete one of your classes not now no i wouldn't okay um may i offer one as an example um

if i am taking a class and uh i'm expected to know basic commands in the linux shell right touch yeah uh things like that uh would you would you expect a student in your class uh after they finish your class to be able to um right right

right assembly?


SPEAKER_02:
It depends who they are.

If they're not the kind of classes I teach, I would hand them the cheat sheet and I would say, um, this is, these are the commands that you're supposed to be using and this is what they do and this is how they use them.


SPEAKER_01:
Okay, so let's consider it.

Are you familiar with the OSI model?

Or maybe the internet model would be easier.

We can use either or.


SPEAKER_02:
No, but I would like you to go back to the original question.

So I, you know, I'd like you to... I don't understand why you're asking me these questions in relation to the presentation, to the deviation.

Perhaps you could clarify that.


SPEAKER_01:
Well, it's...

Consider this, if you will.

We're talking about confusion and deliberately deceptive design.

Yes.

If I am a parent,

Am I going to give my child who has not yet gone through driver education keys to a car?


SPEAKER_02:
I don't know, but I don't know.

That depends on you.


SPEAKER_01:
I give my five-year-old child keys to a car and let them drive.


SPEAKER_02:
No, but I don't understand how that relates to the systemic deviation issues that we've been discussing in the presentation.

I don't understand why you're asking that question and how does it relate to systemic deviation?


SPEAKER_01:
Daniel, could you help maybe provide some of your thoughts?


SPEAKER_00:
Yeah, I'm hearing a lot of pieces here like the stated intent of a system and then direct and indirect consequences of the system in an environment of nested interacting different cognitive systems and

cognitive deterioration but deterioration implies like some sort of prior more effective state so it's not always a simple deterioration just change in function leading to externalities and risks and all kinds of dangers and abuses which were brought up in the presentation

so then what i was just hearing in this sort of pedagogical direction is like from the micro to the macro like the multiple choice question or whatever you assess what you choose to say the intent of this course is to learn this like here's the level or the core screening at which the learning is is intended to happen at

and then there's the micro on down through the question and the way that it's presented on the page ordering of the test and all that on up through like the syllabus design and these higher order questions and so that's kind of like a scenario where we can explore systemic deviation

and think about how there's like educational experiences not not saying this what either of you said but where this all takes me is just there's uh a course archetype that could be imagined where the topic is presented and on all levels of analysis for the students in their own context it doesn't deviate from that


SPEAKER_03:
on through educational experiences that can be putting people back and putting them down and leaving them in a in a worse situation for any number of reasons thank you thank you daniel let me just say that i appreciate because i think you're contextualizing jeff's questions so so that i can understand what he was getting at better and i must say that i haven't um

analyzed in depth how systemic deviation applies to education and learning.

But it's something that you're putting ideas into my head, I can look at it.

But to your last point, the consequence is very often can be that the student is put off the subject for good.

so you may have um so i can see how it's a first it depends on the education style what kind of teacher are you and i have had what i consider a good teacher is the one that leads me to the love and the appreciation of the subject and they do so by providing me with the self-confidence

Yes, it's a constructivist approach.

You can tell the student, yes, you can understand this.

If you don't understand it this way, I can explain it to you another way.

And if you cannot understand it, it doesn't matter.

You can always understand the next thing or another thing.

And you can still figure out the subject in the end.


SPEAKER_02:
But there's also teachers who will just throw you at the deep end of the subject and let you swim out of it.


SPEAKER_03:
Either you survive and pass the test or you fail the subject.

And that's the kind of teachers that I don't consider good teachers at all because let me as well not go to that class.

I'm not learning anything other than

survive to the subject without any help.


SPEAKER_02:
In fact, it can be a traumatic experience.

And I don't know if this is addressing your point, Daniel, but a lot of learning experiences can be traumatic psychologically and impair the learning.

I don't know if you agree or if you have experienced that, but I have.


SPEAKER_00:
Yeah, that speaks to these sort of first and second order consequences and also to the disentangling and the sort of challenges of intentionality, which is like deviation or aberrance implies that there would be some non-deviated...

non-aberrant form so it's like what is the true form of something what how does intention what are situations when when natural systems just are the way they are

And then that takes on a special relevance when moving from just the consideration of some sort of morphological phenotype into cognitive phenotype and social systems design where the degrees of freedom and the updating can be

wildly fast and with these current ai synthetic intelligence systems etc there's the possibility for systems that have opaqueness like we've never seen

and rule updating, pattern updating that could for example like accelerate language change to a pace and a tempo and a mode that would be unrecognizable or lock in language to an attractor from some specific past and even those modes could be switching so it's like the control levers are so powerful

and they can be moved very quickly with very little notice all presented in the case of technology like that pretty cleanly through a trusted device so that opens up really important considerations yes and to that you see language for me it's uh must be explicit how do you say you must communicate okay


SPEAKER_03:
The moment it becomes, it mutates, it's transformed into a new formalism that only the speaker or the system understands and the other people because they don't have the code or they haven't evolved the understanding and cognition in the same way.

um they don't understand it then it fails that's the system where the systemic failures occurs right so unless you if you're designing if you're speaking a language uh if you're sending out information uh in me for a purpose of communicating it then it needs to be very clear and uh unfortunately because it is technologically so

interesting to see how it can actually happen otherwise.

How can you design a system to start speaking in its own language?

It's very interesting and it's fascinating and it's pushing the technology boundary, but does it still communicate the original concept?

And at some point, nobody knows.

Certainly, there is no way of verifying that.

And for me, that is a critical failure.

That's where the critical failure can happen.

And as you said, we need to be careful.

Is that what we want?

Or is that what we want to be guarded against?


SPEAKER_00:
yeah and i know that you are continuing to explore active inference and think about different ways it connects but that notion of a free energy measure which bounds surprise where surprise is like the information theory converted value of the prediction error or the deviation

so it's like rather than training some reward function and taking system state mapping it to a reward function like some ranked score and saying better or worse and then that reward function how did you get it is it out of date etc rather than going through that intermediary accessory ranking system it's possible to work directly on the information space

of the expected behavior of the system like working on body temperature and reducing surprise about going out of your homeostatic body temperature range rather than needing to translate body temperature to a reward distribution and then map back to a behavior choices so it's it's interesting to think like what are the green light yellow light and red light for

systemic deviation and you in the presentation laid out many many social and technical domains where people sort of people um bring things up and they and at the very least they deserve to be heard and considered


SPEAKER_03:
Now, I have to admit that as I have in a shorter video that I have very limited understanding of active influence and free energy.

But as I interact with you guys, I'm kind of learning more and taking the chance to read more and listen more.

And so this surprise thing, you see,

I don't know how many of you maybe not like surprises at all.


SPEAKER_02:
There is a whole section of the population which they have to create a category called autistic and they now go around wearing the labels and say, hey guys, I'm autistic, I don't like surprises.


SPEAKER_03:
Okay, surprises is gonna throw me off

my balance and it's going to make me reject the whatever is being proposed because it creates an emotional imbalance so uh some of us like to um follow be able to predict or at least cope or how do you say modulate our internal responses and i don't understand this thing about mechanism

surprise mechanism.

Is it supposed to be, in the free energy principle, is surprise something that is, is it describing something that you think happens in everyone?

Or is it supposed to be good?

Or could you want to say a few words about this surprise thing?

Because surprise doesn't sound good to me, you know?


SPEAKER_00:
sure yeah there's a ton ton to say on this a sort of contextualizing historical note is a lot of terms from psychology made their way into statistics like belief learning surprise and now statistics is being used to map back onto computational cognitive science and so we get into this situation that's like surprise as a general concept

in the information theoretic sense does not need to apply to a given human's experienced or conversational everyday sense of like that was a surprising event though that's a case of surprise when we're talking about the information theory quantity of surprise

it's more about how likely or unlikely a given observation is and so if somebody says like just to give an example i'm the kind of person who loves being surprised and they're talking about what they have for dinner then at a sensory level there's a surprise associated with that new dinner

But at the level of narrative or self-identity, they're confirming their identity.

So it gets a bit specific and multi-layered when applying concepts to human psychological constructs.

But in the general case, no, surprise has nothing to do with the felt sense of any given person.


SPEAKER_03:
But in terms of cognition, this is more like a request or suggestion.

So as I look into active influence and free energy, a lot of the constructs I come across when I do the reading

they seem to be kind of given you know and here there is a surprise factor but they're not really explained for me for for the people who don't have the background i mean i don't really understand what you're talking about so and a number of other things which for me are not very clearly or not simply enough so to speak exemplified as you're doing now with examples with the example of the dinner now when you talk about a simple example of the dinner

it's like i don't mind being surprised at dinner i don't care i'm happy to be surprised where i there are certain situations however where surprise is not on um like so i mean there's looking at the surprise factor i i i am right about it in terms of cognition so where does your how does your brain respond to certain um

cognitive events and then I didn't quite grasp where did the surprise come in so and how and I'm afraid in terms of psychological abuse that surprise is used as a tactic to disorient that what worries me most so I don't know exactly how surprise is fit into the whole of the active influence and free energy thing and I haven't looked at it enough but as I managed to

to probably hopefully summarize enough in a few lines saying if i don't think the brain can be um i don't think the mind rather can be represented by a model of base and brain then everything else

is a speculation.

So I mean it's interesting that you see it that way and that you can work with things that I'm not particularly understanding but maybe that doesn't explain or explore the cognitive models that I am interested in.

So I don't know whether I should be putting too much time trying to understand something that from what I see is

has not not not sufficiently meaningful for for what i'm looking at however if you decide that you wanna explain the surprise in active influence for everyone else to understand uh and then i think you know maybe i can help you because i am the kind that i can probably help you


SPEAKER_02:
make it very clear what is it that is not clear uh so and maybe that could help others i don't know but this surprise thing and this free energy um uh from the materials that i've read it's it's a little bit like you know you're throwing the the river or the the newcomer into the deep end of something that they don't understand you know what what's going on in that thing so um uh how many people are using active inference

Are there any expectations or projections as to where active influence and free energy are going?


SPEAKER_00:
yeah these are all good questions i don't have some specific number but but yeah i think if you keep exploring and there's different kinds of prospectuses that are written for different domains like robotics neuroscience etc and then there's sort of our prospectus from an open science and participation angle what we've done in the space and how people are getting involved


SPEAKER_03:
so yeah i mean if i if you for example had to say paula i want you to pass an exam in active inference okay the minimum entry level for active input and free energy i want you to be able to understand what it is and answer my questions okay

And I don't have unlimited resources to read everything about it.

So I will have to go and search for the main concepts in the resources that you give me.

What I think I haven't seen yet is the cheat sheet for active influence.

And that's what I would like to see.

If you want me to speak more intelligently about it,

and and if you don't have one and if you would think it could be useful i'd be happy to help devise a cheat sheet for active insurance energy but i don't know whether what i produce would

satisfy the entire universe of this field.

And in fact, I don't understand where is it going.

So for example, from an engineering viewpoint, I would like, I've seen these equations, okay, these equations, and I looked at the equations and I said, okay, what does it do?

What problem does it solve?

What does it do that if I didn't use active inference, if I didn't use this equation, how would the outcome of the system be different?

So this is what you may want to, if you want to speak to people like me, you may want to simplify the field to answer more pragmatic questions.


SPEAKER_00:
yeah question paula yeah sorry just yeah jeff go for it and just sort of in our last closing section go for it though when was the last time you sneezed or me you yeah


SPEAKER_03:
me i remember i'm funny enough i remember because i don't sneeze that often and i mean i don't remember precisely whether it was today or yesterday but definitely today or yesterday i sneezed do you know what made you sneeze

so sneeze is another one of those complex things but i think it was a slight exposure to a temperature colder temperature than the what was in the room like a little current or drops i mean i always know why i'm sneezing i'm not sneezing because there is a cold draft

or because there is some uh irritant agent in the in the that i'm breathing in there is one of the two what about you jeff when did you sneeze last uh yesterday


SPEAKER_01:
um i sneeze when i when i get when i get interesting ideas uh it's called the photon whenever i see the sun when i are a change in in light temperature i sneeze um my point being is that you know there's all these all these um embodied

reactions that we have that are surprise right when you get goosebumps when you sneeze when you have muscle soreness when somebody tickles you when you laugh when you cough when you itch when you have a stomach ache when you have diarrhea when you pass gas right all these things are signals that we don't we are not primary causal observers

they have to be translated through a mechanism.

And we have this embodied agency to be able to understand that there is signal, even if we can't interpret it.


SPEAKER_02:
Okay.


SPEAKER_01:
And I think that's a good place to leave it at.

I think that's a very human...


SPEAKER_00:
explanation of surprise surprisal and active inference daniel thank you both for the discussion paula thanks for the the sharing of your learnings and perspectives i look forward to continuing to explore systems and deviations thank you very much for the opportunity to share nice meeting you guys nice to meet you