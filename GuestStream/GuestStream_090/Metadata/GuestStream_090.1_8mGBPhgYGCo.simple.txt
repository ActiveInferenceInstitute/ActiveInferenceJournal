SPEAKER_00:
hello and welcome it's october 31st 2024 we're in active guest stream number 90.1 and benjamin nelson will be presenting and discussing mechanics of the mind so benjamin thank you to you


SPEAKER_02:
Good morning.

Today I would like to discuss the development and integration of various cognitive mechanisms within a unified framework I have been developing.

I am currently competing for the in the art competition and I'd like to talk about the framework

I've designed to emulate human cognitive functions and enable advanced decision-making, most importantly, abstract reasoning in computational systems.

I'd like to start, of course, by introducing several mechanisms I've designed, each contributing uniquely to the system's overall functionality.

In pre-testing the combination of these mechanisms, which I won't be able to get into all of them today, unfortunately, because I've been competing for the ArcRise, and it's incredibly challenging and transformative.

It's amazing.

The combination of these mechanisms have, in pre-testing so far, scored consistently above 85%, which is really encouraging and I will be submitting here shortly.

The mechanisms we see I have listed here is attentional selection, memory encoding and retrieval, reinforcement learning, distress dynamics, which is much like emotions in the system, and somatic stress, those underlying stresses that

kind of fuel those emotions, right?

The epsilon control, prioritization, optimization, iteration, belief dynamics, and adaptation, and very importantly, Robert Worden's requirement equation.

It's the requirement for cognition in an equation here reshaped

to create like a representational efficiency as a subsystem that's woven throughout the cognitive computing framework.

Within this framework and for the purpose of this presentation, I have categorized these functions into somatic and autonomic processes and I want to talk about

briefly what that means.

My favorite thing about active inference, I would say the people or the amazing amount of democratized education or the innovation.

There's just so much.

But one of my favorite, favorite things is the ability to

take these ideas using through the high road and low road to the academic inference and pull them out of the out of just nothing out of the ethos out of our thoughts and our conversations and turn them into something that has substances tangible and um in doing so

I've come across some really amazing things I'm excited about in the papers that I'll be writing later this year.

The attentional selection, like memory encoding and retrieval, reinforcement learning, belief adaptation, prioritization, optimization, iteration, these conscious processes are reflective of

cognitive functions, but there isn't a one-to-one relationship between these things.

These are representations, these are confabulations of mine and how I see these processes where it's more important for the outcome.

to be the same as opposed to the processes to exactly mirror biological functions.

So we also have subconscious operations in the system such as distress and somatic stress, epsilon control,

It's amazing in these processes and many of them do not work unless there is entropy.

And then, of course, belief dynamics and adaptation.

We see

resource allocation in this balance and interaction that occurs between these processes where autonomic functions manage baseline operations freeing somatic functions for higher level tasks.

One of the things that started me down this road years ago was an attempt to resolve cognitive feedback loops in people like to understand them and to see if there was some way to

either circumnavigate or circumvent these types of loops in conversation.

It was the first time that I applied a mathematical framework to a philosophical problem or a syllogism.

And in doing so, I kind of opened the door for myself to that eventually led me here to active inference in the institute.

So these things deal with in the framework

resource allocation so autonomic functions will manage those baseline operations as I said the feedback loops those autonomic functions provide inputs to the somatic functions for example the distress dynamics which I'll go into more here in a little bit which for instance could influence attention and many other things the well I'll get to that in a second I get ahead of myself so the

we see here the we require active processing and deliberate control these functions involve conscious decision making processes where the system actively selects stores updates and refines information based on current goals and evidence autonomic functions operate without the need for a conscious intervention distress dynamics and these other mechanisms that we discussed fall into this category they manage the system's internal states

and beliefs based on ongoing input.

So, for instance, in the Ark Prize, the tasks, the grid tasks that are presented and the purpose being to ensure stability and adaptability in response to changing conditions, which is necessary and kind of

and intrinsic property of these dynamic states.

So one of my favorite things that I have learned through this is about the role of Markov arrays.

So the Markov matrix that

is modeling the probabilistic effects of stress on cognitive functions and state transitions in this very simple illustration here we can see them as

unique and separate layers that are passing values up and down if we were to you know stack them uh passing values up and down and the the reporting from those uh rows columns uh informs the for instance the epsilon control just stress shades belief dynamics uh the warden's uh requirement equation the subsystem um there

to take a massive amount of data, tens of thousands of arguments, methods and calls and send them in a very nonlinear fashion through the system to dynamically influence every part of the system simultaneously so that the entirety of the system is in play and acting simultaneously.

and we'll talk a little bit more about how that works momentarily.

Here, when we look at, this is an older illustration, so I apologize, but it displays something that I really, that I think is really kind of cool, how the cognitive landscape and a cognitive computing framework can be visualized.

So when we see these, like our internal and external model and the,

information is coming in, then these Markov arrays are passing information back and forth.

They're updating those states and predicting those state transitions and

through that, like for instance, if we include memory encoding and retrieval and we were to treat these spaces on those grids in the same way as nodes, like a file folder with compressed data, there are groupings of those data over time through iterative processes that strengthen those beliefs, for instance, like prior beliefs.

So as there is more and more confirmation evidence, those

uh nodes for all intents and purposes are assigned higher order values and those higher order values are uh passed through that system um and yeah i think it's really exciting to balance um what would be a uh internal model and an external model the the predictive capacity i'm really excited about researching this more too because the uh with one or two the the

probabilistic effects on cognitive function state transitions.

It can be inaccurate, which is okay.

It's not meant to be perfect in that way.

But when you put many of them together, the accuracy of those predictions and

the temporal element to those predictions and that accuracy increases exponentially.

So I'm excited about exploring that more, certainly.

These components that are in this system that are communicating and carrying information, or that have these Markov arrays, are carrying information non-linearly through the system from these cognitive mechanisms and all their components.

operate synchronously and asynchronously.

It's really, really fascinating.

There's just a continuous stream of simultaneous data blowing throughout the entire system.

The arrays effectively serve as like conduits for data flow within the system, interconnecting everything and allowing everything to operate independently.

meaningfully, which is controlled through the epsilon control.

So these

probabilistic, like the arrays handling the probabilistic transitions between different cognitive states effectively ensure the entire system is dynamic and we get real time information processing.

It's really, really fascinating.

With the inclusion of Robert Warden's requirement equation, the

that the efficiency via the amount of energy required for the the amount of computation that occurs is significantly reduced.

It's amazing.

So

central to the non-linear communication really is like a dynamic state transition model prop like uh model probabilities of moving between states based on internal and external factors and they're you know the uh in data propagation where we're facilitating data flow between these mechanisms so they enable these complex interactions ensuring that changes in one mechanism appropriately affect another so um the

Next slide here, we kind of see how that works a little bit, where the distress calculation, which is, by the way, so this is one of my favorite things, right?

So when coding in Python, which I'm not a software engineer or an expert by any means, and competing in the arc has been one of the most challenging experiences in my life.

It's really, really fun.

these equations translate really, really well into Python and give a framework for the ideas that I have about the way that emotions would be represented in computational systems, the way that evolutionary imperatives would be represented in a system, the way that subconscious processes would be represented in the system.

There's an unlimited amount of creativity.

With Python as your medium, you can almost do anything, seemingly do anything.

It's really, really, really incredible.

What an interesting and bizarre form of self-expression I never knew that I would engage in.

It's just absolutely wonderful.

we see that the distress calculation is regulating the distress it's updating distress states we see coefficients at play these individual arguments representative of things like the derivative of time right or contextual factors external stimulus and those are updated there is the somatic stress system that is

understanding the role, the impact of emotions in guiding the system through by adjusting things like the cognitive load, time pressure, for instance, when you're taking a test.

This is specifically for the ARC Prize, which has a time limit.

There's focus intensity for like intentional selection when focusing on grid tasks and prioritizing what part of that grid or feature of that grid is important and needs to be understood.

Having errors and error feedback, very important, right?

How resources are distributed through the system.

And something I'm really excited to talk about later on, which demonstrates, I think, kind of the flexibility of this in terms of how kind of fun and silly it can be and simple.

And then, of course, we'll talk about how incredibly brilliant and powerful it can be.

as seen in the Warden RE subsystem.

The Markov array that you see in the middle, that's how I've made them in the system.

And you see different arguments feeding into that array with predetermined values.

Those values can be tuned.

which is really amazing it's uh the the fine tuning the system is one of the funnest things that uh i do because when the when the nature of the the project changes or the application is different the system can very easily be fine-tuned to best meet the uh requirements for that uh

task or object or undertaking.

So with Robert Warden's requirement equation in the system, it maximizes the efficiency of those processes greatly.

So before I move on to that here, I wanted to talk a little bit about Robert Warden's requirement equation

which is designed in this way to maximize the overall fitness by guiding decision making.

So for the purpose of the ARC test.

So in fitness evaluation, it effectively assesses outcomes of actions, incredibly flexible.

decision guidance recommending actions that maximize fitness and it integrates with other systems such as prioritization optimization and iteration to provide optimization criteria within the markov array it

as that dynamic compute expected fitness values, which influence decisions across the entirety of the system.

Let's see here.

I want to talk about something really kind of fun, because before we talk about some things

in terms of why these things are important and what they could potentially mean in terms of our future and how these new intelligent systems emerge.

I actually worked on this with a friend of mine who's a carpenter.

He makes cabinets, and I've known him for years.

He was my boss when I was just a kid.

He was kind of my first mentor in a way, and he's still a close and dear friend of mine 30 years later.

And we were talking about how do we understand...

like how would we approach decision making and how would what are some things that in decision making that we would think valuable and for me it was like kind of my confidence and whether i'm right or wrong i can't really know

especially if it's something that I've never seen before.

And that's kind of the basis of Francois Chollet's ARC prize and the ARC test is that he wrote a book called On the Measure of Intelligence.

And in that book,

the he talks about how the the way to really solve like a problem to be an abstract problem solver is to approach the problem uh with no knowledge of a solution no knowledge of the problem and to be able to solve it so in that way uh for me it's a the the only way i could kind of finalize my decision is in terms of my confidence that i'm right or wrong and

when we look at turning that into a computational framework is really pretty simple as you can see.

It's, you know, am I right?

Am I wrong?

What's my initial confidence, right?

Is probably going to be relatively low, but as I move through the task and I feel like I'm doing well and my emotions are calm and I,

you know, like my beliefs about this based on what I've done so far are confirming that the things look right.

My vision is telling me that it looks good and that that's what it's supposed to look like.

And all of those things through those Markov arrays are

feeding this confidence and increasing or decreasing these values.

And that initial confidence effectively goes to the point where you're so confident in the decision that you just go, Hey, I've solved the problem, right?

So the model says, Hey, I've hit, you know, point 996.

I'm convinced that this is okay.

So I initially thought that

The confidence, if it was right, it would be high.

And if it was wrong, it would be low.

That is not necessarily the case at all.

In fact, the confidence or an understanding that you may be wrong should just be slightly less than being right.

And what happens in the model is that when it's solving these tasks, that it becomes overly confident.

It was amazing.

The system becomes effectively arrogant and starts just making decisions on what it thinks, whether or not it thinks tasks have been resolved and

I was not really sure what to do.

I thought that the mechanism just might not be effective or that I may not have developed it correctly.

It was my dear friend that I just mentioned who noticed it and commented to the point that when people are arrogant or when something is

overly confident.

It is humility that resets that stage.

And it was then that I applied a decay factor.

Again, the role of entropy in these systems, I applied a decay factor to reduce that confidence when over time,

and in response to answering questions correctly to reduce that so it's approaching each new question with a fresh mind without making assumptions about

what's whether or not it's right or wrong with the answer.

So, um, I thought that was really funny and there's a threshold for understanding when the, the system should stop.

And we see that, um, down below as the confidence threshold, which is just a fraction of a point.

Um, I don't know if I got that right.

Is it things that I just kind of like, uh, copied and pasted out of, uh, different code segments from different, uh, iterations of this, uh,

process so conversely something that's really really really amazing that is very similar but much more serious in terms of its impact is the requirement for cognition and equation in a computational framework it seems to represent to be representative of

almost like a representational efficiency.

It manages that fitness throughout the system by kind of controlling the flow of energy and where energy is distributed in the system and why that's important.

It's calculating those state transitions and making predictions about those things and informing the rest of the system.

the amount, and I would encourage everybody to explore this as something that is so far incredibly flexible and improves everything that it touches.

I really can't overstate how valuable that this has been in being able to produce meaningful results around the cognitive computing frameworks that I've been attempting to develop.

So for instance, when I incorporated distress dynamics, emotional attenuation into the system, curiosity, happiness, and the component pieces, which I didn't have, I do have

visualizations on, but I didn't have a chance to incorporate them this morning, so my apologies.

But if anybody's interested, please reach out to me and I can show you what those wonderful things look like where you can see not just the emotions modulating through the system over iterations, but you can see their

components the of those emotions modulating through those systems as well.

And not necessarily in in tandem.

It's, it's pretty, pretty amazing.

So the let's see, where was I?

So when I incorporated the distress dynamics into the arc model called Archangel, which I actually named after Daniel Friedman, because he is definitely an angel to me, and the

this the percentage of correct uh questions the correct predictions about the output grid uh and being reflective of you know an input grid or a training example anything like that uh test that went up by 30 right um i could not get above the theoretical maximum of 85

without Robert Warden's requirement equation, no matter how much I complexified the overall or individual mechanisms or the overall framework.

So to the point of more than doubling the amount of just code that's in the system, complexifying these mechanisms, and just to see if that would necessarily be the case.

fascinating and and

It drives my curiosity.

Certainly that was the case.

So the effect that the requirement equation, for instance, has on prioritization, optimization and iteration, like optimization within the system, increased my score exponentially.

So the effect that it has not just in itself, but the role it plays in influencing the effectiveness and efficiency of all of the other mechanisms in the system

created like an aggregate increase that was as significant as those of the distress dynamics.

um the more it uh it seems to be that simplicity is really the key um with the arc contest in some ways that um the the more you add in the the like the more kind of like i guess you know it gets computationally like muddy and uh it it seems to be difficult for the model to

embrace like the and to move quickly through uh relatively what would be simple tasks for uh you know you and i um the using just simple form and uncomplex for like non-complex forms of these cognitive mechanisms by

using the equations, thread pool for parallelization and things like that, speeds up that process and makes the model much, much, much more effective to the tune of, in some cases, solving tasks for smaller grids within one to two or three iterations.

It's very interesting to see a cognitive computing framework get an answer right on the first try.

um and uh to see that in real time is really cool and to to have had a part in making that it's like it's amazing so um

the there's still like there's so much to do i'm really excited about um submitting um at the art prize and the opportunities that may hold and i am excited about many of the the discoveries that uh were kind of emergent uh phenomena as i don't when i think of coding i think of deterministic systems and maybe you do too of they're not being um

any autonomy or abstraction.

Everything is dictated, it's prescribed, and seeing this model operating in that system and making these decisions in these ways where it gets to take off on its own and its own beliefs about those things.

dictate what actions it chooses right so when we like reinforcement learning you know our thoughts uh our experiences our past experiences those inform our beliefs um and our along with our uh you know what we're inferring or foraging right um

those beliefs inform our actions and those actions have consequences and in that you see the beginnings of I think like what would be considered almost like a cognitive trajectory and it's going to be really fun to continue to explore and complexify those things and look deeper into them and see what can be found so the

I apologize.

In some ways, I didn't have the opportunity to prepare as much as I would have liked.

I've actually never done this before.

So I'm really, really thrilled to be here and to share even a little bit or to contribute in some small way.

And I hope that my work

as it gets better and I continue at the Institute learning from all of the great and amazing minds, the scholars there, and the amazing access to resources that they have that I'll be able to gauge more meaningfully and have opportunities like this again in the future.

And I hope that if you find any of this interesting that you'll reach out to me directly and I can have more detailed conversations and answer questions and things like that.

Thank you.


SPEAKER_00:
Alright.

those watching live they can write questions let's go over what the arc challenge is you didn't show any grids or anything so not everyone may be familiar so could you show any pictures or the code running or what the arc challenge is and walk us through what the system is doing what is the arc task how do cognitive mechanisms relate to what is being done for the arc task


SPEAKER_02:
Well, that's really exciting.

So I'm happy to go into that.

So I'm a little hesitant to run code.

And I'm a little hesitant to interact with my computer too much.

So I have a very old laptop.


SPEAKER_00:
Just show some images that just go to a website where we can see some examples and talk us through how the mechanisms relate to it.

Fantastic.


SPEAKER_01:
Okay, just a moment.


SPEAKER_02:
All right.

And should I, I imagine I should stop sharing and then just reshare this screen here.

Okay.


SPEAKER_01:
Give me just a moment.


SPEAKER_02:
yes so uh this is the arc prize leaderboards where i hope to be uh soon um and this these are there are over a thousand teams of the most brilliant people uh around the world uh competing

for what is uh called the arc prize and the arc is the abstract reasoning corpus it is a way to test computational models on their ability to think abstractly and to solve problems uh to solve for abstract problem solving right so um when the uh

model is uh and here i'll leave that so when the model is uh engaging with the tasks it's presented a series of grids and there are patterns colors um rolled things that need to be done as you can see in this case here there is there needs to be one uh yellow

field here there it's feel it's filled in and you see these as they become gradually filled in this would be like an example of what the model would encounter in training data in the training phase and then as you see the last one i would say oh okay well obviously i need to fill in empty space with the yellow squares right uh and um

that becomes much, much, much more complex over time, uh, through the test, as I understand it.

Uh, when I, let me see if I can go here and, uh, yeah, I've, we, this is like, cause humans can take this too.

Um, and my score right now in pre-testing is about the same as a human.

So about 86 to, I think 88%, uh, is about what, uh, a person would score, um, taking the arc.

So, um, the.

You can see here where it's just simple pattern completion.

The grids range anywhere from one by one to 30 by 30, as stated here on the ARC website.

I can only imagine that the patterns presented in such large grids become really complex.

Though you can't see what the model is doing,

there are certain things you can see like the computational load, like through Kaggle, where the contest is hosted, you can see the performance of your system.

And also I can hear my computer as it starts

sounding like a jet engine going off as it's like trying to, you know, process and bring this model.

So the ARC test, as I think I mentioned, was created by and co-founded by Francois Chollet, who's also the founder of Keras.

And guys, just absolutely brilliant.

I've learned a lot about him since I've been here.

And let me see here now if I can.

pull up an example of my framework.

And Daniel, if you'll let me know whether or not it actually shows up, because this is where my computer typically wants to start slowing down.


SPEAKER_01:
OK.


SPEAKER_02:
So you can see there, one of the most difficult things that I have encountered for this entire process was the actual generation of the submission folder itself.

There is, as I might have mentioned, I'm not a software engineer by any standards, and it can, there is a lot of really highly technical and, let's see here, let's see the full version, a lot of highly technical things and for brilliant and like,

experienced innovators and leaders like the folks at Minds AI, probably not even a hurdle.

But for me, it was like a really, really, really difficult process.

And I was able to get some help from a very brilliant gentleman.

And I finally was able to generate the

the submission file.

So now I can, I had to tear my model apart to figure out where it was going wrong.

And then I was able to, now I can put it back together and actually submit.

So wonderful here.

Can you see that Daniel?

Fantastic.

So, um, very boring stuff.

That's just the imports.

Um, the, the model doesn't use the internet.

It's not allowed to use the internet, um, because the test answers need to be, uh, you know, they they've got to stay secure.

So, um, the.

Everything that the model does is internal.

You have small things like pandas or whatever, libraries that you can access, but those are things that the wonderful people behind Kaggle have already loaded and are available in the system for you.

That's really wonderful as part of the notebook.

Here, to start, you can see there's a combination of two different types of kind of like

frameworks right so there's you know how we have like machine learning and then there's all these other stuff right and then you get down uh to the to the newest one and that's active inference so but active inference on its own for something like this is not necessarily effective especially given the time constraints that i've been uh under having only started and found out about this uh about six weeks ago so um i've included some uh

in this process some functionality that is more akin to just physical processes like the ability to interact with the objects as if they were physical.

So there's dimensionality reduction and other like for instance feature extraction and different types of tools really that the model can employ to help

navigate and manage those processes so here we'll see uh prioritization optimization and iteration as an algorithm uh in the the process and what this is doing is performing perceptual gating by computing the dot product as you see between the input data and the beliefs so the arguments that we're seeing is that the input data so that's the input sensory data and the agent's beliefs

going to return the gated perceptual output so um when we look at that obviously that's not enough on its own so it's like how do we how do we round out these products make each mechanism holistic all right i think of it like a circle with circles inside of it um and you know the more you can fill that operation that

overarching mechanism and complexify it, the more effective it will be in some ways, right?

There's obviously a balance, but then you have Robert Warden's requirement equation comes in to drive that efficiency and balance that throughout the system.

So you can get away with a lot.

So we calculate the optimization objective as a Euclidean norm between desired and actual outputs.

Again, you can see the arguments

there and these were really fun gradient calculations, which I was able to

uh based on some fluid dynamics uh some maths that i learned from keith affis um i was able to create gradient calculations that use dimensionality reduction to to um calculate uh a two like a two-dimensional space in a one-dimensional space and it was uh really cool and we get um

basically a weighting system, like a more complex weighting system in a simpler environment.

So we have weight with respect to the optimization objective, and we have weight with respect to noise in the system and reducing noise.

And I'm sure many of you are aware that computational noise in systems is something that slows the process, causes mistakes,

When we're going to see here where we're defining the algorithm and we're implementing it, we get the input sensory data, we get the agent's beliefs, our noise parameter, the target output, the maximum number of iterations, and the convergence tolerance.

Very important things.

So convergence in these systems is kind of the where all of the things come together and they agree on the task and the confidence hits that mark of saying this is now I know it's right.

And then the model will submit the answer kind of like the short and sweet to that.

And then

here back this is uh this is just simply some processing um i don't know what the grids are and i don't know what they look like and i don't know what um like people have done so uh i and i don't think anybody does i haven't actually talked to anybody else uh who's taking who's competing in the arc but um for instance what if there are multiple layers and there are colors hidden underneath the layers right so

I, for a time, had given the model the ability to assess the grids for dimensionality and, if necessary, visualize them in two and three dimensional spaces.

to find out if in fact that was the case and then return that to the other functions we'll see that scale the grid or resize it, things like that.

Here we have our attentional selection, just our simple attention mechanisms.

We're using feature dimensions and hidden dimensions, much like we would with beliefs.

really fun stuff really simple um nothing too exciting there now the hopfield network how the memory works is actually really fun and i've had a super exciting time playing with this i mean and maybe um

you know, I might have even taken it too far and almost like destroyed my own computer.

Hopfield Network's amazingly dynamic.

In this case, the memory encoding and retrieval between the Hopfield Network, which works under the Atkinson-Shiffrin model of memory, so we have like a long-term, short-term working memory, this Hopfield Network is expanding

within that is it is absorbing data collecting patterns things like that and uh employing a hebion uh uh equation for that encoding and retrieval and that's been very very effective and it's opened doors to uh some ways to manipulate the hotfield network um that again uh you have to be really careful with because you you know you might uh accidentally set your computer on fire um

So the things here, it's a little dense and I don't know what my time constraints are.

So I'm going to move past that for now.

But I have written a research paper that you can find on my link tree about this specifically.

And I go into much more detail.

The memory system and capacity, you can see the capacity.

the size of the hopfield network these are all defined things you know the hopfield network is the hopfield network size the memory is done in a deck form where the each max line uh max line will be uh you know a number of decks so a max line is 10 decks right so we're going to have whatever that

MaxLen is that's going to be our capacity of the total deck.

So here we see how kind of a cool condensed refactor of a complex encoding mechanism and a lot of like try accept blocks, things like that to handle

errors in the system, things like that.

Keep it going.

So here we go.

You can see the long-term memory, which is not really a play in this system.

I haven't really engaged it.

I don't know really if it's necessary even because of the way the Hopfield network in this system

uh will expand and contract it's dynamic to meet the needs of the task I wanted to I didn't want to come in with a memory system that is just holding uh all of this training data and um has like a really strong prior knowledge of what the tasks are I wanted to

kind of stay true to Francois Chollet's, as I interpret it, perspectives on abstract problem solving.

And I want the model to use and leverage the full weight of its cognitive mechanisms to solve the problem in that way, as if it had never seen it before and was unaware of it and a solution, but can still

abstractly resolve the issue.

So you can also see the size of those memory systems.

And I we passed it already, I didn't touch on it.

But there's also, you know, like the amount of beliefs that can be held in the memory systems.

And I guess I can touch on this as well.

The

Normally, there's a much more complex framework that's my actual cognitive computing framework that I deconstructed and decomposed and reconstructed to make Archangel for the Ark Prize.

But that physical memory, which is

partitioned into drives is short-term, long-term and working, is set up as a system of nodes and like data is grouped through these encoding processes and retrieval processes.

It's influenced by belief and emotions, much like a Hopfield network would be and how memory is.

I'm sure we all can identify with that.

And there are iterative processes that continue to organize and to strengthen that as new information, new data comes in to form priors and to assist with the formation of priors.

posterior beliefs and in regard to new evidence, which we see ties in through that same Markovian process into belief into beliefs.

Yeah.

So those higher order values that are produced when that when the new

information comes in or like data is grouped more tightly together and compressed into those those notes those higher order values are reported as assumptions about the world things that

the model would need a certain amount of evidence to override and to change its thoughts in regards to that.

So it's not something that you have to

impose on the system in terms of like uh saying if in an if that this if this then that relationship it is uh it is automatic it modulates itself and um it's really cool to see it's really fun to watch and uh i have an like a natural language processing version of this cognitive computing framework

for, you know, so I can interact with it, have response generation.

And in that is where you see how those memory, that memory system is incredibly effective for producing subtle nuance in contextual data.

So the somatic system that you see here, this is where we see kind of like the, if we were just to distill down

like what is happening in the system like you would in a body it's we would look to like uh or i would look to my uh my thoughts and my feelings but my feelings in a subjective way but this deals with those physical processes that are happening more so

and how energy is distributed through the system, carried and influenced by emotions or distress in the system.

So we have cognitive load, time pressure, focus, intensity, error, feedback, and the limitations of resources and how those impact confidence.

So we see that we can adjust stress levels based on all kinds of things, including task difficulty, how those stress levels are managed.

And in that Markovian process, when, for instance, let's say I encounter a task or the model encounters a task, I should say,

and it gets the answer wrong and there will be a redistribution of resources through that system and also uh in synchronously a redirection of the cognitive load away from uh

uh functions that aren't in play or as necessary to uh and kind of guided by robert ward's requirement equation to try to maximally like uh put the system to the task i should say so uh here we have the epsilon control uh which uh i'm a really big fan of and this is like kind of where we can fine tune those processes um and uh under like

create a system here uh for the them to operate autonomously so they there's like automatic they can automatically modulate uh and create you know stability throughout the system um when things get really dynamic you can also manually fine-tune these things but uh here you can see the application of the markov matrix and its role there um in uh uh

catching that distress vector and updating those stress levels.

And of course, again, entropy in the system applying decay.

So the cognitive system class that you see now is kind of where all of these things come together in and like in

not so much to solve the task, but for the homogenization of all of these necessary operations.

So, for instance, we see now all of those many arguments that come together to form

what emotions are in the system we see uh three um represented here happiness anxiety and curiosity which i thought would be uh the best for resolving the tasks and of course the astir the that stimuli when we are happy it's reward we have anxiety

we feel a penalty and the difference between or the not maybe the opposite but counter to curiosity would be novelty right um and uh

when we are propagating common cognitive states through that markov matrix to communicate those things to homogenize all of those things we're going to see the influence of those emotional states on the markov transition probabilities for how does anxiety affect the system how does it affect decision making how does happiness influence decision making these processes are happening uh synchronously and asynchronously so the that is a massive

like uh uh spread throughout the system um you know looking at those processes or those um uh mechanisms as like you know uh little circles with circles inside of them throughout all of those things are woven these threads of of distress that um influence and the um

all of those functions as those cognitive states are propagated through the Markov matrix.

So we get to introduce non-linearity by applying non-linear transformation here.

I'm sure many of you are probably more familiar with sigmoid and cognoid, I believe, and tan.

uh which is something i've been learning about it's very very amazing um tan is obviously my favorite and i think uh because um as daniel uh has uh told me many of times it's not uh to stop engaging in hyperbole and i'm working on it very much so so um

Now we see some action selection.

So simple, just action selection, the evaluating our actions where we see the Markov matrix in play for

the how like cognitive states are moving through the system and and we're going to assign like rewards and penalties which i basically just picked up from q learning uh features and for reinforcement learning so the i'm just kind of taking what i can know and taking what i have what i think will work and trying it so certainly getting uh uh consistently above 86 percent um in on the arc test even i think in pre-testing um

is no small feat.

The being able to do that is the culmination of tens of thousands of failures.

I could I would love to I'm making a composite of all of the failed code snippets and sections and everything that I like just kind of that sit in the junk pile.

And it's massive tens of 1000s of lines of code that have produced from that hundreds of lines of code.

that are effective in resolving these issues that seem to, as outputs, reflect the outputs of biological processes and cognition.

So iteration, always super important, update emotions, propagate states, select actions, evaluate.

Here we see our confidence scoring class.

Sorry about the names for some of these things.

Six weeks of 20-hour days, seven days a week to compete in one of the hardest and most technologically rigorous competitions, certainly that I've ever been in my entire life.

But my dedication and self-determination is...

indomitable so i will i will just work 20 hours a day seven days a week till i either win or lose uh and fortunately for me that submission deadline is rapidly approaching so i'll be able to sleep for a couple of days and uh get working on writing wonderful research papers which is like my favorite thing you know thinking and about all the wonderful uh uh

mysteries of active inference and cognition existence and putting those ideas on paper.

So again, Decay.

I actually named this after my friend.

His last name is Dahl.

So I call it the Dahl factor to introduce humility.

And as much as I love him, he is a very confident person.

So it's fitting to name humility after him in this system.

Many people who are familiar with Active Inference are probably familiar with Q-Learning.

Q-Learning is implemented here as a, almost like an agent is what I've been calling it, but it has a really, really, really like powerful effect on action selection.

Again, it's, you know, the, if we are,

if our beliefs are informed by our experiences our knowledge our assumptions about the world and ourselves um and our actions are informed by our beliefs uh then certainly uh re the reinforcement learning uh which is employing q learning here would be uh uh would have a large

part to play in that.

So I spent a lot of time.

The Q learning is also very, very for anybody who's interested in doing this type of thing or finding out more Q learning is very, very, very, very touchy.

It's very sensitive.

It errors and it breaks and it is fragile.

And I wonder not to engage in hyperbole, but how that reflects our memory and our assumptions, which for all intents and purposes are not real.

So here we see Robert Warden's requirement equation is a subsystem.

We're going to get initial representations of what's happening in the system.

and that's going to create uh efficiency scores for these things those efficiency scores are going to be passed and calculated uh all of those things exactly as the equation would which is amazing to be able to um take something that's so brilliant and uh just

And that's kind of guess what I was like, meaning when I said that it's like, uh, it's flexible, it's you can, and it integrates into anything.

You can just take the equation itself and, and write it here and then say,

you know, okay, so the sensory input to generate new representations from decision variable, action variable, probability distribution over states, conditional probability over decision given state, the conditional probability of next state given current state in action, and the value function mapping between states and future states for our parameters,

very very very quickly line out this these representations these efficiencies and integrate them into so many other things through the use of those Markov arrays so or a Markov matrix we can calculate the representational efficiency very simply

decision variable, action variable, probability distribution over states, right?

Value function mapping between state and future state, conditional probability of next state given current state and action.

I mean, it's just incredible.

And we see these here in the same way that you would see notations in many of the papers that I've read through the Active Inference Institute.

And we can calculate fitness.

in the system based on Robert Ward's requirement equation as you see here is a

Same thing, decision variable, action variable, probability distribution over states, on and on, the value function mapping between states and future states.

So here's where we get to where everything, both types of, where we see the kind of the mix of artificial intelligence and cognitive computing, or at least my attempt at cognitive computing.

this is where they come together in the form of like tools in hand for solving tasks um in the problem in solving intelligence class um we uh have our epsilon our distress um i made uh well i'll talk about the multi-agent plurality um here shortly but we also see um all of our uh

coefficients for the distress dynamic calculations.

Those values represented our Markov matrix and all of those, you know, belief history, somatic stress, confidence

the weights the epsilon control all of those things coming into play the distress state indices such as the cognitive load time pressure focus intensity we see the memory system here and we are starting to see now some actions and

things that deal specifically with the tasks themselves.

So for instance, something that I found was really interesting that made an impact in terms of how many questions I was getting right was giving the model the ability to think about how hard the task was before it started the task.

And in this simple bit of code here, just a very, very simple heuristic, we have the size of the grid,

What are things that are unique about the grid?

And then return those values and pass it along.

And all of a sudden, the confidence, the effectiveness of the confidence in the system works better.

It's like the role of emotions has a greater impact on the generating the correct task output.

It's hard not to, and I'll be honest with everyone, it's hard not to fill this with as much matplotlib and logging and debugging, everything that you can do because looking inside and seeing the...

just thousands and thousands and thousands and thousands of contributing forces and factors and variables at play is so cool and uh

Um, yeah, so it's, it's neat to look into, uh, inside of these and see how these things work specifically.

Um, when even someone like me can, uh, put pen to paper and make these things without knowing how they will necessarily operate or work, um, calculating rewards, extracting features.

reinforcement learning and how those things play affect the Q value history, state action pairs, et cetera.

the i know we're getting to something i really enjoy here um feature extraction selecting actions based on uh you know the um those return q values the higher the q value uh the the more often that a uh uh the chosen task has been correct

So it's the model is going to necessarily try those higher Q values first, since they are the most likely to be true and then move on to other actions, including things like rotating the the grid, looking at it, flipping it horizontally, vertically, reducing it, zooming in.

So to see better detail and

Here's the scale grid.

And let's see here.

The generating the action space.

So this was a lot of fun to try to figure out because I had no idea how to do any of this stuff.

It's like, what even happens when the model is in the system?

This is one of the things that was so difficult with finding out how to even submit the file is because the model is doing all of the lifting.

we can interact with the model on the outside in terms of tuning it, but once it's inside there, you can't see what's happening.

Generating that action space was really interesting to

give the agents something to work with inside that space so and here you can see um that I had to disable um many of the trans uh like the transformations because they they weren't effective the they weren't producing um Q values effectively and they were increasing the uh

the size of the action space so much that they um that they wouldn't meaningfully uh that it like it bogged down the the system overall computationally so um i uh i just kind of know those um and here we see resize grid features um

Solve grid tasks with multi-agent support.

So I don't know if there's any younger people in the audience.

If there is, maybe you're familiar with a cartoon show called Naruto.

And this character, the main character,

uh one of his his abilities uh they're kind of like superheroes uh and one of his abilities is to um become uh to clone himself to become like a thousand of himself all at once and he uses that to overpower his enemies kind of thing um in this case i wasn't sure if it was actually even allowed um but i figured i would uh give it a try the the when we think about like

taking a test.

I think about the dialogue that I will have with myself.

i have one internal voice like you know that i talked to but it made me think of uh of that um dialogue where you see like you know you have an angel on one shoulder and a devil on the other shoulder or you know the pitchfork guy or whatever it is and they're having a conversation back and forth and presenting counterpoints in different ways of looking at things um certainly that plurality could be uh represented computationally

in the form of agents inside of the agent.

So when the agent gets to a point where it is stuck, this multi-agent plurality is enacted and these agents appear inside of the agent effectively, and they receive their own test grids.

And they start trying to solve the test grid as they look out through the agent at its test grid and at the input test grid.

When they can't get an answer right themselves, they do something that, this is why I wasn't sure if it was allowed or not, they ask each other.

Here, let's see here, where is that?

Uh, well, I, oh, it's up there in the problem solving class.

I should have, I should have mentioned it, but, um, up there where those, uh, those classes, those different things, the functions are instantiated.

You see, um, the number of agents and you can change the number of agents you get.

It could be a hundred.

It could be five.

I, I kept it very low.

I think three to five agents.

Um, and when they get three answers wrong.

they they raise their hand and they hold up their grids and they say what do you guys have and those agents communicate with each other as we'll see in a second where they say oh i've got this and they go oh okay that you got that one ahead of me so now i know what the right answer is and when the those agents are able to complete a grid collaboratively that grid is then passed to uh the model agent archangel uh and it's then used or employed to complete the task so um

That was actually really super fun to make.

I really enjoyed making that.

I kind of organically, and one of the first things that I ever presented to Daniel, and I think I showed this when I very first came to the Institute and was hoping to be let in the door, was a schema for what I know now is

colloquially I guess referred to as a multi-agent system so that I haven't gotten a chance to make one really before and I have made this one and I've gone and

further complexified the system to make what I've so far been calling Nexi, which are little autonomous agents, but they are builders as opposed to agents that call out to each other.

They don't have greedy policies.

um uh so evaluating the solution really simple it's like for going through the uh training and evaluation phases um you you want to know how you're doing this is a visualization stuff for me because i love seeing this it's a values rewards epsilon um and uh this is uh just kind of boring stuff here that's uh not very much fun um we see um

as we're coming up on training and evaluation spaces there are certain like secondary or tertiary cognitive processes within here within

like the throughout the model so i mean for instance here you'll see um uh how we're handling predicted output shapes mismatching and coming down here to our selecting our actions but we know that these this action selection is heavily influenced by reinforcement learning and the q learning feature right so um that continues um as these things uh uh

further intertwine.

Here we go.

As we see it, the reinforcement learning queue learning update and the reinforcement learning decay and epsilon control decay epsilon.

So here in the evaluation definition, we are evaluating the agent's performance on the provided evaluation data that's provided by the ARC.

this just gives a baseline for is my model actually solving the tasks or is it am I just way off base I mean there has to be some which I'm so grateful for them for thinking of this and and the the way that they've structured everything even if it's the hardest thing you've ever done is still absolutely brilliant and intentional and

uh and it's so easy to see the wisdom of it once you get into it um they have you know given us the ability to you know create a baseline for okay these systems work these solve tasks um but will it solve you know uh the test so we'll see um

These are just a lot of if that, then this kind of things, if error, then kind of stuff.

And then we get down to the main execution block.

One thing I want to be clear about, there is only a small, small fraction of the cognitive mechanisms that just I, by myself,

have made that have proven effective in other ways and in different systems and for different purposes.

And I'd really like to encourage other people who are interested to really dig in and explore the possibilities there because

not only is active inference amazing and incredibly, incredibly challenging, but the potentials for discoveries, it's like there's something around every corner, under every rock, every single equation that you come across holds some hidden and deeper meaning.

It's almost esoteric.

And when I'm putting them together and seeing how they interoperate, there are things that

that become evident or obvious that can be like with the confidence and the decay factor that we put in to introduce humility, where they can be silly kind of and fun and just thoughtful, or they can be something that's deeply meaningful and deeply impactful and has broad reaching technological implications for humanity, such as Robert Warden's requirement equation for cognition.

And this is all just the boring stuff here.

This is where we're initializing that problem solving intelligence.

We're plotting metrics, we're calling the test files, so the JSON formatted files that contain the training challenges.

and training solutions, yada, yada.

So I don't spend a lot of time looking at those things because I want to kind of maintain the veracity.

Like I really want the model to work on its own and to do all of the heavy lifting.

I don't want to bias the model by knowing too much about

how the competition even works, which is made something certainly more difficult for me than others.

But overall, I wouldn't have traded this experience for anything.

And Daniel, I'm so grateful to you for tasking me with this.

Definitely the things that you've always given me to do as Undertakings are

There are things that I didn't even know I could do.

And this is one of those things that's just been an absolutely transformative experience that has radically increased my abilities and has given me so much insight that has inspired my curiosity.

And it's like, I can't wait to

research and read more and put pen to paper and continue coding.

I never thought I would be doing that.

So this, as you can see, is the Kaggle working submission dot JSON.

This is what I have been pulling my hair out over forever.

Not this necessarily this file path, but actually generating this file path.

This has always been there since the beginning, but this file path would not create.

And this is like, for instance, when tearing my model apart to make this, which unfortunately

some of the cool pieces that belong as integrations here were not in this because I had to figure out what was preventing that submission file from being generated and it was turned out a bunch of things just my lack of familiarity with coding I'm not an expert so though I may be if I keep up at it someday so the there were things inside and outside of loops and

I found some functions that had basically been rendered ineffectual as a result, and those failures in the system were stopping the formation of the JSON file pathway before it could be enacted.

So here, and I don't know if anybody's interested in this, I can

I'll quickly scroll down to the bottom and we'll see, I don't know if this is one of the, it may take a second to, so let me leave this alone.

But here, let me try the logs.

So here, for instance, this is Archangel 1.0.

It successfully ran in 3,116.3 seconds, which is actually pretty slow.

I don't know what the other people's, like, what other competitors' code looks like, certainly.

And just let me know if my screen starts lagging.

It usually does when this starts running.

But...

I know that they're brilliant, they're experts, every single one of them, and their models will typically run really fast and are very, I'm assuming, very, very, very efficient.

I know, I'm assuming probably in under, when I first started before I really got the cognitive mechanisms in play and those somatic subsystems and some of those larger calculations that are occurring,

the model would complete almost instantaneously.

It was just so quick.

The blink of an eye and 1,200 questions, training, all of that gone and producing a result.

But the result was not favorable.

It wasn't a score that I would be happy with.

If I remember correctly, Daniel didn't ask me to get first place.

He asked me to beat the theoretical maximum.

So that's what I'm trying to do.

So here you can see where it says does not exist.

I was so sad.

But let me see if we can get if there is any scoring to be had.

No.

So unfortunately, I picked the one model that

didn't produce a score because I was tearing it apart to find that submission file, which we'll see no operation, none in the submission file you can submit.

My model only produces one output.

one correct answer.

But you can actually choose to produce two if you want, like you can get two tries at getting the answer right.

That's how hard the test is.

So my model was basically the action selection through a boring series of events in the generate action space was not selecting a new action.

And so it was defaulting to the error of no operation.

And

uh closing the task out completely so in this case the tasks were being prematurely uh ended or were running uh as no operation through their total iterations which in this case it looks like it was set to 500 so um i would love to um if i can i don't know if i'll be able to but certainly anybody can

reach out to me directly as those log files are I download them every time and you can see that score of 86.4% consistently about 84 or 86 above 86 to 87% what's really interesting is it seems that I'm going to have to just get out of this and because it's a

It sounds like my computer's firing up like a jet engine.

So I wonder, and I would love other people's thoughts on this, if you cannot get 100%.

um no matter at like i have seemed to like kind of and it may just be me but unless i uh game the system there's not really a way to get a higher score that system naturally even scoring well above the the the maximum uh possible

um still won't get every answer right so i don't know if that's uh because it has to be that way or if it's uh if it's just my uh my lack of uh familiarity uh with this so um i'm gonna try one more time really quickly to um uh


SPEAKER_01:
I don't want to... There we go.

To find... Oh, here we go.

It could be right here.

It must still be running.

No, draft session.

Oh, here we are.


SPEAKER_02:
So one of the things that's also been fascinating is learning all of the new systems all of the time.

And it's like every day I have to learn a new system and it's pretty amazing.

It keeps you on your toes, that's for sure.


SPEAKER_01:
So let me edit the, oh wait, no, here it logs.

Let's see if this pops up really quick.

Thank you everybody for your patience.

I appreciate it.

Here we are.

Let me see.

We should have... Yep.

Let's model complete.

We won't be able to see that either if it's not going to.

Let's see here.

Yeah, I'm sorry, guys.


SPEAKER_02:
I don't want to waste too much.

I don't want to waste people's time unnecessarily.

I know everybody is.


SPEAKER_00:
How about go show the low road, high road, and then we'll see if there's any last questions and that will be good for it.


SPEAKER_02:
Okay, low road, high road.

I'm trying to think whereas I don't know if I I'm so disorganized after the having like, okay, okay.


SPEAKER_00:
Then it's all good.


SPEAKER_02:
Then it's all good.


SPEAKER_00:
Then it's all good.


SPEAKER_02:
I don't know where it is.


SPEAKER_00:
Okay, then you can unsure if that can be basically the end.

How is it gonna continue from here?


SPEAKER_02:
so um i i have to kind of rebuild the model back up um and uh but i'm very confident uh based on the model's performance um that uh once the pro like everything's integrated because that's another thing the mo these models if they're not they they don't just kind of like gradually get the questions or they'll get like

80 one time and 20 another time um it seems for me at least um that there is a uh you you're either getting in the you're either getting like 70 with this framework or you're getting zero percent

There are specific criteria almost whereby the model will be able to perform better, but it's either better or really not at all.

Each framework, for instance, the model that is producing like Archangel 1.0 that produces

uh, uh, the 86%.

Uh, consistent score, right.

Is not the same model in any way as the model that, uh, that I first started with that would only produce 30% and the model that produced 48%, the model that produced 72%, right.

They're all different and structured differently.

And each one has been, um, trial and error, 100%.

And, and

hundreds of hours in the last month and a half i'm like 700 hours in somebody said told me that my the bags under my eyes were going into my cheeks like they were so i thought that was pretty funny okay do you have any last comments or ideas

No, I think that cognitive computing is so exciting, that active inference is so exciting.

There's so much room for discovery here.

There's so much room for creativity.

Everything that, again, that we see and we find is inspiring in every way.

And the implications for how those technologies are employed has broad and very, very, very important implications.


SPEAKER_00:
like implications for humanity i think i i think it's like the next big thing all right thank you benjamin good luck with getting the submission and i hope that you can reduce people's uncertainty which will surely be the realized efficacy of your scripts oh well thank you thank you bye