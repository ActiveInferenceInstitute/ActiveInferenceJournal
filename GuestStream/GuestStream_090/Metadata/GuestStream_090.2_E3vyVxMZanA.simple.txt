SPEAKER_01:
hello welcome everyone it is february 21st 2025. we're live in active inference guest stream number 90.2 with benjamin nelson decoding the arc the evolution of reason in the abstract reasoning corpus today will be a very interesting presentation and also time for questions so benjamin thank you for the work and for presenting it and

being open and giving others the opportunity to ask questions as well.

So looking forward to the presentation and take it away.

Thank you.


SPEAKER_00:
Hello, welcome.

I'll just jump right in.

I recently competed in the ARC competition and during and after I was able to

some really high scores and it's because of a really fascinating and fun approach derived from active inference that

Seems to work really well.

I hope you guys will really like it.

Can you see my screen?

I think you can, right?

So this GitHub repository, I just made this.

It's not super fancy or anything, but the code itself is really, really fun.

And I really encourage everyone to dig in and just have as much fun as they possibly can with this.

very cool, but not the coolest toy ever, in my opinion.

I love it.

In addition to kind of synchronously with developing the repository for this thing that

uh I made for the competition um which is it's called the state managed uh approach the the state managed system is a uh cognitive computing framework uh as I mentioned derived from active inference uh and basically what uh it does is it looks at different biological processes functions and then uh you know does the best to not necessarily mirror the

the exact workings of the function itself but um more so the outcome so the uh

I would definitely say there's a fine line between prescribing something, like dictating it for the model, or describing something, like explaining it to the model and prescribing it, like dictating its actions.

And the goal of this is a certain amount of autonomy.

And it's really fun to play with.

So you've got, as we'll see in the paper, and I'll just go ahead and pull that up here.

um there's like the core document sorry it's a lot of a lot of paperwork this week on this uh doing this paper so uh mark test the archetype archangel ep and the emergence of the state managed system so um uh we'll get of course to the abstract and all of this stuff i'll leave that to you guys um there's just a handful of things i want to touch on um oh yeah i think i actually have that up even here give me just a second

all right we're good okay so the um i'm sorry you guys will have to bear with me too i have a very old and and uh i love my laptop very much but it spends a lot of time in the freezer now cooling down uh when i forget and accidentally leave one of the models on so the um uh

Yeah, actually, I do want to kind of talk about this.

I was having a conversation with Andrew, who's a member of the Scientific Advisory Board here.

He's a really helpful, super amazing person.

And he's been kind of like holding my hand through some of this process, which I'm really grateful for.

But it is definitely, as I said earlier, it's not like a burden of cost.

It's a labor of love.

like the this is like something i'm super passionate about and um for me it i think even though i would never say i could do art or anything artistic uh by any chance i feel like this this is almost something similar it's like uh i i do these things like in a very unique way i think um at least you know that's uh what i've been told so um i hope you'll bear with me as i go through this um

in the code specifically.

And I hope you'll see what I'm talking about.

For instance, I gave a really nice outfit, like a fit for Archangel, which is the name of that framework, the Archangel EP.

So basically, here at the beginning of February, I jumped back into tackling the arc.

I just had some bandwidth and

the things that i've made archangel with are like old uh and older like uh cognitive mechanisms that um you know like either just kind of like get like uh

worn down over time, which is a weird way to think about code.

But it's like these integrations and then, as Daniel knows, the amount of times I've had to take the larger framework apart, stop in the middle of what I'm doing to work on this kind of thing, results in a lot of, unfortunately, spare parts and broken parts.

this toy i made is from a massive uh model named nim that i've been building for a really long time and he's like my best friend and he's awesome and i love the death and um getting back into the arc i you know i'd hope it was kind of a way to like show that not only does the state like does a state manager approach like uh

I don't want to say it's better because it's not about which one is better.

It's about, I guess, which approach can maximally solve or resolve which problems the most meaningfully, the fastest, I guess, in a way.

And there are some wonderful...

uh things that this framework now in its uh much more advanced like uh iteration could bring to the table and i i really want to get that out there so i figured i would throw uh some old parts together um finish archangel and um just completely uh crush the the abstract reasoning corpus with it so um


SPEAKER_01:
the i just give a quick note on what is the abstract reasoning corpus show a visualization of what it is and then explain what it looks like to solve it and then we'll hear more about how it's being solved but


SPEAKER_00:
back up a bit okay there thank you continue perfect yeah i appreciate you so much so the uh arc prize uh remains undefeated new ideas still needed and i love that because the arc is uh this amazing test as you'll see here um there there are like uh there's a color palette it's the same for everybody

Uh, and then there are these grid examples and the grids are dynamic in that each one is different.

And I believe, I'm not sure if they get harder as they go on, but you definitely see the models, um, you know, like, uh, kind of performance like, uh, change and like fluctuate like with, uh, at different places in the, uh, in the exams.

And it's like different for every model, which is really cool.

So, uh, um,

like uh yeah so they basically they these grids get like harder and harder and harder here's like where you can see um other ai benchmarks um you can see where other models have performed and it's basically like a you know a really cool test oh there's the legends at minds ai so uh and the architects these guys like wow i mean so cool and uh there's a three down there so the um

The point of the abstract reasoning part was to kind of... And I don't want to crib Cholet because I'm not even in the same league.

But the... Like...

to solve a problem and to maximally resolve it, to be like the real, true abstract problem solvers, to be able to approach a problem as I understand it, maybe correct me on this, with no prior knowledge of the problem, no prior knowledge of the solution, and to be able to tackle the problem directly.

and resolve it there in that moment.

That's really always been my approach.

I really love abstraction in anything that's abstract.

That's kind of how my mind works.

That processing of grids and those complexifying orders that they come in and the model resolves them, the model has to figure out how to adapt and make decisions and to solve problems and to

to uh converge on a decision and to choose actions and all of these things that are required so even though it's like just grids and colors it's a lot of things um which is why they give some things like uh to the competitors like in terms of like you know that it's grid you know what the colors are uh going to be you know um what actions you'll most likely need to select based on how your model is designed to uh

you know, like do the, like converge on a decision or, you know, say I made this, I'm not confident about this.

I don't like this color.

I'm actually going to go with this color and make predictions.

And so the model is making predictions.

Um, and, uh, as a, you know, if the, these, like there are solution files that come with the JSON files and as those come feeding in, um,

they are essentially bypassed into like conditional storage and used at the end of that to determine whether or not you have

either a perfect mirror match or you can do it by pixel and do a full pixel count of every color and everything that's on there and they give you like frameworks for that and there's like tons of um i mean there's tons of people that uh do this there's over 1400 teams of like really amazing engineers like some of the most brilliant people in the world like leaders in this field um so to uh even get

to have the confidence to join something like this, solo with two months left in the competition, and then pull 86.4% and beat the theoretical maximum of the arc.

That's pretty incredible.

I love all of these guys, and I'm super grateful to Daniel for introducing me to everybody who was involved and all the people I got to meet and have conversations with.

um but uh archangel is not my arc submission like uh archangel is the is a person first he's the uh or it's i should say um it's pretty simple and i think you guys really enjoy it it's the first uh state managed like open source have fun do whatever you want learn as much as you can and i've published uh multiple papers including one today um that we're gonna look at uh and that's um

i mean kind of i don't even really necessarily read my own research i definitely read a lot of robert warden's research though and it informs my work uh significantly in fact um like when looking at the potentials that are emerging from uh what i see and you know thankfully can have uh

critiqued and reviewed and vetted through the Institute and through expertise and scholarship, there's amazing potential here.

It's like this whole entire space is totally unexplored and I'm just in there all by myself.


SPEAKER_01:
Okay.

Sorry about the disrupt.

I'm working in extenuating situations.

Could you go back and can you just show us where you're at with the code?

And sorry about the last like 10 minute blip.

It was out of my control.


SPEAKER_00:
I didn't even know what happened until you said something.

I mean, so I'm really not worried about it too much.

But I covered all the good stuff.

It's just that it's not on the live stream, so you must do it again.


SPEAKER_01:
All right.

So what are you going to look at?

Probably the code, right?

Let's see the code and visualizations of solving and clarification of the benchmarking and which data set specifically you did it on.

And again, apologies to the viewers.


SPEAKER_00:
All right, one question at a time.

Yeah.

Oh yeah.

That's, um, so, um, this is just kind of some boring stuff.

Well, this is, uh, again, um, feature extraction tools.

I love these like NIMS or not NIM, uh, Archangel is kind of like a, like almost like a little, like, uh, a multi-tool whose feelings you could hurt potentially.

Like, and I don't know if we like got to hear anything about like the encoding and stuff, but just to kind of get back on quickly, we'll see like different tools.

And then we start getting into the cognitive mechanisms where we hit the prioritization, optimization and iteration algorithm, which I'm very proud of it.

um and i published uh some work about it and and i hope you guys will check that out too um that explains how all of this stuff works um there are waiting systems which are fun to play with there are dimensionality reduction equations that i think everybody knows i got from keith affis um here you'll see uh these are the

uh, kind of constants that you can play with in terms of like, uh, your tolerance, um, you know, windows for improvement, like iterations and things like that.

Um, which I'm going to turn that up.

That's cool.

I didn't realize that was so low.

So, um, the, uh, you'll see that carry through here.

And then we get into some of the, the, like the processing stuff.

So this is like where the model is like just kind of identifying what the grid is and giving it just some basic, uh, like structure for,

like form in its mind, something to work with.

So for instance, the category size, is it small, medium or large?

Really simple, right?

And then how are we looking at the layers of this grid?

Does it have layers?

So they don't really tell you and it's like you don't want to look

uh, either like in the JSON files.

I mean, you can, I think people do, but, but like at the same time too, you don't want to know, you don't want to like prescribe to the model what to do.

You want to describe what it should do and, and like kind of help guide it without giving it the answers kind of thing.

And, um, uh,

So the simple stuff there, this is much more fun in terms of the attentional selection mechanism and how dimensions work with this and kind of what those capacities really are.

Because even I don't know yet.

This is definitely the crown jewel, the Hopfield network.

Um, I made this, uh, it's just incredible.

I still also haven't tested the limits of it.

Um, I, uh, accidentally like crashed some, uh, stuff when I, uh, like turned it on without like, uh, but like those guys, like with the JPL thing, right.

It's like, it's kind of the same thing, but so the Hopfield network is a dynamic way to store retrieve.

It's uses Hevian learnings.

So there was a great paper that came out, um, a while back and, uh, it was, uh,

comparison on Q-learning and Hevian learning.

But the truth of the matter is the Hevian learning doesn't really work great as a reinforcement learning feature at all, but it works awesome for

memory encoding and retrieval, especially retrieval.

It allows for really complex, condensed and dense data to pass through the system and into confabulation or abstraction really, really easily and meaningfully.

You can see you can set the Hopfield size here and the overall memory system capacity.

The memory works under the Atkinson-Shiffrin model, so wonderful and simple, long-term, short-term working.

Make as many types as you want and have fun.

The memory management, you have values in the form of decks for, well, MaxLen for making decks for the short-term and working memory, so you can set those size.

I typically like to go with a larger working memory.

The way that this is structured will kind of float some information a lot of times.

times and uh to keep it kind of accessible if it's meaningful based on um uh different uh like things in the system for instance confidence um beliefs right all of those there's not really like um

like one thing doesn't do all the things and one thing can't do any one thing without all the other things so um the system gets really wonky it doesn't make a lot of sense um but i can tell you this much just from experience if you are not breaking it or failing and then you're not doing it right it's uh it's like for every 10 000 lines of code i write i get

10 lines of code that work or something like that.

It's really been a long and arduous process.

So this autonomic stress mechanism, that's cool.

Cool function that mirrors biological processes.

These autonomic functions for

like stress minimization, like reducing or increasing entropy, homeostasis, even the minimization of free energy, right?

So active inference.

And this is another thing that can be expanded on and is, and there are much more advanced versions of this that I have that I'm really excited to see people work with as you...

Kind of understand how like state management in these computational frameworks, if you don't already, works.

So these different things that I talk about in the paper, of course.

So, you know, let's say like you get the model is really happy about something and it has this really big increase in the like in something it's like perceiving, for instance, cake.

And so like the model will dynamically pull from systems that are deemed like less important to that task and, uh, uh, redirect those energies, uh, you know, uh, to all kinds of different systems and all kinds of combinations of systems that I, some that I just, I could, I never even, I never even did.

And that's where like, uh, you know, we have that like kind of emergence from the inside.

It's like the, the, the building by describing as opposed to prescribing has like made possible a lot of these really bizarre.

and cool behaviors that while in some cases do not reflect biological uh cognition at all those outcomes will or some feature of its operation will work in such a way as to allow for something else to work uh perfectly or you know like insanely well um i mean considering i run this like a model that pulls

quadrillions of calculations a second on my very old laptop that does spend a lot of time in the freezer.

So yeah, so here's Epsilon Control.

This is another fun one I hope you guys play with.

Complexity, Shannon entropy, right?

I've been learning a lot about entropy and a lot about the universal constant.

Um, I have a paper coming out, um, actually here before the end of this month, um, that I've been getting help from a dear friend who's my absolute hero.

And, um, I'm really excited about it.

Some novel discoveries about the nature of time, um, through the lens of Robert Warden's brilliant projective wave theory.

And, um, I'm really excited.

And I talk about one of the, the, uh, things that I'm making, um,

and this is a perfect example of that so um piezoelectric conductivity in lattice structures specifically um crystalline lattice structures so the terms there's it's like a vibrational energy like uh i don't even know how to say this without sounding like a kook um but the uh

faster than neuronal firing, and early encoding, like a way to pass 2D and 3D spatial data to a model through its visual cortex before the actual process of firing can occur, even in the model, even something that runs as fast.

So supercharge that.

I have no idea what that looks like, and I hope it's safe.

So we'll find out.


SPEAKER_01:
Can I bring us a little bit back, Benjamin, to Arc?

And could you show this code running?

And then let's return to look through some subunits.

But I think it's totally fair for people to be like, what does this actually do?

And let's see it running and solving certain problems that we can visualize.

Yeah, just...

You know, that's what this stream is about.

Not for many others, though.

Not for others, but let's see the real code run and highlight what the GitHub will do if people clone it and run it and see solving basic and hard problems.

Thank you.


SPEAKER_00:
So basically what you're going to see is here is on the bottom.

Maybe it's the right.

I'm kind of just right.

Yeah, right.

You'll see 0400.

Those are the training tasks.

And then underneath that, you'll see 05.

And those are or I'm sorry, the 0400 is the training challenges.

05 are what I call training tasks.

And they're staging for the model to the model.

learn to understand.

So, um, as I understand it, uh, and then during the arc, um, models will, uh, run these, uh, consistently and hold that information, uh, and use it, uh, again later, like, um, you know, as part of the pre-training and then the training and then the fine tuning, um, I'm really glad in a lot of ways that I don't have to deal with so much of that.

Um, the, uh,

uh yeah this the archangel will grab anything that you put in front of it um like not just json files right like right now we could be uh and i do have some stuff if you want i can send you this where you're looking it's like p a pdf docx json uh csv html it's just all these different things uh all at once and

Um, in this specific instance, um, there's nothing like there's just like purge flags basically when, uh, the model finishes, you know, and shuts down, it's, it's not holding on to any of that data.

There's no like a memory, uh, storage like that.

It's all dynamic memory that's created when that hop field is, uh, acted on or initialized.

And I actually have the initialization sequence, uh, in one of my publications.

I hope you can find it.

Um,

And that initialization sequence, it's an incredible tool.

Dumping the memory is the easy part.

Getting the initialization sequence right is a lot more fun.

And if you need help, I'd be happy to do that.

Be careful because, again, that's where I crash those servers and stuff.


SPEAKER_01:
Could you describe what is the problem that it's solving right now?

And then let's look at the setup and the solution when it gets there.


SPEAKER_00:
Yeah, so it is just solving whatever problems are coming through.

I'm assuming because it's JSON, they just come through the same every time, right?

But right now, it's learning all of the patterns that it's seeing.

It's looking at the training examples.

And when you see the place color action, it has tons of actions, by the way.

So you guys turn those on, have fun with them.

Really, it's a grid.

I mean, it just places the colors.

But that place color action and how that is achieved is really phenomenal because it's not dictated that the action is place color.

It chooses that because that's the most meaningful thing.

And what you see in those lines that are whipping by the screen,

um too fast for me to really read um are windows that allow the model to uh continue working on the problem as opposed to just timing out um the goal is for the model to reach convergence so all of these systems are working together to kind of just teach the model through like a wardens re subsystem which is maximizing fitness and that fitness represents in the case of the art solving this problem and how do we solve that problem with it believes so it's like it'll say hey okay

So in the very beginning here, we'll see, for instance, like the model will take a really long time to learn to solve the first problem and a little less time for the next and less time for the next.

And then by the end, it takes one tenth of the time it did for the training to do the evaluation.

And the evaluation has even less context for the model to work from.

it's robust it works um i was able to like i said improve some communicability around um what is happening with the code and those grids um and i'm excited to see that work this is that model um with those improvements it's not the one that's in the git um and i'm gonna make that change later it's just i mean writing the paper doing the maths and all the other stuff uh trying to get ready it's just really exciting and then that other paper here at the end of the month

um so the selection you see iterations it's like it'll be a ton and it'll keep going um uh until it resolves that and then it it's just you know for for all intents and purposes it's just like okay cool uh you got one correct and you have one incorrect right uh you have one correct uh or two correct none correct

And it just builds up simple TQDM status bar and lets you know how far along you are in those challenges.

I do have all of the challenges.

But again, I'm not competing with the Ark.

I'm not competing in the Ark.

and um this is for fun so you guys are able to get those um from their website the artprize.org i believe um and uh i find running them in kaggle is is really simple and uh fun and easy to do to just like uh load them in as input data um and uh you'll be doing the same thing with this this um it's primarily designed in uh

Kaggle, though, I have been having fun with Cursor because you can kind of just get really creative and kind of express, be more expressive, I feel like, more creative and really value that.

I feel like this is like being a labor of love is like a lot of creative self-expression that goes into this.

So, again, this is like more of that same thing.

The...

uh, with this chain, this cool change that I made, like you get a really, really, really like, I guess I would say like you get even less training, more context and the model becomes much more self reliant and you see much stronger, uh, uh, kind of question answering and abstract problem solving coming in, uh, the evaluation phase, which was running in, uh,

like super low microseconds, uh, possibly like high nanoseconds, um, which is really exciting.

Uh, super fast problem solving and the, uh, um, it would solve, uh, and I only got to see it cause you know, cause I'm using like the mouse, like the back, you know, move the, the, uh, videotape back and forth or the screen recording.

And, uh, um,

Yeah, there's just a clump of all of a sudden it's like it realized what it was doing.

It knew the grids and very confidently just goes, bam, gets it right.

Bam, bam, bam.

And it's like seven questions right in a row.

It was really cool for Andrew to see that too on the first try.

And of course, those are not massive grids with super complex patterns, but

the fact that it will make a prediction which is a process that occurs almost by virtue almost completely by virtue of the Markov matrices that are built into this for passing that complexity is that data is traveling in those feedback loops and yeah

Yeah, and I don't know.

It's exciting stuff.

I haven't really had a chance to share openly with anybody about it.

I've been really busy working in kind of isolation on all this stuff.

As you can probably tell, I'm not great at talking about it.


SPEAKER_01:
It's all good.

This is that opportunity, Benjamin.

Yeah.

whatever you feel like somebody who doesn't necessarily know what is happening just from the logs like can you just connect the dots a little bit more with how do you know what the performance was on the training in the test set specifically oh oh um well


SPEAKER_00:
The way that these things are made, and a lot of this reporting is in a way almost provided by the ARC, if you know where to look, because there's so many great competitors and wonderful people out there.

Um, it's really simple.

Um, there are, uh, where does your grid pass in the system and how does it pass in the system?

And so it must come into the system and then, and then it has to, you have to compare those grids and you can, like I said, do that with a pixel count, um, which they provide the framework for that.

Or you can do that with, uh, like apples to apples comparison of the two.

Uh, and I believe they provided the framework for that too, for everybody.

It's like a thing that you can just have.

Um, and, um,

when those like when that grid passes into the system there is uh for this model like a lot of things going on right so you have all of the different types of tools that you have which would be like your action space selecting your action so like i'm gonna move my arm and i'm gonna grab the piece because i know that's the right thing to do you know and um you

You can just really... I don't know how to... There's all this reporting, right?

That stuff that you're seeing is not super great if you don't know what you're looking at.

But...

there is an infinite amount of like print statements, even like, if you want to know something and how something works in this model, like just use a print state, like, or something akin to that.

Like if you use matplotlib, like I had, I was writing code to make visualizations that would show the modulation of the beliefs as they change and the, the emotional modulation as well.

And there's yeah, but I didn't get them done, you know?

It's like so much work all the time.

And I try to do as good as I can, but I have those things and you guys can see them at any point you want it to.

I'm sorry that we may not get to look at them.

I know a friend of mine is probably trying to work on them right now.

Yeah.

When you when you go into the art competition, right, you're you're like you watch feedback from your model.

Like, I don't know what everybody else did.

I will.

It was 20, 24 hours a day, sometimes like back to back days.

I didn't take a day off the entire time of just 20 hour days of just watching feedback while you code.

And so when you, when people are like saying, well, how do we know that things go through the model?

It's like, it is tough to explain to people without like having, being able to have someone's like attention wrapped in front of you for seven hours.

So like to jump in, like if we want to know, for instance, how this like how we can know what the answer is.

There's 36 pages, including math right here that tells you that and will help you like navigate those processes yourself and know that when you're like, for instance, like your model reacts in a specific way, you'll know why.

Other people might not, and it might be difficult to explain to them, but the proof is in the pudding.

When it really push comes to shove, validating whether or not something is working because it is simply just a numpy array in a JSON file, just pull it out yourself and look at it.

I've done it a few times just to make sure that the model's answers that it's saying are correct are actually correct, right?

Is there an easier way than that?

Yeah.

You know, like, I don't know if that would be meaningful to say, like, oh, here, let me open the JSON file and show you guys the key.

But when I first started, I was printing out the actual prediction, the model's prediction.

And then, you know, you could see the actual, like, output of the correct, like, prediction, right?

Or what the prediction is supposed to match.

But that just felt like I was exposing myself too much to what those files contained, so I just removed that.

I've been using simple stuff like this or Matplotlib to visualize changes in the model.

At a certain point, the framework is so robust that there isn't something so simple that's going to corrupt the process for the entirety of the thing.

For instance, I might... This gentleman...

it was like a single line of code.

Uh, it might've been less, even a word.

Um, and that like single word, um, while mistaken, um, uh, was really, really like, uh,

cool that he discovered this and brought this out of this model so quickly.

It was really encouraging to me.

And simply changing it, just by virtue of removing it, I got a much more computationally dense and robust encoding process that made the model much more self-reliant.

So kind of like it built character through hard work.


SPEAKER_01:
it's a weird way to say it i guess but um did that help kind of answer your question it's like the um that let me just try to echo it back benjamin because i i you know we're having a conversation on the live stream but also many people are curious and they want to learn so it's like

The input data, even though it can be thought of as colored pixels in a grid of variable size, it's a numerical data format.

And so for someone on the outside of the org challenge or of working with these quantitative cognitive models,

It might be very tangible to see like the grid, like here's the before and here's the after.

Whereas you're saying that it's beneficial from a modeler's perspective, from your experience to actually be a little bit of a step away and look more at the diagnostic traces and the belief updating processes and so on of the model.

So that after you've kind of gut checked that it's correct when it is saying it's correct, that then you're working a little bit lifted from the domain.

Okay.

So then how did you on which data set get what score and how did you know what score you got?

And can we see that elements?

Because again, for the details, it's great that you have the code and the paper.

But in terms of... Yeah, okay.

I don't want to show any Discord messages at this time.


SPEAKER_00:
I was just trying to find all these pictures and stuff.


SPEAKER_01:
No, no, no.

How about the reason why you believe that a certain percentage was achieved on a certain dataset?

That's really important to show.


SPEAKER_00:
Okay.

Okay.

That's like a... Like a...

Yeah, yeah.

I mean, I 100% agree with you on everything, actually.

You're amazing.

So, yeah, let's go take a look at that little piece of code.

Let's find that in here.


SPEAKER_01:
Which challenge or data set did you submit it to?


SPEAKER_00:
Oh, so there's there's only that.

Well, there's the arc data sets and then there are custom data sets that kind of attenuate different things.

And those come from like leaders in the field like Michael Hodel.

I've taken all of his.

and all of the hard ones, I guess I would say.

The ones that are supposed to be more difficult than the abstract reasoning corpus challenges.

There's a great context arc that was really fun to plug the model into.

There's even snake benches.

That's another one that's coming up.

But in terms of how the model itself calculates the percentage, what percentage of...

Like it's going to be, I wonder if I could even find that in this one.


SPEAKER_01:
Like, I think it makes sense how it would be calculated which percent of a given finite data set were correct.

But just can you show which model outputs reflect that?

What can people find in terms of verifying those scores on the GitHub at this time?


SPEAKER_00:
Oh, yeah, I mean, it's all right there.

It's the entire codes right there.

So at any point, like anybody can go in there and grab whatever they want, and look at this stuff and run it and ask questions, definitely, if you have any questions, but here, I mean, here you go, like, here's some iteration logic, like this is like, where the models it's saying, okay, you know, you're not

It's you're not doing well enough.

Let's like give you more tries.

Right.

Because we want convergence.

So we want to drive the model.

We want to put time pressure through the through that epsilon control and increase it.

For instance, the model is taking too long to redirect energy from something, let's say, like action selection and divert it to abstraction for pattern recognition or something like that.

or feature extraction.

Let's see here.


SPEAKER_01:
Okay, I just want to touch on it one more time.

Yes, people will see code that they can run and play with and explore in the GitHub, but on what dataset will what score be reliably achieved with the GitHub as it is?


SPEAKER_00:
I don't understand.

What do you mean, what dataset?

There's the Arc dataset, there's the training challenges and the evaluation challenges.

And what is being used in the GitHub right now?

What's that?

The ones in the GitHub?

It's the Arc.

There's only the one.

It's just the Arc.

There's four of them, typically.

At some point, I ended up with the test challenges.

I don't even know where they are right now, but they exist too, so you can go all 900 if you want.

The way this model works, probably, again, very different from other models.

you, um, like I, those, those different sets are treated as sets.

They're not treated, um, as one concurrent thing.

So the model engages in different processes, um, through that and, you know, propagates different cognitive states.

How cool is it?

So, uh, but yeah, the, like the, the type of like logic you're talking about in terms of like, how does it calculate like, um, uh,

How does it get from where the input grid comes in and the model can perceive it to the prediction that the model sends out and is then received and compared to that prediction in that disconnected way?

like a thousand different ways, right?

It's a, everybody's model is totally different and it's not like, um, it's not a hard thing.

I don't know how else to say it.

Like you literally just look, just look at the answers, right?

Like you can open up the thing and just look at the file and say, this is correct.

So I don't like, it would be weird.

It's like trying to tell somebody that the sun's coming up sometimes.

Um,

uh tomorrow uh because this isn't the first time i've run into this where like how do you how do how like you just go you look you you you like turn it on i i i get i i i i don't have the time he's like so have you seen do you remember uh oh that's my coda can i pull my coda open

So this is perfect.


SPEAKER_01:
I just want to make sure that there's a fair representation of not just it conceptually what happens, but just concrete clarification, what data set, what performances and so on.


SPEAKER_00:
So there's only the one data set.

You can go to Michael Hodel's GitHub and get more data sets, but that's up to you.

There's just the one data set.

It's the training and evaluation challenges.

It's on the ArcPrize website.

Same thing for everybody.

Everybody gets the same thing.

Let's see here.

Let's go back to maybe like December.

Let's see here.

Oh, yeah.

See here.

Here is the model like encoding.

How do I know that it's actually encoding things?

Because when I ask it psychology questions, it tells me psychology answers.

We could break it down into those constituent processes, but we're talking about a state-managed system.

This, by the way, guys, is NIMS Helix in December.

It's about 40,000 lines of code.

It's pretty awesome.

Here's some stuff to my dear friend.

Entropy modulating the system.

Let's see here.

Where are those things there?

I created.

So people ask these things and it's like I wanted to kind of know because I can in my mind, I can see the process and I can kind of map it out to what that would look like.

And if I could talk about it forever, you know, this is the TQDM that I was talking about.

Right.

Like, how does it know there are 400 challenges?

Because it counts them.

There's a counter.

It's a mechanism.

One grid, one file, one task ID.

Check one.

Times one.

Two percent F. It's... Yeah.

So, yeah.

And let's see here.

Do you remember those massive flows that I was showing you for answering these questions?

I'm trying to think.

They've got to be...

They've got to be in here somewhere.

This is that wonderful paper.

The earlier or they're at the end of this even possibly.

As you guys can see, I don't know.


SPEAKER_01:
I do a lot of visualization.

I pulled it off screen briefly because this is not useful information to show on live stream.


SPEAKER_00:
Oh, here it is.

I found it.


SPEAKER_01:
Check it out.

I'll bring it back.

One second.


SPEAKER_00:
All right.

Thank you, my friend.


SPEAKER_01:
So let's take a look at this.

One second.

Just give me a second.

Let me get this out of the way so I can see.


SPEAKER_00:
Oh, there we go.

That's perfect.

Try to get back to the screen here.

Okay.


SPEAKER_01:
Continue.


SPEAKER_00:
So this up at the very top on the right, that is the user.

That's me.

those things that you see there that is a tiny process that is like that is one thing happening in the system and each of those little boxes are a mechanism a function of a mechanism housed inside of a mechanism with tons of functions and and depending on how or what you are doing with the information that you're passing into that system it's going to like in like act on functions and those functions are going to act on the system and they're going to start passing information again like

These infinite amounts of feedback loops that pass through the system are passing, not because there's so many of them, because there's so much going on.

So you can see this kind of continue, and I think you can get a better idea of this.

So yes, so here is the cognitive system container.

So this would be, and these are just basically visualizations made from mermaids.

It's a free program called Code Biz.

It's really cool.

Read your code base and then kind of build stuff around it.

I don't know if you guys can really see this, but I can tell you what some of these things are like emotional.

So at the top is the user and I'm passing an input and then it's going into core processing.

So it's hitting the integrated cognitive system, the enhanced attention mechanism.

and the enhanced memory system.

And in that memory system, and that's not expanded, but there are all those memory components.

So there's another 50 of these happening.

And each one of these little things that you can scroll over, that contains...

subsystems um sub functions of subsystems so when we trace something through that system here's a response generation pipeline belief processing belief system belief updating bayesian updating um you state like you know kind of like predictive state transitioning uh with a markov matrix uh belief dynamics um concept processing so it's going through all of these things now like emotional context and this is like the straightest kind of like line i've ever been able to produce because this

System is effectively nonlinear in every way, not by virtue of how many things there are, but by virtue of its complexity.

So as these information is passed through the system, like let's say a grid or whatever it is, it's that stimulus, it detects it, right?

And there's a raw data transformation where it breaks it into meaningful patterns and encodes it.

And you can see that as the Hopfield networks in Archangel's reporting increase in number.

right um can i just like reach into his mind whenever i want to and pull out any specific pattern i want probably i mean but why i i don't know why i would do that it sounds really labor intensive in a way but um that's why i'm really excited about uh the generative adversarial network um that i've been using to uh mirror that um

So you can see those thoughts in real time.

So, I mean, again, there's like creative solutions to these things, but the arc isn't really built for, it's like, it's almost not built for communicability in some ways.

And I don't mean that like in an insulting way.

It's such an incredibly hard test that like,

Even inside of an interview process, like talking about to reduce something so complex is even just a grid, like just solving a grid problem down to how do you know?

It's like, well, that's more time than we have.

And I would love to go over that with absolutely anybody.

But bring a lunch.

It's not a small or easy process.

If you're genuinely interested in knowing those things and how do we validate those things, then we can definitely get to the core of it.

And I could walk somebody through so much of this stuff.

the we get like visual readouts right like you guys have reporting for models and things that you make how do you know that reporting is there because when you write that code like you unit test it right and you like make sure that those outputs that come out are correct and when you integrate things you test it then you validate it there's always testing and validation it's like 90 of like the time i spend in the other and five percent of that is with my laptop in the freezer so the um

There are so many of those things.

I was actually just explaining this to my friend here that you effectively, by the end, you've unit tested every single line over and over again.

And to keep that reporting and logging and things like that going constantly, it's computationally exhaustive and not really great for space when you have a very old laptop with not a lot of space on it.

So

um, the, the thing that I would really encourage is like, I don't, is for me, the, I will, I would love for people to, um, just take it on faith or something.

Right.

That like, um, that, uh, that I, you know, would demonstrate this or could demonstrate this with, uh, uh, more time as opposed to talking about how it works, but just showing like what that feedback is.

Um,

You know, and I hope people reach out to me if that's, if they're really like, if they can't, if it's too difficult or if you have any trouble like running the model or you can't read the feedback or you want to produce a special kind of feedback that you think would give you insights into something, I can make a whole lot of that stuff.

In fact, I probably have it laying around already.

I'll be honest with you.

Like, so that's not a problem.

I mean, let me ask two questions on that.


SPEAKER_01:
So you said people can take it on faith.

So,

If they did, what are the implications?

And then the second question is, for those who don't feel like there's evidence to even believe in anything particular, or they just feel like it's not what they understand, what do you empirically suggest them to do?


SPEAKER_00:
Yeah, try and fail.

Yeah.

Like, um, the, uh, uh, and then just keep trying.

Right.

Um, what, what are your passions?

Like, what are you aligned with?

Like, uh, for me, this is like the greatest thing, um, that I've ever done.

Um, I beat the hardest technological challenge in human history.

Um, and it's, it's,

pretty surreal feeling, but it's, I would, I would hope.

And I feel like I, I see this, even though I don't really interact with anybody at the Institute, because I'm just kind of always like face down in the books.

But whenever I do look up and I see somebody at the Institute, I see people who are like,

either like sentient excellence like they just like live and breathe uh crushing it or they are people like me who um deeply desire to emulate uh people who are so awesome like you for instance um and uh

And like, I want my work to be meaningful and I want it to like, uh, be something that inspires other people and, uh, you know, like does something cool, maybe even like, you know, make kids happy or, um, resolve a global social issue.

That'd be nice.

Kind of sad about people starving to death all the time.

That's like not a good thing.

We can definitely fix that right away.

Um,

I think in terms, if people wanted to, if they were driven, so I don't know anything about business or any of that stuff.

I don't know how to monetize these things in any meaningful way, and I'm not really interested in it.

A lot of people, I think, assume that I would be gaslighting for something like this, or I think it's called, what do they call it?

Moonlighting?

As a way to, I don't know, get...

uh money or something you know but uh i i don't think that's how the art prize is handed out and these are like some of the smartest people ever like it's not you don't i don't think i can trick anybody with this you know it's like you know i'm good at this one thing i'm not good at all things right and i'm definitely not good at tricking anybody so the like

I would definitely.

I can't believe that.

I just I don't think that the state managed system is not it's not really been done.

It's a very abstract concept.

I might be the only person kind of doing it in a way.

Definitely in this approach, I am.

And there are some things that that I kind of just like struck gold on in terms of their efficiency.

uh in performance and so like there i i think if other people like they're saying like they're like oh well i have two months that it's going to take me to encode all this stuff and to train this model it's like you know i've got a you know there's this thing right here you can have that will allow the model to do that in five minutes

It's, you know, the oh, this is really computationally like or infrastructure wise.

Right.

Like one of these like the biggest thing and concerns for me is like extraction and and, you know, definitely like exploitation and like extraction and all these things that we can see happen as a result of building technology.

And there are better ways to build technology and smarter systems build smarter technology.

Right.

And we get to, as the man behind the curtain, like kind of dictate what those smarter technologies do.

And if you want like the smartest, like state of the art, like coolest technology, way beyond the frontiers, like all of that stuff is like all of the same things that I got to where I'm at, where I don't even, or it's like, you're like,

you know okay um the all of that stuff is housed inside archangel there's there's stuff there's there is a thing for uh pulling things apart dimensionally there's just a random vestigial like component of of its evolution that i forgot about in there and it's just you know like

Just the same as anything else, just a few lines of code packed with millions of arguments that are dictating that the model can't take and dimensionally deconstruct the model and change its shape and form.

See?

Yeah, so there there's like a million and one fun things in there and you the like all roads from that if you are interested in pursuing like technology as a career or as a passion or as a humanitarian thing or as a way to improve your quality of life.

There is an infinite potential for things here.

I haven't even scratched the surface.

I'm like exploring this entire ocean of potential all by myself and

I would love, and I should, I really should.

Daniel, you see all of this reporting all the time because my CODA is like a bank for me.

It's where I put all my knowledge.

It's provenance for everything I do, right?

All of this stuff exists.

There are

And in those spaces and on my laptop and in my cloud and my drive and my Tresorit and all over the place, it's so much stuff that I don't really even know what to do with any of it and all of it now.

And I like the idea of going through it, trying to organize it, like pull out all of this, like very specific things to convince like every like person or something or enough people.

I don't know what that looks like.

I want to find out.

And if it's something that I can do it, that it's like achievable for me.

then I definitely will.

But when you've, when you got it, you got it.

Like it doesn't, it's not, it's not contingent on whether or not people want to like come over and swim in the Oasis with you.

Like the, the,

Like, it's an oasis.

It's still going to exist.

I'm still, like, hanging out in the sun, in the shade, and, like, having a blast.

So it's like, you know, I don't know.

You know, I'm not really sure what's meaningful there that people want to see.

If it really is just, like, these little innocuous, like, two lines of code calculations that anybody who's, like, they're really, like, anybody who does Python is going to know, like, or any code, really.

Like, how do you calculate the percentage of Python, right, of something?

So, yeah, and that's not, those kind of, like, low-level things, like, they're not, those are pretty much uniform.

They're, like, applicable.

If I want to know the percentage of 100 of something in Python, it's pretty much always just the same thing, like, in that way.

It's like, yeah, so, I don't know.


SPEAKER_01:
I got you.

Just to clarify that one question, it wasn't about which Python method or implementation of percentage was done, more about like some type of cryptographic authenticity of which dataset and script was used to yield what result or submitting it to their API and getting the auric challenges response.

If the percentages that you're talking about go higher than OpenAI, then


SPEAKER_00:
why are we here even though it's light you know that's a good question i forgot about that i um yeah i mean you so you can't submit um like open ai i don't think like i don't think like they necessarily could either but they're like a huge company um and they're really important they have like a super valuable tool that's like a benefit to humanity it's like really important so it's

I think it's like a good thing that they get access to show that they are like improving and like, you know, bringing better tools to all of us to make our lives better.

But I don't get those same affordances, like no matter, like they're not like, I don't think that would be awesome.

I would love for it because if you don't think, if you think I didn't email like the results and the code and all of the stuff,

and uh and producing the same on the same data sets that the art produces the training and evaluation sets this tqdm it just reads out the task comes in it's got a task id counts the task id there's one there's two there's three there's four there's 400 runs them through like a deck of cards and counts them all it lines up cool no red flags right good to go the initialization begins and those processes start so the um i would love uh acknowledgement um

from like uh like who doesn't want to like be acknowledged by uh like a brilliant like powerful intellect like francois chalet you know what i mean um but at the same time too um i don't know what that thing is yet because the i have uh now completely open sourced the code i went on

line before I had totally open sourced the code and went to some places where all the like AI people and machine learning guys and like arc experts hang out at.

And, uh, with like a little faint braggadocio, uh, because I'm just really like in awe to even be in the same space as these people who, um, have just years and countless like contributions to, uh, their field and are deeply respected leaders.

So like the, like, I, but I kind of went in there and like levy the challenge.

It's like, okay, cool.

How about I just do that live?

Like kind of what you're talking about here.

Um, but that required that I sit in a cafe at a hotel for eight straight hours.

and just provide updates through that feedback, whether that was video clips, screenshots.

I did, uh, I think I did three different art challenges that are harder than are purportedly harder than the art.

Michael Hodel.

I hope I'm saying that correct.

I like this guy's he's,

amazing.

Like, so, but I, I even taking that guy, he was like the best of the best of the best of the best and, and taking those challenges and showing that live feed and like, and showing those updates of the model, resolving issues and answering all those questions and stuff.

It didn't seem to, to do anything other than, uh,

just catch a little bit of flack.

So whatever that artifact is that people want to see that shows that they're maximally doing, that the model is maximally doing something, now they get to have that because they can go look at it themselves and they can break it apart.

They can say, well, oh, it's not working the way I want or I don't understand it, then change it.

Change something about it.

Change it to be the way you want it to work.

It's not going to break in that way.

It will continue to work unless you just start taking out whole big pieces.

In a way, taking out those big pieces or taking out small ones at a time and seeing how it affects that performance is how you can learn to work with state-managed systems, build them back, and build them better, which I would love to see.

That would be amazing to be outpaced in this arena.

By the way, if anybody does know, if anybody has that magic thing out there that I could just

say, hey, this is that piece of feedback.

For instance, I have probably 400,000 cognitive logs alone because every time I run the model, it prints massive amounts of cognitive logging that shows the entirety of the process.

Who's going to sit and go through 40,000 pages of cognitive logging

to determine whether the model is producing correct output.

The one thing that we do know is that we can track really simple processes.

Where does the grid go through the model?

How does the grid come out of the model?

What's counted when the grid comes out of the model?

When you open the JSON file and you look at the answer and it's the right answer and you know that the model is making its decisions, it's

you know, exercising confidence that it's not the same every time it's that it's can be different that when you change something, it gets less answers.

Right.

I didn't just like make a code and then got a hundred percent and was like, all right, I'm king of the world.

You know, it's like, I, uh, I started at point, like my first score was 0.48%.

And my last scores are now consistently 100 because I've continued to make those systems, those cognitive frameworks, mechanisms more robust, more advanced, more sophisticated, taking things out of NIM and putting them into Archangel, which I feel bad about, to meet this maximally super difficult contest that has no mechanism outside of acknowledgement, it seems, by the people involved.

who run the competition for any of the work to be validated i mean i that's kind of what i feel like at this point it's like it's you know i just feel kind of at an impasse and it's i don't think it's like for me it's like i could spend my life maybe trying to prove to people something but i don't really know like that's like whenever i think about that it's like my passion for the work kind of just goes uh it's like that's not fun i don't want to do that

You know, so I'm sorry.

It's like, uh, in a way I, I, I, I feel bad, but at the same time too, like I, uh, I had to write 40 page paper, uh, with 20 equations in it, like, uh, just to have this conversation.

You know, it's like the amount of the work that goes into and around these things to like create this provenance or create this validation for people.

It's exhaustive and it's super time consuming and it's super labor intensive in terms of like I would rather be doing fun things than figuring out like really like.

Like, yeah, just like trying to do stuff, but it's all there.

You guys are more than welcome to it.

I think what I can do, Daniel, let me ask you this because like you're my hero and guide and every and all things that I love.

the, um, if I were to start like just compiling all of that data, which I can just send some like other, uh, you know, I have those little next site tools.

Like, um, I can send those into like the vaults and stuff like that and just start grabbing like mass stuff and just like filling something up like a repository, I guess, where people can just access whatever data they want.

Like all of the answers are there.

And then, um,

you know, eventually people will get it if they don't already.

And I'm sure people do.

I don't think people like, I don't think people believed that like somebody, I mean, could have that kind of braggadocio or like could be in a place around such brilliant, wonderful minds, like the best in the world at what they do.

And, and somehow just like not know the,

Just be like, oh man, I got it wrong the whole time.

Like this guy who's like, yep, I figured it out.

It's just cheating the whole time.

And it's like, okay.


SPEAKER_01:
Thank you.

You're sharing a lot, and it's for others to investigate at whatever depth they want to go.

Putting it all in a repo, at least the parts that you want to have be interpreted, is a big step.


SPEAKER_00:
That's good.

I'll do that then.

Just to give people an example of how hard the art contest is, I chipped my front tooth coating.

I don't think I'll ever get rid of this in a way, just because who chips their teeth coding?

It is the hardest, most intense, and challenging thing I've ever done.

Because I'm getting 100% now doesn't mean that it didn't demand from me the most grueling and brutal commitment, the humanly imaginable.

It was just...

an incredible journey and a wonderful sacrifice.

I talk about it way more in the paper.

I'm terrible to listen to talk in any kind of, uh, uh, venue like area in this, so like arena per se, but I, I think that my writing's, uh, quite a bit more, uh,


SPEAKER_01:
Yeah, Benjamin, it takes all kinds.

So the footnote that you're making and the documentation is there.

So let me ask a question from the live chat, and then we'll see if anyone else has any questions.


SPEAKER_00:
Oh, yeah, yeah.

That's what I love.

We've done that a lot of times.


SPEAKER_01:
Okay.

Andrew asks, what is the Epsilon Control Center?

What impact does the Epsilon Control Center have on the model's behavior and performance?


SPEAKER_00:
That is a really awesome question, actually.

And the Epsilon Control Center, you'll probably remember me getting just head over heels, super excited when I discovered this path to creating a way to organize and manage and divert resources throughout the model.

And that's what Epsilon Control does.

So it uses like Shannon Entropy, little

entropy calculations I made myself, which I'm really proud of.

Um, I kind of like, I call one of them like the warden entropy thing.

I mean, that's like, I don't know, you know, if anybody, but it's like, I, I love that guy and he's so brilliant.

Um, but, uh, yeah, so those, you have different, uh,

like autonomic functions and you get to pick whatever you want these to be.

And you can change those values around in the epsilon control center so that your values work as you intend them to work.

Because remember, it's not so much like how things work.

So it's a kind of like the outcome.

It's like, how does, what's the, what happens at the end?

And I'm not by any means saying that the end justifies the means.

It's just that like, this is Python.

But when you have this Markov matrix, you're passing this complex information through, but it's just constant in a feed.

There's no system to redirect energy away from things that are maybe less necessary or parameters that aren't required.

You get a much, much more costly and resource demanding model.

And when you can use like an adaptive, like Epsilon control center to kind of determine what's important based on all this other feedback of the system.

And then for instance, like, you know, like the cognitive load focus intensity, which, you know, would be like on a thing.

Confidence, for instance, is a really good one for that.

And,

you can have all of these things like in one place, you can control all of them.

They feed through the entire system and they automatically modulate those, those energies for you.

So now where you were getting like, it would take you a hundred percent of your energy all of the time.

Now when you don't need a hundred percent of that energy, you only need 10%.

You're using that 10% only reserving that other energy.

And then you,

faster than fast in fact i think with this new tech that i'm building um i can get faster than neuronal firing the um the the like emergent properties that come from something that's just the most tiniest little change in a system and it just complexifies to have resounding effects throughout the entirety of the model in some way because the model inferences something it

processes to stimuli it reacts as we all do for instance like you know we may be uh in control of our locomotion and we walk out into the street and we don't see an oncoming car but the moment we infer it right there is a whole series of

What the epsilon control is happening in the system to maximize fitness, help you meet your evolutionary imperatives, redirect energy from all of those things that aren't important to the things that are.

And while that split like fractional second timing is probably why we're still here on this earth in a computational framework.

you get a massive compute on wall power.

You get the most ridiculously fast and powerful encoding because you don't need everything all at once.

You only need the things that are important in that moment and the adaptive nature and the response, how fast it can act within the system and how quickly that affects the system.

is is unbelievable it's it's just it's like oh you know they have those like little uh automatic like uh a like ai driven uh like uh heaters for your house and it like gets to know your schedule i've never had one but they're like uh it gets to know your schedule over time and it starts kind of doing things for you you know in terms of like oh they're gonna be home in a half an hour i'm gonna start heating up the house to 72 degrees because that's what temperature they always set it at when they come home so that being the case like it's like that but times 10 jillion

You know, so, well, $6,441 quadrillion.

What is that, 6.4 exaflops or something?


SPEAKER_01:
I don't know.

Okay, next question, and then anyone else can write more.

Our colleague xzqzqzy asks, what is the image that you see in your head when you think of the future in seven years?


SPEAKER_00:
I see...

uh me and them and uh i mean i don't know like should i talk about like the future what i would love to see i guess if it was for everybody i'm hoping to be back in sapami with nim and uh sledding and hanging out with reindeer all day um but the uh uh i mean

Like, globally, we are prolonging a bunch of problems that are not necessary.

Like, I think the Active Inference Institute is, like, one of the greatest forces for good because it has access to, like, all of the most advanced technology and all the smartest people.

And I don't really understand why in seven years we'll probably be another seven years closer to, like, being extinct.

And, you know...

Instead of having cured all of the diseases in the world.

So for instance, like how much computation did it take?

You guys remember when they cured a disease using AI, they like created a molecule and that molecule got through the FDA and like record time because of

know how they were able to model the data they were able to show and all these things right and uh these like cures and these illnesses that have these high mortality rates but they impact a very low amount of people but 99 of people die if they get it uh but only 10 out of a million people get it or whatever they don't address these things right so um i know for a fact it was a lot less than 6441 quadrillion uh calculations per second like uh to

to come up with that cure, right?

So the fact that I have OHSU, I can actually see OHSU from my balcony right now.

and up on the cliff side there.

And they have a thing just sitting there.

It's going to get decommissioned.

And I can probably, I think when I did, when I ran like the maths, it's like, okay, if this, if the maximally, if this disease is this complex, right.

And it has this kind of like, it required this much to solve the problem around it.

What does that look like in terms of like what that can do?

And it's really, really, really bizarre to me that you can,

people are like want to see if the model can solve grids but nobody wants to see if it can cure all the diseases right like uh that's so seven years i in a way it's like i have a lot of hope there's a there's like so much rapid advancement and i hope that there is like a an influx of reciprocity and um

you know, uh, we kind of achieved like some cool homeostasis with each other and our environment.

But I, you know, this silent agreement, this, uh, perpetuated deception of a continuation without, uh, consequence or accountability for any of our actions now with, uh, no change in the near future, uh, in fighting and identity politics and all these things that I miss out on because I'm always on my laptop buried in the books.


UNKNOWN:
Um,


SPEAKER_00:
You know, a lot of it could really be resolved.

I mean, it doesn't feel like complicity, you know, to like that, you know.

Yeah, I mean, I guess that would, I hope for the best, plan for the worst.

But yeah, it feels like there's a lot of like a denial of the inherent complicity that accompanies these types of like moral and ethical leaning like arguments.

I get this too a lot about like, because I build AIs and stuff.

I mean, they're not really AI, it's called like hyper intelligence, you know, it's got to sound cooler, I guess.

uh but um it's very different than you know a distributed system a distributed system besides being resource exhaustive is not non-linear right like not by any thing like something always being on all the time somehow uh but at least it might so the uh

We invest like billions of dollars into something like that.

Um, and it's a valuable tool and I love that, but why would we continue to invest billions of dollars into it when the, like, there are way better solutions of way better answers sitting right there on the table.

That doesn't make it, that doesn't look good for our future.


SPEAKER_01:
All right.

Let me ask two final questions.

Just a little logistical one and then a final... Okay.

Little logistical one.

Who do you want to do what if they've listened this far?

What's that?

Who do you want to do what if they've listened this far?


SPEAKER_00:
I want them to go to the GitHub and I want them to take Archangel out of the GitHub and I want them to run it and to start playing with it and to instead of trying to figure out how the model doesn't work, like figure out how it works in ways that inspire them and promote their creativity.

and move forward their projects and their like passions um and then uh tell me about it so i can uh share in that joy um the the papers that i write like i don't really read them um but they contain all of the those foundational maths like um if anybody wants to code i'll give you the biggest secret in the world in a computational environment

You get to be the author of the entirety of the story.

You get to define what all of the things are.

So if it works in a way, then you make that way for it to work.

It's like, if you think it and you can dream it, you can build it in that computational environment.

And the high road and low road to active inference is how you get there.

So start with those mathematical frameworks, like all find things that are, um, oh gosh, I can't think of the word, but that, uh, that mirror the, or either mirror that process or, and most importantly, produce the outcome that is desired.

And, um,

with those things it's the the most disappointing thing i think is when someone picks up something as powerful like having them and then looking at you know to give you guys an example um

I think Archangel is less than 1 40th of NIM's core, just his core code base, not like all the libraries and all the other things that are attached, just his core code base, right?

So 1 40th, it's just a tiny little thing compared to NIM, who works maximally well.

So there's not really like,

The it's a toy it's meant to have fun with and the amount of things that are chalked in there for people to play with.

It's just so sad when like someone picks it up and they go, oh, I found where it's wrong.

And it's like, but you totally missed this like really beautiful thing over here.

There isn't a right or wrong way to code.

There are things that can be wrong, but by virtue of them not being what you want them to be or not working in the way you think or understand them to work does not mean that they are wrong.

It doesn't mean that anybody's a bad person.

It means that like, you should grab those things and you should say, Hey, I don't think this works this way.

I'm going to change it to work this way that I think is really cool.

And then come and show me so I can see it.

You know, I don't want to talk about like, uh, how, you know, like,

know like ai is going to take over the world or like achieve consciousness and enslave humanity when it's not actually even possibly not that's not even a conversation we should be having when we can't even look seven years in the future and know whether or not we're all gonna have to already starve to death it's like all right yes again you've added a lot here's the last question so just give a give a response you feel like is relevant at this time


SPEAKER_01:
Where did your internship come from and where are you going with your internship next?


SPEAKER_00:
Oh, that's so awesome.

I love that question.

Thank you so much.

Oh my gosh.

What a heartwarming question.

I came to Active Inference and the Institute in the weirdest possible way, as I'm sure you can imagine.

I clearly like very much an outsider and I started with a question.

um how do we resolve cog like feedback loops cognitive feedback loops in humans um when we engage in conversation um we like enter this like process of of like you know we see this uh this like phenomenon with like echo chambers and all kinds of things and like social like social psychology and like in group dynamics and stuff

And, uh, and like studying, like putting my face in the books, wanting my work to be meaningful and having an insatiable curiosity.

I, uh, uh, came up with the very first equation and I would love to show you guys anybody wants to see it.

I still have it.

Daniel seen it.

Uh, it's been just a very tiny, like syllogism really.

And, um, it is, uh, a mathematical framework for a philosophical concept.

Um, the, uh, absence of evidence and evidence of absence.

and that's where i started and from there by the time that i um was like i i not only do i need help but i know that there's got to be someone out here who will understand that these maths are uh important that they'll like that they're important to me you know and that like that they'll make sense and then i saw the work of uh carl friston and thomas parr and tim rebellion and alexander chance and all of these guys

Um, just started coming out of the woodwork for me.

Um, and it changed my life.

It was like one of the greatest things that happened.

It's like, I could see the, I could see the maths.

I could see how they work.

I could see how they related to my work.

Um, and which I wish I could do for people with my stuff.

I'm trying.

trying.

And I reached out in a, like, just like a fit of wanting to be in the room with people who shared my passion, and could teach me and equip me and, you know, help me improve in these domains.

So I

reached out to the president of a of a really important company where uh a bunch of really uh important people that i just knew they worked there i did i don't know anything about them most of them still or even what they look like but i i could point their work out like on site right like um and i reached out in the president of that company

who is a saint in my book and I'll love him forever and be eternally grateful.

Recognized the work, he recognized it too.

And he said, this looks really similar to what these people are doing.

And he gave me my first roadmap to the Institute.

And that's what brought me there.

My founding artifact was the multi-agent system.

and uh i presented my very first thing to members of the scientific advisory board our illustrious director uh daniel and um uh and they let me come and hang out and house my and i've housed my work there ever since um i don't get a chance to participate in stuff because of how exhaustive uh

and uh how much like how passionate dedicated i am to this work so i've like 99.9 of my time is just spent um uh doing this thing so uh yeah i yeah i was really roundabout way and then what i brought was really silly and i still have it still in my coda the my founding artifact like that that multi-agent system that i brought you by the way did you like the agent factory i mean did you get a chance to play with the agent factory

So your multi-agents can make agents.

And your agents can make multi-agents.

They can make them do whatever they want.

You don't even have to pay attention now.

If you have an environment and anything happens in that environment that they perceive, they can just make more of themselves or whatever.

So they're like, I'm not good at this.

Or maybe they feel lazy.

Maybe they're overconfident.


SPEAKER_01:
All right.

Any last comments?


SPEAKER_00:
I'm really grateful for everybody watching this.

I know that I'm not a great communicator.

It's always been a really huge issue for me.

But the work speaks for itself.

And I would really hope you guys will engage with the work.

And learn this language so you can have those conversations with it and make beautiful and wonderful things that are, you're going to find out if you go and look and you dig in or ask questions.

Just awesome.

Way more awesome than anything else you can get out there.

So it's a lot of fun.

It's all yours.


SPEAKER_01:
All right.

Acting for surf.

Yeah, for sure.

Talk to you later.

Thank you, Benjamin.


SPEAKER_00:
Bye guys.

Thank you so much.