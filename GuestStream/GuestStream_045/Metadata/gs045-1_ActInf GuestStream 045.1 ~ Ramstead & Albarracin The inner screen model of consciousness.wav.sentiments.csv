start	end	speaker	sentiment	confidence	text
6570	7614	A	0.872096598148346	Hello and welcome.
7732	10718	A	0.8484060764312744	It's June 19, 2023.
10884	17534	A	0.9106110334396362	We're going to have a presentation and a discussion with Maxwell Ramstead and Mal Abarasan here.
17652	21050	A	0.9503171443939209	So thank you, Maxwell and Mao, for joining.
21130	26482	A	0.9850708246231079	Looking forward to your presentation, setting some of the context, and then thank you to all of our guests.
26586	33010	A	0.7422622442245483	You'll have an opportunity to introduce yourself and give some background when you first give reflections.
33090	35634	A	0.7679586410522461	So onto the slides.
35682	36630	A	0.654767632484436	Maxwell.
37130	37762	B	0.5708940029144287	Excellent.
37826	44586	B	0.6247590780258179	Well, maybe now and I can just briefly reintroduce ourselves for those of us watching at home.
44768	48086	B	0.7754416465759277	So, hey, folks, my name is Maxwell Ramstead.
48198	52270	B	0.8543363213539124	I am the director of Research versus AI.
52850	60750	B	0.6963529586791992	I am a scholar in the tradition of active inference and an expert on the free energy principle.
61410	61822	B	0.5491447448730469	Yeah.
61876	63194	B	0.7132864594459534	And mao.
63242	64400	B	0.8186510801315308	Would you please?
65570	66222	C	0.4753468334674835	Sure.
66356	67086	C	0.617027759552002	So.
67268	68862	C	0.8499742150306702	My name is Malva Hasan.
68926	70686	C	0.9233626127243042	I work at Versus with Maxwell.
70718	77874	C	0.7219333052635193	I'm Director of Product for Research and development, but I'm also doing a PhD in cognitive computing.
78002	85206	C	0.796893298625946	I worked in social sciences and in artificial intelligence in the artificial intelligence field.
85308	100540	C	0.6948921084403992	And I've specifically tried to apply active inference to more socially grounded questions and sometimes more abstract and representational questions, diving all the way down to the philosophy that can be attached to it.
103180	104440	B	0.8805532455444336	Thank you, Mal.
104880	108076	B	0.9874817132949829	So, yeah, I'm very pleased to present this work.
108258	117580	B	0.8404108285903931	Today, Mao and I will be discussing our new preprint called the Inner Screen Model of Consciousness.
117660	126240	B	0.8216057419776917	And it is about basically an application of the free energy principle to the problem, the conundrum of consciousness.
127460	140890	B	0.6972669363021851	So just to give a little bit of background and now I'll just be walking through the slides, if at any point you want to jump in and add complete correct, please feel free to do so.
142220	147944	B	0.8974698185920715	This is work that started in late last year and continued throughout the year.
147982	152010	B	0.6532984375953674	It's preoccupied us quite a bit, actually, over the last while.
152540	171132	B	0.6116276383399963	Mao and I are the lead authors on this, what has now become a series of papers, with one more preprint coming out, hopefully before the end of the month, and another in the works, hopefully before the end of the year, with the same core group of authors.
171276	179300	B	0.8820542693138123	So obviously Mao, as well as Adam Saffron, Alex Keefer, Brendan Klein, Chris Fields and Carl Friston.
179640	184128	B	0.8694570660591125	And the follow up papers include a bunch of other authors.
184224	192230	B	0.973546028137207	So we've been working with some pretty cool folks on this, folks listed here and others.
193240	194036	B	0.5491447448730469	Yeah.
194218	204468	B	0.8552550077438354	So the overall aim across the two or three papers is to present something like a minimal, unifying model of consciousness premised on the free energy principle.
204564	217680	B	0.7571085095405579	In the paper that we're discussing today, we are presenting, as I was intimating a moment ago, a model of consciousness that follows directly from applying the free energy principle to well understood human neurophysiology.
218660	224512	B	0.6614576578140259	The take home message of today's talk is that, well, let me take one step back.
224566	233904	B	0.8468913435935974	There has been a lot of discussion in the literature over the last decade about whether the free energy principle has anything unique to teach us about consciousness.
234032	237060	B	0.8172762989997864	And there have been responses pro and contra.
237960	242224	B	0.5311776399612427	And I think that the question up until recently was just unsettled.
242352	245930	B	0.733561635017395	We would like to suggest a positive response to that question.
246540	257768	B	0.6924137473106384	And as such, one of the take home messages is that actually, yes, a model of consciousness can be directly derived from the free energy principle applied to explain known neuroanatomy.
257864	274400	B	0.784110963344574	And I guess the kind of technical message, the technical part of the takeaway is that consciousness has or is isomorphic to a nested holographic mathematical structure.
275380	279990	B	0.6757152080535889	So this sounds like a mouthful, might sound a little crazy.
280520	283780	B	0.904495120048523	We are going to unpack this presently.
286200	288710	B	0.848030149936676	Now, did you want to add anything to that?
289560	291240	C	0.475308895111084	No, all good.
291390	292360	B	0.5708940029144287	Excellent.
292860	311560	B	0.5512121915817261	So the original paper that we wrote turned into, like a 24,000 word monstrosity of a paper, and it was elephantine both in the sense that it was very large and also in the sense that of the soupy parable of the blind men and the elephant.
311640	322800	B	0.8813022971153259	What we're trying to do is in some sense, identify a parsimonious mathematical structure that underwrites the different accounts of consciousness that have been developed based on the free energy principle.
323220	326028	B	0.7632585167884827	I'll spare you the original paper structure.
326204	331204	B	0.8933014273643494	I said a moment ago that we were developing a minimal unifying model.
331322	340664	B	0.6975910663604736	This is a notion that was proposed by our friend and colleague Vanya Visa, I believe, a few years ago now, in 2020.
340702	357624	B	0.6264001727104187	And Vanya at the time was noticing, well, the field of consciousness studies is replete with a bunch of different models and theories, and there seems to be no end in sight to the multiplication of these theories.
357752	376540	B	0.8360514044761658	And the idea is maybe what the field needs is not one additional N plus one theory of consciousness, but rather a minimal unifying model by which Vanya means a model that specifies only necessary properties of consciousness.
376620	385590	B	0.6342212557792664	So this doesn't come with, like, a strong sufficiency claim, really, like, what are the kind of rudimentary building blocks that are necessary for consciousness in general.
386200	390004	B	0.7960993051528931	This model would have determinable descriptions that can be made more specific.
390122	395672	B	0.7931531071662903	So it's kind of a base model that can be expanded to cover different varieties of conscious experience.
395806	405980	B	0.5654420256614685	And finally, that it's minimal and unifying in the sense that it integrates current approaches to consciousness in no small part by highlighting their common assumptions.
406960	413496	B	0.6289768815040588	So kind of pointing to a least common denominator of all existing accounts.
413688	430960	B	0.840167760848999	And so what we have tried to do in this paper is to well, in this series of papers is to engage in this analysis and this mummy analysis, if you will, for theories of consciousness premised on the free energy principle directly.
431120	434340	B	0.5584254860877991	So it's worth quickly discussing the free energy principle.
434680	442090	B	0.45237818360328674	I'm almost embarrassed to do this at the Active Inference Institute, but it's always worth going through this very quickly.
442620	449572	B	0.8750174641609192	So there's a standard distinction in physics that one can leverage between dynamics, mechanics and principles.
449636	453500	B	0.815021812915802	The free energy principle, as it says on the tin is a principle.
454000	461692	B	0.8682207465171814	So principles are kind of the foundation of a hierarchy of theory building in science, as it were.
461746	467600	B	0.8894628882408142	Top of the hierarchy are formal descriptions of behavior what are known as dynamics.
468100	476400	B	0.8672117590904236	So if you're applying dynamical systems theory to understand the time evolution of some system, you're in the realm of dynamics.
476820	481648	B	0.8678338527679443	Arguably, folks like Kepler and Galileo were also in the realm of dynamics.
481744	486740	B	0.9143542051315308	So I see some empirical phenomenon and I produce a formal description of that behavior.
487080	504030	B	0.8787874579429626	Mechanics comes into play when we move from Kepler and Galileo to Newton, when we move from merely describing some behavior to providing equations of motion that allow us to explain why that behavior has the particular shape that it does.
504720	515200	B	0.8683819770812988	So classical mechanics, for example, gives us an account of gravitational force and explains why orbits are shaped the way they do.
515270	531108	B	0.892510712146759	So if galileo and kepler just noticed the shape of orbits and provided a formal description of them, newton explains where that shape comes from in some sense, and principles, in turn, explain where mechanics come from.
531274	547748	B	0.866561770439148	So classical mechanics come from the principle of least action or stationary action, which, very roughly speaking, is the principle according to which no more or no less energy is used than necessary to perform some physical movements.
547844	548644	B	0.6747135519981384	That kinetic.
548692	558284	B	0.8127338290214539	And potential energies balance out such that the true paths of a system through its state space are those for which that balance equals zero.
558482	564572	B	0.8697643876075745	The principle of least action explains where classical mechanics comes from.
564626	565710	B	0.7325658798217773	In some sense.
566020	574876	B	0.8829476833343506	And similarly, the free energy principle is at the basis of another kind of mechanics that is becoming known as Bayesian mechanics.
574988	583620	B	0.8737475275993347	You can think of the free energy principle as having the same relation to Bayesian mechanics as the principle of least action has to classical mechanics.
583960	588576	B	0.8152790069580078	And Bayesian mechanics is the physics of probabilistic beliefs.
588768	597210	B	0.867390513420105	So it's a physics that connects the properties of the system that you're considering the physical properties of the system.
597580	620668	B	0.8309146761894226	In particular, the information entropy of states of a system to the connects the thermodynamic entropy of the states of a system to the information entropy of the beliefs that a system has about the systems to which it is coupled.
620764	621024	B	0.571090042591095	Here.
621062	628112	B	0.8558118939399719	A probabilistic belief means a probability density in a very general sense.
628166	633840	B	0.7751972079277039	We're not assuming some kind of contentful motion of belief like you might find in philosophy.
634000	634324	B	0.6346455812454224	Really.
634362	636576	B	0.8994526267051697	This is about kind of a tracking relation.
636688	640260	B	0.8494236469268799	But we'll get that to that in actually, just a few slides.
640700	644148	B	0.8813126683235168	There are two main formulations of the free energy principle in the literature.
644244	646200	B	0.6971408724784851	The classical and the quantum.
646780	650740	B	0.8872338533401489	Both rest on this apparatus of the Markov blanket.
650900	656744	B	0.8690462708473206	The Markov blanket definitionally is the degrees of freedom that separate.
656792	659080	B	0.7543787360191345	But couple two systems.
659160	662844	B	0.8615750074386597	Or rather, two things within a larger system.
662962	673810	B	0.8182478547096252	It's effectively a statistical boundary that allows us to say that, well, given this boundary, the inside is independent of the outside.
674660	678368	B	0.7433608770370483	The way that we express the dependencies.
678464	690256	B	0.8205256462097168	So taking one step back quickly, this is a dynamic systems approach to cognition, to self organizing systems, and to physical systems more generally.
690448	701992	B	0.8467402458190918	It is a dynamical systems approach in the sense that we're using the tools of dynamical systems theory to examine the time evolution of a system, its trajectory in its state space.
702126	712670	B	0.8823532462120056	And in this context, a generative model is used to encode the relations of dependence that obtain in the time evolution of the system.
713120	726492	B	0.6502894759178162	So this is important and I've been kind of making this point maybe ad nauseam for the last, I guess, half decade.
726636	730390	B	0.5818935036659241	But the generative model is not a model that you have in your head.
732520	740740	B	0.8450589776039124	It is a statistical model that represents the conditional dependence structure of the entire system that you're considering.
740820	747690	B	0.8472418189048767	So this is an environment agent system in the broadest sense.
748300	765230	B	0.7049896121025085	And the free energy principle says that if a specific sparseness structure obtains so if things are disconnected in a special way, then it'll look as if the subsets that are disconnected are tracking each other.
765620	771120	B	0.8557643890380859	So more technically, we partition our system into particles.
771700	781028	B	0.8304857015609741	Particles are basically internal states shrouded behind their Markov blanket, where the Markov blanket is composed of sensory states and active states.
781194	793930	B	0.7004714012145996	Sensory states affect internal states but are not affected by internal states and active states affect external states but are not affected by external states.
795740	808860	B	0.766793966293335	This separation of causal dependence and this structure intervening between the two bulk subsets of the system is really critical.
809440	832928	B	0.8865916132926941	The free energy principle says if my generative model, which encodes all of the dependencies of the system, if my generative model contains a Markov blanket in the sense that we just defined, then we are basically licensed in our interpretation of internal states as basically tracking external states where tracking has a specific mathematical definition.
833024	840884	B	0.9087260961532593	In this context, tracking means to encode the parameters of some probabilistic belief about external states.
841002	854140	B	0.7399132251739502	So to the extent that we want to call this representation, we should note that this is not a representation in the typical tele semantic sense of having some internal states track some external features.
855840	866288	B	0.9154636859893799	What we're saying is that basically if I have a Markov blanket, then my internal states are basically shaping a belief about the external world.
866454	869570	B	0.6472294926643372	And I think that's really critical to understand.
870980	874224	B	0.7807058691978455	And this is where the inference and the modeling bit comes from.
874262	879360	B	0.8563092350959778	This kind of tracking relationship, formally speaking, is approximate daisy and inference.
879440	889524	B	0.8340728878974915	So basically, in a nutshell, the free energy principle says in our physical universe as we understand it, with the usual mechanics running in the background, right?
889562	902484	B	0.8609694838523865	Classical relativistic, quantum and statistical, if boundaries exist in the physical system, then the bulk across the boundary is going to be tracking whatever is beyond the boundary.
902612	906440	B	0.79756760597229	So in a nutshell, this is what the free energy principle says.
906510	908616	B	0.6405290365219116	Now, I noticed you put some stuff in the chat.
908648	911416	B	0.8316384553909302	Would you mind using your voice to compliment.
911608	917490	C	0.699337899684906	Yeah, I was just saying that this part that you were just explaining often seems kind of esoteric to people.
918180	926304	C	0.7645537853240967	But it's critical to understand the sparseness of the coupling because then you kind of start understanding where perspective comes from.
926422	939668	C	0.7742931842803955	And if you have perspective, you also have the capacity to assess causality starting from a point and extending outwards to something else.
939754	944744	C	0.5142847895622253	And this is true from any so that's what I wanted to add.
944942	945924	B	0.9079863429069519	Thank you, Mala.
945972	947960	B	0.8712142109870911	I think that's useful addition.
948860	949272	B	0.5491447448730469	Yeah.
949326	953260	B	0.8737809062004089	So this is the classical formulation of the free energy principle.
953760	973004	B	0.5456855297088623	There is a new hip funky formulation that has become available over the last half decade due to Chris Fields, Jim Glazebrook and their colleagues, the so called quantum information theoretic formulation of the FEP.
973132	973888	B	0.6303364038467407	Fear not.
973974	976860	B	0.6044726371765137	This doesn't appeal directly to quantum mechanics.
976940	990756	B	0.6370818018913269	Rather, it appeals to the tools that have been used to extend information theory in the context of quantum mechanics, which allow you to calculate like all sorts of funky wave equations and propagation operators and all that.
990778	992608	B	0.725089967250824	We don't have to get into the details.
992784	995560	B	0.6730899810791016	Basically, it's just a way to reframe what I just said.
995710	1003836	B	0.8391022682189941	So what I just said is if there's a boundary in my physical system, then the things across the boundary will look as if they're tracking each other.
1004018	1016540	B	0.8034897446632385	Another way of saying that is, well, this boundary is a kind of screen green takes on a particular sense in quantum information theory.
1017120	1038576	B	0.862057089805603	We don't necessarily have to get into the details of it, but basically you can think of these degrees of freedom that couple the two systems as a kind of probabilistic surface and you can think of the bulk across either side of the boundary as in alternation reading and writing information onto the blanket.
1038768	1052932	B	0.8854426145553589	So any Markov blanket whatsoever can be construed as a classical information channel or a screen and in effect, all of the classical information that you need to describe the way that things across the boundary.
1052996	1059736	B	0.8463526368141174	So the so called bulk of the system, couple to one another, is contained on the boundary.
1059848	1065810	B	0.6330375671386719	It encodes the classical information that's necessary to describe the couplings within the system.
1068980	1070800	B	0.7873749732971191	This is holography.
1072260	1073292	B	0.8053709864616394	This is the hologram.
1073356	1075180	B	0.5768758058547974	Not in the sense of Holography.
1075260	1087440	B	0.8924484848976135	Although we might discuss senses in which these things are intertwined, we're using the word Hologram in the sense of the Holographic principle from physics.
1087600	1095508	B	0.8908450603485107	The Holographic principle is a principle that was originally discovered in the context of black hole thermodynamics.
1095604	1101720	B	0.8475790023803711	And what it basically tells us is necessarily from the point of view of an external observer.
1102240	1110220	B	0.7786926031112671	Some bulk in physical space can only contain as much information as can fit onto its surface.
1110720	1114120	B	0.905965268611908	So this echoes what we were just discussing about Markov blanket.
1114200	1129140	B	0.6570665240287781	The physical reason is that if a bulk collapses into a black hole and the bulk contained any more information than could be fit onto its boundary then we would basically be losing information.
1129290	1139940	B	0.6247896552085876	And that would violate the conservation of classical information also known as the principle of unitarity in quantum mechanics which basically says that information is never lost.
1141080	1145032	B	0.7832387685775757	So we're using the word Hologram in that sense.
1145166	1150324	B	0.6743453741073608	This is different from the sense of Hologram everyone has seen, like the Hologram of Tupac.
1150372	1154696	B	0.49925023317337036	Or does that make me look seem old at the Super Bowl a few years ago?
1154798	1158284	B	0.5298460125923157	Or maybe Pokemon cards, maybe that also makes me seem old now.
1158322	1168416	B	0.7826070189476013	I don't know what the kids are doing, but you've seen like red baseball cards and stuff like that with different superimposed picture layers that become visible as you move.
1168518	1171116	B	0.6620360016822815	That's not the sense of Hologram that's at stake.
1171228	1178428	B	0.876550018787384	Although maybe so we'll get to why, but we'll focus on the Hologram theoretic formulation.
1178604	1200228	B	0.8779630064964294	So, to summarize, in the Holographic principle version of the free energy principle, the quantum information theoretic version of the principle, all of the classical information that I need as an external observer to characterize the coupling between two subsystems of a larger system exist on the boundary.
1200404	1203310	B	0.7894752025604248	And that's a pretty remarkable physical fact.
1204080	1221824	B	0.7652148604393005	And a few years ago, Chris Fields, Jim Glazebrook and Mike Levin proposed that maybe this kind of information concentrating bottleneck architecture also has application to consciousness in the form of an internal screen.
1221942	1231408	B	0.6991928815841675	So the idea was that the information that I bring to bear, to parse my sensory stream and make sense of what is constantly bombarding me, it has to live somewhere.
1231584	1235764	B	0.8073788285255432	And so the idea is, well, it lives in this inner screen.
1235882	1241992	B	0.8740818500518799	So you basically have an external Markov blanket, which is a Markov blanket just in the usual sense.
1242126	1253912	B	0.8419396281242371	And then the idea is well within the set of internal states that are kind of partitioned off from the organisms due to the organism's Markov blanket.
1253976	1258830	B	0.9018021821975708	Then you would have an internal Markov blanket structure within those internal states.
1259440	1261852	B	0.7474842667579651	This is prediction six from their great paper.
1261906	1266348	B	0.8641991019248962	Minimal physicalism internal awareness requires internal boundaries.
1266444	1276144	B	0.6268602609634399	And there's this interesting connection to integrated information theory I am agnostic with respect to IIT, so we're not going to go there today.
1276182	1284036	B	0.8449774980545044	But for those of you who are interested, this kind of inner loop mechanism seems to generate positive integrated information.
1284138	1286470	B	0.8256132006645203	So there's an interesting connection there.
1286920	1291332	B	0.887225866317749	Before I move on to Neurophysiology, I'll hand things over to Mao.
1291396	1292968	B	0.7943547964096069	If you wanted to add anything.
1293134	1305950	C	0.8094642758369446	Yeah, actually I was literally about to type something that this is actually also connected to some neomaterialist formulations of folding onto itself.
1306720	1311470	C	0.5846381783485413	So maybe this is something worth digging into a little later in the talk.
1312480	1313228	B	0.9184247851371765	Awesome.
1313394	1314376	B	0.7465407252311707	Then we shall.
1314488	1319920	B	0.583335816860199	And I believe that Ali is also a co author on the paper and we have him.
1319990	1322604	B	0.9389697313308716	So congratulations, by the way, on the preprint.
1322732	1325728	B	0.8986806869506836	I saw it released and Mao has told me about it.
1325814	1332704	B	0.9839212894439697	I'm really happy to see such serious philosophical work being done with the free energy principle as the basis.
1332752	1336496	B	0.9600620865821838	I think you should be very happy with the end result and proud.
1336688	1341080	B	0.781501829624176	But now let me get back to my monologue.
1341580	1346756	B	0.7200246453285217	So rather our Mao and my diet.
1346868	1348036	B	0.7052531838417053	It's not really a dialogue.
1348068	1349992	B	0.4883619546890259	It's sort of like I don't know how to call it.
1350046	1355816	B	0.8161313533782959	Anyway, I'm thinking in French.
1355848	1357768	B	0.5610747337341309	I have the words in French, I promise.
1357944	1374716	B	0.6784332394599915	So now that we've, you know, reviewed in a very much too short, way too brutally fast fashion the free energy principle and its core formulations, we're now going to derive a model of consciousness by applying it to the known neurophysiology of the brain.
1374748	1375650	B	0.7772849202156067	Are you ready?
1376340	1377392	B	0.6031491756439209	You buckled up?
1377446	1378290	B	0.7295194268226624	Okay, good.
1378740	1383440	B	0.8891092538833618	So we have just said that the FEP can be used to model things that have boundaries.
1383520	1392520	B	0.796299934387207	I submit to you that the brain is a thing with boundaries and importantly, a lot, many, several internal boundaries.
1393980	1399236	B	0.6618436574935913	So in particular, we know that the brain has a very sparse structure.
1399428	1403628	B	0.8441541790962219	So if you think of just the raw numbers, right?
1403714	1410860	B	0.9009012579917908	There are roughly on the order of 100 and 5160 billion neurons in the brain.
1411360	1425410	B	0.7275896668434143	But each neuron only makes about something like, I want to say five figures, because I've spent so long, ten to the five connections, right?
1429300	1437520	B	0.6424168944358826	My neurophysiology is a bit far behind me, but it's something on the order of a few thousand to maybe tens of thousands of connections per neuron.
1437600	1443640	B	0.6357558965682983	So obviously, if you just think about it, most neurons are not connected to each other, not directly.
1444140	1448756	B	0.6802690029144287	And furthermore, the brain has a hierarchical structure.
1448948	1451252	B	0.7560299038887024	And when you think about it, what is a hierarchy?
1451316	1454524	B	0.765311062335968	A hierarchy is a sparse connectivity structure, right?
1454562	1468096	B	0.6207104921340942	So if you think about a hierarchy of connectivity, what having a hierarchical structure means, at the end of the day, this isn't some statement about power dynamics where things at the top of the hierarchy are more important than things at the bottom.
1468198	1474284	B	0.48583608865737915	Your cortical neurons don't drain more juice than other parts of the brain.
1474332	1476080	B	0.6917463541030884	The neurons in those parts.
1477300	1488420	B	0.850308358669281	What we're talking about is a regular sparse pattern of connectivity, where I only make connections to the layers directly below me and to the layers directly above me.
1488490	1497290	B	0.7182545065879822	What I want to suggest now is that you can understand the sparseness as a set of nested Markov blankets, and that's going to do a lot of heavy lifting for us.
1497660	1501316	B	0.8924364447593689	So the discussions here are based on two papers.
1501428	1507464	B	0.8938060998916626	One by Fields and colleagues called neurons as hierarchies of quantum reference frames.
1507512	1508348	B	0.9838730692863464	It's really cool.
1508434	1509804	B	0.8935759663581848	I recommend it.
1509922	1516780	B	0.862741231918335	And also a paper by Inesh Ipolito, myself and our colleagues on Markov blankets in the brain.
1516860	1534256	B	0.7974189519882202	So this is going to be a much too short summary of those discussions, but basically, you can start with individual neurons and then talk about their Markov blankets to bring it back to something that I was saying earlier, but that I didn't emphasize while we were going through the slides.
1534448	1539888	B	0.8622211217880249	The Markov blanket identifies dynamical dependencies, not necessarily physical boundaries.
1539984	1545816	B	0.8265283107757568	So it's a statistical boundary it's not necessarily like the boundaries of a wall, like a cell.
1545998	1566270	B	0.9029818773269653	In the case of formalizing individual neurons with Markov blanket we would associate the post synaptic conductance with the internal states, the post synaptic voltage with the active states, the presynaptic conductance to external states and the presynaptic voltage to sensory states.
1566580	1572656	B	0.8832270503044128	You have some equations of motion that tell you how each of these quantities change and what they depend on.
1572838	1589124	B	0.8024726510047913	And you'll notice that this has the dependency structure of a Markov blanket where the internal states only depend on sensory active and internal states, the active states only depend on internal states, and so on.
1589162	1601400	B	0.8497462272644043	So it respects the dependency structures that we were discussing a bit earlier, where again, the sensory states can only depend on other blanket states and external states and so on.
1601470	1606760	B	0.8119850158691406	So here we have a nice dynamic Markov blanket that we carve around our neurons.
1606920	1609500	B	0.7808771133422852	And then there are two directions that we can go.
1609650	1624640	B	0.8419285416603088	We can ascend the scales towards canonical microcircuits and then cortical columns, individual brain regions, whole brain networks and so on.
1624710	1632180	B	0.8984367847442627	And at each of these successive scales of self organization you can similarly identify Markov blanket.
1632760	1640600	B	0.7558889985084534	If you want to discuss this in more detail, you can go see the paper by Inesh and myself and colleagues.
1642060	1653576	B	0.8878437876701355	You can also go from the individual neuron down towards gated channels, towards synapses dendrites and the soma.
1653608	1658376	B	0.8616850972175598	So the body of the cell, all of these things have successive Markov blanket.
1658568	1665724	B	0.8626869320869446	And so all throughout the brain's organization at the different scales at which itself organizes.
1665772	1670156	B	0.6635133624076843	You have this nice structure of nested Markov blankets, of Markov blankets?
1670188	1671676	B	0.7699816823005676	Of Markov blankets.
1671868	1677020	B	0.8451152443885803	So that's one clear immediate sense in which there are these blankets.
1677100	1685204	B	0.8323890566825867	And you can start to think of these blankets as screens in the way that we just were talking about.
1685322	1692468	B	0.8474789261817932	A slightly more illustrative example of what we're talking about here is Markov blankets and predictive coding.
1692564	1695892	B	0.6832689642906189	This is a figure pretty typical in the predictive coding literature.
1695956	1716028	B	0.6600860953330994	What it tells you is that the brain has a series of levels or layers, where superordinate layers are basically passing predictions about sensory input onto subordinate layers and subordinate layers are shuffling prediction error back up to the superordinate layers.
1716124	1722844	B	0.8781070709228516	This is probably like I'm almost embarrassed again to discuss this at the active inference institute.
1722892	1726976	B	0.7189446091651917	I'm sure everyone is quite familiar with these things already.
1727158	1734500	B	0.7663150429725647	The novelty that we are introducing here is to say well, each of these layers is connected to each other via a Markov blanket.
1734920	1745764	B	0.8897526860237122	And so that's I think like a key insight is that each of these layers has internal states and communicates to other layers through what you can formalize as a Markov blanket.
1745812	1757660	B	0.7173173427581787	So you can understand at any given scale of brain activity, you can understand the different levels of message passing as successively nested screens.
1758240	1767884	B	0.8118376731872559	The cool thing is that what each of these screens is doing in some sense is course graining, the stuff in the screen below.
1768082	1773296	B	0.8902220726013184	So in some sense each screen is kind of implicitly contained in the following one.
1773318	1781780	B	0.9712325930595398	And what you end up having is a kind of nested structure of screens of screens of screens of screens, which is, I think, pretty cool.
1781850	1788740	B	0.8406805396080017	We recover, as you'll note in this figure, the inner screen hypothesis.
1789080	1793288	B	0.6942782998085022	Each of these, this is probably a better way to visualize it.
1793374	1799316	B	0.8867591023445129	You have at the left the kind of external Markov blanket of the organism.
1799428	1804348	B	0.8101269602775574	It is segregating or carving out a set of internal states.
1804434	1816380	B	0.8812721967697144	And what we're saying is these internal states have a layered level structure, a sparse structure that we can formalize using nested Markov blanket.
1817140	1822288	B	0.8545007109642029	And like I was saying, each screen successively coarse grains the next screen.
1822454	1847480	B	0.8044977784156799	And this gives some flesh to this notion of contextual computing, this idea that really what the brain is, is an organ of context where each layer is providing context to the layer below and where each layer is attuning to increasingly higher order, slower and more physically widespread regularities.
1848940	1861640	B	0.8389861583709717	So one thing that we're proposing here, which is a novel hypothesis that we intend to test empirically over the next few years, is that this architecture has two special layers.
1861720	1867532	B	0.8453793525695801	In some sense you can think about it as write only layers.
1867596	1887220	B	0.6935489177703857	So if you're thinking about the stack, the sensory periphery or the sensory bottom, in one sense can only write in one direction, it can only write into the system and the topmost level can only write downwards.
1887560	1889488	B	0.607311487197876	This is a key architectural feature.
1889584	1896340	B	0.8820353746414185	One thing to point out is that in the paper we associated the topmost level to structures like the hippocampus.
1896420	1903000	B	0.651882529258728	We don't need to suggest that the hippocampus is uniquely the top of this hierarchy.
1903080	1911320	B	0.49899232387542725	Rather there is probably a whole bulk of structures that basically cannot any longer be coarse grained.
1911400	1914108	B	0.8414389491081238	So you kind of have like an executive level top.
1914194	1919516	B	0.6493360996246338	And what's particular about this top is that it can only write down into the stack.
1919628	1933312	B	0.8985533118247986	So its function really is to be about and monitor the other layers of the stack, implementing a form of COVID action which trickles down throughout the stack.
1933456	1936612	B	0.7314693927764893	So now I saw you write some stuff.
1936746	1938916	B	0.8570144176483154	Would you like to add?
1939018	1950330	C	0.7018301486968994	Yeah, so I think one of the things that's important to highlight is why some things can only write up and some things can only write down.
1951340	1973772	C	0.8022084832191467	And what this means for irreducible, the irreducible mark of blanket, which is the part where experience happens because there's a counter that and some future questions that are going to happen that relates to superstructures and then why don't we experience the consciousness of a superstructure?
1973916	1977730	C	0.8369055986404419	So I think it might be important to dig into that a little bit.
1978360	1979110	B	0.4650449752807617	Absolutely.
1980360	1981444	B	0.8529649972915649	Thank you.
1981642	1988020	B	0.6891505718231201	So, yeah, to summarize then, there are basically two, right, only layers.
1988520	1998260	B	0.6693110466003418	As you ascend the layers which are successively coarse graining each other, there is an irreducible screen that can't further be coarse grained.
1998420	2003024	B	0.882384717464447	We believe that this corresponds to something like a naturalized Homunculus.
2003092	2007660	B	0.7249535322189331	And we're calling this perspective with an intentional provocation.
2008000	2021772	B	0.8796486258506775	We're calling this perspective Neocartesian in the sense that we may have in some sense identified the processes that make it seem as if there was something like a Homunculus.
2021836	2024416	B	0.5495089292526245	Obviously we're not, or maybe not.
2024438	2032950	B	0.6708967089653015	Obviously it's worth saying we are not falling into the Homunculus fallacy because we're not claiming that the topmost layers perceive themselves.
2033640	2043080	B	0.6659120917320251	So the buck stops with the top layers and the top layers can only perceive themselves vicariously by acting through other layers.
2043500	2056088	B	0.8596525192260742	And we associate this action of layers of internal Markov blankets on each other with attention in particular and other neuromodulatory effects.
2056264	2078252	B	0.8735010623931885	So I mean the overall picture is one where consciousness is intrinsically related to overt and covert actions, to the overt acting and sensing associated with the external Markov blanket and with the COVID actions that are being deployed within the stack and in particular that are issued by the very top set of levels.
2078316	2081164	B	0.8224607110023499	As I said, this is not necessarily a strict hierarchy.
2081212	2084304	B	0.8326757550239563	It could be a hierarchy with several different tops.
2084432	2090156	B	0.9024012088775635	But this integrated top structure we believe could be associated with a naturalized Homunculus.
2090288	2097880	B	0.8308980464935303	I'm going to skip through the rest and thank you for your attention.
2103260	2105364	B	0.8305988311767578	Unless Malana wants to add something.
2105502	2113672	C	0.689782977104187	Just one thing is, I think to put it in simpler terms as well, the two layers that can only write can't store memories.
2113816	2123148	C	0.6227320432662964	Because that's right, memories is not just an encoding, it's a process of retrieval.
2123324	2142436	C	0.48916909098625183	And it requires interactions between different levels, which is why the lowest levels are only interacting with things which are external and therefore can't necessarily store and can't make direct interactions with anything else within the entity itself and the highest level as well.
2142538	2148170	C	0.7407238483428955	So there is no memories being encoded at these two levels, which is why they're right only and not.
2149260	2151370	C	0.7341572046279907	I think that helps a little bit.
2152780	2153352	B	0.8529649972915649	Thank you.
2153406	2154650	B	0.7128563523292542	Yeah, I would agree.
2155680	2157576	B	0.9802727699279785	So thank you all for your attention.
2157688	2160392	B	0.9701475501060486	Thank you in particular, Dan, for the invitation.
2160456	2169280	B	0.9893767833709717	It's always great to be at the AWI and yeah, we looking forward to this discussion.
2174960	2183084	C	0.7725191712379456	I think Daniel said he wasn't going to do too much animation, so if.
2183122	2187410	B	0.7083948850631714	People have are you going to do any facilitation at all then.
2195400	2196150	C	0.5491447448730469	Yeah.
2196840	2197348	C	0.584351658821106	Okay.
2197434	2201670	D	0.9834845662117004	So thanks Maxwell and Mao for the amazing talk.
2202940	2210600	D	0.9741584658622742	There are so many interesting things to dig on in this paper, I don't know even where to start.
2210670	2214810	D	0.8477506637573242	But I do have one question too, actually, in particular.
2215280	2225896	D	0.7750709056854248	So does this inner screen model imply a kind of protopenpsychism or a more restricted bioppsychism?
2226088	2236348	D	0.867007315158844	I mean, do you think the type of nested Holographic structure described by the model all exists in biological systems?
2236524	2247430	D	0.8822594285011292	And regardless of the answer, would you think that it generalizes to larger systems comprising these systems, like populations and colonies and so on?
2247960	2248756	B	0.5860152840614319	Maybe I can take.
2248778	2250070	B	0.7393327951431274	A quick stab at that.
2250760	2260920	B	0.648849606513977	So we think that the free energy principle itself commits you to a kind of I don't know what the right word is.
2261070	2262696	B	0.887236475944519	We're writing a paper now.
2262878	2268280	B	0.5324707627296448	We're struggling with the exact coinage, but it's not quite a pen psychism.
2268620	2277260	B	0.9219896793365479	It's a pen representationalism or a pen tracking ism, if you'll allow me, the absolutely disgusting neologism.
2277600	2286140	B	0.859659731388092	Basically what the FEP implies is that anything that has a boundary, it looks as if it's tracking what's beyond the boundary.
2286220	2291716	B	0.645715594291687	So at a very basic level, the FEP kind of licenses this talk about anything.
2291898	2298660	B	0.7986369729042053	So anything whatsoever looks as if it's tracking what's across the boundary by virtue of existing.
2299240	2308008	B	0.7318342328071594	So at a very basic level, if I see a rock outside, I know that it's not 1000 degrees Celsius outside.
2308094	2308730	B	0.5664746165275574	Right.
2309100	2314676	B	0.8674973249435425	The fact that a rock has a specific structure entails something about its environment.
2314868	2319464	B	0.6253825426101685	Likewise, I can see you, Maria, you are not wearing a winter parka.
2319512	2327696	B	0.7557175159454346	And I can infer from that that it's probably room temperature around you and not like you're not somewhere in Antarctica or wherever else.
2327798	2332464	B	0.8711570501327515	So this kind of basic tracking relationship applies to everything.
2332582	2346432	B	0.8092332482337952	What we've tried to do in this paper is to start spelling out more explicitly what the difference is between just rocks and rock stars in some sense.
2346486	2351744	B	0.9101967215538025	Like, what is the special kind of structure that you need to add to the Markov blanket?
2351792	2357028	B	0.7204795479774475	And what you'll notice is that you get consciousness by making the overall structure more sparse.
2357124	2369608	B	0.5024695992469788	So as you make more of the connectivity zero, you get all of these weird things that pop up, one of which is we think like this consciousness structure.
2369784	2377180	B	0.850568950176239	Mao has thought about this maybe more than I have, so I'd be curious to get her perspective.
2377780	2387170	C	0.5537393689155579	Well, so I know that people are a little bit wary of panpsychism, so we usually add the term proto in front of it.
2387940	2393860	C	0.6029587388038635	And so the idea is that we have to deconceptualize what consciousness means.
2393930	2399030	C	0.8366587162017822	And oftentimes what we mean is something that resembles what humans do.
2399800	2411770	C	0.869015634059906	And we have to be a little bit if we take our formalism consciousness can become emergent at the scales where humans are.
2412380	2421660	C	0.6371212005615234	But it doesn't mean that it doesn't exist at lower scales, where the inertia or the entropy generated by policies is lower.
2421810	2428844	C	0.844253659248352	So if you think of a rock, its policy is pretty much maintained bonds.
2428892	2429472	C	0.6717482209205627	You know what I mean?
2429526	2430480	C	0.6332046985626221	There's nothing else.
2430550	2439324	C	0.7078493237495422	The scale at which some kind of thing exists and changes is much different than you deciding to have coffee.
2439452	2450804	C	0.7491317987442017	But in effect, your cells could be something that we could consider exist, closer to something that a rock does and even lower just the proteins that make up your system.
2450922	2476060	C	0.8378227353096008	So if we understand that there is nestedness and that the conscious process happens once you have this capacity to exchange information across layers, anything that has the stacking of layers in a nested fashion is in effect, proto conscious.
2476400	2481056	C	0.7495636343955994	But we have to be very careful about what we load into.
2481158	2484370	C	0.8182218670845032	The term conscious, I think, is mainly the question.
2485300	2486832	B	0.8476874232292175	I'm sharing my screen here.
2486886	2493860	B	0.8888142704963684	This is from a paper on path integrals, particular kinds and strange particles.
2494440	2501856	B	0.8466219305992126	So it is a typology of different kinds of Markov blankets and different kinds of particles.
2502048	2510890	B	0.8761857151985168	So something like a rock, it still has a Markov blanket, but its Markov blanket is not partitioned into sensory and active states.
2511340	2520364	B	0.6563169956207275	There are no states that have this property that active states have that they affect the external world that are not affected by it.
2520402	2521230	B	0.7625625729560852	In return.
2521840	2524220	B	0.7236730456352234	A rock just has sensory states.
2524290	2528290	B	0.5382086634635925	If I kick a rock, unless it's radioactive, it's not going to act on me.
2529780	2532940	B	0.8420407772064209	It only has the inference part of active inference.
2533020	2538050	B	0.8377529382705688	It's only kind of changing its state as a response to the forces that are acting on it.
2538660	2543412	B	0.8308453559875488	Active particles are particles that have both sensory and active states.
2543466	2546550	B	0.8442190289497375	And you might think, for example, of a cell.
2547720	2550420	B	0.8181382417678833	A cell has this kind of structure.
2551320	2559960	B	0.857492208480835	Particles like ourselves have additional sparseness in the Markov blanket, in particular, what we call strange particles.
2561420	2569660	B	0.65462726354599	The internal states of strange particles do not have direct access to the active states of strange particles, and therefore they need to be inferred.
2570160	2572344	B	0.7637052536010742	And this is what gets you planning.
2572392	2588064	B	0.5267287492752075	At the end of the day, a strange particle can only exist by kind of inferring itself into existence precisely because there are no direct connections between the active and the internal states.
2588182	2597584	B	0.5855823159217834	So as you remove connectivity from the overall structure from here to here, you're adding sparseness.
2597632	2600100	B	0.5665664076805115	From here to here, you're adding sparseness.
2600520	2609320	B	0.6788378357887268	As you make the system more and more sparse, you get more and more interesting behavior to emerge from the system.
2609470	2624460	B	0.6914243698120117	And you can think of the topmost structure that we were describing as an instance of this broader architecture where the topmost layer doesn't have direct access to the active states of the system.
2624530	2632160	B	0.7134743928909302	And therefore, it kind of has to go through the entire bulk of the system to infer itself into existence.
2635420	2644580	C	0.726336658000946	So there's a few hands up there on Google where you can see the people who share hand.
2644750	2645084	C	0.584351658821106	Okay.
2645122	2647390	C	0.8478740453720093	So, Ali, I think you raised your hand first.
2650400	2651004	E	0.46103888750076294	Yes.
2651122	2656370	E	0.9825000762939453	Thank you again for your crystal clear and really illuminating talk.
2658180	2666996	E	0.6843587160110474	I've written down three questions, but maybe I'll begin with probably the most basic and naive one.
2667178	2678470	E	0.8820708990097046	So in some of the earlier literature on active inference and the FEP, there was this emphasis on distinguishing between generative process and generative model.
2679180	2691352	E	0.5855861306190491	But in this paper, in figure one, which you also shown in your slides, we don't see any generative process in the diagram.
2691416	2696300	E	0.8761918544769287	So where does generative process fit into this diagram?
2697120	2707968	E	0.7919965982437134	Because the way I see it, it's basically somehow included in the generative model or I don't know.
2708134	2712480	E	0.827766478061676	What is the distinction between these two concepts?
2713060	2720660	B	0.5702803730964661	So you'll have to forgive some of the earlier literature for this, there's some terminological inconsistency.
2721880	2730568	B	0.8683547973632812	The only two constructs that are at play here are the generative model and the variational density that's encoded by internal states.
2730734	2731770	B	0.532121479511261	That's it.
2732140	2740170	B	0.6830383539199829	So it is not the case that the FEP is about how the generative models the generative process.
2740720	2748984	B	0.8629453182220459	A lot of this language comes from previous Bayesian approaches and in particular, the helmholtz machine.
2749112	2750860	B	0.7853323221206665	In the helmholtz machine.
2751600	2754808	B	0.8783867359161377	So helmholtz machines are some of the earlier predictive coding machines.
2754904	2772916	B	0.8813463449478149	And in the helmholtz machine, basically you have a forward pass that connects the sensory end to basically the top of the predictive hierarchy and then a backwards pass connecting top of the model back to the sensory end.
2773018	2780950	B	0.8667383193969727	And in a helmholtz machine, you would call the forward pass a recognition model and the backwards pass a generative model.
2781640	2790884	B	0.8423746228218079	The forwards passes a recognition model because you're inputting some data and then basically by the time the information trickles up to the top, you have recognized what caused the data.
2791022	2805744	B	0.8583280444145203	And the backwards pass is called a generative model for the reasons that are sometimes invoked in the predictive coding literature where you're basically generating possible sensoria given a certain configuration of states.
2805942	2811280	B	0.5079332590103149	So we don't use recognition and generative in that sense anymore.
2812180	2813820	B	0.5181030631065369	And I apologize.
2813900	2821536	B	0.6501979827880859	In some previous publications, I've been a bit sloppy in the way that I use my language and I've used the term recognition density.
2821648	2830410	B	0.8655572533607483	What's really at stake is and I'll share my screen just to help make the point.
2831180	2832890	B	0.7614654302597046	It's what it says here.
2833980	2836664	B	0.8431500792503357	So you have your generative model, right?
2836702	2839524	B	0.8534950017929077	Your generative model is a joint probability density.
2839572	2841820	B	0.8821107149124146	So what is a joint probability density?
2842240	2860670	B	0.8534670472145081	Well, you have a bunch of different basically states that your system is defined over and you have a probability density that the shape of which captures the way that states can change over time.
2861040	2864816	B	0.8413494825363159	So, like, if I change this way, then I need to change in that way.
2864838	2867120	B	0.7657109498977661	And that's what this shape encodes.
2867960	2879320	B	0.8989325761795044	And what the FEP says is if my generative model has a certain sparseness, if it has Markov blanket, then there's this additional probability density that I can define.
2879820	2883370	B	0.7635743021965027	It is parameterized by the internal states of the system.
2884220	2886356	B	0.842479944229126	It's called the variational density.
2886548	2892350	B	0.8373763561248779	And this is like my probabilistic best guess about what's causing my external states.
2892960	2905516	B	0.7162924408912659	At no point do you need to appeal to any other bits of generative process when you're actually coding these models up in MATLAB or in Python.
2905628	2910930	B	0.8635814189910889	What we call the generative process is just the equations of motion that govern external states.
2911540	2918964	B	0.8110061287879944	So if you actually hand code one of these one day, your generative process might include like, Newtonian physics and whatever else.
2919002	2925510	B	0.7970311045646667	It's sort of just like what is the process that actually animates the dynamics of external states?
2927720	2939368	B	0.48985064029693604	In some very simple models, like in the ones used by Miguel Aguilera and colleagues, you're looking at linear dissipative systems and they don't have any dynamics right.
2939454	2943020	B	0.5428727865219116	So basically, the system kind of just dissipates.
2943440	2947116	B	0.8206727504730225	A linear dissipative system is a dampened spring physically, right?
2947138	2950476	B	0.8309608697891235	So it just goes spring and then it dissipates to the fixed point.
2950578	2959570	B	0.8879225254058838	So similarly, you may or may not have dynamics to the external states and that's what gets harnessed in the generative process.
2960100	2960992	B	0.6941731572151184	This should be clear.
2961046	2961264	B	0.5491447448730469	Yeah.
2961302	2962028	B	0.5036985874176025	Sorry, ma'am.
2962124	2977280	C	0.8284779787063599	No, I mean, I think what the question that Ali is asking also has some important correlates that often get asked to us, like what's the difference between consciousness or dreaming?
2977440	2985000	C	0.7941479682922363	Or what's the difference between a dead system that decays or being psychotic?
2985740	3006192	C	0.6797150373458862	And I think what Maxwell is saying is our system currently doesn't say anything about your actual connection to the real world other than a thing, which is successful at being a thing, is probably well joined relative to its needs to the world.
3006326	3024180	C	0.5887867212295532	And therefore your relation to reality has probably got a better grasp if you are functional for a longer amount of time, this minus senescence.
3024840	3029392	C	0.8271432518959045	So yeah, does that kind of help also, Ali?
3029456	3030070	E	0.46103888750076294	Yes.
3031800	3032950	E	0.9221440553665161	Thank you both.
3033640	3035860	E	0.9041063785552979	It really makes a lot more sense now.
3035930	3037110	E	0.9793016910552979	Thank you so much.
3037480	3039024	B	0.9303674697875977	Well, it's my pleasure.
3039072	3042764	B	0.8199878931045532	And remember, model just means joint probability density here.
3042802	3043390	B	0.7360090017318726	Right?
3045520	3060508	B	0.6394389271736145	There's a criminally underappreciated paper that Carl wrote in Entropy in 2012 called the Free Energy Principle for Biological Systems, which is where a lot of the Markov blanket story comes from.
3060594	3060890	B	0.6733751893043518	And in.
