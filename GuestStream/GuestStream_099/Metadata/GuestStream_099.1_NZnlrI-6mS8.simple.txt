SPEAKER_00:
All right.

Hello and welcome.

It's 9th of March, 2025.

We're in Active Inference Guest Stream 99.1 with Avel.

So welcome, Avel, if you would like to say hello.

Thank you.

And go into your presentation.

We're looking forward to it.

So go for it.


SPEAKER_01:
Hello.

So I'm Avel Guédin-Carrieux.

I work with Andy Clark, who is a cognitive philosopher at the University of Sussex.

in the context of the X-CAPE project, which is a project on cognitive archaeology, which focuses on the relation between mind and material culture.

I'm also a founding member of CAIRO's scientific para-academicalisation.

Let's think of it as a think tank.

And what I will present today, let us consider it as an advertisement for the social science sub-project in the Acton Institute.

because it's the aggregation of the work I did to motivate, well, necessity for, I will say, new mathematics for the study of social change that are inspired by Active Inference, but not really in line with what is done mathematically to formalize it.

So we will go from contextuality to constraints, and I will try to articulate an Active Inference ontology for participatory realism and social change.

First, let us try to motivate what is it that we are doing here.

So, human minds and human culture display a very clear sign of open-ended evolution.

What do I mean by open-ended evolution?

It is evolution that is open-ended.

I'm sorry, this is kind of circular.

Essentially, you can make new things that did not exist before, that were not a thing before, that were not a part of some platonic space of things.

We made it up.

It was made up.

This is what I mean by open-ended evolution.

And this is true in generally whatever it is that you might do.

So, for example, we have an impression of a space landscape on the left of the screen.

And, you know, it's buildings.

We made them up.

We built those buildings and they ensured a specific perception of what a building is that did not predate the concept of a building, the invention of building by humans.

And this is very manifest, for example, in writing because, you know, writing is a sign.

The entire activity of writing relies on signs being a thing.

But signs are a thing only if we look at them as signs.

So we are looking at letters on this screen and understand them as being embedded with meaning.

But the concept of a C does not pre-exist humanity.

There is no C dimension in the universal wave function at Big Bang.

We've got it up.

It's a part of the evolution.

And the problem of explaining, presenting, addressing mathematically and physically the open-ended evolution of stuff, it's a pretty huge problem.

Stuart Kaufman, best physics guy, in my opinion, dedicated his career to that.

And let's be frank, he did not solve it.

He is not near to solving it.

Because it's a hard problem.

Because there is this idea that

Open-ended change brings out new stuff.

In mathematics, we have to represent a nice space that has specific possibilities in it.

Else, we are not going far.

And this seems to be incoherent with the logic of open-ended evolution.

So, hard problem.

I will jump to cognitive science because, again, my interest here is in human mind and social evolution.

And

I will try to explain what we mean by explaining in cognitive science.

So for schematic purposes, I will say there are three kinds of explanation that we can go for.

One is nomological, it's with regard to laws.

So for example, if I, I don't know, throw a thing and see that it falls this way, I can formulate a law that describes what happens.

And because it happens a lot, it happens every time I try,

I claim it is a law.

I claim that describing the regularity explains this activity.

So it's a phenomenological approach to explanation.

I just described the phenomena and hope this is explanatory.

This is how we do things in physics, not in psychology, not in biology, not in cognitive science, not in sociology.

What is more natural in those disciplines, the special sciences, is a mechanical explanation.

So we look at structure.

and we show how this structure entails this phenomenon.

For example, we have the Hodgkin-Oxley model of neural activity, which postulates a bunch of electrochemistry, which, if verified, and it seems to be verified, explains the action potential activity of neurons.

And I would say pretty close to mechanical explanation in the space of possible explanation are functional explanations, which address not

does it work but why is it and that is centered on you know functional hypothesis so it's for example most of what biologists evolutionary biologists do it's adaptive hypothesis what why must this happen because it's selected for

And I would say both you can cluster those approaches between homological, where you tend to try to describe laws, and mechanical and functional hypothesis, where you will have a more lean approach to modeling and trying to get into what is going on in a specific system for it to act like that.

And in neuroscience, we are pretty good at mechanisms.

This is according to Brun and Piccinini.

the hallmark of what they call cognitive neuroscience.

We assume that the behavior, as we can ensure it, derives from cognitive mechanisms.

Those cognitive mechanisms are implemented by the physical structure of the brain.

And this physical structure is integrated in a context of operation that involves both physiological and ecological factors.

So we can look at, for example, activation, patterns of activation in brain activity, and map them into an equation here.

It's from DOMATOB, and it tries to map brain activity onto reinforcement learning, which is a very hype family, was at least a very hype family of algorithms describing learning.

So we can explain activity from structure, but what we cannot do with a mechanistic approach is explain why the structure is there, because

you can describe, you can explain activity from structure, but if you try to explain structure from structure, you get, you know, regression to infinity.

You do not explain much, or at least you do not have the possibility to explain without regressing to the infinite.

The argument I will make here is that both cognitive structure, understood as, you know, patterns in cognitive activity, and its evolution,

flow from a single phenomena, which is the construction of meaning to cognitive agency.

So the structure produces a function, a part of activity, which itself will shape the structure at time t plus one.

This is the only way I can think of to at least have a baseline concept of what it is to study operand evolution.

System does stuff.

Stuff changes system.

Pretty simple.

I don't see how we could go around that.

And to be more precise, I will argue that we exist in a context that is characterized by social constraints and that define what we agree, let us say, we can and cannot do in a given social context.

And these constraints are integrated and enacted by humans.

And the way they are integrated and enacted kind of ontologically by construction leads to their reconstruction.

And this is what underlies both the structure of cognition through the integration of thinking in those systems of constraints and the open-ended evolution thereof.

So we do active inference.

This is the Active Inference Institute.

We may as well explain active inference.

Well, I guess most people who are attending to the talk now know what I'm talking about, but this is going on YouTube.

I will reference it.

I need to explain what active inference is.

Active inference is built from what Karl Freestone and colleagues proposed as a principle for cognition that is Bayesian inference.

Bayesian inference basically reduces to the formula you see on screen the probability of an hypothesis given an evidence

is equal to the probability of an evidence given an hypothesis times the probability of the hypothesis over the probability of evidence.

So, for example, if you hear barking, it's pretty likely there is a dog.

Unless it's very likely there is a dog near you.

For example, you are in an office and the office is closed, so no dog can enter.

Or unless you have other explanation for hearing barking.

For example, you have a

YouTube tab open with eight hours of barking noises.

I don't know why you would, but if you did, you would hear barking and not think of a dog.

So this reduces to this formula.

P of E knowing H means the probability of hearing barking if there is a dog.

Probability of H means probability of having a dog with you.

Probability of E means probability of hearing the barking.

you can compute the probability of having a dog with you, knowing that you heard barking from that.

This is the most basic stuff you can do with statistics.

And the thing is, there is no reason why your brain or any single natural system for that matter could compute this, because neurons do action potential, they don't do numbers.

So the novelty in Fritz's approach is to propose an algorithm, well, more of a physical process that could approach optimal Bayesian inference, so the optimal inference of hypothesis given evidence, through minimization of something called rational free energy.

You don't need to know exactly what this formula is.

What is important is that it's something that is always higher

to surprise.

So if you minimize your energy, you minimize surprise, you approach a perfect Bayesian model of what is going on around you.

And if you assume that your activity layer upon layer upon layer of your activity, self-organize like that to infer the causes of sensory stimuli,

they will effectively predict upcoming signal in a way that enables adaptive understanding and navigation of the world.

And this is pretty much what the active inference paradigm is.

It's assuming that the brain does that.

We will not try to illustrate what exactly we mean by active inference predictive processing.

The core idea is that your brain predicts sensation

given prior knowledge of the world.

So please look at the screen.

Look at the sentence in the middle of it.

Do not look away.

And pick something in your peripheral vision.

For example, I'm picking a water bottle at my right.

And while still looking at the screen, you don't glance at the object you picked.

You try to make out as much detail as possible about it.

I'm going to pick two things for most of you.

You will be confident about knowing what it is.

You will see what it is, but also you won't be able to see any single detail that tells you what it is.

For example, I'm seeing a water bottle.

I know it is a water bottle, but I just see a blue thing.

I do not have the detail to know it's a water bottle.

It could be a vase for all I can see.

But I have the prior information that it is indeed a water bottle because I put it there.

I'm remembering that if I want to drink, I need to catch it.

So I know it's a water bottle and I see a water bottle.

You can now look away from the screen.

So what this illustrates is that your perception is at a pretty basic level embedded in prior knowledge.

And this is something that we have known more or less intuitively since a pretty long time.

For example, this is the rabbit and duck illustration that Wittgenstein really liked.

and i will predict once again that when you see this illustration you see either a rabbit or a duck and you may you know if i look at the what would be the back of the head of the rabbit or the mouth of the uh sorry the back of the head of the duck or the mouth of the rabbit i see the rabbit if i look at the ears slash beak i see a duck but i always see one at a time i don't see you know

a complex 2D field for which I have duck value and rabbit value as a computational system would.

I see a rabbit or I see a duck.

And this is again because my perception is embedded in prior concepts I have about the world.

And I know about rabbits, I know about duck, and I will perceive either a rabbit or a duck, knowing those are pretty much two different kinds of things.

I cannot perceive both.

So, active inference entails that perception works, as I said it would, under predictive processing, but also that actions work the same.

So in a sense, under active inference, agents will engage with the world by maximizing the Bayesian coherence, which is predicting, in a sense, the kind of predicting we do by minimizing national free energy.

of sensory motor states with a power belief through both perception and action.

And what this means is that I may, for example, if I don't know what is the water bottle, I may glance at it.

But also, if I want water, I will take it.

I will expect myself to solve the problem I have, the fact I want water.

And this is this expectation that will lead to the sending of motor signals

that enabled me to grab the bottle.

This is a bit abstract because, you know, cognitive neuroscience, it's mostly math.

But I want to make very clear why this matters.

In engineering, signal engineering, control engineering, this kind of stuff, there is a very well-known problem that is called the inverse problem.

If you have a forward model of the world, so

how things move.

And even if this model is well-known and well-behaved, directly inferring what is going on in the world requires to work not with the forward model, but with its inverse.

And most of the time, it's not feasible.

Let's take an example.

What do you see?

I will strongly expect that you see a big blurred thing

with red and orange.

This is a painting of William Blake, the Ancient of Days.

And just by applying blurring to it, which is a very simple process, we all understand, you can destroy the information about it so that you cannot tell what is going on with the painting.

And this is in general a problem with any kind of inversion, even if you know the process that builds

your sensation you do not necessarily know how to infer what is going on from your sensation and the same goes for motor control even if you perfectly how your body moves you don't necessarily know what command to send to create this or this or this consequence and if you can calculate it it will be very costly and it will be likely very fragile against both noise

ambiguity, any kind of error in perception, it will be very, very, very bad for adaptive control, deciding on the run all the time.

And actually in France, because agents do not compute explicit representation of the world, but compute or process physically what they expect to sense and what they expect to do given context,

They can perform relative control without being subject to inverse problems because there is no inversion.

There is just a problem model of what I see, what I do.

And this is why active inference is most likely correct, in my opinion.

And this is why it's very important in context that your actions flow from expectation and not from explicit planning.

But this has non-trivial consequences for how we experience the world.

I don't know why I said that.

It does have very obviously consequences for how we experience the world.

So because you anticipate in a joint manner both motor states and sensory states, you will experience reality as a landscape affordances, where affordances is a technical psychology term for opportunity for action.

So let's take again the water bottle.

The point would be that I do not only see it as, you know, an array of pixels that are blue-ish.

I mostly see it as an opportunity for drinking and as something that I force grabbing.

So I can grab it, I can drink for it.

And this is something that is very basic in my perception of the bottle.

Let's take another example.

So this is a path.

And if you look at the color, it's pretty much only green everywhere.

You kind of see a thing in the middle, but you know, from a purely colorimetric statistical perspective, it's not obvious, but you see a path.

This is likely the first thing you saw about this picture.

And if I remove it and I wait a while, it's good to remember what it is.

I predict that you will remember there is a path and there is green.

And there are trees.

And if I ask you to remember exactly which trees are where, you will not remember that.

Or you may have an idea of it, and now that I put it back, you will see that your idea of it is likely false.

At least I saw it work every time I could check in real life whether or not people remembered precisely the layout of the things.

The point is, you remember, you perceive from this picture mostly the fact you can walk.

the center of it you perceive mostly an affordance and you also perceive basic personal concepts green trees but you're keeping in mind only information that is critical for you to navigate it every time you need more information you will not take it from a abstract model of everything that exists in the world will just glance and this is from that that you have the impression of knowing a lot of development because when you don't know about something you can just glance

It's not because you have a full representation of everything you have seen up to this point.

This would, again, not be something computationally possible.

And what I take from this notion of experiencing the world as a landscape of ordinances is that it entails the dissolution of agency as we know it.

I have to say agency as we know it because if I just say agency, Andy will be upset, and I do not want Andy to be upset because he pays me.

I will say agency as we know it.

In the sense that you do not have a perception of the world that you take as an array of facts for taking decisions that you then apply.

Everything is embedded.

When you see something, you already see what you are going to do with it.

You already see the valence that it has for you, both in terms of action that it can do, in terms of emotional consequences, etc.

Your perception action cycles

are not entailed by some kind of central executive agency.

Also, executive functions do play a role.

They flow with your self-model, what you expect yourself to do given context.

And this means that context pretty much decides for you, in a sense.

At least it can.

And this is from there that we build the active inference notion of social evolution slash socialization.

The idea that was argued by Rammstein and by Desir is that humans will integrate and shape expectations about agents such as themselves.

If I see people stopping at a stop sign, I will infer that you have to stop at a stop sign.

And this is something that applies to me personally.

And this means that we develop a shared landscape of cultural affordances.

Affordances, again, mean possibilities for action.

And cultural affordances just mean that those are culturally constructed.

And those affordances, they are not just something that exists in some abstract space that we think about when we want and that we can decide when we apply them and when we don't.

They directly shape what we see about the world and what we expect to do.

So under active inference, what we actually do.

This is what I call embedded normativity.

And this entails, again, that we participatively construct a landscape that regulates, or at least participates to regulate, at the very least contextualize every single action and perception that we can possibly do.

Everything.

And this sees a pretty strong result.

It seems that it can explain, you know,

a lot about operating the evolution of culture, but does it?

We will now take a look at the formal grounding of active inference, the bit of mathematics that's understood to lend its most, if not all, of its legitimacy, which is called the free energy principle.

We are getting into the math stuff.

I'm sorry for those of you that don't like it.

I promise it's interesting.

So if we assume a stochastic dynamical system, dynamical means it moves, stochastic means it has a random component.

And assuming that the system is partitioned between ABE, an agent, a boundary, the environments, and that the states of the agents and the environments are independent from each other, given those of B. So all information you have about A

Sorry, all information that you could have in E about A, it's inside B, which is expressed in the equation in the middle of the screen.

I don't want to explain too much about it.

If you can read it, you can read it.

If not, we'll go back to something less mathematical pretty soon.

Then there is what we call information geometry.

So geometry of the information that is in the system.

And given states of A, the agent, it gives you a belief, a distribution, over the states of E. And these beliefs, they minimize rational free energy.

So the thing that we said, that if it was verified, it would entail predictive processing at inference, it is verified in the visual case,

given the statistical independence of two systems.

So pretty much everything does cognition in the active inference sense.

Terms and conditions do apply to the statement.

So, first, when we talk about the Markov blanket, essentially what we mean is that there is an individuation, there is an identity of the agent in the environment, in the sense that

It's a bit technical mathematically, but intuitively in the sense that they are separated by something that the agent can act on and the agent can sense.

For example, motor and sensory states.

At least from an information theoretic perspective, interaction is only mediated by states of the boundary.

And again,

In the context of active inference and the currency principle, it is taken as the criterion for the existence of A as an individual system.

Something that also is very important to this interactive inference thing is that the entire idea of predicting one's own action depends on a condition that we call strange particles.

where there is no direct observation possible of active states.

So if I do not have a direct way to observe what I do, causally speaking, my internal states are not directly affected by my active states, then you have this process of predicting one's own action, and then you have what Howie, a philosopher of active interference, calls self-evidencing.

So self-evidencing means that, in substance,

an agent gathers proof of its own existence through action.

I hope you remember this notion of Bayesian coherence between a model and sensory motor states.

This is it.

If you maximize the Bayesian coherence between your prior beliefs, what you think the world is and what you think you are in the world, and what you actually experience, you're gathering proof for a model that corresponds pretty much directly

to Iran's existence.

So this is quite critical.

It's the foundation stone over which this entire active inference, inference principle, philosophy lies.

And so I'm accentuating it a bit.

What's important mathematically is the relation between this notion of model of the world and self-model and the active reaction and perception

that an agent enacts.

So we'll have to look a bit more at the mathematics.

I need to explain more mathematical things.

A gauge theory is a mathematical theory where the dynamics of a system are caused by its geometry, more specifically by symmetries in this system.

So first, we have to define the term of symmetries.

Symmetries are a family of transformation that do not affect the system.

So, for example, what you can see on the screen is the ceiling of the Isfahan Mosque.

And what you can see is that you can just switch it a bit.

I did not calculate how much precisely, but you can rotate it a bit.

And this won't change the picture.

This won't change any observable property of the system.

this is what we call symmetry and in this case it is a discrete rotational symmetry you can have a lot of symmetry the principle is you can apply a transformation to the system that modifies nothing about it and most physical forces that are known are gauche theories

Electricity is a gauge theory.

Weak force is a gauge theory.

Strong force is a gauge theory, all of which are compatible in our description.

General relativity is another gauge theory, which is very compatible with the others for reasons I will not get into.

But in a sense, you have a thing called the Einstein's Hilbert tensor that describes the geometry of spacetime, even the density of matter in it.

And this tensor is by construction invariant under coordinate change.

You can move it around.

It doesn't change the system.

This is what we mean by relativity.

And it is this symmetry.

This symmetry is sufficient to entail the entirety of relativity theory and the entire idea of the geometry of spacetime that causes change in the acceleration of particles.

So this is neat.

This is a very powerful mathematical tool that changes a complex equation into, oh, this is invariant.

That's it.

And there is an argument, there is a pretty strong argument that active inference is a gauge theory.

And it is a gauge theory that is entailed by the symmetries in the probability of presence of the system.

in a specific sub-part of the system.

I need to spend a bit of time over this.

Actually, the math is only going worse from there.

You are warned.

So what you see on your screen, the picture, is the decomposition between the conservative and the descriptive components of the autonomous flow of a system on the left.

What you can see that is wobbling around is a conservative flow.

So it's something that I don't need to explain the specific mathematics.

Essentially, this is what happens when you throw a rock and there is no exchange of energy.

There is no eviscible evolution of the system.

And the dissipative component of the flow, it is on the contrary what happens, the attraction toward a specific subsite of the system that will take energy to do its stuff.

And you can decompose an edidymix this way.

And when you look at this system, what it does is that the dissipative component of the flow will attract the system toward the synchronization manifold, which is, in a sense, the most likely trajectory of a system.

So, for example, you will wake up, drink coffee, go to the restrooms, drive, walk to work.

You should walk to work, I guess.

work, go to lunch, etc.

This is how you do things.

And if you skip some steps, like you forget to eat, especially three days in a row, you will be in a pretty bad state and you won't be able to do your usual stuff anymore.

And there is a force that acts on the dynamics of your brain and that enforces states that are at least roughly coherent with this routine, most likely trajectory.

This is the dissipative component of the flow.

And this is the gauge force entailed by the symmetries in the probability of presence of the system, the agent system in its state space.

OK, this was abstract.

I'm sorry.

And essentially, there is an argument made by myself and Sengupta and Friston

that uh because the dynamics of the system are pretty much set at least within the ecosystem theory this force reduces to expression of attention given prayer beliefs so if i'm thirsty that was not a setup if i'm thirsty i will pay attention to water and as we said prior attention perception is always laden with value so let's lie down with what you can do with something so you pay attention to the activity of opening water bottle and starting to drink

swear to you this was not me setting up this i was thirsty and just took the water bottle i did not think about it this was not me making a point so um i would say this is very nice all of this is very i like math but maybe we are running into a problem of circularity because

Under active inference, we accept that the dynamics of the agent flow from the beliefs of the agent, their priors, and more specifically, the symmetries in those prior beliefs.

But also, in the context of the FEP, we take those beliefs to constitute the attractive distribution of the agent-variant system, the actual probability of the system to go there and there.

So the beliefs are entailed by

the dynamics which are entailed by the beliefs there is a circularity problem in that your definition of a system uh well defines not only the system but everything it can possibly do this means you cannot have this you know ribbon type uh phenomena where your structure produces new activity which shapes the structure in novel way because again everything

is entailed by the symmetries of the system.

And you could say renormalization, you could say path integral, you could say a lot of words.

But the FEP is defined in the context of numerical system theory.

This is what they do.

The numerical system theory is a theory where you have space like dimension x

you have a time-like dimension t, and you have a function phi that defines, in a sense, a flow in time.

So a flow in 0 time is 0, and a flow in t1 time and then a flow in t2 time is equal to a flow in t1 plus t2 time.

This is just a coherence condition that

entail that ensure this is actually a flow in time and this theory represents with maximal generality the evolution of a system that is well defined that has an actual limiting space which evolves in time along the well-defined flow so that have physical dynamics let us say and in essence this framing is not general enough to describe open-ended change

or so I will argue.

And here we go in the main course of this talk, the notion of contextuality in relation to active inference, core points I'm making.

So in quantum physics, we have to talk about quantum physics, I'm sorry.

I said it was only getting worse.

In quantum physics, there is a well-defined physical space, but they are somewhat weird and they are known to be somewhat weird.

So we don't consider the state of the system per se, we consider wave functions, which are basically probability solutions over what could the system be.

And those wave functions, most of quantum physics is defined by the action of operators, which are matrix-like linear operators acting on wave functions.

And because of this, you can frame everything

in quantum physics almost everything has linear algebra and then in linear algebra you have a magic decomposition that tells you that everything in context every matrix is characterized by eigenvector and eigenvalues so for any operator you can find a basis of vectors that cover the entire state and each vector when is just multiplied by something

when you apply the operator to it, and this is sufficient to define the operator.

So you take the operator E, you take a basis of X lambda for different lambda, and for each of these X lambda, E applied to X lambda is equal to lambda times X lambda, what is written on the screen.

Good enough.

And when in quantum physics you perform a measurement,

on a system X, the outcome of this measurement is an eigenvalue.

For example, it could be an energy level.

And the probability that you have to find this eigenvalue is equal to the probability of basically the wave function projected on this subspace corresponding to the eigenvalue.

So this subspace that, if you apply the operator to it, is multiplied by the eigenvalue.

And then the system is updated by, well, this.

The projection of its wave function onto the subspace.

There is a bit of normalization to do, but in essence, it's as it's written.

So if you did not follow a lot of that, not a problem.

I just need to explain how quantum measurement works to introduce the next concept that will actually do the work.

So, there is such a thing as commutativity, which exists when you can apply two things in an order that you like.

So, for example, you could have operator, and you can apply E1 then E2, or you could apply E2 then E1, and there is no difference in anything.

We call that commutation.

If E1 and E2 commute,

then you can measure any system in any order and you will get the same result but in general case unless you want any to share eigen basis so the x lambda different application of the two in different order will give you different results with different probability so this property means that quantum properties as they are observable

fundamentally depends on the basis of measurements.

So the basis of eigenvalue with which you look at the system.

And it is not just that there is noise in measurements, as you would have in a classical system.

It is that the way you look at them fundamentally defines the way they are post-measurement.

And this property is called contextuality.

Contextuality is pretty related to open-ended evolution, a reason we'll see.

And it is not something that you can integrate within DST, at least not with the philosophy that the FEP has and why it uses DST.

So if the time dimension is commutative, so t1 plus t2 is equal to t2 plus t1, then DST doesn't have a contextuality.

You can apply T1 plus T2 or T2 plus T1.

These are the same thing.

These give the same results.

You could decide that the time dimension is non-commutative, but then you do not have a natural understanding of time.

The evolution of the system in the time dimension becomes a creative process where the agent could go any different way that he likes with different results.

So this is incoherent with the physical intuition

that is behind DST, as it's used by the FEP, which is to show the emergence of mind-line property beliefs from very simple physical property, clinical system property.

If you just assume that your system is somehow creative by construction, yeah, you will get mind-line property, but you're not explaining it.

So this entails a kind of conflict between active inference and the

mathematical basis that it claims to have.

So, Active Inference tells you that it grounds the description of cognitive agency, cognitive engagement, by taking bare dynamics, the kind of stuff that you have when you take a bunch of neurons and just check them.

Bare dynamical synchronization of a Markov blanket, so a statistical independence blanket, as we defined.

And because of the FTP, we can say that this entails the implicit prediction of sensory and active states, and this grounds cognitive agency.

This is the core claim of active inference.

But a classical EST does not allow the description of a creative process where states of the world, like letters, take a new meaning, entail new dynamics, are made up along the way.

It doesn't give you contextuality, so it doesn't give you the constructive aspect of cognition, because this is the same thing.

Now, if we want to address this mathematically, we have to go in a kind of weirder, more esoteric direction.

Specifically, what we get when we look at the thermodynamics of observation.

So observation, when it is constrained by an agent's internal flow,

has to bring about physical states, in the sense of well-defined observables that have a causal power on things.

The reason for this is not some weird Penrose-Hawker stuff.

It's just dynamics.

If you observe an object, if you are an agent S and you observe an object O, you are getting information.

By Landauer principle, this entails heating.

So this entails the creation of entropy.

This entropy has to go somewhere.

So it has to destroy information.

This is what entropy is.

If you look at something and you make it exist in the sense of some observable that has causal power, you have to destroy the possibility for observing something else.

So meaningful observation, observation that you remember, because if you forget about it, you do not have the same condition, entails the loss of information in the environment.

the lack of definition of what you are not looking at because of either hitting, forgetting or quantum decoherence.

The reason why is developed in Tegmark 2012 paper.

I won't explain the mathematics now, but I suggest you look at it.

And something that we can claim from it, if we are feeling adventurous, which I am, is

following Fosch and the school of quantum Bayesianism, that you can pretty much reduce quantum cosmology, so the construction of space, physical space as well, relies critically on context.

You just need contextuality, understood as the construction of freely-ventured labels from the choice of context by the agent, and build from that

spaces.

So in the 2013 paper that I am putting here, there is a demonstration of this in a specific sub-case.

Again, I will not explain the mathematics.

I will just say that the mathematical work to show that it is possible is ongoing.

There is no definite demonstration that this is the math we need to use.

But we have reason to believe

This exists.

There exists such math.

And when we look at the role of apologies, I forgot to mention this idea that physical spaces and physical observables are brought about in an untrivial sense by agency, by choice of context, by agent, is called participatory realism.

and its core to the Bayesianist view of cosmology, Bayesianist-like act in France.

So when we apply this notion of past-patriotism to humans, what I want to say, and again I will have to be a bit short on the math, is that assuming this thinking through other mind thing from earlier, assuming that humans think of themselves as instance of a

human type let us properties that has expected action then and assuming contextuality of course then successive cycle of observation or integration and an action of social constraints understood as single expectation over what you're supposed to do entails or at least enables the description of a continuous process of open-ended reconstruction future landscape

And this we know is open-ended because of the contextuality which affords by construction open-ended change.

This is pretty much what it means.

And from there, we can have a dual understanding of the integration and inaction of constraints or landscapes that are built culturally and their evolution through the contextuality of the experience.

So a single phenomenon of contextuality builds both community structure and its evolution.

This is nice.

So, let us try to sum up what was said here.

First, there is such a thing as participatory realism, which claims that physical spaces and physical observables are built, brought about by the agency of observers, in our case, cognitive agents.

And this applies to the specific case of human social evolution by claiming that the relation between structure, so the dynamics of a given landscape, and function, so the meaning it takes for individuals, is a core driver of many evolutions.

We have this ribbon-shaped thing where structure builds new stuff, sorry, builds new function, new meaning, that shapes structure in a constructive way.

And this process

It cannot be a structure within DST because DST tells you what the structure is.

It is what defines a chemical system, the flow it has.

So you cannot have evolution of flow within DST.

It's not a thing.

So to address this, I propose to borrow the antique regime that is defined for quantum physics, at least by quantum atheism, which is partial realism, and which states that the existence of stuff

observables, spaces, derives from contextuality, from the role of context in defining physical reality.

And from my own work and the work of Frosse, I will claim that it translates quite directly in the contextual nature of cognition, the fact that we understand the world through concepts and not through, you know, intrinsic perception of what's out there.

This applies in particular to the case of human evolution, human social evolution, because we can describe, assuming active inference and assuming that contextual interpretation of it, the human social and cognitive activity can be described as the construction and the action of a shared system of social constraints, which shape public behavior and private thoughts through the expectation that they build over behavior and over attention.

This is an illustration of that process and the duality it entails between the action of structure and its reconstruction.

What's interesting with this concept is if you have constraints, and if you have a system of constraints that is closed, where each constraint is brought about by other ones, you have what Montaigne-Lemosio, to an activist researcher, defined as a form of life, as biological organization.

Therefore, this entire contextuality thing not only explains open-ended evolution in the context of sociocultural evolution, but it also places this contextuality at the center of the constructive aspect of life.

So it may be used to build new mathematics of life that accounts for organization and open-ended evolution.

This entails that humans can be understood as a model, well, human sociocultural life forms can be understood as a model for a broader understanding of life.

And in that broader understanding of life, to build it, we need first to understand how humans set the context for social activity.

So, like Vessières, in a sense, I think that this is because we think about what we do, in a sense that is reflexive.

We have what we call the existential stance, which is the attitude of reflecting over what one would do in this context, reflecting about the interaction in disembodied, abstract terms.

And this entails, at least this participates in the construction of many things.

So, for example, taking roles within certain interaction, taking the role of the explorer of the picture, a designer, developer, tester of software.

This enables also to have a reflexive understanding of what we mean by specific acts as communicative acts.

So this entails language and material symbolism.

This enables material symbolism in the sense of monumentality.

Shaping material landscape so as to build certain meaning into this landscape.

And this enables ritual, the embodied synchronous activity that is meant to have a specific

function that is meant to entail specific norms and build specific emotions.

All of this is part of how humans set the context for social activity, and all of this is stuff for which we have a lot of information.

So we can try at least to build mathematics to understand that.

I wanted to conclude on that, saying by Wittgenstein, Sarah saying that human agreement decides what is true and what is false.

It is what humans being say that is true and false and they agree in the language they use.

That is not an agreement in opinion, but in form of life.

Which is, in my opinion, the extent that we can understand interpret Wittgenstein, just a way to say that what is meaningful, what is constraining in human activity is not the specific nature, the literal meaning of a statement.

It's the choice of framings and it's the context that is set by the language used by people, which is, in my opinion, a kind of visionary way to understand, to preface all of this stuff.

So I was, of course, not able to say a lot about the mathematics or really the mechanics that I suppose about all this stuff.

I had to stick to the basics.

And I think you would agree that basics were a bit abstract.

So I would strongly suggest that you look at the stuff I wrote about this.

I have two papers.

One on the right is Contextuality, Cognitive Engagement and Inference, which is a quite bare bones argument that contextuality is indeed intrinsic to cognition and critical to explain change.

And the other on the left, From the Existential Stance to Structural Strains, is a thicker, more committed argument that

Indeed, there are such a thing as social cultural from life that are entailed by social constraints built by existential stance as understood under active inference.

So the entire program.

So thank you for listening.

I hope that it did not get too abstract, like moderates acceptable onto exception.

And I guess I will take on the questions.


SPEAKER_00:
Thank you, Abel.

Awesome.

All right.

I'll start with writing with one question I wrote down and then look forward to anyone's questions in live chat.

So how do...

modeling and active inference techniques like structure learning dynamic markov blanket detection language like notations for generative models deal or not with this question of the open-endedness of life and evolution they don't switch technique and how it's applied i'd have to look at the fine prints

But just to unpack why I'm asking, and then maybe it would be a little clearer, is like, you brought in this question of the open-endedness.

So what is the theoretical challenge posed?

Have prior methods been inadequate?

And what would be the case if there were some type of model flexible applications that could track open-endedness, or is that impossible?


SPEAKER_01:
I don't want to commit on possibility because I guess... So all of this relies on the idea that the choice of state space is not natural.

It's built by a system with activity.

So I don't want to commit to abstract possible and possible depends on what is interesting to you in the process.

So, for example, if I take structure learning, if you have some mechanism to postulate new concepts,

to reach a system will engage with the world.

This is the kind of thing that drives money change.

My point is not that it's impossible to do.

My point is that it's not underwritten by the French principle because the French principle is where you have a fixed amount of stuff and a specific flow in the stuff space.

So if you want to do concept learning, you will have to postulate new things and it won't be as physically principle as it is in the

So what you would need to ground physically this kind of stuff is something else, or maybe a more specific, updated version of DFP, I don't know.

But not something that is framed, strictly speaking, within ecosystem theory.


SPEAKER_00:
Awesome.

Makes a lot of sense.

Okay, I'll ask questions from the chat.

Anyone else can write.

Okay, Susan wrote, do social activities depend on individual allostatic capabilities?


SPEAKER_01:
Allostatic, oh yeah.

Like, how do you say?

So the core arguments I would say that is in the social constraint stuff is that let's say there is a coherence of what the constraints are

between individuals.

So, for example, the concept of money applies to you, it applies to me, it applies to anyone who lives pretty much in a urban context.

That does not mean that it applies the same to anyone.

Money won't mean the same for me or you as it would mean for Elon Musk.

Because, for example, this is, okay, this is, I'm getting technical and finance, but

People who are really, really rich, that are valued in billions, they do not actually have money on their bank accounts.

What they have is these actions, shares and stuff, which is valued billions, and they use it as leverage to get loans after loans after loans after loans after loans.

So they get free money, basically.

This is not money that they spend.

so this does not mean the same thing when we say money depending um on whether we're considering the perspective of you know working class or even normal person a billionaire a bank a state all these agents can engage with money in different manner and uh you can make shit up essentially you can decide that no i don't do a 10 euros bill

You can invent new S-related things.

For example, you can build a common pool, a bank basically with friends.

It's allowed.

You can do it.

You can build new meaning into things.

And this is something, I don't know if you see my cursor, but that is entailed by the integration of social constraints.

Because when I act in the context of constraints, OK, I'm constrained.

These are constraints.

What I'm allowed to do with them,

anything I can do with them, basically.

I'm able to project the meaning and to build the strategies that I like.

And this means that this system of constraints will change with time because people will find new ways to use it at that stage.

And yes, this is related to allostatic load.

This is related to pretty much anything, including a bodily signal that is relevant for me to define my strategy.

The difficulty, again, is to represent mathematically how novelty occurs.

Because we can't just track every single state of everything.

And if we did, that still does not tell you where money is.

There is no money parameter in the Big Bang.

This is not the thing.

So money has been made up.

People have been made up.

Vision has been made up.

And the core difficulty that I'm trying to point out is to

build mathematics that allow for this kind of construction of meaningful observable states.

And yes, again, agency is an important need, so allostasis is.


SPEAKER_00:
How do you think that active inference picks up on that challenge of being able to model that?


SPEAKER_01:
Conceptually, there is the entire inactive semiotics thing.

So active inference allows you to think of cognitive engagements as something that's embedded in concepts.

So in agency and in the context that agents project into the world.

And this is very good.

This is, I think, why we should think of perception and action.

The problem is that the math do not follow.

The math do not math.

Again, we justify active inference based on a framework that is built within DST.

Contextuality and therefore open-ended change is not something that is afforded by DST.

I assume someone in the chat is saying, yes, but what about what Chris Fields is doing?

Yeah, Chris Fields is doing

strange category theory stuff that has, I would say, the capability to show open-ended change because it has very few mathematical constraints and does not have the kind of constraints you find within set theoretical approaches.

I would say the issue is that you do not have this basic intuition of just better synchronization building new stuff.

because the mathematical framework is very general it's not just bare synchronization anymore it's i don't even know what it is it's info how do you say infomorphism i don't know what infomorphism is like i have a definition in mind but i do not know what to do with it so i would say there is a lot of work that remains to be done to build meaningful physical intuition about this process

because basically we have the choice between math that are too constrained to describe any change and math that is not constrained enough to explain it in terms of specific constraints and specific patterns of activity.


SPEAKER_00:
yes certainly that comes up like what is the most general schema for modeling a cognitive agent or a cultural agent it's just a blank spec the less the schema says the more general it is and the less is there and the more degrees of freedom and modeler historiosity come into play

because the less there is the more general it is and then that's like where the low road and the high road kind of intersect is the free energy principle which your talk also did a great job of bringing into and out of quickly um is architecture independent

It's some relationships and frameworks that meet inactive inference with the bottom-up embodied, extended, et cetera, et cetera, lineage and ecological psychology and all of the actual model constructivism and instrumentalism.

And it's interesting how, yeah, what do you think about this?


SPEAKER_01:
I'm not sure I understood that.


SPEAKER_00:
where you're going after the sorry okay jesse wrote the problem with math and physics and any scientific discourse is the models just are more approximate of the error correction criteria the errors are more approximate of the error correction criteria okay


SPEAKER_01:
um where are you continuing on in your research and work like after seeing things this way or is it laid out in the papers or where else are you going with it so i should really have done a part in the talk about this runtime so essentially um i had to stop focusing on the math because i had to look at the sociology and i have to have to

I have to have a proof of work for this entire array of concepts.

And I'm focusing on this application to concrete process of what I call ground building.

So the construction of the set of priors that is shared by a community.

Mostly the two case studies that I've been focusing on are the Unification Church, which is Korean, far-right, Christian, light,

cult that, among other things, kept the conservative Japanese party in power for 70 years, edited the journal Reagan was reading, and according to CIA, I did not verify, could a country in South America, so as you can see, very important points for a cult.

and they are mostly known because of their ability to generate huge mobile panics around their coercive practices for recruitment and fundraising and so i wrote a paper about an actual entrance approach to this to this recruiting and you know conversion strategies which was successful because

Something we have with Active Influence and that is hard to address from a pure ethnographic perspective is the integration between the linguistics, what we say, and the base cognition, how we experience something.

This is something that cognitive science... Cognition is something that cognitive science studies pretty well, I think.

And the other major case study I've been working on

is the construction of the landscape in the Sierra de Valença, which is an archaeological site started by Xscape, where you have a lot of finial mounds that are playing around and who may or may not have a structuring role in the navigation of the area.

And so I've been doing theory and modeling on what's going on there.


SPEAKER_00:
That is very interesting.

Dare I ask how the mounds play a role in the navigation of the area?


SPEAKER_01:
So it is claimed that, basically, if you go from mound to mound, you are pretty close from an optimal path to travel through landscape, which is very well done.

So it's not trivial to know where you're supposed to go.

I would say the non-trivial question is, at least

context of the illustration on it, did people intend to use the mounds as landmarks to help with navigation?

And I would say our core point is that intent, at least in the common sense, is not that important because from the moment those mounds are built, they do shape the landscape.

It does not matter when you say this or that.

what you profoundly mean in your inner self because there is no such thing as a inner self there is what you do the context in which you do it and how it shapes the context and i would say this is a pretty core to this approach of ground building that i've tried to construct and illustrate


SPEAKER_00:
interesting it makes me think about sort of the first and third person biosemiotic perspectives like when it comes to ant colony pheromone modifications of the environment or nest building intention wouldn't come so much into play yet it may dominate aspects of our experience

so considering well is the biosemiotic event of the pheromone perception or the mountain navigation or or the reading or writing of an environmental mark in what ways does the causal consequence or experience from the first person perspective accord with the outside

behavioral observation from the third person perspective which sort of strips the experience of intentionality yet does so with methods like intentional inference and and inference to latent states proposed by modelers so clearly part of the modeler's constraint however the reference of those modeling constraints is the biological constraint so


SPEAKER_01:
so i guess this is uh something that's pretty critical in the approach i'm proposing what we think of intentionality pretty much does not exist because uh the baseline model that we have in our accidental safety is you have a body and you have a mind and the mind controls the body this is not a thing um well you have a perception and use this perception to decide and act

And this is not a thing.

Your perception of the environment is integrated to a perception of yourself, which is a direct cause for your behavior.

So, intentions are embedded in the environment.

And this is true for ants and the bio-semitics of, you know, what is it called?

Well, pheromones.

And this is true for cults.

So, for example, there is an entire debate around

Are the munis, so the cults, the Unification Church cults, are they con artists?

I don't know.

I don't care.

I don't know if they believe in what they say.

I think they do.

I don't think that changes the morals of the situation because they have built the system and the system is bad and we do not have, we can just characterize the context, what it is, what makes people do.

And again,

Thinking about whether people intend to build something bad in the deep of their inner selves is not a meaningful question because there is no such thing as an inner self.

There is what you think to yourself.

It's a thing.

But there is no self that is not embedded in some context of operation.

If your self is what you expect yourself to do, how you expect yourself to behave, your self model,

then it's always embedded in something, at least self-talk.

There is no way to escape that.

So again, there is no... Let's say the notion of intention that we can motivate based on cognitive science, fields of cognition, it's much more minimal than the stuff that we expect and that we usually take to be necessary for responsibility.

So there is a problem.

And as far as I'm concerned, this problem can be solved sociologically by the analysis of premises, by the analysis of social constraints, of the common ground of social interaction.

And I would be pretty confident in it, because if we can't do that, we can't do anything.


SPEAKER_00:
Cool.

Do you want to add any more comments or what else are you thinking about, or how would you want to see people pick this up and continue?


SPEAKER_01:
Uh, read my papers.

That's the simplest stuff.

I'm trying to do an advert for them.

I'm trying to show them.

But again, it's mostly math.

No one else in math by talking.

That's not a thing.

I don't think so.

So I would highly recommend that you take a look at the paper, which go much more.

detail about for example the mechanics of social cognition as i understand them and i strongly suggest that you look into the social sciences project on the active influence of sorry the active influence attitudes that i am founded i guess i can say that and send me anything that you uh that you would want me to look at and i will look at it and

I want to build new stuff from that.

This is the core message.

And I think it's pretty possible, pretty easy, pretty constructive, pretty productive, good things.


SPEAKER_00:
Awesome.

I want to ask so many questions about the social science project, but that's a great way to end it.

And I would look forward to it being reactivated this year too.


SPEAKER_01:
Yeah.


SPEAKER_00:
Let's do this.

Cool.

Thank you, Avel.

Thank you.


SPEAKER_01:
Bye.