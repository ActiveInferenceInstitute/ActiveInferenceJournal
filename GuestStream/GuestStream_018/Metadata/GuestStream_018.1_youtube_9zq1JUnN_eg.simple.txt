SPEAKER_04:
Hello, everyone.

Welcome to Act In Flab guest stream number 18.1.

We're here with Julian Keberstein and Michael Kirchhoff, as well as Dave, Dean, and Steven from Act In Flab.

And we're really appreciative for the authors for joining today to be discussing some of their work.

We're going to have a presentation by the authors and then following the presentation, we'll have ample time for discussion.

So please feel free to write any questions down in the live chat and we'll get to it.

So without further ado, Julian and Michael, thanks a lot for joining and please take it away.


SPEAKER_06:
Well, thanks so much for inviting us.

We've been looking forward to this particular session, and thanks for staying up late in the US and wherever you are in Europe for getting up early.

It's only 3.30 in the afternoon here for us, so that's more manageable in Australia.

I'll just share my screen.

Is that right?

Yeah, you guys can see that.

Bring that up.

So that should all be clear in a second, is that right?


SPEAKER_04:
Looks good.


SPEAKER_06:
Great.

So the paper is called The Literalist Fallacy and the Free Energy Principle.

It's a philosophical paper on the topic of scientific realism, scientific anti-realism slash instrumentalism in the context of the FEP, or the Free Energy Principle.

I suppose just as a primer, this is a revised and resubmit stage for our paper at this particular moment in time.

So any comments that we might be able to get to further improve the quality of the paper will, of course, be welcomed.

So let's start.

There will be a little bit of, I suppose, conceptual stage setting at the start, just given the nature of this particular paper.

And also because it sort of speaks to a few other issues that go beyond just a sort of narrow focus on the free energy principle.

So this is the debate as it sits, or at least as we try to sketch it in the paper, between scientific realism and instrumentalism.

So let's just say briefly what scientific realism is and briefly what instrumentalism is.

And then I will say a little bit more about how to think about scientific realism.

Overall, the point of the paper was to sort of try to marshal a set of arguments for why at least a version of scientific realism

can be accommodated by FEP models.

And it was motivated in part because it seems like in the last few years there's been a flurry of papers in one way or another arguing for scientific anti-realism with respect to the FEP or how to interpret parts of that particular model.

So that's the kind of setting we're in.

So, scientific realism, that's the view that one reasonable goal of our currently best scientific theories, scientific models, is to offer literally true, or probably true, or approximately true, or probably approximately true descriptions and explanations of target systems.

I have here in bracket, for example, natural phenomena, but it could also be artificial systems in the context of artificial intelligence, artificial life, for example.

Now, by contrast then, instrumentalism or scientific anti-realism, that's the view that scientific theories and models are nothing but instruments for prediction of observable behavior of target systems.

So here, the claim is something like this.

From an instrumentalist perspective, theories slash models, they have explanatory power, and that gives them some utility.

But they're not, in any sense of the word, truth producing.

So one has not to think about instrumentalists or the instrumentalist position as putting forth statements about how the world is on the basis of their models, by which you can say something, say true or false, about how the world is.

So the main question now is, for this particular paper we are considering, is the FEP truth producing in a way that's consistent with scientific realism?

And of course, as I mentioned just a minute or so ago, we think it is indeed consistent with a particular way of conceiving of scientific realism.

Maybe a footnote here that's important, both scientific realism and instrumentalism are quite

are multiple, there's multiple different versions of each particular framework in the philosophy of science.

So we're trying to offer a reasonable general characterization of these particular frameworks in order to sort of get some traction on the debate.

So as I said, it's a reasonable goal of our best scientific theories and models to offer these true or probably true or approximately true descriptions of target systems.

Now, here we draw inspiration from Peter Guthrie Smith, his book here, Theory and Reality, that tells us how perhaps to interpret that particular general claim.

He says the following.

He says it's a mistake to express the scientific realist position in a way that depends on the accuracy of our current scientific theories.

So if we express scientific realism by asserting the real existence of entities recognized by science at this particular point in time, then if those particular theories turn out to be false, well, then the whole framework of scientific realism turn out to be false.

So we shouldn't think that's what you have to do in order to advocate for a kind of scientific realism about scientific models and theories and their relation to target systems.

So building on this, we can say.

So again, this notion here is that an actual and reasonable aim of science is to give us these accurate descriptions.

Well, that's not the claim that scientific theories must be true now and make truth-producing claims about target systems now.

I mean, it's a nice thing if they do, but it is not a necessary condition for one to adopt scientific realism about scientific theories and models.

There's no commitment to the success of the individual sciences, so there can be trouble in biology, but we can still hold, for instance, scientific realism about, for instance, the FEP applied to the cognitive sciences, for example.

Now, importantly, and this is why I'm just spending a little bit of time initially on scientific realism, the kind of version of scientific realism we're interested in

is going to allow for theories and models to posit idealizations, for instance, understood as distortions, approximations, understood here as perhaps inexactness of scientific models.

They can pose fictional entities, for instance, entities that are not actual, and thus like in the here and now.

But the important point is that

You can keep that view and still endorse scientific realism because one aspect here is that the long-term aim of working with your scientific models is for them to become truth producing or to become more and more aligned with the target systems that we're interested in.

And we'll finesse this view as we sort of move along.

Now, this issue between the scientific realist and the instrumentalist, as we are considering it in the context of the FEP, comes up when we consider what we call the map problem.

And this is not a term of art that we have invented.

There are other authors, both in the FEP and elsewhere, that make use of it.

For instance, Mel Andrews in her nice paper

2021 in biology and philosophy that speaks of this particular problem.

So this is just a quote from the paper that gets us thinking about what our focus is.

So we're going to ask, what is the relationship between scientific models constructing using the FEP and the realities these models purport to represent?

Our focus is especially on the FEP and what, if anything, it tells us about the system that is used to model.

And this is what we call the map problem.

How does the map, your theories, your models relate to the territory, real world target systems of which those theories and models are maps?

Now, if there's anybody joining on the live stream, this is just a very brief statement about what the free energy principle says.

Julian and I, and as well as Ian, are working under the assumption that that doesn't need to take long to introduce that in this particular context.

But very briefly, then, the FEP states that a self-organizing system that tends towards maintaining a non-equilibrium steady state with its environment must minimize free energy.

where minimizing free energy, at least under a certain Bayesian interpretation, is to maximize model evidence, that is, maximize the likelihood of some data given a model of the system's interactions with its environment.

Now, how does the MAP problem arise in the context of the FEP?

Well, it might arise if you're a, say,

a researcher working in artificial intelligence and the aim is to build robots that engage in active inference for example navigating or making decisions etc so here the question becomes what's the relationship between our fep model understood as an active inference model and then how

One engineers, if you like, artificial agents to perform in accordance with those particular models, what those models specifies in terms of, say, decision making, belief updating, and selecting action policies for adaptive behavior.

A different way the map problem might arise would be from the computational neuroscientific perspective, where one might be interested in tracking transitions across belief, perhaps in deep generative models.

And the map problem then is, well, how does that

theoretical specification of free energy minimization under active inference, how does that map onto what the brain actually does in order to, say, shift from beliefs to beliefs or to make decisions about what to do in the world?

So that's just a few examples of where this particular issue becomes prevalent.

Now, just to situate this discussion a little bit, because there's a few tweaks and turns in the paper, and it's a large and somewhat complex conceptual landscape we're working in, or at least it seems to me.

We're just going to try to situate this a little bit more so you get a feel for this.

We've got a nice reviewer comment that sort of introduces the issue here.

So the comment is something like, if we take the free energy principle, like many other theories across different sciences, then we can think about that as a kind of model-based approach to science.

And if you look at the little image over here, which is a modification of Geer's description of how this works, modified by Geoffrey Smith in a 2009 paper,

we can initially start to develop a description of a model and to say something about what the model system in question is.

And the comment is something like this.

We can study models for their own sake.

As Andrews has pointed out, Mel, as I referred to earlier,

Any model that can be treated realistically can also be treated instrumentally.

Scientists can disagree about which bits of the model are meant to be real.

Now, this is important in understanding how the map problem arises.

So Andrews in the 2021 paper gives us a whole list of different ways one can see the kind of mathematical structure of the FEP being interpreted as a scientific model.

The work of Michael Weisberg is influential in the context of philosophy of science, philosophy of biology.

So she and he, they can with sort of a minimally three different models that we are interested in, as a sort of targetless model, the FEP as a generalized model, and then the FEP as a target-directed model.

Now, you can work purely on the mathematics, if you like, of the free energy principle,

for the sake of just understanding the model, for getting your model description right of your model system as per that image.

Now, here the point is that that in and of itself doesn't give rise to anything like the map problem because you can disagree.

You can come at that work from an instrumentalist perspective.

You can come at it from a scientific realist perspective.

But doing that kind of work doesn't really allow you to adjudicate between the two positions, or so it seems to us.

So that would be the instance of a targetless model.

You're not asking questions that relate from the model to a target system.

You can treat the FEP as a generalized model.

You can perhaps think of it as you could model theories of natural selection from the point of view of the FEP, but we are not saying anything about the involvement of any particular kind of species.

That maps on to, for instance, a different discussion as well, which we consider, but we won't talk to unless it comes up in the Q&A, about the role of the Markov blanket notation.

Now, as we put it in the paper, that gives you a kind of generalized approach for delineating boundaries, but it doesn't give you an approach for delineating boundaries for any particular individual.

In that sense, it's a generalist take on FEP models on the basis of the Markov blanket formulism.

Now, the math problem for us gets interesting when you pursue a target-directed model, when you try to implement the mathematical structures posited by the FEP in terms of a process theory such as active inference.

So you're sort of moving from a mathematically general characterization of the adaptive behavior to specifying what a particular individual or set of individuals must do

in order to engage adaptively in the world.

So you're sort of committing yourself to getting the right-hand side of this model or this little image, if you like, saying something about in which way do your model now resemble the systems that you're actually aiming to explain or understand something about.

OK, so once we have that, we should give the argument for the instrumentalists.

And then once we've done that, we'll see the kind of problem that we raise for the instrumentative that we think is a kind of a fallacy of inference from certain considerations to certain claims about the FEP.

So premise one here is that active inference models under the FEP introduce distortions in representing biological and cognitive systems via idealizations.

So one way to think about that might be the introduction of variational free energy as a kind of distortion into the framework in order to kind of solve a computational problem about how surprise is minimized, as well as in exactness via approximation.

And one example might be something like introducing this idea that free energy minimization can be construed mathematically as akin to a kind of

bayesian inference would be an inexactness introduced into the formalism primarily because it was so it seems nobody thinks that the brain quite literally uh encodes something like base's theorem okay premise two then is that scientific realism requires that models provide descriptions of target systems that are literally true

So that's somewhat of a dead aisle, if you like, if you were to hold scientific realism with respect to premise one.

Premise three, then, is that active inference models are not true and accurate representations of biological and cognitive systems, precisely because of the issues raised in premise one.

Therefore, active inference models are false.

They're at best useful fictions.

And just to give you the references of where we are drawing work from in terms of defining the term idealization and the term approximation, here we're using a nice paper by McMullen on Galilean idealizations to think about idealization, and we are using a canonical paper by Norton to define approximation.

These are somewhat contentious, primarily because there's, as one might expect, there's all kinds of other takes on it, but you have to come down on one side, I suppose.

So, once we have the instrumentalist claim up and running, this is the kind of fallacy that we're arguing that a set of papers defending instrumentalism in the context of the FEP is making.

And we coined it the literalist fallacy.

And just the prime use of

Premise two here is the claim that scientific realism requires that models provide descriptions of target systems that are literally true.

Hence the claim the literal is fallacy because we're going to show that's not a necessary condition upon which the base one's defense of scientific realism

So what we say is the mistake, the literalist fantasy is the mistake of accepting or affirming about the FEP from the fact that active inference models are not literally mapped onto biological and cognitive systems.

A slightly different formulation that we have here is that in this context of the FEP, some find apparent discrepancies between the map and the territory a compelling reason to defend instrumentalism about the FEP.

And we take that to be problematic, given this particular kind of fallacy.

We identify this particular fallacy by those defending instrumentalism about the FEP and we call it the literalist fallacy.

Here's the second variation of it, if you like.

This is the fallacy of inferring the truth of instrumentalism based on the claim that the properties of FEP models do not literally map onto real-world target systems.

So one question that might be interesting to discuss in the Q&A is whether or not it's indeed the problem for an instrumentalist to infer the truth of their own position

on the basis of the claim that the properties of FEP models do not literally map onto real-world target systems.

So the pushback here on the second formulation is something like this.

Instrumentalists are not asserting the truth of their own position.

That would be self-contradictory.

Now, there's a set of conceptual issues here, but I just wanted to flag the issue and perhaps come back to it in the Q&A.

It would take us too long to get into it, and it is somewhat philosophical and conceptual.

Here's some evidence, if you like, a set of papers across some different topics that we argue and are all committing this kind of fallacy.

Here's a 2020 paper by Van Ness and Hippolyto that state, they state that it remains, quote, it remains disputed

whether it's the FEP statistical models or scientific tools to describe non-equilibrium steady-state systems, which we call the instrumentalist reading, or are literally implemented and utilized by those systems, the so-called realist reading.

And what they're going to conclude is that since FEP models are not true and accurate descriptions of these target systems, instrumentalism turns out to be the only option.

So for us, that's the literalist fallacy because it assumes that the realist position is that your theoretical models literally have to be implemented in target systems for that kind of framework and the philosophy of science to be up and running.

Runeberg et al.

2021, presumably updated to 2022 at some point this year in their target article on BBS, focused on the ontological status of the Markov blanket formulism in the FEP.

Now, they argue that much of the literature on the FEP implies that organisms literally instantiate the mathematical structure of Markov blankets.

They argue that such a use of the formulism conflates a model with its target system.

Now, if you think that in order to use the Markov blanket formalism productively, even from the scientific realist point of view, that the mathematical formulation of that particular formalism has to be implemented in the actual target system, then you're committing the literalist fallacy, because even the scientific realist is going to push back against that.

Colombo and Palacios in a 2021 article in Biology and Philosophy target the issue of ergodicity in the FEP, namely that one can realistically model biological systems as having an ergodic density.

Now, they deny that ergodicity captures properties of biological systems, and therefore the FEP is biologically implausible.

Now, a line on that is that's akin or a species of the literalist fallacy, precisely because it's going to assume,

that the theorists actually think that it's part and parcel of target systems that they have an ergodic density.

Our take on it is, no, that particular approach to modeling state transitions under the FEP is precisely that.

It's an approximation of scientific convenience in order to say something about how systems occupy states over time, but you shouldn't conflate that particular perspective with saying that's literally the case of target systems.

i'll skip the last quote here uh just for time considerations we can come back to it if there's there's any issues okay so let's turn to some examples and some cases of this literalist fallacy and how to how to think about it and in terms of scientific realism so in the paper we consider a bunch of this sort of cases or examples we consider the notion of variational free energy

We consider the Markov blanket formulism.

We consider the role of Bayesian inference in these sorts of formulations.

And then finally, we turn to consider the topic of ergodicity.

And for this particular presentation, if you like, we're only going to focus on the first variation of free energy and then the latter, ergodicity.

And perhaps we can come back to the other cases in Q&A.

OK.

What strikes us, there's two different ways of interpreting the variational free energy notation, primed here under the consideration that it seems as if organisms are minimizing variational free energy in the long run.

The as if formulation here, which seems ever pervasive now in the literature,

is not, I think, a one-way street.

There's a couple of options here that we now want to try to unpack, especially because we're doing the presentation and especially because we've been prompted to do so, I think, by a set of review comments.

But let's get into it.

This is the sort of first option, if you like, that's going to deliver a set of reasons for thinking that instrumentalism is the case for the FEP, and we're going to push back on those particular reasons.

So variational free energy is an information theoretic construction used to compute how organisms are able to resist decay by positing variational free energy as an upper bound.

Now, under the FPP, for an organism to exist, it must keep its states within certain bounds.

So that's the generic open up.

So I'll give you some examples now of the as-if formulation, sort of prompted by this quote from Friston.

The FTP is a mathematical formulation of how adaptive systems natural tendency to decay.

Ramstad and colleagues in 2020 paper say, this means that internal and active states will look as if

they're trying to minimize the same quantity, namely the surprise of states that constitute the thing, a particle, or some creature.

So here we have the as-if statement.

They appear to perform this kind of minimization of variational free energy.

Similarly, in a 2019 paper with himself,

Any system that avoids surprising exchanges with the world will look as if it's predicting, tracking, and minimizing a quantity called variation or free energy on average and over time.

Now, I've included this because we're going to speak to this one, this particular paper, as a second option for how to think of the as-if formulation and how perhaps to square as-if formulations with a kind of scientific realism.

Van Ness 2020, the system does not actually predict, infer, track, or minimize a quantity called variation of free energy, but it merely looks as if the probabilistic model merely tracks certain real statistical relations in the organism environment system.

So this particular reading here, this first reading, the as if formulation of variation of free energy leads to scientific realism,

about active inference models under the FEP.

And it does so precisely because we have to sort of treat systems only as if, but not actually minimizing this particular quantity.

Yeah?


SPEAKER_01:
Just jump in on this a minute.

So the Ramstad quotes there are saying that what it looks as if the

system is minimizing is surprisal whereas van s shifts to talking about variational free energy good point so um yeah i think we could accept that it looks as if the system is minimizing surprisal because variational free energy is this bound on surprisal yes so the ramstead quotes are actually consistent with realism yes that they could be read as allowing that

the system really does minimize variational free energy.

And it looks as if, in doing so, it's minimizing surprisal.

So perhaps we can come back to that in the discussion.

I don't think that Ramstad and colleagues are necessarily best read as endorsing instrumentalism.

I think is quite consistent with realism, actually.


SPEAKER_06:
Yeah, no, I agree.

And I think we'll see that come out.

reasonably explicit when we turn to the second option to just step in if I don't actually manage to pull that out explicitly.

Very good, yeah.

So basically, what we can now assume is that variational free energy on this first reading is a mathematical fiction.

At least that's what we're told.

These sorts of constructs are useful fictions, but they do not actually exist.

So how to think about that then?

Because we tend to agree with that particular point.

You can think that variational free energy, a bit like a Galilean frictionless plane, for example, is a concrete entity, as in it has some mathematical concreteness about it.

But it's not one that actually exists in target systems.

Here, the mass is not the territory.

So even though we can kind of think of frictionless planes as being concrete in one sort of sense of its mathematical concreteness,

one wouldn't want to infer that Julian is a friction plane, for example.

That would be false, and it would ultimately end up in a bad set of influences.

Now, here again, we draw on the work of Godfrey Smith in order to think more generally about the use of fictional entities in the context of science more generally.

But here's what he says, generally speaking, he doesn't address anything to do with the FEP, just to make that clear.

Now, fictions do not exist, he says, but at least many of them might have existed.

And if they had, they would have been concrete, physical things located in space and time and engaging in causal relations.

So it's kind of counterfactual test you can run on fictional entities and science from the point of view given here.

Now, you can say fictional entities such as variational free energy that might lack actual existence in target systems can be useful for understanding target systems nevertheless.

So, you might say that active influence models provide insight into the workings of biological systems, for instance, with helping to understand what a system has to do in order to maintain homeostasis.

You can also say something like the following, namely that under a kind of Bayesian interpretation of how one minimizes this particular quantity, you can draw some similarities to how that, to how, um, surprise is minimized in actual target systems by understanding something about the minimization of variational free energy.

But there's a kind of similarity relation one can draw between the positing of fictional entities in the theoretical models,

and then what actual target systems are doing.

Now, just to give you a sense of this, so motivated by active inference models on the DFEP, Pa and colleagues say the following about the significance of their work on active inference.

I'll just give you the quote, and you can kind of see this coming into being.

So in brief,

We use Magnoencephalography in combination with eye tracking to assess the neural correlates of a form of short-term memory doing a dot cancellation task using dynamic modeling to quantify changes in effective connectivity

we found evidence that the coupling between the dorsal and ventral attention networks changed during the saccadic interrogation of a simple visual scene.

Now they say here, and I've highlighted this intuitively, this is consistent with the idea that these neuronal connections may encode beliefs about what I would see if I were to look there, and that this mapping is optimized as new data are obtained with each fixation.

So the idea here is that fictional entities, such as variational free energy,

allows for a further understanding of target systems by making precise how target systems may minimize free energy, whether or not that be variational free energy or expected free energy, in the sense of minimizing their surprisal and not directly in the sense of minimizing these two notations.

So the summary here that we give in the article is that

The FEP comprises what is known as indirect representation of a target system.

So it says something indirectly about the operations of target systems, even if it involves the use of abstract entities.

It's an idealized approach representing complex or unknown processes in the world.

It's standard practice to view scientific models as indirect representations of the real world target system.

Now, furthermore, most theoretical models are composed of a set of mixed claims.

Now, this is rather important for us to sort of preserve a notion of scientific realism about the FTP.

Basically, and we use the work of Spielert here,

This means that the model will posit, if true, the presence of what he calls both OK entities, such as electrons and their ilk, and supposedly non-OK entities, such as numbers or theoretical ideals.

Now, we think the FEP is something like such a model, so a model composed of mixed claims.

It put forward all kinds of OK entities, neurons, reflex arcs, etc., and perhaps what you might think of as non-OK entities, such as the variational free energy notation,

where non-OK entities has to be understood in terms of not being literally true of their target systems.

So this gets us to the second formulation that Julian alluded to earlier of the as-if formulation.

Now, take us an example here from Dennett's 1996 book, Kinds of Minds.

And I think thanks to an anonymous reviewer here for pointing us to this idea.

than its so-called Popperian creatures.

These creatures are said to be able to select from possible action policies, although it's not put exactly in those terms, in order to prune away inferior options to avoid fatal consequences.

So in this sense, these creatures have some kind of inner environment where they can select amongst possible actions.

Now, here's the Tales of Two Densities paper that I co-authored with Max Ramstad and Carl Friston.

I'm not going to read you the quote here, but the basic idea is going to be something like this, that one can prune away unwanted action policies by testing what kind of expected sensory observations one might encounter were one to elicit certain kinds of actions.

But whether or not one prunes away action policies, the crucial part here is that that kind of belief transitioning over possible sensory outcomes given certain kinds of actions can itself be characterized in a fictional way, in a form of fictionalism, as Julian mentioned earlier, that is entirely consistent, as far as we can tell, with scientific realism.

So for the Popperian active inference feature, one can think of trajectories pursued over possible action policies in terms of fictions, as I just mentioned.

And now we come back to our formulations of fictional entities and science from a couple of slides ago.

Now, you might say that action policies are concrete belief states, but they're not actual.

They do not actually exist.

They do not actually exist given their counterfactual or hypothetical characteristics.

Yet were they to exist, they would be actual with some causal powers.

There would be implications for inferring one over the other.

Arguably, some of the hypothesis come to fruition and therefore exist.

So what we have here is an as-if formulation of FEP explanations that has a fictional characteristic to it.

So part of the entities that compose our FEP explanations are fictional entities, but they're entirely consistent with scientific realism about FEP explanations, given the considerations about the status of fictional entities in science in general.

Okay, so let's see, we've been going for about 35 minutes.

I'll start wrapping this up so we can get to the Q&A.

Second case, one slide really quickly about ergodicity, just to get us thinking about this, at least, and we can come back to it.

Now, Friston defines ergodicity in the following way.

One can interpret the average amount of time a state is occupied as the probability of a system being in that state when it's observed at random.

Okay.

Now, Colombo and Palacios in this 2021 paper in Biology and Philosophy, they say that phase spaces of biological systems are structurally unstable.

They're always changing and unpredictable, making them non-ergotic.

There isn't a set of fixed states, if you like, that the system keeps returning to if such a system is a biological system on this particular account by Colombo and Palacios.

Now, they say that the FEP trades off realism for generality and mathematical precision.

And they do so in the sense to sort of put pressure on this idea that the FEP can be thought of in terms that are consistent with scientific realism.

Now, it's true if you take the approach to the FEP as a generalized strategy to modeling,

that the FEP trades off realism for generality and in the same time maximizing mathematical precision.

But I think here's the twist.

So this would be the first way of responding to this particular claim.

If you turn the FEP, the mathematical structure, into a target directed system, what we get here, we get to work with specific systems.

So now you get to increase the level of realism in your

in the relationship, if you like, between your model and your target system.

A second way of thinking about ergodicity is that, yeah, okay, it's true that they don't map up, they don't have biological plausibility, but you can think of ergodicity as a convenient modeling assumption.

So the FAP doesn't claim that biological systems are literally ergodic.

There's even a loosening in the literature now to saying locally ergodic,

Or there's even a further loosening to shifting talk of ergodicity entirely to talk about kind of nest densities and so on, where you can actually still retain this kind of meta-stability, this level of change and this degree of unpredictability.

So to conclude, arguments for instrumentalism about the FEP, or at least the ones that we are considering, I'm sure there's one or two we have not considered, trade on the literalist fallacy.

They accept or affirm instrumentalism on the grounds that the properties of active inference models under the FEP do not literally map onto biological systems.

If we are correct, then there is a version of scientific realism that is a live and tenable option with respect to the FEP.

Thank you.


SPEAKER_04:
Awesome.

Thank you.

Okay.

Great times.

Perhaps for the first word, we'll go to Julian.

Feel free to maybe say hi, give your first take, and then we'll go to the Acton Flab participants.


SPEAKER_01:
Yeah, so thanks for having us.

It's going to be fun to talk about this paper.

I think we should just jump straight into discussion rather than me add anything onto what Michael already said.

He gave an excellent summary of the paper.

So let's see what you guys make of it.


SPEAKER_04:
Okay, so age or beauty?

Where do we begin?

Dave or Dean or Stephen?

Who would like to go first?

Stephen first and then either Dave or Dean.


SPEAKER_00:
Well, I'd just like to say thanks for the book that you published a few years ago about the third wave.

It was actually the key book that kind of

made me keep going with active inference after i first heard about it because uh so it was a really really cool it's nice to hear boundaries because i've been looking at inactive embodied approaches and uh so just that's the first piece um and um so in there you talk about the idea of mark of blankets you're not directly but the idea of things being dynamic and changing and um i'm curious whether when you're thinking about instrumentalism

there's a there's a in some ways the the danger of instrumentalism or is it starts to everything gets referred back to maths and then the maths isn't tethered to reality because it's instrumental and you can't it can be a kind of a challenge then as we try where we're trying to bring in the four e's um to think about well how how does this start to map onto

the way that organisms are trying to get a grip on the world in a bit more of a literal sense outside of the model.

So, yeah, I'd be interested in your thoughts about this question of the ability for the modelling to be used in sort of almost a way to

get into phenomenon that might be happening during this minimization process michael do you want to start i i i can start um


SPEAKER_06:
Well, I think one thing that's important there, just stepping back, and thanks for the nice words on the book.

That's always a pleasure to hear.

The instrumentalist, I suppose, is just sort of, as I said, making a truth claim is off the table for an instrumentalist, partly because...

the definition of instrumentalism is the sort of not to put forward any kinds of statements about the world that can be true or false now they can say that you have observations you know you take in observations about how systems work and that's fine

One line there that's been pushed a bit in the literature now is to say, well, you can be agnostic about whether those kinds of observations can sort of truthfully reflect or oppositely, falsely reflect anything about the actual world.

Now, my sense is that, and this is just my sense, that scientists, given different tasks and activities, questions and focus points, will shift a bit.

between these.

And that's, in a sense, why I had this notion, or why we have this notion of a targetless model.

I think precisely because that's the domain we don't need to come down on one or the other side, query the model for gaining more understanding.

A nice example, I was talking to an ecologist on the weekend, is just thinking about these massive climate change models with this hyper-practical goal

But yet they're so wonderfully complex that one spends one's career figuring out how the model works.

And that's OK, in a sense.

But I'm shifting it and trying to answer your question.

I think some of the work that Julie and I have been doing on the sort of ever or on occasion to soften that shifting boundaries delineated by appeal to Markov blankets

tells us something concretely about such systems.

So we can start thinking a bit about the differences between, say, the spider and the spider web relative to whether or not the Australian orb weaver has just eaten its web or whether it's producing its web.

So in that sense, you might think that its sensory epithelia is shrinking and expanding depending on what time of day it is.

So, yeah, and to add to that, I'd like to think that it's the ambition of even theoretical neurobiologists, or if, you know, depending on the domain or issue they're targeting, is to, if you're working in the context of psychiatry on the basis of FEP models, you want to understand something about, well, actual psychiatric disorders that we as human beings may experience

may go through and and you want to understand the the mechanisms of how that of how that works so you can intervene in the right kind of way like you want to do that presumably you have to say something about how those mechanisms work and so you can you can quite literally as i said manipulate if that's possible in one in one way or another anyway so that's my sort of initial take on that


SPEAKER_01:
I want to go in a slightly different direction on how does the free energy principle relate to these ideas about embodied, inactive, extended cognition?

Well, Thomas Van Es and Ines Hippolyto both argue for an instrumentalist reading of the free energy principle in order to show how it could be consistent with

a non-representational understanding of cognition.

So they're keen on avoiding the idea that the brain literally represents the world by encoding a generative model.

And the way that they avoid that interpretation of the free energy principle is by endorsing the claim that the free energy principle is just a useful fiction for modeling the brain.

And we think there's a couple of different issues that are getting mixed up here.

So one is representational readings of the free energy principle.

And Carl Friston often says that the brain doesn't have a model, but is a model, that the organism as a whole is a model of its environment.

And here he's picking up on ideas from cybernetics, like the good regulator theorem, the law of requisite varietyism from Ashby.

so that idea of the organism being a model of its environment um we think can be read in a realist way actually but but also as suggesting a non-representationalism so this came up a little bit when michael was talking about popperian creatures where they're able to because of the deep

hierarchical nature of the generative model.

They try out possibilities before they act on them.

And that's sometimes taken to imply in the philosophical literature that the organism, if it's able to do that kind of counterfactual inference, it must have some kind of model of these possible states of affairs that it's carrying out inference over.

And so that gets you back into a kind of representational reading of the free energy principle again.

But we are offering an interpretation of the free energy principle where we take very seriously this idea that the organism is a model, but doesn't have a model.

and and therefore that opens up the space for a realist interpretation of the free energy principle um that is also non-representationalist or inactive um and that's the i think the space that thomas van s for instance thinks is not available to proponents of the free energy principle um but rather than go into why we think he's wrong let's let me just stop there because i've said quite a lot already


SPEAKER_04:
Thank you for the responses.

So, Dean?


SPEAKER_02:
Well, I think I'll ask both gentlemen for your opinion on this.

I think if you set your argument up as a literal one,

you're going to find yourself into trouble because I think this thing kind of gets resolved.

There's no debate if it's metaphorical because you have to have a minimum of two.

I mean, with these Markov blankets, you've got internal and external.

You need minimum of two just so that you have discrimination, just so that you can tell

variation in the world and that's what metaphors allow for so i'm just wondering why we're not arguing for both that it's the synthesis of the instrumentalist and that way to measure and filter what's in and what's out because we do measure that and and filter for that and also the relational piece

I still don't like to bump into edges, so I agree with you.

As an organism, I am the model until I fall off the cliff, right?

So if we looked at this as a metaphor instead of literally, wouldn't that kind of at least smooth out some of the differences instead of versus, it's and, this equals that in a metaphorical sense?

What are your thoughts on that?


SPEAKER_01:
I don't think you can have both instrumentalism and realism, although Max Ramstad has said things along those lines that he wants to try to do the best of both worlds.

But the difficulty is that these positions actually come into conflict, contradict each other.

Because one says that the free energy principle does not map onto anything in the world, so we can't

make any claims based on the free energy principle about how cognitive biological systems are organized.

It's literally just a modeling tool.

So it can help us to predict make predictions about the behavior that we can observe of

biological cognitive systems, but the free energy principle doesn't correspond to, doesn't map onto anything in the behavior or the organization of biological and cognitive systems.

And that to me seems in conflict with the idea that the organism is a generative model.

If you say the organism is a generative model, then that seems to me to commit you to the idea that the free energy principle is describing

Something about how biological cognitive systems are organized and therefore it ought to be construed in realist terms, not in instrumentalist terms.

Now, you said something else about metaphor there.

Yeah.

Science introduces all kinds of metaphors.

And I think that introduces a kind of distinct set of issues, really, from the instrumentalism versus realism debate.

Because we can still ask, well, how do we interpret those metaphors?

So no doubt it's true that science engages in metaphorical talk all the time.

But it's once you get into the question of how to interpret the metaphors that then the realism instrumentalism issue comes back again.


SPEAKER_02:
So can I just do one quick follow-up?

If I focus on the instrumentalism or the realism and not focus on the link with the two arrow ends, the metaphor, I absolutely appreciate what you're saying, Gillian.

If I pick one camp or the other, then I'm not focused on the metaphor.

But what if I'm just exclusively looking at that link as opposed to the opposing camps?

I'm very comfortable.

I'm a contradiction.

I'm a human being, right?

So I'm not really sure why I have to pick a side.

You haven't convinced me about that yet.


SPEAKER_06:
I mean, it depends a bit about how you flesh out the term metaphor here, right?

So if we went back to that little image I had from gear, you know, your model description, model system, and some target system.

They say, for instance, you posit metaphorical entities.

Is that what you have in mind there, by metaphor?


SPEAKER_02:
I'm talking about the process of the way to be able to link two discrete or discriminatory ideas or objects.

Because I want to be able to hold up the relationship and the measure of that relationship.

I don't want to say that I have to discard one in order to take up the other.


SPEAKER_01:
Maybe it's useful to bring in the Markov blanket here as a metaphor for the boundary.

So the blanket seems like a good metaphor for capturing the boundary of a particle or an organism.

Right.

And so then we can ask, well, what is the relation between that Markov blanket concept where the Markov blankets are nested?

So you can find them at multiple scales of organization, multiple temporal spatial scales.

What's the relationship between that nesting of Markov blankets and the self-organizing systems that we're using them to model?

So I think that's where you get to when you try to unpack the metaphor.

Those nested Markov blankets is a metaphor.

And how do we then interpret that?

And for Michael and I, the way to interpret that metaphor is to think of self-organizing systems as literally having this... Well, not literally.

That's a taken use of words, isn't it?

But as...

But to think that there is a nested organization within self-organizing systems that can be modeled and described indirectly using the mathematics of the free energy principle or using the formalism of Markov blankets or using the Bayes causal nets.


SPEAKER_06:
So on that note, you use these particular constructs, I think, on the basis of what Julian just said, to actually guide your research.

in the sense of figuring out something about how your target systems are organized.

So the one way of casting this is in the jargon we've been using that you distort, you introduce a distortion that you think you needn't take literally, for instance, the mathematics underlying this particular Markov blanket formulism.

But you use that in order to guide and direct your search.

Now, that's important because that's the kind of key to our particular

to the way of thinking for us about scientific realism, that we can have all these distortions and all these points of inexactness in our theoretical models.

However, the ambition is to say something about the target system.

That's where the sort of conversation between the instrumentalists, or at least a version of that, a version of the scientific realist framework,

Now, I should say there's a set of good reasons for thinking that the two positions in philosophy of science are mutually exclusive.

They can't be true at the same time.

And one is the positing of a set of metaphysical claims on behalf of the scientific realist.

It's typically the case that one is committed to the following.

There's some kind of mind-independent reality.

okay now that can't be the commitment of the instrumentals because you can't posit that because you have no you're not producing the truth about how the world is the second metaphysical commitment is that we can somehow get a grip on uh unobservable causes of our obsolescence but that's not an option for the instrumentalists they can say something about their observations if you're an empiricist for example you can't you can't start making

influences from that to unobservable causes of those observations so metaphysically there's there's something at stake when you have a discussion that goes that considers these kinds of sort of broader considerations in philosophy of science but those are metaphysical commitments and i suppose we can argue for those here all day should like or maybe we should maybe we should not


SPEAKER_01:
So to make it more concrete again, going back to the nested Markov blankets, and the reason that we describe self-organizing systems in those terms is because of how the faster processes are enslaved by slower processes.

So you see this circular causality that's described in complex systems theory.

So there's a dynamics that you can observe in living self-organizing systems that can be inexactly and approximately described using the formalism of Markov blankets.

And it's because of that similarity or resemblance between the formal apparatus that we're using when we employ

base nets and the modeling formalism of Markov blankets.

It's because there's that kind of similarity or resemblance between the models that we're making as scientists and the dynamics of self-organizing systems that we think it makes sense to interpret that metaphor in realist terms.

Does that make sense?


SPEAKER_02:
Oh, yeah.

Again, I wouldn't argue that if you do place yourself in one camp, you reject what maybe the other side is arguing.

What I'm thinking of is the

the statistical probability as a distribution allows for perforations, meaning the metaphor, I wouldn't say it's a bridge, but it's kind of an escape hatch to boundary cross.

And I mean, quite literally, if I use a metaphor, I get out of the constraint of

of not having that other person share the idea unless we can arrive at some convergence around something that we both understand from the past in order to be able to project into that new set of congruencies.

I don't want to take up all of this conversation.

I just wanted to see if there was a quick way to resolve the debate.


SPEAKER_01:
I think that the issue here is really something to do with what philosophers do, where we like to disagree and argue with each other, right?

Right.

And that works for some people depending on their personality, and for other people it doesn't work so well.

They prefer to try and find agreement or...

to find a way of communicating with each other.

For us, as philosophers, I think disagreeing and arguing is not to fail to communicate.

It's just what we do as philosophers.


SPEAKER_04:
What that made me think about is very few people are in the position of putting their name and a year and a version on an idea and being like the avatar of the idea.

Like Godfrey Smith 2009, Longino 2013.

Here's what the idea is.

And...

Dean or anyone who might be interested in applying these ideas might have less of a qualm with shifting their regime of attention even within a sentence from one usage to another.

And it's in the fine art and science of philosophy where some of these minds become fleshed out and we can really see like how deep the

logic goes and that's like kind of like higher overtones in the symphony of thought and then you know dean's just fiddling away on the subway trying to trying to get whatever currency they get up there in canada um let me go to dave with a question um because you haven't gone yet and then uh steven afterwards okay um


SPEAKER_03:
Coming at this whole question, particularly the question of metaphor, my background is I'm coming at this from general semantics, through the cybernetic theory of learning teaching, through George Lakoff's grounded metaphor theory, and through Mark Solm's conscious ego.

So when you say metaphor, dot, dot, dot, I say, well, who's actually driving the analysis?

Who is it that has to be appealed to?

And I would say, look, the interpretation is done by the metaphoric structure.

And why is that a good grounding?

Because the fundamental grounding of every living control system, the speed of updating, the question of how existentially imperative that you not violate your priors,

down through very delicate questions of of mathematical formalisms it's all grounded in the cline of avoidance or approach and the cline of pain versus pleasure so it's all grounded it's got a basis your entire structure of um

inference of induction your whole induction is already grounded so don't worry about what the metaphor means in terms of theories ask what do the theories mean in terms of metaphor don't be shy about telling me i've gone off the deep end every last person i respect has been accused of going off the deep end


SPEAKER_01:
i might i might i might like might let julian take first steps here so i can sort of get myself into into my own headspace all right um so uh i like what you how you describe metaphors and uh and the place that they have within the free energy principle where they're grounded in these perception action emotion processes um so for fep that uh

what everything is organized around is these imperatives to resist disintegration.

And so it makes sense to me that the metaphors we use in communicating with each other and thinking are

in the end going to inherit there and be grounded in life processes.

That's something that we talk about in terms of the life-mind continuity thesis coming out of inactive ideas in philosophy, the philosophy of biology.

So there's an interesting connection there between the embodied cognition ideas that Lakoff and Johnson are using and

and the four E ideas.

So I think that's what you were just describing.

But that comes at this from a slightly different direction to what we're concerned with in our paper, where what we're looking at is, say, a MATLAB model that somebody might make in simulating active vision like Thomas Parr has done.

Or Micah Allen when he's looking at how to model the interactions between heart rate and fear perception.

And he's constructing like a simulation, an in silico model using the mathematics of the free energy principle.

to describe those kinds of interactions between interoceptive processes like monitoring of your heart rate and extraoceptive perceptions, say, of fearful images of faces making fearful expressions.

So that's a kind of in silico model that's been made there.

And what can we learn from those sorts of simulations about, say, interactions between heart rate and visual perception?

And that's where our sorts of questions come up.

Because you can think, well, the in silico simulations that are being made, they're just instruments for making predictions about, say, heart rates, how heart rates can interact with perception.

And the simulation can be useful for predicting the kinds of data that we could measure

But the simulation itself isn't going to give us knowledge of how the interceptive system interacts with visual perception.

And we just say, no, that's wrong.

The simulation can actually tell you something important, give you a kind of

knowledge maybe in the long term so we have to look over time and look at all of the refinements that are going to happen in active inference models before we can actually arrive at something that is a true accurate description but in the meantime the kinds of approximations idealizations that we're operating with when we make these kinds of in silico simulations

are still telling us something important about how the mind is organized, how living systems are organized.

So that's the sort of claim that we're making.

Can you see that that's sort of a little bit of a tangent from what you were asking about metaphor?

Maybe it isn't, and you can explain how you see them coming together.


SPEAKER_03:
I have probably stated my point in an overly polemical way.

I was very excited.

I was really, I am very excited about what you're doing.

Kind of like when Muhammad, the opponent finally lands a really solid blow on Muhammad Ali and Ali says, okay, enough playing around.

Let's hit back.

No, I'm very sympathetic.

I invited Professor Solms to this discussion.

I certainly hope he's going to watch the film.

No, I'm very much on your side.

I'm just saying, I think the embodied perspective,

the pre-Galilean perspective, where valence, where value, where teleology are viewed as a foundation, or at very minimum, a co-equal foundation of the entire intellectual structure, the entire research structure.

I think that is exactly correct.

And I'm really pleased, for instance, a subtle British nuance, perhaps, that Professor Christian uses the term

teleology so often in such an important sense.

I think that already by itself involves hitting back.


SPEAKER_01:
But he always says he's deflating teleology, doesn't he?

He loves this word deflation.

Deflation, I guess.

It's something that you can see in physics as well.

Michael found something very interesting in a

a YouTube video from Friston about where he was responding to some presentations that he'd heard where he describes how this variational free energy relates to Gibbs free energy.

Michael, did you want to come in on that?


SPEAKER_06:
Yeah, I mean, this is definitely well beyond my pay grade.

Yeah, me too.


SPEAKER_01:
Probably some people in our group here and in our audience will be able to... The basic gist of it is something like this.


SPEAKER_06:
that you can describe transitionings across belief states by appeal to variational free energy.

And that's nice.

It gives you a nice sort of computational modeling language to speak about state transitions across different beliefs.

So the claim is here.

And the claim is interesting because it allows for an even tighter grip between your fictional constructs and actual systems that you can give a formulation of those state transitions by mathematically showing an equivalence relation across the variation of free energy and the Gibbs free energy, which then by definition allows you to show in energy spent per joule or something like that what it actually costs

to change one's beliefs, for example, in the context of the FEP.

Now, that's great if that's the case, because that brings you even closer from your model space to your target system space.

But that's a bit like when somebody asks me in Okinawa, well, how does the octopus mechanistically select its action policies?

well i'm not a marine biologist and i'm not a specialist in octopi i mean that that that's not for me as a philosopher to tell you and i have i'm gonna i'm gonna cheat out and provide the same sort of reason for not going any further than that but it's a good example i think um yeah the reason i brought it up was because you were talking about teleology and


SPEAKER_01:
And what Friston does in deflating that notion is actually bring it back to something in physics as well, like Gibbs free energy.

And the free energy principle shows you how you can take something that looks like it's going back to Aristotle, but actually show how to bring it into contact with the mathematics that we now have for understanding self-organizing dynamical systems.


SPEAKER_06:
I mean, I think it's just an important note there.

So even if the term teleology is being used in the literature, one ought not to confuse it with the sort of notion of a final cause as per the Aristotelian system, right?

So we have sort of a final cause and ultimate end point that one necessarily strives towards, right?

But rather that self-organization is somehow inherently purposeful.

And to me, that strikes me as right, but it also strikes me as a deflated notion of teleology.


SPEAKER_01:
Yeah, but there's lots more we could say on this, but probably it's for another session, isn't it?

It's a little bit of a tangent from what we're currently talking about.

Sure.


SPEAKER_04:
Cool.

Stephen, and then I'll have a question, and then we can sort of land.


SPEAKER_00:
Yeah, I think this question about what we can model with the FPP or what FPP is able to be used to do modeling on using variational free energy is

and what the model is.

And I think you've kind of resolved this to some extent by distinguishing modeling from models.

So there's instrumental models, there's realist models, and there's this process of modeling.

And one of the things about non, and I think in some ways, you don't have to say non-linear, I mean, non-linear dynamical systems might be best .

But the thing with those systems is,

And is that they are, in this case anyway, generative.

And we've been looking at, and I was actually talking to Daniels in our tools session about how these Bayesian graphs could be thought of.

And one of the things is that generally you have a model and you try and fit things to your model.

Like in psychology, you fit someone to the model of psychology, right?

And that can be the problem because now this person's being fit to all these models.

Well, in this case, these models generally, not always, generate the data.

But they generate a little bit different each time because it's stochastic.

So you see the way they evolve.

And that's what we're sort of getting at.

So building the model can be a useful design thinking tool to think about how it would be structured.

And then you get this idea of modeling,

And this is actually maybe tying this with what Dave was saying a little bit.

My belief is that at the moment, all the ways that we are able to model are very low dimensional, like extremely low dimensional.

However, I do believe I've been looking at stuff where phenomenologically it would be possible to use experience as the raw instrument.

So I think high dimensionality can be done through, there is a potential for high dimensionality.

So there's this question of like when we're modeling using models, which are low dimensional to such an extent, and they even like often are partially observable Markov decision processes.

So they're not even actually saying the data coming in has been a change.

necessarily through, you know, you either have these psychological models, which are very low dimensional, and are partially observable.

So it's gone up, and it's hit the point of beliefs, and then they start to look, or they have these incredibly particulate models, starting from like, the first atoms of life or whatever.

And

I think that your intuition is probably right, actually, in terms of there are then, because we've been looking at some of this in terms of phenomenologically, that is there ways that experiential information can be modelled in or put into these models?

And so it doesn't only have to be these very low dimensional

which may be so low dimensional that maybe that's part of the problem.

It's not that the FEP is real.

It's just what they're using to model it is still so low dimensional.


SPEAKER_06:
Yeah, that's a nice question.

Let me at least attempt a form of response.

So Julian and I, Ian, met the other day and we were just sort of chit-chatting here.

And since you did mention Markov decision processes, I suppose one way of conceiving of this, if you like, low-dimensional versus high-dimensional or kind of simplicity versus complexity or kind of inaccuracy versus more accuracy distinction would be just to sort of

quite often one finds that those sorts of processes are modeled in discrete states.

And my assumption is that that's a simplification because it makes work somehow more tractable.

So it's manageable.

You can write the code on the basis of discrete state transitions, for example, and still learn something, even if you sort of think that maybe state transitions are continuous, for example.

Another thing that's more meta, I suppose, to that view is sort of the following.

So we're quite inspired by a philosopher by the name of Michael Weisberg.

So his name appears frequently now in the paper.

And he has this really nice paper from 2006, I believe it is, or 2007 in biology and philosophy, where he gives you two different approaches to a model-based science.

We follow one in part because we don't think it's very feasible to do the other.

One he refers to as a kind of brute force approach.

Now, I suppose this is going to give you all the high dimensionality that you can imagine that given computational power to pull it off.

On that approach, the goal is to have the values of all the variables we can identify in your target system reflected in your model.

This is a super high degree, if you like, of correspondence between your model system and your target system.

But the catch is that that particular ambition is extremely difficult, given the sheer complexity of real-world systems.

So the alternative is to say, well, then any other kind of model-based approach

in the sciences, if you can't achieve that degree of completeness, if you like, is to use idealizations.

So by necessity, almost, you have to simplify.

I suppose that would be one way of thinking about why we have low dimensional models and why one uses low dimensional models.

Can you use experience to improve those models?

Yeah, I'm not sure.


SPEAKER_01:
Perhaps it seems like you ought to be able to.

I would ask a slightly different question, but I see Stephen wants to come back.

So I'll hold my comment for a minute.

Yeah, cool.


SPEAKER_00:
Well, I just wonder, I think, I suppose the dimensionality is so low that it's almost like even if you made it a thousand times more, it still would be, it's still useful because it shows the dynamics shifting, which is a little bit different to most models, right?

However, yeah, there's like, it's, I don't know how many zeros it has been magnified by in terms of multiplying the complexity.

But that might be, anyway, so that, I think it's a good point you're making though, yeah.


SPEAKER_01:
Thanks.

Well, let's take the Casper Hess deeply felt effect model.

I don't know if you know that one.

So there's a variable in that model, a matrix, the G matrix, which is trying to capture the minimization of expected free energy and the role that that plays in selecting routine action policies.

And the idea is that that G matrix is something that is changing over time.

such that you can do better or worse than expected at minimizing expected free energy.

So there's a variable there, which I guess is still going to yield models which are low dimensional in your sense.

But it's still being used to model something that is, I think, phenomenological in the end, namely valence.

And so the moral I would draw from that is that something that's an idealization and approximation, because it's low dimensional, doesn't necessarily mean that that modeling tool that you're using there that has this low dimensionality can't still be used to describe something high level and phenomenological, namely valence.

And that goes back to what Dave was saying before.

I think that the valence is actually something that's built into free energy minimizing systems because variational free energy is a way of describing, a way of indirectly representing something that's fundamental to life, which is this tendency to avoid decay or disintegration.

So the low dimensionality, I think, doesn't stand in the way of using this to model very high dimensional phenomenologically deep, thick concepts like valence.


SPEAKER_00:
Yeah, that's a really good example, actually.

Just one point on that.

And also, we're talking about general, because I do agree with the idea of if we're saying what are generally tractable

dynamical processes which maybe is another type of realism in a way or it's realism but to think of that is it does show that affect becomes a plausible way which pretty well hasn't i don't know any other way to think about it previously it's why we start to get into consciousness as well with mark soames is yeah it gives this plausible way where what was relegated in our scientific world because basically consciousness was taken away by psychology

and feelings were kind of these this lower down ideas like well wait a sec this is actually the all-encompassing way to know what you think so that's actually because i actually do a lot of work with metaphors and one of the things that happens with metaphors is people what's the metaphor of knowing when you get something right like what's it like to know something so if you ask a mathematician what the answer is to a problem

they don't get an answer on a computer screen.

They actually feel the answer being right.

So they've kind of somehow, and then what's that like?

And then you can process that as a spatial metaphor in the room.

But like you said, it's affective.

So yeah, I do agree with what you're saying.

And what I'm interested in as well is working backwards from an affective state and trying to plot out people's low dimensionality another way.

But that's for another conversation.

But I do agree with what you're saying.

I don't know whether you would say that the realism in the dynamics is different to realism in reality.

physical, physical ways.


SPEAKER_01:
So in the model that the G vector is is being used to set precision on action policy.

So which action policies can you be confident in?

That's a kind of metacognitive process in that it's not just acting based on some gut feeling, you know, in the way that you described, but

But using that feedback from the body to assign precision, so to look at how reliable a prediction error is in relation to your predictions when the quantity that you're minimizing is this expected free energy quantity.

So there's something global going on there, I think, which gets you closer to what you're looking for when you're thinking about consciousness.

something in the global dynamics when you're thinking about the G vector.


SPEAKER_04:
So I'll just read out one question from the chat and the answer could be as simple as read the paper or give a thought.

And then I'll ask a closing question for the authors.

So the question is from Matthew McTeague and they wrote, how do we resolve the controversy of the conflation between heuristic and Markov blankets?

What metaphysical legwork should be done to defend an ontological Markov blanket?


SPEAKER_06:
Okay, so the question is something like, we don't really take that up.

One sneaky move might be to say, go read the Greerback et al.

paper.

But moving from heuristics to ontology, I think Julian has already touched on that quite a bit when speaking on the sort of multi-scale characteristics of self-organizing systems.

So if you have as part of your model, and this is our preferred approach here,

uh the formalism like the markov blanket formalism then of course you're not going to be saying that heuristic this will be the literalist fallacy it's going to just be mappable onto the this multi-scale structure that comprises the system so now you have to interpret that's the next step in this modeling you have to interpret these sorts of notations under a certain description such that you can start thinking about what it is about biological

organization that reflects in that indirect sense that we are working with these sorts of heuristics.

So that's the work that one should do.

But it's not the kind of thing that we discuss at length in one section of the paper.

We call the section, the paper moves across four different domains that has to be done with some swiftness and level of generality to bring the philosophical point home.

But I think that's a separate paper, actually, that little question.

So thank you, Matthew, for that.


SPEAKER_04:
Awesome.

So just one closing question.

As you are reviewing and revising the paper,

Who is your audience and how would it impact the next several months or years of active inference and free energy principle research and application if people were to really direct the regime of attention and understand what you're talking about and update their generative models accordingly?


SPEAKER_06:
William, do you want me or you should go first?

I'm happy to go first with initial thoughts.


SPEAKER_01:
I wanted to bring up

the recent paper by miguel aguilera and um and chris buckley and others where the the problems that they raised there are about how to take the free energy principle and uh and use it to to model uh

real biological cognitive systems and they take very simple system and then show what kinds of assumptions you need to build into the free energy principle in order to to use it to model those systems and they argue that those assumptions are are unrealistic and they pick out a very small class of systems and those systems are unlikely to be biological cognitive systems so that looks like bad news for the free energy principle and

but not from the perspective of our paper, because what our paper shows is that all of those assumptions that they identify are actually exactly the kinds of idealizations and approximations that don't rule out taking the free energy principle to indirectly represent biological cognitive systems.

And so the contribution of our paper to the community, I think, is to just point out that even if we look at the assumptions that underlie the free energy principle and think, well, those don't literally apply to biological and cognitive systems.

that doesn't rule out the possibility of still making active inference models and using them to learn important things about biological cognitive systems.

It would only rule that out if you think that those systems literally have to instantiate the assumptions that are built into the FEP before you can apply the FEP.

But we've argued, no, those assumptions don't need to literally obtain.

They can just be idealizations and approximations.

So the contribution, I think, of our paper to the community is to say, well, look, there are these real challenges, but they don't stand in the way of using the free energy principle to carry on doing active inference models and learn something important from those models.


SPEAKER_06:
Okay, if we can achieve that, that's certainly a job well done.

I think in terms of the audience, perhaps outside the technical, very specific niche of the free energy principle,

I mean, one would like to hope that a bit like when you had Stephen on a few weeks back talking about free energy, a user's guide, which we crafted as a sort of ambition in part was, of course, to introduce these sorts of conversations into the context of philosophy of biology.

And then hopefully they will see the light of day.

I think similarly here, and I'm sure Julian will agree that, you know, I think these sorts of papers that take up like broad picture discussions in the philosophy of science with say an emphasis on the free energy principle will bring an audience from the philosophy of science into contact with the kind of, you know, area of speciality that we're working in.

But I would like to see that as an aim as well.

I think secondly as well, or secondly just that,

Just working through with some precision these kinds of conceptual details in this highly mathematical and sometimes really abstract domain that is the free energy principle is important.

Precisely, also I think for the scientists working on it, to have a feel for what is the conceptual assumptions of making some claim.

So you're also conceptually engineering this debate in a particular sense that can be fruitful, I think, for non-philosophers working on it, a bit like what Julian was touching on there.


SPEAKER_04:
Awesome.

Well, Michael and Julian, thanks so much for the paper, and also Ian for co-authoring on the paper, and best of luck with it.

Dave, Dean, and Stephen, and also Matthew, thanks for participating.

This is a really interesting discussion, and we hope to continue the conversation however you all would like.

Thanks, guys.

Good night.

See you later, everybody.

Bye.