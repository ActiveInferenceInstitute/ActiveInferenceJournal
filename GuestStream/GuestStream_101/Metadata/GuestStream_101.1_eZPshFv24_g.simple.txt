SPEAKER_00:
All right.

Hello and welcome.

It is April 8th, 2025, and we're an active guest stream 101.1 with Mohsin Jafari and Yuli Li.

So thank you both for joining and looking forward to this presentation and discussion.


SPEAKER_02:
Well, Daniel, thank you so much for having us here.

It's really great pleasure.

What I'm going to do is I'll have, I have few slides for you.

I'll present my slides and it's an open discussion.

So please stop me whenever you have questions.

And that's about it.

So let me start.

Again, my name is Mohsen Jafari.

I am professor at Rutgers University of Engineering.

This work, we have been working in this area for the last, I would say, four to five years.

And this is a joint work with Professor Andrea Mata from Politecnico Milano.

There are four PhD students currently working on this.

Actually, one of them, Yufei Hong, the last one, he graduated about a year ago, but the rest are in the program.

They are working in the program.

So what I'm going to do, well,

Again, it took us a while to understand active influencing.

I am myself coming from automation background.

I have computer science, half engineering, so I'm very familiar with modeling, with the stochastic systems and so on and so forth.

Definitely in terms of active influencing, it was a little bit different for me to get acquainted with, but that's why it took a while to basically understand the terms, the jargons and the underlying assumptions and so on.

But we feel that we are quite comfortable with the theory and the framework.

Our background is engineering, so we like to see that we can apply active influencing to engineering systems.

So that is really the main theme, the main trust of our group's work.

And for that reason, we are looking at engineering.

know large complex human machine systems where you have physical systems machinery buildings communities and so on and at the same time you have humans so there are both aspects of it and these are large systems so one example here is like a building community or a smart community i'm sure many of us have heard about this where you have some buildings each building has zones

and and then you have the community which has many buildings in it and these communities are part of a larger network sometimes called distribution network if you are looking at from energy perspective then you can connect to the power grid or any other type of network so they're different how you know there's a hierarchy of hierarchy of different layers in the system and it's quite complex it's the way that information is being

and passed up and down and being processed there are many issues in terms of privacy confidentiality abstract abstraction of information and so on so that's one example and i'm going to talk more about this as we move on

Another example is in the top, in the production systems.

The production systems, manufacturing systems are usually complex systems.

There are many, many stations, robotics, and you name it.

And there are many examples where you have hundreds or thousands of this machinery in the same area.

And of course, these systems interact with the environment, with the outside, and there are lots of complex interactions inside the system.

another system of the same complexity that involves again machinery and human is is roadways you know navigation in the roadways you have cars and and these days we have mixed traffic you have smart cars you have not so smart cars and and of course the interaction between all this you know vehicles in the system uh in terms of navigation is a quite complex problem

Along the same line, you can look at the simpler systems, but you can look at very complex dynamics in this system.

I'm borrowing this picture from the literature, but basically think about this table with a robot that tries to push the ball, but the table has a complex dynamics in terms of tilting, in terms of friction on the table.

So exactly what you do and what you see may not be exactly what you are trying to do.

And this is another type of system that we are trying to look into and study.

And again, if time allows, we will discuss this.

Let me just go back a little bit.

the whole idea of looking at degenerative modeling is not new for us i would say about 15 to 20 years ago i i have i i did some work in this in this topic again for large complex systems the whole problem there is that to build this like in this case this automata models for distributed systems and

our work research was to build algorithms where you can actually generate this the automata model for the whole system in some smart in some automated way so this is a this is something that we have been doing for for some time and

it did not directly relate to active inferencing but again the whole idea of creating generative models for the purpose of creating perception of how the system works has been there in the past you know in the past this is another example of a manufacturing system actually this is a real manufacturing system where the idea is you want to build this graph model on the right hand side which happens to be a petri net

And you want to be able to develop this Petri Net based on the information that you collect from the system.

And again, this could be a very complex system and the problem of interest here becomes, okay, how do I create this graph model that describes the logic of how the system works in some smart automated way?

This is another example we did in the past.

Here you have a simple chemical process.

You are receiving sensory information from the process and the idea is to build a state transition model.

Daniel, I know that one of you, you know in your email to me, you asked the question, how do you incorporate the sensory information to building your models?

And actually this is one example of it that

you directly use the sensory data to create the state transition model and these state transition models basically describe the behavior of the process again I'm not going to go into detail of it but what I'm trying to

The point I'm trying to make is that, you know, the whole idea of generative modeling and automation has been around for some time, but not within the context of active influencing.

So when we are looking at this type of, you know, human machine systems, we are talking about really complexity in terms of the physical systems.

There is a lot of physics behind the systems.

And of course, there is human and all the, you know, complexities that comes with the human behavior.

Usually with this system, state spaces are very large.

And especially if you shuffle the states together because of the dependencies, then the problem becomes quite complex.

In many cases, you have hybrid systems in terms of some of the activities, functions are time-based.

So you have to have a continuous model for it.

And some of the activities are event-based.

So you have time-based and event-based dynamics.

And that definitely makes the problem more interesting and more complex.

Again, we have many sources of uncertainties in these systems.

usually what you do and this is this practice this has been the practice in the past and now is to create some layer by layer decomposition of this type of systems in terms of states variables outcomes data and so on and of course nowadays we have all the issues with the data confidentiality and privacy and so on that you need to consider in these systems

so before we get into too much of detail let's just look at a very simple case suppose i have this building and suppose that this building has only a single zone and what i'm trying to do is i want to basically control the the temperature in this building so the or in the zone so the problem of interest here is

can i build an active inference model to do this so i want to create an agent that can actually control this this zone and for that reason what you need to do is you need to create of course your hidden states your controls actions your observations outcomes and preferences all of it together i'm not going to go to details of it but in a zone like this

It makes a lot of sense to assume that the occupancy level in the zone is hidden from the controller, because either you have to have very sophisticated sensory network in the zone to know exactly how many people are there, because as you know, the occupancy impacts the temperature, humidity in the zone.

and also infiltration external infiltration if you somebody keeps the window open or the door open it will definitely impact the quality temperature inside the zone so these could be you can consider these as hidden variables and in terms of actions excuse me in terms of actions

the amount of air that you supply to the zone, as well as the flow rate and the temperature, both in terms of rate and the temperature, is something that you can control.

And for the observations,

suppose that you have the thermostat or some sort of sensor that you can see the temperature in the zone or average temperature in the zone and let's show it by phi t so basically i have my hidden states i have my outcomes or phi t and i have my actions now within this context you can actually build a

an active continuous active inference model for this without getting it too much into the dynamics of the of the system actually this is quite complex dynamics in terms of you know the thermal flow but by using the active inference you basically avoid that

and you use this probabilistic model to control to basically build your model i'm not going to go through the details of this but you can actually do it you can create your your the elements of your active influencing and

And one thing that I like to mention is that, let me just go through this and basically explain the details of it.

We said that the temperature in the zone is phi, but we define a g function that describes the outcome in terms of the hidden states and actions.

Very normal, very regular in active influencing literature, right?

And we are going to assume that it is Gaussian with some sort of a noise level.

Now from thermodynamics, we know that we can describe the temperature in the zone through this time series function.

And it just happens that here, this time series function is a function of control actions as well as hidden states.

That makes life much easier.

So that basically describes your g function through which you can describe your outcomes in terms of the hidden states and actions.

You can continue the formulation and active influencing on this.

Formulate your variational free energy and one idea that you may want to have here is that you define a target.

The target is very interesting here because as a as a owner of the zone, you may actually set some the band gap for the temperature and what you want this active influencing agent to.

to make sure that the temperature stays within within this target band gap so it is very doable and again that is what i'm showing here and of course you can use your variational free energy you can

look at the gradients in terms of the inferencing and in terms of control so again i'm not going to go through these details we can always come back to this if you have questions later on but i'm just following the normal literature in active inferencing to do this formulation of course you can generalize this to much more complex and more general and here i have

some general formulation of it in terms of different variables that has to go to this type of continuous active influencing function and and and how you define the targets because usually the target

for an active influencing agent in this type of systems comes from a higher level.

And the way this target is defined depends on the dynamics at the higher level and the lower level.

And definition of this type of target is very interesting in this type of system.

That is one of the areas that right now we are doing some research on to see how we can actually do that type of formulation and build this hierarchical model in this context.

Again, I'm just not going to go through the details.

Let me move to another layer.

Suppose that you have a community now.

So within the community, you have different agents.

Each agent could be a zone or a building.

I just showed you how you can do the zone, but you can extend it to a building, assuming that the zones are independent.

If the zones are dependent, of course, it just makes your model much more complex, but it's still very doable.

now when you are looking at the from the community level of course there are lots of confidentiality and the privacy issues and the active influencing agents at the lower level are not going to give all the detailed information about their what's going on there to the higher level

So there is some abstraction of information that will go from the lower level to the higher level.

And that is exactly what we are trying to model in this case.

Again, let's move on with, and if you have questions, we can always come back to the

to the detailed formulation.

But without going through details, you can actually define the hidden states in some abstract level.

You can define observations in some abstract level.

You can define actions in some abstract level at the community layer.

remember you have the building you have the zone you have the building you have community and as you move on the abstraction level becomes more and more and you can form all the matrices and all the relationship at the community level we are assuming that your active inference model is discrete

So at the zone level, we are trying to control temperature.

Clearly it is time-based, whereas in the community level, we are trying to basically set some commands between the, or define some commands to the lower levels.

So we deal with it in discrete way.

Let me just add here that if I may go back to here, when you are looking at this higher level community layer,

or level you are dealing with the distribution network much you know another higher level i am assuming that the distribution layer is going to set some targets and also it is going to give some information to the community for example market price and or the day head plan which is very usual in the sense that

You define your schedule of how you are going to consume energy for tomorrow.

So this is the target that the community level active influence has to respect.

So you can set all these targets at different levels.

And our formulation, again, we are going through the same active influencing formulation.

You can use Markov blankets.

You can use different forms of it.

to to do the formulation here I'm just showing you some simple examples and again you will have my slides but active influencing is doing amazing it is at the community level it is able to to follow the target very well it is able to

minimize the pricing system and also the use of I am assuming that your community for example has solar panels and energy storage and it tries to optimize the usage of all this together so that is really very exciting and very interesting to see that without

truly understanding the inner dynamics of these complex systems i can actually employ active influencing to come out with with the controls which otherwise you have to either use some reinforcement learning or some exact models which sometimes is not even possible because the flow of information and the flow of the physical

elements such as you know thermal flow and all that is is very complex

so let's move on and now this brings us to another example in the production system and I'll tell you where is it that we bring the probabilistic diffusion to this and where it is we are expanding our research to and how it came about first of all I showed you a hierarchical system in terms of community the fact is that if you really want to do this for a real complex system the number of states and

and the models will be very very complex and we know that in active inferencing one of the issues there is to compute expected free energy for the future to define your you know plans strategies optimize your strategies that's a major issue in large complex systems

because computation of these expected free energies is not easy if not impossible is not easy we tried it for this production system actually this is a work we are doing in Italy and it's huge if you are using month colors search all that and creating this habitual networks and so on in order to calculate the

the expected free energy problem becomes extremely difficult.

So that was one reason for us to start looking for maybe different solutions to deal with expected free energy problem.

Now I'm not going to go through this, but I'm just showing you some of the elements of how you can use the traditional active influencing in terms of Monte Carlo search and all of it for expected free energy.

But again, when you go for large complex systems, these become really big issues.

Let me just stop here for a sec.

What I did was I basically showed you some examples of real complex human machine systems.

I would say I showed you community.

We have done some work in that area.

We are trying to expand our work and really bring to more real problems.

we also did in production systems quite complex problem in terms of state space explosion and so on so forth so we have been searching for some different ways of dealing with this expected free energy problem how do you really do this what is the organic way of really doing it

i feel that as human we don't do it that way we don't search for different solutions for the future active influencing is really it has its roots in predictive mind so to me it is very organic so we we have been trying to find some organic ways of dealing with expected free energy so let me put it that way so

This brought us to problem of probabilistic diffusion.

What is it?

Well, I don't know if you are familiar, Daniel, with probabilistic diffusion, but basically the problem is that you start from initial data, in this case image of a cat.

You bring noise and perturbation to it until you make a total noise.

and then you basically recreate the image from that right sounds very simple it just happens that when you go from your initial data in this case again the image of this cat to total noise you are basically going through this Markovian step and in each step you have discussion approximations for your state variables

now in this case your state variables are you know pixels of the image and you just keep on applying it to these pixels until you can create this total noise so it's fully corrupted and then you create a reverse process which is also gaussian but then you have to use some sort of approximation neural net approximation or any other sort of approximation to build the original image the original data set

so this has been in the literature i would say for five six years now this is called probabilistic diffusion looking at it from engineering perspective i like to call it reverse engineering because what it tells me is that i can start from some ordered structure

i can totally uh destroy it which is my noise totally corrupted and then from total disorder i can recreate order again right so this is basically what this diffusion is about any questions i understand or should i continue yeah continue thank you

so without going through the the whole process of how you do this again this is a Markovian in each step you have Gaussian assumptions as you're going forward as you're going backward again you have Gaussian it's Markovian but you really have to compute your noise levels as you're going backward

and it just happens that again there are a number of papers recent papers in the literature that going back you can look at this score function which i have it here as the gradient of log of q now one point here when you are going forward you can assume that you are using the original distribution even though you have to approximate it and when you are going backward you are trying to get to that original distribution

so when you are going forward i have q i'm using q for my transitions and when i'm going backward i'm going to introduce some parameter theta and use p because i want to come to back to this original distribution it just happens that usually backward reverse or the backward process you have to use some sort of a neural net but it is based on this score function which is gradient of this

log of Qt Xt given X0 it's a very important point here

if for my reverse process it is important that i keep my original data set my original painting accessible because without that information this reverse may not be tractable again we can always go back to details of it but this is already in the literature there is nothing new on that one

and the beauty of this methodology is that you can actually do sampling conditional sampling and by this conditional sampling you can actually define where you want to go back because you may not actually go back to the same origin you may add few things to it or you may actually change your original design and that is very useful when you are looking at reverse engineering problems

There is a discrete version of it.

And to us, this is very interesting because we think many engineering processes can be described by graphs.

And this graph diffusion, it has been around again for a few years, only a few years.

And there are a number of works on this.

We are also trying to use this for engineering processes.

And the way you use the graph diffusion is, again, you start from a graph, you totally destroy it, and then you build it back.

There are some very interesting applications of this in the literature.

In the literature, there are two ways that people have used so far in terms of using the diffusion together with reinforcement learning in control actions.

They don't use active inferencing.

They use the diffusion with reinforcement learning.

Here is one example.

This is by a group from 2022.

so basically think about this you define your control actions you have control actions you have your states as i have done here like a's are your control actions it's s are your states so if you combine look at the combination of actions and states you have that you know the small square or rectangle there and then you put them next to each other so you have the whole sequence going from time zero to whatever time it is

so if I create this table this looks more like an image and then of course actions are states there are multi-variables there are many elements inside each so I have this like a image type structure and then I apply on a noising and denoising to it and when I am going back when I'm doing my reverse process

reinforcement learning in terms of some reward function to find the best sequence of actions, the best trajectories.

This is a very interesting concept and quite useful or close to what we are trying to do.

There is another example of this.

By the way, we have taken this methodology and done some improvement on this because when the number of time steps increases, this problem

may not actually converge so we are looking at some what we call window stitching and some adaptive planning of doing the same thing and we have some preliminary results on that again I'm not going to go to the details

another work of the similar sort rather than looking at the actions and states together they apply the same methodology to the states and then they use inverse dynamics to define the actions okay but pretty much it is the same approach and with this you can use reinforcement learning to try to optimize you know your trajectory

now i call these model one these two model one because they are not actually using they use reinforcement learning they have some reward function but they are not actually formalizing how this optimization or optimal control should be the model 2 which is our model actually puts active influencing and diffusion together

in the following sense so think about it this way the diffusion is going to teach me how to go from point a to point b okay so from diffusion i can create many different samples of going from point a to point b avoiding many obstacles and all of it

So I already learned how to go from one point to another point.

I look at it as a predictor.

So actually probabilistic diffusion creates a motion prediction for me.

Very organic.

And then I can actually use active inferencing together with this to find my best sequence of motions going from one point to another point.

So that is basically the whole, you know, this is the whole theme or whole philosophy behind our methodology of combining active influencing and diffusion.

So the forward process is the same as, exactly the same as diffusion, but the backward process, every time that you start from a state in the reverse process, diffusion process, you start from a, you know, state,

and you have again you have all these different samples of going from this point to this point but for each of them you can apply the expected free energy from active influencing to find which one of them will give you the best sequence of actions and that is the overall model that we have here let me show you this in terms of let me just jump through this for a sec

uh to this uh parking model a lot model so here suppose i have in the first in the top graph on the left hand side i have only five six parking slots in the other one i have more so you have some parked cars

want to teach these cars how to go and park themselves in the best possible way so there are some empty slots and these cars starting from some random place they should go and park okay so there are two problems here one is that first i have to know how to drive in such an environment

going from point a which is some random point to a parking slot that is one problem the second problem is that i have to go to the best slot to the best place right so

what we do is the first problem we solve it with probably probabilistic diffusion how do i do it i start suppose that i take a car one of these green cars i take it from there suppose it is parked in a slot in a parking slot i take it from there and i apply this forward process to it until i bring it to total noise somewhere out there

then I reverse this process.

And I create different samples of this reverse process.

So basically by doing so, I know how to start from a, how to go from some random location to a parking slot.

So I have learned that through my diffusion process.

Now that I have that, then I apply my active inferencing to see which one of them is gonna be my best choice.

one thing here is that as i am doing my problems the diffusion at any point that i'm look using what i have learned to find my eye you know to find my projection for the future i can use variational free energy to inject what i am observing to my diffusion process so in a way we are updating our diffusion process by the observations that i am actually receiving in real time

again I have applied my diffusion I have set up samples of how to go from some random point to a

parking slot i have many samples but now that i am doing active influencing i am actually applying in real time so now i make an observation diffusion tells me go this way it for the next step it gives me an estimate but when i actually apply it the result is a little bit different different

so i am going to use variational free energy to make a correction find a new point and apply my diffusion again until i get to my best location so that is basically the whole idea behind this now in in here the inverse dynamics

is you know bicycle model it's a very say from the literature there's nothing new about it so given that i have my actions or states i can find the other one in this example we are applying the diffusion to the actions but you can do both again but remember actions and the states are related through this inverse dynamics model so that's not an issue

one last item here is that really a contribution that we are making here is actually i will say there are two contributions one is how to deal with expected free energy in really complex systems in some organic way that's number one and again reverse engineering is something that we do a lot in engineering

number two is that how to integrate the elements of active influencing especially the variational free energy to update my diffusion process

And in this work that we did for the parking model, we were actually able to demonstrate that.

Before getting into any, and maybe Yulin can help me here, now we are trying to use this idea for many different applications.

And we are also trying to expand our parking model to more navigation on the road by looking at stitching these windows together.

One of the areas that we are trying to work on is, how to actually navigate a ball, for example on a table, which is very dynamic.

So it is tilting, there are frictions, and it has to be able to find its way.

So we are thinking that this ball is looking for food, but we don't know if there is a food or not.

So the ball has to go, or this organism has to go and find

has to survive, but in order to survive it has to find food, but it doesn't know if there is a food.

So it has to explore this in a very dynamic environment.

And again Yulin, is there anything you want to mention here, before we start our conversation about all this?

Yulin, are you there?

Well, can you say a few words on this unit?


SPEAKER_01:
Sorry, I just lost audio for a second.

Sure.

So this is the most recent work we're doing.

So again, as Dr. Jafari described, this is similar to Tim Snyder, Dr. Snyder's work about active exploration for robotic manipulations.

right and as as Christopher described this environment is extremely challenging and almost impossible for reinforcement learning and we add extra layer of challenge just tilting the table such that that the table is dynamic during the learning exploration task so our idea is to solve this problem with a hierarchical setting right so um

Right now, we're experimenting with three layers.

The top layer is a high-level planner using active inference.

Using the active inference controller, this layer updates belief using variation of free energy and performs planning using the expected free energy.

where does the expected free energy, all those information comes, we need to sample many different possible trajectories.

So that's how we move to the second layer, the diffusion projector.

Our diffusion projector learns from dataset and from past experience to generate possible paths.

The high-level active inference layer will select a preferred region, some kind of points or area or distribution, as we refer to G-distribution.

that belief gets passed on to the diffusion planner.

And the diffusion planner generates many possible trajectories to that region.

And at this point, the actual goal hasn't been found yet.

We are still looking for the goal.

But we are generating diverse trajectory towards that most probable region.

And these trajectories consist of a sequence of waypoints and corresponding states that represent the possible paths.

And then, obviously, we calculate the expected free energy and then select the best possible trajectory.

And once we have the trajectory, now we have the low-level controller.

The low-level controller is just a lightweight, small-scale reinforcement learning controller that generates actions to connect the small waypoints.

So by having this hierarchical structure, we believe we can solve this problem much faster than the original literature, where Dr. Snyder solved this problem with model predictive control with active inference.

If you run that, it takes tremendous amounts of planning time and learning time, and we believe by

because of the nature of diffusion process, we can make this learning process and planning process much faster.


SPEAKER_02:
Thank you, Yulin.

Well, Daniel, I think we are done.

Sorry, I don't know how long it took, but it was long.

I'm sorry.


SPEAKER_00:
It was awesome.

Yeah, I'll ask some questions.

Is that okay?


SPEAKER_02:
Yes.

Well, I think there is some sort of fact


SPEAKER_00:
i know i think it might be on your side oh it sounds cool though okay but is there any way to like maybe mute but it's it's minimal when you're talking oh it's okay

okay um all right i'll read some of the pre-submitted questions some of them are cool to maybe get your uh short short takes on so could i should i keep the should i share or should i just you can keep it up you know it's it's yeah you can keep it up and i'll just if in case you want to show a slide um

how did you incorporate physics like friction forces or air resistance into the model so when you're and and just thinking from your engineering expertise more broadly how do you bring in these physical features and constraints into the model's dynamics to what extent do you encode them symbolically um core screen them how do you include those in the model


SPEAKER_02:
well again there are two aspects of the model here so let me just go back one thing i want to make sure that we are on the same page there are two things we are looking at one is this hierarchical models right large complex hierarchical models and one example is here this is one example this is physics this is total i mean this is a time series model from

from the temperature in a zone and in this in this case for a given zone we have this type of physics model right and and it is easy to incorporate it both in terms of states and actions and so on

But in all honesty, when you enlarge the system, if you look at the complex zones, if you look at many different factors, it will be very difficult to find a physics-based, tractable model to actually to use, in which case you have to use some sort of neural nets or some sort of approximation.

this is one example where you bring physics another example which I showed you is is here where um this is it this is the bicycle model again this comes from physics in terms of doing the inverse Dynamics uh kinematics so um

think that's a great question we have done some of it i don't know the answer to all of it how it is going to be done how it can be done but depending on the system i think it is very possible to incorporate physics but again when the system becomes complex it may not be very attractive


SPEAKER_00:
Yeah.


SPEAKER_01:
Sorry, just add a small point to that.

So in training the diffusion model, we are using the data from the physical simulation.

So I think that was incorporated as a noise to the physical simulation where the diffusion model learns from data, the frictions and the physical properties.


SPEAKER_02:
And that was a very good point, Yulin, because there is another point.

For example, when you are training it for buildings, for instance, you use some digital twin of the building, right?

And for that, again, that digital twin incorporates many of the physics elements of that building in the backend, not directly using the active influencing or diffusion, but in the backend it is using it.

So there are different ways of using physics,

But again, assuming that it is tractable.


SPEAKER_00:
Awesome.

How did you handle perception through sensors and sensor fusion and feature extraction of the data from these sensors?

So how do you do structured learning on everything from which of the kind of layers of the system to model on through which kinds of model architectures you used for the neural network mediated steps?


SPEAKER_02:
well let's step back on it so if you are looking at from active influencing perspective well if you have a continuous systems then again you look at the dynamics continuous dynamics of the system if it is too complex of course you use this probabilistic framework to describe it if it is discrete more than likely you are using some sort of a markov or state transition

behaviors so having said that let me just go back to this i'm glad that first of all let me also stop here there are many engineering systems that can be described by graphs

uh perhaps you can call them automata in in terms of the if you look at it from computer science perspective but the graph models are very usual but let me go back to this to answer that question and i'm glad that i have that slide in here um actually i kept that side looking at the questions that you have this is one good example of how i can use

the sensor information so if i'm looking looking at these tables you can think about lambda so think about it this way that you define a time a time unit and again i'm talking very engineering define a time unit one second two seconds five seconds whatever milliseconds and if you don't receive any information or any data you call it lambda

P arrow up could be that temperature is going up, arrow down means temperature is coming up, coming down and so on and so forth.

The same for the P pressure and so on.

So basically what you see on this table, that's a process data.

These are actual data you're receiving from the process.

But there is a methodology that you can take this and from that, you can create the automata or the state transition graph on the right-hand side.

and as this sensor information or data is increasing and becoming more and more you can keep on updating your model so there are already ways of creating this type of structures now again in active influencing the underlying assumption is that if you are using a discrete model it is some sort of state transition diagram

Okay, you use Markov blankets or you use state transition diagrams and there are ways to build it.

I mean, it's not, we have done a lot of work on this in the past.

This is an existing work in the literature for almost from 20 years ago.

So there are ways to build that.

But when you come to the active influencing or diffusion, you already assume that you have that structure.

Okay, so to us, it's not part of active influencing.

Active influencing, you already have it in there.

But again, of course, you can combine all of them together.


SPEAKER_00:
Yeah, that was a really interesting angle with the noising process as sequential.

Sorry, I'm getting a little bit of an echo from you still.

Could you just mute, Wilson?

Okay, thank you.

Thank you.

Yeah, the sequential application of the Gaussian process, which also has kind of analogy in if you're 90% confident, each time step, then there's a decay in the confidence.

So it's kind of like projecting out through time.

And then planning backwards in time with increasing precision is like moving forward in reducing uncertainty about a path to take.

in a planning space but it was the other direction from a diffusive information neutralizing direction and so it's a it's a algorithmic way to kind of talk about the forward and the backwards

aspect of gaining and removing information and um how do you plug this into existing engineering tools or what kinds of toolkits are you using for specifying and for running these models unmute


SPEAKER_02:
two models that we have tried so far one is that parking lot model in a simulated environment we have created the simulated environment for it we are planning to expand it of course and so that is one model and and and again the diffusion there well as you said it is a it's a it's a predictor it predicts and first it by going forward it tries to

uh lose information totally and then by going uh backward it tries to gain the information and by doing so it finds the its way of how to go from one random location in this parking area whatever that is to a to a to a specific um you know parking spot and by doing so then you you use this

into your optimization because you want to find which spot is really your best spot and you have to go and park there

Honestly, it is so organic in engineering system because the engineering system works like this.

In engineering system, you always have some organic.

If you look at the human-like systems, and that is why I'm so interested in active influencing because it's so organic.

We always do it that way.

You always have a process defined.

okay there is always a structure and you want to always use that structure to find the solution so to me it is very organic in engineering like systems and as i said many engineering systems you can use graphs to describe them many engineering systems are hierarchical you can decompose it and look at the you know simpler cases you can create abstractions but to me it is very natural that

you organically learn how to do things and then you use your expertise to find the best way of doing it you don't mix the two you basically well you you integrate the two but you understand that first you have to know how to build one piece but then you think about okay how am I going to optimize this so you use that knowledge to optimize it and that's exactly what we are trying to do


SPEAKER_00:
awesome all right in closing just give your thoughts on this it'll be awesome and and thanks again for this great work so what would be the obstacles to advancing this approach to more complex autonomous navigation scenarios and agents well honestly i don't know this may


SPEAKER_02:
Again, see, there are two elements here.

One is the diffusion or the projector, and the other one is the optimizer, which is active influencing.

So we have a projector, we have an optimizer.

These two are integrated together.

I'm sure there will be complexities.

And, you know, as we move on in this direction, I'm sure we will find many complexities.

But let's just look at the projector.

The projector, which is a diffusion,

it has to um i forgot to say that the two examples i showed you on the diffusion from the literature they both assume that the initial data sample is uh there is an expert so there is some expert information sitting there meaning that on the driving in the parking lot example i already know where i should be going i am expert in going from one point to a parking spot

we don't want to make that assumption we are looking at cases that there is no expert information on this so you really have to learn from almost nothing when you do it that way then you have to somehow find ways of doing a lot of sampling

well the sampling with diffusion is much much easier than and much more efficient than doing Monte Carlo searches much much easier than that but still you have to create that type of knowledge base and then you use that knowledge base in your optimization so I personally think that that may be an area that needs some attention

and the second area is of course the complexity of active influencing an engineering system itself because you know engineering systems are big it's huge i mean if you want to look at real applications you're really looking at large systems i mean a production system there may be hundreds

thousands of machines and processes that you have to integrate all together how do you incorporate all this into this fusion diffusion and active influencing framework well remains to be seen but definitely a very interesting problem awesome yulin do you have any last words or or what what stage are you in in europe where are you going where are you going with that


SPEAKER_01:
well uh just to answer your last question um i think the biggest challenging is growing state space right if if the problem if the like the driving navigation problem gets extremely complex if we introduce a bigger map then space space a state space will just explode

It will introduce a very big computational challenge.

That's why we want to use diffusion and we want to use the window stitch method to separate a big problem into smaller problems.


SPEAKER_00:
Awesome.

Awesome.

Thank you again for joining.

Looking forward to hearing more about this work in due time.


SPEAKER_02:
Thank you so much.

Thank you.

Thanks so much.

Bye.