SPEAKER_01:
Hello, everyone.

Welcome.

It is September 13th, 2022.

We're here at the Active Inference Institute with John Vervaeke.

So, John, welcome.

Thank you for joining.

I'm very much looking forward to this conversation.

Hello, and to you.

Thank you, Daniel.

It's a great pleasure being here.

I'm looking forward to this.

Is there any introduction or hello that you'd like to provide as we head into this journey together?


SPEAKER_00:
I guess I can give just a little bit of background so people know where I'm coming from.

I'm an associate professor at the University of Toronto.

I'm appointed both in cognitive psychology and in cognitive science.

I teach in both and I am the director of the cognitive science program.

So I do a lot of work integrating, especially psychology and ideas from artificial intelligence, large framework models, philosophical framework models for the nature of the mind.

I especially do work on intelligence, consciousness, insight, flow, mindfulness, and wisdom, all centered upon a notion, well, not a notion, a proposal, a theoretical proposal that I call relevance realization, and perhaps we'll get into that at some point.


SPEAKER_01:
Into it we go.

So, to provide some context,

these live streams are multi-directional roads we're going to be talking about different ideas for some people it'll be their day-to-day life and the water they swim in for other people it might be their first time hearing about relevance realization or predictive processing or active inference and so we always want to make it accessible and also provide depth

So, yesterday, in speaking with some other participants at the Institute about how to frame this discussion, I was bringing a notion of a three-legged stool.

And the three legs of this stool that provided stability are, again, those relevance realization, predictive processing, and active inference.

And then a participant dean said, flip the stool.

It's still stable.

And so that led to some discussions of what was the betweenness of these ideas and what were they really doing alone and what do they do together?

And we're going to approach that.

So first, we'll be exploring relevance realization and predictive processing.


SPEAKER_00:
Mm-hmm.


SPEAKER_01:
in terms of what they are and how you recently connected them in a recent paper.

And then we'll bring in active inference as a third guest to the party.

But first what is relevance realization and what is predictive processing?

How did you bring those two together in the recent work with Brett Anderson and Mark Miller?


SPEAKER_00:
So the two lines were, uh, working independently.

Um,

I first got my first paper officially accepted in 2009, didn't get published until 2012 because they were holding it back for a special issue that took forever to come out.

The reason I mentioned the earlier date is that's before I think most of Friston's major publications.

And that's just, and I'm not claiming precedent or anything, I'm just claiming independence.

I didn't know about his work until after the theory

uh was well developed and i assume he might even not know of mine even now and that's fine um so the idea behind relevance realization is that if you take a look at many different problems uh within attempts to explain the mind in a non-homuncular non-question begging manner you hit this problem of relevance realization uh so for example um

How does categorization work?

Well, we notice the two things are similar.

What does it mean to say they're similar?

Well, logically, it means they share many properties.

And then Goodman famously pointed out that any two objects share an indefinite number of true properties.

You know, a plum and a lawnmower both have round shiny surfaces.

They're both found in North America.

Neither one existed 300 million years ago.

Both have an odor.

Neither one is a particularly good weapon, et cetera, et cetera, et cetera.

And what people will say to me is they can't say those are false because they're all true.

They'll say, but that doesn't matter.

And that's the move.

When you go from logical similarity to psychological similarity, you say, well, I zero in on the relevant comparisons.

Ah, and how do you do that?

And that, of course, is still the crux of the categorization problem.

Let's take a look at inference.

Well, inference is just to follow all the implications of a proposition in relation to other propositions.

Well, how many are those?

Well, let's take a proposition.

It's going to be windy tomorrow.

That would have implications for me if I'm sailing that are different for the implications for me if I'm flying a kite or if I'm planning to have a picnic or if I'm planning to stay inside or if I'm planning to take an airplane.

And do I check out all the possible connections between that proposition?

No, I only select those that are relevant.

And this was a point made very well quite a while ago by Christopher Cherniak in his book, Minimal Rationality.

Problem solving.

Many of you are already familiar with this, so I'll just state it.

We know that the search space for most problems is combinatorial explosive.

You can't search the whole space, so you have to somehow ignore most of the space while nevertheless reliably being able to solve a wide variety of problems in a wide variety of domains.

I can make similar arguments for communication.

I can make similar arguments for learning, et cetera.

I won't go into them.

I'm just giving enough to exemplify that independently, all of these things keep crashing into this issue of zeroing in on the relevant information.

And you can even note it in your everyday experience.

What should you pay attention to right now?

What should you draw from working memory?

What should you draw from long-term memory?

Especially the fact that you can combine different things from long-term memory.

What sequence of actions should you perform?

What possibilities you could consider, et cetera.

I take it that this is at least plausible enough for me to go on.

People can take a look at all the publications to see the arguments more in depth.

So this crucial ability for relevance realization needs to be addressed if we're ever going to provide, I've argued, I've argued since my thesis, if we're going to provide a naturalistic explanation of the mind.

And to the degree to which we avoid it, try to just pretend it's not there, etc.,

I think it undermines our efforts to give a naturalistic explanation.

Now, this is sometimes called the frame problem.

I don't call it that anymore because Shanahan has rightly argued that the frame problem was two separate problems.

One was to create a viable logic for change that didn't get you sort of enmeshed in a bleed out of all kinds of identities.

And he argues that that challenging problem has largely been solved.

He claims to be one of the people that solved it.

Nobody seems to be challenging him on that.

I don't either.

What he says remains, and those are his words, not mine, is the deeper problem of relevance.

That's exactly what he calls it, the relevance problem.

So this problem is a key problem, and...

I have a proposal that I've worked on with other people, Tim Littlecrop, Blake Richards, Leo Ferraro, Brett Anderson and Mark Miller in the recent paper, Gary Hovhannessian in a paper we recently published, also integrating relevance realization theory and an active big five personality theory.

And the proposal, I mean, the proposal has more sort of technical details, but just to give the idea,

And we're not claiming that this, I'm not claiming, none of us claim that this proposal is completely novel.

What we're claiming is you see it implicit in many different areas where progress is being made, and you can draw it out and explicate it and therefore make more specific proposals of how to look for it or how to engineer it.

And this is the proposal that the brain basically uses at many different levels, opponent processing.

And what it's doing is it's doing something very analogous to evolution.

It's opening up variations and then putting selective pressure on them.

And then from that opening up variations, putting selective pressure on them.

And you can see this at many different levels.

Your attention is doing it right now.

Your default mode network is trying to make your attention wander off and introduce new ideas.

Your task focuses network is drawing it back in, killing off most of those options, but one of two of them might be actually relevant to what's going on.

You keep them.

And the idea is that you do this, and there's many of these trade-off relationships.

I'm just giving one example.

There's many of these trade-off relationships.

They're operating in a massively recursive, multidimensional self-organizing process to help you repeatedly zero in.

on the relevant information.

Like I say, there's more detail, obviously, but that's, as fast as I could make it, a gist of what the theory is proposing.


SPEAKER_01:
Thank you for the summary.

Definitely a lot there.

In one way, it's like moving from the sketch of the continents and the lay of the land, the space of the possible for cognitive science across these different domains, and then asking how the relevant

view combinations are selected.

And then one can point to a broad range of so-called cognitive phenomena in human, as well as in other cognitive systems, learning, memory, planning, attention, compositionality, action selection, and policy inference, all of these areas, which one might imagine could have bespoke custom theory,

Or there might be a way to look at some similarities, ironically or not, finding the relevant similarities in these different cognitive domains and asking whether we could improve our inference and our action regarding those domains through the usage of an integrative framework like relevance realization.


SPEAKER_00:
That's excellent, Daniel.

And so just to add to why I think it's reasonable and perhaps even plausible that there is such a domain general central capacity is we have robustly replicated evidence for the existence of general intelligence.

By the way, general intelligence doesn't mean it can't be analyzed in components.

It means at its functional level, it forms a causal whole that has reliable predictive relations.

And we have.

It's the most powerful psychometric in psychology.

People don't like to hear that, but it is nevertheless the case.

And so we have evidence that there is above all, and not in place of,

But above all the specific learning you have for specific domains, there is powerful evidence for general intelligence, a domain general ability.

The way we test for it, Leo and I made this argument in another paper, is basically we test for people's capacity at relevance realization again and again and again.

And so that's why I think it's plausible that there is this underlying capacity.

And what that helps do is it helps, it allows you, it allows to bridge into more comprehensive patterns of explanation we have.

So, for example, the model I just proposed to you is explicitly explicit.

an analogy, but a strong analogy, you know, to the way evolutionary processes produce adaptive morphology from organisms, evolution, variation, selection, and it doesn't require an intelligent designer.

Right.

Evolution is clearly a process that is itself not intelligent and can produce intelligence.

And so that gives us the potential way out of any homuncular explanations of intelligence.

Like, you know, the central executive selects this or that and those kinds of explanations that just presuppose an answer to this question.

And so instead, the idea is no, no.

the brain at this general level, again, I'm not denying specific heuristics, although I'm proposing that perhaps relevance realization is how those specific heuristics might be generated.

I'm not denying specific heuristics.

I'm not denying domain specific knowledge.

I'm not denying any of that, but I'm saying there is a general ability

Just like there is this general process of evolution for biological adaptivity, there is this general, if you'll allow me, cognitive evolution of your fittedness, your cognitive fittedness as a problem solver to your environment.


SPEAKER_01:
Yes, and in those ways, it's very resonant with generalized Darwinian models or neural Darwinism, as well as the trend in eco-evo-devo, ecology, evolution, and development, by way of looking at proliferation and that pruning back process.

Yes.

in different spatial and temporal scales, different systems, like the way that it might happen with synapses forming and then being pruned during development, the way that ecosystem assembly might occur with initial plants forming some sort of substrate that later forms ground for development, and then even at slower and longer timescales with evolution.

And especially when we think about the neural aspects, learning and behavior are part of development.

They're processes that happen within a lifetime.

And that is a great angle to consider.

So relevance realization in our first pocket.

Let's move to the second leg.

predictive processing.

What is predictive processing and how did it come into play and why did it come into play for this recent work?


SPEAKER_00:
So I've been familiar with predictive processing and I would often be an annoyance that the conferences were predictive processing was being presented because I would ask, where does the model come from?

And where does the innovations for the model come from?

And things like that.

And the questions were genuine.

I wasn't trying to sabotage.

I wanted to understand how this was

Integrating, and I wasn't getting, to be fair, and the fault is probably also mine.

I was learning all about this.

I've learned about it quite a bit, and I have my bias.

But Brett, Brett Anderson, approached me and he said, look, I think that what you're doing in relevance realization is really needed for predictive processing.

And then at the very same time, and this is one of those happy coincidences that are the shadows of God or something like that.

A former student of mine who went through the cognitive science program with me, Mark Miller, who has worked with Andy Clark and a bunch of the other predictive processing people came and he said, John, I want to start working with you again.

And I want to integrate what you've been doing and I've been doing.

And so the three of us started talking and he said,

And when we went back and forth a lot and we came up with,

a way in which we saw these two theories converging.

So predictive processing, I mean, there's a lot of technicalities and people vary to the degree to which they're committed to, you know, a strong Bayesian or weaker Bayesian.

Everybody agrees that you can't be pure Bayes because it would be computationally intractable.

You have to do some approximation.

And then the idea is you have a massively recursive network that is basically

doing something really interesting.

Now, again, not to claim priority or precedence, but independently, in the 2012 paper, we predicted that the brain basically tries to model itself in order to model the environment, because this actually gets you through a lot, past a lot of difficult problems.

And that was, and independently, and again,

uh i want to give due credit uh the idea was no no the brain shouldn't predict the world uh the brain should predict itself in a multiply recursive self-correcting fashion in order to predict the world and for reasons that i won't go into right now that just that that just gets you past so many of these roadblocks right and then the idea is well what should the brain what is the brain doing when it's predicting itself

you know, there's all kinds of math, but you know, a good interpretation is the brain is trying to reduce the degree to which it surprises itself.

The brain is higher levels.

Well, right.

You've got a level of the brain level is meant to be taken as an abstraction, not an anatomical region.

There's a level of the brain that is, you know,

doing the sensory motor interaction with the world.

And the idea is this is a loop.

It's not input output.

It's a continuous loop or sensation.

Perception is modifying action and action is modifying perception.

And so there's a level of the brain that is just registering that as patterns of activity in that causal interaction.

And then layers above it try to predict

that pattern is going to unfold and when there's error the error is fed back into that layer and it is corrected to try and make a better prediction and then what you do you do this massively recursively you have layers predicting the layers below them so on and you propagate error up and you propagate prediction down and what that does is it um it allows you to slowly slowly

hone in on the causal structure of the world.

And it doesn't promise to get you the perfect causal structure of the world or any Cartesian thing like that.

But what's really interesting and one of the things we talked about is, you know, you also have that recursive sort of stacking of layers of prediction in various models of deep learning.

And deep learning also does.

It was one of the inspirations for relevance realization theory.

It does the variation and selection in things like the wake-sleep algorithm.

And we thought, hey, there's a lot of things converging here.

And then we started examining this with other people, like Clark.

And we were going through it.

He says, well, what do you predict?

There's a combinatorial explosive number of patterns you could predict in the environment.

Well, then you predict the important ones or the relevant ones.

Oops, that's going to be problematic.

And then you predict the reliable ones.

No, that's not good yet enough.

And then you had the idea of precision weighting in which you're trying to prioritize which patterns are given processing, which is...

basically a model, and many people explicitly claim this in the predictive processing framework, of attention.

That's what attention is.

Attention is psychologically a prioritization process that's doing the precision weighting that helps the predictive processing avoid a combinatorial explosion.

You can see the convergence coming in here.

But then, you know, and

Fairly recently, I think it was 2017, 2018, Clark was talking about this.

And he said, well, precision weighting ultimately comes down to task relevance.

And it was like, oh, no.

That's just homuncular.

We need a little man in there.

That's relevant.

That's not relevant.

And that can't be it.

And then what you see is predictive processing framework is moving to trying to come up with sort of dynamical self-correcting way in which the trade-off relationships in the environment are being used in order to help.

Trade-off relationships, sorry, in the way the organism is trying to survive in its environment.

That's more accurate.

can be made use of in an opponent processing fashion to help get a non-homuncular account of the precision weighting.

And we saw the two theories as just, oh, wow, they're converging.

They're coming right together.

And then it looks like they could actually help each other.

The relevance realization can help explicate what these trade-offs are like and the kind of opponent processing make.

And I do mean explicate.

I think this is already implicit in the most cutting edge work

within precision weighting and predictive processing.

And the predictive processing, I sometimes like to use this analogy and don't push it too far, but I think the predictive processing is basically giving us the Mendelian genetics of intelligence and relevance realization is giving us the Darwinian evolutionary theory and they need each other very deeply.

And there's a lot of things that the relevance realization theory can give to the predictive processing that it doesn't do as directly on its own.

These are things like helping to explain connections to a lot of phenomenological features, salience, priests,

the linkage to theories of consciousness.

I can go into all of this in detail.

And so the two theories just feed together, and they really strongly support each other.

I think a very strong advantage, which is coming out now, and this is something we're just starting to work on, so I don't have too much to say that I'm very confident about, but I'm confident in the intuition that I will have something to say, which is that

You know, there's been a very strong critique of the predictive processing framework coming out of somebody who I hold in very high regard, Evan Thompson.

And it's complex.

And there's an ongoing debate.

I do think that Evan's main point, if I can boil down a very complex argument, and I hope Evan will forgive me because I'm just trying to make sort of a promise here, but make it a plausible promise.

is that the predictive processing can be sort of refuted with, you know, easy counter examples of, you know, pendulum clocks in training on a mantelpiece and all kinds of... So you get panpsychism all over the place if these predictive processing are supposed to be the model of the cognitive... I've heard some predictive processing people just bite that bullet.

But for me, that seems implausible.

I think the answer...

which is almost forefronted in some ways in Evan's point, is that predictive processing is not really as for ease it claims to be.

It's not properly embodied, embedded, inactive, and extended.

Now, I think

The way out of that is by the connection, the integration with relevance realization theory, because relevance realization theory rounds out in the bioeconomy of an organism.

And it grounds out in the fact that relevance is always relevant to a system that is autopoetic.

Montague put it very well.

We're different from computers in that they don't care about the information they process.

We care about the information we process.

And I propose to you, we care about the information we process because we are fundamentally taking care of ourselves.

We are autopoietic beings.

and the theory of relevance realization ultimately grounds out it says that relevance is deeper than representation it's deeper than inference it's deeper than logic it's actually running off the bioeconomics of the organism and it is working in terms of the autopoiesis and so i think if predictive processing is integrated with relevance realization it gets very clearly and explicitly and deeply integrated within both

Continue.

With embodiment and embeddedness.

And that would address, I think, many of the criticisms that are emerging from Evan Thompson's critique.

So not only is there increased explanatory power outward in terms of explaining mental phenomena, there's increased explanatory power in responding to deep criticism.

So that's sort of where we're at right now.


SPEAKER_01:
amazing many ways to go here and many great questions in live chat that i know we'll be able to get to one footnote that we'll come to as well is connecting so many of the terms that we're using here which are being used in a technical sense

scientific or even formal and mathematical to their everyday uses ranging from attention and relevance to all these different notions of prediction explanation design control and so forth so connecting these natural language terms to the way that they're used in cognitive sciences is a very rich area

For the predictive processing architecture itself, you absolutely conveyed it, which is it is building from Bayesian formalisms around inference and uses a vertical nested model spatial metaphor.

It's not actually like a skyscraper or anything like that, where higher levels are making ongoing predictions and lower levels are said to be feeding upwards

observations and initially or at the most peripheral aspects of the agents we have what are most sensory like observations but those can become processed in a predictive framework step by step for example edge detection and vision object recognition and so on um and then very interesting how um even at the very beginning asking how this came about

you spoke to the way that Brett and Mark became involved in this ongoing line of research, which I think speaks to the social inaction of research and the distributed cognitive elements of development of theory and practice.

And then to bring to the very end,

that the relevance is agentic and situational.

And that's kind of like the strange loop or like the quasi tautology, like fitness in an evolutionary setting is situational.

And it is both the most mysterious and explanatory phenomena.

And it's the most circular phenomena.

And so relevance as well is so hyper situational that,

that it can seem like it's going to evade generalization.

yet by combining computational architectures which are inspired by both advances in modern machine learning and artificial intelligence and deeper investigations of natural intelligences of diverse kinds ranging from ecological psychology and all these other fields that is what you pointed to in the title convergent solutions to the frame problem and um

So anything else to add on predictive processing, relevance realization, or their edge before we add more in?


SPEAKER_00:
Yeah, I mean, there's an important point, which is important to both Brett and Mark, as well as myself.

I wanted to, first of all, try to lay out what you might call the scientific provenance of what we're talking about here.

But now I want to also talk about a domain in which it offers significant promise.

I won't go over the argument here.

I've done it in multiple places, both in many different video series.

I won't even name them.

The point is, in talks I've given at conferences, the relevance realization machinery, I think you can make a very plausibly strong case because relevance realization is not cold calculation.

It's about caring.

it's about what grabs your attention it's about what calibrates your arousal it's about what binds you adaptively to the environment this is about the fundamental agent arena fittedness that makes you a cognitive agent it generates the primary affordances that are brought into your cognition through salience etc what i'm trying to get at is this is like a primordial connectedness that is constitutive of your agency

And I think relevance realization and that kind of connectedness and constitution of your agency is very much what people are seeking when they're seeking this domain general feature of meaning in life.

It's a kind of connectedness.

The language that is used is mattering, being connected, connecting.

having a fit between you and the world, that you make a difference, right?

All of this language, which is almost always metaphorical, in fact, using the word meaning is a metaphor.

We're taking something from propositions.

We're trying to talk about our relatedness to the environment.

And I think...

The relevance realization when it is giving you what Marlo Ponti would call an optimal grip or in fact a meta optimal grip on the environment is actually affording that meaning in life.

That's one point.

I want to make another point, then I'm going to bring the two points together.

So a bit of patience.

If you take a look at how relevance realization works, and this is one of the advantages.

So I've done a lot of work in sort of insight and self-deception that have not been gone into as much in predictive processing, you know, because everybody's doing what has attracted their interest and what they find relevant to coin a phrase.

But what I would say to you is the very processes that make us adaptively intelligent make us perennially prone to self-deceptive, self-destructive behavior because we are intelligent

By ignoring so much information, we always run the risk that we are actually ignoring the information needed to solve the problem.

And you can catch this in the evolutionary dynamics of relevance realization when you have an aha moment.

When you go, you have an insight and you realize, oh, I've been framing this.

We'll even sometimes use that word.

I've been looking at this the wrong way.

And we don't mean visual perception.

We mean, right, I thought she was angry, but it turns out she's actually afraid.

I've completely misinterpreted.

And you know what I'm talking about, those insight moments.

And that's when the system, right, is actually doing something like punctuated equilibrium, like in evolution.

But the point is we don't always have insights.

We have the opposite of insight, which is we get locked into, blocked into, misframing situations in a self-deceptive, self-destructive manner.

We can do this individually and collectively, echo chambering, et cetera.

And therefore, we need processes that ameliorate the self-deception

without hamstringing the adaptive relevance realization that enhance insight enhance that connectedness that's meaning in life uh while reducing the foolishness the self-deceptive self-destructive behavior and i put it to you that across time and across cultures people have come up with ecologies of practices for doing that and that's what i would call wisdom it's a kind of rationally self-transcending rationality and therefore there are deep connections

that can be made scientifically plausible and empirically testable, some of the testing is already occurring, about central aspects of what goes into a lot of falls under the name, I don't like this term, but we don't seem to have a better term for it, spirituality, where people are primarily sort of in an often nebulous fashion talking about wisdom, insight,

the alteration of consciousness and somehow.

But if you think about it, a wise person is a person that can go into a very messy, complex situation and somehow zero in on the relevant information, what really matters, and appropriately fit themselves to that situation to make a difference to it in a way that

brings about a movement towards flourishing for all parties involved.

And so an additional thing that the connection to relevance realization provides that predictive processing doesn't have, I'm not saying it couldn't have, but I'm saying this just speeds it up and makes it, is a connection to a lot of the work that has been done

and others, collecting relevance realization to meaning in life, altered states of consciousness, insight, flow, wisdom.

And that is a powerful way to extend the explanatory scope of the theory while also increasing its existential and cultural relevance.


SPEAKER_01:
Thank you.

Very interesting there.

I want to pick up where you mentioned this may be towards what people can be seeking with questions around life's meaning, people's search for meaning.

And you use some terms there like

things that matter and you've brought up in writing and in conversation about asking people questions around what matters and seeing that as an entry point into further investigation as well as like connection and fit and you also brought up from ecological psychology uh the notion of affordances capacities for action and optimal grip where we need to hold the sports implement

enough to use it but it has to be flexible and adaptive and situational as well and this points in our language and thought to extensive spatial and visual visual and physical metaphors and figures of speech we talk about sketching ideas and even tangible aspects like comprehension and grasping ideas so we even use this kind of optimal grip language around cognitive ideas

And this is being dovetailed in a new way with cognitive physics and the Bayesian mechanics that we'll be exploring more in active inference.

So I think that's extremely interesting that even the formalisms

are seeing convergence and similarity in terms of the physicality of things that might seem cognitive, mental, abstract, even spiritual and vice versa.

And I wanted to know where's action in this picture.


SPEAKER_00:
So, I mean, action for me is the, um,

How do I say this without, I'm trying to not say too many things all at once.

There's agent arena relationships, set up affordances, and that's a basic level of relevance realization, a level I call participatory knowing.

where the environment the the arena and the agent are co-shaping each other so that affordances open up and you don't make affordances they're not subjective they're not in you they're not features of the environment they're real relations i i say they're transjective relations that's what affordance is and we need to open up our ontology and this has been a this has been sort of a philosophical

dimension of a lot of this like we need to we need to bring back the idea of real relations we've already been implicitly assuming them adaptivity is a is the adapt as the adaptivity of the great white shark in the shark no put it in the Sahara desert it dies is it in the ocean no if I put an elephant in the ocean it drowns right so no no it's a real relationship a real relation of fittedness

So we need to have an ontology of real relations.

And so the participatory knowing is, and you remember, this is something come out of philosophy.

I'm trying not to do too many arguments at once.

You don't have to know you know in order to know.

Because if you do that, you get into infinite regress and skepticism.

So this is a kind of knowing that you don't know that you know because it makes all other kinds of knowing possible for you.

It's a co-shaping by the physics, by the biology, even by the culture between you and the environment so that affordances open up.

So agent arena affordances are there.

Prospectival knowing is layers up of recursive relevance realization in which

The relevance is being translated as relevance to something like working memory, and that's what salience is, I put it to you, that salience is relevance to working memory.

I do not think we should be saying that salience is a property of objects or a subjective phenomenon.

That, again, doesn't ultimately make ontological sense.

But I'll just keep going.

Perspectival knowing is knowing what it's like to be you here now in this state of mind, in this situation.

And a situation is how the arena is made affordant to you.

And your state of mind is how you are fitted to the arena.

But now you are salience landscaping it.

You are foregrounding and backgrounding.

You are sizing up some things.

You're leaving other things not as gestalted together, more penumbra, right?

And it's dynamic and it's flowing.

You're always salience landscaping.

And the function of that salience landscaping is to select, and I mean this like in an evolutionary sense, to select which affordances are going to be enacted.

That's your perspectival knowing.

And what it does when it makes that selection is it also taps into your procedural knowing, your sets of skills.

your sensory motor routines for interacting with the environment, your procedural knowledge.

This is your know-how.

This is your knowing how to do this.

And then only within a subset of your knowing how, you know how to make certain inferences.

You know how to make certain proposals and propositions, et cetera.

And that's your propositional knowing.

So action is going up that stack.

That's my proposal.

It's the participatory knowing that is taken up by perspectival knowing that is taken up by procedural knowing that can be reflected and extended by propositional knowing.


SPEAKER_01:
One other aspect of action, which I saw in the tension or compromise between thinking different threads and only having one mouth, is action is like the eye of the needle because the embodied entity is able to only engage in one action selection at a time with potentially serious and even fatal consequence.


SPEAKER_00:
Exactly, exactly.


SPEAKER_01:
Thank you for bringing that out.

That's important.

Thank you.

And cognitive systems, either as if, as we model them, or in their actuality, can engage in

all of these interesting phenomena that we've been exploring like counterfactuals planning um all these different aspects that help one emulate simulate however we want to think about that but consider alternate pasts and presence which is like the um perspective

counterfactual and alternate futures, which we must engage with to understand which sequences of actions we prefer to select.

And then in predictive processing, the imperative becomes to, among other things, reduce our surprise about the world, which can be an optimistic model we're reducing surprise about.

So it's not that we've expunged pragmatic value.

In fact, we've balanced, and as we'll explore formally soon, balanced epistemic and pragmatic value through action selection by way of replacing this monolithic reward pursuit


SPEAKER_00:
and seeing curiosity and epistem as merely like a tributary to reward exactly and so that that's another that's that's part of what i met with the the analogy i gave earlier about uh genetics and and uh evolutionary theory uh because

you know, and we're all familiar, people who initially encounter this say, but I don't want to reduce all surprises.

I want, and then what the typical predictive processing is, oh, but you'll, you will sometimes go for a short-term increase in surprise for long-term reduction.

And then what we're talking about is overall rate.

But the problem is you then need something that is selecting between different longitudinal domains of processing.

Uh,

Because, of course, it's not always the case that you should prefer long-term over short-term, right?

And there aren't simple comparative algorithms for this.

You need dynamic trade-off relationships between short-term, long-term, between…

you know, well, I like some short-term, I don't want all my short-term surprises to go away because if that was to go away, then, you know, that would impact greatly on my long-term learning because I get locked in local minima.

And that's not the only explanation for curiosity, but that's one kind of explanation you give.

And you go, yeah, right.

But, you know, that means you can't use a simple hill climbing.

You got to do other things.

What are you doing?

And, you know, there's, you know, there's people,

There's people like Brett and I who think that there's things happening in the brain like self-organizing criticality at multiple levels of firing, small world network organization at multiple levels of wiring that are trying to constantly dynamically optimize these trade-off relationships.

And Chris Honey has talked about the fact that you can see the brain processing at multiple levels.

He actually argues, and I don't know if I completely agree with this, but he argues, and I knew Chris was at U of T for a while.

He argues that there actually isn't memory.

There's just different speeds, longitudinal rates at which information is being processed, which is a really cool idea.

And so again, what this does is as soon as you start to

make those completely legitimate moves on behalf of predictive processing, explaining things like curiosity, like insight, like wonder, because wonder and curiosity aren't the same.

Curiosity is there's something missing and you

piece of information and you go looking to fill it in and get rid of your ignorance.

Wondering is when you call yourself and your world into question in order to set yourself onto a developmental pathway.

It's an aspirational project.

And so

Predictive processing, when it opens up its theoretical language in order to address these, you can see how it starts to lean more and more into the kind of language that is afforded by recursive relevance realization theory.


SPEAKER_01:
great one closing note um before we move to active inference is this question of does the fact that these models are reducing or bounding surprise mean I can't have any surprise and the nest there's as you pointed out there's various ways to approach or balance that um critique

For example, considering the long term or the rate of surprise.

And one of the most powerful responses is nested modeling, which could be like the self-belief, I expect and prefer to hear from diverse and novel perspectives.

Then, yes, one will be surprised in a little sense, you know, lowercase surprise by every phoneme.

then in a deeper sense who we are we can be connected with by hearing new information so it's um absolutely a valid critique of the kernel of a single layer surprise minimizer just like you would have various trivial critiques of single layer reward maximizers however especially with nested architectures and considering embodiedness we can see how um higher level beliefs about the self

which can include like the rhetorical and the narrative, absolutely provide a context by which lower level surprises are accommodated, if not surfed on top of.


SPEAKER_00:
Just one thing, I think we can even make some significant progress, and I did this in a series with Greg Enriquez and Christopher Mastropietro, The Elusive Eye, sort of integrating predictive processing and relevance realization models to give an account of the self.

You take all the accumulating evidence that self-reference, which is really just self-relevance, is the glue of cognition and perception, relevance realization, and then you can basically integrate that

with Howie and other people's, I think it's Howie and Michael, their idea of a predictive processing model of the self.

And they just go together very nicely.

And then you can talk about, well, there's relevance realization to the self,

And this is not just a homuncular thing.

And you can also point out the fact that cells are, because we're mammalian primates, and this is Greg's point, is we learn to turn the arrow of relevance the other way.

We are not just for our whole development, how are things relevant for me?

We also develop, how am I relevant to others and to the world and even to my culture?

And that, again, starts to connect up with meaning in life.

How am I connected to something bigger than myself?

This is the metaphor that people use.

See what I mean?

There's just so many things that can be brought into a convergent and powerful conversation once we get this integration going.

I'm not saying it's complete, but I'm trying to at least make it plausible that it has to

plausible promise to extend the scope and power of our scientific explanation into domains that it has hitherto been blocked from getting at.


SPEAKER_01:
That's heavy.

That's a massive cognitive entity.

That's groovy.

We're in the path of least action together.

Let us move to active inference.

So, in the paper, you mentioned active inference one time, though I think we can see it interwoven densely.

And the quotation in the paper was pointing to Sajid et al.

2020's paper.

It has recently been argued that active inference and free energy minimization necessarily entail the minimization of redundancy and the maximization of degeneracy.


SPEAKER_00:
So first, just...

I just wanted to highlight redundancy and maximization just to give another example are drawn directly from cutting edge biology.

I keep wanting to show again and again that this is not a trivial claim of autopoiesis and embodiment.

We are making use of fundamental biological principles.

This is, again, to give a basis for a reply to Evan's, I think, everything that Evan does is brilliant, right?

And so this is, but this is, again, I just, I'm sorry, I have a deep respect for his critique, and I just want to keep pointing out, here's a possible response.

Great.


SPEAKER_01:
So we have a few questions.

Images and pieces of information about active inference, which we will uncover through action We will reduce our surprise about what is under the gray box through action.

But first just wanted to hear your perspective What is active inference?

How did it come into play and when and what was it doing in your recent paper?


SPEAKER_00:
So For me

and I know there's variation on this between people, I see active inference within the predictive processing framework because I see the idea of the interplay between active inference and perception.

And that, first of all, Mark and Brett and many of the people that we cite are not bound to a strict propositional logical, or sorry, the logical manipulation of propositions when they use the word inference.

If

they would do that, then Evan really does have a purchase point because then they are being locked at the propositional level of processing.

They're not tapping into all the non-propositional in a deep way.

But Mark, for example, very much inactive embodied, he says we just use inference because that was the original term and it's just stayed as a way of talking.

So the way I think about it is like this.

You have two ways of dealing with the error.

You can change your model or you can change the world.

And changing your model is broadly perception.

I just want to stop here and open that up.

When we say perception, we don't mean what the empiricists gave us with the sense of perception.

We don't mean just a purely receptive bottom-up taking in of information because we also mean prediction.

Right.

And so in a very real sense, when I'm looking around this room, I'm not detecting most of what I'm seeing.

I'm predicting it.

Now, that doesn't mean it's an illusion.

True predictions are true.

If you don't believe that, you don't believe in science.

You have to give up this sort of empiricist thing that unless I touched it somehow in detection, it's not true.

No.

True predictions are true.

They are real relations.

They are true to the world, right, in an important way.

I would put it to you that to get closer to what is meant by perception, we have to take two terms that were separated in empiricism and then put at weird relationship through the Enlightenment.

We have to actually integrate imagination and perception together.

You are constantly imago-perceiving and percepto-imagining your environment.

But that doesn't mean it's an illusion.

So first of all, that point, right?

Yeah.

And that opens so much up for explaining the imagination and distinguishing imaginary from imaginal and all kinds of important and powerful things.

The other thing you can do is you can change the world.

And I take it that active inference is a generic term for many different species of how we can change the world.

We can change the world by simply – and we're constantly doing this, by the way – we can just slightly alter our –

Again, the perspectival knowing.

And you're constantly doing this.

You're constantly just shifting your attention around so the world is disclosing itself to you in new ways.

Right?

And you say, well, that's just a new way of seeing.

It's not just a new way of seeing.

You are disclosing.

Look.

You can't ever see all of one object.

You only see an aspect of it, no matter what you're doing.

Yet you think you're seeing the whole thing.

Because what you're doing with this active inference is you are tracking, and I really want to play on that sensory motor metaphor, you are tracking the through line between all of these aspects.

For me, that's one of the fundamental things that active inference means.

It means that I am, look, look at how I'm doing.

But notice how actually, how unsurprised you are as I do this.

That is so active inference is not just I make stuff in the world.

It is that too.

You know, I get the water and I drink it.

And so now I am no longer thirsty, but it's even in the, it's even in how you are tracking the,

which is an action, a sensory motor action, how you are tracking the through line in the multi-aspectuality of anything in the world.

Because the amount of information that any object can present to you is actually combinatorially explosive.

For me, right, and again, I'm not denying the gross motor changes in the world of active inference, but I'm most interested in this cognitive navigation of the multi-aspectuality and multiple perspectives

of the world such that we find the through line and here's the thing that's really intriguing daniel the through line is not itself an aspect it's not itself a perspective it is something that runs through them and ties them together and that is the track i propose to you of active inference at its most primordial level


SPEAKER_01:
I think that golden thread is how the broader system changes through time, which we model action as influencing how things change through time and the causal structure of the world.

But to pull a step back,

you pointed towards the two ways that a given agent can reduce the free energy of their generative model.

So this is not Gibbs free energy.

This isn't the thermochemical free energy that causes combustion.

This isn't Tesla tech free energy, though I eagerly await the day when that synthesis is made.

This is an information theoretic quantity that bears resemblance to the free energy

calculations used in chemistry and physics and other areas and we call that bayesian mechanics and the process theory by which it occurs being active inference and so you pointed to two ways in which a given agent can reduce the free energy which bounds the surprisal with a tractable heuristic of their generative model

And those are to change the model, so change one's self, and that can subsume an entire taxonomy of cognitive types and parameters as modeled.

They don't have to be a specific neuroanatomical region.

And those parameters that can be changing to reduce free energy of a generative model can include the continuum of perception, learning, as well as expectation, preferences, and also models of action.

And the other way in which a given entity can bound their free energy

and seek to reduce it is through taking action in the world and so active inference is built around the action perception loop and it gives two meta affordances for reducing the free energy by way of minimizing surprise so i'm going to go one more level into detail with the active inference by revealing the first gray box

So this is an image from a recent paper this year by Chris Thornton called an informal reconstruction of the free energy framework, examining the conceptual problems that arise.

And the red text is a additional annotation that we've added into this excellent summary figure.

and we can read this figure as being a uh perhaps a kairos based historiography it's not a literal chronology of history but we can see it as part of the dialectic of research progression and it begins with the necessity of learning and developing which leads one to adopt a bayesian inferential scheme

My personal preference is that last names don't stay attached to terms, but Bayesian inference broadly just means models that update, as opposed to, for example, descriptive frequentist statistics.

The necessity of heuristics for Bayesian inference comes very early because exact Bayes is very hard to compute, especially on large or unknown state spaces.

The necessity of heuristics takes a further developmental stage by the necessity of proxies that bound

the exact Bayesian or even the heuristic or approximate Bayesian solution.

And so we can consider that like uncertainty reduction.

And then this is all pre-Fristen et al, here Dion with the Bayesian brain work and also the work of Hinton and others in level four, where we see the free energy minimization.

Free energy minimization is a computational heuristic

that is already widely in use going back to feynman and before to uh bound uncertainty with a attractable computational approach that includes reducing uncertainty and kind of being on this pareto optimal frontier of uh not collapsing uncertainty too much or too little and

And in a way, that's kind of like the energy and the enthalpy term in the Gibbs free energy world, except we're in an informational world now.

So that's where we were at before the recent work in the last, say, 10 to 20 years of especially Carl Friston and collaborators.

And what Thornton points to as some of the key contributions that were made was this particularly agentic interpretation of the lower four levels by suggesting that the figure could be separated from the ground, that the generative model could be separated or partitioned from the generative process, which is the niche.

and that entails a process theory which we call active inference which is suggesting a synthesis of inference broadly considered as you pointed to and action and finding all the contact points and the ways that inference and action come together just as the term active inference would suggest which means like action is used to improve inference you turn over the object

Inference is about action.

It's about selecting action.

It's about learning the consequences of action and how conditional they are on world states and other hidden state inferences.

And so the one level seven that we can bring in, which in the active inference textbook is called the high road to active inference, is the necessity of persistence.

And quite simply, objects that aren't acting at least as if they're surviving will not be around to be observed later.

So whether it's a rock or whether it's a computer or whether it's a biological system, it must at least be acting for the time that you're observing it or modeling it as if it is surviving in a potentially very complex statistical niche.

And so these six levels do an excellent job of describing how general statistical and learning frameworks like Bayesian statistics can become improved and elaborated upon through computational approaches, which have only been developed, for example, the Bayesian graph approach and so on in the previous several decades.

In the agentic frame,

directly leads us to considerations of active inference and understanding how inference and self-modeling including self-modeling about action of the agents are a way that either we can either think of what agents are actually doing or at the very least we can model what agents are doing through active inference excellent i'd like to i don't know this paper uh it looks like a paper i would like to have uh so i'll i'll ask you to send me a link later


SPEAKER_00:
Awesome.

So then do you want to add any more or we can go one more level?

I mean, I think I don't know if what I'm proposing is an additional level.

Maybe it is, or maybe it's a way of adding a dimension to the highest level or dimensions to all of it, at least maybe level seven, six and five relevance realization.

And then again, relevance realization, predictive processing have common ancestors.

Jeff Hinton, who of course was at U of T and deep learning was one of the explicit things we drew upon when we were trying to talk about relevance realization.

And remember the title of the paper, relevance realization and the emerging framework in cognitive science.

We were trying to say, look, there are general strategies in different areas that look remarkably similar and they seem to be strategies for dealing with this central problem

a relevance realization.


SPEAKER_01:
We could see the organism's persistence or eco-evolutionary fitness as being like the environment as the selector of relevance.

And then we can think the view from the inside, the psychological or even experiential aspects of relevance to be a part of that broader system.

And we can imagine kind of two cases.

One is where the organism's experience and cognition around relevance is aligned with ecologically selective fitness.

Yes.

At which case you're going to find that entity surviving and thriving.

You can also imagine where relevance leads us askew and things become relevant, whether it's repetitive behavior, self-destructive behavior through information filtering, all these cases in which our relevance realization is missing the mark.

It sins with respect to the ecological selection.

Exactly.


SPEAKER_00:
And that's my point.

How...

The very process that makes you adaptive also makes you perennially susceptible to self-destructive behavior.

You sin.

You miss the mark in a way that you can't realize you're doing.


SPEAKER_01:
And we calibrate and we learn as long as we are around.


SPEAKER_00:
Right.

Well, what I meant is as long as you're remaining in your sin, it self-encloses.

And the ability of an adaptive system to reduce perturbation means when you have these kinds of parasitic processing going on,

It hijacks that adaptivity and prevents your attempts to perturb it and help you break out of the inappropriate framing.

That's why you need very comprehensive ecologies of practices in order to cultivate wisdom.

It's why simply knowing that you shouldn't do that same stupid thing you do in your romantic relationships is massively insufficient for not doing that same stupid thing you keep doing in your romantic relationships.


SPEAKER_01:
Yes, and the agentic framework with the ecological richness that is being brought in helps us contextualize and take a pluralistic approach towards the various kinds of interventions which might be suggested because interventions for different kinds of relevance

you know, mal alignments, self-perceived, other perceived and cases where there's conflict there, they could include like neurochemical, it could include an action oriented.

There's so many different ways in which this nexus of the entity engaging in inference and action can be modified and shaped that without integrative models to help us understand, it can descend into kind of a disciplinary preference show off.


SPEAKER_00:
Yeah, yeah.

The church of the level, I call it.

The church of the level of analysis you believe everybody should be working at.

Yes.

Great.


SPEAKER_01:
So, let's look at a second aspect of active inference, which is its formal basis.

Now, there are many ongoing developments in the formalisms around active inference and the free energy principle.

And so this is barely even the tip of the iceberg, but hopefully showing these formalisms, which we explore in much greater detail in many of the other several hundred live streams that you'll find at the Active Inference Institute, just to show a few of the aspects of the formalism so people can triangulate

and have a little bit of a sense for where is active inference between so this is from a paper of da costa et al from 2020 active inference on discrete state spaces a synthesis so i'll make this image as large as i can there's two key aspects in this figure

the top which we won't go into detail in is describing two types of inference which are on the bottom perceptual inference which is like a best fitting estimate for perception given the sensory data which are incoming which includes the blind spot and the low resolution outside of the fovea and the lack of color vision outside the fovea and all these other attributes of our generative model

such that we even know that we're in a generative model and not, for example, within some sort of naive signal processing inward only view.

So I see this as just absolute slam dunk for predictive processing architectures broadly that we don't experience the blind spot, we don't see it, and that's normal.

because our salience has been tuned down to blurriness in that area and so on.

And in the top, we have expected free energy minimization, which in contrast with the variational free energy minimization, expected free energy is prospective.

It's about selecting amongst

policies sequences of actions sequences of affordances that can be expected to result in different outcomes now the entity could be wrong and that could lead to the entity not existing but within the scope of the generative model expected free energy is how different policies about one's own world states about the markov blanket here which are the set of perceptual and active nodes that mediate the interface between the entity and the niche

The way that those are balanced in prospective inference is summarized on the top.

And then it's quite interesting to look at some of these special cases on the bottom.

And so we can think about these as like the poles in which the big tent of active inference is propped up on.

These are cases where when one parameter is minimized or maximized or doesn't exist, there are various special cases that arise.

So just to give a few examples,

where there is no preference,

we see information gain maximization.

That's like a pure novelty search.

In contrast, where we have no ambiguity or risk, so we have complete information, then we can engage in classical utility-like calculations.

So that's kind of like when we don't have to learn anything or reduce our uncertainty, then that's a special case in which pragmatic value alone can be pursued.

where pragmatic value has been taken off the table because all outcomes are equal because our preferences across them are flat, then the inference can move into a more exploratory mode represented by like optimal surprise or information maximization.

And there are some deeper and more subtle links with maximum entropy principles.

But this is just to show a few of the kinds of formalisms that we explore in active inference, which bring together many previous threads in perceptual inference, as well as inference about action, for example, from cybernetics, control theory, and so on.

Just a few notes.

And then one last piece that I think will hopefully connect us to thinking about communication, culture, and then also bridge to the questions that I've seen stack up in the live chat.

So these are from the Active Inference Ontology, which is a project at the Active Inference Institute that we've been developing for well over a year now.

And what we have is what started as a terms list, but continues to develop to be much, much more.

And we think of active inference and building competency and familiarity with learning and applying active inference in terms of quite literally skilled performance of a language.

The terms and how they're related constitute the active inference ontology.

And so two views that speak hopefully to the directions that this can help us pursue rigor as well as accessibility are,

simple English definitions that link to other terms, just like you'd see in a dictionary.

A dictionary doesn't really tell you what the word means.

It just has more words, yet it still is considered a useful artifact by those who are learning and applying a language.

And so that's exactly what our terms and definitions provide, which are natural language definitions for some of these terms, which often straddle the line

or confuse optimally between everyday usages and technical usages.

Again, surprise, attention, all these different terms which you might hear day to day being used informally, they sometimes are used both in an informal and quite technical sense in active inference.

And a second aspect that's been a great,

direction and and uh really inclusive area of participation is with translating all of those terms into different natural languages so here we see english as well as um equal partners with spanish portuguese french italian czech russian hebrew persian and hopefully many more to come and so by treating this linguistic artifact as a collaborative and participatory project

and being able to bring in natural languages that people have, as well as bring in computer languages like our nomenclature and how we name computer variables,

We aim for something like a triple play where we can connect natural language descriptions of everyday settings or of contrived settings.

Those everyday natural language descriptions can be visualized and they can also be rendered as executable models.

Because we see that as where the promise of applying active inference can be most powerful when people are engaging in the skills and in the ways that feel natural and meaningful to them, such as in community, engaging in practices.

and that is supported and scaffolded and in feedback with computational systems that facilitate the communication and imagination around the discussion for example visualization and also provide in the same flow

executable simulations so it's not just like there's people who are having a conversation at the chalkboard and then the modelers go take it into a different room and that's where like the alchemy happens we think that by connecting the ontology with natural terms and computational representations that there will be new ways to be developing certain kinds of cognitive models and infrastructure together


SPEAKER_00:
So you're actually trying to afford wisdom.

What does that mean or what does it look like?

Well, I mean, insofar as you're helping people to apply Sophia into phronesis, these are the two words for wisdom in ancient Greek.

Sophia is your knowledge of first principles, and phronesis is how you apply it within a particular context so that it is effective, both giving you virtuosity and virtue.

You're trying to help people translate Sophia into phronesis, which is the sort of meta ability that is required for people to be genuinely wise.


SPEAKER_01:
with virtuosity and virtue, I see a lot of what could be positive for research and technical areas, which is it's not enough to have virtuosity alone.

Someone could be very skilled at taking aim in a variety of different domains, maybe one domain, maybe across domains, but without virtue,

then what you have skill and capacity without alignment maybe even the propositional belief that alignment doesn't exist or it's impossible it's useless or worthless or meaningless and then all that virtuosity to say it's for not would be an understatement because that person already made that claim but it could be worse than for not


SPEAKER_00:
And I want to say the opposite is also the case.

Virtue without virtuosity is something that undermines the respect that virtue is due because you have people sort of attempting virtue without having the capacity, the virtuosity needed to genuinely empower it in the world.

And so that's also problematic.

And so you can get the reduction of virtue to following simplistic rules or merely signaling the presence of something without having the requisite virtuosity to bring it reliably into being.


SPEAKER_01:
How does what you've been working on point towards or help us come to terms with wise technologies?


SPEAKER_00:
So that's, I mean, for me, I try to take, I mean, a big part of my, I wear three hats.

One is the scientist hat, which I've been mostly wearing today in our conversation.

But I also wear a hat where I help to,

develop, teach, curate, create, cultivate the colleges of practices.

As you said, pluralism, I wanted to strengthen the pluralism point you made, but it wasn't right for me to intervene at the time.

I mean, one of the things that the framework I'm proposing with Brad and Mark is to note that a lot of relevance realization and hence predictive processing is taking place by

making use of trade-off relationships between different values, different properties of the environment.

I gave you the opponent processing with the detention.

You can think of the opponent processing within the autonomic nervous system for constantly calibrating.

So what you do is you get a system that is two systems that are biased in opposite directions.

One is trying to interpret everything as threat and opportunity.

Another one is trying to interpret everything as a safety and recuperation, and they're pulling in on each other like this constantly.

And that's how your level of arousal in a non-homuncular fashion is constantly evolving its calibration to the world.

So many examples of this, right, often in multiple ways.

multiple dimensions, where I mean trade-off relationships that are also in trade-off relationships with each other.

That's why I use the metaphor of an ecology.

If you think of ecology as all these checks and balances, both at the same level and between levels of organization, ecology.

There is no panacea practice, no free lunch theorem, et cetera, et cetera.

There is no panacea practice.

You need to get a dynamic ecology of practices that

Well, optimizes for that multi-layered opponent processing.

And so I try to use my knowledge as a scientist to look for places within traditional and emerging ecologies of practices where I can see those design principles being applied very well or being developed very well.

And then I help to develop those, cultivate them, help build those communities.

And then that takes me into my third hat, which I didn't ever think I'd be wearing and I'm wearing, which is what is it to build these communities so that the wisdom of individual cognition

and the wisdom of distributed cognition are optimally aligned so that we have the best access within a community and then build those communities into communities of communities.

That's this project that I now find I'm actually engaged in a lot.

I do not claim to have any particular expertise for this.

It's just that I have fallen into it and I seem to be the person that is undertaking it.

So that's why I'm sort of hesitant, but I'm doing it with other people.

And so the answer to your question is I wear these three hats and I try to integrate them so that they mutually afford and constrain each other as much as I possibly can.


SPEAKER_01:
very interesting a lot to um say there uh there's a few ways we can go i think let's bring up one topic and then we'll go in the end to the uh questions so if people have any questions please feel free to add them now and it's a term that's one of

My personal favorites, which is- Oh, I like this term.


SPEAKER_00:
I like this term.

You introduced it.

I did not know this term until our previous conversation off camera, where you introduced this term to me, which I really liked.


SPEAKER_01:
It's a great term arising from work on insects and the work of Halligan defined stigmergy as a mechanism of indirect coordination in which the trace left by an action in a medium stimulates subsequent actions.

Stigmergy enables complex coordinated activity without any need for planning, control, communication, simultaneous presence, or even mutual awareness.

think it's a really fascinating and provocative idea because a lot of times when we hear about

collective intelligence or just collective algorithms more broadly, there are examples like flocks of birds, which absolutely swarm and flock, and they use visual coordination, but they don't leave a trace on their aerial environment.

Or you have the examples of traffic jams or of swarms or mobs of people, in which case, again, there's jostling, there's contact amongst entities, but a trace is not left.

And so those one might think of as like a live conversation where no trace is recorded.

And that kind of synchronous coordination is absolutely an important component to consider.

But especially when we think about at least two incredibly important cases, which are our digital environments and the various modifications that we make to them and our physical ecosystems and the kinds of modifications that are made to these niches.

neither of those cases are going to even be hinted at if we only consider non-stigma collective behavior and collective wisdom and so um in some recent work with colleagues we've continued exploration that has been existing since the earliest days of wikipedia and before around digital coordination as digital stigmergy because although there are times for synchronous coordination

For example, in this conversation, broadly through all kinds of modifications, including this video as an artifact that could be rewatched or transcribed or analyzed in the future, broadly communication

in the online setting can be said to result in complex coordinated activity without the need for planning, control, et cetera, et cetera.

So just wanted to hear your thoughts on StigmaRG.


SPEAKER_00:
Yeah, I've got three things I want to say about that because it's super cool.

First of all, for me, where StigmaJury really called out for me is how it affords cultural ratcheting.

A proposal that one of our primary capacities for adaptivity is cultural ratcheting, which means we don't relearn from scratch.

We come in and culture has preserved previous learning and then we ratchet it up.

So we culturally ratchet in a very powerful way.

And so that gives us a kind of adaptivity that is closed off to most organisms.

There are a few species that you could plausibly say chimps, bonobos, maybe some evidence from dolphins and elephants where there's something like a culture.

But this, this is where human beings excel.

And Stigman seems to fit right in there powerfully.

And you want to note that what we're doing right now is so important.

Because we're actually, we are collapsing the boundary that used to exist between live speech and writing.

Because we have all the spontaneity of this, but then it's preserved and it can enter into this meta dialogue with other videos where people are moving between the videos in dialogical fashion.

And so you get this layering effect, which is also working within the cultural ratcheting.

And that is very, very interesting and needs to be explored.

So that's cool.

And then I wanted to connect what you just said with the issue that the neuroscientist Reed Montague talks about of mutual modeling.

And this is something that I think needs to be properly integrated into this overarching framework that's being built.

I've done some work, especially with respect to aspects of consciousness, mutual modeling.

So

He talks about that you face a certain kind of problem in communication.

And he calls it, it's an efficiency paradox.

So the idea is, well, one of the things I need to do to increase efficiency is to reduce acting at cross purposes.

So I reduce acting at cross purposes by having two or more systems talk more to each other.

They communicate more.

But another way, classically, of course, by which I improve efficiency is I reduce the metabolic costs or whatever, the costs of my problem solving.

And of course, communication is very time and energy expensive.

And so he says, notice how these, and I'm doing this on purpose, are in a trade-off relationship, right?

The more we communicate, the more we increase our costs and we lose efficiency.

The more we reduce communication, we reduce our metabolic costs, but we increase acting at cross purposes and our efficiency also goes down.

How do we solve this?

And then he gives the wonderful analogy before he moves to the brain.

And he says, well, consider an old married couple, happily married couple.

Some people stay married because they hate each other, and that's the best way they can torture each other.

But I'm talking about people who stay married because they are loved.

They have almost like this telepathy with each other.

And he didn't quite use this language, but he uses the language of modeling.

But I think calling it generative modeling is no imposition on him.

And he says his example is straight, like a straight relationship.

I'm just going to use that for ease of reference.

I'm not prioritizing that or making any cultural claim.

I'm just saying it's easier to talk because I can just quickly use common language, right?

So the husband, right, has a generative model of his wife.

And the wife has a generative model of the husband so that they can actually coordinate their behavior without having to talk to each other very much.

So that's where he leaves it.

Now, what I argued is kind of that's right, but you have to cycle because periodically they have to come back together and talk to each other.

right to make sure their model the general models aren't getting out of whack and then they can go off and do their coordinated uncommunicating behavior and they cycle and then i said you can so you can actually see the brain doing this it has it you do the task focused where you're processing all the world and you coordinate all these different areas of the brain are coordinated without having to communicate much on the task and then you go to default mode

where what are they doing?

Well, they're all centrally hubbed and they're all checking in with each other because you just do all this sort of self-referential imagination, making sure all the models are in sync and then you go back on the world

You know, sync up again, go back on the world, sync up again, all these trade-off relationships and how you resolve the paradox.

And then I thought, you know, mutual modeling and stigmergy, like they really belong together as underlying concepts.

Now, Montague's argument is you see the brain adopting this strategy.

You see the brain doing this strategy.

All right.

Where you've got areas are engaged in generative modeling of each other.

And think how easily this could fit into predictive processing framework because there's areas of the brain are predicting other areas.

But the idea, and then, you know, you can point to evidence of synesthesia, cross-modal enhancement of perception, the fact that one...

supposedly specialized area like acoustics can actually take oversight in people that teach, blind people who teach themselves echolocation, synesthesia, and a whole bunch of other things just pile up as evidence that the brain is adopting this strategy.

And so I thought this was an interesting thing because this notion in one sense

points to cultural ratcheting and stigmergy and mutual modeling between people, but it also points inward to mutual modeling within the brain.

And like I said, I think this is so close already to a lot of what's going on

And the framework we're talking about, they're bringing this in.

And then again, then we could extend the explanation to things like synesthesia, that you could get cross-modal enhancement, that you can have one area of the brain supposedly dedicated to one sense modality, picking up the ability for, right, in rehabilitation, et cetera, et cetera, et cetera.


SPEAKER_01:
Well, two layers of marital stigmergy.

The first would be the neuroanatomical stigmergy by which local synaptic changes and other sort of neuroarchitectural changes enable complex coordinated activity without the need for a central neuron.

So at the micro scale, we have the physicality of learning.


SPEAKER_00:
Excellent.


SPEAKER_01:
And then there's the post-it note.

And there's the note on the door.

There's the modification of the environment, which is stimulating subsequent activity.

And it doesn't need to be the recipe for dinner.

It can just be a note or an inside joke.

And so when we have a model that's integrative and allows us to situate advanced cognitive agents in their niche...

then we can actually bring in those kinds of modifications, which is the root of StigmaG to mark stigma, not in a taboo way, but to mark the environments and the ways that that can elicit action, whether it's, again, a post-it note on the door in the relationship or a comment on a video, these are all ways that we can spur others to action.


SPEAKER_00:
Or, and so you can take the mutual modeling idea and then do George Herbert Mead,

You're right.

You're in a baseball.

You're on a baseball team and you don't necessarily need to form a specific model of all the other players.

You might want to have that a bit.

But you can he said, what you do is you create the generalized other.

You create a model.

Right.

Will allow you to interact with all of them very effectively.

And so, right.

We can carry around.

We can like.

We can have stackings.

We can have more specific mutual models for how I relate to my partner.

But then they are in a dynamic, recursive relationship with a generalized other model.

And that also is a trace of others in the guts of our cognitive modeling in a very, very powerful way.

Yes, multiplayer rituals.


SPEAKER_01:
as cultural ratcheting, enable people to be involved in cumulative as well as re-experienced and re-imagined cultural praxis.

And if there's a level to generalize out to,

Perhaps it is one of them that is relevant, such that we can have participatory ritual, as one can say every single culture has.

But taking awareness and wisdom into the process of shaping our rituals, so maybe they can be aligned with our preferences.


SPEAKER_00:
That's exactly right.

And there's a whole movement, and I'm involved in it.

And I spoke to this at a recent invited lecture I gave at Cambridge about ritual knowing and the connections between ritual, the imaginal, and being rational.

And so very much, very much.

If you'll allow me, I'll give you one instance of this.

And think about how this goes to updating and all this stuff we're talking about in predictive processing and reducing surprise.

Okay, so you go into academics, who are supposed to be the cream of the crop.

So a little bit of self-deprecation there.

And you give them...

Convincing evidence, rigorously tight arguments that they should start saving for their retirement now.

You allow them to raise whatever objections they have.

You meet them.

You get them to all agree that you've convinced them that they should save for their retirement.

You go away.

You come back in six months.

None of them are saving for their retirement.

Hyperbolic discounting, et cetera, et cetera.

Hyperbolic discounting is an adaptive thing, et cetera.

I won't go into all of that, right?

But then what you do, and there's like, you know, Hirschfeld and other people, all this, what you do is you now do something else.

You get them, and this is the imaginal, not imaginary.

You get them to imagine their future self as a family member that they have a responsibility for and that they love and they want to give the best possible life to.

Two things you find when you come back six months later.

The people that do the imagining start to save, and the more vividly they can imagine, the more they save.

So you overcome a kind of egocentric hyperbolic discounting through an imaginal, it's basically a ritual, this imaginal binding of yourself to your future self so that you get a more adaptive relationship.


SPEAKER_01:
It makes me think about variational free energy, which is about the present and the past as religion, religare, and then expected free energy as preligare, because we need to bind ourselves to futures that haven't happened.


SPEAKER_00:
Yeah, there's a current agentic

Way in which religio, that's my preferred etymological origin for religion, binding, connectedness, and there's also aspirational religio.

And what religion often does is try to find a sweet spot, an optimal relationship between current and aspirational religio.


SPEAKER_01:
amazing let us look at some of these comments so any of them feel free to add comments or give a response so first ali has written

In Deleuze's words, relevance questions are how much and how in what cases and who questions as opposed to what is X questions from difference and repetition.

So what are the questions that bring us towards relevance as opposed to questions that make relevance obscured?


SPEAKER_00:
That's a really interesting question.

I'm not...

I don't know much Deleuze.

I've read a little bit about Deleuze, and I should read more Deleuze because I'm a deep fan of Spinoza, and he has a very interesting reading.

I have the book by Deleuze on Spinoza, but I'm really hesitant to give much of an answer here because I don't know Deleuze very well.


SPEAKER_01:
It doesn't have to be a Deleuzian answer.

Just what kinds of questions and interrogative practices help us find relevance here?


SPEAKER_00:
So I think that to collapse a large argument built from Sperber and Wilson and their work on a book entitled Relevance, by the way, at least within communication, I think this is where I disagree with the lose, but this is where I hesitate because I don't know to lose well.

So that's my hesitancy.

I think all of the questions are ways of,

trying to get a reformulation of what we find relevant.

They bring out different aspects, bring in different perspectives and point the arrow of relevance in different direction.

And what Sperber and Wilson, they said, okay, you have the pragmatic aspect of all communication.

What's pragmatics?

Pragmatics is what you convey beyond what you can say, because I can't actually put into my words every, all of the information I'm trying to convey to you.

Because if I, if I did that, well, if, if, and by the use of, if I'm making use of not the logical if, but the temporal and conditional, if I, in this case, I'm referring to me and I'm referring to me insofar as I'm in this current situation, um,

did that, and that was referring to what?

Of all the things I've spoken of, I'm speaking of trying to give the specific verbal form of everything I'm trying to convey.

And then for each one of those, what do I mean by the current situation?

You see what happens?

You get a penumbra of ever-expanding attempts to translate the conveyance

And you get a combinatorially explosive list of sentences that I can't say.

And you do this all the time.

You know, you drive up and you open your window and you say, excuse me, I'm out of gas.

You mean your car is out of gas.

You're not trying to be more flatulent.

You mean gas is actually standing for gasoline.

You mean you're not completely out of gas.

You have some for you can drive at least a few more minutes.

Right.

And you know all of these things are at work because if you violate any one of those expectations, you get pissed off.

If they say to you, there's a gas station at the corner and you drive to the corner and the gas station has been closed for 10 years, you don't go, well, well, he told me the truth.

Because you, right, it was conveyed to you that you could make use of the gas station because you're out of gas.

I won't go on on that.

I'm just trying to give an intuitive example.

And so Grice gives these four maxims that we are trying to always follow in order to manage the conveyance so it doesn't become culminatorily explosive.

And it's the in its manner and format and what is quality.

So he gives three that are not relevance.

And the fourth one is relevance, explicitly so.

And then Sperber and Wilson just basically argue all the other ones collapse into relevance.

Like quality is tell the truth.

Well, no, you don't tell the truth.

You don't tell everything that's in your mind when you're speaking to somebody.

You select out of all of this in there, a subset that's relevant.

So give the relevant truth, the relevant manner, et cetera, et cetera.

So.

We always are doing this.

And I think questions actually operate primarily at the pragmatic level.

Of course, they have semantic consequence.

But what we're constantly doing is asking, what are you conveying and what are the implicatures, which are not the same thing as implications, what are the relevant implicatures before I try and derive the implications of what you're saying?

That's what questions, I think, do.

Now,

I want to also be clear about this, that we need to be directing the questions in two directions.

Sometimes we are probing, are we aspectualizing, framing the arena well?

in terms of, so we check to see, is the world disclosing itself to us such that we are solving our problems and flourishing?

But sometimes we also need to step back and look at the framing itself and ask, is the framing

right?

Actually misdirecting or misleading me.

So I think questions are always trying to reconfigure the fittedness.

And one of the things we, and therefore they're trying to enhance relevance realization at the pragmatic level, but we should always remember to direct the questions in at least these two directions.


SPEAKER_01:
Excellent.

Thank you.

All right.

Here's a question from Brock.

Can you give some examples of how depending on ignoring to realize relevance can prevent realization of meaning?

Does this relate to reciprocal narrowing and opening?


SPEAKER_00:
Yes, yes, totally.

And so Brock is familiar with my work and I'll just, let me just quickly open those final things up so other people are aware of what he's alluding to.

Thank you, Brock, for doing that.

A notion of reciprocal narrowing is drawn from my friend and colleague, Mark Lewis, who has proposed a learning model of addiction rather than a disease model of addiction.

Our current model, which governments and agencies like, is the disease model.

You have this thing, it's infected you, and it's debilitating you.

I want to make something very clear.

Mark is not saying that there is not a neurochemical layer, but he's trying to, well, he's trying to get an insight.

He's trying to get you to realize that the disease model makes all kinds of predictions that have been empirically disconfirmed.

I won't go through all of them, but they have to do with the effect that, you know, when we have that model, we'll tend to think of the substance as in and of itself addictive.

You know, cocaine is so addictive.

Heroin is so addictive.

Well, you know, there was lots of soldiers in Vietnam using opioids.

And when they came back, the vast majority of them stopped without having to have any special treatment.

They stopped using opioids.

But opioids are so addictive.

Well, what's different?

because presumably the chemical structure of heroin in Vietnam and the United States is the same.

What is different?

The agent arena relationship is different.

You're a soldier in a traumatic circumstance in Vietnam.

In the United States, you're a citizen and you're not.

And of course that caused all kinds of other problems for these people because the agent arena relationships are so different.

Here's what Mark proposes.

So I'll use alcohol because it's one people can easily relate to.

I have a very challenging arena and I'm stressed.

So I take some alcohol and it reduces the stress, but it actually limits my cognitive flexibility.

So my problem solving abilities go down.

So the options available to me in the world goes down.

So the world narrows.

As the world narrows, it becomes more stressful to me.

So now I want to take more alcohol to keep the stress away, but that's now impairing my cognitive flexibility.

You see what's happening?

The world as an arena is narrowing and my capacity as an agent is narrowing.

So you've got reciprocal narrowing until I can't be any other than I am and there is no future for me at all.

other than this moment of taking the drug.

And that's addiction.

It's reciprocal narrowing.

Now, I was literally, Daniel, I was literally at lunch with Mark Lewis, and I said, but Mark, if there's reciprocal narrowing, there has to be reciprocal opening.

And he went, oh, you're right.

And I talked about how Plato talks about this in the model of what's called Anagage, his model in the Republic of how you ascend out of the cave into...

seeing the real world, reciprocal opening.

And so I think when we engage in ignoring relevant information, we will often very readily fall prey to a very powerful kind of reciprocal narrowing.

So let's go back to the example I used.

You don't have the insight.

You think she's angry when she's actually afraid.

You don't have the insight.

And so you push on her and you only take evidence confirming, confirmation bias, that she's angry in to your model.

And then you only act towards her as if she's... And she's going to start probably...

almost like a self-fulfilling prophecy, respond more and more because your anger, right?

You start to act towards her in a way that gets increasingly aggressive and you reciprocally narrow.

And then it gets harder and harder for you to see that she's not angry.

And it gets harder for her not to communicate to you in a way that you have to interpret as anger.

Because when she tries to give you something else, you ignore it in zero.

And you have been in arguments and fights like that at some point in your life with somebody who,

that you don't want to be severed from.

But that kind of thing can sever the connectedness.

And when you're at the end of your life, you don't really care how many objects you've manipulated.

You don't care how many French fries you eat.

You care about the relationships you had and how deep they are.

And if you didn't pay attention at that time, you lost a relationship and severed a connectedness that enhances your meaning of life.

You fell into reciprocal narrowing.

It severed a relationship and your connectedness mattering to another human being has been lost.


SPEAKER_01:
There's no more interpersonal gravity and the relationship does not matter.

Yes.

right i'm going to read just a few uh non-question comments and then get to a question in these last minutes so uh griswold wrote ants hold hands in the river of information to float along together that's wonderful ian wrote vision and fusion communities coupling and decoupling and imagination as allostatic remembering of the future

Ah, wow.

Nice.

Very cool.


SPEAKER_00:
All right.


SPEAKER_01:
And here's one more question.

This is from Dave.

So Dave says, have you found, oh, I don't know if this is the correct way to pronounce the name, but Giles Falchionier's

work on mental spaces and conceptual fusion useful in explaining and improving the evolution of concrete mental activities and we can also see this work on generalized space and navigation with chris fields and mike levin and many others so whether you're familiar with that researcher or not how does this idea of cognitive spaces help us work in physical and social spaces


SPEAKER_00:
For me, again, and this how, you know, the connection to relevance realization and its connection to biology and evolutionary modeling is really helpful here.

So give me a moment.

So one of the ways in which evolution selects is it accepts.

Acceptation means it doesn't have to generate an entirely new

mechanism.

And so let me give you a concrete example.

It's one of my favorite ones.

What I'm doing with my tongue right now is speaking.

Of course, tongues did not evolve for speech because we have so many organisms that have tongues and they aren't capable of speech.

But what does the tongue do?

Well, it helps masticate.

So it has to be highly flexible.

It has to be a poison and calorie detector.

So it has to have lots of nerve endings and it has to be it's in the air passageway because that's how we evolved.

Right.

And so it's it's almost pre-designed, as some people say, pre-adapted for speech.

And so it gets exacted into speech.

I think there's growing evidence.

Look at Barbara Tversky's book, Mind in Motion, that the brain.

And this goes to the work of Michael Anderson and DeHaan and others.

The brain is an exactive process.

The brain is constantly exacting machinery that emerged for one arena set of actions for another.

Specifically, it looks like the set of abilities that we generate for navigating

physical space is exacted into moving around in conceptual space.

The fact that we're even calling it conceptual space and we talk about things being higher and lower and we move between, et cetera.

It's just totally impregnated with navigational language.

And we talk about orientation and finding our way or losing our way.

Can you follow this argument?

That's tracking language.

Can you follow this argument?

Where is it going to?

Right.

You know, I lost the thread.

Just like again and again and again and again.

And so it really and it helps to explain really weird stuff that's otherwise not well explained.

Okay, cerebellum, more neurons than your neocortex, often not included in fMRIs, by the way, which is a mistake.

You know, many fMRIs, I think, should be removed from their findings because the cerebellum is not included.

And we are now getting overwhelming evidence for the cerebellar effect.

cerebellum cortex loop and by excluding the cerebellum from our fmris we are conf we are we are smuggling in a confound that has not been properly controlled for so just a general point there when people are sitting in what's the cerebellum for you know sensory motor balance right then people are sitting absolutely still eyes closed

perfectly stable in meditation.

Their cerebellum is firing like crazy.

Why?

They're not doing anything.

They're not moving.

They're in a position where they can be deeply comfortable because they are aligned with gravity and they're stable, stable, stable.

Their eyes are

Well, presumably because they are navigating and they're trying to balance complex contingencies of attention and move through the experiential space in a powerful way.

And the cerebellum, this, this, when I started talking about this, it was controversial.

Now it's approaching consensus position that this is the cerebellum has been exacted for these kinds of functions.

So I think the idea that we, but that,

And I've only briefly looked at Foucaulnier's work when I was doing work on metaphor, and I didn't find it particularly helpful for metaphor, so I didn't go into it more deeply.

But the idea that we are doing something like mapping between spaces, I think this just plugs into the exactive nature of our cognition, that it is a form of rapid cognitive evolution.

Awesome.


SPEAKER_01:
Well, in the final minutes, do you have any words of wisdom?

Any thoughts?

Where do we go from here?

Where do people go from here?


SPEAKER_00:
Well, it depends.

I mean, you can go theoretically in which you can look up my publications and Mark is coming.

He got an amazing grant and other grants.

And so he's coming to UFT.

He and I are going to do work.

Brett and I are doing work.

The three of us are going to continue to work, so look for that.

Gary and I, who published the paper on relevance realization and personality, have one pretty well written on integrating relevance realization and attachment theory in terms of attachment is actually an optimal gripping practice between the child and the mother, or frequently the mother, the primary caregiver, I should say.

And so you can look for all of that.

For those of you who are interested more in the wisdom stuff, you can look at the stuff I published on wisdom.

I don't think I wrote any wisdom papers on my own.

They're with other people.

If you're interested in mindfulness, I've got two publications, one on an Oxford book,

uh an anthology edited by amir raz on hypnosis and meditation and a more recent one which i recommend in the routledge handbook on the philosophy of meditation where i talk about all this having how this all works out in terms of attention and meditation and contemplation why they're not the same thing why they're an opponent processing relationship why that's conducive to uh uh

insight and more systemic and systematic insight, etc.

If you're interested in learning about the meaning crisis, you can go to my YouTube series, Awakening from the Meaning Crisis, and follow that argument all the way through.

I have a new series coming out, which is about trying to

tap into how we can afford these kinds of flowing emergent conversations that take us beyond where we can go in an individual cognition and empower us um and it's called after socrates where i'm tracing out what's going on in dialectic into the logos um that's coming out uh this year probably october november

Rebel Wisdom, David Fuller, they're making a documentary film about me and my work that's coming out also October, November of this year.

So that's a bunch of things you can look for and look at.


SPEAKER_01:
Amazing.

Well, thank you very much for joining.

You're always welcome to come back.

We really appreciate it.


SPEAKER_00:
Thank you so much, Daniel.

And thank you so much for, I mean, there's a couple of things.

Maybe if you sent me your slides or something from this, that would be great because there's a couple of papers that I want to read now.

And it was excellent.

It was genuinely back and forth.

And I appreciated your insight and your perspective a lot.

And also your graciousness.

Thank you.

Thank you very much.

Thank you, John.

Till next time.

Take good care.

Thank you, everyone.