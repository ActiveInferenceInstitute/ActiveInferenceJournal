SPEAKER_01:
Hello and welcome.

It is July 17th, 2024.

We're in Active Inference Guest Stream 83.1 with Josh Bongard.

Thank you for joining.

This should be very exciting.

We'll have a presentation and then some discussion.

So if you're in the live chat, please feel free to write any questions.

And thank you again, Josh.

Looking forward to this.


SPEAKER_00:
Yeah, thank you, Daniel.

And thanks to those of you that are attending online.

So my name is Josh Bongard.

I'm a professor of computer science here at the University of Vermont.

And my bread and butter in my lab is the study of robotics and AI.

And obviously, we're in the middle of the current AI summer.

So what I wanted to do today is show a couple of highlights from my group, things that I've worked on in the past and that we're working on at the moment.

that I hope in the long term will help us realize sort of the long-term vision for a lot of those trying to create intelligent machines, which is to create machines that are helpful but also safe.

We're part of the way there, but as anyone who's worked with chat GPT or stable diffusion knows or even has a robot vacuum cleaner at home, there are some limitations to our current technology.

It's hard to create machines that are autonomous,

and useful and safe all simultaneously.

So what are the things that we're missing?

That's what I wanted to sort of seed the pool with today and hopefully we can move on to an interactive discussion about it.

So I'm gonna leave this slide up and just sort of talk over the slide for a few minutes that'll hopefully generate some food for thought and then questions.

This is a snapshot from some of the projects I've worked on over the years.

First thing you'll probably notice is there's a lot of different robots that have very different structural properties.

They not only act differently, but look very different.

And that is a fundamental foundation in everything we do in my research group, which is to try and understand how the body facilitates cognition.

Years ago with my PhD advisor, we wrote a popular science book called How the Body Shapes the Way We Think.

And we can mean that literally or figuratively.

We wrote that book a while ago.

We made some arguments about how the body shapes the way we think.

And since that time, my group and others have formulated other arguments for why or how the body shapes the way we think.

And I'm hoping to survey some of those today.

As I mentioned, you can see a lot of different robots here, very different structure.

They've got very different form and function, but across each of the pair of videos that you see here, you'll notice that there's also a common pattern, which is on the left side, you tend to see something that's virtual, and on the right side of the video pair, you tend to see something that's physical.

And this illustrates the basic approach that my group takes to understanding how the body shapes the way we think.

which is to create AI that creates robots, creates embodied AI.

So what do I mean by that?

What I mean is that in all of the projects that you see here, we create an AI that searches the space of all possible robots,

that could solve the tasks that we want the robots to solve.

Most people that are familiar with AI and robotics and autonomous cars and drones have a rough understanding that AI is somehow optimizing or tuning the brain of the autonomous car or the drone or the robot, what have you.

There's an underlying assumption in all of that current, in most current robotics, which is that the AI tunes the brain, but does not tune the body.

Tesla cars are dreamed up mostly by humans and an AI tunes their brain or their control policy.

But of course nature doesn't work that way.

Nature produced us and all the other intelligent organisms on this planet by carefully tuning body and brain simultaneously.

Certain bodies facilitate certain kinds of behaviors and certain kinds of intelligent behavior and other bodies don't.

They obstruct that particular behavior or that intelligent behavior.

So in all of our work, we ask the AI not just to tune the brain of a robot, but its body simultaneously.

And as you can see visually here, the AI often comes up with bodies that are well suited to whatever we want them to do.

So if you direct your attention to the very top left of the screen for a moment, this is now a 22 year old experiment, but I think it still visualizes the potential of this approach.

In this case, we were interested in creating a robot that can brachiate, that can swing across beams or tree branches or electrical wires for various inspection tasks.

And you'll notice that in this case, the AI came up with a solution that in retrospect seems intuitive.

The robot has to carry a very heavy battery, which you can see in the physical robot in the top left there, the black box that's at the bottom.

And the AI has figured out how to design the body of this robot so that it's actually able to exploit the forward momentum of this heavy object, this battery, to facilitate its movement or brachiation across this physical beam.

So it's a simple example, a simple robot, a simple task, but it demonstrates this interplay between AI, robotics, body, and brain.

If the AI was not free to place the battery at a particular place on the robot's body, it would be much harder, it would require more energy, it would require a more complex brain for the robot to figure out how to move its heavy weight across this beam.

So that idea of tuning body and brain has suffused everything that we work on.

Some other examples you can see in the top center and the top right.

Here we have a robot that suffers damage.

Its body changes over time.

So now the AI has to grapple with not just designing a body,

but grappling with a body that changes.

One of the things that we as intelligent organisms here in the world and all embodied AI, all autonomous cars, all drones, all robots have to deal with is entropy.

The world throws a lot of stuff at us.

We have to deal with wear and tear, injury,

In our case, we grow from a single cell into about 10 to the 12 cells.

We change massively in terms of our physical magnitude.

How do you continue to operate, keep yourself alive and do whatever it is you need to do across massive morphological change?

That is not an easy thing to do.

And again, it requires an AI.

If it's going to do this with robots, it's got to figure out how to carefully tune body and brain to deal

with the generation of behavior inside a body that is changing either unexpectedly due to injury and wear and tear or intentionally.

You can see in the very center panel, this is again a pretty good visualization of where designing body along with brain comes in handy.

If we want to make flying machines or swimming machines,

We have to very, very carefully tune the geometry and material properties of the body itself to realize flight.

So what you're seeing in this middle panel here, this is partway through the AI experimenting with the design of different kinds of wings for an ornithopter, a drone that flies by flapping its wings.

This flexible wing that you see here in the center of the screen, this is a bit of a transition from traditional robots that are made of rigid structures, like you can see in the top row,

into a more modern era in robotics, which is sometimes referred to as soft robotics.

Material science has come a long way in the last 20 years.

So we can now start to build robots, embodied AI.

We can start to build robots out of materials other than rigid plastic and metals.

And we can, again, we can start to move into an era in which robots, like organisms, can exploit the material properties of their bodies to facilitate whatever behaviors they need to do to survive or be useful to humans and so on.

So in the middle right panel, this is a highlight of some work that my group has done in collaboration with Rebecca Kramer Bottiglio's lab at Yale.

Rebecca's lab is famously advancing the state of the art in soft robotics.

What can you get robots to do when they're made out of soft materials?

You can see an example of some of those soft robots, middle right, and a very different soft robot lower left.

which is exploiting its body properties in order to move in interesting ways one of the interesting things about soft robotics in my perspective is that it starts to usher in an era in which

robots can actually grow and complexify their bodies.

You can see these hollow cubes in the middle right and these hollow sort of chambers in the bottom left expanding and contracting as we push and pull air into and then out of the body of the robot.

Suddenly, now you have robots that can change their geometry, they can change their volume,

they become what's known as thermodynamically open.

It's a fancy term for meaning that they can draw new material and new energy into themselves.

The thermodynamically open machines that you see middle right and lower left, the only

thing they're drawing into their body is more air but it's a start i mentioned already that humans grow from a single cell into 10 to the 12 cells every organism on this planet with a few exceptions starts small and gets bigger over its lifetime that fundamental morphological change start small start simple and gradually grow in size and complexity

that provides scaffolding.

It provides a gradient on which to learn how to gradually grapple with the world around you.

Most organisms, again, there are exceptions, are not thrust into this world with all of their machinery online from the beginning.

Just the way I'm phrasing this is obviously intentional to sort of dichotomize growing organisms and robots with fixed bodies.

autonomous cars are still very dangerous.

Autonomous drones are still very dangerous to be around because

99.99% of the time they do the right thing, but every once in a while they don't know what to do and no one knows what they're going to do in those uncertain circumstances.

That is a very concerning situation as we start to now deploy robots and autonomous vehicles into everyday environments where they are in close proximity to humans.

Why is it that even with state of the art AI and with all of Google's data centers and AI training algorithms, we still can't rub out that 0.001% where no one knows what's going to happen.

Part of the reason, again, is these machines are born with complex bodies.

We drop a controller into

a one-ton autonomous car made of metal and plastics.

It's very dangerous.

We don't grow autonomous cars from a very small, simple, lightweight machine that can't cause anyone any harm whatsoever.

And then when that simple, small machine demonstrates and verifies to us that it's safe, then we allow it to become larger and more complex.

It sounds like silly sci-fi.

Why would we build a machine like that?

But again, every organism starts simple and grows in complexity.

And if it doesn't do the right thing, if it performs dangerous actions that are harmful to itself or fatal to itself, by definition, it doesn't get any further.

That's again, one of the ways of thinking about how the body shapes the way we think.

In my personal and professional opinion, any physical machines that we deploy into the real world, they should start as very small, lightweight machines that can't harm anyone.

They have a very limited number of actions that they can perform and they sort of cycle through all those actions and verify everything.

And only then can they take

more mass, more energy into themselves?

Can they recruit more material?

They can sort of be allowed to be thermodynamically open and grow and complexify themselves.

There's lots of ways in which we're starting to create machines that grow and complexify themselves.

I just talked about these soft robots that can pull in air or possibly fluids.

They could be hydrodynamic machines.

They could mechanically or magnetically connect to other robots that sort of swarm robotics.

That's another path to growing machines.

At the moment, most of these machines are still restricted to academic labs.

They also are not safe yet, but I think in the long run, they're going to be a safer alternative to dropping AI into very large, complex, heavy, dangerous machines and crossing our fingers and hoping for the best.

Okay, so I've talked a little bit about rigid robots and soft robots.

I wanna try and talk as little as possible, so there's some time for a good discussion, but I wanna talk about what I see as sort of a third era of robotics and embodied AI, which is just starting to open up in the last few years, which is biobotics or creating biobots.

And you can see two biobots on display at the bottom center of my slide here.

A biobot is a robot that's made up of only biological components, no technological components whatsoever.

So in the bottom left here, Kriegman, Blackist and Levin and myself in 2020 published a paper demonstrating the first biobot.

This became known after publication in the popular media as xenobots, X-E-N-O, xeno, xenobots.

because these xenobots are built from about 2,000 frog cells, and the cells were taken from a particular species of frog, which is Xenopus laevis.

Michael Levin, our biology colleague at Tufts University, is world renowned for demonstrating that you can reconfigure genetically unmodified materials, like, for example, frog cells,

And that rearrangement of living tissues not only does not kill the organism, the organism is able to, in some cases, continue on doing what it does, what it needs to do, ingest materials, survive, reproduce in this reconfigured state.

There's a lot of biological implications for that.

One of the biological implications is that frog DNA does not code for frog.

What you're looking at in the bottom left, the xenobot, is about a millimeter in diameter, so it looks like a speck of pepper to the unmagnified eye, and yet it's able to walk around the bottom of a petri dish.

It doesn't have all the features of a living organism, but it's got enough of them that it's motile.

It's able to get itself from point A to point B.

So one of the other implications for AI of this biological discovery that you could rearrange genetically unmodified living tissues is that

maybe we can task an AI with discovering novel rearrangements of living tissue to produce robots, to produce something that moves around and does something useful on a human's behalf.

So that's what I mean by a biobot, a biobot that's made from, in this case, genetically unmodified cells.

um the the swarm of xenobots that you see in the bottom uh right uh as you can see they're sort of pushing around some material in their their dish this um sort of visually hints at applications for this this type of robotic technology which is they might be able to act like very very small roomba

robot vacuum cleaners in the future.

They might be able to collect microplastics out of waterways or cancer cells out of bloodstreams.

The swarm that you see that's cleaning up in this slide at the bottom right, the material that they're cleaning up is actually other frog cells.

It turns out that if the AI designs this swarm just right, and the swarm that you're looking at, this is an AI-designed swarm.

The AI came up with the shape for each member of the swarm.

The swarm is pushing these little white circles, which are individual frog cells, pushing them into piles.

Turns out these individual frog skin cells at a certain stage of development are sticky.

and they clump together into a pile.

And some of these piles, if they're big enough, if they contain enough frog cells, they will grow very small hairs on the surface cells, the cells that are on the surface of the pile.

And those little small hairs are called cilia.

They're usually used to pull dirt and pathogens off the body of frogs.

Here, when those cilia grow on small piles of frog cells, they're able to exert enough force against the surrounding water that these piles start to move.

And so what you have in essence is a child xenobot.

This swarm pushes cells together and in essence makes copies of themselves.

This is another implication of this work is that in this case, the AI has figured out how to design robots.

that replicate, they make copies of themselves by finding raw material in their environment and constructing copies of themselves.

This has been a longstanding dream in robotics, dating back a very long time to John von Neumann in the 1950s, who had a thought experiment.

It would be great if we could create robots that would create copies of themselves, which would create copies of themselves,

And if those robots do useful work for humans as a side effect, for von Neumann that was creating moon bases and then Mars bases and then colonizing the galaxy, which sounds great.

But the seed of this idea is if we want robots to really be useful at scale,

Instead of manually constructing billions of robots and then deploying them to do something useful, which is expensive, it would be much cheaper to make one robot that does something useful for us.

And by the way, it also makes two copies of itself, which does more useful work for us and four and eight and 16 and so on.

We're not there yet with the xenobots, but it's a demonstration that that is possible.

And again, all of that becomes possible because the AI is designing both the bodies and the brains of these robots.

This is very far now from the traditional view of AI and robotics, where we build a robot body, we humans build a robot body, and then the AI tinkers with the brain of that fixed machine.

Part of the reason why I'm here today and part of the message of my group is we need to think more broadly about how to combine AI and robotics and possibly synthetic biology.

And when we do, when we think more broadly, there are whole new paths that open up to ways in which we might create in the future, not yet, but in the future, create intelligent, useful and safe machines.

In the current era in AI, there is one particular approach, which is auto completion of tokens, which has come to dominate the field and come to dominate the popular imagination.

We all kind of have an understanding more or less of what ChatGPT is doing.

And there are some very strong lobbying organizations out there that are bent on convincing us that if we just do this with more compute, more data,

We will eventually get to safe machines.

My contention is there just isn't enough data out there to make non embodied AI like chat GPT and stable diffusion and all the rest to make them safe.

We have to think differently about designing bodies and brains of machines simultaneously to realize this long term goal.

Okay.

I've been talking for a while.

I'm going to stop and I'm happy to take questions or engage in some discussion.

And I'm happy to come back to any of these experiments and provide more detail if that's helpful.

Over to you, Daniel.


SPEAKER_01:
Thank you.

Wow.

Awesome.

What a cornucopia of bodies and minds.

It was a great overview.

I was really struck by some of the similarities and the convergence on whole of lifecycle design and kind of holistic design coming from, on one hand, a systems engineering and a materials perspective.

And on the other hand, from the biology perspective, with like eco evo devo and this convergence upon

needing to think about how the end-to-end function maybe even past the point of functionality like into the planned graceful decay of a robot as well so it brings in a lot of topics that even from an outsider's perspective seem to be put as kind of secondary so that's very cool okay great i'm looking forward to what people in the live chat write

My first question is, how over these 22 years, how have the materials, the theories, like the contexts, advances in Turing computation, all these kinds of things, how have they intersected and just what has the ride been like as you pursued these questions?


SPEAKER_00:
Yeah, I think it's, um, the short answer again is, is, is focusing on the physical aspect of AI and robotics.

So the materials from which we can build machines has changed over 20 years.

And from my perspective, the experiment, the top left there, that was something I did as part of my PhD, you know, the materials at the time, it was, it was very hard to build a robot.

You got, you bought some motors, you bought a battery, you bought some metal.

you bought some wires and you wired everything up.

There was the assumption that bodies were fixed.

And not only that, but they were difficult to make.

So once you made one, you were very careful with it to make sure it didn't change, that it didn't become damaged.

And that seemed to comport with a lot of the theory

in AI and neuroscience, which had the same sort of idea that the brain or in the case of robotics, the control policy is the puppeteer.

It's something that's pulling the strings of a fixed thing, either the body of an organism or a robot.

and if you look at a lot of a lot of theory in both fields ai and neuroscience that that assumption runs so deep so for example an active inter inference or you know the free energy principle we want to reduce surprisal that there's a fixed set of actions that we perform

to try and reduce the surprise between what we're sensing and what we predicted we would sense given the past action where do those actions come from why are they fixed does the set of actions grow over time maybe the the sensory data that's coming is coming from a new sensor that's just coming online or a sensor that's recently duplicated now there's two of them but they're not quite reporting exactly

the same thing.

There's a whole bunch of assumptions underlying a lot of the theory about active inference, predictive coding, you name it.

You pick your concept from neuroscience or cognitive science or AI.

Once you peel back those assumptions, imagine the robot's body changes.

Imagine the robot splits in two and becomes two copies of itself.

A lot of the theory and the formal underpinnings of that theory break down.

You start to get into ill-posed questions, which force you to now think about how do you fundamentally change the theory.

If you have a hierarchy of actions, like in predictive coding or active inference, what if that hierarchy itself is growing and changing over time?

How do we address that in a formal manner?

So to get back to your question, I think these advances in what we can do physically, we can build robots now out of soft materials.

We can build robots out of living materials, which

on their own will grow and divide and seek out energy and material on their own, that those physical machines, these odd new kinds of creatures are militating.

They're pushing against the theory and specifically they're pushing against these unspoken assumptions that lie underneath a lot of this theory about what's required to act intelligently in a complex world.


SPEAKER_01:
That's awesome.

Like the real world and the territory expanding into our unknown unknown.

Okay.

There's a bunch of questions in the live chat, so I'm just going to go for them.

Give any answer that you like.

Okay.

Sure.

David Williams wrote, how do you think about the controllers in your robotics?

Embedded AI, at least today, is rather hard.

Batteries and chips, PCBs, not soft and not easily synthesized locally.

So how do you think about the controllers in your robotics?


SPEAKER_00:
Yeah, great question.

So right, exactly.

The controllers are dealing with hard, rigid, fixed components.

We need to start thinking about controllers that can, in which, for example, the input layer and the output layer can grow and shrink over time.

There may be new sensors or new input coordinates that are growing or being attached to a machine, and the controller needs to be able to carefully deal with those new input channels while the machine is operating.

same thing goes for the output channel there may be new actions or new dimensions of action along which the machine can act and

control policies, reinforcement learning, all the rest of it, all those assumptions that make reinforcement learning work, which is what drives most autonomous vehicles at the moment, assumes that the dimensionality of input and the dimensionality of output, the things that the machine can do and sense,

are fixed during training or during behavior generation, during execution.

That is absolutely not true in any organism on the planet, and that's becoming increasingly untrue for our coming machines.

Now, how to do it well, I don't have any answers, but we have to figure it out.

You were asking a question about thinking about controllers.

That's a concrete example about how we have to rethink

control policy optimization even if we're not thinking directly about the body even if we just focus on the control policy and ask what happens as the input and output channel the dimensionality of the input and output channels change during behavior execution


SPEAKER_01:
Yeah, just one short point on that.

It's like training with a fixed set of perceptual elements or of affordances or of actuators.

It's like training on one point in a larger space of the adjacent possible of like bodies or of architectures.

So then, okay, we're bringing all this compute to train a special case in the fixed setting.

And that's not even how the smallest organism works.

So that just, again, like kind of...

shows that point.

Okay.


SPEAKER_00:
Sorry, before we move on from that point, just to again illustrate how the body shapes the way we think, in the case of a growing biological body, there are new input channels that come online throughout our lifetime, but they don't appear de novo.

Whatever it is, whatever that new input channel is, as we're growing, we just have more sense cells.

the signals that they're sending into the peripheral and central nervous system are not orthogonal to whatever else is already coming in as input because new input channels or new cells are slowly dividing and at the moment of division they're providing exactly the same signal as some other sensory channel that already exists.

So the body, or in this case biological growth, provides an immediate scaffold, a gradient.

In robotics, it can be very scary to think about attaching a sensor to an autonomous vehicle.

What the hell does it do with this new information that's coming in

Because we haven't thought carefully about how to add that new sense modality to the machine.

Again, we have to look to nature that every new sense sense modality is gradually coming online and gradually drifts away or becomes increasingly orthogonal to the starting input modality.

So that's how we should, if we did that physically with machines, it would simplify

reinforcement learning or make it easier for reinforcement learning or what have you.

Sorry, let me reshare my screen here.

It would simply make it easier for the... Sorry, something seems to have gone wrong here.

Give me a moment.

Yep.

Okay.

All right.

Uh, yeah, it would makes things easier on the control policy optimization process.

If new sense organs and new motor outputs are coming online, but they resemble things that already exist.


SPEAKER_01:
That's super interesting.

Brings up a lot of questions about like self and non self recognition and what is a self as new and different senses and actions come online.

Sure.

Okay.

Prakash Kavi asks,

Do these biobots have any sense of agency?

What is your sense?

I am quite intrigued by the idea that beyond a critical point, they start growing hair.

And do these biobots act independently of each other and also what happens at a group level?

So what's your sense of agency in biobots and I guess the biobot and the group level?


SPEAKER_00:
Yeah, it's a great question.

So I'll start with a disclaimer.

I'm not a biologist.

I'm a computer scientist by formal training.

So I can only say so much about what the cells are doing and what they want to do.

I definitely follow in the footsteps of the late Daniel Dennett in that when we talk about agency, each of us individually has to decide whether or not we take the intentional stance or not.

In my opinion, it's a point of view.

If it's easier to explain what the xenobots are doing,

by talking about what the cells want to do, like grow cilia and coordinate their actions, fine.

If it's easier to explain what the xenobots are doing by not taking the intentional stance,

and describing cells as mechanical components that are transforming input into actions, that's fine too.

This is something also that comes from my colleague, Mike Levin.

It depends.

As scientists, if we want to try and explain and understand what these machines are doing, if taking the intentional stance makes explanation easier, fine.

If not, then not.

But attributing agency as sort of an objective property of the bots or the cells themselves, independent of us as observers, to me that's philosophically and practically problematic.

As far as I know, there is no objective measure of agency in cells, let alone in organic robots.


SPEAKER_01:
super interesting that's like the second order cybernetics or the observer theory or the polycomputing question which is to say just looking at something and then treating one's perspective as um objectively the case it is objectively the subjective experience


SPEAKER_00:
absolutely now that being said again there is there is an empirical side to this we can make some progress in understanding the xenobots uh by comparing them against a control so instead of cells if these were you know magnets or some complex mechanical system in which more of us are comfortable in saying there is no agency it's just a you know it's a bucket of cogs doing something

and that control does not exhibit kinematic self-replication, for example, or it's much harder for the AI to figure out how to put together non-agential components to do what it is, then

then I feel a little bit more comfortable by saying the cells are doing something more.

Now, I don't know whether it's a gentile or they want to do something or if it's free will or consciousness, I don't know.

But if we can point at biobots or machines that are built from biological components and say it's easier to get them to do things because they start to, they become complicit in the overall goal.

compared to mechanical parts which don't, okay.

And again, as a roboticist in the top and the middle rows that you see on my slide here, when we do build things out of metal and rubber and plastics and ceramics, it's usually super hard.

It's really hard to get them to do whatever we want them to do.

We've been working on robotics since the end of the Second World War.

And we've got the Roomba.

And maybe we've got autonomous cars.

We're getting there.

It's taken a really long time because robotics is really hard.

It's really hard to convince physical materials to adapt and do something useful and safe.

On the flip side, we've been working on xenobots at the bottom here.

We've been working on them for about five or six years.

And we've got Roombas.

We're making faster progress.

in robotics, when we build from cells than when we build from metal suggests, you know, the cells are somehow helping.

I don't know that they want to help.

We've got to be careful there.

That's the intentional stance.

But when you deal with smart, when you, when you try and compose machines from smart machines and cells are smart machines, we're making fat.

I know I'm biased, but I think we're making faster progress than when we build machines out of inert materials.


SPEAKER_01:
Yeah, super interesting.

Okay, I'll read some comments from David Clement.

David wrote,

Does your work incorporate agential hierarchies?

For example, do xenobots grow by replicating the initial seed cell into a higher order system?

And is it critical for lower order systems to act as a component of a virtual machine, meaning that they have a target behavior that is less than the higher order system?

And that's kind of related to Prakash's question as well.

How do you bridge that from the individual component into the swarm or the aggregate?


SPEAKER_00:
yeah it's a really it's a really good question so absolutely i think the that when we started working on the xenobots and mike's mike levin started to talk about machines made of machines made of machines that definitely has influenced the work in my group to focus on this issue of hierarchy i don't know about a gentile hierarchy again we just talked about a gentile agency that's maybe a

a subjective stance.

But definitely, why would you want to build machines out of machines out of machines?

At the moment, our state-of-the-art robots, like autonomous vehicles, are not hierarchical.

The control policy operates at the level of the machine as a whole.

For example, if there is an emergency blowout of the tire in an autonomous vehicle, the tire itself, the rubber that makes up the tire, doesn't deform and try and fix or reduce surprisal locally.

It can't.

It's rubber.

It's inert material.

We don't have machines built of machines built of machines yet.

But as biology in general and the xenobots in particular demonstrate, there's an adaptive advantage to being a hierarchy of physical things, of physical machines.

If there is a surprising event at the level of the machine as a whole,

but that surprise trickles down through the hierarchy, it's unlikely that everyone at every level of the hierarchy is going to be surprised.

Someone somewhere in the hierarchy is gonna say, from my local view at least, on this bigger surprising issue,

I know what to do.

So let me start to communicate to my peers and up the hierarchy to deal with surprise.

That would be from a engineering point of view, that would be a good thing to have in big, heavy, fast moving robots that are near humans.

There's always going to be some surprising event that the vehicle as a whole has never seen before.

There's great YouTube videos of, you know, horrifyingly, you know, scary, surprising edge cases for autonomous vehicles.

Okay.

We're never going to fix every edge case.

Well, we can fix.

is to make hierarchies and maybe agential hierarchies where local surprise can be handled or global surprise can be broken down into local surprising events which can be handled locally.

If I understood the second part of your question is, how do we design that hierarchy?

Should the smaller parts be trying to pull in the same direction or be trying to solve some part of the goal of the higher level?

I think that's a super interesting question and I don't think that the answer is obvious.

It may be that smaller parts pursuing orthogonal goals ends up actually being useful.

It may end up being useful.

Just to give you a quick example, if you want, if there's a surprising event and you've got a whole bunch of semi-independent machines organized in a hierarchy, I would argue that every single one of those members of the hierarchy should have a slightly different body and brain.

It should have a slightly different form and function.

You don't want a monoculture.

You don't want all the parts being smaller versions of the bigger parts and trying to achieve smaller versions of the same goals.

Because then you've basically got a committee in which everybody thinks and feels the same way.

And as we know from humans, that's a dangerous thing, right?

You get group think or group act.

You actually want a hetero culture.

You want a whole bunch of things that are unique in terms of form and function.

And that maximizes your chances that someone somewhere in the hierarchy says, just because of the way I'm built and the way I think with my local control policy, I know what's going on and I have the seed of a solution.

Here's the seed, you all figure out what you need to do to make it a reality at the larger level.

That's another aspect of where the body comes into play.


SPEAKER_01:
Yeah, thank you.

everywhere is the last mile from somewhere things have to be addressed locally no matter how you think about a communications architecture distally everything and embodiment calls our attention back to that like it has to be somewhere locally so then why not take that as the starting point instead of like this kind of resource challenge and then about like the multiple subunits

When there's a damage to the nest of an ant colony or there's some things spilled on the surface, it's like not that every single nest makes a perfect pebble move.

It's that 51% accuracy with a bunch of non-specific flurrying of activity, just like kind of stress or these more generic higher order signaling.

that is what allows nest mates with different brains and bodies to fulfill their own paths of least action and then colonies for which that doesn't clean up the mess or it cleans up too well and there's externalities those colonies are swept off the table and then we see the persistence of collective systems that could figure that out in their growth from a little colony to a big colony

absolutely great great example um i had a question you you mentioned uh both safety as well as like reliability and how do you think about capacities and evaluations on diverse intelligences we're all familiar with ram cpu hard drive storage some of the von neumann type architectural descriptors

However, how do we even think about what does that rubric or report card even start to look like when we know that there's complex interactions with the niche and when the kinds of capacities that we're talking about may have even open-endedness?


SPEAKER_00:
yeah great great point great point right so you know we are the beneficiaries of you know two big revolutions one of them is the ai revolution but then the older one is the digital electronics revolution right so digital electronics works we all have you know a super computer in our pocket like there's no arguing with it it's an incredibly powerful way to make machines that internally communicate quickly and richly and then can communicate with other machines

I mean that's it.

That's the information age that we're in.

It's been so successful that it's hard to think about alternatives or why we would even bother thinking about alternatives.

But again, living systems, a lot of what cells do, they rely on electrical communication, but they also rely on mechanical communication, chemical communication, thermal communication.

Cells are using all physical modalities, not all physical modalities, but as many as they can get their hands on simultaneously all the time.

Why?

Why don't they just abandon everything and do everything purely electrically like our modern civilization has done?

Because it's dangerous.

You don't have a diversified portfolio.

So one panel here that I haven't talked about is the one in the bottom right, which is basically just what you're looking at is what's called a granular

It's a material that's made up of a bunch of grains.

In this case, the blue circles that you see, these are little just rubber pucks.

And there is an oscillation being supplied at the left-hand side.

And you can see that this leads to interesting non-linear vibrational behavior within this material.

What does that have to do with robotics or AI?

if you view the vibrations as the carrier of information so if if a puck is vibrating that's a one if the puck is not vibrating that's a zero now you can start to imagine creating materials that communicate shannon information throughout the physical structure not with electricity but with a different a different modality dynamics or vibration

And it turns out that you can actually compose these metamaterials to embody logic gates.

If you vibrate one particle or another particle, but not both and not neither, you can watch a third particle and it will either vibrate or not.

in accordance with an exclusive or gate and you can build this up.

Now again, why would you do that?

We can make an XOR gate that's vanishingly small and vanishingly fast in digital electronics.

Why would you ever want to do something different?

Because it turns out there are advantages of communicating with vibration rather than electricity under certain conditions.

Having a machine that can communicate between distant parts of its body through mechanical vibration, as well as electricity has an advantage over a machine that can only communicate long distances within its body electrically.

I won't go into the reasons, but you can intuitively start to understand that so again, I think we need to.

If we're serious about creating safe and useful autonomous machines, we have to break out of the digital electronics assumption that that's the only way to do things.

We have to break out of the assumption that non-embodied cognition is the way to go and it's easy to just drop it into a physical body and we're good to go.

We have to peel back some of these very deep assumptions about the right way to do things.

that have built up in our society since the Second World War because a lot of those technologies have been very successful.

Nothing wrong with them, but when we come to apply them to creating safe and useful machines, not always the right thing or the only way to approach things.


SPEAKER_01:
That's really interesting.

It's like a sort of generalized compute concept where we could talk about, well,

These are the chemicals that it can detect with this fidelity and here's its tactile interface.

Here's its electromagnetic capacity for sending and receiving.

That's what kind of motivates or complements the generic theory like free energy principle, which doesn't tell us about how anything is in particular, but then sets us up with kind of the framework to plug in these different modules.

And then it's an empirical question.

And then right here is sort of the...

virtual body and a real body and so that's also very interesting how how does that work like in a collaboration or with a graduate student like how do you balance this digital adjacent possible off of the material and the more costly um implementation with embodiment


SPEAKER_00:
yeah well with so with grad students and postdocs or whoever you know i'm collaborating with that's kind of starting out you know this can be a very frightening prospect for someone who's trying to get into ai and robotics because it looks like everything's been done it's solved like we all we got you know we just have to wait for google and microsoft to buy more compute and data and they'll they're going to finish off the last one percent of the dangerous behavior so if you're trying to contribute

to society's goal of making useful, autonomous, safe machines as starting out, what do you do?

It looks like this massive brick wall.

There's no entry point.

So my take on this is, again, is that we may be going about this all wrong, right?

The assumption that electricity should be the carrier of information inside an autonomous machine, that's an assumption.

Why electricity?

Why not vibration?

Why not something else?

Even if you start to think about the alternatives, the immediate reaction is, well, it's not gonna be as good.

Maybe, maybe.

But if you think about vibration, you were just mentioning like compute, we can use vibration for compute, but vibration is movement.

So the minute you start to think about vibration as the carrier of Shannon information, you are now conflating action with computation.

They cannot be separated.

Descartes convinced the West 400 years ago that they're separate.

They just are.

And you look at AI and robotics, what a surprise.

These two are attempts to create

you know, AGI is bicameral.

There's one team that says it's gonna happen in computers and the other side that says it's gonna happen in physical machines.

That's the Cartesian legacy that they're separate.

But the minute you look at some very humble material like the one in the bottom right, it's a bunch, it's 12 hockey pucks next to one another.

There's no Cartesian division anymore between body and brain.

There is a body and there is a brain there

but it looks very different from anything we would usually consider.

And there's no value judgment here.

It's not better or worse.

Maybe it is, depending on what your metric is.

It's just very different.

And so with grad students and postdocs, I encourage them to pursue that.

Could we do things completely differently?

And in the long run, might that be a better way to do things?

Who knows?

We'll see.


SPEAKER_01:
Awesome.

I'll make one comment and then ask a last question.

You brought up Descartes, and that's the res extensa, res cognitum question.

dualism between the thinking and the non-thinking substance, and embodied cognition, embodied intelligence provides both an operational, instrumental, and an ontological counter-argument or complementary perspective, which is just, well, in practice and in actuality, take it or leave it, they are inseparable.

And so, at the very least, that starts to ratchet and leapfrog the discussion about what is mind and body.

And, you know, you started with pointing out how important it was to co-evolve in the complementarity of mind and body.

And it's like, they're two separate things that need to be complementary and tangoing, and also maybe they're...

integrated and blurred in even deeper ways than the dance so that's like it's it's an empirical entry point into what otherwise is a thought experiment which can have utility but also can be just arbitrarily misleading absolutely one of my one of my former mentors inman Harvey at the University of Sussex used to talk about robotics as philosophy with a screwdriver


SPEAKER_00:
You know, it's not just armchair philosophy.

It's when you start to build some of these machines, maybe in retrospect, you, you, in the case of the metamaterials project for me in retrospect,

I said, oh my God, you know, most action and cognition are not complementary, separate things that are complementary.

They're one in the same thing.

It's not embodied cognition.

It's not an adjective of a noun.

It's embodiment is cognition.

There are not two things here.

There's just one thing.

Very hard to think about.

It's so alien to a Western mind, but...


SPEAKER_01:
you know it just is sometimes i think about that in terms of like adjectives getting added in front of a word and then the term expanding and then it just encompassing oh of course cognition is ecological embodied enacted etc etc etc etc and then so it kind of like it needs to be distinguished and then it subsumes again and that's part of

In closing, what are you excited about?

Where can people continue to learn more?

What would you say to a person who's wanting to go in this area?


SPEAKER_00:
Yeah, okay, great question.

Google my name and it'll take you into lectures and papers and tutorials and and people want folks want to email me that's perfectly fine again Google my name you can find my email happy to put you in touch with the right people I think it's you know it's easier than ever to get started you can go to chat GPT and say you know create some tutorials for me to start

coding up robots.

Ironically, non-embodied AI provides a good on-ramp now, not just for reading about these ideas or listening to people talk about these ideas.

You can start coding them up in a way that's easier than ever.

In the old days, you had to learn C and then go on from there.

Very easy to get your hands dirty.

Maybe not with physical materials, but you can create, like you see in the left of each of these panels, you can create machines that are virtual.

They're not physical, but they're embodied.

It's another point that's important to make.

Embodiment does not imply physicality.

You need to be able to push against the world and observe how the world pushes back.

But the world and you may be virtual like you see on the left or physical like you see on the right.

So you can actually relatively quickly get your hands dirty with playing around with embodied AI these days.

And I encourage everyone to do so.

Cool.

Any last comments?

I would just say I was at the Computer Vision and Pattern Recognition Conference, CVPR, a few weeks back.

This is one of the flagship AI conferences, 15,000 attendees.

And after my talk, a lot of grad students came up and they said, listen, you sort of demonstrated there's another path here, that I was feeling depressed or anxious about how to make progress in AI when these Goliaths have these data centers at their beck and call.

I would just encourage everyone that when you think differently about all this stuff,

There are new paths that open up.

They may not in the long run be the right path, but there are alternatives to this monolithic predict the next token idea, which is currently in vogue.

It may be the beginning of the end, but I think this is just the end of the beginning.

We've figured a few things out.

There are some things that work, but they're still producing not quite useful and definitely dangerous machines.

There is room for improvement.

And there's nothing that says that only Google with all its resources is going to be the one that can figure out these improvements.

Think differently.

Try some of these alternative approaches.

And maybe you will be the one that comes up with the answer, whatever it is.


SPEAKER_01:
Cool.


SPEAKER_00:
Good luck.


SPEAKER_01:
Awesome.

Thank you, Josh.


SPEAKER_00:
Really appreciate it.

Thanks for having me.


SPEAKER_01:
Yeah.

And until next time.

Thank you.

Bye.