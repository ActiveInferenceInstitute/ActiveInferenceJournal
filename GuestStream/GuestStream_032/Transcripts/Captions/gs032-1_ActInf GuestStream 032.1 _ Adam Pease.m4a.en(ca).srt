1
00:00:12,000 --> 00:00:14,256
DANIEL FRIEDMAN: Hello and welcome. This is ActInf lab

2
00:00:14,288 --> 00:00:18,292
Livestream number 32.1. It's January 10,

3
00:00:18,346 --> 00:00:21,040
2023. We're here with Adam Pease,

4
00:00:21,200 --> 00:00:23,680
and we will be hearing a presentation

5
00:00:23,760 --> 00:00:25,664
followed by a discussion. So Adam,

6
00:00:25,712 --> 00:00:28,596
thank you very much for joining today.

7
00:00:28,778 --> 00:00:31,190
Looking forward to this and off to you.

8
00:00:31,520 --> 00:00:33,868
ADAM PEASE: Okay, thanks very much for having me.

9
00:00:33,954 --> 00:00:37,656
Looking forward to presenting a few bits

10
00:00:37,688 --> 00:00:39,756
of initial research as well as some

11
00:00:39,778 --> 00:00:42,430
background on long term ongoing research

12
00:00:42,880 --> 00:00:46,960
into understanding language and trying

13
00:00:47,030 --> 00:00:50,144
to mimic some just some elements of

14
00:00:50,182 --> 00:00:53,072
human thought. Everything I do is open

15
00:00:53,126 --> 00:00:55,456
source. So I've got some links for you

16
00:00:55,478 --> 00:00:57,900
there. I also have a pretty active

17
00:00:57,980 --> 00:00:59,268
YouTube channel, although it's been a

18
00:00:59,274 --> 00:01:01,828
little quiet lately, so there's a lot of

19
00:01:01,834 --> 00:01:03,844
material here that I won't be able to go

20
00:01:03,882 --> 00:01:07,812
into in depth and so eager to answer

21
00:01:07,946 --> 00:01:09,460
questions when we get to the question

22
00:01:09,530 --> 00:01:11,524
period. And also would encourage folks

23
00:01:11,572 --> 00:01:13,144
to take a look at that channel where

24
00:01:13,182 --> 00:01:16,132
there's longer video format

25
00:01:16,196 --> 00:01:18,056
presentations about a whole host of

26
00:01:18,078 --> 00:01:20,264
topics that we'll probably touch on

27
00:01:20,302 --> 00:01:24,156
today. So I have a large

28
00:01:24,258 --> 00:01:27,356
ontology. I'll explain in a minute what

29
00:01:27,378 --> 00:01:29,884
I mean by an ontology. That's called

30
00:01:29,922 --> 00:01:33,180
sumo. And I'm also going to

31
00:01:33,250 --> 00:01:35,856
coherence some work that Facebook has

32
00:01:35,878 --> 00:01:38,636
done called their baby corpus. So that's

33
00:01:38,668 --> 00:01:41,036
the background for the cartoons that I'm

34
00:01:41,068 --> 00:01:44,624
showing you. The main

35
00:01:44,662 --> 00:01:46,940
topic that I want to cover today is the

36
00:01:46,950 --> 00:01:48,656
notion of common sense auto

37
00:01:48,688 --> 00:01:51,156
communication. My objective is to be

38
00:01:51,178 --> 00:01:54,704
able to make statements in human natural

39
00:01:54,752 --> 00:01:56,950
language, just in English at the moment,

40
00:01:58,380 --> 00:02:00,948
ask questions also in natural language

41
00:02:01,044 --> 00:02:03,912
and get answers, but get answers with

42
00:02:03,966 --> 00:02:06,772
exploration, something that Modern

43
00:02:06,836 --> 00:02:09,944
question answering systems that we hear

44
00:02:09,982 --> 00:02:12,764
about each day in the popular press are

45
00:02:12,802 --> 00:02:15,516
generally not capable of doing. You

46
00:02:15,538 --> 00:02:17,004
might get an answer, but you don't know

47
00:02:17,042 --> 00:02:20,616
why, and knowing why and understanding

48
00:02:20,648 --> 00:02:23,070
an explanation is very important.

49
00:02:24,240 --> 00:02:25,840
So we're not talking about just

50
00:02:25,910 --> 00:02:27,424
information retrieval, we're not talking

51
00:02:27,462 --> 00:02:29,216
about Google, where you ask a question

52
00:02:29,318 --> 00:02:32,464
and you get a list of documents in which

53
00:02:32,502 --> 00:02:34,880
there might be an answer or even

54
00:02:34,950 --> 00:02:37,664
Google's occasional capabilities for

55
00:02:37,702 --> 00:02:39,936
very specific sorts of questions where

56
00:02:39,958 --> 00:02:41,248
they give you an answer but they'll

57
00:02:41,264 --> 00:02:43,204
never tell you why. It's more like you

58
00:02:43,242 --> 00:02:45,156
ask, what's the weather Coda? You get a

59
00:02:45,178 --> 00:02:47,556
nice concise link to the weather, but

60
00:02:47,578 --> 00:02:49,528
you won't get an explanation for why the

61
00:02:49,534 --> 00:02:51,050
weather is what it is.

62
00:02:54,460 --> 00:02:56,504
So what do I mean by biology? Are you

63
00:02:56,542 --> 00:02:58,664
meaning to share? We see the first

64
00:02:58,702 --> 00:03:01,096
slide. You're still only seeing the

65
00:03:01,118 --> 00:03:03,208
first slide. Okay, I'm on slide three.

66
00:03:03,294 --> 00:03:05,724
So let's go back to I'm not sure why

67
00:03:05,762 --> 00:03:08,990
that's not showing up, but good.

68
00:03:09,360 --> 00:03:11,048
It looks good. Now, common sense auto

69
00:03:11,064 --> 00:03:12,908
format, this format then instead of the

70
00:03:12,914 --> 00:03:14,876
slide presentation format. Thank you.

71
00:03:14,898 --> 00:03:17,136
It looks good. Okay, so here's what I

72
00:03:17,158 --> 00:03:20,672
just talked about. So let me give you my

73
00:03:20,726 --> 00:03:23,468
definition for what is an biology,

74
00:03:23,564 --> 00:03:25,152
because this is a word that at a certain

75
00:03:25,206 --> 00:03:27,900
point in recent history, maybe about a

76
00:03:27,910 --> 00:03:30,196
decade or two ago, got overloaded so

77
00:03:30,218 --> 00:03:31,956
much now that just about anything is

78
00:03:31,978 --> 00:03:34,804
called an ontology. And so for me to

79
00:03:34,842 --> 00:03:37,284
distinguish ontology from things we

80
00:03:37,322 --> 00:03:39,924
already had words for, like semantic

81
00:03:39,972 --> 00:03:43,288
network or schema, I consider an

82
00:03:43,294 --> 00:03:45,380
ontology to be essentially a dictionary

83
00:03:45,460 --> 00:03:48,600
for computer to read. And that also

84
00:03:48,670 --> 00:03:51,256
requires a bit of unpacking. What is a

85
00:03:51,278 --> 00:03:53,464
dictionary for computers to read? Well,

86
00:03:53,502 --> 00:03:55,916
for me, it means minimally. We've got to

87
00:03:55,938 --> 00:03:59,224
have terms, a set of terms that label

88
00:03:59,272 --> 00:04:00,604
things in our world. But most

89
00:04:00,642 --> 00:04:02,204
importantly, we have to have a set of

90
00:04:02,242 --> 00:04:04,816
definitions that are stated in a

91
00:04:04,838 --> 00:04:07,212
computable language. So just stating

92
00:04:07,276 --> 00:04:10,176
things in English or French that are

93
00:04:10,198 --> 00:04:11,568
definitions for words, well, that's a

94
00:04:11,574 --> 00:04:14,912
dictionary. It's not an ontology. And if

95
00:04:14,966 --> 00:04:18,244
we don't have definitions in some sort

96
00:04:18,282 --> 00:04:20,416
of mathematical language, a programming

97
00:04:20,448 --> 00:04:23,440
language of some sort, then our machines

98
00:04:23,520 --> 00:04:25,440
are only going to have the barest

99
00:04:25,520 --> 00:04:28,804
abilities to manipulate or do things

100
00:04:29,002 --> 00:04:31,580
with those natural language definitions.

101
00:04:31,600 --> 00:04:33,540
So I think they have to be in a formal

102
00:04:33,700 --> 00:04:35,768
language to nail down meanings so that

103
00:04:35,774 --> 00:04:37,796
we have shared meaning. We have shared

104
00:04:37,828 --> 00:04:41,244
meaning between people that agree to use

105
00:04:41,282 --> 00:04:43,964
a particular ontology. And maybe more

106
00:04:44,002 --> 00:04:45,336
importantly, we have shared meaning

107
00:04:45,368 --> 00:04:48,524
between people and computers so that the

108
00:04:48,562 --> 00:04:51,784
same constraints, the same inferences

109
00:04:51,912 --> 00:04:54,704
that people would be able to make with

110
00:04:54,742 --> 00:04:57,824
these terms, the computer is also able

111
00:04:57,862 --> 00:05:00,252
to make because of these mathematically

112
00:05:00,316 --> 00:05:02,048
expressed definitions. So that's what

113
00:05:02,054 --> 00:05:05,520
I've spent the last 22 years trying

114
00:05:05,590 --> 00:05:09,504
to build up. And this is work that draws

115
00:05:09,552 --> 00:05:11,780
on linguistics, philosophy, and computer

116
00:05:11,850 --> 00:05:15,156
science, as well as logic as a

117
00:05:15,178 --> 00:05:18,132
subdiscipline of probably all of those

118
00:05:18,186 --> 00:05:22,120
three. And one reason

119
00:05:22,190 --> 00:05:25,524
I'm doing this. Nowadays, artificial

120
00:05:25,572 --> 00:05:27,400
intelligence has become almost

121
00:05:27,470 --> 00:05:29,816
synonymous with machine learning. So I

122
00:05:29,838 --> 00:05:32,664
need to explain a little bit, well, why

123
00:05:32,702 --> 00:05:34,444
am I doing this? This is sort of old

124
00:05:34,482 --> 00:05:36,636
fashioned AI of writing down lots of

125
00:05:36,658 --> 00:05:39,004
rules. Why do we still need to do this?

126
00:05:39,202 --> 00:05:41,576
Well, I'm a big fan of Daniel Kahneman's

127
00:05:41,608 --> 00:05:44,444
work. This is just one justification of

128
00:05:44,482 --> 00:05:46,592
many. But hopefully, because it's very

129
00:05:46,646 --> 00:05:50,364
well articulated in his work, hopefully

130
00:05:50,412 --> 00:05:52,016
this can be at least the start of a

131
00:05:52,038 --> 00:05:53,616
justification for some of you who might

132
00:05:53,638 --> 00:05:56,524
be unfamiliar with this symbolic

133
00:05:56,572 --> 00:05:58,512
approach that used to be the primary

134
00:05:58,576 --> 00:06:01,764
approach in artificial intelligence. I

135
00:06:01,802 --> 00:06:04,052
think that he makes a good case that

136
00:06:04,106 --> 00:06:06,004
humans have two modes of thought. We

137
00:06:06,042 --> 00:06:08,492
have an instinctive, intuitive,

138
00:06:08,576 --> 00:06:10,664
sensory, pattern matching kind of

139
00:06:10,702 --> 00:06:13,284
process that's good for face or voice

140
00:06:13,332 --> 00:06:16,116
recognition or making a very snap

141
00:06:16,148 --> 00:06:18,488
judgment about what to do in a

142
00:06:18,494 --> 00:06:22,264
particular situation that is learned

143
00:06:22,312 --> 00:06:25,100
from the presentation of many, many

144
00:06:25,170 --> 00:06:28,124
similar situations. And that sort of

145
00:06:28,162 --> 00:06:30,412
mode of thought fits very well with

146
00:06:30,466 --> 00:06:32,268
statistically based machine learning,

147
00:06:32,354 --> 00:06:33,948
neural networks, deep neural networks

148
00:06:33,964 --> 00:06:35,744
and so forth. That's an important part

149
00:06:35,782 --> 00:06:37,616
of intelligence, and it's led to a lot

150
00:06:37,638 --> 00:06:40,400
of important commercial activities.

151
00:06:40,980 --> 00:06:42,576
But there is another mode of

152
00:06:42,598 --> 00:06:46,008
intelligence that Professor Cunningman,

153
00:06:46,204 --> 00:06:48,964
I think illustrates quite clearly. That

154
00:06:49,002 --> 00:06:51,300
is a slower, more deliberative,

155
00:06:51,640 --> 00:06:54,724
deductive approach where people can

156
00:06:54,762 --> 00:06:56,884
explain what they do as opposed to just

157
00:06:56,922 --> 00:07:00,628
give a reaction. And it seems like in

158
00:07:00,714 --> 00:07:02,616
large parts of the AI community people

159
00:07:02,638 --> 00:07:04,312
are starting to recognize that, yes,

160
00:07:04,366 --> 00:07:07,544
there is still this set of things that

161
00:07:07,582 --> 00:07:09,656
we require our computers to do that

162
00:07:09,678 --> 00:07:12,924
they're not doing very well with the

163
00:07:12,962 --> 00:07:16,696
current neural

164
00:07:16,728 --> 00:07:17,500
approach,

165
00:07:19,840 --> 00:07:22,460
numeric approach that we need another

166
00:07:22,530 --> 00:07:26,476
mode of tool set for. And so you're

167
00:07:26,508 --> 00:07:28,172
starting to see this keyword

168
00:07:28,236 --> 00:07:31,344
neurosymbolic approach of trying to

169
00:07:31,382 --> 00:07:34,272
balance statistical machine learning

170
00:07:34,326 --> 00:07:36,812
approaches with some sort of explicit

171
00:07:36,876 --> 00:07:39,776
representation in a symbolic form. And

172
00:07:39,798 --> 00:07:41,236
it's this latter bit that I've been

173
00:07:41,258 --> 00:07:42,564
doing a lot of work with and I think

174
00:07:42,602 --> 00:07:45,492
it's the combination of these two main

175
00:07:45,546 --> 00:07:47,764
approaches that's going to lead us to

176
00:07:47,802 --> 00:07:49,716
some more exciting capability. That's

177
00:07:49,748 --> 00:07:52,408
just my assessment of the state of the

178
00:07:52,414 --> 00:07:54,756
field. But there is some emerging

179
00:07:54,788 --> 00:07:56,872
evidence that this in fact is the case,

180
00:07:56,926 --> 00:08:00,488
that we have a potential with

181
00:08:00,574 --> 00:08:02,556
integrating these two approaches to

182
00:08:02,578 --> 00:08:05,100
handle a broader range of things that

183
00:08:05,170 --> 00:08:08,300
would look more like human intelligence.

184
00:08:11,200 --> 00:08:15,260
Along with this grand goal of doing AI,

185
00:08:16,000 --> 00:08:19,976
I've also been applying this work in

186
00:08:20,018 --> 00:08:23,392
creating this large dictionary to some

187
00:08:23,446 --> 00:08:25,964
far more prosaic stuff in data

188
00:08:26,022 --> 00:08:28,272
integration. The bulk of the commercial

189
00:08:28,336 --> 00:08:30,228
consulting work that I've been doing

190
00:08:30,314 --> 00:08:33,652
really over the past ten years is just

191
00:08:33,706 --> 00:08:35,904
looking at a software engineering

192
00:08:35,952 --> 00:08:38,968
methodology of trying to capture the

193
00:08:39,054 --> 00:08:42,392
formal meaning of things that we use in

194
00:08:42,446 --> 00:08:44,724
computer science databases,

195
00:08:44,852 --> 00:08:47,448
spreadsheets and so forth. Anytime you

196
00:08:47,454 --> 00:08:49,304
have a spreadsheet, you usually have a

197
00:08:49,422 --> 00:08:51,836
set of columns across the top of your

198
00:08:51,858 --> 00:08:54,510
spreadsheet that has some labels. And

199
00:08:54,960 --> 00:08:58,172
it's very unusual for people to have any

200
00:08:58,226 --> 00:09:01,212
sort of explicit definitions of what

201
00:09:01,266 --> 00:09:04,780
those labels actually mean. It's usually

202
00:09:04,850 --> 00:09:07,456
just assumed that people, by looking at

203
00:09:07,478 --> 00:09:09,232
those labels, if you're in the same

204
00:09:09,286 --> 00:09:11,424
community or you can ask for an

205
00:09:11,462 --> 00:09:14,080
explanation that gives you a good sense

206
00:09:14,150 --> 00:09:18,032
of what's the intended semantics of

207
00:09:18,086 --> 00:09:20,212
that particular column based on that

208
00:09:20,266 --> 00:09:22,932
particular label. And what I've found is

209
00:09:22,986 --> 00:09:25,616
that it might work for a spreadsheet

210
00:09:25,648 --> 00:09:27,476
where you've got a few dozen columns and

211
00:09:27,498 --> 00:09:29,944
you're working closely with some

212
00:09:29,982 --> 00:09:32,296
longtime colleagues. But as soon as you

213
00:09:32,318 --> 00:09:35,336
get to a larger organization with a

214
00:09:35,358 --> 00:09:39,032
larger set of symbols, labels where

215
00:09:39,086 --> 00:09:40,392
people may be working at different

216
00:09:40,446 --> 00:09:42,364
locations maybe they've never even met

217
00:09:42,402 --> 00:09:45,944
each other. Where there's interactions

218
00:09:45,992 --> 00:09:48,076
occurring over the space of years in

219
00:09:48,098 --> 00:09:50,652
large multinational corporations, that

220
00:09:50,706 --> 00:09:52,604
people's initial assumptions about how

221
00:09:52,642 --> 00:09:54,688
clear their labels are are usually

222
00:09:54,774 --> 00:09:57,344
completely wrong. And so people wind up

223
00:09:57,382 --> 00:09:59,392
using data in dramatically different

224
00:09:59,446 --> 00:10:01,676
ways inconsistent with its original

225
00:10:01,708 --> 00:10:04,272
intent, precisely because nobody's taken

226
00:10:04,326 --> 00:10:07,276
the time to actually define things and

227
00:10:07,318 --> 00:10:08,836
Beren. In the rare cases of

228
00:10:08,858 --> 00:10:10,372
organizations that do have data

229
00:10:10,426 --> 00:10:12,772
dictionaries that define their terms,

230
00:10:12,826 --> 00:10:14,548
the intended meaning of their terms,

231
00:10:14,714 --> 00:10:18,052
they tend to define them in very

232
00:10:18,106 --> 00:10:20,404
informal ways using natural language

233
00:10:20,452 --> 00:10:22,056
definitions, which means then that the

234
00:10:22,078 --> 00:10:24,040
machines can do very little to help

235
00:10:24,110 --> 00:10:27,284
ensure that people's intended

236
00:10:27,412 --> 00:10:30,564
specification of semantics is consistent

237
00:10:30,612 --> 00:10:33,804
across a large body of terms. We might

238
00:10:33,842 --> 00:10:35,932
be able to have a human being keep a

239
00:10:36,066 --> 00:10:38,744
data dictionary of 100 terms consistent

240
00:10:38,792 --> 00:10:41,916
and well organized over time, over a

241
00:10:41,938 --> 00:10:44,192
long period of time. But once you get to

242
00:10:44,246 --> 00:10:46,128
thousands or tens of thousands of terms

243
00:10:46,214 --> 00:10:48,544
it's well beyond human capacity to keep

244
00:10:48,582 --> 00:10:50,944
such a product consistent you need

245
00:10:50,982 --> 00:10:53,376
automation. And unless you have

246
00:10:53,558 --> 00:10:57,088
definitions that are explicit and in a

247
00:10:57,094 --> 00:10:59,284
computable language, the computer can do

248
00:10:59,322 --> 00:11:01,092
very little to help keep those

249
00:11:01,146 --> 00:11:03,348
definitions consistent. So that's one of

250
00:11:03,354 --> 00:11:05,332
the big byproducts of all of this work

251
00:11:05,386 --> 00:11:07,444
so far. And I use techniques like

252
00:11:07,482 --> 00:11:09,488
automated theoremproving that I don't

253
00:11:09,504 --> 00:11:11,096
have time to talk about now but would

254
00:11:11,118 --> 00:11:13,048
love to talk about it in detail for

255
00:11:13,054 --> 00:11:15,496
anyone who's interested to keep these

256
00:11:15,598 --> 00:11:18,216
definitions consistent. So I have a

257
00:11:18,238 --> 00:11:21,308
logical approach for the semantics of

258
00:11:21,314 --> 00:11:24,632
terms, lexical semantics, the semantics

259
00:11:24,696 --> 00:11:26,904
of the words we use. And this extends

260
00:11:26,952 --> 00:11:30,220
also to computer science controls like

261
00:11:30,290 --> 00:11:34,130
labels for tables or columns or

262
00:11:34,980 --> 00:11:37,120
database elements and so forth.

263
00:11:38,900 --> 00:11:41,424
And this is useful anywhere. Pretty much

264
00:11:41,462 --> 00:11:43,088
anyone has a spreadsheet, anyone has a

265
00:11:43,094 --> 00:11:46,820
database. This is something

266
00:11:46,970 --> 00:11:50,390
that people don't realize they could

267
00:11:51,000 --> 00:11:54,230
make use of. People seem to accept that

268
00:11:54,600 --> 00:11:56,116
they're going to need to have a lot of

269
00:11:56,138 --> 00:11:59,236
human communication to explain the

270
00:11:59,258 --> 00:12:01,444
meanings of terms. And there's just

271
00:12:01,482 --> 00:12:04,148
another way, right? And that's what I've

272
00:12:04,164 --> 00:12:05,588
developed and that's what I'm basing

273
00:12:05,604 --> 00:12:07,850
this work on language understanding on.

274
00:12:08,460 --> 00:12:10,856
There's a common belief that oh, this is

275
00:12:10,878 --> 00:12:14,156
just too hard, that we should be able

276
00:12:14,178 --> 00:12:15,912
to come up with these things easily.

277
00:12:15,976 --> 00:12:17,752
There's too much of them, meanings

278
00:12:17,816 --> 00:12:21,724
change and so forth. Once you take

279
00:12:21,762 --> 00:12:25,970
the perspective that there is a need for

280
00:12:27,300 --> 00:12:29,904
precise semantics for our labels and

281
00:12:29,942 --> 00:12:33,280
that this precise semantics is something

282
00:12:33,350 --> 00:12:36,276
like definition in the dictionary but in

283
00:12:36,298 --> 00:12:39,456
a formal language then it's

284
00:12:39,488 --> 00:12:42,004
not just a sort of a graph or a list of

285
00:12:42,042 --> 00:12:44,596
relationships or likelihoods or

286
00:12:44,778 --> 00:12:45,860
probabilities.

287
00:12:47,960 --> 00:12:50,768
It starts to be hard to imagine then how

288
00:12:50,794 --> 00:12:52,376
a machine would just come up with this

289
00:12:52,398 --> 00:12:54,328
sort of thing automatically. And of

290
00:12:54,334 --> 00:12:57,688
course we have another venue in which

291
00:12:57,854 --> 00:13:00,264
we take this sort of harder approach of

292
00:13:00,302 --> 00:13:02,156
programming and don't expect machines to

293
00:13:02,178 --> 00:13:03,916
just do everything automatically and

294
00:13:03,938 --> 00:13:06,860
that's programming. We have many, many

295
00:13:06,930 --> 00:13:08,732
millions of programmers in the world

296
00:13:08,786 --> 00:13:12,524
now. They're expensive. It is a time

297
00:13:12,562 --> 00:13:15,616
consuming process to program things but

298
00:13:15,638 --> 00:13:17,276
we invest in this because there simply

299
00:13:17,308 --> 00:13:20,592
isn't another way to do it. And we make

300
00:13:20,646 --> 00:13:24,160
this enterprise of programming feasible

301
00:13:24,500 --> 00:13:26,770
through a couple of points.

302
00:13:27,300 --> 00:13:29,856
One is having very rich languages so we

303
00:13:29,878 --> 00:13:31,652
can say everything that we want to say.

304
00:13:31,706 --> 00:13:33,556
So we don't want to be restricted in the

305
00:13:33,578 --> 00:13:35,012
sort of programs we can write.

306
00:13:35,066 --> 00:13:36,448
Similarly, we need to make sure we're

307
00:13:36,464 --> 00:13:38,164
not restricted in the sorts of

308
00:13:38,202 --> 00:13:40,856
definitions that we can write. And the

309
00:13:40,878 --> 00:13:42,584
way that we make that practical is

310
00:13:42,622 --> 00:13:44,244
through reuse. You're a Modern

311
00:13:44,292 --> 00:13:46,264
programmer. If you deliver some

312
00:13:46,302 --> 00:13:49,576
software, you're writing maybe 1% of

313
00:13:49,598 --> 00:13:52,056
the program, 1% of the code that's

314
00:13:52,088 --> 00:13:54,444
delivered. Most of what you deliver is

315
00:13:54,482 --> 00:13:56,444
going to be a set of large libraries and

316
00:13:56,482 --> 00:13:58,828
reusable components, operating system,

317
00:13:58,914 --> 00:14:02,664
database, web server

318
00:14:02,712 --> 00:14:04,716
and any number of other things, java

319
00:14:04,748 --> 00:14:07,740
collection classes, NumPy libraries,

320
00:14:07,820 --> 00:14:10,912
if you're doing Python. The way in which

321
00:14:10,966 --> 00:14:13,004
Modern software development is practical

322
00:14:13,052 --> 00:14:15,376
is through reuse. And so that's the

323
00:14:15,398 --> 00:14:17,104
other thing that I've been working to

324
00:14:17,142 --> 00:14:19,104
provide is this thing called sumo,

325
00:14:19,152 --> 00:14:21,476
which is a library of distinctions that

326
00:14:21,498 --> 00:14:23,732
can be reused that takes this problem

327
00:14:23,786 --> 00:14:25,472
that many people would otherwise

328
00:14:25,536 --> 00:14:27,568
consider to be completely intractable

329
00:14:27,664 --> 00:14:29,784
manual creation of knowledge and makes

330
00:14:29,822 --> 00:14:31,316
it eminently practical because you're

331
00:14:31,348 --> 00:14:33,492
actually reusing most of your semantics

332
00:14:33,556 --> 00:14:35,640
by virtue of using this library.

333
00:14:37,500 --> 00:14:40,916
So this sumo like sumo wrestler

334
00:14:40,948 --> 00:14:43,192
suggested upper emerged ontology started

335
00:14:43,246 --> 00:14:45,964
in the year 2000. It started as just and

336
00:14:46,002 --> 00:14:48,796
upper ontology. So the acronym is a bit

337
00:14:48,818 --> 00:14:51,276
of a misnomer, a bit of anachronism, if

338
00:14:51,298 --> 00:14:53,788
you will, right now, that it's really a

339
00:14:53,794 --> 00:14:55,516
comprehensive ontology, not just an

340
00:14:55,538 --> 00:14:57,248
upper ontology because it's crowned to

341
00:14:57,254 --> 00:15:00,336
be about 20,000 terms, 80,000

342
00:15:00,518 --> 00:15:03,212
handwritten statements in an expressive

343
00:15:03,276 --> 00:15:05,440
higher order. Mathematical logic

344
00:15:05,800 --> 00:15:09,204
includes links to vast fact bases like

345
00:15:09,242 --> 00:15:12,368
the Yago system, lots of translations

346
00:15:12,464 --> 00:15:14,708
from its authored format into some of

347
00:15:14,714 --> 00:15:17,188
the standard representations used in the

348
00:15:17,194 --> 00:15:20,104
automated theorem proven community. And

349
00:15:20,142 --> 00:15:21,976
as I mentioned, it's all open source and

350
00:15:21,998 --> 00:15:23,736
online and to every version has been

351
00:15:23,758 --> 00:15:25,236
open source. There's nothing that's held

352
00:15:25,268 --> 00:15:26,920
back for commercial reasons.

353
00:15:29,660 --> 00:15:32,348
Let me mention WordNet. So another

354
00:15:32,434 --> 00:15:35,244
common misconception in ontology is that

355
00:15:35,282 --> 00:15:37,868
we have to use words and follow the

356
00:15:37,874 --> 00:15:40,284
definitions of words. And as we should

357
00:15:40,322 --> 00:15:43,320
all know, words are ambiguous and words

358
00:15:43,410 --> 00:15:45,584
are polysimous. The same word can have

359
00:15:45,622 --> 00:15:48,832
multiple meanings. So we've created a

360
00:15:48,886 --> 00:15:52,032
very clear division, but also

361
00:15:52,086 --> 00:15:55,932
a relationship between the senses,

362
00:15:55,996 --> 00:15:58,340
the concepts that we have in the world

363
00:15:58,410 --> 00:16:00,164
that have formal definitions and the

364
00:16:00,202 --> 00:16:02,772
labels that we as humans put on those

365
00:16:02,826 --> 00:16:05,796
concepts to communicate them to each

366
00:16:05,818 --> 00:16:09,752
other. And this also makes it easy to

367
00:16:09,806 --> 00:16:12,696
ensure that our ontology is not tied to

368
00:16:12,718 --> 00:16:15,784
any particular one language because any

369
00:16:15,822 --> 00:16:19,784
one of us who's multilingual knows an

370
00:16:19,822 --> 00:16:23,644
English word and a tagalog word

371
00:16:23,842 --> 00:16:26,632
can have the same underlying semantics,

372
00:16:26,696 --> 00:16:28,620
the same underlying real world

373
00:16:28,690 --> 00:16:31,512
coherence, but we use different labels.

374
00:16:31,576 --> 00:16:33,276
And so we need to make sure that we can

375
00:16:33,298 --> 00:16:36,448
have vocabularies that are mapped to our

376
00:16:36,534 --> 00:16:39,804
common single formal ontology that tries

377
00:16:39,852 --> 00:16:42,704
to explain and define concepts in our

378
00:16:42,742 --> 00:16:45,344
world and not let sort of language and

379
00:16:45,382 --> 00:16:47,964
labels and intuitions about those labels

380
00:16:48,012 --> 00:16:50,484
creep into our formal definition. So we

381
00:16:50,522 --> 00:16:52,868
reuse Princeton's Word Net, which is a

382
00:16:52,874 --> 00:16:55,124
project going on for about 30 years now,

383
00:16:55,162 --> 00:16:57,904
I think. And it has also projections

384
00:16:57,952 --> 00:17:00,132
into multiple languages, polish Word Net

385
00:17:00,186 --> 00:17:03,876
toggleordnet for example. There's

386
00:17:03,908 --> 00:17:06,664
continuing work on that which I'm very

387
00:17:06,702 --> 00:17:08,596
excited because I started the tagalog

388
00:17:08,628 --> 00:17:12,216
Word net back in the De

389
00:17:12,238 --> 00:17:14,556
La Salle University and so it's great to

390
00:17:14,578 --> 00:17:17,496
see that sort of effort continuing.

391
00:17:17,688 --> 00:17:20,504
There's word Nets for Arabic and Chinese

392
00:17:20,552 --> 00:17:23,052
and many other languages and so we keep

393
00:17:23,106 --> 00:17:25,440
those labels in English, those

394
00:17:25,510 --> 00:17:27,660
dictionaries human dictionaries,

395
00:17:27,820 --> 00:17:30,972
distinct but related to the formal

396
00:17:31,036 --> 00:17:33,244
inventory of mathematically expressed

397
00:17:33,292 --> 00:17:35,200
concepts. And so back in the early

398
00:17:35,270 --> 00:17:37,668
2000s, we took an effort to go through

399
00:17:37,834 --> 00:17:41,552
all 117,000 sunsets

400
00:17:41,616 --> 00:17:45,600
in WordNet, all 117,000 linguistically

401
00:17:45,680 --> 00:17:48,644
labeled concepts and map them all to

402
00:17:48,682 --> 00:17:51,304
Sumo one at a time by hand. It's just an

403
00:17:51,342 --> 00:17:54,104
enormous effort where we couldn't have

404
00:17:54,142 --> 00:17:55,784
really done it automatically. It

405
00:17:55,822 --> 00:17:58,356
required human inspection. We invested

406
00:17:58,388 --> 00:18:00,696
that effort and it since paid off for

407
00:18:00,718 --> 00:18:02,364
the linguistic work that we do with this

408
00:18:02,402 --> 00:18:05,660
ontology. Why do we need both?

409
00:18:05,730 --> 00:18:08,524
Well, the formal definitions are things

410
00:18:08,562 --> 00:18:10,684
that just aren't in WordNet or any other

411
00:18:10,722 --> 00:18:13,900
dictionary. You might have a word for

412
00:18:13,970 --> 00:18:16,124
earlier and a natural language

413
00:18:16,172 --> 00:18:18,224
definition for what it means for some

414
00:18:18,262 --> 00:18:20,496
events to be earlier than another. But

415
00:18:20,518 --> 00:18:23,052
we need a precise mathematical logical

416
00:18:23,116 --> 00:18:25,792
definition of what earlier means. And so

417
00:18:25,846 --> 00:18:29,572
sumo has this and many, many other

418
00:18:29,706 --> 00:18:32,644
axioms that individually are trivial but

419
00:18:32,682 --> 00:18:35,460
together add up to creating a certain

420
00:18:35,530 --> 00:18:37,364
understanding about the world that

421
00:18:37,402 --> 00:18:39,640
without it, machines just don't have.

422
00:18:39,710 --> 00:18:42,424
We need a machine to know that if one

423
00:18:42,462 --> 00:18:45,912
event is earlier than another, that the

424
00:18:46,046 --> 00:18:49,576
end point of this first

425
00:18:49,678 --> 00:18:53,064
event is before the beginning point of

426
00:18:53,102 --> 00:18:55,944
the second event. So we've got a formal

427
00:18:55,992 --> 00:18:57,996
mathematical definition of earlier which

428
00:18:58,018 --> 00:18:59,736
you just don't have in a dictionary.

429
00:18:59,848 --> 00:19:03,260
This allows machine to do logic

430
00:19:03,760 --> 00:19:06,864
inference, automated inference, and give

431
00:19:06,902 --> 00:19:08,672
you conclusions and explain those

432
00:19:08,726 --> 00:19:11,132
conclusions. Not a criticism of WordNet,

433
00:19:11,196 --> 00:19:12,416
just they're different products with

434
00:19:12,438 --> 00:19:14,130
different needs and we need both.

435
00:19:15,700 --> 00:19:19,012
Also, I get a lot of questions about

436
00:19:19,066 --> 00:19:21,924
what kind of logic do we need? Do we

437
00:19:21,962 --> 00:19:23,680
really need a very complicated

438
00:19:23,760 --> 00:19:26,736
expressive logic? It's very popular

439
00:19:26,848 --> 00:19:29,652
nowadays for people to use taxonomies or

440
00:19:29,706 --> 00:19:32,228
knowledge graphs. Well, knowledge graphs

441
00:19:32,244 --> 00:19:34,196
are essentially semantic networks. It's

442
00:19:34,228 --> 00:19:35,784
a knowledge representation that was

443
00:19:35,822 --> 00:19:39,256
created back really in the 1960s. And so

444
00:19:39,278 --> 00:19:41,396
it does surprise me that it's kind of

445
00:19:41,518 --> 00:19:43,464
what's old is new again in artificial

446
00:19:43,512 --> 00:19:45,544
intelligence somehow and that knowledge

447
00:19:45,592 --> 00:19:48,972
graphs are a big thing now. But it's a

448
00:19:49,026 --> 00:19:51,612
knowledge representation technology that

449
00:19:51,666 --> 00:19:54,652
leaves out a lot of stuff that we would

450
00:19:54,706 --> 00:19:56,976
need to say about the real world in

451
00:19:56,998 --> 00:19:59,696
order to define the terms that we use.

452
00:19:59,878 --> 00:20:02,476
So natural language definitions aren't

453
00:20:02,508 --> 00:20:05,264
enough and we believe that defining our

454
00:20:05,302 --> 00:20:06,852
terms or our concepts is good. Which

455
00:20:06,906 --> 00:20:10,004
particular language do we choose? And

456
00:20:10,042 --> 00:20:13,444
I've had people often say usually really

457
00:20:13,482 --> 00:20:15,956
without any backup. Oh, those are the

458
00:20:15,978 --> 00:20:18,856
rare cases. Well, I got frustrated with

459
00:20:18,878 --> 00:20:22,040
that. So I did a paper recently,

460
00:20:23,260 --> 00:20:26,904
now almost two years old, about trying

461
00:20:26,942 --> 00:20:29,400
to quantify how often do we use

462
00:20:29,470 --> 00:20:31,864
constructs in language that require more

463
00:20:31,902 --> 00:20:34,280
than just a graph of relationships.

464
00:20:35,600 --> 00:20:38,140
And so I came up with some statistics.

465
00:20:38,480 --> 00:20:40,396
I'm not going to go into this paper in

466
00:20:40,418 --> 00:20:42,156
great detail, but if you're interested,

467
00:20:42,258 --> 00:20:44,588
I'd love to follow up with you. And I

468
00:20:44,594 --> 00:20:48,412
came up with that in looking at two

469
00:20:48,466 --> 00:20:51,056
large corporate brown. Corpus is kind of

470
00:20:51,078 --> 00:20:52,556
old and kind of small by Modern

471
00:20:52,588 --> 00:20:54,896
standards, but I also used the Corpus of

472
00:20:54,918 --> 00:20:56,548
Contemporary American English, took a

473
00:20:56,554 --> 00:20:59,556
random sample of sentences, created an

474
00:20:59,578 --> 00:21:01,524
automated system for looking at some

475
00:21:01,562 --> 00:21:03,844
various features that require in

476
00:21:03,882 --> 00:21:06,436
language a translation into using an

477
00:21:06,458 --> 00:21:08,396
expressive logic, such as modal

478
00:21:08,448 --> 00:21:11,770
expressions, can, may, should, might,

479
00:21:12,220 --> 00:21:16,280
expressions of authorship said wrote

480
00:21:16,860 --> 00:21:20,280
Epistemic. Nose believes these

481
00:21:20,350 --> 00:21:23,384
are words in language that trigger the

482
00:21:23,422 --> 00:21:25,172
need for a more expressive

483
00:21:25,236 --> 00:21:27,436
representation. I can give you a lot of

484
00:21:27,458 --> 00:21:30,300
detail on why that's directly entailed.

485
00:21:31,120 --> 00:21:33,148
This is not just my opinion trying to

486
00:21:33,234 --> 00:21:35,756
advocate a more expressive logic. These

487
00:21:35,778 --> 00:21:37,296
are very sort of strict things that are

488
00:21:37,318 --> 00:21:39,616
well known in linguistics, but at least

489
00:21:39,638 --> 00:21:42,768
now it's well quantified that about 50%

490
00:21:42,854 --> 00:21:45,196
of statements taken from a random sample

491
00:21:45,228 --> 00:21:47,404
of a large corpus do actually require

492
00:21:47,452 --> 00:21:50,096
these more expressive semantics. So I

493
00:21:50,118 --> 00:21:52,196
think I've made a strong case that we

494
00:21:52,218 --> 00:21:54,224
can't just get away with graphs unless

495
00:21:54,272 --> 00:21:55,956
we want to leave out about half of the

496
00:21:55,978 --> 00:21:58,288
things that people say to each other.

497
00:21:58,394 --> 00:22:00,456
And that tells me that we really need

498
00:22:00,478 --> 00:22:02,360
this as more expressive logic.

499
00:22:04,620 --> 00:22:07,784
Okay, so that's all the pre gamble that

500
00:22:07,822 --> 00:22:11,936
was the library of semantics, of meaning

501
00:22:11,988 --> 00:22:14,684
that I already have, and how can I use

502
00:22:14,722 --> 00:22:18,636
that now to try to create a system? And

503
00:22:18,658 --> 00:22:20,616
this is research, right? And it's

504
00:22:20,728 --> 00:22:22,508
relatively experimental even at the

505
00:22:22,514 --> 00:22:26,192
moment. The attempt is

506
00:22:26,326 --> 00:22:28,656
to try to create a system where the

507
00:22:28,678 --> 00:22:32,720
machine can translate automatically from

508
00:22:32,790 --> 00:22:35,800
English sentences into a formal,

509
00:22:35,900 --> 00:22:39,204
precise semantics using these terms out

510
00:22:39,242 --> 00:22:41,156
of the ontology that themselves are

511
00:22:41,178 --> 00:22:45,188
precisely defined. So I have at

512
00:22:45,194 --> 00:22:48,292
the starting point English statements or

513
00:22:48,346 --> 00:22:51,096
questions. I translate these things to

514
00:22:51,118 --> 00:22:53,512
logic. I want to be able to send them to

515
00:22:53,646 --> 00:22:56,136
a powerful theorem prover that's at

516
00:22:56,158 --> 00:22:58,676
least first order logic plus equality,

517
00:22:58,868 --> 00:23:01,228
but preferably higher order logic. So I

518
00:23:01,234 --> 00:23:02,376
can handle some of these modal

519
00:23:02,408 --> 00:23:03,932
expressions. There are a few such

520
00:23:03,986 --> 00:23:07,084
provers, and I want it

521
00:23:07,122 --> 00:23:10,972
to engage in its process of doing

522
00:23:11,026 --> 00:23:14,060
theorem proving, not only with the

523
00:23:14,130 --> 00:23:16,288
statements and the question that a

524
00:23:16,294 --> 00:23:18,304
particular user has provided at one

525
00:23:18,342 --> 00:23:20,864
time, but also this rich background that

526
00:23:20,902 --> 00:23:23,100
describes the world. So that the machine

527
00:23:23,260 --> 00:23:26,240
is not just doing a sort of simple

528
00:23:26,310 --> 00:23:28,768
matching even with these powerful tools,

529
00:23:28,784 --> 00:23:30,820
but it's really taking into account

530
00:23:30,970 --> 00:23:33,140
background knowledge, world knowledge,

531
00:23:33,560 --> 00:23:36,372
in the same way that a person would.

532
00:23:36,506 --> 00:23:38,324
And then when it's done, when it's got

533
00:23:38,362 --> 00:23:39,876
an answer, I want it to be able to

534
00:23:39,898 --> 00:23:41,420
explain what it does. And theorem

535
00:23:41,440 --> 00:23:43,800
provers have this capability already.

536
00:23:43,870 --> 00:23:46,344
It's built in. They were designed to

537
00:23:46,382 --> 00:23:48,584
provide proofs because a lot of the work

538
00:23:48,622 --> 00:23:51,728
in theran proving is for theoremproving

539
00:23:51,764 --> 00:23:54,844
in advanced mathematics. So there's a

540
00:23:54,882 --> 00:23:57,612
quiet but significant community of

541
00:23:57,666 --> 00:24:00,200
mathematicians and computer scientists

542
00:24:00,360 --> 00:24:02,984
that are using automated theoremproving

543
00:24:03,112 --> 00:24:06,296
to prove novel theorems in mathematics.

544
00:24:06,328 --> 00:24:08,108
And because they're in mathematics,

545
00:24:08,124 --> 00:24:10,912
they have a very strict standard of what

546
00:24:10,966 --> 00:24:13,056
constitutes a real work. You have to

547
00:24:13,078 --> 00:24:15,312
show a proof, just like almost all of us

548
00:24:15,366 --> 00:24:17,684
probably experienced in high school

549
00:24:17,722 --> 00:24:20,388
geometry of proving. One triangle is the

550
00:24:20,394 --> 00:24:22,132
same as another through maybe the side

551
00:24:22,186 --> 00:24:25,396
angle, side process. Machines can

552
00:24:25,418 --> 00:24:28,380
now do this and much more significant

553
00:24:28,480 --> 00:24:30,788
and complicated and sophisticated sorts

554
00:24:30,804 --> 00:24:34,564
of proofs and provide detailed breakdown

555
00:24:34,692 --> 00:24:38,024
of how it reached its conclusion. And I

556
00:24:38,062 --> 00:24:39,604
take this as to being something that's

557
00:24:39,652 --> 00:24:42,010
required. If you ask another person,

558
00:24:42,540 --> 00:24:45,304
what's the answer to question X? Okay,

559
00:24:45,342 --> 00:24:47,836
they give you Y as an answer, but then

560
00:24:47,858 --> 00:24:49,816
you want to know, what's the details?

561
00:24:49,848 --> 00:24:51,256
How did you come to that conclusion?

562
00:24:51,288 --> 00:24:52,956
It's not just enough to say, Well, I

563
00:24:52,978 --> 00:24:54,860
told you so, so believe me, sometimes

564
00:24:54,930 --> 00:24:56,416
you might get away with that, but not

565
00:24:56,438 --> 00:24:58,176
all the time, especially not for

566
00:24:58,198 --> 00:25:00,688
anything that's complicated. And so our

567
00:25:00,694 --> 00:25:02,016
machines should be able to do that as

568
00:25:02,038 --> 00:25:05,440
well. So I've done

569
00:25:05,510 --> 00:25:08,168
a number of forays into this grand goal

570
00:25:08,204 --> 00:25:10,052
over the course of my career. I started

571
00:25:10,106 --> 00:25:11,664
out with something called Controller

572
00:25:11,712 --> 00:25:13,956
English to Logic Translation, where it

573
00:25:13,978 --> 00:25:16,948
had a hand built grammar of a small

574
00:25:17,034 --> 00:25:19,688
subset of English that was designed to

575
00:25:19,694 --> 00:25:21,816
be unambiguous. It was all written in

576
00:25:21,838 --> 00:25:24,376
prologue and I was able to create

577
00:25:24,478 --> 00:25:28,008
expressions using Sumo terms in its

578
00:25:28,174 --> 00:25:30,232
logic, which was mostly first order

579
00:25:30,286 --> 00:25:31,976
logic back then in the early two

580
00:25:31,998 --> 00:25:34,392
thousands. And it was, you know,

581
00:25:34,446 --> 00:25:37,116
somewhat somewhat successful. But it was

582
00:25:37,138 --> 00:25:39,064
a fairly restricted subset of English.

583
00:25:39,112 --> 00:25:40,732
And so the parser would break and say

584
00:25:40,786 --> 00:25:43,036
syntax error all too often. And that was

585
00:25:43,058 --> 00:25:46,304
kind of frustrating. It was sort of like

586
00:25:46,422 --> 00:25:48,624
what one experiences today with

587
00:25:48,662 --> 00:25:51,904
something like Alexa or Google where

588
00:25:51,942 --> 00:25:53,680
you ask a question and says, I'm sorry,

589
00:25:53,750 --> 00:25:55,984
I don't understand. And so people wind

590
00:25:56,022 --> 00:26:00,230
up self governing their

591
00:26:00,600 --> 00:26:03,476
utterances to adapt to the machine. And

592
00:26:03,498 --> 00:26:05,712
people were able to do that with my Kelt

593
00:26:05,776 --> 00:26:07,508
system. But it's still kind of

594
00:26:07,514 --> 00:26:08,808
frustrating. I'd like to be able to

595
00:26:08,814 --> 00:26:12,120
handle text that was written not for

596
00:26:12,190 --> 00:26:14,964
that particular system and not dumbed

597
00:26:15,012 --> 00:26:17,960
down on the fly by a human, but rather

598
00:26:18,030 --> 00:26:21,372
any arbitrary sort of text. So then I

599
00:26:21,426 --> 00:26:24,584
started working with Stanford's core NLP

600
00:26:24,632 --> 00:26:27,420
system and using dependency parse

601
00:26:28,000 --> 00:26:30,412
transformations and trying to turn

602
00:26:30,466 --> 00:26:33,416
dependency parses into logic. I did have

603
00:26:33,458 --> 00:26:36,176
some success with that, but I found that

604
00:26:36,278 --> 00:26:40,048
even as good as machine learning based

605
00:26:40,134 --> 00:26:43,088
statistical parsers are, there's still a

606
00:26:43,094 --> 00:26:45,376
lot of cases where they break down. In

607
00:26:45,398 --> 00:26:48,724
fact, they give a lot of

608
00:26:48,762 --> 00:26:50,880
metrics that look very encouraging,

609
00:26:50,960 --> 00:26:53,824
usually on a per word or per symbol

610
00:26:53,872 --> 00:26:57,556
basis, and they'll say, or we're 97%

611
00:26:57,658 --> 00:27:00,692
correct on. And unlabeled attachment

612
00:27:00,756 --> 00:27:02,296
score is one that's used in the

613
00:27:02,318 --> 00:27:05,064
dependency parsing community. And that

614
00:27:05,102 --> 00:27:07,928
sounds like a very high percentage, but

615
00:27:08,094 --> 00:27:11,304
your average sentence in English is

616
00:27:11,422 --> 00:27:13,196
depending upon, you know, who you talk

617
00:27:13,218 --> 00:27:16,424
to, how you collect the statistics,

618
00:27:16,472 --> 00:27:20,510
about 24 words. Well, if you look at

619
00:27:21,200 --> 00:27:24,830
97% raised to the 24th power,

620
00:27:25,520 --> 00:27:27,952
then you get a problem and you get

621
00:27:28,006 --> 00:27:30,924
actually less than 50% of your sentences

622
00:27:31,052 --> 00:27:32,688
are going to be parsed correctly. And

623
00:27:32,694 --> 00:27:34,828
again, that's unlabeled attachment score

624
00:27:34,924 --> 00:27:36,704
for dependency parses. That merely means

625
00:27:36,742 --> 00:27:38,448
that two words are found to have the

626
00:27:38,454 --> 00:27:41,268
same dependency relation without a

627
00:27:41,274 --> 00:27:43,232
commitment to what exactly that relation

628
00:27:43,296 --> 00:27:45,136
is. Well, you need the labeled

629
00:27:45,168 --> 00:27:46,644
attachment score, which of course is

630
00:27:46,682 --> 00:27:48,644
lower. And you needed to be correct for

631
00:27:48,682 --> 00:27:50,536
all of these words to have really a

632
00:27:50,558 --> 00:27:53,016
coherent understanding of a sentence if

633
00:27:53,038 --> 00:27:54,612
you're going to do any sort of automatic

634
00:27:54,676 --> 00:27:58,084
translation. So, although the systems

635
00:27:58,132 --> 00:27:59,796
are good and they've certainly gotten

636
00:27:59,828 --> 00:28:02,488
better from 2015, I mean, Stanford

637
00:28:02,504 --> 00:28:05,944
Stanza is yet another few percentage

638
00:28:05,992 --> 00:28:08,284
points better than core NLP was in terms

639
00:28:08,322 --> 00:28:10,488
of its dependency parsing, but it's

640
00:28:10,504 --> 00:28:12,572
still not reliable enough, not

641
00:28:12,626 --> 00:28:15,680
consistent, not stable enough for me to

642
00:28:15,750 --> 00:28:18,892
use that as a basis for translation.

643
00:28:18,956 --> 00:28:20,656
And then there was all the problem of,

644
00:28:20,678 --> 00:28:24,240
well, how do I actually take that

645
00:28:24,310 --> 00:28:27,136
output and reliably create logic from

646
00:28:27,158 --> 00:28:28,976
it? And that meant at that time I was

647
00:28:28,998 --> 00:28:31,076
doing a handbuilt rule base and that

648
00:28:31,098 --> 00:28:33,060
just didn't work in the limit. It was

649
00:28:33,130 --> 00:28:34,544
encouraging. I think there's potential

650
00:28:34,592 --> 00:28:36,260
if you had enough people working on it,

651
00:28:36,330 --> 00:28:38,676
a bit more research. But it wasn't the

652
00:28:38,698 --> 00:28:40,152
way in which I thought I could reach

653
00:28:40,206 --> 00:28:42,472
success. So I'm doing something

654
00:28:42,526 --> 00:28:46,376
different now. So I'm doing what

655
00:28:46,398 --> 00:28:49,796
I guess is more prevalent now in machine

656
00:28:49,828 --> 00:28:51,436
learning that instead of doing a

657
00:28:51,458 --> 00:28:53,320
pipeline of machine learning operations

658
00:28:53,400 --> 00:28:55,404
trying to do everything all at once with

659
00:28:55,442 --> 00:28:58,540
extraordinarily large corporate where I

660
00:28:58,610 --> 00:29:02,172
have trying to brain a system to do

661
00:29:02,226 --> 00:29:04,444
auto formalization of language to go

662
00:29:04,482 --> 00:29:06,752
straight from language to logic without

663
00:29:06,806 --> 00:29:08,544
any intermediate approach like

664
00:29:08,582 --> 00:29:11,232
dependency parsing. And this is based on

665
00:29:11,286 --> 00:29:13,612
some of the success with my colleague

666
00:29:13,676 --> 00:29:16,196
Joseph Urban who's been doing this sort

667
00:29:16,218 --> 00:29:19,764
of work for mathematics. So one of the

668
00:29:19,802 --> 00:29:23,552
challenges of using theorem provers,

669
00:29:23,616 --> 00:29:24,916
automated theorem provers for

670
00:29:24,938 --> 00:29:26,724
mathematics is that as formal as

671
00:29:26,762 --> 00:29:29,252
mathematics is, it's not really quite

672
00:29:29,306 --> 00:29:32,004
formal enough in a mathematics textbook.

673
00:29:32,052 --> 00:29:34,356
There's still a lot of text and there's

674
00:29:34,388 --> 00:29:35,732
still a lot of things that aren't

675
00:29:35,796 --> 00:29:38,376
themselves precisely defined. And

676
00:29:38,398 --> 00:29:40,536
there's also a lot of stuff there in

677
00:29:40,558 --> 00:29:42,636
mathematics that's not in a common and

678
00:29:42,658 --> 00:29:45,132
computable format. So for a long time

679
00:29:45,186 --> 00:29:47,276
there's been this problem of how do we

680
00:29:47,298 --> 00:29:49,660
take mathematical textbooks and turn

681
00:29:49,730 --> 00:29:52,392
them into extraordinarily detailed

682
00:29:52,456 --> 00:29:54,716
formalizations that an automated theorem

683
00:29:54,748 --> 00:29:57,164
prover can handle in first order logic

684
00:29:57,212 --> 00:29:59,376
plus equality or some other kind of

685
00:29:59,478 --> 00:30:02,960
mathematical logic. So Joseph has had

686
00:30:03,030 --> 00:30:05,456
considerable success at this and we

687
00:30:05,478 --> 00:30:08,596
decided to team up on trying to do this

688
00:30:08,618 --> 00:30:10,964
even harder problem of just looking at

689
00:30:11,002 --> 00:30:13,780
unrestricted text, not just mathematics.

690
00:30:15,000 --> 00:30:18,176
And they've been using Google's Neural

691
00:30:18,208 --> 00:30:20,196
machine translation system, which is

692
00:30:20,218 --> 00:30:22,548
built on top of TensorFlow. We're at the

693
00:30:22,554 --> 00:30:24,952
moment using kind of a relatively old

694
00:30:25,006 --> 00:30:26,468
version of that. We tried a newer

695
00:30:26,484 --> 00:30:28,056
version. It turned out to actually be

696
00:30:28,078 --> 00:30:30,648
slower for our purposes, but we need to

697
00:30:30,654 --> 00:30:33,896
do a lot more expectation and make

698
00:30:33,918 --> 00:30:35,836
this work more popular so people tell us

699
00:30:35,858 --> 00:30:37,084
where we're going wrong and maybe

700
00:30:37,122 --> 00:30:38,748
there's some better machine learning

701
00:30:38,834 --> 00:30:40,910
libraries that we could use for this.

702
00:30:41,920 --> 00:30:44,496
So this is the architectures. Now I want

703
00:30:44,518 --> 00:30:47,424
to tell you a bit more about how we

704
00:30:47,462 --> 00:30:49,968
actually come up with this set of

705
00:30:50,054 --> 00:30:52,336
natural language logic pairs. Because

706
00:30:52,518 --> 00:30:55,792
like other work of this sort, the

707
00:30:55,846 --> 00:30:59,048
libraries of pairs, of your input output

708
00:30:59,084 --> 00:31:01,556
pairs that you're trying to train has to

709
00:31:01,578 --> 00:31:04,976
be really big orders of magnitude bigger

710
00:31:05,008 --> 00:31:06,784
than any sort of pipeline approach

711
00:31:06,832 --> 00:31:08,148
because you're trying to tackle the

712
00:31:08,154 --> 00:31:09,768
whole problem and to end. And there's a

713
00:31:09,774 --> 00:31:12,052
lot more variability. Your statistical

714
00:31:12,116 --> 00:31:14,072
significance for the appearance of any

715
00:31:14,126 --> 00:31:16,744
given feature correlated with any other

716
00:31:16,782 --> 00:31:20,010
given feature is really low.

717
00:31:20,380 --> 00:31:23,016
He has a very long tail in language of

718
00:31:23,038 --> 00:31:25,116
things that are not seen too often. So

719
00:31:25,138 --> 00:31:27,228
your corpus has to be very big. How do

720
00:31:27,234 --> 00:31:29,244
we get that? Corpus certainly not

721
00:31:29,282 --> 00:31:32,264
feasible to translate a lot of English

722
00:31:32,312 --> 00:31:34,784
by hand Hinton logic. So how do we get

723
00:31:34,822 --> 00:31:38,976
this thing to begin with? So we

724
00:31:38,998 --> 00:31:42,192
were aware of this project done at

725
00:31:42,246 --> 00:31:45,040
Facebook called the Baby Corpus, in part

726
00:31:45,110 --> 00:31:48,256
because Tomash Micheloff has returned to

727
00:31:48,278 --> 00:31:49,904
his home country of the Czech Republic

728
00:31:49,952 --> 00:31:52,496
and now works with Joseph Urban at CTU

729
00:31:52,528 --> 00:31:55,524
Prague. So we had benefit of getting

730
00:31:55,562 --> 00:31:57,750
some of his perspective on this work.

731
00:31:58,120 --> 00:32:00,484
It was basically an effort to try to

732
00:32:00,522 --> 00:32:02,680
teach machines how to do simple

733
00:32:02,750 --> 00:32:04,776
inferences and we'll look at some of

734
00:32:04,798 --> 00:32:06,600
those simple inferences in a moment.

735
00:32:06,750 --> 00:32:09,608
And in order to do that, they tried to

736
00:32:09,774 --> 00:32:12,652
generative a very large synthetic data

737
00:32:12,706 --> 00:32:16,136
set of simple natural

738
00:32:16,168 --> 00:32:18,856
language sentences and simple natural

739
00:32:18,888 --> 00:32:21,068
language inferences that they wanted the

740
00:32:21,074 --> 00:32:23,116
machines to be able to train up to

741
00:32:23,138 --> 00:32:23,820
handle.

742
00:32:26,580 --> 00:32:28,800
Ultimately they used really only a few

743
00:32:28,870 --> 00:32:32,210
sort of rules or patterns. I think

744
00:32:32,580 --> 00:32:34,176
Tomash has said there's something like

745
00:32:34,198 --> 00:32:35,616
20 different patterns. I've looked at

746
00:32:35,638 --> 00:32:38,336
the code, it's written in lieu. It

747
00:32:38,358 --> 00:32:40,356
wouldn't be hard to rewrite it in a sort

748
00:32:40,378 --> 00:32:43,456
of more common language. I think it's

749
00:32:43,488 --> 00:32:45,348
not particularly complicated code, not a

750
00:32:45,354 --> 00:32:47,204
huge code base, a lot of simple

751
00:32:47,242 --> 00:32:49,496
patterns, a great idea, but I think we

752
00:32:49,518 --> 00:32:52,548
can do better at it given the resources

753
00:32:52,644 --> 00:32:55,976
that Sumo provides for generation as

754
00:32:55,998 --> 00:32:57,716
well as understanding and anchoring

755
00:32:57,748 --> 00:33:01,276
meaning. So they had a lot of their

756
00:33:01,298 --> 00:33:03,292
knowledge representation, such as it is,

757
00:33:03,346 --> 00:33:05,692
was things like, you know, you have a

758
00:33:05,746 --> 00:33:09,128
bedroom, a thing, the location actors

759
00:33:09,304 --> 00:33:12,744
existing in this world. It sort of harks

760
00:33:12,792 --> 00:33:17,448
back to the blocks world of Patrick

761
00:33:17,464 --> 00:33:20,836
Henry Winston, I think it was Winston

762
00:33:20,888 --> 00:33:22,432
Hope. I've got that reference right now.

763
00:33:22,486 --> 00:33:24,796
Back in the 70s there was this notion

764
00:33:24,828 --> 00:33:27,984
that we could do there's a system called

765
00:33:28,102 --> 00:33:30,692
Shirley, I think it was, that did

766
00:33:30,746 --> 00:33:32,676
operations in a world of blocks, so a

767
00:33:32,698 --> 00:33:34,224
constrained world. There were actors,

768
00:33:34,272 --> 00:33:35,876
there were a few things that could be

769
00:33:35,898 --> 00:33:39,524
manipulated and the system was able to

770
00:33:39,562 --> 00:33:41,136
understand very simple utterances.

771
00:33:41,168 --> 00:33:42,424
Well, they've kind of turned this on its

772
00:33:42,462 --> 00:33:44,548
head, created a knowledge representation

773
00:33:44,644 --> 00:33:46,888
for a certain world and then tried to

774
00:33:46,894 --> 00:33:48,616
generate a lot of sentences from it to

775
00:33:48,638 --> 00:33:51,288
create this synthetic model of things

776
00:33:51,374 --> 00:33:54,044
that a machine should be able to do

777
00:33:54,082 --> 00:33:57,708
coherence about. So here's some of

778
00:33:57,714 --> 00:33:59,704
the content of their questions. So Free

779
00:33:59,752 --> 00:34:02,216
is either in the school or the park mary

780
00:34:02,248 --> 00:34:04,016
went back to. The office. Is Mary in the

781
00:34:04,038 --> 00:34:05,616
office? So the first sentence is just a

782
00:34:05,638 --> 00:34:09,090
confusion element of

783
00:34:09,620 --> 00:34:11,984
the corpus. It's really if Mary went

784
00:34:12,022 --> 00:34:13,776
back to the office, yes, she's in the

785
00:34:13,798 --> 00:34:17,088
office. Bill is either in the kitchen or

786
00:34:17,094 --> 00:34:18,524
the park. Another confusion sentence

787
00:34:18,572 --> 00:34:20,276
fred moved to the cinema. Is Fred in the

788
00:34:20,298 --> 00:34:22,336
park? Well, no, he's not in the park,

789
00:34:22,368 --> 00:34:25,876
but park has Beren seen as a

790
00:34:25,978 --> 00:34:28,596
token earlier and so they wanted to make

791
00:34:28,618 --> 00:34:31,032
sure that the automated learning system

792
00:34:31,086 --> 00:34:34,132
isn't just trying to find proximity,

793
00:34:34,276 --> 00:34:36,088
which is a good thing to include in

794
00:34:36,094 --> 00:34:39,464
their data set. So lots of stuff like

795
00:34:39,502 --> 00:34:42,296
this and more complicated things. Also

796
00:34:42,398 --> 00:34:43,788
I've just presented really some of the

797
00:34:43,794 --> 00:34:46,232
most simple examples but all generated

798
00:34:46,296 --> 00:34:48,284
from a very simple knowledge model,

799
00:34:48,482 --> 00:34:51,772
concepts that weren't really defined and

800
00:34:51,906 --> 00:34:55,884
a massive presentation of mind numbingly

801
00:34:55,932 --> 00:34:59,504
tiny variations and a wide variety of

802
00:34:59,622 --> 00:35:02,976
sentences. So we started out

803
00:35:02,998 --> 00:35:04,976
thinking well, let's just cover the

804
00:35:04,998 --> 00:35:06,736
stuff that's in the baby corpus so we

805
00:35:06,758 --> 00:35:08,976
understand what they were doing. And the

806
00:35:08,998 --> 00:35:10,516
big advantage that we thought we could

807
00:35:10,538 --> 00:35:12,820
bring to this is we don't have to learn

808
00:35:12,890 --> 00:35:16,592
logic in a way they had a simple corpus

809
00:35:16,736 --> 00:35:18,612
that was trying to accomplish something

810
00:35:18,666 --> 00:35:21,128
that's very hard, which was to teach

811
00:35:21,214 --> 00:35:24,004
machines just through massive examples

812
00:35:24,132 --> 00:35:26,136
how to do logical inferences or a

813
00:35:26,158 --> 00:35:28,244
certain subset of logical inferences.

814
00:35:28,372 --> 00:35:30,408
We have an easier problem if we use a

815
00:35:30,414 --> 00:35:32,270
theorem proof. We don't have to teach

816
00:35:32,640 --> 00:35:35,676
the system to do logical inference, we

817
00:35:35,698 --> 00:35:38,780
already have that. We just need to get

818
00:35:38,850 --> 00:35:41,340
the knowledge representation from

819
00:35:41,410 --> 00:35:43,728
English into logic and then let the

820
00:35:43,734 --> 00:35:45,570
theorem provers do their thing.

821
00:35:47,380 --> 00:35:49,888
So again, very simple world. They had

822
00:35:49,974 --> 00:35:52,720
objects, locations, actors, states,

823
00:35:52,870 --> 00:35:56,908
ActInf lab, few other decorations and

824
00:35:56,934 --> 00:35:59,044
so we tried to figure out really what

825
00:35:59,082 --> 00:36:01,524
they meant in a way that was hard

826
00:36:01,722 --> 00:36:03,552
because they didn't have a distinction

827
00:36:03,616 --> 00:36:06,640
between instances and classes.

828
00:36:06,800 --> 00:36:09,920
So we can talk about in sumo

829
00:36:10,000 --> 00:36:12,448
relationship that in an action one thing

830
00:36:12,474 --> 00:36:14,504
is an object transferred from one

831
00:36:14,542 --> 00:36:16,616
location to another. They have this

832
00:36:16,638 --> 00:36:18,664
action of being gettable which is really

833
00:36:18,702 --> 00:36:20,888
a modal. So we had to figure out what

834
00:36:20,894 --> 00:36:22,776
did they mean? They didn't really mean a

835
00:36:22,798 --> 00:36:26,024
modal, they meant something that can be

836
00:36:26,062 --> 00:36:27,756
transferred and then there has to be

837
00:36:27,778 --> 00:36:30,524
some kind of transferred examples. We

838
00:36:30,562 --> 00:36:32,540
wound up interpreting a lot of their

839
00:36:32,690 --> 00:36:35,876
symbols not as classes.

840
00:36:35,928 --> 00:36:38,416
So the notion of and apple is a class,

841
00:36:38,598 --> 00:36:41,216
but the apple that gets transferred in a

842
00:36:41,238 --> 00:36:43,024
particular sentence is an instance. So

843
00:36:43,062 --> 00:36:44,784
this difference between existential and

844
00:36:44,822 --> 00:36:46,656
universal quantification so we'd create

845
00:36:46,678 --> 00:36:48,704
a term like apple, one is a kind of

846
00:36:48,742 --> 00:36:51,556
apple is an instance of an apple and

847
00:36:51,578 --> 00:36:53,344
that's a gettable thing and it's located

848
00:36:53,392 --> 00:36:55,268
in the particular area, et cetera. I

849
00:36:55,274 --> 00:36:56,644
don't have a lot of time to go into our

850
00:36:56,682 --> 00:36:58,628
knowledge representation, but if you

851
00:36:58,634 --> 00:37:00,196
want a full course on sumo, I can do

852
00:37:00,218 --> 00:37:01,848
that at some point. There's a lot of

853
00:37:01,854 --> 00:37:04,516
videos online also, so maybe I'll skip

854
00:37:04,548 --> 00:37:06,696
through a little bit of this we wanted

855
00:37:06,718 --> 00:37:09,000
to make sure we covered all of their

856
00:37:09,150 --> 00:37:12,424
stuff. They referred to things like

857
00:37:12,462 --> 00:37:14,264
chocolate and milk and garden and

858
00:37:14,302 --> 00:37:16,444
container and box. And we actually had

859
00:37:16,482 --> 00:37:18,156
all this in sumo. So getting back to

860
00:37:18,178 --> 00:37:20,028
this notion of, well, if you had to

861
00:37:20,034 --> 00:37:21,656
define all this stuff from scratch,

862
00:37:21,688 --> 00:37:23,704
you'd be tempted, just like the Facebook

863
00:37:23,752 --> 00:37:26,168
guys did, to just use the labels and

864
00:37:26,194 --> 00:37:27,936
assume everything, everybody means the

865
00:37:27,958 --> 00:37:30,304
same thing. But we didn't have to do

866
00:37:30,342 --> 00:37:32,608
that. We already had these terms

867
00:37:32,694 --> 00:37:34,428
precisely defined and sumo and we're

868
00:37:34,444 --> 00:37:37,344
able just to reuse them. So we did a big

869
00:37:37,382 --> 00:37:38,996
table, this is just a portion of that

870
00:37:39,018 --> 00:37:41,076
table, all the different things that

871
00:37:41,098 --> 00:37:44,836
they referred to that we already had or

872
00:37:44,858 --> 00:37:46,756
in some a few cases didn't have, and we

873
00:37:46,778 --> 00:37:49,444
needed to add them. But adding the new

874
00:37:49,482 --> 00:37:51,192
concepts and their definitions is easy

875
00:37:51,246 --> 00:37:53,716
because the new concepts had definitions

876
00:37:53,748 --> 00:37:55,720
that were based on, in turn, other terms

877
00:37:55,790 --> 00:37:57,928
we already had. So we just had to

878
00:37:57,934 --> 00:37:59,450
combine them in the right ways.

879
00:38:03,340 --> 00:38:06,636
We didn't take for granted that we

880
00:38:06,658 --> 00:38:08,236
were just using the first meaning of

881
00:38:08,258 --> 00:38:09,644
things. For example, they had the word

882
00:38:09,682 --> 00:38:11,656
pajamas in some of their database.

883
00:38:11,688 --> 00:38:13,960
While pajamas have a couple of meanings

884
00:38:14,040 --> 00:38:16,524
in the dictionary, I wasn't all that

885
00:38:16,562 --> 00:38:18,288
familiar with the second meaning, but it

886
00:38:18,294 --> 00:38:20,208
does exist, and so we want to make sure

887
00:38:20,294 --> 00:38:21,936
we're using the right meaning. So we

888
00:38:21,958 --> 00:38:24,256
also did mappings to word net of the

889
00:38:24,278 --> 00:38:26,516
terms we defined so that we had

890
00:38:26,538 --> 00:38:28,676
disambiguation potential force, our

891
00:38:28,698 --> 00:38:32,004
natural language. There were a number

892
00:38:32,042 --> 00:38:34,356
of things because of this small and

893
00:38:34,378 --> 00:38:37,440
artificial world, they had inferences

894
00:38:37,520 --> 00:38:40,560
like if you're hungry, then essentially

895
00:38:40,640 --> 00:38:42,184
you go to the kitchen and eat something

896
00:38:42,222 --> 00:38:44,116
that's in the kitchen that doesn't

897
00:38:44,148 --> 00:38:45,480
really hold in the real world.

898
00:38:45,550 --> 00:38:48,292
Obviously we're not in this fantasy

899
00:38:48,436 --> 00:38:50,564
constrained world that hunger

900
00:38:50,612 --> 00:38:52,088
immediately entails. You go to the

901
00:38:52,094 --> 00:38:53,660
kitchen and eat an apple.

902
00:38:55,200 --> 00:38:57,036
So we had to create some kind of some

903
00:38:57,058 --> 00:38:59,644
bogus rules in Sumo that were very

904
00:38:59,682 --> 00:39:01,916
specific just to this corpus to try to

905
00:39:01,938 --> 00:39:03,596
replicate the inferences that they were

906
00:39:03,618 --> 00:39:06,968
doing. So here's the

907
00:39:06,994 --> 00:39:09,792
rule that gives the right answer for

908
00:39:09,846 --> 00:39:12,304
this corpus. It gets a little

909
00:39:12,342 --> 00:39:13,984
complicated to state it, but we can

910
00:39:14,022 --> 00:39:15,728
state it in sumo that if you have a

911
00:39:15,734 --> 00:39:18,016
cognitive agent that's hungry and that's

912
00:39:18,048 --> 00:39:20,756
ant a particular time, then there's a

913
00:39:20,778 --> 00:39:24,608
translocation event that is desired

914
00:39:24,704 --> 00:39:28,084
by that agent and that translocation has

915
00:39:28,122 --> 00:39:29,944
a destination of the kitchen where

916
00:39:29,982 --> 00:39:31,880
there's a getting of an apple.

917
00:39:33,100 --> 00:39:35,880
A rule that doesn't belong to be in sumo

918
00:39:36,540 --> 00:39:39,156
on any permanent basis, but is what's

919
00:39:39,188 --> 00:39:41,592
used to cover the semantics of this

920
00:39:41,646 --> 00:39:44,408
particular corpus. And we looked at

921
00:39:44,414 --> 00:39:45,812
things like being bored and tired,

922
00:39:45,876 --> 00:39:47,368
which they had. They all say, if you're

923
00:39:47,384 --> 00:39:49,470
bored and tired, you go to sleep. Okay.

924
00:39:49,840 --> 00:39:52,044
I wish that that were true for all of us

925
00:39:52,082 --> 00:39:53,804
hardworking engineers that we had that

926
00:39:53,842 --> 00:39:56,368
option. We don't at all times, but that

927
00:39:56,454 --> 00:39:57,968
was what covered the semantics of the

928
00:39:57,974 --> 00:39:59,904
corpus. So you had to do similar things

929
00:39:59,942 --> 00:40:03,696
for Board and Tired. They don't really

930
00:40:03,718 --> 00:40:06,276
have weights and measures and units in

931
00:40:06,298 --> 00:40:09,524
the baby ontology. Sumo of course, has a

932
00:40:09,562 --> 00:40:11,876
detailed ontology of weights and

933
00:40:11,898 --> 00:40:13,428
measures of units, all the system

934
00:40:13,514 --> 00:40:17,270
inclination measures and

935
00:40:17,640 --> 00:40:19,108
we had to figure out how we were going

936
00:40:19,114 --> 00:40:21,416
to translate these hacks that were in

937
00:40:21,438 --> 00:40:24,436
this corpus of things have a numerical

938
00:40:24,468 --> 00:40:26,424
size, one, two or three, something like

939
00:40:26,462 --> 00:40:28,564
that. How are we going to represent

940
00:40:28,612 --> 00:40:30,944
that? So we figured out a similar hack

941
00:40:31,012 --> 00:40:34,044
for covering that. All right,

942
00:40:34,082 --> 00:40:37,324
so we did this exploration to make

943
00:40:37,362 --> 00:40:40,380
sure that we could cover one of these

944
00:40:40,450 --> 00:40:42,748
examples worlds. But what we really want

945
00:40:42,754 --> 00:40:45,132
to do is generate a much larger corpus

946
00:40:45,196 --> 00:40:47,292
with a more interesting, more varied

947
00:40:47,356 --> 00:40:49,776
Seth of things that are referred to in

948
00:40:49,798 --> 00:40:54,544
the real world. So we wanted to do a

949
00:40:54,582 --> 00:40:56,944
synthetic text generation as our first

950
00:40:56,982 --> 00:40:59,196
step so that we COVID kind of seed the

951
00:40:59,238 --> 00:41:02,196
system long term. We know that we need

952
00:41:02,218 --> 00:41:04,528
to go beyond that synthetic test. We're

953
00:41:04,544 --> 00:41:06,948
not there yet. We're just still in the

954
00:41:07,034 --> 00:41:09,656
process of creating this very large set

955
00:41:09,678 --> 00:41:12,312
of synthetic sentences because we can

956
00:41:12,366 --> 00:41:14,596
start with an idea or a knowledge

957
00:41:14,628 --> 00:41:16,936
representation about what we want to

958
00:41:16,958 --> 00:41:19,480
express in the world and generate

959
00:41:20,620 --> 00:41:22,964
syntactically and semantically valid

960
00:41:23,012 --> 00:41:24,668
logic expressions from that. While at

961
00:41:24,674 --> 00:41:27,836
the same time, because we've created the

962
00:41:27,858 --> 00:41:29,788
state of the world artificially in a

963
00:41:29,794 --> 00:41:31,596
program, we can then also create a

964
00:41:31,618 --> 00:41:33,228
sentence that models that state of the

965
00:41:33,234 --> 00:41:35,316
world. So we go kind of both directions,

966
00:41:35,368 --> 00:41:37,872
both to logic and language from a very

967
00:41:37,926 --> 00:41:41,116
ad hoc sort of expression in some Java

968
00:41:41,148 --> 00:41:43,424
code about what's true in the real

969
00:41:43,462 --> 00:41:46,256
world. And that allows us to do a lot of

970
00:41:46,278 --> 00:41:49,620
variation, but it's never going to cover

971
00:41:49,690 --> 00:41:51,616
the full expressivity of natural

972
00:41:51,648 --> 00:41:53,092
language. But we think it will cover

973
00:41:53,226 --> 00:41:55,972
enough that it gives us a head start

974
00:41:56,026 --> 00:41:57,812
where we can then start saying, well,

975
00:41:57,866 --> 00:42:01,256
where does our automatic language to

976
00:42:01,278 --> 00:42:03,128
logic system break down? What are the

977
00:42:03,134 --> 00:42:04,856
sentences? Where it fails? Where it

978
00:42:04,878 --> 00:42:06,152
generates something that's not even

979
00:42:06,206 --> 00:42:08,344
syntactically correct? Maybe. Or

980
00:42:08,382 --> 00:42:11,080
violates constraints that we know from

981
00:42:11,150 --> 00:42:14,044
Sumo about how the world works and then

982
00:42:14,082 --> 00:42:16,364
try to add those as new patterns to our

983
00:42:16,402 --> 00:42:18,444
generation system so we can find one

984
00:42:18,482 --> 00:42:21,964
sentence that causes a problem. We look

985
00:42:22,002 --> 00:42:25,212
at the core issue of what

986
00:42:25,266 --> 00:42:28,976
causes the problem and look at maybe the

987
00:42:28,998 --> 00:42:30,540
things that are variable the sentence.

988
00:42:30,620 --> 00:42:31,788
So we might have a sentence that's

989
00:42:31,804 --> 00:42:34,384
problematic, that has some subject and

990
00:42:34,422 --> 00:42:36,288
an object where the subjects and the

991
00:42:36,294 --> 00:42:38,624
objects have a wide varieties that could

992
00:42:38,742 --> 00:42:41,636
things that could be substituted in that

993
00:42:41,658 --> 00:42:43,396
we can turn into sort of a template to

994
00:42:43,418 --> 00:42:45,796
try to cover another pattern, if you

995
00:42:45,818 --> 00:42:47,428
will, in natural language. And one of

996
00:42:47,434 --> 00:42:49,176
our possibilities, I think, will be to

997
00:42:49,198 --> 00:42:52,296
look at framenet that is exactly such a

998
00:42:52,318 --> 00:42:55,450
large inventory of these things.

999
00:42:55,820 --> 00:42:58,056
I've wanted to do a projection of

1000
00:42:58,078 --> 00:43:01,024
framenet into sumo for several decades

1001
00:43:01,092 --> 00:43:04,796
now. Did some early work with the

1002
00:43:04,818 --> 00:43:08,604
team there, and we published some work

1003
00:43:08,642 --> 00:43:11,320
about that in the mid two thousands,

1004
00:43:11,480 --> 00:43:13,128
but we didn't do a comprehensive

1005
00:43:13,224 --> 00:43:15,392
inventory of all of their different

1006
00:43:15,446 --> 00:43:16,912
frames. And so I think there's a good

1007
00:43:16,966 --> 00:43:21,600
project there to do a more

1008
00:43:21,670 --> 00:43:23,884
detailed exploration of all the frames

1009
00:43:23,932 --> 00:43:26,364
in framenet and translating them to Sumo

1010
00:43:26,412 --> 00:43:27,996
because the frames in framenet don't

1011
00:43:28,028 --> 00:43:30,244
have a precise logical semantics. Just

1012
00:43:30,282 --> 00:43:32,276
one of the challenges I think that

1013
00:43:32,298 --> 00:43:34,260
people have found with using that

1014
00:43:34,330 --> 00:43:36,772
resource. It's not anchored in the same

1015
00:43:36,826 --> 00:43:40,196
way that it needs to be, I think, to be

1016
00:43:40,218 --> 00:43:42,776
used more productively there's. I think

1017
00:43:42,798 --> 00:43:44,456
an interesting project there that would

1018
00:43:44,478 --> 00:43:47,656
have a very practical outcome. But for

1019
00:43:47,678 --> 00:43:49,016
now I'm just going to talk about the

1020
00:43:49,038 --> 00:43:50,904
synthetic text because we're not even

1021
00:43:50,942 --> 00:43:53,160
into that phase yet. The synthetic text

1022
00:43:53,230 --> 00:43:55,304
is the tough stuff. We just started this

1023
00:43:55,342 --> 00:43:58,940
work sort of midfall so that

1024
00:43:59,010 --> 00:44:00,684
kind of gives you a perspective on where

1025
00:44:00,722 --> 00:44:02,296
we are. This is going to be a long term

1026
00:44:02,328 --> 00:44:06,012
thing. So I tried to collect

1027
00:44:06,076 --> 00:44:08,704
all of the things that I thought I could

1028
00:44:08,742 --> 00:44:11,324
detail both linguistically and in Sumo.

1029
00:44:11,452 --> 00:44:15,116
So things like propositional attitudes,

1030
00:44:15,228 --> 00:44:18,524
modals tenses names and roles and basic

1031
00:44:18,572 --> 00:44:20,364
forms of transitive, intransitive

1032
00:44:20,412 --> 00:44:23,510
ditransitive verbs in the

1033
00:44:24,040 --> 00:44:27,364
subject verb object, basic grammar of

1034
00:44:27,402 --> 00:44:30,756
English, try to say what some

1035
00:44:30,778 --> 00:44:33,120
of these things are. So I'm going to

1036
00:44:33,130 --> 00:44:35,288
give you an example. It's a real example

1037
00:44:35,374 --> 00:44:37,592
of stuff we can generate and it looks

1038
00:44:37,646 --> 00:44:39,896
kind of funny. And I'll tell you why it

1039
00:44:39,918 --> 00:44:42,472
looks funny and what we can do to fix

1040
00:44:42,526 --> 00:44:45,752
it. And it's other examples like it.

1041
00:44:45,886 --> 00:44:48,012
But I'm giving you words and all of this

1042
00:44:48,066 --> 00:44:51,356
extremely early research even though

1043
00:44:51,378 --> 00:44:53,148
I think it's very promising, I'm going

1044
00:44:53,154 --> 00:44:54,736
to tell you what's wrong so far and the

1045
00:44:54,758 --> 00:44:57,248
examples show stuff that look kind of

1046
00:44:57,254 --> 00:44:59,696
funny. So an internet user traps a

1047
00:44:59,718 --> 00:45:01,244
crustacean. That's a pretty funny

1048
00:45:01,292 --> 00:45:04,144
sentence. It's syntactically, valid and

1049
00:45:04,182 --> 00:45:05,792
I think you can imagine an

1050
00:45:05,846 --> 00:45:07,884
interpretation of that sentence that's

1051
00:45:07,932 --> 00:45:09,868
legitimate in the real world. Okay, I'm

1052
00:45:09,884 --> 00:45:11,508
an internet user and I go down to the

1053
00:45:11,514 --> 00:45:14,068
beach and I catch a crab. You can

1054
00:45:14,074 --> 00:45:15,888
imagine that actually happening, but I'm

1055
00:45:15,904 --> 00:45:17,664
not sure you'd ever find that sentence

1056
00:45:17,712 --> 00:45:20,584
uttered by a person. We think we can do

1057
00:45:20,622 --> 00:45:23,944
better constraining. Ultimately our

1058
00:45:23,982 --> 00:45:26,200
language generative through using large

1059
00:45:26,270 --> 00:45:29,496
language models. It should be in

1060
00:45:29,518 --> 00:45:32,840
principle fairly easy to do so that we

1061
00:45:32,910 --> 00:45:35,292
generate stuff that's just a little bit

1062
00:45:35,346 --> 00:45:37,628
more reasonable, little more common, a

1063
00:45:37,634 --> 00:45:40,076
little more expected. But this is what

1064
00:45:40,098 --> 00:45:41,564
we've got right now because we're just

1065
00:45:41,602 --> 00:45:42,876
creating these templates and we

1066
00:45:42,898 --> 00:45:46,472
substitute in all of the legitimate

1067
00:45:46,536 --> 00:45:48,680
possibilities where legitimate is just

1068
00:45:48,770 --> 00:45:51,760
does it meet syntactic and type

1069
00:45:51,830 --> 00:45:55,552
constraints specified by suma. And so

1070
00:45:55,606 --> 00:45:57,456
it's possible for an interview user to

1071
00:45:57,478 --> 00:45:59,216
trap across station. So we generate this

1072
00:45:59,238 --> 00:46:00,804
sort of thing amongst many other

1073
00:46:00,842 --> 00:46:03,476
possibilities and at the same time we

1074
00:46:03,498 --> 00:46:05,316
generate the logic expression that you

1075
00:46:05,338 --> 00:46:07,616
see on the left. I'm sorry, I'm throwing

1076
00:46:07,648 --> 00:46:10,884
code at you and I don't have the time

1077
00:46:10,922 --> 00:46:13,524
here to go into the full syntax of this

1078
00:46:13,562 --> 00:46:15,704
expression at the moment, this is just

1079
00:46:15,742 --> 00:46:17,256
first order logic. So it's an

1080
00:46:17,278 --> 00:46:19,144
existential quantifier saying there

1081
00:46:19,182 --> 00:46:22,476
exists an internet user, a trapping or

1082
00:46:22,498 --> 00:46:24,636
an ambush is the term that's used in

1083
00:46:24,658 --> 00:46:26,972
Sumo. Again, remember, labels and

1084
00:46:27,026 --> 00:46:29,276
definitions are different. So we used a

1085
00:46:29,298 --> 00:46:32,920
particular software identifier

1086
00:46:33,000 --> 00:46:36,540
of ambush but its definition fits with

1087
00:46:36,610 --> 00:46:38,584
what you would expect of trapping.

1088
00:46:38,712 --> 00:46:40,944
Okay? And just the word that we happen

1089
00:46:40,982 --> 00:46:43,152
to be using in English is trapping. The

1090
00:46:43,206 --> 00:46:45,292
software programming language Identifier

1091
00:46:45,356 --> 00:46:47,376
we're using in the Sumo library is

1092
00:46:47,398 --> 00:46:49,828
ambush. So you shouldn't expect those to

1093
00:46:49,834 --> 00:46:51,492
be identical because we have different

1094
00:46:51,546 --> 00:46:55,092
labels for things that we may have used

1095
00:46:55,146 --> 00:46:57,216
consistently in terms of their formal

1096
00:46:57,248 --> 00:46:59,380
semantics, but their labels may vary.

1097
00:47:00,760 --> 00:47:02,420
So we have an agent that does something,

1098
00:47:02,490 --> 00:47:04,264
the agent is the internet user. The

1099
00:47:04,302 --> 00:47:06,600
object of the action is the crustacean

1100
00:47:07,180 --> 00:47:10,680
and the object of the action is

1101
00:47:10,750 --> 00:47:12,076
something and that something is a

1102
00:47:12,098 --> 00:47:14,280
crustacean. So very simple sentence,

1103
00:47:14,360 --> 00:47:17,036
very simple logic, formalization and so

1104
00:47:17,058 --> 00:47:20,348
we generate tons of sentences like this

1105
00:47:20,514 --> 00:47:23,688
for different objects

1106
00:47:23,864 --> 00:47:25,864
and different agents and different

1107
00:47:25,922 --> 00:47:28,048
actions. This is your most simple

1108
00:47:28,134 --> 00:47:30,848
subject verb object sentence and we have

1109
00:47:30,934 --> 00:47:32,864
lots of different objects that can play

1110
00:47:32,902 --> 00:47:34,784
roles, different agents that can play

1111
00:47:34,822 --> 00:47:36,368
roles and different processes that are

1112
00:47:36,374 --> 00:47:38,164
already defined in Sumo. So we just go

1113
00:47:38,202 --> 00:47:40,372
through the entire inventory and we also

1114
00:47:40,426 --> 00:47:42,244
probabilistically generate them. We look

1115
00:47:42,282 --> 00:47:46,224
at each of these symbols

1116
00:47:46,272 --> 00:47:49,336
in Sumo has a connection to Word net and

1117
00:47:49,358 --> 00:47:52,776
WordNet has word frequencies for each

1118
00:47:52,798 --> 00:47:56,200
of those concepts. So by looking

1119
00:47:56,270 --> 00:47:59,172
into WordNet we can see which concepts,

1120
00:47:59,236 --> 00:48:01,644
formally defined concepts in Sumo are

1121
00:48:01,682 --> 00:48:05,148
more likely to occur in free text

1122
00:48:05,314 --> 00:48:08,808
individually. And so we do prioritize

1123
00:48:08,904 --> 00:48:11,628
our generation on the basis of trying to

1124
00:48:11,714 --> 00:48:15,628
make it more likely using a

1125
00:48:15,714 --> 00:48:17,964
randomizer in Java and then a frequency

1126
00:48:18,012 --> 00:48:20,364
table. We try to make it more likely

1127
00:48:20,412 --> 00:48:22,400
that we generate sentences with things

1128
00:48:22,470 --> 00:48:25,056
that are more commonly seen. But as we

1129
00:48:25,078 --> 00:48:28,116
can see, even though internet user may

1130
00:48:28,138 --> 00:48:31,568
be fairly common in natural

1131
00:48:31,584 --> 00:48:33,956
language text, you wouldn't likely see

1132
00:48:33,978 --> 00:48:35,876
it paired with trapping and or a

1133
00:48:35,898 --> 00:48:38,924
crustacean. And so it's these pairwise

1134
00:48:38,992 --> 00:48:40,916
selectional restrictions that we don't

1135
00:48:40,948 --> 00:48:42,296
have right now, which is why you get

1136
00:48:42,318 --> 00:48:43,720
these funny combinations.

1137
00:48:45,980 --> 00:48:49,416
We can generate time, so we can have

1138
00:48:49,438 --> 00:48:52,036
the internet user trapstation or trap

1139
00:48:52,068 --> 00:48:55,044
expectation or will trap or is trapping

1140
00:48:55,172 --> 00:48:57,592
and its formal temporal logic

1141
00:48:57,656 --> 00:49:00,860
expression. One thing you often find

1142
00:49:00,930 --> 00:49:03,964
in simpler knowledge expressions is

1143
00:49:04,082 --> 00:49:07,180
verbs used as predicates without tense.

1144
00:49:07,340 --> 00:49:09,820
So you might have in a knowledge graph

1145
00:49:09,980 --> 00:49:12,416
internet user a relation trapping or

1146
00:49:12,438 --> 00:49:15,164
traps of some sort and then crustacean,

1147
00:49:15,212 --> 00:49:16,900
right? This would be a more typical

1148
00:49:17,240 --> 00:49:19,536
expression in a graph and that doesn't

1149
00:49:19,568 --> 00:49:21,664
really capture what the entire sentence

1150
00:49:21,712 --> 00:49:24,916
is saying. It says that there is a

1151
00:49:24,938 --> 00:49:27,924
temporal qualification to what is

1152
00:49:27,962 --> 00:49:29,524
happening in the sentence is happening

1153
00:49:29,642 --> 00:49:33,352
now. And so there's a begin fund

1154
00:49:33,406 --> 00:49:35,368
of this activity and an end function of

1155
00:49:35,374 --> 00:49:38,024
this activity and now is between those

1156
00:49:38,062 --> 00:49:40,024
two things. You have a dictic as we say

1157
00:49:40,062 --> 00:49:42,332
in linguistics, something that's being

1158
00:49:42,386 --> 00:49:45,116
referred to that gives semantics to the

1159
00:49:45,138 --> 00:49:48,156
sentence that's only meaningful in the

1160
00:49:48,178 --> 00:49:50,936
context of the speaker and the listener

1161
00:49:51,048 --> 00:49:54,428
here, there now, et cetera. There's a

1162
00:49:54,434 --> 00:49:55,788
lot of these things and we've got to be

1163
00:49:55,794 --> 00:49:57,276
able to handle that in order to capture

1164
00:49:57,308 --> 00:49:58,668
the semantics of the sentence. So it's

1165
00:49:58,684 --> 00:50:00,924
not enough to say there's a trapping

1166
00:50:00,972 --> 00:50:03,088
relation between the internet user and

1167
00:50:03,094 --> 00:50:05,744
the crustacean. We really have to go to

1168
00:50:05,862 --> 00:50:08,476
a temporal modal logic beyond first

1169
00:50:08,518 --> 00:50:10,784
order logic with equality to capture

1170
00:50:10,832 --> 00:50:13,284
this information and capture it in a way

1171
00:50:13,322 --> 00:50:15,716
that's going to work not just now for

1172
00:50:15,738 --> 00:50:17,892
this one isolated case, but for all

1173
00:50:17,946 --> 00:50:20,016
possible cases of these sort of temporal

1174
00:50:20,048 --> 00:50:22,264
expressions. It's also common for people

1175
00:50:22,302 --> 00:50:24,948
that don't have a background in modal

1176
00:50:24,964 --> 00:50:26,964
logic to sort of assume that there's

1177
00:50:27,012 --> 00:50:28,916
some kind of a fudge for this in a graph

1178
00:50:28,948 --> 00:50:31,464
representation. There isn't, right?

1179
00:50:31,582 --> 00:50:33,384
This is why logicians work on this

1180
00:50:33,422 --> 00:50:35,164
stuff. It's hard. Getting it right has

1181
00:50:35,202 --> 00:50:38,076
taken many, many decades of effort and

1182
00:50:38,098 --> 00:50:39,800
so you can fudge it, but essentially

1183
00:50:39,880 --> 00:50:41,228
somewhere down the line you're going to

1184
00:50:41,234 --> 00:50:43,000
get completely wrong conclusions,

1185
00:50:43,080 --> 00:50:45,216
nonsensical conclusions, because you

1186
00:50:45,238 --> 00:50:46,576
don't have the same strength of

1187
00:50:46,598 --> 00:50:48,444
semantics in your representation.

1188
00:50:48,572 --> 00:50:50,864
That's why we need this difficult and

1189
00:50:50,902 --> 00:50:52,160
expressive logic.

1190
00:50:54,260 --> 00:50:55,952
We have negation. Negation is another

1191
00:50:56,006 --> 00:50:57,720
big problem for graphs, right? You've

1192
00:50:57,740 --> 00:50:59,472
got to be able to negate an arbitrary

1193
00:50:59,536 --> 00:51:01,652
conjunction or disjunction of other

1194
00:51:01,706 --> 00:51:03,668
statements. To do that, you've got to

1195
00:51:03,674 --> 00:51:06,724
have a construct that is beyond a

1196
00:51:06,762 --> 00:51:10,408
particular relation, that is sort of a

1197
00:51:10,414 --> 00:51:13,208
contextualized relation. It can handle a

1198
00:51:13,214 --> 00:51:15,464
whole expression. Logic already gives

1199
00:51:15,502 --> 00:51:18,072
you this and getting negation right is

1200
00:51:18,206 --> 00:51:21,384
really a necessity in logic or in any

1201
00:51:21,422 --> 00:51:23,530
other representation you try to create.

1202
00:51:24,620 --> 00:51:26,268
Sometimes people try to say, well, I can

1203
00:51:26,274 --> 00:51:27,948
do that in my graph or I can do that in

1204
00:51:27,954 --> 00:51:29,804
my description logic. And well, maybe

1205
00:51:29,842 --> 00:51:32,396
you can for this one point case. But

1206
00:51:32,418 --> 00:51:34,416
essentially, if you're doing this in

1207
00:51:34,438 --> 00:51:36,816
your ad hoc representation, that's not a

1208
00:51:36,838 --> 00:51:38,816
formal expressive logic, you're going to

1209
00:51:38,838 --> 00:51:41,872
wind up syntactically recreating what

1210
00:51:41,926 --> 00:51:44,192
logicians have already done and done

1211
00:51:44,246 --> 00:51:47,296
many years prior and you're going to

1212
00:51:47,318 --> 00:51:49,228
sort of discover these things on a point

1213
00:51:49,254 --> 00:51:50,964
by point basis instead of just getting

1214
00:51:51,002 --> 00:51:53,184
them right from the start. So encourage

1215
00:51:53,232 --> 00:51:56,116
people to use a representation that can

1216
00:51:56,138 --> 00:51:57,636
handle the full complexity of the

1217
00:51:57,658 --> 00:51:59,832
semantics of English and only a higher

1218
00:51:59,886 --> 00:52:03,144
order logic will give you that. So

1219
00:52:03,262 --> 00:52:04,836
here's a case where the internet user

1220
00:52:04,868 --> 00:52:06,852
doesn't trap a crustacean on negating,

1221
00:52:06,916 --> 00:52:09,108
this entire complex existentially

1222
00:52:09,204 --> 00:52:11,228
quantified expression that includes a

1223
00:52:11,234 --> 00:52:13,132
temporal Coda logic expression within

1224
00:52:13,186 --> 00:52:16,460
it. What if I have an agent?

1225
00:52:16,530 --> 00:52:19,336
Patrick desires that the internet user

1226
00:52:19,368 --> 00:52:22,156
trap across station pretty common to see

1227
00:52:22,178 --> 00:52:25,952
in news texts. Kevin McCarthy said

1228
00:52:26,006 --> 00:52:29,632
he believes that the next vote for

1229
00:52:29,686 --> 00:52:31,680
speaker will be successful.

1230
00:52:33,780 --> 00:52:37,684
Bolsonaro desires that he be

1231
00:52:37,722 --> 00:52:40,484
the leader of the country again. These

1232
00:52:40,522 --> 00:52:43,764
are very common expressions in

1233
00:52:43,802 --> 00:52:46,464
natural language. They're not infrequent

1234
00:52:46,592 --> 00:52:48,832
and they're difficult and they require

1235
00:52:48,896 --> 00:52:51,056
this sort of expressive logic and that's

1236
00:52:51,088 --> 00:52:52,628
the sort of thing that we're handling.

1237
00:52:52,724 --> 00:52:54,712
We're able to generate this stuff and

1238
00:52:54,766 --> 00:52:56,584
have a representation that handles it

1239
00:52:56,622 --> 00:52:59,096
and then maybe, if we're lucky, have a

1240
00:52:59,118 --> 00:53:00,904
therapeutic that can handle it. Higher

1241
00:53:00,942 --> 00:53:02,552
order logic. Therapeutic is still

1242
00:53:02,606 --> 00:53:04,520
difficult and somewhat experimental,

1243
00:53:04,600 --> 00:53:06,076
and so that's a parallel line of

1244
00:53:06,098 --> 00:53:09,276
research. But we're not sort of hand

1245
00:53:09,298 --> 00:53:10,716
waving away this problem. We're not

1246
00:53:10,738 --> 00:53:12,616
imagining it doesn't exist or imagining

1247
00:53:12,648 --> 00:53:14,656
that we can really handle all this

1248
00:53:14,678 --> 00:53:18,048
complexity and language without this

1249
00:53:18,134 --> 00:53:21,440
additional set of computational support

1250
00:53:21,510 --> 00:53:23,024
that we believe is, in fact, really

1251
00:53:23,062 --> 00:53:26,464
required. So here

1252
00:53:26,502 --> 00:53:28,144
just making the logic and the sentence

1253
00:53:28,192 --> 00:53:29,584
more and more difficult. The Plumber

1254
00:53:29,632 --> 00:53:31,476
knows that Patrick desires that the

1255
00:53:31,498 --> 00:53:33,200
internet user traps and crustacean

1256
00:53:33,280 --> 00:53:35,136
pretty artificial sounding sentence,

1257
00:53:35,248 --> 00:53:38,884
admittedly but not all such

1258
00:53:39,002 --> 00:53:43,652
constructs for sentences are that

1259
00:53:43,706 --> 00:53:46,730
rare. You do get a news report,

1260
00:53:47,580 --> 00:53:51,932
the New York Times reported that the

1261
00:53:51,986 --> 00:53:55,260
speaker desires that this bill

1262
00:53:55,330 --> 00:53:57,516
pass without further amendment. That

1263
00:53:57,538 --> 00:53:59,304
would not be a particularly unusual

1264
00:53:59,352 --> 00:54:01,324
sentence and yet it follows exactly this

1265
00:54:01,362 --> 00:54:02,060
pattern.

1266
00:54:04,480 --> 00:54:06,976
So one of the things that we need to do

1267
00:54:07,078 --> 00:54:09,824
and if anyone is at all intrigued by

1268
00:54:09,862 --> 00:54:12,384
this work and thinking well, how can I

1269
00:54:12,582 --> 00:54:14,960
contribute? Which would be wonderful,

1270
00:54:15,380 --> 00:54:17,972
here is the great way to do that one

1271
00:54:18,026 --> 00:54:21,270
thing that we need that

1272
00:54:21,880 --> 00:54:24,884
needs to be added to sumo and yet is

1273
00:54:24,922 --> 00:54:28,070
also fairly well constrained in terms of

1274
00:54:28,840 --> 00:54:31,844
the complexity of the underlying axioms

1275
00:54:31,892 --> 00:54:33,716
that need to be expressed. So it's

1276
00:54:33,748 --> 00:54:36,036
possible to make these fairly formulaic

1277
00:54:36,148 --> 00:54:38,392
and in fact the use that we make of them

1278
00:54:38,446 --> 00:54:41,476
inside my Java code that generates logic

1279
00:54:41,508 --> 00:54:43,736
language pairs is very formulaic and

1280
00:54:43,758 --> 00:54:47,676
we'll look for only axioms that

1281
00:54:47,698 --> 00:54:49,576
are of a very particular restricted

1282
00:54:49,608 --> 00:54:51,964
force in order to do its restriction of

1283
00:54:52,002 --> 00:54:55,152
which sentences get generated. We have

1284
00:54:55,206 --> 00:54:57,468
this notion of capability, a capability

1285
00:54:57,564 --> 00:55:02,032
relation in sumo so it says that some

1286
00:55:02,086 --> 00:55:05,612
kind of thing is capable of performing

1287
00:55:05,676 --> 00:55:07,556
some kind of role in some kind of

1288
00:55:07,578 --> 00:55:10,996
action. So ears are capable of

1289
00:55:11,018 --> 00:55:13,264
hearing, guns are capable of shooting

1290
00:55:13,392 --> 00:55:15,332
and we have to talk about things that

1291
00:55:15,386 --> 00:55:18,836
might happen in order to restrict the

1292
00:55:18,858 --> 00:55:21,040
sentences that we generate. We'd like to

1293
00:55:21,050 --> 00:55:24,516
be able to say that John can't

1294
00:55:24,548 --> 00:55:26,804
be eating a boat dock, we might generate

1295
00:55:26,852 --> 00:55:29,208
something like that now but we want to

1296
00:55:29,214 --> 00:55:31,864
be able to restrict eating to have an

1297
00:55:31,902 --> 00:55:35,016
object transferred or a resource that

1298
00:55:35,038 --> 00:55:38,444
is only food, ideally food for that

1299
00:55:38,482 --> 00:55:40,248
particular animal. So we want Termites

1300
00:55:40,264 --> 00:55:41,708
to be able to eat boat docks, but we

1301
00:55:41,714 --> 00:55:43,148
don't want Bob the Plumber to be able to

1302
00:55:43,154 --> 00:55:46,816
eat a boat dock. And we

1303
00:55:46,838 --> 00:55:49,088
have a lot of processes and we have a

1304
00:55:49,094 --> 00:55:51,788
lot of objects. In sumo. And so creating

1305
00:55:51,804 --> 00:55:53,232
an inventory of these different

1306
00:55:53,286 --> 00:55:55,964
capability expressions would eliminate,

1307
00:55:56,012 --> 00:55:58,624
I think, a lot of the kind of funny

1308
00:55:58,672 --> 00:56:00,852
sounding sentences we generate now.

1309
00:56:00,906 --> 00:56:03,552
That said, I think it's not catastrophic

1310
00:56:03,616 --> 00:56:04,976
that we have some of these funny

1311
00:56:05,008 --> 00:56:06,432
sentences because remember that we're

1312
00:56:06,496 --> 00:56:10,192
ultimately trying to go from organically

1313
00:56:10,256 --> 00:56:12,676
occurring natural language text in the

1314
00:56:12,698 --> 00:56:15,536
wild in order into arbitrary logic

1315
00:56:15,568 --> 00:56:17,304
expressions. So the fact that we have

1316
00:56:17,342 --> 00:56:19,208
other sentences that kind of have a

1317
00:56:19,214 --> 00:56:22,136
similar form but don't really make a lot

1318
00:56:22,158 --> 00:56:25,020
of common sense may not be a big issue

1319
00:56:25,090 --> 00:56:26,412
because as long as we have enough

1320
00:56:26,466 --> 00:56:28,504
examples of things, that are reasonable,

1321
00:56:28,552 --> 00:56:30,444
that do cover the vocabulary we care

1322
00:56:30,482 --> 00:56:32,392
about, that do have reasonable

1323
00:56:32,456 --> 00:56:35,810
selectional restrictions that will still

1324
00:56:36,420 --> 00:56:39,184
enable us to translate the good stuff

1325
00:56:39,302 --> 00:56:41,920
that occurs the sensible sentences into

1326
00:56:41,990 --> 00:56:43,856
sensible logic expressions and the fact

1327
00:56:43,878 --> 00:56:46,460
that we have a corpus of translations

1328
00:56:46,540 --> 00:56:48,544
where the translation is reasonable but

1329
00:56:48,582 --> 00:56:51,876
the core sentence is kind of bogus. May

1330
00:56:51,898 --> 00:56:53,716
just be background noise. We may be able

1331
00:56:53,738 --> 00:56:56,804
to get away with that. But even if that

1332
00:56:56,842 --> 00:56:58,484
proves not to be a problem it still

1333
00:56:58,522 --> 00:57:01,072
would be better for us to have in Sumo

1334
00:57:01,136 --> 00:57:03,224
these capability expressions just to add

1335
00:57:03,262 --> 00:57:05,224
to our knowledge of how the world works.

1336
00:57:05,342 --> 00:57:08,836
So if anybody is intrigued by this, I'd

1337
00:57:08,868 --> 00:57:10,648
love to help you get started because I

1338
00:57:10,654 --> 00:57:12,296
think it would be not too hard to do and

1339
00:57:12,318 --> 00:57:14,250
would be of great value to the project.

1340
00:57:16,620 --> 00:57:18,808
So we have a lot, as I've said, I've

1341
00:57:18,824 --> 00:57:20,348
said a couple of times now, we have a

1342
00:57:20,354 --> 00:57:21,596
lot of processes, we have a lot of

1343
00:57:21,618 --> 00:57:23,644
objects. What do I mean by a lot? Well,

1344
00:57:23,682 --> 00:57:26,944
here's just a segment of the

1345
00:57:26,982 --> 00:57:30,332
natural language comments on a portion

1346
00:57:30,396 --> 00:57:32,272
of the hierarchy, starting from the top.

1347
00:57:32,326 --> 00:57:34,236
Here are all the process types. In suma,

1348
00:57:34,268 --> 00:57:37,396
we have 1300 of them at last count and

1349
00:57:37,418 --> 00:57:39,350
here are a number of them.

1350
00:57:41,320 --> 00:57:43,376
So in a lot of sentences we don't

1351
00:57:43,408 --> 00:57:46,708
restrict what processes can hold for a

1352
00:57:46,714 --> 00:57:48,116
given sentence. And we'd like to have

1353
00:57:48,138 --> 00:57:50,036
again these selectional restrictions

1354
00:57:50,148 --> 00:57:52,616
based on capability expressions for the

1355
00:57:52,638 --> 00:57:54,776
type of objects that can participate in

1356
00:57:54,798 --> 00:57:56,548
the types of processes, so that we don't

1357
00:57:56,564 --> 00:57:57,690
get silly stuff.

1358
00:58:00,460 --> 00:58:02,904
For each of these processes we have

1359
00:58:02,942 --> 00:58:04,844
mappings to verbs and word net. So

1360
00:58:04,882 --> 00:58:07,516
that's what allows us to cycle to

1361
00:58:07,538 --> 00:58:09,560
iterate through all the process types

1362
00:58:09,640 --> 00:58:12,396
and still generate a sentence, not using

1363
00:58:12,498 --> 00:58:15,056
the labels in Sumo, but rather using the

1364
00:58:15,078 --> 00:58:17,632
labels, the legitimate words in the word

1365
00:58:17,686 --> 00:58:20,144
net dictionary. So for example, for

1366
00:58:20,182 --> 00:58:21,984
Ambush it's mapped to a particular

1367
00:58:22,102 --> 00:58:24,656
numbered senseet a collection of

1368
00:58:24,678 --> 00:58:27,072
synonyms, collection of synonymous words

1369
00:58:27,126 --> 00:58:29,200
in WordNet that linguistically

1370
00:58:29,280 --> 00:58:32,596
identifies a sense in English. And so we

1371
00:58:32,618 --> 00:58:34,916
have ambush that's mapped to since that

1372
00:58:34,938 --> 00:58:38,116
blah blah blah 926, it has a

1373
00:58:38,138 --> 00:58:40,424
certain definition, has a certain set of

1374
00:58:40,462 --> 00:58:43,336
synonyms ambush, god, ambush, lying in

1375
00:58:43,358 --> 00:58:45,064
wait and a trap. And that's why we saw

1376
00:58:45,102 --> 00:58:47,076
trapping earlier. The internet user

1377
00:58:47,108 --> 00:58:49,784
traps a crustacean that was exactly this

1378
00:58:49,902 --> 00:58:56,236
equivalent symbol sunset. For ambush we

1379
00:58:56,258 --> 00:58:58,556
have lots of case rules. So these are

1380
00:58:58,658 --> 00:59:00,684
the ways in which entities can

1381
00:59:00,722 --> 00:59:03,544
participate in events. There are some

1382
00:59:03,602 --> 00:59:05,760
simple systems, including some simple

1383
00:59:05,830 --> 00:59:09,650
systems in linguistics. If you look at,

1384
00:59:11,700 --> 00:59:15,056
I think Verbelen has some of this set

1385
00:59:15,078 --> 00:59:18,028
of restrictions. So agent, patient,

1386
00:59:18,124 --> 00:59:20,192
instrument, resource, these are very

1387
00:59:20,246 --> 00:59:23,764
common and you'll also see

1388
00:59:23,962 --> 00:59:26,724
agent, zero agent one, sometimes as

1389
00:59:26,762 --> 00:59:29,380
labels in semiformal linguistics,

1390
00:59:29,460 --> 00:59:32,100
talking about the roles that entities

1391
00:59:32,180 --> 00:59:34,040
play in activity.

1392
00:59:36,220 --> 00:59:38,392
And so occasionally I've gotten this

1393
00:59:38,526 --> 00:59:40,024
question, which I think is funny, is

1394
00:59:40,062 --> 00:59:41,484
like, well, why isn't it enough to have

1395
00:59:41,522 --> 00:59:43,420
just agent, patient and instrument?

1396
00:59:43,840 --> 00:59:46,092
Well, yes, that does cover, at a high

1397
00:59:46,146 --> 00:59:49,432
level, maybe exhaustively the roles

1398
00:59:49,496 --> 00:59:51,496
that things can play. I mean, James

1399
00:59:51,528 --> 00:59:54,324
Pustiovsky also has this set of qualia

1400
00:59:54,392 --> 00:59:56,770
relations. This is a common,

1401
00:59:57,620 --> 01:00:00,256
I think, approach in linguistics to try

1402
01:00:00,278 --> 01:00:02,880
to explain language through a small

1403
01:00:02,950 --> 01:00:04,896
number of covering predicates or

1404
01:00:04,918 --> 01:00:07,056
abstractions. And while that might be

1405
01:00:07,078 --> 01:00:09,116
fine for abstract linguistics in

1406
01:00:09,158 --> 01:00:10,916
practice, there's a lot more that we can

1407
01:00:10,938 --> 01:00:13,348
say about the world, about how things

1408
01:00:13,434 --> 01:00:16,484
interact in events that happen. And so

1409
01:00:16,522 --> 01:00:18,836
we've come up with 67 of them. And I

1410
01:00:18,858 --> 01:00:20,536
think this is, you know, many orders of

1411
01:00:20,558 --> 01:00:22,392
magnitude too small, but it's a good

1412
01:00:22,446 --> 01:00:24,872
start. It's the stuff that we've found

1413
01:00:24,926 --> 01:00:27,800
that's been useful over the years.

1414
01:00:27,870 --> 01:00:32,132
So invading virus catalyst broker

1415
01:00:32,196 --> 01:00:35,480
enjoys reagent all of these relations.

1416
01:00:35,630 --> 01:00:38,892
Many of them are subrelations of things

1417
01:00:38,946 --> 01:00:41,144
like agent and patient and instrument

1418
01:00:41,192 --> 01:00:43,070
and resource, but they're more specific.

1419
01:00:43,700 --> 01:00:46,316
They entail different additional

1420
01:00:46,428 --> 01:00:48,588
knowledge when they're used. And it's

1421
01:00:48,604 --> 01:00:50,316
knowledge which fits with our knowledge

1422
01:00:50,348 --> 01:00:51,570
of the real world.

1423
01:00:53,540 --> 01:00:56,668
We have lots of objects. So here's just

1424
01:00:56,694 --> 01:00:59,044
the corpuscular objects, things that are

1425
01:00:59,082 --> 01:01:02,500
not substances, that hae Parr,

1426
01:01:03,400 --> 01:01:06,292
and we have 930 of them. A lot of them

1427
01:01:06,346 --> 01:01:08,404
are content bearing objects or things

1428
01:01:08,442 --> 01:01:10,216
that might have writing or symbols on

1429
01:01:10,238 --> 01:01:13,928
them that are common in our world, as

1430
01:01:13,934 --> 01:01:17,000
well as organic objects like organisms.

1431
01:01:17,980 --> 01:01:20,056
There's a lot of these, and they all

1432
01:01:20,078 --> 01:01:21,192
play different roles in different

1433
01:01:21,246 --> 01:01:24,904
activities. Here are some of the roles

1434
01:01:25,032 --> 01:01:28,508
that human beings or agents can play.

1435
01:01:28,674 --> 01:01:30,476
You can have a certain profession. You

1436
01:01:30,498 --> 01:01:32,924
can be a plumber or a programmer, and

1437
01:01:32,962 --> 01:01:34,508
you can switch freely from one to the

1438
01:01:34,514 --> 01:01:36,256
other. This past weekend and made my

1439
01:01:36,278 --> 01:01:37,488
toilet breaks and I have to be a

1440
01:01:37,494 --> 01:01:39,932
plumber. Today I'm a programmer.

1441
01:01:40,076 --> 01:01:42,208
Maybe tonight I will be teaching a

1442
01:01:42,214 --> 01:01:44,000
course, and so I'll be a lecturer.

1443
01:01:45,780 --> 01:01:47,750
These different roles are free and

1444
01:01:48,200 --> 01:01:52,004
flexible and large, and they also are

1445
01:01:52,042 --> 01:01:53,636
temporarily qualified, right? You can

1446
01:01:53,658 --> 01:01:55,332
play different roles at different times.

1447
01:01:55,386 --> 01:01:58,176
So it's not enough to say, as WordNet

1448
01:01:58,208 --> 01:02:00,016
unfortunately does, as a linguistic

1449
01:02:00,048 --> 01:02:03,776
product, that a subtype of human is

1450
01:02:03,818 --> 01:02:06,216
plumber. Well, you can be a plumber one

1451
01:02:06,238 --> 01:02:07,864
time and not be a plumber another time,

1452
01:02:07,902 --> 01:02:09,368
and that doesn't mean you cease to be a

1453
01:02:09,374 --> 01:02:12,220
human. It's a bad relation to have

1454
01:02:12,370 --> 01:02:14,460
formally, although it's a reasonable

1455
01:02:14,960 --> 01:02:16,472
relation to have linguistically,

1456
01:02:16,536 --> 01:02:18,492
because you can do the substitution test

1457
01:02:18,546 --> 01:02:21,496
that linguists do of substituting,

1458
01:02:21,608 --> 01:02:23,516
say, a superclass for a subclass. And it

1459
01:02:23,538 --> 01:02:25,456
works in a lot of sentences, but it

1460
01:02:25,478 --> 01:02:27,376
doesn't work formally, doesn't work in

1461
01:02:27,398 --> 01:02:29,984
logic. So we need to separate out these

1462
01:02:30,022 --> 01:02:31,932
rules and say that they're transient,

1463
01:02:31,996 --> 01:02:34,032
temporally qualified rules that people

1464
01:02:34,086 --> 01:02:37,184
can have. So we can generate against

1465
01:02:37,302 --> 01:02:39,148
bogus stuff like Robert Kills a boat

1466
01:02:39,164 --> 01:02:40,644
dock. It doesn't really make any sense?

1467
01:02:40,682 --> 01:02:42,308
It makes sense syntactically, but we

1468
01:02:42,314 --> 01:02:44,116
need these capability restrictions to

1469
01:02:44,138 --> 01:02:46,356
handle them. And a lot of times we do

1470
01:02:46,378 --> 01:02:48,548
have restrictions, like the rule below

1471
01:02:48,634 --> 01:02:52,276
here. But I can't

1472
01:02:52,308 --> 01:02:54,356
afford to do theorem proving while I'm

1473
01:02:54,388 --> 01:02:56,036
doing generation. If I need to generate

1474
01:02:56,068 --> 01:02:58,964
a 1 TB corpus of language logic pairs,

1475
01:02:59,092 --> 01:03:01,640
I can't prove the truth of every

1476
01:03:01,710 --> 01:03:04,392
sentence. This would take many years

1477
01:03:04,526 --> 01:03:06,472
just to do one run of the generation

1478
01:03:06,536 --> 01:03:08,364
system. I've got to find a way to

1479
01:03:08,402 --> 01:03:09,976
optimize that. And the way to optimize

1480
01:03:10,008 --> 01:03:11,400
it is just to look at capability

1481
01:03:11,480 --> 01:03:14,616
expressions, even though the following

1482
01:03:14,648 --> 01:03:16,764
rule that I'm showing up here says that

1483
01:03:16,882 --> 01:03:18,988
a killing has to have an object that's

1484
01:03:19,004 --> 01:03:21,216
an organism and a boat doc is not an

1485
01:03:21,238 --> 01:03:24,576
organism. So this would be trapped if I

1486
01:03:24,598 --> 01:03:26,336
could do theoremproving for everything I

1487
01:03:26,358 --> 01:03:27,952
generate. But I just don't have time.

1488
01:03:28,086 --> 01:03:30,384
So I need to use this more restrictive

1489
01:03:30,432 --> 01:03:32,868
form that I can turn into a sort of a

1490
01:03:32,874 --> 01:03:36,032
lookup table and make run much faster.

1491
01:03:36,176 --> 01:03:37,776
Okay? So I need this following

1492
01:03:37,808 --> 01:03:40,340
expression that if there's a capability

1493
01:03:40,420 --> 01:03:43,736
of killing the killing event, only the

1494
01:03:43,758 --> 01:03:45,508
patient has to be an organism. If it's

1495
01:03:45,524 --> 01:03:47,668
the patient or the object of the killing

1496
01:03:47,684 --> 01:03:49,320
event, it must be an organism.

1497
01:03:50,700 --> 01:03:52,876
I also had the question of how much is

1498
01:03:52,898 --> 01:03:54,908
too much? Right now I am able to

1499
01:03:54,914 --> 01:03:57,996
generate, say, a terabyte corpus in the

1500
01:03:58,018 --> 01:04:01,852
span of a couple of hours and then train

1501
01:04:01,906 --> 01:04:04,732
on it. Training takes about 20 hours on

1502
01:04:04,786 --> 01:04:08,720
a multi GPU, fairly beefy server.

1503
01:04:09,540 --> 01:04:11,616
How much is too much? I don't have a

1504
01:04:11,638 --> 01:04:13,664
sense of that. Hohwy much is it too

1505
01:04:13,702 --> 01:04:16,688
little? We're getting good fidelity.

1506
01:04:16,784 --> 01:04:21,270
We break things up in the standard train

1507
01:04:21,640 --> 01:04:24,980
test split

1508
01:04:26,760 --> 01:04:28,596
and we get good metrics. We get a

1509
01:04:28,618 --> 01:04:30,392
perplexity score that's down around

1510
01:04:30,446 --> 01:04:34,132
1.11.2. That's one reasonable measure

1511
01:04:34,196 --> 01:04:36,148
for the fidelity of your deep neural

1512
01:04:36,164 --> 01:04:39,464
network training approach. But is that

1513
01:04:39,502 --> 01:04:41,416
good enough? I don't know yet. We just

1514
01:04:41,438 --> 01:04:43,176
need to do a lot more experiments. So we

1515
01:04:43,198 --> 01:04:46,028
have about 100 names that we use. We

1516
01:04:46,034 --> 01:04:48,956
have a corpus of common human names. We

1517
01:04:48,978 --> 01:04:51,048
have about these 300 roles. We have lots

1518
01:04:51,064 --> 01:04:53,192
of different propositional attitudes,

1519
01:04:53,256 --> 01:04:55,928
each of which could be negated. We have

1520
01:04:55,954 --> 01:04:58,176
modals like can, may, should that are

1521
01:04:58,198 --> 01:05:00,076
also formally expressed in our modal

1522
01:05:00,108 --> 01:05:02,252
logic. Those in turn, could be negated.

1523
01:05:02,316 --> 01:05:05,052
We have 400 different sorts of roles

1524
01:05:05,116 --> 01:05:08,192
like plumber and teacher, 1300

1525
01:05:08,246 --> 01:05:10,036
processes. Those in fast could be

1526
01:05:10,058 --> 01:05:12,020
negated. And we have past, present,

1527
01:05:12,090 --> 01:05:13,776
future, and then the progressive tents

1528
01:05:13,808 --> 01:05:15,364
for each of those. All of those

1529
01:05:15,402 --> 01:05:18,340
possibilities, we've got 930 direct

1530
01:05:18,410 --> 01:05:20,612
corpuscular objects. And then we've got

1531
01:05:20,666 --> 01:05:22,168
substances which I haven't listed on

1532
01:05:22,174 --> 01:05:23,784
here. We've got lots of substances like

1533
01:05:23,822 --> 01:05:27,556
water or gasoline, 67 case rules.

1534
01:05:27,668 --> 01:05:30,724
And again, 930 of those same corpuscular

1535
01:05:30,772 --> 01:05:33,020
objects that can be indirect objects.

1536
01:05:33,760 --> 01:05:35,356
And then I've also added a bunch of

1537
01:05:35,378 --> 01:05:37,564
politeness expressions like can I may,

1538
01:05:37,602 --> 01:05:40,956
I should do the following so a lot

1539
01:05:40,978 --> 01:05:43,372
of these modal expressions can become

1540
01:05:43,426 --> 01:05:46,404
politeness. So please. May I? Et cetera.

1541
01:05:46,552 --> 01:05:49,504
So we can handle stuff in chatbot or

1542
01:05:49,542 --> 01:05:51,612
conversational, kind of stuff that's

1543
01:05:51,676 --> 01:05:53,536
very commonly seen. So I did an

1544
01:05:53,558 --> 01:05:55,008
inventory of stuff that a lot of the

1545
01:05:55,014 --> 01:05:57,164
chat bots use for their sentence

1546
01:05:57,212 --> 01:05:58,928
patterns to make sure we cover that.

1547
01:05:59,014 --> 01:06:00,436
But a lot of these combinations are

1548
01:06:00,458 --> 01:06:02,756
nonsense, so I've got to somehow Parr it

1549
01:06:02,778 --> 01:06:06,068
down. If not if it's not a problem in

1550
01:06:06,074 --> 01:06:08,036
terms of creating a lot of junk that can

1551
01:06:08,058 --> 01:06:09,536
otherwise get ignored when I'm

1552
01:06:09,568 --> 01:06:11,464
translating a sentence, at the very

1553
01:06:11,502 --> 01:06:13,576
least, it slows down training. And so as

1554
01:06:13,598 --> 01:06:17,076
I make the corpus larger, I have to pare

1555
01:06:17,108 --> 01:06:18,936
down the nonsense just so that my

1556
01:06:18,958 --> 01:06:22,056
training phase is possible, because I

1557
01:06:22,078 --> 01:06:23,996
don't have the resources of OpenAI to

1558
01:06:24,018 --> 01:06:26,076
spend $3 million a month on running

1559
01:06:26,178 --> 01:06:28,844
their chat GPT for the world, right?

1560
01:06:28,882 --> 01:06:31,276
I've got to run on one server that my

1561
01:06:31,298 --> 01:06:33,310
friend and Prague has access to.

1562
01:06:35,840 --> 01:06:37,792
So there's lots more that I can still

1563
01:06:37,846 --> 01:06:40,412
do. Units and measures. I've only begun

1564
01:06:40,476 --> 01:06:42,176
starting to do that. I've got a little

1565
01:06:42,198 --> 01:06:46,216
bit of that. So I can say Bob

1566
01:06:46,268 --> 01:06:50,020
puts three birds in his wagon

1567
01:06:51,000 --> 01:06:54,916
or £3 of steak in his

1568
01:06:55,018 --> 01:06:57,430
jar, something of that sort,

1569
01:06:57,960 --> 01:06:59,748
because we've got a whole set of I think

1570
01:06:59,754 --> 01:07:01,216
there are about 60 different system

1571
01:07:01,258 --> 01:07:04,376
international units and Sumo has them

1572
01:07:04,398 --> 01:07:05,956
all. And then, of course, your values

1573
01:07:05,988 --> 01:07:07,512
can be within all sorts of different

1574
01:07:07,566 --> 01:07:10,036
ranges. We've got logical combinations

1575
01:07:10,068 --> 01:07:11,704
of sentences that I could generate. So

1576
01:07:11,742 --> 01:07:13,816
Bob goes to the store and Bob buys

1577
01:07:13,848 --> 01:07:17,400
cookies. We can temporarily qualify

1578
01:07:17,480 --> 01:07:19,356
all of these things. I've got a little

1579
01:07:19,378 --> 01:07:21,788
bit of that already. So Bob goes to the

1580
01:07:21,794 --> 01:07:23,900
store on Tuesday, bob goes to the store

1581
01:07:23,970 --> 01:07:27,010
on January 27 of 2003.

1582
01:07:28,660 --> 01:07:30,608
We have a bit of an issue that a lot of

1583
01:07:30,614 --> 01:07:32,032
these case rules require different

1584
01:07:32,086 --> 01:07:34,528
prepositions, so I don't have those

1585
01:07:34,614 --> 01:07:36,736
working correctly. I need to actually do

1586
01:07:36,758 --> 01:07:38,148
a whole set of patterns that are a

1587
01:07:38,154 --> 01:07:40,228
little fragment of framenet, if you

1588
01:07:40,234 --> 01:07:43,780
will, for different action types and

1589
01:07:43,850 --> 01:07:46,244
which particular prepositions are

1590
01:07:46,362 --> 01:07:48,196
historically used. So you get in the

1591
01:07:48,218 --> 01:07:50,916
car, you get on the boat, you go to the

1592
01:07:50,938 --> 01:07:53,352
station. I don't handle all of those

1593
01:07:53,406 --> 01:07:55,976
correctly. Things we can do, like with

1594
01:07:55,998 --> 01:07:57,912
more than one agent right now. Agents

1595
01:07:57,966 --> 01:07:59,688
are always singular in my examples. We

1596
01:07:59,694 --> 01:08:01,416
can certainly have Jack and Jill go up

1597
01:08:01,438 --> 01:08:04,444
the hill. And not just Jack. I have now

1598
01:08:04,482 --> 01:08:07,596
just implemented quotes for said so we

1599
01:08:07,618 --> 01:08:09,884
can handle this common form for news

1600
01:08:09,922 --> 01:08:12,428
reports or novels or what have you.

1601
01:08:12,594 --> 01:08:14,128
Lots more things that can be done to

1602
01:08:14,134 --> 01:08:16,284
make this a more comprehensive corpus.

1603
01:08:16,332 --> 01:08:20,016
Long before I run out of stuff to do, I

1604
01:08:20,038 --> 01:08:23,100
can cover a lot larger portion or subset

1605
01:08:23,180 --> 01:08:25,120
of English.

1606
01:08:27,140 --> 01:08:29,444
So here's just some detail on how we run

1607
01:08:29,482 --> 01:08:32,036
the model. I just got a script. It's not

1608
01:08:32,058 --> 01:08:35,620
too hard, it just takes a long time. So

1609
01:08:35,690 --> 01:08:38,976
culture work. Once I get done exhausting

1610
01:08:39,008 --> 01:08:40,836
the set of things I can think of that I

1611
01:08:40,858 --> 01:08:42,644
can do, then we need to start seeing

1612
01:08:42,682 --> 01:08:45,304
where it fails on natural text. A big

1613
01:08:45,342 --> 01:08:47,444
thing to do is to use either word to VEC

1614
01:08:47,492 --> 01:08:49,928
or some large language model, maybe as a

1615
01:08:49,934 --> 01:08:51,276
way to tear down the number of

1616
01:08:51,298 --> 01:08:54,476
nonsensical combinations along with my

1617
01:08:54,498 --> 01:08:56,764
preferred approach of having a lot more

1618
01:08:56,802 --> 01:08:58,684
capability. Sentences which will then

1619
01:08:58,722 --> 01:09:01,576
add to the understanding, the competence

1620
01:09:01,688 --> 01:09:03,884
of this core model regardless of whether

1621
01:09:03,922 --> 01:09:04,904
we're trying to do language

1622
01:09:04,952 --> 01:09:06,336
understanding or some other kind of

1623
01:09:06,358 --> 01:09:08,336
project. And I really want to do a

1624
01:09:08,358 --> 01:09:11,456
comprehensive test on the baby corpus to

1625
01:09:11,478 --> 01:09:13,712
just see if I can do better. If I'm not

1626
01:09:13,766 --> 01:09:16,768
learning and teaching a machine learning

1627
01:09:16,854 --> 01:09:19,056
system how to do inference, but using a

1628
01:09:19,078 --> 01:09:20,496
system that already knows how to do

1629
01:09:20,518 --> 01:09:22,228
inference, I think I should be able to

1630
01:09:22,234 --> 01:09:24,516
get better scores. But that remains an

1631
01:09:24,538 --> 01:09:26,788
empirical question. If I can do that, I

1632
01:09:26,794 --> 01:09:28,196
think maybe then people will pay more

1633
01:09:28,218 --> 01:09:29,688
attention to this work. So it would be a

1634
01:09:29,694 --> 01:09:33,096
nice demo. Okay, that's it.

1635
01:09:33,198 --> 01:09:35,112
So thanks for learning about this early

1636
01:09:35,166 --> 01:09:37,160
work as well as the more mature model

1637
01:09:37,230 --> 01:09:38,904
that it's based on that's already being

1638
01:09:38,942 --> 01:09:41,940
applied commercially and would love it

1639
01:09:41,950 --> 01:09:43,724
if I got somebody on this call so

1640
01:09:43,762 --> 01:09:45,244
excited that you wanted to do some work

1641
01:09:45,282 --> 01:09:45,870
together.

1642
01:09:48,240 --> 01:09:50,076
Excellent. Thank you for the

1643
01:09:50,098 --> 01:09:53,116
presentation, Adam. You can unshare or

1644
01:09:53,138 --> 01:09:55,900
leave it up, and we will begin with Dave

1645
01:09:56,060 --> 01:09:57,904
providing some initial comments and

1646
01:09:57,942 --> 01:10:01,296
questions. >>>DAVE DOUGLASS: Yes. One idea.

1647
01:10:01,398 --> 01:10:03,984
Can you hear me now? I can. Great. One

1648
01:10:04,022 --> 01:10:06,452
idea that occurred to me several points

1649
01:10:06,506 --> 01:10:09,430
during your presentation was if you put

1650
01:10:10,520 --> 01:10:15,460
part of the Pruning inside the model by

1651
01:10:15,530 --> 01:10:19,770
creating persistent agents with

1652
01:10:20,140 --> 01:10:24,004
goals and beliefs, bob isn't

1653
01:10:24,052 --> 01:10:27,460
just a transient pattern of activations,

1654
01:10:27,540 --> 01:10:29,720
but Bob is something that stays around

1655
01:10:29,790 --> 01:10:33,400
for a while. And perhaps Bob's desires

1656
01:10:33,480 --> 01:10:37,832
evolve more slowly than Bob's beliefs,

1657
01:10:37,976 --> 01:10:40,284
including Bob's beliefs about Carol and

1658
01:10:40,322 --> 01:10:42,664
Carol's relevance and whether Carol

1659
01:10:42,712 --> 01:10:44,556
believes correct things about what he's

1660
01:10:44,588 --> 01:10:46,876
interested in right now. Have you gotten

1661
01:10:46,908 --> 01:10:50,530
around to something as charming as that?

1662
01:10:51,300 --> 01:10:53,104
Well, that's what the baby folks did,

1663
01:10:53,142 --> 01:10:56,032
right? They've got this model world

1664
01:10:56,086 --> 01:10:57,876
model, and they generate sentences and

1665
01:10:57,898 --> 01:10:59,796
variations of those sentences based on

1666
01:10:59,818 --> 01:11:01,348
that world model. And we could certainly

1667
01:11:01,434 --> 01:11:04,468
re implement the simple system that

1668
01:11:04,474 --> 01:11:07,972
they've done in Lua in a more

1669
01:11:08,026 --> 01:11:09,864
complicated blocks world, if you will,

1670
01:11:09,902 --> 01:11:11,796
that uses all the entities and objects

1671
01:11:11,828 --> 01:11:13,828
that are in sumo. That's something I'd

1672
01:11:13,844 --> 01:11:14,650
like to do.

1673
01:11:22,950 --> 01:11:24,820
Okay, reconnecting here.

1674
01:16:35,580 --> 01:16:37,370
We've got Daniel back.

1675
01:16:42,060 --> 01:16:44,024
Okay, maybe he's having some back

1676
01:16:44,062 --> 01:16:47,596
Internet issues. Yes, I had

1677
01:16:47,618 --> 01:16:51,436
to move to a backup force for

1678
01:16:51,458 --> 01:16:53,900
a strange reason. But let us continue

1679
01:16:53,970 --> 01:16:57,310
the conversation with no video.

1680
01:16:57,860 --> 01:17:01,180
And yes, the last thing you added

1681
01:17:01,260 --> 01:17:04,832
was the capacities and the opportunity

1682
01:17:04,966 --> 01:17:07,536
to contribute there. Please feel free to

1683
01:17:07,558 --> 01:17:09,716
pick up there, or I can pick up there

1684
01:17:09,738 --> 01:17:11,380
and take it in a different direction.

1685
01:17:11,960 --> 01:17:14,196
Yeah, Sajid, I was just talking a little

1686
01:17:14,218 --> 01:17:16,644
bit further about maybe some other work

1687
01:17:16,682 --> 01:17:20,550
that's going on in psychology and

1688
01:17:21,160 --> 01:17:23,124
ontologies of emotions, and I was just

1689
01:17:23,162 --> 01:17:26,544
commenting how Suma already has

1690
01:17:26,682 --> 01:17:28,536
extensive ontology of emotions but of

1691
01:17:28,558 --> 01:17:30,264
course it has ontologies of many other

1692
01:17:30,302 --> 01:17:32,040
things. So anybody that wanted to study

1693
01:17:32,110 --> 01:17:35,768
a representation of emotion for use

1694
01:17:35,854 --> 01:17:38,124
in psychotherapy or any other reason

1695
01:17:38,242 --> 01:17:40,652
would kind of get for free all of this

1696
01:17:40,706 --> 01:17:43,868
other stuff. Defining model of the rest,

1697
01:17:44,034 --> 01:17:46,188
which would, I think make that work,

1698
01:17:46,274 --> 01:17:48,524
have a greater impact over time and be

1699
01:17:48,562 --> 01:17:50,480
more readily adoptable in different

1700
01:17:50,550 --> 01:17:52,608
concepts because it has this link to a

1701
01:17:52,614 --> 01:17:54,636
whole host of other semantically defined

1702
01:17:54,668 --> 01:17:58,208
entities. Yeah, one of

1703
01:17:58,214 --> 01:17:59,700
the things that would make it a lot

1704
01:17:59,770 --> 01:18:03,184
easier too to participate

1705
01:18:03,232 --> 01:18:05,844
across groups is if it were easier to

1706
01:18:05,882 --> 01:18:09,636
actually run Sigma. Several of

1707
01:18:09,658 --> 01:18:13,160
us have tried to install

1708
01:18:13,310 --> 01:18:15,896
and run it. I don't know that anybody in

1709
01:18:15,918 --> 01:18:18,424
the active inference group has ever

1710
01:18:18,462 --> 01:18:22,036
succeeded for the appropriate

1711
01:18:22,068 --> 01:18:24,072
environment. You have some really nice

1712
01:18:24,206 --> 01:18:26,424
videos and I've tried to follow those.

1713
01:18:26,462 --> 01:18:28,364
In every case it broke down with some

1714
01:18:28,402 --> 01:18:31,276
warning like if you keep going, your

1715
01:18:31,298 --> 01:18:33,436
Windows system may self destruct. Why

1716
01:18:33,458 --> 01:18:35,756
don't you stop now? So it's pretty

1717
01:18:35,778 --> 01:18:39,228
scary. We even tried to go to a vendor,

1718
01:18:39,324 --> 01:18:42,636
a provider of cloud services systems.

1719
01:18:42,748 --> 01:18:46,080
Like Sumo et al. That provide

1720
01:18:46,150 --> 01:18:48,912
rigor in how those different states get

1721
01:18:48,966 --> 01:18:51,236
translated and mapped to each other like

1722
01:18:51,338 --> 01:18:53,716
short text to long text, long text to

1723
01:18:53,738 --> 01:18:56,336
short text, short text to mouse

1724
01:18:56,368 --> 01:18:59,152
movement. All those different mappings

1725
01:18:59,296 --> 01:19:03,096
are implausible in multiple ways without

1726
01:19:03,198 --> 01:19:05,396
a formal semantics the kind that you're

1727
01:19:05,428 --> 01:19:08,970
describing. Yeah,

1728
01:19:09,500 --> 01:19:12,890
I agree. Maybe I could say a word about

1729
01:19:13,820 --> 01:19:15,340
uncertain reasoning,

1730
01:19:16,960 --> 01:19:20,124
because this is an area that I think

1731
01:19:20,162 --> 01:19:21,692
a lot of people that are used to being

1732
01:19:21,746 --> 01:19:26,332
in a probabilistic representation often

1733
01:19:26,386 --> 01:19:28,156
have some misconceptions about what's

1734
01:19:28,188 --> 01:19:30,688
possible in logic. Usually. Based on the

1735
01:19:30,694 --> 01:19:33,264
fact that the logic that most people are

1736
01:19:33,302 --> 01:19:36,576
exposed to academically is going to be

1737
01:19:36,598 --> 01:19:39,968
first order logic where you do have just

1738
01:19:40,134 --> 01:19:41,936
truth values. Binary truth values,

1739
01:19:41,968 --> 01:19:44,196
right? It's either true or false. And

1740
01:19:44,298 --> 01:19:45,824
people want to be able to represent

1741
01:19:45,872 --> 01:19:48,356
things that are uncertain or likely or

1742
01:19:48,378 --> 01:19:51,510
unlikely and therefore assume that

1743
01:19:52,440 --> 01:19:54,516
logic can't handle that and while it

1744
01:19:54,538 --> 01:19:56,164
can, it's just you have to go beyond

1745
01:19:56,212 --> 01:19:58,104
first order logic. And so that's exactly

1746
01:19:58,222 --> 01:20:01,064
why we're in the realm of higher order

1747
01:20:01,102 --> 01:20:02,804
logic and sumo and have modal

1748
01:20:02,852 --> 01:20:05,224
expressions. We want to be able to say

1749
01:20:05,262 --> 01:20:08,668
and can say in the logic that something

1750
01:20:08,754 --> 01:20:10,972
is likely or that one thing is more

1751
01:20:11,026 --> 01:20:13,996
likely than another or that because of

1752
01:20:14,018 --> 01:20:16,268
such and such event something has become

1753
01:20:16,354 --> 01:20:17,968
more likely. So we have to make a

1754
01:20:17,974 --> 01:20:19,676
projection that includes some temporal

1755
01:20:19,708 --> 01:20:22,972
reasoning as well. So logic

1756
01:20:23,036 --> 01:20:25,836
is maybe you could call it a non

1757
01:20:25,868 --> 01:20:29,488
classical logic, right? I find that a

1758
01:20:29,494 --> 01:20:30,716
little uncomfortable because most non

1759
01:20:30,748 --> 01:20:32,804
classical logics are things like four

1760
01:20:32,842 --> 01:20:35,684
valued logics or things that don't just

1761
01:20:35,722 --> 01:20:37,344
have true and false. Well, modal logics

1762
01:20:37,392 --> 01:20:39,732
do still just have true and false but

1763
01:20:39,786 --> 01:20:42,484
they are able to describe an entire

1764
01:20:42,602 --> 01:20:45,304
situation with all its possibilities and

1765
01:20:45,342 --> 01:20:48,280
conditionals things like possible worlds

1766
01:20:48,620 --> 01:20:50,936
which allow us to capture some of these

1767
01:20:50,958 --> 01:20:54,160
same intuitions that a probabilistic

1768
01:20:54,260 --> 01:20:56,264
representation like Bayesian reasoning

1769
01:20:56,312 --> 01:21:00,172
can. I think there's to my mind

1770
01:21:00,226 --> 01:21:02,392
a clear advantage of the symbolic

1771
01:21:02,456 --> 01:21:06,316
representation. It is possible,

1772
01:21:06,418 --> 01:21:10,540
of course, to have large libraries

1773
01:21:10,620 --> 01:21:16,588
of empirical data, to have realistic

1774
01:21:16,684 --> 01:21:19,956
probability assessments and say that

1775
01:21:20,058 --> 01:21:24,116
such and such an event is 73%

1776
01:21:24,218 --> 01:21:27,396
likely in this context. But a lot of

1777
01:21:27,418 --> 01:21:29,124
times when I see people using

1778
01:21:29,242 --> 01:21:30,912
probabilistic or Bayesian

1779
01:21:30,976 --> 01:21:33,816
representations, they're sort of using

1780
01:21:33,918 --> 01:21:37,080
them. Mathematics is precise,

1781
01:21:37,740 --> 01:21:40,404
the source data is often not precise.

1782
01:21:40,452 --> 01:21:42,552
People are making a guess, I guess,

1783
01:21:42,606 --> 01:21:45,176
that it's probably 70% likely that the

1784
01:21:45,198 --> 01:21:46,504
following will happen. Then they encode

1785
01:21:46,552 --> 01:21:48,764
that in their system and I think those

1786
01:21:48,802 --> 01:21:51,820
things are better represented as

1787
01:21:51,890 --> 01:21:54,172
symbolic preferences. This is more

1788
01:21:54,226 --> 01:21:56,524
likely than that, but we don't know that

1789
01:21:56,562 --> 01:21:59,932
it's 73% likely versus

1790
01:21:59,996 --> 01:22:03,180
56% likely. An additional

1791
01:22:03,260 --> 01:22:06,048
problem I think often not maybe not in

1792
01:22:06,054 --> 01:22:07,584
your case, but in certainly in many

1793
01:22:07,622 --> 01:22:09,192
cases with people that are doing numeric

1794
01:22:09,276 --> 01:22:11,024
probabilities is that the numeric

1795
01:22:11,072 --> 01:22:13,220
probabilities force a total order

1796
01:22:13,290 --> 01:22:15,364
essentially. And you've got these

1797
01:22:15,402 --> 01:22:19,780
appearance of precision where 73%

1798
01:22:19,850 --> 01:22:23,624
is more likely than 56%. But in

1799
01:22:23,662 --> 01:22:26,264
reality, if that comes from anything

1800
01:22:26,382 --> 01:22:29,044
less than statistically rigorous

1801
01:22:29,092 --> 01:22:31,944
empirical data, then it's just sort of a

1802
01:22:31,982 --> 01:22:34,456
confidence factor like was used in a lot

1803
01:22:34,478 --> 01:22:38,028
of old style expert systems. That

1804
01:22:38,114 --> 01:22:41,036
doesn't give you reliable results. So

1805
01:22:41,218 --> 01:22:43,372
none of those criticisms may actually

1806
01:22:43,426 --> 01:22:45,276
apply to your situation. I don't have

1807
01:22:45,298 --> 01:22:46,990
enough detail about what you're doing,

1808
01:22:47,360 --> 01:22:50,210
but I ask you to consider those points.

1809
01:22:51,380 --> 01:22:53,664
Awesome. I'll give a thought on that and

1810
01:22:53,702 --> 01:22:57,090
then Dave happy to hear from it.

1811
01:22:57,460 --> 01:23:01,680
So for any given model architecture

1812
01:23:01,840 --> 01:23:03,984
symbolically represented like a symbolic

1813
01:23:04,032 --> 01:23:06,900
regression or a Bayesian graph

1814
01:23:07,400 --> 01:23:10,768
constraining on that model structure

1815
01:23:10,944 --> 01:23:13,480
which in the variational inference world

1816
01:23:13,550 --> 01:23:16,136
we just call Q. It's just the

1817
01:23:16,158 --> 01:23:18,856
variational distribution, the one that

1818
01:23:18,878 --> 01:23:20,760
we are getting to choose, the family

1819
01:23:20,830 --> 01:23:23,256
that we're parameterizing it from. So

1820
01:23:23,278 --> 01:23:26,076
it's like our designer symbolic model

1821
01:23:26,258 --> 01:23:29,484
and why the data come in.

1822
01:23:29,602 --> 01:23:32,508
So then free energy, which is the

1823
01:23:32,594 --> 01:23:35,592
imperative for inclination, whether it's

1824
01:23:35,656 --> 01:23:38,992
the real time variation of free energy

1825
01:23:39,126 --> 01:23:43,036
happening right now or it's the planned

1826
01:23:43,068 --> 01:23:46,656
or anticipated expected free energy in

1827
01:23:46,678 --> 01:23:50,272
either of those cases, for a given

1828
01:23:50,406 --> 01:23:52,752
generative model, given Q distribution

1829
01:23:52,816 --> 01:23:55,076
and given set of data, you might have a

1830
01:23:55,098 --> 01:23:57,156
very high confidence in something that

1831
01:23:57,178 --> 01:24:00,260
was very inadequate. And so in that way

1832
01:24:00,330 --> 01:24:02,904
it's like there are distributions of

1833
01:24:02,942 --> 01:24:06,804
scattered plots that can confuse

1834
01:24:06,932 --> 01:24:09,544
a least squares regression or you get

1835
01:24:09,582 --> 01:24:12,244
some sort of misleading model outcome

1836
01:24:12,292 --> 01:24:14,648
and it may even be invisible. You may be

1837
01:24:14,654 --> 01:24:16,268
able to look at diagnostics of the

1838
01:24:16,274 --> 01:24:18,124
linear regression and tell that some

1839
01:24:18,162 --> 01:24:20,476
sort of error or aberration is

1840
01:24:20,498 --> 01:24:22,956
happening. But you also may not like a

1841
01:24:22,978 --> 01:24:25,710
kind of unknown unknowns question.

1842
01:24:26,080 --> 01:24:29,120
And in the case of cognitive modeling,

1843
01:24:29,780 --> 01:24:32,416
these state spaces can be very large and

1844
01:24:32,438 --> 01:24:35,490
they're often trained with sparse data.

1845
01:24:35,940 --> 01:24:39,516
So this problem of overfitting

1846
01:24:39,708 --> 01:24:41,580
and conditional and dynamics

1847
01:24:41,660 --> 01:24:44,116
relationships so that something can be

1848
01:24:44,138 --> 01:24:46,292
like true and trained upon for 100 video

1849
01:24:46,346 --> 01:24:48,196
frames and then something chance, and

1850
01:24:48,218 --> 01:24:51,044
then there's a nonlinear change in what

1851
01:24:51,082 --> 01:24:53,716
can happen next or how things unfold

1852
01:24:53,748 --> 01:24:55,576
through time. So that's kind of like the

1853
01:24:55,598 --> 01:24:57,720
complexity of action.

1854
01:24:58,140 --> 01:25:01,560
And perhaps could you speak to

1855
01:25:01,630 --> 01:25:04,716
how action is represented or treated or

1856
01:25:04,738 --> 01:25:07,944
how the concept of action selection

1857
01:25:07,992 --> 01:25:09,596
and planning and strategy and

1858
01:25:09,618 --> 01:25:12,140
implementation impact? How did these

1859
01:25:12,290 --> 01:25:14,750
features develop in sumo through time?

1860
01:25:21,530 --> 01:25:23,158
I think there was more to that question.

1861
01:25:23,244 --> 01:25:25,686
It sounds like Daniel maybe having some

1862
01:25:25,708 --> 01:25:27,834
connectivity issues. That was it just

1863
01:25:27,872 --> 01:25:29,606
how did the concept of action evolve

1864
01:25:29,638 --> 01:25:33,654
through time? How does the concept

1865
01:25:33,702 --> 01:25:37,166
yeah, let's see. There was a

1866
01:25:37,188 --> 01:25:39,054
lot packed into your question. I'm not

1867
01:25:39,092 --> 01:25:42,446
sure I grasped most of it, but let me

1868
01:25:42,468 --> 01:25:44,686
just maybe make I'll give myself a

1869
01:25:44,708 --> 01:25:49,346
related question, which is how

1870
01:25:49,368 --> 01:25:51,506
do we handle the fact that sometimes in

1871
01:25:51,528 --> 01:25:53,106
machine learning systems, the

1872
01:25:53,128 --> 01:25:55,506
mathematics has such linearities that we

1873
01:25:55,528 --> 01:25:57,330
get nonsensical conclusions?

1874
01:25:59,290 --> 01:26:01,560
I think that's a fairly common problem.

1875
01:26:02,170 --> 01:26:05,542
So I think that the interaction between

1876
01:26:05,676 --> 01:26:07,846
these two models of the world, the

1877
01:26:07,868 --> 01:26:10,578
statistically machine learning derived

1878
01:26:10,674 --> 01:26:14,202
model and the symbolic model, is really

1879
01:26:14,256 --> 01:26:16,714
important so that our machines don't go

1880
01:26:16,752 --> 01:26:18,858
off the rails, as it were. I'm using a

1881
01:26:18,864 --> 01:26:21,738
term called cognitive guardrails, and I

1882
01:26:21,744 --> 01:26:23,500
think this applies well to people.

1883
01:26:24,130 --> 01:26:27,342
People have instinctive action to many

1884
01:26:27,396 --> 01:26:31,006
things, and we have at the same time a

1885
01:26:31,108 --> 01:26:33,870
generative cognitive mind that

1886
01:26:33,940 --> 01:26:36,366
constrains those reactions. We might

1887
01:26:36,388 --> 01:26:38,686
react emotionally and react badly to

1888
01:26:38,708 --> 01:26:40,286
something that sort of triggers us in

1889
01:26:40,308 --> 01:26:42,098
some way, but then we have another

1890
01:26:42,184 --> 01:26:44,418
process in our head that says, well,

1891
01:26:44,584 --> 01:26:46,898
we're in a social situation. And so,

1892
01:26:46,984 --> 01:26:48,482
no, I don't want to punch this person

1893
01:26:48,536 --> 01:26:49,826
that's offended me, even though I might

1894
01:26:49,848 --> 01:26:53,462
be tempted to do so. If we have a self

1895
01:26:53,516 --> 01:26:56,086
driving car that sees an object in front

1896
01:26:56,108 --> 01:26:58,646
of it, my initial reaction might to be

1897
01:26:58,668 --> 01:27:01,846
to plow through it, but the Costa to

1898
01:27:01,868 --> 01:27:04,038
doing so might be very high. So maybe I

1899
01:27:04,044 --> 01:27:07,306
want to swerve or brain gradually. And

1900
01:27:07,328 --> 01:27:08,986
having this interaction between these

1901
01:27:09,008 --> 01:27:11,786
two models, I think can address some of

1902
01:27:11,808 --> 01:27:14,410
this problem that we see with

1903
01:27:14,480 --> 01:27:17,482
nonlinearities of Modern machine

1904
01:27:17,546 --> 01:27:20,142
learning systems that do work really

1905
01:27:20,196 --> 01:27:22,062
well in a lot of common cases and then

1906
01:27:22,116 --> 01:27:24,154
sometimes just veer off into infinity,

1907
01:27:24,202 --> 01:27:25,678
as it were, and do something completely

1908
01:27:25,764 --> 01:27:26,750
ridiculous.

1909
01:27:28,790 --> 01:27:32,126
Yes, I appreciate that response.

1910
01:27:32,158 --> 01:27:34,574
I think it's exactly like you described

1911
01:27:34,622 --> 01:27:37,838
with overfitting to the meaning

1912
01:27:38,014 --> 01:27:40,334
and going off the rails from a cognitive

1913
01:27:40,382 --> 01:27:42,846
perspective. There's like the known

1914
01:27:42,878 --> 01:27:45,478
unknown variants as. And example

1915
01:27:45,564 --> 01:27:47,766
especially there's University of

1916
01:27:47,788 --> 01:27:50,726
Wyoming, I think did a nice paper maybe

1917
01:27:50,908 --> 01:27:52,298
quite a while back now, probably at

1918
01:27:52,304 --> 01:27:59,964
least five years back, that would

1919
01:28:00,002 --> 01:28:02,956
say, yes, it's a cat or a dog because it

1920
01:28:02,978 --> 01:28:04,876
was just training on sort of a

1921
01:28:04,898 --> 01:28:08,844
coincidental feature of pixels that

1922
01:28:08,882 --> 01:28:11,292
maybe approximated the fur of the

1923
01:28:11,346 --> 01:28:15,084
animal. And so it couldn't recognize it

1924
01:28:15,122 --> 01:28:17,056
recognized a test pattern as being a

1925
01:28:17,078 --> 01:28:18,880
cat, and it couldn't recognize a simple

1926
01:28:18,950 --> 01:28:20,704
cartoon drawing as a cat because it

1927
01:28:20,742 --> 01:28:22,324
never Beren anything like that and

1928
01:28:22,362 --> 01:28:24,816
wasn't looking at the essential features

1929
01:28:24,848 --> 01:28:28,132
of the world. And so machines are really

1930
01:28:28,186 --> 01:28:31,156
great at finding correlations, but that

1931
01:28:31,178 --> 01:28:32,212
doesn't mean they're the right

1932
01:28:32,266 --> 01:28:33,896
correlations. And I think that's ant the

1933
01:28:33,918 --> 01:28:36,490
root of a lot of things that we call

1934
01:28:38,220 --> 01:28:41,416
overtraining or overfitting, but we

1935
01:28:41,438 --> 01:28:43,704
never know, really, whether it's fit

1936
01:28:43,742 --> 01:28:46,732
correctly or overfit. Sure there's some

1937
01:28:46,866 --> 01:28:49,804
numeric measures that at times can tell

1938
01:28:49,842 --> 01:28:52,412
you. Okay, we're bouncing out of this

1939
01:28:52,466 --> 01:28:56,044
local minimum and our

1940
01:28:56,082 --> 01:28:58,684
fidelity has gone down numerically. But

1941
01:28:58,722 --> 01:29:00,556
we don't know what that really means in

1942
01:29:00,578 --> 01:29:02,444
respect to the common sense, larger

1943
01:29:02,492 --> 01:29:04,144
world that is represented by something

1944
01:29:04,182 --> 01:29:06,112
that's much larger than any given test

1945
01:29:06,166 --> 01:29:08,944
set that we might be training on. So I

1946
01:29:08,982 --> 01:29:11,364
think that having a sort of completely

1947
01:29:11,482 --> 01:29:13,972
different representation of the world

1948
01:29:14,026 --> 01:29:15,764
can help guard against some of this.

1949
01:29:15,802 --> 01:29:18,096
And so I thought of using machine

1950
01:29:18,128 --> 01:29:20,660
learning and symbolic systems together

1951
01:29:20,730 --> 01:29:24,320
where the symbolic system addresses

1952
01:29:24,400 --> 01:29:28,056
problems in the input data because

1953
01:29:28,238 --> 01:29:31,192
faulty input data, erroneous input data

1954
01:29:31,326 --> 01:29:33,736
is always a big problem. How do we know

1955
01:29:33,758 --> 01:29:35,448
we're training on the right stuff? How

1956
01:29:35,454 --> 01:29:38,350
do we know that if we're training on a

1957
01:29:39,520 --> 01:29:42,476
system to diagnose check fraud, for

1958
01:29:42,498 --> 01:29:45,276
example, or credit card fraud, that we

1959
01:29:45,298 --> 01:29:47,816
don't have some bogus data that's crept

1960
01:29:47,848 --> 01:29:49,512
in here there that might have a spurious

1961
01:29:49,576 --> 01:29:51,772
correlation? We've got, say, zeroed out

1962
01:29:51,826 --> 01:29:55,024
Fields or a field of 99. That's really a

1963
01:29:55,062 --> 01:29:57,024
don't care field. But it's in the data,

1964
01:29:57,142 --> 01:29:58,736
and there's no easy way for us to

1965
01:29:58,758 --> 01:30:00,640
discover it. If we've got terabytes of

1966
01:30:00,710 --> 01:30:03,316
data, wouldn't it be nice to have a

1967
01:30:03,338 --> 01:30:05,604
common sense system that could act like

1968
01:30:05,722 --> 01:30:08,276
an intern, a human intern working at

1969
01:30:08,298 --> 01:30:10,516
warp speed, looking over all of our

1970
01:30:10,538 --> 01:30:14,184
input data to make sure we've not

1971
01:30:14,222 --> 01:30:17,444
included any inputs that are at odds

1972
01:30:17,492 --> 01:30:19,736
with what we know about the real world?

1973
01:30:19,918 --> 01:30:21,770
And then on the output side,

1974
01:30:22,300 --> 01:30:26,084
making a few inferences

1975
01:30:26,212 --> 01:30:28,812
in our symbolic system could help the

1976
01:30:28,866 --> 01:30:32,044
overall computational system not make

1977
01:30:32,082 --> 01:30:34,428
really dumb conclusions like, oh, we

1978
01:30:34,434 --> 01:30:36,136
don't know what that thing is, so let's

1979
01:30:36,168 --> 01:30:38,824
run over. It might be the conclusion

1980
01:30:38,872 --> 01:30:41,276
that a statistical system has, but we'd

1981
01:30:41,308 --> 01:30:45,696
like to have our combined agent be

1982
01:30:45,718 --> 01:30:47,376
able to trap things like that in the

1983
01:30:47,398 --> 01:30:48,620
same way that a person wouldn't

1984
01:30:48,700 --> 01:30:50,188
presumably punch somebody else who's

1985
01:30:50,204 --> 01:30:51,988
offended him because they know that

1986
01:30:51,994 --> 01:30:53,860
that's both illegal and immoral.

1987
01:30:56,280 --> 01:30:59,364
Thanks. Dave, do you want to add or ask

1988
01:30:59,402 --> 01:31:02,628
something? Yeah. A couple of the other

1989
01:31:02,714 --> 01:31:04,912
approaches that sometimes simplify

1990
01:31:05,056 --> 01:31:08,056
exactly the same kind of problems that

1991
01:31:08,158 --> 01:31:11,524
Daniel and Adam have both been cutting

1992
01:31:11,572 --> 01:31:15,560
through. One is fuzzy logic.

1993
01:31:16,560 --> 01:31:19,740
Sometimes a fuzzy solution and a

1994
01:31:19,890 --> 01:31:22,060
probabilistic evolution agree

1995
01:31:22,210 --> 01:31:25,484
numerically, but in

1996
01:31:25,522 --> 01:31:27,564
other situations they don't. And in many

1997
01:31:27,602 --> 01:31:30,888
of those cases, the fuzzy answer turns

1998
01:31:30,904 --> 01:31:33,352
out to be way back when Lufty Zodig

1999
01:31:33,416 --> 01:31:35,749
defying and reacting to situations. And

2000
01:31:36,249 --> 01:31:37,936
it wasn't until he started calling the

2001
01:31:37,958 --> 01:31:40,064
logic fuzzy that people were beating on

2002
01:31:40,102 --> 01:31:41,580
him. He was just coming up with the

2003
01:31:41,590 --> 01:31:46,784
great results. Another approach

2004
01:31:46,832 --> 01:31:50,496
that's been impressing me is David

2005
01:31:50,528 --> 01:31:53,364
Deutsch and jarrah Marletto's work in

2006
01:31:53,402 --> 01:31:55,496
Constructor theory, where they start by

2007
01:31:55,518 --> 01:31:58,116
asking what can be done and what can't

2008
01:31:58,148 --> 01:32:01,944
be done, and what does it mean

2009
01:32:01,982 --> 01:32:04,264
to do something, what does it mean to be

2010
01:32:04,302 --> 01:32:05,720
able to construct?

2011
01:32:07,840 --> 01:32:11,912
They generative the notion of catalyst,

2012
01:32:11,976 --> 01:32:15,388
for instance, as a general concept in

2013
01:32:15,554 --> 01:32:19,916
systems theory, and they've

2014
01:32:19,948 --> 01:32:22,736
just identified a lot of things that

2015
01:32:22,758 --> 01:32:24,864
people spend a lot of brain power on as

2016
01:32:24,902 --> 01:32:28,364
just simply being nonsensical. You can't

2017
01:32:28,412 --> 01:32:30,316
construct that. Therefore, you're

2018
01:32:30,348 --> 01:32:32,144
wasting your time. If you try to work

2019
01:32:32,182 --> 01:32:35,556
out how it could be done, would be

2020
01:32:35,578 --> 01:32:37,876
done with the consequences. If it could

2021
01:32:37,898 --> 01:32:40,388
be done, it just can't be. So go on to

2022
01:32:40,394 --> 01:32:41,350
something interesting.

2023
01:32:44,200 --> 01:32:46,940
Well, I'm not familiar with the latter

2024
01:32:46,960 --> 01:32:48,436
work, but I am a bit familiar with fuzzy

2025
01:32:48,468 --> 01:32:49,832
logic. And maybe I should just mention

2026
01:32:49,886 --> 01:32:52,184
that this has been another thing where

2027
01:32:52,222 --> 01:32:54,884
people that are familiar with fuzzy

2028
01:32:54,932 --> 01:32:57,916
logic wonder how you could do this in a

2029
01:32:57,938 --> 01:33:03,036
non fuzzy logic. And the

2030
01:33:03,058 --> 01:33:05,948
challenge then comes down to, again,

2031
01:33:06,114 --> 01:33:07,784
people that aren't familiar with logics

2032
01:33:07,832 --> 01:33:11,280
beyond first order. A lot of things

2033
01:33:11,350 --> 01:33:14,704
we might say about, like, John is

2034
01:33:14,742 --> 01:33:19,728
tall. Okay, and maybe John how

2035
01:33:19,734 --> 01:33:21,776
do we compute whether John is tall? We

2036
01:33:21,798 --> 01:33:24,348
have this problem of well, in a

2037
01:33:24,374 --> 01:33:26,836
traditional logic system, we would have

2038
01:33:26,858 --> 01:33:28,224
the problem that, okay, if he's above

2039
01:33:28,272 --> 01:33:30,288
6ft, he's tall. If he's below 6ft, he's

2040
01:33:30,304 --> 01:33:33,572
tall. Therefore, if he's 5ft eleven and

2041
01:33:33,626 --> 01:33:35,428
seven eight inches, he's not tall. And

2042
01:33:35,434 --> 01:33:36,712
of course, we all know from a common

2043
01:33:36,766 --> 01:33:38,148
sense point standpoint, that's

2044
01:33:38,164 --> 01:33:40,184
ridiculous. And so we'd want to use

2045
01:33:40,222 --> 01:33:44,152
fuzzy logic. But in fact, what we should

2046
01:33:44,206 --> 01:33:47,992
be able to say is that he's tall

2047
01:33:48,056 --> 01:33:50,910
with respect to a particular group.

2048
01:33:51,440 --> 01:33:54,120
And if we can make these more complex

2049
01:33:54,200 --> 01:33:57,804
statements, generally involving sets of

2050
01:33:57,842 --> 01:34:01,420
things and conditionals that are beyond

2051
01:34:01,580 --> 01:34:03,904
first order logic, we can express these

2052
01:34:03,942 --> 01:34:07,552
things perfectly well in this

2053
01:34:07,606 --> 01:34:09,472
more expressive logic. We don't always

2054
01:34:09,526 --> 01:34:11,088
have to go to fuzzy logic, because one

2055
01:34:11,094 --> 01:34:13,136
of the challenges that I think we have

2056
01:34:13,158 --> 01:34:15,316
with fuzzy logic is, again, a lot of the

2057
01:34:15,338 --> 01:34:17,428
people that did work in this sort of

2058
01:34:17,514 --> 01:34:21,796
world back almost 30. Years ago came

2059
01:34:21,818 --> 01:34:24,724
up with things that were functioning

2060
01:34:24,772 --> 01:34:27,400
well empirically as sort of hacks

2061
01:34:27,820 --> 01:34:31,432
because they didn't have data about what

2062
01:34:31,486 --> 01:34:35,272
is the actual statistical value curve of

2063
01:34:35,326 --> 01:34:38,380
Tallness. It was just somebody's guess

2064
01:34:38,450 --> 01:34:40,344
about what the curve of tallness

2065
01:34:40,392 --> 01:34:42,510
membership should be, for example.

2066
01:34:42,960 --> 01:34:46,136
So I like the notion

2067
01:34:46,248 --> 01:34:49,232
of fuzzy logic intuitively. I'm not sure

2068
01:34:49,286 --> 01:34:51,856
that I care for it so much on a

2069
01:34:51,878 --> 01:34:53,884
theoretical basis and on a practical

2070
01:34:53,932 --> 01:34:55,696
basis, there's simply another way to do

2071
01:34:55,718 --> 01:34:56,290
it.

2072
01:34:59,060 --> 01:35:01,184
Very interesting. Dave, want to add

2073
01:35:01,222 --> 01:35:04,224
anything? Yeah.

2074
01:35:04,262 --> 01:35:08,564
Now, if we have time, this is a

2075
01:35:08,602 --> 01:35:11,796
much deeper question about the way the

2076
01:35:11,818 --> 01:35:15,128
sumo rules are written is,

2077
01:35:15,294 --> 01:35:18,644
do we have time to go in a lot of depth

2078
01:35:18,692 --> 01:35:19,800
in this venue?

2079
01:35:22,380 --> 01:35:24,452
Not necessarily breadth, not necessarily

2080
01:35:24,516 --> 01:35:26,924
a big answer, but okay, I'll just ask

2081
01:35:26,962 --> 01:35:31,256
this reading through the rule,

2082
01:35:31,448 --> 01:35:37,900
a number of rules have very

2083
01:35:37,970 --> 01:35:41,410
specifically asked in the first

2084
01:35:41,860 --> 01:35:45,084
participant of a relation

2085
01:35:45,212 --> 01:35:48,304
if the following holds, then the

2086
01:35:48,342 --> 01:35:51,168
following logic applies. If a different

2087
01:35:51,254 --> 01:35:56,944
set of conditions on the recipient

2088
01:35:56,992 --> 01:35:59,300
of action, indirect object or direct

2089
01:35:59,370 --> 01:36:03,124
object of a process hold,

2090
01:36:03,242 --> 01:36:05,568
then you can apply the following logic

2091
01:36:05,664 --> 01:36:07,288
and I look at that and I say wait a

2092
01:36:07,294 --> 01:36:10,632
minute, these different rules are

2093
01:36:10,686 --> 01:36:13,224
splitting off very different kind of

2094
01:36:13,262 --> 01:36:17,116
real world situations within the same

2095
01:36:17,218 --> 01:36:20,888
Sumo class. Well there's

2096
01:36:20,904 --> 01:36:23,068
got to be two things have to be true in

2097
01:36:23,074 --> 01:36:25,564
order to do that, in order to find these

2098
01:36:25,682 --> 01:36:28,464
differentiating rules within a single

2099
01:36:28,502 --> 01:36:31,360
class. First, you call those by the same

2100
01:36:31,430 --> 01:36:34,976
name in whatever natural languages you

2101
01:36:34,998 --> 01:36:36,576
were thinking in when you wrote the

2102
01:36:36,598 --> 01:36:40,240
rules. And second, the formal

2103
01:36:41,160 --> 01:36:45,300
literally the abstract algebra of these

2104
01:36:45,370 --> 01:36:48,596
various cases have to all be

2105
01:36:48,778 --> 01:36:50,516
analogous, they all have to be

2106
01:36:50,538 --> 01:36:54,392
isomorphic. And my name for that

2107
01:36:54,446 --> 01:36:57,332
situation is you're covering analogical

2108
01:36:57,396 --> 01:37:00,744
cases in the same Sumo class and in that

2109
01:37:00,782 --> 01:37:04,424
sense the Sumo class itself is and

2110
01:37:04,462 --> 01:37:07,660
analogy, it's an analogy among these

2111
01:37:07,730 --> 01:37:11,496
various cases which in different domains

2112
01:37:11,528 --> 01:37:14,684
of applause. Am I just

2113
01:37:14,722 --> 01:37:18,704
not thinking discerningly enough about

2114
01:37:18,822 --> 01:37:21,248
what a Sumo class represents or can a

2115
01:37:21,254 --> 01:37:25,600
Sumo class actually be a higher analogy?

2116
01:37:29,060 --> 01:37:30,588
It's hard for me to know because there's

2117
01:37:30,604 --> 01:37:32,208
no analogical reasoning happening so I'm

2118
01:37:32,214 --> 01:37:34,268
not sure you're talking about analogies

2119
01:37:34,364 --> 01:37:36,112
and there's no natural language

2120
01:37:36,176 --> 01:37:37,584
happening once you're in the formal

2121
01:37:37,632 --> 01:37:38,868
system. So I'm not sure why you

2122
01:37:38,874 --> 01:37:41,008
mentioned natural language. I think we'd

2123
01:37:41,024 --> 01:37:43,156
have to look at a very specific example

2124
01:37:43,338 --> 01:37:47,076
and then we could run

2125
01:37:47,098 --> 01:37:48,648
that example on a theorem proof and

2126
01:37:48,654 --> 01:37:50,324
you'd see exactly how things behave.

2127
01:37:50,372 --> 01:37:53,450
It's not something about classes per se.

2128
01:37:54,140 --> 01:37:56,296
You just mentioned how the rules work in

2129
01:37:56,318 --> 01:37:59,064
a logic. You've got preconditions for

2130
01:37:59,102 --> 01:38:00,920
the antecedent of a rule and you've got

2131
01:38:01,070 --> 01:38:03,180
the coherence of a rule and yes indeed

2132
01:38:03,520 --> 01:38:06,204
the symbols in that formal system have

2133
01:38:06,242 --> 01:38:08,510
to match. That's how logic works,

2134
01:38:09,680 --> 01:38:11,836
right? I'll get some specific examples

2135
01:38:11,868 --> 01:38:14,290
of an email to you. Okay, sounds great

2136
01:38:15,140 --> 01:38:18,928
in our last minutes. Here and also

2137
01:38:19,014 --> 01:38:22,660
apologies for the internet disrupt.

2138
01:38:24,200 --> 01:38:28,384
This is part of our long term journey

2139
01:38:28,512 --> 01:38:30,388
learning about this and applying it

2140
01:38:30,394 --> 01:38:32,468
active inference lab. So we're going to

2141
01:38:32,474 --> 01:38:35,304
keep this thread alive and be able to

2142
01:38:35,502 --> 01:38:38,776
bring some more informed areas of

2143
01:38:38,798 --> 01:38:41,144
intersection and application. But one

2144
01:38:41,182 --> 01:38:43,160
that I wanted to mention was to return

2145
01:38:43,230 --> 01:38:47,390
to your type one, type two thinking

2146
01:38:48,000 --> 01:38:51,820
and the way that there's a faster

2147
01:38:52,320 --> 01:38:56,376
reflexive or habitual statistical

2148
01:38:56,488 --> 01:38:59,948
type one inference and then a slower

2149
01:39:00,044 --> 01:39:01,872
type two, what you referred to as

2150
01:39:01,926 --> 01:39:05,024
deliberate and deductive that

2151
01:39:05,062 --> 01:39:09,004
involves symbolic logic. And in chapter

2152
01:39:09,052 --> 01:39:11,144
five of the active coherence textbook

2153
01:39:11,292 --> 01:39:15,220
there's a schematic of a Dopaminergic

2154
01:39:15,640 --> 01:39:18,116
neural circuit in the central and

2155
01:39:18,138 --> 01:39:20,816
peripheral nervous system where there's

2156
01:39:20,848 --> 01:39:23,084
a Dopamine related parameter

2157
01:39:23,232 --> 01:39:27,256
computationally that's like a dial in

2158
01:39:27,278 --> 01:39:30,340
the model that is controller the balance

2159
01:39:30,500 --> 01:39:33,944
between replicating actions according to

2160
01:39:34,062 --> 01:39:37,288
the prior like just the habit. So it's

2161
01:39:37,304 --> 01:39:38,952
some distribution of capacities,

2162
01:39:39,016 --> 01:39:40,924
affordance and then if there's three

2163
01:39:40,962 --> 01:39:44,076
options, it's zero 8.1.1.

2164
01:39:44,178 --> 01:39:47,352
So then under the most habitual setting,

2165
01:39:47,496 --> 01:39:50,764
like what we might even call nonagentic

2166
01:39:50,812 --> 01:39:54,416
or subconscious, then that vector of

2167
01:39:54,438 --> 01:39:56,844
affordances is recapitulated in action

2168
01:39:56,892 --> 01:39:59,888
selection. And then in a different

2169
01:39:59,974 --> 01:40:02,564
dopaminergic regime there is

2170
01:40:02,602 --> 01:40:06,208
increasingly fine scale and potentially

2171
01:40:06,304 --> 01:40:10,132
overfit application of the free

2172
01:40:10,186 --> 01:40:12,848
energy. And that can reflect like a

2173
01:40:13,034 --> 01:40:16,292
symbolically informed, deep generative

2174
01:40:16,356 --> 01:40:18,868
model of the world which captures

2175
01:40:18,964 --> 01:40:21,076
semantics of the world like nested

2176
01:40:21,108 --> 01:40:23,604
timescales and temporal priority

2177
01:40:23,652 --> 01:40:26,764
effects. So it's interesting that this

2178
01:40:26,802 --> 01:40:30,184
area, while deep hierarchical generative

2179
01:40:30,232 --> 01:40:33,324
models often are described as if they

2180
01:40:33,362 --> 01:40:36,444
have semantic value. However, that is

2181
01:40:36,482 --> 01:40:39,872
usually just sort of specified or only

2182
01:40:39,926 --> 01:40:42,572
explored in a few limited cases.

2183
01:40:42,716 --> 01:40:45,968
So integrating and working at that

2184
01:40:46,054 --> 01:40:48,812
mapping between the top down symbolic

2185
01:40:48,876 --> 01:40:52,068
and the bottom up data driven is going

2186
01:40:52,074 --> 01:40:54,356
to be a really important, interesting

2187
01:40:54,458 --> 01:40:58,212
area. So as a closing round or

2188
01:40:58,266 --> 01:41:01,236
question, what do you see in the

2189
01:41:01,258 --> 01:41:04,868
ecosystem and or what directions, if you

2190
01:41:04,874 --> 01:41:06,436
didn't state them earlier, you're

2191
01:41:06,468 --> 01:41:09,050
working on this year?

2192
01:41:10,300 --> 01:41:12,552
Well, yeah, the generative AI stuff

2193
01:41:12,606 --> 01:41:15,610
certainly got huge amount of press.

2194
01:41:16,720 --> 01:41:18,792
It's fascinating as an intellectual

2195
01:41:18,856 --> 01:41:21,304
exercise, certainly. And it's

2196
01:41:21,352 --> 01:41:25,112
fascinating to have systems

2197
01:41:25,256 --> 01:41:27,484
that can complete sentences and write

2198
01:41:27,522 --> 01:41:30,928
stories and always have an answer to a

2199
01:41:30,934 --> 01:41:32,976
question. But as we're seeing with a lot

2200
01:41:32,998 --> 01:41:36,668
of newer things that are being written

2201
01:41:36,684 --> 01:41:39,184
as follow ups to all the excitement that

2202
01:41:39,222 --> 01:41:42,016
people are showing how these systems

2203
01:41:42,048 --> 01:41:43,764
will give you an answer, but it's often

2204
01:41:43,802 --> 01:41:46,836
a complete hallucination. Right. So one

2205
01:41:46,858 --> 01:41:48,964
recently of saying, well, you know,

2206
01:41:49,002 --> 01:41:51,990
Hillary Clinton was the 43rd president.

2207
01:41:53,260 --> 01:41:55,704
Well, it came up with that somehow by

2208
01:41:55,742 --> 01:41:58,024
foraging together various texts that

2209
01:41:58,062 --> 01:41:59,176
other people have written, but it

2210
01:41:59,198 --> 01:42:00,664
doesn't make sense together. It's not

2211
01:42:00,702 --> 01:42:01,290
true.

2212
01:42:05,100 --> 01:42:07,868
I think these systems are interesting in

2213
01:42:07,874 --> 01:42:11,612
the way that a parrot can

2214
01:42:11,666 --> 01:42:14,716
have a very limited conversation. You

2215
01:42:14,738 --> 01:42:16,716
can teach your Parr how to say Polly ant

2216
01:42:16,738 --> 01:42:18,428
a cracker and say thank you and you give

2217
01:42:18,434 --> 01:42:19,744
it a cracker. That doesn't mean it

2218
01:42:19,782 --> 01:42:21,456
actually understands anything about what

2219
01:42:21,478 --> 01:42:23,052
it's doing. It's just a stimulus

2220
01:42:23,116 --> 01:42:26,256
response. Now, first there

2221
01:42:26,278 --> 01:42:27,808
is a philosophical question if the

2222
01:42:27,814 --> 01:42:30,604
stimulus response pairing is complicated

2223
01:42:30,652 --> 01:42:32,764
enough. Well, isn't our human beings

2224
01:42:32,812 --> 01:42:34,544
also just collections of stimulus and

2225
01:42:34,582 --> 01:42:37,008
response? That may be true, but I don't

2226
01:42:37,024 --> 01:42:38,752
think we're at that level of complexity

2227
01:42:38,816 --> 01:42:40,996
yet for our machines. And I think some

2228
01:42:41,018 --> 01:42:43,124
of the things that we can get these

2229
01:42:43,162 --> 01:42:45,364
generative models to do that are so

2230
01:42:45,402 --> 01:42:47,544
obviously nonsensical human are good

2231
01:42:47,582 --> 01:42:50,840
evidence that they're certainly not

2232
01:42:50,990 --> 01:42:52,936
sentient and they're not even smart and

2233
01:42:52,958 --> 01:42:54,584
they're certainly not very reliable. If

2234
01:42:54,622 --> 01:42:57,884
we have very challenging or high

2235
01:42:57,922 --> 01:43:00,604
criticality tasks to worry about, I

2236
01:43:00,642 --> 01:43:03,500
think they'll be useful in the same way

2237
01:43:03,570 --> 01:43:05,976
that Google search is useful. It doesn't

2238
01:43:06,008 --> 01:43:08,008
always get the right answer, it will

2239
01:43:08,114 --> 01:43:11,136
universally get many wrong answers, but

2240
01:43:11,158 --> 01:43:14,576
it's very powerful and useful tool when

2241
01:43:14,598 --> 01:43:17,440
you have a human being available to

2242
01:43:17,510 --> 01:43:21,264
filter out all the nonsense and just

2243
01:43:21,462 --> 01:43:24,888
use that as a filter for what they'd

2244
01:43:24,924 --> 01:43:27,264
otherwise have to do. It's not feasible

2245
01:43:27,312 --> 01:43:28,996
for a human being to answer question by

2246
01:43:29,018 --> 01:43:30,672
reading all the books in the library.

2247
01:43:30,816 --> 01:43:34,020
But if Google can give you ten books and

2248
01:43:34,090 --> 01:43:36,296
ten pages in those ten books where your

2249
01:43:36,318 --> 01:43:38,088
answer may be found, it's done you a

2250
01:43:38,094 --> 01:43:40,024
great service, even though it's given

2251
01:43:40,062 --> 01:43:43,284
you Winnie Lapoo along with the Handbook

2252
01:43:43,332 --> 01:43:45,416
of Analytical or Organic Chemistry or

2253
01:43:45,438 --> 01:43:48,044
something where your actual answer is

2254
01:43:48,082 --> 01:43:50,956
found. So in that same way,

2255
01:43:51,138 --> 01:43:54,172
Chat GBT might be very useful in

2256
01:43:54,306 --> 01:43:56,252
breaking your writer's block to help

2257
01:43:56,306 --> 01:43:58,716
write the summary for a proposal or a

2258
01:43:58,738 --> 01:44:00,728
student essay, but you certainly don't

2259
01:44:00,744 --> 01:44:02,204
want to have it write the whole essay

2260
01:44:02,252 --> 01:44:03,836
for you and hand it in because you'll

2261
01:44:03,868 --> 01:44:06,784
probably fail. So I'm not quite as

2262
01:44:06,822 --> 01:44:09,520
worried about high school or college

2263
01:44:09,590 --> 01:44:12,800
essays as some commentators have been.

2264
01:44:12,950 --> 01:44:14,848
I think it'll be a useful partner, and

2265
01:44:14,854 --> 01:44:16,116
that's about all. And we've got to

2266
01:44:16,138 --> 01:44:18,464
understand these limitations and ideally

2267
01:44:18,512 --> 01:44:20,244
pair it with a symbolic system that

2268
01:44:20,282 --> 01:44:21,764
really knows something about the real

2269
01:44:21,802 --> 01:44:23,430
world so that they can work together.

2270
01:44:25,260 --> 01:44:28,488
Awesome. Dave first,

2271
01:44:28,574 --> 01:44:31,940
and then Adam, what are your closing

2272
01:44:32,020 --> 01:44:33,480
thoughts or reflections?

2273
01:44:38,560 --> 01:44:41,084
I've enjoyed this very much. We've got

2274
01:44:41,122 --> 01:44:43,580
lots of work to plow forward and do.

2275
01:44:43,650 --> 01:44:46,380
I'm glad there's going to be comma work

2276
01:44:46,450 --> 01:44:50,670
that we can

2277
01:44:51,380 --> 01:44:53,792
become affordances for one another on.

2278
01:44:53,846 --> 01:44:54,960
Thank you, gentlemen.

2279
01:44:58,820 --> 01:45:00,864
Well, thank you, Dave, for the good

2280
01:45:00,902 --> 01:45:03,216
questions, good comments, and Daniel as

2281
01:45:03,238 --> 01:45:06,036
well, and for setting this up. I guess I

2282
01:45:06,058 --> 01:45:08,180
would encourage what I've maybe

2283
01:45:08,250 --> 01:45:10,836
encouraged in the past is a lot of the

2284
01:45:10,858 --> 01:45:12,948
things that we've talked about in these

2285
01:45:13,034 --> 01:45:16,452
several conversations we've had are

2286
01:45:16,506 --> 01:45:19,464
general, right? We're saying, what's an

2287
01:45:19,502 --> 01:45:21,976
overarching direction for the field or

2288
01:45:21,998 --> 01:45:24,264
something? And I think that if we got

2289
01:45:24,302 --> 01:45:26,996
down into some real specific examples

2290
01:45:27,028 --> 01:45:28,992
and actually doing some representation

2291
01:45:29,076 --> 01:45:32,252
together, then a lot of these more

2292
01:45:32,306 --> 01:45:34,684
philosophical notions would go away and

2293
01:45:34,722 --> 01:45:36,604
we'd get down to doing something that

2294
01:45:36,722 --> 01:45:39,340
has practical utility. That's why I also

2295
01:45:39,410 --> 01:45:43,596
encourage actually having, if people

2296
01:45:43,778 --> 01:45:46,204
do, say, some of the sumo exercises

2297
01:45:46,252 --> 01:45:48,208
together, because I think, Dave, some of

2298
01:45:48,214 --> 01:45:50,304
the questions that you were having over

2299
01:45:50,502 --> 01:45:53,216
what is a rule? How is it working? I can

2300
01:45:53,238 --> 01:45:54,964
answer all those questions and give you

2301
01:45:55,002 --> 01:45:57,396
some very precise experience that would

2302
01:45:57,418 --> 01:46:01,284
give you a real, actual understanding of

2303
01:46:01,322 --> 01:46:04,756
how logic works and how sumo works. If

2304
01:46:04,778 --> 01:46:07,204
we took the time together to go through

2305
01:46:07,242 --> 01:46:09,236
those exercises, do some work with the

2306
01:46:09,258 --> 01:46:10,756
theorem prover, and it would clear up,

2307
01:46:10,778 --> 01:46:12,292
I think, a lot of maybe

2308
01:46:12,346 --> 01:46:15,668
misunderstandings or misconceptions and

2309
01:46:15,754 --> 01:46:17,252
give us a real path to do something

2310
01:46:17,306 --> 01:46:19,596
concrete together. Because although the

2311
01:46:19,618 --> 01:46:22,876
talking is great fun, it's the doing and

2312
01:46:22,898 --> 01:46:24,652
writing a practical computational system

2313
01:46:24,706 --> 01:46:27,004
that hopefully we all want to get to.

2314
01:46:27,202 --> 01:46:30,904
As the Jesuits say, “Let us descend

2315
01:46:31,032 --> 01:46:34,684
into the particular.” Yes. That's great.

2316
01:46:34,722 --> 01:46:38,040
I love it. Great ending the stream.


