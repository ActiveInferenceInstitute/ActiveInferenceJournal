SPEAKER_00:
hello and welcome everyone it is june 13th 2022 and we're here in actinv lab guest stream number 23.1 with maxwell and dalton we're talking about rebooting the free energy principle literature and their recent publication so i'll pass it to the two of you to provide just an initial introduction and some context for the paper before we jump into some specific parts

Maxwell first.


SPEAKER_05:
Cool.

My name is Maxwell Ramstad.

I'm the director of research at the versus research lab, where we specialize in probabilistic approaches to artificial intelligence.

And of late, most of my research has been on the physics foundations of the free energy principle.

And yeah, very, very much looking forward to having this conversation.


SPEAKER_01:
Awesome.

And Dalton?

Sure.

Okay.

Well, I'm Dalton.

I'm a mathematician and a physicist.

So right now I'm at Stony Brook University in New York.

I'm also at the Versys Lab where we're doing some work on the free energy principle.

Right now, my research interests are about formal approaches to biological physics and mathematical foundations of complex systems and these kinds of questions.

One of the most interesting frameworks in this sphere is the free energy principle.

And that's how I've gotten involved in this literature.


SPEAKER_00:
Awesome.

So maybe in the same order, what brought us to this paper?

What was the gap that this paper stepped into and how did this team arise around the paper?

And I'll bring it up on the screen as well.

It's a good question.


SPEAKER_05:
Well, I think the paper does a bunch of different things.

The first, I mean, we've presented this as rebooting the free energy principle literature.

i think uh yeah over the last it's it's been almost two decades now since uh the fup has been a thing uh i think the first paper was circa 2005-ish and the framework or the the field of study that is emerged around the free energy principle has um changed a lot over the last two decades no small part

in terms of the self-understanding that we have as a community of practitioners working with these techniques.

And I mean, as Dalton pointed out a while back, I think the last time that really the FUP literature had been surveyed in a systematic fashion to kind of present where we were at, where we are currently, like the state of the art, was probably Carl's

monograph from 2019 january 2019 um i mean you know both of you were part of this international physics reading group that we had uh this was not this was not a simple uh piece to read and uh yeah since then um there hasn't really been uh basically a summary of where the literature is so on the one hand we were aiming to uh

reboot the literature to basically summarize the ways that the free energy principle had been applied in the literature and to also present a lot of the progress that had been made over the last three years, a lot of which is due to Delta.

So I think that segues nicely into the Delta.


SPEAKER_01:
Well, too generous by far, as usual.

But yeah, so Maxwell raises a good point that there hasn't been really an effort to tie together all the different threads since probably 2019.

And one of the reasons why, I mean, that's a long time, but it's not overly long.

However, in the last couple of years, there have been some pretty serious advances in the state of the mathematics and the physics behind the free energy principle.

So now, you know, three years later, we're in 2022.

It's not a long time, but nevertheless, there have been big developments that really have

uh beg this kind of a survey to be done and so that was one of the aims at least of the paper was to draw together all the different threads to unify them make them a bit more cohesive and and present the free energy principle as we're conceptualizing it today in a very top to bottom fashion


SPEAKER_00:
before we jump into the sections and the arguments and the claims in the paper which i'm sure will cover a lot of these updates i'd just love to hear what is the free energy principle what is active inference and how are they related i mean i guess in the most general sense the free energy principle uh


SPEAKER_05:
is a statement that says that we can understand the dynamics of self-organizing systems as following a path of least surprisal in the most general sense.

And then in that context, it's good that you asked the question.

I think that there are at least two uses of the term active inference in the literature.

The one that I've tended to use is a very broad sense, which is just like active inference is specifying a path of least action for what are called autonomous states.

So like the active and internal states of systems that are considered things under the free energy formulation.

Active inference has also been used to refer to a class of specific partially observable Markov decision process models that have been deployed.

And most of the implement in silico implementations of the free energy principle rely on these.

I think this has led to a little bit of confusion in that when folks say,

Active inference is a general theory that's able to account for self-organization.

They're not saying this specific class of POMDP models is effectively repurposable for everything.

So yeah, I would say the first sense that I outlined is the sense in which we say that active inference is a corollary of the free energy principle.

And yeah, I mean, in its most general form, the free energy principle is just a statement, an alternative statement or a restatement of the principle of stationary action, where the action is defined as a surprisal, in effect.


SPEAKER_00:
Great.

Dalton, same questions to you.


SPEAKER_01:
Yeah, I think Maxwell pretty much covered it.

So as I mentioned, my background is actually not in the free energy principle, not originally, and it's not even in machine learning.

So I have come at this literature with a bit of a different set of

ideas and traditions and tools.

And so as a result, I can't really talk about active inference.

I'm not totally familiar with it, but I can talk about the free energy principle at length.

I'll try to be brief.

So to me, the free energy principle is a statement that random dynamical systems do, on average, unsurprising things.

And it's a very simple statement.

All it means is that if you have a random dynamical system and it's trying to get to some place in state space, that is not surprising to it.

So some preferred region of state space, maybe a particular phenotype

maybe a particular morphological blueprint something like this the free energy principle is a statement of not only that that happens but also a set of tools to model how that happens how do systems get to these kinds of attractors and there's this very interesting way in which

the getting to that attractor can be read as inference.

And this is where all these connections in literature appear to things like active inference.

You can talk about how systems actually get themselves to that attractor as a perception and action problem.

And you can model it using this very famous variational free energy bound.

And you can show, okay, when the system is encoding some sort of belief about its environment and about itself,

When it does this inference, you have the minimization of some upper bound on surprisal.

So the system is at least doing unsurprising things at the level of, you know, it's not exceeding some kind of intrinsic surprisal.

That's some of the early formulations.

Some of the more recent formulations take it even further, and you say the surprisal, full stop of some trajectory of the system is going to be minimized by the system.

So it's going to take...

on average, the system is going to do what it expects to do, which in this case is get to some region in the state space that it prefers to inhabit.

What makes that not a tautology and what makes it something that we can actually operationalize and ask interesting questions about

is the fact that there is this nice connection to inference.

There are all of these explicit mathematical tools that we can use to talk about surprise minimization, not just as the kind of information theoretic statement of systems that aren't surprising or systems that aren't surprised.

do unsurprising things it ends up a little bit more nuanced than that and so so to me the free energy principle is this whole host of results about random dynamical systems and especially random dynamical systems which are organized or which self-organize i think that is uh how i would think of it and it's and it's got some physics and uh stuff that that we can actually talk about in that context


SPEAKER_00:
Awesome, thanks both for those great answers.

I'm pulling up the paper and so many things in what you said, I just wanted to follow up on, but let's follow the main line of the paper and wherever you think there's some dots that could be connected or any questions arising or areas of future research or the connection to applications that you're working on or other people might think about getting involved in, we can just take those little cul-de-sacs from the main line.

So I have the paper up.

on Bayesian mechanics of physics of and by beliefs.

The two of you are the first authors.

There's also Connor Hines, Magnus Kudal, Baron Millage, Lancelot da Costa, Brennan Klein, and Carl Friston.

Any just overview notes on, again, like what led to this team or anything like that while we're on this first page?


SPEAKER_05:
Well,

From my perspective, Dalvin and I have been talking a lot about this kind of stuff for the last year, year and a half, two years.

And yeah, I won't try to, I'll try not to be too,

overly generous, Dalton, but like, I think, yeah.

So some of Dalton's work has, I think, changed the way that we think about the FEP

in particular um what what dalton did in this great paper towards a geometry and analysis uh for uh bayesian mechanics is to show that the free energy principle and the principle of constrained maximum entropy are actually uh dual to each other they are two sides of the same coin um and i i you know i i've been um i've been following this line of

uh, work for, uh, quite some time.

And I think it, it foundationally changes the way that we think about the FEP.

It moves it from like this, um, some might say exotic result from, you know, theoretical, uh, neurobiology to, uh, you know, it connects it back up to, um, the foundations of contemporary physics effectively by showing that, you know, uh,

this thing that we understand and almost take for granted, you know, maximum entropy inference procedures turn out to connect up to this free energy literature in a non-trivial way.

So I think the paper started out and it didn't end this way, but I think we started off trying to write a reader friendly companion to the work that Dalton had done.

But by the end of it, realized that this was more

I think Dalton's paper towards the geometry and analysis for Bayesian mechanics, Hiller's, I think it stands on its own as a piece of mathematical reasoning.

So it is an exercise in maximum entropy inference math, and it shows that you can recover

some of the really core results of the free energy formulation, just using the language of constrained maximum entropy.

In particular, Dalton approves the approximate Bayesian inference lemma that had, you know, caused so much discussion in our literature for the last bit.

And so, you know, I think the paper grew out of that.

And yeah, the team is something of a who's who of like the,

know the the core contributors to this literature and just from a strategic point of view it was important for us to have like you know alliance da costa uh carl friston you know connor heinz and folks that had been uh i think contributing to this core formulation and in particular to the development of uh you know this new framing of the free energy stuff a bayesian mechanics um

So yeah, I think that the paper grew out of that.

And if Dalton's paper is this Dalton's stent towards the geometry and analysis for Bayesian mechanics is a kind of standalone piece of mathematical reasoning, this is more about how this actually fits into the free energy principle literature.

So this is very much more a free energy principle literature paper.

And yeah, we were hoping to do as reader-friendly an introduction as we could.

There are actually two whole kind of introductory sections in the paper.

But we ended up doing a lot of, I think, important work in that paper connecting up to the free energy principle.

I hope that helps answer me.


SPEAKER_00:
Great answer.

And welcome, Lars.

Would you like to give any overviews or notes before we jump into the sections of the paper?


SPEAKER_02:
Hey, thanks.

Thanks for sending me the link there, Maxwell, and allowing me on here.

No, nothing really to add there.

I'm just here as a spectator.

I have a few questions as we go down along, and maybe I can throw into the conversation.

But yeah, thanks for having me on.


SPEAKER_00:
awesome all right so the abstract begins with a really clear aim the aim of this paper is to introduce a field of study that has emerged over the last decade called bayesian mechanics and we're going to be unpacking that claim so suffice to say the abstract's very clear and summarizes some of the core points that we're going to delve into now we're looking now at the contents so

what led to the sections the paper being this way and in this order what did you feel like it was important to include what did you feel like it was important to introduce and why well so if you look i'll actually pull it up in front of me so that we uh we're all talking about the same thing um give me one second

And it's viewable in large size on the live stream.

So yeah, feel free to have your own copy up, but I'll have whatever section we're looking at will be very visible on the live stream.


SPEAKER_01:
While Maxwell is grabbing his copy, I'll just give a couple of contextual remarks.

So like Maxwell described, I mean, originally,

I had released this set of results about what we call approximate Bayesian inference and the sort of mathematical basis for some of the key ideas in the FEP literature, up until that point anyway.

And originally it was meant to be a much shorter paper that just dissected some of those results and related them back to the FEP in a way that was a little more concrete and a way that people who actually work on the FEP might care a little more about, because of course the stuff that I wrote about is a little far removed from the FEP, even though it's an object of inspiration.

for the results in that paper, there is a reading of that paper where it's formally pretty distinct from the FEP.

So originally, that was the goal, is just give it some extra...

physics, intuition, and some extra connection to the actual FEP.

It became something a little bit different as we were building this out and we realized, okay, there are a whole set of new results, not only mine, but also from Carl's TNB group and from other folks, and they all really should be tied together nicely.

And part of that is

the connecting the geometry and analysis paper to the actual FEP.

Part of it is actually talking about what we would think of the FEP as today.

That shaped the table of contents a little bit because a lot of what we then wanted to go and say is, okay, we have this theory of the free energy principle.

One of the key ideas in the way that we're viewing the free energy principle today is that it is just a bit of physics.

It is much like classical mechanics or statistical mechanics.

It has a set of mathematical results that sort of hang around it, that give it a nice foundation.

And it applies to specific systems and describes them in a specific way.

And that was why we began with both an overview of what is mechanics, what do we talk about in physics when we say mechanics, and also section three is what is the free energy principle?

What have we talked about so far in the literature?

And what might we define as Bayesian mechanics?

So what is the physics of beliefs or systems that carry beliefs?

So that sort of shaped the first maybe 20 pages of the papers.

It's just building out the theory and the context for the theory.

Afterwards is a bit of a sort of change in our line of attack, but you'll see it does remain very similar.

So I won't get too far ahead of myself.


SPEAKER_00:
Great.

Any other notes, Maxwell, or we can carry on?


SPEAKER_05:
I think that's a great summary.

I think we try to keep this as self-contained as possible as a paper.

The two introductory sections are meant to

provide some kind of visual intuition for a lot of the more formal results that are discussed in the paper and in the papers that it builds on.

We have the artistic brilliance of Brennan Klein that's added to this paper, so I think the illustrations help.

um the idea was that you know this based on dalton's work we are formulating basically a geometry and analysis for the core results in the free energy principle literature so we thought let's leverage uh the geometric nature of a lot of these intuitions to really illustrate them and so yeah that i think explains a lot of the structure

And the paper ends on some philosophical considerations and hopefully clarifies some of the confusions or misunderstandings, understandable misunderstandings that have arisen.

Yeah, so I think that does really address.

I guess the last thing to point out is we introduced this

field of study in the last section that we called G-theory, which is, I think, the direction that we're going to be moving in for a while, which is formulating the free energy principle in the Bayesian mechanics in terms of maximum caliber.

So extending this duality

between the density dynamics formulation of the free energy principle in terms of probability densities over states and constrained maximum entropy to path-based formulation.

So path entropy is called caliber.

And you can, Dalton is one of the few world specialists in maximum caliber.

And, yeah, maximum caliber is maximum path entropy.

So it's the same idea as maximum entropy, but you're considering the entropy of paths.

And we have had, you know, the free energy principle started off as formulated in terms of paths.

After all, it is a version of the principle of stationary action.

It leads us to write down paths of stationary action.

And so the...

the ambition now is to connect these things up much more formally so that uh we can uh we can handle really genuine non-equilibria uh things like wandering uh markov blankets and uh yeah moving attractors and all that kind of stuff which find uh you know a home much more naturally in the language of maximum caliber did you did you want to add anything to that belton you're really the max cal expert


SPEAKER_01:
No, I think that's a good account of one of the key future directions is we spend the first half introducing Bayesian mechanics.

We spend the second half talking about where Bayesian mechanics fits into the rest of statistical mechanics and high energy physics by connecting it to MaxEnt and to gauge theory.

And this is where some of the geometric stuff comes in.

And then the very last thing we do, we sort of cap it off by saying, OK, now we've talked a lot about Bayesian mechanics.

We've talked a lot about maximum entropy Bayesian mechanics.

But there is, in some sense, a much more natural formulation of Bayesian mechanics

in terms of dynamics.

Because ultimately, that's what we're thinking about, is dynamical systems and the way that they evolve in time, the way that they flow over their state space.

And there's a sense in which not only is it much more natural, mathematically it just works easier, it looks prettier, it's much nicer.

There's also a sense in which it's meaningless to talk about states of a process which is constantly in flux.

So limiting ourselves to densities over states as exists in the last couple of years of the literature, which has in fact not always been the case.

Some of the early stuff is written in terms of generalized coordinates of motion, which are nothing but a particular way of talking about dynamics and therefore paths.

So there's a sense in which the recent detour into states is very limiting, not only mathematically, but conceptually limiting.

And we can see that directly in the way that it is

handling things like non-Markovian processes or processes that change with statistics that are out of equilibrium.

So at the very end, we say, you know, we've done all this work.

The best next step is to take all of this

and all of the stuff that we've just done about maximum entropy Bayesian mechanics, and put it in dynamical terms.

And this necessitates passing to what we call maximum caliber, which is also due to James originally.

It's the principle of path entropy.

But...

Eventually, you know, the goal is we would be able to write all of this stuff.

And in particular, we'd be able to generalize what we have written into a language that's much more dynamical.

And Max Cal, we already know, has demonstrated an immense success in treating non-equilibrium processes.

So mathematically, I mean, there's reason to be very optimistic about what we will gain

when we generalize the duality that we've talked about previously.

And so it really does seem like it's the ideal thing to do in the very near future.


SPEAKER_00:
Awesome.

Let's jump into the sections.

So section one is the introduction.

And just one part that I wanted to highlight that the footnotes are so informative.

There's some of these motifs like we set out to make it as simple as possible and four pages was our limit, but then we ended up innovating this way.

So that's one funny motif.

And then the other funny motif that I see is the super informative footnote.

often because maybe it's possible to just make the claim stand alone and in direct response to somewhere else so that's very exciting and interesting like footnote one covers a lot of the prerequisite

fields like dynamical systems theory, calculus, probability, and information theory.

So I found that to be very interesting because it helps understand where we can come from and what kinds of backgrounds we'd want to be learning about.

And then also a very important distinction of the two meanings of the word belief

in the probabilistic sense of bayesian statistics or the propositional or folk understanding as you write from philosophy and cognitive science so um just thought those were two interesting footnotes and and reflected like part of the process and the discourse around the primary text and how that can be clarified in this format feel free to make any overall comments on that or that's just getting to page three


SPEAKER_05:
Well, about the prerequisites, it's a difficult balance to achieve in some sense, right?

Because we don't want to be academic gatekeepers.

No one benefits from gatekeeping.

But these are also highly technical fields.

so you know i i've been joking for you know the last few months if you've never taken a derivative you're gonna have a bad time in this literature it's just not the kind of thing that lends itself to um you know surface engagement in some sense like it's very and especially with these um

These new developments, I mean, there's Dalton's work that basically shows that the free energy principle is dual to maximum entropy, maximum caliber.

So there's this kind of deep connection to, I mean, effectively the core of contemporary physics.

And there are these new results that show that the free energy principle is asymptotically equivalent to the principle of unitarity from quantum mechanics

There are these new quantum formulations of FEP that have popped up.

So yeah, I mean,

navigating the space comfortably presupposes a lot um and the good news is that it's hard for everyone so uh there's uh there's something to learn for everyone uh you know i'd spent the last uh three years of my life teaching myself like category theory and gauge theory and stuff which turned out to be very useful uh you know connecting up with dalton and

doing all of this work, but now we're launching ourselves into quantum theory, which I'm less familiar with.

So there's something to find difficult for everyone.

But yeah, I really do think that the fully appreciate going on here.

Some technical prerequisites are important.

Otherwise, we're led to making false assertions.

I see this circulate a lot that dynamical systems approaches are contradictory to information theoretic approaches, which is just nonsense from a formal point of view.

yeah information metrics naturally re-emerge when you're considering for example uh how do you measure distances and state space effectively it's just yeah so the the more uh mathematical background one comes with i think the easier it is to integrate into this um yeah


SPEAKER_00:
Yes.

Well, indeed, there's a lot of encouraging and good news and hopefully a community that also values participation and accessibility as well.

So, agreed.

Important general points there.


SPEAKER_01:
Yeah, before we move on, I'll say something really quickly about this second footnote.

just because it's a remark that's actually pretty important to me.

In fact, Maxwell is the one who wrote it, but I didn't even realize, but it is an important clarification that when we talk about beliefs and inference, it's much more general than just an agent or a cognitive agent.

object.

The manner in which we talk about inference and we talk about carrying beliefs is this much more general sense of just two random dynamical systems that are coupled and therefore reflect the statistics of each other.

Generically, this is a system estimating the statistics of an embedding environment.

The very important point is any system with any noise, and in fact systems with no noise, have statistics.

And so any system that estimates or couples to another system with statistics

can be interpreted as mathematical inference.

One system performs inference about the other.

The sort of content that you place on that idea of inference is very case dependent.

So it's not the case that stones, for instance, are cognitive.

But it is very much the case that stones reflect the statistics of their environment simply because these two systems are coupled and their statistics reflect each other.

And so this is what we mean in the sense of talking about agents that carry beliefs.

Simply, it is about objects

that do this kind of statistical estimation, which we would think of as inference.

But it's certainly much more general than simply something like a reinforcement learning agent that actually stores representation of its environment.

It is a representation, but in a much more trivial sense in the general case.


SPEAKER_05:
I mean, I would add to that by pointing out that Dalton was saying that we

There were disadvantages to focusing on the density dynamics formulation, which features Markov blankets and the like.

So Markov blankets are great and we like them.

But I think focusing on them so much in the literature over the last several years has obscured the fact that the free energy principle is at core a statement about how, you know, as Dalton was saying earlier, random dynamical systems couple to each other.

So, you know, the Markov blanket is not some, I often hear and read in the literature, the Markov blanket secludes the organism from its environment, but it's not, that's not,

That's not the idea at all.

The Markov blanket is the set of states via which the organism and its environment are coupled.

And in fact, we made this case in a paper on a variational approach to niche construction several years ago.

You can basically swap the sensory and active states

of your organism and you get sensory and active states of an environment.

It is fundamentally a story about how systems couple and synchronize with each other.

It's not a story about how things that exist are somehow secluded from an environment.

It's really a story about how, yeah,

we become a model of our environment, meaning that we are in tune with, engaged with, and reflecting the structure of that environment.

This becomes very clear, by the way, when you look at the quantum formulations of the free energy principle.

If you take the asymptotic limit of the free energy principle, so its behavior as time tends towards infinity, for classical systems that have space-time individuation,

what you get is something like the good regulator theorem so i become as much as possible as i can like my environment uh you know modulo this space time separation i can't be my environment because i'm here and it's there in some sense and then what you get in that context is statistical mirroring

But in the quantum context, when there is no space like separation between systems, the FEP tends towards entanglement.

So systems that are related in an FEP theoretic way at the quantum level become entangled.

That is precisely what the FEP does.

Conforming to the FEP means that systems become maximally entangled.

So it really is not a statement about, you know,

how organisms are separate from their environment.

It's a statement about how organisms are things in general, self-organizing systems, individuate and couple simultaneously to their environment and how that's not a contradiction.


SPEAKER_00:
Excellent.

So as we rush through section one and head to section two, I just wanted to pull out two really key quotes.

You wrote, in this paper, we discussed the relationship between dynamics, mechanics, and principles.

And then later on page five, you write Bayesian mechanics is specialized for particular systems that have a partition of states and go on to describe it more.

So as we head towards section two, an overview of the idea of mechanics and indeed Bayesian mechanics, could you unpack a little bit by what you mean, dynamics, mechanics, and principles?


SPEAKER_05:
Sure.

So Nell Andrews, as everyone I think in the literature knows now, wrote this great paper, The Math is Not the Territory, which challenged us to be very clear about what we meant, really, when we're talking about the free energy principle and active inference.

And in there,

I think Mel makes a number of contributions, but one of their most important contributions is to differentiate between the FEP as an uninterpreted formal structure and the FEP as it might figure in applications to model specific kinds of systems.

And Mel points out that, you know,

A lot of the confusion in the philosophical literature has to do with the fact that the primary FTP literature often doesn't differentiate between just the mathematical structure of the theory and then these models interpreted as representing certain features of a target system that we want to make sense of.

And that's important because falsification or empirical validation, more generally,

Um, applies to one kind of thing, but not the other, right?

So, uh, the, the free energy principle in so far as it is a mathematical theory, I like a formal statement is no more falsifiable.

or subject to empirical verification than calculus would be.

You wouldn't try to falsify the axioms of calculus.

They do or do not apply informatively to certain kinds of systems.

So there's a level at which the core formal results of the FPP have that status.

They're mathematical results.

And we can use this to do some interesting empirical stuff.

So what we wanted to do is to differentiate between three kinds of formal things in the first class of tools that Mel was outlining.

Namely, we distinguish between dynamics, mechanics, and principles.

So the dynamics are descriptive.

They are basically a formal description of some systems behavior.

You might say that like Galilean mechanics is almost entirely dynamics.

You needed someone like Newton to come around and say, well, there are general equations of motion that one can write down to account for

sort of how this description plays out in some sense.

So we move from dynamics to mechanics in the same way that we move from description to explanation, from a target phenomenon that is formalized in a certain way

that we would like to have an explanation for to a set of equations of motion that really account for how those dynamics come to be.

And then principles, if mechanics tell you how, principles tell you why.

So usually in physics, we appeal to some symmetry or conservation principle in order to derive

the mechanics or the mechanical theory for the systems in question.

So what we're left with is principles, mechanics and dynamics, all of which are formal theories.

And once you have a mechanics, you can apply it to study specific kinds of systems empirically.

And that's where empirical verification would come in.

So principles are not falsifiable.

They're just bits of math.

And you use them to write down mechanical theories.

which when interpreted in the right context and when the variables are mapped onto things that are of interest target systems, then they become subject to empirical evaluation.

So hopefully that,

you know, clarifies a lot of the model around the FEP.

One of the reasons why we spent so long, you know, outlining the idea of mechanics and physics is that this isn't some exotic way of thinking about things.

This is really just physics, just straight vanilla reasoning from physics.

Yeah, I'll stop there.

Delphin has probably some interesting things to add.


SPEAKER_01:
No, I think you've covered it.

Yeah, it's just that there are important formal differences in physics between what we would call a mechanical theory for some object and a dynamical description of some object.

And so in this tower of things, you get...

ideas you get theories that sit at different layers in the tower this hierarchy ends up being useful in clarifying uh this host of different results in the fep and where one fits into the other so it was important to take the time to discuss it uh but um that was that and that's the whole point of section two


SPEAKER_00:
Awesome.

So to also move quickly through section two on page nine, you write, we are concerned here with what we have called Bayesian mechanics.

And then you launch into an example of mechanical theory, operationalizing a mathematical principle, and you provide some classical

statistical formulations on page 10 so could you give us an overview of what the equations on page 10 are showing like what they do for classical physics and what is the analogy or what is the connection that this is preparing us to make with bayesian mechanics yes uh well in fact i have an entire paper uh


SPEAKER_01:
that's about to come out about this, just like building on the analogy.

So I'll leave that as an Easter egg for the audience.

Watch out for a classical physics for the Bayesian mechanic paper.

So I think- Instant classic.

It might be some interest, yeah.

Might be of some interest.

But yeah, so on page 10, we are just giving an example of this kind of formal difference.

So you have some kind of principle in classical physics.

It is the principle that systems are kind of lazy.

There is some kind of...

an amount of energy that it takes to get from a to b and systems don't waste that energy so they take precisely the shortest path from a to b or the path of least energy in in the more technical sense of the transfer of potential energy into kinetic energy so if you have some amount of stored energy the transfer of that into energy of motion is minimized along the path that's a very

abstract statement.

And there's not a lot that you can actually do with that computationally.

All you can say is systems try and get from A to B using the shortest amount of motion possible, no extra motion.

So if you see in figure one, for instance, there are these paths that fly off into

sort of these very strange fluctuations.

In the classical world, those fluctuations don't exist because classical systems take this energy-minimizing parabolic path in the dark of blue.

What is computational about that is that principle of stationary action, so the principle that you don't waste energy, results in a mechanical theory, a law of motion for the mechanics of classical objects.

This is what we would call Newton's law, Newton's second law in particular.

Everyone knows F equals ma.

It's force equals mass times acceleration.

So the idea is that

If you are such a system, if you minimize the amount of energy that you take, then you're

the acceleration of you must obey precisely the force being applied to you.

And so this is your law of motion.

This is a mechanical theory.

The dynamics that come out of that are able to be discussed when you start putting in actual details, when you plug in whatever force being applied.

Sorry, that's a dog.

You probably heard it.

What is the force being applied to the system?

What are the initial conditions for the system?

What is the mass for the system?

All of this extra data starts giving you trajectories.

So an actual model of the system, which is less explanatory and more descriptive.

And this is at the very bottom of the hierarchy where you get this dynamical theory that's got all this extra data in it.

So this is very quickly an account of that hierarchy.


SPEAKER_00:
Awesome.

Let's move into section three and figure two.

So the caption is three faces of Bayesian mechanics.

What are the three faces of Bayesian mechanics and what is this figure showing?


SPEAKER_05:
Well, it's often been suggested that there are like 17,000 versions of the free energy principle.

And that it's not very clear what the current version is and all that stuff.

And some of this is fair and some of it isn't.

I think some of it is fair because it is true that often in the technical papers, not sufficient care has been given to making very explicit which assumptions we're making about the systems that we're interested in modeling.

So what we tried to do in section three is to provide a comprehensive survey of all of the ways that the free energy principle has been articulated in the literature.

And so it turns out that there are basically three main ways in which the FEP has been applied, which we're representing here.

So we've already alluded to the first distinction.

The FEP can either be formulated in terms of a probability density over states directly or as a probability density over paths, so over trajectories of states that we write in so-called generalized coordinates.

And those are importantly different.

So the literature over the last, I guess, circa 2012 to 2019 focused almost exclusively on the density over states formulation.

And this is where you get

The approximate Bayesian inference lemma that's played a pretty critical role in a lot of these investigations.

This is also where you get states that play the role of Markov blankets effectively.

Whereas the original formulation of the FEP was in terms of a probability density over paths.

So you're not really so much interested in the dynamics of a system just in terms of how probable its states are.

What you're actually interested in is entire trajectories that unfold over time.

And the most general paths formulation doesn't make a lot of the assumptions that have been criticized over the last little bit.

Importantly, we don't assume that the systems being described are stationary.

We don't assume that, and accordingly, we don't assume that the system has a non-equilibrium, a steady state.

And we're now returning to this formulation because it's less restrictive for reasons that Dalton could probably detail better than I can.

So then within the density over states formulation, what you get is this kind of mode tracking or mode matching behavior where, I mean, essentially what we're saying is that a system that conforms to the free energy principle

is such that it looks as if the average internal state is tracking the average external state or matching it.

And the relevant difference in that density over states formulation is that the external mode that the system is tracking can have dynamics to it or can also not.

And it was important to distinguish these cases because a lot of the formal analysis, so for example, our colleagues at Sussex released this great paper, How Particular Are the Physics of the Free Energy Principle?

And they come to the conclusion that

The FEP doesn't really have anything interesting to say about the class of systems that they examined.

What is the class of systems that they examined?

They are looking at linear systems that undergo dissipation, effectively.

So physically, these are dampened springs.

So to restate, if you take away the mathematical baggage, what they're saying is the FEP doesn't have anything particularly interesting to say about the behavior of dampened springs.

So what does a dampened spring do?

Well, it starts off and then it dissipates back to a fixed point.

Like just due to friction.

So the mode...

towards which the system is flowing has no dynamics to it.

It is a fixed point.

It just dissipates back to a fixed point.

And what they're showing is that there's nothing interesting to say from an FEP theoretic perspective about those systems.

But I mean, the counterpoint is sort of that there isn't anything interesting FEP theoretically to say about those systems.

There isn't any interesting external dynamics that the internal dynamics would be matching.

And a lot of these null results where we use FVP technology to say stuff about a system and there's nothing interesting to say, look at systems that have fixed external modes.

And so the idea is that the FVP applies vacuously to those systems because there's nothing interesting to say.

So yeah, to summarize my rant,

We tried to summarize the main applications of the FEP in the literature.

We identified three.

And strategically, we point out where some commentators may have been led astray by focusing on one rather than the other.

So in particular, a lot of this

These ideas that the FEP can't handle things like systems with moving attractors and systems that don't have like a single mode.

These are understandable characterizations given that basically from 2012 to 2019, we mostly focused on this middle class of systems.

So systems that we're describing in terms of the density over states that have a dynamic mode.

So it's understandable why people would focus their attention on that.

But the FEP in its most general form doesn't make perhaps problematic assumptions.

like stationarity and it, yeah, it also applies interestingly to systems that have interesting external state dynamics.

So strategically, I think that's what we were going for in this section.

And I believe this is the only place in the entire literature where

this is reviewed so comprehensively in terms of this tripartite distinction um so you know i i don't mean to be disingenuous and to suggest that you know the confusions that have arisen are only due to um you know just uh a lack of paying attention these things have not been expressed very clearly the assumptions have not always been stated very clearly and yeah it

the form of the path of least action in each of these things looks very different.

So we can also understand why it might seem like there are 17 versions of the free energy principle, but there aren't.


SPEAKER_00:
Thank you, Maxwell.

As we speed through this section, I'll just note that formalism one on page 15 is familiar and has to do with the flow of states in the particular partition.

And we've also seen the Helmholtz decomposition shown in figure three in terms of a decomposition on

into the vertical and the horizontal, the gradient pursuing and the solenoidal isocontour aspect of flow.

Those are reviewed in the citations that are provided here.

So let's get into the newer stuff.

In section four, you're discussing some mathematical preliminaries on the maximum entropy principle, gauge theory, and dualization.

But first, yes, Lars.


SPEAKER_02:
Moving on to section four, because I thought section three was...

incredibly illuminating for me personally, and I think the literature in general, having the separation out.

And there was a question that arose for me in working through this that I just wanted to throw out there.

I don't want to distract the journey through the paper too much.

But in moving to this, you talk about on page 19, when the FEP is applied to density over states as opposed to path, we assume non-equilibrium steady state density.

And then on the next page, page 20, you see, we can view this NAS, non-equilibrium steady state density as providing a set of prior preferences, which lead the particular system to look like it attempts to enact and bring about these preferences through action.

If you then move to the path-based formulation where there is no NAS assumption, how do you recover these preferences in

in that formulation?

Or can you not use that formulation to describe systems that are doing actions that look like they have preferences?

Or is there a piece that I'm missing?

Does that make sense?


SPEAKER_01:
I can take that one.

So one of the key deliverables of this third section is this three faces type thing, right?

So the idea of the free energy principle and the mechanical theory that arises from it.

is we would want a mechanical theory, a law of motion for Bayesian inference or for systems that do Bayesian inference.

And what it ends up being is approximate Bayesian inference.

And this comes in three flavors, mode matching, mode tracking, or path tracking.

This is the three-faces thing.

So that I mean just like you have different flavors of classical mechanics you have things that move continuously like satellites in orbit or you have things that move and then stop moving like a bowl thrown through the air eventually returns to the ground and things that sit on the ground don't move unless they're acted upon.

So there are very different flavors of approximate Bayesian influence and these three are in particular the kinds of things that we're thinking about.

So

The reason why I give that context is because we can still imagine preferences on the paths of a system.

A system must evolve in such a way that it avoids certain areas of the state space, given that it remains a system.

a human can't evolve in such a way that it dips too far away from its allostatic bounds.

There are certain set points and certain bounds around those set points in which I can oscillate, but too far outside of those bounds and I'm in trouble.

Likewise, you know,

I can have something like a stone that kind of evolves through a state space.

The stone doesn't have preferences per se, but it has a definition.

And so we can read not preferences, but definitions about what a stone looks like in the same sense as we understand what a human looks like as certain preferences that guarantee cohesion.

So things that are definitional of a stone guarantee that same kind of cohesion.

There's a type error if you would identify them.

But mathematically, they end up looking very similar.

And what's interesting about that is now you can talk about preferences or you can talk about definitions along the path of evolution of a system.

A stone must stay roughly together.

It must stay in this sort of crystalline structure.

If you start hammering away at it, you turn it into a powder.

And this is something that we wouldn't think of as a stone.

So in the same sense, if a human...

doesn't eat for too long and maybe starves to death.

It's a really grim example, but unfortunately, it's one of the better ones.

You can imagine you're drifting too far away from this state of being satiated or having sufficient energy to maintain cellular processes and the chemical reactions that sustain life.

And as a result, you know, the preference along your set of paths has been violated.

So I think, yes, there is a sense in which even though we have forgone a nest density per se, we still have a density over paths, not over states, that this density still expresses something of a definition for the system or a set of preferences for the system without which we don't have a conceptualization of that system.

That's a very long answer to your question, but maybe it satisfies you.


SPEAKER_03:
No, that's great.

Thank you so much.

That was really useful.

That makes sense.

Thank you.


SPEAKER_05:
You can kind of think about it as these constraints force systems to basically pick trajectories that are at the trough of a preference landscape or a constraint landscape, if you want to think about it.

So you get the same kind of thing, as Dalton was saying.

But the systems aren't assumed to be stationary.

you know, non-equilibrium steady state distributions per se.

But there is something analogous.

And a lot of the future work in G theory is precisely about using the technology of maximum caliber to really make sense of this formally.


SPEAKER_00:
let's move into section four so in section four as noted and as referenced to the previous publication there's a discussion that the fep is dueled to the constrained maximum entropy principle and then one of the ways that that's pursued in this section is through the lens or at least related to gauge theory so we're looking at figure four


SPEAKER_01:
what is gauge theory what is category theory dual and how is it being deployed in this situation um i guess i'll take that one as well uh figure four you said yes okay illustration of fiber bundles sections oh yeah okay yeah uh well mega fig i i recognize that name i believe that's how we refer to it internally

Yeah, well, so if you ask me, because I am a mathematician primarily, if you were to ask me or if you were to ask a mathematician, what is a gauge theory, you would probably get a response roughly like, well, gauge theory is the study of a particular geometric space called a fiber bundle.

So there is a type of space called a fiber bundle in geometry.

It looks exactly like that figure.

It's a bunch of fibers pasted onto something on the bottom, what we call a base manifold.

And studying how do things behave in a space like this, how do they behave in the sort of fibers, and how does that reflect some kind of behavior on the base manifold?

These are interesting geometric questions that arise in the study of fiber bundles and hence in what is called gauge theory.

If you're a physicist, I mean, it turns out that fiber bundles are the natural space for talking about classical gauge theories.

So the theory of certain high energy particles.

But it's a little bit more general than that.

And so if you're a physicist, this is what you think of.

You think about...

like gauge bosons uh but but this is only because fiber bundles are a very natural way of talking about these things and so it is a little bit more general what we're talking about in the figure four is this idea that uh

in this space of fibers, you can kind of trace out surfaces and that these surfaces are like probability densities over the base manifold.

And in fact, they aren't just like probability densities, they are.

So you can formulate probabilities over a state space as an object in a fiber bundle.

And therefore, if you have all the technology available to you, you can draw this very nice gauge theoretic interpretation of what it means to be a probability density.

And therefore, because the object of Bayesian mechanics is systems that do inference, and so systems that estimate probability densities, there is a nice gauge theoretic interpretation to Bayesian mechanics that hinges pretty much on this picture.

What we would call the gauge in this situation is the choice of this J function.

So you see you have several different surfaces, three of them, each of which comes with a different choice of J. So the idea of choosing a function in the fibers.

and therefore choosing a shape for your surface.

This is what we would think of as a gauge theory.

And that's why I went down this route in the geometry and analysis paper, because it ends up drawing a very nice picture of what it might mean to engage in constrained inference.


SPEAKER_00:
Awesome.


SPEAKER_05:
And could I give a pedestrian or so the, the bystander, the, yeah, the, the more, the less technical version of it is, um, so gauge theories and Dalton track me whenever I say something that's wildly or even not so wildly inaccurate, but gauge theories are basically how one would, um, how one articulates, uh, symmetries or conservation laws and contemporary physics, uh,

So most physics relies on the idea that some transformations that are of interest, like the ones described by Maxwell's equations,

have some kind of symmetry or that concern.


SPEAKER_01:
I think a slightly better way of going about it would be to say that modern physics is broken up roughly into stuff and forces.

And forces act on stuff, and stuff gets acted on by forces.

So the interesting thing in gauge theory is you can talk about how a definition of some stuff, the shape of some stuff, is intimately dependent on the forces acting on the stuff.

And so this is where we get this idea of we have a particular shape to our surface.

We have some probabilities over our states, but that this is actually defined by the choice of gauge, this J function.

So our assignment of probability to states is actually determined not by probability, but it's determined by the constraints on those states.

Certain states are preferable, certain states are not.

Unpreferable states get low probability.

Preferable states get high probability.

And our notion of preferability is encoded in the choice of J. It's a function that constrains different states.

So constraints in this case are like penalties.

So our assignment of penalties, so our choice of force, is actually what shapes our assignment of probability.

That's ultimately...

I think, well, that's a slightly different way of viewing the geometry of the situation is gauge theory is all about these kinds of what we would call covariance relationships.

Covariance meaning literally two things varying together.

If I choose a force, I'm forced to choose some stuff.

And likewise, if I choose some stuff, that necessitates an underlying choice of force.

So gauge covariance ends up being very helpful in situations like this.


SPEAKER_00:
thanks let's see if we can touch on some of these last figures in figure five we see a vector field on a curve that's reminding us of that sort of baseball diamond shape from earlier with a path of least action and in figure six a probability density is generated by level sets of the constraint function

J. So either figure five or figure six, whichever you feel fits in best here, what is being shown and where were you going with it?

How is it connected to alternative phrasings?


SPEAKER_01:
Yeah, I guess I'll just cut to figure six, which is kind of about this covariance thing.

So if I choose a particular functional form for J, in this case, it's a penalty that is proportional to distance.

I would expect my assignment of probability to fall off roughly like a distance function.

So probability of a state should decrease as the penalty on a state increases.

So in this case, the probability of a state should decrease as I go away from some central point, and it should do so symmetrically.

And so we would expect a Gaussian density from this.

And it is indeed the case that you can understand the covariance as a kind of projecting down and then lifting back up.

And what do you get when you do that?

Well, the stuff in the equation, the probability, ends up being defined by, we take all of the sort of rings on the J function, you project them down.

you get circles on the base manifold.

When you lift them back up, they're rings.

And so we know a symmetric probability density with a whole bunch of rings is just a Gaussian probability density.

So this figure is kind of capturing what does this covariance relationship actually look like?

How do we actually build stuff out of forces?

And it ends up being the case that it's this very simple recipe of you push everything down,

And then you lift it back up.

And the lift is e to the j. So you place j onto x. That's the first step.

Your second step is then you hit it with this exponential function.

And e to the minus x squared is, of course, a Gaussian density.

So that's all that figure 6 is depicting.

It's just zooming in on one of the objects in figure 4.


SPEAKER_00:
Great.

And I thought on page 34 also, the striking result that the splitting of the flow of a system into vertical and horizontal components under the constrained maximum entropy principle is isomorphic to the Helmholtz decomposition of the flow of the autonomous partition of a particular system.

so for those who are caught up with the way that the helm holds decomposition was used for example in the papers that we discussed in live stream 32 with uh markov blankets and chaos stochastic chaos this is augmenting it or transposing it into another formalization um and moving on again quickly um it's worth pointing out that there's um


SPEAKER_05:
there are some significant advantages to reformulating things in terms of maximum entropy.

I'll let Dalton speak to the more technical parts of this, but I guess one thing that pops out to me more politically is that maximum entropy and constrained maximum entropy

I mean, they are just core parts of the physicist's toolbox.

So the fact that we are able to reproduce the Helmholtz decomposition in terms of the way that flow splits up in the gauge theoretic formulation I think is quite significant.

It gives us an entirely independent line of reasoning arising at the same results.

So especially due to some work by Martin Beal and colleagues a few years ago, we were no longer sure whether some of these results obtained.

There had been doubt thrown onto the derivations of the approximate Bayesian inference lemma in some papers.

Life as We Know It from 2013, I believe, is the paper that they targeted.

One way of reading this is that independent of all these analyses and independent of whether Beale and colleagues are correct about their criticism of the 2013 paper, this is an independent derivation that just follows from uncontroversial mathematics, and we're able to re-derive basically the main core

uh, portions of the formal results, uh, that Carl had derived.

So the approximate Bayesian inference lemma, the Helmholtz decomposition.

Um, and I mean, in some sense, the magic is that we understand now why these arise to begin with.

Uh, there's, uh, yeah, I think the, um,

The maximum entropy interpretation in some sense, especially in the gauge theoretic formulation, in some sense tells us, well, why does approximate Bayesian inference work just full stop?

And these sets of results explain effectively why this has to be the case.


SPEAKER_00:
Only my facilitator hat prevents me from being that excited.

um section 5.4 also explored more in the previous citation so the four things that i wanted to just touch on as briefly as people wanted as we close are the three philosophical areas that are introduced in section six and then of course just the appetizer of g theory so in page 38

section six the philosophy of bayesian mechanics 6.1 addresses clarifying the epistemic status of the fep so what were you aiming to bring people's attention to and address in 6.1 with this philosophical question


SPEAKER_05:
Well, I think this basically summarizes the point about dynamics, mechanics, and principles that we were making earlier.

You know, so the FEP has been described variously in various and sometimes very different ways, even by like its core proponents.

So Carl introduced the FEP to the world as a theory of cortical function circa 2005, and then as a unified brain theory in 2010, which

led a lot of people, and I think not to, like, this isn't bad faith, it led a lot of people to say, well, okay, so this is a theory, and so it should be making predictions, and therefore it should be empirically verifiable.

So I think, you know, the way that we talked about it led to a lot of confusion, and it's been described as, you know, a framework, whatever that means, by myself included, right?

So mea culpa, we called it the active inference framework for a long time without really being specific as to what that meant.

We kind of met all of this, this cluster of results that kind of agglomerate around the FEP, um, um, Raja and colleagues have called this a, uh,

a trick uh kind of like the variational auto encoder trick in machine learning so it's a it's a trick if you can write a markov blanket for a system then you can make you can write down a model that looks as that says that the system looks as if it's performing bayesian inference it's also been called a physics a physics of sentient systems a formal ontology

So the point is to say, well, everyone is kind of right.

You know, these are all, in some sense, valid assessments.

And Mel is really the one who clarified things initially, I think, by distinguishing formal structures from interpreted empirically evaluable models.

and um yeah i think that the first part here is to say well we can make sense of this model by appealing to this tripartite distinction that we've outlined so by distinguishing dynamics which are descriptions formal descriptions of some behavior that we want to get to mechanical theories that explain how then principles that explain why

And then what we're calling, I think, empirical applications, which are basically these formal models plus an assignment or an interpretation or evaluation of these models in terms of the features of target systems that we want to explain.

Yeah, so when they're applied in that way, mechanical theories become empirical theories, as we write, in the ordinary sense.

But yeah, so hopefully this kind of clarifies everything around falsification, how this thing is used, and importantly, why this is just standard physics.

I mean, this isn't all that spooky in terms of the use of mathematics to make sense of physically relevant aspects of our universe.

So that's what we were trying to do in that section.

Great.


SPEAKER_00:
Really clear.

6.1, it reads to me like it's the tip of an iceberg with a nice landing and takeoff strip.

And yes, it's a big iceberg, but it is an iceberg and there is a tip that makes sense.

6.2 on page 39, Ilan Vital and the FEP.

What does this French linguistics have to do with the FEP, Maxwell?


SPEAKER_05:
Well, Dalton might have some pretty interesting remarks to make, but just briefly, I mean, I find it kind of ironic that the people who are most critical of FEP right now, like folks from the inactive tradition and folks from the ecological tradition, sometimes frame their own research as trying to struggle against dualism in some sense.

But our belief is that

They are intrinsically dualistic frameworks.

So is a French term.

Vitalism, I don't know how familiar you are with the history of biology, but before the 20th century and the discovery of DNA, most serious physicists believed in something like Aristotle's entelechy.

So you had to have some kind of physical mechanism for purposiveness.

And so Elan Vital was this kind of vital force that they believed, the vitalists believed, animated living systems and differentiated them from non-living systems like stones and rocks.

And we believe that one of the consequences of the perspective that we're adopting here and building on, you know, especially the work of Mike Levin, who's done amazing, made amazing contributions in this field, is that it

Self-organization and cognition and life and these things that we like to point out as being distinct from inert matter actually are more on a continuum.

The Bayesian mechanics says that basically anything that's a thing...

will exhibit some features of what we think of as cognition.

So it is a massively deflationary and absolutely, resolutely monistic perspective that we're advancing here.

Yeah, which says that trying to look for the boundary between living and non-living systems is bound to fail in some sense.

There is a continuum.

These processes that we're interested in are also events by rocks and by tornadoes and by crystals.

And it is a question of degree to which systems act as cognitive systems.

Yeah.

I'm sure Dalton has more interesting things to say about that.


SPEAKER_00:
Yes, on 6.2, what else would you add there, Dalton?


SPEAKER_01:
Well, maybe not more interesting, perhaps more interesting things to say.

Well, yeah, I mean, I think this section is mostly just a recapitulation of footnote two, in a sense.

Meaning we made this statement that inference, per se, representation of some statistics of something else is this very broad, very general thing.

And any system that is not a closed system does inference.

So what that means is under the free energy principle,

And at least what we've written in that paper, what we've worked out so far, there isn't a way to talk about cognition versus non-cognition.

It's more of a spectrum of cognition.

There are certain systems that are more cognitive.

This is something that Carl might call temporal depth.

So there are systems that are very good at planning and executing actions.

And there are systems that are not.

So there's a very clear difference between humans and stones, for instance.

But that difference isn't in...

one does inference and another doesn't.

It's that one does a bit more complicated inference.

It has better or more accurate representations or more representations, full stop maybe.

And it's better at using those representations to do action.

But both stones and humans are estimators of the statistics of the processes around them simply by mathematical construction.

And so there's this very...

uncontroversial statement, or at least it shouldn't be a controversy, that systems, things in the very most general sense, exhibit this kind of representation-based inference that we would typically identify as cognition.

So that was the motivation for talking about that.

And then Maxwell tied a very nice bow on it with this great history of a debate around very similar questions.

But yeah, it was this idea of a spectrum of cognition.


SPEAKER_00:
Awesome.

And citation 92 there is the 2018 paper answering Schrodinger's question.

So...

many years ago, the other Maxwell at all, who raised that question and sparked really a phase transition in the discourse.

And that was also like one of the papers that really drew me in and got me excited.

And so it's amazing to see what other questions and answers have been risen.


SPEAKER_05:
6.3 and then g so 6.3 is a slightly longer section and it's on maps and territories so yeah what is that i'm really glad i'm really glad that we were able to write this so um i i never found this particularly confusing but i i it it has led to a lot of confusion um

So in particular, there's this entire paper by Thomas Van Ness that just is just confused about this issue.

I forget what it's called.

It's living life model.

Anyway, so folks have said, well, is the free energy principle just a description that we are?

a model that we are using to describe interesting features of the world?

Or is it saying that self-organizing systems actually are models of the world?

And so I never particularly found this problematic.

Because this phrase in the paper, I think, sums it up correctly.

The free energy principle is, in some sense, a map of that part of the territory that looks as if it is a map.

And so Thomas Metzinger actually retweeted our paper and pointed, called this nested representationalism, which I found interesting.

So yeah, there are these kind of two distinct levels at play, but there's no foul play here because the FEP model is very explicit about which parts of the formalism pertain to our map of the territory.

And which parts of the formalism pertain to the map that self-organizing systems are constructing according to our map?

Yeah, so I think it's important to point out that there isn't a contradiction here.

There are just these two probability densities that are at play in the construction, the Q density and the P density.

And you can understand the generative model or the P density as basically

uh our model of uh the self-organizing system in terms of uh yeah joint probability density uh over uh it's it's state space or potentially it's a

space of paths.

So in that sense, the self-organizing system being its own best model really means we have a model.

We can explain the system's dynamics.

And the system's potential is formalized as a generative model, as a joint probability density.

It just so happens that part of the variables that are described by that joint probability density play the role of parameterizing additional probability densities over another subset of variables described by the generative model.

So there are really these two, I think, unambiguously different senses of being a model that are at play.

And yeah, I don't think this is a sleight of hand and hopefully we have clarified.

Yeah.

What, what exactly is at stake here?

I think there are some nice connections to the maximum entropy formulation.

So as Dalton articulated in the paper, at least, you said, you said as much in discussion today.

I think by flipping to the perspective of maximization of entropy, we effectively recover our own position as modelers trying to model the system.

So the prism through maximum entropy adds this additional clarification that

uh yeah we can entirely recover the perspective of a modeler using maximum entropy modeling to model a free energy type system by invoking this duality of perspectives um and i think that's really important um then there's this other piece here which says that the the maps that we construct in fep and in max end uh both adhere to a kind of epistemic minimalism

So maximum entropy inference is basically saying I'm going to, well, given some data set, the probability density that most, that is,

the one that best explains the data set is the one with the highest entropy.

What this means is that we are building in to that probability distribution as little prior information as possible.

It's like starting from the point of view of maximal ignorance, given a few constraints, what is the underlying probability density?

Um, the FEP has a similar starting point for maximal ignorance, which says I can't go beyond the blanket.

Like I am stuck with the data that I'm generating and.

with the way that I probe the world, the data generating process to generate my data.

And there is no going beyond that.

You can't go beyond the blanket unless you break the blanket, but then you're just introducing a new blanket.

So for example, I can't see in your brains.

I could put you in an fMRI machine and break the blanket, but then I'm really introducing another blanket, which is this new set of data that I have to continue making inferences from

Um, so I mean, the, then the, the FEP and Maxent kind of emerge as, uh, these epistemically, um, minimalistic or, um, you know, they kind of emerge as the way that you would construct a map of the part of the territory that acts as a map from a perspective, from, from a starting point of maximal ignorance.


SPEAKER_00:
Great.

And I think that's connected in the Active Inference textbook to figure 9.1, the meta-Bayesian perspective.

And there it's not described in the context of maximum entropy, but it's something very similar with this nested representationalism.

Any other philosophical notes before we go to section seven?


SPEAKER_05:
Yeah, that's exactly right.

That's exactly right.

Yeah.


SPEAKER_00:
I love this book.


SPEAKER_05:
Yeah, Dalton, anything to add before we launch into G-theory?


SPEAKER_01:
No, I think you raised an interesting point.

So we can talk about, you know, when we use the FEP to model a system, what we're doing is forming a model of the system where the system forms a model of its environment.

And so there is this nested representationalism.

What's interesting about the maximum entropy point of view is you can kind of dualize it.

You can take this sort of mirror image of this thing and you can ask, okay, well, we're not interested in a model of the system modeling something.

All we want is a model of the system.

So what does the system look like when it's creating that model?

Not what does the system's model look like?

So this is the dualization aspect of things.

And so you can talk about... And when you dualize, you can talk about things like constraints on agent states rather than the predictions and actions of the agent.

So it's a bit of a different viewpoint.

It's just emphasizing different...

levels of the nest, so to speak, which is kind of interesting because you do get both of these perspectives for free as soon as you commit to this relational symmetry of an observer in an environment and an agent in an environment and how those two things do model each other.

And that's what you get when you dualize things.

But yeah, that's it for me on that section.

I think Maxwell pretty much covered a lot of the important points.


SPEAKER_05:
I mean, I will say that, you know, this probably is not obvious until you really look at the mathematical formulation and notice that there are two, you know, as I wrote in that paper from a few years ago, the FEP is a tale of two densities.

And you really need to, like, take a look at the math to understand that there isn't a, this isn't like a case of reification.

This is just formulated.

So it isn't so simple that you could just put it in a directed acyclic graph and say, hey, look, here are these two.

But definitely, if you take the time to work through the formalism,

There are clearly these two different senses of being a model that are at play, that are cleanly distinguished, and I think are actually not all that problematic.


SPEAKER_00:
Awesome.

It's almost like thinking through other minds highlighted some of the social consequence and theory of mind and behavioral aspects of certain types of cognitive entities, but systems

Thinking of, through, about other systems or infers, thinking through other infers, infer ants, that type of dual view from the inside, view from the outside is again, what you're suggesting is enabled by that kind of a commitment to these foundations.

And

of course it could be a whole nother guest stream and perhaps should be on g theory but as we close here what can we say today on 6 13 2022 about g theory and what is exciting you all about how you're going to continue forward do you want to take this one dalton uh yeah sure uh so


SPEAKER_01:
I mean, like I mentioned earlier on, there's already a lot of really promising stuff in the literature about path integrals and path entropy and the kind of power it has to deal with systems that we would normally kind of balk at.

And so it's already very promising.

There's reason to be optimistic about how this extension will benefit us in the future.

So G-theory itself is... Maxwell coined this term to describe the extension of this duality from mode matching and Max-Ent, Max-Cal, which will involve precisely this.

We'll try to formulate the free energy principle in its full generality as dual to entropy in its full generality on paths and so forth.

And so...

The reason why this is so exciting is because already there's a very clear path towards talking about systems that are non-stationary, so systems whose statistics change, more complicated forms of inference, more complicated forms of constraints and preferences.

And so it seems like already it's a much more faithful description of the kinds of systems that we want to talk about and extends to things like more complex systems, things like humans potentially,

So this is really, I guess, the end goal, is to do this dualization, to now build an FET dual model of something like a brain, which we know models its environment in this very complicated way, and so the kinds of representations it does are very complicated.

So how do we model that?

that should arise out of maximum caliber and therefore out of G-theory.

And in principle, eventually we'll have a very faithful, very foundational picture of complex systems.

But this is a very long-term goal.

In the short term, we just want to get the maps to work.


SPEAKER_05:
To connect that a bit to Lars's question earlier, what does it mean to have a non-stationary density over paths?

Well, I mean, what we're interested in is the way that the density changes as a function of the dynamics.

So that you really have like these moving surfaces over a space of paths or a space of states.

And to really capture all of that kind of time dependency and

um yeah requires moving from uh maxcent to maxcal uh from states to paths and um all of these kind of more fine-grained uh you know wandering blankets and moving attractors and all that good stuff uh should fall fairly naturally out of uh yeah g theoretic formulation of this stuff


SPEAKER_00:
i like how within fep as we know it we have variational free energy f and then expected free energy takes us into the future and planning and that's g and then we see a little bit of like free energy principle f and then g is the next letter so that's a funny little would know dual analogy um well

If anybody has any closing thoughts, it would be a great time for that.

But just wanted to say that there's a lot of appreciation in the chat and a lot of excitement around this work.

So we hope that you just continue acting and inferring and serving.


SPEAKER_05:
That's kind of you to say.

Thank you very much for the invitation to discuss our work.

this has been great uh and yeah we uh we look forward to uh you know exploring the future uh with this whole community and um thanks for your time your attention your energy uh very very positive always a pleasure to be on active lab and uh yeah thanks for the guest stream yes i can only echo that uh it's been a real pleasure so thank you


SPEAKER_00:
Thank you, Maxwell and Dalton et al.

Thank you, Lars, for joining and until the next time.

Bye.


SPEAKER_05:
May the gradient descend ever in your favor, my friend.


SPEAKER_00:
And with yours slash ours.

Bye.

Take care.