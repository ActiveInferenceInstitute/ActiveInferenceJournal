00:00 _Daniel Friedman:_
Hello, it's June 23rd, 2023.
We're in ActInf GuestStream Number 46.1 with Denise Holt.
So Denise, thank you very much for joining.
We'll have your presentation first, any length of time you want,
and then we'll have a discussion about some of the topics you're bringing up,
and I'll read some comments from the live chat too.
So thanks again, Denise, looking forward to your presentation.

00:30 _Denise Holt:_
Hi, Daniel. Thank you so much for having me today.
Yeah, so let's just dive right in.
Today I'm going to be talking about Active Inference AI and the Spatial Web.
And for those who are not familiar, there is a company called Verses AI,
and they're basically delivering the next generation of AI.
This is beyond the current machine learning, deep learning models
that we're all so familiar with that are incredible tools,
but really those are tools.
They are great at creating content, performing tasks, things like that,
but they operate in a way that is pattern matching,
and they're all siloed in their ability for what they can do.
They're trained on enormous amounts of data to increase the pattern recognition
and hopefully increase accurate outputs, but that's really what they do.
What Verses has created is something completely different,
and it's based on Active Inference.
And so Active Inference AI is entirely new,
and this is the AI that will be able to get us to AGI,
leading to synthetic self-evolving intelligence.
So today what I'm going to be talking about in this deck is Active Inference AI
and the Spatial Web and how these technologies are going to affect
and change the world.
We'll talk about how Active Inference works with artificial intelligence,
how the Spatial Web protocol enables the perception
and the belief updating of the AI,
and how these technologies together enable the only AI in the world
that can run critical operations for systems or infrastructure,
smart cities, the planet.
So when you're talking about airports, hospitals, things like that.
So, yeah, so let's dive right in.
So the Spatial Web, what is that?
So the Spatial Web is being called the network of everything.
Basically, it's the next evolution of the internet,
and it's powered by AI.
So this is taking us from a library of pages and documents
that we have in the World Wide Web.
And oh, my gosh, my dog is wanting out.
I'm so sorry.
I have to let him out of the park.
Sorry about that.
So the next evolution of the internet.

Now, you know, as I said, World Wide Web, a library of pages, documents,
you know, everything is static.
The Spatial Web protocol, HSTP, hyperspace transaction protocol,
and the programming language for the protocol called HSML,
which is hyperspace modeling language.
This new protocol takes us into a library of spaces where, you know,
we have spatial domains, and everything within any space can be locatable
and programmable within this new network.
And it's just extending the protocol that we have now, right?
So same internet, just more capabilities.
Now, Dr. Karl J. Friston and the Verses AI white paper,
and I'm sure a lot of you are familiar with him,
the father of Active Inference and the Free Energy Principle.
Now, so Verses with Dr. Friston has developed a new type of AI
that mimics the self-organized systems of nested intelligence found in nature.
And it's based on his methodologies of Active Inference
and the Free Energy Principle and the Spatial Web protocols,
which I just mentioned, which were developed by Verses AI.
In December, they put out a white paper called
Designing Ecosystems of Intelligence from First Principles.
And just to back up a second, you know, Verses created the protocol,
the HSTP and the HSML, but donated it to the public
because nobody can own the internet.
But they needed that in place for what they wanted to do as a company.
So that framework needed to be there.
So then they also donated the protocol and the IP to the IEEE,
which is one of the largest core standards bodies
that develops everything with, you know, electronics and engineering.
You know, they're responsible for the core standards around things
like Bluetooth and Wi-Fi and things like that.
So the core standards have been being developed around the protocol
for the last almost three years.
And yeah, Verses in that time has been building, you know,
what they've been building, which I'll be talking about.
So what is this white paper about?
It's basically about shared intelligence.
So in the white paper, they proposed cyber-physical nested ecosystems
of distributed intelligence, joining humans, machines,
and AI agents on a common network.
So we're talking about humans as integral participants, adaptive behavior,
self-evidencing, self-organization, belief updating over several scales,
belief sharing over ensembles of agents.
So we're talking about a network of intelligent agents
and collective intelligence.
And then, of course, the protocols, HSTP and HSML.
So the knowledge graph and digital twins.
Digital twins of our planet and all nested systems and entities within them.
So nested ecosystems, intelligent agents, both human and synthetic,
sensing and perceiving continuously evolving environments,
making sense of changes, updating their mental model
and what they know to be true, and then acting on the new information
they receive.
And in the white paper, it's also discussing a network
of distributed intelligence.
So this enables a cognitive architecture made up of the collective
intelligence of multiple agents that continuously communicate,
coordinate, and collaborate with each other.
Individual and specialized intelligences are all coming together
on a common network.
They're speaking a common language, HSML and HSTP.
It's efficient, powerful cross-communication to perform tasks,
regulate systems, and address problems in real time.
And it scales up and grows in tandem with humans.
So Active Inference and the Free Energy Principle.
So what exactly is Active Inference?
Active Inference is a biologically inspired approach to AI systems
as a method for understanding behavior incorporating the brain,
cognition, and behavior, modeled after the design principles
from nature and from how the brain, nervous system,
and the body act and react.
One of the questions that Dr. Fristin asks in this paper
that is an important question in reference to Active Inference
is, you know, with AI systems, you need to be able to understand
what is it that intelligence must be, given that intelligent systems
exist in a universe like ours.
So Active Inference is a theoretical framework that describes how agents
like people, animals, robots, or artificial systems can maintain
their internal states and behavior in unison with their objectives or goals.
So what is the Free Energy Principle?
The Free Energy Principle is the theoretical foundation of Active Inference.
It proposes that organisms or agents maintain their internal states
and behavior by acting in a way that minimizes the difference
between their current beliefs about the world and what they expect to be true.
So in other words, the agents try to make things more predictable
by mitigating the difference between what they expect to happen
and what actually ends up happening.
And they do this by way of a continuous cycle of improving their perception
by acting on the environment.
So basically, it helps to extract the signal from the noise
and extract the regularities from the irregularities.
So extracting the prediction error, minimizing the prediction error.
And there are two parts to this inference cycle.
There's the perceptual inference part, which minimizes the free energy
by improving the internal model to better match the sensory input.
Making Bayesian inferences about the world, the brain minimizes free energy
by optimizing perception, so through hypothesizing and observation.
In other words, the brain models the environment better,
improving the perception.
Now, the Active Inference part minimizes the free energy
by acting on the environment.
So acting on the environment to reduce the surprises,
the disorder or the unpredictability,
and action can indirectly influence the observation.
So Active Inference, the Active Inference part of free energy minimization
is equal to lowering the surprise in the sensory observations
by acting on the environment.
Actions can't directly change observations,
but they can indirectly change them by acting on the environmental states.
So then we get to Active Inference AI.
So in the context of artificial intelligence,
Active Inference and the Free Energy Principle explain how agents can learn
and adapt to new situations and how they can generate predictions
and plan actions based on their goals or objectives,
which leads to more accurate predictions and results,
which is the real goal of AI.
Active Inference AI enables us to overcome current limitations
with machine learning and deep learning AI models,
providing a realistic path towards artificial general intelligence.
So, you know, the idea is that an agent can use Active Inference
to minimize the free energy and optimize its behavior
in a way that's consistent with its objectives,
which leads to more accurate AI.
So the action perception loop,
the perceptual inference and Active Inference unfold continuously
and simultaneously, underlying deep continuity between perception and action.
They're both sides of the same coin,
performing the same free energy minimization algorithm.
So the free energy can be minimized by improving the perception
and then acting on the environment in this loop that just keeps narrowing down the focus.
And then also by learning the generative model,
you know, how the brain codes the environment.
So, you know, that's the side that the Spatial Web protocol actually helps with
because it bakes context into every person, place or thing in any space.
So that context informs the AI.
So then it's optimizing the expected precision and regulating the learning.
So thus we update the model over and over to improve our understanding of the world.
And that is what the AI does as well.
So how does it do this?
So self-optimization and self-evolution.
So Active Inference AI and the Free Energy Principle through the Bayesian inference
allows a neural network to self-optimize through intake
and continuous updating of new real-time sensory data
while simultaneously considering previously established outputs and determinations.
So past decisions plus the new input lead to future outcomes.
And that cycle is a self-optimization and self-evolution cycle.
So a self-evolving system evolves over time.
Current systems, current AI systems are more like a machine.
They're just neural nets that are trained to do a specific task.
But a self-evolving system is learning from moment to moment and upgrading its world model.
And thus it mimics biology while also enabling general intelligence.
So within the Free Energy Principle, neural networks self-optimize
through a set of mathematical rules enabling next generation artificial intelligence
to efficiently learn, predict, plan, and make decisions.
Spatial Web protocol. Let's talk about this.
So what is the Spatial Web protocol?
HSTP, hyperspace transaction protocol.
It gives browsers the ability to link spaces with an ID for every person, place, or thing,
both digital and physical, so virtual or real.
But it's much more than a location identifier.
HSTP is also a gatekeeper.
It allows various parties the ability to agree on who, what, and where anything is in space,
who owns it, has access to it, and what can be done with it.
So HSTP gives browsers the ability to link the spaces with an ID.
Oh, did I get this in here?
So HSTP is multidimensional query.
So it allows for query over multiple dimensions, identifying, localizing,
and updating the attributes, conditions, contingencies,
and interrelationships of objects in space and over time.
So if it can be defined and calculated in the sphere of natural or digital science,
it can be searchable through HSTP.
So HSML, this is the programming language that informs the protocol.
And I like to call it the smartest contract around because it's the foundational contract now
for every person, place, or thing in any space in any reality.
So the only way to create a truly technologically augmented existence is to be able to consider
and measure the contextual elements that affect the expression of shared information
by and between all objects in space.
This is known as computable context.
And this is what HSML, hyperspace modeling language, was made for.
And what are some of the contextual elements that can be programmed?
Location, the where, the when of anything in any space.
And you're talking about reality, the different realities, spaces, time, and channels as well.
And then activities, so the what and the how.
And this is in regards to things like rights and credentials or claims or activities.
And then when you're talking about identities, the who and the what of anything in any space,
you're talking about authority or domains or users or assets.
So all of these contextual elements can affect the expression of the shared information by and between anything.
So belief updating through context and sensors.
So HSML is a cipher for context.
The Spatial Web, which is web 3.0, the next evolution of the internet,
is a library of spaces that contain objects, people, places, and things.
These objects do things and change over time.
The context or circumstances that govern these shifts and changes is the most important factor to consider
if we're to understand how objects relate to each other, to people, and to their environments.
So the Free Energy Principle and HSML.
The Free Energy Principle is perfectly suited to the programming language of the Spatial Web.
HSML, the hyperspace modeling language, which enables computable context based on defining, recording, and tracing
the changing details in physical and digital dimensions, social dimensions, meanings, culture, conditions, circumstances, situations,
whether geometrical, geopolitical, or geosocial by nature.
Self-evidencing and belief updating.
So HSML computes context, enabling the AI's perception to understand the real-time changing state of anything in the world,
accumulating evidence for a generative model of one's sensed world, also known as self-evidencing.
So we're talking about multiple agents, so individual intelligences,
and based on each agent's generative world model, unique perspective, frame of reference,
and nested ecosystems of these intelligences, and different levels of self-organization.
So all of this results in a collective shared intelligence.
So, call on architecture and markup blankets.
So the Spatial Web is a holonic structure.
So Active Inference, well, Active Inference AI within the Spatial Web on the versus CosmOS platform
operates with a holonic structure of nested spatial domains.
So if you're not familiar with what a holon is, a holon is where, you know, something can be a whole in and of itself,
and yet also be a part of something greater.
So the human heart is a great example.
The human heart's made up of cells.
Each one of those cells, they're whole cells in and of themselves, yet they're also part of the heart.
And then the heart is a whole heart, but yet it's part of the human body.
So you have this nested structure of whole parts that are governed by the outside part,
but still have this intrinsic governing going on within itself as well.
So each component is a whole element, part of the entire organism.
They're nested entities and they're governed by the rules of the greater influencing organism.
And then they have inherited, they inherit the governing and it's passed to the internal parts that are nested within it.
And each part has its own governmental considerations for its specific intrinsic requirements as well.
So this is how the Spatial Web is set up to work as well.
So when you're talking about spatial domains, you're talking about, for instance,
you can have a restaurant that's inside of a skyscraper building that's inside of a city,
and that city is inside of a state, these nested domains.
And then the Active Inference AI also includes the principle of Markov blankets at each level of analysis.
So the Markov blankets define boundaries acting as partitions to mediate the interactions between the internal and external states of the spatial domains,
such as like a single unit or a region or entire complex network.
And this results in a self-organizing system.
And a Markov blanket is just a mediator between how things are attuned to each other through the Free Energy Principle.
So nested domains in the Spatial Web.
So one good example of how this may work is, you know, if you take a factory, right?
So, you know, a factory is a part of the supply chain and has raw materials feeding into it from various locations.
Like mines or, you know, anywhere.
And then the factory produces finished goods that may ship to another destination, like a warehouse, right?
Like a distribution warehouse.
So just as that factory is an object within a larger ecosystem of the supply chain,
every object within the factory belongs to its internal ecosystem, right?
So with a factory, you've got all the internal ecosystem of what's going on in that factory.
But yet it's still part of this global supply chain with, you know, raw materials being fed into it.
And then when it's done with what it's doing, it's feeding out to other like distribution, you know, pathways.
So you have an internal and an external ecosystem,
and they simultaneously operate according to the individual internal and external standards.
The interdependencies, the interrelationships.
So, you know, this is how you can see things working within the Spatial Web.
So every object within the entire Spatial Web network is part of an interrelated ecosystem
that feeds a continuous stream of real-time context between all points in space and time.
This continual interaction and communication stream takes note of all the nuances and changes within the relationships
between all objects and the parameters that govern them,
which leads to adaptive collective intelligence automation.
So you have programmable spaces.
And, you know, within these spaces, everything within these spaces have a digital ID.
And the way the Spatial Web is set up is it enables zero knowledge proofs between all of these entities.
So anything inside of any space is uniquely identifiable and programmable with a digital twin of the earth,
producing a model for data normalization.
So by programming context into everything in any space, it creates this digital twin of the space.
So the Spatial Web becomes a digital twin of everything from the planet to every single system,
every single object within it that's on the network.
So.
The contingencies and changing details, inherent qualities, circumstances for all objects and situations can now be measured and computed,
providing a basis for the AI perception affecting all entities and their interrelationships to each other.
So you're talking about adaptive intelligence automation, security through geo encoded governance,
multi network interoperability, and it enables all smart technologies to function together on a unified system.
So, you know, when you consider all of the Web3 technologies, all of the extended reality technologies, you know, AR, VR,
distributed ledger technologies. So you have all of these technologies that are siloed and disparate.
This brings all of those technologies onto a common unified network now with a common language between them.
So it makes all of these all of these technologies then become interoperable.
And when you're talking about smart technologies, when you're talking about like the Internet of Things,
there's been no common language for these Internet of Things to talk to each other and communicate.
So the Spatial Web brings all of the Internet of Things onto the common network now where they become baked into this?
this network and informing the AI, so all of the data being gathered by all of these sensors or cameras or, you know,
the context that's baked into the protocol. This is all the data that is now coming together that is continually updating in real time and informing the AI.
So you have ecosystems of nested intelligence. The design of intelligent systems must begin from the physicality of information and its processing at every scale or level of organization.
So within the Spatial Web, you have AI that scales up the way nature does, aggregating locally contextualized knowledge bases and acting across ecosystems.
And this maximizes efficiency. So this is the complete opposite of the way the machine learning models work because they're top down.
It's just massive amounts of data. And, you know, that's what's training the machine model AI.
But there's a cutoff date. So then that model now can only reference this historical data that it's been trained on.
And, you know, again, it's just a it's it's a pattern recognition machine.
The algorithms are just to make sense of the data that it's been fed and how to recognize patterns within it.
Every time those models have to compute and try to perform an output, it requires massive amounts of energy because it still has to pull from its library, this massive library to try to make sense of things.
Now, the way that the Spatial Web works with the Active Inference AI is you have any amount of data.
You know, small amounts of data can now be made smart because you have context informing the AI and you have sensors that are giving it real time data inputs to let it kind of look outward and see what's happening in the world now.
Not, you know, referencing historical data.
So this leads to minimizing complexity.
So when you're talking about the machine learning versus the Active Inference for efficiency and accuracy.
The more complex a system is, the more energy it consumes.
So that's what I was just referring to with all this big data approach on these machine models.
Active Inference in the Free Energy Principle naturally minimize the complexity.
That's the whole idea with the Free Energy Principle is to minimize the prediction error and use the information that it can sense.
Right. So it's taking in the senses from sensors, like the Internet of Things and cameras and things like that.
But it's also taking in what it knows about.
It's, you know, the data at hand. Right.
And it's informed to the call, the Spatial Web protocol with all of the context, all of the attributes around everything in any space or any data set.
So, you know, sensor data is noisy and ambiguous, but HSML provides clarity with specific and precise contextual data to narrow the complexity and close the gap on the free energy.
So more certainty means less noise, and that that equals free energy is reduced faster and lower.
So it's a it's a faster way to operate, more efficient.
And, you know, another point to this, which is really interesting, too, is that, you know, most of the data that exists exists behind.
Password walls right behind gated it within gated password areas, right, whether it's, you know, on the Internet and it's all the data that people have behind a password or whether you're talking about like an enterprise organization that has all their proprietary data that's in time.
Internal, you know, so the awesome thing about the Spatial Web is that an Active Inference is that you can be within this network and still have all of your proprietary data gated off because the protocol allows for that security.
You know, it's a it's gated at every touch point.
So you can put boundaries around your particular data, but still be able to access the the the power of the network and the power of the Active Inference.
AI now for your proprietary data because it can take that small amount of data and make it smart.
So this is a game changer for, you know, access to AI for any systems in any databases.
So embodied AI.
Active Inference mimics biological design.
And it's like embodied AI with the ability to take action.
And this is the core engine of the Spatial Web.
So what makes Active Inference so accurate?
Active Inference is so accurate because it continually looks outward into the world, measuring the world in real time through a global network of sensors, IoT devices, cameras, robots, drones, anything that's connected within the Spatial Web, the digital twin network of the world.
HSML informs the AI with precise data, extracts the signal from the noise, minimizing the prediction error.
And this mimics the way humans and animals make decisions.
So the perception of the world in the Spatial Web, Active Inference, AI, you know, create this creates a cybernetic feedback loop of perception of the world and it updates the model of the world with the belief of what it knows to be true, gaining the understanding of the intricacies and inner workings of the world.
So that it can make decisions and take action.
And it provides ever, ever evolving intelligence.
So the more this feedback loop plays out, the AI learns more about the world and the results of the actions taken just as a child learns about the world as it grows and interacts with it.
And the more accurate this AI becomes by further updating its understanding of the world.
So it's been described to me that, you know, when versus launches their COSM operating system, and then, you know, which is going to be later this year, it's going to enable everybody to be able to build these intelligent agents on top of the network, right?
They're they have a intelligent app store, that's going to be launching with the operating system.
So then everybody can make these intelligent agents.
The difference is these agents.
So when you build an app on say, like the Apple App Store, or Google Play, you're building a siloed piece of software, right?
Those apps are not aware of each other, they just do whatever their function is to do.
The difference is these intelligent agents that you're building on COSM are going to be aware of each other and aware of the network.
So they're going to be empowered with the AI and be able to act as an agent within the network.
Now, it's been described to me that, you know, when people are first building these, you know, intelligent agent apps, it's not going to be like this stark difference of like, the power of what it can do versus the power of what these machine models can do, because they're all pretty, it's all pretty impressive right now.
But the difference is, is if you take like, the comparison of like a chimpanzee and a toddler, at first they seem about the same intellectually.
But the difference is that toddler is going to grow, it's going to grow into a full fledged adult, it's going to continue learning, whereas that chimpanzee has maxed out.
So that's going to be really interesting to watch over the next, you know, year or two is that we're going to see this Active Inference AI really modeling the same way that humans learn and it's going to grow in intelligence with this, you know, scores of these intelligent agents now all working together within the network.
So now one of the really awesome things about this too, is that the Active Inference AI is explainable, auditable and governable.
So versus AI just published a groundbreaking industry report about a week, week and a half ago, called designing explainable artificial intelligence with Active Inference, a framework for transparent introspection and decision making.
So Active Inference is explainable AI.
Now, how, how can this be? Well, Active Inference can self report. So machine learning models, they're black boxes, you know, and and therefore they can't quantify their uncertainty.
They're unobservable, unalterable and unknowable. Basically, the the way the algorithm is processing the data and coming up with its output, you can't see what's happening, you can't know how it's coming to its decision.
It's just this black box that's happening. And there's no way to really know what it's doing just how you know, the input and the output. So you can't explain that.
Now, one of the interesting things, you know, with this call for, you know, putting governance around AI is that if you have these black boxes that are not controllable, and not explainable, how do you govern that?
So, you know, the only options have been to, you know, either, you know, regulate the the companies that are developing these, you know, these tools, or to just let the free market reign. Now, letting free market reign is a little bit tricky with AI, because that can really lead to like this AI arms race kind of a thing, you know, for AI domination.
And that, that that has some risks to, you know, like the human nature, right. So, and then the other problem with regulating the companies that are developing these tools is that you're asking them, you're basing those regulations off them being able to do things like, you know, explain how the results are coming, you know, to fruition through their tools, or holding them accountable for, you know,
for outputs that are, you know, false, or, you know, causing harm to anybody, or, you know, different things like that, which you really can't do that either. Because what's happening within these tools is not controllable. It's not auditable, it's not controllable. So there's a real issue with governance around these machine model AIs.
Now, with Active Inference AI, it is completely explainable, auditable, transparent. And when you're talking about the the self report, you know, Active Inference AI is capable of introspection.
So this enables the intelligent agents to access and analyze their own internal states and decision making processes. So we get better understanding of their decision making process. And they have the ability to report on themselves to basically report on how they arrived at their decisions.
Beliefs and belief updating are known. So this, this dissolves the explainability problem of the conventional AI.
And then you also have programmable intelligence. So versus refers to this as code as law.
So the act of correcting a machine occurs within the code within the computational architecture of versus AI system, human law can now be transformed into computable law that AI can comprehend, abide by, and then act accordingly within its decision making process.
This is a process which is fully auditable, knowable, and it updates in real time. And versus has been proving this concept in a program called Flying Forward 2020.
And this is a European drone project.
The conducted with the European Union. And, you know, there's eight or 12 different countries involved. I'm, I'm not sure. But basically, what they've proven is that they can take the the Spatial Web protocol, the HSTP and HSML.
And they can translate human laws, all the laws around like the airspace laws, and you know, laws, how how they shift crossing country boundaries, different things like that.
They can take those laws, put them in a programmable, you know, code through the protocol that the AI within the drone can understand, and then abide by.
So they've, they've met with great success through this project. And they've, they've proven that, you know, these drones can deliver medical supplies, you know, to a hospital crossing borders into various air state airspaces, you know, understanding no fly zones versus fly zones, all of these things.
So basically, human law computable that the AI can understand and abide by. So when you're talking about AI governance, you know, this, the protocol
allows you to actually program law that the AI can understand. So then the other aspect of this too, is, you know, humans with AI, because, you know, there's a lot of
there's a lot of fear baked into people, especially in regard to all these sci fi scenarios that have played out in, you know, fictional books and movies and things like that. But one of the great things about the Active Inference AI within the Spatial Web is that the AI grows in tandem with the humans, you know, because you can take programmable laws and
make it to where the AI understands and you've got this symbiotic relationship between the AI and the human, it's a network system that operates in tandem with humans. And then the AI is growing its intelligence in sync with the growth of humans and the world, right? So it makes a controllable AI.
So in versus white paper, you know, one of their opening statements was that the the purpose of the white paper, its denouement is a cyber-physical ecosystem of natural and synthetic sensemaking in which humans are an integral are integral participants, what we call shared intelligence.
So versus AI and the Spatial Web foundation offer us the framework in which we can build an ethical and cooperative path forward for AI and human civilization. And one thing I want to read to you from the white paper that's, you know, specific about this is, is this, so quote, we believe that developing a cyber-physical network of emerging intelligence in the manner described by the white paper is a
necessary and appropriate process. And the process described above not only ought to, but for architectural reasons must be pursued in a way that positively values and safeguards the individuality of people, as well as potentially non human persons.
So, in the late 1990s, before the widespread adoption of the internet, as a communication technology, a future state of society had been hypothesized in which the intrinsic value of individuals is acknowledged in part because knowledge is valuable and knowledge and life are inseparable.
That is, each person has a distinct and unique life experience, and as such knows something that no one else does.
This resonates deeply with our idea that every intelligence implements a generative model of its own existence.
The form of collective intelligence that we envision can emerge only from a network of essentially unique epistemically and experientially diverse agents.
This useful diversity of perspectives is a special case of functional specialization across the components of a complex system.
So, you know, within the versus white paper for this Active Inference, AI, you know, they're very clear about the importance of the human experience and the various human experiences in tandem with the growth of the AI within the Spatial Web.
So I just thought that was really important to to kind of let people know.
So then you have accurate world models.
Collective intelligence trained on real time data evolves, making decisions and updating its interior model based on what is happening now, not on historical data sets.
Active Inference AI is not a language model generating words about the world based on outdated knowledge it's been fed regarding the world.
Active Inference is like a biological organism that perceives and acts on our world by generating more accurate models, understandings and beliefs about our world.
These ever more accurate world models enable better decisions, a smarter world.
And this is the true measure of intelligence.
So Active Inference AI as the operator, this is the final section.
So you have the Internet of everything.
The days of training AI on big data will give way to an interconnected Internet of everything that deploys Active Inference AI throughout the network.
Inherently secure and accurate because it takes any point of real time data and makes it smart through an empowered ecosystem of interconnected AI apps that act as intelligent agents.
Active Inference, QASM and the Spatial Web.
Active Inference AI inside of the versus AI QASM operating system has access to the entire Spatial Web with IoT sensors and cameras and all context markers attached to all objects within all spaces within the network, tracking and identifying changes over time.
This AI becomes an ecosystem of intelligent agents that are all interoperable over HSTP.
So what does this mean for the planet?
Active Inference AI can run the planet.
Dan Mapes, who's one of the co-founders of versus, he describes the Spatial Web with Active Inference AI as a nervous system for the planet.
Together, these technologies enable the only AI in the world that can run critical operations for systems, infrastructures, smart cities and the planet.
So when you're thinking of climate or traffic control or smart cities or advanced education or hospitals or airports, all of these are critical systems that need accurate functioning of the AI.
You cannot rely on machine models who give you plausible answers, plausible outputs that sound accurate, but aren't necessarily accurate because they're just trained to make it sound appropriate.
Appropriate and accurate are very different things.
So because the Active Inference AI is based on real time data, actual data, context that's baked into everything, it's an accurate form of AI and it can be trusted to run these critical systems.
So it can be the operator.
And then we come to sentient intelligence.
So this is the missing piece of the data puzzle that gets us to artificial general intelligence.
We now have the world model and we now possess the ability for continuous and adaptive context markers, enabling a cognitive world, a cognitive model of this world and the ability to compute awareness.
So this is taking us from the artificial narrow intelligence, which is what these machine models are, to potentially artificial general intelligence and then artificial super intelligence.
Because the more the Active Inference AI learns about the world, it can start to question and become curious about the world.
And it's the difference between asking the AI agent something and then having the AI agent ask you something to clarify what you want or what your needs are.
It's that curiosity back on you that'll take us to the artificial super intelligence.
So I'm just going to close by letting you know that versus AI, their CosmOS is going to be launching at the end of the year.
And the idea is let's create a new world together.
They've created the tools for anybody to create the AIs on top of.
So, you know, it's a huge opportunity.
They're going to be launching the beta at the end of this year.
If you go to my website, DeniseHolt.us, there's a menu item where you can sign up for the beta if you'd like.
So if you'd like to be considered, feel free to sign up there.
And then, of course, I have a podcast and it's on YouTube or Spotify, Apple, anywhere you find a podcast.
But if you'd like to learn more about this, you know, that's really my role is I've just been educating on the Spatial Web protocol and this Active Inference AI.
So there's a lot of information on my website.
There's a lot of articles on the podcast.
There's just a lot of information so that you can learn more.
So I think that's it.

53:56 _Daniel:_
Awesome. Thank you.

53:59 _Denise:_
Thank you, Daniel.

54:00 _Daniel:_
All right. I'm going to come back on video and then....
All right.
Well, thank you for the amazing presentation.
There's many places to begin, many ways to do it.
But again, thank you again for sharing this information. So?

54:20 _Denise:_
My pleasure!

54:26 _Daniel:_
I'll start by just asking the live stream viewers if they want to ask anything, just put it in a live chat.
And then perhaps -- just there were so many topics that you brought up that perhaps I can just reflect on a few of the topics and just kind of
summarize it as as I heard it, especially where it's different from what we've heard in terms of framings on other streams where we go way more into the technical.
But but there are just so many great ways that you had of framing what was happening.
OK, so good?

54:57 _Denise:_
Yeah, sounds great.

54:59 _Daniel:_
All right. So you described Active Inference as biologically based;
and one way that... biologically INSPIRED, perhaps exactly, but based upon biological systems.
And it made me think about the way of viewing the world in terms of its spatial connectivity and then thinking about the world in terms of its statistical or causal connectivity.
And so when people think about what would biologically inspired AI look like, they might think about the actual connections amongst the neurons in the brain or the actual connections amongst ants in the colony.
But that connectivity allows solving that problem.
So if you want to solve some different problem or some thing else, you need to learn from those structures, but not copy them verbatim.
And so that level of learning that we have to pull back to and the level of thinking is about the agent in their engagement with the environment and the minimization of surprise instead of the maximization of reward.
And that's a really clear path, I think, from what we can generalize from natural intelligence towards how we can think about what kinds of imperatives we should design and what design principles should be for synthetic intelligent agents.

56:20 _Denise:_
Absolutely. Yeah.

56:24 _Daniel:_
Okay.
What brought you to this presentation? Like what was your way into the Spatial Web or how did this even come to be?

56:36 _Denise:_
Well, so Dan Mapes, who's one of the co-founders, he's a longtime friend of mine.
And, you know, so I knew when he and his co-founder, Gabriel Rene, who's the CEO of Verses, when they were starting Verses back in 2016, 2017 - so, you know, I knew what I knew what was coming.
And I've been kind of watching it unfold over the last, like, you know, handful of years.
And so then last summer, you know, it became really clear to me that, you know, Verses was getting close to launching to the public.
You know, they've been working over the past, you know, couple of years with like Fortune 500 companies, with, you know, governments and smart city development all over the globe.
They've been involved in this Flying Forward project.
You know, they've been deep into the supply chain - one of the first apps they created was an app called Wayfinder, which is specifically built for, you know, the supply chain.
And so, you know, watching all of that, but then knowing it's coming to later this year, I was like, okay, there's a transition.
And, you know, people need to understand what's coming, because, you know, I've been involved in like, you know, blockchain and Web3 for the last, you know, handful of years.
And so you see all these amazing technologies being built and all these awesome projects.
But one of the biggest problems is that they're all siloed and the interoperability is the biggest struggle.
So, you know, to me, it's like, okay, you know, these people need to know that this is coming.
And, you know, the interoperability is going to be there for, you know, not just within the Web3 or the blockchain space, but really all technology.
Really, you know, anybody who has a business that is present on the World Wide Web is going to want to evolve that presence into the Spatial Web, just for the empowerment of what this AI and this interoperability is going to do for their business.
So I knew there was a learning curve.
So that's really what I set out to do, was to kind of break down that learning curve and really start to educate people about the protocol, about the AI and about what to expect.

59:14 _Daniel:_
All right. Great. Um, few more questions. 
Again, we're just starting to explore this.
And so whatever you do or don't know is all good. 
How will the open source nature of the web and the ecosystem around Active Inference related technologies be secured?

59:34 _Denise:_
Well, so, so basically, you know, you have to think of the COSM operating system as that's, that's literally the operating system that is going to enable people to easily build with build these intelligent agents within the Spatial Web network, right?
So, you know, that allows anybody to come on this network and build these, build these intelligent agents, these intelligent apps, right?
So the beauty of it is that the protocol itself for the Spatial Web, it bakes in security at every touch point, right?
So you can program in access permissions, different things like that into whatever you're building.
So it really becomes individualized, right? You can, you can gate off to where, you know, you have data that's proprietary.
And then you have data that's allowed to be accessed by the world.
You can, you can make it look however you want for whatever you're building, whatever your project is.
And what these intelligent apps then become is, it's your opportunity to share your knowledge with the world, right?
And you can share it to whatever extent that you, that you want to, you know.

1:00:59 _Daniel:_
Thanks.
When talking about just a few terms, I wrote down - culture, ownership, authority -
How do differences amongst locations and peoples play out when there are such different concepts of those mentioned terms and many other terms that arose?
It might not just be something like, well, the drone can go a hundred feet here and 10 feet here.
What about when there's different concepts of authority and ownership and justice and culture?

1:01:33 _Denise:_
Right. So, well, so that's, that's one of the, it's one of the beauties of the world is that, you know, we all have our own unique understandings, our own unique beliefs, our own unique cultural traditions.
And the differing governing bodies and types of government, right?
So the protocol needed to be built to be able to preserve all of that?
"You know, you don't want there to be this next evolution of technology that includes AI that becomes this dictatorship of, you know, "This is the way the world's going to be,"
"and this is how everybody has to operate!"
This preserves the uniqueness and the individuality of everybody in any area.
So really the way this plays out, it's going to be able to be customized for region, for, you know, cultures, belief systems, you know.
So it's like this socio-technical ability to, you know, safeguard and preserve traditions and different things and mindsets.
So, you know, really it's, it's, it's, you know, it's not going to be a hindrance as much as it is going to be something that, you know, kind of preserves the beauty of individuality.
And so when you're talking about systems like that, like you were talking about, you know, it's pretty much going to be similar to where it is today.
You know, like, you know, people have the right to? the right of refusal, right? [Laughs]
"You know, even in a restaurant, you know, "no shirt, no shoes, no service," you know!
So, you know, there's not going to be a lot of difference with that, you know.
And then, so when you're talking about things like drone delivery and things like that, then you're going to have other standards bodies that are making those decisions to, you know, make things more inclusive rather than, you know, kind of silliness of, you know, denying people for whatever reason.

1:03:48 _Daniel:_
Wow! All right.
I'll ask a question from the live chat.
Bert asks, "Thank you for the presentation.
What is the limitation of implementing this vision?
Is it getting people to use the hyperspatial language or getting Active Inference working right?"
Or I'll add a secret third thing.

1:04:11 _Denise:_
Well, so, so, you know, I've had people say that, you know, ask that with me saying, you know, "Well, what's the guarantee that anybody's going to, you know, you know, take part in this new Spatial Web?""
And it's you have to think of the way the Internet has evolved, right?
This isn't just like this whole separate network that you're going to try to bring everybody on to.
It's the same network we're already on, and it's just evolving the capabilities within that network.
So, you know, when you think of the way the Internet started, you know, when you had like TCP/IP and the killer app was email.
And then Sir Tim Berners-Lee created HTTP and HTML.
And then you had the World Wide Web, right?
So it didn't get rid of email!
It just enabled this whole other capability that now people could build websites.
Now, instead of just sending, you know, digital messages from computer to computer, you could actually bring an audience to your web page and engage that way on the Internet.
And you could do it that way on like a property within the network.
So that's all that's happening right now, is that we're just taking the capability from this Web 2 environment that really lacks security;
and it lacks protection for people and their data;
and it opens up a lot of vulnerabilities, because you have to all of the transactions are taking place,
the data is transacting on a website, which is the property of a centralized organization, right?
So what this is doing is, it's decentralizing it;
now, everything in any space becomes programmable and becomes a spatial domain, right?
So now you have self-sovereign identity;
you have zero-trust architecture;
you have this ability to program 3D spaces.
So it's going to be a natural progression for people to come, you know, tp take advantage of this new programming language to, you know, be able to empower and expand what they can do within the network we already are on.
So, you know, the World Wide Web is like 40 billion computers!
Now we're evolving from just computers to spaces and objects and everything within there.
So, you know, it's not going to be a matter of people? getting people to do that.
It's, you know, people are going to go, "Wow, I can do that!"
And, you know, it's going to be a natural progression.
As far as the Active Inference AI, it's going to start working within the network, and it's just going to grow.
So the more people are engaging on, you know, within the Spatial Web network, and the more people that are building these AI apps?
And I think, if we look at what's happened just in the first six months of this year since ChatGPT came out, with all of the, you know, all of the open source and everything that's been available as soon as it got available to the public -
And now we can tinker with it.
Now we can build things.
You've had an explosion of development!
So, you know, with the ability to build these intelligent agents within the network and do it very easily and have this interoperability within the network, I just see it as, we're going to have this explosion of development.
So that's, of course, that's my opinion, but that's what I see happening.

1:08:01 _Daniel:_
You stake your claim!
That's a beautiful thing.
I'll ask another question.
Your answer led perfectly to it.
Bert asked again in the chat:
"Also, is there a resource where we can learn more about how to build a hyperSpatial Website?"

1:08:18 _Denise:_
So, I don't think there? I don't think those resources are out yet.
And, you know, and it's not going to be a website.
So, you know, it's as soon as the COSM operating system launches, the AI is going to become a tool for building anything.
So the other side of this app store where you can build an intelligent agent is the interface.
The public interface is an intelligent agent called GIA, and it stands for General Intelligent Agent.
So GIA then becomes the interface for the public of the network, of the Spatial Web.
So GIA is going to become your personal assistant -
everybody's personal assistant.
GIA will be able to act on your behalf within the network.
So, you know, just like with ChatGPT-4 and how the AIs are starting to be able to program.
So within the Spatial Web, the AI is going to play an integral part in creating your own intelligent agents and, you know, doing your own?
establishing your own presences and, you know, spatial domains and things like that.
So I don't have a lot of detail on how that's going to look or work, but that's my general understanding of it.
So I don't think there's going to be a huge learning curve when it comes to that.

1:09:59 _Daniel:_
Wow. All right! I'll go to another question. Dave asked in the chat,
"Does Verses plan eventually to expand the inventory of Element types (beyond the 12 mentioned in today's presentation)?
People negotiate concerns that don't seem to fit easily in this framework."

1:10:19 _Denise:_
Yeah. So I don't know. I don't know if I can really answer that.
And the reason why is because I don't, I don't -- my technical knowledge of what's happening behind the scenes is very limited.
So the answer could be yes; it could be it's already there.
I mean, the reality is, is those those 12 aspects are just, you know, kind of a generalized idea of what you can program.
But when you're talking about, you know, HSTP being multidimensional, you know, and you can program in everything from like, you know, temperature to, you know, pressure to, you know, you can... you can... you can?
If it's programmable and definable, you know, in a computational form, you can? you can bake it into, you know, the context around whatever you're programming.
So, you know, in that respect, it's it's pretty unlimited, except for that limitation, as long as it's measurable and definable in a computational way.

1:11:30 _Daniel:_
I'll try to restate that, just how I heard it, because I think it's a really important point.
The 12 (again, this can be totally off base, if I don't have any information), but the 12 components shown are kind of like fully one way of fully showing your work.
But when you really get down to the last mile and the shoes on the ground, you're in the realm of the particulars and the specific measurements, at which point complex cultural topics will be playing out through the minute particulars, not necessarily inheriting some stringency from a top-down ontology.
If that's fair, I just want to kind of say it that way.

1:12:19 _Denise:_
Yeah.

1:12:20 _Daniel:_
OK! You mentioned, I think, a few times in the presentation, the idea of realities.
So, yeah, we have our beloved cyber-physical reality.
And what other are the plural realities?

1:12:34 _Denise:_
So basically, when you think of being able to, you know, program the context into the spaces, right, then that provides you with a digital twin, which automatically is giving you this mixed reality ability.
Right? Because, you know, digital twin and then physical reality, this is going to open us up to this augmented existence, this augmented reality existence that we all kind of envision.
But the foundation hasn't been there.
The framework hasn't really been there.
This is providing that framework.
So we're going to? we're going to see this kind of augmented reality future for us, you know, where we're able to cross, you know, cross through mixed realities.
You're going to have the virtual reality, you're going to have the augmented reality, and then you're going to have the physical reality.
And there's going to be an unlimited way of mixing that.
And then the other aspect of this, too, is when you talk about like virtual reality and you talk about the metaverses and different, you know, metaverse experiences, you know, I think one of the reasons why the metaverse experience has been so lackluster is because they're siloed right now!
When you consider the Spatial Web, that's going to be able to make it to where you can jump in and out of these virtual reality spaces.
You can actually take your assets from one space to another space, because all of it then becomes interoperable over the network.
So this is going to really open up - everything that we've been wanting to do is going to now be possible within this Spatial Web network.

1:14:29 _Daniel:_
Great. All right. As we kind of begin to land the plane, I'll just reflect on two or so positive aspects that I think are part of the vision, which we will, of course, await future sensory observations to confirm, reduce our surprise.
But in Active Inference, what we expect is what we prefer.
So if we think it's the most likely path forward, then c'est la vie.
So the first positive thing is that it starts from the actual and the measurements, defining things at some defined cyber-physical layer; and (potentially extrapolating here, but)
earlier this week, we had a GuestStream with Mahault [Albarracin] and Maxwell [Ramstead].
And in the quantum Free Energy Principle approach to the brain, there is a top level decision maker within that blanket where the buck stops.
So that doesn't mean like that the brain is not composed of, you know, as a component of part of larger compositions; but within the given blanket, there's a highest stop.
So instead of handing our self-sovereigntizing ability and intelligence to the black box, here we can start from the actual, maybe even pick up and stabilize or change what we already have.
So rather than proposing just a totally different future that some scaling law is going to help us get to, maybe or maybe not, we start with like what we already measure and the decisions we already make.
So I very much appreciate the pragmatism. What else might you reflect on that point?

1:16:18 _Denise:_
I think you said it well. Yeah.

1:16:23 _Daniel:_
OK! Then the second piece was that everyone's knowledge is adding something.
It might be a close sample or a distant sample on some dimension in some setting; but everyone, every cognitive agent is adding non-zero information.
And there's a lot of technical details underneath why that is.
The amount of information added might be very small for a given question; but because of differences, we literally get more perspectives.
So we always see better with more perspectives if we have the right integration approach.
So that's also very powerful. And it's something that is formally true with the math and the statistics.
And I think we want it to be true for our ecosystems.

1:17:17 _Denise:_
Right. Yeah, absolutely.
And it's interesting because, yeah, you want to preserve that, the diversity of information and opinion and have that accessible.
For sure.

1:17:39 _Daniel:_
Awesome. Well, it will be quite the coming days, probably, or at least as expected or preferred.
But we'll very much look forward to you coming back on the ActInf Streams, as well as some technical presentations that might help our community and our Institute learn, more about the details, or more philosophical discussions.
The whole spectrum of learning and applying and implementing these technologies will be really important to characterize.
But for sure, it's been incredible to have you share this first bit.
Is there any last words you'd like?

1:18:22 _Denise:_
No, just thank you so much for having me.
It's been a pleasure.
And I will throw this out there.
I know there's not a lot of information available out there regarding the Spatial Web and the Active Inference AI.
So if anybody has any questions, feel free to reach out to me.
You can reach me on Twitter or LinkedIn or my blog, deniseholt.us.
There's plenty of ways on there to reach me.
So I'm happy to answer any questions anybody might have.

1:18:54 _Daniel:_
All right. Thank you, Denise.
Till next time.

1:18:58 _Denise:_
Thanks a lot. Bye bye.
