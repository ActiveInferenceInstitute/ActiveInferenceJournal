1
00:00:07,674 --> 00:00:08,808
Hello, everyone.

2
00:00:08,808 --> 00:00:10,777
Welcome to the Active Inference Lab.

3
00:00:10,777 --> 00:00:13,446
Today it is August 20th, 2021,

4
00:00:13,713 --> 00:00:17,684
and we are here in guestroom number
nine plate one with some awesome guests.

5
00:00:17,984 --> 00:00:21,554
So we'll just start with introductions
and then head into a short

6
00:00:21,554 --> 00:00:24,557
presentation
before a question and answer period.

7
00:00:24,991 --> 00:00:27,827
So if you're watching live,
definitely write questions in the chat.

8
00:00:28,261 --> 00:00:29,129
So I'm Daniel.

9
00:00:29,129 --> 00:00:32,098
I'm a researcher in California and Blue.

10
00:00:34,034 --> 00:00:34,934
And Blue Knight.

11
00:00:34,934 --> 00:00:38,104
I am an independent research
consultant in New Mexico,

12
00:00:38,671 --> 00:00:41,541
and I'll pass it to Rafael.

13
00:00:41,541 --> 00:00:42,842
Hi, everyone.

14
00:00:43,109 --> 00:00:44,544
Thank you guys for having us over.

15
00:00:44,544 --> 00:00:47,580
I'm Rafael
I'm also an independent researcher.

16
00:00:47,580 --> 00:00:52,952
I have a day job at Google that has some
but not a lot to do with this topic.

17
00:00:53,119 --> 00:00:58,224
And I been working with Brian of

18
00:00:58,224 --> 00:01:02,462
and Jacob on this topic
for about a year and a half now.

19
00:01:02,762 --> 00:01:04,364
It's been a wild ride.

20
00:01:04,364 --> 00:01:05,732
So run outs go ahead.

21
00:01:07,767 --> 00:01:08,968
And everyone.

22
00:01:08,968 --> 00:01:10,737
Thank you. Daniel Blue.

23
00:01:10,737 --> 00:01:14,874
The only thing that I'm up to this week
at Carnegie Mellon.

24
00:01:15,141 --> 00:01:16,709
School of Business.

25
00:01:17,210 --> 00:01:20,647
My areas of research, our collective
intelligence, better to come from reading

26
00:01:21,581 --> 00:01:24,150
wasn't wanted in such a technical
architecture looking at,

27
00:01:24,150 --> 00:01:26,219
but it is at adaptive systems

28
00:01:27,387 --> 00:01:31,491
you know I was very interested
in the actor interesting book.

29
00:01:31,491 --> 00:01:34,561
We met Rafael and Jacob met up,
you know, across

30
00:01:34,561 --> 00:01:37,864
different CIA conferences
and got this project going.

31
00:01:37,864 --> 00:01:42,335
So we're really excited to talk more
about and learn from all the discussions.

32
00:01:42,502 --> 00:01:43,269
We have

33
00:01:44,304 --> 00:01:45,438
always

34
00:01:46,940 --> 00:01:47,707
sounds cool.

35
00:01:47,707 --> 00:01:52,212
So let's go to Raphael's presentation
and then we'll just have

36
00:01:52,212 --> 00:01:54,347
a bunch of time for questions,
so go for it.

37
00:01:55,281 --> 00:01:56,082
All right.

38
00:01:56,082 --> 00:01:57,717
Before I get started,
can you confirm this?

39
00:01:57,717 --> 00:01:59,419
You can see in your right.

40
00:01:59,419 --> 00:02:00,820
Yeah, we see the slides.

41
00:02:00,820 --> 00:02:01,754
The slides. Perfect.

42
00:02:01,754 --> 00:02:03,690
All right. Cool. All right. So

43
00:02:06,326 --> 00:02:08,361
what are we doing here?

44
00:02:08,761 --> 00:02:10,630
So as we mentioned,

45
00:02:10,630 --> 00:02:13,766
the the interest here
is to try to understand

46
00:02:13,766 --> 00:02:16,803
better the phenomenon
of collective intelligence.

47
00:02:17,137 --> 00:02:20,073
And so two examples
here of what we're talking about,

48
00:02:20,140 --> 00:02:22,375
and they're pretty different examples.

49
00:02:22,375 --> 00:02:26,679
One of them is a pretty classic
example is the murmuration starlings.

50
00:02:26,679 --> 00:02:31,217
So top left, I know the bird
that's solving a puzzle on the top,

51
00:02:31,217 --> 00:02:32,552
right as a crow, not a starling.

52
00:02:32,552 --> 00:02:34,621
So I'm cheating a little bit,
but that's fine.

53
00:02:35,555 --> 00:02:38,892
So the on the bottom,

54
00:02:38,892 --> 00:02:43,830
the example is the discovery of the Higgs
boson, which is an amazing example of

55
00:02:44,430 --> 00:02:47,033
kind of a large scale,
long term sensitive collaboration.

56
00:02:47,033 --> 00:02:51,037
So those are both legit
examples of collective intelligence.

57
00:02:51,037 --> 00:02:54,374
And and yet the way that we approach

58
00:02:54,374 --> 00:02:57,944
analyzing
these things is a little bit different.

59
00:02:58,411 --> 00:03:02,582
So if you're doing something around
complex aerodynamic systems

60
00:03:02,582 --> 00:03:04,651
or if the biology

61
00:03:04,651 --> 00:03:08,154
you tend to look primarily
at the collective behavior

62
00:03:08,154 --> 00:03:12,458
and to be able to do that in a computable
way, you assume that individual agents

63
00:03:12,458 --> 00:03:16,496
are following simple rules to react
to the environment and to their peers.

64
00:03:17,430 --> 00:03:19,098
And if you're doing something like

65
00:03:20,133 --> 00:03:22,702
like anthropology or social science,

66
00:03:22,702 --> 00:03:26,773
you're probably thinking of collectives
that look more like the bottom.

67
00:03:26,773 --> 00:03:30,777
And so you're focused on
these really sophisticated agents

68
00:03:30,777 --> 00:03:35,481
that have these complex
social cognitive capabilities

69
00:03:35,648 --> 00:03:39,319
that are the thing, that analyze them
with the ability to focus collective.

70
00:03:39,686 --> 00:03:43,256
And you try to build a picture
of the collective behavior

71
00:03:43,256 --> 00:03:46,226
a kind of bottom up
from the sum of those interactions.

72
00:03:46,759 --> 00:03:50,129
And both are valid perspectives,
of course, but they're speaking three

73
00:03:50,129 --> 00:03:54,334
different languages, and we think that
there must a missing link here,

74
00:03:54,667 --> 00:03:59,205
because if you think about us humans,
I mean, I definitely feel like

75
00:03:59,205 --> 00:04:03,076
I am at the same time,
an autonomous and autonomous individual.

76
00:04:03,076 --> 00:04:06,312
And a member of not just one,
but a bunch of collective right?

77
00:04:06,312 --> 00:04:11,150
So I fluidly go in and out of companies
or sports team or, or

78
00:04:12,352 --> 00:04:13,353
quality

79
00:04:13,353 --> 00:04:16,022
and of course I'm part of my family.

80
00:04:16,022 --> 00:04:20,660
So all these collectives can demonstrate
intelligence behavior that that cannot

81
00:04:20,660 --> 00:04:25,098
be explained explicitly about aggregation
of all of the individual intelligence.

82
00:04:25,098 --> 00:04:26,165
And yet

83
00:04:27,433 --> 00:04:28,935
the collective itself

84
00:04:28,935 --> 00:04:32,705
is a complex system
that is composed of components

85
00:04:32,705 --> 00:04:37,443
that are in and of themselves, highly
autonomous, complex systems as well.

86
00:04:37,443 --> 00:04:41,581
And that's how we framed the goal of our
of our research.

87
00:04:41,581 --> 00:04:44,117
We're looking at
what we call the missing link, which is

88
00:04:45,318 --> 00:04:47,120
a plausible theoretical description

89
00:04:47,120 --> 00:04:49,188
of the functional relationship
between these two skills.

90
00:04:50,189 --> 00:04:54,327
And in particular,
we think that the missing link

91
00:04:54,327 --> 00:04:57,830
will be solid by understanding
what kinds of social cognitive features

92
00:04:57,830 --> 00:05:01,401
enable the formation
of an effective collective within

93
00:05:02,235 --> 00:05:04,937
within these kinds of autonomous
students.

94
00:05:05,805 --> 00:05:06,139
All right.

95
00:05:07,840 --> 00:05:09,409
To do that,

96
00:05:09,409 --> 00:05:13,212
we've been using active inference
as as a framework

97
00:05:13,513 --> 00:05:19,252
since the group here is probably way
familiar with active inference already.

98
00:05:19,252 --> 00:05:22,689
I'm not going to go a lot into it,

99
00:05:23,089 --> 00:05:26,459
just pointing out here
that we're approaching this.

100
00:05:27,260 --> 00:05:30,463
You're might see the language
that's a little bit different

101
00:05:30,463 --> 00:05:34,500
from from some of the canonical stuff
that for Semantic.

102
00:05:34,534 --> 00:05:36,669
But Alex, we're using
some different domains later,

103
00:05:36,903 --> 00:05:38,071
but it's really the same principle.

104
00:05:38,071 --> 00:05:41,441
We're all looking at nature
and as a mark of blanket

105
00:05:41,774 --> 00:05:46,479
and try to to model exactly what's

106
00:05:47,714 --> 00:05:50,416
the generated distribution

107
00:05:50,416 --> 00:05:55,855
that that creates behavior
in that in that sense.

108
00:05:56,022 --> 00:05:59,926
And look at what happens
when you put it against some or

109
00:05:59,926 --> 00:06:03,996
true system and dynamics that are
that are happening in the environment.

110
00:06:04,364 --> 00:06:09,068
And of course you
you, you run the system as an

111
00:06:10,503 --> 00:06:11,037
all right.

112
00:06:12,171 --> 00:06:15,007
Except that in our case
it's a multi scale model, right?

113
00:06:15,074 --> 00:06:18,311
Because we're interested
both in what happens at the scale

114
00:06:18,311 --> 00:06:21,314
of individual agents
and the global system.

115
00:06:21,981 --> 00:06:26,552
For us, it's actually quite interesting
to try to decouple things

116
00:06:26,552 --> 00:06:31,357
and look at what's going on
very specific way.

117
00:06:32,191 --> 00:06:36,028
Modeling many
to many relationships is really hard.

118
00:06:36,396 --> 00:06:40,700
So we really focus on these pairwise
subsystems.

119
00:06:41,100 --> 00:06:46,372
So our our motto is really composed

120
00:06:46,406 --> 00:06:49,909
of a collection of pairs of agents.

121
00:06:50,243 --> 00:06:55,114
They only interact with each other
within a single pair and

122
00:06:56,249 --> 00:06:59,419
we basically compose them

123
00:07:00,019 --> 00:07:03,122
the what we call the system scale model

124
00:07:03,556 --> 00:07:07,493
bottom
up from copies of these pairs of agents.

125
00:07:08,227 --> 00:07:08,961
All right.

126
00:07:09,061 --> 00:07:13,900
So let's look first
at the individual scale, where we have

127
00:07:15,568 --> 00:07:19,906
each pair is operating on the same
physical environment they're sharing.

128
00:07:20,273 --> 00:07:21,441
Then think of them as sharing.

129
00:07:21,441 --> 00:07:25,445
One of these circles,
if you're familiar with

130
00:07:26,145 --> 00:07:28,648
with the McGregor model

131
00:07:28,915 --> 00:07:32,452
that that's been published in 2015.

132
00:07:32,852 --> 00:07:36,122
It's very simple, very simple.

133
00:07:36,122 --> 00:07:36,722
Intentionally

134
00:07:38,724 --> 00:07:40,827
stylized active inference

135
00:07:40,827 --> 00:07:44,464
model that was originally designed
to be analytically solvable actually.

136
00:07:44,797 --> 00:07:46,966
So it allows us to have a really clear

137
00:07:48,100 --> 00:07:51,871
view of what's going on on this system
as a general system.

138
00:07:52,438 --> 00:07:55,808
And we just added
some minimal capabilities.

139
00:07:56,976 --> 00:08:01,247
So each of the agents that are marked out
as little can think of them

140
00:08:01,247 --> 00:08:04,650
as little parts within this
within the circle environment,

141
00:08:05,151 --> 00:08:09,722
they, each of them can only do a couple
of things, which is their capabilities.

142
00:08:10,022 --> 00:08:12,992
They can only observe their own position.

143
00:08:12,992 --> 00:08:16,295
They can't directly
observe the environment or that that is

144
00:08:18,064 --> 00:08:20,299
meaning
they can't observe their own position.

145
00:08:20,299 --> 00:08:23,202
They can only get a clue

146
00:08:23,202 --> 00:08:26,372
which is an on off sensor

147
00:08:26,372 --> 00:08:28,374
generated by a chemical signal on each.

148
00:08:28,374 --> 00:08:32,478
So I'm getting a ping here from
a friendly viewer, also known as my wife,

149
00:08:32,612 --> 00:08:37,350
saying that my image may be blurred
and now it's good father's

150
00:08:39,852 --> 00:08:43,489
yes. It might look a little different,
but I have a high resolution,

151
00:08:43,489 --> 00:08:47,159
one saved locally no matter what
the final process YouTube one looks like.

152
00:08:47,460 --> 00:08:48,794
Thanks, YouTube

153
00:08:49,228 --> 00:08:49,896
all right.

154
00:08:49,896 --> 00:08:51,297
Thanks, YouTube.

155
00:08:52,231 --> 00:08:52,865
All right. Cool.

156
00:08:52,865 --> 00:08:55,701
So as as I was saying,

157
00:08:55,935 --> 00:09:00,973
the main way that agents get information
about their physical environment

158
00:09:01,274 --> 00:09:05,545
is by this sensory state,
which is a binary.

159
00:09:05,545 --> 00:09:09,348
I want a on off sensor
that you can think of it

160
00:09:09,348 --> 00:09:14,253
as being generated by a chemical signal
or a kind of smell on each cell.

161
00:09:14,520 --> 00:09:17,924
And it's emanating from this
from this source for this same source

162
00:09:17,924 --> 00:09:18,824
position.

163
00:09:20,359 --> 00:09:22,328
So that's pretty much it
about the physical environment

164
00:09:22,328 --> 00:09:27,033
and agents can go left
and right or states and so on.

165
00:09:27,033 --> 00:09:31,771
That environment now
talking about the relationship between

166
00:09:33,339 --> 00:09:35,641
between agents and their peers on a pair

167
00:09:36,409 --> 00:09:38,511
there, Kiran,
there's a funny thing to say, but

168
00:09:39,845 --> 00:09:43,749
the the agent can observe their

169
00:09:44,383 --> 00:09:47,720
their peer or their partners
position, relative position

170
00:09:48,187 --> 00:09:50,790
meaning I'm one or two or however many

171
00:09:53,993 --> 00:09:55,261
to the left or to the right.

172
00:09:55,261 --> 00:09:57,663
They can be actually
in the same position as well.

173
00:09:58,798 --> 00:10:02,435
And they can also observe their
their moles.

174
00:10:02,568 --> 00:10:02,835
Right.

175
00:10:02,835 --> 00:10:06,872
They're there, can observe
whether the agent,

176
00:10:06,872 --> 00:10:10,476
the other agent, the partner has gone
to left five or six on the left.

177
00:10:10,476 --> 00:10:11,811
And the last

178
00:10:12,511 --> 00:10:13,613
say, direction

179
00:10:14,347 --> 00:10:14,880
right.

180
00:10:15,982 --> 00:10:19,151
Let's talk a little bit about reward
functions.

181
00:10:19,518 --> 00:10:22,688
The agents have independent report
functions that are to speak

182
00:10:23,556 --> 00:10:25,725
with one common pick and one private.

183
00:10:25,958 --> 00:10:27,660
That's the reason why that supports them.

184
00:10:27,660 --> 00:10:30,830
Become clear a little bit later. Cool.

185
00:10:31,230 --> 00:10:32,131
So that's it.

186
00:10:32,131 --> 00:10:36,535
That's pretty much it about the individual agents and promises a really simple,

187
00:10:37,503 --> 00:10:40,506
really simple model and the global scale.

188
00:10:40,506 --> 00:10:46,278
They said is number of agent there
you can think of like 80 copies

189
00:10:46,278 --> 00:10:49,649
of these two pairs of agents,
meaning 160 agents

190
00:10:49,915 --> 00:10:52,485
in total or or whatever.

191
00:10:52,785 --> 00:10:58,057
And from that perspective
of the higher scale, the

192
00:10:58,057 --> 00:11:01,560
the markup blanket is actually composed
of the,

193
00:11:01,994 --> 00:11:05,665
of the collections
of all of these pairs, right?

194
00:11:05,965 --> 00:11:09,735
So they are each interaction
interacting with a

195
00:11:11,037 --> 00:11:13,305
with a global environment.

196
00:11:13,572 --> 00:11:17,410
And the cool thing is that we're square

197
00:11:19,045 --> 00:11:21,814
the way that the sensor inputs
are relayed

198
00:11:22,014 --> 00:11:24,684
to each agent is as designers.

199
00:11:24,917 --> 00:11:27,586
So you can think of it at the top level
as kind of

200
00:11:28,621 --> 00:11:30,790
bringing in some, some

201
00:11:30,790 --> 00:11:34,427
not just some target states that are

202
00:11:34,860 --> 00:11:38,330
that are pretty much the sort of smells
that that agent picks up

203
00:11:40,533 --> 00:11:40,900
all right.

204
00:11:40,900 --> 00:11:44,303
The other important thing
is that the optimal state for the system

205
00:11:44,970 --> 00:11:47,440
corresponds to the agents
share target only.

206
00:11:48,541 --> 00:11:51,977
But so from the system's perspective,

207
00:11:52,011 --> 00:11:55,381
it wants all the agents to be
in that share target.

208
00:11:55,381 --> 00:11:57,817
But the agents themselves,
they don't know it.

209
00:11:58,718 --> 00:12:02,021
Why it's important is that it means that
there is no exogenous incentive

210
00:12:02,021 --> 00:12:03,456
to achieve the global goal.

211
00:12:03,456 --> 00:12:05,124
So it's not like just for nudging.

212
00:12:05,124 --> 00:12:07,326
We're asking all of the agents
the same thing.

213
00:12:07,326 --> 00:12:10,696
And lo and behold, they're going to do it

214
00:12:11,363 --> 00:12:11,697
all right.

215
00:12:11,697 --> 00:12:16,635
And let's talk a little bit about
how free energy minimization happens here

216
00:12:17,369 --> 00:12:22,742
on the on the individual level
and the level of the individual agent.

217
00:12:23,676 --> 00:12:27,213
We just assume that there's some process,
some neurological process

218
00:12:27,213 --> 00:12:30,916
within each agent
that that does gradient descent.

219
00:12:31,250 --> 00:12:33,219
That's the traditional technique.

220
00:12:34,320 --> 00:12:34,653
But at the

221
00:12:34,653 --> 00:12:38,657
global level, what we're actually doing
is that the behavior

222
00:12:38,824 --> 00:12:44,063
that we're simulating at the collective
of all of these individual agents, the

223
00:12:44,430 --> 00:12:48,701
the aggregate of that behavior
is what we want

224
00:12:49,034 --> 00:12:52,404
what we would like to see
approximate gradient descent.

225
00:12:52,404 --> 00:12:55,641
So that's the thing that we do
actually want to demonstrate here.

226
00:12:55,641 --> 00:12:58,878
We want to look at the behavior
of the collective

227
00:12:58,878 --> 00:13:04,049
calculate the free energy, the collective
free energy, which is F Sigma here

228
00:13:04,049 --> 00:13:08,654
in this in this equation at the bottom,
and see if it's actually minimized.

229
00:13:08,654 --> 00:13:10,890
If it's minimized that way,

230
00:13:10,956 --> 00:13:13,592
then we can say that the system this this

231
00:13:14,760 --> 00:13:17,897
group of very simple agents
as a collective, it's

232
00:13:18,230 --> 00:13:21,467
performing active influence
at the global scale or not

233
00:13:21,867 --> 00:13:25,871
and shock reveal
what we find is that the extent

234
00:13:25,871 --> 00:13:28,274
to which the collective
is actually able to do that

235
00:13:29,108 --> 00:13:31,710
if the energy to be assumption depends

236
00:13:31,710 --> 00:13:35,181
on the social capabilities
that we and now these simple

237
00:13:37,650 --> 00:13:40,419
so we focused on two

238
00:13:40,419 --> 00:13:46,158
cognitive capabilities or or features

239
00:13:47,092 --> 00:13:49,895
that are stylized versions of

240
00:13:50,496 --> 00:13:53,432
of things that we traditionally look at.

241
00:13:53,432 --> 00:13:55,935
And in social science

242
00:13:55,935 --> 00:13:59,672
the first one is
what we call theory of mind

243
00:14:00,172 --> 00:14:03,943
and what we define that as that

244
00:14:03,943 --> 00:14:06,779
is the ability of an agent
to put itself in the shoes of another.

245
00:14:07,112 --> 00:14:10,149
And we actually try to model
that in a free literally.

246
00:14:10,983 --> 00:14:14,253
So if you think of shallow versus deep

247
00:14:14,420 --> 00:14:19,091
representations of of the other,
you can think of a shallow representation

248
00:14:19,091 --> 00:14:23,128
as like a mechanistic
or if they're going this way, it means it

249
00:14:23,128 --> 00:14:27,032
means there's some rule based
kind of kind of move kind of way,

250
00:14:27,032 --> 00:14:30,870
which you, you could think of, of being

251
00:14:31,770 --> 00:14:35,174
an internalization of a rule that I think
somebody else is following up

252
00:14:35,174 --> 00:14:37,610
but we actually did
here is something quite different, right?

253
00:14:37,610 --> 00:14:42,715
So it was based on the philosophy
of active inference. That

254
00:14:44,283 --> 00:14:44,783
means that

255
00:14:44,783 --> 00:14:47,720
the agent has every
agent has self-actualization.

256
00:14:47,887 --> 00:14:51,724
And what we said is, hey,
the socialization

257
00:14:51,724 --> 00:14:54,193
of the internal part of it needs to be

258
00:14:55,694 --> 00:14:59,498
implemented by some kind of quote
unquote neural neurological circuits.

259
00:14:59,899 --> 00:15:02,701
And what if that's exactly the same type

260
00:15:02,701 --> 00:15:06,906
of circuit, the same structure
we're being used to model the partners.

261
00:15:06,906 --> 00:15:09,909
So, so that you actually
also had a partner actualization.

262
00:15:10,643 --> 00:15:14,013
So this is quite literally
putting yourself in the shoes of

263
00:15:14,580 --> 00:15:16,348
of your partner, right?

264
00:15:16,348 --> 00:15:20,219
So you have your own beliefs
about your position

265
00:15:20,853 --> 00:15:24,890
and about your desires and you also have

266
00:15:25,557 --> 00:15:28,928
the literally the same kind of belief

267
00:15:29,194 --> 00:15:34,566
about the partners position
and their desires and you can use that

268
00:15:35,801 --> 00:15:39,038
loss of force, whatever, sorry,
you have it over from which you have from

269
00:15:39,038 --> 00:15:40,439
the environment to predict

270
00:15:42,675 --> 00:15:43,742
the partner's actions

271
00:15:43,742 --> 00:15:45,911
exactly the same way that you're
predicting your own actions.

272
00:15:46,145 --> 00:15:49,949
The only difference, of course, is that
you don't actually control your partner.

273
00:15:49,949 --> 00:15:53,786
So you're predicting that
that's the dotted line from it to out

274
00:15:53,786 --> 00:15:56,021
or from we want to be in the right.

275
00:15:57,556 --> 00:16:00,192
So your predicting
or how you're creating counterfactuals

276
00:16:00,192 --> 00:16:01,694
about what your partner's going to do.

277
00:16:01,694 --> 00:16:04,229
And then of course, you can observe

278
00:16:04,296 --> 00:16:06,799
observe whether or not prediction
matches the,

279
00:16:07,232 --> 00:16:10,903
the, the outcome in the next round.

280
00:16:10,903 --> 00:16:14,974
And that's each partner
is asked to calibrate their model of the,

281
00:16:16,141 --> 00:16:18,410
of the, of their partner.

282
00:16:18,410 --> 00:16:21,547
And the other thing is you want

283
00:16:21,814 --> 00:16:24,683
those two predictions to be consistent
between themselves, right?

284
00:16:24,683 --> 00:16:26,618
You want that
you want the beliefs about yourself

285
00:16:26,618 --> 00:16:31,056
and the partner to have some consistency
and that actually helps you

286
00:16:31,824 --> 00:16:34,226
to what you call triangulation.

287
00:16:34,226 --> 00:16:35,027
Right? So, you know,

288
00:16:36,395 --> 00:16:38,731
very maybe very
little about your physical environment,

289
00:16:38,731 --> 00:16:41,667
but you're seeing your partner
do stuff and

290
00:16:42,868 --> 00:16:45,604
moving around
and you're using that information

291
00:16:45,604 --> 00:16:48,474
to inform your
your belief about your own position.

292
00:16:48,874 --> 00:16:51,243
So that's the power really.

293
00:16:51,243 --> 00:16:54,046
The power of all theory
in mind for our model.

294
00:16:54,446 --> 00:16:56,582
And we're going to see how useful
that is.

295
00:16:58,350 --> 00:16:59,752
Now, the other

296
00:16:59,752 --> 00:17:02,821
one is goal alignment
I realized that I've been speaking

297
00:17:02,821 --> 00:17:06,191
for a long time,
so I'm going to go a little bit faster.

298
00:17:06,692 --> 00:17:08,727
And so the other feature
that we talked about

299
00:17:08,727 --> 00:17:10,429
is this thing called goal alignment.

300
00:17:10,429 --> 00:17:13,966
And it's really about the ability
for an agent

301
00:17:13,966 --> 00:17:17,403
to adapt its goals
to to match another goal.

302
00:17:17,970 --> 00:17:20,472
And this is

303
00:17:20,472 --> 00:17:24,877
this is a bottom up
incentive and sensitization mechanism.

304
00:17:25,044 --> 00:17:28,514
Remember that what I mentioned
that the system actually has an optimum

305
00:17:28,514 --> 00:17:31,650
but has no direct way
to tell the agents about it.

306
00:17:32,484 --> 00:17:35,020
So the assumption here
is that to the extent that you can,

307
00:17:35,120 --> 00:17:39,291
that you have overlaps
between the two agents goals,

308
00:17:39,291 --> 00:17:43,562
and it turns out that
those that the overlapping goals

309
00:17:43,562 --> 00:17:48,000
are aligned with a system optimum
that provides a bottom up way for

310
00:17:48,367 --> 00:17:51,837
for collectively optimal behavior
to to to happen.

311
00:17:52,104 --> 00:17:55,874
And we didn't model dynamics,
the dynamics of how that goal

312
00:17:55,941 --> 00:17:56,675
alignment happens.

313
00:17:56,675 --> 00:17:59,645
We just assume that
it can be flipped on and off

314
00:18:00,712 --> 00:18:02,648
just again for simplicity.

315
00:18:02,648 --> 00:18:05,818
And that's that's the thing
that we'd like to explore for the call.

316
00:18:06,919 --> 00:18:08,587
So we did a virtual experiment.

317
00:18:08,587 --> 00:18:13,225
We ran simulations
with all four possible combinations of

318
00:18:13,525 --> 00:18:16,962
with or without the right mind,
with or without goal alignment.

319
00:18:17,396 --> 00:18:21,433
And so and basically what we

320
00:18:21,900 --> 00:18:24,770
and the baseline here,
which is without the remote with alcohol,

321
00:18:24,870 --> 00:18:27,473
make a response to the scenario
where these agents

322
00:18:27,473 --> 00:18:28,740
are pretty much blind to each other.

323
00:18:28,740 --> 00:18:32,111
They're not interacting with them
with each other at all.

324
00:18:32,111 --> 00:18:34,446
We can see each other,
but they're not using that information.

325
00:18:35,481 --> 00:18:38,717
And we're going to see how those features
actually drive

326
00:18:38,717 --> 00:18:42,788
the behavior of individual agents
and also the system itself,

327
00:18:43,989 --> 00:18:44,790
of course.

328
00:18:44,790 --> 00:18:47,626
So basically what we find is that

329
00:18:48,060 --> 00:18:51,396
I don't think I mentioned this before,
but we defined in each pair

330
00:18:51,630 --> 00:18:55,801
that there is a strong,
perceptually strong and perceptual agent.

331
00:18:56,635 --> 00:18:58,804
The retention is pretty much following

332
00:18:58,804 --> 00:19:03,275
almost a random noise
that they have very, very poor smell

333
00:19:04,776 --> 00:19:05,911
receptors,

334
00:19:06,145 --> 00:19:09,214
but they
still they can still use the partners

335
00:19:10,249 --> 00:19:12,518
position motion to translate. Right.

336
00:19:12,518 --> 00:19:18,557
So the the effect here that we see
agents wise are mostly what benefit that

337
00:19:18,557 --> 00:19:22,728
these social capabilities
and the weak agent with.

338
00:19:23,195 --> 00:19:26,698
And so we see that

339
00:19:26,765 --> 00:19:30,536
the model with both together
actually is the one where

340
00:19:30,536 --> 00:19:34,473
the performance of those
the weak agents consistently improves

341
00:19:35,274 --> 00:19:40,045
really well to the point where it gets
almost as good at finding an optimum

342
00:19:40,345 --> 00:19:44,349
as the as the strong agent.

343
00:19:44,783 --> 00:19:49,755
And why is that so the key
to the basic intuition is that theory

344
00:19:49,755 --> 00:19:54,226
of mind by itself in this model
is not able to improve outcomes.

345
00:19:54,226 --> 00:19:57,095
Not that much because

346
00:19:57,095 --> 00:20:00,232
remember, each agent has 22 goals

347
00:20:00,532 --> 00:20:06,271
which correspond to the two peaks here
and in the middle drawing the left side.

348
00:20:06,672 --> 00:20:10,008
And because there's this great ambiguity,
right,

349
00:20:10,008 --> 00:20:14,646
if I'm going to to assert in a certain
direction what goal that

350
00:20:15,581 --> 00:20:17,049
it's hard to interpret that

351
00:20:17,049 --> 00:20:19,284
in terms of going to the specific goal
if you don't

352
00:20:19,551 --> 00:20:21,320
if there's two possible goals
for your thought.

353
00:20:21,320 --> 00:20:24,623
So that limits
how much useful information

354
00:20:24,623 --> 00:20:28,060
the agent can get from the
from the strong

355
00:20:28,994 --> 00:20:31,663
and goal alignment itself

356
00:20:32,664 --> 00:20:37,035
doesn't help by itself because now
you have a small reward target.

357
00:20:37,035 --> 00:20:41,173
Target but they're so notch for well
defined where we're going.

358
00:20:41,707 --> 00:20:44,876
But putting that the ticket values
together actually does result in.

359
00:20:44,876 --> 00:20:45,711
Interesting.

360
00:20:45,711 --> 00:20:49,181
So I'll I'll let it let that sink in
for a second.

361
00:20:49,481 --> 00:20:53,218
A theory of mind knowing for
putting yourself in the shoes of another

362
00:20:53,719 --> 00:20:56,388
plus having goal alignment

363
00:20:56,388 --> 00:20:59,558
the capacity to to to share a goal

364
00:21:00,259 --> 00:21:02,594
it actually creates

365
00:21:02,594 --> 00:21:06,231
benefits
for the agents that are compensates

366
00:21:06,231 --> 00:21:09,635
helps a lot to compensate
for deficiencies in the in the

367
00:21:10,202 --> 00:21:12,638
in the agent's ability to navigate to

368
00:21:14,573 --> 00:21:17,009
and that

369
00:21:17,009 --> 00:21:19,945
also is true looking at the collective.

370
00:21:20,078 --> 00:21:23,382
So remember we're talking about
whether these models

371
00:21:23,382 --> 00:21:26,518
can minimize
the collective free energy F sigma.

372
00:21:26,852 --> 00:21:31,356
So we're interpreting this these runs of

373
00:21:32,624 --> 00:21:37,462
all these fronts are optimization
for the individual agents

374
00:21:37,763 --> 00:21:42,601
as part of one single Bayesian inference,
step four, do you collect them?

375
00:21:42,901 --> 00:21:43,235
Right.

376
00:21:43,235 --> 00:21:46,738
And what you see here is the

377
00:21:47,372 --> 00:21:50,142
if we're doing this right,
the graph should look like

378
00:21:51,343 --> 00:21:55,414
like gradient descent down the
the free energy gradient.

379
00:21:55,681 --> 00:22:01,520
And this only really happens
consistently towards a fifth out of zero

380
00:22:01,653 --> 00:22:05,123
in the fourth model where you have
both of these social capabilities.

381
00:22:05,324 --> 00:22:07,459
As we mentioned,
you get some improvement.

382
00:22:08,593 --> 00:22:10,662
You have some abilities from these agents
that are coming

383
00:22:10,662 --> 00:22:12,431
from their individual capabilities.

384
00:22:12,431 --> 00:22:16,201
But when you when you put
the social cognitive together

385
00:22:16,201 --> 00:22:19,771
with with the capabilities
about the environment,

386
00:22:19,771 --> 00:22:24,810
that's when you get the ability
to really minimize the system, manage

387
00:22:26,778 --> 00:22:27,112
all right.

388
00:22:27,112 --> 00:22:33,018
So that's what what we found in our paper
and we think it's a pretty interesting

389
00:22:33,018 --> 00:22:36,288
and compelling example
of being able to link

390
00:22:37,322 --> 00:22:41,159
so in a very stylized way,
but very clearly linked

391
00:22:41,860 --> 00:22:45,297
social cognitive capabilities
at the individual level that are just

392
00:22:45,530 --> 00:22:47,432
that are not just simple rules. Right.

393
00:22:47,432 --> 00:22:47,733
With this

394
00:22:47,733 --> 00:22:51,002
not about simple rule following,
but it actually has to do with

395
00:22:51,236 --> 00:22:54,239
interpreting the other
and using that information

396
00:22:54,673 --> 00:22:56,875
and linking that directly to

397
00:22:57,909 --> 00:23:00,045
to active inference
at the collective level.

398
00:23:01,179 --> 00:23:02,614
And what would like to say that?

399
00:23:02,614 --> 00:23:06,551
I think the four most exciting things
that we've been discussing

400
00:23:06,551 --> 00:23:11,022
the last couple of months are,
first of all, can you actually

401
00:23:11,990 --> 00:23:15,360
look at experiments with with humans and

402
00:23:16,928 --> 00:23:19,064
because,
you know, these capabilities, it's

403
00:23:19,431 --> 00:23:22,567
got these social capabilities
are things that you can measure

404
00:23:23,535 --> 00:23:25,103
your mind and abilities

405
00:23:25,103 --> 00:23:27,939
and goals of things that you can test out
with human subjects.

406
00:23:28,240 --> 00:23:33,044
And can you use our model to to

407
00:23:33,612 --> 00:23:36,181
to represent and simulate

408
00:23:36,181 --> 00:23:39,751
and contrast
with what happens in groups of humans

409
00:23:39,751 --> 00:23:44,523
and see if the differences
in their abilities to

410
00:23:45,357 --> 00:23:48,393
to to have theory of mind
and to align on goals

411
00:23:49,361 --> 00:23:52,864
matches up with with what we're
defining here as energy minimization.

412
00:23:53,165 --> 00:23:55,333
That's 11 idea.

413
00:23:55,333 --> 00:23:58,770
Another one is, you know, collectives,
one of the things that collectives

414
00:23:58,770 --> 00:24:03,341
can can have is behaviors
around shared resources.

415
00:24:03,675 --> 00:24:07,112
And these resources involve them
with capabilities in different ways.

416
00:24:07,412 --> 00:24:11,817
So that creates we think that creates
sort of an onramp to understanding

417
00:24:12,083 --> 00:24:14,986
the idea of economic value

418
00:24:15,620 --> 00:24:18,890
that's we've been joking jokingly
holding it for some omics.

419
00:24:19,691 --> 00:24:24,162
This is the further down
you go, the more speculative we get.

420
00:24:24,496 --> 00:24:25,997
But we think that

421
00:24:28,333 --> 00:24:30,802
active inference can actually help us
understand

422
00:24:30,802 --> 00:24:34,673
this notion of of
where does it come from?

423
00:24:34,906 --> 00:24:37,876
Is it really just up

424
00:24:37,876 --> 00:24:41,379
related to Star City
or is actually also related to

425
00:24:41,413 --> 00:24:44,216
to the capabilities
that it's knowing with different agents

426
00:24:44,216 --> 00:24:46,117
how these two things
relate to each other.

427
00:24:46,117 --> 00:24:48,653
So we think that there's a
there's a powerful idea there,

428
00:24:50,455 --> 00:24:54,526
this notion of, again, omics,
I wrote a little bit about that.

429
00:24:54,526 --> 00:24:58,497
I think it's it's been starting
to pick up steam in some areas.

430
00:24:58,797 --> 00:25:01,099
And, you know, ultimately

431
00:25:02,400 --> 00:25:04,102
all of us are embedded in one

432
00:25:04,102 --> 00:25:06,872
big collective,
which is guy from guy theory.

433
00:25:07,472 --> 00:25:10,642
It's the planetary scale
collective intelligence

434
00:25:10,642 --> 00:25:12,811
that sometimes works really well.

435
00:25:12,811 --> 00:25:14,679
Sometimes it doesn't work really well.

436
00:25:14,679 --> 00:25:18,917
Can we use these
sorts of ideas of multi scale

437
00:25:20,185 --> 00:25:21,119
active inference modeling

438
00:25:21,119 --> 00:25:24,122
to, to improve how we define and model

439
00:25:25,056 --> 00:25:27,492
the the behavior of that guy assistant

440
00:25:28,860 --> 00:25:33,365
finally going from the pretty big
to the pretty small and individuals

441
00:25:33,932 --> 00:25:39,271
and individual humans brain
we've been looking Jeff Hawkins since

442
00:25:40,605 --> 00:25:43,174
the thousand in theory
from his recent book

443
00:25:43,542 --> 00:25:48,146
and there's a lot of interesting ideas
that look a lot like active inference but

444
00:25:48,914 --> 00:25:51,149
as far as you know nobody's

445
00:25:51,316 --> 00:25:55,420
tried to model with what he says
is the fundamental unit of intelligence

446
00:25:55,420 --> 00:25:58,924
which are these vertical columns
in the New York cortex

447
00:25:59,925 --> 00:26:02,761
nobody's tried to model
those using active inference

448
00:26:03,028 --> 00:26:05,430
and that's name implies the

449
00:26:06,264 --> 00:26:08,466
the main thesis of of this theory

450
00:26:08,466 --> 00:26:14,139
is that the intelligence in our brains
comes from the collective behavior

451
00:26:14,439 --> 00:26:17,275
of all these

452
00:26:17,909 --> 00:26:19,177
all these cortical columns

453
00:26:19,177 --> 00:26:21,913
interacting by a certain algorithm.

454
00:26:22,213 --> 00:26:26,151
And so what it would look what would it
look like to try to implement this

455
00:26:26,451 --> 00:26:27,385
this unit

456
00:26:27,385 --> 00:26:31,523
so of the brain, what inter, quote
unquote agent capabilities are required.

457
00:26:32,090 --> 00:26:33,992
So I'm going to pause there.

458
00:26:33,992 --> 00:26:38,830
I've I've overstayed my welcome
oh, I'm really curious to hear

459
00:26:38,830 --> 00:26:43,668
what kind of questions
or thoughts we have in homes.

460
00:26:43,768 --> 00:26:44,069
Yeah.

461
00:26:45,203 --> 00:26:45,870
Thanks.

462
00:26:46,538 --> 00:26:46,938
Awesome.

463
00:26:46,938 --> 00:26:49,474
Thanks for the fascinating unit then.

464
00:26:51,376 --> 00:26:51,843
Thanks.

465
00:26:51,843 --> 00:26:54,512
So great presentation.

466
00:26:54,946 --> 00:26:59,050
So maybe we could start
with just a preview of a then blue.

467
00:26:59,551 --> 00:27:04,055
Just what is bringing you
to being right here

468
00:27:04,055 --> 00:27:05,357
and what are your first thoughts?

469
00:27:05,357 --> 00:27:09,094
Either being involved on the work
or on the collective behavior side

470
00:27:09,361 --> 00:27:10,629
more generally.

471
00:27:12,731 --> 00:27:13,765
Of blue?

472
00:27:13,765 --> 00:27:15,266
Are you being pushed out?

473
00:27:15,266 --> 00:27:17,636
You've got a lot of authors.

474
00:27:20,472 --> 00:27:21,272
Thank you.

475
00:27:21,272 --> 00:27:22,207
Thank you.

476
00:27:22,774 --> 00:27:25,977
Know, I think all this work in particular

477
00:27:26,611 --> 00:27:29,080
and I'd start with this work
as a context or up the

478
00:27:29,247 --> 00:27:32,584
the the bigger idea is

479
00:27:32,584 --> 00:27:35,353
a part of the thing that we

480
00:27:35,353 --> 00:27:37,622
I'm invested and invested together

481
00:27:38,123 --> 00:27:41,793
is figuring out one

482
00:27:41,793 --> 00:27:45,196
understanding causality
of where does collective intelligence

483
00:27:45,196 --> 00:27:48,867
emerge from, what are the interactions
between humans or humans and machines.

484
00:27:49,100 --> 00:27:50,068
Those things

485
00:27:50,435 --> 00:27:54,706
while you can have causal theory from
a management social science perspective,

486
00:27:56,074 --> 00:27:58,376
it's very
hard to know that it is optimal.

487
00:27:58,643 --> 00:28:02,981
Is that the outcome lack of statistical,
you know, mechanics approach

488
00:28:02,981 --> 00:28:05,250
to looking at best behavior
and saying that

489
00:28:05,583 --> 00:28:08,353
the at the aggregate level,
this is how the outcome should behave.

490
00:28:08,553 --> 00:28:11,923
But you can look at the micro
interactions underneath.

491
00:28:12,090 --> 00:28:15,293
So think from my perspective, active
inference is

492
00:28:17,362 --> 00:28:20,865
not not correct,
but from a social scientist perspective,

493
00:28:20,965 --> 00:28:24,969
it is an atypical way of physics, way
of looking at DeMarco,

494
00:28:26,071 --> 00:28:28,339
looking at the statistical mechanics

495
00:28:28,473 --> 00:28:32,010
without worrying about how exactly does
theory of mind come about.

496
00:28:32,010 --> 00:28:35,413
So as Rafal explained,
we had a partner actualization group.

497
00:28:35,847 --> 00:28:40,452
We think the analog in social science
is theory of mind.

498
00:28:41,286 --> 00:28:45,757
And what we could demonstrate
is that even if there are individual

499
00:28:46,624 --> 00:28:49,060
active inference agents, they will need

500
00:28:49,060 --> 00:28:51,930
some form of partner actualization.

501
00:28:52,297 --> 00:28:55,800
And in humans you can observe that
as the capability of mind

502
00:28:56,234 --> 00:29:00,238
to be able to use each other
as sources of information.

503
00:29:00,238 --> 00:29:01,606
So if I cannot

504
00:29:03,007 --> 00:29:04,275
work in my environment

505
00:29:04,275 --> 00:29:07,512
because my physical skills
like looking at and smelling the

506
00:29:08,279 --> 00:29:10,381
different chemicals at different
levels is low,

507
00:29:10,815 --> 00:29:14,819
but my social receptiveness is
so I can look at my partner and infer

508
00:29:14,819 --> 00:29:18,156
something about my environment, then
I could still work in the environment

509
00:29:18,957 --> 00:29:22,527
but that alone is not enough
for us to work as a collective.

510
00:29:22,527 --> 00:29:25,263
Does the free energy
we collectively not go down

511
00:29:25,530 --> 00:29:27,332
just if everybody can understand

512
00:29:27,332 --> 00:29:29,634
each other's perspective,
what's happening, each other's shoes?

513
00:29:30,034 --> 00:29:31,770
So then we need something more.

514
00:29:31,770 --> 00:29:33,304
So the second thing that we introduce

515
00:29:33,304 --> 00:29:37,108
and test out
is some form of aligning goals.

516
00:29:37,108 --> 00:29:40,478
Like there has to be a reason
to find common peaks.

517
00:29:41,613 --> 00:29:45,049
OK, the current model
does not see how it comes about.

518
00:29:45,083 --> 00:29:47,485
That is a social science textbook
pushing the causality

519
00:29:47,519 --> 00:29:50,655
like we trust each other
do we have a good communication

520
00:29:51,456 --> 00:29:53,024
processes are not like that would be

521
00:29:54,893 --> 00:29:57,462
accuracies and efficiency issues
in communication them since

522
00:29:57,762 --> 00:30:00,799
all of this is not you know
yes doesn't worry about that.

523
00:30:00,799 --> 00:30:04,102
But it tells us that
these two capabilities at the individual

524
00:30:04,369 --> 00:30:07,138
level are important to get a collective

525
00:30:07,438 --> 00:30:12,377
like I think from from our perspective
that is really the core contribution.

526
00:30:12,377 --> 00:30:15,213
If you are saying that there are some

527
00:30:15,213 --> 00:30:18,483
cognitive capabilities
that are beyond an individual EFA model,

528
00:30:18,483 --> 00:30:20,552
the way MacGregor had set it up,

529
00:30:20,552 --> 00:30:22,720
there are needed for it
to scale up as a collective

530
00:30:23,421 --> 00:30:26,391
right there's much more to be done, but
we are starting to build these barriers.

531
00:30:26,424 --> 00:30:29,060
So the exciting thing that I find that

532
00:30:30,061 --> 00:30:33,865
more about what can be map,
which is experiment

533
00:30:34,032 --> 00:30:37,669
if we run human agents
in a similar environment

534
00:30:38,002 --> 00:30:41,472
and ask them to do a similar task
and we have agents working together,

535
00:30:41,973 --> 00:30:45,944
can we create a mapping of
what is the theory of mind

536
00:30:45,944 --> 00:30:50,949
index like the score for this person
or this person on this scale?

537
00:30:51,516 --> 00:30:53,952
Because that would help us preemptively
say that

538
00:30:54,319 --> 00:30:57,722
if you have a collection of people
that this distribution of theory of mind

539
00:30:57,789 --> 00:31:01,893
and their ability to understand
each other like social perceptiveness,

540
00:31:02,126 --> 00:31:06,865
which is standard scale
in social sciences, I think it's called

541
00:31:06,865 --> 00:31:09,767
automating the mind in the AI,
that's a standard scale.

542
00:31:10,068 --> 00:31:16,140
So if we can create a mapping
from a real indicator of theory of mind

543
00:31:16,207 --> 00:31:20,245
onto these things, we can start having
some predictions that this team is likely

544
00:31:20,245 --> 00:31:23,514
to succeed
more than this combination of so.

545
00:31:23,648 --> 00:31:25,783
So that starts to open up data.
All right.

546
00:31:25,783 --> 00:31:27,185
Now, we have some interesting

547
00:31:28,486 --> 00:31:29,087
understanding

548
00:31:29,087 --> 00:31:31,589
of how the whole system works
and can we try to

549
00:31:32,257 --> 00:31:34,592
so this is very much the beginnings

550
00:31:34,592 --> 00:31:38,029
of a grander research statement

551
00:31:38,029 --> 00:31:41,633
and the research direction
that we are trying to pursue and using.

552
00:31:41,633 --> 00:31:45,637
If in tandem with quantum theories

553
00:31:45,637 --> 00:31:48,940
or management or social science theories
to figure out more,

554
00:31:49,173 --> 00:31:51,476
how can we help things
better, design deeper

555
00:31:53,144 --> 00:31:53,978
than that?

556
00:31:54,812 --> 00:31:55,313
Is that enough?

557
00:31:55,313 --> 00:31:57,081
Like, I didn't go much beyond that.

558
00:31:57,081 --> 00:32:02,487
We're very happy to talk more on
other kinds with lots of level of people.

559
00:32:02,820 --> 00:32:03,721
Audio.

560
00:32:04,822 --> 00:32:06,658
Thanks for all. That was great.

561
00:32:06,658 --> 00:32:12,030
Yeah, I really enjoyed this paper from
my background is like biological sciences

562
00:32:12,030 --> 00:32:12,764
and so like I've done

563
00:32:12,764 --> 00:32:15,967
cellular and molecular neuroscience
like all the way through my PhD

564
00:32:16,100 --> 00:32:17,902
until I kind of
took the jump off the that.

565
00:32:18,903 --> 00:32:19,604
So for

566
00:32:19,604 --> 00:32:23,007
me it's I'm not as
well versed in the social science aspect,

567
00:32:23,007 --> 00:32:27,545
but I think a lot about collectives
and I'm super drawn to collective

568
00:32:27,545 --> 00:32:32,350
intelligence and even hierarchical
systemic organization, right?

569
00:32:32,550 --> 00:32:36,054
So how bodies are different
from molecules

570
00:32:36,054 --> 00:32:40,625
to cells to tissues
and organs, et cetera, and even like

571
00:32:40,892 --> 00:32:45,897
societies and ecosystems, like the theory
that you were talking about earlier.

572
00:32:45,897 --> 00:32:47,832
So so this picture was awesome for me.

573
00:32:47,832 --> 00:32:50,802
I do have quite a bit of questions,
especially at like

574
00:32:50,802 --> 00:32:52,270
the social science front.

575
00:32:52,270 --> 00:32:54,038
Like in the beginning of the paper,

576
00:32:54,038 --> 00:32:56,441
you guys outlines
like a whole lot of different

577
00:32:57,742 --> 00:33:00,011
potential ways that we operate.

578
00:33:00,011 --> 00:33:02,280
Like as multisystem

579
00:33:03,581 --> 00:33:04,983
multi-agent systems.

580
00:33:04,983 --> 00:33:07,485
And so like a lot of them,
you have theory of mind in there

581
00:33:08,119 --> 00:33:09,587
and also the bow alignment.

582
00:33:09,587 --> 00:33:12,657
But you also have like shared norms
and folk psychology.

583
00:33:12,957 --> 00:33:16,627
And so what, what made you choose
just those two

584
00:33:16,995 --> 00:33:20,365
as opposed to like testing
all the other ones out?

585
00:33:20,431 --> 00:33:21,566
Or did you try others

586
00:33:21,566 --> 00:33:24,969
or did you not figure out a way
to like mathematically get it together?

587
00:33:24,969 --> 00:33:26,471
Or what was your logic there?

588
00:33:27,839 --> 00:33:29,374
Experience

589
00:33:31,509 --> 00:33:32,610
of doing?

590
00:33:32,610 --> 00:33:33,444
I that

591
00:33:35,713 --> 00:33:38,282
yes, I think so.

592
00:33:38,649 --> 00:33:39,851
We had

593
00:33:40,651 --> 00:33:43,321
about six months of discussion of
what would be a scoop of the paper

594
00:33:43,621 --> 00:33:47,392
and that's where we got so many things
that guys are going to

595
00:33:48,226 --> 00:33:49,627
get all really excited about.

596
00:33:49,627 --> 00:33:52,697
Looking at a regular question,
what makes up the level of dynamics?

597
00:33:53,931 --> 00:33:56,567
But before we could jump on
to any of those things,

598
00:33:56,567 --> 00:33:59,937
I think it was important to boil down
as to what are the key

599
00:34:01,406 --> 00:34:03,841
pieces that are needed
before we conclude.

600
00:34:03,841 --> 00:34:09,280
So the key piece was at this point,
if does a very good job of explaining

601
00:34:09,580 --> 00:34:12,784
an individual interacting
with an environment and how it operates.

602
00:34:13,351 --> 00:34:16,521
So yes, we can go to norms,
yes we can go to these things,

603
00:34:16,521 --> 00:34:19,824
but these are details
about how norms emerge.

604
00:34:20,024 --> 00:34:20,992
And at the end of the day,

605
00:34:20,992 --> 00:34:23,361
I'll get I could be misunderstanding
some pieces of it

606
00:34:23,594 --> 00:34:26,998
because I'm coming from social scientists
to actual threats.

607
00:34:27,465 --> 00:34:29,467
So pardon my errors.

608
00:34:29,467 --> 00:34:31,536
That is correct me, my understanding.
