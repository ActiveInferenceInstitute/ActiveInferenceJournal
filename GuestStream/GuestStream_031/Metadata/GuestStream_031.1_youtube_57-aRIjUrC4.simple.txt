SPEAKER_03:
all right hello and welcome everyone it's december 7th 2022 this is active inference live stream number 31.1 we are here with brett kagan and we're going to be hearing a presentation and having a discussion on free energy principle and active inference in synthetic biological intelligence we'll have a presentation followed by a discussion so feel free to submit any questions if you would like

Brett, thank you for joining.

Really looking forward to this presentation and discussion.

Off to you.


SPEAKER_02:
Thanks so much, Daniel.

Thank you everyone joining us today.

Hopefully we've got some interesting stuff.

So what I want to talk to you about is the work that we've been doing in what we call synthetic biological intelligence and particularly the use we've made of principles from the free energy principle and active inference frameworks.

So

If we jump to sort of the first question and we can kind of ask ourselves, because we work with neural systems, what is there that's unique about neural systems?

And one of the obvious answers to that is that they display this unique ability to collate information and apply it in an adaptive behavior in multiple contexts.

And that could be a fitting definition for intelligence, if you like.

But to actually be able to test this in actual cells in real time, what you have to do is be able to record the information from the cells and provide information back to the cells in real time.

So how did we go about setting this up?

How did we get these cells?

So we did it in two ways.

Either we took what's called a human-induced pluripotent stem cell.

That's the H-I-P-S-C there that you can see.

And what you can do is develop these from any donor blood, tissue, or skin.

And you can basically make a pluripotent stem cell line.

And then you can use a number of different methods to turn that into neurons of

you know, quite a degree of specificity.

We used quite a broad one for most of our work, which is called a dual somatic inhibition, which follows like natural ontological development, or ontogeny development, I should say, to sort of create these predominantly cortical cultures in a dish.

But you can use other direct methods, such as what's called an NGN2 direct differentiation, which gives rise to a more excitatory culture,

Then we also took primary cortical neural cultures from mouse and we grew them as a comparison because we wanted to make sure that we were using, at least in some sense, bonafide cortical neurons.

And the best way to do that is to take it from animals.

But fortunately, as you see, we will be able to move and we have moved away from that now in our current practice.

So we're completely animal testing free at the moment.

And then what we did was we plated these onto what's called a high-density multi-electrode array.

And essentially, I'll show you a bit more of this in a second.

This is essentially a CMOS chip, which is a type of chip that you might get in a digital camera.

But it also can be used in this purpose because what it can do is sense electrical signals, even very small ones, and actually be able to stimulate to them.

And so just some evidence that we actually did do the work we said we did.

Here's some examples of some cultures that we've grown.

And they show what we're able to do is use techniques to actually capture key markers of aspects of these cells.

So for example, this blue over here, hopefully it's coming up all right on your screens.

This shows something called DAPI, which marks all the nucleus of any cell.

If you want, you can look at something called NUEN here.

NUEN marks neurons.

So all the green dots, and you might be able to see it better in this picture, all the green dots show that this is actually a neuron.

And then, of course, one of the things that we know neurons have is that they send out axons.

And that's what this thing called beta-3 tubulin marks in the red.

And finally, we want to know, do they have dendrites?

And you can see here in the purple, this is marking dendrites.

Also a little bit of axons, but it also marks dendrites as well.

And then more than that, we want to know is not just are they neurons, because most neurons will have those traits, but also are they cortical neurons?

And BRN1 is actually a marker for cortical neurons.

You can see here, actually, not only are they neurons, but most of those neurons are cortical specifically.

There's, of course, going to be different cell types in there.

For example, GFAP here marks supporting cell types such as glia.

And you can see here we have a number of glia.

You can also really obviously see that these glia, these in the bigger picture, have quite a different morphology than the neurons.

So it's nice that we have sort of this mixed population because it means that we're able to test something that has some degree of comparable characteristics to what you might see in the cortical, in an animal or in our cortical areas.

Of course, it's much, much simpler magnitudes and magnitude simpler than that.

But it is reassuring for the function to know that there are some similarities as a model.

And importantly, for anyone who has looked at sort of creating cells out of stem cells, one of the big problems is that not all of those cells might be fully differentiated.

And if you do have cells that aren't differentiated and still pluripotent when you put them in a dish,

uh they can turn into anything and of course most of the time what they turn into something uh invasive and potentially cancerous depending what it is fortunately this kr67 marks dividing cells so this would sort of mark any cell that wasn't uh fully differentiated and we had uh this is a case where we had none of them and that was common but generally we had none to very very few and

Because of that, we're actually able to have these cultures growing for extended periods of time.

And this is what's a cryo scanning electron microscopy image.

So these are real biological neurons.

They're a little cracked because when you do the cryo aspect of the scanning and you freeze them for the necessary preparation.

They do tend to crack a bit, but you can still mostly see that there are a lot of intact neurons, a lot of connections.

And then behind that, you can actually see all the electrodes.

And you can also see the density and the complexity of this.

And this is actually an area of the chip that is less dense and interconnected than some of the other areas, because if you look at the ones that are highly dense and interconnected, you can't see the chip behind it.

We kind of wanted to show the fact that there's a chip behind this.

And I think like one of the key things to take away from this simply is the degree of complexity you get here compared to something like an artificial neural network.

A lot of the time people look at models and they're quite nice and neat and symmetrical.

And that's just not what happens in biology.

And as we'll discuss later, there's probably some interesting features that arise out of this degree and this extent of random or pseudo random connectivity.

And so what we could then do with this technology is map out.

This is an example of like the chip surface.

And then the firing rate in hertz can be seen here as a color scale.

And we can see over time with different cell types, we can get their activity and different cell types sort of turn on or begin to become active at different times.

But importantly, what we can do is get a fairly even distribution of active cells over the surface area.

fairly consistently again anyone who works in this area knows there's a fair bit of variation inherently and that's stuff we're working on now for the future but we are able to get this degree of um

of activity over time.

And that gives us some useful cell cultures to test.

Of course, how do we go about testing that?

Which is the big question.

And we know that as a living organism, you, me, mice, cats, whatever, we need to have the closed loop feedback to operate.

And what does that mean?

Essentially, it means that we're able to

receive information about the outcomes of our actions and modify our actions as a result of it.

So if I reach over for a cell phone, I immediately get sensory feedback in a number of modalities as I do that action.

And as I pick it up, I'm aware of the success of it.

If I fail, I'm aware of that too.

uh and this is actually this little mouse with a vr headset on is uh from this uh atinger study which is one of my favorite studies that's been done in recent times where they actually attached their virtual reality to mice and i found that if they disconnected the mouse's movement as it was developing from the actual visual information it got it led to quite catastrophic

functional developmental impairments.

And it just really shows, it shouldn't be surprising so much, but it does show us that this link with our environment is incredibly important for us as organisms to develop.

And so if you're looking at cells in a dish and you want to try and elicit intelligence, you can immediately say, well, you need to have some sort of linkage, some embodiment, which is achieved through this closed loop system to be set up.

And so like one of the better ways to sort of do this is to contrast it with an open feedback system, because that's what people generally do.

So just to emphasize this closed loop means that we stimulate some sort of sensation and that can be done with electrical stimulation.

and we can provide then sensory feedback again through electrical stimulation on how that response alters the world and it's actually been demonstrated before in a few studies for example in this vacuum paper that this closed loop stimulation does result in increased plasticity um

But we wanted to try and take it a little further and actually see if we could elicit a very clear goal directed behavior.

And so we set up, this is a little schematic of the dish.

And what we did was we almost arbitrarily defined, I shouldn't say it's arbitrary because there was a lot of planning and strategy behind it.

But what I mean by this is that

uh within a given framework for example here what we did was we designated a sensory region where we put information into electrodes using a combination of rate and place coding and then we read it out in this sort of counterbalanced region here so activity in these two regions would make the paddle move up activity in these two regions would make the paddle move down but the reason i say it's arbitrary was that we were able to uh

basically change this configuration to a number of ways.

And for the most part, although there were some differences, get a degree of statistically significant performance.

And that, of course, just shows the fact that neurons, as again, shouldn't be a surprise to anybody, are incredibly plastic and able to adapt and change how they respond otherwise.

And I think that's a really interesting thing because, of course, starting out here,

There is no real reason why neurons should behave in any particular way unless they're doing it to accord to some fundamental imperative.

And this is just an example of the visualization.

You're actually able to go

uh there's a there's a site if you jump to our website i'll show that later it's called spike stream and you can go and play around with this yourself it's available so this is an example of the electrode uh multi-electrode ray each little dot is a potential electrode we can route the blue ones are the ones we're routing at the moment each little bar is a activity and you can see we put activity in the top

And then we read it out at the bottom and it moves these paddle.

And over time, as I'll show you, it gets better.

Feel free to go to the spike stream and have a look at that.

But right now, what I want to discuss is, yes, it's all well and good that a system may be able to organize its behavior.

in a changing environment.

And this is actually an example of a very successful, so these are actual neurons driving this paddle.

So it's an example of one of our more successful cultures, but by no means is it a weird exception.

We do see this sort of better performance fairly often, again,

there is variation, of course.

And one of the ways that we wanted to investigate this initially was this idea of the free energy principle, which I'm sure many of you are familiar with.

So I'm not going to go into it in a great amount of detail, but I will provide kind of like a higher level summary of it here.

And the key things that we can sort of boil it down to in a very oversimplified sense, essentially, it means that

what we want to do with the free energy principle it suggests that there is an innate imperative for a system to actually match a prediction that it makes to incoming sensation and it's going to be phrased in Bayesian terms and there's a lot of implications one can take from that and you know I love this picture that um Carl Carfriston wrote up in his uh developed as part of his nature neuroscience reviews uh

article if you haven't seen read it it's a great article it covers a lot of good stuff uh but simply between the linkages between the different levels of the system and of course like it is and like one of the strong arguments for it is that being able to predict and act in your environment is theoretically necessary so and the other like implication of course is that there needs to be a statistical boundary between the internal and the external

which is called a Markov blanket, and we're going to touch on that a bit more later.

Diving into the notion of active inference via the free energy principle, formally it's sort of been stated that this is the process of minimizing variational free energy through action and perception.

And essentially what it's saying here is that a living organism is going to actively generate this internal model of the external world and then align those models.

And

Broadly speaking, there's two ways we can do that, either perception or action.

So if I use my cell phone as an example before, if I reach over, pick it up, what I've done is I've created a model in my head based on the visual information I've received, where the cell phone is.

I've reached over, I've picked it up.

Very good.

My perception matched my reality.

Let's say, though, that I didn't and I dropped it as I tried to pick it up.

Well, what could I do?

Either I could get better at

predicting the world and say, look, when I reach, when I reach, I will always drop my cell phone or, you know,

I could get better at defining where it is in the world.

Or what I could do is get better at the actual reaching action.

And really, when you boil down to it, these are the only two ways that a system can get better at predicting its environment, either through getting better prediction or getting better at controlling the environment.

And so for our cell cultures, what we wanted to do was simply remove one of these options.

So it's a very simple implication from a very nuanced theory, but...

following that we sort of said if the world became truly random something that like we as people like you can't anthropomorphize this too much because like we as people can't really experience something that's truly random um but in a dish with random random noise you you could at least approximate it um and so

That's what we did.

And so we had these two options.

So what we then said is that this is true.

What the cells will do is actually change their actions to make it accord with the internal model of the world that they have to decide and derive from the sensory stimulation we feed them.

So under this model here, that's sort of represented in this picture that you can see, what we propose is that the neural cells or the system will try to minimize the difference between the internal and the external world to minimize the free energy of the system, i.e.

minimize their surprisal.

We kind of predicted whether aversive is the right word or not.

It would certainly, we would say that non-predictable random stimulation should be something that the cells would try to avoid.

While on the flip side, if we gave them a predictable stimulus when they did something they liked, that might be reinforcing.

And again, I put these words in quotes because there's a whole language question, no question around what is it?

Is it truly aversive?

Is it driving?

Is it whatever?

But for the sake of communication, we have to pick words right now.

So hopefully you understand the context in which they're used.

And so what we propose then is that the cells should modify their activity to avoid adopting a state.

In this case, that's a pattern of activity that would lead to an increase in surprise.

And so what we could see here, we set up some experimental tests and we compared a number of different methods.

So we compared this control group.

This was simply media in a dish that had the stimulations and feedback applied to it.

media in a dish should not be able to learn without any cells we had an in silico model that would drive the pattern with random noise and essentially this was to test the control group you can think the media only control group I should say uh you can think of it as testing

were we able to get activity simply through our stimulation the in silico was saying could we get performance simply through something in the system itself you know making sure that the system isn't biased in any obvious way then we had a rest control group where this there were cells in a dish but no stimulation and this is asking the question

Left alone will the spontaneous activity of neurons, because neurons always have activity regardless of whether you're stimulating them or not, will that lead to better performance?

Again, there's no reason it should if our system is set up properly.

Of course, if there's a bias, it would, but that's what we're testing here.

And then finally, we had both mouse and human cells that were given the information where the ball was, were given feedback, and were able to play the game.

And what you can see is...

Basically, this is a little hard to interpret this graph if you don't stare at heat maps all day.

But if you compare, say, just the top right, which is the number of hits that are occurring in any given minute by the minute on the x-axis, you can see that it doesn't really change too much over time for the control group.

But compare it, and obviously the other, the in silico and the resting controls are kind of the same as that.

If you compare it to the mouse and say the human cultures, you can see quite a clear difference here.

And if you want more asterisks for significance, because who doesn't love asterisks?

At least all scientists love asterisks or other symbols of significance.

What we can do is you can see over time this control groups, the media control, the silico control, the rest control, they don't show any difference over time.

A bit of variation, but ultimately no real significant difference over time.

In contrast, the mouse and the human cells

Both showed learning over time, and by the second time point, they outperformed all the other cultures, all the other conditions, I should say.

Interestingly, the human cells even ended up slightly outperforming the mouse cells.

And although I would be careful not to overinterpret this, it was interesting to note that we've run this experiment a number of times, and this is a very consistent difference.

And so it could be an interesting way to start to investigate differences in the future between species if one wanted to set up a study more rigorously to actually test this.

And these results were replicated.

It wasn't like we found one measure that suddenly looked like performance and we ignored the rest.

We looked at a number of them.

Some of the other interesting ones are stuff like the percentage of long rallies, where it's hit the ball more than three times in a row, so 4.4 plus in a row.

and you can see here again significantly did you know changes over the time for the mouse and human cells nothing for the others likewise the aces which is like tennis where they miss the ball without even hitting it once this decreases uh statistically significantly over time for the mouse and human cortical cells not for the others so much

uh so that's interesting but you know we sort of say like well it's interesting it shouldn't be surprising because we know that neural cells are adaptive uh and the fact you can see it in a dish is cool but

What are the implications?

What can this actually teach us about how these cells are behaving?

And one of the things people have looked at in detail previously is functional plasticity.

So what we looked at here is, of course, we also assessed functional plasticity and saw that there was a massive difference between the resting state functional plasticity and the gameplay functional plasticity.

But what does that actually mean?

What does that actually look like, going beyond just the fact that there's plasticity occurring in the culture?

So what you can do is you can look here at just the correlation and the activity between the cells in the motor regions that I was showing you before and the sensory regions.

And it's not too surprising that whether or not they're playing the game, you have quite a high degree of correlation.

In fact, the correlations at rest are slightly stronger than the correlations at gameplay.

But what is interesting, actually, is if you take the average correlation, not just what is the overall correlation, but you actually break down the average correlation per culture and session, what you do is you actually get a far higher average correlation between the sensory and motor regions when they're playing the game than when they're at rest.

this makes sense if you need to coordinate your action with incoming stimulation you need to have a degree of correlation between where you receive that action and the activity there and where you're at your activity outputs going out but conversely if you have in this case basically you can think of it as two buttons even though they're spread over four regions what you would actually need to have is a negative correlation or reduced correlation between these regions

uh and if you look at the percentage of exclusive motor region activity in this graph which is where you have activity in either the up or the down region and bear in mind again these are counterbalanced so this result is actually pretty interesting to see uh what you see here is that during rest versus gameplay you actually have a higher degree of uh exclusive motor region activity

uh which would of course be necessary for discrete control in one direction versus the other and that was this was quite an exciting result because it was really supportive sort of that there is something quite dynamic and interesting going on uh in in the way that these cultures are reorganizing their activity and likewise this actually just shows the degree that this correlation decreases over time uh with two linear regressions and you get two very different linear regressions over

the first five minutes and the last 15 and we arbitrarily just based on some early work decided to and again not super arbitrarily but based on some early work i should say we uh decided to sort of split the games up into the first and stabilize and so that was quite supportive to suggest like what we're seeing here is really the tapping in of some of the key uh adaptive properties of the neural cultures

And to take it further, a bit more of a focus on the sort of free energy implications here, we can, of course, reframe surprise that has a link with information entropy.

And as for those of you familiar with this, this can also be captured as a tail divergence between the two distributions of what might be occurring.

And so we wanted to actually calculate here the information entropy of the actual cultures.

And now it's important to note here, this is internal to the cultures.

uh both at gameplay and at rest and if we didn't normalize it there's there's quite a lot of variation going on in any given culture but it becomes much clearer once you do normalize it uh simply to to baselines uh and you can see here that when you give them random feedback so one one thing i'll say firstly is that the gameplay normally actually has much lower information entropy than when they're at rest

Two, when you give them random feedback, their information entropy increases massively, thereby suggesting that these cells indeed should be, under the free energy principle, should be predisposed to avoid this.

And that's actually what we saw.

But what we're interested in is to say, well, what if we tried different types of feedback?

Like, how do we know, like, this is all well and good, but how do we know that this type of feedback is actually what's leading to these results?

Because it could be anything.

And so we set out and we introduced a few other control conditions.

So this is our regular one that I've sort of was showing you before.

If it was a bit unclear, hopefully this helps to clear it up a bit.

When they played the game, they missed the ball, they get random unpredictable sensory feedback.

When they hit the ball, they get predictable.

We then added something we called the silent condition, which is when they missed the ball, they basically had all their feedback removed.

And yet when they hit the ball, nothing, they didn't get any additional feedback.

The game just continued.

Now, it is important to note, of course, that when the game restarts after a miss, the direction of the ball is random.

So there is still some randomness in this game, but presumably less so than in the normal stim condition.

And this can be contrasted with this open loop or no feedback condition.

um their synonyms in this case basically where the game is played information about where the ball is is presented to the uh cells or the system cells or controls whatever the case is uh and then

uh but if they miss they don't get anything changed if they hit they don't get anything changed and so really it's asking the question like will a culture just play the game for the sake of playing the game like there's no reason it should but maybe they like maybe they do so we wanted to test that and then the final condition we we included here of course is a rest condition

And if this helps to make it clear, if you're more graphical, this can give you an example.

So here you can see the ball going up, it hits it, and then you get like a predictable stimulation here.

The ball goes, it continues, and it gets hit again, and then it misses and it gets a random feedback, and then the game continues.

Silent in contrast, you can see that this random feedback here at the same time point is removed for the silent condition.

Likewise, there's no predictable stimulation across the culture.

And then the no feedback, it's just the ball becomes completely predictable from the very first serve.

There is no unpredictability in it at all.

And so when we look at the results here, and obviously, if you're interested, you can go look at the paper because we dive into this in similar detail as before.

But just in brief, what I'll show you is that here, what we've done is just compared it to rest because it helps control the variability a little bit.

And it makes it look a little neater.

But essentially, the stimulus condition, they outperform rest, they outperform their starting position over time.

It replicates what we saw in the first study.

And the silent one, there is a very slight increase.

It doesn't reach statistical significance, but they do end up also statistically slightly better than the no feedback condition, which shows pretty much no learning compared to rest at all.

so that matches up pretty much with what we expect to see like around the free energy principle you know a condition that gets a small amount of randomness shows a small amount of learning if you want to do that but not a lot uh something that gets a lot of random information as a result of a an action that we we deem undesirable shows a greater tendency to avoid that action and something that has no incentive to behave in a particular way doesn't behave in a particular way

But what was really interesting and exciting for us also, although I'll be honest, it made us stop for a few minutes to actually think about why this has happened, was that when you look at this normalized information entropy, again, we got a replication that when you gave them random feedback, the actual internal information entropy goes up.

With the silent condition, the information entropy also went up.

And in fact, even more so.

And we went, why would this be the case?

And of course, what we realized quite quickly was, well, neurons left alone do fire spontaneously.

And when you take a neuron from a stimulated condition to an unstimulated condition, they do tend to re-engage with the random spontaneous activity quite vigorously straight away.

And so we went, and yet it didn't show the same degree of learning.

So of course, like I will say, this is one finding that absolutely needs to be followed up more in the future, and we are doing that.

But it does have an interesting implication in terms of Markov blankets.

So I mentioned this before, I flagged it before, and this is why, because I think this is one of the really interesting results.

So to go into more detail, what a Markov blanket is, is it's a statistical boundary that can distinguish an internal state from an external state.

And this can be at any level.

So it could be at an individual neuron, a cluster of neurons.

a nuclear distinct functional region of the brain, the whole brain, the body, in relation to the rest of the world or what's outside it.

And so the fact that, as I was saying, that we see that the silent condition even shows more randomness or information entropy than when we're actually providing external random information into the system is actually very, very consistent with what we know about the stochasticity of spontaneous activity.

But what it does also suggest is that cells will respond differently to randomness inside a system versus outside a system.

And that was a really exciting result to sort of find like

I miss physical evidence that perhaps this marker blanket really exists.

Of course, it makes sense it exists.

Theoretically, there's a lot of reasons.

I mean, even just the simplest notion that we can separate what our internal thoughts are from someone's external thoughts.

Sorry, not external thoughts.

Someone's external voice to us, I should say, suggests that we need to have some sort of barrier to distinguish these types of structured information, one internally, one external.

But seeing it was very, very interesting.

uh and so we also wanted to of course extend beyond this and sort of not just stop here and look at what other interesting things might be happening and you know one of the other interesting findings that we've we've recently completed and there's a pre-print of this up now is this idea of neural criticality and so what is criticality for those who aren't very familiar with it in brief

it is this state where a population's activity is coordinated basically between two other states.

So physically, you could think of it at that point between where water becomes ice and there's a point just in between, which is a transition.

To bring it back to the brain, you can think of it as a brain that firing rate could be either highly coordinated, rhythmic oscillatory, much as like when we sleep or in catatonia, or

It could be completely disorganized, like in some cases of epilepsy.

And then there's a middle ground.

And there's obviously quite a, you know, it's a spectrum.

So there's quite a lot of middle ground.

But the closer you get to this sort of critical transition point, this is called criticality.

And theoretically, it's been proposed to maximize, excuse me, there's my timer telling me to take a break.

It's theoretically has been proposed to act as a key criteria to maximize information transmission and capacity.

And what's also really interesting is that it's been linked to a number of different cognitive behaviors, although the field is certainly a bit unclear.

about what that is so uh it's been linked for example to responses to drugs working memory attention one of my particular favorites is scores of fluid intelligence uh but these studies have some some concerns with how how they investigate it and ultimately one of the biggest concerns is that they're doing these you know for these these ones at least in uh humans

We have lots of compensatory mechanisms.

You have to use FMRI or similar, mostly FMRI measures to actually investigate it.

So there's a lot of barriers in actually concluding this.

So we set up a study to actually investigate this and essentially, again, to not go into too much detail about the nuances, we looked at three key different metrics.

There's been a bit of criticism in the field where people focus predominantly on power laws.

power laws can arise from noise alone so we wanted to avoid that shortfall and look at three different measures uh and so this is this is sort of the setup we had we took them we compared them either playing the game or at rest which i described to you before and then we looked at these things called the the dcc the branching ratio or the shape collapse error and we wanted to see how we could group them sorry my slides have frozen


SPEAKER_01:
me try to jump to the next one all righty so hopefully that's back for everyone now let me just


SPEAKER_02:
There we go.

Okay.

So what we saw here really surprisingly was a very stark difference in criticality across a number of measures.

So you can just see here, basically the prediction between the rest and the active is quite a, just noticeably by eye, very different.

And of course that's statistically significant.

Diving into more detail, we could look at these different measures and this is just some quick overview of what those different measures look like.

So the DCC, the branching ratio.

So for example, with branching ratio, critical systems sort of maintain the number of sort of threads of activity that might happen in a subcritical system.

That variation will die off over time.

In a supercritical system, it's going to continue to expand up to a point.

And then there's a shape collapse error, of course, which is looking to see how you can collapse different avalanche shapes across a given spectrum.

And then looking across all of these, we get quite strong statistical differences showing quite clearly that when you have the system embodied in an environment, it's showing this measure of criticality, which is very interesting.

And one of the interesting things for this actually is that it shows that this criticality is very fundamental and that information input seems to drive it very strongly.

And to us, this does seem like a challenge, suggesting that it is in itself inherently a marker of some sort of higher order

uh system uh but of course i think the most interesting thing is simply that we can identify this and then what it does is open up the possibility to further investigate it with more nuanced tests that were explicitly designed to investigate criticality um but what was nice also to see like i guess some suggestion that it does have a role in some sort of information processing in some degree uh is the fact that uh here's also just showing you these results in a

slightly different measure but looking at the correlations there were some statistically significant correlations between the different measures of criticality and the gameplay performance showing that cultures that showed higher degrees of criticality across all three markers also had better gameplay performance in this hit miss ratio where they hit the ball more often than they missed it which was of course interesting to see and does suggest that although

we think that because this is arising in such a simple system, with such simple input, that it's unlikely to represent, or at least in of itself, be a criteria for intelligence per se, that there certainly is some link between processing information and criticality.

And if you want a more nuanced discussion of this, please feel free.

There's a pre-print up now while the paper's going through peer review.

We discuss it in more detail there.

And finally, what I would say, though, is that just to sort of really hammer home the point that this is a very fundamental property of these cultures, and that is so drastically different when they're playing the game versus rest, that when we wanted to classify the cells based on criticality metrics and performance as either playing the game or rest,

We were able to do this with a 98% success rate if you took it to performance.

And even if you just ignored performance and you just looked at criticality, with Random Forest, we were able to do this with a 92% success rate of characterizing whether they're playing the game or at rest.

And that obviously suggests that this is very fundamental, that once there's information input in these cells,

they drastically reorganize their activity.

And that's really interesting.

Of course, one of the questions that we also get asked a lot when we sort of put out this early work was a lot of people would say, oh, but who cares?

You know, we literally had someone write a comment

One of the peer reviewers actually at one of the points said to us, but this can't actually do anything better than reinforcement learning.

So how can you conclude anything about biology, which was a surprising comment to get.

But what we wanted to do and said, fair enough, we think there's plenty you can learn about biology, whether or not it does better or worse than reinforcement learning.

But it's a fair question.

Does this do, performance-wise, can it do anything interesting compared to reinforcement learning?

We know that if you run reinforcement learning enough, you will get superhuman performance with the game of Pong.

They will solve it.

They'll beat humans.

That's fine.

They can do the same with...

protein foldings, chess, go, that's all well and good.

But does that mean that there is no room for a biological system when it comes to this?

So what we wanted to do was actually compare it for sample efficiency, because that is, of course, something that reinforcement learning struggles with greatly.

So what we did was we compared three different deep learning algorithms, DQN, A2C, and PPO,

with three different types of information input and against our biological cultures to see how they performed.

And so just showing you here some results where we took the image vector, which had a CNN to run and process it and then feed it into the deep RL algorithms.

What we're able to see actually

was that our mouse and human cells, which are here in blue and orange, significantly outperformed and outlearned.

DQN was pretty much always the lowest performer, which is fine.

We know that it's very sample inefficient.

But even more sample efficient algorithms like A2C and PPO also failed to show the same degree of performance, even though they started higher.

for whatever reason we could never quite figure out, just some quirk of the algorithm, they never showed the same degree of learning.

And this was, again, mimicked across multiple comparisons.

But what was brought up to us was this idea of saying, well, there is, of course, a curse of dimensionality.

So what you're doing is you're feeding in a, I think it was a 40 by 40 image vector to these deep reinforcement learning.

And of course, it's going to take them longer to converge.

They have to deal with more information.

And we went, you know what, that's a fair point.

So what we did was run it even simpler.

And we came out and we said, all right, what we'll do is we'll feed them vectors of simply, you know, four vector matrix of where the paddle is and where the ball is.

And that will be much simpler and closer to the game plane.

So we fed that into them.

And what we saw was actually they formed us with less information.

and of course these are the the mouse and human image time because we can't alter the information put in this way it was a post-hoc study the actual mouse and human cortical cells but yeah they did even worse across all metrics

and we found again they're outperforming it a little more information than what the uh people are getting because the cells are really only just receiving the ball position we don't we're not yet able to encode proprioception because the dish brain system is very simple and you know although we would argue again like this sparsity of information should truly make it harder not easier with less information and certainly with our initial pilot testing we found that

the more information you gave them, the better they could do.

We again said, fair enough.

Let's change the information input to the reinforcement learning algorithms, give them the simplest possible information that matches as close as we could possibly do to what the cells are getting and see how they performed.

And again, they performed even worse, suggesting that, in fact, more information is probably helpful.

And so I think what we could show here is that, like, yes, there is certainly something interesting going on in neural cells and the way they're able to process information.

And it comes back to this quote that I love so much, which is to say that, like, if the human brain or in this case, even a simple collection of neurons in a dish was so simple that we could understand it, we might be so simple that we couldn't.

uh and you know we like to think that the tools we're building such as this is going to help us to actually simplify it enough that we'll be able to unpick and start to understand the nuances behind this but

One of the nice things that we're able to show is that even without fully understanding all the nuances of what's going on inside a dish like this, we can see that it does have some distinct traits in terms of intelligence that have promising advantages for information processing above and beyond what's going on in reinforcement learning.

We really think this hammers home that this is going to be a powerful tool to investigate these features in more detail.

So as sort of a summed up conclusion, what we're able to do with the system essentially is have a system of real biological neural cultures that can exhibit a very rudimentary form of natural intelligence through their inherent adaptive traits.

And these adaptive traits

like frankly, quite amazing to the extent and variety and diversity of what they're shown.

And even with the data that we've already generated, we're only just scratching the surface, but there's a lot of potential that they have.

And so simply by having this closed loop system of electrophysiological stimulation recording via these multi-electrode arrays, we could embed them into a, or embody them into a simulated world, depending which term you prefer.

and they could get better at playing it and moving the paddle to actually be able to perform the game with quite a consistent degree of coordination and with a faster learning rate than multiple reinforcement learning algorithms.

And of course, this is, as I said, it's a lot of work, and we're only just scratching the surface.

And so one of the things we're excited to do, because we're actually not an academic lab, we're a small startup based in Melbourne, Australia, is we want to open this platform up to everybody.

so if you have a question or you think everything i've just told you is completely wrong and that neurons work in a totally different way that's fine you know reach out we will in next year um be opening up for alpha testing and so the most exciting projects will be supporting to have an early access to this if you want to investigate the properties of these neurons and you have basic python or java coding skills

You can access them virtually and code them as an environment and see how they respond and test it and go away and write a paper sort of showing how you think that it should all work based on actual data.

And this is because we acknowledge this is a whole industry like this or whole field of research, of course.

And so we want to try and make these tools available for as many people as possible.

And we're going to make it as easy for you as possible as well.

And it's going to be fairly affordable.

So that's the end of the talk.

And of course, it's not just me working on it.

There's a whole team and a number of collaborators that we work with.

These are just the collaborators that sort of touch on this work.

There are many other very valuable people we work with and are expanding in other areas.

And so, and actually we're fortunate enough that Professor Adil Razi, who's one of our closest collaborators, has actually been able to join us today for the discussion part of it.

And so if there are any discussions, really happy to take questions.


SPEAKER_03:
All right.

Wow.

Well, thank you very much for that excellent presentation.

It gives us a lot to jump into.

So perhaps Adil, feel free to say hello, introduce yourself and add any general remarks so that we can jump into some more questions.


SPEAKER_00:
Yeah, thank you, Daniel.

Great talk, Brett.

And as always, you did, it was a tour de force through so many projects that you love.

It is really doing amazing work.

So I'm based at Monash University.

We're not that far from where Cortical Labs is in the city.

We are a bit suburban at the main campus, Monash University, where we have this computational systems neuroscience lab.

And our lab is using brain imaging and computational models

especially dynamic, causal modeling, uh, and active infants, uh, as frameworks to look into the brain and try to understand what's up, you know, um, uh, yeah, how,

how one can look at the mechanisms of, for example, how the brain implements coordination, for example.

For this, we use, as I said, mathematical framework of divinference and also dynamic causal modeling.

So that's basically what we are doing and happy to contribute to this discussion.

It spreads, you know,

you know there and it should be uh the one who should be talking well and i would be gladly just sitting here and listen to wonderful uh interaction we already are having awesome well


SPEAKER_03:
My first question, just for context, was how did active inference come together with this line of research?

Were you studying active inference and then looking for an embodied system?

Or was it something like you were studying this very interesting system and looking for some type of framework to help you model it?


SPEAKER_02:
Absolutely.

It's a great question.

And it goes back historically.

So Andy Kitchen, actually, and Hon, who's one of the founders of the company,

they were interested and they were looking for ways to explore it.

And actually, Adeel, you ended up having a conversation with them, I believe, and they were basically looking for a method of like, how could we talk to the cells?

And they came across Active Inference.

Or did you introduce them to Active Inference?


SPEAKER_00:
I would say that Andy and Hon at that time, that we are talking about late 2018, early 2019,

um and they were already interested in free energy principle um and but then i just moved to melbourne from from london in mid-2018 and i ended up giving a talk at alfred where cortical lab is being incubated at the time um and i was discussing these uh these ideas and so it was kind of uh you know um

interaction which just happened and then we thought yeah well okay there's lots of synergy and there we go uh we had uh we workshopped some of the early ideas uh at that time um and

thought about you know on and and Andy were really thinking about how to actually what could be the first thing that we should do which would then um really uh showcase the power of the dish brain of course the dish brain exact name came later on yeah yeah probably his brain child no no actually this frame this frame is a name


SPEAKER_02:
definitely goes goes to andy as well um okay i would have given it some some sort of uh esoteric uh name that that everyone would have gone what the hell is that so no good call by andy to do that um

Yeah, but of course, like it does have a lot of really useful features, the whole active inference framework that make it quite an ideal thing to test.

You know, the whole action perception cycle, the fact that there are like implications that you can simply take and be able to test the biological plausibility of it or make it very useful as a system for us to adopt.

um having said that though and like you know deal can attest to this like we also well i think that it was uh i think as a neil seth calls it uh maybe other people call it that too it was a bit of an adversarial uh collaboration in some aspects as well because we were interested in the idea but we had no stake in proving or disproving it we were simply testing it and so we had a number of discussions as we went through you know what if we see x y and z

uh what would be the states just kind of challenge it not just support it and so i think that was one of the things that made it a really exciting collaboration in that there was a high degree of skepticism amongst the team about pretty much everything we did um and i think that's what came together in making quite a nice paper because we were like as everyone should be in science but let's be realistic seldom are we were trying to be our own worst critics

because we were trying to figure out what else could be explaining it.

And I think there are interesting future directions we can explore, but certainly the results, as they are, did find support that this certainly is a key characteristic of how cells respond.


SPEAKER_03:
Awesome.

So one preemptive question about learning and then we'll drive back towards active inference.

So what kinds of mechanisms do the neurons use to engage game mode and also to learn?

Are they changing their topology in terms of their connectivity?

Are they changing what happens at synapses?

Are there changes happening inside of cells?

What happens when the game mode turns on and how does it actually improve throughout the course of that experiment?


SPEAKER_02:
Look, that's a great question.

And the reality is we don't have the full answer for that yet.

Most likely, it's going to be a combination of the latter two you mentioned.

changes that are happening potentially inside cells or inside synapses.

I mean, it's not necessarily too useful to try and break those apart.

The idea of like larger scale morphological changes are less likely simply due to the time scale that we see and the fact that we don't typically

Although there will be some future work showing some other things as we've moved on and advanced with our work.

We typically, in this study at least, didn't see learning across days.

So it's unlikely there are massive changes in connectivity.

It's more likely that it's functional changes in plasticity and how they respond to information.

And it could be a number of things like it could be, you know, of course, it's probably some sort of relationship and balance between heavy and homeostatic plasticity, long term potentiation to long term depression.

And then there's so many mechanisms that you can break down to look at how that is, you know, from.

you know like one interesting candidate could be looking at like phosphorylation of coughlin which interestingly takes i think about five minutes uh to to uh translocate from from inside to outside uh synapses and then is known to alter long-term potentiation uh

which would roughly accord with that time.

But this is something we need to investigate more in the future.

Higher level to that, I mean, Adil might have some ideas to sort of discuss higher level than this, you know, less reductive and more high level.


SPEAKER_00:
Yeah, more computational.

So, yeah, I mean, you know,

We are really interested in learning mechanisms, and especially from active, in terms of what are the learning mechanisms in artificial, that we can mimic in artificial neural networks.

So one of the, while we have the biological chip, which can learn, can we actually now understand how it's doing this?

And can we, in the short term, have,

better artificial neural networks.

Of course, where Brett and his team is taking to us that we actually don't need the artificial neural networks anymore.

We'll just have the biological chips, right?

So that's exciting.

So we have been looking at certain things, some of the more unresolved problems in deep learning and in machine learning

For example, lifelong learning and continual learning.

We know that artificial neural networks, they break down in tasks where you have to do

multiple tasks in series and they could do very good human-like performances on a single task, but then you train them on the second one and then they forget what they learned in the first one, unlike humans who could run, swim, speak without forgetting what, otherwise it will be catastrophic.

So that's one thing.

Another thing, you know, credit assignments, one of the bigger problems.

How do you actually solve the credit assignment problem, which is, again, an unsolved, long-standing problem in deep learning.

So what sort of choices we make that result in rewards in future.

So what are

And many a times what happens, there's a delay.

There's a delay in recording what behaviors resulted

in the in the in the world for example uh so so looking at what elements and what choices that we made that resulted in a long-term gain is another problem that that i we really don't know right now how do we actually going to but these are bigger very big problems which are unsolved and i think it just shows you the the power of the display system

that it can actually help us to you know i think there's a real um real opportunity here for us to actually attack those problems as well at the power level yeah as brett was saying


SPEAKER_02:
And I think it comes down to also being the right tool for the right job.

So reinforcement learning CNNs can do amazing things if you've got the data to train them, if you've got the rest of the setup that you need and you want to use it for the right purpose.

Are they very good for doing stuff in dynamic real time with limited data, fuzzy information?

So far, no.

And so maybe there will be a case where we can take

some of the findings from how neurons work and apply it in an algorithm in itself uh you know i know and i did a deal and his his team are doing some amazing work with uh you know building up active inference models uh and i think those results are really gonna you know i think excite a lot of people just as just as just as some flagging of some of the work you're doing a deal i won't mention anything else but it's going to be really exciting i think for people to see what's what's happening um and

But likewise, I do think that there will be things that biology maintains superiority over the question.

And the nice thing about biology, of course, when you talk about generalized intelligence, is we have no proof of principle that generalized intelligence can arise out of silicon hardware.

or quantum-based hardware.

We do have proof of principle that it can arise out of biological wetware.

Our brains, and brains of flies, of cats, of rats, whatever, show general intelligence to differing degrees.

And so to us, it's like not a question of can biology show generalized intelligence, but how do you get there?

And that's a less speculative question, not necessarily an easier question to answer.

It's not easier necessarily, but it does give you that ground truth.

It's the thing in and of itself sort of answer.


SPEAKER_03:
Wow, so much there.

In silico and in principle systems can display open-ended symbolic learning going back to the Turing machine.

But for the kind of open-ended enacted intelligence that we might be interested in, in settings like you described, which are real-time, fuzzy, and with small data, and we could also add with a high risk or survival threat, those kinds of settings

we have empirical evidence across the surface of the planet that biological systems can make that happen and we have zero empirical examples of silicon chips making that kind of a functionality arise so that's a very interesting point um

That kind of brings to this question about the similarities and the differences between the artificial neural networks and the biological structure, and also between the reinforcement learning paradigm and the active inference paradigm in which rather than maximizing a reward function,

we are minimizing an expected free energy or a variational free energy by way of bounding surprise.

So in describing the experimental setup,

the reward or rather the consequence of succeeding or failing was you adjusting the regularity of the input and in a reinforcement learning paradigm that's a little bit of an unconventional manipulation one might expect oh we'll add sugar or we'll add a dopamine agonist or an antagonist to the dish

to signal the positive or the negative valence directly kind of by putting our our finger on the scale of the reward function but rather you were able to train and learn by changing the patterns of regularity of feedback so how does active inference

have similarity and difference with reinforcement learning in terms of the way that we can use patterns of regularity, not just valence of interventions in learning?


SPEAKER_02:
I'll give an answer that I'm going to pass over to Adil who can dive a lot more into the computational side of it than what I could.

What I would say, though, is that there's a few things as well.

Like one of them, of course, is can you even adopt a reinforcement learning paradigm in a dish?

It's not like there was a choice between the two, because we don't have access to a privileged reward network inside the dish to be able to say, you know, good sales, bad sales.

You could, like in theory, squirt dopamine in, but you can't continually squirt dopamine in.

You can't do it in a spatial or temporal way.

resolution that's accurate enough, right?

It diffuses slowly across media.

We can't do it.

So for us, we needed to find something that was more fundamental.

and i think that's an important point and i think it's also interesting to note like that there are studies that look at the fact that you can mimic changes that you see with uh electrical information that you can also achieve through like the application of small molecules such as such as dopamine or whatever neurotransmitters

And the right stimulation can increase long-term potentiation much in the same way that say dopamine would.

And so dopamine seems likely to be a tool.

This is speculative, of course, but it seems likely to be a tool that shortcuts

uh the the way that these systems work in line with some broader imperatives such as free energy minimization more so than uh being something unique and special it is unique and special in its own right like in the way that it works but it must be serving a more fundamental function um


SPEAKER_00:
yeah i think that that's probably like a good way then to sort of lead into the differences between let's say an active frame inference framework and a reinforcement learning framework which which i think a deal would be best to best to discuss yeah um great question daniel uh first we started with the differences in uh in silico models or artificial neural networks and the biological neural networks so uh first of all as we see

uh the artificial neural network is a um is a caricature of an actual biological neuron um it just mimics that you know it takes an input uh you know and then

gives you an output.

There's a nonlinear function.

And then once you have many of them and stack them up and make layers, they can do amazing things.

So this is like artificial neural networks just using one of the

know a cartoon or what a biological neural network do it would do it it has a lot more than that it has it is an extremely complex uh biological uh you know thing so imagine now that uh you know we can we use all of the power and all the uh you know you know um

when it comes to what it can in terms of information processing and then build systems, how powerful they will be.

As we know, currently these huge

what we call these large-scale language models, for example, LLMs, and all those fundamental models that we have been seeing with billions of parameters.

To train them, it requires

a gigawatts of power it's basically like a whole city can build up with once they train now a human brain is just using a you know a small fraction of energy and time and power to do much more than what they could do they still can't do so

causal learning and causal reasoning problems very basics of them uh and while biological neurons can do it you know very easily as we are doing it right now we are having a back and forth discussion and you know um that's a big is one of the you know most uh sophisticated sophisticated and

huge neural network would not be able to achieve uh even for a few few few minutes um so that's that's what we are looking at there's an enormous um you know uh opportunity that we have to actually harness this power and do amazing things um now coming back to so that's you know uh now coming back to active inference and reinforcement learning now

this has been the uh this has been asked many times and um there are papers that call has it nothing new side it has a paper on on where they look at um you know uh however um

So I think active inference is biologically plausible.

So the main difference is that when you are an active inference system is optimizing a single quantity.

It's what we call the free energy, evasion free energy.

And that gives you a single optimization function.

you are doing perception, planning and decision making in the same with the same quantity.

So let me put this this way, you know, things that how things have happened over the past few decades that we it has been always been about how to optimize a function.

So once you have, let's say, a value function or reward in reinforcement learning,

It's all about how best you can optimize this quantity.

Well, what we are asking, we are saying that what is we are optimizing, not how we optimize.

So what is that quantity?

And that's the vision synergy that we are optimizing.

And it gives you all of that in a single year.

compared to a reinforcement learning system that would require multiple objective functions to optimize.

So I think it's not biologically attainable to have that.

So I don't think, and that's why the active inference is a unifying framework.

And it probably would rattle and offend few that we think that active inference subsumes all those computational frameworks like reinforcement learning,

you know, into dynamic programming and all those derivatives because it is basically what the brains are doing, you know, and they're doing it better than what, you know, framework that we have been using so far.

So I think there are differences, clear differences.

And however, having said that, I would really would like to see

uh in future and probably we probably will have a dig at it how you can actually uh mathematically which is then become unambiguously sure um provided a proof that where these uh you know

why active inference is superior.

So there's still a gap there.

While we could develop insular co-active inference agents and we can show them that they are doing better than reinforcement learning agents, and we have quite a few, there's a whole...

sort of work that one of my PhD students, Ashwin Paul, is doing and the papers are coming, where we are comparing active influence agents with the state of the art, reinforcement learning and deep learning networks.

And we are showing, of course, the active inference is doing better, but the theoretical proofs are still missing.

Similarly, like how active inference is

What are the similarities and differences?

For example, I would be very interested to know how it's different from Tudorov's work.

And again, Ashwin is looking at that.

I even know Tudorov's paper, P&A's paper in 2009, which looks at efficient computations, optimal action, which is far reaching.

They show that you can both in discrete and continuous settings

They have shown that the algorithms can beat dynamic programming and learning-based algorithms.

What is this?

What is how active inference is different from Tishpa's information bottleneck?

how how what are the links between universal prize of solomon off all those all those things i still you know it's it's really early days uh you know uh what are the similarities the differences

of active interest with all those big ideas, which are therefore, you know, in cybernetics and other literature for many, many, many years, for decades, what are the differences and in similarity?

So it's a good question.

We don't have all the answers, but, you know, all the, yeah.

So it would be very exciting next few years, looking at all those big questions.


SPEAKER_03:
just wanted to echo one point you made and then ask a question from the chat so in reinforcement learning what you should optimize is almost treated as an obvious question you want to win the game you want more points that's the way to win you want to stay alive then you want to optimize survival so that's your reward function and what to optimize is kind of swept under the rug

And then there's this big question of how to optimize it.

And that's what has led to this enormous diversification of different approaches and heuristics for how to optimize and different gradient descent methods and so on in reinforcement learning.

in contrast in active inference what to optimize is actually known it's the variational or the expected free energy as exactly specified by the generative model and we know how to optimize it which is with a variety of locally plausible

biologically inspired update rules for example message passing and belief propagation so that's a very subtle but also paradigmatic difference which is that the structure of what we're going to optimize as our unified imperative for perception cognition and action the free energy functional has methods and software packages that will step by step convergently optimize it

and so the onus is actually to specify the generative model in a useful way rather than treating what should be optimized as just a bygone discussion and then go into all these questions about implementation which are the parts that actually differ the most across systems so i think that's very um insightful i wanted to ask a question from the chat from michael

What would be the difference if you change the electrode array to stimulate differently?

For example, instead of just growing the neurons on top, what if the neurons synapsed with the electrodes?

So what kinds of experimental setups are possible and which ones are interesting and how do you know and what do you choose to do?


SPEAKER_02:
i think the the first thing to say about that uh good question and certainly as the technology develops we'll be able to ask these questions in better and more interesting ways like it's probably worth well you know i've made this comparison before but i'll make it again like the the work that we've done here is you know we we're excited by it but at the same time like it is probably equivalent to like the early transistors made by shockley

know it's janky it's kind of ugly it does a job but not without not without limitations um and so you know what we're really excited in is as the community hopefully come together and work on this

five ten fifteen twenty years maybe longer uh you know 70 years of continuous development have led from a transistor being a large ugly thing to thousands of them you know within every device that i can see uh so that's like one thing i'll just say in terms of like i will point out like that the the neurons do

in as much as they probably ever can integrate with the electrodes as is.

As you saw from that picture I showed at the start, they are deeply integrated into the electrode.

We could not and let the neurons survive remove them in any meaningful way and keep that structure.

To get them, we'd have to completely disassociate that structure, and most neurons won't survive that.

very long anyway uh so they are currently integrated like i mean synapses synapses work slightly differently uh yeah there's a whole there's a whole collection of traits like there is of course electrical activity is a shared language between neurons and and uh the hardware and that's what makes it possible to stimulate them with electricity because it can it can sort of mimic

the change in ions across the membrane to stimulate action potentials, which is how they then communicate with electricity.

But then action potentials, of course, trigger the release of chemical signals and so forth.

And so there's a lot that's going on there.

And I think it's about building the bridge.

It's not necessarily about

I don't know quite the right way to phrase this, about completely recapturing everything that's unique to biology and the hardware or unique to the hardware in biology.

It's about where's the useful bridge and synthesis

uh between them to elicit the best of both worlds and and again it comes down that right tool for the right job but in this case it's like a different circumstance like what's the right tool to process the information uh is it is it a biological part is it the hardware part uh and so when we communicated then what we need to figure out and again this is an open question like i'm not sure where it will go

But what we need to figure out is what's the best way at the time with the technology we have.

Right now, it's not trying to replicate sort of hardware-based synapses to do sort of chemical communication, although maybe in the future it will be.

But yeah, it's a very interesting question.

And the base of the answer is we don't really know where it could go.

And we don't know where it would do.

As I mentioned in the talk, they are incredibly plastic neurons.

We can change the configuration.

We can change the type of neurons.

We can move from 2D to 3D.

And this is work that we have ongoing now.

And I think that what we're going to see is just an explosion of results as we start to make inroads in this area.


SPEAKER_03:
saying that the neurons might not survive the separation from their cyber physical digital substrate reminds me of the reality of some to all of us today if we were also stripped from our digital substrate many critical systems also would not

function and I think that speaks to some of the recent work of Friston et al.

at Versus with the idea of the ecosystems of shared intelligence where we're thinking about distributed cognitive processes that are mediated by interfaces and so some emitted data set is received by another cognitive entity on the other side of the blanket

maybe it's person to person maybe it's computer to computer or something mixed or some augmented system but there's a really tractable and elegant way to talk about those heterogeneous systems so even if in the local context one algorithm or another outperforms another

there's going to be an immense value for using active inference and FEP to just talk about how to compose these systems.

And so that's very important insight.


SPEAKER_02:
100%.

That's a really good point, Daniel, like, very valuable.

And I, yeah, it comes down, I think, like fully agree with you, it comes down to like, how do we phrase and think about these even and that's a challenge.

Like even discussing what these systems are, and what they're showing is a challenge right now.

And we need to work on building up that language together.

So we can can have those useful discussions and figure out how to how to leverage this distributed network that we're all I think it's inevitable.

that you bring up that that's where we are and we're only going to go deeper down that direction.


SPEAKER_03:
Awesome.

Just a little bit of some questions on information as we head towards the end.

It was a very striking finding about the changes in information dynamics when gameplay was activated versus rest, as well as during learning.

And also that's kind of analogized by, let's say, a person in an fMRI

And they're mind wandering, they're engaging the default mode and then some task comes on and the information dynamics sharpen and we associate that with the mechanisms of attention.

So how did you measure or quantify the information or what do those informational measures mean in the context of neural firing patterns?


SPEAKER_02:
Yeah, that's a big question.

And it's, again, it's something that we need to do more work at diving into to actually unpick about what it actually means.

At this point, what we're limited to look, well, that's not entirely true.

We're not limited to it.

What we did look at just for the sake of time and complexity were individual spikes in a given location.

And so you can arrange that spatially and temporally.

And so what we've looked at, and we've dived into this more work with our recent work with organoids as well, trying to pick apart

sort of the sub functional sub units of computation or intelligence or whatever word you want to use.

But yes, essentially what it is, is it's the pattern of activity you're seeing across time and space for a given spike in a location versus the other ones.

And so there's a number of ways you can look at this.

I think the really exciting stuff that's coming out is around sort of trying to break apart.

So people started

Hodgkin-Huskley models, et cetera, they looked at neural spiking and they were like, how does a single neuron spike?

What makes a single neuron spike?

And they came up with some rules that are mostly true, but now we know are kind of still wrong because many neurons follow those rules and many do not.

And some are circumstance dependent.

And then people sort of extended that and they looked at how the given system changed its activity over time.

And then, of course, you can expand that out and look at like how do pairs of neurons and then trios of neurons and grow that up into a whole population.

And so what we've tried to do with this work that I've sort of shared with you today is look at that at a few different levels.

And so depending the level depends the exact answer to like what is information.

But

Essentially, the simplest answer is it's the spikes that we can see in this case going on and their relationships to other spikes.

I don't know, Dil might have more to expand on that.


SPEAKER_00:
No, I think at some point, as you mentioned, we want to look at those functional subunits, using those mean field models, using those functional units.

as neural populations and then you know hopefully there emerges like you know a few functional subunits and then can we look at the connectivity patterns using for something like a neural mass models you know which have been used quite a lot um something like a gentleman with models but a bit more uh Dynamics in them um and uh yeah so that would be really interesting to see uh how

the patterns are emerging when neurons learn how the patterns are firing patterns and and and connections and and and and then uh you know uh how these are changing over time as more and more learning is happening and that would be something yeah we are all talking about lots of uh unknowns and lots of very interesting directions that one can take um which makes it all exciting


SPEAKER_02:
And I think like our thinking also, at least my thinking has changed over the course of looking at this.

When I started out, I kind of thought, well, an individual neuron is the smallest functional unit, theoretically, right?

So that's probably what's going on.

And then they'll connect up.

And then I realized, well,

think like yeah it is a single neurons a functional unit but so are two neurons and three neurons and and the collective you know uh you know exponential growth as you go out to a whole pattern at the end of the day when we look at actually at the levels we're looking at for example criticality if you if you go look at the preprint we broke it down into areas like sensory versus motor areas and we found that they all kind of behave more or less the same so does that mean that on the dish we have one functional unit or eight hundred thousand

or everything in between and looking at looking at the organoid stuff that we've moved to that that we're not quite ready to share yet but like I think what we can sort of start to tentatively conclude from this work is that it's it is indeed that answer of like one to the combination of the the everything and I think that's what makes the biological systems and this is why I emphasize it in my talk look at the amount of connectivity and sort of

chaotic connectivity to some extent um that's occurring within these systems and that gives you something that we can't model with neuromorphic or with algorithms with any degree of um uh with the same traits at least i think i can say without being too controversial with the same traits we can't yet model that algorithmically yet and i think that makes it interesting as well


SPEAKER_03:
Awesome.

One just remark on that before kind of a closing discussion, the Hodgkin-Huxley models were on large single isolated neurons.

And so a theme I heard you say multiple times was like the right tool or the right model in the right context.

And so when studying sodium and potassium flows,

across the membrane of a single isolated neuron that is absolutely an appropriate model and something that provided immense insights and then as you pointed out especially if you're interested in properties of systems and connected neurons it's like a yes and like there are sodium flows

but you could imagine contexts where learning happens and the informational pattern or the entropy of a given neuron does change or it might not change but the pairwise relationship might change or the pairwise relationship might not change but some higher order relationship does change and so that doesn't replace mechanistic or smaller subunit based models

but rather we can broaden the discussion to thinking even about the environment like of the dish or of our peripersonal space that these cognitive systems are embedded in and talk about distributed cognitive functions without privileging the ecological or the sort of atomic levels of explanation yeah absolutely and thank you for clarifying that if i if i sort of implied otherwise yeah

Awesome, no, just to highlight because despite the ring on the cover of the active inference textbook, there isn't a single model to rule them all.

And I think like it's really by getting into the particulars of experiments and also by speaking with researchers and by talking about this kind of cutting edge research that we see how pluralism in the methodological and in the explanations

actually plays out and that's just very exciting um so i guess just a uh closing question and then we can just have any other remarks uh michael asks in the chat

What should someone study or do to get more involved with this research?

I'm an undergraduate student interested in pursuing this field for my career, and I'd love to work with Cortical Labs.


SPEAKER_02:
So I think it really depends the area you want to go down.

We're always looking for good people to work with.

And as I said before, this is going to be a whole industry and a whole field of research, we hope and believe anyway.

So I guess you should pick what it is that interests you and what you're passionate about.

There's so much stuff going on, right?

You could study electrical engineering, you could study physics, you could study software engineering, you could study neuroscience, you could study stem cell biology, anything in between.

These are multidisciplinary, highly collaborative outputs.

I showed the team before we have people from all of those industries and others.

And it's only the combination of these areas that give rise to the chance to actually make something that it's the Gestalt, right?

It's greater than the sum of its parts.

And I think honestly, that's one of the reasons why we've had some success coming from a sort of startup industry focus is that

there's not that many of us and we don't have that much money but what we do have is like an amazing team of people to work with amazing collaborators like a deal to work with um and we can bring it all together in one spot and that's that's hard to do by its nature in academia like by its nature academia tends to silo and you have exceptions to that rule of course you have like very highly collaborative works that do come out of academia

they're always they are always i've worked in academia um so they're always at a distance those collaborations they're not all under one roof with one one goal and one purpose so


SPEAKER_03:
Oh, no, just so yeah, please.

Any general comments?

Feel free to respond to that.

And also just any general thoughts you want to add.


SPEAKER_00:
I was I was I was to say I cannot recommend enough cortical labs.

They are highly disciplinary, well, disciplinary team with expertise from cell biology to, you know, to software engineering, to real time interfacing, to computational models and machine learning.

So, you know,

anything that you know your expertise and you you want to do there would be something that that that's there and really cutting edge and so um yeah I I think there's this whole project you know it just shows you know uh the whole breadth of things that we can do from uh from neurons to sentient behavior and I'm I'm patting my backs for saying sentient

sentence today which hasn't been said so um and and i should say brett is also leading a you know a project on on that site we which we didn't get chance to talk about about the about the nomenclature and all that that happens with the semantic of sentence and consciousness and emergency and all that um so um and and and and the whole ethics side of thing

So there are big, big opportunities and questions, open challenges, and I think you... Actually, Adil, you make a good point.


SPEAKER_02:
I should use this opportunity, if I may, Daniel.

At least a two-flag, yeah, we are engaging in a paper.

So if you are interested in the words that we use, whether you think that we use them correctly or incorrectly,

uh we would invite anyone you know we've made these offers before but it's a great place to say it again reach out um we are setting up and we will have a formal invitation uh somewhat soon i can't exactly say when because there's so much going on at the moment but fairly soon we'll have an invitation uh come join us let's work together and just like figure out what language we want to use as a community because uh

then we can move towards actually building some stuff instead of just being caught up with like, what does this word mean?

And that's going to be necessary.

So yeah, please reach out to us.


SPEAKER_03:
Yeah, I'll just note one project at the Institute, which is the Active Inference Ontology, where we've been developing definitions and also translations across languages of core and supplemental terms, and we use that to annotate papers, we make natural language descriptions of mathematical formalizations, and we totally agree that ontology-based systems engineering

for active inference cyber physical systems is how we're going to treat this with the respect and also bring in the discussions around ethics philosophy and so on so this isn't a linguistics debate that excludes other fields this is like laying down the dance floor so that we can actually have a discussion that's inclusive and meaningful going forward which is what is so important yeah

That's awesome.


SPEAKER_02:
I got to look this up.

I didn't know that you guys had one of those.

I'm going to have a look up later.


SPEAKER_03:
I'll send it to you in an email.

Well, thank you so much.

What an awesome line of research and a December surprise or treat for us.

So super exciting.

And please always feel welcome to just reach out and join for any other time.


SPEAKER_02:
Awesome.

Thank you so much, Daniel, for having us and everyone watching.

Bye.

Thank you.