1
00:00:06,380 --> 00:00:08,448
>>>DANIEL FRIEDMAN: All right. Hello and welcome, everyone.

2
00:00:08,614 --> 00:00:12,080
It's December 7, 2022.

3
00:00:12,230 --> 00:00:14,620
This is Active Inference live stream

4
00:00:14,700 --> 00:00:18,556
number 31.1. We are here with Brett

5
00:00:18,588 --> 00:00:21,072
Kagan and we're going to be hearing a

6
00:00:21,126 --> 00:00:23,712
presentation and having a discussion on

7
00:00:23,766 --> 00:00:26,036
free energy principle and active

8
00:00:26,068 --> 00:00:28,132
inference in synthetic biological

9
00:00:28,196 --> 00:00:30,820
intelligence. We'll have a presentation

10
00:00:30,980 --> 00:00:33,704
followed by a discussion, so feel free

11
00:00:33,742 --> 00:00:35,656
to submit any questions if you would

12
00:00:35,678 --> 00:00:38,644
like. Brett, thank you for joining.

13
00:00:38,692 --> 00:00:40,092
Really looking forward to this

14
00:00:40,226 --> 00:00:43,230
presentation and discussion. Off to you.

15
00:00:44,160 --> 00:00:45,996
>>>BRETT KAGAN: Thanks so much, Daniel, and thank you.

16
00:00:46,018 --> 00:00:47,736
Everyone joining us today. Hopefully

17
00:00:47,768 --> 00:00:49,852
we've got some interesting stuff. So

18
00:00:49,906 --> 00:00:51,984
what I want to talk to you about is the

19
00:00:52,022 --> 00:00:54,736
work that we've been doing in what we

20
00:00:54,758 --> 00:00:56,492
call synthetic biological intelligence,

21
00:00:56,556 --> 00:00:59,056
and particularly the use we've made of

22
00:00:59,158 --> 00:01:00,512
principles from the free energy

23
00:01:00,566 --> 00:01:01,884
principle and active Inference

24
00:01:01,932 --> 00:01:06,464
frameworks. So if

25
00:01:06,502 --> 00:01:08,340
we jump to sort of the first question

26
00:01:08,410 --> 00:01:09,664
and we can kind of ask ourselves,

27
00:01:09,712 --> 00:01:11,376
because we work with neural systems,

28
00:01:11,488 --> 00:01:13,344
what is there that's unique about neural

29
00:01:13,392 --> 00:01:15,296
systems? And one of the obvious answers

30
00:01:15,328 --> 00:01:17,684
to that is that they display this unique

31
00:01:17,732 --> 00:01:19,832
ability to collate information and apply

32
00:01:19,886 --> 00:01:21,636
it in an adaptive behavior in multiple

33
00:01:21,668 --> 00:01:23,476
contexts. And that could be a fitting

34
00:01:23,508 --> 00:01:24,936
definition for intelligence, if you

35
00:01:24,958 --> 00:01:28,248
like. But to actually be

36
00:01:28,254 --> 00:01:30,648
able to test this in actual cells in

37
00:01:30,654 --> 00:01:31,976
real time, what you have to do is be

38
00:01:31,998 --> 00:01:33,708
able to record the information from the

39
00:01:33,714 --> 00:01:35,916
cells and provide information back to

40
00:01:35,938 --> 00:01:38,876
the cells in real time. So how did we go

41
00:01:38,898 --> 00:01:40,316
about setting this up? How did we get

42
00:01:40,338 --> 00:01:42,770
these cells? So we did it in two ways.

43
00:01:43,380 --> 00:01:45,968
Either we took what's called a human

44
00:01:46,054 --> 00:01:48,076
induced pluripotent stem cell. That's

45
00:01:48,108 --> 00:01:51,632
the hiPSC there that you can see.

46
00:01:51,766 --> 00:01:53,552
And what you can do is develop these

47
00:01:53,606 --> 00:01:57,148
from any donor blood, tissue or skin.

48
00:01:57,324 --> 00:01:59,456
And you can basically make a pluripotent

49
00:01:59,488 --> 00:02:00,836
stem cell line. And then you can use a

50
00:02:00,858 --> 00:02:02,404
number of different methods to turn that

51
00:02:02,442 --> 00:02:05,076
into neurons of quite a degree of

52
00:02:05,098 --> 00:02:07,384
specificity. We used quite a broad one

53
00:02:07,422 --> 00:02:08,616
force, most of our work, which is called

54
00:02:08,638 --> 00:02:10,788
a jewel smad inhibition, which follows

55
00:02:10,804 --> 00:02:12,920
like, natural ontological development,

56
00:02:14,140 --> 00:02:16,570
or ontogeney development, I should say,

57
00:02:17,340 --> 00:02:20,984
to sort of create these

58
00:02:21,102 --> 00:02:24,348
predominantly cortical cultures in a

59
00:02:24,354 --> 00:02:26,012
dish. But you can use other direct

60
00:02:26,066 --> 00:02:27,276
methods such as what's called an

61
00:02:27,298 --> 00:02:29,084
Ngntirect differentiation, which gives

62
00:02:29,122 --> 00:02:31,836
rise to a more excitatory culture. Then

63
00:02:31,858 --> 00:02:33,784
we also took primary cortical

64
00:02:33,832 --> 00:02:35,528
neurocultures from mouse and we drew

65
00:02:35,544 --> 00:02:36,784
them as a competition because we wanted

66
00:02:36,822 --> 00:02:38,496
to make sure that we were using, at

67
00:02:38,518 --> 00:02:40,716
least in some sense, bona fide cortical

68
00:02:40,828 --> 00:02:42,848
neurons. And the best way to do that is

69
00:02:42,854 --> 00:02:44,784
to take it from animals. But

70
00:02:44,822 --> 00:02:47,536
fortunately, as you see, we will be able

71
00:02:47,558 --> 00:02:48,996
to move, and we have moved away from

72
00:02:49,018 --> 00:02:50,356
that now in our current practice. So

73
00:02:50,378 --> 00:02:52,596
we're completely animal testing free at

74
00:02:52,618 --> 00:02:55,156
the moment. And then what we did was we

75
00:02:55,178 --> 00:02:57,604
plated these onto what's called a high

76
00:02:57,642 --> 00:02:59,764
density multiletrode array. And

77
00:02:59,802 --> 00:03:00,968
essentially I'll show you a bit more of

78
00:03:00,974 --> 00:03:03,416
this in a second. This is essentially a

79
00:03:03,518 --> 00:03:05,496
CMOs chip, which is a type of chip that

80
00:03:05,518 --> 00:03:07,896
you might get in a digital camera. But

81
00:03:07,918 --> 00:03:09,396
it's also can be used in this purpose

82
00:03:09,428 --> 00:03:11,100
because what it can do is sense

83
00:03:11,250 --> 00:03:13,164
electrical signals, even very small

84
00:03:13,202 --> 00:03:14,664
ones, and actually be able to stimulate

85
00:03:14,712 --> 00:03:17,852
to them. And so just

86
00:03:17,986 --> 00:03:20,124
some evidence that we actually did do

87
00:03:20,162 --> 00:03:21,516
the work we said we did. Here's some

88
00:03:21,538 --> 00:03:22,828
examples of some cultures that we've

89
00:03:22,844 --> 00:03:25,376
grown, and they show what we're able to

90
00:03:25,398 --> 00:03:28,124
do is use techniques to actually capture

91
00:03:28,252 --> 00:03:31,804
key markers of aspects of these cells.

92
00:03:31,852 --> 00:03:34,576
So, for example, this Bleu over here,

93
00:03:34,598 --> 00:03:35,820
hopefully it's coming up all right on

94
00:03:35,830 --> 00:03:37,844
your screens. This shows something

95
00:03:37,882 --> 00:03:39,984
called DAPI, which marks all the nucleus

96
00:03:40,032 --> 00:03:43,028
of any cell. If you want, you can look

97
00:03:43,034 --> 00:03:44,564
at something called new. And here new

98
00:03:44,602 --> 00:03:47,296
and marks neurons. So all the green dots

99
00:03:47,328 --> 00:03:48,276
and you might be able to see a bit

100
00:03:48,298 --> 00:03:50,128
better in this picture, all the green

101
00:03:50,154 --> 00:03:51,992
dots show that this is actually a

102
00:03:52,046 --> 00:03:54,248
neuron. And then, of course, one of the

103
00:03:54,254 --> 00:03:55,768
things that we know neurons have is that

104
00:03:55,774 --> 00:03:57,976
they send out axons. And that's what

105
00:03:57,998 --> 00:03:59,876
this thing called, beta three tubulin

106
00:03:59,908 --> 00:04:02,248
marks in the red. And finally, we want

107
00:04:02,254 --> 00:04:03,628
to know, do they have dendrites? And you

108
00:04:03,634 --> 00:04:05,084
can see here in the purple, this is

109
00:04:05,122 --> 00:04:06,636
marking dendrites. Also a little bit of

110
00:04:06,658 --> 00:04:08,748
axons, but it also marks dendrites as

111
00:04:08,754 --> 00:04:11,388
well. And then more than that, we want

112
00:04:11,394 --> 00:04:13,064
to know is not just are they neurons,

113
00:04:13,112 --> 00:04:15,264
because most neurons will have those

114
00:04:15,302 --> 00:04:17,324
traits, but also are they cortical

115
00:04:17,372 --> 00:04:20,128
neurons? And BRN one is actually a

116
00:04:20,134 --> 00:04:21,616
marker for cortical neurons. You can see

117
00:04:21,638 --> 00:04:23,120
here actually, not only are they

118
00:04:23,190 --> 00:04:25,008
neurons, but most of those neurons are

119
00:04:25,014 --> 00:04:27,428
cortical. Specifically, there's of

120
00:04:27,434 --> 00:04:28,768
course, going to be different cell types

121
00:04:28,784 --> 00:04:32,004
in there. For example, GFAP here mark

122
00:04:32,042 --> 00:04:34,436
supporting cell types such as glia. And

123
00:04:34,458 --> 00:04:35,796
you can see here we have a number of

124
00:04:35,818 --> 00:04:37,956
glia. You can also really obviously see

125
00:04:37,978 --> 00:04:39,808
that these glia, these in the bigger

126
00:04:39,824 --> 00:04:41,512
picture, have quite a different

127
00:04:41,566 --> 00:04:44,388
morphology than the neurons. So it's

128
00:04:44,404 --> 00:04:45,716
nice that we have sort of this mixed

129
00:04:45,748 --> 00:04:46,948
population because it means that we're

130
00:04:46,964 --> 00:04:48,316
able to test something that has some

131
00:04:48,338 --> 00:04:52,696
degree of comparable characteristics

132
00:04:52,728 --> 00:04:56,556
to what you might see in an animal or

133
00:04:56,578 --> 00:05:00,332
in our cortical areas. Of course,

134
00:05:00,386 --> 00:05:02,428
it's much, much simpler magnitudes and

135
00:05:02,434 --> 00:05:06,064
magnitude simpler than that. But it is

136
00:05:06,182 --> 00:05:07,728
reassuring for the function to know that

137
00:05:07,734 --> 00:05:10,448
there are some similarities as a model.

138
00:05:10,614 --> 00:05:12,720
And importantly for anyone who has

139
00:05:12,790 --> 00:05:14,528
looked at sort of creating cells out of

140
00:05:14,534 --> 00:05:15,968
stem cells, one of the big problems is

141
00:05:15,974 --> 00:05:17,664
that not all of those cells might be

142
00:05:17,782 --> 00:05:19,684
fully differentiate. And if you do have

143
00:05:19,722 --> 00:05:21,268
cells that aren't differentiate that are

144
00:05:21,274 --> 00:05:22,708
still pouriponent when you put them in a

145
00:05:22,714 --> 00:05:24,996
dish, they can turn into anything. And

146
00:05:25,018 --> 00:05:26,148
of course, most of the time what they

147
00:05:26,154 --> 00:05:28,208
turn into is something invasive and

148
00:05:28,234 --> 00:05:29,848
potentially cancerous, depending what it

149
00:05:29,854 --> 00:05:33,028
is. Fortunately, this KR 67 marks

150
00:05:33,124 --> 00:05:35,448
dividing cells. So this would sort of

151
00:05:35,454 --> 00:05:38,148
mark any cell that wasn't fully

152
00:05:38,164 --> 00:05:41,624
differentiated. And this is a case

153
00:05:41,662 --> 00:05:42,956
where we had none of them and that was

154
00:05:42,978 --> 00:05:44,684
common, but generally we had none to

155
00:05:44,722 --> 00:05:46,556
very, very few. And because of that,

156
00:05:46,578 --> 00:05:48,460
we're actually able to have these

157
00:05:48,610 --> 00:05:51,484
cultures growing for extended periods of

158
00:05:51,522 --> 00:05:54,136
time. And this is what's action

159
00:05:54,168 --> 00:05:55,968
planning, electron microscopy image. So

160
00:05:55,974 --> 00:05:57,868
these are real biological neurons.

161
00:05:57,964 --> 00:05:59,216
They're a little cracked because when

162
00:05:59,238 --> 00:06:01,596
you do the cryo aspect of the scanning

163
00:06:01,628 --> 00:06:04,364
and you freeze them for the necessary

164
00:06:04,412 --> 00:06:06,976
preparation, they do tend to crack a

165
00:06:06,998 --> 00:06:08,724
bit. But you can still mostly see that

166
00:06:08,762 --> 00:06:11,156
there are a lot of intact neurons, a lot

167
00:06:11,178 --> 00:06:12,628
of connections, and then behind that you

168
00:06:12,634 --> 00:06:14,708
can actually see all the electrodes and

169
00:06:14,714 --> 00:06:15,988
you can also see the density and the

170
00:06:15,994 --> 00:06:18,292
complexity of this. And this is actually

171
00:06:18,346 --> 00:06:20,484
an area of the chip that is less dense

172
00:06:20,532 --> 00:06:22,248
and interconnected than some of the

173
00:06:22,254 --> 00:06:24,088
other areas because if you look at the

174
00:06:24,094 --> 00:06:25,096
ones that are highly dense and

175
00:06:25,118 --> 00:06:27,076
interconnected, you can't see the chip

176
00:06:27,108 --> 00:06:28,728
behind it. We kind of wanted to show the

177
00:06:28,734 --> 00:06:30,410
fact that there's a chip behind this.

178
00:06:31,180 --> 00:06:32,740
And I think one of the key things to

179
00:06:32,750 --> 00:06:34,584
take away from this simply is the degree

180
00:06:34,632 --> 00:06:36,556
of complexity you get here compared to

181
00:06:36,578 --> 00:06:37,816
something like an artificial neural

182
00:06:37,848 --> 00:06:39,628
network. A lot of the time people look

183
00:06:39,634 --> 00:06:41,560
at models and they're quite nice and

184
00:06:41,570 --> 00:06:43,856
neat and symmetrical and that's just not

185
00:06:43,878 --> 00:06:46,348
what happens in biology. And as we'll

186
00:06:46,364 --> 00:06:48,592
discuss later, there's probably some

187
00:06:48,646 --> 00:06:50,416
interesting features that arise out of

188
00:06:50,438 --> 00:06:54,716
this degree and this extent of random

189
00:06:54,748 --> 00:06:57,844
or pseudorandom connectivity. And so

190
00:06:57,882 --> 00:06:58,964
what we could then do with this

191
00:06:59,002 --> 00:07:01,540
technology is map out this is an example

192
00:07:01,610 --> 00:07:03,796
of like, the chip surface and then the

193
00:07:03,818 --> 00:07:05,796
firing rate in hertz can be seen here as

194
00:07:05,818 --> 00:07:08,836
a color scale. And we can see over time

195
00:07:08,938 --> 00:07:10,984
with different cell types, we can get

196
00:07:11,022 --> 00:07:13,316
their activity and different cell types

197
00:07:13,348 --> 00:07:14,872
sort of turn on or begin to become

198
00:07:14,926 --> 00:07:16,216
active at different times. But

199
00:07:16,238 --> 00:07:17,976
importantly, what we can do is get a

200
00:07:18,078 --> 00:07:20,756
fairly even distribution of active cells

201
00:07:20,788 --> 00:07:23,032
over the surface area fairly

202
00:07:23,096 --> 00:07:25,148
consistently. Again, anyone who works in

203
00:07:25,154 --> 00:07:26,556
this area knows there's a fair bit of

204
00:07:26,578 --> 00:07:28,204
variation inherently and that's stuff

205
00:07:28,242 --> 00:07:29,708
we're working on now for the future.

206
00:07:29,874 --> 00:07:32,050
But we are able to get this degree of

207
00:07:33,540 --> 00:07:35,296
activity over time and that gives us

208
00:07:35,318 --> 00:07:37,744
some useful cell cultures to test. Of

209
00:07:37,782 --> 00:07:41,104
course. How do we go about testing that?

210
00:07:41,142 --> 00:07:44,144
Which is the big question. And we know

211
00:07:44,182 --> 00:07:47,076
that as a living organism, you, me,

212
00:07:47,178 --> 00:07:49,988
mice, cats, whatever, we need to have

213
00:07:49,994 --> 00:07:51,504
the closed loop feedback to operate.

214
00:07:51,552 --> 00:07:53,024
And what does that mean? Essentially,

215
00:07:53,072 --> 00:07:56,464
it means that we're able to receive

216
00:07:56,512 --> 00:07:58,116
information about the outcomes of our

217
00:07:58,138 --> 00:07:59,736
actions and modify our actions as a

218
00:07:59,758 --> 00:08:01,448
result of it. So if I reach over for a

219
00:08:01,454 --> 00:08:04,228
cell phone, I immediately get sensory

220
00:08:04,324 --> 00:08:07,496
feedback in a number of modalities as I

221
00:08:07,518 --> 00:08:08,968
do that action. And as I pick it up,

222
00:08:08,974 --> 00:08:10,728
I'm aware of the success of it. If I

223
00:08:10,734 --> 00:08:13,596
fail, I'm aware of that too. And this is

224
00:08:13,618 --> 00:08:15,816
actually this little mouse with a VR

225
00:08:15,848 --> 00:08:18,396
headset from this Attenger study, which

226
00:08:18,418 --> 00:08:19,768
is one of my favorite studies that's

227
00:08:19,784 --> 00:08:21,564
been done in recent times where they

228
00:08:21,602 --> 00:08:23,224
actually attached their virtual reality

229
00:08:23,272 --> 00:08:24,576
to mice. And I found that if they

230
00:08:24,598 --> 00:08:26,848
disconnected the mouse's movement as it

231
00:08:26,854 --> 00:08:28,444
was developing from the actual visual

232
00:08:28,492 --> 00:08:30,736
information it got, it led to quite

233
00:08:30,838 --> 00:08:33,928
catastrophic developmental,

234
00:08:34,044 --> 00:08:36,180
functional developmental impairments.

235
00:08:36,680 --> 00:08:38,516
And it just really shows it shouldn't be

236
00:08:38,538 --> 00:08:41,236
surprising so much, but it does show us

237
00:08:41,258 --> 00:08:43,536
like that this link with our environment

238
00:08:43,648 --> 00:08:45,876
is incredibly important for us as

239
00:08:45,898 --> 00:08:49,248
organisms to develop. And so if you're

240
00:08:49,264 --> 00:08:51,048
looking at cells in a dish and you want

241
00:08:51,054 --> 00:08:52,488
to try and elicit intelligence, you can

242
00:08:52,494 --> 00:08:54,424
immediately say, well, you need to have

243
00:08:54,462 --> 00:08:56,388
some sort of linkage, some Embodiment,

244
00:08:56,484 --> 00:08:58,036
which is active through this closed loop

245
00:08:58,068 --> 00:09:01,608
system to be set up. And so one of

246
00:09:01,614 --> 00:09:03,116
the better ways to sort of do this is to

247
00:09:03,138 --> 00:09:04,892
contrast it with an open feedback system

248
00:09:04,946 --> 00:09:06,620
because that's what people generally do.

249
00:09:06,690 --> 00:09:08,824
So just to emphasize this closed loop

250
00:09:08,872 --> 00:09:11,196
means that we stimulate some sort of

251
00:09:11,218 --> 00:09:12,629
sensation and that can be done with an

252
00:09:13,129 --> 00:09:14,896
electrical stimulation. And we can

253
00:09:14,918 --> 00:09:16,960
provide then a sensory feedback, again

254
00:09:17,030 --> 00:09:19,344
through electrical stimulation on how

255
00:09:19,382 --> 00:09:21,356
that response alters the world. And it's

256
00:09:21,388 --> 00:09:22,848
actually been demonstrated before in a

257
00:09:22,854 --> 00:09:24,164
few studies, for example, in this back

258
00:09:24,202 --> 00:09:26,144
and paper, that this closed loop

259
00:09:26,192 --> 00:09:28,176
stimulation does result in increased

260
00:09:28,208 --> 00:09:29,220
plasticity.

261
00:09:31,080 --> 00:09:33,188
But we wanted to try and take it a

262
00:09:33,194 --> 00:09:35,396
little further and actually see if we

263
00:09:35,418 --> 00:09:38,060
could elicit a very clear goal directed

264
00:09:38,160 --> 00:09:40,728
behavior. And so we set up this is a

265
00:09:40,734 --> 00:09:42,728
little schematic of the dish. And what

266
00:09:42,734 --> 00:09:46,360
we did was we almost arbitrarily defined

267
00:09:47,180 --> 00:09:48,872
I shouldn't say it's arbitrary because

268
00:09:48,926 --> 00:09:51,444
there was a lot of planning and strategy

269
00:09:51,492 --> 00:09:53,724
behind it. But what I mean by this is

270
00:09:53,762 --> 00:09:56,476
that within a given framework, for

271
00:09:56,498 --> 00:09:57,676
example, here, what we did was we

272
00:09:57,698 --> 00:09:59,516
designated a sensory region where we put

273
00:09:59,538 --> 00:10:01,708
information into electrodes using a

274
00:10:01,714 --> 00:10:03,528
combination of rate and place encoding.

275
00:10:03,624 --> 00:10:05,168
And then we read it out in this sort of

276
00:10:05,174 --> 00:10:08,268
counterbalanced region here. So activity

277
00:10:08,364 --> 00:10:09,968
in these two regions would make the

278
00:10:09,974 --> 00:10:11,536
paddle move up. Activity in these two

279
00:10:11,558 --> 00:10:13,330
regions would make the paddle move down.

280
00:10:13,940 --> 00:10:15,876
But the reason I say it's arbitrary was

281
00:10:15,898 --> 00:10:19,332
that we were able to basically change

282
00:10:19,386 --> 00:10:21,492
this configuration to a number of ways

283
00:10:21,546 --> 00:10:23,396
and for the most part, although there

284
00:10:23,418 --> 00:10:26,036
were some differences, get a degree of

285
00:10:26,058 --> 00:10:27,676
statistically significant performance.

286
00:10:27,728 --> 00:10:29,544
And that, of course, just shows the fact

287
00:10:29,582 --> 00:10:31,448
that neurons as, again, shouldn't be a

288
00:10:31,454 --> 00:10:33,604
surprise to anybody, are incredibly

289
00:10:33,652 --> 00:10:36,584
plastic and able to adapt and change how

290
00:10:36,622 --> 00:10:39,336
they respond otherwise. And I think

291
00:10:39,358 --> 00:10:40,316
that's a really interesting thing

292
00:10:40,338 --> 00:10:42,108
because, of course, starting out here,

293
00:10:42,274 --> 00:10:44,008
there is no real reason why neuron

294
00:10:44,024 --> 00:10:45,900
should behave in any particular way

295
00:10:46,050 --> 00:10:48,476
unless they're doing it to accord to

296
00:10:48,498 --> 00:10:51,356
some fundamental imperative. And this is

297
00:10:51,378 --> 00:10:53,528
just an example of the visualization.

298
00:10:53,624 --> 00:10:56,908
You're actually able to go there's a

299
00:10:56,914 --> 00:10:58,348
site. If you jump to our website, we'll

300
00:10:58,364 --> 00:11:00,492
show that later. It's called Spikestream

301
00:11:00,636 --> 00:11:02,144
and you can go and play around with this

302
00:11:02,182 --> 00:11:04,176
yourself. It's available. So this is an

303
00:11:04,198 --> 00:11:07,576
example of the electrode multiletrode

304
00:11:07,628 --> 00:11:09,344
ray. Each little dot is a potential

305
00:11:09,392 --> 00:11:10,836
electrode we can route. The Bleu ones

306
00:11:10,858 --> 00:11:11,908
are the ones we're routing at the

307
00:11:11,914 --> 00:11:15,312
moment. Each little bar is an activity

308
00:11:15,376 --> 00:11:16,916
and you can see we put activity in the

309
00:11:16,938 --> 00:11:18,916
top and then we read it out at the

310
00:11:18,938 --> 00:11:21,656
bottom and it moves these paddle. And

311
00:11:21,678 --> 00:11:23,512
over time, as I'll show you, it gets

312
00:11:23,566 --> 00:11:25,844
better. Feel free to go to the spike

313
00:11:25,892 --> 00:11:27,304
stream and have a look at that. But

314
00:11:27,342 --> 00:11:29,304
right now what I want to discuss is,

315
00:11:29,502 --> 00:11:30,988
yes, it's all well and good that a

316
00:11:30,994 --> 00:11:33,196
system may be able to organize its

317
00:11:33,218 --> 00:11:36,508
behavior in a changing environment. And

318
00:11:36,514 --> 00:11:38,732
this is actually an example of a very

319
00:11:38,786 --> 00:11:40,696
successful so these are actual neurons

320
00:11:40,728 --> 00:11:42,492
driving this paddle. So it's an example

321
00:11:42,546 --> 00:11:44,748
of one of our more successful cultures.

322
00:11:44,844 --> 00:11:47,516
But by no means is it a weird exception.

323
00:11:47,548 --> 00:11:48,912
We do see this sort of better

324
00:11:48,966 --> 00:11:51,776
performance fairly often. Again, there

325
00:11:51,798 --> 00:11:54,976
is variation, of course, and one of the

326
00:11:54,998 --> 00:11:56,944
ways that we wanted to investigate this

327
00:11:56,982 --> 00:11:59,204
initially was this idea of the free

328
00:11:59,242 --> 00:12:01,508
energy principle, which I'm sure many of

329
00:12:01,514 --> 00:12:03,188
you are familiar with. So I'm not going

330
00:12:03,194 --> 00:12:04,724
to go into it in a great amount of

331
00:12:04,762 --> 00:12:06,928
detail, but I will provide kind of like

332
00:12:06,954 --> 00:12:09,256
a higher level summary of it Beren and

333
00:12:09,278 --> 00:12:11,396
the key things that we can sort of boil

334
00:12:11,428 --> 00:12:14,580
it down to in a very oversimplified

335
00:12:14,660 --> 00:12:18,136
sense. Essentially it means that what we

336
00:12:18,158 --> 00:12:20,016
want to do with the Frenchie principle,

337
00:12:20,068 --> 00:12:21,528
it suggests that there is an innate

338
00:12:21,544 --> 00:12:24,972
generative or a system to actually match

339
00:12:25,026 --> 00:12:27,832
a prediction that it makes to incoming

340
00:12:27,896 --> 00:12:29,468
sensation. And this can be phrased in

341
00:12:29,474 --> 00:12:31,916
Bayesian terms and there's a lot of

342
00:12:31,938 --> 00:12:33,584
implications one can take from that.

343
00:12:33,622 --> 00:12:35,916
And I love this picture that Karl

344
00:12:35,948 --> 00:12:38,256
Friston wrote up in his or developed as

345
00:12:38,278 --> 00:12:40,640
part of his Nature Neuroscience Reviews

346
00:12:41,940 --> 00:12:43,536
article. If you haven't seen it, read

347
00:12:43,558 --> 00:12:44,928
it. It's a great article. It covers a

348
00:12:44,934 --> 00:12:46,944
lot of good stuff, but simply between

349
00:12:46,982 --> 00:12:48,452
the linkages between the different

350
00:12:48,506 --> 00:12:51,268
levels of the system. And of course it

351
00:12:51,274 --> 00:12:52,916
is. And one of the strong arguments for

352
00:12:52,938 --> 00:12:54,724
it is that being able to predict and act

353
00:12:54,762 --> 00:12:56,832
in your environment is theoretically

354
00:12:56,896 --> 00:13:00,144
necessary. And the other implication,

355
00:13:00,192 --> 00:13:01,368
of course, is that there needs to be a

356
00:13:01,374 --> 00:13:02,696
statistical boundary between the

357
00:13:02,718 --> 00:13:04,616
internal and the external, which is

358
00:13:04,638 --> 00:13:05,768
called a micro blanket. And we're going

359
00:13:05,774 --> 00:13:07,370
to touch on that a bit more later.

360
00:13:07,980 --> 00:13:09,576
Diving into the notion of active

361
00:13:09,608 --> 00:13:12,460
inference via the free energy principle,

362
00:13:12,800 --> 00:13:14,636
formally, it's sort of been stated that

363
00:13:14,658 --> 00:13:16,136
this is a process of minimizing

364
00:13:16,168 --> 00:13:17,736
variation of free energy through action

365
00:13:17,768 --> 00:13:20,876
and perception. And essentially what

366
00:13:20,898 --> 00:13:21,932
it's saying here is that a living

367
00:13:21,986 --> 00:13:23,736
organism is going to actively generate

368
00:13:23,768 --> 00:13:25,308
this internal model of the external

369
00:13:25,324 --> 00:13:27,570
world and then align those models. And

370
00:13:28,020 --> 00:13:29,696
broadly speaking, there's two ways we

371
00:13:29,718 --> 00:13:31,056
can do that, either perception or

372
00:13:31,078 --> 00:13:33,456
action. So if I use my cell phone as an

373
00:13:33,478 --> 00:13:35,956
example before, if I reach over, pick it

374
00:13:35,978 --> 00:13:38,068
up, what I've done is I've created a

375
00:13:38,074 --> 00:13:40,016
model in my head based on the visual

376
00:13:40,048 --> 00:13:42,548
information I've received, where the

377
00:13:42,554 --> 00:13:45,216
cell phone is. I've reached over, I've

378
00:13:45,248 --> 00:13:47,904
picked it up, very good. My perception

379
00:13:47,952 --> 00:13:49,976
matched, matched my reality. Let's say

380
00:13:49,998 --> 00:13:51,656
though, that I didn't and I dropped it

381
00:13:51,678 --> 00:13:53,496
as I tried to pick it up. Well, what

382
00:13:53,518 --> 00:13:55,530
could I do? Either I could get better at

383
00:13:56,620 --> 00:14:00,376
predicting the world and say look, when

384
00:14:00,398 --> 00:14:01,736
I reach, I will always drop my cell

385
00:14:01,758 --> 00:14:04,856
phone or I could get better at defining

386
00:14:04,888 --> 00:14:06,828
where it is in the world. All what I

387
00:14:06,834 --> 00:14:07,964
could do is get better at the actual

388
00:14:08,002 --> 00:14:10,188
reaching action. And really when you

389
00:14:10,194 --> 00:14:11,596
boil down to it, these are the only two

390
00:14:11,618 --> 00:14:13,324
ways that a system can get better at

391
00:14:13,362 --> 00:14:14,592
predicting its environment, either

392
00:14:14,646 --> 00:14:16,288
through getting better prediction or

393
00:14:16,294 --> 00:14:17,376
getting better at controlling the

394
00:14:17,398 --> 00:14:19,184
environment. And so for our cell

395
00:14:19,222 --> 00:14:21,484
culture, what we wanted to do was simply

396
00:14:21,532 --> 00:14:24,404
remove one of these options. So it's a

397
00:14:24,442 --> 00:14:26,612
very simple implication from a very

398
00:14:26,666 --> 00:14:29,856
nuanced theory. But following

399
00:14:29,888 --> 00:14:32,052
that, we sort of said if the world

400
00:14:32,106 --> 00:14:34,036
became truly random, something that like

401
00:14:34,058 --> 00:14:35,456
we as people, like you can't

402
00:14:35,488 --> 00:14:37,204
anthropomorphicize this too much because

403
00:14:37,242 --> 00:14:38,312
like we as people can't really

404
00:14:38,366 --> 00:14:39,604
experience something that's truly

405
00:14:39,652 --> 00:14:42,916
random, but in addition with random

406
00:14:42,948 --> 00:14:44,916
noise, you could at least approximate

407
00:14:44,948 --> 00:14:45,530
it.

408
00:14:48,140 --> 00:14:49,784
That's what we did. And so we had these

409
00:14:49,822 --> 00:14:51,048
two options. So what we then said is

410
00:14:51,054 --> 00:14:52,588
that this is true. What the cells will

411
00:14:52,594 --> 00:14:55,356
do is actually change their action to

412
00:14:55,378 --> 00:14:57,564
make it accord with the internal model

413
00:14:57,602 --> 00:14:59,032
of the world that they have to decide

414
00:14:59,096 --> 00:15:01,384
and derive from the sensory stimulation

415
00:15:01,432 --> 00:15:05,912
we feed them. So under this model here,

416
00:15:06,066 --> 00:15:07,616
that's sort of represented in this

417
00:15:07,638 --> 00:15:08,816
picture that you can see, what we

418
00:15:08,838 --> 00:15:10,816
propose is that the neural cells or the

419
00:15:10,838 --> 00:15:12,176
system will try to minimize the

420
00:15:12,198 --> 00:15:13,616
difference between the internal and the

421
00:15:13,638 --> 00:15:16,016
external world to minimize the free

422
00:15:16,038 --> 00:15:17,796
energy of the system, ie. Minimize their

423
00:15:17,818 --> 00:15:20,752
surprising. And we kind of predicted

424
00:15:20,816 --> 00:15:22,516
whether aversive is the right word or

425
00:15:22,538 --> 00:15:24,836
not. It would certainly we would say

426
00:15:24,858 --> 00:15:26,512
that nonpredictable random stimulation

427
00:15:26,576 --> 00:15:27,716
should be something that the cells would

428
00:15:27,738 --> 00:15:30,296
try to avoid. While on the flip side,

429
00:15:30,318 --> 00:15:31,716
if we gave them a predictable stimulus

430
00:15:31,748 --> 00:15:33,336
when they did something they like that

431
00:15:33,358 --> 00:15:35,416
might be reinforcing. And again,

432
00:15:35,518 --> 00:15:37,076
whether I put these words in quotes

433
00:15:37,108 --> 00:15:38,852
because there's a whole language

434
00:15:38,916 --> 00:15:40,104
question no one could have a question

435
00:15:40,142 --> 00:15:41,956
around what is it, is it truly aversive?

436
00:15:41,988 --> 00:15:43,916
Is it driving? Is it whatever? But for

437
00:15:43,938 --> 00:15:45,228
the sake of communication, we have to

438
00:15:45,234 --> 00:15:46,636
pick words right now so hopefully you

439
00:15:46,658 --> 00:15:48,808
understand the context in which they're

440
00:15:48,824 --> 00:15:51,308
used. And so what we propose then is

441
00:15:51,314 --> 00:15:52,476
that the cells should modify their

442
00:15:52,498 --> 00:15:54,636
activity to avoid adopting a state. In

443
00:15:54,658 --> 00:15:56,316
this case, that's a pattern of activity

444
00:15:56,428 --> 00:15:57,776
that would lead to an increase in

445
00:15:57,798 --> 00:16:00,496
surprise. And so what we can see here,

446
00:16:00,518 --> 00:16:02,736
we set up some experimental tests and we

447
00:16:02,758 --> 00:16:04,796
compared a number of different methods.

448
00:16:04,828 --> 00:16:06,496
So we compared this control group. This

449
00:16:06,518 --> 00:16:08,436
was simply media in a dish that had the

450
00:16:08,458 --> 00:16:11,076
stimulations and feedback applied to it.

451
00:16:11,178 --> 00:16:12,868
Media and a dish should not be able to

452
00:16:12,874 --> 00:16:14,836
learn without any cells. We had an in

453
00:16:14,858 --> 00:16:16,948
silicone model that would drive the

454
00:16:16,954 --> 00:16:18,436
pattern with random noise. And

455
00:16:18,458 --> 00:16:20,072
essentially this was to test the control

456
00:16:20,126 --> 00:16:21,576
group. You can think the media only

457
00:16:21,598 --> 00:16:23,528
control group, I should say you can

458
00:16:23,534 --> 00:16:25,928
think of it as testing. Were we able to

459
00:16:25,934 --> 00:16:27,256
get activity simply through our

460
00:16:27,278 --> 00:16:29,592
stimulation? The encilico was saying

461
00:16:29,646 --> 00:16:31,764
could we get performance simply through

462
00:16:31,822 --> 00:16:34,284
something in the system itself making

463
00:16:34,322 --> 00:16:35,884
sure that the system isn't biased in any

464
00:16:35,922 --> 00:16:38,220
obvious way. Then we had a rest control

465
00:16:38,290 --> 00:16:40,456
group where there were cells in a dish

466
00:16:40,488 --> 00:16:42,092
but no stimulation. And this was asking

467
00:16:42,146 --> 00:16:44,416
the question left alone, will the

468
00:16:44,438 --> 00:16:46,544
spontaneous activity of neurons because

469
00:16:46,582 --> 00:16:49,244
neurons always have activity regardless

470
00:16:49,292 --> 00:16:50,656
of whether you're stimulating them or

471
00:16:50,678 --> 00:16:52,064
not will that lead to better

472
00:16:52,102 --> 00:16:53,664
performance? Again, there's no reason it

473
00:16:53,702 --> 00:16:56,908
should if our system is set up properly.

474
00:16:57,004 --> 00:16:58,884
Of course, if there's a bias, it would,

475
00:16:59,002 --> 00:17:01,156
but that's what we're testing here. And

476
00:17:01,178 --> 00:17:02,692
then finally we had both mouse and human

477
00:17:02,746 --> 00:17:04,100
cells that were given the information

478
00:17:04,170 --> 00:17:06,032
where the ball was were given feedback

479
00:17:06,176 --> 00:17:08,436
and were able to play the game. And what

480
00:17:08,458 --> 00:17:12,216
you can see is basically this

481
00:17:12,238 --> 00:17:13,796
is a little hard to interpret this graph

482
00:17:13,828 --> 00:17:15,448
if you don't stare at heat maps all day.

483
00:17:15,534 --> 00:17:17,064
But if you compare, say, just the top

484
00:17:17,102 --> 00:17:19,048
right, which is the number of hips that

485
00:17:19,054 --> 00:17:21,336
are occurring in any given minute by the

486
00:17:21,358 --> 00:17:24,268
minute on the x axis, you can see that

487
00:17:24,274 --> 00:17:25,804
it doesn't really change too much over

488
00:17:25,842 --> 00:17:27,336
time for the control group. But compare

489
00:17:27,368 --> 00:17:30,028
it and obviously the encilicone, the

490
00:17:30,034 --> 00:17:31,436
resting controls are kind of the same as

491
00:17:31,458 --> 00:17:33,116
that. If you compare it to the mouse

492
00:17:33,148 --> 00:17:34,944
and, say, the human cultures you can see

493
00:17:35,062 --> 00:17:37,696
quite a clear difference here. And if

494
00:17:37,718 --> 00:17:41,164
you want more asteroids for significance

495
00:17:41,292 --> 00:17:44,288
because who doesn't love asterisks? At

496
00:17:44,294 --> 00:17:47,204
least all scientists love asterisks or

497
00:17:47,242 --> 00:17:49,348
other symbols of significance. What we

498
00:17:49,354 --> 00:17:51,892
can do is you can see over time this

499
00:17:51,946 --> 00:17:54,164
control groups, the media controlled in

500
00:17:54,202 --> 00:17:56,036
silicon controlled or rest control they

501
00:17:56,058 --> 00:17:58,008
don't show any difference over time. A

502
00:17:58,014 --> 00:18:00,184
bit of variation, but ultimately no real

503
00:18:00,222 --> 00:18:02,264
significant difference over time. In

504
00:18:02,302 --> 00:18:05,988
contrast, the mouse and the human cells

505
00:18:06,164 --> 00:18:07,816
both showed learning over time. And by

506
00:18:07,838 --> 00:18:09,784
the second time point they outperformed

507
00:18:09,912 --> 00:18:12,476
all the other cultures, all the other

508
00:18:12,498 --> 00:18:13,948
conditions. I should say.

509
00:18:14,114 --> 00:18:15,916
Interestingly, the human cells even

510
00:18:15,938 --> 00:18:18,380
ended up slightly outperforming the

511
00:18:18,450 --> 00:18:20,188
mouse cells. And although I would be

512
00:18:20,194 --> 00:18:22,284
careful not to overinterpret this it was

513
00:18:22,322 --> 00:18:24,776
interesting to note that we've run this

514
00:18:24,818 --> 00:18:26,496
experiment a number of times and this is

515
00:18:26,518 --> 00:18:29,056
a very consistent difference. And so it

516
00:18:29,078 --> 00:18:30,208
could be an interesting way to start to

517
00:18:30,214 --> 00:18:31,920
investigate differences in the future

518
00:18:31,990 --> 00:18:34,620
between species. If one wanted to set up

519
00:18:34,630 --> 00:18:37,092
a study more rigorously to actually test

520
00:18:37,146 --> 00:18:40,544
this and these results were replicated

521
00:18:40,592 --> 00:18:42,324
it wasn't like we found one measure that

522
00:18:42,362 --> 00:18:44,276
suddenly looked like performance and we

523
00:18:44,298 --> 00:18:46,532
ignored the rest. We looked at a number

524
00:18:46,586 --> 00:18:48,340
of them. Some of the other interesting

525
00:18:48,410 --> 00:18:49,848
ones are stuff like the percentage of

526
00:18:49,854 --> 00:18:51,444
long rallies where it's hit the ball

527
00:18:51,572 --> 00:18:53,464
more than three times in a row. So force

528
00:18:53,502 --> 00:18:56,888
four plus in a row and

529
00:18:56,974 --> 00:19:00,196
you can see here again significantly

530
00:19:00,388 --> 00:19:02,508
changes over the time for the mouse and

531
00:19:02,514 --> 00:19:04,252
human cells, nothing for the others.

532
00:19:04,306 --> 00:19:07,016
Likewise the aces, which is like tennis,

533
00:19:07,048 --> 00:19:08,316
where they miss the ball without even

534
00:19:08,338 --> 00:19:10,620
hitting at once. This decreases

535
00:19:11,680 --> 00:19:13,552
statistically significantly over time

536
00:19:13,606 --> 00:19:16,380
for the mouse and human cortical cells,

537
00:19:16,460 --> 00:19:19,436
not for the others. So much so that's

538
00:19:19,468 --> 00:19:21,776
interesting, but we sort of say like,

539
00:19:21,798 --> 00:19:22,896
well it's interesting, it shouldn't be

540
00:19:22,918 --> 00:19:25,004
surprising because we know that neural

541
00:19:25,052 --> 00:19:28,068
cells are adaptive and the fact you can

542
00:19:28,074 --> 00:19:31,284
see it in a dish is cool. But what

543
00:19:31,322 --> 00:19:32,724
are the implications? What can this

544
00:19:32,762 --> 00:19:34,800
actually teach us about how these cells

545
00:19:34,880 --> 00:19:37,092
are behaving? And one of the things

546
00:19:37,146 --> 00:19:38,904
people have looked at in detail

547
00:19:39,022 --> 00:19:42,292
previously is functional plasticity.

548
00:19:42,356 --> 00:19:43,784
So what we looked at here is, of course

549
00:19:43,822 --> 00:19:45,736
we also assessed functional activity and

550
00:19:45,758 --> 00:19:47,608
saw that there was a massive difference

551
00:19:47,694 --> 00:19:50,376
between the resting state functional

552
00:19:50,408 --> 00:19:52,648
plasticity and the gameplay functional

553
00:19:52,664 --> 00:19:56,396
plasticity. But what does

554
00:19:56,418 --> 00:19:57,356
that actually mean? What does that

555
00:19:57,378 --> 00:19:58,604
actually look like, going beyond just

556
00:19:58,642 --> 00:19:59,832
the fact that there's plasticity

557
00:19:59,896 --> 00:20:02,188
occurring in the culture. So what you

558
00:20:02,194 --> 00:20:03,696
can do is you can look here at just the

559
00:20:03,718 --> 00:20:06,544
correlation and the activity between the

560
00:20:06,582 --> 00:20:08,508
cells in the motor regions that I've

561
00:20:08,524 --> 00:20:09,964
shown you before and the sensory

562
00:20:10,012 --> 00:20:12,908
regions. And it's not too surprising

563
00:20:13,004 --> 00:20:15,456
that whether or not they're playing the

564
00:20:15,478 --> 00:20:17,696
game, you have quite a high degree of

565
00:20:17,718 --> 00:20:19,072
correlation. In fact, the correlations

566
00:20:19,136 --> 00:20:21,268
at Rest are slightly stronger than the

567
00:20:21,274 --> 00:20:24,052
correlations at gameplay. But what is

568
00:20:24,106 --> 00:20:25,972
interesting actually is if you take the

569
00:20:26,026 --> 00:20:29,416
average correlation, not just what is

570
00:20:29,438 --> 00:20:30,616
the overall correlation, but you

571
00:20:30,638 --> 00:20:31,604
actually break down the average

572
00:20:31,652 --> 00:20:35,236
correlation per culture and session.

573
00:20:35,348 --> 00:20:36,792
What you do is you actually get a far

574
00:20:36,846 --> 00:20:40,424
higher average correlation between the

575
00:20:40,462 --> 00:20:43,128
sensory and motor regions when they're

576
00:20:43,144 --> 00:20:45,036
playing the game than when they're at

577
00:20:45,058 --> 00:20:47,228
risk. This makes sense if you need to

578
00:20:47,234 --> 00:20:48,616
coordinate your action with incoming

579
00:20:48,648 --> 00:20:50,696
stimulation, you need to have a degree

580
00:20:50,728 --> 00:20:52,296
of correlation between where you receive

581
00:20:52,328 --> 00:20:54,752
that action and the activity there and

582
00:20:54,806 --> 00:20:56,704
where at your activity outputs going

583
00:20:56,742 --> 00:21:00,368
out. But conversely, if you have in

584
00:21:00,374 --> 00:21:01,968
this case, basically you can think of it

585
00:21:01,974 --> 00:21:03,168
as two buttons even though they're

586
00:21:03,174 --> 00:21:05,456
spread over four regions, what you would

587
00:21:05,478 --> 00:21:06,784
actually need to have is a negative

588
00:21:06,832 --> 00:21:09,184
correlation or a reduced correlation

589
00:21:09,232 --> 00:21:11,796
between these regions. And if you look

590
00:21:11,818 --> 00:21:13,456
at the percentage of exclusive motor

591
00:21:13,488 --> 00:21:15,556
region activity in this graph, which is

592
00:21:15,578 --> 00:21:17,156
where you have activity in either the up

593
00:21:17,178 --> 00:21:18,584
or the down region and bear in mind,

594
00:21:18,622 --> 00:21:20,344
again, these are counterbalanced. So

595
00:21:20,382 --> 00:21:21,592
this result is actually pretty

596
00:21:21,646 --> 00:21:24,920
interesting to see. What you see here

597
00:21:24,990 --> 00:21:26,904
is that during Rest versus gameplay you

598
00:21:26,942 --> 00:21:28,890
actually have a higher degree of

599
00:21:29,340 --> 00:21:32,376
exclusive motor region activity, which

600
00:21:32,398 --> 00:21:33,756
would of course be necessary for

601
00:21:33,778 --> 00:21:35,448
discrete control in one direction versus

602
00:21:35,464 --> 00:21:37,116
the other. And this was quite an

603
00:21:37,138 --> 00:21:39,212
exciting result because it was really

604
00:21:39,266 --> 00:21:40,524
supportive sort of that there is

605
00:21:40,562 --> 00:21:42,688
something quite dynamics and interesting

606
00:21:42,774 --> 00:21:45,356
going on in the way that these cultures

607
00:21:45,388 --> 00:21:47,040
are reorganizing their activity. And

608
00:21:47,110 --> 00:21:48,896
likewise, this actually just shows the

609
00:21:48,918 --> 00:21:50,652
degree that this correlation decreases

610
00:21:50,716 --> 00:21:54,156
over time with two linear regressions

611
00:21:54,188 --> 00:21:55,616
and you get two very different linear

612
00:21:55,648 --> 00:21:58,276
regressions over the first 5 minutes and

613
00:21:58,298 --> 00:22:00,884
the last 15. And we arbitrarily, just

614
00:22:00,922 --> 00:22:04,036
based on some early work, decided to and

615
00:22:04,058 --> 00:22:05,636
again, not super arbitrarily, but based

616
00:22:05,658 --> 00:22:07,924
on some early work, I should say, we

617
00:22:08,042 --> 00:22:09,556
decided to sort of split the games up

618
00:22:09,578 --> 00:22:11,336
into the first and stabilize. And so

619
00:22:11,358 --> 00:22:12,676
that was quite supportive to suggest

620
00:22:12,708 --> 00:22:14,280
that what we're seeing here is really

621
00:22:14,430 --> 00:22:16,490
the tapping in of some of the key

622
00:22:17,100 --> 00:22:19,636
adaptive properties of the neural

623
00:22:19,668 --> 00:22:24,972
cultures and to take it further focus

624
00:22:25,026 --> 00:22:26,648
on the sort of free energy implications

625
00:22:26,744 --> 00:22:30,616
here we can of course reframe surprise

626
00:22:30,728 --> 00:22:33,100
it has a link with information entropy.

627
00:22:34,480 --> 00:22:36,844
And as for those of you familiar, this

628
00:22:36,882 --> 00:22:38,672
is of course to catch it as a kale just

629
00:22:38,806 --> 00:22:41,116
divergence between the two distributions

630
00:22:41,308 --> 00:22:43,936
of what might be occurring. And so we

631
00:22:43,958 --> 00:22:45,340
wanted to actually calculate here the

632
00:22:45,350 --> 00:22:47,172
information entropy of the actual

633
00:22:47,226 --> 00:22:48,608
cultures. And now it's important to note

634
00:22:48,624 --> 00:22:51,300
here this is entorhinal to the cultures

635
00:22:51,960 --> 00:22:54,596
both at gameplay and at rest. And if we

636
00:22:54,618 --> 00:22:56,356
didn't normalize it, there's quite a lot

637
00:22:56,378 --> 00:22:58,440
of variation going on in any given

638
00:22:58,510 --> 00:23:00,308
culture. But it becomes much clearer

639
00:23:00,324 --> 00:23:03,240
once you do normalize it simply to

640
00:23:03,310 --> 00:23:05,704
baselines. And you can see here that

641
00:23:05,742 --> 00:23:07,956
when you give them random feedback so

642
00:23:07,998 --> 00:23:10,732
one thing I'll say firstly is that the

643
00:23:10,866 --> 00:23:13,452
gameplay normally actually has much

644
00:23:13,506 --> 00:23:15,196
lower information entropy than when

645
00:23:15,218 --> 00:23:18,236
they're at rest. Two, when you give them

646
00:23:18,258 --> 00:23:20,616
random feedback, their information

647
00:23:20,738 --> 00:23:24,124
entropy increases massively, thereby

648
00:23:24,172 --> 00:23:26,652
suggesting that these cells indeed

649
00:23:26,716 --> 00:23:29,372
should be under the French principle

650
00:23:29,436 --> 00:23:31,410
should be predisposed to avoid this.

651
00:23:32,500 --> 00:23:34,560
And that's actually what we saw. But

652
00:23:34,630 --> 00:23:36,144
what we're interested in is to say well,

653
00:23:36,182 --> 00:23:38,036
what if we tried different types of

654
00:23:38,058 --> 00:23:39,796
feedback? Like how do we know this is

655
00:23:39,818 --> 00:23:41,796
all well and good, but how do we know

656
00:23:41,818 --> 00:23:43,332
that this type of feedback is actually

657
00:23:43,386 --> 00:23:46,128
what's leading to these results?

658
00:23:46,144 --> 00:23:49,140
Because it could be anything. And so we

659
00:23:49,210 --> 00:23:50,756
set out and we introduced a few other

660
00:23:50,778 --> 00:23:52,776
control conditions. So this is our

661
00:23:52,798 --> 00:23:53,896
regular one that I've sort of was

662
00:23:53,918 --> 00:23:55,336
showing you before if it was a bit

663
00:23:55,358 --> 00:23:56,664
unclear, hopefully this helps to clear

664
00:23:56,702 --> 00:23:58,792
it up a bit. When they played the game,

665
00:23:58,846 --> 00:24:00,356
they missed the ball, they get random,

666
00:24:00,388 --> 00:24:02,156
unpredictable sensory feedback. When

667
00:24:02,178 --> 00:24:03,704
they hit the ball, they get predictable.

668
00:24:03,832 --> 00:24:05,308
We then added something we called the

669
00:24:05,314 --> 00:24:07,436
silent condition, which is when they

670
00:24:07,458 --> 00:24:09,644
missed a ball, they basically had all

671
00:24:09,682 --> 00:24:12,588
their feedback removed. And yet when

672
00:24:12,594 --> 00:24:14,008
they hit the ball, nothing. They didn't

673
00:24:14,024 --> 00:24:15,208
get any additional feedback. The game

674
00:24:15,234 --> 00:24:17,376
just continued. Now, it is important to

675
00:24:17,398 --> 00:24:18,704
note, of course, that when the game

676
00:24:18,742 --> 00:24:20,716
restarts, after a missed, the direction

677
00:24:20,748 --> 00:24:22,592
of the ball is random. So there is still

678
00:24:22,646 --> 00:24:25,636
some randomness in this game,

679
00:24:25,818 --> 00:24:29,012
but presumably less so than in the

680
00:24:29,066 --> 00:24:31,348
normal stem condition. And this can be

681
00:24:31,354 --> 00:24:33,444
contrasted with this open loop or no

682
00:24:33,482 --> 00:24:36,884
feedback condition. There are synonyms

683
00:24:36,932 --> 00:24:39,160
in this case, basically, where the game

684
00:24:39,230 --> 00:24:41,096
is played, information about where the

685
00:24:41,118 --> 00:24:45,380
ball is is presented to the cells

686
00:24:45,460 --> 00:24:47,188
or the system cells or controls,

687
00:24:47,204 --> 00:24:48,410
whatever the case is.

688
00:24:51,340 --> 00:24:52,936
But if they miss, they don't get

689
00:24:52,958 --> 00:24:54,236
anything changed. If they hit, they

690
00:24:54,258 --> 00:24:55,436
don't get anything changed. And so

691
00:24:55,458 --> 00:24:56,636
really it's asking a question like will

692
00:24:56,658 --> 00:24:58,936
culture just play the game for the sake

693
00:24:58,968 --> 00:25:00,700
of playing the game? There's no reason

694
00:25:00,770 --> 00:25:03,468
it should, but maybe they do. So we

695
00:25:03,474 --> 00:25:04,672
wanted to test that. And then the final

696
00:25:04,726 --> 00:25:06,464
condition we included here, of course,

697
00:25:06,502 --> 00:25:09,276
is a rest condition. And if this helps

698
00:25:09,308 --> 00:25:10,496
to make it clear, if you're more

699
00:25:10,518 --> 00:25:12,736
graphical, this can give you an example.

700
00:25:12,838 --> 00:25:14,832
So here you can see the ball going up,

701
00:25:14,886 --> 00:25:16,496
it hits it, and then you've got like a

702
00:25:16,518 --> 00:25:17,936
predictable stimulation here. The ball

703
00:25:17,968 --> 00:25:19,876
goes, it continues and it gets hit again

704
00:25:19,978 --> 00:25:21,664
and then it misses and it gets a random

705
00:25:21,712 --> 00:25:23,712
feedback. And then the game continuum

706
00:25:23,856 --> 00:25:25,844
silent. In contrast, you can see that

707
00:25:25,882 --> 00:25:27,728
this random feedback here at the same

708
00:25:27,754 --> 00:25:29,876
time point is removed for the silent

709
00:25:29,908 --> 00:25:31,336
condition. Likewise, there's no

710
00:25:31,358 --> 00:25:32,856
predictable stimulation across the

711
00:25:32,878 --> 00:25:34,804
culture and then there's no feedback.

712
00:25:34,852 --> 00:25:36,728
It's just the ball becomes completely

713
00:25:36,814 --> 00:25:38,836
predictable from the very first serve.

714
00:25:38,868 --> 00:25:41,116
There is no unpredictability in it at

715
00:25:41,138 --> 00:25:44,600
all. And so when we look at the results

716
00:25:44,680 --> 00:25:47,128
here, and obviously, if you're

717
00:25:47,144 --> 00:25:48,460
interested, you can go look at the paper

718
00:25:48,530 --> 00:25:50,652
because we dive into this in similar

719
00:25:50,706 --> 00:25:53,256
detail as before. But just in brief,

720
00:25:53,288 --> 00:25:54,656
what I'll show you is that here, what

721
00:25:54,678 --> 00:25:56,064
we've done is just compared it to rest

722
00:25:56,102 --> 00:25:57,452
because it helps control the variability

723
00:25:57,516 --> 00:25:59,728
a little bit and it makes it look a

724
00:25:59,734 --> 00:26:03,552
little neater. But essentially, the

725
00:26:03,606 --> 00:26:05,132
stimulus condition, they outperform

726
00:26:05,196 --> 00:26:07,108
rest, they outperform their starting

727
00:26:07,194 --> 00:26:09,636
position. Over time, it replicates what

728
00:26:09,658 --> 00:26:12,004
we saw in the first study. And the

729
00:26:12,042 --> 00:26:14,336
silent one, there is a very slight

730
00:26:14,368 --> 00:26:15,872
increase. It doesn't reach statistical

731
00:26:15,936 --> 00:26:18,788
significance, but they do end up also

732
00:26:18,874 --> 00:26:20,776
statistically slightly better than a no

733
00:26:20,798 --> 00:26:22,056
feedback condition, which shows pretty

734
00:26:22,078 --> 00:26:24,136
much no learning compared to rest at

735
00:26:24,158 --> 00:26:26,936
all. So that matches up pretty much with

736
00:26:26,958 --> 00:26:29,864
what we expect to see around the free

737
00:26:29,902 --> 00:26:31,948
free energy principle condition that

738
00:26:31,954 --> 00:26:33,832
gets a small amount of randomness,

739
00:26:33,976 --> 00:26:36,028
shows a small amount of learning, if you

740
00:26:36,034 --> 00:26:38,190
want to do that, but not a MOT.

741
00:26:39,040 --> 00:26:40,424
Something that gets a lot of random

742
00:26:40,472 --> 00:26:42,788
information as a result of an action

743
00:26:42,824 --> 00:26:45,536
that we deem undesirable, shows a

744
00:26:45,558 --> 00:26:47,276
greater tendency to avoid that action.

745
00:26:47,388 --> 00:26:49,424
And something that has no incentive to

746
00:26:49,542 --> 00:26:51,068
behave in a particular way, doesn't

747
00:26:51,084 --> 00:26:53,744
behave in a particular way. But what was

748
00:26:53,782 --> 00:26:55,520
really interesting and exciting for us

749
00:26:55,590 --> 00:26:57,468
also, although I'll be honest, it made

750
00:26:57,494 --> 00:26:58,836
us stop for a few minutes to actually

751
00:26:58,858 --> 00:27:00,756
think about why this chaos happened was.

752
00:27:00,778 --> 00:27:02,432
That when you look at this normalized

753
00:27:02,496 --> 00:27:04,228
information entropy, again, we got a

754
00:27:04,234 --> 00:27:06,008
replication that when you gave them

755
00:27:06,014 --> 00:27:10,324
random feedback, the actual internal

756
00:27:10,372 --> 00:27:12,456
information entropy goes up. With the

757
00:27:12,478 --> 00:27:14,120
silent condition, the information

758
00:27:14,190 --> 00:27:16,856
entropy also went up, in fact, even more

759
00:27:16,878 --> 00:27:18,936
so. And we went, why would this be the

760
00:27:18,958 --> 00:27:21,464
case? And of course, what we realized

761
00:27:21,512 --> 00:27:24,364
quite quickly was, well, neurons left

762
00:27:24,402 --> 00:27:26,428
alone do fire spontaneously. And when

763
00:27:26,434 --> 00:27:28,504
you take a neuron from a stimulated

764
00:27:28,552 --> 00:27:30,184
condition to an unstimulated condition,

765
00:27:30,232 --> 00:27:32,396
they do tend to re engage with the

766
00:27:32,418 --> 00:27:33,836
random spontaneous activity quite

767
00:27:33,858 --> 00:27:37,010
vigorously straight away. And yet

768
00:27:37,460 --> 00:27:39,296
it didn't show the same degree of

769
00:27:39,318 --> 00:27:41,776
learning. So of course, like I will say,

770
00:27:41,798 --> 00:27:43,136
this is one finding that absolutely

771
00:27:43,238 --> 00:27:44,528
needs to be followed up more in the

772
00:27:44,534 --> 00:27:46,656
future and we are doing that. But it

773
00:27:46,678 --> 00:27:48,436
does have an interesting implication in

774
00:27:48,458 --> 00:27:51,060
terms of Markov blankets. So I mentioned

775
00:27:51,130 --> 00:27:52,516
this before, I flagged it before and

776
00:27:52,538 --> 00:27:53,748
this is why. Because I think this is one

777
00:27:53,754 --> 00:27:56,436
of the really interesting results. So to

778
00:27:56,458 --> 00:27:57,820
go Hinton more detail, what a Markov

779
00:27:57,840 --> 00:28:00,404
blanket is, is it's a statistical

780
00:28:00,452 --> 00:28:02,296
boundary that can distinguish an

781
00:28:02,318 --> 00:28:04,696
internal state from an external state.

782
00:28:04,798 --> 00:28:06,936
And this can be at any level. So it

783
00:28:06,958 --> 00:28:08,888
could be at an individual neuron, a

784
00:28:08,894 --> 00:28:12,488
cluster of neurons, nuclear distinct

785
00:28:12,504 --> 00:28:13,676
functional regions of the brain, the

786
00:28:13,698 --> 00:28:16,316
whole brain, the body, in correlation to

787
00:28:16,338 --> 00:28:17,580
the rest of the world or what's outside

788
00:28:17,650 --> 00:28:20,896
it. And so the fact that, as I

789
00:28:20,918 --> 00:28:22,428
was saying, that we see that the silent

790
00:28:22,444 --> 00:28:27,164
condition even shows more randomness

791
00:28:27,212 --> 00:28:29,548
or information entropy than when we're

792
00:28:29,564 --> 00:28:31,804
actually providing external random

793
00:28:31,852 --> 00:28:34,788
information into the system is actually

794
00:28:34,874 --> 00:28:36,916
very consistent with what we know about

795
00:28:36,938 --> 00:28:39,024
the stochasticity of spontaneous

796
00:28:39,072 --> 00:28:41,568
activity. But what it does also suggest

797
00:28:41,664 --> 00:28:43,392
is that cells will respond differently

798
00:28:43,456 --> 00:28:45,984
to randomness inside a system versus

799
00:28:46,032 --> 00:28:49,112
outside a system. And that was a really

800
00:28:49,166 --> 00:28:51,720
exciting result to sort of find allostat

801
00:28:51,790 --> 00:28:53,976
physical evidence that perhaps this

802
00:28:53,998 --> 00:28:56,056
Markov blanket really exists. Of course

803
00:28:56,158 --> 00:28:58,004
it makes sense. It exists theoretically.

804
00:28:58,052 --> 00:28:59,724
There's a lot of reasons, even just the

805
00:28:59,762 --> 00:29:01,384
simplest notion that we can separate

806
00:29:01,432 --> 00:29:02,956
what our internal thoughts are from

807
00:29:02,978 --> 00:29:04,540
someone's external thoughts,

808
00:29:06,640 --> 00:29:08,876
someone's external voice to us, I should

809
00:29:08,898 --> 00:29:11,216
say, suggests that we need to have some

810
00:29:11,238 --> 00:29:12,544
sort of barrier to distinguish these

811
00:29:12,582 --> 00:29:16,304
types of structured information, one

812
00:29:16,342 --> 00:29:19,200
internally, one external. But seeing it

813
00:29:19,270 --> 00:29:23,424
was very interesting. And so we

814
00:29:23,462 --> 00:29:25,372
also wanted to, of course, extend beyond

815
00:29:25,436 --> 00:29:27,340
this and sort of not just stop here and

816
00:29:27,350 --> 00:29:28,484
look at what other interesting things

817
00:29:28,522 --> 00:29:30,404
might be happening. And one of the other

818
00:29:30,442 --> 00:29:32,304
interesting findings that we've recently

819
00:29:32,352 --> 00:29:33,668
completed, and there's a preprint of

820
00:29:33,674 --> 00:29:35,816
this up now, is this idea of

821
00:29:35,838 --> 00:29:38,136
neurocriticality. And so what is

822
00:29:38,158 --> 00:29:39,944
criticality for those who aren't very

823
00:29:39,982 --> 00:29:43,400
familiar with it, in brief, it is this

824
00:29:43,550 --> 00:29:45,944
state where a population's activity is

825
00:29:45,982 --> 00:29:49,064
coordinated basically between two other

826
00:29:49,102 --> 00:29:51,816
states. So physically you could think of

827
00:29:51,838 --> 00:29:53,852
it at that point between where water

828
00:29:53,906 --> 00:29:55,356
becomes ice and as a point just in

829
00:29:55,378 --> 00:29:57,276
between, which is a transition to bring

830
00:29:57,298 --> 00:29:59,356
it back to the brain you can think of it

831
00:29:59,378 --> 00:30:01,776
as a brain. That firing rate could be

832
00:30:01,798 --> 00:30:04,396
either highly coordinated, rhythmic

833
00:30:04,428 --> 00:30:06,704
oscillatory, much as, like, when we

834
00:30:06,742 --> 00:30:10,096
sleep, or in catatonia, or it could be

835
00:30:10,118 --> 00:30:11,744
completely disorganized, like in some

836
00:30:11,782 --> 00:30:14,124
cases of epilepsy. And that then there's

837
00:30:14,172 --> 00:30:15,680
a middle ground, and there's obviously

838
00:30:15,750 --> 00:30:18,388
quite a spectrum, so there's quite a lot

839
00:30:18,394 --> 00:30:20,244
of middle ground. But the closer you get

840
00:30:20,282 --> 00:30:22,064
to this sort of critical transition

841
00:30:22,112 --> 00:30:23,956
point this is called criticality, and

842
00:30:24,058 --> 00:30:26,004
theoretically, it's been proposed to

843
00:30:26,122 --> 00:30:29,076
maximize give me there's my time ant

844
00:30:29,098 --> 00:30:31,728
telling me to take a break. It's

845
00:30:31,744 --> 00:30:33,432
theoretically, it's been proposed to act

846
00:30:33,486 --> 00:30:36,980
as a key criteria to maximize

847
00:30:37,060 --> 00:30:38,852
information transmission and capacity.

848
00:30:38,916 --> 00:30:40,748
And what's also really interesting is

849
00:30:40,754 --> 00:30:41,948
that it's been linked to a number of

850
00:30:41,954 --> 00:30:43,688
different cognitive behavior, although

851
00:30:43,784 --> 00:30:45,820
the field is certainly a bit unclear

852
00:30:46,240 --> 00:30:49,448
about what that is. So it's

853
00:30:49,464 --> 00:30:51,164
Beren linked, for example, to responses

854
00:30:51,212 --> 00:30:53,280
to drugs, working memory, attention.

855
00:30:53,700 --> 00:30:55,676
One of my particular favorites is cores

856
00:30:55,708 --> 00:30:57,040
of fluid intelligence.

857
00:30:58,420 --> 00:31:01,436
But these studies have some concerns

858
00:31:01,468 --> 00:31:03,316
with how they investigate it. And

859
00:31:03,338 --> 00:31:04,768
ultimately, one of the biggest concerns

860
00:31:04,784 --> 00:31:07,588
is that they're doing these ones. At

861
00:31:07,594 --> 00:31:10,548
least in humans, we have lots of

862
00:31:10,554 --> 00:31:13,796
compensatory mechanisms. You have to use

863
00:31:13,978 --> 00:31:17,376
fMRI or mostly fMRI measures

864
00:31:17,408 --> 00:31:19,368
to actually investigate it. So there's a

865
00:31:19,374 --> 00:31:21,076
lot of barriers in actually concluding

866
00:31:21,108 --> 00:31:23,832
this. So we set up a study to actually

867
00:31:23,886 --> 00:31:25,972
investigate this. And essentially,

868
00:31:26,116 --> 00:31:27,592
again, to not go into too much detail

869
00:31:27,646 --> 00:31:30,008
about the nuances, we looked at three

870
00:31:30,094 --> 00:31:32,328
key different metrics. There's been a

871
00:31:32,334 --> 00:31:33,564
bit of criticism in the field where

872
00:31:33,602 --> 00:31:35,164
people focus predominantly on power

873
00:31:35,202 --> 00:31:37,384
laws. Power laws can arise from noise

874
00:31:37,432 --> 00:31:38,924
alone. So we wanted to avoid that

875
00:31:38,962 --> 00:31:40,492
shortfall and look at three different

876
00:31:40,546 --> 00:31:43,756
measures. And so this is sort of the set

877
00:31:43,778 --> 00:31:45,244
up we had. We took them, we compared

878
00:31:45,292 --> 00:31:47,744
them either playing the game or at rest,

879
00:31:47,862 --> 00:31:49,568
which I described to you before. And

880
00:31:49,574 --> 00:31:50,736
then we looked at these things called

881
00:31:50,758 --> 00:31:53,908
the DCC, the branching ratio or the

882
00:31:53,914 --> 00:31:55,716
shape collapse error. And we wanted to

883
00:31:55,738 --> 00:31:57,590
see how we could group them.

884
00:32:00,680 --> 00:32:03,780
Sorry, my slides have frozen.

885
00:32:10,380 --> 00:32:13,128
Let me try to jump to the next one. All

886
00:32:13,134 --> 00:32:15,336
righty, so hopefully that's back for

887
00:32:15,358 --> 00:32:19,388
everyone. Now, let me just there we go.

888
00:32:19,554 --> 00:32:22,860
Okay, so what we saw here really

889
00:32:22,930 --> 00:32:24,744
surprisingly, was a very stark

890
00:32:24,792 --> 00:32:28,332
difference in criticality across

891
00:32:28,386 --> 00:32:29,676
a number of measures. So you can just

892
00:32:29,698 --> 00:32:31,576
see here, basically, the prediction

893
00:32:31,608 --> 00:32:34,248
between the Rest and the Active is quite

894
00:32:34,354 --> 00:32:36,384
just noticeably by eye, very different.

895
00:32:36,422 --> 00:32:37,980
And of course, that's statistically

896
00:32:38,140 --> 00:32:40,848
significant. Diving into more detail,

897
00:32:40,934 --> 00:32:42,000
we could look at these different

898
00:32:42,070 --> 00:32:43,732
measures. And this is just some quick

899
00:32:43,866 --> 00:32:45,044
overview of what those different

900
00:32:45,082 --> 00:32:48,928
measures look like. So the DCC,

901
00:32:49,024 --> 00:32:50,644
the branching ratio. So, for example,

902
00:32:50,682 --> 00:32:53,072
with branching ratio, critical systems

903
00:32:53,136 --> 00:32:56,928
sort of maintained the number of threads

904
00:32:56,944 --> 00:32:58,676
of activity that might happen. In a sub

905
00:32:58,698 --> 00:33:01,876
critical system, that variation will die

906
00:33:01,908 --> 00:33:03,444
off over time. In a supercritical

907
00:33:03,492 --> 00:33:05,204
system, it's going to continue to expand

908
00:33:05,252 --> 00:33:08,088
up into a point, and then there's a

909
00:33:08,094 --> 00:33:09,736
shape collapse error, of course, which

910
00:33:09,758 --> 00:33:12,280
is looking to see how you can collapse

911
00:33:12,440 --> 00:33:14,636
different avalanche shapes across a

912
00:33:14,658 --> 00:33:16,972
given spectrum. And then looking across

913
00:33:17,026 --> 00:33:18,332
all of these, we get quite strong

914
00:33:18,386 --> 00:33:20,044
statistical differences, showing quite

915
00:33:20,082 --> 00:33:22,220
clearly that when you have the system

916
00:33:22,290 --> 00:33:24,156
embodied in an environment, it's showing

917
00:33:24,188 --> 00:33:26,416
this measure of criticality, which is

918
00:33:26,438 --> 00:33:29,088
very interesting. And one of the

919
00:33:29,094 --> 00:33:30,400
interesting things for this, actually,

920
00:33:30,470 --> 00:33:32,492
is that it shows that this criticality

921
00:33:32,556 --> 00:33:34,704
is very fundamental and that information

922
00:33:34,822 --> 00:33:37,696
input seems to drive it very strongly.

923
00:33:37,808 --> 00:33:39,316
And to us, this does seem like a

924
00:33:39,338 --> 00:33:40,868
challenge, suggesting that it is in

925
00:33:40,874 --> 00:33:42,916
itself inherently a marker of some sort

926
00:33:42,938 --> 00:33:45,990
of higher order system.

927
00:33:47,000 --> 00:33:48,676
But of course, I think the most

928
00:33:48,698 --> 00:33:50,552
interesting thing is simply that we can

929
00:33:50,606 --> 00:33:52,696
identify this and then what it does is

930
00:33:52,718 --> 00:33:54,036
open up the possibility to further

931
00:33:54,068 --> 00:33:55,988
investigate it with more nuanced tests

932
00:33:56,084 --> 00:33:57,768
that were explicitly designed to

933
00:33:57,774 --> 00:34:00,716
investigate criticality. But what was

934
00:34:00,738 --> 00:34:02,684
nice also to see like, I guess, some

935
00:34:02,722 --> 00:34:04,716
suggestion that it does have a role in

936
00:34:04,818 --> 00:34:07,756
some sort of information processing in

937
00:34:07,778 --> 00:34:11,424
some degree, is the fact that he is also

938
00:34:11,462 --> 00:34:13,872
just showing you these results in a

939
00:34:14,006 --> 00:34:16,096
slightly different measure. But looking

940
00:34:16,118 --> 00:34:17,856
at the correlation, there were some

941
00:34:17,958 --> 00:34:19,580
statistically significant correlations

942
00:34:19,660 --> 00:34:20,816
between the different measures of

943
00:34:20,838 --> 00:34:23,916
criticality and the gameplay

944
00:34:23,948 --> 00:34:25,616
performance, showing that cultures that

945
00:34:25,638 --> 00:34:27,212
showed higher degrees of criticality

946
00:34:27,276 --> 00:34:29,940
across all three markers also had better

947
00:34:30,010 --> 00:34:31,776
gameplay performance in this hitmiss

948
00:34:31,808 --> 00:34:32,916
ratio, where they hit the ball more

949
00:34:32,938 --> 00:34:34,564
often than they missed it. Which was,

950
00:34:34,602 --> 00:34:35,864
of course, interesting to see. And does

951
00:34:35,902 --> 00:34:39,096
suggest that although we

952
00:34:39,118 --> 00:34:40,984
think that because this is arising in

953
00:34:41,022 --> 00:34:43,832
such a simple system, with such simple

954
00:34:43,886 --> 00:34:46,200
input, that it's unlikely to represent,

955
00:34:47,980 --> 00:34:51,816
or at least in of itself be a criteria

956
00:34:51,848 --> 00:34:54,124
for intelligence per se, that there

957
00:34:54,162 --> 00:34:55,870
certainly is some link between

958
00:34:56,320 --> 00:34:58,264
processing information and criticality.

959
00:34:58,312 --> 00:34:59,416
And if you want a more nuanced

960
00:34:59,448 --> 00:35:02,668
discussion of this, please feel free.

961
00:35:02,754 --> 00:35:03,996
There's a preprint up now, all the

962
00:35:04,018 --> 00:35:06,096
papers going through peer review. We

963
00:35:06,118 --> 00:35:08,624
discuss it in more detail there. And

964
00:35:08,662 --> 00:35:10,256
finally, what I would say, though, is

965
00:35:10,278 --> 00:35:12,352
that just to sort of really hammer home

966
00:35:12,406 --> 00:35:14,160
the point that this is a very

967
00:35:14,310 --> 00:35:16,880
fundamental property of these cultures

968
00:35:16,960 --> 00:35:19,092
and that it is so drastically different

969
00:35:19,146 --> 00:35:20,464
when they're playing the game, versus

970
00:35:20,512 --> 00:35:22,704
rest. That when we wanted to classify

971
00:35:22,752 --> 00:35:24,848
ourselves based on criticality metrics

972
00:35:24,864 --> 00:35:26,836
and performance as either playing the

973
00:35:26,858 --> 00:35:29,096
game or Rest. We were able to do this

974
00:35:29,118 --> 00:35:32,504
with a 98% success rate. If you took

975
00:35:32,542 --> 00:35:34,344
Hinton performance, and even if you just

976
00:35:34,382 --> 00:35:35,816
ignored performance and you just looked

977
00:35:35,838 --> 00:35:38,004
at criticality with random forest,

978
00:35:38,052 --> 00:35:40,668
we're able to do this with a 92% success

979
00:35:40,754 --> 00:35:42,168
rate of characterizing, whether they're

980
00:35:42,184 --> 00:35:43,592
playing the game or at Rest. And that's

981
00:35:43,656 --> 00:35:45,884
that's obviously suggested this is very

982
00:35:45,922 --> 00:35:47,208
fundamental, that once there's

983
00:35:47,224 --> 00:35:49,180
information input in these cells,

984
00:35:50,560 --> 00:35:52,076
they drastically reorganize their

985
00:35:52,098 --> 00:35:54,110
activity. And that's really interesting.

986
00:35:54,560 --> 00:35:55,856
Of course, one of the questions that we

987
00:35:55,878 --> 00:35:57,408
also get asked a lot when we sort of put

988
00:35:57,414 --> 00:35:58,784
out this early work was a lot of people

989
00:35:58,822 --> 00:36:01,456
would say, oh, but who cares? We

990
00:36:01,478 --> 00:36:04,000
literally had someone write a comment.

991
00:36:05,140 --> 00:36:07,010
One of the peer reviewers, not in the

992
00:36:07,400 --> 00:36:09,668
actually at one of the points said to us

993
00:36:09,834 --> 00:36:12,900
but this can't actually do anything

994
00:36:12,970 --> 00:36:15,236
better than reinforcement learning. So

995
00:36:15,258 --> 00:36:17,124
how can you conclude anything about

996
00:36:17,162 --> 00:36:18,996
biology? Which was a surprising comment

997
00:36:19,028 --> 00:36:23,304
to get, but what we

998
00:36:23,342 --> 00:36:25,176
wanted to do and said fair enough. Like

999
00:36:25,278 --> 00:36:26,376
we think there's plenty you can learn

1000
00:36:26,398 --> 00:36:28,024
about biology, whether or not it does

1001
00:36:28,062 --> 00:36:29,364
better or worse in reinforcement

1002
00:36:29,412 --> 00:36:31,004
learning. But it's a fair question.

1003
00:36:31,042 --> 00:36:33,228
Like does this do performance wise? Can

1004
00:36:33,234 --> 00:36:34,428
it do anything interesting compared to

1005
00:36:34,434 --> 00:36:36,284
reinforcement learning? We know that if

1006
00:36:36,322 --> 00:36:38,332
you run reinforcement learning enough,

1007
00:36:38,466 --> 00:36:40,556
you will get superhuman affordance with

1008
00:36:40,578 --> 00:36:41,996
the game of Pong. They will solve it.

1009
00:36:42,018 --> 00:36:43,648
They'll be humans, that's fine. They can

1010
00:36:43,654 --> 00:36:46,604
do the same with protein foldings chest

1011
00:36:46,652 --> 00:36:49,504
go. That's all well and good, but that

1012
00:36:49,542 --> 00:36:51,936
does that mean that there is no room for

1013
00:36:51,958 --> 00:36:54,336
a biological system when it comes to

1014
00:36:54,358 --> 00:36:56,324
this? So what we wanted to do was

1015
00:36:56,362 --> 00:36:57,776
actually compare it for sample

1016
00:36:57,808 --> 00:36:59,444
efficiency because that is of course

1017
00:36:59,482 --> 00:37:01,156
something that reinforcement learning

1018
00:37:01,338 --> 00:37:03,636
struggles with greatly. So what we did

1019
00:37:03,658 --> 00:37:05,376
was we compared three different deep

1020
00:37:05,408 --> 00:37:08,780
learning algorithms, DQN, ATC and PPO

1021
00:37:08,960 --> 00:37:10,248
with three different types of

1022
00:37:10,254 --> 00:37:12,376
information input and against our

1023
00:37:12,398 --> 00:37:14,024
biological cultures to see how they

1024
00:37:14,062 --> 00:37:16,264
performed. And so, just showing you here

1025
00:37:16,302 --> 00:37:17,876
some results where we took the image

1026
00:37:17,908 --> 00:37:20,056
vector, which had a CNN to run and

1027
00:37:20,078 --> 00:37:22,008
process it and then feed it into the

1028
00:37:22,174 --> 00:37:24,956
DPRL algorithms. What we were able to

1029
00:37:24,978 --> 00:37:28,716
see actually was that our mouse and

1030
00:37:28,738 --> 00:37:30,316
human cells, which are here in Bleu and

1031
00:37:30,338 --> 00:37:33,196
orange, significantly outperformed and

1032
00:37:33,218 --> 00:37:37,024
outlined DQN was pretty much always

1033
00:37:37,142 --> 00:37:39,248
the lowest performer, which is fine, we

1034
00:37:39,254 --> 00:37:40,368
know that it's very sample and

1035
00:37:40,374 --> 00:37:42,188
efficient. But even more sample

1036
00:37:42,204 --> 00:37:43,856
efficient algorithms like A, two C and

1037
00:37:43,878 --> 00:37:47,348
PPO also failed to show the

1038
00:37:47,354 --> 00:37:49,364
same degree of performance, even though

1039
00:37:49,402 --> 00:37:51,812
they started higher. For whatever

1040
00:37:51,866 --> 00:37:53,236
reason, we can never quite figure out

1041
00:37:53,258 --> 00:37:55,156
just some quirk of the algorithm. They

1042
00:37:55,178 --> 00:37:56,356
never showed the same degree of

1043
00:37:56,378 --> 00:37:58,208
learning. And this was again mimicked

1044
00:37:58,224 --> 00:38:01,096
across multiple comparisons. But what

1045
00:38:01,118 --> 00:38:02,696
was brought up to us was this idea of

1046
00:38:02,718 --> 00:38:04,868
saying well, there is of course a curve

1047
00:38:04,884 --> 00:38:06,276
force dimensionality. So what you're

1048
00:38:06,308 --> 00:38:08,008
doing is you're feeding in I think it

1049
00:38:08,014 --> 00:38:11,130
was a 40 by 40 image vector to these

1050
00:38:11,740 --> 00:38:14,348
deep reinforcement learning. And of

1051
00:38:14,354 --> 00:38:15,836
course it's going to take them longer to

1052
00:38:15,858 --> 00:38:17,164
converge. They have to deal with more

1053
00:38:17,202 --> 00:38:19,404
information. And we went, you know what,

1054
00:38:19,442 --> 00:38:21,516
that's a fair point. So what we did was

1055
00:38:21,538 --> 00:38:24,712
run it even simpler and we came out and

1056
00:38:24,786 --> 00:38:25,856
we said all right, what we'll do is

1057
00:38:25,878 --> 00:38:28,128
we'll feed them vectors of simply, you

1058
00:38:28,134 --> 00:38:31,056
know, four vector matrix of where the

1059
00:38:31,078 --> 00:38:32,896
paddle is and where the ball is and that

1060
00:38:32,918 --> 00:38:34,308
will be much simpler and closer to the

1061
00:38:34,314 --> 00:38:36,916
game plane. So we fed that into them and

1062
00:38:36,938 --> 00:38:40,164
what we saw was actually they formed us

1063
00:38:40,202 --> 00:38:44,436
with less information, of course the

1064
00:38:44,458 --> 00:38:46,744
mouse and human image time because we

1065
00:38:46,782 --> 00:38:48,696
can't alter the information put in this

1066
00:38:48,718 --> 00:38:50,472
way it was a post.

1067
00:38:50,526 --> 00:38:54,344
Pardon the actual

1068
00:38:54,542 --> 00:38:56,744
mouse and human cortical cells but yeah,

1069
00:38:56,782 --> 00:39:01,036
they did even worse across and

1070
00:39:01,058 --> 00:39:03,932
we found gain they're outperforming. It

1071
00:39:03,986 --> 00:39:06,910
more indoctrination than what the

1072
00:39:07,920 --> 00:39:09,372
getting because the cells are really

1073
00:39:09,426 --> 00:39:11,388
only just received in the ball position.

1074
00:39:11,554 --> 00:39:12,664
We're not yet able to encode

1075
00:39:12,712 --> 00:39:14,340
proprioception because the disparate

1076
00:39:14,360 --> 00:39:16,416
system is very simple. And although we

1077
00:39:16,438 --> 00:39:18,448
would argue again that this sparsity of

1078
00:39:18,454 --> 00:39:20,348
information should truly make it harder,

1079
00:39:20,444 --> 00:39:22,368
not easier with less information and

1080
00:39:22,374 --> 00:39:24,336
certainly with our initial pilot testing

1081
00:39:24,368 --> 00:39:26,356
we found that the more information you

1082
00:39:26,378 --> 00:39:28,196
gave them the better they could do. We

1083
00:39:28,218 --> 00:39:32,132
again said fair enough, let's change

1084
00:39:32,186 --> 00:39:33,828
the information input to the

1085
00:39:33,994 --> 00:39:35,876
reinforcement learning algorithms give

1086
00:39:35,898 --> 00:39:37,536
them the simplest possible information

1087
00:39:37,658 --> 00:39:40,216
that matches as close as we could

1088
00:39:40,238 --> 00:39:42,168
possibly do to what the cells are

1089
00:39:42,174 --> 00:39:43,944
getting and see how they performed. And

1090
00:39:43,982 --> 00:39:46,084
again they performed even worse

1091
00:39:46,212 --> 00:39:48,488
suggesting that in fact more information

1092
00:39:48,574 --> 00:39:51,416
is probably helpful. And so I think what

1093
00:39:51,438 --> 00:39:53,324
we could show here is that yes there is

1094
00:39:53,362 --> 00:39:55,932
certainly something interesting going on

1095
00:39:55,986 --> 00:39:57,724
in neural cells and the way they're able

1096
00:39:57,762 --> 00:39:59,724
to process information. And it comes

1097
00:39:59,762 --> 00:40:01,870
back to this quote that I love so much,

1098
00:40:02,240 --> 00:40:04,476
which is to say that if the human brain,

1099
00:40:04,508 --> 00:40:06,956
or in this case even a simple collection

1100
00:40:06,988 --> 00:40:08,688
of neurons in a dish was so simple that

1101
00:40:08,694 --> 00:40:10,736
we could understand it, we might be so

1102
00:40:10,758 --> 00:40:14,016
simple that we couldn't. We like to

1103
00:40:14,038 --> 00:40:15,200
think that the tools we're building,

1104
00:40:15,270 --> 00:40:16,708
such as this, is going to help us to

1105
00:40:16,714 --> 00:40:18,308
actually simplify it enough that we'll

1106
00:40:18,314 --> 00:40:19,428
be able to unpick and start to

1107
00:40:19,434 --> 00:40:22,164
understand the nuances behind this.

1108
00:40:22,362 --> 00:40:25,268
But one of the nice things that we're

1109
00:40:25,274 --> 00:40:26,768
able to show is that even without fully

1110
00:40:26,784 --> 00:40:28,276
understanding all the nuances of what's

1111
00:40:28,308 --> 00:40:30,984
going on inside a dish like this we can

1112
00:40:31,022 --> 00:40:33,204
see that it does have some distinct

1113
00:40:33,252 --> 00:40:35,704
traits in terms of intelligence that

1114
00:40:35,742 --> 00:40:37,096
have promising advantages for

1115
00:40:37,118 --> 00:40:39,332
information processing above and beyond

1116
00:40:39,396 --> 00:40:40,664
what's going on in reinforcement

1117
00:40:40,712 --> 00:40:42,236
learning. And we really think this

1118
00:40:42,258 --> 00:40:43,388
hammers home that this is going to be a

1119
00:40:43,394 --> 00:40:45,564
powerful tool to investigate these

1120
00:40:45,602 --> 00:40:50,204
features in more detail. So as

1121
00:40:50,242 --> 00:40:54,256
sort of a summed up conclusion what

1122
00:40:54,278 --> 00:40:55,520
we're able to do with the system

1123
00:40:55,590 --> 00:40:59,040
essentially is have a system of real

1124
00:40:59,110 --> 00:41:01,504
biological neurocultures that can

1125
00:41:01,542 --> 00:41:03,924
exhibit a very rudimentary form of

1126
00:41:04,042 --> 00:41:06,404
natural intelligence through their

1127
00:41:06,442 --> 00:41:08,516
inherent adaptive traits. And these

1128
00:41:08,538 --> 00:41:11,524
adaptive traits are frankly quite

1129
00:41:11,562 --> 00:41:14,228
amazing to the extent and variety and

1130
00:41:14,234 --> 00:41:15,828
diversity of what they're shown. And

1131
00:41:15,914 --> 00:41:17,224
even with the data that we've already

1132
00:41:17,262 --> 00:41:18,756
generated, we're only just scratching

1133
00:41:18,788 --> 00:41:21,816
the surface. But there's a lot of

1134
00:41:21,838 --> 00:41:23,764
potential that they have. And so simply

1135
00:41:23,812 --> 00:41:26,088
by having this closed loop system of

1136
00:41:26,094 --> 00:41:27,848
electrophysiological stimulation and

1137
00:41:27,854 --> 00:41:31,448
recording via these multilector rays,

1138
00:41:31,624 --> 00:41:34,444
we could embed them into or embody them

1139
00:41:34,562 --> 00:41:36,236
into a simulated world, depending which

1140
00:41:36,258 --> 00:41:38,796
term you prefer. And they could get

1141
00:41:38,818 --> 00:41:41,376
better at playing it and moving the

1142
00:41:41,398 --> 00:41:42,848
paddle to actually be able to perform

1143
00:41:42,934 --> 00:41:45,756
the game with quite a consistent degree

1144
00:41:45,788 --> 00:41:47,196
of coordination and with a faster

1145
00:41:47,228 --> 00:41:49,692
learning rate than multiple

1146
00:41:49,756 --> 00:41:52,530
reinforcement learning algorithms. And

1147
00:41:52,980 --> 00:41:54,528
of course, this is as I said, it's a lot

1148
00:41:54,534 --> 00:41:55,708
of work and we're only just scratching

1149
00:41:55,724 --> 00:41:56,944
the surface. And so one of the things

1150
00:41:56,982 --> 00:41:59,116
we're excited to do, because we're

1151
00:41:59,148 --> 00:42:00,608
actually not an academic lab, we're a

1152
00:42:00,614 --> 00:42:02,428
small start up based in Melbourne,

1153
00:42:02,444 --> 00:42:04,176
Australia, is we want to open this

1154
00:42:04,198 --> 00:42:07,656
platform up to everybody. So if you have

1155
00:42:07,678 --> 00:42:09,508
a question or you think everything I've

1156
00:42:09,524 --> 00:42:10,856
just told you is completely wrong and

1157
00:42:10,878 --> 00:42:12,312
that neurons work in a totally different

1158
00:42:12,366 --> 00:42:15,864
way, that's fine. Reach out. We will

1159
00:42:15,902 --> 00:42:18,548
in next year be opening up for alpha

1160
00:42:18,564 --> 00:42:20,016
testing. And so the most exciting

1161
00:42:20,068 --> 00:42:21,596
projects will be supporting to have an

1162
00:42:21,618 --> 00:42:23,596
early access to this. If you want to

1163
00:42:23,618 --> 00:42:25,116
investigate the properties of these

1164
00:42:25,138 --> 00:42:27,852
neurons, and you have basic Python or

1165
00:42:27,906 --> 00:42:31,180
Java coding skills, you can access

1166
00:42:31,250 --> 00:42:34,476
them virtually and code them as an

1167
00:42:34,498 --> 00:42:36,576
environment and see how they respond and

1168
00:42:36,598 --> 00:42:39,424
test it and go away and write a paper

1169
00:42:39,462 --> 00:42:41,248
sort of showing how you think that it

1170
00:42:41,254 --> 00:42:43,010
should all work based on actual data.

1171
00:42:43,700 --> 00:42:45,456
And this is because we acknowledge this

1172
00:42:45,478 --> 00:42:48,144
is a whole industry like this or whole

1173
00:42:48,182 --> 00:42:50,676
field of research, of course. And so we

1174
00:42:50,698 --> 00:42:51,616
want to try and make these tools

1175
00:42:51,648 --> 00:42:52,836
available for as many people as

1176
00:42:52,858 --> 00:42:54,948
possible, and we're going to make it as

1177
00:42:54,954 --> 00:42:56,376
easy for you as possible as well. And

1178
00:42:56,398 --> 00:42:59,080
it's going to be fairly affordable.

1179
00:42:59,500 --> 00:43:03,448
So that's the end of the talk. And of

1180
00:43:03,454 --> 00:43:07,016
course, it's not just me working on

1181
00:43:07,038 --> 00:43:09,336
it. There's a whole team and a number of

1182
00:43:09,358 --> 00:43:11,016
collaborators that we work with. These

1183
00:43:11,038 --> 00:43:12,396
are just the collaborators that sort of

1184
00:43:12,418 --> 00:43:14,364
touch on this work. There are many other

1185
00:43:14,402 --> 00:43:15,788
very valuable people we work with and

1186
00:43:15,794 --> 00:43:18,684
are expanding in other areas. And

1187
00:43:18,722 --> 00:43:19,852
actually we're fortunate enough that

1188
00:43:19,906 --> 00:43:22,384
Professor Adeel Razi, who's one of our

1189
00:43:22,502 --> 00:43:24,288
closest collaborators, has actually been

1190
00:43:24,294 --> 00:43:26,172
able to join us today for the discussion

1191
00:43:26,236 --> 00:43:28,624
part of it. And so if there are any

1192
00:43:28,662 --> 00:43:30,352
discussions, really happy to take

1193
00:43:30,406 --> 00:43:31,010
questions.

1194
00:43:33,720 --> 00:43:36,310
All right, wow.

1195
00:43:36,920 --> 00:43:40,310
Well, thank you very much for that

1196
00:43:40,760 --> 00:43:42,708
excellent presentation. It gives us a

1197
00:43:42,714 --> 00:43:45,190
lot to jump into.

1198
00:43:45,580 --> 00:43:48,712
So perhaps, Adeel, feel free to

1199
00:43:48,766 --> 00:43:51,560
say hello, introduce yourself, and add

1200
00:43:51,630 --> 00:43:54,484
any general remarks so that we can jump

1201
00:43:54,532 --> 00:43:57,076
into some more questions. 

1202
00:43:58,098 --> 00:44:01,644
>>>ADEEL RAZI: Yes, thank you, Daniel. Great talk, Brett. And as

1203
00:44:01,682 --> 00:44:04,936
always, it was a tour de force,

1204
00:44:05,048 --> 00:44:08,172
through so many projects that you love

1205
00:44:08,226 --> 00:44:11,440
us, is really doing amazing work.

1206
00:44:11,510 --> 00:44:14,800
So I'm based at

1207
00:44:14,870 --> 00:44:17,104
Minnesota University. We are not that

1208
00:44:17,142 --> 00:44:20,700
far from where ecological Labs

1209
00:44:20,860 --> 00:44:24,116
is in the city.

1210
00:44:24,298 --> 00:44:27,956
We are a bit suburban at

1211
00:44:27,978 --> 00:44:29,952
the main campus, Manash University,

1212
00:44:30,016 --> 00:44:33,460
where you have this computational system

1213
00:44:33,530 --> 00:44:36,792
neuroscience lab. And our

1214
00:44:36,846 --> 00:44:40,484
lab is using brain imaging

1215
00:44:40,532 --> 00:44:43,688
and computational models, especially

1216
00:44:43,774 --> 00:44:46,116
dynamics, causal modeling and active

1217
00:44:46,148 --> 00:44:49,212
inference, as frameworks to look into

1218
00:44:49,266 --> 00:44:51,420
the brain and try to understand what's

1219
00:44:56,560 --> 00:45:00,708
how one can look at the mechanisms,

1220
00:45:00,904 --> 00:45:02,604
for example, how the brain implements

1221
00:45:02,652 --> 00:45:06,592
cognition. For example. For this we

1222
00:45:06,646 --> 00:45:08,370
use, as I said,

1223
00:45:09,540 --> 00:45:12,652
mathematical framework of inference

1224
00:45:12,716 --> 00:45:15,684
and also dynamic cause of modeling. So

1225
00:45:15,722 --> 00:45:19,380
that's basically what we are doing and

1226
00:45:19,450 --> 00:45:22,288
happy to contribute to this discussion.

1227
00:45:22,384 --> 00:45:27,412
It spreads there

1228
00:45:27,466 --> 00:45:30,024
and you should be the one who should be

1229
00:45:30,062 --> 00:45:32,424
talking more. And I would be gladly just

1230
00:45:32,462 --> 00:45:35,160
sitting here and listening to wonderful

1231
00:45:35,820 --> 00:45:37,930
interaction we already have having.

1232
00:45:39,440 --> 00:45:42,572
Awesome. Well, my first question just

1233
00:45:42,626 --> 00:45:46,072
for context was how did active inference

1234
00:45:46,216 --> 00:45:48,604
come together with this line of

1235
00:45:48,642 --> 00:45:51,016
research? Were you studying active

1236
00:45:51,048 --> 00:45:53,376
inference and then looking for an

1237
00:45:53,398 --> 00:45:56,416
embodied system or was it something like

1238
00:45:56,438 --> 00:45:58,656
you were studying this very interesting

1239
00:45:58,838 --> 00:46:01,776
system and looking for some type of

1240
00:46:01,798 --> 00:46:03,830
framework to help you model it?

1241
00:46:04,920 --> 00:46:08,148
Absolutely. It's a great question. It

1242
00:46:08,154 --> 00:46:11,616
goes back historically. So Andy

1243
00:46:11,648 --> 00:46:12,630
Kitchen actually,

1244
00:46:15,080 --> 00:46:17,556
who's one of the founders of the

1245
00:46:17,578 --> 00:46:21,200
company, they were interested in,

1246
00:46:21,210 --> 00:46:23,224
they were looking for ways to explore it

1247
00:46:23,262 --> 00:46:26,056
and actually a deal. You ended up having

1248
00:46:26,078 --> 00:46:27,480
a conversation with them, I believe,

1249
00:46:27,550 --> 00:46:28,908
and they were basically looking for a

1250
00:46:28,914 --> 00:46:31,788
method of like, how could we talk to the

1251
00:46:31,794 --> 00:46:33,736
cells and they came across active

1252
00:46:33,768 --> 00:46:36,076
inference or did you introduce them to

1253
00:46:36,098 --> 00:46:39,980
active inference? I would say that

1254
00:46:40,130 --> 00:46:43,536
Andy Ari Kahn at that time that we are

1255
00:46:43,558 --> 00:46:46,688
talking about late 2018, early 2019,

1256
00:46:46,694 --> 00:46:49,904
and they were

1257
00:46:49,942 --> 00:46:51,600
already interested in free energy

1258
00:46:51,670 --> 00:46:55,492
principle. But then

1259
00:46:55,626 --> 00:46:59,728
I just moved to Melbourne from London

1260
00:46:59,824 --> 00:47:03,172
in mid 2018 and I end up giving a talk,

1261
00:47:03,226 --> 00:47:06,424
ant Alfred, where Cortical lab is being

1262
00:47:06,462 --> 00:47:09,704
incubated at that time. And I was

1263
00:47:09,742 --> 00:47:13,864
discussing these ideas and it

1264
00:47:13,902 --> 00:47:18,368
was kind of interaction

1265
00:47:18,404 --> 00:47:21,132
which just happened. And then we

1266
00:47:21,186 --> 00:47:23,208
thought, yeah, well, okay, there's lots

1267
00:47:23,224 --> 00:47:26,476
of synergy and there

1268
00:47:26,498 --> 00:47:29,896
we go. We workshop

1269
00:47:30,008 --> 00:47:34,912
some of the early ideas at that time and

1270
00:47:35,046 --> 00:47:38,592
thought about on Andy were really

1271
00:47:38,726 --> 00:47:40,704
thinking about how to actually what

1272
00:47:40,742 --> 00:47:43,036
could be the first thing that we should

1273
00:47:43,078 --> 00:47:46,310
do, which would then really

1274
00:47:47,160 --> 00:47:49,856
showcase the power of the dish brain.

1275
00:47:49,888 --> 00:47:51,572
Of who? The dish brain. Exact name came

1276
00:47:51,626 --> 00:47:52,550
later on.

1277
00:47:56,040 --> 00:47:59,256
The child? No, actually described as a

1278
00:47:59,278 --> 00:48:02,168
name. Definitely goes to Andy as well.

1279
00:48:02,334 --> 00:48:04,776
Okay. I would have given it some sort of

1280
00:48:04,878 --> 00:48:07,368
esoteric name that everyone would have

1281
00:48:07,374 --> 00:48:09,336
gone, what the hell is that? It's a good

1282
00:48:09,358 --> 00:48:10,910
call by Andy to do that,

1283
00:48:12,480 --> 00:48:14,316
but of course it does have a lot of

1284
00:48:14,338 --> 00:48:16,776
really useful features. The whole active

1285
00:48:16,808 --> 00:48:19,276
inference framework that make it quite

1286
00:48:19,298 --> 00:48:21,996
an ideal thing to test, the whole action

1287
00:48:22,028 --> 00:48:23,536
perception cycle, the fact that there

1288
00:48:23,558 --> 00:48:25,564
are implications that you can simply

1289
00:48:25,612 --> 00:48:28,604
take and be able to test the biological

1290
00:48:28,652 --> 00:48:32,032
plausibility of it all, make it very

1291
00:48:32,086 --> 00:48:35,460
useful as a system for us to adopt.

1292
00:48:36,040 --> 00:48:38,996
Having said that, though, and deal can

1293
00:48:39,018 --> 00:48:39,990
attest to this,

1294
00:48:42,920 --> 00:48:45,204
I think as a Neil Seth calls it, maybe

1295
00:48:45,242 --> 00:48:46,468
other people call it that too. It was a

1296
00:48:46,474 --> 00:48:48,676
bit of an adversarial collaboration in

1297
00:48:48,698 --> 00:48:50,728
some aspects as well because we were

1298
00:48:50,894 --> 00:48:53,256
interested in the idea, but we had no

1299
00:48:53,278 --> 00:48:55,736
stake in proving or disproving it. We

1300
00:48:55,758 --> 00:48:57,288
were simply testing it. And so we had a

1301
00:48:57,294 --> 00:48:59,610
number of discussions as we went through

1302
00:49:00,380 --> 00:49:02,510
what if we see x, y and Z?

1303
00:49:04,160 --> 00:49:06,044
What would be the states? Just kind of

1304
00:49:06,082 --> 00:49:08,204
challenge it, not just support it. And

1305
00:49:08,242 --> 00:49:09,836
so I think that was one of the things

1306
00:49:09,858 --> 00:49:10,824
that made it a really exciting

1307
00:49:10,872 --> 00:49:13,356
collaboration, in that there was a high

1308
00:49:13,378 --> 00:49:15,328
degree of skepticism amongst the team

1309
00:49:15,414 --> 00:49:17,490
about pretty much everything we did.

1310
00:49:18,020 --> 00:49:19,648
And I think that's what came together in

1311
00:49:19,654 --> 00:49:21,296
making it quite a nice paper, because we

1312
00:49:21,318 --> 00:49:23,868
were like, as everyone should be in

1313
00:49:23,894 --> 00:49:26,112
science, but let's be realistic. Seldom

1314
00:49:26,176 --> 00:49:28,608
are. We were trying to be our own west

1315
00:49:28,704 --> 00:49:30,916
critics because we were trying to figure

1316
00:49:30,938 --> 00:49:33,510
out what else could be explaining it.

1317
00:49:35,800 --> 00:49:37,144
I think there are interesting future

1318
00:49:37,182 --> 00:49:38,872
directions we can explore but certainly

1319
00:49:38,926 --> 00:49:40,840
the results as they are did find support

1320
00:49:40,910 --> 00:49:43,476
that this only is a key characteristic

1321
00:49:43,508 --> 00:49:44,920
of how cells respond.

1322
00:49:47,920 --> 00:49:51,532
Awesome so one preemptive question about

1323
00:49:51,586 --> 00:49:54,444
learning and then we'll drive back

1324
00:49:54,482 --> 00:49:57,096
towards active coherence so what kinds

1325
00:49:57,128 --> 00:50:00,440
of mechanisms do the neurons use

1326
00:50:00,530 --> 00:50:04,304
to engage game mode and also to learn?

1327
00:50:04,502 --> 00:50:07,776
Are they changing their topology in

1328
00:50:07,798 --> 00:50:10,144
terms of their connectivity? Are they

1329
00:50:10,182 --> 00:50:12,496
changing what happens at synapses? Are

1330
00:50:12,518 --> 00:50:14,848
there changes happening inside of cells?

1331
00:50:14,944 --> 00:50:17,444
What happens when the game mode turns on

1332
00:50:17,482 --> 00:50:19,664
and how does it actually improve

1333
00:50:19,712 --> 00:50:21,044
throughout the course of that

1334
00:50:21,082 --> 00:50:24,804
experiment? Look, that's a great

1335
00:50:24,842 --> 00:50:27,268
question and the reality is we don't

1336
00:50:27,284 --> 00:50:30,408
have the full answer for that yet. Most

1337
00:50:30,494 --> 00:50:33,592
likely it's going to be a combination of

1338
00:50:33,646 --> 00:50:36,088
the latitude. You mentioned changes that

1339
00:50:36,094 --> 00:50:37,988
are happening potentially inside cells

1340
00:50:38,004 --> 00:50:40,060
or inside synapses. I mean it's not

1341
00:50:40,130 --> 00:50:42,044
necessarily too useful to try and break

1342
00:50:42,082 --> 00:50:45,196
those apart. The idea of

1343
00:50:45,298 --> 00:50:47,436
larger scale morphological changes are

1344
00:50:47,458 --> 00:50:49,896
less likely simply due to the timescale

1345
00:50:49,928 --> 00:50:52,936
that we see and the fact that we don't

1346
00:50:53,128 --> 00:50:55,696
typically, although there will be some

1347
00:50:55,718 --> 00:50:57,376
future work sort of showing some other

1348
00:50:57,398 --> 00:51:00,028
things as we've moved on and advanced

1349
00:51:00,044 --> 00:51:01,936
with our work we typically, in this

1350
00:51:01,958 --> 00:51:04,192
study at least, didn't see learning

1351
00:51:04,246 --> 00:51:06,532
across days. So it's unlikely there are

1352
00:51:06,666 --> 00:51:08,976
massive changes in sort of connectivity.

1353
00:51:09,088 --> 00:51:10,736
It's more likely that it's functional

1354
00:51:10,768 --> 00:51:12,276
changes in plasticity and how they

1355
00:51:12,298 --> 00:51:15,108
respond to information and it could be a

1356
00:51:15,114 --> 00:51:18,060
number of things. Of course, it's

1357
00:51:18,080 --> 00:51:19,496
probably some sort of relationship and

1358
00:51:19,518 --> 00:51:21,396
balance between heavy and homeostatic

1359
00:51:21,428 --> 00:51:24,136
plasticity long term potentiation to

1360
00:51:24,158 --> 00:51:26,388
long term depression. And then there's

1361
00:51:26,404 --> 00:51:28,252
so many mechanisms that you can break

1362
00:51:28,306 --> 00:51:33,116
down to look at how that is from one

1363
00:51:33,138 --> 00:51:34,316
interesting candidate could be looking

1364
00:51:34,338 --> 00:51:36,008
at like foster evolution of coughlin

1365
00:51:36,024 --> 00:51:37,884
which interestingly takes I think about

1366
00:51:37,922 --> 00:51:41,144
5 minutes to translocate

1367
00:51:41,192 --> 00:51:43,940
from inside to outside system absence

1368
00:51:43,960 --> 00:51:45,276
and then is known to alter long term

1369
00:51:45,308 --> 00:51:48,844
potentiation which would roughly accord

1370
00:51:48,892 --> 00:51:50,416
at that time. But this is something we

1371
00:51:50,438 --> 00:51:52,370
need to investigate more in the future.

1372
00:51:53,560 --> 00:51:55,476
Higher level to that. I mean a deal

1373
00:51:55,578 --> 00:51:58,740
might have some ideas to sort of discuss

1374
00:51:58,810 --> 00:52:02,150
higher level than this.

1375
00:52:02,920 --> 00:52:04,532
Less productive and more high level.

1376
00:52:04,666 --> 00:52:07,640
Yeah, more computational.

1377
00:52:11,740 --> 00:52:13,320
We are really interested in learning

1378
00:52:13,390 --> 00:52:17,172
mechanisms and especially formative

1379
00:52:17,316 --> 00:52:21,260
entrance brain of what are the learning

1380
00:52:21,330 --> 00:52:26,236
mechanisms that

1381
00:52:26,258 --> 00:52:27,736
we can mimic in artificial neural

1382
00:52:27,768 --> 00:52:31,344
networks while we have

1383
00:52:31,382 --> 00:52:33,904
the biological chip which can learn can

1384
00:52:33,942 --> 00:52:36,204
we actually now understand how it's

1385
00:52:36,252 --> 00:52:39,200
doing this and can we in the short term

1386
00:52:40,260 --> 00:52:44,396
have better artificial neural networks?

1387
00:52:44,508 --> 00:52:47,284
Of course, where Brain and his team is

1388
00:52:47,322 --> 00:52:49,156
taking to us that we actually don't need

1389
00:52:49,178 --> 00:52:51,360
the artificial neural networks anymore,

1390
00:52:51,520 --> 00:52:54,112
we'll just have the biological chips.

1391
00:52:54,176 --> 00:52:57,720
Right. That's exciting.

1392
00:52:58,300 --> 00:53:01,640
So we have been looking at certain

1393
00:53:01,710 --> 00:53:06,164
things some of the more unresolved

1394
00:53:06,212 --> 00:53:08,732
problems in independent learning and in

1395
00:53:08,786 --> 00:53:12,904
machine learning force. Example lifelong

1396
00:53:12,952 --> 00:53:16,636
learning and continuum learning where we

1397
00:53:16,658 --> 00:53:20,776
know that artificial neural networks,

1398
00:53:20,968 --> 00:53:24,524
they break down in tasks.

1399
00:53:24,572 --> 00:53:27,484
Where you have to do multiple task

1400
00:53:27,532 --> 00:53:30,850
injuries, and they could do very good

1401
00:53:31,220 --> 00:53:33,670
human like performances on a single

1402
00:53:34,040 --> 00:53:37,076
task, but then you train them on the

1403
00:53:37,098 --> 00:53:39,524
second one, and then they forget what

1404
00:53:39,562 --> 00:53:41,696
they learned in the first one. Unlike

1405
00:53:41,728 --> 00:53:45,110
humans who could run, swim, speak

1406
00:53:45,420 --> 00:53:48,996
without forgetting what otherwise

1407
00:53:49,028 --> 00:53:52,664
it will be. So that's one thing.

1408
00:53:52,702 --> 00:53:55,640
Another thing, credit assignment,

1409
00:53:56,060 --> 00:53:58,780
one of the bigger problems. How do you

1410
00:53:58,930 --> 00:54:01,816
actually solve the credit assignment

1411
00:54:01,848 --> 00:54:04,492
problem, which is again an unsolved long

1412
00:54:04,546 --> 00:54:06,750
standing problem in deep learning,

1413
00:54:08,320 --> 00:54:12,204
what sort of choices we make

1414
00:54:12,402 --> 00:54:15,644
that result in the

1415
00:54:15,682 --> 00:54:19,888
boards in culture and many times

1416
00:54:19,974 --> 00:54:23,548
what happens there's

1417
00:54:23,564 --> 00:54:27,296
a delay in recording what behaviors

1418
00:54:27,328 --> 00:54:31,156
resulted in the

1419
00:54:31,178 --> 00:54:34,820
reward, for example. So looking ant

1420
00:54:34,890 --> 00:54:37,976
what elements and what choices that we

1421
00:54:37,998 --> 00:54:40,516
made that resulted in a long term gain

1422
00:54:40,628 --> 00:54:44,232
is another problem that we really

1423
00:54:44,286 --> 00:54:45,992
don't know right now. How do we actually

1424
00:54:46,046 --> 00:54:49,340
going to but these are very big problems

1425
00:54:49,490 --> 00:54:53,324
which are unsolved, and I think it

1426
00:54:53,362 --> 00:54:56,168
just shows you the power of the dish

1427
00:54:56,184 --> 00:54:58,732
brain system that it can actually help

1428
00:54:58,786 --> 00:55:03,164
us to I think there's a real

1429
00:55:03,202 --> 00:55:05,576
opportunity here for us to actually take

1430
00:55:05,618 --> 00:55:08,144
those problems as well at the high

1431
00:55:08,182 --> 00:55:10,770
level, as Brett was saying.

1432
00:55:12,020 --> 00:55:14,084
And I think it comes down to also being

1433
00:55:14,122 --> 00:55:16,004
like the right tool for the right job.

1434
00:55:16,202 --> 00:55:19,540
So reinforcement learning,

1435
00:55:19,610 --> 00:55:23,412
CNNs can do amazing things if you've got

1436
00:55:23,466 --> 00:55:25,510
the data to train them, if you've got

1437
00:55:26,840 --> 00:55:28,776
the rest of the setup that you need and

1438
00:55:28,798 --> 00:55:29,784
you want to use it for the right

1439
00:55:29,822 --> 00:55:32,824
purpose. Are they very good for doing

1440
00:55:32,862 --> 00:55:34,772
stuff in dynamic real time with limited

1441
00:55:34,836 --> 00:55:38,152
data, fuzzy information? So far,

1442
00:55:38,206 --> 00:55:41,132
no. And so maybe there will be a case

1443
00:55:41,186 --> 00:55:43,912
where we can take some of the findings

1444
00:55:43,976 --> 00:55:46,076
from how neurons work and apply it in an

1445
00:55:46,098 --> 00:55:49,404
algorithm in itself. I know

1446
00:55:49,442 --> 00:55:52,284
a known Anil and his team are doing some

1447
00:55:52,322 --> 00:55:54,968
amazing work with building up active

1448
00:55:54,984 --> 00:55:57,424
imprints models and I think those

1449
00:55:57,462 --> 00:55:59,344
results are really going to, I think,

1450
00:55:59,382 --> 00:56:01,936
excite a lot of people just as some

1451
00:56:01,958 --> 00:56:03,008
flagging of some of the work. You're

1452
00:56:03,014 --> 00:56:04,464
doing a deal. I won't mention anything

1453
00:56:04,502 --> 00:56:06,128
else once you've done that, but it's

1454
00:56:06,144 --> 00:56:07,204
going to be really exciting, I think,

1455
00:56:07,242 --> 00:56:08,870
for people to see what's happening.

1456
00:56:11,480 --> 00:56:13,316
But likewise, I do think that there will

1457
00:56:13,338 --> 00:56:15,788
be things that biology maintains

1458
00:56:15,824 --> 00:56:19,288
superiority over. The question and the

1459
00:56:19,294 --> 00:56:20,712
nice thing about biology, of course,

1460
00:56:20,846 --> 00:56:22,004
when you talk about generalized

1461
00:56:22,052 --> 00:56:24,216
intelligence, is we have no proof of

1462
00:56:24,238 --> 00:56:26,852
principle that generalized intelligence

1463
00:56:26,916 --> 00:56:31,290
can arise out of silicon hardware or

1464
00:56:31,740 --> 00:56:34,696
quantum based hardware. We do have proof

1465
00:56:34,728 --> 00:56:37,068
of principle that it can arise out of

1466
00:56:37,074 --> 00:56:40,764
biological wetware our brains and

1467
00:56:40,882 --> 00:56:42,788
brains of flies, of cats, of racks,

1468
00:56:42,824 --> 00:56:46,064
whatever, show general intelligence to

1469
00:56:46,102 --> 00:56:48,528
differing degrees. And so to us it's

1470
00:56:48,534 --> 00:56:50,784
like not a question of can biology show

1471
00:56:50,822 --> 00:56:52,896
generalized intelligence? But how do you

1472
00:56:52,918 --> 00:56:56,232
get there? And that's a less speculative

1473
00:56:56,316 --> 00:56:57,984
question, not necessarily an easier

1474
00:56:58,032 --> 00:56:59,216
question to answer. It's not easier

1475
00:56:59,248 --> 00:57:00,756
necessarily, but it does give you that

1476
00:57:00,778 --> 00:57:02,932
ground truth, the thing in Elf itself

1477
00:57:03,066 --> 00:57:04,150
sort of answer,

1478
00:57:07,720 --> 00:57:11,120
wow. So much there in silicone.

1479
00:57:11,280 --> 00:57:13,920
And in principle, systems can display

1480
00:57:14,000 --> 00:57:16,712
open ended symbolic learning going back

1481
00:57:16,766 --> 00:57:19,912
to the Turing machine, but for the kind

1482
00:57:19,966 --> 00:57:23,116
of openended enacted intelligence that

1483
00:57:23,138 --> 00:57:25,976
we might be interested in in settings

1484
00:57:26,008 --> 00:57:28,812
like you described, which are real time

1485
00:57:28,946 --> 00:57:31,136
fuzzy and with small data. And we could

1486
00:57:31,158 --> 00:57:33,676
also add with a high risk or survival

1487
00:57:33,708 --> 00:57:37,344
threat, those kinds of settings. We have

1488
00:57:37,382 --> 00:57:40,128
empirical evidence across the surface of

1489
00:57:40,134 --> 00:57:42,816
the planet that biological systems can

1490
00:57:42,838 --> 00:57:45,108
make that happen. And we have zero

1491
00:57:45,274 --> 00:57:48,736
empirical examples of silicon chips

1492
00:57:48,848 --> 00:57:52,800
making that kind of a functionality

1493
00:57:52,880 --> 00:57:54,836
arise. So that's a very interesting

1494
00:57:54,938 --> 00:57:55,590
point.

1495
00:57:58,380 --> 00:58:01,288
That. Kind of brings to this question

1496
00:58:01,374 --> 00:58:03,176
about the similarities and the

1497
00:58:03,198 --> 00:58:04,692
differences between the artificial

1498
00:58:04,756 --> 00:58:06,452
neural networks and the biological

1499
00:58:06,516 --> 00:58:08,604
structure and also between the

1500
00:58:08,642 --> 00:58:11,676
reinforcement learning paradigm and the

1501
00:58:11,698 --> 00:58:13,900
active inference paradigm. In which,

1502
00:58:13,970 --> 00:58:16,984
rather than maximizing a reward

1503
00:58:17,032 --> 00:58:20,516
function, we are minimizing an expected

1504
00:58:20,568 --> 00:58:22,912
free energy or a variational free energy

1505
00:58:23,046 --> 00:58:26,176
by way of bounding surprise. So in

1506
00:58:26,198 --> 00:58:29,824
describing the experimental setup, the

1507
00:58:29,862 --> 00:58:33,412
reward or rather the coherence of

1508
00:58:33,466 --> 00:58:37,552
succeeding or failing was you adjusting

1509
00:58:37,696 --> 00:58:40,496
the regularity of the input.

1510
00:58:40,688 --> 00:58:42,452
And in a reinforcement learning

1511
00:58:42,506 --> 00:58:44,036
paradigm, that's a little bit of an

1512
00:58:44,058 --> 00:58:46,712
unconventional manipulation one might

1513
00:58:46,766 --> 00:58:48,936
expect, oh, well, we'll add sugar or

1514
00:58:48,958 --> 00:58:51,016
we'll add a dopamine agonist or an

1515
00:58:51,038 --> 00:58:54,456
antagonist to the dish to signal the

1516
00:58:54,478 --> 00:58:56,596
positive or the negative valence

1517
00:58:56,788 --> 00:58:59,736
directly, kind of by putting our finger

1518
00:58:59,768 --> 00:59:02,190
on the scale of the reward function.

1519
00:59:02,560 --> 00:59:06,060
But rather you were able to

1520
00:59:06,210 --> 00:59:09,768
train and learn by changing the patterns

1521
00:59:09,784 --> 00:59:13,552
of regularity of feedback. So how

1522
00:59:13,606 --> 00:59:16,476
does active coherence have similarity

1523
00:59:16,508 --> 00:59:18,764
and difference with reinforcement

1524
00:59:18,812 --> 00:59:20,752
learning in terms of the way that we can

1525
00:59:20,806 --> 00:59:24,160
use patterns of regularity, not just

1526
00:59:24,230 --> 00:59:27,190
valence of interventions in learning?

1527
00:59:29,080 --> 00:59:30,548
I'll give an answer that I'm going to

1528
00:59:30,554 --> 00:59:32,996
pass over to a deal who can dive a lot

1529
00:59:33,018 --> 00:59:34,724
more into the computational side of it

1530
00:59:34,762 --> 00:59:36,790
than what I could.

1531
00:59:38,280 --> 00:59:39,448
What I would say, though, is that

1532
00:59:39,454 --> 00:59:40,968
there's a few things as well. One of

1533
00:59:40,974 --> 00:59:44,376
them, of course, is can you even adopt a

1534
00:59:44,398 --> 00:59:46,216
reinforcement learning paradigm in a

1535
00:59:46,238 --> 00:59:49,024
dish? It's not like there was a choice

1536
00:59:49,092 --> 00:59:51,724
between the two because we don't have

1537
00:59:51,762 --> 00:59:54,456
access to a privileged reward network

1538
00:59:54,648 --> 00:59:56,844
inside the dish to be able to say good

1539
00:59:56,882 --> 01:00:00,156
cells, bad cells. You could like

1540
01:00:00,178 --> 01:00:02,156
in theory, squat dopamine in, but you

1541
01:00:02,178 --> 01:00:03,768
can't continually squeak dopamine in.

1542
01:00:03,794 --> 01:00:06,316
You can't do it in a spatial or temporal

1543
01:00:06,508 --> 01:00:08,784
resolution. That's accurate enough,

1544
01:00:08,822 --> 01:00:10,850
right? It diffuses slowly. Across media.

1545
01:00:11,380 --> 01:00:14,736
We can't do it. So for

1546
01:00:14,758 --> 01:00:16,420
us, we needed to find something that was

1547
01:00:16,490 --> 01:00:19,316
more fundamental. And I think that's an

1548
01:00:19,338 --> 01:00:21,284
important point. And I think it's also

1549
01:00:21,322 --> 01:00:22,884
interesting to note, like that there are

1550
01:00:22,922 --> 01:00:25,408
studies that look at the fact that you

1551
01:00:25,434 --> 01:00:28,810
can mimic changes that you see with

1552
01:00:29,580 --> 01:00:31,592
electrical information that you can also

1553
01:00:31,646 --> 01:00:33,624
achieve through like the application of

1554
01:00:33,662 --> 01:00:35,736
small molecules such as Domain or

1555
01:00:35,758 --> 01:00:39,336
whatever neurotransmitters. And the

1556
01:00:39,358 --> 01:00:41,256
right stimulation can increase long term

1557
01:00:41,288 --> 01:00:42,924
tangential much in the same way that,

1558
01:00:42,962 --> 01:00:46,268
say, Dopamine would. And so domain seems

1559
01:00:46,354 --> 01:00:49,944
likely to be a tool this is speculative,

1560
01:00:49,992 --> 01:00:52,464
of course but it seems likely to be a

1561
01:00:52,502 --> 01:00:56,528
tool that shortcuts the

1562
01:00:56,534 --> 01:00:59,600
way that these systems work in line with

1563
01:00:59,670 --> 01:01:02,304
some broader imperatives such as free

1564
01:01:02,342 --> 01:01:06,932
energy minimization more so than being

1565
01:01:06,986 --> 01:01:09,236
something unique and special. It is

1566
01:01:09,258 --> 01:01:11,156
unique and special in its own right, in

1567
01:01:11,178 --> 01:01:13,524
the way that it works. But it must be

1568
01:01:13,562 --> 01:01:16,070
serving a more fundamental function.

1569
01:01:18,200 --> 01:01:19,988
Yeah, I think that's probably like a

1570
01:01:19,994 --> 01:01:21,576
good way then to sort of lead into the

1571
01:01:21,598 --> 01:01:23,188
differences between, let's say an active

1572
01:01:23,284 --> 01:01:25,268
inference framework and a reinforcement

1573
01:01:25,284 --> 01:01:26,584
learning framework which I think a deal

1574
01:01:26,622 --> 01:01:28,410
would be best to discuss.

1575
01:01:30,540 --> 01:01:33,356
Great question. First we started with

1576
01:01:33,378 --> 01:01:37,464
the differences in silicon models

1577
01:01:37,512 --> 01:01:40,280
the artificial neural network and the

1578
01:01:40,370 --> 01:01:43,152
biological neural network. First of all,

1579
01:01:43,206 --> 01:01:46,800
as we see the artificial neural network

1580
01:01:47,540 --> 01:01:50,732
is a caricature of an actual biological

1581
01:01:50,796 --> 01:01:54,196
neuron. It just mimics that. It takes an

1582
01:01:54,218 --> 01:01:57,844
input and then gives

1583
01:01:57,882 --> 01:02:00,020
you an output. There's a nonlinear

1584
01:02:00,440 --> 01:02:03,204
function and then once you have many of

1585
01:02:03,242 --> 01:02:07,032
them and clark them up and

1586
01:02:07,166 --> 01:02:09,832
make layers they can do amazing things.

1587
01:02:09,886 --> 01:02:12,036
So this is like artificial neural

1588
01:02:12,068 --> 01:02:15,316
network just using the virtue

1589
01:02:15,348 --> 01:02:18,772
of a cartoon or whatever

1590
01:02:18,846 --> 01:02:22,188
biological neural network do. It has a

1591
01:02:22,194 --> 01:02:25,912
lot more than that. It is an extremely

1592
01:02:26,056 --> 01:02:30,408
complex biological thing.

1593
01:02:30,514 --> 01:02:34,592
So imagine now that can

1594
01:02:34,646 --> 01:02:41,456
we use all of the power and all the when

1595
01:02:41,478 --> 01:02:44,516
it comes to what it can in terms of

1596
01:02:44,618 --> 01:02:47,732
information processing and then build

1597
01:02:47,786 --> 01:02:50,550
systems, how powerful they will be.

1598
01:02:51,320 --> 01:02:54,470
As we know currently,

1599
01:02:55,000 --> 01:03:00,216
these huge what

1600
01:03:00,238 --> 01:03:03,172
we call these large scale language

1601
01:03:03,236 --> 01:03:06,696
models for example, LLMs and then all

1602
01:03:06,718 --> 01:03:09,004
those fundamental models that we have

1603
01:03:09,042 --> 01:03:12,556
been seeing with billions of

1604
01:03:12,578 --> 01:03:16,616
parameters to train them, it requires

1605
01:03:16,808 --> 01:03:20,364
gigawatts of power. It's basically like

1606
01:03:20,402 --> 01:03:23,184
a whole city can be locked up with once

1607
01:03:23,222 --> 01:03:26,512
they train. Now a human brain is just

1608
01:03:26,566 --> 01:03:30,332
using a small fraction of inadequate

1609
01:03:30,396 --> 01:03:33,444
time and power to do much more than what

1610
01:03:33,482 --> 01:03:35,888
they could do. They still can't do solve

1611
01:03:35,984 --> 01:03:38,464
causal learning and causal reasoning

1612
01:03:38,512 --> 01:03:41,652
problems. Very basics of them. And while

1613
01:03:41,706 --> 01:03:45,228
biological neurons can do it very easily

1614
01:03:45,344 --> 01:03:47,176
as we are doing it right now we are

1615
01:03:47,198 --> 01:03:52,024
having a back and forth discussion that

1616
01:03:52,142 --> 01:03:56,900
a big is one of the most sophisticated

1617
01:03:56,980 --> 01:03:59,564
and huge neural network would not be

1618
01:03:59,602 --> 01:04:03,630
able to achieve even for a few minutes.

1619
01:04:04,080 --> 01:04:06,156
So that's what we are looking at.

1620
01:04:06,178 --> 01:04:10,076
That's an enormous opportunity that

1621
01:04:10,098 --> 01:04:12,208
we have to actually harness this power

1622
01:04:12,294 --> 01:04:16,032
and do amazing things now coming

1623
01:04:16,086 --> 01:04:19,744
back to coming back active

1624
01:04:19,942 --> 01:04:22,044
inference lab and reinforcement

1625
01:04:22,092 --> 01:04:25,524
learning. Now, this has

1626
01:04:25,562 --> 01:04:28,644
been asked many times and there are

1627
01:04:28,682 --> 01:04:30,724
papers that Karl has written, I think

1628
01:04:30,762 --> 01:04:33,684
Nullsaid has a paper on where they look

1629
01:04:33,722 --> 01:04:38,836
at Hohwy what

1630
01:04:38,858 --> 01:04:40,416
is biological. So I think active

1631
01:04:40,448 --> 01:04:42,960
coherence is biologically plausible.

1632
01:04:43,040 --> 01:04:46,248
So the main difference is

1633
01:04:46,334 --> 01:04:49,600
that when you are an active inference

1634
01:04:49,620 --> 01:04:53,112
system is optimizing a single quantity,

1635
01:04:53,256 --> 01:04:55,064
what we call the free energy of racial

1636
01:04:55,112 --> 01:04:58,764
free energy and that

1637
01:04:58,802 --> 01:05:01,468
gives you with a single optimization

1638
01:05:01,564 --> 01:05:04,412
function you are doing perception

1639
01:05:04,476 --> 01:05:07,808
planning and decision making with the

1640
01:05:07,814 --> 01:05:11,856
same quantity. So let me put this this

1641
01:05:11,878 --> 01:05:15,168
way think that how things have happened

1642
01:05:15,254 --> 01:05:18,596
over the past few decades that it has

1643
01:05:18,618 --> 01:05:21,796
been always been about how to optimize a

1644
01:05:21,818 --> 01:05:23,924
function. So once you have, let's say,

1645
01:05:23,962 --> 01:05:26,448
a value function or what in

1646
01:05:26,474 --> 01:05:29,208
reinforcement, learning is all about how

1647
01:05:29,294 --> 01:05:31,524
best you can optimize this quantity.

1648
01:05:31,652 --> 01:05:34,184
While what we are asking, we are saying

1649
01:05:34,222 --> 01:05:37,192
that what is we are optimizing, not how.

1650
01:05:37,246 --> 01:05:39,988
We optimize. So what is that quantity?

1651
01:05:40,084 --> 01:05:41,928
And that's the ratio for energy that we

1652
01:05:41,934 --> 01:05:44,764
are optimizing. And it gives you all of

1653
01:05:44,802 --> 01:05:48,236
that in a single compared to a

1654
01:05:48,258 --> 01:05:50,376
reinforcement learning system that would

1655
01:05:50,418 --> 01:05:52,864
require multiple objective functions to

1656
01:05:52,902 --> 01:05:55,536
optimize. So I think it's not

1657
01:05:55,638 --> 01:05:58,130
biologically taenable to have that.

1658
01:05:59,460 --> 01:06:03,876
And that's why the active inference is

1659
01:06:03,898 --> 01:06:06,788
a unifying framework and it probably

1660
01:06:06,874 --> 01:06:11,236
would rattle and offend few that we

1661
01:06:11,258 --> 01:06:15,392
think that active infant subsumes all

1662
01:06:15,466 --> 01:06:18,868
those computational

1663
01:06:18,964 --> 01:06:21,290
framework like reinforcement learning

1664
01:06:23,340 --> 01:06:27,144
into dynamic programming and all those

1665
01:06:27,342 --> 01:06:31,212
derivatives because it is basically

1666
01:06:31,346 --> 01:06:34,876
what the brain are doing and they are

1667
01:06:34,898 --> 01:06:38,904
doing it better than what framework

1668
01:06:38,952 --> 01:06:41,916
that we have Beren using so far. So I

1669
01:06:41,938 --> 01:06:43,852
think there are differences, clear

1670
01:06:43,906 --> 01:06:47,056
differences. However,

1671
01:06:47,158 --> 01:06:49,456
having said that, I would really would

1672
01:06:49,478 --> 01:06:53,332
like to see in future probably

1673
01:06:53,386 --> 01:06:55,892
we probably will have a dig at it how

1674
01:06:55,946 --> 01:06:58,804
you can actually mathematically which

1675
01:06:58,842 --> 01:07:01,590
chaos then become unambiguously sure

1676
01:07:03,320 --> 01:07:05,750
provided proof. That.

1677
01:07:08,360 --> 01:07:11,360
Active inference lab appear so there is

1678
01:07:11,370 --> 01:07:14,010
still a gap there. While we could

1679
01:07:14,700 --> 01:07:18,040
develop insulate active inference agents

1680
01:07:18,110 --> 01:07:20,520
and we can show them that they are doing

1681
01:07:20,590 --> 01:07:22,840
better than reinforcement learning

1682
01:07:22,910 --> 01:07:24,990
agents and then we have quite a few.

1683
01:07:26,080 --> 01:07:30,028
There's a whole sort of work that

1684
01:07:30,194 --> 01:07:33,072
my PhD student Ashwin Paul is doing and

1685
01:07:33,126 --> 01:07:35,296
the papers are coming where we are

1686
01:07:35,318 --> 01:07:39,264
comparing active coherence agents with

1687
01:07:39,302 --> 01:07:41,296
the state of the art with learning and

1688
01:07:41,318 --> 01:07:45,584
deep learning networks and

1689
01:07:45,622 --> 01:07:47,292
we are showing of course active

1690
01:07:47,366 --> 01:07:51,270
inference lab is doing better

1691
01:07:51,640 --> 01:07:54,084
but theoretical proofs are still

1692
01:07:54,122 --> 01:07:57,264
missing. Similarly like active inference

1693
01:07:57,312 --> 01:08:00,708
lab, what are

1694
01:08:00,714 --> 01:08:02,408
the similarities and differences? For

1695
01:08:02,414 --> 01:08:03,976
example, I would be very interested to

1696
01:08:03,998 --> 01:08:06,676
know how it's different from Tudorov's

1697
01:08:06,708 --> 01:08:09,880
work. Again, Ashwin is looking at that.

1698
01:08:09,950 --> 01:08:13,004
I am in all trudeau's paper, PNAS paper

1699
01:08:13,042 --> 01:08:15,224
in 2009 which looks at efficient

1700
01:08:15,272 --> 01:08:17,036
computations optimal action which hae

1701
01:08:17,058 --> 01:08:19,692
Parr reaching. They show that you can

1702
01:08:19,826 --> 01:08:22,560
both in discrete and continuum settings.

1703
01:08:24,740 --> 01:08:26,800
They have shown that their algorithms

1704
01:08:27,300 --> 01:08:30,880
can beat dynamic programming and

1705
01:08:30,950 --> 01:08:35,140
children learning based algorithms.

1706
01:08:37,000 --> 01:08:39,124
Active inference lab is different from

1707
01:08:39,162 --> 01:08:40,756
fish, prize bottle, information

1708
01:08:40,858 --> 01:08:41,940
bottleneck.

1709
01:08:44,920 --> 01:08:46,736
What are the links between universal

1710
01:08:46,768 --> 01:08:50,072
tries of Solomonov, all those

1711
01:08:50,126 --> 01:08:54,170
things? It's really early days.

1712
01:08:56,700 --> 01:08:58,168
What are the similarities and

1713
01:08:58,174 --> 01:09:01,484
differences of active entrance with all

1714
01:09:01,522 --> 01:09:03,804
those big ideas which are there for you

1715
01:09:03,922 --> 01:09:05,832
in Serbanetics and another literature

1716
01:09:05,896 --> 01:09:08,764
for many, many years, for decades? What

1717
01:09:08,802 --> 01:09:11,004
are the differences and in similarities?

1718
01:09:11,052 --> 01:09:12,976
It's a good question. We don't have all

1719
01:09:12,998 --> 01:09:17,344
the answers but it

1720
01:09:17,382 --> 01:09:19,890
would be very exciting next year is

1721
01:09:20,420 --> 01:09:22,690
looking at all those big questions.

1722
01:09:24,920 --> 01:09:27,124
I just wanted to echo one point you made

1723
01:09:27,162 --> 01:09:29,552
and then ask a question from the Chat.

1724
01:09:29,616 --> 01:09:33,396
So in reinforcement learning what

1725
01:09:33,498 --> 01:09:36,516
you should optimize is almost treated as

1726
01:09:36,538 --> 01:09:38,276
an obvious question. You want to win the

1727
01:09:38,298 --> 01:09:40,456
game, you want more points, that's the

1728
01:09:40,478 --> 01:09:42,900
way to win. You want to stay alive,

1729
01:09:42,980 --> 01:09:45,048
then you want to optimize survival so

1730
01:09:45,054 --> 01:09:46,696
that's your reward function. And what to

1731
01:09:46,718 --> 01:09:48,696
optimize is kind of swept under the rug.

1732
01:09:48,808 --> 01:09:50,396
And then there's this big question of

1733
01:09:50,418 --> 01:09:52,684
how to optimize it. And that's what has

1734
01:09:52,722 --> 01:09:55,596
led to this enormous diversification of

1735
01:09:55,618 --> 01:09:58,524
different approaches and heuristics for

1736
01:09:58,642 --> 01:10:01,036
how to optimize and different gradient

1737
01:10:01,068 --> 01:10:02,944
descent methods and so on in

1738
01:10:02,982 --> 01:10:05,872
reinforcement learning. In contrast, in

1739
01:10:05,926 --> 01:10:09,712
active inference, what to optimize is

1740
01:10:09,766 --> 01:10:12,864
actually known. It's the variational or

1741
01:10:12,902 --> 01:10:16,864
the expected free energy as exactly

1742
01:10:16,982 --> 01:10:20,724
specified by the generative model and we

1743
01:10:20,762 --> 01:10:23,844
know how to optimize it, which is with a

1744
01:10:23,882 --> 01:10:26,548
variety of locally plausible

1745
01:10:26,724 --> 01:10:29,544
biologically inspired update rules, for

1746
01:10:29,582 --> 01:10:31,796
example, message passing and belief

1747
01:10:31,828 --> 01:10:34,744
propagation. So that's a very subtle but

1748
01:10:34,782 --> 01:10:37,544
also paradigmatic difference which is

1749
01:10:37,582 --> 01:10:40,140
that the structure of what we're going

1750
01:10:40,210 --> 01:10:42,712
to optimize as our unified imperative

1751
01:10:42,776 --> 01:10:44,856
for perception, cognition and action.

1752
01:10:44,968 --> 01:10:48,344
The free energy functional has methods

1753
01:10:48,392 --> 01:10:51,712
and software packages that will step by

1754
01:10:51,766 --> 01:10:54,352
step convergently optimize it.

1755
01:10:54,486 --> 01:10:57,532
And so the onus is actually to specify

1756
01:10:57,676 --> 01:11:00,208
the generative model in a useful way

1757
01:11:00,374 --> 01:11:02,576
rather than treating what should be

1758
01:11:02,598 --> 01:11:05,500
optimized as just a bygone discussion

1759
01:11:05,580 --> 01:11:07,252
and then go into all these questions

1760
01:11:07,306 --> 01:11:08,976
about implementation which are the parts

1761
01:11:09,008 --> 01:11:10,900
that actually differ the most across

1762
01:11:10,970 --> 01:11:12,550
systems. So I think that's very

1763
01:11:13,080 --> 01:11:15,668
insightful. I wanted to ask a question

1764
01:11:15,754 --> 01:11:19,176
from the Chat, from Michael what would

1765
01:11:19,198 --> 01:11:21,656
be the difference if you change the

1766
01:11:21,678 --> 01:11:23,444
electrode array to stimulate

1767
01:11:23,492 --> 01:11:25,336
differently? For example, instead of

1768
01:11:25,358 --> 01:11:27,576
just growing the neurons on top, what if

1769
01:11:27,598 --> 01:11:30,376
the neuron synapses with the electrodes?

1770
01:11:30,488 --> 01:11:33,388
So what kinds of experimental setups are

1771
01:11:33,474 --> 01:11:36,380
possible and which ones are interesting

1772
01:11:36,530 --> 01:11:38,476
and how do you know and what do you

1773
01:11:38,498 --> 01:11:42,512
choose to do? I think the first

1774
01:11:42,566 --> 01:11:44,960
thing to say about that good question.

1775
01:11:45,110 --> 01:11:48,236
And certainly as the technology develops

1776
01:11:48,268 --> 01:11:50,450
we'll be able to ask these questions in

1777
01:11:50,900 --> 01:11:53,628
better and more interesting ways. It's

1778
01:11:53,644 --> 01:11:55,136
probably worth well, I've made this

1779
01:11:55,158 --> 01:11:56,516
comparison before, but I'll make it

1780
01:11:56,538 --> 01:11:59,910
again. The work that we've done here is

1781
01:12:00,600 --> 01:12:02,692
we're excited by it but at the same time

1782
01:12:02,746 --> 01:12:04,612
it is probably equivalent to the early

1783
01:12:04,666 --> 01:12:07,204
transistors made by Shockley. It's

1784
01:12:07,252 --> 01:12:10,600
janky, it's kind of ugly. It does a job

1785
01:12:10,750 --> 01:12:15,096
but not without limitations. And so

1786
01:12:15,278 --> 01:12:17,416
what we're really excited in is as the

1787
01:12:17,438 --> 01:12:19,164
community hopefully come together and

1788
01:12:19,202 --> 01:12:21,820
work on this 510,

1789
01:12:21,890 --> 01:12:24,350
1520 years, maybe longer.

1790
01:12:25,600 --> 01:12:27,676
70 years of continuum development have

1791
01:12:27,698 --> 01:12:31,128
led from a transistor being a large ugly

1792
01:12:31,304 --> 01:12:34,336
thing to thousands of them within every

1793
01:12:34,358 --> 01:12:37,648
device that I can see. So that's like

1794
01:12:37,654 --> 01:12:39,536
one thing I'll just say in terms of,

1795
01:12:39,558 --> 01:12:42,604
like, I will point out that the neurons

1796
01:12:42,652 --> 01:12:46,164
do, inasmuch as they probably ever can

1797
01:12:46,282 --> 01:12:49,476
integrate with the electrodes as is as

1798
01:12:49,498 --> 01:12:52,116
you saw from that picture I showed at

1799
01:12:52,138 --> 01:12:55,440
the start, they are deeply integrated

1800
01:12:55,600 --> 01:12:58,340
into the electrode.

1801
01:12:59,420 --> 01:13:01,444
We could not and let the neuron survive,

1802
01:13:01,492 --> 01:13:03,848
remove them in any meaningful way and

1803
01:13:03,854 --> 01:13:06,468
keep that structure. To get them, we'd

1804
01:13:06,484 --> 01:13:08,048
have to completely like disassociate

1805
01:13:08,084 --> 01:13:10,168
their structure and most neurons won't

1806
01:13:10,184 --> 01:13:13,630
survive that for very long anyway,

1807
01:13:14,400 --> 01:13:16,460
so they are currently integrated.

1808
01:13:17,040 --> 01:13:19,260
Synapses work slightly differently.

1809
01:13:21,200 --> 01:13:22,636
There's a whole collection of traits.

1810
01:13:22,668 --> 01:13:24,380
Like, there is, of course, electrical

1811
01:13:24,540 --> 01:13:26,800
activity is a shared language between

1812
01:13:26,870 --> 01:13:30,348
neurons and the hardware and that's

1813
01:13:30,364 --> 01:13:32,816
what makes it possible to stimulate them

1814
01:13:32,838 --> 01:13:35,056
with electricity because it can sort of

1815
01:13:35,078 --> 01:13:38,196
mimic the change in ions across the

1816
01:13:38,218 --> 01:13:40,496
membrane to stimulate action potentials,

1817
01:13:40,528 --> 01:13:41,828
which is how they then communicate with

1818
01:13:41,834 --> 01:13:43,136
electricity. But then action potentials,

1819
01:13:43,168 --> 01:13:44,964
of course, trigger the release of

1820
01:13:45,002 --> 01:13:47,944
chemical signals and so forth. So

1821
01:13:47,982 --> 01:13:49,560
there's a lot that's going on there and

1822
01:13:49,630 --> 01:13:51,636
I think it's about building the bridge.

1823
01:13:51,748 --> 01:13:53,450
It's not necessarily about,

1824
01:13:55,740 --> 01:13:57,064
I don't know, quite the right word

1825
01:13:57,102 --> 01:14:00,920
phrases about completely recapturing

1826
01:14:01,000 --> 01:14:02,988
everything that's unique to biology and

1827
01:14:02,994 --> 01:14:05,144
the hardware all unique to the hardware

1828
01:14:05,192 --> 01:14:07,532
in biology. It's about where's the

1829
01:14:07,586 --> 01:14:12,156
useful bridge and synthesis between

1830
01:14:12,258 --> 01:14:14,716
them to elicit the best of both worlds.

1831
01:14:14,748 --> 01:14:17,216
And again, it comes down the right tool

1832
01:14:17,238 --> 01:14:18,336
for the right job. But in this case,

1833
01:14:18,358 --> 01:14:19,484
it's like a different circumstance.

1834
01:14:19,532 --> 01:14:21,840
Like what's the right tool to process

1835
01:14:21,910 --> 01:14:25,564
the information? Is it a biological

1836
01:14:25,612 --> 01:14:28,256
Parr? Is it the hardware part? And so

1837
01:14:28,278 --> 01:14:29,396
when we communicate with them, what we

1838
01:14:29,418 --> 01:14:30,756
need to figure out and again, this is an

1839
01:14:30,778 --> 01:14:32,308
open question. I'm not sure where it

1840
01:14:32,314 --> 01:14:34,436
will go. But what we need to figure out

1841
01:14:34,458 --> 01:14:37,768
is what's the best way? At the time of

1842
01:14:37,774 --> 01:14:40,276
the technology we have right now, it's

1843
01:14:40,308 --> 01:14:44,010
not trying to replicate sort of

1844
01:14:45,180 --> 01:14:47,528
hardware based synapses to do sort of

1845
01:14:47,534 --> 01:14:49,016
chemical communication. Although maybe

1846
01:14:49,038 --> 01:14:51,096
in the future it will be. But yeah,

1847
01:14:51,118 --> 01:14:52,860
it's a very interesting question and the

1848
01:14:52,930 --> 01:14:54,684
base of the answer is we don't really

1849
01:14:54,722 --> 01:14:57,036
know where it could go and we don't know

1850
01:14:57,058 --> 01:14:59,036
where it would do. As I mentioned, the

1851
01:14:59,058 --> 01:15:00,936
talk, they are incredibly plastic

1852
01:15:00,968 --> 01:15:02,396
neurons. We can change the

1853
01:15:02,418 --> 01:15:04,188
configuration, we can change the type of

1854
01:15:04,194 --> 01:15:06,384
neurons, we can move from two D to three

1855
01:15:06,422 --> 01:15:08,044
D. And this is work that we have ongoing

1856
01:15:08,092 --> 01:15:11,088
now. And I think that what we're going

1857
01:15:11,094 --> 01:15:13,296
to see is just an explosion of results

1858
01:15:13,328 --> 01:15:15,604
as we start to make inroads in this

1859
01:15:15,642 --> 01:15:16,230
area.

1860
01:15:19,160 --> 01:15:21,124
Saying that the neurons might not

1861
01:15:21,162 --> 01:15:25,024
survive the separation from their cyber

1862
01:15:25,072 --> 01:15:28,744
physical digital substrate reminds me of

1863
01:15:28,862 --> 01:15:32,232
the reality of some to all of us

1864
01:15:32,286 --> 01:15:35,064
today. If we were also stripped from our

1865
01:15:35,102 --> 01:15:38,856
digital substrate, many critical systems

1866
01:15:38,888 --> 01:15:41,436
also would not function. And I think

1867
01:15:41,458 --> 01:15:43,180
that speaks to some of the recent Karl

1868
01:15:43,250 --> 01:15:46,604
J. Friston et al versus with

1869
01:15:46,642 --> 01:15:49,176
the idea of the ecosystems of shared

1870
01:15:49,208 --> 01:15:52,768
intelligence where we're thinking about

1871
01:15:52,854 --> 01:15:56,064
distributed cognitive processes that are

1872
01:15:56,102 --> 01:15:59,200
mediated by interfaces. And so some

1873
01:15:59,270 --> 01:16:02,224
emitted data set is received by another

1874
01:16:02,342 --> 01:16:04,308
cognitive entity on the other side of

1875
01:16:04,314 --> 01:16:06,404
the blanket and maybe it's person to

1876
01:16:06,442 --> 01:16:08,388
person, maybe it's computer to computer

1877
01:16:08,474 --> 01:16:10,816
or something mixed or some augmented

1878
01:16:10,848 --> 01:16:14,176
system, but there's a really tractable

1879
01:16:14,368 --> 01:16:16,904
and elegant way to talk about those

1880
01:16:16,942 --> 01:16:20,584
heterogeneous systems. So even if in the

1881
01:16:20,622 --> 01:16:24,008
local context one algorithm or another

1882
01:16:24,094 --> 01:16:27,144
outperforms another, there's going to be

1883
01:16:27,262 --> 01:16:29,556
an immense value for using active

1884
01:16:29,588 --> 01:16:32,236
inference and FEP to just talk about how

1885
01:16:32,258 --> 01:16:34,744
to compose these systems. And so that's

1886
01:16:34,792 --> 01:16:39,020
very important. Insight 100%

1887
01:16:39,090 --> 01:16:40,504
that's a really good point, Daniel.

1888
01:16:40,552 --> 01:16:43,784
Like very valuable. And it comes down,

1889
01:16:43,842 --> 01:16:45,456
I think fully agree with you. It comes

1890
01:16:45,478 --> 01:16:47,424
down to how do we phrase and think about

1891
01:16:47,462 --> 01:16:49,280
these even? And that's a challenge.

1892
01:16:49,620 --> 01:16:52,896
Even discussing what these systems are

1893
01:16:53,078 --> 01:16:55,436
and what they're showing is a challenge

1894
01:16:55,468 --> 01:16:57,012
right now. And we need to work on

1895
01:16:57,066 --> 01:16:58,676
building up that language together so we

1896
01:16:58,698 --> 01:17:00,516
can have those useful discussions and

1897
01:17:00,538 --> 01:17:02,420
figure out how to leverage this

1898
01:17:02,570 --> 01:17:04,388
distributed network that we're all I

1899
01:17:04,394 --> 01:17:07,716
think it's inevitable that you bring up

1900
01:17:07,738 --> 01:17:09,976
that's where we are and so we're only

1901
01:17:09,998 --> 01:17:11,720
going to go deeper down that direction.

1902
01:17:13,020 --> 01:17:15,304
Awesome. Just a little bit of some

1903
01:17:15,342 --> 01:17:18,124
questions on information as we head

1904
01:17:18,162 --> 01:17:21,768
towards the end. It was a very striking

1905
01:17:21,864 --> 01:17:25,244
finding about the changes in information

1906
01:17:25,362 --> 01:17:29,208
dynamics when gameplay was activated

1907
01:17:29,304 --> 01:17:32,352
versus rest as well as during learning.

1908
01:17:32,486 --> 01:17:34,912
And also that's kind of analogized by,

1909
01:17:34,966 --> 01:17:37,904
let's say, a person in an fMRI and

1910
01:17:37,942 --> 01:17:39,836
they're mind wandering, they're engaging

1911
01:17:39,868 --> 01:17:42,092
the default mode, and then some task

1912
01:17:42,156 --> 01:17:44,560
comes on and the information dynamics

1913
01:17:44,640 --> 01:17:46,996
sharpen and we associate that with the

1914
01:17:47,018 --> 01:17:51,380
mechanisms of attention. So how did you

1915
01:17:51,530 --> 01:17:54,244
measure or quantify the information or

1916
01:17:54,282 --> 01:17:57,384
what dot one informational measures mean

1917
01:17:57,502 --> 01:17:59,524
in the context of neural firing

1918
01:17:59,572 --> 01:18:00,440
patterns?

1919
01:18:02,860 --> 01:18:05,240
Yeah, that's a big question. And again,

1920
01:18:05,310 --> 01:18:07,384
it's something that we need to do more

1921
01:18:07,422 --> 01:18:09,176
work at diving into to actually and pick

1922
01:18:09,198 --> 01:18:11,784
about what it actually means at this

1923
01:18:11,822 --> 01:18:13,476
point, what we're limited to look,

1924
01:18:13,518 --> 01:18:16,008
well, that's not entirely true. We're

1925
01:18:16,024 --> 01:18:17,916
not led to it. What we did look at,

1926
01:18:17,938 --> 01:18:19,868
just for the sake of time and

1927
01:18:19,874 --> 01:18:22,028
complexity, were individual spikes in a

1928
01:18:22,034 --> 01:18:24,296
given location. And so you can arrange

1929
01:18:24,328 --> 01:18:26,816
that spatially and temporarily. And so

1930
01:18:26,838 --> 01:18:28,076
what we've looked at and we've dived

1931
01:18:28,108 --> 01:18:29,536
into this more work with our recent work

1932
01:18:29,558 --> 01:18:31,056
with Organoids as well, trying to pick

1933
01:18:31,078 --> 01:18:33,916
apart sort of the sub functional

1934
01:18:33,948 --> 01:18:36,044
subunits of computation or intelligence

1935
01:18:36,092 --> 01:18:38,896
or whatever word you want to use. But

1936
01:18:38,918 --> 01:18:40,596
yes, essentially what it is is it's the

1937
01:18:40,618 --> 01:18:42,340
pattern of activity you're seeing across

1938
01:18:42,410 --> 01:18:44,548
time and space for a given spike in a

1939
01:18:44,554 --> 01:18:48,390
location versus the other one. And so

1940
01:18:49,180 --> 01:18:50,728
there's a number of ways you can look at

1941
01:18:50,734 --> 01:18:52,264
this. I think the really exciting stuff

1942
01:18:52,302 --> 01:18:54,936
that's coming out is around sort of

1943
01:18:55,118 --> 01:18:58,090
trying to break apart. So people started

1944
01:18:58,780 --> 01:19:01,096
hodgkin huskily models, et cetera, they

1945
01:19:01,118 --> 01:19:02,616
looked at neurospiking and they were

1946
01:19:02,638 --> 01:19:04,616
like how does a single neuron spike,

1947
01:19:04,648 --> 01:19:06,028
what makes a single neuron spike? And

1948
01:19:06,034 --> 01:19:07,820
they came up with some rules that are

1949
01:19:07,970 --> 01:19:09,788
mostly true, but now we know are kind of

1950
01:19:09,794 --> 01:19:12,988
still wrong because many neurons

1951
01:19:13,004 --> 01:19:14,816
follow those rules and many do not. And

1952
01:19:14,838 --> 01:19:17,120
some are circumstance dependent.

1953
01:19:18,100 --> 01:19:19,836
And then people have sort of extended

1954
01:19:19,868 --> 01:19:22,050
that and they looked at how a given

1955
01:19:22,980 --> 01:19:25,008
system change its activity over time.

1956
01:19:25,094 --> 01:19:26,416
And then, of course, you can expand that

1957
01:19:26,438 --> 01:19:28,048
out and look at like, how do pairs of

1958
01:19:28,054 --> 01:19:30,196
neurons and then trios of neurons and

1959
01:19:30,218 --> 01:19:31,968
grow that up into a whole population?

1960
01:19:32,144 --> 01:19:34,244
And so what we've tried to do with this

1961
01:19:34,282 --> 01:19:35,568
work that I've sort of shared with you

1962
01:19:35,594 --> 01:19:37,064
today is look at that at a few different

1963
01:19:37,102 --> 01:19:38,744
levels and so depending the level

1964
01:19:38,782 --> 01:19:41,944
depends the exact answer to what is

1965
01:19:41,982 --> 01:19:46,372
information. But essentially

1966
01:19:46,516 --> 01:19:48,632
the simplest answer is it's the spikes

1967
01:19:48,696 --> 01:19:50,620
that we can see in this case going on

1968
01:19:50,690 --> 01:19:53,260
and their relationships to other spikes?

1969
01:19:54,240 --> 01:19:55,868
I don't know, Dean might have more to

1970
01:19:55,954 --> 01:20:00,236
expand on that. No, I think Beren I

1971
01:20:00,258 --> 01:20:03,424
think at some point we also as you

1972
01:20:03,462 --> 01:20:05,344
mentioned, we want to look at those

1973
01:20:05,382 --> 01:20:11,424
functional subunits, considering using

1974
01:20:11,542 --> 01:20:15,044
those main field models, using those

1975
01:20:15,082 --> 01:20:18,352
function units as neural

1976
01:20:18,416 --> 01:20:21,684
populations and then hopefully they

1977
01:20:21,802 --> 01:20:24,016
emergence like a few functional

1978
01:20:24,048 --> 01:20:26,320
subunits. And then can we look at

1979
01:20:26,410 --> 01:20:28,472
connectivity patterns using something

1980
01:20:28,526 --> 01:20:30,936
like a neural mass models which have

1981
01:20:30,958 --> 01:20:33,130
been used quite a lot,

1982
01:20:33,900 --> 01:20:35,764
something like a gentle width models,

1983
01:20:35,812 --> 01:20:38,810
but bit more dynamics in them.

1984
01:20:39,180 --> 01:20:42,076
And so that would be really interesting

1985
01:20:42,178 --> 01:20:46,008
to see how the patterns

1986
01:20:46,104 --> 01:20:49,564
are emerging, when neurons learn, how

1987
01:20:49,602 --> 01:20:52,190
the patterns are foraging patterns and

1988
01:20:52,560 --> 01:20:56,832
connections and how

1989
01:20:56,886 --> 01:20:59,776
these are changing over time as more and

1990
01:20:59,798 --> 01:21:02,224
more learning is happening. And that

1991
01:21:02,262 --> 01:21:05,440
would be something we are talking about

1992
01:21:05,510 --> 01:21:07,972
lots of unknowns and lots of very

1993
01:21:08,026 --> 01:21:10,052
interesting directions that one can

1994
01:21:10,106 --> 01:21:13,860
take, which makes it all exciting.

1995
01:21:14,840 --> 01:21:17,924
And I think our thinking also at least

1996
01:21:17,962 --> 01:21:19,624
my thinking has changed over the course

1997
01:21:19,662 --> 01:21:22,312
of looking at this. When I started out,

1998
01:21:22,366 --> 01:21:24,168
I kind of thought well, an individual

1999
01:21:24,254 --> 01:21:26,420
neuron is the smallest functional unit

2000
01:21:26,500 --> 01:21:27,944
theoretically, right? So that's probably

2001
01:21:27,982 --> 01:21:30,120
what's going on and then they'll connect

2002
01:21:30,190 --> 01:21:33,176
up and then I realized, well, I think

2003
01:21:33,198 --> 01:21:34,568
like, yeah, it is a single neurons, a

2004
01:21:34,574 --> 01:21:36,068
functional unit, but so are two neurons

2005
01:21:36,084 --> 01:21:38,280
and three neurons and the collective

2006
01:21:39,180 --> 01:21:40,928
exponential growth as you go out to

2007
01:21:40,934 --> 01:21:41,936
whole pattern. And at the end of day

2008
01:21:41,958 --> 01:21:43,836
when we look at actually at the levels

2009
01:21:43,868 --> 01:21:44,720
we Beren looking at, for example,

2010
01:21:44,790 --> 01:21:46,528
criticality, if you go look at a

2011
01:21:46,534 --> 01:21:48,876
preprint, we broke it down into areas

2012
01:21:48,908 --> 01:21:50,608
like sensory verse, motor areas and we

2013
01:21:50,614 --> 01:21:52,576
found that they all kind of behave more

2014
01:21:52,598 --> 01:21:54,876
or less the same. So does that mean that

2015
01:21:54,918 --> 01:21:56,928
under dish we have one functional unit

2016
01:21:57,024 --> 01:22:00,100
or 800,000 or everything

2017
01:22:00,170 --> 01:22:03,776
in between and looking at the organoid

2018
01:22:03,808 --> 01:22:04,996
stuff that we've moved to that that

2019
01:22:05,018 --> 01:22:07,024
we're not quite ready to share yet. But

2020
01:22:07,082 --> 01:22:09,160
I think what we can sort of start to

2021
01:22:09,230 --> 01:22:11,976
tentatively conclude from this work is

2022
01:22:11,998 --> 01:22:14,600
that it is indeed that answer of like

2023
01:22:14,670 --> 01:22:16,936
one to the combination of the

2024
01:22:16,958 --> 01:22:18,616
everything. And I think that's what

2025
01:22:18,638 --> 01:22:21,116
makes the biological systems and this is

2026
01:22:21,138 --> 01:22:22,636
why I emphasize it in my talk. Look at

2027
01:22:22,658 --> 01:22:25,420
the amount of connectivity and sort of

2028
01:22:25,570 --> 01:22:27,740
chaotic connectivity to some extent

2029
01:22:28,480 --> 01:22:30,436
that's occurring within these systems.

2030
01:22:30,568 --> 01:22:31,936
And that gives you something that we

2031
01:22:31,958 --> 01:22:34,624
can't model with neuromorphic or with

2032
01:22:34,662 --> 01:22:40,496
algorithms, with any degree of with

2033
01:22:40,518 --> 01:22:42,256
the same traits. At least I think I can

2034
01:22:42,278 --> 01:22:43,776
say without being too controversial with

2035
01:22:43,798 --> 01:22:45,764
the same traits. We can't yet model that

2036
01:22:45,802 --> 01:22:47,380
algorithmically yet. And I think that

2037
01:22:47,450 --> 01:22:49,110
makes it interesting as well.

2038
01:22:51,080 --> 01:22:54,020
Awesome. One just remark on that before

2039
01:22:54,090 --> 01:22:56,648
kind of a closing discussion. The

2040
01:22:56,734 --> 01:23:00,344
Hodgkin Huxley models were on

2041
01:23:00,462 --> 01:23:04,292
large single isolated neurons.

2042
01:23:04,436 --> 01:23:06,756
And so a theme I heard you say multiple

2043
01:23:06,788 --> 01:23:09,068
times was like the right tool or the

2044
01:23:09,074 --> 01:23:11,884
right model in the right concept. And so

2045
01:23:11,922 --> 01:23:15,020
when studying sodium and potassium flow

2046
01:23:15,440 --> 01:23:18,344
across the membrane of a single isolated

2047
01:23:18,392 --> 01:23:21,296
neuron, that is absolutely an

2048
01:23:21,318 --> 01:23:23,664
appropriate model and something that

2049
01:23:23,702 --> 01:23:26,896
provided immense insights. And then,

2050
01:23:26,918 --> 01:23:29,436
as you pointed out, especially if you're

2051
01:23:29,468 --> 01:23:32,384
interested in properties of systems and

2052
01:23:32,422 --> 01:23:34,900
connected neurons, it's like a yes,

2053
01:23:34,970 --> 01:23:38,496
and there are sodium flows.

2054
01:23:38,688 --> 01:23:41,556
But you could imagine concepts where

2055
01:23:41,658 --> 01:23:45,424
learning happens and the informational

2056
01:23:45,472 --> 01:23:48,436
pattern or the entropy of a given neuron

2057
01:23:48,548 --> 01:23:50,520
does change. Or it might not change,

2058
01:23:50,590 --> 01:23:52,136
but the pairwise relationship might

2059
01:23:52,158 --> 01:23:54,024
change. Or the pairwise relationship

2060
01:23:54,142 --> 01:23:56,200
might not change. But some higher order

2061
01:23:56,270 --> 01:23:59,452
relationship does change. And so that

2062
01:23:59,506 --> 01:24:03,112
doesn't replace mechanistic or smaller

2063
01:24:03,176 --> 01:24:06,748
subunit based models. But rather we

2064
01:24:06,834 --> 01:24:09,356
can broaden the discussion to thinking

2065
01:24:09,458 --> 01:24:12,176
even about the environment, like of the

2066
01:24:12,198 --> 01:24:14,912
dish or of our peripersonal space that

2067
01:24:14,966 --> 01:24:17,568
these cognitive systems are embedded in

2068
01:24:17,734 --> 01:24:19,852
and talk about distributed cognitive

2069
01:24:19,916 --> 01:24:23,156
functions without privileging the

2070
01:24:23,178 --> 01:24:26,288
ecological or the sort of atomic levels

2071
01:24:26,304 --> 01:24:29,396
of explanation. Yeah, absolutely. And

2072
01:24:29,418 --> 01:24:31,508
thank you for clarifying that if I sort

2073
01:24:31,514 --> 01:24:35,092
of implied otherwise. Awesome.

2074
01:24:35,226 --> 01:24:39,476
Just to highlight, because despite

2075
01:24:39,508 --> 01:24:41,796
the ring on the COVID of the active

2076
01:24:41,828 --> 01:24:44,632
inference textbook, there isn't a single

2077
01:24:44,686 --> 01:24:47,876
model to rule them all. And I think it's

2078
01:24:47,908 --> 01:24:50,584
really by getting into the particulars

2079
01:24:50,632 --> 01:24:53,628
of experiments and also by speaking with

2080
01:24:53,714 --> 01:24:55,196
researchers and by talking about this

2081
01:24:55,218 --> 01:24:57,084
kind of cutting edge research that we

2082
01:24:57,122 --> 01:24:59,688
see how pluralism in the methodological

2083
01:24:59,784 --> 01:25:03,068
and in the explanations actually plays

2084
01:25:03,084 --> 01:25:05,728
out. And that's just very exciting. So I

2085
01:25:05,734 --> 01:25:08,368
guess just a closing question and then

2086
01:25:08,374 --> 01:25:10,800
we can just have any other remarks.

2087
01:25:11,380 --> 01:25:14,224
Michael asks in the chat, what should

2088
01:25:14,262 --> 01:25:16,976
someone study or do to get more involved

2089
01:25:17,008 --> 01:25:19,184
with this research? I'm an undergraduate

2090
01:25:19,232 --> 01:25:21,156
student interested in pursuing this

2091
01:25:21,178 --> 01:25:23,204
field for my career and I'd love to work

2092
01:25:23,242 --> 01:25:24,500
with Cortical Labs.

2093
01:25:27,240 --> 01:25:29,396
I think it really depends the Brea you

2094
01:25:29,498 --> 01:25:31,064
want to go down. We're always looking

2095
01:25:31,102 --> 01:25:32,968
for good people to work with and as I

2096
01:25:32,974 --> 01:25:35,016
said, before. This is going to be a

2097
01:25:35,038 --> 01:25:37,608
whole industry and a whole field of

2098
01:25:37,614 --> 01:25:39,790
research. We hope and believe, anyway.

2099
01:25:40,960 --> 01:25:44,156
So I guess you should pick what it

2100
01:25:44,178 --> 01:25:46,088
is that interests you and what you're

2101
01:25:46,104 --> 01:25:48,764
passionate about. There's so much stuff

2102
01:25:48,802 --> 01:25:49,996
going on, right? You could study

2103
01:25:50,098 --> 01:25:51,712
electrical engineer, you could study

2104
01:25:51,766 --> 01:25:52,828
physics, you could study software

2105
01:25:52,844 --> 01:25:53,584
engineering, you could study

2106
01:25:53,622 --> 01:25:55,056
neuroscience, you could study stem cell

2107
01:25:55,078 --> 01:25:58,610
biology, anything in between.

2108
01:26:00,340 --> 01:26:03,440
These are multidisciplinary,

2109
01:26:04,040 --> 01:26:06,660
highly collaborative outputs.

2110
01:26:08,120 --> 01:26:10,276
I showed the team before. We have people

2111
01:26:10,378 --> 01:26:12,596
from all of those industries and others,

2112
01:26:12,778 --> 01:26:16,244
and it's only the combination of these

2113
01:26:16,362 --> 01:26:19,548
areas that give rise

2114
01:26:19,664 --> 01:26:21,800
to the chance to actually make something

2115
01:26:21,870 --> 01:26:23,508
that it's the gestalt, right? It's

2116
01:26:23,524 --> 01:26:25,656
greater than the sum of its parts. And I

2117
01:26:25,678 --> 01:26:26,648
think, honestly, that's one of the

2118
01:26:26,654 --> 01:26:28,920
reasons why we've had some success

2119
01:26:28,990 --> 01:26:31,284
coming from a sort of start up industry

2120
01:26:31,332 --> 01:26:34,268
focus, is that there's not that many of

2121
01:26:34,274 --> 01:26:35,950
us and we don't have that much money.

2122
01:26:36,400 --> 01:26:38,764
But what we do have is, like, an amazing

2123
01:26:38,882 --> 01:26:41,068
team of people to work with, amazing

2124
01:26:41,154 --> 01:26:43,390
collaborators, like a deal to work with,

2125
01:26:44,480 --> 01:26:46,464
and we can bring it all together in one

2126
01:26:46,502 --> 01:26:48,816
spot. And that's hard to do by its

2127
01:26:48,838 --> 01:26:50,176
nature. And academia, like, by its

2128
01:26:50,198 --> 01:26:52,256
nature, academia tends to silo, and you

2129
01:26:52,278 --> 01:26:54,272
have exceptions to that rule, of course.

2130
01:26:54,406 --> 01:26:56,164
You have very highly collaborative works

2131
01:26:56,202 --> 01:26:58,788
that do come out of academia, but they

2132
01:26:58,794 --> 01:27:00,900
are always I worked in academia.

2133
01:27:01,320 --> 01:27:02,644
They're always at a distance, those

2134
01:27:02,682 --> 01:27:04,164
collaborations. They're not all under

2135
01:27:04,202 --> 01:27:08,024
one roof with one goal and

2136
01:27:08,062 --> 01:27:09,080
one purpose.

2137
01:27:17,180 --> 01:27:19,308
Any general comments, feel free to

2138
01:27:19,314 --> 01:27:21,164
respond to that. And also just any

2139
01:27:21,202 --> 01:27:23,964
general thoughts you want to add? I was

2140
01:27:24,002 --> 01:27:25,580
to say I cannot recommend enough

2141
01:27:25,650 --> 01:27:28,460
cortical labs. They are highly

2142
01:27:29,360 --> 01:27:32,092
multidisciplinary team with expertise

2143
01:27:32,156 --> 01:27:35,676
from cell biology to software

2144
01:27:35,708 --> 01:27:38,124
engineering to real time interfacing,

2145
01:27:38,172 --> 01:27:41,164
to computational models and machine

2146
01:27:41,212 --> 01:27:45,108
learning. So anything that

2147
01:27:45,274 --> 01:27:47,412
your expertise and you want to do,

2148
01:27:47,466 --> 01:27:49,588
there would be something that's there

2149
01:27:49,674 --> 01:27:51,300
and really cutting edge,

2150
01:27:53,960 --> 01:27:56,744
I think. There's this whole project, it

2151
01:27:56,782 --> 01:27:59,704
just shows the whole breadth of things

2152
01:27:59,742 --> 01:28:02,804
that we can do, from neurons to sentient

2153
01:28:02,852 --> 01:28:05,304
behavior. And I'm cutting my back for

2154
01:28:05,342 --> 01:28:08,036
saying sentient sentence today, which

2155
01:28:08,078 --> 01:28:09,710
hasn't been Sajid.

2156
01:28:11,680 --> 01:28:15,164
And I should say Brea is also leading a

2157
01:28:15,202 --> 01:28:18,184
project on that site, which we didn't

2158
01:28:18,232 --> 01:28:22,004
get chance to talk about, the nonclature

2159
01:28:22,072 --> 01:28:24,256
and all that. That happens with the

2160
01:28:24,278 --> 01:28:26,572
semantics of sentence and consciousness

2161
01:28:26,636 --> 01:28:32,496
and agency and all that and

2162
01:28:32,518 --> 01:28:34,450
the whole ethic side of thing.

2163
01:28:35,460 --> 01:28:38,516
There are big opportunities and

2164
01:28:38,538 --> 01:28:41,344
questions open, challenges.

2165
01:28:41,472 --> 01:28:45,172
And I think actually do you make a

2166
01:28:45,226 --> 01:28:46,500
good point. I should use this

2167
01:28:46,570 --> 01:28:49,124
opportunity, if I may, Daniel, at least

2168
01:28:49,162 --> 01:28:50,896
a two flag. Yeah, we are we are engaging

2169
01:28:50,928 --> 01:28:53,784
in a number of paper, so if you are

2170
01:28:53,822 --> 01:28:55,304
interested in the words that we use,

2171
01:28:55,342 --> 01:28:56,456
whether you think that we use them

2172
01:28:56,478 --> 01:28:58,648
correctly or incorrectly, we would

2173
01:28:58,654 --> 01:29:00,320
invite anyone. We've made these offers

2174
01:29:00,340 --> 01:29:01,756
before, but it's a great place to say it

2175
01:29:01,778 --> 01:29:05,276
again, reach out. We are setting up,

2176
01:29:05,298 --> 01:29:07,340
and we will have a formal invitation

2177
01:29:08,080 --> 01:29:10,524
somewhat soon. I can't exactly say when

2178
01:29:10,562 --> 01:29:11,868
because there's so much going on at the

2179
01:29:11,874 --> 01:29:13,056
moment, but fairly soon we'll have an

2180
01:29:13,078 --> 01:29:15,696
invitation. Come join us. Let's work

2181
01:29:15,718 --> 01:29:16,976
together and just figure out what

2182
01:29:16,998 --> 01:29:18,850
language we want to use as a community,

2183
01:29:19,300 --> 01:29:22,480
because then we can move towards

2184
01:29:22,550 --> 01:29:24,208
actually building some stuff instead of

2185
01:29:24,214 --> 01:29:25,376
just being caught up with, like, what

2186
01:29:25,398 --> 01:29:27,748
does this word mean? And that's going to

2187
01:29:27,754 --> 01:29:29,076
be necessary. So, yeah, please. Great

2188
01:29:29,098 --> 01:29:32,068
chat to us. Yeah. I'll just note one

2189
01:29:32,154 --> 01:29:34,196
project at the Institute, which is

2190
01:29:34,218 --> 01:29:36,664
active coherence lab ontology where

2191
01:29:36,702 --> 01:29:39,096
we've been developing definitions and

2192
01:29:39,118 --> 01:29:41,880
also translations across languages of

2193
01:29:41,950 --> 01:29:44,824
core and supplemental terms, and we use

2194
01:29:44,862 --> 01:29:47,508
that to annotate papers. We make natural

2195
01:29:47,524 --> 01:29:49,656
language descriptions of mathematical

2196
01:29:49,688 --> 01:29:52,652
formalizations, and we totally agree

2197
01:29:52,706 --> 01:29:55,720
that ontology based systems engineering

2198
01:29:55,880 --> 01:29:58,200
for active inference, cyber, physical

2199
01:29:58,280 --> 01:30:01,208
systems is how we're going to treat this

2200
01:30:01,314 --> 01:30:03,936
with the respect. And also bring in the

2201
01:30:03,958 --> 01:30:06,396
discussions around ethics, philosophy

2202
01:30:06,428 --> 01:30:08,844
and so on. So this isn't a linguistics

2203
01:30:08,892 --> 01:30:11,344
debate that excludes other Fields. This

2204
01:30:11,382 --> 01:30:14,416
is like laying down the dance floor so

2205
01:30:14,438 --> 01:30:16,396
that we can actually have a discussion

2206
01:30:16,428 --> 01:30:18,512
that's inclusive and meaningful going

2207
01:30:18,566 --> 01:30:20,390
forward, which is what is so important.

2208
01:30:21,400 --> 01:30:22,996
That's awesome. I got to look force

2209
01:30:23,018 --> 01:30:24,276
stuff. I didn't know that you guys had

2210
01:30:24,298 --> 01:30:25,156
one of those. I'm going to have a look

2211
01:30:25,178 --> 01:30:27,416
up later. I'll send it to you in an

2212
01:30:27,438 --> 01:30:30,104
email. Well, thank you so much. What an

2213
01:30:30,142 --> 01:30:34,040
awesome line of research and a December

2214
01:30:34,540 --> 01:30:38,360
surprise or treat for us. So super

2215
01:30:38,430 --> 01:30:40,456
exciting. And please always feel welcome

2216
01:30:40,558 --> 01:30:43,880
to just reach out and join for any other

2217
01:30:43,950 --> 01:30:46,664
time. Awesome. Thank you so much,

2218
01:30:46,702 --> 01:30:48,168
Daniel, for having us and everyone

2219
01:30:48,254 --> 01:30:51,360
watching. All right, bye bye. Thank you.

2220
01:30:51,430 --> 01:30:51,676
Bye.


