start	end	speaker	sentiment	confidence	text
170	1150	A	0.8720964789390564	Hello and welcome.
1300	10142	A	0.8725501298904419	It's September 15, 2023 and we're at the Active Inference Institute in active guest stream number 56.1.
10276	20110	A	0.902710497379303	Today we have Gregory Sargent Petri and we'll be hearing a talk followed by a discussion on geometry of world model influences behaviors.
20450	27478	A	0.9164189696311951	First there'll be a presentation and then any comments that people have in the live chat or any other questions.
27564	28582	A	0.9588078260421753	It will be great to talk.
28636	33174	A	0.9910315275192261	So thank you a lot for coming, really looking forward to this.
33292	35320	A	0.7167054414749146	So please to you.
36250	42554	B	0.9901200532913208	Thank you very much, Daniel, for the invitation first, it's really very happy to be able to present this work here.
42592	63214	B	0.7451749444007874	So it's a work around some models of consciousness, at least some computational models of consciousness, some part of consciousness, and how it can help to generate different kind of behaviors, especially when we think about, let's say, artificial agents.
63412	65702	B	0.824923038482666	So I'm Gregor Santui.
65706	71742	B	0.798568844795227	It's a work in collaboration with david Rodrof, kenneth willie Ford, Daniel Benka.
71806	73714	C	0.6187845468521118	In fact, it's not just one work.
73752	79250	B	0.8970818519592285	It'S a collection of works that have been on for already around ten years.
79320	80534	B	0.8481324315071106	So if you want to know more.
80572	89462	C	0.7112470269203186	About this group and the work that we're doing, you can go on the page, on my personal Web page, and there's a link to PCM HTML, and.
89516	91466	B	0.8648341298103333	There'S a summary of all the work.
91488	95626	C	0.868226945400238	We'Ve been doing and some summary of.
95648	100354	B	0.5811767578125	The work we've been doing and also of some articles that can be relevant on this subject.
100502	104842	B	0.683994710445404	So today we'll focus more particularly on two articles.
104986	127590	B	0.7822628617286682	So one that is accepted and will appear very soon, the other one need to resubmit, which give formulation of, let's say, autonomous agents or let's say mathematical formulation of agents that have a world model that is structured geometrically in such a way that this world model captures some features of consciousness.
127930	130760	C	0.8839898705482483	So the first article is, let's say.
131450	134566	B	0.7703218460083008	The review of the experimental results that.
134588	136642	C	0.8754748106002808	We have and the most recent formalism.
136706	148682	B	0.770649254322052	That we have on our work, which is the literature on POMD partial cerebral stream process, which is optimal control, stochastic optimal control.
148736	149818	B	0.6492434144020081	And we just try to tweak a.
149824	153206	C	0.8386877179145813	Bit this formalism to introduce the ideas.
153238	156654	B	0.8529698848724365	With how you can include inside of the world model of the agent some.
156692	159006	C	0.8368937373161316	Ideas on consciousness and still continue to.
159028	162462	B	0.8293554782867432	Have algorithms to do inference to find optimal policies and everything.
162596	181554	B	0.8763422966003418	The Zecholia article focuses more particularly on how changing the world model of the agent can change its behavior, in particular the relationship, the geometry of the world model, the way that it perceives its environment and the way it acts with respect to for agent strategy.
181602	185334	B	0.8591350317001343	So the way that it looks for something, so it will change its behavior in looking for something.
185452	187238	C	0.8852025866508484	So I will start by presenting a.
187244	189314	B	0.7362041473388672	Bit what are all these terms?
189372	191114	B	0.806656002998352	So, world model, why you need it.
191232	193050	C	0.8339664936065674	What is a foraging strategy?
194190	198010	B	0.8026281595230103	How can you define an agent that is looking for a certain object?
198160	204218	B	0.9042171835899353	In particular, what is an exploration based on Curiosity or let's say more technically epistemic value.
204384	210240	B	0.8477275967597961	So let's consider the setting where you have, let's say, a real world, so that's the space that surround us, 3d space.
210930	217166	B	0.8987799286842346	You do a setup where you have an agent which is, let's say, a solid it has a solid frame, so it has a center three axis.
217198	219230	B	0.856987714767456	What is in front, what is on its side, what is above?
219310	220146	B	0.5848218202590942	Above it.
220248	225310	B	0.8751550316810608	And it's looking for an object O, which is itself a solid inside of R three.
225400	238470	B	0.885058581829071	And all the configuration of the agents and the objects they are defined by, let's say, a reference frame that is external and that characterizes completely their configuration inside of this world.
238620	243610	B	0.8574848771095276	Now, the agent A, what it wants to do is to find for the object O.
243760	248778	B	0.7378889322280884	But it can only have some noisy observation of where the object O is.
248864	272014	B	0.8955177068710327	So to be able to find O, it needs to have some atriorian where O should be to be able to plan the consequences of its actions with respect to where O will be once it has moved and to update, to be able to plan how the observation can act with respect to updating its prior.
272062	275650	B	0.8133885860443115	So, in another words, so you have an agent and the agent is looking for O.
275720	277170	B	0.7506591081619263	It thinks that O is, for example.
277240	278306	C	0.8434825539588928	In this direction, on the right.
278328	280610	B	0.8795512318611145	So it's going to move towards the right and makes an observation.
280690	284182	B	0.6815016269683838	If it doesn't see O, it's going to change its belief on where O is.
284236	289766	B	0.8306533098220825	So this is a very standard formalism that you can find like in POMDP stochastic optimal control.
289948	310574	B	0.8653164505958557	But the one other point we want to really emphasize is the fact that the agent A has its own frame of reference and the way that it's going to give the coordinates of the object, the way that it will trace where the object is, is using its own way of computing the coordinates of O.
310612	313102	B	0.8309875130653381	So it has its own way to measure where O is.
313156	319698	B	0.8331403136253357	So it doesn't have to refer to a global frame, a global coordinate system, to be able to know where O is.
319784	322754	B	0.6130520105361938	So for example, I am always centered on myself.
322952	325794	B	0.793924868106842	When I move, I see the object.
325992	329862	B	0.7953011989593506	I don't think about me moving, but I think about the object moving.
329916	332274	B	0.8314223885536194	And this is because when I move, I change my frame.
332322	336546	B	0.8953474760055542	So the way I'm going to reference the object is going to change accordingly.
336658	345174	B	0.8472669720649719	And the point we want to introduce is the fact that you can have several ways for the agent to define its own coordinate system with respect to its environment.
345222	350554	B	0.6950450539588928	And this is a key feature that we want to capture in terms of modeling.
350602	356074	B	0.8367487788200378	But also we think that it is something that is very structuring with respect to models of consciousness.
356202	358800	B	0.8638835549354553	Because when you consider more generally an agent.
362470	364162	C	0.7843239307403564	Let'S say, that has a world.
364216	371842	B	0.8674682378768921	Model in which it has its own point of view perspective on this world model.
371976	380758	B	0.8289417624473572	You kind of start tackling the problem of how to introduce a point of view on the environment of the agent.
380844	387590	B	0.8606608510017395	How can you introduce, in the way that it is going to encode its environment, a certain point of view?
387660	389586	B	0.8243758678436279	And in particular, if you think about.
389628	392186	C	0.8132150173187256	It in terms of the role of.
392208	397494	B	0.8096835017204285	Space to be able to take into account your own perspective on the environment.
397542	403360	B	0.5943893790245056	You can see that if you take away everything that fills up the space, you keep just the space itself.
406130	414478	B	0.8635716438293457	The space allows you to, let's say, to structure the way that you are going to fill in some information about the environment.
414574	429766	B	0.8389023542404175	And it's centered on your own point of view in a way that when you're going to act, you're still going to keep the unfilled space, you're still going to keep the same way of modeling this space.
429868	432086	B	0.7964737415313721	The space will stay the same when you move.
432108	434038	B	0.8074327111244202	When I move, the space is the same.
434204	441126	B	0.6991965174674988	But I took into account the fact that I can move from one point to another in this space without changing the space.
441228	447002	B	0.596511721611023	And something that is also very important is that with respect to any movement that I can do, the space doesn't change.
447056	449322	B	0.7838892936706543	So there's no particular point in space.
449376	451260	C	0.8564826846122742	With respect to the movements that I do.
453390	463534	B	0.8180652260780334	Another property that is very similar is that instead of considering just my actions and the way that I can change my frame while I'm doing an action, you can also imagine taking the frame of somebody else.
463652	473890	B	0.8104254603385925	So it means that you see that the space that you use to be able to structure your environment doesn't change when you take the perspective of somebody else.
473960	494918	B	0.8476210236549377	For example, if you imagine yourself as a solid agent changing by a rotation your own solid frame and translating, okay, so this is something that we will use in fact as a definition for the state space, the way that the agent encodes its environment.
495014	511390	B	0.7217738032341003	And you will see that there's a natural notion that encodes this idea that you can change perspective on your environment, on the world model that you have of your environment, simply by introducing something that's very well known, which is the notion of a group acting on a certain space.
511540	514414	B	0.886149525642395	So this is just to sum up a bit what we're trying to do.
514452	532360	B	0.8162517547607422	So we're just trying to do like exploration inside of an environment, but we're adding additional information, which is that the way the agents is going to encode its environment takes into consideration the fact that it can change its reference frame on this space without singling out any point.
533290	538418	B	0.899052619934082	Okay, so what do we mean by perspective taking more precisely?
538594	540650	B	0.7975559234619141	So how do we go from the real world?
540720	550874	B	0.8842736482620239	So let's say the world described by the external frame that allows you to say the agent is here and the object is here from the internal world of the agent.
550992	556938	B	0.8656885623931885	So you just define a map that will take into consideration that the agent can have a first perspective on its environment.
557034	563860	B	0.8521838188171387	The simplest case in the Euclidean case is just rewriting the coordinates of O inside of the frame of the agent, reference frame of the agent.
564310	569682	B	0.8768283724784851	And then once the agent moves, its frame solid frame in the real world changes.
569816	576630	B	0.5910273194313049	And this induces indeed a transformation inside of its internal world, which will lead in a fine transformation.
577850	581602	B	0.864932656288147	Okay, but you could imagine also having other transformations.
581666	585800	B	0.6486524939537048	I don't know if you can see my mouse probably.
586330	588118	B	0.8242768049240112	Can you see my mouse or not?
588284	588614	B	0.4936186671257019	No.
588652	597062	B	0.7222627401351929	Okay, so the map CSI can also be something else than an affined transformation.
597206	599702	B	0.8182665109634399	It could be like any kind of transformation.
599846	604862	B	0.8294621706008911	For example, in an affined case, the apparent volume of the object doesn't change.
604916	614370	B	0.8721949458122253	But if you change this map and consider, for example, a projective transformation, as we will describe later, you can have that the size, apparent size of the object changes.
614520	617106	C	0.7001153826713562	So we went from something that is.
617128	622706	B	0.5620882511138916	A bit already very well known and not very innovative, which is that you.
622728	623810	C	0.7147538065910339	Can rewrite.
625530	627878	B	0.8111922740936279	The motions, depends on the.
627884	629846	C	0.6509100198745728	Frame that you choose to describe them.
630028	638460	B	0.8753088116645813	Into, saying that you can in fact change some frames to be able to account for some perceptive property.
639870	648890	B	0.8853437304496765	And what we ask also for the agents that we consider is that they can imagine the consequences of their moves, which on their future observations.
649310	660074	B	0.8754093050956726	So this is something just to say that the agents that we consider have a notion of agency, which is that they can plan the consequences of their actions so that they can choose the best action with respect to a certain reward.
660122	662474	C	0.7846027612686157	In particular, the reward that we consider.
662612	665810	B	0.7701030969619751	Is trying to maximize a certain surprise.
669270	673806	B	0.8520222306251526	So to sum it up, we have an agent that is looking for certain objects.
673838	676758	B	0.8445720672607422	So it has beliefs of where this object is.
676844	681622	B	0.7572141885757446	And the beliefs lives on an internal state space.
681676	697590	B	0.8852282762527466	So on a world model of the environment, it can make observation, which allows it to update its beliefs and then it can predict the consequences of its actions so that it can plan the way that it should act with respect to a certain objective.
697670	703650	B	0.8680676221847534	So formally, this is simply the notion of Markov decision process, or more generally, like the notion of partially observable Markov.
703670	706270	C	0.485492080450058	Decision process because we do not have.
706340	713146	B	0.8125759959220886	A complete information of the environment, but only some observations that are limited.
713338	716170	B	0.7577426433563232	And it's very related.
716250	717440	C	0.784932553768158	And let's say.
719830	723726	B	0.8145328164100647	There'S a strong duality between POMDP and active inference.
723758	725940	B	0.5198003649711609	So there is really a strong link between both.
727350	735670	B	0.8669784069061279	So now what I did in the way that I presented it so I presented it the idea I tried to present the idea of what we're doing.
735740	739018	B	0.8364645838737488	So the general context POMDPs agents that.
739024	741894	C	0.8737392425537109	Are planning their action with respect to a certain objective.
741942	743658	C	0.8101137280464172	Here the objective is to find a.
743664	751766	B	0.913923442363739	Certain object and I give the formal setting for defining it which are NDP PMDP.
751798	767026	B	0.778078019618988	And now I will go one step further and define it explicitly and I will continue like this approach for the second part where I will also present our results and our specificity, where I'll dealt with a general statement, then a bit more precise and then really digging into the result.
767208	776018	B	0.883834719657898	So here the classical way to define a Markup decision process is to consider that you have a set of configurations of the environment, which is the state space or of the world model in.
776024	777186	C	0.7089264392852783	The way, or at least the way.
777208	778802	B	0.6731096506118774	That you encode your environment.
778946	785910	B	0.8475977778434753	So this is something on which you can act, because the agent, when it makes an action, it changes the state of the environment.
786490	791498	B	0.8706380724906921	And the way that the actions change the environment is with respect to a.
791504	797446	C	0.8483874201774597	Certain Markov kernel, probability kernel.
797558	802102	B	0.7857526540756226	So it's stochastic, which means that each actions changes the state of the environment.
802166	803622	B	0.6392821669578552	But you don't know completely.
803776	805098	B	0.6473371386528015	It's not deterministic.
805194	816546	B	0.5646629333496094	You allow some errors in the way that it acts on the environment, and you have a reward for a function that is associated to the actions that you can do at time T and also the state of the agent at time t.
816728	822594	B	0.5709986686706543	A partially observable Markov decision process is the same thing than a Markov decision process.
822792	834242	B	0.5743816494941711	But you authorize to say that your observation on your environment are only partial, which means that you do not have a precise information on the state of the environment.
834386	848710	B	0.8703921437263489	So the way that you need to relate observation and states is through also a probability kernel, which tells you that if you're at state, for example S, you would expect to make a certain observation.
848870	864334	B	0.5376413464546204	Let's say if you think the object is at X, you expect to see the object at X, but with a certain error because you know that your sensors are also random, they can make some mistakes and you keep similarly a reward function.
864372	874900	B	0.6402134299278259	So it's the same thing that an MDP mark audition process, but you just allow to have some to get information on your environment through observations that are not complete.
875610	880194	B	0.8795825839042664	In fact, there's a formulation in terms of partially observable Markov decision processes.
880322	896714	B	0.8534896373748779	Our particular case of Markov decision processes, which is called belief MDPs, belief Markov decision process and the only difference that you have between Markov process and belief MDP is the fact that the state space is necessarily continuous in the second case.
896752	899930	B	0.6448411345481873	So POMDPs can be seen as a particular case of MDPs.
901230	911882	B	0.8527844548225403	So we said that the actions of a POMDP act on the state space and you account for the consequences of the actions only through observations.
912026	922946	B	0.8718448877334595	So graphically it means that you have the state space of your so the world model of your environment X on which you reference for example, where the object is.
922968	930134	B	0.8708682656288147	So the position of the object and then when you act it induces a consequence on the position of the object at time t plus one.
930172	940150	B	0.8811163306236267	And then you can make an observation of where you think the object will be or you can make an observation with respect to where the object is, depending if you're planning into the future or if you're really doing the action.
941210	943286	C	0.8241083025932312	You'Re implementing the consequence of the actions.
943318	944426	B	0.8138414621353149	In the real world.
944608	950726	B	0.8120543360710144	The thing that we're trying to do in our setting is to replace simply the actions by a change of perspective.
950838	956542	B	0.8516955375671387	Like I told you, when the agent acts, its coordinate system on the environment changes.
956676	962282	B	0.8425253033638	So you can always see it in a way passively, where you just see it as a change of coordinates.
962426	975070	B	0.7943434715270996	So we want to say that instead of considering actions on the environment, we have a space on which there's a natural notion of changing of reference frame and actions are simply certain kind of changes of frames.
975230	980482	B	0.5124845504760742	We also allow to have some actions that do not correspond to changes of frames.
980546	992842	B	0.8976780772209167	We just say that we include the possibility that some actions are changes of frames and the changes of frames have something that is related to all the transformations that are internal for the agents.
992976	1000810	B	0.8729038834571838	So for example, things that it knows that a priori, it's encoded in the way the agents will interact with the environment.
1002050	1010800	B	0.7871495485305786	So the way that we do it a bit more formally is that we say that changing perspective is simply through the action of a group.
1011410	1022786	B	0.888327419757843	So for example, in the affine case, when the agent moves, a change of frame is an affine transformation and we say that the world model.
1022888	1027298	B	0.8007216453552246	So the state space is simply a space on which the group acts.
1027474	1032806	B	0.88773113489151	So formally, what does it mean that the group acts on the space?
1032908	1038600	B	0.8060208559036255	It's just saying that you have a space.
1038970	1041626	B	0.7008382678031921	S group g.
1041728	1046970	B	0.8940047025680542	There's an application that goes that takes an element from g and S and that sends back S.
1047040	1049802	B	0.7925660014152527	In other words, for every g you can associate a function.
1049856	1050778	B	0.7350568175315857	From s to s.
1050864	1055886	B	0.785332441329956	And you assume also that it has good properties, which is that it satisfies equation one and.
1055908	1057966	C	0.7933544516563416	That if you don't move, you stay.
1057988	1058958	B	0.7525796294212341	At the same place.
1059124	1063858	B	0.8368344902992249	So this is like just the notion of a g space, a group acting on space.
1064024	1083090	B	0.870287299156189	But now if we want to include this in MDPs and POMDPs, we just assume that the state space is a g space, that some actions are some elements of the group, and that when we choose the actions that corresponds to the element of the group, it corresponds to the way that the group acts on the element.
1083170	1086546	B	0.5109034776687622	So there is nothing like very convoluted.
1086578	1088166	B	0.7716611623764038	It's just saying that you define the.
1088188	1090410	C	0.7429847121238708	Collection of functions which you see as.
1090480	1092938	B	0.7929593324661255	Changes of frames and the way that they act.
1093024	1095834	B	0.7892459630966187	So the probability kernel from the state.
1095872	1098346	C	0.8128440380096436	Space to the state space at time.
1098368	1107200	B	0.8639776706695557	T to time t plus one after the action, after the change of perspective is simply through the way that the function changes the state space.
1107570	1110026	B	0.8199021816253662	So it's just kind of a way of reformulation.
1110058	1117374	B	0.5400463342666626	But what is really hidden behind here is that we have the structure of the group and that we don't consider any kind of actions.
1117422	1121090	B	0.8678356409072876	We assume that there is more structure in the actions that we can consider.
1121160	1128754	C	0.7788809537887573	And that it's defined in the way that it's encoded inside of the geometry.
1128802	1130006	B	0.6939934492111206	Of the space that we have.
1130108	1132630	B	0.7829487919807434	So we don't separate any more action and state space.
1132780	1139826	B	0.9052770137786865	We say that the state space in its geometry encodes already certain kind of actions which are its change of perspectives.
1139938	1141546	B	0.8224721550941467	So there are two case that we consider.
1141648	1146086	B	0.8415362238883972	The first case is where the state S is the Occlusion space and g, the FN transformation.
1146118	1157040	B	0.8933436870574951	It corresponds to translations and rotations of the agents and changing rewriting the coordinates of the object inside of the solid reference frame of the agent.
1157410	1164770	B	0.8570389151573181	And the second case where the space space is a projected space and the group is a projected transformation.
1166710	1179922	B	0.842287540435791	We described what are the generative models that we consider and how we can include inside of the classical theory of POMDPs the fact that you can take a perspective on your environment.
1180066	1193046	B	0.8034536242485046	Now we will introduce like a classical notion of epistemic value which will allow us to define what is behavior, what is an exploratory behavior with respect to curiosity.
1193158	1198970	B	0.7565218806266785	So what it is for an agent to explore its environment based on curiosity.
1199890	1222946	B	0.8424390554428101	So curiosity, or let's say the drive for exploration is quantity that will it's, it's a quantity that you will okay, so it's, okay it's so how do you define it?
1222968	1225150	B	0.7603426575660706	Just with like very generally.
1225310	1237830	B	0.8822128176689148	So you start with the agent has a prior on the state of its environment, then it plans the consequence of one of its move at the next time, at the next time step.
1237900	1242566	B	0.8106473684310913	So this changes the prior that it has on the environment because there's an action on the environment.
1242598	1247370	B	0.868675947189331	So we get a new prior and now it's going to make an observation.
1247870	1250646	B	0.8293426632881165	So it imagines that it's going to make an observation.
1250758	1256186	B	0.869313657283783	Once it makes an observation there's an apostrophe, the prior is updated.
1256218	1257546	B	0.6313089728355408	So you get an apostrophe.
1257658	1270206	B	0.8825398087501526	The way that you define curiosity or let's say epistemic value is how informative is the observation that you will do, how far is the apostrophe from the Apuri?
1270318	1278546	B	0.6585409641265869	But you cannot do it for one given observation because the way that you compute it is by planning what will happen at the next step.
1278568	1281670	B	0.8536492586135864	So you need to consider all the possible observation that you will make.
1281740	1291980	B	0.8818334341049194	So the observations are themselves stochastic with respect to the way that you consider with respect to a priori on the state space of a time t.
1293790	1297910	B	0.8736884593963623	As we said, forest actions are changes of frame.
1297990	1308670	B	0.6790544390678406	So we can also define epistemic value for frames for changes of frames and in particular something that we gain, that is I think interesting is that now we have a function that is defined.
1309090	1311262	C	0.7126322984695435	On a group that can be a continuous group.
1311316	1317038	B	0.8579216599464417	So you can allow to have for example, if you want to maximize it, you can or minimize it, I mean.
1317044	1318340	C	0.7262939810752869	It depends how you see it.
1318790	1326950	B	0.5466875433921814	You could do gradient descent for example, so you can have more analytical tools because you're on a space that is continuous and has some structure.
1327770	1338614	B	0.9110997319221497	So now to give the formal definition of epistemic value, so as I said, it's based on the quantity C that I will define now.
1338812	1344246	B	0.8690464496612549	So if you give yourself a prior on a space x and you give yourself a probability kernel.
1344278	1351580	B	0.8585264682769775	So a stochastic map from X to Y, stochastic map is simply saying that for any x you will associate a measure on Y.
1353330	1360510	B	0.8798590898513794	Then you can get a joint distribution on x and Y, which is simply given by the product p y knowing x times the prior.
1361330	1377590	B	0.9000702500343323	And in fact the quantity C is simply the mutual information between x and Y, which is saying how far is the joint distribution with respect to the independent distribution, the product of the marginal distribution on X and on Y.
1377740	1382118	B	0.768867015838623	But this is like you see it appears everywhere the mutual information.
1382284	1388920	B	0.9236000776290894	So this formulation is based on the paper that is from fiston and all active inference and the Pacific value.
1389690	1391586	B	0.831880509853363	Mutual information is something that appears everywhere.
1391618	1392694	C	0.7821730375289917	But I think that there's a very.
1392732	1399926	B	0.7909536361694336	Nice re expression of the mutual information which allows to give a better interpretation of this quantity, which is the interpretation.
1399958	1401766	C	0.8969906568527222	That I was discussing in the previous slide.
1401878	1414946	B	0.8511168956756592	So if you rewrite mutual information, you can always see it as the coolBACK lyler distance between the Aposterior for a given observation and the prior coolBACK distance being a way of computing how far you are, how far the two distribution are.
1415048	1418770	B	0.8312601447105408	But you need to look at the expectation with respect to the observation that you make.
1418840	1421060	B	0.7780852317810059	So it's exactly what I was discussing before.
1422870	1431800	B	0.9040258526802063	So then this is like for any kernel, any kernel from x to Y with a prior on x.
1432250	1440586	B	0.8902226686477661	But as we were discussing here, you have to take into so this would be the kernel, but you have to take into consideration that you can do actions and that your prior R on X.
1440688	1454094	B	0.892431378364563	So the way to compute epistemic value for this kernel here when having only the prior on x is that you propagate the prior by the action on x one.
1454212	1466574	B	0.8612232208251953	Then you get a prior on x one and you can define the epistemic value for this prior and Markov kernel which corresponds to the randomness of your sensors which is always fixed.
1466622	1478440	B	0.691487193107605	And this is very important, this one doesn't change even if you change frames, the kernel that you have relating your prior, what you think about the state space relating the state space and the observation never changes.
1479450	1491642	B	0.9029899835586548	And so explicitly this means that after a certain action or after a certain change of frame, you get a joint distribution on x and y, which is the following one here.
1491696	1501094	B	0.8934926986694336	So this corresponds to the prior propagated on x one and then the epistemic value is simply the mutual information of this joint distribution.
1501222	1503342	B	0.6971778273582458	So now how does the algorithm work?
1503476	1513810	B	0.8962886929512024	The algorithm that corresponds to defining an exploratory behavior for an agent that is looking for so we started with a prior of where O should be.
1513960	1525410	B	0.749092161655426	Then you maximize curiosity based on some changes of frames that are around the identity elements which correspond to not changing frame.
1526230	1537762	B	0.879368007183075	Then you get an action that you can apply, you propagate the prior to the next step with this action and then you just update your Apiori with respect to a certain observation and then it loops back.
1537836	1550438	B	0.9107028841972351	So this is the algorithm that we consider in the second paper that was listed in the presentation, which corresponds to having an agent that is looking for a certain object.
1550624	1565278	B	0.8412397503852844	Its behavior is defined by an exploratory, is driven by exploration, driven by curiosity, taking into account that its state space is structured by the action of a.
1565284	1569198	C	0.7676433324813843	Group, so that its state space is structured by the fact that it corresponds.
1569214	1572894	B	0.8253531455993652	To all the possible ways of changing frames.
1572942	1579430	B	0.8526496887207031	So it has inside of the state space, inside of the geometry of the state space, all the possible ways of changing frames.
1582250	1585814	C	0.8029916286468506	And this is like explicitly what we do.
1585852	1587846	C	0.8398445248603821	So in this context, this is the.
1587868	1591802	B	0.8343621492385864	Algorithm that we consider and nothing else, then we get a very interesting result.
1591856	1595418	B	0.887546181678772	At least I find it's interesting in.
1595424	1596906	C	0.7826175093650818	The way that it's presented here.
1596928	1597738	B	0.9068445563316345	I find it interesting.
1597824	1603726	B	0.8522617816925049	And then if you go more into detail it's because the Ecclesian case is very particular.
1603828	1622494	B	0.8569490909576416	But what you get is that if you look at the behavior of an agent that is driven by exploration, by curiosity, but that has state space structured by Ecclesial transformation.
1622542	1640822	B	0.8373861908912659	So the first case where the agent is simply encoding its environment in its reference frame but nothing else, then it doesn't need to move in the second case, where the changes of charts are given by projective transformations.
1640886	1654254	B	0.8704252243041992	So the way it's encoded it's in transformation takes into account a projective deformation of its environment, then it will always try to get closer to the object.
1654372	1657466	B	0.766565203666687	So you have two very separate behaviors.
1657658	1663970	B	0.970740020275116	So this is something that is I think is very interesting to note.
1665830	1686546	B	0.6962389349937439	So before going into the details of how you can prove this statement, I will say a bit more about why it's an interesting perspective point of view on this subject because and how it goes a bit further than simply considering this very simple setting.
1686738	1700140	B	0.887917160987854	What you could imagine is that encoding the fact that the agent encoding the actions of the agent directly inside of the state space of the agent through geometry could be a way to stabilize the representations of the agent.
1700930	1706670	B	0.505574107170105	And this is something that we're working on now and there's already literature in this direction.
1707090	1711290	B	0.8055742979049683	Okay, so now let us proof the statement.
1711370	1717310	B	0.8625513911247253	And to prove the statement, we need to give a formal precise statement.
1717470	1727080	B	0.8608810305595398	So more particularly what we were able to show is that if you assume that the agent has as moves staying still, so it's allowed to stay still.
1727770	1731926	C	0.7889031767845154	Then if its changes of frame are.
1731948	1736440	B	0.7786968350410461	Given by a fine transformation, the agent stays still.
1737450	1750060	B	0.8599982857704163	Now, in the projected case, if you assume that the agent is always looking in the direction of the object, it will always try to get closer to the object.
1753810	1754560	B	0.7123860716819763	Okay?
1755010	1776834	B	0.8752164244651794	So the idea of the proof is that what plays the role for drive of the agent is how big the agent is appearing to is the size of the object in the reference frame of the agent and it's how big it appears to be to the agent.
1776952	1783254	B	0.8466906547546387	So in the first case, the volume of the object in the internal space of the agent doesn't change.
1783372	1784840	B	0.758429765701294	So it doesn't need to move.
1785210	1798854	B	0.6154907941818237	In the second case, if it makes a move, what is informative is to try to make the object bigger because once it's bigger, the apostrophe will be further from the prior with respect to a certain observation.
1798902	1803630	B	0.6193787455558777	So it will always privilege moves that allow to make the object look bigger.
1803970	1816020	B	0.8097187876701355	And in this case, what you can do is you can show that this corresponds in fact to actions or change of frames that gets you closer to the object.
1816390	1818290	B	0.748802661895752	So how do we prove the results?
1818630	1824530	B	0.8842934370040894	So, as we said, we consider a change of frame from the real world to the internal world.
1824600	1827742	B	0.6259766817092896	Here, I didn't consider changes of perspectives with respect to moves.
1827806	1830838	B	0.8413770794868469	Here is simply how you relate the real world to the internal world.
1830924	1846246	B	0.7523013353347778	In the Euclidean case it's clear, it's just that the way that you write the coordinates of the object in the solid frame in the projective case it's not obvious because there are several ways that you can relate the solid frame of the agent to the projective frame.
1846438	1856400	B	0.8639981150627136	So one way that we decided to do it is we give some set of axioms that we consider to be, let's say, coherent with our own experience of space.
1856770	1859550	B	0.8365975618362427	Which is that we feel that we're always centered on ourself.
1859970	1862698	B	0.7604418992996216	That the axis of the soil frame.
1862714	1865262	C	0.8064696192741394	Of the agent inside of 3D space.
1865316	1868702	B	0.8706660866737366	So what is in front of it or what is on the right, what is top are preserved.
1868846	1877430	B	0.8509137630462646	That there is no point in front of the object that appears to be at infinity and that that near to the center of the object, the volumes are preserved.
1878330	1885000	B	0.8655312061309814	So when you do this formulation like this result is in this article here.
1885530	1888946	B	0.572109580039978	So the way that we relate some solid.
1888978	1906910	B	0.8034418821334839	Frames like some solid reference of the agent to some projectors transformations are in this article, in particular in proposition A, one where we show that this set of axioms limits the set of projected transformation we can consider and we will only have this projected transformation.
1907410	1921410	B	0.8869152665138245	And so the change of frames from the external world to the internal world is given by rewriting the coordinates of the agent of the object in the solid frame of the agent and then applying this projective transformation.
1923590	1930920	B	0.8754935264587402	So now what we defined here are the maps that relate the observation of the agent.
1932730	1933480	C	0.5511216521263123	Back.
1937050	1952320	B	0.8908274173736572	So we define the maps in the Euclidean and projective case that relate the observation of the agent observation of the object to the way that it represents this object inside of its internal world here.
1952850	1959134	B	0.5494006872177124	So this is simply like the POMDP that we defined before.
1959332	1964234	B	0.7555480003356934	And now once the agent doesn't move, it changes its ecclesian reference frame.
1964282	1966414	B	0.5454044938087463	So there is a solid reference frame.
1966542	1981414	B	0.8860571384429932	So from going from one side reference frame to another solid reference frame, you can, by applying the projective transformation we had before, define another one that we call PSI that goes from the state space at time zero to the state space after action, after moving.
1981612	1983206	B	0.7805130481719971	What is very important is that we.
1983228	1987526	C	0.8873260021209717	Consider the Markov kernel associated to a.
1987548	2004474	B	0.8809362649917603	Noisy observation to be of this shape here, which is that if you know that the object if you think the object is at point X then you believe that the observation will be around X in the ball around X for a ball of a certain radius, which is a small radius.
2004522	2005390	B	0.7008209824562073	Epsilon.
2005810	2006222	B	0.7123860716819763	Okay?
2006276	2008720	B	0.8542471528053284	And I need to charge my computer, so sorry.
2026940	2040300	B	0.8830601572990417	So now press epistemic value as defined curve between the previous formula.
2042080	2045836	B	0.7060933709144592	What in fact that it has a very simple expression.
2046028	2053052	B	0.8788986802101135	So the epistemic value of the prior propagated after the transformation phi after this changes of frame phi.
2053116	2054560	B	0.7906824350357056	So you have a prior here.
2054630	2056224	B	0.8317462801933289	You propagate it on x one through.
2056262	2058672	C	0.8374776244163513	Phi and you compute the epistemic value.
2058726	2061956	B	0.8722509145736694	For this joint for the joint distribution over x one.
2061978	2064948	B	0.8760526776313782	And y is given by this formula here.
2065034	2084208	B	0.8289833664894104	Well, it's simply integrating over all the possible places where the object could be times the probabilistic volume of the ball of size epsilon for the propagated measure and logarithmic of the same quantity.
2084404	2086540	B	0.780312716960907	So this is very direct to right.
2086610	2090060	B	0.768814206123352	You can just compute it and you find this expression.
2090560	2097810	B	0.8425693511962891	But what you have already here is that if you consider an Euclidean transformation, then the quantity cubed PSI minus one b epsilon y doesn't change.
2098180	2101292	B	0.8553866744041443	So then you have the epistemic value that is constant.
2101356	2105280	B	0.6295127868652344	So basically, if you try to maximize epistemic value, maximize this quantity, you can do anything.
2105350	2107696	C	0.7576645016670227	You have always one move which is not to move.
2107718	2108336	B	0.6716262698173523	So you don't move.
2108358	2108716	B	0.7312531471252441	It's okay.
2108758	2109910	B	0.6583499908447266	It's perfectly fine.
2110920	2112308	B	0.7666422724723816	Now, in the second case where you.
2112314	2114036	C	0.8455763459205627	Have the projective where you consider that.
2114138	2119952	B	0.6058477759361267	The way you relate environment and internal world is through a projective transformation, then it's more complicated.
2120016	2129320	B	0.7953073978424072	And so you need to use a trick which is that you know that once an observation has been made the support of the prior will be smaller.
2129740	2133772	B	0.8543426990509033	And so after one step if you suppose that your epsilon so the size.
2133826	2136088	C	0.6250032782554626	Of, let's say noisiness of your sensor.
2136104	2147760	B	0.6624016165733337	Is small enough, you have a support that is of the distribution that's small enough so that you can do an asymptoteic development of the quantity in the interval.
2148580	2155376	B	0.8445473313331604	So this is an equality, but this is an approximation here and now.
2155478	2171096	B	0.8540468811988831	This is very useful because now that, you know, doing this in a way you can say that you just need to develop this quantity at the point where the object is really so if you do it, you get this expression here.
2171278	2183850	B	0.8449537754058838	And what appears to play a role is only the determinant of the Jacobian of a projective transformation which here in the accelerated case will be one in projective case can be many things.
2184860	2188184	B	0.5557476282119751	So here also it's not very clear because how do you define CM?
2188232	2190664	B	0.8717527389526367	So CM is defined as a composition of several maps.
2190712	2196936	B	0.8939913511276245	I didn't go into the details but it corresponds to the map that are given by the changes of frame.
2197048	2209670	B	0.8909948468208313	So if you have the occasion space and the internal spaces after moving you have a change of frame in the Euclidean space but it corresponds to also a change of frame in the internal space.
2210040	2219460	B	0.814747154712677	So the way you define PSI is simply saying that you inverse the projective transformation from internal world to external world to go at time zero.
2219530	2225000	B	0.8898521065711975	Then you apply the change of frames and then you apply the projective transformation to go from external to internal.
2226300	2231592	B	0.8770444393157959	And so it is exactly this formula that you have here and which is very nice with this.
2231726	2234984	B	0.6799013614654541	And then you have the first term that doesn't depend on the actions that you do.
2235022	2236348	B	0.6281888484954834	So you don't need to take it into account.
2236434	2239470	B	0.8025565147399902	This one will be one and then you just need to compute this one.
2240320	2244464	B	0.6341025829315186	In fact this one has a very simple expression so it's expression 2023.
2244502	2255200	B	0.8448275923728943	And then here you can directly see which moves correspond to increasing this quantity and decreasing this quantity because we want to increase epistemic value.
2255350	2270650	B	0.7381009459495544	And so this is the result this allows to prove the result that we said in the first day like in the several slides before that in the projective case, if you have enough movements, if you look at the object then you're always going to go closer to the object.
2271740	2280964	B	0.5149630904197693	A way to interpret it is as if the agent it was a bit paranoiac or paranoid, a bit like very uncertain on its own beliefs.
2281092	2286296	B	0.7572680711746216	So it knows the object might be over there but it's always uncertain.
2286328	2290364	B	0.8841913342475891	So it needs to go check and once it's checked it's more certain.
2290562	2294048	B	0.6103870868682861	But still as it can always be even more certain.
2294134	2298080	B	0.6046760678291321	It will always try to get more and more certainty.
2300020	2310416	B	0.8066475987434387	And so I only presented in this presentation all the aspects which are more computational and the algorithm and some analysis of the algorithm we considered.
2310448	2318632	B	0.8828358054161072	But we also have some experiments on how this setting allowed to generate different behaviors, behaviors that we would expect explain.
2318686	2321636	C	0.7876269817352295	For example, some illusions like the Moon illusions.
2321668	2338120	B	0.5095140337944031	And I invite you, if you're interested on this, to listen on to the online talk of the MOC Four conference that was in Oxford last week or to check out one of these three papers.
2338280	2340620	B	0.9726439714431763	And I would like to thank you very much for your attention.
2348160	2349644	A	0.9191187024116516	All right, awesome.
2349842	2350590	A	0.7093686461448669	Wow.
2352020	2361030	A	0.8922460079193115	Very interesting and different ways than how I've seen the POMDP and related works.
2363320	2368916	A	0.8890970945358276	Okay, let's just start off with little context and then I'll read some questions and read some questions from the live chat.
2368948	2373530	A	0.850382387638092	So what brought you to study this question this way?
2376460	2377208	B	0.749803364276886	What question?
2377294	2380296	B	0.8380265235900879	The question of, okay, did you come.
2380318	2385352	A	0.5134758353233337	From a math side and find consciousness and geometries to be interesting or vice versa?
2385416	2388140	A	0.8771294355392456	What kind of brought you to want to make this contribution?
2388880	2400604	C	0.6354661583900452	So at the beginning so when I did my PhD in maths, I was more interested, I was interested in, let's say, all this idea of critical brain hypothesis.
2400652	2403776	C	0.7731930613517761	So trying to understand the way that.
2403798	2409780	B	0.7186568379402161	The brain processes information and makes it something that can be exploited.
2413240	2419716	B	0.8839131593704224	So the critical brain hypothesis tells you that the activity of the neurons is basically close to a certain criticality criticality.
2419748	2421864	C	0.8176588416099548	And the source of statistical physics because.
2421902	2423848	B	0.8120548129081726	You can model the activation of the.
2423854	2428730	C	0.8691748976707458	Neurons as, let's say, statistical system like an Icing model.
2429820	2431496	B	0.6593060493469238	So I worked a lot on this.
2431598	2435084	C	0.7979830503463745	Then there's another hypothesis that is very.
2435122	2437448	B	0.7812308073043823	Common, which is the Bayesian brain hypothesis.
2437624	2439768	B	0.7725824117660522	And so the Bayesian brain hypothesis led.
2439784	2445740	C	0.7750020027160645	Me to active inference, to learning more about optimal control, Bayesian perspective on optimal.
2448720	2451984	C	0.8856186270713806	So my advisor was PhD advisor was.
2452022	2453744	B	0.5810926556587219	Working with David, and they still work.
2453782	2458508	C	0.8465256690979004	Together on trying to implement some aspects.
2458524	2465264	B	0.8571026921272278	Of consciousness and how it can influence influence, especially with their article on the Moon illusion.
2465312	2475588	B	0.7083844542503357	So I was interested in knowing how this kind of, let's say, ideas simply.
2475604	2479364	C	0.7334325313568115	Like in a very naive way, they interact with the Bayesian brain hypothesis.
2479492	2481416	B	0.7611110806465149	And then I continued in fact, one.
2481438	2487052	C	0.8758156895637512	Of the lines of my research is structured like algebraically structured statistics or machine learning.
2487186	2493964	B	0.5410776138305664	And so the way that they see it very geometrically, in fact, let's say geometrically or algebraic, it's not the same.
2494002	2507020	C	0.6819583177566528	Thing, but it's very related, is something that I wanted to understand a bit better, let's say, to make it in a formal setting so that it's simply a particular case of what is in the literature.
2507100	2510224	B	0.8500545620918274	So it's specifying what exists in the literature.
2510272	2514276	B	0.7070062756538391	And this took some time because I was more on the active inference, like.
2514298	2515748	C	0.7742011547088623	The free energy principle side.
2515834	2527256	B	0.7170822620391846	So I had to read more about optimal control Stochastic, optimal control Pmdps and understand that in fact, what we're doing is simply adding more structure on the.
2527278	2530168	C	0.744817852973938	Latent space of the agent, on the.
2530174	2531450	B	0.731673538684845	State space of the agent.
2531760	2537384	B	0.7553569674491882	And doing this allows to ask the question like why is it useful?
2537512	2541224	C	0.7410454750061035	Why having a state space that encodes different perspectives?
2541272	2546556	B	0.6162950396537781	So the motivation comes from consciousness study, cognitive sciences, but why it can be useful for robotics.
2546588	2548092	C	0.6296948194503784	And it's always been like my motivation.
2548156	2552588	B	0.8254638314247131	Study some statistical models, more structured models.
2552604	2554864	C	0.7073696851730347	With more a priori that can be.
2554982	2565440	B	0.7981470227241516	Useful for understanding the behavior of a closed system like an agent, like a collection of neurons, like even like molecular machines.
2565600	2568230	B	0.5579338073730469	So it's a very long answer, but it's okay.
2569580	2570328	A	0.84200119972229	Cool.
2570494	2577050	A	0.7541580200195312	So you focused on the spatial movement epistemic foraging case.
2577980	2589340	A	0.894828200340271	Is there something special about space or can we also think about this perspective taking in terms of, for example, semantic or a narrative reference frame?
2591920	2597644	C	0.5255848169326782	I think it's a very important question because up to now all the work reference will need to space.
2597842	2602364	B	0.7771106362342834	So the fang is space in terms of a 3D space and not space in terms of geometry.
2602412	2603920	C	0.7786106467247009	And the fact of writing it as.
2603990	2608016	B	0.8433181643486023	Geometry allows to get out from the classical point of view a space as.
2608038	2618096	C	0.6401210427284241	A 3D space because you see that there's more and more like for example, in geometric deep learning, there's more and more the use of space to encode invariance of certain objects.
2618128	2624116	C	0.7781315445899963	And these objects are not necessarily have the three dimensional structure.
2624148	2626760	C	0.731704592704773	You can have objects that have higher groups of environments.
2627100	2631592	C	0.8000341653823853	So I think that it's indeed using.
2631646	2633844	B	0.7985698580741882	Geometry for other contexts.
2633972	2635496	B	0.7159616947174072	And it's really the aim of trying.
2635518	2637464	C	0.8772321343421936	To go to this more general formulation.
2637512	2640376	B	0.7188167572021484	Is to be able to apply it to real world models.
2640408	2641736	C	0.8170775175094604	What I mean by real world models.
2641768	2643240	B	0.7813593745231628	It means the ones that are learned.
2643320	2644364	C	0.811451256275177	To be able to have an agent.
2644402	2645964	B	0.6230348348617554	In an open environment that will learn.
2646002	2649152	C	0.8325533866882324	The way it would learn its generative model.
2649206	2654176	C	0.8253062963485718	But they are priori that it can take a perspective on its environment and see what it can do.
2654198	2655424	C	0.7593387365341187	So we really wanted to get out.
2655462	2658404	B	0.7688946723937988	From the least for me, go out.
2658442	2660976	C	0.7831446528434753	From 3D space and go to implementing.
2661008	2665636	B	0.8248190879821777	It completely in autonomous agents to kind.
2665658	2666740	A	0.6772300601005554	Of follow on that.
2666810	2669064	A	0.8062056303024292	There's a question in the chat, great talk.
2669182	2675210	A	0.8787443041801453	I also wonder whether it applies to any modality, not just visual spatial, but also text.
2677020	2679672	C	0.846974790096283	Yeah, so for other modalities, like sound.
2679726	2687850	B	0.7548085451126099	For example, but I don't know for applying to text, there's a lot of work now on large language models and.
2688220	2693240	C	0.8337047696113586	All this idea of prompting and having these models being able to have some kind of imagination.
2693400	2698140	C	0.8489900231361389	So you would like to have these ideas applied in this context.
2698300	2702416	C	0.5990663766860962	But for now, it's not the line that I'm trying to do.
2702438	2704560	C	0.50242680311203	So I'm trying to stay on deep learning.
2704630	2711428	C	0.8446290493011475	So basically take standard data set without considering text and just try to see.
2711514	2716340	B	0.713795006275177	How these ideas, like in geometric deep learning, can stabilize representations.
2717080	2723884	B	0.65458083152771	So it's not the same that it's clearly other modalities, especially if we consider like, multimodal integration.
2724032	2728376	B	0.6823230981826782	Like, you try to rebuild the state space and you don't want to see it only as a vector space, but.
2728398	2731352	C	0.7459999322891235	You wanted to see it with more structure because you want to force the way.
2731406	2739516	C	0.8362463712692261	Like you have constraints, you know, a priority, the constraints that you're going to have on the way that you can take a perspective on one moldality or the other.
2739618	2740764	B	0.6515774130821228	But it's not for text.
2740882	2742492	B	0.7262763381004333	At least not but I think maybe.
2742546	2744076	C	0.8209966421127319	It could be used for text, but.
2744098	2745372	B	0.5927654504776001	It'S not what I'm doing now.
2745506	2747630	D	0.8895447254180908	Can I add something about this question?
2748900	2752770	D	0.6088755130767822	Sorry, I just want to rebound on that.
2754260	2758080	D	0.6372977495193481	I have the luck of collaborating with real mathematician.
2758900	2766112	D	0.6851288080215454	I'm just some guy with intuition that I've found the right people to do the work regarding multimodality.
2766176	2769588	D	0.6669827103614807	This is important to understand that this is not about vision.
2769764	2772180	D	0.7979878783226013	This is about spatial cognition.
2772340	2773748	D	0.6955430507659912	It's supremodal.
2773844	2789820	D	0.6848995089530945	The claim is that vision is just one particular way of integrating information, indeed in an obviously projective manner, but that's integrated in a much larger field of experience than the field of view or the visual field.
2789970	2792876	D	0.7908066511154175	And obviously proprioception touch.
2792978	2813716	D	0.7702239751815796	When you build a representation just by touching something and you get this 3D representation of that thing automatically in your mind hearing to the extent that it's about source localization and building spatial representation, all of that stuff that's the claim of the theory is integrated in this projective space.
2813898	2822184	D	0.8197945952415466	There are priors from memories, there are stuff from vision, stuff from addition, stuff from proprioception, interoception, you name it.
2822222	2824056	D	0.7891479730606079	All senses contribute to it.
2824158	2825284	D	0.5172738432884216	So it's not vision.
2825332	2830564	D	0.5989324450492859	The claim is that projective 3D projective geometry in that case is beyond vision.
2830612	2834632	D	0.7245832085609436	Vision is just actually a slave to that supremodal representation.
2834696	2835660	B	0.7443410754203796	That's the claim.
2836640	2837390	A	0.918424665927887	Awesome.
2838720	2839710	A	0.5299542546272278	Yeah, please.
2840160	2845004	C	0.7551271915435791	It's important because I think we work like a group.
2845042	2846456	C	0.8120171427726746	There are several different perspectives.
2846488	2848064	C	0.7675123810768127	For me, I'm more on the computational side.
2848102	2852050	C	0.5244700908660889	So it's important to have that because clearly something I won't be able to answer.
2852420	2852976	A	0.84200119972229	Cool.
2853078	2856112	A	0.8919891715049744	Here's a nice following question from Vladimir in the chat.
2856176	2872360	A	0.6747926473617554	They wrote if the Eg visual sensors have variable resolution, for example, higher resolution in the center, this can naturally lead to Curiosity based change of orientation response within your framework.
2873180	2874964	C	0.8620493412017822	So is it a question or an affirmation?
2875012	2876490	C	0.8400563597679138	So it's for E g, right?
2878060	2894396	A	0.8826185464859009	If there's variable sensor precision, for example, higher precision in the sensor, might you see any resulting Curiosity associated change merely based upon the asymmetry or the structure of the sensor field?
2894578	2899616	C	0.5347445011138916	Okay, so I shouldn't say it, but I will still say it because I don't know if the paper will go out one day or not.
2899638	2901200	C	0.6086080074310303	But this is more attention.
2902020	2904160	B	0.5650150775909424	This is more attention than Curiosity.
2905540	2906928	C	0.8381458520889282	So you can act on your sensor.
2906944	2909764	C	0.8393208980560303	So that you can change the way that you integrate them.
2909802	2913140	C	0.4895668625831604	And this really acts as a form of attention.
2913800	2916150	C	0.7869037985801697	So I really went into it.
2917560	2921720	A	0.8774858713150024	What is the interplay between attention and curiosity?
2925820	2935726	C	0.8465603590011597	I mean, it's the way you're going to move basically on the way, the.
2935748	2938420	B	0.5030631422996521	Way that it deforms the way that you move.
2939030	2941554	C	0.7588727474212646	So the consequences of your actions are not the same.
2941592	2946100	C	0.8369776010513306	So basically curiosity is what drives actions and the way that you.
2948870	2949426	B	0.6628233790397644	Choose your.
2949448	2952930	C	0.7946229577064514	Action with respect to reward, which is epistemic value and now attention.
2953010	2959990	C	0.8591521978378296	Or let's say changing the sensors is a way to change the consequences of your action with respect to, let's say, optimizing this value.
2960060	2963014	C	0.7737487554550171	So it's, it's like yeah, I mean.
2963052	2966426	B	0.6696472764015198	It'S it's yeah, I don't know if.
2966448	2969242	C	0.6084266304969788	I should say it or not, but okay, let's say it's okay.
2969376	2970294	C	0.8157535195350647	I think it's a metric.
2970342	2975150	C	0.8859254121780396	Basically it acts like a sort of metric on the space, on the group directly.
2976210	2979786	C	0.8403364419937134	So when you have a function, you want to do gradient descent, you choose a metric.
2979818	2988674	C	0.8671096563339233	And the metric is so the attention will act as a metric and so the metric will allow you to deform, in fact, the steps that you will do.
2988712	2990318	C	0.6708788871765137	And so I think this is how it acts.
2990414	3002840	C	0.8008217811584473	So it's very known that it's known that the fact that changing the sensors is related to attention, that's not something much new, but the fact that you can directly in our setting related to groups and you can relate it to.
3003530	3004966	B	0.8531602025032043	Changing the metric on the group is.
3004988	3006914	C	0.519818902015686	Something that can be done.
3006972	3009180	C	0.9134647250175476	And I think it's interesting.
3012030	3014970	A	0.8387596607208252	All right, another question in the chat.
3016030	3020540	A	0.9044234752655029	What is a formal framework for learning geometry from data?
3020990	3029498	A	0.8797033429145813	How do we move from empirical data sets, the files on our computers, and the things that we do deep learning on take into machine learning pipelines?
3029594	3038690	A	0.9036349058151245	And how do we utilize geometric approaches and formalize to the kind of analytical precision that we saw here, some of these geometric relationships.
3039590	3046580	C	0.8837596774101257	So there are several different fields of how to use geometry on data.
3047930	3049666	C	0.758097767829895	It depends how you see geometry.
3049698	3064010	C	0.8305139541625977	But one way is a TDA topological data analysis, which is basically trying to, let's say you want to provide learning by geometric stability property of your data and try to interpret it as a certain kind of space.
3064080	3067914	C	0.846124529838562	And then you look at the whole of your space and this is something that defines your data set.
3067952	3068854	C	0.8129928112030029	So this is one approach.
3068902	3080074	C	0.7094975709915161	Another one is people doing manifold, so they know that the data lives in a low dimensional manifold and they try to learn this manifold.
3080122	3082286	C	0.731293261051178	So that's another way of doing it.
3082308	3084506	C	0.5018328428268433	So that's lots of work in this direction.
3084538	3089780	C	0.5144575238227844	There are people who are interested in variance and equivalents, so more in geometric deep learning.
3090550	3099702	C	0.53756183385849	There are people who are interested in the same setting on a priorities how to use geometric aprioris and included in learning for deep learning, reinforcement learning.
3099756	3103814	C	0.751706063747406	And this is what we do with this is where many people do this.
3103852	3105080	C	0.6993470191955566	It's not just us.
3105690	3110700	C	0.5890380144119263	For us we try to focus on this idea of how to exploit it for reinforcement learning.
3113230	3119682	A	0.8682289719581604	So in this setting Epistemic value was the only driver of action.
3119846	3121486	C	0.7823363542556763	Is that so?
3121508	3127134	A	0.7415514588356018	It's kind of like an expected free energy except without Pragmatic value.
3127332	3130350	A	0.6578242778778076	So we only have the Epistemic term remaining?
3130690	3131294	B	0.5662814974784851	Exactly.
3131412	3149382	C	0.7866302728652954	In fact if you look at in terms of optimal control and not by Asian, because you know that there's this duality that is most of the time stated in Active Inference where you have basically a duality between let's say value function and a probabilistic version of value function.
3149436	3159686	C	0.861709475517273	So you can encode on priors, you can encode all your drives with priors are with the value function directly.
3159718	3179646	C	0.7266368865966797	So rewards and so both are kind of dual and they're dual in a way you can make this duality, I don't know if it's explicitly dual like in some context this sentence makes sense for Active Inference for me I'm not completely aware if the duality is exactly formal but at least the idea is here.
3179668	3184086	C	0.7284049987792969	So there's no big difference, at least the way I see it with value function and seeing it probabilistically.
3184138	3190786	C	0.842211127281189	But the terms of Epistemic value is an exploration drive which you also find in reinforcement learning.
3190888	3192814	C	0.7522493600845337	Maybe not in this exact expression.
3192862	3195940	C	0.8761720657348633	I think that the exact expression that was given in the paper of.
3197770	3198086	B	0.54979008436203	I.
3198108	3202246	C	0.7098830938339233	Think it's pezulo and for sure I.
3202268	3203560	B	0.7395033240318298	Know is on the paper.
3206830	3213674	C	0.6503231525421143	It'S very economical way to define Epistemic value.
3213712	3217500	C	0.7233286499977112	So it's an exploratory drive, you can always add to the value function.
3218750	3230800	C	0.6294059753417969	But there's a lot of problem of trying to explore in fact your environment to find the good policies because if you're in a state space that is continuous it's really difficult to resolve the p one EP.
3235750	3248760	A	0.7583457231521606	Yes, it's like if you knew which curiosities you could get rewarded from you would have already known the answer to the search.
3250970	3260966	A	0.6785700917243958	So that's one of the challenges with Pragmatic value it converges well to expectations.
3261078	3272350	A	0.514651358127594	But then this work really focuses in on Epistemic value and shows what it can do alone as a driver.
3273330	3277930	A	0.8994676470756531	So how would you bring Pragmatic value into this formalism?
3278090	3279520	C	0.6672132015228271	You just add it.
3280690	3286642	C	0.8865396976470947	You can put the value functions of some of rewards in some way and then you add the Epistemic value.
3286696	3297090	C	0.7233365774154663	In fact, when you look at the formulation in terms of belief MDP for POMDP, the Curiosity Epistemic value is simply a value function, nothing more.
3297160	3298374	C	0.8150324821472168	It's a one step value function.
3298412	3308700	C	0.7131734490394592	But I mean this is like just playing with definitions but so you can always add a drive for exploration and this is something that's really often done in reinforcement learning.
3312110	3321900	C	0.7320094704627991	I think it's even standard in not this way, not exactly special, but there's a book that's called Reinforcement Learning state of the art and they introduce this exploratory drive.
3323310	3324526	C	0.7871879935264587	This is a book maybe that has.
3324548	3326030	B	0.7835904359817505	Ten years or something like that.
3326180	3327840	C	0.7330711483955383	So it's something that you add up.
3328690	3329774	B	0.812966525554657	The way we will do it now.
3329812	3339202	C	0.8256067037582397	Is we can put some drives with respect to preferences and then you add for example, an epistemic value and you try to just solve the optimization problem.
3339336	3344274	C	0.6867533326148987	But in terms of formalism, if you look at the belief MDP, it's nothing more than a certain value function.
3344392	3350120	C	0.9597889184951782	So it's not cool.
3351770	3372030	A	0.8586328029632568	So space remains when we translate through it or when we whether we're in the Euclidean or in the projective setting space is basically what is not changed through action.
3373170	3374222	A	0.8258432745933533	Is that the case?
3374276	3375200	A	0.6095885634422302	Okay, yeah.
3378530	3386366	C	0.8395202159881592	The thing is that there's a bit of technicality so the way that we use is we use a chart for the projected plane.
3386398	3392130	C	0.7053413987159729	So we need to use homogeneous coordinates, so we need to take away a lower dimensional plane.
3392470	3393906	B	0.6763472557067871	So that's why we always have the.
3393928	3409858	C	0.862489640712738	Same like in the way that we encoded, we always are in r three because we chose a chart, we chose homogeneous coordinates and we did projective transformations from one homogeneous coordinate to another homogeneous coordinate but it always lists to a projective transformation.
3409954	3411126	C	0.7062080502510071	So what is hidden in the way.
3411148	3412202	B	0.8153750896453857	That we write it is in fact.
3412256	3416118	C	0.6219307780265808	We don't have the same space in the first case we have ecclesian, in the second we have projective.
3416294	3430234	C	0.8036633729934692	But the way as we use charts and we don't put all the details of the fact that for example, you can compose two projective transformations even if you write it in charts in terms of homogeneous coordinates and it stays a projective transformation.
3430282	3433906	C	0.5770629048347473	This is something that is okay but we just don't write it this way.
3433928	3437458	C	0.7307227253913879	We stay in charts and so that's why there's a similarity between because we.
3437464	3439422	B	0.6758228540420532	Want to implement it, there's a similarity.
3439486	3440340	C	0.7165009379386902	Between the.
3442310	3445282	B	0.8191563487052917	Projective case and projected case.
3445336	3447010	C	0.8175535798072815	Have the same state space r three.
3447080	3448754	C	0.8122485876083374	But the space of transformation is really.
3448792	3450870	B	0.5365236401557922	Different and in fact they are not the same space.
3451020	3460310	C	0.7011436820030212	But what is important for us in terms of space is just to tell yourself that if you take away everything that is inside of space, everything that populates space, you take it away.
3460460	3470394	C	0.651308536529541	What you're left with is with this kind of concepts which already takes into account the fact that when you act you're not changing the space and there's no single point that is singled out.
3470512	3478330	C	0.5157446265220642	This is very important because it's a very typical like it types a lot the object you're looking at if you move there's no point in the space that is changing.
3478490	3479774	B	0.49735021591186523	There's no point that is single out.
3479812	3481386	C	0.7825829386711121	And when you move the space is not changing.
3481418	3486086	C	0.8691151142120361	So you know that you already have inside of your space a change of charts that is encoded.
3486218	3490466	C	0.7253085374832153	And even more when you can imagine that you take the perspective of somebody else.
3490648	3496718	C	0.7920344471931458	And this is really something that is at the basis of the space we consider is that the space is simply.
3496814	3501134	B	0.6414552330970764	A way to support the fact that you can change charts, you can change perspectives.
3501262	3504694	C	0.8322451710700989	And so it's including this idea inside of agency that we're trying to do.
3504732	3505798	C	0.5177990794181824	So maybe I was not clear in.
3505804	3510520	B	0.866879940032959	The way that I said it first, but I think this is really important.
3511390	3513162	A	0.7136745452880859	It's the water we're in.
3513296	3518682	A	0.9614325761795044	So it's a very interesting way to approach it.
3518736	3531360	A	0.5888028740882874	And it reminds me way back when, actually almost three years ago when we discussed the projective consciousness model and phenomenal selfhood in live stream number nine.
3532070	3541330	A	0.7625498175621033	And we talked a lot about flipping between the Euclidean and the projective modes.
3541670	3570746	A	0.7899948954582214	How an agent could have on one hand a space in which a book is a rectangle and yet also be seeing it very close to their face so that its visual projection was different and yet here there was different behavior associated with the frame alone.
3570938	3587630	A	0.8222507834434509	So what's going on there where even though they apparently can be reconstructed from each other, what flips can we flip from thinking more Euclidean?
3587710	3595240	A	0.6203610897064209	And then in that situation I'm a plane 30,000ft above my city so there's nowhere I need to go.
3595690	3605800	A	0.8597728610038757	But then in the projective setting we do have this kind of inbuilt epistemic drive to be near.
3608810	3610890	C	0.5732761025428772	I think it's hard coded.
3612830	3615750	C	0.7769396305084229	One of the things that it can be useful for is communication.
3615830	3617466	C	0.7900356650352478	So using space as a way to.
3617488	3619882	B	0.7538983225822449	Communicate, taking it as a priority that.
3619936	3621942	C	0.6915239095687866	We have very different architectures.
3622086	3624654	C	0.5752807259559631	The way that we treat information are not the same.
3624772	3627486	C	0.49499985575675964	We don't have exactly the same connection, neurons and everything.
3627588	3631742	C	0.6616544723510742	But we still have a common framework in which we can discuss, for example.
3631796	3646870	C	0.6330636143684387	And visual information is something that is very immediate for us, which is not obvious if you take the perspective, the point of view, if you go from the idea that it's rebuilt and the environment you're living on is not exactly the space that we see.
3646940	3655910	C	0.5370305776596069	There's something that we constructed for functional reasons and that one of them could be that we can communicate very directly with it.
3656060	3658006	C	0.7011532187461853	So I think it's hard coded that.
3658028	3664790	B	0.7016322016716003	The state space needs to have this action and that all the agents share this action but they don't share the same architecture.
3664870	3666234	B	0.7330974340438843	So it gives a common base for.
3666272	3669690	C	0.7169091105461121	Discussion like true actions, for example, change of perspective.
3671230	3680734	C	0.7455950975418091	So it's to answer the question eclean projective we're not going in the direction in terms of research where we're trying to say that you can go from Eclean to projective for the same agent.
3680852	3690402	C	0.8602375984191895	So agents are hard coded with a latent space which has some structure and then we try to exploit it for function, for communication, for multi agent like.
3690536	3692530	B	0.6631203293800354	Behavior so that they can collaborate.
3696250	3705510	A	0.8404570817947388	Okay, so each agent is within its own projective setting and then the Euclidean sets the stage and allows that multi perspective.
3706090	3708506	C	0.7708063721656799	The Euclidean space, which is the outside.
3708608	3710966	B	0.6868951320648193	World, is just here in this toy.
3710998	3715450	C	0.8392682671546936	Model because it's a way to reference the configuration of the world.
3715520	3721558	C	0.841701865196228	But for a network, this would be, for example, the configurations of its sensors.
3721734	3723514	C	0.7767230272293091	So it's just here.
3723712	3726750	C	0.6019832491874695	There's this kind of ambiguity between space and space.
3726820	3736358	C	0.8525059819221497	So outside space, which is Euclidean and inside, which is projective, but the outside space is just a way to discuss configurations of something that is related.
3736394	3737134	C	0.6961193084716797	To the environment.
3737182	3743246	C	0.8952298164367676	So it can be like your sensors, the configuration of your sensors or something like this information coming from your sensors.
3743278	3745266	C	0.8124838471412659	So you just give a space from it.
3745288	3747494	C	0.7762767672538757	And the geometry is really in the.
3747532	3749986	B	0.7844594120979309	Reconstructed world that is internal.
3750098	3755446	C	0.6711138486862183	But being able to do networks that do this is somewhere that we're working on now.
3755468	3758722	C	0.6676288843154907	And it's not that obvious because there's a lot of algorithms.
3758786	3761682	C	0.6638078689575195	The problem algorithmic problems that we try to solve.
3761746	3763010	C	0.6690118312835693	And that we need to solve.
3763090	3767500	C	0.5726672410964966	And this toy model is really like the ambiguity comes only from the fact that it's a toy model.
3768030	3770986	C	0.7795628309249878	But what is space is inside it's, what is reconstructed.
3771018	3778240	C	0.8507834076881409	It's the thing that we perceive space from sensors as being a whole, as being something that structures the information.
3779810	3783470	C	0.5595031380653381	So, David you want to say mean.
3783540	3788610	D	0.8593506217002869	Yes indeed in the talk that you are referring to, I was giving and also kenneth williford if I remember.
3788680	3789806	D	0.6647412776947021	Well, yeah, indeed.
3789838	3796454	D	0.861606776714325	The toy models encoded a certain world model in an Euclidean way.
3796652	3810454	D	0.7848610877990723	And then using homogeneous coordinate and this kind of stuff to do the projective transformation, we just transform the Euclidean space into a projective space and you can go.
3810492	3812198	D	0.7712126970291138	Of course you can invert it.
3812204	3815786	D	0.6516023278236389	I mean, there is an onliner division, but you can invert it anyway.
3815968	3818026	D	0.8075692653656006	So you can go from one to the other.
3818128	3819354	D	0.6539435982704163	But Gregor is right.
3819392	3819706	D	0.5014293193817139	That it.
3819728	3821450	D	0.7936728596687317	Was a choice of modeling.
3821610	3826058	D	0.7611768841743469	It was a bit motivated by my experience as a brain scientist.
3826234	3832582	D	0.8492029905319214	There are reasons to believe that memory, for instance, place cells and grid cells deaden.
3832666	3835134	D	0.8876295685768127	Though there are new hypothesis about their hyperbolic.
3835182	3840558	D	0.8689752221107483	Characters but usually they are thought as encoding space in an ecclesial manner.
3840654	3863382	D	0.8392477035522461	So since when we project future action, we use sometimes and we have to use memory or even if we do remembrance of the past and we project ourselves in the scenes in the past, there is this access to memory systems that we used to think, and probably this is still the case, encode information in an Euclidean manner.
3863446	3873854	D	0.8255654573440552	So it would make sense that then for the conscious access, there would be some operation that would allow us to go from Euclidean to projective, which was implemented that way at the same time.
3873892	3887822	D	0.497927188873291	But this is way beyond my abilities in math, so Gregor will correct me, there is a way of seeing projective geometry as being more general, as an extension of a fine space by adding point at infinity.
3887886	3891150	D	0.8711405396461487	So if now you think about a projective space with a metric.
3891310	3893282	D	0.7577812671661377	Basically, the projective space.
3893336	3895174	D	0.8628160953521729	Is an extension of Eclidean space.
3895292	3897510	D	0.7438381910324097	Am I saying something completely false?
3899130	3903190	D	0.7261943817138672	No, it's one way to seeing it.
3903260	3909586	D	0.8452125787734985	And there are also a lot of operations that use dialogues, I would say exchange between projective and Eclidean.
3909618	3929690	D	0.8509812355041504	If you think about multiview reconstruction of 3D Eclidean space from multiple shots in your camera you take several shots of a building from different perspective and then you can use a deterministic algorithm approach using epipolar geometry to kind of infer under some prior that basically all lines that converge at points at infinity are actually parallel.
3929770	3930682	D	0.6160221695899963	Then you reconstruct.
3930746	3933030	D	0.7995949387550354	You go from projective to ecclesiast.
3933050	3939010	D	0.6553073525428772	So there is a deep relationship between the two that is possible and probably functional.
3940950	3943426	D	0.6093829870223999	Yeah, that's about it.
3943528	3947410	D	0.8185533881187439	And Epipolar geometry is a subset of projective geometry.
3948570	3950150	D	0.8555948734283447	Just to give some context.
3953440	3954188	B	0.6875004172325134	David has.
3954194	3956524	C	0.6107101440429688	A better intuition on projective spaces than me.
3956562	3974070	C	0.5841259956359863	This is like so when he faced notes he really has a very intuitive, physical, personal, visualization and most of the time he's right.
3976680	3983060	A	0.8710496425628662	Are we experiencing a projective geometry or what is it like to experience a projective geometry?
3984760	3988808	C	0.8370006680488586	So one problem that there is with this model is the fact that you.
3988814	3990244	B	0.798592746257782	Need to force the point at infinity.
3990292	3994888	C	0.7959081530570984	To be so the plane you take away from the projected space has to be behind.
3995054	3997880	C	0.6110275387763977	And so you're not really working with real maps.
3998620	4000024	C	0.7062879800796509	No, you can always extend them.
4000062	4000504	C	0.7335982322692871	That's okay.
4000542	4011564	C	0.6855215430259705	But the thing is if you want to see it in the way that we see it us, which is we have something in front of us I find it a bit restrictive to say that you cannot see what's behind you.
4011602	4013104	C	0.5600785613059998	I mean, you never see it, right?
4013222	4017228	C	0.6715783476829529	I mean, you can imagine it which is not the same thing because you change your frame.
4017324	4019984	C	0.544175386428833	So I can't answer really this question.
4020022	4035380	C	0.6364243626594543	I'm just pointing out the fact that for me it's very perturbating to think that I have a plane that corresponds to discontinuity with respect to I have a plane that destroys completely the way that I can think about movement behind me.
4035450	4043092	C	0.5110299587249756	Which is that if I had to imagine I had a whole space that is around me and not just in front of me things would be very weird in terms of transformations.
4043236	4045210	C	0.5547276139259338	But it's not something that is not possible.
4045840	4048056	D	0.7664961218833923	This is what happens when you take psychedelic.
4048168	4054424	D	0.7956950068473816	You basically allow the projective transformation to have all its degrees of freedom.
4054472	4060876	D	0.7932047247886658	But in the perception, like in sensory motor processes this is calibrated, this is restricted.
4060908	4063632	D	0.7932673692703247	So we have to choose certain subset of the group.
4063686	4067932	D	0.8861504793167114	Basically it's only certain projected transformation that will be used in practice.
4067996	4073392	D	0.7440447807312012	But now if you go into mystical experience or you take drugs they are going to mess.
4073446	4073916	D	0.5679154396057129	Precisely.
4073948	4076624	D	0.8302400708198547	That's the hypothesis with those parameters.
4076672	4079696	D	0.7658700346946716	And now you have the full fledged 15 degrees of freedom transformation.
4079808	4084264	D	0.668472945690155	And you see things that are very weird, like that looks like mandalas or things like that.
4084302	4089988	D	0.6733540296554565	So that's something you can get when you leave too much freedom to the projective action.
4090164	4090890	D	0.49467554688453674	Basically.
4093180	4097710	A	0.883594274520874	What if what we're seeing, quote in front of us is behind us or something like that?
4099600	4100670	C	0.7294426560401917	What do you mean?
4103200	4106750	A	0.6119474768638611	What was the issue with not being able to see behind us?
4107200	4108140	B	0.6309531927108765	The issue is.
4108210	4117084	C	0.7971674799919128	So if you want to see the projected space as a 3d space, as the way that we see it now, you need to take away a plane and basically projective transformation.
4117132	4123364	C	0.7072616815567017	So there's a sort of plane at infinity on which you can I mean, it doesn't exist in the projected space.
4123402	4134036	C	0.8439062833786011	It exists only in the way you define an Ecligian chart, like a 3d, like R three chart with a plane that is taken away, this plane that is behind you.
4134058	4139208	C	0.7285820245742798	If you apply a projective transformation in front of you, everything will seem fine.
4139374	4146504	C	0.6855993866920471	You're expecting like it's things that you experience but then once what happened is that it can send things at infinity back behind you.
4146622	4162144	C	0.6225325465202332	So this is something that is a bit I mean, for me so you can write it explicitly there's no problem mathematically but if it's really the way that we experience it, it's extremely weird to think about so I prefer not thinking about it.
4162182	4167250	C	0.7442587018013	So this is the only thing and I don't take drugs so I leave it to other people.
4168260	4184404	C	0.594007134437561	It's true that taking drugs in this context makes complete like you could model it in the projective framework and not in the Euclearian framework because you have a huge amount of projective transformations that make sense more than the one that are related to actions in the art.
4184442	4200380	C	0.5331677794456482	So in the presentation I gave there was a way to relate ecclesian frames to projective frames under certain axioms and in fact you have a huge much bigger space of projective transformations than the one that are restricted by the actions of the agent.
4200450	4202668	C	0.7604106068611145	So the actions of the agent inside.
4202754	4203740	B	0.7636162638664246	Of the real space.
4203810	4215856	C	0.6193259358406067	So the Euclidean space induce projective transformation in its internal world but there are much more projective transformation than these actions and so you can imagine in this setting having very confusing states of your.
4215878	4217010	B	0.6992162466049194	Mind in a way.
4219380	4220156	C	0.576257586479187	Which you cannot.
4220188	4221510	B	0.7730429768562317	In the appeal case.
4223800	4243610	A	0.7260611653327942	I wonder if a creature or a robot with 360 degree cameras would it not be so perplexed as it wouldn't necessarily have a visual before or a visual in front and behind?
4243980	4246350	C	0.7075244188308716	And the thing is how do you glue them together?
4249360	4252732	A	0.8205132484436035	You still have to pick a point of convergence, right?
4252786	4255992	C	0.782345712184906	I mean you need to find a way to do multimodal integration.
4256056	4263116	C	0.8110442757606506	Like, if you want to have a camera that's 360, you have the space to represent it, so maybe you can represent it as a sphere.
4263148	4267568	C	0.7160410284996033	And in this case, the sensors are different.
4267654	4272268	C	0.8085402250289917	So it's not necessarily the same robot than the models that we are considering.
4272284	4275092	C	0.8289807438850403	But there might be also another homogeneous space.
4275226	4279060	C	0.8499296307563782	So g space, it's a space acting which corresponds to the rotations.
4281240	4286212	C	0.8596139550209045	If you say that, it can look 360 and then you can rotate and the space of observation stays the same.
4286266	4291428	C	0.7815796732902527	So you can always imagine acting on it and so you can imagine like having another g space structure.
4291524	4306200	C	0.5976346731185913	And the good thing about it is just with respect to the perspective, if you have an agent that can take a different perspective on its environment, which depends on its sensors, on its actions, on the kind of data you have, then you can define g space and you can do exactly the same setting.
4306280	4311760	C	0.7003596425056458	Everything like it's made in the more general context so you can apply it.
4311830	4315904	C	0.779878556728363	And so it's not limited only to the projective case.
4316102	4319330	C	0.8676947951316833	We come from the PCM projective consciousness model.
4319780	4334920	C	0.5042368769645691	But the framework now, or at least the way to replace this framework inside of optimal control is well adapted for any change of perspective and not just projective.
4336460	4337160	A	0.918424665927887	Awesome.
4337310	4341272	A	0.901877224445343	Well, where are you going to go to next?
4341326	4347070	A	0.9156949520111084	Where will the epistemic drive take you carrying forward?
4347760	4349788	B	0.8606414794921875	So there are two projects now.
4349874	4365728	C	0.8874706625938416	So the first one is to be able to maybe David can talk, to implement it so that it can be used for monitoring behaviors or to be able to predict behaviors or to analyze it.
4365814	4367376	B	0.8207538723945618	So you have model of behaviors of.
4367398	4378688	C	0.8043182492256165	Agents like maladati's behaviors, things that we already published but in a more limited context now to make it inside of a computational framework so that we can use it to analyze experiments with humans.
4378784	4381860	C	0.7282546758651733	So this is the first project which is ongoing with several students.
4381930	4392740	C	0.9737187027931213	So on the page that I put on the first slide, there's all the work that we're doing, the people who are working with us and we're very grateful for them working with us and all the ongoing work in this direction.
4392900	4397512	C	0.8156060576438904	And there's the second one, which is more like, let's say machine learning.
4397566	4406216	C	0.7225212454795837	And so for me it's very important you have effective algorithms, things that you can really use in practice, things that you can really implement and implementing when you have group structures.
4406248	4407864	C	0.8045357465744019	There are many, many problems that appear.
4407912	4413312	C	0.8119451403617859	How to do sarcastic optimal control when the latent space is a homogeneous space is, I think, a completely open question.
4413446	4415404	C	0.7812566161155701	I start to have answers in this direction.
4415452	4423700	C	0.8722853064537048	So I hopefully the work will come out soon, let's say January or something like this.
4423850	4426420	C	0.6449031829833984	But there's a huge work in this direction.
4428520	4428980	C	0.84200119972229	Cool.
4429050	4430710	A	0.8537742495536804	Anything else you want to add?
4431960	4433940	B	0.9861782789230347	Thank you very much for the invitation.
4436540	4443368	A	0.7039543390274048	A lot to think about mentally rotate project.
4443534	4452670	A	0.8351547122001648	I mean, after all, as you even alluded to with communication, this is a perspective taking question.
4453200	4464800	A	0.6043689846992493	Technology is adding some new flavors and methods, for example, asynchronous communication, but it's synchronous for the agent when they perceive it.
4464870	4484420	A	0.9750031232833862	But all these different modalities of communication and it's quite interesting to think about and just really cool that you and colleagues are pursuing that from empirical data analytic and from theoretical mathematical approaches.
4485240	4487204	C	0.8394097685813904	I mean, on this side for communication.
4487252	4488024	C	0.5470304489135742	I think so.
4488062	4490570	C	0.9784859418869019	It's something I find extremely interesting.
4490940	4496650	C	0.9446912407875061	More generally, if some people want to work on the project, please tell us, and I will be very happy.
4497340	4500730	C	0.9049935936927795	And even if you have money, please tell us, and we will be very happy.
4503740	4504730	C	0.6408694386482239	I agree.
4506140	4506890	A	0.7671424746513367	Great.
4508100	4508912	C	0.6825478076934814	We're very open.
4508966	4510156	C	0.7081524729728699	You can always send us a mail.
4510188	4512450	C	0.959489643573761	We'll be very happy to discuss about this.
4513700	4514256	C	0.84200119972229	Cool.
4514358	4517650	A	0.9492079019546509	Okay, well, thank you again to all.
4518100	4519410	A	0.6996943354606628	Till next time.
4520020	4521728	A	0.654654860496521	Okay, see you.
4521814	4522124	C	0.5137446522712708	Bye.
