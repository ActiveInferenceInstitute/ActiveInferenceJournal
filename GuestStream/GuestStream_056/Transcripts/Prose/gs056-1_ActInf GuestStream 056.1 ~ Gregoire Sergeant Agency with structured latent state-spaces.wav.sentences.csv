start	end	sentNum	speaker	confidence	text
170	1150	1	A	0.98668	Hello and welcome.
1300	10142	2	A	0.82374	It's September 15, 2023 and we're at the Active Inference Institute in ActInf guest stream number 56.1.
10276	20110	3	A	0.99	Today we have Gregoire Sergeant-Perthuis and we'll be hearing a talk followed by a discussion on geometry of world model influences behaviors.
20450	27478	4	A	1	First there'll be a presentation and then any comments that people have in the live chat or any other questions.
27564	28582	5	A	0.99	It will be great to talk.
28636	33174	6	A	0.91	So thank you a lot for coming, really looking forward to this.
33292	35320	7	A	0.99	So please to you.
36250	42554	8	B	0.99973	Thank you very much, Daniel, for the invitation first, it's really very happy to be able to present this work here.
42592	63214	9	B	0.62	So it's a work around some models of consciousness, at least some computational models of consciousness, some part of consciousness, and how it can help to generate different kind of behaviors, especially when we think about, let's say, artificial agents.
63412	65702	10	B	0.83	So I'm Gregor Santui.
65706	71742	11	B	0.9479	It's a work in collaboration with David Rudrauif, Kenneth Williford, Daniel Bennequin.
71806	73714	12	C	1	In fact, it's not just one work.
73752	79250	13	B	0.9992	It's a collection of works that have been on for already around ten years.
79320	80534	14	B	1	So if you want to know more.
80572	89462	15	C	0.99999	About this group and the work that we're doing, you can go on the page, on my personal Web page, and there's a link to PCM HTML, and.
89516	91466	16	B	0.5392	There's a summary of all the work.
91488	95626	17	C	0.62724	We'Ve been doing and some summary of.
95648	100354	18	B	0.98	The work we've been doing and also of some articles that can be relevant on this subject.
100502	104842	19	B	1	So today we'll focus more particularly on two articles.
104986	127590	20	B	1	So one that is accepted and will appear very soon, the other one need to resubmit, which give formulation of, let's say, autonomous agents or let's say mathematical formulation of agents that have a world model that is structured geometrically in such a way that this world model captures some features of consciousness.
127930	130760	21	C	1	So the first article is, let's say.
131450	134566	22	B	1	The review of the experimental results that.
134588	136642	23	C	0.99999	We have and the most recent formalism.
136706	148682	24	B	1	That we have on our work, which is the literature on POMD partial cerebral stream process, which is optimal control, stochastic optimal control.
148736	149818	25	B	1	And we just try to tweak a.
149824	153206	26	C	0.99949	Bit this formalism to introduce the ideas.
153238	156654	27	B	0.99998	With how you can include inside of the world model of the agent some.
156692	159006	28	C	0.99665	Ideas on consciousness and still continue to.
159028	162462	29	B	0.99995	Have algorithms to do inference to find optimal policies and everything.
162596	181554	30	B	0.81	The Zecholia article focuses more particularly on how changing the world model of the agent can change its behavior, in particular the relationship, the geometry of the world model, the way that it perceives its environment and the way it acts with respect to for agent strategy.
181602	185334	31	B	1	So the way that it looks for something, so it will change its behavior in looking for something.
185452	187238	32	C	1	So I will start by presenting a.
187244	189314	33	B	0.9999	Bit what are all these terms?
189372	191114	34	B	0.67	So, world model, why you need it.
191232	193050	35	C	0.64759	What is a foraging strategy?
194190	198010	36	B	1	How can you define an agent that is looking for a certain object?
198160	204218	37	B	1	In particular, what is an exploration based on Curiosity or let's say more technically epistemic value.
204384	210240	38	B	1	So let's consider the setting where you have, let's say, a real world, so that's the space that surround us, 3d space.
210930	217166	39	B	1	You do a setup where you have an agent which is, let's say, a solid it has a solid frame, so it has a center three axis.
217198	219230	40	B	0.99651	What is in front, what is on its side, what is above?
219310	220146	41	B	0.62828	Above it.
220248	225310	42	B	1	And it's looking for an object O, which is itself a solid inside of R three.
225400	238470	43	B	1	And all the configuration of the agents and the objects they are defined by, let's say, a reference frame that is external and that characterizes completely their configuration inside of this world.
238620	243610	44	B	1	Now, the agent A, what it wants to do is to find for the object O.
243760	248778	45	B	0.99997	But it can only have some noisy observation of where the object O is.
248864	272014	46	B	1	So to be able to find O, it needs to have some atriorian where O should be to be able to plan the consequences of its actions with respect to where O will be once it has moved and to update, to be able to plan how the observation can act with respect to updating its prior.
272062	275650	47	B	1	So, in another words, so you have an agent and the agent is looking for O.
275720	277170	48	B	0.88	It thinks that O is, for example.
277240	278306	49	C	1	In this direction, on the right.
278328	280610	50	B	1	So it's going to move towards the right and makes an observation.
280690	284182	51	B	0.99987	If it doesn't see O, it's going to change its belief on where O is.
284236	289766	52	B	0.98	So this is a very standard formalism that you can find like in POMDP stochastic optimal control.
289948	310574	53	B	0.99622	But the one other point we want to really emphasize is the fact that the agent A has its own frame of reference and the way that it's going to give the coordinates of the object, the way that it will trace where the object is, is using its own way of computing the coordinates of O.
310612	313102	54	B	1	So it has its own way to measure where O is.
313156	319698	55	B	1	So it doesn't have to refer to a global frame, a global coordinate system, to be able to know where O is.
319784	322754	56	B	1	So for example, I am always centered on myself.
322952	325794	57	B	0.99999	When I move, I see the object.
325992	329862	58	B	1	I don't think about me moving, but I think about the object moving.
329916	332274	59	B	1	And this is because when I move, I change my frame.
332322	336546	60	B	1	So the way I'm going to reference the object is going to change accordingly.
336658	345174	61	B	1	And the point we want to introduce is the fact that you can have several ways for the agent to define its own coordinate system with respect to its environment.
345222	350554	62	B	1	And this is a key feature that we want to capture in terms of modeling.
350602	356074	63	B	0.99996	But also we think that it is something that is very structuring with respect to models of consciousness.
356202	358800	64	B	0.99999	Because when you consider more generally an agent.
362470	364162	65	C	0.97724	Let'S say, that has a world.
364216	371842	66	B	0.99994	Model in which it has its own point of view perspective on this world model.
371976	380758	67	B	1	You kind of start tackling the problem of how to introduce a point of view on the environment of the agent.
380844	387590	68	B	1	How can you introduce, in the way that it is going to encode its environment, a certain point of view?
387660	389586	69	B	0.9	And in particular, if you think about.
389628	392186	70	C	1	It in terms of the role of.
392208	397494	71	B	0.67008	Space to be able to take into account your own perspective on the environment.
397542	403360	72	B	1	You can see that if you take away everything that fills up the space, you keep just the space itself.
406130	414478	73	B	1	The space allows you to, let's say, to structure the way that you are going to fill in some information about the environment.
414574	429766	74	B	0.64	And it's centered on your own point of view in a way that when you're going to act, you're still going to keep the unfilled space, you're still going to keep the same way of modeling this space.
429868	432086	75	B	1	The space will stay the same when you move.
432108	434038	76	B	0.98873	When I move, the space is the same.
434204	441126	77	B	0.99999	But I took into account the fact that I can move from one point to another in this space without changing the space.
441228	447002	78	B	1	And something that is also very important is that with respect to any movement that I can do, the space doesn't change.
447056	449322	79	B	1	So there's no particular point in space.
449376	451260	80	C	0.99972	With respect to the movements that I do.
453390	463534	81	B	0.99996	Another property that is very similar is that instead of considering just my actions and the way that I can change my frame while I'm doing an action, you can also imagine taking the frame of somebody else.
463652	473890	82	B	1	So it means that you see that the space that you use to be able to structure your environment doesn't change when you take the perspective of somebody else.
473960	494918	83	B	1	For example, if you imagine yourself as a solid agent changing by a rotation your own solid frame and translating, okay, so this is something that we will use in fact as a definition for the state space, the way that the agent encodes its environment.
495014	511390	84	B	1	And you will see that there's a natural notion that encodes this idea that you can change perspective on your environment, on the world model that you have of your environment, simply by introducing something that's very well known, which is the notion of a group acting on a certain space.
511540	514414	85	B	1	So this is just to sum up a bit what we're trying to do.
514452	532360	86	B	1	So we're just trying to do like exploration inside of an environment, but we're adding additional information, which is that the way the agents is going to encode its environment takes into consideration the fact that it can change its reference frame on this space without singling out any point.
533290	538418	87	B	0.99872	Okay, so what do we mean by perspective taking more precisely?
538594	540650	88	B	1	So how do we go from the real world?
540720	550874	89	B	0.98	So let's say the world described by the external frame that allows you to say the agent is here and the object is here from the internal world of the agent.
550992	556938	90	B	0.99	So you just define a map that will take into consideration that the agent can have a first perspective on its environment.
557034	563860	91	B	1	The simplest case in the Euclidean case is just rewriting the coordinates of O inside of the frame of the agent, reference frame of the agent.
564310	569682	92	B	1	And then once the agent moves, its frame solid frame in the real world changes.
569816	576630	93	B	1	And this induces indeed a transformation inside of its internal world, which will lead in a fine transformation.
577850	581602	94	B	0.94403	Okay, but you could imagine also having other transformations.
581666	585800	95	B	1	I don't know if you can see my mouse probably.
586330	588118	96	B	1	Can you see my mouse or not?
588284	588614	97	B	0.99856	No.
588652	597062	98	B	0.99098	Okay, so the map CSI can also be something else than an affined transformation.
597206	599702	99	B	1	It could be like any kind of transformation.
599846	604862	100	B	1	For example, in an affined case, the apparent volume of the object doesn't change.
604916	614370	101	B	1	But if you change this map and consider, for example, a projective transformation, as we will describe later, you can have that the size, apparent size of the object changes.
614520	617106	102	C	1	So we went from something that is.
617128	622706	103	B	1	A bit already very well known and not very innovative, which is that you.
622728	623810	104	C	1	Can rewrite.
625530	627878	105	B	0.98	The motions, depends on the.
627884	629846	106	C	0.73324	Frame that you choose to describe them.
630028	638460	107	B	0.99815	Into, saying that you can in fact change some frames to be able to account for some perceptive property.
639870	648890	108	B	1	And what we ask also for the agents that we consider is that they can imagine the consequences of their moves, which on their future observations.
649310	660074	109	B	1	So this is something just to say that the agents that we consider have a notion of agency, which is that they can plan the consequences of their actions so that they can choose the best action with respect to a certain reward.
660122	662474	110	C	1	In particular, the reward that we consider.
662612	665810	111	B	1	Is trying to maximize a certain surprise.
669270	673806	112	B	1	So to sum it up, we have an agent that is looking for certain objects.
673838	676758	113	B	1	So it has beliefs of where this object is.
676844	681622	114	B	0.68	And the beliefs lives on an internal state space.
681676	697590	115	B	1	So on a world model of the environment, it can make observation, which allows it to update its beliefs and then it can predict the consequences of its actions so that it can plan the way that it should act with respect to a certain objective.
697670	703650	116	B	1	So formally, this is simply the notion of Markov decision process, or more generally, like the notion of partially observable Markov.
703670	706270	117	C	0.9995	Decision process because we do not have.
706340	713146	118	B	0.82	A complete information of the environment, but only some observations that are limited.
713338	716170	119	B	0.96	And it's very related.
716250	717440	120	C	1	And let's say.
719830	723726	121	B	0.99306	There'S a strong duality between POMDP and active inference.
723758	725940	122	B	0.99	So there is really a strong link between both.
727350	735670	123	B	0.93	So now what I did in the way that I presented it so I presented it the idea I tried to present the idea of what we're doing.
735740	739018	124	B	1	So the general context POMDPs agents that.
739024	741894	125	C	0.99785	Are planning their action with respect to a certain objective.
741942	743658	126	C	0.97	Here the objective is to find a.
743664	751766	127	B	0.57627	Certain object and I give the formal setting for defining it which are NDP PMDP.
751798	767026	128	B	0.99	And now I will go one step further and define it explicitly and I will continue like this approach for the second part where I will also present our results and our specificity, where I'll dealt with a general statement, then a bit more precise and then really digging into the result.
767208	776018	129	B	1	So here the classical way to define a Markup decision process is to consider that you have a set of configurations of the environment, which is the state space or of the world model in.
776024	777186	130	C	0.98	The way, or at least the way.
777208	778802	131	B	1	That you encode your environment.
778946	785910	132	B	1	So this is something on which you can act, because the agent, when it makes an action, it changes the state of the environment.
786490	791498	133	B	0.99	And the way that the actions change the environment is with respect to a.
791504	797446	134	C	0.99996	Certain Markov kernel, probability kernel.
797558	802102	135	B	1	So it's stochastic, which means that each actions changes the state of the environment.
802166	803622	136	B	0.99999	But you don't know completely.
803776	805098	137	B	0.99973	It's not deterministic.
805194	816546	138	B	1	You allow some errors in the way that it acts on the environment, and you have a reward for a function that is associated to the actions that you can do at time T and also the state of the agent at time t.
816728	822594	139	B	0.95	A partially observable Markov decision process is the same thing than a Markov decision process.
822792	834242	140	B	0.99993	But you authorize to say that your observation on your environment are only partial, which means that you do not have a precise information on the state of the environment.
834386	848710	141	B	1	So the way that you need to relate observation and states is through also a probability kernel, which tells you that if you're at state, for example S, you would expect to make a certain observation.
848870	864334	142	B	0.98435	Let's say if you think the object is at X, you expect to see the object at X, but with a certain error because you know that your sensors are also random, they can make some mistakes and you keep similarly a reward function.
864372	874900	143	B	1	So it's the same thing that an MDP mark audition process, but you just allow to have some to get information on your environment through observations that are not complete.
875610	880194	144	B	0.88	In fact, there's a formulation in terms of partially observable Markov decision processes.
880322	896714	145	B	0.84464	Our particular case of Markov decision processes, which is called belief MDPs, belief Markov decision process and the only difference that you have between Markov process and belief MDP is the fact that the state space is necessarily continuous in the second case.
896752	899930	146	B	0.98	So POMDPs can be seen as a particular case of MDPs.
901230	911882	147	B	0.92	So we said that the actions of a POMDP act on the state space and you account for the consequences of the actions only through observations.
912026	922946	148	B	0.9	So graphically it means that you have the state space of your so the world model of your environment X on which you reference for example, where the object is.
922968	930134	149	B	0.93	So the position of the object and then when you act it induces a consequence on the position of the object at time t plus one.
930172	940150	150	B	1	And then you can make an observation of where you think the object will be or you can make an observation with respect to where the object is, depending if you're planning into the future or if you're really doing the action.
941210	943286	151	C	0.92829	You'Re implementing the consequence of the actions.
943318	944426	152	B	1	In the real world.
944608	950726	153	B	1	The thing that we're trying to do in our setting is to replace simply the actions by a change of perspective.
950838	956542	154	B	0.99963	Like I told you, when the agent acts, its coordinate system on the environment changes.
956676	962282	155	B	1	So you can always see it in a way passively, where you just see it as a change of coordinates.
962426	975070	156	B	0.6	So we want to say that instead of considering actions on the environment, we have a space on which there's a natural notion of changing of reference frame and actions are simply certain kind of changes of frames.
975230	980482	157	B	0.99999	We also allow to have some actions that do not correspond to changes of frames.
980546	992842	158	B	0.99998	We just say that we include the possibility that some actions are changes of frames and the changes of frames have something that is related to all the transformations that are internal for the agents.
992976	1000810	159	B	1	So for example, things that it knows that a priori, it's encoded in the way the agents will interact with the environment.
1002050	1010800	160	B	0.94	So the way that we do it a bit more formally is that we say that changing perspective is simply through the action of a group.
1011410	1022786	161	B	1	So for example, in the affine case, when the agent moves, a change of frame is an affine transformation and we say that the world model.
1022888	1027298	162	B	1	So the state space is simply a space on which the group acts.
1027474	1032806	163	B	1	So formally, what does it mean that the group acts on the space?
1032908	1038600	164	B	0.70206	It's just saying that you have a space.
1038970	1041626	165	B	0.94	S group g.
1041728	1046970	166	B	0.99772	There's an application that goes that takes an element from g and S and that sends back S.
1047040	1049802	167	B	0.98	In other words, for every g you can associate a function.
1049856	1050778	168	B	0.99999	From s to s.
1050864	1055886	169	B	1	And you assume also that it has good properties, which is that it satisfies equation one and.
1055908	1057966	170	C	0.9999	That if you don't move, you stay.
1057988	1058958	171	B	1	At the same place.
1059124	1063858	172	B	1	So this is like just the notion of a g space, a group acting on space.
1064024	1083090	173	B	0.99972	But now if we want to include this in MDPs and POMDPs, we just assume that the state space is a g space, that some actions are some elements of the group, and that when we choose the actions that corresponds to the element of the group, it corresponds to the way that the group acts on the element.
1083170	1086546	174	B	1	So there is nothing like very convoluted.
1086578	1088166	175	B	0.99959	It's just saying that you define the.
1088188	1090410	176	C	0.99989	Collection of functions which you see as.
1090480	1092938	177	B	0.99993	Changes of frames and the way that they act.
1093024	1095834	178	B	0.99	So the probability kernel from the state.
1095872	1098346	179	C	0.99715	Space to the state space at time.
1098368	1107200	180	B	1	T to time t plus one after the action, after the change of perspective is simply through the way that the function changes the state space.
1107570	1110026	181	B	1	So it's just kind of a way of reformulation.
1110058	1117374	182	B	0.99999	But what is really hidden behind here is that we have the structure of the group and that we don't consider any kind of actions.
1117422	1121090	183	B	1	We assume that there is more structure in the actions that we can consider.
1121160	1128754	184	C	1	And that it's defined in the way that it's encoded inside of the geometry.
1128802	1130006	185	B	1	Of the space that we have.
1130108	1132630	186	B	1	So we don't separate any more action and state space.
1132780	1139826	187	B	0.99998	We say that the state space in its geometry encodes already certain kind of actions which are its change of perspectives.
1139938	1141546	188	B	1	So there are two case that we consider.
1141648	1146086	189	B	1	The first case is where the state S is the Occlusion space and g, the FN transformation.
1146118	1157040	190	B	1	It corresponds to translations and rotations of the agents and changing rewriting the coordinates of the object inside of the solid reference frame of the agent.
1157410	1164770	191	B	0.9	And the second case where the space space is a projected space and the group is a projected transformation.
1166710	1179922	192	B	0.99987	We described what are the generative models that we consider and how we can include inside of the classical theory of POMDPs the fact that you can take a perspective on your environment.
1180066	1193046	193	B	0.58	Now we will introduce like a classical notion of epistemic value which will allow us to define what is behavior, what is an exploratory behavior with respect to curiosity.
1193158	1198970	194	B	1	So what it is for an agent to explore its environment based on curiosity.
1199890	1222946	195	B	0.96	So curiosity, or let's say the drive for exploration is quantity that will it's, it's a quantity that you will okay, so it's, okay it's so how do you define it?
1222968	1225150	196	B	0.99972	Just with like very generally.
1225310	1237830	197	B	1	So you start with the agent has a prior on the state of its environment, then it plans the consequence of one of its move at the next time, at the next time step.
1237900	1242566	198	B	1	So this changes the prior that it has on the environment because there's an action on the environment.
1242598	1247370	199	B	1	So we get a new prior and now it's going to make an observation.
1247870	1250646	200	B	0.62	So it imagines that it's going to make an observation.
1250758	1256186	201	B	0.97758	Once it makes an observation there's an apostrophe, the prior is updated.
1256218	1257546	202	B	1	So you get an apostrophe.
1257658	1270206	203	B	1	The way that you define curiosity or let's say epistemic value is how informative is the observation that you will do, how far is the apostrophe from the Apuri?
1270318	1278546	204	B	0.99969	But you cannot do it for one given observation because the way that you compute it is by planning what will happen at the next step.
1278568	1281670	205	B	1	So you need to consider all the possible observation that you will make.
1281740	1291980	206	B	1	So the observations are themselves stochastic with respect to the way that you consider with respect to a priori on the state space of a time t.
1293790	1297910	207	B	0.99998	As we said, forest actions are changes of frame.
1297990	1308670	208	B	1	So we can also define epistemic value for frames for changes of frames and in particular something that we gain, that is I think interesting is that now we have a function that is defined.
1309090	1311262	209	C	0.9997	On a group that can be a continuous group.
1311316	1317038	210	B	1	So you can allow to have for example, if you want to maximize it, you can or minimize it, I mean.
1317044	1318340	211	C	0.41	It depends how you see it.
1318790	1326950	212	B	1	You could do gradient descent for example, so you can have more analytical tools because you're on a space that is continuous and has some structure.
1327770	1338614	213	B	1	So now to give the formal definition of epistemic value, so as I said, it's based on the quantity C that I will define now.
1338812	1344246	214	B	1	So if you give yourself a prior on a space x and you give yourself a probability kernel.
1344278	1351580	215	B	1	So a stochastic map from X to Y, stochastic map is simply saying that for any x you will associate a measure on Y.
1353330	1360510	216	B	0.60199	Then you can get a joint distribution on x and Y, which is simply given by the product p y knowing x times the prior.
1361330	1377590	217	B	0.48	And in fact the quantity C is simply the mutual information between x and Y, which is saying how far is the joint distribution with respect to the independent distribution, the product of the marginal distribution on X and on Y.
1377740	1382118	218	B	0.99698	But this is like you see it appears everywhere the mutual information.
1382284	1388920	219	B	0.99	So this formulation is based on the paper that is from fiston and all active inference and the Pacific value.
1389690	1391586	220	B	0.99559	Mutual information is something that appears everywhere.
1391618	1392694	221	C	0.9995	But I think that there's a very.
1392732	1399926	222	B	0.99999	Nice re expression of the mutual information which allows to give a better interpretation of this quantity, which is the interpretation.
1399958	1401766	223	C	0.9116	That I was discussing in the previous slide.
1401878	1414946	224	B	1	So if you rewrite mutual information, you can always see it as the coolBACK lyler distance between the Aposterior for a given observation and the prior coolBACK distance being a way of computing how far you are, how far the two distribution are.
1415048	1418770	225	B	0.99999	But you need to look at the expectation with respect to the observation that you make.
1418840	1421060	226	B	1	So it's exactly what I was discussing before.
1422870	1431800	227	B	1	So then this is like for any kernel, any kernel from x to Y with a prior on x.
1432250	1440586	228	B	1	But as we were discussing here, you have to take into so this would be the kernel, but you have to take into consideration that you can do actions and that your prior R on X.
1440688	1454094	229	B	0.57	So the way to compute epistemic value for this kernel here when having only the prior on x is that you propagate the prior by the action on x one.
1454212	1466574	230	B	0.99999	Then you get a prior on x one and you can define the epistemic value for this prior and Markov kernel which corresponds to the randomness of your sensors which is always fixed.
1466622	1478440	231	B	1	And this is very important, this one doesn't change even if you change frames, the kernel that you have relating your prior, what you think about the state space relating the state space and the observation never changes.
1479450	1491642	232	B	0.74	And so explicitly this means that after a certain action or after a certain change of frame, you get a joint distribution on x and y, which is the following one here.
1491696	1501094	233	B	1	So this corresponds to the prior propagated on x one and then the epistemic value is simply the mutual information of this joint distribution.
1501222	1503342	234	B	1	So now how does the algorithm work?
1503476	1513810	235	B	0.74	The algorithm that corresponds to defining an exploratory behavior for an agent that is looking for so we started with a prior of where O should be.
1513960	1525410	236	B	0.99993	Then you maximize curiosity based on some changes of frames that are around the identity elements which correspond to not changing frame.
1526230	1537762	237	B	0.99997	Then you get an action that you can apply, you propagate the prior to the next step with this action and then you just update your Apiori with respect to a certain observation and then it loops back.
1537836	1550438	238	B	1	So this is the algorithm that we consider in the second paper that was listed in the presentation, which corresponds to having an agent that is looking for a certain object.
1550624	1565278	239	B	0.5538	Its behavior is defined by an exploratory, is driven by exploration, driven by curiosity, taking into account that its state space is structured by the action of a.
1565284	1569198	240	C	0.99999	Group, so that its state space is structured by the fact that it corresponds.
1569214	1572894	241	B	0.81	To all the possible ways of changing frames.
1572942	1579430	242	B	1	So it has inside of the state space, inside of the geometry of the state space, all the possible ways of changing frames.
1582250	1585814	243	C	1	And this is like explicitly what we do.
1585852	1587846	244	C	0.97	So in this context, this is the.
1587868	1591802	245	B	0.99704	Algorithm that we consider and nothing else, then we get a very interesting result.
1591856	1595418	246	B	1	At least I find it's interesting in.
1595424	1596906	247	C	1	The way that it's presented here.
1596928	1597738	248	B	1	I find it interesting.
1597824	1603726	249	B	0.58	And then if you go more into detail it's because the Ecclesian case is very particular.
1603828	1622494	250	B	0.97287	But what you get is that if you look at the behavior of an agent that is driven by exploration, by curiosity, but that has state space structured by Ecclesial transformation.
1622542	1640822	251	B	1	So the first case where the agent is simply encoding its environment in its reference frame but nothing else, then it doesn't need to move in the second case, where the changes of charts are given by projective transformations.
1640886	1654254	252	B	0.71	So the way it's encoded it's in transformation takes into account a projective deformation of its environment, then it will always try to get closer to the object.
1654372	1657466	253	B	1	So you have two very separate behaviors.
1657658	1663970	254	B	1	So this is something that is I think is very interesting to note.
1665830	1686546	255	B	1	So before going into the details of how you can prove this statement, I will say a bit more about why it's an interesting perspective point of view on this subject because and how it goes a bit further than simply considering this very simple setting.
1686738	1700140	256	B	0.99986	What you could imagine is that encoding the fact that the agent encoding the actions of the agent directly inside of the state space of the agent through geometry could be a way to stabilize the representations of the agent.
1700930	1706670	257	B	1	And this is something that we're working on now and there's already literature in this direction.
1707090	1711290	258	B	0.99764	Okay, so now let us proof the statement.
1711370	1717310	259	B	1	And to prove the statement, we need to give a formal precise statement.
1717470	1727080	260	B	1	So more particularly what we were able to show is that if you assume that the agent has as moves staying still, so it's allowed to stay still.
1727770	1731926	261	C	0.99993	Then if its changes of frame are.
1731948	1736440	262	B	0.99999	Given by a fine transformation, the agent stays still.
1737450	1750060	263	B	1	Now, in the projected case, if you assume that the agent is always looking in the direction of the object, it will always try to get closer to the object.
1753810	1754560	264	B	0.99256	Okay?
1755010	1776834	265	B	1	So the idea of the proof is that what plays the role for drive of the agent is how big the agent is appearing to is the size of the object in the reference frame of the agent and it's how big it appears to be to the agent.
1776952	1783254	266	B	1	So in the first case, the volume of the object in the internal space of the agent doesn't change.
1783372	1784840	267	B	1	So it doesn't need to move.
1785210	1798854	268	B	1	In the second case, if it makes a move, what is informative is to try to make the object bigger because once it's bigger, the apostrophe will be further from the prior with respect to a certain observation.
1798902	1803630	269	B	1	So it will always privilege moves that allow to make the object look bigger.
1803970	1816020	270	B	1	And in this case, what you can do is you can show that this corresponds in fact to actions or change of frames that gets you closer to the object.
1816390	1818290	271	B	0.99	So how do we prove the results?
1818630	1824530	272	B	1	So, as we said, we consider a change of frame from the real world to the internal world.
1824600	1827742	273	B	1	Here, I didn't consider changes of perspectives with respect to moves.
1827806	1830838	274	B	1	Here is simply how you relate the real world to the internal world.
1830924	1846246	275	B	1	In the Euclidean case it's clear, it's just that the way that you write the coordinates of the object in the solid frame in the projective case it's not obvious because there are several ways that you can relate the solid frame of the agent to the projective frame.
1846438	1856400	276	B	1	So one way that we decided to do it is we give some set of axioms that we consider to be, let's say, coherent with our own experience of space.
1856770	1859550	277	B	1	Which is that we feel that we're always centered on ourself.
1859970	1862698	278	B	0.99999	That the axis of the soil frame.
1862714	1865262	279	C	1	Of the agent inside of 3D space.
1865316	1868702	280	B	1	So what is in front of it or what is on the right, what is top are preserved.
1868846	1877430	281	B	0.99996	That there is no point in front of the object that appears to be at infinity and that that near to the center of the object, the volumes are preserved.
1878330	1885000	282	B	0.98	So when you do this formulation like this result is in this article here.
1885530	1888946	283	B	0.74	So the way that we relate some solid.
1888978	1906910	284	B	0.99696	Frames like some solid reference of the agent to some projectors transformations are in this article, in particular in proposition A, one where we show that this set of axioms limits the set of projected transformation we can consider and we will only have this projected transformation.
1907410	1921410	285	B	1	And so the change of frames from the external world to the internal world is given by rewriting the coordinates of the agent of the object in the solid frame of the agent and then applying this projective transformation.
1923590	1930920	286	B	0.64	So now what we defined here are the maps that relate the observation of the agent.
1932730	1933480	287	C	0.95528	Back.
1937050	1952320	288	B	1	So we define the maps in the Euclidean and projective case that relate the observation of the agent observation of the object to the way that it represents this object inside of its internal world here.
1952850	1959134	289	B	0.92	So this is simply like the POMDP that we defined before.
1959332	1964234	290	B	1	And now once the agent doesn't move, it changes its ecclesian reference frame.
1964282	1966414	291	B	1	So there is a solid reference frame.
1966542	1981414	292	B	0.98	So from going from one side reference frame to another solid reference frame, you can, by applying the projective transformation we had before, define another one that we call PSI that goes from the state space at time zero to the state space after action, after moving.
1981612	1983206	293	B	0.99988	What is very important is that we.
1983228	1987526	294	C	0.99989	Consider the Markov kernel associated to a.
1987548	2004474	295	B	0.99645	Noisy observation to be of this shape here, which is that if you know that the object if you think the object is at point X then you believe that the observation will be around X in the ball around X for a ball of a certain radius, which is a small radius.
2004522	2005390	296	B	0.99848	Epsilon.
2005810	2006222	297	B	0.53069	Okay?
2006276	2008720	298	B	0.99	And I need to charge my computer, so sorry.
2026940	2040300	299	B	1	So now press epistemic value as defined curve between the previous formula.
2042080	2045836	300	B	0.58909	What in fact that it has a very simple expression.
2046028	2053052	301	B	1	So the epistemic value of the prior propagated after the transformation phi after this changes of frame phi.
2053116	2054560	302	B	1	So you have a prior here.
2054630	2056224	303	B	1	You propagate it on x one through.
2056262	2058672	304	C	0.61699	Phi and you compute the epistemic value.
2058726	2061956	305	B	0.52	For this joint for the joint distribution over x one.
2061978	2064948	306	B	0.87	And y is given by this formula here.
2065034	2084208	307	B	0.50022	Well, it's simply integrating over all the possible places where the object could be times the probabilistic volume of the ball of size epsilon for the propagated measure and logarithmic of the same quantity.
2084404	2086540	308	B	1	So this is very direct to right.
2086610	2090060	309	B	1	You can just compute it and you find this expression.
2090560	2097810	310	B	0.97134	But what you have already here is that if you consider an Euclidean transformation, then the quantity cubed PSI minus one b epsilon y doesn't change.
2098180	2101292	311	B	1	So then you have the epistemic value that is constant.
2101356	2105280	312	B	1	So basically, if you try to maximize epistemic value, maximize this quantity, you can do anything.
2105350	2107696	313	C	1	You have always one move which is not to move.
2107718	2108336	314	B	1	So you don't move.
2108358	2108716	315	B	0.99979	It's okay.
2108758	2109910	316	B	0.99983	It's perfectly fine.
2110920	2112308	317	B	1	Now, in the second case where you.
2112314	2114036	318	C	0.99997	Have the projective where you consider that.
2114138	2119952	319	B	0.94	The way you relate environment and internal world is through a projective transformation, then it's more complicated.
2120016	2129320	320	B	1	And so you need to use a trick which is that you know that once an observation has been made the support of the prior will be smaller.
2129740	2133772	321	B	0.86	And so after one step if you suppose that your epsilon so the size.
2133826	2136088	322	C	1	Of, let's say noisiness of your sensor.
2136104	2147760	323	B	0.84	Is small enough, you have a support that is of the distribution that's small enough so that you can do an asymptoteic development of the quantity in the interval.
2148580	2155376	324	B	1	So this is an equality, but this is an approximation here and now.
2155478	2171096	325	B	0.99999	This is very useful because now that, you know, doing this in a way you can say that you just need to develop this quantity at the point where the object is really so if you do it, you get this expression here.
2171278	2183850	326	B	1	And what appears to play a role is only the determinant of the Jacobian of a projective transformation which here in the accelerated case will be one in projective case can be many things.
2184860	2188184	327	B	1	So here also it's not very clear because how do you define CM?
2188232	2190664	328	B	0.99	So CM is defined as a composition of several maps.
2190712	2196936	329	B	1	I didn't go into the details but it corresponds to the map that are given by the changes of frame.
2197048	2209670	330	B	0.86	So if you have the occasion space and the internal spaces after moving you have a change of frame in the Euclidean space but it corresponds to also a change of frame in the internal space.
2210040	2219460	331	B	1	So the way you define PSI is simply saying that you inverse the projective transformation from internal world to external world to go at time zero.
2219530	2225000	332	B	0.99999	Then you apply the change of frames and then you apply the projective transformation to go from external to internal.
2226300	2231592	333	B	0.95	And so it is exactly this formula that you have here and which is very nice with this.
2231726	2234984	334	B	0.72	And then you have the first term that doesn't depend on the actions that you do.
2235022	2236348	335	B	1	So you don't need to take it into account.
2236434	2239470	336	B	1	This one will be one and then you just need to compute this one.
2240320	2244464	337	B	1	In fact this one has a very simple expression so it's expression 2023.
2244502	2255200	338	B	1	And then here you can directly see which moves correspond to increasing this quantity and decreasing this quantity because we want to increase epistemic value.
2255350	2270650	339	B	1	And so this is the result this allows to prove the result that we said in the first day like in the several slides before that in the projective case, if you have enough movements, if you look at the object then you're always going to go closer to the object.
2271740	2280964	340	B	0.83	A way to interpret it is as if the agent it was a bit paranoiac or paranoid, a bit like very uncertain on its own beliefs.
2281092	2286296	341	B	1	So it knows the object might be over there but it's always uncertain.
2286328	2290364	342	B	1	So it needs to go check and once it's checked it's more certain.
2290562	2294048	343	B	0.99999	But still as it can always be even more certain.
2294134	2298080	344	B	1	It will always try to get more and more certainty.
2300020	2310416	345	B	1	And so I only presented in this presentation all the aspects which are more computational and the algorithm and some analysis of the algorithm we considered.
2310448	2318632	346	B	0.99912	But we also have some experiments on how this setting allowed to generate different behaviors, behaviors that we would expect explain.
2318686	2321636	347	C	1	For example, some illusions like the Moon illusions.
2321668	2338120	348	B	1	And I invite you, if you're interested on this, to listen on to the online talk of the MOC Four conference that was in Oxford last week or to check out one of these three papers.
2338280	2340620	349	B	0.69	And I would like to thank you very much for your attention.
2348160	2349644	350	A	0.82	All right, awesome.
2349842	2350590	351	A	0.99562	Wow.
2352020	2361030	352	A	0.99995	Very interesting and different ways than how I've seen the POMDP and related works.
2363320	2368916	353	A	0.95281	Okay, let's just start off with little context and then I'll read some questions and read some questions from the live chat.
2368948	2373530	354	A	1	So what brought you to study this question this way?
2376460	2377208	355	B	0.99913	What question?
2377294	2380296	356	B	0.82	The question of, okay, did you come.
2380318	2385352	357	A	0.99999	From a math side and find consciousness and geometries to be interesting or vice versa?
2385416	2388140	358	A	0.99999	What kind of brought you to want to make this contribution?
2388880	2400604	359	C	0.94	So at the beginning so when I did my PhD in maths, I was more interested, I was interested in, let's say, all this idea of critical brain hypothesis.
2400652	2403776	360	C	1	So trying to understand the way that.
2403798	2409780	361	B	1	The brain processes information and makes it something that can be exploited.
2413240	2419716	362	B	0.8	So the critical brain hypothesis tells you that the activity of the neurons is basically close to a certain criticality criticality.
2419748	2421864	363	C	0.74	And the source of statistical physics because.
2421902	2423848	364	B	1	You can model the activation of the.
2423854	2428730	365	C	0.6264	Neurons as, let's say, statistical system like an Icing model.
2429820	2431496	366	B	0.44	So I worked a lot on this.
2431598	2435084	367	C	0.72437	Then there's another hypothesis that is very.
2435122	2437448	368	B	0.99999	Common, which is the Bayesian brain hypothesis.
2437624	2439768	369	B	0.91	And so the Bayesian brain hypothesis led.
2439784	2445740	370	C	1	Me to active inference, to learning more about optimal control, Bayesian perspective on optimal.
2448720	2451984	371	C	0.87	So my advisor was PhD advisor was.
2452022	2453744	372	B	0.99993	Working with David, and they still work.
2453782	2458508	373	C	0.99995	Together on trying to implement some aspects.
2458524	2465264	374	B	1	Of consciousness and how it can influence influence, especially with their article on the Moon illusion.
2465312	2475588	375	B	0.99	So I was interested in knowing how this kind of, let's say, ideas simply.
2475604	2479364	376	C	0.85522	Like in a very naive way, they interact with the Bayesian brain hypothesis.
2479492	2481416	377	B	1	And then I continued in fact, one.
2481438	2487052	378	C	1	Of the lines of my research is structured like algebraically structured statistics or machine learning.
2487186	2493964	379	B	1	And so the way that they see it very geometrically, in fact, let's say geometrically or algebraic, it's not the same.
2494002	2507020	380	C	0.99988	Thing, but it's very related, is something that I wanted to understand a bit better, let's say, to make it in a formal setting so that it's simply a particular case of what is in the literature.
2507100	2510224	381	B	1	So it's specifying what exists in the literature.
2510272	2514276	382	B	1	And this took some time because I was more on the active inference, like.
2514298	2515748	383	C	1	The free energy principle side.
2515834	2527256	384	B	1	So I had to read more about optimal control Stochastic, optimal control Pmdps and understand that in fact, what we're doing is simply adding more structure on the.
2527278	2530168	385	C	0.78905	Latent space of the agent, on the.
2530174	2531450	386	B	0.99934	State space of the agent.
2531760	2537384	387	B	1	And doing this allows to ask the question like why is it useful?
2537512	2541224	388	C	0.99996	Why having a state space that encodes different perspectives?
2541272	2546556	389	B	1	So the motivation comes from consciousness study, cognitive sciences, but why it can be useful for robotics.
2546588	2548092	390	C	1	And it's always been like my motivation.
2548156	2552588	391	B	0.92322	Study some statistical models, more structured models.
2552604	2554864	392	C	0.99964	With more a priori that can be.
2554982	2565440	393	B	0.99924	Useful for understanding the behavior of a closed system like an agent, like a collection of neurons, like even like molecular machines.
2565600	2568230	394	B	1	So it's a very long answer, but it's okay.
2569580	2570328	395	A	0.99842	Cool.
2570494	2577050	396	A	0.69	So you focused on the spatial movement epistemic foraging case.
2577980	2589340	397	A	1	Is there something special about space or can we also think about this perspective taking in terms of, for example, semantic or a narrative reference frame?
2591920	2597644	398	C	0.62	I think it's a very important question because up to now all the work reference will need to space.
2597842	2602364	399	B	1	So the fang is space in terms of a 3D space and not space in terms of geometry.
2602412	2603920	400	C	1	And the fact of writing it as.
2603990	2608016	401	B	0.99999	Geometry allows to get out from the classical point of view a space as.
2608038	2618096	402	C	1	A 3D space because you see that there's more and more like for example, in geometric deep learning, there's more and more the use of space to encode invariance of certain objects.
2618128	2624116	403	C	1	And these objects are not necessarily have the three dimensional structure.
2624148	2626760	404	C	0.61	You can have objects that have higher groups of environments.
2627100	2631592	405	C	0.97	So I think that it's indeed using.
2631646	2633844	406	B	0.99908	Geometry for other contexts.
2633972	2635496	407	B	1	And it's really the aim of trying.
2635518	2637464	408	C	1	To go to this more general formulation.
2637512	2640376	409	B	1	Is to be able to apply it to real world models.
2640408	2641736	410	C	0.99999	What I mean by real world models.
2641768	2643240	411	B	0.99	It means the ones that are learned.
2643320	2644364	412	C	1	To be able to have an agent.
2644402	2645964	413	B	0.53	In an open environment that will learn.
2646002	2649152	414	C	1	The way it would learn its generative model.
2649206	2654176	415	C	0.99994	But they are priori that it can take a perspective on its environment and see what it can do.
2654198	2655424	416	C	1	So we really wanted to get out.
2655462	2658404	417	B	0.99945	From the least for me, go out.
2658442	2660976	418	C	0.99998	From 3D space and go to implementing.
2661008	2665636	419	B	1	It completely in autonomous agents to kind
2665658	2666740	420	A	1	of follow on that.
2666810	2669064	421	A	0.77374	There's a question in the chat: Great talk!
2669182	2675210	422	A	1	I also wonder whether it applies to any modality, not just visual spatial, but also text.
2677020	2679672	423	C	0.99986	Yeah, so for other modalities, like sound,
2679726	2687850	424	B	1	for example, but I don't know for applying to text, there's a lot of work now on large language models and
2688220	2693240	425	C	0.32	all this idea of prompting and having these models being able to have some kind of imagination.
2693400	2698140	426	C	1	So you would like to have these ideas applied in this context.
2698300	2702416	427	C	1	But for now, it's not the line that I'm trying to do.
2702438	2704560	428	C	1	So I'm trying to stay on deep learning.
2704630	2711428	429	C	1	So basically take standard data set without considering text and just try to see
2711514	2716340	430	B	1	how these ideas, like in geometric deep learning, can stabilize representations.
2717080	2723884	431	B	1	So it's not the same that it's clearly other modalities, especially if we consider like, multimodal integration.
2724032	2728376	432	B	0.87682	Like, you try to rebuild the state space and you don't want to see it only as a vector space, but
2728398	2731352	433	C	1	you wanted to see it with more structure because you want to force the way,
2731406	2739516	434	C	0.36919	like you have constraints, you know, a priority, the constraints that you're going to have on the way that you can take a perspective on one moldality or the other.
2739618	2740764	435	B	0.99973	But it's not for text.
2740882	2742492	436	B	0.94	At least not but I think maybe
2742546	2744076	437	C	1	it could be used for text, but
2744098	2745372	438	B	0.93145	it's not what I'm doing now.
2745506	2747630	439	D	0.69675	Can I add something about this question?
2748900	2752770	440	D	0.98688	Sorry, I just want to rebound on that.
2754260	2758080	441	D	1	I have the luck of collaborating with a real mathematician!
2758900	2766112	442	D	0.70707	I'm just some guy with intuition that I've found the right people to do the work regarding multimodality.
2766176	2769588	443	D	0.99999	This is important to understand that this is not about vision.
2769764	2772180	444	D	0.99987	This is about spatial cognition.
2772340	2773748	445	D	0.98511	It's super-model!
2773844	2789820	446	D	1	The claim is that vision is just one particular way of integrating information, indeed in an obviously projective manner, but that's integrated in a much larger field of experience than the field of view or the visual field.
2789970	2792876	447	D	1	And obviously proprioception, touch,
2792978	2813716	448	D	0.99999	when you build a representation just by touching something and you get this 3D representation of that thing automatically in your mind hearing to the extent that it's about source localization and building spatial representation, all of that stuff that's the claim of the theory is integrated in this projective space.
2813898	2822184	449	D	0.98821	There are priors from memories, there are stuff from vision, stuff from addition, stuff from proprioception, interoception, you name it.
2822222	2824056	450	D	1	All senses contribute to it.
2824158	2825284	451	D	1	So it's not vision.
2825332	2830564	452	D	1	The claim is that projective 3D projective geometry in that case is beyond vision.
2830612	2834632	453	D	0.9999	Vision is just actually a slave to that supremodal representation.
2834696	2835660	454	B	0.97505	That's the claim.
2836640	2837390	455	A	0.90767	Awesome!
2838720	2839710	456	A	0.61254	Yeah, please.
2840160	2845004	457	C	0.99333	It's important because I think we work like a group.
2845042	2846456	458	C	0.99427	There are several different perspectives.
2846488	2848064	459	C	0.9	For me, I'm more on the computational side.
2848102	2852050	460	C	1	So it's important to have that because clearly something I won't be able to answer.
2852420	2852976	461	A	0.99974	Cool.
2853078	2856112	462	A	0.99993	Here's a nice following question from Vladimir in the chat.
2856176	2872360	463	A	0.99258	They wrote if the Eg visual sensors have variable resolution, for example, higher resolution in the center, this can naturally lead to Curiosity based change of orientation response within your framework.
2873180	2874964	464	C	0.57	So is it a question or an affirmation?
2875012	2876490	465	C	1	So it's for E g, right?
2878060	2894396	466	A	0.99998	If there's variable sensor precision, for example, higher precision in the sensor, might you see any resulting Curiosity associated change merely based upon the asymmetry or the structure of the sensor field?
2894578	2899616	467	C	0.99803	Okay, so I shouldn't say it, but I will still say it because I don't know if the paper will go out one day or not.
2899638	2901200	468	C	0.61156	But this is more attention.
2902020	2904160	469	B	0.99993	This is more attention than Curiosity.
2905540	2906928	470	C	1	So you can act on your sensor.
2906944	2909764	471	C	0.87	So that you can change the way that you integrate them.
2909802	2913140	472	C	1	And this really acts as a form of attention.
2913800	2916150	473	C	0.95	So I really went into it.
2917560	2921720	474	A	0.99999	What is the interplay between attention and curiosity?
2925820	2935726	475	C	0.85	I mean, it's the way you're going to move basically on the way, the.
2935748	2938420	476	B	0.96116	Way that it deforms the way that you move.
2939030	2941554	477	C	0.99	So the consequences of your actions are not the same.
2941592	2946100	478	C	1	So basically curiosity is what drives actions and the way that you.
2948870	2949426	479	B	0.99999	Choose your.
2949448	2952930	480	C	0.84504	Action with respect to reward, which is epistemic value and now attention.
2953010	2959990	481	C	1	Or let's say changing the sensors is a way to change the consequences of your action with respect to, let's say, optimizing this value.
2960060	2963014	482	C	0.61	So it's, it's like yeah, I mean.
2963052	2966426	483	B	0.71206	It'S it's yeah, I don't know if.
2966448	2969242	484	C	0.99	I should say it or not, but okay, let's say it's okay.
2969376	2970294	485	C	1	I think it's a metric.
2970342	2975150	486	C	0.99997	Basically it acts like a sort of metric on the space, on the group directly.
2976210	2979786	487	C	1	So when you have a function, you want to do gradient descent, you choose a metric.
2979818	2988674	488	C	1	And the metric is so the attention will act as a metric and so the metric will allow you to deform, in fact, the steps that you will do.
2988712	2990318	489	C	1	And so I think this is how it acts.
2990414	3002840	490	C	0.68	So it's very known that it's known that the fact that changing the sensors is related to attention, that's not something much new, but the fact that you can directly in our setting related to groups and you can relate it to.
3003530	3004966	491	B	0.54048	Changing the metric on the group is.
3004988	3006914	492	C	0.99996	Something that can be done.
3006972	3009180	493	C	0.72	And I think it's interesting.
3012030	3014970	494	A	1	All right, another question in the chat.
3016030	3020540	495	A	0.99995	What is a formal framework for learning geometry from data?
3020990	3029498	496	A	0.67	How do we move from empirical data sets, the files on our computers, and the things that we do deep learning on take into machine learning pipelines?
3029594	3038690	497	A	1	And how do we utilize geometric approaches and formalize to the kind of analytical precision that we saw here, some of these geometric relationships.
3039590	3046580	498	C	0.93	So there are several different fields of how to use geometry on data.
3047930	3049666	499	C	0.88	It depends how you see geometry.
3049698	3064010	500	C	0.99876	But one way is a TDA topological data analysis, which is basically trying to, let's say you want to provide learning by geometric stability property of your data and try to interpret it as a certain kind of space.
3064080	3067914	501	C	1	And then you look at the whole of your space and this is something that defines your data set.
3067952	3068854	502	C	0.99	So this is one approach.
3068902	3080074	503	C	0.99998	Another one is people doing manifold, so they know that the data lives in a low dimensional manifold and they try to learn this manifold.
3080122	3082286	504	C	1	So that's another way of doing it.
3082308	3084506	505	C	1	So that's lots of work in this direction.
3084538	3089780	506	C	0.75737	There are people who are interested in variance and equivalents, so more in geometric deep learning.
3090550	3099702	507	C	0.99996	There are people who are interested in the same setting on a priorities how to use geometric aprioris and included in learning for deep learning, reinforcement learning.
3099756	3103814	508	C	1	And this is what we do with this is where many people do this.
3103852	3105080	509	C	0.62765	It's not just us.
3105690	3110700	510	C	1	For us we try to focus on this idea of how to exploit it for reinforcement learning.
3113230	3119682	511	A	0.99	So in this setting Epistemic value was the only driver of action.
3119846	3121486	512	C	0.99	Is that so?
3121508	3127134	513	A	0.60812	It's kind of like an expected free energy except without Pragmatic value.
3127332	3130350	514	A	1	So we only have the Epistemic term remaining?
3130690	3131294	515	B	0.99979	Exactly.
3131412	3149382	516	C	1	In fact if you look at in terms of optimal control and not by Asian, because you know that there's this duality that is most of the time stated in Active Inference where you have basically a duality between let's say value function and a probabilistic version of value function.
3149436	3159686	517	C	1	So you can encode on priors, you can encode all your drives with priors are with the value function directly.
3159718	3179646	518	C	1	So rewards and so both are kind of dual and they're dual in a way you can make this duality, I don't know if it's explicitly dual like in some context this sentence makes sense for Active Inference for me I'm not completely aware if the duality is exactly formal but at least the idea is here.
3179668	3184086	519	C	1	So there's no big difference, at least the way I see it with value function and seeing it probabilistically.
3184138	3190786	520	C	0.9969	But the terms of Epistemic value is an exploration drive which you also find in reinforcement learning.
3190888	3192814	521	C	0.99943	Maybe not in this exact expression.
3192862	3195940	522	C	1	I think that the exact expression that was given in the paper of.
3197770	3198086	523	B	1	I.
3198108	3202246	524	C	0.99527	Think it's pezulo and for sure I.
3202268	3203560	525	B	0.99908	Know is on the paper.
3206830	3213674	526	C	0.60957	It'S very economical way to define Epistemic value.
3213712	3217500	527	C	1	So it's an exploratory drive, you can always add to the value function.
3218750	3230800	528	C	0.904	But there's a lot of problem of trying to explore in fact your environment to find the good policies because if you're in a state space that is continuous it's really difficult to resolve the p one EP.
3235750	3248760	529	A	0.99984	Yes, it's like if you knew which curiosities you could get rewarded from you would have already known the answer to the search.
3250970	3260966	530	A	1	So that's one of the challenges with Pragmatic value it converges well to expectations.
3261078	3272350	531	A	0.99997	But then this work really focuses in on Epistemic value and shows what it can do alone as a driver.
3273330	3277930	532	A	1	So how would you bring Pragmatic value into this formalism?
3278090	3279520	533	C	0.58	You just add it.
3280690	3286642	534	C	1	You can put the value functions of some of rewards in some way and then you add the Epistemic value.
3286696	3297090	535	C	1	In fact, when you look at the formulation in terms of belief MDP for POMDP, the Curiosity Epistemic value is simply a value function, nothing more.
3297160	3298374	536	C	0.79479	It's a one step value function.
3298412	3308700	537	C	0.99983	But I mean this is like just playing with definitions but so you can always add a drive for exploration and this is something that's really often done in reinforcement learning.
3312110	3321900	538	C	0.82	I think it's even standard in not this way, not exactly special, but there's a book that's called Reinforcement Learning state of the art and they introduce this exploratory drive.
3323310	3324526	539	C	0.65973	This is a book maybe that has.
3324548	3326030	540	B	0.99	Ten years or something like that.
3326180	3327840	541	C	1	So it's something that you add up.
3328690	3329774	542	B	1	The way we will do it now.
3329812	3339202	543	C	1	Is we can put some drives with respect to preferences and then you add for example, an epistemic value and you try to just solve the optimization problem.
3339336	3344274	544	C	0.98336	But in terms of formalism, if you look at the belief MDP, it's nothing more than a certain value function.
3344392	3350120	545	C	0.69	So it's not cool.
3351770	3372030	546	A	1	So space remains when we translate through it or when we whether we're in the Euclidean or in the projective setting space is basically what is not changed through action.
3373170	3374222	547	A	1	Is that the case?
3374276	3375200	548	A	0.99889	Okay, yeah.
3378530	3386366	549	C	0.9	The thing is that there's a bit of technicality so the way that we use is we use a chart for the projected plane.
3386398	3392130	550	C	1	So we need to use homogeneous coordinates, so we need to take away a lower dimensional plane.
3392470	3393906	551	B	1	So that's why we always have the.
3393928	3409858	552	C	0.99997	Same like in the way that we encoded, we always are in r three because we chose a chart, we chose homogeneous coordinates and we did projective transformations from one homogeneous coordinate to another homogeneous coordinate but it always lists to a projective transformation.
3409954	3411126	553	C	1	So what is hidden in the way.
3411148	3412202	554	B	1	That we write it is in fact.
3412256	3416118	555	C	1	We don't have the same space in the first case we have ecclesian, in the second we have projective.
3416294	3430234	556	C	0.99785	But the way as we use charts and we don't put all the details of the fact that for example, you can compose two projective transformations even if you write it in charts in terms of homogeneous coordinates and it stays a projective transformation.
3430282	3433906	557	C	0.67991	This is something that is okay but we just don't write it this way.
3433928	3437458	558	C	1	We stay in charts and so that's why there's a similarity between because we.
3437464	3439422	559	B	0.83969	Want to implement it, there's a similarity.
3439486	3440340	560	C	1	Between the.
3442310	3445282	561	B	0.31199	Projective case and projected case.
3445336	3447010	562	C	0.9995	Have the same state space r three.
3447080	3448754	563	C	0.99999	But the space of transformation is really.
3448792	3450870	564	B	0.99991	Different and in fact they are not the same space.
3451020	3460310	565	C	0.99974	But what is important for us in terms of space is just to tell yourself that if you take away everything that is inside of space, everything that populates space, you take it away.
3460460	3470394	566	C	1	What you're left with is with this kind of concepts which already takes into account the fact that when you act you're not changing the space and there's no single point that is singled out.
3470512	3478330	567	C	1	This is very important because it's a very typical like it types a lot the object you're looking at if you move there's no point in the space that is changing.
3478490	3479774	568	B	0.99946	There's no point that is single out.
3479812	3481386	569	C	1	And when you move the space is not changing.
3481418	3486086	570	C	1	So you know that you already have inside of your space a change of charts that is encoded.
3486218	3490466	571	C	1	And even more when you can imagine that you take the perspective of somebody else.
3490648	3496718	572	C	1	And this is really something that is at the basis of the space we consider is that the space is simply.
3496814	3501134	573	B	0.99	A way to support the fact that you can change charts, you can change perspectives.
3501262	3504694	574	C	0.89	And so it's including this idea inside of agency that we're trying to do.
3504732	3505798	575	C	1	So maybe I was not clear in.
3505804	3510520	576	B	1	The way that I said it first, but I think this is really important.
3511390	3513162	577	A	0.64649	It's the water we're in.
3513296	3518682	578	A	1	So it's a very interesting way to approach it.
3518736	3531360	579	A	1	And it reminds me way back when, actually almost three years ago when we discussed the projective consciousness model and phenomenal selfhood in live stream number nine.
3532070	3541330	580	A	0.99	And we talked a lot about flipping between the Euclidean and the projective modes.
3541670	3570746	581	A	1	How an agent could have on one hand a space in which a book is a rectangle and yet also be seeing it very close to their face so that its visual projection was different and yet here there was different behavior associated with the frame alone.
3570938	3587630	582	A	1	So what's going on there where even though they apparently can be reconstructed from each other, what flips can we flip from thinking more Euclidean?
3587710	3595240	583	A	0.84	And then in that situation I'm a plane 30,000ft above my city so there's nowhere I need to go.
3595690	3605800	584	A	0.99999	But then in the projective setting we do have this kind of inbuilt epistemic drive to be near.
3608810	3610890	585	C	1	I think it's hard coded.
3612830	3615750	586	C	0.92	One of the things that it can be useful for is communication.
3615830	3617466	587	C	1	So using space as a way to.
3617488	3619882	588	B	0.99981	Communicate, taking it as a priority that.
3619936	3621942	589	C	1	We have very different architectures.
3622086	3624654	590	C	1	The way that we treat information are not the same.
3624772	3627486	591	C	0.75163	We don't have exactly the same connection, neurons and everything.
3627588	3631742	592	C	0.99998	But we still have a common framework in which we can discuss, for example.
3631796	3646870	593	C	0.73	And visual information is something that is very immediate for us, which is not obvious if you take the perspective, the point of view, if you go from the idea that it's rebuilt and the environment you're living on is not exactly the space that we see.
3646940	3655910	594	C	0.63242	There's something that we constructed for functional reasons and that one of them could be that we can communicate very directly with it.
3656060	3658006	595	C	1	So I think it's hard coded that.
3658028	3664790	596	B	1	The state space needs to have this action and that all the agents share this action but they don't share the same architecture.
3664870	3666234	597	B	1	So it gives a common base for.
3666272	3669690	598	C	0.9998	Discussion like true actions, for example, change of perspective.
3671230	3680734	599	C	0.82	So it's to answer the question eclean projective we're not going in the direction in terms of research where we're trying to say that you can go from Eclean to projective for the same agent.
3680852	3690402	600	C	0.75	So agents are hard coded with a latent space which has some structure and then we try to exploit it for function, for communication, for multi agent like.
3690536	3692530	601	B	0.51944	Behavior so that they can collaborate.
3696250	3705510	602	A	0.84882	Okay, so each agent is within its own projective setting and then the Euclidean sets the stage and allows that multi perspective.
3706090	3708506	603	C	0.99	The Euclidean space, which is the outside.
3708608	3710966	604	B	0.99992	World, is just here in this toy.
3710998	3715450	605	C	0.99899	Model because it's a way to reference the configuration of the world.
3715520	3721558	606	C	0.99991	But for a network, this would be, for example, the configurations of its sensors.
3721734	3723514	607	C	0.57	So it's just here.
3723712	3726750	608	C	0.81422	There's this kind of ambiguity between space and space.
3726820	3736358	609	C	1	So outside space, which is Euclidean and inside, which is projective, but the outside space is just a way to discuss configurations of something that is related.
3736394	3737134	610	C	1	To the environment.
3737182	3743246	611	C	1	So it can be like your sensors, the configuration of your sensors or something like this information coming from your sensors.
3743278	3745266	612	C	1	So you just give a space from it.
3745288	3747494	613	C	1	And the geometry is really in the.
3747532	3749986	614	B	0.73995	Reconstructed world that is internal.
3750098	3755446	615	C	0.58962	But being able to do networks that do this is somewhere that we're working on now.
3755468	3758722	616	C	1	And it's not that obvious because there's a lot of algorithms.
3758786	3761682	617	C	0.98	The problem algorithmic problems that we try to solve.
3761746	3763010	618	C	1	And that we need to solve.
3763090	3767500	619	C	0.92	And this toy model is really like the ambiguity comes only from the fact that it's a toy model.
3768030	3770986	620	C	0.99834	But what is space is inside it's, what is reconstructed.
3771018	3778240	621	C	0.92056	It's the thing that we perceive space from sensors as being a whole, as being something that structures the information.
3779810	3783470	622	C	0.65	So, David you want to say mean.
3783540	3788610	623	D	0.72216	Yes indeed in the talk that you are referring to, I was giving and also kenneth williford if I remember.
3788680	3789806	624	D	0.98307	Well, yeah, indeed.
3789838	3796454	625	D	1	The toy models encoded a certain world model in an Euclidean way.
3796652	3810454	626	D	0.99	And then using homogeneous coordinate and this kind of stuff to do the projective transformation, we just transform the Euclidean space into a projective space and you can go.
3810492	3812198	627	D	1	Of course you can invert it.
3812204	3815786	628	D	0.98	I mean, there is an onliner division, but you can invert it anyway.
3815968	3818026	629	D	1	So you can go from one to the other.
3818128	3819354	630	D	0.98716	But Gregor is right.
3819392	3819706	631	D	0.99885	That it.
3819728	3821450	632	D	0.99996	Was a choice of modeling.
3821610	3826058	633	D	1	It was a bit motivated by my experience as a brain scientist.
3826234	3832582	634	D	0.99899	There are reasons to believe that memory, for instance, place cells and grid cells deaden.
3832666	3835134	635	D	0.99961	Though there are new hypothesis about their hyperbolic.
3835182	3840558	636	D	0.99232	Characters but usually they are thought as encoding space in an ecclesial manner.
3840654	3863382	637	D	1	So since when we project future action, we use sometimes and we have to use memory or even if we do remembrance of the past and we project ourselves in the scenes in the past, there is this access to memory systems that we used to think, and probably this is still the case, encode information in an Euclidean manner.
3863446	3873854	638	D	1	So it would make sense that then for the conscious access, there would be some operation that would allow us to go from Euclidean to projective, which was implemented that way at the same time.
3873892	3887822	639	D	0.70349	But this is way beyond my abilities in math, so Gregor will correct me, there is a way of seeing projective geometry as being more general, as an extension of a fine space by adding point at infinity.
3887886	3891150	640	D	1	So if now you think about a projective space with a metric.
3891310	3893282	641	D	0.99998	Basically, the projective space.
3893336	3895174	642	D	1	Is an extension of Eclidean space.
3895292	3897510	643	D	1	Am I saying something completely false?
3899130	3903190	644	D	0.90128	No, it's one way to seeing it.
3903260	3909586	645	D	1	And there are also a lot of operations that use dialogues, I would say exchange between projective and Eclidean.
3909618	3929690	646	D	0.99863	If you think about multiview reconstruction of 3D Eclidean space from multiple shots in your camera you take several shots of a building from different perspective and then you can use a deterministic algorithm approach using epipolar geometry to kind of infer under some prior that basically all lines that converge at points at infinity are actually parallel.
3929770	3930682	647	D	0.99995	Then you reconstruct.
3930746	3933030	648	D	1	You go from projective to ecclesiast.
3933050	3939010	649	D	0.94	So there is a deep relationship between the two that is possible and probably functional.
3940950	3943426	650	D	0.9148	Yeah, that's about it.
3943528	3947410	651	D	0.74	And Epipolar geometry is a subset of projective geometry.
3948570	3950150	652	D	0.72572	Just to give some context.
3953440	3954188	653	B	0.99819	David has.
3954194	3956524	654	C	1	A better intuition on projective spaces than me.
3956562	3974070	655	C	0.57921	This is like so when he faced notes he really has a very intuitive, physical, personal, visualization and most of the time he's right.
3976680	3983060	656	A	0.99998	Are we experiencing a projective geometry or what is it like to experience a projective geometry?
3984760	3988808	657	C	0.9	So one problem that there is with this model is the fact that you.
3988814	3990244	658	B	0.99991	Need to force the point at infinity.
3990292	3994888	659	C	0.93	To be so the plane you take away from the projected space has to be behind.
3995054	3997880	660	C	1	And so you're not really working with real maps.
3998620	4000024	661	C	0.66803	No, you can always extend them.
4000062	4000504	662	C	0.99994	That's okay.
4000542	4011564	663	C	0.99993	But the thing is if you want to see it in the way that we see it us, which is we have something in front of us I find it a bit restrictive to say that you cannot see what's behind you.
4011602	4013104	664	C	1	I mean, you never see it, right?
4013222	4017228	665	C	0.77	I mean, you can imagine it which is not the same thing because you change your frame.
4017324	4019984	666	C	1	So I can't answer really this question.
4020022	4035380	667	C	0.99799	I'm just pointing out the fact that for me it's very perturbating to think that I have a plane that corresponds to discontinuity with respect to I have a plane that destroys completely the way that I can think about movement behind me.
4035450	4043092	668	C	0.99999	Which is that if I had to imagine I had a whole space that is around me and not just in front of me things would be very weird in terms of transformations.
4043236	4045210	669	C	0.99992	But it's not something that is not possible.
4045840	4048056	670	D	0.99606	This is what happens when you take psychedelic.
4048168	4054424	671	D	1	You basically allow the projective transformation to have all its degrees of freedom.
4054472	4060876	672	D	0.99991	But in the perception, like in sensory motor processes this is calibrated, this is restricted.
4060908	4063632	673	D	1	So we have to choose certain subset of the group.
4063686	4067932	674	D	0.99995	Basically it's only certain projected transformation that will be used in practice.
4067996	4073392	675	D	0.99999	But now if you go into mystical experience or you take drugs they are going to mess.
4073446	4073916	676	D	0.99956	Precisely.
4073948	4076624	677	D	0.89506	That's the hypothesis with those parameters.
4076672	4079696	678	D	1	And now you have the full fledged 15 degrees of freedom transformation.
4079808	4084264	679	D	0.63	And you see things that are very weird, like that looks like mandalas or things like that.
4084302	4089988	680	D	1	So that's something you can get when you leave too much freedom to the projective action.
4090164	4090890	681	D	0.99884	Basically.
4093180	4097710	682	A	1	What if what we're seeing, quote in front of us is behind us or something like that?
4099600	4100670	683	C	0.99989	What do you mean?
4103200	4106750	684	A	0.99999	What was the issue with not being able to see behind us?
4107200	4108140	685	B	0.95	The issue is.
4108210	4117084	686	C	0.7	So if you want to see the projected space as a 3d space, as the way that we see it now, you need to take away a plane and basically projective transformation.
4117132	4123364	687	C	1	So there's a sort of plane at infinity on which you can I mean, it doesn't exist in the projected space.
4123402	4134036	688	C	1	It exists only in the way you define an Ecligian chart, like a 3d, like R three chart with a plane that is taken away, this plane that is behind you.
4134058	4139208	689	C	0.99999	If you apply a projective transformation in front of you, everything will seem fine.
4139374	4146504	690	C	0.98661	You're expecting like it's things that you experience but then once what happened is that it can send things at infinity back behind you.
4146622	4162144	691	C	0.5	So this is something that is a bit I mean, for me so you can write it explicitly there's no problem mathematically but if it's really the way that we experience it, it's extremely weird to think about so I prefer not thinking about it.
4162182	4167250	692	C	0.93	So this is the only thing and I don't take drugs so I leave it to other people.
4168260	4184404	693	C	0.9057	It's true that taking drugs in this context makes complete like you could model it in the projective framework and not in the Euclearian framework because you have a huge amount of projective transformations that make sense more than the one that are related to actions in the art.
4184442	4200380	694	C	0.99	So in the presentation I gave there was a way to relate ecclesian frames to projective frames under certain axioms and in fact you have a huge much bigger space of projective transformations than the one that are restricted by the actions of the agent.
4200450	4202668	695	C	1	So the actions of the agent inside.
4202754	4203740	696	B	1	Of the real space.
4203810	4215856	697	C	0.99	So the Euclidean space induce projective transformation in its internal world but there are much more projective transformation than these actions and so you can imagine in this setting having very confusing states of your.
4215878	4217010	698	B	0.99999	Mind in a way.
4219380	4220156	699	C	0.99982	Which you cannot.
4220188	4221510	700	B	0.98	In the appeal case.
4223800	4243610	701	A	1	I wonder if a creature or a robot with 360 degree cameras would it not be so perplexed as it wouldn't necessarily have a visual before or a visual in front and behind?
4243980	4246350	702	C	0.8	And the thing is how do you glue them together?
4249360	4252732	703	A	1	You still have to pick a point of convergence, right?
4252786	4255992	704	C	0.92	I mean you need to find a way to do multimodal integration.
4256056	4263116	705	C	0.89029	Like, if you want to have a camera that's 360, you have the space to represent it, so maybe you can represent it as a sphere.
4263148	4267568	706	C	0.91	And in this case, the sensors are different.
4267654	4272268	707	C	1	So it's not necessarily the same robot than the models that we are considering.
4272284	4275092	708	C	1	But there might be also another homogeneous space.
4275226	4279060	709	C	1	So g space, it's a space acting which corresponds to the rotations.
4281240	4286212	710	C	0.85199	If you say that, it can look 360 and then you can rotate and the space of observation stays the same.
4286266	4291428	711	C	1	So you can always imagine acting on it and so you can imagine like having another g space structure.
4291524	4306200	712	C	1	And the good thing about it is just with respect to the perspective, if you have an agent that can take a different perspective on its environment, which depends on its sensors, on its actions, on the kind of data you have, then you can define g space and you can do exactly the same setting.
4306280	4311760	713	C	0.99046	Everything like it's made in the more general context so you can apply it.
4311830	4315904	714	C	0.99	And so it's not limited only to the projective case.
4316102	4319330	715	C	0.99999	We come from the PCM projective consciousness model.
4319780	4334920	716	C	0.9926	But the framework now, or at least the way to replace this framework inside of optimal control is well adapted for any change of perspective and not just projective.
4336460	4337160	717	A	0.99909	Awesome.
4337310	4341272	718	A	0.99033	Well, where are you going to go to next?
4341326	4347070	719	A	0.99984	Where will the epistemic drive take you carrying forward?
4347760	4349788	720	B	0.99	So there are two projects now.
4349874	4365728	721	C	1	So the first one is to be able to maybe David can talk, to implement it so that it can be used for monitoring behaviors or to be able to predict behaviors or to analyze it.
4365814	4367376	722	B	1	So you have model of behaviors of.
4367398	4378688	723	C	0.99877	Agents like maladati's behaviors, things that we already published but in a more limited context now to make it inside of a computational framework so that we can use it to analyze experiments with humans.
4378784	4381860	724	C	1	So this is the first project which is ongoing with several students.
4381930	4392740	725	C	1	So on the page that I put on the first slide, there's all the work that we're doing, the people who are working with us and we're very grateful for them working with us and all the ongoing work in this direction.
4392900	4397512	726	C	0.81	And there's the second one, which is more like, let's say machine learning.
4397566	4406216	727	C	1	And so for me it's very important you have effective algorithms, things that you can really use in practice, things that you can really implement and implementing when you have group structures.
4406248	4407864	728	C	0.99999	There are many, many problems that appear.
4407912	4413312	729	C	1	How to do sarcastic optimal control when the latent space is a homogeneous space is, I think, a completely open question.
4413446	4415404	730	C	0.86	I start to have answers in this direction.
4415452	4423700	731	C	1	So I hopefully the work will come out soon, let's say January or something like this.
4423850	4426420	732	C	0.70919	But there's a huge work in this direction.
4428520	4428980	733	C	0.99975	Cool.
4429050	4430710	734	A	0.99998	Anything else you want to add?
4431960	4433940	735	B	1	Thank you very much for the invitation.
4436540	4443368	736	A	1	A lot to think about mentally rotate project.
4443534	4452670	737	A	1	I mean, after all, as you even alluded to with communication, this is a perspective taking question.
4453200	4464800	738	A	0.57909	Technology is adding some new flavors and methods, for example, asynchronous communication, but it's synchronous for the agent when they perceive it.
4464870	4484420	739	A	0.99997	But all these different modalities of communication and it's quite interesting to think about and just really cool that you and colleagues are pursuing that from empirical data analytic and from theoretical mathematical approaches.
4485240	4487204	740	C	0.95	I mean, on this side for communication.
4487252	4488024	741	C	1	I think so.
4488062	4490570	742	C	0.99983	It's something I find extremely interesting.
4490940	4496650	743	C	1	More generally, if some people want to work on the project, please tell us, and I will be very happy.
4497340	4500730	744	C	1	And even if you have money, please tell us, and we will be very happy.
4503740	4504730	745	C	0.97	I agree.
4506140	4506890	746	A	0.99975	Great.
4508100	4508912	747	C	0.75092	We're very open.
4508966	4510156	748	C	1	You can always send us a mail.
4510188	4512450	749	C	0.68782	We'll be very happy to discuss about this.
4513700	4514256	750	C	0.99971	Cool.
4514358	4517650	751	A	0.99171	Okay, well, thank you again to all.
4518100	4519410	752	A	0.5908	Till next time.
4520020	4521728	753	A	0.62485	Okay, see you.
4521814	4522124	754	C	0.9759	Bye.
