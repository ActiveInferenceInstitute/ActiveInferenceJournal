1
00:00:00,000 --> 00:00:09,002
Daniel Friedman: Hello and welcome.

2
00:00:07,663 --> 00:00:12,336
This is active guest stream number 39.1.

3
00:00:09,022 --> 00:00:15,664
It's March 16, 2023.

4
00:00:12,345 --> 00:00:21,258
We are here with Xu Ji, Eric Elmoznino,

5
00:00:21,258 --> 00:00:21,258
and Guillaume Dumas.

6
00:00:16,725 --> 00:00:26,712
We're going to have a presentation

7
00:00:26,712 --> 00:00:26,712
followed by a discussion action.

8
00:00:21,269 --> 00:00:31,205
So thank you all for joining and off to

9
00:00:31,205 --> 00:00:31,205
you for the presentation.

10
00:00:26,720 --> 00:00:33,492
Eric Elmoznino: All right, thanks.

11
00:00:33,415 --> 00:00:34,571
Daniel?

12
00:00:33,495 --> 00:00:35,624
Yeah.

13
00:00:34,587 --> 00:00:36,701
I'm Eric.

14
00:00:35,630 --> 00:00:38,995
I'm a PhD student in Yoshua Bengio's lab.

15
00:00:36,704 --> 00:00:40,105
Xu: I'm Xu Ji.

16
00:00:39,007 --> 00:00:41,292
I'm a postdoc with Yoshua.

17
00:00:40,110 --> 00:00:42,342
Eric: Yeah.

18
00:00:42,311 --> 00:00:44,509
And we're we're really excited to be

19
00:00:44,509 --> 00:00:44,509
here.

20
00:00:42,344 --> 00:00:45,633
Thanks for the invite.

21
00:00:44,512 --> 00:00:50,158
We're going to be talking about why we

22
00:00:50,158 --> 00:00:50,158
can't describe conscious experiences.

23
00:00:45,650 --> 00:00:56,762
So this is going to be our take on a

24
00:00:56,762 --> 00:00:56,762
really long standing problem in the

25
00:00:56,762 --> 00:00:56,762
philosophy of mind.

26
00:00:51,263 --> 00:01:02,759
But we're going to be looking at it

27
00:01:02,759 --> 00:01:02,759
through the lens of computational

28
00:01:02,759 --> 00:01:02,759
neuroscience and information theory.

29
00:00:56,776 --> 00:01:04,971
So, yeah, hopefully it'll be fun for

30
00:01:04,971 --> 00:01:04,971
everyone.

31
00:01:02,769 --> 00:01:06,156
It mixes a bunch of disciplines.

32
00:01:04,974 --> 00:01:19,484
So I think the most salient way to

33
00:01:19,484 --> 00:01:19,484
illustrate the problem that we're going

34
00:01:19,484 --> 00:01:19,484
to be addressing is to ask you to try and

35
00:01:19,484 --> 00:01:19,484
think about how you would describe the

36
00:01:19,484 --> 00:01:19,484
experience of seeing the color red.

37
00:01:07,272 --> 00:01:29,430
So probably the kind of stuff that's

38
00:01:29,430 --> 00:01:29,430
going in your head is things like, well,

39
00:01:29,430 --> 00:01:29,430
it's a bright, aggressive color

40
00:01:29,430 --> 00:01:29,430
symbolizes love, that sort of stuff.

41
00:01:20,553 --> 00:01:32,725
And in a sense, this is a description.

42
00:01:29,437 --> 00:01:33,829
It's effective.

43
00:01:32,744 --> 00:01:39,416
I would be able to guess which color you

44
00:01:39,416 --> 00:01:39,416
were describing, but in another sense,

45
00:01:39,416 --> 00:01:39,416
it's really inadequate.

46
00:01:33,832 --> 00:01:39,440
Xu: Right?

47
00:01:39,422 --> 00:01:42,777
Eric: If I were blind, for instance, your

48
00:01:42,777 --> 00:01:42,777
description would be totally useless.

49
00:01:39,442 --> 00:01:46,012
I would be no better in understanding

50
00:01:46,012 --> 00:01:46,012
what red looks like.

51
00:01:42,787 --> 00:01:53,081
So there's this real sense in which

52
00:01:53,081 --> 00:01:53,081
conscious experiences are ineffable such

53
00:01:53,081 --> 00:01:53,081
that we can't describe them.

54
00:01:46,014 --> 00:01:58,138
And this applies to percepts like red,

55
00:01:58,138 --> 00:01:58,138
but it also applies to experiences more

56
00:01:58,138 --> 00:01:58,138
broadly.

57
00:01:53,082 --> 00:02:03,127
The experience of having a thought is

58
00:02:03,127 --> 00:02:03,127
just so ineffable, so hard to describe.

59
00:01:59,139 --> 00:02:08,179
And really importantly, this doesn't

60
00:02:08,179 --> 00:02:08,179
happen with most of our knowledge.

61
00:02:05,140 --> 00:02:13,224
I could describe most of what I know

62
00:02:13,224 --> 00:02:13,224
except for experiences.

63
00:02:09,185 --> 00:02:14,235
They have this special place.

64
00:02:13,224 --> 00:02:23,328
So it's a big topic in the philosophy of

65
00:02:23,328 --> 00:02:23,328
mind because it relates a lot to this

66
00:02:23,328 --> 00:02:23,328
thing called the hard problem of

67
00:02:23,328 --> 00:02:23,328
consciousness.

68
00:02:14,236 --> 00:02:34,431
So basically all the hard problem is it's

69
00:02:34,431 --> 00:02:34,431
the problem of how and why physical

70
00:02:34,431 --> 00:02:34,431
processes give rise to conscious

71
00:02:34,431 --> 00:02:34,431
experiences in the first place.

72
00:02:24,329 --> 00:02:39,488
So this is probably the oldest and most

73
00:02:39,488 --> 00:02:39,488
debated problem in the philosophy of

74
00:02:39,488 --> 00:02:39,488
mind.

75
00:02:34,437 --> 00:02:43,524
And it's even led many to the conclusion

76
00:02:43,524 --> 00:02:43,524
that actually we're going to give up.

77
00:02:40,489 --> 00:02:52,613
And consciousness can't be explained with

78
00:02:52,613 --> 00:02:52,613
physical theories at all, that it can't

79
00:02:52,613 --> 00:02:52,613
simply emerge from neuroscience

80
00:02:52,613 --> 00:02:52,613
computation or known physical laws.

81
00:02:43,524 --> 00:03:03,666
So that's a bold statement, and I won't

82
00:03:03,666 --> 00:03:03,666
get into all the details about what makes

83
00:03:03,666 --> 00:03:03,666
the hard problem so salient, but just

84
00:03:03,666 --> 00:03:03,666
here's a few things.

85
00:02:53,619 --> 00:03:11,744
So, first of all, we can logically

86
00:03:11,744 --> 00:03:11,744
conceive of what are called philosophical

87
00:03:11,744 --> 00:03:11,744
zombies.

88
00:03:03,669 --> 00:03:15,782
Philosophical zombies very different from

89
00:03:15,782 --> 00:03:15,782
Hollywood zombies.

90
00:03:12,753 --> 00:03:18,813
They're basically beings that are

91
00:03:18,813 --> 00:03:18,813
physically identical to us.

92
00:03:15,782 --> 00:03:19,827
They behave exactly like us.

93
00:03:18,813 --> 00:03:23,861
In fact, they even have the exact same

94
00:03:23,861 --> 00:03:23,861
neural activity that we do.

95
00:03:19,827 --> 00:03:25,881
But they just aren't conscious.

96
00:03:23,864 --> 00:03:35,981
So similarly, instead of these alternate

97
00:03:35,981 --> 00:03:35,981
agents being unconscious, we could also

98
00:03:35,981 --> 00:03:35,981
imagine them as just experiencing

99
00:03:35,981 --> 00:03:35,981
different things when they're in the same

100
00:03:35,981 --> 00:03:35,981
states.

101
00:03:25,885 --> 00:03:46,097
So for instance, it's conceivable at

102
00:03:46,097 --> 00:03:46,097
least that in an alternate universe, the

103
00:03:46,097 --> 00:03:46,097
same exact brain mechanisms that produce

104
00:03:46,097 --> 00:03:46,097
an experience of red in this world would

105
00:03:46,097 --> 00:03:46,097
instead produce an experience of green in

106
00:03:46,097 --> 00:03:46,097
the other.

107
00:03:35,983 --> 00:03:50,136
And that all experiences would kind of be

108
00:03:50,136 --> 00:03:50,136
like flipped in this way.

109
00:03:46,098 --> 00:03:58,209
So intuitively we think that these two

110
00:03:58,209 --> 00:03:58,209
thought experiments aren't actually

111
00:03:58,209 --> 00:03:58,209
possible in our universe.

112
00:03:51,145 --> 00:04:09,262
But even just their logical

113
00:04:09,262 --> 00:04:09,262
conceivability suggests some kind of

114
00:04:09,262 --> 00:04:09,262
explanatory gap where consciousness

115
00:04:09,262 --> 00:04:09,262
doesn't seem to neatly emerge from or be

116
00:04:09,262 --> 00:04:09,262
determined by physical state or

117
00:04:09,262 --> 00:04:09,262
function.

118
00:03:58,210 --> 00:04:14,314
Another really prominent thought

119
00:04:14,314 --> 00:04:14,314
experiment is the knowledge argument.

120
00:04:10,272 --> 00:04:17,341
And this is the main sort of problem that

121
00:04:17,341 --> 00:04:17,341
our work is going to address.

122
00:04:14,314 --> 00:04:20,374
We're not going to address all facets of

123
00:04:20,374 --> 00:04:20,374
the hard problem of consciousness.

124
00:04:17,341 --> 00:04:26,438
But this knowledge argument is one of the

125
00:04:26,438 --> 00:04:26,438
biggest arguments against physicalism.

126
00:04:20,375 --> 00:04:31,487
So how the knowledge argument goes is

127
00:04:31,487 --> 00:04:31,487
it's another thought experiment.

128
00:04:27,447 --> 00:04:38,551
It asks us to imagine Mary, who has grown

129
00:04:38,551 --> 00:04:38,551
up in a black and white room her whole

130
00:04:38,551 --> 00:04:38,551
life.

131
00:04:31,488 --> 00:04:43,608
And despite this poverty and stimulus,

132
00:04:43,608 --> 00:04:43,608
she actually knows a lot.

133
00:04:38,557 --> 00:04:49,664
In fact, we're going to assume that she

134
00:04:49,664 --> 00:04:49,664
knows all the physical facts about how

135
00:04:49,664 --> 00:04:49,664
color perception works.

136
00:04:43,609 --> 00:04:53,700
So all the relevant physics, all the

137
00:04:53,700 --> 00:04:53,700
relevant neuroscience, et cetera.

138
00:04:49,665 --> 00:05:02,736
And now we're going to ask, well, does

139
00:05:02,736 --> 00:05:02,736
she learn something new when she steps

140
00:05:02,736 --> 00:05:02,736
out of the room for the first time and

141
00:05:02,736 --> 00:05:02,736
actually experiences color?

142
00:04:53,708 --> 00:05:11,820
And if we say that she does learn

143
00:05:11,820 --> 00:05:11,820
something new, which I think is the

144
00:05:11,820 --> 00:05:11,820
intuitive answer, there seems to be a

145
00:05:11,820 --> 00:05:11,820
problem.

146
00:05:04,750 --> 00:05:15,864
We assumed that she knew all the relevant

147
00:05:15,864 --> 00:05:15,864
physical facts about color perception.

148
00:05:11,824 --> 00:05:20,915
So doesn't this mean that what she

149
00:05:20,915 --> 00:05:20,915
learned had to be something that was

150
00:05:20,915 --> 00:05:20,915
nonphysical?

151
00:05:15,865 --> 00:05:35,066
And if there was nothing more to color

152
00:05:35,066 --> 00:05:35,066
perception than physically embodied

153
00:05:35,066 --> 00:05:35,066
information and neural activity, then the

154
00:05:35,066 --> 00:05:35,066
experience is something describable that

155
00:05:35,066 --> 00:05:35,066
she presumably could have read about,

156
00:05:35,066 --> 00:05:35,066
understood, and would have already

157
00:05:35,066 --> 00:05:35,066
known?

158
00:05:21,924 --> 00:05:46,178
So it feels like this thought experiment

159
00:05:46,178 --> 00:05:46,178
really pushes us against physicalism

160
00:05:46,178 --> 00:05:46,178
towards this idea that maybe conscious

161
00:05:46,178 --> 00:05:46,178
experience has something on top of just

162
00:05:46,178 --> 00:05:46,178
information content.

163
00:05:35,067 --> 00:05:50,219
Now of course we don't want to reject

164
00:05:50,219 --> 00:05:50,219
physicalism.

165
00:05:48,193 --> 00:05:54,252
It's been very fruitful for us in the

166
00:05:54,252 --> 00:05:54,252
history of science.

167
00:05:51,219 --> 00:05:59,305
So we really do want to say that

168
00:05:59,305 --> 00:05:59,305
experience just consists of information

169
00:05:59,305 --> 00:05:59,305
that can be described.

170
00:05:54,256 --> 00:06:04,292
So there has to be something wrong in

171
00:06:04,292 --> 00:06:04,292
this knowledge argument here.

172
00:05:59,307 --> 00:06:10,351
And what we're going to do is we're going

173
00:06:10,351 --> 00:06:10,351
to bite the bullet and acknowledge that

174
00:06:10,351 --> 00:06:10,351
experiences actually are ineffable.

175
00:06:04,295 --> 00:06:26,517
So maybe it is the case that experiences

176
00:06:26,517 --> 00:06:26,517
can be described in principle since they

177
00:06:26,517 --> 00:06:26,517
consist of nothing more than information,

178
00:06:26,517 --> 00:06:26,517
but maybe they can't be described in

179
00:06:26,517 --> 00:06:26,517
practice, or at least they can't be fully

180
00:06:26,517 --> 00:06:26,517
described in practice using something

181
00:06:26,517 --> 00:06:26,517
like language.

182
00:06:10,353 --> 00:06:33,582
So then the challenge becomes explaining

183
00:06:33,582 --> 00:06:33,582
why experiences are ineffable under a

184
00:06:33,582 --> 00:06:33,582
physicalist framework.

185
00:06:26,519 --> 00:06:37,620
And that's what our work is really going

186
00:06:37,620 --> 00:06:37,620
to be about.

187
00:06:33,583 --> 00:06:42,671
Xu: Okay, so the structure of the talk is

188
00:06:42,671 --> 00:06:42,671
going to be like this.

189
00:06:38,636 --> 00:06:49,745
I'm going to summarize briefly why

190
00:06:49,745 --> 00:06:49,745
characterizing richness and ineffability

191
00:06:49,745 --> 00:06:49,745
is an interesting and important

192
00:06:49,745 --> 00:06:49,745
question.

193
00:06:42,672 --> 00:07:07,862
Then Eric is going to talk about how

194
00:07:07,862 --> 00:07:07,862
there's a natural correspondence between

195
00:07:07,862 --> 00:07:07,862
ineffability and information loss which

196
00:07:07,862 --> 00:07:07,862
is going to let us link biologically

197
00:07:07,862 --> 00:07:07,862
plausible attractor models of working

198
00:07:07,862 --> 00:07:07,862
memory to ineffability, essentially

199
00:07:07,862 --> 00:07:07,862
because information loss is inherent in

200
00:07:07,862 --> 00:07:07,862
attractive dynamics.

201
00:06:49,746 --> 00:07:33,121
Then I will talk about if you consider

202
00:07:33,121 --> 00:07:33,121
the ineffability of conscious experience

203
00:07:33,121 --> 00:07:33,121
to verbal report as just a special case

204
00:07:33,121 --> 00:07:33,121
of information loss between two specific

205
00:07:33,121 --> 00:07:33,121
points in the communication pipeline,

206
00:07:33,121 --> 00:07:33,121
then you can actually generalize the

207
00:07:33,121 --> 00:07:33,121
notion of ineffability more broadly by

208
00:07:33,121 --> 00:07:33,121
considering, for example, loss from

209
00:07:33,121 --> 00:07:33,121
sensory processing to conscious

210
00:07:33,121 --> 00:07:33,121
experience and even interpersonal

211
00:07:33,121 --> 00:07:33,121
information loss.

212
00:07:07,863 --> 00:07:48,275
We're going to prove, using kilgomero of

213
00:07:48,275 --> 00:07:48,275
mutual information that your conscious

214
00:07:48,275 --> 00:07:48,275
experience being ineffable to another

215
00:07:48,275 --> 00:07:48,275
person implies high cognitive

216
00:07:48,275 --> 00:07:48,275
dissimilarity between the two of you

217
00:07:48,275 --> 00:07:48,275
under our model.

218
00:07:33,127 --> 00:08:02,355
And finally we'll talk about whether an

219
00:08:02,355 --> 00:08:02,355
exact definition of conscious experience

220
00:08:02,355 --> 00:08:02,355
is required at least for characterizing

221
00:08:02,355 --> 00:08:02,355
the nature of ineffability and richness

222
00:08:02,355 --> 00:08:02,355
and also some open questions.

223
00:07:49,280 --> 00:08:12,457
So yeah, why is richness and ineffability

224
00:08:12,457 --> 00:08:12,457
an important question?

225
00:08:05,387 --> 00:08:14,476
There are sort of several reasons.

226
00:08:12,459 --> 00:08:21,543
So first, as Eric said, understanding

227
00:08:21,543 --> 00:08:21,543
consciousness is not just of general

228
00:08:21,543 --> 00:08:21,543
interest.

229
00:08:14,476 --> 00:08:38,713
It's a long standing central problem in

230
00:08:38,713 --> 00:08:38,713
philosophy of mind because it's not easy

231
00:08:38,713 --> 00:08:38,713
to reason about, which has led some

232
00:08:38,713 --> 00:08:38,713
dualists to believe that consciousness

233
00:08:38,713 --> 00:08:38,713
must be at least partly nonphysical in

234
00:08:38,713 --> 00:08:38,713
nature because they can't see how it

235
00:08:38,713 --> 00:08:38,713
could be explained by physical

236
00:08:38,713 --> 00:08:38,713
processes.

237
00:08:21,544 --> 00:08:57,905
But it's also a topic that is of great

238
00:08:57,905 --> 00:08:57,905
interest in machine learning because if

239
00:08:57,905 --> 00:08:57,905
you assume that consciousness is

240
00:08:57,905 --> 00:08:57,905
essential to human cognition, then it

241
00:08:57,905 --> 00:08:57,905
follows that we won't be able to engineer

242
00:08:57,905 --> 00:08:57,905
machines that think like humans without

243
00:08:57,905 --> 00:08:57,905
incorporating consciousness.

244
00:08:38,716 --> 00:09:16,029
We're actually going to argue in this

245
00:09:16,029 --> 00:09:16,029
talk that the confusing aspects of human

246
00:09:16,029 --> 00:09:16,029
consciousness, such as its ineffability

247
00:09:16,029 --> 00:09:16,029
can be understood with information

248
00:09:16,029 --> 00:09:16,029
theory, which, as you all know, is born

249
00:09:16,029 --> 00:09:16,029
from computer science.

250
00:09:02,890 --> 00:09:29,167
We're going to use some primitives from

251
00:09:29,167 --> 00:09:29,167
information theory to shed light on why

252
00:09:29,167 --> 00:09:29,167
consciousness is ineffable and hopefully

253
00:09:29,167 --> 00:09:29,167
to dispel some of the mystery surrounding

254
00:09:29,167 --> 00:09:29,167
it.

255
00:09:16,038 --> 00:09:45,324
Eric: All right, so one of the main

256
00:09:45,324 --> 00:09:45,324
primitives over here that we're going to

257
00:09:45,324 --> 00:09:45,324
use is to talk about attractor dynamics

258
00:09:45,324 --> 00:09:45,324
in the brain and in conscious experience

259
00:09:45,324 --> 00:09:45,324
and how that results in ineffability.

260
00:09:31,189 --> 00:09:50,371
So hopefully this sort of perspective is

261
00:09:50,371 --> 00:09:50,371
familiar to most people.

262
00:09:45,329 --> 00:09:58,455
But we could talk about neural dynamics

263
00:09:58,455 --> 00:09:58,455
by saying the brain has a state at any

264
00:09:58,455 --> 00:09:58,455
particular time and we could denote this

265
00:09:58,455 --> 00:09:58,455
state using a vector.

266
00:09:50,371 --> 00:10:06,478
So for instance, in this plot over here,

267
00:10:06,478 --> 00:10:06,478
maybe we could denote each axis in active

268
00:10:06,478 --> 00:10:06,478
states, each dimension using an

269
00:10:06,478 --> 00:10:06,478
individual neuron.

270
00:09:58,457 --> 00:10:12,532
And maybe we denote the activity of each

271
00:10:12,532 --> 00:10:12,532
neuron using its average firing rate.

272
00:10:06,479 --> 00:10:18,591
So any states at a particular time would

273
00:10:18,591 --> 00:10:18,591
be the firing rate of all the neurons

274
00:10:18,591 --> 00:10:18,591
across the brain.

275
00:10:12,533 --> 00:10:22,634
Now, there's nothing special about

276
00:10:22,634 --> 00:10:22,634
neurons or firing rates.

277
00:10:18,595 --> 00:10:32,733
If you think that things like the synapse

278
00:10:32,733 --> 00:10:32,733
strengths or the dendrite potentials or

279
00:10:32,733 --> 00:10:32,733
the astrocytes or whatever else is also

280
00:10:32,733 --> 00:10:32,733
important to the representation, you

281
00:10:32,733 --> 00:10:32,733
could include those in the state.

282
00:10:22,635 --> 00:10:34,750
They're just additional axes.

283
00:10:32,734 --> 00:10:42,836
The details aren't so important as long

284
00:10:42,836 --> 00:10:42,836
as we have some state that describes what

285
00:10:42,836 --> 00:10:42,836
the brain is doing at any particular

286
00:10:42,836 --> 00:10:42,836
time.

287
00:10:34,752 --> 00:10:46,875
Now, of course, the brain is a dynamical

288
00:10:46,875 --> 00:10:46,875
system.

289
00:10:43,848 --> 00:10:48,890
These states are changing.

290
00:10:46,875 --> 00:10:53,944
So you can think of tracing out

291
00:10:53,944 --> 00:10:53,944
trajectories through state space as a

292
00:10:53,944 --> 00:10:53,944
function of time.

293
00:10:48,892 --> 00:11:03,984
And the way that the state evolves will

294
00:11:03,984 --> 00:11:03,984
be determined just by the recurrent

295
00:11:03,984 --> 00:11:03,984
connections within the brain, as well as

296
00:11:03,984 --> 00:11:03,984
inputs coming from elsewhere.

297
00:10:53,948 --> 00:11:06,015
Maybe we're just talking about the

298
00:11:06,015 --> 00:11:06,015
dynamics within a given brain region.

299
00:11:03,985 --> 00:11:13,082
The inputs would be the other brain

300
00:11:13,082 --> 00:11:13,082
regions talking to it, as well as any

301
00:11:13,082 --> 00:11:13,082
sensory stimulus coming in.

302
00:11:06,015 --> 00:11:15,109
Right?

303
00:11:15,105 --> 00:11:23,184
So this dynamical systems perspective of

304
00:11:23,184 --> 00:11:23,184
the brain has been really instrumental in

305
00:11:23,184 --> 00:11:23,184
understanding the computations it

306
00:11:23,184 --> 00:11:23,184
performs.

307
00:11:16,110 --> 00:11:31,265
And one of the primary methods for

308
00:11:31,265 --> 00:11:31,265
characterizing these computations is to

309
00:11:31,265 --> 00:11:31,265
look at what are called the state

310
00:11:31,265 --> 00:11:31,265
attractors of the system.

311
00:11:23,185 --> 00:11:38,334
And for us as well, state attractors are

312
00:11:38,334 --> 00:11:38,334
going to be a really important part of

313
00:11:38,334 --> 00:11:38,334
our ineffability framework in a bit.

314
00:11:31,267 --> 00:11:54,490
So basically what an Tractor state is, is

315
00:11:54,490 --> 00:11:54,490
it's a state where once the system

316
00:11:54,490 --> 00:11:54,490
reaches it, it's going to remain there at

317
00:11:54,490 --> 00:11:54,490
least until inputs come in and change the

318
00:11:54,490 --> 00:11:54,490
dynamics or noise, not just the state out

319
00:11:54,490 --> 00:11:54,490
of this attractor.

320
00:11:39,344 --> 00:11:57,522
So you can see this thing clearly within

321
00:11:57,522 --> 00:11:57,522
the figure.

322
00:11:54,493 --> 00:12:01,502
The X and y axis over here are like the

323
00:12:01,502 --> 00:12:01,502
state of the brain.

324
00:11:58,534 --> 00:12:04,533
Again, maybe something like the average

325
00:12:04,533 --> 00:12:04,533
firing rates of the neurons.

326
00:12:01,503 --> 00:12:08,575
These arrows are illustrating the

327
00:12:08,575 --> 00:12:08,575
dynamics of the brain.

328
00:12:04,534 --> 00:12:12,619
So how the state will evolve given the

329
00:12:12,619 --> 00:12:12,619
brain's connectivity, given the

330
00:12:12,619 --> 00:12:12,619
synapses.

331
00:12:08,576 --> 00:12:18,675
And you can see that there's some regions

332
00:12:18,675 --> 00:12:18,675
where all the arrows, all the dynamics

333
00:12:18,675 --> 00:12:18,675
kind of contract to a single point.

334
00:12:13,620 --> 00:12:21,700
So that's called a fixed point.

335
00:12:19,682 --> 00:12:23,729
If it's one dimensional, it's a kind of

336
00:12:23,729 --> 00:12:23,729
state attractor.

337
00:12:21,701 --> 00:12:35,841
And because all the arrows point towards

338
00:12:35,841 --> 00:12:35,841
it, once you finally reach that state,

339
00:12:35,841 --> 00:12:35,841
you're not going to move out again until

340
00:12:35,841 --> 00:12:35,841
the dynamics change, because inputs came

341
00:12:35,841 --> 00:12:35,841
in or until noise nudges you out.

342
00:12:24,731 --> 00:12:49,984
And you can see that each state attractor

343
00:12:49,984 --> 00:12:49,984
also is associated with this sort of

344
00:12:49,984 --> 00:12:49,984
attractive region, an attractor base in

345
00:12:49,984 --> 00:12:49,984
its cults, where once a trajectory is

346
00:12:49,984 --> 00:12:49,984
somewhere in that region, it will

347
00:12:49,984 --> 00:12:49,984
eventually converge to the attractor

348
00:12:49,984 --> 00:12:49,984
again in the absence of noise.

349
00:12:35,843 --> 00:12:58,071
So these attractors are really common in

350
00:12:58,071 --> 00:12:58,071
the brain and also in artificial

351
00:12:58,071 --> 00:12:58,071
recurrent neural networks trained on

352
00:12:58,071 --> 00:12:58,071
tasks.

353
00:12:50,994 --> 00:13:02,055
And a big computational benefit is that

354
00:13:02,055 --> 00:13:02,055
they provide a form of transient memory.

355
00:12:58,072 --> 00:13:07,102
Once you're in the attractor, you remain

356
00:13:07,102 --> 00:13:07,102
there, that's where the memory comes in.

357
00:13:02,057 --> 00:13:19,228
And because of this and other benefits,

358
00:13:19,228 --> 00:13:19,228
they're implicated in a wide variety of

359
00:13:19,228 --> 00:13:19,228
neural processes like working memory,

360
00:13:19,228 --> 00:13:19,228
long term memory, decision making and

361
00:13:19,228 --> 00:13:19,228
higher level cognition and we'll argue

362
00:13:19,228 --> 00:13:19,228
consciousness in general.

363
00:13:07,104 --> 00:13:22,258
So they're all over the place in the

364
00:13:22,258 --> 00:13:22,258
brain.

365
00:13:19,228 --> 00:13:36,390
An additional aspect of them that's

366
00:13:36,390 --> 00:13:36,390
interesting and it's going to be relevant

367
00:13:36,390 --> 00:13:36,390
for our talk, is that you can think of

368
00:13:36,390 --> 00:13:36,390
attractors as having a sort of dual

369
00:13:36,390 --> 00:13:36,390
discrete and continuous nature.

370
00:13:25,285 --> 00:13:45,486
So what I mean by that is that the

371
00:13:45,486 --> 00:13:45,486
discrete aspects of an attractor is given

372
00:13:45,486 --> 00:13:45,486
by the fact that there's a finite number

373
00:13:45,486 --> 00:13:45,486
of them and that attractors are mutually

374
00:13:45,486 --> 00:13:45,486
exclusive, right?

375
00:13:36,396 --> 00:13:47,507
You're in one or you're in another.

376
00:13:45,487 --> 00:13:53,563
So this means that we could use discrete

377
00:13:53,563 --> 00:13:53,563
symbols to denote which attractor the

378
00:13:53,563 --> 00:13:53,563
system is in.

379
00:13:48,511 --> 00:13:56,590
There's a finite number of them, you're

380
00:13:56,590 --> 00:13:56,590
either in one or another.

381
00:13:53,564 --> 00:14:01,587
And this basically lets us identify or

382
00:14:01,587 --> 00:14:01,587
label the states using a discrete

383
00:14:01,587 --> 00:14:01,587
variable.

384
00:13:56,592 --> 00:14:13,700
There's also a notion though, in which an

385
00:14:13,700 --> 00:14:13,700
attractor is just a continuous high

386
00:14:13,700 --> 00:14:13,700
dimensional vector in this really high

387
00:14:13,700 --> 00:14:13,700
dimensional state space of the brain,

388
00:14:13,700 --> 00:14:13,700
right?

389
00:14:03,603 --> 00:14:15,728
Every attractor basically is just a

390
00:14:15,728 --> 00:14:15,728
vector in state space.

391
00:14:13,700 --> 00:14:20,777
And that means that they're not

392
00:14:20,777 --> 00:14:20,777
arbitrarily discrete states, they have

393
00:14:20,777 --> 00:14:20,777
continuous representations.

394
00:14:15,729 --> 00:14:27,848
We can say, for instance, that one

395
00:14:27,848 --> 00:14:27,848
attractor is more or less similar to

396
00:14:27,848 --> 00:14:27,848
another one depending on how close they

397
00:14:27,848 --> 00:14:27,848
are in state space.

398
00:14:20,778 --> 00:14:34,911
And that gives a representation to the

399
00:14:34,911 --> 00:14:34,911
attractors that's the high dimensional

400
00:14:34,911 --> 00:14:34,911
sort of continuous part.

401
00:14:28,855 --> 00:14:42,994
So just to recap, discrete part is you

402
00:14:42,994 --> 00:14:42,994
could identify which attractor you're in

403
00:14:42,994 --> 00:14:42,994
in the finite set of all possible

404
00:14:42,994 --> 00:14:42,994
attractors.

405
00:14:34,913 --> 00:14:53,107
But you could also talk about an

406
00:14:53,107 --> 00:14:53,107
attractor through this continuous high

407
00:14:53,107 --> 00:14:53,107
dimensional vector that describes where

408
00:14:53,107 --> 00:14:53,107
the attractor is in the high dimensional

409
00:14:53,107 --> 00:14:53,107
state space of the brain.

410
00:14:43,002 --> 00:15:00,111
And to wrap your head around this,

411
00:15:00,111 --> 00:15:00,111
there's a good analogy to word embeddings

412
00:15:00,111 --> 00:15:00,111
in NLP.

413
00:14:54,113 --> 00:15:17,281
So in NLP each word has a discrete ID

414
00:15:17,281 --> 00:15:17,281
that's like the symbolic discrete part,

415
00:15:17,281 --> 00:15:17,281
but also each word is associated to a

416
00:15:17,281 --> 00:15:17,281
high dimensional vector that gives it a

417
00:15:17,281 --> 00:15:17,281
representation sort of the meaning of the

418
00:15:17,281 --> 00:15:17,281
word, where we could say that words are

419
00:15:17,281 --> 00:15:17,281
more or less similar to each other.

420
00:15:00,112 --> 00:15:27,382
Okay, so we're going to use attractor

421
00:15:27,382 --> 00:15:27,382
dynamics quite a bit to explain a

422
00:15:27,382 --> 00:15:27,382
significant source of ineffability in

423
00:15:27,382 --> 00:15:27,382
conscious experience later.

424
00:15:20,313 --> 00:15:36,474
But for that to be relevant, I first need

425
00:15:36,474 --> 00:15:36,474
to spend a bit of time to convince you

426
00:15:36,474 --> 00:15:36,474
that neural dynamics that produce

427
00:15:36,474 --> 00:15:36,474
conscious experience actually do have

428
00:15:36,474 --> 00:15:36,474
attractors.

429
00:15:27,384 --> 00:15:41,523
And for this there's already a lot of

430
00:15:41,523 --> 00:15:41,523
work in the literature connecting

431
00:15:41,523 --> 00:15:41,523
attractors to conscious experience.

432
00:15:36,479 --> 00:15:45,567
So this part is not something new from

433
00:15:45,567 --> 00:15:45,567
our work.

434
00:15:41,524 --> 00:15:56,679
So for instance, one of the leading

435
00:15:56,679 --> 00:15:56,679
theories of consciousness, which is the

436
00:15:56,679 --> 00:15:56,679
global workspace theory, actually

437
00:15:56,679 --> 00:15:56,679
implicitly implies that attractor

438
00:15:56,679 --> 00:15:56,679
dynamics are kind of fundamental.

439
00:15:45,569 --> 00:16:13,789
So what global workspace theory says is

440
00:16:13,789 --> 00:16:13,789
basically like across the brain in all

441
00:16:13,789 --> 00:16:13,789
the different regions, you have sort of

442
00:16:13,789 --> 00:16:13,789
sub process worker, workers basically,

443
00:16:13,789 --> 00:16:13,789
and these different distributed

444
00:16:13,789 --> 00:16:13,789
mechanisms, they can't speak to each

445
00:16:13,789 --> 00:16:13,789
other very easily.

446
00:15:57,685 --> 00:16:19,846
They mainly communicate through this

447
00:16:19,846 --> 00:16:19,846
global workspace just kind of like a

448
00:16:19,846 --> 00:16:19,846
bottleneck.

449
00:16:14,790 --> 00:16:24,897
Think of it like a blackboard that all

450
00:16:24,897 --> 00:16:24,897
the different processes across the brain

451
00:16:24,897 --> 00:16:24,897
could write to.

452
00:16:19,848 --> 00:16:30,951
You could also think of it as like the

453
00:16:30,951 --> 00:16:30,951
ram of the brain, but basically it's

454
00:16:30,951 --> 00:16:30,951
collecting information from the different

455
00:16:30,951 --> 00:16:30,951
workers.

456
00:16:24,898 --> 00:16:52,177
And one key aspect about the global

457
00:16:52,177 --> 00:16:52,177
workspace that's posited in the theory is

458
00:16:52,177 --> 00:16:52,177
that for content in the workspace to then

459
00:16:52,177 --> 00:16:52,177
be broadcast to the subprocesses, for

460
00:16:52,177 --> 00:16:52,177
instance, for us to be able to talk about

461
00:16:52,177 --> 00:16:52,177
what's in the workspace for it to be

462
00:16:52,177 --> 00:16:52,177
written to kind of speech regions.

463
00:16:31,960 --> 00:16:57,226
The content of the workspace has to be

464
00:16:57,226 --> 00:16:57,226
amplified and sustained for a certain

465
00:16:57,226 --> 00:16:57,226
amount of time.

466
00:16:52,178 --> 00:16:59,241
It has to be stable, basically.

467
00:16:57,226 --> 00:17:03,222
And this is clearly where the attractors

468
00:17:03,222 --> 00:17:03,222
come in, right?

469
00:16:59,245 --> 00:17:08,273
Attractors by definition are these states

470
00:17:08,273 --> 00:17:08,273
that are stable, these states that are

471
00:17:08,273 --> 00:17:08,273
sustained.

472
00:17:03,223 --> 00:17:18,376
So basically what global workspace theory

473
00:17:18,376 --> 00:17:18,376
says is that the context of the global

474
00:17:18,376 --> 00:17:18,376
workspace that can be used by the rest of

475
00:17:18,376 --> 00:17:18,376
the brain are the attractor states.

476
00:17:08,274 --> 00:17:33,526
And the relevance to consciousness in

477
00:17:33,526 --> 00:17:33,526
this theory is that it posits that the

478
00:17:33,526 --> 00:17:33,526
contents of this global workspace are the

479
00:17:33,526 --> 00:17:33,526
things that we're aware of, the things

480
00:17:33,526 --> 00:17:33,526
that we're able to report, the things

481
00:17:33,526 --> 00:17:33,526
basically that we're conscious of.

482
00:17:18,377 --> 00:17:36,558
And then just kind of like

483
00:17:36,558 --> 00:17:36,558
terminologically.

484
00:17:34,533 --> 00:17:40,594
Another term for this workspace is called

485
00:17:40,594 --> 00:17:40,594
working memory.

486
00:17:36,558 --> 00:17:50,693
The idea there, it's a sort of like

487
00:17:50,693 --> 00:17:50,693
really short term memory in the sense

488
00:17:50,693 --> 00:17:50,693
that you could quickly act on the things

489
00:17:50,693 --> 00:17:50,693
that are in this global workspace or

490
00:17:50,693 --> 00:17:50,693
report on them.

491
00:17:40,596 --> 00:17:51,708
They're accessible, basically.

492
00:17:50,694 --> 00:17:58,778
Okay, so that's one very powerful

493
00:17:58,778 --> 00:17:58,778
argument for why attractors are relevant

494
00:17:58,778 --> 00:17:58,778
to consciousness.

495
00:17:53,725 --> 00:18:01,744
There's a bunch of other related

496
00:18:01,744 --> 00:18:01,744
arguments.

497
00:17:59,779 --> 00:18:10,835
For instance, just introspectively you

498
00:18:10,835 --> 00:18:10,835
could think of what experience is like is

499
00:18:10,835 --> 00:18:10,835
a sequence going from one thought to the

500
00:18:10,835 --> 00:18:10,835
next to the next.

501
00:18:02,750 --> 00:18:14,873
We kind of have this like a sequence of

502
00:18:14,873 --> 00:18:14,873
discrete events.

503
00:18:10,835 --> 00:18:22,949
And that clearly looks like a dynamical

504
00:18:22,949 --> 00:18:22,949
system, kind of jumping between attractor

505
00:18:22,949 --> 00:18:22,949
states and then experimentally.

506
00:18:14,877 --> 00:18:35,008
There's also been work showing that in

507
00:18:35,008 --> 00:18:35,008
psychology experiments, when you sort of

508
00:18:35,008 --> 00:18:35,008
present a stimulus to a subject and you

509
00:18:35,008 --> 00:18:35,008
vary the amount of time that the stimulus

510
00:18:35,008 --> 00:18:35,008
is presented to kind of bring it below or

511
00:18:35,008 --> 00:18:35,008
above the conscious threshold.

512
00:18:22,951 --> 00:18:44,017
Well, in the conditions where subjects

513
00:18:44,017 --> 00:18:44,017
report being aware of the stimulus, the

514
00:18:44,017 --> 00:18:44,017
main thing that's different is that the

515
00:18:44,017 --> 00:18:44,017
representation is really stable and

516
00:18:44,017 --> 00:18:44,017
robust and noise.

517
00:18:36,009 --> 00:18:48,021
And those are also clearly properties of

518
00:18:48,021 --> 00:18:48,021
attractors.

519
00:18:45,017 --> 00:18:50,023
Xu: Okay?

520
00:18:50,023 --> 00:18:56,029
Eric: So again, I'll use those attractors

521
00:18:56,029 --> 00:18:56,029
to identify a source of ineffability in a

522
00:18:56,029 --> 00:18:56,029
little bit.

523
00:18:50,023 --> 00:19:02,029
But first I need to also introduce how

524
00:19:02,029 --> 00:19:02,029
we're going to formalize the very notion

525
00:19:02,029 --> 00:19:02,029
of ineffability.

526
00:18:56,029 --> 00:19:07,034
And for this we're going to use

527
00:19:07,034 --> 00:19:07,034
information theory part Shannon

528
00:19:07,034 --> 00:19:07,034
information theory.

529
00:19:02,029 --> 00:19:13,040
I'll do that now and then she will talk a

530
00:19:13,040 --> 00:19:13,040
bit about Kamagrav complexity as another

531
00:19:13,040 --> 00:19:13,040
formalism.

532
00:19:07,034 --> 00:19:18,045
But hopefully most people are familiar

533
00:19:18,045 --> 00:19:18,045
with this.

534
00:19:14,041 --> 00:19:23,050
But one thing that we're going to be

535
00:19:23,050 --> 00:19:23,050
using is the entropy of a state.

536
00:19:19,046 --> 00:19:31,058
So for instance, if you have the entropy

537
00:19:31,058 --> 00:19:31,058
of some random variable X, to make things

538
00:19:31,058 --> 00:19:31,058
concrete, maybe that random variable is

539
00:19:31,058 --> 00:19:31,058
conscious experience.

540
00:19:23,050 --> 00:19:41,068
So the entropy of conscious experiences,

541
00:19:41,068 --> 00:19:41,068
that value would be high if the

542
00:19:41,068 --> 00:19:41,068
distribution over conscious experiences

543
00:19:41,068 --> 00:19:41,068
was kind of diffused.

544
00:19:31,058 --> 00:19:51,078
Andy Clark so there's equal probability

545
00:19:51,078 --> 00:19:51,078
for all possible experiences, and entropy

546
00:19:51,078 --> 00:19:51,078
would be low if the distribution over

547
00:19:51,078 --> 00:19:51,078
conscious experiences was peaky.

548
00:19:41,068 --> 00:20:00,081
So that's kind of like the green

549
00:20:00,081 --> 00:20:00,081
distribution in this image would have low

550
00:20:00,081 --> 00:20:00,081
entropy and the red distribution that's

551
00:20:00,081 --> 00:20:00,081
sort of flatter and more uncertainty

552
00:20:00,081 --> 00:20:00,081
would have higher entropy.

553
00:19:51,078 --> 00:20:12,093
And basically what entropy is going to

554
00:20:12,093 --> 00:20:12,093
quantify in our framework is the richness

555
00:20:12,093 --> 00:20:12,093
of a variable, in particular the richness

556
00:20:12,093 --> 00:20:12,093
of conscious experiences.

557
00:20:01,082 --> 00:20:25,106
Why this is a good measure of richness is

558
00:20:25,106 --> 00:20:25,106
because if conscious experiences could

559
00:20:25,106 --> 00:20:25,106
kind of take on many possible values with

560
00:20:25,106 --> 00:20:25,106
equal probability, they're very kind of

561
00:20:25,106 --> 00:20:25,106
diverse in that sense, well, then it's

562
00:20:25,106 --> 00:20:25,106
something that's rich.

563
00:20:12,093 --> 00:20:30,111
Some other notions that are going to be

564
00:20:30,111 --> 00:20:30,111
important are mutual information.

565
00:20:26,107 --> 00:20:35,116
So here that's denoted by I of x and Y.

566
00:20:31,112 --> 00:20:40,121
And what that denotes is how much shared

567
00:20:40,121 --> 00:20:40,121
information there is between two random

568
00:20:40,121 --> 00:20:40,121
variables.

569
00:20:35,116 --> 00:20:50,131
So again, to make things concrete, x we

570
00:20:50,131 --> 00:20:50,131
could take to be a conscious experience,

571
00:20:50,131 --> 00:20:50,131
whereas Y, maybe that's a description of

572
00:20:50,131 --> 00:20:50,131
the experience, maybe a verbal

573
00:20:50,131 --> 00:20:50,131
description.

574
00:20:41,121 --> 00:20:58,139
So in this case, the mutual information

575
00:20:58,139 --> 00:20:58,139
will be really high if the verbal

576
00:20:58,139 --> 00:20:58,139
description uniquely determines the

577
00:20:58,139 --> 00:20:58,139
experience.

578
00:20:51,132 --> 00:21:02,137
So basically, another way of saying that

579
00:21:02,137 --> 00:21:02,137
is knowing the verbal description.

580
00:20:59,140 --> 00:21:05,140
We have no more uncertainty about what

581
00:21:05,140 --> 00:21:05,140
experience is going on.

582
00:21:02,137 --> 00:21:06,141
They perfectly determine each other.

583
00:21:05,140 --> 00:21:09,144
So that would maximize the mutual

584
00:21:09,144 --> 00:21:09,144
information.

585
00:21:06,141 --> 00:21:19,154
And in contrast, if the message told you

586
00:21:19,154 --> 00:21:19,154
nothing about the conscious experience

587
00:21:19,154 --> 00:21:19,154
and you were just as unsure as when you

588
00:21:19,154 --> 00:21:19,154
didn't have the message, well, then the

589
00:21:19,154 --> 00:21:19,154
mutual information would be zero.

590
00:21:09,144 --> 00:21:25,160
This is useful because we could use it to

591
00:21:25,160 --> 00:21:25,160
define a notion of ineffability.

592
00:21:20,155 --> 00:21:35,170
So this conditional entropy that we've

593
00:21:35,170 --> 00:21:35,170
written h of X, given Y is equal

594
00:21:35,170 --> 00:21:35,170
basically to the richness of X.

595
00:21:26,161 --> 00:21:47,182
So the entropy of a conscious, of

596
00:21:47,182 --> 00:21:47,182
conscious experiences minus the mutual

597
00:21:47,182 --> 00:21:47,182
information between conscious experiences

598
00:21:47,182 --> 00:21:47,182
and other variables like their

599
00:21:47,182 --> 00:21:47,182
descriptions, that's the mutual

600
00:21:47,182 --> 00:21:47,182
information.

601
00:21:36,171 --> 00:21:56,191
What this captures basically is how much

602
00:21:56,191 --> 00:21:56,191
information is lost when going from an

603
00:21:56,191 --> 00:21:56,191
experience X to a description Y, right?

604
00:21:48,182 --> 00:22:07,196
If all the information was lost, if Y

605
00:22:07,196 --> 00:22:07,196
doesn't tell you anything about X, the

606
00:22:07,196 --> 00:22:07,196
mutual information is zero, and H of X,

607
00:22:07,196 --> 00:22:07,196
well, the conditional entropy will be

608
00:22:07,196 --> 00:22:07,196
equal to the richness of X.

609
00:21:56,191 --> 00:22:15,204
If Y perfectly determined X, well, then H

610
00:22:15,204 --> 00:22:15,204
of X and the mutual information cancel

611
00:22:15,204 --> 00:22:15,204
and the conditional entropy would be

612
00:22:15,204 --> 00:22:15,204
zero.

613
00:22:07,196 --> 00:22:22,211
So what conditional entropy describes

614
00:22:22,211 --> 00:22:22,211
basically is how much information is lost

615
00:22:22,211 --> 00:22:22,211
when moving from X.

616
00:22:15,204 --> 00:22:26,215
So like a conscious experience to Y, a

617
00:22:26,215 --> 00:22:26,215
description of it.

618
00:22:23,212 --> 00:22:31,220
And that's, that's a perfect description

619
00:22:31,220 --> 00:22:31,220
of what ineffability is intuitively,

620
00:22:31,220 --> 00:22:31,220
right?

621
00:22:26,215 --> 00:22:35,224
It's how much information is is lost when

622
00:22:35,224 --> 00:22:35,224
I try and describe something like an

623
00:22:35,224 --> 00:22:35,224
experience.

624
00:22:31,220 --> 00:22:51,240
Okay, so I think we have most of the

625
00:22:51,240 --> 00:22:51,240
background out of the way, and now we're

626
00:22:51,240 --> 00:22:51,240
ready to describe one main source of

627
00:22:51,240 --> 00:22:51,240
ineffability that arises due to attractor

628
00:22:51,240 --> 00:22:51,240
dynamics.

629
00:22:37,226 --> 00:22:55,244
So very quickly to describe some, some

630
00:22:55,244 --> 00:22:55,244
variables over here that we're going to

631
00:22:55,244 --> 00:22:55,244
be using throughout the presentation.

632
00:22:51,240 --> 00:23:04,247
If you look at that top right diagram,

633
00:23:04,247 --> 00:23:04,247
we're going to have X, which is basically

634
00:23:04,247 --> 00:23:04,247
the trajectory of neural activity that's

635
00:23:04,247 --> 00:23:04,247
relevant for a conscious experience.

636
00:22:55,244 --> 00:23:09,252
So for instance, in Global Workspace, x

637
00:23:09,252 --> 00:23:09,252
would be the trajectory of the working

638
00:23:09,252 --> 00:23:09,252
memory state.

639
00:23:04,247 --> 00:23:15,258
We're going to assume that the trajectory

640
00:23:15,258 --> 00:23:15,258
of neural activity produces a conscious

641
00:23:15,258 --> 00:23:15,258
experience.

642
00:23:10,253 --> 00:23:18,261
We're going to be calling that conscious

643
00:23:18,261 --> 00:23:18,261
experience S throughout.

644
00:23:15,258 --> 00:23:29,272
But also the trajectory importantly is

645
00:23:29,272 --> 00:23:29,272
going to follow attractor dynamics so

646
00:23:29,272 --> 00:23:29,272
they converge to states such as so how

647
00:23:29,272 --> 00:23:29,272
does this result in ineffability?

648
00:23:19,262 --> 00:23:40,283
Well, basically the idea is that whenever

649
00:23:40,283 --> 00:23:40,283
you have attractor dynamics, there's a to

650
00:23:40,283 --> 00:23:40,283
one mapping from trajectories to

651
00:23:40,283 --> 00:23:40,283
attractors and this induces information

652
00:23:40,283 --> 00:23:40,283
loss, right.

653
00:23:29,272 --> 00:23:48,291
Just knowing the attractor, we're not

654
00:23:48,291 --> 00:23:48,291
able to kind of go the other way around

655
00:23:48,291 --> 00:23:48,291
and infer what the original trajectory

656
00:23:48,291 --> 00:23:48,291
was.

657
00:23:40,283 --> 00:23:54,297
So this conditional entropy, this

658
00:23:54,297 --> 00:23:54,297
ineffability of X given A is going to be

659
00:23:54,297 --> 00:23:54,297
high, basically.

660
00:23:48,291 --> 00:23:56,299
All right, why does this matter?

661
00:23:54,297 --> 00:24:02,299
Who cares if there's information lost

662
00:24:02,299 --> 00:24:02,299
between the trajectory of working memory

663
00:24:02,299 --> 00:24:02,299
and the attractors that it converges to?

664
00:23:56,299 --> 00:24:18,315
Well, important thing here again is that

665
00:24:18,315 --> 00:24:18,315
Global Workspace postulates that for

666
00:24:18,315 --> 00:24:18,315
working memory content to be accessible

667
00:24:18,315 --> 00:24:18,315
across the brain, it needs to be

668
00:24:18,315 --> 00:24:18,315
amplified and maintained over a

669
00:24:18,315 --> 00:24:18,315
sufficient duration, so thought to be

670
00:24:18,315 --> 00:24:18,315
around 100 milliseconds.

671
00:24:03,300 --> 00:24:29,326
So this means that working memory is

672
00:24:29,326 --> 00:24:29,326
going through these trajectories X, but

673
00:24:29,326 --> 00:24:29,326
only A, only the attractor can be

674
00:24:29,326 --> 00:24:29,326
reported and only the attractor could

675
00:24:29,326 --> 00:24:29,326
broadly affect behavior.

676
00:24:18,315 --> 00:24:34,331
Only it could be written to memory, only

677
00:24:34,331 --> 00:24:34,331
it could be broadcast to these other

678
00:24:34,331 --> 00:24:34,331
processes.

679
00:24:29,326 --> 00:24:42,339
So that means that the contents of

680
00:24:42,339 --> 00:24:42,339
working memory, kind of these transient

681
00:24:42,339 --> 00:24:42,339
contents in the trajectory, X are

682
00:24:42,339 --> 00:24:42,339
inherently fleeting.

683
00:24:35,332 --> 00:25:00,351
There's rich information that was encoded

684
00:25:00,351 --> 00:25:00,351
in the moment, in the moment of the

685
00:25:00,351 --> 00:25:00,351
trajectory, but that can't later be

686
00:25:00,351 --> 00:25:00,351
recalled or reported because only the

687
00:25:00,351 --> 00:25:00,351
attractors can be recalled or reported

688
00:25:00,351 --> 00:25:00,351
and kind of if we zoom out and go back to

689
00:25:00,351 --> 00:25:00,351
our philosophical notions of

690
00:25:00,351 --> 00:25:00,351
ineffability.

691
00:24:43,340 --> 00:25:03,354
This also explains why it's difficult to

692
00:25:03,354 --> 00:25:03,354
sort of catch yourself in a thought.

693
00:25:00,351 --> 00:25:04,355
Right.

694
00:25:04,355 --> 00:25:13,364
Working memory encodes these rich and

695
00:25:13,364 --> 00:25:13,364
subtle thoughts through the trajectory,

696
00:25:13,364 --> 00:25:13,364
but we can never quite pinpoint or report

697
00:25:13,364 --> 00:25:13,364
in words what those thoughts consisted

698
00:25:13,364 --> 00:25:13,364
of.

699
00:25:04,355 --> 00:25:14,365
Were they verbal?

700
00:25:13,364 --> 00:25:15,366
Were they pre verbal?

701
00:25:14,365 --> 00:25:17,368
Did they consist of visual imagery?

702
00:25:15,366 --> 00:25:18,369
It's really hard to say exactly.

703
00:25:17,368 --> 00:25:30,381
And the reasoning would be that, well,

704
00:25:30,381 --> 00:25:30,381
there's just a lot of information that's

705
00:25:30,381 --> 00:25:30,381
lost going from these trajectories to the

706
00:25:30,381 --> 00:25:30,381
attractors that again we could report on

707
00:25:30,381 --> 00:25:30,381
or that we could recall or they could

708
00:25:30,381 --> 00:25:30,381
just broadly affect behavior.

709
00:25:19,370 --> 00:25:37,388
So that's one huge source of ineffability

710
00:25:37,388 --> 00:25:37,388
arising from attractor dynamics in

711
00:25:37,388 --> 00:25:37,388
working memory.

712
00:25:30,381 --> 00:25:46,397
Now these attractor dynamics also give a

713
00:25:46,397 --> 00:25:46,397
lower bound for ineffability during

714
00:25:46,397 --> 00:25:46,397
verbal report.

715
00:25:40,391 --> 00:25:50,401
So now at the top right, I've added

716
00:25:50,401 --> 00:25:50,401
another variable, M.

717
00:25:47,398 --> 00:25:54,405
That's basically some verbal message that

718
00:25:54,405 --> 00:25:54,405
you could be using to describe your

719
00:25:54,405 --> 00:25:54,405
experience.

720
00:25:50,401 --> 00:25:57,408
And M is a function of the attractors,

721
00:25:57,408 --> 00:25:57,408
right.

722
00:25:54,405 --> 00:26:04,409
According to global workspace, only the

723
00:26:04,409 --> 00:26:04,409
attractors can be reported on or used

724
00:26:04,409 --> 00:26:04,409
across the brain.

725
00:25:57,408 --> 00:26:24,429
So this means that basically, the

726
00:26:24,429 --> 00:26:24,429
ineffability of an experience given a

727
00:26:24,429 --> 00:26:24,429
verbal message has to be at least as

728
00:26:24,429 --> 00:26:24,429
great as the ineffability given an

729
00:26:24,429 --> 00:26:24,429
attractor, because M is a function of the

730
00:26:24,429 --> 00:26:24,429
attractor and you can't gain information

731
00:26:24,429 --> 00:26:24,429
when applying a function, you can only

732
00:26:24,429 --> 00:26:24,429
destroy it.

733
00:26:05,410 --> 00:26:35,440
But we're actually going to argue that

734
00:26:35,440 --> 00:26:35,440
the ineffability is not just lower

735
00:26:35,440 --> 00:26:35,440
bounded by the ineffability of the

736
00:26:35,440 --> 00:26:35,440
attractor, it's actually, in practice,

737
00:26:35,440 --> 00:26:35,440
quite a bit greater than that.

738
00:26:25,430 --> 00:26:40,445
And the reason is that M, this message,

739
00:26:40,445 --> 00:26:40,445
is a discrete variable, right?

740
00:26:35,440 --> 00:26:47,452
It's language, whereas A, the attractor

741
00:26:47,452 --> 00:26:47,452
is this really high dimensional snapshot

742
00:26:47,452 --> 00:26:47,452
of some cortical states.

743
00:26:40,445 --> 00:26:52,457
So because of the asymmetry between the

744
00:26:52,457 --> 00:26:52,457
richness of these variables, there has to

745
00:26:52,457 --> 00:26:52,457
be information loss.

746
00:26:47,452 --> 00:27:00,459
And intuitively, what's going on here is

747
00:27:00,459 --> 00:27:00,459
that you can think of there as being a

748
00:27:00,459 --> 00:27:00,459
many to one mapping from attractors to

749
00:27:00,459 --> 00:27:00,459
messages as well.

750
00:26:52,457 --> 00:27:06,465
So for instance, if I say that I saw fat

751
00:27:06,465 --> 00:27:06,465
cats, that paints a picture.

752
00:27:00,459 --> 00:27:19,478
But it's also leaving out significant

753
00:27:19,478 --> 00:27:19,478
details about the original attractor,

754
00:27:19,478 --> 00:27:19,478
which presumably encoded things that you

755
00:27:19,478 --> 00:27:19,478
were aware of, like the cat's color,

756
00:27:19,478 --> 00:27:19,478
size, pose, the background, all these

757
00:27:19,478 --> 00:27:19,478
things that you were aware of and that

758
00:27:19,478 --> 00:27:19,478
were encoded in the attractor.

759
00:27:06,465 --> 00:27:25,484
But you can't really put into a message

760
00:27:25,484 --> 00:27:25,484
without it being prohibitively large.

761
00:27:19,478 --> 00:27:40,499
So again, the idea here is that the

762
00:27:40,499 --> 00:27:40,499
ineffability of experiences given

763
00:27:40,499 --> 00:27:40,499
messages higher than given attractors,

764
00:27:40,499 --> 00:27:40,499
because the message divides the space of

765
00:27:40,499 --> 00:27:40,499
attractors more coarsely, it's a simpler

766
00:27:40,499 --> 00:27:40,499
variable, it adds additional information

767
00:27:40,499 --> 00:27:40,499
loss.

768
00:27:26,484 --> 00:27:50,509
So one problem is, if language is so

769
00:27:50,509 --> 00:27:50,509
coarse and simple, why can it describe

770
00:27:50,509 --> 00:27:50,509
experiences at all?

771
00:27:44,503 --> 00:28:01,514
And the solution is that while attractors

772
00:28:01,514 --> 00:28:01,514
and the message kind of both share this

773
00:28:01,514 --> 00:28:01,514
discrete part, right?

774
00:27:53,512 --> 00:28:07,520
So the message, because language is

775
00:28:07,520 --> 00:28:07,520
discrete, can be used to index or

776
00:28:07,520 --> 00:28:07,520
identify compositional attractors.

777
00:28:01,514 --> 00:28:12,525
There's this comparable richness

778
00:28:12,525 --> 00:28:12,525
basically between the message and the

779
00:28:12,525 --> 00:28:12,525
discrete part of the attractor.

780
00:28:07,520 --> 00:28:23,536
Which means that in practice, the

781
00:28:23,536 --> 00:28:23,536
richness of the experience h of S is

782
00:28:23,536 --> 00:28:23,536
typically much greater than the

783
00:28:23,536 --> 00:28:23,536
ineffability of the experience given the

784
00:28:23,536 --> 00:28:23,536
message.

785
00:28:12,525 --> 00:28:32,545
So that explains why we still can

786
00:28:32,545 --> 00:28:32,545
communicate somewhat with language, even

787
00:28:32,545 --> 00:28:32,545
though it's this really low dimensional

788
00:28:32,545 --> 00:28:32,545
simple thing.

789
00:28:24,537 --> 00:28:42,555
So, to recap quickly, what we have over

790
00:28:42,555 --> 00:28:42,555
here is the argument that the detractor

791
00:28:42,555 --> 00:28:42,555
dynamics are empirically ubiquitous in

792
00:28:42,555 --> 00:28:42,555
neural activity across brain regions.

793
00:28:33,546 --> 00:28:45,558
They've been proposed as a computational

794
00:28:45,558 --> 00:28:45,558
model for working memory.

795
00:28:42,555 --> 00:28:52,564
And prominent models contends that

796
00:28:52,564 --> 00:28:52,564
conscious experience is a projection of

797
00:28:52,564 --> 00:28:52,564
working memory states.

798
00:28:46,559 --> 00:29:05,572
And one of our key contributions is to

799
00:29:05,572 --> 00:29:05,572
connect these theories to argue that

800
00:29:05,572 --> 00:29:05,572
attractor models, working memory offer an

801
00:29:05,572 --> 00:29:05,572
account for the ineffability of conscious

802
00:29:05,572 --> 00:29:05,572
experience, because attractor dynamics

803
00:29:05,572 --> 00:29:05,572
induce significant information loss.

804
00:28:52,565 --> 00:29:07,574
That's the general argument.

805
00:29:05,572 --> 00:29:10,577
There's one quick thing to add over

806
00:29:10,577 --> 00:29:10,577
here.

807
00:29:09,576 --> 00:29:16,583
So I've been talking about working memory

808
00:29:16,583 --> 00:29:16,583
a lot less about conscious experience so

809
00:29:16,583 --> 00:29:16,583
far.

810
00:29:10,577 --> 00:29:17,584
So let's link the two.

811
00:29:16,583 --> 00:29:25,592
What's going on over here is that there's

812
00:29:25,592 --> 00:29:25,592
many ways to link conscious experience to

813
00:29:25,592 --> 00:29:25,592
X to working memory, basically.

814
00:29:19,586 --> 00:29:28,595
And there's kind of two main options.

815
00:29:25,592 --> 00:29:33,600
So one is we could say that the

816
00:29:33,600 --> 00:29:33,600
instantaneous state of working memory is

817
00:29:33,600 --> 00:29:33,600
always conscious.

818
00:29:28,595 --> 00:29:37,603
So all the states in between attractors

819
00:29:37,603 --> 00:29:37,603
are also consciously experienced.

820
00:29:33,600 --> 00:29:42,609
And how attractors would result in

821
00:29:42,609 --> 00:29:42,609
ineffability.

822
00:29:37,604 --> 00:29:51,618
Here is that, again, what you're able to

823
00:29:51,618 --> 00:29:51,618
recall, what you're able to report is

824
00:29:51,618 --> 00:29:51,618
just the attractor, not the actual

825
00:29:51,618 --> 00:29:51,618
experiences in between attractors that

826
00:29:51,618 --> 00:29:51,618
you were having.

827
00:29:42,609 --> 00:29:58,625
But there's another possibility, which is

828
00:29:58,625 --> 00:29:58,625
to say, well, maybe only the attractors

829
00:29:58,625 --> 00:29:58,625
themselves are experienced.

830
00:29:52,619 --> 00:30:01,622
However, importantly, ineffability exists

831
00:30:01,622 --> 00:30:01,622
regardless in this case, right?

832
00:29:58,625 --> 00:30:07,628
If only A is conscious, a can still

833
00:30:07,628 --> 00:30:07,628
encode the fact that there's information

834
00:30:07,628 --> 00:30:07,628
lost during processing.

835
00:30:02,623 --> 00:30:10,631
And working memory during these

836
00:30:10,631 --> 00:30:10,631
trajectories.

837
00:30:07,628 --> 00:30:12,633
Information loss is something that is

838
00:30:12,633 --> 00:30:12,633
computable.

839
00:30:10,631 --> 00:30:23,644
It could be encoded along some dimensions

840
00:30:23,644 --> 00:30:23,644
in the attractor, for instance, which

841
00:30:23,644 --> 00:30:23,644
explains how we could be consciously

842
00:30:23,644 --> 00:30:23,644
aware that there's information lost

843
00:30:23,644 --> 00:30:23,644
during working memory processing.

844
00:30:12,633 --> 00:30:25,646
Okay.

845
00:30:24,645 --> 00:30:26,647
Xu: Yeah.

846
00:30:26,647 --> 00:30:30,651
So now I'm going to talk about

847
00:30:30,651 --> 00:30:30,651
generalizing ineffability.

848
00:30:27,648 --> 00:30:43,664
Once you view ineffability as information

849
00:30:43,664 --> 00:30:43,664
lost from a source variable to a

850
00:30:43,664 --> 00:30:43,664
destination variable, then there are a

851
00:30:43,664 --> 00:30:43,664
myriad of different pathways that you can

852
00:30:43,664 --> 00:30:43,664
characterize, which we're going to split

853
00:30:43,664 --> 00:30:43,664
into two groups.

854
00:30:32,653 --> 00:30:54,675
So pathways confined within an individual

855
00:30:54,675 --> 00:30:54,675
or intrapersonal communication, and

856
00:30:54,675 --> 00:30:54,675
pathways that extend between individuals

857
00:30:54,675 --> 00:30:54,675
or interpersonal communication.

858
00:30:44,665 --> 00:31:01,676
So in the intracase, you've already seen

859
00:31:01,676 --> 00:31:01,676
conscious experience, the working memory

860
00:31:01,676 --> 00:31:01,676
trajectory, the attractive state, and the

861
00:31:01,676 --> 00:31:01,676
message.

862
00:30:54,675 --> 00:31:14,689
But you can also consider D, which is the

863
00:31:14,689 --> 00:31:14,689
input data to the system, and V, which we

864
00:31:14,689 --> 00:31:14,689
use to denote the state of processes

865
00:31:14,689 --> 00:31:14,689
considered outside the delimitation of

866
00:31:14,689 --> 00:31:14,689
working memory.

867
00:31:01,676 --> 00:31:23,698
And you can also consider the cognitive

868
00:31:23,698 --> 00:31:23,698
parameters of the individual being

869
00:31:23,698 --> 00:31:23,698
communicated to.

870
00:31:16,691 --> 00:31:36,711
So we're going to work with Alice and

871
00:31:36,711 --> 00:31:36,711
Bob, and we're going to assume that Bob

872
00:31:36,711 --> 00:31:36,711
has a brain which is structurally

873
00:31:36,711 --> 00:31:36,711
identical to Alice's but has different

874
00:31:36,711 --> 00:31:36,711
parameters phi, tilde instead of phi.

875
00:31:24,699 --> 00:31:43,718
And we're going to denote Bob's cognitive

876
00:31:43,718 --> 00:31:43,718
state using the tilde.

877
00:31:36,711 --> 00:32:01,730
So empirical evidence from neuroscience

878
00:32:01,730 --> 00:32:01,730
suggests that the brain is hierarchical

879
00:32:01,730 --> 00:32:01,730
in nature, and there are many levels of

880
00:32:01,730 --> 00:32:01,730
organization, many instances of active

881
00:32:01,730 --> 00:32:01,730
dynamics across organizational levels and

882
00:32:01,730 --> 00:32:01,730
cortical regions.

883
00:31:47,722 --> 00:32:22,751
So one example is the inferior temporal

884
00:32:22,751 --> 00:32:22,751
cortex is a sensory processing area that

885
00:32:22,751 --> 00:32:22,751
responds discriminatively to novel

886
00:32:22,751 --> 00:32:22,751
sensory stimuli, whereas the prefrontal

887
00:32:22,751 --> 00:32:22,751
cortex, or PFC, appears to be implicated

888
00:32:22,751 --> 00:32:22,751
in maintaining the attention modulated

889
00:32:22,751 --> 00:32:22,751
representations of working memory.

890
00:32:02,731 --> 00:32:34,763
And to a first approximation, in this

891
00:32:34,763 --> 00:32:34,763
simple model, it's easy to obtain the

892
00:32:34,763 --> 00:32:34,763
result that richness of one process

893
00:32:34,763 --> 00:32:34,763
constrains the richness of another.

894
00:32:23,752 --> 00:32:39,768
So here we have that richness of working

895
00:32:39,768 --> 00:32:39,768
memory trajectories.

896
00:32:35,764 --> 00:32:45,774
Hx is upper bounded by the richness of

897
00:32:45,774 --> 00:32:45,774
its inputs.

898
00:32:39,768 --> 00:32:58,787
And subsequently, we also have that the

899
00:32:58,787 --> 00:32:58,787
richness of conscious experience, HS is

900
00:32:58,787 --> 00:32:58,787
upper bounded by the richness of

901
00:32:58,787 --> 00:32:58,787
conscious experience and the richness of

902
00:32:58,787 --> 00:32:58,787
subprocess states.

903
00:32:45,774 --> 00:33:05,788
Now we're going to zoom out and consider

904
00:33:05,788 --> 00:33:05,788
the interpersonal communication case.

905
00:33:01,784 --> 00:33:12,795
Shannon entropy has some drawbacks when

906
00:33:12,795 --> 00:33:12,795
it comes to characterizing interpersonal

907
00:33:12,795 --> 00:33:12,795
ineffability.

908
00:33:06,789 --> 00:33:14,797
A major one is that Shannon entropy.

909
00:33:12,795 --> 00:33:20,803
Assumes you have access to Phi, Alice's

910
00:33:20,803 --> 00:33:20,803
cognitive parameters.

911
00:33:14,797 --> 00:33:32,815
So note that H phi S given m, for

912
00:33:32,815 --> 00:33:32,815
example, is the descriptional complexity

913
00:33:32,815 --> 00:33:32,815
of S given not just A, but also phi.

914
00:33:20,803 --> 00:33:48,831
And since we can't assume in the

915
00:33:48,831 --> 00:33:48,831
interpersonal case that Bob has access to

916
00:33:48,831 --> 00:33:48,831
Alice's brain parameters, we're going to

917
00:33:48,831 --> 00:33:48,831
rely on the Kulgamarov framework for

918
00:33:48,831 --> 00:33:48,831
information theory.

919
00:33:36,819 --> 00:34:04,841
If you're unfamiliar with the kilgomera

920
00:34:04,841 --> 00:34:04,841
of complexity, the first thing to note is

921
00:34:04,841 --> 00:34:04,841
that conglomerate complexity, or Kx, is

922
00:34:04,841 --> 00:34:04,841
defined on instances X, hence the

923
00:34:04,841 --> 00:34:04,841
lowercase rather than variables, which

924
00:34:04,841 --> 00:34:04,841
are noted by capitals.

925
00:33:48,831 --> 00:34:14,851
Kx is roughly defined as the length in

926
00:34:14,851 --> 00:34:14,851
bits Lz of the shortest binary program Z

927
00:34:14,851 --> 00:34:14,851
that prints x and Holtz.

928
00:34:05,842 --> 00:34:22,859
So there's no explicit dependency on the

929
00:34:22,859 --> 00:34:22,859
probability distribution over X, unlike

930
00:34:22,859 --> 00:34:22,859
in Shannon information.

931
00:34:15,852 --> 00:34:35,872
But we can introduce PX by taking an

932
00:34:35,872 --> 00:34:35,872
expectation over the cogomera of

933
00:34:35,872 --> 00:34:35,872
complexity of state to obtain the

934
00:34:35,872 --> 00:34:35,872
cogomerav version of Shannon entropy.

935
00:34:23,860 --> 00:34:44,881
And likewise for ineffability, we

936
00:34:44,881 --> 00:34:44,881
characterized it before using conditional

937
00:34:44,881 --> 00:34:44,881
entropy.

938
00:34:36,873 --> 00:35:03,894
In the Kogamara framework, expected k of

939
00:35:03,894 --> 00:35:03,894
x given y is sort of the analog to shadow

940
00:35:03,894 --> 00:35:03,894
unconditional entropy, and that

941
00:35:03,894 --> 00:35:03,894
represents the length of the shortest

942
00:35:03,894 --> 00:35:03,894
program that prints X, given that you

943
00:35:03,894 --> 00:35:03,894
know Y or that y is accessible to your

944
00:35:03,894 --> 00:35:03,894
program.

945
00:34:45,882 --> 00:35:26,917
And it's approximately equivalent up to

946
00:35:26,917 --> 00:35:26,917
logarithmic terms to kx minus IX, where

947
00:35:26,917 --> 00:35:26,917
IX colon y is kilgomer of mutual

948
00:35:26,917 --> 00:35:26,917
information, which can be interpreted as

949
00:35:26,917 --> 00:35:26,917
the difference in program length for

950
00:35:26,917 --> 00:35:26,917
printing X depending on if you know Y or

951
00:35:26,917 --> 00:35:26,917
not.

952
00:35:04,895 --> 00:35:37,928
Roughly speaking, there are a lot of

953
00:35:37,928 --> 00:35:37,928
similarities between Shannon information

954
00:35:37,928 --> 00:35:37,928
and Polgamorov information.

955
00:35:27,917 --> 00:35:56,947
For example, mutual information in both

956
00:35:56,947 --> 00:35:56,947
cases is maximized if X is equal to y in

957
00:35:56,947 --> 00:35:56,947
the Shannon case, because that means Y

958
00:35:56,947 --> 00:35:56,947
uniquely determines X, and in the

959
00:35:56,947 --> 00:35:56,947
Kogamarov case, because it means that

960
00:35:56,947 --> 00:35:56,947
given Y, you don't require any extra bits

961
00:35:56,947 --> 00:35:56,947
to print X.

962
00:35:37,928 --> 00:36:11,956
In fact, if you assume knowledge of the

963
00:36:11,956 --> 00:36:11,956
probability distribution P, then expected

964
00:36:11,956 --> 00:36:11,956
cogmera of complexity and Shannon entropy

965
00:36:11,956 --> 00:36:11,956
are equivalent up to some constant

966
00:36:11,956 --> 00:36:11,956
factor.

967
00:35:57,948 --> 00:36:25,970
Because it turns out that the most

968
00:36:25,970 --> 00:36:25,970
efficient way to describe a state X on

969
00:36:25,970 --> 00:36:25,970
average, given that, you know, the

970
00:36:25,970 --> 00:36:25,970
distribution, is to encode X with a

971
00:36:25,970 --> 00:36:25,970
description of length minus log PX.

972
00:36:11,956 --> 00:36:26,971
This.

973
00:36:25,970 --> 00:36:48,993
But if you don't know the distribution

974
00:36:48,993 --> 00:36:48,993
which we want to make use of in the

975
00:36:48,993 --> 00:36:48,993
interpersonal case, because the

976
00:36:48,993 --> 00:36:48,993
parameters of the speaker's brain are not

977
00:36:48,993 --> 00:36:48,993
given, then the higher the descriptive

978
00:36:48,993 --> 00:36:48,993
complexity of that unknown distribution,

979
00:36:48,993 --> 00:36:48,993
then the higher the ceiling on active

980
00:36:48,993 --> 00:36:48,993
inference between expected cognitive

981
00:36:48,993 --> 00:36:48,993
complexity and Shannon entropy.

982
00:36:27,972 --> 00:37:06,005
And in our case, we'd expect that to

983
00:37:06,005 --> 00:37:06,005
apply because the space of cognitive

984
00:37:06,005 --> 00:37:06,005
states is enormous, the probability

985
00:37:06,005 --> 00:37:06,005
distribution over those states is very

986
00:37:06,005 --> 00:37:06,005
complex, and the states themselves are in

987
00:37:06,005 --> 00:37:06,005
general complex to reconstruct being very

988
00:37:06,005 --> 00:37:06,005
high dimensional vectors.

989
00:36:49,994 --> 00:37:25,024
The second advantage of Kogama of

990
00:37:25,024 --> 00:37:25,024
complexity, in addition to allowing us to

991
00:37:25,024 --> 00:37:25,024
explicitly avoid conditioning on the

992
00:37:25,024 --> 00:37:25,024
probability distribution, is that Shannon

993
00:37:25,024 --> 00:37:25,024
entropy is a measure of statistical

994
00:37:25,024 --> 00:37:25,024
determinability of states as opposed to

995
00:37:25,024 --> 00:37:25,024
difference in unique states.

996
00:37:07,006 --> 00:37:41,040
So in Shannon information, entropy is

997
00:37:41,040 --> 00:37:41,040
fully determined by the probability

998
00:37:41,040 --> 00:37:41,040
distribution on states, and it's

999
00:37:41,040 --> 00:37:41,040
unrelated to the meaning or structure or

1000
00:37:41,040 --> 00:37:41,040
content of the states.

1001
00:37:26,025 --> 00:37:57,056
Whereas cogmera of complexity is

1002
00:37:57,056 --> 00:37:57,056
concerned with the difficulty of

1003
00:37:57,056 --> 00:37:57,056
reconstructing states I e absolute

1004
00:37:57,056 --> 00:37:57,056
difference, which corresponds more

1005
00:37:57,056 --> 00:37:57,056
closely to the lay definition of

1006
00:37:57,056 --> 00:37:57,056
ineffability.

1007
00:37:42,041 --> 00:38:05,058
Here are a number of results that we

1008
00:38:05,058 --> 00:38:05,058
include in the paper.

1009
00:38:00,053 --> 00:38:06,059
So the first one is quite simple.

1010
00:38:05,058 --> 00:38:18,071
You can't increase cogmerate complexity

1011
00:38:18,071 --> 00:38:18,071
by conditioning on more states, because

1012
00:38:18,071 --> 00:38:18,071
the program can simply choose to ignore

1013
00:38:18,071 --> 00:38:18,071
the input if it doesn't help to shorten

1014
00:38:18,071 --> 00:38:18,071
the length of the program.

1015
00:38:08,061 --> 00:38:31,084
So we have trivially that KS given m, the

1016
00:38:31,084 --> 00:38:31,084
complexity of conscious experience given

1017
00:38:31,084 --> 00:38:31,084
the message is at least as great as KS

1018
00:38:31,084 --> 00:38:31,084
given m and p phi.

1019
00:38:19,072 --> 00:38:42,095
But you would expect this gap to be quite

1020
00:38:42,095 --> 00:38:42,095
significant because of the complexity of

1021
00:38:42,095 --> 00:38:42,095
p phi.

1022
00:38:32,085 --> 00:38:51,104
In our case, and generally in non toy

1023
00:38:51,104 --> 00:38:51,104
cases, the probability distribution

1024
00:38:51,104 --> 00:38:51,104
itself provides a lot of information.

1025
00:38:44,097 --> 00:38:59,112
So it significantly reduces the

1026
00:38:59,112 --> 00:38:59,112
descriptive complexity of S if you're

1027
00:38:59,112 --> 00:38:59,112
able to condition on it.

1028
00:38:51,104 --> 00:39:33,140
This first result illustrates essentially

1029
00:39:33,140 --> 00:39:33,140
the difference in ineffability from the

1030
00:39:33,140 --> 00:39:33,140
tabular raza case on the left, where you

1031
00:39:33,140 --> 00:39:33,140
don't condition on Alice's brain

1032
00:39:33,140 --> 00:39:33,140
parameters phi, to the case where you can

1033
00:39:33,140 --> 00:39:33,140
assume access to Alice's brain

1034
00:39:33,140 --> 00:39:33,140
parameters, which is analogous to the

1035
00:39:33,140 --> 00:39:33,140
Shannon entropy characterization that

1036
00:39:33,140 --> 00:39:33,140
Eric was talking about.

1037
00:39:01,108 --> 00:39:40,147
But the quantity that we're more

1038
00:39:40,147 --> 00:39:40,147
interested in is this expression in the

1039
00:39:40,147 --> 00:39:40,147
green box.

1040
00:39:33,140 --> 00:40:21,182
So K s given M and P tilde phi, which is

1041
00:40:21,182 --> 00:40:21,182
the expected ineffability well, in

1042
00:40:21,182 --> 00:40:21,182
expectation of Alice's experience s given

1043
00:40:21,182 --> 00:40:21,182
the message and Bob's brain parameters

1044
00:40:21,182 --> 00:40:21,182
tilde phi, you can show that this

1045
00:40:21,182 --> 00:40:21,182
quantity is upper bounded by an

1046
00:40:21,182 --> 00:40:21,182
expression that scales with KP phi given

1047
00:40:21,182 --> 00:40:21,182
tilde phi, which is a measure of the

1048
00:40:21,182 --> 00:40:21,182
cognitive dissimilarity or the

1049
00:40:21,182 --> 00:40:21,182
descriptive complexity of Alice's brain

1050
00:40:21,182 --> 00:40:21,182
given Bob's brain.

1051
00:39:40,147 --> 00:40:32,193
So, in other words, if your experiences

1052
00:40:32,193 --> 00:40:32,193
are ineffable to someone I e, the left

1053
00:40:32,193 --> 00:40:32,193
hand term in the green box is high.

1054
00:40:22,183 --> 00:40:40,201
That implies that your brains are highly

1055
00:40:40,201 --> 00:40:40,201
behaviorally dissimilar under our model.

1056
00:40:33,194 --> 00:40:53,214
So we can use this result to provide an

1057
00:40:53,214 --> 00:40:53,214
account for what Mary learned when she

1058
00:40:53,214 --> 00:40:53,214
stepped out of her black and white room.

1059
00:40:43,204 --> 00:41:10,225
And essentially what it's saying is that

1060
00:41:10,225 --> 00:41:10,225
neurotypical Alice's experience of color

1061
00:41:10,225 --> 00:41:10,225
is ineffable to Mary, which implies that

1062
00:41:10,225 --> 00:41:10,225
they are cognitively dissimilar.

1063
00:40:54,215 --> 00:41:25,240
And cognitive dissimilarity is not the

1064
00:41:25,240 --> 00:41:25,240
same as knowledge inadequacy, because

1065
00:41:25,240 --> 00:41:25,240
knowing how the brain should respond to a

1066
00:41:25,240 --> 00:41:25,240
particular stimulus is not the same as

1067
00:41:25,240 --> 00:41:25,240
being able to execute that response when

1068
00:41:25,240 --> 00:41:25,240
you're actually exposed to the stimulus.

1069
00:41:10,225 --> 00:41:38,253
So the cognitive dissimilarity principle

1070
00:41:38,253 --> 00:41:38,253
is something that we generally believe

1071
00:41:38,253 --> 00:41:38,253
intuitively, but it's also been studied

1072
00:41:38,253 --> 00:41:38,253
in neuroscience.

1073
00:41:25,240 --> 00:41:52,267
So the ability for the neural activity of

1074
00:41:52,267 --> 00:41:52,267
two brains to synchronize, which is to

1075
00:41:52,267 --> 00:41:52,267
say, to behave in a mutually determined

1076
00:41:52,267 --> 00:41:52,267
manner, appears to facilitate

1077
00:41:52,267 --> 00:41:52,267
communication between individuals.

1078
00:41:38,253 --> 00:42:01,270
There's also a connection to theory of

1079
00:42:01,270 --> 00:42:01,270
mind, which is the skill of being able to

1080
00:42:01,270 --> 00:42:01,270
infer the thoughts of others.

1081
00:41:54,269 --> 00:42:21,290
So if Bob's cognitive functions, FX and

1082
00:42:21,290 --> 00:42:21,290
FS, which produce his working memory

1083
00:42:21,290 --> 00:42:21,290
trajectory and his conscious experience,

1084
00:42:21,290 --> 00:42:21,290
are optimized for decoding Alice's

1085
00:42:21,290 --> 00:42:21,290
message m into her conscious experience

1086
00:42:21,290 --> 00:42:21,290
s, then ineffability is reduced.

1087
00:42:01,270 --> 00:42:47,316
If bob's conscious experience s tilde is

1088
00:42:47,316 --> 00:42:47,316
conditioned on compared to m because it

1089
00:42:47,316 --> 00:42:47,316
implies that part of the computation of

1090
00:42:47,316 --> 00:42:47,316
reconstructing s is executed during

1091
00:42:47,316 --> 00:42:47,316
inference of tilde s meaning that the

1092
00:42:47,316 --> 00:42:47,316
smallest program from tilde s bob's

1093
00:42:47,316 --> 00:42:47,316
conscious.

1094
00:42:21,290 --> 00:42:53,322
Experience and tilde phi Bob's cognitive

1095
00:42:53,322 --> 00:42:53,322
parameters to s.

1096
00:42:47,316 --> 00:43:14,337
Alice's conscious experience would make

1097
00:43:14,337 --> 00:43:14,337
use of tilde s to reduce the sort of

1098
00:43:14,337 --> 00:43:14,337
residual work that needs to be the

1099
00:43:14,337 --> 00:43:14,337
residual information that needs to be

1100
00:43:14,337 --> 00:43:14,337
supplied in order to determine s, which

1101
00:43:14,337 --> 00:43:14,337
would shorten the descriptive length of

1102
00:43:14,337 --> 00:43:14,337
that program.

1103
00:42:53,322 --> 00:43:30,353
So, in other words, making progress at

1104
00:43:30,353 --> 00:43:30,353
inferring the conscious experience of

1105
00:43:30,353 --> 00:43:30,353
others in your own cognitive processing

1106
00:43:30,353 --> 00:43:30,353
could literally be interpreted as

1107
00:43:30,353 --> 00:43:30,353
reducing the ineffability of their

1108
00:43:30,353 --> 00:43:30,353
conscious experience.

1109
00:43:15,338 --> 00:43:36,359
Quickly, we're going to touch on the

1110
00:43:36,359 --> 00:43:36,359
grounding problem.

1111
00:43:33,356 --> 00:43:41,364
So, as Eric mentioned before, two

1112
00:43:41,364 --> 00:43:41,364
individuals will generally understand the

1113
00:43:41,364 --> 00:43:41,364
same word or sentence in different ways.

1114
00:43:36,359 --> 00:43:48,371
And our measure of ineffability does

1115
00:43:48,371 --> 00:43:48,371
capture this dissonance for two reasons.

1116
00:43:42,365 --> 00:44:05,382
And first, measures of ineffability, such

1117
00:44:05,382 --> 00:44:05,382
as we saw in the previous slide, they are

1118
00:44:05,382 --> 00:44:05,382
bound by a ceiling that scales with

1119
00:44:05,382 --> 00:44:05,382
cognitive dissimilarity or the cogmera of

1120
00:44:05,382 --> 00:44:05,382
complexity of PFI given p, tilde Phi.

1121
00:43:48,371 --> 00:44:16,393
And phi includes all the parameters in

1122
00:44:16,393 --> 00:44:16,393
Alice's computational graph, including

1123
00:44:16,393 --> 00:44:16,393
those that parameterize functions defined

1124
00:44:16,393 --> 00:44:16,393
on the input data D.

1125
00:44:05,382 --> 00:44:18,395
And likewise for Bob.

1126
00:44:16,393 --> 00:44:32,409
So that means that Alice's parameters,

1127
00:44:32,409 --> 00:44:32,409
phi are grounded in a representation that

1128
00:44:32,409 --> 00:44:32,409
is at least partly shared with Bob's

1129
00:44:32,409 --> 00:44:32,409
tilde phi.

1130
00:44:18,395 --> 00:45:01,432
So if Bob's parameters implement a

1131
00:45:01,432 --> 00:45:01,432
function that operates differently on

1132
00:45:01,432 --> 00:45:01,432
input data compared to Alice, then they

1133
00:45:01,432 --> 00:45:01,432
do not inform on each other to a great

1134
00:45:01,432 --> 00:45:01,432
extent and the ceiling on ineffability is

1135
00:45:01,432 --> 00:45:01,432
increased via this KP phi given p tilde,

1136
00:45:01,432 --> 00:45:01,432
phi tan and secondly, conscious

1137
00:45:01,432 --> 00:45:01,432
experience s is a function of phi.

1138
00:44:33,409 --> 00:45:06,437
It's computed using a function that

1139
00:45:06,437 --> 00:45:06,437
depends on phi.

1140
00:45:01,432 --> 00:45:11,442
And likewise for Bob and phi contains

1141
00:45:11,442 --> 00:45:11,442
Alice's long term knowledge.

1142
00:45:06,437 --> 00:45:35,466
Therefore, S is capable of containing

1143
00:45:35,466 --> 00:45:35,466
information about the assumptions that

1144
00:45:35,466 --> 00:45:35,466
Alice makes in the process of generating

1145
00:45:35,466 --> 00:45:35,466
her conscious experience and that's

1146
00:45:35,466 --> 00:45:35,466
included in the reconstruction target of

1147
00:45:35,466 --> 00:45:35,466
KS, which is to say the description or

1148
00:45:35,466 --> 00:45:35,466
complexity of her conscious experience.

1149
00:45:11,442 --> 00:45:58,489
So, our model offers an interpretation

1150
00:45:58,489 --> 00:45:58,489
for the observations of Sperling, which

1151
00:45:58,489 --> 00:45:58,489
were made in 1960 in this very famous

1152
00:45:58,489 --> 00:45:58,489
experiment where he showed subjects a

1153
00:45:58,489 --> 00:45:58,489
grid of characters briefly and then asked

1154
00:45:58,489 --> 00:45:58,489
them to recall a specific row.

1155
00:45:39,470 --> 00:46:24,509
He observed that subjects were generally

1156
00:46:24,509 --> 00:46:24,509
able to report the prompted row

1157
00:46:24,509 --> 00:46:24,509
accurately, but not all the characters in

1158
00:46:24,509 --> 00:46:24,509
the grid, despite being able to report

1159
00:46:24,509 --> 00:46:24,509
that they had a conscious experience of

1160
00:46:24,509 --> 00:46:24,509
they consciously apprehended all

1161
00:46:24,509 --> 00:46:24,509
characters in the grid.

1162
00:45:59,490 --> 00:46:35,520
And our model offers an account for this

1163
00:46:35,520 --> 00:46:35,520
this phenomenon in in the following way.

1164
00:46:26,511 --> 00:46:57,542
So upon being exposed to the grid of

1165
00:46:57,542 --> 00:46:57,542
characters and being prompted to report

1166
00:46:57,542 --> 00:46:57,542
the characters in a specific row, working

1167
00:46:57,542 --> 00:46:57,542
memory contents represented by the

1168
00:46:57,542 --> 00:46:57,542
attractive state A presumably contains

1169
00:46:57,542 --> 00:46:57,542
the identities of those four characters

1170
00:46:57,542 --> 00:46:57,542
in the prompted row as well as a summary

1171
00:46:57,542 --> 00:46:57,542
over the grid.

1172
00:46:35,520 --> 00:47:07,546
For example, the approximate number of

1173
00:47:07,546 --> 00:47:07,546
characters or their agreement and an

1174
00:47:07,546 --> 00:47:07,546
estimate of the information lost by that

1175
00:47:07,546 --> 00:47:07,546
summary.

1176
00:46:57,542 --> 00:47:29,568
Whilst information sufficient to

1177
00:47:29,568 --> 00:47:29,568
discriminate all characters would exist

1178
00:47:29,568 --> 00:47:29,568
at some point in the computational

1179
00:47:29,568 --> 00:47:29,568
pipeline, but primarily in upstream

1180
00:47:29,568 --> 00:47:29,568
sensory state V from which working memory

1181
00:47:29,568 --> 00:47:29,568
trajectory X and working memory output A

1182
00:47:29,568 --> 00:47:29,568
are computed.

1183
00:47:07,546 --> 00:47:49,588
Subsequently, since the active states A

1184
00:47:49,588 --> 00:47:49,588
is directly accessible to verbal

1185
00:47:49,588 --> 00:47:49,588
reporting processes, the characters of

1186
00:47:49,588 --> 00:47:49,588
the prompted row, the grid details at

1187
00:47:49,588 --> 00:47:49,588
summary level, and the presence of

1188
00:47:49,588 --> 00:47:49,588
information loss would be directly

1189
00:47:49,588 --> 00:47:49,588
reportable, whereas full grid details

1190
00:47:49,588 --> 00:47:49,588
wouldn't.

1191
00:47:30,569 --> 00:48:01,594
And note that this explanation would hold

1192
00:48:01,594 --> 00:48:01,594
irrespective of where the distinction

1193
00:48:01,594 --> 00:48:01,594
between conscious and unconscious is

1194
00:48:01,594 --> 00:48:01,594
drawn.

1195
00:47:50,589 --> 00:48:14,607
So whether X the working memory

1196
00:48:14,607 --> 00:48:14,607
trajectory, which may contain sufficient

1197
00:48:14,607 --> 00:48:14,607
information to discriminate all

1198
00:48:14,607 --> 00:48:14,607
characters or not, whether X is

1199
00:48:14,607 --> 00:48:14,607
considered conscious or not.

1200
00:48:02,595 --> 00:48:35,628
So, as this suggests, one of the points

1201
00:48:35,628 --> 00:48:35,628
that we make is that at least when it

1202
00:48:35,628 --> 00:48:35,628
comes to characterizing richness and

1203
00:48:35,628 --> 00:48:35,628
ineffability, the exact definition of

1204
00:48:35,628 --> 00:48:35,628
what constitutes conscious experience.

1205
00:48:18,611 --> 00:48:44,637
So the definition of FS phi in the

1206
00:48:44,637 --> 00:48:44,637
computational pipeline is not that

1207
00:48:44,637 --> 00:48:44,637
important.

1208
00:48:35,628 --> 00:49:01,648
We utilize this minimal computational

1209
00:49:01,648 --> 00:49:01,648
model without relying on the

1210
00:49:01,648 --> 00:49:01,648
implementation details in order to allow

1211
00:49:01,648 --> 00:49:01,648
us to make general statements about

1212
00:49:01,648 --> 00:49:01,648
richness ineffability.

1213
00:48:46,639 --> 00:49:19,666
And as Eric hinted before, you can

1214
00:49:19,666 --> 00:49:19,666
account for the report of the report of

1215
00:49:19,666 --> 00:49:19,666
ineffability from this computational

1216
00:49:19,666 --> 00:49:19,666
assuming this computational graph,

1217
00:49:19,666 --> 00:49:19,666
irrespective of how you define FS.

1218
00:49:02,649 --> 00:49:29,676
So if X is considered to be conscious,

1219
00:49:29,676 --> 00:49:29,676
then the attracted dynamics bottleneck,

1220
00:49:29,676 --> 00:49:29,676
the amount of information accessible to

1221
00:49:29,676 --> 00:49:29,676
working memory output and verbal report.

1222
00:49:20,667 --> 00:49:35,682
But if X is not conscious, then

1223
00:49:35,682 --> 00:49:35,682
information lost during processing can

1224
00:49:35,682 --> 00:49:35,682
still be reported on.

1225
00:49:30,676 --> 00:49:43,690
It can still be approximately computed

1226
00:49:43,690 --> 00:49:43,690
and reported on, leading us to report on

1227
00:49:43,690 --> 00:49:43,690
ineffability.

1228
00:49:35,682 --> 00:49:52,699
So finally, some future directions for

1229
00:49:52,699 --> 00:49:52,699
this work.

1230
00:49:46,693 --> 00:49:56,703
One of them is to link it to the

1231
00:49:56,703 --> 00:49:56,703
neuroscience.

1232
00:49:52,699 --> 00:50:11,712
So, for example, to actually get some

1233
00:50:11,712 --> 00:50:11,712
empirical estimates of the amount of

1234
00:50:11,712 --> 00:50:11,712
information lost using neural correlates

1235
00:50:11,712 --> 00:50:11,712
of working memory state, for example.

1236
00:49:56,703 --> 00:50:26,727
And also, I think for a deeper

1237
00:50:26,727 --> 00:50:26,727
understanding of consciousness, you have

1238
00:50:26,727 --> 00:50:26,727
to consider why it exists and not just

1239
00:50:26,727 --> 00:50:26,727
how it manifests.

1240
00:50:12,713 --> 00:50:29,730
So this is something that we don't touch

1241
00:50:29,730 --> 00:50:29,730
on on the paper.

1242
00:50:26,727 --> 00:50:41,742
But the use of information bottlenecks in

1243
00:50:41,742 --> 00:50:41,742
machine learning would suggest that

1244
00:50:41,742 --> 00:50:41,742
information loss actually has a purpose.

1245
00:50:30,731 --> 00:50:44,745
And specifically the purpose is

1246
00:50:44,745 --> 00:50:44,745
generalization.

1247
00:50:42,743 --> 00:51:09,764
It improves the robustness of functions

1248
00:51:09,764 --> 00:51:09,764
learned from data to noise, and it

1249
00:51:09,764 --> 00:51:09,764
improves the ambiguity of functions to

1250
00:51:09,764 --> 00:51:09,764
perform optimally on inputs that were not

1251
00:51:09,764 --> 00:51:09,764
seen during training, which is what

1252
00:51:09,764 --> 00:51:09,764
generalization is defined by.

1253
00:50:46,747 --> 00:51:30,785
And this is important because if we want

1254
00:51:30,785 --> 00:51:30,785
to incorporate sort of observations about

1255
00:51:30,785 --> 00:51:30,785
consciousness into our artificial models,

1256
00:51:30,785 --> 00:51:30,785
what we really want to capture is the

1257
00:51:30,785 --> 00:51:30,785
benefit that consciousness affords

1258
00:51:30,785 --> 00:51:30,785
biological models.

1259
00:51:12,766 --> 00:51:44,799
And we might not need to transfer the

1260
00:51:44,799 --> 00:51:44,799
actual form that it takes in human

1261
00:51:44,799 --> 00:51:44,799
cognition and that's it.

1262
00:51:30,785 --> 00:51:52,807
Daniel: Awesome.

1263
00:51:51,806 --> 00:51:57,812
Thank you for the presentation, Kiom.

1264
00:51:52,807 --> 00:52:06,814
It would be awesome if you could give

1265
00:52:06,814 --> 00:52:06,814
some opening remarks and then we can have

1266
00:52:06,814 --> 00:52:06,814
a discussion and hear any questions from

1267
00:52:06,814 --> 00:52:06,814
the live chat.

1268
00:51:57,812 --> 00:52:08,817
Guillaume: Sure.

1269
00:52:07,816 --> 00:52:14,823
Well, thanks again for the invitation to

1270
00:52:14,823 --> 00:52:14,823
mind jazz on these beautiful topics.

1271
00:52:08,817 --> 00:52:37,846
So as opening questions and discourse, I

1272
00:52:37,846 --> 00:52:37,846
would say, like a strong message here is

1273
00:52:37,846 --> 00:52:37,846
that through the formalization that was

1274
00:52:37,846 --> 00:52:37,846
just presented, we have an account that

1275
00:52:37,846 --> 00:52:37,846
allowed to make the bridge between access

1276
00:52:37,846 --> 00:52:37,846
consciousness and phenological

1277
00:52:37,846 --> 00:52:37,846
consciousness.

1278
00:52:14,823 --> 00:53:00,863
Something that was described very well in

1279
00:53:00,863 --> 00:53:00,863
the paper that was cited of the Nakash in

1280
00:53:00,863 --> 00:53:00,863
Philosophical Transaction B, how you

1281
00:53:00,863 --> 00:53:00,863
don't necessarily need something more

1282
00:53:00,863 --> 00:53:00,863
than access consciousness to account for

1283
00:53:00,863 --> 00:53:00,863
these phenomenal aspects, but it's also a

1284
00:53:00,863 --> 00:53:00,863
lot of open questions.

1285
00:52:38,847 --> 00:53:19,882
Like typically we have seen how there is

1286
00:53:19,882 --> 00:53:19,882
an information loss within brain and

1287
00:53:19,882 --> 00:53:19,882
between brains, but we can also

1288
00:53:19,882 --> 00:53:19,882
complexify the within brain message

1289
00:53:19,882 --> 00:53:19,882
passage, for instance adding

1290
00:53:19,882 --> 00:53:19,882
metacognition.

1291
00:53:01,864 --> 00:53:31,894
So at mida we are also working on

1292
00:53:31,894 --> 00:53:31,894
addition of cognitive architecture on top

1293
00:53:31,894 --> 00:53:31,894
of global neural workspace with typically

1294
00:53:31,894 --> 00:53:31,894
attention schema theory for Michael

1295
00:53:31,894 --> 00:53:31,894
Garciano.

1296
00:53:19,882 --> 00:53:38,901
And so there is again in these meta

1297
00:53:38,901 --> 00:53:38,901
representational steps a lot of

1298
00:53:38,901 --> 00:53:38,901
information as well.

1299
00:53:31,894 --> 00:54:10,927
And I think from an empirical point of

1300
00:54:10,927 --> 00:54:10,927
view at both behavior and

1301
00:54:10,927 --> 00:54:10,927
neurophysiological level, there is also a

1302
00:54:10,927 --> 00:54:10,927
lot to unpack there on how our

1303
00:54:10,927 --> 00:54:10,927
metacognitive representation of ourselves

1304
00:54:10,927 --> 00:54:10,927
is also impoverished information from the

1305
00:54:10,927 --> 00:54:10,927
real states that occur underlying and

1306
00:54:10,927 --> 00:54:10,927
that connected well with the social

1307
00:54:10,927 --> 00:54:10,927
dimension of consciousness.

1308
00:53:38,901 --> 00:54:16,933
And here we tapped a bit on that with the

1309
00:54:16,933 --> 00:54:16,933
ineffability at the interpersonal level.

1310
00:54:10,927 --> 00:54:39,956
But in the case of the attention schema,

1311
00:54:39,956 --> 00:54:39,956
there is a very interesting reversal from

1312
00:54:39,956 --> 00:54:39,956
evolutionary standpoint of why the brain

1313
00:54:39,956 --> 00:54:39,956
comes up to represent others at first and

1314
00:54:39,956 --> 00:54:39,956
then we are recycling the neural

1315
00:54:39,956 --> 00:54:39,956
mechanisms to predict others behavior on

1316
00:54:39,956 --> 00:54:39,956
ourself.

1317
00:54:16,933 --> 00:54:59,975
And there is a kind of flipping of the

1318
00:54:59,975 --> 00:54:59,975
traditional narrative in cognitive

1319
00:54:59,975 --> 00:54:59,975
neuroscience with Graziano because the

1320
00:54:59,975 --> 00:54:59,975
others come first in a way and self

1321
00:54:59,975 --> 00:54:59,975
consciousness become a sort of side

1322
00:54:59,975 --> 00:54:59,975
effect of having to have all the

1323
00:54:59,975 --> 00:54:59,975
mechanisms to deal with others.

1324
00:54:40,956 --> 00:55:10,981
And here we don't talk too much about the

1325
00:55:10,981 --> 00:55:10,981
representation of the self, but I think

1326
00:55:10,981 --> 00:55:10,981
it's a very interesting path following

1327
00:55:10,981 --> 00:55:10,981
this work.

1328
00:54:59,976 --> 00:55:26,997
Then there is also something that we

1329
00:55:26,997 --> 00:55:26,997
didn't discuss too much, but we think

1330
00:55:26,997 --> 00:55:26,997
about the trajectory to the attractor and

1331
00:55:26,997 --> 00:55:26,997
how many trajectories can lead to one

1332
00:55:26,997 --> 00:55:26,997
attractor.

1333
00:55:11,982 --> 00:55:32,003
But interestingly, from a sequence of

1334
00:55:32,003 --> 00:55:32,003
attractor you can recover sort of a

1335
00:55:32,003 --> 00:55:32,003
trajectory.

1336
00:55:26,997 --> 00:55:42,013
So like if I have point A and point B and

1337
00:55:42,013 --> 00:55:42,013
point C, by having the sequence IBC, I

1338
00:55:42,013 --> 00:55:42,013
will tend to have a trajectory that looks

1339
00:55:42,013 --> 00:55:42,013
alike each time.

1340
00:55:32,003 --> 00:55:50,021
And so it's kind of heading towards like

1341
00:55:50,021 --> 00:55:50,021
the dynamics also of social interaction

1342
00:55:50,021 --> 00:55:50,021
and culture.

1343
00:55:42,013 --> 00:56:09,034
So typically cultural artifacts like

1344
00:56:09,034 --> 00:56:09,034
music or movies are eliciting stuff from

1345
00:56:09,034 --> 00:56:09,034
a subjective experience that seems like

1346
00:56:09,034 --> 00:56:09,034
stronger than just words, I'm saying

1347
00:56:09,034 --> 00:56:09,034
stronger than words, but even words are

1348
00:56:09,034 --> 00:56:09,034
sequences.

1349
00:55:50,021 --> 00:56:22,047
So in a way there is maybe in the

1350
00:56:22,047 --> 00:56:22,047
dynamics of communication a little bit of

1351
00:56:22,047 --> 00:56:22,047
information that is retrieved by the

1352
00:56:22,047 --> 00:56:22,047
interpolation of different discrete

1353
00:56:22,047 --> 00:56:22,047
states of different attractors.

1354
00:56:09,034 --> 00:56:28,053
It's in the inequality that we saw.

1355
00:56:24,049 --> 00:56:46,071
The inequalities are there, but maybe we

1356
00:56:46,071 --> 00:56:46,071
can play a bit with those phenomena to

1357
00:56:46,071 --> 00:56:46,071
see to what extent we can retrieve more

1358
00:56:46,071 --> 00:56:46,071
information by playing on those dynamical

1359
00:56:46,071 --> 00:56:46,071
phenomena in communication and regarding

1360
00:56:46,071 --> 00:56:46,071
communication.

1361
00:56:28,053 --> 00:56:58,083
So we talked about the grounding problem

1362
00:56:58,083 --> 00:56:58,083
and how the message and the attractors

1363
00:56:58,083 --> 00:56:58,083
are kind of aligned between people

1364
00:56:58,083 --> 00:56:58,083
through a shared statistical

1365
00:56:58,083 --> 00:56:58,083
environment.

1366
00:56:46,071 --> 00:57:15,094
And I think the Kolmogorov framework is

1367
00:57:15,094 --> 00:57:15,094
interesting in the sense of a generative

1368
00:57:15,094 --> 00:57:15,094
model of the world that you have to share

1369
00:57:15,094 --> 00:57:15,094
with others.

1370
00:57:00,079 --> 00:57:21,100
In a sense, I'm working a lot on autism

1371
00:57:21,100 --> 00:57:21,100
and I'm interested in neurodiversity.

1372
00:57:16,095 --> 00:57:46,125
The fact that you have this

1373
00:57:46,125 --> 00:57:46,125
dissimilarity, the cognitive

1374
00:57:46,125 --> 00:57:46,125
dissimilarity in the information loss, is

1375
00:57:46,125 --> 00:57:46,125
also very interesting to interpret how

1376
00:57:46,125 --> 00:57:46,125
diversity at the biological level can

1377
00:57:46,125 --> 00:57:46,125
have an impact on how certain people

1378
00:57:46,125 --> 00:57:46,125
would have more difficulty to communicate

1379
00:57:46,125 --> 00:57:46,125
with others.

1380
00:57:24,103 --> 00:57:50,129
Specifically in a neurotypical world.

1381
00:57:46,125 --> 00:57:55,134
Like, we have a society that is very

1382
00:57:55,134 --> 00:57:55,134
normative in design for neurotypical.

1383
00:57:50,129 --> 00:58:06,139
And so people who are more outside the

1384
00:58:06,139 --> 00:58:06,139
norm and are more neurodiverse would then

1385
00:58:06,139 --> 00:58:06,139
have more difficulty to align their

1386
00:58:06,139 --> 00:58:06,139
genetic model and communicate with

1387
00:58:06,139 --> 00:58:06,139
others.

1388
00:57:56,135 --> 00:58:11,144
That's also something that would be nice

1389
00:58:11,144 --> 00:58:11,144
to discuss or to explore later.

1390
00:58:06,139 --> 00:58:25,158
And finally, so since we are on an active

1391
00:58:25,158 --> 00:58:25,158
active inference Livestream, I would take

1392
00:58:25,158 --> 00:58:25,158
the occasion to mention how it could

1393
00:58:25,158 --> 00:58:25,158
connect with active inference.

1394
00:58:11,144 --> 00:58:50,183
We didn't really talk about the active

1395
00:58:50,183 --> 00:58:50,183
inference formalism in the paper, but

1396
00:58:50,183 --> 00:58:50,183
typically I'm coming back from a workshop

1397
00:58:50,183 --> 00:58:50,183
on computational neurophenology where we

1398
00:58:50,183 --> 00:58:50,183
used the previous work of Varela on

1399
00:58:50,183 --> 00:58:50,183
neuroscience and phenology to try to have

1400
00:58:50,183 --> 00:58:50,183
a generative passage between first person

1401
00:58:50,183 --> 00:58:50,183
and third person experience.

1402
00:58:25,158 --> 00:59:04,191
And we discussed during the whole week

1403
00:59:04,191 --> 00:59:04,191
how computational models can be a third

1404
00:59:04,191 --> 00:59:04,191
constraint to stabilize this relationship

1405
00:59:04,191 --> 00:59:04,191
between first and third person

1406
00:59:04,191 --> 00:59:04,191
perspective on consciousness.

1407
00:58:50,183 --> 00:59:11,198
And I was among the rare people there not

1408
00:59:11,198 --> 00:59:11,198
completely convinced by active

1409
00:59:11,198 --> 00:59:11,198
inference.

1410
00:59:05,192 --> 00:59:35,222
And I was like trying to argue about the

1411
00:59:35,222 --> 00:59:35,222
need for plurality at the formalism

1412
00:59:35,222 --> 00:59:35,222
level, even from a theoretical

1413
00:59:35,222 --> 00:59:35,222
perspective and for plurality in those

1414
00:59:35,222 --> 00:59:35,222
domain, but at least from a formal point

1415
00:59:35,222 --> 00:59:35,222
of view, to try to not bet all our eggs

1416
00:59:35,222 --> 00:59:35,222
in the same basket, so to say.

1417
00:59:12,199 --> 00:59:43,230
And here it's a very nice example how

1418
00:59:43,230 --> 00:59:43,230
even you can combine formalism that were

1419
00:59:43,230 --> 00:59:43,230
mutually exclusive in the literature.

1420
00:59:35,222 --> 00:59:58,245
So for typically coming more from the

1421
00:59:58,245 --> 00:59:58,245
embodied cognition and variables work,

1422
00:59:58,245 --> 00:59:58,245
people with embodied cognition work tends

1423
00:59:58,245 --> 00:59:58,245
to be more in dynamical system theory and

1424
00:59:58,245 --> 00:59:58,245
very opposed to computationalism and

1425
00:59:58,245 --> 00:59:58,245
information theory.

1426
00:59:43,230 --> 01:00:04,132
Here we show in this paper that

1427
01:00:04,132 --> 01:00:04,132
information theory and dynamical system

1428
01:00:04,132 --> 01:00:04,132
theory can totally work hand in hand.

1429
00:59:58,245 --> 01:00:10,130
So it doesn't mean that we need to commit

1430
01:00:10,130 --> 01:00:10,130
to one or to have all formalism.

1431
01:00:04,234 --> 01:00:21,267
But to maintain this plurality, I think

1432
01:00:21,267 --> 01:00:21,267
is very important from an epistemological

1433
01:00:21,267 --> 01:00:21,267
standpoint and still the connection with

1434
01:00:21,267 --> 01:00:21,267
active inference, that could be

1435
01:00:21,267 --> 01:00:21,267
interesting.

1436
01:00:10,136 --> 01:00:32,318
And that's one of the things that I kept

1437
01:00:32,318 --> 01:00:32,318
from last week workshop, is how from a

1438
01:00:32,318 --> 01:00:32,318
social interaction point of view

1439
01:00:32,318 --> 01:00:32,318
synchronization.

1440
01:00:21,277 --> 01:00:42,312
And I worked a lot on intervention

1441
01:00:42,312 --> 01:00:42,312
synchronization and those phenomenal

1442
01:00:42,312 --> 01:00:42,312
synchronization can be optimality for

1443
01:00:42,312 --> 01:00:42,312
information transfer, as we see here.

1444
01:00:32,326 --> 01:00:59,012
But in the context of active inference,

1445
01:00:59,012 --> 01:00:59,012
it's also the optimal minimizer of free

1446
01:00:59,012 --> 01:00:59,012
energy because you have the two

1447
01:00:59,012 --> 01:00:59,012
generative models that are perfectly

1448
01:00:59,012 --> 01:00:59,012
aligned and so you don't have error in

1449
01:00:59,012 --> 01:00:59,012
your prediction because the other person

1450
01:00:59,012 --> 01:00:59,012
become a mirror of your own generative

1451
01:00:59,012 --> 01:00:59,012
model.

1452
01:00:42,324 --> 01:01:10,590
So that may be also some bridges and

1453
01:01:10,590 --> 01:01:10,590
predictions that can show that those

1454
01:01:10,590 --> 01:01:10,590
different formattems are multiple way of

1455
01:01:10,590 --> 01:01:10,590
looking at the same thing.

1456
01:00:59,031 --> 01:01:19,491
Daniel: Thank you.

1457
01:01:18,387 --> 01:01:21,676
Awesome points.

1458
01:01:20,510 --> 01:01:29,415
So feel free to discuss if you have any

1459
01:01:29,415 --> 01:01:29,415
responses and just take it from there.

1460
01:01:21,694 --> 01:01:30,536
Eric and shoe.

1461
01:01:29,428 --> 01:01:33,875
Or I can ask some questions or read some

1462
01:01:33,875 --> 01:01:33,875
comments.

1463
01:01:30,541 --> 01:01:36,155
Do you have any comments on Guillum's

1464
01:01:36,155 --> 01:01:36,155
thoughts?

1465
01:01:33,886 --> 01:01:41,609
Xu: Yeah, I think we have some.

1466
01:01:39,455 --> 01:01:42,742
Do you have things to say?

1467
01:01:41,626 --> 01:01:43,833
Eric: Go first.

1468
01:01:42,752 --> 01:01:47,027
Xu: Yeah, that was a long list of

1469
01:01:47,027 --> 01:01:47,027
comments.

1470
01:01:44,950 --> 01:02:11,206
I find your comments about the autism

1471
01:02:11,206 --> 01:02:11,206
link really interesting because actually

1472
01:02:11,206 --> 01:02:11,206
that's pretty much directly what the

1473
01:02:11,206 --> 01:02:11,206
message of the result is, is that

1474
01:02:11,206 --> 01:02:11,206
cognitive dissimilarity is associated

1475
01:02:11,206 --> 01:02:11,206
with difficulty in communicating.

1476
01:01:51,067 --> 01:02:44,538
So yeah, actually the last thing that you

1477
01:02:44,538 --> 01:02:44,538
said about how if the communicator and

1478
01:02:44,538 --> 01:02:44,538
the listener's brains are synchronized or

1479
01:02:44,538 --> 01:02:44,538
if they're equal, there's no prediction

1480
01:02:44,538 --> 01:02:44,538
error, that's kind of the machine

1481
01:02:44,538 --> 01:02:44,538
learning problem, actually, as a whole.

1482
01:02:13,223 --> 01:02:53,626
I don't know if this is a big thing, but

1483
01:02:53,626 --> 01:02:53,626
the whole point of machine learning is to

1484
01:02:53,626 --> 01:02:53,626
discover the true model that you're

1485
01:02:53,626 --> 01:02:53,626
trying to learn so that you have no

1486
01:02:53,626 --> 01:02:53,626
prediction error.

1487
01:02:45,539 --> 01:02:54,633
Right?

1488
01:02:53,627 --> 01:03:07,704
So, yeah, I dean, so I'm not an expert on

1489
01:03:07,704 --> 01:03:07,704
active inference by any means.

1490
01:02:56,659 --> 01:03:18,819
But one thing that does make me a bit

1491
01:03:18,819 --> 01:03:18,819
like apprehensive about it is that it's

1492
01:03:18,819 --> 01:03:18,819
so concerned with prediction.

1493
01:03:09,724 --> 01:03:40,032
Generative models are about

1494
01:03:40,032 --> 01:03:40,032
reconstruction and prediction, whereas

1495
01:03:40,032 --> 01:03:40,032
cognition is about survival, and

1496
01:03:40,032 --> 01:03:40,032
prediction is part of survival.

1497
01:03:22,850 --> 01:03:40,036
Obviously.

1498
01:03:40,032 --> 01:03:56,191
I mean, you need to be able to predict, I

1499
01:03:56,191 --> 01:03:56,191
don't know, not crashing into a car or

1500
01:03:56,191 --> 01:03:56,191
something so that you don't die, but it's

1501
01:03:56,191 --> 01:03:56,191
just a part.

1502
01:03:40,036 --> 01:04:27,440
And more generally, the inference of

1503
01:04:27,440 --> 01:04:27,440
cognitive states in the brain is not

1504
01:04:27,440 --> 01:04:27,440
about discovery of truth in some sense,

1505
01:04:27,440 --> 01:04:27,440
you know, it's not about coming up with

1506
01:04:27,440 --> 01:04:27,440
with true model or explanation for some

1507
01:04:27,440 --> 01:04:27,440
phenomenon.

1508
01:03:59,219 --> 01:04:33,506
It's about sort of optimizing for your

1509
01:04:33,506 --> 01:04:33,506
fitness.

1510
01:04:27,442 --> 01:04:44,618
So, yeah, that's something that I don't

1511
01:04:44,618 --> 01:04:44,618
quite understand, sort of what the active

1512
01:04:44,618 --> 01:04:44,618
inference perspective on that would be.

1513
01:04:35,526 --> 01:04:52,696
I don't know if Daniel, you had some

1514
01:04:52,696 --> 01:04:52,696
comments or not.

1515
01:04:44,618 --> 01:04:59,761
Daniel: Okay, just jumping with active

1516
01:04:59,761 --> 01:04:59,761
inference and then I'll give more

1517
01:04:59,761 --> 01:04:59,761
comments in the chat.

1518
01:04:54,710 --> 01:05:01,724
But I think that's a great set of

1519
01:05:01,724 --> 01:05:01,724
points.

1520
01:04:59,761 --> 01:05:06,777
So if I can make one point to Guillaumes

1521
01:05:06,777 --> 01:05:06,777
first.

1522
01:05:01,729 --> 01:05:31,029
You spoke about in the presentation the

1523
01:05:31,029 --> 01:05:31,029
generalized ineffability, and it reminded

1524
01:05:31,029 --> 01:05:31,029
me of a few times in active inference

1525
01:05:31,029 --> 01:05:31,029
where we're hearing about generalized

1526
01:05:31,029 --> 01:05:31,029
synchrony, generalized, which means like,

1527
01:05:31,029 --> 01:05:31,029
not necessarily lockstep or mirror, but

1528
01:05:31,029 --> 01:05:31,029
mutually information encoding and not

1529
01:05:31,029 --> 01:05:31,029
necessarily linearly correlate and

1530
01:05:31,029 --> 01:05:31,029
synchronize, like the end state of the

1531
01:05:31,029 --> 01:05:31,029
metronomes.

1532
01:05:07,786 --> 01:05:44,155
But there's like complex information

1533
01:05:44,155 --> 01:05:44,155
transfer, especially in this multi scale

1534
01:05:44,155 --> 01:05:44,155
setting, generalized synchrony, which is

1535
01:05:44,155 --> 01:05:44,155
enabled by the generalized coordinates,

1536
01:05:44,155 --> 01:05:44,155
which are the coordinates of motion of

1537
01:05:44,155 --> 01:05:44,155
the path.

1538
01:05:32,030 --> 01:05:55,263
So these are kind of the summary

1539
01:05:55,263 --> 01:05:55,263
statistics to describe the Taylor series

1540
01:05:55,263 --> 01:05:55,263
expansion around that path or to better

1541
01:05:55,263 --> 01:05:55,263
describe that path taken in some way.

1542
01:05:44,156 --> 01:06:11,365
And generalized homeostasis, which for

1543
01:06:11,365 --> 01:06:11,365
certain environmental regularities it may

1544
01:06:11,365 --> 01:06:11,365
be sufficient to be entirely retrodictive

1545
01:06:11,365 --> 01:06:11,365
or there may be physical or cyberphysical

1546
01:06:11,365 --> 01:06:11,365
constraints so that you'll have a system

1547
01:06:11,365 --> 01:06:11,365
that is purely designed a different way.

1548
01:05:55,264 --> 01:06:19,444
So I wouldn't say any theory is

1549
01:06:19,444 --> 01:06:19,444
necessarily too opinionated with respect

1550
01:06:19,444 --> 01:06:19,444
to what you could describe.

1551
01:06:11,366 --> 01:06:37,626
And I think part of the reason to want

1552
01:06:37,626 --> 01:06:37,626
such a descriptive approach, which is

1553
01:06:37,626 --> 01:06:37,626
what I feel like you all did, by deciding

1554
01:06:37,626 --> 01:06:37,626
to describe an analytics framework for

1555
01:06:37,626 --> 01:06:37,626
ineffability rather than, for example, a

1556
01:06:37,626 --> 01:06:37,626
mechanistic explanation, but describing

1557
01:06:37,626 --> 01:06:37,626
some evidence.

1558
01:06:19,444 --> 01:06:53,783
All of that was just to say pluralism in

1559
01:06:53,783 --> 01:06:53,783
what we're approaching that ineffable

1560
01:06:53,783 --> 01:06:53,783
space from multiple compressions or bowls

1561
01:06:53,783 --> 01:06:53,783
to even describe English words,

1562
01:06:53,783 --> 01:06:53,783
scientific models.

1563
01:06:38,633 --> 01:07:07,866
And it reminds me of the recent

1564
01:07:07,866 --> 01:07:07,866
discussions with Lance Acosta who

1565
01:07:07,866 --> 01:07:07,866
described how other discrepancy measures

1566
01:07:07,866 --> 01:07:07,866
other than free energy could be used and

1567
01:07:07,866 --> 01:07:07,866
that free energy has been used in machine

1568
01:07:07,866 --> 01:07:07,866
learning.

1569
01:06:53,785 --> 01:07:24,030
The variational auto encoders all kinds

1570
01:07:24,030 --> 01:07:24,030
of Bayesian applications because it has a

1571
01:07:24,030 --> 01:07:24,030
KL divergence and so it has some

1572
01:07:24,030 --> 01:07:24,030
convenient variational optimization

1573
01:07:24,030 --> 01:07:24,030
properties as a discrepancy measure, but

1574
01:07:24,030 --> 01:07:24,030
it is not the only discrepancy measure.

1575
01:07:07,866 --> 01:07:36,158
And you mentioned two in your discussion,

1576
01:07:36,158 --> 01:07:36,158
which were the Shannon syntactic sort of

1577
01:07:36,158 --> 01:07:36,158
classical information content and then

1578
01:07:36,158 --> 01:07:36,158
the Colemagorov, the program.

1579
01:07:24,032 --> 01:07:40,193
And so that is like another distance

1580
01:07:40,193 --> 01:07:40,193
measure.

1581
01:07:37,159 --> 01:07:55,342
So in some ways these spaces can't or

1582
01:07:55,342 --> 01:07:55,342
won't or don't even need to collapse

1583
01:07:55,342 --> 01:07:55,342
below pluralism of at least several

1584
01:07:55,342 --> 01:07:55,342
relatively stabilized kinds.

1585
01:07:40,193 --> 01:08:15,487
But I thought that was a very important

1586
01:08:15,487 --> 01:08:15,487
point, Guillaume, about explanatory

1587
01:08:15,487 --> 01:08:15,487
pluralism and how we can be excited about

1588
01:08:15,487 --> 01:08:15,487
one area of science or one way of knowing

1589
01:08:15,487 --> 01:08:15,487
and it's compatible with others ways of

1590
01:08:15,487 --> 01:08:15,487
knowing because we have some of those

1591
01:08:15,487 --> 01:08:15,487
properties of differences that were

1592
01:08:15,487 --> 01:08:15,487
discussed.

1593
01:07:55,346 --> 01:08:20,537
So those are first thoughts before even

1594
01:08:20,537 --> 01:08:20,537
any active technicality.

1595
01:08:16,491 --> 01:08:28,610
Guillaume: Go for it.

1596
01:08:27,602 --> 01:08:28,618
Eric: Sure.

1597
01:08:28,611 --> 01:08:33,667
Xu: No, I just want to remark that KL is

1598
01:08:33,667 --> 01:08:33,667
distance between two distributions.

1599
01:08:29,619 --> 01:08:40,735
Yeah, anyway.

1600
01:08:35,683 --> 01:09:00,873
Guillaume: Yeah, I was just saying in the

1601
01:09:00,873 --> 01:09:00,873
case of the autism, this typically show

1602
01:09:00,873 --> 01:09:00,873
how also you don't necessarily need to go

1603
01:09:00,873 --> 01:09:00,873
to the mechanistic neurobiology to have

1604
01:09:00,873 --> 01:09:00,873
potential explanation.

1605
01:08:42,754 --> 01:09:22,096
And so in the case of Crabber for

1606
01:09:22,096 --> 01:09:22,096
explaining the brain, there's a very nice

1607
01:09:22,096 --> 01:09:22,096
definition, very nice mindscape of

1608
01:09:22,096 --> 01:09:22,096
different kind of explanation and in the

1609
01:09:22,096 --> 01:09:22,096
same way those different formalism can

1610
01:09:22,096 --> 01:09:22,096
give different perspective on how to

1611
01:09:22,096 --> 01:09:22,096
understand what's going on.

1612
01:09:00,878 --> 01:09:38,249
Autism has been very focused on the

1613
01:09:38,249 --> 01:09:38,249
neurobiology at some point and the

1614
01:09:38,249 --> 01:09:38,249
genetics, but maybe it's not at that

1615
01:09:38,249 --> 01:09:38,249
level specifically that the functional

1616
01:09:38,249 --> 01:09:38,249
understanding should occur.

1617
01:09:23,104 --> 01:09:56,431
I don't say it has a no causal

1618
01:09:56,431 --> 01:09:56,431
relationship because it's highly

1619
01:09:56,431 --> 01:09:56,431
genetically irritable and so on, but

1620
01:09:56,431 --> 01:09:56,431
sometimes the functional understanding is

1621
01:09:56,431 --> 01:09:56,431
not necessarily at the very lowest level

1622
01:09:56,431 --> 01:09:56,431
of explanation.

1623
01:09:38,251 --> 01:10:13,545
Daniel: So now, to kind of move to active

1624
01:10:13,545 --> 01:10:13,545
imprints and really physics based

1625
01:10:13,545 --> 01:10:13,545
approaches, the trajectory recovery is

1626
01:10:13,545 --> 01:10:13,545
going to have some maximum information

1627
01:10:13,545 --> 01:10:13,545
representation with the generalized

1628
01:10:13,545 --> 01:10:13,545
coordinates of motion.

1629
01:10:00,411 --> 01:10:18,594
It's how paths are represented in many

1630
01:10:18,594 --> 01:10:18,594
settings.

1631
01:10:13,547 --> 01:10:35,764
And so that path of least action, the

1632
01:10:35,764 --> 01:10:35,764
Bayesian mechanics on that mindscape,

1633
01:10:35,764 --> 01:10:35,764
whatever it is, empirically, it's like

1634
01:10:35,764 --> 01:10:35,764
fitting a spline in that space or doing

1635
01:10:35,764 --> 01:10:35,764
some other kind of modeling.

1636
01:10:18,598 --> 01:10:52,933
Whether it's SPM modeling or hyper

1637
01:10:52,933 --> 01:10:52,933
scanning, there's some kind of

1638
01:10:52,933 --> 01:10:52,933
generalized time series modeling between

1639
01:10:52,933 --> 01:10:52,933
the present and artifacts, the past, the

1640
01:10:52,933 --> 01:10:52,933
future, other entities.

1641
01:10:35,766 --> 01:10:57,981
Guillaume: What do you mean, Daniel?

1642
01:10:56,970 --> 01:10:58,994
I didn't get it.

1643
01:10:57,981 --> 01:11:09,047
Daniel: Just that that kind of trajectory

1644
01:11:09,047 --> 01:11:09,047
recovery is what is being parameterized

1645
01:11:09,047 --> 01:11:09,047
in physics of consciousness type models

1646
01:11:09,047 --> 01:11:09,047
or physics of cognition.

1647
01:10:59,002 --> 01:11:31,265
Bayesian physics, anything where a

1648
01:11:31,265 --> 01:11:31,265
probability distribution has a position,

1649
01:11:31,265 --> 01:11:31,265
velocity, acceleration, and so on, it's

1650
01:11:31,265 --> 01:11:31,265
being path inferred continuous time

1651
01:11:31,265 --> 01:11:31,265
generative models, and there's discrete

1652
01:11:31,265 --> 01:11:31,265
time generative models in activ and

1653
01:11:31,265 --> 01:11:31,265
hybrid models, just like other Bayesian

1654
01:11:31,265 --> 01:11:31,265
graphs.

1655
01:11:09,048 --> 01:11:40,359
So in the continuous time setting where

1656
01:11:40,359 --> 01:11:40,359
there's a Taylor series expansion, that's

1657
01:11:40,359 --> 01:11:40,359
trajectory recovery.

1658
01:11:31,266 --> 01:11:57,527
Xu: Yeah, well, I think more generally,

1659
01:11:57,527 --> 01:11:57,527
maybe the point is that you could use

1660
01:11:57,527 --> 01:11:57,527
Bayesian learning variational inference

1661
01:11:57,527 --> 01:11:57,527
to learn a generative model of these

1662
01:11:57,527 --> 01:11:57,527
states that we're referring to.

1663
01:11:44,394 --> 01:11:58,530
Right.

1664
01:11:57,528 --> 01:12:17,662
If you had some kind of data set that

1665
01:12:17,662 --> 01:12:17,662
actually represents a sample from, let's

1666
01:12:17,662 --> 01:12:17,662
say, the True model, then you could use

1667
01:12:17,662 --> 01:12:17,662
variational inference to approximate that

1668
01:12:17,662 --> 01:12:17,662
model.

1669
01:11:58,530 --> 01:12:23,720
You don't have to, though.

1670
01:12:21,708 --> 01:12:30,798
I mean, there are many generative model

1671
01:12:30,798 --> 01:12:30,798
techniques in machine learning that don't

1672
01:12:30,798 --> 01:12:30,798
fall under variational inference.

1673
01:12:23,720 --> 01:12:35,840
Daniel: I'll read a comment and a

1674
01:12:35,840 --> 01:12:35,840
question.

1675
01:12:33,820 --> 01:12:50,990
So Yashua Bengio writes Guillaume Dumas

1676
01:12:50,990 --> 01:12:50,990
idea about trajectories of consecutive

1677
01:12:50,990 --> 01:12:50,990
attractors to recover information about

1678
01:12:50,990 --> 01:12:50,990
likely trajectories that lead into each

1679
01:12:50,990 --> 01:12:50,990
of these attractors that are normally

1680
01:12:50,990 --> 01:12:50,990
lost in working memory is very cool.

1681
01:12:35,841 --> 01:12:52,012
And then shu.

1682
01:12:50,997 --> 01:12:58,077
Eric, any relation between what you

1683
01:12:58,077 --> 01:12:58,077
talked about and the compositional

1684
01:12:58,077 --> 01:12:58,077
properties of conscious thoughts?

1685
01:12:52,012 --> 01:13:01,049
Eric: Yeah, I think so.

1686
01:13:00,030 --> 01:13:13,162
In terms of compositionality of conscious

1687
01:13:13,162 --> 01:13:13,162
thoughts, I think what Yasha is referring

1688
01:13:13,162 --> 01:13:13,162
to now is that our thoughts kind of

1689
01:13:13,162 --> 01:13:13,162
compose concepts that we already have.

1690
01:13:02,053 --> 01:13:15,182
So it's something like a sentence.

1691
01:13:13,162 --> 01:13:23,266
If I think the fat cat, I'm composing

1692
01:13:23,266 --> 01:13:23,266
these mental concepts of fat and cat, and

1693
01:13:23,266 --> 01:13:23,266
that generates sort of a new experience.

1694
01:13:15,182 --> 01:13:27,304
So experiences are always generated from

1695
01:13:27,304 --> 01:13:27,304
these building blocks.

1696
01:13:23,267 --> 01:13:39,424
And then, similarly, one thing that we

1697
01:13:39,424 --> 01:13:39,424
didn't talk so much about is that

1698
01:13:39,424 --> 01:13:39,424
conscious experiences, language and

1699
01:13:39,424 --> 01:13:39,424
attractors, can also have this shared

1700
01:13:39,424 --> 01:13:39,424
compositional structure.

1701
01:13:27,308 --> 01:13:48,517
So, like language, it's clear base based

1702
01:13:48,517 --> 01:13:48,517
words combined to form new little

1703
01:13:48,517 --> 01:13:48,517
phrases, new sentences that have novel

1704
01:13:48,517 --> 01:13:48,517
meaning in a systematic way.

1705
01:13:39,424 --> 01:14:01,588
How this could happen with attractors is,

1706
01:14:01,588 --> 01:14:01,588
well, kind of in the most basic case,

1707
01:14:01,588 --> 01:14:01,588
different dimensions in this high

1708
01:14:01,588 --> 01:14:01,588
dimensional state space might converge to

1709
01:14:01,588 --> 01:14:01,588
different attractors.

1710
01:13:48,519 --> 01:14:07,647
And so now one attractor that's converged

1711
01:14:07,647 --> 01:14:07,647
to is really a composition of attractors

1712
01:14:07,647 --> 01:14:07,647
along different dimensions.

1713
01:14:01,588 --> 01:14:12,697
So this is a sense in which our

1714
01:14:12,697 --> 01:14:12,697
experiences are compositional.

1715
01:14:08,651 --> 01:14:18,757
Our attractors that generate those

1716
01:14:18,757 --> 01:14:18,757
experiences can have compositional

1717
01:14:18,757 --> 01:14:18,757
structure.

1718
01:14:13,700 --> 01:14:22,796
And this could be a reason why language

1719
01:14:22,796 --> 01:14:22,796
itself is compositional.

1720
01:14:18,758 --> 01:14:29,862
We're basically trying to come up with

1721
01:14:29,862 --> 01:14:29,862
some way of describing or identifying

1722
01:14:29,862 --> 01:14:29,862
compositions of attractors.

1723
01:14:22,797 --> 01:14:38,950
Xu: I mean, I would add that

1724
01:14:38,950 --> 01:14:38,950
compositionality is a mechanism for

1725
01:14:38,950 --> 01:14:38,950
reducing descriptional complexity.

1726
01:14:29,864 --> 01:14:52,091
In fact, that's arguably the objective

1727
01:14:52,091 --> 01:14:52,091
for the compositional nature of our

1728
01:14:52,091 --> 01:14:52,091
thoughts and language features.

1729
01:14:42,991 --> 01:14:57,141
Like less time to describe, more

1730
01:14:57,141 --> 01:14:57,141
robustness to noise.

1731
01:14:52,092 --> 01:15:11,227
Yeah, I mean, if you're trying to

1732
01:15:11,227 --> 01:15:11,227
describe an instance of a state,

1733
01:15:11,227 --> 01:15:11,227
obviously the descriptional complexity is

1734
01:15:11,227 --> 01:15:11,227
much less if it's built up of concepts

1735
01:15:11,227 --> 01:15:11,227
that you already know about.

1736
01:15:00,112 --> 01:15:22,338
Eric: Yeah, just to bring this back to

1737
01:15:22,338 --> 01:15:22,338
something I mentioned in the talk, I

1738
01:15:22,338 --> 01:15:22,338
pointed out that attractors have this

1739
01:15:22,338 --> 01:15:22,338
discrete structure.

1740
01:15:15,260 --> 01:15:26,369
There's a finite number of them, and we

1741
01:15:26,369 --> 01:15:26,369
could assign labels to them.

1742
01:15:22,338 --> 01:15:33,439
But if these attractors are

1743
01:15:33,439 --> 01:15:33,439
compositional, which would allow for a

1744
01:15:33,439 --> 01:15:33,439
richer space, richer number of

1745
01:15:33,439 --> 01:15:33,439
attractors, basically it's finite.

1746
01:15:26,371 --> 01:15:36,476
But the space of total attractors is

1747
01:15:36,476 --> 01:15:36,476
exponentially large.

1748
01:15:33,441 --> 01:15:42,538
So we don't want a Lagrange that's

1749
01:15:42,538 --> 01:15:42,538
assigning one unique word to every

1750
01:15:42,538 --> 01:15:42,538
composition of attractors.

1751
01:15:36,477 --> 01:15:45,560
It would be an exponentially large

1752
01:15:45,560 --> 01:15:45,560
language.

1753
01:15:42,538 --> 01:15:53,648
We want some kind of language that will

1754
01:15:53,648 --> 01:15:53,648
minimize the description, like what Shu

1755
01:15:53,648 --> 01:15:53,648
said, you could have a language that's

1756
01:15:53,648 --> 01:15:53,648
compositional.

1757
01:15:45,563 --> 01:16:00,658
Daniel: Yeah, I think that provides a

1758
01:16:00,658 --> 01:16:00,658
really.

1759
01:15:57,679 --> 01:16:02,672
Eric: I think you're muted Daniel.

1760
01:16:00,658 --> 01:16:04,693
Daniel: Sorry.

1761
01:16:03,685 --> 01:16:21,866
It provides a very interesting and

1762
01:16:21,866 --> 01:16:21,866
justifying rationale for using the

1763
01:16:21,866 --> 01:16:21,866
description length as opposed to the Kale

1764
01:16:21,866 --> 01:16:21,866
divergence, which is maybe in some

1765
01:16:21,866 --> 01:16:21,866
telepathy enabled world or space.

1766
01:16:04,697 --> 01:16:30,950
The KL divergence does help you move

1767
01:16:30,950 --> 01:16:30,950
quickly or on some defined manifold.

1768
01:16:22,871 --> 01:17:03,220
But in encoding decoding space and on the

1769
01:17:03,220 --> 01:17:03,220
computers that we have, then writing

1770
01:17:03,220 --> 01:17:03,220
shorter programs and or making smaller

1771
01:17:03,220 --> 01:17:03,220
information, theoretic compressions

1772
01:17:03,220 --> 01:17:03,220
becomes one of the imperatives to take

1773
01:17:03,220 --> 01:17:03,220
the kind of empirical approach that you

1774
01:17:03,220 --> 01:17:03,220
are describing.

1775
01:16:30,951 --> 01:17:13,325
Because though you've described mainly

1776
01:17:13,325 --> 01:17:13,325
equations, these are all also computer

1777
01:17:13,325 --> 01:17:13,325
packages that can be used to model

1778
01:17:13,325 --> 01:17:13,325
different data sets.

1779
01:17:03,221 --> 01:17:19,382
So what kinds of data sets do you think

1780
01:17:19,382 --> 01:17:19,382
this is most proximally applicable to?

1781
01:17:13,326 --> 01:17:25,446
Eric: Yeah.

1782
01:17:24,438 --> 01:17:33,528
Are you saying like, what kind of data

1783
01:17:33,528 --> 01:17:33,528
sets would kind of minimum description

1784
01:17:33,528 --> 01:17:33,528
length computational models be most

1785
01:17:33,528 --> 01:17:33,528
useful for.

1786
01:17:25,448 --> 01:17:38,578
Daniel: Or just with the approaches and

1787
01:17:38,578 --> 01:17:38,578
measures that you described today?

1788
01:17:34,530 --> 01:17:49,684
What kinds of data sets or behavioral and

1789
01:17:49,684 --> 01:17:49,684
cognitive settings do you think that

1790
01:17:49,684 --> 01:17:49,684
could be used as an empirical tool or

1791
01:17:49,684 --> 01:17:49,684
measure for?

1792
01:17:39,580 --> 01:17:53,724
I think it'd be really interesting to

1793
01:17:53,724 --> 01:17:53,724
hear about does the data already exist?

1794
01:17:49,684 --> 01:17:55,748
Is it some hypothetical measurement?

1795
01:17:53,725 --> 01:17:58,773
Are there ways to even reanalyze?

1796
01:17:55,748 --> 01:17:58,777
Yes.

1797
01:17:58,774 --> 01:18:00,733
Guillaume or anyone else?

1798
01:17:58,778 --> 01:18:25,987
Guillaume: Yeah, I think on language

1799
01:18:25,987 --> 01:18:25,987
already there is a lot of things that

1800
01:18:25,987 --> 01:18:25,987
have been done on the number of bytes per

1801
01:18:25,987 --> 01:18:25,987
second transferred, for instance, and I

1802
01:18:25,987 --> 01:18:25,987
guess on large corpus of discussions or

1803
01:18:25,987 --> 01:18:25,987
even in clinical settings.

1804
01:18:03,768 --> 01:18:32,005
For instance, I'm working on the clinical

1805
01:18:32,005 --> 01:18:32,005
alliance between a patient and a

1806
01:18:32,005 --> 01:18:32,005
clinician, for instance.

1807
01:18:25,987 --> 01:18:43,016
This formalism of ineffability and

1808
01:18:43,016 --> 01:18:43,016
information loss would be interesting to

1809
01:18:43,016 --> 01:18:43,016
apply to as even a form of biomarker.

1810
01:18:33,006 --> 01:18:44,017
I mean.

1811
01:18:43,016 --> 01:18:47,020
Even if at the language level, it's not

1812
01:18:47,020 --> 01:18:47,020
bio.

1813
01:18:44,017 --> 01:18:59,032
And then you can also apply those

1814
01:18:59,032 --> 01:18:59,032
information theoretic measurements to

1815
01:18:59,032 --> 01:18:59,032
physiological data, movement, neural

1816
01:18:59,032 --> 01:18:59,032
data.

1817
01:18:48,021 --> 01:19:03,030
So in my lab, we are recording multiple

1818
01:19:03,030 --> 01:19:03,030
brains simultaneously.

1819
01:18:59,032 --> 01:19:17,044
We can totally try to empirically

1820
01:19:17,044 --> 01:19:17,044
approach what we are describing this

1821
01:19:17,044 --> 01:19:17,044
paper and show that, for instance, in

1822
01:19:17,044 --> 01:19:17,044
certain population that are more

1823
01:19:17,044 --> 01:19:17,044
challenged to communicate through

1824
01:19:17,044 --> 01:19:17,044
neurodiversity.

1825
01:19:03,030 --> 01:19:29,056
So what we discussed earlier, we can

1826
01:19:29,056 --> 01:19:29,056
apply the same type of measurements with

1827
01:19:29,056 --> 01:19:29,056
information theory instead of just

1828
01:19:29,056 --> 01:19:29,056
classical neuroimaging measurements.

1829
01:19:17,044 --> 01:19:34,061
So that would be, for instance, empirical

1830
01:19:34,061 --> 01:19:34,061
way of dealing with that.

1831
01:19:29,056 --> 01:19:50,077
What I'm very interested in would be to

1832
01:19:50,077 --> 01:19:50,077
make the relationship between the access

1833
01:19:50,077 --> 01:19:50,077
consciousness and the V basically process

1834
01:19:50,077 --> 01:19:50,077
and the information loss that you have in

1835
01:19:50,077 --> 01:19:50,077
your working memory.

1836
01:19:35,062 --> 01:19:58,085
Right now, I feel that no imaging

1837
01:19:58,085 --> 01:19:58,085
technology are not at that level of

1838
01:19:58,085 --> 01:19:58,085
possibility.

1839
01:19:51,078 --> 01:19:59,086
But who knows?

1840
01:19:58,085 --> 01:20:04,085
Maybe we're going to have soon the

1841
01:20:04,085 --> 01:20:04,085
ability to disentangle that kind of

1842
01:20:04,085 --> 01:20:04,085
stuff.

1843
01:19:59,086 --> 01:20:14,095
Xu: Oh, yes, the delimitation of what

1844
01:20:14,095 --> 01:20:14,095
constitutes working memory in the brain.

1845
01:20:05,086 --> 01:20:21,102
I think that's not a settled question,

1846
01:20:21,102 --> 01:20:21,102
right?

1847
01:20:16,097 --> 01:20:28,109
I mean, there are lots of different

1848
01:20:28,109 --> 01:20:28,109
possible approaches.

1849
01:20:22,103 --> 01:20:33,114
Eric: Yeah, I mean, it's totally up in

1850
01:20:33,114 --> 01:20:33,114
the air.

1851
01:20:31,112 --> 01:20:42,122
Classically, in global workspace theory,

1852
01:20:42,122 --> 01:20:42,122
they traditionally thought, okay, working

1853
01:20:42,122 --> 01:20:42,122
memory is localized to prefrontal

1854
01:20:42,122 --> 01:20:42,122
cortex.

1855
01:20:34,115 --> 01:20:53,134
Now, the new perspective that's emerging

1856
01:20:53,134 --> 01:20:53,134
that maybe working memory is sort of

1857
01:20:53,134 --> 01:20:53,134
distributed across the brain, we see kind

1858
01:20:53,134 --> 01:20:53,134
of sustained attractor representations

1859
01:20:53,134 --> 01:20:53,134
all over the place from this distributed

1860
01:20:53,134 --> 01:20:53,134
working memory.

1861
01:20:42,123 --> 01:20:59,140
So all these different pieces, what

1862
01:20:59,140 --> 01:20:59,140
constitutes x?

1863
01:20:53,134 --> 01:21:01,136
What constitutes that working memory

1864
01:21:01,136 --> 01:21:01,136
trajectory?

1865
01:20:59,140 --> 01:21:06,141
And also what constitutes the

1866
01:21:06,141 --> 01:21:06,141
experience?

1867
01:21:02,137 --> 01:21:10,145
What's the function that goes from x from

1868
01:21:10,145 --> 01:21:10,145
working memory to an experience?

1869
01:21:06,141 --> 01:21:11,146
All that is up in the air.

1870
01:21:10,145 --> 01:21:15,150
When writing this paper, we had plenty of

1871
01:21:15,150 --> 01:21:15,150
discussions about what is the

1872
01:21:15,150 --> 01:21:15,150
trajectory?

1873
01:21:11,146 --> 01:21:22,157
The whole trajectory conscious is just

1874
01:21:22,157 --> 01:21:22,157
the attractor conscious is there kind of

1875
01:21:22,157 --> 01:21:22,157
a sense in which both these things are

1876
01:21:22,157 --> 01:21:22,157
true.

1877
01:21:15,150 --> 01:21:26,161
So, like, Guillaume was talking about

1878
01:21:26,161 --> 01:21:26,161
access versus phenomenal consciousness.

1879
01:21:22,157 --> 01:21:38,173
Access consciousness refers to what I'm

1880
01:21:38,173 --> 01:21:38,173
able to report, whereas phenomenal

1881
01:21:38,173 --> 01:21:38,173
consciousness kind of refers more to the

1882
01:21:38,173 --> 01:21:38,173
standard definition of what is my

1883
01:21:38,173 --> 01:21:38,173
experience like.

1884
01:21:26,161 --> 01:21:54,189
So our framework kind of illustrates that

1885
01:21:54,189 --> 01:21:54,189
maybe we could unify these things where x

1886
01:21:54,189 --> 01:21:54,189
the trajectory is some phenomenal,

1887
01:21:54,189 --> 01:21:54,189
experience it's in the moment, whereas

1888
01:21:54,189 --> 01:21:54,189
your tractor is really the only thing

1889
01:21:54,189 --> 01:21:54,189
you're able to report, remember?

1890
01:21:38,173 --> 01:22:02,191
And you must still know that something is

1891
01:22:02,191 --> 01:22:02,191
missing between what you're reporting and

1892
01:22:02,191 --> 01:22:02,191
what you were actually experiencing

1893
01:22:02,191 --> 01:22:02,191
throughout.

1894
01:21:54,189 --> 01:22:26,215
Xu: Yeah, in terms of our model, it's

1895
01:22:26,215 --> 01:22:26,215
pretty clear, but I think actually

1896
01:22:26,215 --> 01:22:26,215
grounding it in empirical data sets is a

1897
01:22:26,215 --> 01:22:26,215
challenging question.

1898
01:22:05,194 --> 01:22:31,220
The other thing is that colgomer of

1899
01:22:31,220 --> 01:22:31,220
complexity is more of a theoretical

1900
01:22:31,220 --> 01:22:31,220
measure.

1901
01:22:26,215 --> 01:22:53,242
So that that's actually, I think, the

1902
01:22:53,242 --> 01:22:53,242
reason why Shannon information is much

1903
01:22:53,242 --> 01:22:53,242
more ubiquitous, for example, in machine

1904
01:22:53,242 --> 01:22:53,242
learning, because basically, given a

1905
01:22:53,242 --> 01:22:53,242
generative model, you can approximate it,

1906
01:22:53,242 --> 01:22:53,242
for example, just using Monte Carlo

1907
01:22:53,242 --> 01:22:53,242
estimation.

1908
01:22:33,222 --> 01:23:06,249
But Kogamov complexity yeah, it would be

1909
01:23:06,249 --> 01:23:06,249
much more of an approximation with a much

1910
01:23:06,249 --> 01:23:06,249
greater error.

1911
01:22:53,242 --> 01:23:10,253
I think if you attempted to approximate

1912
01:23:10,253 --> 01:23:10,253
that.

1913
01:23:06,249 --> 01:23:15,258
So I guess that would be a potential

1914
01:23:15,258 --> 01:23:15,258
concern.

1915
01:23:13,256 --> 01:23:16,259
Eric: Yeah.

1916
01:23:15,258 --> 01:23:28,271
One advantage of it, if you could measure

1917
01:23:28,271 --> 01:23:28,271
the Call Margaret complexity is it would

1918
01:23:28,271 --> 01:23:28,271
allow you to kind of measure the

1919
01:23:28,271 --> 01:23:28,271
ineffability of an experience on an

1920
01:23:28,271 --> 01:23:28,271
individual case.

1921
01:23:16,259 --> 01:23:42,285
So, for instance, one thing we spoke

1922
01:23:42,285 --> 01:23:42,285
about with theory of mind was that this

1923
01:23:42,285 --> 01:23:42,285
complexity of the experience, given the

1924
01:23:42,285 --> 01:23:42,285
message, we would think it would be much

1925
01:23:42,285 --> 01:23:42,285
higher than an experience given Bob's

1926
01:23:42,285 --> 01:23:42,285
experience given the listener's

1927
01:23:42,285 --> 01:23:42,285
experience.

1928
01:23:28,271 --> 01:23:47,290
Because the listener's brain is doing a

1929
01:23:47,290 --> 01:23:47,290
lot of the work of decoding the message

1930
01:23:47,290 --> 01:23:47,290
into a similar sort of experience.

1931
01:23:42,285 --> 01:23:55,298
So it'd be useful if you could see

1932
01:23:55,298 --> 01:23:55,298
something like are there certain types of

1933
01:23:55,298 --> 01:23:55,298
experiences where the message is wildly

1934
01:23:55,298 --> 01:23:55,298
insufficient?

1935
01:23:47,290 --> 01:23:59,302
The comagraph complexity of the

1936
01:23:59,302 --> 01:23:59,302
experience given the message is massive.

1937
01:23:55,298 --> 01:24:05,302
But actually people do a really good job

1938
01:24:05,302 --> 01:24:05,302
inferring the experience and maybe it

1939
01:24:05,302 --> 01:24:05,302
would be different in a case of, like,

1940
01:24:05,302 --> 01:24:05,302
autism.

1941
01:23:59,302 --> 01:24:10,307
Maybe there's some sorts of experiences

1942
01:24:10,307 --> 01:24:10,307
that they simply can't reconstruct.

1943
01:24:05,302 --> 01:24:17,314
So I think there's some value in trying

1944
01:24:17,314 --> 01:24:17,314
to create measures of Kalmakov complexity

1945
01:24:17,314 --> 01:24:17,314
to kind of handle these individual

1946
01:24:17,314 --> 01:24:17,314
cases.

1947
01:24:10,307 --> 01:24:20,317
The issue is it's not really computable.

1948
01:24:17,314 --> 01:24:23,320
You can't search through the space of all

1949
01:24:23,320 --> 01:24:23,320
possible programs.

1950
01:24:20,317 --> 01:24:25,322
But maybe there are kind of ways to get

1951
01:24:25,322 --> 01:24:25,322
around this.

1952
01:24:23,320 --> 01:24:30,327
For instance, you could sort of

1953
01:24:30,327 --> 01:24:30,327
parameterize a program with, I don't

1954
01:24:30,327 --> 01:24:30,327
know, a neural network.

1955
01:24:25,322 --> 01:24:45,342
Let's say you have a neural network going

1956
01:24:45,342 --> 01:24:45,342
from message to some brain scan for an

1957
01:24:45,342 --> 01:24:45,342
experience and then maybe the size of

1958
01:24:45,342 --> 01:24:45,342
that neural network or the complexity of

1959
01:24:45,342 --> 01:24:45,342
the network could be sort of a surrogate

1960
01:24:45,342 --> 01:24:45,342
for the complexity of the program.

1961
01:24:30,327 --> 01:24:47,343
The shortest program.

1962
01:24:45,342 --> 01:24:47,344
Xu: Yeah.

1963
01:24:47,344 --> 01:24:51,348
Guillaume: That'S a cool idea.

1964
01:24:49,346 --> 01:24:53,350
Daniel: That is really cool.

1965
01:24:52,349 --> 01:25:07,358
It reminds me of using adversarial neural

1966
01:25:07,358 --> 01:25:07,358
networks which don't have as strong

1967
01:25:07,358 --> 01:25:07,358
analytical guarantees as, for example,

1968
01:25:07,358 --> 01:25:07,358
cryptography.

1969
01:24:53,350 --> 01:25:14,365
But then they kind of converge in being

1970
01:25:14,365 --> 01:25:14,365
able to protect or change or modify

1971
01:25:14,365 --> 01:25:14,365
information in certain ways.

1972
01:25:07,358 --> 01:25:22,373
But you aren't getting the same bounds or

1973
01:25:22,373 --> 01:25:22,373
guarantees on the formality.

1974
01:25:15,366 --> 01:25:27,378
And that's kind of like the discrete

1975
01:25:27,378 --> 01:25:27,378
continuous dialectic.

1976
01:25:22,373 --> 01:25:40,391
And so it's important to embody even that

1977
01:25:40,391 --> 01:25:40,391
pluralism with respect to state spaces

1978
01:25:40,391 --> 01:25:40,391
because if the formalisms in any of these

1979
01:25:40,391 --> 01:25:40,391
domains, the formalism for discrete

1980
01:25:40,391 --> 01:25:40,391
continuous, they're not always aligned.

1981
01:25:27,378 --> 01:25:44,395
And those are definitely the areas that

1982
01:25:44,395 --> 01:25:44,395
can be studied.

1983
01:25:41,392 --> 01:25:55,406
But for the space of empirical models

1984
01:25:55,406 --> 01:25:55,406
that we're talking about as part of even

1985
01:25:55,406 --> 01:25:55,406
then methodological pluralism and

1986
01:25:55,406 --> 01:25:55,406
science.

1987
01:25:45,396 --> 01:26:00,405
But if we're talking about statistical

1988
01:26:00,405 --> 01:26:00,405
models, we want to be able to intake the

1989
01:26:00,405 --> 01:26:00,405
data at some point.

1990
01:25:55,406 --> 01:26:07,412
So it has to have certain properties

1991
01:26:07,412 --> 01:26:07,412
which are even looser than the math.

1992
01:26:00,405 --> 01:26:09,414
And there's probably a lot that could fit

1993
01:26:09,414 --> 01:26:09,414
in this.

1994
01:26:07,412 --> 01:26:11,416
And I think it'll be interesting.

1995
01:26:10,415 --> 01:26:41,446
Like when you have a hyper scanning

1996
01:26:41,446 --> 01:26:41,446
experiment, how do you include the

1997
01:26:41,446 --> 01:26:41,446
environment or how do you deal with

1998
01:26:41,446 --> 01:26:41,446
different number of sensors or different

1999
01:26:41,446 --> 01:26:41,446
types of sensors, different kinds of

2000
01:26:41,446 --> 01:26:41,446
action, and report that people might

2001
01:26:41,446 --> 01:26:41,446
encode their symbols through all kinds of

2002
01:26:41,446 --> 01:26:41,446
accessibility and interface types which I

2003
01:26:41,446 --> 01:26:41,446
think returns to Guillaume's point.

2004
01:26:11,416 --> 01:26:43,448
So yes, please.

2005
01:26:41,446 --> 01:27:03,462
Guillaume: Actually that also reminds me

2006
01:27:03,462 --> 01:27:03,462
that there is also a nice empirical

2007
01:27:03,462 --> 01:27:03,462
playground associated with what we

2008
01:27:03,462 --> 01:27:03,462
discussed is how we can maximize from an

2009
01:27:03,462 --> 01:27:03,462
environmental perspective instead of the

2010
01:27:03,462 --> 01:27:03,462
biological perspective this information

2011
01:27:03,462 --> 01:27:03,462
transfer.

2012
01:26:44,449 --> 01:27:30,489
So I'm working for instance with Michael

2013
01:27:30,489 --> 01:27:30,489
Lipsheet which is part of Earliest as

2014
01:27:30,489 --> 01:27:30,489
well from anthropological standpoint,

2015
01:27:30,489 --> 01:27:30,489
humans came out with rituals or cultural

2016
01:27:30,489 --> 01:27:30,489
practice to maximize the alignments of

2017
01:27:30,489 --> 01:27:30,489
people and those things also are very

2018
01:27:30,489 --> 01:27:30,489
important in our society or to reach

2019
01:27:30,489 --> 01:27:30,489
consensus and collaborate and so on.

2020
01:27:03,462 --> 01:27:45,504
And I guess this can also of issue would

2021
01:27:45,504 --> 01:27:45,504
be very important, I mean when we have to

2022
01:27:45,504 --> 01:27:45,504
converge on optimal collective dynamics.

2023
01:27:30,489 --> 01:28:08,521
Here we are talking with Alice and Bob in

2024
01:28:08,521 --> 01:28:08,521
a diadic scale but a nice follow up also

2025
01:28:08,521 --> 01:28:08,521
on this work will be at the group level,

2026
01:28:08,521 --> 01:28:08,521
how you optimize consensus and

2027
01:28:08,521 --> 01:28:08,521
collaboration on group scales strictly

2028
01:28:08,521 --> 01:28:08,521
for taxing climate change or social

2029
01:28:08,521 --> 01:28:08,521
inequality and very challenging topics of

2030
01:28:08,521 --> 01:28:08,521
society.

2031
01:27:45,504 --> 01:28:26,539
Xu: Yeah, so actually that touches on a

2032
01:28:26,539 --> 01:28:26,539
well, possibly weakness of the simple

2033
01:28:26,539 --> 01:28:26,539
model that we use which is that we don't

2034
01:28:26,539 --> 01:28:26,539
incorporate any feedback loops.

2035
01:28:09,522 --> 01:28:43,556
So we have this very simple

2036
01:28:43,556 --> 01:28:43,556
unidirectional model which I think has

2037
01:28:43,556 --> 01:28:43,556
advantages as well because it sort of

2038
01:28:43,556 --> 01:28:43,556
shows basic principles in a relatively

2039
01:28:43,556 --> 01:28:43,556
easy to understand way.

2040
01:28:26,539 --> 01:28:56,569
But you're right in that realistically

2041
01:28:56,569 --> 01:28:56,569
there's always feedback not just at the

2042
01:28:56,569 --> 01:28:56,569
interpersonal level but obviously within

2043
01:28:56,569 --> 01:28:56,569
the brain working memory is top down

2044
01:28:56,569 --> 01:28:56,569
attention actually.

2045
01:28:43,556 --> 01:29:01,568
So that's something that we didn't

2046
01:29:01,568 --> 01:29:01,568
address.

2047
01:28:56,569 --> 01:29:10,577
Eric: Yeah, it would be really

2048
01:29:10,577 --> 01:29:10,577
interesting to sort of unify our work

2049
01:29:10,577 --> 01:29:10,577
with the field of pragmatics which is

2050
01:29:10,577 --> 01:29:10,577
exactly about this.

2051
01:29:04,571 --> 01:29:18,585
It's like given many back and forth steps

2052
01:29:18,585 --> 01:29:18,585
in dialogue, how do people come to a

2053
01:29:18,585 --> 01:29:18,585
consensus?

2054
01:29:11,578 --> 01:29:29,596
And this could also kind of involve the

2055
01:29:29,596 --> 01:29:29,596
active inference framework where as a

2056
01:29:29,596 --> 01:29:29,596
listener I'm going to ask questions that

2057
01:29:29,596 --> 01:29:29,596
are going to try and reduce my

2058
01:29:29,596 --> 01:29:29,596
uncertainty about the speaker's state as

2059
01:29:29,596 --> 01:29:29,596
much as possible.

2060
01:29:19,586 --> 01:29:34,601
Daniel: Awesome, thank you for these

2061
01:29:34,601 --> 01:29:34,601
comments.

2062
01:29:32,599 --> 01:29:50,617
So in my experience, computer scientists

2063
01:29:50,617 --> 01:29:50,617
and those who have empirical data

2064
01:29:50,617 --> 01:29:50,617
measurement experience, they know that

2065
01:29:50,617 --> 01:29:50,617
you can have different kinds of

2066
01:29:50,617 --> 01:29:50,617
behavioral measurements or just columns

2067
01:29:50,617 --> 01:29:50,617
in a database.

2068
01:29:34,601 --> 01:30:00,621
You could have heart rate and you can

2069
01:30:00,621 --> 01:30:00,621
have video data and you kind of have this

2070
01:30:00,621 --> 01:30:00,621
like open ended it doesn't need to be

2071
01:30:00,621 --> 01:30:00,621
just a matrix that gets multiplied in

2072
01:30:00,621 --> 01:30:00,621
this extremely clean way.

2073
01:29:50,617 --> 01:30:35,656
And I feel like that leads to a lot of

2074
01:30:35,656 --> 01:30:35,656
these very open ended and flexible

2075
01:30:35,656 --> 01:30:35,656
approaches which, on one hand address the

2076
01:30:35,656 --> 01:30:35,656
different forms and functions and

2077
01:30:35,656 --> 01:30:35,656
settings that these kinds of questions

2078
01:30:35,656 --> 01:30:35,656
are asked and at the same time are

2079
01:30:35,656 --> 01:30:35,656
working, if not to address, at least to

2080
01:30:35,656 --> 01:30:35,656
have continuity with classical

2081
01:30:35,656 --> 01:30:35,656
discussions on a wide range of topics

2082
01:30:35,656 --> 01:30:35,656
like sequence.

2083
01:30:00,621 --> 01:30:49,670
Eric: Yeah, the question of not

2084
01:30:49,670 --> 01:30:49,670
everything is a vector, not everything is

2085
01:30:49,670 --> 01:30:49,670
a matrix.

2086
01:30:43,664 --> 01:30:52,673
You could have more complicated data

2087
01:30:52,673 --> 01:30:52,673
structures.

2088
01:30:49,670 --> 01:30:56,677
That's really interesting and I think

2089
01:30:56,677 --> 01:30:56,677
relevance to consciousness.

2090
01:30:52,673 --> 01:31:10,685
So it certainly seems like our thoughts,

2091
01:31:10,685 --> 01:31:10,685
our experiences have this sort of

2092
01:31:10,685 --> 01:31:10,685
symbolic structure in a way you can kind

2093
01:31:10,685 --> 01:31:10,685
of think of them as like any thought as

2094
01:31:10,685 --> 01:31:10,685
sort of a graph.

2095
01:30:57,678 --> 01:31:16,691
I have a couple of concepts in mind maybe

2096
01:31:16,691 --> 01:31:16,691
in working memory and I have some idea of

2097
01:31:16,691 --> 01:31:16,691
how they relate to each other.

2098
01:31:11,686 --> 01:31:22,697
If it's not a graph, it's something like

2099
01:31:22,697 --> 01:31:22,697
that, maybe some kind of smooth

2100
01:31:22,697 --> 01:31:22,697
representation of a graph.

2101
01:31:16,691 --> 01:31:30,705
On the other hand, when you just look at

2102
01:31:30,705 --> 01:31:30,705
the brain all you see is neurons, all you

2103
01:31:30,705 --> 01:31:30,705
see is distributed high dimensional

2104
01:31:30,705 --> 01:31:30,705
neural activity.

2105
01:31:23,698 --> 01:31:52,727
So there's this really interesting

2106
01:31:52,727 --> 01:31:52,727
question of how you link them together

2107
01:31:52,727 --> 01:31:52,727
and I think attractor dynamics are

2108
01:31:52,727 --> 01:31:52,727
another interesting avenue for getting

2109
01:31:52,727 --> 01:31:52,727
there again, you kind of get a lot of

2110
01:31:52,727 --> 01:31:52,727
things, you get these high dimensional

2111
01:31:52,727 --> 01:31:52,727
continuous states that you could

2112
01:31:52,727 --> 01:31:52,727
represent you get sort of discrete states

2113
01:31:52,727 --> 01:31:52,727
that you could represent and they could

2114
01:31:52,727 --> 01:31:52,727
compose together.

2115
01:31:30,705 --> 01:31:58,733
Yeah, I think there's something there.

2116
01:31:54,729 --> 01:32:01,730
Guillaume: To.

2117
01:32:01,730 --> 01:32:31,760
Daniel: Kind of extend that point to this

2118
01:32:31,760 --> 01:32:31,760
very meta science area of discussion

2119
01:32:31,760 --> 01:32:31,760
around pluralism in science that

2120
01:32:31,760 --> 01:32:31,760
Guillaume opened the box on when practice

2121
01:32:31,760 --> 01:32:31,760
in the behavioral lab, if not much more

2122
01:32:31,760 --> 01:32:31,760
broadly, is using structures that have

2123
01:32:31,760 --> 01:32:31,760
different column types than certain

2124
01:32:31,760 --> 01:32:31,760
kinds.

2125
01:32:01,730 --> 01:32:40,769
Markov decision that might have been

2126
01:32:40,769 --> 01:32:40,769
taken to be in principle or like

2127
01:32:40,769 --> 01:32:40,769
arguments for the superiority, even

2128
01:32:40,769 --> 01:32:40,769
contextually of one framework.

2129
01:32:31,760 --> 01:32:47,776
Those are just unveiled purely

2130
01:32:47,776 --> 01:32:47,776
methodologically as modeler degrees of

2131
01:32:47,776 --> 01:32:47,776
freedom.

2132
01:32:40,769 --> 01:32:53,782
Like whether you use a generative model

2133
01:32:53,782 --> 01:32:53,782
that's continuous time or discrete time,

2134
01:32:53,782 --> 01:32:53,782
continuous state space.

2135
01:32:47,776 --> 01:33:05,788
Discrete state space, the thermometer

2136
01:33:05,788 --> 01:33:05,788
data, how you discretized it, where you

2137
01:33:05,788 --> 01:33:05,788
put the thermometer all these broader

2138
01:33:05,788 --> 01:33:05,788
factors that kind of instantiate the

2139
01:33:05,788 --> 01:33:05,788
experiment and the pipeline.

2140
01:32:53,782 --> 01:33:14,797
They're just all embodied and cultured

2141
01:33:14,797 --> 01:33:14,797
niche events in a scientific niche, in a

2142
01:33:14,797 --> 01:33:14,797
social niche.

2143
01:33:06,789 --> 01:33:50,833
And that's a very pragmatic or people

2144
01:33:50,833 --> 01:33:50,833
might use other words or like realist or

2145
01:33:50,833 --> 01:33:50,833
I don't know what adjective would

2146
01:33:50,833 --> 01:33:50,833
describe that take on starting with the

2147
01:33:50,833 --> 01:33:50,833
scientific community and formal modeling

2148
01:33:50,833 --> 01:33:50,833
and the modeling process as its own

2149
01:33:50,833 --> 01:33:50,833
behavior object and then working to have

2150
01:33:50,833 --> 01:33:50,833
the empirical practice more general, like

2151
01:33:50,833 --> 01:33:50,833
leading the generality open endedness

2152
01:33:50,833 --> 01:33:50,833
with practice.

2153
01:33:15,798 --> 01:33:55,837
Though that raises so many second order

2154
01:33:55,837 --> 01:33:55,837
questions as well.

2155
01:33:51,834 --> 01:34:23,860
Guillaume: Yeah, well, we can have also

2156
01:34:23,860 --> 01:34:23,860
from a very pragmatic standpoint we need

2157
01:34:23,860 --> 01:34:23,860
to have reproducibility so to have those

2158
01:34:23,860 --> 01:34:23,860
norms in design of experiment and format

2159
01:34:23,860 --> 01:34:23,860
tools makes sense but we need to just

2160
01:34:23,860 --> 01:34:23,860
remind ourselves often that they also

2161
01:34:23,860 --> 01:34:23,860
constrain our way of thinking.

2162
01:33:58,841 --> 01:34:37,874
And typically the history of science show

2163
01:34:37,874 --> 01:34:37,874
us how mathematics is guided by the

2164
01:34:37,874 --> 01:34:37,874
problems that we have to solve and

2165
01:34:37,874 --> 01:34:37,874
speaker.

2166
01:34:23,860 --> 01:34:47,884
If we take quantum mechanics it was not

2167
01:34:47,884 --> 01:34:47,884
like the formalism was popped out at

2168
01:34:47,884 --> 01:34:47,884
first and then quantum physicists use

2169
01:34:47,884 --> 01:34:47,884
it.

2170
01:34:37,874 --> 01:34:59,896
It was a generative process and a

2171
01:34:59,896 --> 01:34:59,896
collaborative effort between

2172
01:34:59,896 --> 01:34:59,896
mathematicians and physicists and

2173
01:34:59,896 --> 01:34:59,896
interestingly they come up even with two

2174
01:34:59,896 --> 01:34:59,896
different formalism that were shown to be

2175
01:34:59,896 --> 01:34:59,896
compatible later on.

2176
01:34:47,884 --> 01:35:16,907
So it's a nice tales in a way showing how

2177
01:35:16,907 --> 01:35:16,907
you can have even a stronger inter

2178
01:35:16,907 --> 01:35:16,907
subjective consensus by adopting

2179
01:35:16,907 --> 01:35:16,907
different formalisms that then later on

2180
01:35:16,907 --> 01:35:16,907
are shown to be compatible and

2181
01:35:16,907 --> 01:35:16,907
equivalent.

2182
01:34:59,896 --> 01:35:35,926
I have, unfortunately, to leave at some

2183
01:35:35,926 --> 01:35:35,926
point to pick up my daughter, but we can

2184
01:35:35,926 --> 01:35:35,926
go into category theory and more meta

2185
01:35:35,926 --> 01:35:35,926
mathematics to try to show that those

2186
01:35:35,926 --> 01:35:35,926
format in the end are potentially

2187
01:35:35,926 --> 01:35:35,926
equivalent.

2188
01:35:19,910 --> 01:35:41,932
But from a history of science, I think

2189
01:35:41,932 --> 01:35:41,932
it's not just about the equivalent.

2190
01:35:35,926 --> 01:35:47,938
It's also to have different viewpoints

2191
01:35:47,938 --> 01:35:47,938
that confirm each other to make.

2192
01:35:41,932 --> 01:35:50,941
Daniel: Our model.

2193
01:35:50,941 --> 01:35:54,945
Guillaume: Of the world intersubjectively

2194
01:35:54,945 --> 01:35:54,945
stable.

2195
01:35:50,941 --> 01:35:58,949
So to say, yeah, I'll give you.

2196
01:35:54,945 --> 01:36:02,947
Daniel: A small short closing comment,

2197
01:36:02,947 --> 01:36:02,947
Yom, and then we'll talk a little bit

2198
01:36:02,947 --> 01:36:02,947
more.

2199
01:35:58,949 --> 01:36:22,967
Shoe and Eric, when I first saw some of

2200
01:36:22,967 --> 01:36:22,967
your figures for hyper scanning, and

2201
01:36:22,967 --> 01:36:22,967
there were nodes that were being

2202
01:36:22,967 --> 01:36:22,967
connected with different edges that were

2203
01:36:22,967 --> 01:36:22,967
within and among brains, and there was

2204
01:36:22,967 --> 01:36:22,967
this one part dimension of my experience

2205
01:36:22,967 --> 01:36:22,967
that was like, you can't do that.

2206
01:36:02,947 --> 01:36:27,972
They're not connected, but it's a

2207
01:36:27,972 --> 01:36:27,972
statistical causal graph.

2208
01:36:22,967 --> 01:36:32,977
So they are exactly the same type of

2209
01:36:32,977 --> 01:36:32,977
explanation and empirical data

2210
01:36:32,977 --> 01:36:32,977
structure.

2211
01:36:27,972 --> 01:36:40,985
It's the same exact mutual information,

2212
01:36:40,985 --> 01:36:40,985
linear causation, whatever you want to do

2213
01:36:40,985 --> 01:36:40,985
in edges and edge in that

2214
01:36:40,985 --> 01:36:40,985
representation.

2215
01:36:32,977 --> 01:36:42,987
And that's the map territory situation.

2216
01:36:40,985 --> 01:36:43,988
They're not the ones that are touching.

2217
01:36:42,987 --> 01:36:55,999
And it was just like by seeing two levels

2218
01:36:55,999 --> 01:36:55,999
and the way that the representation could

2219
01:36:55,999 --> 01:36:55,999
be used, it was approved by example what

2220
01:36:55,999 --> 01:36:55,999
it meant at one level.

2221
01:36:44,989 --> 01:37:05,004
Guillaume: Yeah, it was hard to publish

2222
01:37:05,004 --> 01:37:05,004
at first because I think of that reason.

2223
01:36:57,002 --> 01:37:08,007
Daniel: Thank you.

2224
01:37:07,006 --> 01:37:09,008
Farewell, Guill.

2225
01:37:08,007 --> 01:37:13,012
Guillaume: Yeah, thanks again for the

2226
01:37:13,012 --> 01:37:13,012
invitation.

2227
01:37:09,008 --> 01:37:14,013
Take care.

2228
01:37:13,012 --> 01:37:20,019
Daniel: So what direction would you like

2229
01:37:20,019 --> 01:37:20,019
to go?

2230
01:37:18,017 --> 01:37:24,023
Or I can read another comment or anyone

2231
01:37:24,023 --> 01:37:24,023
else in the live chat in our last

2232
01:37:24,023 --> 01:37:24,023
minute.

2233
01:37:20,019 --> 01:37:38,036
Okay, let's kind of read last comment

2234
01:37:38,036 --> 01:37:38,036
from Yasha wrote, but these attractors

2235
01:37:38,036 --> 01:37:38,036
presumably correspond to different

2236
01:37:38,036 --> 01:37:38,036
concepts in the same sentence, are not

2237
01:37:38,036 --> 01:37:38,036
independently sampled.

2238
01:37:24,023 --> 01:37:52,051
Sorry, it's not like verbatim, but what

2239
01:37:52,051 --> 01:37:52,051
are these structures in language in terms

2240
01:37:52,051 --> 01:37:52,051
of I thought that was a very memorable

2241
01:37:52,051 --> 01:37:52,051
thing to say, that words are sequences,

2242
01:37:52,051 --> 01:37:52,051
too.

2243
01:37:38,037 --> 01:38:22,075
It's like they're modular with respect to

2244
01:38:22,075 --> 01:38:22,075
the dictionary, but then even the

2245
01:38:22,075 --> 01:38:22,075
phonemes or the writing structures have

2246
01:38:22,075 --> 01:38:22,075
their own compositional logic, like a

2247
01:38:22,075 --> 01:38:22,075
periodic table, and then there's sub

2248
01:38:22,075 --> 01:38:22,075
logics, and then there's just different

2249
01:38:22,075 --> 01:38:22,075
uses of different levels of description,

2250
01:38:22,075 --> 01:38:22,075
which is why we don't speak the same

2251
01:38:22,075 --> 01:38:22,075
language unless we do.

2252
01:37:53,052 --> 01:38:37,090
Eric: Yeah, well, directly, I think what

2253
01:38:37,090 --> 01:38:37,090
Yasha is referring to is like when you

2254
01:38:37,090 --> 01:38:37,090
sample a sentence, I guess, clearly these

2255
01:38:37,090 --> 01:38:37,090
are their own discrete things, but you're

2256
01:38:37,090 --> 01:38:37,090
not going to be sampling them

2257
01:38:37,090 --> 01:38:37,090
independently from each other.

2258
01:38:25,078 --> 01:38:43,096
It's like different words will cohere

2259
01:38:43,096 --> 01:38:43,096
more or less, and also they'll cohere

2260
01:38:43,096 --> 01:38:43,096
more or less.

2261
01:38:37,090 --> 01:38:48,101
Given a context, you want to form some

2262
01:38:48,101 --> 01:38:48,101
kind of sentence that describes some

2263
01:38:48,101 --> 01:38:48,101
context or some observations.

2264
01:38:43,096 --> 01:39:01,108
So, yeah, in regards to these

2265
01:39:01,108 --> 01:39:01,108
compositional attractors, again, the

2266
01:39:01,108 --> 01:39:01,108
simple picture where you have different

2267
01:39:01,108 --> 01:39:01,108
attractors converging along different

2268
01:39:01,108 --> 01:39:01,108
dimensions, obviously these attractors

2269
01:39:01,108 --> 01:39:01,108
are going to affect the convergence of

2270
01:39:01,108 --> 01:39:01,108
others.

2271
01:38:48,101 --> 01:39:01,108
Right?

2272
01:39:01,108 --> 01:39:05,112
So it's not like everything is just

2273
01:39:05,112 --> 01:39:05,112
moving independently along different

2274
01:39:05,112 --> 01:39:05,112
dimensions.

2275
01:39:02,109 --> 01:39:35,142
Xu: Yeah, I mean, simplifying assumption

2276
01:39:35,142 --> 01:39:35,142
that we make in our simple computational

2277
01:39:35,142 --> 01:39:35,142
model used in the paper is that we hide

2278
01:39:35,142 --> 01:39:35,142
sort of dependencies as noise in the

2279
01:39:35,142 --> 01:39:35,142
variables to avoid needing to consider

2280
01:39:35,142 --> 01:39:35,142
these links explicitly to sort of

2281
01:39:35,142 --> 01:39:35,142
highlight the main points about richness

2282
01:39:35,142 --> 01:39:35,142
and affordability that we wanted to

2283
01:39:35,142 --> 01:39:35,142
make.

2284
01:39:07,114 --> 01:39:53,160
But I really liked your point, Daniel,

2285
01:39:53,160 --> 01:39:53,160
about how there is sort of the data,

2286
01:39:53,160 --> 01:39:53,160
there's the physical reality and then

2287
01:39:53,160 --> 01:39:53,160
there's the compositional structure that

2288
01:39:53,160 --> 01:39:53,160
is sort of imposed on that.

2289
01:39:36,143 --> 01:39:55,161
I mean, it's a model, right?

2290
01:39:53,160 --> 01:40:10,171
So it's a modeling assumption that you

2291
01:40:10,171 --> 01:40:10,171
make and you have to choose at what level

2292
01:40:10,171 --> 01:40:10,171
of abstraction to define that model and

2293
01:40:10,171 --> 01:40:10,171
it can feel a bit arbitrary.

2294
01:39:55,161 --> 01:40:25,185
Eric: And then you also discussed kind of

2295
01:40:25,185 --> 01:40:25,185
well, we all speak different languages.

2296
01:40:18,179 --> 01:40:26,187
Yeah.

2297
01:40:26,187 --> 01:40:38,199
An interesting question for that in our

2298
01:40:38,199 --> 01:40:38,199
work is would that imply that we have

2299
01:40:38,199 --> 01:40:38,199
different attractor structures across

2300
01:40:38,199 --> 01:40:38,199
different cultures that have different

2301
01:40:38,199 --> 01:40:38,199
languages?

2302
01:40:26,187 --> 01:40:47,208
Is there an interaction there or are

2303
01:40:47,208 --> 01:40:47,208
these just these different languages

2304
01:40:47,208 --> 01:40:47,208
equivalent ways of describing the same

2305
01:40:47,208 --> 01:40:47,208
state of attractors?

2306
01:40:38,199 --> 01:40:55,216
And I think it's somewhere in the middle,

2307
01:40:55,216 --> 01:40:55,216
regardless of what language we all have,

2308
01:40:55,216 --> 01:40:55,216
I think similar concepts and similar

2309
01:40:55,216 --> 01:40:55,216
conscious experiences.

2310
01:40:47,208 --> 01:41:13,228
But there's some kind of cases where you

2311
01:41:13,228 --> 01:41:13,228
have a word in a given language that

2312
01:41:13,228 --> 01:41:13,228
maybe identifies sort of a fundamental

2313
01:41:13,228 --> 01:41:13,228
attractor and that's kind of like part of

2314
01:41:13,228 --> 01:41:13,228
their conscious vocabulary, I guess.

2315
01:40:56,217 --> 01:41:20,235
Whereas regardless of what language we

2316
01:41:20,235 --> 01:41:20,235
speak, we'd be able to get in that

2317
01:41:20,235 --> 01:41:20,235
conscious state ourselves.

2318
01:41:13,228 --> 01:41:28,243
But maybe given our language like the

2319
01:41:28,243 --> 01:41:28,243
attractors that you would need to compose

2320
01:41:28,243 --> 01:41:28,243
to construct this conscious state would

2321
01:41:28,243 --> 01:41:28,243
be a bit more complicated.

2322
01:41:20,235 --> 01:41:35,250
You'd need something like a longer

2323
01:41:35,250 --> 01:41:35,250
sentence, a longer thought to have the

2324
01:41:35,250 --> 01:41:35,250
same sort of experience.

2325
01:41:28,243 --> 01:41:38,253
Daniel: Awesome.

2326
01:41:37,252 --> 01:41:45,260
Well, one thing that brought to mind was

2327
01:41:45,260 --> 01:41:45,260
neural patches on the skin.

2328
01:41:38,253 --> 01:42:03,272
Like different parts of the body have

2329
01:42:03,272 --> 01:42:03,272
different density of sensory types from

2330
01:42:03,272 --> 01:42:03,272
very fine scale touch and action to some

2331
01:42:03,272 --> 01:42:03,272
more broader patches like where two

2332
01:42:03,272 --> 01:42:03,272
needles you can't determine the

2333
01:42:03,272 --> 01:42:03,272
difference between them.

2334
01:41:45,260 --> 01:42:15,284
And then that relates to many areas to

2335
01:42:15,284 --> 01:42:15,284
kind of development of taste and

2336
01:42:15,284 --> 01:42:15,284
differentiability being able to determine

2337
01:42:15,284 --> 01:42:15,284
differences.

2338
01:42:04,273 --> 01:42:46,315
And then you, of course, use this very

2339
01:42:46,315 --> 01:42:46,315
evocative but also grounded dual

2340
01:42:46,315 --> 01:42:46,315
representation of the samples that are

2341
01:42:46,315 --> 01:42:46,315
discrete and may have compositional

2342
01:42:46,315 --> 01:42:46,315
structure with a path that's moving

2343
01:42:46,315 --> 01:42:46,315
through them and seeking to embed the

2344
01:42:46,315 --> 01:42:46,315
topology of the sample points within an

2345
01:42:46,315 --> 01:42:46,315
information geometry, which is the kind

2346
01:42:46,315 --> 01:42:46,315
that are actual statistics input.

2347
01:42:16,285 --> 01:43:00,323
And then the neural patches are regions

2348
01:43:00,323 --> 01:43:00,323
where to one person it's like, yeah, I

2349
01:43:00,323 --> 01:43:00,323
drove through New Mexico and to the other

2350
01:43:00,323 --> 01:43:00,323
person it's like every inch, they're

2351
01:43:00,323 --> 01:43:00,323
having this rich experience.

2352
01:42:46,315 --> 01:43:02,325
They know the different stops.

2353
01:43:00,323 --> 01:43:26,349
And then I think one last great point

2354
01:43:26,349 --> 01:43:26,349
from the presentation was that we could

2355
01:43:26,349 --> 01:43:26,349
kind of I'm not exactly sure I said, but

2356
01:43:26,349 --> 01:43:26,349
emulate this informational characteristic

2357
01:43:26,349 --> 01:43:26,349
and maybe not even have the embodiment

2358
01:43:26,349 --> 01:43:26,349
for that to even have consciousness.

2359
01:43:03,326 --> 01:43:28,351
Of course, that'll be the debate then.

2360
01:43:26,349 --> 01:43:33,356
But the debate used to be much less

2361
01:43:33,356 --> 01:43:33,356
sophisticated than that.

2362
01:43:28,351 --> 01:43:36,359
And also people took principled stances.

2363
01:43:33,356 --> 01:43:46,369
Eric: Yeah, I wasn't totally clear on

2364
01:43:46,369 --> 01:43:46,369
that last point that you made.

2365
01:43:40,363 --> 01:44:15,392
Daniel: Principled stances on whether

2366
01:44:15,392 --> 01:44:15,392
this would be emulating or simulating or

2367
01:44:15,392 --> 01:44:15,392
approximating analytical framework for

2368
01:44:15,392 --> 01:44:15,392
consciousness, or whether this by

2369
01:44:15,392 --> 01:44:15,392
implementing that machine, that it would

2370
01:44:15,392 --> 01:44:15,392
be implementing consciousness versus the

2371
01:44:15,392 --> 01:44:15,392
kind of linear regression package that

2372
01:44:15,392 --> 01:44:15,392
does cognitive modeling that could be

2373
01:44:15,392 --> 01:44:15,392
understood in a purely SPM like

2374
01:44:15,392 --> 01:44:15,392
framework.

2375
01:43:47,370 --> 01:44:27,404
And SPM doesn't take a package

2376
01:44:27,404 --> 01:44:27,404
perspective, except maybe implicitly on

2377
01:44:27,404 --> 01:44:27,404
whether SPM models generate

2378
01:44:27,404 --> 01:44:27,404
consciousness.

2379
01:44:16,393 --> 01:44:31,408
Most likely it's easy to say no because

2380
01:44:31,408 --> 01:44:31,408
of generalized linear models.

2381
01:44:27,404 --> 01:44:41,418
So some people may take an in principle

2382
01:44:41,418 --> 01:44:41,418
stance that any description or

2383
01:44:41,418 --> 01:44:41,418
simulation, in certain ways, it's all

2384
01:44:41,418 --> 01:44:41,418
good.

2385
01:44:31,408 --> 01:44:43,420
We're definitely not generating anything

2386
01:44:43,420 --> 01:44:43,420
conscious.

2387
01:44:41,418 --> 01:44:55,432
It just would purely be a hugely

2388
01:44:55,432 --> 01:44:55,432
energetically, expensive, potentially

2389
01:44:55,432 --> 01:44:55,432
statistics exercise, which is fine.

2390
01:44:43,420 --> 01:44:57,434
Xu: Yeah.

2391
01:44:56,433 --> 01:45:14,445
The chain of reasoning of our work, I

2392
01:45:14,445 --> 01:45:14,445
suppose, is that if you assume a certain

2393
01:45:14,445 --> 01:45:14,445
model of consciousness, then that implies

2394
01:45:14,445 --> 01:45:14,445
ineffability as it is understood by

2395
01:45:14,445 --> 01:45:14,445
information loss.

2396
01:44:59,436 --> 01:45:29,459
But obviously information loss does not

2397
01:45:29,459 --> 01:45:29,459
apply, does not imply consciousness, even

2398
01:45:29,459 --> 01:45:29,459
though it's an attribute of how

2399
01:45:29,459 --> 01:45:29,459
consciousness manifests in humans.

2400
01:45:14,445 --> 01:45:56,487
So yeah, I mean, this question of what is

2401
01:45:56,487 --> 01:45:56,487
the necessary desidorata to declare

2402
01:45:56,487 --> 01:45:56,487
whether a system is conscious or not is

2403
01:45:56,487 --> 01:45:56,487
not what we discuss in the paper at all.

2404
01:45:31,462 --> 01:46:04,489
I mean, from my perspective as a machine

2405
01:46:04,489 --> 01:46:04,489
learning practitioner, it's closer to

2406
01:46:04,489 --> 01:46:04,489
what I said in the last slide.

2407
01:45:57,488 --> 01:46:09,494
I would like to get the benefits of

2408
01:46:09,494 --> 01:46:09,494
consciousness in an artificial model.

2409
01:46:05,490 --> 01:46:21,506
And it doesn't matter so much whether the

2410
01:46:21,506 --> 01:46:21,506
form that takes is similar to how it

2411
01:46:21,506 --> 01:46:21,506
manifests in biological systems or not.

2412
01:46:10,495 --> 01:46:23,508
Why should it?

2413
01:46:21,506 --> 01:46:34,519
You know, I mean, we don't have the kind

2414
01:46:34,519 --> 01:46:34,519
of resources that evolution has had over

2415
01:46:34,519 --> 01:46:34,519
over a billion years to optimize for this

2416
01:46:34,519 --> 01:46:34,519
model.

2417
01:46:23,508 --> 01:46:57,542
So the question is, how do we design

2418
01:46:57,542 --> 01:46:57,542
systems that can benefit from, for

2419
01:46:57,542 --> 01:46:57,542
example, the generalization and

2420
01:46:57,542 --> 01:46:57,542
robustness properties that being very

2421
01:46:57,542 --> 01:46:57,542
contractive in processing can give you,

2422
01:46:57,542 --> 01:46:57,542
rather than what's the exact definition

2423
01:46:57,542 --> 01:46:57,542
of consciousness and how do we replicate

2424
01:46:57,542 --> 01:46:57,542
that inner machines?

2425
01:46:35,520 --> 01:47:10,549
Because that to me is sort of a very

2426
01:47:10,549 --> 01:47:10,549
superficial well, it's a more superficial

2427
01:47:10,549 --> 01:47:10,549
problem in that it's looking at the how

2428
01:47:10,549 --> 01:47:10,549
and not the why.

2429
01:46:57,542 --> 01:47:15,554
Eric: And yeah, I have some thoughts on

2430
01:47:15,554 --> 01:47:15,554
this.

2431
01:47:12,551 --> 01:47:34,573
Also, jonathan Simon, who's a co author

2432
01:47:34,573 --> 01:47:34,573
on our work, he gave a really interesting

2433
01:47:34,573 --> 01:47:34,573
presentation recently that I heard, which

2434
01:47:34,573 --> 01:47:34,573
is, whatever model of consciousness you

2435
01:47:34,573 --> 01:47:34,573
assume, let's say global workspace

2436
01:47:34,573 --> 01:47:34,573
theory, there's a minimal model of it

2437
01:47:34,573 --> 01:47:34,573
that you could construct.

2438
01:47:15,554 --> 01:47:37,576
We could easily construct some kind of

2439
01:47:37,576 --> 01:47:37,576
model.

2440
01:47:34,573 --> 01:47:46,585
Like, to make this really concrete,

2441
01:47:46,585 --> 01:47:46,585
there's a bunch of mini neural networks

2442
01:47:46,585 --> 01:47:46,585
that are the sub processes and they're

2443
01:47:46,585 --> 01:47:46,585
communicating through some shared Rnn,

2444
01:47:46,585 --> 01:47:46,585
let's say.

2445
01:47:37,576 --> 01:48:02,595
So you can construct a minimal model like

2446
01:48:02,595 --> 01:48:02,595
this, train it on some task, and then if

2447
01:48:02,595 --> 01:48:02,595
your viewpoint was that a global

2448
01:48:02,595 --> 01:48:02,595
workspace theory with such and such

2449
01:48:02,595 --> 01:48:02,595
properties is what generates

2450
01:48:02,595 --> 01:48:02,595
consciousness, well, then you'd be forced

2451
01:48:02,595 --> 01:48:02,595
to say that your minimal model is

2452
01:48:02,595 --> 01:48:02,595
conscious.

2453
01:47:46,585 --> 01:48:11,604
And this is in a way, I guess, not

2454
01:48:11,604 --> 01:48:11,604
problematic, but sort of counterintuitive

2455
01:48:11,604 --> 01:48:11,604
because the model could be doing really

2456
01:48:11,604 --> 01:48:11,604
simple things.

2457
01:48:02,595 --> 01:48:14,607
It could not even be reporting that it's

2458
01:48:14,607 --> 01:48:14,607
having any consciousness at all.

2459
01:48:11,604 --> 01:48:15,608
It might not even have language.

2460
01:48:14,607 --> 01:48:20,613
It might just be doing something like

2461
01:48:20,613 --> 01:48:20,613
solving mnist in a global workspace type

2462
01:48:20,613 --> 01:48:20,613
architecture.

2463
01:48:15,608 --> 01:48:24,617
Do you really want to say that that thing

2464
01:48:24,617 --> 01:48:24,617
is conscious?

2465
01:48:20,613 --> 01:48:33,626
Yeah, it is a problem, I think, with most

2466
01:48:33,626 --> 01:48:33,626
theories of consciousness.

2467
01:48:27,619 --> 01:48:43,636
Maybe one kind of exception in my view is

2468
01:48:43,636 --> 01:48:43,636
theories that say we basically have a

2469
01:48:43,636 --> 01:48:43,636
representation that we're conscious.

2470
01:48:33,626 --> 01:48:58,651
So one canonical example, I guess, is

2471
01:48:58,651 --> 01:48:58,651
Michael Graciano's attention schema

2472
01:48:58,651 --> 01:48:58,651
theory which basically says our brain

2473
01:48:58,651 --> 01:48:58,651
constructs a model of what attention is

2474
01:48:58,651 --> 01:48:58,651
doing in the brain.

2475
01:48:43,636 --> 01:49:02,649
And that model basically just describes

2476
01:49:02,649 --> 01:49:02,649
something that is like experience.

2477
01:48:58,651 --> 01:49:11,658
It describes, oh, I'm aware of these

2478
01:49:11,658 --> 01:49:11,658
things, they have these properties, I

2479
01:49:11,658 --> 01:49:11,658
could report that I'm experiencing these

2480
01:49:11,658 --> 01:49:11,658
things.

2481
01:49:02,649 --> 01:49:16,663
It's basically a representation, a set of

2482
01:49:16,663 --> 01:49:16,663
neural activity in the brain.

2483
01:49:11,658 --> 01:49:25,671
And there you don't have the same problem

2484
01:49:25,671 --> 01:49:25,671
where you can construct a minimal model

2485
01:49:25,671 --> 01:49:25,671
because presumably this representation of

2486
01:49:25,671 --> 01:49:25,671
consciousness is really complex.

2487
01:49:16,663 --> 01:49:39,686
And then I guess another set of theories

2488
01:49:39,686 --> 01:49:39,686
would say that even if you emulate

2489
01:49:39,686 --> 01:49:39,686
whatever processes in the brain we think

2490
01:49:39,686 --> 01:49:39,686
generate consciousness, the physical

2491
01:49:39,686 --> 01:49:39,686
implementation might be really important

2492
01:49:39,686 --> 01:49:39,686
over here.

2493
01:49:25,672 --> 01:49:57,703
So the example that comes to mind is IIT,

2494
01:49:57,703 --> 01:49:57,703
which would say it's basically substrate

2495
01:49:57,703 --> 01:49:57,703
dependent in the sense that you could

2496
01:49:57,703 --> 01:49:57,703
have the exact same function, the exact

2497
01:49:57,703 --> 01:49:57,703
same mechanism implemented in different

2498
01:49:57,703 --> 01:49:57,703
ways, like on a computer processor or a

2499
01:49:57,703 --> 01:49:57,703
neuromorphic hardware.

2500
01:49:39,686 --> 01:50:05,706
And in one case there may or may not be

2501
01:50:05,706 --> 01:50:05,706
consciousness, whereas you have the exact

2502
01:50:05,706 --> 01:50:05,706
same function in another substrate and

2503
01:50:05,706 --> 01:50:05,706
yeah, it is conscious.

2504
01:49:57,704 --> 01:50:15,716
So that's, I guess, another class of

2505
01:50:15,716 --> 01:50:15,716
theories that would say that emulation

2506
01:50:15,716 --> 01:50:15,716
does not necessarily imply that you're

2507
01:50:15,716 --> 01:50:15,716
actually generating consciousness.

2508
01:50:05,706 --> 01:50:29,730
Daniel: In our last 2 minutes, what are

2509
01:50:29,730 --> 01:50:29,730
your closing thoughts or next directions

2510
01:50:29,730 --> 01:50:29,730
exhortations to the humans and language

2511
01:50:29,730 --> 01:50:29,730
models?

2512
01:50:18,719 --> 01:50:42,743
Eric: Yeah, well, I guess I'm interested

2513
01:50:42,743 --> 01:50:42,743
in this stuff a lot from a purely

2514
01:50:42,743 --> 01:50:42,743
philosophical perspective.

2515
01:50:31,732 --> 01:50:49,750
So the hard problem for me is really

2516
01:50:49,750 --> 01:50:49,750
salience of why would any physical

2517
01:50:49,750 --> 01:50:49,750
mechanisms generate consciousness?

2518
01:50:42,743 --> 01:51:01,756
And the nice thing, at least for me about

2519
01:51:01,756 --> 01:51:01,756
this work, the most satisfying part of it

2520
01:51:01,756 --> 01:51:01,756
was that I initially had this intuition

2521
01:51:01,756 --> 01:51:01,756
that experiences what the color red is.

2522
01:50:49,750 --> 01:51:09,764
It's not just information, it's kind of

2523
01:51:09,764 --> 01:51:09,764
underdetermined there's something more

2524
01:51:09,764 --> 01:51:09,764
than just information because I can't do

2525
01:51:09,764 --> 01:51:09,764
things like describe it.

2526
01:51:01,756 --> 01:51:16,771
But now we have a theory that kind of

2527
01:51:16,771 --> 01:51:16,771
breaks that intuition.

2528
01:51:10,765 --> 01:51:23,778
And now I have a satisfying explanation,

2529
01:51:23,778 --> 01:51:23,778
I feel, for why I can't describe my

2530
01:51:23,778 --> 01:51:23,778
experiences but under a physicalist

2531
01:51:23,778 --> 01:51:23,778
framework.

2532
01:51:16,771 --> 01:51:38,793
So I think it'd be interesting to reason

2533
01:51:38,793 --> 01:51:38,793
through some other of the thought

2534
01:51:38,793 --> 01:51:38,793
experiments that make the hard problem

2535
01:51:38,793 --> 01:51:38,793
salient and kind of develop some models

2536
01:51:38,793 --> 01:51:38,793
that kind of break the intuitions.

2537
01:51:23,778 --> 01:51:45,800
For the hard problem in my case at least,

2538
01:51:45,800 --> 01:51:45,800
I've seen it done in this scenario with

2539
01:51:45,800 --> 01:51:45,800
the topic of ineffability.

2540
01:51:38,793 --> 01:51:51,806
So there's no reason in principle that it

2541
01:51:51,806 --> 01:51:51,806
can't be done across other aspects of the

2542
01:51:51,806 --> 01:51:51,806
hard problem.

2543
01:51:45,800 --> 01:51:52,807
Xu: Yeah.

2544
01:51:51,806 --> 01:52:17,826
So I think if I were to sum up the work

2545
01:52:17,826 --> 01:52:17,826
in one very high level sentence, it's

2546
01:52:17,826 --> 01:52:17,826
that, well, reasoning subjectively about

2547
01:52:17,826 --> 01:52:17,826
subjectivity is very difficult, but

2548
01:52:17,826 --> 01:52:17,826
reasoning objectively about subjectivity

2549
01:52:17,826 --> 01:52:17,826
is easier.

2550
01:51:52,807 --> 01:52:30,839
And that's sort of what we do in the

2551
01:52:30,839 --> 01:52:30,839
paper because we take an objective

2552
01:52:30,839 --> 01:52:30,839
standpoint and we try to formalize or

2553
01:52:30,839 --> 01:52:30,839
characterize subjectivity from that

2554
01:52:30,839 --> 01:52:30,839
standpoint.

2555
01:52:17,826 --> 01:52:38,847
That sort of makes the picture clearer.

2556
01:52:34,843 --> 01:53:01,864
From my perspective, I'm interested in

2557
01:53:01,864 --> 01:53:01,864
consciousness mainly in terms of what it

2558
01:53:01,864 --> 01:53:01,864
offers what it brings in terms of, for

2559
01:53:01,864 --> 01:53:01,864
example, improving generalization of

2560
01:53:01,864 --> 01:53:01,864
artificial learned models.

2561
01:52:40,849 --> 01:53:22,885
Yeah, it's interesting because another

2562
01:53:22,885 --> 01:53:22,885
work that I'm doing is formalizing

2563
01:53:22,885 --> 01:53:22,885
generalization bounds for information

2564
01:53:22,885 --> 01:53:22,885
bottleneck, which is a regularization

2565
01:53:22,885 --> 01:53:22,885
principle used in machine learning.

2566
01:53:05,868 --> 01:53:51,914
So it's just really interesting how

2567
01:53:51,914 --> 01:53:51,914
evolution has sort of discovered by

2568
01:53:51,914 --> 01:53:51,914
itself this this regularizer principle

2569
01:53:51,914 --> 01:53:51,914
that that that it applies to to human

2570
01:53:51,914 --> 01:53:51,914
cognition that we can also show

2571
01:53:51,914 --> 01:53:51,914
mathematically, actually does improve

2572
01:53:51,914 --> 01:53:51,914
guarantees on on generalization.

2573
01:53:22,885 --> 01:53:55,918
That that is really mind blowing to me.

2574
01:53:52,915 --> 01:54:00,917
Daniel: Wow.

2575
01:53:59,922 --> 01:54:03,920
Great presentation.

2576
01:54:01,918 --> 01:54:08,925
So thank you both for joining you're

2577
01:54:08,925 --> 01:54:08,925
welcome back anytime.

2578
01:54:04,921 --> 01:54:10,927
Eric: Thanks so much, Daniel.

2579
01:54:09,926 --> 01:54:11,928
It was a lot of fun.

