1
00:00:08,641 --> 00:00:11,277
Hello
and welcome to the Active Inference Lab.

2
00:00:11,578 --> 00:00:17,217
Today it is October 25th, 2021,
and we are here in Active

3
00:00:17,217 --> 00:00:21,321
Inference Guest stream number 12.1
with Martin Butz.

4
00:00:21,621 --> 00:00:24,958
So this is going to be an awesome
presentation and discussion

5
00:00:25,258 --> 00:00:26,426
if you're watching live.

6
00:00:26,426 --> 00:00:29,796
Please feel free to add
any questions into the live chat

7
00:00:29,796 --> 00:00:32,799
and we'll be compiling those
and otherwise

8
00:00:32,799 --> 00:00:36,536
we're just going to have a presentation
and then discussion interval.

9
00:00:36,603 --> 00:00:40,707
So, Martin, thanks so much for joining
our lab to give this presentation.

10
00:00:40,707 --> 00:00:44,544
And we're really looking forward
to what you have to share.

11
00:00:44,744 --> 00:00:47,881
Yeah, a big pleasure to be here tonight,

12
00:00:47,881 --> 00:00:49,716
this morning, I guess, for you guys

13
00:00:49,716 --> 00:00:51,885
in California.

14
00:00:52,719 --> 00:00:55,288
So let's see if I get the.

15
00:00:55,989 --> 00:00:57,624
Screen sharing here. Right.

16
00:00:57,624 --> 00:00:59,959
Again, we practiced before this.

17
00:01:00,593 --> 00:01:01,828
This one here

18
00:01:02,796 --> 00:01:03,997
looks great.

19
00:01:03,997 --> 00:01:05,331
And I just need.

20
00:01:05,331 --> 00:01:08,468
To have at least one video on the side
here for me.

21
00:01:10,003 --> 00:01:12,072
So, yeah, big pleasure

22
00:01:12,739 --> 00:01:17,077
to present our labs
work on which I call event predictive,

23
00:01:17,577 --> 00:01:21,548
active inference, and particularly
also modeling the development

24
00:01:21,548 --> 00:01:26,553
of conceptual compositional cognition
from sensorimotor experiences.

25
00:01:27,187 --> 00:01:29,889
You might have already

26
00:01:30,323 --> 00:01:33,593
kind of noticed the picture here.

27
00:01:33,593 --> 00:01:36,362
This artistic picture on the top, right?

28
00:01:36,362 --> 00:01:39,399
And I think it shows nicely
and intuitively

29
00:01:39,399 --> 00:01:43,169
how our brain continuously
seems to attempt

30
00:01:43,837 --> 00:01:49,008
to infer the hidden causes
behind our sensory perceptions.

31
00:01:49,309 --> 00:01:54,013
And thus this kind of terrace,
this kind of bend for us a little bit.

32
00:01:54,013 --> 00:01:56,316
Because the top part, of course.

33
00:01:56,316 --> 00:01:57,450
Just can be.

34
00:01:57,450 --> 00:02:00,019
Interpreted in two ways in this,
obviously

35
00:02:00,720 --> 00:02:06,392
not quite rightly positioned
or it cannot be like this.

36
00:02:06,392 --> 00:02:07,127
In reality,

37
00:02:08,161 --> 00:02:10,130
it gives you a couple of other examples.

38
00:02:10,130 --> 00:02:14,200
What I mean by this active inference,
which is known to

39
00:02:14,200 --> 00:02:19,472
or explained often by friston and others,
to accentuate, essentially develop

40
00:02:19,472 --> 00:02:23,176
latent hidden states to explain
away. The.

41
00:02:23,510 --> 00:02:27,780
Sensory sections by inferring
the hidden causes behind them.

42
00:02:28,214 --> 00:02:33,753
So here you see in color illustration,
which is the cortical illusion sometimes.

43
00:02:34,120 --> 00:02:36,256
Where you. Probably won't believe it.

44
00:02:36,256 --> 00:02:40,493
I have to measure it each time again
to make sure that I'm really right.

45
00:02:40,493 --> 00:02:45,331
But essentially in this yellow
tinted figure, essentially

46
00:02:45,331 --> 00:02:48,301
these blue colored squares here,

47
00:02:48,301 --> 00:02:51,104
they are essentially grayscale. Now.

48
00:02:51,504 --> 00:02:53,873
If you test them by.

49
00:02:53,873 --> 00:02:57,977
A. New graphics program, you will see
that this is a grayscale position.

50
00:02:57,977 --> 00:02:59,412
So I blue points here.

51
00:02:59,412 --> 00:03:00,613
In fact, grayscale.

52
00:03:00,613 --> 00:03:03,082
And here on this side
with the blue tinted background,

53
00:03:03,416 --> 00:03:05,218
you essentially have the same situation.

54
00:03:05,218 --> 00:03:07,854
But it's the yellow pieces. That are.

55
00:03:08,221 --> 00:03:11,257
Actually grayscale as illustrated
here on the right little bit.

56
00:03:11,824 --> 00:03:15,161
And this just shows essentially
that our brain.

57
00:03:16,029 --> 00:03:19,232
Is. Interpreting its sensory perceptions

58
00:03:19,532 --> 00:03:24,337
in the light more and logically fitting.

59
00:03:24,337 --> 00:03:24,637
Here.

60
00:03:25,838 --> 00:03:27,941
Of the circumstances.

61
00:03:27,941 --> 00:03:30,410
Now, in this case, yellow light

62
00:03:30,743 --> 00:03:35,682
makes a true blue square appear gray
when we look at it.

63
00:03:35,782 --> 00:03:37,617
So we perceive it gray.

64
00:03:37,617 --> 00:03:42,155
The sensory stimulation is gray,
but the true cause behind

65
00:03:42,155 --> 00:03:43,590
it must be a blue square.

66
00:03:43,590 --> 00:03:50,263
So i i brain essentially correctly
and actively infers that this squares

67
00:03:50,263 --> 00:03:54,500
most likely blue, because under this
yellow light conditions it appears gray.

68
00:03:54,601 --> 00:03:58,238
And we're not even aware of that.

69
00:03:58,238 --> 00:03:59,572
So this is.

70
00:03:59,572 --> 00:04:01,007
Roughly an.

71
00:04:01,007 --> 00:04:04,777
Example of a very low level
inference process in our brain

72
00:04:04,777 --> 00:04:08,348
that takes into account the situation
and essentially puts

73
00:04:08,348 --> 00:04:11,884
the perceptual sensory
information in this event,

74
00:04:12,151 --> 00:04:15,355
this light event,
this lightning condition, essentially.

75
00:04:16,155 --> 00:04:17,223
Another.

76
00:04:17,223 --> 00:04:22,095
Nice example of this is these shadows
that I found here on line

77
00:04:22,095 --> 00:04:25,698
from from some artistic exhibition.

78
00:04:25,965 --> 00:04:27,734
And you have here two shadows.

79
00:04:27,734 --> 00:04:31,904
And as long as you look at the shadows
and you perceive the shadows, you kind of

80
00:04:31,904 --> 00:04:34,340
not only perceive the shadows,
but you perceive a person

81
00:04:34,340 --> 00:04:35,675
and the illustration of a person

82
00:04:35,675 --> 00:04:39,012
and to a certain extent,
you have the feeling that some person

83
00:04:39,012 --> 00:04:41,481
must be standing here
somewhere, such that.

84
00:04:42,282 --> 00:04:45,752
I. Will perceive this, this shadows.

85
00:04:45,752 --> 00:04:47,553
But lo and behold.

86
00:04:47,553 --> 00:04:49,756
This situation is totally different.

87
00:04:49,756 --> 00:04:56,029
These are actually cool artistic
sculptures that produce the shadows.

88
00:04:56,029 --> 00:05:01,868
And again, you see that they are
you have perceived

89
00:05:02,235 --> 00:05:05,972
the shadow and interpreted
not only the shadow, but created

90
00:05:05,972 --> 00:05:09,142
a whole scene, the whole event like this
and a light source

91
00:05:09,142 --> 00:05:10,410
and the person in the middle.

92
00:05:10,410 --> 00:05:10,910
And then the.

93
00:05:10,910 --> 00:05:15,448
Shadow that produces this in order
to make sense of the shadow itself.

94
00:05:15,448 --> 00:05:15,581
Yeah.

95
00:05:15,581 --> 00:05:20,186
So again, you inferred the hidden causes
behind the shadow in this case.

96
00:05:20,186 --> 00:05:21,754
Not quite correctly.

97
00:05:21,754 --> 00:05:26,693
Because it's a cool
illustrating, a cool artistic

98
00:05:28,461 --> 00:05:29,996
sculpture here that's

99
00:05:29,996 --> 00:05:33,466
with an installation with a light source.

100
00:05:33,766 --> 00:05:36,736
Perfectly positioned, such
that the sculpture creates

101
00:05:36,736 --> 00:05:39,272
a particular human like shadow figure.

102
00:05:39,772 --> 00:05:41,874
So the first proposition. That I.

103
00:05:42,575 --> 00:05:45,044
Take out of
this is essentially that our brain

104
00:05:45,545 --> 00:05:50,383
seems to be this generative predictive
model and uses active inference

105
00:05:50,383 --> 00:05:55,088
essentially with this generative
predictive model to generate acting,

106
00:05:55,621 --> 00:06:00,326
inferring internal activities
that is internal, active and coatings

107
00:06:00,593 --> 00:06:04,664
that try to explain away
the current sensory perceptions

108
00:06:04,897 --> 00:06:08,735
and thus make sense of it in the sense
that we explain them away

109
00:06:08,735 --> 00:06:11,804
by ideally inferring the true
hidden causes.

110
00:06:12,538 --> 00:06:13,639
Behind.

111
00:06:13,639 --> 00:06:15,742
The perceptions
that we actually perceive.

112
00:06:16,909 --> 00:06:20,613
This generative predictive models
explains a way perceptions

113
00:06:20,613 --> 00:06:24,851
it maintains distributed
predictive activities

114
00:06:26,152 --> 00:06:28,154
which form this kind of attractors,

115
00:06:28,621 --> 00:06:32,825
which often then are formalized,
particularly by Friston.

116
00:06:32,825 --> 00:06:34,527
And his. Followers.

117
00:06:34,527 --> 00:06:35,261
So to say.

118
00:06:35,261 --> 00:06:37,397
And in. Various ways.

119
00:06:37,730 --> 00:06:39,565
Formalizing this and.

120
00:06:39,565 --> 00:06:43,503
Essentially suggesting
that the brain develops

121
00:06:43,503 --> 00:06:48,541
this local free energy minima,
this local attractor like minima,

122
00:06:48,908 --> 00:06:53,079
that is the consistent explanation
of a particular perception

123
00:06:53,079 --> 00:06:55,748
that you currently
have under consideration.

124
00:06:56,482 --> 00:06:59,852
So this would be, for example,
in the shadow situation, right?

125
00:07:00,219 --> 00:07:01,888
We perceive the shadow, but we know

126
00:07:02,855 --> 00:07:03,856
intuitively that

127
00:07:03,856 --> 00:07:06,993
there's a light source and something
in between that produces a shadow.

128
00:07:06,993 --> 00:07:08,494
And thus in the.

129
00:07:08,494 --> 00:07:11,130
In the shadow of a person,
we essentially immediately

130
00:07:11,130 --> 00:07:14,233
have the feeling
that some person must be standing there.

131
00:07:15,134 --> 00:07:17,970
The free energy formalism essentially

132
00:07:19,005 --> 00:07:21,340
pushes towards the generation

133
00:07:21,340 --> 00:07:25,411
of these generative predictive models
and pushes towards

134
00:07:25,411 --> 00:07:29,582
the continuous active inference processes
that are unfolding

135
00:07:29,882 --> 00:07:33,152
within these developing generative
predictive models

136
00:07:33,553 --> 00:07:36,789
and one can nicely distinguish
three kind of aspects

137
00:07:37,156 --> 00:07:40,026
of this general inference
process formalism.

138
00:07:40,860 --> 00:07:42,061
And that is on the one.

139
00:07:42,061 --> 00:07:44,564
Hand site on the first insight,
knowing what is going on.

140
00:07:44,564 --> 00:07:48,434
So that's essentially the fast adaptation
of internal model activities

141
00:07:48,801 --> 00:07:53,639
towards this local free energy minima
to explain to ourselves what's going on.

142
00:07:53,639 --> 00:07:58,044
So if you looked altogether at the shadow
and you perceive the shadow, then

143
00:07:59,345 --> 00:08:00,780
you perceive not only

144
00:08:00,780 --> 00:08:03,916
the shadow, but you had the feeling
that you inferred the causes.

145
00:08:03,916 --> 00:08:07,186
That is, that there is a person in
the light source that creates the shadow.

146
00:08:07,787 --> 00:08:11,457
Now then the second part is learning
more about the world.

147
00:08:11,524 --> 00:08:13,926
We can revise our generative
predictive models.

148
00:08:13,926 --> 00:08:18,931
For example, you have now revised your
predictive models learning about that.

149
00:08:18,931 --> 00:08:22,435
There are some cool people
that make sculptures that produce human

150
00:08:22,435 --> 00:08:25,771
like shadows, and there's
no human actually, but just a sculpture.

151
00:08:26,172 --> 00:08:29,175
And so you have learn something
new about the world essentially.

152
00:08:29,542 --> 00:08:32,612
And we draw the first two aspects
of inference

153
00:08:32,612 --> 00:08:36,482
aspects essentially, of course,
only to really survive in our world,

154
00:08:36,482 --> 00:08:39,085
to live, to interact
with our world in better manners.

155
00:08:39,485 --> 00:08:41,754
So to really pursue our goals.

156
00:08:42,421 --> 00:08:45,825
And our knowledge driven behavior.

157
00:08:45,825 --> 00:08:49,595
Of epistemic behavior
with them by the means of these

158
00:08:49,595 --> 00:08:53,366
developing generative predictive models.

159
00:08:53,366 --> 00:08:55,134
Let me explain it a little bit further.

160
00:08:55,134 --> 00:08:57,837
So so it's clear how I mean, this

161
00:08:58,704 --> 00:09:03,009
so essentially
also implied by the generative

162
00:09:03,876 --> 00:09:06,879
by the free energy
formalism and extra inference formalism,

163
00:09:06,879 --> 00:09:10,016
one can say
that our brain is continuously.

164
00:09:10,683 --> 00:09:12,385
On the one. Hand side.

165
00:09:12,385 --> 00:09:14,020
In the. Present for sure. Right.

166
00:09:14,020 --> 00:09:15,221
I mean, we are ready.

167
00:09:15,221 --> 00:09:17,256
Why we for example, write a letter here.

168
00:09:17,623 --> 00:09:22,128
We are ready to produce the
next word and write it out

169
00:09:24,330 --> 00:09:25,064
on paper.

170
00:09:25,064 --> 00:09:29,101
For example, we consider the recent past
by doing this

171
00:09:29,101 --> 00:09:32,905
to be really in the present
and fully embodied and grounded in the.

172
00:09:32,905 --> 00:09:35,308
Here and now.

173
00:09:35,308 --> 00:09:36,976
The present

174
00:09:37,476 --> 00:09:39,912
is also continuously updated

175
00:09:39,912 --> 00:09:44,050
by our sensory
feedback, by interact with environment.

176
00:09:44,050 --> 00:09:47,720
So for example,
we might update our belief how sturdy

177
00:09:47,720 --> 00:09:50,656
the pencil is or how hot it is
and things like this.

178
00:09:51,424 --> 00:09:52,291
And we.

179
00:09:52,291 --> 00:09:54,827
Learn about our.

180
00:09:54,827 --> 00:09:58,564
World while we interact with it, such
as improving our writing skills

181
00:09:58,564 --> 00:09:59,665
and so forth.

182
00:09:59,665 --> 00:10:02,101
But most importantly, we use this

183
00:10:03,069 --> 00:10:05,204
presentation of the presence
and the belief where.

184
00:10:05,204 --> 00:10:07,440
We are in. Essentially to.

185
00:10:08,307 --> 00:10:09,375
Predict. The future.

186
00:10:09,375 --> 00:10:12,745
What is going to happen,
if you like, this future considerations.

187
00:10:13,179 --> 00:10:14,614
And then.

188
00:10:15,181 --> 00:10:19,352
Essentially to pursue particular future

189
00:10:19,418 --> 00:10:24,357
desired situation such as finalizing
writing this letter, writing this word,

190
00:10:26,125 --> 00:10:28,127
producing a letter for another person.

191
00:10:29,362 --> 00:10:30,896
And. Having overall purposes.

192
00:10:30,896 --> 00:10:33,633
Also other purposes, of course,
for the current day and so forth.

193
00:10:33,633 --> 00:10:36,268
And these considerations,
depending on our focus

194
00:10:36,569 --> 00:10:39,939
and the difference
between the desired future considerations

195
00:10:39,939 --> 00:10:42,842
and the current expected future
considerations

196
00:10:43,242 --> 00:10:45,911
make us improve our behavior and act in

197
00:10:45,911 --> 00:10:48,180
Nicole directed manner its environment.

198
00:10:49,315 --> 00:10:50,449
One can.

199
00:10:50,883 --> 00:10:53,252
Illustrate this in a different way
by essentially.

200
00:10:53,252 --> 00:10:54,420
Saying, Well, the.

201
00:10:54,420 --> 00:10:55,755
Active inference

202
00:10:55,855 --> 00:11:00,026
framework essentially suggests
that we are continuous in a predictive

203
00:11:00,026 --> 00:11:03,562
state of mind, ready
to produce, to process

204
00:11:03,562 --> 00:11:06,866
the next sensory information
for doing information integration.

205
00:11:06,866 --> 00:11:13,706
They're producing local posteriors,
integrating this local posteriors

206
00:11:13,706 --> 00:11:17,610
as perception with our overall beliefs
and our models, or perceiving the shadow

207
00:11:17,610 --> 00:11:19,879
inferring that there's
probably a personal light source

208
00:11:19,879 --> 00:11:25,418
that produces the shadow integrating
and overall consistent in attempting

209
00:11:25,418 --> 00:11:28,988
to create an overall consistent,
a posterior predictive state of mind.

210
00:11:28,988 --> 00:11:31,891
And we use this state
of mind essentially. To.

211
00:11:33,592 --> 00:11:35,928
Roll out future considerations,

212
00:11:35,928 --> 00:11:39,331
including habitually behavior
with our environment test.

213
00:11:39,331 --> 00:11:41,934
If you like this,
if you want to go there,

214
00:11:41,934 --> 00:11:45,137
or if you want to pursue particular,
other,

215
00:11:45,137 --> 00:11:49,475
other, other states in the future, choose
the best one we can do.

216
00:11:49,742 --> 00:11:52,845
Execute it, and then close the loop
by using the reference

217
00:11:52,845 --> 00:11:58,951
copy to do the temporal prediction
in the here and now.

218
00:11:58,951 --> 00:12:01,987
This epistemic goal

219
00:12:01,987 --> 00:12:05,991
directed behavior
can essentially be formalized nicely.

220
00:12:05,991 --> 00:12:07,593
In this.

221
00:12:08,561 --> 00:12:10,996
Reasonably short creation style.

222
00:12:11,731 --> 00:12:12,631
Tool.

223
00:12:12,631 --> 00:12:16,936
To generate
golder active epistemic behavior.

224
00:12:16,936 --> 00:12:20,072
This comes from Friston and Zullo

225
00:12:20,139 --> 00:12:22,374
at its work in 2015,

226
00:12:23,442 --> 00:12:25,544
which essentially

227
00:12:25,845 --> 00:12:29,882
I think is a very nicely formalized,
intuitive equation here, actually.

228
00:12:29,882 --> 00:12:35,788
So let's be pursuing the minimization
of free energy under a particular policy

229
00:12:36,088 --> 00:12:41,927
pie at a certain state, and pursuing this
free energy consists of two components.

230
00:12:41,927 --> 00:12:44,997
The first component is essentially
the pursuer.

231
00:12:44,997 --> 00:12:46,766
The goal directed component.

232
00:12:46,766 --> 00:12:51,103
And in this equation, it's essentially
trying to minimize the difference

233
00:12:51,604 --> 00:12:54,673
between the observations
that are expected to perceive.

234
00:12:55,040 --> 00:12:59,612
When I pursue a particular policy pie
and so a particular behavior pie.

235
00:13:00,112 --> 00:13:02,982
And compared to the observations

236
00:13:02,982 --> 00:13:05,951
that I would like to perceive
under my internal model,

237
00:13:06,452 --> 00:13:11,657
so this is essentially the expected
divergence from desired future states.

238
00:13:12,057 --> 00:13:14,860
And I pursue I try to then of course

239
00:13:14,860 --> 00:13:18,964
infer a policy pies or behavior pie
that minimizes

240
00:13:19,265 --> 00:13:22,101
the divergence from the expected

241
00:13:22,101 --> 00:13:25,037
future states to the desired future
states.

242
00:13:25,938 --> 00:13:28,941
The other component in this
equation is the epistemic

243
00:13:30,142 --> 00:13:30,576
part.

244
00:13:30,576 --> 00:13:31,744
It's essentially

245
00:13:31,744 --> 00:13:36,482
the minimization to attempt
to minimize expected future uncertainty.

246
00:13:36,482 --> 00:13:41,053
So it's the expectation of over my future
horizon tower.

247
00:13:41,387 --> 00:13:42,221
This for my.

248
00:13:42,221 --> 00:13:46,892
Timeline into the future
as you see here and it's essentially the

249
00:13:47,393 --> 00:13:52,364
the expectation of future uncertainty,
which I try to minimize as well.

250
00:13:52,364 --> 00:13:56,502
So under my consideration
of my policy pie,

251
00:13:56,535 --> 00:14:01,907
I expect future internal states and Towle
and this entails under the policy

252
00:14:02,174 --> 00:14:05,644
lead to the expectation
of future observations and then certainty

253
00:14:05,711 --> 00:14:06,679
of this observation.

254
00:14:06,679 --> 00:14:10,216
So the observation density is essentially

255
00:14:10,216 --> 00:14:12,251
so the entropy over. That, the more.

256
00:14:12,251 --> 00:14:17,456
Uncertain the the, the more diffuse
my expectation, the more uncertain

257
00:14:17,456 --> 00:14:21,861
my expectation, the less
I like this future considerations.

258
00:14:21,861 --> 00:14:25,297
And out of this two components
in the equation, one can essentially

259
00:14:26,031 --> 00:14:28,033
derive agents that act

260
00:14:28,434 --> 00:14:31,804
in directed and epistemic manners.

261
00:14:32,137 --> 00:14:32,805
We have done

262
00:14:34,006 --> 00:14:36,842
implemented such agents.

263
00:14:36,909 --> 00:14:38,344
Mainly.

264
00:14:38,811 --> 00:14:39,945
Partially.

265
00:14:39,945 --> 00:14:42,147
As. Rather still rather crude

266
00:14:42,481 --> 00:14:46,185
approximations, simply
with recurrent neural network structures.

267
00:14:46,185 --> 00:14:51,390
Here, for example, this rocket ball agent
that was is controlled by a newer

268
00:14:51,390 --> 00:14:57,363
network on the fly, essentially by first
training the network to learn the.

269
00:14:57,363 --> 00:15:01,033
Sensorimotor model. Of this agent.

270
00:15:01,033 --> 00:15:02,334
So this agent.

271
00:15:02,334 --> 00:15:02,801
Undergoes.

272
00:15:02,801 --> 00:15:05,704
Gravity and has inertia,
and the simulation in 2D

273
00:15:06,171 --> 00:15:09,208
and has this to a thrust
that go diagonally

274
00:15:10,442 --> 00:15:13,412
diagonally downwards so it can contract

275
00:15:13,412 --> 00:15:16,649
gravity and steer,
as you see essentially.

276
00:15:16,982 --> 00:15:22,354
And the red line that you see here
is essentially the imagination

277
00:15:22,354 --> 00:15:26,725
of the neural network where it expects
to fly to over the next couple of steps.

278
00:15:27,359 --> 00:15:29,762
So essentially the system rolls out, as

279
00:15:29,762 --> 00:15:33,299
I illustrated
before, essentially into the future.

280
00:15:33,299 --> 00:15:38,037
It's sensorimotor dynamics that expected
sensorimotor dynamics under expected

281
00:15:38,037 --> 00:15:42,608
motor control commands
that it imagines executing.

282
00:15:43,442 --> 00:15:45,411
And it then compares this.

283
00:15:45,411 --> 00:15:47,513
The resulting stage
with the desired state

284
00:15:47,680 --> 00:15:51,583
can take the divergence
or simply the delta if it's to domestic.

285
00:15:52,651 --> 00:15:53,852
And you

286
00:15:53,852 --> 00:15:56,922
said delta to
projected back onto the motor commands.

287
00:15:56,922 --> 00:16:00,225
So that's the system essentially acts

288
00:16:00,225 --> 00:16:03,662
in its own best interest
to pursue this goals.

289
00:16:03,662 --> 00:16:06,732
The goals are given from the outside
in this case.

290
00:16:07,032 --> 00:16:09,234
So this is still a rather simple system

291
00:16:09,902 --> 00:16:13,672
in the sense that it's not probabilistic
really, or tries to minimize

292
00:16:14,039 --> 00:16:17,643
uncertainty here,
but just for some goal directed behavior.

293
00:16:17,910 --> 00:16:20,346
We have also done this
with various other systems.

294
00:16:20,346 --> 00:16:22,781
For example, the multi. Joined

295
00:16:22,781 --> 00:16:24,416
arm that.

296
00:16:24,416 --> 00:16:27,553
Additionally has to constrain
to avoid collisions

297
00:16:27,553 --> 00:16:31,290
which are signaled by this here
sensors as you see here.

298
00:16:31,290 --> 00:16:35,127
And you can also get quite some good
behavior, very similar principle.

299
00:16:35,761 --> 00:16:38,630
And so to conclude the first part
right now,

300
00:16:38,630 --> 00:16:43,168
I hope you have understood
the active inference component. And.

301
00:16:44,937 --> 00:16:47,106
Inferences about essentially

302
00:16:47,106 --> 00:16:50,976
also suggesting implicitly
that our mind is not only about knowing

303
00:16:50,976 --> 00:16:54,813
what is going on, it also continuously
learns about the words retrospectively.

304
00:16:54,813 --> 00:16:56,582
So it's partially also in the past,

305
00:16:56,582 --> 00:17:00,452
in some sense in its activities state
and in the future.

306
00:17:00,452 --> 00:17:02,187
Considering and.

307
00:17:02,187 --> 00:17:05,157
Inferring or directed epistemic behavior.

308
00:17:05,958 --> 00:17:07,226
However,

309
00:17:08,060 --> 00:17:11,397
this is certainly good
and we can generate

310
00:17:11,663 --> 00:17:14,466
closed loop
control systems in this manner

311
00:17:14,466 --> 00:17:17,703
which are closely related to model
predictive control, for that matter.

312
00:17:18,570 --> 00:17:19,671
But in.

313
00:17:19,671 --> 00:17:23,909
Order to really become event
predictive or.

314
00:17:23,942 --> 00:17:24,343
More.

315
00:17:24,343 --> 00:17:28,514
Abstract in our scene, right, right
now, essentially you have seen a system

316
00:17:28,514 --> 00:17:33,318
that only is just writing something
or is controlling a flying trajectory.

317
00:17:33,318 --> 00:17:33,585
Right.

318
00:17:33,585 --> 00:17:38,791
It's not really able to decide
to write a whole letter.

319
00:17:38,791 --> 00:17:39,892
Right, in the sense right.

320
00:17:39,892 --> 00:17:42,795
F Strictly speaking,
so it's not able to abstract the way

321
00:17:43,162 --> 00:17:46,231
from the actual current behavior.

322
00:17:46,698 --> 00:17:49,768
So the question is how
where do this event,

323
00:17:49,768 --> 00:17:52,805
predictive structures
that I was talking about come in?

324
00:17:53,138 --> 00:17:55,040
And that leads me
to my second proposition.

325
00:17:55,040 --> 00:17:56,041
That's essentially that

326
00:17:57,042 --> 00:17:59,211
that it appears to be

327
00:17:59,812 --> 00:18:03,615
that due to evolutionary shaped
inductive processing biases,

328
00:18:04,716 --> 00:18:08,153
our brain develops
even predictive compositional structures.

329
00:18:08,620 --> 00:18:11,256
These structures
tend to model the hidden causes

330
00:18:11,623 --> 00:18:15,094
behind sensory perceptions,
if already intuitively seen it.

331
00:18:15,394 --> 00:18:19,765
I want to illustrate this further
with an actual motor behavior,

332
00:18:19,765 --> 00:18:23,602
but before I do so, let me characterize
where this

333
00:18:23,902 --> 00:18:24,870
where this proposition

334
00:18:24,870 --> 00:18:28,507
essentially comes from, right
where where does this belief, that event

335
00:18:28,774 --> 00:18:33,245
predictive structures are the right way
to go, the right way to abstract forward.

336
00:18:33,679 --> 00:18:38,250
And it comes from
from the psychological literature mainly.

337
00:18:38,250 --> 00:18:42,521
And I start with the quotation
here from Jeff Sex and Barbara

338
00:18:42,588 --> 00:18:45,190
Fescue from 2001,

339
00:18:45,691 --> 00:18:47,793
which essentially reads, okay, event

340
00:18:49,161 --> 00:18:51,663
events have been characterized
as a segment of time

341
00:18:51,663 --> 00:18:54,900
at a given location that is conceived
by an observer to have a.

342
00:18:54,900 --> 00:18:57,169
Beginning and an end and their.

343
00:18:58,137 --> 00:19:00,172
Behavior up psychological

344
00:19:00,172 --> 00:19:04,143
work essentially is suggested
that when you have people

345
00:19:04,476 --> 00:19:08,480
segment movies or other little scenes

346
00:19:08,480 --> 00:19:11,717
or cartoons, even in things like this,
they do this very systematically.

347
00:19:11,717 --> 00:19:13,352
So they have a really clear perception
when.

348
00:19:13,352 --> 00:19:16,088
An event starts and when it ends.

349
00:19:17,022 --> 00:19:19,324
And out of this,

350
00:19:19,324 --> 00:19:22,394
it's appears
that we process our environment

351
00:19:22,394 --> 00:19:26,532
in terms of we perceive our environment
in terms of these events.

352
00:19:26,798 --> 00:19:31,403
But the important is that the event is
it's not really in the environment

353
00:19:31,403 --> 00:19:33,872
per say, right? There's no labor.
This is an event.

354
00:19:34,039 --> 00:19:38,343
But our brain constructs these events
and that's what what they're.

355
00:19:38,343 --> 00:19:41,180
Baldwin lovely put into a recent

356
00:19:41,880 --> 00:19:44,216
special issue contribution so she says.

357
00:19:44,449 --> 00:19:48,420
Baldwin Cosi
should they say events the experiences

358
00:19:48,420 --> 00:19:52,257
we think we are having and recall having
had they are constructed.

359
00:19:52,257 --> 00:19:54,293
They are not what actually occurs

360
00:19:54,293 --> 00:19:57,296
because what occurs in the end
is ongoing, dynamic, marginal

361
00:19:57,296 --> 00:20:01,633
and multidimensional sensory flow,
which is somewhat transformed via

362
00:20:01,733 --> 00:20:04,803
psychological processes
into structure, describable,

363
00:20:05,370 --> 00:20:08,307
memory, evidence of experience now.

364
00:20:08,307 --> 00:20:11,310
And so essentially, right,
there is no labor of events,

365
00:20:11,310 --> 00:20:15,781
but our brain creates this abstractions
and this compact

366
00:20:16,048 --> 00:20:20,185
and encoding of the events
that we perceive. Of.

367
00:20:20,419 --> 00:20:22,254
That exists in our environment.

368
00:20:22,254 --> 00:20:24,323
But we construct them essentially.

369
00:20:24,323 --> 00:20:27,025
They are not really existing.

370
00:20:27,025 --> 00:20:29,761
On their own.

371
00:20:29,761 --> 00:20:32,998
And over last years, a lot of research

372
00:20:32,998 --> 00:20:36,235
has focused on this event
predictive cognition.

373
00:20:36,235 --> 00:20:38,003
And this research
essentially investigates

374
00:20:38,003 --> 00:20:40,906
how events and cocktails,
conceptualizations, that of

375
00:20:41,373 --> 00:20:44,309
I learned structured
and processed dynamically.

376
00:20:44,576 --> 00:20:45,677
And this research line

377
00:20:45,677 --> 00:20:49,314
essentially suggests that event
predictive in coatings and processes

378
00:20:49,781 --> 00:20:53,552
optimally mediate between sensorimotor
processes and language.

379
00:20:53,852 --> 00:20:55,921
Maybe I should have put inference
processes here.

380
00:20:56,221 --> 00:20:59,458
So this is a quote
from our recent special issue.

381
00:20:59,458 --> 00:21:05,130
So in summary, this event, predictive
cognition essentially comes from

382
00:21:06,365 --> 00:21:08,500
psychological research.

383
00:21:08,500 --> 00:21:13,238
To. Ask is work is to have sex
and to have sex continuation until today.

384
00:21:13,238 --> 00:21:16,341
Actually, there's much more recent work
from him about this.

385
00:21:16,608 --> 00:21:20,579
It's rooted partially even more deeply
in behavioral psychology.

386
00:21:20,579 --> 00:21:22,681
If you look at the common
coding theory of

387
00:21:22,681 --> 00:21:26,218
welcome trends and switch or behavior
control theory of your outcome,

388
00:21:26,251 --> 00:21:31,156
Hoffman and Bennett Thomas
work on the theory of event coding.

389
00:21:31,423 --> 00:21:34,293
If you want to learn more about this,
I'll allow me

390
00:21:34,293 --> 00:21:37,663
to point you to our recent special issue
on this topic.

391
00:21:38,063 --> 00:21:40,732
In the topics
in Cognitive Science Journal.

392
00:21:41,433 --> 00:21:45,504
With quite a variety of contributions
spanning developmental neuro

393
00:21:46,004 --> 00:21:49,908
and behavioral psychology,
also linguistics

394
00:21:51,176 --> 00:21:52,711
contributions.

395
00:21:52,711 --> 00:21:54,813
And cognitive modeling and.

396
00:21:54,813 --> 00:21:59,017
Computational contributions.

397
00:21:59,017 --> 00:22:01,586
So what are these event structures
now really about?

398
00:22:02,621 --> 00:22:05,490
It's essentially
when we think about particular event

399
00:22:05,490 --> 00:22:07,125
predictive structures, right?

400
00:22:07,125 --> 00:22:09,127
One can quickly.

401
00:22:09,127 --> 00:22:13,065
Go to the conclusion while events
must be somewhat distributed, networks

402
00:22:13,532 --> 00:22:17,536
that essentially predict
the types of entities

403
00:22:17,536 --> 00:22:21,807
that are involved in an event
like a class and the hand and an agent

404
00:22:21,807 --> 00:22:25,177
that reaches for the glass to drink,
drink out of it.

405
00:22:25,711 --> 00:22:29,748
The relative spatial relations
between the hand and object, for example,

406
00:22:30,048 --> 00:22:33,785
and the interaction dynamics such as
the hand would be moving to that object.

407
00:22:34,086 --> 00:22:36,321
These are event structures

408
00:22:36,321 --> 00:22:39,991
and then we have somehow this feeling of
event boundaries and event transitions.

409
00:22:39,991 --> 00:22:42,094
We know when a particular event can

410
00:22:42,494 --> 00:22:45,464
commence and when it can enter
and can begin and end.

411
00:22:45,931 --> 00:22:49,000
And so, for example,
when I grasp this cup

412
00:22:49,000 --> 00:22:52,471
here, I just can basically grasp it.

413
00:22:52,471 --> 00:22:55,941
And once I have grasp it, I can transport
it and then I can put it back down.

414
00:22:56,341 --> 00:22:58,410
And I'm. Free again.

415
00:22:58,410 --> 00:23:02,381
So to say,
combined with events and event boundaries

416
00:23:02,781 --> 00:23:06,952
I create, I can create mentally
event schemas which have previously

417
00:23:07,252 --> 00:23:10,489
and previously shows
are called scripts and similar things.

418
00:23:10,489 --> 00:23:14,493
And I think these scripts and develop
naturally out of this event predictive

419
00:23:14,826 --> 00:23:17,562
coding principle
and this event predictive coding

420
00:23:17,562 --> 00:23:22,134
principle, we essentially have now a much
more clearer idea, I think, of what

421
00:23:22,601 --> 00:23:26,104
these scripts and schematics
have often been characterized before.

422
00:23:26,338 --> 00:23:27,539
Actually are.

423
00:23:27,539 --> 00:23:31,042
And of course, once we have schemata,
we can embed them again and other events

424
00:23:31,376 --> 00:23:33,512
forming hierarchies out of that.

425
00:23:33,512 --> 00:23:37,749
So to get back to this illustration
of writing a letter,

426
00:23:38,016 --> 00:23:41,520
we can now say essentially, well,
we our mind is

427
00:23:41,520 --> 00:23:45,390
not really in a continuous past
consideration,

428
00:23:45,390 --> 00:23:50,762
but it considers past events essentially
or the unfolding of past events.

429
00:23:50,762 --> 00:23:51,263
And notice

430
00:23:51,263 --> 00:23:55,233
that these do not need to be partitioned
as Chris visits illustrated here.

431
00:23:55,233 --> 00:23:58,570
And we have certainly events
unfolding in parallel.

432
00:23:58,570 --> 00:24:00,705
For example,
if you think about the letter

433
00:24:00,705 --> 00:24:01,606
writing here

434
00:24:01,606 --> 00:24:06,211
at your writing, for example,
the second word here is a scholar or so,

435
00:24:06,211 --> 00:24:10,248
but you also have the full writing
this letter event

436
00:24:10,282 --> 00:24:13,852
in your head, this event of having
sit down at the table

437
00:24:13,852 --> 00:24:15,120
and being ready to write this letter.

438
00:24:15,120 --> 00:24:18,690
So there multiple event aspects,
of course, that consider

439
00:24:18,690 --> 00:24:23,028
particular subcomponents of the lecture
through environment out there.

440
00:24:24,229 --> 00:24:26,097
And so again, we know what's going on.

441
00:24:26,097 --> 00:24:28,767
We can retrospectively.

442
00:24:28,767 --> 00:24:29,701
Improve.

443
00:24:29,701 --> 00:24:32,671
Our individual writing skills
for writing particular words,

444
00:24:32,671 --> 00:24:34,473
for writing in general,
but also our excuse

445
00:24:34,473 --> 00:24:38,176
of writing a whole letter
and improving this, for example.

446
00:24:38,543 --> 00:24:41,213
And then we can again pursue the events

447
00:24:41,213 --> 00:24:44,950
of finalizing this letter,
posting it later on and so forth.

448
00:24:44,950 --> 00:24:48,520
So we have a full sequence in mind
that actually.

449
00:24:49,287 --> 00:24:49,955
Then.

450
00:24:49,955 --> 00:24:53,925
Includes the concludes,
the full letter writing episode

451
00:24:54,459 --> 00:24:57,796
that is not only in the letter
but also putting a stamp on the

452
00:24:57,796 --> 00:24:59,598
envelope,
putting the letter in the envelope,

453
00:24:59,598 --> 00:25:02,200
putting it to the post office
and so forth.

454
00:25:02,200 --> 00:25:04,402
So all this is included

455
00:25:05,937 --> 00:25:06,671
for the fun of it.

456
00:25:06,671 --> 00:25:09,741
I included this lovely video
project here.

457
00:25:10,642 --> 00:25:12,511
So here we see an event of a.

458
00:25:13,478 --> 00:25:13,979
Of a.

459
00:25:13,979 --> 00:25:18,383
Billiard ball or pool table
starting situation and somebody.

460
00:25:18,383 --> 00:25:20,185
Is shooting the white boy.

461
00:25:20,185 --> 00:25:21,319
And, and so.

462
00:25:21,319 --> 00:25:24,222
We have a nice sit and we look,
oh, some balls hit the ball.

463
00:25:24,222 --> 00:25:24,923
It's a hole.

464
00:25:24,923 --> 00:25:26,324
No, no, they don't actually.

465
00:25:26,324 --> 00:25:30,495
Low and behold, they come back together
to the starting position.

466
00:25:30,829 --> 00:25:34,799
So I hope
the video was a nice illustration of you

467
00:25:35,066 --> 00:25:38,737
definitely having expected something
totally different, although not

468
00:25:38,737 --> 00:25:42,073
something very concrete,
but at least the final state of the event

469
00:25:42,073 --> 00:25:46,111
that the balls will be distributed around
the table in some form or the other.

470
00:25:46,378 --> 00:25:51,016
Certainly they will not ever come back
to the starting position like this.

471
00:25:51,016 --> 00:25:53,285
And that's why hopefully. Some of you.

472
00:25:53,285 --> 00:25:55,587
Were at least
a little smiling to themselves.

473
00:25:55,587 --> 00:25:57,822
Yeah, that it's
kind of a cool illustration now.

474
00:25:57,856 --> 00:25:59,124
That my brain.

475
00:25:59,124 --> 00:26:03,161
Has this events in mind
and it essentially steps, jumps

476
00:26:03,161 --> 00:26:04,062
ahead, right

477
00:26:04,062 --> 00:26:09,000
when the starting of an event unfolds,
it kind of knows what the final situation

478
00:26:09,000 --> 00:26:13,538
is most likely going to be,
even if it's not fully concrete.

479
00:26:13,538 --> 00:26:17,342
But it still has some in the pie
situation deployed by a situation,

480
00:26:17,342 --> 00:26:20,679
a distributional sense to it.

481
00:26:20,845 --> 00:26:23,248
So it's also really interesting

482
00:26:23,248 --> 00:26:28,053
and we have low and behold actually
formalized this event predictive active

483
00:26:28,053 --> 00:26:32,624
inference now and an event effective
inference model where.

484
00:26:32,624 --> 00:26:34,893
The modeled.

485
00:26:34,893 --> 00:26:36,962
Reaching behavior and visual.

486
00:26:36,962 --> 00:26:41,199
Eye. Fixation behavior in infants
actually together.

487
00:26:41,199 --> 00:26:41,800
With.

488
00:26:41,833 --> 00:26:45,203
Colleagues from from Potsdam University
from the development developmental

489
00:26:45,270 --> 00:26:46,771
psychology side.

490
00:26:46,771 --> 00:26:48,807
So now we essentially have the same.

491
00:26:50,108 --> 00:26:50,942
Same.

492
00:26:50,942 --> 00:26:54,446
Equation again as before,
but it's only conditioned now.

493
00:26:54,512 --> 00:26:56,581
On. Events here as you see.

494
00:26:56,848 --> 00:26:58,049
So the whole equation.

495
00:26:58,049 --> 00:27:02,821
Is. Conditioned on in which events
we believe to be currently in.

496
00:27:02,821 --> 00:27:06,091
So the latent hidden state,
this model we had before is now

497
00:27:06,091 --> 00:27:09,427
an event model. And

498
00:27:09,427 --> 00:27:13,231
and so and we put the
M basically as the in turn in motivation.

499
00:27:13,231 --> 00:27:17,402
So the desired observations
given motivations are compared

500
00:27:17,402 --> 00:27:20,572
with the expected observations pursuing

501
00:27:20,572 --> 00:27:24,242
a particular policy under condition
that we are in the particular.

502
00:27:24,242 --> 00:27:30,215
Event and and the particular event series
unfolds while.

503
00:27:30,215 --> 00:27:33,385
Interacting with environment
to illustrate this further

504
00:27:33,985 --> 00:27:37,789
because actually, yes, has done this work

505
00:27:37,789 --> 00:27:40,892
and so provided
this following illustration here when.

506
00:27:40,892 --> 00:27:41,860
We have.

507
00:27:41,860 --> 00:27:45,597
Now as the behavior policy here,
for example, the case position

508
00:27:46,431 --> 00:27:48,867
of saying to an infant

509
00:27:48,867 --> 00:27:52,137
and so we might start somewhat
explain this equation

510
00:27:52,137 --> 00:27:55,340
a little bit further by the situation
that, okay, the infant

511
00:27:55,607 --> 00:27:59,377
say it's he
or she really likes teddy bears.

512
00:27:59,377 --> 00:28:00,345
So basically

513
00:28:00,345 --> 00:28:04,149
it's really it's internal motivation
is to look at teddy bear teddy bears.

514
00:28:04,149 --> 00:28:05,517
And and.

515
00:28:05,517 --> 00:28:07,485
It really perceives
a lot of pleasure out of that.

516
00:28:07,485 --> 00:28:09,721
So it really likes
to look at teddy bears.

517
00:28:10,188 --> 00:28:14,926
And so its observation is the desire
to see a teddy bear like objects.

518
00:28:15,960 --> 00:28:18,329
And thus

519
00:28:18,329 --> 00:28:20,598
by. Pursuing a policy

520
00:28:20,598 --> 00:28:24,135
that minimizes divergence
from seeing teddy bears.

521
00:28:24,502 --> 00:28:27,439
So essentially
it will fixate teddy bears.

522
00:28:27,972 --> 00:28:29,607
But now when.

523
00:28:29,607 --> 00:28:34,112
We now see that suddenly
this ball here is moving.

524
00:28:34,713 --> 00:28:39,084
Now. There might be a surprise
in the observation because the baby

525
00:28:39,084 --> 00:28:42,887
probably has expected that
everything else will stay rather stable.

526
00:28:43,621 --> 00:28:46,925
So what is happening
is that there is a large uncertainty of

527
00:28:46,925 --> 00:28:49,994
what this polar picture is suddenly doing
and where it's roiling from.

528
00:28:49,994 --> 00:28:51,730
And this makes

529
00:28:51,963 --> 00:28:55,100
the baby, for example,
look at the ball now

530
00:28:55,100 --> 00:28:58,970
because it wants to know all its roads
and build a good predictive model.

531
00:28:58,970 --> 00:29:03,141
So it's not surprised off the ball, given
it caught its attention

532
00:29:03,141 --> 00:29:04,476
in the first place,

533
00:29:04,476 --> 00:29:07,746
of course, and sofas
seems to be somewhat relevant for itself.

534
00:29:08,246 --> 00:29:11,049
And so it actually predicts
the next ball location

535
00:29:11,149 --> 00:29:14,652
and it will also continue
then to most likely

536
00:29:15,053 --> 00:29:17,455
at least depending on the age, of course,

537
00:29:17,455 --> 00:29:20,592
little later age
probably then illustrated in this picture

538
00:29:20,592 --> 00:29:24,963
here, predict that this ball
will eventually fall to the ground

539
00:29:25,230 --> 00:29:29,234
and thus it actually will
at some point anticipate

540
00:29:29,234 --> 00:29:33,638
not only the next ball position,
but will look at the critical next

541
00:29:33,638 --> 00:29:34,973
ball position, which would be

542
00:29:34,973 --> 00:29:38,109
when does this object
then suddenly fall to the ground?

543
00:29:39,043 --> 00:29:40,478
Yeah. And so.

544
00:29:40,478 --> 00:29:44,482
We have kind of a two event prediction,
the immediate next situation.

545
00:29:44,849 --> 00:29:46,050
And the.

546
00:29:46,050 --> 00:29:51,256
Event boundary when the ball switches
from rolling into falling

547
00:29:51,689 --> 00:29:54,759
and then expecting
that it will fall somewhere on the floor

548
00:29:54,759 --> 00:29:56,194
and hopefully not in a teddy bear.

549
00:29:57,362 --> 00:29:58,696
So to

550
00:29:58,696 --> 00:30:01,099
get this really important
and lo and behold,

551
00:30:02,367 --> 00:30:04,736
the study is from from Adam Moritz

552
00:30:05,403 --> 00:30:08,373
it's Adam and big it it's now.

553
00:30:08,373 --> 00:30:11,442
Is showing that in over.

554
00:30:11,442 --> 00:30:14,445
The first year. Of.

555
00:30:14,445 --> 00:30:19,784
Our human life usually we develop
this anticipatory event predictive.

556
00:30:19,784 --> 00:30:22,620
I gaze behavior so what they did

557
00:30:22,887 --> 00:30:27,959
so essentially they showed little kids,
little videos of hands grasping

558
00:30:27,992 --> 00:30:32,096
teddy bears or little claw
like Gerber scrappers,

559
00:30:32,931 --> 00:30:35,300
grasping teddy bears

560
00:30:35,300 --> 00:30:37,602
or other simple kind of objects.

561
00:30:37,936 --> 00:30:41,606
And what you can show is that
when you track the this baby's eyes

562
00:30:41,973 --> 00:30:45,643
for six months of age, they don't show
any anticipatory gaze behavior.

563
00:30:45,643 --> 00:30:50,849
So they they track the object, the hand
that moves to the target object at best.

564
00:30:51,049 --> 00:30:53,318
Usually
they even like a little bit behind.

565
00:30:53,318 --> 00:30:54,686
But lo and behold,

566
00:30:56,521 --> 00:30:59,490
with seven and a half months of age
about.

567
00:31:00,558 --> 00:31:03,361
The. The babies start to anticipate

568
00:31:04,662 --> 00:31:06,497
and they do so

569
00:31:06,497 --> 00:31:10,869
particularly and only
so when there is an effect, when the hand

570
00:31:10,902 --> 00:31:14,772
not only reaches for that entity,
but then also lifts it.

571
00:31:15,006 --> 00:31:18,376
So of course, after its test
trials are done there

572
00:31:18,409 --> 00:31:21,479
in this experiment, so usually in
after the first or second try.

573
00:31:22,080 --> 00:31:23,448
And the hand really.

574
00:31:23,448 --> 00:31:24,782
Shakes the object a little bit.

575
00:31:24,782 --> 00:31:26,351
Then the.

576
00:31:26,351 --> 00:31:30,421
Babies start to anticipate
and they only do so this about 11 months

577
00:31:30,421 --> 00:31:31,356
when there's no effect,

578
00:31:31,356 --> 00:31:34,225
when the hand just reaches for the object
but doesn't do anything with it.

579
00:31:34,592 --> 00:31:37,996
So then they stay on the reactive or hand
following behavior

580
00:31:38,363 --> 00:31:40,565
and only do this later on.

581
00:31:40,565 --> 00:31:41,966
On the anticipate.

582
00:31:41,966 --> 00:31:42,166
In the.

583
00:31:42,166 --> 00:31:46,004
Later age was about 11 months old
and interestingly with a claw

584
00:31:46,871 --> 00:31:50,742
they at seven and a half
they don't anticipate at all.

585
00:31:50,742 --> 00:31:54,746
So they don't see any attentiveness
or any anticipation that this crowd

586
00:31:54,746 --> 00:31:56,547
will do something with the object.

587
00:31:56,547 --> 00:31:59,651
But with 11 months of age,
they essentially show

588
00:31:59,651 --> 00:32:00,852
the similar behavior.

589
00:32:00,852 --> 00:32:03,054
Then when they watch a hand
with seven and a half months

590
00:32:03,054 --> 00:32:05,590
in, the hand lifts the object,
the claw lifts object.

591
00:32:05,790 --> 00:32:08,993
Then they also start to anticipate
to watch 11 months,

592
00:32:09,227 --> 00:32:10,461
but only once, 18 months.

593
00:32:10,461 --> 00:32:12,463
They also anticipate.

594
00:32:12,463 --> 00:32:13,331
When the clock.

595
00:32:13,331 --> 00:32:17,635
Is not lifting the object,
but just moving there and lo and behold,

596
00:32:17,635 --> 00:32:21,739
we simulated this with our event
predictive, active inference model.

597
00:32:22,073 --> 00:32:24,342
Essentially assuming.

598
00:32:24,709 --> 00:32:26,711
So to say, simulating that.

599
00:32:26,711 --> 00:32:27,512
The until.

600
00:32:27,512 --> 00:32:31,249
About six months of age
they just don't cannot interpretive

601
00:32:31,249 --> 00:32:36,087
and often hand reaching for objects
and so they just cannot make an event

602
00:32:37,322 --> 00:32:38,189
case out of it.

603
00:32:38,189 --> 00:32:39,857
And they just

604
00:32:40,291 --> 00:32:44,028
process the unexpected information that
as the hand starts moving and they trick.

605
00:32:44,028 --> 00:32:44,996
The hand.

606
00:32:46,497 --> 00:32:50,101
With 12 months of age, it's
similar to when they see a claw.

607
00:32:50,535 --> 00:32:53,671
But with 12 months of age,
when they see your hand and an object

608
00:32:53,972 --> 00:32:57,241
they imagine are probably
this hand wants to reach for the object.

609
00:32:57,542 --> 00:32:59,811
And so once the hand starts moving.

610
00:32:59,811 --> 00:33:01,713
They will and they will move.

611
00:33:01,713 --> 00:33:04,916
Their eyes to the object
to be ready to process

612
00:33:04,916 --> 00:33:07,485
what the hand is going to do
with the object.

613
00:33:08,886 --> 00:33:11,289
And in fact, the model.

614
00:33:11,289 --> 00:33:12,790
This now.

615
00:33:12,790 --> 00:33:16,327
Was. An event predictive vision
modeling approach

616
00:33:16,327 --> 00:33:19,897
essentially that essentially implements
this active inference equation

617
00:33:20,164 --> 00:33:24,235
and event predictive level
that I just showed.

618
00:33:24,235 --> 00:33:29,107
So it's it's essentially essentially
first trained to learn a realistic event,

619
00:33:29,107 --> 00:33:33,911
predictive schemata of the unfolding
dynamic, starting and ending conditions.

620
00:33:33,911 --> 00:33:35,446
And then it.

621
00:33:35,446 --> 00:33:41,252
Applies active inference of the current
best event interpretation first.

622
00:33:41,252 --> 00:33:43,087
So the trust needs to know which event.

623
00:33:43,087 --> 00:33:45,790
So if it sees the situation, it needs to
infer

624
00:33:46,124 --> 00:33:48,259
is reaching
event is most likely to unfold.

625
00:33:48,593 --> 00:33:51,496
And once it's certain
that the reaching for event unfolds

626
00:33:51,496 --> 00:33:55,967
so it knows are reaching
and with a grasping and something

627
00:33:55,967 --> 00:33:57,301
doing something with the object.

628
00:33:57,301 --> 00:34:02,206
So I will look there to minimize
my future

629
00:34:02,540 --> 00:34:06,277
expected uncertainty, minimizing
this anticipated

630
00:34:06,277 --> 00:34:10,081
uncertainty of what
the hand is going to do with the object.

631
00:34:11,015 --> 00:34:14,152
And maybe you can look at the.

632
00:34:14,152 --> 00:34:16,587
Results in detail. In the paper.

633
00:34:17,055 --> 00:34:20,391
Essentially what is happening
is that the system.

634
00:34:20,825 --> 00:34:21,392
Learns.

635
00:34:21,392 --> 00:34:26,097
To during training to
infer the correct events and then during

636
00:34:26,130 --> 00:34:29,333
testing after sufficient training phases
rather quickly,

637
00:34:29,700 --> 00:34:33,037
it starts to anticipate.

638
00:34:33,104 --> 00:34:36,074
To. When the reach starts here.

639
00:34:36,074 --> 00:34:38,042
Over time.

640
00:34:38,142 --> 00:34:41,312
It starts to anticipate
and look at the goal object

641
00:34:41,312 --> 00:34:42,980
because it has encoded.

642
00:34:42,980 --> 00:34:44,682
This is a retraining event.

643
00:34:44,682 --> 00:34:45,383
And I know.

644
00:34:45,383 --> 00:34:47,318
How the reaching event unfolds.

645
00:34:47,318 --> 00:34:49,520
And thus I look
at the end of the reaching event

646
00:34:49,787 --> 00:34:51,422
because I want to minimize.

647
00:34:51,422 --> 00:34:53,357
The the free energy.

648
00:34:53,357 --> 00:34:59,697
That I anticipate unfolding in the near
future while reaching and grasping.

649
00:34:59,864 --> 00:35:00,431
An. Object.

650
00:35:00,431 --> 00:35:02,467
Because this is the situation
that I'm currently in

651
00:35:02,867 --> 00:35:04,902
so that's what the system emergent

652
00:35:04,969 --> 00:35:08,139
so to say that's that's
what emergent called anticipatory gaze

653
00:35:08,539 --> 00:35:13,544
by this active inference or event
predictive active inference formalism.

654
00:35:14,846 --> 00:35:16,347
So okay

655
00:35:16,347 --> 00:35:20,384
we have shown that this thetan static,
latent and coatings

656
00:35:20,785 --> 00:35:24,422
that can nicely foster

657
00:35:24,422 --> 00:35:27,391
the emergence of this
anticipatory behavior.

658
00:35:27,758 --> 00:35:32,396
But can such or how can such event
predictive structures actually learned?

659
00:35:32,697 --> 00:35:34,832
This is what I want to show you next.

660
00:35:34,832 --> 00:35:37,935
But it could also have a short break,
if you like, Daniel,

661
00:35:37,935 --> 00:35:40,938
or what you say.

662
00:35:40,938 --> 00:35:44,809
So maybe ask and just double down
on a few of these cool points

663
00:35:44,809 --> 00:35:49,480
and ask a few questions and then jump
into the second part of the presentation.

664
00:35:49,480 --> 00:35:51,716
Yeah, please. Okay.

665
00:35:51,716 --> 00:35:55,386
So a few just kind of general questions.

666
00:35:55,386 --> 00:35:56,521
One was

667
00:35:56,521 --> 00:36:00,024
you brought in the neural network angle
and so that it was just

668
00:36:00,024 --> 00:36:03,060
a general question how do the analytical

669
00:36:03,461 --> 00:36:06,397
single line equation formalism

670
00:36:06,831 --> 00:36:10,801
connect to different modern machine
learning architectures?

671
00:36:10,968 --> 00:36:13,104
And what does that have to do
with the scaling

672
00:36:13,104 --> 00:36:16,841
or where
active inference could be applied?

673
00:36:16,841 --> 00:36:19,944
I think I'm going to answer this
in the second part of my talk.

674
00:36:20,111 --> 00:36:21,078
Perfect.

675
00:36:21,179 --> 00:36:21,779
Okay.

676
00:36:21,812 --> 00:36:25,216
This is going to become much
more neural networks just now.

677
00:36:25,216 --> 00:36:28,653
And I will conclude also
with a general statement about this.

678
00:36:28,653 --> 00:36:32,123
So maybe we keep this for later,
essentially.

679
00:36:32,857 --> 00:36:34,559
I mean, this was an LTM network.

680
00:36:34,559 --> 00:36:38,429
LSM networks are used for state
of the art machine learning.

681
00:36:38,429 --> 00:36:39,197
So it's not like.

682
00:36:39,197 --> 00:36:40,364
Something that.

683
00:36:40,364 --> 00:36:42,466
Is like totally trivial or so.

684
00:36:43,267 --> 00:36:44,101
Great. And

685
00:36:45,236 --> 00:36:46,537
the events

686
00:36:46,537 --> 00:36:49,707
basis is
something that I'm sure you'll return to.

687
00:36:49,707 --> 00:36:53,878
But you mentioned
how events have boundaries and schema

688
00:36:53,878 --> 00:36:59,550
or schemata and hierarchies,
and one thought was, how are these

689
00:37:00,251 --> 00:37:03,521
boundaries, schema
and hierarchies learned in humans,

690
00:37:03,888 --> 00:37:09,827
and how does that inform our design
of cognitive systems? Yes.

691
00:37:09,894 --> 00:37:12,563
Also, this is kind of what I continue
is essentially

692
00:37:14,098 --> 00:37:15,366
this is the question here, like,

693
00:37:15,366 --> 00:37:18,936
so how are these event
predictive structures learned?

694
00:37:18,936 --> 00:37:21,072
Not so much in humans.

695
00:37:21,072 --> 00:37:25,543
I will not so much focus on in the talk
now, but how can this be

696
00:37:25,543 --> 00:37:29,981
lost in artificial systems but inspired
of course, by human learning?

697
00:37:30,381 --> 00:37:34,752
Well, I'm maximally uncertain
and curious about those,

698
00:37:34,752 --> 00:37:38,956
I guess implicitly expected
and prefer that they be resolved.

699
00:37:40,524 --> 00:37:41,492
But I hope so.

700
00:37:41,492 --> 00:37:42,460
It just reminded me

701
00:37:42,460 --> 00:37:46,063
of how they're in culture, like
at the end of a movement of a symphony.

702
00:37:46,297 --> 00:37:48,466
If you clap, you didn't get it.

703
00:37:48,466 --> 00:37:51,435
Because that's not the uncultured moment
to clap.

704
00:37:51,435 --> 00:37:54,538
There's a broader event
that actually goes beyond the sound.

705
00:37:55,039 --> 00:37:58,643
And so it just made me think
about how through learning,

706
00:37:59,176 --> 00:38:01,812
we reconceptualize what events are.

707
00:38:02,113 --> 00:38:05,049
And if events truly are one of the

708
00:38:06,083 --> 00:38:09,053
a kind of atomic units of cognition,

709
00:38:09,387 --> 00:38:13,524
then that's incredibly powerful.

710
00:38:13,524 --> 00:38:15,159
I would think so, yes.

711
00:38:15,159 --> 00:38:17,061
Was this a question or comment?

712
00:38:17,061 --> 00:38:17,962
That was just a comment

713
00:38:17,962 --> 00:38:21,632
on the importance of having events
based cognitive processes

714
00:38:22,033 --> 00:38:25,736
and how it reconsiders
our own experience and suggests

715
00:38:25,736 --> 00:38:27,071
how to design other architectures.

716
00:38:27,071 --> 00:38:30,341
So maybe we can go to the second part
of the presentation.

717
00:38:30,341 --> 00:38:33,744
A fantastic part is really right
that it goes hand in hand, right?

718
00:38:33,744 --> 00:38:38,149
While these events develop, we are
we getting more and more ready to look

719
00:38:38,382 --> 00:38:43,788
and explore deeper event structures,
right, and more complex event structures.

720
00:38:43,788 --> 00:38:48,826
And of course, the real mystery is
how this events structures are learned.

721
00:38:49,493 --> 00:38:53,264
And I want to show you a couple of ideas

722
00:38:53,264 --> 00:38:57,568
that we are pursuing in our mind,
the machine learning research part.

723
00:38:57,568 --> 00:39:01,772
And then the last part of the talk,
I will link this event structure

724
00:39:01,872 --> 00:39:05,209
also to language structures
to a certain extent.

725
00:39:05,876 --> 00:39:09,113
So but allow me,
it didn't interest of time

726
00:39:09,113 --> 00:39:12,983
to go a little bit fast over this machine
learning components here because to

727
00:39:13,084 --> 00:39:16,887
I had to explain the machine
learning architectures

728
00:39:16,887 --> 00:39:20,324
in all that detail
it would take talks on on its own.

729
00:39:20,691 --> 00:39:25,996
But I just want to give you a little bit
of an idea where we are in this respect.

730
00:39:26,163 --> 00:39:29,734
But the main question that was asked,
and that's also really a really good

731
00:39:29,900 --> 00:39:33,270
question is essentially what are these?

732
00:39:34,238 --> 00:39:35,773
How can

733
00:39:35,773 --> 00:39:38,709
our brain learn this event structures?

734
00:39:39,009 --> 00:39:42,780
And there must be essentially in machine
learning

735
00:39:42,780 --> 00:39:45,850
jargon
all these inductive learning biases.

736
00:39:45,850 --> 00:39:49,754
Yeah, these inductive tendencies to learn

737
00:39:50,621 --> 00:39:52,790
this event predictive structures

738
00:39:52,790 --> 00:39:56,427
and ideally
to learn them in a very compact,

739
00:39:56,427 --> 00:39:59,797
very suitably compressed form, to

740
00:40:00,231 --> 00:40:02,933
identify the causality

741
00:40:03,601 --> 00:40:05,936
that generate

742
00:40:05,936 --> 00:40:09,607
the sensory perceptions
in the first place and allow them

743
00:40:10,141 --> 00:40:12,209
to combine

744
00:40:12,743 --> 00:40:16,313
these event structures
in a very composition,

745
00:40:16,313 --> 00:40:19,683
a very flexible manner, such
that we get ready. To.

746
00:40:20,718 --> 00:40:24,188
To apply our knowledge
also in other situations that are related

747
00:40:24,188 --> 00:40:28,159
to previous experiences,
but of course always different.

748
00:40:29,026 --> 00:40:33,330
And. And I argued before that essentially

749
00:40:34,098 --> 00:40:37,201
they must on the one hand side
be event oriented

750
00:40:37,201 --> 00:40:39,069
interpretation tendencies in general,

751
00:40:39,069 --> 00:40:42,506
as we have already seen in the quote
from the old for example also.

752
00:40:42,907 --> 00:40:45,676
So there must be
we must essentially foster

753
00:40:45,676 --> 00:40:50,281
the development of this event predictive,
stable and compact, latent states

754
00:40:50,281 --> 00:40:53,551
this what seems
what our brain seems to do.

755
00:40:54,351 --> 00:40:56,053
And it.

756
00:40:56,053 --> 00:41:00,891
Seems to develop these event states
in terms of attempting to characterize

757
00:41:00,891 --> 00:41:04,795
starting conditions, contextual
conditions and in conditions of events.

758
00:41:05,029 --> 00:41:08,566
So contextual conditions
means like when can invent unfold

759
00:41:08,566 --> 00:41:11,101
and what is happening
typically why an event unfolds.

760
00:41:11,535 --> 00:41:15,272
The starting condition means
when can this an event start out?

761
00:41:15,272 --> 00:41:18,075
So I can reach only for an object
when it's in reach.

762
00:41:18,442 --> 00:41:21,412
So for example now
and the ending condition.

763
00:41:21,612 --> 00:41:23,180
So essentially. When an event.

764
00:41:23,180 --> 00:41:26,183
And so again reaching
event ends is typically when I grasp

765
00:41:26,183 --> 00:41:30,020
an object for example
an appears that there is event

766
00:41:30,020 --> 00:41:34,291
predictive biases is inductive
bias has to segment

767
00:41:34,692 --> 00:41:37,795
our stream of information
into this events

768
00:41:38,062 --> 00:41:41,632
and two very important
ones are probably signals of surprise

769
00:41:41,632 --> 00:41:42,900
because usually when I don't

770
00:41:42,900 --> 00:41:46,537
have a good event or when I don't know
exactly how an event unfolds,

771
00:41:47,137 --> 00:41:49,540
I get to really first
better to, for example,

772
00:41:49,540 --> 00:41:52,643
extend my hands, reach for things
and so forth, but then may touch them.

773
00:41:52,977 --> 00:41:56,881
I fail to grasp and properly and
they fall down and this is surprising.

774
00:41:56,881 --> 00:41:58,682
And then I get.

775
00:41:58,682 --> 00:42:01,552
Surprise signals which over time

776
00:42:02,186 --> 00:42:05,289
become non surprising any more
because I know that

777
00:42:05,289 --> 00:42:08,292
when I reach for the object
then to begin to grasp and forward

778
00:42:08,292 --> 00:42:09,894
and then prepare
for the grasp, and then. I

779
00:42:11,128 --> 00:42:11,595
manage.

780
00:42:11,595 --> 00:42:13,831
The whole sequence without the surprises.

781
00:42:14,665 --> 00:42:17,935
And the other one
is this latent signals of stability

782
00:42:18,335 --> 00:42:20,905
because
and this also relates to causality.

783
00:42:21,205 --> 00:42:25,342
In a sense,
because our I mean, our environment of a.

784
00:42:25,342 --> 00:42:30,014
World is a three dimensional space time
continuum, essentially.

785
00:42:30,281 --> 00:42:34,818
And forces
or causal interactions can only unfold

786
00:42:35,252 --> 00:42:39,123
when two entities
can exchange these forces.

787
00:42:39,290 --> 00:42:40,257
And this is typically,

788
00:42:40,257 --> 00:42:43,994
in the physical world, only possible
when they come in contact with each other

789
00:42:44,595 --> 00:42:45,362
via Zoom.

790
00:42:45,362 --> 00:42:48,232
And we we can exchange information
over this long range.

791
00:42:49,466 --> 00:42:54,171
Long range means, but also in the sense
we are in contact right now.

792
00:42:54,171 --> 00:42:55,372
Right by.

793
00:42:55,372 --> 00:43:00,044
This tool, by this digital device,
essentially, and the Internet.

794
00:43:00,344 --> 00:43:00,945
That.

795
00:43:01,045 --> 00:43:03,781
Enables us to. Now.

796
00:43:03,781 --> 00:43:05,249
Establish virtual rooms.

797
00:43:05,249 --> 00:43:08,252
That's why a zoom room, for example,
is also called a Zoom room.

798
00:43:08,252 --> 00:43:12,189
Yeah, because it's a virtual room
where we are together, not physically,

799
00:43:12,189 --> 00:43:13,824
but information wise.

800
00:43:13,824 --> 00:43:17,461
We can exchange information
and thoughts and ideas and so forth.

801
00:43:17,461 --> 00:43:21,665
And that's essentially very similar
to being in the real room that typically

802
00:43:22,032 --> 00:43:24,501
similar things. Are. Mainly unfolding.

803
00:43:25,302 --> 00:43:30,207
And so this is the event predictive
biases that make us structure our.

804
00:43:30,674 --> 00:43:32,409
Environment and our our.

805
00:43:32,409 --> 00:43:35,546
Thoughts and our general
predictive models in this event,

806
00:43:36,113 --> 00:43:38,048
composition and manner,
and the other one is,

807
00:43:38,048 --> 00:43:44,021
of course, the importance of curiosity
in homeostasis to make sure that we on

808
00:43:44,021 --> 00:43:48,726
the one hand side, essentially, I mean,
our brain has does not have the capacity.

809
00:43:48,892 --> 00:43:51,762
Our brain has some phenomenal capacity
for sure, but certainly doesn't

810
00:43:51,762 --> 00:43:54,999
have the capacity to learn everything
in all its detail about it.

811
00:43:55,265 --> 00:43:57,768
Yeah. I mean it's totally impossible.

812
00:43:57,768 --> 00:44:01,739
I mean, otherwise we would need
to learn down to quantum mechanics how.

813
00:44:01,739 --> 00:44:03,741
Everything unfolds the whole time. Right?

814
00:44:03,974 --> 00:44:07,344
So this is.
This. Is absolute impractical.

815
00:44:07,344 --> 00:44:10,714
So of course, we need to develop models

816
00:44:11,215 --> 00:44:16,320
that we believe, so to say,
are best suited for our needs right?

817
00:44:16,320 --> 00:44:18,489
So while we build.

818
00:44:18,489 --> 00:44:20,858
Our models
and why we pursue active inference,

819
00:44:21,258 --> 00:44:23,761
as you're already seen in the active
inference equation, right, there

820
00:44:23,761 --> 00:44:28,532
is this important component
that essentially tries to minimize

821
00:44:28,532 --> 00:44:32,803
the divergence between desired
perceptions and actual perceptions.

822
00:44:32,803 --> 00:44:33,003
Right.

823
00:44:33,003 --> 00:44:36,840
And this is essentially maintaining
internal homeostasis of Friston

824
00:44:36,840 --> 00:44:40,210
would argue
also that it's this perception, right?

825
00:44:40,544 --> 00:44:42,813
It's not necessarily
only about the outside environment,

826
00:44:42,813 --> 00:44:44,915
but it's also the perception
of your own body. Right.

827
00:44:44,915 --> 00:44:47,618
So if you desperately hungry

828
00:44:48,585 --> 00:44:49,753
or starving or whatever.

829
00:44:49,753 --> 00:44:53,557
Right, then of course you do everything
to prevent this from happening.

830
00:44:55,225 --> 00:44:58,462
Hopefully it doesn't get to this.

831
00:44:58,962 --> 00:45:01,298
And and curiosity

832
00:45:01,565 --> 00:45:05,135
meanwhile, of course, drives
our curious minds.

833
00:45:05,135 --> 00:45:07,104
Our knowledge gain experience.

834
00:45:07,104 --> 00:45:10,174
But also this knowledge
gained experience is partially embodied.

835
00:45:10,174 --> 00:45:11,842
So also our sensory system

836
00:45:11,842 --> 00:45:14,511
kind of signals to us
what is probably interesting for us.

837
00:45:14,912 --> 00:45:18,348
And it's going hand in hand
with the homeostasis component.

838
00:45:18,749 --> 00:45:22,720
We build models mainly about the stuff
that really interests us

839
00:45:22,720 --> 00:45:27,658
and that we believe is important to us
in our which cultural social world.

840
00:45:27,658 --> 00:45:30,861
Of course, this can be very awkward,
very cool,

841
00:45:30,861 --> 00:45:33,363
artistic things and so forth,
but nonetheless, right.

842
00:45:34,164 --> 00:45:37,067
It is still in the human run important.

843
00:45:38,001 --> 00:45:40,871
But when we do
and we try to implement this now. In.

844
00:45:41,105 --> 00:45:43,774
Artificial neural network structures.

845
00:45:43,774 --> 00:45:44,975
I want to. Show you a couple of

846
00:45:46,009 --> 00:45:48,712
brief glimpses, at least at

847
00:45:48,812 --> 00:45:52,750
what we have done in my group
over the last couple of years.

848
00:45:52,750 --> 00:45:54,418
The first that I want to show

849
00:45:54,418 --> 00:45:58,188
you is a derivative of this rocket
ball system where we now.

850
00:45:58,188 --> 00:45:58,856
Have.

851
00:45:58,856 --> 00:45:59,857
Again, similar

852
00:45:59,857 --> 00:46:03,427
continue a network structure,
but we have to enhance the system now,

853
00:46:03,961 --> 00:46:06,964
not only processing sensory
and motor information

854
00:46:06,964 --> 00:46:10,501
predicting sensory consequences
as in the rocket ball thing.

855
00:46:10,501 --> 00:46:11,602
And that mighty.

856
00:46:11,602 --> 00:46:15,405
Joint arm that you saw before,
but also. We.

857
00:46:15,405 --> 00:46:18,509
Allow it
to give a contextual input stage,

858
00:46:18,509 --> 00:46:22,880
which is essentially like an event stage
that develops.

859
00:46:24,481 --> 00:46:26,283
The. Ability to distinguish

860
00:46:26,283 --> 00:46:30,287
between different vehicles
that the system is currently controlling.

861
00:46:30,487 --> 00:46:34,958
Notice recall that the system
as a sensory input get gets x, y

862
00:46:35,192 --> 00:46:39,296
positions of the vehicle and motor.

863
00:46:39,429 --> 00:46:40,430
Commands are.

864
00:46:40,430 --> 00:46:43,233
These two or four thrust motors.

865
00:46:44,401 --> 00:46:44,902
So it

866
00:46:44,902 --> 00:46:48,071
doesn't see which vehicle it's
currently controlling.

867
00:46:48,071 --> 00:46:50,474
It only sees its position.

868
00:46:50,474 --> 00:46:53,777
And so in order to distinguish
the different vehicles, it

869
00:46:53,777 --> 00:46:57,815
either needs to enhance its latent
state is in the long, short term memory

870
00:46:57,815 --> 00:47:03,320
structure of the Cartoon Network
structure, or it needs to contextualize

871
00:47:03,687 --> 00:47:07,357
a latent latent inductive bias
essentially here.

872
00:47:07,658 --> 00:47:11,061
And by training this,
lo and behold, can do this.

873
00:47:11,428 --> 00:47:14,064
Now, this is a trained. Model and it can.

874
00:47:14,298 --> 00:47:16,867
Learn to control this for three vehicles

875
00:47:17,801 --> 00:47:20,838
that have different inertia
and gravity properties. And

876
00:47:21,939 --> 00:47:22,940
and also.

877
00:47:22,940 --> 00:47:28,111
Thrust different thrust motors than does
so thus this now essentially.

878
00:47:28,111 --> 00:47:29,112
Buy on the.

879
00:47:29,112 --> 00:47:32,883
One hand side continuously doing this
active inference with a line

880
00:47:32,883 --> 00:47:38,021
that you see again the thought projecting
where it will be in the future,

881
00:47:38,455 --> 00:47:42,659
but also it retrospectively
continuously adapts its internal event

882
00:47:42,659 --> 00:47:45,495
estimate of which vehicle it's
currently controlling

883
00:47:45,495 --> 00:47:47,664
or not really of which vehicle
is currently controlling.

884
00:47:47,664 --> 00:47:50,067
What's rather
what's the best contextual state.

885
00:47:50,067 --> 00:47:51,468
That allows.

886
00:47:51,468 --> 00:47:55,606
Me to predict the current sensorimotor
dynamics in the best way.

887
00:47:56,640 --> 00:47:58,709
And it does this rather well.

888
00:47:58,709 --> 00:48:01,411
Lo and behold,
if you plot the internal state,

889
00:48:01,411 --> 00:48:05,449
this contextual state, that emerges
that's not trained or in a sense

890
00:48:05,449 --> 00:48:10,153
like super traits are not trained in
a supervised way, but it's trained via.

891
00:48:10,854 --> 00:48:11,521
An active.

892
00:48:11,521 --> 00:48:13,957
Inference process, essentially.

893
00:48:13,957 --> 00:48:18,996
So it emerges like a distinction
between the three different vehicles

894
00:48:19,329 --> 00:48:24,368
by just simply optimizing
this forward model of the dynamics

895
00:48:24,668 --> 00:48:26,737
of the different mix
of the three vehicles

896
00:48:27,004 --> 00:48:30,908
and having the inductive bias
that's important here too, to succeed

897
00:48:31,241 --> 00:48:34,945
essentially that the vehicles
do not switch all the time,

898
00:48:34,945 --> 00:48:38,282
but they are stable for a while,
like about 50 steps or something.

899
00:48:38,282 --> 00:48:40,384
And then they randomly switch
at a certain point in.

900
00:48:40,384 --> 00:48:42,419
Time and and.

901
00:48:42,419 --> 00:48:45,555
The inductive phases
that this contextual vector that's hidden

902
00:48:45,555 --> 00:48:49,493
here, essentially there's a stable vector
that only adapts itself

903
00:48:49,826 --> 00:48:54,965
much slower than the internal dynamics
of the actual recurrent neural network.

904
00:48:54,965 --> 00:48:59,403
And then during training
such these structures typically merge

905
00:48:59,436 --> 00:49:04,441
distinguishing the three vehicles
and you can even train this to transport

906
00:49:04,441 --> 00:49:08,979
objects then that somewhat polarizations
are possible are necessary to do so.

907
00:49:09,246 --> 00:49:12,049
But admittedly,

908
00:49:12,049 --> 00:49:15,886
these these structures do emerge,
but not very robustly.

909
00:49:15,886 --> 00:49:20,991
And the structure of this latent state
is still typically rather fuzzy.

910
00:49:21,258 --> 00:49:24,928
So over the last two years,
we essentially have produced

911
00:49:24,928 --> 00:49:27,664
a couple of other neural networks
that really try. To.

912
00:49:28,031 --> 00:49:32,936
Work on this compression and the suitable
compression of this latent states.

913
00:49:33,203 --> 00:49:33,937
Further,

914
00:49:35,038 --> 00:49:35,973
we have

915
00:49:35,973 --> 00:49:41,178
done this with various gating networks
originally first to providing

916
00:49:41,178 --> 00:49:44,548
surprise signals or essentially surprise
when the switch occurs

917
00:49:44,548 --> 00:49:48,018
and we just give it a switch
occurrence signal.

918
00:49:48,285 --> 00:49:52,923
That was last year, essentially
where we develop nice latent codes

919
00:49:52,923 --> 00:49:56,893
for predicting some abstract functions,
for example, in distinguishing

920
00:49:56,893 --> 00:50:00,097
between them, even seeing
some similarities between them.

921
00:50:00,998 --> 00:50:02,799
But then.

922
00:50:02,799 --> 00:50:04,201
This here.

923
00:50:04,368 --> 00:50:06,003
At the Cox.

924
00:50:06,003 --> 00:50:07,838
II meeting, we. Have.

925
00:50:07,838 --> 00:50:08,905
Done this again.

926
00:50:08,905 --> 00:50:12,442
So we see
we have this event anticipation module.

927
00:50:12,442 --> 00:50:13,643
This is a

928
00:50:14,411 --> 00:50:16,713
still rather simple neural network.

929
00:50:16,713 --> 00:50:20,751
Then we have an event switching module
that's a gated recurrent unit

930
00:50:21,051 --> 00:50:25,655
network here that allows the next
anticipation of the next event code

931
00:50:25,655 --> 00:50:28,959
or the passing of the next event code
into the lower level

932
00:50:28,959 --> 00:50:32,763
event processing structure
that is actually processing the sensory

933
00:50:32,763 --> 00:50:36,900
information only at certain points
in time when this event boundary

934
00:50:36,900 --> 00:50:41,038
anticipation network actually
activates a switch and this event bound

935
00:50:41,071 --> 00:50:44,875
anticipation network learns
to activate the switch by a particular,

936
00:50:45,909 --> 00:50:48,979
suitably
designed inductive learning biases.

937
00:50:48,979 --> 00:50:52,682
So the first inductive based essentially
design of the model that you develop

938
00:50:52,682 --> 00:50:55,385
essentially an event processing module.

939
00:50:55,685 --> 00:50:56,720
That is.

940
00:50:56,720 --> 00:51:00,524
Contextualized by the belief of which
what's the current most suitable

941
00:51:00,524 --> 00:51:02,659
event code?
So what's the event that's unfolding?

942
00:51:02,959 --> 00:51:06,696
And then event bound anticipation module
that essentially switches between events

943
00:51:07,164 --> 00:51:10,801
just in time and lo and behold,
this system actually Jerry does learn

944
00:51:11,134 --> 00:51:14,271
to switch when the information is there
that it can know

945
00:51:14,304 --> 00:51:17,340
when the event switches.

946
00:51:17,541 --> 00:51:20,043
That it learns an optimal model.

947
00:51:20,043 --> 00:51:22,112
About the switches.

948
00:51:22,112 --> 00:51:25,682
And if you have, for example,
in this case we use like well not encoded

949
00:51:25,682 --> 00:51:31,555
symbolic sequences and different sequence
processing out of matter basically.

950
00:51:31,822 --> 00:51:32,889
Then the.

951
00:51:32,889 --> 00:51:37,327
System developed distinct event codes
for the three types. Of.

952
00:51:38,161 --> 00:51:39,463
Dynamics, for example.

953
00:51:39,463 --> 00:51:42,099
And interestingly, because you see.

954
00:51:42,099 --> 00:51:47,337
Two P, one to the event,
one to program, one essentially to.

955
00:51:47,337 --> 00:51:51,374
Switch and b b to switches
between B and C and three.

956
00:51:51,575 --> 00:51:54,344
The problem is three switches
between APC.

957
00:51:54,578 --> 00:51:56,079
V. APC V.

958
00:51:56,079 --> 00:51:57,514
So it's a kind of a combination.

959
00:51:57,514 --> 00:51:59,916
Of problem one and. Problem two.

960
00:51:59,916 --> 00:52:03,587
And so lo
and behold, the P three code essentially

961
00:52:03,787 --> 00:52:08,458
is between the P one code
and the P two code in all the cases,

962
00:52:08,725 --> 00:52:10,093
although of course, two different

963
00:52:10,093 --> 00:52:12,929
initialization
of the three different networks, they

964
00:52:13,830 --> 00:52:15,932
of course develop different latent codes.

965
00:52:16,500 --> 00:52:18,702
But they still kind of

966
00:52:20,003 --> 00:52:22,572
and. Imply

967
00:52:22,606 --> 00:52:27,410
the underlying structure of the events
and the similarity between events.

968
00:52:28,512 --> 00:52:31,648
But maybe the most advanced network

969
00:52:31,648 --> 00:52:34,050
is the one here again from Chris

970
00:52:35,085 --> 00:52:37,954
together
trying to work with scale matches here.

971
00:52:38,355 --> 00:52:41,791
This paper now that essentially
also has a very similar structure,

972
00:52:41,791 --> 00:52:43,693
you have a hidden latent state

973
00:52:43,693 --> 00:52:47,063
that's in the previous previous code
that's essentially.

974
00:52:47,063 --> 00:52:50,534
In. This network that's it's this code

975
00:52:50,534 --> 00:52:52,802
that is passed down through here

976
00:52:53,637 --> 00:52:57,641
and this hidden latent code
is maintained over time

977
00:52:58,008 --> 00:53:01,011
and is just controlled
or can be adjusted by a gate.

978
00:53:01,278 --> 00:53:04,047
It's a much bigger cascade
that opens only very selectively.

979
00:53:04,047 --> 00:53:07,217
And this gate. Is.

980
00:53:07,250 --> 00:53:09,853
Is designed
such that there is a lost function.

981
00:53:10,220 --> 00:53:11,221
That.

982
00:53:11,755 --> 00:53:13,690
Punishes gate openings.

983
00:53:13,690 --> 00:53:17,160
So the system really doesn't
really want to open its gate.

984
00:53:17,160 --> 00:53:19,729
But if it's really helpful. To.

985
00:53:20,697 --> 00:53:23,567
Lower the prediction error on the side,
it does.

986
00:53:23,567 --> 00:53:27,404
So it's also open the gate
and thus changes context

987
00:53:27,737 --> 00:53:31,441
with this obvious recommendation system
or this event.

988
00:53:31,541 --> 00:53:33,176
Coding system

989
00:53:33,376 --> 00:53:35,011
that has the.

990
00:53:35,011 --> 00:53:38,715
Next event code ready to switch to it
just in.

991
00:53:38,715 --> 00:53:41,418
Time, and then combines this

992
00:53:41,751 --> 00:53:44,588
to predict the next consequences.

993
00:53:44,821 --> 00:53:48,124
So again, sense, remote event,
predictive model essentially.

994
00:53:48,625 --> 00:53:49,726
And this.

995
00:53:49,726 --> 00:53:52,829
System is now quite ready to

996
00:53:53,396 --> 00:53:58,802
to process state of the art
challenges here not only toy problems

997
00:53:58,802 --> 00:54:02,639
as in the admittedly in the last
and the two other systems.

998
00:54:02,639 --> 00:54:04,941
So for example
there's a billiard ball scenario

999
00:54:04,941 --> 00:54:08,245
which is a kind of a benchmark machine
learning community.

1000
00:54:08,645 --> 00:54:09,679
Where.

1001
00:54:09,813 --> 00:54:14,784
Our system with suitable parameterization
decreases.

1002
00:54:15,118 --> 00:54:17,320
The mean squared error much.

1003
00:54:17,320 --> 00:54:21,291
More than standard Alice tem accrual
or standard recurrent neural networks.

1004
00:54:21,591 --> 00:54:24,794
And particularly
when you have a testing scenario.

1005
00:54:25,195 --> 00:54:25,962
That.

1006
00:54:25,962 --> 00:54:29,065
Differs
a little bit from the training scene.

1007
00:54:29,299 --> 00:54:32,469
And what's even more important maybe
or more interesting in this scenario

1008
00:54:32,469 --> 00:54:37,374
is that the matching to this illustration
here, you see essentially.

1009
00:54:37,741 --> 00:54:38,775
That the.

1010
00:54:38,775 --> 00:54:44,281
Length and state of the
our system called gate lord.

1011
00:54:44,281 --> 00:54:44,914
Essentially,

1012
00:54:46,349 --> 00:54:47,183
you can really

1013
00:54:47,183 --> 00:54:51,421
see that there is a particular dynamic
unfolding right now.

1014
00:54:51,421 --> 00:54:52,822
So first. Of all.

1015
00:54:52,822 --> 00:54:57,060
Those in a certain direction, after
the first interaction with the boundary,

1016
00:54:57,761 --> 00:55:01,331
the legend stage perfectly switches
to one stable new state.

1017
00:55:01,631 --> 00:55:06,236
And then this second bounce and again
it switches to a new state.

1018
00:55:06,670 --> 00:55:08,305
So that's.

1019
00:55:08,305 --> 00:55:09,072
Very powerful.

1020
00:55:09,072 --> 00:55:12,242
A little bit hand-waving due to time
can explain

1021
00:55:13,143 --> 00:55:15,812
all of the all of the components here.

1022
00:55:16,046 --> 00:55:19,582
But do you see a really nice
generalization behavior?

1023
00:55:19,582 --> 00:55:23,119
For example, when you train
only this fetch and pick and place.

1024
00:55:23,486 --> 00:55:25,255
Task in.

1025
00:55:25,255 --> 00:55:28,692
In situations
where the group object contact

1026
00:55:28,692 --> 00:55:30,960
always occurs at time point five.

1027
00:55:32,862 --> 00:55:34,230
And. In generalization,

1028
00:55:34,230 --> 00:55:37,467
the contact also occurs at other time
points.

1029
00:55:38,301 --> 00:55:40,637
Immediately,
the ALICE term and crew networks

1030
00:55:42,238 --> 00:55:44,574
get much worse
in their predictive accuracy.

1031
00:55:44,974 --> 00:55:48,978
Okay, so it's to generalize this
to this other scenarios

1032
00:55:49,379 --> 00:55:50,280
and there are a couple of.

1033
00:55:50,280 --> 00:55:51,548
Other also.

1034
00:55:51,548 --> 00:55:54,751
Combinations with reinforcement
learning systems.

1035
00:55:54,751 --> 00:55:59,923
So actually we took our
the question took that gate lot module

1036
00:55:59,923 --> 00:56:03,259
essentially this model learning module
and combined it

1037
00:56:03,259 --> 00:56:06,062
with state of the art reinforcement
learning systems.

1038
00:56:06,529 --> 00:56:10,433
And as a result
we could beat, learn faster,

1039
00:56:10,433 --> 00:56:13,937
be more simple, efficient essentially
and be partially more accurate.

1040
00:56:14,371 --> 00:56:17,374
Than the. State of the art reinforcement.

1041
00:56:17,374 --> 00:56:20,510
Learn us in the couple of this
many great world tasks.

1042
00:56:20,510 --> 00:56:22,011
For example.

1043
00:56:22,011 --> 00:56:24,280
So really important. To.

1044
00:56:24,280 --> 00:56:27,650
Induce the right inductive
learning biases.

1045
00:56:28,051 --> 00:56:29,853
These essentially improve

1046
00:56:30,787 --> 00:56:33,123
the late and state codes that

1047
00:56:33,423 --> 00:56:37,060
much more systematically seem to develop.

1048
00:56:37,894 --> 00:56:38,495
Really.

1049
00:56:38,661 --> 00:56:43,767
Kind of in explaining called like
explaining the causality in in

1050
00:56:44,367 --> 00:56:48,037
with a latent code about what's
really going on in the environment,

1051
00:56:48,671 --> 00:56:51,541
such as where
the sheep, for example, is or.

1052
00:56:51,908 --> 00:56:53,476
Where the call.

1053
00:56:53,476 --> 00:56:55,678
Position will be if, if the system

1054
00:56:56,346 --> 00:56:59,649
remembers where the key is on one side
and so forth.

1055
00:56:59,649 --> 00:57:03,052
So particularly a very suited
also for partially observable

1056
00:57:03,353 --> 00:57:06,055
Markov decision process problems.

1057
00:57:06,055 --> 00:57:08,358
So where you need to maintain longer
term.

1058
00:57:08,591 --> 00:57:09,626
Memory.

1059
00:57:09,626 --> 00:57:15,632
Of particular events
happened in particular environments.

1060
00:57:15,632 --> 00:57:18,868
Okay, so that's a second part

1061
00:57:18,868 --> 00:57:22,639
of the neural networks.

1062
00:57:22,639 --> 00:57:25,742
And if you still have
a couple of minutes. I.

1063
00:57:26,209 --> 00:57:27,944
Try to

1064
00:57:28,845 --> 00:57:32,415
put you through the last component
into that.

1065
00:57:32,415 --> 00:57:34,651
I wanted to show you. That. Event.

1066
00:57:34,651 --> 00:57:40,723
This event, predictive structures
can be very closely related to language.

1067
00:57:41,090 --> 00:57:42,058
And that.

1068
00:57:42,058 --> 00:57:44,928
I find most exciting because this might.

1069
00:57:44,928 --> 00:57:46,663
And in fact I'm really.

1070
00:57:46,663 --> 00:57:51,301
Close to language gap and really clear
around language in our sensorimotor

1071
00:57:51,301 --> 00:57:56,372
experience is by this tendency
to develop event predictive structures

1072
00:57:56,372 --> 00:58:00,977
that are then very simple,
very easily linked to the language

1073
00:58:00,977 --> 00:58:04,214
that each of us experiences
while we grow up.

1074
00:58:04,514 --> 00:58:05,748
Let me show. You.

1075
00:58:05,748 --> 00:58:06,916
What I mean by this event.

1076
00:58:06,916 --> 00:58:09,385
Predictive structures
in terms of a language domain.

1077
00:58:09,719 --> 00:58:13,823
Let's take this this example of of a ball

1078
00:58:13,823 --> 00:58:17,060
that rolled on the table
because it was cricket.

1079
00:58:17,293 --> 00:58:18,661
For example, now.

1080
00:58:18,661 --> 00:58:19,329
And so if.

1081
00:58:19,329 --> 00:58:21,431
You read the sentence, actually,
it was crooked.

1082
00:58:21,431 --> 00:58:23,700
Yeah. You,
you might say or the ball was crooked.

1083
00:58:23,700 --> 00:58:26,236
That's why I wrote down
and that's probably was the table.

1084
00:58:27,237 --> 00:58:31,040
So so
how come we we are able to make sense

1085
00:58:31,541 --> 00:58:36,613
of the sentence with it's
particularly being think of us ambiguous

1086
00:58:36,646 --> 00:58:39,782
being referential ambiguity here
being able to.

1087
00:58:40,517 --> 00:58:44,854
Be. Be bound to the subject
or the object essentially.

1088
00:58:45,188 --> 00:58:48,024
And so what I mean,
what happens when we read such a sentence

1089
00:58:48,391 --> 00:58:52,128
is essentially that while we process and
and so we read the ball

1090
00:58:52,128 --> 00:58:54,631
and it created create
probably a kind of a predictive

1091
00:58:54,631 --> 00:58:58,434
and coding structure of the ball
so the ball can roll and bounce.

1092
00:58:59,002 --> 00:58:59,969
And it.

1093
00:58:59,969 --> 00:59:04,474
It gets repelled when it hit something
and it has some particular size

1094
00:59:04,474 --> 00:59:07,410
and possibly
we also imagine some kind of particular.

1095
00:59:07,410 --> 00:59:08,378
Ball.

1096
00:59:08,711 --> 00:59:12,081
Like a soccer ball or something
depending on what are usually

1097
00:59:12,115 --> 00:59:14,884
not very visual
person. So I don't usually.

1098
00:59:16,352 --> 00:59:18,121
Imagine that an actual ball.

1099
00:59:18,121 --> 00:59:20,256
And then I then read roll down.

1100
00:59:20,256 --> 00:59:24,561
So the rolling is much more active
than the falling at this point

1101
00:59:24,561 --> 00:59:28,031
and I imagine the ball essentially
rolling somewhere.

1102
00:59:28,831 --> 00:59:30,400
Somehow and then.

1103
00:59:30,400 --> 00:59:33,169
This somewhere
somehow is specified. That's the table.

1104
00:59:33,169 --> 00:59:35,972
So it rolls down the table.

1105
00:59:35,972 --> 00:59:37,173
So apparently.

1106
00:59:37,173 --> 00:59:37,807
It's.

1107
00:59:37,807 --> 00:59:39,842
There's a table and there's a tabletop
so it's probably

1108
00:59:39,842 --> 00:59:42,912
on the surface of the table
that rolling event unfolds.

1109
00:59:42,912 --> 00:59:45,281
And so I put this together
and I have this rolling down,

1110
00:59:45,281 --> 00:59:48,585
as we've seen before, the baby
expecting the rolling in, the falling,

1111
00:59:48,885 --> 00:59:52,155
if Now this event structure
right of a ball rolling down,

1112
00:59:52,422 --> 00:59:54,991
meaning like it rolled
first on the surface

1113
00:59:54,991 --> 00:59:58,294
and then it probably dropped down
somewhere.

1114
00:59:58,595 --> 01:00:00,897
That's rolling down the table.

1115
01:00:01,431 --> 01:00:05,735
And now we read
because it was crooked essentially.

1116
01:00:05,735 --> 01:00:10,139
And this essentially implies that the
course due to the because situation right

1117
01:00:10,440 --> 01:00:13,576
that essentially was the second
part of the sentence was not true or like

1118
01:00:13,576 --> 01:00:16,346
this is explaining part of the sentence
that because part right

1119
01:00:16,579 --> 01:00:19,115
so was it not crooked
then the rolling event

1120
01:00:19,449 --> 01:00:24,787
would not not take place this essentially
counter factual reasoning.

1121
01:00:24,787 --> 01:00:28,257
Right
so so can it be that the ball is crooked

1122
01:00:28,257 --> 01:00:31,995
and that's it roll down the table
and that's

1123
01:00:32,629 --> 01:00:35,431
if the boy would have some sort
of crooked dent or whatever, it's most

1124
01:00:35,798 --> 01:00:38,101
likely has not rolled down the table.

1125
01:00:38,101 --> 01:00:40,770
So that seems to be not so plausible.

1126
01:00:41,037 --> 01:00:42,605
So but kind of.

1127
01:00:43,606 --> 01:00:46,242
Tilted crooked

1128
01:00:46,275 --> 01:00:49,112
table seems to be much more plausible.

1129
01:00:49,112 --> 01:00:53,983
So most likely it was the table
that was assigned with a pronoun, right.

1130
01:00:53,983 --> 01:00:58,354
So we can we have essentially analyzed
the whole event with its causality in.

1131
01:00:58,354 --> 01:00:59,889
It by.

1132
01:00:59,889 --> 01:01:02,859
Imagining the words that we read

1133
01:01:02,859 --> 01:01:05,928
and the sentence structure
that we perceive as grammar. And.

1134
01:01:06,896 --> 01:01:10,433
Generating in imagination
of what we perceive.

1135
01:01:10,767 --> 01:01:14,704
And then actually we have
this year was together this question

1136
01:01:14,971 --> 01:01:17,740
Stegeman Phillips Pfaff published a paper

1137
01:01:18,007 --> 01:01:22,245
on the so-called learner architecture,
which essentially learns

1138
01:01:22,478 --> 01:01:25,448
about an environment
in event predictive structure.

1139
01:01:26,215 --> 01:01:29,018
It is trained. Informed.

1140
01:01:29,018 --> 01:01:30,153
How. To.

1141
01:01:30,153 --> 01:01:32,422
Link the individual

1142
01:01:33,690 --> 01:01:36,926
event components
that it has learned out of its

1143
01:01:37,427 --> 01:01:40,830
observing in environment,
with the language process, the system.

1144
01:01:41,264 --> 01:01:44,600
And then it can in fact do just what
I have illustrated.

1145
01:01:44,600 --> 01:01:49,338
It can disambiguate ambiguous sentences
by creating

1146
01:01:49,939 --> 01:01:53,643
concrete
imaginations of an a state of affair.

1147
01:01:54,010 --> 01:01:56,379
So, for example, we have here this.

1148
01:01:56,379 --> 01:01:57,680
This scenario.

1149
01:01:59,382 --> 01:02:01,884
Unfortunately looks like are viruses
here.

1150
01:02:02,085 --> 01:02:03,686
This has nothing to do with Corona.

1151
01:02:03,686 --> 01:02:04,987
So sorry about it.

1152
01:02:04,987 --> 01:02:07,390
It was created before

1153
01:02:07,423 --> 01:02:09,425
the whole damn pandemic.

1154
01:02:09,425 --> 01:02:12,562
But nonetheless, what's important
is that these creatures

1155
01:02:12,562 --> 01:02:15,331
here pushed on stuff
from these platforms.

1156
01:02:15,732 --> 01:02:17,900
And our learner.

1157
01:02:17,900 --> 01:02:19,001
System analyzes

1158
01:02:19,001 --> 01:02:23,172
these things and essentially creates
even predictive structures out of it.

1159
01:02:23,573 --> 01:02:28,111
And so then after it has learned this,
it can essentially generate

1160
01:02:28,111 --> 01:02:29,245
sentence interpretation.

1161
01:02:29,245 --> 01:02:33,616
So after training, essentially
you can create give it a sentence such as

1162
01:02:33,850 --> 01:02:37,854
the green virus rests on the platform
and it moves to the box after it falls.

1163
01:02:37,854 --> 01:02:41,791
So rather complex sentence
and what the system then is doing,

1164
01:02:41,791 --> 01:02:45,762
it can create itself out of the entities
that. Are.

1165
01:02:46,229 --> 01:02:48,898
Uttered like a green virus, a platform

1166
01:02:49,232 --> 01:02:52,735
and box,
which has been decided to be green here.

1167
01:02:52,769 --> 01:02:56,072
So that's randomly chosen
then maybe it's not specified.

1168
01:02:56,539 --> 01:02:57,540
It's a range.

1169
01:02:57,540 --> 01:03:00,777
Is these three objects in such a way

1170
01:03:01,177 --> 01:03:04,213
such that it can imagine
an event sequence

1171
01:03:04,213 --> 01:03:07,383
unfolding in this constellation
to make the sentence true.

1172
01:03:07,650 --> 01:03:09,619
So you can see this in this video here.

1173
01:03:09,619 --> 01:03:12,421
So essentially the system learned

1174
01:03:12,421 --> 01:03:15,892
to generate this constellation of the C
and the virus.

1175
01:03:15,892 --> 01:03:19,662
Lo and behold, falls
on the platform, actually,

1176
01:03:19,662 --> 01:03:22,732
and then it rests on the platform
for a little while,

1177
01:03:22,999 --> 01:03:27,570
and then it moves to the box
after it has fallen the platform.

1178
01:03:27,570 --> 01:03:32,108
So this is the interpretation of
the sentence that the system has created.

1179
01:03:32,375 --> 01:03:35,611
And I think it's a nice illustration
hopefully for you also convincing

1180
01:03:35,611 --> 01:03:39,215
illustration
that this event structures, sentences

1181
01:03:39,215 --> 01:03:41,484
addressing event structures.

1182
01:03:42,251 --> 01:03:43,820
Can be.

1183
01:03:43,953 --> 01:03:44,887
What we make of it.

1184
01:03:44,887 --> 01:03:45,521
What meaning?

1185
01:03:45,521 --> 01:03:49,892
Making sense of a sentence is essentially
something like this is the internal

1186
01:03:49,892 --> 01:03:53,262
creation of a consistent event
or event progression.

1187
01:03:53,629 --> 01:03:54,330
That.

1188
01:03:54,330 --> 01:03:59,335
Fits to the described tendency
to disambiguate, of course, certain.

1189
01:03:59,335 --> 01:04:01,671
Temporal and and.

1190
01:04:01,671 --> 01:04:05,441
Referential and so forth, ambiguities
that might be inherent

1191
01:04:05,441 --> 01:04:10,246
in the sentence and grammatical structure
that is provided.

1192
01:04:10,246 --> 01:04:12,448
We have also just recently shown that

1193
01:04:12,849 --> 01:04:16,352
this event predictive
inference structure also nicely

1194
01:04:17,320 --> 01:04:19,388
fits to the rational speech model.

1195
01:04:19,388 --> 01:04:20,623
Actually, for that matter.

1196
01:04:20,623 --> 01:04:21,858
And one.

1197
01:04:21,858 --> 01:04:24,660
Can nicely model.

1198
01:04:24,660 --> 01:04:26,162
Learning.

1199
01:04:26,362 --> 01:04:31,000
About the preferences of others.

1200
01:04:31,000 --> 01:04:35,037
This essentially
this example in this study

1201
01:04:35,037 --> 01:04:39,208
goes with actual behavior experiments
done on my work years.

1202
01:04:39,208 --> 01:04:43,179
So for example,
you can imagine when you have a scene

1203
01:04:43,179 --> 01:04:47,416
like this in this admittedly
very abstract entities here.

1204
01:04:47,850 --> 01:04:51,420
And so for example, have the scenario
and Maria wants to signal

1205
01:04:51,420 --> 01:04:54,523
an object to the following scene
in the following scene to Samantha.

1206
01:04:54,724 --> 01:04:58,561
So Maria Maria says read,
please take a read one essentially.

1207
01:04:58,694 --> 01:05:02,465
And Samantha chooses the angel object
such as she takes

1208
01:05:02,465 --> 01:05:05,134
the red cloud here, red stripe cloud.

1209
01:05:05,568 --> 01:05:10,373
Then you can possibly infer something
about preferences.

1210
01:05:10,740 --> 01:05:15,845
Low and behold, she might like,
for example, clouds more than circles.

1211
01:05:16,913 --> 01:05:17,980
But you don't know anything

1212
01:05:17,980 --> 01:05:21,317
about squares because it was no option
to choose from squares.

1213
01:05:21,751 --> 01:05:26,522
And you can also, by the active
inference, formalism

1214
01:05:26,522 --> 01:05:31,227
within this formalism, actually, you can
then also do it the other way around.

1215
01:05:31,227 --> 01:05:34,530
And you want to, for example,
possibly learn about

1216
01:05:35,731 --> 01:05:37,133
Elizabeth as preferences.

1217
01:05:37,133 --> 01:05:41,170
And therefore only in this scenario
can give options to choose among objects.

1218
01:05:41,437 --> 01:05:43,439
So for example, if you want to.

1219
01:05:43,439 --> 01:05:44,941
Learn.

1220
01:05:45,274 --> 01:05:49,111
About if the say if the person prefers

1221
01:05:50,546 --> 01:05:52,682
clouds or circles,

1222
01:05:52,682 --> 01:05:55,851
you could for example, say,
pick one of the green ones

1223
01:05:56,252 --> 01:06:00,423
and then you would see
if she person takes the cloud or circle.

1224
01:06:00,423 --> 01:06:03,292
And then you have some hint
that the person might

1225
01:06:04,260 --> 01:06:06,662
prefer clouds or circles, for example.

1226
01:06:07,330 --> 01:06:09,932
And we have monitors in this recursive

1227
01:06:10,232 --> 01:06:13,803
inference process very closely
related to the active inference.

1228
01:06:13,803 --> 01:06:16,806
Formalism use a typical kind of urgency

1229
01:06:17,073 --> 01:06:20,543
to look like l divergence again,
where. We.

1230
01:06:20,977 --> 01:06:23,980
Essentially. Compare our prior.

1231
01:06:23,980 --> 01:06:28,951
Knowledge of feature preferences
of our expected posterior

1232
01:06:28,985 --> 01:06:30,553
knowledge of future preferences

1233
01:06:30,553 --> 01:06:33,356
by pursuing a particular action,
that particular utterance.

1234
01:06:33,889 --> 01:06:38,461
And when we compare this to the actual
behavior of the human participants,

1235
01:06:38,794 --> 01:06:42,331
we get really good fits
and in fact could show us a.

1236
01:06:42,331 --> 01:06:44,633
From a from a from.

1237
01:06:44,633 --> 01:06:46,202
The information criterion

1238
01:06:47,503 --> 01:06:50,072
manner that our cognitive model fits
better.

1239
01:06:50,072 --> 01:06:53,109
Than than other. Competitive models.

1240
01:06:53,442 --> 01:06:56,879
And this leads me
to the end of my presentation now.

1241
01:06:57,013 --> 01:07:00,049
So just a language
really briefly in the end,

1242
01:07:00,449 --> 01:07:03,152
but I hope you see what I mean by that.

1243
01:07:03,152 --> 01:07:06,555
This is when predictive cognition
essentially and the active

1244
01:07:06,555 --> 01:07:09,859
inference processes
that unfold this within this event,

1245
01:07:09,859 --> 01:07:13,029
predictive cognitive systems
and our brains for that matter,

1246
01:07:13,029 --> 01:07:16,432
most likely are very compatible
to a linguistic structures.

1247
01:07:17,433 --> 01:07:21,637
So what I have shown you today,
and I hope you could follow me

1248
01:07:21,637 --> 01:07:26,409
so fine, wasn't too much
that essentially our generative mind.

1249
01:07:26,409 --> 01:07:27,076
Yeah.

1250
01:07:27,076 --> 01:07:31,547
May have may have the self-motivated
objective to act highly flexibly

1251
01:07:31,547 --> 01:07:35,484
and go direct and pursue epistemic
self-motivated actions in general.

1252
01:07:35,484 --> 01:07:39,422
This is quite clear to survive, right,
to interact with our complex floods,

1253
01:07:39,789 --> 01:07:44,193
to seeing that we have become this
crazy human beings with all our social

1254
01:07:44,193 --> 01:07:48,064
likes and dates and capability
and intelligence and so forth.

1255
01:07:48,831 --> 01:07:52,802
On this human cognitive level event,
predictive conceptualizations

1256
01:07:53,102 --> 01:07:57,907
seem to be really important
to enable us to act in a deeper, goal

1257
01:07:57,907 --> 01:08:02,812
directed, self-motivated manner
and to conceptualize our environment.

1258
01:08:02,812 --> 01:08:06,682
Thus, to be able to communicate
and interact and cooperate

1259
01:08:06,982 --> 01:08:10,586
with others and compete
also with each other, for that matter.

1260
01:08:10,586 --> 01:08:11,020
In a.

1261
01:08:11,020 --> 01:08:14,056
Highly more sophisticated manner
than. Any.

1262
01:08:14,056 --> 01:08:17,760
Other animals
can to learn such conceptualizations.

1263
01:08:17,760 --> 01:08:18,561
We really need

1264
01:08:18,561 --> 01:08:22,598
this inductive learning biases, and it's
certainly not fully figured out yet.

1265
01:08:22,932 --> 01:08:24,166
How this learning and.

1266
01:08:24,166 --> 01:08:26,435
Processing biases. Are.

1267
01:08:26,435 --> 01:08:28,337
Working, weakening our functioning.

1268
01:08:29,505 --> 01:08:30,773
But we know

1269
01:08:30,773 --> 01:08:33,776
one can
show clearly that this concept Jasons

1270
01:08:33,809 --> 01:08:38,013
are really good to enable deeper goal
directed, self-motivated planning,

1271
01:08:38,414 --> 01:08:42,852
reasoning, counterfactual reasoning,
filling in gaps, finding and unknowns.

1272
01:08:43,786 --> 01:08:46,055
Disambiguate ambiguous situations.

1273
01:08:46,655 --> 01:08:49,325
And pursuing yet abstract.

1274
01:08:49,325 --> 01:08:51,660
And concrete behaviors
on multiple levels.

1275
01:08:52,661 --> 01:08:56,398
And last point
was that language seemed to be mapped

1276
01:08:56,799 --> 01:09:03,072
really rather simplistic easily on this,
which essentially possibly might.

1277
01:09:03,072 --> 01:09:04,640
Explain why.

1278
01:09:04,640 --> 01:09:07,276
We as babies naturally.

1279
01:09:07,276 --> 01:09:11,046
Learn our mother tongue without much,

1280
01:09:11,580 --> 01:09:14,150
obviously much effort and particular.

1281
01:09:14,150 --> 01:09:15,951
The complexity of the grammar behind it.

1282
01:09:15,951 --> 01:09:18,721
Also know
no artificial intelligence side.

1283
01:09:19,021 --> 01:09:21,991
I would like to conclude. With that that.

1284
01:09:21,991 --> 01:09:25,594
The current deep learning systems
most because they don't foster

1285
01:09:25,594 --> 01:09:28,831
this general activity
and this conceptualization of structures,

1286
01:09:30,166 --> 01:09:33,536
they do not really foster event
predictive generative models

1287
01:09:33,869 --> 01:09:37,940
and as others have said
thus many may call. The.

1288
01:09:37,940 --> 01:09:42,811
More simpler architectures
that are nonetheless including systems

1289
01:09:42,811 --> 01:09:46,782
like transformers
and so forth, really still rather highly

1290
01:09:46,982 --> 01:09:51,820
computationally demanding
stochastic parrots, arguably.

1291
01:09:51,820 --> 01:09:53,822
And interesting
to discuss this, of course,

1292
01:09:55,224 --> 01:09:56,492
I believe that

1293
01:09:56,492 --> 01:10:00,396
if we develop more event predictive
generative systems,

1294
01:10:00,396 --> 01:10:05,467
then we actually foster the development
of the learning of generative models,

1295
01:10:05,467 --> 01:10:09,638
that is, and ideally causal models
of the actual true

1296
01:10:09,872 --> 01:10:14,677
causal letter that we encounter via
our sensorimotor experiences,

1297
01:10:15,110 --> 01:10:19,315
enabling us to generate much more robust
for costs, possible action

1298
01:10:19,348 --> 01:10:23,719
recommendations and explanations of why
we would recommend particular things

1299
01:10:23,719 --> 01:10:25,020
or forecast particular things.

1300
01:10:25,020 --> 01:10:29,892
Because we essentially are designed
to learn about the causes.

1301
01:10:30,192 --> 01:10:32,861
That. Lead us to predict certain things.

1302
01:10:32,861 --> 01:10:35,264
So we can also of course
talk about the causes.

1303
01:10:35,664 --> 01:10:39,335
And in my opinion, these systems may
then indeed use strongly

1304
01:10:39,335 --> 01:10:41,503
AI or artificial general intelligence

1305
01:10:45,074 --> 01:10:46,208
where self-motivated

1306
01:10:46,208 --> 01:10:49,778
learning will be inevitable,
part of such systems.

1307
01:10:50,212 --> 01:10:52,047
And. Self-Motivated learning.

1308
01:10:52,047 --> 01:10:55,050
And so that behavior
thus will be part of these systems.

1309
01:10:55,584 --> 01:10:56,819
And so.

1310
01:10:56,819 --> 01:10:58,287
I think it's.

1311
01:10:58,287 --> 01:11:01,390
We should be aware
that there is no reason.

1312
01:11:01,690 --> 01:11:02,992
I see no reason.

1313
01:11:02,992 --> 01:11:06,996
Research on human cognition
and it's functionally

1314
01:11:07,296 --> 01:11:10,766
no reason
why an artificial system should not reach

1315
01:11:10,766 --> 01:11:13,469
such intelligence level.

1316
01:11:14,003 --> 01:11:18,440
And so, as others also have pointed out,
I want to conclude with a.

1317
01:11:18,941 --> 01:11:19,241
With.

1318
01:11:19,241 --> 01:11:23,545
A word of caution, essentially,
and a word of awareness that

1319
01:11:24,280 --> 01:11:26,782
if these systems come into being

1320
01:11:26,782 --> 01:11:31,287
come into existence, yes,
we need to make very much sure

1321
01:11:31,287 --> 01:11:35,391
that we don't design
just for profit or for.

1322
01:11:35,758 --> 01:11:36,258
Some.

1323
01:11:37,559 --> 01:11:40,195
Individual personal interests.

1324
01:11:40,195 --> 01:11:44,767
But we better put a good person purpose
into these systems.

1325
01:11:44,767 --> 01:11:48,704
And it's a good idea
to think about this now more so.

1326
01:11:49,571 --> 01:11:50,506
This concludes my talk.

1327
01:11:50,506 --> 01:11:51,840
Thank you so much for attention.

1328
01:11:51,840 --> 01:11:55,644
Parts of this general motivation
and background you can find in my.

1329
01:11:56,612 --> 01:11:57,513
Book from.

1330
01:11:57,513 --> 01:11:59,782
20 1617.

1331
01:11:59,948 --> 01:12:01,350
How. The mind comes into being.

1332
01:12:01,350 --> 01:12:02,451
And I.

1333
01:12:02,451 --> 01:12:04,687
Some funding from the Humboldt
Foundation and.

1334
01:12:05,954 --> 01:12:07,189
Mainly and.

1335
01:12:07,189 --> 01:12:10,459
Thank you for my team
actually to produce much of this work.

1336
01:12:10,459 --> 01:12:12,294
I don't have a team slide here.

1337
01:12:12,294 --> 01:12:13,729
And but thank you for your.

1338
01:12:13,729 --> 01:12:15,331
Attention as well.

1339
01:12:16,398 --> 01:12:18,167
Awesome presentation.

1340
01:12:18,167 --> 01:12:20,402
Thank you very much. Thank you.

1341
01:12:21,236 --> 01:12:25,708
Maybe you can unshared
and we can have a little discussion.

1342
01:12:26,508 --> 01:12:27,042
Mm hmm.

1343
01:12:27,042 --> 01:12:28,243
Definitely.

1344
01:12:29,545 --> 01:12:33,148
Well, tons of very interesting ideas.

1345
01:12:33,482 --> 01:12:35,184
Anyone can write a question in the chat.

1346
01:12:35,184 --> 01:12:38,220
But let me just start
with a introductory question.

1347
01:12:38,687 --> 01:12:42,891
How did you come to be working
with active models?

1348
01:12:43,092 --> 01:12:45,527
What were you working on before?

1349
01:12:45,561 --> 01:12:50,632
Was it a system specific or question
specific path that led you to integrate

1350
01:12:50,799 --> 01:12:56,238
these novel components
into active inference?

1351
01:12:57,673 --> 01:12:58,507
Yes, thanks.

1352
01:12:58,507 --> 01:13:00,909
I just little bit confused
because it's this camera.

1353
01:13:00,909 --> 01:13:03,045
No name. Okay. Um,

1354
01:13:04,113 --> 01:13:05,447
but let me.

1355
01:13:05,447 --> 01:13:08,250
Actually turn. To the screen then.

1356
01:13:08,250 --> 01:13:11,954
Yes. Well,

1357
01:13:11,954 --> 01:13:17,159
I have studied all my research career,
essentially started to study

1358
01:13:17,159 --> 01:13:20,596
anticipatory behavior
from the very early on during

1359
01:13:22,030 --> 01:13:24,400
diploma, a bachelor's degree studies

1360
01:13:24,400 --> 01:13:27,102
essentially coming into contact
with a psychologist

1361
01:13:27,102 --> 01:13:31,240
in which spoke Joachim Hoffmann's
group on anticipatory behavior control.

1362
01:13:31,240 --> 01:13:34,410
And I think in his work,
he already essentially

1363
01:13:34,410 --> 01:13:37,379
from the psychological perspective. Of.

1364
01:13:38,013 --> 01:13:42,885
Formalizes
this principle, of active inference on a

1365
01:13:42,918 --> 01:13:48,524
on the very crude, more in words
specified psychological level

1366
01:13:48,557 --> 01:13:52,194
where and I started very early
to also realize that.

1367
01:13:53,762 --> 01:13:56,899
That was the.

1368
01:13:56,899 --> 01:13:58,700
Devil's in the details.

1369
01:13:58,700 --> 01:14:00,702
And the.

1370
01:14:00,702 --> 01:14:04,640
Question is really
what are representations like what

1371
01:14:04,907 --> 01:14:08,410
what is the representations that
this anticipations that this predictions

1372
01:14:08,877 --> 01:14:10,078
actually unfold?

1373
01:14:10,078 --> 01:14:12,581
What What's the nature
of these representations?

1374
01:14:12,581 --> 01:14:16,919
And even now a days, we still see
lots of machine learning work.

1375
01:14:16,919 --> 01:14:17,820
Where.

1376
01:14:17,853 --> 01:14:21,023
Representations are given in advance
and so forth.

1377
01:14:21,557 --> 01:14:23,592
And or are.

1378
01:14:23,592 --> 01:14:29,231
Just totally done by, let's say,
the Atari games or these successes.

1379
01:14:29,231 --> 01:14:30,265
I mean, there

1380
01:14:30,265 --> 01:14:34,970
you just give the play an image and you
you kill the problem with so much data.

1381
01:14:35,404 --> 01:14:36,905
That it still.

1382
01:14:37,072 --> 01:14:40,809
Converges,
but the system is not really learning

1383
01:14:40,943 --> 01:14:44,012
the system activity,
the actual structure of the problem.

1384
01:14:44,646 --> 01:14:48,750
And but most recent advances,
of course, also from others.

1385
01:14:48,750 --> 01:14:49,751
For example, the

1386
01:14:51,720 --> 01:14:52,321
the dreamer.

1387
01:14:52,321 --> 01:14:56,558
Architecture or the planet architecture
from from

1388
01:14:57,726 --> 01:14:58,160
what's his name.

1389
01:14:58,160 --> 01:15:00,329
Haffner is the last name.

1390
01:15:00,329 --> 01:15:02,865
This course also very close
in this direction but not.

1391
01:15:03,365 --> 01:15:05,200
Oh designer.

1392
01:15:05,434 --> 01:15:07,302
Half. Yeah. Yes.

1393
01:15:07,302 --> 01:15:11,607
They goes in this direction,
but They don't really foster

1394
01:15:11,607 --> 01:15:13,876
event predictive laden codes yet
and I think.

1395
01:15:13,876 --> 01:15:15,143
They should.

1396
01:15:16,678 --> 01:15:19,281
Cool.

1397
01:15:19,281 --> 01:15:24,152
I have some predictions
about where you might go,

1398
01:15:24,152 --> 01:15:27,456
but just to sort of restate it,
you said just in your previous

1399
01:15:27,456 --> 01:15:31,126
answer that it was a crude
active inference in words.

1400
01:15:31,760 --> 01:15:37,533
And so I wanted to ask what is active
inference crudely in words?

1401
01:15:37,933 --> 01:15:40,335
And then what key

1402
01:15:41,236 --> 01:15:44,773
pieces of the formalism today
refined those words?

1403
01:15:44,773 --> 01:15:47,676
And then what do you see
being incorporated into the formalism

1404
01:15:47,676 --> 01:15:51,713
going forwards?

1405
01:15:51,713 --> 01:15:54,883
So what's what's active
inference, crudely speaking and words?

1406
01:15:56,385 --> 01:15:58,587
It's well, it's

1407
01:15:58,587 --> 01:16:01,323
active inference essentially formalizes.

1408
01:16:02,724 --> 01:16:04,126
How our.

1409
01:16:04,126 --> 01:16:06,862
Minds and how clever learning systems

1410
01:16:07,896 --> 01:16:10,465
should infer

1411
01:16:10,465 --> 01:16:14,836
to develop generative models
about the world and use this models

1412
01:16:14,836 --> 01:16:18,140
to pursue says motivated co-directed

1413
01:16:18,140 --> 01:16:21,343
behavior.

1414
01:16:21,343 --> 01:16:23,946
That's the general formalism.

1415
01:16:23,946 --> 01:16:27,716
And my point
today was essentially that this formalism

1416
01:16:27,716 --> 01:16:31,186
is overly general in a sense,
because it doesn't

1417
01:16:31,186 --> 01:16:33,755
specify the nature.

1418
01:16:34,222 --> 01:16:37,659
Of. The encoding of the predictive
coatings.

1419
01:16:37,659 --> 01:16:41,730
And. Evolution
as obviously shaped our minds,

1420
01:16:42,197 --> 01:16:45,367
such that we have particular

1421
01:16:45,367 --> 01:16:49,104
expectations
of this suitable of the structure

1422
01:16:49,104 --> 01:16:54,242
that's suitable to model the outside
environment and thus interact with this.

1423
01:16:54,242 --> 01:16:56,144
Environment in a.

1424
01:16:56,144 --> 01:17:00,849
More flexible, adaptive, directed,
socially competent manner.

1425
01:17:01,650 --> 01:17:04,353
And that's where the event
predictive stuff falls in.

1426
01:17:05,887 --> 01:17:07,956
Thank you for the answer.

1427
01:17:07,956 --> 01:17:13,295
Now a sequence of events
might have a narrative could be said

1428
01:17:13,295 --> 01:17:14,930
that connects them.

1429
01:17:14,930 --> 01:17:19,101
How does narrative relate to your work
here?

1430
01:17:19,101 --> 01:17:24,806
Is that just a bigger nesting event
or how do we connect micro-scale events,

1431
01:17:25,140 --> 01:17:27,943
which it's very nice
how you, you know, rolling off

1432
01:17:27,943 --> 01:17:30,812
the table was a clear demonstration
of that kind of an event.

1433
01:17:30,946 --> 01:17:35,250
How does that connect to broader
narratives?

1434
01:17:35,250 --> 01:17:37,252
Yeah, very good question.

1435
01:17:37,252 --> 01:17:38,387
Good and very interesting

1436
01:17:39,588 --> 01:17:42,057
is I think.

1437
01:17:42,791 --> 01:17:45,060
As I said in as I tried

1438
01:17:45,060 --> 01:17:49,364
to imply also that the events exists
on multiple

1439
01:17:49,364 --> 01:17:53,568
levels of granularity
and precision in an event can consist of.

1440
01:17:53,568 --> 01:17:55,937
Yet sup events essentially. Right.

1441
01:17:55,937 --> 01:17:59,841
I mean like the whole episode
of writing a letter, for example,

1442
01:17:59,841 --> 01:18:04,713
consists of writing individual words,
sentences, paragraphs, thoughts,

1443
01:18:04,980 --> 01:18:08,617
expressing individual
thought components and so forth, right?

1444
01:18:08,617 --> 01:18:10,152
So, so. And.

1445
01:18:10,152 --> 01:18:10,652
So on.

1446
01:18:10,652 --> 01:18:13,689
Event per say.

1447
01:18:13,689 --> 01:18:15,023
Can I mean you have the.

1448
01:18:15,023 --> 01:18:17,426
Event of your current day.

1449
01:18:17,426 --> 01:18:19,361
Right? And you compress this as an event.

1450
01:18:19,361 --> 01:18:20,595
So, so this.

1451
01:18:20,595 --> 01:18:23,365
So that's the beauty about it
I think also because.

1452
01:18:23,932 --> 01:18:25,200
An. Event.

1453
01:18:25,534 --> 01:18:27,769
It's not it's not

1454
01:18:27,836 --> 01:18:31,406
there's not only one event
unfolding in our minds.

1455
01:18:31,707 --> 01:18:32,607
In every.

1456
01:18:32,607 --> 01:18:37,679
Here and now situation,
but it's it's about these

1457
01:18:38,246 --> 01:18:41,616
different aspects
that have beginnings and endings, right?

1458
01:18:41,616 --> 01:18:44,252
Like this, like meeting here.

1459
01:18:44,252 --> 01:18:48,123
But my answer to your question,
my individual sentences,

1460
01:18:48,123 --> 01:18:51,827
my individual words,
my actual utterances that I produce,

1461
01:18:52,194 --> 01:18:55,530
these are all events nested
within each other.

1462
01:18:55,831 --> 01:19:01,169
And each of these components
is characterized by certain stability.

1463
01:19:01,169 --> 01:19:05,574
Situations
like the whole why we have this meeting,

1464
01:19:06,608 --> 01:19:07,843
the in a certain

1465
01:19:07,843 --> 01:19:11,646
interactive situation and this is more
or less stable during the whole meeting.

1466
01:19:11,780 --> 01:19:14,249
I guess, I'm the presenter here today
and so forth.

1467
01:19:14,549 --> 01:19:18,854
And then we have listeners
and you are the, the mediator so to say.

1468
01:19:18,854 --> 01:19:20,822
Right,
and this is the situation all the time.

1469
01:19:20,822 --> 01:19:23,658
And this table front from the beginning
of the end, from the whole situation.

1470
01:19:23,658 --> 01:19:23,859
Right.

1471
01:19:23,859 --> 01:19:27,529
But when you pose me a question,
then you focus in on this question

1472
01:19:27,529 --> 01:19:28,830
answering situation event

1473
01:19:28,830 --> 01:19:32,134
and that's one particular event
within nested within the other event.

1474
01:19:32,134 --> 01:19:36,138
And while I produce my train of thought,
there are also the events again

1475
01:19:36,404 --> 01:19:37,005
unfold, right?

1476
01:19:37,005 --> 01:19:39,241
So this so there's a. Lot and and.

1477
01:19:39,241 --> 01:19:43,979
Each of these events though
is characterized by certain stabilities.

1478
01:19:44,379 --> 01:19:45,013
That are.

1479
01:19:45,013 --> 01:19:49,351
Unfolding, such as the question
answer situation, where we focus on the

1480
01:19:49,351 --> 01:19:52,487
particular component of this current talk
and the current

1481
01:19:52,487 --> 01:19:56,258
topic of this meeting.

1482
01:19:56,258 --> 01:19:56,825
Awesome.

1483
01:19:56,825 --> 01:20:02,697
What that reminded me of was Chronos
and Kairos, two Greek word

1484
01:20:02,697 --> 01:20:06,434
roots for time and the chronometer
the decimal of the time.

1485
01:20:06,601 --> 01:20:11,139
And there's testing of chronology
like the second is within the DECA

1486
01:20:11,139 --> 01:20:15,343
second or the, you know, the minute,
the hour, but then Kairos, this

1487
01:20:15,343 --> 01:20:21,149
more semantic or action oriented
kind of timeliness also has nesting

1488
01:20:21,449 --> 01:20:25,620
and that can be perfectly
nothing like the example.

1489
01:20:25,654 --> 01:20:27,422
The letter with the sentence, the word,

1490
01:20:28,790 --> 01:20:29,724
etc. is funny because

1491
01:20:29,724 --> 01:20:32,661
it's called a letter right at the bigger
and the smaller level.

1492
01:20:32,861 --> 01:20:34,129
Hmm. Mm hmm.

1493
01:20:34,129 --> 01:20:34,629
Right.

1494
01:20:34,629 --> 01:20:37,632
But then also, the boundaries could be

1495
01:20:37,632 --> 01:20:38,667
subjective.

1496
01:20:38,667 --> 01:20:39,901
So not to say arbitrary,

1497
01:20:39,901 --> 01:20:43,772
but literally defined by the subject,
learned by the subject.

1498
01:20:43,972 --> 01:20:45,640
And so it seems to be no problem

1499
01:20:45,640 --> 01:20:49,444
to have machine learning systems
that can nest Chronos very well.

1500
01:20:49,911 --> 01:20:54,883
But how do we achieve an adequate nested,
action

1501
01:20:54,883 --> 01:20:58,753
oriented representation?

1502
01:20:58,753 --> 01:21:01,823
Any thoughts
or ask a question from a chat?

1503
01:21:01,823 --> 01:21:03,758
I think the

1504
01:21:03,758 --> 01:21:06,528
that's a very important part
and that's also the beauty.

1505
01:21:06,528 --> 01:21:08,296
I think about the event structures,
right?

1506
01:21:08,296 --> 01:21:11,166
That essentially it's
not it's always subjective

1507
01:21:12,300 --> 01:21:16,304
because it's the stability that
each of us perceives that makes an event.

1508
01:21:16,671 --> 01:21:18,640
Become an event now.

1509
01:21:18,640 --> 01:21:21,376
And I mean,
because our world for us is all the same.

1510
01:21:21,543 --> 01:21:24,279
We are very similar
in this event structures.

1511
01:21:24,579 --> 01:21:27,816
But nonetheless, of course,
the events are very

1512
01:21:27,816 --> 01:21:30,719
individually
unfolding in each of our minds.

1513
01:21:31,052 --> 01:21:32,020
And they are.

1514
01:21:32,020 --> 01:21:35,690
Characterized by this stability
and systematize properties

1515
01:21:35,690 --> 01:21:37,893
that each event has.

1516
01:21:37,893 --> 01:21:40,862
And the nice thing about it as well
is that

1517
01:21:40,862 --> 01:21:44,266
the partitioning and segmentation
is extremely flexible, right?

1518
01:21:44,266 --> 01:21:48,036
I mean, you can
it doesn't depend on time.

1519
01:21:48,403 --> 01:21:49,371
In order to.

1520
01:21:50,372 --> 01:21:53,041
Implement
this in machine learning systems,

1521
01:21:53,408 --> 01:21:56,311
you need to have a system
that can flexibly.

1522
01:21:57,279 --> 01:21:58,146
Maintain.

1523
01:21:58,146 --> 01:22:01,716
Particular latent states
over extended periods of time

1524
01:22:01,716 --> 01:22:05,020
and systematically change them
when the time is ripe.

1525
01:22:05,020 --> 01:22:08,223
So to say, and this is what we have done
with the eight

1526
01:22:08,223 --> 01:22:11,526
lot system
that I have showed the towards the end,

1527
01:22:11,526 --> 01:22:13,862
which is going to be published
in December.

1528
01:22:15,630 --> 01:22:16,264
Very Cool.

1529
01:22:16,264 --> 01:22:18,333
So I'll ask a question from the chat.

1530
01:22:18,733 --> 01:22:21,603
So Dean has asked

1531
01:22:21,603 --> 01:22:24,940
entertaining counterfactuals is time
distributing

1532
01:22:25,307 --> 01:22:28,476
and time provides
the twist like a mobius strip.

1533
01:22:29,210 --> 01:22:32,614
So if we include dire chronic continuity

1534
01:22:33,081 --> 01:22:37,686
with events, episodic, partitioned,
do we break free

1535
01:22:37,686 --> 01:22:39,087
from training

1536
01:22:43,224 --> 01:22:46,695
a classical
a classical dean phrasing to be sure,

1537
01:22:46,928 --> 01:22:50,665
which I just read literally,
rather than choose to interpret, but.

1538
01:22:52,634 --> 01:22:54,769
Maybe
you can help me with in the rotation.

1539
01:22:54,769 --> 01:22:57,172
But I would say the.

1540
01:22:58,006 --> 01:23:00,709
The kind of fictional component

1541
01:23:00,709 --> 01:23:04,612
was the problem that the counterfactual
is, is time demanding or consuming

1542
01:23:04,612 --> 01:23:09,484
or mentally challenging essentially to
because time is on the issue.

1543
01:23:09,484 --> 01:23:14,189
And so I need to be so I cannot do
counterfactual reasonings on the fly.

1544
01:23:14,189 --> 01:23:16,725
And that's certainly true. We have

1545
01:23:17,792 --> 01:23:22,130
useful typically in our best explanation
very quickly and habitually.

1546
01:23:22,130 --> 01:23:24,199
And only when we.

1547
01:23:24,532 --> 01:23:25,500
Really realize.

1548
01:23:25,500 --> 01:23:28,770
Errors we fall into.

1549
01:23:28,937 --> 01:23:30,338
Counterfactuals.

1550
01:23:30,338 --> 01:23:33,108
I usually give the example
with a cricket ball.

1551
01:23:33,108 --> 01:23:36,678
I actually usually I give
a simple example which is not dynamic.

1552
01:23:36,678 --> 01:23:42,684
Like the ball fits into a suitcase
because it is large, for example.

1553
01:23:43,118 --> 01:23:47,222
So the ball fits into the suitcase
because it is large.

1554
01:23:47,522 --> 01:23:52,327
So it is a suitcase
that is large and not the ball. And.

1555
01:23:52,327 --> 01:23:54,562
And that is kind of also. A.

1556
01:23:54,562 --> 01:23:57,132
Typical garden course.
Effect in language.

1557
01:23:57,132 --> 01:24:00,335
Linguistics where you fall
into the best interpretation.

1558
01:24:00,635 --> 01:24:02,370
The pronoun it.

1559
01:24:02,370 --> 01:24:04,439
Usually fits with the subject.

1560
01:24:04,773 --> 01:24:05,974
And so.

1561
01:24:05,974 --> 01:24:08,777
Your best hypothesis
to bind it to a subject.

1562
01:24:09,177 --> 01:24:10,678
You read on.

1563
01:24:10,678 --> 01:24:14,182
And then you get to the final sentence
and then you try to imagine

1564
01:24:14,182 --> 01:24:16,051
why does the ball fit in the suitcase?

1565
01:24:16,051 --> 01:24:17,752
And then essentially.

1566
01:24:17,752 --> 01:24:20,455
You. Realize
you have to revise your model.

1567
01:24:20,455 --> 01:24:22,357
And that's
kind of the kind of factual part

1568
01:24:22,357 --> 01:24:26,127
that only happens, I think, when there is
surprise or other reasons

1569
01:24:26,127 --> 01:24:30,565
to really pursue
this additional cognitive effort.

1570
01:24:30,565 --> 01:24:31,699
Great answer.

1571
01:24:31,699 --> 01:24:33,535
Let me see if there's a link

1572
01:24:33,535 --> 01:24:37,572
to what Dean suggested
and the stochastic parrot notion.

1573
01:24:38,039 --> 01:24:41,776
So if we think about a stochastic seed,

1574
01:24:42,343 --> 01:24:44,846
preferring seed, rewarding parrot,

1575
01:24:45,313 --> 01:24:48,516
it's like there's some maize in the seed
could be on either side.

1576
01:24:48,516 --> 01:24:50,585
And so it's rewarded
when it's discovering that, it's

1577
01:24:50,585 --> 01:24:55,356
strengthening that, and then it switches
and then it just stochastic leaf

1578
01:24:55,356 --> 01:24:59,427
sometimes investigates the other branch
and then reinforces that.

1579
01:24:59,427 --> 01:25:01,329
Now that's all time bound.

1580
01:25:02,530 --> 01:25:04,566
If we think about the

1581
01:25:04,566 --> 01:25:09,104
event as the context,
then the counterfactual

1582
01:25:09,537 --> 01:25:12,373
the continued possibility

1583
01:25:12,574 --> 01:25:15,543
of imagining a counterfactual

1584
01:25:15,543 --> 01:25:19,114
is kind of what allows the rapid

1585
01:25:19,614 --> 01:25:24,419
moving from the training
on the side that it has been on.

1586
01:25:25,186 --> 01:25:29,023
And in one step with one gate opening,

1587
01:25:29,023 --> 01:25:34,129
we can counterfactual,
we enter into a different context.

1588
01:25:34,529 --> 01:25:37,599
And then he adds, it's bi directional

1589
01:25:38,133 --> 01:25:41,269
and the not present is that.

1590
01:25:41,269 --> 01:25:44,038
Now let me restart this literally,
he says.

1591
01:25:44,372 --> 01:25:46,741
The not present is now plus then

1592
01:25:47,509 --> 01:25:49,511
and then plus now.

1593
01:25:50,011 --> 01:25:54,482
This is our ability, both episodic
and dire, chronic continuity.

1594
01:25:54,716 --> 01:25:59,220
That is the
what if the mind can work out. Yes.

1595
01:26:00,321 --> 01:26:02,524
And that's that's
that's the beautiful part, right?

1596
01:26:02,524 --> 01:26:06,861
I mean, our mind can essentially
by this gate openings create

1597
01:26:08,163 --> 01:26:12,834
a switch between alternative events

1598
01:26:12,867 --> 01:26:16,771
or event sub
event components switched entity property

1599
01:26:17,839 --> 01:26:19,941
switch other aspects of it.

1600
01:26:19,941 --> 01:26:21,943
And and and.

1601
01:26:22,210 --> 01:26:24,612
It not needs to do
so it's not only doing this

1602
01:26:24,612 --> 01:26:27,715
by randomly switching these things
because it usually switches them

1603
01:26:27,715 --> 01:26:31,386
very systematically in a meaningful
manner that actually the consequence

1604
01:26:31,386 --> 01:26:34,389
of an event actually changes as well.

1605
01:26:34,389 --> 01:26:34,622
Right.

1606
01:26:34,622 --> 01:26:38,393
Because you usually do what if questions
that actually change to further.

1607
01:26:38,393 --> 01:26:39,794
Event progression.

1608
01:26:39,794 --> 01:26:41,296
And you can do this.

1609
01:26:41,296 --> 01:26:43,731
Mentally really well and I think the.

1610
01:26:43,731 --> 01:26:46,901
This essentially. Can.

1611
01:26:47,969 --> 01:26:52,240
Could be done and should be further
explored with such gating mechanisms,

1612
01:26:52,807 --> 01:26:56,010
really core component for future research

1613
01:26:56,110 --> 01:27:01,282
think to really show that such systems
not only are able to explain events,

1614
01:27:01,516 --> 01:27:05,720
but can also really reason
in terms of counterfactual madness,

1615
01:27:05,720 --> 01:27:09,691
then saying, well,
if I switch, if this property

1616
01:27:09,691 --> 01:27:13,995
would have been different, then actually
the other thing would have not happened.

1617
01:27:14,295 --> 01:27:20,235
This is actually also really important
to assign blame, for example, to people.

1618
01:27:21,336 --> 01:27:21,736
Would.

1619
01:27:21,736 --> 01:27:26,040
What you not have shot the ball
or something like this and.

1620
01:27:26,441 --> 01:27:27,242
That's.

1621
01:27:27,242 --> 01:27:28,576
That's also very socially.

1622
01:27:28,576 --> 01:27:30,645
Relevant lo and behold there.

1623
01:27:31,713 --> 01:27:34,682
As well as designing education

1624
01:27:35,250 --> 01:27:37,719
and thinking about when are we trying to

1625
01:27:37,752 --> 01:27:42,123
when are we fine tuning
but not opening or changing a gate?

1626
01:27:42,624 --> 01:27:44,659
And then it made me think about that

1627
01:27:45,393 --> 01:27:50,064
equation which you did an awesome job
to walk through and showed read it

1628
01:27:50,064 --> 01:27:52,934
because like sensory motor inputs

1629
01:27:53,635 --> 01:27:56,137
the the equation is a linear string,

1630
01:27:56,738 --> 01:27:59,741
but then we can engage
in this counterfactual.

1631
01:27:59,774 --> 01:28:04,646
What if the inference on observables
weren't conditioned on policy

1632
01:28:05,079 --> 01:28:08,549
and actually to have competency with
those equations

1633
01:28:09,050 --> 01:28:12,553
is to know a little bit
about counterfactuals.

1634
01:28:12,553 --> 01:28:16,724
And then on the cutting edge
you're drawing from other fields

1635
01:28:16,724 --> 01:28:21,195
and you're asking looking at pazuello
and Friston at all 2015

1636
01:28:21,195 --> 01:28:24,198
and then asking, well,
what if this formalism included

1637
01:28:24,966 --> 01:28:27,335
another event based

1638
01:28:27,335 --> 01:28:30,705
cognitive framework
that was not previously connected?

1639
01:28:30,938 --> 01:28:33,875
So it's like the learning trajectory
for those of us

1640
01:28:34,442 --> 01:28:38,780
who are learning the equations includes
the counterfactuals and the gate opening,

1641
01:28:38,946 --> 01:28:44,018
and then research is just kind of
going one step further.

1642
01:28:44,018 --> 01:28:47,855
And so just made me wonder
about how we design education

1643
01:28:47,855 --> 01:28:55,063
to accommodate this kind of gate
opening and counterfactual space.

1644
01:28:55,063 --> 01:28:57,432
How we accommodate education,

1645
01:28:58,966 --> 01:28:59,701
the what?

1646
01:28:59,701 --> 01:29:01,903
What for what kind of education you mean?

1647
01:29:02,804 --> 01:29:06,274
Yes, what.

1648
01:29:06,741 --> 01:29:08,409
Which education you're referring.

1649
01:29:08,409 --> 01:29:10,478
To the.

1650
01:29:10,478 --> 01:29:11,446
Human.

1651
01:29:11,446 --> 01:29:14,749
Human education
for learning, active inference

1652
01:29:14,749 --> 01:29:18,086
or for learning another area?

1653
01:29:18,086 --> 01:29:20,521
Yeah, I think it's good

1654
01:29:21,556 --> 01:29:23,925
and interesting. If I.

1655
01:29:23,925 --> 01:29:29,263
Thought I would say it's it's
I think it's.

1656
01:29:29,263 --> 01:29:32,233
Extremely useful for sure to know

1657
01:29:32,533 --> 01:29:35,069
particularly also
to look at the equations and.

1658
01:29:35,069 --> 01:29:37,138
And analyze. Their components.

1659
01:29:37,705 --> 01:29:39,140
And then.

1660
01:29:39,273 --> 01:29:43,277
Progressively also enhance them
or selectively compact them, take

1661
01:29:44,011 --> 01:29:46,514
kick away the one segment or the other

1662
01:29:46,514 --> 01:29:48,583
and then you see exactly
what's happening. So

1663
01:29:49,684 --> 01:29:52,253
I guess hopefully this was educational.

1664
01:29:52,320 --> 01:29:55,156
How I presented it, I guess.

1665
01:29:55,156 --> 01:29:57,725
It's a flow of sensory inputs

1666
01:29:58,726 --> 01:30:01,195
and then there's some discrete.

1667
01:30:01,262 --> 01:30:01,996
Structures.

1668
01:30:01,996 --> 01:30:04,465
If you think about the individual

1669
01:30:05,199 --> 01:30:08,469
components in the equation
as as event components,

1670
01:30:08,469 --> 01:30:11,572
in the sense.

1671
01:30:11,572 --> 01:30:13,508
Very cool.

1672
01:30:13,508 --> 01:30:17,145
I have one more question
and then maybe any closing thoughts

1673
01:30:17,545 --> 01:30:20,314
you mentioned,
you know, the Zoom room or the

1674
01:30:20,314 --> 01:30:23,551
the Gizzi room, online
events, calendar events.

1675
01:30:23,551 --> 01:30:27,722
Do we all get invited to?

1676
01:30:27,722 --> 01:30:32,994
That's just very interesting
with how we're bringing our evolutionary

1677
01:30:32,994 --> 01:30:38,299
and our ecological behavioral embodiments
into, the digital space.

1678
01:30:38,900 --> 01:30:39,434
And so

1679
01:30:40,701 --> 01:30:43,704
what does it bode for online events,

1680
01:30:44,272 --> 01:30:49,177
thinking beyond just webinars, but like
how do we think about online events?

1681
01:30:49,177 --> 01:30:51,412
Because in one sense,
you're very local to me.

1682
01:30:51,412 --> 01:30:53,114
You're in my headphones

1683
01:30:53,114 --> 01:30:57,218
giving me the sensory flow,
but you're on a different continent.

1684
01:30:57,452 --> 01:31:01,122
And so where do you think or what
theoretical questions

1685
01:31:01,122 --> 01:31:02,223
or applied questions does it

1686
01:31:02,223 --> 01:31:05,293
raise to think about online events,
which are a novel affordances

1687
01:31:05,526 --> 01:31:11,933
from an evolutionary perspective?

1688
01:31:11,933 --> 01:31:16,671
I mean, I think for the one for the one
good of it,

1689
01:31:16,671 --> 01:31:20,074
they have shown us
that we don't need to fly as much around

1690
01:31:20,074 --> 01:31:22,477
the globe
as we have done before the pandemic,

1691
01:31:23,144 --> 01:31:26,214
which is probably
a really good thing for our planet.

1692
01:31:26,214 --> 01:31:27,748
And we should acknowledge this.

1693
01:31:27,748 --> 01:31:29,784
And accept. This. I think

1694
01:31:31,886 --> 01:31:33,621
I have the impression that

1695
01:31:33,621 --> 01:31:36,591
particularly older colleagues
have issues for that.

1696
01:31:37,124 --> 01:31:39,961
And I think it's.

1697
01:31:40,127 --> 01:31:45,132
It's a very good and important thing
that we should be all aware of.

1698
01:31:45,132 --> 01:31:47,535
That and.

1699
01:31:48,236 --> 01:31:51,772
Shout it out loud as I do right
now, that why. Now?

1700
01:31:52,440 --> 01:31:53,174
And the.

1701
01:31:53,174 --> 01:31:55,042
Very severe situation for our.

1702
01:31:55,042 --> 01:31:56,944
World and this.

1703
01:31:56,944 --> 01:32:00,615
Pandemic has shown us
also and even shows us now

1704
01:32:00,615 --> 01:32:05,019
how we humans are so easily able. To.

1705
01:32:05,386 --> 01:32:09,023
Neglect things or deny things
that are so obvious

1706
01:32:09,023 --> 01:32:11,058
that they are occurring, which.

1707
01:32:11,459 --> 01:32:12,860
Very scary and very.

1708
01:32:12,860 --> 01:32:17,665
Unfortunate for our own future.

1709
01:32:17,665 --> 01:32:23,371
Meanwhile, saying this,
I think it was a great opportunity to

1710
01:32:24,906 --> 01:32:26,474
for all of us

1711
01:32:26,474 --> 01:32:30,077
to acknowledge that video cards
like this work really well.

1712
01:32:30,912 --> 01:32:33,848
And of course, after one
and a half years of pandemic,

1713
01:32:33,848 --> 01:32:36,450
I guess all of you guys also. Enjoy.

1714
01:32:37,618 --> 01:32:39,654
Local meetings again. And.

1715
01:32:39,654 --> 01:32:40,955
Going out with other people.

1716
01:32:40,955 --> 01:32:42,857
So we also see how

1717
01:32:42,857 --> 01:32:47,194
social we creatures are
and what is missing in such video calls.

1718
01:32:47,662 --> 01:32:47,995
Which is.

1719
01:32:47,995 --> 01:32:52,567
Of course, the personal interaction
and really the development of

1720
01:32:52,567 --> 01:32:56,504
of getting a feel of how the other person
really takes us personally.

1721
01:32:56,504 --> 01:33:00,341
And when you can make a statement
about what's actually

1722
01:33:00,341 --> 01:33:04,245
happening and through life out there,
that's of course, very different.

1723
01:33:04,245 --> 01:33:07,381
Unfortunately,
not possible via Zoom calls.

1724
01:33:08,482 --> 01:33:11,252
But so I can only urge everybody that.

1725
01:33:13,354 --> 01:33:15,122
We should be aware that

1726
01:33:15,122 --> 01:33:18,526
when we fly around the world,
we better make it worthwhile.

1727
01:33:18,526 --> 01:33:20,761
And on to
it is only for a couple of days.

1728
01:33:22,530 --> 01:33:25,600
It Made me think of a trilemma fly.

1729
01:33:25,600 --> 01:33:27,101
We could have met in person, you know.

1730
01:33:27,101 --> 01:33:29,270
We could have met in Iceland
or something. Somewhere in the middle.

1731
01:33:30,638 --> 01:33:33,341
There is an impact in the hardware

1732
01:33:33,341 --> 01:33:38,613
and the bandwidth of a video call,
and that impact is very cloaked.

1733
01:33:39,246 --> 01:33:42,049
And then there's also machine
learning models.

1734
01:33:42,049 --> 01:33:46,787
And so maybe somehow I don't know
if X is the impact of a flight

1735
01:33:47,655 --> 01:33:50,992
is a video call 0.1 or 1,000th

1736
01:33:50,992 --> 01:33:54,428
or one millionth of a flight,
and making some of these

1737
01:33:56,163 --> 01:33:59,433
impacts that are very real clearer

1738
01:33:59,667 --> 01:34:02,637
so that we can design events

1739
01:34:03,404 --> 01:34:06,807
that are policies
that align with our preferences

1740
01:34:07,475 --> 01:34:10,978
to reduce our uncertainty
and to connect socially,

1741
01:34:10,978 --> 01:34:14,982
but also to pragmatically keep certain

1742
01:34:14,982 --> 01:34:17,985
ecological parameters
within a region that we can

1743
01:34:19,420 --> 01:34:20,321
thrive in

1744
01:34:21,656 --> 01:34:23,557
case. Absolutely, that would be good.

1745
01:34:23,557 --> 01:34:26,427
I mean, a video call it certainly
if less than a million,

1746
01:34:26,527 --> 01:34:30,331
I think I'm a flight,
although of course, it is significant.

1747
01:34:30,331 --> 01:34:33,067
But it's I mean, incomparably less.

1748
01:34:34,935 --> 01:34:36,404
And but.

1749
01:34:36,404 --> 01:34:41,876
Nonetheless, one has to be,
of course, also be aware that,

1750
01:34:41,876 --> 01:34:45,513
unfortunately, we are in a situation
where we really need global efforts.

1751
01:34:46,047 --> 01:34:49,717
So one cannot really point fingers
to individual persons

1752
01:34:49,717 --> 01:34:53,587
because we need global
policy changes to save our.

1753
01:34:53,621 --> 01:34:57,758
Own world and our future of our children.

1754
01:34:57,758 --> 01:35:00,027
And I have three kids. And.

1755
01:35:00,161 --> 01:35:03,764
I'm very concerned.

1756
01:35:03,764 --> 01:35:06,867
Do you have anything that you'd like
to just leave us with or.

1757
01:35:06,867 --> 01:35:10,171
That's a perfect closing note?

1758
01:35:10,171 --> 01:35:12,840
No, I don't want to leave
on the downside.

1759
01:35:13,441 --> 01:35:13,741
Sure.

1760
01:35:13,741 --> 01:35:17,978
But it's a great pleasure to
to do this with you guys.

1761
01:35:17,978 --> 01:35:20,414
And now we drift
a little bit to the climate.

1762
01:35:20,414 --> 01:35:21,148
And I'm.

1763
01:35:21,382 --> 01:35:24,218
I'm. Thankful
that we also can talk about this.

1764
01:35:24,585 --> 01:35:25,319
A little bit.

1765
01:35:25,319 --> 01:35:28,289
And but I hope it's I mean.

1766
01:35:28,289 --> 01:35:31,892
It's hopefully you also see
that it's an amazingly exciting topic.

1767
01:35:32,393 --> 01:35:34,528
And not only.

1768
01:35:34,528 --> 01:35:37,198
One inside how our human mind works.

1769
01:35:37,198 --> 01:35:38,132
And how.

1770
01:35:38,132 --> 01:35:43,237
We manage to be as intelligent,
but also as limited as we.

1771
01:35:43,237 --> 01:35:44,805
Are in the end.

1772
01:35:44,805 --> 01:35:48,642
And but meanwhile, I also I think it

1773
01:35:48,642 --> 01:35:52,413
has certainly I mean, this

1774
01:35:53,981 --> 01:35:58,018
is amazingly
developing over the last couple of years.

1775
01:35:58,018 --> 01:36:00,654
And yes, and.

1776
01:36:00,654 --> 01:36:03,190
There I guess also things go so far.

1777
01:36:03,190 --> 01:36:05,659
So it's important that. We.

1778
01:36:06,327 --> 01:36:09,363
Think about the dangerous of AI.

1779
01:36:09,363 --> 01:36:10,631
And unfortunately,

1780
01:36:10,631 --> 01:36:14,602
as we have seen this, Cambridge
Analytica is only an example of what is.

1781
01:36:14,602 --> 01:36:16,837
Going on right now.

1782
01:36:16,837 --> 01:36:17,671
In terms of.

1783
01:36:17,671 --> 01:36:20,341
AI driven, targeted.

1784
01:36:21,375 --> 01:36:24,979
Influence of our own selves and our way.

1785
01:36:24,979 --> 01:36:26,981
We think about stuff and our beliefs

1786
01:36:27,581 --> 01:36:31,886
and hopefully we will manage
also to foster this awareness of this

1787
01:36:31,886 --> 01:36:37,057
and thus be more ready to contact it
and find back to our.

1788
01:36:37,625 --> 01:36:39,593
Beautiful human social.

1789
01:36:39,593 --> 01:36:41,262
Abilities.

1790
01:36:41,729 --> 01:36:46,000
Thank you for that
excellent and uplifting note.

1791
01:36:46,567 --> 01:36:47,968
It was really an honor.

1792
01:36:47,968 --> 01:36:50,704
Martin So thanks again
for the presentation and the chat.

1793
01:36:50,704 --> 01:36:52,907
Really appreciate it as well.

1794
01:36:52,907 --> 01:36:55,342
You and any colleagues are always
welcome to

1795
01:36:55,776 --> 01:36:59,280
come on a live stream or to get involved
in the act and flop in any way.

1796
01:36:59,380 --> 01:37:03,284
So this was just a great conversation
and it was hopefully very informative for

1797
01:37:03,284 --> 01:37:04,218
our audience as well.

1798
01:37:05,252 --> 01:37:06,420
I hope so too.

1799
01:37:06,420 --> 01:37:09,890
Thanks for inviting me here
and thanks for running this lab.

1800
01:37:09,890 --> 01:37:13,194
It seems to be a really good group
and I hope we can stay in contact

1801
01:37:13,194 --> 01:37:15,663
over the next month. And yes.

1802
01:37:15,663 --> 01:37:17,331
Thank you. We will.

1803
01:37:17,431 --> 01:37:19,200
Okay. Take care.

1804
01:37:19,200 --> 01:37:21,235
See you. Bye bye.

1805
01:37:21,235 --> 01:37:41,522
Thank you.
