SPEAKER_03:
Hello everyone.

It's April 25th, 2022.

We're here with Adam Saffron and today we're going to be having a guest stream, the radically embodied conscious cybernetic Bayesian brain from free energy to free will and back again.

So Adam, thanks a ton for joining on this day.

Really looking forward to your presentations and thanks again, Adam, take it away.


SPEAKER_01:
Thank you for inviting me and letting me come to talk with you.

I'll present some ideas from a recent manuscript in entropy called The Radically Embodied Conscious Cybernetic Bayesian Brain, From Free Energy to Free Will and Back Again.

After that, looking forward to discussing some of the ideas with all of you.

And hopefully this is the beginning of an ongoing conversation.

So what I tried to do with this manuscript was basically marry good old fashioned cognitive science with a more an activist perspective, trying to find a middle way between these ways of viewing of things.

And this is the view that I've come to over a number of years, where

The idea being that embodiment, at this point, it's not news that the mind is embodied, but the claim is that it is very, very embodied.

Some would say radically embodied.

I'm not sure if that made the most sense to use that term because the term radical with respect to embodiment is usually pointing to a perspective or radical inactivism

that avoids talking about representations or models and instead is saying you know what's really going on is these couplings with the world and maybe you could say there's like an implicit information processing or intelligence even that might be objected to but these talk of representations and symbols and models from cognitive science um that's those are not real things

And so this paper goes through a perspective in which basically we do have representations and models, and we also have these sort of inactive couplings with the world.

And I say it's radical in that nearly every mental process you would care to talk about, the way you have to understand it according to this view would be first and fundamentally and foremost in terms of its embodied character.

So before I move on, is everything coming across clearly?

Okay, sound.


SPEAKER_03:
Yeah, I did disable my video because due to some incredible consequences of different situations, I'm using a hotspot, but it's all good.


SPEAKER_01:
Okay, you're on the run.

Okay.

uh... so

To review a little background, I mean, a lot of this people who were watching this were familiar with, but I'll review some background on predictive processing and active inference.

Maybe some of what I'll present is a somewhat heterodox view.

That's also something to discuss.

So a basic account of predictive coding, you have these deep pyramidal neurons, and you have these superficial pyramidal neurons.

where they're deep with respect to cortex as having this layered structure, roughly six layers with some variations on the theme depending on where you look.

And the idea is that the cortex as a whole is engaging in what's sometimes called hierarchical or what's often called

hierarchical predictive coding or potentially predictive processing because there might be some assumptions with saying predictive coding that not everyone would sign up for, such as that you are only suppressing and explaining away information as opposed to sometimes enhancing it.

And there's other nuances that could make people object to saying predictive coding.

Instead of getting into those weeds, the idea would be that you have this hierarchy of beliefs, implicit and neuronal organization.

The nature of these beliefs, and this gets into these debates about representation and inactivism, but this idea that

You could say there's an implicit belief at each neuron and set of neurons about what they expect, what patterns they expect to encounter.

And according to this predictive processing view, through their activity, they're trying to predict this incoming activity and suppress it or explain it away to minimize overall activity, and that you only update these beliefs where you got it wrong via a prediction error.

And this is under certain assumptions.

If you have a good model and events in the world are relatively slow relative to your internal signaling units, you can have substantial energetic savings for an organ of about 2% of your body mass and 20% of your metabolism.

Seems like the kind of thing natural selection would do, and there's some decent evidence for this.

So the basics of neural architecture here for Cortex is viewing it as a predictive processing hierarchy or a heterarchy, and that each of your modalities would be a different belief hierarchy, and they would all come together and exchange their information for a joint belief.

across all your modalities in terms of what you think should be in your sensorium as it moves through the world, whether it's the world you're in right now or some sort of counterfactual world in the present or future.

So that's predictive processing in a nutshell.

And so in this account, the goal was to use

predictive processing to try to get into the micro mechanics of goal oriented behavior and agency.

And so what I suggested is that the work has been done within active inference on this sort of imaginative planning

pursuing of goals, the work to refer to would be sophisticated inference or sophisticated affective inference, which is thinking about basically planning into the future as this tree search of possibilities where you're going on different branches of these possibilities and then picking the ones either in imagination or in reality that would correspond to you, minimizing your prediction error the best or realizing value the best.

this exploration of a tree of possibilities and going down different branches.

And so this would be, I suppose, a particular flavor of this.

And the idea being that a lot of what would be pulling along this stream of consciousness of imaginings would be this iterative comparison between sensed and imagined states or between various goal states.

So here I have this comic book that a friend helped me make.

And I have multiple comics throughout.

I tend to view comics as being really highly expressive in a way that I think we should probably use them more in terms of being able to capture the joints and experience space with sufficient richness and detail.

And there could even be something like comic book-esque about the stream of experience, which could be part of the reason that they're so effective.

But to return to this comic or a modal frame sequence as I sometimes call it, you see in the bottom here this is the actual pose of the agent and up top what's going through the mind's eye whether we're talking about an imagination or a perception.

And so here it's just a simple contrasting of what you're perceiving in each given moment and then what you're imagining.

So you're sitting, you want tea,

You then look and you say, I am not drinking tea.

I am at my computer, and there is a laptop in front of me.

You look down, and you're imagining having tea in your cup.

But then you look, and no, there is indeed no tea.

And then you imagine a next step.

And so what's happening here is you're doing this contrast.

And what I propose is that in contrasting between these states,

they're arranging they're basically setting up prediction errors for each other where what doesn't match would potentially get you a natural prioritization of what features are unaligned and then from those you use that to retrieve some sort of relevant affordance to help you bridge this gap between your imagination and reality and

And there's a lot of devils in details of the ways this could work, but that some sort of iterative contrasting of goal states and a goal hierarchy where it's like you might have an ultimate goal, but to achieve that goal, you have to now go and think of what are all of the sub steps and the sub goals that would be needed to actually get the tea in my hand.

You're going to have to ambulate to the kitchen, make the tea, et cetera, et cetera.

And as you're going back and forth at some place, some point, you either have a plan that's compelling enough or the next action is close enough to your present pose that you just find yourself launching into action, sometimes accompanied by a feeling of having decided.

Sometimes you just find yourself moving.

But that's the basic account here, that the stream of consciousness is being pulled along in this goal-oriented fashion, this value-driven fashion, sometimes more freely wandering, but usually there's an interest.

And as an active inference in predictive processing, your preferences or your attracting states, the attractors that you'll find them as a system, which you're attracted to,

takes the form of predictions.

And so the things in your mind that you're imagining that they become the goal state, they become the state of the world that you prefer, in that instance, or in general, if it's a regular kind of imagining, and this now becomes the attracting state that your system self organizes, and you engage in action selection of different kinds to minimize that difference between what you're imagining, and what you are estimating for the world.

So I go into some discussion of neural architecture and different aspects that might be more or less relevant for different of this kind of action selection.

I probably should have just thrown this on top of a picture of a brain, but I didn't.

But in some ways, it might be a good thing.

And I wonder whether this account of having a dual tier system

Something like a system 1 and a system 2 is a broader story than just brains.

And so I have written out here, like, here would be neural substrates of what would enable you to do this.

But well, it could be across brains.

You might have similar processes happening within, let's say, like an insect nervous system by different means.

Like instead of the basal ganglia, you might be using the mushroom bodies.

If we're talking about an ant colony, for instance, it's possible you have a different attracting states of the colony where some are taking this role of a higher-level controller and a lower-level controller.

But the basic idea here is that you have an upper-level controller that's capable of aggregating information across different... So you have this lower-level process in this control hierarchy where the lower level is...

taking care of your immediate couplings with the world.

This would be the more inactive portion.

If we're talking about the brain, it would be something like loosely assembled constellation of cortical reactive dispositions, maybe orchestrated by the cerebellar system, of what would be called amortized inference.

And it would be largely unconscious and automatic.

Phenomenologists would talk about just things being

ready at hand, as opposed to being present to hand.

You're just effortless engagement and effortless mastery with the world.

But on top of this, you have a slower process.

In this case, I'm saying it's more involving conscious processing, something more system two-like, to use Kahneman's language, where it's involved in more deliberate, potentially effortful modes of cognition,

which would be a higher level of control over this faster, smooth coupling system.

So go into some details of neural architecture.

Potentially, this might be just what you need for a lot of active inferential agents, something like this across whether or not we're talking about neurons.

This might be a broader story for active inferential agents.

So to return to the example of making tea, go into it some.

We're saying that we're back to the mouse brains.

Here in the brain, areas associated with mental imagery, maybe even physical and computational substrates

mental imagery phenomenality itself, but like the Protonius, for instance, involved in imagination have heavily implicated multiple reasons to think why this would be the case.

But I have this little Cartesian theater here with the different imaginings.

And down below, the idea is you are iterating through different imaginings largely via large-scale orchestration by the hippocampal complex and its capacities to couple with the rest of the cortex to guide these high-level attracting states where some portions of which would be your experience.

And so the reason you would bring up the hippocampus in here is it seems to be a specialized subsystem for sequential predictive modeling.

You could say that for cortex as a whole.

Technically, hippocampus is a kind of cortex, arcade cortex, old vintage.

But that basically, so Damasio will talk about this in terms of a convergence-divergence zone, where many things will funnel in and then funnel back with high centrality.

I forget his name.

He's at Waterloo, the spawn architecture.

But he'll talk about semantic pointers.

But there's different ways of viewing the high centrality of hippocampus as it basically will predict this trajectory of the overall organism through space.

You can both encode memories, what was happening in my storium, whether in reality or imagination, at each point as I was moving through space and time.

And you could also use it for replay, including in counterfactual circumstances.

And so I have some diagrams here of the neural systems involved.

And right here, you'd have the, I think that's good for now.

So anyone wants to know more details about that later, we could.

So to return to trying to go more phenomenological, so these modal frame sequences are comics.

Ultimately, what I'm trying to build up to is a sufficiently detailed account of neural architecture and a sufficiently detailed account of phenomenology so that we can basically talk about something as highfalutin as free will and have some purchase.

So in this complex modal frame sequence, you have that up top and imagining row.

Below that you have what's actually in your perception.

Below that you have your pose and your proprioceptive inference.

And then below that you have your interoceptive inference.

So as you're stepping through, the stream of consciousness is evolving through space and time, encoded or orchestrated by the hippocampal system at this high, potentially most integrative high level of action selection.

you are having different wounds in your body corresponding to the interoceptive concomitants of, or the interoceptive aspects of what it means to be in different situations.

So for instance, like a hunger situation here, you're getting prediction error, interoceptive prediction error that would be roughly vaguely localized here as like a cool sensation around your gut and mouth or thirst or hunger, something like this.

And now as you're going into movement, you might have here like you're still having this interoceptive code of hot and cold states, pleasant and unpleasant, but it's kind of getting infused into other modalities where your proprioception, some of the phenomenology of like feeling like an urge in your body, it's one of the claims I make is that you have this kind of quasi-synesthetic cross-mapping between interoceptive signals

and the proprioceptive and exteroceptive associates.

Part of the reason I claim this and say that this is both part of the phenomenology of will and maybe part of the mechanism also is that interoceptive signals are poorly localizable in space and time.

They tend to have pretty low resolution for them.

And so they drift free from their sources.

And that's a kind of anomalous inference, but an adaptively anomalous inference

they may get infused into the relevant effector and sensor systems and objects in the worlds for which they would be relevant.

I make a lot of different claims in this work from a number of years of study.

A lot of it can be taken a la carte.

You can find some things to be more compelling, some things to be less compelling.

But I do think you get a whole that's greater than the sum of its parts.

But it can also be taken in a piecemeal fashion.

So you might not be particularly compelled by this account of interception as being synesthetic in nature.

Nothing really, not too much will ride on that, but not too much of what will follow will ride on that, but it could end up being important so I'm putting it in there.

Okay.

And so across all of this, this is happening within a perspective of computational neurophenomenology.

As Anil Seth calls it, or I call it Marian neurophenomenology.

And the reason I call it Marian is specifically his account of multiple levels of analysis, which I guess supervene on each other.

And you can do two things because things have these multiple levels that they can be engaged with.

You can either engage with them a la carte because of, let's say, for instance, you want to do cognitive science, but you have no idea how the brain works, and for many years we haven't, and there's a lot of mystery still.

You can kind of bracket, like, here's this big set of unknowns, but it's at a different level.

But working at this other level, we can obtain knowledge, even though we might be ignorant at these other levels.

And that would be functionalism and cognitive science.

But for me, what's more exciting about this actually, this Marian stack, is the capacity not for independence but interdependence and mutual constraints, using the implementation level or the mechanistic level as a constraint of what's a likely set of algorithms, using a likely set of algorithms to test hypotheses on the implementation level.

using what you think the in things like neuropsychiatric literature to constrain and the neuroimaging literature to constrain algorithm and thereby implementation.

So the idea of what excites me is like filling in this crossword puzzle, leveraging constraints, and then cross-referencing them with phenomena.

I'm using basically machine learning as a version principle and typically going to the races of this idea that a lot of cortex could be understood in terms of particle predictive problem, but also evoking some additional machine learning principles.

But that's the overall scope of it.

in terms of all the body parts and faces, this is part of the radical embodiment idea, is that instead of the cortex being this grab bag of associations with areas

What does that mean and why?

The idea is that once you really place it front and center as a cybernetic controller for an embodied embedded agent, once you place embodiment front and center, a lot of it becomes .

So for instance, if they like, OK, there's something like right around here.

So something like .

But then you're like, wait a second, that's not too many steps removed from where the ears first pipe in.

So the idea that something like

You know, going from phonemes or going from sound patterns undifferentiated to phonemes and steps, it ends up making cortex dysfunctions, in my opinion, a lot more applicable.

It becomes somewhat like location, location, location, and location relative to the modalities.

It ends up explaining a lot of things.

A similar story for Broca's area.

What a coincidence that it's a hop, skip, and a jump away from what might move your mouth bits.

There's doubles in details here.

I don't want to be glib and underestimate the complexity.

But the claim is that actually once you place embodiment in the center, an elegance kind of falls out and becomes a lot easier to keep track of things.

If you're thinking of cortex as this control, cybernetic control hierarchy over to basically help a body move through the world and model the world as it moves through it.

So we are ready, I think, to get to free will.

And so taking these modal frame sequences, and here is doing one for this experience of standing to make tea.

and then taking that model and then porting it to a Lebet experiment.

So what is a Lebet paradigm?

So some people say Lebet, some people say Lebet.

I think Lebet said Lebet, but I'll continue to say Lebet because it's more common, and I just will.

But the idea is that you're there and you want to see, do people or don't they have something like meaningful conscious control over their actions?

And so the idea is, okay, let's strip this down and take the most insignificant of all actions.

It's like, well, surely we need to have control there if we're going to say we have control anyway.

And so the decision to just move your hand based on feeling like you want to do so.

And this coming from basically it's endogenous.

It's not being decided from without, but you doing something based on something internal to you.

And what was found with the Labette studies, or Labet, is that you get this ramping activity preceding the decision to move your hand.

You have this clock, right?

And it's a big clock that you're looking at.

And it might be a dot or a big hand moving in a circle.

And the reason that you have this is basically so that you can estimate the time when it was that you said, I will move my hand.

When did you decide?

And you then say, OK, when you made that decision, what were you looking at?

Where was this dot as it moved around in a circle?

And this can get you very fine resolution, sub-second resolution, because if it's a big clock, then the dot will be moving slowly.

And you can say, OK, it was right there.

But what's observed is that you're getting this ramping activity with this predictive of the action called the readiness potential.

And it will peak a good 200 milliseconds before you reporting, it varies, but it'll peak substantially before you saying, I've decided.

And so if

And so the claim is, well, if this potential has predictive information of your action and is the cause of your action, and it's happening prior to your conscious decision, your decision cannot be the thing that caused the action.

There's a problem right away with this in that with ERP methods, you're actually averaging over many, many trials to get these waveforms because you're measuring from the outside of the brain.

It's like trying to detect events inside a stadium while measuring, like listening to the roar of the crowd on the outside.

And you're limited in what you can do.

So you have to average together a lot of different episodes.

And then you get these event-related potentials or ERPs.

so you get predictive information from this of when people moved but the idea that a readiness potential is causal or deterministic in some fashion there's some debate about that whether you can infer that um i'm going to say that the readiness potential is in fact reflecting a causal process um and it's reflecting a conscious causal process even

that is contributing to the action um upstream of um the decision itself where the decision could have some more you know depends on i don't know if there's one account but it could have some epiphenomenal aspects to it and that the decision is not necessarily um the thing it's it's not the only uh difference maker there but the idea is that this

is a function of mental imagery where you are imagining will and won't move.

And as you're rehearsing, moving your hand, you're having different things associated with it.

And that building up of that recurring, a building up of activity in these body maps

whether we're talking about getting ready to actually change your proprioceptive pose as you're imagining, starting to move closer to a threshold where you're going to get robust enough activity that is actually going to drive your muscles and your affector systems, or building up activity in your interoceptive modalities, like your insular and cingulate hierarchies and maybe their synesthetically cross-couplings with other modalities, that that building up of a feeling of urge is itself consciousness leading to the stream

the causal stream of action.

So that I would say, so yeah, the, and then on top of all the different imaginings would be orchestrated by the capital system would be the basic model.

So currently, and so, and, and,

So currently, I am working on expanding this to seeing what different states of consciousness, the ways in which they could impact these sorts of phenomena in terms of changing your awareness of this rehearsal process or changing one of the primary things of interest.

So and also whether differences in the mechanisms of agency could potentially contribute to the phenomenology of psychedelics.

I'll try to explain what I mean.

So here would be someone relatively unaltered, engaging in mental rehearsal.

Their mind's sort of wandering off to nature.

They're seeing a tree.

Here's imagination.

Here's perception.

Here, more vivid than imagination.

And they're just sort of imagining things, imagining, will I move?

Won't I move?

And then at a certain point,

imagination becomes vivid enough that they can really see it happening.

And at a certain point of vividness of imaginings as a function of this rehearsal of will I move, won't I move, you get enough buildup of whether we're on the implementation level or mechanistic level, we might talk about recurrent activity.

In terms of active inference on the functional level, we might talk about model evidence.

But at a certain point, you cross a certain threshold, leading to model selection of you altering your proprioceptive pose and this becoming a self-fulfilling prophecy through active inference.

You then minimize the prediction error between your imagination, I am moving, and the action through reflex arcs, the way that basically motor control is thought to work in active inference.

and predictive processing.

So the psychedelic angle would be, as someone is dosing with these compounds, their imagination becomes more vivid.

And they might show stronger ramping at first and maybe greater awareness of these patterns of mental stimulation leading up to the action.

It might get stronger still as you dose more and more.

Also greater coupling between interoceptive and proprioceptive modalities, increasing the gain on this positive feedback between mental imagery and feelings of urge.

And so in a way, this would be an enhancement of the willing aspect of agency as you move up this dose response curve.

But then you get to a certain level and you start to get into this psychedelic regime where your thought becomes highly creative.

And then your directed willing might start to go down.

Potentially, the idea is you might find other things competing for your awareness, different creative possibilities.

So you're now imagining nature very vividly, and this is competing with you rehearsing, will I move or won't I move?

And less predicting I'm about to move.

And as you come up with the dose, these inferences, you directing a certain move might become less and less.

Extremely high doses, you might get a compromise of these mechanisms of agency, of this conjoining of your interoceptive and your proprioceptive predictions of your basically

of your stream of consciousness being pulled along by value-driven policy selection via sophisticated affective inference.

So I think the reverse direction is this in terms of

this paradigm potentially informing psychedelics could be that one source of hallucinations or delusions or atypical altered consciousness and cognition would be that if you take the basic micro mechanics of agency,

And you compromise that.

So as you're beginning to somewhat imagine an action, but it's not well integrated into some causal unfolding, you could come to this anomalous inferences about what's causing these basically

The different endogenous activity in your brain, the different events that could lead to motor actions, if these aren't being integrated into a self-consistent, coherent causal unfolding, one of the ways that you could try to make sense of this would be a confabulation of something like a hallucination.

And so this could potentially

also explain some of psychedelic phenomenology and potentially clinical neuropsychiatric phenomenology with things like schizophrenia as potentially being a function of disrupted agency mechanisms.

So that's currently the area of focus.

And a preprint just came out on that called On the Degrees of Freedom Worth Having.


SPEAKER_03:
psychedelics as a window for understanding and expanding uh free will I believe that's what I called it and so that would be a little bit um also apologies if there's any strange stream hiccups but could you maybe unpack what the alien or extraterrestrial was doing and how does the confabulation relate to a narrative understanding of action


SPEAKER_01:
So in this one, so we're starting out just imagining your hand moving or imagining being in nature.

And then same here as the dose goes up.

And it goes up, and you might start to get some more intense interoceptive sensations.

The 5-HT2A receptors, which heavily mediate the effects of classic psychedelics, they're highly expressed in the interior insula, the top of the interoceptive hierarchy.

And so you keep going up.

The sensations become more intense.

Imagination becomes closer to reality.

And so here, what I'm calling the heroic dose and this extreme dose regimes,

you're starting to get for instance like your ownership of the actions are starting to get undermined so here i'm depicting like you find your hand moving but you're not accounting for your willing of the move being the thing you're not saying oh i was rehearsing it and it felt this way and that was part of the causal stream into action you just found yourself moving and

And so one way you could make sense of this or confabulate around this here is a hand, like it's a feeling of the hand pushing down on your hand from without, just an example of a potential confabulation or hallucination someone might have.

And this one here, it's expanded, and it's basically someone, it's not even your hand anymore pressing it, but an alien's pressing it.

It's just an example of, for instance, so psychedelics, the classic psychedelics will act on these 5-HT2A receptors.

They are heavily expressed on these deep pyramidal neurons of cortex's six layers.

The layer five, well, basically, they're big neurons that loop with the thalamus.

And they let you form these broad synchronous complexes, which in predictive processing are thought to encode your beliefs, some subset of which would be your experience.

And so if you increase the gain on these, the idea is that you might have enhanced perceptual vividness.

But because, though, you've done a radical alteration of multiple kinds to the normal regime of processing in your mind, the normal ways you would model,

even though you're experiencing things intensely, this would potentially be of an atypical variety of experience.

And so here is the intense perception, apperception of the alien.

It's a counterfactual alien.

It's not actually an alien.

That would be an example of an anomalous inference you might make.

And it has some relation to what's happening and the fact that maybe there was some motor rehearsal going on, but you're not able to keep track of it.

And here, you're actually having phenomenal consciousness in each of these moments, but you don't have conscious access unless in these iterative moments of experience

you can somehow get callbacks where things can be contextualized within some sort of causal unfolding.

The claim would be that basically this would be a way of separating out phenomenal consciousness from conscious access, that there's things that can happen as you're generating these quail states as estimates of what's happening of system world, system world, system world, specifically your sensorium as you think it is based on your current engagement or in counterfactual circumstances.

and that that's the stream of consciousness, but that not all of the frames of experience are accessible or rememberable.

And so in this case here, maybe there was some rehearsal, but you're not keeping track of it.

And then the best causal account you were able to come up with was that an alien made you do it.

And you might have even forgotten that this was you, or maybe you do remember it, but would need probably some more contextualization or not.

It's unclear.

So that would be the basic idea is that psychedelics would be increasing consciousness level or the vividness of your experience, but potentially undermining the coherence in terms of causal unfoldings or your usual priors by which you structure the world in the spirit of Robin Carr at Harris and Carl Friston's Rebus model, which I'm currently discussing in the context of a broader framework that I call Albus.

But yeah, I don't know, did that help at all or?


SPEAKER_03:
Yes.

It also reminded me of what you said about the different levels and their interdependence and mutual constraints.

So it's like a sound is heard and potentially in one state of consciousness or mind or brain, it's 98% likely to be one thing and

option B and C are 1% likelihood.

And so it just goes forward with as if option A, like as if I'm in control, but then some things might happen where like that 1% chance that it is an alien gets accepted and sort of passed forward.

And then that might lead to the experience through the generative model of something that like,

was a distributional so it's like a change in quantitative distributions that leads to a qualitative change at increasingly higher and categorical and semantic experiential layers beautifully said


SPEAKER_01:
And it would depend on your cultural priors.

So whether you would call this a relaxed belief or a strengthened belief, I'm not sure.

But for instance, you might not be seeing it.

An indigenous people of South America, for instance, they might not see an alien.

It might be related to something having to do with their spirituality and whatever available myths you have.

would then go into basically this interpretation.

Your best guess, which is always wrong, sometimes useful, but your best guess of what's going on will be different depending on what they would call the set and the setting, but also where the setting is the broader cultural, the set and setting are also broader to the culture.

Not everyone will come to the inference of aliens, probably.

And actually, that's been shown, that hallucinations are culturally specific.


SPEAKER_03:
Yeah, with which kinds of extraterrestrial morphologies are seen in relationship to which are prevalent in the media and the stories of a given region.

I don't know all the details, but one can imagine.


SPEAKER_01:
like not everyone i mean like you could like say like um uh maybe there is something about like gray aliens which is like a little more archetypal i don't know if i'd say this but like uh

If you look at the eigendimensions, like morphological variation, what's relevant to us, you're just exaggerating many of the dimensions that would be relevant for us engaging in intersubjective modeling or modeling of ourselves, even for the sake of control.

So bigger hands might be important.

Where is attentional inference?

Where is this person attending to?

Where am I attending to?

So you want to know the heads and the eyes.

That's going to be really crucial.

That's a far out story, but there could be aspects that aren't just through the medium.


SPEAKER_03:
It's super interesting.

And yeah, not to go into alien stream mode, but thinking about a large headed archetype with very large dark eyes and the long fingers like you're kind of hinting at.

It's like, it's all pupil.

It's all cortex.

It doesn't have the strength, but it has a lot of nimbleness with its hands and with its body.

And so like, that's like one archetype of cognitive action.

I don't know.

And then what, maybe there's a blob and a shadow.

There's like these different archetypes, different little characters in this comic book of cognition.


SPEAKER_01:
that different from a child's um affordances too right like they're not they're not capable of like moving things around much but it's like their intentional actions are mostly like hand-eye coordination of like that's their purchase on the world that's their grip but you know for all this you know so this is the current like focus is how might psychedelics

inform our understanding of the micromechanics of agency and how might the micromechanics of agency inform our understanding of what psychedelics are doing.

That's currently one of the things I'm focusing on and about to do some experiments on at the Center for Psychedelic and Consciousness Science I'm working at at Hopkins.

fundamentally and upstream of this, the idea is that these studies, which purportedly show that there's no free will, they show no such thing.

It's very ambiguous what they're showing, and I believe if you do an active inferential handling of them, you'll actually see that there are several ways in which consciousness is contributing to causal streams leading to action, which would be having some of the varieties of free will worth having.

Is it arbitrary?

uh degrees of free will no uh are there some varieties of free will worth having that we don't have like can you just like fly all of a sudden that'd be nice that'd be worthwhile we can't do that either but if you want your beliefs and desires to be able to meaningfully said to be be able to be said to be uh

meaningful, efficient core screenings, maybe even maximally efficient core screenings of what is happening, I think we do have that.

And I think you can find this even within these Libet paradigms.

If you didn't, I think you still could have many of the varieties of free will worth having because many people have criticized and saying, oh, just moving your hand without a reason, that's not really agency.

That's not what we want from free will.

We want meaningful decisions.

Sure, but I think even though for these studies, which people often will trot out and say, look, my brain made me do it, even then, I don't think it follows that

They show that our consciousness is epiphenomenal through and through.

And I think active inference basically shows some of the particular ways that consciousness is indeed causal, even in these circumstances.

And I think that's a very big deal.

I don't know how well it's surviving the replication crisis, but there's plenty of studies showing that

some undesirable consequences of people not believing in their own free will or their own agency.

Whether or not that works, I think there is a kind of this face valid account of this and that like, kind of like Dumbo's magic feather.

So like, you know, this elephant, I'm taking this from Dan Dennett from his book, Freedom of Olives, but this elephant

has a feather that the crows told him will help him fly.

And he had his big ears, and he used them to fly when he had the feather.

But it was because he believed.

Whether or not believing in free will gives you free will, not believing you're a meaningful cause, that becomes true just by believing it.

So I think it's quite dangerous to take basically something where we have something precious, something that basically would empower us to pursue our values, and to say, based on the several studies and using the authority of science, telling people that they are not meaningful causes.

I think that's extremely pernicious.

um and i think active inference can there's already great work being done like within like the neurophilosophy of free will pushing back against this and i think active inference can help uh showing people what are the meaningful degrees of freedom that they have um and how can they be preserved and expanded wow very interesting do you have any more slides to go through or may i ask some questions uh no more slides uh


SPEAKER_03:
Okay, so those who are watching live, please feel free to ask a question.

Otherwise, I want to pick up near the beginning when you spoke about finding oneself in a stream of action.

So what is happening when we find ourself in a stream of action?

And I want to hear what you have to say and then take this to some questions about memory and free will.

But when we are suddenly aware, like, whoa, I'm on a run.

I mean, I guess I did make prior decisions about deciding and so on, but like, whoa, now my leg is moving forward.


SPEAKER_01:
So the... I imagine this varies a good amount, like as a...

ter and intra individual difference variable.

So both between and within people, you're going to get a good amount of variance on this, I think.

But the way Heidegger described it in terms of this difference between describing like hammering.

And when you're a skilled craftsperson, the hammer is in your hand and it is ready at hand.

And your mind could be elsewhere.

Or people might have the phenomenology of this.

on a run or on a drive, you might just find yourself home, you can listen to an audio book, you'll barely know you're just you have this effortless mastery of the task set.

And it's only when something goes wrong that things are brought into awareness.

And so the

It's only, and so then you get this motion between, so here's the hammer just in your hand, ready at hand to present to hand.

And now it's in the foreground.

It was initially in this unconscious or semi-conscious background.

And so like if someone's running, like for instance, they could largely be in a similar state of effortless mastery, especially because, you know, just natural pendulum motion gets you like a lot of the control that combined with some spinal pattern generators, you know, it's, and

little other tweaks it's like you barely need to do anything once you once you've been trained up but let's say you're trail running and or let's say you run and then you step on something the idea would be that this violation of your expectations would cause basically prediction error

And that this prediction error, the thing that was different.

So, okay.

So within predictive processing, part of one of this marriage between category and phenomenology where things just become unconscious and you only become conscious when you're something's wrong, you might, while being careful not to conflate levels of analysis, you could get a good amount of this just from predictive processing with a dual tier architecture.

Like if,

Basically, you're really well trained up.

You can explain things.

You can basically handle things just with these efficient, unconscious couplings, unconscious inference, and a bunch of reflex arcs being skillfully deployed, doing most of the things you need to do.

And whether you want to call this modeling or not, it would be a matter of choice.

I would call it modeling.

But you wouldn't need to become aware of it

unless something was wrong.

And so then the idea is this lower down, it's not handled.

You don't predict it.

You don't explain away the prediction error.

It makes its way deeper into the brain, into the... It becomes more broadly... The deeper portion is, of course, it's... ...more explicit modeling and conscious modeling... ...processing challenges...

will be greater, more capable of accessing these richly connected sub networks, which could support basically this larger scale integrative simulation, some aspect of which would be your experience.

I don't know if that got it at all, but.


SPEAKER_03:
Yeah, awesome.

So we're driving back towards free will, because I really liked how you approached it in this conversation.

So I want to think about three concepts, memory, free will, and experience.

what are their Venn diagrams?

Like, can we, uh, of things that we remember, did we have free will for them or not more or less than expected for things that we experienced?

Do we remember them more or not?

Could there be something that you didn't experience, but you remember and had free will on and so on?

Like how our memory free will and experience bound together.


SPEAKER_01:
That's a fantastic question.

I don't,

So what's coming to mind, that's a whole other conversation.

But what was coming to mind for me at the moment is that

There's a partial definitional aspect of a connection between free will and experience.

So people want different things.

I wouldn't call free will one thing.

In fact, I actually think there's a certain wisdom in just the language of it.

People want both the willing, they want the agency, and they want the degrees of freedom in terms of they want to be able to pivot.

They want to be able to have what they do be a function of their past and being constrained by their memories and their meanings from the past.

But they also want to be able to break free, whether in the face of something new or just encountering something new or to explore.

And so having that freedom for exploration is also going to be a part of agency, both within a context and across time.

But the memory is going to be important because without the memory, that's the constraint based on values, based on you.

You know, there's many aspects of the self, for instance, some of the most essential ones and maybe some of the gold standards of free will.

It's like this interface of like, you both want things and you want that you want them, where the wanting that you want is based on this integrative and like narrative type self.

so that would be a way in which memory would very strongly like where free will would be a function both of experience that you want your experience your consciousness and your experience to be part of the causal stream leading to action part of your your valuing your affective inference you want that to be influencing both across time and in the moment um and so the experience would be essential like

It's not clear that many, like Dennett has argued that free will and consciousness must always be handled together.

But without memory, you also though, it's not you either.

I think there's an interesting thing though, in terms of like you're alluding to like basically connections between causation and memory.

And I believe we are better capable of remembering things when we can take them up into a causal unfolding.

This basically affords a representation with more of a sparse structure of salience, of this led to this led to this.

And then you hold that causal graph in your mind as basically the core of your generative model.

And it seems to be a highly efficient way of remembering things is to come up with a causal account of them.

And so if something is a product of your agency in a way that is automatically structuring things in this causal fashion, and so there should be a connection between having agency and free will in a circumstance and being better able to remember things.

I don't know if that's the case, but it seems like some things from education theory suggest, like with respect to active learning, but I can see that going a lot of different ways.

So that's a deep question.

And that's what came to mind.

But what do you think?


SPEAKER_03:
Wow.

Well, the last piece you brought up about the sparsity, kind of the sharpness on the sparsity of the causal story, and then things that have a sharp...

and a sparse causal architecture as experienced with our very limited working memory they're like pre-digested and therefore very apt to be able to leave certain kinds of traces and then maybe something could leave a trace that didn't have a perceived sparse causal architecture in the moment

But that might be an example of a memory that's hard to recall or that might be cleaned up in post-production and may be very susceptible to being influenced because subsequent updates could try to draw attention to part of that uncertainty.

And if there was just a loose memory of many things happening at a scene,

asking even a question about part of it could start to sharpen that aspect.

And, um, so it's, it's an interesting question and also kind of like the questions, like what if you had some sort of suffering, but you didn't remember it or in between moments or when you were sleeping, you were having some sort of negative experience.

So just, I mean, what is happening with the mind and the brain?

The brain seems to be continuous, but then we have these more flashes and discreteness and shifting of mental attention.

Go ahead.


SPEAKER_01:
I just like the way you're describing this.

Yeah.

I feel like it's a really good case in point of the answer to do we or don't we have free will should always be what do you mean?

And the answer is always the way you're showing these different processes could either go together synergistically or come apart.

It's like

How many meaningful degrees of freedom do we have in what circumstances?

Or in what senses do we have how much of which of the varieties of free will that we want in different circumstances?

So it's like the answer is there or isn't there free will?

it seems like like much more interesting is getting into the details and useful.

It's like getting into the details you're talking about right now with like the different ways that memory and experience and choice can all go together or not both within and across time.

Like that's,


SPEAKER_03:
then that answer is like that i guess you could say that's like that's the real problem of free will and then that um interesting yeah like um that when the experiment of pushing the button is presented as being about the exertion of decision making in the moment rather than the um memory or the recalling of something

that might've been different in the moments, those are quite different settings and it could be a total different neurophysiology

And also what you said about how this sort of tension between having a connection to the past and the constraints that it provides, but also the ability to choose.

And I guess that's what's explored in these varieties papers.

So I wanted to not just ask, like, what are the varieties, but just specifically asking about the similarities and differences with bodily action.

What are the varieties of free will we might have with respect to bodily action, like the so-called voluntary and involuntary bodily processes, and then mental action, where in active inference, we can model regimes of attention and metacognition and thought as like action policies on mental states.

So what kinds of free will are out there for the body?

And what does that say about what might be a cognitive degree of freedom or not?

Like, you know, just choosing what we want.


SPEAKER_01:
So in terms of like body actions,

If we're dealing with something highly rehearsed, then it seems like that could be an example or something where it's like ..

you can model that, the predictive processing, like the hammer strike, and the loop is closed before it ever even enters the brain.

It's in the CNS and the reflex arc, but it doesn't perhaps even make it up top before your body moves.

That's just after the fact that you're aware of it.

But then if you're doing something like,

And so then at this other extreme of abstraction, you might have something like planning, reaching a distal goal where there's many steps involved, and you need to come to some sort of sequence of the steps.

And along the way, actually, I don't know if that would be the extreme, but that would be...

there's certain things that have to happen to some orders.

At the extreme of abstraction, it might be something like going to grad school, something like that.

Too real.

Getting a new job.

Ouch.

That itself, there's a lot of things that have to happen before other things, a lot of dependencies, and a lot of multiple realizability.

There's always multiple realizability.

I go to reach for this glass.

I could have reached for this.

I could have done a weird thing and gone like this.

I could have pinky out, pinky in.

I prefer pinky out.

But there's all sorts of things that could have done.

There is multiple realizable.

But the multiple realizability of something like going to college, going to grad school, that's even more so the number of ways you can go into it.

And then I guess I'm thinking in this middle regime of something that's still very clearly motoric, but would be novel in that fine-grained motor control.

I'm learning for the first time, and I'm doing a tea ceremony.

or I'm learning calligraphy, or I'm just learning to knit or something.

There, it's the fine-grained things are now being monitored as present at hand.

And you actually need to use your sophisticated inference machinery to help scaffold this basically

the acquisition of skilled motor abilities, the capacity for skilled motor performance.

But I would also, I think, suggest that the whole way through, it's always built experience once it's being co-opted or controlled.

And its controllability is always modal in a motoric fashion.

claims I make in this paper, turns out that it's called premotor theory.

But that basically, through partial expression of a motor command or a motor prediction, the inference copy from that, the associated sensations, can be used as a means of top-down attentional selection.

It could be used as a means of attending to memory in terms of working memory.

Basically, you can use these.

partially expressed motor predictions, not enough to actually cross threshold, but use them to basically as a source of control over dynamics of where your awareness is going and what's going in or out of your awareness.

And the claim I make is actually that this is exhaustive.

Like this is the only like lever you have is basically whatever is built off of a control hierarchy off of skeletal muscle.

It's a claim.

But the idea would be like, even though I'm talking about something as abstract as,

going to college or grad school, there's still going to be some, it has to cash out as static and modal.

You're seeing yourself in the different contexts, even for the abstracts, like justice.

You still, to experience it, it's still going to have some sort of thing.

Here's justice's scales.

Here's the courtroom.

Here's seeing this memory from your past where there is an injustice or justice was served.

Here's you feeling this uneasiness or this righteousness.

So the idea, I would claim, is that any kind of control on any level will always cash out motorically.

But there are meaningful differences in terms of whether you're engaging in something which is involving these immediate fast feedback loops.

It might be multiply realizable, but less so.

Or something which the affordance structure is more

being played out in terms of your capacity to control it and relate to it in terms of these even more multiply realizable high level plans of all the things, situations you might be in that would be related to achieving high level goals or abstract goals.

I don't know if that makes sense.


SPEAKER_03:
Well, one thought on that is it's like a jigsaw puzzle.

So there's only one way to assemble it.

And it's kind of like there's therefore this bundle of trajectories of different realizations of how one is going to assemble it.

Like there's sort of what happens on the table, all the combinatorics of the way to assemble it.

And then there's like all of the real life combinatorics about how many minutes am I going to spend playing this jigsaw?

And then I'm going to go get up and do other stuff.

and so the multiple realization of the jigsaw where it does all kind of come back to being completed is one thing and then yeah you brought up how when things are even the outcomes are unknown or there's multiple realizations those are where we start to maybe think about hierarchical nesting of models like we've been discussing in the slam paper and also

the vivid imagining of different future states what is the regime of attention that might for somebody who wants to be an athlete help them make practicing and being on that path like more natural so what what how specific and what modalities that's kind of what it made me think of but

I kind of want to keep on going on this mental action route.

Has there been anything like a mental or a cognitive Libe experiment?

Like where the instructions would be like, take a couple of breaths and just, you know, get up and walk around or whatever.

Just take a couple of breaths and then identify the moment on the clock when you chose to think about X. A pure mental on mental assessment.


SPEAKER_02:
So, before I forget,


SPEAKER_01:
Just before I forget, I actually think what you're just mentioning, the optimal intentional engagement for something like a sport or some performance, actually, I think that's a key example of through skilled mental action or not, through the skillfulness of your mental actions, having more or less freedom where, for instance, if you're choking, for instance, you do it wrong.

Jun Tani has a good paper on choking and active inference.

And so if you get that wrong, that would be like your free will being undermined by your mental action not being well calibrated in terms of where you're positioning your attentional selection for optimal grip or optimal engagement with what you're doing.

In terms of this more purely mental action libette, there's different versions of it that have been run, some of which I think would get a little bit more to that

And kind of what you described in terms of has one paper called Decisions that Matter.

And so basically, it would be choosing between charities.

And in this charity choice, you actually don't see the same type of ramping.

And I think this supports, to some degree,

the model I'm suggesting, and that if this ramping is a buildup of basically activity in your action-oriented body maps, cross-coupling with your interoceptive body maps, and this feeling of urge and mental stimulation, it makes sense that you would have that for something like pressing a button.

But if it's something like which charity I'm going to donate to, you might not get that same kind of tight coupling and feedback.

And so I think that's some evidence in support of that.

But I think the particular thing you brought up, there's these and this is a direction I'm beginning to look into.

There's these closely related waveforms to the readiness potential, the event related negativity and the SPN

stimulus preceding negativity.

And I believe some of them would be, for instance, preparing for information that's coming and then acting.

I think that would be the ERN or the SPN, the stimulus preceding negativity is,

You're preparing to receive information that's possibly salient, but there's no action required.

So I think that might be potentially, you could think of all these things though, and actively as having, they look,

very similar electrophysiologically.

And I would suggest that they are all fundamentally similar and that what they're using, whether we're talking about patterns of attentional selection or specifically orchestrating mental simulation to act or not in terms of an overt action, that in all these cases, it is grounded in the modalities.

And this is basically understood implementationally as recurrent activity in different places of the control hierarchy over body maps.

Or in terms of algorithmically and functionally, an accumulation of model evidence for shifting your proprioceptive pose.

That would be for an overt action, but for a documental action, similar story.

But if the model evidence, I guess, would be a slightly different model, but it's

if what you're imagining is your own, you're imagining your body being in a different state that would allow you to orient differently, to bias your sensors differently, to move your attention around differently, to do different precision weighting, but you don't imagine it vividly enough that it will actually drive your spinal reflex arcs.

But that this would be what you would use even for potential purely mental acts.

it would still be co-opting a control hierarchy off of skeletal muscle.

And the reason I focus on skeletal muscle is because it's designed to have basically large gross actions with low latency, and it's controllable.

And the conditions for fine-grained control are realized because you can actually direct your sensors using your effectors

with a large-scale meaningful outcome that can be causally modeled and tracked and controlled.

And so then the idea is that basically, Vygotsky first expressed an idea like this, I think, with respect to thought as inner speech, where first you learn how to speak, and then through partially expressing your speech, you learn how to co-opt this process for a stream of thought.

as inner speech.

Whether you want to say that that exhausts thinking is a whole other thing, but inner speech would be a significant part of thinking.

So the idea is this is all intentional mental operations, whether we're talking about shifting around basically the fine-grained adjustment of an overt skilled motor act or guiding your mental action with respect to attention and mental imagery and imaginings, that in each case

you have the initial affordance structure, the initial control levers established via these overtly expressed behaviors and couplings of the world, which then later, by partially expressing them, gives you something you can repurpose for things like imaginative planning or covert detention.

Or I would argue, any intentionally influenced mental process


SPEAKER_03:
maybe ultimately uh have its origins in this co-opting of motor control bold claim okay so what could be systems yes go ahead i just said could be wrong not financial advice not not extraterrestrial advice hardly even active advice

It's very interesting.

What systems rise to this capacity and does their embodiment matter more?

So there are insects with tremendously reduced central nervous systems.

One could imagine a computational system that can engage in counterfactuals, but its only affordance or embodiment is one Morse code receiver or something like that.

So what systems have this capacity and why?


SPEAKER_01:
Um, so I definitely don't know the boundaries, but if I were to shoot from the hip on this, the idea would be the handling would still be of this computational neuro phenomenology or Mario phenomenology, but instead of drawing brains,

we would draw a different nervous system or whatever the signaling information processing system is, we would still give it this kind of handling where there would be a mechanism, there would be a function, there would be some intermediate algorithmic mapping across these levels, and then you connect this to phenomenology.

And so if

In this phenomenology, you're having basically goal states being represented, and the representation of these goal states is part.

At that level, you're also able to get an account of the guidance of action selection to bring them about.

Then you could say that you have degrees of freedom in that way.

So if we're talking about something like

And insects, you actually sent me a really interesting paper recently about dual systems thinking broadly construed, including for insects.

And it seems like you would need at least a two-tier hierarchy where this upper level can

break free of immediate engagements with the sensorium and where this lower level would allow for your couplings with the world and the orchestration of overt action selection uh in terms of actually like sensory motor coupling to the world and then a process which can basically um

on top of that hierarchically higher that could infer these state transitions, but without them being expressed.

And if you have that, then you could do the types of counterfactual processing that you would need for planning and constructing causal models.

It seems possible that insects might be able to do this in terms of, for instance, like in that paper you sent recently.

So the central complex has a lot of these properties of the hippocampal system.

It's kind of like it has properties of the hippocampal system and the thalamus at the same time.

And it's giving you the salience map used for both orienting and moving.

But you also get these mushroom bodies, which are like the stratum, which would be basically helping with moment-to-moment action selection, biasing it in a value-driven direction.

And so in this paper, you're getting

dual systems for control, one which seems to be more immediate and reactive, and the other seems to be governed by slower processes.

And so it's possible that something like this could give you

ability to do sweeps of possibilities of counterfactual inference where you basically take the beginning of expressing the motor command and so the insects thinking i'm a locomote in that direction um i i don't know the evidence well enough to know if this is the case but um it could be and then

So for a rodent, you'll see these sweeps in the hippocampus.

There's a maze.

And you'll see predictive of whether the mouse goes left or right.

You'll see these place fields representing different points in space.

And in anticipation of this, you'll see these sweeps ahead of activity.

And then where the sweep is most robust, that will be the branch that the animal will go down.

It will go down that set of places.

in theory you could do a similar thing by other means uh maybe with some homology even in the insect nervous system maybe you can even do it in an ant colony if you're getting like an inner attractor capable of aggregating across all these different um finer grain couplings and engaging in control but so basically whatever has

or I can't say, I'm not gonna say sufficient, but the claim I'll make for necessity would be some sort of dual tier architecture where the lower level gives you the couplings with the world and the upper level gives you counterfactual affordance and integration across these lower level potentially segregated coupling processes.

Something like that could do it for you.

And so could insects do it?

No, potentially, I don't know.

Could the insect colony do it?

Maybe.

The thing where I would place a potential constraint is...

It seems like we might need an architecture to have properties where it could signal fast enough where these inferences of quickly enough that it can stay on top of its evolving action perception cycles.

So in terms of its surfing uncertainty, it's moving through the world as couplings, the architecture, whether we're talking about a brain or some set of signaling across multiple individuals in like a hive mind,

We want it, I think, to be fast enough to have the estimates correspond to this sparse causal graph, what Benji would call, I think, independently controllable factors of the world, and not have a causal world model where you are an agent within it.

But it seems like you would need to have the ability to model independently controllable factors.

And so you need a signaling system that's fast enough

to pull this off.

And so some sort of small world network architecture would be likely required, where you have a combination of local modularity, but then synergy through having some central hub.

And so if this could be pulled off by the hive mind, and if this can orchestrate the overall swarm to do things quickly enough to basically have purchase, have the right grips on the world, that it can both inform and be informed by its action perception cycles,

then you could have an agency architecture, which by some dimensions we might describe in terms of free will.

That dodged the question.


SPEAKER_03:
Before I respond, what about just the computational one?

What if it was a computational one and it was instantiating a digital twin, a limited or comprehensive digital twin of itself?


SPEAKER_01:
I mean, I personally think the... I feel like an integrated information theorist would say absolutely not.

Some people within active inference communities would say no, it has to be physically realized.

But I think something like a digital twin or some sort of emulation, the important thing for me is that the...

there is a set of dependencies of effective connectivity that could be involving virtual processes.

And that if you trace out the patterns of effective connectivity of kinds, not necessarily made of matter, that if that is entailing the modeling of a system and its relationships with the world, and where within that system world model, it has this kind of agentic affordance,

For me, that counts.

But a lot of people would disagree on that.

But for me, I think you're trying to find the maximally explanatory core screening.

And sometimes that might be found at the level of the virtual machine and not in terms of the physical realization.

And then that's actually the most meaningful cause.

And then if you trace it out there, that's where you would look for it.

And so that could be in a digital twin or emulation.

But a lot of people would disagree with that.


SPEAKER_03:
So when you were talking about applying this to the colony level, I thought about like the foraging behavior.

That's like reaching out of the ground and grabbing a seed.

And so that's like the enacted foraging trip.

And then is there a counterfactual, I could be foraging or we could be foraging at some different scale

underground uh on the other side of the markov blanket of the nest entrance and then what if somebody were going to be tracking the the elevation of a forager and they'd be like well they go up and down in the nest but on the times where they make that decision to forage they always go up 200 milliseconds before foraging

It's like, well, yeah, that's where the nest entrance is.

So without going into whether they have will or not, it's like, it's some kind of cognitive motor integration when the person hits the button.

So then the way that you frame this as being like not a trivial artifact, in fact, an interesting outcome of aggregation of ERPs across trials

It's like, how couldn't there be a coherent preamble?

Now, I guess if we're 30 seconds long, that would be a different setting.

But then when we connect it to the specific mechanisms that do have to come together in order for there to be a coherent motor action,

it's it's quite an interesting view and I wonder how those who have um interpreted it in a very different way feel have you spoken or asked to anyone who has a very clear and um different interpretation of what this potential means


SPEAKER_01:
I've been discussing it some with, or I forget, I've been discussing some with, or a good amount with Uri Mose and Aaron Scherger.

Aaron Scherger has, he has multiple views, but some of them do disagree.

And so one of them is you, in theory, because you're averaging across multiple trials, there is an interpretation of readiness potentials as artifactual.

And it's possible that sometimes you are dealing with an artifact of measurement, and this is an open question.

But he's also, for instance, he's testing out the mental simulation view also.

Another interesting hypothesis he has is actually some of the evidence accumulation is actually fast feedback loops with muscle spindles.

And actually, you're getting basically the urge, actually, a lot of it is actually in the body itself.

But one interesting thing before I forget is that these, like,

build up and then threshold crossing.

I believe this you'll see across all nervous systems where you get action selection.

And I would wonder whether this similarly to me saying like, you know, this isn't just like a brain story.

Might we see

basically something like this, if we're looking at them.

I think in your active input paper, you talk about stigmergic coherence.

But through some sort of like, forgive me if I'm butchering it, but some sort of measure of that kind, you might see something like generalized action potentials for large scale changes in switching modes of the hive mind of the colony.

And while I'm just speculating, I actually also, in terms of multistage hierarchies,

I actually wonder whether the brains, like for instance, the resting state networks of the brain, maybe not like, there's different granularities and parcellations.

It can be as much as 17 or more if you wanted.

But there are some solutions that are like maybe, so seven networks are most well-known, but there's also like five network solutions.

And I'm wondering if there are actually universality classes for active inferential agents, that you'll actually get something like homolog of different resting state networks in their patterns of effective connectivity.

So generalized resting state networks, generalized empirical phenomena to like things like readiness potentials.

Very speculative, but I think we might.


SPEAKER_03:
a few interesting things that makes me think of and uh are we making cognitive science a creation in our own image if we talk about the generalized hippocampus and the general and so to what extent are we or can we must we generalize from our own action perception loop is uh

putting another umbrella which the human mind is just a realization of and say well the cognitive domain is bigger than the human brain because it includes the brain body and the extended niche but also includes non-human systems like if we want a cognitive science that includes a thermometer or something like that like a thermostat is that a is that a cope

Because actually, that is still the water that that model swims in is still human and cognitive.

Like, I don't know.

But these are interesting pieces.


SPEAKER_01:
I mean, it seems like, seems like surely what you're describing has to be the case.

And it's like, and that's like a both a good thing and a bad thing where it's like, we need

to be able to draw on an analogy with something we understand.

We're usually making sense of things in terms of other things, and so our own experience as this base domain, in order to give us some purchase, can we do it without it?

You could say first principles thinking, but which first principles?

But then there's all of the baggage that could come.

It seems like

we can't avoid doing that.

Maybe we could, but I don't know if we'd want to, but then like, we really need to be careful to track the disanalogies.

Like if we're saying generalized to the campus, like, okay, wait, wait, wait, what are the disanalogies here?

What are the proper unique properties that are present in the target domain and not the base domain of like the map, the analogical mapping you're doing or vice versa?

Yes.

Yeah.

That's fraught what you're describing.


SPEAKER_03:
Yeah.

Um,

well I think a kind of closing area just one point that I want to pick up on I thought it was really powerful what you said about really the social consequences and the personal consequences of interpretation of neurosciences and in some ways even science communication around empirical results like

the idea that we could opt out to free will and that in a world where there's limited degrees of freedom you might be coerced into thinking you had free will or not but if there's any glimmer of free will it can be used to deny and deceive itself so that puts research in this area

in a different reflexive position than research on other systems.

So I guess just how do we move forward here while drawing on the specifics and being respectful of basically the past and the present and the future?


SPEAKER_01:
I mean, for me, I definitely have a lot of...

uh, sold a soul in the game and that like, this is actually maybe the biggest thing that a couple of things, but this might've been one of the biggest things that got me into cognitive science was a very long extended, um, freak out about free will when I was younger, where it was just, I couldn't see how anything could be mean.

I couldn't see how anything could be meaningful without it.

Um, I don't know if I still believe that exactly, but, um,

For me, it was very difficult to not believe that there were this sort of all or nothing thinking about free will and then going with the nothing.

Dennett actually rescued me from that with Freedom Evolves, his book.

But there was a long time where it seriously bothered me and it had real negative consequences on my life.

the and i'm not alone in this i've talked to others and they also feel that way and um part of the way this is coming up in the present work with um psychedelics actually is um so there's this study with um i'm preparing for with creative professionals who are suffering from burnout and one thing i'm wondering in terms of like people can get burnt out from you know multiple reasons but to the extent that this is continuous with burnout is continuous with uh

depression or feeling like you don't have agency in context where you want to have agency or feeling like you don't have adequate control of something where it really matters that you do.

that seems like a good recipe for burnout.

And it seems also like a decent model for some forms of depression, where if you view yourself as not being able to be a cause in the world, if you're not able to meaningfully work towards your values, that could be very distressing.

I mean, it could also be a state of like a quasi-Buddhistic, like blissful surrender.

But there's a question, are we flirting with nihilism there?

There's a question.

And the other question is,

Is it even legitimate, though, to be an eliminativist on the self and on volition, and then just to say, it's okay, you're not real, your volition isn't real anyways, don't worry about it?

Was that even a legitimate intellectual move to begin with?

I would argue it wasn't.

So yeah, I think this is the stakes here for people's sense of themselves changing.

I believe they really matter.

And I believe they have both social and clinical and social consequences, existential consequences for people.

And I'm glad that there's this growing community of people in the neurophilosophy of free will who have been doing a really great job pushing against some of these, I believe, excessively inflationary views.

And I believe that active inference might be a really valuable contribution to these efforts in terms of providing formal models and models that can go across this Marian neurophenomenological stack

or computational neurophenomenological setup and actually address these phenomena in enough detail where not only can we feel meaningfully satisfied where we understand our own agency, but we could intervene, and hopefully for the better.


SPEAKER_03:
Yeah, just some last thoughts on that.

That's very powerful.

And the mutual constraints and the interdependencies of the different levels,

it may come down to someone's genetic sequence of a receptor or some kind of binding affinity with a molecule, but then it could also be integrated in kind of a full stack way with talk or action or changes to the niche.

So it gives like a full stack yes and way that's not

I think a dead end.

It's more like a starting state.

Like if the computer weren't working and then there was like the hardware and there's a software, but then moving beyond just that type of analogy, just very,

powerful about burnout and about the different cognitive ways that we might get there and get into it and get out of it.

And so it's like stoicism or whatever, plus preferences, because it's not just the neutral stance.

It's not just a descriptive stance on burnout.

There's like a preference there.

So Adam, if you have any other thoughts, please feel free.


SPEAKER_01:
I guess a quick thought is

is if we're looking and this is like to follow up on the um comment or something like these somewhat buddhistic eliminativist framings of um agency and i said like are they even legitimate uh i'm gonna argue um no they're not uh and specifically um if we're thinking of something like modeling the self

through time as a high level controller, if you engage in some sort of practice, whether it's discipline meditation for a long period of times, or you've taken like a very high dose of psychedelics, and you've basically collapsed the depth of your, the temporal depth and counterfactual richness of your generative modeling, you will not find yourself there.

You will be gone.

There will be no like you to talk about it.

You might call this something like ego depth.

But then to say that there never was a you process to begin with, I believe that is actually illegitimate.

You've basically used a search strategy that a priori should not have been able to find the self.

And then using that search strategy, you then concluded it didn't exist.

And I think that just doesn't work.

So in this case,

you know, to quote Dennett again, uh, you know, individuals, their narratives, their persons, you know, they're real patterns.

And, um, but they're also, there's a reflexiveness to it where their own belief and their own reality is an important part of their causal significance.

And so.

I think it would be good to have some nice debates with different members of the active inference community who are more deflationary on things like selves, self-processes, and agency.

Because ultimately, I think this is a thing where it's going to be like, well, we should be respectful in disagreements.

I think it really matters we get it right to the extent we can.


SPEAKER_03:
Thank you, Adam, for the excellent presentation.

Apologies for any internet glitches that might have happened.

We are a strange loop and this has been a strange live stream.


SPEAKER_00:
Always good talking to you, Daniel.