start	end	speaker	sentiment	confidence	text
330	880	A	0.546256959438324	You.
2450	4014	B	0.915437638759613	Hello and welcome everyone.
4132	7358	B	0.9168386459350586	This is Active Inference guest stream number 55.1.
7444	10126	B	0.8724424242973328	It's August 30, 2023.
10308	20910	B	0.8844640254974365	Today we are going to have a presentation followed by a discussion on geometric constraints on human brain function by James Pang and Alex Fornito.
21890	24350	B	0.9821031093597412	Thank you again for joining.
24890	27618	B	0.9813886880874634	Really looking forward to the presentation and the discussion.
27714	32150	B	0.6931732296943665	So please off to you two to introduce yourself and continue however you like.
32220	33000	B	0.8529649376869202	Thank you.
33850	35666	A	0.9527631402015686	Well, thanks very much, Daniel.
35858	37394	A	0.8144635558128357	My name is Alex Vonita.
37442	49260	A	0.9268239140510559	I'm based in the School of Psychological Sciences and Turn Institute for Brain and Mental Health at Monash University, and James Penn, who is a research fellow working in the team.
49790	55326	A	0.7463827729225159	And so the idea today was that we were going to talk a little bit about this work.
55428	67860	A	0.9256993532180786	I'll begin by providing a bit of a historical and theoretical background and then James will take over and jump into the specifics of what we did and what we found.
69910	87080	A	0.7268134951591492	We're assuming some basic understanding of neuroscience and some elements of human brain imaging and we'll go through a little bit of maths, but hopefully it'll be enough to give a picture and if there's any questions about it afterwards, we'll be happy to try and answer them.
88350	98250	A	0.7635157108306885	So a key motivating factor for this work is really trying to understand how the structure or anatomy of the brain constrains its function.
98400	106714	A	0.8240276575088501	And if you look at a diverse range of systems found throughout nature, we know that the structure of the system can change its dynamics.
106762	115700	A	0.8508406281471252	So, for example, the shape of a racing car will influence its aerodynamics and how fast it can go.
116390	125166	A	0.8365578651428223	The folding patterns of a protein will influence the other proteins that it can interact with and have quite large effects.
125198	133010	A	0.8338413834571838	So here, for example, we've got example of the hemoglobin protein in a healthy person and someone with sickle cell anemia.
133090	138150	A	0.7681959867477417	And this change in the geometry of the protein leads to a 20 year difference in life expectancy.
139390	144598	A	0.8801277279853821	And here we've got the molecular structures of diamond and graphite.
144694	149398	A	0.8244985342025757	So both of these materials are made of the same atoms.
149414	150966	A	0.5368621349334717	They're all purely carbon atoms.
150998	153710	A	0.8225176334381104	It's just the bonds between them that are different.
153860	160634	A	0.830652117729187	And that difference is sufficient to create quite a variation in the properties of the material.
160682	173166	A	0.5003471374511719	So diamond being one of the hardest substances on Earth and valued at somewhere between twelve to $90 million per kilo, whereas graphite is one of the most brittle and only costs you about $20 per kilo.
173358	181560	A	0.49014681577682495	And so this is essentially the reason why we don't propose to people with H two B pencil, we use diamond rings instead.
183930	185942	A	0.5405611395835876	Now, the brain is no different.
185996	195738	A	0.8350952863693237	We think anatomy constraints function, but there has been a long standing debate about the specific properties that are the most relevant and how we should best conceptualize them.
195824	211546	A	0.770129919052124	And this can be traced back to the days of Ramani Kahal and Camilla Golgi, two people considered to be some of the founding fathers of modern neuroscience, golgi developed a technique for staining neurons that allowed you to visualize their structure under the microscope.
211658	224260	A	0.5139114856719971	And Cahal really perfected that technique and studied the nervous system in extensive detail and really laid down the foundations for what we think about the anatomy of the brain to this day.
225350	231026	A	0.8379163146018982	Now, both of these men were recognized for their efforts in 1906 with a Nobel prize.
231138	237954	A	0.6727401614189148	But even at the award ceremony, when giving their lectures, they were in bitter disagreement.
238082	251414	A	0.9143900871276855	So if you actually look at the recordings of their lectures, cahal says, we applied Golgi's method, and our observations revealed, in my opinion, the terminal arrangement of the nerve fibers.
251542	256442	A	0.7971583604812622	Nerve elements possess reciprocal relationships in continuity, but not in continuity.
256586	266686	A	0.7865408062934875	So here he's saying that cells are fundamentally discrete elements separated in physical space and that there's a gap between them at the synapse.
266718	270690	A	0.8660752177238464	The synaptic cleft and signaling occurs through this gap.
272310	274562	A	0.5676183700561523	Olga, on the other hand, didn't agree.
274696	286834	A	0.6449825763702393	He said, while I admire the brilliancy of the doctrine, which is a worthy product of the high intellect of my illustrious Spanish colleague, I cannot agree with him on some points of an anatomical nature, which are for the theory of fundamental importance.
286962	293466	A	0.7311251759529114	I found myself unable to follow the current of opinion because I was confronted by one concrete anatomical fact.
293648	298730	A	0.9233165383338928	This was the existence of the formation, which I have called the diffuse nerve network.
299070	302582	A	0.855521559715271	And so, for Golgi, all the cells were continuous.
302646	304522	A	0.7185912132263184	They form one continuous network.
304586	311870	A	0.8797311782836914	There was no point of separation between them, and signaling occurred through this continuous network.
313350	324018	A	0.5763434171676636	Now, ultimately, a growing body of evidence, and you can see it in Golgi's statements, was starting to favor Cahal's model.
324184	335510	A	0.6949558854103088	But really, it was only resolved in the 1940s with the advent of electron microscopy, where people could actually resolve synapses and saw that they were spatially disjoint.
335930	344940	A	0.8964434862136841	And this ultimately established the neuron doctrine as the fundamental theory about how the nerve, the system is organized at a cellular level.
346510	364126	A	0.8345202207565308	And this basic idea that we can divide the brain up into discrete units was then carried through to different scales, most famously by Corbinian Broadman, who developed a parcellation of the cortex based on cyto architectonic grounds.
364318	376040	A	0.900522768497467	His idea was that different parts of the cortex have different cellular properties, and so they define these discrete areas that are functionally specialized in some way.
377850	382806	A	0.8354123830795288	And certainly this has been a very influential idea in neuroscience ever since.
382988	406234	A	0.5279175043106079	But around the same time, in fact, a couple of years earlier, the neurologist Alfred Campbell published his own cytoacyctonic map, and he agreed that you could identify discrete boundaries largely in primary zones, but then in the cortex in between, it was a lot more difficult to find sharp outlines or boundaries.
406362	412190	A	0.8504074811935425	And he suggested that actually the changes were more gradual or continuous in nature.
414310	426534	A	0.52513587474823	Broadman's view became more popular and certainly became sort of the dominant theory in neuroscience, even though subsequent attempts to try to replicate it were different.
426572	431880	A	0.8104137182235718	And so different anatomists would parcelate the brain in different ways, using different boundaries and so on.
432730	451770	A	0.8531461954116821	But nonetheless, this kind of congruence between the discrete model of cahal and discrete model of Broadman eventually led to the idea that essentially we can think about the brain as a multiscale network where at the cellular level we can identify discrete cells that are connected by synapses.
451930	466654	A	0.85102379322052	Then we can scale up at the population level at a mesoscale resolution and identify how population of cells are linked by bundles of axons and then all the way through to the macro scales, which is what you sort of see when you look at one of Broadman's maps.
466702	473570	A	0.862923264503479	You have these broad, roughly so architectonic areas connected by white matter bundles.
475450	491554	A	0.5296193957328796	And in the last two or so decades we've had the measurement techniques for characterizing these networks on a vast scale and there's been a pretty well established pipeline for mapping these networks.
491682	498534	A	0.8560081124305725	So the basic idea is that we have the brain, we divide it up into these discrete areas and they act as our network nodes.
498662	504078	A	0.9000059366226196	And then for every pair of nodes we measure some aspect of structural or functional connectivity between them.
504164	507710	A	0.8529198169708252	Functional connectivity being some aspect of coupling in activity.
508050	511930	A	0.8695772886276245	And then we can represent that in the form of a connectivity matrix.
512010	522302	A	0.8989556431770325	So each row and column represents a different region and each element tells you about the type and strength of connectivity between areas that can equivalently be represented as a graph.
522366	531590	A	0.7555246949195862	And then with that graph representation, we can apply all sorts of different analytic tools to understand different aspects about how the network is connected and organized.
532810	540920	A	0.7988605499267578	And this basic approach has been used quite extensively to understand how the underlying anatomical properties of the network constrain function.
541230	542806	A	0.9844772815704346	This is one of my favorite examples.
542838	547530	A	0.8695403337478638	This was a study of two different worms, c Elegance and P Pacificus.
547870	553414	A	0.8226652145385742	Both of their nervous systems in the head have been mapped at the level of each cell and synapse and they're actually identical.
553462	559534	A	0.8370304703712463	So they've got the same type of cells, the same number of cells, it's just the connectivity between them that's different.
559572	563778	A	0.7612113952636719	And that's what you see in this network projection here that the topology of the network is different.
563944	578146	A	0.769642174243927	And in this study they showed that changes in the connectivity of just two hub neurons were sufficient to elicit a difference in the behavior of the animals, such that P Pacificus is a predator of sea elegance.
578178	582150	A	0.8247770071029663	And here you can see Pacificus eating poor sea elegance for lunch.
583930	591626	A	0.6768024563789368	Now, we can't lock humans up in a room and see who eats who and try to understand how their anatomy constraints function in that way.
591648	599002	A	0.7954590916633606	But we can do things like use MRI to measure anatomical connectivity and functional connectivity and correlate the two.
599056	603520	A	0.5078041553497314	And it's pretty consistent finding that we generally find there is a correlation between them.
604210	609674	A	0.732022225856781	We can run computational models where we have a structural network, we simulate the activity.
609722	613434	A	0.8653953671455383	Then we apply, say, a lesion to that network and look at the effects on the activity.
613482	622500	A	0.5385986566543579	And we can show, for example, that if you lesion a hub area you have quite a dramatic impact on brain function compared to if you lesion a more weakly connected non hub area.
623190	624814	A	0.862749457359314	Or we could use clinical studies.
624862	634342	A	0.6168860793113708	We could look at cases where there are naturally arising lesions through stroke or some other form of brain damage and we can understand the functional impairments that result.
634396	649050	A	0.6739501953125	So, for example, in this case, people with lesions to certain types of hub areas with diffuse connectivity showed much more generalized cognitive impairments than people with lesions to areas with more specific patterns of connectivity.
650450	651470	A	0.9868353605270386	So this is great.
651540	660078	A	0.9686779975891113	This has been really informative and great for understanding the role of individual brain regions or connections in brain function.
660244	668654	A	0.5288372039794922	But it doesn't really give us a coherent, unified perspective about how dynamics emerge from the underlying structure.
668702	670530	A	0.6071935892105103	It's all a little bit piecemeal.
671190	690060	A	0.7223385572433472	Now, if we want to develop such a coherent understanding we can draw some inspiration from different physics and engineering where typically the structural constraints on the dynamics of a system are studied by understanding the eigenmodes of the system.
691070	697114	A	0.8388044238090515	Now, the eigen modes of a system are found by solving an eigenvalue problem such as this one.
697232	708282	A	0.877742350101471	So an eigenvector we can think of as something that we measure about a system that doesn't change its direction if it's subjected to some kind of transformation.
708426	711786	A	0.810880184173584	So if that's the case, then this equality holds.
711818	719250	A	0.9074433445930481	So the idea here is that PSI is our vector, something we measure about the system subjected to some transformation L.
719400	727974	A	0.8544708490371704	And if PSI is an eigenvector, then the transformed eigenvector is equal to the eigenvector just scaled by some value.
728092	733778	A	0.8307533860206604	So the transformation can scale the vector, but it doesn't change its direction.
733954	740330	A	0.8683044910430908	And so if that's the case, then this scaling factor, lambda, is what we call an eigenvalue and PSI is an eigenvector.
741230	746406	A	0.8239967226982117	This kind of equation is applied to a lot of different systems and a lot of different contexts.
746518	764394	A	0.8454517126083374	But when we're studying the eigen modes of a system, typically our L term here is an operator called the Laplacian operator which essentially describes how smoothly some kind of structural property of the system varies through an appropriate spatial embedding.
764522	775490	A	0.9067147970199585	So I'll come back a little bit to what that means because we can make different choices for what we use in L and that determines the specific anatomical properties that we prioritize.
776170	792410	A	0.6917977929115295	But for now, I just want to emphasize that a key property of these eigenvectors is that they're orthogonal and so that then we can use them as a basis set for reconstructing different activity patterns that we might see in the network.
793710	799626	A	0.49403291940689087	So I guess the most famous example of a basis set that many people will be familiar with is a Fourier set.
799728	809242	A	0.8889220356941223	So, for example, here we have some one dimensional signal, and we can decompose that signal as a weighted sum of sine and cosine functions of varying frequencies.
809386	815114	A	0.7892293930053711	So here you've got the different functions, different frequencies, and here you've got some weighting factors.
815162	819330	A	0.8597002625465393	And we can reconstruct this signal as a weighted sum of these functions.
819830	826578	A	0.9017103910446167	In a similar way, we can extract our Eigen modes of the brain based on some particular anatomical property.
826744	834770	A	0.773979902267456	And we end up with these spatial patterns here that are organized again in terms of spatial frequency or the wavelength of fluctuation.
834850	847050	A	0.6689247488975525	So here you can see we've got a very low frequency fluctuation moving from back to front, top to bottom, medial, lateral, and then as you move up, you get these more high frequency fluctuations.
847470	853386	A	0.8334557414054871	And so then we can use these patterns to reconstruct any spatial map that we observe on the brain.
853418	857706	A	0.9059146046638489	So it could be a map of brain activity recorded during a particular task.
857738	862538	A	0.888198733329773	It could be, say, a map of cortical thickness variations or gray matter volume variations.
862714	867146	A	0.6333754658699036	It's sufficiently general to allow you to reconstruct any type of map.
867258	869646	A	0.8520427346229553	And so we can do that just as a weighted sum.
869678	877190	A	0.9057731628417969	So here Y represents our map, and then we represent that as a weighted sum of our modes with the A coefficients representing the weights.
881290	889666	A	0.5672505497932434	Sorry, I should emphasize that that explanation can be a little bit abstract for people who aren't familiar with Eigen modes.
889698	893222	A	0.6342299580574036	And it is always a bit of a challenge to get an intuition.
893286	899274	A	0.7318554520606995	And so you can do what one of the people in the team did and asked Chat GPT to explain eigenmodes to a ten year old.
899312	901642	A	0.9335060715675354	And it turns out that it does a pretty good job.
901696	904894	A	0.9584373831748962	I was quite happy with this explanation, so I thought I'd share it.
905092	910058	A	0.6758935451507568	So our Chat GPT says, of course, let's imagine we have a wobbly jiggly bowl of jelly.
910154	912478	A	0.823388397693634	When you poke it, it wiggles and shakes, right?
912644	920802	A	0.868527352809906	Now, imagine if you poke the jelly in different spots or with different amounts of force, each time you poke it differently, the jelly wiggles and shakes in a different way.
920936	922994	A	0.7787020206451416	Eigenmos are like those different ways.
923032	925620	A	0.7451609969139099	The jelly wiggles and shakes when you poke it.
926470	931222	A	0.74323970079422	So essentially, seeing this video here, the jelly is poked and it wobbles in a particular way.
931276	937830	A	0.8619635701179504	If you poke the jelly in a different spot or with a different amount of force, you'll trigger a different pattern of vibration.
938170	943814	A	0.8707225322723389	And so commonly, Eigen modes are used in the context of systems that vibrate.
943942	954800	A	0.8690775632858276	And the idea is these Eigen modes correspond to preferred patterns of vibration when the system is perturbed, and those preferred patterns are just dictated by the structural properties of that system.
955490	965682	A	0.7151380181312561	We can extend it more generally and think about it more as how a system responds to any type of excitation and how an excitation spreads through some connected system.
965736	969742	A	0.8707282543182373	And the Eigen modes correspond to the preferred patterns of excitation.
969886	972820	A	0.8261390924453735	Again determined by the physical properties of the system.
975590	991754	A	0.7967607378959656	So naturally, given everything we've been talking about and these ideas that the brain is a multiscale network, we need to make a choice about how we define alloplastian what specific anatomical properties are we going to extract our eigen modes from?
991872	996170	A	0.6662871241569519	And so a natural choice would be to extract them from brain connectivity.
996510	999642	A	0.601129412651062	And we can do this quite in a reasonably straightforward way.
999696	1002682	A	0.8437105417251587	We get some map of the connections in the brain.
1002826	1005834	A	0.7470946907997131	We map connectivity between every pair of nodes.
1005882	1009466	A	0.8704192638397217	After we apply some discretization, we define our discrete nodes.
1009498	1011546	A	0.7911676168441772	We map every pair of connections.
1011738	1013782	A	0.8525788187980652	We represent that in the form of a matrix.
1013866	1016802	A	0.8479481935501099	And then we extract this quantity here.
1016856	1018718	A	0.8407096862792969	It's called a graph Laplacian.
1018894	1022866	A	0.7545585036277771	The details are not so important, but that's essentially our l operator here.
1022968	1029510	A	0.7558256983757019	And it describes how smoothly connectivity varies as we move from node to node in the network.
1031050	1041466	A	0.6360774040222168	And when we do that, several studies have shown that you can use the eigen modes extracted from this graphaloplassian to reconstruct kind of classic functional networks that you record.
1041568	1049718	A	0.6891610622406006	With functional MRI, we can reconstruct different patterns of functional connectivity between pairs of areas.
1049894	1053546	A	0.8447229862213135	You can use it to reconstruct different eg signals.
1053738	1064450	A	0.8404091596603394	And people have even shown that you can make predictions about the pattern of neurodegeneration that you see in different forms of dementia.
1065510	1077906	A	0.9677590727806091	So this has been really fantastic important work and a really important proof of principle that this eigenmode framework can be used to understand how the structure of the system constrains its dynamics.
1078018	1092170	A	0.8966649174690247	And in each case, the interpretation is that these dynamical patterns that we see with fMRI or EEG or so on, are reflecting excitations of these underlying eigen modes or the resonant modes of the anatomy of the brain.
1094190	1100294	A	0.7034010887145996	This view very much aligns with what we would think of as a classical view of brain organization that I've just been discussing.
1100342	1108778	A	0.8485242128372192	So, following from Cahal and Broadman's work, the idea is that at lots of different scales, we can divide the brain up into discrete areas.
1108874	1116770	A	0.8143869042396545	They're connected in some way and it's the signaling along these connections between these discrete areas that drives activity.
1118310	1133510	A	0.7671301364898682	But there are reasons to think that, particularly at coarser scales, so we know at the fundamental cellular scale, the network is discrete, but at coarser scales, perhaps a different set of approximations might be useful.
1133850	1146646	A	0.675439178943634	So if you look at dense reconstructions of neuronal tissue, so this is, say, with electron microscopy, you find that cortical tissue is extremely dense.
1146678	1152270	A	0.6506779789924622	It's like a really rich, thick forest of cells and their processes.
1153250	1168770	A	0.8160573244094849	And as we've talked about, there's been a lot of debate about where you can actually draw boundaries between discrete areas and how valid and reliable that is outside some kind of classic examples seen in primary cortex.
1169350	1179314	A	0.7132805585861206	And if you look more deeply at the cellular organization of specific regions, here on the left we've got the cellular organization and on the right we've got a myelin stain.
1179442	1185366	A	0.8549486398696899	You see, you get these deep penetrating fibers that are coming in from the white matter.
1185468	1194698	A	0.8372663259506226	This is what this kind of classic graph approach will pick up because we define our nodes in the cortex and then we're mapping the connections that pass through the white matter.
1194864	1203802	A	0.851089596748352	But you can also see that there's a lot of connectivity that's moving horizontally or tangential to the geometry of the cortex.
1203946	1209178	A	0.6630110144615173	And so these horizontal connections allow for the continuous spread of activity.
1209354	1216930	A	0.8027864694595337	So rather than activity jumping between discrete nodes, it can actually spread as a propagating wave.
1218710	1234226	A	0.7331768870353699	And just to emphasize some of the limitations of the discrete model, not long after Broadman's work, just a couple of decades, the renowned physiologist Lorenzo de Nou was pretty emphatic about his concerns with the approach.
1234338	1245254	A	0.6146683096885681	He said the only really good cyto architectonic pictures are those of Campbell, who, let me put in capital letters, has been the only cyto architectonist who has described facts and only facts.
1245382	1252880	A	0.6695452332496643	The German cyto architectonist has mixed facts and theory in such a manner that nobody can tell where facts ends and theories begin.
1253810	1274610	A	0.6059522032737732	So again, this is just emphasizing the idea that while we might be able to define discrete areas at a mesoscopic or macroscopic resolutions, in some cases, especially around the borders of primary sensory or motor areas, for large swathes of cortex, those distinctions become a little bit blurry.
1277050	1281874	A	0.8609579801559448	So an alternative approach has emerged out of neural field theory.
1282002	1291318	A	0.8649272918701172	So neural field theory has been around for several decades now and this is a different approach to thinking about cortical activity.
1291414	1301174	A	0.6331989765167236	So the basic idea is that instead of dividing the brain into discrete specialized areas or nodes, we can treat the cortex as a continuous sheep.
1301302	1309514	A	0.5106009840965271	And we are actually interested in trying to capture how patterns of brain activity propagate through that continuous sheet.
1309642	1313966	A	0.8362165093421936	And so this is something that you can see in diverse types of electrophysiological recordings.
1313998	1320734	A	0.9075273871421814	So this, for example, this video is of the dynamics of voltage sensitive dyes recorded in the mouse brain.
1320862	1336520	A	0.866117000579834	And you can see that you observe these propagating waves of excitation that move continuously through the cortex rather than jumping from region to region as would be implied by a kind of strongly discrete model.
1339150	1344970	A	0.867692768573761	So a big emphasis in neural field theory is on describing these wavelike propagation patterns.
1345470	1363470	A	0.8480314016342163	And it's been shown in recent theoretical work that if we accept that wavelike propagation drives neuronal activity, then really the eigen modes that we should be extracting or prioritizing are those that are derived from the geometry of the brain.
1363630	1377560	A	0.7815845608711243	So our eigenvalue becomes this problem here where this operator here is called the LaPlace beltrami operator and it describes how smoothly the geometry or the shape or the curvature of the brain varies through space.
1378090	1389994	A	0.8720795512199402	And just to briefly explain why that's the case, here we've got the wave equation that's used in some forms of neural field theory, at least the divisions that we've been focusing on.
1390112	1402634	A	0.900781512260437	And so the basic idea is that the firing rate of a given population of neurons B at location R and T is given by the Afferent field of incoming populations.
1402682	1404062	A	0.8029634952545166	So other populations A.
1404116	1411520	A	0.9057486057281494	So we've got other populations providing this Afferent field of activity that determines the firing rate of B.
1412210	1419730	A	0.8370296359062195	And obviously, we then need to describe what this afferent field looks like and that's given by this part of the equation here.
1419880	1424210	A	0.9242565631866455	So on the left here, this set of terms describes how the field evolves through time.
1424280	1433640	A	0.7372574210166931	We're not going to focus on that today over here, which is what we're interested in, where we've got how the field is evolving through space.
1434170	1441158	A	0.8320565819740295	And so here we can see our friend, the LaPlace Beltrami operator, which describes the geometry.
1441254	1445370	A	0.7910075187683105	And here we've got the length scale of axonal connectivity.
1445710	1448566	A	0.7843980193138123	In this model, we make a very simple assumption about connectivity.
1448598	1454430	A	0.8813541531562805	We assume each point is connected to its neighbors in a distance dependent and isotropic way.
1454580	1457242	A	0.8662914037704468	And that distance dependence is roughly exponential.
1457306	1467410	A	0.77455735206604	So the idea is that areas nearby to a given location R will have a strong influence and that influence declines roughly exponentially as a function of distance.
1468150	1473140	A	0.7615195512771606	And the speed of that decay is given by this R term here.
1473830	1477546	A	0.8432695269584656	You can see that geometry is firmly embedded in this equation.
1477678	1482022	A	0.702943742275238	Now, I should point out this isn't something that's just been plucked out of thin air.
1482076	1489738	A	0.8691233396530151	This is a damped wave equation that has been used for centuries to describe wave dynamics in all sorts of different media.
1489904	1498918	A	0.8679850101470947	And so from that physics, we know very well that the geometry of the system constrains the spatial properties of wave propagation.
1499094	1503470	A	0.8745759725570679	And you can start from first principles of neuronal biophysics and derive this equation.
1506290	1515290	A	0.8622729778289795	And given all that work, we know that the eigen modes of the LaPlace Beltrami operator actually correspond to the standing waves of the dynamics.
1515370	1516830	A	0.8875037431716919	So what are standing waves?
1516990	1521186	A	0.8516465425491333	So in this simple example, we've got two traveling waves here, a blue and a green.
1521368	1533800	A	0.5078189373016357	And as they interact with each other, you get these patterns of constructive and destructive interference represented by this red line here, that cause these very large amplitude fluctuations that are fixed in space.
1534250	1538050	A	0.7137043476104736	So they're not actually traveling like the original carrier waves, they're fixed in space.
1538140	1540230	A	0.8770297765731812	So that's why they're called standing waves.
1540390	1542534	A	0.8727264404296875	And they're a nice example of resonance.
1542662	1550342	A	0.8096509575843811	So these fluctuations in the red trace are much larger in amplitude than the original carrier waves.
1550406	1555326	A	0.8322978615760803	So it's an example of resonance where we're getting a larger response in the system than the energy that we put in.
1555508	1562382	A	0.7306573390960693	And just to convince you that this is something real here, for example, we have a pool of water, a classic wave system.
1562516	1569026	A	0.8776352405548096	If you apply vibrations at a specific point in the pool, you see these waves that travel out.
1569128	1572606	A	0.8369863033294678	They hit the opposite wall, reflect back and start to interact.
1572718	1582470	A	0.8689668774604797	And then you see the emergence of these standing wave patterns that are fixed in space but show these very large scale amplitude fluctuations.
1584250	1586946	A	0.6837027072906494	Another classic example is the Cladney plate.
1586978	1597130	A	0.8814295530319214	So if you arrange dust particles on a plate and then you apply some vibration at a particular frequency, the dust particles will settle into these complex patterns.
1597470	1604190	A	0.8732091784477234	The pattern is determined by the specific frequency that you apply and specifically where you apply the vibration.
1604530	1608906	A	0.7983659505844116	And the patterns correspond to the eigen modes of the plate.
1609018	1617780	A	0.8540887832641602	And again, those patterns are determined by the physical properties of the plate things like its stiffness, its geometry and so on.
1619190	1626738	A	0.6977179050445557	This is a little bit gratuitous, but you can extend the idea to three dimensions and you can actually cause the particles to levitate.
1626914	1636470	A	0.7252975106239319	Again, in this case, they're trapped within the nodal lines of sound waves that are being projected in three dimensions.
1639390	1641654	A	0.5391026139259338	And this does have real world consequences.
1641782	1647180	A	0.8853379487991333	So this is a video of the Tacoma Narrows bridge in the 1940s.
1648110	1651574	A	0.7696505188941956	The engineers didn't pay enough attention to eigen modes.
1651622	1659626	A	0.5296585559844971	And so on this particular day, crosswinds hit the bridge in just the right spots and at just the right frequencies to excite the eigen modes of the bridge.
1659658	1667410	A	0.6104350090026855	So you triggered these resonant responses and created these large scale amplitude fluctuations that ultimately led to the collapse of the bridge.
1670710	1688946	A	0.7796823382377625	So hopefully, that background has kind of illustrated that there's sort of two different views of thinking about which anatomical properties of the brain might be more important in constraining dynamics.
1689058	1701230	A	0.8762383460998535	So on the one hand, we have the classical kind of connectome centric view in which we view the cortex as comprising discrete areas and dynamics are dominated by node to node transmission.
1702050	1708638	A	0.7621161341667175	The connectivity between areas is topologically complex and not homogeneous, and we very much think that that's very important.
1708724	1710960	A	0.861236035823822	And so we prioritize measuring that.
1711490	1717822	A	0.6911630034446716	We don't really directly account for the spatial embedding of the network or its geometry.
1717886	1720820	A	0.790752649307251	We can look at it secondarily, but it's not baked into the model.
1721750	1725266	A	0.5504982471466064	And because we're interested in connectivity, that means we need to measure it.
1725288	1736550	A	0.8538625836372375	So from a practical perspective, at least, if you're dealing with neuroimaging data, you need a T one weighted image to measure brain anatomy but also diffusion MRI image to be able to measure brain connectivity.
1738330	1747494	A	0.8904614448547363	The other perspective, which is a geometrically informed perspective that arises out of neural field theory, views the cortex as a continuous sheet.
1747542	1750986	A	0.5941371321678162	We're not making distinctions between different areas of the cortex.
1751178	1758362	A	0.8662283420562744	We think dynamics are dominated by propagating waves of excitation, especially at these mesoscopic and macroscopic scales.
1758506	1764938	A	0.8590133190155029	We approximate connectivity between different points of the cortex as being homogeneous and distance dependent.
1765114	1769134	A	0.8435171246528625	So we know that there is a strong distance dependent in connectivity.
1769182	1770626	A	0.5475524663925171	It doesn't explain everything.
1770728	1774574	A	0.46695008873939514	So some things are missed, but we know it's certainly an important feature.
1774622	1777918	A	0.7817835807800293	So then the question is how far we can get with this approximation.
1778094	1788070	A	0.8334866166114807	And a nice feature of this approach is that we are directly accounting for spatial and geometric effects, the physical properties of the brain, which are overlooked by the connectome approach.
1788650	1796026	A	0.9141777157783508	A nice practical benefit of this approach is that because we approximate connectivity in a simple way, we don't actually have to measure it.
1796128	1799686	A	0.8204743266105652	We can derive our basis set simply by looking at the geometry of the brain.
1799718	1804910	A	0.6680550575256348	And so we only need a T one weighted scan, which is very standard in MRI experiments.
1806210	1814554	A	0.5923413634300232	So hopefully that's set the scene for thinking about different anatomical constraints on the brain and which ones we might want to prioritize.
1814682	1816122	A	0.8753336071968079	I'll now hand over to James.
1816186	1824770	A	0.893520176410675	He'll talk about how we went about testing these different ideas and trying to understand which constraints might be more important for dynamics.
1826970	1828390	C	0.9094076156616211	Thank you, Alex.
1831930	1837474	C	0.6077930927276611	I'm going to focus more on the things that we found in the paper that we recently published.
1837522	1846186	C	0.8403948545455933	I think a lot of you have the link for it, but let us know and send us a message if you want to want us for the link.
1846288	1858234	C	0.8778800368309021	So basically we start with we're trying to answer and test the theory on which modes of the brain could best describe activity measured in FMI.
1858282	1862110	C	0.8891781568527222	So we'll begin by how do we actually measure these modes.
1862470	1873618	C	0.911237359046936	So geometric modes are based on the T one weighted image, which is a standard imaging tool that people use in the field.
1873784	1884246	C	0.7188189625740051	And you can extract a model of the cortical surface here on the right, and there are robust pipelines to do so.
1884348	1886998	C	0.7880848050117493	And you can do that on a population average sense.
1887084	1894570	C	0.8679770827293396	Basically, you get a group template of the surface, or you can do that on an individual basis.
1896350	1904560	C	0.8547106385231018	On the other hand, connector modes need deficient MRI and a structural MRI because you need to kind of align the two.
1904930	1913330	C	0.8731988072395325	And then we run a tractography pipeline, basically finding connections between regions in the brain.
1914470	1922510	C	0.8811693787574768	And then from there you can construct a vertex level or even region level connector matrix.
1922590	1931430	C	0.8769834637641907	Basically it's a matrix where each element represents the connection of one region or one vertex to another region or another vertex.
1932010	1944970	C	0.9238689541816711	And you feed this cortical surface or this connector matrix in the eigenvalue problem equations that Alex has mentioned in the previous slides.
1945390	1950770	C	0.8705209493637085	And then how do we test the performance of these geometric and connector modes?
1950870	1955680	C	0.8587990999221802	Basically, we focus a lot on FMI data.
1956210	1963700	C	0.5202720165252686	So there are several open access data sets that are available.
1964070	1975874	C	0.590494692325592	For example, the popular Human Connector Project, which roughly has about 1200 participants, but we focus on 255 participants who are completely unrelated.
1975922	1978530	C	0.6906073093414307	There are no twins and no siblings.
1978690	1989722	C	0.8983743190765381	And within the Human Connector Project data set for each subject, they have what we call task evoke data.
1989856	2002074	C	0.903631865978241	Basically, these are functional activity that was recorded whilst each participant was performing a particular task.
2002122	2008074	C	0.8794865012168884	And Hcp has a suite of seven different tasks, and within each task several.
2008122	2011758	C	0.7443099021911621	Different contrasts within it.
2011924	2015218	C	0.8908804655075073	And then we also analyze resting state data.
2015304	2021250	C	0.7010967135429382	Basically, resting state data is where the participant is just inside the scanner and just not doing anything.
2021320	2038550	C	0.859796941280365	And you just scan brain activity through time and you can construct a functional connectivity as well, where each element of this matrix represents how correlated the activity is between two regions.
2039130	2043830	C	0.8281954526901245	We also analyze data from what we call neural vault.
2044190	2051018	C	0.5140005350112915	It's an open access repository of thousands and thousands of different maps that people have contributed.
2051114	2062670	C	0.9201789498329163	And each map was acquired with distinct experimental protocols and we took about 10,000 of those from Neurovolt.
2063270	2074318	C	0.6775758862495422	And again, the level of heterogeneity in the different tasks is quite remarkable in the Neurovolt.
2074334	2085670	C	0.5527769327163696	So we wanted to do our analysis on quite different tasks to make sure we are capturing something really meaningful.
2086650	2091562	C	0.8719439506530762	So just to remind yourselves of what we're going to do next.
2091616	2094842	C	0.8417633771896362	So basically, Alex already had mentioned this.
2094976	2097974	C	0.8778027892112732	You extract, for example, this spatial map.
2098022	2102890	C	0.8857133388519287	Say that's the task evolved map and we decompose that into different sets of eigen modes.
2102970	2108350	C	0.8724662065505981	So these patterns could be the geometric modes or they could be the connector modes.
2108690	2121950	C	0.8977420926094055	And it will be weighted by a coefficient A, and the weights represent how each mode is expressed for that particular map.
2122110	2142166	C	0.8709555864334106	And you can truncate the number of modes that you want to use and then you can reconstruct back the data by just taking a linear sum of the coefficient multiplied by the geometric or the connector modes.
2142358	2146886	C	0.8490176796913147	So what did we find by doing these analyses?
2147078	2154442	C	0.8865923881530762	So first I'm going to show you how the spatial maps look like in terms of reconstruction.
2154586	2164690	C	0.8877362608909607	So on the left I'm showing you the different task develop special maps, and these are group average maps for the human connector project data set.
2164840	2168100	C	0.8277774453163147	And again, these are the seven tasks for that data set.
2168550	2175894	C	0.9080660343170166	And then we ask, okay, if we use about ten modes, how would this patient map look like?
2175932	2179590	C	0.7793538570404053	And for this result, we're focusing on the geometric modes.
2180490	2183286	C	0.7845152616500854	So the reconstruction looks like this.
2183468	2197530	C	0.7565857768058777	From afar they look quite different, but if you actually look a bit closely, it already captures the kind of the large scale core scale patterns that you can see from the data.
2197600	2199206	C	0.8282458186149597	For example, this relational map.
2199238	2202670	C	0.8195428848266602	You can clearly see this deemergence of this big pattern.
2203010	2206926	C	0.898695707321167	Now, what happens if we incorporate more modes into it?
2207028	2209870	C	0.8859783411026001	So we increase the number of modes to 100.
2210020	2225714	C	0.7901219725608826	And now you can see that the reconstruction almost looks like the empirical data, but there are still subtle differences, especially in the more localized activity, for example, here in the arrows.
2225842	2238114	C	0.7291346788406372	And if we increase it further, you can see that we can better capture those isolated localized patterns just by increasing it to 200 modes.
2238242	2245738	C	0.7986571788787842	So you can see that the modes are actually really an efficient basis set for task evoke data.
2245904	2247962	C	0.8878180980682373	We do the same for resting state data.
2248016	2255274	C	0.8408198952674866	We increase the number of modes in here and compare the functional connectivity based from the empirical data and the reconstruction.
2255322	2261598	C	0.8191991448402405	And we see the same thing that as you increase the number of modes to 200, we can capture the empirical data.
2261764	2280786	C	0.5975317358970642	And you can do this in a more systematic way by calculating how well can we reconstruct the empirical data just by taking the correlation of the empirical and the reconstruction in reconstructed maps as a function of an increasing number of modes.
2280898	2288722	C	0.5412500500679016	And we see that indeed the reconstruction accuracy increases as we increase the number of modes.
2288866	2307098	C	0.8517510890960693	And up to 200, we can get about 85% to 90% accuracy, which is quite efficient given that we do the analysis on a cortical surface with about 30,000 vertices.
2307274	2321330	C	0.7587459087371826	So mathematically, the maximum number of modes available to us is about 30,000, and using 200 out of the 30,000, we can already reconstruct the data quite efficiently.
2322070	2331766	C	0.878896951675415	And then we've shown that the modes are quite powerful and efficient in representing the data.
2331868	2345814	C	0.883929431438446	We now test the Hypotheses or the questions that Alex has laid a while ago, that are the geometric modes more parsimonious than the other anatomical modes?
2345942	2360314	C	0.9029130935668945	And when I say anatomical modes, again, we're focusing on the connector modes, which is based on the connectivity matrix, but we also test another anatomical mode based on an EDR rule.
2360362	2385266	C	0.7845584750175476	So an EDR rule is the exponential distance rule, which as Alex has mentioned a while ago, which is that because the assumption of neuroflu theory is that the connections are very localized and also organized in a distance dependent way, specifically, the connection weight changes exponentially as a function of distance.
2385378	2394298	C	0.8858022689819336	So we want to test that hypothesis on how dominant that exponential distance effect is.
2394384	2417220	C	0.8285823464393616	So for the details, we just created a synthetic network based on a simple probability of connection following an exponential distance rule with a skating factor or an exponent alpha, which we matched from empirical diffusion MRI data.
2417590	2425666	C	0.8198614716529846	And again, there's a lot of empirical evidence of the existence of this exponential distance rule.
2425698	2431922	C	0.799971342086792	So it's not just a hypothetical theoretical kind of assumption.
2432066	2451194	C	0.879156231880188	We see the effect in Macaques if you follow the weight as a function of distance from track tracing data, and this is in logarithmic scale, you see this linear curve which represents an exponential in linear coordinates.
2451322	2466046	C	0.8926635980606079	And we see the same with human diffusion MRI data that the weight changes as a function of distance in an exponential distance weight, and even in other species like mouse rats, mimosa, and so on and so forth.
2466078	2469502	C	0.8390688896179199	So this is a universal property found in a lot of different species.
2469566	2481030	C	0.6736133694648743	So this exponential distance rule connectivity is actually empirically valid.
2481770	2492698	C	0.9100583791732788	So by using these three different anatomical properties, we can calculate the modes using the equations that Alexis mentioned a while ago.
2492784	2501646	C	0.9024863839149475	And you can get these geometric modes on the left, connector modes in the middle, and the modes from the exponential distance rule connectivity on the right?
2501828	2515534	C	0.6281074285507202	And again, the modes are arranged in quite a unique way in that the first couple of modes will represent the low spatial frequency or patterns with very long spatial wavelengths.
2515662	2522610	C	0.8979097604751587	And if you go further down, you can get these high special frequency or short special wavelength patterns.
2524630	2532120	C	0.8099793791770935	The basis set that the modes provide can capture different scales of the data.
2533130	2543242	C	0.8878628611564636	So how do these anatomical modes compare when we now reconstruct the different FMI data that we have?
2543376	2553914	C	0.8846734166145325	So, for resting state functional connectivity, we compared the three modes, again by measuring the accuracy as a function of the number of modes.
2554042	2567742	C	0.664508044719696	And you can see that the geometric modes outperform both of the connectome and the EDR modes, but you can see that the EDR modes are quite close to the geometric modes.
2567886	2589654	C	0.6993299722671509	So again, suggesting that the fundamental effect that the EDR connectivity does in empirical data, it highlights the importance of this simple but important exponential distance rule connectivity.
2589782	2595898	C	0.8516173362731934	And we can see the same thing by reconstructing the different task activation maps that we have.
2595984	2598730	C	0.8039178848266602	And I'm showing you here the difference.
2598800	2610714	C	0.707701563835144	So it's the geometric minus the connector and geometric minus DDR reconstruction accuracies and red means the geometric modes are outperforming the other anatomical modes.
2610762	2616270	C	0.7293670773506165	So in all the data sets that we have, the results are quite consistent.
2616430	2626920	C	0.584892749786377	So again, it suggests that the geometric modes are more parsimonious than the other anatomical modes that we have.
2627930	2641750	C	0.8994510769844055	And then we go a bit further on, how do we actually use the concept of these modes in analyzing FMI activation maps.
2642330	2650410	C	0.9089046120643616	So I just kind of just want to explain a little bit of what traditional approach we have in brain map mapping research edge.
2650490	2658954	C	0.9080986976623535	So for example, you do an experiment, you capture the activation map shown here for a particular task.
2659002	2662094	C	0.8616678714752197	And I'm showing you here the kind of the one B version of that.
2662132	2671198	C	0.8258891105651855	So the value, the activation versus the vertex in this cortical surface.
2671374	2694786	C	0.8731735348701477	So what traditionally what we do is to because we want to highlight people ask, okay, if a person does a particular task, which regions of the brain are kind of driving those the behavioral performance that we have whilst performing a particular task.
2694818	2720270	C	0.8772602081298828	So what people usually do is to threshold these maps and and you can set threshold barely arbitrarily, and then you can get these clusters of activity and we then make a conclusion that these clusters of activity are the ones kind of driving the behavioral effects that we see whilst performing a task.
2720350	2729110	C	0.7167968153953552	And people can even go further and hone down exactly really highly localized regions if you increase the threshold.
2729530	2750290	C	0.6223559975624084	But if you go further back we started from this whole brain activation map, you can clearly see that by thresholding you actually are removing a lot of important activity patterns that are sub threshold, but they do exist.
2750390	2754270	C	0.7597870230674744	So it's kind of like the analogy.
2755330	2769140	C	0.5658506751060486	By doing these thresholding approach, you're just looking just at the tip of the iceberg, you're ignoring a lot of the important properties of the iceberg that are not seen by the threshold that you set.
2769590	2774834	C	0.8106300234794617	So what we can do is to use the mode approach to actually look.
2774872	2775460	A	0.5319188833236694	At.
2779690	2785154	C	0.8764822483062744	Look at the properties of all the activation maps.
2785282	2790646	C	0.5228642821311951	And here on the left, I'm showing you here the power of each mode.
2790678	2797546	C	0.9272245764732361	So basically the weights that we obtained from the reconstructions that we had a while ago.
2797728	2809694	C	0.9007436037063599	And the figure on the left shows you the results that we have on average for the Human Connector Project data set.
2809812	2814254	C	0.8905611634254456	And on the right is for the 10,000 maps from Neurovolt.
2814382	2822430	C	0.849420964717865	So what you can see here actually is most of the power is contained within about 50 modes.
2822590	2838262	C	0.8789429068565369	And if you remember, the modes represent and each mode represents a different wavelength and they are arranged and that the first couple of modes represent this long spatial wavelength, spatial structure.
2838406	2870002	C	0.7106324434280396	So what this means is that actually in FMI activation maps, most of the power is within those long wavelengths, kind of suggesting that indeed, even by performing a particular task, you are actually activating this almost whole brain so you can see this almost whole brain activity that, again, you will miss out if you do some thresholding effect.
2870136	2882274	C	0.708845317363739	And to further emphasize the importance of these long wavelength patterns, we did a simple experiment where we tried to remove, say, the first couple long wavelength modes.
2882322	2884870	C	0.7699530124664307	And that's the solid curve that you see in here.
2885020	2895594	C	0.5008511543273926	And by doing so, if we start removing those long wavelength modes, the reconstruction accuracy completely drops, even by just removing 25% of them.
2895712	2905898	C	0.5704589486122131	But if we just remove the short wavelength modes so starting from the right, the effect on the reconstruction accuracy is not that significant.
2905994	2919220	C	0.8105570673942566	So again, alluding to the fact that these long wavelength modes are really important and they describe the important structure found in activation maps from FMI data.
2920550	2929634	C	0.6159719824790955	So again, we've shown how the modes can explain and represent spatial activation patterns.
2929762	2942538	C	0.895521342754364	What happens with the dynamics and the way we can do this is we go back to the crux of the neural field theory, which the geometric argument modes were based from.
2942704	2944934	C	0.7605392932891846	And Neurofield theory is very generalized.
2944982	2951702	C	0.8231250643730164	You can construct different populations of excitatory inhibitory neurons and you can even connect the thyroids and so on and so forth.
2951846	2960750	C	0.8352460861206055	But the important bits to remember is that mirror field theory relies on the idea that activation propagates through space as waves.
2961730	2985106	C	0.7972738742828369	And to simplify the experiment that we want to do, because we want to model the activity as a function of time, we just focus on the cortex and we simulate the equation based from the wave model and we tune the parameter.
2985298	2990362	C	0.7210874557495117	But if you look at the equation, there are only two parameters and we fix one of them.
2990416	2997290	C	0.6927605271339417	So basically, the model is only relying on tuning one free parameter.
2998270	3004190	C	0.8706561326980591	And what we did was to compare that with a more sophisticated neuromass model.
3004260	3007562	C	0.819494366645813	So, neuromass models rely on the connector.
3007626	3022900	C	0.8814961910247803	So basically you have regions in the brain that they are connected and the connections are based from diffusion MRI and each region will have its own dynamical properties so they evolve through time.
3023510	3028310	C	0.8732752799987793	So it relies a lot of on this connection and again, local dynamics.
3028970	3039400	C	0.6849119663238525	But it's important to highlight that this highly sophisticated model has about 19 parameters and we fix about 15 adults, but we still need to kind of tune about four.
3040170	3054400	C	0.8625346422195435	So in comparison to the wave model, again, wave model only has one and what we did was to how well can it recapitulate functional connectivity data.
3055570	3070690	C	0.8065750598907471	So here I'm showing you an example for the empirical functional connectivity that we have and the resulting model based functional connectivity for both the wave and the neuromass models.
3071030	3087400	C	0.5749074220657349	And we can kind of quantify how well the model based functional connectivity results stack up with respect to the empirical data in a variety of ways.
3087770	3091814	C	0.5742768049240112	One can look at how well does the edge FC.
3091862	3103550	C	0.5136342644691467	So basically each element of this matrix compares between the empirical and the model based data and you can see that both models are performing quite similarly.
3104290	3109066	C	0.8668181300163269	We can also look at the average connectivity within each region.
3109098	3119620	C	0.6909101605415344	So basically you're taking the average of a row or a column and you can see that the wave model now outperforms the neuromus model by a bit.
3119990	3128070	C	0.7382590770721436	And you can gain further because these properties, the first two properties are based on static FC.
3128410	3131942	C	0.8040037155151367	Basically you're kind of averaging the effects across time.
3132076	3141322	C	0.7533847093582153	But we also measured how well two models compare in capturing dynamical properties through time.
3141456	3147674	C	0.6620206832885742	And you see that the wave model actually outperforms the neural mass model.
3147872	3160560	C	0.5978761911392212	And so in summary, for this, it's just to show that the simplicity of the wave model can capture a lot of these properties of functional data.
3161170	3174770	C	0.6696821451187134	Again, highlighting the idea that this wave evolving auto traveling in space and time in the brain is probably a good approximation.
3175930	3182994	C	0.8939456343650818	We also simulated the effect if we stimulate, say, the visual cortex.
3183122	3191338	C	0.8699996471405029	So we just ping the visual cortex and allow it to the activity to propagate through space and time.
3191424	3200310	C	0.8383495807647705	And this will be the propagation starts from the visual cortex and then it goes to the frontal cortex.
3200470	3212400	C	0.8000956773757935	And I think I want to highlight one observation that we found is that we can see that when we started from the visual cortex, the activity starts to separate into two.
3213430	3223086	C	0.8907584547996521	In the psychology and neuroscience literature, people have actually found this effect and they call it the separation into the dorsal and ventral stream.
3223118	3227990	C	0.8390464186668396	And each stream has important cognitive implications.
3228570	3240406	C	0.8097357153892517	But people have tried to explain this separation by capturing the complex layer specific activity, individual cortex.
3240518	3257280	C	0.6393556594848633	But what this simple experiment that we have done has shown that maybe the geometry and the idea of waves propagating could be sufficient in obtaining these kind of physiological effect.
3259730	3269730	C	0.8783132433891296	And then we also tried to compare it with how well does it recapitulate the visual hierarchy that people have found in primates.
3270390	3285682	C	0.8832429647445679	For example, this work in the last couple of years where they also did a simulation where they stimulated the visual cortex.
3285746	3303770	C	0.8535714149475098	And what they found was if you follow regions along the visual hierarchy in the macaque cortex, you see the activity patterns are kind of delayed in a hierarchical way, so they follow the same kind of relationship as the visual hierarchy.
3303930	3305230	C	0.7284672856330872	So we did the same thing.
3305300	3316006	C	0.8980680704116821	We compared the activity, the amplitude of the activity by matching the regions that people found in the visual hierarchy of the maca cortex.
3316058	3324834	C	0.5769439935684204	And we tried to find the regions in the human brain and then we see the same effect.
3324952	3350910	C	0.8339257836341858	And then when we compared it to a typical measure of hierarchy in the neuroimaging space, by using the intracortical myelin map, which is just the ratio of t one and T two, we see the effect that the time to peak of these activation patterns well captures the rank of the intracortical myelin, again highlighting that.
3350980	3360910	C	0.8409109115600586	Indeed, what we're getting is capturing this hierarchical kind of processing starting from the visual cortex.
3361730	3373278	C	0.7519767880439758	And think of the last result that I want to highlight is the subcortex, because again, the brain is not just the cortex.
3373374	3387954	C	0.875339150428772	So what we did was to also calculate the modes from subcortical regions and what we did was to mask these subcortical regions and perform the same and solve the same equation using the whole plastic primary operator.
3388002	3392198	C	0.8710870146751404	And you can get these argument modes for the thalamus triadom and the hippocampus.
3392374	3397574	C	0.8768776655197144	And we compared that to what we call in the field as functional gradients.
3397622	3404400	C	0.6504547595977783	Basically, they are representations, low dimensional representation of resting state FMI data.
3405650	3420338	C	0.9035431742668152	So what we did was to compare the geometric modes for the different subcortical structures and the different functional gradients based on FMI data.
3420504	3447180	C	0.6384239196777344	And you can see that the modes are almost in perfect correspondence with the functional gradients and we see the same effect for the different structures, again, probably highlighting the idea that the geometric effects that we solve in the cortex are much more dominant in the subcortex, that geometry really constraints function.
3450370	3457360	C	0.833716094493866	Just to tie things together, what are the advantages of this approach that we found?
3458290	3469410	C	0.8327571153640747	First, it's a more physical understanding of the relationship between structure and function based on ideas in physics engineering that has been used in the last century.
3469910	3473582	C	0.8513643741607666	The vectoring modes are only based on T one weighted images.
3473726	3483010	C	0.5997163653373718	So it's very simple to perform and the analysis can be done by anyone with structural T one weighted image.
3483170	3490890	C	0.7782913446426392	And hence you can apply it in quite different experimental contexts in both humans, other species, health and disease.
3491550	3500954	C	0.8325275182723999	And finally, to summarize things, hopefully we've shown that geometric modes are indeed more parsimonious than other anatomical modes.
3501082	3520210	C	0.5289500951766968	And this is confirming a lot of the predictions from theoretical calculations of near field theory and highlights the importance of treating the brain as this really physical system in correspondence with what people are doing in physics and engineering.
3521350	3534818	C	0.8150102496147156	But it also highlights the idea that the effects that we see in FMI might be dominated by the effect of this simple local and exponential distance rule connectivity.
3534994	3552718	C	0.6637105345726013	However, the contributions of long range connections are still there, but what we're highlighting is maybe their influence may not be observable with the resolution that we currently have with FMI data.
3552884	3584630	C	0.587882399559021	So it would be interesting to see and perform these experiments in a much more highly resolved, say, track tracing data from other species that we found that evoked activity is dominated by these long wavelength modes, which challenges a lot of the traditional approach we have in the Neuroimaging field where we focus a lot on these focal activations and that traveling waves shaped by geometry are sufficient to explain a lot of physiological phenomena.
3585690	3592700	C	0.837562084197998	They just emerged from the model and we didn't baked all these physiological phenomena into the model.
3593390	3609230	C	0.8004564046859741	And finally that geometric constraints seem to be universally exist in both cortex and subcortex and that we can use one single approach to study the whole brain quite nicely.
3609730	3615842	C	0.8793652653694153	And I just want to add both Alex and I would like to thank all the other co authors of the work.
3615896	3619490	C	0.8584373593330383	It has been a truly multi institute collaboration.
3619990	3635154	C	0.6883438229560852	All the open access data set that we have used and if people are interested in doing our analysis, we have written an open access software package repository in GitHub.
3635202	3636438	C	0.8510113954544067	You can access that in here.
3636524	3647018	C	0.7619289755821228	So people can analyze modes in the brain in quite different contexts that they want to do and I think that's where we want to end.
3647104	3647980	C	0.8529649376869202	Thank you.
3651570	3652174	B	0.9184247851371765	Awesome.
3652292	3655790	B	0.9887635707855225	Well, thank you for the great presentation.
3657090	3658846	B	0.645077645778656	Lot of places to go.
3659028	3661630	B	0.8549931645393372	First I'll pass to Dean.
3664630	3665890	D	0.9208449125289917	Thank you gentlemen.
3667110	3686182	D	0.9051424860954285	I first got wind of this paper through another individual in the active inference community and I think I was the one that may have pounded the table that we might want to do a guest stream on this and it's ticked the paper and really brought it to life.
3686316	3692502	D	0.9890062808990479	So thank you very much, I really appreciate it, especially some of the dynamic images.
3692646	3702206	D	0.8353455662727356	I think it really helps in terms of explaining what you guys were trying to do your work with and your subject matter on.
3702228	3703342	D	0.75941002368927	So I'll just start with that.
3703396	3705342	D	0.8428124785423279	I have some questions later on.
3705396	3711870	D	0.9844022989273071	But just first of all, thank you for a fantastic explanation.
3713430	3714420	A	0.8529649376869202	Thank you.
3718060	3723300	B	0.8821134567260742	When you present this in a neuroscience setting, what's a common response or reaction?
3723380	3733864	B	0.7885139584541321	From the introduction, I could really tell how careful you were to speak to the totality and the different threads in neuroscience.
3733912	3750850	B	0.8106598854064941	So after all that set up and all the statistical analysis that's presented, where does that put people in terms of their own understanding of the way that they've been doing complementary methodologies or orienting their research questions that way.
3754680	3761830	A	0.7808699607849121	Yeah, I think generally people are at least we found that people are quite interested.
3762680	3779240	A	0.7361206412315369	I guess the approach is a bit different to how a neuroscientist would typically think about the brain but kind of aligns with how, say a physicist might narrowly easily start approaching thinking about or modeling the brain.
3779320	3783390	A	0.5964810848236084	And so the work was really trying to bring those two kind of perspectives together.
3784880	3815930	A	0.5263316035270691	I think the reaction is usually kind of this is really interesting, how do I make sense of it or what I do practically, I guess some people might kind of split it artificially into this comparison of odd geometry versus connectivity which is probably not the right way to think about it.
3817180	3829100	A	0.819632887840271	The way we like to think about it is that we're sort of comparing two different models and each of those models makes certain approximations and prioritizes different features.
3830880	3839048	A	0.5957428812980652	The approach we put forward in this paper emphasizes the role of geometry and it does have connectivity embedded in that model.
3839154	3842796	A	0.7377523183822632	It's just a kind of simplified approximation of connectivity.
3842828	3863424	A	0.5162113308906555	This kind of homogeneous distance dependent journal whereas typical connectome centric view will try to capture all the complex connectivity but we'll ignore also the horizontal connectivity that really is what drives activity spreading through the brain that's completely ignored.
3863472	3876490	A	0.5891107320785522	And so really the idea behind this work was to kind of test in a way between these two approaches and see which one's approximations were kind of more useful in a sense.
3879660	3882490	B	0.9085129499435425	Dean, want to add something or I can make a comment there?
3883340	3887112	D	0.6421758532524109	No finish this because then I'm going to ask my questions about the Jello.
3887256	3900480	B	0.9097331762313843	Yeah, well, the statistics was very clear and it was very interesting how with two different data sets there were similar curves with also very different number of samples.
3900900	3911680	B	0.845755934715271	So it was almost like some of the statistical distributions were latched onto relatively early and then that captured the big continent.
3911760	3916664	B	0.8486324548721313	And a lot of the connections are local.
3916862	3940130	B	0.8810708522796631	And this is, of course, a topic to explore about the molecular and the mechanistic electromagnetic basis and whether this to what extent it represents traveling propagating electrochemical waves and or loading heavily on simply diffuse local connections and even the blurry line between those two.
3940740	3962390	B	0.8601470589637756	So it is really like a question about what is being captured because even the EDR with the spread captures a variance component related to local abundant, direct, fast acting connections in some regions and distant connections maybe over the days.
3963240	3972410	B	0.7624629139900208	Distal connections really do matter as the Jello sets and things change.
3972780	3987870	B	0.8724438548088074	But at the exact timescale that some of these patterns are happening at your work is showing new information and comparison with different ways it's been looked at.
3991970	4016770	C	0.5966541171073914	Yeah, I think one of the things that it highlighted even probably just in my head is we've been focusing a lot on trying to capture the effects of this complex connectivity and we ignore all these lateral, horizontal local diffusing connections.
4017450	4033210	C	0.6819363832473755	But what the work has now kind of shown, it highlighted maybe the issues that we have with FMI because truly both of these worlds happen probably simultaneously.
4033630	4047280	C	0.6147955060005188	But just the effects that we're seeing in FMI is probably not the most efficient way to capture both worlds or it cannot hung down the specifics of one world over the other.
4049330	4062290	C	0.7957761287689209	In the results that we're getting is that the effects of this very localized connectivity probably dominates a lot of what we see there FMI.
4063030	4077990	C	0.5417327284812927	But time will tell if we improve the ways we capture brain activity with OpenAI and we can really kind of particularly focus on the different aspects of the approximations.
4079470	4082442	C	0.8690523505210876	To me, that's the kind of the beauty of the work.
4082496	4088170	C	0.6540764570236206	It now highlighted these effects into the broader audience.
4089790	4097338	A	0.6916933059692383	Yeah, everything that we've presented is really addressing things that we were at measure with fMRI.
4097434	4114500	A	0.5432981848716736	So on pretty coarse spatial and temporal scales, there's some theoretical work suggesting that kind of the more complex aspects of connectivity that can't be explained by an EDR might play an important role in supporting dynamic transitions between different brain states.
4115190	4122690	A	0.49435994029045105	But that would happen on a very rapid scale that could be missed with fMRI or at least a typically organized fMRI experiment.
4122850	4133450	A	0.7987343072891235	And so one thing we're interested in looking at further is trying to pick that apart a little bit and trying to isolate the functional contributions of those more complicated connections.
4136510	4137018	B	0.84200119972229	Cool.
4137104	4144240	D	0.9106584787368774	Dean, can I ask about the metaphor of the spoon tapping on the cello there?
4144610	4152800	D	0.8483272790908813	Metaphorically speaking, that seems like an external perturbation on something that can respond to that.
4154230	4159074	D	0.5700591206550598	Now, you'll appreciate I'm asking from a very naive point of view.
4159192	4160980	D	0.7138496041297913	I'm comfortable with it.
4161350	4178150	D	0.8387924432754517	Is there any difference then in terms of, say, something that happens interoceptively, like something that's simply coming from within system and does that show up in the same way as when there's a response to an external stimuli?
4179790	4180154	A	0.5491447448730469	Yeah.
4180192	4197630	A	0.8631728291511536	So the actual underlying model, a key component that we haven't really talked about, is that you have thalamocortical loops and there's a driving input from the thalamus that influences the wave activity in the cortex.
4198050	4206722	A	0.8429418206214905	And they could be sensory thalamic nuclei or they could be interceptive inputs as well.
4206856	4214180	A	0.7966107726097107	And they would be expected to drive cortical activity in different and spatially non uniform ways.
4216230	4222262	A	0.6936889290809631	Really distinguishing between those different types of inputs, as far as I'm aware, hasn't been modeled yet.
4222316	4228834	A	0.8711162209510803	It's all been kind of at a simple level where you treat the cortex homogeneously and you have a single thalamic nucleus.
4228882	4244030	A	0.8427181839942932	I mean, some people have started to split them up, but that would be that the underlying principle and the model could be extended in such a way that you could potentially distinguish between interreceptive and extra receptive inputs.
4245010	4246014	D	0.8873594999313354	Can I ask him one more?
4246052	4251790	C	0.8704217672348022	Dan, I just want to add, for example, the visual cortex experiment that we perform.
4251860	4253754	C	0.5924009084701538	It's a really simple perturbation.
4253802	4260034	C	0.6767178177833557	Right, but it could represent different types of perturbation we just can't particularly capture at the moment.
4260072	4265860	C	0.7776350975036621	But it's like an overlying if we perturb it in a certain way this will be the effect that we see.
4267030	4272920	D	0.865265429019928	You must have known I was going to ask next thing because that was the direction I was going with that visual cortex example.
4273770	4282534	D	0.756562352180481	So from the active inference community, one of the things that we're always dealing with is surprise, say versus sensory attenuation.
4282662	4292078	D	0.8220934867858887	And then on the third vertices, the seeming unawareness prior to the surprise or the attenuated state, but still available.
4292244	4312718	D	0.6889423131942749	And so I'm kind of curious, when you move away from the visual can you still have these sort of same waves going through the brain because other sensory uptake is causing that same you get a surprising feeling, like a sense of weightlessness perhaps.
4312894	4320920	D	0.5831992626190186	Right, or you're an astronaut and that's now something you become attenuated to.
4323210	4334474	D	0.9593972563743591	I know it kind of stuck with the fMRI but it just seems so the possibilities in terms of what you guys are opening up just seems really interesting.
4334672	4344910	D	0.8449973464012146	Is that something like the interoceptive thing where you can see this now having opening up new areas of inquiry?
4348850	4377110	A	0.8086081147193909	Yeah, so I think there's some really interesting work where people have looked at recursive neural nets structured in such a way that you can get wavelike propagation between the elements of the network and have shown that the systems that have that wavelike propagation, it actually facilitates their ability to predict what's happening in, say, a movie.
4377770	4382726	A	0.5451962351799011	So it improves their predictive performance physiologically.
4382918	4394650	A	0.872925877571106	It'll have shown that just with simple visual stimulation you get these back to front propagations but there's also front to back propagations which are presumably encoding the predictions.
4394810	4405950	A	0.829056978225708	And so then the question is how do the top down predictions and the bottom up sensory input get reconciled between the interactions of these waves?
4407190	4424034	A	0.8900708556175232	I think these are kind of really interesting ways forward that we're still coming to terms with and we haven't really quite made sense of what the ways mean for computation.
4424082	4442250	A	0.9553780555725098	I know that Peter Robinson, who's on the slide here has written a couple of papers talking about how these fields can relate to predictions but yeah, I think this is kind of a very new exciting area that is worth exploring.
4442910	4451950	B	0.785744309425354	Yeah, one kind of connection there is like the standing wave that you showed in the physical water pool.
4452530	4473074	B	0.836832582950592	And so now when we're looking at a solid color visually and there's some stable non equilibrium steady state or stable representation or stable population code or all these different things which may not be exhaustive or incompatible like at all, but there's some standing wave.
4473202	4480134	B	0.7465296387672424	Now maybe that is component number 99, just like principal component 99.
4480172	4491386	B	0.7267182469367981	Its amplitude might be small but there's like some mode that's ramping up and it's associated positively or it's ramping down.
4491408	4493130	B	0.8251873850822449	It's associated negatively.
4495010	4507854	B	0.8896152377128601	And there's some standing pattern that amidst the pelting of new sensory observations in like a Bayesian updating setting, it is remaining the same.
4507972	4511714	B	0.5493487119674683	Now the more inertia you have on the distribution, the more stable it's going to be.
4511832	4517906	B	0.5994868278503418	Which is like equivalent to saying the less attention you pay to sensory stimuli, the more stable your priors are going to be.
4518008	4527542	B	0.8919419646263123	It could be a prior about perception, could be a prior about action and there are descending motor patterns as well.
4527676	4548510	B	0.733790397644043	And all these different modes are being played like in an apartment building and there's like different songs but they're happening in different frequency, spatial, temporal and frequency bands so that we can tune in to different songs like different radio stations, but with more spatial richness.
4551010	4568500	B	0.5597127079963684	It's a total expansion of the palate that recapitulates certain aspects of topology and helps us even identify residuals that are most apt to be explained that way.
4569610	4585130	B	0.7568142414093018	But it also opens up to these big waves that get filtered out, like by low pass, potentially filtering in different data sets so that shorter term relationships can become more apparent.
4585550	4597370	B	0.5244802832603455	But that can be the ripple on the wave and so end up throwing out a huge amount just of the sheer information content of rich, dynamical data sets.
4603310	4608340	C	0.959566056728363	Yeah, really interesting concept, trying to wrap my head around it.
4609990	4623074	C	0.9080120921134949	Yes, it's really cool because again, we still don't know because what we found is that for example, in different task data that we have, not all modes are equally excited.
4623202	4630818	C	0.7102575302124023	Certain modes are excited in quite different ways and we don't know yet what these combinations mean.
4630924	4634170	C	0.6596211194992065	Truly behaviorally, cognitively.
4636190	4643100	C	0.5802573561668396	But yeah, we'll keep working on it as palace and see what happens.
4645650	4647280	D	0.824773907661438	That's one more quick question.
4647730	4650480	D	0.809252142906189	I appreciate the geometry part of it.
4653570	4683420	D	0.8820053935050964	So does any of this speak also to sort of the tunneling effects of that eigenvalue or eigen mode eigenvalue quantum piece where you can be riding the surface of this and appreciating that the parsimonious speak to that surface effect?
4684110	4701822	D	0.7917057871818542	Is there anything about this that also helps us understand better how something goes through the wave, like quite literally across from one slope, past the crown and onto the other side?
4701876	4707230	D	0.500767707824707	Or is that again something that you guys weren't really spending a lot of time on?
4707380	4716286	D	0.8424927592277527	But I did notice, I pulled up the paper and I noticed on page eleven you were talking about some of the ways that you were analyzing the volumes.
4716398	4727590	D	0.883309543132782	So that's the context that I was curious about, that sort of tunneling piece to go along with how we sort of follow the patterns on the surface.
4732430	4734800	A	0.6545912623405457	I'm not quite sure I follow you're asking.
4737490	4760970	B	0.8537272810935974	Let me try to see where it comes as I see it, Dean's, a quantum tunneling connoisseur post even and with the basis set of the sine wave, it's like imposing this kind of oscillatory pattern and then you're up, waiting or downweighting.
4760990	4775180	B	0.8061394095420837	But is it possible to use a basis set or is it possible to detect modes in your analysis where there's an effect locally and then there's like a tunnel and there's like a region that the wave doesn't appear to pass through?
4787060	4787616	D	0.608309805393219	By the way.
4787638	4788800	D	0.8880262970924377	Thank you, Daniel.
4797240	4798208	C	0.5293582677841187	Stumped.
4798384	4801844	A	0.7775806188583374	I guess it means on what you mean by tunneling, right?
4801882	4814776	A	0.788342297077179	So, like each mode, like if you look at the high frequency modes, they are quite patchy and so there'll be sort of disjointed areas of high amplitude and low amplitude, but they fluctuate in time, right?
4814798	4816216	A	0.7989410758018494	Like they're standing waves.
4816248	4819084	A	0.818028450012207	And so they'll kind of alternate up and down.
4819202	4832080	A	0.8287242650985718	So in a sense it looks like there's coupling over long distances, but that's just due to the standing wave dynamics, which is just driven by the interference pattern of the traveling waves.
4833220	4849670	A	0.8107861280441284	So I'm not sure if that's kind of what you were getting at, but I guess from a perspective of just if you were just looking at the standing wave dynamics, it would look like things in spatially disjoint locations were kind of coupled in some way.
4851560	4872860	B	0.845750629901886	It's like one jello, it stays put where you hit it and it stays put 1 mile away and it oscillates between like a jump rope or it could be it somewhere that's also very variable, then be like the opposite of a jump rope with one mode.
4873920	4878676	B	0.8410859704017639	And that's what's captured in the set of functions that are then parameterized.
4878728	4900464	B	0.8805769085884094	So then when you assemble them or when you superimpose them, you could get kind of digitized looking outcome patterns in terms of the real empirical correlations and it's map, not territory.
4900512	4905960	B	0.6727126240730286	And it's tempting to interpret these very literally as with many statistical tools.
4906460	4918620	B	0.8060612678527832	When I think, as we've discussed, there's multiple possible mechanisms and in your paper and in your work, you've probably thought of many, many mechanisms that lend themselves to unique empirical predictions.
4920480	4931148	B	0.8804757595062256	But basis set decomposition is used like in SPM, which is kind of like one of the precedents of active inference.
4931244	4935170	B	0.8889182806015015	And the work by Karl Frist and others, it's using basis sets as.
4940180	4941196	A	0.5782390236854553	They used.
4941318	4942660	A	0.5548703074455261	They use it everywhere.
4945240	4952550	B	0.8989307880401611	Do you have any closing or near closing thoughts or where does the work go?
4953340	4960760	B	0.5846919417381287	What data sets are salient or questions or cognitive phenomena or what are you excited about for your lab and for the fields.
4963580	4964650	C	0.8122873306274414	Your lab?
4967840	4972830	A	0.637448787689209	There's a few different ways that we're interested in progressing it.
4973920	4994512	A	0.7746214866638184	So one is, I guess, trying to reconcile this purely geometric approach that makes a very simple approximation with connectivity, with the actual connectivity of the brain, and trying to understand if the contributions of these kind of complex connections are not so easily revealed by a classic fMRI experiment.
4994656	4997200	A	0.8600087761878967	What are their contributions to dynamics?
4997360	5007450	A	0.8888956904411316	And is there a way of kind of bringing some of that complex connectivity into the wave model and trying to get some traction on that question?
5010780	5015144	A	0.5191905498504639	Another aspect is we've done the simplest thing.
5015182	5020670	A	0.5386528968811035	We treat all areas of the cortex as homogeneous, but we know that's not the case.
5021280	5029150	A	0.8505302667617798	Areas vary in terms of the cell density, degree of myelination, level of synaptic complexity and density and so on.
5029760	5032312	A	0.8204841017723083	And so that, in a sense, could be imagined.
5032376	5035596	A	0.8266754150390625	You could imagine that as changing the effective geometry of the cortex.
5035628	5046020	A	0.8800144791603088	And so we're playing around with how do you introduce that heterogeneity and how does that change the mode structure and does that have an impact on your ability to reconstruct dynamics?
5048840	5063144	A	0.6682555675506592	We're then also interested in sort of taking this forward to leverage these approaches for thinking about different ways in which we might be able to map brain changes in different disorders or variations across species and so on.
5063182	5074088	A	0.5660843849182129	And so kind of like classical SPM analyses, but making inference at the modal level and seeing if that can provide some useful insights.
5074264	5077340	A	0.8409503102302551	So there's a few different strategies.
5082940	5084920	B	0.8044846057891846	Any other comments or thoughts?
5086140	5086600	A	0.4936186671257019	No.
5086670	5088904	B	0.8718470335006714	Dean, where do you go after this?
5088942	5089476	B	0.6866146922111511	Dean?
5089588	5092356	B	0.8715755343437195	In your own neuroimaging career?
5092548	5093096	D	0.4936186671257019	No.
5093198	5093896	D	0.6722825169563293	Stop it.
5093998	5095736	D	0.7113781571388245	I just think it was a very clear picture.
5095768	5105390	D	0.969779372215271	And again, I really appreciated the paper itself, but today's presentation sort of brought it to life and made it.
5106720	5130128	D	0.7489081025123596	I know that you guys were really trying to focus on making sure that you got all of your formalities in a row, but just the way you presented it today made it even more come alive in terms of the mechanisms that you use to sort of come up with a clearer picture.
5130304	5132244	D	0.8476375937461853	That's what I came away with.
5132282	5134310	D	0.9663229584693909	So, again, thank you very much.
5135560	5135924	A	0.84200119972229	Cool.
5135962	5137136	C	0.965381920337677	Thanks for the invitation.
5137248	5137924	A	0.8529649376869202	Thank you.
5138042	5138660	A	0.5491447448730469	Yeah.
5138810	5142592	B	0.9143308401107788	We'll look forward to seeing the continuation of this trajectory.
5142656	5143356	B	0.9352793097496033	You're always welcome.
5143418	5144364	B	0.5905475616455078	Come back.
5144482	5146510	B	0.9444290995597839	So thank you both.
5147200	5147724	C	0.8529649376869202	Thank you.
5147762	5148300	A	0.748913586139679	Thanks, guys.
5148370	5148844	B	0.639849066734314	See you.
5148882	5149080	B	0.5137446522712708	Bye.
