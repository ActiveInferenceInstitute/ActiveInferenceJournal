SPEAKER_06:
Hello, welcome everyone.

It is July 17th, 2025.

We're in Active Inference Guest Stream 114.1 with several of the authors of How do Inner Screens enable imaginative experience?

Applying the Free Energy Principle directly to the study of conscious experience.

Thank you to the authors who have joined and to Koya for precipitating this stream.

So without further inner screen stream ado, Chris, please, however you'd like to take it and I'll scroll to wherever you need.


SPEAKER_02:
Okay, thank you, Daniel.

Thank you, Adam and Maxwell for being here.

and thanks to our other co-authors who are not here for whatever reason one of which is because we changed the schedule on this presentation by an hour at the very last moment so we just wanted to talk a little bit about this paper and then open it up to questions so it'll be it's good that that you have some questions prepared so what's the basic motivation here

The basic motivation is simple.

If one looks at any kind of standard active inference picture of what's going on, in the middle of that picture is a Markov blanket.

And in fact, we could look at figure one because that illustrates this.

And this is all very familiar.

One has some system that's interacting with some environment.

And the interaction is mediated by a boundary.

And the boundary is what keeps the states of the system conditionally independent from the states of the environment.

It's called a Markov blanket.

In the quantum formulation of the FEP, it's a holographic screen.

They have exactly the same function.

They encode information flowing from the environment to the system.

That's called sensation.

and they encode information that's flowing from the system to the environment that's called action of course that's what it's called from the system's point of view from the environment's point of view the system's actions are its sensations and the environment's actions are the system's sensations so it's all a completely symmetric system

with this Markov blanket boundary in between that encodes the information exchange from one to another so now in this standard picture if we ask what can the system possibly be conscious of there's a fairly obvious answer it can be conscious of its sensations and maybe conscious of its actions because all that's data that's written on its Markov blanket

and then in some vague sense maybe it's conscious of something that's going on inside it and that's where the the problem is what does it mean to say that a system is conscious of internal states or internally generated experience and in the most straightforward reading of the fep

uh that simply doesn't happen all that's going on internally is some dynamical system doing its thing some bunch of physics uh some vector floating around in a state space and we can make this very precise in the quantum formulation and the quantum formulation what's going on inside the system may just be a unitary evolution of some pure state

in some almost isolated hilbert space and so on the inside of the system at least in the quantum formulation it's very easy to stipulate that there's no classical information at all nothing that could be experienced no definite states that aren't big superpositions of all the possible values of all the possible degrees of freedom

so at least in that way of thinking or in that formulation if there are no boundaries inside the system that function as markov blankets there's no possibility of inner experience and if there are boundaries in the inside of the system that function as markov blankets then the experiences encoded on those boundaries are the experiences of the systems that are bounded by those boundaries

i.e.

of parts of the system, not the whole system.

So in this way of thinking about the FEP, which is, again, is kind of the most straightforward possible way of thinking about it, what a system experiences is only the data that's written on its Markov blanket, either by its environment or by itself.

So the motivating question

for this paper is how do we account for imaginative experience in that kind of model and the answer is pretty obvious we've got to invoke some sort of inner boundary or inner markov blanket or inner screen that mediates this experience and

we've got to somehow see the agent of interest as being inside that boundary so that's what we do in this paper um so if you daniel would please fast forward to figure three there it is

uh i don't know whether it's any it's possible to make that a little bit bigger on the screen but yeah that's better um this is kind of a stripped down picture of an active inference agent that's complicated enough to have several perception action loops which we've labeled qrf for quantum reference frame which is the

representation of our perception perception action loop and the quantum formulation and what controls these uh perception action loops specifically by allocating attention to them and we think of attention in again the simplest possible way as allocating energy to allow the things to actually function

um what controls all that is some sort of executive system which is a meta controller or a meta processor in a kind of software language or software architecture language and since these perception action loops are exchanging information with this meta controller there must be a boundary inside and that boundary defines

what the meta controller experiences what the meta controller experiences is the activity state of the perception action loops that's what it's trying to control and it also experiences whatever output they give it so they might identify some object and tell the meta controller oh that's a table or that's a conspecific or that's a predator or that says something else and this system as a whole

experiences what's written on its boundary which is labeled b here by its environment so we have two different kinds of experience going on now we have an experience on an outer screen which is information encoded by the by the environment or information encoded by the system's actions and information on this inner screen called bmc

which is just the experience of the metacontroller.

But it's also the experience of the perception action loops that they get from the metacontroller.

So they can experience the data that the metacontroller writes on their boundaries.

And these sort of black things that look like valves at the top are meant to indicate the flow of control, i.e.

the flow of energy, resources, memory,

precision, whatever you want to call it, from some resource pool to these perception action loops or QRFs.

So this simple architecture does not encode or support any kind of perceptual experience.

So it doesn't support visual imagination or inner speech

or anything like that.

And we can claim that based on two or three decades now of cognitive neuroscience, which indicate that imagination, at least in humans and presumably in mammals and probably in vertebrates,

employs the same kind of input processing that perception does up to a few details so when you have a some sort of imaginative visual experience or or when you engage in inner speech um your fairly low level perceptual processes are engaged and this is fairly well documented so

So imagination is not just something that, for example, the prefrontal cortex does or the executive network does.

It involves the sensory systems.

So to make a model of imagination in this active inference framework that's realistic for the animals that we know about, we need to engage these perceptual modules.

So the solution to doing that

um is actually pretty straightforward and if you'll scroll down to figure four please daniel what we do is just add another boundary and this boundary is labeled b in in this picture and we make the stipulation that b in uh

can and typically does encode all of the information that's on the boundary that's labeled here be out which is the markov blanket around the whole system and that bn is what what the system experiences and this picture is complicated by issues of control not only does the

the system the executive system or the meta controller need to manage the activity of the perception action modules these qrfs it needs to manage the flow of information between be out the boundary that the environment can write directly on and be in and most of the time it's going to leave those channels open

but it needs to be able to close them for example by closing the eyes or stopping up the ears or something like that and then it can allow these perception action modules to see information that either themselves or other perception action modules have written on this inner boundary

so if you look at this picture and think about popular architectures like the global workspace then clearly what we've done here is just distribute the global workspace between the meta processors boundary and the inner screen boundary and we've also indicated by the red horizontal arrows here that

sometimes the meta controller may not actually be possible to completely suppress a channel from the external environment so even when you're sleeping and dreaming for example a loud enough noise can typically wake you up and if you're driving on the highway and sort of idly reminiscing about something events on the highway can rapidly bring you to your senses or else you die

so uh there's heavy evolutionary pressure to keep these channels openable by the external environment and in mammals at least that's implemented by the ventral attention system which can override the dorsal attention system and say no pay attention no kidding that thing in front of you is a tiger so that's what we've done in this paper architecturally

has kind of followed the standard active inference architecture to one logical conclusion about experiencing the content that's created inside the system as if it was content created outside the system.

And the remainder of the paper talks about what we know about this capability, the capability of imagination.

and um the short answer is we know a lot more about it than we did say 20 years ago but we know a lot less about it than we like to so we know very little for example about its phylogenetic distribution we can look at lots of kinds of animals including birds and octopi and certainly mammals

and infer that some of their behavior is playing and some of that play behavior at least may be driven by internal imagination we don't know we can look at human variation and see a lot of differences in human capabilities to have imaginative experience

so for example uh i'm pretty incapable of having visual imaginative experience aside from diagrams and so are a lot of other people um we know that imaginative experiences are involved in various ways in pathology so uh for example uh we know that

one symptom of some sorts of schizophrenia involves uncontrolled imaginative experience or failures of what's called the reality monitoring system confusion between internally generated experience and externally generated experience so a lot turns on how imagination is implemented and so it's important

uh for the active inference project to have an implementation of act of imaginative experience that's fully consistent with all of the other uh architectural assumptions of of active inference so that's what we're trying to provide here and uh we've hopefully provided a very simple um

bare bones kind of minimal assumption model of what's required for this kind of phenomenology.

And hopefully the model is detailed enough to be able to provoke or at least encourage various further experimentation into exactly how imaginative experience works

in the at this point only system where we really have uh access to reports of imaginative experience even though they may not be very reliable and that is us so um that's kind of a summary of what we're doing in this paper

and i'm happy to um answer questions or or if they're not questions for for me defer them to my colleagues who know much more about various aspects of this topic than i do well if i could prompt you uh in a specific direction i think one one nice thing to maybe


SPEAKER_05:
discuss that was a great presentation of the work by the way thank you for being uh so you know thorough and comprehensive um i was wondering if you had a few words maybe to add on the neo-cartesian angle so i think there's a sense in which the work that we've done here kind of vindicates something like a naturalization of the homunculus it certainly makes a lot of these ideas a lot less um silly sounding do you do you have a view there


SPEAKER_02:
Well, I would say it only vindicates, in the same way that the global workspace model does, the idea of an inner screen, an inner locus, if you will, of classical information.

in what could be an otherwise quantum system or an otherwise boundaryless internal boundaryless system it says that to explain certain sorts of phenomenology you need to have some such construct where it differs from the classical homuncular picture which may of course be a parody

is that the systems that can experience what's on the inner screen are in a very real sense smaller than the entire system and one way in which they're smaller is that there has to be stuff between the inner screen and the outer screen and

That stuff architecturally is not experienceable by the system inside the inner screen in this picture.

The other way that it differs is that the executive system and the executive system plus the perception action loops

have very different experiences um and in a lot of kind of i'll call it folk psychology uh the experiencing agent is more or less equated with its metacognitive system so um if i say

i'm currently experiencing x that's by definition a report from my metacognitive system and because it has to be looking at what's going on inside my cognitive system my total cognitive system and i think one implication of this kind of work is that those reports are always unreliable because the metacognitive system is always working with

a very stripped down, coarse-grained, abstracted, reportable experience.

So what I say I'm experiencing is actually not a very good guide to what I'm actually experiencing.

And a corollary of that is what I can remember experiencing is not a terribly good guide to what I'm actually experiencing.

so it it does make those challenges to kind of folk psychological notions of kind of inner life


SPEAKER_05:
Yeah, thanks for that.

That was very interesting.

So I know, Adam, yeah, you unmuted.

I was hoping you also had something to add to that.

I know neo-Cartesianism has been one of the things that, like, I think I got the, you know, I was first introduced to this idea by you and Sam Vasey about at the same time.

So hopefully this also sparks, you know, interest, maybe even joy.


SPEAKER_00:
interest joy and uh trepidation like i guess i can blame you for partially like not giving up on the idea because it's so unpopular because it's just like you know dennett was like so like

clear and firm on this point and so many people joined him on like Descartes errors and I mean clearly there are problems there and like I can't deny what like you know what Chris is saying about like we can't just like blindly trust like folk psychology or our introspective access and we know there has to be distortions

But I guess one thing I was wondering about is whether some quasi-Cartesian intuitions might actually reflect both joints in phenomenological space and potentially guides to how they're realized, like in terms of what sorts of implementations or computational objects they might be.

And so this work from Chris, it comes from a very different background, even though I'm also inspired by the free energy principle.

Chris is coming from the fundamental physics and how quantum systems must have a singular interface or locality.

is created in order to achieve... I'm going to butcher what I'm saying, but the way you're approaching this is very different from me, but very convergent.

And so then this idea of an inner screen, that's something I was suggesting from my reading of both cognitive neuroscience, like neuroimaging literatures, and also attempts at trying to make cross-mappings between machine learning architectures and understandings of neural function and how you might interpret the brain as a kind of hybrid machine learning architecture and generative model.

So in some of the work, some of it explored with Tim Verbalen in the context of robotics, the idea is like interpreting the brain as a cybernetic controller for an embodied agent.


SPEAKER_05:
That's your slam paper with Tim, right?


SPEAKER_00:
Yeah, the slam paper.


SPEAKER_05:
Yeah, cool.

Very cool.


SPEAKER_00:
What's cool is in this work, they have basically one of their core data structures they use for robot autonomy is a view and oppose network.

And so I don't want to over-interpret or over-stress the connection, but I've sometimes somewhat fancifully, but

perhaps I should just commit to the crime, thought of as almost like a kind of quasi-Cartesian theater in homunculus and their relation.

And the idea is you have the view of the robot and its pose as being two very closely entangled data structures that are basically almost heavily mutually informing each other.

Because what you're seeing is informed very heavily about where your sensors are pointed, and that also what you're seeing gives you a sense of what your body is doing.

And so these are the two primary data structures.

And these are also, if you look at, I guess, neural real estate and cortical hierarchies, the brain is dominated by vision and then touch.

And so the idea I've been exploring, and it wasn't, I keep being drawn back to,

It's not part of the hardcore of any theory that if it was falsified, it wouldn't disprove the overall framework, but if it was shown to be evidenced, I think it would provide some support, is that potentially inner portions of the cortical hierarchy as a kind of shared latent workspace

could potentially operate by principles of geometric deep learning and potentially correspond to something like a visuospatial modality and a somatospatial modality, which are mutually coupled and informing.

Something like a Cartesian theater and a homunculus.

And the idea being that this being something like an inner screen and observer, even though it's not really strictly the sense that you don't have homuncular regress and that it's not like you have the clear problem of like,

adducing a fully competent homunculus as an explanation which requires a homunculus inside it, the idea of something like a centralized body-like data structure in relation to something like a centralized visuospatial modality, and that these two mutually informing each other is part of what brings coherence to the sensorium.

So in Chris's work here, it's like showing how, like in coupling quantum systems, you need a kind of singular interface

to establish locality and coherence.

I'm going to need you to, like, rescue me, Chris, because I shouldn't be speaking until I'm speaking at the school.

But at least shamanistically, I interpret this as a kind of convergence of some quasi-Cartesian intuitions.

Now, how far you want to go with them, I don't want to say we've vindicated folk psychology.

And the points you made about you know introspection has to get it wrong.

It's the whole point of maps have to be simpler than their territories.

They have to diverge.

But I do wonder whether...

what you've arrived at here could actually provide some uh vindication for some folk intuitions of a of a quasi-cartesian variety of the kind even that um dennett for all those years cautioned us against that's you know i i know that's that's my personal inter um uh one of the ways i'm uh thinking of this but you know i i know it's like nothing you're suggesting actually firmly establishes that or depends on it or right so that's my ramble i don't know if that made any sense


SPEAKER_05:
I thought that was a great ramble.


SPEAKER_02:
Thank you.

Yeah, what Dennett and others fundamentally cautioned against was kind of regressive homuncularism, where every layer basically has the same conceptual structure and every layer has basically the same experience.

And of course, that won't do, right?

so i think what the what the markov blanket construction i think forces us to do is be very careful about saying

who has access to what information within any complicated layered hierarchical multi-component cognitive system and um because it it any such um componentization

makes each of the components an agent and so each of the components has an environment that they exchange information with and so i think what the what the fep encourages is just being very careful about that and um not assuming that a component has access to information

that it can't get from some part of its environment.

So if we think of multiple components interacting with a shared memory, which is basically what the GNW is, then they have access to whatever information is written in the shared memory.

And that's not kind of a difficult thing to think about.

and that information may be fairly rich but what it isn't is the same as the total experience of any combination of those systems uh each each system has its own experience of whatever is written in that shared memory and kind of the broadest

brush access to that information is is more or less by definition what we call the meta controller the executive system or something along those lines but again that's that's always coarse-grained so i yeah i i don't think the two views are inconsistent i think well the if the

the active inference picture of things is is just a way of being precise about it thanks um do you want to ask one of your questions sweetie yeah i was um i was thinking about the uh


SPEAKER_04:
A metacognitive system is like a place to gather the memories or it's like the reason why we have shared memories in the first place.

That way around, like a locus to which the memories of the other systems can be shared to or something like that.

But yeah, that's highly speculative.

So I was thinking like one thing we didn't talk about at all was this like the quantum reference frames.

What we understand under this, we skip like the figure and where they end.

It's like the coarse grained structure on the retina or something like this.

Is this part of quantum reference frames or are they starting

uh later in the hierarchy with concepts like a gestalt or something like that um here so that would be one question um how deep the quantum reference frames we are looking here in the inner screen are i just lost your audio oh i just lost you


SPEAKER_02:
Oh, could the other person hear me or is it?


SPEAKER_04:
Yeah, just repeat the question.

Yeah, so we didn't look at the quantum reference frames.

Can you hear me, Chris?

Yes.

Yeah, okay.

So we didn't talk about the quantum reference frames.

And so one question would be, what are they in a short answer?

And then another question related to this is,

um how deep in the neuronal architecture are we talking about here so um are we talking about like something like pixels or a single um receptors in the retina or are we talking about gestalt representations further down in the hierarchy um so all um

Yeah, so how deep does this kind of reference frames that are in the inner screen?


SPEAKER_02:
OK, well, yeah, thank you.

I can answer both of those, at least to some extent.

So this construct of a quantum reference frame that we use,

is is actually a very old idea that's been formally updated in the last two or three decades uh really under pressure from the quantum communication and quantum security communities so in classical physics you have things called reference frames

uh for example cartesian coordinates or a reference frame and um these are things that we use so clocks meter sticks all of those are reference frames what does that mean well it means two things a reference frame is both a standard

so it defines a kind of unit for example the meter and it's a way of measuring so a meter stick lets you measure things in meters so it's those two concepts kind of bundled together and in classical physics these things are treated as abstractions

uh if you read einstein's work for example he's constantly talking about moving frames of reference etc and observers sitting on moving frames of reference and reporting what they see and on and on and on so as quantum information started to become a discipline it was recognized early on

that this purely abstract way of thinking of reference frames wouldn't do, that the physicality of reference frames actually had to be taken into account.

So a meter stick is not an abstraction.

It's an actual object.

It's a piece of wood or a piece of metal that we hold in our hands.

and we use it to interact with the world and those interactions are actually forceful they require energy and so on so measurement uh is not this completely passive abstract thing where by magic you get some information uh you have to actually kind of whack the world with something with your meter stick

to get some information out of it and that's the fundamental reason for things like heisenberg's uncertainty principle so if you think about reference frames in this physical way and then you think about observers as physical systems like us and you ask so what's required for me to be able to use a meter stick uh i used to have one around here

but I don't see it right now.

So if I have this object, a meter stick, and I want to measure length, then I have to have some concept of what length is.

And that concept has to be encoded in my brain.

It has to be part of me as a physical device.

And if I use a clock,

i have to have some sense of time i have to be able to notice that the hands on the clock have moved for example so i have to have a clock in my head i have to actually be a clock in order to use a clock somewhere out in the external world otherwise i won't even notice that the clock is moving so that led us to think about what does it mean to say that the observer implements

uh quantum reference frames that components of the observer actually are quantum reference frames and we know from neuroscience for example that the hippocampus encodes a very sophisticated 3d reference frame and we know that some of the perihippocampal areas encode fairly fairly sophisticated clocks so we're not making this up it has some connection to neuroscience it's not completely

theoretically motivated so now we can ask uh what how do we want to conceptualize these things and again we think of meter sticks and clocks as just objects in the environment and they may do something like clocks they may have to use energy and they may just sit there like meter sticks

And they may be outcomes of some complicated physical process.

So, for example, if I want to define what up means, if I'm measuring spin, I'm generally going to do it with reference to the Earth's gravitational field.

Well, what's that, right?

It has something to do with the curvature of local spacetime.

But it defines an external reference frame that I can use.

I can use the gravitational field or the magnetic field to think about what up means.

But that requires that I have some representation, that I implement some representation that lets me access by interaction that external direction, directionality, either magnetic

or gravitational.

And we know that we use gravity all the time to move around.

That's one of the key features of our bodily system.

We know that birds, for example, use magnetism in migrating, that kind of thing.

So again, this is stuff that we know about from a neuroscience perspective also.

So to sort of come to a close on the first question,

a quantum reference frame in this way of thinking is a component of the internal process of some observer and you can think of as a component of the internal process of some organism and theoretically that internal process is just some dynamical system or can be represented by some hamiltonian operator or something simple

and of course we have no clue about how to write those operators down but formally they're easy to play with so you can think of a quantum reference frame as just some components of a dynamical system or a hamiltonian so now the question of of how deep are they and that's a subtle question because one can construct an arbitrarily deep hierarchy of operators

And if those operators all have a property, so in quantum theory, for example, all measurement operators are Hermitian, which just means that their eigenvalues are real.

The outputs that they give you are real numbers.

And so you can, since they're finite resolution, you can think of the outputs as binary numbers, some bit strings.

You can construct an arbitrarily large hierarchy of these operators, and the whole hierarchy will be Hermitian, so it will look at the world and give you a real bit string, provided one condition is met, and the condition that has to be met is the operators have to commute.

That's what those arrows mean in this diagram that's on the screen.

and in quantum physics and classical physics of course all operators commute but in quantum theory they don't so quantum theory has the great advantage of giving us a formalism that automatically lets us talk about failures of commutativity which means that if i do operation a and then b i get a different answer than if i do b and then a

And clearly a lot of our interaction with the world has that structure.

If I do one thing and then another thing, the second thing often depends on the result of the first.

And it can depend causally or it can depend non-causally.

And if it depends non-causally, then that's quantum non-communitivity.

Both kinds occur all the time.

so one advantage of the quantum formalism is that it allows you to deal with non-commutativity between operators which translates as the inability to define joint probability distributions over sets of variables but if you can define a joint probability distribution over a set of variables however large it is you can define one qrf over it and so you can think of

um things that for example in the dorsal early dorsal visual system uh identify moving edges okay that's a reference frame that identifies moving what moving edges you can identify lots of those in the visual field or you can think of something that identifies chairs or you can think of something that identifies scenes or you can think of something that identifies short

histories of different scenes and as long as those the operators that build up those identifiers commute you can think of that as one quantum reference frame so you automatically get a very deeply hierarchical system that nonetheless divides splits into fragments when you have operators operations that don't commute


SPEAKER_04:
when looking at the world changes it you know yeah um you want to respond or ask anything else for you please yeah thanks for the uh answer uh really interesting um

I was thinking about what to do with Adam's questions or remarks.

Should I address them now or later?

Sure.

Do you want to talk about it?

Your thoughts?


SPEAKER_06:
Should who address what?


SPEAKER_04:
Adam wrote four messages.


SPEAKER_06:
Yeah, Adam, if you write something in the chat, please say it on the street.


SPEAKER_00:
Okay.

So, Chris, in your work in terms of quantum interpretations of the FEP, some people might...

pattern match and then say like, oh, you mean like orchestrated reduction and like quantum computation.

But no, it's like a quantum formalism for the use of quantum formalism.

And it makes me wonder, like, you know, I reached the limits of my technical depth here, but in terms of like how far we can go with like which, you know, quantum intuitions and interpretations.

So like,

So for instance, when you're thinking of interacting neuronal populations, as they're coming in and out of coherence, and they have probabilistic properties to where they're at in terms of their degree of coherence as they form, they couple with various types of synchrony, these interacting clouds of neurons,

Is there a sense in which part of the reason you could get quantum formalism from a neuronal system is because of its probabilistic nature, like some sort of mapping between Bayesian brain-like ideas, like the born rule of total probability?

But one of the things I was wondering is, so if there is this requirement for

order to get coherence about multiple observers with their multiple reference frames that you get this like establishment of a singular um interface across them with like um locality and um also coherent temporality uh but locality at least as i understand it um could this for instance like um so is this like requirements maybe something that's also sculpted by natural selection or development to some degree like genetics helps along but like

Could this be part of what, could this get, as a precondition for coherence, as like normal populations find ways of, and they interact in different ways to achieve coherence, that they establish the creation of an inner screen with locality as part of this requirement for coherent coupling?

And so it's like,

Again, a ramble.

But thinking about quantum derivation of inner screens, it makes me wonder about quantum formalism as a source of mathematical interpretations of neural functioning.

CF Bayesian brains and born-world tool probability, where they're interacting around populations as fuzzy-blanket probabilistic sets, each with their own reference frame, induce the formation of semi-centralized inner screens as a couple due to the requirement of its creation for coherent coupling with its locality and temporality, informational properties, and this also providing a source of phenomenal coherence slash binding as a source of something like a quasi-Cartesian inner theater,

and perhaps even a basis for egocentric, projective, geometric, visuospatial awareness and sensation slash imagination.

So that's a lot of different things.

But I'm wondering, I'm at the limits of my technical depth here of where I should and shouldn't go with drawing from ideas from quantum physics and whether what I said is somewhat in the ballpark of mappings between neural functioning and quantum formalism.


SPEAKER_02:
yeah i i think this is very much worth pursuing um i i wouldn't be surprised if neuronal coherence is not constantly essentially drawing different boundaries in the nervous system

across which classical information is forced to flow one reason for thinking that is that phase coherence is so important and phase coherence is i mean quantum coherence is a measure of a particular kind of unobservable phase coherence and

phase coherence is something that we can't observe locally right we as as outside observers can observe phase coherence locally unless we just happened to look at the right two neurons or the right two parts of some assemblage right we won't notice that this one over here happens to be phase coherent with that one over there unless we're looking correctly and that's kind of what unobservability means um

There's reasonably good experimental evidence that human cognition exhibits intrinsic contextual or non-causal contextuality.

The relevant work was done by Edebar Zafirov and Andrei Krennikov and their collaborators.

It's very careful experimental work and they understand the mathematics intimately well.

uh so from that perspective i mean krunikov insists on causing calling it quantum-like but i think if if it can only be described correctly using the quantum formalism you might as well just call it a quantum phenomenon because quantum theory doesn't have any

intrinsic scaling or anything like that i mean we associate it with the microscopic for historical reasons but black holes are quantum objects which are some of the biggest things we know anything about um so i think i think there's a lot to be done there i i think um probably the formalism that quantum theory provides

will actually make it much simpler to think about neural behavior because it does build in these kinds of phenomena like phase coherence that we know experimentally are important but we we lose our ability to think about when we just think about things like firing rate


SPEAKER_05:
That was super interesting.

I am going to have to drop.

Unfortunately, I had a hard stop now.

But I think Carl just joined us.

Is that the case?


SPEAKER_01:
Yes, yes.

Excellent.


SPEAKER_05:
So it's like a relay race.

It's good to hear from you, Carl.

So have a good rest of the conversation, everyone.

Thank you very much.

Thank you, Maxwell.


SPEAKER_02:
All right.

Thanks, Maxwell.


SPEAKER_05:
Good to see you all.


SPEAKER_02:
Yeah, I'm going to have to depart fairly soon, but I can at least briefly bridge to Carl's part of the conversation, if you all want to carry on.

What's happened so far, Carl, is just a brief description of what the paper is about, followed by

some conversation about what quantum reference frames are, what inner screens are.

And we're just getting to, thanks to Adam, a discussion of how coherent activity among distributed neurons may draw different effective

uh boundaries and hence create construct different effective markov blankets within the system so you know you know far more about this than i do i suspect not but thank you for orientating me


SPEAKER_06:
Maybe to connect with the earlier discussion and continue on, Carl, how would you see this in light of the theater discussion and responses?

What unique explanations and predictions come from bringing this work together

that were absent packets and parcel and other work that had active inference perspectives on awareness and consciousness but not the quantum do you want to just unpack the theta issue it it came up a little bit but please however you want to summarize and continue


SPEAKER_01:
For my benefit, just to sort of focus me, what specifically were you referring to when talking about theatre?


SPEAKER_06:
Like your paper response to the theatre critics.


SPEAKER_01:
Oh, the theatre.

Sorry, I thought you meant theatre rhythms.


SPEAKER_06:
Oh, yes.


SPEAKER_01:
Right.

I was in a different world.

My apologies.

Let me orientate.

My response to the theatre critics.

Oh, that was with Alan Hobson, yeah.

So that was some time ago.

2016.

Right.

Yeah, well, that's nearly 10 years ago.

Can you remind me what you took from that paper?


SPEAKER_06:
I'll just summarise from the abstract.

You wrote, In brief, we fully concur with the theatre-free formulation offered by DeLega and Dewhurst and take the opportunity to explain why and how we use the Cartesian theatre metaphor.

do this by drawing an analogy between consciousness and evolution the analogy is used to emphasize the circular causality inherent in free energy principle aka active inference earlier times we conclude with a comment on the special forms of active inference that may be associated with self-awareness and how they may be especially informed by dream states and it was in that sort of era with the

I think therefore I am and the early sorts of recursive Bayesian models that you are proposing and working on.

So how do you feel like this paper extends and continues in that line?

What do we gain in terms of explanation and prediction from bringing in the quantum formalism?


SPEAKER_01:
I can only answer that really from a classical perspective, but I think a lot has been added to the stories and a lot of nuances has crept into it, which is nicely framed by the quantum information theoretic formalism.

I'm trying to cast my mind back a decade and what was around then and what is around now.

And certainly there's a lot more

literature addressing consciousness in its various guises and in particular my mind goes to a direct confrontation of issues of experience and phenomenology

um and within that space the role of um hierarchies and specifically the role of um markov blankets in defining those kinds of hierarchies which begs the question if there are hierarchies in the brain first of all

is there an irreducible Markov blanket in the sense that there can be no further sparsity of coupling or conditional independences or dynamical architectures that admit any further Markov blankets?

So this was one of the

contributions from the classical perspective to an early formulation of the paper that Chris has just taken us through.

The other thing that's brought to the table is, if there are Markov blankets within a brain, what constitutes the active states of any of these internal Markov blankets?

So that becomes an interesting focus.

And the story that people like Lars Sandvich-Smith and company, including people like Mark Soames would pursue,

is that the way that you act upon things lower in, say, a centripetal or centrifugal hierarchy would be primarily through mechanisms like attention.

Again, in the classical context would be read as

optimizing the precision or the confidence ascribed to various representations at lower levels and that's i think an interesting move because that weds the psychological interpretation of that gain control active gain control to attention in the psychology literature

It also provides a nice link to Mark Soames's notion of felt uncertainty, remembering that precision is the complement or the inverse of uncertainty and that there are people who would regard any feelings or qualitative experiences would require there to be a mechanism in the brain that would

render what was transparent opaque, that would be attention or would, from the point of view of simulations, be the gain control that comes along with this kind of mental action.

And I use the word mental action as another way of describing the role of, or the process that would be implicit in having active states on Markov blankets in the brain.

So we're talking about a covert kind of action.

And that covert action can be read as attention or it can be read as sort of actively selecting those sources of evidence for belief updating within on the internal side of the Markov blanket.

so i think that's quite a nice story um that sort of is quite accommodating of a number of different perspectives and different kinds of formulation but let's come back to this notion of um an irreducible um markov blanket i think that that in itself is an interesting concept um and in many senses when i read chris talking about the inner screen

what could argue and indeed a lot of people do argue, Shamil being one of these people, Ruben along with Shamil being one of these people, that there are a whole host of inner screens and I think the most recent analogy is that of these smart glasses that through mental action you can render opaque or transparent with screen after screen after screen

So what is the inner screen?

And to my mind, just in a very simple-minded way, that has to be the innermost screen that surrounds the irreducible Markov blanket.

And there's some interesting issues that attend that.

Well, if this irreducible Markov blanket is responsible for

providing messages and if we take the quantum theoretic formulation then we're talking about the holographic screen that

is surrounding the irreducible bulk that constitutes this irreducible part of the system.

And writing that classical information to the active sector of the holographic screen has to have consequences.

And what are those consequences?

Well, we've just said

um from a sort of neurophysiological point of view it has to engage those mechanisms that mediate gain control and immediately you're now drawn to thinking okay well that basically means that the projections of the inner screen um must in some way do some kind of attentional selection beyond

the screen and that's the sort of mental action that I was referring to previously.

So I think the notion of the inner screen is something which we didn't have until a few years ago.

and it if you like to my mind is is a denouement of um arguments that have been formalized and developed over over the past 10 10 years i'm not sure that speaks to the the inner the um the theater debates uh they were more predicated on um

if I remember correctly, a dual aspect monism that inherits from the two kinds of information geometries that you get from a classical physics perspective where you're linking the movement on a statistical manifold

to an information geometry which essentially encapsulates a belief space a little bit changing your mind to exactly the same or supervening on it on the same substrate

which would be a neuronal substrate that you could cast in terms of neural firing, that has itself an information geometry read as classical stochastic thermodynamics.

So whenever there's a space of probability distributions, say of the kind that underwrites statistical or

stochastic thermodynamics, there is a thermodynamics, so there's a natural link there between the energetics of the brain and the informational or representational geometry on two statistical manifolds that supervene on the same substrate.

Perhaps I should pass back to Chris now, who hasn't gone away, so he's still here.

Chris would wrap up that thermodynamic aspect into a thermodynamic free energy sector on the holographic screen.

I think there's an interesting discussion here

um as to whether there is a dual aspect well whether there are any information geometries in the spirit of um the uh statistical manifolds and if there are how are the thermodynamic versus the um the classical information structures linked and i'll have a rest now was that good enough


SPEAKER_04:
Thank you very much.

Great.

Wow.

I want to change directions away from the theater to something else.

In the paper, you talked about the phylogeny of imagination.

And you gave some reasons why the second layer in the screen

was implemented and there was the event of a covert action, social situations could be better managed if some actions are covert and the other thing was the planning depth.

um i was thinking maybe um um there's this cybernetic concept of second order observation to use the inner observation on something else to see what one person is using to experience this thing so to reflect on the own source and i think um this

idea of this inner screen uh could um yeah is really good at capturing this idea so we can use on the inner screen a quantum reference frame to look at another quantum reference frame and to look what a gradual reference frame we used there like um a second observation this could be maybe like another um

um advent for this kind of architecture or is the um could this be achieved with a without this in a screen yeah i i think a very good question is how does the system


SPEAKER_03:
represent its own capabilities.


SPEAKER_02:
So in the kind of simple-minded picture that we drew, the metacognitive system or the controller, the attention system, has to know something about what the various perceptual and action

capabilities of the organism are good for so that it can decide what to spend energy on what to spend energy doing and this we know that this goes way way down in phylogeny so uh we know that even bacteria have very sophisticated ways of um

for example, swapping in or out whole metabolic pathways to deal with different food sources that are present in the environment.

And a key discovery from the 60s and early 70s was how this works, how the food source itself is perceived and how the perception of a food source can trigger

uh the expression of whole families of genes that then encode enzymes for metabolizing and using that food source so you can think of that in terms of meta control and you can think of that as a system saying oh here's something in the environment that tells me

that i should turn off a whole bunch of my information processing and turn on a whole other bunch of my information processing so in a sense i should switch what i'm paying attention to and switch what i'm doing about it i should turn on whole different perception and action capabilities as units

So we know that that kind of capability is extremely deep in phylogeny.

All organisms have that kind of capability.

So when we get up to these very complex organisms that actually have brains, we can ask, what's the analog of that at the level of, for example, neural representations

in the motor system of what the arms or hands can do uh and how those representations are engaged when you're faced with a problem like picking up a coffee cup or you know getting a nail out of a board to the hammer um

your system, and this is not consciously very accessible information, of course, kind of knows how to use the capabilities of the limbs to do these jobs.

And so I think a question for the discussion that Carl was just enunciating about attentional control

and metacognitive representation is this question of how the system represents its own capabilities, from how to use its limbs to how to manage its immune system, the sorts of things that Mark Solms is very engaged with, to much more abstract things like

Now, do I have the cognitive wherewithal to read this paper and understand it?

We do have some sort of understanding of that that's difficult to articulate.

So I think all of those questions are aspects of exactly the same kind of question of

internal resource representation or internal capability representation which an attention system has to have it's if it's going to function in a to do the job that an attention system has to do so i'm i'm afraid i'm going to have to depart too now um

but please carry on as long as you like and uh thankfully this is being recorded so i can see at some later time what was said in this latter part so thank you carl for joining and uh thank you all for for being here and being interested thank you chris


SPEAKER_01:
okay does anyone have a comment or question or i can read uh some of the questions in the live chat yes carl well yeah i'm just picking up on on that last question which i thought was extremely interesting i noticed you put the um strange things paper up on the on the chat i think that was that was quite astute of you because um the very notion

of an inner screen tells you immediately that anything lying behind that inner screen does not have direct access to the actuators to the active states of any cell or any person or indeed any population and that has quite a fundamental implication because if you can always read the internal states within a Markov blanket as

or at least describe them as making inferences about the cause of their sensory sector, what that means is that the internal states behind the inner screen will also be representing in some sense, in some minimal sense, their own actions, because the actions are going to be vicariously a cause of the sensory impressions.

or the sensory sector of the Markov blanket.

That's quite remarkable because what that basically means is that if you have an inner screen, you effectively are inferring what you're doing.

You have Bayesian beliefs about your own behaviour.

you're not directly aware of in the sense that there's a dynamical coupling between your active states.

Say, for example, the primary afferents going to your spinal cord.

So the spinal cord knows exactly the consequences of its action, but the central nervous system or parts of it behind the inner screen do not.

So you've now got this interesting situation

where you've got beliefs posterior beliefs or you can be described as having as if you had posterior beliefs about your own action now if you've got posterior beliefs you must have prior beliefs if you've got prior beliefs about your own action before it's happened you have intentions

So at some level there's a bright line between things that do and do not have intentions.

And I would, you know, just coming back to Chris's examples of, you know,

the base of phylogenetic trees.

Perhaps it would be even simpler just to go for a thermostat.

A thermostat has direct access to the consequences of its action, whereas I do not.

So you could argue, is there a different kind of intentionality?

Or does a thermostat have intentions in the same spirit that I have intentions?

And if your answer is yes, then largely you are...

answering or you are making that discrimination or disambiguation between things that are and are not intentional on the basis of possessing uh possessing an inner screen and then you can have a further argument which i suspect um um was um hinting at is um if i'm inferring what i'm going to do or to use chris's words what am i doing

then the question is, on what temporal scale is the doing expressed?

Am I leading a good life?

Am I going to the shops?

Am I adjusting my posture to increase my comfort?

Am I reflexively responding to heart rate variability?

All of these are very different time constants.

So I think there is a question now of the temporal depth of the imagination that would be effectively a description of the belief updating to evaluate, to infer what your intentions are or to form a posterior belief

that will then be enacted by your reflexes, that is predicated on your prior beliefs about your action, namely your intentions.

So I think there's possibly a vague spectrum of things that just look very myopically into the future, say viruses,

and things that look quite a long way into the future you know things things like you and me so i think there's some really interesting um like purely technical um things that attend any belief updating or any system that is equipped with an inner screen that can then be described as if it is doing a certain kind of belief updating and to finish um the the recursion and the metacognitive aspect

inherits from the fact that you don't have direct access to the consequences of your actions.


SPEAKER_06:
I'll ask a few related questions here in the chat.

So, Andreas asks, can we introspect our Markov blankets or not?

what is being observed who or what is there to observe that are you going to answer that daniel or


SPEAKER_04:
I think Chris would be the prime person to answer those questions.


SPEAKER_01:
I'm not sure in this section of the paper when there is a... Daniel, can you just scroll down just to make sure there's not a figure of R?

Right.

Perhaps that was it.

I think there's quite a straightforward answer to that question, just looking at the architecture of the kind that's being presented on screen now.

So if there is any hierarchical or heterarchical structure

induced by the sparse coupling of any dynamics, whether they're intracellular dynamics or whether they're the connectome in the brain, then that hierarchical structure just is defined by a series of nested Markov blankets.

And just to keep things simple, you can imagine a sandwich cake or a layer cake of Markov blanket after Markov blanket.

And from the point of view of any given Markov blanket, what is it seeing and who is it talking to?

So the Markov blanket is just an expression of the inputs and the outputs.

So in this simplified picture of concentric or layer cakes or hierarchical subsumption hierarchy of Markov blankets, then

Effectively, one level is basically seeing the outputs of another level.

So it's basically seeing the active states of another level.

And the active states of the given level, say level I, now provide the inputs, namely the sensory states of the level below.

And this becomes particularly obvious when you think about predictive coding hierarchies.

So predictive coding hierarchies, you have this notion of ascending and descending messages, where the ascending messages are effectively

free energy gradients or the prediction errors, usually precision weighted prediction errors that ascend from lower levels of the hierarchy, lower Markov blankets, if you like, to the next Markov blanket, which would be the next level up.

And then they are reciprocated, inducing the circular causality, which you always require when thinking about anything

embedded in its environment by descending predictions.

So the actual message is what is seen and what is acted.

Well, in this instance, we're associating action with descending predictions, but usually those predictions are going to be of precision to do the selection we were talking about, but more generally, we can think of them as basically actions on the level below.

So what that basically means is that if I'm on Markov blanket and I have hidden states behind me, I am basically trying to make sense of the prediction errors that are coming from the Markov blanket below me.

And in making sense of those, I am now acting on those blankets by issuing predictions

that I am now going to be using in order to evaluate the prediction error.

And then if you actually write out the requisite variables in a predictive coding scheme and just look at the links, you can quite easily identify the implicit Markov blankets layer after layer after layer.


SPEAKER_04:
Do we have more questions from the chat?


SPEAKER_06:
Do you want to ask any?

Or I can get into the one chat.


SPEAKER_04:
I have another question from the figure four.

Can you stay there on the figure four?

Like every credit reference frame has in and outside

connection to the executive or metacognitive screen.

But the thermodynamic free energy distribution quantum reference frame, the top one, has only an input.

The output is then through valves that co-regulate, I guess, the quantum reference frame activation.

So yeah, I was thinking, why is there only one direction?

And isn't then the teo-dynamic free energy distribution quantum reference frame, that's a terrible name by the way, isn't this then higher in the hierarchy than the executor, which could be

answer to the question that Dorsal attention overrides like the other, something like this.

I'm not sure.


SPEAKER_06:
Yeah, I think a related question that I have to that is like, if layers beget another layer, then what is structurally different about the inner screen

Does it imply similar awarenesses?

Where does the narrative self-identification relate to these finite hierarchies which come to a stop just through the finiteness of things?

But that might be a Chris question related to this diagram.

I guess sort of just in a closing-ish round from Adam and Carl, how do you see this work going forward?

What would you be looking to reduce your uncertainty with further?

What kinds of predictions or experiments do you feel like came out of that?

Or how did the discussions of the authors relate to

what takeaways and what research directions arise now maybe adam first well i never know actually um


SPEAKER_00:
first like to be surprised um in terms of um uh just seeing like independently can like what people come up with because you know i approach this from a very different take um than being like grounded in the formalism you know i've come from like a systems neuroscience and cybernetic perspective um but it's like the ways there are differences are in some ways most interesting to me but also the points of convergence but the um

I guess wondering how far we could go with the quasi-Cartesian interpretations, like not going too far.

But going far enough, I'm wondering whether it can bear, it's like earlier Carl mentioned like mental transparency, but like what different aspects of consciousness studies and phenomenologies can be elucidated by further developments?

So something I posted in the Zoom chat was like, there's been suggestions of, you know,

there being potentially a Bayesian blurb problem and interpretations of the brain as a generative model that could produce awareness.

Like, why doesn't experience seem probabilistic?

Like, why don't we get superpositions?

Why does this seem so classical?

And so, like, Andy Clark, for instance, discussed this in terms of, like, the requirement of consciousness in terms of its functional role as being coupled to mental action or policy selection.

And that doesn't seem incompatible with what's being proposed here, but I wonder to what degree is this inner screen having classical properties part of what mediates this transition?

Or rather part of what would explain another way, not necessarily mutually exclusive because the screen is helping for precision waiting and mental action and attentional selection, but to what degree is this another

uh complementary or separate um solution to the so-called bayesian blur problem um to the extent that it is a problem um and one more thing i guess i would wonder is in terms of like unpacking quasi-cartesian intuitions is so like in the work with like tim like these like two data structures they have are like a view network and a pose network that are like closely coupled for like the state of the um embodied agent relative to the world or for the robot

And something I would wonder is this inner screen, to what extent does it have the properties that would correspond to some of the phenomenology of space?

To what degree is it connected to visual spatial awareness?

But to what degree does it?

connects to somatospatial awareness?

Is that subsumed into visuospatial awareness?

Is there only one modality?

Are there multiple spaces?

These are, I guess, questions I've wondered about in terms of what is the relationship between what phenomenologists might sometimes describe as the lived body

and what the folk might call or what people might call the mind's eye.

So I have a lot of different questions and wondering whether further developments of this theory could constrain some of the many places I have uncertainty.


SPEAKER_01:
So just to pick up on some of the key issues that Adam's just foregrounded for us,

So the Bayesian blur, I only understand through Andy Clark's writing.

And I think Adam picked up on a very important point there that comes back to what we're talking about before in terms of the differences between intentions and action.

Action is a real variable.

It's not a random variable.

You can only infer a random variable.

So that means that your actual action, including your mental action,

is not a random variable and it cannot have a probability distribution it just is so the manifestation of your mental actions can't have a base in blur um just in a very simple-minded way that can also be read in terms of the act of selection

you can only select one of many things um and that's why i quite like it when people use the word selection or attention selection or selecting this as opposed to that um and that the act of selection is you know selection is a verb uh and it does speak to the the um

discrete aspect or the unitary aspect of manifesting your intentions that cannot have a Bayesian blur.

So I think that that's an interesting thing that inherits from the inner screen.

The other interesting thing is that the inner screen

because it can no longer the innermost screen my apologies because it can no longer be sub-partitioned thereby enabling more and more abstract explanations for parts of the inner screen the only way that it can know itself is by acting on its world because its world is just the rest of the brain for us or the rest of the cell for a bacteria

which means that it can only know itself through acting.

And that's quite unique to the inner screen.

And what does that mean in terms of future research?

Well, it means that there may be one or more.

I'm not saying there's just one inner screen.

There could be a number of them in a heterarchical structure.

But it does beg the question now, what is the functional anatomy of this inner screen from a biological point of view?

And that's why I sort of deliberately emphasised the neurobiology and the neuropharmacology of this mental action a la Mark Soames, because we know there has to be connections from the inner screen.

to the cells of origin are the things that do the mental action, which ultimately reduce to classical ascending neuromodulatory systems.

So we've got a good start in principle for the neurobiology of it.

On the other hand, you might start to apply these ideas and the predictions to artificial consciousness.

So we wanted to simulate consciousness, or perhaps we were worried about the ethics of AI alignment.

Can machines suffer?

Are they self-aware?

And all of these questions, I think, rest very much upon the functional architectures and the implicit information geometries that you are literally in a position to build.

And then you're asking questions about, well, where would self-awareness live?

Well, it would have to live in that inner screen, or in that innermost screen, because as every time you move behind these successive screens,

you are, from a technical point of view, compressing your fantasies about what's causing your sensorium of sensorium of sensorium.

And that compression ultimately reduces to the simplest explanation for my sensorium in that it's me.

so you have the which is just another hypothesis but it's a nice simple explanation for gathering together all these different modalities that adam's talking about sort of visual uh visual modalities the auditory the interceptive um all of these can be jointly explained by a very simple hypothesis oh i am an embodied artifact more precisely

It's not just I am one, because if there was just one hypothesis, there would be no hypothesis to select from.

So there'd be no active selection.

So you would never know that.

But as soon as you have different hypotheses about you in different states of mind or you in different states of being,

you can now act upon your brain and ultimately your body to contextualize and gather evidence yes i am in this state of mind uh everything that i'm receiving from my interceptive modalities visual modalities auditory modalities tells me that currently i am scared you know i'm in a dark alley in a city that i do not know my my heart is racing and i feel um petrified

The best explanation for this is that it is me in this particular state of mind.

If I know I'm in that state of mind, then I can act by selectively attenuating or attending to various sources of information.

I will probably, in this instance, attend acutely to my auditory modalities.

less to my visual, but also attend acutely, or in fact, I will actually attenuate my attention to my bodily states in preparation for flight and fight.

And of course, in so doing, I will engage different kinds of reflexes and generate more evidence that I am in a state of panic, angst, or at least arousal and alertness that would prepare me.

to come back to where i started you know would you want to build that into a into a robot you might well do if you believe people like yosha back for example you know if you want um if you want to elude the singularity then he would argue you really need to make our artifacts as conscious and empathetic as we are

So you might have to move in that sort of biomimetic direction in order to guarantee true AI alignment right across the board.


SPEAKER_06:
A great place to take it and leave it for now.

So thank you to the authors for

very provocative paper and for joining this discussion and to okoye for precipitating it and giving a lot of thought to it as well so best of luck till the next screen stream thanks bye bye