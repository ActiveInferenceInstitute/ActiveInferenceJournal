SPEAKER_00:
hello welcome everyone it is september 17th 2025 we are in active inference guest stream 120.1 with emmanuel adieffa olasupo who will be presenting

Modeling Thought in Time, A Physics of Temporal Intelligence as the Next Frontier of AI.

There will be a presentation followed by a discussion.

So if you're watching live, please write any ideas or questions in the live chat.

And thank you for joining, Emmanuel, to you for the presentation.


SPEAKER_01:
Thank you, Daniel.

I appreciate the invitation.

I'm incredibly humbled by the opportunity to give this talk.

The title actually is not Marlene's time, but this is the paper that I think connected you and I. And so I just wanted to start the presentation by sort of clarifying or motivating the talk based upon this paper, this preprint that I had published.


SPEAKER_02:
And just to give a short summary of what the paper is about, you know, the argument is that the

current LLMs that are being used right now, both in the industry and in academia, they have what we call a temporal blindness problem.

which means that they do not represent time in the lived sense as humans do.

And so if the goal is to achieve conscious AI or AI that mimics human cognition and human's ability to manipulate thoughts and emotions, then this paper argues that time is

a foundational feature that needs to be represented akin to how humans experience time in the sense of thinking in time and so on.


SPEAKER_01:
I'll get back to this towards the latter part of the presentation, but I just wanted to motivate the lecture based upon this paper.


SPEAKER_02:
The actual title of the talk is Temporal Intelligence and the Emergent Properties of Consciousness.

Indeed,

you know, I'm going to sort of break this talk into three components.

The first is I'm going to idea of course defined processes, right?

And so this is the type of process in that one would argue supports temporal cognition by structuring how information is organized over time and enabling the system to become more predictive and generative and generate expectations about the temporal sequence of

Impendent inputs.

Right.

And so that course defined process.

And that's the first part that I'll talk about.

And I'll talk about the mathematics that perhaps governs that process, both within biological systems, but also artificial systems.

The second part of this of this talk is going to be on this idea of predictive remapping.

And this is an example of what I would think of as temporal cognition and action.

right um um this is informed by um this idea of active sensing right uh this idea that uh cognitive systems must move in order to compute information in the world right and so i will also speak a little bit about this um and then the third part is the more um um

speculative or perhaps more, it has the potential to be more paradigm shifting if

one or myself or groups or others, anyone can achieve this idea of the emergence of thought, right?

So how does your thought emerge?

How do they flow and synchronize with other people's thoughts?

And can we achieve a mechanistic view of consciousness, right?

Because that I think is key into achieving AGI, right?

Artificial General Intelligence.

And so those three will be the, so this type-part type structure would be kind of how I go about giving this talk.

And so I normally approach questions with physics and mathematics.

So I'm a theoretical physicist.

My PhD is in theoretical physics.

But I normally use the two to try to understand the phenomenons that I study.

And I particularly look at complex systems, particularly biological systems, to explore that.

And so that is important.

to sort of highlight my biases, right?

We all have biases in which we use to sort of inform how we think about the world, right?

So this idea of course defined, I'm illustrated here in this figure, right?

So what you see here is, at least what you can appreciate here is that as you move towards the right, the scene gets more fine, right?

And this is the general principle of course-defined processing.

And so what I'm showing here is a cartoon of neurons in the brain that turns out they compute each part of this processing.

And so you have these early cells, where I represented here, late cell, biphasic, and late.

And so it turns out that in the mice brain,

They are neurons that compute each part of this kind of stage in course defined.

And, you know, you can sort of see in this cartoon here, or in this experiment with Parker et al, where you have the mouse moving along this virtual world, right?

And its neural activity is being recorded.

During that sort of toss that it has been asked to perform.

And you know the work this work here that I'm presented is done with Christopher Neil at the University of Oregon and he basically pioneered the field of Activision.

And what's very profound about this is that this is such a break from how biologists and neuroscientists do experiments because now these animals aren't head fixed, right?

But they're actually moving the world akin to how we as organisms move into the world and collect information.

And so in this paper, they found this course to find process and phenomenon, which I've illustrated again here in cartoon.

Right.

But I want to emphasize that course to find process and is quite ubiquitous.

And what that actually means is that you can actually, you know, there are papers that have published course to find process and in other sensory modalities, hearing, smell, taste, touch.

And so allow me to give you a simple example.

You can imagine you are in a group of crowd and you meet your partner, for example, and you spot her at a distant location.

What you might first do is sort of hear this sort of global and coarser voice of everyone.

And then as she approaches you closer, you kind of fine tune

your auditory system, in a sense, your brain will do that, and then you start to focus on a singular voice.

And so that's an example of this course-defined process and operating in the auditory system, right?

And so you can find this process across sensory modalities, and it's not just across biological systems, but it's also artificial systems, right?

And so the last paper that I cited here,

you know, they use course-defined processing to sort of optimize the grip of robots.

So you can imagine a robot extends its arm, tries to reach for something.

It first needs to kind of get an understanding of the general area of the scene, and then over time will understand, oh, this is a cup, so I have to hold it in a particular way in order to maintain the grip, right?

And so course-defined, excuse me,

The point that I want to make here is that it's a ubiquitous way by which biological systems and artificial systems process information, right?

And so what I am interested in understanding is what are the mathematics, what are the computations that these systems are performing in order to achieve the output that I've shown in this sort of nice illustration, right?

And so the first thing, you know,

And so let me dive into that a little bit.

And again, I am aware that perhaps people that are watching come from different fields.

So I do apologize if it's a little bit too complicated or I haven't explained it as well as I would have liked.

But let me take a stab at this.

So what you see here is we're going to try to understand this phenomenon.

using what we call a recurrent artificial recurrent neural network right and so the hallmark of these networks is one they are connected right to each other so let's just say for example you see e and i there's a line that connects e and to i and i to e they also have self connections right so you see that e is connected to itself i is connected to itself

And they also have the ability to get input, external input.

And so these features or these components make up our current neural network.

And they also go in multiple directions.

So it's not one way, like a feed forward direction, but also feedback and so on and so on.

People in the past have used these networks to try to understand phenomenons in the brain, for example.

And one of those is Murphy and Murphy Miller, 2009, where they published this paper called balance amplification.

And so allow me to try to explain a little bit of what this means.

What does it actually say?

Right.

So here is so we're going to be working with E&I networks.

Right.

And these are excitatory and inhibitory networks in the brain, in the biological system.

And so here shows the equation, we call this a rate model equation, first differential equations, where you have E here, which represents the excitatory parts of that network, right?

And then you have the inhibitory parts of that network.

So we have R, which represents the rate, right, of the network.

We have W, which represents the weight matrix.

And then you have I, which represents the internal or external input that the system will get.

And so you have this first order differential equation,

that basically will tell us, we think of this as the governing equation.

It will tell us how the network behaves over time.

And so this is the tradition that I was working from when I wanted to understand the mathematics governing a course to find.

And so what I have done is basically I took the same governing equations, right?

So E here just represents I the same way.

So this represents the external input.

And I have solved this equation in a fundamentally different way.

And so that equation and the solution for that equation is what we call, what we think of as the course-defined solution.

And so this solution here, what is unique about it is that instead of each unit in the network having a single time by which it's perturbed or responsive, it actually has a heterogeneous, it has the ability to have

Each neuron has the ability to have its own temporal dynamics.

And you can imagine if you want to understand something like course defined, you need a temporal handle in order to kind of play with and parametrize in order to try to simulate whether or not the model can achieve the particular output.

And so that is the novelty of solving this particular equation in the way that I've solved it.

And this is kind of like the first type of

This is the first time that such an equation has been solved in this manner.

And I think of this as a general form of this solution because it can be generalized to a lot of other things, right?

So you can imagine it can be generalized to, you know, not just vision, but, you know, different sensory organisms, sorry, different sensory modalities like audition and so on.

as so long as it has this handle of time and something that is trying to, a preferential object, in this case, let's say vision, right?

And so this cartoon, if you may, right, this is the case when if you were to draw a diagram of the neuron, two neurons, for example, right, so E and I,

But this diagram is basically showing more of a population representation of the network.

And we're going to think of the network as not just E and I, but we're going to think of them as having two different modes.

So you can imagine the network interacts with each other, and you have what we call the difference mode.

So you have E and I, whereby they're kind of competing with each other.

right and you have another mode where you have e plus i and the sum and they're summoned together in a sense right to produce some type of effect i know that's the mouthful that's a little bit hard to process right but i just what i want you to take away from it is that when we look at these networks we're going to look at the modes by which these networks operate within so we have the sum mode and we have the difference mode and it turns out that the difference mode right is what actually creates the initial amplification in the system

So let's say, for example, when E and I are imbalanced, you have this initial amplification.

That's how you can maybe understand the initial parts of this time series.

So in this case here, E and I, they're imbalanced.

The network amplifies, right, based upon its feedforward connection to E plus I. And then as this minus W plus gets stronger, you get an inhibition, and then the network goes down.

And so this is the type of network that and so this is the type of behavior that we would expect.

And so remember, the goal here is to simulate course defined processes.

Right.

And so on the B here is the experimental results.

Right.

That I've shown earlier in the cartoon.

Right.

And then here is the response of the network that I just showed you when we don't solve the equation the way that we the way that I've solved it with the course defined solution.

And, you know, you don't have to be genius to realize and see that these two are not the same.

And so what this is saying is that the way that the way by which these government Murphy Miller saw this equation cannot produce course defined.

But what if we used the course-defined solution, the one that I noted earlier?

What you start to see is something a little bit, it starts to resemble B, right?

But here's the catch.

This simulation here is the case where there is no input into the network.

So this is actually, imagine you have a network or you have a system.

Imagine I took a ball and I put it on top of a hill.

Right.

Because of the and I didn't touch the ball at all because of the the structure or the architecture of the hill, the ball will just roll down.

Right.

So you can think of that as the internal dynamics of the system where there is no no one pushed the ball.

There is just basically the system that you're trying to understand and how it behaves.

And so but at the same time, you see that it doesn't quite mimic B. Now, if I.

create an input into E and I, you can see that D and B looks very similar.

So what does this actually mean?

What does this actually mean?

What this means is that when you think about course defined, when you think about systems in general, it seems that systems have this internal structure that is almost tuned or prepared to behave or be amplified in a way that represents the way in which the inputs

kind of favor, if you may.

Right.

And so basically what this is saying is that, you know, in short.

You can understand course to find using these government, this solution that I have that I have sort of put forth.

He just to not complicate things any further.

this or this is my screen i can't get feedback from anyone but danny can you see my screen can you see my mouth perfect so here you see that e so so so on the y-axis here is the kind of distribution of how i set the time constants of each neuron because if you remember in in my governing equation each neuron can have a different time constant right and so

this here shows that for this kind of like let's take an example this trace here that represents a certain class of neurons the early neurons i set the excitatory neurons to be slower than inhibitory neurons right because you know the higher the value the slower the lower the value the foster right and then you can see that

For this set of neurons, I set it to be the same thing, right?

Excitatory neurons are faster than the inhibitory neurons.

But you can see that the net average of it is slower.

So you see this difference between excitatory and inhibitory.

You see the peaks different.

But you can see, for example, the biphasic, it's almost a flip where the excitatory neurons are slower or faster than the inhibitory neurons.

And so this is something that.

Now the experimentalists can go and say, OK, let's measure specifically the inhibitory neurons and see whether or not they actually represent or recapitulate the model's predictions.

Right.

And this is kind of the point of like why, you know, you know, for those that are not necessarily.

interested in modeling and mathematics, you might wonder, like, why model these things, right?

It's because these models will generate hypotheses and intuitions that experimentalists can now go and test and say, okay, you know, maybe in the biphasic neurons, right, in the biphasic group, the one that looks like an S,

Right.

Based upon Emanuel's predictions, we expect the when we measure the time of the inhibitory neurons, we expect them to be slower than the excitatory neurons.

Right.

And so this is kind of, you know, what we did when we tried to understand whether or not these equations actually recapitulate the biology.

So, you know, so that's the first part of what I'm going to talk about.

This idea of course defined and how it kind of, it kind of gives you a hint as to how the systems kind of are, how the functional architecture or the structure, the internal dynamics of the system is almost prepared to process information in a way that makes sense, right?

In a way by which is economically efficient or energetically efficient.

Right.

And so the second part, I'm going to talk about this idea of what I call retinotopic mechanics.

This is a little bit more of the physics side of me informing some of these questions that people have been trying to solve for many years.

So should I wait for questions or should I continue to go, Daniel?

Because it's a bit of a mouthful, the first part.

Let's continue.

excellent okay so the the second part here i'm going to talk about this idea of predictive remapping and so retinal topics is remap is basic retinal topic mechanics is basically a field that i have put forth right a hybrid of physics and neuroscience and you know the the the the the framework came about based upon this notion of or this idea of um uh um um um

a motion blur that happens when you make eye movements.

So here I'm showing a human eye.

Here I'm showing the mouse, the eye of a rodent making eye movements.

And then here I'm showing the eye of a mouse, sorry, a Drosophila, which is like a fly in a sense, right?

And you can see that all of these systems across scale, they make eye movements, right?

They actively make eye movements around the world to try to collect information, right?

and one of the things that that happens is that whenever you make an eye movement you experience this kind of motion blur right like but sorry you don't experience it but that's actually what happens and so your brain needs to find a way to kind of eliminate and cancel this motion blur so you can see and experience the world in a very continuous and fluid manner

And so one of the questions in neuroscience and physicists and mathematicians have been trying to answer for many years is how does this happen?

Why is it that

You know, you don't experience what you would experience if you were like taking a picture with a camera, for example.

Imagine if the train passed you and you try to take the picture, right, of this fast train with the camera, you would experience the blurriness of that train.

But you and I make these eye movements all the time if you think of the eye as a camera, but we don't experience this motion blur.

How does the brain achieve that, right?

That's really the question that informed this computational framework that I introduced.

And so,

Many people think of neurons as perceptrons, right?

Or like a thermometer, right?

Where, you know, imagine you had a thermometer, right?

It would give you the measurement and it would go back down, right?

Or perceptron, where it's a linear weighted sum of the inputs that you put into the network.

And that's basically the foundation of, you know, AGIs, right?

Where you have these perceptrons and they're performing these operations.

And so with this, you know, I radically turn things on its head.

And I think of these, I think of neurons as spring-loaded sensors, right?

especially because i'm interested in this idea of movement and active sensing so it's not that the neurons themselves are moving but they're they're they're getting information from different parts of the brain that is almost um tethered to where in space they need to acquire information right so you can imagine if i wanted to look here right because i have these two monitors so it looks like i'm looking away but imagine if i if i wanted to look here right

right i would have to sort of allocate some resource towards this part of the visual scene right in order to achieve some level of uh perception right or some desirable outcome and so what you see here is not the neurons themselves moving but how the brain or how these neurons are operating like springs in order to allocate different

neural resources in different parts of space.

In this case, visual space.

So A here is sort of, you know, this spring sort of being attracted to this moss, right?

B here is a case where

It's unresponsive.

So you can imagine a maladaptive case where, you know, you don't want to pay attention to something and so you self-inhibit, right?

Or maybe a disease model where you can't pay attention, ADHD.

You can imagine here C being a case where you hallucinate, right?

So instead of you responding to N, you start responding to something else, right?

And this larger field that you see is what I refer to as elastic fields.

These things have no empirical support yet, but this is something that I think is foundational in understanding active sense and active vision, right?

And so I'm not going to go too much into details of this model.

There's a paper that you can read where I published in Physics Review where I outlined comprehensively these equations and how the prediction goes.

But in short, I bring together a range of papers

that show that, hey, maybe what the brain is doing, it's undergoing these predictive shifts prior to an eye movement.

And these predictive shifts are what kind of blunts this motion blur that would normally occur.

But what I found in this paper, just to conclude, is that these processes, these predictive processes

they're all happening but they're happening at distinct windows in time so for example you can imagine if i wanted to look at an object that is here the peripheral moss would be the thing that is actually pulling the system prior to me making the eye movement and so that predictive remapping of the neurons right of the springs

That would go prior to me making an eye movement such that I wouldn't actually see the intermediate parts.

So it's almost like the resources that I have here would kind of predictably go here so that when I make the eye movement, there is no resource that is actually computed in the intermediary parts for me to actually experience the motion blur.

And so that's the general gist of this kind of idea of predictive remapping.

And my contribution is that I think that the computations and the way to think about this is in the terms of forces, is in the terms of Newtonian mechanics.

And like I said, you can look at the paper if you want to know more.

Ask me questions after this talk.

Now, let's get to the more fun part of this talk rather than the more, I guess, technically intense part.

So ultimately, right, like, you know, the connection is to understand these temporal dynamics in the brain in order to be able to understand consciousness and eventually apply it to artificial intelligence systems.

And so the first part of this is to understand consciousness.

Right.

And, you know,

I think that, you know, I normally use this example as a metaphor to understand conscious behavior or collective intelligence.

So what you see is that, you know, this process is called murmuration, by the way.

And so what you see is that each of these birds, right, they are on one level individuals, but on another level,

They're a collective.

They're part of a group.

They're part of a larger network.

And what you see is that, you know, at some level of description, you know, you see it looks like a chaotic system, very random, very stochastic.

But then at another level, you start to see this kind of collective behavior, this emergent property where they're kind of moving in a very structured manner.

And so I normally think about humans in this sense, right?

I normally think of thought in this sense, or even neurons.

And I'm not the first to think about this.

Giorgio Parisi, who won the Nobel Prize, a physicist, kind of used the bird flocking as one of the systems that he studied to understand complex systems.

And so one of the things that I'm doing right now is to understand these systems in terms of dynamical system, in terms of tractors specifically.

And, you know, many people have done this before, but not

applying it to the question or to the phenomena that i will be applying to which i'll talk about in the next slides and so we have these things called attractors in physics and you know here i'm showing you a strange attractor a tourist attractor a cycle attractive and then here's the point attractive so just to give some intuition right you can think about a pendulum if i had a pendulum for example and i move that pendulum and i let it go right that pendulum at some point

will stop right at the center so there's a particular point that's attracting that pendulum right and that's an intuition that can give you about what a point attractor is right a simple pendulum right the the dynamics of that of that of that system reflects a point attractor and so is there a tractor

Is there an attractor that can help us understand consciousness?

And specifically what I mean in this term by consciousness is just mental thought.

I think of mental thought or mental content as kind of something you need to understand in order to understand consciousness or put forth a theory of consciousness.

And so one question that I think needs to be asked is,

or something that I believe is that to understand consciousness and leverage the insights to build conscious AI, we need a database to use to study and ultimately uncover the fundamental laws governing consciousness.

And so I would argue specifically in the scientific domain and the academic domain, there is no such database, right?

At the very most, you have consciousness researchers looking at maybe 50 subjects or two people in the lab and an fMRI study and, you know,

I don't think that data is sufficient in order to understand something as dramatic, if you may, as consciousness.

And here's an example.

I want you to ask yourself, is there someone in the world right now having the same exact thought as you at this very moment in time?

And if there was, how would you even measure this?

Right.

There is I mean, I'm sure Google has this data, but they're not interested in actually studying consciousness.

They're interested in selling you shit that you don't want to buy.

Right.

But in short, right, like from, you know.

When you think about the study of consciousness and the history of consciousness.

there's not a lot of there isn't any data set that you can actually mine or study to explore to actually give you intuitions about what possibly could be consciousness or collective intelligence and how you can even apply that to an a conscious ai right if if such was even possible and so that is what led to the this you know the the introduction of conversation net and so conversation that is a repository that um has

spontaneous human conversations in real time that you can actually use as a way to measure whether or not uh for example is there someone saying the same exact issue in this exact time right you can start to understand these types of questions or at least study these types of questions and so we just released uh the third uh database for conversation that

And just to give you an example of that, you can sort of go on the ConversationNet website and you can just download this data for free and sort of try to understand

or try to sort of mine this data, right?

And a lot of this data are anonymized, consent of people, and they're coming from my other company, Figbox, that one of the core attributes is connecting people through 20-minute conversations.

And so I just found that as a useful way to sort of support scientific research.

There are some people in the audience that may be aware of ImageNet, which is a database that basically was foundational to introducing data into machine learning systems.

And as a result, ImageNet was used to build AlexNet,

And, you know, here is Professor Hilton, who recently won the Nobel Prize last year.

And this is his student, Alex, who built AlexNet.

And so a lot of this, we think that, you know, conversation that is really important into not just studying consciousness and complexity, but also can help in building conscious AI, more human-like AI, right?

Studying human conversations, spontaneous conversations, and so on.

and and you know alex net led to let's say for example some of the software is used for facial recognition self-driving cars and so forth and so what are some of the things that we want to use on conversation that as far as like to study uh uh um these types of uh uh properties right one of the things we you know some of the things can be this idea of self-recurrence inter-agent synchronicity you know phase relationship invariance and then uh propagation and variance

and so let me just give you a simple example of that so here's a case of of someone's conversation right this individual was having a conversation right and what we did is we measured i'm sorry i'm showing an instance where the person is saying the same exact phrase at different points in time and what you can see is you can see kind of this structure

in this what we call motor cognitive maps, where you kind of see the same structure emerge when a person is seeing the same thing at different points in time.

And so this is some of the ways in which you can start to measure and visualize these sort of things that I've, these sort of, these sort of phenomenons that we're interested in exploring.

And we think of these phenomenons as temporal invariance.

Right.

Things are things that kind of have this predictive pattern that you can kind of tease out from this dataset in order to understand the idea of whether or not, you know, there is some emergent property happening as people are having different thoughts and different speeches and different parts in space.

And so here is just a simple example of how you would think about

attractors.

So what you can see is that there are four attractors in this kind of fictitious simulation.

And each individual, you can think of that as every individual having some thought in some time window.

And so each individual in some ways are being attracted to a particular type of thought.

And so let's say, for example, some famous person just died.

You can imagine that

that you know a lot of people are talking about those things and so they're attracted to that thought right within some window in time right and so this is kind of again this is fictitious right this is not actual data but this just gives you an idea of how you can um how i'm thinking about using a track just to understand and and uh uh this idea of

thoughts or consciousness and again how you can start to mind this type of data to ask these very kind of sci-fi questions that you know prior to conversation that you really can't answer these questions because there's no data to answer now you know ultimately right you know a lot of what I just talked about is very new and you know very orthogonal and very different from the way people think about these things and I understand that um and so

we can just do is you know is there a way for us to learn something about the data that we're on where we're measuring and just add some sort of temporal invariance layer to these networks that you know open ai and anthropic and gemini right these llms right these uh these uh transformers right and you know i'm not particularly um

uh uh optimistic about that part i think to get agi we need to fundamentally build new systems that are radically different right but one of the things that we've done um is build digital twins right and so this is just a this is and this was done actually a lot i i've included these individuals that you see at the bottom

Because they kind of inform the way that I think about, they kind of teach me, to be honest, the way that I think about artificial networks.

So this is someone like, there's a brother to me, Kikurimusa.

You know, he's a machine learning expert in London.

And then this is Daniel Olds.

Him and I work with the conversation at a database and we try to understand systems.

And I should mention that this right here is actually, for the most part, built and trained by Timothy, who is another young, brilliant individual that works with us on ConversationNet.

And so basically what we did is we took these LLMs and we trained them on ConversationNet data to see whether or not they improved performance or not.

And so in short, there are ways in which we can use the LLMs now to try to understand whether or not

They will sort of create more human-like responses and things like that.

But like I said, I'm not particularly convinced.

And I think the endeavor of maybe building new types of systems could potentially be fruitful and groundbreaking.

And so I go back to this paper that I initially brought up at the start of my talk.

um where it's like how do we build systems that think in time how do we build agi that think in time are predictive that can maybe create causal causal temporal inferences and things like that so i've been sort of talking to a very uh you know off you know he he's pretty out there this this guy and and i love him for that and him and i talk a lot about systems and um how to think about systems

And, you know, Rob, you know, we've been thinking about and sort of playing around with this idea of polychronous systems.

So let me explain that a little bit.

What I'm showing you here is a network that has two layers, layers I and layer J. PI, P2 and P3, they represent, let's say, C, A and T. What defines a polychronous group is the temporal pattern.

that um that leads it to let's say for example the second wave so in this case here pi is connected to cat with the latency of one p2 is connected to cat with the latency of five p3 is connected to capital latency of nine right for this word cat to be encoded there needs to be an activation key and a delayed key so in a sense the activation key needs to be

uh configured in a way by which they all activate this node at the same exact time and so you need an activation key that is almost an offset to the delay key and so if you were to add this together like that same example we add eight to um eight to nine eight to one sorry you would get nine zero to nine you would get nine four to five you get nine and so in a sense

If you just took this very simple example as the initial measure or the initial way by which the network is computed or encoded words, you can kind of instantly see that it has to do some temporal computation for it to encode a word.

This is radically different from, let's say, the way LLMs are now where you have

Let's say C as a vector that has a series of numbers.

You have A as a vector with a series of numbers.

You have T as a vector with a series of numbers.

And they're just basically doing these statistical correlations with these tokens, right?

But what's happening here with these polyclinic systems is that the system is actually having to think about the temporal order and the temporal differences in order to encode time, right?

And so, sorry, in order to encode words.

And so what you can get is an increase in representational capacity.

Right.

You can also get emergent behaviors like self-organizing behaviors.

I don't want to go too much into that, but I'm more than happy to explain what that is in the in the question section.

But in short, like this is kind of the work that I've been doing from a both.

from the biological side and the stuff that I've been doing from an artificial side.

Again, I understand that this may not be what you guys are used to hearing when it comes to active inference, but hopefully some of the ways that I'm thinking about things, at least one or two of the things that I've talked about, kind of informs or helps think differently about some of the questions that you all may be engaged in.

And yeah, I appreciate, again, the

the opportunity to talk.

And again, a lot of the pictures that you've seen through the course of this talk is just the people that are critical to either get in the data, analyze the data, the conversations that I've had with the data, or just some of my work.

Um, yeah, I, I would entertain any, uh, questions or comments.

Thank you again.

And, um, it's glad to, um, share some of these ideas, some of these crazy, some, some a little crazy, but it was good to share them.


SPEAKER_00:
Awesome.

Thank you.

All right.

All right.

So for people watching live, they can write a question in the live chat.

I'll read one.

And we'll just go from there.

I wrote down a few things as well.

So Hongzhu wrote, how many inevitable overlappings could there be between complexity versus consciousness?

Is it safe enough for us to assume analyzing complexity is inevitably connected to explanation of consciousness?


SPEAKER_02:
let me just reread it how many inevitable overlapping could there be between complexity versus subjective and phenomenal consciousness so maybe just yeah how do we think about that overlap that's a good question i mean i'm just going to leave this uh this uh image because it's so beautiful and so if no one likes my arms at least they have something good look good to look at so basically right like when i think about i think that's an excellent question because

Ultimately, complexity is connected to consciousness, right?

Understanding the different scales of things, right?

And then eventually understanding how that can inform the question of subjective experience and things like that.

Let me be a little bit more precise with my answer.

You know, I actually just...

connected with the Santa Fe Institute in New Mexico, which they sort of pioneered complexity science.

And, you know, one of the things that I proposed is understanding, using the brain, for example, to understand certain laws and then seeing whether or not they scale across different phenomena.

Let's say, for example, societal groups.

or cells or humans or other organisms.

And so I think ultimately complexity and studying it is important.

The only thing about that is that there have been previous work that have shown that under complexity, stability breaks down.

So the more complex you study something, apparently, the more unstable the system becomes.

And so I think the challenge there, or I think the opportunity is how do we study complexity?

And, you know, the question of can complexity bring forth some stable phenomenon or some stable predictions that mimics kind of, you know,

biological systems for example and the idea of thought and conversations or you know um systems that are adaptive and optimal and so on so i think yes in short complexity is is is is is one of the frontiers and understanding um consciousness and even bringing us to a better understanding of uh how to build conscious ais awesome all right next question is from bert he wrote


SPEAKER_00:
There's two questions, so we'll just do one at a time.

First question.

Could you explain the mechanics implied in the spring visualization?


SPEAKER_02:
Yeah, that's a... Again, whoever asked that question, I will encourage them to read the paper.

But by mechanics, I assume that the person means the sets of equations or the...

the uh the rules that that shift these springs in a particular way so each of these so so you what i have done is that i have i i i i think about neural fields as force fields so you can imagine that there is a particular force or sorry there's a moss in the in the field that is kind of perturbing

these springs in specific directions and the motivation for these masses are very uh biological right so you can imagine i see a very colorful object in my in my visual scene right that colorful object you can think of as a moss by which the springs will kind of move towards especially if i want to look at that object and so the kinematics

just thinking about neurons as particles under Newtonian mechanics, you'll see that they undergo this F equals ma.

These kind of ideas where the mass and the acceleration, they will determine the force by which that particular thing experiences.

And so that's why these springs, that's why I think of them as the Newtonian law of remapping.

They undergo these forces.

And these forces are just effectively ways by which these neurons are allocated their attention dynamically in space and time in order to kind of provide sensitivity to particular things that you want to attend to.

And so the kinematics is basically, you know, Newtonian force equations and, you know, putting that under more biological constraints.

Right.

Like I'll give another very simple example.

You can imagine, for example,

You normally hear when people are in very high-stakes situations, they'll say, I couldn't see anything.

It felt like I was undergoing tunnel vision, in a sense.

In that sense, I would argue that the force that was being exerted in that person's visual system was so strong

that it pulled them outside of their elastos kind of like this larger thing right so if i wanted to look at something right now my neurons need to kind of still it needs to attend to that area but it kind of needs to leave a little bit of resources in my periphery so that i can actually see what's in my in the corner of my eye and so that's what these elastic fields are for they kind of control for the system from over committing right and so it's kind of these biological constraints

along with these kind of Newtonian kinematics that I've combined to create this kind of novel computational field of research.

And so, you know, maybe I wasn't, you know, again, whoever that person is, they can read the paper or connect with me on Figbox.

I'll love to work out the equations with them if they like.

But that's kind of the idea here.

And these types of things you can imagine are useful for like computer vision.

If you want to, like, build a robotic eye, for example, right?

Does it undergo retinotopic mechanics?

How do you create constraints where the robot doesn't completely converge on a single point but has some kind of processing in the periphery?

And again, these elastic fields, there is no biological evidence for it.

It's something that I have kind of predicted.

And there are particular, I'm hoping, experimentalists at some point

uh will kind of uh give this idea some um um some uh some tension and and explore because i think they are uh key into understanding um active sensing and active vision specifically cool yeah just a few comments on that and then i'll ask bert's second question


SPEAKER_00:
the idea of spring loaded systems either coupled oscillators or springs like pullback attractors for joints it's often used in active inference like in the 2022 textbook chapter 8 has examples of spring joints

And then we can generalize that a little bit more to energy based models where there's a potential function like a pullback or a gravity function as you move away.

So like this flat circle with a spring pulling laterally, you could think about the Z axis there.

It's like a bowl.

And then there's like more pullback as you go up the edges of the bowl.

And it is the generalization of Newtonian mechanics to have the Bayesian mechanics, which allows for different energy functions

to exist for a given state space.

So I think it's totally on the right track, and I'm sure you'll find many connections as you learn about these.

Okay.


SPEAKER_02:
That's an excellent point, Daniel.

And I actually want to say one last thing about that.

I actually use the equilibrium term, this FE, right?

This equilibrium force is actually the force that relaxes the spring back.

So I use Hook, and that is motivated by Hook's Law.

So as the system gets to, you can imagine if I pull a spring really hard, it could break, right?

So as the system kind of gets to what I call the elastic limit, the spring will then pull it back.

And then that's really basically what resets it back to its equilibrium state.

So you're exactly right.

That pullback system is also in my model.

And, you know, I found that,

know the law that actually governs this uh remapping obeys newtonian almost it's akin to newtonian's uh uh a law of gravitation right and uh you know um um it's not exactly uh newtonian's law of gravitation but it's very similar the exponent in this case is 1.6 so yeah excellent


SPEAKER_00:
That also reminds me of Lachlan Kent's work on mental gravity, where he explores both the qualitative metaphors and that sort of quantitative gravitational and the different exponents associated with pullback outside of the energy minima.

The second question of Bert was... I think there's a third question.

Oh, yes.

Okay.

Bert wrote,

Are LLM conversations with ChatGPT a huge conversation net like source?

What would be possible with such large data sets?


SPEAKER_02:
Sorry, I didn't understand that question.


SPEAKER_00:
Are LLM conversations, so like human talking to a language model or just to LLMs, a huge conversation net like source?

What would be possible with such large data sets?


SPEAKER_02:
Yeah, I mean,

Just to clarify, conversation that is human to human conversations.

If I understood the question correctly, Daniel, and maybe you can help me.

So the person that asked the question has proposed two scenarios.

The first is an LLM and a human having a conversation, right?

Like you do with ChagiBT and so on.

And then a human having a conversation.

And how would such data


SPEAKER_00:
um i guess um help or um enhance uh or affect that interaction in in those two cases yeah basically as the overall availability of conversation data all the all the combinations human human agent agent etc as we as the amount becomes so vast what kinds of of analyses or what kinds of models become more possible

other than just better recapitulation of chat.


SPEAKER_02:
Yeah.

Well, I will ask the person to put the onus on the person that asked the question because, you know, that's kind of what I wanted to inspire for us to sort of answer that question together, right?

And that's why the data is open source, right?

But a low hanging fruit answer would be you would just use that data to fine tune these models.

right and see whether or not you get different results right um as far as the human to human interact i'm very excited about that because you know one of the reasons why i sort of thought about this this this stuff was what if who you married in the future was someone that you constantly had the same thought at the same exact time what is that's the way that you found your partner

that every time you had a conversation that person was being synchronized in some part of the world i find that deeply profound that like perhaps this entanglement akin to like how particles are entangled could be a way to match people right to find like okay is my person right the person that i'm constantly thinking about and we already see this actually right in the way

when you really really are close with someone you kind of finish their sentences or sometimes they're like oh i was just thinking about you so i have this strong intuition that these things already exist we just don't have a way to measure that and so conversation that is my vision of one day being able to study these spooky actions at a distance as einstein would say right and um you know there's actually a data set right now on conversation net where we have two groups having a conversation at the same exact time

And so people right now can just mine that data and explore that and see whether or not you kind of pick up on these residents.

Right.

And so, you know, that is kind of the two ways that I would say you can sort of use that data and deploy them in the world.

Right.

And, you know, like I said, as we continue to build conversation that, you know, this amount of data that we're trying to collect is going to be unprecedented.

And I'll say one last thing.

Normally, when we think about systems, we think that when they have this sort of, when their internal, like you can imagine that you have this spontaneous conversation that human beings are having, that in those conversations, they're not like forced, they're not scripted, they're not pretended in a sense, right?

And in that sense, if you were to use that type of data, you're able to pick up the more natural properties

of what it means to be a human being right you're able to pick up the more spontaneous parts of cognition because the data set right is very spontaneous and is inscripted so maybe a lot of the conversations that have been trained on on the llms are conversations that are scripted and so they don't capture real human dynamics right the subtleties the noise the the the stochasticity and so again

it offers another avenue into building new types of systems, ones that are more creative, right?

Rather than probabilistic, for example, right?

One that invent context rather than find them, right?

That's how I would think about it in this very moment.


SPEAKER_00:
Nice.

I agree.

I think it

prepares the stage for systems that are part of societies of cognitive agents rather than just like an extended monologue or a book that's univocal is going to be continuing on a thematic thread which is good for a coherence but it still is is very single player um okay last question um well

address this and then also feel free just to close with like where where are you going from here um what happens next but here's the last question are there more questions or that's the actually the last question um the the this is the penultimate question yeah i don't know what that means but i i'll take your word for it yes

Simona wrote, what metric would you say we would end up using to detect or measure if an AI does become conscious?

Turing tests have become outdated.

Where do you see being the next measuring bar?


SPEAKER_02:
What's the name of the person that asked the question?


SPEAKER_00:
Simona.


SPEAKER_02:
Simona.

Oh, of course.

Of course.

Yeah, she would ask that question.

I know Simona, by the way.

Anyways, this is actually a question that...

I was asked by one of the leading pioneers in AI right now.

I forgot.

Oh, Josh Bach.

He asked me that same question, or at least their group asked me that same question.

I am of the opinion that to build conscious AI, first of all, I don't think that any human being can build a conscious AI.

Paradoxically, what I think must happen for

uh conscious ai to occur it is you build kind of the po the the the uh the um the foundational pieces like the clay by which that ai system can become conscious on its own independent of the architecture of the system so let's say for example shimona and i wanted to build a conscious ai what we would do is we would kind of have ideas of

the building blocks of consciousness and then we would use that to build the system in the architecture and then we would leave the system to its own and then come back maybe later and say hey you know are you conscious or do you start to behave very much like let's say for example we use the human right as a measurement right as a human being so in a sense that's a it's a paradoxical answer right in the sense that

We can't build a conscious AI because consciousness, I don't think it's something you can directly built.

It's something that emerges from a system.

And so we would have to create or understand the properties of consciousness.

Right.

As I'm trying to do with conversation that or not just me, but hopefully everyone in the audience in the community and, you know, build these substrates that that that eventually

uh can um lead to ais that become begin to have this kind of self-organization self-emergence right they begin to have an intention right um and so i think i think i think that's very important and if i were to go on a limb and say what is the exact property that is needed or like two things is a self-awareness of course but some concept of death

i think that the ai must invent some concept of death which obviously is going to be based upon like compute right right like the ai must be aware that if i don't power myself in some sense i will stop functioning and i think a concept of death is foundational to an ai becoming conscious um because i think that a lot of the things that we humans do some parts right is driven by our sense of finality

especially in the Western context.

I would say from a more African metaphysics, death is probably not as high in cognition.

It's more about community and village and spirituality.

But I think from a Western metaphysics point of view, death is a key driving force in cognition and the ways by which cognitions kind of preserve themselves in a sense.


SPEAKER_00:
Interesting.

So sort of in closing, what are your next moves?

What are you looking for and how can people learn more and collaborate and everything?


SPEAKER_02:
Yeah.

Well, my, my, my ultimate move is to become top 15 on a particular list.

Um, someone, you know, but, but I would say, no, that was just a joke, but I would say this, that my next move is, you know, continue to work with Christopher O'Neill.

um you know exploring options uh as far as uh you know what i want to do next as far as science um i also have a company uh called figbox right which i mentioned briefly where i'm building that and trying to uh become the trojan horse of social media uh uh in a sense of trying to facilitate and connect people through human conversations and and and uh you know that's something that that i'm working on heavily

um i'm also uh open to collaborators right like um and uh you know i'm you know i have several grants for example one of them at the santa fe institute uh right now um so you know uh for conversation that to scale we definitely need uh people to fund the service and things like that um i also do other things in africa where i support like african thinkers and entrepreneurs i'm very passionate about that i think that uh science needs

to be more interdisciplinary in order to tap into the knowledge and the abilities of people across different spectrums, as well as gender as well.

So I'm very passionate about the inclusivity of science, making sure women are able to contribute, making sure that people of different cultures and races are able to contribute.

I think that in order to solve

complex problems, right?

An interdisciplinary approach is foundational.

And I don't think that science is doing a very good job at that.

So that's another thing that I work on.

And so, yeah, that's kind of like, you know, kind of my future plans.

And, you know, I really am very humbled that you've entertained to have me speak.

And of course, I'd love to build a relationship with you at some point as well.

And so thank you.


SPEAKER_00:
Thank you.

A lot of

Food for thought, a lot of material to explore.

So please be in touch and till next time.

Thanks again.


SPEAKER_01:
Bye.

Yeah.


SPEAKER_02:
I hope that wasn't too mathematically dense, you know, because it could be intense a little bit.


SPEAKER_01:
Yeah.

Yeah.

Yeah.