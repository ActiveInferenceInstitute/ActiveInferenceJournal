SPEAKER_00:
hello and welcome this is active guest stream number 87.2 on september 10 2024 we're continuing on with the cognar ecosystem series with john boyk so john thank you again go for it and we'll look forward to people's comments and questions great thank you daniel


SPEAKER_01:
uh my name is john boyk i'm a active inference institute research fellow um i have two new papers published or excuse me posted as a pre-prints and that's what this live stream these two live streams are about next slide please daniel

So on September 5th, we had our first one.

I encourage listeners to check that out.

The links are in the PDF.

And today we're talking about the second paper, which is the Cognar Ecosystem Preliminary Thoughts on a Story Graph Meaning Representation.

Next slide, please.

So the next several slides are brief recaps of what we discussed before.

The Cognar project is new, and it's large, and it's fairly complex.

And it might help a little bit to set the stage for this talk just by quickly reviewing some of the main components of the Cognar system.

So Cognar means cognitive narrative and it's, uh, it's a, it's a, it's a, um, the, the cognitive system is still a concept.

It's, it's new.

It's very much being created as we speak.

It's conceived to be an open source online ecosystem of tools and services, et cetera, that facilitates group cognition, especially for large groups and especially with regard to deliberation, strategizing, and collective problem solving.

Cognar helps users

and the phrase I like to use is tell their story.

So I use the word story and I use the word narrative in the paper and I will in this talk, but I don't mean story as in fable or I mean story as in

actually what i mean by story is is the a belief model of a user so the idea is that relative to some problem or situation of interest a group as having a online discussion you could say and the users are contributing their an externalization of their belief model to this discussion so they are they are in this in this story they're they're

describing what's the situation or problem, what happened, why did it happen, what might happen next.

What might happen next clearly is predictive, right?

So there's predictions are part of, generally are part of a story.

Who does this situation affect?

Who was involved?

What does it mean?

What should be done?

What can be learned?

All those kinds of questions can be addressed in a story.

And a story really is a model, an externalization of beliefs about how a user sees the world and sees the situation and thinks that the world works.

Next slide, please.

Um, so, uh, stories can be rich and by rich, I mean, potentially long, complex, nuanced, informative, conditional dynamic, et cetera.

So maybe a typical story might be the equivalent of a few pages of text perhaps, but, uh, but, uh, could be even be longer.

It could be like a equivalent to a book chapter, for example, or a story could be very short equivalent to a paragraph that really depends on what the user wants to communicate, but they can be rich.

And this is much different from other online services that are aimed at collaborative decision-making and similar tasks.

This is not a choose multiple choice sort of system where the user can contribute to the conversation by choosing A, B, C, or D, or filling in a blank with a couple of words.

Stories can be much, much richer than that.

There is a backend computational system, and that system assists and guides users in constructing their stories.

assess the stories for quality, but for example, is the story on topic?

Is it comprehensible?

Did the user follow whatever rules the group set out for submitting stories?

And primarily the backend computational systems helps the group to digest and make sense of the many stories that might've been submitted.

And when I say many stories and large group,

I mean, potentially a group of thousands to tens of thousands to hundreds of thousands, even to millions of peoples.

So, you know, potentially very, very large groups.

And the backend system also performs inference for queries that users generates.

For example, I'm part of a group, we're all sharing our stories, and I might have some question about some particular story, like in that story, does the economy, does unemployment go down?

Some question like that, and I can pose a query

or even a more specific query either to the storyteller of that story or to the story itself.

And the system can also generate queries all by itself.

When you're creating a story, the system might ask you, I'm confused, do you mean that the unemployment is going to go down because of this or some such question like that?

But the system, this is quite important, the system does not predict the future.

So it's not going to assess a story for how useful that will be in real life or how accurate it will be.

That's the purpose of a story.

A user does this in their story.

The user says, I believe that if we take actions A, B, C, and D, then unemployment will go down, for example.

And the system does also not assess the realism or accuracy of the story or a group of stories.

And that's really the responsibility of the group that's collecting the stories.

Next slide, please.

Importantly, those last two bullets means that the back-end system does not have to have its own model of how the world works in reality.

It does not need to know mechanics, for example, or biology.

It really just needs to communicate stories and help users digest stories and help users create stories in such a way that users can communicate their belief systems and share their belief systems together.

So if the purpose of the Cognar system is to facilitate group cognition, the obvious question is, well, what is cognition?

In this project, I'm looking at cognition through the active inference lens.

And active inference is a normative Bayesian description of cognition.

In the previous PDFs for the first series, there's links that listeners could follow to find some literature on this.

And obviously, there's references in my papers also.

So an agent has, in active inference, an agent has an internal probabilistic model about how the world works.

And that is the model that is conveyed, really, that is externalized into the story.

So cognition is idealized here, simplified as a four-part cyclic process of predict, act, sense, and learn.

So I underline the word act here because

Often that's really not considered a part of cognition, but in the active inference world, it is.

So for example, I'm learning how to play football.

I predict that if I jump up high and raise my arms, I might catch a high pass.

I act on those predictions.

I sense whether I actually caught the ball or not.

And if I didn't catch the ball, I learn from my mistakes.

I learn that I need to jump higher or reach higher or take some other action.

And then we repeat the process.

And over time, I get better and better at catching that ball.

And in action, an agent favors choices that ensure the greatest resolution of uncertainty under the constraints that are preferred outcomes are realized.

So my preferences are that I catch that ball and I really want to reduce the uncertainty that I'm going to miss it.

So I repeat this learning process over and over and my certainty about catching that ball goes up and up as I get better.

And active inference is normative, so it offers a description of functional cognition.

And that's what we're after in the Cognar system is to facilitate functional cognition as opposed to dysfunctional cognition.

So for example, dysfunctional cognition would not ensure the greatest resolution of uncertainty under the constraints that preferred outcomes are realized.

If uncertainty does not decrease about preferred outcomes, then that's a sign that cognition may have problems.

Next slide, please.

so what is cognar really then um i in in this project i i look at a group as an organism as a cognitive organism so just like any organism it needs to needs to react in the world it needs to do those that four-step process of you know sense act learn uh a cognitive architecture

integrates information and coordinates action.

And every organism has a cognitive architecture, and so do groups.

So do groups viewed as organisms.

And the cognitive architecture for an individual human, say, is the human biology, the central nervous system, the body, and also tools that a human might use.

Computers, for example, could be considered a part of that cognitive architecture.

Notes to remember is an extension of the brain's capacity to remember, for example.

And cognitive architecture for a group might include rules, methods, institutions, sensors, sensors for air pollution, for example, for a group that might be a nation.

And essentially, all the components by which and through which cognition occurs.

As an aside, in a previous series of three papers that we discussed in the previous guest streams a few years ago,

I look at a society's core systems, that is governance systems, economic systems, financial systems, legal systems, as part of that society's cognitive architecture.

And this Cognar project is kind of closely related, or maybe you could say an offshoot of that initial series.

So Cognar is a component of the cognitive architecture of the groups that use it.

And its purpose again is to facilitate functional cognition.

And as I've mentioned, a story is a potentially dynamic externalized representation of a user's internal belief model about how the world works.

Next slide.

Just a couple more of these recaps, and then we're on to the meat of today's talk.

Um, so, um, under the hood, this is how the Cognar system works.

Um, I've used the word story.

I've used the word narrative, but, um, I do not mean textual, uh, information.

So it's not, users don't convey and discuss and, and share their stories in, in text form, but rather in a very special kind of meaning representation that I call a story graph.

And story graphs really are the core innovation of the Cognar system.

It's really what allows the Cognar system to function well.

Um, this diagram shows how story graphs are constructed.

A user might either speak or write a short text passages, a sentence, a few sentences, maybe with some metadata associated with that, perhaps a table, perhaps the graphs, you know, something like that, perhaps a, a few words about how the sentence is supposed to be interpreted.

Um, uh, the system accepts that, uh, those passages, uh, translates that into a story graph fragment, and then merges that story graph fragment into the growing story graph and the story graph fragment and the story graph.

That's, that's, that's the meaning representation, uh, for the Cognar system.

Once the story graph is constructed, then several things can happen.

It could be translated into a natural language, potentially.

So one day you should be able to instruct the system to take the story graph and then read it back to me, play it back to me so I can hear how it sounds, or translate that story graph into some other alternative meaning representation that's maybe better suited for a particular

logical or inference some kind of inference model or some kind of analysis or translate it directly into you know either in part or in whole into some kind of probabilistic model or logical model or other kind of model to conduct either analysis or inference next slide please

Here's an example of a meaning representation that's used.

This is a very popular meaning representation called abstract meaning representation.

This is for the sentence, similar technique is almost impossible to apply to other crops.

such as cotton, soybeans, and rice.

You can see at a glance from this meaning representation that it's graph-based, that's one thing, and that the edges in this graph represent some kind of relationship between words and the sentence.

The rest of it is not important.

And I don't use, we don't use AMR in the Cognar system.

We're actually, the purpose of this second paper is to explore what is the best meaning representation for Cognar?

What does, what should it do?

What should it, how should it be constructed?

What should it be able to accomplish?

Those kinds of questions.

But this graph picture gives you a very rough idea of what we might be after.

Next slide, please.

so um the purpose of the of the story graph meaning representation is to represent a story in a format that's less ambiguous than natural language natural language can be very ambiguous and it should be a representation that is readable and understandable both by humans and computers

As a creator of a story, I should be able to look at that graph and confirm or validate that, yes, that the system understood what I was trying to tell it, things like that.

It provides a structure for inference and analysis.

It serves, as I noted in the previous slide, it serves as input to various kinds of inference and analytical models.

and it serves as an interlingua which is a natural language independent representation that's suitable for translation into other languages and and models next slide so now we now we can really begin with today's talk so what is the cognar meaning representation

That's the question, but whatever it is, it's fit for purpose.

And what does fit for purpose mean?

Daniel, if you back up one slide, this is the purpose.

So the task at hand is to design a meaning representation that is capable of performing these tasks.

Okay, let's go forward two slides.

All right, so I've already showed you an example of AMR, abstract meaning representation.

And I've mentioned that that's a common meaning representation used in research.

So, there's others.

So, before we jump into questions about what should the cognitive meaning representation look like, it's useful to look at the meaning representations that are used in the research world, particularly in the natural language inference.

on natural language inferences inferences falls under the general category of natural language processing there's many tasks that that fall into the categories of nlp and nlu natural language understanding and natural language inference is one of them and perhaps it's analyzed the in a sense the most difficult because in in in nli

for inference, the system or the model really needs to understand the meaning of some text.

So this is the way that NLI is conducted in the research setting.

uh some text is selected usually that text is just a single sentence or maybe you know a short a small number of sentences at the most um and that text might be selected from some some database of of sentences you know where the meaning is is well understood

And that text then is sent to a natural language processing system, so for parsing, word sense disambiguation.

The result of that is then sent to some meaning representation, such as AMR.

And then the meaning representation is used within the inference method.

So this is typically how it's done, but the Cognar is much different.

The setting is much different.

In Cognar, numbers 1, 2, and 3 here happen almost at the same time.

And it's interactive.

So Cognito doesn't select text out of a database to make a story.

Users are contributing text to make a story.

And they're doing that for some reason.

A user wants to convey some information, some aspect of their beliefs about how the world works.

So in an NLI study, that text is fixed.

You're given a sentence, and then the whole system is going to be scored on how well it understands that particular sentence.

But in Cognar, if the system doesn't understand what you tried to say, it can ask you for feedback.

It can say, I don't understand.

Who is the word he referring to, for example?

Or do you mean flame?

Do you mean flame as in a hot burning candle?

Or do you mean flame as in a romantic interest?

So the system can ask you for

ask you questions, give you feedback, maybe suggest phrasing or just simply say, I don't understand what you just entered.

And then the user is able to adjust that text to something that the system can understand.

which of course can reduce ambiguity and error and improve the quality of the story, the text that is being converted into a story.

And as I showed in one of the graphs a few slides ago, the system then takes that text and converts that into a story graph fragment.

And depending on the use case for the Cognar system, say in a use case that involves group decision making, the editing of that story might occur over a series of rounds where people edit their stories, share their stories.

The system helps digest the set of stories in a given round and how they've changed and what they entail and how they're different and how they're similar.

And then at the end of each round, users would have the opportunity maybe to read other people's stories, digest the information from other stories, and maybe change their story if they see an idea that they like or they think, oh, I should have included that.

I meant to, but I didn't, and I'm going to include that in my story now.

So in that process of iteration and rounds, the quality of the story increases even further.

So that's really quite different from the research setting that is typically used in NLI.

And it gives the Cognar system a lot more flexibility as to how it operates.

Because it can interact with the user and ask questions and give feedback to the user and tell the user that it doesn't understand something when it doesn't understand something, it really has the capacity, at least the potential capacity, to create much higher quality stories.

and perform even more complex forms of inference than would be possible in normal NLI studies.

Okay, next slide.

So in the literature over the years, many meaning representations have been proposed.

This is a table from the second article, but there's even more than this.

This is just some selected meaning representations.

And actually, meaning representations are being developed and created regularly.

So it's not that there's three fixed meaning representations and you have to pick one of them.

That's not really the way it works.

People are creating new ones as

as new situations arises, new tasks arises that they're trying to address.

We will focus on a few of them today, and the second paper focuses on a few of them, particularly discourse representation theory, which is, I don't know, about the fifth one down or so.

And there's a few others, type theory with records, the last one.

And we'll also look at Disco Cirque towards the bottom there, which is not exactly a meaning representation, but it's related.

Next slide.

This is a T this is a, uh, graphic from Lou, uh, 2021.

And, uh, he was interested in, in meeting representations for document length text.

And so are we, you know, document length text means, you know, potentially the, the equivalent of a, a book or a book chapter, for example.

um so we have the same interest as lou he's also interested in graphical meaning representations not all meaning representations are graphical and the reason that you might prefer a graphical meaning representation is because graphs computers understand graphs very well that's a it's a way to encode text information such that computers are able to process it well

And I might back up just a minute here and say like, why is it even necessary that a backend computational system assesses stories and, you know,

does inference on stories why not just why not just write your story in text form and and you know share it with the group why why not that well the reason is because uh we're interested here in group in group cognition in the large group setting

So if you have a group of, say, 100,000 people and each of them is submitting some long story that's complicated and nuanced and dynamic, they're going to change it maybe next week as they learn something new.

There's no human that's able to digest, you know, a hundred thousand long stories.

It's just not going to happen.

So the purpose of that backend system is to help use, help the group to digest all of that information and make sense of all that information.

And that's why the computer needs to understand what is written.

And that is one way to do that is to use a graph based meaning representation.

So in Lou's table, you can see that discourse representation theory really scores quite well for all the many things that are necessary for understanding aspects of text.

And for the very same reasons, DRT looks interesting for the Cognar system also.

Next slide, please.

So this is an example of discourse representation theory.

This is the box form, and DRT is not graph-based, inherently graph-based, but people have proposed ways to convert this into a graph.

This is a DRT for the two sentences Max fell, John might have pushed him.

We have some reference, X1, X2.

X1 is a person named Max, and some event happens, he fell, and he fell before some event, and that event being pushed by John.

And the two boxes represent roughly the two sentences, and they're related in the sense that this word because.

because of k1 k2 yeah max fell because john might have pushed him um uh yeah that's that's that i think it's it's kind of straightforward how you would read a drt box next slide please

As I said, DRT itself is not inherently graph-based.

And Lou came up with a version of DRT that he calls Discourse Representation Tree Structure, DRTS.

that is graph-based and that really is aimed at document-length text.

And this looks particularly interesting in the Cognar setting because it's graph-based, it's really constructed for long text, and it has all the benefits that DRT has.

So you could imagine a story graph looking a little bit like this, but still far more sophisticated.

Next slide, please.

By the way, that was a DRTS for the very same two sentences.

Max fell, John might have pushed him.

Another type, this is not really a meaning representation per se, but closely related, something that would be of interest in the Cognar setting, is type theory with records.

So type theory actually is closely related to category theory.

Types are really like category objects.

And type theory with records is a hybrid type theory.

But in type theory with records, there's records, uh, that is, you know, in a sense, a, uh, abstract description of some potential situation.

The potential situation here is, uh,

boy hugs a dog that's so that's the event that is this uh hypothetical that could happen boy hugs a dog and for that to happen there has to be a boy there have to has to be a dog and there has to be some event where the boy hugs the dog so that's written as a record and um

Then there has to be, if that event is perceived in life or in a story or in the imagination, there becomes a witness for that event.

So type theory with records has both record types and witnesses.

And a witness really is like a proof and the proof of the proof of this boy hugs dog event is that, uh, you know, I witnessed a boy and I witnessed a dog and I witnessed this boy hugging the dog.

So there we go.

That's the proof.

And this is actually, type theory with records really kind of captures in a way the way human cognition works.

Because we have in our minds these kind of possible things that could happen.

And then we witness the world and process our sense information.

And we usually make then probabilistic judgments about whether something happened.

uh it's dark i think that was a horse in the front yard it looked like a horse it was big it sounded like a horse i don't know why a horse would be in my front yard but i think i'm pretty sure that was a horse so that would be a potential witness for a horse in the yard type event

TTR is very flexible.

Records can be nested.

It can be as complex as you would like.

It's kind of closely related to DRT, but it can do some things and has some capabilities that maybe DRT doesn't have.

And its inference using type theory through records is potentially fast in that it depends mostly on type checking.

So was there a boy, an individual of type boy?

Was there a dog?

And so on.

And because it depends mostly on type checking,

play well with proof assistance for which there's, you know, sophisticated software programs to do that service proof assistance, logical proof assistance.

So inference with TTR could be potentially fast.

And as I said, it mimics semen cognition more so than interpretation of logical formulas.

It's more flexible than that.

Next slide.

So what I'm doing here, maybe I should have introduced what I'm doing a little bit, but I'm just going through some of the meaning representations that look potentially useful for the Cognar setting.

So I'm going to take a quick diversion from that, though.

We'll get back to it.

I'm going to take a quick diversion and talk about large language models in this setting.

I think probably most users are familiar now with large language models.

In the paper, I call them pre-trained language models.

But they're large in the sense that they have billions of parameters, as the top graph is showing, and the size of the models is increasing over the years.

So they essentially ingest an enormous amount of text that's available.

via the web and other sources and then process that text and find associations between words and between words in a sentence and between words in different sentences and things like that so that through those, you know, it learns those associations and then

can perform various tasks based on based on the information in those associations and um the large language models typically use some kind of transformer attention mechanism which showed in the you know high level view is shown in the bottom the graph there

There's some text comes in at the bottom.

This is a few French words, and that's encoded through an encoder.

That information is sent to the decoder.

There's attention mechanisms mixed in there.

And then the output of the decoder is going to be some answer to a query.

And in this case, it's the translation of the French into English.

I won't go into any, you know, it's not necessary to go into any more detail about how transformers and large language model works, but that's the high level overview.

Next slide.

And the reason that I'm injecting this LLM discussion here is that I really wanted to talk about vector embedding, because that'll be important to the next meaning representation we talk about.

So in using large language models, words are converted, embedded really, into vectors to capture their meaning.

This is just a really simple sort of example, but suppose you have the word cat and suppose you have a list of a vector, really a list, a vector of 30 other words like mom and dog and tree and run and a variety of other words.

Well, cat is gonna be more similar to, the meaning of cat is gonna be more similar to some of those and less similar to others.

So cat might be very similar to tiger.

So if tiger is in this, is one of the possibilities in this list, then that's gonna get a high similarity score.

So from that process, you can imagine constructing a series of numbers that are reflecting how similar some query object is to some reference objects.

or at least reference vectors.

So that's basically how the meaning of words is embedded into vectors.

And then these vectors can be used in a variety of computational tasks.

It also opens up the possibility for what's called a vector database, where on the left there, at the bottom left, the user has some kind of query.

For example, how do you translate this sentence from French into English?

Maybe has some extra content that kind of gives more information about the setting.

So maybe the content in this example is the French phrase has to do with the petroleum industry.

for example.

It's like a little hint as to what this phrase might mean.

That information then is embedded in vectors, and those vectors could be saved in a vector database, a very large vector database.

And then at the bottom right, the LLM could communicate back and forth with the vector database looking for vectors that are good matches for

what the query is, and then eventually the LLM spits out some kind of answer.

So that's a brief overview of vector embedding, and that'll be important in the next meeting representation we discuss.

Next slide, please.

I'm calling the disco-circ here a meaning representation, but that's not actually true.

It's not a formal meaning representation.

It's really more a computational method.

So, a disco-circ, distributional compositional circuits, is kind of a mixture of category theory and distributional semantics.

Distributional semantics is really what I was just referring to with a vector embedding of word meaning.

And it presents a graphical calculus via string diagrams.

An example of a string diagram is shown there.

And this is not just a diagram that sort of shows relationships.

It's actually a computational diagram.

It's the way string diagrams are processed really implies that there's some computational aspect going on here.

So let's just look at the at the very top left there.

We have some entity Alice and Alice is sober and the meaning of Alice and the meaning of sober should be merged in some way to create the concept of a sober Alice.

Right.

And how is that merging done?

Well, it's depicted as a string.

This string diagram is shown here, but

The vector representations of Alice and Sober are then multiplied.

You can think another word for vectors or complicated vectors is tensors.

So these tensors might be very high dimensional.

And then you have some multiplication happening in a high dimensional space.

And that is merging the ideas of Alice and Sober.

And then it continues on through the rest of the graph, multiplication of high dimensional tensors.

And then the answer is whatever the output of the last tensor product

the the last event in that tensor product line of events so um

just a little bit i don't want to really get into category theory too much but it obviously category theory obviously is important in this sort of approach and um and as we'll discuss later it has category theory and applied category theory really it may be applicable in many of the many of the

computational tasks that Cognar has to perform.

So I'll just say a few quick words on it.

So string diagrams represent morphisms and monodal categories.

Category objects are the nouns, the strings.

So the string for Alice, that's a object.

And the boxes are morphisms.

Morphisms are like maps, like functions, sort of.

And they transform one type into another.

So we have the type Alice, and we have the type Solver, and then we're going to do something to merge those two types together.

And then functors map the monoidal category of string diagrams into another category of vector spaces.

And that's where this linear maps can happen, the multiplication.

So again, this string diagram is really a computational diagram more than anything else.

And the other thing maybe that's important here is that since we're talking about linear multiplication operations in high dimensional space,

um this system becomes a little it's really really best suited maybe for uh Quantum computers Quantum computers could handle the you know when they're event when as they become more and more available and as they improve

quantum computers could handle this kind of situation very very well it can still be done on on on you know current systems but would really be ideally suited for quantum computation next slide please

So there's variations on disco circ, uh, actually on disco cat, uh, which is the, the, the disco circ is really aimed at understanding, um, you know, how multiple sentences fit together.

Disco cat is aimed at, uh, understanding single sentences.

uh so a higher order version of disco cat uh as uh

uses a Lambda calculus as a word in this higher order version is a diagram valued higher order function via Lambda calculus.

And then the meaning of a sentence can be given by composing Lambda terms together.

And then that ends up with a diagram that can be interpreted in the category Vect as in Disco Cat.

So this is again a computational graph that we're looking at.

It's for the sentence no man is an island.

And the pink areas in there, that is the areas where the actual vector multiplication is happening.

But because it's offering this higher order function, it can do things that a discusser can't do.

It can easily handle adverbs, propositions, negation, quantifiers, and more.

So this is really interesting.

It has potential.

It may offer a way to use the system that is more applicable to conventional computing rather than quantum computing.

And it's obviously more flexible and can process other kinds of meanings that DiscoCirc has trouble with.

um but um it's new and it this higher order version there's not a higher order version of disco circ yet this is a higher order version for disco cat nevertheless quite interesting next slide please

Okay, so now we're going to jump back and talk a little bit about the potential roles of large language models in Cognar.

But just to kind of summarize what we've already discussed, we've talked about a couple of meaning representations or things like DiscoCirc and higher order DiscoCat that are closely related.

So we have a few ideas now about maybe what a Cognar meaning representation might look like.

It's probably going to be graph-based.

It might lose tree structures.

potential for, you know, especially with quantum computers, potential for kind of using a very different approach of the disco cat and higher order disco circ when it's available.

So that we have a few ideas that we might work from.

And now the question arises, well, why do we even want to use a meaning representation?

Why can't you just take text, you know,

Some sentences and feed that into a large language model and and get the kind of inference that you seek do the kinds of analysis that you seek.

So I want to address that question.

So.

Large language models, they're pretty amazing.

They can do a lot of things.

And they've really, in a sense, taken the research world by a storm in the last few years.

And they've been used in NLI.

So there's numerous studies that have used large language models to perform a variety of NLI tasks.

And there's many NLI tasks, and different databases, and complexities of sentences, and types of linguistic

phenomena that are used for various kinds of NLI tests in various kinds of NLI tests.

So from everything that's been written so far that I've digested, LLMs can be amazing, but they can also really struggle in certain situations.

And it happens that some of those situations are the situations of Cognar.

So LLM struggle with complex text, long text.

If it's not domain specific, they can struggle.

Stories can be about anything.

They can be about industrial processes or environmental issues or social issues or political issues or whatever.

Story can be about anything.

And LLM struggle with that kind of variable setting, variable domains, and also struggle regarding logical reasoning, especially over long texts.

And in some NLI tests, LLMs can really do quite poorly.

Some they do okay, and some they can really fail.

LLMs can also hallucinate.

They can kind of make up people in situations.

And they don't generally, I'm really talking about vanilla LLMs here, but they generally don't provide explainable answers.

And that's kind of important because, for example, I'm writing a story and maybe the

scores my story quality in some way maybe i get a low a low score for story quality because perhaps the story is off you know in theory perhaps the story is off topic or it's uh not just not comprehensible or it's incomplete or you know some kind of problem like that

And I maybe want to know why am I getting a low quality score in the story?

What's going on?

Why did you give me this score?

And in general, at least a vanilla LLM wouldn't be able to provide that answer.

Its answer would be, well, I multiplied all these numbers in some high dimensional space and came up with this value.

And that's why you got a low score.

And in contrast to that, this is just one of many contrasts, using a story graph as an intermediary in the computational process provides several utilities, one of which is that that story graph can then be inspected visually by a user to see if the system has understood

the story correctly.

I can, if I'm, as I'm creating a story, I can view aspects of the story graph to see that, um, uh, that, uh, you know, these two persons in the story are related.

One works for the other, for example, the system understood that correctly.

Um, so, uh, you know, the question here is it's not whether LLMs should be used at all in Cognar.

It's really more of the question of, um, there's two approaches, uh, uh, an approach to natural language inference that does not use any kind of intermediate meaning representation, just, just text as input and the approach where, uh, there is a intermediate meaning representation in this case, a story graph.

And from what I can tell in reading the literature, the LLMs are just not capable of doing all the things, all the sort of inference and analytical processes that would be necessary in the Cognar setting.

So using story graphs as an intermediary in that computational process could be, I think, more useful.

And also keep in mind that suppose that the group is very large, suppose that hundreds of thousands of people are gathering for some event to explore some situation.

And many of them are submitting long stories, long complex stories.

Well, you would have to somehow compare all these stories to each other.

You'd have to have LLMs ingesting very large masses of textual information and then comparing their various parts and then following the logical line of reasoning through a story.

Really, LLMs are just not up to that task as it sits today and as it looks even in the near future.

Next slide, please.

But that doesn't mean that LLMs couldn't still be useful.

So the combination of LLMs and story graphs or story graph fragments is potentially useful and makes sense from what's in the literature today and what looks to be coming down the pike.

So for example, as a user starts to create a story graph and inputs text or spoken language into the system to create a story graph fragment, an LLM might be very useful to help understand the words of those passages

and to put them into a proper story graph fragment that might be one example and another interesting really interesting approach is to use a graph a story graph as a contextual input to an llm so in in theory llms could digest graphical information and use that to provide a context for the query

And LLMs might be useful, for example, in transforming story graphs or story graph fragments into natural language to export a written story of what the story graph is saying.

And several new, more sophisticated approaches are being developed for LLM.

There's many of them.

Some of them are actually what I've just mentioned, using graphical information as input to the LLM.

That's one of the approaches.

And another is processing the outputs of the LLM through some kind of other program, maybe a logic program to enforce semantic constraints.

And you can think of that actually as tool use by LLMs.

So that's really an interesting possibility too.

And there's many others, and these newer, more sophisticated approaches could be useful in many areas of Cognar, potentially.

But nevertheless, it still appears to me that using a meaning representation as an intermediary, either as input to an LLM or as something that the LLM is creating from

Text or spoken language would seem to be the most useful and productive path to follow at this point.

Next slide.

Okay, so now we've talked about several possible meaning representations, graph-based and not graph-based.

Well, yeah, graph-based and not graph-based.

DTR is not, type theory with records is not really graph-based, but potentially it could be converted to graphs.

So now we get an idea of what's out there.

And now the task is, so what is the Cognar meaning representation?

And I said in one of the early slides, whatever that meaning representation is, it's fit for purpose.

And then we talked about what that purpose is.

For example, be readable by both humans and computers, and facilitate analytical and inference computations, et cetera.

so in the paper i offer a desiderata of about 20 or so items roughly 20 items um that this you know that's these are the things that we would want a cognitive meaning representation to to to do or to qualities that we would want it to have

And these seven that I list here is just kind of a smattering out of that larger set of about 20 or so.

Obviously, we would want the graph to be readable by humans and computers for inference and analysis.

And for computational reasons, I think we would want the meaning representation to be graph-based.

Uh, it should be capable of handling document like text stories of very, uh, stories that contain varied linguistic phenomena.

And there's a lot of linguistic phenomena.

If you're, if you're trying, if you really wanna understand natural language, there's a lot of linguistic phenomena to understand.

And some of it is quite challenging.

Um, I, I give examples of that kind of phenomena in the papers, in the two papers.

Uh, the story graph should be reproducible in the sense that similar stories should have similar graphs.

Otherwise, comparing graphs would not be so meaningful.

Comparing two stories by comparing the graphs wouldn't be very meaningful.

The system should be able to handle metadata.

For example, if I'm typing in a passage of text, but I want to refer to a table, I input a table of data or maybe a figure or something.

And, uh, the, the meeting representation ought to be able to handle that.

It ought to be, be able to handle fluid beliefs because we're not creating a story that is static.

We're creating a story that is, that is live and amenable.

And if, if this happens to be a group event, that's going in rounds, I might change my story, parts of it, um, you know, over the next hour or the next day or something.

Um, and it should also be able to handle beliefs about beliefs, right?

So, but, uh, in this story, I'm telling you, I believe that such and such person is acting the way they're acting because they think that such and such is the case.

Uh, so beliefs about beliefs, uh, you know, uh, and non-symmetric information, like in this story, I know that John is a murderer, but my neighbor doesn't know that.

And the meaning representation has to handle uncertainty in all its forms.

In particular, uncertainty about predictions.

So part of the inactive inference, part of the cognitive process is anticipation of what

will happen if some action is taken or not taken.

So these are predictions, anticipations of what will happen if certain actions are taken.

And a story, stories in general, will have predictions in them.

Typically will have predictions in them.

For example, if we tax rich, wealthy people more, the economy will

get better or we'll get worse or, you know, something will happen.

So stories often, usually, uh, typically have predictions in them and there's uncertainty associated with those predictions and uncertainty, even about what the story is saying.

Like, I think I saw a horse in my front yard, but I'm not sure.

And, uh, if it's a horse, I really better go close the gate to the garden or, you know, sue my neighbor for letting their horse eat my corn or, you know, whatever.

um so how so now suddenly you know i showed you the picture of the amr the little graph for a sentence and i showed you the store the graphs for two sentences put together max fell john pushed him now we're you can see that we're talking about something much more sophisticated here we're talking about you know predictions and models modeled you know the output of of probabilistic models and

um we're talking about beliefs about beliefs so that so one could imagine a meaning representation that maybe has multiple layers to it a graph based meaning representation that has multiple nodes and multiple layers and that that a user should be able to zoom in to to look at a particular part or zoom out so

You should be able to have various views of this meaning representation.

And maybe as you zoom out, it should be possible to just kind of summarize what you're looking at.

If you zoom out all the way out of a story, maybe you end up with something similar to a tagline to a movie, like this is a story about

How a man who was once a thief turns his life around and he says it's possible for anyone in his position to do so.

Maybe that's the overall meaning of the story, but then you can zoom in to the different details.

um you should also be able to confer nodes and edges in this meaning representation with with meaning so maybe a group of nodes and edges really represents say a bank you know a bank has some complicated transactions that occur within it and

there's ports to this bank the bank the you know people can put their savings money in this bank or take out loans and various things so you could imagine some kind of compositional or you know

a set of nodes and edges that have meaning in in and of themselves and are also reusable so to make it really useful if you if i want if if many of us are telling stories about banks well it might be very useful to have some bank objects that we have in a library that we can include in our story that makes it much easier to construct the story

And ideally, this whole meaning representation would be compositional in the category sense.

So in category theory, g of f, there's a function or map f and g mapping.

And you apply one to the results of the other.

That's called a composition.

And in category theory, that composition preserves algebraic structure.

And then there's functors between categories that preserve structure, including the composition of morphisms.

So if it's possible, that sort of approach could be used so that it makes sense when you link computational events together in this graph.

In a sense, the meaning is preserved or conveyed through some series of computations.

and transformations.

And that's different than just modularity.

Modularity really means just the ability to chain things together.

So compositional is kind of a more sophisticated setting.

And as I said, you should be able to reuse objects to make it really easy and fast to create graphs for some particular story.

So these are just a small selection of the many desiderata that are listed in the paper.

And whatever the meaning representation is, it would be really good if all or many of these could be fulfilled.

Next slide, please.

I've already mentioned category theory, applied category theory, so just a few more thoughts on that.

Category theory can be used to reduce the complexity of a system, to understand the complexity of a system and then to work with the complexity of a system, to manage complexity.

And compositionality is part of that.

And in particular, it is, I think, possible to use C-sets, which is an object from applied category theory, as property graphs as the basis of story graphs.

So, you know, I've already showed you graph pictures of, you know, like say AMR of what kind of a simple, simple meaning representation might look like, a simple Cognar meaning representation might look like, but that could actually be stored under the hood as property graphs where a node has various, you know, flexible properties that can be attributed to it.

And same with edges, edges can have properties.

And all of that could be really constructed as C-sets from applied category theory.

And then there's also functors for various kinds of transformations, graph-to-graph, graph-to-text transformations that

kind of preserve meaning through the transformations.

I've mentioned zooming in and zooming out and summarization.

There's an interesting paper where an applied category approach has been used to make a system, this in the chemical world, but a systems dynamic model of a situation.

and then convert that into causal loop diagrams.

And causal loop diagrams are kind of a simplified version of a systems dynamic model.

And causal loop diagrams are sort of more approachable for the lay public, but still convey some of the main information that would be contained in a systems dynamic model.

So that offers kind of one possibility of how you might zoom in and out and summarize meaning for story graphs.

And then there's also mathematical models of group interactions and belief sharing that could be constructed using concepts like sheaf and topos theory from category theory.

So that's the application of category theory to the Cognar meaning representation and Cognar computational processes, I think, is a really rich area for exploration.

Next slide.

So given all of that in the paper, I suggest maybe the best approach for a meaning representation is to base the meaning representation on the tree structure, the discourse representation tree structure.

And then with TTR, type theory with records, and higher order disco-circ as being also potentially interesting.

But if DRTS is used sort of as kind of the main idea, then it would still have to have numerous extensions as per the desiderata.

So layers, compositionality, and so forth.

And also, I think it might be useful to use a categorical grammar, like combinatorial categorical grammar, CCG.

And that kind of grammar is, for example, patterns in a language.

you know, verb noun, adjective noun, big dog, dog runs, you know, those sort of patterns would be contained in a categorical grammar.

And then the system would understand if you use those patterns, the system would better understand what it is you're trying to say.

So that's a form of restriction of input, user input to a categorical grammar.

But it probably makes sense to do so to improve the capacity of the system to understand what is being said.

And if you were to use some kind of pattern in text that wasn't part of the category of grammar, then the system could say, I don't understand what you're trying to tell me.

Can you rephrase that?

Do you mean this?

Or do you mean this?

You know, something like that.

And then, uh, one inference, one potential inference pipeline is to use a categorical grammar, create the story graph, and then send, uh, convert the story into a logical forms is like, for example, suitable for natural logic, and then send the results of that to a proof assistance, a proof assistant for a fast inference.

These are just some ideas, but at this point, it looks like this approach might be the most productive of the approaches that we've discussed.

Next slide.

Um, so some research questions, um, I should say that this is a, this is a, it looks like a long list, but this is a short list of all the possible, uh, you know, uh, to do's and questions that could be raised about, uh, about the cognitive system and about the cognitive meaning representation.

I mean, there's really all kinds of questions, like questions that don't have anything to do with the meaning representation per se, like how do you ensure that the information being shared is not manipulated?

How do you ensure the quality of information that's being submitted and discussed in this Cognar setting?

What are the social implications of this?

What are the legal implications of this?

How do you protect privacy of a person's information and their stories?

There's all kinds of big picture questions like that.

And then there's detailed questions.

uh that need to be answered too but uh you know how do you construct what is a what is the meaning graph uh representation what is the role of of of category theory and developing the system um

what kinds of stories are going to be applied here?

What are the categories of stories?

So just looking at the second bullet there, maybe one early step is just to create a, or excuse me, the first bullet,

is just to create a small set of very simple stories.

Maybe the stories are only a short paragraph in size, and those serve then as the kind of proof of concept or as the core of what the rest of the machinery is constructed on.

So perhaps that's a good start, generate a small set of simple stories.

It could even be like three or four or five simple stories just to start.

And then using those simple stories, perhaps develop some kind of simplistic meaning representation, perhaps building on discourse representation tree structures, convey these simple stories in that representation.

And then maybe that process is even done manually at first, not in some automated fashion.

automated fashion the automation would come later as you as you know we get more familiar from comfortable with the approach and the chosen meaning representation um as I mentioned category theory and in particular algebraic Julia which is a software in the Julia system

that is aimed at applied category theory could be useful.

There's various kinds of models in algebraic Julia that could be useful.

Explore C-sets as property graphs for meaning representations.

That would be, I think, useful.

Uh, given a simple next bullet, given a simple meeting representation, explore version control systems for that.

How do, how, how are we keeping track of edits to stories so that they can, so that we have a history of edits and so that, uh, we can construct a, uh, you know, we can regenerate a story from the various original inputs in the edits.

And then how are stories stored?

What kind of database is used for storage and recall?

How do we zoom in and out of stories and summarize meaning when you zoom out?

What kind of query language is used for story graphs?

You have a graph and you have various questions that you want to ask about the graph for inference.

What kind of, how do you query a story graph?

How are LLMs used?

What role do they have?

Could they be used for generating a story graph fragment from a small text passage?

What is the initial simple inference pipeline?

Does it involve, for example, natural logic and proof software?

proof assistance.

How about a simple analysis on story graphs?

How do you compare the similarity between two story graphs?

What is the first simple probabilistic model for handling story graph uncertainty?

and predictions how does that occur you know there's various software programs that handle a probabilistic model so you know choosing one of them and um and you know incorporating uncertainty and

Uncertainty really means, too, in predictions, maybe the future comes out this way.

Maybe this time I run the story, I execute the story computationally.

The result is that events A and B happen.

And then I execute the story again.

And because it's a probabilistic story,

events a and b don't happen in the second round they they happen in the some other event happens event c happens then i run the story again and again a and b happen and i run the story again and again c happens and then i run the story again and now d happens so uh you know the outcomes of a story are are variable because stories are probabilistic that's the way we understand the world

So all of those are research questions to consider, ideas for moving forward, ideas for getting involved.

Next slide, please.

And that's really kind of where we're at right now.

In the series of papers, I've laid out the ideas of Cognar, sort of the vision of Cognar, really.

And that's all that's been done on the Cognar project to date is these two papers.

There's no GitHub repository for Cognar code.

Nothing has happened yet.

This is fresh.

i i hope that the vision is interesting to not just to other researchers but the public at large and civic organizations and people who are interested in improving the ability of society to

cog functionally cognate and make better decisions and be functional in the group setting so i i hope this project is of interest and uh cognar really needs your help to move forward there's numerous interesting questions to explore so please reach out to me you know if you have interest

Upcoming, I believe that I'll be submitting a project to the Active Inference Institute, so that'll be kind of one hub to work through.

I'll be involved in some additional talks, the Active Inference Institute symposium coming up, and so on.

I think my email address is in the papers, so people can reach me that way, or I think they can reach me through the Institute, and I encourage anyone who is interested to reach out.

So that's all I got, Daniel.


SPEAKER_00:
Thank you.

A lot of places to continue.

For people who are watching live, feel free to write a question.

How about just to start it off, what did you get more curious about during the course of this path?


SPEAKER_01:
Oh, well...

you know i obviously was a process to create these papers and uh i i did you know at first when i started i didn't realize what i was up against i didn't realize how complicated this project was and i thought that i could i thought that i could create a working model of you know some code of a of a of a story graph and doing inference on a story graph and things like that and i suppose that could still be possible but

I realized as I went through the process that there was so much to think about, there was so much meat to this whole thing that it would be better for me to write two introductory papers that lay out the vision than actually constructing some initial version of the cognitive system.

So, you know, it was kind of humbling in a sense, the process of humbling in a sense, in that I realized I really didn't know enough to actually start constructing the Cognar system.

I really needed to like lay out some of the fundamentals before that step could even be taken.


SPEAKER_00:
Yeah.

The papers and the presentation, it's like a whirlwind tour of linguistics and semantics.

you're dealing and invoking with, well, you said like natural language is ambiguous.

And then it's like, well, what does that mean when it's precisely what it is?

And then here's the vector representation, here's string diagrams and all these different like proofs.

And all these interacting pieces, like the backend could have,

multiple parallel or or related processing methods one just doing like how many words are there over under 300 words defined by a space between the two words and then some other part could could go through llms it's like it's more like a linguistics fusion approach and also you're really focusing

in on the representation, not so much on the social process around how people would convene and narrativize around what it is.


SPEAKER_01:
Right, right, right.

That's a good point.

The papers really are focused on sort of the nuts and bolts parts of this.

But clearly, if Cognar were to be successful, there would be a very large, potentially large social impact.

And then there would be all kinds of questions, some of which I already raised, about how do you protect user privacy and how do you ensure that

quality information is being shared and discussed you know all that kind of stuff so my thinking is is that uh really i think maybe it's better to focus on the nuts and bolts parts first to get a simple uh you know to get simple meaning representations constructed

conveys a few simple stories in them, figure out some of the inference methods that might work best for this, those kinds of nuts and bolts questions.

And then once you have something to kind of show and tell, once you have a little small working model, then start to explore how you use this in the social setting.

How do you engage people to participate in Cogner?

How does that work?

And even there, I imagine the process that'll happen if the project moves forward is that there'll be maybe the initial work on this will be kind of slow and detailed.

But as things, as artifacts start to be developed and there starts to be something to kind of put you, something you can hold in your hand,

then there'll be a little wider circle of researchers and you know others from the civic society and just ordinary people who become interested in the project and start to contribute and as that grows eventually there'll be a you know start to be a little bit more of a critical mass that oh this is really starting to be a thing we have you know there's

We're starting to get a repository for this.

We're starting to understand how it could be used, what it would look like, how we engage people, how we make this easy to construct stories, story graphs out of stories, how we ensure that the dialogue and the

discussions and the sharing are healthy and useful for cognition.

And also numerous questions, as that happens, there'll be more and more of the social questions will come into play.

there's also like all kinds of other questions like how do you like in the nli setting it's really uh straightforward how you measure success you know you you you have a fixed set of sentences you know you know this is their gold standard so you know what the actual meaning of these sentences is and then you score the model or system that you're constructing on how well they reach the

actual meaning of these sentences.

Well, they convey the actual meaning.

Well, how do you do that in the Cognar setting?

Like, how would you actually do a study to prove that the Cognar system is understanding properly what you're saying?

It becomes a little more complicated because now you're engaging the user in creating the story

in an interactive fashion so it's a you know even studying the cognitive system you know from a scientific standpoint becomes a little bit more complex right because users are actively engaged in in the dynamics and and for that matter you know how do you how do you how do you assess

the quality of cognition?

That's a really interesting question.

In one of the early slides, I suggested that active inference can be used as a means to assess what functional cognition looks like versus dysfunctional cognition.

Maybe you can think just off the top of your head of a few examples where that would clearly be a symptom of dysfunctional cognition.

For example, if I had a pattern, as a person, if I have a pattern of making really poor predictions about what's going to happen next, you know, I see a lion in the road and I think, oh, that's a pet lion.

I'll walk up to it and pet it on the head.

That's a really poor prediction, right?

So those kind of pattern of poor predictions might be a sign of dysfunctional cognition.

Well, how do you assess functional versus dysfunctional cognition in this group setting, right?

There's many interesting avenues just in that question alone, many interesting avenues to explore.

uh for example the brain seems to you know information flow in the human brain seems to occur at that edge of chaos concept you know it's it's not it's stable the system is stable but almost unstable and because it's almost unstable potentially an input from off to the side an intuition from off to the side can

rapidly change the setup so that i switch gears and now i realize that that lion really is dangerous and i'm going to uh you know jump out of the way really fast so that's a system on the edge of chaos really is in many ways a the most efficient processing system you know it's most amenable to

input, it's most flexible, and yet it retains its kind of core stability.

So these ideas of chaos and other ideas from complex system science could actually be used for assessing information flow in the cognitive system and kind of the quality of information flow.

That's just one idea, but there's dozens of related avenues you could follow just on that question alone.


SPEAKER_00:
I'll ask a live chat question and then anyone else write a live chat question or I'll add anything if we have time.

Andrew writes, Dr. Boyk, thank you for presenting your work.

It's a very interesting project.

Do you have any thoughts on implementation in terms of code, e.g.

any particular programming languages or libraries?


SPEAKER_01:
um well um i'm a fan of julia so in the papers i i i uh i uh suggest various uh probabilistic software programs and uh uh an algebraic julia system that i've already mentioned in this talk uh julia is fantastic uh for a variety of reasons speed and other reasons

now that being said this project doesn't have to be constructed in julia but i see i see julia as a potential resource for constructing this and and maybe as a place to start you know initially

You know, certainly Julie is an open source project, so is Python, but you would want to engage the open source community as much as possible in this project because there's, you know, around the world, there's just so much talent and so many good ideas can come from that world.

Just on that topic, maybe this is kind of an aside, but this is conceived to be an open source project.

And one of the reasons I conceive it to be that way is you could imagine, suppose that Cognar was successful.

And suppose that you had a repository of stories.

And again, each story is conveying the belief system of a human in relation to some situation.

Suppose you had a repository of a million stories.

You have this really rich information about how people think in different situations, in a variety of different situations.

And that kind of information is very powerful, very powerful.

And you would not necessarily want some private entity, like a corporate entity, to have control over that whole thing.

I think you would really want some kind of open governance, an open source project controlled by some governance framework to ensure that this whole thing is used for a common good, that it's really used for purpose, for its purpose, intended purpose, which is to facilitate a group cognition.


SPEAKER_00:
A comment in the chat, Saskia wrote, life is thriving on the edge of chaos and order.

So it's this kind of paradox and the precarious nature of the body.

Like how much oxygen storage does the body have?

Very little, how much water, how much nutrition, like there's different kinds of reservoirs, but it isn't just trying to hold on to flows.

So that gives streamlined nature adaptive and on, on the critical

frontier and then at the same time also precarious over different time scales and this is making it explicit with the narrative and cognitive infrastructure as the information processing semantic linguistic narrative elements of our ecosystem become like more and more intermediative more and more active more and more powerful


SPEAKER_01:
Yeah.

As an offshoot to that comment, I think that democracy, the idea of democracy, could be framed in that edge of chaos view.

in the sense that in a democracy what you would really like is that each person has the potential to influence the the group as a whole this you know the condition of the group as a whole and that's that's what that edge of chaos you know allows because it a lot it's it's it's as i said before this system is

stable, but just on the edge of maximal flexibility, so that an input from some person, like an idea, a comment in a democratic system, can actually change the system.

Or a small group of people can actually change the system with some good input.

So I think that not only is the edge of chaos model maybe useful for Cogner, but it might actually be useful as we explore the interplay between what is a political system, really even what is an economic system, what is a political system, what is an economic system, what is a legal system in the context of the goal of group cognition, either societal cognition or otherwise.


SPEAKER_00:
Yeah, another, I think, really important point with the juxtaposition you made of graph-based, more formalized, non-distributional semantics and using LLMs to project onto those formal structures, generate from them.

First off, how incredible that from a semantic graph, we could generate materials in many natural languages, many lengths to many different audiences, if only for a starting point.

So just on the generation side, that's very powerful.

And then an interesting thing to consider is like the information supply chain, for example, for someone's voice in a group.

so then if people's inputs are taken as a blob of text smashed into a very large model and then it comes out then the information supply chain of that perspective has been collided with a very large billions of parameters lot of tokens of training and then the supply chain of the resulting outcome is like

group perspectives provided and whatever the question mark unknown training and inputs supply chain that are obscured for a proprietary LLM.

Or even if it's an open source, totally open LLM, you'd still have a complex information supply chain.

So this opens up an opportunity for end to end or in early stages or later stages or parallel stages

to be able to have the kind of, for example, counterfactual reasoning, like, here's how this graph looked with and without.

Here's the distribution of outcomes with and without what this traceback had done.

And then there's kind of a trade-off if there's a more simple, more symbolic system, like more code-like, more formal semantics, then the traceability will be deeper.


SPEAKER_01:
Explainability, yeah.


SPEAKER_00:
And then if you make it more statistical, it'll start getting blurred in with more and more other factors just probabilistically, but it still could be disentangled.

So it's like the LLM route has the fluency and a lot of other advantages.

And strengths and then also having more traceable like rails and flesh in tandem could give, it's just a design palette.

It's not that one or the other or the blender, it's situational, but using the two together.


SPEAKER_01:
Good point.

You actually raise numerous good issues there that are worthy of, you know, prolonged discussion.

But one of the points you raise, and it's a really good point, is that there isn't just one model in Cognar to digest information from a group of stories and present it to the group as a summary.

That's not just a single model doing that.

there can be many different views many different questions many different queries you can just like uh you know just like the inf like how do you summarize the information about a nation well there's all kinds of you know ways to do that there's graphs about the economy there's graphs about health there's grab you know like there's there's many ways to to to put together the information from us from a

body of information to make sense of it.

And Cognar would, you know, most likely would be multiple models, some of which would be maybe more explainable than other models.

Maybe, you know, some logic models might be very explainable.

Some results of LLM models might be less explainable.

But nevertheless, there would be a history of, you know, edits to story graphs, a history of how story graphs evolved.

There would be the possibility of looking backwards in retrospect to assess how the evolution happened, how ideas developed, how different models might have looked at that information differently.

Then you could assess the capability of Cogner in retrospect about how it

how it handled various situations you could assess the functionality of the group process like was this functional cognition were did were many voices heard was that information used did was it represent anything on the edge of chaos where you know a single voice could have an influence over the whole

You know, because there's a history, say, you could examine that trajectory in various ways and assess your system and assess the group process.


SPEAKER_00:
one interesting side inter point one to point two discussion was around like classical and quantum information fungible and non-fungible information and how like the single source of truth that you invoked last time even though that's a fractal concept just this get

branch as its own sort of time cone of traceability of classical information there are certain operations that you can do like the diff the merge the rebase and all those kinds of different decisions however the actual non-fungible cognitive entities

it doesn't work like that so it's this interesting tension between how enabled on certain dimensions these representations are but of course those are not the first person perspective on semantics the whole point of of the second paper is to to throw some approaches to this question of what can you make that

represent semantics, but then immediately to whom slash how, and they do, they represent and are different things to different views.

Like for example, just the visual view of a figure, and then the more statistical analysis on the graph, is that the same semantics?

Is that different semantics, even though it's like the same representation?

And so how does the representation do relevant work

in a specific cognitive ecosystem and that's sort of like the systems design and the metacognitive engineering question especially if not too strong of even though this is hard to to peel back to but what what biases and what priors and what biases and those are those are the same distribution


SPEAKER_01:
Right.

And clearly the system would have to be very transparent to be able to, you know, assess all of that, to assess biases in the system, to assess biases in, you know, the way Cognar assesses similarity between stories or something like that.

So there's certainly a lot to unpack with that.

I do want to just briefly mention something that we talked about in the first talk.

And that is just to emphasize that we've been talking about groups forming to explore some topic or situation of interest to them.

Cognar actually has a wide range of use cases, some of which don't look like that at all.

Cognar could be used, for example, in customer service for a corporation where people are maybe submitting a story graph to explain why they're

gadget broke or didn't work or why it broke or how it broke or whatever.

So there's really a wide range of use cases for this.

And secondly, as I conceive of Cognar, it's agnostic to how the group wants to operate.

Right.

So it's not forcing a group to use, you know, if say it's engaged, a group is engaged in decision making, it's not forcing a group to use majority, you know, you know, in voting use majority rules or or rank choice voting or some other system of voting or.

some other you know arrangement of how the group is structured you know whether it's an autocratic group or a democratic group or whatever the cognar is intended to be kind of agnostic to the group setting and so that means that there's a variety of types of groups with different interests and different structures and different rules and different methods and different approaches can all use cognar in the way that they see fit

know there obviously might be some restrictions on how it's used but by and large it's flexible and and a kind of an open system so that so that you know various kinds of groups can use it for various purposes but whatever the you know the the the system is whatever group uses it for whatever purpose the the system is learning from the engagement the system is you know the come back in computational system is learning

you know, how people think what they, what they, what they think will happen next when this and that happens, how, how better to, how better to summarize information or, you know, present information or encourage a group to move towards well-supported decisions when they're trying to make decisions or, you know, like all of that kind of stuff, the system is learning in the background, you know, uh, uh, just like, uh, an intelligent agent would learn in a, in a new setting.


SPEAKER_00:
Cool.

So maybe just what are some of the possible anticipated milestones for the rest of the year?


SPEAKER_01:
Oh, I most likely will try to... These two papers are in preprint, so I most likely will try to submit them to journals for publication.

Although they are kind of conceptual papers, they're not the normal type of research paper.

They're concept papers.

So that'll happen.

I'll start a group, a project, at the Active Inference Institute.

And I encourage people to reach out to me on that.

And really, I hope to pick one or two of these research questions myself and focus on that next.

So hopefully, there'll be a couple of more papers coming out at some point here.

and um you know really it's up to the community as to what happens from there i'll do what i can and if people like the idea maybe someone will jump in and you know participate

And maybe just in closing, and we're almost done now at the end of these two sessions, and maybe it would be just a good idea to kind of look at the big picture a little bit as to, like, why are we doing, why is this of any interest to anyone, right?

It's an interesting academic excursion for certain.

There's all kinds of, you know, basically touches on numerous scientific fields.

So there's all kinds of good research questions, but why should we even do this, you know?

and uh to that i would say there is a you know at least i'm i'm proposing that um groups can be thought of as organisms cognitive organisms and as cognitive organisms groups you know whether they're societies or corporations or civic clubs or whatever need to be able to be functional like make good decisions

act in the way that active inference kind of lays out in that they're, you know, a functional group is going to reduce the uncertainty about achieving the kinds of conditions that are good for it.

You certainly would want that for society and you even want it for human civilization as a whole, right?

It would be good if humans

reduce the uncertainty that we live in a good kind of world that people flourish in right we would want that for everybody and um when you look around today there's obviously uh many many examples of

what appear to be more decision-making on the part of humans, because we face really a poly-crisis.

Climate change and extinction rates are skyrocketing and we are in danger.

Humans are in danger, serious danger.

and um new ways of of looking at our situation our condition i think are needed in order to maybe steer a different direction to inspire a different kind of organization for society that is more functional that that does exactly what a functional organism does it

senses its world, it makes decisions that are good for it, that reduce the uncertainty about achieving the conditions that it needs to thrive and continue.

And I think that a high-level approach to small groups, large groups, societies,

holds great promise great potential to to suggest ways that where we might not be doing well and where we could do better and and opens up a whole host of really i think useful questions about how could humans humans groups whether we're talking about small human groups or

Nations and civilization as a whole, how can we reorganize ourselves to achieve what we actually want, but to function, you know, purposefully through, through organizations and institutions and rules and mechanisms that are fit for purpose, but actually our quality functional processes through which we can sense our world.

anticipate what's going to happen next, make good decisions, and reduce the uncertainty that there are future conditions are really what exactly we need to thrive.

So there's nitty gritty detail to this project,

that that are important and interesting and then there's this big picture that i think is really really useful to to think of you know of of how how viewing groups as organisms that are cognitive and that cognition has a purpose functional cognition can be you know described and used as a target for

moving human groups towards a future where we are simply more functional.

And I suspect that through the process of evolution, each of us, or most of us, crave, you know, are missing that.

Maybe we don't even know what we're missing, but once you get a whiff of what functional cognition and good decision making and

and fairness and all that other kind of you know things that go with it once that what what once you get a whiff of what that feels like i suspect that there would be a great sense of relief you know for people they would go like oh god i i'm so glad we you know we can get together as a group and be functional and make you know good decisions and we have a we have some clue as to

how to assess the quality of our interactions and our in our cognitive process so that we we know that we're aiming towards a future that is really substantially better than the poly crisis that we now exist in all right thank you john great time thanks for having thanks for having me yep okay thanks everybody in live chats too thank you