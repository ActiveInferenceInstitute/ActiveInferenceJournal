1
00:00:05,759 --> 00:00:08,400
こんにちは、オクターブ

2
00:00:08,400 --> 00:00:10,860
推論研究所へようこそ。これは、

3
00:00:10,860 --> 00:00:15,839
2023 年 4 月 25 日のアクティブなゲスト ストリーム番号 41.1 です。

4
00:00:15,839 --> 00:00:18,480
エリオット マーフィーとスティーブン ピアンタドシと一緒にここにいます。

5
00:00:18,480 --> 00:00:20,939
これは

6
00:00:20,939 --> 00:00:23,039
かなりの議論になるでしょう。

7
00:00:23,039 --> 00:00:24,779
スティーブンとエリオット エリオットからのオープニング ステートメントから始めます。

8
00:00:24,779 --> 00:00:27,359
それからいくつかの

9
00:00:27,359 --> 00:00:28,920
質問をしてください。

10
00:00:28,920 --> 00:00:32,759
最後に公開討論を行いますので、スティーブン、

11
00:00:32,759 --> 00:00:34,739
参加していただきありがとうございます。開会の辞に感謝します。こんにちは、

12
00:00:34,739 --> 00:00:36,960


13
00:00:36,960 --> 00:00:39,780
私はスティーブ・ピアンタドシです。

14
00:00:39,780 --> 00:00:42,239


15
00:00:42,239 --> 00:00:44,700
カリフォルニア大学バークレー校で心理学と神経科学の教授をしています。

16
00:00:44,700 --> 00:00:46,860
ええと、

17
00:00:46,860 --> 00:00:48,899
私たちがここにいる理由の一部は、私が最近大

18
00:00:48,899 --> 00:00:51,719
規模な言語モデルに関する論文を書いたことであり、その

19
00:00:51,719 --> 00:00:53,940
一部は、構文とセマンティクスの学習

20
00:00:53,940 --> 00:00:55,199


21
00:00:55,199 --> 00:00:57,300
に関して彼らが達成したことについての熱意を伝えようとしているからです。

22
00:00:57,300 --> 00:00:59,100


23
00:00:59,100 --> 00:01:00,719


24
00:01:00,719 --> 00:01:03,059
部分的には、

25
00:01:03,059 --> 00:01:04,979
これらのモデルは、言語についてどのように

26
00:01:04,979 --> 00:01:06,780
考えるか、

27
00:01:06,780 --> 00:01:08,520


28
00:01:08,520 --> 00:01:11,939
言語表現の理論と

29
00:01:11,939 --> 00:01:13,560
文法の理論、

30
00:01:13,560 --> 00:01:17,220
そしておそらく学習の理論についてどのように考えるかを本当に変えると思います。

31
00:01:17,220 --> 00:01:19,080


32
00:01:19,080 --> 00:01:21,960
メフィー 私は

33
00:01:21,960 --> 00:01:23,040


34
00:01:23,040 --> 00:01:25,799
テキサスの UT Health の脳神経外科部門のポスドクです。

35
00:01:25,799 --> 00:01:27,240
非常に興味深くスティーブンの論文を読んでいます。

36
00:01:27,240 --> 00:01:29,759
多くの人を研究しましたが、

37
00:01:29,759 --> 00:01:31,619
いくつかの収束領域がありましたが、

38
00:01:31,619 --> 00:01:32,820


39
00:01:32,820 --> 00:01:34,979
今日私が焦点を当てたいことは スティーブンに応答し、ダイバージェンスの

40
00:01:34,979 --> 00:01:36,600
領域に関係するような調査を行っている

41
00:01:36,600 --> 00:01:38,640


42
00:01:38,640 --> 00:01:41,700
ので、スティーブンの論文は、

43
00:01:41,700 --> 00:01:43,619
現代の機械学習が

44
00:01:43,619 --> 00:01:46,220


45
00:01:46,220 --> 00:01:48,119
チョムスキーのアプローチの理論的枠組み全体を覆し、迂回したという考えに基づいていることを知っているので、

46
00:01:48,119 --> 00:01:49,860


47
00:01:49,860 --> 00:01:51,479
いくつかに応答したいと思いました. これらの主要な議論と

48
00:01:51,479 --> 00:01:52,560
文学における他の関連する議論の一部は、

49
00:01:52,560 --> 00:01:54,060


50
00:01:54,060 --> 00:01:55,799
聞いている人がいくつかの洞察と考えを持っている可能性があるため、

51
00:01:55,799 --> 00:01:58,500


52
00:01:58,500 --> 00:02:00,720
大規模な言語

53
00:02:00,720 --> 00:02:03,180
モデルは次のトークンを予測するだけであり、

54
00:02:03,180 --> 00:02:04,079


55
00:02:04,079 --> 00:02:05,579
明らかに少しのトークンがあると言うのは非常に一般的な批判です。 決まり文句です ええと、

56
00:02:05,579 --> 00:02:07,619
まったく真実では

57
00:02:07,619 --> 00:02:09,419
なく、彼らは次のトークンを予測

58
00:02:09,419 --> 00:02:11,700
するだけではありません 彼らはまた、作り話をしているようです 彼らは幻覚を起こしているようです 彼らは

59
00:02:11,700 --> 00:02:14,340
おそらく嘘をついています 彼らは

60
00:02:14,340 --> 00:02:16,440
同じ質問に対してランダムに異なる答えを提供し

61
00:02:16,440 --> 00:02:18,300
、

62
00:02:18,300 --> 00:02:20,220
言語のような構造を確率的に模倣しているようです

63
00:02:20,220 --> 00:02:22,020
彼らは

64
00:02:22,020 --> 00:02:23,819
時々自分自身を修正する必要があるときに、

65
00:02:23,819 --> 00:02:25,440
少しプッシュすると、

66
00:02:25,440 --> 00:02:27,000
気が変わることがあります。

67
00:02:27,000 --> 00:02:28,560
実際、フォックスニュースが現在

68
00:02:28,560 --> 00:02:30,060
タッカーカールソンの代わりを探している場合、

69
00:02:30,060 --> 00:02:31,800
彼らは

70
00:02:31,800 --> 00:02:33,680
より少ないことをすることができます。

71
00:02:33,680 --> 00:02:36,120
彼らはあなたが

72
00:02:36,120 --> 00:02:38,040
知っている同様の口径を探しているので、これらのモデルは

73
00:02:38,040 --> 00:02:40,620
あらゆる種類の野生のもののように見えます.

74
00:02:40,620 --> 00:02:41,940
過去10年間で、

75
00:02:41,940 --> 00:02:43,500


76
00:02:43,500 --> 00:02:45,900
私たちがタバコのベッドであるかのように開発された一連の異なるシステムがあり

77
00:02:45,900 --> 00:02:47,580
、それらのそれぞれは. 別のニューラルネットアプローチに基づいています

78
00:02:47,580 --> 00:02:49,620
しかし最終的にはそれらは

79
00:02:49,620 --> 00:02:51,180
すべて言葉を取り、

80
00:02:51,180 --> 00:02:53,220
数百または

81
00:02:53,220 --> 00:02:56,220
数千の数のリストによってそれらを特徴付けているようです.G23ネットワークは

82
00:02:56,220 --> 00:03:00,000


83
00:03:00,000 --> 00:03:02,160
そのアーキテクチャに1,750億の重みと96のアテンションヘッドを持っています.

84
00:03:02,160 --> 00:03:03,780
スティーブンはここで私を修正できます。

85
00:03:03,780 --> 00:03:06,060


86
00:03:06,060 --> 00:03:07,319
これらのさまざまな部分が

87
00:03:07,319 --> 00:03:09,180
実際に何を意味するのかについてはよくわかりません

88
00:03:09,180 --> 00:03:10,920


89
00:03:10,920 --> 00:03:13,680


90
00:03:13,680 --> 00:03:15,360


91
00:03:15,360 --> 00:03:17,040
彼らは次のトークンを予測しますが、

92
00:03:17,040 --> 00:03:18,659
最初から最後までのアーキテクチャ全体は

93
00:03:18,659 --> 00:03:21,599
一種のエンジニアリングベースの動機です。

94
00:03:21,599 --> 00:03:22,500


95
00:03:22,500 --> 00:03:24,659
ええと、私はいつも、さまざまなテクノロジー企業のこれらのLLMから

96
00:03:24,659 --> 00:03:27,360
失敗したすべてのモデルについてはどうなのか疑問に

97
00:03:27,360 --> 00:03:28,800


98
00:03:28,800 --> 00:03:30,300


99
00:03:30,300 --> 00:03:31,980
思っています。

100
00:03:31,980 --> 00:03:33,060
ええと、あなたが知っているように、彼らは

101
00:03:33,060 --> 00:03:34,980
本当にうまく機能するこれらのモデルを持っているように見えます

102
00:03:34,980 --> 00:03:36,720
箱から出してすぐに使用できます

103
00:03:36,720 --> 00:03:38,459
ええと、それらはすべて、

104
00:03:38,459 --> 00:03:40,739
ある種の有名なアーティストにちなんで名付けられているようです。

105
00:03:40,739 --> 00:03:42,780
サラダの後にダーリーまたはダリがあります。

106
00:03:42,780 --> 00:03:45,360
ダヴィンチはおそらくきれいです すぐに、

107
00:03:45,360 --> 00:03:46,980
これらの企業の 1 つが大規模な言語モデルをリリースする予定です。

108
00:03:46,980 --> 00:03:49,500
ええと、Jesus と呼ばれるか、

109
00:03:49,500 --> 00:03:50,879
私にはわかりませんが、

110
00:03:50,879 --> 00:03:53,040
彼らはいつもこれが私たちの

111
00:03:53,040 --> 00:03:54,900
新しい財団モデルであり、ピカソと呼ばれています。

112
00:03:54,900 --> 00:03:56,280
これは私たちが試した最初のものです。

113
00:03:56,280 --> 00:03:58,140
問題はありません。 箱から出してすぐに使用できます

114
00:03:58,140 --> 00:03:59,819
が、毎回失敗したオリバーブラックボックスについてはどうなのかといつも疑問に思っています.1

115
00:03:59,819 --> 00:04:01,680


116
00:04:01,680 --> 00:04:03,659


117
00:04:03,659 --> 00:04:05,760


118
00:04:05,760 --> 00:04:07,379


119
00:04:07,379 --> 00:04:09,840
つのモデルまたは別のモデルを知っていることを選択する背後にある科学的推論のような、非常にオープンで明確な構造がないように思われます.

120
00:04:09,840 --> 00:04:11,939
ええと、しかし、私は

121
00:04:11,939 --> 00:04:14,280
それについて修正されることを受け入れるかもしれません.

122
00:04:14,280 --> 00:04:16,798
基本的な言語モデル

123
00:04:16,798 --> 00:04:18,298
でさえ、

124
00:04:18,298 --> 00:04:20,699


125
00:04:20,699 --> 00:04:22,139


126
00:04:22,139 --> 00:04:23,520
基本的なWeb予測のように.

127
00:04:23,520 --> 00:04:25,320


128
00:04:25,320 --> 00:04:27,300
これが本当に、サイバーベラのような

129
00:04:27,300 --> 00:04:29,040


130
00:04:29,040 --> 00:04:30,960
人々によって提案された言語モデルよりも10フォーカスモデルを好む理由です。

131
00:04:30,960 --> 00:04:32,880


132
00:04:32,880 --> 00:04:34,560
そのため、自然言語と同様にPythonコードを

133
00:04:34,560 --> 00:04:36,479


134
00:04:36,479 --> 00:04:38,580
着陸させたときに、LLMSがPythonについて深いことを教えてくれるとは誰も本当に考えていないことが指摘されています

135
00:04:38,580 --> 00:04:40,080


136
00:04:40,080 --> 00:04:42,120
Python は

137
00:04:42,120 --> 00:04:43,740
フレーズ構造の文法を持つ記号言語であり、

138
00:04:43,740 --> 00:04:46,620
LLMS が Python の秘密を正しく明らかにしているとは誰も言っ

139
00:04:46,620 --> 00:04:48,600


140
00:04:48,600 --> 00:04:50,940
ていないので、ここでさまざまなことを説明すると、言語タスクでの成功に基づいて、n モデルが自然言語の

141
00:04:50,940 --> 00:04:52,620
説明理論として解釈できる場合、

142
00:04:52,620 --> 00:04:54,000


143
00:04:54,000 --> 00:04:56,040


144
00:04:56,040 --> 00:04:57,540
反論がないことは、コンピューター言語

145
00:04:57,540 --> 00:04:58,919
の説明理論としても優れているはずです。

146
00:04:58,919 --> 00:05:01,139
したがって、

147
00:05:01,139 --> 00:05:02,699
自然

148
00:05:02,699 --> 00:05:04,620
言語の成功したモデルは、Amazon 言語の生成句構造に対する証拠として使用することはできません。

149
00:05:04,620 --> 00:05:06,540


150
00:05:06,540 --> 00:05:07,800


151
00:05:07,800 --> 00:05:09,720
そのため、コーパス モデルは

152
00:05:09,720 --> 00:05:11,280
他の理由から実際にはより適切な用語です。

153
00:05:11,280 --> 00:05:13,500
エミリー・ベンダーや他の何人かは、

154
00:05:13,500 --> 00:05:15,300
訓練用コーパスの特徴を実際に示していると思います.

155
00:05:15,300 --> 00:05:16,979
スティーブンは

156
00:05:16,979 --> 00:05:17,940
あなたがこれをあなたの論文で

157
00:05:17,940 --> 00:05:19,860
実際に制限として引用していると思います.

158
00:05:19,860 --> 00:05:21,120
ええと、彼らは

159
00:05:21,120 --> 00:05:22,680
訓練用コーパスの特徴が敷設プロセスに大きな影響を与える可能性があることを示しています.

160
00:05:22,680 --> 00:05:24,600


161
00:05:24,600 --> 00:05:25,800


162
00:05:25,800 --> 00:05:27,780
言語クラスでの大規模な言語モデルのパフォーマンスは、トレーニング コーパスの

163
00:05:27,780 --> 00:05:29,699
多様性に大きく影響されます

164
00:05:29,699 --> 00:05:31,440


165
00:05:31,440 --> 00:05:33,180
が、自然言語自体に

166
00:05:33,180 --> 00:05:35,340
偏りがあるわけではありません。単に

167
00:05:35,340 --> 00:05:37,199
計算システムであるため、人間の

168
00:05:37,199 --> 00:05:39,120
発言や行動に偏りがある可能性があります。

169
00:05:39,120 --> 00:05:41,039
しかし、自然言語自体は

170
00:05:41,039 --> 00:05:43,020
偏りがなく、非常に大きな言語

171
00:05:43,020 --> 00:05:45,180
モデルであるため、

172
00:05:45,180 --> 00:05:47,880


173
00:05:47,880 --> 00:05:49,500
あらゆる種類の偏見にさらされていることに同意するのは難しいようです。

174
00:05:49,500 --> 00:05:51,000
したがって、実際には言語のモデルになることはできません。

175
00:05:51,000 --> 00:05:52,020
何かのモデルです。

176
00:05:52,020 --> 00:05:53,880
それ以外の場合は、この議論をまとめるために、

177
00:05:53,880 --> 00:05:55,620


178
00:05:55,620 --> 00:05:58,139
ええと、LLM は明らかに

179
00:05:58,139 --> 00:05:59,759


180
00:05:59,759 --> 00:06:01,320
子供の言語経験にさらされていますが、これは

181
00:06:01,320 --> 00:06:02,699
スティーブンがそれを見て、

182
00:06:02,699 --> 00:06:04,680
彼の論文で話している別のものであり、それでも

183
00:06:04,680 --> 00:06:06,360
彼らの学習成果はまだ残っている可能性があります。

184
00:06:06,360 --> 00:06:08,160
文法の

185
00:06:08,160 --> 00:06:09,840
一般化が原則として学習可能であることに対処することに関連しているので、

186
00:06:09,840 --> 00:06:11,580


187
00:06:11,580 --> 00:06:12,660
ここでのこの声明に同意します。原則として、

188
00:06:12,660 --> 00:06:14,100


189
00:06:14,100 --> 00:06:16,080


190
00:06:16,080 --> 00:06:17,639
広範な習得

191
00:06:17,639 --> 00:06:20,520
フレームワークを知っているようなものではなく、学習可能性について何かを教えてくれることを知っていますが、それは

192
00:06:20,520 --> 00:06:21,900
あなたができることと同じくらいだと思います

193
00:06:21,900 --> 00:06:24,539


194
00:06:24,539 --> 00:06:26,819
学習に必要ではない帰納的偏見があることを示すことは、それが子供には存在しないことを

195
00:06:26,819 --> 00:06:28,139
示すことと実際には同じではないので、

196
00:06:28,139 --> 00:06:30,060


197
00:06:30,060 --> 00:06:31,560


198
00:06:31,560 --> 00:06:32,639
否定的な証拠、指導

199
00:06:32,639 --> 00:06:34,500
、修正、およびフィードバックを知っているかどうかについて長い議論がありました.

200
00:06:34,500 --> 00:06:36,720
語学学習は乳児や子供にとって必要であるか、または

201
00:06:36,720 --> 00:06:39,120
有用でさえあります

202
00:06:39,120 --> 00:06:40,440
が、今のところ、

203
00:06:40,440 --> 00:06:42,479
Eugene Choi や Gary Marcus など、

204
00:06:42,479 --> 00:06:44,340
LLM の

205
00:06:44,340 --> 00:06:45,660
現在のトレーニングに非常に費用がかかることを強調している他の人たちに同意します。

206
00:06:45,660 --> 00:06:46,440


207
00:06:46,440 --> 00:06:48,600


208
00:06:48,600 --> 00:06:50,400


209
00:06:50,400 --> 00:06:51,960
いくつかのテクノロジー企業の手に支配されている彼らの

210
00:06:51,960 --> 00:06:54,539
環境への影響は非常に大きく

211
00:06:54,539 --> 00:06:56,039
、ゲイリー・マーカスとユージーンを除いて、多くの人々がここでの評価

212
00:06:56,039 --> 00:06:57,300
において制約が少なく保守的であることを知っているので

213
00:06:57,300 --> 00:06:58,979


214
00:06:58,979 --> 00:07:00,660


215
00:07:00,660 --> 00:07:02,880
、ビル・ゲイツは最近、

216
00:07:02,880 --> 00:07:05,100
チャットGPTはええと書いた

217
00:07:05,100 --> 00:07:06,960


218
00:07:06,960 --> 00:07:11,400
GUI

219
00:07:11,400 --> 00:07:13,020
とヘンリー キッシンジャーは 2 月に

220
00:07:13,020 --> 00:07:15,240
ウォール ストリート ジャーナルに、チャット

221
00:07:15,240 --> 00:07:17,400
GBT の能力が拡大するにつれて、

222
00:07:17,400 --> 00:07:19,560
人間の知識を再定義し、

223
00:07:19,560 --> 00:07:21,780
私たちの現実の構造の変化を加速させ、

224
00:07:21,780 --> 00:07:23,220
政治と社会を再編成すると書いています。

225
00:07:23,220 --> 00:07:25,620
ジェネレーティブ AI は、新しい形態の人間の意識を生成するために公開されているため、

226
00:07:25,620 --> 00:07:28,319


227
00:07:28,319 --> 00:07:30,419
現時点で非常に急進的な主張が行われているので、

228
00:07:30,419 --> 00:07:32,220


229
00:07:32,220 --> 00:07:35,099
AI の誇大宣伝により、

230
00:07:35,099 --> 00:07:36,840
アカデミアの特定の部分に保存され、

231
00:07:36,840 --> 00:07:39,240
多くの壮大な計画が

232
00:07:39,240 --> 00:07:40,680
立てられている可能性があることを知っているのではないかと思いますが、私はあなたが ここで

233
00:07:40,680 --> 00:07:42,180
スティーブンに戻すためだけに、もっと具体的に知っておいてください。

234
00:07:42,180 --> 00:07:44,280
おそらく問題を提起したかったのですが、

235
00:07:44,280 --> 00:07:46,919
rorski と Beaumont による批判があり、

236
00:07:46,919 --> 00:07:49,259


237
00:07:49,259 --> 00:07:50,520


238
00:07:50,520 --> 00:07:51,240


239
00:07:51,240 --> 00:07:53,280
彼は lingbuzz で読んだと思います。

240
00:07:53,280 --> 00:07:54,419
彼らが

241
00:07:54,419 --> 00:07:56,819
行った反論は、

242
00:07:56,819 --> 00:07:58,500
あなたが科学が演繹的論理の一例であることを知っているからです.

243
00:07:58,500 --> 00:08:00,479
あなたの異議は、

244
00:08:00,479 --> 00:08:02,340
科学は演繹的ではなく、

245
00:08:02,340 --> 00:08:04,380
帰納的です.しかし、私は一般的なポイントが

246
00:08:04,380 --> 00:08:06,900
より正確かもしれないと思います。

247
00:08:06,900 --> 00:08:08,520


248
00:08:08,520 --> 00:08:10,620
言語モデルが

249
00:08:10,620 --> 00:08:13,020
人間の言語行動や

250
00:08:13,020 --> 00:08:15,300
神経画像応答をうまく予測できるという事実を利用しないでください.

251
00:08:15,300 --> 00:08:17,460
それだけでは

252
00:08:17,460 --> 00:08:19,199
人間の言語の理論を導き出すことができると主張することはできません.スティーブンの

253
00:08:19,199 --> 00:08:21,000
論文では、

254
00:08:21,000 --> 00:08:23,220
特定の構造は

255
00:08:23,220 --> 00:08:25,020
他の構造よりもうまく機能します 正しい注意

256
00:08:25,020 --> 00:08:26,819


257
00:08:26,819 --> 00:08:28,680
メカニズムは重要です 予測は重要です 意味表現が

258
00:08:28,680 --> 00:08:30,180
重要です したがって、

259
00:08:30,180 --> 00:08:32,219
現在、これらのモデルに基づいて収集することができます

260
00:08:32,219 --> 00:08:34,260
が、これまでのところ、私が

261
00:08:34,260 --> 00:08:36,000
文学で収集できたのはこれだけです.

262
00:08:36,000 --> 00:08:37,559
ここでより多くの洞察があるかどうかわからないので、

263
00:08:37,559 --> 00:08:39,899
Rosky と Boomer は予測が不十分な例を使用しましたが、

264
00:08:39,899 --> 00:08:42,719
強力な説明は

265
00:08:42,719 --> 00:08:44,760
正しい説明力であり、

266
00:08:44,760 --> 00:08:46,500
予測精度は現代科学の基礎を形成していませ

267
00:08:46,500 --> 00:08:48,120
ん。

268
00:08:48,120 --> 00:08:49,440


269
00:08:49,440 --> 00:08:50,820


270
00:08:50,820 --> 00:08:52,440
人間の言語の一部を正確にモデル化できます

271
00:08:52,440 --> 00:08:54,180
が、人間が学習できず処理が非常に困難な

272
00:08:54,180 --> 00:08:55,920
不可能な言語や不自然な

273
00:08:55,920 --> 00:08:58,200
構造に対しても非常にうまく機能します。

274
00:08:58,200 --> 00:09:00,360


275
00:09:00,360 --> 00:09:01,560


276
00:09:01,560 --> 00:09:03,060


277
00:09:03,060 --> 00:09:04,380


278
00:09:04,380 --> 00:09:08,339
同時にここにいるのは間違いなく一人ではないので、

279
00:09:08,339 --> 00:09:10,320
オープンAIのチーフサイエンティストであるElia umは

280
00:09:10,320 --> 00:09:12,180
最近のインタビューで、

281
00:09:12,180 --> 00:09:13,680
次のトークンを十分に予測することの意味は何か、

282
00:09:13,680 --> 00:09:15,540
それはあなたが

283
00:09:15,540 --> 00:09:17,940
その作成につながった根本的な現実を理解していることを意味すると言いました.

284
00:09:17,940 --> 00:09:19,920
そのトークンは、

285
00:09:19,920 --> 00:09:21,779


286
00:09:21,779 --> 00:09:23,100


287
00:09:23,100 --> 00:09:24,540
ここの文献の多くのより保守的な主張とはかなり異なるものです。

288
00:09:24,540 --> 00:09:26,519
また、

289
00:09:26,519 --> 00:09:27,839


290
00:09:27,839 --> 00:09:30,019
科学のさまざまな要素が

291
00:09:30,019 --> 00:09:32,580
帰納的または演繹的である可能性があることに応えて、それは実際にはどちらにも含まれていないか、

292
00:09:32,580 --> 00:09:34,140
あなたが持っていることを知っていますか？ 既存の

293
00:09:34,140 --> 00:09:36,300
理論を定式化する ハイパー仮説を立てる

294
00:09:36,300 --> 00:09:38,519
データを収集する それを分析する それは

295
00:09:38,519 --> 00:09:40,200
一種の演繹的な

296
00:09:40,200 --> 00:09:41,880
プロセスですが、

297
00:09:41,880 --> 00:09:43,680
特定の観察から始めて

298
00:09:43,680 --> 00:09:44,940
いくつかのパターンを見つけ、

299
00:09:44,940 --> 00:09:46,860
一般的な結論を導き出す場合もあります そして、

300
00:09:46,860 --> 00:09:49,380
魔法のように発明するアブダクションがあります

301
00:09:49,380 --> 00:09:52,019
仮説を立てて、

302
00:09:52,019 --> 00:09:53,760
仮説のスペースを縮小する

303
00:09:53,760 --> 00:09:55,620
演繹的推論が非科学的だ

304
00:09:55,620 --> 00:09:58,200
とか、帰納的推論が非科学的だとか、

305
00:09:58,200 --> 00:10:00,360
外向的推論が非科学的だとか、実際には言わないでしょうね

306
00:10:00,360 --> 00:10:01,800
これらはすべて、

307
00:10:01,800 --> 00:10:03,540
物事を行うためのさまざまな方法です

308
00:10:03,540 --> 00:10:05,459
ええと、あなたの論文では、

309
00:10:05,459 --> 00:10:08,399


310
00:10:08,399 --> 00:10:09,779
ハリケーンやパンデミックを予測するモデルは、

311
00:10:09,779 --> 00:10:12,060


312
00:10:12,060 --> 00:10:13,860
科学が得るのと同じくらい厳密なものの例であり、言語モデルでも

313
00:10:13,860 --> 00:10:16,019
状況は同じであると読者に結論付けるように懇願します

314
00:10:16,019 --> 00:10:18,120


315
00:10:18,120 --> 00:10:19,920
が、私にとって問題は、

316
00:10:19,920 --> 00:10:22,200
ハリケーンを予測するモデルがそうではないことだと思います ハリケーンとは何かという

317
00:10:22,200 --> 00:10:23,940
質問に答えるビジネスでは、

318
00:10:23,940 --> 00:10:25,740


319
00:10:25,740 --> 00:10:27,420


320
00:10:27,420 --> 00:10:29,040
天気を正確に予測するモデルは非常に正確ですが、

321
00:10:29,040 --> 00:10:30,600


322
00:10:30,600 --> 00:10:32,700
気象部門と連携していることはわかりませんが、

323
00:10:32,700 --> 00:10:34,380
その代わりにはなりません。

324
00:10:34,380 --> 00:10:35,760


325
00:10:35,760 --> 00:10:37,620
それをあなたに手渡すことを知っているだけです

326
00:10:37,620 --> 00:10:41,820
ええ、わかりましたええと、たくさんありますええと、

327
00:10:41,820 --> 00:10:43,800


328
00:10:43,800 --> 00:10:45,240


329
00:10:45,240 --> 00:10:47,579
ええと言うだけで始めることができると思いますええと、ええと、

330
00:10:47,579 --> 00:10:51,300
これらの

331
00:10:51,300 --> 00:10:54,000
モデルが制御されていることについてのこれらの批判の多くと同じように同意しますええと、あなたが知っている

332
00:10:54,000 --> 00:10:56,220
1つまたは2つの企業は

333
00:10:56,220 --> 00:10:59,160
非常に問題があります.

334
00:10:59,160 --> 00:11:01,320


335
00:11:01,320 --> 00:11:03,480


336
00:11:03,480 --> 00:11:04,980


337
00:11:04,980 --> 00:11:06,180
インターネットからのテキストで訓練されているため、彼らはあらゆる種類の偏見を持っていることを知っています.

338
00:11:06,180 --> 00:11:08,640


339
00:11:08,640 --> 00:11:10,980
ええと、

340
00:11:10,980 --> 00:11:13,079
それは非常に問題です. 少なくとも現時点では、

341
00:11:13,079 --> 00:11:16,500
モデルがうまく機能していないので、

342
00:11:16,500 --> 00:11:18,420


343
00:11:18,420 --> 00:11:20,640
あなたが知っている質問や問題の例を見つけるのは簡単だと思います。

344
00:11:20,640 --> 00:11:23,100


345
00:11:23,100 --> 00:11:25,500


346
00:11:25,500 --> 00:11:26,760


347
00:11:26,760 --> 00:11:29,820
ええと、必ずしもそれらの

348
00:11:29,820 --> 00:11:32,399
用語で正しいとは限りませんが、

349
00:11:32,399 --> 00:11:34,920
言語のパフォーマンスに関しては、

350
00:11:34,920 --> 00:11:38,459
具体的には構文と意味論であり、ええと、

351
00:11:38,459 --> 00:11:40,980


352
00:11:40,980 --> 00:11:43,019
他のドメインの他の理論の種類をはるかに超えていると思います

353
00:11:43,019 --> 00:11:46,920
ので、他の

354
00:11:46,920 --> 00:11:49,380
理論はありません 生成できる言語学またはコンピューター

355
00:11:49,380 --> 00:11:53,100
サイエンスは、テキスト

356
00:11:53,100 --> 00:11:56,700
の長い一貫性のある文法的な文章を知っているので、

357
00:11:56,700 --> 00:11:58,500


358
00:11:58,500 --> 00:12:01,140


359
00:12:01,140 --> 00:12:04,920


360
00:12:04,920 --> 00:12:08,220
会社によって展開されているツールやものを知っているので、すべての問題を認めているようなものです。

361
00:12:08,220 --> 00:12:09,959


362
00:12:09,959 --> 00:12:12,899
彼らはどのように言語を扱っているのでしょうか。

363
00:12:12,899 --> 00:12:14,760


364
00:12:14,760 --> 00:12:16,320
多くの熱意がここから生まれていると思います。

365
00:12:16,320 --> 00:12:17,760


366
00:12:17,760 --> 00:12:20,160


367
00:12:20,160 --> 00:12:23,700
言語能力の点で彼らのようなものはまったくありませんでした。

368
00:12:23,700 --> 00:12:24,899
それが私が

369
00:12:24,899 --> 00:12:27,660
思うことです エキサイティングなので、はい、

370
00:12:27,660 --> 00:12:29,220
あなたが始めたこれらの事柄の多くに同意します

371
00:12:29,220 --> 00:12:31,320


372
00:12:31,320 --> 00:12:33,300
が、それでも、

373
00:12:33,300 --> 00:12:35,100
構文とセマンティクスの観点から、

374
00:12:35,100 --> 00:12:37,079


375
00:12:37,079 --> 00:12:39,240
それらに匹敵する理論は他にないと思いますが、

376
00:12:39,240 --> 00:12:40,140


377
00:12:40,140 --> 00:12:42,120
プッシュさせてください 当時はそうだったので、

378
00:12:42,120 --> 00:12:44,940


379
00:12:44,940 --> 00:12:46,320


380
00:12:46,320 --> 00:12:48,000
言語学科で私が話した多くの人々からの主な反対意見は、

381
00:12:48,000 --> 00:12:50,760
あなたが論文の最初に知っている一般的な人のように、

382
00:12:50,760 --> 00:12:53,100
本当に

383
00:12:53,100 --> 00:12:54,120
よく言うことです。

384
00:12:54,120 --> 00:12:55,620
確かに彼らは

385
00:12:55,620 --> 00:12:57,360
素晴らしい仕事をしており、構文とセマンティクスの

386
00:12:57,360 --> 00:12:58,920
多くの側面のすべての側面を正確にモデル化しています

387
00:12:58,920 --> 00:13:01,380
が、

388
00:13:01,380 --> 00:13:03,300


389
00:13:03,300 --> 00:13:04,920
チョムスキーが古い概念である言語に関する事実について話しているのと同じように、私は実際のことを知りません.

390
00:13:04,920 --> 00:13:06,660


391
00:13:06,660 --> 00:13:09,000
しかし、それは

392
00:13:09,000 --> 00:13:10,260
一種の重要な概念であり、

393
00:13:10,260 --> 00:13:12,899


394
00:13:12,899 --> 00:13:16,860
llmsが独自に

395
00:13:16,860 --> 00:13:19,200
提供できる言語自体に関する発見があるかどうか、たとえば、llmが文

396
00:13:19,200 --> 00:13:21,899


397
00:13:21,899 --> 00:13:24,600
構造を持っているとしましょう.タイプXは

398
00:13:24,600 --> 00:13:26,279
文よりも処理が難しいことについて予測したかのように. タイプ

399
00:13:26,279 --> 00:13:28,620
Y、そしてこれは

400
00:13:28,620 --> 00:13:31,200
彼らだけがそれを生成し、人間の

401
00:13:31,200 --> 00:13:33,899
言語学者であるチョムスキー・ホームスタインは誰も

402
00:13:33,899 --> 00:13:34,980
それを予測したことがないというユニークな予測です。

403
00:13:34,980 --> 00:13:37,260


404
00:13:37,260 --> 00:13:38,760


405
00:13:38,760 --> 00:13:40,800


406
00:13:40,800 --> 00:13:42,480


407
00:13:42,480 --> 00:13:44,279
これは言語処理についての新しい洞察です

408
00:13:44,279 --> 00:13:45,839
これは

409
00:13:45,839 --> 00:13:47,940
あなたが知っている言語についての新しい洞察です

410
00:13:47,940 --> 00:13:49,560


411
00:13:49,560 --> 00:13:51,240


412
00:13:51,240 --> 00:13:52,620
それは近い将来に起こるかもしれないからです

413
00:13:52,620 --> 00:13:54,540
が、それが私にとって、

414
00:13:54,540 --> 00:13:57,240


415
00:13:57,240 --> 00:13:59,519


416
00:13:59,519 --> 00:14:02,040
ここの言語学コミュニティ全体を代表して話すことについて多くの言語学者が話している理由の核心だと思います。

417
00:14:02,040 --> 00:14:03,180


418
00:14:03,180 --> 00:14:04,800


419
00:14:04,800 --> 00:14:08,279
私は彼らが

420
00:14:08,279 --> 00:14:10,019


421
00:14:10,019 --> 00:14:12,420
提供した洞察を一種の一般原則として考えていると思います.

422
00:14:12,420 --> 00:14:14,459


423
00:14:14,459 --> 00:14:16,200


424
00:14:16,200 --> 00:14:18,720


425
00:14:18,720 --> 00:14:20,820
言語の塊を記憶する力のようなものだと思います.

426
00:14:20,820 --> 00:14:22,500


427
00:14:22,500 --> 00:14:24,540
たとえば、構成が非常に得意であり、特にチョムスキーの多くの言語理論があります。

428
00:14:24,540 --> 00:14:26,160


429
00:14:26,160 --> 00:14:28,740
それらは、

430
00:14:28,740 --> 00:14:30,899


431
00:14:30,899 --> 00:14:33,660
記憶するための最小量の構造を見つけようとするものであり、

432
00:14:33,660 --> 00:14:36,480


433
00:14:36,480 --> 00:14:38,279
小さな集合から可能な限り多くを導き出そうとするものです。 操作のコレクション

434
00:14:38,279 --> 00:14:40,440


435
00:14:40,440 --> 00:14:42,300
ええと、それらの理論ではうまくいかなかったと思いますが、

436
00:14:42,300 --> 00:14:44,459
これは

437
00:14:44,459 --> 00:14:46,740
非常にうまくいくので、

438
00:14:46,740 --> 00:14:48,360
ええと、

439
00:14:48,360 --> 00:14:50,040


440
00:14:50,040 --> 00:14:51,300
たとえば文法の理論について考えると、記憶能力を持つものについて考えると、

441
00:14:51,300 --> 00:14:54,240
どのようなものを構築しますか

442
00:14:54,240 --> 00:14:56,040
ええと、人間は、

443
00:14:56,040 --> 00:14:58,139


444
00:14:58,139 --> 00:14:59,880
さまざまな構文や

445
00:14:59,880 --> 00:15:01,380
さまざまな単語を記憶するという本当に驚くべき能力が好きです。

446
00:15:01,380 --> 00:15:02,940


447
00:15:02,940 --> 00:15:04,380


448
00:15:04,380 --> 00:15:06,420


449
00:15:06,420 --> 00:15:07,920


450
00:15:07,920 --> 00:15:10,260
私たちは何万もの単語を知っています。 ある意味では、

451
00:15:10,260 --> 00:15:12,480
その

452
00:15:12,480 --> 00:15:15,660
種のアプローチがうまく機能するという原理の証明のようなものです。

453
00:15:15,660 --> 00:15:17,279


454
00:15:17,279 --> 00:15:19,380
それらを使って他のタイプの予測を行うことを考えることができます。ええと、一部の

455
00:15:19,380 --> 00:15:21,779
人々は現在行っていますが、

456
00:15:21,779 --> 00:15:23,339
たとえば、それらを使用して

457
00:15:23,339 --> 00:15:25,860
測定しようとしています。

458
00:15:25,860 --> 00:15:27,899
たとえば、これらのモデルからの処理の難しさの測定の驚きは、

459
00:15:27,899 --> 00:15:29,160


460
00:15:29,160 --> 00:15:30,600


461
00:15:30,600 --> 00:15:31,699


462
00:15:31,699 --> 00:15:34,260
文脈自由

463
00:15:34,260 --> 00:15:36,120
文法や他の種類の言語

464
00:15:36,120 --> 00:15:37,440
モデルと言うよりもはるかに優れています。そして、

465
00:15:37,440 --> 00:15:39,899
これらの驚きや

466
00:15:39,899 --> 00:15:41,940
予測可能性が人間の処理権とどのように関係しているかは興味深い質問です。

467
00:15:41,940 --> 00:15:44,399
一部をキャプチャするか、

468
00:15:44,399 --> 00:15:46,620
非線形である可能性があります。または、ほんの

469
00:15:46,620 --> 00:15:49,079
一部しかキャプチャできないことを知っている可能性があります。または、

470
00:15:49,079 --> 00:15:51,420
興味深い

471
00:15:51,420 --> 00:15:53,940
種類の他の科学的質問であるものは何でも、

472
00:15:53,940 --> 00:15:55,500


473
00:15:55,500 --> 00:15:57,779
たとえば接続について予測できるのは原則として正しいと思います。

474
00:15:57,779 --> 00:15:59,880
文章の間で、

475
00:15:59,880 --> 00:16:02,279
この論文では、宣言を10の異なる方法で質問に変換することを知っているこの例を示しました。

476
00:16:02,279 --> 00:16:05,459


477
00:16:05,459 --> 00:16:07,920


478
00:16:07,920 --> 00:16:10,620
おそらく、GPTまたは何かが行われていることを知っているときに、

479
00:16:10,620 --> 00:16:12,540


480
00:16:12,540 --> 00:16:15,420
すべてが含まれている10の異なる質問を見つけているときです。

481
00:16:15,420 --> 00:16:18,060
何らかの形で、意味空間または構文空間の根底にあるモデルの近くに関連する種類のもので

482
00:16:18,060 --> 00:16:20,339


483
00:16:20,339 --> 00:16:22,139


484
00:16:22,139 --> 00:16:24,660
あり、これらの種類のものは、

485
00:16:24,660 --> 00:16:26,459


486
00:16:26,459 --> 00:16:28,560
言語学者が正しいことを望んでいる可能性があることを知っているタイプのものであると思います。

487
00:16:28,560 --> 00:16:30,180


488
00:16:30,180 --> 00:16:32,220


489
00:16:32,220 --> 00:16:34,320
私が知る限り、

490
00:16:34,320 --> 00:16:36,120
それらはまだ経験的に評価されていないので、

491
00:16:36,120 --> 00:16:39,660
そうです、そうです、これらの

492
00:16:39,660 --> 00:16:41,220
種類のモデルはほんの数年しか経っていないということです.  「

493
00:16:41,220 --> 00:16:43,440


494
00:16:43,440 --> 00:16:45,000


495
00:16:45,000 --> 00:16:46,259


496
00:16:46,259 --> 00:16:48,540
まだ完了していません。そうではありません。まったくそうではありません。

497
00:16:48,540 --> 00:16:50,880
つまり、

498
00:16:50,880 --> 00:16:51,720
それは正しい見方だと思いますが、

499
00:16:51,720 --> 00:16:52,920
これは、

500
00:16:52,920 --> 00:16:54,779


501
00:16:54,779 --> 00:16:56,579
あなたが言及した驚きの問題に到達すると思います。あなたが言及した

502
00:16:56,579 --> 00:16:58,139
レーナビリティーええと、

503
00:16:58,139 --> 00:17:00,839
LMSといくつかの構文を知っています 彼らは

504
00:17:00,839 --> 00:17:03,060
明らかに乳児よりもはるかに多くのデータを使ってそれを行っている

505
00:17:03,060 --> 00:17:04,439


506
00:17:04,439 --> 00:17:06,240
ので、潜在的な構造の観察

507
00:17:06,240 --> 00:17:09,000
自体は刺激

508
00:17:09,000 --> 00:17:10,799
の貧弱さの評判ではなく、

509
00:17:10,799 --> 00:17:12,540
私が言うべき弱いバージョンは明確

510
00:17:12,540 --> 00:17:13,500


511
00:17:13,500 --> 00:17:15,059
な議論の貧弱さなので、単なる事実です.

512
00:17:15,059 --> 00:17:17,579
LMS が私たちの

513
00:17:17,579 --> 00:17:19,559
文法的な賞でできることは非常に印象的です。私は

514
00:17:19,559 --> 00:17:20,939
同意します。実際、おそらく

515
00:17:20,939 --> 00:17:22,500


516
00:17:22,500 --> 00:17:23,699
5、6、7 年前には予測できなかったでしょう

517
00:17:23,699 --> 00:17:25,260
が、

518
00:17:25,260 --> 00:17:28,199
人間には驚きがあり、私たちが

519
00:17:28,199 --> 00:17:30,120
それらの祈りを私たちと一緒に持ってきて、

520
00:17:30,120 --> 00:17:31,080
計算

521
00:17:31,080 --> 00:17:33,299
言語学が仮説と

522
00:17:33,299 --> 00:17:34,740
理論的言語学を制約できるかどうかを確認するために、

523
00:17:34,740 --> 00:17:36,480


524
00:17:36,480 --> 00:17:38,039


525
00:17:38,039 --> 00:17:39,720
さまざまな学習パラメータが

526
00:17:39,720 --> 00:17:43,080
制御されている慎重な実験と巨大な言語モデルを知っている必要があります。

527
00:17:43,080 --> 00:17:45,299
gbt freeのようなものは基本的に

528
00:17:45,299 --> 00:17:47,520
ここでは役に立たないことを知っているので、これは

529
00:17:47,520 --> 00:17:49,559
タイルレンズと、あなたが興味を持っていることを知っている

530
00:17:49,559 --> 00:17:51,960
赤ちゃんのLMプロジェクトのようなものが必要であり、

531
00:17:51,960 --> 00:17:53,700


532
00:17:53,700 --> 00:17:55,320
生態学的に有効なトレーニングセットがもっとあることを知っているという苦情につながります。

533
00:17:55,320 --> 00:17:56,940


534
00:17:56,940 --> 00:17:58,380
何らかの構造がそこから学習されることを論文で予測してください。

535
00:17:58,380 --> 00:17:59,640


536
00:17:59,640 --> 00:18:01,679
あなたはそこにいるのではないかと思います

537
00:18:01,679 --> 00:18:03,059
が、それでも、

538
00:18:03,059 --> 00:18:04,679
赤ちゃんのLMチャレンジでさえ、

539
00:18:04,679 --> 00:18:07,260
より伝統的な問題に対処するという重要な問題がまだあることを知っています。

540
00:18:07,260 --> 00:18:09,419
子供たちは

541
00:18:09,419 --> 00:18:11,400


542
00:18:11,400 --> 00:18:13,200


543
00:18:13,200 --> 00:18:15,539
言語を超えたさまざまな要因に基づいて、現在の入力量に基づいて一般化し始めます。これには、

544
00:18:15,539 --> 00:18:17,700
伝統的な

545
00:18:17,700 --> 00:18:18,720
心理言語学と言語

546
00:18:18,720 --> 00:18:21,539
習得が必要なので、あなたが言ったように頻度や驚きなどを気にするLMSが必要です

547
00:18:21,539 --> 00:18:22,919


548
00:18:22,919 --> 00:18:24,600
が、

549
00:18:24,600 --> 00:18:26,160
本当に素晴らしい Sophie sluts と

550
00:18:26,160 --> 00:18:27,600
Andrea Martin によるこの論文は本当に美しい論文であり

551
00:18:27,600 --> 00:18:30,000
、

552
00:18:30,000 --> 00:18:31,620
分布

553
00:18:31,620 --> 00:18:34,080
統計が時々構造構築の瞬間の手がかりになり得ることを非常によく示しているのを見たことがあると思いますが、

554
00:18:34,080 --> 00:18:36,240


555
00:18:36,240 --> 00:18:37,919


556
00:18:37,919 --> 00:18:39,660
構成に関するこれらの概念を置き換えます。

557
00:18:39,660 --> 00:18:42,360
Chomsky 57 からの引用を読んでください。これは、

558
00:18:42,360 --> 00:18:45,240
スロットなどに非常によく似ており、言語の

559
00:18:45,240 --> 00:18:47,820


560
00:18:47,820 --> 00:18:49,440
意味論的および統計的モデルの否定できない関心と重要性にもかかわらず、文法上の違いのセットを決定または特徴付ける問題とは

561
00:18:49,440 --> 00:18:51,360
直接関係がないように思われると言います。

562
00:18:51,360 --> 00:18:52,919


563
00:18:52,919 --> 00:18:54,600


564
00:18:54,600 --> 00:18:56,340


565
00:18:56,340 --> 00:18:57,840
文法は自律的で

566
00:18:57,840 --> 00:18:59,520
意味から独立しており、

567
00:18:59,520 --> 00:19:01,320
確率モデルは構文構造の

568
00:19:01,320 --> 00:19:03,179
基本的な問題のいくつかに特に洞察を与えない

569
00:19:03,179 --> 00:19:05,880
ため、2 番目の文の 2 番目の

570
00:19:05,880 --> 00:19:07,980
ヘッジは、

571
00:19:07,980 --> 00:19:10,380
間違っていますが、

572
00:19:10,380 --> 00:19:11,580


573
00:19:11,580 --> 00:19:13,740


574
00:19:13,740 --> 00:19:16,559
57年に利用可能な統計モデルであると明らかに言われていることは、今日のモデルに適用すると正確ではなくなり、あなたが正しく述べたように、

575
00:19:16,559 --> 00:19:18,600


576
00:19:18,600 --> 00:19:20,340
新しい

577
00:19:20,340 --> 00:19:21,900
文字列と分布カテゴリについて抽象的な一般化を行うことができることを知っているのは事実ですが、

578
00:19:21,900 --> 00:19:23,640


579
00:19:23,640 --> 00:19:25,380
単一のモデルのパフォーマンス

580
00:19:25,380 --> 00:19:27,480


581
00:19:27,480 --> 00:19:29,760


582
00:19:29,760 --> 00:19:31,440


583
00:19:31,440 --> 00:19:33,900
今日利用可能な計算モデルと

584
00:19:33,900 --> 00:19:36,240
人間の脳のモデルとの間に大きな隔たりを与えることによって、特定の

585
00:19:36,240 --> 00:19:38,100
構造の着陸可能性を

586
00:19:38,100 --> 00:19:40,679
支持または否定する直接的な証拠を提供するものではありません。

587
00:19:40,679 --> 00:19:42,539
構造は学習可能ではありません

588
00:19:42,539 --> 00:19:44,520


589
00:19:44,520 --> 00:19:47,100
ええええ だから私はおそらく、人々が行った

590
00:19:47,100 --> 00:19:49,380
いくつかの

591
00:19:49,380 --> 00:19:51,000
異なるバージョンの学習可能性の

592
00:19:51,000 --> 00:19:52,620
議論を展開する価値があると思います

593
00:19:52,620 --> 00:19:55,679
非常に強力な種類

594
00:19:55,679 --> 00:19:57,720
の不可能性主張がありました

595
00:19:57,720 --> 00:19:59,160
ええと チョムスキーの伝統から出てきたものです 正しい

596
00:19:59,160 --> 00:20:01,260


597
00:20:01,260 --> 00:20:04,140


598
00:20:04,140 --> 00:20:05,820
必要なデータの量については決して主張していません

599
00:20:05,820 --> 00:20:08,220
言語学習の論理的な問題についての主張があり

600
00:20:08,220 --> 00:20:10,740
、それは

601
00:20:10,740 --> 00:20:12,120
不可能だったということです。 あなたが

602
00:20:12,120 --> 00:20:15,720


603
00:20:15,720 --> 00:20:17,580


604
00:20:17,580 --> 00:20:19,380


605
00:20:19,380 --> 00:20:21,660
獲得したい言語のクラスまたは文法のクラスは、

606
00:20:21,660 --> 00:20:23,220
ええと、人々は長い間、

607
00:20:23,220 --> 00:20:25,380
そのバージョンの物事に反対して議論してきました。

608
00:20:25,380 --> 00:20:26,340


609
00:20:26,340 --> 00:20:27,120


610
00:20:27,120 --> 00:20:28,860


611
00:20:28,860 --> 00:20:30,419


612
00:20:30,419 --> 00:20:32,580


613
00:20:32,580 --> 00:20:35,220
その伝統に基づいて構築された獲得理論は、

614
00:20:35,220 --> 00:20:37,980


615
00:20:37,980 --> 00:20:39,240
さまざまな仮説をたどり、

616
00:20:39,240 --> 00:20:40,860
さまざまな

617
00:20:40,860 --> 00:20:42,600
オプションや物事を検討する順序について多くのことを心配しています.

618
00:20:42,600 --> 00:20:43,380


619
00:20:43,380 --> 00:20:45,059
ええと、私のお気に入りの参考文献は、ええと、Nick jader

620
00:20:45,059 --> 00:20:46,919
によるこの論文です.

621
00:20:46,919 --> 00:20:49,799
Paul vetani um は、自然言語

622
00:20:49,799 --> 00:20:51,539
の理想的な学習のようなものと呼びました。

623
00:20:51,539 --> 00:20:53,039


624
00:20:53,039 --> 00:20:54,840
これは基本的に、制約

625
00:20:54,840 --> 00:20:57,539
のない学習者が

626
00:20:57,539 --> 00:21:00,480
十分なデータを使用して、文字列を正しく観察するだけで

627
00:21:00,480 --> 00:21:01,860
生成規則または

628
00:21:01,860 --> 00:21:03,360
生成文法の種類を習得できることを示していますが、

629
00:21:03,360 --> 00:21:05,640


630
00:21:05,640 --> 00:21:08,160
その論文は

631
00:21:08,160 --> 00:21:10,200


632
00:21:10,200 --> 00:21:13,140
それは、

633
00:21:13,140 --> 00:21:15,120
ポジティブな例から学ぶことは、

634
00:21:15,120 --> 00:21:17,820
文字列を観察するだけでは論理的に不可能であると主張していた、この膨大な量の研究に応えたものでした.

635
00:21:17,820 --> 00:21:20,520


636
00:21:20,520 --> 00:21:23,460


637
00:21:23,460 --> 00:21:25,679


638
00:21:25,679 --> 00:21:28,140
議論は、

639
00:21:28,140 --> 00:21:30,419


640
00:21:30,419 --> 00:21:33,299


641
00:21:33,299 --> 00:21:34,919
言語獲得が機能するためには、生来的に指定された何かを持たなければならないというものだったので、

642
00:21:34,919 --> 00:21:36,600


643
00:21:36,600 --> 00:21:39,480
ある種の

644
00:21:39,480 --> 00:21:41,220
生来の文法や仮説の生来の順序付け、または

645
00:21:41,220 --> 00:21:42,900
何か、そしてそのすべてが

646
00:21:42,900 --> 00:21:45,659
完全に間違っていることが判明したので、

647
00:21:45,659 --> 00:21:48,299
あなたが知っているなら、Taterとvataniが行う

648
00:21:48,299 --> 00:21:50,520
もう少し現実的な学習設定に移行すると、

649
00:21:50,520 --> 00:21:53,340


650
00:21:53,340 --> 00:21:55,500


651
00:21:55,500 --> 00:21:57,240
理想化された学習者が何かを習得できるようになり、

652
00:21:57,240 --> 00:21:59,100
何もありません。 そこに

653
00:21:59,100 --> 00:22:00,600
必要なデータの量についての声明は、

654
00:22:00,600 --> 00:22:02,700
まさに純粋な

655
00:22:02,700 --> 00:22:06,780
論理的な学習能力であり、

656
00:22:06,780 --> 00:22:08,940
その能力は、

657
00:22:08,940 --> 00:22:11,460
大きな言語モデルの大きなバージョンも

658
00:22:11,460 --> 00:22:13,679
正しく話していると思うので、Chader

659
00:22:13,679 --> 00:22:15,600
invitaniやその他の他の

660
00:22:15,600 --> 00:22:17,460
そのスピリットえ

661
00:22:17,460 --> 00:22:19,500
えと、あなたは数学と

662
00:22:19,500 --> 00:22:21,480
原則としての議論を知っていますが、

663
00:22:21,480 --> 00:22:24,720
実際に

664
00:22:24,720 --> 00:22:27,840
文法的な権利や実際の種類の

665
00:22:27,840 --> 00:22:30,000
実装された言語モデルを作成したことはありません。

666
00:22:30,000 --> 00:22:32,640
ええと、訓練されたモデルを知っていても

667
00:22:32,640 --> 00:22:35,400
1億または1000億、

668
00:22:35,400 --> 00:22:38,340
または多くの多くのトークンについて、

669
00:22:38,340 --> 00:22:41,159
ええと、その種のモデルでさえ、

670
00:22:41,159 --> 00:22:43,080
そのバージョンの議論に関連していると思いますし、

671
00:22:43,080 --> 00:22:46,140


672
00:22:46,140 --> 00:22:48,659
言語学習が不可能ではないことを示すことは、

673
00:22:48,659 --> 00:22:51,360
非常に制約のないスペースから大丈夫です それから

674
00:22:51,360 --> 00:22:53,640
2 番目のバージョンがあります。

675
00:22:53,640 --> 00:22:56,760
これは、

676
00:22:56,760 --> 00:22:59,760
子供たちが正しく理解できる特定のデータを使用して言語を学習できるというものです。

677
00:22:59,760 --> 00:23:02,340
これは、データの量

678
00:23:02,340 --> 00:23:04,620
とデータの形式の両方です

679
00:23:04,620 --> 00:23:06,360
。赤ちゃんの LM チャレンジを知らない人向けです。

680
00:23:06,360 --> 00:23:08,520


681
00:23:08,520 --> 00:23:10,440
うーん、ええと、ええと、

682
00:23:10,440 --> 00:23:12,840
これは

683
00:23:12,840 --> 00:23:14,340
申し訳ありませんが、それを

684
00:23:14,340 --> 00:23:16,620
競争またはええと、ええと、ええと、

685
00:23:16,620 --> 00:23:20,580


686
00:23:20,580 --> 00:23:22,380


687
00:23:22,380 --> 00:23:24,539
人間サイズのデータ​​で言語モデルを訓練するように人々を誘導しようとするのは挑戦だと思います。

688
00:23:24,539 --> 00:23:27,179


689
00:23:27,179 --> 00:23:28,679
ええと、トレーニング セットには 1000 万

690
00:23:28,679 --> 00:23:31,140
または 100 百万の異なる

691
00:23:31,140 --> 00:23:33,120
um から 1000 万または 100 百万の異なる 2 つの異なるバージョンがあると思います。ええと、100 番目または

692
00:23:33,120 --> 00:23:35,640


693
00:23:35,640 --> 00:23:38,100


694
00:23:38,100 --> 00:23:41,159
1000 番目、または

695
00:23:41,159 --> 00:23:43,140
これらの大きな AI 企業が言語に使用しているのと同じくらい大きいものを知っているようなものです。

696
00:23:43,140 --> 00:23:46,620
モデルええと、

697
00:23:46,620 --> 00:23:48,720
ええと、実際には、

698
00:23:48,720 --> 00:23:50,340
それはまさに正しい種類のものであり、

699
00:23:50,340 --> 00:23:52,020
フィールドが正しく必要としているものだと思います。

700
00:23:52,020 --> 00:23:54,780
なぜなら、ええと、

701
00:23:54,780 --> 00:23:57,059
子供サイズの量のデータで、

702
00:23:57,059 --> 00:23:58,980
ええと、基本的に正しい構文を学ぶことができるからです。

703
00:23:58,980 --> 00:24:01,140


704
00:24:01,140 --> 00:24:02,880
これらの刺激の貧弱さの主張に対する最も強力な議論になるでしょう.

705
00:24:02,880 --> 00:24:04,260


706
00:24:04,260 --> 00:24:06,299


707
00:24:06,299 --> 00:24:08,220
あるいは、あなたはあまり学ぶことができないかもしれません。

708
00:24:08,220 --> 00:24:10,740


709
00:24:10,740 --> 00:24:12,840


710
00:24:12,840 --> 00:24:14,700


711
00:24:14,700 --> 00:24:16,799


712
00:24:16,799 --> 00:24:17,520


713
00:24:17,520 --> 00:24:18,720
うーん、私は実際にそこに

714
00:24:18,720 --> 00:24:20,220
ある失敗を解釈するのが少し難しいと思う.

715
00:24:20,220 --> 00:24:22,620


716
00:24:22,620 --> 00:24:24,720


717
00:24:24,720 --> 00:24:26,400


718
00:24:26,400 --> 00:24:28,919


719
00:24:28,919 --> 00:24:31,200


720
00:24:31,200 --> 00:24:33,059


721
00:24:33,059 --> 00:24:34,440
ええと、世界には

722
00:24:34,440 --> 00:24:36,539
彼らの前にあるものがありますええと、彼らの発話は

723
00:24:36,539 --> 00:24:38,520
インタラクティブでもありますので、あなたは

724
00:24:38,520 --> 00:24:39,960
何かを言うことができ、あなたの親があなたが求めるものをあなたに持ってきたかどうかを確認することができます。

725
00:24:39,960 --> 00:24:41,400


726
00:24:41,400 --> 00:24:43,799


727
00:24:43,799 --> 00:24:46,020


728
00:24:46,020 --> 00:24:49,020


729
00:24:49,020 --> 00:24:51,240
言語習得における重要な手がかりを知っています

730
00:24:51,240 --> 00:24:52,799
ええと、ええと、ええと、

731
00:24:52,799 --> 00:24:55,440
赤ちゃんのLMチャレンジでは、

732
00:24:55,440 --> 00:24:58,200
これらの

733
00:24:58,200 --> 00:25:00,960
モデルを一種のマルチモーダル入力でトレーニングする機能があります。ええと、

734
00:25:00,960 --> 00:25:02,340


735
00:25:02,340 --> 00:25:05,039
与えたいだけのビデオデータを与えることができると思います

736
00:25:05,039 --> 00:25:07,140
ええと、でもおそらく、

737
00:25:07,140 --> 00:25:09,000


738
00:25:09,000 --> 00:25:11,220
子供たちが実際に得るセットアップとフィードバックのタイプを正確に再現するのは難しいでしょう。

739
00:25:11,220 --> 00:25:12,840


740
00:25:12,840 --> 00:25:14,700
ええと、あなたが

741
00:25:14,700 --> 00:25:17,700
知っているかどうかはわかりません。

742
00:25:17,700 --> 00:25:19,799


743
00:25:19,799 --> 00:25:20,760


744
00:25:20,760 --> 00:25:23,700


745
00:25:23,700 --> 00:25:26,580
大規模な言語モデルに関連する興味深い質問があると思います。

746
00:25:26,580 --> 00:25:28,320


747
00:25:28,320 --> 00:25:30,299
これは、

748
00:25:30,299 --> 00:25:31,919
すべてのデータが何を行っているかを正確に理解しているようなものです。

749
00:25:31,919 --> 00:25:34,200
つまり、非常に

750
00:25:34,200 --> 00:25:36,659


751
00:25:36,659 --> 00:25:38,279
多くのデータが必要になる可能性があります。 これらのモデルは、

752
00:25:38,279 --> 00:25:40,620
何らかの形式のセマンティクスを内部で効果的に発明しているためです。

753
00:25:40,620 --> 00:25:43,919


754
00:25:43,919 --> 00:25:45,600
つまり、両方とも構文のルールを発見しており

755
00:25:45,600 --> 00:25:47,460
、そこで

756
00:25:47,460 --> 00:25:49,380
単語の意味についてかなり学習しているように見えます。

757
00:25:49,380 --> 00:25:50,940


758
00:25:50,940 --> 00:25:52,200
ええと、

759
00:25:52,200 --> 00:25:54,059
ええと、完全に不明確ではありません

760
00:25:54,059 --> 00:25:56,220
これらの最新モデルのデータの多くは、

761
00:25:56,220 --> 00:25:58,919
構文対セマンティクスに必要です。

762
00:25:58,919 --> 00:26:00,240


763
00:26:00,240 --> 00:26:02,159
私自身の推測では、

764
00:26:02,159 --> 00:26:05,580
構文側はおそらくセマンティック側

765
00:26:05,580 --> 00:26:07,860
よりも必要なデータがはるかに少ないと思います。

766
00:26:07,860 --> 00:26:09,600


767
00:26:09,600 --> 00:26:11,159
実際には、元学生の学生です。

768
00:26:11,159 --> 00:26:12,960
私のフランク・マリカと私は

769
00:26:12,960 --> 00:26:15,120
数年前に論文を書き、

770
00:26:15,120 --> 00:26:17,400
学習者が言語の

771
00:26:17,400 --> 00:26:19,679


772
00:26:19,679 --> 00:26:22,140
さまざまな側面を学ぶために必然的に獲得しなければならない情報の量を推定しようとしました。

773
00:26:22,140 --> 00:26:23,820


774
00:26:23,820 --> 00:26:25,320


775
00:26:25,320 --> 00:26:26,880
それらの意味はおそらくご存知でしょう

776
00:26:26,880 --> 00:26:28,320


777
00:26:28,320 --> 00:26:32,100
構文を学ぶ必要があります そして基本的にその分析で私たちが見つけたのは、基本

778
00:26:32,100 --> 00:26:34,080


779
00:26:34,080 --> 00:26:35,640
的に

780
00:26:35,640 --> 00:26:37,440
これらの各ドメインのエンベロープ計算の一種に過ぎないということ

781
00:26:37,440 --> 00:26:40,679
です 構文は実際には非常に

782
00:26:40,679 --> 00:26:42,779
少数の情報です

783
00:26:42,779 --> 00:26:46,400
構文を学ぶのにそれほど多くの情報は必要ありません

784
00:26:46,400 --> 00:26:49,320
が、

785
00:26:49,320 --> 00:26:52,740
取得する情報のほとんどは実際にはセマンティクスに関するものであるため、

786
00:26:52,740 --> 00:26:55,740
30 から 50 000 の

787
00:26:55,740 --> 00:26:57,720
異なる単語の意味を知っていると指定します。

788
00:26:57,720 --> 00:27:00,000


789
00:27:00,000 --> 00:27:02,340


790
00:27:02,340 --> 00:27:04,620
それには多くの情報が必要であり、

791
00:27:04,620 --> 00:27:06,360
おそらく各会議は数ビット以上である

792
00:27:06,360 --> 00:27:08,460


793
00:27:08,460 --> 00:27:11,279
可能性があるので、大

794
00:27:11,279 --> 00:27:12,659


795
00:27:12,659 --> 00:27:14,820
規模な言語モデルで起こっていることは、

796
00:27:14,820 --> 00:27:16,320
トレーニングデータのほとんどが単語に関するものであると私に推測させる可能性があります

797
00:27:16,320 --> 00:27:18,600
意味論と、

798
00:27:18,600 --> 00:27:20,760
子供たちが単語の意味論を正しく理解するための他の方法について考えることができます.

799
00:27:20,760 --> 00:27:22,140


800
00:27:22,140 --> 00:27:24,600


801
00:27:24,600 --> 00:27:27,360


802
00:27:27,360 --> 00:27:29,039


803
00:27:29,039 --> 00:27:30,960
ええ、

804
00:27:30,960 --> 00:27:32,640


805
00:27:32,640 --> 00:27:35,279
リンゼイの研究室からの以前の結果のいくつかは、少なくとも

806
00:27:35,279 --> 00:27:37,740
生態学的に有効に制限されていることを示唆していることを知っています

807
00:27:37,740 --> 00:27:40,919
トレーニングサイトを知っているモデルは

808
00:27:40,919 --> 00:27:42,840
一般化しているようです 英語の線形ルールを知っている

809
00:27:42,840 --> 00:27:44,940
はい いいえ 質問形成 ROM

810
00:27:44,940 --> 00:27:46,620
階層的ルール以外

811
00:27:46,620 --> 00:27:48,120
正しい階層 ルールなので、

812
00:27:48,120 --> 00:27:49,980


813
00:27:49,980 --> 00:27:52,020
正しい

814
00:27:52,020 --> 00:27:54,000
構文価格と帰納的バイアスのスペースが

815
00:27:54,000 --> 00:27:56,220
まだ実際に確定していないことを知っているという本当の意味があると思いますが、

816
00:27:56,220 --> 00:27:57,960
少なくとも私には

817
00:27:57,960 --> 00:27:59,400
いくつかのルールが必要であることは明らかです。

818
00:27:59,400 --> 00:28:01,320
また、

819
00:28:01,320 --> 00:28:02,700
英語の子供たちがこの周波数の問題に戻っているという証拠もあります。

820
00:28:02,700 --> 00:28:04,679


821
00:28:04,679 --> 00:28:06,360
英語の子供たちは、長距離の下位補体位置の指定された位置

822
00:28:06,360 --> 00:28:08,100
で動きの中間コピーを綴ることがある

823
00:28:08,100 --> 00:28:10,140


824
00:28:10,140 --> 00:28:11,880


825
00:28:11,880 --> 00:28:13,980
ので、

826
00:28:13,980 --> 00:28:15,360
ソーントンといくつかによる論文があります。 これについての他の論文では、

827
00:28:15,360 --> 00:28:18,120
どの人が

828
00:28:18,120 --> 00:28:19,919
それをしたと思いますかではなく、

829
00:28:19,919 --> 00:28:21,900


830
00:28:21,900 --> 00:28:23,159


831
00:28:23,159 --> 00:28:25,020
誰が

832
00:28:25,020 --> 00:28:26,760
それをしたと思いますかと言われています.

833
00:28:26,760 --> 00:28:28,799
子供は

834
00:28:28,799 --> 00:28:30,779
文法の設定を間違えますが、

835
00:28:30,779 --> 00:28:32,820
入力の頻度は実際にはゼロです。

836
00:28:32,820 --> 00:28:35,159
そのため、私たちの共通の友人であるゲイリー・マーカスも、

837
00:28:35,159 --> 00:28:36,779


838
00:28:36,779 --> 00:28:39,000


839
00:28:39,000 --> 00:28:41,159
ドイツ語の名詞複数形の場合、特定の種類のより規則的な

840
00:28:41,159 --> 00:28:42,779
形で子供の出力を決定する頻度に反対する議論をしています。

841
00:28:42,779 --> 00:28:44,580
頻繁なものよりも好まれ、その

842
00:28:44,580 --> 00:28:46,559
ような例がたくさんあるので、

843
00:28:46,559 --> 00:28:49,080
被験者が

844
00:28:49,080 --> 00:28:50,460
受動的に何かを経験している、

845
00:28:50,460 --> 00:28:52,559
または入力

846
00:28:52,559 --> 00:28:54,299


847
00:28:54,299 --> 00:28:56,039
であまり頻繁ではないため、8歳頃まで子供の理解研究が非常に遅れていると時々主張されていますが、

848
00:28:56,039 --> 00:28:56,880


849
00:28:56,880 --> 00:28:59,220
ケン Wexler と同僚は、被験者の

850
00:28:59,220 --> 00:29:01,260
経験を調べました。ダブル H の

851
00:29:01,260 --> 00:29:03,539
質問は、メアリーが好きな人などです。彼らは、

852
00:29:03,539 --> 00:29:05,820
これらが受動の被験者や経験と同じくらいインプットにおいてまれであることを発見しましたが、

853
00:29:05,820 --> 00:29:07,500


854
00:29:07,500 --> 00:29:09,659
子供たちは

855
00:29:09,659 --> 00:29:10,980
これらの質問の理解研究に

856
00:29:10,980 --> 00:29:13,860
問題はありませんが、

857
00:29:13,860 --> 00:29:16,020
被験者の言語的受動態の経験から、

858
00:29:16,020 --> 00:29:17,880
頻度は再び無関係に見えるか

859
00:29:17,880 --> 00:29:19,380
、少なくとも

860
00:29:19,380 --> 00:29:20,940
説明が正しくない

861
00:29:20,940 --> 00:29:22,320
理論

862
00:29:22,320 --> 00:29:25,080
構築に関しては説明的ではないので、LMS がこれらをどのように助けることができるか 頻度以外に何か他のことが明らかに起こっている

863
00:29:25,080 --> 00:29:27,059
場合に、分岐するケースを知っている

864
00:29:27,059 --> 00:29:28,440


865
00:29:28,440 --> 00:29:30,960
あなたが知っているミョウバンは、

866
00:29:30,960 --> 00:29:33,419


867
00:29:33,419 --> 00:29:35,100
あなたの論文にあるケースのこの号に戻って

868
00:29:35,100 --> 00:29:36,899
、彼らが

869
00:29:36,899 --> 00:29:38,399
無色のスクリーンのアイデアの構造を一般化していることを示しています。

870
00:29:38,399 --> 00:29:41,279


871
00:29:41,279 --> 00:29:43,080


872
00:29:43,080 --> 00:29:44,520


873
00:29:44,520 --> 00:29:46,380
言語を統計的に学べないことについてのあなたの

874
00:29:46,380 --> 00:29:48,059
主張は正しいと思いますが、1950 年代のチョムスキーの

875
00:29:48,059 --> 00:29:49,559


876
00:29:49,559 --> 00:29:51,779
今日の統計モデルに関する指摘は、

877
00:29:51,779 --> 00:29:53,700
2023 年の商用 LMS には

878
00:29:53,700 --> 00:29:55,440
当てはまりません。

879
00:29:55,440 --> 00:29:57,539


880
00:29:57,539 --> 00:29:59,520
ジオメトリ全体を知っているエンタープライズ・チョムスキーの基本的な

881
00:29:59,520 --> 00:30:01,080
ポイントは、

882
00:30:01,080 --> 00:30:02,700
すべての

883
00:30:02,700 --> 00:30:04,980
ダイアグラムの頻度がゼロである文法構造を持つことができ、また、

884
00:30:04,980 --> 00:30:06,899


885
00:30:06,899 --> 00:30:08,039
概念的な

886
00:30:08,039 --> 00:30:09,840
インターフェースに明確に解釈可能な指示を提供できないため、他の

887
00:30:09,840 --> 00:30:11,580
心のシステムのインターフェースを示している.

888
00:30:11,580 --> 00:30:13,980
あなたの論文 GPT は、画面のアイデアを引っ張るなどの例を模倣しています

889
00:30:13,980 --> 00:30:16,559
が、

890
00:30:16,559 --> 00:30:18,840
この文は Google で 150 000 を超える結果を生成し、

891
00:30:18,840 --> 00:30:20,700


892
00:30:20,700 --> 00:30:22,620
文献で広く議論されています。

893
00:30:22,620 --> 00:30:24,480
模倣できるという事実を模倣することができます。

894
00:30:24,480 --> 00:30:26,640
少なくとも私たちは

895
00:30:26,640 --> 00:30:27,840
あまり自信を持って何も言うことができない

896
00:30:27,840 --> 00:30:30,899
ので、ご存知のとおり、

897
00:30:30,899 --> 00:30:32,580
ユニバーシティ カレッジ ダブリンの後ろにいるアビバは最近、この引用を持っています。

898
00:30:32,580 --> 00:30:34,380


899
00:30:34,380 --> 00:30:36,840


900
00:30:36,840 --> 00:30:38,880


901
00:30:38,880 --> 00:30:40,500


902
00:30:40,500 --> 00:30:42,480
LMS がある種の擬態に関与していると非難する ええと、

903
00:30:42,480 --> 00:30:43,919


904
00:30:43,919 --> 00:30:46,860


905
00:30:46,860 --> 00:30:48,840
あなたが論文で与えた gbt の例文は実際には

906
00:30:48,840 --> 00:30:50,700
良い仕事をしていません。

907
00:30:50,700 --> 00:30:52,320


908
00:30:52,320 --> 00:30:54,240


909
00:30:54,240 --> 00:30:55,740
やるかやらないかのどちらかですが、

910
00:30:55,740 --> 00:30:57,120


911
00:30:57,120 --> 00:30:59,880
このような 10 の例を示すという点で妥協点はありません。

912
00:30:59,880 --> 00:31:02,880
無色の緑のアイデアは、

913
00:31:02,880 --> 00:31:04,679


914
00:31:04,679 --> 00:31:06,840
茶色のきらめくウサギ、

915
00:31:06,840 --> 00:31:09,899
白いキラキラしたクマ、黒い光沢のあるカンガルー、

916
00:31:09,899 --> 00:31:12,360
緑のキラキラしたサルなどとは非常に異なるセマンティック オブジェクトです。

917
00:31:12,360 --> 00:31:15,120
黄色のまばゆいライオンズ 赤く光る

918
00:31:15,120 --> 00:31:16,320
要素 そうですね これらはすべて

919
00:31:16,320 --> 00:31:18,899
意味論的に奇妙で少し

920
00:31:18,899 --> 00:31:20,820
奇妙ですが、それでも法的

921
00:31:20,820 --> 00:31:22,440
構造のようなものです それらは一種の意味のある

922
00:31:22,440 --> 00:31:25,320
合成意味論的オブジェクトです ええと、

923
00:31:25,320 --> 00:31:27,179


924
00:31:27,179 --> 00:31:29,580
私はちょうどそう言ったので、

925
00:31:29,580 --> 00:31:33,179
私は多分私ができるかもしれません

926
00:31:33,179 --> 00:31:34,799
最初のポイントに最初に正しく反応できる

927
00:31:34,799 --> 00:31:36,120
ので、

928
00:31:36,120 --> 00:31:37,799
ええと、あなたは

929
00:31:37,799 --> 00:31:40,140
これらの他の種類の獲得

930
00:31:40,140 --> 00:31:42,179
パターンについて話し始めましたが、おそらく周波数に直接マッピングされていない可能性があります。ええと、

931
00:31:42,179 --> 00:31:44,279


932
00:31:44,279 --> 00:31:47,159


933
00:31:47,159 --> 00:31:50,640
現代の学習

934
00:31:50,640 --> 00:31:53,039
モデルのようなものだと考えるのは実際には間違いだと思います なぜなら、

935
00:31:53,039 --> 00:31:54,899


936
00:31:54,899 --> 00:31:57,120
彼らはルールや構造などのかなり複雑なファミリーのように明らかに学んでいるからです。

937
00:31:57,120 --> 00:31:59,580


938
00:31:59,580 --> 00:32:02,399


939
00:32:02,399 --> 00:32:03,899


940
00:32:03,899 --> 00:32:06,600


941
00:32:06,600 --> 00:32:08,580
単純

942
00:32:08,580 --> 00:32:10,559
または倹約的なええと、

943
00:32:10,559 --> 00:32:12,360


944
00:32:12,360 --> 00:32:13,980
彼らが正しく見たデータの説明と、それが

945
00:32:13,980 --> 00:32:16,080
ニューラル ネットワークにどのようにキャッシュアウトされるかについての説明は、おそらく

946
00:32:16,080 --> 00:32:19,200
複雑であり、それはパラメーターと学習アルゴリズムの詳細を知っていることに依存することを知っています。

947
00:32:19,200 --> 00:32:20,880


948
00:32:20,880 --> 00:32:22,679


949
00:32:22,679 --> 00:32:24,480
そのようなことです

950
00:32:24,480 --> 00:32:27,000
が、私はおそらく、彼らがそうであるように、

951
00:32:27,000 --> 00:32:29,279


952
00:32:29,279 --> 00:32:31,740


953
00:32:31,740 --> 00:32:35,640
彼らが複雑な一連のことを学んでいるのと同じように、

954
00:32:35,640 --> 00:32:38,399


955
00:32:38,399 --> 00:32:40,799
複雑な種類のものを学んでいる可能性が高いのではないかと思います.

956
00:32:40,799 --> 00:32:43,799
ルールと構造のファミリの

957
00:32:43,799 --> 00:32:46,919
ええと、つまり、

958
00:32:46,919 --> 00:32:49,380
ええと、それらの一般化は、あなたが

959
00:32:49,380 --> 00:32:52,500
与えた人々の例のようかもしれないと思います。ええと、

960
00:32:52,500 --> 00:32:55,440


961
00:32:55,440 --> 00:32:57,720
入力右で

962
00:32:57,720 --> 00:33:00,000
ある種の不連続かもしれません。

963
00:33:00,000 --> 00:33:02,220


964
00:33:02,220 --> 00:33:03,840


965
00:33:03,840 --> 00:33:06,059
これまでに見てきたデータの最も単純な文法は、目に

966
00:33:06,059 --> 00:33:09,120
見えない文字列を正しく予測するものであり、

967
00:33:09,120 --> 00:33:12,360
それが起こった場合、

968
00:33:12,360 --> 00:33:14,100
データを学習して、

969
00:33:14,100 --> 00:33:16,860
いくつかの新しい目に見えないで一般化する表現を学習することになります. これまでのところ、

970
00:33:16,860 --> 00:33:19,440


971
00:33:19,440 --> 00:33:21,720
純粋に、その一般化は、これまでの

972
00:33:21,720 --> 00:33:23,460


973
00:33:23,460 --> 00:33:25,019
シーンで見たデータの最も単純な説明のようなものだからです.

974
00:33:25,019 --> 00:33:25,980


975
00:33:25,980 --> 00:33:28,320
言語学者がやろうとしたのは、

976
00:33:28,320 --> 00:33:29,700
データを見て、

977
00:33:29,700 --> 00:33:31,260
それの理論、そして時々その

978
00:33:31,260 --> 00:33:33,419
理論はいくつかの新しい現象

979
00:33:33,419 --> 00:33:35,840
やいくつかの新しいタイプの文を正しく予測します.

980
00:33:35,840 --> 00:33:38,159


981
00:33:38,159 --> 00:33:41,100


982
00:33:41,100 --> 00:33:42,899


983
00:33:42,899 --> 00:33:45,000


984
00:33:45,000 --> 00:33:47,039
また、現在、そのようなパターンを示している

985
00:33:47,039 --> 00:33:48,899
かどうかは、未解決の

986
00:33:48,899 --> 00:33:51,299
経験的な問題だと思います。なぜなら、

987
00:33:51,299 --> 00:33:52,740


988
00:33:52,740 --> 00:33:54,120


989
00:33:54,120 --> 00:33:55,620
少量のデータでそれらをトレーニングし、

990
00:33:55,620 --> 00:33:57,480
それらの一般化をテストする必要があるためです。

991
00:33:57,480 --> 00:33:58,260


992
00:33:58,260 --> 00:34:00,120


993
00:34:00,120 --> 00:34:01,620


994
00:34:01,620 --> 00:34:03,899
人間が

995
00:34:03,899 --> 00:34:06,059
純粋に頻度に基づいていないことを行っていることを知っているという事実は、

996
00:34:06,059 --> 00:34:07,860
いずれにせよ正しい証拠です。なぜなら、

997
00:34:07,860 --> 00:34:09,300
豊富で

998
00:34:09,300 --> 00:34:10,980
興味深いクラスの理論について学んだら、

999
00:34:10,980 --> 00:34:13,980
それが予想される行動であるからです。

1000
00:34:13,980 --> 00:34:16,980
私は約1年前に論文を持っていました.

1001
00:34:16,980 --> 00:34:18,719
あなたは

1002
00:34:18,719 --> 00:34:20,040


1003
00:34:20,040 --> 00:34:22,560
Yangとpianta dosiについてよく知っていると思います.

1004
00:34:22,560 --> 00:34:24,179
どこで私たちがい

1005
00:34:24,179 --> 00:34:26,879


1006
00:34:26,879 --> 00:34:29,280
たのか.

1007
00:34:29,280 --> 00:34:32,639
ええと、

1008
00:34:32,639 --> 00:34:34,679
異なる形式言語なので、

1009
00:34:34,679 --> 00:34:35,820


1010
00:34:35,820 --> 00:34:38,760
一般的なモデルを与えると考えてみてください.10

1011
00:34:38,760 --> 00:34:41,159
または20の単純な文字列を知っているだけで、

1012
00:34:41,159 --> 00:34:43,500


1013
00:34:43,500 --> 00:34:46,199


1014
00:34:46,199 --> 00:34:49,320
何らかのパターンに従うと、そのデータを説明できるプログラムを見つけるように求めます。

1015
00:34:49,320 --> 00:34:50,940


1016
00:34:50,940 --> 00:34:52,679


1017
00:34:52,679 --> 00:34:54,839
文字列のパターンをプログラムで書き留める方法です。

1018
00:34:54,839 --> 00:34:56,280
その図には、

1019
00:34:56,280 --> 00:34:58,020
この点に本当に関連する論文があります。

1020
00:34:58,020 --> 00:34:59,820


1021
00:34:59,820 --> 00:35:02,640
そのような

1022
00:35:02,640 --> 00:35:04,200
モデルが作る一般化は、

1023
00:35:04,200 --> 00:35:06,660
定性的には、

1024
00:35:06,660 --> 00:35:08,160
あなたが人々のために説明しているものと同じように、

1025
00:35:08,160 --> 00:35:10,560


1026
00:35:10,560 --> 00:35:12,060
ええと、少量

1027
00:35:12,060 --> 00:35:13,980
のデータを与えることができ、トレーニング入力の頻度がゼロであっても、目に見えない

1028
00:35:13,980 --> 00:35:16,740
文字列を非常に高い確率で予測します。

1029
00:35:16,740 --> 00:35:18,420


1030
00:35:18,420 --> 00:35:20,280


1031
00:35:20,280 --> 00:35:22,740
多くの場合、あなたが見たデータ

1032
00:35:22,740 --> 00:35:24,660
の最も簡潔な計算記述は、

1033
00:35:24,660 --> 00:35:26,640


1034
00:35:26,640 --> 00:35:29,640
特定の新しい目に見えない出力を予測するものであるため、

1035
00:35:29,640 --> 00:35:32,940
そのモデルは本質的に、

1036
00:35:32,940 --> 00:35:34,800


1037
00:35:34,800 --> 00:35:36,839


1038
00:35:36,839 --> 00:35:38,160


1039
00:35:38,160 --> 00:35:40,619
私が 以前に取り上げました

1040
00:35:40,619 --> 00:35:42,900
が、

1041
00:35:42,900 --> 00:35:43,980


1042
00:35:43,980 --> 00:35:45,660
子供たちがそのような

1043
00:35:45,660 --> 00:35:48,599
異常または予期しないことを言っているこれらの議論の文脈で考えれば、

1044
00:35:48,599 --> 00:35:50,280
これらすべての種類のアカウントによって予測されることを知っていると思います。

1045
00:35:50,280 --> 00:35:52,859


1046
00:35:52,859 --> 00:35:54,180
これらは文法

1047
00:35:54,180 --> 00:35:55,680
の興味深い空間を効果的に比較しており、

1048
00:35:55,680 --> 00:35:56,760


1049
00:35:56,760 --> 00:35:58,079
それらはその

1050
00:35:58,079 --> 00:35:59,760
ような振る舞いを示します.

1051
00:35:59,760 --> 00:36:04,680
ええ、そうです.大丈夫だと思います.

1052
00:36:04,680 --> 00:36:06,960
少なくとも

1053
00:36:06,960 --> 00:36:10,140
性別の観点からは、構文は

1054
00:36:10,140 --> 00:36:13,140
別々に機能している. しかし、それはまだ

1055
00:36:13,140 --> 00:36:15,359
セマンティクスにマッピングされており、プラグマティクスに正しく通知されているため、

1056
00:36:15,359 --> 00:36:17,040
中東では

1057
00:36:17,040 --> 00:36:18,480
プログラム構文は明らかに無意味です。

1058
00:36:18,480 --> 00:36:20,160
非常に小さいです。

1059
00:36:20,160 --> 00:36:22,320
線形化とラベル付けだけです。

1060
00:36:22,320 --> 00:36:24,180


1061
00:36:24,180 --> 00:36:26,220
セントロモーターシステムへの線形化アルゴリズム

1062
00:36:26,220 --> 00:36:27,900
とある種の

1063
00:36:27,900 --> 00:36:30,480


1064
00:36:30,480 --> 00:36:32,220
概念システムのええとセンターの分類アルゴリズムえ

1065
00:36:32,220 --> 00:36:33,839
えと、チョムスキーのアーキテクチャは、

1066
00:36:33,839 --> 00:36:35,940
構文をセマンティクスにマッピングするプロセスに依存しているようなものです。それは

1067
00:36:35,940 --> 00:36:37,560
泡の意味の

1068
00:36:37,560 --> 00:36:39,960
規制です。それは単なる構造ではなく、

1069
00:36:39,960 --> 00:36:42,180
単なる意味ではないので、LMSには実際にはこれがありません

1070
00:36:42,180 --> 00:36:43,680


1071
00:36:43,680 --> 00:36:45,180
セマンティクスへのマッピングはどこにあるのか

1072
00:36:45,180 --> 00:36:47,160
、マッピングがある場合は何をするのか、

1073
00:36:47,160 --> 00:36:48,480
マッピングプロセスはどのように見えるのか、

1074
00:36:48,480 --> 00:36:50,099
そのセマンティクスのプロパティは何か、

1075
00:36:50,099 --> 00:36:52,320
あなたはこれらが何をするのか知っています

1076
00:36:52,320 --> 00:36:54,000
セマンティクスのプロパティが

1077
00:36:54,000 --> 00:36:55,500
独自のセットに配置するもの

1078
00:36:55,500 --> 00:36:57,180


1079
00:36:57,180 --> 00:36:58,980
自然言語の場合のようなマーケティングプロセスの制約は、あなたが知っているようなものです。

1080
00:36:58,980 --> 00:37:01,079
これらの種類の制約は、

1081
00:37:01,079 --> 00:37:02,640
相互に通知しますか?

1082
00:37:02,640 --> 00:37:05,579
要素は、ペアリングを意味する

1083
00:37:05,579 --> 00:37:07,260
この形式を実際に説明していないように見える、前後のプロセスのようなものです.

1084
00:37:07,260 --> 00:37:09,359
たとえば、

1085
00:37:09,359 --> 00:37:11,339
どの文字列がどのような意味を持っているかは正しいです。

1086
00:37:11,339 --> 00:37:14,640
申し訳ありませんが、

1087
00:37:14,640 --> 00:37:16,740
それらにはセマンティクスがまったくないということですか

1088
00:37:16,740 --> 00:37:18,599
、それとも、構造がセマンティクスにどのようにマッピングされるかの

1089
00:37:18,599 --> 00:37:21,180
間に明確な描写がないと言っているのですか。

1090
00:37:21,180 --> 00:37:23,400


1091
00:37:23,400 --> 00:37:25,500
ええ、後者です。 正しいので、彼らは

1092
00:37:25,500 --> 00:37:27,300
明らかに潜在的にある種の

1093
00:37:27,300 --> 00:37:28,800
セマンティクスを持っています 概念的な役割についてあなたが主張したことは知っています

1094
00:37:28,800 --> 00:37:30,180
理論は

1095
00:37:30,180 --> 00:37:31,920
ここに関連しています 残りの部分は

1096
00:37:31,920 --> 00:37:33,900
もう少し神秘的かもしれませんが、

1097
00:37:33,900 --> 00:37:35,339
実際の大豆言語学

1098
00:37:35,339 --> 00:37:36,900
マッピングプロセスの理論があります それ自体は

1099
00:37:36,900 --> 00:37:39,060
明示的であり、実際にそれを見ることが

1100
00:37:39,060 --> 00:37:40,440
でき、心理言語モデルでさまざまな理論をテストできます。

1101
00:37:40,440 --> 00:37:42,000
また、

1102
00:37:42,000 --> 00:37:44,700
実際の規制は何ですか?あなたが知っている

1103
00:37:44,700 --> 00:37:46,079
種類の制約された曖昧さ

1104
00:37:46,079 --> 00:37:48,119
あいまいさ 1 つの

1105
00:37:48,119 --> 00:37:50,400
単語の複数の意味または 1 つを知っているという意味での曖昧さ 複数の解釈を構造化するなど、

1106
00:37:50,400 --> 00:37:53,040


1107
00:37:53,040 --> 00:37:55,200
そうです、意味論があると思うなら、

1108
00:37:55,200 --> 00:37:57,599


1109
00:37:57,599 --> 00:37:59,640
構文から意味論へのマッピングが必要だと思いますええと、

1110
00:37:59,640 --> 00:38:00,960


1111
00:38:00,960 --> 00:38:03,599


1112
00:38:03,599 --> 00:38:04,980


1113
00:38:04,980 --> 00:38:07,560
深いレベルで彼らがどのように働いているかを誰も本当に理解しているわけではないということには同意します そうですね、

1114
00:38:07,560 --> 00:38:10,140


1115
00:38:10,140 --> 00:38:11,940
生成構文とセマンティクスで言うほど明確ではないことに同意します。

1116
00:38:11,940 --> 00:38:13,859


1117
00:38:13,859 --> 00:38:15,180


1118
00:38:15,180 --> 00:38:17,880
構成のルールを書き留めて、

1119
00:38:17,880 --> 00:38:19,920


1120
00:38:19,920 --> 00:38:21,480
構成要素から文から構成上の意味を導き出すことができることを知っています。 または

1121
00:38:21,480 --> 00:38:23,339
そのようなものは、

1122
00:38:23,339 --> 00:38:24,660
ええと、それは彼らが正しく機能している方法ではないことを知っています

1123
00:38:24,660 --> 00:38:27,060
が、ええと、私は

1124
00:38:27,060 --> 00:38:28,859


1125
00:38:28,859 --> 00:38:32,160
それがそのようでなければ

1126
00:38:32,160 --> 00:38:34,619
ならないことを

1127
00:38:34,619 --> 00:38:36,420
当然とは思いません

1128
00:38:36,420 --> 00:38:38,760
すべてが高次元のベクトル空間で表現されていることは正しく機能し、

1129
00:38:38,760 --> 00:38:40,800


1130
00:38:40,800 --> 00:38:43,740


1131
00:38:43,740 --> 00:38:46,200
そのベクトルのセマンティクスが追加の単語ごとに更新される複雑な方法があります。 たとえば、

1132
00:38:46,200 --> 00:38:48,240


1133
00:38:48,240 --> 00:38:51,480


1134
00:38:51,480 --> 00:38:53,940


1135
00:38:53,940 --> 00:38:55,320


1136
00:38:55,320 --> 00:38:57,660


1137
00:38:57,660 --> 00:38:59,099


1138
00:38:59,099 --> 00:39:01,260
少なくともおおよその質問に答えることができるような文のセマンティクスの表現の種類 完全では

1139
00:39:01,260 --> 00:39:02,760
ないことを意味しますが、

1140
00:39:02,760 --> 00:39:04,380


1141
00:39:04,380 --> 00:39:06,720
ええと、それはエングラムモデルのようなものではなく、

1142
00:39:06,720 --> 00:39:07,740
実際には

1143
00:39:07,740 --> 00:39:10,500
セマンティクスを持たないものではありません。

1144
00:39:10,500 --> 00:39:12,780
ええと、それらは

1145
00:39:12,780 --> 00:39:14,040
間違いなく

1146
00:39:14,040 --> 00:39:16,920
セマンティクスを表していると思います。

1147
00:39:16,920 --> 00:39:20,040
ええと、それらが言語を処理するときにそれを更新していることを知っていますが、

1148
00:39:20,040 --> 00:39:21,599


1149
00:39:21,599 --> 00:39:23,400
これらの他の正式な理論のように見えないのはたまたまです。ええと、

1150
00:39:23,400 --> 00:39:24,599


1151
00:39:24,599 --> 00:39:26,400
私にはわかりません

1152
00:39:26,400 --> 00:39:27,720
他の形式理論と同じように、なぜそれが問題なのかというと、

1153
00:39:27,720 --> 00:39:29,640


1154
00:39:29,640 --> 00:39:31,920
お粗末な近似を知っているか、

1155
00:39:31,920 --> 00:39:33,720


1156
00:39:33,720 --> 00:39:35,520
完全に

1157
00:39:35,520 --> 00:39:37,260


1158
00:39:37,260 --> 00:39:39,359


1159
00:39:39,359 --> 00:39:41,520
間違っている可能性があるということです。

1160
00:39:41,520 --> 00:39:42,780
これらのことは正しく行われているので、

1161
00:39:42,780 --> 00:39:45,240
これについて別の考え方をすれば、LMS は

1162
00:39:45,240 --> 00:39:47,760
よく知られている LMS は圧縮アルゴリズムです

1163
00:39:47,760 --> 00:39:49,740
が、自然言語の理解は解凍に関するものであり、

1164
00:39:49,740 --> 00:39:51,540


1165
00:39:51,540 --> 00:39:54,180
意味の曖昧さをなくすことです X 意味から

1166
00:39:54,180 --> 00:39:56,099
XYZ は、

1167
00:39:56,099 --> 00:39:58,020
あなたが知っていることについて推論を行うことがすべてです トレーニング データ

1168
00:39:58,020 --> 00:39:59,579
にない概念間のメタ関係です。

1169
00:39:59,579 --> 00:40:01,859


1170
00:40:01,859 --> 00:40:03,180
メラニー ミッチェルが

1171
00:40:03,180 --> 00:40:06,119
あなたの一番上にあることを示すいくつかの例は、彼女が再び上にあることを知っています。

1172
00:40:06,119 --> 00:40:08,700


1173
00:40:08,700 --> 00:40:10,140


1174
00:40:10,140 --> 00:40:11,880
他のことは正しく進行しています。

1175
00:40:11,880 --> 00:40:13,260


1176
00:40:13,260 --> 00:40:16,440
論文でこれらの例のいくつかを議論していると思いますので、ご存知のように、

1177
00:40:16,440 --> 00:40:18,119
言語の学部は

1178
00:40:18,119 --> 00:40:20,940
少なくともこの言語理論の下ではまだありません。

1179
00:40:20,940 --> 00:40:22,920
文字列の生成ではなく、

1180
00:40:22,920 --> 00:40:25,200
この形式に関するものです。

1181
00:40:25,200 --> 00:40:27,540
ペアリング マシンを意味するので、

1182
00:40:27,540 --> 00:40:29,400
属格の伝統では意味論にあるものはすべて正しいと考えることさえあるので、

1183
00:40:29,400 --> 00:40:31,859


1184
00:40:31,859 --> 00:40:33,540
ポール ペトロフスキーの接続詞には、

1185
00:40:33,540 --> 00:40:36,000
人間の意味論は

1186
00:40:36,000 --> 00:40:37,500


1187
00:40:37,500 --> 00:40:39,900


1188
00:40:39,900 --> 00:40:42,000
公正であるというものがあります。 それは

1189
00:40:42,000 --> 00:40:43,920


1190
00:40:43,920 --> 00:40:46,320
あなたが知っている、またはおそらくあなたの言葉の首で起こっている多くのことと互換性があります

1191
00:40:46,320 --> 00:40:47,940
が、それでもなお、

1192
00:40:47,940 --> 00:40:49,859
自然言語は

1193
00:40:49,859 --> 00:40:51,540
まだより構成的であることを知っています。

1194
00:40:51,540 --> 00:40:54,060


1195
00:40:54,060 --> 00:40:55,260


1196
00:40:55,260 --> 00:40:56,820


1197
00:40:56,820 --> 00:40:58,260
より豊かな構造構成を

1198
00:40:58,260 --> 00:41:00,839
持つように作られているので、もっと多くのことが行われている可能性があるため、

1199
00:41:00,839 --> 00:41:02,160


1200
00:41:02,160 --> 00:41:03,480
アテンション ベースのマシン

1201
00:41:03,480 --> 00:41:05,640
メカニズムやトランスフォーマーなどを知っていることは以前に指摘されていましたが、

1202
00:41:05,640 --> 00:41:07,800


1203
00:41:07,800 --> 00:41:10,320


1204
00:41:10,320 --> 00:41:12,359
マージに近い個別のトークン バインディングの組み合わせが可能です。 単純な再帰行列乗算よりも演算子のようです

1205
00:41:12,359 --> 00:41:14,640


1206
00:41:14,640 --> 00:41:16,140
が、バイナリ分岐政府の問題は知っています

1207
00:41:16,140 --> 00:41:17,460


1208
00:41:17,460 --> 00:41:19,260
ここで別の例を選択して、

1209
00:41:19,260 --> 00:41:20,640
完全な意味の規制について説明します

1210
00:41:20,640 --> 00:41:23,640
1つの原理バイナリ分岐イメージは

1211
00:41:23,640 --> 00:41:24,839
興味深い質問ですが、幾何学

1212
00:41:24,839 --> 00:41:26,700
文法は常に異なるものに開かれています

1213
00:41:26,700 --> 00:41:28,740


1214
00:41:28,740 --> 00:41:30,660
合成計算におけるこの明らかな制約の起源と場所は、

1215
00:41:30,660 --> 00:41:31,800
どこ

1216
00:41:31,800 --> 00:41:33,540
から来たのか、おそらく

1217
00:41:33,540 --> 00:41:34,980
マージの条件、スムーズなシステムによって課されたもの、

1218
00:41:34,980 --> 00:41:37,079
おそらくそれはあなたが知っている一種のプライアであり

1219
00:41:37,079 --> 00:41:39,060
、実際には

1220
00:41:39,060 --> 00:41:40,500
最近の作業生成文法です.

1221
00:41:40,500 --> 00:41:43,859


1222
00:41:43,859 --> 00:41:46,440
結婚のすべての理論的仮定を根付かせ、取り除こうとしました正しい多分集合

1223
00:41:46,440 --> 00:41:47,700
論は生成文法をモデル化するための最良の方法ではないかもしれません多分

1224
00:41:47,700 --> 00:41:48,780


1225
00:41:48,780 --> 00:41:50,339
マリアの

1226
00:41:50,339 --> 00:41:51,540
論理的説明はより適切です

1227
00:41:51,540 --> 00:41:53,520
そこには他の多くの最近のアイデアがあり、

1228
00:41:53,520 --> 00:41:55,020
それらはすべて互換性があります

1229
00:41:55,020 --> 00:41:57,540
チョムスキーのアプローチは正しいです実際、

1230
00:41:57,540 --> 00:41:58,680
トランプが

1231
00:41:58,680 --> 00:42:00,060
最も好きなことの1つは、彼が

1232
00:42:00,060 --> 00:42:01,380
間違っていることが証明されたときです.これらの理論の多くは、中心的な主流の

1233
00:42:01,380 --> 00:42:03,720


1234
00:42:03,720 --> 00:42:06,300
ミニマリストアーキテクチャに反対しています.

1235
00:42:06,300 --> 00:42:08,640


1236
00:42:08,640 --> 00:42:11,839
活気に満ちた分野 ボーン

1237
00:42:11,839 --> 00:42:15,119
スタインの人々 ご存知のように、ペトロフスキー ええと、

1238
00:42:15,119 --> 00:42:17,520
ハジプラ 彼らは、

1239
00:42:17,520 --> 00:42:19,380


1240
00:42:19,380 --> 00:42:20,940
化学文法の主流が言うことの多くと根本的な点で

1241
00:42:20,940 --> 00:42:21,960


1242
00:42:21,960 --> 00:42:24,240
意見が一致していませんが、意見の相違の余地はまだありますが、

1243
00:42:24,240 --> 00:42:26,400
核となる仮定を正しく設定することと互換性があります。

1244
00:42:26,400 --> 00:42:27,599
デビッド 例えば、私は

1245
00:42:27,599 --> 00:42:29,400
この中心的な点である種の逸脱を着ています

1246
00:42:29,400 --> 00:42:31,920
が、それでもこれらの

1247
00:42:31,920 --> 00:42:33,240
直感をさまざまな正式なシステムに根付けようとしています.

1248
00:42:33,240 --> 00:42:34,500


1249
00:42:34,500 --> 00:42:36,000


1250
00:42:36,000 --> 00:42:38,099


1251
00:42:38,099 --> 00:42:40,320


1252
00:42:40,320 --> 00:42:42,240


1253
00:42:42,240 --> 00:42:44,579
2020年、彼らはこのペーパー

1254
00:42:44,579 --> 00:42:47,040
トライアルリストのリカレントネットワークを奇妙に敷設しています。

1255
00:42:47,040 --> 00:42:48,359


1256
00:42:48,359 --> 00:42:49,859
これは、あなたが正しく認識していると思うので、問題の

1257
00:42:49,859 --> 00:42:51,060
核心に到達するための非常に良い例です。  -

1258
00:42:51,060 --> 00:42:53,099


1259
00:42:53,099 --> 00:42:54,780


1260
00:42:54,780 --> 00:42:56,520
動詞の数の一致

1261
00:42:56,520 --> 00:42:58,020
ですが、Mitchell と Barrow は、

1262
00:42:58,020 --> 00:43:00,060
これらのネットワークが

1263
00:43:00,060 --> 00:43:01,680
不自然な文の構造でも数の一致を獲得することを示しました。その

1264
00:43:01,680 --> 00:43:03,359
ため、

1265
00:43:03,359 --> 00:43:04,859
自然言語には見られない構造であり、

1266
00:43:04,859 --> 00:43:06,540
人間が処理するのに苦労している

1267
00:43:06,540 --> 00:43:09,359
ため、rnns の学習モードは

1268
00:43:09,359 --> 00:43:11,880
少なくとも rnn は乳児と明確に区​​別されているため、

1269
00:43:11,880 --> 00:43:14,339
乳児のホモサピエンスが正しいことを知っているので、

1270
00:43:14,339 --> 00:43:16,260
Mitchell と

1271
00:43:16,260 --> 00:43:18,359
Bowers は、lstl モデルは個々の文の

1272
00:43:18,359 --> 00:43:20,040
単数形と複数形の適切な表現を持っている一方で、

1273
00:43:20,040 --> 00:43:22,140


1274
00:43:22,140 --> 00:43:24,359


1275
00:43:24,359 --> 00:43:25,800
個々のレベルで表現できる一般化は行われていないことを示しています

1276
00:43:25,800 --> 00:43:27,359
したがって、モデルは抽象化としての数の表現を持っていません

1277
00:43:27,359 --> 00:43:28,859


1278
00:43:28,859 --> 00:43:31,200
どの数が

1279
00:43:31,200 --> 00:43:34,020
単数基底複数形の具体的なインスタンスにすぎないので、

1280
00:43:34,020 --> 00:43:35,400


1281
00:43:35,400 --> 00:43:38,579
LMを介して言語行動をうまく予測したり、

1282
00:43:38,579 --> 00:43:40,800
同様の方法で神経反応をうまく予測したりすることは

1283
00:43:40,800 --> 00:43:42,480
明らかに素晴らしいことであり、おそらく私たちは

1284
00:43:42,480 --> 00:43:43,920
それに入ることができます その問題は後で出しますが、

1285
00:43:43,920 --> 00:43:45,240
ここにはコインの片面しかありません

1286
00:43:45,240 --> 00:43:47,099
コインの反対側は、なぜ

1287
00:43:47,099 --> 00:43:48,780
このタイプの行動であり、他の

1288
00:43:48,780 --> 00:43:50,339
行動ではないのかを説明しています なぜこの構造は私は

1289
00:43:50,339 --> 00:43:52,740
似ておらず、それがおそらくチョムスキーの最も多く

1290
00:43:52,740 --> 00:43:55,380
、あなたが彼を最もよく知っているようです 重要な

1291
00:43:55,380 --> 00:43:56,760
点は、これが他のシステムではない理由です。

1292
00:43:56,760 --> 00:43:59,400
言語学的な理論のようなものは、

1293
00:43:59,400 --> 00:44:00,720


1294
00:44:00,720 --> 00:44:02,760
LM が実際に行われているのに対し、コインの開始を正しく示しているため、

1295
00:44:02,760 --> 00:44:03,839
Mitchell の恥ずかしい論文は、

1296
00:44:03,839 --> 00:44:05,819
彼が

1297
00:44:05,819 --> 00:44:09,420
うまくやっているようなことをしています。

1298
00:44:09,420 --> 00:44:11,400
ヘインズのクレットとスタニスラッシュは 2019 年からのものでした。

1299
00:44:11,400 --> 00:44:13,319
彼らは lstm で数の一致を調べ

1300
00:44:13,319 --> 00:44:15,480
、数の一致をエンコードする 2 つの特殊なユニットを見つけましたが、

1301
00:44:15,480 --> 00:44:17,640


1302
00:44:17,640 --> 00:44:19,020
パフォーマンスへの全体的な貢献は

1303
00:44:19,020 --> 00:44:21,839
低く、2021 年にはええと、正しい

1304
00:44:21,839 --> 00:44:24,000
ことを示しているこの論文がありました。

1305
00:44:24,000 --> 00:44:26,040
彼らのニューラル言語モデルは、

1306
00:44:26,040 --> 00:44:28,079


1307
00:44:28,079 --> 00:44:30,540
ネストされた長期合意の

1308
00:44:30,540 --> 00:44:32,160
イタリア語での性別マーキングの真の再帰的処理を達成しませんでした。前に

1309
00:44:32,160 --> 00:44:34,020


1310
00:44:34,020 --> 00:44:35,819
あなたが主張したように、あなたが知っているいくつかの階層処理が達成されたとしても、

1311
00:44:35,819 --> 00:44:37,380
いくつかの階層が

1312
00:44:37,380 --> 00:44:39,960
残されていたと思いますが、それはそこにありましたが、質問

1313
00:44:39,960 --> 00:44:41,280
それは正しいマッピングですか?それは正しい

1314
00:44:41,280 --> 00:44:42,900
種類の階層です。lstn

1315
00:44:42,900 --> 00:44:45,119
ベースのモデルは、

1316
00:44:45,119 --> 00:44:47,220
1 度の埋め込みの短いスパンで主題の Web 契約を獲得できることがわかりましたが、

1317
00:44:47,220 --> 00:44:49,260
いくつかのより長い依存関係で失敗し

1318
00:44:49,260 --> 00:44:51,359
、最新の

1319
00:44:51,359 --> 00:44:53,700
論文 uh La crepe satell で 彼らは

1320
00:44:53,700 --> 00:44:56,760


1321
00:44:56,760 --> 00:45:00,180


1322
00:45:00,180 --> 00:45:01,980
同じタスクで gpt2 XL を含む最新の Transformer LMS を評価し、トランスフォーマーは

1323
00:45:01,980 --> 00:45:04,260
LSM よりも人間に似たパフォーマンスを発揮し、

1324
00:45:04,260 --> 00:45:06,300
全体的

1325
00:45:06,300 --> 00:45:08,040
にトランスファー以上のパフォーマンスを発揮しましたが、

1326
00:45:08,040 --> 00:45:09,660
私が言及したように、

1327
00:45:09,660 --> 00:45:11,099


1328
00:45:11,099 --> 00:45:13,020


1329
00:45:13,020 --> 00:45:14,400
私がこれらの研究に言及した理由は、

1330
00:45:14,400 --> 00:45:17,040


1331
00:45:17,040 --> 00:45:18,540
興味深い質問である OMS の限界を探求するだけでなく、UCL の

1332
00:45:18,540 --> 00:45:19,500


1333
00:45:19,500 --> 00:45:21,540
Neil Smith のような人々による研究を検討することを知っているからです。

1334
00:45:21,540 --> 00:45:24,180


1335
00:45:24,180 --> 00:45:26,579
90 年代に多言語のサバントと

1336
00:45:26,579 --> 00:45:28,740
定型的なコントロールを比較して、

1337
00:45:28,740 --> 00:45:30,540


1338
00:45:30,540 --> 00:45:32,520


1339
00:45:32,520 --> 00:45:34,500


1340
00:45:34,500 --> 00:45:35,880
ミシュランのウイルス論文の

1341
00:45:35,880 --> 00:45:37,079
ように自然と不自然な両方のグラフィック構造を含む人工言語の第二言語学習を調査しました。フレームワーク全体が自然

1342
00:45:37,079 --> 00:45:39,119
対不自然であることがわかりました。

1343
00:45:39,119 --> 00:45:41,000


1344
00:45:41,000 --> 00:45:43,319
コントロールは

1345
00:45:43,319 --> 00:45:45,480
言語的に自然な側面をマスターすることができた

1346
00:45:45,480 --> 00:45:46,920
コントロールだけが最終的に

1347
00:45:46,920 --> 00:45:48,660
構造に依存する不自然な現象を処理でき

1348
00:45:48,660 --> 00:45:50,460
、どちらも

1349
00:45:50,460 --> 00:45:52,560
構造に依存しない側面をマスターすることはできなかったので、

1350
00:45:52,560 --> 00:45:53,880


1351
00:45:53,880 --> 00:45:55,440
文の3番目の単語に重点を置いていることを知っているようないくつかの奇妙なルール

1352
00:45:55,440 --> 00:45:56,940
そのように彼らは、

1353
00:45:56,940 --> 00:45:58,740
クリストファーの能力は

1354
00:45:58,740 --> 00:46:00,900
完全に彼の無傷の言語

1355
00:46:00,900 --> 00:46:03,480
能力によるものであると主張しますが、コントロールはより多くのドメインを使用することができます

1356
00:46:03,480 --> 00:46:05,579


1357
00:46:05,579 --> 00:46:07,319
注意

1358
00:46:07,319 --> 00:46:09,900
制御などを知っているような一般的な認知リソース.

1359
00:46:09,900 --> 00:46:11,520


1360
00:46:11,520 --> 00:46:13,319
少し

1361
00:46:13,319 --> 00:46:16,079
前に、Mitchell の

1362
00:46:16,079 --> 00:46:18,359
当惑した論文の lstm は自然構造と

1363
00:46:18,359 --> 00:46:19,920
不自然構造にほとんど

1364
00:46:19,920 --> 00:46:22,319
同じ方法でアプローチするので、それが

1365
00:46:22,319 --> 00:46:24,240
心理的にもっともらしいモデルではないことを知っているわけではありません。

1366
00:46:24,240 --> 00:46:26,400


1367
00:46:26,400 --> 00:46:28,200


1368
00:46:28,200 --> 00:46:30,060
La

1369
00:46:30,060 --> 00:46:31,920
creta の作品のトランスフォーマー モデルとこれらのテーマはすべて、

1370
00:46:31,920 --> 00:46:33,780


1371
00:46:33,780 --> 00:46:35,819
現在に至るまでずっと私たちと一緒にいるようです。そのため、

1372
00:46:35,819 --> 00:46:37,560
彼が

1373
00:46:37,560 --> 00:46:39,240
数週間前に投稿した最近の論文の 1 つは、子供向けのスピーチを見て、

1374
00:46:39,240 --> 00:46:41,880
ええと、  lstms と

1375
00:46:41,880 --> 00:46:43,740
Transformers は、生態学的に

1376
00:46:43,740 --> 00:46:46,380
もっともらしい量のデータに限定され、抽象的なルールではなく英語の権利の線形ルールについて述べたように一般化されました。

1377
00:46:46,380 --> 00:46:47,640


1378
00:46:47,640 --> 00:46:49,920


1379
00:46:49,920 --> 00:46:51,780
実際、先週の linton's Lab からの最近の研究では、

1380
00:46:51,780 --> 00:46:54,599
昨年のまあまあを見て、

1381
00:46:54,599 --> 00:46:56,220


1382
00:46:56,220 --> 00:46:58,160
Garden を見ると パスの驚きは、ええと、構文上の曖昧さの解消の難しさを説明していません。ええと、

1383
00:46:58,160 --> 00:47:01,319


1384
00:47:01,319 --> 00:47:02,280


1385
00:47:02,280 --> 00:47:03,900
驚きは、

1386
00:47:03,900 --> 00:47:05,400
すべての構造にわたって庭の小道効果のサイズを過小評価します。

1387
00:47:05,400 --> 00:47:06,780
これは、

1388
00:47:06,780 --> 00:47:08,099
あなたが知っている前に言及したこの問題に到達します。

1389
00:47:08,099 --> 00:47:10,140


1390
00:47:10,140 --> 00:47:11,520
構文のいくつかの側面に関連するすべてのことに驚くかもしれませんが、そうではないかもしれません。

1391
00:47:11,520 --> 00:47:12,960
他のものは、それは一種の非常に

1392
00:47:12,960 --> 00:47:14,819
非賛辞の問題であり、非常に

1393
00:47:14,819 --> 00:47:16,800
議論の余地があります。

1394
00:47:16,800 --> 00:47:18,720
まだ解決されていませんが、リントンは、

1395
00:47:18,720 --> 00:47:20,640
ガーデンパスの効果が私に

1396
00:47:20,640 --> 00:47:21,720
期待するよりもはるかに難しいことを示しました.

1397
00:47:21,720 --> 00:47:24,359
予測不可能なので、

1398
00:47:24,359 --> 00:47:26,160
この議論を言い換える別の言い方をすると、これは

1399
00:47:26,160 --> 00:47:29,160


1400
00:47:29,160 --> 00:47:30,660
チョムスキーとの最近の議論の引用であり、この自然な基礎を理解するための

1401
00:47:30,660 --> 00:47:32,940
不自然な問題です。

1402
00:47:32,940 --> 00:47:34,560


1403
00:47:34,560 --> 00:47:36,180


1404
00:47:36,180 --> 00:47:38,819
存在

1405
00:47:38,819 --> 00:47:40,740
し、おそらく存在できないすべての要素があるとしましょう

1406
00:47:40,740 --> 00:47:42,660


1407
00:47:42,660 --> 00:47:44,880
いくつかのモデルがあるとしましょう

1408
00:47:44,880 --> 00:47:46,560
これらの 3 つの

1409
00:47:46,560 --> 00:47:48,780
カテゴリを区別できない人工的なモデル このモデルが何をしていても、それは

1410
00:47:48,780 --> 00:47:50,640
化学を正しく理解するのに役立たない

1411
00:47:50,640 --> 00:47:52,020
それは何か他のことをしている それは

1412
00:47:52,020 --> 00:47:53,940
何かのために何かをしている 確かに、

1413
00:47:53,940 --> 00:47:55,020


1414
00:47:55,020 --> 00:47:57,180
化学を理解する必要があるかどうかは別のことです。

1415
00:47:57,180 --> 00:47:58,560


1416
00:47:58,560 --> 00:47:59,579
これらの研究のいくつかに対して

1417
00:47:59,579 --> 00:48:02,400
あなたが言ったことを知っています.

1418
00:48:02,400 --> 00:48:03,540


1419
00:48:03,540 --> 00:48:04,920
あなたの論文では、

1420
00:48:04,920 --> 00:48:06,240


1421
00:48:06,240 --> 00:48:07,859


1422
00:48:07,859 --> 00:48:09,720


1423
00:48:09,720 --> 00:48:12,300
政治の通常のバランスでは誤検知に対して何かが不可能であることを示すために、

1424
00:48:12,300 --> 00:48:13,440


1425
00:48:13,440 --> 00:48:15,780
500の独立してサンプリングされた言語などを見る必要があることを

1426
00:48:15,780 --> 00:48:17,880
示す必要があると言っていると思います。

1427
00:48:17,880 --> 00:48:19,020


1428
00:48:19,020 --> 00:48:20,579


1429
00:48:20,579 --> 00:48:23,880


1430
00:48:23,880 --> 00:48:25,800


1431
00:48:25,800 --> 00:48:27,119


1432
00:48:27,119 --> 00:48:29,040
ミシュラン・バウアーズのような人々が行っているので、これが私がここで正しく行っている主要な議論に本当に反論しているかどうかはよくわかりません.

1433
00:48:29,040 --> 00:48:30,839


1434
00:48:30,839 --> 00:48:32,220
原則として不可能であるという議論は、

1435
00:48:32,220 --> 00:48:33,599
ある種の拡張的な意味ではなく、

1436
00:48:33,599 --> 00:48:34,980
世界中の言語を検索して、

1437
00:48:34,980 --> 00:48:37,440


1438
00:48:37,440 --> 00:48:38,579
すべての言語で

1439
00:48:38,579 --> 00:48:40,260
不可能であることを証明することを確認するのと同じように、それは一種の

1440
00:48:40,260 --> 00:48:41,280
別の議論です。

1441
00:48:41,280 --> 00:48:43,740


1442
00:48:43,740 --> 00:48:45,180
アマゾンでは、

1443
00:48:45,180 --> 00:48:47,220


1444
00:48:47,220 --> 00:48:48,420
言語システムが実際に

1445
00:48:48,420 --> 00:48:50,160
できることと同じように行っていることの原則に基づいて、実際には

1446
00:48:50,160 --> 00:48:53,339


1447
00:48:53,339 --> 00:48:55,980


1448
00:48:55,980 --> 00:48:58,560
不可能に比べて

1449
00:48:58,560 --> 00:49:00,480
一部の人々は、X を実行する

1450
00:49:00,480 --> 00:49:02,520
言語が存在しないことを知っているようなことを言いたがります。

1451
00:49:02,520 --> 00:49:04,859
したがって、その

1452
00:49:04,859 --> 00:49:06,960
制限を統計モデルに組み込む必要があります。

1453
00:49:06,960 --> 00:49:09,119


1454
00:49:09,119 --> 00:49:11,220


1455
00:49:11,220 --> 00:49:13,079


1456
00:49:13,079 --> 00:49:15,119
20 つか 20 のヨーロッパ

1457
00:49:15,119 --> 00:49:16,920
言語か何かだけを見ただけです。つまり、

1458
00:49:16,920 --> 00:49:19,020


1459
00:49:19,020 --> 00:49:22,380


1460
00:49:22,380 --> 00:49:24,599
モデルに何かをする動機を与えるべきではないということです。

1461
00:49:24,599 --> 00:49:26,280


1462
00:49:26,280 --> 00:49:28,200
統計的に正当化された普遍的でない場合は、

1463
00:49:28,200 --> 00:49:28,980


1464
00:49:28,980 --> 00:49:30,180


1465
00:49:30,180 --> 00:49:32,760
そうではありません。

1466
00:49:32,760 --> 00:49:33,960
あなたが完全に正しいことを知っていますが、それは

1467
00:49:33,960 --> 00:49:35,339
より一般的に社会

1468
00:49:35,339 --> 00:49:36,960
科学と心理科学に当てはまります.

1469
00:49:36,960 --> 00:49:39,180
類型論的にそうです.

1470
00:49:39,180 --> 00:49:40,380
これらのことを正しく確立することは非常に難しいので、

1471
00:49:40,380 --> 00:49:43,140


1472
00:49:43,140 --> 00:49:44,640
あなたはちょっと古い男だと思います. あなたは、

1473
00:49:44,640 --> 00:49:47,339


1474
00:49:47,339 --> 00:49:49,859


1475
00:49:49,859 --> 00:49:52,619
Xを持つ言語がないように、

1476
00:49:52,619 --> 00:49:54,480
強い主張が正しいことを証明するのは非常に難しいと言っています

1477
00:49:54,480 --> 00:49:56,339
自然言語では何かが許可されていないという強い主張は、

1478
00:49:56,339 --> 00:49:58,800
証明するのが非常に難しいと思います

1479
00:49:58,800 --> 00:49:59,880


1480
00:49:59,880 --> 00:50:01,980


1481
00:50:01,980 --> 00:50:05,460
多くの強力な

1482
00:50:05,460 --> 00:50:08,460
試みがあったことを知っている.すべての言語が何をするかについて、生成構文から多くの強力な主張があることを知っている.

1483
00:50:08,460 --> 00:50:10,380


1484
00:50:10,380 --> 00:50:12,720


1485
00:50:12,720 --> 00:50:16,800


1486
00:50:16,800 --> 00:50:19,140
人々は

1487
00:50:19,140 --> 00:50:21,119
ある種の反例を見つけるのが非常に得意である. これらの

1488
00:50:21,119 --> 00:50:22,740
多くの

1489
00:50:22,740 --> 00:50:24,720
ことについて、エバンスとレビンソンによるこの論文を引用します。

1490
00:50:24,720 --> 00:50:26,579


1491
00:50:26,579 --> 00:50:28,500
実際、ご存知のとおり、どの

1492
00:50:28,500 --> 00:50:30,660
言語も X を実行できないことについて何年も前から聞いていました。

1493
00:50:30,660 --> 00:50:32,160


1494
00:50:32,160 --> 00:50:33,599


1495
00:50:33,599 --> 00:50:35,460
エバンスとレビンソンの

1496
00:50:35,460 --> 00:50:37,859
論文は、この権利についての私の考えを本当に変えました.

1497
00:50:37,859 --> 00:50:40,680
言語は

1498
00:50:40,680 --> 00:50:43,260
実際には私が思っているよりもはるかに多様である.

1499
00:50:43,260 --> 00:50:44,940


1500
00:50:44,940 --> 00:50:47,760


1501
00:50:47,760 --> 00:50:50,700


1502
00:50:50,700 --> 00:50:53,579


1503
00:50:53,579 --> 00:50:54,839
あなたが言ったことの冒頭のようなものに戻ります.

1504
00:50:54,839 --> 00:50:57,660
ええと、

1505
00:50:57,660 --> 00:50:59,880


1506
00:50:59,880 --> 00:51:01,619
子供たちが学ぶことを学び、

1507
00:51:01,619 --> 00:51:03,660
彼らが学ぶデータからそれを学んだ言語アーキテクチャが必要であり、

1508
00:51:03,660 --> 00:51:05,940
それらのアーキテクチャが

1509
00:51:05,940 --> 00:51:09,000
物事になる可能性は低いかもしれないことに私たちは同意すると思います.  lstms のように、または

1510
00:51:09,000 --> 00:51:10,559
単純なリカレント ネットワークを知っているか、または

1511
00:51:10,559 --> 00:51:12,300


1512
00:51:12,300 --> 00:51:14,400
そのようなものを知っています。そのすべての作業は、適切なアーキテクチャに磨きをかけるのに非常に役立つと思います。

1513
00:51:14,400 --> 00:51:16,680


1514
00:51:16,680 --> 00:51:19,200


1515
00:51:19,200 --> 00:51:20,460


1516
00:51:20,460 --> 00:51:21,420


1517
00:51:21,420 --> 00:51:23,819


1518
00:51:23,819 --> 00:51:25,200
あなたが指摘していたポイントは、

1519
00:51:25,200 --> 00:51:26,700


1520
00:51:26,700 --> 00:51:29,160
ええと、しかし、

1521
00:51:29,160 --> 00:51:31,500
これには一種の裏返しがあると思います。つまり、

1522
00:51:31,500 --> 00:51:32,760


1523
00:51:32,760 --> 00:51:34,380


1524
00:51:34,380 --> 00:51:37,619
人々が学ぶことができるもののスペースは、実際には、

1525
00:51:37,619 --> 00:51:39,599
この偏見があるように過小評価されていると思います。

1526
00:51:39,599 --> 00:51:41,760
つまり、人々は

1527
00:51:41,760 --> 00:51:43,800
x y と z um を学習できないことを知っています

1528
00:51:43,800 --> 00:51:46,020
が、少なくとも

1529
00:51:46,020 --> 00:51:47,460
言語以外の人々は、たとえば音楽や数学で見られるパターンのように、

1530
00:51:47,460 --> 00:51:49,680
さまざまな種類のパターンを学習するこの本当に驚くべき能力を持っています。

1531
00:51:49,680 --> 00:51:51,240


1532
00:51:51,240 --> 00:51:53,160


1533
00:51:53,160 --> 00:51:55,619


1534
00:51:55,619 --> 00:51:57,839
私たちは洗練されたタイプのアルゴリズムを学ぶことができます.

1535
00:51:57,839 --> 00:52:00,240


1536
00:52:00,240 --> 00:52:03,119
スペースシャトルを飛ばしたり、

1537
00:52:03,119 --> 00:52:05,760
ロッククライミングのために結び目を作ったりすることを学ぶことができます。

1538
00:52:05,760 --> 00:52:07,319


1539
00:52:07,319 --> 00:52:09,540


1540
00:52:09,540 --> 00:52:11,280


1541
00:52:11,280 --> 00:52:13,440
人々は

1542
00:52:13,440 --> 00:52:16,680
習得することができ、その

1543
00:52:16,680 --> 00:52:19,680
概念は、非常に

1544
00:52:19,680 --> 00:52:21,359


1545
00:52:21,359 --> 00:52:24,059
制限のない空間で機能する学習システムを探す動機付けになると私は思います.

1546
00:52:24,059 --> 00:52:26,160


1547
00:52:26,160 --> 00:52:28,859


1548
00:52:28,859 --> 00:52:30,119


1549
00:52:30,119 --> 00:52:33,420
制限された空間

1550
00:52:33,420 --> 00:52:35,040
ええと、その

1551
00:52:35,040 --> 00:52:36,540
言語が制限されているのは本当かも

1552
00:52:36,540 --> 00:52:37,859
しれませんが、私たちが言語で見るものは

1553
00:52:37,859 --> 00:52:39,960
他のソースから来ているのも本当かもしれません.えーと言語は、たとえば音楽や数学と比較して特に実用的である

1554
00:52:39,960 --> 00:52:42,180
可能性があります.

1555
00:52:42,180 --> 00:52:44,099


1556
00:52:44,099 --> 00:52:47,040


1557
00:52:47,040 --> 00:52:48,720
これらの種類の実用的な

1558
00:52:48,720 --> 00:52:50,040
制約は、

1559
00:52:50,040 --> 00:52:51,480


1560
00:52:51,480 --> 00:52:53,400
言語の形式を制約するものです。適切または言語は

1561
00:52:53,400 --> 00:52:54,660
伝達可能です。

1562
00:52:54,660 --> 00:52:56,760
たとえば、音楽よりもおそらく伝達的であり、

1563
00:52:56,760 --> 00:52:58,440


1564
00:52:58,440 --> 00:53:01,140
物事の形式を制約する可能性があるので、ご存知のとおり、

1565
00:53:01,140 --> 00:53:02,700
これは非常に重要です

1566
00:53:02,700 --> 00:53:05,520


1567
00:53:05,520 --> 00:53:07,140
自然言語の特性がどこから

1568
00:53:07,140 --> 00:53:09,059
来るのかについての言語学の古い議論は、ええと、

1569
00:53:09,059 --> 00:53:11,160
ええと、私が言おうとしているのは、人間ができる

1570
00:53:11,160 --> 00:53:12,660


1571
00:53:12,660 --> 00:53:15,119
すべてのものを見るという一種の視点があるということだと思います

1572
00:53:15,119 --> 00:53:16,980
言語の外でも、

1573
00:53:16,980 --> 00:53:18,599
すべての豊富な構造と

1574
00:53:18,599 --> 00:53:20,819
アルゴリズムとプロセス

1575
00:53:20,819 --> 00:53:23,760
について学習し、内面化することができました。

1576
00:53:23,760 --> 00:53:25,559
あなたは大丈夫かもしれませんが、言語はそのようなものであり、そうです、

1577
00:53:25,559 --> 00:53:27,420
言語には

1578
00:53:27,420 --> 00:53:29,700
これらの他の面白い小さな特性がいくつかありますええと、

1579
00:53:29,700 --> 00:53:31,380
おそらくそれらを知っています 言語がどこから来たかの他のいくつかの部分から来ています.ええと、私たちは

1580
00:53:31,380 --> 00:53:34,020


1581
00:53:34,020 --> 00:53:36,720


1582
00:53:36,720 --> 00:53:38,400
かなり洗練された

1583
00:53:38,400 --> 00:53:40,800
実用的な推論を持っていることを知っています.ええと、

1584
00:53:40,800 --> 00:53:42,720
私たちはそれを使用して特定の

1585
00:53:42,720 --> 00:53:45,359
コミュニケーション

1586
00:53:45,359 --> 00:53:47,160


1587
00:53:47,160 --> 00:53:49,559
上の目的を達成しています. 言語システム自体なので、

1588
00:53:49,559 --> 00:53:51,180
これらの他の

1589
00:53:51,180 --> 00:53:53,819
プロパティのいくつかは、他の起源を持つプロパティである可能性があり、

1590
00:53:53,819 --> 00:53:55,619


1591
00:53:55,619 --> 00:53:57,059
そのビューは

1592
00:53:57,059 --> 00:53:59,579
間違っている可能性があると思いますが、

1593
00:53:59,579 --> 00:54:01,800


1594
00:54:01,800 --> 00:54:04,200
間違っているかどうかを確認するために見る必要があると思います。 私はそれが

1595
00:54:04,200 --> 00:54:05,400


1596
00:54:05,400 --> 00:54:10,020
ええと、ええと、言語学者の大部分によって却下されたと思います.

1597
00:54:10,020 --> 00:54:12,900
ちょうどあなたが

1598
00:54:12,900 --> 00:54:14,579
知っているように、人々が言うのを聞いたことがあります.

1599
00:54:14,579 --> 00:54:15,720
まあ、コミュニケーションは

1600
00:54:15,720 --> 00:54:17,760
言語の正しいことについて実際には何も説明していません

1601
00:54:17,760 --> 00:54:20,040
.

1602
00:54:20,040 --> 00:54:22,200
特定の島の

1603
00:54:22,200 --> 00:54:23,760
制約や、彼らが

1604
00:54:23,760 --> 00:54:25,319
正しく取り組んでいることのように説明しますが、

1605
00:54:25,319 --> 00:54:26,700


1606
00:54:26,700 --> 00:54:28,319
コミュニケーションのプレッシャーが

1607
00:54:28,319 --> 00:54:30,359
おそらく説明する言語には、他のあらゆる種類のものがあります。

1608
00:54:30,359 --> 00:54:31,500


1609
00:54:31,500 --> 00:54:33,540


1610
00:54:33,540 --> 00:54:36,359
用語の幅は、

1611
00:54:36,359 --> 00:54:39,119
それが

1612
00:54:39,119 --> 00:54:41,460
言語を形作ることができる力を考慮したものであり、

1613
00:54:41,460 --> 00:54:43,680
すべてを何らかの形の生来の

1614
00:54:43,680 --> 00:54:45,359
制約やそのようなものに入れる必要はありません。

1615
00:54:45,359 --> 00:54:46,680


1616
00:54:46,680 --> 00:54:48,420
そのようなものの多くはそれらと互換性があると思います

1617
00:54:48,420 --> 00:54:49,980
病気のプログラム

1618
00:54:49,980 --> 00:54:51,960
このプログラムの途中で

1619
00:54:51,960 --> 00:54:53,339
構文を最小限にしたいので、

1620
00:54:53,339 --> 00:54:54,660
複雑にしたくありません。これ

1621
00:54:54,660 --> 00:54:56,220
以上複雑にしなければ

1622
00:54:56,220 --> 00:54:57,960
ならないことを知っているので、興味深いプロパティについて言及した人もいました

1623
00:54:57,960 --> 00:54:59,460
そのため、

1624
00:54:59,460 --> 00:55:00,480


1625
00:55:00,480 --> 00:55:02,579
どの言語モデルでも説明する必要があるプロパティがいくつかあります。

1626
00:55:02,579 --> 00:55:04,200


1627
00:55:04,200 --> 00:55:05,400
人の特徴の設定の例を示します。

1628
00:55:05,400 --> 00:55:06,599


1629
00:55:06,599 --> 00:55:08,880
これらの人の特徴は、非常に

1630
00:55:08,880 --> 00:55:10,440
重要な異なる一般化を示します。

1631
00:55:10,440 --> 00:55:12,480


1632
00:55:12,480 --> 00:55:14,220
ドメイン経由で説明される 一般的な学習メカニズムなので、私は

1633
00:55:14,220 --> 00:55:16,020
ここに座っています クイーン・メアリーのダニエル・ハーパーの作品

1634
00:55:16,020 --> 00:55:17,700
たとえば、

1635
00:55:17,700 --> 00:55:19,740
人の形態学的構成 それは

1636
00:55:19,740 --> 00:55:21,720
数との相互作用 それは

1637
00:55:21,720 --> 00:55:24,059
空間への接続です その意味論の特性

1638
00:55:24,059 --> 00:55:26,040
とそれは線形化 それらはすべて

1639
00:55:26,040 --> 00:55:27,240
見える 私たちの言語知識の有力な候補になるのは、

1640
00:55:27,240 --> 00:55:28,619
私たちが

1641
00:55:28,619 --> 00:55:30,359
言語知識によって意味することですが、

1642
00:55:30,359 --> 00:55:32,280
一方で、格と

1643
00:55:32,280 --> 00:55:34,319
合意、頭の動きなどがあります。これらは

1644
00:55:34,319 --> 00:55:36,420
すべて構造的な現象ですが、

1645
00:55:36,420 --> 00:55:39,319
純粋に意味に基づく説明には抵抗しているようです。

1646
00:55:39,319 --> 00:55:42,420


1647
00:55:42,420 --> 00:55:44,339
理論的な言語学の

1648
00:55:44,339 --> 00:55:45,839
正しい構文が、

1649
00:55:45,839 --> 00:55:47,520


1650
00:55:47,520 --> 00:55:49,440
構造化された意味を構築する計算エンジンに過ぎず、それが

1651
00:55:49,440 --> 00:55:51,240
ミニマリストプログラムの目標であるとすれば素晴らしいことですが、それは

1652
00:55:51,240 --> 00:55:52,800
私たちが実際に見つけたものではなく、具体的なモデルのような実際のミニマリストにはありません具体

1653
00:55:52,800 --> 00:55:54,720


1654
00:55:54,720 --> 00:55:57,240
的な鉱物学者理論の

1655
00:55:57,240 --> 00:55:59,040
目標は単なるものです プログラムのように

1656
00:55:59,040 --> 00:56:01,260
言語は完璧です 大丈夫 それは

1657
00:56:01,260 --> 00:56:03,119
プログラムです 私たちが見つけたのは

1658
00:56:03,119 --> 00:56:05,160
明らかに大丈夫ではありません 言語学者は

1659
00:56:05,160 --> 00:56:07,680
実際にそれを

1660
00:56:07,680 --> 00:56:09,900


1661
00:56:09,900 --> 00:56:11,280
信じていません.

1662
00:56:11,280 --> 00:56:13,740
常にそれを見つけるとは限らないので、

1663
00:56:13,740 --> 00:56:15,839
合意と頭の動きは

1664
00:56:15,839 --> 00:56:17,640
形態学的であり、音韻的で驚異的な

1665
00:56:17,640 --> 00:56:19,319


1666
00:56:19,319 --> 00:56:20,700
パフォーマンスシステムの特性であり、

1667
00:56:20,700 --> 00:56:22,440
パフォーマンスシステムと呼ばれるものなので、

1668
00:56:22,440 --> 00:56:23,760
ミニマリストプログラム自体は、

1669
00:56:23,760 --> 00:56:24,839
あなたが話していることの多くと本当に互換性があります

1670
00:56:24,839 --> 00:56:26,880
言語を知っています

1671
00:56:26,880 --> 00:56:28,500
言語には、

1672
00:56:28,500 --> 00:56:31,200


1673
00:56:31,200 --> 00:56:32,700
コミュニケーション効率のために完成され、最適化できる側面があります。

1674
00:56:32,700 --> 00:56:35,520
それについてはまったく疑いの

1675
00:56:35,520 --> 00:56:38,160
余地はありませんが、効率の場所はどこにあるのでしょうか。

1676
00:56:38,160 --> 00:56:39,960


1677
00:56:39,960 --> 00:56:42,000


1678
00:56:42,000 --> 00:56:43,680
感覚

1679
00:56:43,680 --> 00:56:45,540
運動でそれはスピーチで、

1680
00:56:45,540 --> 00:56:47,640
おそらくスピーチと音韻論で、

1681
00:56:47,640 --> 00:56:50,400
おそらくあなたは知っている誰が知っているという意味ですが、

1682
00:56:50,400 --> 00:56:52,740
これらの多くのことは、あなたが知っているよりもはるかに多くのことを要求すると思います

1683
00:56:52,740 --> 00:56:56,059


1684
00:56:56,059 --> 00:56:57,839
構造依存のような構成上のテーマのような昔ながらの概念への真剣な考察

1685
00:56:57,839 --> 00:56:59,700


1686
00:56:59,700 --> 00:57:01,140


1687
00:57:01,140 --> 00:57:03,720
文学のどこかにあるかもしれませんが、

1688
00:57:03,720 --> 00:57:06,720
ええと、あなたが知っているような基本的なトピックだけでも、拡張射影

1689
00:57:06,720 --> 00:57:08,640
を上げる量指定子、

1690
00:57:08,640 --> 00:57:09,900


1691
00:57:09,900 --> 00:57:12,059


1692
00:57:12,059 --> 00:57:13,920


1693
00:57:13,920 --> 00:57:16,619
副詞的階層のような副詞的です。

1694
00:57:16,619 --> 00:57:18,180
構文

1695
00:57:18,180 --> 00:57:20,579
とクエリ それ自体が一種のドメインであるセマンティック ええと概念システムの非常に奇妙なプロパティ 古代の

1696
00:57:20,579 --> 00:57:23,099


1697
00:57:23,099 --> 00:57:24,559


1698
00:57:24,559 --> 00:57:27,420
一次認識からの一般的な奇妙な残り物 私たちが

1699
00:57:27,420 --> 00:57:29,220


1700
00:57:29,220 --> 00:57:31,260
イベントを渡す方法の特徴

1701
00:57:31,260 --> 00:57:32,520
エージェントと患者を知っている そんなものは

1702
00:57:32,520 --> 00:57:33,960
絶対にありません それは人間

1703
00:57:33,960 --> 00:57:35,520
固有のものではありません

1704
00:57:35,520 --> 00:57:37,260
が、構文が

1705
00:57:37,260 --> 00:57:39,059
これらのシステムに命令を提供する方法を知っているので、

1706
00:57:39,059 --> 00:57:42,480


1707
00:57:42,480 --> 00:57:43,800
生成言語学者も言語生成についてさまざまな理論を持っていることを知っています.

1708
00:57:43,800 --> 00:57:45,839


1709
00:57:45,839 --> 00:57:47,040


1710
00:57:47,040 --> 00:57:49,380
補題を保存するかどうかに基づいて言語生成について話します. または、

1711
00:57:49,380 --> 00:57:51,240
私たちがフレーズや文章を作成するのとまったく同じ方法で単語を作成するかどうかにかかわらず、

1712
00:57:51,240 --> 00:57:52,619


1713
00:57:52,619 --> 00:57:53,819
あなたは

1714
00:57:53,819 --> 00:57:55,440
構築文法と一種の

1715
00:57:55,440 --> 00:57:57,180
生成文法を区別して

1716
00:57:57,180 --> 00:57:58,680
いることを知っています.

1717
00:57:58,680 --> 00:58:00,119


1718
00:58:00,119 --> 00:58:01,559


1719
00:58:01,559 --> 00:58:04,440
つまり、生成に着想を得たいくつかのモデルでは、

1720
00:58:04,440 --> 00:58:06,480


1721
00:58:06,480 --> 00:58:08,460
構文構造を生成するメカニズムが

1722
00:58:08,460 --> 00:58:10,200


1723
00:58:10,200 --> 00:58:12,200
単語レベルの上または下に適用されるプロセスを区別しないことを知っています.

1724
00:58:12,200 --> 00:58:14,640


1725
00:58:14,640 --> 00:58:16,500


1726
00:58:16,500 --> 00:58:18,660
表現

1727
00:58:18,660 --> 00:58:20,099
字句アクセスの各段階は、

1728
00:58:20,099 --> 00:58:21,960
異なる種類のデータ

1729
00:58:21,960 --> 00:58:23,760
構造間の遷移です 正しい

1730
00:58:23,760 --> 00:58:25,740
形式と構文があります これらの 3 つの

1731
00:58:25,740 --> 00:58:27,480
機能は一種の混合物であり、

1732
00:58:27,480 --> 00:58:28,920
それらは常に重なり合うわけではありません 異なる

1733
00:58:28,920 --> 00:58:31,440
言語は異なる方法でそれらを実現する

1734
00:58:31,440 --> 00:58:34,800
ので、ご存知のとおりです 奇妙な言葉の基本的な

1735
00:58:34,800 --> 00:58:36,839
定義は、この奇妙な

1736
00:58:36,839 --> 00:58:39,720
マルチシステム定義であり、

1737
00:58:39,720 --> 00:58:41,040
さまざまな認知

1738
00:58:41,040 --> 00:58:42,900
システムの多くが、すべての電気製品の基礎を豊かにしています.

1739
00:58:42,900 --> 00:58:44,940


1740
00:58:44,940 --> 00:58:46,680
ええと、このようなものはありません.

1741
00:58:46,680 --> 00:58:48,299


1742
00:58:48,299 --> 00:58:50,099
言語理論は

1743
00:58:50,099 --> 00:58:52,200
正しく、または少なくともLLMSがどのように行っているかについては、

1744
00:58:52,200 --> 00:58:53,220


1745
00:58:53,220 --> 00:58:55,859


1746
00:58:55,859 --> 00:58:58,799


1747
00:58:58,799 --> 00:59:01,559
正しいという言葉の定義と、LLMがHood rightという言葉について実際に洞察を提供できるものは何かを尋ねます。

1748
00:59:01,559 --> 00:59:03,780


1749
00:59:03,780 --> 00:59:04,680


1750
00:59:04,680 --> 00:59:06,720
単語が何であるかの目的地がない場合、

1751
00:59:06,720 --> 00:59:07,920
あなたは本当に困っています.

1752
00:59:07,920 --> 00:59:10,319
少なくともLMSまたは人工システムを使用して、

1753
00:59:10,319 --> 00:59:12,780
単語が何を意味するかを通知する必要がある

1754
00:59:12,780 --> 00:59:14,400
か、おそらくそれはもう必要ありません.

1755
00:59:14,400 --> 00:59:16,859
私はあなたが何を意味しているのか分かりません

1756
00:59:16,859 --> 00:59:18,599


1757
00:59:18,599 --> 00:59:20,339


1758
00:59:20,339 --> 00:59:24,059


1759
00:59:24,059 --> 00:59:25,740


1760
00:59:25,740 --> 00:59:27,359


1761
00:59:27,359 --> 00:59:29,819
用語 単語 右のようなものを

1762
00:59:29,819 --> 00:59:31,920
使用できます 補題または

1763
00:59:31,920 --> 00:59:34,440
単語会社またはそのようなものは、従来の

1764
00:59:34,440 --> 00:59:35,819
選択のように感じます

1765
00:59:35,819 --> 00:59:38,040
私はそれが何であるかわかりません 何が問題になっているのかわかりません。

1766
00:59:38,040 --> 00:59:39,180


1767
00:59:39,180 --> 00:59:41,880


1768
00:59:41,880 --> 00:59:43,920
同意すると言う 単語は慣習化されていることを

1769
00:59:43,920 --> 00:59:45,599
知っている アイコンは直感的ではない

1770
00:59:45,599 --> 00:59:47,819
正書法によってしばしば偏っている概念

1771
00:59:47,819 --> 00:59:50,760
スペースを正しく配置する方法 だから

1772
00:59:50,760 --> 00:59:52,559
私はその批判に同意します

1773
00:59:52,559 --> 00:59:54,240
直観的な意味での単語は実際には

1774
00:59:54,240 --> 00:59:56,339
科学的ではないことを知っています 構造ですが、

1775
00:59:56,339 --> 00:59:58,260
私の質問を言い換えさせてください。

1776
00:59:58,260 --> 01:00:00,359


1777
01:00:00,359 --> 01:00:02,160
単語の直感的な概念を、

1778
01:00:02,160 --> 01:00:03,660


1779
01:00:03,660 --> 01:00:04,740
科学的に受け入れられる、または

1780
01:00:04,740 --> 01:00:06,540
心理的にもっともらしいものにどのように分解しますか?

1781
01:00:06,540 --> 01:00:08,280


1782
01:00:08,280 --> 01:00:10,559


1783
01:00:10,559 --> 01:00:12,599
独特の特徴 ええと形態学的カテゴリー

1784
01:00:12,599 --> 01:00:15,180
概念 語根は

1785
01:00:15,180 --> 01:00:17,579
カテゴリー特徴とマージされています あなたが知っている

1786
01:00:17,579 --> 01:00:20,700
概念を取得し、

1787
01:00:20,700 --> 01:00:22,440
名詞またはカテゴリでそれを作成して

1788
01:00:22,440 --> 01:00:24,119
名詞または事件を取得しました これらの異なるモデルは

1789
01:00:24,119 --> 01:00:26,220
異なる予測を正しく行います ええ、つまり、

1790
01:00:26,220 --> 01:00:28,859
私は思います その一般的な考え方は、

1791
01:00:28,859 --> 01:00:30,839
大規模な言語モデルに適している可能性が高く、

1792
01:00:30,839 --> 01:00:32,880


1793
01:00:32,880 --> 01:00:34,380


1794
01:00:34,380 --> 01:00:36,660
たとえば、品詞のカテゴリのようなものが必要であり、

1795
01:00:36,660 --> 01:00:38,819


1796
01:00:38,819 --> 01:00:42,900
それらのカテゴリを更新できる必要があると思います 彼らが

1797
01:00:42,900 --> 01:00:45,240


1798
01:00:45,240 --> 01:00:48,119
これまで見てきた言語に基づいて、あなたが知っているように、

1799
01:00:48,119 --> 01:00:50,520
GPTは名詞と動詞を適切な場所に配置します。そのためには、

1800
01:00:50,520 --> 01:00:53,400


1801
01:00:53,400 --> 01:00:55,319
名詞

1802
01:00:55,319 --> 01:00:57,000
と動詞の表現が必要であり、それを

1803
01:00:57,000 --> 01:01:00,839
行う能力が必要です ええと、一連の

1804
01:01:00,839 --> 01:01:02,579
他の単語の中に自分を見つけて、次に名詞または動詞がある可能性が高いかどうかを判断してください。ええと、

1805
01:01:02,579 --> 01:01:04,680


1806
01:01:04,680 --> 01:01:05,400


1807
01:01:05,400 --> 01:01:07,559
その

1808
01:01:07,559 --> 01:01:09,319
レベルでは、そのような種類の単語の特性は、ええと、そこに

1809
01:01:09,319 --> 01:01:12,480
ある可能性が非常に高いと思います

1810
01:01:12,480 --> 01:01:15,780
また、

1811
01:01:15,780 --> 01:01:17,640


1812
01:01:17,640 --> 01:01:19,619
これらの

1813
01:01:19,619 --> 01:01:21,420
モデルの内部表現に見られる可能性が非常に高いものもあります。それ以外の方法でどのようになるかはわかりませんが、

1814
01:01:21,420 --> 01:01:24,180


1815
01:01:24,180 --> 01:01:26,339
私が知る限り、

1816
01:01:26,339 --> 01:01:29,579
それは そこは

1817
01:01:29,579 --> 01:01:31,500
主要な議論や意見の相違がある場所ではありません

1818
01:01:31,500 --> 01:01:35,220


1819
01:01:35,220 --> 01:01:38,280
私が思うに正しいと思います 言語のすべての理論は、

1820
01:01:38,280 --> 01:01:40,079


1821
01:01:40,079 --> 01:01:41,400


1822
01:01:41,400 --> 01:01:43,140
さまざまな場所やそのようなものに現れるさまざまな種類の単語があることを言わなければならないと思います

1823
01:01:43,140 --> 01:01:44,339


1824
01:01:44,339 --> 01:01:45,240
ええと、

1825
01:01:45,240 --> 01:01:47,160
そうですね、あなたがコミュニケーションについて言及したことを知っている問題についてはどうですか。ええと、

1826
01:01:47,160 --> 01:01:49,020


1827
01:01:49,020 --> 01:01:51,299


1828
01:01:51,299 --> 01:01:53,099
トランプが言語は

1829
01:01:53,099 --> 01:01:54,960
思考システムである、または言語が

1830
01:01:54,960 --> 01:01:57,780
進化しなかったことを知っているなどのことを言っているとき、あなたは完全に正しいです。

1831
01:01:57,780 --> 01:01:58,799
生意気な彼は、

1832
01:01:58,799 --> 01:02:00,180
彼が非常に特定の意味で意味していることを本当に意味しているわけではありませんが、

1833
01:02:00,180 --> 01:02:01,619


1834
01:02:01,619 --> 01:02:03,540
言語は

1835
01:02:03,540 --> 01:02:05,640
思考システムであると言うとき、私たちが意味するのは、

1836
01:02:05,640 --> 01:02:06,780
それを

1837
01:02:06,780 --> 01:02:08,339
アーキテクチャ上の主張にしようとしているということです。

1838
01:02:08,339 --> 01:02:09,599
ミニマリスト プログラムの

1839
01:02:09,599 --> 01:02:10,380


1840
01:02:10,380 --> 01:02:12,240
アーキテクチャ 構文の派生と

1841
01:02:12,240 --> 01:02:13,740
概念システムは文字通り

1842
01:02:13,740 --> 01:02:15,960
異なるシステムです 概念

1843
01:02:15,960 --> 01:02:18,180
システムは構文から何かを取り出し、

1844
01:02:18,180 --> 01:02:19,799
それを使って独自のビジネスを行います CI

1845
01:02:19,799 --> 01:02:21,900
システムには独自の規則

1846
01:02:21,900 --> 01:02:23,700
と原則があります。

1847
01:02:23,700 --> 01:02:25,319
言語では両方とも類似した

1848
01:02:25,319 --> 01:02:27,000
記号構成システムですが、

1849
01:02:27,000 --> 01:02:29,160
異なる方法では、思考のサブセットのみが

1850
01:02:29,160 --> 01:02:32,339
適切に CI インターフェイス システムと呼ばれます。

1851
01:02:32,339 --> 01:02:34,619
なぜなら、CI システムは

1852
01:02:34,619 --> 01:02:36,480
定義上、人間が持っている概念システムにアクセスして構文から命令を読み取ることができないものは何でも知っているからです。

1853
01:02:36,480 --> 01:02:38,819


1854
01:02:38,819 --> 01:02:40,859


1855
01:02:40,859 --> 01:02:42,540
それらが何であるかは完全にはわかりません

1856
01:02:42,540 --> 01:02:43,920


1857
01:02:43,920 --> 01:02:45,540
文法的な参照と明確さのイベントと関係があるようです

1858
01:02:45,540 --> 01:02:47,099
それらは

1859
01:02:47,099 --> 01:02:48,359
あなたが知っている言語が概念的に気にかけている主要なカテゴリーのようです

1860
01:02:48,359 --> 01:02:49,440


1861
01:02:49,440 --> 01:02:50,940
が、それが

1862
01:02:50,940 --> 01:02:52,859
単なる 仮説は正しいです

1863
01:02:52,859 --> 01:02:53,940
が、私たちが知っているのは、それらは

1864
01:02:53,940 --> 01:02:56,220
色をあまり使用していないように見えるということです。

1865
01:02:56,220 --> 01:02:58,440
つまり、言語が

1866
01:02:58,440 --> 01:03:00,240
形態学的に色の色合いを知っていることを示したり、形態学的に

1867
01:03:00,240 --> 01:03:01,140


1868
01:03:01,140 --> 01:03:03,900


1869
01:03:03,900 --> 01:03:06,359
心配したり懸念したりする言語はありません。

1870
01:03:06,359 --> 01:03:07,980


1871
01:03:07,980 --> 01:03:10,079
問題についてのある程度の心配や懸念を示しますが、私たちは証拠などの

1872
01:03:10,079 --> 01:03:11,960


1873
01:03:11,960 --> 01:03:13,500
認識論的概念のようなものを利用しているので、

1874
01:03:13,500 --> 01:03:15,599


1875
01:03:15,599 --> 01:03:17,640
あなたはよく知っています.

1876
01:03:17,640 --> 01:03:19,500


1877
01:03:19,500 --> 01:03:21,720


1878
01:03:21,720 --> 01:03:23,400
思考言語のどの側面が

1879
01:03:23,400 --> 01:03:25,619
密接に結びついていて、どの側面に

1880
01:03:25,619 --> 01:03:27,900
結びついていないかを明らかにするため、中西部の

1881
01:03:27,900 --> 01:03:29,280
プログラムでは、それを非常に

1882
01:03:29,280 --> 01:03:31,680
きれいに切り分けることができます。これは、チョムスキーが言語が考えたと言ったときに

1883
01:03:31,680 --> 01:03:33,180
知っているよりもはるかに微妙なフレームワークです.

1884
01:03:33,180 --> 01:03:34,559


1885
01:03:34,559 --> 01:03:36,960
繰り返しになりますが、彼はそうでは

1886
01:03:36,960 --> 01:03:38,339
ないかもしれませんが、それは

1887
01:03:38,339 --> 01:03:40,319
彼の理論の実際のアーキテクチャが言っていることではありません。

1888
01:03:40,319 --> 01:03:42,480


1889
01:03:42,480 --> 01:03:43,920


1890
01:03:43,920 --> 01:03:46,559


1891
01:03:46,559 --> 01:03:48,839


1892
01:03:48,839 --> 01:03:50,700
メンタリストプログラムから出てきた

1893
01:03:50,700 --> 01:03:52,380
言語が思考に等しいと本当に信じている人は誰もいない

1894
01:03:52,380 --> 01:03:53,760
言語システムは、

1895
01:03:53,760 --> 01:03:55,920


1896
01:03:55,920 --> 01:03:57,599
さまざまな概念システムにアクセスし、再フォーマットし、操作するために最善を尽くしているようですが、

1897
01:03:57,599 --> 01:03:59,220
その限界があります。

1898
01:03:59,220 --> 01:04:01,440


1899
01:04:01,440 --> 01:04:02,819


1900
01:04:02,819 --> 01:04:05,160
構文エンジンに関して、

1901
01:04:05,160 --> 01:04:07,260
どれが

1902
01:04:07,260 --> 01:04:09,480
ええとではないので、この種の概念は、

1903
01:04:09,480 --> 01:04:11,579
概念の語彙化が

1904
01:04:11,579 --> 01:04:14,099
何らかの方法でそれを変更するように思われるという考えに戻ることを知っています。

1905
01:04:14,099 --> 01:04:16,200


1906
01:04:16,200 --> 01:04:17,819
概念自体なので、

1907
01:04:17,819 --> 01:04:19,319
講義が概念である場合、突然

1908
01:04:19,319 --> 01:04:21,240
それを少し変換します。

1909
01:04:21,240 --> 01:04:22,680
少し追加して、その上に何か他のものを振りかけます。

1910
01:04:22,680 --> 01:04:24,299
これは、

1911
01:04:24,299 --> 01:04:26,700
ナノタイプによって異なるようですが、これらは

1912
01:04:26,700 --> 01:04:29,160
すべて、幾何学内の非常に明確な建築上の

1913
01:04:29,160 --> 01:04:31,619
主張のようなものです。 文法は

1914
01:04:31,619 --> 01:04:34,980
非常に明確な経験的予測を行うので、

1915
01:04:34,980 --> 01:04:36,420
言い換えれば、私が言っているのは、

1916
01:04:36,420 --> 01:04:37,140


1917
01:04:37,140 --> 01:04:38,940
これらすべての神経心理学研究が

1918
01:04:38,940 --> 01:04:42,119
刺激されていることだと思います.

1919
01:04:42,119 --> 01:04:43,980


1920
01:04:43,980 --> 01:04:45,420


1921
01:04:45,420 --> 01:04:47,819
言語が脳内で損傷を受けると、

1922
01:04:47,819 --> 01:04:50,040


1923
01:04:50,040 --> 01:04:51,960
それらのシステムに影響を与える特定の動揺やモードが失われますが、

1924
01:04:51,960 --> 01:04:54,299
Gen gram Enterprise 内からの実際の予測はありませんが、

1925
01:04:54,299 --> 01:04:56,040
これらの非言語

1926
01:04:56,040 --> 01:04:57,540
システムは損なわれるか、

1927
01:04:57,540 --> 01:04:59,579
コア言語システムが停止した場合に突然シャットダウンする必要があります。

1928
01:04:59,579 --> 01:05:01,200


1929
01:05:01,200 --> 01:05:02,760
ええと、

1930
01:05:02,760 --> 01:05:05,099


1931
01:05:05,099 --> 01:05:07,859
構文

1932
01:05:07,859 --> 01:05:09,900
システムと非言語システムの間の主な分離を強調するものがあるとすれば、実際には妥協しているので、

1933
01:05:09,900 --> 01:05:11,880
ここでの

1934
01:05:11,880 --> 01:05:14,339
言語とコミュニケーションからの多くの予測は、

1935
01:05:14,339 --> 01:05:16,020
文学がその要点を見逃していることを知っています.

1936
01:05:16,020 --> 01:05:19,380
建築上の主張

1937
01:05:19,380 --> 01:05:21,540
ええと、私はただ与えることができますか、ダニエルは

1938
01:05:21,540 --> 01:05:24,180


1939
01:05:24,180 --> 01:05:25,799
そこに行きたいですか、そこに少し背景を与えるので、ええと、

1940
01:05:25,799 --> 01:05:26,760


1941
01:05:26,760 --> 01:05:30,119
EVフェデレンコと

1942
01:05:30,119 --> 01:05:32,880
ローズマリー・バーリーからのこれらの論文があります。

1943
01:05:32,880 --> 01:05:34,500


1944
01:05:34,500 --> 01:05:37,799
彼らは失語症の患者な

1945
01:05:37,799 --> 01:05:40,200
ので、言語能力に障害のある人は

1946
01:05:40,200 --> 01:05:41,880


1947
01:05:41,880 --> 01:05:43,140


1948
01:05:43,140 --> 01:05:45,000
基本的に、

1949
01:05:45,000 --> 01:05:46,980
言語能力に障害があっても、あなたは

1950
01:05:46,980 --> 01:05:49,020
まだ

1951
01:05:49,020 --> 01:05:50,579
ある種の推論

1952
01:05:50,579 --> 01:05:52,859
能力を維持できることを示しています。たとえば、チェスマスターや

1953
01:05:52,859 --> 01:05:55,020
チェスグランドマスターのような人々は

1954
01:05:55,020 --> 01:05:58,140
明らかに非常に優れています。 推論では、うーん、えーと、

1955
01:05:58,140 --> 01:06:00,780


1956
01:06:00,780 --> 01:06:02,640
完全な言語能力を持っていないかもしれません、

1957
01:06:02,640 --> 01:06:04,079
そして、そのような忍耐強い仕事を補完するものもあります.ebb

1958
01:06:04,079 --> 01:06:06,119


1959
01:06:06,119 --> 01:06:08,520
's Labからの研究もあり、

1960
01:06:08,520 --> 01:06:11,220
えーと、脳の部分がええと、

1961
01:06:11,220 --> 01:06:13,859
言語を気にかけていることを示しています.

1962
01:06:13,859 --> 01:06:14,640


1963
01:06:14,640 --> 01:06:16,319


1964
01:06:16,319 --> 01:06:17,700
他の領域を気にする脳の部分から切り離すことができます。

1965
01:06:17,700 --> 01:06:19,619
同じ種類の

1966
01:06:19,619 --> 01:06:21,599
言語のようなものであっても、音楽

1967
01:06:21,599 --> 01:06:23,819
や数学のようなものは

1968
01:06:23,819 --> 01:06:25,859


1969
01:06:25,859 --> 01:06:27,240
言語領域では起こらない傾向があります。 彼は、

1970
01:06:27,240 --> 01:06:29,400


1971
01:06:29,400 --> 01:06:30,539


1972
01:06:30,539 --> 01:06:33,539
これは基本的にチョムスキーに反する証拠であり、

1973
01:06:33,539 --> 01:06:36,660
その

1974
01:06:36,660 --> 01:06:38,579
言語は正しく考えるための媒体であると主張し、

1975
01:06:38,579 --> 01:06:40,440


1976
01:06:40,440 --> 01:06:42,420
言語がなくても起こりうる思考があり、

1977
01:06:42,420 --> 01:06:44,160
言語を気にする脳の領域は

1978
01:06:44,160 --> 01:06:46,020
彼らが認識している脳の領域ではないように思われるからです.

1979
01:06:46,020 --> 01:06:48,359
気にする 考えるのを気にする

1980
01:06:48,359 --> 01:06:50,099
エリオット、あなたが言っているのは、

1981
01:06:50,099 --> 01:06:51,780
人々は

1982
01:06:51,780 --> 01:06:53,039


1983
01:06:53,039 --> 01:06:56,220
その区別を本当に信じていないということです。

1984
01:06:56,220 --> 01:06:57,720


1985
01:06:57,720 --> 01:06:59,880


1986
01:06:59,880 --> 01:07:01,740


1987
01:07:01,740 --> 01:07:03,480


1988
01:07:03,480 --> 01:07:04,799
これらの議論の中でさえ、自己矛盾のようなものです。そのため、あなたの論文では、

1989
01:07:04,799 --> 01:07:06,839
チョムスキーは

1990
01:07:06,839 --> 01:07:08,220
言語は思考システムであると考えていると時々言います

1991
01:07:08,220 --> 01:07:10,319
が、数ページ後、

1992
01:07:10,319 --> 01:07:12,480
チョムスキーは構文は他のものとはまったく別のシステムであると考えていると言うでしょう。

1993
01:07:12,480 --> 01:07:13,799


1994
01:07:13,799 --> 01:07:15,480
そうですね、構文の自律性など、

1995
01:07:15,480 --> 01:07:18,900
これはチョムスキーのことであり、

1996
01:07:18,900 --> 01:07:20,460
私の矛盾ではありません。つまり、彼は

1997
01:07:20,460 --> 01:07:22,140
これらの両方のことを正確に言っているので、

1998
01:07:22,140 --> 01:07:24,780


1999
01:07:24,780 --> 01:07:26,280
彼は

2000
01:07:26,280 --> 01:07:28,319
これらのことを本当に信じているのか、それとも

2001
01:07:28,319 --> 01:07:30,420
物理的なものは何から生じるのかを自問したいと思うかもしれません。

2002
01:07:30,420 --> 01:07:32,520
言語は思考システムであると言っているだけで、それは何を

2003
01:07:32,520 --> 01:07:34,619


2004
01:07:34,619 --> 01:07:35,579
意味するのか、それは何を意味するのか、それは非常に

2005
01:07:35,579 --> 01:07:36,780
漠然とした

2006
01:07:36,780 --> 01:07:38,640
声明にすぎません。問題は、

2007
01:07:38,640 --> 01:07:41,280
言語がトールにどの程度貢献しているか、どのように

2008
01:07:41,280 --> 01:07:43,500
貢献していないかということです。

2009
01:07:43,500 --> 01:07:45,839
彼の主張は

2010
01:07:45,839 --> 01:07:48,420
主に進化論的または何か正しいことだと思います。

2011
01:07:48,420 --> 01:07:51,180
これがシステムの起源であり、

2012
01:07:51,180 --> 01:07:52,859


2013
01:07:52,859 --> 01:07:55,559


2014
01:07:55,559 --> 01:07:57,599
患者の種類と

2015
01:07:57,599 --> 01:07:59,520
神経画像データとの二乗は

2016
01:07:59,520 --> 01:08:00,660


2017
01:08:00,660 --> 01:08:04,079
同じように難しいと思いますが、 彼がそう思わないなら、

2018
01:08:04,079 --> 01:08:07,079
彼はそれを言うべきではありません、さもないと人々は彼の言ったこと

2019
01:08:07,079 --> 01:08:08,579
に反応するでしょう.

2020
01:08:08,579 --> 01:08:11,280


2021
01:08:11,280 --> 01:08:13,619


2022
01:08:13,619 --> 01:08:15,420


2023
01:08:15,420 --> 01:08:16,920
思考のいくつかの側面は

2024
01:08:16,920 --> 01:08:19,020
明らかに人間に固有のものですが、

2025
01:08:19,020 --> 01:08:21,000
本質的または因果的にそれに結び付けられているわけではありません.

2026
01:08:21,000 --> 01:08:22,920


2027
01:08:22,920 --> 01:08:24,600
システムのアーキテクチャは、アーキテクチャからのイベントを修辞的に

2028
01:08:24,600 --> 01:08:26,399
表現できる一般化の種類とは大きく異なります。

2029
01:08:26,399 --> 01:08:28,979


2030
01:08:28,979 --> 01:08:30,960
たとえば、失語症から作業を行う場合 あなたが

2031
01:08:30,960 --> 01:08:32,698


2032
01:08:32,698 --> 01:08:33,960


2033
01:08:33,960 --> 01:08:35,759
チェスをするなどと述べたように、患者は複雑な推論に欠陥を示していません。

2034
01:08:35,759 --> 01:08:37,380


2035
01:08:37,380 --> 01:08:39,179


2036
01:08:39,179 --> 01:08:41,160
私が言ったように、

2037
01:08:41,160 --> 01:08:43,799
構文と形式を意味する意味は、

2038
01:08:43,799 --> 01:08:45,600
あなたができることを意味するだけです。 言語を外部化する

2039
01:08:45,600 --> 01:08:46,979
と、これらはすべて

2040
01:08:46,979 --> 01:08:48,540
別個の機能であり、別個のシステムです。

2041
01:08:48,540 --> 01:08:51,000
構文の自律性は、

2042
01:08:51,000 --> 01:08:52,020


2043
01:08:52,020 --> 01:08:53,819
多くの人が考えていることを知っているという意味ではありません。それは

2044
01:08:53,819 --> 01:08:54,719
単に、

2045
01:08:54,719 --> 01:08:56,160


2046
01:08:56,160 --> 01:08:58,439
特定の意味ではない特定の構文操作があることを意味するだけです。

2047
01:08:58,439 --> 01:09:00,299
構文でできることは

2048
01:09:00,299 --> 01:09:01,920
構文しかできず、

2049
01:09:01,920 --> 01:09:03,420
意味論はできないので、意味

2050
01:09:03,420 --> 01:09:05,279


2051
01:09:05,279 --> 01:09:07,259
論は正しくて正しいというペトロフスキーの理論を知っているのと、特定の奇妙な奇妙なことが

2052
01:09:07,259 --> 01:09:10,319


2053
01:09:10,319 --> 01:09:11,698
あるというシンセティシャンの信念を許すという違いに戻ります。

2054
01:09:11,698 --> 01:09:13,080


2055
01:09:13,080 --> 01:09:15,719
単なる構文である構文を使用できるため、

2056
01:09:15,719 --> 01:09:17,759


2057
01:09:17,759 --> 01:09:20,100
アーキテクチャのフレームワークの種類の中でも離婚が存在するため、

2058
01:09:20,100 --> 01:09:22,439


2059
01:09:22,439 --> 01:09:24,359
神経心理学的レベルでも離婚が見られることはそれほど驚くことではありません。

2060
01:09:24,359 --> 01:09:25,979


2061
01:09:25,979 --> 01:09:28,319


2062
01:09:28,319 --> 01:09:30,960
言語の予測は

2063
01:09:30,960 --> 01:09:34,140
進化論的アイデアだと考えられているので、そうで

2064
01:09:34,140 --> 01:09:36,960
ない場合は、

2065
01:09:36,960 --> 01:09:39,060
それが

2066
01:09:39,060 --> 01:09:41,160
言語に依存していると予測しないと言っている場合は、

2067
01:09:41,160 --> 01:09:44,399
ええと、その理論が好きな人は誰でもいくつかの予測を

2068
01:09:44,399 --> 01:09:45,899
考え出す必要があると思います

2069
01:09:45,899 --> 01:09:47,520


2070
01:09:47,520 --> 01:09:49,979
その

2071
01:09:49,979 --> 01:09:51,660
理論が実際に何を意味するのか知っているということは、予測の内容を理解するために、

2072
01:09:51,660 --> 01:09:53,819
この種の予測が

2073
01:09:53,819 --> 01:09:55,440
本当に必要な場合が多いように感じます。

2074
01:09:55,440 --> 01:09:57,360


2075
01:09:57,360 --> 01:09:58,320


2076
01:09:58,320 --> 01:10:00,540


2077
01:10:00,540 --> 01:10:03,660
それはすべて良いことです.ええと、

2078
01:10:03,660 --> 01:10:05,880


2079
01:10:05,880 --> 01:10:08,040


2080
01:10:08,040 --> 01:10:12,660
息を吸い込み、ええと、

2081
01:10:12,660 --> 01:10:15,480
誰かが他の

2082
01:10:15,480 --> 01:10:17,520
質問をする機会を持ちたいと思っていましたが、うわー、

2083
01:10:17,520 --> 01:10:20,460


2084
01:10:20,460 --> 01:10:21,780


2085
01:10:21,780 --> 01:10:22,500


2086
01:10:22,500 --> 01:10:25,199
私たちがカバーした多くのトピックについてお二人に感謝します

2087
01:10:25,199 --> 01:10:27,120
結論と次のステップですが、デイブは

2088
01:10:27,120 --> 01:10:29,820
質問をしたいですか、それとも

2089
01:10:29,820 --> 01:10:32,840
簡単な反省をしたいですか。

2090
01:10:36,900 --> 01:10:38,880
いいえ、

2091
01:10:38,880 --> 01:10:39,960


2092
01:10:39,960 --> 01:10:42,239
チャットにはたくさんのコメントがありますので、お

2093
01:10:42,239 --> 01:10:45,120
二人とも

2094
01:10:45,120 --> 01:10:47,460
自分の時間に読んで、みんながどこに何を

2095
01:10:47,460 --> 01:10:49,440
追加したかを確認できることを願っています

2096
01:10:49,440 --> 01:10:52,860
私たちはここから

2097
01:10:52,860 --> 01:10:57,179
2023 年 5 月に咆哮を上げて進みますか? その先に

2098
01:10:57,179 --> 01:11:00,960
何ができるか 言語学者 大規模な言語モデルの

2099
01:11:00,960 --> 01:11:02,940
開発者とユーザー 認知

2100
01:11:02,940 --> 01:11:05,159
科学者 あなたはそれぞれ、

2101
01:11:05,159 --> 01:11:06,960
最も

2102
01:11:06,960 --> 01:11:08,159


2103
01:11:08,159 --> 01:11:10,080


2104
01:11:10,080 --> 01:11:13,260


2105
01:11:13,260 --> 01:11:14,699
実り多い道は何だと思いますか?

2106
01:11:14,699 --> 01:11:15,600


2107
01:11:15,600 --> 01:11:17,460
認知心理学のように

2108
01:11:17,460 --> 01:11:18,659
真剣に受け止めることです。最近、多くの素晴らしい研究が行われています。

2109
01:11:18,659 --> 01:11:21,000
たとえば、

2110
01:11:21,000 --> 01:11:24,060
教会の EBT ウルフ アルファ

2111
01:11:24,060 --> 01:11:25,739
プラグインから、chat gbt が

2112
01:11:25,739 --> 01:11:28,080
さまざまな種類のモジュールとやり取りできる方法、

2113
01:11:28,080 --> 01:11:30,179
正当なモジュールを構築する方法などを調整しようとしています。

2114
01:11:30,179 --> 01:11:32,580
AGIシステムの種類は、人間が持っている

2115
01:11:32,580 --> 01:11:34,380


2116
01:11:34,380 --> 01:11:35,880
種類のモジュールに心理的に依存していることを必ずしも知っている必要はありませんが、

2117
01:11:35,880 --> 01:11:37,500


2118
01:11:37,500 --> 01:11:38,820
それから恩恵を受けると思います。 いろいろ正しい 好きなもの

2119
01:11:38,820 --> 01:11:41,040


2120
01:11:41,040 --> 01:11:42,540


2121
01:11:42,540 --> 01:11:43,860
すべて ええと、

2122
01:11:43,860 --> 01:11:44,760


2123
01:11:44,760 --> 01:11:46,620
長い目で見れば、

2124
01:11:46,620 --> 01:11:47,880
llms は

2125
01:11:47,880 --> 01:11:49,380
非常に重要で非常に興味深いことを実行できる可能性が最も高いと思いますが、

2126
01:11:49,380 --> 01:11:51,000
それは

2127
01:11:51,000 --> 01:11:53,100
パズルの 1 ピースにすぎないので、実際には

2128
01:11:53,100 --> 01:11:55,440
オープンでさえあります。  AI の CEO である Sam Altman は先週、

2129
01:11:55,440 --> 01:11:56,400


2130
01:11:56,400 --> 01:11:58,440
LLMS でできることは

2131
01:11:58,440 --> 01:12:00,120
本当に使い果たされていることを知っている、

2132
01:12:00,120 --> 01:12:02,520
新しい方向性、新しい新しい新しい道などが必要だと言っ

2133
01:12:02,520 --> 01:12:04,860
た

2134
01:12:04,860 --> 01:12:07,440


2135
01:12:07,440 --> 01:12:09,060
ここに学生がいますが、

2136
01:12:09,060 --> 01:12:11,159
彼も正しいと思いますが、llms が

2137
01:12:11,159 --> 01:12:12,300
素晴らしいことをできることを知っていると思いますが、

2138
01:12:12,300 --> 01:12:14,760
おそらく一般的な AGI アーキテクチャのごく一部を形成するでしょう

2139
01:12:14,760 --> 01:12:17,760


2140
01:12:17,760 --> 01:12:19,679
.AGI を潜在的な潜在的な目標として考えたい場合は、

2141
01:12:19,679 --> 01:12:21,900


2142
01:12:21,900 --> 01:12:25,679
ええと 私は多くのことを考えているので、

2143
01:12:25,679 --> 01:12:28,020
ここで別の例を挙げさせてください。

2144
01:12:28,020 --> 01:12:29,820


2145
01:12:29,820 --> 01:12:31,920
ええと、非常に優れた生産的な

2146
01:12:31,920 --> 01:12:34,140
科学者であるアンナです。

2147
01:12:34,140 --> 01:12:35,400


2148
01:12:35,400 --> 01:12:37,800


2149
01:12:37,800 --> 01:12:39,060
非常に

2150
01:12:39,060 --> 01:12:40,860
認知的にもっともらしい それはまさに

2151
01:12:40,860 --> 01:12:41,880
私たちが推し進めるべきものです

2152
01:12:41,880 --> 01:12:43,679
それはハワード・

2153
01:12:43,679 --> 01:12:45,239
ガードナーのものと互換性があります あなたは複数の知性などの概念を知っています

2154
01:12:45,239 --> 01:12:46,800


2155
01:12:46,800 --> 01:12:48,000
が、同時に、

2156
01:12:48,000 --> 01:12:49,620
このコメントを終了するだけだと思います ええと

2157
01:12:49,620 --> 01:12:51,360
、最後に技術的な話がありました 1週間前

2158
01:12:51,360 --> 01:12:54,840
か数日前に、

2159
01:12:54,840 --> 01:12:56,880
他の多くのものが

2160
01:12:56,880 --> 01:12:59,520
非生産的な方法でAIの誇大宣伝と混同される可能性があるので、

2161
01:12:59,520 --> 01:13:02,100
openaiのGreg Brockmanは、

2162
01:13:02,100 --> 01:13:04,199


2163
01:13:04,199 --> 01:13:06,179
GPDとチャットするさまざまなプラグインを示したこれらの大きなTed Talksの1つを提供しました

2164
01:13:06,179 --> 01:13:08,159
Wolfram が動作することについて言及しましたが、

2165
01:13:08,159 --> 01:13:09,300
画像生成のようなものもあります。

2166
01:13:09,300 --> 01:13:11,820


2167
01:13:11,820 --> 01:13:13,560
チャット TV を購入して物を購入できる instacart ショッピングなどもあります。

2168
01:13:13,560 --> 01:13:15,060


2169
01:13:15,060 --> 01:13:17,040
また、これにより、

2170
01:13:17,040 --> 01:13:18,960
複数のサブシステムが

2171
01:13:18,960 --> 01:13:20,940
異なるサブ機能を実行できるという考えに戻るので、ブロコビッチ

2172
01:13:20,940 --> 01:13:22,620
また、チャット

2173
01:13:22,620 --> 01:13:26,820
GPTにExcelファイル、CSVファイル、および

2174
01:13:26,820 --> 01:13:28,739
学術論文のアーカイブデータベースから提供する例を示しました。

2175
01:13:28,739 --> 01:13:30,060
ここでは、一連の論文

2176
01:13:30,060 --> 01:13:31,739
、次にタイトル、および何が

2177
01:13:31,739 --> 01:13:32,880
正しいかをリストし、

2178
01:13:32,880 --> 01:13:34,500
彼は、chatipatiを使用して知っていると言いました

2179
01:13:34,500 --> 01:13:37,440


2180
01:13:37,440 --> 01:13:39,060
コラムのタイトルが何を

2181
01:13:39,060 --> 01:13:40,860
意味するかを推測するための世界知識

2182
01:13:40,860 --> 01:13:42,780


2183
01:13:42,780 --> 01:13:44,640


2184
01:13:44,640 --> 01:13:47,280


2185
01:13:47,280 --> 01:13:48,840


2186
01:13:48,840 --> 01:13:50,820
TED

2187
01:13:50,820 --> 01:13:52,080
トークでは、聴衆全員が

2188
01:13:52,080 --> 01:13:54,120
スタンディングオベーションをしてくれたことは知っています

2189
01:13:54,120 --> 01:13:56,340
が、Excel ファイルにラベルを記述する機能は

2190
01:13:56,340 --> 01:13:57,900


2191
01:13:57,900 --> 01:14:01,679
素晴らしいと思いますが、

2192
01:14:01,679 --> 01:14:03,120
それを本当に世界の知識と呼ぶかどうかはわかりません。 アントロ

2193
01:14:03,120 --> 01:14:04,800


2194
01:14:04,800 --> 01:14:06,719


2195
01:14:06,719 --> 01:14:08,880
ポモソームの削減と並行して、多くの進歩が必要であり、その

2196
01:14:08,880 --> 01:14:11,640
適切なバランスが取れていると言えます。つまり、心理的に

2197
01:14:11,640 --> 01:14:12,659


2198
01:14:12,659 --> 01:14:13,920


2199
01:14:13,920 --> 01:14:15,360
もっともらしい種類の

2200
01:14:15,360 --> 01:14:17,100
モジュラー アーキテクチャの適切なバランスが必要であると言ったように、あまりにも多くのことはできません。

2201
01:14:17,100 --> 01:14:18,480


2202
01:14:18,480 --> 01:14:19,920
擬人化が多すぎて夢中になってしまうので、

2203
01:14:19,920 --> 01:14:21,540


2204
01:14:21,540 --> 01:14:22,860


2205
01:14:22,860 --> 01:14:25,739
人間のようなモジュラーシステムのモデリングと、信じ

2206
01:14:25,739 --> 01:14:27,780


2207
01:14:27,780 --> 01:14:29,280


2208
01:14:29,280 --> 01:14:31,140
られない、または科学的に

2209
01:14:31,140 --> 01:14:33,679
役に立たないことを少し知っている程度までは、適切なバランスを見つける必要があることを見つける必要があります

2210
01:14:35,040 --> 01:14:37,500
つまり、

2211
01:14:37,500 --> 01:14:40,199


2212
01:14:40,199 --> 01:14:42,739
言語モデルを

2213
01:14:42,739 --> 01:14:45,120
他の形式の

2214
01:14:45,120 --> 01:14:47,640
情報処理に接続するこれらの方法に本当に興奮していることに同意すると思います。ええと、それは人々が持っているもののように思えます。

2215
01:14:47,640 --> 01:14:49,679


2216
01:14:49,679 --> 01:14:52,620


2217
01:14:52,620 --> 01:14:54,840


2218
01:14:54,840 --> 01:14:58,260
言語モデリングと同じように彼らができることに非常に驚いていたので、

2219
01:14:58,260 --> 01:15:00,120
さまざまな種類の推論

2220
01:15:00,120 --> 01:15:01,920
パズルと彼らが解決できることを知っています。

2221
01:15:01,920 --> 01:15:05,340
それは本当に魅力的で、

2222
01:15:05,340 --> 01:15:07,920
おそらくそうなるでしょう。

2223
01:15:07,920 --> 01:15:09,719


2224
01:15:09,719 --> 01:15:11,760
言語と

2225
01:15:11,760 --> 01:15:13,500
思考の関係を再考し、何かが表現を持っている、またはその表現について推論することが何を意味するのかを具体的に説明する方法を見つけようとする必要があります

2226
01:15:13,500 --> 01:15:15,239


2227
01:15:15,239 --> 01:15:17,760


2228
01:15:17,760 --> 01:15:19,380


2229
01:15:19,380 --> 01:15:21,060
が、最終的には

2230
01:15:21,060 --> 01:15:23,820
私は同意すると思います ええと、

2231
01:15:23,820 --> 01:15:26,219
人は物事についてさまざまな考え方を持っていることを知っています。

2232
01:15:26,219 --> 01:15:28,560
それは

2233
01:15:28,560 --> 01:15:32,400
知性にとって重要だと思われます。ええと、

2234
01:15:32,400 --> 01:15:35,040
私は赤ちゃんのLMチャレンジにも非常に興奮しているので、

2235
01:15:35,040 --> 01:15:37,620


2236
01:15:37,620 --> 01:15:39,960
言語的な側面では

2237
01:15:39,960 --> 01:15:42,300
正しいと思います。ええと、まさにそれです より小さなデータセットでどこまで

2238
01:15:42,300 --> 01:15:45,300
到達できるかを確認するのは正しいことです.

2239
01:15:45,300 --> 01:15:47,219
そしておそらく

2240
01:15:47,219 --> 01:15:50,820
最終的には、

2241
01:15:50,820 --> 01:15:53,699


2242
01:15:53,699 --> 01:15:55,739
子供たちが獲得するセマンティクスの種類と、

2243
01:15:55,739 --> 01:15:57,840
どこから、

2244
01:15:57,840 --> 01:15:59,820
どのように取得するかについて、もう少し理解しようとすることを知っています. 外部セマンティクスの種類は、

2245
01:15:59,820 --> 01:16:02,520
言語学習、または

2246
01:16:02,520 --> 01:16:04,560
具体的にはおそらく文法と

2247
01:16:04,560 --> 01:16:06,600
構文の学習に通知できます。

2248
01:16:06,600 --> 01:16:09,480
私のもう 1 つのパスの前進

2249
01:16:09,480 --> 01:16:12,179
ポイントは、

2250
01:16:12,179 --> 01:16:15,840
私のようなものがあると思います。

2251
01:16:15,840 --> 01:16:18,300


2252
01:16:18,300 --> 01:16:21,179


2253
01:16:21,179 --> 01:16:23,340
この種のクラスのモデルに対する人々の期待を超えています

2254
01:16:23,340 --> 01:16:25,500
正しい種類の基礎的な

2255
01:16:25,500 --> 01:16:27,960
統計学習 テキスト

2256
01:16:27,960 --> 01:16:29,940
内のパターンの発見 うーん ええと、

2257
01:16:29,940 --> 01:16:30,719


2258
01:16:30,719 --> 01:16:32,640
非常に驚​​くべき結果をもたらすように思えます えーと、

2259
01:16:32,640 --> 01:16:35,040


2260
01:16:35,040 --> 01:16:37,020
私にとって今後の

2261
01:16:37,020 --> 01:16:39,360
大きな波を導入したと思います

2262
01:16:39,360 --> 01:16:42,000
理論に対する不確実性なので、

2263
01:16:42,000 --> 01:16:43,620
基本

2264
01:16:43,620 --> 01:16:46,739
的に言語のすべての理論は確かにそうですが、

2265
01:16:46,739 --> 01:16:48,960
認知はおそらく神経科学であり、私が考える

2266
01:16:48,960 --> 01:16:50,640
すべてのものと同じように、私たちが

2267
01:16:50,640 --> 01:16:53,100


2268
01:16:53,100 --> 01:16:54,420
実際に

2269
01:16:54,420 --> 01:16:56,219


2270
01:16:56,219 --> 01:16:58,560
その能力を理解するようになったときに作り直されるでしょう。 これらのような本当に一般的な

2271
01:16:58,560 --> 01:17:02,219
種類の学習システムについては、ええと、

2272
01:17:02,219 --> 01:17:03,900
一方

2273
01:17:03,900 --> 01:17:05,820
ではええと、

2274
01:17:05,820 --> 01:17:07,440
過去の

2275
01:17:07,440 --> 01:17:09,360
理論、特にええと、ええと、

2276
01:17:09,360 --> 01:17:11,640


2277
01:17:11,640 --> 01:17:14,100
学習がうまく機能しないことに依存していた理論については、一種の残念なことです。

2278
01:17:14,100 --> 01:17:15,659


2279
01:17:15,659 --> 01:17:18,000
しかし、良い面としては、AI と認知科学、そして言語学の

2280
01:17:18,000 --> 01:17:20,460
両方にとって非常にエキサイティングな時期になっていると思います。

2281
01:17:20,460 --> 01:17:22,620


2282
01:17:22,620 --> 01:17:24,000


2283
01:17:24,000 --> 01:17:25,560
これらの非常

2284
01:17:25,560 --> 01:17:27,420
に強力なツールがあり、

2285
01:17:27,420 --> 01:17:29,719


2286
01:17:29,719 --> 01:17:32,940
人間の能力に向けた質的には異なるサイズのステップのように見えます。

2287
01:17:32,940 --> 01:17:34,620


2288
01:17:34,620 --> 01:17:36,120
そして、それらを統合し、それらがどの

2289
01:17:36,120 --> 01:17:39,060
ように

2290
01:17:39,060 --> 01:17:41,280


2291
01:17:41,280 --> 01:17:43,679


2292
01:17:43,679 --> 01:17:45,540
作られ、どのような原則が

2293
01:17:45,540 --> 01:17:47,460
インテリジェントシステムの設計に組み込まれるかについて、エンジニアリングのレッスンと哲学のレッスンの両方を受講することだと思います。

2294
01:17:47,460 --> 01:17:49,679


2295
01:17:49,679 --> 01:17:52,080
次の5年か10年でフィーリングを本当に形作るでしょう。

2296
01:17:52,080 --> 01:17:53,699


2297
01:17:53,699 --> 01:17:54,900


2298
01:17:54,900 --> 01:17:57,000
また、

2299
01:17:57,000 --> 01:17:58,500
ここでより広いテーマの文脈で言うのと同じように、

2300
01:17:58,500 --> 01:17:59,760
あなたが完全に正しいように、

2301
01:17:59,760 --> 01:18:01,620


2302
01:18:01,620 --> 01:18:04,920
ディープブルーがいつキャスパーになるかについて読んだときに覚えている それは

2303
01:18:04,920 --> 01:18:07,260
チェスのことでしたか?ええと、

2304
01:18:07,260 --> 01:18:08,940
一部のコメンテーターは、

2305
01:18:08,940 --> 01:18:12,480
AIが人間になることができればチェスは終わったことを知っていると言っていました。チェスを勉強する

2306
01:18:12,480 --> 01:18:13,739
意味はゲームオーバーです。

2307
01:18:13,739 --> 01:18:15,420


2308
01:18:15,420 --> 01:18:16,920
もう退屈する必要はありません。

2309
01:18:16,920 --> 01:18:18,900


2310
01:18:18,900 --> 01:18:20,640
人間がチェスをプレイするために必要なすべてのことを AI が達成したとしたら、

2311
01:18:20,640 --> 01:18:22,140


2312
01:18:22,140 --> 01:18:23,100
それをプレイする意味は

2313
01:18:23,100 --> 01:18:24,540
何なのかと思いますが、チェス

2314
01:18:24,540 --> 01:18:26,219
の人気を高めることが判明したかどうかはご存知だと思いますが、

2315
01:18:26,219 --> 01:18:27,900
彼らは私たちの小さなチェスの

2316
01:18:27,900 --> 01:18:29,580
有名人だけでなく、世界的な

2317
01:18:29,580 --> 01:18:31,199
トーナメントにも参加しています。 そして私は、

2318
01:18:31,199 --> 01:18:32,520
同じことがおそらく言語でも起こるだろうと予測します

2319
01:18:32,520 --> 01:18:34,620
.llmsは

2320
01:18:34,620 --> 01:18:36,360
それが言語の終わりであることを意味するものではありません言語はもはや言語ではありません.

2321
01:18:36,360 --> 01:18:37,800


2322
01:18:37,800 --> 01:18:39,179


2323
01:18:39,179 --> 01:18:40,620


2324
01:18:40,620 --> 01:18:42,540
LMS は

2325
01:18:42,540 --> 01:18:44,400
言語理論への一般的な関心を高めます。

2326
01:18:44,400 --> 01:18:46,199
それらのペアリングにより、

2327
01:18:46,199 --> 01:18:48,060
奇妙な制約と明らかな

2328
01:18:48,060 --> 01:18:50,100
制限を知っています。なぜなら、

2329
01:18:50,100 --> 01:18:52,380
この時点でスケールを知っているとも言えるからです。

2330
01:18:52,380 --> 01:18:55,500
ストレスの問題のスケールは、

2331
01:18:55,500 --> 01:18:57,420
必要なものすべてとはかけ離れています。

2332
01:18:57,420 --> 01:18:59,820
不足しているのは あなたが知っているように、LMSの能力は、

2333
01:18:59,820 --> 01:19:01,260


2334
01:19:01,260 --> 01:19:03,239
グループウォッシュの予測と一般化などを行うために、彼らの知識と経験を

2335
01:19:03,239 --> 01:19:04,739


2336
01:19:04,739 --> 01:19:06,780


2337
01:19:06,780 --> 01:19:07,860


2338
01:19:07,860 --> 01:19:09,179
本当に抽象化する.

2339
01:19:09,179 --> 01:19:10,739
たぶん

2340
01:19:10,739 --> 01:19:13,620
特定のトークンタイプに行きますが、

2341
01:19:13,620 --> 01:19:15,060
私の最後の

2342
01:19:15,060 --> 01:19:17,100
主張は、

2343
01:19:17,100 --> 01:19:19,080


2344
01:19:19,080 --> 01:19:21,480


2345
01:19:21,480 --> 01:19:22,860
認知科学者が

2346
01:19:22,860 --> 01:19:26,219
潜在的にLLmsを必要としないことを知っていますが、言語習得文献が必ずしもllmsを必要としないことを知っているということです。 ええと、

2347
01:19:26,219 --> 01:19:27,420
あなたは復活を知っており、ここで明らかに

2348
01:19:27,420 --> 01:19:29,640
反対していますが、ええと、

2349
01:19:29,640 --> 01:19:32,040
LLMSで利益を上げている大規模なテクノロジー企業はLLMSを必要としていると思います.彼ら

2350
01:19:32,040 --> 01:19:33,360
だけが

2351
01:19:33,360 --> 01:19:35,100
実際にそうしているのかもしれません.

2352
01:19:35,100 --> 01:19:37,320


2353
01:19:37,320 --> 01:19:39,000
非常に多様な空間では、LLMS が行っていることと同様のプロセスによって捉えられる

2354
01:19:39,000 --> 01:19:40,560
特定の形態の行動

2355
01:19:40,560 --> 01:19:42,420
と学習が存在する可能性があるため、

2356
01:19:42,420 --> 01:19:44,219


2357
01:19:44,219 --> 01:19:45,540
スティーブンは

2358
01:19:45,540 --> 01:19:47,159
磁気

2359
01:19:47,159 --> 01:19:49,320
と奇妙な種類の学習規則に関する論文でいくつかの興味深い例を挙げています。

2360
01:19:49,320 --> 01:19:51,060
非常にドメイン一般的で非常に

2361
01:19:51,060 --> 01:19:52,920
迅速で非常に神秘的であるため、

2362
01:19:52,920 --> 01:19:54,780
おそらく

2363
01:19:54,780 --> 01:19:56,100
そのような種類の学習が

2364
01:19:56,100 --> 01:19:57,780
関連することはわかっていますが、

2365
01:19:57,780 --> 01:19:59,580
候補の1つが

2366
01:19:59,580 --> 01:20:02,100
自然言語であり、少なくとも

2367
01:20:02,100 --> 01:20:03,480
自然な方法である可能性は低いと思います. 言語は機能し、

2368
01:20:03,480 --> 01:20:05,219
主に

2369
01:20:05,219 --> 01:20:07,380
規制と何を持っているかという点で完全な栄光です。だから、あなたが知っている場所を

2370
01:20:07,380 --> 01:20:09,300
思い出させてくれると思います。

2371
01:20:09,300 --> 01:20:11,520


2372
01:20:11,520 --> 01:20:13,320
私はジョン・ウィックの第4章を

2373
01:20:13,320 --> 01:20:14,940
最近見ました。彼は これは、

2374
01:20:14,940 --> 01:20:16,140
彼が砂漠を歩いているこのシーンで

2375
01:20:16,140 --> 01:20:17,580
、彼は

2376
01:20:17,580 --> 01:20:19,260
この男を暗殺したがっているのを見たことがあるかどうか確信が持てません。それは

2377
01:20:19,260 --> 01:20:21,540


2378
01:20:21,540 --> 01:20:22,739
砂漠を歩いているときのようなもので、

2379
01:20:22,739 --> 01:20:24,840
ええと、オアシスを見ているような錯覚を起こします

2380
01:20:24,840 --> 01:20:26,460
。

2381
01:20:26,460 --> 01:20:28,199
幻覚を見ているが、

2382
01:20:28,199 --> 01:20:29,820
手遅れになる前に、実際に幻覚を起こしていることを時々知っていることに気付く.

2383
01:20:29,820 --> 01:20:31,679


2384
01:20:31,679 --> 01:20:33,239
オアシスを見ているのではなく、まだ

2385
01:20:33,239 --> 01:20:35,040
砂漠にいる.

2386
01:20:35,040 --> 01:20:37,199
おそらくそれが私たちが今いる状況だと思う.

2387
01:20:37,199 --> 01:20:39,360
多くの言語モデルの言語能力により、

2388
01:20:39,360 --> 01:20:41,400
私たちは言語能力の錯覚を持っています。

2389
01:20:41,400 --> 01:20:44,940


2390
01:20:44,940 --> 01:20:46,260


2391
01:20:46,260 --> 01:20:48,360
オアシスが正しいことを見つける前に、常に錯覚を見るので、私たちは

2392
01:20:48,360 --> 01:20:49,440
今、

2393
01:20:49,440 --> 01:20:51,420
砂漠の幻覚状態にあると思います.

2394
01:20:51,420 --> 01:20:53,699
「言語能力の潜在的なスパークが見られます

2395
01:20:53,699 --> 01:20:55,380
が、それはまだ

2396
01:20:55,380 --> 01:20:57,420
あまり明確ではなく、堅牢ではありません。実際には

2397
01:20:57,420 --> 01:20:59,640
オアシスに到達していません。

2398
01:20:59,640 --> 01:21:02,480


2399
01:21:02,820 --> 01:21:06,360
ええと、ただの矢継ぎ早の質問です。短い応答を与えることができるかどうかを確認してください。

2400
01:21:06,360 --> 01:21:09,540


2401
01:21:09,540 --> 01:21:11,219


2402
01:21:11,219 --> 01:21:13,440


2403
01:21:13,440 --> 01:21:15,120
大規模な言語モデルには

2404
01:21:15,120 --> 01:21:17,540
事前

2405
01:21:18,480 --> 01:21:21,300
確率がないと言うこと 大規模な言語モデルには事前

2406
01:21:21,300 --> 01:21:23,820
確率がありますか はい、彼らは間違いなくそうします

2407
01:21:23,820 --> 01:21:25,620
ええと、

2408
01:21:25,620 --> 01:21:28,440
ええと、

2409
01:21:28,440 --> 01:21:30,360
あなたが知っている人々が事前確率についての考え方やベイジアン推論に慣れている方法との違いだと思います

2410
01:21:30,360 --> 01:21:32,340


2411
01:21:32,340 --> 01:21:33,840
たとえば、

2412
01:21:33,840 --> 01:21:36,300
ベイジアン統計モデルを書き留めるのが好きなら、あなたは知っているように言います。

2413
01:21:36,300 --> 01:21:37,860
ここにパラメーターがあり、これが

2414
01:21:37,860 --> 01:21:39,300


2415
01:21:39,300 --> 01:21:40,860


2416
01:21:40,860 --> 01:21:42,360


2417
01:21:42,360 --> 01:21:44,340
パラメーターの事前確率です。

2418
01:21:44,340 --> 01:21:45,900
ええと、大きな言語モデルです。

2419
01:21:45,900 --> 01:21:47,880
事前確率ははるかに暗黙的な権利なので、

2420
01:21:47,880 --> 01:21:49,679


2421
01:21:49,679 --> 01:21:52,080
他の関数よりも簡単に習得できる関数がいくつかあり

2422
01:21:52,080 --> 01:21:53,760
、

2423
01:21:53,760 --> 01:21:55,860


2424
01:21:55,860 --> 01:21:57,540
そのような暗黙の

2425
01:21:57,540 --> 01:21:59,040
事前確率が何であるかについてのステートメントを知っていることを発見しようとする作業さえあります

2426
01:21:59,040 --> 01:22:00,840
が、それが実際に私が考える方法です

2427
01:22:00,840 --> 01:22:02,040


2428
01:22:02,040 --> 01:22:02,940
ええと、

2429
01:22:02,940 --> 01:22:04,620
さまざまな

2430
01:22:04,620 --> 01:22:07,199
ニューラル ネットワーク アーキテクチャの比較についてはご存知でしょう。

2431
01:22:07,199 --> 01:22:09,060
ええと、これはおそらく大喜びするものであり、

2432
01:22:09,060 --> 01:22:10,500


2433
01:22:10,500 --> 01:22:12,600


2434
01:22:12,600 --> 01:22:14,400
子供たちが正しく学ぶことを彼らが学べるようにする前例を見つけなければ

2435
01:22:14,400 --> 01:22:16,140


2436
01:22:16,140 --> 01:22:19,080
ならないのと同じように、同意するかもしれません。ええと、すべてのアーキテクチャがそうするわけではありません それを行うのは、

2437
01:22:19,080 --> 01:22:21,360


2438
01:22:21,360 --> 01:22:23,280
完全になりつつある、または

2439
01:22:23,280 --> 01:22:24,719
あらゆる種類の機能を学習できるアーキテクチャの間でさえ、それらのすべてがそれを行うわけではありません。

2440
01:22:24,719 --> 01:22:27,540


2441
01:22:27,540 --> 01:22:30,000


2442
01:22:30,000 --> 01:22:31,800


2443
01:22:31,800 --> 01:22:34,080
実際には、

2444
01:22:34,080 --> 01:22:36,360
事前確率に対する検索の 1 つです

2445
01:22:36,360 --> 01:22:38,580
が、それは

2446
01:22:38,580 --> 01:22:39,719


2447
01:22:39,719 --> 01:22:41,699


2448
01:22:41,699 --> 01:22:44,340
事前確率ではありません。つまり、普遍文法または何か正しいものに対する検索と考えることができますが、人々がそれについて次のように話しているという意味では、それは事前確率または普遍

2449
01:22:44,340 --> 01:22:46,560
文法ではありません。

2450
01:22:46,560 --> 01:22:48,540


2451
01:22:48,540 --> 01:22:50,159
どのような種類のルールが

2452
01:22:50,159 --> 01:22:51,780
許可されているかについての明示的なステートメント、または

2453
01:22:51,780 --> 01:22:53,880
どのような関数が高

2454
01:22:53,880 --> 01:22:55,320
確率であるかについての明示的なステートメント、またはそのようなものはすべてそこ

2455
01:22:55,320 --> 01:22:57,360
に

2456
01:22:57,360 --> 01:22:58,560


2457
01:22:58,560 --> 01:23:00,540
暗黙のうちにコード

2458
01:23:00,540 --> 01:23:02,880
化されています。

2459
01:23:02,880 --> 01:23:05,100
同じように賞賛するものの空間、そしてそれが

2460
01:23:05,100 --> 01:23:07,020
人間が

2461
01:23:07,020 --> 01:23:09,300
していることのように遠く離れたものであれば、私は

2462
01:23:09,300 --> 01:23:11,219
少なくとも、qpt3のようなものが

2463
01:23:11,219 --> 01:23:13,380
存在する証拠であると言うでしょう.

2464
01:23:13,380 --> 01:23:15,960


2465
01:23:15,960 --> 01:23:18,000
表面分布分析から完全に機能する構文カテゴリを構築する

2466
01:23:18,000 --> 01:23:21,420
これだけでも可能です

2467
01:23:21,420 --> 01:23:24,120
はい、それは正しいですが、

2468
01:23:24,120 --> 01:23:27,300
ほとんどの実践者は

2469
01:23:27,300 --> 01:23:29,460
構文カテゴリが

2470
01:23:29,460 --> 01:23:31,380
生得的であるとは本当に信じていないので、前の問題は

2471
01:23:31,380 --> 01:23:33,060
ここではあまり関係がありません。

2472
01:23:33,060 --> 01:23:35,219
生得的であると設定されている操作なので、

2473
01:23:35,219 --> 01:23:37,500
構文ドメインは、特定の

2474
01:23:37,500 --> 01:23:39,659
言語計算であり、

2475
01:23:39,659 --> 01:23:41,159
カテゴリ自体に含まれていると言われています。

2476
01:23:41,159 --> 01:23:42,719
実際、チャールズ・ヤン・

2477
01:23:42,719 --> 01:23:44,100
ウムでさえ、ここ数年、

2478
01:23:44,100 --> 01:23:46,800
それらが含まれている可能性があることを認めていますが、そうではない可能性があるため、

2479
01:23:46,800 --> 01:23:49,679
人々は別の

2480
01:23:49,679 --> 01:23:51,540
関連する優先順位を与えています。 ご存知のように、

2481
01:23:51,540 --> 01:23:53,100
私とゲイリー・マーケットは

2482
01:23:53,100 --> 01:23:55,080
構成性について話しましたが、それは

2483
01:23:55,080 --> 01:23:56,640
大きな問題であると思われるので、人々は

2484
01:23:56,640 --> 01:23:59,520
それを

2485
01:23:59,520 --> 01:24:02,280
圧縮してから再説明するように求めるチャットを BBC ニュースの記事で行いました。

2486
01:24:02,280 --> 01:24:04,920


2487
01:24:04,920 --> 01:24:06,480


2488
01:24:06,480 --> 01:24:09,060
過失致死罪で逮捕され、

2489
01:24:09,060 --> 01:24:10,920
それを圧縮して再説明すると、

2490
01:24:10,920 --> 01:24:12,420
58人が過失

2491
01:24:12,420 --> 01:24:14,040
致死罪で起訴されていることが明らかになりました。これは、それが行っている圧縮に組み込まれている構成性の欠如のかなり明確な例です。

2492
01:24:14,040 --> 01:24:15,659


2493
01:24:15,659 --> 01:24:17,219


2494
01:24:17,219 --> 01:24:19,260
別の例

2495
01:24:19,260 --> 01:24:20,940
では、

2496
01:24:20,940 --> 01:24:23,159
潜在的なアナロジー推論の例がいくつかあるので、

2497
01:24:23,159 --> 01:24:24,840
Bing チャットでは、Bing がこのトラップ機能を持っていることを知っています。

2498
01:24:24,840 --> 01:24:26,100


2499
01:24:26,100 --> 01:24:28,080
問題は、

2500
01:24:28,080 --> 01:24:29,460


2501
01:24:29,460 --> 01:24:31,080
人間によって既に文書化されているメタ関係を見つけるだけなのか、それとも

2502
01:24:31,080 --> 01:24:33,420
新しい関係を本当に作成しているのかということです。

2503
01:24:33,420 --> 01:24:35,100


2504
01:24:35,100 --> 01:24:38,520
誰かが私に

2505
01:24:38,520 --> 01:24:41,760
イエス・キリストとNokia 9910を比較した表を描いてくれました。

2506
01:24:41,760 --> 01:24:44,640
携帯電話Nokia

2507
01:24:44,640 --> 01:24:46,080
9910

2508
01:24:46,080 --> 01:24:47,520
ええと、それはあなたが知っていると言いました.

2509
01:24:47,520 --> 01:24:49,860
それはサイズと

2510
01:24:49,860 --> 01:24:53,280
重量を比較しました.

2511
01:24:53,280 --> 01:24:55,140
イエスの全能の知識は、

2512
01:24:55,140 --> 01:24:57,600
電話の記憶を神の全知の性質と比較しました.

2513
01:24:57,600 --> 01:25:00,600


2514
01:25:00,600 --> 01:25:02,760
ええと、

2515
01:25:02,760 --> 01:25:04,560
Nokiaが

2516
01:25:04,560 --> 01:25:06,239
数回再リリースされたため、両方とも復活したと言ったと思います.Nokiaは

2517
01:25:06,239 --> 01:25:08,159
素晴らしい答え

2518
01:25:08,159 --> 01:25:10,560
何が問題なのですか 大丈夫です 多分それは

2519
01:25:10,560 --> 01:25:12,120


2520
01:25:12,120 --> 01:25:13,860
類推的な推論のように聞こえるかもしれ

2521
01:25:13,860 --> 01:25:15,420
ませんが、カメラについて知っているような非常に奇妙なものもいくつかありました

2522
01:25:15,420 --> 01:25:17,100


2523
01:25:17,100 --> 01:25:19,679
イエスの説明をしただけか、

2524
01:25:19,679 --> 01:25:21,659
実際にはそうではありません カメラは

2525
01:25:21,659 --> 01:25:24,000
類推的な推論のように見えるものがあるかもしれませんが、それは

2526
01:25:24,000 --> 01:25:27,860
不明ですええ、

2527
01:25:27,860 --> 01:25:31,440
それは私にとって素晴らしい答えのように聞こえると思います

2528
01:25:31,440 --> 01:25:33,020


2529
01:25:33,020 --> 01:25:36,360
私はあなたが言ったように、

2530
01:25:36,360 --> 01:25:38,100
大きな言語モデルは

2531
01:25:38,100 --> 01:25:39,719
品詞の存在証明を学ぶと言っていました

2532
01:25:39,719 --> 01:25:41,520
カテゴリですが、

2533
01:25:41,520 --> 01:25:43,380
品詞のカテゴリを出力するだけでなく、

2534
01:25:43,380 --> 01:25:45,719
文法的な

2535
01:25:45,719 --> 01:25:47,640
構文の知識が豊富で、

2536
01:25:47,640 --> 01:25:50,880
さらに、意味の

2537
01:25:50,880 --> 01:25:52,980
知識とおそらくいくつかの

2538
01:25:52,980 --> 01:25:55,080
実用的な知識があり、

2539
01:25:55,080 --> 01:25:58,080
それらが 翻訳は悪くないです。

2540
01:25:58,080 --> 01:25:59,880
彼らが

2541
01:25:59,880 --> 01:26:01,139
発見したのは、

2542
01:26:01,139 --> 01:26:03,840
品詞のカテゴリだけではありません.

2543
01:26:03,840 --> 01:26:07,020
ええと、申し訳ありませんが、

2544
01:26:07,020 --> 01:26:08,940
それは技術的なカテゴリです. それ以上にええと、ええと、

2545
01:26:08,940 --> 01:26:11,040


2546
01:26:11,040 --> 01:26:13,080


2547
01:26:13,080 --> 01:26:13,980


2548
01:26:13,980 --> 01:26:15,600
ええと、

2549
01:26:15,600 --> 01:26:18,780
お誘いのスラッシュの動機として、

2550
01:26:18,780 --> 01:26:20,699


2551
01:26:20,699 --> 01:26:23,040
将来、

2552
01:26:23,040 --> 01:26:24,540
他のゲストの有無にかかわらず、お二人が再び参加することを願っています.このトランスクリプトに含める

2553
01:26:24,540 --> 01:26:26,520
ためだけにいくつかのエキサイティングな質問と

2554
01:26:26,520 --> 01:26:28,679
次に、

2555
01:26:28,679 --> 01:26:30,060


2556
01:26:30,060 --> 01:26:31,260
参加してくれたエリーとスティーブンの両方に感謝します。

2557
01:26:31,260 --> 01:26:33,719
フアンは、

2558
01:26:33,719 --> 01:26:35,820


2559
01:26:35,820 --> 01:26:38,580
言語を学習している子供たちと比較して、2020年に小さなトランスフォーマーがどのようにジャンクするかを尋ねました。ええと、

2560
01:26:38,580 --> 01:26:40,860
96は、暗黙の事前確率と動物の本能についてどう思いますか。

2561
01:26:40,860 --> 01:26:42,800


2562
01:26:42,800 --> 01:26:45,780
ロイダは尋ねました。  llms のどのような制約が

2563
01:26:45,780 --> 01:26:48,420
トレーニングによってそこに到達しない

2564
01:26:48,420 --> 01:26:50,699
ので、最初に実装するものではないことを発見しているのかもしれません。

2565
01:26:50,699 --> 01:26:52,500


2566
01:26:52,500 --> 01:26:54,780
さらに多くの質問があるので、

2567
01:26:54,780 --> 01:26:57,540


2568
01:26:57,540 --> 01:27:00,600
お互いの作品を見直して再読できることを願っています。

2569
01:27:00,600 --> 01:27:04,020
いつか 41.2 に集まろう

2570
01:27:04,020 --> 01:27:06,060
エリオットとスティーブンに感謝します この

2571
01:27:06,060 --> 01:27:08,280
素晴らしいストリームをありがとう デイブに感謝します

2572
01:27:08,280 --> 01:27:10,739


2573
01:27:10,739 --> 01:27:15,379


