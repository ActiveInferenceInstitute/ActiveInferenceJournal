1
00:00:05,759 --> 00:00:08,400
大家好，歡迎大家來到 Octave

2
00:00:08,400 --> 00:00:10,860
Inference Institute，這是

3
00:00:10,860 --> 00:00:15,839
2023 年 4 月 25 日的第 41.1 號活躍訪客流，

4
00:00:15,839 --> 00:00:18,480
我們與 Elliot Murphy 和

5
00:00:18,480 --> 00:00:20,939
Stephen piantadosi 一起來到這裡，這將是

6
00:00:20,939 --> 00:00:23,039
一場相當大的討論，我們將從

7
00:00:23,039 --> 00:00:24,779
Stephen 和

8
00:00:24,779 --> 00:00:27,359
Elliot 的開場白開始 Elliott 將 然後提出一些

9
00:00:27,359 --> 00:00:28,920
問題，最後我們將進行公開

10
00:00:28,920 --> 00:00:32,759
討論所以史蒂文，請

11
00:00:32,759 --> 00:00:34,739
感謝您的加入，並感謝您的

12
00:00:34,739 --> 00:00:36,960
開場白，

13
00:00:36,960 --> 00:00:39,780
嗨，我是史蒂夫·皮安塔多西，我是

14
00:00:39,780 --> 00:00:42,239


15
00:00:42,239 --> 00:00:44,700
加州大學伯克利分校的心理學和神經科學教授，

16
00:00:44,700 --> 00:00:46,860
嗯， 呃，我想

17
00:00:46,860 --> 00:00:48,899
我們來這裡的部分原因是我最近寫了

18
00:00:48,899 --> 00:00:51,719
一篇關於大型語言模型的論文，

19
00:00:51,719 --> 00:00:53,940
部分是為了表達

20
00:00:53,940 --> 00:00:55,199
對

21
00:00:55,199 --> 00:00:57,300
他們在

22
00:00:57,300 --> 00:00:59,100
學習語法和

23
00:00:59,100 --> 00:01:00,719
語義方面取得的成就的熱情。

24
00:01:00,719 --> 00:01:03,059
在某種程度上指出，我認為

25
00:01:03,059 --> 00:01:04,979
這些模型確實改變了我們

26
00:01:04,979 --> 00:01:06,780
應該如何思考語言，

27
00:01:06,780 --> 00:01:08,520
嗯，我們應該如何思考

28
00:01:08,520 --> 00:01:11,939
語言表徵理論和呃

29
00:01:11,939 --> 00:01:13,560
語法理論，嗯，

30
00:01:13,560 --> 00:01:17,220
可能還有學習理論

31
00:01:17,220 --> 00:01:19,080


32
00:01:19,080 --> 00:01:21,960
meffee 我是

33
00:01:21,960 --> 00:01:23,040


34
00:01:23,040 --> 00:01:25,799
得克薩斯州 UT Health 神經外科系的博士後，

35
00:01:25,799 --> 00:01:27,240
嗯，我非常感興趣地閱讀了 Steven 的論文，

36
00:01:27,240 --> 00:01:29,759
我讀了很多人，

37
00:01:29,759 --> 00:01:31,619
有一些趨同的領域，但

38
00:01:31,619 --> 00:01:32,820
我今天想關注的是

39
00:01:32,820 --> 00:01:34,979
回應 Stephen 並嘗試與 Divergence

40
00:01:34,979 --> 00:01:36,600
領域做一些事情，

41
00:01:36,600 --> 00:01:38,640


42
00:01:38,640 --> 00:01:41,700
嗯，所以你知道 Steven 的論文是

43
00:01:41,700 --> 00:01:43,619
基於這樣的想法，即現代機器學習

44
00:01:43,619 --> 00:01:46,220
已經顛覆並繞過了

45
00:01:46,220 --> 00:01:48,119
喬姆斯基方法的整個理論框架，

46
00:01:48,119 --> 00:01:49,860
所以我想回應

47
00:01:49,860 --> 00:01:51,479
一些 這些主要論點和

48
00:01:51,479 --> 00:01:52,560
文獻中的其他一些相關論點，

49
00:01:52,560 --> 00:01:54,060
嗯，有些人在

50
00:01:54,060 --> 00:01:55,799
聽可能有一些見解

51
00:01:55,799 --> 00:01:58,500
和想法，所以這是一個非常普遍的

52
00:01:58,500 --> 00:02:00,720
批評，說大型語言

53
00:02:00,720 --> 00:02:03,180
模型只是預測下一個標記，而

54
00:02:03,180 --> 00:02:04,079


55
00:02:04,079 --> 00:02:05,579
這顯然有點 陳詞濫調是對的，

56
00:02:05,579 --> 00:02:07,619
嗯，不太正確，他們

57
00:02:07,619 --> 00:02:09,419
不只是預測下一個標記，他們似乎

58
00:02:09,419 --> 00:02:11,700
也在虛構他們似乎產生

59
00:02:11,700 --> 00:02:14,340
幻覺，他們可能在撒謊，他們隨機地

60
00:02:14,340 --> 00:02:16,440
對同一個問題提供不同的答案，

61
00:02:16,440 --> 00:02:18,300
而且他們似乎

62
00:02:18,300 --> 00:02:20,220
隨機模仿類似語言的

63
00:02:20,220 --> 00:02:22,020
結構他們

64
00:02:22,020 --> 00:02:23,819
有時他們不應該糾正自己，

65
00:02:23,819 --> 00:02:25,440
如果你稍微推動他們，

66
00:02:25,440 --> 00:02:27,000


67
00:02:27,000 --> 00:02:28,560


68
00:02:28,560 --> 00:02:30,060


69
00:02:30,060 --> 00:02:31,800
他們有時會改變主意

70
00:02:31,800 --> 00:02:33,680


71
00:02:33,680 --> 00:02:36,120
他們正在尋找一種您

72
00:02:36,120 --> 00:02:38,040
知道的類似口徑，因此這些模型

73
00:02:38,040 --> 00:02:40,620
似乎可以做各種瘋狂的事情，

74
00:02:40,620 --> 00:02:41,940
嗯，在過去的 10 年中，已經

75
00:02:41,940 --> 00:02:43,500


76
00:02:43,500 --> 00:02:45,900
開發出一系列不同的系統，就像我們是煙草床一樣，

77
00:02:45,900 --> 00:02:47,580
它們中的每一個都是 基於不同的

78
00:02:47,580 --> 00:02:49,620
神經網絡方法但最終它們

79
00:02:49,620 --> 00:02:51,180
似乎都採用單詞並

80
00:02:51,180 --> 00:02:53,220
通過數百或

81
00:02:53,220 --> 00:02:56,220
數千個數字列表來表徵它們，因此 G23 網絡

82
00:02:56,220 --> 00:03:00,000


83
00:03:00,000 --> 00:03:02,160
在其架構中具有 1750 億個權重和 96 個注意力頭，

84
00:03:02,160 --> 00:03:03,780
據我所知 史蒂文可以

85
00:03:03,780 --> 00:03:06,060
在這裡糾正我，我們真的不太清楚

86
00:03:06,060 --> 00:03:07,319
這些不同部分的

87
00:03:07,319 --> 00:03:09,180
真正含義它只是看起來

88
00:03:09,180 --> 00:03:10,920
像注意力頭一樣工作，

89
00:03:10,920 --> 00:03:13,680
gpt3 可以關注

90
00:03:13,680 --> 00:03:15,360
字符串中更早的標記以提供幫助

91
00:03:15,360 --> 00:03:17,040
他們預測下一個標記，但

92
00:03:17,040 --> 00:03:18,659
整個架構從頭到尾

93
00:03:18,659 --> 00:03:21,599
都是基於工程的動機，

94
00:03:21,599 --> 00:03:22,500


95
00:03:22,500 --> 00:03:24,659
嗯，我總是想知道

96
00:03:24,659 --> 00:03:27,360


97
00:03:27,360 --> 00:03:28,800
來自不同科技公司的這些 llms 的所有模型都失敗了，

98
00:03:28,800 --> 00:03:30,300
就像這些公司

99
00:03:30,300 --> 00:03:31,980
經常出現的那樣

100
00:03:31,980 --> 00:03:33,060
嗯，你知道，讓他們看起來好像擁有

101
00:03:33,060 --> 00:03:34,980
這些模型，開箱即用，效果

102
00:03:34,980 --> 00:03:36,720


103
00:03:36,720 --> 00:03:38,459


104
00:03:38,459 --> 00:03:40,739


105
00:03:40,739 --> 00:03:42,780


106
00:03:42,780 --> 00:03:45,360
很好 很快，其中一家

107
00:03:45,360 --> 00:03:46,980
公司將發布一個大型

108
00:03:46,980 --> 00:03:49,500
語言模型，呃，叫做 Jesus 或其他

109
00:03:49,500 --> 00:03:50,879
我不知道的東西，

110
00:03:50,879 --> 00:03:53,040
嗯，但他們總是說這是我們的

111
00:03:53,040 --> 00:03:54,900
新基礎模型，它叫做 Picasso，

112
00:03:54,900 --> 00:03:56,280
這是我們嘗試的第一個模型，我們很棒，

113
00:03:56,280 --> 00:03:58,140
沒有問題 開箱即用，

114
00:03:58,140 --> 00:03:59,819
但我總是想知道

115
00:03:59,819 --> 00:04:01,680
Oliver Black boxes

116
00:04:01,680 --> 00:04:03,659
每次都失敗了，似乎沒有

117
00:04:03,659 --> 00:04:05,760
一種非常開放和清晰的

118
00:04:05,760 --> 00:04:07,379
結構來

119
00:04:07,379 --> 00:04:09,840
選擇你知道的一種

120
00:04:09,840 --> 00:04:11,939
或另一種模型背後的科學推理 呃，但我可能會再次接受

121
00:04:11,939 --> 00:04:14,280
糾正，

122
00:04:14,280 --> 00:04:16,798
嗯，所以即使是基本的語言模型也能

123
00:04:16,798 --> 00:04:18,298


124
00:04:18,298 --> 00:04:20,699
像基本的網絡預測一樣在嗯上做得很好，所以

125
00:04:20,699 --> 00:04:22,139
問題是這些工具是否提供了

126
00:04:22,139 --> 00:04:23,520
對傳統

127
00:04:23,520 --> 00:04:25,320
心理語言學概念（如語法

128
00:04:25,320 --> 00:04:27,300
和傳遞）的洞察力所以 這就是為什麼我

129
00:04:27,300 --> 00:04:29,040
更喜歡 10 Focus 模型而不是

130
00:04:29,040 --> 00:04:30,960


131
00:04:30,960 --> 00:04:32,880
像 cyberveras 這樣的人建議的語言模型，

132
00:04:32,880 --> 00:04:34,560
所以有人指出，當他們將 python 代碼和自然語言一樣好時，沒有人

133
00:04:34,560 --> 00:04:36,479
真正認為 llms 告訴我們任何

134
00:04:36,479 --> 00:04:38,580
關於 python 的深刻知識

135
00:04:38,580 --> 00:04:40,080


136
00:04:40,080 --> 00:04:42,120
python 是一種

137
00:04:42,120 --> 00:04:43,740
具有短語結構語法的符號語言

138
00:04:43,740 --> 00:04:46,620
，沒有人說 llms 正在揭開

139
00:04:46,620 --> 00:04:48,600
python 的秘密，所以只是

140
00:04:48,600 --> 00:04:50,940
在這裡放各種，他說如果 n 個模型可以

141
00:04:50,940 --> 00:04:52,620


142
00:04:52,620 --> 00:04:54,000
基於它們

143
00:04:54,000 --> 00:04:56,040
在語言任務上的成功被解釋為自然語言的解釋性理論，那麼在

144
00:04:56,040 --> 00:04:57,540
沒有反駁論點，它們也應該

145
00:04:57,540 --> 00:04:58,919
是計算機語言的良好解釋理論，

146
00:04:58,919 --> 00:05:01,139
呃，因此，

147
00:05:01,139 --> 00:05:02,699
成功的自然

148
00:05:02,699 --> 00:05:04,620
語言模型不能用作

149
00:05:04,620 --> 00:05:06,540
反對亞馬遜語言生成短語結構的證據，

150
00:05:06,540 --> 00:05:07,800


151
00:05:07,800 --> 00:05:09,720
所以語料庫模型確實是一個更

152
00:05:09,720 --> 00:05:11,280
合適的術語，出於其他原因，

153
00:05:11,280 --> 00:05:13,500
人們 像 Emily bender 和其他一些人

154
00:05:13,500 --> 00:05:15,300
已經表明訓練語料庫的特徵

155
00:05:15,300 --> 00:05:16,979
事實上我認為斯蒂芬引用了

156
00:05:16,979 --> 00:05:17,940
你在你的論文中引用這個

157
00:05:17,940 --> 00:05:19,860
實際上作為限制

158
00:05:19,860 --> 00:05:21,120
嗯他們表明

159
00:05:21,120 --> 00:05:22,680
訓練語料庫的特徵可以嚴重影響

160
00:05:22,680 --> 00:05:24,600
鋪設過程所以它已經被證明

161
00:05:24,600 --> 00:05:25,800
大型語言

162
00:05:25,800 --> 00:05:27,780
模型在語言課程上的表現確實受到

163
00:05:27,780 --> 00:05:29,699


164
00:05:29,699 --> 00:05:31,440
訓練語料庫多樣性的嚴重影響，

165
00:05:31,440 --> 00:05:33,180
嗯，但自然語言本身並沒有

166
00:05:33,180 --> 00:05:35,340
偏見，

167
00:05:35,340 --> 00:05:37,199
它只是一個計算系統，人類

168
00:05:37,199 --> 00:05:39,120
可能會在他們所說的和

169
00:05:39,120 --> 00:05:41,039
他們的行為上產生偏見 但是自然語言本身並

170
00:05:41,039 --> 00:05:43,020
沒有偏見 如此大的語言

171
00:05:43,020 --> 00:05:45,180
模型 因此我似乎很難

172
00:05:45,180 --> 00:05:47,880
同意它們受到

173
00:05:47,880 --> 00:05:49,500
各種偏見的影響

174
00:05:49,500 --> 00:05:51,000
因此它們不能真正成為

175
00:05:51,000 --> 00:05:52,020
語言模型 它們是某種事物的模型

176
00:05:52,020 --> 00:05:53,880
其他所以只是為了結束這個

177
00:05:53,880 --> 00:05:55,620
論點，

178
00:05:55,620 --> 00:05:58,139
嗯，你知道，即使 llms 顯然再次

179
00:05:58,139 --> 00:05:59,759
接觸到兒童的更多語言

180
00:05:59,759 --> 00:06:01,320
經驗，這是

181
00:06:01,320 --> 00:06:02,699
斯蒂芬可以看到

182
00:06:02,699 --> 00:06:04,680
並在他的論文中談論的其他東西，即使如此，

183
00:06:04,680 --> 00:06:06,360
他們的學習成果可能仍然 與

184
00:06:06,360 --> 00:06:08,160
解決原則上可以學習的語法概括相關，

185
00:06:08,160 --> 00:06:09,840


186
00:06:09,840 --> 00:06:11,580
所以我同意這裡的

187
00:06:11,580 --> 00:06:12,660
聲明你知道

188
00:06:12,660 --> 00:06:14,100
原則上他們可以告訴我們一些

189
00:06:14,100 --> 00:06:16,080
關於可學習性的東西，而不是

190
00:06:16,080 --> 00:06:17,639
像你知道的廣泛的習得

191
00:06:17,639 --> 00:06:20,520
框架那樣的東西，但

192
00:06:20,520 --> 00:06:21,900
我認為你可以做到這一點 也許現在就說，

193
00:06:21,900 --> 00:06:24,539
表明一些歸納性偏見

194
00:06:24,539 --> 00:06:26,819
對學習來說不是必需的，這與

195
00:06:26,819 --> 00:06:28,139
表明它

196
00:06:28,139 --> 00:06:30,060
不存在於兒童身上並不是一回事，所以

197
00:06:30,060 --> 00:06:31,560
關於你是否

198
00:06:31,560 --> 00:06:32,639
知道負面證據、指導

199
00:06:32,639 --> 00:06:34,500
、糾正和反饋一直存在著長期的爭論

200
00:06:34,500 --> 00:06:36,720
語言學習

201
00:06:36,720 --> 00:06:39,120
對嬰兒和兒童來說是必要的，甚至是有用的，

202
00:06:39,120 --> 00:06:40,440
嗯，但現在我有點同意

203
00:06:40,440 --> 00:06:42,479
Eugene Choi 和 Gary Marcus 以及

204
00:06:42,479 --> 00:06:44,340
其他人的觀點，他們強調了

205
00:06:44,340 --> 00:06:45,660
你知道 llms 目前的培訓成本非常昂貴，

206
00:06:45,660 --> 00:06:46,440


207
00:06:46,440 --> 00:06:48,600
這顯然是一個

208
00:06:48,600 --> 00:06:50,400
集中私人的例子 權力掌握在

209
00:06:50,400 --> 00:06:51,960
一些科技公司手中，他們

210
00:06:51,960 --> 00:06:54,539
對環境的影響是巨大的，

211
00:06:54,539 --> 00:06:56,039
嗯，你知道，很多人

212
00:06:56,039 --> 00:06:57,300
在這裡的評估中沒有那麼拘束和保守，

213
00:06:57,300 --> 00:06:58,979


214
00:06:58,979 --> 00:07:00,660
嗯，除了加里馬庫斯和尤金之外，這要少得多，

215
00:07:00,660 --> 00:07:02,880
所以比爾蓋茨最近

216
00:07:02,880 --> 00:07:05,100
寫道，聊天 GPT 是

217
00:07:05,100 --> 00:07:06,960
嗯 自

218
00:07:06,960 --> 00:07:11,400
圖形用戶界面圖形用戶界面 GUI

219
00:07:11,400 --> 00:07:13,020
um 和 Henry Kissinger 二月份

220
00:07:13,020 --> 00:07:15,240
在華爾街日報上寫道，隨著聊天

221
00:07:15,240 --> 00:07:17,400
gbt 的容量變得更廣泛，他們

222
00:07:17,400 --> 00:07:19,560
將重新定義人類知識，加速

223
00:07:19,560 --> 00:07:21,780
我們現實結構的變化，並

224
00:07:21,780 --> 00:07:23,220
重組政治和社會

225
00:07:23,220 --> 00:07:25,620
生成人工智能的發布是為了產生

226
00:07:25,620 --> 00:07:28,319
新的人類意識形式，所以

227
00:07:28,319 --> 00:07:30,419
目前正在發生非常激進的主張

228
00:07:30,419 --> 00:07:32,220


229
00:07:32,220 --> 00:07:35,099


230
00:07:35,099 --> 00:07:36,840


231
00:07:36,840 --> 00:07:39,240


232
00:07:39,240 --> 00:07:40,680
更

233
00:07:40,680 --> 00:07:42,180
具體地知道，只是把它放回史蒂文

234
00:07:42,180 --> 00:07:44,280
這裡我想提出這個問題，嗯，

235
00:07:44,280 --> 00:07:46,919
rorski 和 Beaumont 的批評，

236
00:07:46,919 --> 00:07:49,259
我認為他在 lingbuzz 上讀過嗯，我

237
00:07:49,259 --> 00:07:50,520


238
00:07:50,520 --> 00:07:51,240


239
00:07:51,240 --> 00:07:53,280
想你在 Twitter 上看到你

240
00:07:53,280 --> 00:07:54,419
不喜歡這個回應 他們

241
00:07:54,419 --> 00:07:56,819
之所以反對，是因為他們提出的反對意見是

242
00:07:56,819 --> 00:07:58,500
你知道科學是演繹邏輯的一個例子，

243
00:07:58,500 --> 00:08:00,479
你的反對意見是

244
00:08:00,479 --> 00:08:02,340
科學不是演繹的，它是歸納的，

245
00:08:02,340 --> 00:08:04,380
但我認為一般觀點

246
00:08:04,380 --> 00:08:06,900
可能更準確，即你

247
00:08:06,900 --> 00:08:08,520
不能，你可以 使用

248
00:08:08,520 --> 00:08:10,620
語言模型可以很好地預測

249
00:08:10,620 --> 00:08:13,020
人類的某些語言行為和某些

250
00:08:13,020 --> 00:08:15,300
神經成像反應這一事實，您不能

251
00:08:15,300 --> 00:08:17,460
單獨使用它來聲稱它們可以產生

252
00:08:17,460 --> 00:08:19,199
人類語言理論，

253
00:08:19,199 --> 00:08:21,000
所以在您的論文 Stephen 中，您知道

254
00:08:21,000 --> 00:08:23,220
這似乎 某些結構

255
00:08:23,220 --> 00:08:25,020
比其他結構更好 正確的注意力

256
00:08:25,020 --> 00:08:26,819
機制很重要 預測很

257
00:08:26,819 --> 00:08:28,680
重要 語義表示很

258
00:08:28,680 --> 00:08:30,180
重要 因此我們

259
00:08:30,180 --> 00:08:32,219
目前可以基於這些模型收集正確的

260
00:08:32,219 --> 00:08:34,260
嗯但到目前為止，這真的是我

261
00:08:34,260 --> 00:08:36,000
在文獻中能夠收集到的全部

262
00:08:36,000 --> 00:08:37,559
不確定你在這裡是否有更多見解，

263
00:08:37,559 --> 00:08:39,899
所以 Rosky 和 ​​Boomer 使用了

264
00:08:39,899 --> 00:08:42,719
預測不佳但強有力的解釋的例子

265
00:08:42,719 --> 00:08:44,760
正確的解釋力而不是

266
00:08:44,760 --> 00:08:46,500
預測準確性構成了

267
00:08:46,500 --> 00:08:48,120
現代科學的基礎，我想

268
00:08:48,120 --> 00:08:49,440
稍後再探討這個，也許

269
00:08:49,440 --> 00:08:50,820
嗯但是現代語言模型 可以

270
00:08:50,820 --> 00:08:52,440
準確地模擬人類語言的一部分，

271
00:08:52,440 --> 00:08:54,180
但它們也可以在人類無法學習並且難以處理的

272
00:08:54,180 --> 00:08:55,920
不可能的語言和不自然的

273
00:08:55,920 --> 00:08:58,200
結構上表現得非常好，

274
00:08:58,200 --> 00:09:00,360
我

275
00:09:00,360 --> 00:09:01,560
知道你對這些批評很熟悉，嗯，

276
00:09:01,560 --> 00:09:03,060


277
00:09:03,060 --> 00:09:04,380
但你是 絕對不是一個人同時在這裡，

278
00:09:04,380 --> 00:09:08,339
所以 uh Elia

279
00:09:08,339 --> 00:09:10,320
um 是 open AI 的首席科學家，他

280
00:09:10,320 --> 00:09:12,180
最近在接受采訪時說，足夠好地

281
00:09:12,180 --> 00:09:13,680
預測下一個標記意味著什麼，

282
00:09:13,680 --> 00:09:15,540
這意味著你了解

283
00:09:15,540 --> 00:09:17,940
導致創建的潛在現實

284
00:09:17,940 --> 00:09:19,920
這個標誌與

285
00:09:19,920 --> 00:09:21,779


286
00:09:21,779 --> 00:09:23,100


287
00:09:23,100 --> 00:09:24,540
這裡的文獻中許多更保守的主張完全不同，

288
00:09:24,540 --> 00:09:26,519
嗯，而且你知道我只是回應說

289
00:09:26,519 --> 00:09:27,839


290
00:09:27,839 --> 00:09:30,019
科學的不同組成部分可以是

291
00:09:30,019 --> 00:09:32,580
歸納的也可以是演繹的，對吧，它不是

292
00:09:32,580 --> 00:09:34,140
真的，或者你有 一個現有的

293
00:09:34,140 --> 00:09:36,300
理論，你制定超假設，

294
00:09:36,300 --> 00:09:38,519
你收集數據，你分析它，這

295
00:09:38,519 --> 00:09:40,200
是一種演繹的演繹

296
00:09:40,200 --> 00:09:41,880
過程，但也有一些情況，你從

297
00:09:41,880 --> 00:09:43,680
一個特定的觀察開始，你會

298
00:09:43,680 --> 00:09:44,940
發現一些模式，然後你得出正確的

299
00:09:44,940 --> 00:09:46,860
一般結論，然後是

300
00:09:46,860 --> 00:09:49,380
你神奇地

301
00:09:49,380 --> 00:09:52,019
發明的綁架 假設並減少

302
00:09:52,019 --> 00:09:53,760
假設空間，你不會真的說

303
00:09:53,760 --> 00:09:55,620
演繹推理是不科學的

304
00:09:55,620 --> 00:09:58,200
或歸納推理是不科學的

305
00:09:58,200 --> 00:10:00,360
或歸納推理是不科學的，

306
00:10:00,360 --> 00:10:01,800
這些都是不同的做事方式，

307
00:10:01,800 --> 00:10:03,540


308
00:10:03,540 --> 00:10:05,459
嗯，我的意思是在你的論文中你給出了

309
00:10:05,459 --> 00:10:08,399
使用的例子 預測颶風

310
00:10:08,399 --> 00:10:09,779
和大流行病的模型作為與

311
00:10:09,779 --> 00:10:12,060


312
00:10:12,060 --> 00:10:13,860
科學一樣嚴格的例子，然後你懇求你的

313
00:10:13,860 --> 00:10:16,019
讀者得出結論，

314
00:10:16,019 --> 00:10:18,120
語言模型的情況沒有什麼不同，

315
00:10:18,120 --> 00:10:19,920
嗯，但我想對我來說，問題是

316
00:10:19,920 --> 00:10:22,200
預測颶風的模型沒有 在

317
00:10:22,200 --> 00:10:23,940
回答

318
00:10:23,940 --> 00:10:25,740
什麼是颶風的問題時，

319
00:10:25,740 --> 00:10:27,420
準確預測天氣的正確模型

320
00:10:27,420 --> 00:10:29,040
非常準確，但他們

321
00:10:29,040 --> 00:10:30,600
不是你知道他們與

322
00:10:30,600 --> 00:10:32,700
氣象部門保持一致，但他們不能替代

323
00:10:32,700 --> 00:10:34,380
它，

324
00:10:34,380 --> 00:10:35,760
嗯，所以我想我' 只是你知道把它

325
00:10:35,760 --> 00:10:37,620
交給你是的

326
00:10:37,620 --> 00:10:41,820
好吧呃那裡有很多嗯

327
00:10:41,820 --> 00:10:43,800
我想我可以先

328
00:10:43,800 --> 00:10:45,240
說嗯嗯

329
00:10:45,240 --> 00:10:47,579
我同意很多這些

330
00:10:47,579 --> 00:10:51,300
批評是正確的關於呃這些

331
00:10:51,300 --> 00:10:54,000
模型被呃你知道

332
00:10:54,000 --> 00:10:56,220
一兩家公司，嗯，

333
00:10:56,220 --> 00:10:59,160
這是非常非常有問題的，

334
00:10:59,160 --> 00:11:01,320
嗯，你知道他們有各種各樣的

335
00:11:01,320 --> 00:11:03,480
偏見，因為

336
00:11:03,480 --> 00:11:04,980
他們接受了來自互聯網的文本培訓，

337
00:11:04,980 --> 00:11:06,180


338
00:11:06,180 --> 00:11:08,640
嗯，這是非常有問題的，

339
00:11:08,640 --> 00:11:10,980
嗯，你知道，我當然同意，

340
00:11:10,980 --> 00:11:13,079
呃事情在 至少目前

341
00:11:13,079 --> 00:11:16,500
這些模型做得不好所以

342
00:11:16,500 --> 00:11:18,420
嗯我認為很容易找到

343
00:11:18,420 --> 00:11:20,640
你知道的問題的例子和

344
00:11:20,640 --> 00:11:23,100
會絆倒他們的問題

345
00:11:23,100 --> 00:11:25,500
嗯我想為什麼我對它們感到興奮

346
00:11:25,500 --> 00:11:26,760
雖然

347
00:11:26,760 --> 00:11:29,820
嗯不是 呃不一定在這些

348
00:11:29,820 --> 00:11:32,399
方面是正確的，但在

349
00:11:32,399 --> 00:11:34,920
語言性能方面，

350
00:11:34,920 --> 00:11:38,459
特別是語法和語義，

351
00:11:38,459 --> 00:11:40,980
嗯，我認為它們遠遠超出

352
00:11:40,980 --> 00:11:43,019
任何其他領域的任何其他理論，

353
00:11:43,019 --> 00:11:46,920
所以沒有其他

354
00:11:46,920 --> 00:11:49,380
理論 語言學或計算機

355
00:11:49,380 --> 00:11:53,100
科學可以讓你知道長

356
00:11:53,100 --> 00:11:56,700
連貫的語法呃文本段落

357
00:11:56,700 --> 00:11:58,500


358
00:11:58,500 --> 00:12:01,140
嗯所以有點承認他們所有的

359
00:12:01,140 --> 00:12:04,920
問題因為你知道

360
00:12:04,920 --> 00:12:08,220
公司部署的工具或東西

361
00:12:08,220 --> 00:12:09,959
嗯嗯還有這個問題

362
00:12:09,959 --> 00:12:12,899
他們在處理語言方面表現如何，

363
00:12:12,899 --> 00:12:14,760


364
00:12:14,760 --> 00:12:16,320
嗯，我認為這是很多

365
00:12:16,320 --> 00:12:17,760
熱情的來源，就

366
00:12:17,760 --> 00:12:20,160


367
00:12:20,160 --> 00:12:23,700
語言能力而言，真的沒有什麼比他們更遙遠的了，

368
00:12:23,700 --> 00:12:24,899
嗯，這就是我

369
00:12:24,899 --> 00:12:27,660
認為的 是令人興奮的，所以是的，我

370
00:12:27,660 --> 00:12:29,220
同意你開始的這些事情，

371
00:12:29,220 --> 00:12:31,320


372
00:12:31,320 --> 00:12:33,300
嗯，但是就像我認為在

373
00:12:33,300 --> 00:12:35,100
語法和語義方面一樣，

374
00:12:35,100 --> 00:12:37,079
沒有其他理論可以

375
00:12:37,079 --> 00:12:39,240
與它們相提並論，嗯，

376
00:12:39,240 --> 00:12:40,140


377
00:12:40,140 --> 00:12:42,120
但讓我來推動 那時候是的，

378
00:12:42,120 --> 00:12:44,940
是的，我會反對我在語言學係採訪過的

379
00:12:44,940 --> 00:12:46,320
很多人的主要反對意見，他們

380
00:12:46,320 --> 00:12:48,000


381
00:12:48,000 --> 00:12:50,760
就像很多一般人一樣，你

382
00:12:50,760 --> 00:12:53,100
首先知道你的論文是真的

383
00:12:53,100 --> 00:12:54,120
說得好，

384
00:12:54,120 --> 00:12:55,620
嗯，你知道你' 沒錯，他們確實做得

385
00:12:55,620 --> 00:12:57,360
很好，嗯，準確地模擬了

386
00:12:57,360 --> 00:12:58,920


387
00:12:58,920 --> 00:13:01,380
句法和語義的許多方面的所有方面，但是，嗯，

388
00:13:01,380 --> 00:13:03,300
我不知道任何真實的，就像

389
00:13:03,300 --> 00:13:04,920
你知道喬姆斯基談論關於

390
00:13:04,920 --> 00:13:06,660
語言的事實，這是一個老式的

391
00:13:06,660 --> 00:13:09,000
概念 但我真的認為這是

392
00:13:09,000 --> 00:13:10,260
一個非常重要的概念，

393
00:13:10,260 --> 00:13:12,899
就像

394
00:13:12,899 --> 00:13:16,860
llms 可以獨特地提供關於語言本身的一些發現，

395
00:13:16,860 --> 00:13:19,200
就像 llm 做出了一些

396
00:13:19,200 --> 00:13:21,899
預測，假設你有一個

397
00:13:21,899 --> 00:13:24,600
句子結構類型 X

398
00:13:24,600 --> 00:13:26,279
比句子更難處理 類型

399
00:13:26,279 --> 00:13:28,620
Y，這是一個獨特的預測，

400
00:13:28,620 --> 00:13:31,200
只有他們會產生它，而沒有人類

401
00:13:31,200 --> 00:13:33,899
語言學家喬姆斯基·霍姆斯坦，這些

402
00:13:33,899 --> 00:13:34,980
人之前都沒有預測到，

403
00:13:34,980 --> 00:13:37,260
但事實證明這是真的你做了眼動

404
00:13:37,260 --> 00:13:38,760
追踪實驗，你做了各種

405
00:13:38,760 --> 00:13:40,800
不同的行為體驗 哦，

406
00:13:40,800 --> 00:13:42,480
你知道，畢竟它是

407
00:13:42,480 --> 00:13:44,279
真的，這是關於

408
00:13:44,279 --> 00:13:45,839
語言處理的新見解，這是

409
00:13:45,839 --> 00:13:47,940
關於語言的新見解，你知道行為我只是

410
00:13:47,940 --> 00:13:49,560
想知道我不是說我不是說

411
00:13:49,560 --> 00:13:51,240
這在原則上是不可能的

412
00:13:51,240 --> 00:13:52,620
因為它可能會在

413
00:13:52,620 --> 00:13:54,540
不久的將來發生，但我想這就是

414
00:13:54,540 --> 00:13:57,240
為什麼很多語言學家

415
00:13:57,240 --> 00:13:59,519


416
00:13:59,519 --> 00:14:02,040
在這裡代表整個語言學社區發言的關鍵，你知道

417
00:14:02,040 --> 00:14:03,180
我想這將是主要的

418
00:14:03,180 --> 00:14:04,800
反對意見之一

419
00:14:04,800 --> 00:14:08,279
是的我的意思是我我 不知道，嗯，我

420
00:14:08,279 --> 00:14:10,019
想我認為他們

421
00:14:10,019 --> 00:14:12,420
提供的見解是一種普遍原則，

422
00:14:12,420 --> 00:14:14,459
所以

423
00:14:14,459 --> 00:14:16,200
嗯，我認為這些事情就像

424
00:14:16,200 --> 00:14:18,720
記憶大塊

425
00:14:18,720 --> 00:14:20,820
語言的力量一樣，就像它們

426
00:14:20,820 --> 00:14:22,500
看起來一樣 例如，要非常擅長結構，

427
00:14:22,500 --> 00:14:24,540
並且有很多

428
00:14:24,540 --> 00:14:26,160
語言學理論，特別是喬姆斯基的

429
00:14:26,160 --> 00:14:28,740
權利，這是關於

430
00:14:28,740 --> 00:14:30,899
試圖找到一種最少量

431
00:14:30,899 --> 00:14:33,660
的結構來記住權利，試圖

432
00:14:33,660 --> 00:14:36,480
從

433
00:14:36,480 --> 00:14:38,279
一些小的集合中盡可能多地推導一些小的

434
00:14:38,279 --> 00:14:40,440
操作的集合，

435
00:14:40,440 --> 00:14:42,300
嗯，我認為對於

436
00:14:42,300 --> 00:14:44,459
那些理論來說並不順利，嗯，而這

437
00:14:44,459 --> 00:14:46,740
確實很好，所以

438
00:14:46,740 --> 00:14:48,360
嗯，如果我們考慮一些

439
00:14:48,360 --> 00:14:50,040
具有記憶能力的東西，

440
00:14:50,040 --> 00:14:51,300
例如我們考慮構建的語法理論

441
00:14:51,300 --> 00:14:54,240


442
00:14:54,240 --> 00:14:56,040
嗯，你知道人類非常喜歡

443
00:14:56,040 --> 00:14:58,139
記住

444
00:14:58,139 --> 00:14:59,880
不同結構或

445
00:14:59,880 --> 00:15:01,380
不同單詞的非凡能力，我們知道數万個

446
00:15:01,380 --> 00:15:02,940
單詞數万個

447
00:15:02,940 --> 00:15:04,380
不同的結構對不起

448
00:15:04,380 --> 00:15:06,420
數万個不同的習語也許我們的

449
00:15:06,420 --> 00:15:07,920
語法理論應該

450
00:15:07,920 --> 00:15:10,260
與此相結合，他們 從某種意義上說，這是

451
00:15:10,260 --> 00:15:12,480
一種原則證明，這種

452
00:15:12,480 --> 00:15:15,660
方法可以很好地發揮作用，

453
00:15:15,660 --> 00:15:17,279
嗯，可以考慮用它們做出其他類型的

454
00:15:17,279 --> 00:15:19,380
預測，嗯，其中一些

455
00:15:19,380 --> 00:15:21,779
人目前正在做，但

456
00:15:21,779 --> 00:15:23,339
例如試圖用它們來

457
00:15:23,339 --> 00:15:25,860
衡量

458
00:15:25,860 --> 00:15:27,899
例如，從這些模型中，處理難度測量出乎意料，

459
00:15:27,899 --> 00:15:29,160


460
00:15:29,160 --> 00:15:30,600
嗯，有些出乎意料的措施

461
00:15:30,600 --> 00:15:31,699


462
00:15:31,699 --> 00:15:34,260
比上下文無關

463
00:15:34,260 --> 00:15:36,120
語法或其他類型的語言

464
00:15:36,120 --> 00:15:37,440
模型要好得多，然後有趣的

465
00:15:37,440 --> 00:15:39,899
問題是，這些出人意料或可

466
00:15:39,899 --> 00:15:41,940
預測性與人類

467
00:15:41,940 --> 00:15:44,399
處理權有何關係，它 可能捕獲其中的一些

468
00:15:44,399 --> 00:15:46,620
或者可能是非線性的或者它可能

469
00:15:46,620 --> 00:15:49,079
你只知道捕獲它的一點點

470
00:15:49,079 --> 00:15:51,420
或者或者任何

471
00:15:51,420 --> 00:15:53,940
其他有趣的科學問題但我

472
00:15:53,940 --> 00:15:55,500
認為原則上他們可以

473
00:15:55,500 --> 00:15:57,779
做出關於例如

474
00:15:57,779 --> 00:15:59,880
連接的預測是正確的 句子之間正確所以

475
00:15:59,880 --> 00:16:02,279
在論文中我給出了這個例子，

476
00:16:02,279 --> 00:16:05,459
你知道

477
00:16:05,459 --> 00:16:07,920
以 10 種不同的方式將聲明轉換為問題，並且

478
00:16:07,920 --> 00:16:10,620
大概當你知道 GPT 或

479
00:16:10,620 --> 00:16:12,540
正在做的事情時，它會找到

480
00:16:12,540 --> 00:16:15,420
10 個不同的問題，這些都是呃

481
00:16:15,420 --> 00:16:18,060
在語義或句法空間底層的模型中某種方式附近的某種方式，

482
00:16:18,060 --> 00:16:20,339


483
00:16:20,339 --> 00:16:22,139


484
00:16:22,139 --> 00:16:24,660
嗯，所以這些東西是

485
00:16:24,660 --> 00:16:26,459
我認為的那種類型，

486
00:16:26,459 --> 00:16:28,560
嗯，你知道一些語言學家可能想要

487
00:16:28,560 --> 00:16:30,180
正確的，這是

488
00:16:30,180 --> 00:16:32,220
句子之間或他們或

489
00:16:32,220 --> 00:16:34,320
他們的句子之間的一些隱藏聯繫 結構，但據我所知，

490
00:16:34,320 --> 00:16:36,120
它們還沒有經過經驗評估，

491
00:16:36,120 --> 00:16:39,660
所以是的，是的，是的，我的意思是這些

492
00:16:39,660 --> 00:16:41,220
模型只有幾年的歷史，

493
00:16:41,220 --> 00:16:43,440
所以我認為

494
00:16:43,440 --> 00:16:45,000


495
00:16:45,000 --> 00:16:46,259
即使這種工作已經

496
00:16:46,259 --> 00:16:48,540
存在，但對它們感到興奮是合理的 還沒有完成，不，那是對的，不

497
00:16:48,540 --> 00:16:50,880
完全，我的意思是，但我

498
00:16:50,880 --> 00:16:51,720
認為這是正確的

499
00:16:51,720 --> 00:16:52,920
觀點，但我認為這

500
00:16:52,920 --> 00:16:54,779
涉及到

501
00:16:54,779 --> 00:16:56,579
你提到的令人驚訝的問題，你提到了

502
00:16:56,579 --> 00:16:58,139
laneability

503
00:16:58,139 --> 00:17:00,839
嗯，你知道 LMS 和一些語法但是 他們

504
00:17:00,839 --> 00:17:03,060
這樣做的數據顯然

505
00:17:03,060 --> 00:17:04,439
比嬰兒多得多，

506
00:17:04,439 --> 00:17:06,240
因此對潛在結構的觀察

507
00:17:06,240 --> 00:17:09,000
本身並不能

508
00:17:09,000 --> 00:17:10,799
說明刺激的貧乏，

509
00:17:10,799 --> 00:17:12,540
我應該說的是較弱的版本，即

510
00:17:12,540 --> 00:17:13,500


511
00:17:13,500 --> 00:17:15,059
傑出論證的貧乏，所以僅僅是事實

512
00:17:15,059 --> 00:17:17,579
LMS 可以用我們的語法獎完成他們所做的事情，

513
00:17:17,579 --> 00:17:19,559
這非常驚人，我

514
00:17:19,559 --> 00:17:20,939
同意，事實上你可能不會

515
00:17:20,939 --> 00:17:22,500
預料到

516
00:17:22,500 --> 00:17:23,699
五六七年前，

517
00:17:23,699 --> 00:17:25,260
嗯，但這並不能否定

518
00:17:25,260 --> 00:17:28,199
人類有驚喜的說法，我們

519
00:17:28,199 --> 00:17:30,120
帶上這些祈禱，

520
00:17:30,120 --> 00:17:31,080
以便看看計算

521
00:17:31,080 --> 00:17:33,299
語言學是否可以限制假設和

522
00:17:33,299 --> 00:17:34,740
理論語言學，我認為它

523
00:17:34,740 --> 00:17:36,480
可以通過這種方式做到這一點，這需要

524
00:17:36,480 --> 00:17:38,039
與你一起完成，你知道控制

525
00:17:38,039 --> 00:17:39,720
不同學習參數的仔細實驗

526
00:17:39,720 --> 00:17:43,080
和巨大的語言模型

527
00:17:43,080 --> 00:17:45,299
像 gbt free 基本上你知道

528
00:17:45,299 --> 00:17:47,520
在這裡沒用，所以這會引起

529
00:17:47,520 --> 00:17:49,559
一些 tile lens 和抱怨我們

530
00:17:49,559 --> 00:17:51,960
需要像嬰兒 LM 項目

531
00:17:51,960 --> 00:17:53,700
這樣的東西我知道你感興趣並且

532
00:17:53,700 --> 00:17:55,320
我們有更多你知道生態

533
00:17:55,320 --> 00:17:56,940
有效的訓練集你

534
00:17:56,940 --> 00:17:58,380
在你的論文中預測

535
00:17:58,380 --> 00:17:59,640
將從中學習到一些結構，我

536
00:17:59,640 --> 00:18:01,679
懷疑你可能是對的，

537
00:18:01,679 --> 00:18:03,059
嗯，但你知道即便如此，即使有

538
00:18:03,059 --> 00:18:04,679
嬰兒 LM 挑戰，仍然存在

539
00:18:04,679 --> 00:18:07,260
解決更傳統問題的非平凡問題，

540
00:18:07,260 --> 00:18:09,419
例如什麼時候 孩子們

541
00:18:09,419 --> 00:18:11,400
開始根據

542
00:18:11,400 --> 00:18:13,200


543
00:18:13,200 --> 00:18:15,539
跨語言的不同因素根據當前輸入量進行概括，這只

544
00:18:15,539 --> 00:18:17,700
需要傳統的

545
00:18:17,700 --> 00:18:18,720
心理語言學和語言

546
00:18:18,720 --> 00:18:21,539
習得，所以你知道 LMS 確實關心

547
00:18:21,539 --> 00:18:22,919
頻率和

548
00:18:22,919 --> 00:18:24,600
意外之類的事情，就像你說的那樣，但

549
00:18:24,600 --> 00:18:26,160
真的很好 Sophie [ __ ] 和

550
00:18:26,160 --> 00:18:27,600
Andrea Martin 的論文非常漂亮，

551
00:18:27,600 --> 00:18:30,000
我想你可能已經看到它

552
00:18:30,000 --> 00:18:31,620
很好地表明分佈

553
00:18:31,620 --> 00:18:34,080
統計有時可以作為

554
00:18:34,080 --> 00:18:36,240
結構構建時刻的線索，但它

555
00:18:36,240 --> 00:18:37,919
確實取代了這些與組合有關的概念，

556
00:18:37,919 --> 00:18:39,660
所以我只是 閱讀

557
00:18:39,660 --> 00:18:42,360
Chomsky 57 的一句話，這聽起來很像

558
00:18:42,360 --> 00:18:45,240
um slots and more 並說儘管

559
00:18:45,240 --> 00:18:47,820


560
00:18:47,820 --> 00:18:49,440


561
00:18:49,440 --> 00:18:51,360
語言的語義和統計模型具有不可否認的興趣和重要性，但它們似乎與

562
00:18:51,360 --> 00:18:52,919
確定

563
00:18:52,919 --> 00:18:54,600
或表徵語法

564
00:18:54,600 --> 00:18:56,340
差異集的問題沒有直接關係 我認為我們不得不

565
00:18:56,340 --> 00:18:57,840
得出這樣的結論：語法是自主的

566
00:18:57,840 --> 00:18:59,520
，獨立於意義，

567
00:18:59,520 --> 00:19:01,320
概率模型沒有

568
00:19:01,320 --> 00:19:03,179
對句法結構的一些基本問題給出特別的洞察力，

569
00:19:03,179 --> 00:19:05,880
所以

570
00:19:05,880 --> 00:19:07,980
第二句的 the 的第二個呃對沖結果

571
00:19:07,980 --> 00:19:10,380
是 不正確，但確實如此，

572
00:19:10,380 --> 00:19:11,580
您

573
00:19:11,580 --> 00:19:13,740
確實知道

574
00:19:13,740 --> 00:19:16,559
57 中的可用統計模型在今天應用於模型時不再準確，

575
00:19:16,559 --> 00:19:18,600
並且可以

576
00:19:18,600 --> 00:19:20,340
對您提到的新

577
00:19:20,340 --> 00:19:21,900
字符串和分佈類別進行抽象概括，

578
00:19:21,900 --> 00:19:23,640
但

579
00:19:23,640 --> 00:19:25,380
單個模型的性能 沒有通過

580
00:19:25,380 --> 00:19:27,480


581
00:19:27,480 --> 00:19:29,760


582
00:19:29,760 --> 00:19:31,440
給出

583
00:19:31,440 --> 00:19:33,900
當今可用的任何計算模型與

584
00:19:33,900 --> 00:19:36,240
人腦模型之間的巨大距離來提供支持或反對特定結構的著陸性的直接證據，成功並不意味著

585
00:19:36,240 --> 00:19:38,100
該結構必然是

586
00:19:38,100 --> 00:19:40,679
陸地，模型失敗也不意味著

587
00:19:40,679 --> 00:19:42,539
結構是不可學習的，

588
00:19:42,539 --> 00:19:44,520


589
00:19:44,520 --> 00:19:47,100
是的，是的，所以我的意思是，我認為可能

590
00:19:47,100 --> 00:19:49,380
值得拆開人們提出的幾個

591
00:19:49,380 --> 00:19:51,000
不同版本的可學習性

592
00:19:51,000 --> 00:19:52,620
論點，因為

593
00:19:52,620 --> 00:19:55,679
有非常非常強烈

594
00:19:55,679 --> 00:19:57,720
的不可能性主張，

595
00:19:57,720 --> 00:19:59,160
嗯，來自喬姆斯基的

596
00:19:59,160 --> 00:20:01,260
傳統，對吧 我們從來沒有

597
00:20:01,260 --> 00:20:04,140
聲稱需要的數據量是

598
00:20:04,140 --> 00:20:05,820
正確的 有關於

599
00:20:05,820 --> 00:20:08,220
語言學習的邏輯問題的說法 這

600
00:20:08,220 --> 00:20:10,740


601
00:20:10,740 --> 00:20:12,120
是不可能的

602
00:20:12,120 --> 00:20:15,720


603
00:20:15,720 --> 00:20:17,580


604
00:20:17,580 --> 00:20:19,380


605
00:20:19,380 --> 00:20:21,660
你會獲得的語言類或語法類，嗯，

606
00:20:21,660 --> 00:20:23,220
人們很長一段時間一直在

607
00:20:23,220 --> 00:20:25,380
反對那個版本的

608
00:20:25,380 --> 00:20:26,340
東西，

609
00:20:26,340 --> 00:20:27,120


610
00:20:27,120 --> 00:20:28,860
嗯，你知道有 gold 的舊作品，

611
00:20:28,860 --> 00:20:30,419
然後是整個

612
00:20:30,419 --> 00:20:32,580
語法

613
00:20:32,580 --> 00:20:35,220
建立在傳統之上的習得理論非常擔心

614
00:20:35,220 --> 00:20:37,980


615
00:20:37,980 --> 00:20:39,240
你遍歷不同的

616
00:20:39,240 --> 00:20:40,860
假設並考慮不同的

617
00:20:40,860 --> 00:20:42,600
選擇和事物的順序，

618
00:20:42,600 --> 00:20:43,380


619
00:20:43,380 --> 00:20:45,059
嗯，我最喜歡的參考

620
00:20:45,059 --> 00:20:46,919
是尼克賈德的這篇論文

621
00:20:46,919 --> 00:20:49,799
和 Paul vetani um 稱之為

622
00:20:49,799 --> 00:20:51,539


623
00:20:51,539 --> 00:20:53,039
自然語言的理想學習

624
00:20:53,039 --> 00:20:54,840
um 這基本上表明，一個

625
00:20:54,840 --> 00:20:57,539
不受約束的學習者可以 uh 有

626
00:20:57,539 --> 00:21:00,480
足夠的數據 uh 獲得 uh

627
00:21:00,480 --> 00:21:01,860
生成規則的種類或

628
00:21:01,860 --> 00:21:03,360
生成語法

629
00:21:03,360 --> 00:21:05,640
um 僅通過觀察字符串是正確的，但

630
00:21:05,640 --> 00:21:08,160
那篇論文 確實是

631
00:21:08,160 --> 00:21:10,200
為了回應大量的工作，這些工作

632
00:21:10,200 --> 00:21:13,140
爭辯說

633
00:21:13,140 --> 00:21:15,120
從正例中學習，因此僅通過

634
00:21:15,120 --> 00:21:17,820
觀察字符串在邏輯上是

635
00:21:17,820 --> 00:21:20,520
不可能的，所以

636
00:21:20,520 --> 00:21:23,460
嗯，當然，你知道

637
00:21:23,460 --> 00:21:25,679
喬姆斯基傳統中的人們真的很喜歡這種

638
00:21:25,679 --> 00:21:28,140
形式 論證是因為它

639
00:21:28,140 --> 00:21:30,419
說，呃，你必須天生就有

640
00:21:30,419 --> 00:21:33,299
特定的東西，才能使

641
00:21:33,299 --> 00:21:34,919
語言習得起作用，這就像

642
00:21:34,919 --> 00:21:36,600
一種數學論證，

643
00:21:36,600 --> 00:21:39,480
你必須有某種

644
00:21:39,480 --> 00:21:41,220
天生的語法或假設的

645
00:21:41,220 --> 00:21:42,900
天生順序，或者 有些事情和所有這些都

646
00:21:42,900 --> 00:21:45,659
被證明是完全錯誤的所以

647
00:21:45,659 --> 00:21:48,299
嗯，如果你知道轉移到

648
00:21:48,299 --> 00:21:50,520
更現實的學習環境，

649
00:21:50,520 --> 00:21:53,340
Tater 和 vatani 做的

650
00:21:53,340 --> 00:21:55,500
嗯嗯然後事實證明你就像一個

651
00:21:55,500 --> 00:21:57,240
理想化的學習者可以獲得東西並且

652
00:21:57,240 --> 00:21:59,100
沒有 關於

653
00:21:59,100 --> 00:22:00,600
um 即使在那裡也需要的數據量的陳述

654
00:22:00,600 --> 00:22:02,700
是那種

655
00:22:02,700 --> 00:22:06,780
純邏輯的 uh 學習能力

656
00:22:06,780 --> 00:22:08,940
um 而這種能力是我認為

657
00:22:08,940 --> 00:22:11,460
大型語言模型的 uh 大版本

658
00:22:11,460 --> 00:22:13,679
也正確所以 Chader

659
00:22:13,679 --> 00:22:15,600
invitani 和其他 這種精神的工作方式

660
00:22:15,600 --> 00:22:17,460


661
00:22:17,460 --> 00:22:19,500
是，你知道數學和

662
00:22:19,500 --> 00:22:21,480
原則上的爭論，但從來沒有

663
00:22:21,480 --> 00:22:24,720
創造出真正的

664
00:22:24,720 --> 00:22:27,840
語法正確的東西，或者真正

665
00:22:27,840 --> 00:22:30,000
實現的語言模型，

666
00:22:30,000 --> 00:22:32,640
所以即使你知道一個

667
00:22:32,640 --> 00:22:35,400
經過訓練的模型 在 1 億或 1000 億或

668
00:22:35,400 --> 00:22:38,340
許多代幣上，

669
00:22:38,340 --> 00:22:41,159
嗯，我認為即使是那種模型也與

670
00:22:41,159 --> 00:22:43,080


671
00:22:43,080 --> 00:22:46,140
辯論的那個版本相關，並且表明

672
00:22:46,140 --> 00:22:48,659
語言學習並非不可能，嗯，

673
00:22:48,659 --> 00:22:51,360
從一個非常不受約束的空間好吧

674
00:22:51,360 --> 00:22:53,640
然後還有第二個版本，

675
00:22:53,640 --> 00:22:56,760
呃，我們可以用

676
00:22:56,760 --> 00:22:59,760
孩子們正確的特定數據來學習語言嗎？

677
00:22:59,760 --> 00:23:02,340
這既是數據量

678
00:23:02,340 --> 00:23:04,620
又是數據形式，

679
00:23:04,620 --> 00:23:06,360
嗯，所以對於那些不了解

680
00:23:06,360 --> 00:23:08,520
嬰兒 LM 挑戰的人來說

681
00:23:08,520 --> 00:23:10,440
嗯嗯是嗯

682
00:23:10,440 --> 00:23:12,840
這個嗯嗯

683
00:23:12,840 --> 00:23:14,340
抱歉把它稱為

684
00:23:14,340 --> 00:23:16,620
競賽或

685
00:23:16,620 --> 00:23:20,580
嗯嗯嗯嗯我想這是一個挑戰嗯

686
00:23:20,580 --> 00:23:22,380
試圖讓人們

687
00:23:22,380 --> 00:23:24,539
在人類規模的數據量上訓練語言模型

688
00:23:24,539 --> 00:23:27,179
嗯所以這更像是

689
00:23:27,179 --> 00:23:28,679
嗯我認為有兩個不同的

690
00:23:28,679 --> 00:23:31,140
版本 10 或 1 億個不同的

691
00:23:31,140 --> 00:23:33,120
um 到 10 或 1 億個不同的單詞

692
00:23:33,120 --> 00:23:35,640
在訓練集中

693
00:23:35,640 --> 00:23:38,100
um 這就像你知道的第 100 個或第

694
00:23:38,100 --> 00:23:41,159
1000 個或與

695
00:23:41,159 --> 00:23:43,140
這些大 AI 公司正在使用的

696
00:23:43,140 --> 00:23:46,620
語言一樣大 模型 um 和

697
00:23:46,620 --> 00:23:48,720
um 我認為實際上它就像是

698
00:23:48,720 --> 00:23:50,340
正確的

699
00:23:50,340 --> 00:23:52,020
事情並且正是該領域需要的東西，

700
00:23:52,020 --> 00:23:54,780
因為你可能會發現

701
00:23:54,780 --> 00:23:57,059
um 一個兒童大小的數據

702
00:23:57,059 --> 00:23:58,980
um 你基本上可以學習

703
00:23:58,980 --> 00:24:01,140
正確的語法，我認為會 將是

704
00:24:01,140 --> 00:24:02,880
反對這些刺激貧困聲明的最有力論據，

705
00:24:02,880 --> 00:24:04,260
您可能會

706
00:24:04,260 --> 00:24:06,299
發現

707
00:24:06,299 --> 00:24:08,220
嗯，也許您學不到很多東西，

708
00:24:08,220 --> 00:24:10,740
也許您知道想出

709
00:24:10,740 --> 00:24:12,840
一種更糟糕的語言模型，

710
00:24:12,840 --> 00:24:14,700
或者它缺乏一些句法或

711
00:24:14,700 --> 00:24:16,799
語義能力，

712
00:24:16,799 --> 00:24:17,520
嗯

713
00:24:17,520 --> 00:24:18,720
嗯，我實際上認為

714
00:24:18,720 --> 00:24:20,220
那裡的失敗有點難以

715
00:24:20,220 --> 00:24:22,620
解釋，因為

716
00:24:22,620 --> 00:24:24,720
嗯，孩子們，嗯，數據，當他們真正

717
00:24:24,720 --> 00:24:26,400
學習語言時，他們獲得的

718
00:24:26,400 --> 00:24:28,919
數據要多得多，而不僅僅是

719
00:24:28,919 --> 00:24:31,200
他們在環境中互動的句子串

720
00:24:31,200 --> 00:24:33,059


721
00:24:33,059 --> 00:24:34,440
嗯，所以他們面前的世界上有一些東西，

722
00:24:34,440 --> 00:24:36,539
他們的話語也是

723
00:24:36,539 --> 00:24:38,520
互動的，所以你可以說點什麼，

724
00:24:38,520 --> 00:24:39,960
然後看看你的

725
00:24:39,960 --> 00:24:41,400
父母是否給你帶來了你要求的東西，

726
00:24:41,400 --> 00:24:43,799
例如人們長期以來一直爭論的權利

727
00:24:43,799 --> 00:24:46,020


728
00:24:46,020 --> 00:24:49,020
你知道

729
00:24:49,020 --> 00:24:51,240
在語言習得中的重要線索

730
00:24:51,240 --> 00:24:52,799
嗯所以

731
00:24:52,799 --> 00:24:55,440
嗯嗯在嬰兒 LM 挑戰中有

732
00:24:55,440 --> 00:24:58,200
能力訓練這些

733
00:24:58,200 --> 00:25:00,960
模型呃使用多模式輸入

734
00:25:00,960 --> 00:25:02,340
我認為你可以給他們盡可能多的視頻

735
00:25:02,340 --> 00:25:05,039
數據

736
00:25:05,039 --> 00:25:07,140
呃，但可能很難

737
00:25:07,140 --> 00:25:09,000
完全複製

738
00:25:09,000 --> 00:25:11,220
孩子們實際得到的設置類型和反饋，

739
00:25:11,220 --> 00:25:12,840
所以嗯，

740
00:25:12,840 --> 00:25:14,700
呃，我不知道你知道我很

741
00:25:14,700 --> 00:25:17,700
高興看到呃，事情進展到哪里

742
00:25:17,700 --> 00:25:19,799
以及事情如何 在那裡，

743
00:25:19,799 --> 00:25:20,760
嗯，嗯，

744
00:25:20,760 --> 00:25:23,700
你知道，我認為

745
00:25:23,700 --> 00:25:26,580
對於大型語言模型有一個有趣的相關問題，

746
00:25:26,580 --> 00:25:28,320


747
00:25:28,320 --> 00:25:30,299
嗯，就像它是什麼，它

748
00:25:30,299 --> 00:25:31,919
準確地理解所有

749
00:25:31,919 --> 00:25:34,200
數據在做什麼，所以嗯，

750
00:25:34,200 --> 00:25:36,659
可能是你需要這麼

751
00:25:36,659 --> 00:25:38,279
多數據 這些模型是因為

752
00:25:38,279 --> 00:25:40,620
它們在內部有效地發明了某種形式

753
00:25:40,620 --> 00:25:43,919
的語義，所以

754
00:25:43,919 --> 00:25:45,600
嗯，它們都在發現

755
00:25:45,600 --> 00:25:47,460
語法規則，而且它們似乎在

756
00:25:47,460 --> 00:25:49,380
學習很多關於詞義的

757
00:25:49,380 --> 00:25:50,940
知識，

758
00:25:50,940 --> 00:25:52,200
嗯，

759
00:25:52,200 --> 00:25:54,059
嗯，這不是完全不清楚，我

760
00:25:54,059 --> 00:25:56,220
想 這些現代模型中的大部分數據

761
00:25:56,220 --> 00:25:58,919
呃是語法與語義所需要的

762
00:25:58,919 --> 00:26:00,240


763
00:26:00,240 --> 00:26:02,159
我自己的猜測我認為可能

764
00:26:02,159 --> 00:26:05,580
是語法方面呃可能

765
00:26:05,580 --> 00:26:07,860
需要比語義方面更少的數據

766
00:26:07,860 --> 00:26:09,600


767
00:26:09,600 --> 00:26:11,159
嗯實際上是學生以前

768
00:26:11,159 --> 00:26:12,960
的學生 我的 Frank Malika 和我幾年前寫了一篇論文，

769
00:26:12,960 --> 00:26:15,120
試圖估計

770
00:26:15,120 --> 00:26:17,400
一個學習者必須獲得的信息量，嗯，

771
00:26:17,400 --> 00:26:19,679


772
00:26:19,679 --> 00:26:22,140
學習

773
00:26:22,140 --> 00:26:23,820
語言的不同方面，所以你必須學習所有的

774
00:26:23,820 --> 00:26:25,320
單詞，你學習他們的論壇，你

775
00:26:25,320 --> 00:26:26,880
學習 它們的含義，你可能知道

776
00:26:26,880 --> 00:26:28,320
它們的頻率，你必須學習

777
00:26:28,320 --> 00:26:32,100
語法，基本上我們

778
00:26:32,100 --> 00:26:34,080
在那個分析中發現，你知道

779
00:26:34,080 --> 00:26:35,640
基本上只是

780
00:26:35,640 --> 00:26:37,440
對這些域中的每一個的一種粗略計算，

781
00:26:37,440 --> 00:26:40,679
語法實際上是非常

782
00:26:40,679 --> 00:26:42,779
少的信息

783
00:26:42,779 --> 00:26:46,400
學習語法不需要那麼多信息，

784
00:26:46,400 --> 00:26:49,320
而

785
00:26:49,320 --> 00:26:52,740
你獲得的大部分信息實際上是關於語義的，所以

786
00:26:52,740 --> 00:26:55,740
指定你知道 30 到 50 000 個

787
00:26:55,740 --> 00:26:57,720
不同的單詞含義，即使

788
00:26:57,720 --> 00:27:00,000
每個含義

789
00:27:00,000 --> 00:27:02,340
只是幾個位 就像

790
00:27:02,340 --> 00:27:04,620
那樣需要大量信息，

791
00:27:04,620 --> 00:27:06,360
可能每次會議都不止

792
00:27:06,360 --> 00:27:08,460
於此，所以

793
00:27:08,460 --> 00:27:11,279
嗯嗯，這可能會讓

794
00:27:11,279 --> 00:27:12,659
我猜測

795
00:27:12,659 --> 00:27:14,820
大型語言模型正在發生的事情是

796
00:27:14,820 --> 00:27:16,320
他們的大部分訓練數據都是關於單詞的

797
00:27:16,320 --> 00:27:18,600
語義，你可以考慮讓

798
00:27:18,600 --> 00:27:20,760
孩子們正確理解單詞語義的其他方式，

799
00:27:20,760 --> 00:27:22,140
這不僅僅是

800
00:27:22,140 --> 00:27:24,600
文本中的一種共現模式，

801
00:27:24,600 --> 00:27:27,360
嗯，但我同意所有這些都

802
00:27:27,360 --> 00:27:29,039
懸而未決，看到

803
00:27:29,039 --> 00:27:30,960
會發生什麼真的很令人興奮所以 是的，我知道

804
00:27:30,960 --> 00:27:32,640


805
00:27:32,640 --> 00:27:35,279
Lindsay 實驗室的一些早期結果表明，至少

806
00:27:35,279 --> 00:27:37,740
僅限於生態有效你

807
00:27:37,740 --> 00:27:40,919
知道培訓網站呃模型似乎

808
00:27:40,919 --> 00:27:42,840
概括你知道英語的線性規則是的

809
00:27:42,840 --> 00:27:44,940
沒有問題形成

810
00:27:44,940 --> 00:27:46,620
除了層次規則之外的 ROM

811
00:27:46,620 --> 00:27:48,120
正確的層次結構 規則所以我認為

812
00:27:48,120 --> 00:27:49,980
有一種真正的意義，你知道

813
00:27:49,980 --> 00:27:52,020
正確的

814
00:27:52,020 --> 00:27:54,000
句法價格和歸納偏差的空間

815
00:27:54,000 --> 00:27:56,220
確實還沒有真正解決，

816
00:27:56,220 --> 00:27:57,960
但至少在我看來很

817
00:27:57,960 --> 00:27:59,400
明顯必須有一些所以

818
00:27:59,400 --> 00:28:01,320
還有一些證據

819
00:28:01,320 --> 00:28:02,700
表明，英語兒童會回到

820
00:28:02,700 --> 00:28:04,679
這個頻率問題，即

821
00:28:04,679 --> 00:28:06,360
英語兒童有時會在

822
00:28:06,360 --> 00:28:08,100


823
00:28:08,100 --> 00:28:10,140


824
00:28:10,140 --> 00:28:11,880


825
00:28:11,880 --> 00:28:13,980
長距離 wh 問題的較低補碼位置的指定位置拼出運動的中間副本，所以

826
00:28:13,980 --> 00:28:15,360
Thornton 和一些人有一篇論文 其他關於

827
00:28:15,360 --> 00:28:18,120
這個的論文所以他們說嗯你認為哪個人

828
00:28:18,120 --> 00:28:19,919
做了那個而不是

829
00:28:19,919 --> 00:28:21,900
你認為哪個人做了那個所以這是

830
00:28:21,900 --> 00:28:23,159
一個有趣的你知道小姐設置

831
00:28:23,159 --> 00:28:25,020
因為有些語言確實拼出

832
00:28:25,020 --> 00:28:26,760
了這些中間副本但

833
00:28:26,760 --> 00:28:28,799
英語不是這樣 孩子

834
00:28:28,799 --> 00:28:30,779
在設置他們的語法時犯了錯誤，但

835
00:28:30,779 --> 00:28:32,820
輸入的頻率實際上是零

836
00:28:32,820 --> 00:28:35,159
，所以我們共同的朋友加里馬庫斯

837
00:28:35,159 --> 00:28:36,779
也反對頻率

838
00:28:36,779 --> 00:28:39,000
決定孩子的輸出在

839
00:28:39,000 --> 00:28:41,159
德語名詞複數的情況下是某種更規則的

840
00:28:41,159 --> 00:28:42,779
形式 首選而

841
00:28:42,779 --> 00:28:44,580
不是常見的，並且有很多這樣的

842
00:28:44,580 --> 00:28:46,559
例子，所以有時聲稱

843
00:28:46,559 --> 00:28:49,080
受試者經歷被動，

844
00:28:49,080 --> 00:28:50,460
受試者被動地經歷

845
00:28:50,460 --> 00:28:52,559
某事或在理解研究中非常延遲的孩子

846
00:28:52,559 --> 00:28:54,299
直到八歲左右，

847
00:28:54,299 --> 00:28:56,039
因為他們在輸入中不是很頻繁

848
00:28:56,039 --> 00:28:56,880


849
00:28:56,880 --> 00:28:59,220
但是肯 Wexler 和他的同事

850
00:28:59,220 --> 00:29:01,260
經歷了 um subject experience Double H

851
00:29:01,260 --> 00:29:03,539
問題，比如誰喜歡 Mary，他們

852
00:29:03,539 --> 00:29:05,820
發現這些問題

853
00:29:05,820 --> 00:29:07,500
在輸入中與 subject 和 experience

854
00:29:07,500 --> 00:29:09,659
of passives 一樣不常見，但是孩子們在

855
00:29:09,659 --> 00:29:10,980
理解這些問題的研究中沒有問題，

856
00:29:10,980 --> 00:29:13,860
但他們確實有理解問題

857
00:29:13,860 --> 00:29:16,020
口頭被動的主題體驗，所以

858
00:29:16,020 --> 00:29:17,880
頻率再次似乎是

859
00:29:17,880 --> 00:29:19,380
無關緊要的，或者至少它不是

860
00:29:19,380 --> 00:29:20,940
解釋性的，我想這

861
00:29:20,940 --> 00:29:22,320
對理論

862
00:29:22,320 --> 00:29:25,080
構建沒有解釋性，所以 LMS 如何幫助解決這些

863
00:29:25,080 --> 00:29:27,059
你知道的不同情況，當

864
00:29:27,059 --> 00:29:28,440
除了頻率之外顯然還有其他事情發生時

865
00:29:28,440 --> 00:29:30,960
所以校友們，你知道他們似乎

866
00:29:30,960 --> 00:29:33,419
再次概括回到

867
00:29:33,419 --> 00:29:35,100
你論文中的案例，

868
00:29:35,100 --> 00:29:36,899
你表明他們

869
00:29:36,899 --> 00:29:38,399
概括了無色

870
00:29:38,399 --> 00:29:41,279
屏幕想法的結構，這通常很酷，

871
00:29:41,279 --> 00:29:43,080
嗯，但積極的刺激從來沒有

872
00:29:43,080 --> 00:29:44,520
真正 關於無法從

873
00:29:44,520 --> 00:29:46,380
統計學上學習語言我知道你的

874
00:29:46,380 --> 00:29:48,059
說法是正確的，但喬姆斯基

875
00:29:48,059 --> 00:29:49,559
在 50 年代關於

876
00:29:49,559 --> 00:29:51,779
當今統計模型的觀點不適用於

877
00:29:51,779 --> 00:29:53,700
2023 年的商業 LMS，這是

878
00:29:53,700 --> 00:29:55,440
正確的，但我們不能用那個單一的

879
00:29:55,440 --> 00:29:57,539
觀點來破壞 你知道整個幾何

880
00:29:57,539 --> 00:29:59,520
企業喬姆斯基的基本

881
00:29:59,520 --> 00:30:01,080
觀點是你可以有一個

882
00:30:01,080 --> 00:30:02,700
語法結構，其中每個

883
00:30:02,700 --> 00:30:04,980
圖表都有零頻率並且它也

884
00:30:04,980 --> 00:30:06,899
無法為概念界面提供清晰可解釋的

885
00:30:06,899 --> 00:30:08,039
說明，

886
00:30:08,039 --> 00:30:09,840
因此其他思維

887
00:30:09,840 --> 00:30:11,580
繫統的界面就像你展示的那樣

888
00:30:11,580 --> 00:30:13,980
你的論文 GPT 模仿了像 pull

889
00:30:13,980 --> 00:30:16,559
the screen ideas 這樣的例子，但是你又知道

890
00:30:16,559 --> 00:30:18,840
這句話在谷歌上產生了超過 150 000 個

891
00:30:18,840 --> 00:30:20,700
結果並且它

892
00:30:20,700 --> 00:30:22,620
在文獻中被廣泛討論它能夠

893
00:30:22,620 --> 00:30:24,480
模仿它可以模仿的事實並

894
00:30:24,480 --> 00:30:26,640
不能真正告訴我們太多在 至少我們真的

895
00:30:26,640 --> 00:30:27,840
不能很有信心地說任何話

896
00:30:27,840 --> 00:30:30,899
所以你知道

897
00:30:30,899 --> 00:30:32,580
都柏林大學背後的阿比巴最近引用了這句話

898
00:30:32,580 --> 00:30:34,380
呃不要把你自己的

899
00:30:34,380 --> 00:30:36,840
輕信誤認為是電影的智慧

900
00:30:36,840 --> 00:30:38,880
事實上甚至年輕的浣熊俠聯盟去年也寫道

901
00:30:38,880 --> 00:30:40,500
評論家是正確的 指責

902
00:30:40,500 --> 00:30:42,480
LMS 從事一種

903
00:30:42,480 --> 00:30:43,919
模仿

904
00:30:43,919 --> 00:30:46,860
um 和

905
00:30:46,860 --> 00:30:48,840
你在論文中給出的來自 gbt 的例句實際上

906
00:30:48,840 --> 00:30:50,700
做得不好，因為正如你所說，

907
00:30:50,700 --> 00:30:52,320
你可能知道

908
00:30:52,320 --> 00:30:54,240
訓練數據中很少見的無意義語言，但

909
00:30:54,240 --> 00:30:55,740
它們可以 要么做，要么他們做不到，但是就給

910
00:30:55,740 --> 00:30:57,120


911
00:30:57,120 --> 00:30:59,880
我們 10 個這樣的例子而言，沒有中間立場，所以你

912
00:30:59,880 --> 00:31:02,880
有無色的綠色想法，這些想法與

913
00:31:02,880 --> 00:31:04,679


914
00:31:04,679 --> 00:31:06,840
諸如棕色閃閃發光的兔子、白色閃閃發光的

915
00:31:06,840 --> 00:31:09,899
兔子、黑色閃亮的袋鼠、

916
00:31:09,899 --> 00:31:12,360
綠色閃閃發光的猴子之類的語義對象截然不同

917
00:31:12,360 --> 00:31:15,120
黃色令人眼花繚亂的獅子 紅色填充

918
00:31:15,120 --> 00:31:16,320
元素 對，這些都像是

919
00:31:16,320 --> 00:31:18,899
語義上的怪異，

920
00:31:18,899 --> 00:31:20,820
有點奇怪，但它們仍然像法律

921
00:31:20,820 --> 00:31:22,440
結構，它們是一種有意義的

922
00:31:22,440 --> 00:31:25,320
合成語義對象，

923
00:31:25,320 --> 00:31:27,179
嗯，對，

924
00:31:27,179 --> 00:31:29,580
我只是說是的，是的，我，我，我的

925
00:31:29,580 --> 00:31:33,179
意思是，所以我也許我可以 可以

926
00:31:33,179 --> 00:31:34,799
先對第一點做出正確回應，

927
00:31:34,799 --> 00:31:36,120
所以

928
00:31:36,120 --> 00:31:37,799
嗯，嗯，你開始談論

929
00:31:37,799 --> 00:31:40,140
這些其他呃類型的習得

930
00:31:40,140 --> 00:31:42,179
模式，這些模式可能不會直接映射

931
00:31:42,179 --> 00:31:44,279
到頻率，

932
00:31:44,279 --> 00:31:47,159
嗯，我認為

933
00:31:47,159 --> 00:31:50,640
認為現代學習

934
00:31:50,640 --> 00:31:53,039
模型實際上是錯誤的 應該只是基於頻率，

935
00:31:53,039 --> 00:31:54,899
因為

936
00:31:54,899 --> 00:31:57,120
嗯，他們顯然正在學習非常

937
00:31:57,120 --> 00:31:59,580
複雜的規則或

938
00:31:59,580 --> 00:32:02,399
結構或其他東西，

939
00:32:02,399 --> 00:32:03,899
嗯，我認為當

940
00:32:03,899 --> 00:32:06,600
他們正在學習時，他們很可能正在學習，他們

941
00:32:06,600 --> 00:32:08,580
在某種意義上正在尋找一個 簡單

942
00:32:08,580 --> 00:32:10,559
或簡約的

943
00:32:10,559 --> 00:32:12,360
嗯嗯，對

944
00:32:12,360 --> 00:32:13,980
他們正確看到的數據的解釋以及這些數據如何

945
00:32:13,980 --> 00:32:16,080
緩存在神經網絡中可能很

946
00:32:16,080 --> 00:32:19,200
複雜，你知道這取決於

947
00:32:19,200 --> 00:32:20,880
嗯你知道參數和

948
00:32:20,880 --> 00:32:22,679
學習算法的細節以及和和

949
00:32:22,679 --> 00:32:24,480
那些事情

950
00:32:24,480 --> 00:32:27,000
嗯，但我認為它是呃我想我可能會

951
00:32:27,000 --> 00:32:29,279
懷疑情況可能是這樣嗯嗯

952
00:32:29,279 --> 00:32:31,740


953
00:32:31,740 --> 00:32:35,640
他們是他們正在

954
00:32:35,640 --> 00:32:38,399
學習一組複雜的

955
00:32:38,399 --> 00:32:40,799
東西正確的一種複雜的東西

956
00:32:40,799 --> 00:32:43,799
一系列的規則和構造

957
00:32:43,799 --> 00:32:46,919
um 這意味著我認為

958
00:32:46,919 --> 00:32:49,380
um 他們的概括可能就像

959
00:32:49,380 --> 00:32:52,500
你給的人的例子

960
00:32:52,500 --> 00:32:55,440
um 可能在輸入權中有點不連續

961
00:32:55,440 --> 00:32:57,720
所以有時你

962
00:32:57,720 --> 00:33:00,000
可以想像看到一些字符串

963
00:33:00,000 --> 00:33:02,220
導致 你的語法和數據的最簡單的

964
00:33:02,220 --> 00:33:03,840
語法，你

965
00:33:03,840 --> 00:33:06,059
到目前為止看到的是一個預測一個

966
00:33:06,059 --> 00:33:09,120
看不見的字符串的正確和

967
00:33:09,120 --> 00:33:12,360
嗯，如果發生這種情況，那麼你將把

968
00:33:12,360 --> 00:33:14,100
數據學習一種

969
00:33:14,100 --> 00:33:16,860
表示，它在一些

970
00:33:16,860 --> 00:33:19,440
看不見的小說中概括 到目前為止，嗯，

971
00:33:19,440 --> 00:33:21,720
純粹是因為這種概括

972
00:33:21,720 --> 00:33:23,460
是對數據的最簡單描述，

973
00:33:23,460 --> 00:33:25,019
你已經看到了迄今為止的場景，

974
00:33:25,019 --> 00:33:25,980
我認為這就是

975
00:33:25,980 --> 00:33:28,320
語言學家試圖做的事情，嘗試呃

976
00:33:28,320 --> 00:33:29,700
看看數據並提出

977
00:33:29,700 --> 00:33:31,260
它的理論，然後有時該

978
00:33:31,260 --> 00:33:33,419
理論正確地預測了一些新現像

979
00:33:33,419 --> 00:33:35,840
或一些新類型的句子，

980
00:33:35,840 --> 00:33:38,159
因此，如果他們正在學習

981
00:33:38,159 --> 00:33:41,100
足夠豐富的理論空間，

982
00:33:41,100 --> 00:33:42,899
那麼你就不會知道

983
00:33:42,899 --> 00:33:45,000
他們這樣做是不合理或出乎意料的

984
00:33:45,000 --> 00:33:47,039
現在也展示這些模式，

985
00:33:47,039 --> 00:33:48,899
無論他們是否這樣做，我認為這

986
00:33:48,899 --> 00:33:51,299
仍然是一個開放的經驗問題，

987
00:33:51,299 --> 00:33:52,740


988
00:33:52,740 --> 00:33:54,120
嗯，因為我們必須用

989
00:33:54,120 --> 00:33:55,620
少量數據訓練他們並測試他們的

990
00:33:55,620 --> 00:33:57,480
概括，以及這些

991
00:33:57,480 --> 00:33:58,260
事情，

992
00:33:58,260 --> 00:34:00,120
嗯，但我不知道 不要認為

993
00:34:00,120 --> 00:34:01,620


994
00:34:01,620 --> 00:34:03,899
你知道人類做的事情

995
00:34:03,899 --> 00:34:06,059
並非純粹基於頻率這一事實是任何

996
00:34:06,059 --> 00:34:07,860
證據都是正確的，因為

997
00:34:07,860 --> 00:34:09,300
一旦你學習了豐富而

998
00:34:09,300 --> 00:34:10,980
有趣的理論類別，那麼

999
00:34:10,980 --> 00:34:13,980
這就是預期的行為，

1000
00:34:13,980 --> 00:34:16,980
嗯實際上 我大約一年前有一篇論文，

1001
00:34:16,980 --> 00:34:18,719
我認為你很

1002
00:34:18,719 --> 00:34:20,040
熟悉

1003
00:34:20,040 --> 00:34:22,560
um uh Yang 和 pianta dosi

1004
00:34:22,560 --> 00:34:24,179
我們在哪裡

1005
00:34:24,179 --> 00:34:26,879
um uh 看著 um

1006
00:34:26,879 --> 00:34:29,280
uh 當你給

1007
00:34:29,280 --> 00:34:32,639
程序學習模型字符串時會發生什麼 呃

1008
00:34:32,639 --> 00:34:34,679
不同的形式語言所以想像

1009
00:34:34,679 --> 00:34:35,820


1010
00:34:35,820 --> 00:34:38,760
嗯給出一個通用模型只是你

1011
00:34:38,760 --> 00:34:41,159
知道 10 或 20 個可能

1012
00:34:41,159 --> 00:34:43,500
遵循某種模式的簡單字符串然後要求它

1013
00:34:43,500 --> 00:34:46,199
找到一個程序可以解釋該

1014
00:34:46,199 --> 00:34:49,320
數據這通常意味著你知道找到

1015
00:34:49,320 --> 00:34:50,940
嗯嗯找到一些 一種以編程方式

1016
00:34:50,940 --> 00:34:52,679


1017
00:34:52,679 --> 00:34:54,839
在字符串中寫下模式的方法，

1018
00:34:54,839 --> 00:34:56,280
嗯，在那個圖中，我們有一篇論文，

1019
00:34:56,280 --> 00:34:58,020
它與這一點真正相關，

1020
00:34:58,020 --> 00:34:59,820


1021
00:34:59,820 --> 00:35:02,640
嗯，那種

1022
00:35:02,640 --> 00:35:04,200
模型做出的

1023
00:35:04,200 --> 00:35:06,660
呃概括，嗯，我認為有點 定性地

1024
00:35:06,660 --> 00:35:08,160
就像你為人們描述的那樣，

1025
00:35:08,160 --> 00:35:10,560


1026
00:35:10,560 --> 00:35:12,060
嗯，你可以給他們少量

1027
00:35:12,060 --> 00:35:13,980
的數據，它會以

1028
00:35:13,980 --> 00:35:16,740
很高的概率預測看不見的字符串，

1029
00:35:16,740 --> 00:35:18,420
即使在訓練輸入中的頻率為零，

1030
00:35:18,420 --> 00:35:20,280
也是如此的原因

1031
00:35:20,280 --> 00:35:22,740
通常，您所看到的對數據的最

1032
00:35:22,740 --> 00:35:24,660
簡潔的計算描述

1033
00:35:24,660 --> 00:35:26,640
是

1034
00:35:26,640 --> 00:35:29,640
預測一些特定的，嗯，新的看不見的

1035
00:35:29,640 --> 00:35:32,940
輸出，因此該模型本質上是

1036
00:35:32,940 --> 00:35:34,800


1037
00:35:34,800 --> 00:35:36,839
Chader 和 Vitani 程序學習的一種實現，

1038
00:35:36,839 --> 00:35:38,160


1039
00:35:38,160 --> 00:35:40,619
我的想法 較早提出來，

1040
00:35:40,619 --> 00:35:42,900
嗯，但

1041
00:35:42,900 --> 00:35:43,980
如果你在

1042
00:35:43,980 --> 00:35:45,660
這些爭論的背景下思考孩子們說不

1043
00:35:45,660 --> 00:35:48,599
尋常或意想不到的事情，就像

1044
00:35:48,599 --> 00:35:50,280
所有這些類型的

1045
00:35:50,280 --> 00:35:52,859
賬戶都預測的那樣，我認為你知道這一點，因為

1046
00:35:52,859 --> 00:35:54,180
只要 這些東西有效地

1047
00:35:54,180 --> 00:35:55,680
比較了一個有趣的語法空間，

1048
00:35:55,680 --> 00:35:56,760


1049
00:35:56,760 --> 00:35:58,079
嗯，然後他們將展示那種

1050
00:35:58,079 --> 00:35:59,760
行為，我認為

1051
00:35:59,760 --> 00:36:04,680
嗯，是的，很好，所以我想你知道

1052
00:36:04,680 --> 00:36:06,960
這個論點是至少從

1053
00:36:06,960 --> 00:36:10,140
性別的角度來看，語法是

1054
00:36:10,140 --> 00:36:13,140
分開運作的 但它仍然

1055
00:36:13,140 --> 00:36:15,359
映射到語義 它正確地告知

1056
00:36:15,359 --> 00:36:17,040
語用學 所以在中東

1057
00:36:17,040 --> 00:36:18,480
程序語法顯然是沒有意義的

1058
00:36:18,480 --> 00:36:20,160
它非常小 它只是它只是一個

1059
00:36:20,160 --> 00:36:22,320
線性化和標記 它們是

1060
00:36:22,320 --> 00:36:24,180
僅有的兩個操作你有一個

1061
00:36:24,180 --> 00:36:26,220
線性化算法到中心電機

1062
00:36:26,220 --> 00:36:27,900
系統和某種

1063
00:36:27,900 --> 00:36:30,480
在概念系統的嗯中心的分類算法

1064
00:36:30,480 --> 00:36:32,220


1065
00:36:32,220 --> 00:36:33,839
嗯所以喬姆斯基的架構有點

1066
00:36:33,839 --> 00:36:35,940
依賴於將句法映射

1067
00:36:35,940 --> 00:36:37,560
到語義的過程，它是泡沫意思

1068
00:36:37,560 --> 00:36:39,960
規則它不僅僅是結構而且

1069
00:36:39,960 --> 00:36:42,180
它不僅僅是意義所以 LMS 真的

1070
00:36:42,180 --> 00:36:43,680
沒有這個 映射過程

1071
00:36:43,680 --> 00:36:45,180
就像映射到語義在哪裡，

1072
00:36:45,180 --> 00:36:47,160
如果有映射，

1073
00:36:47,160 --> 00:36:48,480
映射過程看起來像什麼，

1074
00:36:48,480 --> 00:36:50,099
它的語義屬性是什麼，

1075
00:36:50,099 --> 00:36:52,320
你知道這些是什麼，

1076
00:36:52,320 --> 00:36:54,000
語義屬性放在

1077
00:36:54,000 --> 00:36:55,500
它們自己的集合上是什麼 對

1078
00:36:55,500 --> 00:36:57,180
營銷過程的限制，就像他們對

1079
00:36:57,180 --> 00:36:58,980
自然語言所做的那樣，你

1080
00:36:58,980 --> 00:37:01,079
知道嗎，嗯，做這些限制相互通知，

1081
00:37:01,079 --> 00:37:02,640
他們是一種

1082
00:37:02,640 --> 00:37:05,579
來回過程，就像元素似乎並

1083
00:37:05,579 --> 00:37:07,260
沒有真正描述這種形式

1084
00:37:07,260 --> 00:37:09,359
意味著配對 正確，例如

1085
00:37:09,359 --> 00:37:11,339
哪些字符串的含義

1086
00:37:11,339 --> 00:37:14,640
正確 抱歉，您是說

1087
00:37:14,640 --> 00:37:16,740
嗯，它們根本沒有語義，

1088
00:37:16,740 --> 00:37:18,599
還是說

1089
00:37:18,599 --> 00:37:21,180


1090
00:37:21,180 --> 00:37:23,400
結構如何映射到

1091
00:37:23,400 --> 00:37:25,500
語義之間沒有明確的描述 是的，後者 是的，所以他們

1092
00:37:25,500 --> 00:37:27,300
顯然有一些潛在的某種

1093
00:37:27,300 --> 00:37:28,800
語義 我知道你已經爭論過一個

1094
00:37:28,800 --> 00:37:30,180
概念角色 理論在這裡是相關的 對

1095
00:37:30,180 --> 00:37:31,920
吧，它的其餘部分可能

1096
00:37:31,920 --> 00:37:33,900
有點神秘，但實際的大豆

1097
00:37:33,900 --> 00:37:35,339
語言學在

1098
00:37:35,339 --> 00:37:36,900
映射過程的理論 它本身是

1099
00:37:36,900 --> 00:37:39,060
明確的，你可以在行動中看到它，

1100
00:37:39,060 --> 00:37:40,440
你可以

1101
00:37:40,440 --> 00:37:42,000
在 Psych 語言模型中測試它的不同理論，你有什麼

1102
00:37:42,000 --> 00:37:44,700
實際的規則你

1103
00:37:44,700 --> 00:37:46,079
知道的那種你知道的約束

1104
00:37:46,079 --> 00:37:48,119
歧義在你知道一個

1105
00:37:48,119 --> 00:37:50,400
詞的多重含義或一個意義上的歧義 構造

1106
00:37:50,400 --> 00:37:53,040
多重解釋等等，是的，

1107
00:37:53,040 --> 00:37:55,200
我的意思是，如果你認為他們有

1108
00:37:55,200 --> 00:37:57,599
語義，那麼我認為他們必須

1109
00:37:57,599 --> 00:37:59,640
有從語法到語義的映射，嗯，

1110
00:37:59,640 --> 00:38:00,960


1111
00:38:00,960 --> 00:38:03,599
我同意，這並不是說沒有人

1112
00:38:03,599 --> 00:38:04,980
真正理解他們是如何

1113
00:38:04,980 --> 00:38:07,560
在任何深層次上工作的 是的，所以我同意，

1114
00:38:07,560 --> 00:38:10,140
它不像

1115
00:38:10,140 --> 00:38:11,940
生成語法和語義中所說的那樣清楚

1116
00:38:11,940 --> 00:38:13,859


1117
00:38:13,859 --> 00:38:15,180


1118
00:38:15,180 --> 00:38:17,880


1119
00:38:17,880 --> 00:38:19,920


1120
00:38:19,920 --> 00:38:21,480
或者像這樣的

1121
00:38:21,480 --> 00:38:23,339
事情是

1122
00:38:23,339 --> 00:38:24,660
嗯你知道那不是他們

1123
00:38:24,660 --> 00:38:27,060
工作的方式但

1124
00:38:27,060 --> 00:38:28,859
嗯我我只是我我不會

1125
00:38:28,859 --> 00:38:32,160
想當然地認為它必須像那樣

1126
00:38:32,160 --> 00:38:34,619
嗯嗯這可能是他們的

1127
00:38:34,619 --> 00:38:36,420
工作方式實際上是我們的方式 正確地工作，

1128
00:38:36,420 --> 00:38:38,760
嗯，一切都在

1129
00:38:38,760 --> 00:38:40,800
一些高維向量空間中表示，並且

1130
00:38:40,800 --> 00:38:43,740
有一些複雜的呃方式，

1131
00:38:43,740 --> 00:38:46,200
其中向量語義隨著

1132
00:38:46,200 --> 00:38:48,240
每個額外的單詞或

1133
00:38:48,240 --> 00:38:51,480
語言流中的任何東西而更新，

1134
00:38:51,480 --> 00:38:53,940
但就像我一樣，我認為很明顯

1135
00:38:53,940 --> 00:38:55,320
他們有一些 一種

1136
00:38:55,320 --> 00:38:57,660


1137
00:38:57,660 --> 00:38:59,099
句子語義的表示，就像他們可以

1138
00:38:59,099 --> 00:39:01,260
至少大約回答問題一樣

1139
00:39:01,260 --> 00:39:02,760


1140
00:39:02,760 --> 00:39:04,380


1141
00:39:04,380 --> 00:39:06,720


1142
00:39:06,720 --> 00:39:07,740


1143
00:39:07,740 --> 00:39:10,500


1144
00:39:10,500 --> 00:39:12,780
嗯，我認為他們是，

1145
00:39:12,780 --> 00:39:14,040
嗯，他們肯定

1146
00:39:14,040 --> 00:39:16,920
代表語義，

1147
00:39:16,920 --> 00:39:20,040
嗯，你知道更新它，因為他們

1148
00:39:20,040 --> 00:39:21,599
處理語言，它恰好

1149
00:39:21,599 --> 00:39:23,400
看起來不像其他正式

1150
00:39:23,400 --> 00:39:24,599
理論，

1151
00:39:24,599 --> 00:39:26,400
嗯，我想我不明白 為什麼

1152
00:39:26,400 --> 00:39:27,720
這是一個像其他

1153
00:39:27,720 --> 00:39:29,640
形式理論一樣的問題 可能只是你知道

1154
00:39:29,640 --> 00:39:31,920
近似值很差或者完全

1155
00:39:31,920 --> 00:39:33,720
錯誤

1156
00:39:33,720 --> 00:39:35,520


1157
00:39:35,520 --> 00:39:37,260


1158
00:39:37,260 --> 00:39:39,359


1159
00:39:39,359 --> 00:39:41,520


1160
00:39:41,520 --> 00:39:42,780
這些事情做對了，所以另一種

1161
00:39:42,780 --> 00:39:45,240
思考方式是你知道 LMS

1162
00:39:45,240 --> 00:39:47,760
很好 LMS 是壓縮算法，

1163
00:39:47,760 --> 00:39:49,740
但自然語言理解

1164
00:39:49,740 --> 00:39:51,540
更像是解壓，

1165
00:39:51,540 --> 00:39:54,180
它消除了 X 的歧義

1166
00:39:54,180 --> 00:39:56,099
XYZ 的意義，這一切都是關於

1167
00:39:56,099 --> 00:39:58,020
對你知道的進行推斷

1168
00:39:58,020 --> 00:39:59,579
不在

1169
00:39:59,579 --> 00:40:01,859
訓練數據中的概念之間的元關係，所以

1170
00:40:01,859 --> 00:40:03,180
Melanie Mitchell 給出了一些例子，比如

1171
00:40:03,180 --> 00:40:06,119
在上面，你知道她又在上面，

1172
00:40:06,119 --> 00:40:08,700
呃，在框的頂部，所有這些都

1173
00:40:08,700 --> 00:40:10,140
隨著上下文而變化，所以有很多

1174
00:40:10,140 --> 00:40:11,880
其他事情正在發生，

1175
00:40:11,880 --> 00:40:13,260
嗯，我想你在論文中討論了其中的一些

1176
00:40:13,260 --> 00:40:16,440
例子，所以你知道，

1177
00:40:16,440 --> 00:40:18,119
嗯，但是語言的能力

1178
00:40:18,119 --> 00:40:20,940
至少仍然不是在這種語言理論下，

1179
00:40:20,940 --> 00:40:22,920
它不是關於字符串

1180
00:40:22,920 --> 00:40:25,200
生成，而是關於這種形式 意思是

1181
00:40:25,200 --> 00:40:27,540
配對機器所以有時這在

1182
00:40:27,540 --> 00:40:29,400
屬格傳統中甚至認為

1183
00:40:29,400 --> 00:40:31,859
語義的一切都是公正和正確的所以

1184
00:40:31,859 --> 00:40:33,540
保羅彼得羅夫斯基的聯合是有

1185
00:40:33,540 --> 00:40:36,000
一些是人類語義是公正的而且就是這樣嗯這又是

1186
00:40:36,000 --> 00:40:37,500


1187
00:40:37,500 --> 00:40:39,900
非常簡單優雅

1188
00:40:39,900 --> 00:40:42,000
它是它是它是可解釋的 它

1189
00:40:42,000 --> 00:40:43,920
與你知道的很多事情兼容，

1190
00:40:43,920 --> 00:40:46,320
或者可能會在你的

1191
00:40:46,320 --> 00:40:47,940
詞的脖子上發生，但不管

1192
00:40:47,940 --> 00:40:49,859
它仍然是你知道自然語言

1193
00:40:49,859 --> 00:40:51,540
仍然更具組合性，

1194
00:40:51,540 --> 00:40:54,060
比如呃你知道形式

1195
00:40:54,060 --> 00:40:55,260
語言只是為了做出明確的

1196
00:40:55,260 --> 00:40:56,820
區分 已經使它們具有

1197
00:40:56,820 --> 00:40:58,260
更豐富的結構組合，有

1198
00:40:58,260 --> 00:41:00,839
更多的東西在發生，嗯，也許所以

1199
00:41:00,839 --> 00:41:02,160
之前有人指出，你

1200
00:41:02,160 --> 00:41:03,480
知道諸如基於注意力的機器

1201
00:41:03,480 --> 00:41:05,640
機制和變形金剛之類的東西，

1202
00:41:05,640 --> 00:41:07,800
嗯，允許離散

1203
00:41:07,800 --> 00:41:10,320
令牌綁定的組合，這更接近於

1204
00:41:10,320 --> 00:41:12,359
合併 like operator than simple

1205
00:41:12,359 --> 00:41:14,640
recurrent matrix multiplication

1206
00:41:14,640 --> 00:41:16,140
um but you know the issue of binary

1207
00:41:16,140 --> 00:41:17,460
branching binary branching government

1208
00:41:17,460 --> 00:41:19,260
只是在這裡選擇另一個例子來

1209
00:41:19,260 --> 00:41:20,640
談論完整的含義規則

1210
00:41:20,640 --> 00:41:23,640
一個原則二元分支圖像是

1211
00:41:23,640 --> 00:41:24,839
一個有趣的問題，但幾何

1212
00:41:24,839 --> 00:41:26,700
語法一直對

1213
00:41:26,700 --> 00:41:28,740
不同的人開放 合成計算中這種明顯約束的起源和位置

1214
00:41:28,740 --> 00:41:30,660


1215
00:41:30,660 --> 00:41:31,800
就像它

1216
00:41:31,800 --> 00:41:33,540
來自哪裡可能是

1217
00:41:33,540 --> 00:41:34,980
合併的條件可能是由平滑

1218
00:41:34,980 --> 00:41:37,079
系統強加的可能是一種你

1219
00:41:37,079 --> 00:41:39,060
知道誰知道的先驗實際上它是一些

1220
00:41:39,060 --> 00:41:40,500
最近的工作生成語法

1221
00:41:40,500 --> 00:41:43,859
試圖建立並消除所有關於

1222
00:41:43,859 --> 00:41:46,440
婚姻

1223
00:41:46,440 --> 00:41:47,700
權利的理論假設也許集合論不是

1224
00:41:47,700 --> 00:41:48,780


1225
00:41:48,780 --> 00:41:50,339
建模生成語法的最佳方法也許瑪麗亞

1226
00:41:50,339 --> 00:41:51,540
邏輯解釋更合適

1227
00:41:51,540 --> 00:41:53,520
那裡有很多其他最近的想法都與

1228
00:41:53,520 --> 00:41:55,020


1229
00:41:55,020 --> 00:41:57,540
喬姆斯基的方法是正確的事實上

1230
00:41:57,540 --> 00:41:58,680
是的特朗普

1231
00:41:58,680 --> 00:42:00,060
最喜歡的事情之一就是當他被

1232
00:42:00,060 --> 00:42:01,380
證明是錯誤的時候很多這些

1233
00:42:01,380 --> 00:42:03,720
理論都反對核心

1234
00:42:03,720 --> 00:42:06,300
主流極簡主義架構但是是的

1235
00:42:06,300 --> 00:42:08,640
我認為這是一個非常多樣化的

1236
00:42:08,640 --> 00:42:11,839
喜歡 充滿活力的領域

1237
00:42:11,839 --> 00:42:15,119
Bornstein 的人，你認識 petrovsky uh uh

1238
00:42:15,119 --> 00:42:17,520
hajipura 他們在根本上不同意

1239
00:42:17,520 --> 00:42:19,380


1240
00:42:19,380 --> 00:42:20,940
化學語法的主流觀點，但

1241
00:42:20,940 --> 00:42:21,960
仍有更多的

1242
00:42:21,960 --> 00:42:24,240
分歧空間，但它仍然

1243
00:42:24,240 --> 00:42:26,400
與正確設置核心假設兼容，所以

1244
00:42:26,400 --> 00:42:27,599
很多 大衛我只是

1245
00:42:27,599 --> 00:42:29,400
在這個核心方面穿著例如有點偏離

1246
00:42:29,400 --> 00:42:31,920
但它仍然試圖

1247
00:42:31,920 --> 00:42:33,240
在不同的正式系統中建立這些直覺

1248
00:42:33,240 --> 00:42:34,500


1249
00:42:34,500 --> 00:42:36,000
嗯所以你知道

1250
00:42:36,000 --> 00:42:38,099


1251
00:42:38,099 --> 00:42:40,320
我想再次了解你的想法嗯

1252
00:42:40,320 --> 00:42:42,240
我提到米切爾是對的所以米其林

1253
00:42:42,240 --> 00:42:44,579
鮑爾斯呃 2020 年，他們有這篇論文

1254
00:42:44,579 --> 00:42:47,040
試驗列出了遞歸網絡，

1255
00:42:47,040 --> 00:42:48,359
我想你可能

1256
00:42:48,359 --> 00:42:49,859
知道這是對的，所以這是一個很好的

1257
00:42:49,859 --> 00:42:51,060
例子，只是為了觸及

1258
00:42:51,060 --> 00:42:53,099
問題的核心，所以遞歸神經

1259
00:42:53,099 --> 00:42:54,780
網絡已經被證明可以準確地

1260
00:42:54,780 --> 00:42:56,520
模擬你所知道的非 - 動詞數協議，

1261
00:42:56,520 --> 00:42:58,020
但 Mitchell 和 Barrow 表明，

1262
00:42:58,020 --> 00:43:00,060
這些網絡還將

1263
00:43:00,060 --> 00:43:01,680
與不自然的句子

1264
00:43:01,680 --> 00:43:03,359
結構達成數字協議，因此

1265
00:43:03,359 --> 00:43:04,859
自然語言中沒有的結構以及

1266
00:43:04,859 --> 00:43:06,540
人類很難正確處理的結構，

1267
00:43:06,540 --> 00:43:09,359
因此 rnns 的學習模式至少是

1268
00:43:09,359 --> 00:43:11,880
對於 rnn 與嬰兒的肯定區別，

1269
00:43:11,880 --> 00:43:14,339
你知道嬰兒智人是

1270
00:43:14,339 --> 00:43:16,260
對的，所以故事是米切爾和

1271
00:43:16,260 --> 00:43:18,359
鮑爾斯表明，雖然 lstl 模型

1272
00:43:18,359 --> 00:43:20,040
很好地表示了

1273
00:43:20,040 --> 00:43:22,140
單個句子的單數與復數，但

1274
00:43:22,140 --> 00:43:24,359
沒有進行正確的概括，

1275
00:43:24,359 --> 00:43:25,800
它們可以在個體

1276
00:43:25,800 --> 00:43:27,359
層面上表示 因此該模型沒有將

1277
00:43:27,359 --> 00:43:28,859
數字表示為

1278
00:43:28,859 --> 00:43:31,200
抽象，什麼數字只是單數

1279
00:43:31,200 --> 00:43:34,020
基礎複數的具體實例，

1280
00:43:34,020 --> 00:43:35,400
所以通過 LM 成功預測語言

1281
00:43:35,400 --> 00:43:38,579
行為或

1282
00:43:38,579 --> 00:43:40,800
以類似方式成功預測神經反應

1283
00:43:40,800 --> 00:43:42,480
顯然很棒，也許我們可以

1284
00:43:42,480 --> 00:43:43,920
進入 那個問題稍後但

1285
00:43:43,920 --> 00:43:45,240
這裡只有硬幣的一面

1286
00:43:45,240 --> 00:43:47,099
硬幣的另一面正在解釋為什麼

1287
00:43:47,099 --> 00:43:48,780
這種行為而不是其他一些

1288
00:43:48,780 --> 00:43:50,339
行為為什麼這個結構我不

1289
00:43:50,339 --> 00:43:52,740
相似而且這可能是喬姆斯基最

1290
00:43:52,740 --> 00:43:55,380
喜歡你最了解他的 重要的

1291
00:43:55,380 --> 00:43:56,760
一點真的為什麼這不是其他

1292
00:43:56,760 --> 00:43:59,400
系統所以語言理論

1293
00:43:59,400 --> 00:44:00,720
給了你那個或硬幣的開始，

1294
00:44:00,720 --> 00:44:02,760
而 LM 真的完成了所以

1295
00:44:02,760 --> 00:44:03,839
米切爾尷尬的論文做了

1296
00:44:03,839 --> 00:44:05,819
類似的事情他做得

1297
00:44:05,819 --> 00:44:09,420
很好是的所以就像拿 um Yael Le

1298
00:44:09,420 --> 00:44:11,400
Haynes 的 crets 和 stanislash 是 2019 年的，

1299
00:44:11,400 --> 00:44:13,319
對吧，他們在 lstm 中查看了數字協議，

1300
00:44:13,319 --> 00:44:15,480
發現了兩個專門

1301
00:44:15,480 --> 00:44:17,640
編碼數字協議的單元，但對

1302
00:44:17,640 --> 00:44:19,020
性能的總體貢獻

1303
00:44:19,020 --> 00:44:21,839
很低，然後在 2021 年，嗯，是的，更正

1304
00:44:21,839 --> 00:44:24,000
了這篇論文，他們

1305
00:44:24,000 --> 00:44:26,040
在其中展示了嗯 他們的神經語言模型

1306
00:44:26,040 --> 00:44:28,079
沒有實現意大利語中

1307
00:44:28,079 --> 00:44:30,540
嵌套遠程協議性別

1308
00:44:30,540 --> 00:44:32,160
標記的真正遞歸處理，我想

1309
00:44:32,160 --> 00:44:34,020
嗯，即使

1310
00:44:34,020 --> 00:44:35,819
你所知道的一些分層處理已經實現，正如你

1311
00:44:35,819 --> 00:44:37,380
之前所說的那樣，一些層次結構仍然

1312
00:44:37,380 --> 00:44:39,960
存在，但問題是 它是

1313
00:44:39,960 --> 00:44:41,280
正確的映射嗎？它是正確

1314
00:44:41,280 --> 00:44:42,900
的層次結構嗎？他們發現基於

1315
00:44:42,900 --> 00:44:45,119
lstn 的模型可以

1316
00:44:45,119 --> 00:44:47,220
在短跨度內達成主題網絡協議，一個

1317
00:44:47,220 --> 00:44:49,260
嵌入度，但他們在一些較長的依賴關係上失敗了，

1318
00:44:49,260 --> 00:44:51,359
在最近的

1319
00:44:51,359 --> 00:44:53,700
論文中，uh La crepe satell with 手

1320
00:44:53,700 --> 00:44:56,760
並表明他們在相同任務上評估了

1321
00:44:56,760 --> 00:45:00,180
包括 gpt2 XL 在內的現代 Transformer LMS，

1322
00:45:00,180 --> 00:45:01,980
並且 Transformer 的表現

1323
00:45:01,980 --> 00:45:04,260
比 LSM 與人類更相似，

1324
00:45:04,260 --> 00:45:06,300
並且總體上表現優於轉移，但

1325
00:45:06,300 --> 00:45:08,040
他們在一個關鍵條件下的表現仍然低於機會，

1326
00:45:08,040 --> 00:45:09,660
正如我

1327
00:45:09,660 --> 00:45:11,099
提到的那樣 多重嵌入一個

1328
00:45:11,099 --> 00:45:13,020
困難的經文所以

1329
00:45:13,020 --> 00:45:14,400
我提到這些研究的原因是因為

1330
00:45:14,400 --> 00:45:17,040
你知道這不僅僅是探索

1331
00:45:17,040 --> 00:45:18,540
OMS 的局限性這是一個有趣的

1332
00:45:18,540 --> 00:45:19,500
問題

1333
00:45:19,500 --> 00:45:21,540
嗯但考慮像 UCL 的 Neil Smith 這樣的人的工作

1334
00:45:21,540 --> 00:45:24,180
，他確實在

1335
00:45:24,180 --> 00:45:26,579
上世紀 90 年代，通曉多種語言的 Savant 和典型的

1336
00:45:26,579 --> 00:45:28,740
神經控制者將它們進行比較，因此

1337
00:45:28,740 --> 00:45:30,540
他研究了

1338
00:45:30,540 --> 00:45:32,520
包含

1339
00:45:32,520 --> 00:45:34,500
自然和非自然圖形

1340
00:45:34,500 --> 00:45:35,880
結構的人工語言的第二語言學習，例如米其林病毒論文，

1341
00:45:35,880 --> 00:45:37,079
整個框架是自然的

1342
00:45:37,079 --> 00:45:39,119
與非自然的，他們發現

1343
00:45:39,119 --> 00:45:41,000
雖然學者

1344
00:45:41,000 --> 00:45:43,319
和 控件可以掌握

1345
00:45:43,319 --> 00:45:45,480
語言上的自然方面，只有

1346
00:45:45,480 --> 00:45:46,920
控件最終可以處理

1347
00:45:46,920 --> 00:45:48,660
依賴於結構的非自然現象，

1348
00:45:48,660 --> 00:45:50,460
而且它們都不能掌握

1349
00:45:50,460 --> 00:45:52,560
結構獨立方面，所以一些

1350
00:45:52,560 --> 00:45:53,880
奇怪的規則就像你知道你

1351
00:45:53,880 --> 00:45:55,440
把重點放在句子的第三個

1352
00:45:55,440 --> 00:45:56,940
詞上 像這樣，所以他們

1353
00:45:56,940 --> 00:45:58,740
爭辯說克里斯托弗的能力

1354
00:45:58,740 --> 00:46:00,900
完全歸功於他完整的語言

1355
00:46:00,900 --> 00:46:03,480
能力，但控制可以使用

1356
00:46:03,480 --> 00:46:05,579
更多領域一般的認知

1357
00:46:05,579 --> 00:46:07,319
資源，比如你知道的注意力

1358
00:46:07,319 --> 00:46:09,900
控制等等，這就是為什麼他們可以處理

1359
00:46:09,900 --> 00:46:11,520
困難的過程，

1360
00:46:11,520 --> 00:46:13,319
但我剛才提到你知道一個 一分鐘

1361
00:46:13,319 --> 00:46:16,079
前，米切爾尷尬論文中的 lstm

1362
00:46:16,079 --> 00:46:18,359


1363
00:46:18,359 --> 00:46:19,920
以幾乎

1364
00:46:19,920 --> 00:46:22,319
相同的方式接近自然和非自然結構，所以你不知道這不是一個

1365
00:46:22,319 --> 00:46:24,240
心理上合理的模型，我認為

1366
00:46:24,240 --> 00:46:26,400
無論人類在做什麼，

1367
00:46:26,400 --> 00:46:28,200
類似的觀察都可以應用於

1368
00:46:28,200 --> 00:46:30,060
La creta 作品中的 Transformer 模型

1369
00:46:30,060 --> 00:46:31,920
和所有這些主題都

1370
00:46:31,920 --> 00:46:33,780
很好，它們一直伴隨著

1371
00:46:33,780 --> 00:46:35,819
我們直到現在，所以 talins

1372
00:46:35,819 --> 00:46:37,560
最近發表的另一篇論文他在

1373
00:46:37,560 --> 00:46:39,240
幾週前發表了一篇關於兒童

1374
00:46:39,240 --> 00:46:41,880
定向演講的論文表明，嗯 Lstms 和

1375
00:46:41,880 --> 00:46:43,740
Transformers 僅限於生態學上

1376
00:46:43,740 --> 00:46:46,380
合理的數據量，因為

1377
00:46:46,380 --> 00:46:47,640
我提到了英語權利的線性規則

1378
00:46:47,640 --> 00:46:49,920
而不是抽象規則，

1379
00:46:49,920 --> 00:46:51,780
事實上上周林頓實驗室最近的工作

1380
00:46:51,780 --> 00:46:54,599
看著呃

1381
00:46:54,599 --> 00:46:56,220
去年我應該說看

1382
00:46:56,220 --> 00:46:58,160
花園 意外路徑並不能解釋

1383
00:46:58,160 --> 00:47:01,319
語法消歧的困難，

1384
00:47:01,319 --> 00:47:02,280


1385
00:47:02,280 --> 00:47:03,900
嗯，意外會低估

1386
00:47:03,900 --> 00:47:05,400
所有結構中花園小徑效應的大小，

1387
00:47:05,400 --> 00:47:06,780
這就涉及到

1388
00:47:06,780 --> 00:47:08,099
你之前提到的這個問題，你

1389
00:47:08,099 --> 00:47:10,140
可能會驚訝所有這些與

1390
00:47:10,140 --> 00:47:11,520
語法的某些方面有關，但也許不會

1391
00:47:11,520 --> 00:47:12,960
其他的，這是一個非常

1392
00:47:12,960 --> 00:47:14,819
非致敬的問題，非常

1393
00:47:14,819 --> 00:47:16,800
開放討論，不是尚未

1394
00:47:16,800 --> 00:47:18,720
解決，但林惇表明

1395
00:47:18,720 --> 00:47:20,640
花園小徑效果

1396
00:47:20,640 --> 00:47:21,720
比您對我的期望要困難得多

1397
00:47:21,720 --> 00:47:24,359
不可預測性，所以另一種

1398
00:47:24,359 --> 00:47:26,160
表達這個論點的方式

1399
00:47:26,160 --> 00:47:29,160
是

1400
00:47:29,160 --> 00:47:30,660
引用喬姆斯基最近關於解決這個自然

1401
00:47:30,660 --> 00:47:32,940
基礎的不自然問題的論點，他說假設我們

1402
00:47:32,940 --> 00:47:34,560
有一個擴展的元素週期表，其中

1403
00:47:34,560 --> 00:47:36,180
包括所有確實存在的元素

1404
00:47:36,180 --> 00:47:38,819
或可能存在的元素 存在

1405
00:47:38,819 --> 00:47:40,740
和所有不可能

1406
00:47:40,740 --> 00:47:42,660
存在的元素，假設你有

1407
00:47:42,660 --> 00:47:44,880
一些模型，嗯，一些人工模型，

1408
00:47:44,880 --> 00:47:46,560
無法區分這三個

1409
00:47:46,560 --> 00:47:48,780
類別，無論這個模型在做什麼，它都

1410
00:47:48,780 --> 00:47:50,640
不能幫助我們理解化學，對，它在

1411
00:47:50,640 --> 00:47:52,020
做其他事情，

1412
00:47:52,020 --> 00:47:53,940
它正在做一些事情 當然，但

1413
00:47:53,940 --> 00:47:55,020
是否必須了解

1414
00:47:55,020 --> 00:47:57,180
化學是另外一回事，我

1415
00:47:57,180 --> 00:47:58,560
知道你在回應

1416
00:47:58,560 --> 00:47:59,579
其中一些研究時說過，我想你

1417
00:47:59,579 --> 00:48:02,400
說過你知道，並且為了表明

1418
00:48:02,400 --> 00:48:03,540
某些事情

1419
00:48:03,540 --> 00:48:04,920
在某個地方可能是不可能的 在你的論文中，我

1420
00:48:04,920 --> 00:48:06,240
認為你說

1421
00:48:06,240 --> 00:48:07,859
嗯是為了表明在誤報上政治

1422
00:48:07,859 --> 00:48:09,720
的正常平衡是不可能的，

1423
00:48:09,720 --> 00:48:12,300
你需要

1424
00:48:12,300 --> 00:48:13,440
表明你需要查看類似

1425
00:48:13,440 --> 00:48:15,780
500 種獨立採樣的語言，所以

1426
00:48:15,780 --> 00:48:17,880
你在論文中引用了這個，

1427
00:48:17,880 --> 00:48:19,020
嗯，你 可能不能那樣做，

1428
00:48:19,020 --> 00:48:20,579


1429
00:48:20,579 --> 00:48:23,880


1430
00:48:23,880 --> 00:48:25,800
這不是一件可行的事情，所以你知道我不是

1431
00:48:25,800 --> 00:48:27,119


1432
00:48:27,119 --> 00:48:29,040


1433
00:48:29,040 --> 00:48:30,839
關於原則上不可能的爭論，而不是

1434
00:48:30,839 --> 00:48:32,220


1435
00:48:32,220 --> 00:48:33,599
你知道的某種擴展意義上的嗯，

1436
00:48:33,599 --> 00:48:34,980
就像在

1437
00:48:34,980 --> 00:48:37,440
世界各地搜索語言，以證明在

1438
00:48:37,440 --> 00:48:38,579
每一種語言中都是

1439
00:48:38,579 --> 00:48:40,260
不可能的，對吧，這是一個

1440
00:48:40,260 --> 00:48:41,280
不同的論點，它是否

1441
00:48:41,280 --> 00:48:43,740
在某種隨機語言中是不可能的 在

1442
00:48:43,740 --> 00:48:45,180
亞馬遜中，

1443
00:48:45,180 --> 00:48:47,220
根據

1444
00:48:47,220 --> 00:48:48,420
語言系統實際

1445
00:48:48,420 --> 00:48:50,160
做的事情的原則，實際上是不可能的，就像它可以做的那樣，所以我

1446
00:48:50,160 --> 00:48:53,339
只想說是的，我認為

1447
00:48:53,339 --> 00:48:55,980
那一點是你實際上不

1448
00:48:55,980 --> 00:48:58,560
知道什麼是類型學上的 可能是對

1449
00:48:58,560 --> 00:49:00,480
的，所以有些人喜歡說

1450
00:49:00,480 --> 00:49:02,520
你知道沒有語言可以

1451
00:49:02,520 --> 00:49:04,859
做 X，因此我們必須

1452
00:49:04,859 --> 00:49:06,960
在我們的統計

1453
00:49:06,960 --> 00:49:09,119
模型中正確建立這種限制，但是如果

1454
00:49:09,119 --> 00:49:11,220
統計上沒有證明沒有

1455
00:49:11,220 --> 00:49:13,079
語言可以做 X 是正確的，如果你有

1456
00:49:13,079 --> 00:49:15,119
只看了 20 或 20 種歐洲

1457
00:49:15,119 --> 00:49:16,920
語言或一些正確的東西我的意思

1458
00:49:16,920 --> 00:49:19,020
是它不是

1459
00:49:19,020 --> 00:49:22,380
嗯嗯那樣不應該激勵對

1460
00:49:22,380 --> 00:49:24,599
模型做任何事情

1461
00:49:24,599 --> 00:49:26,280
嗯嗯如果它不是

1462
00:49:26,280 --> 00:49:28,200
統計上合理的通用我

1463
00:49:28,200 --> 00:49:28,980
認為

1464
00:49:28,980 --> 00:49:30,180


1465
00:49:30,180 --> 00:49:32,760
嗯你知道我我我認為你 知道

1466
00:49:32,760 --> 00:49:33,960
你是完全正確的，但這只是

1467
00:49:33,960 --> 00:49:35,339
更普遍地適用於社會

1468
00:49:35,339 --> 00:49:36,960
科學和心理科學，

1469
00:49:36,960 --> 00:49:39,180
就像類型學一樣，是的，

1470
00:49:39,180 --> 00:49:40,380
很難將這些事情建立

1471
00:49:40,380 --> 00:49:43,140
正確，所以我猜你我猜

1472
00:49:43,140 --> 00:49:44,640
你只是有點陳舊 你是

1473
00:49:44,640 --> 00:49:47,339
說強烈的主張

1474
00:49:47,339 --> 00:49:49,859
很難證明是正確的，

1475
00:49:49,859 --> 00:49:52,619
就像沒有語言有 X

1476
00:49:52,619 --> 00:49:54,480


1477
00:49:54,480 --> 00:49:56,339
我認為自然語言中不允許出現某些東西的強烈主張是

1478
00:49:56,339 --> 00:49:58,800
很難證明的，

1479
00:49:58,800 --> 00:49:59,880


1480
00:49:59,880 --> 00:50:01,980
嗯，你知道我認為 已經

1481
00:50:01,980 --> 00:50:05,460
有很多你知道的強有力的

1482
00:50:05,460 --> 00:50:08,460
嘗試有很多來自

1483
00:50:08,460 --> 00:50:10,380


1484
00:50:10,380 --> 00:50:12,720
嗯嗯經常來自生成語法的強烈主張

1485
00:50:12,720 --> 00:50:16,800
關於所有語言的作用

1486
00:50:16,800 --> 00:50:19,140
嗯我認為你知道人們

1487
00:50:19,140 --> 00:50:21,119
非常擅長尋找

1488
00:50:21,119 --> 00:50:22,740
反例 對於很多

1489
00:50:22,740 --> 00:50:24,720
事情，我引用了 Evans 和 Levinson 的這篇論文，

1490
00:50:24,720 --> 00:50:26,579


1491
00:50:26,579 --> 00:50:28,500
嗯，實際上你知道我

1492
00:50:28,500 --> 00:50:30,660
多年來一直聽說沒有語言是如何做 X 的，

1493
00:50:30,660 --> 00:50:32,160
這就是我們用來

1494
00:50:32,160 --> 00:50:33,599
構建我們的理論的東西，Evans

1495
00:50:33,599 --> 00:50:35,460
和 Levin 的 論文 Evans 和 Levinson

1496
00:50:35,460 --> 00:50:37,859
論文真的呃改變了我

1497
00:50:37,859 --> 00:50:40,680
對這個權利的看法就像語言

1498
00:50:40,680 --> 00:50:43,260
實際上比我想像的要多樣化得多 嗯

1499
00:50:43,260 --> 00:50:44,940


1500
00:50:44,940 --> 00:50:47,760
大多數句法學家你會知道嘗試

1501
00:50:47,760 --> 00:50:50,700
為某些東西構建理論所以嗯嗯

1502
00:50:50,700 --> 00:50:53,579
你知道我我我想我們去

1503
00:50:53,579 --> 00:50:54,839
回到你

1504
00:50:54,839 --> 00:50:57,660
所說的開頭，我想我們會同意，呃，

1505
00:50:57,660 --> 00:50:59,880
你需要語言架構來

1506
00:50:59,880 --> 00:51:01,619
學習孩子們學習的東西，並

1507
00:51:01,619 --> 00:51:03,660
從他們學習的數據中學到這些東西，而

1508
00:51:03,660 --> 00:51:05,940
這些架構可能

1509
00:51:05,940 --> 00:51:09,000
不太可能成為事物 像 lstms 或你

1510
00:51:09,000 --> 00:51:10,559
知道簡單的循環網絡或

1511
00:51:10,559 --> 00:51:12,300
其他任何正確的東西，比如

1512
00:51:12,300 --> 00:51:14,400
嗯我認為所有這些工作

1513
00:51:14,400 --> 00:51:16,680
對於磨練

1514
00:51:16,680 --> 00:51:19,200
正確的架構非常有用

1515
00:51:19,200 --> 00:51:20,460
嗯嗯嗯

1516
00:51:20,460 --> 00:51:21,420


1517
00:51:21,420 --> 00:51:23,819
所以我只是想記住所有的

1518
00:51:23,819 --> 00:51:25,200
一切 你提出的觀點

1519
00:51:25,200 --> 00:51:26,700
哦，是的，

1520
00:51:26,700 --> 00:51:29,160
嗯，但我認為這有

1521
00:51:29,160 --> 00:51:31,500
一種反面，那

1522
00:51:31,500 --> 00:51:32,760
就是，

1523
00:51:32,760 --> 00:51:34,380
嗯，我認為

1524
00:51:34,380 --> 00:51:37,619
人們可以學習的東西的空間實際上被

1525
00:51:37,619 --> 00:51:39,599
低估了，就像有這種

1526
00:51:39,599 --> 00:51:41,760
偏見一樣 要說你知道人們無法

1527
00:51:41,760 --> 00:51:43,800
學習 x y 和 z

1528
00:51:43,800 --> 00:51:46,020
嗯但是人們呃至少在

1529
00:51:46,020 --> 00:51:47,460
語言之外有這種非常

1530
00:51:47,460 --> 00:51:49,680
了不起的能力來學習不同

1531
00:51:49,680 --> 00:51:51,240
種類的模式就像

1532
00:51:51,240 --> 00:51:53,160
你在音樂或數學中找到的模式一樣

1533
00:51:53,160 --> 00:51:55,619


1534
00:51:55,619 --> 00:51:57,839
嗯嗯 我們可以學習複雜類型的

1535
00:51:57,839 --> 00:52:00,240
算法，我們可以學習

1536
00:52:00,240 --> 00:52:03,119
你知道駕駛航天飛機，或者你

1537
00:52:03,119 --> 00:52:05,760
知道打結攀岩

1538
00:52:05,760 --> 00:52:07,319
等等，就像那裡有

1539
00:52:07,319 --> 00:52:09,540
各種各樣的程序和

1540
00:52:09,540 --> 00:52:11,280
算法知識，這些知識是

1541
00:52:11,280 --> 00:52:13,440
結構化的 人們能夠

1542
00:52:13,440 --> 00:52:16,680
獲得併且我認為那個呃

1543
00:52:16,680 --> 00:52:19,680
概念呃非常正確地激勵

1544
00:52:19,680 --> 00:52:21,359
尋找可以在

1545
00:52:21,359 --> 00:52:24,059
非常不受限制的空間工作的學習系統

1546
00:52:24,059 --> 00:52:26,160
所以

1547
00:52:26,160 --> 00:52:28,859
嗯嗯你知道你你可能會說

1548
00:52:28,859 --> 00:52:30,119
好吧語言是不同的

1549
00:52:30,119 --> 00:52:33,420
因為語言是 一個受限的空間

1550
00:52:33,420 --> 00:52:35,040
嗯嗯，

1551
00:52:35,040 --> 00:52:36,540
語言是受限的，但也可能是

1552
00:52:36,540 --> 00:52:37,859
我們在語言中看到的東西

1553
00:52:37,859 --> 00:52:39,960
來自其他來源，對吧，

1554
00:52:39,960 --> 00:52:42,180
嗯，語言可能

1555
00:52:42,180 --> 00:52:44,099
特別實用，例如與

1556
00:52:44,099 --> 00:52:47,040
音樂或數學相比

1557
00:52:47,040 --> 00:52:48,720
是的，那些語用

1558
00:52:48,720 --> 00:52:50,040
限制

1559
00:52:50,040 --> 00:52:51,480
嗯是限制

1560
00:52:51,480 --> 00:52:53,400
語言形式的東西，或者語言是

1561
00:52:53,400 --> 00:52:54,660
交際的，它可能

1562
00:52:54,660 --> 00:52:56,760
比音樂更具交際性，

1563
00:52:56,760 --> 00:52:58,440
例如，這可能會限制

1564
00:52:58,440 --> 00:53:01,140
事物的形式，所以我的意思是，正如你所知，

1565
00:53:01,140 --> 00:53:02,700
這是非常

1566
00:53:02,700 --> 00:53:05,520
語言學中關於

1567
00:53:05,520 --> 00:53:07,140
自然語言的屬性從何

1568
00:53:07,140 --> 00:53:09,059
而來的古老爭論，嗯，

1569
00:53:09,059 --> 00:53:11,160
嗯，我想我想說的

1570
00:53:11,160 --> 00:53:12,660
是，有一種觀點，

1571
00:53:12,660 --> 00:53:15,119
呃，你

1572
00:53:15,119 --> 00:53:16,980
可以看待人類可以看到的所有事物 即使在語言之外，

1573
00:53:16,980 --> 00:53:18,599
所有豐富的結構、

1574
00:53:18,599 --> 00:53:20,819
算法和過程都能夠

1575
00:53:20,819 --> 00:53:23,760
了解和內化，

1576
00:53:23,760 --> 00:53:25,559
你說好吧，也許語言就是這樣，

1577
00:53:25,559 --> 00:53:27,420
然後是的，語言也有一些

1578
00:53:27,420 --> 00:53:29,700
其他有趣的小屬性，

1579
00:53:29,700 --> 00:53:31,380
嗯，但你知道也許那些 來自

1580
00:53:31,380 --> 00:53:34,020
其他一些

1581
00:53:34,020 --> 00:53:36,720
語言來自哪裡的其他部分，嗯，

1582
00:53:36,720 --> 00:53:38,400
你知道我們有非常複雜的語用

1583
00:53:38,400 --> 00:53:40,800
推理，

1584
00:53:40,800 --> 00:53:42,720
嗯，我們正在使用它來實現某些

1585
00:53:42,720 --> 00:53:45,359
交流目的，你可以

1586
00:53:45,359 --> 00:53:47,160


1587
00:53:47,160 --> 00:53:49,559
在 語言系統本身

1588
00:53:49,559 --> 00:53:51,180
等等，所以也許這些其他

1589
00:53:51,180 --> 00:53:53,819
屬性中的一些是具有

1590
00:53:53,819 --> 00:53:55,619
其他來源的屬性，嗯，

1591
00:53:55,619 --> 00:53:57,059
我認為那個觀點可能是

1592
00:53:57,059 --> 00:53:59,579
錯誤的，但它是一個，

1593
00:53:59,579 --> 00:54:01,800
嗯，我認為需要看看

1594
00:54:01,800 --> 00:54:04,200
它是否是錯誤的，就像 我認為這已經被

1595
00:54:04,200 --> 00:54:05,400


1596
00:54:05,400 --> 00:54:10,020
很多

1597
00:54:10,020 --> 00:54:12,900
語言學家忽視了，對吧，你

1598
00:54:12,900 --> 00:54:14,579
知道，我聽說人們說，哦，良好的

1599
00:54:14,579 --> 00:54:15,720
溝通並不能真正

1600
00:54:15,720 --> 00:54:17,760
解釋任何關於語言的正確性

1601
00:54:17,760 --> 00:54:20,040
，他們的意思通常是它不能。 不能

1602
00:54:20,040 --> 00:54:22,200
像特定的島嶼

1603
00:54:22,200 --> 00:54:23,760
限製或他們正在

1604
00:54:23,760 --> 00:54:25,319
努力解決的問題那樣解釋，但

1605
00:54:25,319 --> 00:54:26,700


1606
00:54:26,700 --> 00:54:28,319
語言中有各種各樣的其他事情，交際壓力

1607
00:54:28,319 --> 00:54:30,359
可能會解釋，

1608
00:54:30,359 --> 00:54:31,500
嗯，

1609
00:54:31,500 --> 00:54:33,540
嗯，我想我的推銷總是

1610
00:54:33,540 --> 00:54:36,359
為了某種廣度 在術語廣度上，

1611
00:54:36,359 --> 00:54:39,119
考慮到

1612
00:54:39,119 --> 00:54:41,460
可以塑造語言的力量，而不需要將

1613
00:54:41,460 --> 00:54:43,680
其全部置於某種形式的先天

1614
00:54:43,680 --> 00:54:45,359
約束或類似的東西中，不

1615
00:54:45,359 --> 00:54:46,680
完全，我認為我認為很多

1616
00:54:46,680 --> 00:54:48,420
東西都與

1617
00:54:48,420 --> 00:54:49,980
它們兼容 illness program

1618
00:54:49,980 --> 00:54:51,960
因為這個程序的中間部分希望

1619
00:54:51,960 --> 00:54:53,339
語法最少 它不希望它

1620
00:54:53,339 --> 00:54:54,660
複雜 它不希望它變得

1621
00:54:54,660 --> 00:54:56,220
更複雜 它

1622
00:54:56,220 --> 00:54:57,960


1623
00:54:57,960 --> 00:54:59,460
必須如此所以你提到了一些 Curious 屬性 所以

1624
00:54:59,460 --> 00:55:00,480


1625
00:55:00,480 --> 00:55:02,579
在任何語言模型中都需要考慮一些屬性，

1626
00:55:02,579 --> 00:55:04,200
呃，我會給你一個

1627
00:55:04,200 --> 00:55:05,400
關於人物特徵設置的例子，

1628
00:55:05,400 --> 00:55:06,599


1629
00:55:06,599 --> 00:55:08,880
這些人物特徵表現出非常

1630
00:55:08,880 --> 00:55:10,440
重要的不同概括，這些概括

1631
00:55:10,440 --> 00:55:12,480
似乎並不 考慮到通過

1632
00:55:12,480 --> 00:55:14,220
領域一般學習機制，所以我

1633
00:55:14,220 --> 00:55:16,020
坐在這裡是瑪麗皇后學院丹尼爾哈珀的工作，

1634
00:55:16,020 --> 00:55:17,700
例如

1635
00:55:17,700 --> 00:55:19,740
人的形態構成，它

1636
00:55:19,740 --> 00:55:21,720
與數字的相互作用，它與

1637
00:55:21,720 --> 00:55:24,059
空間的聯繫，呃，它的語義屬性

1638
00:55:24,059 --> 00:55:26,040
和線性化，它們似乎

1639
00:55:26,040 --> 00:55:27,240
都是 成為我們

1640
00:55:27,240 --> 00:55:28,619
語言知識的有力候選人，這就是我們

1641
00:55:28,619 --> 00:55:30,359
所說的語言知識，但

1642
00:55:30,359 --> 00:55:32,280
另一方面，我們有格子、

1643
00:55:32,280 --> 00:55:34,319
協議和頭部運動等東西，這些

1644
00:55:34,319 --> 00:55:36,420
都是結構現象，但

1645
00:55:36,420 --> 00:55:39,319
它們似乎抵制純粹

1646
00:55:39,319 --> 00:55:42,420
基於意義的解釋，呃

1647
00:55:42,420 --> 00:55:44,339
理論語言學是對的，

1648
00:55:44,339 --> 00:55:45,839
如果句法只是一個

1649
00:55:45,839 --> 00:55:47,520
構建

1650
00:55:47,520 --> 00:55:49,440
結構化意義的計算引擎，那就太好了，這就是

1651
00:55:49,440 --> 00:55:51,240
極簡主義程序的目標，但這

1652
00:55:51,240 --> 00:55:52,800
不是我們實際發現的，在

1653
00:55:52,800 --> 00:55:54,720
任何實際的極簡主義中都沒有，比如具體

1654
00:55:54,720 --> 00:55:57,240
模型，任何具體的礦物理論，

1655
00:55:57,240 --> 00:55:59,040
目標只是 就像這個程序是

1656
00:55:59,040 --> 00:56:01,260
語言是完美的好吧，這個

1657
00:56:01,260 --> 00:56:03,119
程序是我們發現的東西

1658
00:56:03,119 --> 00:56:05,160
顯然不好沒有語言學家

1659
00:56:05,160 --> 00:56:07,680
真的相信這一點，所以

1660
00:56:07,680 --> 00:56:09,900
如果語法是那樣的話會很棒但是我

1661
00:56:09,900 --> 00:56:11,280
想你知道這個程序是為了尋找

1662
00:56:11,280 --> 00:56:13,740
完美但是 並不總能找到它，

1663
00:56:13,740 --> 00:56:15,839
所以協議和頭部運動的形態

1664
00:56:15,839 --> 00:56:17,640
更多地是為了語音

1665
00:56:17,640 --> 00:56:19,319
現象

1666
00:56:19,319 --> 00:56:20,700
性能係統的屬性，也就是所謂的

1667
00:56:20,700 --> 00:56:22,440
性能係統，所以

1668
00:56:22,440 --> 00:56:23,760
極簡主義程序本身確實

1669
00:56:23,760 --> 00:56:24,839
與你

1670
00:56:24,839 --> 00:56:26,880
所說的很多你知道的語言兼容

1671
00:56:26,880 --> 00:56:28,500
語言的某些方面可以

1672
00:56:28,500 --> 00:56:31,200
um 完善和優化以提高

1673
00:56:31,200 --> 00:56:32,700
交際效率，

1674
00:56:32,700 --> 00:56:35,520
這絕對完全毫無疑問，但

1675
00:56:35,520 --> 00:56:38,160
效率的核心在哪裡是

1676
00:56:38,160 --> 00:56:39,960
語法本身還是某種

1677
00:56:39,960 --> 00:56:42,000
額外的語言系統它是在語

1678
00:56:42,000 --> 00:56:43,680
用學中你知道的是 它在感覺

1679
00:56:43,680 --> 00:56:45,540
運動中 它在演講中嗎

1680
00:56:45,540 --> 00:56:47,640
嗯可能是演講和音韻學

1681
00:56:47,640 --> 00:56:50,400
你知道我的意思是誰知道但我

1682
00:56:50,400 --> 00:56:52,740
認為很多這些東西需要

1683
00:56:52,740 --> 00:56:56,059
更多你知道認真考慮

1684
00:56:56,059 --> 00:56:57,839
老式的概念，比如結構

1685
00:56:57,839 --> 00:56:59,700
依賴性 構圖主題 你有什麼

1686
00:56:59,700 --> 00:57:01,140
諸如此類的東西，您也許可以

1687
00:57:01,140 --> 00:57:03,720
在文獻中的某個地方找到，但是嗯，即使只是

1688
00:57:03,720 --> 00:57:06,720
像您所知道的基本主題，

1689
00:57:06,720 --> 00:57:08,640
量詞提高了擴展的

1690
00:57:08,640 --> 00:57:09,900
預測，以及

1691
00:57:09,900 --> 00:57:12,059
副詞，例如狀語層次結構，

1692
00:57:12,059 --> 00:57:13,920
極簡主義程序中的所有這些東西都

1693
00:57:13,920 --> 00:57:16,619
可以是額外的語言權利，

1694
00:57:16,619 --> 00:57:18,180
它們實際上可以在 句法

1695
00:57:18,180 --> 00:57:20,579
和查詢 語義的非常奇怪的屬性

1696
00:57:20,579 --> 00:57:23,099
呃概念系統

1697
00:57:23,099 --> 00:57:24,559
本身就是一種領域

1698
00:57:24,559 --> 00:57:27,420
古代初級認知的一般奇怪遺留物

1699
00:57:27,420 --> 00:57:29,220
正確的

1700
00:57:29,220 --> 00:57:31,260
我們傳遞事件的方式的特徵 我們傳遞你知道

1701
00:57:31,260 --> 00:57:32,520
代理人和病人的方式 這樣的事情

1702
00:57:32,520 --> 00:57:33,960
絕對不是 這不是人類

1703
00:57:33,960 --> 00:57:35,520
特有的

1704
00:57:35,520 --> 00:57:37,260
嗯，但你知道語法

1705
00:57:37,260 --> 00:57:39,059
為這些系統提供指令的方式

1706
00:57:39,059 --> 00:57:42,480
你知道正確的似乎是這樣你

1707
00:57:42,480 --> 00:57:43,800
知道生成語言學家也有不同的

1708
00:57:43,800 --> 00:57:45,839
語言生成理論

1709
00:57:45,839 --> 00:57:47,040
我將只

1710
00:57:47,040 --> 00:57:49,380
根據我們是否存儲引理來談論語言生成

1711
00:57:49,380 --> 00:57:51,240
或者我們構建單詞的方式是否與

1712
00:57:51,240 --> 00:57:52,619
我們構建短語和句子的方式完全相同，所以我

1713
00:57:52,619 --> 00:57:53,819
知道你區分

1714
00:57:53,819 --> 00:57:55,440
了構造語法和

1715
00:57:55,440 --> 00:57:57,180
生成語法，你知道

1716
00:57:57,180 --> 00:57:58,680
它們對記憶限制的重視程度，

1717
00:57:58,680 --> 00:58:00,119
而只是

1718
00:58:00,119 --> 00:58:01,559
從

1719
00:58:01,559 --> 00:58:04,440
自下而上，所以你知道在一些

1720
00:58:04,440 --> 00:58:06,480
生成句法結構的啟發模型機制中，在

1721
00:58:06,480 --> 00:58:08,460


1722
00:58:08,460 --> 00:58:10,200


1723
00:58:10,200 --> 00:58:12,200
單詞級別之上或之下應用的過程之間沒有區別

1724
00:58:12,200 --> 00:58:14,640
沒有指針，這意味著語法

1725
00:58:14,640 --> 00:58:16,500
和形式都存儲在一起一個

1726
00:58:16,500 --> 00:58:18,660
單一的原子

1727
00:58:18,660 --> 00:58:20,099
詞彙訪問中的每個階段都是

1728
00:58:20,099 --> 00:58:21,960
不同類型數據

1729
00:58:21,960 --> 00:58:23,760
結構之間的轉換，這意味著有

1730
00:58:23,760 --> 00:58:25,740
形式和語法這三個

1731
00:58:25,740 --> 00:58:27,480
特徵混合在一起並且

1732
00:58:27,480 --> 00:58:28,920
它們並不總是重疊不同的

1733
00:58:28,920 --> 00:58:31,440
語言以不同的方式實現它們

1734
00:58:31,440 --> 00:58:34,800
所以你知道 一個奇怪的

1735
00:58:34,800 --> 00:58:36,839
詞的基本定義就是這個奇怪的

1736
00:58:36,839 --> 00:58:39,720
多系統定義，其中很多

1737
00:58:39,720 --> 00:58:41,040
東西很多不同的認知

1738
00:58:41,040 --> 00:58:42,900
系統豐富了每個

1739
00:58:42,900 --> 00:58:44,940
電子產品的基礎，你有

1740
00:58:44,940 --> 00:58:46,680
嗯沒有什麼比這更

1741
00:58:46,680 --> 00:58:48,299
豐富的過程了

1742
00:58:48,299 --> 00:58:50,099
嗯在其他任何地方 語言學理論是

1743
00:58:50,099 --> 00:58:52,200
正確的，或者至少在 llms 正在做的事情中，

1744
00:58:52,200 --> 00:58:53,220


1745
00:58:53,220 --> 00:58:55,859
所以我猜我猜我會問

1746
00:58:55,859 --> 00:58:58,799
你你對單詞 right 的定義是什麼，

1747
00:58:58,799 --> 00:59:01,559
以及 llms 能真正提供

1748
00:59:01,559 --> 00:59:03,780
對單詞 Hood right 的見解，因為如果

1749
00:59:03,780 --> 00:59:04,680
你有點如果你 沒有

1750
00:59:04,680 --> 00:59:06,720
一個詞是什麼的目的地那麼

1751
00:59:06,720 --> 00:59:07,920
你真的有麻煩了就像我們必須

1752
00:59:07,920 --> 00:59:10,319
至少使用 LMS 或人工

1753
00:59:10,319 --> 00:59:12,780
系統來告知我們一個詞的意思

1754
00:59:12,780 --> 00:59:14,400
或者我們可能不再需要它了我是

1755
00:59:14,400 --> 00:59:16,859
不知道你

1756
00:59:16,859 --> 00:59:18,599


1757
00:59:18,599 --> 00:59:20,339


1758
00:59:20,339 --> 00:59:24,059


1759
00:59:24,059 --> 00:59:25,740


1760
00:59:25,740 --> 00:59:27,359
怎麼想 我不是

1761
00:59:27,359 --> 00:59:29,819
term word right what like

1762
00:59:29,819 --> 00:59:31,920
I mean you could use you know lemmas or

1763
00:59:31,920 --> 00:59:34,440
word firms or or anything like that

1764
00:59:34,440 --> 00:59:35,819
just feels like a conventional Choice

1765
00:59:35,819 --> 00:59:38,040
我不確定它是什麼，

1766
00:59:38,040 --> 00:59:39,180
那裡有什麼利害關係

1767
00:59:39,180 --> 00:59:41,880
所以你會怎麼想我會 說我

1768
00:59:41,880 --> 00:59:43,920
同意這個詞是一種約定俗成你

1769
00:59:43,920 --> 00:59:45,599
知道圖標不是直觀的概念

1770
00:59:45,599 --> 00:59:47,819
它經常受到正字法的影響

1771
00:59:47,819 --> 00:59:50,760
我們把空間放在正確的方式所以

1772
00:59:50,760 --> 00:59:52,559
我同意批評你

1773
00:59:52,559 --> 00:59:54,240
知道直覺意義上的詞並不是

1774
00:59:54,240 --> 00:59:56,339
真正的科學 然而，我

1775
00:59:56,339 --> 00:59:58,260
想讓我重新表述我的問題，嗯，

1776
00:59:58,260 --> 01:00:00,359
你知道如何將

1777
01:00:00,359 --> 01:00:02,160
單詞的直觀概念分解成

1778
01:00:02,160 --> 01:00:03,660
你知道的更

1779
01:00:03,660 --> 01:00:04,740
科學或

1780
01:00:04,740 --> 01:00:06,540
心理上合理的東西，這正是

1781
01:00:06,540 --> 01:00:08,280
幾何初級試圖

1782
01:00:08,280 --> 01:00:10,559
通過將單詞分解成你知道的來做的

1783
01:00:10,559 --> 01:00:12,599
獨特的特徵呃形態類別概念

1784
01:00:12,599 --> 01:00:15,180
根

1785
01:00:15,180 --> 01:00:17,579
與分類特徵合併你知道你

1786
01:00:17,579 --> 01:00:20,700
得到一個你知道的概念並且你已經

1787
01:00:20,700 --> 01:00:22,440
用名詞或類別來獲得

1788
01:00:22,440 --> 01:00:24,119
名詞或事件這些不同的模型

1789
01:00:24,119 --> 01:00:26,220
做出不同的預測是的我的

1790
01:00:26,220 --> 01:00:28,859
意思是我認為 這個一般想法

1791
01:00:28,859 --> 01:00:30,839
可能適用於大型語言

1792
01:00:30,839 --> 01:00:32,880
模型，比如我認為它們必須

1793
01:00:32,880 --> 01:00:34,380
具有類似於

1794
01:00:34,380 --> 01:00:36,660
詞性類別的東西，例如

1795
01:00:36,660 --> 01:00:38,819
嗯，我認為它們

1796
01:00:38,819 --> 01:00:42,900
必須能夠更新它們的

1797
01:00:42,900 --> 01:00:45,240
類別 基於

1798
01:00:45,240 --> 01:00:48,119
他們到目前為止所看到的正確語言，就像

1799
01:00:48,119 --> 01:00:50,520
你知道 GPT 將名詞和動詞放在

1800
01:00:50,520 --> 01:00:53,400
正確的位置一樣，要做到這一點，你

1801
01:00:53,400 --> 01:00:55,319
需要一些名詞

1802
01:00:55,319 --> 01:00:57,000
與動詞的表示，你需要一些

1803
01:00:57,000 --> 01:01:00,839
能力，嗯 uh 將自己定位在

1804
01:01:00,839 --> 01:01:02,579
一串其他單詞中並弄清楚下一個是否

1805
01:01:02,579 --> 01:01:04,680
可能是名詞或動詞

1806
01:01:04,680 --> 01:01:05,400


1807
01:01:05,400 --> 01:01:07,559
um 所以我認為在那個

1808
01:01:07,559 --> 01:01:09,319
級別上 uh 的那些詞的屬性

1809
01:01:09,319 --> 01:01:12,480
很可能是正確的並且

1810
01:01:12,480 --> 01:01:15,780
那裡 還有一些東西

1811
01:01:15,780 --> 01:01:17,640
很可能在

1812
01:01:17,640 --> 01:01:19,619
這些模型的內部表示中被發現，

1813
01:01:19,619 --> 01:01:21,420
我看不出它怎麼可能是

1814
01:01:21,420 --> 01:01:24,180
其他方式，呃，除了那個，

1815
01:01:24,180 --> 01:01:26,339
嗯，但據我所知，

1816
01:01:26,339 --> 01:01:29,579
那是 不是那個呃呃那不是

1817
01:01:29,579 --> 01:01:31,500
主要辯論或

1818
01:01:31,500 --> 01:01:35,220
分歧我認為是正確的就像

1819
01:01:35,220 --> 01:01:38,280
嗯嗯是的我認為所有

1820
01:01:38,280 --> 01:01:40,079
語言理論都必須說

1821
01:01:40,079 --> 01:01:41,400
有不同種類的詞

1822
01:01:41,400 --> 01:01:43,140
可以出現在不同的地方或

1823
01:01:43,140 --> 01:01:44,339
類似的東西

1824
01:01:44,339 --> 01:01:45,240
嗯，

1825
01:01:45,240 --> 01:01:47,160
好吧，那麼你知道你提到溝通的問題怎麼樣，

1826
01:01:47,160 --> 01:01:49,020


1827
01:01:49,020 --> 01:01:51,299
嗯，所以你知道，

1828
01:01:51,299 --> 01:01:53,099
當特朗普看到說語言

1829
01:01:53,099 --> 01:01:54,960
是一種思想系統或者你知道語言

1830
01:01:54,960 --> 01:01:57,780
沒有進化時，你是完全正確的他

1831
01:01:57,780 --> 01:01:58,799
有點 厚顏無恥，他並不是真的意味著

1832
01:01:58,799 --> 01:02:00,180
他在某種非常具體的意義上意味著對，

1833
01:02:00,180 --> 01:02:01,619


1834
01:02:01,619 --> 01:02:03,540
嗯，但是你知道當我們說語言是

1835
01:02:03,540 --> 01:02:05,640
一種思想系統時，我們的意思是，

1836
01:02:05,640 --> 01:02:06,780
嗯，我們正試圖讓它成為一種

1837
01:02:06,780 --> 01:02:08,339
建築主張，所以如果你看

1838
01:02:08,339 --> 01:02:09,599
極簡程序的架構 句法

1839
01:02:09,599 --> 01:02:10,380


1840
01:02:10,380 --> 01:02:12,240
推導和

1841
01:02:12,240 --> 01:02:13,740
概念系統實際上是

1842
01:02:13,740 --> 01:02:15,960
不同的系統 概念

1843
01:02:15,960 --> 01:02:18,180
系統從語法中獲取東西，然後

1844
01:02:18,180 --> 01:02:19,799
用它來處理自己的業務，CI

1845
01:02:19,799 --> 01:02:21,900
系統有自己獨特的規則

1846
01:02:21,900 --> 01:02:23,700
和原則，這就是我

1847
01:02:23,700 --> 01:02:25,319
認為的原因 在語言中都是相似的

1848
01:02:25,319 --> 01:02:27,000
符號組合系統，但在

1849
01:02:27,000 --> 01:02:29,160
不同的方式中，只有思想的一個子集

1850
01:02:29,160 --> 01:02:32,339
被恰當地稱為 CI 接口

1851
01:02:32,339 --> 01:02:34,619
系統，因為 CI 系統根據

1852
01:02:34,619 --> 01:02:36,480
定義你知道

1853
01:02:36,480 --> 01:02:38,819
人類擁有的任何無法訪問和

1854
01:02:38,819 --> 01:02:40,859
讀出語法指令的概念系統 我們

1855
01:02:40,859 --> 01:02:42,540
不完全知道它們是

1856
01:02:42,540 --> 01:02:43,920
什麼它們似乎與

1857
01:02:43,920 --> 01:02:45,540
語法指稱和確定性事件有關

1858
01:02:45,540 --> 01:02:47,099
它們似乎是

1859
01:02:47,099 --> 01:02:48,359
您所知道的語言在

1860
01:02:48,359 --> 01:02:49,440
概念上關心的主要類別

1861
01:02:49,440 --> 01:02:50,940
但我們真的不知道那隻是

1862
01:02:50,940 --> 01:02:52,859
一種 假設是對的，

1863
01:02:52,859 --> 01:02:53,940
但我們所知道的是，他們

1864
01:02:53,940 --> 01:02:56,220
似乎並沒有那麼

1865
01:02:56,220 --> 01:02:58,440
多地使用顏色，或者嗯，所以沒有語言在

1866
01:02:58,440 --> 01:03:00,240
形態上標記你知道顏色的深淺

1867
01:03:00,240 --> 01:03:01,140


1868
01:03:01,140 --> 01:03:03,900
嗯或其他概念特徵，比如

1869
01:03:03,900 --> 01:03:06,359
嗯嗯擔心或關注就像沒有語言

1870
01:03:06,359 --> 01:03:07,980
形態上的 標誌著對某個問題的某種程度的擔憂

1871
01:03:07,980 --> 01:03:10,079
或關注，但我們確實

1872
01:03:10,079 --> 01:03:11,960
使用了諸如

1873
01:03:11,960 --> 01:03:13,500


1874
01:03:13,500 --> 01:03:15,599
證據性之類的認識論概念，所以

1875
01:03:15,599 --> 01:03:17,640
你很了解一個我想我

1876
01:03:17,640 --> 01:03:19,500
說的是極簡主義程序在

1877
01:03:19,500 --> 01:03:21,720
試圖弄清楚 找出

1878
01:03:21,720 --> 01:03:23,400
思想語言的哪些方面與思想語言

1879
01:03:23,400 --> 01:03:25,619
密切相關，哪些方面與

1880
01:03:25,619 --> 01:03:27,900
思想語言無關，因此中西部

1881
01:03:27,900 --> 01:03:29,280
計劃使我們能夠相當

1882
01:03:29,280 --> 01:03:31,680
巧妙地劃分它，這是一個

1883
01:03:31,680 --> 01:03:33,180
比

1884
01:03:33,180 --> 01:03:34,559
喬姆斯基說語言思想時所知道的要微妙得多的框架

1885
01:03:34,559 --> 01:03:36,960
又一次，他不是，也許他的意思是，也許

1886
01:03:36,960 --> 01:03:38,339
他不是，但這不是

1887
01:03:38,339 --> 01:03:40,319
他理論的實際架構所說的，

1888
01:03:40,319 --> 01:03:42,480
這是一種修辭手段，如果你看一下實際的理論，

1889
01:03:42,480 --> 01:03:43,920
你就會知道它非常有用和有趣，可以

1890
01:03:43,920 --> 01:03:46,559
吸引本科生聽眾

1891
01:03:46,559 --> 01:03:48,839


1892
01:03:48,839 --> 01:03:50,700
從 The Mentalist 計劃中走出來 沒有

1893
01:03:50,700 --> 01:03:52,380
人真正相信語言等於

1894
01:03:52,380 --> 01:03:53,760
思想正確 語言系統似乎盡

1895
01:03:53,760 --> 01:03:55,920
最大努力訪問、

1896
01:03:55,920 --> 01:03:57,599
重新格式化和操縱各種

1897
01:03:57,599 --> 01:03:59,220
概念系統，但它有其局限性

1898
01:03:59,220 --> 01:04:01,440
我們知道系統拼寫什麼 關鍵

1899
01:04:01,440 --> 01:04:02,819
核心知識系統已連接

1900
01:04:02,819 --> 01:04:05,160
關於語法引擎，

1901
01:04:05,160 --> 01:04:07,260
哪些不是，

1902
01:04:07,260 --> 01:04:09,480
嗯，所以你知道這回到了這樣的

1903
01:04:09,480 --> 01:04:11,579
想法，即概念的詞法化

1904
01:04:11,579 --> 01:04:14,099
似乎可能以某種方式改變它，它在某種程度上將

1905
01:04:14,099 --> 01:04:16,200
它注入了

1906
01:04:16,200 --> 01:04:17,819
不存在的元素 概念本身，所以如果

1907
01:04:17,819 --> 01:04:19,319
你講的是一個概念，你會突然

1908
01:04:19,319 --> 01:04:21,240
改變它一點，給它

1909
01:04:21,240 --> 01:04:22,680
一點額外的東西，

1910
01:04:22,680 --> 01:04:24,299
在它上面撒一些東西，這似乎因

1911
01:04:24,299 --> 01:04:26,700
不同的納米類型而異，但這些

1912
01:04:26,700 --> 01:04:29,160
都是幾何結構中非常清晰的建築

1913
01:04:29,160 --> 01:04:31,619
主張 語法可以

1914
01:04:31,619 --> 01:04:34,980
做出非常明確的經驗預測所以

1915
01:04:34,980 --> 01:04:36,420
換句話說，我想我想說的

1916
01:04:36,420 --> 01:04:37,140
是

1917
01:04:37,140 --> 01:04:38,940
所有這些神經心理學研究都

1918
01:04:38,940 --> 01:04:42,119
被煽動了你知道在很多工作中

1919
01:04:42,119 --> 01:04:43,980
嗯在這方面它真正表明了什麼

1920
01:04:43,980 --> 01:04:45,420
我認為它表明你知道 當

1921
01:04:45,420 --> 01:04:47,819
語言在大腦中受損時，它會

1922
01:04:47,819 --> 01:04:50,040
失去這種影響這些系統的特殊影響或模式，

1923
01:04:50,040 --> 01:04:51,960
但

1924
01:04:51,960 --> 01:04:54,299
Gengram Enterprise 內部沒有真正的預測，

1925
01:04:54,299 --> 01:04:56,040
但那些非語言

1926
01:04:56,040 --> 01:04:57,540
系統應該會受損，或者

1927
01:04:57,540 --> 01:04:59,579
如果核心語言系統突然關閉，你會知道

1928
01:04:59,579 --> 01:05:01,200


1929
01:05:01,200 --> 01:05:02,760
嗯，事實上，如果

1930
01:05:02,760 --> 01:05:05,099
只是強調

1931
01:05:05,099 --> 01:05:07,859
句法

1932
01:05:07,859 --> 01:05:09,900
系統和非語言系統之間的主要分離是對的，

1933
01:05:09,900 --> 01:05:11,880
那麼我認為這裡的很多預測

1934
01:05:11,880 --> 01:05:14,339
來自語言和交流，嗯，

1935
01:05:14,339 --> 01:05:16,020
你知道文學有點遺漏了

1936
01:05:16,020 --> 01:05:19,380
重點 架構聲明，

1937
01:05:19,380 --> 01:05:21,540
嗯，我可以給，或者 Daniel 你

1938
01:05:21,540 --> 01:05:24,180
想去嗎，嗯，給點

1939
01:05:24,180 --> 01:05:25,799
背景知識，所以有這些

1940
01:05:25,799 --> 01:05:26,760
論文，嗯，嗯，

1941
01:05:26,760 --> 01:05:30,119
來自 EV federenko 和

1942
01:05:30,119 --> 01:05:32,880
Rosemary Varley，正在

1943
01:05:32,880 --> 01:05:34,500
檢查

1944
01:05:34,500 --> 01:05:37,799
嗯，嗯，嗯，部分 他們是失語症患者

1945
01:05:37,799 --> 01:05:40,200
所以所以語言能力受損的人

1946
01:05:40,200 --> 01:05:41,880


1947
01:05:41,880 --> 01:05:43,140


1948
01:05:43,140 --> 01:05:45,000
嗯嗯基本上表明

1949
01:05:45,000 --> 01:05:46,980
語言能力受損你你

1950
01:05:46,980 --> 01:05:49,020
嗯可以仍然有

1951
01:05:49,020 --> 01:05:50,579
嗯嗯保留某種推理

1952
01:05:50,579 --> 01:05:52,859
能力所以像國際象棋大師

1953
01:05:52,859 --> 01:05:55,020
國際象棋大師這樣的人

1954
01:05:55,020 --> 01:05:58,140
顯然非常好 在推理方面，

1955
01:05:58,140 --> 01:06:00,780
嗯嗯嗯可能沒有

1956
01:06:00,780 --> 01:06:02,640
完整的語言能力

1957
01:06:02,640 --> 01:06:04,079
嗯然後補充那種

1958
01:06:04,079 --> 01:06:06,119
耐心的工作還有

1959
01:06:06,119 --> 01:06:08,520
來自 ebb 實驗室的呃工作表明

1960
01:06:08,520 --> 01:06:11,220
嗯嗯呃大腦中

1961
01:06:11,220 --> 01:06:13,859
關心呃語言

1962
01:06:13,859 --> 01:06:14,640
嗯嗯的部分 與

1963
01:06:14,640 --> 01:06:16,319


1964
01:06:16,319 --> 01:06:17,700
大腦中關心其他

1965
01:06:17,700 --> 01:06:19,619
領域的部分是分開的，即使是那些具有相同類型

1966
01:06:19,619 --> 01:06:21,599
語言的領域，比如音樂

1967
01:06:21,599 --> 01:06:23,819
和數學之類的東西，嗯，嗯，

1968
01:06:23,819 --> 01:06:25,859
往往不會發生在

1969
01:06:25,859 --> 01:06:27,240
語言領域，

1970
01:06:27,240 --> 01:06:29,400
所以 EV 和其他人都有 爭辯說，

1971
01:06:29,400 --> 01:06:30,539


1972
01:06:30,539 --> 01:06:33,539
嗯，這基本上是反對

1973
01:06:33,539 --> 01:06:36,660
喬姆斯基的證據，並聲稱，嗯，

1974
01:06:36,660 --> 01:06:38,579
語言是正確思考的媒介，

1975
01:06:38,579 --> 01:06:40,440
因為

1976
01:06:40,440 --> 01:06:42,420
在沒有語言的情況下可能會發生思考，而

1977
01:06:42,420 --> 01:06:44,160
關心語言的大腦區域

1978
01:06:44,160 --> 01:06:46,020
似乎不是他們認為的大腦區域

1979
01:06:46,020 --> 01:06:48,359
關心關心思考

1980
01:06:48,359 --> 01:06:50,099
嗯我猜艾略特你是說

1981
01:06:50,099 --> 01:06:51,780
人們並不真的相信那個

1982
01:06:51,780 --> 01:06:53,039


1983
01:06:53,039 --> 01:06:56,220
他們不相信那種

1984
01:06:56,220 --> 01:06:57,720
區別我的意思是

1985
01:06:57,720 --> 01:06:59,880
嗯

1986
01:06:59,880 --> 01:07:01,740
不就是這樣而且還有很多

1987
01:07:01,740 --> 01:07:03,480
即使在這些論點中也有類似的自相矛盾

1988
01:07:03,480 --> 01:07:04,799
所以在你的

1989
01:07:04,799 --> 01:07:06,839
論文中你有時會說喬姆斯基

1990
01:07:06,839 --> 01:07:08,220
認為語言是一個思想系統

1991
01:07:08,220 --> 01:07:10,319
但是幾頁之後你會說

1992
01:07:10,319 --> 01:07:12,480
喬姆斯基也認為語法是

1993
01:07:12,480 --> 01:07:13,799
一個與其他任何東西完全不同的系統

1994
01:07:13,799 --> 01:07:15,480
對，你語法的自主權

1995
01:07:15,480 --> 01:07:18,900
等等，這是喬姆斯基的事，這

1996
01:07:18,900 --> 01:07:20,460
不是我的矛盾

1997
01:07:20,460 --> 01:07:22,140


1998
01:07:22,140 --> 01:07:24,780


1999
01:07:24,780 --> 01:07:26,280


2000
01:07:26,280 --> 01:07:28,319


2001
01:07:28,319 --> 01:07:30,420
從

2002
01:07:30,420 --> 01:07:32,520
體系結構的角度來看，只是

2003
01:07:32,520 --> 01:07:34,619
說語言是一種思想系統，

2004
01:07:34,619 --> 01:07:35,579
這意味著什麼，這並不意味著

2005
01:07:35,579 --> 01:07:36,780
什麼，這只是一個非常模糊的

2006
01:07:36,780 --> 01:07:38,640
陳述，問題是

2007
01:07:38,640 --> 01:07:41,280
語言究竟對雷神有何貢獻，以及

2008
01:07:41,280 --> 01:07:43,500
它如何沒有貢獻，嗯，是的，

2009
01:07:43,500 --> 01:07:45,839
我的意思是 我認為他的主張

2010
01:07:45,839 --> 01:07:48,420
主要是進化論或某些正確的東西，

2011
01:07:48,420 --> 01:07:51,180
呃這是系統的起源

2012
01:07:51,180 --> 01:07:52,859
，我認為這有點

2013
01:07:52,859 --> 01:07:55,559
同樣難以與

2014
01:07:55,559 --> 01:07:57,599
嗯嗯那種病人和

2015
01:07:57,599 --> 01:07:59,520
神經影像學數據

2016
01:07:59,520 --> 01:08:00,660


2017
01:08:00,660 --> 01:08:04,079
嗯嗯嗯但你知道 如果他不

2018
01:08:04,079 --> 01:08:07,079
這麼認為，那麼他就不應該這麼說，否則人們

2019
01:08:07,079 --> 01:08:08,579
會回應他所說的話，我認為

2020
01:08:08,579 --> 01:08:11,280
很好，不，不，因為爭論是

2021
01:08:11,280 --> 01:08:13,619
語言是一種思想系統，它

2022
01:08:13,619 --> 01:08:15,420
調節思想的某些方面，

2023
01:08:15,420 --> 01:08:16,920
它會產生 思想的某些方面顯然是

2024
01:08:16,920 --> 01:08:19,020
人類獨有的，但在

2025
01:08:19,020 --> 01:08:21,000
本質上或因果關係上並沒有與之相關

2026
01:08:21,000 --> 01:08:22,920


2027
01:08:22,920 --> 01:08:24,600
系統的架構與

2028
01:08:24,600 --> 01:08:26,399
您可以

2029
01:08:26,399 --> 01:08:28,979
從架構中修辭事件的那種概括​​非常不同，

2030
01:08:28,979 --> 01:08:30,960
例如當您從失語症現場工作時 正如

2031
01:08:30,960 --> 01:08:32,698


2032
01:08:32,698 --> 01:08:33,960
您剛才提到的

2033
01:08:33,960 --> 01:08:35,759
下棋等，患者在復雜推理方面沒有表現出任何缺陷，我們實際上希望

2034
01:08:35,759 --> 01:08:37,380
在一種您知道的幾何句法

2035
01:08:37,380 --> 01:08:39,179
的非詞彙主義框架下出現這種情況，

2036
01:08:39,179 --> 01:08:41,160
其中我所說的意思是

2037
01:08:41,160 --> 01:08:43,799
句法和形式形式只是意味著

2038
01:08:43,799 --> 01:08:45,600
您可以 外部化

2039
01:08:45,600 --> 01:08:46,979
語言，所有這些東西都是

2040
01:08:46,979 --> 01:08:48,540
獨立的功能和獨立的系統，

2041
01:08:48,540 --> 01:08:51,000
正確的語法自主性並不

2042
01:08:51,000 --> 01:08:52,020
意味著

2043
01:08:52,020 --> 01:08:53,819
你知道很多人認為這

2044
01:08:53,819 --> 01:08:54,719
意味著它只是意味著要么

2045
01:08:54,719 --> 01:08:56,160
某些某些語法操作

2046
01:08:56,160 --> 01:08:58,439
不是語義的某些

2047
01:08:58,439 --> 01:09:00,299
東西 你可以用你

2048
01:09:00,299 --> 01:09:01,920
只能做語法而不能做

2049
01:09:01,920 --> 01:09:03,420
語義的語法來做，所以這又回到了

2050
01:09:03,420 --> 01:09:05,279
你知道呃

2051
01:09:05,279 --> 01:09:07,259
彼得羅夫斯基的理論語義是

2052
01:09:07,259 --> 01:09:10,319
公正和正確與呃允許

2053
01:09:10,319 --> 01:09:11,698
合成學家相信存在

2054
01:09:11,698 --> 01:09:13,080
某些奇怪的奇怪事物之間的區別 你可以

2055
01:09:13,080 --> 01:09:15,719
用句法的句法來做，所以

2056
01:09:15,719 --> 01:09:17,759
即使在那種架構框架內也有離婚

2057
01:09:17,759 --> 01:09:20,100
，所以

2058
01:09:20,100 --> 01:09:22,439
你也發現

2059
01:09:22,439 --> 01:09:24,359
神經心理學

2060
01:09:24,359 --> 01:09:25,979
層面的離婚並不奇怪我會說

2061
01:09:25,979 --> 01:09:28,319
我想我會

2062
01:09:28,319 --> 01:09:30,960
想要一個 語言的預測被

2063
01:09:30,960 --> 01:09:34,140
認為是進化的想法然後是正確的所以

2064
01:09:34,140 --> 01:09:36,960
就像呃如果那不是如果你說

2065
01:09:36,960 --> 01:09:39,060
那不能預測思想

2066
01:09:39,060 --> 01:09:41,160
依賴於語言

2067
01:09:41,160 --> 01:09:44,399
那麼呃我認為喜歡

2068
01:09:44,399 --> 01:09:45,899
那個理論的人應該提出

2069
01:09:45,899 --> 01:09:47,520
一些預測

2070
01:09:47,520 --> 01:09:49,979
嗯，嗯，你知道那個

2071
01:09:49,979 --> 01:09:51,660
理論實際上意味著什麼我的意思是我覺得

2072
01:09:51,660 --> 01:09:53,819
這些類型的預測

2073
01:09:53,819 --> 01:09:55,440
對於理解預測的內容通常是非常必要的

2074
01:09:55,440 --> 01:09:57,360


2075
01:09:57,360 --> 01:09:58,320


2076
01:09:58,320 --> 01:10:00,540
嗯嗯很抱歉丹尼爾你的手已經

2077
01:10:00,540 --> 01:10:03,660
舉了一段時間呃不 一切都很好，

2078
01:10:03,660 --> 01:10:05,880
只是有點想吸

2079
01:10:05,880 --> 01:10:08,040


2080
01:10:08,040 --> 01:10:12,660
一口氣，嗯，這是一個機會，讓

2081
01:10:12,660 --> 01:10:15,480
任何人都可以問任何其他

2082
01:10:15,480 --> 01:10:17,520
問題，但是哇，

2083
01:10:17,520 --> 01:10:20,460
謝謝你們，我們已經討論了很多話題，嗯，

2084
01:10:20,460 --> 01:10:21,780


2085
01:10:21,780 --> 01:10:22,500


2086
01:10:22,500 --> 01:10:25,199
我們將在最後幾分鐘討論，嗯，

2087
01:10:25,199 --> 01:10:27,120
有點 結論和後續步驟 但 Dave

2088
01:10:27,120 --> 01:10:29,820
你想問一個問題還是

2089
01:10:29,820 --> 01:10:32,840
做一個簡短的反思

2090
01:10:36,900 --> 01:10:38,880
好吧不嗯

2091
01:10:38,880 --> 01:10:39,960


2092
01:10:39,960 --> 01:10:42,239
聊天中有很多評論所以我

2093
01:10:42,239 --> 01:10:45,120
希望你們兩個都可以在

2094
01:10:45,120 --> 01:10:47,460
自己的時間閱讀它們以查看每個人都

2095
01:10:47,460 --> 01:10:49,440
添加了什麼

2096
01:10:49,440 --> 01:10:52,860
當我們

2097
01:10:52,860 --> 01:10:57,179
咆哮到 2023 年 5 月時，我們會從這裡走嗎？超越

2098
01:10:57,179 --> 01:11:00,960
語言學家、大型語言模型

2099
01:11:00,960 --> 01:11:02,940
開發人員和用戶認知

2100
01:11:02,940 --> 01:11:05,159
科學家，你們每個人認為什麼是

2101
01:11:05,159 --> 01:11:06,960
最富有成效的前進道路

2102
01:11:06,960 --> 01:11:08,159


2103
01:11:08,159 --> 01:11:10,080
好吧，

2104
01:11:10,080 --> 01:11:13,260
我會說，嗯，你知道，嗯，最

2105
01:11:13,260 --> 01:11:14,699
富有成效的前進道路 是真的

2106
01:11:14,699 --> 01:11:15,600


2107
01:11:15,600 --> 01:11:17,460
像認知心理學一樣對待 um 不

2108
01:11:17,460 --> 01:11:18,659
認真最近有很多不錯的工作

2109
01:11:18,659 --> 01:11:21,000
試圖調整事情，比如

2110
01:11:21,000 --> 01:11:24,060
是的，你知道來自 alpha 插件的 Church EBT wolf

2111
01:11:24,060 --> 01:11:25,739
聊天 gbt 可以

2112
01:11:25,739 --> 01:11:28,080
與不同類型的模塊交互的方式

2113
01:11:28,080 --> 01:11:30,179
um 構建合法的方式

2114
01:11:30,179 --> 01:11:32,580
一種 AGI 系統，你不一定必須

2115
01:11:32,580 --> 01:11:34,380
知道它在心理上

2116
01:11:34,380 --> 01:11:35,880
依賴於

2117
01:11:35,880 --> 01:11:37,500
人類擁有的那種模塊，但我認為它會

2118
01:11:37,500 --> 01:11:38,820
從中受益所以

2119
01:11:38,820 --> 01:11:41,040
有人聲稱大型語言模型

2120
01:11:41,040 --> 01:11:42,540
也許你知道嗎 各種

2121
01:11:42,540 --> 01:11:43,860
事情都是正確的一切你

2122
01:11:43,860 --> 01:11:44,760
喜歡的一切

2123
01:11:44,760 --> 01:11:46,620
嗯但我認為從長遠來看，最

2124
01:11:46,620 --> 01:11:47,880
有可能的情況是 llms

2125
01:11:47,880 --> 01:11:49,380
可以做一些非常重要和非常

2126
01:11:49,380 --> 01:11:51,000
有趣的事情，但它只是

2127
01:11:51,000 --> 01:11:53,100
拼圖的一部分所以實際上什至是

2128
01:11:53,100 --> 01:11:55,440
開放的 AI CEO Sam Altman 上周說，

2129
01:11:55,440 --> 01:11:56,400


2130
01:11:56,400 --> 01:11:58,440
嗯，你知道我們可以用 llms 做什麼

2131
01:11:58,440 --> 01:12:00,120
真的有點累了，我們需要

2132
01:12:00,120 --> 01:12:02,520
新的方向新的新途徑

2133
01:12:02,520 --> 01:12:04,860
等等我想你可能

2134
01:12:04,860 --> 01:12:07,440
更了解與投資者交談而不是

2135
01:12:07,440 --> 01:12:09,060
語言 這裡的學生，但我

2136
01:12:09,060 --> 01:12:11,159
認為他也是對的，你知道 llms 可以

2137
01:12:11,159 --> 01:12:12,300
做一些驚人的事情，但它們

2138
01:12:12,300 --> 01:12:14,760
可能會構成通用 AGI 架構的一小部分，

2139
01:12:14,760 --> 01:12:17,760


2140
01:12:17,760 --> 01:12:19,679
如果你想在這裡將 AGI 視為一個

2141
01:12:19,679 --> 01:12:21,900
潛在的潛在目標，

2142
01:12:21,900 --> 01:12:25,679
那麼你知道 我想很多所以

2143
01:12:25,679 --> 01:12:28,020
讓我在這裡舉另一個例子所以

2144
01:12:28,020 --> 01:12:29,820
嗯安娜甚至超過

2145
01:12:29,820 --> 01:12:31,920
嗯她是一位非常優秀的多產

2146
01:12:31,920 --> 01:12:34,140
科學家她最近有一篇論文

2147
01:12:34,140 --> 01:12:35,400
嗯爭論一種

2148
01:12:35,400 --> 01:12:37,800
用於 llms 的模塊化架構這是一個

2149
01:12:37,800 --> 01:12:39,060
非常好的框架它是 在

2150
01:12:39,060 --> 01:12:40,860
認知上非常合理，這正是

2151
01:12:40,860 --> 01:12:41,880
我們應該推動的事情，

2152
01:12:41,880 --> 01:12:43,679
因為它與霍華德

2153
01:12:43,679 --> 01:12:45,239
加德納的多元智能概念兼容，等等，嗯，

2154
01:12:45,239 --> 01:12:46,800


2155
01:12:46,800 --> 01:12:48,000
但我認為同時只是

2156
01:12:48,000 --> 01:12:49,620
為了完成這個評論，

2157
01:12:49,620 --> 01:12:51,360
嗯，最後有一個技術談話 我

2158
01:12:51,360 --> 01:12:54,840
想這週或者幾天前，嗯，

2159
01:12:54,840 --> 01:12:56,880
很多其他的東西可以以

2160
01:12:56,880 --> 01:12:59,520
非生產性的方式與 AI 炒作混為一談，所以

2161
01:12:59,520 --> 01:13:02,100
來自 openai 的 Greg Brockman 他給出了他的一個，

2162
01:13:02,100 --> 01:13:04,199
呃，其中一個 Ted Talks，他

2163
01:13:04,199 --> 01:13:06,179
展示了可以聊天 GPD 的不同插件

2164
01:13:06,179 --> 01:13:08,159
可以做我提到的 Wolfram 操作，但

2165
01:13:08,159 --> 01:13:09,300
也有圖像

2166
01:13:09,300 --> 01:13:11,820
生成 instacart 購物之類的東西，在那裡你

2167
01:13:11,820 --> 01:13:13,560
可以通過聊天電視給你買東西，

2168
01:13:13,560 --> 01:13:15,060
你有什麼，

2169
01:13:15,060 --> 01:13:17,040
嗯，這再次讓你回到

2170
01:13:17,040 --> 01:13:18,960
多個子系統可以執行

2171
01:13:18,960 --> 01:13:20,940
不同子功能的想法，所以 Brockovich

2172
01:13:20,940 --> 01:13:22,620
還展示了一個例子，給聊天

2173
01:13:22,620 --> 01:13:26,820
GPT 一個 Excel 文件一個 CSV 文件和一個

2174
01:13:26,820 --> 01:13:28,739
學術論文的存檔數據庫，

2175
01:13:28,739 --> 01:13:30,060
它只列出了一堆論文

2176
01:13:30,060 --> 01:13:31,739
，然後是標題，你有什麼

2177
01:13:31,739 --> 01:13:32,880
權利

2178
01:13:32,880 --> 01:13:34,500
嗯，他說你知道使用

2179
01:13:34,500 --> 01:13:37,440
chatipati 它使用 World Knowledge 來

2180
01:13:37,440 --> 01:13:39,060
推斷列標題的

2181
01:13:39,060 --> 01:13:40,860
含義，因此我們知道您知道

2182
01:13:40,860 --> 01:13:42,780
標題是指論文的標題，它

2183
01:13:42,780 --> 01:13:44,640
理解作者是指

2184
01:13:44,640 --> 01:13:47,280
每篇論文的作者人數，它理解

2185
01:13:47,280 --> 01:13:48,840
創建是指論文

2186
01:13:48,840 --> 01:13:50,820
正確提交的日期，因為它是 TED

2187
01:13:50,820 --> 01:13:52,080
演講你知道所有的觀眾

2188
01:13:52,080 --> 01:13:54,120
都給了我們一個起立鼓掌的權利

2189
01:13:54,120 --> 01:13:56,340
嗯但是我想在 Excel 文件上描述標籤的能力

2190
01:13:56,340 --> 01:13:57,900


2191
01:13:57,900 --> 01:14:01,679
很好但嗯我不確定

2192
01:14:01,679 --> 01:14:03,120
你真的稱之為世界知識所以

2193
01:14:03,120 --> 01:14:04,800
我想有很多 我只想說，在

2194
01:14:04,800 --> 01:14:06,719


2195
01:14:06,719 --> 01:14:08,880
減少人類小體的同時還需要取得很多進展，

2196
01:14:08,880 --> 01:14:11,640
並且你有適當的平衡，所以

2197
01:14:11,640 --> 01:14:12,659
就像我說的，你必須有正確的

2198
01:14:12,659 --> 01:14:13,920
平衡，嗯，在

2199
01:14:13,920 --> 01:14:15,360
心理上合理的

2200
01:14:15,360 --> 01:14:17,100
模塊化架構，但你不能有

2201
01:14:17,100 --> 01:14:18,480
太多 很多

2202
01:14:18,480 --> 01:14:19,920
um 擬人化 因為那樣你會被

2203
01:14:19,920 --> 01:14:21,540
帶走你必鬚髮現我們

2204
01:14:21,540 --> 01:14:22,860
必須在

2205
01:14:22,860 --> 01:14:25,739
建模類人 uh 模塊化

2206
01:14:25,739 --> 01:14:27,780
系統之間找到正確的平衡，但不要把它做到

2207
01:14:27,780 --> 01:14:29,280
你知道

2208
01:14:29,280 --> 01:14:31,140
有點難以置信或科學上

2209
01:14:31,140 --> 01:14:33,679
無用的程度

2210
01:14:35,040 --> 01:14:37,500
我的意思是，我認為我同意所有這些，

2211
01:14:37,500 --> 01:14:40,199
我真的很興奮，因為這些將

2212
01:14:40,199 --> 01:14:42,739
語言模型連接到

2213
01:14:42,739 --> 01:14:45,120
其他信息

2214
01:14:45,120 --> 01:14:47,640
處理形式的方法，呃，這看起來確實像

2215
01:14:47,640 --> 01:14:49,679
人們所擁有的，我想我是說

2216
01:14:49,679 --> 01:14:52,620
我' 我對

2217
01:14:52,620 --> 01:14:54,840
他們能夠做的事情感到非常驚訝，

2218
01:14:54,840 --> 01:14:58,260
就像語言建模一樣，所以

2219
01:14:58,260 --> 01:15:00,120
你知道不同種類的推理

2220
01:15:00,120 --> 01:15:01,920
難題和他們可以解決的事情，

2221
01:15:01,920 --> 01:15:05,340
我認為這真的很迷人

2222
01:15:05,340 --> 01:15:07,920
而且你知道也許會 要求我們

2223
01:15:07,920 --> 01:15:09,719
重新思考我們所知道的

2224
01:15:09,719 --> 01:15:11,760
語言和思想之間的關係

2225
01:15:11,760 --> 01:15:13,500
，並嘗試找出一種方法

2226
01:15:13,500 --> 01:15:15,239
來具體說明

2227
01:15:15,239 --> 01:15:17,760
某物具有

2228
01:15:17,760 --> 01:15:19,380
表徵或推理

2229
01:15:19,380 --> 01:15:21,060
該表徵意味著什麼但最終我

2230
01:15:21,060 --> 01:15:23,820
想我同意 嗯，嗯，

2231
01:15:23,820 --> 01:15:26,219
你知道人們有不同的

2232
01:15:26,219 --> 01:15:28,560
思考方式，這

2233
01:15:28,560 --> 01:15:32,400
對智力來說似乎很重要，

2234
01:15:32,400 --> 01:15:35,040
嗯，我也對嬰兒

2235
01:15:35,040 --> 01:15:37,620
LM 挑戰感到非常興奮，所以我認為在

2236
01:15:37,620 --> 01:15:39,960
語言方面是對的，

2237
01:15:39,960 --> 01:15:42,300
嗯，這正是 正確的做法是

2238
01:15:42,300 --> 01:15:45,300
看看我們能用

2239
01:15:45,300 --> 01:15:47,219
更小的數據集取得多遠，嗯，也許

2240
01:15:47,219 --> 01:15:50,820
最終你會知道嘗試嗯，嗯，

2241
01:15:50,820 --> 01:15:53,699
了解更多關於

2242
01:15:53,699 --> 01:15:55,739
孩子們獲得的語義類型

2243
01:15:55,739 --> 01:15:57,840
以及他們從哪裡獲得

2244
01:15:57,840 --> 01:15:59,820
以及如何獲得的語義 某種外部語義

2245
01:15:59,820 --> 01:16:02,520
可以為語言學習提供信息，或者

2246
01:16:02,520 --> 01:16:04,560
特別是語法和

2247
01:16:04,560 --> 01:16:06,600
句法學習，嗯，

2248
01:16:06,600 --> 01:16:09,480
我想我的另一個呃路徑前進

2249
01:16:09,480 --> 01:16:12,179
點是

2250
01:16:12,179 --> 01:16:15,840
嗯，嗯，就像我覺得

2251
01:16:15,840 --> 01:16:18,300
這些模型已經有，嗯，

2252
01:16:18,300 --> 01:16:21,179
嗯，真的走了很遠 超出人們

2253
01:16:21,179 --> 01:16:23,340
對這類

2254
01:16:23,340 --> 01:16:25,500
模型的期望 正確的基礎

2255
01:16:25,500 --> 01:16:27,960
統計學習 發現

2256
01:16:27,960 --> 01:16:29,940
文本中的模式

2257
01:16:29,940 --> 01:16:30,719


2258
01:16:30,719 --> 01:16:32,640
嗯 似乎給出了非常

2259
01:16:32,640 --> 01:16:35,040
非常顯著的結果

2260
01:16:35,040 --> 01:16:37,020
嗯 對我來說，我

2261
01:16:37,020 --> 01:16:39,360
認為這剛剛引入了巨大的浪潮

2262
01:16:39,360 --> 01:16:42,000
理論的不確定性，所以我認為

2263
01:16:42,000 --> 01:16:43,620
我們的理論

2264
01:16:43,620 --> 01:16:46,739
基本上可以肯定是語言中的一切，

2265
01:16:46,739 --> 01:16:48,960
但認知可能是神經科學，

2266
01:16:48,960 --> 01:16:50,640
就像我認為的所有這些東西一樣，

2267
01:16:50,640 --> 01:16:53,100


2268
01:16:53,100 --> 01:16:54,420
當我們真正開始

2269
01:16:54,420 --> 01:16:56,219
理解這種

2270
01:16:56,219 --> 01:16:58,560
能力時，我們將重新研究 像

2271
01:16:58,560 --> 01:17:02,219
這樣的真正通用的學習系統，所以

2272
01:17:02,219 --> 01:17:03,900
嗯，一方面讓你知道，

2273
01:17:03,900 --> 01:17:05,820
嗯，

2274
01:17:05,820 --> 01:17:07,440
對過去的理論來說有點令人失望，

2275
01:17:07,440 --> 01:17:09,360
尤其是那些

2276
01:17:09,360 --> 01:17:11,640
依賴於

2277
01:17:11,640 --> 01:17:14,100
嗯你知道學習不能

2278
01:17:14,100 --> 01:17:15,659
很好地工作的理論

2279
01:17:15,659 --> 01:17:18,000
但從好的方面來說，我認為這

2280
01:17:18,000 --> 01:17:20,460
對

2281
01:17:20,460 --> 01:17:22,620
人工智能、認知科學和

2282
01:17:22,620 --> 01:17:24,000
語言學來說都是一個非常激動人心的時刻，嗯，

2283
01:17:24,000 --> 01:17:25,560
現在有這些

2284
01:17:25,560 --> 01:17:27,420
非常強大的工具，嗯，

2285
01:17:27,420 --> 01:17:29,719
這似乎是朝著

2286
01:17:29,719 --> 01:17:32,940
人類能力邁出的質上不同規模的一步，

2287
01:17:32,940 --> 01:17:34,620


2288
01:17:34,620 --> 01:17:36,120
嗯 我認為可以將它們整合起來，

2289
01:17:36,120 --> 01:17:39,060
並同時學習

2290
01:17:39,060 --> 01:17:41,280
工程課程和

2291
01:17:41,280 --> 01:17:43,679
哲學課程，了解它們是如何

2292
01:17:43,679 --> 01:17:45,540
製造的，以及

2293
01:17:45,540 --> 01:17:47,460
設計智能係統的原則是什麼，我

2294
01:17:47,460 --> 01:17:49,679
認為那些東西會

2295
01:17:49,679 --> 01:17:52,080
將真正塑造未來

2296
01:17:52,080 --> 01:17:53,699
五到十年的感覺，

2297
01:17:53,699 --> 01:17:54,900


2298
01:17:54,900 --> 01:17:57,000
嗯，就像我只是在

2299
01:17:57,000 --> 01:17:58,500
更廣泛的主題背景下說的那樣，就

2300
01:17:58,500 --> 01:17:59,760
好像你是完全正確的，就像我

2301
01:17:59,760 --> 01:18:01,620
記得當我讀到什麼時候

2302
01:18:01,620 --> 01:18:04,920
深藍色是呃卡斯珀一樣 是

2303
01:18:04,920 --> 01:18:07,260
國際象棋嗎，嗯，是的，有

2304
01:18:07,260 --> 01:18:08,940
一些評論員說你知道國際

2305
01:18:08,940 --> 01:18:12,480
象棋已經結束了，如果人工智能可以成為人類，

2306
01:18:12,480 --> 01:18:13,739
那麼它就是關於

2307
01:18:13,739 --> 01:18:15,420
學習國際象棋的意義的遊戲，你知道沒有必要再

2308
01:18:15,420 --> 01:18:16,920
無聊了，

2309
01:18:16,920 --> 01:18:18,900
嗯，我想 如果人工智能似乎已經實現了

2310
01:18:18,900 --> 01:18:20,640
人類

2311
01:18:20,640 --> 01:18:22,140
下棋所需做的一切，那麼下棋的意義是什麼，

2312
01:18:22,140 --> 01:18:23,100


2313
01:18:23,100 --> 01:18:24,540
嗯，但我想你知道它是否會

2314
01:18:24,540 --> 01:18:26,219
增加國際象棋的受歡迎程度，

2315
01:18:26,219 --> 01:18:27,900
對吧，他們在我們的迷你國際象棋

2316
01:18:27,900 --> 01:18:29,580
名人以及全球

2317
01:18:29,580 --> 01:18:31,199
錦標賽中 而且我預測

2318
01:18:31,199 --> 01:18:32,520


2319
01:18:32,520 --> 01:18:34,620
語言也可能會發生同樣的情況，你知道 llms 並不意味著

2320
01:18:34,620 --> 01:18:36,360
它是語言的終結，不再是

2321
01:18:36,360 --> 01:18:37,800
語言，不再是語言學，我

2322
01:18:37,800 --> 01:18:39,179
實際上會反駁說，也許它

2323
01:18:39,179 --> 01:18:40,620
會恰恰相反，嗯，

2324
01:18:40,620 --> 01:18:42,540
你知道成功的 LMS 將

2325
01:18:42,540 --> 01:18:44,400
增加對語言理論的普遍興趣，

2326
01:18:44,400 --> 01:18:46,199
因為它們的配對你知道

2327
01:18:46,199 --> 01:18:48,060
奇怪的約束和明顯的

2328
01:18:48,060 --> 01:18:50,100
限制，因為我還要

2329
01:18:50,100 --> 01:18:52,380
說你知道此時的規模，

2330
01:18:52,380 --> 01:18:55,500
壓力問題的規模肯定

2331
01:18:55,500 --> 01:18:57,420
遠遠不夠，所

2332
01:18:57,420 --> 01:18:59,820
缺乏的是 LMS 的一種能力，你知道它

2333
01:18:59,820 --> 01:19:01,260
確實抽象了他們的知識和

2334
01:19:01,260 --> 01:19:03,239
經驗，以便進行群體清洗

2335
01:19:03,239 --> 01:19:04,739
預測和概括等

2336
01:19:04,739 --> 01:19:06,780
我舉了一些例子，但

2337
01:19:06,780 --> 01:19:07,860
在文獻中還有其他一些它

2338
01:19:07,860 --> 01:19:09,179
似乎並不擅長

2339
01:19:09,179 --> 01:19:10,739
概括 go of maybe

2340
01:19:10,739 --> 01:19:13,620
particular token types and but I would

2341
01:19:13,620 --> 01:19:15,060
you know I would you know I would guess my final 我最後的

2342
01:19:15,060 --> 01:19:17,100
主張是你知道

2343
01:19:17,100 --> 01:19:19,080
語言習得文獻

2344
01:19:19,080 --> 01:19:21,480
um 不一定需要 llms 儘管

2345
01:19:21,480 --> 01:19:22,860
你知道認知科學家並不

2346
01:19:22,860 --> 01:19:26,219
真的需要 llms 我們可能 呃，

2347
01:19:26,219 --> 01:19:27,420
你知道恢復原狀，但顯然

2348
01:19:27,420 --> 01:19:29,640
不同意，但嗯，我想說的是，從 llms 中

2349
01:19:29,640 --> 01:19:32,040
獲利的大型科技公司需要

2350
01:19:32,040 --> 01:19:33,360
llms，對，他們是唯一

2351
01:19:33,360 --> 01:19:35,100


2352
01:19:35,100 --> 01:19:37,320
真正這樣做的公司

2353
01:19:37,320 --> 01:19:39,000
一個非常多樣化的空間可能存在

2354
01:19:39,000 --> 01:19:40,560
某些形式的行為

2355
01:19:40,560 --> 01:19:42,420
和學習可能會被

2356
01:19:42,420 --> 01:19:44,219
類似於 llms 正在做的過程所捕獲，

2357
01:19:44,219 --> 01:19:45,540
所以斯蒂芬

2358
01:19:45,540 --> 01:19:47,159
在他的論文中給出了一些有趣的例子關於磁力

2359
01:19:47,159 --> 01:19:49,320
和奇怪的學習規則

2360
01:19:49,320 --> 01:19:51,060
非常普遍，非常

2361
01:19:51,060 --> 01:19:52,920
快速，非常神秘，所以你知道

2362
01:19:52,920 --> 01:19:54,780
也許對於那些事情，

2363
01:19:54,780 --> 01:19:56,100
這種學習將是

2364
01:19:56,100 --> 01:19:57,780
相關的，但我仍然認為

2365
01:19:57,780 --> 01:19:59,580
其中一個候選人不太可能

2366
01:19:59,580 --> 01:20:02,100
是自然語言，至少是

2367
01:20:02,100 --> 01:20:03,480
自然的方式 語言是有效的，它

2368
01:20:03,480 --> 01:20:05,219
在形式上非常榮耀，主要是

2369
01:20:05,219 --> 01:20:07,380
監管，你有什麼，所以我想

2370
01:20:07,380 --> 01:20:09,300
你知道這讓我想起了你

2371
01:20:09,300 --> 01:20:11,520
在哪裡你知道你有這張

2372
01:20:11,520 --> 01:20:13,320
圖片我最近看到了約翰維克第四章，

2373
01:20:13,320 --> 01:20:14,940
他有 這是

2374
01:20:14,940 --> 01:20:16,140
他在沙漠中行走的場景

2375
01:20:16,140 --> 01:20:17,580
，他不確定自己是否看到了

2376
01:20:17,580 --> 01:20:19,260
這個想要暗殺的人，

2377
01:20:19,260 --> 01:20:21,540
這有點像當你在沙漠中行走時，

2378
01:20:21,540 --> 01:20:22,739


2379
01:20:22,739 --> 01:20:24,840
嗯，你有一種看到

2380
01:20:24,840 --> 01:20:26,460
綠洲的錯覺，因為事實證明你 重新產生

2381
01:20:26,460 --> 01:20:28,199
幻覺，但隨後你意識到

2382
01:20:28,199 --> 01:20:29,820
你有時在為時已晚之前知道

2383
01:20:29,820 --> 01:20:31,679
你實際上正在產生幻覺它是

2384
01:20:31,679 --> 01:20:33,239
你沒有看到綠洲你仍然

2385
01:20:33,239 --> 01:20:35,040
在沙漠中我認為這

2386
01:20:35,040 --> 01:20:37,199
可能就是我們現在所處的情況

2387
01:20:37,199 --> 01:20:39,360
有了很多語言模型的語言能力，

2388
01:20:39,360 --> 01:20:41,400
我們就有了

2389
01:20:41,400 --> 01:20:44,940
呃語言能力的錯覺，因為你知道，

2390
01:20:44,940 --> 01:20:46,260
嗯，你總是在找到綠洲之前看到錯覺，

2391
01:20:46,260 --> 01:20:48,360
所以我想我

2392
01:20:48,360 --> 01:20:49,440
認為現在我們處於

2393
01:20:49,440 --> 01:20:51,420
沙漠的幻覺狀態

2394
01:20:51,420 --> 01:20:53,699
我看到了

2395
01:20:53,699 --> 01:20:55,380
語言能力的潛在火花，但它仍然不是

2396
01:20:55,380 --> 01:20:57,420
很清晰和強大，嗯，

2397
01:20:57,420 --> 01:20:59,640
我們還沒有真正到達綠洲，

2398
01:20:59,640 --> 01:21:02,480
是的，

2399
01:21:02,820 --> 01:21:06,360
嗯，只是一個快速的問題，所以看看

2400
01:21:06,360 --> 01:21:09,540
你是否可以給出一個簡短的回答，所以

2401
01:21:09,540 --> 01:21:11,219
svenochino

2402
01:21:11,219 --> 01:21:13,440
寫了一個問題，它是正確的嗎 要說

2403
01:21:13,440 --> 01:21:15,120
大型語言模型沒有

2404
01:21:15,120 --> 01:21:17,540
先驗，

2405
01:21:18,480 --> 01:21:21,300
大型語言模型是否有先驗，我會

2406
01:21:21,300 --> 01:21:23,820
說是的，他們肯定有，嗯

2407
01:21:23,820 --> 01:21:25,620
，

2408
01:21:25,620 --> 01:21:28,440
嗯，他們是我認為

2409
01:21:28,440 --> 01:21:30,360
你認識的人習慣於思考

2410
01:21:30,360 --> 01:21:32,340
先驗和貝葉斯推理的區別

2411
01:21:32,340 --> 01:21:33,840
例如，如果你喜歡寫下

2412
01:21:33,840 --> 01:21:36,300
貝葉斯統計模型，你會說

2413
01:21:36,300 --> 01:21:37,860
你知道這是參數，

2414
01:21:37,860 --> 01:21:39,300
這是參數上的先驗是

2415
01:21:39,300 --> 01:21:40,860


2416
01:21:40,860 --> 01:21:42,360
大型語言模型，我認為

2417
01:21:42,360 --> 01:21:44,340
先驗是

2418
01:21:44,340 --> 01:21:45,900
一般的神經堅果，我認為那是

2419
01:21:45,900 --> 01:21:47,880
先驗是更隱含的，所以

2420
01:21:47,880 --> 01:21:49,679
有一些函數他們發現

2421
01:21:49,679 --> 01:21:52,080
比其他函數更容易學習，甚至

2422
01:21:52,080 --> 01:21:53,760
還有一些工作試圖

2423
01:21:53,760 --> 01:21:55,860
發現你知道一些關於那些

2424
01:21:55,860 --> 01:21:57,540
隱含

2425
01:21:57,540 --> 01:21:59,040
先驗是

2426
01:21:59,040 --> 01:22:00,840
什麼的陳述，但這實際上是我的想法

2427
01:22:00,840 --> 01:22:02,040
關於

2428
01:22:02,040 --> 01:22:02,940
嗯，

2429
01:22:02,940 --> 01:22:04,620
嗯，你知道不同

2430
01:22:04,620 --> 01:22:07,199
神經網絡架構的比較，

2431
01:22:07,199 --> 01:22:09,060
嗯，嗯，這可能是一件值得高興的事情，

2432
01:22:09,060 --> 01:22:10,500
我可能會同意

2433
01:22:10,500 --> 01:22:12,600
你必須找到先驗知識，讓他們學習

2434
01:22:12,600 --> 01:22:14,400
孩子們正確學習的東西，

2435
01:22:14,400 --> 01:22:16,140


2436
01:22:16,140 --> 01:22:19,080
嗯，並不是所有的架構都會

2437
01:22:19,080 --> 01:22:21,360
即使在正在

2438
01:22:21,360 --> 01:22:23,280
變得完整或能夠學習

2439
01:22:23,280 --> 01:22:24,719
任何類型的功能的架構中也這樣做，

2440
01:22:24,719 --> 01:22:27,540
即使在

2441
01:22:27,540 --> 01:22:30,000
巨大的數據集大小上，也不是所有的架構都會這樣做，所以

2442
01:22:30,000 --> 01:22:31,800
嗯，我認為這種對

2443
01:22:31,800 --> 01:22:34,080
神經網絡架構的搜索是 確實是對

2444
01:22:34,080 --> 01:22:36,360
先驗的搜索之一，

2445
01:22:36,360 --> 01:22:38,580
嗯，但它不是先驗，或者我的意思是你

2446
01:22:38,580 --> 01:22:39,719
可以將其視為對

2447
01:22:39,719 --> 01:22:41,699
通用語法的搜索或正確的東西，但

2448
01:22:41,699 --> 01:22:44,340
它不是先驗或通用

2449
01:22:44,340 --> 01:22:46,560
語法，就人們

2450
01:22:46,560 --> 01:22:48,540
所說的那樣

2451
01:22:48,540 --> 01:22:50,159
關於允許哪些類型的規則的明確聲明

2452
01:22:50,159 --> 01:22:51,780
或關於

2453
01:22:51,780 --> 01:22:53,880
哪些類型的函數是高

2454
01:22:53,880 --> 01:22:55,320
概率的明確聲明或類似的東西它

2455
01:22:55,320 --> 01:22:57,360
都隱式編碼在那裡

2456
01:22:57,360 --> 01:22:58,560
嗯是的是的完全我認為我認為

2457
01:22:58,560 --> 01:23:00,540
這是正確的我的意思是你知道真正的

2458
01:23:00,540 --> 01:23:02,880
問題正在減少 那些

2459
01:23:02,880 --> 01:23:05,100
相似的人的空間，如果它與

2460
01:23:05,100 --> 01:23:07,020
人類

2461
01:23:07,020 --> 01:23:09,300
正在做的事情有很大的不同，那麼我

2462
01:23:09,300 --> 01:23:11,219
至少會說像 qpt3 這樣的東西

2463
01:23:11,219 --> 01:23:13,380
存在證明你知道

2464
01:23:13,380 --> 01:23:15,960


2465
01:23:15,960 --> 01:23:18,000
從表面分佈分析構建功能齊全的句法類別

2466
01:23:18,000 --> 01:23:21,420
僅此一項是可能的，

2467
01:23:21,420 --> 01:23:24,120
是的，這是正確的，但即使如此，

2468
01:23:24,120 --> 01:23:27,300
我會說大多數從業者並不

2469
01:23:27,300 --> 01:23:29,460
真正相信句法類別

2470
01:23:29,460 --> 01:23:31,380
是天生的，因此先前的問題

2471
01:23:31,380 --> 01:23:33,060
在這裡稍微無關緊要，這是

2472
01:23:33,060 --> 01:23:35,219
設置為天生的操作，因此

2473
01:23:35,219 --> 01:23:37,500
在 語法領域 它是特定的

2474
01:23:37,500 --> 01:23:39,659
語言計算，據說

2475
01:23:39,659 --> 01:23:41,159
屬於 a 和類別本身

2476
01:23:41,159 --> 01:23:42,719
事實上，甚至 Charles Yang

2477
01:23:42,719 --> 01:23:44,100
um 在過去幾年中承認

2478
01:23:44,100 --> 01:23:46,800
他們可能在其中但也許不在其中，

2479
01:23:46,800 --> 01:23:49,679
所以人們已經給出了另一個

2480
01:23:49,679 --> 01:23:51,540
相關的優先級是事情 就像

2481
01:23:51,540 --> 01:23:53,100
嗯，你認識我，Gary markets

2482
01:23:53,100 --> 01:23:55,080
談到了似乎

2483
01:23:55,080 --> 01:23:56,640
是一個大問題的組合性，所以人們給

2484
01:23:56,640 --> 01:23:59,520
聊天 gbt BBC 新聞文章要求它

2485
01:23:59,520 --> 01:24:02,280
壓縮它然後重新解釋它呃所以

2486
01:24:02,280 --> 01:24:04,920
我看到的一個例子是 Peter Smith 58 是 因過失

2487
01:24:04,920 --> 01:24:06,480


2488
01:24:06,480 --> 01:24:09,060
殺人罪被捕，你讓它壓縮

2489
01:24:09,060 --> 01:24:10,920
並重新解釋它，結果是

2490
01:24:10,920 --> 01:24:12,420
58 人被指控過失

2491
01:24:12,420 --> 01:24:14,040
殺人權，這是一個非常明顯的

2492
01:24:14,040 --> 01:24:15,659
例子，表明它正在做的任何壓縮都缺乏組合性，

2493
01:24:15,659 --> 01:24:17,219


2494
01:24:17,219 --> 01:24:19,260
而且有 另一個例子，

2495
01:24:19,260 --> 01:24:20,940
那裡有一些

2496
01:24:20,940 --> 01:24:23,159
潛在的類比推理的例子，所以在

2497
01:24:23,159 --> 01:24:24,840
Bing 聊天中你知道 Bing 有這個

2498
01:24:24,840 --> 01:24:26,100
陷阱功能

2499
01:24:26,100 --> 01:24:28,080
嗯問題是它只是找到

2500
01:24:28,080 --> 01:24:29,460
已經被

2501
01:24:29,460 --> 01:24:31,080
人類記錄的元關係，還是它真的

2502
01:24:31,080 --> 01:24:33,420
創造了新的新關係

2503
01:24:33,420 --> 01:24:35,100
正在建造的東西，

2504
01:24:35,100 --> 01:24:38,520
嗯，所以你知道有人問我，嗯，給我畫了

2505
01:24:38,520 --> 01:24:41,760
一張比較耶穌基督和

2506
01:24:41,760 --> 01:24:44,640
諾基亞 9910 的表格，對了，手機諾基亞

2507
01:24:44,640 --> 01:24:46,080
9910

2508
01:24:46,080 --> 01:24:47,520
嗯，它說你知道他們比較了

2509
01:24:47,520 --> 01:24:49,860
發布日期，比較了尺寸

2510
01:24:49,860 --> 01:24:53,280
和重量，比較了 CPU 和

2511
01:24:53,280 --> 01:24:55,140
耶穌無所不能的知識，它

2512
01:24:55,140 --> 01:24:57,600
把手機的記憶力與

2513
01:24:57,600 --> 01:25:00,600
上帝無所不知的本性相提並論，

2514
01:25:00,600 --> 01:25:02,760
嗯，我也認為它說他們

2515
01:25:02,760 --> 01:25:04,560
都復活了，因為諾基亞

2516
01:25:04,560 --> 01:25:06,239
重新發布了幾次，所以

2517
01:25:06,239 --> 01:25:08,159
諾基亞聽起來像 很好的答案

2518
01:25:08,159 --> 01:25:10,560
那有什麼問題沒關係

2519
01:25:10,560 --> 01:25:12,120
可能聽起來很像類比

2520
01:25:12,120 --> 01:25:13,860
推理但是它也

2521
01:25:13,860 --> 01:25:15,420
有一些非常奇怪的地方

2522
01:25:15,420 --> 01:25:17,100
就像你知道相機它說不

2523
01:25:17,100 --> 01:25:19,679
它只是給出了耶穌的描述或者它

2524
01:25:19,679 --> 01:25:21,659
不是真的 相機是不是有些

2525
01:25:21,659 --> 01:25:24,000
東西看起來像是類比

2526
01:25:24,000 --> 01:25:27,860
推理，但還不清楚是的，嘿，

2527
01:25:27,860 --> 01:25:31,440
我認為這

2528
01:25:31,440 --> 01:25:33,020
對我來說是一個很棒的答案，

2529
01:25:33,020 --> 01:25:36,360
我想像你一樣說

2530
01:25:36,360 --> 01:25:38,100
大型語言模型學習它們

2531
01:25:38,100 --> 01:25:39,719
存在的詞性證明

2532
01:25:39,719 --> 01:25:41,520
類別，但就像他們不只是

2533
01:25:41,520 --> 01:25:43,380
輸出詞性類別一樣，

2534
01:25:43,380 --> 01:25:45,719
就像他們有很多語法

2535
01:25:45,719 --> 01:25:47,640
句法知識，

2536
01:25:47,640 --> 01:25:50,880
嗯，而且他們有

2537
01:25:50,880 --> 01:25:52,980
很多語義知識，可能還有一些語

2538
01:25:52,980 --> 01:25:55,080
用知識，你知道

2539
01:25:55,080 --> 01:25:58,080
他們是 翻譯還不錯，而且

2540
01:25:58,080 --> 01:25:59,880
他們

2541
01:25:59,880 --> 01:26:01,139
發現的

2542
01:26:01,139 --> 01:26:03,840
不僅僅是詞性類別，

2543
01:26:03,840 --> 01:26:07,020
嗯，嗯，我很抱歉，我說我很抱歉，

2544
01:26:07,020 --> 01:26:08,940
這是一個技術類別，對，對，對，對，對，對，對，

2545
01:26:08,940 --> 01:26:11,040
對，但是

2546
01:26:11,040 --> 01:26:13,080
他們發現了 遠不止於此，

2547
01:26:13,080 --> 01:26:13,980
嗯，

2548
01:26:13,980 --> 01:26:15,600
嗯，嗯，

2549
01:26:15,600 --> 01:26:18,780
我將作為一個 um teaser slash

2550
01:26:18,780 --> 01:26:20,699
motivator 希望你們倆

2551
01:26:20,699 --> 01:26:23,040
在未來有或

2552
01:26:23,040 --> 01:26:24,540
沒有其他客人的情況下再次加入 uh 一些

2553
01:26:24,540 --> 01:26:26,520
令人興奮的問題只是為了讓我們

2554
01:26:26,520 --> 01:26:28,679
包含在這份成績單中和 然後

2555
01:26:28,679 --> 01:26:30,060
感謝 Ellie 和 Steven 的

2556
01:26:30,060 --> 01:26:31,260
加入，所以只是最後幾個

2557
01:26:31,260 --> 01:26:33,719
被問到的問題 Juan 問了

2558
01:26:33,719 --> 01:26:35,820
2020 年小變形金剛 Jang 與

2559
01:26:35,820 --> 01:26:38,580
兒童學習語言相比如何

2560
01:26:38,580 --> 01:26:40,860
96 問你對

2561
01:26:40,860 --> 01:26:42,800
隱性先驗與動物本能

2562
01:26:42,800 --> 01:26:45,780
rojda 的看法 llms 中的空間限制是什麼

2563
01:26:45,780 --> 01:26:48,420
他們沒有通過培訓到達那裡，

2564
01:26:48,420 --> 01:26:50,699
所以他們是否發現它不是

2565
01:26:50,699 --> 01:26:52,500
他們在開始時實施的可能

2566
01:26:52,500 --> 01:26:54,780
還有更多問題所以我

2567
01:26:54,780 --> 01:26:57,540
希望我們都可以 um 回顧並

2568
01:26:57,540 --> 01:27:00,600
重新閱讀彼此的作品和

2569
01:27:00,600 --> 01:27:04,020
在未來的某個時間一起參加 41.2

2570
01:27:04,020 --> 01:27:06,060
謝謝 Elliot 和 Steven 的

2571
01:27:06,060 --> 01:27:08,280
精彩直播 謝謝 Dave 謝謝你們

2572
01:27:08,280 --> 01:27:10,739
倆 是的 謝謝

2573
01:27:10,739 --> 01:27:15,379
你們 再見再見

