1
00:00:05,759 --> 00:00:08,400
hello and welcome everyone to the Active

2
00:00:08,400 --> 00:00:10,860
Inference Institute this is active guest

3
00:00:10,860 --> 00:00:15,839
stream number 41.1 on April 25th 2023

4
00:00:15,839 --> 00:00:18,480
we're here with Elliot Murphy and

5
00:00:18,480 --> 00:00:20,939
Stephen piantadosi this is going to be

6
00:00:20,939 --> 00:00:23,039
quite a discussion we will begin with

7
00:00:23,039 --> 00:00:24,779
opening statements from Stephen and

8
00:00:24,779 --> 00:00:27,359
Elliot Elliott will then lead with some

9
00:00:27,359 --> 00:00:28,920
questions and we'll have an open

10
00:00:28,920 --> 00:00:32,759
discussion at the end so Steven please

11
00:00:32,759 --> 00:00:34,739
thank you for joining and to your

12
00:00:34,739 --> 00:00:36,960
opening statement

13
00:00:36,960 --> 00:00:39,780
cool hi so I'm Steve piantadosi I'm a

14
00:00:39,780 --> 00:00:42,239
professor in Psychology and Neuroscience

15
00:00:42,239 --> 00:00:44,700
at UC Berkeley

16
00:00:44,700 --> 00:00:46,860
um and uh I guess part of the reason

17
00:00:46,860 --> 00:00:48,899
that we're here is that I recently wrote

18
00:00:48,899 --> 00:00:51,719
a paper on large language models um in

19
00:00:51,719 --> 00:00:53,940
part trying to convey some enthusiasm

20
00:00:53,940 --> 00:00:55,199
about

21
00:00:55,199 --> 00:00:57,300
um what they've kind of accomplished in

22
00:00:57,300 --> 00:00:59,100
terms of learning syntax and and

23
00:00:59,100 --> 00:01:00,719
semantics

24
00:01:00,719 --> 00:01:03,059
um and in part pointing out I think that

25
00:01:03,059 --> 00:01:04,979
these models really change how how we

26
00:01:04,979 --> 00:01:06,780
should think about language

27
00:01:06,780 --> 00:01:08,520
um how we should think about theories of

28
00:01:08,520 --> 00:01:11,939
of linguistic representation and and uh

29
00:01:11,939 --> 00:01:13,560
theories of grammar

30
00:01:13,560 --> 00:01:17,220
um and likely also theories of learning

31
00:01:17,220 --> 00:01:19,080
hello

32
00:01:19,080 --> 00:01:21,960
awesome yeah so I'm Elliot meffee I'm a

33
00:01:21,960 --> 00:01:23,040
postdoc in the department of

34
00:01:23,040 --> 00:01:25,799
neurosurgery at UT Health in Texas

35
00:01:25,799 --> 00:01:27,240
um I read Steven's paper with great

36
00:01:27,240 --> 00:01:29,759
interest I did a lot of people and there

37
00:01:29,759 --> 00:01:31,619
were some areas of convergence but the

38
00:01:31,619 --> 00:01:32,820
the things I want to kind of focus on

39
00:01:32,820 --> 00:01:34,979
today in responding to Stephen and kind

40
00:01:34,979 --> 00:01:36,600
of probing off to do with areas of

41
00:01:36,600 --> 00:01:38,640
Divergence maybe

42
00:01:38,640 --> 00:01:41,700
um so you know Steven's paper is based

43
00:01:41,700 --> 00:01:43,619
on the idea that modern machine learning

44
00:01:43,619 --> 00:01:46,220
has subverted and bypassed the entire

45
00:01:46,220 --> 00:01:48,119
theoretical framework of chomsky's

46
00:01:48,119 --> 00:01:49,860
approach so I wanted to kind of respond

47
00:01:49,860 --> 00:01:51,479
to some of these main arguments and some

48
00:01:51,479 --> 00:01:52,560
other related arguments in the

49
00:01:52,560 --> 00:01:54,060
literature uh that's some folks

50
00:01:54,060 --> 00:01:55,799
listening might have some some insight

51
00:01:55,799 --> 00:01:58,500
and thoughts on so it's a very common

52
00:01:58,500 --> 00:02:00,720
criticism to say that large language

53
00:02:00,720 --> 00:02:03,180
models just predict the next token and

54
00:02:03,180 --> 00:02:04,079
which

55
00:02:04,079 --> 00:02:05,579
there's obviously a bit of a cliche

56
00:02:05,579 --> 00:02:07,619
right it's um not quite true and they

57
00:02:07,619 --> 00:02:09,419
don't just predict the next token they

58
00:02:09,419 --> 00:02:11,700
also seem to confabulate they seem to

59
00:02:11,700 --> 00:02:14,340
hallucinate they maybe lie they randomly

60
00:02:14,340 --> 00:02:16,440
provide different answers to the same

61
00:02:16,440 --> 00:02:18,300
question and they seem to have

62
00:02:18,300 --> 00:02:20,220
stochastically mimic language-like

63
00:02:20,220 --> 00:02:22,020
structures they sometimes correct

64
00:02:22,020 --> 00:02:23,819
themselves sometimes when they shouldn't

65
00:02:23,819 --> 00:02:25,440
if you push them a little they kind of

66
00:02:25,440 --> 00:02:27,000
change their mind sometimes

67
00:02:27,000 --> 00:02:28,560
um in fact if Fox News is currently

68
00:02:28,560 --> 00:02:30,060
looking for a replacement for Tucker

69
00:02:30,060 --> 00:02:31,800
Carlson they could do less they could

70
00:02:31,800 --> 00:02:33,680
definitely do worse than using

71
00:02:33,680 --> 00:02:36,120
between if they're looking for a you

72
00:02:36,120 --> 00:02:38,040
know similar caliber so these models

73
00:02:38,040 --> 00:02:40,620
seem to do all sorts of like wild things

74
00:02:40,620 --> 00:02:41,940
um and over the past 10 years there's

75
00:02:41,940 --> 00:02:43,500
been a sequence of different you know

76
00:02:43,500 --> 00:02:45,900
systems developed like we're tobacco bed

77
00:02:45,900 --> 00:02:47,580
and each of them is based on a different

78
00:02:47,580 --> 00:02:49,620
neural net approach But ultimately they

79
00:02:49,620 --> 00:02:51,180
all seem to take words and characterize

80
00:02:51,180 --> 00:02:53,220
them by lists of uh hundreds or

81
00:02:53,220 --> 00:02:56,220
thousands of numbers so the G23 network

82
00:02:56,220 --> 00:03:00,000
has 175 billion weights and 96 attention

83
00:03:00,000 --> 00:03:02,160
heads in its architecture and as far as

84
00:03:02,160 --> 00:03:03,780
what I know maybe Steven can can correct

85
00:03:03,780 --> 00:03:06,060
me here we don't really have a great

86
00:03:06,060 --> 00:03:07,319
idea of what these different parts

87
00:03:07,319 --> 00:03:09,180
really mean it just seems to kind of

88
00:03:09,180 --> 00:03:10,920
work that way like attention heads and

89
00:03:10,920 --> 00:03:13,680
gpt3 can pay attention to much earlier

90
00:03:13,680 --> 00:03:15,360
tokens in the string in order to help

91
00:03:15,360 --> 00:03:17,040
them predict the next token but the

92
00:03:17,040 --> 00:03:18,659
whole architecture from start to finish

93
00:03:18,659 --> 00:03:21,599
is kind of engineering based motivations

94
00:03:21,599 --> 00:03:22,500
um

95
00:03:22,500 --> 00:03:24,659
and I always kind of wonder what about

96
00:03:24,659 --> 00:03:27,360
all the models that kind of failed from

97
00:03:27,360 --> 00:03:28,800
these llms from the different tech

98
00:03:28,800 --> 00:03:30,300
companies it's like these companies

99
00:03:30,300 --> 00:03:31,980
often seem to

100
00:03:31,980 --> 00:03:33,060
um you know make it seem like they have

101
00:03:33,060 --> 00:03:34,980
these models that really work very well

102
00:03:34,980 --> 00:03:36,720
Straight Out of the Box

103
00:03:36,720 --> 00:03:38,459
um and they all seem to be named after

104
00:03:38,459 --> 00:03:40,739
some kind of famous artists right right

105
00:03:40,739 --> 00:03:42,780
they have Darley after salad or Dali

106
00:03:42,780 --> 00:03:45,360
they have Da Vinci maybe pretty soon one

107
00:03:45,360 --> 00:03:46,980
of these companies will release a large

108
00:03:46,980 --> 00:03:49,500
language model uh called Jesus or

109
00:03:49,500 --> 00:03:50,879
something I don't know

110
00:03:50,879 --> 00:03:53,040
um but they always say this here's our

111
00:03:53,040 --> 00:03:54,900
New Foundation model it's called Picasso

112
00:03:54,900 --> 00:03:56,280
it's the first one we tried it we're

113
00:03:56,280 --> 00:03:58,140
just great no problems straight out of

114
00:03:58,140 --> 00:03:59,819
the box but I always wonder what about

115
00:03:59,819 --> 00:04:01,680
Oliver Black boxes that have kind of

116
00:04:01,680 --> 00:04:03,659
failed every time there doesn't seem to

117
00:04:03,659 --> 00:04:05,760
be a kind of a very open and clear

118
00:04:05,760 --> 00:04:07,379
structure to the kind of scientific

119
00:04:07,379 --> 00:04:09,840
reasoning behind selecting you know one

120
00:04:09,840 --> 00:04:11,939
model or another uh but again I might be

121
00:04:11,939 --> 00:04:14,280
I'm open to be corrected about that

122
00:04:14,280 --> 00:04:16,798
um so even basic language models do

123
00:04:16,798 --> 00:04:18,298
pretty well on

124
00:04:18,298 --> 00:04:20,699
um like basic web prediction so the

125
00:04:20,699 --> 00:04:22,139
issue is whether these tools provide an

126
00:04:22,139 --> 00:04:23,520
insights into like traditional

127
00:04:23,520 --> 00:04:25,320
psycholinguistic Notions like grammar

128
00:04:25,320 --> 00:04:27,300
and passing so this is really why I kind

129
00:04:27,300 --> 00:04:29,040
of prefer the 10 Focus model rather

130
00:04:29,040 --> 00:04:30,960
language model uh suggested by people

131
00:04:30,960 --> 00:04:32,880
like cyberveras

132
00:04:32,880 --> 00:04:34,560
so it's been pointed out that no one

133
00:04:34,560 --> 00:04:36,479
really thinks llms tell us anything

134
00:04:36,479 --> 00:04:38,580
profound about python when they land

135
00:04:38,580 --> 00:04:40,080
python code just as well as natural

136
00:04:40,080 --> 00:04:42,120
language well python is a symbolic

137
00:04:42,120 --> 00:04:43,740
language with a phrase structure grammar

138
00:04:43,740 --> 00:04:46,620
and nobody says llms are unveiling the

139
00:04:46,620 --> 00:04:48,600
secrets of python right so just to put

140
00:04:48,600 --> 00:04:50,940
various here he says if a n models can

141
00:04:50,940 --> 00:04:52,620
be construed as explanatory theories for

142
00:04:52,620 --> 00:04:54,000
natural language based on their

143
00:04:54,000 --> 00:04:56,040
successes on language tasks then in the

144
00:04:56,040 --> 00:04:57,540
absence of counter arguments they should

145
00:04:57,540 --> 00:04:58,919
be good explanatory theories for

146
00:04:58,919 --> 00:05:01,139
computer language as well uh therefore

147
00:05:01,139 --> 00:05:02,699
successful a n models of natural

148
00:05:02,699 --> 00:05:04,620
language cannot be used as evidence

149
00:05:04,620 --> 00:05:06,540
against generative phrase structure of

150
00:05:06,540 --> 00:05:07,800
Amazon language

151
00:05:07,800 --> 00:05:09,720
so Corpus model is really a more

152
00:05:09,720 --> 00:05:11,280
appropriate term for other reasons too

153
00:05:11,280 --> 00:05:13,500
people like Emily bender and some others

154
00:05:13,500 --> 00:05:15,300
have shown that features of the training

155
00:05:15,300 --> 00:05:16,979
Corpus in fact I think Stephen cites

156
00:05:16,979 --> 00:05:17,940
this you cite this in your paper

157
00:05:17,940 --> 00:05:19,860
actually as a limitation

158
00:05:19,860 --> 00:05:21,120
um they show that features of the

159
00:05:21,120 --> 00:05:22,680
training Corpus can heavily influence

160
00:05:22,680 --> 00:05:24,600
the laying process so it's been shown

161
00:05:24,600 --> 00:05:25,800
that the performance of large language

162
00:05:25,800 --> 00:05:27,780
models on language classes is really

163
00:05:27,780 --> 00:05:29,699
heavily influenced by the the diversity

164
00:05:29,699 --> 00:05:31,440
of the training Corpus

165
00:05:31,440 --> 00:05:33,180
um but natural language itself is not

166
00:05:33,180 --> 00:05:35,340
biased right it's just

167
00:05:35,340 --> 00:05:37,199
it's a computational system human beings

168
00:05:37,199 --> 00:05:39,120
can be biased in what they say and how

169
00:05:39,120 --> 00:05:41,039
they act and but natural language itself

170
00:05:41,039 --> 00:05:43,020
isn't biased right so large language

171
00:05:43,020 --> 00:05:45,180
models therefore it seems difficult for

172
00:05:45,180 --> 00:05:47,880
me to you know agree that they are being

173
00:05:47,880 --> 00:05:49,500
subject to all sorts of biases they

174
00:05:49,500 --> 00:05:51,000
therefore can't really be models of

175
00:05:51,000 --> 00:05:52,020
language they're models of something

176
00:05:52,020 --> 00:05:53,880
else so just to kind of wrap up this

177
00:05:53,880 --> 00:05:55,620
argument

178
00:05:55,620 --> 00:05:58,139
um you know even though llms are clearly

179
00:05:58,139 --> 00:05:59,759
exposed to vastly more linguistic

180
00:05:59,759 --> 00:06:01,320
experience in children again this is

181
00:06:01,320 --> 00:06:02,699
something else that Stephen can see it

182
00:06:02,699 --> 00:06:04,680
and talks about in his paper and even so

183
00:06:04,680 --> 00:06:06,360
their learning outcomes may still be

184
00:06:06,360 --> 00:06:08,160
relevant in addressing what grammatical

185
00:06:08,160 --> 00:06:09,840
generalizations are learnable in

186
00:06:09,840 --> 00:06:11,580
principle so I do agree with this

187
00:06:11,580 --> 00:06:12,660
statement here you know that in

188
00:06:12,660 --> 00:06:14,100
principle they can tell us something

189
00:06:14,100 --> 00:06:16,080
about learnability rather than things

190
00:06:16,080 --> 00:06:17,639
like you know broad Acquisitions

191
00:06:17,639 --> 00:06:20,520
Frameworks and but that's about as much

192
00:06:20,520 --> 00:06:21,900
I think you can maybe say right now

193
00:06:21,900 --> 00:06:24,539
showing that some inductive biases

194
00:06:24,539 --> 00:06:26,819
um are not necessary for learning is not

195
00:06:26,819 --> 00:06:28,139
really the same thing as showing that it

196
00:06:28,139 --> 00:06:30,060
isn't present in children so there's

197
00:06:30,060 --> 00:06:31,560
been a long debate about whether you

198
00:06:31,560 --> 00:06:32,639
know negative evidence and instruction

199
00:06:32,639 --> 00:06:34,500
and correction and feedback during

200
00:06:34,500 --> 00:06:36,720
language learning are necessary or even

201
00:06:36,720 --> 00:06:39,120
useful for infants and children

202
00:06:39,120 --> 00:06:40,440
um but right now I kind of agree more

203
00:06:40,440 --> 00:06:42,479
with Eugene Choi and Gary Marcus and

204
00:06:42,479 --> 00:06:44,340
others who've highlighted how llms are

205
00:06:44,340 --> 00:06:45,660
currently you know very expensive to

206
00:06:45,660 --> 00:06:46,440
train

207
00:06:46,440 --> 00:06:48,600
that clearly an example of a

208
00:06:48,600 --> 00:06:50,400
concentrated private power in the hands

209
00:06:50,400 --> 00:06:51,960
of a few tech companies their

210
00:06:51,960 --> 00:06:54,539
environmental impact is massive

211
00:06:54,539 --> 00:06:56,039
um and you know many people have been

212
00:06:56,039 --> 00:06:57,300
less constrained and conservative in

213
00:06:57,300 --> 00:06:58,979
their assessment here

214
00:06:58,979 --> 00:07:00,660
um which much less other than Gary

215
00:07:00,660 --> 00:07:02,880
Marcus and Eugene so Bill Gates recently

216
00:07:02,880 --> 00:07:05,100
wrote that chat GPT is

217
00:07:05,100 --> 00:07:06,960
um the biggest Tech development since

218
00:07:06,960 --> 00:07:11,400
the uh graphical user interface the GUI

219
00:07:11,400 --> 00:07:13,020
um and Henry Kissinger wrote in February

220
00:07:13,020 --> 00:07:15,240
in the Wall Street Journal that as chat

221
00:07:15,240 --> 00:07:17,400
gbt's capacity has become broader they

222
00:07:17,400 --> 00:07:19,560
will redefine human knowledge accelerate

223
00:07:19,560 --> 00:07:21,780
changes in the fabric of our reality and

224
00:07:21,780 --> 00:07:23,220
reorganize politics and Society

225
00:07:23,220 --> 00:07:25,620
generative AI is published to generate

226
00:07:25,620 --> 00:07:28,319
new forms of human consciousness so very

227
00:07:28,319 --> 00:07:30,419
radical claims happening at the moment I

228
00:07:30,419 --> 00:07:32,220
do wonder if sometimes

229
00:07:32,220 --> 00:07:35,099
or the AI hype may have you know saved

230
00:07:35,099 --> 00:07:36,840
into certain portions of Academia

231
00:07:36,840 --> 00:07:39,240
potentially a lot of grand plans being

232
00:07:39,240 --> 00:07:40,680
made but I think you know more

233
00:07:40,680 --> 00:07:42,180
concretely just to put it back to Steven

234
00:07:42,180 --> 00:07:44,280
here I wanted to maybe raise the issue

235
00:07:44,280 --> 00:07:46,919
of um there's a critique by rorski and

236
00:07:46,919 --> 00:07:49,259
Beaumont that I I think he's read um on

237
00:07:49,259 --> 00:07:50,520
lingbuzz

238
00:07:50,520 --> 00:07:51,240
um

239
00:07:51,240 --> 00:07:53,280
I think you saw on Twitter that you

240
00:07:53,280 --> 00:07:54,419
don't like the response they gave

241
00:07:54,419 --> 00:07:56,819
because the objection that they made is

242
00:07:56,819 --> 00:07:58,500
that you know science is an example of

243
00:07:58,500 --> 00:08:00,479
deductive logic your objection is that

244
00:08:00,479 --> 00:08:02,340
science isn't deductive it's inductive

245
00:08:02,340 --> 00:08:04,380
right and but I think the general Point

246
00:08:04,380 --> 00:08:06,900
might be more accurate namely that you

247
00:08:06,900 --> 00:08:08,520
can't you can't use the fact that

248
00:08:08,520 --> 00:08:10,620
language models do well predicting some

249
00:08:10,620 --> 00:08:13,020
linguistic behavior in humans and some

250
00:08:13,020 --> 00:08:15,300
neural Imaging responses you can't use

251
00:08:15,300 --> 00:08:17,460
that alone to claim that they can yield

252
00:08:17,460 --> 00:08:19,199
a theory of human language

253
00:08:19,199 --> 00:08:21,000
so in your paper Stephen you know that

254
00:08:21,000 --> 00:08:23,220
it seems that certain structures work

255
00:08:23,220 --> 00:08:25,020
better than others the right attentional

256
00:08:25,020 --> 00:08:26,819
mechanism is important prediction is

257
00:08:26,819 --> 00:08:28,680
important semantic representations are

258
00:08:28,680 --> 00:08:30,180
important and therefore we can glean

259
00:08:30,180 --> 00:08:32,219
currently based on these models right

260
00:08:32,219 --> 00:08:34,260
um but so far that's really all I've

261
00:08:34,260 --> 00:08:36,000
been able to glean in the literature I'm

262
00:08:36,000 --> 00:08:37,559
not sure if you have more insights here

263
00:08:37,559 --> 00:08:39,899
so Rosky and Boomer used the example of

264
00:08:39,899 --> 00:08:42,719
poor prediction but strong explanation

265
00:08:42,719 --> 00:08:44,760
right explanatory power and not

266
00:08:44,760 --> 00:08:46,500
predictive accuracy forms the basis of

267
00:08:46,500 --> 00:08:48,120
modern science and I want to explore

268
00:08:48,120 --> 00:08:49,440
this a little bit later maybe

269
00:08:49,440 --> 00:08:50,820
um but modern language models can

270
00:08:50,820 --> 00:08:52,440
accurately model parts of human language

271
00:08:52,440 --> 00:08:54,180
but they can also perform very well on

272
00:08:54,180 --> 00:08:55,920
Impossible languages and unnatural

273
00:08:55,920 --> 00:08:58,200
structures that humans can't learn and

274
00:08:58,200 --> 00:09:00,360
have a great difficulty processing and I

275
00:09:00,360 --> 00:09:01,560
know you're familiar with these with

276
00:09:01,560 --> 00:09:03,060
these criticisms right

277
00:09:03,060 --> 00:09:04,380
um but you're definitely not alone here

278
00:09:04,380 --> 00:09:08,339
at the same time so uh Elia

279
00:09:08,339 --> 00:09:10,320
um the chief scientist at open AI he

280
00:09:10,320 --> 00:09:12,180
said in an interview recently that what

281
00:09:12,180 --> 00:09:13,680
does it mean to predict the next token

282
00:09:13,680 --> 00:09:15,540
well enough it means that you understand

283
00:09:15,540 --> 00:09:17,940
the underlying reality that led to the

284
00:09:17,940 --> 00:09:19,920
creation of that token

285
00:09:19,920 --> 00:09:21,779
which is quite Divergent from a lot of

286
00:09:21,779 --> 00:09:23,100
more conservative claims in the

287
00:09:23,100 --> 00:09:24,540
literature here

288
00:09:24,540 --> 00:09:26,519
um and also you know I would just say in

289
00:09:26,519 --> 00:09:27,839
response to that that different

290
00:09:27,839 --> 00:09:30,019
components of science can be either

291
00:09:30,019 --> 00:09:32,580
inductive or deductive right it's not

292
00:09:32,580 --> 00:09:34,140
really in either or you have an existing

293
00:09:34,140 --> 00:09:36,300
Theory you formulate hyper hypothesis

294
00:09:36,300 --> 00:09:38,519
you collect data you analyze it and

295
00:09:38,519 --> 00:09:40,200
that's kind of deductive a deductive

296
00:09:40,200 --> 00:09:41,880
process but there's also cases where you

297
00:09:41,880 --> 00:09:43,680
start with a specific observation you

298
00:09:43,680 --> 00:09:44,940
find some patterns and you induce

299
00:09:44,940 --> 00:09:46,860
General conclusions right and then

300
00:09:46,860 --> 00:09:49,380
there's abduction where you magically

301
00:09:49,380 --> 00:09:52,019
invent hypotheses and and reduce the

302
00:09:52,019 --> 00:09:53,760
hypothesis space you wouldn't really say

303
00:09:53,760 --> 00:09:55,620
that deductive reasoning is unscientific

304
00:09:55,620 --> 00:09:58,200
or inductive reasoning is unscientific

305
00:09:58,200 --> 00:10:00,360
or abductive reasoning is unscientific

306
00:10:00,360 --> 00:10:01,800
right these are all just different ways

307
00:10:01,800 --> 00:10:03,540
of doing stuff

308
00:10:03,540 --> 00:10:05,459
um I mean in your paper you give the

309
00:10:05,459 --> 00:10:08,399
examples of using models to predict uh

310
00:10:08,399 --> 00:10:09,779
hurricanes and pandemics as being

311
00:10:09,779 --> 00:10:12,060
examples of stuff that is as rigorous as

312
00:10:12,060 --> 00:10:13,860
science gets and then you implore your

313
00:10:13,860 --> 00:10:16,019
reader to conclude that the situation is

314
00:10:16,019 --> 00:10:18,120
no different for language models

315
00:10:18,120 --> 00:10:19,920
um but I guess for me the issue is

316
00:10:19,920 --> 00:10:22,200
models predicting hurricanes are not in

317
00:10:22,200 --> 00:10:23,940
the business of answering the question

318
00:10:23,940 --> 00:10:25,740
what is the hurricane

319
00:10:25,740 --> 00:10:27,420
right models accurately predicting the

320
00:10:27,420 --> 00:10:29,040
weather are very accurate but they're

321
00:10:29,040 --> 00:10:30,600
not you know they're aligned with the

322
00:10:30,600 --> 00:10:32,700
meteorology department but they're not a

323
00:10:32,700 --> 00:10:34,380
substitute for it

324
00:10:34,380 --> 00:10:35,760
um so I guess I'll just you know hand

325
00:10:35,760 --> 00:10:37,620
that over to you

326
00:10:37,620 --> 00:10:41,820
yeah okay well uh there's a lot there

327
00:10:41,820 --> 00:10:43,800
um I I guess I could could start just by

328
00:10:43,800 --> 00:10:45,240
saying that

329
00:10:45,240 --> 00:10:47,579
um uh I agree with like many of these

330
00:10:47,579 --> 00:10:51,300
criticisms right about uh these these

331
00:10:51,300 --> 00:10:54,000
models being controlled by uh you know

332
00:10:54,000 --> 00:10:56,220
one or two companies

333
00:10:56,220 --> 00:10:59,160
um that being very very problematic

334
00:10:59,160 --> 00:11:01,320
um uh you know they have all kinds of

335
00:11:01,320 --> 00:11:03,480
biases that they've acquired because

336
00:11:03,480 --> 00:11:04,980
they're trained on text from the

337
00:11:04,980 --> 00:11:06,180
internet

338
00:11:06,180 --> 00:11:08,640
um that's hugely problematic

339
00:11:08,640 --> 00:11:10,980
um you know I I certainly agree that

340
00:11:10,980 --> 00:11:13,079
there's uh things at least at present

341
00:11:13,079 --> 00:11:16,500
that the models don't do well right so

342
00:11:16,500 --> 00:11:18,420
um I think it's it's easy to to find

343
00:11:18,420 --> 00:11:20,640
examples of you know questions and and

344
00:11:20,640 --> 00:11:23,100
problems that will trip them up

345
00:11:23,100 --> 00:11:25,500
um I I think why I've been excited about

346
00:11:25,500 --> 00:11:26,760
them though

347
00:11:26,760 --> 00:11:29,820
um is not uh not necessarily in in those

348
00:11:29,820 --> 00:11:32,399
terms right but in in terms of

349
00:11:32,399 --> 00:11:34,920
performance on language

350
00:11:34,920 --> 00:11:38,459
um specifically syntax and and semantics

351
00:11:38,459 --> 00:11:40,980
um I think they're uh far beyond kind of

352
00:11:40,980 --> 00:11:43,019
any other other theory in any other

353
00:11:43,019 --> 00:11:46,920
domain right so there's there's no other

354
00:11:46,920 --> 00:11:49,380
Theory out of linguistics or computer

355
00:11:49,380 --> 00:11:53,100
science which can generate you know long

356
00:11:53,100 --> 00:11:56,700
coherent uh grammatical uh passages of

357
00:11:56,700 --> 00:11:58,500
of text

358
00:11:58,500 --> 00:12:01,140
um and so kind of admitting all of their

359
00:12:01,140 --> 00:12:04,920
problems as uh you know tools or or

360
00:12:04,920 --> 00:12:08,220
things which are deployed by companies

361
00:12:08,220 --> 00:12:09,959
um um there's still this this question

362
00:12:09,959 --> 00:12:12,899
of like how are they uh at dealing with

363
00:12:12,899 --> 00:12:14,760
language and

364
00:12:14,760 --> 00:12:16,320
um I think this is where a lot of the

365
00:12:16,320 --> 00:12:17,760
enthusiasm comes from is there really

366
00:12:17,760 --> 00:12:20,160
hasn't been anything uh even remotely

367
00:12:20,160 --> 00:12:23,700
like them in terms of linguistic ability

368
00:12:23,700 --> 00:12:24,899
um and that's the thing that that I

369
00:12:24,899 --> 00:12:27,660
think is is exciting so yes I I agree

370
00:12:27,660 --> 00:12:29,220
with with a bunch of these things you

371
00:12:29,220 --> 00:12:31,320
you started with

372
00:12:31,320 --> 00:12:33,300
um uh but nonetheless like I think in

373
00:12:33,300 --> 00:12:35,100
terms of syntax and and semantics

374
00:12:35,100 --> 00:12:37,079
there's just no other Theory which is is

375
00:12:37,079 --> 00:12:39,240
comparable to them

376
00:12:39,240 --> 00:12:40,140
um

377
00:12:40,140 --> 00:12:42,120
but so let me let me push that back then

378
00:12:42,120 --> 00:12:44,940
right so yeah I I would the the main

379
00:12:44,940 --> 00:12:46,320
objection from a lot of people I've

380
00:12:46,320 --> 00:12:48,000
spoken to in Departments of linguistics

381
00:12:48,000 --> 00:12:50,760
who are like a lot of the general you

382
00:12:50,760 --> 00:12:53,100
know first of your paper is to really

383
00:12:53,100 --> 00:12:54,120
say well

384
00:12:54,120 --> 00:12:55,620
um you know you're right they do they do

385
00:12:55,620 --> 00:12:57,360
a wonderful job uh accurately modeling

386
00:12:57,360 --> 00:12:58,920
all aspects of a lot of aspects of

387
00:12:58,920 --> 00:13:01,380
syntax and semantics however

388
00:13:01,380 --> 00:13:03,300
um I don't know of any real just like

389
00:13:03,300 --> 00:13:04,920
you know Chomsky talks about facts about

390
00:13:04,920 --> 00:13:06,660
language which is an old-fashioned

391
00:13:06,660 --> 00:13:09,000
notion and but I really think that's

392
00:13:09,000 --> 00:13:10,260
kind of an important notion too right

393
00:13:10,260 --> 00:13:12,899
like is there some discovery about

394
00:13:12,899 --> 00:13:16,860
language itself that llms can uniquely

395
00:13:16,860 --> 00:13:19,200
provide so like if llm's made some

396
00:13:19,200 --> 00:13:21,899
prediction about let's say you have a

397
00:13:21,899 --> 00:13:24,600
sentence structure Type X being more

398
00:13:24,600 --> 00:13:26,279
difficult to process than sentence type

399
00:13:26,279 --> 00:13:28,620
Y and this is a unique prediction that

400
00:13:28,620 --> 00:13:31,200
only they'd generate it and no human

401
00:13:31,200 --> 00:13:33,899
linguist Chomsky homestein none of these

402
00:13:33,899 --> 00:13:34,980
people had ever predicted that before

403
00:13:34,980 --> 00:13:37,260
but it turns out to be true you do eye

404
00:13:37,260 --> 00:13:38,760
tracking experiments you do all sorts of

405
00:13:38,760 --> 00:13:40,800
different behavioral experience and oh

406
00:13:40,800 --> 00:13:42,480
you know after all it turns out to be

407
00:13:42,480 --> 00:13:44,279
true this this is a new insight about

408
00:13:44,279 --> 00:13:45,839
language processing it's a new insight

409
00:13:45,839 --> 00:13:47,940
about language you know Behavior I just

410
00:13:47,940 --> 00:13:49,560
wonder I'm not saying I'm not saying

411
00:13:49,560 --> 00:13:51,240
that this is not possible in principle

412
00:13:51,240 --> 00:13:52,620
because it might happen in the near

413
00:13:52,620 --> 00:13:54,540
future but that's I guess for me the

414
00:13:54,540 --> 00:13:57,240
Crux of why a lot of linguists speaking

415
00:13:57,240 --> 00:13:59,519
of speaking on behalf of the entire

416
00:13:59,519 --> 00:14:02,040
Linguistics Community here and you know

417
00:14:02,040 --> 00:14:03,180
I guess that would be one of the main

418
00:14:03,180 --> 00:14:04,800
objections

419
00:14:04,800 --> 00:14:08,279
yeah I mean I I don't know of of uh I I

420
00:14:08,279 --> 00:14:10,019
guess I I think of the insights they've

421
00:14:10,019 --> 00:14:12,420
provided as kind of general principles

422
00:14:12,420 --> 00:14:14,459
right so

423
00:14:14,459 --> 00:14:16,200
um uh I think about these things like

424
00:14:16,200 --> 00:14:18,720
the the the power of memorizing chunks

425
00:14:18,720 --> 00:14:20,820
of language right so like they're they

426
00:14:20,820 --> 00:14:22,500
seem to be very good at constructions

427
00:14:22,500 --> 00:14:24,540
for example and there's lots of

428
00:14:24,540 --> 00:14:26,160
linguistic theories chomsky's in

429
00:14:26,160 --> 00:14:28,740
particular right which are uh about

430
00:14:28,740 --> 00:14:30,899
trying to find kind of minimal amounts

431
00:14:30,899 --> 00:14:33,660
of of structure to memorize right trying

432
00:14:33,660 --> 00:14:36,480
to derive as much as possible from from

433
00:14:36,480 --> 00:14:38,279
um some small set some small collection

434
00:14:38,279 --> 00:14:40,440
of of operations

435
00:14:40,440 --> 00:14:42,300
um and I think that hasn't gone well for

436
00:14:42,300 --> 00:14:44,459
those theories right um whereas this

437
00:14:44,459 --> 00:14:46,740
goes really well right so

438
00:14:46,740 --> 00:14:48,360
um uh if we think about something which

439
00:14:48,360 --> 00:14:50,040
has the memorization abilities if we

440
00:14:50,040 --> 00:14:51,300
think about theories of grammar for

441
00:14:51,300 --> 00:14:54,240
example which uh build on

442
00:14:54,240 --> 00:14:56,040
um you know humans like really

443
00:14:56,040 --> 00:14:58,139
remarkable ability to to memorize

444
00:14:58,139 --> 00:14:59,880
different constructions right or

445
00:14:59,880 --> 00:15:01,380
different words we know tens of

446
00:15:01,380 --> 00:15:02,940
thousands of words tens of thousands of

447
00:15:02,940 --> 00:15:04,380
different constructions sorry tens of

448
00:15:04,380 --> 00:15:06,420
thousands of different idioms maybe our

449
00:15:06,420 --> 00:15:07,920
theory of grammar should be integrated

450
00:15:07,920 --> 00:15:10,260
with that and they're in some sense a

451
00:15:10,260 --> 00:15:12,480
kind of proof of principle that that

452
00:15:12,480 --> 00:15:15,660
kind of approach can work well right

453
00:15:15,660 --> 00:15:17,279
um can think about making other types of

454
00:15:17,279 --> 00:15:19,380
predictions with them um some of which

455
00:15:19,380 --> 00:15:21,779
people uh are are currently doing but

456
00:15:21,779 --> 00:15:23,339
for example trying to use them to

457
00:15:23,339 --> 00:15:25,860
measure uh processing difficulty measure

458
00:15:25,860 --> 00:15:27,899
surprisal for example from from these

459
00:15:27,899 --> 00:15:29,160
models

460
00:15:29,160 --> 00:15:30,600
um there are surprisal measures right

461
00:15:30,600 --> 00:15:31,699
are

462
00:15:31,699 --> 00:15:34,260
much better than say context-free

463
00:15:34,260 --> 00:15:36,120
grammars or other kinds of language

464
00:15:36,120 --> 00:15:37,440
models and then it's interesting

465
00:15:37,440 --> 00:15:39,899
question how those uh surprisles or

466
00:15:39,899 --> 00:15:41,940
predictabilities relate to human

467
00:15:41,940 --> 00:15:44,399
processing right and it may capture some

468
00:15:44,399 --> 00:15:46,620
of it or might be non-linear or it might

469
00:15:46,620 --> 00:15:49,079
you know only capture a little bit of it

470
00:15:49,079 --> 00:15:51,420
or or whatever that's an interesting

471
00:15:51,420 --> 00:15:53,940
kind of other scientific question but I

472
00:15:53,940 --> 00:15:55,500
think in principle right they they can

473
00:15:55,500 --> 00:15:57,779
make predictions about for example the

474
00:15:57,779 --> 00:15:59,880
connections between sentences right so

475
00:15:59,880 --> 00:16:02,279
in in the paper I gave this example of

476
00:16:02,279 --> 00:16:05,459
you know converting a declaration into a

477
00:16:05,459 --> 00:16:07,920
question in 10 different ways right and

478
00:16:07,920 --> 00:16:10,620
presumably when it when you know GPT or

479
00:16:10,620 --> 00:16:12,540
something is is doing that it's finding

480
00:16:12,540 --> 00:16:15,420
10 different questions which are all uh

481
00:16:15,420 --> 00:16:18,060
in some way related kind of nearby in

482
00:16:18,060 --> 00:16:20,339
the models underlying semantic or

483
00:16:20,339 --> 00:16:22,139
syntactic space

484
00:16:22,139 --> 00:16:24,660
um and so those kinds of things are uh

485
00:16:24,660 --> 00:16:26,459
of the type that I think

486
00:16:26,459 --> 00:16:28,560
um uh you know some linguists might want

487
00:16:28,560 --> 00:16:30,180
right which is here's some hidden

488
00:16:30,180 --> 00:16:32,220
connection between sentences or their or

489
00:16:32,220 --> 00:16:34,320
their structures but as far as I know

490
00:16:34,320 --> 00:16:36,120
they haven't been evaluated empirically

491
00:16:36,120 --> 00:16:39,660
yet so right yeah yeah I mean these

492
00:16:39,660 --> 00:16:41,220
kinds of models are only a few years old

493
00:16:41,220 --> 00:16:43,440
so I I think it's

494
00:16:43,440 --> 00:16:45,000
um it's reasonable to be excited about

495
00:16:45,000 --> 00:16:46,259
them even though this kind of work

496
00:16:46,259 --> 00:16:48,540
hasn't been done yet no that's right no

497
00:16:48,540 --> 00:16:50,880
totally totally I mean but I think I

498
00:16:50,880 --> 00:16:51,720
think that's that's the right

499
00:16:51,720 --> 00:16:52,920
perspective to take but I think this

500
00:16:52,920 --> 00:16:54,779
gets to the issue of the

501
00:16:54,779 --> 00:16:56,579
um you mentioned surprisal you mentioned

502
00:16:56,579 --> 00:16:58,139
laneability

503
00:16:58,139 --> 00:17:00,839
um you know LMS and some syntax but they

504
00:17:00,839 --> 00:17:03,060
do so with obviously way way more data

505
00:17:03,060 --> 00:17:04,439
than infants do

506
00:17:04,439 --> 00:17:06,240
um such that observations of potential

507
00:17:06,240 --> 00:17:09,000
structure in and of itself is not a

508
00:17:09,000 --> 00:17:10,799
reputation of the poverty of the

509
00:17:10,799 --> 00:17:12,540
stimulus well the weaker version I

510
00:17:12,540 --> 00:17:13,500
should say of the poverty of

511
00:17:13,500 --> 00:17:15,059
distinguished argument so the mere fact

512
00:17:15,059 --> 00:17:17,579
that LMS can do what they do with our

513
00:17:17,579 --> 00:17:19,559
grammatical prize is very striking I

514
00:17:19,559 --> 00:17:20,939
agree and in fact you wouldn't have

515
00:17:20,939 --> 00:17:22,500
predicted that maybe five or six or

516
00:17:22,500 --> 00:17:23,699
seven years ago

517
00:17:23,699 --> 00:17:25,260
um but it doesn't yeah invalidate the

518
00:17:25,260 --> 00:17:28,199
claim that humans have surprise and we

519
00:17:28,199 --> 00:17:30,120
bring those prayers with us and so in

520
00:17:30,120 --> 00:17:31,080
order to see if computational

521
00:17:31,080 --> 00:17:33,299
Linguistics can constrain hypotheses and

522
00:17:33,299 --> 00:17:34,740
theoretical Linguistics which I think it

523
00:17:34,740 --> 00:17:36,480
can do by the way this needs to be done

524
00:17:36,480 --> 00:17:38,039
with you know careful experiments in

525
00:17:38,039 --> 00:17:39,720
which different learning parameters are

526
00:17:39,720 --> 00:17:43,080
controlled and gigantic language models

527
00:17:43,080 --> 00:17:45,299
like gbt free are basically you know

528
00:17:45,299 --> 00:17:47,520
useless here and this so this gets to

529
00:17:47,520 --> 00:17:49,559
some of tile lens and complaints that we

530
00:17:49,559 --> 00:17:51,960
need something like a baby LM project

531
00:17:51,960 --> 00:17:53,700
which I know you're interested in and

532
00:17:53,700 --> 00:17:55,320
where we have more you know ecologically

533
00:17:55,320 --> 00:17:56,940
valid training sets you make the

534
00:17:56,940 --> 00:17:58,380
prediction in your paper that some

535
00:17:58,380 --> 00:17:59,640
structure will be learned from that I

536
00:17:59,640 --> 00:18:01,679
suspect you you might be right there

537
00:18:01,679 --> 00:18:03,059
um but you know even so even with the

538
00:18:03,059 --> 00:18:04,679
baby LM challenge there's still the kind

539
00:18:04,679 --> 00:18:07,260
of non-trivial issue of addressing more

540
00:18:07,260 --> 00:18:09,419
traditional issues like when the kids

541
00:18:09,419 --> 00:18:11,400
start to generalize based on the amount

542
00:18:11,400 --> 00:18:13,200
of current input based on different

543
00:18:13,200 --> 00:18:15,539
factors cross-linguistically and that

544
00:18:15,539 --> 00:18:17,700
requires just traditional you know

545
00:18:17,700 --> 00:18:18,720
psycholinguistics and language

546
00:18:18,720 --> 00:18:21,539
acquisition so LMS you know do care

547
00:18:21,539 --> 00:18:22,919
about things like frequency and

548
00:18:22,919 --> 00:18:24,600
surprisal as you said but there's a

549
00:18:24,600 --> 00:18:26,160
really nice paper by Sophie and

550
00:18:26,160 --> 00:18:27,600
Andrea Martin the really beautiful paper

551
00:18:27,600 --> 00:18:30,000
and that I think you may have seen that

552
00:18:30,000 --> 00:18:31,620
shows very nicely that distributional

553
00:18:31,620 --> 00:18:34,080
statistics can sometimes be a cue to

554
00:18:34,080 --> 00:18:36,240
moments of structure building but it

555
00:18:36,240 --> 00:18:37,919
does replace these Notions pertaining to

556
00:18:37,919 --> 00:18:39,660
composition so I'll just read a quote

557
00:18:39,660 --> 00:18:42,360
from Chomsky 57 which sounds a lot like

558
00:18:42,360 --> 00:18:45,240
what um slots and more and say despite

559
00:18:45,240 --> 00:18:47,820
undeniable interests and importance

560
00:18:47,820 --> 00:18:49,440
um of semantic and statistical models of

561
00:18:49,440 --> 00:18:51,360
language they appear to have no direct

562
00:18:51,360 --> 00:18:52,919
relevance to the problem of determining

563
00:18:52,919 --> 00:18:54,600
or characterizing the set of grammatical

564
00:18:54,600 --> 00:18:56,340
differences I think that we are forced

565
00:18:56,340 --> 00:18:57,840
to conclude that grammar is autonomous

566
00:18:57,840 --> 00:18:59,520
and independent of meaning and that

567
00:18:59,520 --> 00:19:01,320
probabilistic models give no particular

568
00:19:01,320 --> 00:19:03,179
insight into some of the basic problems

569
00:19:03,179 --> 00:19:05,880
of syntactic structure so that second uh

570
00:19:05,880 --> 00:19:07,980
hedge of the of the of the second

571
00:19:07,980 --> 00:19:10,380
sentence turned out to be incorrect but

572
00:19:10,380 --> 00:19:11,580
it's so it's true that you know what's

573
00:19:11,580 --> 00:19:13,740
obviously said are available stat models

574
00:19:13,740 --> 00:19:16,559
in 57 is no longer accurate when applied

575
00:19:16,559 --> 00:19:18,600
to models today and that can make

576
00:19:18,600 --> 00:19:20,340
abstract generalizations about novel

577
00:19:20,340 --> 00:19:21,900
strings and distributional categories as

578
00:19:21,900 --> 00:19:23,640
you mentioned right but the performance

579
00:19:23,640 --> 00:19:25,380
of a single model does not provide

580
00:19:25,380 --> 00:19:27,480
direct evidence for or against the

581
00:19:27,480 --> 00:19:29,760
landability of a particular structure by

582
00:19:29,760 --> 00:19:31,440
giving the vast distance between any

583
00:19:31,440 --> 00:19:33,900
computational model available today and

584
00:19:33,900 --> 00:19:36,240
the human brain model success does not

585
00:19:36,240 --> 00:19:38,100
mean that the structure is necessarily

586
00:19:38,100 --> 00:19:40,679
land and model failure also doesn't mean

587
00:19:40,679 --> 00:19:42,539
that the structure is not learnable

588
00:19:42,539 --> 00:19:44,520
right

589
00:19:44,520 --> 00:19:47,100
yeah yeah so I I mean I think it's maybe

590
00:19:47,100 --> 00:19:49,380
worth unpacking kind of a couple

591
00:19:49,380 --> 00:19:51,000
different versions of learnability

592
00:19:51,000 --> 00:19:52,620
arguments that people have made because

593
00:19:52,620 --> 00:19:55,679
there have been uh very very strong kind

594
00:19:55,679 --> 00:19:57,720
of impossibility claims

595
00:19:57,720 --> 00:19:59,160
um coming out of kind of chomsky's

596
00:19:59,160 --> 00:20:01,260
tradition right that we're we're never

597
00:20:01,260 --> 00:20:04,140
claims about the amount of data that was

598
00:20:04,140 --> 00:20:05,820
required right there were claims about

599
00:20:05,820 --> 00:20:08,220
The Logical problem of language learning

600
00:20:08,220 --> 00:20:10,740
and that it was just impossible

601
00:20:10,740 --> 00:20:12,120
um right it was impossible without

602
00:20:12,120 --> 00:20:15,720
having uh uh uh kind of substantial

603
00:20:15,720 --> 00:20:17,580
constraints on the the class of

604
00:20:17,580 --> 00:20:19,380
languages or the class of grammars that

605
00:20:19,380 --> 00:20:21,660
that you would you would acquire

606
00:20:21,660 --> 00:20:23,220
um and people for a long time have been

607
00:20:23,220 --> 00:20:25,380
arguing against that that version of

608
00:20:25,380 --> 00:20:26,340
things

609
00:20:26,340 --> 00:20:27,120
um

610
00:20:27,120 --> 00:20:28,860
um you know there's there's old work by

611
00:20:28,860 --> 00:20:30,419
by gold and then there's whole kind of

612
00:20:30,419 --> 00:20:32,580
grammatical theories of acquisition

613
00:20:32,580 --> 00:20:35,220
built on that tradition uh that worry a

614
00:20:35,220 --> 00:20:37,980
lot about the the kind of uh order in

615
00:20:37,980 --> 00:20:39,240
which you Traverse through different

616
00:20:39,240 --> 00:20:40,860
hypotheses and consider different

617
00:20:40,860 --> 00:20:42,600
options and things

618
00:20:42,600 --> 00:20:43,380
um

619
00:20:43,380 --> 00:20:45,059
um and my favorite reference in in this

620
00:20:45,059 --> 00:20:46,919
is is this paper by

621
00:20:46,919 --> 00:20:49,799
um Nick jader and Paul vetani um called

622
00:20:49,799 --> 00:20:51,539
something like ideal learning of of

623
00:20:51,539 --> 00:20:53,039
natural language

624
00:20:53,039 --> 00:20:54,840
um that basically shows that a

625
00:20:54,840 --> 00:20:57,539
unconstrained learner could uh with

626
00:20:57,539 --> 00:21:00,480
enough data acquire the uh the the kind

627
00:21:00,480 --> 00:21:01,860
of generating rules or the the

628
00:21:01,860 --> 00:21:03,360
generating grammar

629
00:21:03,360 --> 00:21:05,640
um just from observing strings right but

630
00:21:05,640 --> 00:21:08,160
that that that paper was was really in

631
00:21:08,160 --> 00:21:10,200
in response to this huge body of work

632
00:21:10,200 --> 00:21:13,140
that that was arguing that that learning

633
00:21:13,140 --> 00:21:15,120
from positive examples so from just

634
00:21:15,120 --> 00:21:17,820
observing strings was was like logically

635
00:21:17,820 --> 00:21:20,520
impossible right so

636
00:21:20,520 --> 00:21:23,460
um uh of course you know people in in

637
00:21:23,460 --> 00:21:25,679
chomsky's Tradition really liked that

638
00:21:25,679 --> 00:21:28,140
form of argument because it was one that

639
00:21:28,140 --> 00:21:30,419
said uh you had to have something

640
00:21:30,419 --> 00:21:33,299
innately uh specified in order for

641
00:21:33,299 --> 00:21:34,919
language acquisition to work it was like

642
00:21:34,919 --> 00:21:36,600
kind of a mathematical argument right

643
00:21:36,600 --> 00:21:39,480
that you had to have uh some some kind

644
00:21:39,480 --> 00:21:41,220
of innate grammar or innate ordering of

645
00:21:41,220 --> 00:21:42,900
hypotheses or something and all of that

646
00:21:42,900 --> 00:21:45,659
just turned out to be totally wrong so

647
00:21:45,659 --> 00:21:48,299
um if you uh you know move to slightly

648
00:21:48,299 --> 00:21:50,520
more kind of realistic learning settings

649
00:21:50,520 --> 00:21:53,340
which Tater and vatani do

650
00:21:53,340 --> 00:21:55,500
um uh then it turns out you like an

651
00:21:55,500 --> 00:21:57,240
idealized learner can acquire stuff and

652
00:21:57,240 --> 00:21:59,100
there's no statements about

653
00:21:59,100 --> 00:22:00,600
um the amount of data that's required

654
00:22:00,600 --> 00:22:02,700
even there right that's the the kind of

655
00:22:02,700 --> 00:22:06,780
pure logical uh ability to learn

656
00:22:06,780 --> 00:22:08,940
um and that ability is is what I think

657
00:22:08,940 --> 00:22:11,460
the uh big versions of large language

658
00:22:11,460 --> 00:22:13,679
models also speak to right so Chader

659
00:22:13,679 --> 00:22:15,600
invitani and other other work kind of in

660
00:22:15,600 --> 00:22:17,460
that that Spirit

661
00:22:17,460 --> 00:22:19,500
um is you know mathematical and kind of

662
00:22:19,500 --> 00:22:21,480
arguing in principle but but never

663
00:22:21,480 --> 00:22:24,720
created something which was really a uh

664
00:22:24,720 --> 00:22:27,840
a grammar right or or a a real kind of

665
00:22:27,840 --> 00:22:30,000
implemented language model

666
00:22:30,000 --> 00:22:32,640
um so even you know a model which is

667
00:22:32,640 --> 00:22:35,400
trained on 100 million or 100 billion or

668
00:22:35,400 --> 00:22:38,340
however many many tokens right

669
00:22:38,340 --> 00:22:41,159
um uh even that kind of model I think is

670
00:22:41,159 --> 00:22:43,080
relevant to that version of of the

671
00:22:43,080 --> 00:22:46,140
debate right and and and showing that uh

672
00:22:46,140 --> 00:22:48,659
language learning is is not impossible

673
00:22:48,659 --> 00:22:51,360
um from a very unconstrained space okay

674
00:22:51,360 --> 00:22:53,640
and then then there's a second version

675
00:22:53,640 --> 00:22:56,760
right which is uh can we learn language

676
00:22:56,760 --> 00:22:59,760
with the specific data that kids get

677
00:22:59,760 --> 00:23:02,340
right and that's both amount of data and

678
00:23:02,340 --> 00:23:04,620
and form of the data

679
00:23:04,620 --> 00:23:06,360
um and so for people who don't know the

680
00:23:06,360 --> 00:23:08,520
the baby LM challenge

681
00:23:08,520 --> 00:23:10,440
um uh is

682
00:23:10,440 --> 00:23:12,840
um uh this uh

683
00:23:12,840 --> 00:23:14,340
um sorry thing to call it a a

684
00:23:14,340 --> 00:23:16,620
competition or a

685
00:23:16,620 --> 00:23:20,580
um a uh uh I guess it is a a challenge

686
00:23:20,580 --> 00:23:22,380
um trying to get people to to train

687
00:23:22,380 --> 00:23:24,539
language models on human-sized amounts

688
00:23:24,539 --> 00:23:27,179
of data um so that's something more like

689
00:23:27,179 --> 00:23:28,679
um I think there's two different

690
00:23:28,679 --> 00:23:31,140
versions 10 or 100 million different

691
00:23:31,140 --> 00:23:33,120
um to 10 or 100 million different words

692
00:23:33,120 --> 00:23:35,640
in the the training set

693
00:23:35,640 --> 00:23:38,100
um which is like you know 100th or

694
00:23:38,100 --> 00:23:41,159
1000th or something as as big as

695
00:23:41,159 --> 00:23:43,140
um these big AI companies are using for

696
00:23:43,140 --> 00:23:46,620
their language models um and

697
00:23:46,620 --> 00:23:48,720
um I think actually it's it's like

698
00:23:48,720 --> 00:23:50,340
that's exactly the the right kind of

699
00:23:50,340 --> 00:23:52,020
thing and exactly what the field needs

700
00:23:52,020 --> 00:23:54,780
right because you might find that on

701
00:23:54,780 --> 00:23:57,059
um a child-sized amount of data

702
00:23:57,059 --> 00:23:58,980
um you can essentially learn syntax

703
00:23:58,980 --> 00:24:01,140
right which I I think would would be the

704
00:24:01,140 --> 00:24:02,880
strongest argument against these Poverty

705
00:24:02,880 --> 00:24:04,260
of stimulus claims you could

706
00:24:04,260 --> 00:24:06,299
alternatively find that

707
00:24:06,299 --> 00:24:08,220
um maybe you can't learn very much

708
00:24:08,220 --> 00:24:10,740
um maybe you you you know come up with a

709
00:24:10,740 --> 00:24:12,840
a much crummier kind of language model

710
00:24:12,840 --> 00:24:14,700
or it's lacking some syntactic or

711
00:24:14,700 --> 00:24:16,799
semantic abilities

712
00:24:16,799 --> 00:24:17,520
um

713
00:24:17,520 --> 00:24:18,720
um I actually think that the the

714
00:24:18,720 --> 00:24:20,220
failures there are a little bit hard to

715
00:24:20,220 --> 00:24:22,620
interpret because

716
00:24:22,620 --> 00:24:24,720
um kids uh data when they're actually

717
00:24:24,720 --> 00:24:26,400
learning language they get a lot more

718
00:24:26,400 --> 00:24:28,919
data than just uh just strings of

719
00:24:28,919 --> 00:24:31,200
sentences right they're interacting in

720
00:24:31,200 --> 00:24:33,059
in an environment

721
00:24:33,059 --> 00:24:34,440
um so there's stuff in the world in

722
00:24:34,440 --> 00:24:36,539
front of them um their utterances are

723
00:24:36,539 --> 00:24:38,520
also interactive right so you can say

724
00:24:38,520 --> 00:24:39,960
something and and see whether your

725
00:24:39,960 --> 00:24:41,400
parent brings you the thing that you ask

726
00:24:41,400 --> 00:24:43,799
for for example right that's long been

727
00:24:43,799 --> 00:24:46,020
been argued by people

728
00:24:46,020 --> 00:24:49,020
um um as a a you know important cue in

729
00:24:49,020 --> 00:24:51,240
in language acquisition

730
00:24:51,240 --> 00:24:52,799
um so

731
00:24:52,799 --> 00:24:55,440
um uh in the baby LM challenge there

732
00:24:55,440 --> 00:24:58,200
there is an ability to train these

733
00:24:58,200 --> 00:25:00,960
models uh with kind of multimodal inputs

734
00:25:00,960 --> 00:25:02,340
I think you can give them as much video

735
00:25:02,340 --> 00:25:05,039
data as as you want to give

736
00:25:05,039 --> 00:25:07,140
um uh but probably it's hard to to kind

737
00:25:07,140 --> 00:25:09,000
of replicate exactly the type of setup

738
00:25:09,000 --> 00:25:11,220
and and feedback that kids actually get

739
00:25:11,220 --> 00:25:12,840
so

740
00:25:12,840 --> 00:25:14,700
um uh I don't know you know I'm I'm

741
00:25:14,700 --> 00:25:17,700
excited to to see uh where that goes and

742
00:25:17,700 --> 00:25:19,799
and how things pan out there

743
00:25:19,799 --> 00:25:20,760
um

744
00:25:20,760 --> 00:25:23,700
um uh you know I I think that there's an

745
00:25:23,700 --> 00:25:26,580
interesting related question for large

746
00:25:26,580 --> 00:25:28,320
language models

747
00:25:28,320 --> 00:25:30,299
um which is like what it which is

748
00:25:30,299 --> 00:25:31,919
understanding exactly what all of the

749
00:25:31,919 --> 00:25:34,200
data is doing so

750
00:25:34,200 --> 00:25:36,659
um it could be that that you need so

751
00:25:36,659 --> 00:25:38,279
much data for these models because

752
00:25:38,279 --> 00:25:40,620
they're effectively inventing some form

753
00:25:40,620 --> 00:25:43,919
of semantics internally right so

754
00:25:43,919 --> 00:25:45,600
um they're both discovering the rule of

755
00:25:45,600 --> 00:25:47,460
syntax and there they appear to be

756
00:25:47,460 --> 00:25:49,380
learning uh quite a bit about word

757
00:25:49,380 --> 00:25:50,940
meanings

758
00:25:50,940 --> 00:25:52,200
um and

759
00:25:52,200 --> 00:25:54,059
um it's not it's totally unclear I think

760
00:25:54,059 --> 00:25:56,220
how much of the the data in these modern

761
00:25:56,220 --> 00:25:58,919
models uh is needed for syntax versus

762
00:25:58,919 --> 00:26:00,240
semantics

763
00:26:00,240 --> 00:26:02,159
um my own guess I think would would be

764
00:26:02,159 --> 00:26:05,580
that the syntactic side is uh probably

765
00:26:05,580 --> 00:26:07,860
requires much less data than the than

766
00:26:07,860 --> 00:26:09,600
the semantic side

767
00:26:09,600 --> 00:26:11,159
um actually a student a former student

768
00:26:11,159 --> 00:26:12,960
of mine Frank Malika and I wrote a paper

769
00:26:12,960 --> 00:26:15,120
a few years ago trying to estimate the

770
00:26:15,120 --> 00:26:17,400
amount of information a learner would

771
00:26:17,400 --> 00:26:19,679
necessarily have to acquire

772
00:26:19,679 --> 00:26:22,140
um for uh learning the different aspects

773
00:26:22,140 --> 00:26:23,820
of language so you have to learn all the

774
00:26:23,820 --> 00:26:25,320
words and you learn their forums you

775
00:26:25,320 --> 00:26:26,880
learn their meanings you probably know

776
00:26:26,880 --> 00:26:28,320
their frequencies you have to learn

777
00:26:28,320 --> 00:26:32,100
syntax and basically what we found

778
00:26:32,100 --> 00:26:34,080
um in that analysis that was you know

779
00:26:34,080 --> 00:26:35,640
basically just a kind of back of the

780
00:26:35,640 --> 00:26:37,440
envelope calculation for each of these

781
00:26:37,440 --> 00:26:40,679
domains is that syntax is actually very

782
00:26:40,679 --> 00:26:42,779
few bits of information it doesn't take

783
00:26:42,779 --> 00:26:46,400
that much information to to learn syntax

784
00:26:46,400 --> 00:26:49,320
whereas like most of the information you

785
00:26:49,320 --> 00:26:52,740
you acquire is actually for semantics so

786
00:26:52,740 --> 00:26:55,740
specifying you know 30 to 50 000

787
00:26:55,740 --> 00:26:57,720
different word meanings you know if even

788
00:26:57,720 --> 00:27:00,000
if each meaning is

789
00:27:00,000 --> 00:27:02,340
um uh just a few bits right like that

790
00:27:02,340 --> 00:27:04,620
that requires a lot of information and

791
00:27:04,620 --> 00:27:06,360
probably each meeting is more than a few

792
00:27:06,360 --> 00:27:08,460
bits right so

793
00:27:08,460 --> 00:27:11,279
um uh it could be like that that would

794
00:27:11,279 --> 00:27:12,659
make me guess that what's happening with

795
00:27:12,659 --> 00:27:14,820
with large language models is most of

796
00:27:14,820 --> 00:27:16,320
their training data is about word

797
00:27:16,320 --> 00:27:18,600
semantics and you can think about other

798
00:27:18,600 --> 00:27:20,760
ways that kids get word semantics right

799
00:27:20,760 --> 00:27:22,140
that's that's not just kind of

800
00:27:22,140 --> 00:27:24,600
co-occurrence patterns in in text

801
00:27:24,600 --> 00:27:27,360
um but I I agree all of that is is up in

802
00:27:27,360 --> 00:27:29,039
the air and and really exciting to see

803
00:27:29,039 --> 00:27:30,960
what will happen so yeah I know that

804
00:27:30,960 --> 00:27:32,640
some of the earlier results from it from

805
00:27:32,640 --> 00:27:35,279
Lindsay's lab suggests that at least

806
00:27:35,279 --> 00:27:37,740
restricted to ecologically valid you

807
00:27:37,740 --> 00:27:40,919
know training sites uh models seem to

808
00:27:40,919 --> 00:27:42,840
generalize you know linear rules for

809
00:27:42,840 --> 00:27:44,940
English yes no question formation ROM

810
00:27:44,940 --> 00:27:46,620
other than the hierarchical rule the

811
00:27:46,620 --> 00:27:48,120
correct hierarchy rule so I think

812
00:27:48,120 --> 00:27:49,980
there's a real sense in which you know

813
00:27:49,980 --> 00:27:52,020
this the the the space of the correct

814
00:27:52,020 --> 00:27:54,000
syntactic price and inductive biases

815
00:27:54,000 --> 00:27:56,220
really is is yet to be really settled on

816
00:27:56,220 --> 00:27:57,960
but it seems at least to me pretty

817
00:27:57,960 --> 00:27:59,400
obvious that there has to be some so

818
00:27:59,400 --> 00:28:01,320
there's also some evidence

819
00:28:01,320 --> 00:28:02,700
um that children in English going back

820
00:28:02,700 --> 00:28:04,679
to this frequency issue that children in

821
00:28:04,679 --> 00:28:06,360
English sometimes spell out an

822
00:28:06,360 --> 00:28:08,100
intermediate copy of movement in the

823
00:28:08,100 --> 00:28:10,140
specified position of the lower

824
00:28:10,140 --> 00:28:11,880
complementizer position of a long

825
00:28:11,880 --> 00:28:13,980
distance wh question so there's a thesis

826
00:28:13,980 --> 00:28:15,360
by Thornton and some other papers about

827
00:28:15,360 --> 00:28:18,120
this so they say um which person do you

828
00:28:18,120 --> 00:28:19,919
think who did that rather than which

829
00:28:19,919 --> 00:28:21,900
person do you think did that so this is

830
00:28:21,900 --> 00:28:23,159
an interesting you know Miss setting

831
00:28:23,159 --> 00:28:25,020
because some languages do actually spell

832
00:28:25,020 --> 00:28:26,760
out these intermediate copies but

833
00:28:26,760 --> 00:28:28,799
English doesn't so the kid makes the

834
00:28:28,799 --> 00:28:30,779
error in setting their grammar but the

835
00:28:30,779 --> 00:28:32,820
frequency of the input is actually zero

836
00:28:32,820 --> 00:28:35,159
and so our mutual friend Gary Marcus

837
00:28:35,159 --> 00:28:36,779
also has an argument against frequency

838
00:28:36,779 --> 00:28:39,000
determining a kid's output in the case

839
00:28:39,000 --> 00:28:41,159
of German noun plurals a more regular

840
00:28:41,159 --> 00:28:42,779
form of the certain kind is preferred

841
00:28:42,779 --> 00:28:44,580
not the frequent one and there's lots of

842
00:28:44,580 --> 00:28:46,559
examples like so it's sometimes claimed

843
00:28:46,559 --> 00:28:49,080
that subject experience passives where

844
00:28:49,080 --> 00:28:50,460
the subject is passively experiencing

845
00:28:50,460 --> 00:28:52,559
something or very delayed in kids in

846
00:28:52,559 --> 00:28:54,299
comprehension studies until around eight

847
00:28:54,299 --> 00:28:56,039
because they're not very frequent in the

848
00:28:56,039 --> 00:28:56,880
input

849
00:28:56,880 --> 00:28:59,220
But Ken Wexler and colleagues have gone

850
00:28:59,220 --> 00:29:01,260
through um subject experience Double H

851
00:29:01,260 --> 00:29:03,539
questions like who likes Mary and they

852
00:29:03,539 --> 00:29:05,820
discovered that these are as infrequent

853
00:29:05,820 --> 00:29:07,500
in the input as subject and experience

854
00:29:07,500 --> 00:29:09,659
of passives but kids have no problem in

855
00:29:09,659 --> 00:29:10,980
comprehension studies of these questions

856
00:29:10,980 --> 00:29:13,860
but they do have problems comprehending

857
00:29:13,860 --> 00:29:16,020
subject experience of verbal passives so

858
00:29:16,020 --> 00:29:17,880
frequency once again seems to be

859
00:29:17,880 --> 00:29:19,380
irrelevant or at least it's not

860
00:29:19,380 --> 00:29:20,940
explanatory right I guess it's not

861
00:29:20,940 --> 00:29:22,320
explanatory with respect to Theory

862
00:29:22,320 --> 00:29:25,080
building so how can LMS help with these

863
00:29:25,080 --> 00:29:27,059
you know diverging cases when there's

864
00:29:27,059 --> 00:29:28,440
clearly something else going on besides

865
00:29:28,440 --> 00:29:30,960
frequency so alums you know they seem to

866
00:29:30,960 --> 00:29:33,419
generalize just again going back to this

867
00:29:33,419 --> 00:29:35,100
issue of the the cases that you have in

868
00:29:35,100 --> 00:29:36,899
your paper and you show that they

869
00:29:36,899 --> 00:29:38,399
generalize the structure of colorless

870
00:29:38,399 --> 00:29:41,279
screen ideas which is often very cool

871
00:29:41,279 --> 00:29:43,080
um but the positive stimulus has never

872
00:29:43,080 --> 00:29:44,520
really been about not being able to

873
00:29:44,520 --> 00:29:46,380
learn language statistically I know you

874
00:29:46,380 --> 00:29:48,059
made that claim right but chomsky's

875
00:29:48,059 --> 00:29:49,559
point in the 50s about statistical

876
00:29:49,559 --> 00:29:51,779
models of the day is not true of

877
00:29:51,779 --> 00:29:53,700
commercial LMS in 2023 and that's

878
00:29:53,700 --> 00:29:55,440
correct but we can't use that single

879
00:29:55,440 --> 00:29:57,539
point to undermine you know the entire

880
00:29:57,539 --> 00:29:59,520
geometry Enterprise chomsky's basic

881
00:29:59,520 --> 00:30:01,080
point was that you could have a

882
00:30:01,080 --> 00:30:02,700
grammatical structure wherein every

883
00:30:02,700 --> 00:30:04,980
diagram has zero frequency and it also

884
00:30:04,980 --> 00:30:06,899
fails to provide clearly interpretable

885
00:30:06,899 --> 00:30:08,039
instructions to the conceptual

886
00:30:08,039 --> 00:30:09,840
interfaces so interfaces of other

887
00:30:09,840 --> 00:30:11,580
systems of the mind so as you're showing

888
00:30:11,580 --> 00:30:13,980
your paper GPT mimics examples like pull

889
00:30:13,980 --> 00:30:16,559
the screen ideas and but you know again

890
00:30:16,559 --> 00:30:18,840
this sentence yields over 150 000

891
00:30:18,840 --> 00:30:20,700
results on Google and it's discussed

892
00:30:20,700 --> 00:30:22,620
extensively in the literature it's able

893
00:30:22,620 --> 00:30:24,480
to mimic the fact that it can mimic this

894
00:30:24,480 --> 00:30:26,640
doesn't really tell us much at least we

895
00:30:26,640 --> 00:30:27,840
can't really say anything with much

896
00:30:27,840 --> 00:30:30,899
confidence so you know abiba behind at

897
00:30:30,899 --> 00:30:32,580
University College Dublin has this quote

898
00:30:32,580 --> 00:30:34,380
recently uh do not mistake your own

899
00:30:34,380 --> 00:30:36,840
gullibility for an lm's intelligence and

900
00:30:36,840 --> 00:30:38,880
in fact even young the wrote last

901
00:30:38,880 --> 00:30:40,500
year that critics are right to accuse

902
00:30:40,500 --> 00:30:42,480
LMS of being engaged in a kind of

903
00:30:42,480 --> 00:30:43,919
mimicry

904
00:30:43,919 --> 00:30:46,860
um and the example sentences from gbt

905
00:30:46,860 --> 00:30:48,840
that you give in the paper actually

906
00:30:48,840 --> 00:30:50,700
don't do a good job because as you say

907
00:30:50,700 --> 00:30:52,320
it's likely that you know meaningless

908
00:30:52,320 --> 00:30:54,240
languages rare in the training data but

909
00:30:54,240 --> 00:30:55,740
they can either do it or they can't but

910
00:30:55,740 --> 00:30:57,120
there's no middle ground in terms of

911
00:30:57,120 --> 00:30:59,880
giving us 10 examples like this so you

912
00:30:59,880 --> 00:31:02,880
have colorless green ideas which are

913
00:31:02,880 --> 00:31:04,679
very different semantic objects from

914
00:31:04,679 --> 00:31:06,840
things like brown shimmering rabbits

915
00:31:06,840 --> 00:31:09,899
white glittery Bears uh black shiny

916
00:31:09,899 --> 00:31:12,360
kangaroos green glittering monkeys

917
00:31:12,360 --> 00:31:15,120
yellow dazzling Lions red shimming

918
00:31:15,120 --> 00:31:16,320
elements right these are all like

919
00:31:16,320 --> 00:31:18,899
semantic semantically weird and a bit

920
00:31:18,899 --> 00:31:20,820
strange but they're still like legal

921
00:31:20,820 --> 00:31:22,440
structures they're kind of meaningful

922
00:31:22,440 --> 00:31:25,320
synthetic semantic objects

923
00:31:25,320 --> 00:31:27,179
um right

924
00:31:27,179 --> 00:31:29,580
I I just said yeah yeah

925
00:31:29,580 --> 00:31:33,179
I I I I mean so I I maybe I can I can

926
00:31:33,179 --> 00:31:34,799
respond to the first point first right

927
00:31:34,799 --> 00:31:36,120
so

928
00:31:36,120 --> 00:31:37,799
um uh you started off talking about

929
00:31:37,799 --> 00:31:40,140
these other uh kinds of acquisition

930
00:31:40,140 --> 00:31:42,179
patterns which maybe don't map directly

931
00:31:42,179 --> 00:31:44,279
onto to frequency

932
00:31:44,279 --> 00:31:47,159
um and I I think it's actually a mistake

933
00:31:47,159 --> 00:31:50,640
to think that uh kind of modern learning

934
00:31:50,640 --> 00:31:53,039
models should be just based on frequency

935
00:31:53,039 --> 00:31:54,899
because

936
00:31:54,899 --> 00:31:57,120
um they're clearly learning like pretty

937
00:31:57,120 --> 00:31:59,580
complicated families of rules or

938
00:31:59,580 --> 00:32:02,399
constructions or something and

939
00:32:02,399 --> 00:32:03,899
um I think it's very likely that when

940
00:32:03,899 --> 00:32:06,600
they're they're learning that they're

941
00:32:06,600 --> 00:32:08,580
um in some sense searching for a simple

942
00:32:08,580 --> 00:32:10,559
or parsimonious

943
00:32:10,559 --> 00:32:12,360
um uh explanation of the data that

944
00:32:12,360 --> 00:32:13,980
they've seen right and how that caches

945
00:32:13,980 --> 00:32:16,080
out in a in a neural network is is maybe

946
00:32:16,080 --> 00:32:19,200
complicated and you know it depends on

947
00:32:19,200 --> 00:32:20,880
um you know parameters and the specifics

948
00:32:20,880 --> 00:32:22,679
of the learning algorithm and and and

949
00:32:22,679 --> 00:32:24,480
those kind of things

950
00:32:24,480 --> 00:32:27,000
um but I think it's it's uh I I guess

951
00:32:27,000 --> 00:32:29,279
I'd suspect maybe that that it's likely

952
00:32:29,279 --> 00:32:31,740
to be the case that

953
00:32:31,740 --> 00:32:35,640
um uh like they're they're they're

954
00:32:35,640 --> 00:32:38,399
learning over a complicated set of

955
00:32:38,399 --> 00:32:40,799
things right a complicated kind of

956
00:32:40,799 --> 00:32:43,799
family of of rules and constructions

957
00:32:43,799 --> 00:32:46,919
um and that means I I think that

958
00:32:46,919 --> 00:32:49,380
um their generalizations may be like the

959
00:32:49,380 --> 00:32:52,500
examples of people that that you gave

960
00:32:52,500 --> 00:32:55,440
um might be kind of discontinuous in the

961
00:32:55,440 --> 00:32:57,720
input right so sometimes you you you

962
00:32:57,720 --> 00:33:00,000
could imagine seeing some strings which

963
00:33:00,000 --> 00:33:02,220
leads you to a grammar and the simplest

964
00:33:02,220 --> 00:33:03,840
grammar of the data that that you've

965
00:33:03,840 --> 00:33:06,059
seen so far is one which predicts an

966
00:33:06,059 --> 00:33:09,120
unseen string right and

967
00:33:09,120 --> 00:33:12,360
um if that happens then you'll be uh

968
00:33:12,360 --> 00:33:14,100
taking the data learning a

969
00:33:14,100 --> 00:33:16,860
representation which generalizes in some

970
00:33:16,860 --> 00:33:19,440
novel unseen way so far

971
00:33:19,440 --> 00:33:21,720
um purely because that generalization is

972
00:33:21,720 --> 00:33:23,460
is sort of the simplest account of the

973
00:33:23,460 --> 00:33:25,019
data that you've seen scene to date

974
00:33:25,019 --> 00:33:25,980
right I think that's sort of what

975
00:33:25,980 --> 00:33:28,320
linguists tried to do right try to uh

976
00:33:28,320 --> 00:33:29,700
look at the data and come up with the

977
00:33:29,700 --> 00:33:31,260
theory of it and then sometimes that

978
00:33:31,260 --> 00:33:33,419
theory predicts some new phenomenon

979
00:33:33,419 --> 00:33:35,840
right or some some new type of sentence

980
00:33:35,840 --> 00:33:38,159
and so if they're learning over a

981
00:33:38,159 --> 00:33:41,100
sufficiently rich space of theories

982
00:33:41,100 --> 00:33:42,899
um then it wouldn't be you know

983
00:33:42,899 --> 00:33:45,000
unreasonable or unexpected for for them

984
00:33:45,000 --> 00:33:47,039
to also show those kinds of patterns now

985
00:33:47,039 --> 00:33:48,899
whether they they do or not I think is

986
00:33:48,899 --> 00:33:51,299
is still an open empirical question

987
00:33:51,299 --> 00:33:52,740
right

988
00:33:52,740 --> 00:33:54,120
um because we have to train them on

989
00:33:54,120 --> 00:33:55,620
small amounts of data and test their

990
00:33:55,620 --> 00:33:57,480
generalizations and and these kind of

991
00:33:57,480 --> 00:33:58,260
things

992
00:33:58,260 --> 00:34:00,120
um but I don't think like just the fact

993
00:34:00,120 --> 00:34:01,620
that

994
00:34:01,620 --> 00:34:03,899
um you know humans do things which are

995
00:34:03,899 --> 00:34:06,059
not purely based on frequency is any

996
00:34:06,059 --> 00:34:07,860
evidence at all either way right because

997
00:34:07,860 --> 00:34:09,300
once you're learning over rich and

998
00:34:09,300 --> 00:34:10,980
interesting classes of theories then

999
00:34:10,980 --> 00:34:13,980
that that is the expected behavior

1000
00:34:13,980 --> 00:34:16,980
um actually I I had um a paper about a a

1001
00:34:16,980 --> 00:34:18,719
year ago that I think you're you're

1002
00:34:18,719 --> 00:34:20,040
familiar with

1003
00:34:20,040 --> 00:34:22,560
um uh Yang and and pianta dosi where

1004
00:34:22,560 --> 00:34:24,179
where we were

1005
00:34:24,179 --> 00:34:26,879
um uh looking at

1006
00:34:26,879 --> 00:34:29,280
um uh kind of what happens when you give

1007
00:34:29,280 --> 00:34:32,639
a program learning model strings from uh

1008
00:34:32,639 --> 00:34:34,679
different formal languages so think of

1009
00:34:34,679 --> 00:34:35,820
like

1010
00:34:35,820 --> 00:34:38,760
um giving a a general model just you

1011
00:34:38,760 --> 00:34:41,159
know 10 or 20 maybe simple strings that

1012
00:34:41,159 --> 00:34:43,500
obey some pattern and then asking it to

1013
00:34:43,500 --> 00:34:46,199
find a program which uh can explain that

1014
00:34:46,199 --> 00:34:49,320
data which often means you know finding

1015
00:34:49,320 --> 00:34:50,940
um uh finding some way of kind of

1016
00:34:50,940 --> 00:34:52,679
programmatically writing down the the

1017
00:34:52,679 --> 00:34:54,839
pattern in in the strings

1018
00:34:54,839 --> 00:34:56,280
um and in that figure we we have a paper

1019
00:34:56,280 --> 00:34:58,020
which is really relevant to to this

1020
00:34:58,020 --> 00:34:59,820
point where

1021
00:34:59,820 --> 00:35:02,640
um the uh generalizations that that kind

1022
00:35:02,640 --> 00:35:04,200
of model makes

1023
00:35:04,200 --> 00:35:06,660
um uh are I think kind of qualitatively

1024
00:35:06,660 --> 00:35:08,160
like the ones you're describing for

1025
00:35:08,160 --> 00:35:10,560
people right where

1026
00:35:10,560 --> 00:35:12,060
um uh you can give them a small amount

1027
00:35:12,060 --> 00:35:13,980
of data and it will predict unseen

1028
00:35:13,980 --> 00:35:16,740
strings with very high probability

1029
00:35:16,740 --> 00:35:18,420
um even though there's zero frequency in

1030
00:35:18,420 --> 00:35:20,280
the training input right and the reason

1031
00:35:20,280 --> 00:35:22,740
it does that is that often the most

1032
00:35:22,740 --> 00:35:24,660
concise computational description of the

1033
00:35:24,660 --> 00:35:26,640
data that you've seen is one that

1034
00:35:26,640 --> 00:35:29,640
predicts some particular uh new unseen

1035
00:35:29,640 --> 00:35:32,940
output so that that model is is

1036
00:35:32,940 --> 00:35:34,800
essentially an implementation of the the

1037
00:35:34,800 --> 00:35:36,839
kind of Chader and Vitani program

1038
00:35:36,839 --> 00:35:38,160
learning

1039
00:35:38,160 --> 00:35:40,619
um idea that that I brought up earlier

1040
00:35:40,619 --> 00:35:42,900
um but it it's one that that I think you

1041
00:35:42,900 --> 00:35:43,980
know if you think about in the context

1042
00:35:43,980 --> 00:35:45,660
of these arguments of kids saying

1043
00:35:45,660 --> 00:35:48,599
unusual or unexpected things like that

1044
00:35:48,599 --> 00:35:50,280
is predicted by all of these kinds of

1045
00:35:50,280 --> 00:35:52,859
accounts right because as long as as

1046
00:35:52,859 --> 00:35:54,180
long as these things are effectively

1047
00:35:54,180 --> 00:35:55,680
comparing an interesting space of

1048
00:35:55,680 --> 00:35:56,760
grammars

1049
00:35:56,760 --> 00:35:58,079
um then they'll they'll show that that

1050
00:35:58,079 --> 00:35:59,760
kind of behavior I think

1051
00:35:59,760 --> 00:36:04,680
uh yeah so okay so I guess you know

1052
00:36:04,680 --> 00:36:06,960
the argument would be that at least from

1053
00:36:06,960 --> 00:36:10,140
the gender perspective syntax is

1054
00:36:10,140 --> 00:36:13,140
functioning separately but it's still

1055
00:36:13,140 --> 00:36:15,359
mapped to semantics it informs

1056
00:36:15,359 --> 00:36:17,040
pragmatics right so in the Middle East

1057
00:36:17,040 --> 00:36:18,480
program syntax is obviously meaningless

1058
00:36:18,480 --> 00:36:20,160
it's very small it's just it's just a

1059
00:36:20,160 --> 00:36:22,320
linearization and labeling they're the

1060
00:36:22,320 --> 00:36:24,180
two only operations you have a

1061
00:36:24,180 --> 00:36:26,220
linearization algorithm to centromotor

1062
00:36:26,220 --> 00:36:27,900
systems and some kind of categorization

1063
00:36:27,900 --> 00:36:30,480
algorithm at the at the um Center at the

1064
00:36:30,480 --> 00:36:32,220
conceptual systems

1065
00:36:32,220 --> 00:36:33,839
um so chomsky's architecture is kind of

1066
00:36:33,839 --> 00:36:35,940
reliant on the process of mapping syntax

1067
00:36:35,940 --> 00:36:37,560
to semantics right it's foam meaning

1068
00:36:37,560 --> 00:36:39,960
regulation it's not just structure and

1069
00:36:39,960 --> 00:36:42,180
it's not just meaning so LMS don't

1070
00:36:42,180 --> 00:36:43,680
really have this mapping process right

1071
00:36:43,680 --> 00:36:45,180
like where's the mapping to semantics

1072
00:36:45,180 --> 00:36:47,160
and if there is a mapping what do the

1073
00:36:47,160 --> 00:36:48,480
what does the mapping process look like

1074
00:36:48,480 --> 00:36:50,099
what are the properties of its semantics

1075
00:36:50,099 --> 00:36:52,320
uh you know what do these what the

1076
00:36:52,320 --> 00:36:54,000
properties of the semantics place on

1077
00:36:54,000 --> 00:36:55,500
their own sets of constraints on the

1078
00:36:55,500 --> 00:36:57,180
marketing process like they do for

1079
00:36:57,180 --> 00:36:58,980
natural language are they kind of you

1080
00:36:58,980 --> 00:37:01,079
know uh do do these kind of constraints

1081
00:37:01,079 --> 00:37:02,640
inform each other is they kind of a back

1082
00:37:02,640 --> 00:37:05,579
and forth process right like elements

1083
00:37:05,579 --> 00:37:07,260
don't really seem to describe this form

1084
00:37:07,260 --> 00:37:09,359
meaning pairing correct like which

1085
00:37:09,359 --> 00:37:11,339
meanings which strings for example right

1086
00:37:11,339 --> 00:37:14,640
well sorry are you saying that

1087
00:37:14,640 --> 00:37:16,740
um that that they don't have semantics

1088
00:37:16,740 --> 00:37:18,599
at all or are you saying that there's

1089
00:37:18,599 --> 00:37:21,180
just not a clear uh delineation between

1090
00:37:21,180 --> 00:37:23,400
how the structures get mapped onto the

1091
00:37:23,400 --> 00:37:25,500
semantics yeah the latter right so they

1092
00:37:25,500 --> 00:37:27,300
clearly have some potentially some kind

1093
00:37:27,300 --> 00:37:28,800
of semantics I know you've argued for a

1094
00:37:28,800 --> 00:37:30,180
conceptual role Theory being relevant

1095
00:37:30,180 --> 00:37:31,920
here right the rest of it maybe little

1096
00:37:31,920 --> 00:37:33,900
bit more mysterious but the actual soy

1097
00:37:33,900 --> 00:37:35,339
Linguistics at the very there's a theory

1098
00:37:35,339 --> 00:37:36,900
of the mapping process itself it's

1099
00:37:36,900 --> 00:37:39,060
explicit and you can see it in action

1100
00:37:39,060 --> 00:37:40,440
and you can test different theories of

1101
00:37:40,440 --> 00:37:42,000
it in Psych linguistic models and what

1102
00:37:42,000 --> 00:37:44,700
have you the the actual regulation the

1103
00:37:44,700 --> 00:37:46,079
kind of you know constrained ambiguity

1104
00:37:46,079 --> 00:37:48,119
ambiguity in the sense of you know one

1105
00:37:48,119 --> 00:37:50,400
word multiple meanings or one structure

1106
00:37:50,400 --> 00:37:53,040
multiple interpretations Etc right

1107
00:37:53,040 --> 00:37:55,200
yeah I mean if you think they have

1108
00:37:55,200 --> 00:37:57,599
semantics then then I think they have to

1109
00:37:57,599 --> 00:37:59,640
have a mapping from the syntax to the

1110
00:37:59,640 --> 00:38:00,960
semantics

1111
00:38:00,960 --> 00:38:03,599
um I agree it's it's not as like nobody

1112
00:38:03,599 --> 00:38:04,980
really understands how they're working

1113
00:38:04,980 --> 00:38:07,560
on any deep level right so I so I agree

1114
00:38:07,560 --> 00:38:10,140
it's it's not as clear as

1115
00:38:10,140 --> 00:38:11,940
um say in in generative syntax and

1116
00:38:11,940 --> 00:38:13,859
semantics right where

1117
00:38:13,859 --> 00:38:15,180
um you know you kind of write down the

1118
00:38:15,180 --> 00:38:17,880
the rules of of composition and and can

1119
00:38:17,880 --> 00:38:19,920
derive a compositional meaning from a

1120
00:38:19,920 --> 00:38:21,480
sentence from the component parts or

1121
00:38:21,480 --> 00:38:23,339
something right like that's

1122
00:38:23,339 --> 00:38:24,660
um you know that's not how they're

1123
00:38:24,660 --> 00:38:27,060
working right but

1124
00:38:27,060 --> 00:38:28,859
um I I just I I wouldn't take for

1125
00:38:28,859 --> 00:38:32,160
granted that it has to be like that like

1126
00:38:32,160 --> 00:38:34,619
um uh it could be that how they're

1127
00:38:34,619 --> 00:38:36,420
working is actually how we work right

1128
00:38:36,420 --> 00:38:38,760
that uh everything is represented in

1129
00:38:38,760 --> 00:38:40,800
some high dimensional Vector space and

1130
00:38:40,800 --> 00:38:43,740
there's some complicated uh way in which

1131
00:38:43,740 --> 00:38:46,200
that Vector semantics gets updated with

1132
00:38:46,200 --> 00:38:48,240
each additional word or whatever

1133
00:38:48,240 --> 00:38:51,480
um in in a linguistic stream

1134
00:38:51,480 --> 00:38:53,940
um but like I I think think it's clear

1135
00:38:53,940 --> 00:38:55,320
that they have some kind of

1136
00:38:55,320 --> 00:38:57,660
representation of the semantics of a

1137
00:38:57,660 --> 00:38:59,099
sentence right like they can answer

1138
00:38:59,099 --> 00:39:01,260
questions for example at least

1139
00:39:01,260 --> 00:39:02,760
approximately I mean it's not not

1140
00:39:02,760 --> 00:39:04,380
perfect but

1141
00:39:04,380 --> 00:39:06,720
um it's it's not like a engram model or

1142
00:39:06,720 --> 00:39:07,740
something right which really doesn't

1143
00:39:07,740 --> 00:39:10,500
have doesn't have semantics so

1144
00:39:10,500 --> 00:39:12,780
um I I think that they're

1145
00:39:12,780 --> 00:39:14,040
um they're they're definitely

1146
00:39:14,040 --> 00:39:16,920
representing semantics and

1147
00:39:16,920 --> 00:39:20,040
um uh you know updating that as they as

1148
00:39:20,040 --> 00:39:21,599
they process language it just happens

1149
00:39:21,599 --> 00:39:23,400
not to look like these other formal

1150
00:39:23,400 --> 00:39:24,599
theories

1151
00:39:24,599 --> 00:39:26,400
um and I I guess I I don't see why

1152
00:39:26,400 --> 00:39:27,720
that's a problem right like those other

1153
00:39:27,720 --> 00:39:29,640
formal theories could just be you know

1154
00:39:29,640 --> 00:39:31,920
poor approximations or or just totally

1155
00:39:31,920 --> 00:39:33,720
wrong right yeah

1156
00:39:33,720 --> 00:39:35,520
yeah yeah no totally totally I mean

1157
00:39:35,520 --> 00:39:37,260
there's also ways in which some of the

1158
00:39:37,260 --> 00:39:39,359
formal theories in semantics are already

1159
00:39:39,359 --> 00:39:41,520
potentially compatible with what some of

1160
00:39:41,520 --> 00:39:42,780
these things are doing right so another

1161
00:39:42,780 --> 00:39:45,240
way to think about this is you know LMS

1162
00:39:45,240 --> 00:39:47,760
are well LMS are compression algorithms

1163
00:39:47,760 --> 00:39:49,740
but natural language understanding is

1164
00:39:49,740 --> 00:39:51,540
kind of all more about decompression

1165
00:39:51,540 --> 00:39:54,180
it's disambiguating meaning X Out of

1166
00:39:54,180 --> 00:39:56,099
meanings XYZ it's all about making

1167
00:39:56,099 --> 00:39:58,020
inferences about you know meta relations

1168
00:39:58,020 --> 00:39:59,579
between Concepts that are not in the

1169
00:39:59,579 --> 00:40:01,859
training data so some examples that

1170
00:40:01,859 --> 00:40:03,180
Melanie Mitchell gives out things like

1171
00:40:03,180 --> 00:40:06,119
on top of you know she's on top of again

1172
00:40:06,119 --> 00:40:08,700
uh it's on top of the box all these kind

1173
00:40:08,700 --> 00:40:10,140
of vary with context so there's a lot of

1174
00:40:10,140 --> 00:40:11,880
other things that are going on right

1175
00:40:11,880 --> 00:40:13,260
um and I think you discuss some of those

1176
00:40:13,260 --> 00:40:16,440
examples in your paper so you know

1177
00:40:16,440 --> 00:40:18,119
um but the faculty of language is still

1178
00:40:18,119 --> 00:40:20,940
not at least again under this theory of

1179
00:40:20,940 --> 00:40:22,920
language and it's not about string

1180
00:40:22,920 --> 00:40:25,200
generation it's about this form meaning

1181
00:40:25,200 --> 00:40:27,540
pairing machine so sometimes this in the

1182
00:40:27,540 --> 00:40:29,400
genitive tradition even think all there

1183
00:40:29,400 --> 00:40:31,859
is to semantics is just and right so

1184
00:40:31,859 --> 00:40:33,540
Paul petrovsky's conjunctive is there

1185
00:40:33,540 --> 00:40:36,000
some is that human semantics is just and

1186
00:40:36,000 --> 00:40:37,500
that's it

1187
00:40:37,500 --> 00:40:39,900
um which again is is very simple elegant

1188
00:40:39,900 --> 00:40:42,000
it's it's it's it's interpretable it's

1189
00:40:42,000 --> 00:40:43,920
compatible with a lot of the things that

1190
00:40:43,920 --> 00:40:46,320
you know or maybe going on in in your

1191
00:40:46,320 --> 00:40:47,940
neck of the words right but regardless

1192
00:40:47,940 --> 00:40:49,859
it's still you know natural language is

1193
00:40:49,859 --> 00:40:51,540
still more compositional

1194
00:40:51,540 --> 00:40:54,060
them things like uh you know formal

1195
00:40:54,060 --> 00:40:55,260
languages just to make a clear

1196
00:40:55,260 --> 00:40:56,820
distinction that's been made they have a

1197
00:40:56,820 --> 00:40:58,260
much richer composition of structure

1198
00:40:58,260 --> 00:41:00,839
there's more stuff going on uh maybe so

1199
00:41:00,839 --> 00:41:02,160
it's been pointed out before that you

1200
00:41:02,160 --> 00:41:03,480
know things like attention-based machine

1201
00:41:03,480 --> 00:41:05,640
mechanisms and Transformers

1202
00:41:05,640 --> 00:41:07,800
um allow for combinations of discrete

1203
00:41:07,800 --> 00:41:10,320
token bindings which is more approximate

1204
00:41:10,320 --> 00:41:12,359
to a merge like operator than simple

1205
00:41:12,359 --> 00:41:14,640
recurrent matrix multiplication

1206
00:41:14,640 --> 00:41:16,140
um but you know the issue of binary

1207
00:41:16,140 --> 00:41:17,460
branching binary branching government

1208
00:41:17,460 --> 00:41:19,260
just to choose another example here to

1209
00:41:19,260 --> 00:41:20,640
talk about the full meaning regulation

1210
00:41:20,640 --> 00:41:23,640
one principle binary branching image is

1211
00:41:23,640 --> 00:41:24,839
an interesting question but geometry

1212
00:41:24,839 --> 00:41:26,700
grammar has always been open to

1213
00:41:26,700 --> 00:41:28,740
different Origins and locations of this

1214
00:41:28,740 --> 00:41:30,660
apparent constraint in synthetic

1215
00:41:30,660 --> 00:41:31,800
computation right like where does it

1216
00:41:31,800 --> 00:41:33,540
come from maybe it's a condition on

1217
00:41:33,540 --> 00:41:34,980
merge maybe it's imposed by a smooth

1218
00:41:34,980 --> 00:41:37,079
system maybe it's a kind of Prior you

1219
00:41:37,079 --> 00:41:39,060
know who knows and in fact it's some

1220
00:41:39,060 --> 00:41:40,500
more recent working generative grammar

1221
00:41:40,500 --> 00:41:43,859
has tried to ground and do away with all

1222
00:41:43,859 --> 00:41:46,440
theoretic assumptions of of marriage

1223
00:41:46,440 --> 00:41:47,700
right maybe set theory isn't the best

1224
00:41:47,700 --> 00:41:48,780
way to model

1225
00:41:48,780 --> 00:41:50,339
um the generative grammar maybe Maria

1226
00:41:50,339 --> 00:41:51,540
logical accounts are more appropriate

1227
00:41:51,540 --> 00:41:53,520
there's lots of other recent ideas there

1228
00:41:53,520 --> 00:41:55,020
which which are all compatible with the

1229
00:41:55,020 --> 00:41:57,540
with chomsky's approach right in fact

1230
00:41:57,540 --> 00:41:58,680
yeah one of the things that Trump get

1231
00:41:58,680 --> 00:42:00,060
likes the most is when he's when he's

1232
00:42:00,060 --> 00:42:01,380
proven wrong right A lot of these

1233
00:42:01,380 --> 00:42:03,720
theories are drawing against the core

1234
00:42:03,720 --> 00:42:06,300
mainstream minimalist architecture but

1235
00:42:06,300 --> 00:42:08,640
that yeah I think so it's a very diverse

1236
00:42:08,640 --> 00:42:11,839
like vibrant field the people who are

1237
00:42:11,839 --> 00:42:15,119
Bornstein you know petrovsky uh uh

1238
00:42:15,119 --> 00:42:17,520
hajipura they disagree in fundamental

1239
00:42:17,520 --> 00:42:19,380
ways with a lot of what the mainstream

1240
00:42:19,380 --> 00:42:20,940
of chemical grammar would say but

1241
00:42:20,940 --> 00:42:21,960
there's still more scope for

1242
00:42:21,960 --> 00:42:24,240
disagreement but it's still compatible

1243
00:42:24,240 --> 00:42:26,400
with setting core assumptions right so a

1244
00:42:26,400 --> 00:42:27,599
lot of David I just wear for example

1245
00:42:27,599 --> 00:42:29,400
kind of deviates in this core respect

1246
00:42:29,400 --> 00:42:31,920
but it's still trying to ground these

1247
00:42:31,920 --> 00:42:33,240
intuitions in in different formal

1248
00:42:33,240 --> 00:42:34,500
systems

1249
00:42:34,500 --> 00:42:36,000
um so you know

1250
00:42:36,000 --> 00:42:38,099
it's kind of

1251
00:42:38,099 --> 00:42:40,320
I want to get your thoughts again on um

1252
00:42:40,320 --> 00:42:42,240
I mentioned Mitchell right so Michelin

1253
00:42:42,240 --> 00:42:44,579
Bowers uh 2020 they have this paper

1254
00:42:44,579 --> 00:42:47,040
trial list recurrent networks laying

1255
00:42:47,040 --> 00:42:48,359
curiously that I think you might be

1256
00:42:48,359 --> 00:42:49,859
aware of right so it's a really good

1257
00:42:49,859 --> 00:42:51,060
example just to kind of get to the heart

1258
00:42:51,060 --> 00:42:53,099
of the issue so recurrent neural

1259
00:42:53,099 --> 00:42:54,780
networks have been shown to accurately

1260
00:42:54,780 --> 00:42:56,520
model you know non-verb number agreement

1261
00:42:56,520 --> 00:42:58,020
but Mitchell and Barrow showed that

1262
00:42:58,020 --> 00:43:00,060
these networks will also land a number

1263
00:43:00,060 --> 00:43:01,680
agreement with unnatural sentence

1264
00:43:01,680 --> 00:43:03,359
structures so structures that are not

1265
00:43:03,359 --> 00:43:04,859
found in natural language and which

1266
00:43:04,859 --> 00:43:06,540
humans have a hard time processing right

1267
00:43:06,540 --> 00:43:09,359
so the mode of learning for rnns is at

1268
00:43:09,359 --> 00:43:11,880
least for rnn's positively distinct from

1269
00:43:11,880 --> 00:43:14,339
from infant you know infant Homo sapiens

1270
00:43:14,339 --> 00:43:16,260
right so the story is Mitchell and

1271
00:43:16,260 --> 00:43:18,359
Bowers show that while the lstl model

1272
00:43:18,359 --> 00:43:20,040
has a good representation of singular

1273
00:43:20,040 --> 00:43:22,140
versus plural for individual sentences

1274
00:43:22,140 --> 00:43:24,359
there's no generalization going on right

1275
00:43:24,359 --> 00:43:25,800
they can represent at the individual

1276
00:43:25,800 --> 00:43:27,359
level so the model doesn't have a

1277
00:43:27,359 --> 00:43:28,859
representation of number as an

1278
00:43:28,859 --> 00:43:31,200
abstraction what number is only concrete

1279
00:43:31,200 --> 00:43:34,020
instances of singular basis plural

1280
00:43:34,020 --> 00:43:35,400
um so successfully predicting language

1281
00:43:35,400 --> 00:43:38,579
Behavior via LM or successfully

1282
00:43:38,579 --> 00:43:40,800
predicting neural responses in a similar

1283
00:43:40,800 --> 00:43:42,480
way is obviously great and maybe we can

1284
00:43:42,480 --> 00:43:43,920
get into that issue later but there's

1285
00:43:43,920 --> 00:43:45,240
only one side of the coin here right the

1286
00:43:45,240 --> 00:43:47,099
other side of the coin is explaining why

1287
00:43:47,099 --> 00:43:48,780
this type of behavior and not some other

1288
00:43:48,780 --> 00:43:50,339
Behavior why this structure I'm not

1289
00:43:50,339 --> 00:43:52,740
similar and that's maybe chomsky's most

1290
00:43:52,740 --> 00:43:55,380
and like you know his most important

1291
00:43:55,380 --> 00:43:56,760
Point really why this are not some other

1292
00:43:56,760 --> 00:43:59,400
system so linguistic Theory kind of

1293
00:43:59,400 --> 00:44:00,720
gives you that or the start of the coin

1294
00:44:00,720 --> 00:44:02,760
right whereas LM is really done so the

1295
00:44:02,760 --> 00:44:03,839
Mitchell embarrassed paper does

1296
00:44:03,839 --> 00:44:05,819
something like that he does it

1297
00:44:05,819 --> 00:44:09,420
well yeah so like take um Yael Le crets

1298
00:44:09,420 --> 00:44:11,400
and stanislash the Haynes were from 2019

1299
00:44:11,400 --> 00:44:13,319
right they looked at number agreement in

1300
00:44:13,319 --> 00:44:15,480
an lstm and found two specialized units

1301
00:44:15,480 --> 00:44:17,640
that encoded number agreement but the

1302
00:44:17,640 --> 00:44:19,020
overall contribution to Performance was

1303
00:44:19,020 --> 00:44:21,839
low and then in 2021 uh yeah corrects

1304
00:44:21,839 --> 00:44:24,000
had this paper where they show that

1305
00:44:24,000 --> 00:44:26,040
um in their neural language model it did

1306
00:44:26,040 --> 00:44:28,079
not achieve genuine recursive processing

1307
00:44:28,079 --> 00:44:30,540
of nested long range agreement gender

1308
00:44:30,540 --> 00:44:32,160
marking in Italian I think

1309
00:44:32,160 --> 00:44:34,020
um even if some hierarchical processing

1310
00:44:34,020 --> 00:44:35,819
what you know was achieved as you've

1311
00:44:35,819 --> 00:44:37,380
argued before right some hierarchy was

1312
00:44:37,380 --> 00:44:39,960
left it was there but the question is is

1313
00:44:39,960 --> 00:44:41,280
it the right mapping is it the right

1314
00:44:41,280 --> 00:44:42,900
kind of hierarchy they found that

1315
00:44:42,900 --> 00:44:45,119
lstn-based models could land subject web

1316
00:44:45,119 --> 00:44:47,220
agreement over short spans one degree of

1317
00:44:47,220 --> 00:44:49,260
embedding but they failed at some longer

1318
00:44:49,260 --> 00:44:51,359
dependencies and in the most recent

1319
00:44:51,359 --> 00:44:53,700
paper uh La crepe satell with the hand

1320
00:44:53,700 --> 00:44:56,760
and showed that they evaluated modern

1321
00:44:56,760 --> 00:45:00,180
Transformer LMS including gpt2 XL on the

1322
00:45:00,180 --> 00:45:01,980
same task and the Transformers perform

1323
00:45:01,980 --> 00:45:04,260
more similarly to humans than LSM did

1324
00:45:04,260 --> 00:45:06,300
and performed above transfer overall but

1325
00:45:06,300 --> 00:45:08,040
they still perform below chance in one

1326
00:45:08,040 --> 00:45:09,660
key condition which is the as I

1327
00:45:09,660 --> 00:45:11,099
mentioned the multiple embedding one the

1328
00:45:11,099 --> 00:45:13,020
difficult scriptures and so the reason

1329
00:45:13,020 --> 00:45:14,400
why I mentioned these studies is because

1330
00:45:14,400 --> 00:45:17,040
you know it's not just to explore the

1331
00:45:17,040 --> 00:45:18,540
limits of OMS which is an interesting

1332
00:45:18,540 --> 00:45:19,500
question

1333
00:45:19,500 --> 00:45:21,540
um but consider work by people like Neil

1334
00:45:21,540 --> 00:45:24,180
Smith at UCL right and he did work in

1335
00:45:24,180 --> 00:45:26,579
the 90s with a polyglot Savant and

1336
00:45:26,579 --> 00:45:28,740
neurotypical controls comparing them so

1337
00:45:28,740 --> 00:45:30,540
he investigated second language learning

1338
00:45:30,540 --> 00:45:32,520
of an artificial language containing

1339
00:45:32,520 --> 00:45:34,500
both natural and unnatural graphical

1340
00:45:34,500 --> 00:45:35,880
structures like the Michelin virus paper

1341
00:45:35,880 --> 00:45:37,079
right the whole framework is natural

1342
00:45:37,079 --> 00:45:39,119
versus unnatural and they found that

1343
00:45:39,119 --> 00:45:41,000
while both the savant

1344
00:45:41,000 --> 00:45:43,319
and the controls could Master the

1345
00:45:43,319 --> 00:45:45,480
linguistically natural aspects only the

1346
00:45:45,480 --> 00:45:46,920
controls could eventually handle the

1347
00:45:46,920 --> 00:45:48,660
structure dependent unnatural phenomena

1348
00:45:48,660 --> 00:45:50,460
and neither of them could Master the

1349
00:45:50,460 --> 00:45:52,560
structure independent aspects so some

1350
00:45:52,560 --> 00:45:53,880
weird rules where it's like you know you

1351
00:45:53,880 --> 00:45:55,440
mark the emphasis on the third word of

1352
00:45:55,440 --> 00:45:56,940
the sentence things like that so they

1353
00:45:56,940 --> 00:45:58,740
argue that Christopher's abilities are

1354
00:45:58,740 --> 00:46:00,900
entirely due to his intact linguistic

1355
00:46:00,900 --> 00:46:03,480
faculties but the controls could employ

1356
00:46:03,480 --> 00:46:05,579
more domain General kind of cognitive

1357
00:46:05,579 --> 00:46:07,319
resources like you know attention

1358
00:46:07,319 --> 00:46:09,900
control Etc which is why they could deal

1359
00:46:09,900 --> 00:46:11,520
with difficult processes

1360
00:46:11,520 --> 00:46:13,319
but I just mentioned you know a minute

1361
00:46:13,319 --> 00:46:16,079
ago that the lstm in the Mitchell

1362
00:46:16,079 --> 00:46:18,359
embarrassed paper approaches natural and

1363
00:46:18,359 --> 00:46:19,920
unnatural structures in pretty much the

1364
00:46:19,920 --> 00:46:22,319
same way so it's not you know it's not a

1365
00:46:22,319 --> 00:46:24,240
psychologically plausible model I would

1366
00:46:24,240 --> 00:46:26,400
argue and for whatever humans are doing

1367
00:46:26,400 --> 00:46:28,200
and similar observations can apply to

1368
00:46:28,200 --> 00:46:30,060
the limits of Transformer models in La

1369
00:46:30,060 --> 00:46:31,920
creta's work and all of these themes are

1370
00:46:31,920 --> 00:46:33,780
like right up that they're staying with

1371
00:46:33,780 --> 00:46:35,819
us all the way to the present so another

1372
00:46:35,819 --> 00:46:37,560
one of talins recent papers that he

1373
00:46:37,560 --> 00:46:39,240
posted a few weeks ago looking at child

1374
00:46:39,240 --> 00:46:41,880
directed speech showed that um lstms and

1375
00:46:41,880 --> 00:46:43,740
Transformers limited to ecologically

1376
00:46:43,740 --> 00:46:46,380
plausible amounts of data generalized as

1377
00:46:46,380 --> 00:46:47,640
I mentioned the linear rules for English

1378
00:46:47,640 --> 00:46:49,920
right rather than the abstract rules and

1379
00:46:49,920 --> 00:46:51,780
in fact more recent work from linton's

1380
00:46:51,780 --> 00:46:54,599
Lab last week looking at uh well last

1381
00:46:54,599 --> 00:46:56,220
year I should say shows that looking at

1382
00:46:56,220 --> 00:46:58,160
Garden paths surprisal does not explain

1383
00:46:58,160 --> 00:47:01,319
uh syntactic disambiguation difficulty

1384
00:47:01,319 --> 00:47:02,280
right

1385
00:47:02,280 --> 00:47:03,900
um surprises will underpredicts the size

1386
00:47:03,900 --> 00:47:05,400
of the Garden Path effect across all

1387
00:47:05,400 --> 00:47:06,780
constructions and this gets to this

1388
00:47:06,780 --> 00:47:08,099
issue that you mentioned before you know

1389
00:47:08,099 --> 00:47:10,140
maybe surprised all this related uh to

1390
00:47:10,140 --> 00:47:11,520
some aspects of syntax but maybe not

1391
00:47:11,520 --> 00:47:12,960
other ones it's kind of a it's a very

1392
00:47:12,960 --> 00:47:14,819
non-tribute issue that is very much it's

1393
00:47:14,819 --> 00:47:16,800
open to to discussion it's not it hasn't

1394
00:47:16,800 --> 00:47:18,720
been settled yet but so Linton showed

1395
00:47:18,720 --> 00:47:20,640
that Garden Path effects are just way

1396
00:47:20,640 --> 00:47:21,720
more difficult than you would expect

1397
00:47:21,720 --> 00:47:24,359
from me unpredictability so another way

1398
00:47:24,359 --> 00:47:26,160
of phrasing this argument

1399
00:47:26,160 --> 00:47:29,160
um is the is the quote a recent argument

1400
00:47:29,160 --> 00:47:30,660
with chomsky's to get at this natural

1401
00:47:30,660 --> 00:47:32,940
basis unnatural issue he says suppose we

1402
00:47:32,940 --> 00:47:34,560
have an expanded periodic table that

1403
00:47:34,560 --> 00:47:36,180
includes all the elements that do exist

1404
00:47:36,180 --> 00:47:38,819
or the elements that can possibly exist

1405
00:47:38,819 --> 00:47:40,740
and all the elements that cannot

1406
00:47:40,740 --> 00:47:42,660
possibly exist and let's say you have

1407
00:47:42,660 --> 00:47:44,880
some model uh some artificial model that

1408
00:47:44,880 --> 00:47:46,560
fails to distinguish between these three

1409
00:47:46,560 --> 00:47:48,780
categories whatever this model is doing

1410
00:47:48,780 --> 00:47:50,640
it's not helping us understand chemistry

1411
00:47:50,640 --> 00:47:52,020
right it's doing something else it's

1412
00:47:52,020 --> 00:47:53,940
it's it's doing something for sure but

1413
00:47:53,940 --> 00:47:55,020
whether or not it's having to understand

1414
00:47:55,020 --> 00:47:57,180
chemistry is something separate and I

1415
00:47:57,180 --> 00:47:58,560
know that you've said in response to

1416
00:47:58,560 --> 00:47:59,579
some of these studies I think you've

1417
00:47:59,579 --> 00:48:02,400
said that you know and in order to show

1418
00:48:02,400 --> 00:48:03,540
that something is likely to be

1419
00:48:03,540 --> 00:48:04,920
impossible somewhere in your paper I

1420
00:48:04,920 --> 00:48:06,240
think you say

1421
00:48:06,240 --> 00:48:07,859
um in order to show that something is

1422
00:48:07,859 --> 00:48:09,720
impossible with normal balance of

1423
00:48:09,720 --> 00:48:12,300
Politics on false positives you need to

1424
00:48:12,300 --> 00:48:13,440
show you need to look at something like

1425
00:48:13,440 --> 00:48:15,780
500 independently sampled languages so

1426
00:48:15,780 --> 00:48:17,880
you cite this in the paper right

1427
00:48:17,880 --> 00:48:19,020
um which you probably can't do that's

1428
00:48:19,020 --> 00:48:20,579
just not it's not a feasible thing to do

1429
00:48:20,579 --> 00:48:23,880
and so you know I'm not I'm not too sure

1430
00:48:23,880 --> 00:48:25,800
that this really refutes the principal

1431
00:48:25,800 --> 00:48:27,119
argument that I'm making here right

1432
00:48:27,119 --> 00:48:29,040
because people like Michelin Bowers are

1433
00:48:29,040 --> 00:48:30,839
making an argument about impossibility

1434
00:48:30,839 --> 00:48:32,220
in principle not

1435
00:48:32,220 --> 00:48:33,599
um in some kind of extensional sense you

1436
00:48:33,599 --> 00:48:34,980
know just like searching across the

1437
00:48:34,980 --> 00:48:37,440
world languages to see to prove across

1438
00:48:37,440 --> 00:48:38,579
every single language that it is

1439
00:48:38,579 --> 00:48:40,260
impossible right that's kind of it's a

1440
00:48:40,260 --> 00:48:41,280
different argument whether it's

1441
00:48:41,280 --> 00:48:43,740
impossible in some random language in

1442
00:48:43,740 --> 00:48:45,180
the Amazon compared to actually

1443
00:48:45,180 --> 00:48:47,220
impossible based on the principles of

1444
00:48:47,220 --> 00:48:48,420
what the language system is actually

1445
00:48:48,420 --> 00:48:50,160
doing like what it can do so I would

1446
00:48:50,160 --> 00:48:53,339
just say that yeah I think that that

1447
00:48:53,339 --> 00:48:55,980
that point is is that you don't actually

1448
00:48:55,980 --> 00:48:58,560
know what is typologically not possible

1449
00:48:58,560 --> 00:49:00,480
right so some people like to say things

1450
00:49:00,480 --> 00:49:02,520
like you know there's no language that

1451
00:49:02,520 --> 00:49:04,859
does X therefore we have to build that

1452
00:49:04,859 --> 00:49:06,960
restriction into our our statistical

1453
00:49:06,960 --> 00:49:09,119
models right but if it's not

1454
00:49:09,119 --> 00:49:11,220
statistically Justified that there is no

1455
00:49:11,220 --> 00:49:13,079
language that does X right if you've

1456
00:49:13,079 --> 00:49:15,119
only looked at 20 or 20 European

1457
00:49:15,119 --> 00:49:16,920
languages or something right I I mean

1458
00:49:16,920 --> 00:49:19,020
it's it's not

1459
00:49:19,020 --> 00:49:22,380
um uh like that shouldn't motivate doing

1460
00:49:22,380 --> 00:49:24,599
anything to the models right

1461
00:49:24,599 --> 00:49:26,280
um uh if it's if it's not a

1462
00:49:26,280 --> 00:49:28,200
statistically Justified Universal I

1463
00:49:28,200 --> 00:49:28,980
think

1464
00:49:28,980 --> 00:49:30,180
um

1465
00:49:30,180 --> 00:49:32,760
well you know I I I think you know

1466
00:49:32,760 --> 00:49:33,960
you're totally right but that just

1467
00:49:33,960 --> 00:49:35,339
applies more generally to the social

1468
00:49:35,339 --> 00:49:36,960
sciences and psychological Sciences

1469
00:49:36,960 --> 00:49:39,180
right like typologically yeah it's very

1470
00:49:39,180 --> 00:49:40,380
difficult to establish these things

1471
00:49:40,380 --> 00:49:43,140
right so I guess you I guess you're just

1472
00:49:43,140 --> 00:49:44,640
kind of stale man you're a bit you're

1473
00:49:44,640 --> 00:49:47,339
saying that the strong claim is very

1474
00:49:47,339 --> 00:49:49,859
difficult to prove right

1475
00:49:49,859 --> 00:49:52,619
like there is no language that has X the

1476
00:49:52,619 --> 00:49:54,480
the strong claim that something is not

1477
00:49:54,480 --> 00:49:56,339
allowed in in natural language is I

1478
00:49:56,339 --> 00:49:58,800
think very very difficult to prove

1479
00:49:58,800 --> 00:49:59,880
um

1480
00:49:59,880 --> 00:50:01,980
um and you know I I think that there

1481
00:50:01,980 --> 00:50:05,460
have been uh lots of you know strong

1482
00:50:05,460 --> 00:50:08,460
attempts there's been lots of strong

1483
00:50:08,460 --> 00:50:10,380
claims from

1484
00:50:10,380 --> 00:50:12,720
um uh often from from generative syntax

1485
00:50:12,720 --> 00:50:16,800
right about what all languages do

1486
00:50:16,800 --> 00:50:19,140
um and I think that you know people have

1487
00:50:19,140 --> 00:50:21,119
been very good at at finding kind of

1488
00:50:21,119 --> 00:50:22,740
counter examples to to a lot of those

1489
00:50:22,740 --> 00:50:24,720
things I cite this this paper by Evans

1490
00:50:24,720 --> 00:50:26,579
and and Levinson

1491
00:50:26,579 --> 00:50:28,500
um which actually you know I I had heard

1492
00:50:28,500 --> 00:50:30,660
for years about how no language does X

1493
00:50:30,660 --> 00:50:32,160
and and that's what we're using to

1494
00:50:32,160 --> 00:50:33,599
construct our theories and that Evans

1495
00:50:33,599 --> 00:50:35,460
and Levin's paper Evans and Levinson

1496
00:50:35,460 --> 00:50:37,859
paper really uh kind of changed my mind

1497
00:50:37,859 --> 00:50:40,680
about this right that like language is

1498
00:50:40,680 --> 00:50:43,260
actually much more uh diverse than than

1499
00:50:43,260 --> 00:50:44,940
I think most

1500
00:50:44,940 --> 00:50:47,760
um most syntacticians will you know try

1501
00:50:47,760 --> 00:50:50,700
to construct theories for something so

1502
00:50:50,700 --> 00:50:53,579
um um you know I I I think we going back

1503
00:50:53,579 --> 00:50:54,839
to kind of the the beginning of what you

1504
00:50:54,839 --> 00:50:57,660
said I think we we'd agree that that uh

1505
00:50:57,660 --> 00:50:59,880
you need language architectures which

1506
00:50:59,880 --> 00:51:01,619
learn the things that kids learn and

1507
00:51:01,619 --> 00:51:03,660
learned it from data that they learn and

1508
00:51:03,660 --> 00:51:05,940
those architectures might might be

1509
00:51:05,940 --> 00:51:09,000
unlikely to be things like lstms or you

1510
00:51:09,000 --> 00:51:10,559
know simple recurrent networks or or

1511
00:51:10,559 --> 00:51:12,300
whatever right like

1512
00:51:12,300 --> 00:51:14,400
um I think all of that work is is very

1513
00:51:14,400 --> 00:51:16,680
useful in in kind of honing in on the

1514
00:51:16,680 --> 00:51:19,200
right architecture

1515
00:51:19,200 --> 00:51:20,460
um

1516
00:51:20,460 --> 00:51:21,420
um

1517
00:51:21,420 --> 00:51:23,819
uh so I'm just trying to to remember all

1518
00:51:23,819 --> 00:51:25,200
of all of the the points you were making

1519
00:51:25,200 --> 00:51:26,700
oh yeah so

1520
00:51:26,700 --> 00:51:29,160
um but I I think this that there there's

1521
00:51:29,160 --> 00:51:31,500
a a kind of Flip Side to to this which

1522
00:51:31,500 --> 00:51:32,760
is that

1523
00:51:32,760 --> 00:51:34,380
um I think that the space of things

1524
00:51:34,380 --> 00:51:37,619
people can learn is actually uh kind of

1525
00:51:37,619 --> 00:51:39,599
underestimated right like there's this

1526
00:51:39,599 --> 00:51:41,760
bias to to to say you know people can't

1527
00:51:41,760 --> 00:51:43,800
learn x y and z

1528
00:51:43,800 --> 00:51:46,020
um but people uh at least outside of

1529
00:51:46,020 --> 00:51:47,460
language have this this really

1530
00:51:47,460 --> 00:51:49,680
remarkable ability to learn different

1531
00:51:49,680 --> 00:51:51,240
kinds of patterns right like the

1532
00:51:51,240 --> 00:51:53,160
patterns you find in in music or

1533
00:51:53,160 --> 00:51:55,619
mathematics for example

1534
00:51:55,619 --> 00:51:57,839
um uh we can learn sophisticated types

1535
00:51:57,839 --> 00:52:00,240
of of algorithms right we can learn to

1536
00:52:00,240 --> 00:52:03,119
you know fly a space shuttle or to you

1537
00:52:03,119 --> 00:52:05,760
know tie knots in for rock climbing or

1538
00:52:05,760 --> 00:52:07,319
whatever right like there there's all

1539
00:52:07,319 --> 00:52:09,540
kinds of uh kind of procedural and

1540
00:52:09,540 --> 00:52:11,280
algorithmic knowledge which is

1541
00:52:11,280 --> 00:52:13,440
structural that that people are able to

1542
00:52:13,440 --> 00:52:16,680
acquire and I think that that that uh

1543
00:52:16,680 --> 00:52:19,680
notion uh very rightly kind of motivates

1544
00:52:19,680 --> 00:52:21,359
looking for learning systems which can

1545
00:52:21,359 --> 00:52:24,059
work over pretty unrestricted spaces

1546
00:52:24,059 --> 00:52:26,160
right so

1547
00:52:26,160 --> 00:52:28,859
um uh you know you you you might say

1548
00:52:28,859 --> 00:52:30,119
that okay well language is different

1549
00:52:30,119 --> 00:52:33,420
because language is a restricted space

1550
00:52:33,420 --> 00:52:35,040
um uh and it might be true that that

1551
00:52:35,040 --> 00:52:36,540
language is restricted but it also might

1552
00:52:36,540 --> 00:52:37,859
be true that the things we see in

1553
00:52:37,859 --> 00:52:39,960
language come from other sources right

1554
00:52:39,960 --> 00:52:42,180
it could be that uh language is

1555
00:52:42,180 --> 00:52:44,099
especially pragmatic for example

1556
00:52:44,099 --> 00:52:47,040
compared to uh music or mathematics

1557
00:52:47,040 --> 00:52:48,720
right and those kinds of pragmatic

1558
00:52:48,720 --> 00:52:50,040
constraints

1559
00:52:50,040 --> 00:52:51,480
um are the things that constrain the

1560
00:52:51,480 --> 00:52:53,400
form of language right or language is

1561
00:52:53,400 --> 00:52:54,660
communicative it's probably more

1562
00:52:54,660 --> 00:52:56,760
communicative than than music for

1563
00:52:56,760 --> 00:52:58,440
example and that might constrain the the

1564
00:52:58,440 --> 00:53:01,140
form of things so I mean as as you know

1565
00:53:01,140 --> 00:53:02,700
this is very old debate in in

1566
00:53:02,700 --> 00:53:05,520
linguistics about kind of where the uh

1567
00:53:05,520 --> 00:53:07,140
where the properties of of natural

1568
00:53:07,140 --> 00:53:09,059
language come from

1569
00:53:09,059 --> 00:53:11,160
um and uh I guess what I'm trying to say

1570
00:53:11,160 --> 00:53:12,660
is that there's one kind of perspective

1571
00:53:12,660 --> 00:53:15,119
where uh you look at all of the things

1572
00:53:15,119 --> 00:53:16,980
humans can do even outside of language

1573
00:53:16,980 --> 00:53:18,599
all of the rich structures and

1574
00:53:18,599 --> 00:53:20,819
algorithms and processes were able to

1575
00:53:20,819 --> 00:53:23,760
learn about about and internalize and

1576
00:53:23,760 --> 00:53:25,559
you say okay maybe language is like that

1577
00:53:25,559 --> 00:53:27,420
and then yes language also has some of

1578
00:53:27,420 --> 00:53:29,700
these other funny little properties

1579
00:53:29,700 --> 00:53:31,380
um but you know maybe those come from

1580
00:53:31,380 --> 00:53:34,020
some other other pieces of of where

1581
00:53:34,020 --> 00:53:36,720
language comes from right it's uh it's

1582
00:53:36,720 --> 00:53:38,400
you know we have pretty sophisticated

1583
00:53:38,400 --> 00:53:40,800
pragmatic reasoning

1584
00:53:40,800 --> 00:53:42,720
um uh we're using it to achieve certain

1585
00:53:42,720 --> 00:53:45,359
communicative ends you can find all

1586
00:53:45,359 --> 00:53:47,160
kinds of kind of communicative features

1587
00:53:47,160 --> 00:53:49,559
uh within the the language system itself

1588
00:53:49,559 --> 00:53:51,180
and so so maybe some of these other

1589
00:53:51,180 --> 00:53:53,819
properties are are properties that have

1590
00:53:53,819 --> 00:53:55,619
some other origin

1591
00:53:55,619 --> 00:53:57,059
um and that that view I think could be

1592
00:53:57,059 --> 00:53:59,579
wrong but it's it's one that

1593
00:53:59,579 --> 00:54:01,800
um I think needs to be looked at to see

1594
00:54:01,800 --> 00:54:04,200
if it's wrong right like I I think it's

1595
00:54:04,200 --> 00:54:05,400
been

1596
00:54:05,400 --> 00:54:10,020
um uh kind of dismissed um by uh large

1597
00:54:10,020 --> 00:54:12,900
chunks of of linguists right just you

1598
00:54:12,900 --> 00:54:14,579
know I've heard people say stuff like oh

1599
00:54:14,579 --> 00:54:15,720
well communication doesn't really

1600
00:54:15,720 --> 00:54:17,760
explain anything about language right

1601
00:54:17,760 --> 00:54:20,040
and what they mean often is it doesn't

1602
00:54:20,040 --> 00:54:22,200
explain like the particular Island

1603
00:54:22,200 --> 00:54:23,760
constraints or something that they're

1604
00:54:23,760 --> 00:54:25,319
that they're working on right but

1605
00:54:25,319 --> 00:54:26,700
there's all kinds of other things in

1606
00:54:26,700 --> 00:54:28,319
language that communicative pressures

1607
00:54:28,319 --> 00:54:30,359
probably do explain

1608
00:54:30,359 --> 00:54:31,500
um so

1609
00:54:31,500 --> 00:54:33,540
um I I guess my my pitch is always for

1610
00:54:33,540 --> 00:54:36,359
for kind of breadth in term breadth in

1611
00:54:36,359 --> 00:54:39,119
consideration of uh the forces that that

1612
00:54:39,119 --> 00:54:41,460
can shape language and not needing to

1613
00:54:41,460 --> 00:54:43,680
put it all into some form of of innate

1614
00:54:43,680 --> 00:54:45,359
constraints or something like that no

1615
00:54:45,359 --> 00:54:46,680
totally and I think I think a lot of

1616
00:54:46,680 --> 00:54:48,420
that stuff is is compatible with with

1617
00:54:48,420 --> 00:54:49,980
them illness program

1618
00:54:49,980 --> 00:54:51,960
because the middle of this program wants

1619
00:54:51,960 --> 00:54:53,339
syntax to be minimal it doesn't want it

1620
00:54:53,339 --> 00:54:54,660
to be complicated it doesn't want it to

1621
00:54:54,660 --> 00:54:56,220
be you know any more complicated it has

1622
00:54:56,220 --> 00:54:57,960
to be so there were some you mentioned

1623
00:54:57,960 --> 00:54:59,460
the the Curious properties right so

1624
00:54:59,460 --> 00:55:00,480
there are some of the properties that

1625
00:55:00,480 --> 00:55:02,579
need to be accounted for in any model of

1626
00:55:02,579 --> 00:55:04,200
language that uh I'll give you an

1627
00:55:04,200 --> 00:55:05,400
example right the setting of a person

1628
00:55:05,400 --> 00:55:06,599
features

1629
00:55:06,599 --> 00:55:08,880
and these person features exhibit very

1630
00:55:08,880 --> 00:55:10,440
non-trivial different generalizations

1631
00:55:10,440 --> 00:55:12,480
that do not seem to be accounted for Via

1632
00:55:12,480 --> 00:55:14,220
domain General learning mechanism so I'm

1633
00:55:14,220 --> 00:55:16,020
sitting here the work of Daniel Harper

1634
00:55:16,020 --> 00:55:17,700
at Queen Mary so for example the

1635
00:55:17,700 --> 00:55:19,740
morphological composition of person it's

1636
00:55:19,740 --> 00:55:21,720
interaction with number it's connection

1637
00:55:21,720 --> 00:55:24,059
to space uh properties of its semantics

1638
00:55:24,059 --> 00:55:26,040
and it's linearization they all appear

1639
00:55:26,040 --> 00:55:27,240
to be strong candidates for our

1640
00:55:27,240 --> 00:55:28,619
knowledge of language right what we mean

1641
00:55:28,619 --> 00:55:30,359
by knowledge of language but on the

1642
00:55:30,359 --> 00:55:32,280
other hand we have things like case and

1643
00:55:32,280 --> 00:55:34,319
agreement and head movement and these

1644
00:55:34,319 --> 00:55:36,420
are all structural phenomena however

1645
00:55:36,420 --> 00:55:39,319
they seem to resist a purely

1646
00:55:39,319 --> 00:55:42,420
meaning-based explanation uh in

1647
00:55:42,420 --> 00:55:44,339
theoretical Linguistics right it would

1648
00:55:44,339 --> 00:55:45,839
be great if syntax were nothing but a

1649
00:55:45,839 --> 00:55:47,520
computational engine that build

1650
00:55:47,520 --> 00:55:49,440
structured meaning and that's the

1651
00:55:49,440 --> 00:55:51,240
minimalist program the goal but that's

1652
00:55:51,240 --> 00:55:52,800
not what we actually find that's not in

1653
00:55:52,800 --> 00:55:54,720
any actual minimalist like concrete

1654
00:55:54,720 --> 00:55:57,240
model any concrete mineralist Theory the

1655
00:55:57,240 --> 00:55:59,040
goal is just like the program is

1656
00:55:59,040 --> 00:56:01,260
language is perfect okay that's the

1657
00:56:01,260 --> 00:56:03,119
program is that what we find no

1658
00:56:03,119 --> 00:56:05,160
obviously not okay no no linguist

1659
00:56:05,160 --> 00:56:07,680
actually believes that and so it would

1660
00:56:07,680 --> 00:56:09,900
be great if syntax was like that but I

1661
00:56:09,900 --> 00:56:11,280
think you know the program is to look

1662
00:56:11,280 --> 00:56:13,740
for Perfection but not always find it so

1663
00:56:13,740 --> 00:56:15,839
case an agreement and head movement are

1664
00:56:15,839 --> 00:56:17,640
morphological more for phonological

1665
00:56:17,640 --> 00:56:19,319
phenomenal the properties of the

1666
00:56:19,319 --> 00:56:20,700
performance systems what's called

1667
00:56:20,700 --> 00:56:22,440
performance systems and so the

1668
00:56:22,440 --> 00:56:23,760
minimalist program itself is really

1669
00:56:23,760 --> 00:56:24,839
compatible with a lot of what you're

1670
00:56:24,839 --> 00:56:26,880
saying about you know language language

1671
00:56:26,880 --> 00:56:28,500
there are aspects of language that can

1672
00:56:28,500 --> 00:56:31,200
be um perfected and optimized for

1673
00:56:31,200 --> 00:56:32,700
communicative efficiency absolutely

1674
00:56:32,700 --> 00:56:35,520
totally no doubt about it but where is

1675
00:56:35,520 --> 00:56:38,160
that locus of efficiency is it in the

1676
00:56:38,160 --> 00:56:39,960
syntax itself or is it some kind of

1677
00:56:39,960 --> 00:56:42,000
extra linguistic system is it in

1678
00:56:42,000 --> 00:56:43,680
pragmatics you know is it in sensory

1679
00:56:43,680 --> 00:56:45,540
motor is it in the speech

1680
00:56:45,540 --> 00:56:47,640
um probably the speech and phonology

1681
00:56:47,640 --> 00:56:50,400
probably you know I mean who knows but I

1682
00:56:50,400 --> 00:56:52,740
think a lot of these things demand much

1683
00:56:52,740 --> 00:56:56,059
more you know serious consideration into

1684
00:56:56,059 --> 00:56:57,839
old-fashioned Notions like structure

1685
00:56:57,839 --> 00:56:59,700
dependence compositional theme what have

1686
00:56:59,700 --> 00:57:01,140
you things like that which you can maybe

1687
00:57:01,140 --> 00:57:03,720
find somewhere in the literature but

1688
00:57:03,720 --> 00:57:06,720
um even just basic topics like you know

1689
00:57:06,720 --> 00:57:08,640
um quantifier raising extended

1690
00:57:08,640 --> 00:57:09,900
projections

1691
00:57:09,900 --> 00:57:12,059
um adverbial like adverbial hierarchies

1692
00:57:12,059 --> 00:57:13,920
all of these things in the minimalist

1693
00:57:13,920 --> 00:57:16,619
program can be extra linguistic right

1694
00:57:16,619 --> 00:57:18,180
they can actually be outside of syntax

1695
00:57:18,180 --> 00:57:20,579
and query very queer properties of the

1696
00:57:20,579 --> 00:57:23,099
semantic uh conceptual systems which are

1697
00:57:23,099 --> 00:57:24,559
in themselves kind of domain General

1698
00:57:24,559 --> 00:57:27,420
weird leftovers from ancient primary

1699
00:57:27,420 --> 00:57:29,220
cognition right the features of the way

1700
00:57:29,220 --> 00:57:31,260
we pass events the way we pass you know

1701
00:57:31,260 --> 00:57:32,520
agents and patients things like that

1702
00:57:32,520 --> 00:57:33,960
that's definitely not that's not human

1703
00:57:33,960 --> 00:57:35,520
specific

1704
00:57:35,520 --> 00:57:37,260
um but you know the way that syntax

1705
00:57:37,260 --> 00:57:39,059
provides instructions to these systems

1706
00:57:39,059 --> 00:57:42,480
you know properly seems to be so you

1707
00:57:42,480 --> 00:57:43,800
know generative linguists have different

1708
00:57:43,800 --> 00:57:45,839
theories of also language production too

1709
00:57:45,839 --> 00:57:47,040
I'll just talk about language production

1710
00:57:47,040 --> 00:57:49,380
based on whether we store lemmas or

1711
00:57:49,380 --> 00:57:51,240
whether we build words in the exact same

1712
00:57:51,240 --> 00:57:52,619
way we will phrase and sentences so I

1713
00:57:52,619 --> 00:57:53,819
know that you you make the distinction

1714
00:57:53,819 --> 00:57:55,440
between construction grammar and kind of

1715
00:57:55,440 --> 00:57:57,180
generative grammar and you know the the

1716
00:57:57,180 --> 00:57:58,680
weight they place on memorizing

1717
00:57:58,680 --> 00:58:00,119
constrictions whereas is just building

1718
00:58:00,119 --> 00:58:01,559
things from from the bottom up from the

1719
00:58:01,559 --> 00:58:04,440
ground up right and so you know in some

1720
00:58:04,440 --> 00:58:06,480
generative inspired models mechanisms

1721
00:58:06,480 --> 00:58:08,460
which generate syntactic structure make

1722
00:58:08,460 --> 00:58:10,200
no distinctions between processes that

1723
00:58:10,200 --> 00:58:12,200
apply above or below the word level

1724
00:58:12,200 --> 00:58:14,640
there's no pointer which meaning syntax

1725
00:58:14,640 --> 00:58:16,500
and form are all stored together a

1726
00:58:16,500 --> 00:58:18,660
single Atomic representations each stage

1727
00:58:18,660 --> 00:58:20,099
in lexical access is a transition

1728
00:58:20,099 --> 00:58:21,960
between different kinds of data

1729
00:58:21,960 --> 00:58:23,760
structures right there's meaning there's

1730
00:58:23,760 --> 00:58:25,740
form and there's syntax these three

1731
00:58:25,740 --> 00:58:27,480
features kind of co-mingle together and

1732
00:58:27,480 --> 00:58:28,920
they don't always overlap different

1733
00:58:28,920 --> 00:58:31,440
languages realize them in different ways

1734
00:58:31,440 --> 00:58:34,800
and so you know a weird the basic

1735
00:58:34,800 --> 00:58:36,839
definition of a word is just this weird

1736
00:58:36,839 --> 00:58:39,720
multi-system definition and where lots

1737
00:58:39,720 --> 00:58:41,040
of things lots of different cognitive

1738
00:58:41,040 --> 00:58:42,900
systems enrich the basis of every

1739
00:58:42,900 --> 00:58:44,940
electrical item right you have

1740
00:58:44,940 --> 00:58:46,680
um there's nothing like this really this

1741
00:58:46,680 --> 00:58:48,299
enrichment process

1742
00:58:48,299 --> 00:58:50,099
um anywhere else in in linguistic Theory

1743
00:58:50,099 --> 00:58:52,200
right or at least in what llms are doing

1744
00:58:52,200 --> 00:58:53,220
like

1745
00:58:53,220 --> 00:58:55,859
so I guess what what I guess I'll ask

1746
00:58:55,859 --> 00:58:58,799
you what is your definition of a word

1747
00:58:58,799 --> 00:59:01,559
right and what can llms really provide

1748
00:59:01,559 --> 00:59:03,780
insights into word Hood right because if

1749
00:59:03,780 --> 00:59:04,680
you kind of if you don't have a

1750
00:59:04,680 --> 00:59:06,720
destination of what a word is then

1751
00:59:06,720 --> 00:59:07,920
you're really in trouble right like we

1752
00:59:07,920 --> 00:59:10,319
have to at least use LMS or artificial

1753
00:59:10,319 --> 00:59:12,780
systems to inform what we mean by a word

1754
00:59:12,780 --> 00:59:14,400
or maybe we don't need that anymore I'm

1755
00:59:14,400 --> 00:59:16,859
not sure what do you think I I'm not I'm

1756
00:59:16,859 --> 00:59:18,599
not sure what you mean I mean

1757
00:59:18,599 --> 00:59:20,339
um

1758
00:59:20,339 --> 00:59:24,059
um I I don't have a what is a word why

1759
00:59:24,059 --> 00:59:25,740
does that matter I mean that that that's

1760
00:59:25,740 --> 00:59:27,359
just a convention about how we use the

1761
00:59:27,359 --> 00:59:29,819
term word right what like

1762
00:59:29,819 --> 00:59:31,920
I mean you could use you know lemmas or

1763
00:59:31,920 --> 00:59:34,440
word firms or or whatever like that that

1764
00:59:34,440 --> 00:59:35,819
just feels like a conventional Choice

1765
00:59:35,819 --> 00:59:38,040
I'm I'm not sure what's it what's at

1766
00:59:38,040 --> 00:59:39,180
stake there

1767
00:59:39,180 --> 00:59:41,880
so how would you I guess I I would say I

1768
00:59:41,880 --> 00:59:43,920
agree word is a conventionalization you

1769
00:59:43,920 --> 00:59:45,599
know icons aren't intuitive concept of

1770
00:59:45,599 --> 00:59:47,819
where it is often biased by orthography

1771
00:59:47,819 --> 00:59:50,760
the way we put spaces things right so so

1772
00:59:50,760 --> 00:59:52,559
that I I agree with that criticism you

1773
00:59:52,559 --> 00:59:54,240
know word in the intuitive sense is not

1774
00:59:54,240 --> 00:59:56,339
really a scientific construct however I

1775
00:59:56,339 --> 00:59:58,260
guess let me rephrase my question how

1776
00:59:58,260 --> 01:00:00,359
would you um you know decompose the

1777
01:00:00,359 --> 01:00:02,160
intuitive concept of word into something

1778
01:00:02,160 --> 01:00:03,660
that is more kind of you know

1779
01:00:03,660 --> 01:00:04,740
scientifically amenable or

1780
01:00:04,740 --> 01:00:06,540
psychologically plausible which is

1781
01:00:06,540 --> 01:00:08,280
exactly what geometric primary tries to

1782
01:00:08,280 --> 01:00:10,559
do by decomposing words into you know

1783
01:00:10,559 --> 01:00:12,599
distinctive features uh morphological

1784
01:00:12,599 --> 01:00:15,180
categories conceptual Roots being merged

1785
01:00:15,180 --> 01:00:17,579
with categorical features you know you

1786
01:00:17,579 --> 01:00:20,700
get a concept you know and you've made

1787
01:00:20,700 --> 01:00:22,440
it with a noun or a category to get a

1788
01:00:22,440 --> 01:00:24,119
noun or Affair these different models

1789
01:00:24,119 --> 01:00:26,220
make different predictions right yeah I

1790
01:00:26,220 --> 01:00:28,859
mean I I think that general idea is

1791
01:00:28,859 --> 01:00:30,839
likely to be right for large language

1792
01:00:30,839 --> 01:00:32,880
models like I think they kind of must

1793
01:00:32,880 --> 01:00:34,380
have things that are kind of like part

1794
01:00:34,380 --> 01:00:36,660
of speech categories for example

1795
01:00:36,660 --> 01:00:38,819
um and I think that they they kind of

1796
01:00:38,819 --> 01:00:42,900
must be able to uh update those their

1797
01:00:42,900 --> 01:00:45,240
categories based on the language that

1798
01:00:45,240 --> 01:00:48,119
they've seen so far right so like like

1799
01:00:48,119 --> 01:00:50,520
you know GPT puts nouns and verbs in the

1800
01:00:50,520 --> 01:00:53,400
right places and to to do that you kind

1801
01:00:53,400 --> 01:00:55,319
of need some representation of the nouns

1802
01:00:55,319 --> 01:00:57,000
versus the verbs and you need some

1803
01:00:57,000 --> 01:01:00,839
ability to uh uh locate yourself in a

1804
01:01:00,839 --> 01:01:02,579
string of other words and figure out if

1805
01:01:02,579 --> 01:01:04,680
there's likely to be a noun or or a verb

1806
01:01:04,680 --> 01:01:05,400
next

1807
01:01:05,400 --> 01:01:07,559
um so I I think that that on on that

1808
01:01:07,559 --> 01:01:09,319
level those kinds of properties of words

1809
01:01:09,319 --> 01:01:12,480
uh are very likely to to be right and

1810
01:01:12,480 --> 01:01:15,780
there there are also things which are uh

1811
01:01:15,780 --> 01:01:17,640
um very likely to be found kind of in

1812
01:01:17,640 --> 01:01:19,619
the internal representations of of these

1813
01:01:19,619 --> 01:01:21,420
models I don't see how it could be any

1814
01:01:21,420 --> 01:01:24,180
other way uh other than that

1815
01:01:24,180 --> 01:01:26,339
um but like as as far as I know that

1816
01:01:26,339 --> 01:01:29,579
that's not where the uh uh that's not

1817
01:01:29,579 --> 01:01:31,500
where the main debates or or

1818
01:01:31,500 --> 01:01:35,220
disagreement I think is right like

1819
01:01:35,220 --> 01:01:38,280
um uh yeah I think all theories of

1820
01:01:38,280 --> 01:01:40,079
language have to have to say that

1821
01:01:40,079 --> 01:01:41,400
there's different kinds of words that

1822
01:01:41,400 --> 01:01:43,140
can show up in different places or

1823
01:01:43,140 --> 01:01:44,339
something like that

1824
01:01:44,339 --> 01:01:45,240
um yeah

1825
01:01:45,240 --> 01:01:47,160
okay so how about the issue you know you

1826
01:01:47,160 --> 01:01:49,020
mentioned communication right

1827
01:01:49,020 --> 01:01:51,299
um so you know and you're totally right

1828
01:01:51,299 --> 01:01:53,099
when Trump see says things like language

1829
01:01:53,099 --> 01:01:54,960
is a thought system or you know language

1830
01:01:54,960 --> 01:01:57,780
didn't evolve he's kind of being a

1831
01:01:57,780 --> 01:01:58,799
little bit cheeky he doesn't really mean

1832
01:01:58,799 --> 01:02:00,180
that he kind of means in a very specific

1833
01:02:00,180 --> 01:02:01,619
sense right

1834
01:02:01,619 --> 01:02:03,540
um but you know when we say language is

1835
01:02:03,540 --> 01:02:05,640
a thought system what we mean is

1836
01:02:05,640 --> 01:02:06,780
um we're trying to get it an

1837
01:02:06,780 --> 01:02:08,339
architectural claim so if you look at

1838
01:02:08,339 --> 01:02:09,599
the architecture of the minimalist

1839
01:02:09,599 --> 01:02:10,380
program

1840
01:02:10,380 --> 01:02:12,240
the syntactic derivation and the

1841
01:02:12,240 --> 01:02:13,740
conceptual systems are literally

1842
01:02:13,740 --> 01:02:15,960
different systems right the conceptual

1843
01:02:15,960 --> 01:02:18,180
systems take stuff from syntax and then

1844
01:02:18,180 --> 01:02:19,799
to their own business with it and the CI

1845
01:02:19,799 --> 01:02:21,900
systems have their own peculiar rules

1846
01:02:21,900 --> 01:02:23,700
and and principles which is why I

1847
01:02:23,700 --> 01:02:25,319
thought in language are both similar

1848
01:02:25,319 --> 01:02:27,000
symbolic compositional systems but in

1849
01:02:27,000 --> 01:02:29,160
different ways only a subset of thought

1850
01:02:29,160 --> 01:02:32,339
is properly called the the CI interface

1851
01:02:32,339 --> 01:02:34,619
System since the CI systems are by

1852
01:02:34,619 --> 01:02:36,480
definition you know whatever conceptual

1853
01:02:36,480 --> 01:02:38,819
systems human have that can't access and

1854
01:02:38,819 --> 01:02:40,859
read out instructions from syntax and we

1855
01:02:40,859 --> 01:02:42,540
don't know what they are fully they seem

1856
01:02:42,540 --> 01:02:43,920
to have something to do with events in

1857
01:02:43,920 --> 01:02:45,540
grammatical reference and definiteness

1858
01:02:45,540 --> 01:02:47,099
they seem to be the main categories that

1859
01:02:47,099 --> 01:02:48,359
language you know cares about

1860
01:02:48,359 --> 01:02:49,440
conceptually

1861
01:02:49,440 --> 01:02:50,940
but we don't really know that's kind of

1862
01:02:50,940 --> 01:02:52,859
just a hypothesis right

1863
01:02:52,859 --> 01:02:53,940
um but what we do know is that they

1864
01:02:53,940 --> 01:02:56,220
don't seem to make use of color all that

1865
01:02:56,220 --> 01:02:58,440
much or um so no language

1866
01:02:58,440 --> 01:03:00,240
morphologically marks you know shades of

1867
01:03:00,240 --> 01:03:01,140
color

1868
01:03:01,140 --> 01:03:03,900
um or other conceptual features like um

1869
01:03:03,900 --> 01:03:06,359
um worry or concern like no language

1870
01:03:06,359 --> 01:03:07,980
morphologically marks a degree of worry

1871
01:03:07,980 --> 01:03:10,079
or concern about an issue but we do make

1872
01:03:10,079 --> 01:03:11,960
use of like um

1873
01:03:11,960 --> 01:03:13,500
epistemological Notions like

1874
01:03:13,500 --> 01:03:15,599
evidentiality and things like that so

1875
01:03:15,599 --> 01:03:17,640
you know one well I guess what I'm

1876
01:03:17,640 --> 01:03:19,500
saying is the minimalist program does a

1877
01:03:19,500 --> 01:03:21,720
good job of trying to figure out which

1878
01:03:21,720 --> 01:03:23,400
aspects of thought language is

1879
01:03:23,400 --> 01:03:25,619
intimately tied to and which aspects of

1880
01:03:25,619 --> 01:03:27,900
thought it's not tied to so the Midwest

1881
01:03:27,900 --> 01:03:29,280
program allows us to kind of carve that

1882
01:03:29,280 --> 01:03:31,680
up quite neatly and and this is a much

1883
01:03:31,680 --> 01:03:33,180
more nuanced framework than you know

1884
01:03:33,180 --> 01:03:34,559
when chomski says languages thought

1885
01:03:34,559 --> 01:03:36,960
again he doesn't maybe he means it maybe

1886
01:03:36,960 --> 01:03:38,339
he doesn't but that's not what the

1887
01:03:38,339 --> 01:03:40,319
actual architecture of his theory says

1888
01:03:40,319 --> 01:03:42,480
it's a rhetorical device that is very

1889
01:03:42,480 --> 01:03:43,920
you know useful and interesting to

1890
01:03:43,920 --> 01:03:46,559
attract undergraduate audiences whatever

1891
01:03:46,559 --> 01:03:48,839
if you look at actual theories that are

1892
01:03:48,839 --> 01:03:50,700
coming out of The Mentalist program no

1893
01:03:50,700 --> 01:03:52,380
one really believes language equals

1894
01:03:52,380 --> 01:03:53,760
thought right the language system seems

1895
01:03:53,760 --> 01:03:55,920
to it tries its best to access and

1896
01:03:55,920 --> 01:03:57,599
reformat and manipulate various

1897
01:03:57,599 --> 01:03:59,220
conceptual systems but it has its limits

1898
01:03:59,220 --> 01:04:01,440
right we know what systems spell Keys

1899
01:04:01,440 --> 01:04:02,819
core knowledge systems are hooked up to

1900
01:04:02,819 --> 01:04:05,160
with respect to the syntax engine and

1901
01:04:05,160 --> 01:04:07,260
which ones are not

1902
01:04:07,260 --> 01:04:09,480
um so you know this kind of gets back to

1903
01:04:09,480 --> 01:04:11,579
the idea that lexisation of a concept

1904
01:04:11,579 --> 01:04:14,099
seems to maybe alter it in some way it

1905
01:04:14,099 --> 01:04:16,200
kind of imbues it with elements that are

1906
01:04:16,200 --> 01:04:17,819
not there in the concept itself so if

1907
01:04:17,819 --> 01:04:19,319
you lecture is a concept you suddenly

1908
01:04:19,319 --> 01:04:21,240
transform it a little bit you give it a

1909
01:04:21,240 --> 01:04:22,680
little extra you sprinkle something else

1910
01:04:22,680 --> 01:04:24,299
on top of it and that seems to vary

1911
01:04:24,299 --> 01:04:26,700
across different nanotypes and but these

1912
01:04:26,700 --> 01:04:29,160
are all like very clear architectural

1913
01:04:29,160 --> 01:04:31,619
claims within geometric grammar that

1914
01:04:31,619 --> 01:04:34,980
make very clear empirical predictions so

1915
01:04:34,980 --> 01:04:36,420
in other words I guess what I'm saying

1916
01:04:36,420 --> 01:04:37,140
is

1917
01:04:37,140 --> 01:04:38,940
all these neuropsychology studies that

1918
01:04:38,940 --> 01:04:42,119
are up incited you know in a lot of work

1919
01:04:42,119 --> 01:04:43,980
um in this vein what does it really show

1920
01:04:43,980 --> 01:04:45,420
I think it shows that you know when

1921
01:04:45,420 --> 01:04:47,819
language is damaged in the brain it

1922
01:04:47,819 --> 01:04:50,040
loses this particular sway or mode of

1923
01:04:50,040 --> 01:04:51,960
influencing those systems but there's no

1924
01:04:51,960 --> 01:04:54,299
real prediction from within the Gen gram

1925
01:04:54,299 --> 01:04:56,040
Enterprise but those non-linguistic

1926
01:04:56,040 --> 01:04:57,540
systems should be impaired or should

1927
01:04:57,540 --> 01:04:59,579
suddenly you know shut down if the core

1928
01:04:59,579 --> 01:05:01,200
language system

1929
01:05:01,200 --> 01:05:02,760
um is compromised right in fact if

1930
01:05:02,760 --> 01:05:05,099
anything that just emphasizes the

1931
01:05:05,099 --> 01:05:07,859
principal divorce between the syntactic

1932
01:05:07,859 --> 01:05:09,900
system and non-linguistic systems right

1933
01:05:09,900 --> 01:05:11,880
so I think the a lot of predictions here

1934
01:05:11,880 --> 01:05:14,339
from the language and communication uh

1935
01:05:14,339 --> 01:05:16,020
you know literature are kind of missing

1936
01:05:16,020 --> 01:05:19,380
the point of the architectural claims

1937
01:05:19,380 --> 01:05:21,540
um I I can just give or Daniel do you

1938
01:05:21,540 --> 01:05:24,180
want to go uh give a little bit of a

1939
01:05:24,180 --> 01:05:25,799
background there so so there's these

1940
01:05:25,799 --> 01:05:26,760
papers

1941
01:05:26,760 --> 01:05:30,119
um uh from uh uh EV federenko and and

1942
01:05:30,119 --> 01:05:32,880
rosemary Varley that that are

1943
01:05:32,880 --> 01:05:34,500
um examining

1944
01:05:34,500 --> 01:05:37,799
um uh uh in part of them aphasic patient

1945
01:05:37,799 --> 01:05:40,200
so so people who have impaired uh

1946
01:05:40,200 --> 01:05:41,880
linguistic abilities

1947
01:05:41,880 --> 01:05:43,140
um

1948
01:05:43,140 --> 01:05:45,000
um basically showing that with impaired

1949
01:05:45,000 --> 01:05:46,980
linguistic abilities you you

1950
01:05:46,980 --> 01:05:49,020
um Can can still have

1951
01:05:49,020 --> 01:05:50,579
um uh preserved kind of reasoning

1952
01:05:50,579 --> 01:05:52,859
abilities so people like Chess Masters

1953
01:05:52,859 --> 01:05:55,020
chess Grand Masters for example who are

1954
01:05:55,020 --> 01:05:58,140
obviously very good at at reasoning

1955
01:05:58,140 --> 01:06:00,780
um uh um might not have uh kind of

1956
01:06:00,780 --> 01:06:02,640
intact linguistic abilities

1957
01:06:02,640 --> 01:06:04,079
um and then complementing that that kind

1958
01:06:04,079 --> 01:06:06,119
of patient work there's also uh work

1959
01:06:06,119 --> 01:06:08,520
from ebb's Lab showing that

1960
01:06:08,520 --> 01:06:11,220
um uh the uh parts of the brain that

1961
01:06:11,220 --> 01:06:13,859
that care about uh language

1962
01:06:13,859 --> 01:06:14,640
um

1963
01:06:14,640 --> 01:06:16,319
um are separable from the parts of the

1964
01:06:16,319 --> 01:06:17,700
brain that care about other other

1965
01:06:17,700 --> 01:06:19,619
domains even ones with same kind of

1966
01:06:19,619 --> 01:06:21,599
language-like so things like like music

1967
01:06:21,599 --> 01:06:23,819
and and Mathematics

1968
01:06:23,819 --> 01:06:25,859
um uh tend not to happen in the in the

1969
01:06:25,859 --> 01:06:27,240
language areas

1970
01:06:27,240 --> 01:06:29,400
um so EV and others have have argued

1971
01:06:29,400 --> 01:06:30,539
that

1972
01:06:30,539 --> 01:06:33,539
um this is uh basically evidence against

1973
01:06:33,539 --> 01:06:36,660
the Chomsky and claim that uh that

1974
01:06:36,660 --> 01:06:38,579
language is the medium for thinking

1975
01:06:38,579 --> 01:06:40,440
right because there's thinking that can

1976
01:06:40,440 --> 01:06:42,420
happen in the absence of language and

1977
01:06:42,420 --> 01:06:44,160
brain areas that care about language

1978
01:06:44,160 --> 01:06:46,020
seem not to be the brain areas that they

1979
01:06:46,020 --> 01:06:48,359
care about care about thinking

1980
01:06:48,359 --> 01:06:50,099
um I I guess Elliot you're you're saying

1981
01:06:50,099 --> 01:06:51,780
that people don't don't really believe

1982
01:06:51,780 --> 01:06:53,039
that

1983
01:06:53,039 --> 01:06:56,220
um uh they don't believe that that

1984
01:06:56,220 --> 01:06:57,720
distinction I mean

1985
01:06:57,720 --> 01:06:59,880
um that uh

1986
01:06:59,880 --> 01:07:01,740
no it's it and also there's a lot of

1987
01:07:01,740 --> 01:07:03,480
like self-contradiction even Within

1988
01:07:03,480 --> 01:07:04,799
These arguments right so so in your

1989
01:07:04,799 --> 01:07:06,839
paper you sometimes say that Chomsky

1990
01:07:06,839 --> 01:07:08,220
thinks that language is a thought system

1991
01:07:08,220 --> 01:07:10,319
but then a few pages later you'll say

1992
01:07:10,319 --> 01:07:12,480
Chomsky also believes that syntax is

1993
01:07:12,480 --> 01:07:13,799
some totally separate system from

1994
01:07:13,799 --> 01:07:15,480
anything else right you autonomy of

1995
01:07:15,480 --> 01:07:18,900
syntax Etc so which is Chomsky thing

1996
01:07:18,900 --> 01:07:20,460
that's not my contradiction I mean he

1997
01:07:20,460 --> 01:07:22,140
said both of those things

1998
01:07:22,140 --> 01:07:24,780
um right exactly so so therefore you may

1999
01:07:24,780 --> 01:07:26,280
want to ask yourself does he really

2000
01:07:26,280 --> 01:07:28,319
believe these things or what is the

2001
01:07:28,319 --> 01:07:30,420
physical arises from from the from the

2002
01:07:30,420 --> 01:07:32,520
architecture right so just saying just

2003
01:07:32,520 --> 01:07:34,619
saying language is a thought system what

2004
01:07:34,619 --> 01:07:35,579
does that mean that doesn't mean

2005
01:07:35,579 --> 01:07:36,780
anything it's just a very vague

2006
01:07:36,780 --> 01:07:38,640
statement the question is how exactly is

2007
01:07:38,640 --> 01:07:41,280
language contributing to Thor and how is

2008
01:07:41,280 --> 01:07:43,500
it not contributing

2009
01:07:43,500 --> 01:07:45,839
uh yeah I mean I think his claim is is

2010
01:07:45,839 --> 01:07:48,420
mainly evolutionary or something right

2011
01:07:48,420 --> 01:07:51,180
that uh this is the the origins of of

2012
01:07:51,180 --> 01:07:52,859
the system which I think is is sort of

2013
01:07:52,859 --> 01:07:55,559
equally hard to square with

2014
01:07:55,559 --> 01:07:57,599
um uh the kind of patient and and

2015
01:07:57,599 --> 01:07:59,520
neuroimaging data

2016
01:07:59,520 --> 01:08:00,660
um

2017
01:08:00,660 --> 01:08:04,079
um but you know if if he doesn't think

2018
01:08:04,079 --> 01:08:07,079
that then he shouldn't say it or people

2019
01:08:07,079 --> 01:08:08,579
will respond to what he said I think

2020
01:08:08,579 --> 01:08:11,280
well no no because the argument is that

2021
01:08:11,280 --> 01:08:13,619
language is a kind of thought system it

2022
01:08:13,619 --> 01:08:15,420
regulates some aspects of though and it

2023
01:08:15,420 --> 01:08:16,920
and it yields some aspects of thought

2024
01:08:16,920 --> 01:08:19,020
that are clearly unique to humans but

2025
01:08:19,020 --> 01:08:21,000
it's not intrinsically or causally tied

2026
01:08:21,000 --> 01:08:22,920
to it right the the architecture of the

2027
01:08:22,920 --> 01:08:24,600
system is very different from the kind

2028
01:08:24,600 --> 01:08:26,399
of generalizations you can rhetorically

2029
01:08:26,399 --> 01:08:28,979
events from the architecture so for

2030
01:08:28,979 --> 01:08:30,960
instance when you site work from aphasic

2031
01:08:30,960 --> 01:08:32,698
patients showing no deficits in complex

2032
01:08:32,698 --> 01:08:33,960
reasoning as you just mentioned playing

2033
01:08:33,960 --> 01:08:35,759
chess and so on we would actually expect

2034
01:08:35,759 --> 01:08:37,380
this under a kind of you know

2035
01:08:37,380 --> 01:08:39,179
non-lexicalist framework of geometry

2036
01:08:39,179 --> 01:08:41,160
syntax where meaning as I said meaning

2037
01:08:41,160 --> 01:08:43,799
syntax and form form just meaning

2038
01:08:43,799 --> 01:08:45,600
anything that you can externalize

2039
01:08:45,600 --> 01:08:46,979
language and all these things are

2040
01:08:46,979 --> 01:08:48,540
separate features and separate systems

2041
01:08:48,540 --> 01:08:51,000
right the autonomy of syntax doesn't

2042
01:08:51,000 --> 01:08:52,020
mean

2043
01:08:52,020 --> 01:08:53,819
you know what a lot of people think it

2044
01:08:53,819 --> 01:08:54,719
means it just means either a certain

2045
01:08:54,719 --> 01:08:56,160
there are certain syntactic operations

2046
01:08:56,160 --> 01:08:58,439
that are not semantic there are certain

2047
01:08:58,439 --> 01:09:00,299
things you can do with syntax that you

2048
01:09:00,299 --> 01:09:01,920
can only do syntax and you can't do

2049
01:09:01,920 --> 01:09:03,420
semantics so this gets back to the

2050
01:09:03,420 --> 01:09:05,279
difference between you know uh

2051
01:09:05,279 --> 01:09:07,259
petrovsky's theory that semantics is

2052
01:09:07,259 --> 01:09:10,319
just and right versus the uh allows

2053
01:09:10,319 --> 01:09:11,698
synthetician's belief that there are

2054
01:09:11,698 --> 01:09:13,080
certain peculiar weird things you can do

2055
01:09:13,080 --> 01:09:15,719
with syntax that are just syntactic so

2056
01:09:15,719 --> 01:09:17,759
there is a divorce even within the kind

2057
01:09:17,759 --> 01:09:20,100
of architectural framework and so it's

2058
01:09:20,100 --> 01:09:22,439
not too surprising that you also find

2059
01:09:22,439 --> 01:09:24,359
that divorce at the neuropsychological

2060
01:09:24,359 --> 01:09:25,979
level I would say

2061
01:09:25,979 --> 01:09:28,319
well that I I think I I would I would

2062
01:09:28,319 --> 01:09:30,960
want a prediction of the language is

2063
01:09:30,960 --> 01:09:34,140
thought evolutionary idea then right so

2064
01:09:34,140 --> 01:09:36,960
like uh if that's not if you're saying

2065
01:09:36,960 --> 01:09:39,060
that that doesn't predict that thought

2066
01:09:39,060 --> 01:09:41,160
is relies on language

2067
01:09:41,160 --> 01:09:44,399
um then then uh I think Whoever likes

2068
01:09:44,399 --> 01:09:45,899
that theory should should come up with

2069
01:09:45,899 --> 01:09:47,520
some predictions

2070
01:09:47,520 --> 01:09:49,979
um about uh you know what that what that

2071
01:09:49,979 --> 01:09:51,660
theory actually means I mean I feel like

2072
01:09:51,660 --> 01:09:53,819
those kinds of predictions are are often

2073
01:09:53,819 --> 01:09:55,440
really necessary for understanding the

2074
01:09:55,440 --> 01:09:57,360
the content of a prediction

2075
01:09:57,360 --> 01:09:58,320
um

2076
01:09:58,320 --> 01:10:00,540
um so sorry Daniel your your hand's been

2077
01:10:00,540 --> 01:10:03,660
been up for a while uh no it's all good

2078
01:10:03,660 --> 01:10:05,880
just kind of wanted to

2079
01:10:05,880 --> 01:10:08,040
bring a

2080
01:10:08,040 --> 01:10:12,660
um breath in and um an opportunity for

2081
01:10:12,660 --> 01:10:15,480
anyone to uh ask any other

2082
01:10:15,480 --> 01:10:17,520
questions but wow

2083
01:10:17,520 --> 01:10:20,460
thank you both for the many topics we've

2084
01:10:20,460 --> 01:10:21,780
covered

2085
01:10:21,780 --> 01:10:22,500
um

2086
01:10:22,500 --> 01:10:25,199
we'll have in the last minutes uh kind

2087
01:10:25,199 --> 01:10:27,120
of conclusion and next steps but Dave

2088
01:10:27,120 --> 01:10:29,820
would you like to ask a question or just

2089
01:10:29,820 --> 01:10:32,840
give a short reflection

2090
01:10:36,900 --> 01:10:38,880
okay no

2091
01:10:38,880 --> 01:10:39,960
um

2092
01:10:39,960 --> 01:10:42,239
there are many comments in the chat so I

2093
01:10:42,239 --> 01:10:45,120
hope that both of you can read them on

2094
01:10:45,120 --> 01:10:47,460
your own time to to see what everyone

2095
01:10:47,460 --> 01:10:49,440
added

2096
01:10:49,440 --> 01:10:52,860
where do we go from here as we

2097
01:10:52,860 --> 01:10:57,179
Roar into May 2023 and Beyond

2098
01:10:57,179 --> 01:11:00,960
what can linguists large language model

2099
01:11:00,960 --> 01:11:02,940
developers and users cognitive

2100
01:11:02,940 --> 01:11:05,159
scientists what do you each think are

2101
01:11:05,159 --> 01:11:06,960
some of the most fruitful Pathways

2102
01:11:06,960 --> 01:11:08,159
forward

2103
01:11:08,159 --> 01:11:10,080
okay

2104
01:11:10,080 --> 01:11:13,260
I would say um you know uh the most

2105
01:11:13,260 --> 01:11:14,699
fruitful pathway forward is to really

2106
01:11:14,699 --> 01:11:15,600
take

2107
01:11:15,600 --> 01:11:17,460
um like cognitive psychology no

2108
01:11:17,460 --> 01:11:18,659
seriously there's a lot of nice work

2109
01:11:18,659 --> 01:11:21,000
recently trying to align things like

2110
01:11:21,000 --> 01:11:24,060
yeah you know Church EBT wolf from alpha

2111
01:11:24,060 --> 01:11:25,739
plugins the way that chat gbt can

2112
01:11:25,739 --> 01:11:28,080
interface with different kind of modules

2113
01:11:28,080 --> 01:11:30,179
um the way of building a legitimate kind

2114
01:11:30,179 --> 01:11:32,580
of AGI system it doesn't necessarily

2115
01:11:32,580 --> 01:11:34,380
have to you know be psychologically

2116
01:11:34,380 --> 01:11:35,880
reliant on the kind of modules that

2117
01:11:35,880 --> 01:11:37,500
human beings have but I think it will

2118
01:11:37,500 --> 01:11:38,820
benefit from it so there have been some

2119
01:11:38,820 --> 01:11:41,040
some claims that large language models

2120
01:11:41,040 --> 01:11:42,540
can maybe do you know all sorts of

2121
01:11:42,540 --> 01:11:43,860
things right everything everything you

2122
01:11:43,860 --> 01:11:44,760
like

2123
01:11:44,760 --> 01:11:46,620
um but I think in the long run it's most

2124
01:11:46,620 --> 01:11:47,880
likely going to be the case that llms

2125
01:11:47,880 --> 01:11:49,380
can do something very important and very

2126
01:11:49,380 --> 01:11:51,000
interesting but it's only going to be

2127
01:11:51,000 --> 01:11:53,100
one piece of the puzzle so in fact even

2128
01:11:53,100 --> 01:11:55,440
open AI CEO Sam Altman said last week

2129
01:11:55,440 --> 01:11:56,400
that

2130
01:11:56,400 --> 01:11:58,440
um you know what we can do with llms has

2131
01:11:58,440 --> 01:12:00,120
really kind of been exhausted we need

2132
01:12:00,120 --> 01:12:02,520
new directions new new new avenues and

2133
01:12:02,520 --> 01:12:04,860
so on I guess it was probably you know

2134
01:12:04,860 --> 01:12:07,440
speaking to investors more than uh you

2135
01:12:07,440 --> 01:12:09,060
know linguistic students here but I

2136
01:12:09,060 --> 01:12:11,159
think he's also right you know llms can

2137
01:12:11,159 --> 01:12:12,300
do something spectacular but they're

2138
01:12:12,300 --> 01:12:14,760
probably going to form a small part of

2139
01:12:14,760 --> 01:12:17,760
the general AGI architecture right and

2140
01:12:17,760 --> 01:12:19,679
if you want to think about AGI as a

2141
01:12:19,679 --> 01:12:21,900
potential potential goal here

2142
01:12:21,900 --> 01:12:25,679
um so you know I think a lot of the so

2143
01:12:25,679 --> 01:12:28,020
let me give me another example here so

2144
01:12:28,020 --> 01:12:29,820
um Anna even over

2145
01:12:29,820 --> 01:12:31,920
um who's a a very good productive

2146
01:12:31,920 --> 01:12:34,140
scientist she has a paper recently

2147
01:12:34,140 --> 01:12:35,400
um arguing for a kind of modular

2148
01:12:35,400 --> 01:12:37,800
architecture for llms and which is a

2149
01:12:37,800 --> 01:12:39,060
very nice framework right it's very

2150
01:12:39,060 --> 01:12:40,860
cognitively plausible it's exactly the

2151
01:12:40,860 --> 01:12:41,880
kind of thing that we should be pushing

2152
01:12:41,880 --> 01:12:43,679
for it's compatible with Howard

2153
01:12:43,679 --> 01:12:45,239
Gardner's you know notion of multiple

2154
01:12:45,239 --> 01:12:46,800
intelligences and so on

2155
01:12:46,800 --> 01:12:48,000
um but I think at the same time just

2156
01:12:48,000 --> 01:12:49,620
just to finish this comment

2157
01:12:49,620 --> 01:12:51,360
um there was a tech talk last week I

2158
01:12:51,360 --> 01:12:54,840
think or maybe a few days ago where um a

2159
01:12:54,840 --> 01:12:56,880
lot of other stuff can be conflated with

2160
01:12:56,880 --> 01:12:59,520
AI hype in unproductive ways so Greg

2161
01:12:59,520 --> 01:13:02,100
Brockman from openai he gave one of his

2162
01:13:02,100 --> 01:13:04,199
uh one of these big Ted Talks where he

2163
01:13:04,199 --> 01:13:06,179
showed different plugins that chat GPD

2164
01:13:06,179 --> 01:13:08,159
can do I mentioned Wolfram operate but

2165
01:13:08,159 --> 01:13:09,300
there's also things like image

2166
01:13:09,300 --> 01:13:11,820
generation instacart shopping where you

2167
01:13:11,820 --> 01:13:13,560
can get chat TV to buy you things and

2168
01:13:13,560 --> 01:13:15,060
what have you

2169
01:13:15,060 --> 01:13:17,040
um and again this this takes you back to

2170
01:13:17,040 --> 01:13:18,960
the idea that multiple subsystems can do

2171
01:13:18,960 --> 01:13:20,940
different sub functions so Brockovich

2172
01:13:20,940 --> 01:13:22,620
also showed an example of giving chat

2173
01:13:22,620 --> 01:13:26,820
GPT an Excel file a CSV file and from an

2174
01:13:26,820 --> 01:13:28,739
archive database of academic papers

2175
01:13:28,739 --> 01:13:30,060
where it just listed a bunch of papers

2176
01:13:30,060 --> 01:13:31,739
and and then titles and what have you

2177
01:13:31,739 --> 01:13:32,880
right

2178
01:13:32,880 --> 01:13:34,500
um and he said that you know using

2179
01:13:34,500 --> 01:13:37,440
chatipati it uses World Knowledge to

2180
01:13:37,440 --> 01:13:39,060
infer what the titles of the columns

2181
01:13:39,060 --> 01:13:40,860
mean so we understood that you know

2182
01:13:40,860 --> 01:13:42,780
title means the title of the paper it

2183
01:13:42,780 --> 01:13:44,640
understood that authors mean the number

2184
01:13:44,640 --> 01:13:47,280
of authors per paper it understood that

2185
01:13:47,280 --> 01:13:48,840
created means the date that paper

2186
01:13:48,840 --> 01:13:50,820
submitted right and because it's a TED

2187
01:13:50,820 --> 01:13:52,080
talk you know the whole the audience

2188
01:13:52,080 --> 01:13:54,120
gave us a standing ovation right

2189
01:13:54,120 --> 01:13:56,340
um but the ability to describe labels on

2190
01:13:56,340 --> 01:13:57,900
an Excel file

2191
01:13:57,900 --> 01:14:01,679
is I guess nice but um I'm not sure

2192
01:14:01,679 --> 01:14:03,120
you'd really call it World Knowledge so

2193
01:14:03,120 --> 01:14:04,800
I guess there's a lot I would just say

2194
01:14:04,800 --> 01:14:06,719
there's a lot of progress needs to be

2195
01:14:06,719 --> 01:14:08,880
made alongside reducing anthropomosome

2196
01:14:08,880 --> 01:14:11,640
and you have the right balance of it so

2197
01:14:11,640 --> 01:14:12,659
like I said you have to have the right

2198
01:14:12,659 --> 01:14:13,920
balance of

2199
01:14:13,920 --> 01:14:15,360
um psychologically plausible kind of

2200
01:14:15,360 --> 01:14:17,100
modular architecture but you can't have

2201
01:14:17,100 --> 01:14:18,480
too much

2202
01:14:18,480 --> 01:14:19,920
um anthropomorphism because then you'll

2203
01:14:19,920 --> 01:14:21,540
get carried away you have to find we

2204
01:14:21,540 --> 01:14:22,860
have to find the right balance between

2205
01:14:22,860 --> 01:14:25,739
modeling kind of human-like uh modular

2206
01:14:25,739 --> 01:14:27,780
systems but not doing it to a degree

2207
01:14:27,780 --> 01:14:29,280
that is a bit you know

2208
01:14:29,280 --> 01:14:31,140
um implausible or scientifically

2209
01:14:31,140 --> 01:14:33,679
unhelpful

2210
01:14:35,040 --> 01:14:37,500
I mean I think I I agree with all that

2211
01:14:37,500 --> 01:14:40,199
I'm really excited about these uh ways

2212
01:14:40,199 --> 01:14:42,739
of kind of connecting language models to

2213
01:14:42,739 --> 01:14:45,120
uh other forms of of information

2214
01:14:45,120 --> 01:14:47,640
processing uh which does seem like what

2215
01:14:47,640 --> 01:14:49,679
what people have I think I've I mean

2216
01:14:49,679 --> 01:14:52,620
I've been like very surprised at the uh

2217
01:14:52,620 --> 01:14:54,840
the things they are able to do

2218
01:14:54,840 --> 01:14:58,260
um just as as language modeling right so

2219
01:14:58,260 --> 01:15:00,120
um you know different kinds of reasoning

2220
01:15:00,120 --> 01:15:01,920
puzzles and things that they can solve I

2221
01:15:01,920 --> 01:15:05,340
I think is is uh really fascinating and

2222
01:15:05,340 --> 01:15:07,920
and you know maybe will require us to to

2223
01:15:07,920 --> 01:15:09,719
rethink our you know the the

2224
01:15:09,719 --> 01:15:11,760
relationships between language and

2225
01:15:11,760 --> 01:15:13,500
thought and and try to figure out a way

2226
01:15:13,500 --> 01:15:15,239
of being specific about what it means

2227
01:15:15,239 --> 01:15:17,760
for something to uh have a

2228
01:15:17,760 --> 01:15:19,380
representation or to reason over that

2229
01:15:19,380 --> 01:15:21,060
that representation But ultimately I

2230
01:15:21,060 --> 01:15:23,820
think I I agree that um

2231
01:15:23,820 --> 01:15:26,219
um you know people have different modes

2232
01:15:26,219 --> 01:15:28,560
of thinking about things and that that

2233
01:15:28,560 --> 01:15:32,400
seems important for uh for intelligence

2234
01:15:32,400 --> 01:15:35,040
um I'm also super excited about the baby

2235
01:15:35,040 --> 01:15:37,620
LM challenge so I think on the kind of

2236
01:15:37,620 --> 01:15:39,960
linguistic side right

2237
01:15:39,960 --> 01:15:42,300
um uh that's exactly the the right thing

2238
01:15:42,300 --> 01:15:45,300
of of seeing how far we can get with uh

2239
01:15:45,300 --> 01:15:47,219
smaller data sets um and maybe

2240
01:15:47,219 --> 01:15:50,820
eventually after that you know trying to

2241
01:15:50,820 --> 01:15:53,699
um uh understand some some more about

2242
01:15:53,699 --> 01:15:55,739
the kinds of semantics that that kids

2243
01:15:55,739 --> 01:15:57,840
acquire and and where they get it from

2244
01:15:57,840 --> 01:15:59,820
and and how kind of external semantics

2245
01:15:59,820 --> 01:16:02,520
can inform uh language learning or

2246
01:16:02,520 --> 01:16:04,560
specifically maybe maybe grammar and and

2247
01:16:04,560 --> 01:16:06,600
syntax learning

2248
01:16:06,600 --> 01:16:09,480
um I guess my my other uh path forward

2249
01:16:09,480 --> 01:16:12,179
point would would be

2250
01:16:12,179 --> 01:16:15,840
um that there's uh like I I feel like

2251
01:16:15,840 --> 01:16:18,300
these kinds of models have have

2252
01:16:18,300 --> 01:16:21,179
um uh really gone far beyond people's

2253
01:16:21,179 --> 01:16:23,340
expectations for this kind of class of

2254
01:16:23,340 --> 01:16:25,500
of model right kind of ground up

2255
01:16:25,500 --> 01:16:27,960
statistical learning discovering

2256
01:16:27,960 --> 01:16:29,940
patterns in in text

2257
01:16:29,940 --> 01:16:30,719
um

2258
01:16:30,719 --> 01:16:32,640
um seems Seems to give like really

2259
01:16:32,640 --> 01:16:35,040
pretty remarkable results

2260
01:16:35,040 --> 01:16:37,020
um and that for me going forward I I

2261
01:16:37,020 --> 01:16:39,360
think has just introduced a huge wave of

2262
01:16:39,360 --> 01:16:42,000
uncertainty over theories so I think

2263
01:16:42,000 --> 01:16:43,620
that our theories of basically

2264
01:16:43,620 --> 01:16:46,739
everything in language for sure

2265
01:16:46,739 --> 01:16:48,960
um but cognition probably Neuroscience

2266
01:16:48,960 --> 01:16:50,640
right like all of those things I think

2267
01:16:50,640 --> 01:16:53,100
are are going to be reworked when we

2268
01:16:53,100 --> 01:16:54,420
when we really come to kind of

2269
01:16:54,420 --> 01:16:56,219
understand the

2270
01:16:56,219 --> 01:16:58,560
um uh the ability of really General

2271
01:16:58,560 --> 01:17:02,219
kinds of learning systems like these so

2272
01:17:02,219 --> 01:17:03,900
um that makes it you know on the one

2273
01:17:03,900 --> 01:17:05,820
hand uh

2274
01:17:05,820 --> 01:17:07,440
um kind of a bummer for for past

2275
01:17:07,440 --> 01:17:09,360
theories right especially theories which

2276
01:17:09,360 --> 01:17:11,640
relied on on

2277
01:17:11,640 --> 01:17:14,100
um uh you know learning not being able

2278
01:17:14,100 --> 01:17:15,659
to to work well

2279
01:17:15,659 --> 01:17:18,000
um but on the upside I think it it makes

2280
01:17:18,000 --> 01:17:20,460
it a a very exciting time both for for

2281
01:17:20,460 --> 01:17:22,620
AI and cognitive science and and

2282
01:17:22,620 --> 01:17:24,000
Linguistics

2283
01:17:24,000 --> 01:17:25,560
um where now there's these these really

2284
01:17:25,560 --> 01:17:27,420
really powerful tools

2285
01:17:27,420 --> 01:17:29,719
um that that seem like a qualitatively

2286
01:17:29,719 --> 01:17:32,940
uh different size step towards human

2287
01:17:32,940 --> 01:17:34,620
human abilities

2288
01:17:34,620 --> 01:17:36,120
um and I think kind of integrating them

2289
01:17:36,120 --> 01:17:39,060
and and taking uh both the the kind of

2290
01:17:39,060 --> 01:17:41,280
engineering lessons and the the kind of

2291
01:17:41,280 --> 01:17:43,679
philosophical lessons about how they're

2292
01:17:43,679 --> 01:17:45,540
made and and what kinds of principles go

2293
01:17:45,540 --> 01:17:47,460
into designing intelligent systems I

2294
01:17:47,460 --> 01:17:49,679
think that that uh those things will

2295
01:17:49,679 --> 01:17:52,080
will really shape the feel over the next

2296
01:17:52,080 --> 01:17:53,699
five or ten years

2297
01:17:53,699 --> 01:17:54,900
um

2298
01:17:54,900 --> 01:17:57,000
and also like I would just say in in the

2299
01:17:57,000 --> 01:17:58,500
context of broader themes here right

2300
01:17:58,500 --> 01:17:59,760
like you're totally right like I

2301
01:17:59,760 --> 01:18:01,620
remember when I was reading about when

2302
01:18:01,620 --> 01:18:04,920
deep blue be uh Casper of was it the the

2303
01:18:04,920 --> 01:18:07,260
chess uh thing right yeah and there were

2304
01:18:07,260 --> 01:18:08,940
some commentators who said you know

2305
01:18:08,940 --> 01:18:12,480
chess is over if an AI can be a human

2306
01:18:12,480 --> 01:18:13,739
then it's game over what's the point in

2307
01:18:13,739 --> 01:18:15,420
studying chess you know there's no need

2308
01:18:15,420 --> 01:18:16,920
of boring anymore

2309
01:18:16,920 --> 01:18:18,900
um and I guess if AI has achieved

2310
01:18:18,900 --> 01:18:20,640
seemingly everything that humans need to

2311
01:18:20,640 --> 01:18:22,140
do to play chess what's the point of

2312
01:18:22,140 --> 01:18:23,100
playing it

2313
01:18:23,100 --> 01:18:24,540
um but I think you know if anything it

2314
01:18:24,540 --> 01:18:26,219
turned out to increase the popularity of

2315
01:18:26,219 --> 01:18:27,900
Chess right they're in our mini chess

2316
01:18:27,900 --> 01:18:29,580
celebrities as well worldwide

2317
01:18:29,580 --> 01:18:31,199
tournaments and I I would predict that

2318
01:18:31,199 --> 01:18:32,520
the same is probably gonna happen with

2319
01:18:32,520 --> 01:18:34,620
language too you know llms do not mean

2320
01:18:34,620 --> 01:18:36,360
it's the end of language no more

2321
01:18:36,360 --> 01:18:37,800
language no more Linguistics I would

2322
01:18:37,800 --> 01:18:39,179
actually push back and say maybe it

2323
01:18:39,179 --> 01:18:40,620
would be the opposite

2324
01:18:40,620 --> 01:18:42,540
um you know the success of LMS will

2325
01:18:42,540 --> 01:18:44,400
increase general interest in linguistic

2326
01:18:44,400 --> 01:18:46,199
Theory due to their pairing you know

2327
01:18:46,199 --> 01:18:48,060
weird constraints and and apparent

2328
01:18:48,060 --> 01:18:50,100
limitations right because I would also

2329
01:18:50,100 --> 01:18:52,380
say you know scale at this point the the

2330
01:18:52,380 --> 01:18:55,500
stress issue scale is kind of definitely

2331
01:18:55,500 --> 01:18:57,420
far from all that's needed what is

2332
01:18:57,420 --> 01:18:59,820
lacking is an ability of LMS to you know

2333
01:18:59,820 --> 01:19:01,260
really abstract their knowledge and

2334
01:19:01,260 --> 01:19:03,239
experiences in order to make group wash

2335
01:19:03,239 --> 01:19:04,739
predictions and generalizations and so

2336
01:19:04,739 --> 01:19:06,780
on I gave some examples but there's some

2337
01:19:06,780 --> 01:19:07,860
others in the literature where it

2338
01:19:07,860 --> 01:19:09,179
doesn't seem to really be good at

2339
01:19:09,179 --> 01:19:10,739
generalizing it can go of maybe

2340
01:19:10,739 --> 01:19:13,620
particular token types and but I would

2341
01:19:13,620 --> 01:19:15,060
you know I would guess my final my final

2342
01:19:15,060 --> 01:19:17,100
claim would be that you know the

2343
01:19:17,100 --> 01:19:19,080
language acquisition literature

2344
01:19:19,080 --> 01:19:21,480
um doesn't necessarily need llms though

2345
01:19:21,480 --> 01:19:22,860
you know cognitive scientists don't

2346
01:19:22,860 --> 01:19:26,219
really need llms we could potentially uh

2347
01:19:26,219 --> 01:19:27,420
you know reinstate and obviously

2348
01:19:27,420 --> 01:19:29,640
disagree here but um I would say big

2349
01:19:29,640 --> 01:19:32,040
tech companies profiting off llms need

2350
01:19:32,040 --> 01:19:33,360
llms right they're the only ones that

2351
01:19:33,360 --> 01:19:35,100
really do it may be the case that the

2352
01:19:35,100 --> 01:19:37,320
mind is a very I will say you know the

2353
01:19:37,320 --> 01:19:39,000
mind is a very diverse space it may be

2354
01:19:39,000 --> 01:19:40,560
that there are certain forms of behavior

2355
01:19:40,560 --> 01:19:42,420
and learning that might be captured by

2356
01:19:42,420 --> 01:19:44,219
processes similar to what llms are doing

2357
01:19:44,219 --> 01:19:45,540
so Stephen has given some interesting

2358
01:19:45,540 --> 01:19:47,159
examples in his papers about magnetism

2359
01:19:47,159 --> 01:19:49,320
and and weird kind of rules of learning

2360
01:19:49,320 --> 01:19:51,060
that are very domain General and very

2361
01:19:51,060 --> 01:19:52,920
quick and very mysterious so you know

2362
01:19:52,920 --> 01:19:54,780
maybe for those sorts of things that

2363
01:19:54,780 --> 01:19:56,100
that kind of learning will be will be

2364
01:19:56,100 --> 01:19:57,780
relevant and but I still think it's

2365
01:19:57,780 --> 01:19:59,580
unlikely that one of the candidates will

2366
01:19:59,580 --> 01:20:02,100
be natural language and at least the way

2367
01:20:02,100 --> 01:20:03,480
natural language works and it's full

2368
01:20:03,480 --> 01:20:05,219
glory in terms of the form mainly

2369
01:20:05,219 --> 01:20:07,380
regulation and what have you so I guess

2370
01:20:07,380 --> 01:20:09,300
I would you know it kind of reminds me

2371
01:20:09,300 --> 01:20:11,520
of where you you know you have this

2372
01:20:11,520 --> 01:20:13,320
image of I saw John Wick chapter four

2373
01:20:13,320 --> 01:20:14,940
recently right and he has this there's

2374
01:20:14,940 --> 01:20:16,140
this scene where he's walking in the

2375
01:20:16,140 --> 01:20:17,580
desert and he's not sure if he's seen

2376
01:20:17,580 --> 01:20:19,260
this guy like he wants to assassinate

2377
01:20:19,260 --> 01:20:21,540
it's kind of like when you walk in the

2378
01:20:21,540 --> 01:20:22,739
desert

2379
01:20:22,739 --> 01:20:24,840
um and you have an illusion of seeing an

2380
01:20:24,840 --> 01:20:26,460
oasis because it turns out you're

2381
01:20:26,460 --> 01:20:28,199
hallucinating but then you realize that

2382
01:20:28,199 --> 01:20:29,820
you know sometimes before it's too late

2383
01:20:29,820 --> 01:20:31,679
that you actually are hallucinating it's

2384
01:20:31,679 --> 01:20:33,239
you're not seeing an oasis you're still

2385
01:20:33,239 --> 01:20:35,040
in the desert and I think that's kind of

2386
01:20:35,040 --> 01:20:37,199
maybe the situation we're in right now

2387
01:20:37,199 --> 01:20:39,360
with with linguistic competence of lots

2388
01:20:39,360 --> 01:20:41,400
of language models we have the illusion

2389
01:20:41,400 --> 01:20:44,940
of uh linguistic competence for you know

2390
01:20:44,940 --> 01:20:46,260
um you always see the illusion before

2391
01:20:46,260 --> 01:20:48,360
you find the Oasis right so I think I

2392
01:20:48,360 --> 01:20:49,440
think right now we're in the

2393
01:20:49,440 --> 01:20:51,420
hallucinating state of the desert where

2394
01:20:51,420 --> 01:20:53,699
we're seeing potential Sparks of of

2395
01:20:53,699 --> 01:20:55,380
linguistic competence but it's still not

2396
01:20:55,380 --> 01:20:57,420
very clear and robust

2397
01:20:57,420 --> 01:20:59,640
um we haven't actually reached the Oasis

2398
01:20:59,640 --> 01:21:02,480
yet yeah

2399
01:21:02,820 --> 01:21:06,360
um just a rapid fire question so see if

2400
01:21:06,360 --> 01:21:09,540
you can give a a short response so

2401
01:21:09,540 --> 01:21:11,219
svenochino

2402
01:21:11,219 --> 01:21:13,440
writes question is it correct to say

2403
01:21:13,440 --> 01:21:15,120
that large language models have no

2404
01:21:15,120 --> 01:21:17,540
priors

2405
01:21:18,480 --> 01:21:21,300
do large language models have priors I'd

2406
01:21:21,300 --> 01:21:23,820
say yes they definitely do

2407
01:21:23,820 --> 01:21:25,620
um and

2408
01:21:25,620 --> 01:21:28,440
um they're I think the the difference to

2409
01:21:28,440 --> 01:21:30,360
how people you know are used to thinking

2410
01:21:30,360 --> 01:21:32,340
about priors and in Bayesian inference

2411
01:21:32,340 --> 01:21:33,840
for example if you like write down a

2412
01:21:33,840 --> 01:21:36,300
Bayesian statistical model you you say

2413
01:21:36,300 --> 01:21:37,860
like you know here's the parameters and

2414
01:21:37,860 --> 01:21:39,300
here's what the priors are on the

2415
01:21:39,300 --> 01:21:40,860
parameters

2416
01:21:40,860 --> 01:21:42,360
um large language models I think the the

2417
01:21:42,360 --> 01:21:44,340
priors are and maybe neural nuts in

2418
01:21:44,340 --> 01:21:45,900
general I think that the that the the

2419
01:21:45,900 --> 01:21:47,880
priors are much more implicit right so

2420
01:21:47,880 --> 01:21:49,679
there's some functions which they find

2421
01:21:49,679 --> 01:21:52,080
easier to learn than uh than other

2422
01:21:52,080 --> 01:21:53,760
functions and there's even some work

2423
01:21:53,760 --> 01:21:55,860
trying to discover you know some

2424
01:21:55,860 --> 01:21:57,540
statement of what those kind of implicit

2425
01:21:57,540 --> 01:21:59,040
priors are

2426
01:21:59,040 --> 01:22:00,840
um but that that's actually how I think

2427
01:22:00,840 --> 01:22:02,040
about

2428
01:22:02,040 --> 01:22:02,940
um

2429
01:22:02,940 --> 01:22:04,620
um you know comparison of different

2430
01:22:04,620 --> 01:22:07,199
neural network architectures right

2431
01:22:07,199 --> 01:22:09,060
um uh which is maybe something elated

2432
01:22:09,060 --> 01:22:10,500
and I might might agree on right like

2433
01:22:10,500 --> 01:22:12,600
you have to find priors which allow them

2434
01:22:12,600 --> 01:22:14,400
to learn the things that that kids learn

2435
01:22:14,400 --> 01:22:16,140
right and

2436
01:22:16,140 --> 01:22:19,080
um not all architectures will do that

2437
01:22:19,080 --> 01:22:21,360
um even among architectures which are

2438
01:22:21,360 --> 01:22:23,280
turning complete or capable of learning

2439
01:22:23,280 --> 01:22:24,719
any kind of function not all of them

2440
01:22:24,719 --> 01:22:27,540
will will do it uh even on on kind of

2441
01:22:27,540 --> 01:22:30,000
huge data set sizes so

2442
01:22:30,000 --> 01:22:31,800
um I I think of this sort of search over

2443
01:22:31,800 --> 01:22:34,080
neural net architectures as really one

2444
01:22:34,080 --> 01:22:36,360
of of a search over priors

2445
01:22:36,360 --> 01:22:38,580
um but it's not priors or I mean you

2446
01:22:38,580 --> 01:22:39,719
could think of it as a search over

2447
01:22:39,719 --> 01:22:41,699
Universal grammar or something right but

2448
01:22:41,699 --> 01:22:44,340
it's it's it's not priors or Universal

2449
01:22:44,340 --> 01:22:46,560
grammar in the sense that people have

2450
01:22:46,560 --> 01:22:48,540
talked about it as like an explicit

2451
01:22:48,540 --> 01:22:50,159
statement about what kinds of rules are

2452
01:22:50,159 --> 01:22:51,780
allowed or an explicit statement about

2453
01:22:51,780 --> 01:22:53,880
what kinds of functions are high

2454
01:22:53,880 --> 01:22:55,320
probability or something like that it's

2455
01:22:55,320 --> 01:22:57,360
all implicitly coded there

2456
01:22:57,360 --> 01:22:58,560
um yeah yeah totally I think I think

2457
01:22:58,560 --> 01:23:00,540
that's right I mean you know the real

2458
01:23:00,540 --> 01:23:02,880
question is reducing the space of what

2459
01:23:02,880 --> 01:23:05,100
those that prize alike and if it's

2460
01:23:05,100 --> 01:23:07,020
anything remotely like what human beings

2461
01:23:07,020 --> 01:23:09,300
are doing so llm's like I would I would

2462
01:23:09,300 --> 01:23:11,219
at least say that things like qpt3 are

2463
01:23:11,219 --> 01:23:13,380
in existence proof of you know that

2464
01:23:13,380 --> 01:23:15,960
building fully functioning syntactic

2465
01:23:15,960 --> 01:23:18,000
categories from surface distributional

2466
01:23:18,000 --> 01:23:21,420
analysis this alone is possible that's

2467
01:23:21,420 --> 01:23:24,120
yes that is correct but you know even so

2468
01:23:24,120 --> 01:23:27,300
I would say most practitioners don't

2469
01:23:27,300 --> 01:23:29,460
really believe that syntactic categories

2470
01:23:29,460 --> 01:23:31,380
are innate so the prior issue is

2471
01:23:31,380 --> 01:23:33,060
slightly less irrelevant here it's the

2472
01:23:33,060 --> 01:23:35,219
operations that are set to be innate so

2473
01:23:35,219 --> 01:23:37,500
the in the syntax domain it's particular

2474
01:23:37,500 --> 01:23:39,659
linguistic computations that are said to

2475
01:23:39,659 --> 01:23:41,159
be in a and categories themselves in

2476
01:23:41,159 --> 01:23:42,719
fact even Charles Yang

2477
01:23:42,719 --> 01:23:44,100
um has admitted in the last couple years

2478
01:23:44,100 --> 01:23:46,800
that they are maybe in it but maybe not

2479
01:23:46,800 --> 01:23:49,679
so people have given another of a

2480
01:23:49,679 --> 01:23:51,540
relevant priority are things like

2481
01:23:51,540 --> 01:23:53,100
um you know me and Gary markets have

2482
01:23:53,100 --> 01:23:55,080
talked about compositionality that seems

2483
01:23:55,080 --> 01:23:56,640
to be a big problem so people have given

2484
01:23:56,640 --> 01:23:59,520
chat gbt BBC News articles asking it to

2485
01:23:59,520 --> 01:24:02,280
compress it and then re-explain it uh so

2486
01:24:02,280 --> 01:24:04,920
one example I saw was Peter Smith 58 is

2487
01:24:04,920 --> 01:24:06,480
being arrested on charges of

2488
01:24:06,480 --> 01:24:09,060
manslaughter and you get it to compress

2489
01:24:09,060 --> 01:24:10,920
it and re-explain it and it comes out as

2490
01:24:10,920 --> 01:24:12,420
58 people are being charged with

2491
01:24:12,420 --> 01:24:14,040
manslaughter right that's a pretty clear

2492
01:24:14,040 --> 01:24:15,659
example of a lack of compositionality

2493
01:24:15,659 --> 01:24:17,219
being built into whatever compression

2494
01:24:17,219 --> 01:24:19,260
it's doing and there's another example

2495
01:24:19,260 --> 01:24:20,940
where there's been there's some examples

2496
01:24:20,940 --> 01:24:23,159
of potential analogical reasoning so in

2497
01:24:23,159 --> 01:24:24,840
Bing chat you know Bing has this this

2498
01:24:24,840 --> 01:24:26,100
trap function

2499
01:24:26,100 --> 01:24:28,080
um the question is is it just finding

2500
01:24:28,080 --> 01:24:29,460
meta relations that have already been

2501
01:24:29,460 --> 01:24:31,080
documented by humans or is it genuinely

2502
01:24:31,080 --> 01:24:33,420
creating new relations the new stuff

2503
01:24:33,420 --> 01:24:35,100
that's being built

2504
01:24:35,100 --> 01:24:38,520
um so you know someone asked uh drew me

2505
01:24:38,520 --> 01:24:41,760
a table comparing Jesus Christ with the

2506
01:24:41,760 --> 01:24:44,640
Nokia 9910 right the cell phone Nokia

2507
01:24:44,640 --> 01:24:46,080
9910

2508
01:24:46,080 --> 01:24:47,520
um and it said you know they compared

2509
01:24:47,520 --> 01:24:49,860
the release dates it compared the size

2510
01:24:49,860 --> 01:24:53,280
the weight it compared the CPU with

2511
01:24:53,280 --> 01:24:55,140
Jesus's all-powerful knowledge it

2512
01:24:55,140 --> 01:24:57,600
compared the memory of the phone with

2513
01:24:57,600 --> 01:25:00,600
the all-knowing nature of God right

2514
01:25:00,600 --> 01:25:02,760
um also I think it said that they were

2515
01:25:02,760 --> 01:25:04,560
both resurrected because the Nokia was

2516
01:25:04,560 --> 01:25:06,239
re-released a couple of times right so

2517
01:25:06,239 --> 01:25:08,159
the Nokia sounds like a great answer

2518
01:25:08,159 --> 01:25:10,560
what's wrong with that that's okay it

2519
01:25:10,560 --> 01:25:12,120
may be maybe it sounds a lot like

2520
01:25:12,120 --> 01:25:13,860
analogical reasoning but then it also

2521
01:25:13,860 --> 01:25:15,420
had some quite weird ones where it was

2522
01:25:15,420 --> 01:25:17,100
like you know for the camera it said no

2523
01:25:17,100 --> 01:25:19,679
it just gave Jesus's description or it's

2524
01:25:19,679 --> 01:25:21,659
not really what a camera is there's some

2525
01:25:21,659 --> 01:25:24,000
kind of things that look like analogical

2526
01:25:24,000 --> 01:25:27,860
reasoning maybe but it's unclear yeah

2527
01:25:27,860 --> 01:25:31,440
hey I think that that sounds like an

2528
01:25:31,440 --> 01:25:33,020
awesome answer to me

2529
01:25:33,020 --> 01:25:36,360
I I was going to say like you you said

2530
01:25:36,360 --> 01:25:38,100
large language models learn their

2531
01:25:38,100 --> 01:25:39,719
existence proof of part of speech

2532
01:25:39,719 --> 01:25:41,520
categories but like they don't just

2533
01:25:41,520 --> 01:25:43,380
output part of speech categories right

2534
01:25:43,380 --> 01:25:45,719
like they they have a lot of grammatical

2535
01:25:45,719 --> 01:25:47,640
syntactic knowledge

2536
01:25:47,640 --> 01:25:50,880
um uh and moreover like they have a lot

2537
01:25:50,880 --> 01:25:52,980
of semantic knowledge and probably some

2538
01:25:52,980 --> 01:25:55,080
pragmatic knowledge and you know they're

2539
01:25:55,080 --> 01:25:58,080
they're not bad at translation and like

2540
01:25:58,080 --> 01:25:59,880
it's it's way more that they have

2541
01:25:59,880 --> 01:26:01,139
discovered

2542
01:26:01,139 --> 01:26:03,840
um than just part of speech categories

2543
01:26:03,840 --> 01:26:07,020
um uh well I'm sorry I said I'm sorry

2544
01:26:07,020 --> 01:26:08,940
it's a technical categories

2545
01:26:08,940 --> 01:26:11,040
right yeah well sorry so yeah yeah but

2546
01:26:11,040 --> 01:26:13,080
they've discovered way more than that

2547
01:26:13,080 --> 01:26:13,980
um

2548
01:26:13,980 --> 01:26:15,600
yeah um

2549
01:26:15,600 --> 01:26:18,780
I'm going to as a um teaser slash

2550
01:26:18,780 --> 01:26:20,699
motivator for hopefully both of you to

2551
01:26:20,699 --> 01:26:23,040
join uh again in the future with or

2552
01:26:23,040 --> 01:26:24,540
without other guests a few of the

2553
01:26:24,540 --> 01:26:26,520
exciting questions just for us to

2554
01:26:26,520 --> 01:26:28,679
include in this transcript and then

2555
01:26:28,679 --> 01:26:30,060
thank you both Ellie and Steven for

2556
01:26:30,060 --> 01:26:31,260
joining so just a few of the last

2557
01:26:31,260 --> 01:26:33,719
questions that were asked Juan asked how

2558
01:26:33,719 --> 01:26:35,820
do small Transformers Jang at all 2020

2559
01:26:35,820 --> 01:26:38,580
compared with children learning language

2560
01:26:38,580 --> 01:26:40,860
um 96 asked what are your thoughts on

2561
01:26:40,860 --> 01:26:42,800
implicit priors versus animal Instinct

2562
01:26:42,800 --> 01:26:45,780
rojda asked what constraints that space

2563
01:26:45,780 --> 01:26:48,420
in llms don't they get there by training

2564
01:26:48,420 --> 01:26:50,699
so are they discovering it that's not

2565
01:26:50,699 --> 01:26:52,500
what they Implement at the start maybe

2566
01:26:52,500 --> 01:26:54,780
and there's many more questions so I

2567
01:26:54,780 --> 01:26:57,540
hope that we can all um review and

2568
01:26:57,540 --> 01:27:00,600
re-read each other's works and come

2569
01:27:00,600 --> 01:27:04,020
together for 41.2 in some future time

2570
01:27:04,020 --> 01:27:06,060
thank you Elliot and Steven for this

2571
01:27:06,060 --> 01:27:08,280
excellent stream thank you Dave thank

2572
01:27:08,280 --> 01:27:10,739
you both yeah thank you so much

2573
01:27:10,739 --> 01:27:15,379
farewell bye see you

