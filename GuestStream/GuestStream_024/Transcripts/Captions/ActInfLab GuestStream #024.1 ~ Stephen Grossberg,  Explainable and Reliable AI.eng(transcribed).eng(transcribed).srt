1
00:00:01,199 --> 00:00:05,120
hello and welcome everyone it is june 28

2
00:00:05,120 --> 00:00:07,040
2022

3
00:00:07,040 --> 00:00:09,519
and we are here in actin flap guest

4
00:00:09,519 --> 00:00:12,639
stream number 24.1

5
00:00:12,639 --> 00:00:14,639
today we're here with professor stephen

6
00:00:14,639 --> 00:00:15,759
grosberg

7
00:00:15,759 --> 00:00:17,279
and the

8
00:00:17,279 --> 00:00:19,680
agenda will be as follows

9
00:00:19,680 --> 00:00:22,000
first ali will provide a short

10
00:00:22,000 --> 00:00:23,199
introduction

11
00:00:23,199 --> 00:00:26,000
we will then play a 45-minute

12
00:00:26,000 --> 00:00:28,320
pre-recorded video

13
00:00:28,320 --> 00:00:31,119
followed by a q a so

14
00:00:31,119 --> 00:00:33,440
thanks everyone for joining and

15
00:00:33,440 --> 00:00:35,760
professor grossberg really appreciate

16
00:00:35,760 --> 00:00:38,000
joining and i'll pass to ali for the

17
00:00:38,000 --> 00:00:40,559
introduction

18
00:00:42,559 --> 00:00:44,719
hello and welcome i'm ali i'm an

19
00:00:44,719 --> 00:00:46,879
independent researcher from iran i'm

20
00:00:46,879 --> 00:00:48,800
very happy and excited to be here and be

21
00:00:48,800 --> 00:00:51,440
able to speak with uh professor

22
00:00:51,440 --> 00:00:54,239
professor grossberg today uh so i'd like

23
00:00:54,239 --> 00:00:56,239
to thank uh professor grossberg for

24
00:00:56,239 --> 00:00:57,920
joining us

25
00:00:57,920 --> 00:01:00,800
steven grossberg is the one professor of

26
00:01:00,800 --> 00:01:02,480
cognitive and neural systems and a

27
00:01:02,480 --> 00:01:04,559
professor emeritus of mathematics in the

28
00:01:04,559 --> 00:01:06,880
statistics psychological and brain

29
00:01:06,880 --> 00:01:09,040
sciences and biomedical engineering at

30
00:01:09,040 --> 00:01:11,200
boston university

31
00:01:11,200 --> 00:01:13,360
for more than 50 years he has led

32
00:01:13,360 --> 00:01:15,520
pioneering research in discovering and

33
00:01:15,520 --> 00:01:17,680
developing neural design principles for

34
00:01:17,680 --> 00:01:20,000
autonomous adaptive intelligence based

35
00:01:20,000 --> 00:01:22,799
on biological and machine learning

36
00:01:22,799 --> 00:01:24,799
his neural network models have been

37
00:01:24,799 --> 00:01:27,280
applied to many large-scale problems in

38
00:01:27,280 --> 00:01:29,680
engineering and technology including the

39
00:01:29,680 --> 00:01:31,520
design of increasingly autonomous

40
00:01:31,520 --> 00:01:34,799
adaptive algorithms and mobile agents

41
00:01:34,799 --> 00:01:37,439
in fact this is what carl fristen says

42
00:01:37,439 --> 00:01:38,720
about him

43
00:01:38,720 --> 00:01:40,880
whenever you claim to be the first to do

44
00:01:40,880 --> 00:01:43,600
this or that in artificial intelligence

45
00:01:43,600 --> 00:01:46,799
it is customary and correct to add with

46
00:01:46,799 --> 00:01:49,360
the exception of stephen grossberg quite

47
00:01:49,360 --> 00:01:52,159
simply stephen is a living giant and

48
00:01:52,159 --> 00:01:55,600
foundational architect of the field

49
00:01:55,600 --> 00:01:57,680
professor grossberg is the recipient of

50
00:01:57,680 --> 00:02:00,320
the 2015 norman anderson lifetime

51
00:02:00,320 --> 00:02:02,399
achievement award of the society of

52
00:02:02,399 --> 00:02:05,680
experimental psychologists the 2017

53
00:02:05,680 --> 00:02:08,160
frank rosenblatt award of the ieee

54
00:02:08,160 --> 00:02:10,959
computational intelligence society and

55
00:02:10,959 --> 00:02:12,640
the 2019

56
00:02:12,640 --> 00:02:15,200
donald o'heb award of the international

57
00:02:15,200 --> 00:02:17,200
neural network society

58
00:02:17,200 --> 00:02:19,760
his latest book conscious mind resonant

59
00:02:19,760 --> 00:02:21,200
brain as a combination of his

60
00:02:21,200 --> 00:02:23,440
decades-long research written in a

61
00:02:23,440 --> 00:02:25,440
rather non-technical and conversational

62
00:02:25,440 --> 00:02:28,560
style is published in 2021 by oxford

63
00:02:28,560 --> 00:02:30,400
university press

64
00:02:30,400 --> 00:02:32,160
and is the winner of the association of

65
00:02:32,160 --> 00:02:34,800
american publishers in 2022

66
00:02:34,800 --> 00:02:37,360
pro's award for the best book of the

67
00:02:37,360 --> 00:02:39,120
year in neuroscience

68
00:02:39,120 --> 00:02:41,280
now i'll pass it to professor grootsburg

69
00:02:41,280 --> 00:02:43,360
and then we'll continue with the

70
00:02:43,360 --> 00:02:47,959
45-minute pre-recorded lecture

71
00:02:50,000 --> 00:02:51,920
you'd like to say hi otherwise i'll

72
00:02:51,920 --> 00:02:52,879
begin

73
00:02:52,879 --> 00:02:55,680
the video i just saw my face frozen on

74
00:02:55,680 --> 00:02:57,120
the screen

75
00:02:57,120 --> 00:03:01,519
uh well i'm delighted to be here and

76
00:03:01,519 --> 00:03:03,760
i hope you find some points of interest

77
00:03:03,760 --> 00:03:05,519
in the lecture

78
00:03:05,519 --> 00:03:08,000
and i'll look forward

79
00:03:08,000 --> 00:03:12,080
to the q a ali has prepared a series

80
00:03:12,080 --> 00:03:15,519
of questions that i've thought about and

81
00:03:15,519 --> 00:03:18,640
have some prepared sketched answers and

82
00:03:18,640 --> 00:03:19,599
then

83
00:03:19,599 --> 00:03:22,000
after that if you're still

84
00:03:22,000 --> 00:03:25,040
interested i'm happy to do

85
00:03:25,040 --> 00:03:26,959
live q a

86
00:03:26,959 --> 00:03:29,120
about anything related

87
00:03:29,120 --> 00:03:32,560
to the topics of the day

88
00:03:32,560 --> 00:03:34,080
okay

89
00:03:34,080 --> 00:03:36,480
on to the main course

90
00:03:36,480 --> 00:03:39,200
i will play the video

91
00:03:39,200 --> 00:03:41,440
now

92
00:03:41,920 --> 00:03:43,840
and you won't hear anything on the live

93
00:03:43,840 --> 00:03:45,280
stream

94
00:03:45,280 --> 00:03:47,200
all crop it and the audio will be coming

95
00:03:47,200 --> 00:03:50,000
through fine now

96
00:03:53,200 --> 00:03:55,120
hello

97
00:03:55,120 --> 00:03:57,680
i'm delighted to be able to speak to you

98
00:03:57,680 --> 00:03:58,799
today

99
00:03:58,799 --> 00:04:01,760
about a topic concerning artificial

100
00:04:01,760 --> 00:04:04,400
intelligence which as you know is very

101
00:04:04,400 --> 00:04:07,040
much in the news these days

102
00:04:07,040 --> 00:04:09,280
and i'll be contrasting

103
00:04:09,280 --> 00:04:11,840
two very different approaches to

104
00:04:11,840 --> 00:04:15,680
artificial intelligence but to do that

105
00:04:15,680 --> 00:04:17,600
i need to pull up

106
00:04:17,600 --> 00:04:19,600
my powerpoint

107
00:04:19,600 --> 00:04:21,839
slides

108
00:04:21,839 --> 00:04:24,400
and share them with you

109
00:04:24,400 --> 00:04:27,680
and let me maximize them

110
00:04:27,680 --> 00:04:30,160
and minimize my

111
00:04:30,160 --> 00:04:32,479
face

112
00:04:32,479 --> 00:04:35,040
so my topic today

113
00:04:35,040 --> 00:04:38,240
is explainable and reliable ai

114
00:04:38,240 --> 00:04:40,479
comparing deep learning

115
00:04:40,479 --> 00:04:44,639
with adaptive resonance

116
00:04:44,960 --> 00:04:47,040
this lecture is based on the following

117
00:04:47,040 --> 00:04:49,360
article from this year

118
00:04:49,360 --> 00:04:50,240
which

119
00:04:50,240 --> 00:04:53,919
is both open access and on my web page

120
00:04:53,919 --> 00:04:56,639
the article summarizes core problems of

121
00:04:56,639 --> 00:04:58,000
deep learning

122
00:04:58,000 --> 00:05:00,800
such as its untrustworthiness

123
00:05:00,800 --> 00:05:03,520
because it's unexplainable

124
00:05:03,520 --> 00:05:05,759
and its unreliability

125
00:05:05,759 --> 00:05:08,800
because it experiences catastrophic

126
00:05:08,800 --> 00:05:11,520
forgetting the article explains how

127
00:05:11,520 --> 00:05:13,440
adaptive resonance

128
00:05:13,440 --> 00:05:15,600
overcomes these problems indeed

129
00:05:15,600 --> 00:05:19,280
overcomes 17 problems of deep learning

130
00:05:19,280 --> 00:05:22,400
and outlines a blueprint for achieving

131
00:05:22,400 --> 00:05:24,960
autonomous adaptive

132
00:05:24,960 --> 00:05:27,360
intelligence

133
00:05:27,360 --> 00:05:29,680
the article is part of a frontier's a

134
00:05:29,680 --> 00:05:31,680
new robotic special issue about

135
00:05:31,680 --> 00:05:35,280
explainable ai whose editors wrote and i

136
00:05:35,280 --> 00:05:37,280
quote

137
00:05:37,280 --> 00:05:39,360
though deep learning is the main pillar

138
00:05:39,360 --> 00:05:41,840
of current ai techniques

139
00:05:41,840 --> 00:05:44,400
and is ubiquitous in basic science and

140
00:05:44,400 --> 00:05:46,800
real world applications

141
00:05:46,800 --> 00:05:49,039
it is also flagged by

142
00:05:49,039 --> 00:05:52,479
a.i researchers for its black box

143
00:05:52,479 --> 00:05:53,680
problem

144
00:05:53,680 --> 00:05:55,680
it is easy to fool

145
00:05:55,680 --> 00:05:58,880
and it also cannot explain how

146
00:05:58,880 --> 00:06:01,680
it makes a prediction or decision

147
00:06:01,680 --> 00:06:03,919
in other words deep learning is not

148
00:06:03,919 --> 00:06:05,600
trustworthy

149
00:06:05,600 --> 00:06:08,080
no life or death decision

150
00:06:08,080 --> 00:06:11,520
such as a medical or financial decision

151
00:06:11,520 --> 00:06:14,880
can confidently be made based upon a

152
00:06:14,880 --> 00:06:18,400
deep learning prediction

153
00:06:18,400 --> 00:06:21,600
deep learning uses the back propagation

154
00:06:21,600 --> 00:06:24,319
algorithm for learning how to predict

155
00:06:24,319 --> 00:06:27,120
output vectors in response to input

156
00:06:27,120 --> 00:06:28,479
vectors

157
00:06:28,479 --> 00:06:31,199
back propagation was based on perceptron

158
00:06:31,199 --> 00:06:33,520
learning principles that frank

159
00:06:33,520 --> 00:06:36,080
rosenblatt started to introduce in the

160
00:06:36,080 --> 00:06:38,160
1950s

161
00:06:38,160 --> 00:06:40,880
it has a complicated history which

162
00:06:40,880 --> 00:06:43,120
jurgen schmidt uber

163
00:06:43,120 --> 00:06:45,520
beautifully reviewed in an article from

164
00:06:45,520 --> 00:06:47,440
this year

165
00:06:47,440 --> 00:06:49,680
major contributors include shinichi

166
00:06:49,680 --> 00:06:53,520
amari paul werbos and david parker

167
00:06:53,520 --> 00:06:55,360
perhaps one would say that it reached

168
00:06:55,360 --> 00:06:57,840
its modern form with simulated

169
00:06:57,840 --> 00:06:59,440
applications

170
00:06:59,440 --> 00:07:00,599
in paul's

171
00:07:00,599 --> 00:07:02,639
1974 paper

172
00:07:02,639 --> 00:07:06,080
before being popularized 12 years later

173
00:07:06,080 --> 00:07:10,639
by rommel hart hinton and williams

174
00:07:10,639 --> 00:07:13,440
here's a schematic of a back propagation

175
00:07:13,440 --> 00:07:15,280
circuit reprinted

176
00:07:15,280 --> 00:07:18,000
from a survey article by gail carpenter

177
00:07:18,000 --> 00:07:20,560
of neural network models

178
00:07:20,560 --> 00:07:21,680
in it

179
00:07:21,680 --> 00:07:25,120
information flows feed forward from an

180
00:07:25,120 --> 00:07:29,360
input stage to an output stage

181
00:07:29,360 --> 00:07:31,840
learning is supervised by an external

182
00:07:31,840 --> 00:07:35,199
teacher who on each trial defines the

183
00:07:35,199 --> 00:07:38,560
target or desired output

184
00:07:38,560 --> 00:07:41,120
the teaching signal is the error or

185
00:07:41,120 --> 00:07:44,479
mismatch between the actual and the

186
00:07:44,479 --> 00:07:47,440
target outputs

187
00:07:47,440 --> 00:07:51,199
the teaching signal in level f3

188
00:07:51,199 --> 00:07:54,879
of adaptive weights in level f2

189
00:07:54,879 --> 00:07:57,599
have no network pathway whereby to reach

190
00:07:57,599 --> 00:08:00,639
from f3 to f2 within the algorithm

191
00:08:00,639 --> 00:08:04,000
so the algorithm uses an artifice called

192
00:08:04,000 --> 00:08:07,039
weight transport which physically lifts

193
00:08:07,039 --> 00:08:08,879
the weights from here

194
00:08:08,879 --> 00:08:10,960
and moves them there so that they can be

195
00:08:10,960 --> 00:08:13,199
used to control learning

196
00:08:13,199 --> 00:08:16,000
well this is clearly a non-local

197
00:08:16,000 --> 00:08:18,400
operation

198
00:08:18,400 --> 00:08:21,199
as well as being clearly

199
00:08:21,199 --> 00:08:24,199
non-biological

200
00:08:25,280 --> 00:08:27,440
back propagation learns through slow

201
00:08:27,440 --> 00:08:29,919
learning which means that the adaptive

202
00:08:29,919 --> 00:08:32,320
weights change just a little

203
00:08:32,320 --> 00:08:36,000
to reduce error on each learning trial

204
00:08:36,000 --> 00:08:38,479
that requires many trials that is to say

205
00:08:38,479 --> 00:08:41,360
many repetitions of the whole database

206
00:08:41,360 --> 00:08:42,399
to learn

207
00:08:42,399 --> 00:08:47,200
possibly hundreds or thousands of trials

208
00:08:47,200 --> 00:08:49,360
this is to be contrasted with fast

209
00:08:49,360 --> 00:08:52,240
learning or adaptive weight zero error

210
00:08:52,240 --> 00:08:55,040
signals on each trial just as we can

211
00:08:55,040 --> 00:08:57,600
learn a face that we see just once and

212
00:08:57,600 --> 00:08:59,760
remember it for a long time

213
00:08:59,760 --> 00:09:02,160
if backprop tried to use fast learning

214
00:09:02,160 --> 00:09:03,360
it would become

215
00:09:03,360 --> 00:09:06,320
wildly unstable

216
00:09:06,320 --> 00:09:08,560
catastrophic forgetting also occurs in

217
00:09:08,560 --> 00:09:11,360
back prop so that during any learning

218
00:09:11,360 --> 00:09:14,080
trial an unpredictable part of its

219
00:09:14,080 --> 00:09:19,600
learned memory can unexpectedly collapse

220
00:09:19,600 --> 00:09:22,160
so deep learning which is based on back

221
00:09:22,160 --> 00:09:25,120
propagation is thus neither reliable

222
00:09:25,120 --> 00:09:25,959
nor

223
00:09:25,959 --> 00:09:27,920
trustworthy

224
00:09:27,920 --> 00:09:29,760
but why is this

225
00:09:29,760 --> 00:09:31,680
one reason is that all inputs are

226
00:09:31,680 --> 00:09:33,920
processed by a shared set of learned

227
00:09:33,920 --> 00:09:35,200
ways

228
00:09:35,200 --> 00:09:37,600
the algorithm cannot selectively buffer

229
00:09:37,600 --> 00:09:39,519
learned weights that is still

230
00:09:39,519 --> 00:09:41,440
predictably useful

231
00:09:41,440 --> 00:09:43,279
in particular there's no attention

232
00:09:43,279 --> 00:09:45,040
mechanism

233
00:09:45,040 --> 00:09:47,200
this problem occurs in any learning

234
00:09:47,200 --> 00:09:49,760
algorithm whose shared weight updates

235
00:09:49,760 --> 00:09:52,800
follow the gradient of the error

236
00:09:52,800 --> 00:09:55,200
in response to the current batch of data

237
00:09:55,200 --> 00:09:56,240
points

238
00:09:56,240 --> 00:10:00,160
while ignoring past batches

239
00:10:00,160 --> 00:10:02,160
there have been multiple efforts to fix

240
00:10:02,160 --> 00:10:04,000
back propagation

241
00:10:04,000 --> 00:10:06,640
one is to selectively slow learning on

242
00:10:06,640 --> 00:10:09,279
the weights important for learning by

243
00:10:09,279 --> 00:10:11,760
optimizing parameters using the bayes

244
00:10:11,760 --> 00:10:14,079
rule as kirkpatrick at all

245
00:10:14,079 --> 00:10:16,560
suggested a few years ago

246
00:10:16,560 --> 00:10:20,160
but that assumes an omniscient observer

247
00:10:20,160 --> 00:10:23,120
who can discover and alter

248
00:10:23,120 --> 00:10:24,240
uh

249
00:10:24,240 --> 00:10:26,480
the important weights

250
00:10:26,480 --> 00:10:29,279
as well as non-local computations such

251
00:10:29,279 --> 00:10:32,560
as the bayesian computation

252
00:10:32,560 --> 00:10:34,160
the same problem occurs with

253
00:10:34,160 --> 00:10:36,480
evolutionary algorithms

254
00:10:36,480 --> 00:10:39,200
and diffusion based neuromodulation and

255
00:10:39,200 --> 00:10:43,920
other approaches to try to fix back prop

256
00:10:43,920 --> 00:10:46,480
these efforts to overcome catastrophic

257
00:10:46,480 --> 00:10:47,680
forgetting

258
00:10:47,680 --> 00:10:50,320
created additional conceptual and

259
00:10:50,320 --> 00:10:52,880
computational problems

260
00:10:52,880 --> 00:10:55,360
i view them as adding epicycles to

261
00:10:55,360 --> 00:10:57,600
ameliorate a fundamental flaw in the

262
00:10:57,600 --> 00:10:58,560
model

263
00:10:58,560 --> 00:11:00,800
which to me is reminiscent of adding at

264
00:11:00,800 --> 00:11:03,440
the cycles to correct problems in the

265
00:11:03,440 --> 00:11:06,399
ptolemaic model of the solar system

266
00:11:06,399 --> 00:11:09,120
as we all know the copernical model that

267
00:11:09,120 --> 00:11:12,839
we now accept didn't require

268
00:11:12,839 --> 00:11:16,560
epicycles this is why jeffrey hinton who

269
00:11:16,560 --> 00:11:18,480
played a key role in developing both

270
00:11:18,480 --> 00:11:21,279
backdrop and deep learning said in an

271
00:11:21,279 --> 00:11:24,000
axios interview a few years ago that

272
00:11:24,000 --> 00:11:26,720
quote he's deeply suspicious about

273
00:11:26,720 --> 00:11:28,320
propagation

274
00:11:28,320 --> 00:11:31,279
i don't think it's how the brain works

275
00:11:31,279 --> 00:11:34,959
we clearly don't need all the label data

276
00:11:34,959 --> 00:11:37,600
my view is throw it all away

277
00:11:37,600 --> 00:11:38,959
and start

278
00:11:38,959 --> 00:11:40,800
over

279
00:11:40,800 --> 00:11:42,880
i would claim we don't have to start

280
00:11:42,880 --> 00:11:43,839
over

281
00:11:43,839 --> 00:11:46,399
because these problems were solved in

282
00:11:46,399 --> 00:11:50,240
the 1970s and 1980s

283
00:11:50,240 --> 00:11:52,480
in particular in the first issue of the

284
00:11:52,480 --> 00:11:55,360
journal neural networks in 1988

285
00:11:55,360 --> 00:11:58,800
i had an article that listed 17 problems

286
00:11:58,800 --> 00:12:00,560
of back propagation

287
00:12:00,560 --> 00:12:03,839
that are overcome by adaptive resonance

288
00:12:03,839 --> 00:12:07,839
and here they are

289
00:12:07,839 --> 00:12:10,160
with regard to not needing all the label

290
00:12:10,160 --> 00:12:11,279
data

291
00:12:11,279 --> 00:12:14,480
i noted in the third item here that

292
00:12:14,480 --> 00:12:16,480
self-organized unsupervised or

293
00:12:16,480 --> 00:12:18,800
supervised learning frees us from

294
00:12:18,800 --> 00:12:21,519
needing labels all the time

295
00:12:21,519 --> 00:12:22,959
as to slow

296
00:12:22,959 --> 00:12:26,160
learning i noted that in art you can

297
00:12:26,160 --> 00:12:29,279
have fast or slow learning

298
00:12:29,279 --> 00:12:32,399
indeed ort can learn to classify an

299
00:12:32,399 --> 00:12:36,240
entire database using fast learning on a

300
00:12:36,240 --> 00:12:39,120
single learning trial as gail carpenter

301
00:12:39,120 --> 00:12:42,800
and i showed in the 1980s

302
00:12:42,800 --> 00:12:47,440
rover auto overcomes all 17 problems of

303
00:12:47,440 --> 00:12:49,040
back propagation

304
00:12:49,040 --> 00:12:54,320
without ex other cycles furthermore

305
00:12:54,320 --> 00:12:56,720
all the core art predictions

306
00:12:56,720 --> 00:12:58,639
have been supported

307
00:12:58,639 --> 00:13:01,720
by subsequent psychological and

308
00:13:01,720 --> 00:13:03,920
neurobiological data

309
00:13:03,920 --> 00:13:07,279
indeed art is a principled biological

310
00:13:07,279 --> 00:13:09,120
and technological

311
00:13:09,120 --> 00:13:10,320
theory

312
00:13:10,320 --> 00:13:13,440
unlike backprop and deep learning which

313
00:13:13,440 --> 00:13:14,880
are just

314
00:13:14,880 --> 00:13:17,200
algorithms

315
00:13:17,200 --> 00:13:19,519
art has explained data from hundreds of

316
00:13:19,519 --> 00:13:22,000
experiments and it's made scores of

317
00:13:22,000 --> 00:13:24,480
predictions that have subsequently

318
00:13:24,480 --> 00:13:27,839
received experimental support

319
00:13:27,839 --> 00:13:30,959
well why has art been so successful

320
00:13:30,959 --> 00:13:32,959
there are a number of reasons but one of

321
00:13:32,959 --> 00:13:35,760
them is that art can be derived from a

322
00:13:35,760 --> 00:13:38,800
thought experiment about a universal

323
00:13:38,800 --> 00:13:41,040
problem in error correction

324
00:13:41,040 --> 00:13:43,120
that i published 40 years ago in

325
00:13:43,120 --> 00:13:45,680
psychological review

326
00:13:45,680 --> 00:13:48,639
the thought experiment asks the question

327
00:13:48,639 --> 00:13:51,920
how can a coding error be corrected if

328
00:13:51,920 --> 00:13:55,360
no individual cell knows that one has

329
00:13:55,360 --> 00:13:56,720
occurred

330
00:13:56,720 --> 00:13:59,440
let me quote from my paper

331
00:13:59,440 --> 00:14:01,519
the importance of this issue becomes

332
00:14:01,519 --> 00:14:02,639
clear

333
00:14:02,639 --> 00:14:05,839
when we realize that erroneous cues can

334
00:14:05,839 --> 00:14:09,120
accidentally be incorporated into a code

335
00:14:09,120 --> 00:14:10,880
when our interactions with the

336
00:14:10,880 --> 00:14:12,639
environment is simple

337
00:14:12,639 --> 00:14:15,199
and will only become evident when our

338
00:14:15,199 --> 00:14:17,920
environmental expectations become more

339
00:14:17,920 --> 00:14:19,519
demanding

340
00:14:19,519 --> 00:14:22,240
and even if our code perfectly matched a

341
00:14:22,240 --> 00:14:24,720
given environment we would certainly

342
00:14:24,720 --> 00:14:26,079
make errors

343
00:14:26,079 --> 00:14:29,040
as the environment itself fluctuates so

344
00:14:29,040 --> 00:14:32,000
i was talking about autonomous local

345
00:14:32,000 --> 00:14:33,600
learning

346
00:14:33,600 --> 00:14:36,880
in a changing world

347
00:14:36,880 --> 00:14:39,360
a purely logical inquiry into error

348
00:14:39,360 --> 00:14:42,480
correction is translated at every step

349
00:14:42,480 --> 00:14:46,320
of the thought experiment into processes

350
00:14:46,320 --> 00:14:48,639
learning autonomously

351
00:14:48,639 --> 00:14:51,920
in real time with only locally computed

352
00:14:51,920 --> 00:14:53,279
quantities

353
00:14:53,279 --> 00:14:55,120
moreover the thought experiment uses

354
00:14:55,120 --> 00:14:57,519
familiar environmental facts

355
00:14:57,519 --> 00:15:00,959
about how we learn as its hypotheses

356
00:15:00,959 --> 00:15:03,760
and art circuits naturally emerge

357
00:15:03,760 --> 00:15:06,000
where these facts are familiar because

358
00:15:06,000 --> 00:15:08,399
they're you they're ubiquitous

359
00:15:08,399 --> 00:15:10,720
environmental constraints on the

360
00:15:10,720 --> 00:15:12,720
evolution of our brains

361
00:15:12,720 --> 00:15:14,800
and since we're living with them all the

362
00:15:14,800 --> 00:15:18,399
time they become familiar

363
00:15:18,399 --> 00:15:20,480
because of this universality art

364
00:15:20,480 --> 00:15:23,279
circuits may thus in some form

365
00:15:23,279 --> 00:15:26,000
be embodied in all future truly

366
00:15:26,000 --> 00:15:29,519
autonomous adaptive intelligent devices

367
00:15:29,519 --> 00:15:33,920
whether biological or artificial

368
00:15:33,920 --> 00:15:37,440
or it has probably for this reason

369
00:15:37,440 --> 00:15:40,320
already been used in many large-scale

370
00:15:40,320 --> 00:15:42,639
engineering and technological

371
00:15:42,639 --> 00:15:44,720
applications

372
00:15:44,720 --> 00:15:47,440
in fact almost immediately after art was

373
00:15:47,440 --> 00:15:48,880
introduced

374
00:15:48,880 --> 00:15:52,000
it began being used because it succeeded

375
00:15:52,000 --> 00:15:54,480
in benchmark studies against machine

376
00:15:54,480 --> 00:15:57,199
learning back propagation statistical

377
00:15:57,199 --> 00:15:58,240
methods

378
00:15:58,240 --> 00:16:01,040
genetic algorithms either getting much

379
00:16:01,040 --> 00:16:03,040
better accuracy

380
00:16:03,040 --> 00:16:06,560
or much faster training speed or both

381
00:16:06,560 --> 00:16:08,800
it's also used in applications where

382
00:16:08,800 --> 00:16:11,519
other algorithms totally fail

383
00:16:11,519 --> 00:16:14,639
such as the boeing company's part

384
00:16:14,639 --> 00:16:19,279
design reuse and inventory compression

385
00:16:19,279 --> 00:16:20,880
application

386
00:16:20,880 --> 00:16:23,360
that's just one of many large-scale

387
00:16:23,360 --> 00:16:25,040
applications in engineering and

388
00:16:25,040 --> 00:16:28,000
technology some of which can be found on

389
00:16:28,000 --> 00:16:31,839
our tech lab webpage at bu.edu

390
00:16:31,839 --> 00:16:34,240
the boeing parts design retrieval system

391
00:16:34,240 --> 00:16:37,519
in particular was used to help design

392
00:16:37,519 --> 00:16:41,360
the boeing 777

393
00:16:41,360 --> 00:16:43,600
and to do that you needed fast learning

394
00:16:43,600 --> 00:16:45,759
and stable memory to learn in search a

395
00:16:45,759 --> 00:16:47,040
huge

396
00:16:47,040 --> 00:16:49,680
and continually growing non-stationary

397
00:16:49,680 --> 00:16:51,360
parts inventory

398
00:16:51,360 --> 00:16:53,759
at the time of this application there

399
00:16:53,759 --> 00:16:56,399
are already 16 million

400
00:16:56,399 --> 00:16:58,800
one million dimensional vectors

401
00:16:58,800 --> 00:17:00,959
that were used to

402
00:17:00,959 --> 00:17:03,680
describe each of the parts and you have

403
00:17:03,680 --> 00:17:05,280
to be able to quickly search the

404
00:17:05,280 --> 00:17:07,919
inventory if you wanted to find a part

405
00:17:07,919 --> 00:17:10,319
to use in a new plane

406
00:17:10,319 --> 00:17:12,880
especially if your new design might have

407
00:17:12,880 --> 00:17:15,039
a part in the inventory that was similar

408
00:17:15,039 --> 00:17:15,919
to it

409
00:17:15,919 --> 00:17:18,880
finding it and slightly modifying design

410
00:17:18,880 --> 00:17:20,000
could save

411
00:17:20,000 --> 00:17:24,400
millions of dollars in fabrication costs

412
00:17:24,400 --> 00:17:26,799
satellite remote sensing is another

413
00:17:26,799 --> 00:17:29,520
large scale application that art was

414
00:17:29,520 --> 00:17:32,559
used for very soon and gail carpenter

415
00:17:32,559 --> 00:17:34,960
and her colleagues took the lead here

416
00:17:34,960 --> 00:17:38,000
for example using a very small number of

417
00:17:38,000 --> 00:17:42,400
pixels of ground truth of 17 vegetation

418
00:17:42,400 --> 00:17:43,760
classes

419
00:17:43,760 --> 00:17:49,200
they used art to automatically complete

420
00:17:49,520 --> 00:17:51,600
these

421
00:17:51,600 --> 00:17:53,600
maps you are

422
00:17:53,600 --> 00:17:56,240
using remote sensing data

423
00:17:56,240 --> 00:17:58,559
art did it in a day

424
00:17:58,559 --> 00:18:00,720
rapidly and automatically it gave a

425
00:18:00,720 --> 00:18:03,520
confidence map for each pixel and the

426
00:18:03,520 --> 00:18:07,039
pixels were 30 meters in scale which it

427
00:18:07,039 --> 00:18:09,440
was small enough to see roads

428
00:18:09,440 --> 00:18:12,799
this contrasted with an ai expert system

429
00:18:12,799 --> 00:18:15,440
which took a whole year to do with and

430
00:18:15,440 --> 00:18:17,280
it had to derive that

431
00:18:17,280 --> 00:18:20,240
ad hoc rules from experts you have to

432
00:18:20,240 --> 00:18:22,320
correct up upwards of a quarter of a

433
00:18:22,320 --> 00:18:25,840
million site labels and even so the

434
00:18:25,840 --> 00:18:29,039
pixel size was an order of magnitude

435
00:18:29,039 --> 00:18:31,440
larger

436
00:18:31,440 --> 00:18:33,600
gail went on with her colleagues to

437
00:18:33,600 --> 00:18:35,919
study information fusion and remote

438
00:18:35,919 --> 00:18:38,400
sensing let's say you have multiple

439
00:18:38,400 --> 00:18:39,919
observers

440
00:18:39,919 --> 00:18:42,720
each of them may be using different

441
00:18:42,720 --> 00:18:46,080
labels the labels may also be incomplete

442
00:18:46,080 --> 00:18:49,039
or missing or even incorrect and the

443
00:18:49,039 --> 00:18:50,960
task was to derive

444
00:18:50,960 --> 00:18:53,360
consistent knowledge from potentially

445
00:18:53,360 --> 00:18:55,520
inconsistent data

446
00:18:55,520 --> 00:18:58,960
to automatically learn and stably store

447
00:18:58,960 --> 00:19:01,679
one to many mappings

448
00:19:01,679 --> 00:19:03,679
and along the way gail and a colleague

449
00:19:03,679 --> 00:19:06,799
showed how to self-organize a hierarchy

450
00:19:06,799 --> 00:19:10,320
of cognitive rules including confidence

451
00:19:10,320 --> 00:19:13,039
measures between these different levels

452
00:19:13,039 --> 00:19:16,000
of the hierarchy

453
00:19:16,000 --> 00:19:18,240
there's been continual work on arts a

454
00:19:18,240 --> 00:19:20,960
more recent work was summarized in a

455
00:19:20,960 --> 00:19:24,400
special issue of neural networks just in

456
00:19:24,400 --> 00:19:26,720
december 2019

457
00:19:26,720 --> 00:19:29,679
that was edited by donald lunch who

458
00:19:29,679 --> 00:19:31,360
started this special issue with a

459
00:19:31,360 --> 00:19:34,080
general overview of neural network

460
00:19:34,080 --> 00:19:35,840
models that i and my colleagues

461
00:19:35,840 --> 00:19:39,039
developed and then went on in a long and

462
00:19:39,039 --> 00:19:41,280
detailed article with several

463
00:19:41,280 --> 00:19:44,400
collaborators to provide a survey of

464
00:19:44,400 --> 00:19:46,480
adaptive resonance theory neural network

465
00:19:46,480 --> 00:19:49,200
models for engineering applications to

466
00:19:49,200 --> 00:19:53,320
the present time

467
00:19:53,360 --> 00:19:56,000
so back propagation and deep learning

468
00:19:56,000 --> 00:19:58,320
are a feed forward adaptive filter but

469
00:19:58,320 --> 00:20:00,880
art is more than that

470
00:20:00,880 --> 00:20:02,840
in fact art is an

471
00:20:02,840 --> 00:20:04,840
explainable

472
00:20:04,840 --> 00:20:07,679
self-organizing production system

473
00:20:07,679 --> 00:20:10,640
in a non-stationary world

474
00:20:10,640 --> 00:20:13,440
what do these works mean

475
00:20:13,440 --> 00:20:15,919
or it's self-organizing because it can

476
00:20:15,919 --> 00:20:18,080
autonomously carry out

477
00:20:18,080 --> 00:20:21,840
arbitrary combinations of unsupervised

478
00:20:21,840 --> 00:20:24,799
or supervised learning trials with the

479
00:20:24,799 --> 00:20:28,480
world as its only teacher

480
00:20:28,480 --> 00:20:31,799
it's a production system because it uses

481
00:20:31,799 --> 00:20:35,440
hypothesis testing to discover and learn

482
00:20:35,440 --> 00:20:36,799
rules

483
00:20:36,799 --> 00:20:40,000
by a top-down matching process that

484
00:20:40,000 --> 00:20:42,480
focuses attention on

485
00:20:42,480 --> 00:20:44,640
critical feature patterns these are the

486
00:20:44,640 --> 00:20:48,240
patterns that predict behavioral success

487
00:20:48,240 --> 00:20:52,799
while suppressing irrelevant features

488
00:20:52,799 --> 00:20:54,960
or it's explainable using both its

489
00:20:54,960 --> 00:20:57,760
activities or short-term memory stm

490
00:20:57,760 --> 00:20:59,039
traces

491
00:20:59,039 --> 00:21:01,360
and its adaptive weights or long-term

492
00:21:01,360 --> 00:21:04,000
memory ltm traces

493
00:21:04,000 --> 00:21:08,159
activation dynamics learning dynamics

494
00:21:08,159 --> 00:21:10,880
observing the stm traces in a critical

495
00:21:10,880 --> 00:21:14,080
feature pattern explain what recognition

496
00:21:14,080 --> 00:21:17,120
categories will learn to code

497
00:21:17,120 --> 00:21:20,000
and what features predict goal-oriented

498
00:21:20,000 --> 00:21:21,360
actions

499
00:21:21,360 --> 00:21:23,280
in particular the long-term memory

500
00:21:23,280 --> 00:21:26,559
traces in the fuzzy arcmap algorithm

501
00:21:26,559 --> 00:21:29,360
translate into explicit

502
00:21:29,360 --> 00:21:32,320
fuzzy if-then rules that code what

503
00:21:32,320 --> 00:21:34,960
combinations of critical features in

504
00:21:34,960 --> 00:21:36,400
what numerical

505
00:21:36,400 --> 00:21:39,760
ranges effectively control predictions

506
00:21:39,760 --> 00:21:41,679
thereby illustrating one of many

507
00:21:41,679 --> 00:21:45,039
examples where neural networks can learn

508
00:21:45,039 --> 00:21:48,640
rule-based behaviors

509
00:21:49,039 --> 00:21:51,760
art includes a bottom-up adaptive filter

510
00:21:51,760 --> 00:21:53,919
or feed-forward neural network as i've

511
00:21:53,919 --> 00:21:57,039
observed already but that's supplemented

512
00:21:57,039 --> 00:22:00,320
by top-down learned expectations

513
00:22:00,320 --> 00:22:02,960
and two types of recurrent inhibitory

514
00:22:02,960 --> 00:22:05,360
feedback interactions that help to

515
00:22:05,360 --> 00:22:08,000
choose the recognition categories and

516
00:22:08,000 --> 00:22:10,159
the critical features

517
00:22:10,159 --> 00:22:12,799
notably top-down expectations use what

518
00:22:12,799 --> 00:22:15,360
gail carpenter and i call the art

519
00:22:15,360 --> 00:22:18,159
matching rule to learn how to focus

520
00:22:18,159 --> 00:22:20,960
attention on critical features that

521
00:22:20,960 --> 00:22:22,000
control

522
00:22:22,000 --> 00:22:24,400
predictive success

523
00:22:24,400 --> 00:22:26,480
the art matching rule is another way of

524
00:22:26,480 --> 00:22:27,880
talking

525
00:22:27,880 --> 00:22:30,240
computationally about the process of

526
00:22:30,240 --> 00:22:32,320
object attention

527
00:22:32,320 --> 00:22:35,600
how we pay attention to salient objects

528
00:22:35,600 --> 00:22:38,000
in the world

529
00:22:38,000 --> 00:22:40,480
and we show how it stabilizes learning

530
00:22:40,480 --> 00:22:42,320
and thereby avoids catastrophic

531
00:22:42,320 --> 00:22:44,320
forgetting

532
00:22:44,320 --> 00:22:46,720
remarkably and this has been supported

533
00:22:46,720 --> 00:22:49,840
by many data

534
00:22:50,559 --> 00:22:52,799
the art matching rule can be realized by

535
00:22:52,799 --> 00:22:54,480
a top down

536
00:22:54,480 --> 00:22:57,679
modulatory on center off surround

537
00:22:57,679 --> 00:23:00,400
network well what does this mean

538
00:23:00,400 --> 00:23:02,720
well let's say we have bottom-up inputs

539
00:23:02,720 --> 00:23:05,520
from external features to feature

540
00:23:05,520 --> 00:23:07,600
selective cells that gets stored in

541
00:23:07,600 --> 00:23:10,080
short-term memory

542
00:23:10,080 --> 00:23:12,240
let's say we activate a recognition

543
00:23:12,240 --> 00:23:14,640
category which has previously been

544
00:23:14,640 --> 00:23:17,200
learned and tries to read out

545
00:23:17,200 --> 00:23:18,600
its learned

546
00:23:18,600 --> 00:23:21,039
excitatory prototype

547
00:23:21,039 --> 00:23:23,520
well it can't fully do so because it

548
00:23:23,520 --> 00:23:26,400
also reads out an inhibitory off

549
00:23:26,400 --> 00:23:28,000
surround that's broader than the

550
00:23:28,000 --> 00:23:29,280
prototype

551
00:23:29,280 --> 00:23:31,200
and so this is approximately one

552
00:23:31,200 --> 00:23:34,159
excitatory against one's inhibitory it

553
00:23:34,159 --> 00:23:38,880
can only give you a modulatory on center

554
00:23:38,880 --> 00:23:41,279
but if you have both bottom-up inputs

555
00:23:41,279 --> 00:23:42,240
and

556
00:23:42,240 --> 00:23:45,279
the top-down expectations simultaneously

557
00:23:45,279 --> 00:23:47,200
active

558
00:23:47,200 --> 00:23:49,760
then within the bounds of the prototype

559
00:23:49,760 --> 00:23:52,320
if you also have a bottom-up feature

560
00:23:52,320 --> 00:23:54,640
you have two excitatory

561
00:23:54,640 --> 00:23:57,200
against one inhibitory and

562
00:23:57,200 --> 00:23:58,880
those features

563
00:23:58,880 --> 00:24:02,000
can be selected gain amplified and

564
00:24:02,000 --> 00:24:05,760
synchronized to start focusing attention

565
00:24:05,760 --> 00:24:08,640
on this critical feature pattern while

566
00:24:08,640 --> 00:24:11,120
outlier features the ones that aren't

567
00:24:11,120 --> 00:24:13,520
within the prototype only have one

568
00:24:13,520 --> 00:24:16,720
excitation against one inhibition or

569
00:24:16,720 --> 00:24:19,039
suppressed

570
00:24:19,039 --> 00:24:22,000
and in 1999 i was able to begin to

571
00:24:22,000 --> 00:24:24,559
understand how laminar cortical circuits

572
00:24:24,559 --> 00:24:26,880
carry out object detention

573
00:24:26,880 --> 00:24:29,760
in particular layer six of a higher

574
00:24:29,760 --> 00:24:31,279
cortical area

575
00:24:31,279 --> 00:24:34,000
can activate layer 6 of a lower cortical

576
00:24:34,000 --> 00:24:34,880
area

577
00:24:34,880 --> 00:24:38,080
either directly or via lathe 5

578
00:24:38,080 --> 00:24:39,760
and then

579
00:24:39,760 --> 00:24:43,279
it can fold up the layer 4

580
00:24:43,279 --> 00:24:44,240
to

581
00:24:44,240 --> 00:24:47,120
modulate and on center

582
00:24:47,120 --> 00:24:50,320
and to inhibit and off surround

583
00:24:50,320 --> 00:24:53,600
so attention acts via a top-down

584
00:24:53,600 --> 00:24:56,480
modulatory on-center off surround

585
00:24:56,480 --> 00:25:00,000
network via folded feedback within

586
00:25:00,000 --> 00:25:02,720
laminar neocortex

587
00:25:02,720 --> 00:25:05,440
and this is one example of the paradigm

588
00:25:05,440 --> 00:25:08,320
of laminar computing that i introduced

589
00:25:08,320 --> 00:25:10,400
which has why are all neocortical

590
00:25:10,400 --> 00:25:12,880
circuits organized in layers

591
00:25:12,880 --> 00:25:15,760
and how do laminate circuits give rise

592
00:25:15,760 --> 00:25:18,080
to all kinds of biological

593
00:25:18,080 --> 00:25:20,880
intelligence

594
00:25:20,880 --> 00:25:23,039
adaptive resonance enters the story

595
00:25:23,039 --> 00:25:26,240
because attended feature clusters

596
00:25:26,240 --> 00:25:29,760
reactivate their bottom of pathways

597
00:25:29,760 --> 00:25:32,640
activated categories reactivate their

598
00:25:32,640 --> 00:25:34,640
top down pathways

599
00:25:34,640 --> 00:25:38,240
closing an excitatory feedback loop

600
00:25:38,240 --> 00:25:39,360
between

601
00:25:39,360 --> 00:25:42,960
features and categories giving rise to a

602
00:25:42,960 --> 00:25:45,039
feature category

603
00:25:45,039 --> 00:25:48,559
resonance that synchronizes amplifies

604
00:25:48,559 --> 00:25:52,240
and prolongs system response between the

605
00:25:52,240 --> 00:25:56,000
attended critical features and the

606
00:25:56,000 --> 00:25:59,279
category to which they are bound

607
00:25:59,279 --> 00:26:01,200
and it's this resonance that triggers

608
00:26:01,200 --> 00:26:04,000
fast learning in the bottom up and

609
00:26:04,000 --> 00:26:05,360
top-down

610
00:26:05,360 --> 00:26:08,240
adaptive weights which is why i have

611
00:26:08,240 --> 00:26:11,600
called the theory adaptive resonance

612
00:26:11,600 --> 00:26:13,120
theory

613
00:26:13,120 --> 00:26:16,240
moreover i've done a lot of work since

614
00:26:16,240 --> 00:26:19,120
then showing that all conscious states

615
00:26:19,120 --> 00:26:21,760
are resonant states and these feature

616
00:26:21,760 --> 00:26:24,400
category resonances a one example of

617
00:26:24,400 --> 00:26:27,360
that one that supports conscious

618
00:26:27,360 --> 00:26:28,880
recognition

619
00:26:28,880 --> 00:26:32,559
of visual objects and scenes

620
00:26:32,559 --> 00:26:34,640
there's a lot of data support for our

621
00:26:34,640 --> 00:26:36,880
predictions it's well known that

622
00:26:36,880 --> 00:26:39,039
attention does have an on center off

623
00:26:39,039 --> 00:26:40,240
surround

624
00:26:40,240 --> 00:26:43,600
a circuit behind it and that attention

625
00:26:43,600 --> 00:26:47,360
can facilitate matched bottom-up signals

626
00:26:47,360 --> 00:26:49,120
many other data

627
00:26:49,120 --> 00:26:51,279
as well

628
00:26:51,279 --> 00:26:53,679
so now we can say more about why art is

629
00:26:53,679 --> 00:26:56,320
explainable or trustworthy

630
00:26:56,320 --> 00:26:59,039
in short-term memory it's because the

631
00:26:59,039 --> 00:27:01,360
critical feature patterns determine the

632
00:27:01,360 --> 00:27:03,200
attentional focus

633
00:27:03,200 --> 00:27:05,760
that controls information processing and

634
00:27:05,760 --> 00:27:06,880
you can just

635
00:27:06,880 --> 00:27:09,520
read off what those features are

636
00:27:09,520 --> 00:27:11,360
in long-term memory again it's the

637
00:27:11,360 --> 00:27:14,000
critical feature patterns that determine

638
00:27:14,000 --> 00:27:16,559
the adaptive weights learned by the

639
00:27:16,559 --> 00:27:18,480
bottom-up adaptive filter and the

640
00:27:18,480 --> 00:27:20,559
top-down learned expectation

641
00:27:20,559 --> 00:27:23,039
so you know also what these weights are

642
00:27:23,039 --> 00:27:25,039
encoding

643
00:27:25,039 --> 00:27:27,600
or it's reliable and avoids catastrophic

644
00:27:27,600 --> 00:27:30,799
forgetting because outlier features

645
00:27:30,799 --> 00:27:32,640
that are not in the critical feature

646
00:27:32,640 --> 00:27:34,559
pattern is suppressed

647
00:27:34,559 --> 00:27:36,960
so that only the predictive features are

648
00:27:36,960 --> 00:27:40,240
processed and coded

649
00:27:40,240 --> 00:27:42,480
well it's a production system because it

650
00:27:42,480 --> 00:27:45,600
carries out a kind of hypothesis testing

651
00:27:45,600 --> 00:27:47,760
and this is nicely illustrated in the

652
00:27:47,760 --> 00:27:48,880
simplest

653
00:27:48,880 --> 00:27:52,080
art model called art one that gail

654
00:27:52,080 --> 00:27:53,679
carpenter and i

655
00:27:53,679 --> 00:27:56,399
published in 1987.

656
00:27:56,399 --> 00:28:00,159
art one has an attentional system

657
00:28:00,159 --> 00:28:02,399
that does all the category learning and

658
00:28:02,399 --> 00:28:04,320
the expectation learning and the paying

659
00:28:04,320 --> 00:28:05,679
attention

660
00:28:05,679 --> 00:28:08,000
that interacts with an orienting system

661
00:28:08,000 --> 00:28:10,240
which is activated when there are big

662
00:28:10,240 --> 00:28:12,960
enough matches in the attentional system

663
00:28:12,960 --> 00:28:16,159
and thereby drives a reset and search

664
00:28:16,159 --> 00:28:17,120
for

665
00:28:17,120 --> 00:28:20,240
novel or better matching categories

666
00:28:20,240 --> 00:28:23,679
here's a schematic of the art hypothesis

667
00:28:23,679 --> 00:28:26,799
testing and learning cycle

668
00:28:26,799 --> 00:28:28,720
so let's say you have a bottom-up

669
00:28:28,720 --> 00:28:31,440
feature pattern coming in there may be

670
00:28:31,440 --> 00:28:34,320
many many active bottom-up features but

671
00:28:34,320 --> 00:28:36,159
i'll draw just one

672
00:28:36,159 --> 00:28:38,480
arrow here for simplicity

673
00:28:38,480 --> 00:28:40,720
but that vector of input features can

674
00:28:40,720 --> 00:28:43,919
activate a distributed pattern of future

675
00:28:43,919 --> 00:28:47,039
detector cells some may be very active

676
00:28:47,039 --> 00:28:50,240
some not so active some not active at

677
00:28:50,240 --> 00:28:51,200
all

678
00:28:51,200 --> 00:28:54,080
and as this is happening

679
00:28:54,080 --> 00:28:56,720
each of these active pathways is trying

680
00:28:56,720 --> 00:29:00,080
to turn on the orienting system so there

681
00:29:00,080 --> 00:29:02,320
might be quite a few inputs converging

682
00:29:02,320 --> 00:29:03,200
here

683
00:29:03,200 --> 00:29:05,600
but as the features are activated each

684
00:29:05,600 --> 00:29:08,240
of them tries to inhibit the orienting

685
00:29:08,240 --> 00:29:10,720
system and there is many features as

686
00:29:10,720 --> 00:29:13,840
there are inputs so this excitation

687
00:29:13,840 --> 00:29:16,240
inhibition of balance keeping the

688
00:29:16,240 --> 00:29:19,840
orienting system quiet as the feature

689
00:29:19,840 --> 00:29:22,159
padding goes to the adaptive filter and

690
00:29:22,159 --> 00:29:25,200
chooses a category

691
00:29:25,200 --> 00:29:27,039
that category reads out to learn

692
00:29:27,039 --> 00:29:29,360
top-down expectation that obeys the art

693
00:29:29,360 --> 00:29:32,080
matching rule which can suppress some

694
00:29:32,080 --> 00:29:34,960
mismatched features thereby reducing the

695
00:29:34,960 --> 00:29:36,960
amount of inhibition on the oriented

696
00:29:36,960 --> 00:29:40,399
system and raising the question when you

697
00:29:40,399 --> 00:29:42,000
have too little

698
00:29:42,000 --> 00:29:45,120
inhibition and too much excitation

699
00:29:45,120 --> 00:29:47,360
how big a mismatch will activate the

700
00:29:47,360 --> 00:29:50,720
orient system and cause reset

701
00:29:50,720 --> 00:29:52,840
and that

702
00:29:52,840 --> 00:29:56,080
uh ratio is determined

703
00:29:56,080 --> 00:29:58,480
by what's called vigilance which i'll

704
00:29:58,480 --> 00:30:01,360
say more about soon

705
00:30:01,360 --> 00:30:03,520
but if you don't have enough inhibition

706
00:30:03,520 --> 00:30:06,840
then the orienting system gets activated

707
00:30:06,840 --> 00:30:11,279
it equally activates all the cells in

708
00:30:11,279 --> 00:30:13,520
the category layer because it doesn't

709
00:30:13,520 --> 00:30:16,240
know which cell may be active or not so

710
00:30:16,240 --> 00:30:17,520
it causes a

711
00:30:17,520 --> 00:30:19,200
novelty

712
00:30:19,200 --> 00:30:22,640
uh sensitive non-specific burst of

713
00:30:22,640 --> 00:30:26,000
arousal novel events are arousing

714
00:30:26,000 --> 00:30:28,480
thereby selectively shutting off the

715
00:30:28,480 --> 00:30:30,159
active category

716
00:30:30,159 --> 00:30:33,360
eliminating its top-down expectation

717
00:30:33,360 --> 00:30:35,440
and unmasking the original feature

718
00:30:35,440 --> 00:30:37,760
pattern which can again go through the

719
00:30:37,760 --> 00:30:39,440
adaptive filter

720
00:30:39,440 --> 00:30:41,200
however now

721
00:30:41,200 --> 00:30:42,080
this

722
00:30:42,080 --> 00:30:45,039
previously disconfirmed category remains

723
00:30:45,039 --> 00:30:46,000
off

724
00:30:46,000 --> 00:30:49,039
and the category level is renormalized

725
00:30:49,039 --> 00:30:52,159
so it responds to the same input pattern

726
00:30:52,159 --> 00:30:55,279
with a new category and you go through

727
00:30:55,279 --> 00:30:56,799
this cycle

728
00:30:56,799 --> 00:30:59,279
of resonance and reset

729
00:30:59,279 --> 00:31:01,679
until you get a good enough match

730
00:31:01,679 --> 00:31:04,480
to either learn a new category or select

731
00:31:04,480 --> 00:31:08,000
a previously learned category

732
00:31:08,000 --> 00:31:10,320
and it's a theorem that as categories

733
00:31:10,320 --> 00:31:11,919
are learned through this matching

734
00:31:11,919 --> 00:31:13,039
process

735
00:31:13,039 --> 00:31:15,279
search automatically

736
00:31:15,279 --> 00:31:18,279
disengages

737
00:31:18,640 --> 00:31:21,679
leading to direct access without search

738
00:31:21,679 --> 00:31:25,679
to the globally best matching category

739
00:31:25,679 --> 00:31:28,080
explaining for example how we can

740
00:31:28,080 --> 00:31:31,039
quickly recognize familiar objects like

741
00:31:31,039 --> 00:31:33,679
your mother's face even if as we get

742
00:31:33,679 --> 00:31:36,480
older we store enormous numbers of

743
00:31:36,480 --> 00:31:38,080
additional memories

744
00:31:38,080 --> 00:31:39,840
so you don't have to start your whole

745
00:31:39,840 --> 00:31:42,240
repertoire when you see mom you get

746
00:31:42,240 --> 00:31:46,480
direct access and quickly say hi mom

747
00:31:46,480 --> 00:31:48,000
there's a lot of support to the

748
00:31:48,000 --> 00:31:50,799
hypothesis testing cycle

749
00:31:50,799 --> 00:31:53,120
one source of support is from a ventral

750
00:31:53,120 --> 00:31:54,640
aid potentials

751
00:31:54,640 --> 00:31:58,080
also called human scalp potentials which

752
00:31:58,080 --> 00:32:00,559
shows correlated sequences of three

753
00:32:00,559 --> 00:32:03,039
different evoked potentials during

754
00:32:03,039 --> 00:32:05,120
oddball learning tests

755
00:32:05,120 --> 00:32:07,039
an experiment that john

756
00:32:07,039 --> 00:32:10,720
paul ben k and i reported in the 80s

757
00:32:10,720 --> 00:32:14,080
where you'll get a p120 for a mismatch

758
00:32:14,080 --> 00:32:17,679
and then 200 for the arousal activated

759
00:32:17,679 --> 00:32:19,600
by the ordering system

760
00:32:19,600 --> 00:32:22,000
and a p300 for the short-term memory

761
00:32:22,000 --> 00:32:25,279
reset of the category layer thereby

762
00:32:25,279 --> 00:32:28,399
supporting the processing stages

763
00:32:28,399 --> 00:32:31,039
of the search cycle

764
00:32:31,039 --> 00:32:34,480
there was also physiological data from

765
00:32:34,480 --> 00:32:37,120
infra-temporal cortex where categories

766
00:32:37,120 --> 00:32:39,360
are learned early on

767
00:32:39,360 --> 00:32:42,559
from the lab of bob desimone who showed

768
00:32:42,559 --> 00:32:45,840
an active matching process that's reset

769
00:32:45,840 --> 00:32:49,679
between trials during this kind of

770
00:32:49,679 --> 00:32:52,000
event

771
00:32:52,000 --> 00:32:53,840
there's also classical data about

772
00:32:53,840 --> 00:32:56,960
hippocampal mismatch dynamics it's known

773
00:32:56,960 --> 00:32:59,440
that novelty potentials subside as

774
00:32:59,440 --> 00:33:01,679
learning proceeds from numerous

775
00:33:01,679 --> 00:33:04,159
experiments this is as the orienting

776
00:33:04,159 --> 00:33:06,399
system is disengaged

777
00:33:06,399 --> 00:33:08,960
and there's more recent data using

778
00:33:08,960 --> 00:33:11,600
multiple electrode studies from the lab

779
00:33:11,600 --> 00:33:13,200
of errol miller

780
00:33:13,200 --> 00:33:15,360
from prefrontal cortex

781
00:33:15,360 --> 00:33:17,760
and simultaneous recordings in a

782
00:33:17,760 --> 00:33:19,279
hippocampus

783
00:33:19,279 --> 00:33:21,519
and they show there's rapid object

784
00:33:21,519 --> 00:33:23,840
associative learning may occur in

785
00:33:23,840 --> 00:33:26,799
prefrontal cortex which is a projection

786
00:33:26,799 --> 00:33:29,440
of infra-temporal cortex one of the

787
00:33:29,440 --> 00:33:32,000
stages of category learning while the

788
00:33:32,000 --> 00:33:35,039
hippocampus may guide neocortical

789
00:33:35,039 --> 00:33:36,720
plasticity for

790
00:33:36,720 --> 00:33:38,480
by signaling

791
00:33:38,480 --> 00:33:41,120
success or failure well this is just

792
00:33:41,120 --> 00:33:43,279
what happens when the attentional system

793
00:33:43,279 --> 00:33:48,320
interacts with the orienting system

794
00:33:48,320 --> 00:33:50,960
there's also complementary computing in

795
00:33:50,960 --> 00:33:53,600
art in particular the attentional and

796
00:33:53,600 --> 00:33:56,720
orienting system was a complementary as

797
00:33:56,720 --> 00:33:59,519
manifested by the fact that two

798
00:33:59,519 --> 00:34:01,200
event-related potentials are

799
00:34:01,200 --> 00:34:05,840
complementary processing negativity in

800
00:34:05,840 --> 00:34:08,079
processing negativity

801
00:34:08,079 --> 00:34:10,879
is activated when there's a top down

802
00:34:10,879 --> 00:34:13,599
match in the attentional system

803
00:34:13,599 --> 00:34:17,359
the m200 as i just noted is activated

804
00:34:17,359 --> 00:34:20,000
when there's a mismatch that activates

805
00:34:20,000 --> 00:34:22,800
the orienting system and you can just

806
00:34:22,800 --> 00:34:25,359
look across these four rows

807
00:34:25,359 --> 00:34:26,639
and see

808
00:34:26,639 --> 00:34:27,760
that these

809
00:34:27,760 --> 00:34:29,280
two

810
00:34:29,280 --> 00:34:33,199
kinds of erp potentials are manifestly

811
00:34:33,199 --> 00:34:34,960
complementary as

812
00:34:34,960 --> 00:34:37,679
illustrator the complementarity of the

813
00:34:37,679 --> 00:34:40,879
attentional and orienting systems

814
00:34:40,879 --> 00:34:43,119
so this leads us to discuss another

815
00:34:43,119 --> 00:34:45,679
paradigm introduced which i call

816
00:34:45,679 --> 00:34:47,760
complementary computing

817
00:34:47,760 --> 00:34:50,719
that asks what is the nature of brain

818
00:34:50,719 --> 00:34:53,719
specialization

819
00:34:53,760 --> 00:34:56,800
complementary computing introduces new

820
00:34:56,800 --> 00:34:58,400
principles of uncertainty and

821
00:34:58,400 --> 00:35:00,960
complementarity that clarify

822
00:35:00,960 --> 00:35:02,720
why there are multiple

823
00:35:02,720 --> 00:35:05,599
parallel processing streams with

824
00:35:05,599 --> 00:35:08,880
multiple processing stages in our brains

825
00:35:08,880 --> 00:35:11,599
and a beautiful example of that is this

826
00:35:11,599 --> 00:35:13,040
famous image

827
00:35:13,040 --> 00:35:14,960
of the macro circuit of the visual

828
00:35:14,960 --> 00:35:16,960
system from david vanessa and his

829
00:35:16,960 --> 00:35:19,040
colleagues where you can see these

830
00:35:19,040 --> 00:35:21,119
multiple

831
00:35:21,119 --> 00:35:23,599
uh parallel processing streams and the

832
00:35:23,599 --> 00:35:25,359
multiple

833
00:35:25,359 --> 00:35:28,160
stages needed to achieve what i call

834
00:35:28,160 --> 00:35:32,560
hierarchical resolution of uncertainty

835
00:35:32,560 --> 00:35:34,560
but what are complement

836
00:35:34,560 --> 00:35:37,680
complementary properties their analogies

837
00:35:37,680 --> 00:35:40,880
like a key fits into a lock or puzzle

838
00:35:40,880 --> 00:35:44,720
pieces fitting together in words

839
00:35:44,720 --> 00:35:46,800
computing one set of properties at a

840
00:35:46,800 --> 00:35:49,599
processing stage prevents that stage

841
00:35:49,599 --> 00:35:52,320
from computing a complementary set of

842
00:35:52,320 --> 00:35:53,599
properties

843
00:35:53,599 --> 00:35:55,680
these complementary parallel processing

844
00:35:55,680 --> 00:35:58,480
streams are balanced against one another

845
00:35:58,480 --> 00:36:02,320
it's a very yin yang kind of situation

846
00:36:02,320 --> 00:36:04,560
and interactions between the streams

847
00:36:04,560 --> 00:36:05,839
overcome

848
00:36:05,839 --> 00:36:09,839
their complementary weaknesses

849
00:36:09,839 --> 00:36:11,839
in fact there are many complementary

850
00:36:11,839 --> 00:36:13,680
processes that are known in the brain

851
00:36:13,680 --> 00:36:16,880
that have been modeled here is just

852
00:36:16,880 --> 00:36:19,520
five of them there are many more

853
00:36:19,520 --> 00:36:21,760
so this is a basic

854
00:36:21,760 --> 00:36:25,880
principle of brain organization

855
00:36:26,079 --> 00:36:28,320
so in summary so far back propagation

856
00:36:28,320 --> 00:36:30,560
and deep learning do not have

857
00:36:30,560 --> 00:36:32,880
thought to memory activation patterns

858
00:36:32,880 --> 00:36:34,160
including

859
00:36:34,160 --> 00:36:36,160
critical feature patterns so they can't

860
00:36:36,160 --> 00:36:39,599
pay attention indeed they don't have any

861
00:36:39,599 --> 00:36:42,800
fast information processing nor do they

862
00:36:42,800 --> 00:36:44,720
have long-term memory top-down learned

863
00:36:44,720 --> 00:36:48,000
expectations so they can't carry out

864
00:36:48,000 --> 00:36:51,280
hypothesis testing using interactions

865
00:36:51,280 --> 00:36:54,400
short-term and long-term memory traces

866
00:36:54,400 --> 00:36:56,400
indeed there's no neural architecture

867
00:36:56,400 --> 00:36:59,839
there's just an algorithm in this really

868
00:36:59,839 --> 00:37:02,400
great contrast with complementary

869
00:37:02,400 --> 00:37:04,880
computing which discusses the global

870
00:37:04,880 --> 00:37:07,680
organization of our brains

871
00:37:07,680 --> 00:37:09,760
from the very start it was shown how

872
00:37:09,760 --> 00:37:11,680
easy it is to get catastrophic

873
00:37:11,680 --> 00:37:14,800
forgetting and carpenter and i showed it

874
00:37:14,800 --> 00:37:16,160
in art

875
00:37:16,160 --> 00:37:19,119
when we would shut down the art matching

876
00:37:19,119 --> 00:37:22,480
rule then we demonstrated you could get

877
00:37:22,480 --> 00:37:24,640
catastrophic forgetting if you had just

878
00:37:24,640 --> 00:37:25,920
four

879
00:37:25,920 --> 00:37:29,280
input vectors a b c d

880
00:37:29,280 --> 00:37:32,560
presented in the order a b c a d a b c a

881
00:37:32,560 --> 00:37:34,320
d and so on

882
00:37:34,320 --> 00:37:37,040
if they obeyed very simple

883
00:37:37,040 --> 00:37:39,680
subset relationships

884
00:37:39,680 --> 00:37:42,720
and here's a computer simulation of that

885
00:37:42,720 --> 00:37:44,640
here you don't have the arc matching

886
00:37:44,640 --> 00:37:45,520
rule

887
00:37:45,520 --> 00:37:47,040
here's a b

888
00:37:47,040 --> 00:37:48,480
c a d

889
00:37:48,480 --> 00:37:51,359
a b c a d

890
00:37:51,359 --> 00:37:53,040
and you see a

891
00:37:53,040 --> 00:37:55,760
is coded by category one here

892
00:37:55,760 --> 00:37:58,480
by category two here by category one

893
00:37:58,480 --> 00:38:01,440
here two here it never settles down but

894
00:38:01,440 --> 00:38:04,480
as soon as you impose the art matching

895
00:38:04,480 --> 00:38:06,079
rule

896
00:38:06,079 --> 00:38:09,040
learning is complete by the second trial

897
00:38:09,040 --> 00:38:11,040
and after that point you get direct

898
00:38:11,040 --> 00:38:14,160
access to the globally best matching

899
00:38:14,160 --> 00:38:16,079
category

900
00:38:16,079 --> 00:38:17,680
well let's say a little more about

901
00:38:17,680 --> 00:38:19,839
vigilance

902
00:38:19,839 --> 00:38:22,079
vigilance determines what features are

903
00:38:22,079 --> 00:38:24,480
learned in the critical feature pattern

904
00:38:24,480 --> 00:38:26,720
it clarifies how our brains learn

905
00:38:26,720 --> 00:38:28,960
concrete knowledge for some tests and

906
00:38:28,960 --> 00:38:32,240
abstract knowledge for others so in

907
00:38:32,240 --> 00:38:34,400
particular high vigilance leads to

908
00:38:34,400 --> 00:38:37,200
learning of narrow concrete categories

909
00:38:37,200 --> 00:38:40,160
like a category that fires selectively

910
00:38:40,160 --> 00:38:43,839
to a frontal view of your mother's face

911
00:38:43,839 --> 00:38:46,160
low vigilance leads to learning abroad

912
00:38:46,160 --> 00:38:48,880
and abstract categories like everyone

913
00:38:48,880 --> 00:38:50,400
has a face

914
00:38:50,400 --> 00:38:52,400
it should be emphasized that critical

915
00:38:52,400 --> 00:38:54,880
feature patterns are explainable

916
00:38:54,880 --> 00:38:56,400
at every

917
00:38:56,400 --> 00:38:58,480
level of vigilance

918
00:38:58,480 --> 00:39:01,520
it's known

919
00:39:01,520 --> 00:39:03,440
from physiological experiments by

920
00:39:03,440 --> 00:39:05,200
desmond again

921
00:39:05,200 --> 00:39:06,000
that

922
00:39:06,000 --> 00:39:08,160
their vigilance

923
00:39:08,160 --> 00:39:10,800
control in the infra temple cortex which

924
00:39:10,800 --> 00:39:13,760
they showed by studying easy versus

925
00:39:13,760 --> 00:39:15,839
difficult discriminations

926
00:39:15,839 --> 00:39:17,200
in monkeys

927
00:39:17,200 --> 00:39:19,040
and in the difficult condition which

928
00:39:19,040 --> 00:39:20,320
you'd assume would give you high

929
00:39:20,320 --> 00:39:22,960
vigilance as expected you had

930
00:39:22,960 --> 00:39:25,359
enhancement of the responses and

931
00:39:25,359 --> 00:39:28,480
sharpened seal activity to the attended

932
00:39:28,480 --> 00:39:30,720
stimuli

933
00:39:30,720 --> 00:39:33,920
how is vigilance computed well let's say

934
00:39:33,920 --> 00:39:35,839
of input vector

935
00:39:35,839 --> 00:39:39,520
it instates a vector of

936
00:39:39,520 --> 00:39:42,240
activities in feature detectors at the

937
00:39:42,240 --> 00:39:44,320
same time as it tries to activate the

938
00:39:44,320 --> 00:39:47,040
earning system but it this does so

939
00:39:47,040 --> 00:39:50,320
multiplied by a parameter

940
00:39:50,320 --> 00:39:52,320
row which is a sensitivity or game

941
00:39:52,320 --> 00:39:55,119
parameter that's vigilance

942
00:39:55,119 --> 00:39:57,920
and as these features get in state they

943
00:39:57,920 --> 00:40:01,520
try to shut off the orienting system

944
00:40:01,520 --> 00:40:05,599
and if the excitation is less than the

945
00:40:05,599 --> 00:40:07,920
inhibition the orienting system stays

946
00:40:07,920 --> 00:40:08,960
quiet

947
00:40:08,960 --> 00:40:12,560
so the system can resonate and learn

948
00:40:12,560 --> 00:40:14,800
but if inhibition isn't strong enough

949
00:40:14,800 --> 00:40:17,520
the orienting system gets activated you

950
00:40:17,520 --> 00:40:20,160
get reset and search for new categories

951
00:40:20,160 --> 00:40:24,240
is a very simple computation because you

952
00:40:24,240 --> 00:40:27,000
have an orienting system that's

953
00:40:27,000 --> 00:40:30,640
complementary to the attentional system

954
00:40:30,640 --> 00:40:32,640
well how do you change vigilance based

955
00:40:32,640 --> 00:40:34,720
on predictive success

956
00:40:34,720 --> 00:40:37,440
for this we have to go from unsupervised

957
00:40:37,440 --> 00:40:39,920
to supervised art models

958
00:40:39,920 --> 00:40:42,079
so we'll have

959
00:40:42,079 --> 00:40:44,800
an unsupervised art a model an

960
00:40:44,800 --> 00:40:47,280
unsupervised art d model

961
00:40:47,280 --> 00:40:49,680
linked together by a learned associative

962
00:40:49,680 --> 00:40:53,119
map as occurs in fuzzy arcmap and a key

963
00:40:53,119 --> 00:40:56,319
point is you can have an input here

964
00:40:56,319 --> 00:40:59,119
that can create an output there because

965
00:40:59,119 --> 00:41:02,160
you have both bottom up and top down

966
00:41:02,160 --> 00:41:05,359
connections at all these levels

967
00:41:05,359 --> 00:41:08,400
so in this way you can learn many to one

968
00:41:08,400 --> 00:41:10,640
and one to many

969
00:41:10,640 --> 00:41:12,079
maps

970
00:41:12,079 --> 00:41:14,480
one example of a many-to-one map is

971
00:41:14,480 --> 00:41:17,200
let's say you're trying to categorize

972
00:41:17,200 --> 00:41:19,280
visually processed

973
00:41:19,280 --> 00:41:22,960
a letter a which comes in multiple fonts

974
00:41:22,960 --> 00:41:25,280
you'll learn various visual

975
00:41:25,280 --> 00:41:28,079
categories of a based on visual

976
00:41:28,079 --> 00:41:30,240
similarity

977
00:41:30,240 --> 00:41:32,319
at the same time you're learning

978
00:41:32,319 --> 00:41:35,280
auditory categories for saying a

979
00:41:35,280 --> 00:41:37,839
and then the associative map can

980
00:41:37,839 --> 00:41:40,319
map all of these visual categories of

981
00:41:40,319 --> 00:41:44,000
different a's to saying a

982
00:41:44,000 --> 00:41:45,599
but it could have been here that these

983
00:41:45,599 --> 00:41:47,599
inputs were symptoms tests and

984
00:41:47,599 --> 00:41:49,839
treatments in a medical database

985
00:41:49,839 --> 00:41:51,599
prediction

986
00:41:51,599 --> 00:41:53,920
example and you're predicting length of

987
00:41:53,920 --> 00:41:55,599
stay in the hospital

988
00:41:55,599 --> 00:41:57,760
the possibilities here are endless and

989
00:41:57,760 --> 00:42:01,119
then in many applications

990
00:42:01,119 --> 00:42:03,839
or let's say

991
00:42:06,560 --> 00:42:08,079
you're trying to figure out what this

992
00:42:08,079 --> 00:42:10,960
image is and you've learned to say

993
00:42:10,960 --> 00:42:13,599
that's a dog but today you say it's

994
00:42:13,599 --> 00:42:17,119
rover and that causes a mismatch which

995
00:42:17,119 --> 00:42:20,000
drives the search to focus attention on

996
00:42:20,000 --> 00:42:22,880
the particular combination of features

997
00:42:22,880 --> 00:42:25,599
in this door that will identify it as

998
00:42:25,599 --> 00:42:28,560
rover that leads to learning of a visual

999
00:42:28,560 --> 00:42:30,720
category of rover

1000
00:42:30,720 --> 00:42:33,680
an auditory category for the name rover

1001
00:42:33,680 --> 00:42:36,640
an associated map between them and you

1002
00:42:36,640 --> 00:42:40,000
can now simultaneously store expert

1003
00:42:40,000 --> 00:42:43,520
knowledge about that image

1004
00:42:43,520 --> 00:42:45,440
well how do you can jointly minimize

1005
00:42:45,440 --> 00:42:47,200
predictive error and maximize

1006
00:42:47,200 --> 00:42:48,880
generalization

1007
00:42:48,880 --> 00:42:50,960
so that you minimize

1008
00:42:50,960 --> 00:42:53,040
uh using um

1009
00:42:53,040 --> 00:42:55,280
memory resources let me read you an

1010
00:42:55,280 --> 00:42:56,319
answer

1011
00:42:56,319 --> 00:42:59,760
and then show what it means in images

1012
00:42:59,760 --> 00:43:02,640
match tracking realizes a minimax

1013
00:43:02,640 --> 00:43:04,319
learning principle

1014
00:43:04,319 --> 00:43:06,960
namely given a predictive error

1015
00:43:06,960 --> 00:43:09,760
vigilance increases just enough to

1016
00:43:09,760 --> 00:43:12,720
trigger search and thus sacrifices

1017
00:43:12,720 --> 00:43:14,640
the minimum generalization to correct

1018
00:43:14,640 --> 00:43:17,119
the error so let's say you've made a

1019
00:43:17,119 --> 00:43:20,000
prediction that must mean that vigilance

1020
00:43:20,000 --> 00:43:22,800
is less than the analog match between

1021
00:43:22,800 --> 00:43:24,960
bottom up and top down

1022
00:43:24,960 --> 00:43:26,560
but let's say now

1023
00:43:26,560 --> 00:43:27,359
you

1024
00:43:27,359 --> 00:43:29,599
have a mismatch well that'll lead to a

1025
00:43:29,599 --> 00:43:32,160
match tracking signal that bumps

1026
00:43:32,160 --> 00:43:35,280
vigilance up till it's just above the

1027
00:43:35,280 --> 00:43:37,920
analog match just big enough to drive a

1028
00:43:37,920 --> 00:43:40,720
search so you've given up the minimum

1029
00:43:40,720 --> 00:43:42,880
amount of generalization

1030
00:43:42,880 --> 00:43:45,520
to correct the error

1031
00:43:45,520 --> 00:43:47,839
well arc mechanisms like vigilance

1032
00:43:47,839 --> 00:43:50,240
control realized in laminar

1033
00:43:50,240 --> 00:43:52,560
cortical and phalanx circuits the answer

1034
00:43:52,560 --> 00:43:56,800
is yes my phd student max versace and i

1035
00:43:56,800 --> 00:43:58,640
showed this by developing the

1036
00:43:58,640 --> 00:44:02,240
synchronous matching art or smart model

1037
00:44:02,240 --> 00:44:04,359
which introduced a lot more

1038
00:44:04,359 --> 00:44:06,640
neurophysiological and anatomical verse

1039
00:44:06,640 --> 00:44:08,240
similitude

1040
00:44:08,240 --> 00:44:10,240
into the model including spiking

1041
00:44:10,240 --> 00:44:13,119
dynamics laminar cortical circuits

1042
00:44:13,119 --> 00:44:15,560
interacting with specific and

1043
00:44:15,560 --> 00:44:19,119
non-specific thalamic nuclei

1044
00:44:19,119 --> 00:44:21,599
this is another example of laminar

1045
00:44:21,599 --> 00:44:22,880
computing

1046
00:44:22,880 --> 00:44:25,680
and here's a schematic of the model you

1047
00:44:25,680 --> 00:44:28,319
see all the cortical layers with

1048
00:44:28,319 --> 00:44:31,680
identified cells a hierarchy of cortical

1049
00:44:31,680 --> 00:44:34,319
regions interacting with specific

1050
00:44:34,319 --> 00:44:37,760
thalamic nuclei and non-specific

1051
00:44:37,760 --> 00:44:39,920
thalamic nuclei

1052
00:44:39,920 --> 00:44:42,480
a ton of anatomical data got

1053
00:44:42,480 --> 00:44:45,119
functionally explained in this way and

1054
00:44:45,119 --> 00:44:47,359
many other data as well for example we

1055
00:44:47,359 --> 00:44:49,920
showed if you have a good enough match

1056
00:44:49,920 --> 00:44:52,319
between bottom up and top down you're

1057
00:44:52,319 --> 00:44:55,119
going to get fast gamma oscillations

1058
00:44:55,119 --> 00:44:57,839
during attention there was quite a bit

1059
00:44:57,839 --> 00:45:00,560
of data about that already but we also

1060
00:45:00,560 --> 00:45:02,720
showed if you have a big enough mismatch

1061
00:45:02,720 --> 00:45:05,920
you'll get slower beta oscillations that

1062
00:45:05,920 --> 00:45:08,319
wasn't well known

1063
00:45:08,319 --> 00:45:10,079
but since that time there have been

1064
00:45:10,079 --> 00:45:13,200
experiments in at least four labs in

1065
00:45:13,200 --> 00:45:14,800
three different parts of the brain

1066
00:45:14,800 --> 00:45:18,079
confirming that prediction

1067
00:45:18,079 --> 00:45:20,240
most important vigilance control was

1068
00:45:20,240 --> 00:45:21,119
shown

1069
00:45:21,119 --> 00:45:23,760
how to be uh controlled by mismatch

1070
00:45:23,760 --> 00:45:26,480
mediated acetylcholine release

1071
00:45:26,480 --> 00:45:28,480
a big enough mismatch

1072
00:45:28,480 --> 00:45:31,280
in the non-specific thalamic nucleus

1073
00:45:31,280 --> 00:45:34,640
activates nucleus basal minor

1074
00:45:34,640 --> 00:45:35,839
that

1075
00:45:35,839 --> 00:45:38,880
releases acetylcholine and layer 5 cells

1076
00:45:38,880 --> 00:45:41,640
across the cortex reducing after

1077
00:45:41,640 --> 00:45:44,319
hyperpolarization currents and causing

1078
00:45:44,319 --> 00:45:46,720
vigilance to go up

1079
00:45:46,720 --> 00:45:49,359
and i also showed that breakdowns in

1080
00:45:49,359 --> 00:45:52,240
acetylcholine modulation can help to

1081
00:45:52,240 --> 00:45:55,200
explain the symptoms of multiple

1082
00:45:55,200 --> 00:45:58,160
mental disorders

1083
00:45:58,160 --> 00:46:00,800
so as to memory consolidation we know

1084
00:46:00,800 --> 00:46:02,880
there's a dynamic phase of memory

1085
00:46:02,880 --> 00:46:04,640
consolidation

1086
00:46:04,640 --> 00:46:06,880
while the input exemplar still drives

1087
00:46:06,880 --> 00:46:10,000
memory search and before direct access

1088
00:46:10,000 --> 00:46:12,800
occurs but what if the orienting systems

1089
00:46:12,800 --> 00:46:15,280
cut out what if you have a lesion in the

1090
00:46:15,280 --> 00:46:17,359
hippocampus

1091
00:46:17,359 --> 00:46:18,480
well then

1092
00:46:18,480 --> 00:46:21,599
as occurs in medial temporal amnesia

1093
00:46:21,599 --> 00:46:24,400
you get unlimited anterograde amnesia

1094
00:46:24,400 --> 00:46:25,839
because you can't search for new

1095
00:46:25,839 --> 00:46:27,119
categories

1096
00:46:27,119 --> 00:46:30,079
you get limited retrograde amnesia

1097
00:46:30,079 --> 00:46:32,720
because you could have direct access to

1098
00:46:32,720 --> 00:46:35,760
previously learned categories this is a

1099
00:46:35,760 --> 00:46:37,680
failure of consolidation which is

1100
00:46:37,680 --> 00:46:41,200
mediated by the rna system you get

1101
00:46:41,200 --> 00:46:43,599
defective novelty reactions because that

1102
00:46:43,599 --> 00:46:44,960
is also

1103
00:46:44,960 --> 00:46:47,599
mediated by the orienting system

1104
00:46:47,599 --> 00:46:49,680
and memory consolidation novelty

1105
00:46:49,680 --> 00:46:52,560
detection mediated by the same structure

1106
00:46:52,560 --> 00:46:53,920
for the same

1107
00:46:53,920 --> 00:46:55,280
reason

1108
00:46:55,280 --> 00:46:58,400
there's normal priming because priming

1109
00:46:58,400 --> 00:47:01,359
occurs within the attentional system

1110
00:47:01,359 --> 00:47:03,680
learning of the first item dominates you

1111
00:47:03,680 --> 00:47:06,319
can get some learning but you can't then

1112
00:47:06,319 --> 00:47:07,839
search

1113
00:47:07,839 --> 00:47:09,920
and there's an impaired ability to

1114
00:47:09,920 --> 00:47:12,880
attend to relevant dimensions of stimuli

1115
00:47:12,880 --> 00:47:14,960
again because you can't

1116
00:47:14,960 --> 00:47:16,480
search

1117
00:47:16,480 --> 00:47:19,200
so now where does intra-temporal cortex

1118
00:47:19,200 --> 00:47:22,319
fit in within the larger brain

1119
00:47:22,319 --> 00:47:27,200
i introduced the predictive art or part

1120
00:47:27,200 --> 00:47:30,160
algorithm uh a model

1121
00:47:30,160 --> 00:47:32,400
in order to show how the prefrontal

1122
00:47:32,400 --> 00:47:34,880
cortex among other things learns to

1123
00:47:34,880 --> 00:47:36,400
control all

1124
00:47:36,400 --> 00:47:38,640
higher order intelligence you can find

1125
00:47:38,640 --> 00:47:42,400
that in a 2018 paper on my web page i

1126
00:47:42,400 --> 00:47:46,240
also published it open access

1127
00:47:46,240 --> 00:47:49,680
and in this macro circuit

1128
00:47:49,680 --> 00:47:52,319
these green areas of prefrontal cortex

1129
00:47:52,319 --> 00:47:56,000
control processes like working memory

1130
00:47:56,000 --> 00:47:58,240
learned plans

1131
00:47:58,240 --> 00:48:01,520
prediction optimized action

1132
00:48:01,520 --> 00:48:04,720
these regions in red control processes

1133
00:48:04,720 --> 00:48:07,839
like reinforcement learning emotion

1134
00:48:07,839 --> 00:48:11,119
motivation adaptively timed learning

1135
00:48:11,119 --> 00:48:12,960
the category learning i've talked about

1136
00:48:12,960 --> 00:48:14,160
in i.t

1137
00:48:14,160 --> 00:48:17,280
is just in those two regions all these

1138
00:48:17,280 --> 00:48:19,839
processes

1139
00:48:19,839 --> 00:48:22,880
uh control visual perception and there

1140
00:48:22,880 --> 00:48:25,680
are detailed models of all of these

1141
00:48:25,680 --> 00:48:28,319
regions and their interactions now

1142
00:48:28,319 --> 00:48:30,880
and each brain region in nature and in

1143
00:48:30,880 --> 00:48:32,880
predictive art carries out a different

1144
00:48:32,880 --> 00:48:37,280
function contrasting really dramatically

1145
00:48:37,280 --> 00:48:39,920
with the homogeneous organization of a

1146
00:48:39,920 --> 00:48:41,119
typical

1147
00:48:41,119 --> 00:48:44,079
deep learning network

1148
00:48:44,079 --> 00:48:46,800
so i've told you just a little bit about

1149
00:48:46,800 --> 00:48:48,720
some aspects of cognition and why

1150
00:48:48,720 --> 00:48:50,640
they're explainable

1151
00:48:50,640 --> 00:48:53,280
but if you put in all the biological

1152
00:48:53,280 --> 00:48:55,760
models of perceptual cognition emotion

1153
00:48:55,760 --> 00:48:58,880
and action they're all explainable

1154
00:48:58,880 --> 00:49:01,760
and then you can assert

1155
00:49:01,760 --> 00:49:04,240
how perceptual and cognitive processes

1156
00:49:04,240 --> 00:49:07,359
use art like excitatory matching and

1157
00:49:07,359 --> 00:49:09,280
match-based learning

1158
00:49:09,280 --> 00:49:10,359
to create

1159
00:49:10,359 --> 00:49:13,559
self-stabilizing attentive and conscious

1160
00:49:13,559 --> 00:49:16,559
representations of objects and events

1161
00:49:16,559 --> 00:49:19,839
that embody increasing expertise about

1162
00:49:19,839 --> 00:49:21,280
the world

1163
00:49:21,280 --> 00:49:23,760
moreover complementary spatial and motor

1164
00:49:23,760 --> 00:49:26,480
processes that i couldn't mention at all

1165
00:49:26,480 --> 00:49:28,880
use inhibitory matching and mismatch

1166
00:49:28,880 --> 00:49:32,319
based learning to continually update

1167
00:49:32,319 --> 00:49:34,720
spatial and motor representations to

1168
00:49:34,720 --> 00:49:38,079
compensate for bodily changes throughout

1169
00:49:38,079 --> 00:49:39,119
life

1170
00:49:39,119 --> 00:49:41,880
taken together they provide a

1171
00:49:41,880 --> 00:49:43,680
self-stabilizing perceptual and

1172
00:49:43,680 --> 00:49:45,520
cognitive front end

1173
00:49:45,520 --> 00:49:47,599
for conscious awareness and knowledge

1174
00:49:47,599 --> 00:49:49,839
acquisition

1175
00:49:49,839 --> 00:49:50,960
which can

1176
00:49:50,960 --> 00:49:54,160
intelligently manipulate the more labile

1177
00:49:54,160 --> 00:49:57,200
spatial and motor processes that enable

1178
00:49:57,200 --> 00:50:00,240
our changing bodies to act effectively

1179
00:50:00,240 --> 00:50:02,400
on a changing world

1180
00:50:02,400 --> 00:50:04,800
and when you put them all together they

1181
00:50:04,800 --> 00:50:06,800
provide a blueprint for designing

1182
00:50:06,800 --> 00:50:08,880
autonomous adaptive algorithms and

1183
00:50:08,880 --> 00:50:09,839
mobile

1184
00:50:09,839 --> 00:50:12,800
robots with behaviors humans can

1185
00:50:12,800 --> 00:50:15,280
understand and control because they're

1186
00:50:15,280 --> 00:50:17,359
both explainable

1187
00:50:17,359 --> 00:50:19,040
and reliable

1188
00:50:19,040 --> 00:50:22,720
see my webpage sites.vu.edu

1189
00:50:22,720 --> 00:50:24,240
or steve g

1190
00:50:24,240 --> 00:50:27,280
for these um

1191
00:50:27,280 --> 00:50:28,480
models

1192
00:50:28,480 --> 00:50:30,640
and with that i'd like to

1193
00:50:30,640 --> 00:50:33,760
thank you very much for your

1194
00:50:33,760 --> 00:50:36,079
attention

1195
00:50:36,079 --> 00:50:38,160
uh before we get started what i want to

1196
00:50:38,160 --> 00:50:39,200
say so

1197
00:50:39,200 --> 00:50:41,520
i should say that everything i've talked

1198
00:50:41,520 --> 00:50:43,440
about and much more

1199
00:50:43,440 --> 00:50:45,839
is in my book conscious mind resonant

1200
00:50:45,839 --> 00:50:47,040
brain

1201
00:50:47,040 --> 00:50:50,240
how each brain makes a mind to those who

1202
00:50:50,240 --> 00:50:52,280
don't know it's

1203
00:50:52,280 --> 00:50:55,359
self-contained and non-technical

1204
00:50:55,359 --> 00:50:58,880
it's written in a conversational style

1205
00:50:58,880 --> 00:51:01,119
so that people who know nothing about

1206
00:51:01,119 --> 00:51:03,040
the mind or the brain

1207
00:51:03,040 --> 00:51:05,440
can enjoy reading it and

1208
00:51:05,440 --> 00:51:08,000
i have friends who are a rabbi a

1209
00:51:08,000 --> 00:51:10,559
minister a

1210
00:51:10,559 --> 00:51:14,079
painter a gallery owner a lawyer a

1211
00:51:14,079 --> 00:51:15,599
social worker

1212
00:51:15,599 --> 00:51:18,319
who've all been enjoying reading it

1213
00:51:18,319 --> 00:51:22,480
also it's a big book it's almost 800

1214
00:51:22,480 --> 00:51:26,079
double column pages with over 600 color

1215
00:51:26,079 --> 00:51:28,079
figures so everything

1216
00:51:28,079 --> 00:51:30,079
is illustrated

1217
00:51:30,079 --> 00:51:32,880
but instead of costing a hundred fifty

1218
00:51:32,880 --> 00:51:34,559
dollars it costs

1219
00:51:34,559 --> 00:51:36,000
thirty 35

1220
00:51:36,000 --> 00:51:39,599
for the hard copy and only 17 for the

1221
00:51:39,599 --> 00:51:41,200
kindle because

1222
00:51:41,200 --> 00:51:43,760
i spent a lot of my own money

1223
00:51:43,760 --> 00:51:45,760
so that people who are interested in the

1224
00:51:45,760 --> 00:51:47,040
topic

1225
00:51:47,040 --> 00:51:47,920
can

1226
00:51:47,920 --> 00:51:50,640
read it and one other comment

1227
00:51:50,640 --> 00:51:52,240
if people

1228
00:51:52,240 --> 00:51:55,839
do have questions or comments

1229
00:51:55,839 --> 00:51:57,839
about my lecture or anything they read

1230
00:51:57,839 --> 00:52:00,079
in the book my email

1231
00:52:00,079 --> 00:52:02,160
is just steve

1232
00:52:02,160 --> 00:52:04,880
s t e e at

1233
00:52:04,880 --> 00:52:07,920
b-u austin university

1234
00:52:07,920 --> 00:52:10,880
dot e-d-u and i'll be happy

1235
00:52:10,880 --> 00:52:13,599
to try to reply so

1236
00:52:13,599 --> 00:52:14,960
thank you

1237
00:52:14,960 --> 00:52:17,680
now uh some researchers an explainable

1238
00:52:17,680 --> 00:52:20,480
ai people like lena de giovannia and

1239
00:52:20,480 --> 00:52:22,160
antonio di checo

1240
00:52:22,160 --> 00:52:25,119
demand that any explainable ai should at

1241
00:52:25,119 --> 00:52:28,000
the very least meet these four criteria

1242
00:52:28,000 --> 00:52:30,720
to be fair not biased in one way or

1243
00:52:30,720 --> 00:52:34,240
another to be accountable or reliable

1244
00:52:34,240 --> 00:52:36,480
to be secure against malicious hacker

1245
00:52:36,480 --> 00:52:39,040
attacks and not to be fooled easily

1246
00:52:39,040 --> 00:52:41,599
and also to be transparent now you

1247
00:52:41,599 --> 00:52:44,319
explained how adaptive resonance theory

1248
00:52:44,319 --> 00:52:47,680
or art and by the way i gotta say i love

1249
00:52:47,680 --> 00:52:49,680
your creative and clever use of acronyms

1250
00:52:49,680 --> 00:52:51,680
for your models

1251
00:52:51,680 --> 00:52:53,760
my favorite one is sovereign model

1252
00:52:53,760 --> 00:52:56,800
self-organizing vision uh expectation

1253
00:52:56,800 --> 00:52:58,839
recognition emotion intelligent

1254
00:52:58,839 --> 00:53:01,520
goal-oriented navigation if i'm great

1255
00:53:01,520 --> 00:53:02,880
amazing

1256
00:53:02,880 --> 00:53:06,079
anyway you explained how art can address

1257
00:53:06,079 --> 00:53:08,000
and overcome the issues of

1258
00:53:08,000 --> 00:53:11,200
accountability security and transparency

1259
00:53:11,200 --> 00:53:13,760
of current deep learning approaches

1260
00:53:13,760 --> 00:53:16,559
but it seems that this fairness issue

1261
00:53:16,559 --> 00:53:19,839
aka the problem of algorithmic bias has

1262
00:53:19,839 --> 00:53:22,240
also been a growing concern lately

1263
00:53:22,240 --> 00:53:24,160
especially since it's regarded by some

1264
00:53:24,160 --> 00:53:26,240
researchers like antonio badia as a

1265
00:53:26,240 --> 00:53:29,440
practically intractable problem so i

1266
00:53:29,440 --> 00:53:32,319
wanted to ask in what ways do you think

1267
00:53:32,319 --> 00:53:34,559
art can contribute to the

1268
00:53:34,559 --> 00:53:36,880
ongoing quest for mitigating this

1269
00:53:36,880 --> 00:53:39,280
problem

1270
00:53:39,440 --> 00:53:40,839
well when

1271
00:53:40,839 --> 00:53:42,880
um ali

1272
00:53:42,880 --> 00:53:45,119
sent me this question i said well first

1273
00:53:45,119 --> 00:53:46,720
i'd like you to

1274
00:53:46,720 --> 00:53:49,920
send me a definition of algorithmic bias

1275
00:53:49,920 --> 00:53:50,960
that

1276
00:53:50,960 --> 00:53:53,280
will clarify what you have in mind so

1277
00:53:53,280 --> 00:53:55,280
that i know what i'm trying to respond

1278
00:53:55,280 --> 00:53:58,160
to and you wrote me that you borrowed

1279
00:53:58,160 --> 00:54:00,079
the term from body's book the

1280
00:54:00,079 --> 00:54:02,400
information manifold

1281
00:54:02,400 --> 00:54:05,559
and you sent me a quote from page

1282
00:54:05,559 --> 00:54:07,440
247

1283
00:54:07,440 --> 00:54:09,119
that i will

1284
00:54:09,119 --> 00:54:11,760
quote in part before

1285
00:54:11,760 --> 00:54:15,440
i respond to that background information

1286
00:54:15,440 --> 00:54:17,680
so there are two main reasons for

1287
00:54:17,680 --> 00:54:19,119
algorithmic

1288
00:54:19,119 --> 00:54:21,040
approach to decision making that may

1289
00:54:21,040 --> 00:54:23,760
result in unfair outcomes either at the

1290
00:54:23,760 --> 00:54:26,240
individual or group level

1291
00:54:26,240 --> 00:54:29,280
one is that data used is biased and

1292
00:54:29,280 --> 00:54:31,040
another is that the

1293
00:54:31,040 --> 00:54:33,680
algorithm analyzes the data in such a

1294
00:54:33,680 --> 00:54:37,280
way that it yields biased results

1295
00:54:37,280 --> 00:54:38,960
the basic point to remember is that

1296
00:54:38,960 --> 00:54:40,799
algorithms are designed to achieve a

1297
00:54:40,799 --> 00:54:41,920
certain

1298
00:54:41,920 --> 00:54:44,640
goal not created naturally by evolution

1299
00:54:44,640 --> 00:54:46,000
or accident

1300
00:54:46,000 --> 00:54:47,920
thus most algorithms are written to

1301
00:54:47,920 --> 00:54:50,559
detect certain patterns of interest

1302
00:54:50,559 --> 00:54:54,480
for a particular objective not just any

1303
00:54:54,480 --> 00:54:56,319
pattern

1304
00:54:56,319 --> 00:54:58,799
to be able to pick out some patterns in

1305
00:54:58,799 --> 00:55:01,599
disregard others program is

1306
00:55:01,599 --> 00:55:04,400
build a model of the data by listing

1307
00:55:04,400 --> 00:55:06,319
expectations

1308
00:55:06,319 --> 00:55:08,480
about what data should be like in order

1309
00:55:08,480 --> 00:55:11,920
to qualify as relevant to the problem

1310
00:55:11,920 --> 00:55:15,480
well as i'll explain below

1311
00:55:15,480 --> 00:55:17,920
self-organizing learning classification

1312
00:55:17,920 --> 00:55:20,319
prediction models like adaptive

1313
00:55:20,319 --> 00:55:23,280
resonance theory or art overcome all the

1314
00:55:23,280 --> 00:55:24,559
problems

1315
00:55:24,559 --> 00:55:27,359
it's a general purpose device but why

1316
00:55:27,359 --> 00:55:30,640
don't i try to answer that

1317
00:55:30,640 --> 00:55:33,359
as part of my replies to

1318
00:55:33,359 --> 00:55:37,119
ali's subsequent questions

1319
00:55:38,559 --> 00:55:40,640
okay thank you so much

1320
00:55:40,640 --> 00:55:42,000
now uh

1321
00:55:42,000 --> 00:55:45,359
as you also mentioned in your lecture in

1322
00:55:45,359 --> 00:55:49,440
1988 you pointed out 17 issues with back

1323
00:55:49,440 --> 00:55:51,599
propagation in one of your

1324
00:55:51,599 --> 00:55:53,520
most famous and highly cited papers on

1325
00:55:53,520 --> 00:55:56,000
non-linear neural network

1326
00:55:56,000 --> 00:55:57,200
so

1327
00:55:57,200 --> 00:56:01,119
it's been 40 34 years now now do you see

1328
00:56:01,119 --> 00:56:03,440
any fundamental copernican change of

1329
00:56:03,440 --> 00:56:05,119
perspective happening in deep learning

1330
00:56:05,119 --> 00:56:08,240
research or we still keep uh we're still

1331
00:56:08,240 --> 00:56:10,799
keep adding epicycle upon epicycle to

1332
00:56:10,799 --> 00:56:13,200
our ptolemaic model

1333
00:56:13,200 --> 00:56:16,640
well you've sort of anticipated what i'm

1334
00:56:16,640 --> 00:56:19,520
going to say and as i said in my

1335
00:56:19,520 --> 00:56:22,079
lecture various investigators and i

1336
00:56:22,079 --> 00:56:23,119
mentioned

1337
00:56:23,119 --> 00:56:24,720
cloon

1338
00:56:24,720 --> 00:56:27,599
kirkpatrick and velas

1339
00:56:27,599 --> 00:56:30,319
have recently attempted to modify deep

1340
00:56:30,319 --> 00:56:32,559
learning to overcome some of his

1341
00:56:32,559 --> 00:56:35,760
problems but as ali just mentioned

1342
00:56:35,760 --> 00:56:38,319
my lecture noted that at least to my

1343
00:56:38,319 --> 00:56:41,040
mind they're like epic cycles

1344
00:56:41,040 --> 00:56:43,760
that are added to a kind of ptolemaic

1345
00:56:43,760 --> 00:56:45,200
model

1346
00:56:45,200 --> 00:56:47,440
of the solar system too it comes up

1347
00:56:47,440 --> 00:56:50,319
overcome some of his its problems

1348
00:56:50,319 --> 00:56:52,240
but as we all know

1349
00:56:52,240 --> 00:56:55,839
the ptolemaic model ultimately crashed

1350
00:56:55,839 --> 00:56:58,200
because it was both qualitatively and

1351
00:56:58,200 --> 00:57:00,480
quantitatively wrong

1352
00:57:00,480 --> 00:57:02,319
and they could only be solved by

1353
00:57:02,319 --> 00:57:04,880
throwing out the ptolemaic model

1354
00:57:04,880 --> 00:57:07,200
and replacing it with the copernican

1355
00:57:07,200 --> 00:57:08,319
model

1356
00:57:08,319 --> 00:57:11,520
that became the basis for modern

1357
00:57:11,520 --> 00:57:14,319
astronomy and astrophysics

1358
00:57:14,319 --> 00:57:17,359
so art overcomes foundational deep

1359
00:57:17,359 --> 00:57:19,119
learning problems

1360
00:57:19,119 --> 00:57:22,000
that can't be solved using epicycles and

1361
00:57:22,000 --> 00:57:23,680
had already

1362
00:57:23,680 --> 00:57:24,880
done it

1363
00:57:24,880 --> 00:57:28,880
shortly after i introduced it in 1976

1364
00:57:28,880 --> 00:57:32,079
and i it can't be over emphasized

1365
00:57:32,079 --> 00:57:34,240
as i noted in my lecture deep learning

1366
00:57:34,240 --> 00:57:36,400
is untrustworthy

1367
00:57:36,400 --> 00:57:39,200
because it's not explainable

1368
00:57:39,200 --> 00:57:41,760
and it's unreliable

1369
00:57:41,760 --> 00:57:44,160
because it can experience catastrophic

1370
00:57:44,160 --> 00:57:45,599
forgetting

1371
00:57:45,599 --> 00:57:48,079
and that happens for a basic reason deep

1372
00:57:48,079 --> 00:57:50,720
learning just like backprop

1373
00:57:50,720 --> 00:57:53,040
which is its learning engine is just a

1374
00:57:53,040 --> 00:57:54,400
feed forward

1375
00:57:54,400 --> 00:57:57,440
adaptive filter

1376
00:57:57,440 --> 00:57:59,359
so as you know in your question i

1377
00:57:59,359 --> 00:58:01,359
describe these two problems in addition

1378
00:58:01,359 --> 00:58:03,280
to 15 others

1379
00:58:03,280 --> 00:58:05,599
in my offsited article that i published

1380
00:58:05,599 --> 00:58:08,480
in 1988 in the first issue

1381
00:58:08,480 --> 00:58:10,559
of neural networks

1382
00:58:10,559 --> 00:58:13,839
and i also showed them that art

1383
00:58:13,839 --> 00:58:16,880
had already solved the problems in 1976

1384
00:58:16,880 --> 00:58:17,839
and

1385
00:58:17,839 --> 00:58:19,280
what i find

1386
00:58:19,280 --> 00:58:21,040
sad

1387
00:58:21,040 --> 00:58:23,040
is that back propagation and deep

1388
00:58:23,040 --> 00:58:26,000
learning architects like jeff hinton

1389
00:58:26,000 --> 00:58:28,559
who knows all of this background

1390
00:58:28,559 --> 00:58:31,520
never mentioned his history

1391
00:58:31,520 --> 00:58:32,720
um

1392
00:58:32,720 --> 00:58:34,960
and keep talking about making deep

1393
00:58:34,960 --> 00:58:36,400
learning explain

1394
00:58:36,400 --> 00:58:38,400
the brain

1395
00:58:38,400 --> 00:58:40,400
but it can't explain the brain because

1396
00:58:40,400 --> 00:58:42,160
its foundation

1397
00:58:42,160 --> 00:58:44,799
is contradicted by basic

1398
00:58:44,799 --> 00:58:48,240
psychological and neural

1399
00:58:48,839 --> 00:58:51,280
data yes

1400
00:58:51,280 --> 00:58:54,720
great in the deep learning community

1401
00:58:54,720 --> 00:58:58,240
i like comparative discussion

1402
00:58:58,240 --> 00:59:00,400
and criticism

1403
00:59:00,400 --> 00:59:05,520
but i don't like solipsism in science

1404
00:59:05,520 --> 00:59:07,359
great thank you

1405
00:59:07,359 --> 00:59:08,720
now uh

1406
00:59:08,720 --> 00:59:10,160
on slides

1407
00:59:10,160 --> 00:59:12,240
number 50 of your presentation you

1408
00:59:12,240 --> 00:59:13,680
pointed out that

1409
00:59:13,680 --> 00:59:16,880
art is inconsistent with models where

1410
00:59:16,880 --> 00:59:19,280
top-down matches suppressive such as

1411
00:59:19,280 --> 00:59:21,200
bayesian explaining away

1412
00:59:21,200 --> 00:59:24,720
a similar view is evident on page 195 of

1413
00:59:24,720 --> 00:59:26,880
conscious mind resonant brain

1414
00:59:26,880 --> 00:59:29,119
to which you also add one of many

1415
00:59:29,119 --> 00:59:30,799
serious problems

1416
00:59:30,799 --> 00:59:32,960
of the bayesian models is that fully

1417
00:59:32,960 --> 00:59:35,040
suppressive matching circuits cannot

1418
00:59:35,040 --> 00:59:37,920
solve the stability plasticity dilemma

1419
00:59:37,920 --> 00:59:40,000
now would you care to further

1420
00:59:40,000 --> 00:59:42,240
elaborate on this point

1421
00:59:42,240 --> 00:59:44,240
sure um

1422
00:59:44,240 --> 00:59:47,839
my lecture and my book summarizes

1423
00:59:47,839 --> 00:59:48,720
uh

1424
00:59:48,720 --> 00:59:49,760
my book

1425
00:59:49,760 --> 00:59:51,680
my lecture couldn't go into a lot of it

1426
00:59:51,680 --> 00:59:53,839
some of the copious

1427
00:59:53,839 --> 00:59:56,559
psychological anatomical and

1428
00:59:56,559 --> 00:59:58,240
neurophysiological

1429
00:59:58,240 --> 01:00:01,040
evidence

1430
01:00:01,040 --> 01:00:03,440
expectations

1431
01:00:03,440 --> 01:00:05,200
which obey what

1432
01:00:05,200 --> 01:00:08,079
uh gail carpenter and i call the art

1433
01:00:08,079 --> 01:00:09,839
matching rule

1434
01:00:09,839 --> 01:00:12,319
are matched against bottom-up input

1435
01:00:12,319 --> 01:00:13,599
patterns

1436
01:00:13,599 --> 01:00:16,319
and as the lecture briefly noted the art

1437
01:00:16,319 --> 01:00:19,280
matching rule is defined by a modulatory

1438
01:00:19,280 --> 01:00:20,880
on center

1439
01:00:20,880 --> 01:00:23,599
off surround network

1440
01:00:23,599 --> 01:00:26,839
and the modulatory on center is

1441
01:00:26,839 --> 01:00:31,040
excitatory however acting by itself

1442
01:00:31,040 --> 01:00:34,960
it can't fully excite its target cells

1443
01:00:34,960 --> 01:00:38,240
it can prime them sensitize

1444
01:00:38,240 --> 01:00:41,440
excuse or modulate them

1445
01:00:41,440 --> 01:00:43,760
to be ready to fire vigorously when

1446
01:00:43,760 --> 01:00:46,480
matched bottom-up inputs

1447
01:00:46,480 --> 01:00:47,839
arrive

1448
01:00:47,839 --> 01:00:50,240
and when there is a good enough match

1449
01:00:50,240 --> 01:00:52,640
between the bottom-up inputs and an

1450
01:00:52,640 --> 01:00:53,599
active

1451
01:00:53,599 --> 01:00:56,000
top-down expectation

1452
01:00:56,000 --> 01:00:58,319
that's reading out a circuit that obeys

1453
01:00:58,319 --> 01:01:00,240
the art matching rule

1454
01:01:00,240 --> 01:01:02,400
that's when you get what i

1455
01:01:02,400 --> 01:01:04,400
noted in my lecture

1456
01:01:04,400 --> 01:01:06,319
what i call a feature

1457
01:01:06,319 --> 01:01:10,000
category resonance because it develops

1458
01:01:10,000 --> 01:01:12,480
between the matched or intended features

1459
01:01:12,480 --> 01:01:14,960
and the recognition category

1460
01:01:14,960 --> 01:01:17,040
that they activate

1461
01:01:17,040 --> 01:01:18,799
and it's this resonance that

1462
01:01:18,799 --> 01:01:21,599
synchronizes and gain amplifies

1463
01:01:21,599 --> 01:01:23,760
the match speech as well

1464
01:01:23,760 --> 01:01:27,599
suppressing the mismatch features

1465
01:01:27,599 --> 01:01:30,079
and that sustained

1466
01:01:30,079 --> 01:01:32,640
resonance is important because it's

1467
01:01:32,640 --> 01:01:36,000
sustained long enough to drive learning

1468
01:01:36,000 --> 01:01:38,559
in the more slowly varying adaptive ways

1469
01:01:38,559 --> 01:01:40,240
of the active

1470
01:01:40,240 --> 01:01:42,240
bottom-up filter

1471
01:01:42,240 --> 01:01:45,680
and learn top-down expectation

1472
01:01:45,680 --> 01:01:49,599
it's because resonance triggers learning

1473
01:01:49,599 --> 01:01:51,920
that i call the theory adaptive

1474
01:01:51,920 --> 01:01:54,880
resonance theory

1475
01:01:54,880 --> 01:01:56,799
and the art matching rule avoids

1476
01:01:56,799 --> 01:01:59,200
catastrophic forgetting as i briefly

1477
01:01:59,200 --> 01:02:00,400
mentioned

1478
01:02:00,400 --> 01:02:03,599
in the lecture because it suppresses

1479
01:02:03,599 --> 01:02:05,760
irrelevant features

1480
01:02:05,760 --> 01:02:07,680
using its off surround while it's

1481
01:02:07,680 --> 01:02:11,039
amplifying and focusing attention

1482
01:02:11,039 --> 01:02:13,359
on the critical features

1483
01:02:13,359 --> 01:02:15,520
that regulate both bottom-up and

1484
01:02:15,520 --> 01:02:17,359
top-down learning

1485
01:02:17,359 --> 01:02:19,280
as well as

1486
01:02:19,280 --> 01:02:22,160
successful predictions

1487
01:02:22,160 --> 01:02:24,079
because they're relevant they've been

1488
01:02:24,079 --> 01:02:26,559
selected by previous

1489
01:02:26,559 --> 01:02:28,960
learning experiences

1490
01:02:28,960 --> 01:02:32,079
to which discover the set of features

1491
01:02:32,079 --> 01:02:35,359
that are predictive or causal

1492
01:02:35,359 --> 01:02:38,319
in a given situation

1493
01:02:38,319 --> 01:02:40,400
and along the way

1494
01:02:40,400 --> 01:02:43,920
not only does the art matching rule

1495
01:02:43,920 --> 01:02:46,640
achieve causality and predictions

1496
01:02:46,640 --> 01:02:47,599
although

1497
01:02:47,599 --> 01:02:49,599
as the world changes you have to update

1498
01:02:49,599 --> 01:02:50,400
your

1499
01:02:50,400 --> 01:02:53,359
causal explanations it also solves the

1500
01:02:53,359 --> 01:02:57,280
stability plasticity dilemma

1501
01:02:57,280 --> 01:02:59,440
in brief purely suppressive matching

1502
01:02:59,440 --> 01:03:01,280
can't do any of this

1503
01:03:01,280 --> 01:03:04,079
it shuts off the expected data

1504
01:03:04,079 --> 01:03:06,799
and so it can't focus attention or learn

1505
01:03:06,799 --> 01:03:08,480
about it

1506
01:03:08,480 --> 01:03:10,319
and um

1507
01:03:10,319 --> 01:03:13,680
there is fully suppressive matching

1508
01:03:13,680 --> 01:03:14,799
in

1509
01:03:14,799 --> 01:03:17,839
a spatial and modal learning

1510
01:03:17,839 --> 01:03:20,799
but that isn't learning

1511
01:03:20,799 --> 01:03:22,400
to be expert

1512
01:03:22,400 --> 01:03:24,319
about the world

1513
01:03:24,319 --> 01:03:26,480
i could explain that more if you want to

1514
01:03:26,480 --> 01:03:27,599
know but

1515
01:03:27,599 --> 01:03:30,559
that's also in my book and these two

1516
01:03:30,559 --> 01:03:32,559
kinds of learning

1517
01:03:32,559 --> 01:03:34,079
the

1518
01:03:34,079 --> 01:03:36,640
excitatory match-based learning and the

1519
01:03:36,640 --> 01:03:39,119
inhibitory dispatch learning

1520
01:03:39,119 --> 01:03:41,440
are computational complementary it's

1521
01:03:41,440 --> 01:03:43,280
another example

1522
01:03:43,280 --> 01:03:46,640
of complementary computing and

1523
01:03:46,640 --> 01:03:48,559
the match based learning goes on in the

1524
01:03:48,559 --> 01:03:50,799
ventral or what cortical stream and the

1525
01:03:50,799 --> 01:03:52,640
mismatch learning

1526
01:03:52,640 --> 01:03:54,000
goes on in

1527
01:03:54,000 --> 01:03:56,559
the where or

1528
01:03:56,559 --> 01:03:58,799
dorsal cortical stream

1529
01:03:58,799 --> 01:04:00,960
the watch stream for perception and

1530
01:04:00,960 --> 01:04:03,039
categorization and prediction

1531
01:04:03,039 --> 01:04:05,680
the where stream for spatial

1532
01:04:05,680 --> 01:04:08,400
representation and action and then

1533
01:04:08,400 --> 01:04:10,319
you need what to wear and where to what

1534
01:04:10,319 --> 01:04:12,559
interactions

1535
01:04:12,559 --> 01:04:14,400
so that you can

1536
01:04:14,400 --> 01:04:16,799
reach for and otherwise engage through

1537
01:04:16,799 --> 01:04:18,799
approach and what have you

1538
01:04:18,799 --> 01:04:20,559
look at reach for

1539
01:04:20,559 --> 01:04:21,760
approach

1540
01:04:21,760 --> 01:04:25,720
to things that you've recognized

1541
01:04:26,160 --> 01:04:27,920
thank you now following from the

1542
01:04:27,920 --> 01:04:30,480
previous question and uh considering

1543
01:04:30,480 --> 01:04:32,640
that the free energy principle and

1544
01:04:32,640 --> 01:04:35,119
active inference framework as works in

1545
01:04:35,119 --> 01:04:37,440
progress are related to predictive

1546
01:04:37,440 --> 01:04:40,240
coding and bayesian brain hypothesis

1547
01:04:40,240 --> 01:04:42,240
what is your view on the extent of

1548
01:04:42,240 --> 01:04:44,880
compatibility between art and active

1549
01:04:44,880 --> 01:04:46,000
inference

1550
01:04:46,000 --> 01:04:47,839
because despite some prima facie

1551
01:04:47,839 --> 01:04:50,720
similarities between the two

1552
01:04:50,720 --> 01:04:52,400
do you see them as fundamentally

1553
01:04:52,400 --> 01:04:55,839
incompatible or irreconcilable

1554
01:04:55,839 --> 01:04:57,760
and how could this

1555
01:04:57,760 --> 01:05:00,000
how could this issue be rigorously

1556
01:05:00,000 --> 01:05:02,240
evaluated and positively resolved in

1557
01:05:02,240 --> 01:05:04,559
terms of reconciliation or integration

1558
01:05:04,559 --> 01:05:07,760
of art and act and active inference or

1559
01:05:07,760 --> 01:05:10,079
otherwise because you see

1560
01:05:10,079 --> 01:05:13,119
to add some more context here um smith

1561
01:05:13,119 --> 01:05:15,280
smith at all in their recent paper and

1562
01:05:15,280 --> 01:05:16,880
active inference approach to modeling

1563
01:05:16,880 --> 01:05:18,400
structure learning

1564
01:05:18,400 --> 01:05:20,799
uh have stated that although they are

1565
01:05:20,799 --> 01:05:22,880
they have not explicitly incorporated

1566
01:05:22,880 --> 01:05:23,839
arts

1567
01:05:23,839 --> 01:05:25,680
top-down attentional and feedback

1568
01:05:25,680 --> 01:05:26,880
mechanisms

1569
01:05:26,880 --> 01:05:29,119
there are mechanisms within their active

1570
01:05:29,119 --> 01:05:31,920
inference-based model which they believe

1571
01:05:31,920 --> 01:05:33,839
are quite similar to top-down and

1572
01:05:33,839 --> 01:05:36,720
bottom-up feedback exchange in art so

1573
01:05:36,720 --> 01:05:38,720
there's a seems to be some degree of

1574
01:05:38,720 --> 01:05:40,240
disagreement about

1575
01:05:40,240 --> 01:05:42,240
the compatibility between the two

1576
01:05:42,240 --> 01:05:44,079
frameworks

1577
01:05:44,079 --> 01:05:47,039
well let me try to

1578
01:05:47,039 --> 01:05:49,359
respond to the two parts of your

1579
01:05:49,359 --> 01:05:51,440
question separately

1580
01:05:51,440 --> 01:05:53,280
so i'm not going to try to talk about

1581
01:05:53,280 --> 01:05:56,160
smith at all for a moment

1582
01:05:56,160 --> 01:05:57,119
um

1583
01:05:57,119 --> 01:06:00,480
let's talk about free energy and i like

1584
01:06:00,480 --> 01:06:03,280
getting definitions on the table

1585
01:06:03,280 --> 01:06:05,680
because it's really so frustrating to

1586
01:06:05,680 --> 01:06:07,440
try to remember what something is when

1587
01:06:07,440 --> 01:06:09,520
someone's talking about it

1588
01:06:09,520 --> 01:06:12,000
so i go to wikipedia

1589
01:06:12,000 --> 01:06:14,400
wikipedia writes in part that the free

1590
01:06:14,400 --> 01:06:19,200
energy principle asserts quote

1591
01:06:19,200 --> 01:06:21,920
that systems minimize the free energy

1592
01:06:21,920 --> 01:06:24,799
function of their internal states

1593
01:06:24,799 --> 01:06:27,200
which entail beliefs about hidden states

1594
01:06:27,200 --> 01:06:28,799
in their environment

1595
01:06:28,799 --> 01:06:31,440
the implicit minimization of free energy

1596
01:06:31,440 --> 01:06:33,520
is formally related

1597
01:06:33,520 --> 01:06:36,240
to variational bayesian methods and was

1598
01:06:36,240 --> 01:06:37,520
originally

1599
01:06:37,520 --> 01:06:40,319
introduced by carl fristen as an

1600
01:06:40,319 --> 01:06:42,319
explanation for embodied perception

1601
01:06:42,319 --> 01:06:43,599
neuroscience

1602
01:06:43,599 --> 01:06:45,520
where it's also known as active

1603
01:06:45,520 --> 01:06:47,119
inference and we all know

1604
01:06:47,119 --> 01:06:49,039
paul is a brilliant

1605
01:06:49,039 --> 01:06:52,000
and very insightful man

1606
01:06:52,000 --> 01:06:54,000
the free energy principle describes the

1607
01:06:54,000 --> 01:06:55,920
behavior of a given system by modeling

1608
01:06:55,920 --> 01:06:57,680
it through a markov

1609
01:06:57,680 --> 01:07:00,960
blanket that tries to minimize the

1610
01:07:00,960 --> 01:07:02,240
difference

1611
01:07:02,240 --> 01:07:04,480
between their model of the world

1612
01:07:04,480 --> 01:07:06,319
and their sense

1613
01:07:06,319 --> 01:07:08,559
and associated perception

1614
01:07:08,559 --> 01:07:10,640
this difference can be described as

1615
01:07:10,640 --> 01:07:14,319
surprised and is minimized by continuous

1616
01:07:14,319 --> 01:07:17,359
correction of the world model

1617
01:07:17,359 --> 01:07:19,760
of the system

1618
01:07:19,760 --> 01:07:21,839
uh one more part of the quote the free

1619
01:07:21,839 --> 01:07:23,680
energy principle has been criticized for

1620
01:07:23,680 --> 01:07:26,160
being very difficult to understand

1621
01:07:26,160 --> 01:07:28,480
each and even for experts

1622
01:07:28,480 --> 01:07:30,559
and the mathematical consistency of the

1623
01:07:30,559 --> 01:07:31,839
theory may have been questioned by

1624
01:07:31,839 --> 01:07:33,440
recent studies

1625
01:07:33,440 --> 01:07:35,280
discussions of the principle have also

1626
01:07:35,280 --> 01:07:37,680
been criticized for invoking

1627
01:07:37,680 --> 01:07:40,319
metaphysical assumptions

1628
01:07:40,319 --> 01:07:43,280
far removed from a testable scientific

1629
01:07:43,280 --> 01:07:44,640
prediction

1630
01:07:44,640 --> 01:07:47,280
making the principle on

1631
01:07:47,280 --> 01:07:50,280
falsifiable

1632
01:07:50,319 --> 01:07:52,880
and in a 2018 interview fristen

1633
01:07:52,880 --> 01:07:54,640
acknowledged

1634
01:07:54,640 --> 01:07:57,359
that the free energy principle is not

1635
01:07:57,359 --> 01:07:58,640
properly

1636
01:07:58,640 --> 01:08:01,280
falsifiable

1637
01:08:01,280 --> 01:08:04,640
so that's fristed himself

1638
01:08:04,640 --> 01:08:07,119
so my main concern with the free energy

1639
01:08:07,119 --> 01:08:10,400
principle just like any theory about how

1640
01:08:10,400 --> 01:08:12,880
brain makes a mind is

1641
01:08:12,880 --> 01:08:16,319
how much data can it explain

1642
01:08:16,319 --> 01:08:19,679
in a principle and unifying way

1643
01:08:19,679 --> 01:08:22,560
that's what we do in science we

1644
01:08:22,560 --> 01:08:24,560
develop theories to explain and predict

1645
01:08:24,560 --> 01:08:25,520
data

1646
01:08:25,520 --> 01:08:27,279
and in the case of the free energy

1647
01:08:27,279 --> 01:08:29,759
principle from what i can see

1648
01:08:29,759 --> 01:08:33,120
the answer is essentially no data and

1649
01:08:33,120 --> 01:08:36,158
you can correct me from wrong

1650
01:08:36,158 --> 01:08:39,198
it therefore cannot be evaluated as a

1651
01:08:39,198 --> 01:08:42,080
physical theory at all

1652
01:08:42,080 --> 01:08:44,479
and there's a basic reason for this

1653
01:08:44,479 --> 01:08:46,640
problem

1654
01:08:46,640 --> 01:08:49,198
our brains are designed to autonomously

1655
01:08:49,198 --> 01:08:51,040
learn in real time

1656
01:08:51,040 --> 01:08:54,439
in response to a changing or

1657
01:08:54,439 --> 01:08:57,120
non-stationary world that's filled with

1658
01:08:57,120 --> 01:08:59,679
unexpected events like today

1659
01:08:59,679 --> 01:09:02,158
we're experiencing an unexpected event i

1660
01:09:02,158 --> 01:09:04,799
didn't know till recently that i'd be

1661
01:09:04,799 --> 01:09:07,960
enjoying your company today

1662
01:09:07,960 --> 01:09:10,640
optimization principles were designed to

1663
01:09:10,640 --> 01:09:11,920
cope

1664
01:09:11,920 --> 01:09:14,560
with stationary dynamics whose rules and

1665
01:09:14,560 --> 01:09:18,719
probabilities do not change through time

1666
01:09:18,960 --> 01:09:21,600
so it's not possible to quote minimize

1667
01:09:21,600 --> 01:09:23,120
the difference between their model of

1668
01:09:23,120 --> 01:09:24,960
the world and their sense and associated

1669
01:09:24,960 --> 01:09:26,640
perception unquote

1670
01:09:26,640 --> 01:09:29,279
because there is no predefined model of

1671
01:09:29,279 --> 01:09:30,479
the world

1672
01:09:30,479 --> 01:09:33,279
which is always changing in unexpected

1673
01:09:33,279 --> 01:09:36,479
ways so you need a theory about

1674
01:09:36,479 --> 01:09:39,919
how the world changes

1675
01:09:40,600 --> 01:09:43,120
surprise occurs in art when there's a

1676
01:09:43,120 --> 01:09:44,158
big enough

1677
01:09:44,158 --> 01:09:45,520
mismatch

1678
01:09:45,520 --> 01:09:47,600
between an input pattern and the

1679
01:09:47,600 --> 01:09:49,120
currently active

1680
01:09:49,120 --> 01:09:52,158
top down expectation of a category that

1681
01:09:52,158 --> 01:09:53,920
it's activating

1682
01:09:53,920 --> 01:09:56,000
this mismatch activates the art

1683
01:09:56,000 --> 01:09:58,560
orienting system that i briefly

1684
01:09:58,560 --> 01:10:00,560
discuss in my talk which interacts with

1685
01:10:00,560 --> 01:10:02,400
the attentional system

1686
01:10:02,400 --> 01:10:04,159
where the category learning doesn't

1687
01:10:04,159 --> 01:10:05,520
occur

1688
01:10:05,520 --> 01:10:08,640
and as i illustrated in our discussions

1689
01:10:08,640 --> 01:10:10,640
of search and vigilance

1690
01:10:10,640 --> 01:10:12,960
that it drives hypothesis testing or

1691
01:10:12,960 --> 01:10:14,320
memory search

1692
01:10:14,320 --> 01:10:16,480
to discover a better match or to begin

1693
01:10:16,480 --> 01:10:19,280
to learn a new category

1694
01:10:19,280 --> 01:10:21,840
so auto discuss a better match in the

1695
01:10:21,840 --> 01:10:24,239
case where

1696
01:10:24,239 --> 01:10:27,199
the system was attending some other

1697
01:10:27,199 --> 01:10:29,199
familiar features when the new input

1698
01:10:29,199 --> 01:10:30,640
occurs

1699
01:10:30,640 --> 01:10:32,560
but the features of the new input have

1700
01:10:32,560 --> 01:10:34,560
previously been categorized that's why

1701
01:10:34,560 --> 01:10:35,920
they're familiar

1702
01:10:35,920 --> 01:10:38,159
and then the orient system very quickly

1703
01:10:38,159 --> 01:10:39,679
shifts attention

1704
01:10:39,679 --> 01:10:41,520
to the matching category and you

1705
01:10:41,520 --> 01:10:44,239
resonate on and you recognized it

1706
01:10:44,239 --> 01:10:46,719
consciously often

1707
01:10:46,719 --> 01:10:48,880
art begins to learn a new category when

1708
01:10:48,880 --> 01:10:50,719
the input represents

1709
01:10:50,719 --> 01:10:55,120
a truly unfamiliar and novel situation

1710
01:10:55,120 --> 01:10:58,800
now as to bayesian methods in science

1711
01:10:58,800 --> 01:11:01,120
hey i'm a mathematician

1712
01:11:01,120 --> 01:11:04,159
how can i not love days right

1713
01:11:04,159 --> 01:11:05,920
but the beauty of bayes is its

1714
01:11:05,920 --> 01:11:07,679
simplicity

1715
01:11:07,679 --> 01:11:10,320
you just write the probability of two

1716
01:11:10,320 --> 01:11:14,320
events a and b in two different ways

1717
01:11:14,320 --> 01:11:17,520
the probability of b given a times the

1718
01:11:17,520 --> 01:11:19,600
probability of a

1719
01:11:19,600 --> 01:11:22,320
the probability of a given b times the

1720
01:11:22,320 --> 01:11:24,719
probability of b

1721
01:11:24,719 --> 01:11:27,760
set them equal because they're identical

1722
01:11:27,760 --> 01:11:30,320
divide by let's say probability they and

1723
01:11:30,320 --> 01:11:31,920
then optimized

1724
01:11:31,920 --> 01:11:34,560
that's base

1725
01:11:34,560 --> 01:11:37,360
and it's a useful statistical method and

1726
01:11:37,360 --> 01:11:40,400
should continue to be used in statistics

1727
01:11:40,400 --> 01:11:42,400
but it's just the formal identity

1728
01:11:42,400 --> 01:11:44,640
wherein lies its power

1729
01:11:44,640 --> 01:11:47,040
it says nothing about any physical

1730
01:11:47,040 --> 01:11:48,400
reality

1731
01:11:48,400 --> 01:11:52,159
whether in physics chemistry or biology

1732
01:11:52,159 --> 01:11:55,199
today's rule itself tells us nothing

1733
01:11:55,199 --> 01:11:57,199
about physical reality

1734
01:11:57,199 --> 01:11:59,840
and contains no heuristics to discover

1735
01:11:59,840 --> 01:12:02,640
anything about physical reality

1736
01:12:02,640 --> 01:12:04,880
but that you need to develop models

1737
01:12:04,880 --> 01:12:05,840
driven

1738
01:12:05,840 --> 01:12:08,880
by a profound analysis of large

1739
01:12:08,880 --> 01:12:10,480
databases

1740
01:12:10,480 --> 01:12:13,120
so it turns out that biological models

1741
01:12:13,120 --> 01:12:14,960
like god do not

1742
01:12:14,960 --> 01:12:18,560
incorporate the bayes rule however

1743
01:12:18,560 --> 01:12:21,040
art does routinely

1744
01:12:21,040 --> 01:12:23,760
choose the best or optimal categories

1745
01:12:23,760 --> 01:12:26,480
that represent the database

1746
01:12:26,480 --> 01:12:28,400
so you don't need base to achieve

1747
01:12:28,400 --> 01:12:30,239
optimality

1748
01:12:30,239 --> 01:12:32,719
also base works best in a stationary

1749
01:12:32,719 --> 01:12:35,360
world with stationary probabilities

1750
01:12:35,360 --> 01:12:37,199
and arts designed

1751
01:12:37,199 --> 01:12:41,440
to learn about a non-stationary world

1752
01:12:41,440 --> 01:12:43,199
so you know one can discuss this till

1753
01:12:43,199 --> 01:12:45,199
the cows come home

1754
01:12:45,199 --> 01:12:48,000
uh it's good for what it was designed

1755
01:12:48,000 --> 01:12:49,360
for

1756
01:12:49,360 --> 01:12:50,960
um

1757
01:12:50,960 --> 01:12:53,040
and some of the neuroscientists who try

1758
01:12:53,040 --> 01:12:54,960
to apply bays

1759
01:12:54,960 --> 01:12:57,440
are wonderful experimentalists

1760
01:12:57,440 --> 01:13:00,560
but they know no myth and no theory

1761
01:13:00,560 --> 01:13:02,000
and

1762
01:13:02,000 --> 01:13:02,840
you know

1763
01:13:02,840 --> 01:13:06,320
it's uh

1764
01:13:06,400 --> 01:13:09,280
the temptation of a free lunch

1765
01:13:09,280 --> 01:13:12,000
there it is waiting to be applied

1766
01:13:12,000 --> 01:13:16,520
there is no free lunch in science

1767
01:13:19,360 --> 01:13:20,480
thank you

1768
01:13:20,480 --> 01:13:21,280
uh

1769
01:13:21,280 --> 01:13:22,000
now

1770
01:13:22,000 --> 01:13:24,400
as a final point of comparison uh what

1771
01:13:24,400 --> 01:13:27,840
are the smith i didn't reply to yes

1772
01:13:27,840 --> 01:13:28,719
yes

1773
01:13:28,719 --> 01:13:34,800
okay you quoted a sentence of smith

1774
01:13:35,120 --> 01:13:36,080
but

1775
01:13:36,080 --> 01:13:40,159
before that said smith at all wrote

1776
01:13:40,159 --> 01:13:42,880
it is also worth highlighting that as

1777
01:13:42,880 --> 01:13:45,040
our model is intended primarily as a

1778
01:13:45,040 --> 01:13:47,120
proof of concept

1779
01:13:47,120 --> 01:13:50,080
and a demonstration of an available

1780
01:13:50,080 --> 01:13:53,199
model expansion reduction approach

1781
01:13:53,199 --> 01:13:55,920
that can be used within active inference

1782
01:13:55,920 --> 01:13:57,360
research

1783
01:13:57,360 --> 01:14:00,880
it does not explicitly incorporate

1784
01:14:00,880 --> 01:14:04,560
some aspects such as top-down attention

1785
01:14:04,560 --> 01:14:06,560
that are of clear importance to

1786
01:14:06,560 --> 01:14:08,800
cognitive learning processes

1787
01:14:08,800 --> 01:14:10,159
and that have been implemented in

1788
01:14:10,159 --> 01:14:12,239
previous models for example

1789
01:14:12,239 --> 01:14:14,560
the adaptive resonance theory rock model

1790
01:14:14,560 --> 01:14:17,600
gross word was designed to incorporate

1791
01:14:17,600 --> 01:14:19,760
top-down attentional mechanisms and

1792
01:14:19,760 --> 01:14:21,679
feedback mechanisms

1793
01:14:21,679 --> 01:14:23,520
to address a fundamental knowledge

1794
01:14:23,520 --> 01:14:26,000
accusation problem

1795
01:14:26,000 --> 01:14:28,400
the temporal instability of previously

1796
01:14:28,400 --> 01:14:31,040
learned information that can occur

1797
01:14:31,040 --> 01:14:33,840
when a system also remains sufficiently

1798
01:14:33,840 --> 01:14:35,920
plastic to learn new and potentially

1799
01:14:35,920 --> 01:14:38,640
overlapping information

1800
01:14:38,640 --> 01:14:41,199
while our simulations do not explicitly

1801
01:14:41,199 --> 01:14:42,719
incorporate these additional

1802
01:14:42,719 --> 01:14:46,560
complexities there are clear analogs

1803
01:14:46,560 --> 01:14:48,560
to the top down and bottom up feedback

1804
01:14:48,560 --> 01:14:51,199
exchanges and within our model

1805
01:14:51,199 --> 01:14:53,040
such as the prediction and prediction

1806
01:14:53,040 --> 01:14:54,719
error signaling

1807
01:14:54,719 --> 01:14:56,640
within the neural process theory

1808
01:14:56,640 --> 01:14:58,880
associated with active entrance

1809
01:14:58,880 --> 01:15:01,280
art addresses the temporal instability

1810
01:15:01,280 --> 01:15:02,880
problem primarily

1811
01:15:02,880 --> 01:15:04,719
through mechanisms that learn top-down

1812
01:15:04,719 --> 01:15:07,440
expectancies that guide attention and

1813
01:15:07,440 --> 01:15:10,239
match them on bottom-up input patterns

1814
01:15:10,239 --> 01:15:13,120
which is quite similar to

1815
01:15:13,120 --> 01:15:15,360
the prior expectations and likelihood

1816
01:15:15,360 --> 01:15:18,480
mappings used with an active inference

1817
01:15:18,480 --> 01:15:21,360
but as i've already noted the quote

1818
01:15:21,360 --> 01:15:23,760
prior expectations and likelihood

1819
01:15:23,760 --> 01:15:26,640
matching mappings within adaptive

1820
01:15:26,640 --> 01:15:29,760
inference quote unquote do not have any

1821
01:15:29,760 --> 01:15:31,760
of the key learning attention and memory

1822
01:15:31,760 --> 01:15:33,360
stability properties of the york

1823
01:15:33,360 --> 01:15:35,760
matching rule york matching rule is

1824
01:15:35,760 --> 01:15:38,400
unique solution to that problem

1825
01:15:38,400 --> 01:15:41,599
in its variations

1826
01:15:42,000 --> 01:15:44,640
it's been supported by

1827
01:15:44,640 --> 01:15:47,760
psychological anatomical physiological

1828
01:15:47,760 --> 01:15:51,120
and biophysical data

1829
01:15:51,120 --> 01:15:54,000
it also occurs in many species

1830
01:15:54,000 --> 01:15:56,400
nobu sugar for example shows it occurs

1831
01:15:56,400 --> 01:15:58,480
in bats

1832
01:15:58,480 --> 01:16:00,880
it occurs in ferrets

1833
01:16:00,880 --> 01:16:02,800
you know

1834
01:16:02,800 --> 01:16:07,040
so also i think it's important to know

1835
01:16:07,040 --> 01:16:08,800
that when learning begins in an arc

1836
01:16:08,800 --> 01:16:11,199
model it doesn't need

1837
01:16:11,199 --> 01:16:14,640
prior expectations or likelihood

1838
01:16:14,640 --> 01:16:17,360
in fact typically the initial

1839
01:16:17,360 --> 01:16:19,280
bottom-up weights are chosen to be

1840
01:16:19,280 --> 01:16:21,120
random

1841
01:16:21,120 --> 01:16:22,480
because you don't know what you're going

1842
01:16:22,480 --> 01:16:24,880
to be experiencing and the initial

1843
01:16:24,880 --> 01:16:27,280
top-down expectations are chosen to be

1844
01:16:27,280 --> 01:16:28,719
large

1845
01:16:28,719 --> 01:16:31,920
so that whatever category happens to be

1846
01:16:31,920 --> 01:16:34,719
learned when it reads out its top down

1847
01:16:34,719 --> 01:16:36,400
expectation

1848
01:16:36,400 --> 01:16:39,199
it can match whatever features activated

1849
01:16:39,199 --> 01:16:40,640
that category

1850
01:16:40,640 --> 01:16:42,480
so they all start larger than their

1851
01:16:42,480 --> 01:16:44,000
pruned

1852
01:16:44,000 --> 01:16:46,239
to match the critical features that

1853
01:16:46,239 --> 01:16:47,360
happen

1854
01:16:47,360 --> 01:16:50,080
to be learned in that category

1855
01:16:50,080 --> 01:16:52,800
so there are no

1856
01:16:52,800 --> 01:16:54,719
built-in models

1857
01:16:54,719 --> 01:16:58,640
or discovers its own models

1858
01:16:58,640 --> 01:17:00,719
i should also emphasize that active

1859
01:17:00,719 --> 01:17:02,440
entrance is also not

1860
01:17:02,440 --> 01:17:04,159
explainable

1861
01:17:04,159 --> 01:17:06,400
arts is explainable because

1862
01:17:06,400 --> 01:17:09,040
a currently active critical feature

1863
01:17:09,040 --> 01:17:11,440
activity pattern

1864
01:17:11,440 --> 01:17:13,360
namely the features to which attention

1865
01:17:13,360 --> 01:17:15,520
is paid controls

1866
01:17:15,520 --> 01:17:16,480
all

1867
01:17:16,480 --> 01:17:18,480
learning and prediction by the model and

1868
01:17:18,480 --> 01:17:20,000
in principle

1869
01:17:20,000 --> 01:17:22,239
can be measured by neurophysiological

1870
01:17:22,239 --> 01:17:23,600
experiments

1871
01:17:23,600 --> 01:17:26,000
a model without cell activities or

1872
01:17:26,000 --> 01:17:28,960
short-term memory traces

1873
01:17:28,960 --> 01:17:31,199
that can represent the critical feature

1874
01:17:31,199 --> 01:17:32,159
pattern

1875
01:17:32,159 --> 01:17:35,679
can't be explainable

1876
01:17:35,679 --> 01:17:37,840
so i think there are qualitative

1877
01:17:37,840 --> 01:17:39,520
differences

1878
01:17:39,520 --> 01:17:42,000
i don't say people shouldn't use active

1879
01:17:42,000 --> 01:17:43,199
inference

1880
01:17:43,199 --> 01:17:46,719
it may be incredibly useful and powerful

1881
01:17:46,719 --> 01:17:49,440
in technological applications

1882
01:17:49,440 --> 01:17:51,760
but when one is doing

1883
01:17:51,760 --> 01:17:53,280
you know

1884
01:17:53,280 --> 01:17:56,159
brain science psychology

1885
01:17:56,159 --> 01:17:59,280
it just doesn't match under foundational

1886
01:17:59,280 --> 01:18:01,360
data

1887
01:18:01,360 --> 01:18:04,159
it just doesn't

1888
01:18:05,360 --> 01:18:08,080
more personal

1889
01:18:08,080 --> 01:18:09,040
thanks

1890
01:18:09,040 --> 01:18:12,400
and uh i guess you'd

1891
01:18:12,400 --> 01:18:14,960
somehow already answered a part of this

1892
01:18:14,960 --> 01:18:16,159
question but

1893
01:18:16,159 --> 01:18:18,880
uh what are the possible ways in which

1894
01:18:18,880 --> 01:18:22,400
an arts approach to explainable ai

1895
01:18:22,400 --> 01:18:24,159
which if i'm not mistaken can be

1896
01:18:24,159 --> 01:18:26,560
described as a modern dependent

1897
01:18:26,560 --> 01:18:29,440
intrinsically explainable approach

1898
01:18:29,440 --> 01:18:32,320
can inform active inferences approaching

1899
01:18:32,320 --> 01:18:34,480
cross-fertilize with it which is based

1900
01:18:34,480 --> 01:18:36,560
on abductive reasoning through

1901
01:18:36,560 --> 01:18:38,640
constructing generative models for

1902
01:18:38,640 --> 01:18:39,760
example

1903
01:18:39,760 --> 01:18:42,640
as i sketched out in par and patzulo's

1904
01:18:42,640 --> 01:18:44,719
understanding explanation and active

1905
01:18:44,719 --> 01:18:46,880
inference paper

1906
01:18:46,880 --> 01:18:49,040
well first um

1907
01:18:49,040 --> 01:18:53,600
i i don't think art is model dependent

1908
01:18:53,600 --> 01:18:56,960
uh as i just noted one begins typically

1909
01:18:56,960 --> 01:19:00,320
the learning out with random

1910
01:19:00,320 --> 01:19:03,199
initial bottom-up weights and uniformly

1911
01:19:03,199 --> 01:19:04,640
distributed

1912
01:19:04,640 --> 01:19:07,280
drop down initial adaptive weight so you

1913
01:19:07,280 --> 01:19:10,080
can match any category that you happen

1914
01:19:10,080 --> 01:19:12,320
to learn

1915
01:19:12,320 --> 01:19:15,040
but the authors you quoted write in part

1916
01:19:15,040 --> 01:19:17,600
that active entrance and here i want to

1917
01:19:17,600 --> 01:19:19,440
quote them

1918
01:19:19,440 --> 01:19:22,480
so we i can respond in

1919
01:19:22,480 --> 01:19:24,960
a little more detail

1920
01:19:24,960 --> 01:19:28,159
active entrance quote implies a deep

1921
01:19:28,159 --> 01:19:30,320
generative model

1922
01:19:30,320 --> 01:19:33,520
that includes a model of the world

1923
01:19:33,520 --> 01:19:36,800
used to infer policies and a higher

1924
01:19:36,800 --> 01:19:38,320
level model that attempts to predict

1925
01:19:38,320 --> 01:19:41,120
which policies will be selected

1926
01:19:41,120 --> 01:19:43,840
based upon a space of hypothetical that

1927
01:19:43,840 --> 01:19:47,360
is down to factual explanations

1928
01:19:47,360 --> 01:19:49,840
and which can subsequently be used to

1929
01:19:49,840 --> 01:19:51,000
provide

1930
01:19:51,000 --> 01:19:53,199
retrospective explanations about the

1931
01:19:53,199 --> 01:19:56,000
policies pursued

1932
01:19:56,000 --> 01:19:59,199
so again artworks without a generative

1933
01:19:59,199 --> 01:20:00,719
model of the world

1934
01:20:00,719 --> 01:20:04,560
or any predefined policies

1935
01:20:04,560 --> 01:20:05,520
uh

1936
01:20:05,520 --> 01:20:07,040
of course what it's trying to do is

1937
01:20:07,040 --> 01:20:08,480
discover

1938
01:20:08,480 --> 01:20:10,480
what changing world it happens to be in

1939
01:20:10,480 --> 01:20:12,800
and nobody knows what it is

1940
01:20:12,800 --> 01:20:15,199
at priority

1941
01:20:15,199 --> 01:20:17,520
and in general in our classifier

1942
01:20:17,520 --> 01:20:18,880
responds

1943
01:20:18,880 --> 01:20:20,880
to a front end

1944
01:20:20,880 --> 01:20:24,120
of pre-processes

1945
01:20:24,320 --> 01:20:27,440
that process perceptual data from one or

1946
01:20:27,440 --> 01:20:29,120
another sense

1947
01:20:29,120 --> 01:20:32,800
notably vision and audition where we get

1948
01:20:32,800 --> 01:20:36,960
most of our information about the world

1949
01:20:36,960 --> 01:20:38,320
um

1950
01:20:38,320 --> 01:20:40,239
and that's why classifier like art

1951
01:20:40,239 --> 01:20:42,400
begins its work in the brain

1952
01:20:42,400 --> 01:20:45,440
in the temporal cortex

1953
01:20:45,440 --> 01:20:47,840
where it received highly

1954
01:20:47,840 --> 01:20:51,920
pre-processed perceptual representations

1955
01:20:51,920 --> 01:20:54,159
so um

1956
01:20:54,159 --> 01:20:56,800
or decades of work went into

1957
01:20:56,800 --> 01:20:58,960
understanding our brains consciously

1958
01:20:58,960 --> 01:21:01,280
seeing here

1959
01:21:01,280 --> 01:21:04,159
and in the case of vision art

1960
01:21:04,159 --> 01:21:06,400
classifies perceptual boundaries and

1961
01:21:06,400 --> 01:21:08,800
surfaces that require

1962
01:21:08,800 --> 01:21:11,760
multiple stages of processing

1963
01:21:11,760 --> 01:21:15,600
because as i mentioned briefly they

1964
01:21:15,600 --> 01:21:17,280
or the outcome of what i call

1965
01:21:17,280 --> 01:21:20,400
hierarchical resolution of uncertainty

1966
01:21:20,400 --> 01:21:23,199
you need multiple stages

1967
01:21:23,199 --> 01:21:26,800
to define a perceptual boundary surface

1968
01:21:26,800 --> 01:21:30,080
one reason being because our sensory

1969
01:21:30,080 --> 01:21:31,679
organs

1970
01:21:31,679 --> 01:21:34,239
register such noisy and incomplete data

1971
01:21:34,239 --> 01:21:35,679
like you may know

1972
01:21:35,679 --> 01:21:38,639
that our photosensitive retina

1973
01:21:38,639 --> 01:21:41,280
has a huge blind spot

1974
01:21:41,280 --> 01:21:44,080
where you can't register any

1975
01:21:44,080 --> 01:21:47,199
sense any visual signal the blind spot

1976
01:21:47,199 --> 01:21:49,120
as big as the fovea

1977
01:21:49,120 --> 01:21:51,520
where all of our high resolution

1978
01:21:51,520 --> 01:21:54,639
vision occurs so it's not a little thing

1979
01:21:54,639 --> 01:21:57,440
and we're moreover veins

1980
01:21:57,440 --> 01:21:59,840
come out of the fovea and occlude the

1981
01:21:59,840 --> 01:22:02,080
retina in multiple places

1982
01:22:02,080 --> 01:22:04,159
and you can't

1983
01:22:04,159 --> 01:22:06,480
register visual signals on the veins

1984
01:22:06,480 --> 01:22:07,600
either so

1985
01:22:07,600 --> 01:22:09,600
the signal you're getting is very

1986
01:22:09,600 --> 01:22:11,920
incomplete and it takes

1987
01:22:11,920 --> 01:22:14,480
multiple processing stages

1988
01:22:14,480 --> 01:22:18,159
to overcome those uncertainties and

1989
01:22:18,159 --> 01:22:20,000
my college and i've worked for decades

1990
01:22:20,000 --> 01:22:21,360
to explain

1991
01:22:21,360 --> 01:22:25,239
how that happens

1992
01:22:25,440 --> 01:22:26,400
um

1993
01:22:26,400 --> 01:22:28,880
maybe i'll stop after that

1994
01:22:28,880 --> 01:22:30,560
thank you so much

1995
01:22:30,560 --> 01:22:33,760
now uh this next question is of a

1996
01:22:33,760 --> 01:22:35,440
personal interest to me

1997
01:22:35,440 --> 01:22:37,520
because currently i'm working on

1998
01:22:37,520 --> 01:22:39,679
modeling some probabilistic aspects of

1999
01:22:39,679 --> 01:22:42,159
affective response to music and

2000
01:22:42,159 --> 01:22:44,000
your most recent paper toward

2001
01:22:44,000 --> 01:22:45,760
understanding the brain dynamics of

2002
01:22:45,760 --> 01:22:47,120
music

2003
01:22:47,120 --> 01:22:48,880
immensely helped me gain a better

2004
01:22:48,880 --> 01:22:52,159
understanding of entrainment

2005
01:22:52,159 --> 01:22:54,000
as you pointed out in the supplementary

2006
01:22:54,000 --> 01:22:56,480
notes for this paper

2007
01:22:56,480 --> 01:22:59,360
violation of prior learned expectations

2008
01:22:59,360 --> 01:23:01,920
is instrumental in inducing a wide range

2009
01:23:01,920 --> 01:23:04,880
of effective responses in musical and

2010
01:23:04,880 --> 01:23:06,719
non-musical situations

2011
01:23:06,719 --> 01:23:08,960
uh some psychologists such as patrick

2012
01:23:08,960 --> 01:23:11,120
usland have distinguished between

2013
01:23:11,120 --> 01:23:14,239
perception and arousal of emotions

2014
01:23:14,239 --> 01:23:16,239
interrupt you but you left out a

2015
01:23:16,239 --> 01:23:17,520
question

2016
01:23:17,520 --> 01:23:19,280
is it the lack of time where you just

2017
01:23:19,280 --> 01:23:22,880
skipped it accidentally because i want

2018
01:23:22,880 --> 01:23:26,159
quite a bit about it

2019
01:23:26,480 --> 01:23:28,400
how do you see the future of art and

2020
01:23:28,400 --> 01:23:30,320
neuro and spider

2021
01:23:30,320 --> 01:23:33,360
i think that will be our last question

2022
01:23:33,360 --> 01:23:35,840
okay so we'll come back to that

2023
01:23:35,840 --> 01:23:37,360
yes yes thank you

2024
01:23:37,360 --> 01:23:39,120
because that that's an important

2025
01:23:39,120 --> 01:23:41,760
question to me yes okay so sorry to

2026
01:23:41,760 --> 01:23:43,840
interrupt i just want to be sure no

2027
01:23:43,840 --> 01:23:45,440
problem thank you

2028
01:23:45,440 --> 01:23:47,600
now uh yes um

2029
01:23:47,600 --> 01:23:50,080
well some psychologists such as patrick

2030
01:23:50,080 --> 01:23:52,880
guslin have distinguished between uh the

2031
01:23:52,880 --> 01:23:55,520
perception and the arousal of emotions

2032
01:23:55,520 --> 01:23:58,320
in the context of musical experience

2033
01:23:58,320 --> 01:24:01,199
and also several studies such as the

2034
01:24:01,199 --> 01:24:03,280
works of justland and gabrielson from

2035
01:24:03,280 --> 01:24:05,199
the psychology department of uppsala

2036
01:24:05,199 --> 01:24:06,560
university

2037
01:24:06,560 --> 01:24:09,520
have shown that despite music's ability

2038
01:24:09,520 --> 01:24:11,679
to communicate a wide range of

2039
01:24:11,679 --> 01:24:13,600
positively and negatively balanced

2040
01:24:13,600 --> 01:24:15,520
emotions

2041
01:24:15,520 --> 01:24:18,560
it somehow evokes mostly positively

2042
01:24:18,560 --> 01:24:21,440
valenced emotions uh for instance we can

2043
01:24:21,440 --> 01:24:24,480
easily perceive uh rage or anger in

2044
01:24:24,480 --> 01:24:27,440
music without necessarily getting angry

2045
01:24:27,440 --> 01:24:29,679
on the other hand we're more likely to

2046
01:24:29,679 --> 01:24:31,920
actually feel elevated and happy after

2047
01:24:31,920 --> 01:24:34,480
listening to happy music

2048
01:24:34,480 --> 01:24:37,440
and also the evidence shows that this

2049
01:24:37,440 --> 01:24:39,440
disparity between perception and

2050
01:24:39,440 --> 01:24:42,000
evocation of mu of emotion

2051
01:24:42,000 --> 01:24:44,159
is probably even more significant in

2052
01:24:44,159 --> 01:24:46,159
musical experiences than

2053
01:24:46,159 --> 01:24:49,360
any other non-musical experiences

2054
01:24:49,360 --> 01:24:52,480
so how can this difference in diversity

2055
01:24:52,480 --> 01:24:55,120
between perceived and

2056
01:24:55,120 --> 01:24:57,520
aroused aroused or evoked musical

2057
01:24:57,520 --> 01:24:59,760
emotions be account and be accounted for

2058
01:24:59,760 --> 01:25:01,120
within art

2059
01:25:01,120 --> 01:25:04,400
framework can it possibly be regarded as

2060
01:25:04,400 --> 01:25:06,639
another kind of broken symmetry as you

2061
01:25:06,639 --> 01:25:08,199
mentioned on page

2062
01:25:08,199 --> 01:25:10,560
621 of your book

2063
01:25:10,560 --> 01:25:15,040
but specific to musical effects

2064
01:25:15,520 --> 01:25:18,000
so um

2065
01:25:18,000 --> 01:25:20,159
as you've noted i haven't studied this

2066
01:25:20,159 --> 01:25:23,600
issues in the context of music but i'll

2067
01:25:23,600 --> 01:25:27,040
try to venture some general comments

2068
01:25:27,040 --> 01:25:29,679
i should first note that the laminar

2069
01:25:29,679 --> 01:25:32,080
model

2070
01:25:32,080 --> 01:25:33,600
which is

2071
01:25:33,600 --> 01:25:37,840
a development of art to show

2072
01:25:38,080 --> 01:25:41,840
how and why all neocortical circuits

2073
01:25:41,840 --> 01:25:45,120
that support perception and cognition

2074
01:25:45,120 --> 01:25:47,840
typically share a canonical

2075
01:25:47,840 --> 01:25:50,719
six-layer circuit

2076
01:25:50,719 --> 01:25:53,440
my colleagues and i have modeled how

2077
01:25:53,440 --> 01:25:57,520
just as in our brains variations of this

2078
01:25:57,520 --> 01:25:59,760
canonical laminate circuit can support

2079
01:25:59,760 --> 01:26:00,719
all

2080
01:26:00,719 --> 01:26:03,360
perceptual and cognitive

2081
01:26:03,360 --> 01:26:05,280
processes so there's a major

2082
01:26:05,280 --> 01:26:08,639
generalization of art

2083
01:26:08,880 --> 01:26:10,960
and we've done it for vision speech and

2084
01:26:10,960 --> 01:26:13,120
cognitive working memory

2085
01:26:13,120 --> 01:26:16,480
and planning in particular

2086
01:26:16,480 --> 01:26:19,360
so the main point is that the

2087
01:26:19,360 --> 01:26:22,400
laminar circuitry is basically in all

2088
01:26:22,400 --> 01:26:24,719
perceptual and cognitive

2089
01:26:24,719 --> 01:26:27,760
areas vision auditions etc etc that's

2090
01:26:27,760 --> 01:26:28,719
how

2091
01:26:28,719 --> 01:26:32,320
one can create a context for discussing

2092
01:26:32,320 --> 01:26:35,440
music and in fact my work on music

2093
01:26:35,440 --> 01:26:37,040
applied

2094
01:26:37,040 --> 01:26:39,199
such discoveries like

2095
01:26:39,199 --> 01:26:41,840
i was able to put together

2096
01:26:41,840 --> 01:26:45,280
discoveries that had been made

2097
01:26:45,280 --> 01:26:46,880
based on

2098
01:26:46,880 --> 01:26:49,520
if what i believe were different

2099
01:26:49,520 --> 01:26:53,440
evolutionary pressures upon

2100
01:26:54,080 --> 01:26:57,120
the organization of our brains but that

2101
01:26:57,120 --> 01:27:00,639
evolution also discovered and i try to

2102
01:27:00,639 --> 01:27:02,719
sketch how if you put some of them

2103
01:27:02,719 --> 01:27:05,440
together in a certain way

2104
01:27:05,440 --> 01:27:07,280
then

2105
01:27:07,280 --> 01:27:09,040
capacity

2106
01:27:09,040 --> 01:27:11,040
for

2107
01:27:11,040 --> 01:27:13,280
learning and consciously performing

2108
01:27:13,280 --> 01:27:14,480
music

2109
01:27:14,480 --> 01:27:16,480
book could arise

2110
01:27:16,480 --> 01:27:19,360
so now how about arousal

2111
01:27:19,360 --> 01:27:21,360
well it's essential of course for all

2112
01:27:21,360 --> 01:27:23,679
awareness and consciousness

2113
01:27:23,679 --> 01:27:26,239
your cortex needs to be

2114
01:27:26,239 --> 01:27:28,400
adequately aroused for waking

2115
01:27:28,400 --> 01:27:29,679
consciousness

2116
01:27:29,679 --> 01:27:33,920
to occur at all it also arouses and

2117
01:27:33,920 --> 01:27:36,320
plays a major role in the processing

2118
01:27:36,320 --> 01:27:38,480
of emotions and is very relevant to

2119
01:27:38,480 --> 01:27:40,159
musical

2120
01:27:40,159 --> 01:27:41,360
issues

2121
01:27:41,360 --> 01:27:44,480
because my gated dipole model

2122
01:27:44,480 --> 01:27:47,520
explains how opponent processes

2123
01:27:47,520 --> 01:27:49,360
opposites

2124
01:27:49,360 --> 01:27:53,199
are organized in all parts of our brain

2125
01:27:53,199 --> 01:27:57,360
are perceptual cognitive motor

2126
01:27:57,360 --> 01:27:59,280
affective

2127
01:27:59,280 --> 01:28:02,320
in particular emotions are organized

2128
01:28:02,320 --> 01:28:04,080
in pairs

2129
01:28:04,080 --> 01:28:07,520
in such an emotional dipole

2130
01:28:07,520 --> 01:28:10,000
and one reason is because emotions need

2131
01:28:10,000 --> 01:28:12,000
to compete with each other

2132
01:28:12,000 --> 01:28:16,639
such as fear versus relief

2133
01:28:16,639 --> 01:28:19,120
for example in post-traumatic stress

2134
01:28:19,120 --> 01:28:21,120
disorder therapy

2135
01:28:21,120 --> 01:28:24,400
a therapist may try to help a patient

2136
01:28:24,400 --> 01:28:28,239
to think about positive experiences

2137
01:28:28,239 --> 01:28:30,960
that generate relief

2138
01:28:30,960 --> 01:28:34,000
in order to inhibit the chronic fear

2139
01:28:34,000 --> 01:28:38,159
that's so destabilizing during ptsd

2140
01:28:38,159 --> 01:28:39,280
so their

2141
01:28:39,280 --> 01:28:42,480
opposites are competing

2142
01:28:42,480 --> 01:28:44,639
and another property that arousal

2143
01:28:44,639 --> 01:28:46,639
enables is that

2144
01:28:46,639 --> 01:28:49,360
the sudden offset of an emotion like

2145
01:28:49,360 --> 01:28:50,880
fear

2146
01:28:50,880 --> 01:28:54,000
let's say during escape behavior

2147
01:28:54,000 --> 01:28:56,239
let's say you know a favorite example of

2148
01:28:56,239 --> 01:28:57,520
mine is

2149
01:28:57,520 --> 01:29:00,000
you know some cruel experimentalist puts

2150
01:29:00,000 --> 01:29:02,320
the pigeon in the skinner box

2151
01:29:02,320 --> 01:29:04,639
the floor is electrified

2152
01:29:04,639 --> 01:29:07,600
the uh pigeon is feeling pain and fear

2153
01:29:07,600 --> 01:29:08,560
it's

2154
01:29:08,560 --> 01:29:10,880
dashing frantically around trying to

2155
01:29:10,880 --> 01:29:12,880
keep its feet off the floor

2156
01:29:12,880 --> 01:29:15,920
it bangs into a red buzzer

2157
01:29:15,920 --> 01:29:19,360
the buzzer shuts the shock off

2158
01:29:19,360 --> 01:29:20,560
and

2159
01:29:20,560 --> 01:29:22,800
the animal experience the wave of relief

2160
01:29:22,800 --> 01:29:24,960
or positive motivation

2161
01:29:24,960 --> 01:29:28,560
for learning the escape response

2162
01:29:28,560 --> 01:29:29,600
so

2163
01:29:29,600 --> 01:29:33,760
the rebound from theater relief

2164
01:29:33,760 --> 01:29:36,480
that can be associated with actions that

2165
01:29:36,480 --> 01:29:39,199
lead to escape and can motivate escape

2166
01:29:39,199 --> 01:29:41,600
by means in the future

2167
01:29:41,600 --> 01:29:44,639
is energized by arousal in the gated

2168
01:29:44,639 --> 01:29:46,719
dipole

2169
01:29:46,719 --> 01:29:50,800
you shut off the external cue of shock

2170
01:29:50,800 --> 01:29:54,239
but the arousal is tonically or

2171
01:29:54,239 --> 01:29:56,480
has sustained activity in both the fear

2172
01:29:56,480 --> 01:29:57,679
and elite

2173
01:29:57,679 --> 01:29:59,040
channel so

2174
01:29:59,040 --> 01:30:01,040
because the arousal is sustained or

2175
01:30:01,040 --> 01:30:03,040
tonic through time

2176
01:30:03,040 --> 01:30:05,040
and equally activates the fear and

2177
01:30:05,040 --> 01:30:06,560
relief channels

2178
01:30:06,560 --> 01:30:09,760
when fear suddenly decreases

2179
01:30:09,760 --> 01:30:11,920
then arousal in the relief channel wins

2180
01:30:11,920 --> 01:30:13,920
the competition

2181
01:30:13,920 --> 01:30:16,000
and can thereby call what i call an

2182
01:30:16,000 --> 01:30:18,480
antagonistic rebound

2183
01:30:18,480 --> 01:30:21,199
from theater relief that activates the

2184
01:30:21,199 --> 01:30:22,639
relief channel

2185
01:30:22,639 --> 01:30:24,480
and thereby providing

2186
01:30:24,480 --> 01:30:26,880
motivation for escape

2187
01:30:26,880 --> 01:30:30,159
uh whether reactive or learned

2188
01:30:30,159 --> 01:30:33,280
uh through escape experiences

2189
01:30:33,280 --> 01:30:36,639
and i also approve which is related

2190
01:30:36,639 --> 01:30:38,800
to some degree of music that

2191
01:30:38,800 --> 01:30:42,480
the non-occurrence of an expected event

2192
01:30:42,480 --> 01:30:44,960
can by itself cause

2193
01:30:44,960 --> 01:30:46,719
a burst of arousal and thus an

2194
01:30:46,719 --> 01:30:49,679
antagonistic rebound

2195
01:30:49,679 --> 01:30:51,120
and can

2196
01:30:51,120 --> 01:30:54,400
flip emotions from positive to negative

2197
01:30:54,400 --> 01:30:56,239
in so doing

2198
01:30:56,239 --> 01:30:58,400
and i always loved that discovery

2199
01:30:58,400 --> 01:30:59,600
because

2200
01:30:59,600 --> 01:31:02,960
i especially love discoveries where

2201
01:31:02,960 --> 01:31:05,520
the occurrence of nothing has profound

2202
01:31:05,520 --> 01:31:06,960
effects on

2203
01:31:06,960 --> 01:31:08,960
future behavior

2204
01:31:08,960 --> 01:31:11,520
so it's the non-occurrence of the

2205
01:31:11,520 --> 01:31:14,239
expectation cause of this mismatch

2206
01:31:14,239 --> 01:31:15,760
that can flip

2207
01:31:15,760 --> 01:31:18,320
emotions

2208
01:31:18,320 --> 01:31:20,800
now how this influence of the perception

2209
01:31:20,800 --> 01:31:22,400
of music

2210
01:31:22,400 --> 01:31:24,080
needs more work it's

2211
01:31:24,080 --> 01:31:26,800
as i mentioned my paper i haven't

2212
01:31:26,800 --> 01:31:29,280
tried to study

2213
01:31:29,280 --> 01:31:30,800
that

2214
01:31:30,800 --> 01:31:32,000
uh

2215
01:31:32,000 --> 01:31:32,800
my

2216
01:31:32,800 --> 01:31:35,600
my paper on music i feel is like

2217
01:31:35,600 --> 01:31:38,320
you know a drop in the bucket and

2218
01:31:38,320 --> 01:31:41,199
hopefully if i don't get around to it

2219
01:31:41,199 --> 01:31:43,040
someone else will

2220
01:31:43,040 --> 01:31:45,440
but the above examples show that arousal

2221
01:31:45,440 --> 01:31:47,360
and emotion

2222
01:31:47,360 --> 01:31:50,960
are not the same thing cause arousal

2223
01:31:50,960 --> 01:31:53,280
can support all emotions

2224
01:31:53,280 --> 01:31:56,880
fear relief hunger satiety whatever

2225
01:31:56,880 --> 01:31:59,600
the ones that win the competition

2226
01:31:59,600 --> 01:32:01,360
are then able

2227
01:32:01,360 --> 01:32:03,600
to support compatible behaviors by

2228
01:32:03,600 --> 01:32:06,000
motivating them

2229
01:32:06,000 --> 01:32:07,920
and i've also explained that the level

2230
01:32:07,920 --> 01:32:10,320
of arousal must be chosen

2231
01:32:10,320 --> 01:32:13,600
within an intermediate range

2232
01:32:13,600 --> 01:32:15,840
to support normal behaviors it's a kind

2233
01:32:15,840 --> 01:32:17,520
of golden

2234
01:32:17,520 --> 01:32:18,719
mean

2235
01:32:18,719 --> 01:32:22,480
there's an inverted view

2236
01:32:23,120 --> 01:32:26,159
on the effects of having arousal from

2237
01:32:26,159 --> 01:32:28,400
too little or too much

2238
01:32:28,400 --> 01:32:30,960
and if you have too little arousal

2239
01:32:30,960 --> 01:32:33,440
you have an underarouse syndrome

2240
01:32:33,440 --> 01:32:35,679
which can support

2241
01:32:35,679 --> 01:32:38,480
symptoms like autism

2242
01:32:38,480 --> 01:32:39,360
and

2243
01:32:39,360 --> 01:32:41,920
over arousal can support

2244
01:32:41,920 --> 01:32:45,679
symptoms of abuse like schizophrenia is

2245
01:32:45,679 --> 01:32:47,840
only one of many factors in these

2246
01:32:47,840 --> 01:32:49,199
diseases

2247
01:32:49,199 --> 01:32:52,400
but i'm happy to say that subsequent

2248
01:32:52,400 --> 01:32:54,639
clinical data supported those

2249
01:32:54,639 --> 01:32:56,400
predictions that

2250
01:32:56,400 --> 01:32:58,560
these two mental disorders are at the

2251
01:32:58,560 --> 01:33:00,560
opposite speed

2252
01:33:00,560 --> 01:33:04,560
of the arousal inverted view

2253
01:33:04,560 --> 01:33:07,679
so i think and you know this very

2254
01:33:07,679 --> 01:33:09,520
speculative because i've never really

2255
01:33:09,520 --> 01:33:11,920
seriously studied it and i

2256
01:33:11,920 --> 01:33:15,440
try not to speculate but what the hell

2257
01:33:15,440 --> 01:33:18,159
oh the kind of arousal that music

2258
01:33:18,159 --> 01:33:21,199
activated generally positive just like

2259
01:33:21,199 --> 01:33:23,920
the arousal that activates exploratory

2260
01:33:23,920 --> 01:33:26,960
behaviors is positive

2261
01:33:26,960 --> 01:33:29,120
it somehow links

2262
01:33:29,120 --> 01:33:31,440
that you know music is a

2263
01:33:31,440 --> 01:33:35,280
a sonic adventure if you like

2264
01:33:35,280 --> 01:33:37,520
there's no aversive cue when listening

2265
01:33:37,520 --> 01:33:40,080
to music except perhaps

2266
01:33:40,080 --> 01:33:42,960
music that played so loud as to cause a

2267
01:33:42,960 --> 01:33:44,320
headache or

2268
01:33:44,320 --> 01:33:47,280
ear damage or even a seizure

2269
01:33:47,280 --> 01:33:50,560
insusceptible in the individual stuff

2270
01:33:50,560 --> 01:33:52,480
there's no particular reason why it

2271
01:33:52,480 --> 01:33:54,080
shouldn't be

2272
01:33:54,080 --> 01:33:56,320
um

2273
01:33:56,400 --> 01:33:57,280
uh

2274
01:33:57,280 --> 01:33:59,360
positive

2275
01:33:59,360 --> 01:34:03,199
so now which question you wanna ask me

2276
01:34:03,199 --> 01:34:05,840
uh i think we're left with just two

2277
01:34:05,840 --> 01:34:07,280
other questions

2278
01:34:07,280 --> 01:34:09,120
if

2279
01:34:09,120 --> 01:34:11,520
yeah well not too tired starts where

2280
01:34:11,520 --> 01:34:14,159
there's a final point of comparison

2281
01:34:14,159 --> 01:34:17,520
another starts on a more fearless

2282
01:34:17,520 --> 01:34:21,040
yes uh the last where and the last

2283
01:34:21,040 --> 01:34:23,600
the two questions

2284
01:34:23,600 --> 01:34:25,199
so you want to

2285
01:34:25,199 --> 01:34:26,960
uh how do you see the future of all

2286
01:34:26,960 --> 01:34:29,120
ignorance by their research

2287
01:34:29,120 --> 01:34:32,239
and before that yes before that uh i

2288
01:34:32,239 --> 01:34:33,600
just wanted to

2289
01:34:33,600 --> 01:34:36,560
ask you about the um your view about

2290
01:34:36,560 --> 01:34:41,040
artificial consciousness uh do you see

2291
01:34:41,040 --> 01:34:44,159
i really need the first answer to answer

2292
01:34:44,159 --> 01:34:48,560
the second question okay as you wish yes

2293
01:34:48,560 --> 01:34:50,480
okay so

2294
01:34:50,480 --> 01:34:53,520
so yeah uh and how do you see

2295
01:34:53,520 --> 01:34:55,280
yeah

2296
01:34:55,280 --> 01:34:57,760
yes it's quite fine and uh how do you

2297
01:34:57,760 --> 01:35:01,119
see the future of art and brain inspired

2298
01:35:01,119 --> 01:35:04,080
ai research in general uh in your view

2299
01:35:04,080 --> 01:35:06,639
what research areas ought to gain more

2300
01:35:06,639 --> 01:35:10,400
attention than they do today

2301
01:35:10,400 --> 01:35:14,639
so i'll give you quite a general answer

2302
01:35:14,639 --> 01:35:17,760
but it implies

2303
01:35:18,800 --> 01:35:20,800
what i think about this

2304
01:35:20,800 --> 01:35:23,440
so first with a caveat i like to say i

2305
01:35:23,440 --> 01:35:26,159
couldn't predict the present so i can't

2306
01:35:26,159 --> 01:35:28,800
predict the future

2307
01:35:28,800 --> 01:35:31,520
that being said i believe that all

2308
01:35:31,520 --> 01:35:34,080
engineering technology and ai

2309
01:35:34,080 --> 01:35:36,639
will increasingly embody

2310
01:35:36,639 --> 01:35:39,679
autonomous adaptive intelligence

2311
01:35:39,679 --> 01:35:43,280
in the coming century and we can already

2312
01:35:43,280 --> 01:35:45,040
see its beginnings

2313
01:35:45,040 --> 01:35:47,840
in autonomous automobiles and airplanes

2314
01:35:47,840 --> 01:35:49,600
and increasingly

2315
01:35:49,600 --> 01:35:52,159
autonomous controllers on the factory

2316
01:35:52,159 --> 01:35:54,320
floor and many people

2317
01:35:54,320 --> 01:35:57,040
have written about it

2318
01:35:57,040 --> 01:35:59,600
and i think art will play a central role

2319
01:35:59,600 --> 01:36:02,080
in this as well as other models

2320
01:36:02,080 --> 01:36:03,840
that are summarized in my book and

2321
01:36:03,840 --> 01:36:04,880
that's

2322
01:36:04,880 --> 01:36:09,040
because already in 1980 i published

2323
01:36:09,040 --> 01:36:11,840
a thought experiment

2324
01:36:11,840 --> 01:36:14,239
in the journal psychological review

2325
01:36:14,239 --> 01:36:16,080
which was then and still

2326
01:36:16,080 --> 01:36:17,920
probably remains the leading theory

2327
01:36:17,920 --> 01:36:20,400
journal in psychology

2328
01:36:20,400 --> 01:36:23,360
and you may recall that einstein derived

2329
01:36:23,360 --> 01:36:27,119
both special relativity theory and

2330
01:36:27,119 --> 01:36:29,199
general relativity

2331
01:36:29,199 --> 01:36:31,840
from thought experiments and

2332
01:36:31,840 --> 01:36:33,040
let me just

2333
01:36:33,040 --> 01:36:35,280
clarify by my thought experiment wherein

2334
01:36:35,280 --> 01:36:36,639
they derive

2335
01:36:36,639 --> 01:36:39,360
their enormous power

2336
01:36:39,360 --> 01:36:42,159
so my thought experiment was about how

2337
01:36:42,159 --> 01:36:44,639
any system

2338
01:36:44,639 --> 01:36:45,480
can

2339
01:36:45,480 --> 01:36:49,119
autonomously it's all about autonomy

2340
01:36:49,119 --> 01:36:51,360
correct predictive errors in a changing

2341
01:36:51,360 --> 01:36:52,960
world

2342
01:36:52,960 --> 01:36:55,440
and the hypotheses upon which the

2343
01:36:55,440 --> 01:36:57,840
thought experiment were derived

2344
01:36:57,840 --> 01:37:00,560
are just a few facts that are familiar

2345
01:37:00,560 --> 01:37:02,159
to us all

2346
01:37:02,159 --> 01:37:04,480
from daily life

2347
01:37:04,480 --> 01:37:06,080
and they're familiar because they

2348
01:37:06,080 --> 01:37:08,400
represent ubiquitous

2349
01:37:08,400 --> 01:37:10,400
environmental pressures on the evolution

2350
01:37:10,400 --> 01:37:13,360
of our brains over the millennia

2351
01:37:13,360 --> 01:37:16,000
and when they act together

2352
01:37:16,000 --> 01:37:19,679
i suggest art is the unique outcome

2353
01:37:19,679 --> 01:37:21,199
that's a huge

2354
01:37:21,199 --> 01:37:22,560
claim

2355
01:37:22,560 --> 01:37:23,440
and

2356
01:37:23,440 --> 01:37:25,199
i turned to the power of the thought

2357
01:37:25,199 --> 01:37:28,960
experiment not any personal ego trip

2358
01:37:28,960 --> 01:37:31,440
for that belief

2359
01:37:31,440 --> 01:37:33,760
in particular nowhere in the thought

2360
01:37:33,760 --> 01:37:36,960
experiment of the words mind or brain

2361
01:37:36,960 --> 01:37:38,560
mentioned

2362
01:37:38,560 --> 01:37:40,239
so if you

2363
01:37:40,239 --> 01:37:43,119
accept that these facts about the world

2364
01:37:43,119 --> 01:37:45,679
exist which we all do

2365
01:37:45,679 --> 01:37:48,960
and that they're always operating on us

2366
01:37:48,960 --> 01:37:51,440
then you have to accept the outcome if

2367
01:37:51,440 --> 01:37:52,719
you believe

2368
01:37:52,719 --> 01:37:56,000
in the scientific method and logic

2369
01:37:56,000 --> 01:38:00,239
so art is a universal solution

2370
01:38:00,239 --> 01:38:02,719
to the problem of autonomous

2371
01:38:02,719 --> 01:38:06,320
error correction and changing world

2372
01:38:06,320 --> 01:38:08,080
so in another way if you can't find a

2373
01:38:08,080 --> 01:38:10,480
mistake in the thought experiment

2374
01:38:10,480 --> 01:38:11,840
then i think

2375
01:38:11,840 --> 01:38:13,600
you either have to believe

2376
01:38:13,600 --> 01:38:17,280
in art like dynamics may be expressed in

2377
01:38:17,280 --> 01:38:19,119
laminar or

2378
01:38:19,119 --> 01:38:21,520
your favorite art variant

2379
01:38:21,520 --> 01:38:23,280
or you have to give up your belief in

2380
01:38:23,280 --> 01:38:26,239
logic and the scientific method

2381
01:38:26,239 --> 01:38:28,320
it doesn't imply that art can't be

2382
01:38:28,320 --> 01:38:29,760
further developed

2383
01:38:29,760 --> 01:38:32,159
i expect a large number of scientists

2384
01:38:32,159 --> 01:38:35,199
technology and technologists to be busy

2385
01:38:35,199 --> 01:38:37,520
developing what's like

2386
01:38:37,520 --> 01:38:41,199
architectures long after and gone

2387
01:38:41,199 --> 01:38:42,800
so maybe now we can go to your

2388
01:38:42,800 --> 01:38:45,920
philosophical note with that background

2389
01:38:45,920 --> 01:38:48,239
yes thank you so much

2390
01:38:48,239 --> 01:38:49,520
now uh

2391
01:38:49,520 --> 01:38:51,920
yes uh as i mentioned i mentioned

2392
01:38:51,920 --> 01:38:54,639
earlier uh i just wanted to ask about

2393
01:38:54,639 --> 01:38:57,840
your review about your v1 artificial

2394
01:38:57,840 --> 01:38:59,360
consciousness

2395
01:38:59,360 --> 01:39:01,440
do you see the consciousness as

2396
01:39:01,440 --> 01:39:05,600
artificially producible or engineerable

2397
01:39:05,600 --> 01:39:09,760
as some researchers like mike sormsley

2398
01:39:09,760 --> 01:39:11,520
is there a fundamental distinction

2399
01:39:11,520 --> 01:39:14,239
between a biologically conscious agent

2400
01:39:14,239 --> 01:39:16,639
and an artificial agent with a fully

2401
01:39:16,639 --> 01:39:18,480
simulated computational model of

2402
01:39:18,480 --> 01:39:19,600
consciousness

2403
01:39:19,600 --> 01:39:22,000
i know it's a big big question but i

2404
01:39:22,000 --> 01:39:24,000
couldn't resist asking your opinion as

2405
01:39:24,000 --> 01:39:27,760
an authority on consciousness modeling

2406
01:39:27,760 --> 01:39:30,960
i'm happy to give it a shot

2407
01:39:30,960 --> 01:39:32,159
so

2408
01:39:32,159 --> 01:39:34,560
as i just noted

2409
01:39:34,560 --> 01:39:36,960
my work on art suggests it solves the

2410
01:39:36,960 --> 01:39:39,600
universal problem

2411
01:39:39,600 --> 01:39:41,520
about how we can learn to correct

2412
01:39:41,520 --> 01:39:45,679
predictive errors in a changing world

2413
01:39:45,679 --> 01:39:49,440
my work also shows in its analysis

2414
01:39:49,440 --> 01:39:51,520
of hierarchical resolution of

2415
01:39:51,520 --> 01:39:53,760
uncertainty remember like how you go

2416
01:39:53,760 --> 01:39:56,080
from some a noisy retina

2417
01:39:56,080 --> 01:39:59,520
to a surface representation that can

2418
01:39:59,520 --> 01:40:02,960
control looking and reaching

2419
01:40:02,960 --> 01:40:05,440
uh how evolution may have been driven to

2420
01:40:05,440 --> 01:40:06,719
discover

2421
01:40:06,719 --> 01:40:09,520
conscious states

2422
01:40:09,520 --> 01:40:13,679
so this was a surprise to me too

2423
01:40:13,679 --> 01:40:16,000
conscious states were needed in order to

2424
01:40:16,000 --> 01:40:17,679
choose

2425
01:40:17,679 --> 01:40:20,159
that processing level

2426
01:40:20,159 --> 01:40:22,560
the levels that computes

2427
01:40:22,560 --> 01:40:24,679
a sufficiently complete

2428
01:40:24,679 --> 01:40:27,760
context-sensitive and stable

2429
01:40:27,760 --> 01:40:29,920
representation in the case of vision

2430
01:40:29,920 --> 01:40:32,560
surface representation

2431
01:40:32,560 --> 01:40:35,040
with which to successfully plan and act

2432
01:40:35,040 --> 01:40:37,520
to realize value goals

2433
01:40:37,520 --> 01:40:39,440
but let me make it

2434
01:40:39,440 --> 01:40:40,400
clear

2435
01:40:40,400 --> 01:40:42,239
so you start with a noisy red and you

2436
01:40:42,239 --> 01:40:43,280
have to go

2437
01:40:43,280 --> 01:40:46,080
up all of these stages until

2438
01:40:46,080 --> 01:40:48,719
you get a sufficiently complete

2439
01:40:48,719 --> 01:40:51,040
surface and boundary representation that

2440
01:40:51,040 --> 01:40:52,400
you can use

2441
01:40:52,400 --> 01:40:55,360
to regulate successful action

2442
01:40:55,360 --> 01:40:56,960
and if you used one of the earliest

2443
01:40:56,960 --> 01:40:58,239
stages

2444
01:40:58,239 --> 01:41:01,040
it would lead to incorrect actions which

2445
01:41:01,040 --> 01:41:02,000
would

2446
01:41:02,000 --> 01:41:05,199
kill you off by governing selection

2447
01:41:05,199 --> 01:41:08,320
so how the hell do you know

2448
01:41:08,320 --> 01:41:10,800
where the stage is where you can

2449
01:41:10,800 --> 01:41:13,119
compute the sufficiently complete contra

2450
01:41:13,119 --> 01:41:14,639
extensive

2451
01:41:14,639 --> 01:41:16,639
and stable

2452
01:41:16,639 --> 01:41:18,239
one

2453
01:41:18,239 --> 01:41:22,719
and i sh propose in vision i predicted

2454
01:41:22,719 --> 01:41:24,800
that the choice is embodied in what i

2455
01:41:24,800 --> 01:41:26,719
call a surface

2456
01:41:26,719 --> 01:41:28,719
shroud resonance

2457
01:41:28,719 --> 01:41:31,280
between pre-strike visual cortical area

2458
01:41:31,280 --> 01:41:32,880
v4

2459
01:41:32,880 --> 01:41:35,280
in the next processing stage

2460
01:41:35,280 --> 01:41:38,800
posterior parietal cortex or ppc

2461
01:41:38,800 --> 01:41:41,520
so it's in v4 you get this really good

2462
01:41:41,520 --> 01:41:44,880
surface representation

2463
01:41:44,880 --> 01:41:47,360
and then a resonance

2464
01:41:47,360 --> 01:41:49,679
between the surface and spatial

2465
01:41:49,679 --> 01:41:53,119
attention which fits the surface

2466
01:41:53,119 --> 01:41:56,639
that spatial attention and ppc

2467
01:41:56,639 --> 01:41:59,119
is called a shroud christopher tyler

2468
01:41:59,119 --> 01:42:01,440
gave it that name

2469
01:42:01,440 --> 01:42:05,280
the surface route resonance

2470
01:42:05,280 --> 01:42:06,880
allows you to

2471
01:42:06,880 --> 01:42:08,960
pay conscious

2472
01:42:08,960 --> 01:42:11,679
spatial attention to

2473
01:42:11,679 --> 01:42:14,400
the surface that you're going to use

2474
01:42:14,400 --> 01:42:15,920
to control looking and reaching

2475
01:42:15,920 --> 01:42:17,119
behaviors

2476
01:42:17,119 --> 01:42:19,040
so it's a way of ensuring you have a

2477
01:42:19,040 --> 01:42:21,280
good enough representation to control

2478
01:42:21,280 --> 01:42:23,759
action

2479
01:42:25,440 --> 01:42:27,600
so

2480
01:42:27,600 --> 01:42:29,920
the shroud is computed in posterior

2481
01:42:29,920 --> 01:42:31,760
parietal cortex

2482
01:42:31,760 --> 01:42:34,560
which is part of the dorsal or

2483
01:42:34,560 --> 01:42:37,760
where cortical stream

2484
01:42:37,760 --> 01:42:40,880
and the shroud modulates

2485
01:42:40,880 --> 01:42:43,199
invariant category learning in the

2486
01:42:43,199 --> 01:42:44,639
ventral

2487
01:42:44,639 --> 01:42:46,960
or what cortical stream

2488
01:42:46,960 --> 01:42:49,040
i can't go into that right now but my

2489
01:42:49,040 --> 01:42:51,119
book discusses it

2490
01:42:51,119 --> 01:42:53,280
the category learning itself in the what

2491
01:42:53,280 --> 01:42:55,760
cortical stream as i indicated

2492
01:42:55,760 --> 01:42:58,239
is supported by a feature category

2493
01:42:58,239 --> 01:43:00,239
resonance

2494
01:43:00,239 --> 01:43:01,280
and so

2495
01:43:01,280 --> 01:43:03,840
the surface shroud resonance is

2496
01:43:03,840 --> 01:43:07,119
modulating in varying category learning

2497
01:43:07,119 --> 01:43:10,480
uh in the future category resonances

2498
01:43:10,480 --> 01:43:13,199
surface shroud resonance also supports

2499
01:43:13,199 --> 01:43:15,280
conscious seeing

2500
01:43:15,280 --> 01:43:17,199
the future category resonance is

2501
01:43:17,199 --> 01:43:18,400
supporting

2502
01:43:18,400 --> 01:43:21,040
conscious recognition

2503
01:43:21,040 --> 01:43:23,440
and when they synchronize the course

2504
01:43:23,440 --> 01:43:25,040
streams

2505
01:43:25,040 --> 01:43:27,600
on a familiar object

2506
01:43:27,600 --> 01:43:30,239
that's when you consciously see

2507
01:43:30,239 --> 01:43:33,599
something that you know about

2508
01:43:33,679 --> 01:43:36,639
okay so

2509
01:43:36,639 --> 01:43:39,040
conscious states hereby arise due to

2510
01:43:39,040 --> 01:43:40,480
learning

2511
01:43:40,480 --> 01:43:42,560
requirements

2512
01:43:42,560 --> 01:43:45,440
this sort of fell out of the wash

2513
01:43:45,440 --> 01:43:46,639
of

2514
01:43:46,639 --> 01:43:50,639
how you do invariant category learning

2515
01:43:50,639 --> 01:43:53,440
and learning in particular without

2516
01:43:53,440 --> 01:43:55,600
catastrophic forgetting it's regulating

2517
01:43:55,600 --> 01:43:58,239
feature category resonances

2518
01:43:58,239 --> 01:44:00,639
so given that the above solutions are

2519
01:44:00,639 --> 01:44:03,520
computationally universal

2520
01:44:03,520 --> 01:44:06,400
in the sense i sketch

2521
01:44:06,400 --> 01:44:08,480
the self-organizing machine that

2522
01:44:08,480 --> 01:44:11,280
embodies them

2523
01:44:11,280 --> 01:44:13,639
should be able to support internal

2524
01:44:13,639 --> 01:44:16,320
representations whose parametric

2525
01:44:16,320 --> 01:44:20,560
properties mimic conscious states

2526
01:44:20,560 --> 01:44:23,119
well whether such a machine can

2527
01:44:23,119 --> 01:44:26,159
experience conscious qualia

2528
01:44:26,159 --> 01:44:28,880
remains as much of a mystery the

2529
01:44:28,880 --> 01:44:30,800
machines as it does

2530
01:44:30,800 --> 01:44:33,040
to humans

2531
01:44:33,040 --> 01:44:35,520
and that's because no computational

2532
01:44:35,520 --> 01:44:38,480
theory which after all is just a set of

2533
01:44:38,480 --> 01:44:40,639
equations

2534
01:44:40,639 --> 01:44:42,719
uh can't do more than imitate the

2535
01:44:42,719 --> 01:44:45,600
dynamics of our brains perhaps with

2536
01:44:45,600 --> 01:44:47,600
great precision

2537
01:44:47,600 --> 01:44:50,000
i don't have a clue

2538
01:44:50,000 --> 01:44:51,520
why

2539
01:44:51,520 --> 01:44:52,360
the

2540
01:44:52,360 --> 01:44:54,800
representations that my colleague and

2541
01:44:54,800 --> 01:44:57,920
i've worked so hard to explain huge

2542
01:44:57,920 --> 01:45:00,000
amounts of psychophysical data about

2543
01:45:00,000 --> 01:45:02,000
seeing

2544
01:45:02,000 --> 01:45:04,239
extra shading

2545
01:45:04,239 --> 01:45:05,460
3d form

2546
01:45:05,460 --> 01:45:07,360
[Music]

2547
01:45:07,360 --> 01:45:09,600
just go through the list

2548
01:45:09,600 --> 01:45:12,080
why they support qualia

2549
01:45:12,080 --> 01:45:14,080
i don't know

2550
01:45:14,080 --> 01:45:16,800
they ask god

2551
01:45:16,800 --> 01:45:18,960
or whatever god you

2552
01:45:18,960 --> 01:45:24,080
choose to believe in in the 21st century

2553
01:45:25,679 --> 01:45:28,560
thank you so much professor um i think

2554
01:45:28,560 --> 01:45:30,400
we have a couple of questions in the

2555
01:45:30,400 --> 01:45:33,280
chat but uh we are actually approaching

2556
01:45:33,280 --> 01:45:36,239
our two-hour limit i don't know daniel

2557
01:45:36,239 --> 01:45:37,840
if uh

2558
01:45:37,840 --> 01:45:40,960
it's a good place to stop or

2559
01:45:40,960 --> 01:45:43,040
whatever you say

2560
01:45:43,040 --> 01:45:45,520
i think that's a great place to stop

2561
01:45:45,520 --> 01:45:47,679
you've given us a lot to

2562
01:45:47,679 --> 01:45:49,679
to think about and digest

2563
01:45:49,679 --> 01:45:52,800
and i hope that these words are

2564
01:45:52,800 --> 01:45:55,600
taken well and paid attention to might

2565
01:45:55,600 --> 01:45:57,679
create some categories activate some

2566
01:45:57,679 --> 01:45:59,440
categories

2567
01:45:59,440 --> 01:46:02,239
um but professor grossberg thanks again

2568
01:46:02,239 --> 01:46:04,080
for this amazing live stream we really

2569
01:46:04,080 --> 01:46:06,159
appreciate it i appreciate it i'm

2570
01:46:06,159 --> 01:46:08,000
depending on younger people like

2571
01:46:08,000 --> 01:46:09,280
yourself

2572
01:46:09,280 --> 01:46:11,440
that do just what you said daniel i'm

2573
01:46:11,440 --> 01:46:14,000
not going to be around that much longer

2574
01:46:14,000 --> 01:46:15,920
so um

2575
01:46:15,920 --> 01:46:18,239
i i hope you have

2576
01:46:18,239 --> 01:46:21,119
whether with my work directly or related

2577
01:46:21,119 --> 01:46:23,119
work you have a very

2578
01:46:23,119 --> 01:46:26,800
fulfilling intellectual adventure i know

2579
01:46:26,800 --> 01:46:30,000
i've been on a wild ride since i was 17

2580
01:46:30,000 --> 01:46:30,880
and

2581
01:46:30,880 --> 01:46:35,040
that's 65 years of discovery and

2582
01:46:35,040 --> 01:46:38,639
i've loved every minute of it

2583
01:46:39,119 --> 01:46:40,639
thank you very much

2584
01:46:40,639 --> 01:46:42,320
see you soon

2585
01:46:42,320 --> 01:46:43,360
thank you

2586
01:46:43,360 --> 01:46:45,199
it was really pleasure meeting you thank

2587
01:46:45,199 --> 01:46:47,360
you

2588
01:46:47,760 --> 01:46:49,920
thank you

2589
01:46:49,920 --> 01:46:51,760
so you'll tell me when i'll see this

2590
01:46:51,760 --> 01:46:52,840
right

2591
01:46:52,840 --> 01:46:57,800
somewhere on youtube awesome

2592
01:47:16,320 --> 01:47:18,400
you

