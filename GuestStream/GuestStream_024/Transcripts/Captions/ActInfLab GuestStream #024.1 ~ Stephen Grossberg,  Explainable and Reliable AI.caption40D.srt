1
00:00:01,334 --> 00:00:03,436
DANIEL FRIEDMAN: Hello and welcome, everyone!

2
00:00:03,436 --> 00:00:06,439
It is June 28th, 2022

3
00:00:07,107 --> 00:00:09,609
and we are here in ActInfLab GuestStream

4
00:00:09,609 --> 00:00:11,811
number 24.1.

5
00:00:12,712 --> 00:00:15,315
Today we're here with Professor
Stephen Grossberg

6
00:00:15,782 --> 00:00:19,352
and the agenda will be as follows.

7
00:00:19,786 --> 00:00:22,822
First,
Ali will provide a short introduction.

8
00:00:23,356 --> 00:00:25,925
We will then play a 45 minute

9
00:00:26,192 --> 00:00:29,963
prerecorded video followed by a Q&A.

10
00:00:30,363 --> 00:00:32,999
So thanks, everyone, for joining.

11
00:00:32,999 --> 00:00:36,436
And Professor Grossberg,
really appreciate joining.

12
00:00:36,503 --> 00:00:39,639
And I'll pass to Ali
for the introduction.

13
00:00:42,842 --> 00:00:43,877
ALI RAHMJOO: Hello and welcome!

14
00:00:43,877 --> 00:00:46,646
I'm Ali. I'm an independent researcher
from Iran.

15
00:00:46,713 --> 00:00:50,083
I'm very happy and excited to be here
and be able to speak with

16
00:00:50,784 --> 00:00:52,852
{Professor and} Professor Grossberg today.

17
00:00:53,553 --> 00:00:57,023
So I'd like to thank Professor Grossberg
for joining us.

18
00:00:58,091 --> 00:01:02,462
Stephen Grossberg is the Wang Professor
of Cognitive and Neural Systems

19
00:01:02,462 --> 00:01:06,633
and a professor emeritus of mathematics
in the statistics, psychological

20
00:01:06,633 --> 00:01:10,236
and brain sciences and biomedical
engineering at Boston University.

21
00:01:11,371 --> 00:01:13,006
For more than 50 years,

22
00:01:13,006 --> 00:01:16,309
he has led pioneering research
in discovering and developing

23
00:01:16,309 --> 00:01:19,779
neural design principles
for autonomous adaptive intelligence

24
00:01:19,779 --> 00:01:22,215
based on biological and machine learning.

25
00:01:23,083 --> 00:01:24,651
His neural network models

26
00:01:24,651 --> 00:01:29,222
have been applied to many large scale
problems in engineering and technology,

27
00:01:29,222 --> 00:01:31,091
including the design of increasingly

28
00:01:31,091 --> 00:01:34,160
autonomous
adaptive algorithms and mobile agents.

29
00:01:34,961 --> 00:01:38,431
In fact,
this is what Karl Friston says about him.

30
00:01:38,898 --> 00:01:43,403
Whenever you claim to be the first to do
this or that in artificial intelligence,

31
00:01:43,703 --> 00:01:48,808
it is customary and correct to add,
with the exception of Stephen Grossberg.

32
00:01:49,209 --> 00:01:52,078
Quite simply, Stephen is a living giant

33
00:01:52,078 --> 00:01:54,414
and foundational architect of the field.

34
00:01:55,782 --> 00:01:59,018
Professor
Grossberg is the recipient of the 2015

35
00:01:59,018 --> 00:02:02,422
Norman Anderson Lifetime Achievement
Award of the Society

36
00:02:02,422 --> 00:02:08,061
of Experimental Psychologists, the 2017
Frank Rosenblatt Award of the Tripoli

37
00:02:08,294 --> 00:02:12,432
Computational Intelligence Society
and the 2019

38
00:02:12,699 --> 00:02:16,536
Donald Wahab Award of the International
Neural Network Society.

39
00:02:17,470 --> 00:02:21,875
His latest book, "Conscious Mind, Resonant
Brain," as a culmination of his decades

40
00:02:21,875 --> 00:02:26,012
long research written in a rather
non-technical and conversational style,

41
00:02:26,279 --> 00:02:29,716
is published in 2021
by Oxford University Press

42
00:02:30,650 --> 00:02:34,587
and is the winner of the Association
of American Publishers in 2022

43
00:02:34,954 --> 00:02:38,725
Prose Award for the Best
Book of the Year in Neuroscience.

44
00:02:39,292 --> 00:02:42,629
Now I'll pass it to Professor Grossberg
and then we'll continue

45
00:02:42,629 --> 00:02:50,003
with the 45 minute prerecorded lecture.

46
00:02:50,003 --> 00:02:51,237
FRIEDMAN: If you'd like to say hi...

47
00:02:51,237 --> 00:02:53,406
otherwise, I'll begin the video.

48
00:02:53,473 --> 00:02:56,676
GROSSBERG: (I just saw my face frozen on the screen!)

49
00:02:57,510 --> 00:03:00,346
Well, I'm delighted to be here, and

50
00:03:01,714 --> 00:03:02,282
I hope you

51
00:03:02,282 --> 00:03:05,018
find some
points of interest in the lecture.

52
00:03:05,585 --> 00:03:09,289
And I'll look forward to the Q&A.

53
00:03:09,322 --> 00:03:14,827
Ali has prepared a series of questions
that I've thought about

54
00:03:14,827 --> 00:03:18,631
and have some prepared, sketched answers.

55
00:03:18,631 --> 00:03:24,470
And then after that, if you're
still interested, I'm happy to do.

56
00:03:25,071 --> 00:03:28,775
Live Q&A about anything related

57
00:03:29,275 --> 00:03:32,579
to the topics of the day.

58
00:03:34,214 --> 00:03:36,616
FRIEDMAN: OK! - On to the main course.

59
00:03:36,616 --> 00:03:39,586
I will play the video now.

60
00:03:42,088 --> 00:03:44,424
(And you won't hear anything on the live
stream.

61
00:03:45,391 --> 00:03:47,627
I'll crop it,
and the audio will be coming through

62
00:03:47,627 --> 00:03:49,929
fine now.)

63
00:03:53,366 --> 00:03:54,667
GROSSBERG (via video): Hello!

64
00:03:55,235 --> 00:03:58,304
I'm delighted to be able
to speak to you today

65
00:03:58,871 --> 00:04:02,909
about a topic concerning
artificial intelligence,

66
00:04:02,909 --> 00:04:06,613
which, as you know,
is very much in the news these days.

67
00:04:07,213 --> 00:04:11,351
And I'll be contrasting
two very different approaches

68
00:04:11,784 --> 00:04:14,087
to artificial intelligence.

69
00:04:14,087 --> 00:04:17,190
But to do that, I need to pull up

70
00:04:17,724 --> 00:04:20,860
my PowerPoint slide cards

71
00:04:21,928 --> 00:04:24,530
and share them with you

72
00:04:24,530 --> 00:04:27,000
and let me maximize them

73
00:04:27,767 --> 00:04:31,137
and minimize my space.

74
00:04:32,505 --> 00:04:34,707
So my topic today

75
00:04:35,108 --> 00:04:37,844
is explainable and reliable. A.I.

76
00:04:38,344 --> 00:04:41,881
Comparing deep learning with adaptive

77
00:04:41,881 --> 00:04:44,851
resonance.

78
00:04:45,151 --> 00:04:48,788
This lecture is based
on the following article from this year,

79
00:04:49,389 --> 00:04:53,426
which is both open access
and on my web page.

80
00:04:54,127 --> 00:04:57,630
The articles summarizes
core problems of deep learning,

81
00:04:58,131 --> 00:05:00,500
such as its untrustworthiness.

82
00:05:00,900 --> 00:05:05,071
Because it's unexplainable
and it's unreliable

83
00:05:05,905 --> 00:05:09,609
because it experiences
catastrophic forgetting.

84
00:05:10,443 --> 00:05:14,447
The article explains
how adaptive resonance overcomes

85
00:05:14,447 --> 00:05:18,885
these problem and indeed overcomes
17 problems of deep learning

86
00:05:19,385 --> 00:05:23,623
and outlines
a blueprint for achieving autonomous

87
00:05:23,623 --> 00:05:26,326
adaptive intel diligence.

88
00:05:27,560 --> 00:05:31,531
The article is part of a frontiers
in robotics special issue

89
00:05:31,531 --> 00:05:35,902
about explainable A.I.,
whose editors wrote and I quote,

90
00:05:37,470 --> 00:05:40,473
though deep learning
is the main pillar of current A.I.

91
00:05:40,473 --> 00:05:46,279
techniques and is ubiquitous in
basic science in real world applications.

92
00:05:46,946 --> 00:05:50,750
It is also flagged by AI researchers

93
00:05:50,750 --> 00:05:53,252
for its black box problem.

94
00:05:53,820 --> 00:05:57,990
It is easy to fool us
and it also cannot explain

95
00:05:57,990 --> 00:06:01,060
how it makes a prediction or decision.

96
00:06:01,861 --> 00:06:05,098
In other words,
deep learning is not trustworthy.

97
00:06:05,665 --> 00:06:07,767
No life or death decision,

98
00:06:08,167 --> 00:06:11,137
such as a medical or financial decision,

99
00:06:11,637 --> 00:06:17,043
can confidently be made
based upon a deep learning prediction.

100
00:06:18,578 --> 00:06:21,147
Deep learning is in the back propagation

101
00:06:21,647 --> 00:06:25,385
algorithm for learning
how to predict out the factors

102
00:06:25,385 --> 00:06:27,987
in response to win protect is

103
00:06:28,621 --> 00:06:32,525
that propagation was based on perceptron
learning principles

104
00:06:32,525 --> 00:06:37,530
that Frank Rosenblatt's
started to introduce in the 1950s.

105
00:06:38,398 --> 00:06:42,535
It has a complicated history,
which Juergen Schmidthuber

106
00:06:43,169 --> 00:06:46,472
beautifully refuted in an article
from this year.

107
00:06:47,607 --> 00:06:49,809
Major contributors include Shinichi

108
00:06:49,809 --> 00:06:52,812
Amari for Bros and David Parker.

109
00:06:53,646 --> 00:06:57,950
Perhaps one would say that
it reached its modern form with simulated

110
00:06:57,950 --> 00:07:02,388
applications in Paul's 1974 paper

111
00:07:02,755 --> 00:07:05,691
before being popularized 12 years later

112
00:07:06,259 --> 00:07:09,362
by Rummel, Hart, Hinton and Williams

113
00:07:10,830 --> 00:07:14,834
is a schematic of a back propagation
circuit with printed word

114
00:07:15,368 --> 00:07:19,839
from a survey article by Gail
Carpenter of Neural Network Models.

115
00:07:20,673 --> 00:07:24,310
Any information flows, feedforward

116
00:07:24,677 --> 00:07:28,147
from an input stage to an output stage.

117
00:07:29,449 --> 00:07:29,882
Learning

118
00:07:29,882 --> 00:07:34,187
is supervised by an external teacher
who on each trial

119
00:07:34,387 --> 00:07:37,523
defines a target or desired output.

120
00:07:38,791 --> 00:07:40,927
The teaching signal is the error

121
00:07:40,927 --> 00:07:43,563
or mismatch between the actual

122
00:07:43,996 --> 00:07:46,232
and the target outputs.

123
00:07:47,567 --> 00:07:49,802
The teaching signal in level

124
00:07:50,002 --> 00:07:52,872
three of adaptive weights

125
00:07:52,872 --> 00:07:56,709
and level left to have no network pathway

126
00:07:56,709 --> 00:08:00,179
whereby to reach from F3
to EC2 within the algorithm.

127
00:08:00,780 --> 00:08:05,418
So the algorithm uses an artifice
called way transport,

128
00:08:05,818 --> 00:08:10,089
which physically lifts the weights
from here and moves them there

129
00:08:10,089 --> 00:08:12,825
so that they can be used to control
learning.

130
00:08:13,392 --> 00:08:17,163
Well,
this is clearly a non-local operation

131
00:08:18,564 --> 00:08:21,234
as well as being clearly

132
00:08:21,234 --> 00:08:25,071
non-biological.

133
00:08:25,471 --> 00:08:26,939
Back propagation learns

134
00:08:26,939 --> 00:08:30,877
through slow learning, which means that
the adaptive weights change

135
00:08:30,877 --> 00:08:35,715
just a little to reduce error
on each learning trial.

136
00:08:36,182 --> 00:08:40,286
That requires many trials,
that is to say, many repetitions

137
00:08:40,286 --> 00:08:43,322
of the whole database to learn possibly

138
00:08:43,589 --> 00:08:46,359
hundreds or thousands of trials.

139
00:08:47,426 --> 00:08:50,062
This is to be contrasted with fast
learning

140
00:08:50,463 --> 00:08:55,434
where adaptive weights zero error signals
on each trial, just as we can learn

141
00:08:55,434 --> 00:08:59,372
a phase that we see just once
and remember it for a long time.

142
00:08:59,972 --> 00:09:02,975
If back prop try to use fast
learning would become

143
00:09:03,342 --> 00:09:06,445
wildly unstable.

144
00:09:06,445 --> 00:09:09,415
Catastrophic
forgetting also occurs in back prop

145
00:09:09,715 --> 00:09:13,452
so that during any learning trial,
an untreated active

146
00:09:13,553 --> 00:09:18,057
part of its learning memory
can unexpectedly collapse.

147
00:09:19,692 --> 00:09:22,261
So deep learning, which is based on back

148
00:09:22,261 --> 00:09:24,764
propagation, is thus neither reliable

149
00:09:25,231 --> 00:09:28,134
nor trustworthy.

150
00:09:28,134 --> 00:09:29,835
But why is this?

151
00:09:29,835 --> 00:09:34,740
One reason is that all inputs a process
by a shared set of learned weights,

152
00:09:35,341 --> 00:09:37,743
the algorithm cannot selectively buffer

153
00:09:37,743 --> 00:09:41,180
learned weights
that are still predictably useful.

154
00:09:41,647 --> 00:09:44,250
In particular,
there's no attention mechanism.

155
00:09:45,284 --> 00:09:49,455
This problem occurs in any learning
algorithm whose shared weight updates

156
00:09:49,922 --> 00:09:53,726
follow the gradient of the error
in response

157
00:09:53,726 --> 00:09:59,131
to the current batch of data points
while ignoring past actions.

158
00:10:00,333 --> 00:10:00,700
There have been

159
00:10:00,700 --> 00:10:03,469
multiple efforts to fix back propagation.

160
00:10:04,036 --> 00:10:08,774
One is to selectively slow learning
on the weights, important for learning

161
00:10:09,208 --> 00:10:12,211
by optimizing parameters
using the Bayes rule,

162
00:10:12,211 --> 00:10:16,115
as Kirkpatrick Atoll
suggested a few years ago.

163
00:10:16,749 --> 00:10:19,919
But that assumes and omniscient observer

164
00:10:20,319 --> 00:10:22,455
who can discover and alter

165
00:10:24,290 --> 00:10:26,659
the important weights

166
00:10:26,659 --> 00:10:32,131
as well as non-local computation
such as the Bayesian computation.

167
00:10:32,732 --> 00:10:36,035
The same problem occurs
with evolutionary algorithms

168
00:10:36,602 --> 00:10:39,138
and diffusion based neuromodulation

169
00:10:39,138 --> 00:10:42,475
and other approaches
to try to fix spectra from

170
00:10:44,110 --> 00:10:47,279
these efforts to overcome catastrophic
forgetting

171
00:10:47,747 --> 00:10:52,151
created additional conceptual
and computational problems.

172
00:10:53,019 --> 00:10:56,322
I view them as adding epicycles
to ameliorate

173
00:10:56,322 --> 00:11:00,860
a fundamental flaw in the model,
which to me is reminiscent of adding

174
00:11:00,860 --> 00:11:05,931
Epicycles to correct problems in the
Ptolemaic model of the solar system.

175
00:11:06,599 --> 00:11:08,801
As we all know, the Copernican model

176
00:11:09,068 --> 00:11:12,872
that we now
accept didn't require epicycles.

177
00:11:14,006 --> 00:11:16,108
Perhaps this is why Geoffrey Hinton,

178
00:11:16,108 --> 00:11:20,146
who played a key role in developing
both back prop and deep learning,

179
00:11:20,146 --> 00:11:24,583
said in an Axios interview
a few years ago that, quote,

180
00:11:24,984 --> 00:11:27,887
he's "deeply
suspicious of back propagation.

181
00:11:28,487 --> 00:11:30,956
I don't think it's how the brain works.

182
00:11:31,457 --> 00:11:34,493
We clearly don't need
all the labeled data.

183
00:11:35,094 --> 00:11:37,263
My view is throw it all away

184
00:11:37,730 --> 00:11:39,832
and start over."

185
00:11:40,933 --> 00:11:43,536
I would claim we don't have to start over

186
00:11:43,969 --> 00:11:49,809
because these problems were solved
in the 1970s and 1980s

187
00:11:50,376 --> 00:11:55,081
in particular in the first issue
of the journal Neural Networks in 1988.

188
00:11:55,548 --> 00:11:59,318
I had an article that listed
17 Problems of Back

189
00:11:59,318 --> 00:12:03,489
Propagation that are overcome
by adaptive resonance.

190
00:12:03,956 --> 00:12:06,325
And here they are

191
00:12:08,027 --> 00:12:10,863
with regard to not needing to label data.

192
00:12:11,430 --> 00:12:16,502
I noted in the third item here
that self-organized, unsupervised,

193
00:12:16,502 --> 00:12:20,973
unsupervised learning
frees us from needing labels all the time

194
00:12:21,674 --> 00:12:23,876
as to slow learning.

195
00:12:24,310 --> 00:12:28,714
I noted that in art
you can have fast or slow learning.

196
00:12:29,315 --> 00:12:30,549
Indeed.

197
00:12:30,549 --> 00:12:34,253
Or can learn to classify
an entire database

198
00:12:34,620 --> 00:12:39,291
using fast learning on a single learning
trial, says Gale Carpenter.

199
00:12:39,291 --> 00:12:42,328
And I showed in the 1980s.

200
00:12:42,962 --> 00:12:48,734
Rover Auto overcomes
all 17 problems of back propagation

201
00:12:49,168 --> 00:12:51,537
without ex bicycles.

202
00:12:51,937 --> 00:12:53,072
Furthermore,

203
00:12:54,306 --> 00:12:54,940
all the

204
00:12:54,940 --> 00:12:58,210
core AI predictions have been supported

205
00:12:58,744 --> 00:13:03,449
by subsequent psychological
and neurobiological data.

206
00:13:04,016 --> 00:13:06,185
Indeed, art is the principle,

207
00:13:06,519 --> 00:13:09,922
biological and technological theory.

208
00:13:10,389 --> 00:13:12,958
Unlike back prop and deep learning,

209
00:13:13,292 --> 00:13:15,961
which are just AI algorithms,

210
00:13:17,296 --> 00:13:22,034
Art has explained data from hundreds
of experiments, and it's made scores

211
00:13:22,034 --> 00:13:26,972
of predictions that have subsequently
received experimental support.

212
00:13:28,073 --> 00:13:30,543
But why has it been so successful?

213
00:13:31,110 --> 00:13:33,846
There are a number of reasons,
but one of them is

214
00:13:34,313 --> 00:13:39,485
that art can be derived from its thought
experiment about a universal problem

215
00:13:39,485 --> 00:13:44,790
an error correction that I published
40 years ago in Psychological Review.

216
00:13:45,858 --> 00:13:48,127
The thought experiment asks the question,

217
00:13:48,761 --> 00:13:51,330
How can a coding error be corrected

218
00:13:51,764 --> 00:13:56,168
if no individual cell knows
that one has occurred?

219
00:13:56,836 --> 00:13:59,605
Let me quote from my paper

220
00:13:59,605 --> 00:14:02,341
The importance of this issue
becomes clear

221
00:14:02,741 --> 00:14:05,444
when we realize that erroneous cues

222
00:14:05,744 --> 00:14:08,881
can accidentally be incorporated
into a code

223
00:14:09,315 --> 00:14:12,384
when our interactions
with the environment is both

224
00:14:12,751 --> 00:14:14,987
and will only become evident

225
00:14:14,987 --> 00:14:18,791
when our environmental expectations
become more demanding.

226
00:14:19,625 --> 00:14:22,328
And even if our code perfectly matched

227
00:14:22,328 --> 00:14:25,831
a given environment,
we would certainly make errors.

228
00:14:26,232 --> 00:14:28,534
As the environment itself fluctuates.

229
00:14:29,001 --> 00:14:32,671
So I was talking about
autonomous local learning

230
00:14:33,672 --> 00:14:36,909
in a changing world,

231
00:14:37,042 --> 00:14:40,045
a purely logical inquiry into error
correction

232
00:14:40,045 --> 00:14:43,215
is translated
at every step of the thought

233
00:14:43,215 --> 00:14:46,018
experiment into processes.

234
00:14:46,352 --> 00:14:49,922
Learning autonomously in real time

235
00:14:50,289 --> 00:14:52,925
with only locally computed quantities.

236
00:14:53,525 --> 00:14:57,263
Moreover, the thought experiment uses
familiar environmental facts

237
00:14:57,663 --> 00:15:00,599
about how we learn as its hypotheses

238
00:15:01,066 --> 00:15:03,469
and short circuits naturally emerge

239
00:15:03,903 --> 00:15:06,672
where these facts are familiar
because they are you.

240
00:15:06,805 --> 00:15:10,142
They are ubiquitous
environmental constraints

241
00:15:10,476 --> 00:15:12,811
on the evolution of our brains.

242
00:15:12,811 --> 00:15:15,347
And since we're living with them
all the time,

243
00:15:15,581 --> 00:15:18,517
they become familiar

244
00:15:18,517 --> 00:15:19,351
because of this.

245
00:15:19,351 --> 00:15:23,022
Universally,
earth circuits made us in some form

246
00:15:23,455 --> 00:15:27,326
be embodied in all future
truly autonomous.

247
00:15:27,326 --> 00:15:30,896
Adaptive, intelligent devices
with a biological

248
00:15:30,896 --> 00:15:34,133
or artificial,

249
00:15:34,133 --> 00:15:36,135
or it has probably for this reason

250
00:15:37,503 --> 00:15:40,005
already been used in many large scale

251
00:15:40,339 --> 00:15:43,742
engineering
and technological applications.

252
00:15:44,877 --> 00:15:45,444
In fact,

253
00:15:45,444 --> 00:15:49,014
almost immediately after
it was introduced,

254
00:15:49,014 --> 00:15:53,752
it began being used
because it succeeded in benchmark studies

255
00:15:53,752 --> 00:15:58,290
against machine learning, back
propagation, statistical methods,

256
00:15:58,290 --> 00:16:02,761
genetic algorithms
either getting much better accuracy

257
00:16:03,195 --> 00:16:05,965
or much faster training, speed or both.

258
00:16:06,732 --> 00:16:11,170
It's also used in applications
where other algorithms totally fail,

259
00:16:11,570 --> 00:16:14,273
such as the Boeing Company's port

260
00:16:14,707 --> 00:16:17,176
design, reuse and inventory

261
00:16:17,509 --> 00:16:20,412
compression application.

262
00:16:21,046 --> 00:16:25,084
That's just one of many large scale
applications in engineering and

263
00:16:25,084 --> 00:16:30,255
technology, some of which can be found
on our Tech Live Web page at B.U.

264
00:16:30,255 --> 00:16:31,991
dot edu.

265
00:16:31,991 --> 00:16:35,260
The Boeing parts design
retrieval system in particular

266
00:16:35,728 --> 00:16:40,132
was used to help design the Boeing 777.

267
00:16:41,467 --> 00:16:45,104
And to do that, you needed fast
learning and stable memory to learn

268
00:16:45,104 --> 00:16:48,307
and search a huge and continually

269
00:16:48,307 --> 00:16:51,010
growing non stationary parts inventory.

270
00:16:51,443 --> 00:16:53,779
At the time of this application.

271
00:16:53,779 --> 00:16:58,550
There are already 16 million, 1
million dimensional vectors

272
00:16:58,951 --> 00:17:03,055
that were used
to describe each of the parts

273
00:17:03,322 --> 00:17:06,091
and you have to be able
to quickly search the inventory

274
00:17:06,091 --> 00:17:09,728
if you want to find a part
to use in a new plane,

275
00:17:10,462 --> 00:17:14,400
especially if your new design
might have a part in the inventory

276
00:17:14,400 --> 00:17:15,968
that was similar to it.

277
00:17:15,968 --> 00:17:18,971
Finding it and slightly modifying design

278
00:17:18,971 --> 00:17:23,342
could save millions of
dollars in fabrication costs.

279
00:17:24,476 --> 00:17:25,544
Satellite Remote

280
00:17:25,544 --> 00:17:29,982
sensing is another large scale
application that art was used

281
00:17:29,982 --> 00:17:34,553
for very soon, and Gail Carpenter
and a colleagues took the lead here

282
00:17:35,054 --> 00:17:38,690
for example,
using a very small number of pixels

283
00:17:38,690 --> 00:17:43,328
of ground truth of 17 vegetation classes.

284
00:17:43,862 --> 00:17:47,499
They used art to automatically complete

285
00:17:49,568 --> 00:17:52,404
these maps

286
00:17:53,739 --> 00:17:55,774
using remote sensing data.

287
00:17:56,375 --> 00:17:59,311
Or did it in a day rapidly

288
00:17:59,311 --> 00:18:03,015
and automatically,
it gave a confidence map for each pixel

289
00:18:03,348 --> 00:18:05,651
and the pixels with 30 meters

290
00:18:06,018 --> 00:18:09,054
in scale,
which was small enough to see roads.

291
00:18:09,555 --> 00:18:14,927
This contrasted with an AI expert system
which took a whole year to do with

292
00:18:15,360 --> 00:18:19,465
and it had to derive at ad hoc rules
from experts.

293
00:18:19,832 --> 00:18:23,902
You had to correct up upwards
of a quarter of a million site labels.

294
00:18:24,269 --> 00:18:26,905
And even so, the pixel size

295
00:18:26,905 --> 00:18:29,975
was an order of magnitude larger.

296
00:18:31,577 --> 00:18:32,611
Gail went on

297
00:18:32,611 --> 00:18:36,748
with her colleagues to study
information, fusion and remote sensing.

298
00:18:37,082 --> 00:18:39,585
Let's say you have multiple observers.

299
00:18:40,018 --> 00:18:43,655
Each of them may be using different
labels.

300
00:18:43,989 --> 00:18:48,794
The labels may also be incomplete
or missing or even incorrect.

301
00:18:48,794 --> 00:18:52,531
And the task was to derive
consistent knowledge

302
00:18:52,531 --> 00:18:57,069
from potentially inconsistent data
to automatically learn

303
00:18:57,069 --> 00:19:01,240
and stably store one too many mappings.

304
00:19:01,807 --> 00:19:05,344
And along the way, Gail and a colleague
showed how to self-organize

305
00:19:05,344 --> 00:19:11,016
a hierarchy of cognitive rules,
including confidence measures

306
00:19:11,383 --> 00:19:14,453
between these different levels
of the hierarchy.

307
00:19:16,221 --> 00:19:18,190
There's been continual work on art.

308
00:19:18,190 --> 00:19:23,162
Some more recent work was summarized
in a special issue of neural networks

309
00:19:23,495 --> 00:19:26,465
just in in December 2019

310
00:19:26,832 --> 00:19:31,203
that was edited by Donald Bunch,
who started the special issue

311
00:19:31,203 --> 00:19:33,238
with a general overview

312
00:19:33,238 --> 00:19:36,575
of neural network models
that I and my colleagues developed,

313
00:19:36,909 --> 00:19:40,712
and then went on in a long
and detailed article

314
00:19:40,712 --> 00:19:45,117
with several collaborators
to provide a survey of adaptive

315
00:19:45,117 --> 00:19:48,720
resonance theory neural network models
for engineering applications

316
00:19:49,021 --> 00:19:53,492
to the present time,

317
00:19:53,492 --> 00:19:58,197
so that propagation and deep learning
are a feedforward adaptive filter.

318
00:19:58,230 --> 00:20:00,499
But art is more than that.

319
00:20:00,999 --> 00:20:04,203
In fact, art is explainable

320
00:20:04,636 --> 00:20:07,272
self-organizing production system

321
00:20:07,773 --> 00:20:09,975
in a non stationary world.

322
00:20:10,742 --> 00:20:12,544
What do these words mean?

323
00:20:13,679 --> 00:20:15,214
Or self-organizing.

324
00:20:15,214 --> 00:20:21,920
Because they can autonomously carry out
arbitrary combinations of unsupervised

325
00:20:21,954 --> 00:20:25,591
or super sized
learning trials with the world

326
00:20:25,924 --> 00:20:28,560
as its only teacher.

327
00:20:28,560 --> 00:20:33,799
It's a production system
because it uses hypothesis testing

328
00:20:34,199 --> 00:20:39,404
to discover and learn rules
by a top down matching process

329
00:20:39,404 --> 00:20:44,276
that focuses attention
on critical feature patterns.

330
00:20:44,309 --> 00:20:47,980
These are the patterns
that predict behavioral success

331
00:20:48,347 --> 00:20:53,352
while suppressing irrelevant features,
or it's

332
00:20:53,352 --> 00:20:57,122
explainable using both its activities
or short term memory.

333
00:20:57,122 --> 00:21:00,292
As STM traces and its adaptive

334
00:21:00,292 --> 00:21:03,362
way to a long term memory, LTM traces,

335
00:21:04,096 --> 00:21:07,399
activation dynamics, learning dynamics,

336
00:21:08,233 --> 00:21:11,903
observing the STM traces
in a critical feature pattern.

337
00:21:12,304 --> 00:21:16,842
Explain in what recognition
categories will learn to code

338
00:21:17,276 --> 00:21:20,912
and what features
predict goal oriented actions

339
00:21:21,513 --> 00:21:26,218
and particularly the long term memory
traces in the fuzzy art map algorithm

340
00:21:26,618 --> 00:21:32,190
translate into explicit fuzzy
if then rules that code.

341
00:21:32,190 --> 00:21:37,262
What combat actions of critical features
in what numerical ranges

342
00:21:37,562 --> 00:21:42,501
effectively control predictions
thereby illustrating one of many examples

343
00:21:42,501 --> 00:21:45,871
where neural networks can learn
rule based

344
00:21:45,871 --> 00:21:48,740
behaviors.

345
00:21:49,174 --> 00:21:53,545
Art includes a bottom up adaptive filter,
a feedforward neural network,

346
00:21:53,545 --> 00:21:58,417
as I've observed already,
but that's supplemented by top down

347
00:21:58,417 --> 00:22:02,287
learned expectations
and two types of recurrent

348
00:22:02,287 --> 00:22:06,758
inhibitory feedback interactions
that help to choose the recognition

349
00:22:06,758 --> 00:22:09,428
categories and the critical features.

350
00:22:10,195 --> 00:22:13,832
Notably, top down expectations
use what Joe Carpenter

351
00:22:13,832 --> 00:22:19,104
and I call the art matching rule to learn
how to focus attention

352
00:22:19,471 --> 00:22:23,809
on critical features
that control predictive success.

353
00:22:24,643 --> 00:22:27,346
The art matching rule is another way
of talking

354
00:22:27,846 --> 00:22:31,950
computationally
about the process of object attention

355
00:22:32,484 --> 00:22:38,156
how we pay attention
to salient objects in the world,

356
00:22:38,156 --> 00:22:42,461
and we show how it stabilizes learning
and thereby avoids catastrophic

357
00:22:42,461 --> 00:22:43,061
forgetting.

358
00:22:44,429 --> 00:22:46,331
Remarkably, and this has been

359
00:22:46,331 --> 00:22:52,704
supported by many data,
the art matching role can be realized

360
00:22:52,704 --> 00:22:58,510
by a top down
modulatory on center or surround network.

361
00:22:58,510 --> 00:23:00,645
Where? What does this mean?

362
00:23:00,645 --> 00:23:04,549
Well, let's say we have bottom up
inputs from external features

363
00:23:04,916 --> 00:23:09,654
to feature selective cells
that get stored in short term memory.

364
00:23:10,188 --> 00:23:13,258
Let's say
we activate a recognition category

365
00:23:13,458 --> 00:23:16,895
which has previously been learned
and tries to read out

366
00:23:17,295 --> 00:23:20,565
its learned excitatory prototype.

367
00:23:21,266 --> 00:23:24,836
But it can't fully do so
because it also reads out

368
00:23:25,170 --> 00:23:28,907
an inhibitory of surround
that's broader than the prototype.

369
00:23:29,574 --> 00:23:33,678
So this is approximately one excitatory
against once inhibitory.

370
00:23:34,112 --> 00:23:39,084
It can only give you
one modulatory on center.

371
00:23:39,084 --> 00:23:43,121
But if you have both bottom up inputs
and the top down

372
00:23:43,121 --> 00:23:45,957
expectation simultaneously active,

373
00:23:47,292 --> 00:23:49,928
then within the bounds of the prototype.

374
00:23:49,928 --> 00:23:54,332
If you also have a bottom up feature,
you have two excitatory

375
00:23:54,766 --> 00:23:59,671
against one inhibitory
and those features can be

376
00:23:59,771 --> 00:24:03,041
selected,
gained, amplified and synchronized.

377
00:24:03,442 --> 00:24:07,946
To start focusing attention
on this critical feature pattern.

378
00:24:08,313 --> 00:24:12,484
Well, outlier features
the ones that aren't within the prototype

379
00:24:12,884 --> 00:24:17,856
only have one excitation
against one inhibition or suppressed.

380
00:24:19,224 --> 00:24:19,591
And in

381
00:24:19,591 --> 00:24:22,894
1999, I was able to begin to understand

382
00:24:22,894 --> 00:24:26,498
how lamina cortical circuits
carry out object attention.

383
00:24:27,032 --> 00:24:30,969
In particular, layer
six of a higher cortical area

384
00:24:31,436 --> 00:24:34,506
can activate layer
six of a lower cortical area,

385
00:24:35,040 --> 00:24:38,143
either directly or via a five,

386
00:24:38,143 --> 00:24:42,314
and then it can fold up the layer

387
00:24:42,314 --> 00:24:46,718
for to modulate in, on center

388
00:24:47,219 --> 00:24:49,921
and to inhibit and of surround.

389
00:24:50,455 --> 00:24:53,225
So attention x by a top down

390
00:24:53,592 --> 00:24:57,229
modulatory on center of surround network

391
00:24:57,496 --> 00:25:02,200
by a folded feedback
within lamina neocortex.

392
00:25:02,834 --> 00:25:07,839
And this is one example of the paradigm
of lamina computing that I introduced,

393
00:25:08,406 --> 00:25:12,544
which ask Why are all neocortical
circuits organized in layers?

394
00:25:13,011 --> 00:25:16,781
And how do laminar circuits
give rise to all kinds

395
00:25:16,781 --> 00:25:19,317
of biological intelligence?

396
00:25:20,952 --> 00:25:22,420
Adaptive resonance sets

397
00:25:22,420 --> 00:25:25,891
is the story
because attended feature clusters

398
00:25:26,358 --> 00:25:29,094
react elevate their bottom up pathways,

399
00:25:29,761 --> 00:25:33,365
activated categories
reactivate their top down

400
00:25:33,365 --> 00:25:37,903
pathways closing in excitatory
feedback loop

401
00:25:38,370 --> 00:25:41,206
between features and categories,

402
00:25:41,206 --> 00:25:46,077
giving rise to a feature category
resonance

403
00:25:46,478 --> 00:25:51,483
that synchronizes, amplifies
and prolongs system response

404
00:25:51,783 --> 00:25:54,653
between the attended critical features

405
00:25:54,653 --> 00:25:58,623
and the category to which they are bound.

406
00:25:59,424 --> 00:26:02,360
And it's this resonance
that triggers fast learning

407
00:26:02,694 --> 00:26:05,063
in the bottom up and top down.

408
00:26:05,397 --> 00:26:08,733
Adaptive waits,
which is why I have called

409
00:26:08,733 --> 00:26:12,270
this theory adaptive resonance theory.

410
00:26:13,238 --> 00:26:14,506
Moreover,

411
00:26:14,506 --> 00:26:17,943
I've done a lot of work
since then, showing that all

412
00:26:17,943 --> 00:26:22,480
conscious states or resonant states
and these feature category

413
00:26:22,480 --> 00:26:26,952
resonances are one example of that,
one that supports conscious

414
00:26:27,385 --> 00:26:31,356
recognition of visual objects and scenes.

415
00:26:32,791 --> 00:26:35,493
There's a lot of data support
for our predictions.

416
00:26:35,493 --> 00:26:39,798
It's well known that attention
does happen on center of surround

417
00:26:40,365 --> 00:26:43,602
a circuit behind it, and that attention

418
00:26:43,602 --> 00:26:47,105
can facilitate matched bottom up signals.

419
00:26:47,439 --> 00:26:50,041
Many other data as well.

420
00:26:51,543 --> 00:26:53,044
So now we can say more about

421
00:26:53,044 --> 00:26:57,782
why art is explainable or trustworthy
in short term memory.

422
00:26:57,782 --> 00:27:00,785
It's because the critical feature
patterns

423
00:27:00,785 --> 00:27:05,824
determine the attentional focus
that controls information processing.

424
00:27:05,824 --> 00:27:10,795
And you can just read off what
those features are in long term memory.

425
00:27:10,795 --> 00:27:15,400
Again, it's the critical feature patterns
that determine the adaptive way

426
00:27:15,400 --> 00:27:20,338
to learn by the bottom up adaptive filter
and the top down learned expectation.

427
00:27:20,672 --> 00:27:23,942
So, you know
also what these weights are encoding

428
00:27:25,243 --> 00:27:26,511
less reliable and

429
00:27:26,511 --> 00:27:30,482
avoids catastrophic
forgetting because outlier features

430
00:27:30,915 --> 00:27:34,185
that are not in the critical feature
pattern is suppressed

431
00:27:34,653 --> 00:27:39,024
so that only the predictive features
are processed and coded.

432
00:27:40,492 --> 00:27:42,127
Well, it's a production system

433
00:27:42,127 --> 00:27:45,330
because it carries out
a kind of hypothesis testing.

434
00:27:45,764 --> 00:27:50,935
And this is nicely illustrated
in the simplest art model called

435
00:27:50,935 --> 00:27:55,774
or one that Gale Comparator
and I published in 1987

436
00:27:56,608 --> 00:27:59,044
or at one has an attentional system

437
00:28:00,345 --> 00:28:03,915
that does all the category learning
and the expectation learning

438
00:28:03,915 --> 00:28:08,186
and the paying attention
that interacts with an orienting system

439
00:28:08,186 --> 00:28:11,322
which is activated
when there are big enough matches

440
00:28:11,322 --> 00:28:17,662
in the attentional system and thereby
drives a reset and search for novel.

441
00:28:17,662 --> 00:28:19,798
Look at a match in categories.

442
00:28:20,432 --> 00:28:25,870
Here's a schematic of the yard
hypothesis testing and learning cycle.

443
00:28:26,905 --> 00:28:27,806
So let's say you

444
00:28:27,806 --> 00:28:30,575
have a bottom up
feature pattern coming in.

445
00:28:30,975 --> 00:28:34,279
There may be many,
many active bottom of features,

446
00:28:34,279 --> 00:28:38,116
but I'll draw
just one arrow here for simplicity.

447
00:28:38,616 --> 00:28:41,386
But that vector of input features
can activate

448
00:28:41,386 --> 00:28:45,290
a distributed pattern of feature detector
cells.

449
00:28:45,557 --> 00:28:50,829
Some may be very active, some
not so active, some not active at all.

450
00:28:51,329 --> 00:28:55,533
And as this is happening,
each of these active

451
00:28:55,533 --> 00:28:59,938
pathways is trying
to turn on the orienting system.

452
00:28:59,938 --> 00:29:04,676
So there might be quite a few inputs
converging here, but as the features

453
00:29:04,676 --> 00:29:08,880
are activated, each of them tries
to inhibit the orienting system

454
00:29:09,180 --> 00:29:12,083
and there is many features
as there are inputs.

455
00:29:12,450 --> 00:29:15,386
So this excitation
and addition of balance,

456
00:29:15,754 --> 00:29:20,725
keeping the orienting system quiet
as the feature padding goes,

457
00:29:20,759 --> 00:29:24,496
the adaptive filter
and chooses a category.

458
00:29:25,296 --> 00:29:28,600
That category reads out of learned
top down expectation

459
00:29:28,600 --> 00:29:33,438
that obeys the art matching rule,
which can suppress a mismatch features,

460
00:29:33,838 --> 00:29:37,609
thereby reducing the amount of inhibition
on the orienting system

461
00:29:38,009 --> 00:29:40,178
and raising the question

462
00:29:40,178 --> 00:29:44,883
when you have too little inhibition
and too much excitation.

463
00:29:45,250 --> 00:29:48,720
How big a mismatch
will activate the orienting system

464
00:29:49,053 --> 00:29:51,756
and cause reset and that

465
00:29:54,125 --> 00:29:56,194
ratio is determined

466
00:29:56,194 --> 00:29:59,998
by what's called vigilance,
which I'll say more about soon.

467
00:30:01,533 --> 00:30:03,601
But if you don't have enough inhibition,

468
00:30:03,601 --> 00:30:06,237
then the orienting system gets activated.

469
00:30:06,838 --> 00:30:09,340
It equally activates

470
00:30:09,674 --> 00:30:12,410
all the cells in the category layer

471
00:30:12,443 --> 00:30:15,780
because it doesn't know
which cell may be active or not.

472
00:30:16,080 --> 00:30:18,683
So it causes and novelty

473
00:30:19,784 --> 00:30:22,620
sensitive, nonspecific bursts

474
00:30:22,620 --> 00:30:25,657
of arousal, novel events or browsing,

475
00:30:26,191 --> 00:30:29,794
thereby selectively
shutting off the active category,

476
00:30:30,295 --> 00:30:33,031
eliminating its top down expectation,

477
00:30:33,498 --> 00:30:36,067
and unmasking the original feature added,

478
00:30:36,367 --> 00:30:39,070
which can again
go through the adaptive filter.

479
00:30:39,604 --> 00:30:41,739
However, now this

480
00:30:42,140 --> 00:30:45,543
previously this confirmed category
remains off

481
00:30:46,077 --> 00:30:51,516
and the category level is we normalize
sort response to the same input bad

482
00:30:51,516 --> 00:30:56,521
and with the new category
and you go through this cycle

483
00:30:56,921 --> 00:31:01,326
of resonance and reset
until you get a good enough match

484
00:31:01,893 --> 00:31:06,931
to either learn a new category
or select a previously learned category.

485
00:31:08,166 --> 00:31:11,302
And it's a theorem that as categories
are learned through

486
00:31:11,302 --> 00:31:14,973
this matching process, search
automatically

487
00:31:15,406 --> 00:31:18,276
disengages

488
00:31:18,710 --> 00:31:21,379
leading to direct access without search

489
00:31:21,846 --> 00:31:24,482
to the globally best matching category.

490
00:31:25,817 --> 00:31:27,752
Explaining, for example, how

491
00:31:27,752 --> 00:31:32,223
we can quickly recognize familiar objects
like your mother's face.

492
00:31:32,223 --> 00:31:37,729
Even if, as we get older, we store
enormous numbers of additional memories

493
00:31:38,196 --> 00:31:41,065
so you don't have to search
your whole repertoire.

494
00:31:41,065 --> 00:31:45,403
When you see Mom, you get direct
access and quickly say, Hi, Mom.

495
00:31:46,671 --> 00:31:50,441
There's a lot of support
for the hypothesis testing cycle.

496
00:31:50,842 --> 00:31:54,279
One source of support is from event
related potentials,

497
00:31:54,812 --> 00:31:57,248
also called human scalp potentials,

498
00:31:57,615 --> 00:32:01,219
which shows correlated sequences
of three different

499
00:32:01,519 --> 00:32:04,756
evoked potentials
during oddball learning tasks.

500
00:32:05,290 --> 00:32:10,328
An experiment that John Paul Bank
and I reported in the eighties

501
00:32:10,795 --> 00:32:13,798
where you'll get a p120 for a mismatch

502
00:32:14,165 --> 00:32:19,337
and then 200 for the arousal activated
by the ordering system

503
00:32:19,737 --> 00:32:25,076
and a p300 for the short term memory
reset of the category layer, thereby

504
00:32:25,276 --> 00:32:29,914
supporting the processing
stages of the search cycle.

505
00:32:31,182 --> 00:32:33,952
There was also physiological data

506
00:32:34,285 --> 00:32:39,057
from a temporal cortex
where categories are learned early on

507
00:32:39,457 --> 00:32:44,696
from the lab of Bob Desdemona,
who showed an active matching process

508
00:32:44,996 --> 00:32:48,132
that's reset between trials during

509
00:32:48,132 --> 00:32:50,435
this kind of event.

510
00:32:52,170 --> 00:32:56,140
There's also classical data
about hippocampal mismatch dynamics.

511
00:32:56,474 --> 00:32:59,377
It's known that novelty potentials
subside

512
00:32:59,377 --> 00:33:02,513
as learning proceeds
from numerous experiments.

513
00:33:02,547 --> 00:33:05,850
This is as the orienting
system is disengaged,

514
00:33:06,517 --> 00:33:09,554
and there's more recent data
using multiple

515
00:33:09,620 --> 00:33:12,824
electrode studies
from the lab of Cheryl Miller,

516
00:33:13,324 --> 00:33:19,364
from pre-frontal cortex and simultaneous
recordings in active campus.

517
00:33:19,364 --> 00:33:22,867
And they show this rapid object
associative learning

518
00:33:23,334 --> 00:33:26,604
may occur in prefrontal cortex,
which is a projection

519
00:33:26,971 --> 00:33:31,376
of inferred temporal cortex,
one of the stages of category learning.

520
00:33:31,743 --> 00:33:36,447
While the hippocampus may guide
neocortical plasticity four

521
00:33:36,881 --> 00:33:39,984
by signaling success or failure.

522
00:33:40,418 --> 00:33:44,088
Well, this is just what happens
when the attentional system interacts

523
00:33:44,489 --> 00:33:48,059
with the orienting system.

524
00:33:48,493 --> 00:33:51,429
There's also complimentary
computing in art.

525
00:33:51,863 --> 00:33:56,234
In particular, the attentional
and orienting system was a complementary

526
00:33:56,567 --> 00:34:00,405
as manifested
by the fact that two event related

527
00:34:00,405 --> 00:34:04,242
potentials are complementary
processing negativity

528
00:34:04,242 --> 00:34:09,447
and n200 processing
negativity is activated

529
00:34:09,447 --> 00:34:13,151
when there's a top down
match in the attentional system.

530
00:34:13,751 --> 00:34:17,555
The N200, as I just noted, is activated

531
00:34:17,555 --> 00:34:21,692
when there's a mismatch
that activates the orienting system.

532
00:34:22,026 --> 00:34:28,499
And you can just look across
these four rows and see that these two

533
00:34:29,367 --> 00:34:34,238
kinds of ERP
potentials are manifestly complementary.

534
00:34:34,238 --> 00:34:37,141
As illustrated, the complementarity

535
00:34:37,442 --> 00:34:40,111
of the attention and orienting systems.

536
00:34:40,978 --> 00:34:44,615
So this leads us to discuss
another paradigm introduced,

537
00:34:45,049 --> 00:34:48,453
which I call complementary computing,
that has

538
00:34:48,486 --> 00:34:52,390
what is the nature
of brain specializations?

539
00:34:53,958 --> 00:34:57,562
Complementary computing introduces
new principles

540
00:34:57,595 --> 00:35:02,467
of uncertainty and complementarity
that clarify why there are multiple

541
00:35:02,867 --> 00:35:08,606
parallel processing streams with multiple
processing stages in our brains.

542
00:35:09,040 --> 00:35:12,710
And a beautiful example of that
is this famous image

543
00:35:13,177 --> 00:35:16,747
of the macro circuit of the visual system
from David Ranson

544
00:35:16,747 --> 00:35:19,984
and his colleagues,
where you can see these multiple

545
00:35:21,486 --> 00:35:23,354
parallel processing streams

546
00:35:23,354 --> 00:35:27,792
and the multiple stages
needed to achieve,

547
00:35:27,792 --> 00:35:31,662
I call hierarchical resolution
of uncertainty.

548
00:35:32,730 --> 00:35:37,335
So what our complement complementary
properties, their analogies

549
00:35:37,802 --> 00:35:41,672
like a key fits into a lock
for puzzle pieces

550
00:35:42,039 --> 00:35:44,876
fitting together in words

551
00:35:44,876 --> 00:35:48,946
computing one set of properties
that a stage prevents

552
00:35:48,946 --> 00:35:53,284
that stage from computing
a complementary set of properties.

553
00:35:53,784 --> 00:35:58,289
These complementary parallel processing
streams a balance against one another.

554
00:35:58,623 --> 00:36:01,893
It's a very yin yang kind of situation,

555
00:36:02,426 --> 00:36:08,432
and interactions between the streams
overcome their complementary weaknesses.

556
00:36:09,934 --> 00:36:11,135
In fact, there are many

557
00:36:11,135 --> 00:36:14,906
complementary processes that are known
in the brain that have been modeled.

558
00:36:15,339 --> 00:36:17,942
Here is just a of them.

559
00:36:17,942 --> 00:36:19,644
There are many more.

560
00:36:19,644 --> 00:36:22,480
So this is a basic principle

561
00:36:22,480 --> 00:36:25,950
of brain organization.

562
00:36:26,250 --> 00:36:29,220
So in summary,
so far back propagation and deep learning

563
00:36:29,220 --> 00:36:32,957
do not have thought to memory activation
patterns,

564
00:36:32,957 --> 00:36:37,261
including critical feature patterns,
so they can't pay attention.

565
00:36:37,562 --> 00:36:41,799
Indeed, they don't have any fast
information processing,

566
00:36:42,233 --> 00:36:44,835
nor do they have long term memory
at the moment.

567
00:36:44,835 --> 00:36:49,807
Expectation
So they can carry out hypothesis testing

568
00:36:50,208 --> 00:36:54,045
using interaction
short term and long term memory traces.

569
00:36:54,512 --> 00:36:56,514
Indeed, there's no neural architecture.

570
00:36:56,514 --> 00:37:01,385
There's just an algorithm
in this really great contrast with

571
00:37:01,652 --> 00:37:04,488
complementary computing, which discusses

572
00:37:04,488 --> 00:37:06,891
the global organization of brains.

573
00:37:07,892 --> 00:37:11,829
From the very start, it was shown
how easy it is to get catastrophic

574
00:37:11,829 --> 00:37:12,363
forgetting.

575
00:37:12,363 --> 00:37:15,833
And Carpenter and I showed it in art

576
00:37:16,200 --> 00:37:19,637
when we would shut down
the matching rule.

577
00:37:20,004 --> 00:37:23,874
Then we demonstrated
you could get catastrophic forgetting

578
00:37:23,874 --> 00:37:28,279
if you had just
four input vectors A, B, C, D

579
00:37:29,380 --> 00:37:30,448
presented in the

580
00:37:30,448 --> 00:37:33,951
order ABCD, ABCD, and so on.

581
00:37:34,385 --> 00:37:37,989
If they obeyed very simple subset

582
00:37:37,989 --> 00:37:42,360
relationships
and here's a computer simulation of that.

583
00:37:42,827 --> 00:37:47,498
Here you don't have the matching
rule is a, b, c,

584
00:37:47,732 --> 00:37:52,770
d, a, b, c, a, D and you see A

585
00:37:53,204 --> 00:37:58,609
is coded by category one here by category
two here by category one.

586
00:37:58,609 --> 00:38:00,911
Year two we are never settled down.

587
00:38:01,412 --> 00:38:05,016
But as soon as you impose
the matching rule,

588
00:38:06,183 --> 00:38:10,388
learning is complete by the second trial
and after that point

589
00:38:10,388 --> 00:38:15,226
you get direct access
to the globally best matching category.

590
00:38:16,260 --> 00:38:18,896
Well, let's say a little more
about vigilance.

591
00:38:19,897 --> 00:38:24,168
Vigilance determines what features are
learned in the critical feature pattern.

592
00:38:24,602 --> 00:38:28,005
It clarifies our brains, learn concrete
knowledge

593
00:38:28,005 --> 00:38:31,575
for some tasks
and abstract knowledge for others.

594
00:38:32,043 --> 00:38:35,613
So in particular, high vigilance leads
to learning of narrow,

595
00:38:35,913 --> 00:38:38,349
concrete categories, like a category

596
00:38:38,716 --> 00:38:42,520
that fires selectively
to a frontal view of your mother's face.

597
00:38:43,921 --> 00:38:46,290
Low vigilance leads to learning of broad

598
00:38:46,290 --> 00:38:49,994
and abstract categories,
like everyone has its face.

599
00:38:50,594 --> 00:38:54,565
It should be emphasized that
critical feature patterns are explainable

600
00:38:54,899 --> 00:38:57,902
at every level of vigilance.

601
00:38:58,569 --> 00:39:00,438
It's known

602
00:39:01,639 --> 00:39:04,608
from physiological experiments
by does moment again

603
00:39:05,343 --> 00:39:07,411
that there's vigilance

604
00:39:08,245 --> 00:39:12,917
control in the infra temple cortex,
which they showed by studying

605
00:39:12,950 --> 00:39:16,887
easy versus
difficult discriminations in monkeys

606
00:39:17,321 --> 00:39:21,158
and the difficult condition which you'd
assume would give you their children's.

607
00:39:21,158 --> 00:39:24,929
As expected,
you had enhancement of the responses

608
00:39:25,262 --> 00:39:30,901
and sharpen selectivity to the intended
stimulate.

609
00:39:30,901 --> 00:39:33,170
How is vigilance computed?

610
00:39:33,471 --> 00:39:37,174
Well, let's say of input vector
it in states

611
00:39:38,142 --> 00:39:41,679
of vector of activities,
feature detectors

612
00:39:42,046 --> 00:39:45,483
at the same time as it tries
to activate the warning system.

613
00:39:45,783 --> 00:39:49,987
But it
this does so multiplied by a parameter

614
00:39:50,388 --> 00:39:54,658
rho, which is a sensitivity
against gravity that vigilance.

615
00:39:55,259 --> 00:39:59,163
And as these features get in state,
they try to shut off

616
00:39:59,530 --> 00:40:01,565
the orienting system.

617
00:40:01,565 --> 00:40:05,169
And if the excitation is less

618
00:40:05,436 --> 00:40:08,773
than the inhibition,
the orienting system stays quiet.

619
00:40:09,106 --> 00:40:11,342
So the system can resonate and learn.

620
00:40:12,676 --> 00:40:13,310
But if

621
00:40:13,310 --> 00:40:17,114
inhibition isn't strong enough,
the orienting system gets activated.

622
00:40:17,481 --> 00:40:20,251
You get reset
and search for new categories.

623
00:40:20,251 --> 00:40:26,257
This is a very simple computation
because you have an orienting system

624
00:40:26,524 --> 00:40:29,960
that's complementary
to the attentional system.

625
00:40:30,895 --> 00:40:34,331
Well, how do you change
vigilance based on predictive success?

626
00:40:34,932 --> 00:40:40,037
For this, we have to go from unsupervised
to supervised start models.

627
00:40:40,037 --> 00:40:41,672
So we'll have

628
00:40:42,273 --> 00:40:46,911
an unsupervised art,
a model in unsupervised, or B model

629
00:40:47,344 --> 00:40:52,383
linked together by a learned associate
of map as occurs in the art map.

630
00:40:52,683 --> 00:40:55,986
And the key point is
you can have an input here

631
00:40:56,420 --> 00:41:00,758
that can create an output there
because you have both bottom up

632
00:41:00,758 --> 00:41:04,395
and top down in actions
at all of these levels.

633
00:41:05,429 --> 00:41:07,598
So in this way, you can learn

634
00:41:07,598 --> 00:41:11,469
many to one and one too many maps.

635
00:41:12,203 --> 00:41:17,341
One example of a many to one map
is let's say you're trying to categorize

636
00:41:17,341 --> 00:41:22,646
visually processed a letter
A, which comes in multiple fonts.

637
00:41:23,113 --> 00:41:26,250
You'll learn various visual categories.

638
00:41:26,250 --> 00:41:29,053
Are they based on visual similarity?

639
00:41:30,421 --> 00:41:31,622
At the same time, you're

640
00:41:31,622 --> 00:41:35,125
learning auditory categories for saying A

641
00:41:35,426 --> 00:41:40,331
and then the associated napkin map
all of these visual categories

642
00:41:40,331 --> 00:41:43,000
of different age to saying, Hey,

643
00:41:44,134 --> 00:41:47,137
but it could have been here
that these inputs were symptoms,

644
00:41:47,137 --> 00:41:50,841
test treatments in a medical database
prediction

645
00:41:51,675 --> 00:41:55,312
example and you're predicting
length of stay in the hospital.

646
00:41:55,746 --> 00:41:57,781
The possibilities here are endless.

647
00:41:57,781 --> 00:42:01,252
And then in many applications

648
00:42:01,252 --> 00:42:03,454
or let's say

649
00:42:06,724 --> 00:42:07,191
you're trying

650
00:42:07,191 --> 00:42:12,129
to figure out what this images
and you've learned to say that's a dog.

651
00:42:12,429 --> 00:42:17,034
But today you say it's rover
and that causes a major mismatch,

652
00:42:17,034 --> 00:42:21,839
which drives the search to focus
attention on the particular combination

653
00:42:21,839 --> 00:42:26,243
of features in this talk
that will identify it as Rover.

654
00:42:26,610 --> 00:42:30,047
That leads to learning
of a visual category of Rover

655
00:42:30,848 --> 00:42:36,086
in auditory categories of the name, rover
and associated map between them.

656
00:42:36,420 --> 00:42:39,156
And you can now simultaneously store

657
00:42:39,456 --> 00:42:42,660
expert knowledge about that image.

658
00:42:43,627 --> 00:42:44,161
Well, how do

659
00:42:44,161 --> 00:42:48,632
you conjointly minimize predictive error
and maximize generalization

660
00:42:48,966 --> 00:42:54,438
so that you minimize using memory
resources?

661
00:42:54,438 --> 00:42:58,542
Let me read you an answer
and then show what it means in images.

662
00:42:59,910 --> 00:43:04,048
Match tracking realizes in kinematics
a learning principle,

663
00:43:04,448 --> 00:43:08,419
namely, given a predictive error,
vigilance increases

664
00:43:08,419 --> 00:43:12,856
just enough to trigger search
and the sacrifices,

665
00:43:12,856 --> 00:43:15,392
the minimum generalization
to correct the error.

666
00:43:15,759 --> 00:43:20,798
So let's say you've made a prediction
that must mean that vigilance is less

667
00:43:21,231 --> 00:43:24,568
than the analog
between bottom up and top down.

668
00:43:25,069 --> 00:43:28,639
But let's say now you have a mismatch.

669
00:43:28,639 --> 00:43:33,210
Well, that'll lead to a match
tracking signal that vigilance up

670
00:43:33,210 --> 00:43:38,582
till it's just above the analog match,
just big enough to drive the search.

671
00:43:38,983 --> 00:43:44,421
So you've given up the minimum amount of
general deception to correct the error?

672
00:43:45,723 --> 00:43:46,256
Well, all

673
00:43:46,256 --> 00:43:49,860
lot mechanisms like vigilance, control
realized in lamina

674
00:43:50,327 --> 00:43:53,631
cortical insular mixture
because the answer is yes.

675
00:43:54,365 --> 00:43:55,299
My Ph.D.

676
00:43:55,299 --> 00:43:58,569
student Extra Saatchi
and I showed this by developing

677
00:43:58,569 --> 00:44:01,205
the synchronous matching order,
a smart model

678
00:44:02,406 --> 00:44:05,576
which introduce
a lot more neurophysiological

679
00:44:05,576 --> 00:44:10,381
and anatomical verisimilitude
into the model, including spiking

680
00:44:10,381 --> 00:44:14,051
dynamics, lamina cortical circuits,
interacting

681
00:44:14,385 --> 00:44:18,756
with specific and nonspecific
galactic nuclei.

682
00:44:19,289 --> 00:44:22,559
This is another example
of what I'm going to computing,

683
00:44:23,027 --> 00:44:25,295
and here's a schematic of the model.

684
00:44:25,629 --> 00:44:29,800
You see all the cortical layers
with identified cells,

685
00:44:30,167 --> 00:44:35,839
a hierarchy of cortical regions
interacting with specific thalamic nuclei

686
00:44:36,173 --> 00:44:42,346
in nonspecific thalamic nuclei,
a ton anatomical data

687
00:44:42,346 --> 00:44:46,550
got functionally explained in this way
and many other data as well.

688
00:44:46,550 --> 00:44:47,217
For example,

689
00:44:47,217 --> 00:44:51,955
we showed if you have a good enough
match between bottom up and top down,

690
00:44:52,322 --> 00:44:56,393
you're going to get fast
gamma oscillations during a tension.

691
00:44:56,660 --> 00:45:00,964
There was quite a bit of data
about that already, but we also showed

692
00:45:00,964 --> 00:45:05,402
if you have big enough mismatch,
you'll get slower data oscillations.

693
00:45:05,703 --> 00:45:07,471
That wasn't well known,

694
00:45:08,505 --> 00:45:11,475
but since that time
there have been experiment in at least

695
00:45:11,842 --> 00:45:14,845
four labs
in three different parts of the brain

696
00:45:14,878 --> 00:45:17,181
confirming that prediction.

697
00:45:18,215 --> 00:45:20,818
Most important,
vigilance control was shown

698
00:45:21,251 --> 00:45:24,455
how to be a control by mismatch mediate

699
00:45:24,922 --> 00:45:28,192
the colon release so big enough mismatch

700
00:45:28,592 --> 00:45:33,330
in the nonspecific thalamic nucleus
activates nucleus based cells.

701
00:45:33,330 --> 00:45:36,600
The miner that releases

702
00:45:36,600 --> 00:45:41,338
acetylcholine in lay off
high shields across the cortex, reducing

703
00:45:41,338 --> 00:45:46,210
after hyper polarization currents
and causing vigilance to go up.

704
00:45:46,844 --> 00:45:51,348
And I also showed that breakdown
in acetylcholine modulation

705
00:45:51,749 --> 00:45:56,787
can help to explain
the symptoms of multiple mental disorders

706
00:45:58,255 --> 00:46:00,624
so as to memory consolidation.

707
00:46:00,624 --> 00:46:05,095
We know there's a dynamic phase of memory
consolidation, while

708
00:46:05,095 --> 00:46:11,101
the input exemplar still drives memory
search and before direct access occurs.

709
00:46:11,101 --> 00:46:13,637
But what if the orienting
systems cut out?

710
00:46:14,004 --> 00:46:16,607
What if you have a lesion
in the hippocampus?

711
00:46:17,474 --> 00:46:20,511
Well, then, as occurs in medial temporal

712
00:46:20,511 --> 00:46:24,481
amnesia,
you get unlimited anterograde amnesia

713
00:46:24,481 --> 00:46:26,750
because you can search
for new categories.

714
00:46:27,284 --> 00:46:29,853
You get limited retrograde amnesia

715
00:46:30,220 --> 00:46:34,958
because you could have direct access
to previously learned categories.

716
00:46:35,392 --> 00:46:40,164
This is a failure of consolidation,
which is mediated by the ordinances.

717
00:46:40,164 --> 00:46:45,736
So you get defective novelty reactions
because that is also mediated

718
00:46:45,736 --> 00:46:49,807
by the orienting system
and memory consolidation, novelty

719
00:46:49,807 --> 00:46:54,745
detection mediated by the same structures
for the same reason.

720
00:46:55,512 --> 00:46:57,881
It's normal priming because

721
00:46:57,881 --> 00:47:00,784
priming occurs
within the attentional system.

722
00:47:01,418 --> 00:47:03,720
Learning of the first item dominates.

723
00:47:03,720 --> 00:47:06,990
You can get some learning,
but you can't then search.

724
00:47:08,025 --> 00:47:11,161
And there's an impaired ability
to attend to relevant

725
00:47:11,161 --> 00:47:15,732
dimensions of stimuli again
because you can't search.

726
00:47:16,600 --> 00:47:18,735
So now where does intra temple

727
00:47:18,735 --> 00:47:21,572
cortex fit in the larger brain?

728
00:47:22,472 --> 00:47:25,609
I introduced the predictive

729
00:47:25,709 --> 00:47:28,111
or taught algorithm

730
00:47:29,012 --> 00:47:33,150
model in order
to show how the prefrontal cortex,

731
00:47:33,150 --> 00:47:38,222
among other things, learns to control
all higher order intelligence.

732
00:47:38,222 --> 00:47:42,092
You can find that in a 2018 paper
on my web

733
00:47:42,092 --> 00:47:45,195
page,
results were published in Open Access

734
00:47:46,396 --> 00:47:51,134
and in this macro circuit,
these green areas

735
00:47:51,134 --> 00:47:54,271
of prefrontal cortex control processes

736
00:47:54,271 --> 00:47:57,541
like working memory, learning plans,

737
00:47:58,308 --> 00:48:00,744
prediction and optimized action.

738
00:48:01,712 --> 00:48:05,949
These regions in red control processes
like reinforcement

739
00:48:05,949 --> 00:48:10,687
learning, motion
motivation, adaptively timed learning.

740
00:48:11,255 --> 00:48:16,360
The category learning I've talked about
in I.T is just in those two regions.

741
00:48:16,760 --> 00:48:20,230
All these processes

742
00:48:20,430 --> 00:48:23,700
control visual perception
and there are detailed

743
00:48:23,700 --> 00:48:27,571
models of all of these regions
and their interactions.

744
00:48:27,571 --> 00:48:32,409
Now in each brain region, in nature
and in predictive art carries out

745
00:48:32,409 --> 00:48:37,047
a different function,
contrasting really dramatically

746
00:48:37,381 --> 00:48:42,686
with the whole mad genius organization
of the typical deep learning network.

747
00:48:44,121 --> 00:48:46,423
So I told you just a little bit

748
00:48:46,423 --> 00:48:50,160
about some aspects of cognition
and why they're explainable,

749
00:48:50,761 --> 00:48:54,598
but if you put in
all the biological models of perceptual

750
00:48:54,598 --> 00:48:58,568
cognition, emotion and action,
they're all explainable.

751
00:48:58,969 --> 00:49:01,939
And then you can observe

752
00:49:01,939 --> 00:49:04,441
how perceptual and cognitive processes

753
00:49:04,741 --> 00:49:08,912
work, like excitatory
matching, match based learning

754
00:49:09,446 --> 00:49:11,682
to create self stabilizing,

755
00:49:11,882 --> 00:49:16,320
attentive and conscious
representations of objects and events

756
00:49:16,720 --> 00:49:20,657
that embody increasing expertize
about the world.

757
00:49:21,458 --> 00:49:25,162
Moreover, complementary spatial
and motor processes that I couldn't

758
00:49:25,162 --> 00:49:30,000
mention at all use inhibitor
free matching and mismatch based learning

759
00:49:30,434 --> 00:49:34,604
to continually update spatial
and motor representations

760
00:49:34,604 --> 00:49:38,675
to compensate for bodily changes
throughout life.

761
00:49:39,242 --> 00:49:44,314
Taken together, they provide a self
stabilizing, perceptual and cognitive

762
00:49:44,314 --> 00:49:48,785
front end for conscious awareness
and knowledge acquisition,

763
00:49:49,987 --> 00:49:55,325
which can intelligently manipulate
the more labeled spatial and motor

764
00:49:55,325 --> 00:49:58,562
processes that enable changing bodies

765
00:49:58,562 --> 00:50:01,832
to act effectively on a changing world.

766
00:50:02,532 --> 00:50:06,169
And when you put them all together,
they provide a blueprint

767
00:50:06,169 --> 00:50:07,471
for designing autonomy.

768
00:50:07,471 --> 00:50:11,742
This adaptive algorithms
and mobile robots with behaviors

769
00:50:12,142 --> 00:50:15,846
humans can understand and control
because they're both

770
00:50:15,846 --> 00:50:18,582
explainable and reliable.

771
00:50:19,182 --> 00:50:20,817
See my web page,

772
00:50:20,817 --> 00:50:23,987
sites (dot) BU (dot) EDU (slash) SteveG, 

773
00:50:24,254 --> 00:50:25,255
for these

774
00:50:27,324 --> 00:50:28,592
models.

775
00:50:28,592 --> 00:50:32,262
And with that, I'd like to
thank you very much

776
00:50:32,596 --> 00:50:36,333
for your attention.
[End of video]

777
00:50:36,500 --> 00:50:38,935
GROSSBERG (live): Before we get started,
what I want to say so

778
00:50:39,369 --> 00:50:44,441
I should say that everything I talk about
and much more is in my book

779
00:50:44,441 --> 00:50:49,212
Conscious Mind, Resonant Brain
How each Brain Makes and Why.

780
00:50:49,813 --> 00:50:52,349
For those who don't know, it's

781
00:50:52,349 --> 00:50:54,918
self-contained and non-technical.

782
00:50:55,452 --> 00:51:00,323
It's written in a conversational style
so that people will know

783
00:51:00,323 --> 00:51:04,628
nothing about the mind
or the brain and enjoy reading it.

784
00:51:04,628 --> 00:51:09,166
And I have friends who are a rabbi,
a minister,

785
00:51:10,434 --> 00:51:14,037
a painter, a gallery owner, a lawyer,

786
00:51:14,037 --> 00:51:18,742
a social worker
who've all been enjoying reading it all.

787
00:51:18,742 --> 00:51:20,310
So it's a big book.

788
00:51:20,310 --> 00:51:23,547
It's almost 800 double column

789
00:51:23,547 --> 00:51:26,750
pages with over 600 color figures.

790
00:51:26,750 --> 00:51:31,955
So everything is illustrated,
but instead of costing

791
00:51:32,155 --> 00:51:36,126
hundred $50, it costs $35

792
00:51:36,126 --> 00:51:40,097
for the hard copy
and only $17 for the Kindle.

793
00:51:40,097 --> 00:51:43,366
Because I spent a lot of my own money

794
00:51:43,834 --> 00:51:48,638
so that people who are interested
in the book and read it.

795
00:51:48,638 --> 00:51:54,611
And one other comment,
if people do have questions or comments

796
00:51:56,012 --> 00:51:58,582
about my lecture
or anything, they're reading the book.

797
00:51:58,582 --> 00:52:03,920
My email is just Steve STV

798
00:52:05,021 --> 00:52:08,625
The EU Boston University study

799
00:52:08,692 --> 00:52:12,095
the EU and I'll be happy to try to apply,

800
00:52:12,262 --> 00:52:15,132
so thank you.

801
00:52:15,132 --> 00:52:17,801
Help some researchers and explainable

802
00:52:18,001 --> 00:52:21,738
AI people like Leonardo Giovanna
and Antonio de Checco

803
00:52:22,239 --> 00:52:26,610
demand that any explainable
I should at the very least meet

804
00:52:26,610 --> 00:52:31,348
these four criteria to be fair,
not biased in one way or another,

805
00:52:31,648 --> 00:52:36,586
to be accountable or reliable,
to be secure against malicious hacker

806
00:52:36,586 --> 00:52:40,991
attacks and not to be fooled easily
and also to be transparent.

807
00:52:41,391 --> 00:52:45,128
Now you explained
how adaptive resonance theory or art.

808
00:52:45,128 --> 00:52:48,465
And by the way, I got to say,
I love your creative

809
00:52:48,465 --> 00:52:50,700
and clever
use of acronyms for your models.

810
00:52:51,768 --> 00:52:53,770
My favorite one is Sovereign Model,

811
00:52:53,770 --> 00:52:57,607
self-organizing vision, expectation
recognition,

812
00:52:57,607 --> 00:53:01,378
emotion, intelligent, goal
oriented navigation, if I'm correct.

813
00:53:01,711 --> 00:53:02,646
Amazing.

814
00:53:03,046 --> 00:53:06,183
Anyway, you explained how art can address

815
00:53:06,183 --> 00:53:09,953
and overcome
the issues of accountability, security

816
00:53:09,953 --> 00:53:13,924
and trends, currency of current
deep learning approaches.

817
00:53:13,924 --> 00:53:17,194
But it seems that this fairness issue,
a.k.a.

818
00:53:17,194 --> 00:53:22,232
the problem of algorithmic bias,
has also been a growing concern lately,

819
00:53:22,465 --> 00:53:25,669
especially since it's regarded
by some researchers like Antonio

820
00:53:25,669 --> 00:53:28,638
Badia
as a practically intractable problem.

821
00:53:29,005 --> 00:53:33,677
So I wanted to ask, in
what ways do you think art can contribute

822
00:53:33,677 --> 00:53:37,480
to the ongoing quest
for mitigating this problem?

823
00:53:39,516 --> 00:53:41,451
Well, when

824
00:53:41,718 --> 00:53:44,888
a fairly sent me this question,
I said, Well,

825
00:53:44,921 --> 00:53:50,093
first I'd like you to send me
a definition of algorithmic bias

826
00:53:50,093 --> 00:53:53,230
that will clarify what you have in mind

827
00:53:53,230 --> 00:53:55,832
so that I know
what I'm trying to respond to.

828
00:53:56,433 --> 00:53:57,601
And you wrote me

829
00:53:57,601 --> 00:54:02,472
that you part the term from body
is both the information manifold.

830
00:54:02,472 --> 00:54:06,943
And you sent me a quote from page 247

831
00:54:07,611 --> 00:54:10,680
that I will quote in part

832
00:54:10,680 --> 00:54:14,918
before I respond
to that background information.

833
00:54:15,552 --> 00:54:20,323
So there are two main reasons
for algorithmic approach to decision

834
00:54:20,323 --> 00:54:22,225
making that may result in unfair

835
00:54:22,225 --> 00:54:25,862
outcomes,
either at the individual or group level.

836
00:54:26,396 --> 00:54:31,768
One is that data used is biased,
and another is that the algorithm

837
00:54:32,002 --> 00:54:36,740
analyzes the data in such a way
that it yields biased results.

838
00:54:37,440 --> 00:54:40,176
The basic point to remember
is that algorithms are designed

839
00:54:40,176 --> 00:54:45,548
to achieve a certain goal not created
naturally by evolution or accident.

840
00:54:46,182 --> 00:54:50,186
Thus, most algorithms are written
to detect certain patterns of interest

841
00:54:50,720 --> 00:54:55,158
for a particular objective,
not just any pattern,

842
00:54:56,526 --> 00:54:57,961
to be able to pick out

843
00:54:57,961 --> 00:55:01,231
some patterns and disregard
others, program is

844
00:55:01,798 --> 00:55:05,869
build a model of the data
by listing expectations

845
00:55:06,403 --> 00:55:11,041
about what data should be like in order
to qualify as relevant to the problem.

846
00:55:12,042 --> 00:55:14,911
Well, as I'll explain below,

847
00:55:15,378 --> 00:55:20,450
self-organizing learning classification
and prediction models like adaptive

848
00:55:20,450 --> 00:55:24,220
resonance Theory or art overcome
all the problems.

849
00:55:24,721 --> 00:55:26,823
It's a general purpose device.

850
00:55:27,190 --> 00:55:29,859
But why don't I try to answer that

851
00:55:30,727 --> 00:55:33,930
as part of my replies to at least

852
00:55:33,997 --> 00:55:37,367
subsequent questions?

853
00:55:38,735 --> 00:55:39,469
Okay.

854
00:55:39,469 --> 00:55:40,770
Thank you so much.

855
00:55:40,770 --> 00:55:43,573
Now, as you also mentioned

856
00:55:43,907 --> 00:55:47,577
in your lecture in 1988, you pointed out

857
00:55:47,644 --> 00:55:52,349
17 issues with back propagation
and one of your most famous

858
00:55:52,349 --> 00:55:55,185
and highly cited papers
on nonlinear neural network.

859
00:55:56,119 --> 00:55:59,923
So it's been 40, 34 years now.

860
00:56:00,223 --> 00:56:04,227
Now, do you see any fundamental
Copernican change of perspective

861
00:56:04,227 --> 00:56:07,330
happening and deep learning research
or we still keep

862
00:56:07,931 --> 00:56:12,302
we're still adding Epicycles
upon Epicycles to our Ptolemaic model?

863
00:56:13,303 --> 00:56:14,237
Well, you've

864
00:56:14,237 --> 00:56:17,407
sort of anticipated
what I'm going to say,

865
00:56:17,407 --> 00:56:24,013
and as I said in my lecture,
there is investigators and I mentioned on

866
00:56:24,814 --> 00:56:29,386
Kirkpatrick and Vella
as well have recently attempted

867
00:56:29,386 --> 00:56:33,189
to modify deep learning
to overcome some of those problems.

868
00:56:33,189 --> 00:56:38,862
But as I just mentioned by lecture noted
that at least in my mind,

869
00:56:38,862 --> 00:56:42,031
they're like epicycles that are added

870
00:56:42,031 --> 00:56:46,636
to a kind of Ptolemaic model
of the solar system

871
00:56:46,636 --> 00:56:49,939
to overcome some of its problems.

872
00:56:50,507 --> 00:56:55,145
But as we all know, the Ptolemaic model
ultimately crashed

873
00:56:55,979 --> 00:56:59,749
because it was both qualitatively
and quantitative wrong

874
00:57:00,617 --> 00:57:04,587
and they could only be solved
by throwing out the Ptolemaic model

875
00:57:05,021 --> 00:57:07,891
and replacing it
with the Copernican model

876
00:57:08,425 --> 00:57:10,994
that became the basis for modern

877
00:57:11,628 --> 00:57:14,397
astronomy and astrophysics.

878
00:57:14,397 --> 00:57:18,601
So art overcomes
foundational, deep learning problems

879
00:57:19,302 --> 00:57:24,073
that can't be solved using Epicycles,
and it's already done.

880
00:57:24,107 --> 00:57:28,311
It Shortly after I introduced it in 1976,

881
00:57:28,978 --> 00:57:31,581
and it can't be overemphasized.

882
00:57:32,215 --> 00:57:36,019
As I noted in my lecture,
Deep learning is untrustworthy

883
00:57:36,553 --> 00:57:38,822
because it's not explainable

884
00:57:39,322 --> 00:57:41,591
and it's unreliable

885
00:57:41,925 --> 00:57:45,094
because it can experience
catastrophic forgetting.

886
00:57:45,695 --> 00:57:47,997
And that happens for a basic reason.

887
00:57:47,997 --> 00:57:52,035
Deep learning, just like back prop,
which is its learning

888
00:57:52,035 --> 00:57:57,440
engine, is just the sheet
for with adaptive filter.

889
00:57:57,540 --> 00:57:59,309
So as you note in your question,

890
00:57:59,309 --> 00:58:02,712
I described these two problems
in addition of 15 others.

891
00:58:03,446 --> 00:58:06,883
In my oft cited article
that I published in 1988

892
00:58:06,883 --> 00:58:12,589
and the first issue of neural network,
and I also showed that

893
00:58:12,589 --> 00:58:17,026
that or that already
solved the problem of the 1976.

894
00:58:17,961 --> 00:58:20,230
What I find sad

895
00:58:21,130 --> 00:58:24,300
is that back propagation
and deep learning architects

896
00:58:24,300 --> 00:58:27,437
like Jeff Jensen, who knows all of this

897
00:58:27,437 --> 00:58:30,840
background, never mention this history

898
00:58:32,876 --> 00:58:35,478
and keep talking about making deep
learning.

899
00:58:35,478 --> 00:58:38,581
Explain the brain.

900
00:58:38,581 --> 00:58:41,618
But it can't explain the brain cause
its foundation

901
00:58:42,252 --> 00:58:45,855
is contradicted by basic psychological

902
00:58:45,855 --> 00:58:48,725
and neural data.

903
00:58:50,026 --> 00:58:53,796
Yes, some great deep learning community.

904
00:58:54,898 --> 00:58:59,769
I like comparative
discussion and criticism,

905
00:59:00,537 --> 00:59:03,706
but I don't like solipsism and science.

906
00:59:05,575 --> 00:59:06,042
Great.

907
00:59:06,042 --> 00:59:06,943
Thank you.

908
00:59:07,443 --> 00:59:09,612
Now on slide

909
00:59:10,280 --> 00:59:13,016
number 50 of your presentation,
you pointed out

910
00:59:13,016 --> 00:59:17,587
that art is inconsistent with models
where top down

911
00:59:17,587 --> 00:59:20,723
matches suppressive
such as Bayesian explaining away.

912
00:59:21,758 --> 00:59:26,429
A similar view is evident on page
195 of conscious mind resonant brain,

913
00:59:27,063 --> 00:59:30,366
to which you also adds
one of many serious problems

914
00:59:30,967 --> 00:59:33,670
of the Bayesian models
is that fully suppressive

915
00:59:33,670 --> 00:59:37,473
matching circuits cannot solve
the stability plasticity dilemma.

916
00:59:38,341 --> 00:59:41,277
Would you care to further
elaborate elaborate on this point?

917
00:59:42,312 --> 00:59:43,713
Sure.

918
00:59:44,380 --> 00:59:47,283
My lecture and my book summarizes

919
00:59:48,818 --> 00:59:49,919
my book.

920
00:59:49,953 --> 00:59:51,821
My lecture couldn't go into a lot of it.

921
00:59:51,821 --> 00:59:56,059
Some of the copious
psychological anatomical

922
00:59:56,059 --> 00:59:58,962
and your physical logical evidence

923
01:00:01,164 --> 01:00:04,634
expectations which obey what

924
01:00:06,603 --> 01:00:09,439
I call the old matching rule

925
01:00:09,973 --> 01:00:13,109
or match against bottom up
input patterns.

926
01:00:13,676 --> 01:00:17,914
And as the lecture briefly noted,
the matching rule is defined

927
01:00:17,914 --> 01:00:20,416
by a modulatory on center

928
01:00:21,017 --> 01:00:23,786
off surround network,

929
01:00:23,786 --> 01:00:27,624
and the modulatory center is excitatory.

930
01:00:28,257 --> 01:00:30,560
However, acting by itself.

931
01:00:30,560 --> 01:00:34,464
So it can't fully excite its target
cells.

932
01:00:35,131 --> 01:00:37,433
It can prime them sensitize

933
01:00:38,901 --> 01:00:41,638
or modulate them

934
01:00:41,671 --> 01:00:43,606
to be ready to fire vigorously

935
01:00:43,606 --> 01:00:47,377
when matched, bottom up inputs arrive,

936
01:00:47,977 --> 01:00:51,247
and when there is a good enough
between the parent

937
01:00:51,347 --> 01:00:55,652
input and an active up down expectation,

938
01:00:56,185 --> 01:00:59,789
that's reading out a circuit
that obviously ought matching role.

939
01:01:00,390 --> 01:01:04,060
That's
when you get what I noted in my lecture,

940
01:01:04,560 --> 01:01:08,064
what I call a feature category resonance,

941
01:01:08,064 --> 01:01:12,635
because it develops
between the matched or intended features

942
01:01:12,635 --> 01:01:16,606
and the recognition category
that they activate.

943
01:01:17,206 --> 01:01:21,210
And it's this resonance
that synchronizes and amplifies

944
01:01:21,811 --> 01:01:26,382
the matched features
while suppressing the mismatch feature.

945
01:01:27,750 --> 01:01:30,053
And that sustained

946
01:01:30,053 --> 01:01:32,388
resonance is important

947
01:01:32,388 --> 01:01:37,593
because it sustained long enough to drive
learning in the more slowly varying

948
01:01:37,593 --> 01:01:41,731
adaptive weights of the active bottom up
filter

949
01:01:42,331 --> 01:01:45,268
and learned top down expectation.

950
01:01:45,868 --> 01:01:51,140
And because resonance triggers
learning that I call the theory

951
01:01:51,140 --> 01:01:53,743
adaptive resonance theory

952
01:01:55,044 --> 01:01:59,315
and the old matching rule avoids
catastrophic forgetting as I briefly

953
01:01:59,315 --> 01:02:03,152
mentioned in the lecture,
because it suppresses

954
01:02:03,720 --> 01:02:07,824
irrelevant features,
using it to off surround while it's

955
01:02:07,824 --> 01:02:10,526
amplifying and focusing attention

956
01:02:11,160 --> 01:02:14,831
on the critical features
that regulate both

957
01:02:14,831 --> 01:02:19,368
bottom up and top down
learning as well as.

958
01:02:19,368 --> 01:02:22,305
Successful predictions

959
01:02:22,305 --> 01:02:23,706
because they're relevant.

960
01:02:23,706 --> 01:02:26,075
They've been selected by previous

961
01:02:26,642 --> 01:02:29,078
learning experiences

962
01:02:29,078 --> 01:02:33,783
to which discover
this set of features that are predictive.

963
01:02:33,916 --> 01:02:38,454
Also in a given situation.

964
01:02:38,454 --> 01:02:42,992
And along the way,
not only does the matching rule

965
01:02:43,926 --> 01:02:44,861
achieve

966
01:02:44,861 --> 01:02:48,931
causality and predictions,
although as the world changes,

967
01:02:48,931 --> 01:02:52,001
you have to update
your plausible explanations.

968
01:02:52,468 --> 01:02:55,538
It also serves as plasticity dilemma.

969
01:02:57,440 --> 01:03:00,643
In brief, purely suppressive match
and can't do any of this.

970
01:03:01,410 --> 01:03:03,679
It shuts off the expected data

971
01:03:04,213 --> 01:03:08,618
and so it can't focus, attention
or learn about it.

972
01:03:08,618 --> 01:03:14,190
And there is fully suppressive
matching and

973
01:03:15,391 --> 01:03:18,027
spatial and modal learning,

974
01:03:18,027 --> 01:03:20,296
but that isn't learning

975
01:03:21,030 --> 01:03:23,633
to be expert about the world.

976
01:03:24,500 --> 01:03:27,170
I can explain that more
if you want to know, but

977
01:03:27,837 --> 01:03:31,808
that's also in my book
and these two kinds of learning,

978
01:03:32,675 --> 01:03:37,413
the excitatory match based learning
and the inhibitory

979
01:03:37,413 --> 01:03:41,350
mismatch learning or computation
complementary.

980
01:03:41,350 --> 01:03:45,521
It's another example
of complementary computing and

981
01:03:46,789 --> 01:03:50,693
the match based learning goes on
in the ventral or what cortical stream

982
01:03:50,693 --> 01:03:55,631
and the mismatch learning
goes on in the where or

983
01:03:56,732 --> 01:03:58,968
dorsal cortical stream.

984
01:03:58,968 --> 01:04:02,738
The what stream for perception
and categorization of prediction.

985
01:04:03,239 --> 01:04:07,543
The West Stream
for the spatial representation in action.

986
01:04:07,543 --> 01:04:11,547
And then you need what,
where and where, what interactions

987
01:04:12,582 --> 01:04:17,520
so that you can reach for
and otherwise engage through approach.

988
01:04:17,520 --> 01:04:21,457
And if you look at reach for approach

989
01:04:21,958 --> 01:04:24,961
to things that you've recognized.

990
01:04:26,329 --> 01:04:27,063
Thank you.

991
01:04:27,063 --> 01:04:31,033
Now, following from the previous question
and considering that

992
01:04:31,200 --> 01:04:35,204
the free energy principle and active
inference framework has works in

993
01:04:35,204 --> 01:04:39,909
progress are related to predictive
coding and Bayesian brain hypothesis.

994
01:04:40,443 --> 01:04:41,410
What is your view

995
01:04:41,410 --> 01:04:45,481
on the extent of compatibility
between art and active inference?

996
01:04:46,182 --> 01:04:49,552
Because despite some prima facie
similarities between the two,

997
01:04:50,820 --> 01:04:55,091
do you see them as fundamentally
incompatible or irritants salable?

998
01:04:55,958 --> 01:04:57,827
And how could this

999
01:04:57,860 --> 01:05:00,897
how could this issue
be rigorously evaluated

1000
01:05:00,897 --> 01:05:04,767
and positively resolved
in terms of reconciliation or integration

1001
01:05:04,767 --> 01:05:08,404
of art and acting and active inference
or otherwise?

1002
01:05:08,704 --> 01:05:12,842
Because you seem to add some more context
here, Smith.

1003
01:05:13,242 --> 01:05:17,013
Smith at all in their recent paper,
an active inference approach to modeling

1004
01:05:17,013 --> 01:05:18,781
structure learning.

1005
01:05:18,781 --> 01:05:22,184
Have it stated that
although there they have not explicitly

1006
01:05:22,184 --> 01:05:26,522
incorporated arts in a top down
attentional and feedback mechanisms,

1007
01:05:27,056 --> 01:05:31,994
there are mechanisms within their active
inference based model which they believe

1008
01:05:32,028 --> 01:05:36,032
are quite similar to top down
and bottom up feedback exchange in art.

1009
01:05:36,032 --> 01:05:39,602
So there seems to be
some degree of disagreement

1010
01:05:39,602 --> 01:05:43,539
about the compatibility
between the two frameworks.

1011
01:05:44,273 --> 01:05:50,146
Well, let me try to respond
to the two parts of your question.

1012
01:05:51,580 --> 01:05:52,715
So I'm not going to try to

1013
01:05:52,715 --> 01:05:57,320
talk about Smith at all for a moment.

1014
01:05:57,320 --> 01:05:59,088
Let's talk about free energy.

1015
01:05:59,088 --> 01:06:02,959
And I like getting definitions
on the table

1016
01:06:03,459 --> 01:06:06,662
because it's really so frustrating
to try to remember

1017
01:06:06,662 --> 01:06:09,098
what something is
when someone's talking about it.

1018
01:06:09,732 --> 01:06:12,134
So I go to Wikipedia.

1019
01:06:12,134 --> 01:06:16,038
Wikipedia writes in part
that the free energy principle

1020
01:06:16,072 --> 01:06:18,741
asserts, quote,

1021
01:06:19,375 --> 01:06:20,843
"that systems minimize

1022
01:06:20,843 --> 01:06:24,113
the free energy function
of their internal state...

1023
01:06:24,947 --> 01:06:28,284
which entailed beliefs about,
hidden states in their environment.

1024
01:06:28,985 --> 01:06:33,122
The implicit minimization of free energy
is formally related

1025
01:06:33,723 --> 01:06:38,260
to variational Bayesian methods
and which originally introduced

1026
01:06:38,260 --> 01:06:43,165
by Karl Friston as an explanation
for embodied perception in neuroscience,

1027
01:06:43,699 --> 01:06:46,168
where it's also known
as active inference."

1028
01:06:46,168 --> 01:06:48,504
We all know he's a brilliant

1029
01:06:49,171 --> 01:06:52,141
and very insightful man.

1030
01:06:52,141 --> 01:06:55,411
The free energy principle describes
the behavior of a given system

1031
01:06:55,411 --> 01:06:58,481
by modeling it through a Markov blanket

1032
01:06:58,481 --> 01:07:04,086
that tries to minimize the difference
between their model of the world

1033
01:07:04,587 --> 01:07:08,124
and their sense
and associative perception.

1034
01:07:08,691 --> 01:07:12,928
This difference can be described
as surprise, and it's minimized

1035
01:07:12,928 --> 01:07:18,367
by continuous correction
of the world model of the system.

1036
01:07:20,302 --> 01:07:22,938
One more part of
the quote The free energy principle has

1037
01:07:22,938 --> 01:07:28,144
been criticized for being very difficult
to understand, even for experts.

1038
01:07:28,711 --> 01:07:30,746
And the mathematical consistency of a

1039
01:07:30,746 --> 01:07:32,915
theory may have been questioned
by recent studies.

1040
01:07:33,549 --> 01:07:37,753
Discussions of the principle
have also been criticized for invoking

1041
01:07:37,753 --> 01:07:41,490
metaphysical assumptions far removed

1042
01:07:41,657 --> 01:07:44,193
from a testable scientific predictions,

1043
01:07:44,760 --> 01:07:48,864
making the principle on falsifiable.

1044
01:07:50,433 --> 01:07:53,969
And in a 2018 interview,
Friston acknowledged

1045
01:07:54,770 --> 01:08:00,109
that the free energy
principle is not properly falsifiable.

1046
01:08:01,477 --> 01:08:04,713
So that's risk. So

1047
01:08:04,713 --> 01:08:09,251
so my main concern with the free energy
principle, just like any theory

1048
01:08:09,952 --> 01:08:12,121
about how brain makes a mind, is

1049
01:08:13,022 --> 01:08:15,791
how much data can it explain

1050
01:08:16,425 --> 01:08:18,627
in a principle and unifying way?

1051
01:08:19,728 --> 01:08:21,897
That's what we do in science.

1052
01:08:21,897 --> 01:08:25,134
We develop theories to imperfect data.

1053
01:08:25,734 --> 01:08:29,271
And in the case of the free energy
principle, from what I can see

1054
01:08:29,939 --> 01:08:32,641
here, there is essentially no data.

1055
01:08:33,075 --> 01:08:34,977
And you can correct me if I'm wrong.

1056
01:08:36,278 --> 01:08:37,980
It therefore cannot be

1057
01:08:37,980 --> 01:08:40,983
evaluated as a physical theory at all.

1058
01:08:42,251 --> 01:08:45,454
And there's a basic for this problem.

1059
01:08:46,789 --> 01:08:50,626
Our brains are designed
to autonomously learn in real time

1060
01:08:51,127 --> 01:08:55,865
in response
to a changing non stationary world

1061
01:08:55,865 --> 01:08:59,235
that's filled with unexpected
events like today,

1062
01:08:59,835 --> 01:09:03,072
we're experiencing an unexpected event
that I didn't know till

1063
01:09:03,706 --> 01:09:06,775
that I'd be enjoying your company today.

1064
01:09:07,910 --> 01:09:09,812
Optimization principles

1065
01:09:09,812 --> 01:09:14,016
were designed to cope
with stationary dynamics.

1066
01:09:14,016 --> 01:09:19,088
One's rules and probabilities
do not change through time,

1067
01:09:19,088 --> 01:09:22,591
so it's not possible to, quote, minimize
the difference between

1068
01:09:22,591 --> 01:09:26,162
their model of the world and their sense
in associate perception, unquote,

1069
01:09:26,795 --> 01:09:30,099
because there is no predefined
model of the world,

1070
01:09:30,633 --> 01:09:34,036
which is always changing
in unexpected ways.

1071
01:09:34,470 --> 01:09:37,373
So you need a theory about how the world

1072
01:09:37,373 --> 01:09:40,442
changes.

1073
01:09:40,442 --> 01:09:45,214
Surprise occurs in art
when there's a big enough mismatch

1074
01:09:45,714 --> 01:09:48,751
between an input pad
and the currently active

1075
01:09:49,318 --> 01:09:53,355
top down expectation of a category
that it's activating.

1076
01:09:54,123 --> 01:09:57,259
This mismatch activates
the orienting system

1077
01:09:57,259 --> 01:10:00,563
that I briefly discussed in my book,
which interacts

1078
01:10:00,563 --> 01:10:05,000
with the attentional system
where the category learning does occur.

1079
01:10:05,668 --> 01:10:09,705
And as I illustrated in our discussions
of search in this,

1080
01:10:09,705 --> 01:10:13,976
you learned that it drives
hypothesis testing or memory search

1081
01:10:14,476 --> 01:10:19,415
to discover a better match
or to begin to learn new category.

1082
01:10:19,415 --> 01:10:21,684
So order discuss a better match.

1083
01:10:21,684 --> 01:10:22,751
In the case where

1084
01:10:24,453 --> 01:10:25,287
the system was

1085
01:10:25,287 --> 01:10:30,025
attending, some other familiar features
when the new event that occurs

1086
01:10:30,793 --> 01:10:34,330
but the features are new when put have
previously been categorized.

1087
01:10:34,330 --> 01:10:36,098
That's why they're familiar.

1088
01:10:36,098 --> 01:10:39,368
And then the orienting system
very quickly shifts attention

1089
01:10:39,902 --> 01:10:41,370
to the matching category.

1090
01:10:41,370 --> 01:10:48,010
And you resonate on you recognize it
consciously, often, or it begins to learn

1091
01:10:48,010 --> 01:10:52,281
a new category when the input represents
a truly unfamiliar

1092
01:10:52,281 --> 01:10:54,416
and novel situation

1093
01:10:55,317 --> 01:10:57,486
so as to Bayesian methods in

1094
01:10:59,021 --> 01:11:01,290
Hey, I'm a mathematician,

1095
01:11:01,290 --> 01:11:04,360
how can I not love it's right.

1096
01:11:04,360 --> 01:11:07,830
But the beauty of Bayes
is its simplicity.

1097
01:11:07,830 --> 01:11:08,797
You're just right.

1098
01:11:08,797 --> 01:11:13,869
The probability of two events
A and B in two different ways.

1099
01:11:14,470 --> 01:11:18,907
The probability of being given
eight times the probability then

1100
01:11:19,808 --> 01:11:24,079
the probability of a given p times
the probability of B

1101
01:11:24,847 --> 01:11:27,950
set them equal because they're identical.

1102
01:11:27,950 --> 01:11:31,553
Divide by, let's say, probability A
and then optimized.

1103
01:11:32,087 --> 01:11:33,055
That's Bayes

1104
01:11:34,623 --> 01:11:36,058
and it's a useful

1105
01:11:36,058 --> 01:11:39,928
statistical method and should continue
to be used in statistics.

1106
01:11:40,529 --> 01:11:44,166
But it's just the form of identity
where in lies its power.

1107
01:11:44,800 --> 01:11:48,003
It says nothing
about any physical reality,

1108
01:11:48,537 --> 01:11:51,507
whether in physics, chemistry or biology.

1109
01:11:52,308 --> 01:11:56,779
Today's rule itself
tells us nothing about physical reality

1110
01:11:57,313 --> 01:12:02,084
and contains no risk takes to discover
anything about physical reality

1111
01:12:02,951 --> 01:12:05,521
that you need to develop models driven

1112
01:12:05,921 --> 01:12:09,958
by a profound
analysis of large databases.

1113
01:12:10,592 --> 01:12:13,729
So it turns out that biological models
like R

1114
01:12:13,729 --> 01:12:17,132
do not incorporate the base rule.

1115
01:12:17,132 --> 01:12:20,536
However, authors routinely

1116
01:12:21,070 --> 01:12:26,642
choose the best or optimal categories
that represent the data best,

1117
01:12:26,642 --> 01:12:29,578
so you don't need Bayes to achieve
optimality.

1118
01:12:30,346 --> 01:12:34,049
Also, Bayes works best
in a stationary world with stationary

1119
01:12:34,049 --> 01:12:39,121
probabilities and it's designed to
learn about a non stationary

1120
01:12:41,857 --> 01:12:44,626
one discusses till the cows come home.

1121
01:12:45,794 --> 01:12:48,597
It's good for what it was designed for

1122
01:12:51,033 --> 01:12:54,470
and some of the neuroscientists
who try to apply Bayes

1123
01:12:55,237 --> 01:12:57,606
wonderful experimentalists,

1124
01:12:57,606 --> 01:13:00,676
but they know no math and no theory.

1125
01:13:00,676 --> 01:13:03,212
And you know, it's

1126
01:13:06,548 --> 01:13:09,451
the temptation of a free lunch.

1127
01:13:09,451 --> 01:13:11,553
There it is waiting to be applied.

1128
01:13:12,187 --> 01:13:19,561
There is no free lunch in science.

1129
01:13:19,561 --> 01:13:20,462
Thank you.

1130
01:13:21,397 --> 01:13:25,601
Now, as a final point of comparison,
what are the is Smith?

1131
01:13:25,601 --> 01:13:26,869
I didn't replied.

1132
01:13:26,869 --> 01:13:29,938
Yes, yes. Oh, okay.

1133
01:13:30,105 --> 01:13:35,210
You quoted a sentence of Smith.

1134
01:13:35,210 --> 01:13:39,014
But before that said Smith wrote,

1135
01:13:40,282 --> 01:13:43,318
It is also worth highlighting that as our

1136
01:13:43,652 --> 01:13:46,422
is intended
primarily as a proof of concept

1137
01:13:47,256 --> 01:13:52,694
and a demonstration of an available model
expansion reduction approach

1138
01:13:53,295 --> 01:13:56,832
that can be used
within active inference research.

1139
01:13:57,433 --> 01:14:00,402
It does not explicitly incorporate

1140
01:14:00,903 --> 01:14:04,039
some aspects such as top down intention

1141
01:14:04,673 --> 01:14:08,377
that are of clear importance
to the cognitive learning processes

1142
01:14:08,911 --> 01:14:11,046
and that have been implement
in previous models.

1143
01:14:11,046 --> 01:14:13,749
For example, the adaptive resonance.

1144
01:14:13,749 --> 01:14:17,152
The Iraq model of Grossberg
was designed to incorporate

1145
01:14:17,753 --> 01:14:21,123
top down attentional mechanisms
and feedback mechanism

1146
01:14:21,824 --> 01:14:25,294
to address a fundamental knowledge
acquisition problem,

1147
01:14:26,161 --> 01:14:30,599
the temporal instability of previously
learned information that can occur

1148
01:14:31,166 --> 01:14:34,570
when a system also remains
sufficiently plastic

1149
01:14:34,570 --> 01:14:37,539
to learn new
and potentially overlapping information.

1150
01:14:38,740 --> 01:14:39,341
Well, our

1151
01:14:39,341 --> 01:14:43,779
simulations do not explicitly incorporate
these additional complexities.

1152
01:14:44,313 --> 01:14:46,815
There are clear analogs.

1153
01:14:46,815 --> 01:14:51,320
The top down and bottom up feedback
exchanges are not within our model,

1154
01:14:51,320 --> 01:14:54,256
such as the prediction
and prediction error signaling

1155
01:14:54,923 --> 01:14:58,594
within the neural process theory
associated with active instrumental

1156
01:14:59,061 --> 01:15:02,464
order addresses
the temporal instable problem, primarily

1157
01:15:03,031 --> 01:15:07,035
the mechanism that top down expectancies
that guide attention

1158
01:15:07,436 --> 01:15:12,040
and match them on platform up
into patterns, which is quite similar

1159
01:15:12,040 --> 01:15:15,511
to the prior expectations and likelihood

1160
01:15:15,511 --> 01:15:18,680
mappings used with an active inference.

1161
01:15:18,680 --> 01:15:21,383
But as I've already noted, the quote

1162
01:15:21,416 --> 01:15:25,420
prior expectations
and likelihood matching mappings

1163
01:15:25,420 --> 01:15:30,425
within adaptive inference, quote unquote
do not have any of the key

1164
01:15:30,425 --> 01:15:33,061
learning, attention and memory stability
properties.

1165
01:15:33,061 --> 01:15:37,933
The matching New York matching
rule is a unique solution to that problem

1166
01:15:38,500 --> 01:15:42,137
in its variations,

1167
01:15:42,137 --> 01:15:45,941
it's been supported by psychological,

1168
01:15:45,941 --> 01:15:51,246
anatomical,
physiological and biophysical data.

1169
01:15:51,246 --> 01:15:53,582
It also occurs in many species.

1170
01:15:54,149 --> 01:15:57,319
Nobu Suruga,
for example, shows it occurs in bats.

1171
01:15:58,687 --> 01:16:01,490
It occurs in ferrets, you know.

1172
01:16:02,891 --> 01:16:05,661
So also, I think it's important to note

1173
01:16:07,229 --> 01:16:10,766
that when learning begins
in an art model, it doesn't need

1174
01:16:11,366 --> 01:16:13,802
for higher expectations or likelihood.

1175
01:16:14,703 --> 01:16:18,073
In fact, typically the initial bottom up,

1176
01:16:18,473 --> 01:16:21,443
it shows it to be random

1177
01:16:21,443 --> 01:16:24,012
if you don't know
what you're going to be experiencing.

1178
01:16:24,313 --> 01:16:28,216
And the initial top down
expectations are chosen to be large

1179
01:16:28,884 --> 01:16:33,488
so that whatever category
happens to be learned when it reads out

1180
01:16:34,056 --> 01:16:38,660
its top down expectation,
it can match whatever features

1181
01:16:38,727 --> 01:16:40,796
activated that category.

1182
01:16:40,796 --> 01:16:44,766
So they will start lodging
than their room to match

1183
01:16:44,766 --> 01:16:49,471
the critical features that happen
to be learned in that category.

1184
01:16:50,138 --> 01:16:54,376
So there are no built in models

1185
01:16:54,876 --> 01:16:58,780
or discovers its own models.

1186
01:16:58,780 --> 01:17:03,518
I should also emphasize that
active inference is also not explainable.

1187
01:17:04,319 --> 01:17:07,856
Sports is explainable
because a currently active

1188
01:17:08,523 --> 01:17:12,628
feature activity pattern,
namely the features

1189
01:17:12,628 --> 01:17:17,933
to which attention is paid, controls
all learning and prediction.

1190
01:17:17,933 --> 01:17:20,102
The model and in principle

1191
01:17:20,102 --> 01:17:23,071
can be measured
by neurophysiological experiments,

1192
01:17:23,739 --> 01:17:27,576
a model without stellar activities
or short term memory traces

1193
01:17:29,077 --> 01:17:31,246
that can represent the critical feature

1194
01:17:31,647 --> 01:17:34,082
and can't be explainable.

1195
01:17:35,817 --> 01:17:38,954
So I think there are quality differences.

1196
01:17:39,688 --> 01:17:42,758
I don't say people shouldn't
use active inference.

1197
01:17:43,325 --> 01:17:46,161
It may be incredibly useful and powerful

1198
01:17:46,828 --> 01:17:49,031
in technological applications,

1199
01:17:49,665 --> 01:17:52,501
but when one is doing, you know,

1200
01:17:53,435 --> 01:17:56,304
brain science, psychology,

1201
01:17:56,304 --> 01:17:58,407
it just doesn't match

1202
01:17:58,407 --> 01:18:01,176
the foundational data.

1203
01:18:01,176 --> 01:18:03,612
It's just doesn't

1204
01:18:05,213 --> 01:18:08,183
want a personal thing.

1205
01:18:08,183 --> 01:18:08,884
Thanks.

1206
01:18:09,084 --> 01:18:11,253
And I guess you

1207
01:18:12,554 --> 01:18:15,791
somehow already answered
part of this question, but

1208
01:18:16,692 --> 01:18:21,663
what are the possible ways in which art's
approach to explainable AI,

1209
01:18:22,531 --> 01:18:24,866
which,
if I'm not mistaken, can be described

1210
01:18:24,866 --> 01:18:28,570
as a modern dependent,
intrinsically explainable approach,

1211
01:18:29,538 --> 01:18:31,707
can inform active inference
inferences approach

1212
01:18:32,407 --> 01:18:34,843
across fertilize,
but that which is based on

1213
01:18:35,110 --> 01:18:38,647
objective reasoning through
constructing generative models.

1214
01:18:38,647 --> 01:18:42,150
For example,
as I sketched out in an pezzullo's

1215
01:18:42,751 --> 01:18:45,721
understanding
explanation and active inference paper.

1216
01:18:47,089 --> 01:18:48,590
Well, first,

1217
01:18:49,157 --> 01:18:54,029
I don't think or is model dependent.

1218
01:18:54,029 --> 01:18:57,099
As I just noted, one begins typically

1219
01:18:57,099 --> 01:19:00,335
to learn in art with random

1220
01:19:00,335 --> 01:19:02,137
initial bottom up waves

1221
01:19:02,137 --> 01:19:06,842
and uniformly distribute
you did top down initial adaptive way

1222
01:19:06,842 --> 01:19:10,879
so you can match any category
that you happen to learn.

1223
01:19:12,481 --> 01:19:15,217
But the authors you quoted write in part

1224
01:19:15,217 --> 01:19:18,687
that active inference in here,
I want to quote them

1225
01:19:19,621 --> 01:19:21,656
so we can find

1226
01:19:23,158 --> 01:19:25,026
a more detail.

1227
01:19:25,026 --> 01:19:29,865
Active inference
quote implies a deep generative model

1228
01:19:30,465 --> 01:19:33,001
that includes a model of the world

1229
01:19:33,668 --> 01:19:36,271
used to infer policy

1230
01:19:36,271 --> 01:19:39,374
in a higher level model
that attempts to predict which policies

1231
01:19:39,374 --> 01:19:43,044
will be selected
based upon a space of hyper

1232
01:19:43,678 --> 01:19:49,484
that is counterfactual explanations
and which can subsequently

1233
01:19:49,484 --> 01:19:54,890
be used to provide retrospective
explanations about the policies pursued.

1234
01:19:56,191 --> 01:19:57,259
So again,

1235
01:19:57,259 --> 01:20:00,362
artworks
without a generative model of the world

1236
01:20:00,862 --> 01:20:06,034
or any predefined paths, the course

1237
01:20:06,134 --> 01:20:10,472
one is trying to discover
what changing world it happens to be,

1238
01:20:10,472 --> 01:20:14,042
and then nobody knows what it is
at priority

1239
01:20:15,277 --> 01:20:16,945
and in general or not.

1240
01:20:16,945 --> 01:20:20,582
Classify responds to a front end

1241
01:20:20,982 --> 01:20:24,452
of three processes

1242
01:20:24,452 --> 01:20:29,958
that process perceptual data
from one or another sense, notably

1243
01:20:29,958 --> 01:20:35,063
vision and audition,
where we get most of our information

1244
01:20:35,063 --> 01:20:38,433
about the world.

1245
01:20:38,433 --> 01:20:41,870
And that's why a classifier
like art begins its work in the brain,

1246
01:20:42,470 --> 01:20:44,906
in the temporal cortex,

1247
01:20:45,540 --> 01:20:47,943
where it receives highly

1248
01:20:47,943 --> 01:20:50,912
pre processed perceptual representation.

1249
01:20:52,013 --> 01:20:57,752
So for decades,
the work went into understanding.

1250
01:20:57,752 --> 01:20:59,988
Brains consciously stay in here

1251
01:21:01,423 --> 01:21:03,592
and in the case of vision or

1252
01:21:04,159 --> 01:21:08,129
classifies perceptual boundaries
and surfaces that require

1253
01:21:08,830 --> 01:21:11,233
multiple stages of processing.

1254
01:21:11,967 --> 01:21:14,302
Because as I mentioned

1255
01:21:14,302 --> 01:21:17,405
briefly,
they were the outcome of what I call

1256
01:21:17,405 --> 01:21:19,975
hierarchical resolution of uncertainty.

1257
01:21:20,609 --> 01:21:22,611
You need multiple stages

1258
01:21:23,311 --> 01:21:26,481
to define a perceptual boundary surface

1259
01:21:26,948 --> 01:21:29,417
one reason being because the sensory

1260
01:21:30,151 --> 01:21:33,321
organs registers such noisy

1261
01:21:33,321 --> 01:21:37,259
and incomplete data like you may know,
there are photosensitive

1262
01:21:38,760 --> 01:21:41,463
has a huge blind spot

1263
01:21:41,463 --> 01:21:46,201
where you can't register any sense,
any virtual signal.

1264
01:21:46,568 --> 01:21:48,737
The blind as big as the phobia

1265
01:21:49,271 --> 01:21:52,474
or all of our high resolution
vision occurs.

1266
01:21:52,474 --> 01:21:54,776
So it's not a little thing.

1267
01:21:54,776 --> 01:21:56,912
And moreover, veins

1268
01:21:57,612 --> 01:22:01,683
come out of the 12 year and occlude
the retina in multiple places.

1269
01:22:02,183 --> 01:22:06,922
And you can register visual signals
on the veins, either

1270
01:22:06,922 --> 01:22:12,661
So the signal you're getting
is very incomplete and it takes multiple

1271
01:22:12,661 --> 01:22:16,965
processing stages
to overcome those uncertainties.

1272
01:22:16,965 --> 01:22:20,802
And my cousin, I've worked for decades
to explain

1273
01:22:21,503 --> 01:22:24,739
how that happens

1274
01:22:25,607 --> 01:22:27,943
and maybe I'll stop after

1275
01:22:29,344 --> 01:22:30,378
so much.

1276
01:22:30,679 --> 01:22:35,083
Now, this next question
is of a personal interest to me,

1277
01:22:35,550 --> 01:22:38,153
because currently working on modeling

1278
01:22:38,153 --> 01:22:41,389
some probabilistic aspects
of affective response to music

1279
01:22:41,389 --> 01:22:46,294
and your most recent paper toward
understanding the brain dynamics of music

1280
01:22:47,262 --> 01:22:48,363
immensely helped

1281
01:22:48,363 --> 01:22:50,765
me gain
a better understanding of entrainment.

1282
01:22:52,233 --> 01:22:55,337
As you pointed out in the supplementary
notes for this paper,

1283
01:22:56,571 --> 01:22:58,440
violation of prior learned

1284
01:22:58,440 --> 01:23:02,043
expectations is instrumental
in inducing a wide range

1285
01:23:02,043 --> 01:23:06,514
of affective responses
in musical and nonmusical situations.

1286
01:23:07,115 --> 01:23:10,452
Some psychologists, such as Patrick
Houston, have distinguished

1287
01:23:10,452 --> 01:23:14,456
between perception
and arousal of emotions.

1288
01:23:14,456 --> 01:23:17,092
Trust you, but you left out a question.

1289
01:23:17,592 --> 01:23:20,895
This is lots of time where you just skip
the next question.

1290
01:23:21,363 --> 01:23:24,366
I want up quite a bit about it

1291
01:23:25,600 --> 01:23:29,437
so how do you see the future
of art and neuro inspired?

1292
01:23:30,372 --> 01:23:32,841
I think that will be our last question.

1293
01:23:33,508 --> 01:23:35,910
Okay. So come back to that.

1294
01:23:35,910 --> 01:23:37,545
Yes, yes. Thank you.

1295
01:23:37,545 --> 01:23:40,615
Because that
that's an important question. Yes.

1296
01:23:40,849 --> 01:23:41,216
Okay.

1297
01:23:41,216 --> 01:23:42,350
So sorry to interrupt.

1298
01:23:42,350 --> 01:23:44,419
I just want to be sure no problem.

1299
01:23:44,419 --> 01:23:46,755
Thank you. Now, yes.

1300
01:23:47,689 --> 01:23:50,859
Well, some psychologists
such as Patrick Forslund,

1301
01:23:50,859 --> 01:23:53,661
have distinguish between the perception

1302
01:23:53,895 --> 01:23:57,565
and the arousal of emotions
in the context of musical experience.

1303
01:23:58,466 --> 01:24:02,270
And also several studies
such as The Works of Use, Lynn

1304
01:24:02,270 --> 01:24:06,041
and Gabrielson from the Psychology
Department of Sully University

1305
01:24:06,741 --> 01:24:10,512
have shown that despite music's ability
to communicate

1306
01:24:10,512 --> 01:24:14,349
a wide range of positively
and negatively emotions,

1307
01:24:15,683 --> 01:24:16,785
it is somehow

1308
01:24:16,785 --> 01:24:19,854
evokes mostly positively balanced
emotions.

1309
01:24:20,755 --> 01:24:23,925
For instance, we can easily perceive rage

1310
01:24:23,925 --> 01:24:27,128
or anger in music
without necessarily getting angry.

1311
01:24:27,629 --> 01:24:30,698
On the other hand,
we're more likely to actually feel

1312
01:24:30,698 --> 01:24:33,334
elevated and happy
after listening to music.

1313
01:24:34,569 --> 01:24:39,474
And also the evidence shows
that this disparity between perception

1314
01:24:39,474 --> 01:24:44,112
and evocation of emotion
is probably even more significant

1315
01:24:44,112 --> 01:24:48,683
in musical experiences
than any other nonmusical experiences.

1316
01:24:49,451 --> 01:24:52,654
So how can this difference in diversity

1317
01:24:52,654 --> 01:24:58,359
between perceived and aroused, aroused
or evoked musical emotions

1318
01:24:58,359 --> 01:25:01,863
be accounted to be accounted
for within art framework?

1319
01:25:01,863 --> 01:25:06,401
Can it possibly be regarded
as another kind of broken symmetry,

1320
01:25:06,401 --> 01:25:10,171
as you mention on page 621 of your book,

1321
01:25:10,738 --> 01:25:15,577
but specific to musical?

1322
01:25:15,577 --> 01:25:18,847
So as you've noted,

1323
01:25:18,847 --> 01:25:22,717
I haven't studied
this issues in the context of music, but

1324
01:25:22,717 --> 01:25:26,488
I'll try to venture some general comments

1325
01:25:27,188 --> 01:25:30,391
I should note that the lab and art model,

1326
01:25:32,160 --> 01:25:33,728
which is

1327
01:25:33,728 --> 01:25:36,264
a development of art, to show

1328
01:25:38,166 --> 01:25:41,402
how and why all neocortical circuits

1329
01:25:42,036 --> 01:25:44,639
that support perception and cognition

1330
01:25:45,273 --> 01:25:47,342
typically share a canonical

1331
01:25:47,909 --> 01:25:50,845
six layer circuit.

1332
01:25:50,845 --> 01:25:53,581
My colleagues and I have modeled,

1333
01:25:53,581 --> 01:25:58,386
just as in our brains, variations
of this canonical

1334
01:25:58,386 --> 01:26:04,192
lamina circuit can support all perceptual
and cognitive processes.

1335
01:26:04,192 --> 01:26:10,965
So there's a major generalization of art,
and we've done it for vision, speech

1336
01:26:10,965 --> 01:26:16,571
and cognitive working memory
and planning in particular.

1337
01:26:16,571 --> 01:26:20,942
So the main point
is that the alignment of circuitry

1338
01:26:20,942 --> 01:26:23,244
is basically in all perceptual

1339
01:26:24,812 --> 01:26:27,582
areas, vision or

1340
01:26:27,582 --> 01:26:29,751
that's how one can create

1341
01:26:29,751 --> 01:26:33,121
a context for discussing music.

1342
01:26:33,121 --> 01:26:38,459
And in fact, my work on music
applied such discoveries.

1343
01:26:38,593 --> 01:26:41,362
I was able to put together

1344
01:26:41,930 --> 01:26:44,098
discoveries that had been made

1345
01:26:45,366 --> 01:26:47,368
based on

1346
01:26:47,368 --> 01:26:51,706
what I believe were different
evolutionary pressures that had

1347
01:26:54,242 --> 01:26:56,144
the organization about brains.

1348
01:26:56,144 --> 01:27:01,716
But that evolution also discovered
and I try to sketch how

1349
01:27:01,716 --> 01:27:04,485
if you put some them together
in a certain way,

1350
01:27:05,587 --> 01:27:09,958
then the capacity for

1351
01:27:11,125 --> 01:27:15,930
learning
and consciously music could arise.

1352
01:27:16,598 --> 01:27:18,866
So now how about arousal?

1353
01:27:19,500 --> 01:27:23,838
So it's essential, of course,
to all awareness and consciousness.

1354
01:27:23,838 --> 01:27:28,476
Your cortex needs to be adequately
aroused for waking

1355
01:27:28,476 --> 01:27:31,212
consciousness to occur at all.

1356
01:27:32,247 --> 01:27:34,916
It also arousal plays a major role

1357
01:27:34,916 --> 01:27:38,486
in the processing of emotions
and is very relevant.

1358
01:27:38,553 --> 01:27:40,922
The musical issues

1359
01:27:41,522 --> 01:27:45,226
was mitigated dipole model explains

1360
01:27:45,226 --> 01:27:50,431
how own and plus this piece of this
that's organized

1361
01:27:50,431 --> 01:27:53,935
in all parts of our brain

1362
01:27:53,935 --> 01:27:56,104
perceptual cognitive motor

1363
01:27:57,438 --> 01:28:00,208
affective in particular,

1364
01:28:00,208 --> 01:28:03,244
emotions are organized in pairs

1365
01:28:03,244 --> 01:28:06,581
as in such an emotional dipole.

1366
01:28:07,682 --> 01:28:10,785
And one reason is because
emotions need to compete

1367
01:28:10,785 --> 01:28:15,089
with each other,
such as fear versus relief.

1368
01:28:16,791 --> 01:28:17,825
For example, in

1369
01:28:17,825 --> 01:28:20,628
post-traumatic stress disorder therapy,

1370
01:28:21,296 --> 01:28:23,898
a therapist may try to help patients

1371
01:28:24,565 --> 01:28:27,635
to think about positive experiences

1372
01:28:28,403 --> 01:28:31,039
that generate relief

1373
01:28:31,039 --> 01:28:34,142
in order to inhibit the chronic

1374
01:28:34,142 --> 01:28:37,345
that's so destabilizing during PTSD.

1375
01:28:38,279 --> 01:28:41,382
So their opposites are competing

1376
01:28:42,583 --> 01:28:45,420
and. Another property
that arousal enables

1377
01:28:45,420 --> 01:28:50,158
is that this sudden offset of an emotion
like here,

1378
01:28:51,059 --> 01:28:54,128
let's say during escape behavior,

1379
01:28:54,128 --> 01:28:56,998
let's say,
you know, favorite example of mine is,

1380
01:28:57,732 --> 01:29:01,803
you know, some cruel experimentalist
puts the picture in a box

1381
01:29:02,537 --> 01:29:04,772
that was electrified.

1382
01:29:04,772 --> 01:29:07,775
The pitch is feeling pain and fear.

1383
01:29:07,775 --> 01:29:13,081
It's dashing frantically around,
trying to keep its feet off the floor.

1384
01:29:13,081 --> 01:29:15,183
It bangs into a red buzzer,

1385
01:29:16,050 --> 01:29:18,720
the buzzer shuts the shock off

1386
01:29:19,454 --> 01:29:21,923
and the animal experienced

1387
01:29:21,923 --> 01:29:24,559
a wave of relief or positive motivation

1388
01:29:25,093 --> 01:29:27,962
for learning the escape response.

1389
01:29:28,696 --> 01:29:32,200
So this rebound from theater relief

1390
01:29:33,901 --> 01:29:34,435
that can

1391
01:29:34,435 --> 01:29:39,040
be associated with actions
that lead to escape and can motivate

1392
01:29:39,040 --> 01:29:44,078
escape by means in the future
is energized by arousal.

1393
01:29:44,078 --> 01:29:46,547
Indicate a dipole.

1394
01:29:46,948 --> 01:29:50,118
You shut off the external cue of shock,

1395
01:29:51,018 --> 01:29:53,221
but the arousal is technically

1396
01:29:53,221 --> 01:29:58,326
or has sustained activity
in both this gear and the channel.

1397
01:29:58,359 --> 01:30:02,363
So because the arousal is sustained
or tonic through time

1398
01:30:03,164 --> 01:30:06,134
and equally activates
the fear and relief channels

1399
01:30:06,734 --> 01:30:09,270
when fear suddenly decreases,

1400
01:30:09,871 --> 01:30:13,341
then arousal and the relief
channel wins, the competition.

1401
01:30:14,041 --> 01:30:18,045
And therefore I call what I call
an antagonistic rebound

1402
01:30:18,613 --> 01:30:22,316
from fear relief
that activates the relief channel

1403
01:30:22,750 --> 01:30:26,254
and thereby
providing motivation for escape,

1404
01:30:27,488 --> 01:30:29,724
whether reactive or learned

1405
01:30:30,725 --> 01:30:33,394
to escape experiences.

1406
01:30:33,394 --> 01:30:37,498
And I want to appropriate,
which is related to some degree

1407
01:30:37,498 --> 01:30:41,702
the music that the non occurrence
of an expected event

1408
01:30:42,670 --> 01:30:45,173
and by itself cause

1409
01:30:45,173 --> 01:30:48,643
a burst of arousal
and that's an antagonistic rebound

1410
01:30:49,811 --> 01:30:52,346
and can slap emotions

1411
01:30:52,346 --> 01:30:55,583
from the negative in so doing.

1412
01:30:56,350 --> 01:30:58,586
And I always love that discovery

1413
01:30:58,586 --> 01:31:04,692
because I especially loved discoveries
where the occurrence of nothing

1414
01:31:04,692 --> 01:31:08,262
has profound effects on future behavior.

1415
01:31:09,096 --> 01:31:13,835
So it's the non occurrence,
the expectation because of this mismatch

1416
01:31:14,402 --> 01:31:16,804
that can emotions

1417
01:31:18,439 --> 01:31:20,041
now how this influences

1418
01:31:20,041 --> 01:31:23,444
the perception of music needs more work.

1419
01:31:23,444 --> 01:31:29,851
It's as I mentioned my paper
I haven't tried to study the

1420
01:31:31,919 --> 01:31:33,988
I my my paper on music

1421
01:31:33,988 --> 01:31:37,592
I feel is like
you know a drop in the bucket.

1422
01:31:37,592 --> 01:31:42,463
And hopefully if I don't get around to it
someone else will.

1423
01:31:43,231 --> 01:31:46,834
But the above examples show
that arousal and emotion

1424
01:31:47,502 --> 01:31:52,640
are not the same thing
because arousal can support all emotion,

1425
01:31:53,407 --> 01:31:56,344
peer relief, hunger, satiety, whatever

1426
01:31:57,078 --> 01:32:00,882
the ones that when the competition
or then able

1427
01:32:01,549 --> 01:32:04,652
to support
compatible behaviors by motivating them.

1428
01:32:06,120 --> 01:32:06,521
And I've

1429
01:32:06,521 --> 01:32:09,857
also explained that the level of arousal
must be chosen

1430
01:32:10,525 --> 01:32:15,429
within an intermediate range
to support normal behaviors.

1431
01:32:15,429 --> 01:32:18,299
It's the kind of golden mean.

1432
01:32:18,900 --> 01:32:20,935
There's an inverted you

1433
01:32:23,271 --> 01:32:25,540
on the effects of having arousal

1434
01:32:26,040 --> 01:32:28,543
from too little or too much.

1435
01:32:28,543 --> 01:32:30,545
And if you have too little arousal,

1436
01:32:31,145 --> 01:32:33,548
you have an under arouse syndrome

1437
01:32:33,548 --> 01:32:37,451
which can support symptoms like autism.

1438
01:32:38,553 --> 01:32:41,489
And although arousal can support

1439
01:32:41,956 --> 01:32:45,293
symptoms of abuse like schizophrenia,

1440
01:32:45,626 --> 01:32:48,729
there's only one of many factors
in these diseases.

1441
01:32:49,363 --> 01:32:51,966
But I'm happy to say that subsequent

1442
01:32:52,500 --> 01:32:58,072
clinical data supported those predictions
that these two mental disorders

1443
01:32:58,072 --> 01:33:03,010
are the opposite speeds
of the arousal in gratitude.

1444
01:33:04,612 --> 01:33:06,480
So I think and you know,

1445
01:33:06,480 --> 01:33:10,718
this is very speculative because
I've never really seriously studied it.

1446
01:33:10,718 --> 01:33:13,921
And I try not to speculate, but

1447
01:33:15,823 --> 01:33:16,290
the kind

1448
01:33:16,290 --> 01:33:20,094
of arousal that
music activates are generally positive,

1449
01:33:20,094 --> 01:33:25,700
just like the arousal that activates
exploratory behaviors is positive,

1450
01:33:27,001 --> 01:33:30,338
is somehow linked

1451
01:33:30,371 --> 01:33:34,375
to a a sonic adventure, if you like.

1452
01:33:35,409 --> 01:33:38,346
There's no aversive cue
when listening to music,

1453
01:33:38,346 --> 01:33:42,883
except perhaps music played
so loud as to cause

1454
01:33:42,883 --> 01:33:46,721
a headache or your damage
or even a seizure.

1455
01:33:47,355 --> 01:33:50,057
In susceptible individuals, though

1456
01:33:50,758 --> 01:33:57,932
there's no particular reason
why it shouldn't be positive.

1457
01:33:59,567 --> 01:34:02,136
So now which question you want to ask me?

1458
01:34:04,038 --> 01:34:07,141
I think we're left
with just two other questions.

1459
01:34:07,408 --> 01:34:11,746
If you're not too tired to start with.

1460
01:34:11,746 --> 01:34:17,251
As a final point, a person noticed
that on a more philosophical.

1461
01:34:17,551 --> 01:34:22,356
Yes, the last where
until last the two questions.

1462
01:34:23,791 --> 01:34:25,559
So you want to uh

1463
01:34:25,726 --> 01:34:28,562
how do you see the future of our neurons
but our research.

1464
01:34:29,230 --> 01:34:31,132
And before that. Yes, before that

1465
01:34:32,233 --> 01:34:33,701
I just wanted to

1466
01:34:33,701 --> 01:34:38,372
ask you about the your view
about artificial consciousness.

1467
01:34:39,440 --> 01:34:40,875
Do you see.

1468
01:34:41,142 --> 01:34:43,711
I really need the first answer.

1469
01:34:43,711 --> 01:34:45,746
The answer the second question.

1470
01:34:45,746 --> 01:34:48,716
Okay. As you wish. Yes.

1471
01:34:48,716 --> 01:34:49,183
Okay.

1472
01:34:49,183 --> 01:34:51,752
So so. Yeah.

1473
01:34:51,752 --> 01:34:53,621
And how do you see.

1474
01:34:53,621 --> 01:34:56,424
Yeah, yes, it's quite fine.

1475
01:34:56,791 --> 01:35:01,595
And how do you see the future of art
and brain inspired A.I.

1476
01:35:01,595 --> 01:35:05,499
research in general in view,
what research areas

1477
01:35:05,499 --> 01:35:10,471
ought to gain more attention
than they do today?

1478
01:35:10,471 --> 01:35:13,574
So I'll give you quite a general answer,

1479
01:35:14,775 --> 01:35:17,611
but it implies

1480
01:35:18,946 --> 01:35:20,948
what I think about this.

1481
01:35:20,948 --> 01:35:25,052
So first, with a caveat, I like to say
I couldn't predict the present,

1482
01:35:25,453 --> 01:35:27,655
so I can't predict the future.

1483
01:35:28,923 --> 01:35:31,258
That being said, I believe that

1484
01:35:31,258 --> 01:35:36,230
all engineering technology
and I will increasingly embody

1485
01:35:36,731 --> 01:35:39,300
autonomous adaptive intelligence

1486
01:35:39,800 --> 01:35:42,369
in the coming century,

1487
01:35:42,369 --> 01:35:44,739
and we can already see its beginnings

1488
01:35:45,239 --> 01:35:47,274
in autonomous automobiles and

1489
01:35:47,942 --> 01:35:52,680
and increasingly autonomous controllers
on the factory floor.

1490
01:35:52,680 --> 01:35:57,151
And many people have written about it.

1491
01:35:57,151 --> 01:36:00,154
And I think art
will play a central role in this,

1492
01:36:00,154 --> 01:36:03,891
as well as other models
that are summarized in my book.

1493
01:36:03,891 --> 01:36:07,728
And that's because already in 1980,

1494
01:36:07,728 --> 01:36:10,831
I published a thought experiment

1495
01:36:11,899 --> 01:36:15,069
in the journal Psychological Review,
which was then

1496
01:36:15,069 --> 01:36:19,607
and still probably remains
the leading theory journal in psychology.

1497
01:36:20,574 --> 01:36:25,813
And you may recall that Einstein derived
both special relativity theory

1498
01:36:25,813 --> 01:36:31,018
and general relativity
from Ford experiments.

1499
01:36:31,018 --> 01:36:34,989
And let me just clarify
that my thought experiment,

1500
01:36:35,055 --> 01:36:38,459
when they describe their enormous power.

1501
01:36:39,460 --> 01:36:42,229
So my thought experiment was about how

1502
01:36:42,229 --> 01:36:48,469
any system an autonomous fleet
what about autonomous

1503
01:36:49,270 --> 01:36:52,106
correct
predictive errors in a changing world

1504
01:36:53,140 --> 01:36:57,478
and the hypotheses upon
which what experiment were derived.

1505
01:36:58,045 --> 01:37:00,681
But just a few facts that are familiar

1506
01:37:00,681 --> 01:37:03,684
to us all from daily life.

1507
01:37:04,652 --> 01:37:07,922
And they are familiar
because represent ubiquitous

1508
01:37:08,455 --> 01:37:12,393
environmental pressures on the evolution
of our brains over the millennia.

1509
01:37:13,527 --> 01:37:16,197
And when they act together,

1510
01:37:16,197 --> 01:37:19,834
I think just art is the unique outcome.

1511
01:37:19,834 --> 01:37:25,906
That's a huge claim and I turn to
the power of the thought experiment.

1512
01:37:25,906 --> 01:37:30,244
Not any personal ego trip without belief

1513
01:37:31,512 --> 01:37:33,848
in particular, nowhere in the thought

1514
01:37:33,848 --> 01:37:37,751
experiment of the word
mind or brain mentioned.

1515
01:37:38,719 --> 01:37:42,089
So if you accept that these facts

1516
01:37:42,089 --> 01:37:44,825
about the world exist, which we all do,

1517
01:37:45,826 --> 01:37:48,262
and that they're always operating on us,

1518
01:37:49,096 --> 01:37:51,398
then you have to accept the outcome.

1519
01:37:51,398 --> 01:37:55,102
If you believe in the scientific
method logic.

1520
01:37:56,136 --> 01:37:59,640
So what is a universal solution

1521
01:38:00,474 --> 01:38:02,910
to the problem of economists?

1522
01:38:02,910 --> 01:38:06,547
Error correction a change in world

1523
01:38:06,547 --> 01:38:09,250
turn another way
If you can find a mistake in the thought

1524
01:38:09,250 --> 01:38:12,419
experiment, then I think you either

1525
01:38:12,419 --> 01:38:17,324
have to believe in art,
like dynamics may be expressed

1526
01:38:17,324 --> 01:38:20,995
in life, in art
or your favorite art variant.

1527
01:38:21,729 --> 01:38:25,366
Or you have to give up your belief
in logic and the scientific method.

1528
01:38:26,400 --> 01:38:29,303
It doesn't imply that I can't be further
developed.

1529
01:38:29,904 --> 01:38:34,008
I expect a large number of scientists
to acknowledge and technologies

1530
01:38:34,508 --> 01:38:39,680
to be busy developing,
much like architecture's long instrument.

1531
01:38:41,048 --> 01:38:42,316
So maybe now we

1532
01:38:42,316 --> 01:38:44,485
can go to your philosophical note
with that.

1533
01:38:46,086 --> 01:38:48,389
Yes. Thank you so much.

1534
01:38:48,389 --> 01:38:51,392
Now, just as I mentioned,

1535
01:38:51,592 --> 01:38:55,529
I mentioned earlier,
I just wanted to ask about your view

1536
01:38:55,529 --> 01:38:58,799
about your view
on artificial consciousness.

1537
01:38:59,533 --> 01:39:03,704
Do you see the consciousness
as artificially reducible

1538
01:39:03,704 --> 01:39:08,842
or engineer able as some researchers
like Mike Soames leads?

1539
01:39:09,877 --> 01:39:14,315
Is there a fundamental distinction
between biologically conscious agent

1540
01:39:14,315 --> 01:39:17,384
and an artificial agent
with a fully simulated

1541
01:39:17,384 --> 01:39:19,753
computational model of consciousness?

1542
01:39:19,753 --> 01:39:23,824
I know it's a big, big question,
but I couldn't resist asking your opinion

1543
01:39:24,024 --> 01:39:26,226
as an authority on consciousness
modeling.

1544
01:39:27,828 --> 01:39:30,030
I'm happy to give it a shot.

1545
01:39:31,031 --> 01:39:35,703
So as I just noted, my work on art

1546
01:39:35,703 --> 01:39:38,005
suggests itself the universal

1547
01:39:39,807 --> 01:39:41,041
about how we can learn

1548
01:39:41,041 --> 01:39:44,078
to correct
predictive errors in a changing world.

1549
01:39:45,846 --> 01:39:47,982
My work also shows and

1550
01:39:47,982 --> 01:39:52,286
analysis of hierarchical resolution
of uncertainty.

1551
01:39:52,286 --> 01:39:55,622
Remember,
like how you go from sun, a noisy retina

1552
01:39:56,223 --> 01:39:59,360
to the surface representation

1553
01:39:59,360 --> 01:40:01,929
that can control looking in reaching

1554
01:40:03,364 --> 01:40:06,200
how evolution may have been driven
to discover

1555
01:40:06,767 --> 01:40:09,603
conscious states.

1556
01:40:09,603 --> 01:40:12,473
So this was a surprise to me too.

1557
01:40:13,741 --> 01:40:17,044
Conscious states were needed in order
to choose

1558
01:40:17,778 --> 01:40:19,780
that processing level.

1559
01:40:20,347 --> 01:40:23,717
The levels that computes the sufficiently

1560
01:40:23,951 --> 01:40:27,121
complete context sensitive and stable

1561
01:40:27,855 --> 01:40:31,825
representation in the case of vision,
the surface representation

1562
01:40:32,760 --> 01:40:37,664
with which to successfully plan
and act to value calls.

1563
01:40:37,664 --> 01:40:40,100
So let me make it clear.

1564
01:40:40,534 --> 01:40:45,072
So you start with a noisy rat
and you have to go up all of these stages

1565
01:40:45,072 --> 01:40:50,978
until you get sufficiently complete
surface and boundary representation

1566
01:40:50,978 --> 01:40:54,848
that you can use
to regulate successful action.

1567
01:40:55,549 --> 01:40:57,885
And if you used one of the stages,

1568
01:40:58,419 --> 01:41:00,921
it would lead to incorrect actions

1569
01:41:00,921 --> 01:41:04,691
which would kill you off
by Darwinian selection.

1570
01:41:05,325 --> 01:41:07,428
So how the hell do you know

1571
01:41:08,362 --> 01:41:12,800
where the stage is, where you can compute
this sufficiently complete,

1572
01:41:13,267 --> 01:41:17,137
extensive and stable one

1573
01:41:18,272 --> 01:41:20,007
and I

1574
01:41:20,007 --> 01:41:22,342
proposed in vision, I predicted

1575
01:41:22,910 --> 01:41:26,046
that the choice is embodied
in what I call surface

1576
01:41:26,780 --> 01:41:30,184
shroud resonance between destroyed

1577
01:41:30,217 --> 01:41:34,955
visual cortical area, the floor
and the next processing stage.

1578
01:41:35,489 --> 01:41:38,125
A stirrup while cortex of the state.

1579
01:41:38,859 --> 01:41:40,327
So it's in the poor.

1580
01:41:40,327 --> 01:41:43,497
You get this really good surface
representation

1581
01:41:45,032 --> 01:41:47,301
and then a resident

1582
01:41:47,501 --> 01:41:52,239
between the surface and spatial attention
which fits the surface,

1583
01:41:53,307 --> 01:41:56,076
that spatial attention and PPC

1584
01:41:56,743 --> 01:42:01,115
is called a shroud of the pilot
gave it that name.

1585
01:42:01,648 --> 01:42:03,684
A surface shroud resonance

1586
01:42:05,319 --> 01:42:08,355
allows you to a conscious

1587
01:42:09,123 --> 01:42:12,659
spatial attention to the surface

1588
01:42:12,659 --> 01:42:16,697
that you're going to use the controller
looking and reaching behaviors.

1589
01:42:17,297 --> 01:42:20,601
So it's a way of ensuring
you have a good enough representation

1590
01:42:20,601 --> 01:42:25,572
to control action.

1591
01:42:25,572 --> 01:42:28,609
So the shroud is

1592
01:42:28,609 --> 01:42:31,278
computed in plastic parietal cortex,

1593
01:42:31,979 --> 01:42:36,350
which is part of the dorsal
or where cortical stream

1594
01:42:37,951 --> 01:42:38,552
and the

1595
01:42:38,552 --> 01:42:42,556
shroud modulates invariant category

1596
01:42:42,556 --> 01:42:46,560
learning in the ventral
or what cortical stream?

1597
01:42:47,161 --> 01:42:50,330
I can't go into that now,
but my book discusses it.

1598
01:42:51,298 --> 01:42:55,269
The category of learning itself
in the what cortical, as I indicated,

1599
01:42:55,936 --> 01:42:59,239
is supported
by a feature category resonance.

1600
01:43:00,307 --> 01:43:03,343
And so the surface shroud resonance

1601
01:43:03,744 --> 01:43:06,346
is modulating invariant category learning

1602
01:43:07,648 --> 01:43:11,018
in the featured category resonance
with surface

1603
01:43:11,018 --> 01:43:14,421
shroud resonance also supports in

1604
01:43:15,455 --> 01:43:18,058
the future category
resonance is supporting

1605
01:43:18,458 --> 01:43:21,161
conscious recognition

1606
01:43:21,161 --> 01:43:24,298
and when they synchronize across streams

1607
01:43:25,199 --> 01:43:27,734
on a familiar object,

1608
01:43:27,734 --> 01:43:30,337
that's when you consciously see

1609
01:43:30,337 --> 01:43:33,840
something that you know about.

1610
01:43:33,840 --> 01:43:36,410
Okay, so

1611
01:43:36,677 --> 01:43:38,278
conscious states here

1612
01:43:38,278 --> 01:43:42,783
arise due to learning requirements.

1613
01:43:42,783 --> 01:43:46,053
This sort of fell out of the wash of

1614
01:43:46,753 --> 01:43:49,523
how you do invariant category learning

1615
01:43:50,791 --> 01:43:53,527
and learning in particular

1616
01:43:53,527 --> 01:43:54,895
catastrophic forgetting.

1617
01:43:54,895 --> 01:43:57,264
It's regulating
feature category resonance.

1618
01:43:58,365 --> 01:43:59,399
So given

1619
01:43:59,399 --> 01:44:03,003
that the above solutions
the computational universe so

1620
01:44:03,604 --> 01:44:06,573
in the sense I sketch

1621
01:44:06,573 --> 01:44:09,943
the self-organizing machine
that embodies them

1622
01:44:11,311 --> 01:44:14,848
should be able to support
internal representations

1623
01:44:14,881 --> 01:44:18,986
with parametric properties
mimic the state.

1624
01:44:20,721 --> 01:44:22,956
So whether such a machine

1625
01:44:22,956 --> 01:44:25,392
can experience conscious qualia

1626
01:44:26,393 --> 01:44:28,462
remains as much of a mystery

1627
01:44:28,862 --> 01:44:33,166
to machines as it does for humans.

1628
01:44:33,166 --> 01:44:36,136
And that's
because no computational theory,

1629
01:44:36,637 --> 01:44:39,740
which after all, is
just a set of equations,

1630
01:44:41,208 --> 01:44:44,478
can't do more than imitate
the dynamics of our brains.

1631
01:44:44,911 --> 01:44:47,814
Perhaps with great precision.

1632
01:44:47,814 --> 01:44:50,851
I don't have a clue why

1633
01:44:51,618 --> 01:44:53,820
the representations that

1634
01:44:54,921 --> 01:44:57,357
I've worked so hard to explain

1635
01:44:57,457 --> 01:45:00,594
huge amounts of psychophysical data
about them

1636
01:45:02,062 --> 01:45:05,699
excruciating 3D form.

1637
01:45:07,467 --> 01:45:09,736
Just go through the list

1638
01:45:09,736 --> 01:45:12,272
why they support Qualia.

1639
01:45:12,272 --> 01:45:13,507
I don't know.

1640
01:45:14,274 --> 01:45:15,842
Ask God,

1641
01:45:16,977 --> 01:45:19,980
or whatever God you choose to believe in

1642
01:45:20,013 --> 01:45:25,886
in the 21st century.

1643
01:45:25,886 --> 01:45:27,187
Thank you so much, Professor.

1644
01:45:28,188 --> 01:45:30,824
I think we have a couple of questions
in the chat

1645
01:45:30,824 --> 01:45:35,162
but we are actually approaching
our two hour limit.

1646
01:45:35,462 --> 01:45:37,764
I don't know, Daniel, if

1647
01:45:37,964 --> 01:45:40,033
it's a good place to stop or

1648
01:45:41,201 --> 01:45:42,536
whatever you say.

1649
01:45:43,170 --> 01:45:45,739
I think that's great place to stop.

1650
01:45:45,739 --> 01:45:49,443
You've given us a lot to
to think about and digest.

1651
01:45:49,810 --> 01:45:53,280
And I hope that these words are taken

1652
01:45:53,280 --> 01:45:56,083
well and paid attention to might create

1653
01:45:56,083 --> 01:45:58,719
some categories,
activate some categories.

1654
01:45:59,953 --> 01:46:03,957
But Professor Grossberg,
thanks again for this amazing livestream.

1655
01:46:03,957 --> 01:46:05,459
We really appreciate. It.

1656
01:46:05,459 --> 01:46:06,059
Appreciate it.

1657
01:46:06,059 --> 01:46:07,527
And I'm depending on younger

1658
01:46:07,527 --> 01:46:11,398
people like yourself to do
just what you said, Daniel!

1659
01:46:11,431 --> 01:46:14,701
I'm not going to be around
that much longer. So

1660
01:46:16,069 --> 01:46:18,405
I hope you have,

1661
01:46:18,405 --> 01:46:21,575
whether with my work
directly or related work,

1662
01:46:21,575 --> 01:46:25,812
you have a very fulfilling
intellectual adventure.

1663
01:46:25,812 --> 01:46:30,317
I know I've been on a wild ride
since I was 17, and

1664
01:46:31,051 --> 01:46:33,820
that's 65 years of discovery.

1665
01:46:35,222 --> 01:46:39,359
I've loved every minute of it.

1666
01:46:39,359 --> 01:46:42,496
Thank you very much! See you soon.

1667
01:46:42,496 --> 01:46:43,330
Thank you.

1668
01:46:43,530 --> 01:46:45,132
It was really pleasure meeting you.

1669
01:46:45,132 --> 01:46:47,701
Thank you. And

1670
01:46:50,103 --> 01:46:50,971
so you'll tell me

1671
01:46:50,971 --> 01:46:54,074
when I'll see this, right? - somewhere

1672
01:46:54,074 --> 01:47:26,840
on YouTube?
