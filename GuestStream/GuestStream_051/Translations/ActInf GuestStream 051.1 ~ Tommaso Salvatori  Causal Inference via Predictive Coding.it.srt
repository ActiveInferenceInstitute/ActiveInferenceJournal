1
00:00:19,020 --> 00:00:21,119
ciao e benvenuto,

2
00:00:21,119 --> 00:00:23,400
è attiva l'inferenza ospite

3
00:00:23,400 --> 00:00:28,140
numero 51.1 il 28 luglio 2023

4
00:00:28,140 --> 00:00:31,439
siamo qui con Tomaso Salvatore e

5
00:00:31,439 --> 00:00:33,840
faremo una presentazione e una

6
00:00:33,840 --> 00:00:37,020
discussione sulla recente inferenza causale del lavoro

7
00:00:37,020 --> 00:00:39,660
tramite la codifica predittiva quindi

8
00:00:39,660 --> 00:00:42,480
grazie mille per l'adesione a coloro che

9
00:00:42,480 --> 00:00:44,340
stanno guardando  dal vivo sentiti libero di scrivere

10
00:00:44,340 --> 00:00:47,520
domande nella chat dal vivo e via a

11
00:00:47,520 --> 00:00:50,399
te grazie grazie

12
00:00:50,399 --> 00:00:52,980
mille Daniel per avermi invitato

13
00:00:52,980 --> 00:00:56,039
uh sono sempre stato un grande fan del

14
00:00:56,039 --> 00:00:57,719
canale e ho guardato molti

15
00:00:57,719 --> 00:00:58,920
video

16
00:00:58,920 --> 00:01:01,379
sono abbastanza  entusiasta di essere qui e uh e di

17
00:01:01,379 --> 00:01:04,260
essere quello che parla questa volta,

18
00:01:04,260 --> 00:01:06,600
quindi parlerò di questi recenti

19
00:01:06,600 --> 00:01:08,700
preprint che ho pubblicato che è

20
00:01:08,700 --> 00:01:11,159
stato il lavoro degli ultimi due

21
00:01:11,159 --> 00:01:12,119
mesi

22
00:01:12,119 --> 00:01:15,900
ed è una collaborazione con

23
00:01:15,900 --> 00:01:18,659
with lookup  in Ketty sono in makarak

24
00:01:18,659 --> 00:01:21,600
barami Leggenda Thomas lukasiavich

25
00:01:21,600 --> 00:01:24,000
ed è fondamentalmente un lavoro congiunto tra

26
00:01:24,000 --> 00:01:26,299
versi che è la compagnia per cui lavoro

27
00:01:26,299 --> 00:01:31,680
all'Università di Oxford e uhuvian

28
00:01:31,680 --> 00:01:34,200
quindi

29
00:01:34,200 --> 00:01:36,299
durante questo discorso

30
00:01:36,299 --> 00:01:38,220
farò

31
00:01:38,220 --> 00:01:40,979
questo fondamentalmente lo schema del discorso di cui

32
00:01:40,979 --> 00:01:43,140
inizierò a parlare  cos'è la codifica predittiva

33
00:01:43,140 --> 00:01:44,520


34
00:01:44,520 --> 00:01:47,659
e le interazioni date di cosa è

35
00:01:47,659 --> 00:01:51,299
una breve introduzione storica perché

36
00:01:51,299 --> 00:01:54,060
pensi che sia importante studiare la

37
00:01:54,060 --> 00:01:56,159
codifica creativa anche ad esempio per la

38
00:01:56,159 --> 00:01:58,619
prospettiva dell'apprendimento automatico,

39
00:01:58,619 --> 00:02:00,720
quindi fornirò una

40
00:02:00,720 --> 00:02:04,560
piccola introduzione a cosa sia l'inferenza causale

41
00:02:04,560 --> 00:02:07,200
e  e una volta che avremo tutte queste

42
00:02:07,200 --> 00:02:08,880
informazioni insieme,

43
00:02:08,880 --> 00:02:12,540
discuterò uh perché ho scritto questo documento qual

44
00:02:12,540 --> 00:02:14,520
è stata fondamentalmente la domanda di ricerca che

45
00:02:14,520 --> 00:02:16,560
ha ispirato me e gli altri

46
00:02:16,560 --> 00:02:18,300
collaboratori

47
00:02:18,300 --> 00:02:21,660
e presenterò i risultati principali

48
00:02:21,660 --> 00:02:24,980
che sono come eseguire

49
00:02:24,980 --> 00:02:27,480
l'inferenza quindi l'intervento e l'

50
00:02:27,480 --> 00:02:29,340
inferenza controfattuale

51
00:02:29,340 --> 00:02:33,319
e  come apprendere le strutture causali

52
00:02:33,319 --> 00:02:35,879
da un dato set di dati utilizzando la

53
00:02:35,879 --> 00:02:37,920
codifica predittiva e poi ovviamente

54
00:02:37,920 --> 00:02:39,959
concluderò con qualche

55
00:02:39,959 --> 00:02:43,500
piccolo riassunto e qualche discussione sul

56
00:02:43,500 --> 00:02:45,840
motivo per cui credo che questo lavoro possa effettivamente avere

57
00:02:45,840 --> 00:02:49,940
un impatto e alcune direzioni future,

58
00:02:50,700 --> 00:02:53,400
quindi cos'è la codifica creativa la

59
00:02:53,400 --> 00:02:55,680
codifica creativa  è in generale famoso per

60
00:02:55,680 --> 00:02:58,440
essere un metodo di apprendimento ispirato alle neuroscienze,

61
00:02:58,440 --> 00:03:01,140
quindi quale teoria su come

62
00:03:01,140 --> 00:03:04,560
funziona l'elaborazione delle informazioni nel cervello

63
00:03:04,560 --> 00:03:05,819
e in modo

64
00:03:05,819 --> 00:03:08,400
molto formale il livello di

65
00:03:08,400 --> 00:03:10,560
codifica creativa può essere descritto come

66
00:03:10,560 --> 00:03:12,659
avere fondamentalmente una

67
00:03:12,659 --> 00:03:16,319
struttura gerarchica di neuroni nel cervello

68
00:03:16,319 --> 00:03:19,080
e tu  hanno due diverse famiglie di

69
00:03:19,080 --> 00:03:20,700
neuroni nel cervello

70
00:03:20,700 --> 00:03:23,280
la prima famiglia è quella

71
00:03:23,280 --> 00:03:24,480
incaricata di inviare

72
00:03:24,480 --> 00:03:27,659
informazioni di previsione in modo che i neuroni in uno specifico

73
00:03:27,659 --> 00:03:29,959
livello della gerarchia inviino informazioni

74
00:03:29,959 --> 00:03:33,959
e prevedano l'attività del

75
00:03:33,959 --> 00:03:35,940
livello inferiore

76
00:03:35,940 --> 00:03:38,340
e la seconda famiglia di  neuron è quello

77
00:03:38,340 --> 00:03:41,099
dei neuroni di errore e i neuroni freccia

78
00:03:41,099 --> 00:03:43,019
inviano informazioni sull'errore di previsione

79
00:03:43,019 --> 00:03:46,319
in alto nella gerarchia, quindi un livello prevede

80
00:03:46,319 --> 00:03:49,200
l'attività del livello al di sotto di

81
00:03:49,200 --> 00:03:51,659
questa attività ha una certa previsione

82
00:03:51,659 --> 00:03:54,239
come una mancata corrispondenza che si verificherebbe effettivamente

83
00:03:54,239 --> 00:03:56,220
nel livello sottostante

84
00:03:56,220 --> 00:03:57,840
e informazioni su  l'

85
00:03:57,840 --> 00:04:02,400
errore di previsione viene inviato al tasto freccia,

86
00:04:02,400 --> 00:04:04,860
tuttavia la codifica predittiva

87
00:04:04,860 --> 00:04:07,220
in realtà non è stata bruciata come

88
00:04:07,220 --> 00:04:10,799
neuroscienza come teoria dalle

89
00:04:10,799 --> 00:04:11,939
neuroscienze,

90
00:04:11,939 --> 00:04:13,860
ma in realtà è stata inizialmente sviluppata

91
00:04:13,860 --> 00:04:16,139
come metodo per l'elaborazione e la

92
00:04:16,139 --> 00:04:19,380
compressione del segnale negli anni '50, quindi il

93
00:04:19,380 --> 00:04:21,899
lavoro di  Oliver Elias, che in realtà è

94
00:04:21,899 --> 00:04:25,020
contemporaneo di uh vestiti Shannon di

95
00:04:25,020 --> 00:04:26,160
Shannon,

96
00:04:26,160 --> 00:04:27,960
si sono resi conto che una volta che abbiamo un

97
00:04:27,960 --> 00:04:30,900
predittore, un modello che

98
00:04:30,900 --> 00:04:33,600
funziona bene nel prevedere i dati,

99
00:04:33,600 --> 00:04:36,000
l'invio di messaggi sull'errore in

100
00:04:36,000 --> 00:04:37,919
quelle previsioni è in realtà molto

101
00:04:37,919 --> 00:04:41,100
più economico che inviare l'intero messaggio

102
00:04:41,100 --> 00:04:42,720
ogni  tempo

103
00:04:42,720 --> 00:04:45,240
ed è così che è nata la codifica

104
00:04:45,240 --> 00:04:47,639
piuttosto

105
00:04:47,639 --> 00:04:49,500
come meccanismo di elaborazione e compressione del segnale

106
00:04:49,500 --> 00:04:52,020
nella teoria dell'informazione negli anni

107
00:04:52,020 --> 00:04:53,639
'50, in

108
00:04:53,639 --> 00:04:57,120
realtà è stato negli anni '80 che

109
00:04:57,120 --> 00:04:59,400


110
00:04:59,400 --> 00:05:01,800
è diventato esattamente lo stesso modello utilizzato

111
00:05:01,800 --> 00:05:03,540
nelle neuroscienze

112
00:05:03,540 --> 00:05:07,500
e uh  quindi con il lavoro di Mumford o

113
00:05:07,500 --> 00:05:10,440
altri lavori, ad esempio, spiega

114
00:05:10,440 --> 00:05:12,960
come la classificazione delle informazioni di processo in modo da

115
00:05:12,960 --> 00:05:14,520
ottenere segnali di previsione dal

116
00:05:14,520 --> 00:05:17,160
mondo esterno e dobbiamo comprimere

117
00:05:17,160 --> 00:05:20,280
questa rappresentazione e uh e avere questa

118
00:05:20,280 --> 00:05:22,740
rappresentazione interna nei nostri neuroni

119
00:05:22,740 --> 00:05:25,199
e il metodo  è molto simile se non

120
00:05:25,199 --> 00:05:27,720
equivalente a quello utilizzato

121
00:05:27,720 --> 00:05:30,419
sviluppato da Elias e Oliver negli

122
00:05:30,419 --> 00:05:32,900
anni '50

123
00:05:32,940 --> 00:05:35,520
forse qual è il più grande cambiamento di paradigma

124
00:05:35,520 --> 00:05:38,100
avvenuto nel 1999

125
00:05:38,100 --> 00:05:41,400
grazie al lavoro di Ballard

126
00:05:41,400 --> 00:05:44,880
in cui hanno introdotto

127
00:05:44,880 --> 00:05:46,199
questo concetto che ho  accennato in precedenza

128
00:05:46,199 --> 00:05:48,060
sulle strutture gerarchiche nel

129
00:05:48,060 --> 00:05:51,360
cervello in cui le informazioni sulla previsione sono

130
00:05:51,360 --> 00:05:54,240
dall'alto verso il basso e le informazioni sull'errore sono dal

131
00:05:54,240 --> 00:05:55,560
basso verso l'alto

132
00:05:55,560 --> 00:05:57,660
e qualcosa che hanno fatto che non è stato

133
00:05:57,660 --> 00:05:59,759
fatto prima è che

134
00:05:59,759 --> 00:06:02,820
spiegano e sviluppano questa teoria

135
00:06:02,820 --> 00:06:05,759
non solo in Francia ma solo ma

136
00:06:05,759 --> 00:06:07,979
anche  su come funziona l'apprendimento nel

137
00:06:07,979 --> 00:06:10,139
cervello quindi è anche una teoria su come le nostre

138
00:06:10,139 --> 00:06:13,139
sinapsi vengono aggiornate

139
00:06:13,139 --> 00:06:16,080
e l'ultima grande svolta di cui

140
00:06:16,080 --> 00:06:17,940
parlerò in questa breve

141
00:06:17,940 --> 00:06:21,900
introduzione storica risale al 2003 ma

142
00:06:21,900 --> 00:06:25,380
è uh poi ha continuato ad andare avanti nel nel

143
00:06:25,380 --> 00:06:28,380
anni dopo uh grazie a Car Freeston in

144
00:06:28,380 --> 00:06:32,100
cui fondamentalmente ha preso la teoria di

145
00:06:32,100 --> 00:06:35,039
Robin Ballard e l'ha sviluppata, l'ha

146
00:06:35,039 --> 00:06:38,400
estesa e generalizzata alla

147
00:06:38,400 --> 00:06:40,919
teoria dei modelli generativi quindi

148
00:06:40,919 --> 00:06:42,720
in pratica l'affermazione principale che

149
00:06:42,720 --> 00:06:45,479
ha fatto Carfiston è che la codifica creativa è

150
00:06:45,479 --> 00:06:48,780
un  Schema di massimizzazione delle prove di

151
00:06:48,780 --> 00:06:50,340
un tipo specifico di modello generativo

152
00:06:50,340 --> 00:06:52,979
che introdurrò anche

153
00:06:52,979 --> 00:06:55,139
in seguito, in

154
00:06:55,139 --> 00:07:00,300
modo da fare un breve riassunto nei

155
00:07:00,300 --> 00:07:01,560
primi due

156
00:07:01,560 --> 00:07:03,900
tipi di angolo creativo che ho

157
00:07:03,900 --> 00:07:05,340
descritto, quindi elaborazione e

158
00:07:05,340 --> 00:07:07,020
compressione del segnale e il  l'

159
00:07:07,020 --> 00:07:09,180
elaborazione delle informazioni nella retina e nel

160
00:07:09,180 --> 00:07:11,160
cervello in generale sono metodi di inferenza

161
00:07:11,160 --> 00:07:12,300


162
00:07:12,300 --> 00:07:14,819
e il più grande

163
00:07:14,819 --> 00:07:17,819
cambiamento è stata la più grande rivoluzione che abbiamo

164
00:07:17,819 --> 00:07:21,120
avuto nel 1999, quindi diciamo che nel 21°

165
00:07:21,120 --> 00:07:23,580
secolo la codifica operativa è stata vista

166
00:07:23,580 --> 00:07:25,919
come un algoritmo di apprendimento in modo da poter prima

167
00:07:25,919 --> 00:07:29,699
comprimere le informazioni  e poi aggiorniamo tutte

168
00:07:29,699 --> 00:07:31,800
le sinapsi o tutte le variabili latenti

169
00:07:31,800 --> 00:07:34,139
che abbiamo nel nostro modello generativo per

170
00:07:34,139 --> 00:07:38,599
migliorare il nostro stesso modello generativo

171
00:07:38,759 --> 00:07:43,199
quindi diamo alcune uh definizioni

172
00:07:43,199 --> 00:07:45,000
che sono un po' più formali in

173
00:07:45,000 --> 00:07:48,479
modo che la codifica operativa possa essere vista come un

174
00:07:48,479 --> 00:07:50,220
generativo gaussiano gerarchico  modello

175
00:07:50,220 --> 00:07:53,400
quindi ecco una figura molto semplice in cui

176
00:07:53,400 --> 00:07:54,780
abbiamo questa struttura gerarchica

177
00:07:54,780 --> 00:07:58,319
che può essere profonda quanto vogliamo

178
00:07:58,319 --> 00:08:01,560
e i segnali di previsione del segnale vanno

179
00:08:01,560 --> 00:08:04,620
da una variabile latente XM a quella

180
00:08:04,620 --> 00:08:06,599
successiva e viene trasformata

181
00:08:06,599 --> 00:08:09,720
ogni volta tramite la funzione GN

182
00:08:09,720 --> 00:08:12,620
o GI

183
00:08:15,319 --> 00:08:18,180
questo è un modello generativo come ho detto e

184
00:08:18,180 --> 00:08:19,680
qual è la probabilità marginale di questo

185
00:08:19,680 --> 00:08:21,780
modello generativo beh è semplicemente la

186
00:08:21,780 --> 00:08:24,960
probabilità dell'ultimo

187
00:08:24,960 --> 00:08:27,660
puoi vedere il mio cursore sì giusto sì

188
00:08:27,660 --> 00:08:29,940
è perfetto quindi è il modello genetico

189
00:08:29,940 --> 00:08:32,700
dell'ultimo vertice è la distribuzione Scusa probabilmente

190
00:08:32,700 --> 00:08:34,979
dell'ultimo vertice per

191
00:08:34,979 --> 00:08:37,140
la distribuzione di probabilità di ogni

192
00:08:37,140 --> 00:08:40,440
altro vertice condizionata dall'attività

193
00:08:40,440 --> 00:08:43,020
del vertice prima o dalla

194
00:08:43,020 --> 00:08:45,860
variabile latente prima di

195
00:08:45,899 --> 00:08:48,240
I Ho già detto che è un

196
00:08:48,240 --> 00:08:50,399
modello generativo gaussiano il che significa che quelle

197
00:08:50,399 --> 00:08:54,260
probabilità sono in forma gaussiana

198
00:08:54,660 --> 00:08:57,120
e ogni

199
00:08:57,120 --> 00:09:00,480
funzione endos  funzione G in generale e

200
00:09:00,480 --> 00:09:02,880
uh soprattutto visto che ad esempio nel

201
00:09:02,880 --> 00:09:05,459
paper di Rambler e in tutti i paper che

202
00:09:05,459 --> 00:09:07,920
sono venuti dopo anche a causa della

203
00:09:07,920 --> 00:09:10,500
rivoluzione del deep learning quelle funzioni sono

204
00:09:10,500 --> 00:09:13,220
semplicemente Mappe lineari o

205
00:09:13,220 --> 00:09:15,120
mappe non lineari con funzioni di attivazione

206
00:09:15,120 --> 00:09:18,000
o mappe non lineari con

207
00:09:18,000 --> 00:09:22,040
funzione di attivazione e un  bias additivo

208
00:09:23,220 --> 00:09:27,180
così possiamo dare una

209
00:09:27,180 --> 00:09:28,860
definizione formale di codifica creativa e possiamo

210
00:09:28,860 --> 00:09:30,300
dire che la codifica operativa è uno

211
00:09:30,300 --> 00:09:33,480
schema di inversione per un tale modello generativo in cui la

212
00:09:33,480 --> 00:09:35,839
sua evidenza del modello è massimizzata

213
00:09:35,839 --> 00:09:38,760
minimizzando una quantità che è chiamata la

214
00:09:38,760 --> 00:09:40,920
variazione dell'energia libera

215
00:09:40,920 --> 00:09:43,740
in generale il  l'obiettivo di ogni

216
00:09:43,740 --> 00:09:46,019
modello generativo è massimizzare l'evidenza del modello ma

217
00:09:46,019 --> 00:09:48,860
questa quantità è sempre intrattabile e

218
00:09:48,860 --> 00:09:51,019
abbiamo alcune

219
00:09:51,019 --> 00:09:53,279
tecniche che ci consentono di

220
00:09:53,279 --> 00:09:55,980
approssimare la soluzione e quella

221
00:09:55,980 --> 00:09:58,500
che usiamo nella codifica creativa

222
00:09:58,500 --> 00:10:00,720
invece di minimizzare l'aberrazione dell'energia libera

223
00:10:00,720 --> 00:10:03,480
che è un  che è un limite inferiore

224
00:10:03,480 --> 00:10:06,839
dell'evidenza del modello in questo lavoro e

225
00:10:06,839 --> 00:10:09,660
in realtà in molti in molti

226
00:10:09,660 --> 00:10:11,700
altri quindi è il modo standard di farlo

227
00:10:11,700 --> 00:10:13,740
questa minimizzazione viene eseguita l'

228
00:10:13,740 --> 00:10:16,080
ingrediente discesa

229
00:10:16,080 --> 00:10:18,540
um e sì esegui abbiamo concordato in discesa

230
00:10:18,540 --> 00:10:19,980
e ci sono  in realtà altri metodi

231
00:10:19,980 --> 00:10:22,140
come la massimizzazione delle aspettative che

232
00:10:22,140 --> 00:10:23,580
è spesso equivalente

233
00:10:23,580 --> 00:10:25,140
o puoi usare altri

234
00:10:25,140 --> 00:10:26,940
algoritmi di passaggio di messaggi come la

235
00:10:26,940 --> 00:10:29,959
propagazione delle convinzioni, ad esempio,

236
00:10:30,720 --> 00:10:33,980
e andare un po 'indietro nel tempo, quindi

237
00:10:33,980 --> 00:10:35,940
dimenticando un po' i

238
00:10:35,940 --> 00:10:38,760
modelli statistici generativi

239
00:10:38,760 --> 00:10:41,360
se possiamo vedere la codifica creativa

240
00:10:41,360 --> 00:10:44,040
come intendo ho già detto un paio di

241
00:10:44,040 --> 00:10:46,200
volte come modello gerarchico

242
00:10:46,200 --> 00:10:48,420
con le attività neurali quindi con le

243
00:10:48,420 --> 00:10:50,700
variabili latenti dei neuroni che rappresentano le

244
00:10:50,700 --> 00:10:53,459
attività neurali il mittente segnala verso il basso la

245
00:10:53,459 --> 00:10:54,899
gerarchia

246
00:10:54,899 --> 00:10:57,540
e con i nodi di errore o i neuroni di errore

247
00:10:57,540 --> 00:11:01,019
il mittente segnala verso l'alto la gerarchia quindi

248
00:11:01,019 --> 00:11:03,660
questo e  le informazioni sull'errore indietro

249
00:11:03,660 --> 00:11:05,700
qual è la variazione dell'energia libera di

250
00:11:05,700 --> 00:11:08,220
questi modelli di codifica gestiti dalla classe è

251
00:11:08,220 --> 00:11:09,899
semplicemente la somma

252
00:11:09,899 --> 00:11:12,720
dell'errore quadratico medio di tutti i

253
00:11:12,720 --> 00:11:14,399
neuroni dell'errore

254
00:11:14,399 --> 00:11:18,120
quindi è la somma dell'errore

255
00:11:18,120 --> 00:11:21,980
dell'errore totale al quadrato

256
00:11:22,019 --> 00:11:24,480
e questa rappresentazione è  sarà

257
00:11:24,480 --> 00:11:27,120
utile in uh nelle diapositive successive e in

258
00:11:27,120 --> 00:11:28,740
come spiegherò come utilizzare la

259
00:11:28,740 --> 00:11:30,120
codifica creativa per modellare l'

260
00:11:30,120 --> 00:11:32,940
inferenza causale, ad esempio

261
00:11:32,940 --> 00:11:34,800
penso che la codifica predittiva sia importante

262
00:11:34,800 --> 00:11:36,240
e non lo è è un buon algoritmo da

263
00:11:36,240 --> 00:11:37,500
studiare

264
00:11:37,500 --> 00:11:39,600
bene prima di tutto come  Ho detto prima che

265
00:11:39,600 --> 00:11:41,399
ottimizza l'obiettivo corretto che è

266
00:11:41,399 --> 00:11:43,079
l'evidenza del modello o la verosimiglianza marginale

267
00:11:43,079 --> 00:11:44,339


268
00:11:44,339 --> 00:11:45,660
e

269
00:11:45,660 --> 00:11:47,700
poi lo fa ottimizzando un

270
00:11:47,700 --> 00:11:49,440
limite inferiore che è chiamato la variazione dell'energia

271
00:11:49,440 --> 00:11:52,440
libera come ho detto e il

272
00:11:52,440 --> 00:11:54,240
finale virtuale è interessante perché può essere

273
00:11:54,240 --> 00:11:57,680
scritto come  somma di due termini diversi

274
00:11:57,680 --> 00:12:00,839
che sono e ciascuno di quei termini di

275
00:12:00,839 --> 00:12:04,680
ottimizzazione come uh come impatti importanti,

276
00:12:04,680 --> 00:12:06,899
ad esempio nei compiti di apprendimento automatico

277
00:12:06,899 --> 00:12:09,060
o in generale nei compiti di apprendimento,

278
00:12:09,060 --> 00:12:12,420
quindi uno di quei termini forza la memorizzazione,

279
00:12:12,420 --> 00:12:15,440
quindi nel secondo termine fondamentalmente dice

280
00:12:15,440 --> 00:12:18,180
forza il modello  per adattare un set di dati specifico

281
00:12:18,180 --> 00:12:19,560


282
00:12:19,560 --> 00:12:21,240
e il primo termine

283
00:12:21,240 --> 00:12:23,519
costringe il modello a ridurre al minimo la

284
00:12:23,519 --> 00:12:26,040
complessità e come sappiamo, ad esempio,

285
00:12:26,040 --> 00:12:28,500
per la Teoria del rasoio dei risultati

286
00:12:28,500 --> 00:12:31,260
se abbiamo due modelli diversi

287
00:12:31,260 --> 00:12:33,000
che si comportano in modo simile su un

288
00:12:33,000 --> 00:12:35,640
set di allenamento specifico, quello che abbiamo  da ottenere

289
00:12:35,640 --> 00:12:37,380
e quello che dovrebbe

290
00:12:37,380 --> 00:12:39,899
generalizzare uh di più è quello meno

291
00:12:39,899 --> 00:12:41,160
complesso,

292
00:12:41,160 --> 00:12:44,100
quindi l'aggiornamento di un modello generativo tramite l'

293
00:12:44,100 --> 00:12:46,380
energia libera operativa ci consente sostanzialmente di

294
00:12:46,380 --> 00:12:47,779


295
00:12:47,779 --> 00:12:51,959
convergere al modello di rasoio risultato uh ottimale

296
00:12:51,959 --> 00:12:54,720
che è sia che memorizza un

297
00:12:54,720 --> 00:12:56,100
set di dati ma è anche  in grado di

298
00:12:56,100 --> 00:12:58,680
generalizzare molto bene su punti dati invisibili non visti

299
00:12:58,680 --> 00:13:00,240


300
00:13:00,240 --> 00:13:02,639
un secondo motivo per cui la codifica operativa

301
00:13:02,639 --> 00:13:08,600
è importante è che in realtà non è una

302
00:13:08,720 --> 00:13:11,760


303
00:13:11,760 --> 00:13:13,920
struttura gerarchica che non deve essere definita ma può essere

304
00:13:13,920 --> 00:13:15,959
modellata su architetture più complesse e flessibili

305
00:13:15,959 --> 00:13:18,240
come la grafica diretta

306
00:13:18,240 --> 00:13:21,540
modello con qualsiasi forma o generalizzato ancora

307
00:13:21,540 --> 00:13:23,700
di più a reti con molti cicli

308
00:13:23,700 --> 00:13:25,920
che assomigliano alla regione del cervello e il

309
00:13:25,920 --> 00:13:27,779
risultato finale nella ragione sottostante

310
00:13:27,779 --> 00:13:30,300
è che non stai imparando e

311
00:13:30,300 --> 00:13:32,339
prevedendo con un passaggio in avanti e poi

312
00:13:32,339 --> 00:13:34,260
indietro propagando l'errore ma stai

313
00:13:34,260 --> 00:13:36,600
minimizzare una funzione energetica

314
00:13:36,600 --> 00:13:38,459
e questo permette praticamente a ogni tipo di

315
00:13:38,459 --> 00:13:39,839
gerarchia di essere

316
00:13:39,839 --> 00:13:41,180
uh

317
00:13:41,180 --> 00:13:43,860
permette di andare dietro le chiavi dirette e

318
00:13:43,860 --> 00:13:46,860
permette di imparare i cicli e questo è in

319
00:13:46,860 --> 00:13:48,060
realtà abbastanza importante perché il

320
00:13:48,060 --> 00:13:50,399
cervello è pieno di cicli poiché abbiamo

321
00:13:50,399 --> 00:13:53,399
alcune informazioni da alcuni documenti recenti

322
00:13:53,399 --> 00:13:56,459
uh che sono riusciti a mappare completamente

323
00:13:56,459 --> 00:13:59,279
il cervello di alcuni animali come il

324
00:13:59,279 --> 00:14:00,420
moscerino della frutta

325
00:14:00,420 --> 00:14:03,899
il cervello è pieno di Cicli quindi ha

326
00:14:03,899 --> 00:14:06,720
senso prosciugare i nostri modelli di apprendimento automatico

327
00:14:06,720 --> 00:14:09,000
o i

328
00:14:09,000 --> 00:14:11,160
nostri modelli in generale con un algoritmo

329
00:14:11,160 --> 00:14:14,160
che ci permetta di drenare usando

330
00:14:14,160 --> 00:14:17,160
ciclici  strutture

331
00:14:17,160 --> 00:14:19,380
la terza ragione per cui la codifica operativa è

332
00:14:19,380 --> 00:14:21,240
interessante è che è stato formalmente

333
00:14:21,240 --> 00:14:23,820
dimostrato che è più robusta della

334
00:14:23,820 --> 00:14:25,139
rete neurale standard a partire dalla

335
00:14:25,139 --> 00:14:27,060
propagazione del nero, quindi se si dispone di una

336
00:14:27,060 --> 00:14:28,200
rete neurale e si desidera eseguire

337
00:14:28,200 --> 00:14:30,320
attività di classificazione, la

338
00:14:30,320 --> 00:14:34,139
codifica creativa è più robusta

339
00:14:34,139 --> 00:14:36,260
e  questo è

340
00:14:36,260 --> 00:14:38,339
interessante in attività come l'

341
00:14:38,339 --> 00:14:40,680
addestramento all'apprendimento online su piccoli set di dati o

342
00:14:40,680 --> 00:14:43,440
attività di apprendimento continuo e la teoria

343
00:14:43,440 --> 00:14:45,540
deriva fondamentalmente dal fatto che la

344
00:14:45,540 --> 00:14:48,540
codifica imperativa è stata spostata per

345
00:14:48,540 --> 00:14:50,820
approssimare la discesa del gradiente implicito

346
00:14:50,820 --> 00:14:53,339
che è una versione diversa della

347
00:14:53,339 --> 00:14:54,899
discesa del gradiente esplicita che è  la

348
00:14:54,899 --> 00:14:57,180
discesa verde standard utilizzata

349
00:14:57,180 --> 00:14:59,880
fondamentalmente in ogni singolo modello

350
00:14:59,880 --> 00:15:03,680
ed è una variazione più robusta

351
00:15:05,880 --> 00:15:08,279
penso che va bene ho fatto una codifica operativa intran piuttosto lunga

352
00:15:08,279 --> 00:15:09,779
penso che ora mi sto spostando

353
00:15:09,779 --> 00:15:11,639
sul secondo argomento che è l'inferenza causale

354
00:15:11,639 --> 00:15:13,019


355
00:15:13,019 --> 00:15:15,839
e cosa c'è  inferenza causale l'inferenza causale

356
00:15:15,839 --> 00:15:18,420
è una teoria è una

357
00:15:18,420 --> 00:15:20,339
teoria molto generale che è stata formalizzata

358
00:15:20,339 --> 00:15:23,100
maggiormente da Judy abbigliamento è sicuramente

359
00:15:23,100 --> 00:15:25,500
la persona più importante nel

360
00:15:25,500 --> 00:15:27,839
campo della causale in Francia ha scritto dei

361
00:15:27,839 --> 00:15:29,760
libri molto carini per esempio il libro di

362
00:15:29,760 --> 00:15:32,760
Y è altamente raccomandato  se vuoi

363
00:15:32,760 --> 00:15:35,220
saperne di più su questo argomento

364
00:15:35,220 --> 00:15:37,800
e fondamentalmente affronta il seguente

365
00:15:37,800 --> 00:15:38,639
problema,

366
00:15:38,639 --> 00:15:40,440
quindi supponiamo di avere una

367
00:15:40,440 --> 00:15:42,000
distribuzione di probabilità congiunta

368
00:15:42,000 --> 00:15:44,160
associata a una rete bayesiana, questo

369
00:15:44,160 --> 00:15:46,199
sarà un po 'l'

370
00:15:46,199 --> 00:15:49,260
esempio corrente per tutto il documento,

371
00:15:49,260 --> 00:15:51,839
specialmente quando  non sei con le

372
00:15:51,839 --> 00:15:54,480
reti asiatiche di questa forma

373
00:15:54,480 --> 00:15:57,660
era basato sulle reti le

374
00:15:57,660 --> 00:16:00,240
variabili all'interno possono rappresentare

375
00:16:00,240 --> 00:16:02,100
quantità diverse quindi ad esempio la nostra

376
00:16:02,100 --> 00:16:04,620
rete visiva con questa forma può

377
00:16:04,620 --> 00:16:06,899
rappresentare

378
00:16:06,899 --> 00:16:08,820
le quantità sulla destra così socio

379
00:16:08,820 --> 00:16:10,800
economico Studio statua di un

380
00:16:10,800 --> 00:16:13,079
individuo suo  livello di istruzione la sua

381
00:16:13,079 --> 00:16:16,699
intelligenza e il suo livello di reddito

382
00:16:17,100 --> 00:16:19,440
qualcosa in cui la statistica classica è

383
00:16:19,440 --> 00:16:22,920
molto brava ed è uh mentre uh l'

384
00:16:22,920 --> 00:16:25,320
applicazione più utilizzata è modellare

385
00:16:25,320 --> 00:16:28,019
osservazioni o correlazioni una

386
00:16:28,019 --> 00:16:29,279
correlazione fondamentalmente risponde alla

387
00:16:29,279 --> 00:16:32,519
domanda qual è se osserviamo

388
00:16:32,519 --> 00:16:35,579
un'altra variabile C

389
00:16:35,579 --> 00:16:37,500
quindi per esempio in  in questo caso qual è

390
00:16:37,500 --> 00:16:39,660
il livello di reddito il

391
00:16:39,660 --> 00:16:41,820
livello di reddito previsto di un individuo se

392
00:16:41,820 --> 00:16:44,339
osservo questo livello di istruzione

393
00:16:44,339 --> 00:16:48,180
e, naturalmente, se quella persona

394
00:16:48,180 --> 00:16:50,220
ha un grado di istruzione più elevato, ad

395
00:16:50,220 --> 00:16:52,500
esempio un master o un dottorato di ricerca mi aspetto

396
00:16:52,500 --> 00:16:54,360
Generale che quella persona abbia  un livello di reddito più alto

397
00:16:54,360 --> 00:16:56,040


398
00:16:56,040 --> 00:16:58,139
e questa è una correlazione,

399
00:16:58,139 --> 00:17:00,300
tuttavia a volte ci sono cose che

400
00:17:00,300 --> 00:17:03,300
sono molto difficili da osservare ma giocano un

401
00:17:03,300 --> 00:17:05,040
ruolo enorme nel determinare quelle

402
00:17:05,040 --> 00:17:06,119
quantità,

403
00:17:06,119 --> 00:17:08,220
quindi ad esempio potrebbe essere che il

404
00:17:08,220 --> 00:17:11,160
livello di reddito sia molto più

405
00:17:11,160 --> 00:17:13,380
definito dall'intelligenza di un

406
00:17:13,380 --> 00:17:15,540
persona specifica

407
00:17:15,540 --> 00:17:18,720
e forse che l'intelligenza o

408
00:17:18,720 --> 00:17:21,000
se una persona è intelligente è anche molto

409
00:17:21,000 --> 00:17:24,540
probabile che abbia un livello di istruzione superiore,

410
00:17:24,540 --> 00:17:27,540
ma comunque il vero motivo per cui

411
00:17:27,540 --> 00:17:30,120
il reddito è I è dovuto

412
00:17:30,120 --> 00:17:32,220
al QI

413
00:17:32,220 --> 00:17:34,740
e questo può essere questo non può  be Studia

414
00:17:34,740 --> 00:17:36,360
semplicemente per correlazioni e deve essere

415
00:17:36,360 --> 00:17:39,120
studiato con una tecnica più avanzata

416
00:17:39,120 --> 00:17:41,280
che si chiama intervento

417
00:17:41,280 --> 00:17:43,320
un Intervento fondamentalmente risponde alla

418
00:17:43,320 --> 00:17:46,500
domanda che cos'è D se cambiamo C in

419
00:17:46,500 --> 00:17:48,240
un valore specifico

420
00:17:48,240 --> 00:17:51,000
così per esempio possiamo prendere un

421
00:17:51,000 --> 00:17:54,660
individuo  e controlla il suo livello di reddito

422
00:17:54,660 --> 00:17:57,120
e poi cambia il suo livello di istruzione quindi

423
00:17:57,120 --> 00:17:59,220
intervieni su questo mondo

424
00:17:59,220 --> 00:18:01,080
e cambia il suo livello di istruzione senza

425
00:18:01,080 --> 00:18:03,419
toccare la sua intelligenza e vedi

426
00:18:03,419 --> 00:18:07,260
quanto cambia il suo reddito

427
00:18:07,260 --> 00:18:09,900
ad esempio se il reddito cambia molto

428
00:18:09,900 --> 00:18:12,179
significa che l'intelligenza

429
00:18:12,179 --> 00:18:14,460
non  Non gioca un ruolo importante in questo ma il

430
00:18:14,460 --> 00:18:16,799
livello di istruzione lo fa se il livello di reddito

431
00:18:16,799 --> 00:18:19,020
non cambia molto significa che forse

432
00:18:19,020 --> 00:18:20,640
c'è una variabile nascosta in questo caso

433
00:18:20,640 --> 00:18:22,860
l'intelligenza che determina il

434
00:18:22,860 --> 00:18:25,760
livello di reddito di una persona

435
00:18:25,980 --> 00:18:28,740
la terza quantità importante

436
00:18:28,740 --> 00:18:31,080
inferenza causale è quella  di controfattuali quindi,

437
00:18:31,080 --> 00:18:33,120
ad esempio, un controfattuale risponde alla

438
00:18:33,120 --> 00:18:36,720
domanda quale sarebbe e cambiamo

439
00:18:36,720 --> 00:18:39,240
C con un valore diverso nel passato

440
00:18:39,240 --> 00:18:40,679
così, ad esempio, possiamo vedere che la

441
00:18:40,679 --> 00:18:42,059
differenza tra interventi e

442
00:18:42,059 --> 00:18:45,059
controfattuali è che gli interventi

443
00:18:45,059 --> 00:18:47,820
agiscono nel futuro, quindi sto intervistando

444
00:18:47,820 --> 00:18:50,340
nel mondo ora per osservare un cambiamento nel

445
00:18:50,340 --> 00:18:53,220
futuro beh il controfattuale ci permette di

446
00:18:53,220 --> 00:18:56,039
tornare indietro nel tempo e cambiare una variabile

447
00:18:56,039 --> 00:18:59,160
indietro nel tempo e vedere come quel cambiamento

448
00:18:59,160 --> 00:19:01,320
avrebbe influenzato il mondo in cui viviamo

449
00:19:01,320 --> 00:19:02,940
ora

450
00:19:02,940 --> 00:19:06,299
e quelli sono definiti da judapple come i

451
00:19:06,299 --> 00:19:08,100
tre  livelli di inferenza causale

452
00:19:08,100 --> 00:19:09,660
correlazione è l'intervento di primo livello

453
00:19:09,660 --> 00:19:11,580
è il secondo livello in

454
00:19:11,580 --> 00:19:14,720
controfattuale è il terzo livello

455
00:19:16,020 --> 00:19:18,120
altri interventi

456
00:19:18,120 --> 00:19:20,640
li definirò più formalmente ora che ho dato

457
00:19:20,640 --> 00:19:23,760
una definizione intuitiva e sto

458
00:19:23,760 --> 00:19:25,500
usando questa notazione qui  che

459
00:19:25,500 --> 00:19:27,240
in realtà è lo stesso per tutta la

460
00:19:27,240 --> 00:19:29,640
presentazione quindi X sarà sempre

461
00:19:29,640 --> 00:19:32,820
una variabile latente s i sarà sempre

462
00:19:32,820 --> 00:19:35,340
un punto dati o un'osservazione

463
00:19:35,340 --> 00:19:38,520
e VI sarà sempre un vertice quindi

464
00:19:38,520 --> 00:19:40,860
ogni volta che vedi VI siamo solo

465
00:19:40,860 --> 00:19:42,720
interessato alla struttura del grafico,

466
00:19:42,720 --> 00:19:45,299
ad esempio,

467
00:19:45,299 --> 00:19:46,860
quindi supponiamo di avere un modello bayesiano

468
00:19:46,860 --> 00:19:50,160
che ha la stessa struttura del

469
00:19:50,160 --> 00:19:52,679
modello bayesiano che abbiamo visto nella

470
00:19:52,679 --> 00:19:54,780
diapositiva precedente

471
00:19:54,780 --> 00:19:57,840
dato che X3 è uguale a S3 questa è l'

472
00:19:57,840 --> 00:20:00,660
osservazione che facciamo le statistiche consentono

473
00:20:00,660 --> 00:20:03,360
per calcolare la probabilità o l'

474
00:20:03,360 --> 00:20:04,679
aspettativa

475
00:20:04,679 --> 00:20:07,380
di X4 che è la variabile latente

476
00:20:07,380 --> 00:20:09,240
relativa a questo vertice

477
00:20:09,240 --> 00:20:13,860
dato che X3 è uguale a S3

478
00:20:13,860 --> 00:20:15,679


479
00:20:15,679 --> 00:20:17,760
intervento esterno abbiamo bisogno di un nuovo tipo di

480
00:20:17,760 --> 00:20:19,919
notazione che si chiama operazione do

481
00:20:19,919 --> 00:20:21,179


482
00:20:21,179 --> 00:20:23,880
quindi in questo caso

483
00:20:23,880 --> 00:20:26,100
X4 vogliamo calcolare  la probabilità di

484
00:20:26,100 --> 00:20:30,000
X4 dato il fatto che interveniamo

485
00:20:30,000 --> 00:20:33,059
nella parola e cambiamo X3 West 3.

486
00:20:33,059 --> 00:20:35,580
e come lo facciamo per eseguire un

487
00:20:35,580 --> 00:20:38,400
intervento Judo Pearl ci dice che dobbiamo

488
00:20:38,400 --> 00:20:40,020


489
00:20:40,020 --> 00:20:41,880
avere un passaggio intermedio prima di

490
00:20:41,880 --> 00:20:45,059
calcolare una correlazione è prima di tutto

491
00:20:45,059 --> 00:20:46,860
dobbiamo rimuovere tutto per rimuovere tutti i

492
00:20:46,860 --> 00:20:50,160
bordi in entrata a V3,

493
00:20:50,160 --> 00:20:52,799
quindi dobbiamo studiare non questa

494
00:20:52,799 --> 00:20:55,679
rete bayesiana ma questa seconda

495
00:20:55,679 --> 00:20:58,200
e quindi a questo punto siamo autorizzati a

496
00:20:58,200 --> 00:21:00,840
calcolare una correlazione come

497
00:21:00,840 --> 00:21:03,299
facciamo normalmente

498
00:21:03,299 --> 00:21:06,500
e questo è un intervento

499
00:21:07,020 --> 00:21:09,299
controfattuale  è una generalizzazione di

500
00:21:09,299 --> 00:21:11,700
ciò che, come ho detto, è vissuto nel passato

501
00:21:11,700 --> 00:21:14,100
e stanno calcolando utilizzando

502
00:21:14,100 --> 00:21:15,419
modelli causali strutturali

503
00:21:15,419 --> 00:21:18,299
un modello causale strutturale è una tupla

504
00:21:18,299 --> 00:21:21,120
che è concettualmente simile a una

505
00:21:21,120 --> 00:21:23,460
rete bayesiana ma fondamentalmente abbiamo

506
00:21:23,460 --> 00:21:26,220
questa nuova classe di variabili in cima che

507
00:21:26,220 --> 00:21:28,580
sono le variabili non osservabili che usano

508
00:21:28,580 --> 00:21:30,960
quindi abbiamo la rete bayesiana che

509
00:21:30,960 --> 00:21:34,020
avevamo prima di X1 X2 X3 S4

510
00:21:34,020 --> 00:21:37,460
ma abbiamo anche quelle non osservabili o

511
00:21:37,460 --> 00:21:40,020
variabili che dipendono dall'ambiente non

512
00:21:40,020 --> 00:21:42,539
puoi controllarle puoi dedurle ma

513
00:21:42,539 --> 00:21:43,980
tu

514
00:21:43,980 --> 00:21:46,020
ma loro sono lì

515
00:21:46,020 --> 00:21:48,539
e

516
00:21:48,539 --> 00:21:51,360
f  è un insieme di funzioni che dipende da

517
00:21:51,360 --> 00:21:53,400
tutto

518
00:21:53,400 --> 00:21:57,299
fondamentalmente f di x di x3 dipende da X1

519
00:21:57,299 --> 00:21:58,980
perché abbiamo una freccia su x2 perché

520
00:21:58,980 --> 00:22:00,960
tu hai una freccia e dalla

521
00:22:00,960 --> 00:22:02,940
variabile non osservabile che

522
00:22:02,940 --> 00:22:05,840
influenza anche l'estremo

523
00:22:06,179 --> 00:22:09,240
quindi sì intuitivamente puoi vederci

524
00:22:09,240 --> 00:22:11,940
puoi pensare  di un modello causale strutturale

525
00:22:11,940 --> 00:22:14,159
come una rete bayesiana con quelle

526
00:22:14,159 --> 00:22:16,679
variabili non osservabili in cima e ogni

527
00:22:16,679 --> 00:22:19,500
variabile non osservabile influenza solo la

528
00:22:19,500 --> 00:22:22,020


529
00:22:22,020 --> 00:22:24,600
propria ultima variabile X, quindi ad esempio

530
00:22:24,600 --> 00:22:27,960
IU non toccherà mai X1 così come u3

531
00:22:27,960 --> 00:22:30,360
toccherà solo Q3 E1 influenzerà tutti

532
00:22:30,360 --> 00:22:34,039
X1 e  così via e così via quindi l'

533
00:22:35,039 --> 00:22:37,679
esecuzione dell'inferenza controfattuale

534
00:22:37,679 --> 00:22:39,900
risponde alla seguente domanda quindi cosa

535
00:22:39,900 --> 00:22:42,960
X4 sarebbe in X3 sarebbe stato uguale a un'altra

536
00:22:42,960 --> 00:22:46,620
variabile in una situazione di superamento tu

537
00:22:46,620 --> 00:22:49,340
estraneo

538
00:22:49,340 --> 00:22:51,840
richiede tre diversi passaggi quindi l'

539
00:22:51,840 --> 00:22:53,039
abduzione

540
00:22:53,039 --> 00:22:54,900
è il

541
00:22:54,900 --> 00:22:57,179
è il calcolo di tutte le

542
00:22:57,179 --> 00:22:59,460
variabili di sfondo quindi in questo  in questo passaggio

543
00:22:59,460 --> 00:23:01,200
vogliamo tornare indietro nel tempo e capire

544
00:23:01,200 --> 00:23:03,419
com'era l'ambiente l'ambiente non osservabile

545
00:23:03,419 --> 00:23:04,919


546
00:23:04,919 --> 00:23:08,039
in quello specifico momento nel tempo

547
00:23:08,039 --> 00:23:11,039
e lo facciamo fissando tutte le

548
00:23:11,039 --> 00:23:14,280
variabili latenti X ad alcuni dati specifici che

549
00:23:14,280 --> 00:23:16,140
abbiamo già

550
00:23:16,140 --> 00:23:18,960
ed eseguendo questi uh questo

551
00:23:18,960 --> 00:23:21,120
inferenza sull'usato

552
00:23:21,120 --> 00:23:24,240
quindi useremo la U

553
00:23:24,240 --> 00:23:26,940
per mantenere la U che abbiamo appreso ed

554
00:23:26,940 --> 00:23:28,500
eseguire un intervento

555
00:23:28,500 --> 00:23:29,880
quindi

556
00:23:29,880 --> 00:23:32,340
una controfattura può anche essere vista come

557
00:23:32,340 --> 00:23:34,980
un intervento indietro nel tempo in cui

558
00:23:34,980 --> 00:23:36,960
conosciamo l'ambiente le

559
00:23:36,960 --> 00:23:40,620
variabili d'ambiente U1 U2  e u4 in quel momento specifico

560
00:23:40,620 --> 00:23:43,039


561
00:23:43,200 --> 00:23:44,340
e

562
00:23:44,340 --> 00:23:46,679
qual è il passaggio mancante

563
00:23:46,679 --> 00:23:49,440
quindi quale sarebbe X4 in X3 sarebbe stato uguale a

564
00:23:49,440 --> 00:23:50,780
un altro

565
00:23:50,780 --> 00:23:53,280
un altro punto dati in quella

566
00:23:53,280 --> 00:23:55,980
situazione specifica ora ora possiamo calcolare una

567
00:23:55,980 --> 00:23:57,120
correlazione

568
00:23:57,120 --> 00:23:59,520
e la correlazione la facciamo sul percorso

569
00:23:59,520 --> 00:24:02,039
sul grafico  in cui abbiamo

570
00:24:02,039 --> 00:24:04,440
già eseguito un intervento utilizzando

571
00:24:04,440 --> 00:24:06,659
le variabili ambientali che abbiamo

572
00:24:06,659 --> 00:24:10,140
appreso nella fase di abduzione

573
00:24:10,140 --> 00:24:14,419
e questa è un'inferenza controfattuale

574
00:24:15,480 --> 00:24:18,000
questa è l'ultima diapositiva dell'inferenza causale

575
00:24:18,000 --> 00:24:20,159
presente introduzione

576
00:24:20,159 --> 00:24:21,720
e riguarda l'apprendimento strutturale

577
00:24:21,720 --> 00:24:23,880
fondamentalmente praticamente tutto ciò che ho detto

578
00:24:23,880 --> 00:24:27,360
finora si basa sul fatto che conosciamo

579
00:24:27,360 --> 00:24:29,700
le dipendenze causali tra

580
00:24:29,700 --> 00:24:31,500
i punti dati quindi conosciamo la struttura

581
00:24:31,500 --> 00:24:33,120
del grafico sappiamo quale variabile

582
00:24:33,120 --> 00:24:34,860
influenza quale

583
00:24:34,860 --> 00:24:37,260
conosciamo le frecce in generale

584
00:24:37,260 --> 00:24:39,659
ma in pratica questo non è

585
00:24:39,659 --> 00:24:42,900
sempre possibile quindi noi

586
00:24:42,900 --> 00:24:45,419
non abbiamo accesso al grafico causale

587
00:24:45,419 --> 00:24:47,400
la maggior parte delle volte e in realtà imparare

588
00:24:47,400 --> 00:24:49,919
il miglior grafico causale dai dati è ancora

589
00:24:49,919 --> 00:24:51,840
un problema aperto stiamo migliorando in questo stiamo

590
00:24:51,840 --> 00:24:53,880
migliorando ma

591
00:24:53,880 --> 00:24:57,299
come eseguire esattamente questo compito

592
00:24:57,299 --> 00:24:58,380
uh

593
00:24:58,380 --> 00:25:01,140
è ancora un problema aperto

594
00:25:01,140 --> 00:25:03,179
quindi, come ho detto, in pratica l'obiettivo è fare

595
00:25:03,179 --> 00:25:04,740
riferimento alle relazioni del Consiglio dai

596
00:25:04,740 --> 00:25:07,380
dati osservativi, quindi dato un set di dati

597
00:25:07,380 --> 00:25:09,780
vogliamo dedurre il grafico esattamente diretto

598
00:25:09,780 --> 00:25:12,179
che descrive la connettività

599
00:25:12,179 --> 00:25:14,460
tra il sistema e le variabili

600
00:25:14,460 --> 00:25:15,960
del set di dati

601
00:25:15,960 --> 00:25:17,700
quindi, ad esempio, qui abbiamo un esempio

602
00:25:17,700 --> 00:25:19,440
che immagino che

603
00:25:19,440 --> 00:25:22,860
tutti conosciamo grazie uh a causa

604
00:25:22,860 --> 00:25:25,080
della pandemia quindi abbiamo quelle quattro

605
00:25:25,080 --> 00:25:28,799
variabili età vaccinazione ricovero

606
00:25:28,799 --> 00:25:31,380
e e CT

607
00:25:31,380 --> 00:25:33,600
e vogliamo dedurre le

608
00:25:33,600 --> 00:25:36,059
dipendenze causali tra quelle variabili quindi

609
00:25:36,059 --> 00:25:37,980
per esempio vogliamo imparare direttamente

610
00:25:37,980 --> 00:25:40,260
dai dati che la probabilità  di una

611
00:25:40,260 --> 00:25:43,080
persona ricoverata dipende dalla

612
00:25:43,080 --> 00:25:45,419
sua età e dal fatto che sia

613
00:25:45,419 --> 00:25:49,760
vaccinata o meno e così via e così via quindi

614
00:25:51,299 --> 00:25:55,020
questa è la fine della lunga

615
00:25:55,020 --> 00:25:58,080
introduzione ma uh spero sia stato

616
00:25:58,080 --> 00:26:00,179
abbastanza chiaro e spero di aver dato come il

617
00:26:00,179 --> 00:26:02,039
nozioni di base per comprendere

618
00:26:02,039 --> 00:26:05,159
fondamentalmente i risultati del documento e

619
00:26:05,159 --> 00:26:07,740
ora possiamo passare alle domande di ricerca

620
00:26:07,740 --> 00:26:09,059
quindi le domande di ricerca sono le

621
00:26:09,059 --> 00:26:10,440
seguenti

622
00:26:10,440 --> 00:26:12,900
prima voglio vedere

623
00:26:12,900 --> 00:26:15,299
se la codifica creativa può essere utilizzata per

624
00:26:15,299 --> 00:26:16,980
eseguire l'inferenza causale

625
00:26:16,980 --> 00:26:20,100
quindi la codifica operativa finora è stata

626
00:26:20,100 --> 00:26:22,380
utilizzata solo  eseguire per calcolare le correlazioni

627
00:26:22,380 --> 00:26:25,020
nelle reti bayesiane

628
00:26:25,020 --> 00:26:27,419
e la grande domanda è: possiamo andare oltre

629
00:26:27,419 --> 00:26:29,400
la correlazione e l'intervento del modello e

630
00:26:29,400 --> 00:26:31,679
controfattuale in un modo biologicamente plausibile,

631
00:26:31,679 --> 00:26:32,760


632
00:26:32,760 --> 00:26:34,380
quindi in uh

633
00:26:34,380 --> 00:26:36,120
in un modo che sia ad esempio semplice

634
00:26:36,120 --> 00:26:39,059
intuitivo e ci permetta di giocare solo con

635
00:26:39,059 --> 00:26:40,740
i neuroni  e non toccare ad esempio

636
00:26:40,740 --> 00:26:43,740
l'enorme struttura del grafico

637
00:26:43,740 --> 00:26:46,380
e Più in pratica più specificamente

638
00:26:46,380 --> 00:26:48,299
la domanda diventa possiamo definire un

639
00:26:48,299 --> 00:26:51,000


640
00:26:51,000 --> 00:26:52,740
modello causale struttura basato sulla codifica operativa per eseguire interventi e

641
00:26:52,740 --> 00:26:55,320
controfattuali

642
00:26:55,320 --> 00:26:58,380
la seconda domanda è

643
00:26:58,380 --> 00:27:00,179
come ho detto che avere un modello personalizzato di struttura

644
00:27:00,179 --> 00:27:02,159
presuppone che noi  conoscere la struttura

645
00:27:02,159 --> 00:27:04,260
della rete di evasione,

646
00:27:04,260 --> 00:27:07,919
quindi supponiamo di avere le frecce,

647
00:27:07,919 --> 00:27:09,960
possiamo andare oltre e utilizzare le

648
00:27:09,960 --> 00:27:11,520
reti di codifica creativa per apprendere la

649
00:27:11,520 --> 00:27:14,418
struttura causale del grafico,

650
00:27:16,140 --> 00:27:18,900
in pratica dare risposte positive a

651
00:27:18,900 --> 00:27:21,120
entrambe queste domande ci consentirebbe di

652
00:27:21,120 --> 00:27:23,120
utilizzare la codifica predittiva come  un metodo di inferenza causale end-to-end

653
00:27:23,120 --> 00:27:26,039
che fondamentalmente

654
00:27:26,039 --> 00:27:28,740
prende un set di dati e ci permette di testare

655
00:27:28,740 --> 00:27:30,419
gli interventi e le

656
00:27:30,419 --> 00:27:34,820
previsioni controfattuali direttamente da questo set di dati,

657
00:27:36,840 --> 00:27:39,299
quindi affrontiamo il primo il

658
00:27:39,299 --> 00:27:40,740
primo problema quindi la

659
00:27:40,740 --> 00:27:42,419
codifica vibrativa dell'inferenza causale che è anche la

660
00:27:42,419 --> 00:27:45,120
sezione che fornisce  il titolo dell'articolo

661
00:27:45,120 --> 00:27:46,740
fondamentalmente

662
00:27:46,740 --> 00:27:48,539
e qui mostrerò come eseguire la

663
00:27:48,539 --> 00:27:50,760
codifica operativa delle correlazioni che è

664
00:27:50,760 --> 00:27:52,440
già nota

665
00:27:52,440 --> 00:27:54,419
um e come eseguire

666
00:27:54,419 --> 00:27:56,760
query interventistiche che penso

667
00:27:56,760 --> 00:28:01,140
sia la vera questione dell'articolo

668
00:28:01,140 --> 00:28:03,900
quindi ecco un causale  grafico che è il

669
00:28:03,900 --> 00:28:05,700
solito grafico che avevamo

670
00:28:05,700 --> 00:28:07,260


671
00:28:07,260 --> 00:28:09,240
ed ecco il

672
00:28:09,240 --> 00:28:11,760
modello di codifica creativa corrispondente quindi gli assi sono le

673
00:28:11,760 --> 00:28:13,980
variabili latenti e corrispondono ai

674
00:28:13,980 --> 00:28:18,000
neuroni in un modello di rete neurale

675
00:28:18,000 --> 00:28:20,760
e La freccia nera che passa dalle

676
00:28:20,760 --> 00:28:22,740
informazioni di previsione da un neurone

677
00:28:22,740 --> 00:28:25,559
a quello in basso nella gerarchia

678
00:28:25,559 --> 00:28:28,500
e ogni vertice ha anche questo

679
00:28:28,500 --> 00:28:31,140
neurone di errore che passa le informazioni in alto nella

680
00:28:31,140 --> 00:28:32,820
gerarchia, quindi l'informazione di ogni

681
00:28:32,820 --> 00:28:36,480
errore va al nodo del valore

682
00:28:36,480 --> 00:28:39,120
nella gerarchia in alto e sostanzialmente

683
00:28:39,120 --> 00:28:41,400
gli dice di correggersi per cambiare  la

684
00:28:41,400 --> 00:28:43,760
previsione

685
00:28:44,700 --> 00:28:46,559
quindi per eseguire una correlazione usando la

686
00:28:46,559 --> 00:28:48,840
codifica predittiva quello che devi fare è

687
00:28:48,840 --> 00:28:50,400
prendere un'osservazione e

688
00:28:50,400 --> 00:28:52,620
fissare semplicemente il valore di un neurone specifico

689
00:28:52,620 --> 00:28:53,820


690
00:28:53,820 --> 00:28:55,200
quindi se vuoi calcolare la

691
00:28:55,200 --> 00:28:58,740
probabilità di X4 dato X3 uguale a S3

692
00:28:58,740 --> 00:29:02,340
dobbiamo semplicemente  prendi X3 e fissalo a

693
00:29:02,340 --> 00:29:04,380
S3 in modo che non cambi

694
00:29:04,380 --> 00:29:08,159
più ed esegui una minimizzazione dell'energia

695
00:29:08,159 --> 00:29:09,720
e questo modello

696
00:29:09,720 --> 00:29:12,659
e minimizzando aggiornando l'asse

697
00:29:12,659 --> 00:29:16,380
uh tramite una minimizzazione della variazione

698
00:29:16,380 --> 00:29:18,419
dell'energia libera consente al modello di

699
00:29:18,419 --> 00:29:20,820
convergere a una soluzione  a questa domanda

700
00:29:20,820 --> 00:29:22,919
quindi la probabilità o il valore atteso

701
00:29:22,919 --> 00:29:27,179
di X4 dato X3 è uguale a 3.

702
00:29:27,179 --> 00:29:29,340
ma come faccio a eseguire un intervento ora

703
00:29:29,340 --> 00:29:31,679
senza agire sulla struttura del

704
00:29:31,679 --> 00:29:33,419
grafico

705
00:29:33,419 --> 00:29:35,640
beh questa è fondamentalmente la prima

706
00:29:35,640 --> 00:29:37,679
idea dell'articolo

707
00:29:37,679 --> 00:29:39,960
oh questo è ancora come  eseguire una

708
00:29:39,960 --> 00:29:43,260
correlazione quindi fissare S3 uguale a X3 è il

709
00:29:43,260 --> 00:29:45,600
primo passo dell'algoritmo e il

710
00:29:45,600 --> 00:29:47,220
secondo è ottenere l'asse

711
00:29:47,220 --> 00:29:50,539
minimizzando la variazione di energia libera

712
00:29:51,240 --> 00:29:53,340
un intervento che in teoria

713
00:29:53,340 --> 00:29:55,200
corrisponde a rimuovere quelle

714
00:29:55,200 --> 00:29:56,220
frecce

715
00:29:56,220 --> 00:29:57,659
e risponde alla domanda la

716
00:29:57,659 --> 00:29:59,279
probabilità  di X4

717
00:29:59,279 --> 00:30:02,399
eseguendo un intervento in modo che X3 sia

718
00:30:02,399 --> 00:30:04,860
uguale a tre la codifica imperativa può essere

719
00:30:04,860 --> 00:30:07,080
eseguita come segue

720
00:30:07,080 --> 00:30:09,840
quindi scriverò qui l'algoritmo

721
00:30:09,840 --> 00:30:13,140
così prima come in una correlazione fissi S3

722
00:30:13,140 --> 00:30:17,039
uguale uguale a iFix X3 uguale

723
00:30:17,039 --> 00:30:18,720
all'osservazione che ottieni

724
00:30:18,720 --> 00:30:21,299
allora questo è il passo importante

725
00:30:21,299 --> 00:30:24,059
devi intervenire non più sul grafico

726
00:30:24,059 --> 00:30:26,700
ma sull'errore di predizione e

727
00:30:26,700 --> 00:30:28,980
correggerlo uguale a zero

728
00:30:28,980 --> 00:30:31,020
avere un errore di predizione uguale a zero

729
00:30:31,020 --> 00:30:32,480
fondamentalmente

730
00:30:32,480 --> 00:30:36,179
fa sì che uh invii informazioni prive di significato

731
00:30:36,179 --> 00:30:38,460
in alto nella gerarchia o in realtà

732
00:30:38,460 --> 00:30:40,200
non invii informazioni del  gerarchia

733
00:30:40,200 --> 00:30:41,880
perché fondamentalmente ti dice che la

734
00:30:41,880 --> 00:30:44,659
previsione è sempre corretta

735
00:30:44,659 --> 00:30:48,120
e il terzo passo è come abbiamo fatto

736
00:30:48,120 --> 00:30:50,220
prima per aggiornare l'asse l'

737
00:30:50,220 --> 00:30:52,919
asse non vincolato o X1 X2 X4

738
00:30:52,919 --> 00:30:55,679
riducendo al minimo la variazione di energia libera

739
00:30:55,679 --> 00:30:59,039
come mostrerò ora o sperimentalmente

740
00:30:59,039 --> 00:31:00,840
semplicemente facendo  questo piccolo trucco di

741
00:31:00,840 --> 00:31:02,399
impostare un errore di predizione

742
00:31:02,399 --> 00:31:05,120
pari a zero

743
00:31:05,640 --> 00:31:08,220
ci impedisce di agire effettivamente sulla

744
00:31:08,220 --> 00:31:10,320
struttura del grafico

745
00:31:10,320 --> 00:31:13,620
come fa la teoria del do calcolo e di

746
00:31:13,620 --> 00:31:16,919
inferire le uh mancanti delle variabili dopo

747
00:31:16,919 --> 00:31:19,140
un intervento semplicemente eseguendo

748
00:31:19,140 --> 00:31:22,640
aberrazione della minimizzazione dell'energia libera

749
00:31:24,659 --> 00:31:26,580
che dire dell'inferenza controfattuale l'

750
00:31:26,580 --> 00:31:28,080
inferenza controfattuale è in realtà

751
00:31:28,080 --> 00:31:30,539
facile una volta che abbiamo

752
00:31:30,539 --> 00:31:34,740
definito uh come eseguire un intervento

753
00:31:34,740 --> 00:31:36,539
e questo perché, come abbiamo visto in precedenza,

754
00:31:36,539 --> 00:31:38,640
eseguire una controfattuale simile

755
00:31:38,640 --> 00:31:40,380
all'esecuzione di un intervento in una

756
00:31:40,380 --> 00:31:44,360
situazione passata dopo aver dedotto il

757
00:31:44,360 --> 00:31:48,120
non osservabili le variabili non osservabili

758
00:31:48,120 --> 00:31:49,620
così

759
00:31:49,620 --> 00:31:51,480
come puoi vedere nella trama che ho mostrato

760
00:31:51,480 --> 00:31:53,520
in precedenza sui passaggi di azione e

761
00:31:53,520 --> 00:31:56,039
previsione del rapimento i passaggi di azione e

762
00:31:56,039 --> 00:31:58,320
previsione non avevano quelle

763
00:31:58,320 --> 00:31:59,640
due frecce

764
00:31:59,640 --> 00:32:02,580
che sono state rimosse una bella codifica

765
00:32:02,580 --> 00:32:06,299
ci permette di mantenere le frecce di questo uh

766
00:32:06,299 --> 00:32:08,279
in  il grafico

767
00:32:08,279 --> 00:32:11,340
e ed eseguire controfattuali

768
00:32:11,340 --> 00:32:13,380
semplicemente eseguendo un passo di abduzione come è stato

769
00:32:13,380 --> 00:32:14,640
fatto in precedenza

770
00:32:14,640 --> 00:32:16,679
un passo di azione in cui

771
00:32:16,679 --> 00:32:18,600
eseguiamo semplicemente un intervento sul singolo

772
00:32:18,600 --> 00:32:21,240
nodo quindi fissiamo il valore del nodo e impostiamo

773
00:32:21,240 --> 00:32:24,240
l'errore a zero

774
00:32:24,240 --> 00:32:26,399
ed eseguiamo la minimizzazione dell'energia a

775
00:32:26,399 --> 00:32:27,960
ridurre al minimo la durata dell'energia libera per

776
00:32:27,960 --> 00:32:30,679
calcolare la previsione,

777
00:32:32,399 --> 00:32:36,299
quindi penso che questo sia un metodo semplice ed

778
00:32:36,299 --> 00:32:39,840
elegante per eseguire interventi

779
00:32:39,840 --> 00:32:42,899
e controfattuali e uh

780
00:32:42,899 --> 00:32:44,880
sì, quindi penso che la cosa che dobbiamo

781
00:32:44,880 --> 00:32:46,500
mostrare ora sia se funziona nella pratica

782
00:32:46,500 --> 00:32:48,720
o meno e noi  ho un paio di

783
00:32:48,720 --> 00:32:49,919
esperimenti

784
00:32:49,919 --> 00:32:52,440
e ora ti mostrerò due

785
00:32:52,440 --> 00:32:54,240
diversi esperimenti il ​​primo è

786
00:32:54,240 --> 00:32:57,179
semplicemente un esperimento di dimostrazione del concetto

787
00:32:57,179 --> 00:33:01,020
che mostra che nella codifica operativa

788
00:33:01,020 --> 00:33:02,480
è in grado di eseguire

789
00:33:02,480 --> 00:33:06,120
interventi e controfattuali

790
00:33:06,120 --> 00:33:08,700
e il secondo mostra effettivamente una

791
00:33:08,700 --> 00:33:11,220
semplice applicazione  in che modo

792
00:33:11,220 --> 00:33:13,440
le query interventistiche possono essere utilizzate per migliorare le

793
00:33:13,440 --> 00:33:16,260
prestazioni dei compiti di classificazione su un

794
00:33:16,260 --> 00:33:18,360
tipo specifico di reti di codifica operativa

795
00:33:18,360 --> 00:33:20,940
che è quella di un

796
00:33:20,940 --> 00:33:22,080
modello completamente connesso,

797
00:33:22,080 --> 00:33:24,659
iniziamo dal primo,

798
00:33:24,659 --> 00:33:27,679
quindi come facciamo questo compito, quindi dato un

799
00:33:27,679 --> 00:33:30,360
modello strutturale del Consiglio

800
00:33:30,360 --> 00:33:33,360
noi  generiamo dati di addestramento e li usiamo

801
00:33:33,360 --> 00:33:35,760
per apprendere i pesi in modo da apprendere le

802
00:33:35,760 --> 00:33:39,480
funzioni dei modelli Kaza strutturali

803
00:33:39,480 --> 00:33:42,779
e quindi generiamo dati di test di test

804
00:33:42,779 --> 00:33:44,399
sia per query interventistiche che di

805
00:33:44,399 --> 00:33:46,080
controfazione

806
00:33:46,080 --> 00:33:48,000
e mostriamo se siamo in grado di

807
00:33:48,000 --> 00:33:51,360
convergere ai dati di test corretti  utilizzando la

808
00:33:51,360 --> 00:33:53,340
codifica creativa

809
00:33:53,340 --> 00:33:54,779


810
00:33:54,779 --> 00:33:57,240
e, ad esempio, qui uh in quei due

811
00:33:57,240 --> 00:33:58,860
grafici rappresentano l'

812
00:33:58,860 --> 00:34:00,600
intervento interventistico e le query controfattuali

813
00:34:00,600 --> 00:34:03,539
di questo grafico specifico che è il

814
00:34:03,539 --> 00:34:05,880
grafico del bias a farfalla che è un grafico

815
00:34:05,880 --> 00:34:08,280
che viene spesso utilizzato in uh per verificare

816
00:34:08,280 --> 00:34:10,859
se un'inferenza causale se

817
00:34:10,859 --> 00:34:12,179
l'intervento e le

818
00:34:12,179 --> 00:34:15,540
tecniche controfattuali  il lavoro è così semplice ma

819
00:34:15,540 --> 00:34:18,000
nel documento puoi trovare molti

820
00:34:18,000 --> 00:34:20,760
grafici diversi ma in generale quei

821
00:34:20,760 --> 00:34:22,800
due grafici quei due grafici mostrano che il

822
00:34:22,800 --> 00:34:26,940
metodo funziona mostra uno spettacolo che l'

823
00:34:26,940 --> 00:34:27,918


824
00:34:27,918 --> 00:34:32,219
errore assoluto medio tra le

825
00:34:32,219 --> 00:34:33,960
quantità controfattuali interventistiche

826
00:34:33,960 --> 00:34:37,399
noi noi  compute e le quantità interventistiche e

827
00:34:37,399 --> 00:34:39,780
controfattuali del

828
00:34:39,780 --> 00:34:41,460
grafico originale

829
00:34:41,460 --> 00:34:43,800
sono vicine l'una all'altra quindi l'errore è

830
00:34:43,800 --> 00:34:45,800
piuttosto piccolo

831
00:34:45,800 --> 00:34:49,139
il secondo esperimento è uh è fondamentalmente

832
00:34:49,139 --> 00:34:51,239
un'estensione di un esperimento che ho proposto

833
00:34:51,239 --> 00:34:54,540
in un articolo precedente che è l'

834
00:34:54,540 --> 00:34:56,460
apprendimento su topologie di grafi arbitrari

835
00:34:56,460 --> 00:34:59,040
che io che ho scritto l'anno scorso

836
00:34:59,040 --> 00:35:01,080
in quel documento

837
00:35:01,080 --> 00:35:04,200
fondamentalmente propongo questo tipo di

838
00:35:04,200 --> 00:35:06,060
rete come prova del concetto che è una

839
00:35:06,060 --> 00:35:08,160
rete completamente connessa che è in

840
00:35:08,160 --> 00:35:11,579
generale la peggiore rete neurale che puoi

841
00:35:11,579 --> 00:35:13,500
avere per eseguire

842
00:35:13,500 --> 00:35:15,960
esperimenti di apprendimento automatico perché

843
00:35:15,960 --> 00:35:20,520
ci ha dato un fisso  insieme di neuroni

844
00:35:20,520 --> 00:35:23,660
in pratica

845
00:35:23,760 --> 00:35:26,400
ogni coppia di neuroni è

846
00:35:26,400 --> 00:35:28,680
collegata da due diverse sinapsi quindi

847
00:35:28,680 --> 00:35:31,200
è il massimo è il modello con

848
00:35:31,200 --> 00:35:33,359
la massima complessità possibile in

849
00:35:33,359 --> 00:35:34,619
generale

850
00:35:34,619 --> 00:35:36,300
la cosa buona è che poiché hai

851
00:35:36,300 --> 00:35:37,859
molti cicli il modello è estremamente

852
00:35:37,859 --> 00:35:39,599
flessibile  nel senso che puoi

853
00:35:39,599 --> 00:35:42,480
addestrarlo ad esempio su un'immagine tritata e

854
00:35:42,480 --> 00:35:45,359
su un punto dati e sulla sua etichetta ma

855
00:35:45,359 --> 00:35:47,400
poi il modo in cui puoi interrogarlo grazie

856
00:35:47,400 --> 00:35:50,640
alle informazioni che tornano indietro è uh puoi

857
00:35:50,640 --> 00:35:52,140
interrogare in molti modi diversi quindi

858
00:35:52,140 --> 00:35:54,060
puoi formare attività di classificazione in cui

859
00:35:54,060 --> 00:35:55,980
fornisci un'immagine ed esegui la

860
00:35:55,980 --> 00:35:57,480
minimizzazione dell'energia e ottieni l'etichetta

861
00:35:57,480 --> 00:35:59,400
ma puoi anche, ad esempio, eseguire

862
00:35:59,400 --> 00:36:01,320
attività di generazione in cui dai

863
00:36:01,320 --> 00:36:03,060
all'etichetta eseguire la minimizzazione dell'energia e

864
00:36:03,060 --> 00:36:05,220
ottenere l'immagine che puoi eseguire ad

865
00:36:05,220 --> 00:36:06,960
esempio image  completamento che dai

866
00:36:06,960 --> 00:36:10,260
metà dell'immagine e converge e e

867
00:36:10,260 --> 00:36:12,119
converge lascia che il modello si converta nella

868
00:36:12,119 --> 00:36:14,400
seconda metà e così via e così via quindi è

869
00:36:14,400 --> 00:36:16,440
fondamentalmente un modello che apprende

870
00:36:16,440 --> 00:36:19,619
le statistiche del set di dati nella sua

871
00:36:19,619 --> 00:36:21,900
interezza senza essere focalizzato sulla

872
00:36:21,900 --> 00:36:25,079
classificazione o  generazione in generale

873
00:36:25,079 --> 00:36:27,900
quindi questa flessibilità è grande

874
00:36:27,900 --> 00:36:31,260
il problema è che per questo

875
00:36:31,260 --> 00:36:34,140
motivo ogni singola attività non funziona bene

876
00:36:34,140 --> 00:36:35,820
quindi puoi fare molte cose diverse

877
00:36:35,820 --> 00:36:38,579
ma nessuna di esse è fatta bene

878
00:36:38,579 --> 00:36:39,960
e

879
00:36:39,960 --> 00:36:42,480
qui voglio mostrare come usare  Le

880
00:36:42,480 --> 00:36:44,099
query interventistiche anziché le

881
00:36:44,099 --> 00:36:46,740
query correlazionali uh standard o le

882
00:36:46,740 --> 00:36:48,119
query condizionali

883
00:36:48,119 --> 00:36:49,980
migliorano leggermente i risultati di tali

884
00:36:49,980 --> 00:36:51,960
attività di classificazione,

885
00:36:51,960 --> 00:36:54,000
quindi quali sono le ragioni congettive di

886
00:36:54,000 --> 00:36:57,599
queste uh l'accuratezza del test

887
00:36:57,599 --> 00:37:01,079
su tali attività non è così elevata la

888
00:37:01,079 --> 00:37:03,180
prima le due ragioni sono che il modello

889
00:37:03,180 --> 00:37:05,640
è distratto  nel correggere ogni singolo

890
00:37:05,640 --> 00:37:07,920
uh ogni singolo errore quindi in pratica

891
00:37:07,920 --> 00:37:09,420
presenti un'immagine e vorresti

892
00:37:09,420 --> 00:37:11,579
ottenere un'etichetta ma il modello si sta effettivamente

893
00:37:11,579 --> 00:37:13,859
aggiornando per prevedere anche l'

894
00:37:13,859 --> 00:37:16,320
errore nelle immagini

895
00:37:16,320 --> 00:37:18,480
e la seconda ragione che è quella che ho

896
00:37:18,480 --> 00:37:21,119
detto è che il  la struttura è troppo

897
00:37:21,119 --> 00:37:24,540
complessa quindi di nuovo da un risultato

898
00:37:24,540 --> 00:37:27,079
raisin Occam razor

899
00:37:27,079 --> 00:37:28,800
argomentazione

900
00:37:28,800 --> 00:37:30,720
questo è il peggior modello che puoi avere quindi

901
00:37:30,720 --> 00:37:32,160
ogni volta che hai un modello che si adatta a un

902
00:37:32,160 --> 00:37:33,960
set di dati quel modello sarà meno

903
00:37:33,960 --> 00:37:35,579
complesso di questo che sta andando  da

904
00:37:35,579 --> 00:37:37,560
preferire

905
00:37:37,560 --> 00:37:40,560
ma in generale uh solo per studiarlo

906
00:37:40,560 --> 00:37:41,400


907
00:37:41,400 --> 00:37:43,380
l'idea è di poter interrogare in questo modello gli

908
00:37:43,380 --> 00:37:44,820
interventi da utilizzare per migliorare le

909
00:37:44,820 --> 00:37:46,859
prestazioni di uh di quei

910
00:37:46,859 --> 00:37:48,599
modelli completamente connessi

911
00:37:48,599 --> 00:37:51,060
beh la risposta è sì

912
00:37:51,060 --> 00:37:53,160
quindi ecco come eseguo le

913
00:37:53,160 --> 00:37:55,619
query interventistiche così  Presento un'immagine alla

914
00:37:55,619 --> 00:37:56,640
rete

915
00:37:56,640 --> 00:37:59,460
correggo l'errore dei pixel in modo che sia

916
00:37:59,460 --> 00:38:01,560
uguale a zero in modo che questo errore non venga

917
00:38:01,560 --> 00:38:03,180
propagato nella rete

918
00:38:03,180 --> 00:38:05,700
e quindi calcolo l'etichetta

919
00:38:05,700 --> 00:38:08,400
e come puoi vedere la precisione migliora

920
00:38:08,400 --> 00:38:11,339
ad esempio da 89 utilizzando il

921
00:38:11,339 --> 00:38:13,380
metodo di query standard delle reti di codifica creativa

922
00:38:13,380 --> 00:38:16,800
a 92 che è l'accuratezza dopo

923
00:38:16,800 --> 00:38:19,020
l'intervento e lo stesso accade

924
00:38:19,020 --> 00:38:21,540
per i mezzi di moda

925
00:38:21,540 --> 00:38:24,420
e penso che un critico molto legittimo

926
00:38:24,420 --> 00:38:26,940
che probabilmente tutti penserebbero

927
00:38:26,940 --> 00:38:28,920
quando vedendo quelle trame è che va bene che

928
00:38:28,920 --> 00:38:32,099
migliori i mezzi da 89  a 92 fa

929
00:38:32,099 --> 00:38:36,180
ancora schifo fondamentalmente e sì, è vero

930
00:38:36,180 --> 00:38:38,400
e in realtà nelle diapositive successive

931
00:38:38,400 --> 00:38:40,619
mostrerò come agire sulla

932
00:38:40,619 --> 00:38:42,660
struttura di questo uh di questo

933
00:38:42,660 --> 00:38:43,859
modello completamente connesso

934
00:38:43,859 --> 00:38:46,500
migliorerà ancora di più i risultati fino

935
00:38:46,500 --> 00:38:48,480
al punto in cui hanno raggiunto il  una performance ricca e uh

936
00:38:48,480 --> 00:38:50,820
che non è nemmeno vicina alla

937
00:38:50,820 --> 00:38:52,560
performance allo stato dell'arte ovviamente

938
00:38:52,560 --> 00:38:55,320
ma è ancora all'altezza ma non è all'altezza di un

939
00:38:55,320 --> 00:38:57,380
livello che diventa sostanzialmente accettabile

940
00:38:57,380 --> 00:39:01,760
Indagine di Kenworth che indaga

941
00:39:02,040 --> 00:39:04,980
quindi sì, quindi questa è stata la parte

942
00:39:04,980 --> 00:39:08,400
sull'inferenza causale usando la codifica creativa

943
00:39:08,400 --> 00:39:10,920
e immagino di riassumere posso dire che

944
00:39:10,920 --> 00:39:15,060
uh la parte interessante di questo uh dei

945
00:39:15,060 --> 00:39:17,640
risultati che ho appena mostrato è

946
00:39:17,640 --> 00:39:19,859
che ho mostrato che la codifica operativa è in grado

947
00:39:19,859 --> 00:39:22,560
di eseguire interventi in modo molto semplice

948
00:39:22,560 --> 00:39:24,780
e intuitivo perché non devi

949
00:39:24,780 --> 00:39:26,280
agire  la struttura del vecchio grafico

950
00:39:26,280 --> 00:39:28,740
a volte le funzioni di quelle funzioni

951
00:39:28,740 --> 00:39:31,079
non sono più disponibili e

952
00:39:31,079 --> 00:39:34,020
così via ma devi semplicemente devi

953
00:39:34,020 --> 00:39:36,140
semplicemente

954
00:39:36,140 --> 00:39:39,780
intervenire su un singolo neurone studia l'

955
00:39:39,780 --> 00:39:41,640
errore di previsione a zero

956
00:39:41,640 --> 00:39:44,220
ed esegui uh un processo di minimizzazione dell'energia

957
00:39:44,220 --> 00:39:46,619


958
00:39:46,619 --> 00:39:49,200
e questi estesi sono  ci ha permesso di

959
00:39:49,200 --> 00:39:51,240
definire modelli causali strutturali basati sulla codifica creativa

960
00:39:51,240 --> 00:39:52,920


961
00:39:52,920 --> 00:39:54,920
Ora passiamo alla seconda

962
00:39:54,920 --> 00:39:57,900
parte del lavoro che riguarda l'

963
00:39:57,900 --> 00:40:01,700
apprendimento della struttura strutturale,

964
00:40:02,000 --> 00:40:05,099
quindi l'apprendimento delle istruzioni, come ho detto,

965
00:40:05,099 --> 00:40:07,260
si occupa del problema dell'apprendimento della

966
00:40:07,260 --> 00:40:09,720
struttura causale del modello

967
00:40:09,720 --> 00:40:11,880
dai dati osservativi,

968
00:40:11,880 --> 00:40:13,800
questo è  in realtà nessun problema che

969
00:40:13,800 --> 00:40:17,760
esiste da decenni

970
00:40:17,760 --> 00:40:21,359
ed è sempre stato fino a un paio

971
00:40:21,359 --> 00:40:24,000
di anni fa affrontato utilizzando

972
00:40:24,000 --> 00:40:25,560
metodi di ricerca combinatoria

973
00:40:25,560 --> 00:40:26,640
il problema con quei

974
00:40:26,640 --> 00:40:29,280
metodi di ricerca di comunità è che la loro

975
00:40:29,280 --> 00:40:32,880
complessità raddoppia in modo esponenziale

976
00:40:32,880 --> 00:40:34,740
quindi non appena i dati diventano

977
00:40:34,740 --> 00:40:36,780
multi-  dimensionale e

978
00:40:36,780 --> 00:40:39,920
il grafico Bison che vuoi imparare

979
00:40:39,920 --> 00:40:42,300
cresce di dimensioni imparandolo

980
00:40:42,300 --> 00:40:46,680
è incredibilmente lento

981
00:40:46,680 --> 00:40:48,780
la nuova soluzione che è uscita in realtà

982
00:40:48,780 --> 00:40:51,000
un paio di anni fa in un nuovo giornale

983
00:40:51,000 --> 00:40:53,540
del 2018

984
00:40:53,839 --> 00:40:55,920
mostra che è possibile imparare effettivamente

985
00:40:55,920 --> 00:40:57,900
questa struttura non usando un

986
00:40:57,900 --> 00:40:59,940
metodo di ricerca combinatore ma usando

987
00:40:59,940 --> 00:41:01,619
un metodo basato sul gradiente

988
00:41:01,619 --> 00:41:05,280
e questo era fondamentalmente questo

989
00:41:05,280 --> 00:41:07,320
problema esperto in generale perché ora

990
00:41:07,320 --> 00:41:08,820
puoi semplicemente

991
00:41:08,820 --> 00:41:10,980
avere un precedente sui parametri che è

992
00:41:10,980 --> 00:41:12,420
lo scopo prioritario che

993
00:41:12,420 --> 00:41:14,700
definirò un po 'meglio  in questa

994
00:41:14,700 --> 00:41:15,599
diapositiva

995
00:41:15,599 --> 00:41:18,180
esegui la discesa del gradiente e anche se

996
00:41:18,180 --> 00:41:19,740
hai un modello che è doppio triplo la

997
00:41:19,740 --> 00:41:20,820
dimensione

998
00:41:20,820 --> 00:41:23,640
è uh l'algoritmo è ancora incredibilmente

999
00:41:23,640 --> 00:41:25,440
veloce

1000
00:41:25,440 --> 00:41:28,260
e per questo motivo questo documento è un

1001
00:41:28,260 --> 00:41:31,200
questo è sì, penso che sia un po 'nuovo

1002
00:41:31,200 --> 00:41:33,180
e penso che abbia già in giro  600

1003
00:41:33,180 --> 00:41:35,099
citazioni o cose o cose del genere

1004
00:41:35,099 --> 00:41:37,140
e ogni documento che sto vedendo ora

1005
00:41:37,140 --> 00:41:38,720
sulla consulenza agli amici e sulla

1006
00:41:38,720 --> 00:41:42,000
struttura di apprendimento del grafico usa il loro metodo,

1007
00:41:42,000 --> 00:41:44,820
cambia solo un po '

1008
00:41:44,820 --> 00:41:46,980
trovano metodi di inferenza più veloci o leggermente migliori,

1009
00:41:46,980 --> 00:41:49,440
ma usano ancora tutti

1010
00:41:49,440 --> 00:41:53,760
il  prima di questo documento definito e lo

1011
00:41:53,760 --> 00:41:56,460
faccio anche io e lo facciamo anche noi

1012
00:41:56,460 --> 00:41:58,859
quindi qui troveremo una nuova quantità

1013
00:41:58,859 --> 00:42:01,500
che è l'agenzia Matrix l'agenzia

1014
00:42:01,500 --> 00:42:03,480
Matrix è semplicemente una matrice che codifica

1015
00:42:03,480 --> 00:42:06,359
le connessioni del modello quindi è una

1016
00:42:06,359 --> 00:42:08,520
matrice binaria e

1017
00:42:08,520 --> 00:42:10,920
in generale  è una matrice binaria quindi,

1018
00:42:10,920 --> 00:42:12,180
ovviamente, quando esegui

1019
00:42:12,180 --> 00:42:14,880
l'ottimizzazione basata sul gradiente, la rendi continua

1020
00:42:14,880 --> 00:42:16,800
e quindi a un certo punto hai una soglia

1021
00:42:16,800 --> 00:42:19,800
che sostanzialmente uccide un bordo o o

1022
00:42:19,800 --> 00:42:21,480
la imposti su uno

1023
00:42:21,480 --> 00:42:27,780
e M3 IJ è uguale a uno se

1024
00:42:27,780 --> 00:42:30,540
abbiamo  se il grafo bayesiano come bordo

1025
00:42:30,540 --> 00:42:35,040
dal vertice I al vertice J o zero

1026
00:42:35,040 --> 00:42:37,380
altrimenti, ad esempio questa agenzia

1027
00:42:37,380 --> 00:42:39,540
Matrix qui rappresenta la

1028
00:42:39,540 --> 00:42:42,780
struttura di connettività di questa rete visiva

1029
00:42:42,780 --> 00:42:44,040
e

1030
00:42:44,040 --> 00:42:46,079
fondamentalmente questo metodo

1031
00:42:46,079 --> 00:42:48,780
affronta due problemi che vogliamo

1032
00:42:48,780 --> 00:42:51,000
su questi uh sull'apprendimento della

1033
00:42:51,000 --> 00:42:53,460
struttura  dell'equazione Rete l'

1034
00:42:53,460 --> 00:42:54,780
idea è che partiamo da un

1035
00:42:54,780 --> 00:42:57,200
modello completamente connesso che

1036
00:42:57,200 --> 00:43:00,240
concettualmente è uh è simile in realtà

1037
00:43:00,240 --> 00:43:02,220
è equivalente alla rete di codifica operativa che ho

1038
00:43:02,220 --> 00:43:04,020
definito in precedenza che è completamente

1039
00:43:04,020 --> 00:43:06,480
connesso quindi hai molti

1040
00:43:06,480 --> 00:43:08,640
vertici e ogni coppia di vertici  è

1041
00:43:08,640 --> 00:43:10,920
connesso da uh da due diversi bordi

1042
00:43:10,920 --> 00:43:13,319
e vuoi semplicemente sfoltire quelli

1043
00:43:13,319 --> 00:43:15,780
che non sono necessari

1044
00:43:15,780 --> 00:43:18,540
così può essere visto come un metodo che

1045
00:43:18,540 --> 00:43:20,819
esegue la riduzione del modello parti da

1046
00:43:20,819 --> 00:43:22,020
un modello grande e vuoi renderlo

1047
00:43:22,020 --> 00:43:22,800
piccolo

1048
00:43:22,800 --> 00:43:25,800
quindi cosa c'è  il primo ingrediente per

1049
00:43:25,800 --> 00:43:28,260
ridurre bene i modelli è ovviamente la città sparsa

1050
00:43:28,260 --> 00:43:29,220


1051
00:43:29,220 --> 00:43:31,619
e qual è il precedente che tutti usano

1052
00:43:31,619 --> 00:43:33,839
per rendere un modello più sparso è il

1053
00:43:33,839 --> 00:43:36,480
precedente di LaPlace che in machine learning

1054
00:43:36,480 --> 00:43:38,880
è semplicemente noto come norma L1

1055
00:43:38,880 --> 00:43:40,920
che qui è definita

1056
00:43:40,920 --> 00:43:43,980
la soluzione che il  questo documento che ho

1057
00:43:43,980 --> 00:43:46,740
citato in precedenza proponeva di aggiungere il

1058
00:43:46,740 --> 00:43:49,319
secondo precedente in cima che impone quella che

1059
00:43:49,319 --> 00:43:53,359
è probabilmente la più grande

1060
00:43:53,359 --> 00:43:55,980
caratteristica uh delle reti bayesiane

1061
00:43:55,980 --> 00:43:57,780
su cui vuoi eseguire l'

1062
00:43:57,780 --> 00:43:59,819
inferenza causale è che vuoi che siano

1063
00:43:59,819 --> 00:44:01,020
cicliche

1064
00:44:01,020 --> 00:44:03,000
e fondamentalmente hanno mostrato  che l'

1065
00:44:03,000 --> 00:44:06,359
aciclicità può essere imposta a un'agenzia

1066
00:44:06,359 --> 00:44:08,160
Matrix come precedente

1067
00:44:08,160 --> 00:44:10,859
e ha questa forma qui quindi è

1068
00:44:10,859 --> 00:44:14,640
la traccia di Matrix che è

1069
00:44:14,640 --> 00:44:18,420
uh l'esponenziale di a per a

1070
00:44:18,420 --> 00:44:21,859
dove a è di nuovo l'agenzia Matrix e

1071
00:44:21,859 --> 00:44:24,300
fondamentalmente questa quantità qui

1072
00:44:24,300 --> 00:44:27,900
è  è uguale a zero se e solo se la

1073
00:44:27,900 --> 00:44:30,480
rete bayesiana o il

1074
00:44:30,480 --> 00:44:32,819
o il grafico che stai considerando

1075
00:44:32,819 --> 00:44:35,720
è un c clic

1076
00:44:37,619 --> 00:44:40,260
quindi li userò in uh in alcuni

1077
00:44:40,260 --> 00:44:42,960
esperimenti quindi quei due in Forza

1078
00:44:42,960 --> 00:44:45,660
quei due precedenti su

1079
00:44:45,660 --> 00:44:47,520
tipi diversi  delle reti di pazienti

1080
00:44:47,520 --> 00:44:49,200
e sto cercando di fonderle con le

1081
00:44:49,200 --> 00:44:51,540
tecniche che abbiamo proposto in precedenza

1082
00:44:51,540 --> 00:44:52,740
sull'esecuzione dell'inferenza causale la

1083
00:44:52,740 --> 00:44:55,020
codifica operativa

1084
00:44:55,020 --> 00:44:56,520
quindi presenterò due diversi

1085
00:44:56,520 --> 00:44:59,640
esperimenti quindi uno è una prova del

1086
00:44:59,640 --> 00:45:00,960
concetto che sono gli

1087
00:45:00,960 --> 00:45:03,660
esperimenti standard mostrati in  tutti i

1088
00:45:03,660 --> 00:45:06,599
compiti di apprendimento strutturale che è l'inferenza

1089
00:45:06,599 --> 00:45:08,880
della rete bayesiana corretta dai dati

1090
00:45:08,880 --> 00:45:11,760
e poi costruirò sopra

1091
00:45:11,760 --> 00:45:13,500
gli esperimenti di classificazione che ho mostrato

1092
00:45:13,500 --> 00:45:14,280
prima

1093
00:45:14,280 --> 00:45:16,020
e uh

1094
00:45:16,020 --> 00:45:18,540
e mostrerò come effettivamente quei precedenti

1095
00:45:18,540 --> 00:45:21,060
mi permettono di migliorare la

1096
00:45:21,060 --> 00:45:22,500
classificazione  accuratezza l'

1097
00:45:22,500 --> 00:45:25,500
accuratezza del test di modelli di codifica predittiva completamente connessi

1098
00:45:25,500 --> 00:45:28,160


1099
00:45:29,520 --> 00:45:31,680
quindi passiamo al primo esperimento

1100
00:45:31,680 --> 00:45:33,300
che consiste nell'inferire la struttura del

1101
00:45:33,300 --> 00:45:34,980
grafico

1102
00:45:34,980 --> 00:45:37,319
e tutti gli esperimenti seguono

1103
00:45:37,319 --> 00:45:39,480
sostanzialmente la stessa pipeline in tutti gli

1104
00:45:39,480 --> 00:45:42,060
articoli sul campo il primo passo è

1105
00:45:42,060 --> 00:45:45,119
generare  una rete di visione da un grafico casuale

1106
00:45:45,119 --> 00:45:46,079


1107
00:45:46,079 --> 00:45:48,359
quindi in pratica normalmente i due

1108
00:45:48,359 --> 00:45:50,640
grafici casuali che tutti testano sono

1109
00:45:50,640 --> 00:45:53,520
renegrafi di Erdos e grafici senza scala

1110
00:45:53,520 --> 00:45:55,859
in modo da generare quei grandi grafici

1111
00:45:55,859 --> 00:45:58,680
che normalmente hanno 20 per gli 80 80

1112
00:45:58,680 --> 00:46:01,619
nodi diversi e alcuni bordi

1113
00:46:01,619 --> 00:46:04,619
che si campionano in modo casuale

1114
00:46:04,619 --> 00:46:06,540
e  usi questo grafico per generare un

1115
00:46:06,540 --> 00:46:08,280
set di dati

1116
00:46:08,280 --> 00:46:10,819
in modo da campionare ad esempio

1117
00:46:10,819 --> 00:46:14,460
n Big N punti dati e quello che fai è

1118
00:46:14,460 --> 00:46:16,859
prendere il grafico che

1119
00:46:16,859 --> 00:46:18,780
hai generato in precedenza e lo butti

1120
00:46:18,780 --> 00:46:20,819
via mantieni solo il set di dati

1121
00:46:20,819 --> 00:46:23,099
e l'attività che hai  voler risolvere ora è

1122
00:46:23,099 --> 00:46:25,020
imparare

1123
00:46:25,020 --> 00:46:27,420
è avere un algoritmo di addestramento che

1124
00:46:27,420 --> 00:46:29,819
fondamentalmente ti permetta di

1125
00:46:29,819 --> 00:46:32,579
recuperare la struttura del

1126
00:46:32,579 --> 00:46:34,619
grafico che hai buttato via

1127
00:46:34,619 --> 00:46:36,839
quindi il modo in cui lo facciamo qui è che siamo

1128
00:46:36,839 --> 00:46:38,460
in una codifica creativa completamente connessa

1129
00:46:38,460 --> 00:46:41,760
modellare su questo set di dati D utilizzando sia i

1130
00:46:41,760 --> 00:46:43,800
precedenti sparsi che quelli SQL che abbiamo

1131
00:46:43,800 --> 00:46:45,359
definito in precedenza

1132
00:46:45,359 --> 00:46:48,780
e e vedere se effettivamente il

1133
00:46:48,780 --> 00:46:50,760
grafico a cui convergiamo dopo

1134
00:46:50,760 --> 00:46:53,220
aver eliminato le

1135
00:46:53,220 --> 00:46:55,319
voci dell'agenzia Matrix che

1136
00:46:55,319 --> 00:46:57,599
sono inferiori a una certa soglia è

1137
00:46:57,599 --> 00:47:00,060
simile a  quello del grafico iniziale

1138
00:47:00,060 --> 00:47:02,359


1139
00:47:02,520 --> 00:47:04,500
e mostra anche che questo è

1140
00:47:04,500 --> 00:47:06,599
effettivamente il caso, quindi questo è un esempio

1141
00:47:06,599 --> 00:47:09,020
e mostro molte diverse

1142
00:47:09,020 --> 00:47:12,420
parametrizzazioni e dimensioni

1143
00:47:12,420 --> 00:47:15,060
e cose del genere nel documento,

1144
00:47:15,060 --> 00:47:16,920
ma penso che questi due siano gli

1145
00:47:16,920 --> 00:47:18,900
esempi più rappresentativi  con un

1146
00:47:18,900 --> 00:47:20,760
grafico Nursery di errore e un grafico a scala libera

1147
00:47:20,760 --> 00:47:23,579
con 20 nodi

1148
00:47:23,579 --> 00:47:25,800
e qui a sinistra puoi vedere il

1149
00:47:25,800 --> 00:47:27,300
terreno attraverso il grafico che è quello

1150
00:47:27,300 --> 00:47:29,339
campionato

1151
00:47:29,339 --> 00:47:30,839
in modo casuale

1152
00:47:30,839 --> 00:47:32,599
e sulla destra puoi vedere il grafico

1153
00:47:32,599 --> 00:47:35,220
il modello di difficoltà carino come appreso

1154
00:47:35,220 --> 00:47:37,440
dai dati  impostato

1155
00:47:37,440 --> 00:47:39,359
e come puoi vedere sono abbastanza

1156
00:47:39,359 --> 00:47:40,500
simili

1157
00:47:40,500 --> 00:47:42,780
non è ancora perfetto quindi ci

1158
00:47:42,780 --> 00:47:45,000
sono alcuni errori ma

1159
00:47:45,000 --> 00:47:47,460
in generale la struttura

1160
00:47:47,460 --> 00:47:49,500
funziona abbastanza bene abbiamo anche alcuni

1161
00:47:49,500 --> 00:47:52,140
esperimenti quantitativi

1162
00:47:52,140 --> 00:47:54,000
che non mostriamo qui  perché sono

1163
00:47:54,000 --> 00:47:55,740
solo tabelle enormi con molti numeri

1164
00:47:55,740 --> 00:47:57,180
e ho pensato che fosse forse un po'

1165
00:47:57,180 --> 00:48:00,660
troppo per la presentazione ma

1166
00:48:00,660 --> 00:48:02,220
i risultati mostrano che funzionano in

1167
00:48:02,220 --> 00:48:06,060
modo simile ai metodi contemporanei

1168
00:48:06,060 --> 00:48:07,920
anche perché devo dire che come la maggior parte

1169
00:48:07,920 --> 00:48:10,859
della qualità  deriva da on the acigli

1170
00:48:10,859 --> 00:48:15,799
prior che è stato introdotto nel 2018.

1171
00:48:16,920 --> 00:48:19,680
la seconda classe di esperimenti sono i

1172
00:48:19,680 --> 00:48:21,599
nostri esperimenti di classificazione che, come

1173
00:48:21,599 --> 00:48:23,880
ho detto, sono le estensioni di quello che

1174
00:48:23,880 --> 00:48:25,560
ho condiviso in precedenza

1175
00:48:25,560 --> 00:48:27,119
e l'idea è di utilizzare l'

1176
00:48:27,119 --> 00:48:28,560
apprendimento della struttura per migliorare la classificazione

1177
00:48:28,560 --> 00:48:31,140
sui risultati della classificazione sui

1178
00:48:31,140 --> 00:48:33,420
mezzi e sui mezzi di moda set di dati

1179
00:48:33,420 --> 00:48:36,780
a partire da un grafico completamente connesso,

1180
00:48:36,780 --> 00:48:40,560
quindi quello che ho fatto è che ho diviso i

1181
00:48:40,560 --> 00:48:42,839
cluster grafici completamente connessi di

1182
00:48:42,839 --> 00:48:46,440
neuroni in modo che il cluster 1B

1183
00:48:46,440 --> 00:48:49,140
sia quello relativo all'input

1184
00:48:49,140 --> 00:48:51,900
e tutti i piccoli quindi  abbiamo un

1185
00:48:51,900 --> 00:48:55,319
numero specifico di cluster nascosti

1186
00:48:55,319 --> 00:48:57,720
e poi abbiamo il cluster di etichette che

1187
00:48:57,720 --> 00:48:58,800
è

1188
00:48:58,800 --> 00:49:01,560
la classe il cluster di neuroni che

1189
00:49:01,560 --> 00:49:04,079
dovrebbero darmi le previsioni dell'etichetta

1190
00:49:04,079 --> 00:49:06,480


1191
00:49:06,480 --> 00:49:08,700
e li ho addestrati usando per usare

1192
00:49:08,700 --> 00:49:10,980
la prima volta lo sparse prima  solo così

1193
00:49:10,980 --> 00:49:14,099
l'idea è cosa succede se io se elimino le

1194
00:49:14,099 --> 00:49:16,500
connessioni di cui non ho bisogno da un da un

1195
00:49:16,500 --> 00:49:17,460
modello

1196
00:49:17,460 --> 00:49:20,880
e imparo come modello di parser

1197
00:49:20,880 --> 00:49:24,119
funziona bene la risposta è no

1198
00:49:24,119 --> 00:49:25,500
non funziona e il motivo e il

1199
00:49:25,500 --> 00:49:28,500
motivo per cui è  che alla fine il

1200
00:49:28,500 --> 00:49:30,660
grafico con cui convergi è in realtà

1201
00:49:30,660 --> 00:49:32,700
il generato, quindi sostanzialmente il modello

1202
00:49:32,700 --> 00:49:36,180
impara a prevedere l'etichetta in base

1203
00:49:36,180 --> 00:49:38,400
all'etichetta stessa, quindi scarta tutte le

1204
00:49:38,400 --> 00:49:40,020
informazioni dall'input

1205
00:49:40,020 --> 00:49:42,480
e mantiene solo l'etichetta e come puoi

1206
00:49:42,480 --> 00:49:45,119
vedere qui il  l'etichetta y predice se stessa o

1207
00:49:45,119 --> 00:49:46,560
in altri esperimenti quando cambi i

1208
00:49:46,560 --> 00:49:48,960
parametri che hai che y prevede a

1209
00:49:48,960 --> 00:49:52,520
zero che preex X1 predice di nuovo y

1210
00:49:52,520 --> 00:49:55,980
quindi qual è la soluzione a

1211
00:49:55,980 --> 00:49:57,240
questo problema beh la soluzione a questo

1212
00:49:57,240 --> 00:49:59,520
problema è che dobbiamo

1213
00:49:59,520 --> 00:50:03,000
convergere  a un grafico aciclico

1214
00:50:03,000 --> 00:50:05,220
e quindi dobbiamo aggiungere qualcosa che

1215
00:50:05,220 --> 00:50:08,000
impedisce una ciclicità e qual è quella

1216
00:50:08,000 --> 00:50:10,200
ovviamente è quella che ho già

1217
00:50:10,200 --> 00:50:12,780
proposto e poi mostro una seconda

1218
00:50:12,780 --> 00:50:14,520
tecnica

1219
00:50:14,520 --> 00:50:17,280
quindi la prima usa l'SQL precedente

1220
00:50:17,280 --> 00:50:18,680
definito in precedenza

1221
00:50:18,680 --> 00:50:21,359
e la seconda è  a è una nuova

1222
00:50:21,359 --> 00:50:22,859
tecnica che in realtà fa uso di

1223
00:50:22,859 --> 00:50:24,359
esempi negativi

1224
00:50:24,359 --> 00:50:26,520
quindi un negativo un esempio negativo in questo

1225
00:50:26,520 --> 00:50:30,060
caso è semplicemente uh il punto dati in

1226
00:50:30,060 --> 00:50:32,280
cui hai un'immagine ma l'etichetta è

1227
00:50:32,280 --> 00:50:33,240
sbagliata

1228
00:50:33,240 --> 00:50:35,220
quindi qui ad esempio hai un'immagine di

1229
00:50:35,220 --> 00:50:36,900
un sette  ma l'etichetta che sto dando

1230
00:50:36,900 --> 00:50:39,599
al modello è un due

1231
00:50:39,599 --> 00:50:40,980


1232
00:50:40,980 --> 00:50:44,579
e l'idea è molto semplice in quanto è

1233
00:50:44,579 --> 00:50:47,460
già stata utilizzata in molti uh Funziona

1234
00:50:47,460 --> 00:50:49,740
quindi ogni volta che il modello è un

1235
00:50:49,740 --> 00:50:52,079
esempio positivo deve aumentare per

1236
00:50:52,079 --> 00:50:53,520
ridurre al minimo la variazione  di energia libera

1237
00:50:53,520 --> 00:50:56,520
e ogni volta che ha un è un

1238
00:50:56,520 --> 00:50:58,859
esempio negativo deve aumentarlo

1239
00:50:58,859 --> 00:51:01,260
quindi lasciami spostare sull'errore questa

1240
00:51:01,260 --> 00:51:04,200
quantità da minimizzare

1241
00:51:04,200 --> 00:51:05,960
straniera

1242
00:51:05,960 --> 00:51:08,579
con molti esperimenti e molti

1243
00:51:08,579 --> 00:51:10,859
uh di sperimentazioni abbiamo visto che le

1244
00:51:10,859 --> 00:51:12,119
due tecniche

1245
00:51:12,119 --> 00:51:15,000
fondamentalmente il primo porta agli stessi

1246
00:51:15,000 --> 00:51:17,220
risultati e anche il secondo porta allo stesso

1247
00:51:17,220 --> 00:51:18,599
grafico,

1248
00:51:18,599 --> 00:51:21,000
quindi ecco

1249
00:51:21,000 --> 00:51:22,800
i nuovi risultati alcuni mezzi e

1250
00:51:22,800 --> 00:51:25,079
mezzi di moda usando le due tecniche

1251
00:51:25,079 --> 00:51:27,660
che ho appena proposto

1252
00:51:27,660 --> 00:51:30,960
e ora passiamo ad alcuni che

1253
00:51:30,960 --> 00:51:33,900
non sono ancora uh grandiose ma sicuramente più

1254
00:51:33,900 --> 00:51:36,000
ragionevoli accuratezze di test quindi qui

1255
00:51:36,000 --> 00:51:39,059
abbiamo un errore di test di 3,17 per i minuti e un

1256
00:51:39,059 --> 00:51:42,119
errore di test di 13,98 per i mezzi di moda

1257
00:51:42,119 --> 00:51:44,819
e in realtà questi possono essere quei risultati che

1258
00:51:44,819 --> 00:51:48,300
possono essere molto migliorati imparando la

1259
00:51:48,300 --> 00:51:51,300
struttura del grafico da  tritato

1260
00:51:51,300 --> 00:51:53,040
e quindi aggiustando la struttura del

1261
00:51:53,040 --> 00:51:55,319
grafico e facendo una qualche forma di

1262
00:51:55,319 --> 00:51:57,660
messa a punto così se si mette a punto il modello sulla

1263
00:51:57,660 --> 00:52:00,000
struttura gerarchica corretta ad

1264
00:52:00,000 --> 00:52:01,980
un certo punto si raggiunge l'accuratezza del test

1265
00:52:01,980 --> 00:52:03,359
che è quella che ci si aspetterebbe da un

1266
00:52:03,359 --> 00:52:05,460
modello gerarchico ma quelli  quelli sono

1267
00:52:05,460 --> 00:52:08,099
semplicemente quello a cui il modello completamente connesso

1268
00:52:08,099 --> 00:52:10,980
converge naturalmente,

1269
00:52:10,980 --> 00:52:13,859
quindi ad esempio da un errore di test di

1270
00:52:13,859 --> 00:52:15,420
18.32

1271
00:52:15,420 --> 00:52:17,339
del treno del modello completamente connesso su mezzi di

1272
00:52:17,339 --> 00:52:20,359
moda semplicemente eseguendo

1273
00:52:20,359 --> 00:52:22,859
correlazioni o query condizionali

1274
00:52:22,859 --> 00:52:24,420
che è un modo standard per interrogare

1275
00:52:24,420 --> 00:52:26,520
il modello di codifica operativa

1276
00:52:26,520 --> 00:52:29,220
aggiungendo  interventi e l'AC click

1277
00:52:29,220 --> 00:52:32,040
prior insieme rende questo

1278
00:52:32,040 --> 00:52:34,200
errore di test molto più basso

1279
00:52:34,200 --> 00:52:37,200
e possiamo osservarlo anche perché

1280
00:52:37,200 --> 00:52:39,319


1281
00:52:39,780 --> 00:52:41,819
non entrerò un po 'nei dettagli

1282
00:52:41,819 --> 00:52:45,420
su uh su quest'ultimo esperimento e su come

1283
00:52:45,420 --> 00:52:48,660
il prior aciclico agisce sul  struttura

1284
00:52:48,660 --> 00:52:50,339
del grafico

1285
00:52:50,339 --> 00:52:52,440
quindi eseguo eseguo un esperimento su

1286
00:52:52,440 --> 00:52:54,960
uh su un nuovo set di dati che intendo dire

1287
00:52:54,960 --> 00:52:56,460
chiamare il nuovo set di dati potrebbe essere

1288
00:52:56,460 --> 00:52:58,500
troppo è che lo chiamo un

1289
00:52:58,500 --> 00:53:01,440
set di dati a due mezzi in cui hai il

1290
00:53:01,440 --> 00:53:04,319
punto di input  è formato da due

1291
00:53:04,319 --> 00:53:07,319
immagini diverse e l'etichetta dipende solo dalla

1292
00:53:07,319 --> 00:53:08,520
seconda immagine

1293
00:53:08,520 --> 00:53:10,800
sulla prima storia dell'immagine

1294
00:53:10,800 --> 00:53:12,720
quindi l'idea qui

1295
00:53:12,720 --> 00:53:15,079
è la struttura del modello la

1296
00:53:15,079 --> 00:53:18,540
ciclicità precedente e cose del genere

1297
00:53:18,540 --> 00:53:20,819
in grado di riconoscere che la seconda metà

1298
00:53:20,819 --> 00:53:23,400
dell'immagine è  in realtà privo di significato in

1299
00:53:23,400 --> 00:53:27,960
uh nell'esecuzione nell'apprendimento della

1300
00:53:27,960 --> 00:53:31,140
classificazione nell'esecuzione

1301
00:53:31,140 --> 00:53:33,119
come si comporta l'addestramento in generale come

1302
00:53:33,119 --> 00:53:36,480
ad esempio abbiamo questo uh

1303
00:53:36,480 --> 00:53:39,000
nodo di input di input nodo di output e solo i nodi sono

1304
00:53:39,000 --> 00:53:41,940
completamente connessi e il modello

1305
00:53:41,940 --> 00:53:43,740
converge

1306
00:53:43,740 --> 00:53:45,900
in una struttura gerarchica che è il

1307
00:53:45,900 --> 00:53:48,960
uno che sappiamo esegue meglio le

1308
00:53:48,960 --> 00:53:50,880
attività di classificazione

1309
00:53:50,880 --> 00:53:53,520
beh ecco un è un esempio di un

1310
00:53:53,520 --> 00:53:54,980
metodo di allenamento

1311
00:53:54,980 --> 00:53:59,280
eseguito quindi in c0 che è l'inizio dell'allenamento

1312
00:53:59,280 --> 00:54:00,720


1313
00:54:00,720 --> 00:54:03,000
abbiamo questo modello qui quindi s0

1314
00:54:03,000 --> 00:54:05,819
corrisponde ai sette quindi

1315
00:54:05,819 --> 00:54:08,099
alla prima immagine  poiché uno corrisponde

1316
00:54:08,099 --> 00:54:09,839
all'immagine a sette colonne, abbiamo di nuovo l'

1317
00:54:09,839 --> 00:54:12,300
etichetta Y e tutte le variabili latenti x0

1318
00:54:12,300 --> 00:54:13,800
X1 X2

1319
00:54:13,800 --> 00:54:15,720
e il modello è completamente connesso, quindi l'

1320
00:54:15,720 --> 00:54:17,040
agenzia Matrix

1321
00:54:17,040 --> 00:54:20,579
è piena di uno non ci sono zeri

1322
00:54:20,579 --> 00:54:23,720
abbiamo cicli automatici e cose del genere

1323
00:54:23,720 --> 00:54:27,319
il  modello per un paio di epoche fino a quando

1324
00:54:27,319 --> 00:54:30,540
e ciò che sappiamo immediatamente è che, ad

1325
00:54:30,540 --> 00:54:31,920
esempio, il modello

1326
00:54:31,920 --> 00:54:34,740
capisce immediatamente che i quattro non sono necessari

1327
00:54:34,740 --> 00:54:36,839
per eseguire la classificazione, quindi non lo fa,

1328
00:54:36,839 --> 00:54:40,740
quindi ogni nodo in uscita dal

1329
00:54:40,740 --> 00:54:43,980
secondo cluster di input viene rimosso

1330
00:54:43,980 --> 00:54:45,900
e  qualcosa che non abbiamo capito è

1331
00:54:45,900 --> 00:54:48,660
che questo è questo cluster è quello

1332
00:54:48,660 --> 00:54:50,400
relativo all'output

1333
00:54:50,400 --> 00:54:52,260
quindi

1334
00:54:52,260 --> 00:54:55,319
abbiamo una mappa lineare direttamente da s0 a Y

1335
00:54:55,319 --> 00:54:56,480


1336
00:54:56,480 --> 00:54:59,339
che è questa parte qui

1337
00:54:59,339 --> 00:55:01,160
ma sappiamo che in realtà una mappa lineare

1338
00:55:01,160 --> 00:55:04,740
non è la migliore  mappa per

1339
00:55:04,740 --> 00:55:07,200
eseguire la classificazione dei mezzi quindi abbiamo

1340
00:55:07,200 --> 00:55:08,700
bisogno di una gerarchia abbiamo bisogno di un po 'di

1341
00:55:08,700 --> 00:55:11,579
profondità per migliorare i risultati e come

1342
00:55:11,579 --> 00:55:14,220
puoi vedere questa linea qui è l'

1343
00:55:14,220 --> 00:55:15,599
accuratezza

1344
00:55:15,599 --> 00:55:18,960
che fino a questo punto quindi fino a C2 è

1345
00:55:18,960 --> 00:55:22,500
simile a um quindi è 91  che è

1346
00:55:22,500 --> 00:55:24,059
leggermente migliore della classificazione lineare,

1347
00:55:24,059 --> 00:55:25,500


1348
00:55:25,500 --> 00:55:28,740
ma una volta che si procede con l'addestramento,

1349
00:55:28,740 --> 00:55:30,660
il modello capisce che ha bisogno di una certa

1350
00:55:30,660 --> 00:55:33,119
gerarchia per adattarsi meglio ai dati,

1351
00:55:33,119 --> 00:55:35,640
quindi vedi che questa freccia inizia

1352
00:55:35,640 --> 00:55:38,760
a diventare sempre più forte nel tempo

1353
00:55:38,760 --> 00:55:41,700
fino a quando non capisce che il lineare

1354
00:55:41,700 --> 00:55:44,339
map in realtà non è realmente necessario e

1355
00:55:44,339 --> 00:55:45,920
lo rimuove

1356
00:55:45,920 --> 00:55:48,780
quindi il modello con cui convergi è un

1357
00:55:48,780 --> 00:55:51,000
modello che parte da zero va a un

1358
00:55:51,000 --> 00:55:53,760
nodo nascosto e poi va

1359
00:55:53,760 --> 00:55:57,180
all'etichetta con una mappa lineare molto debole

1360
00:55:57,180 --> 00:55:59,700
che viene effettivamente rimossa se tu se

1361
00:55:59,700 --> 00:56:02,760
imposti una soglia di uh se la

1362
00:56:02,760 --> 00:56:05,520
soglia del venditore è ad esempio 0,1 0,2 a un certo

1363
00:56:05,520 --> 00:56:07,619
punto la mappa lineare viene dimenticata e

1364
00:56:07,619 --> 00:56:10,680
tutto ciò che ottieni è con una è

1365
00:56:10,680 --> 00:56:13,319
con una rete gerarchica

1366
00:56:13,319 --> 00:56:15,720
che è quella uh quindi ha imparato la

1367
00:56:15,720 --> 00:56:17,099
struttura corretta per eseguire

1368
00:56:17,099 --> 00:56:19,260
compiti di classificazione che sono gerarchici

1369
00:56:19,260 --> 00:56:21,900
e ha anche appreso che la seconda

1370
00:56:21,900 --> 00:56:25,020
immagine non ha avuto alcun ruolo nella definizione

1371
00:56:25,020 --> 00:56:28,440
dell'accuratezza del test e questo è tutto

1372
00:56:28,440 --> 00:56:30,420
questo è tutto eseguito anche tutti quei

1373
00:56:30,420 --> 00:56:33,839
lavori sono semplicemente eseguiti da eseguire da

1374
00:56:33,839 --> 00:56:36,599
un processo di minimizzazione dell'energia libera quindi

1375
00:56:36,599 --> 00:56:38,400
si inizializza il modello si definisce l'

1376
00:56:38,400 --> 00:56:40,859
energia libera si definiscono i priori in modo che

1377
00:56:40,859 --> 00:56:43,559
lo sparse e il clic C prima

1378
00:56:43,559 --> 00:56:45,780
si esegua la minimizzazione dell'energia e si

1379
00:56:45,780 --> 00:56:47,400
converga a gerarchico in un

1380
00:56:47,400 --> 00:56:49,500
modello gerarchico che è ben in grado di

1381
00:56:49,500 --> 00:56:51,839
eseguire la classificazione su tritato

1382
00:56:51,839 --> 00:56:54,000
e quindi se si  quindi esegui un po 'di

1383
00:56:54,000 --> 00:56:55,800
messa a punto raggiungi risultati molto competitivi

1384
00:56:55,800 --> 00:56:57,359
come fai nelle reti di feed forward

1385
00:56:57,359 --> 00:56:59,339
con la propagazione del feedback

1386
00:56:59,339 --> 00:57:01,260
ma penso che non sia questa la

1387
00:57:01,260 --> 00:57:03,780
parte interessante la parte interessante è che ti piace

1388
00:57:03,780 --> 00:57:05,160
tutto questo processo questo processo tutto

1389
00:57:05,160 --> 00:57:07,980
insieme di intervento e l'

1390
00:57:07,980 --> 00:57:09,780
aciclicità

1391
00:57:09,780 --> 00:57:11,700
ti permette  prendere una rete completamente connessa

1392
00:57:11,700 --> 00:57:12,660


1393
00:57:12,660 --> 00:57:15,119
e convergere in una rete gerarchica

1394
00:57:15,119 --> 00:57:16,140
che è in grado di eseguire

1395
00:57:16,140 --> 00:57:20,058
la classificazione con buoni risultati

1396
00:57:20,760 --> 00:57:23,000
e sì, è

1397
00:57:23,000 --> 00:57:26,280
praticamente tutto ora sono oh sì wow

1398
00:57:26,280 --> 00:57:29,220
ho parlato molto e sono uh questa è la

1399
00:57:29,220 --> 00:57:32,160
conclusione  del discorso che è

1400
00:57:32,160 --> 00:57:35,280
fondamentalmente sto facendo un piccolo riassunto e

1401
00:57:35,280 --> 00:57:37,559
penso che l'importante conclusione se

1402
00:57:37,559 --> 00:57:39,300
devo darti in una frase di questo

1403
00:57:39,300 --> 00:57:40,980
documento è che la codifica predittiva è un

1404
00:57:40,980 --> 00:57:44,400
metodo di aggiornamento delle convinzioni che è in grado di

1405
00:57:44,400 --> 00:57:46,559
eseguire end-to  -fine l'apprendimento del cugino in modo che

1406
00:57:46,559 --> 00:57:48,599
sia in grado di eseguire interventi per

1407
00:57:48,599 --> 00:57:51,420
apprendere una struttura dai dati e quindi

1408
00:57:51,420 --> 00:57:53,160
eseguire interventi e

1409
00:57:53,160 --> 00:57:56,058
controfattuali in

1410
00:57:56,700 --> 00:57:58,440
modo da inferenza causale in altri e

1411
00:57:58,440 --> 00:58:00,119
modellare in modo efficiente gli interventi

1412
00:58:00,119 --> 00:58:01,680
semplicemente impostando l'errore di previsione su

1413
00:58:01,680 --> 00:58:03,359
zero, quindi è una tecnica molto facile

1414
00:58:03,359 --> 00:58:06,240
da eseguire  interventi e

1415
00:58:06,240 --> 00:58:07,619
semplicemente devi solo toccare un

1416
00:58:07,619 --> 00:58:08,940
neurone non devi agire sulla

1417
00:58:08,940 --> 00:58:10,859
struttura del grafo

1418
00:58:10,859 --> 00:58:14,339
puoi usarlo per eseguire per

1419
00:58:14,339 --> 00:58:16,140
creare strutture modelli causali

1420
00:58:16,140 --> 00:58:18,359
biologicamente plausibili

1421
00:58:18,359 --> 00:58:20,819
è in grado di apprendere la struttura per  uh

1422
00:58:20,819 --> 00:58:24,119
dai dati come ho detto forse già molte volte

1423
00:58:24,119 --> 00:58:26,940


1424
00:58:26,940 --> 00:58:28,740
e un paio di frasi sui

1425
00:58:28,740 --> 00:58:31,260
lavori futuri è che

1426
00:58:31,260 --> 00:58:33,180
qualcosa che sarebbe bello fare è

1427
00:58:33,180 --> 00:58:36,119
migliorare le prestazioni del modello che

1428
00:58:36,119 --> 00:58:38,460
abbiamo definito perché penso che si

1429
00:58:38,460 --> 00:58:40,980
comporti ragionevolmente bene su  un sacco di

1430
00:58:40,980 --> 00:58:43,079
compiti quindi si comporta abbastanza bene

1431
00:58:43,079 --> 00:58:45,780
sull'apprendimento strutturale su per me

1432
00:58:45,780 --> 00:58:48,119
intervento e controfattuali ma

1433
00:58:48,119 --> 00:58:49,440
in realtà se guardi al

1434
00:58:49,440 --> 00:58:51,420
modello all'avanguardia c'è sempre un

1435
00:58:51,420 --> 00:58:53,880
metodo molto specifico che funziona meglio

1436
00:58:53,880 --> 00:58:55,559
nel singolo compito

1437
00:58:55,559 --> 00:58:58,260
quindi sarebbe interessante vedere  se

1438
00:58:58,260 --> 00:59:00,180
possiamo raggiungere quel livello di prestazioni in

1439
00:59:00,180 --> 00:59:03,599
uh in compiti specifici aggiungendo alcuni

1440
00:59:03,599 --> 00:59:05,599
trucchi o alcuni

1441
00:59:05,599 --> 00:59:10,260
o alcuni nuovi metodi di ottimizzazione e

1442
00:59:10,260 --> 00:59:12,839
generalizzandolo a sistemi dinamici

1443
00:59:12,839 --> 00:59:14,280
che sono in realtà molto più interessanti

1444
00:59:14,280 --> 00:59:17,220
dei sistemi statici come

1445
00:59:17,220 --> 00:59:20,099
modelli causali dinamici e o  altre tecniche

1446
00:59:20,099 --> 00:59:22,200
che ti consentono di eseguire l'

1447
00:59:22,200 --> 00:59:25,200
inferenza causale in sistemi che si muovono in modo che

1448
00:59:25,200 --> 00:59:27,799
un'azione intrapresa in un passaggio temporale specifico

1449
00:59:27,799 --> 00:59:30,299
influenzi un altro nodo in un passaggio temporale successivo

1450
00:59:30,299 --> 00:59:32,640
che è fondamentalmente una causalità grandiosa

1451
00:59:32,640 --> 00:59:34,859


1452
00:59:34,859 --> 00:59:38,160
sì, è così e uh grazie

1453
00:59:38,160 --> 00:59:41,118
mille grazie

1454
00:59:47,460 --> 00:59:51,119


1455
00:59:51,119 --> 00:59:53,160
presentazione fantastica e molto completa che pensava davvero di

1456
00:59:53,160 --> 00:59:55,700
essere disattivato scusa

1457
00:59:57,119 --> 00:59:59,700
disattivato su Zoom ma sì grazie per

1458
00:59:59,700 --> 01:00:02,400
la presentazione fantastica e molto completa

1459
01:00:02,400 --> 01:00:05,099
c'era davvero molto

1460
01:00:05,099 --> 01:00:06,900
lì e c'erano anche molte belle

1461
01:00:06,900 --> 01:00:09,900
domande nella chat dal vivo quindi forse per

1462
01:00:09,900 --> 01:00:12,900
riscaldare  nelle domande come sei arrivato

1463
01:00:12,900 --> 01:00:15,960
a studiare questo argomento se hai studiato la

1464
01:00:15,960 --> 01:00:18,900
causalità e hai trovato utile la codifica predittiva

1465
01:00:18,900 --> 01:00:21,000
o viceversa o come sei

1466
01:00:21,000 --> 01:00:23,160
arrivato a questo incrocio

1467
01:00:23,160 --> 01:00:25,740
devo dire che la prima

1468
01:00:25,740 --> 01:00:27,240
persona che è venuta fuori con questa idea è stata

1469
01:00:27,240 --> 01:00:29,040
uh era Baron

1470
01:00:29,040 --> 01:00:33,900
così così come penso che un anno e

1471
01:00:33,900 --> 01:00:36,660
mezzo fa ancora di più ha portato come una

1472
01:00:36,660 --> 01:00:38,940
pagina con questa idea e poi è stato

1473
01:00:38,940 --> 01:00:42,119
dimenticato e nessuno l'ha raccolto e uh

1474
01:00:42,119 --> 01:00:43,980
e l'estate scorsa ho iniziato a

1475
01:00:43,980 --> 01:00:47,880
incuriosirmi sulla causalità e l'

1476
01:00:47,880 --> 01:00:50,339
um  Ho letto ad esempio The Book of Life

1477
01:00:50,339 --> 01:00:52,440
mentre ascoltavo i podcast, conosco il

1478
01:00:52,440 --> 01:00:53,760
modo standard in cui ti interessi

1479
01:00:53,760 --> 01:00:54,900
a un argomento

1480
01:00:54,900 --> 01:00:57,480
e ricordo questa idea di

1481
01:00:57,480 --> 01:01:00,180
Baron e gliel'ho proposta e uh e

1482
01:01:00,180 --> 01:01:03,180
io ero tipo perché non  lo espandiamo e uh

1483
01:01:03,180 --> 01:01:06,000
e in realtà lo trasformiamo in un documento quindi ho

1484
01:01:06,000 --> 01:01:07,319
coinvolto alcune persone per aiutarmi con gli

1485
01:01:07,319 --> 01:01:09,359
esperimenti e uh e questo è il

1486
01:01:09,359 --> 01:01:12,000
risultato finale alla fine

1487
01:01:12,000 --> 01:01:14,160
fantastico fantastico sì

1488
01:01:14,160 --> 01:01:15,240
um

1489
01:01:15,240 --> 01:01:17,400
molto da dire che andrò solo alla

1490
01:01:17,400 --> 01:01:19,619
chat dal vivo  prima e rispondi a un sacco di

1491
01:01:19,619 --> 01:01:21,240
domande diverse e se qualcun altro

1492
01:01:21,240 --> 01:01:22,440
vuole aggiungermi, prima accenderò la luce

1493
01:01:22,440 --> 01:01:24,059
perché penso che mi sto

1494
01:01:24,059 --> 01:01:28,440
perdendo sempre di più sì

1495
01:01:28,440 --> 01:01:30,720
chi ha detto che l'inferenza attiva non può risolvere  un

1496
01:01:30,720 --> 01:01:32,160
problema di stanza buia

1497
01:01:32,160 --> 01:01:34,980
oh sì eccoci qui

1498
01:01:34,980 --> 01:01:37,020
quindi diresti che l'interruttore della luce l'ha reso

1499
01:01:37,020 --> 01:01:39,299
più leggero

1500
01:01:39,299 --> 01:01:40,680
sì,

1501
01:01:40,680 --> 01:01:42,240
penso di sì

1502
01:01:42,240 --> 01:01:43,980
nessun problema qui

1503
01:01:43,980 --> 01:01:46,940
um ok ml Dawn ha scritto

1504
01:01:46,940 --> 01:01:49,559
poiché nella codifica predittiva tutte le

1505
01:01:49,559 --> 01:01:52,020
distribuzioni sono generalmente gaussiane i

1506
01:01:52,020 --> 01:01:53,760
messaggi dal basso verso l'alto sono

1507
01:01:53,760 --> 01:01:55,500
previsione ponderata di precisione  errori in cui

1508
01:01:55,500 --> 01:01:57,420
la precisione è l'inverso della

1509
01:01:57,420 --> 01:02:00,000
covarianza gaussiana cosa succede se

1510
01:02:00,000 --> 01:02:03,319
vengono utilizzate distribuzioni non gaussiane

1511
01:02:03,780 --> 01:02:05,339
è

1512
01:02:05,339 --> 01:02:09,059
fondamentalmente il metodo generale rimane

1513
01:02:09,059 --> 01:02:10,380
diverso la differenza principale è che

1514
01:02:10,380 --> 01:02:13,079
tu non hai errori di previsione

1515
01:02:13,079 --> 01:02:15,480
che come è stato correttamente sottolineato è

1516
01:02:15,480 --> 01:02:18,480
fondamentalmente il  derivata

1517
01:02:18,480 --> 01:02:20,819
dell'energia libera virtuale se hai ipotesi gaussiane

1518
01:02:20,819 --> 01:02:22,920


1519
01:02:22,920 --> 01:02:25,020
sì hai anche quella singola quantità

1520
01:02:25,020 --> 01:02:27,960
da impostare a zero e probabilmente

1521
01:02:27,960 --> 01:02:29,880
dovrai agire sulla struttura del

1522
01:02:29,880 --> 01:02:30,900
grafico

1523
01:02:30,900 --> 01:02:34,020
per eseguire interventi

1524
01:02:34,020 --> 01:02:37,079
e anche tu uh e colleghi avete avuto un

1525
01:02:37,079 --> 01:02:39,900
documento nel 2022 predittivo  codifica Al di là delle

1526
01:02:39,900 --> 01:02:41,880
distribuzioni gaussiane che ha esaminato

1527
01:02:41,880 --> 01:02:43,859
alcuni di questi problemi giusto sì sì

1528
01:02:43,859 --> 01:02:46,260
esattamente così quella carta era un

1529
01:02:46,260 --> 01:02:47,339
po'

1530
01:02:47,339 --> 01:02:50,460
l'idea alla base di quella carta è uh

1531
01:02:50,460 --> 01:02:53,220
e noi modelliamo Transformers questa è la

1532
01:02:53,220 --> 01:02:54,420
motivazione più grande usando piuttosto

1533
01:02:54,420 --> 01:02:57,180
difficile e la risposta è uh non è

1534
01:02:57,180 --> 01:02:59,460
perché il  il meccanismo di attenzione ha

1535
01:02:59,460 --> 01:03:02,099
un Max morbido alla fine e Max morbido chiama

1536
01:03:02,099 --> 01:03:03,960
uh

1537
01:03:03,960 --> 01:03:08,400
come non per la distribuzione gaussiana ma sì

1538
01:03:08,400 --> 01:03:11,280
per la distribuzione Max morbida il

1539
01:03:11,280 --> 01:03:13,440
non capisco il nome ora ma sì

1540
01:03:13,440 --> 01:03:16,079
e uh quindi sì questa è una generalizzazione

1541
01:03:16,079 --> 01:03:19,140
è un po '  difficile chiamarlo una volta

1542
01:03:19,140 --> 01:03:20,700
rimosso il presupposto di Gastonè

1543
01:03:20,700 --> 01:03:22,319
ancora un po' complicato chiamarlo

1544
01:03:22,319 --> 01:03:24,059
codice creativo

1545
01:03:24,059 --> 01:03:26,400
quindi è un tipo

1546
01:03:26,400 --> 01:03:29,819
così, ad esempio, come parlare con uh con l'auto

1547
01:03:29,819 --> 01:03:32,700
Freestone o gli piace il codice creativo

1548
01:03:32,700 --> 01:03:35,160
è solo se tu hai solo gauss

1549
01:03:35,160 --> 01:03:37,680
e gaussiano  presupposti

1550
01:03:37,680 --> 01:03:39,720
ma sì, questo è più un

1551
01:03:39,720 --> 01:03:42,660
dibattito filosofico che uh

1552
01:03:42,660 --> 01:03:44,940
interessante e un altro argomento

1553
01:03:44,940 --> 01:03:46,740
che penso sia sicuramente di grande

1554
01:03:46,740 --> 01:03:49,500
interesse sono le somiglianze e le differenze

1555
01:03:49,500 --> 01:03:52,980
tra l'apparato dell'attenzione in

1556
01:03:52,980 --> 01:03:56,099
Transformers e il modo in cui l'attenzione

1557
01:03:56,099 --> 01:03:58,440
è descritta da una

1558
01:03:58,440 --> 01:04:00,180
prospettiva neurocognitiva e da

1559
01:04:00,180 --> 01:04:03,240
un'elaborazione predittiva Precisione  angolo di attesa cosa ne

1560
01:04:03,240 --> 01:04:06,200
pensi

1561
01:04:06,359 --> 01:04:08,700
bene l'idea è che um

1562
01:04:08,700 --> 01:04:12,359
sì, ci penso è che da una

1563
01:04:12,359 --> 01:04:15,000
bella prospettiva di elaborazione e anche di

1564
01:04:15,000 --> 01:04:16,400
inferenza operativa l'

1565
01:04:16,400 --> 01:04:19,260
attenzione può essere vista come una sorta di

1566
01:04:19,260 --> 01:04:21,299
problema di apprendimento strutturale c'è

1567
01:04:21,299 --> 01:04:23,040
penso che ci sia un  articolo recente di uh

1568
01:04:23,040 --> 01:04:25,680
dal gruppo di Chris Buckley che mostra

1569
01:04:25,680 --> 01:04:26,339
che

1570
01:04:26,339 --> 01:04:28,079
dovrebbe esserci una

1571
01:04:28,079 --> 01:04:30,420
ristampa nell'archivio in cui fondamentalmente hanno

1572
01:04:30,420 --> 01:04:31,859
mostrato che il meccanismo di attenzione

1573
01:04:31,859 --> 01:04:35,819
sta semplicemente imparando la Precisione

1574
01:04:35,819 --> 01:04:38,880
sui parametri di peso specifici per

1575
01:04:38,880 --> 01:04:41,040
altri punti dati quindi questa Precisione

1576
01:04:41,040 --> 01:04:43,200
non è un non è un non è un parametro

1577
01:04:43,200 --> 01:04:45,540
che è nella struttura del modello quindi non è

1578
01:04:45,540 --> 01:04:47,579
un parametro specifico del modello

1579
01:04:47,579 --> 01:04:49,140
è un parametro che cambia velocemente come i

1580
01:04:49,140 --> 01:04:51,660
nodi di valore che vengono aggiornati

1581
01:04:51,660 --> 01:04:53,760
minimizzando la variazione di energia libera

1582
01:04:53,760 --> 01:04:55,440
e una volta che ti  l'ho minimizzato

1583
01:04:55,440 --> 01:04:57,000
e calcolato, poi lo butti via

1584
01:04:57,000 --> 01:04:58,920
e per il prossimo punto dati devi

1585
01:04:58,920 --> 01:05:00,780
ricalcolarlo da zero

1586
01:05:00,780 --> 01:05:03,299
quindi sì, penso che l'analogia di

1587
01:05:03,299 --> 01:05:05,819
calcolo sia saggia uh il

1588
01:05:05,819 --> 01:05:07,920
meccanismo di attenzione può essere visto come una sorta di

1589
01:05:07,920 --> 01:05:10,559
apprendimento della struttura ma un  strutturare

1590
01:05:10,559 --> 01:05:13,020
l'apprendimento che è specifico del punto dati e

1591
01:05:13,020 --> 01:05:15,119
non specifico del modello

1592
01:05:15,119 --> 01:05:17,280
e penso che se vogliamo generalizzare un

1593
01:05:17,280 --> 01:05:18,960
po' e passare

1594
01:05:18,960 --> 01:05:20,339
dal meccanismo dell'attenzione in

1595
01:05:20,339 --> 01:05:21,900
Transformers al meccanismo dell'attenzione della

1596
01:05:21,900 --> 01:05:24,180
scienza cognitiva,

1597
01:05:24,180 --> 01:05:28,020
sento che probabilmente sono due diversi a cui

1598
01:05:28,020 --> 01:05:31,260
piace tracciare somiglianze e  uh

1599
01:05:31,260 --> 01:05:33,359
penso che l'analogia dell'apprendimento strutturale

1600
01:05:33,359 --> 01:05:36,660
e quanto sia importante una connessione in

1601
01:05:36,660 --> 01:05:38,760
rispetto a un'altra probabilmente

1602
01:05:38,760 --> 01:05:41,900
fa il lavoro molto meglio fredda

1603
01:05:42,000 --> 01:05:44,880
risposta grigia okay

1604
01:05:44,880 --> 01:05:49,200
ml Don chiede nei controfattuali qual è

1605
01:05:49,200 --> 01:05:51,240
la differenza tra le variabili nascoste

1606
01:05:51,240 --> 01:05:55,440
X e le variabili non osservate U

1607
01:05:55,440 --> 01:05:59,180
la differenza è  che puoi

1608
01:05:59,540 --> 01:06:01,740
penso che il principale sia che non puoi

1609
01:06:01,740 --> 01:06:03,599
osservare l'uso

1610
01:06:03,599 --> 01:06:05,819
puoi usarli perché puoi puoi

1611
01:06:05,819 --> 01:06:09,000
calcolarli e correggerli ma non puoi

1612
01:06:09,000 --> 01:06:10,559
l'idea è che non hai alcun controllo

1613
01:06:10,559 --> 01:06:13,380
su di loro quindi usano l'uso dovrebbe essere

1614
01:06:13,380 --> 01:06:16,020
visto come variabili specifiche dell'ambiente

1615
01:06:16,020 --> 01:06:18,540
che sono lì influenzano il

1616
01:06:18,540 --> 01:06:21,240
tuo processo ok perché per

1617
01:06:21,240 --> 01:06:23,280
esempio quando torni indietro nel tempo l'

1618
01:06:23,280 --> 01:06:25,079
ambiente è diverso quindi l'idea è

1619
01:06:25,079 --> 01:06:26,520
per esempio se ti

1620
01:06:26,520 --> 01:06:28,440
piace tornare all'esempio

1621
01:06:28,440 --> 01:06:29,880
prima del di

1622
01:06:29,880 --> 01:06:31,920
il reddito previsto di una persona con

1623
01:06:31,920 --> 01:06:34,619
un'intelligenza specifica dell'istruzione uh

1624
01:06:34,619 --> 01:06:37,440
uh titolo di studio

1625
01:06:37,440 --> 01:06:40,200
l'idea è che se voglio vedere

1626
01:06:40,200 --> 01:06:43,559
quanto imparerò oggi con uh con un

1627
01:06:43,559 --> 01:06:45,359
con non so con un master

1628
01:06:45,359 --> 01:06:47,339
è diverso rispetto  a quanto guadagnerei

1629
01:06:47,339 --> 01:06:48,359


1630
01:06:48,359 --> 01:06:50,819
20 anni fa con una laurea magistrale è

1631
01:06:50,819 --> 01:06:52,619
diverso ad esempio qui in Italia

1632
01:06:52,619 --> 01:06:55,440
rispetto ad altri paesi e tutte quelle

1633
01:06:55,440 --> 01:06:57,000
variabili che non sono sotto il tuo

1634
01:06:57,000 --> 01:06:58,859
controllo non puoi modellarle usando la tua

1635
01:06:58,859 --> 01:07:00,359
rete di visione

1636
01:07:00,359 --> 01:07:03,480
ma ci sono va bene quindi tu

1637
01:07:03,480 --> 01:07:05,220
non puoi ignorarli quando

1638
01:07:05,220 --> 01:07:07,559
vuoi trarre delle conclusioni quindi lui è sì è

1639
01:07:07,559 --> 01:07:08,760
praticamente tutto ciò che

1640
01:07:08,760 --> 01:07:10,079
non puoi controllare

1641
01:07:10,079 --> 01:07:13,079
puoi dedurli quindi puoi

1642
01:07:13,079 --> 01:07:14,819
eseguire un'inferenza controfattuale

1643
01:07:14,819 --> 01:07:16,740
indietro nel tempo e dire oh 20

1644
01:07:16,740 --> 01:07:19,020
anni fa me lo sarei guadagnato  molto

1645
01:07:19,020 --> 01:07:20,640
se io

1646
01:07:20,640 --> 01:07:22,559
fossi così intelligente che questo

1647
01:07:22,559 --> 01:07:24,599
grado in media ovviamente

1648
01:07:24,599 --> 01:07:27,059
e ma non è che posso cambiare le

1649
01:07:27,059 --> 01:07:30,720
politiche del governo verso posti di lavoro o

1650
01:07:30,720 --> 01:07:32,819
cose del genere

1651
01:07:32,819 --> 01:07:35,099
è un controfattuale più profondo

1652
01:07:35,099 --> 01:07:38,400
sì esattamente quindi sì quelli sono l'uso

1653
01:07:38,400 --> 01:07:40,200
fantastico va bene

1654
01:07:40,200 --> 01:07:42,480
avere  hai implementato le

1655
01:07:42,480 --> 01:07:45,660
coordinate generalizzate nella codifica predittiva

1656
01:07:45,660 --> 01:07:46,920
no non l'

1657
01:07:46,920 --> 01:07:50,039
ho mai fatto l'ho uh

1658
01:07:50,039 --> 01:07:52,680
sì l'ho studiato ma l'ho uh

1659
01:07:52,680 --> 01:07:55,260
non l'ho mai implementato so che tendono ad

1660
01:07:55,260 --> 01:07:57,599
essere instabili e uh

1661
01:07:57,599 --> 01:08:00,299
ed è  molto difficile renderli stabili,

1662
01:08:00,299 --> 01:08:02,940
penso che sia questo il punto

1663
01:08:02,940 --> 01:08:05,460
che ho tratto dal parlare con le persone che

1664
01:08:05,460 --> 01:08:08,359
li hanno implementati,

1665
01:08:08,400 --> 01:08:11,039
ma sì sì, sono a conoscenza di alcuni

1666
01:08:11,039 --> 01:08:12,839
documenti che sono usciti di recente

1667
01:08:12,839 --> 01:08:15,599
su di loro che sono stati testati su

1668
01:08:15,599 --> 01:08:18,000
un carico britannico  stile codificatore in realtà

1669
01:08:18,000 --> 01:08:20,520
penso che ancora da Baron ci sia

1670
01:08:20,520 --> 01:08:22,979
un articolo là fuori che è uscito la

1671
01:08:22,979 --> 01:08:25,439
scorsa estate ma no, non ci ho mai giocato

1672
01:08:25,439 --> 01:08:26,580
con loro io stesso figo

1673
01:08:26,580 --> 01:08:29,160
pagliaccetto l'

1674
01:08:29,160 --> 01:08:32,040
aggiunta di più livelli nella gerarchia

1675
01:08:32,040 --> 01:08:35,160
riduce il problema di distrazione di

1676
01:08:35,160 --> 01:08:38,238
prevedere l'input

1677
01:08:38,939 --> 01:08:41,698
aggiungendo altro  livello in uh

1678
01:08:41,698 --> 01:08:43,439
in che senso perché il

1679
01:08:43,439 --> 01:08:45,779
problema della distruzione è dato da Cycles quindi in pratica

1680
01:08:45,779 --> 01:08:47,399
fornisci un'immagine

1681
01:08:47,399 --> 01:08:49,920
e il fatto che tu abbia uh

1682
01:08:49,920 --> 01:08:53,279
così patch che escono dall'immagine andando

1683
01:08:53,279 --> 01:08:55,799
nei neuroni e poi altri bordi

1684
01:08:55,799 --> 01:08:57,500
che tornano indietro

1685
01:08:57,500 --> 01:08:59,939
questo fondamentalmente crea il fatto che

1686
01:08:59,939 --> 01:09:03,560
hai un errore che quelli fondamentalmente

1687
01:09:03,560 --> 01:09:06,179
questi in entrata si adattano ai pixel

1688
01:09:06,179 --> 01:09:08,339
dell'immagine creano alcuni

1689
01:09:08,339 --> 01:09:09,719
errori di previsione quindi hai alcuni

1690
01:09:09,719 --> 01:09:12,140
errori di previsione che si diffondono all'interno del modello

1691
01:09:12,140 --> 01:09:14,640
e questo è sì e questo problema penso

1692
01:09:14,640 --> 01:09:16,979
sia generale di cicli e  probabilmente

1693
01:09:16,979 --> 01:09:21,439
non è correlato alla gerarchia in generale ai

1694
01:09:23,060 --> 01:09:25,140
pixel

1695
01:09:25,140 --> 01:09:26,759
se non hai bordi in entrata

1696
01:09:26,759 --> 01:09:27,660
non hai

1697
01:09:27,660 --> 01:09:30,540
più nessun problema di distruzione

1698
01:09:30,540 --> 01:09:33,238
interessante e e la specifica della

1699
01:09:33,238 --> 01:09:35,939
rete aciclica attraverso l'operatore di traccia

1700
01:09:35,939 --> 01:09:37,859


1701
01:09:37,859 --> 01:09:41,819
che è una tecnica molto interessante e

1702
01:09:41,819 --> 01:09:46,339
quando è stata portata  in gioco

1703
01:09:46,560 --> 01:09:49,140
uh per quanto ne so penso che sia uscito

1704
01:09:49,140 --> 01:09:52,380
con il documento che ho citato nel 2018

1705
01:09:52,380 --> 01:09:54,360
non lo so almeno nella

1706
01:09:54,360 --> 01:09:56,940
letteratura sull'inferenza causale non sono a conoscenza

1707
01:09:56,940 --> 01:09:59,699
di alcun metodo precedente direi di no

1708
01:09:59,699 --> 01:10:01,860
perché quello  Voglio dire, questo è il

1709
01:10:01,860 --> 01:10:04,140
documento molto citato, quindi direi che sono usciti

1710
01:10:04,140 --> 01:10:05,520
con quell'idea

1711
01:10:05,520 --> 01:10:07,980
wow sì, è abbastanza carino che

1712
01:10:07,980 --> 01:10:09,480
tu possa fare la discesa del gradiente e imparare

1713
01:10:09,480 --> 01:10:11,400
la struttura Penso che sia

1714
01:10:11,400 --> 01:10:14,219
una tecnica molto potente sì

1715
01:10:14,219 --> 01:10:15,840
a volte è come quando guardi

1716
01:10:15,840 --> 01:10:17,640
quando sono diventate disponibili

1717
01:10:17,640 --> 01:10:19,440
diverse caratteristiche dell'inferenza bayesiana e

1718
01:10:19,440 --> 01:10:23,159
dell'inferenza causale,

1719
01:10:23,159 --> 01:10:25,620
è davvero notevole come perché perché

1720
01:10:25,620 --> 01:10:28,500
questo non è stato fatto in un

1721
01:10:28,500 --> 01:10:30,719
quadro di modellazione causale bayesiana è come

1722
01:10:30,719 --> 01:10:32,760
perché sono passati solo dai cinque ai

1723
01:10:32,760 --> 01:10:36,659
25 anni in cui questo è accaduto

1724
01:10:36,659 --> 01:10:39,960
e quindi è molto molto breve  ed

1725
01:10:39,960 --> 01:10:42,060
è anche relativamente tecnico, quindi ci sono

1726
01:10:42,060 --> 01:10:43,920
relativamente pochi gruppi di ricerca impegnati

1727
01:10:43,920 --> 01:10:46,920
in esso e um è

1728
01:10:46,920 --> 01:10:49,860
davvero fantastico ciò che sta consentendo

1729
01:10:49,860 --> 01:10:51,960
no sì sì esattamente voglio dire che è anche

1730
01:10:51,960 --> 01:10:54,179
penso che la parte eccitante di questo campo

1731
01:10:54,179 --> 01:10:56,040
sia un po 'uh voglio dire che ci sono

1732
01:10:56,040 --> 01:10:59,100
sicuramente  scoperte là fuori che devono

1733
01:10:59,100 --> 01:11:01,020
ancora essere scoperte e probabilmente mi

1734
01:11:01,020 --> 01:11:03,000
piacciono perché, ad esempio, per

1735
01:11:03,000 --> 01:11:05,300
quanto sia stata una svolta quella carta che hanno

1736
01:11:05,300 --> 01:11:07,800
trovato uh

1737
01:11:07,800 --> 01:11:09,960
come hanno semplicemente scoperto il giusto

1738
01:11:09,960 --> 01:11:12,120
precedente per le strutture acicliche

1739
01:11:12,120 --> 01:11:14,040
okay è un

1740
01:11:14,040 --> 01:11:17,100
sì, voglio dire, non lo so  esattamente, ma

1741
01:11:17,100 --> 01:11:19,080
potrebbe essere un'idea che ti viene in un

1742
01:11:19,080 --> 01:11:21,120
pomeriggio, non conosco la storia

1743
01:11:21,120 --> 01:11:23,040
di come gli altri se ne siano inventati,

1744
01:11:23,040 --> 01:11:25,320
ma potrebbe potenzialmente essere che loro

1745
01:11:25,320 --> 01:11:27,239
sono lì alla lavagna, sei

1746
01:11:27,239 --> 01:11:29,280
tipo oh, quello in realtà  funziona è un

1747
01:11:29,280 --> 01:11:32,159
enorme passo avanti e ho semplicemente sì

1748
01:11:32,159 --> 01:11:33,960
definito il precedente

1749
01:11:33,960 --> 01:11:36,739
e anche molte di queste scoperte

1750
01:11:36,739 --> 01:11:40,500
non si limitano a impilare non è come

1751
01:11:40,500 --> 01:11:44,280
una uh uh una torre di blocchi che

1752
01:11:44,280 --> 01:11:47,640
sovrappongono e compongono quindi qualcosa

1753
01:11:47,640 --> 01:11:50,159
sarà generalizzato a um

1754
01:11:50,159 --> 01:11:52,140
coordinate generalizzate o sincronia generalizzata o

1755
01:11:52,140 --> 01:11:55,020
grafici arbitrariamente grandi o

1756
01:11:55,020 --> 01:11:57,239
um Sensor Fusion con input multimodali

1757
01:11:57,239 --> 01:12:00,679
ed è come se tutti si fondessero in

1758
01:12:00,679 --> 01:12:03,659
modi davvero soddisfacenti ed efficaci, quindi anche

1759
01:12:03,659 --> 01:12:05,640
le piccole cose che di nuovo qualcuno può

1760
01:12:05,640 --> 01:12:08,100
inventare in un momento

1761
01:12:08,100 --> 01:12:11,100
um possono davvero avere un impatto

1762
01:12:11,100 --> 01:12:14,159
um  okay ml Dawn dice grazie mille per

1763
01:12:14,159 --> 01:12:16,199
aver posto le mie domande e grazie mille

1764
01:12:16,199 --> 01:12:18,060
a Tomaso per la presentazione stimolante

1765
01:12:18,060 --> 01:12:21,360
così bella oh grazie mille e poi

1766
01:12:21,360 --> 01:12:23,280
Bert chiede

1767
01:12:23,280 --> 01:12:25,560
in che modo i modelli linguistici che usano la

1768
01:12:25,560 --> 01:12:27,179
codifica predittiva differirebbero da quelli che

1769
01:12:27,179 --> 01:12:30,260
usano Transformers

1770
01:12:31,679 --> 01:12:32,520
um

1771
01:12:32,520 --> 01:12:35,340
ok penso che in realtà  se

1772
01:12:35,340 --> 01:12:36,659
dovessi costruire oggi un modello linguistico

1773
01:12:36,659 --> 01:12:38,640
usando la codifica predittiva userò ancora

1774
01:12:38,640 --> 01:12:40,020
i Transformer

1775
01:12:40,020 --> 01:12:41,880
quindi l'idea è che per esempio se hai

1776
01:12:41,880 --> 01:12:42,780


1777
01:12:42,780 --> 01:12:45,659
diciamo questo modello grafico gerarchico

1778
01:12:45,659 --> 01:12:48,440
di questa o queste

1779
01:12:48,440 --> 01:12:50,460
reti bayesiane gerarchiche che

1780
01:12:50,460 --> 01:12:53,100
ho definito nell'in  il primissimo fa

1781
01:12:53,100 --> 01:12:55,380
scorrere una freccia per codificare una funzione

1782
01:12:55,380 --> 01:12:57,300
che è la mappa lineare

1783
01:12:57,300 --> 01:12:59,219
ok, quindi un'ora era semplicemente la

1784
01:12:59,219 --> 01:13:01,080
moltiplicazione di a del vettore

1785
01:13:01,080 --> 01:13:03,060
codificato nelle variabili latenti

1786
01:13:03,060 --> 01:13:06,300
per questa matrice di peso che puoi quindi

1787
01:13:06,300 --> 01:13:08,580
rendere non lineare e cose del genere  ma in

1788
01:13:08,580 --> 01:13:09,960
realtà può essere qualcosa di molto più

1789
01:13:09,960 --> 01:13:12,179
complesso la funzione inclusa nella

1790
01:13:12,179 --> 01:13:14,880
freccia può essere una convoluzione può essere un

1791
01:13:14,880 --> 01:13:16,800
meccanismo di attenzione

1792
01:13:16,800 --> 01:13:20,820
quindi quindi in realtà come lo farei

1793
01:13:20,820 --> 01:13:23,880
userò comunque intendo che è effettivamente

1794
01:13:23,880 --> 01:13:26,460
il modo in cui l'abbiamo fatto in uh  nell'Oxford

1795
01:13:26,460 --> 01:13:28,860
Group lo scorso anno abbiamo

1796
01:13:28,860 --> 01:13:30,900
esattamente la struttura in cui ogni freccia è un

1797
01:13:30,900 --> 01:13:33,420
Transformer ora, quindi uno è il

1798
01:13:33,420 --> 01:13:35,159
meccanismo dell'attenzione e il successivo è la

1799
01:13:35,159 --> 01:13:38,219
rete di feed forward come Transformers

1800
01:13:38,219 --> 01:13:40,020
e fondamentalmente l'unica differenza che

1801
01:13:40,020 --> 01:13:41,640
hai è che quelli  variabili si

1802
01:13:41,640 --> 01:13:43,739
desidera calcolare il posteriore e si

1803
01:13:43,739 --> 01:13:45,239
rendono tali posteriori Indipendenza

1804
01:13:45,239 --> 01:13:47,400
indipendente tramite approssimazione del campo medio VIA

1805
01:13:47,400 --> 01:13:49,560
quindi in pratica si seguono

1806
01:13:49,560 --> 01:13:51,659
tutti i passaggi che consentono di

1807
01:13:51,659 --> 01:13:53,520
convergere fino

1808
01:13:53,520 --> 01:13:56,520
all'energia libera di variazione della codifica creativa ma il

1809
01:13:56,520 --> 01:13:58,199
modo in cui si  calcola le previsioni

1810
01:13:58,199 --> 01:14:01,199
e il modo in cui invii i segnali

1811
01:14:01,199 --> 01:14:04,739
è uh è fatto tramite Transformer

1812
01:14:04,739 --> 01:14:07,560
quindi userò ancora Transformers in

1813
01:14:07,560 --> 01:14:10,679
generale Voglio dire che funzionano così bene che

1814
01:14:10,679 --> 01:14:12,840
non penso che possiamo essere arroganti

1815
01:14:12,840 --> 01:14:15,060
e dire oh no lo farò  meglio tramite

1816
01:14:15,060 --> 01:14:17,640
un metodo di codifica puramente predittivo,

1817
01:14:17,640 --> 01:14:18,920


1818
01:14:18,920 --> 01:14:21,480
ma si avvicinerà comunque a Transformers,

1819
01:14:21,480 --> 01:14:22,500


1820
01:14:22,500 --> 01:14:24,420
mi dispiace, hai detto che l'apprendimento della struttura si

1821
01:14:24,420 --> 01:14:27,540
avvicinerebbe all'approccio di Transformer

1822
01:14:27,540 --> 01:14:29,219
sì, l'apprendimento della struttura che ho menzionato

1823
01:14:29,219 --> 01:14:32,640
prima in uh quando qualcuno chiede

1824
01:14:32,640 --> 01:14:34,800
le somiglianze tra la codifica creativa

1825
01:14:34,800 --> 01:14:38,060
e il meccanismo di attenzione

1826
01:14:38,280 --> 01:14:41,699
molto sì molto  interessante

1827
01:14:41,699 --> 01:14:42,900
um

1828
01:14:42,900 --> 01:14:45,719
una cosa che mi chiedo da Amazon

1829
01:14:45,719 --> 01:14:47,640
non riuscivo a vedere il concetto di profondità

1830
01:14:47,640 --> 01:14:49,380
nelle reti di codifica predittiva che hai

1831
01:14:49,380 --> 01:14:50,880
citato molto probabilmente mi mancava la

1832
01:14:50,880 --> 01:14:52,380
definizione fornita per la

1833
01:14:52,380 --> 01:14:56,480
codifica predittiva riguardava il concetto di profondità

1834
01:14:56,640 --> 01:14:59,460
cosa intendevi per profondità

1835
01:14:59,460 --> 01:15:02,219
no sì è vero  è uh perché la

1836
01:15:02,219 --> 01:15:04,980
definizione standard come ho detto più

1837
01:15:04,980 --> 01:15:06,960
volte è a è gerarchica hai delle

1838
01:15:06,960 --> 01:15:08,400
previsioni che vanno in una direzione qualche

1839
01:15:08,400 --> 01:15:09,719
errore di previsione che va nella direzione opposta

1840
01:15:09,719 --> 01:15:10,620


1841
01:15:10,620 --> 01:15:14,340
fondamentalmente cosa uh quello che abbiamo fatto in questo

1842
01:15:14,340 --> 01:15:16,320
articolo e anche nell'ultimo in uh

1843
01:15:16,320 --> 01:15:18,420
che si chiama  L'apprendimento su

1844
01:15:18,420 --> 01:15:19,920
topologie di grafi arbitrari che abbiamo una

1845
01:15:19,920 --> 01:15:22,260
codifica relativa è che possiamo considerare la

1846
01:15:22,260 --> 01:15:25,620
profondità uh come una

1847
01:15:25,620 --> 01:15:28,380


1848
01:15:28,380 --> 01:15:31,380
coppia indipendente uh fondamentalmente di variabile latente

1849
01:15:31,380 --> 01:15:33,239
variabile latente e freccia

1850
01:15:33,239 --> 01:15:34,739
e hai previsioni che vanno in quella

1851
01:15:34,739 --> 01:15:36,300
direzione e previsione Freccia che va

1852
01:15:36,300 --> 01:15:38,340
con l'altra ma poi tu  puoi comporli

1853
01:15:38,340 --> 01:15:41,880
in quanti um molti modi così puoi puoi

1854
01:15:41,880 --> 01:15:45,239
quindi in pratica questa

1855
01:15:45,239 --> 01:15:47,040
composizione non deve essere

1856
01:15:47,040 --> 01:15:48,659
gerarchica alla fine

1857
01:15:48,659 --> 01:15:50,820
può avere Cicli quindi puoi ad

1858
01:15:50,820 --> 01:15:53,520
esempio collegare un'altra uh un'altra

1859
01:15:53,520 --> 01:15:55,440
variabile latente alla prima  uno e

1860
01:15:55,440 --> 01:15:57,540
poi colleghi gli altri e puoi

1861
01:15:57,540 --> 01:15:59,340
avere una struttura che è intrecciata quanto

1862
01:15:59,340 --> 01:16:00,420
vuoi,

1863
01:16:00,420 --> 01:16:02,699
quindi per esempio nell'altro foglio

1864
01:16:02,699 --> 01:16:04,500
alleniamo

1865
01:16:04,500 --> 01:16:06,659
uh una rete che ha la forma di una

1866
01:16:06,659 --> 01:16:08,460
struttura cerebrale quindi abbiamo un sacco di

1867
01:16:08,460 --> 01:16:09,900
regioni del cervello che sono scarsamente

1868
01:16:09,900 --> 01:16:12,239
collegate all'interno ed è parzialmente

1869
01:16:12,239 --> 01:16:13,860
connesso tra loro

1870
01:16:13,860 --> 01:16:15,719
e non c'è niente di

1871
01:16:15,719 --> 01:16:17,640
gerarchico lì alla fine, ma

1872
01:16:17,640 --> 01:16:18,960
puoi ancora addestrarlo riducendo al minimo l'

1873
01:16:18,960 --> 01:16:20,699
energia libera operativa e

1874
01:16:20,699 --> 01:16:22,620
riducendo al minimo l'errore di previsione totale

1875
01:16:22,620 --> 01:16:25,159
della rete

1876
01:16:25,159 --> 01:16:27,360
in modo da poterlo avere

1877
01:16:27,360 --> 01:16:31,980
per un dato motivo in un grafico aggrovigliato

1878
01:16:31,980 --> 01:16:35,159
potresti vedere tre strati successivi

1879
01:16:35,159 --> 01:16:37,560
che quando li guardi da soli

1880
01:16:37,560 --> 01:16:38,820
diresti oh quello è un edificio a tre piani

1881
01:16:38,820 --> 01:16:41,940
che è un modello a tre strati che dice

1882
01:16:41,940 --> 01:16:43,980
tre adattivi ma poi quando scatti

1883
01:16:43,980 --> 01:16:46,620
un'immagine più grande lì  non è come un

1884
01:16:46,620 --> 01:16:50,280
massimo esplicito o un minimo esplicito a

1885
01:16:50,280 --> 01:16:52,140
quella rete

1886
01:16:52,140 --> 01:16:54,360
sì esatto e questo è fondamentalmente dato

1887
01:16:54,360 --> 01:16:55,980
dal fatto che ogni operazione

1888
01:16:55,980 --> 01:16:58,080
nelle reti predittive coreane è uh è

1889
01:16:58,080 --> 01:16:59,460
strettamente locale

1890
01:16:59,460 --> 01:17:01,739
quindi praticamente ogni messaggio che passa

1891
01:17:01,739 --> 01:17:03,000
ogni previsione e ogni

1892
01:17:03,000 --> 01:17:05,280
errore di previsione  che invii lo invii solo ai

1893
01:17:05,280 --> 01:17:08,280
neuroni molto vicini ok e se

1894
01:17:08,280 --> 01:17:10,380
la struttura globale è effettivamente

1895
01:17:10,380 --> 01:17:13,380
gerarchica o meno il singolo

1896
01:17:13,380 --> 01:17:16,940
messaggio che passa non vede nemmeno che

1897
01:17:17,460 --> 01:17:19,620
immagino sia una specie di

1898
01:17:19,620 --> 01:17:22,820
speranza per l'apprendimento di nuove

1899
01:17:22,820 --> 01:17:27,739
architetture modello è lo spazio di  ciò che è

1900
01:17:27,739 --> 01:17:33,300
progettato dall'alto verso il basso è molto piccolo e

1901
01:17:33,300 --> 01:17:36,480
molti modelli in uso oggi anche se

1902
01:17:36,480 --> 01:17:38,640
modelli super efficaci

1903
01:17:38,640 --> 01:17:41,100
um anche se potresti chiedere effettivo per

1904
01:17:41,100 --> 01:17:43,320
unità di calcolo o meno questa è una

1905
01:17:43,320 --> 01:17:45,300
domanda di secondo livello ma molti

1906
01:17:45,300 --> 01:17:47,580
modelli efficaci oggi non ne hanno alcuni

1907
01:17:47,580 --> 01:17:49,860
proprietà delle reti di codifica predittiva

1908
01:17:49,860 --> 01:17:52,739
come la loro capacità

1909
01:17:52,739 --> 01:17:55,520
di utilizzare solo calcoli locali

1910
01:17:55,520 --> 01:17:59,400
che danno realismo biologico

1911
01:17:59,400 --> 01:18:02,880
um o solo realismo spazio-temporale ma

1912
01:18:02,880 --> 01:18:06,060
possono anche fornire molti vantaggi in

1913
01:18:06,060 --> 01:18:08,159


1914
01:18:08,159 --> 01:18:10,500
impostazioni di calcolo federato o calcolo distribuito

1915
01:18:10,500 --> 01:18:12,780
no sì esattamente sono completamente d'accordo

1916
01:18:12,780 --> 01:18:14,520
perché io  penso che l'idea in generale sia

1917
01:18:14,520 --> 01:18:16,679
questa e non so se sarà

1918
01:18:16,679 --> 01:18:18,540
un vantaggio, quindi penso che sia molto

1919
01:18:18,540 --> 01:18:20,159
promettente esattamente per i motivi che hai

1920
01:18:20,159 --> 01:18:20,880
detto

1921
01:18:20,880 --> 01:18:22,920
e uh e il motivo è che la

1922
01:18:22,920 --> 01:18:25,380
stringa del modello di oggi con propagazione all'indietro

1923
01:18:25,380 --> 01:18:28,860
puoi sostanzialmente riassumere  loro come

1924
01:18:28,860 --> 01:18:32,040
monitoraggio della propagazione all'indietro è una

1925
01:18:32,040 --> 01:18:34,080
funzione perché fondamentalmente hai una

1926
01:18:34,080 --> 01:18:36,120
mappa dall'input all'output e la

1927
01:18:36,120 --> 01:18:39,600
propagazione all'indietro fondamentalmente diffonde le

1928
01:18:39,600 --> 01:18:41,699
informazioni dal suo

1929
01:18:41,699 --> 01:18:44,340
grafico computazionale quindi ogni

1930
01:18:44,340 --> 01:18:45,960
modello di rete neurale della rete neurale utilizzato oggi

1931
01:18:45,960 --> 01:18:48,960
è una funzione durante la codifica predittiva

1932
01:18:48,960 --> 01:18:51,179
e un'altra codifica liberativa come la

1933
01:18:51,179 --> 01:18:53,820
vecchia classe di funzioni che la classe di

1934
01:18:53,820 --> 01:18:56,040
metodi che si addestrano nell'uso di

1935
01:18:56,040 --> 01:18:58,500
calcoli locali e in realtà funzionano

1936
01:18:58,500 --> 01:19:01,620
minimizzando una funzione di energia globale,

1937
01:19:01,620 --> 01:19:03,840
non si limitano a modellare le funzioni

1938
01:19:03,840 --> 01:19:05,940
dall'input all'output, in realtà modellano

1939
01:19:05,940 --> 01:19:07,739
qualcosa che quello  in un certo senso assomiglia ai

1940
01:19:07,739 --> 01:19:10,080
sistemi fisici, quindi hai un

1941
01:19:10,080 --> 01:19:13,500
sistema fisico a cui fissi alcuni valori a

1942
01:19:13,500 --> 01:19:15,360
qualunque input tu abbia e lasci che il

1943
01:19:15,360 --> 01:19:17,280
sistema converga e poi leggi qualche

1944
01:19:17,280 --> 01:19:19,980
altro valore di uh neuroni o variabili

1945
01:19:19,980 --> 01:19:21,960
che dovrebbero essere emesse ma questo

1946
01:19:21,960 --> 01:19:24,120
sistema fisico no  non deve essere una

1947
01:19:24,120 --> 01:19:25,920
mappa fit forward non deve essere una

1948
01:19:25,920 --> 01:19:28,260
funzione che ha uno spazio di input e

1949
01:19:28,260 --> 01:19:30,659
uno spazio di output ed è

1950
01:19:30,659 --> 01:19:32,580
così la classe di modelli che puoi

1951
01:19:32,580 --> 01:19:34,800
imparare è uh quindi in pratica puoi vedere

1952
01:19:34,800 --> 01:19:37,560
come modelli di feed forward  e funzioni

1953
01:19:37,560 --> 01:19:39,600
e poi una classe molto più grande che è

1954
01:19:39,600 --> 01:19:41,880
quella dei sistemi fisici se c'è

1955
01:19:41,880 --> 01:19:43,860
qualcosa di interessante qui fuori non lo so

1956
01:19:43,860 --> 01:19:45,659
ancora perché le funzioni

1957
01:19:45,659 --> 01:19:47,460
funzionano molto bene stiamo vedendo

1958
01:19:47,460 --> 01:19:50,040
quei giorni con la propagazione all'indietro è un

1959
01:19:50,040 --> 01:19:52,199
lavoro pazzesco ma

1960
01:19:52,199 --> 01:19:53,460
quindi sì  Non so se c'è qualcosa di

1961
01:19:53,460 --> 01:19:56,040
interessante nella parte importante, ma la

1962
01:19:56,040 --> 01:19:58,380
parte importante è che è abbastanza grande, ok, ci

1963
01:19:58,380 --> 01:20:00,480
sono molti modelli che non

1964
01:20:00,480 --> 01:20:02,940
puoi riportare alla propagazione e

1965
01:20:02,940 --> 01:20:04,679
puoi allenarti con la codifica creativa

1966
01:20:04,679 --> 01:20:06,659
o la propagazione del bagno o altri

1967
01:20:06,659 --> 01:20:07,860
metodi

1968
01:20:07,860 --> 01:20:10,440
questo è super interessante certamente i

1969
01:20:10,440 --> 01:20:12,719
sistemi biologici i sistemi fisici

1970
01:20:12,719 --> 01:20:15,900
risolvono tutti i tipi di problemi interessanti

1971
01:20:15,900 --> 01:20:17,100
um

1972
01:20:17,100 --> 01:20:19,380
ma non c'è ancora pranzo gratis

1973
01:20:19,380 --> 01:20:21,540
nelle specie di formiche che se la cavano davvero bene in

1974
01:20:21,540 --> 01:20:23,100
questo ambiente potrebbero non fare molto bene

1975
01:20:23,100 --> 01:20:25,679
in un altro ambiente e quindi um là fuori

1976
01:20:25,679 --> 01:20:28,260
nell'entroterra

1977
01:20:28,260 --> 01:20:31,820
potrebbero esserci alcuni algoritmi speciali davvero unici

1978
01:20:31,820 --> 01:20:35,880
che non sono ben descritti

1979
01:20:35,880 --> 01:20:38,460
come una funzione,

1980
01:20:38,460 --> 01:20:42,060
ma forniscono comunque un

1981
01:20:42,060 --> 01:20:46,679
modo procedurale per implementare l'euristica

1982
01:20:46,679 --> 01:20:48,840
che potrebbe essere estremamente estremamente

1983
01:20:48,840 --> 01:20:51,120
efficace

1984
01:20:51,120 --> 01:20:53,880
no sì sì esattamente e uh sì tutto

1985
01:20:53,880 --> 01:20:55,679
questo è stato la maggior parte della mia

1986
01:20:55,679 --> 01:20:58,260
attenzione  di ricerca durante il mio dottorato di ricerca, ad

1987
01:20:58,260 --> 01:20:59,100
esempio

1988
01:20:59,100 --> 01:21:01,380
come trovare questa applicazione che è

1989
01:21:01,380 --> 01:21:04,199
come qui fuori e non all'interno delle

1990
01:21:04,199 --> 01:21:06,739
funzioni,

1991
01:21:07,199 --> 01:21:08,820
bene

1992
01:21:08,820 --> 01:21:12,120
dove va questo lavoro da qui come

1993
01:21:12,120 --> 01:21:14,520
quali direzioni sei entusiasta

1994
01:21:14,520 --> 01:21:17,340
e come vedi le persone

1995
01:21:17,340 --> 01:21:19,679
nell'ecosistema di inferenza attiva ottenere  coinvolta in

1996
01:21:19,679 --> 01:21:22,460
questo tipo di lavoro,

1997
01:21:22,500 --> 01:21:24,840
penso che sia molto probabilmente la

1998
01:21:24,840 --> 01:21:27,780
regia più promettente che è

1999
01:21:27,780 --> 01:21:30,060
uh lei è qualcosa che forse mi piacerebbe

2000
01:21:30,060 --> 01:21:33,060
esplorare un po' è come ho detto,

2001
01:21:33,060 --> 01:21:34,980
c'è davvero da andare dietro a

2002
01:21:34,980 --> 01:21:37,380
modelli statici quindi tutto ciò che ho mostrato

2003
01:21:37,380 --> 01:21:40,260
Finora ho mostrato che si tratta di dati statici,

2004
01:21:40,260 --> 01:21:42,840
quindi i dati non cambiano nel tempo

2005
01:21:42,840 --> 01:21:45,780
non c'è tempo all'interno della definizione di

2006
01:21:45,780 --> 01:21:48,000
codice creativo così com'è come l'ho presentato

2007
01:21:48,000 --> 01:21:49,080
qui,

2008
01:21:49,080 --> 01:21:50,940
tuttavia puoi ad esempio generalizzare il

2009
01:21:50,940 --> 01:21:53,280
codice creativo per funzionare  con

2010
01:21:53,280 --> 01:21:55,800
dati temporali usando coordinate generalizzate come

2011
01:21:55,800 --> 01:21:58,800
hai detto prima uh

2012
01:21:58,800 --> 01:22:01,380
presentandolo come un comune

2013
01:22:01,380 --> 01:22:04,140
modello generativo del filtro di Kalman

2014
01:22:04,140 --> 01:22:08,040
ed è qui che, ad esempio, la

2015
01:22:08,040 --> 01:22:09,900
direzione dell'inferenza causale potrebbe essere molto

2016
01:22:09,900 --> 01:22:12,600
utile perché sì quel modello uh a

2017
01:22:12,600 --> 01:22:14,400
quel punto forse puoi  essere in grado di

2018
01:22:14,400 --> 01:22:17,880
modellare una maggiore causalità e uh e una causa dinamica dei modelli più

2019
01:22:17,880 --> 01:22:21,780
complessa e utile uh

2020
01:22:21,780 --> 01:22:24,780
fondamentalmente

2021
01:22:24,780 --> 01:22:26,940
perché in generale il do calcolo

2022
01:22:26,940 --> 01:22:28,560
e il

2023
01:22:28,560 --> 01:22:32,760
ramo della scienza interventistica e controfattuale uh è

2024
01:22:32,760 --> 01:22:36,000
per lo più sviluppato su piccoli modelli

2025
01:22:36,000 --> 01:22:38,159
quindi è

2026
01:22:38,159 --> 01:22:40,739
come se non lo facessi  t fare interventi su

2027
01:22:40,739 --> 01:22:43,560
modelli giganteschi in generale, quindi se

2028
01:22:43,560 --> 01:22:45,800
guardi ai dati medici, loro usano

2029
01:22:45,800 --> 01:22:50,159
reti di visione relativamente piccole e,

2030
01:22:50,159 --> 01:22:51,179
naturalmente, se vuoi avere un

2031
01:22:51,179 --> 01:22:54,900
modello causale dinamico che modella uh un

2032
01:22:54,900 --> 01:22:56,340
ambiente specifico o una

2033
01:22:56,340 --> 01:22:58,620
realtà specifica hai un  molti neuroni dentro di

2034
01:22:58,620 --> 01:23:00,780
te hanno molte variabili latenti che

2035
01:23:00,780 --> 01:23:02,580
cambiano nel tempo e un intervento in

2036
01:23:02,580 --> 01:23:05,219
più in un certo momento crea un

2037
01:23:05,219 --> 01:23:07,560
effetto in una fase temporale diversa, quindi forse

2038
01:23:07,560 --> 01:23:09,239
nella fase temporale successiva in 10 diverse

2039
01:23:09,239 --> 01:23:11,699
fasi temporali successive e penso che sarebbe

2040
01:23:11,699 --> 01:23:14,100
essere molto interessante da sviluppare come un

2041
01:23:14,100 --> 01:23:16,380
modo biologicamente plausibile di trasmettere

2042
01:23:16,380 --> 01:23:17,699
informazioni

2043
01:23:17,699 --> 01:23:20,040
che sia anche in grado di modellare la

2044
01:23:20,040 --> 01:23:22,860
causalità di Grandeur fondamentalmente

2045
01:23:22,860 --> 01:23:24,659
hmm

2046
01:23:24,659 --> 01:23:29,659
dove vedi l'azione in questi modelli

2047
01:23:30,840 --> 01:23:33,840
dove vedo l'azione a cui

2048
01:23:33,840 --> 01:23:36,480
non ho pensato che

2049
01:23:36,480 --> 01:23:38,760
penso come le azioni in quei  modelli

2050
01:23:38,760 --> 01:23:41,460
forse nello stesso modo in cui io come vedi in

2051
01:23:41,460 --> 01:23:43,080
altri modelli perché la

2052
01:23:43,080 --> 01:23:44,940
codifica creativa è fondamentalmente un modello di

2053
01:23:44,940 --> 01:23:46,260
percezione

2054
01:23:46,260 --> 01:23:49,260
quindi quindi un'azione è puoi vedere che c'è una

2055
01:23:49,260 --> 01:23:52,739
conseguenza di ciò che stai vivendo

2056
01:23:52,739 --> 01:23:55,159
quindi cambiando il modo in cui stai

2057
01:23:55,159 --> 01:23:57,840
sperimentando qualcosa allora tu  puoi

2058
01:23:57,840 --> 01:24:00,060
calcolare forse puoi semplicemente eseguire

2059
01:24:00,060 --> 01:24:01,800
un'azione più intelligente ora che hai più

2060
01:24:01,800 --> 01:24:03,000
informazioni

2061
01:24:03,000 --> 01:24:04,560
ma sì,

2062
01:24:04,560 --> 01:24:06,960
non penso che l'azione sia molto

2063
01:24:06,960 --> 01:24:10,199
facile come sì, non vedo alcuna

2064
01:24:10,199 --> 01:24:12,540
conseguenza esplicita delle azioni oltre al fatto

2065
01:24:12,540 --> 01:24:14,040
che questo può permetterti di fondamentalmente

2066
01:24:14,040 --> 01:24:15,960
forse trai

2067
01:24:15,960 --> 01:24:18,780
semplicemente conclusioni migliori per loro

2068
01:24:18,780 --> 01:24:21,719
eseguire azioni in futuro

2069
01:24:21,719 --> 01:24:23,940
aggiungerò alcuni modi in cui

2070
01:24:23,940 --> 01:24:25,920
le persone hanno uh parlato di

2071
01:24:25,920 --> 01:24:29,340
codifica predittiva e azione uh prima di tutto

2072
01:24:29,340 --> 01:24:33,960
l'azione interna o l'azione nascosta è l'attenzione in modo che

2073
01:24:33,960 --> 01:24:36,120
possiamo pensare alla percezione  come

2074
01:24:36,120 --> 01:24:37,980
azione interna che è un approccio

2075
01:24:37,980 --> 01:24:40,560
un altro approccio abbastanza micro sono gli

2076
01:24:40,560 --> 01:24:42,840
output di un dato nodo possiamo

2077
01:24:42,840 --> 01:24:45,780
intendere quel nodo come una

2078
01:24:45,780 --> 01:24:48,780
cosa particolare con i suoi stati sensoriali cognitivi e di

2079
01:24:48,780 --> 01:24:52,080
azione e quindi in quel senso

2080
01:24:52,080 --> 01:24:54,960
l'output di un nodo e infine

2081
01:24:54,960 --> 01:24:57,179
quale  abbiamo esplorato un po 'nel live

2082
01:24:57,179 --> 01:24:59,940
streaming 43 sulla revisione teorica sulla

2083
01:24:59,940 --> 01:25:02,100
codifica predittiva che stiamo leggendo fino in

2084
01:25:02,100 --> 01:25:03,840
fondo ed era tutto sulla

2085
01:25:03,840 --> 01:25:05,460
percezione tutto sulla percezione e poi

2086
01:25:05,460 --> 01:25:08,040
era come la sezione 5.3

2087
01:25:08,040 --> 01:25:11,719
se hai aspettative sull'azione

2088
01:25:11,719 --> 01:25:15,900
allora l'azione è solo  un'altra variabile in

2089
01:25:15,900 --> 01:25:18,120
questa architettura e che è davvero

2090
01:25:18,120 --> 01:25:20,040
allineata con l'inferenza inattiva dove

2091
01:25:20,040 --> 01:25:21,659
invece di avere come una funzione di ricompensa o

2092
01:25:21,659 --> 01:25:24,000
utilità che massimizziamo

2093
01:25:24,000 --> 01:25:26,699
selezioniamo l'azione in base al fatto che è la

2094
01:25:26,699 --> 01:25:28,800
linea d'azione più probabile il percorso

2095
01:25:28,800 --> 01:25:30,900
dell'azione minima che è la meccanica bayesiana

2096
01:25:30,900 --> 01:25:33,300
e quindi è in realtà molto  naturale

2097
01:25:33,300 --> 01:25:36,420
introdurre una variabile di azione e

2098
01:25:36,420 --> 01:25:40,800
utilizzarla essenzialmente come se fosse una

2099
01:25:40,800 --> 01:25:43,260
previsione su qualcos'altro in modo

2100
01:25:43,260 --> 01:25:45,540
più ricettivo nel mondo perché

2101
01:25:45,540 --> 01:25:48,480
anche noi ci aspettiamo un'azione

2102
01:25:48,480 --> 01:25:50,820
no sì sì esattamente

2103
01:25:50,820 --> 01:25:52,860
no Mi piace molto il modo di definire le azioni

2104
01:25:52,860 --> 01:25:55,260
in realtà e  uh e penso ancora che

2105
01:25:55,260 --> 01:25:57,239
ad esempio non ci siano

2106
01:25:57,239 --> 01:26:01,139
così tanti documenti che applicano questo metodo,

2107
01:26:01,139 --> 01:26:03,239
penso che ci siano un paio di uh da

2108
01:26:03,239 --> 01:26:05,100
Alexander o robria fa qualcosa

2109
01:26:05,100 --> 01:26:08,580
di simile ma in pratica come al di fuori

2110
01:26:08,580 --> 01:26:10,920
della pura inferenza attiva come applicare la

2111
01:26:10,920 --> 01:26:13,260
codifica predittiva  e le azioni per

2112
01:26:13,260 --> 01:26:15,980
risolvere problemi pratici non sono state uh

2113
01:26:15,980 --> 01:26:19,280
esplorate molto

2114
01:26:19,679 --> 01:26:23,400
vabbè grazie per questa eccellente

2115
01:26:23,400 --> 01:26:25,199
presentazione e discussione c'è

2116
01:26:25,199 --> 01:26:27,659
qualcos'altro che vuoi um dire o

2117
01:26:27,659 --> 01:26:30,300
o indirizzare le persone verso

2118
01:26:30,300 --> 01:26:33,360
uh no solo un grande grazie per avermi invitato

2119
01:26:33,360 --> 01:26:34,620
e uh è

2120
01:26:34,620 --> 01:26:36,120
stato davvero divertente e spero di

2121
01:26:36,120 --> 01:26:38,460
tornare ad un certo punto per un po' di Future

2122
01:26:38,460 --> 01:26:40,199
Works

2123
01:26:40,199 --> 01:26:41,580
fantastico in

2124
01:26:41,580 --> 01:26:45,000
qualsiasi momento in qualsiasi momento grazie Thomas quindi grazie

2125
01:26:45,000 --> 01:26:49,820
Daniel ci vediamo ciao ciao

