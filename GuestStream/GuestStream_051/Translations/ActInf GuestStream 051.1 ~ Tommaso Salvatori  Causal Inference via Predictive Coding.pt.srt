1
00:00:19,020 --> 00:00:21,119
olá e bem-vindo,

2
00:00:21,119 --> 00:00:23,400
é a transmissão de convidados de inferência ativa

3
00:00:23,400 --> 00:00:28,140
número 51.1 em 28 de julho de 2023,

4
00:00:28,140 --> 00:00:31,439
estamos aqui com Tomaso Salvatore e

5
00:00:31,439 --> 00:00:33,840
teremos uma apresentação e uma

6
00:00:33,840 --> 00:00:37,020
discussão sobre o trabalho recente de

7
00:00:37,020 --> 00:00:39,660
inferência causal por meio de codificação preditiva,

8
00:00:39,660 --> 00:00:42,480
muito obrigado por se juntar a quem

9
00:00:42,480 --> 00:00:44,340
está assistindo  ao vivo sinta-se a vontade para escrever

10
00:00:44,340 --> 00:00:47,520
perguntas no chat ao vivo e para

11
00:00:47,520 --> 00:00:50,399
você

12
00:00:50,399 --> 00:00:52,980
obrigado muito obrigado Daniel por

13
00:00:52,980 --> 00:00:56,039
me convidar uh sempre fui um grande fã do

14
00:00:56,039 --> 00:00:57,719
canal e tenho assistido muitos

15
00:00:57,719 --> 00:00:58,920
vídeos

16
00:00:58,920 --> 00:01:01,379
estou bastante  animado por estar aqui e uh e

17
00:01:01,379 --> 00:01:04,260
ser o único a falar desta vez,

18
00:01:04,260 --> 00:01:06,600
então vou falar sobre essas recentes

19
00:01:06,600 --> 00:01:08,700
pré-impressões que publiquei, que têm

20
00:01:08,700 --> 00:01:11,159
sido o trabalho dos últimos meses

21
00:01:11,159 --> 00:01:12,119


22
00:01:12,119 --> 00:01:15,900
e é uma colaboração com a

23
00:01:15,900 --> 00:01:18,659
pesquisa  em Ketty estou em makarak

24
00:01:18,659 --> 00:01:21,600
barami Legend Thomas lukasiavich

25
00:01:21,600 --> 00:01:24,000
e é basicamente um trabalho conjunto entre

26
00:01:24,000 --> 00:01:26,299
versos que é a empresa que trabalho para

27
00:01:26,299 --> 00:01:31,680
a Universidade de Oxford e uhuvian

28
00:01:31,680 --> 00:01:34,200
então

29
00:01:34,200 --> 00:01:36,299
durante esta palestra

30
00:01:36,299 --> 00:01:38,220
eu irei

31
00:01:38,220 --> 00:01:40,979
basicamente o esboço da palestra sobre a qual

32
00:01:40,979 --> 00:01:43,140
irei começar a falar  o que

33
00:01:43,140 --> 00:01:44,520
é codificação preditiva

34
00:01:44,520 --> 00:01:47,659
e as interações dadas do que é

35
00:01:47,659 --> 00:01:51,299
uma breve introdução histórica por que você

36
00:01:51,299 --> 00:01:54,060
acha que é importante estudar a

37
00:01:54,060 --> 00:01:56,159
codificação criativa, mesmo por exemplo, da

38
00:01:56,159 --> 00:01:58,619
perspectiva do aprendizado de máquina,

39
00:01:58,619 --> 00:02:00,720
fornecerei uma

40
00:02:00,720 --> 00:02:04,560
pequena introdução ao que é inferência causal

41
00:02:04,560 --> 00:02:07,200
e  e assim que tivermos todas essas

42
00:02:07,200 --> 00:02:08,880
informações juntas,

43
00:02:08,880 --> 00:02:12,540
discutirei por que escrevi este artigo, qual

44
00:02:12,540 --> 00:02:14,520
foi basicamente a questão de pesquisa que

45
00:02:14,520 --> 00:02:16,560
me inspirou e aos outros

46
00:02:16,560 --> 00:02:18,300
colaboradores

47
00:02:18,300 --> 00:02:21,660
e apresentarei os principais resultados

48
00:02:21,660 --> 00:02:24,980
que são como realizar

49
00:02:24,980 --> 00:02:27,480
inferência, intervenção e

50
00:02:27,480 --> 00:02:29,340
inferência contrafactual

51
00:02:29,340 --> 00:02:33,319
e  como aprender as estruturas causais

52
00:02:33,319 --> 00:02:35,879
de um determinado conjunto de dados usando

53
00:02:35,879 --> 00:02:37,920
codificação preditiva e, é claro,

54
00:02:37,920 --> 00:02:39,959
concluirei com um

55
00:02:39,959 --> 00:02:43,500
pequeno resumo e alguma discussão sobre

56
00:02:43,500 --> 00:02:45,840
por que acredito que este trabalho pode ser de fato

57
00:02:45,840 --> 00:02:49,940
impactante e algumas direções futuras.

58
00:02:50,700 --> 00:02:53,400


59
00:02:53,400 --> 00:02:55,680
é geralmente famoso por

60
00:02:55,680 --> 00:02:58,440
ser um método de aprendizado inspirado na neurociência,

61
00:02:58,440 --> 00:03:01,140
então qual teoria de como o

62
00:03:01,140 --> 00:03:04,560
processamento de informações no cérebro funciona

63
00:03:04,560 --> 00:03:05,819
e,

64
00:03:05,819 --> 00:03:08,400
falando muito formalmente, o nível de

65
00:03:08,400 --> 00:03:10,560
codificação criativa pode ser descrito como

66
00:03:10,560 --> 00:03:12,659
basicamente tendo uma

67
00:03:12,659 --> 00:03:16,319
estrutura hierárquica de neurônios no cérebro

68
00:03:16,319 --> 00:03:19,080
e você  têm duas famílias diferentes de

69
00:03:19,080 --> 00:03:20,700
neurônios no cérebro,

70
00:03:20,700 --> 00:03:23,280
a primeira família é a

71
00:03:23,280 --> 00:03:24,480
encarregada de enviar

72
00:03:24,480 --> 00:03:27,659
informações de previsão, então os neurônios em um

73
00:03:27,659 --> 00:03:29,959
nível específico da hierarquia enviam informações

74
00:03:29,959 --> 00:03:33,959
e preveem a atividade do

75
00:03:33,959 --> 00:03:35,940
nível abaixo

76
00:03:35,940 --> 00:03:38,340
e a segunda família de  neurônio é o

77
00:03:38,340 --> 00:03:41,099
dos neurônios de erro e os neurônios de seta

78
00:03:41,099 --> 00:03:43,019
eles enviam informações de erro de previsão para

79
00:03:43,019 --> 00:03:46,319
cima na hierarquia, então um nível prevê

80
00:03:46,319 --> 00:03:49,200
a atividade do nível abaixo

81
00:03:49,200 --> 00:03:51,659
dessa atividade tem alguma previsão

82
00:03:51,659 --> 00:03:54,239
como alguma incompatibilidade que realmente

83
00:03:54,239 --> 00:03:56,220
aconteceria no nível abaixo

84
00:03:56,220 --> 00:03:57,840
e informações sobre  o

85
00:03:57,840 --> 00:04:02,400
erro de previsão é enviado para a tecla de seta,

86
00:04:02,400 --> 00:04:04,860
no entanto, a codificação preditiva

87
00:04:04,860 --> 00:04:07,220
não foi realmente queimada como uma

88
00:04:07,220 --> 00:04:10,799
neurociência como uma teoria das

89
00:04:10,799 --> 00:04:11,939
neurociências,

90
00:04:11,939 --> 00:04:13,860
mas foi inicialmente desenvolvida

91
00:04:13,860 --> 00:04:16,139
como um método para processamento e

92
00:04:16,139 --> 00:04:19,380
compressão de sinal nos anos 50, então o

93
00:04:19,380 --> 00:04:21,899
trabalho de  Oliver Elias, que na verdade é

94
00:04:21,899 --> 00:04:25,020
contemporâneo de roupas Shannon de

95
00:04:25,020 --> 00:04:26,160
Shannon,

96
00:04:26,160 --> 00:04:27,960
eles perceberam que, uma vez que temos um

97
00:04:27,960 --> 00:04:30,900
preditor, um modelo que funciona

98
00:04:30,900 --> 00:04:33,600
bem na previsão de dados,

99
00:04:33,600 --> 00:04:36,000
enviar mensagens sobre o erro

100
00:04:36,000 --> 00:04:37,919
nessas previsões é realmente muito

101
00:04:37,919 --> 00:04:41,100
mais barato do que enviar a mensagem inteira

102
00:04:41,100 --> 00:04:42,720
a cada  tempo

103
00:04:42,720 --> 00:04:45,240
e foi assim que a codificação bonita nasceu,

104
00:04:45,240 --> 00:04:47,639


105
00:04:47,639 --> 00:04:49,500
como um mecanismo de processamento e compressão de sinal

106
00:04:49,500 --> 00:04:52,020
na teoria da informação nos

107
00:04:52,020 --> 00:04:53,639
anos 50,

108
00:04:53,639 --> 00:04:57,120
foi na verdade nos anos 80 uh que se

109
00:04:57,120 --> 00:04:59,400
tornou exatamente o mesmo modelo

110
00:04:59,400 --> 00:05:01,800
usado em uh

111
00:05:01,800 --> 00:05:03,540
em neurociência

112
00:05:03,540 --> 00:05:07,500
e uh  então, com o trabalho de Mumford ou

113
00:05:07,500 --> 00:05:10,440
outros trabalhos, por exemplo, explique

114
00:05:10,440 --> 00:05:12,960
como a classificação das informações do processo para

115
00:05:12,960 --> 00:05:14,520
obtermos sinais de previsão do

116
00:05:14,520 --> 00:05:17,160
mundo externo e precisamos compactar

117
00:05:17,160 --> 00:05:20,280
essa representação e ter essa

118
00:05:20,280 --> 00:05:22,740
representação interna em nossos neurônios

119
00:05:22,740 --> 00:05:25,199
e o método  é muito semelhante senão

120
00:05:25,199 --> 00:05:27,720
equivalente ao que foi usado que

121
00:05:27,720 --> 00:05:30,419
foi desenvolvido por Elias e Oliver nos

122
00:05:30,419 --> 00:05:32,900
anos 50

123
00:05:32,940 --> 00:05:35,520
talvez o que é a maior Mudança de Paradigma

124
00:05:35,520 --> 00:05:38,100
aconteceu em 1999

125
00:05:38,100 --> 00:05:41,400
graças ao trabalho de cerca de Ballard

126
00:05:41,400 --> 00:05:44,880
em que eles introduziram

127
00:05:44,880 --> 00:05:46,199
este conceito que eu  mencionado anteriormente

128
00:05:46,199 --> 00:05:48,060
sobre estruturas hierárquicas no

129
00:05:48,060 --> 00:05:51,360
cérebro onde as informações de previsão são de

130
00:05:51,360 --> 00:05:54,240
cima para baixo e as informações de erro são de

131
00:05:54,240 --> 00:05:55,560
baixo para cima

132
00:05:55,560 --> 00:05:57,660
e algo que eles fizeram que não foi

133
00:05:57,660 --> 00:05:59,759
feito antes é que

134
00:05:59,759 --> 00:06:02,820
eles explicam e desenvolvem essa teoria

135
00:06:02,820 --> 00:06:05,759
não apenas na França, mas apenas, mas

136
00:06:05,759 --> 00:06:07,979
também  sobre como o aprendizado funciona no

137
00:06:07,979 --> 00:06:10,139
cérebro, então também é uma teoria de como nossas

138
00:06:10,139 --> 00:06:13,139
sinapses são atualizadas

139
00:06:13,139 --> 00:06:16,080
e o último grande avanço sobre o qual

140
00:06:16,080 --> 00:06:17,940
falarei nesta breve

141
00:06:17,940 --> 00:06:21,900
introdução histórica é de 2003, mas

142
00:06:21,900 --> 00:06:25,380
então ele continuou no

143
00:06:25,380 --> 00:06:28,380
anos depois, graças a car freeston, no

144
00:06:28,380 --> 00:06:32,100
qual basicamente ele pegou a teoria de

145
00:06:32,100 --> 00:06:35,039
Robin Ballard e desenvolveu uma,

146
00:06:35,039 --> 00:06:38,400
ele a estendeu e generalizou para

147
00:06:38,400 --> 00:06:40,919
a teoria dos modelos generativos, então

148
00:06:40,919 --> 00:06:42,720
basicamente a principal afirmação que aquele

149
00:06:42,720 --> 00:06:45,479
carfiston fez é que a codificação criativa é

150
00:06:45,479 --> 00:06:48,780
um  Esquema de maximização de evidência de

151
00:06:48,780 --> 00:06:50,340
um tipo específico de modelo generativo

152
00:06:50,340 --> 00:06:52,979
que irei apresentar

153
00:06:52,979 --> 00:06:55,139
mais tarde também

154
00:06:55,139 --> 00:07:00,300
para fazer um breve resumo nos dois

155
00:07:00,300 --> 00:07:01,560
primeiros

156
00:07:01,560 --> 00:07:03,900
uh tipos de canto criativo que

157
00:07:03,900 --> 00:07:05,340
descrevi para processamento e

158
00:07:05,340 --> 00:07:07,020
compressão de sinal e o

159
00:07:07,020 --> 00:07:09,180
processamento de informações na retina e no

160
00:07:09,180 --> 00:07:11,160
cérebro em geral são métodos de inferência

161
00:07:11,160 --> 00:07:12,300


162
00:07:12,300 --> 00:07:14,819
e a maior

163
00:07:14,819 --> 00:07:17,819
mudança a maior revolução que

164
00:07:17,819 --> 00:07:21,120
tivemos em 1999 então digamos que no

165
00:07:21,120 --> 00:07:23,580
século 21 a codificação operativa foi vista

166
00:07:23,580 --> 00:07:25,919
como um algoritmo de aprendizado para que possamos primeiro

167
00:07:25,919 --> 00:07:29,699
comprimir informações  e, em seguida, atualize todas

168
00:07:29,699 --> 00:07:31,800
as sinapses ou todas as variáveis ​​latentes

169
00:07:31,800 --> 00:07:34,139
que temos em nosso modelo generativo para

170
00:07:34,139 --> 00:07:38,599
melhorar nosso próprio modelo generativo,

171
00:07:38,759 --> 00:07:43,199
então vamos dar algumas definições

172
00:07:43,199 --> 00:07:45,000
um pouco mais formais

173
00:07:45,000 --> 00:07:48,479
para que a codificação operativa possa ser vista como um

174
00:07:48,479 --> 00:07:50,220
generativo gaussiano hierárquico  modelo,

175
00:07:50,220 --> 00:07:53,400
então aqui está uma figura muito simples na qual

176
00:07:53,400 --> 00:07:54,780
temos essa estrutura hierárquica

177
00:07:54,780 --> 00:07:58,319
que pode ser tão profunda quanto quisermos

178
00:07:58,319 --> 00:08:01,560
e os sinais de previsão de sinal vão

179
00:08:01,560 --> 00:08:04,620
de uma variável latente XM para a

180
00:08:04,620 --> 00:08:06,599
seguinte e é transformada

181
00:08:06,599 --> 00:08:09,720
toda vez por meio da função GN

182
00:08:09,720 --> 00:08:12,620
ou GI

183
00:08:15,319 --> 00:08:18,180
este é um modelo generativo como eu disse e

184
00:08:18,180 --> 00:08:19,680
qual é a probabilidade marginal deste

185
00:08:19,680 --> 00:08:21,780
modelo generativo bem é simplesmente a

186
00:08:21,780 --> 00:08:24,960
probabilidade do último

187
00:08:24,960 --> 00:08:27,660
você pode ver meu meu cursor sim certo sim

188
00:08:27,660 --> 00:08:29,940
é perfeito então é o modelo genético

189
00:08:29,940 --> 00:08:32,700
do último vértice é a distribuição provavelmente Desculpe

190
00:08:32,700 --> 00:08:34,979
do último vértice vezes

191
00:08:34,979 --> 00:08:37,140
a distribuição de probabilidade de todos os

192
00:08:37,140 --> 00:08:40,440
outros vértices condicionados à atividade

193
00:08:40,440 --> 00:08:43,020
do vértice antes ou à

194
00:08:43,020 --> 00:08:45,860
variável latente antes de

195
00:08:45,899 --> 00:08:48,240
eu já disse que é um

196
00:08:48,240 --> 00:08:50,399
modelo generativo gaussiano, o que significa que essas

197
00:08:50,399 --> 00:08:54,260
probabilidades estão na forma gaussiana

198
00:08:54,660 --> 00:08:57,120
e toda

199
00:08:57,120 --> 00:09:00,480
função endos  função G em geral e

200
00:09:00,480 --> 00:09:02,880
uh especialmente porque, por exemplo, no

201
00:09:02,880 --> 00:09:05,459
papel Rambler e em todos os papéis que

202
00:09:05,459 --> 00:09:07,920
vieram depois também por causa da

203
00:09:07,920 --> 00:09:10,500
revolução de aprendizado profundo essas funções são

204
00:09:10,500 --> 00:09:13,220
simplesmente mapas lineares ou

205
00:09:13,220 --> 00:09:15,120
mapas não lineares com

206
00:09:15,120 --> 00:09:18,000
funções de ativação ou mapas não lineares com

207
00:09:18,000 --> 00:09:22,040
função de ativação e um  viés aditivo

208
00:09:23,220 --> 00:09:27,180
para que possamos dar uma

209
00:09:27,180 --> 00:09:28,860
definição formal de codificação criativa e podemos

210
00:09:28,860 --> 00:09:30,300
dizer que a codificação operativa é um

211
00:09:30,300 --> 00:09:33,480
esquema de inversão para tal modelo generativo onde

212
00:09:33,480 --> 00:09:35,839
sua evidência de modelo é maximizada

213
00:09:35,839 --> 00:09:38,760
minimizando uma quantidade que é chamada de

214
00:09:38,760 --> 00:09:40,920
variação de energia livre

215
00:09:40,920 --> 00:09:43,740
em geral o  objetivo de todo

216
00:09:43,740 --> 00:09:46,019
modelo generativo é maximizar a evidência do modelo, mas

217
00:09:46,019 --> 00:09:48,860
essa quantidade é sempre intratável e

218
00:09:48,860 --> 00:09:51,019
temos algumas

219
00:09:51,019 --> 00:09:53,279
técnicas que nos permitem

220
00:09:53,279 --> 00:09:55,980
aproximar a solução e aquela

221
00:09:55,980 --> 00:09:58,500
que usamos na codificação criativa,

222
00:09:58,500 --> 00:10:00,720
em vez de minimizar a aberração da

223
00:10:00,720 --> 00:10:03,480
energia livre, que é um  que é um limite inferior

224
00:10:03,480 --> 00:10:06,839
da evidência do modelo neste trabalho e,

225
00:10:06,839 --> 00:10:09,660
na verdade, em muitos

226
00:10:09,660 --> 00:10:11,700
outros, então é a maneira padrão de fazê-lo,

227
00:10:11,700 --> 00:10:13,740
essa minimização é realizada a

228
00:10:13,740 --> 00:10:16,080
descida do ingrediente

229
00:10:16,080 --> 00:10:18,540
um e sim executar, concordamos na descida

230
00:10:18,540 --> 00:10:19,980
e há  na verdade, outros métodos,

231
00:10:19,980 --> 00:10:22,140
como a maximização da expectativa, que

232
00:10:22,140 --> 00:10:23,580
geralmente é equivalente

233
00:10:23,580 --> 00:10:25,140
ou você pode usar alguns outros

234
00:10:25,140 --> 00:10:26,940
algoritmos de passagem de mensagem, como a

235
00:10:26,940 --> 00:10:29,959
propagação de crenças, por exemplo,

236
00:10:30,720 --> 00:10:33,980
e voltar um pouco no tempo,

237
00:10:33,980 --> 00:10:35,940
esquecendo um pouco sobre os

238
00:10:35,940 --> 00:10:38,760
modelos estatísticos generativos,

239
00:10:38,760 --> 00:10:41,360
se pudermos ver a codificação criativa

240
00:10:41,360 --> 00:10:44,040
como quero dizer, eu já disse algumas

241
00:10:44,040 --> 00:10:46,200
vezes como um modelo hierárquico

242
00:10:46,200 --> 00:10:48,420
com as atividades neurais, com

243
00:10:48,420 --> 00:10:50,700
variáveis ​​latentes de neurônios que representam

244
00:10:50,700 --> 00:10:53,459
atividades neurais, o sinal do remetente para baixo

245
00:10:53,459 --> 00:10:54,899
na hierarquia

246
00:10:54,899 --> 00:10:57,540
e com nós de erro ou neurônios de erro,

247
00:10:57,540 --> 00:11:01,019
o remetente sinaliza para cima na hierarquia, então

248
00:11:01,019 --> 00:11:03,660
isso e  a informação de erro de volta

249
00:11:03,660 --> 00:11:05,700
qual é a variação de energia livre

250
00:11:05,700 --> 00:11:08,220
desta classe de modelos de codificação operados é

251
00:11:08,220 --> 00:11:09,899
simplesmente a soma

252
00:11:09,899 --> 00:11:12,720
do erro médio quadrado de todos os

253
00:11:12,720 --> 00:11:14,399
neurônios de erro

254
00:11:14,399 --> 00:11:18,120
então é a soma do erro

255
00:11:18,120 --> 00:11:21,980
do erro total ao quadrado

256
00:11:22,019 --> 00:11:24,480
e esta representação é  será

257
00:11:24,480 --> 00:11:27,120
útil em uh nos slides posteriores e em

258
00:11:27,120 --> 00:11:28,740
como vou explicar como usar a

259
00:11:28,740 --> 00:11:30,120
codificação criativa para modelar a

260
00:11:30,120 --> 00:11:32,940
inferência causal, por exemplo,

261
00:11:32,940 --> 00:11:34,800
acho que a codificação preditiva é importante

262
00:11:34,800 --> 00:11:36,240
e não é um bom algoritmo para

263
00:11:36,240 --> 00:11:37,500
estudar

264
00:11:37,500 --> 00:11:39,600
bem, antes de tudo, como  Eu disse anteriormente que ele

265
00:11:39,600 --> 00:11:41,399
otimiza o objetivo correto que é

266
00:11:41,399 --> 00:11:43,079
a evidência do modelo ou verossimilhança marginal

267
00:11:43,079 --> 00:11:44,339


268
00:11:44,339 --> 00:11:45,660
e

269
00:11:45,660 --> 00:11:47,700
então o faz otimizando um

270
00:11:47,700 --> 00:11:49,440
limite inferior que é chamado de variação de

271
00:11:49,440 --> 00:11:52,440
energia livre como eu disse e o

272
00:11:52,440 --> 00:11:54,240
acabamento virtual é interessante porque pode ser

273
00:11:54,240 --> 00:11:57,680
escrito como um  soma de dois termos diferentes

274
00:11:57,680 --> 00:12:00,839
que são e cada um desses termos de

275
00:12:00,839 --> 00:12:04,680
otimização como uh como impactos importantes,

276
00:12:04,680 --> 00:12:06,899
por exemplo, em tarefas de aprendizado de máquina

277
00:12:06,899 --> 00:12:09,060
ou em geral em tarefas de aprendizado,

278
00:12:09,060 --> 00:12:12,420
então um desses termos força a memorização,

279
00:12:12,420 --> 00:12:15,440
então no segundo termo basicamente diz

280
00:12:15,440 --> 00:12:18,180
força o modelo  para ajustar um conjunto de dados específico

281
00:12:18,180 --> 00:12:19,560


282
00:12:19,560 --> 00:12:21,240
e o primeiro termo

283
00:12:21,240 --> 00:12:23,519
força o modelo a minimizar a

284
00:12:23,519 --> 00:12:26,040
complexidade e, como sabemos, por exemplo, da

285
00:12:26,040 --> 00:12:28,500


286
00:12:28,500 --> 00:12:31,260
teoria da navalha de resultados, se tivermos dois modelos diferentes

287
00:12:31,260 --> 00:12:33,000
que executam de maneira semelhante em um

288
00:12:33,000 --> 00:12:35,640
conjunto de treinamento específico aquele que temos  para obter

289
00:12:35,640 --> 00:12:37,380
e aquele que é esperado para

290
00:12:37,380 --> 00:12:39,899
generalizar uh mais é o menos

291
00:12:39,899 --> 00:12:41,160
complexo,

292
00:12:41,160 --> 00:12:44,100
portanto, atualizar um modelo generativo por meio de

293
00:12:44,100 --> 00:12:46,380
energia livre operacional nos permite

294
00:12:46,380 --> 00:12:47,779
basicamente

295
00:12:47,779 --> 00:12:51,959
convergir para o modelo razor de resultado ideal uh,

296
00:12:51,959 --> 00:12:54,720
que é o que tanto memoriza um

297
00:12:54,720 --> 00:12:56,100
conjunto de dados, mas também é  capaz de

298
00:12:56,100 --> 00:12:58,680
generalizar muito bem em

299
00:12:58,680 --> 00:13:00,240
pontos de dados não vistos

300
00:13:00,240 --> 00:13:02,639
uma segunda razão pela qual a codificação operativa

301
00:13:02,639 --> 00:13:08,600
é importante é que na verdade não é uma

302
00:13:08,720 --> 00:13:11,760


303
00:13:11,760 --> 00:13:13,920
estrutura hierárquica, mas pode ser

304
00:13:13,920 --> 00:13:15,959
modelada em arquiteturas mais complexas e flexíveis,

305
00:13:15,959 --> 00:13:18,240
como gráficos direcionados

306
00:13:18,240 --> 00:13:21,540
modelo com qualquer forma ou generalizado ainda

307
00:13:21,540 --> 00:13:23,700
mais para redes com muitos ciclos

308
00:13:23,700 --> 00:13:25,920
que se assemelham à região do cérebro e o

309
00:13:25,920 --> 00:13:27,779
resultado final na razão subjacente

310
00:13:27,779 --> 00:13:30,300
é que você não está aprendendo e

311
00:13:30,300 --> 00:13:32,339
prevendo com um passe para frente e depois

312
00:13:32,339 --> 00:13:34,260
propagando o erro de volta, mas você está

313
00:13:34,260 --> 00:13:36,600
minimizando uma função de energia

314
00:13:36,600 --> 00:13:38,459
e isso permite que basicamente todo tipo de

315
00:13:38,459 --> 00:13:39,839
hierarquia seja

316
00:13:39,839 --> 00:13:41,180
uh

317
00:13:41,180 --> 00:13:43,860
permite ir atrás de chaves diretas e

318
00:13:43,860 --> 00:13:46,860
aprender ciclos e isso é

319
00:13:46,860 --> 00:13:48,060
realmente muito importante porque o

320
00:13:48,060 --> 00:13:50,399
cérebro está cheio de ciclos, pois temos

321
00:13:50,399 --> 00:13:53,399
algumas informações de alguns artigos recentes

322
00:13:53,399 --> 00:13:56,459
uh que são gerenciados para mapear completamente

323
00:13:56,459 --> 00:13:59,279
o cérebro de alguns animais, como a

324
00:13:59,279 --> 00:14:00,420
mosca da fruta,

325
00:14:00,420 --> 00:14:03,899
o cérebro está cheio de ciclos, então faz

326
00:14:03,899 --> 00:14:06,720
sentido drenar nossos modelos de aprendizado de máquina

327
00:14:06,720 --> 00:14:09,000
ou

328
00:14:09,000 --> 00:14:11,160
nossos modelos em geral com um algoritmo

329
00:14:11,160 --> 00:14:14,160
que nos permite drenar usando

330
00:14:14,160 --> 00:14:17,160
cíclico  estruturas

331
00:14:17,160 --> 00:14:19,380
a terceira razão pela qual a codificação operativa é

332
00:14:19,380 --> 00:14:21,240
interessante é que foi formalmente

333
00:14:21,240 --> 00:14:23,820
provado que ela é mais robusta do que a

334
00:14:23,820 --> 00:14:25,139
rede neural padrão começando com

335
00:14:25,139 --> 00:14:27,060
propagação de preto, portanto, se você tiver uma

336
00:14:27,060 --> 00:14:28,200
rede neural e quiser executar

337
00:14:28,200 --> 00:14:30,320
tarefas de classificação,

338
00:14:30,320 --> 00:14:34,139
sua codificação criativa é mais robusta

339
00:14:34,139 --> 00:14:36,260
e  isso é

340
00:14:36,260 --> 00:14:38,339
interessante em tarefas como

341
00:14:38,339 --> 00:14:40,680
treinamento de aprendizado on-line em pequenos conjuntos de dados ou

342
00:14:40,680 --> 00:14:43,440
tarefas de aprendizado contínuo e a teoria

343
00:14:43,440 --> 00:14:45,540
basicamente vem do fato de que a

344
00:14:45,540 --> 00:14:48,540
codificação imperativa foi movida para

345
00:14:48,540 --> 00:14:50,820
aproximar a descida do gradiente implícito,

346
00:14:50,820 --> 00:14:53,339
que é uma versão diferente da

347
00:14:53,339 --> 00:14:54,899
descida do gradiente explícito que é  a

348
00:14:54,899 --> 00:14:57,180
descida verde padrão usada

349
00:14:57,180 --> 00:14:59,880
em cada modelo basicamente

350
00:14:59,880 --> 00:15:03,680
e é uma variação que é mais robusta.

351
00:15:05,880 --> 00:15:08,279


352
00:15:08,279 --> 00:15:09,779


353
00:15:09,779 --> 00:15:11,639


354
00:15:11,639 --> 00:15:13,019


355
00:15:13,019 --> 00:15:15,839
inferência causal inferência causal

356
00:15:15,839 --> 00:15:18,420
é uma teoria é uma

357
00:15:18,420 --> 00:15:20,339
teoria muito geral que foi

358
00:15:20,339 --> 00:15:23,100
mais formalizada pelo fato de Judy ele é definitivamente

359
00:15:23,100 --> 00:15:25,500
a pessoa mais importante no

360
00:15:25,500 --> 00:15:27,839
campo da causalidade na França ele escreveu alguns

361
00:15:27,839 --> 00:15:29,760
livros muito bons por exemplo o livro de

362
00:15:29,760 --> 00:15:32,760
Y é altamente recomendado  se você quiser

363
00:15:32,760 --> 00:15:35,220
aprender mais sobre este tópico

364
00:15:35,220 --> 00:15:37,800
e basicamente abordar o seguinte

365
00:15:37,800 --> 00:15:38,639
problema,

366
00:15:38,639 --> 00:15:40,440
então vamos supor que temos uma

367
00:15:40,440 --> 00:15:42,000
distribuição de probabilidade conjunta que está

368
00:15:42,000 --> 00:15:44,160
associada a uma rede bayesiana, este

369
00:15:44,160 --> 00:15:46,199
será um pouco o

370
00:15:46,199 --> 00:15:49,260
exemplo em execução em todo o artigo,

371
00:15:49,260 --> 00:15:51,839
especialmente quando  você não está com

372
00:15:51,839 --> 00:15:54,480
redes asiáticas desta forma,

373
00:15:54,480 --> 00:15:57,660
foi baseado em redes, as

374
00:15:57,660 --> 00:16:00,240
variáveis ​​dentro delas podem representar

375
00:16:00,240 --> 00:16:02,100
diferentes quantidades, por exemplo, nossa

376
00:16:02,100 --> 00:16:04,620
rede visual com esta forma pode

377
00:16:04,620 --> 00:16:06,899
representar

378
00:16:06,899 --> 00:16:08,820
as quantidades à direita, portanto,

379
00:16:08,820 --> 00:16:10,800


380
00:16:10,800 --> 00:16:13,079
sócio-econômico.  nível de educação sua

381
00:16:13,079 --> 00:16:16,699
inteligência e seu nível de renda

382
00:16:17,100 --> 00:16:19,440
algo em que a estatística clássica é

383
00:16:19,440 --> 00:16:22,920
muito boa e é uh enquanto uh o

384
00:16:22,920 --> 00:16:25,320
aplicativo mais usado é para modelar

385
00:16:25,320 --> 00:16:28,019
observações ou correlações uma

386
00:16:28,019 --> 00:16:29,279
correlação basicamente responde à

387
00:16:29,279 --> 00:16:32,519
pergunta o que é se observarmos

388
00:16:32,519 --> 00:16:35,579
outra variável C

389
00:16:35,579 --> 00:16:37,500
por exemplo em  neste caso, qual é

390
00:16:37,500 --> 00:16:39,660
o nível de renda o

391
00:16:39,660 --> 00:16:41,820
nível de renda esperado de um indivíduo se eu

392
00:16:41,820 --> 00:16:44,339
observar esse nível de educação

393
00:16:44,339 --> 00:16:48,180
e, claro, se essa pessoa

394
00:16:48,180 --> 00:16:50,220
tiver um grau de educação superior, por

395
00:16:50,220 --> 00:16:52,500
exemplo, um mestrado ou doutorado, estou esperando

396
00:16:52,500 --> 00:16:54,360
Geral que essa pessoa tenha  um nível de renda mais alto

397
00:16:54,360 --> 00:16:56,040


398
00:16:56,040 --> 00:16:58,139
e isso é uma correlação,

399
00:16:58,139 --> 00:17:00,300
no entanto, às vezes, há coisas que

400
00:17:00,300 --> 00:17:03,300
são muito difíceis de observar, mas desempenham um

401
00:17:03,300 --> 00:17:05,040
papel enorme na determinação dessas

402
00:17:05,040 --> 00:17:06,119
quantidades;

403
00:17:06,119 --> 00:17:08,220
portanto, por exemplo, pode ser que o

404
00:17:08,220 --> 00:17:11,160
nível de renda seja muito mais

405
00:17:11,160 --> 00:17:13,380
definido pela inteligência de um

406
00:17:13,380 --> 00:17:15,540
pessoa específica

407
00:17:15,540 --> 00:17:18,720
e talvez que a inteligência ou

408
00:17:18,720 --> 00:17:21,000
se uma pessoa é inteligente também tem maior

409
00:17:21,000 --> 00:17:24,540
probabilidade de ter um nível de educação superior,

410
00:17:24,540 --> 00:17:27,540
mas ainda assim a verdadeira razão pela qual a

411
00:17:27,540 --> 00:17:30,120
renda é I é por causa

412
00:17:30,120 --> 00:17:32,220
do QI

413
00:17:32,220 --> 00:17:34,740
e isso pode ser isso não pode  ser Estudos

414
00:17:34,740 --> 00:17:36,360
simplesmente por correlações e devem ser

415
00:17:36,360 --> 00:17:39,120
estudados por uma técnica mais avançada

416
00:17:39,120 --> 00:17:41,280
que é chamada de intervenção

417
00:17:41,280 --> 00:17:43,320
uma Intervenção basicamente responde à

418
00:17:43,320 --> 00:17:46,500
pergunta é o que é D se mudarmos C para

419
00:17:46,500 --> 00:17:48,240
um valor específico

420
00:17:48,240 --> 00:17:51,000
então, por exemplo, podemos pegar um

421
00:17:51,000 --> 00:17:54,660
indivíduo  e verifique seu nível de renda

422
00:17:54,660 --> 00:17:57,120
e depois mude seu nível de educação então

423
00:17:57,120 --> 00:17:59,220
intervenha neste mundo

424
00:17:59,220 --> 00:18:01,080
e mude seu nível de educação sem

425
00:18:01,080 --> 00:18:03,419
tocar em sua inteligência e veja

426
00:18:03,419 --> 00:18:07,260
quanto é que sua renda muda

427
00:18:07,260 --> 00:18:09,900
por exemplo se a renda mudar muito

428
00:18:09,900 --> 00:18:12,179
significa que a inteligência

429
00:18:12,179 --> 00:18:14,460
não  t desempenhar um grande papel nisso, mas o

430
00:18:14,460 --> 00:18:16,799
nível de educação faz se o nível de renda

431
00:18:16,799 --> 00:18:19,020
não mudar muito, isso significa que talvez

432
00:18:19,020 --> 00:18:20,640
haja uma variável oculta neste caso

433
00:18:20,640 --> 00:18:22,860
a inteligência que determina o

434
00:18:22,860 --> 00:18:25,760
nível de renda de uma pessoa

435
00:18:25,980 --> 00:18:28,740
a terceira quantidade inferência causal importante

436
00:18:28,740 --> 00:18:31,080
é que  de contrafactuais,

437
00:18:31,080 --> 00:18:33,120
por exemplo, um contrafactual responde à

438
00:18:33,120 --> 00:18:36,720
pergunta o que seria e mudamos

439
00:18:36,720 --> 00:18:39,240
C para um valor diferente no passado,

440
00:18:39,240 --> 00:18:40,679
por exemplo, podemos ver que a

441
00:18:40,679 --> 00:18:42,059
diferença entre intervenções e

442
00:18:42,059 --> 00:18:45,059
contrafactuais é que as intervenções

443
00:18:45,059 --> 00:18:47,820
agem no futuro, então estou entrevistando

444
00:18:47,820 --> 00:18:50,340
no mundo agora para observar uma mudança no

445
00:18:50,340 --> 00:18:53,220
futuro bem contrafactual nos permite

446
00:18:53,220 --> 00:18:56,039
voltar no tempo e mudar uma variável de

447
00:18:56,039 --> 00:18:59,160
volta no tempo e ver como essa mudança

448
00:18:59,160 --> 00:19:01,320
teria influenciado o mundo em que vivemos

449
00:19:01,320 --> 00:19:02,940
agora

450
00:19:02,940 --> 00:19:06,299
e esses são definidos por judapple como os

451
00:19:06,299 --> 00:19:08,100
três  níveis de inferência causal

452
00:19:08,100 --> 00:19:09,660
correlação é o primeiro nível

453
00:19:09,660 --> 00:19:11,580
intervenção é o segundo nível em

454
00:19:11,580 --> 00:19:14,720
contrafactual é o terceiro nível

455
00:19:16,020 --> 00:19:18,120
outras intervenções Vou defini-

456
00:19:18,120 --> 00:19:20,640
las mais formalmente agora que dei

457
00:19:20,640 --> 00:19:23,760
uma definição intuitiva e estou

458
00:19:23,760 --> 00:19:25,500
usando esta notação aqui  que é o

459
00:19:25,500 --> 00:19:27,240
mesmo ao longo de toda a

460
00:19:27,240 --> 00:19:29,640
apresentação, então X sempre será

461
00:19:29,640 --> 00:19:32,820
uma variável latente s i sempre

462
00:19:32,820 --> 00:19:35,340
será um ponto de dados ou uma observação

463
00:19:35,340 --> 00:19:38,520
e VI sempre será um vértice, portanto,

464
00:19:38,520 --> 00:19:40,860
toda vez que você vir VI, estaremos apenas

465
00:19:40,860 --> 00:19:42,720
interessado na estrutura do gráfico,

466
00:19:42,720 --> 00:19:45,299
por exemplo,

467
00:19:45,299 --> 00:19:46,860
então vamos supor que temos um modelo Bayesiano

468
00:19:46,860 --> 00:19:50,160
que tem a mesma estrutura

469
00:19:50,160 --> 00:19:52,679
que o modelo Bayesiano que vimos no

470
00:19:52,679 --> 00:19:54,780
slide anterior

471
00:19:54,780 --> 00:19:57,840
dado que X3 é igual a S3 esta é a

472
00:19:57,840 --> 00:20:00,660
observação que fazemos estatísticas permite

473
00:20:00,660 --> 00:20:03,360
para calcular a probabilidade ou a

474
00:20:03,360 --> 00:20:04,679
expectativa

475
00:20:04,679 --> 00:20:07,380
de X4 que é a variável latente

476
00:20:07,380 --> 00:20:09,240
relacionada a este vértice

477
00:20:09,240 --> 00:20:13,860
dado que X3 é igual a S3

478
00:20:13,860 --> 00:20:15,679


479
00:20:15,679 --> 00:20:17,760
intervenção estrangeira precisamos de um novo tipo de

480
00:20:17,760 --> 00:20:19,919
notação que é chamada de operação do

481
00:20:19,919 --> 00:20:21,179


482
00:20:21,179 --> 00:20:23,880
então neste caso

483
00:20:23,880 --> 00:20:26,100
X4 queremos calcular  a probabilidade de

484
00:20:26,100 --> 00:20:30,000
X4 dado o fato de que intervimos

485
00:20:30,000 --> 00:20:33,059
na palavra e mudamos X3 West 3.

486
00:20:33,059 --> 00:20:35,580
e como fazemos isso para realizar uma

487
00:20:35,580 --> 00:20:38,400
intervenção Judo Pearl nos diz que

488
00:20:38,400 --> 00:20:40,020
temos que

489
00:20:40,020 --> 00:20:41,880
ter uma etapa intermediária antes de

490
00:20:41,880 --> 00:20:45,059
Calcular uma correlação é a princípio nós

491
00:20:45,059 --> 00:20:46,860
temos que remover tudo para remover todas as

492
00:20:46,860 --> 00:20:50,160
arestas de entrada para V3,

493
00:20:50,160 --> 00:20:52,799
então temos que estudar não esta

494
00:20:52,799 --> 00:20:55,679
rede bayesiana, mas esta segunda

495
00:20:55,679 --> 00:20:58,200
e, neste ponto, podemos

496
00:20:58,200 --> 00:21:00,840
calcular uma correlação como

497
00:21:00,840 --> 00:21:03,299
normalmente fazemos

498
00:21:03,299 --> 00:21:06,500
e esta é uma intervenção

499
00:21:07,020 --> 00:21:09,299
contrafactual  é uma generalização disso

500
00:21:09,299 --> 00:21:11,700
que, como eu disse, viveu no passado

501
00:21:11,700 --> 00:21:14,100
e eles estão computando usando

502
00:21:14,100 --> 00:21:15,419
modelos causais estruturais

503
00:21:15,419 --> 00:21:18,299
um modelo causal estrutural é uma tupla

504
00:21:18,299 --> 00:21:21,120
que é conceitualmente semelhante a uma

505
00:21:21,120 --> 00:21:23,460
rede bayesiana, mas basicamente temos

506
00:21:23,460 --> 00:21:26,220
essa nova classe de variáveis ​​no topo que

507
00:21:26,220 --> 00:21:28,580
são as variáveis ​​inobserváveis ​​que eles usam,

508
00:21:28,580 --> 00:21:30,960
então temos a Rede Bayesiana que

509
00:21:30,960 --> 00:21:34,020
tínhamos antes de X1 X2 X3 S4,

510
00:21:34,020 --> 00:21:37,460
mas também temos aquelas variáveis ​​inobserváveis ​​ou

511
00:21:37,460 --> 00:21:40,020
que dependem do ambiente,

512
00:21:40,020 --> 00:21:42,539
você não pode controlá-las, pode inferi-

513
00:21:42,539 --> 00:21:43,980
las, mas você,

514
00:21:43,980 --> 00:21:46,020
mas elas estão lá

515
00:21:46,020 --> 00:21:48,539
e

516
00:21:48,539 --> 00:21:51,360
f  é um conjunto de funções que depende

517
00:21:51,360 --> 00:21:53,400


518
00:21:53,400 --> 00:21:57,299
basicamente de f de x de x3 depende de X1

519
00:21:57,299 --> 00:21:58,980
porque temos uma seta em x2 porque

520
00:21:58,980 --> 00:22:00,960
você tem uma seta e na

521
00:22:00,960 --> 00:22:02,940
variável não observável que também

522
00:22:02,940 --> 00:22:05,840
influencia extrema

523
00:22:06,179 --> 00:22:09,240
então sim intuitivamente você pode nos ver você

524
00:22:09,240 --> 00:22:11,940
pode pensar  de um modelo causal estrutural

525
00:22:11,940 --> 00:22:14,159
como uma rede bayesiana com essas

526
00:22:14,159 --> 00:22:16,679
variáveis ​​não observáveis ​​no topo e cada

527
00:22:16,679 --> 00:22:19,500
variável não observável influencia apenas a

528
00:22:19,500 --> 00:22:22,020


529
00:22:22,020 --> 00:22:24,600
sua própria última variável X, então, por exemplo,

530
00:22:24,600 --> 00:22:27,960
IU nunca tocará X1 também u3

531
00:22:27,960 --> 00:22:30,360
tocará apenas Q3 E1 todos influenciarão

532
00:22:30,360 --> 00:22:34,039
X1 e  assim por diante,

533
00:22:35,039 --> 00:22:37,679
realizando a inferência contrafactual,

534
00:22:37,679 --> 00:22:39,900
responde à seguinte pergunta: o que

535
00:22:39,900 --> 00:22:42,960
seria X4 em X3, igual a outra

536
00:22:42,960 --> 00:22:46,620
variável em uma situação de passagem, você

537
00:22:46,620 --> 00:22:49,340
estrangeiro

538
00:22:49,340 --> 00:22:51,840
requer três etapas diferentes, então a

539
00:22:51,840 --> 00:22:53,039
abdução

540
00:22:53,039 --> 00:22:54,900


541
00:22:54,900 --> 00:22:57,179
é o cálculo de todas as

542
00:22:57,179 --> 00:22:59,460
variáveis ​​de fundo, portanto  nesta etapa,

543
00:22:59,460 --> 00:23:01,200
queremos voltar no tempo e entender

544
00:23:01,200 --> 00:23:03,419
como o ambiente não observável

545
00:23:03,419 --> 00:23:04,919
estava

546
00:23:04,919 --> 00:23:08,039
naquele momento específico no tempo

547
00:23:08,039 --> 00:23:11,039
e fazemos isso fixando todas as

548
00:23:11,039 --> 00:23:14,280
variáveis ​​latentes X em alguns dados específicos que

549
00:23:14,280 --> 00:23:16,140
já temos

550
00:23:16,140 --> 00:23:18,960
e executando estes uh isto

551
00:23:18,960 --> 00:23:21,120
inferência sobre o usado

552
00:23:21,120 --> 00:23:24,240
então vamos usar o U

553
00:23:24,240 --> 00:23:26,940
para manter o U que aprendemos e

554
00:23:26,940 --> 00:23:28,500
realizar uma intervenção

555
00:23:28,500 --> 00:23:29,880
então

556
00:23:29,880 --> 00:23:32,340
uma contrafatura também pode ser vista como

557
00:23:32,340 --> 00:23:34,980
uma intervenção no tempo em que

558
00:23:34,980 --> 00:23:36,960
conhecemos o ambiente as

559
00:23:36,960 --> 00:23:40,620
variáveis ​​de ambiente U1 U2  e u4 naquele momento específico

560
00:23:40,620 --> 00:23:43,039


561
00:23:43,200 --> 00:23:44,340
e

562
00:23:44,340 --> 00:23:46,679
qual é a etapa que falta

563
00:23:46,679 --> 00:23:49,440
então o que seria X4 em X3 foi igual a

564
00:23:49,440 --> 00:23:50,780
outro

565
00:23:50,780 --> 00:23:53,280
outro ponto de dados nessa

566
00:23:53,280 --> 00:23:55,980
situação específica agora agora podemos calcular uma

567
00:23:55,980 --> 00:23:57,120
correlação

568
00:23:57,120 --> 00:23:59,520
e a correlação fazemos no caminho

569
00:23:59,520 --> 00:24:02,039
no gráfico  em que

570
00:24:02,039 --> 00:24:04,440
já realizamos uma intervenção usando

571
00:24:04,440 --> 00:24:06,659
as variáveis ​​de ambiente que

572
00:24:06,659 --> 00:24:10,140
aprendemos na etapa de abdução

573
00:24:10,140 --> 00:24:14,419
e esta é uma inferência contrafactual

574
00:24:15,480 --> 00:24:18,000
este é o último slide da

575
00:24:18,000 --> 00:24:20,159
presente introdução de inferência causal

576
00:24:20,159 --> 00:24:21,720
e é sobre aprendizado estrutural

577
00:24:21,720 --> 00:24:23,880
basicamente basicamente tudo o que eu disse

578
00:24:23,880 --> 00:24:27,360
até agora depende do fato de que conhecemos

579
00:24:27,360 --> 00:24:29,700
as dependências causais entre

580
00:24:29,700 --> 00:24:31,500
os pontos de dados, portanto, conhecemos a estrutura

581
00:24:31,500 --> 00:24:33,120
do gráfico, sabemos qual variável

582
00:24:33,120 --> 00:24:34,860
influencia qual,

583
00:24:34,860 --> 00:24:37,260
conhecemos as setas em geral,

584
00:24:37,260 --> 00:24:39,659
mas na prática isso nem

585
00:24:39,659 --> 00:24:42,900
sempre é possível, portanto,

586
00:24:42,900 --> 00:24:45,419
não temos acesso ao gráfico causal na

587
00:24:45,419 --> 00:24:47,400
maioria das vezes e, na verdade, aprender

588
00:24:47,400 --> 00:24:49,919
o melhor gráfico causal a partir dos dados ainda é

589
00:24:49,919 --> 00:24:51,840
um problema em aberto estamos melhorando nisso estamos

590
00:24:51,840 --> 00:24:53,880
melhorando, mas

591
00:24:53,880 --> 00:24:57,299
como executar essa tarefa exatamente

592
00:24:57,299 --> 00:24:58,380
uh

593
00:24:58,380 --> 00:25:01,140
ainda é um problema em aberto

594
00:25:01,140 --> 00:25:03,179
então, como eu disse basicamente, o objetivo é

595
00:25:03,179 --> 00:25:04,740
referir-se às relações do Conselho a partir de

596
00:25:04,740 --> 00:25:07,380
dados observacionais, portanto, dado um conjunto de dados,

597
00:25:07,380 --> 00:25:09,780
queremos inferir exatamente o

598
00:25:09,780 --> 00:25:12,179
gráfico direcionado que descreve a conectividade

599
00:25:12,179 --> 00:25:14,460
entre o sistema e as variáveis ​​do

600
00:25:14,460 --> 00:25:15,960
conjunto de dados,

601
00:25:15,960 --> 00:25:17,700
por exemplo, aqui temos um exemplo

602
00:25:17,700 --> 00:25:19,440
que eu acho que todos nós estamos

603
00:25:19,440 --> 00:25:22,860
familiarizados, obrigado por causa

604
00:25:22,860 --> 00:25:25,080
da pandemia, então temos essas quatro

605
00:25:25,080 --> 00:25:28,799
variáveis, idade, vacina, hospitalização

606
00:25:28,799 --> 00:25:31,380
e CT,

607
00:25:31,380 --> 00:25:33,600
e queremos inferir as

608
00:25:33,600 --> 00:25:36,059
dependências causais entre essas variáveis,

609
00:25:36,059 --> 00:25:37,980
por exemplo, queremos aprender diretamente

610
00:25:37,980 --> 00:25:40,260
com os dados que a probabilidade  de uma

611
00:25:40,260 --> 00:25:43,080
pessoa ser hospitalizada depende de

612
00:25:43,080 --> 00:25:45,419
sua idade e do fato de estar

613
00:25:45,419 --> 00:25:49,760
vacinada ou não e assim por diante,

614
00:25:51,299 --> 00:25:55,020
então este é o fim da longa

615
00:25:55,020 --> 00:25:58,080
introdução, mas espero que tenha sido claro o

616
00:25:58,080 --> 00:26:00,179
suficiente e espero ter dado como o

617
00:26:00,179 --> 00:26:02,039
básico para entender

618
00:26:02,039 --> 00:26:05,159
basicamente os resultados do artigo e

619
00:26:05,159 --> 00:26:07,740
agora podemos ir para as questões de pesquisa,

620
00:26:07,740 --> 00:26:09,059
portanto, as questões de pesquisa são as

621
00:26:09,059 --> 00:26:10,440
seguintes

622
00:26:10,440 --> 00:26:12,900
primeiro, quero ver

623
00:26:12,900 --> 00:26:15,299
se a codificação criativa pode ser usada para

624
00:26:15,299 --> 00:26:16,980
realizar inferência causal,

625
00:26:16,980 --> 00:26:20,100
portanto, a codificação operacional até agora só foi

626
00:26:20,100 --> 00:26:22,380
usada  executar para calcular correlações

627
00:26:22,380 --> 00:26:25,020
em Redes Bayesianas

628
00:26:25,020 --> 00:26:27,419
e a grande questão é podemos ir além da

629
00:26:27,419 --> 00:26:29,400
correlação e modelar a intervenção e

630
00:26:29,400 --> 00:26:31,679
contrafactual de uma forma biologicamente plausível, de uma

631
00:26:31,679 --> 00:26:32,760


632
00:26:32,760 --> 00:26:34,380


633
00:26:34,380 --> 00:26:36,120
forma que seja, por exemplo, simples

634
00:26:36,120 --> 00:26:39,059
intuitiva e nos permita apenas brincar com

635
00:26:39,059 --> 00:26:40,740
os neurônios  e não tocar, por exemplo,

636
00:26:40,740 --> 00:26:43,740
na enorme estrutura do gráfico

637
00:26:43,740 --> 00:26:46,380
e Mais na prática, mais especificamente,

638
00:26:46,380 --> 00:26:48,299
a questão se torna: podemos definir um

639
00:26:48,299 --> 00:26:51,000


640
00:26:51,000 --> 00:26:52,740
modelo causal de estrutura baseada em codificação operacional para realizar intervenções e

641
00:26:52,740 --> 00:26:55,320
contrafactuais?

642
00:26:55,320 --> 00:26:58,380
A segunda pergunta é

643
00:26:58,380 --> 00:27:00,179
como eu disse que ter um modelo personalizado de estrutura

644
00:27:00,179 --> 00:27:02,159
pressupõe que  conhecer a estrutura

645
00:27:02,159 --> 00:27:04,260
da rede de evasão,

646
00:27:04,260 --> 00:27:07,919
então presumimos que temos as setas,

647
00:27:07,919 --> 00:27:09,960
podemos ir além disso e usar

648
00:27:09,960 --> 00:27:11,520
redes de codificação criativas para aprender a

649
00:27:11,520 --> 00:27:14,418
estrutura causal do gráfico,

650
00:27:16,140 --> 00:27:18,900
basicamente, dar respostas positivas a

651
00:27:18,900 --> 00:27:21,120
ambas as perguntas nos permitiria

652
00:27:21,120 --> 00:27:23,120
usar codificação preditiva como  um

653
00:27:23,120 --> 00:27:26,039
método de inferência causal de ponta a ponta que basicamente

654
00:27:26,039 --> 00:27:28,740
pega um conjunto de dados e nos permite testar

655
00:27:28,740 --> 00:27:30,419
intervenções e

656
00:27:30,419 --> 00:27:34,820
previsões contrafactuais diretamente desse

657
00:27:36,840 --> 00:27:39,299


658
00:27:39,299 --> 00:27:40,740


659
00:27:40,740 --> 00:27:42,419


660
00:27:42,419 --> 00:27:45,120
conjunto de dados.  o título do

661
00:27:45,120 --> 00:27:46,740
artigo basicamente

662
00:27:46,740 --> 00:27:48,539
e aqui mostrarei como realizar

663
00:27:48,539 --> 00:27:50,760
correlações de codificação operacional que

664
00:27:50,760 --> 00:27:52,440
já é conhecida

665
00:27:52,440 --> 00:27:54,419
e como realizar

666
00:27:54,419 --> 00:27:56,760
consultas de intervenção que eu acho que

667
00:27:56,760 --> 00:28:01,140
é a verdadeira questão do artigo

668
00:28:01,140 --> 00:28:03,900
então aqui está um causal  gráfico que é o

669
00:28:03,900 --> 00:28:05,700
gráfico usual que tínhamos

670
00:28:05,700 --> 00:28:07,260


671
00:28:07,260 --> 00:28:09,240
e aqui está o

672
00:28:09,240 --> 00:28:11,760
modelo de codificação criativa correspondente, de modo que os eixos são as

673
00:28:11,760 --> 00:28:13,980
variáveis ​​latentes e correspondem aos

674
00:28:13,980 --> 00:28:18,000
neurônios em um modelo de rede neural

675
00:28:18,000 --> 00:28:20,760
e a seta preta passando de

676
00:28:20,760 --> 00:28:22,740
informações de previsão de um neurônio

677
00:28:22,740 --> 00:28:25,559
para o que está abaixo na hierarquia

678
00:28:25,559 --> 00:28:28,500
e cada vértice também tem esse

679
00:28:28,500 --> 00:28:31,140
neurônio de erro que passa informações para cima na

680
00:28:31,140 --> 00:28:32,820
hierarquia, então as informações de cada

681
00:28:32,820 --> 00:28:36,480
erro vão para o para o nó de valor

682
00:28:36,480 --> 00:28:39,120
no topo da hierarquia e basicamente diz para

683
00:28:39,120 --> 00:28:41,400
ele se corrigir para mudar  a

684
00:28:41,400 --> 00:28:43,760
previsão

685
00:28:44,700 --> 00:28:46,559
então para realizar uma correlação usando

686
00:28:46,559 --> 00:28:48,840
codificação preditiva o que você tem que fazer é

687
00:28:48,840 --> 00:28:50,400
pegar uma observação e

688
00:28:50,400 --> 00:28:52,620
simplesmente fixar o valor de um neurônio específico

689
00:28:52,620 --> 00:28:53,820


690
00:28:53,820 --> 00:28:55,200
então se você quiser calcular a

691
00:28:55,200 --> 00:28:58,740
probabilidade de X4 dado X3 igual a S3

692
00:28:58,740 --> 00:29:02,340
nós simplesmente temos que  pegue X3 e fixe-o em

693
00:29:02,340 --> 00:29:04,380
S3 de uma forma que não mude

694
00:29:04,380 --> 00:29:08,159
mais e execute uma minimização de energia

695
00:29:08,159 --> 00:29:09,720
e este modelo

696
00:29:09,720 --> 00:29:12,659
e minimizando atualizando o eixo

697
00:29:12,659 --> 00:29:16,380
uh por meio de uma minimização da variação

698
00:29:16,380 --> 00:29:18,419
de energia livre permite que o modelo

699
00:29:18,419 --> 00:29:20,820
convirja para uma solução  a esta pergunta,

700
00:29:20,820 --> 00:29:22,919
então a probabilidade ou o valor esperado

701
00:29:22,919 --> 00:29:27,179
de X4 dado X3 é igual a 3.

702
00:29:27,179 --> 00:29:29,340
mas como eu realizo uma intervenção agora

703
00:29:29,340 --> 00:29:31,679
sem agir na estrutura do

704
00:29:31,679 --> 00:29:33,419
gráfico

705
00:29:33,419 --> 00:29:35,640
bem, esta é basicamente a primeira

706
00:29:35,640 --> 00:29:37,679
ideia do artigo,

707
00:29:37,679 --> 00:29:39,960
oh, ainda é como  fazer uma

708
00:29:39,960 --> 00:29:43,260
correlação então fixar S3 igual a X3 é o

709
00:29:43,260 --> 00:29:45,600
primeiro passo do algoritmo e o

710
00:29:45,600 --> 00:29:47,220
segundo é obter o eixo

711
00:29:47,220 --> 00:29:50,539
minimizando a variação da energia livre

712
00:29:51,240 --> 00:29:53,340
uma intervenção que em teoria

713
00:29:53,340 --> 00:29:55,200
corresponde em tirar aquelas

714
00:29:55,200 --> 00:29:56,220
setas

715
00:29:56,220 --> 00:29:57,659
e responde a pergunta a

716
00:29:57,659 --> 00:29:59,279
probabilidade  de X4

717
00:29:59,279 --> 00:30:02,399
executando uma intervenção, portanto, X3 é

718
00:30:02,399 --> 00:30:04,860
igual a três codificação imperativa pode ser

719
00:30:04,860 --> 00:30:07,080
executada da seguinte maneira,

720
00:30:07,080 --> 00:30:09,840
então vou escrever o algoritmo aqui

721
00:30:09,840 --> 00:30:13,140
primeiro, pois em uma correlação você fixa S3

722
00:30:13,140 --> 00:30:17,039
igual a iFix X3 igual à

723
00:30:17,039 --> 00:30:18,720
observação que você obtém

724
00:30:18,720 --> 00:30:21,299
então este é o passo importante que

725
00:30:21,299 --> 00:30:24,059
você tem que intervir não mais no gráfico,

726
00:30:24,059 --> 00:30:26,700
mas no erro de previsão e

727
00:30:26,700 --> 00:30:28,980
corrigi-lo igual a zero

728
00:30:28,980 --> 00:30:31,020
ter um erro de previsão igual a zero

729
00:30:31,020 --> 00:30:32,480
basicamente

730
00:30:32,480 --> 00:30:36,179
faz uh enviar informações sem sentido

731
00:30:36,179 --> 00:30:38,460
na hierarquia ou realmente

732
00:30:38,460 --> 00:30:40,200
não enviar informações do  hierarquia

733
00:30:40,200 --> 00:30:41,880
porque basicamente diz a você que a

734
00:30:41,880 --> 00:30:44,659
previsão está sempre correta

735
00:30:44,659 --> 00:30:48,120
e o terceiro passo é como fizemos

736
00:30:48,120 --> 00:30:50,220
antes para atualizar o eixo

737
00:30:50,220 --> 00:30:52,919
irrestrito Axis ou X1 X2 X4

738
00:30:52,919 --> 00:30:55,679
minimizando a variação de energia livre

739
00:30:55,679 --> 00:30:59,039
como mostrarei agora ou experimentalmente

740
00:30:59,039 --> 00:31:00,840
simplesmente fazendo  esse pequeno truque de

741
00:31:00,840 --> 00:31:02,399
definir um erro de previsão para ser

742
00:31:02,399 --> 00:31:05,120
igual a zero

743
00:31:05,640 --> 00:31:08,220
é que nos impede de realmente agir na

744
00:31:08,220 --> 00:31:10,320
estrutura do gráfico

745
00:31:10,320 --> 00:31:13,620
como a teoria do cálculo faz e

746
00:31:13,620 --> 00:31:16,919
inferir o que falta uh as variáveis ​​após

747
00:31:16,919 --> 00:31:19,140
uma intervenção simplesmente executando

748
00:31:19,140 --> 00:31:22,640
aberração da minimização de energia livre e a

749
00:31:24,659 --> 00:31:26,580


750
00:31:26,580 --> 00:31:28,080
inferência contrafactual a inferência contrafactual é realmente

751
00:31:28,080 --> 00:31:30,539
fácil uma vez que tenhamos

752
00:31:30,539 --> 00:31:34,740
definido uh como fazer uma intervenção

753
00:31:34,740 --> 00:31:36,539
e isso ocorre porque, como vimos anteriormente,

754
00:31:36,539 --> 00:31:38,640
realizar um contrafactual semelhante

755
00:31:38,640 --> 00:31:40,380
a realizar uma intervenção em uma

756
00:31:40,380 --> 00:31:44,360
situação passada depois de inferir o

757
00:31:44,360 --> 00:31:48,120
inobservável as variáveis ​​inobserváveis

758
00:31:48,120 --> 00:31:49,620
de modo que

759
00:31:49,620 --> 00:31:51,480
você pode ver no gráfico que mostrei

760
00:31:51,480 --> 00:31:53,520
anteriormente sobre a ação de abdução e as

761
00:31:53,520 --> 00:31:56,039
etapas de previsão as etapas de ação e

762
00:31:56,039 --> 00:31:58,320
previsão eles não tinham essas

763
00:31:58,320 --> 00:31:59,640
duas setas

764
00:31:59,640 --> 00:32:02,580
foram removidas bastante codificação

765
00:32:02,580 --> 00:32:06,299
nos permite manter as setas deste uh

766
00:32:06,299 --> 00:32:08,279
em  o gráfico e

767
00:32:08,279 --> 00:32:11,340
realizar contrafactuais

768
00:32:11,340 --> 00:32:13,380
simplesmente realizando uma etapa de abdução como

769
00:32:13,380 --> 00:32:14,640
foi feito anteriormente

770
00:32:14,640 --> 00:32:16,679
uma etapa de ação em que simplesmente

771
00:32:16,679 --> 00:32:18,600
realizamos uma intervenção no

772
00:32:18,600 --> 00:32:21,240
nó único, então fixamos o nó de valor e definimos

773
00:32:21,240 --> 00:32:24,240
o erro como zero

774
00:32:24,240 --> 00:32:26,399
e executamos a minimização de energia para

775
00:32:26,399 --> 00:32:27,960
minimizar a duração da energia livre para

776
00:32:27,960 --> 00:32:30,679
calcular a previsão,

777
00:32:32,399 --> 00:32:36,299
então acho que é um método fácil e

778
00:32:36,299 --> 00:32:39,840
elegante para realizar intervenções

779
00:32:39,840 --> 00:32:42,899
e contrafactuais e uh

780
00:32:42,899 --> 00:32:44,880
sim, então acho que o que temos que

781
00:32:44,880 --> 00:32:46,500
mostrar agora é se funciona na prática

782
00:32:46,500 --> 00:32:48,720
ou não e nós  tenho alguns

783
00:32:48,720 --> 00:32:49,919
experimentos

784
00:32:49,919 --> 00:32:52,440
e vou mostrar agora dois

785
00:32:52,440 --> 00:32:54,240
experimentos diferentes, o primeiro é

786
00:32:54,240 --> 00:32:57,179
apenas um experimento de prova de conceito

787
00:32:57,179 --> 00:33:01,020
que mostra que na codificação operativa

788
00:33:01,020 --> 00:33:02,480
é capaz de realizar

789
00:33:02,480 --> 00:33:06,120
intervenções e contrafactuais

790
00:33:06,120 --> 00:33:08,700
e o segundo realmente mostra uma

791
00:33:08,700 --> 00:33:11,220
aplicação simples  em como as

792
00:33:11,220 --> 00:33:13,440
consultas de intervenção podem ser usadas para melhorar o

793
00:33:13,440 --> 00:33:16,260
desempenho das tarefas de classificação em um

794
00:33:16,260 --> 00:33:18,360
tipo específico de redes de codificação operacional,

795
00:33:18,360 --> 00:33:20,940
que é o de um

796
00:33:20,940 --> 00:33:22,080
modelo totalmente conectado,

797
00:33:22,080 --> 00:33:24,659
vamos começar do primeiro,

798
00:33:24,659 --> 00:33:27,679
então como fazemos essa tarefa, dado um

799
00:33:27,679 --> 00:33:30,360
modelo de Conselho estrutural,

800
00:33:30,360 --> 00:33:33,360
nós  geramos dados de treinamento e os usamos

801
00:33:33,360 --> 00:33:35,760
para aprender os pesos, para aprender as

802
00:33:35,760 --> 00:33:39,480
funções dos modelos estruturais do Kaza

803
00:33:39,480 --> 00:33:42,779
e, em seguida, geramos dados de teste de teste

804
00:33:42,779 --> 00:33:44,399
para consultas intervencionais e de

805
00:33:44,399 --> 00:33:46,080
contrafacção

806
00:33:46,080 --> 00:33:48,000
e mostramos se somos capazes de

807
00:33:48,000 --> 00:33:51,360
convergir para os dados de teste corretos  usando

808
00:33:51,360 --> 00:33:53,340
codificação criativa

809
00:33:53,340 --> 00:33:54,779


810
00:33:54,779 --> 00:33:57,240
e, por exemplo, aqui uh nesses dois

811
00:33:57,240 --> 00:33:58,860
gráficos representam

812
00:33:58,860 --> 00:34:00,600
intervenção intervencional e consultas contrafactuais

813
00:34:00,600 --> 00:34:03,539
deste gráfico específico que é o

814
00:34:03,539 --> 00:34:05,880
gráfico de viés borboleta que é um gráfico

815
00:34:05,880 --> 00:34:08,280
que é frequentemente usado em uh para testar

816
00:34:08,280 --> 00:34:10,859
se uma inferência causal se

817
00:34:10,859 --> 00:34:12,179
intervenção e

818
00:34:12,179 --> 00:34:15,540
técnicas contrafactuais  o trabalho é tão simples quanto isso, mas

819
00:34:15,540 --> 00:34:18,000
no papel você pode encontrar muitos

820
00:34:18,000 --> 00:34:20,760
gráficos diferentes, mas em geral esses

821
00:34:20,760 --> 00:34:22,800
dois gráficos esses dois gráficos mostram que o

822
00:34:22,800 --> 00:34:26,940
método funciona mostra que o

823
00:34:26,940 --> 00:34:27,918


824
00:34:27,918 --> 00:34:32,219
erro absoluto médio entre as

825
00:34:32,219 --> 00:34:33,960
quantidades contrafactuais de intervenção

826
00:34:33,960 --> 00:34:37,399
nós nós  computar e as quantidades intervencionais e

827
00:34:37,399 --> 00:34:39,780
contrafactuais do

828
00:34:39,780 --> 00:34:41,460
gráfico original

829
00:34:41,460 --> 00:34:43,800
estão próximas umas das outras, então o erro é

830
00:34:43,800 --> 00:34:45,800
bem pequeno

831
00:34:45,800 --> 00:34:49,139
o segundo experimento é uh é basicamente

832
00:34:49,139 --> 00:34:51,239
uma extensão de um experimento que propus

833
00:34:51,239 --> 00:34:54,540
em um artigo anterior que é o

834
00:34:54,540 --> 00:34:56,460
aprendizado sobre topologias de gráficos arbitrários

835
00:34:56,460 --> 00:34:59,040
que eu escrevi no ano passado

836
00:34:59,040 --> 00:35:01,080
naquele artigo,

837
00:35:01,080 --> 00:35:04,200
basicamente proponho esse tipo de

838
00:35:04,200 --> 00:35:06,060
rede como uma prova de conceito que é uma

839
00:35:06,060 --> 00:35:08,160
rede totalmente conectada que é em

840
00:35:08,160 --> 00:35:11,579
geral a pior rede neural que você pode

841
00:35:11,579 --> 00:35:13,500
ter para realizar

842
00:35:13,500 --> 00:35:15,960
experimentos de aprendizado de máquina porque

843
00:35:15,960 --> 00:35:20,520
nos deu um fixo  conjunto de neurônios

844
00:35:20,520 --> 00:35:23,660
basicamente o que

845
00:35:23,760 --> 00:35:26,400
você tem cada par de neurônio é

846
00:35:26,400 --> 00:35:28,680
conectado por duas sinapses diferentes então

847
00:35:28,680 --> 00:35:31,200
é o máximo é o modelo com

848
00:35:31,200 --> 00:35:33,359
a maior complexidade possível em

849
00:35:33,359 --> 00:35:34,619
geral

850
00:35:34,619 --> 00:35:36,300
o bom é que como você tem

851
00:35:36,300 --> 00:35:37,859
muitos ciclos o modelo é extremamente

852
00:35:37,859 --> 00:35:39,599
flexível  no sentido de que você pode treiná-

853
00:35:39,599 --> 00:35:42,480
lo, por exemplo, em uma imagem picada e

854
00:35:42,480 --> 00:35:45,359
em um ponto de dados e em seu rótulo, mas

855
00:35:45,359 --> 00:35:47,400
a maneira como você pode consultá-lo graças

856
00:35:47,400 --> 00:35:50,640
às informações que retornam é uh, você pode

857
00:35:50,640 --> 00:35:52,140
consultar de várias maneiras diferentes, então  você

858
00:35:52,140 --> 00:35:54,060
pode formar tarefas de classificação nas quais

859
00:35:54,060 --> 00:35:55,980
fornece uma imagem e executa a

860
00:35:55,980 --> 00:35:57,480
minimização de energia e obtém o rótulo,

861
00:35:57,480 --> 00:35:59,400
mas também pode, por exemplo, executar

862
00:35:59,400 --> 00:36:01,320
tarefas de geração nas quais fornece o

863
00:36:01,320 --> 00:36:03,060
rótulo, executa a minimização de energia e

864
00:36:03,060 --> 00:36:05,220
obtém a imagem que pode executar, por

865
00:36:05,220 --> 00:36:06,960
exemplo, imagem  conclusão que você dá

866
00:36:06,960 --> 00:36:10,260
metade da imagem e converge e

867
00:36:10,260 --> 00:36:12,119
converge deixa o modelo converter para a

868
00:36:12,119 --> 00:36:14,400
segunda metade e assim por diante, então é

869
00:36:14,400 --> 00:36:16,440
basicamente um modelo que aprende

870
00:36:16,440 --> 00:36:19,619
as estatísticas do conjunto de dados em sua

871
00:36:19,619 --> 00:36:21,900
totalidade sem ser focado em

872
00:36:21,900 --> 00:36:25,079
classificação ou  geração em geral,

873
00:36:25,079 --> 00:36:27,900
então essa flexibilidade é ótima,

874
00:36:27,900 --> 00:36:31,260
o problema é que, por causa disso,

875
00:36:31,260 --> 00:36:34,140
como todas as tarefas não funcionam bem,

876
00:36:34,140 --> 00:36:35,820
então você pode fazer muitas coisas diferentes,

877
00:36:35,820 --> 00:36:38,579
mas nenhuma delas é bem feita

878
00:36:38,579 --> 00:36:39,960
e

879
00:36:39,960 --> 00:36:42,480
aqui eu quero mostrar como usar

880
00:36:42,480 --> 00:36:44,099
Consultas de intervenção em vez de

881
00:36:44,099 --> 00:36:46,740
consultas correlacionais padrão ou

882
00:36:46,740 --> 00:36:48,119
consultas condicionais

883
00:36:48,119 --> 00:36:49,980
melhoram ligeiramente os resultados dessas

884
00:36:49,980 --> 00:36:51,960
tarefas de classificação,

885
00:36:51,960 --> 00:36:54,000
então quais são as razões conjetivas

886
00:36:54,000 --> 00:36:57,599
dessas uh a precisão do teste

887
00:36:57,599 --> 00:37:01,079
nessas tarefas não sendo tão alta

888
00:37:01,079 --> 00:37:03,180
as duas primeiras razões são que o modelo

889
00:37:03,180 --> 00:37:05,640
está distraído  ao corrigir cada um dos

890
00:37:05,640 --> 00:37:07,920
erros, então basicamente você

891
00:37:07,920 --> 00:37:09,420
apresenta uma imagem e gostaria de

892
00:37:09,420 --> 00:37:11,579
obter um rótulo, mas o modelo está

893
00:37:11,579 --> 00:37:13,859
se atualizando para também prever o

894
00:37:13,859 --> 00:37:16,320
erro nas imagens

895
00:37:16,320 --> 00:37:18,480
e a segunda razão que eu

896
00:37:18,480 --> 00:37:21,119
disse é que o  a estrutura é muito

897
00:37:21,119 --> 00:37:24,540
complexa, portanto, novamente, a partir de um resultado da

898
00:37:24,540 --> 00:37:27,079


899
00:37:27,079 --> 00:37:28,800
argumentação da navalha de Occam,

900
00:37:28,800 --> 00:37:30,720
este é o pior modelo que você pode ter;

901
00:37:30,720 --> 00:37:32,160


902
00:37:32,160 --> 00:37:33,960


903
00:37:33,960 --> 00:37:35,579
para

904
00:37:35,579 --> 00:37:37,560
ser preferido,

905
00:37:37,560 --> 00:37:40,560
mas em geral uh apenas para estudá-lo

906
00:37:40,560 --> 00:37:41,400


907
00:37:41,400 --> 00:37:43,380
a ideia é pode consultar neste modelo as

908
00:37:43,380 --> 00:37:44,820
intervenções podem ser usadas para melhorar o

909
00:37:44,820 --> 00:37:46,859
desempenho de uh desses

910
00:37:46,859 --> 00:37:48,599
modelos totalmente conectados

911
00:37:48,599 --> 00:37:51,060
bem a resposta é sim então

912
00:37:51,060 --> 00:37:53,160
aqui está como eu executo

913
00:37:53,160 --> 00:37:55,619
consultas de intervenção então  Eu apresento uma imagem para a

914
00:37:55,619 --> 00:37:56,640
rede

915
00:37:56,640 --> 00:37:59,460
eu corrijo o erro dos pixels para ser

916
00:37:59,460 --> 00:38:01,560
igual a zero para que esse erro não se

917
00:38:01,560 --> 00:38:03,180
propague na rede

918
00:38:03,180 --> 00:38:05,700
e então eu calculo o rótulo

919
00:38:05,700 --> 00:38:08,400
e como você pode ver a precisão melhora

920
00:38:08,400 --> 00:38:11,339
por exemplo de 89 usando o

921
00:38:11,339 --> 00:38:13,380
método de consulta padrão de redes de codificação criativa

922
00:38:13,380 --> 00:38:16,800
para 92, que é a precisão após a

923
00:38:16,800 --> 00:38:19,020
intervenção e o mesmo acontece

924
00:38:19,020 --> 00:38:21,540
para os meios de moda

925
00:38:21,540 --> 00:38:24,420
e acho que um crítico muito legítimo

926
00:38:24,420 --> 00:38:26,940
que provavelmente todos pensariam ao

927
00:38:26,940 --> 00:38:28,920
ver esses gráficos é que tudo bem você

928
00:38:28,920 --> 00:38:32,099
melhorar os meios de 89  para 92

929
00:38:32,099 --> 00:38:36,180
ainda é uma merda basicamente e sim, é verdade

930
00:38:36,180 --> 00:38:38,400
e estou realmente nos slides posteriores, vou

931
00:38:38,400 --> 00:38:40,619
mostrar como agir na

932
00:38:40,619 --> 00:38:42,660
estrutura deste uh deste

933
00:38:42,660 --> 00:38:43,859
modelo totalmente conectado

934
00:38:43,859 --> 00:38:46,500
melhorará ainda mais os resultados até

935
00:38:46,500 --> 00:38:48,480
o ponto em que atingiram o  rico uh

936
00:38:48,480 --> 00:38:50,820
desempenho que não está nem perto do

937
00:38:50,820 --> 00:38:52,560
desempenho de ponta, é claro,

938
00:38:52,560 --> 00:38:55,320
mas ainda está alto, mas não está em um

939
00:38:55,320 --> 00:38:57,380
nível que se torna basicamente aceitável

940
00:38:57,380 --> 00:39:01,760
Investigação da Kenworth investigando

941
00:39:02,040 --> 00:39:04,980
então sim, então esta é a parte sobre

942
00:39:04,980 --> 00:39:08,400
inferência causal usando codificação criativa

943
00:39:08,400 --> 00:39:10,920
e acho que, para resumir, posso dizer que

944
00:39:10,920 --> 00:39:15,060
a parte interessante desses

945
00:39:15,060 --> 00:39:17,640
resultados que acabei de mostrar é

946
00:39:17,640 --> 00:39:19,859
que mostrei que a codificação operativa é capaz

947
00:39:19,859 --> 00:39:22,560
de realizar intervenções de maneira muito fácil

948
00:39:22,560 --> 00:39:24,780
e intuitiva porque você não precisa

949
00:39:24,780 --> 00:39:26,280
agir  a estrutura do gráfico antigo

950
00:39:26,280 --> 00:39:28,740
mais às vezes essas

951
00:39:28,740 --> 00:39:31,079
funções não estão disponíveis e

952
00:39:31,079 --> 00:39:34,020
assim por diante, mas você simplesmente precisa

953
00:39:34,020 --> 00:39:36,140


954
00:39:36,140 --> 00:39:39,780
intervir em um único neurônio estudando o

955
00:39:39,780 --> 00:39:41,640
erro de previsão para zero

956
00:39:41,640 --> 00:39:44,220
e executar um processo de minimização de energia

957
00:39:44,220 --> 00:39:46,619


958
00:39:46,619 --> 00:39:49,200
e essas extensões  nos permitiu

959
00:39:49,200 --> 00:39:51,240
definir modelos causais estruturais baseados em codificação criativa

960
00:39:51,240 --> 00:39:52,920


961
00:39:52,920 --> 00:39:54,920
Agora passamos para a segunda

962
00:39:54,920 --> 00:39:57,900
parte do trabalho que é sobre

963
00:39:57,900 --> 00:40:01,700
aprendizado de estrutura estrutural,

964
00:40:02,000 --> 00:40:05,099
então aprendizado de instrução como eu disse Lida

965
00:40:05,099 --> 00:40:07,260
com o problema de aprender a

966
00:40:07,260 --> 00:40:09,720
estrutura causal do modelo

967
00:40:09,720 --> 00:40:11,880
a partir de dados observacionais

968
00:40:11,880 --> 00:40:13,800
isso é  na verdade, nenhum problema que

969
00:40:13,800 --> 00:40:17,760
existe há ou décadas

970
00:40:17,760 --> 00:40:21,359
e sempre foi até alguns

971
00:40:21,359 --> 00:40:24,000
anos atrás resolvido usando

972
00:40:24,000 --> 00:40:25,560
métodos de pesquisa combinatória

973
00:40:25,560 --> 00:40:26,640
o problema com esses

974
00:40:26,640 --> 00:40:29,280
métodos de pesquisa da comunidade é que sua

975
00:40:29,280 --> 00:40:32,880
complexidade cresce exponencialmente,

976
00:40:32,880 --> 00:40:34,740
assim que os dados se tornam

977
00:40:34,740 --> 00:40:36,780
multi-  dimensional e

978
00:40:36,780 --> 00:40:39,920
o gráfico Bison que você deseja aprender

979
00:40:39,920 --> 00:40:42,300
cresce em tamanho

980
00:40:42,300 --> 00:40:46,680
aprendendo é incrivelmente lento

981
00:40:46,680 --> 00:40:48,780
a nova solução que saiu na verdade há

982
00:40:48,780 --> 00:40:51,000
alguns anos em um novo jornal

983
00:40:51,000 --> 00:40:53,540
de 2018

984
00:40:53,839 --> 00:40:55,920
mostra que é possível realmente

985
00:40:55,920 --> 00:40:57,900
aprender essa estrutura sem usar um

986
00:40:57,900 --> 00:40:59,940
método de pesquisa combinador, mas usando

987
00:40:59,940 --> 00:41:01,619
um método baseado em gradiente

988
00:41:01,619 --> 00:41:05,280
e isso foi basicamente esse

989
00:41:05,280 --> 00:41:07,320
problema qualificado em geral, porque agora

990
00:41:07,320 --> 00:41:08,820
você pode simplesmente

991
00:41:08,820 --> 00:41:10,980
ter uma prévia dos parâmetros, que é

992
00:41:10,980 --> 00:41:12,420
o objetivo prioritário que vou

993
00:41:12,420 --> 00:41:14,700
definir um pouco melhor  neste

994
00:41:14,700 --> 00:41:15,599
slide

995
00:41:15,599 --> 00:41:18,180
run gradiente descendente e mesmo se você

996
00:41:18,180 --> 00:41:19,740
tiver um modelo que é o dobro do triplo o

997
00:41:19,740 --> 00:41:20,820
tamanho

998
00:41:20,820 --> 00:41:23,640
é uh o algoritmo ainda é incrivelmente

999
00:41:23,640 --> 00:41:25,440
rápido

1000
00:41:25,440 --> 00:41:28,260
e por esta razão este artigo é um

1001
00:41:28,260 --> 00:41:31,200
isso é sim eu acho que é meio novo

1002
00:41:31,200 --> 00:41:33,180
e acho que já tem por aí  600

1003
00:41:33,180 --> 00:41:35,099
citações ou coisas ou coisas assim

1004
00:41:35,099 --> 00:41:37,140
e cada artigo que estou vendo agora

1005
00:41:37,140 --> 00:41:38,720
sobre aconselhar amigos e aprender a

1006
00:41:38,720 --> 00:41:42,000
estrutura do gráfico usa seu método,

1007
00:41:42,000 --> 00:41:44,820
apenas muda um pouco quando

1008
00:41:44,820 --> 00:41:46,980
eles encontram métodos de inferência mais rápidos ou um pouco melhores,

1009
00:41:46,980 --> 00:41:49,440
mas ainda assim todos usam

1010
00:41:49,440 --> 00:41:53,760
o  antes do papel definido e eu

1011
00:41:53,760 --> 00:41:56,460
também e nós também,

1012
00:41:56,460 --> 00:41:58,859
então aqui encontraremos uma nova quantidade

1013
00:41:58,859 --> 00:42:01,500
que é a Matriz da agência a

1014
00:42:01,500 --> 00:42:03,480
Matriz da agência é simplesmente uma matriz que codifica

1015
00:42:03,480 --> 00:42:06,359
as conexões do modelo, então é uma

1016
00:42:06,359 --> 00:42:08,520
Matriz binária e

1017
00:42:08,520 --> 00:42:10,920
em geral  é uma matriz binária, então, é

1018
00:42:10,920 --> 00:42:12,180
claro, quando você faz otimização baseada em gradiente,

1019
00:42:12,180 --> 00:42:14,880
você a torna contínua

1020
00:42:14,880 --> 00:42:16,800
e, em seguida, você tem algum limite em algum

1021
00:42:16,800 --> 00:42:19,800
ponto que basicamente mata uma aresta ou

1022
00:42:19,800 --> 00:42:21,480
o define como um

1023
00:42:21,480 --> 00:42:27,780
e o M3 IJ é igual a um se

1024
00:42:27,780 --> 00:42:30,540
tivermos  se o grafo bayesiano é uma aresta

1025
00:42:30,540 --> 00:42:35,040
do vértice I ao vértice J ou zero, caso

1026
00:42:35,040 --> 00:42:37,380
contrário, por exemplo, esta

1027
00:42:37,380 --> 00:42:39,540
matriz de agência aqui representa a

1028
00:42:39,540 --> 00:42:42,780
estrutura de conectividade dessa rede visual

1029
00:42:42,780 --> 00:42:44,040
e

1030
00:42:44,040 --> 00:42:46,079
basicamente esse método

1031
00:42:46,079 --> 00:42:48,780
aborda dois problemas que queremos

1032
00:42:48,780 --> 00:42:51,000
sobre esses uh sobre aprender a

1033
00:42:51,000 --> 00:42:53,460
estrutura  da equação Rede, a

1034
00:42:53,460 --> 00:42:54,780
ideia é começarmos com um

1035
00:42:54,780 --> 00:42:57,200
modelo totalmente conectado que

1036
00:42:57,200 --> 00:43:00,240
conceitualmente é uh é semelhante na verdade

1037
00:43:00,240 --> 00:43:02,220
é equivalente à rede de codificação operacional que

1038
00:43:02,220 --> 00:43:04,020
defini anteriormente que é totalmente

1039
00:43:04,020 --> 00:43:06,480
conectada, então você tem muitos

1040
00:43:06,480 --> 00:43:08,640
vértices e cada par de vértices  está

1041
00:43:08,640 --> 00:43:10,920
conectado por uh por duas arestas diferentes

1042
00:43:10,920 --> 00:43:13,319
e você simplesmente deseja podar as

1043
00:43:13,319 --> 00:43:15,780
que não são necessárias

1044
00:43:15,780 --> 00:43:18,540
para que possa ser visto como um método que

1045
00:43:18,540 --> 00:43:20,819
realiza a redução do modelo você começa com

1046
00:43:20,819 --> 00:43:22,020
um modelo grande e deseja torná-lo

1047
00:43:22,020 --> 00:43:22,800
pequeno

1048
00:43:22,800 --> 00:43:25,800
então o que é  o primeiro ingrediente para

1049
00:43:25,800 --> 00:43:28,260
reduzir bem os modelos é, claro, a cidade esparsa

1050
00:43:28,260 --> 00:43:29,220


1051
00:43:29,220 --> 00:43:31,619
e qual é o prior que todo mundo usa

1052
00:43:31,619 --> 00:43:33,839
para tornar um modelo mais esparso é o

1053
00:43:33,839 --> 00:43:36,480
LaPlace prior que no aprendizado de máquina

1054
00:43:36,480 --> 00:43:38,880
é simplesmente conhecido como Norma L1

1055
00:43:38,880 --> 00:43:40,920
que é definida aqui

1056
00:43:40,920 --> 00:43:43,980
a solução que o  este artigo que

1057
00:43:43,980 --> 00:43:46,740
mencionei anteriormente propôs é adicionar o

1058
00:43:46,740 --> 00:43:49,319
segundo prior no topo, o que reforça o que

1059
00:43:49,319 --> 00:43:53,359
é provavelmente a maior

1060
00:43:53,359 --> 00:43:55,980
característica das redes bayesianas

1061
00:43:55,980 --> 00:43:57,780
nas quais você deseja realizar

1062
00:43:57,780 --> 00:43:59,819
inferência causal é que deseja que sejam

1063
00:43:59,819 --> 00:44:01,020
cíclicas

1064
00:44:01,020 --> 00:44:03,000
e basicamente elas mostraram  essa

1065
00:44:03,000 --> 00:44:06,359
aciclicidade pode ser imposta a uma

1066
00:44:06,359 --> 00:44:08,160
matriz de agência como a priori

1067
00:44:08,160 --> 00:44:10,859
e tem essa forma aqui, então é

1068
00:44:10,859 --> 00:44:14,640
o traço da Matrix que é o

1069
00:44:14,640 --> 00:44:18,420
uh o exponencial de a vezes a

1070
00:44:18,420 --> 00:44:21,859
onde a é a matriz de agência novamente e

1071
00:44:21,859 --> 00:44:24,300
basicamente essa quantidade aqui

1072
00:44:24,300 --> 00:44:27,900
é  é igual a zero se e somente se a

1073
00:44:27,900 --> 00:44:30,480
Rede Bayesiana ou o

1074
00:44:30,480 --> 00:44:32,819
ou o gráfico que você está considerando

1075
00:44:32,819 --> 00:44:35,720
é um c clique,

1076
00:44:37,619 --> 00:44:40,260
então vou usar isso em uh em alguns

1077
00:44:40,260 --> 00:44:42,960
experimentos para que esses dois em Forçar

1078
00:44:42,960 --> 00:44:45,660
esses dois anteriores em

1079
00:44:45,660 --> 00:44:47,520
tipos diferentes  de redes de pacientes

1080
00:44:47,520 --> 00:44:49,200
e estou tentando mesclá-los com as

1081
00:44:49,200 --> 00:44:51,540
técnicas que propusemos anteriormente sobre a

1082
00:44:51,540 --> 00:44:52,740
realização de inferência causal a

1083
00:44:52,740 --> 00:44:55,020
codificação operacional,

1084
00:44:55,020 --> 00:44:56,520
então vou apresentar dois

1085
00:44:56,520 --> 00:44:59,640
experimentos diferentes, então um é uma prova de

1086
00:44:59,640 --> 00:45:00,960
conceito que são os

1087
00:45:00,960 --> 00:45:03,660
experimentos padrão mostrados em  todas as

1088
00:45:03,660 --> 00:45:06,599
tarefas de aprendizado estrutural, que é a inferência da

1089
00:45:06,599 --> 00:45:08,880
Rede Bayesiana correta a partir dos dados

1090
00:45:08,880 --> 00:45:11,760
e, em seguida, vou construir sobre

1091
00:45:11,760 --> 00:45:13,500
os experimentos de classificação que mostrei

1092
00:45:13,500 --> 00:45:14,280
anteriormente

1093
00:45:14,280 --> 00:45:16,020


1094
00:45:16,020 --> 00:45:18,540
e mostrar como, na verdade, esses priores nos

1095
00:45:18,540 --> 00:45:21,060
permitem melhorar a

1096
00:45:21,060 --> 00:45:22,500
classificação  precisão a

1097
00:45:22,500 --> 00:45:25,500
precisão do teste de modelos de codificação preditiva totalmente conectados,

1098
00:45:25,500 --> 00:45:28,160


1099
00:45:29,520 --> 00:45:31,680
então vamos passar para o primeiro experimento

1100
00:45:31,680 --> 00:45:33,300
que é inferir a estrutura do

1101
00:45:33,300 --> 00:45:34,980
gráfico

1102
00:45:34,980 --> 00:45:37,319
e todos os experimentos seguem

1103
00:45:37,319 --> 00:45:39,480
basicamente o mesmo pipeline em todos os

1104
00:45:39,480 --> 00:45:42,060
artigos no campo a primeira etapa é

1105
00:45:42,060 --> 00:45:45,119
gerar  uma rede de visão de gráfico aleatório,

1106
00:45:45,119 --> 00:45:46,079


1107
00:45:46,079 --> 00:45:48,359
basicamente, normalmente os dois

1108
00:45:48,359 --> 00:45:50,640
gráficos aleatórios que todos testam são

1109
00:45:50,640 --> 00:45:53,520
regrafos de Erdos e gráfico livre de escala,

1110
00:45:53,520 --> 00:45:55,859
então você gera aqueles grandes gráficos

1111
00:45:55,859 --> 00:45:58,680
que normalmente têm 20 para os 80 80

1112
00:45:58,680 --> 00:46:01,619
nós diferentes e algumas arestas

1113
00:46:01,619 --> 00:46:04,619
que você amostra aleatoriamente

1114
00:46:04,619 --> 00:46:06,540
e  você usa este gráfico para gerar um

1115
00:46:06,540 --> 00:46:08,280
conjunto de dados

1116
00:46:08,280 --> 00:46:10,819
então você amostra, por exemplo,

1117
00:46:10,819 --> 00:46:14,460
n Big N pontos de dados e o que você faz é

1118
00:46:14,460 --> 00:46:16,859
pegar o gráfico que eles

1119
00:46:16,859 --> 00:46:18,780
geraram anteriormente e jogá-lo

1120
00:46:18,780 --> 00:46:20,819
fora você só mantém o conjunto de dados

1121
00:46:20,819 --> 00:46:23,099
e a tarefa que você  quer resolver agora é

1122
00:46:23,099 --> 00:46:25,020
aprender

1123
00:46:25,020 --> 00:46:27,420
é ter um algoritmo de treinamento que

1124
00:46:27,420 --> 00:46:29,819
basicamente permite que você

1125
00:46:29,819 --> 00:46:32,579
recupere a estrutura do

1126
00:46:32,579 --> 00:46:34,619
gráfico que você jogou fora,

1127
00:46:34,619 --> 00:46:36,839
então a maneira como fazemos isso aqui é que estamos

1128
00:46:36,839 --> 00:46:38,460
em uma codificação criativa totalmente conectada

1129
00:46:38,460 --> 00:46:41,760
modele neste conjunto de dados D usando os

1130
00:46:41,760 --> 00:46:43,800
esparsos e os anteriores SQL que

1131
00:46:43,800 --> 00:46:45,359
definimos anteriormente

1132
00:46:45,359 --> 00:46:48,780
e veja se realmente o

1133
00:46:48,780 --> 00:46:50,760
gráfico para o qual convergimos após

1134
00:46:50,760 --> 00:46:53,220
remover

1135
00:46:53,220 --> 00:46:55,319
as entradas da Matriz de agência que

1136
00:46:55,319 --> 00:46:57,599
são menores que um determinado limite é

1137
00:46:57,599 --> 00:47:00,060
semelhante a  o do gráfico inicial

1138
00:47:00,060 --> 00:47:02,359


1139
00:47:02,520 --> 00:47:04,500
e também mostra que esse é

1140
00:47:04,500 --> 00:47:06,599
realmente o caso, então este é um exemplo

1141
00:47:06,599 --> 00:47:09,020
e mostro muitas

1142
00:47:09,020 --> 00:47:12,420
parametrizações e dimensões diferentes

1143
00:47:12,420 --> 00:47:15,060
e coisas assim no artigo,

1144
00:47:15,060 --> 00:47:16,920
mas acho que esses dois são os

1145
00:47:16,920 --> 00:47:18,900
exemplos mais representativos  com um

1146
00:47:18,900 --> 00:47:20,760
gráfico de berçário de erro e um gráfico de escala livre

1147
00:47:20,760 --> 00:47:23,579
com 20 nós

1148
00:47:23,579 --> 00:47:25,800
e aqui à esquerda você pode ver o

1149
00:47:25,800 --> 00:47:27,300
terreno através do gráfico que é aquele

1150
00:47:27,300 --> 00:47:29,339
amostrado

1151
00:47:29,339 --> 00:47:30,839
aleatoriamente

1152
00:47:30,839 --> 00:47:32,599
e à direita você pode ver o gráfico

1153
00:47:32,599 --> 00:47:35,220
o belo modelo de dificuldade conforme aprendido

1154
00:47:35,220 --> 00:47:37,440
com os dados  definido

1155
00:47:37,440 --> 00:47:39,359
e como você pode ver eles são bastante

1156
00:47:39,359 --> 00:47:40,500
semelhantes

1157
00:47:40,500 --> 00:47:42,780
ainda não é ainda não é perfeito então existem

1158
00:47:42,780 --> 00:47:45,000
alguns erros mas

1159
00:47:45,000 --> 00:47:47,460
em geral a estrutura é que

1160
00:47:47,460 --> 00:47:49,500
eles funcionam muito bem também temos alguns

1161
00:47:49,500 --> 00:47:52,140
experimentos quantitativos

1162
00:47:52,140 --> 00:47:54,000
que eu não mostro aqui  porque eles são

1163
00:47:54,000 --> 00:47:55,740
apenas tabelas enormes com muitos números

1164
00:47:55,740 --> 00:47:57,180
e eu pensei que talvez fosse um pouco

1165
00:47:57,180 --> 00:48:00,660
demais para a apresentação, mas

1166
00:48:00,660 --> 00:48:02,220
os resultados mostram que eles funcionam de forma

1167
00:48:02,220 --> 00:48:06,060
semelhante aos métodos contemporâneos

1168
00:48:06,060 --> 00:48:07,920
também porque eu tenho que dizer como a maior parte

1169
00:48:07,920 --> 00:48:10,859
da qualidade  vem do acigli

1170
00:48:10,859 --> 00:48:15,799
prior que foi introduzido em 2018.

1171
00:48:16,920 --> 00:48:19,680
a segunda classe de experimentos são

1172
00:48:19,680 --> 00:48:21,599
nossos experimentos de classificação que, como

1173
00:48:21,599 --> 00:48:23,880
eu disse, são as extensões do que

1174
00:48:23,880 --> 00:48:25,560
compartilhei anteriormente

1175
00:48:25,560 --> 00:48:27,119
e a ideia é usar o

1176
00:48:27,119 --> 00:48:28,560
aprendizado de estrutura para melhorar a classificação

1177
00:48:28,560 --> 00:48:31,140
sobre os resultados da classificação nos

1178
00:48:31,140 --> 00:48:33,420
meios e meios de moda conjunto de dados

1179
00:48:33,420 --> 00:48:36,780
a partir de um gráfico totalmente conectado,

1180
00:48:36,780 --> 00:48:40,560
então o que eu fiz foi dividir os

1181
00:48:40,560 --> 00:48:42,839
clusters gráficos totalmente conectados de

1182
00:48:42,839 --> 00:48:46,440
neurônios para que o cluster 1B

1183
00:48:46,440 --> 00:48:49,140
seja aquele relacionado à entrada

1184
00:48:49,140 --> 00:48:51,900
e todos os pequenos então  temos um

1185
00:48:51,900 --> 00:48:55,319
número específico de clusters ocultos

1186
00:48:55,319 --> 00:48:57,720
e, em seguida, temos o cluster de rótulo que

1187
00:48:57,720 --> 00:48:58,800
é

1188
00:48:58,800 --> 00:49:01,560
a classe o cluster de neurônios que

1189
00:49:01,560 --> 00:49:04,079
devem me fornecer as previsões de rótulo

1190
00:49:04,079 --> 00:49:06,480


1191
00:49:06,480 --> 00:49:08,700
e eu os treinei usando para usar

1192
00:49:08,700 --> 00:49:10,980
pela primeira vez o sparse anterior  só então

1193
00:49:10,980 --> 00:49:14,099
a ideia é e se eu cortar as

1194
00:49:14,099 --> 00:49:16,500
conexões que não preciso de um

1195
00:49:16,500 --> 00:49:17,460
modelo

1196
00:49:17,460 --> 00:49:20,880
e aprender como o modelo do analisador

1197
00:49:20,880 --> 00:49:24,119
funciona bem, a resposta é não,

1198
00:49:24,119 --> 00:49:25,500
não funciona e o motivo e o

1199
00:49:25,500 --> 00:49:28,500
motivo é  que você, no final, o

1200
00:49:28,500 --> 00:49:30,660
gráfico com o qual você converge é, na verdade,

1201
00:49:30,660 --> 00:49:32,700
a geração, então basicamente o modelo

1202
00:49:32,700 --> 00:49:36,180
aprende a prever o rótulo com base no

1203
00:49:36,180 --> 00:49:38,400
próprio rótulo, descartando todas as

1204
00:49:38,400 --> 00:49:40,020
informações da entrada

1205
00:49:40,020 --> 00:49:42,480
e mantendo apenas o rótulo e, como você pode

1206
00:49:42,480 --> 00:49:45,119
ver aqui, o  rótulo y prevê a si mesmo ou

1207
00:49:45,119 --> 00:49:46,560
em outros experimentos quando você altera os

1208
00:49:46,560 --> 00:49:48,960
parâmetros que você tem que y prevê em

1209
00:49:48,960 --> 00:49:52,520
zero que preex X1 o prevê y novamente

1210
00:49:52,520 --> 00:49:55,980
então qual é a solução para

1211
00:49:55,980 --> 00:49:57,240
este problema bem a solução para este

1212
00:49:57,240 --> 00:49:59,520
problema é que temos que

1213
00:49:59,520 --> 00:50:03,000
convergir  a um gráfico acíclico

1214
00:50:03,000 --> 00:50:05,220
e então temos que adicionar algo que

1215
00:50:05,220 --> 00:50:08,000
impeça uma ciclicidade e o que é isso é

1216
00:50:08,000 --> 00:50:10,200
claro que eu já

1217
00:50:10,200 --> 00:50:12,780
propus e então eu mostro uma segunda

1218
00:50:12,780 --> 00:50:14,520
técnica

1219
00:50:14,520 --> 00:50:17,280
então a primeira usa o SQL

1220
00:50:17,280 --> 00:50:18,680
definido anteriormente anteriormente

1221
00:50:18,680 --> 00:50:21,359
e a segunda é  a é uma nova

1222
00:50:21,359 --> 00:50:22,859
técnica que realmente faz uso de

1223
00:50:22,859 --> 00:50:24,359
exemplos negativos

1224
00:50:24,359 --> 00:50:26,520
então um negativo um exemplo negativo neste

1225
00:50:26,520 --> 00:50:30,060
caso é simplesmente uh o ponto de dados em

1226
00:50:30,060 --> 00:50:32,280
que você tem uma imagem mas o rótulo está

1227
00:50:32,280 --> 00:50:33,240
errado

1228
00:50:33,240 --> 00:50:35,220
então aqui, por exemplo, você tem uma imagem de

1229
00:50:35,220 --> 00:50:36,900
um sete  mas o rótulo que estou dando

1230
00:50:36,900 --> 00:50:39,599
ao modelo é um dois

1231
00:50:39,599 --> 00:50:40,980


1232
00:50:40,980 --> 00:50:44,579
e a ideia é muito simples pois

1233
00:50:44,579 --> 00:50:47,460
já foi usado em muitos trabalhos uh,

1234
00:50:47,460 --> 00:50:49,740
então toda vez que os modelos são um

1235
00:50:49,740 --> 00:50:52,079
exemplo positivo, ele tem que aumentar para

1236
00:50:52,079 --> 00:50:53,520
minimizar a variação  de energia livre

1237
00:50:53,520 --> 00:50:56,520
e toda vez que tem um

1238
00:50:56,520 --> 00:50:58,859
exemplo negativo, tem que aumentá-lo,

1239
00:50:58,859 --> 00:51:01,260
então deixe-me passar para o erro, essa

1240
00:51:01,260 --> 00:51:04,200
quantidade deve ser minimizada

1241
00:51:04,200 --> 00:51:05,960
externamente

1242
00:51:05,960 --> 00:51:08,579
com muitos experimentos e muitos

1243
00:51:08,579 --> 00:51:10,859
uh de experimentos, vimos que as

1244
00:51:10,859 --> 00:51:12,119
duas técnicas

1245
00:51:12,119 --> 00:51:15,000
basicamente, o primeiro leva aos mesmos

1246
00:51:15,000 --> 00:51:17,220
resultados e o segundo leva ao mesmo

1247
00:51:17,220 --> 00:51:18,599
gráfico,

1248
00:51:18,599 --> 00:51:21,000
então aqui

1249
00:51:21,000 --> 00:51:22,800
estão os novos resultados, alguns meios e

1250
00:51:22,800 --> 00:51:25,079
meios modernos usando as duas técnicas

1251
00:51:25,079 --> 00:51:27,660
que acabei de propor

1252
00:51:27,660 --> 00:51:30,960
e agora passamos para algumas que

1253
00:51:30,960 --> 00:51:33,900
ainda não são ótimas, mas definitivamente

1254
00:51:33,900 --> 00:51:36,000
precisões de teste mais razoáveis, então aqui

1255
00:51:36,000 --> 00:51:39,059
temos um erro de teste de 3,17 para minutos e um

1256
00:51:39,059 --> 00:51:42,119
erro de teste de 13,98 para meios de moda

1257
00:51:42,119 --> 00:51:44,819
e, na verdade, esses podem ser esses resultados

1258
00:51:44,819 --> 00:51:48,300
podem ser muito melhorados aprendendo a

1259
00:51:48,300 --> 00:51:51,300
estrutura do gráfico de  triturado

1260
00:51:51,300 --> 00:51:53,040
e, em seguida, corrigindo a estrutura do

1261
00:51:53,040 --> 00:51:55,319
gráfico e fazendo algum tipo de ajuste fino;

1262
00:51:55,319 --> 00:51:57,660


1263
00:51:57,660 --> 00:52:00,000


1264
00:52:00,000 --> 00:52:01,980


1265
00:52:01,980 --> 00:52:03,359


1266
00:52:03,359 --> 00:52:05,460
uns são

1267
00:52:05,460 --> 00:52:08,099
simplesmente aquele para o qual o modelo totalmente conectado

1268
00:52:08,099 --> 00:52:10,980
convergiu naturalmente,

1269
00:52:10,980 --> 00:52:13,859
por exemplo, a partir de um erro de teste de

1270
00:52:13,859 --> 00:52:15,420
18,32

1271
00:52:15,420 --> 00:52:17,339
do modelo totalmente conectado, treinando na

1272
00:52:17,339 --> 00:52:20,359
moda, simplesmente realizando

1273
00:52:20,359 --> 00:52:22,859
correlações ou consultas condicionais,

1274
00:52:22,859 --> 00:52:24,420
que é uma maneira padrão de consultar a adição de

1275
00:52:24,420 --> 00:52:26,520
modelo de codificação operacional  as

1276
00:52:26,520 --> 00:52:29,220
intervenções e o clique AC

1277
00:52:29,220 --> 00:52:32,040
anterior juntos tornam este

1278
00:52:32,040 --> 00:52:34,200
erro de teste muito menor

1279
00:52:34,200 --> 00:52:37,200
e podemos observá-lo por meios também.

1280
00:52:37,200 --> 00:52:39,319


1281
00:52:39,780 --> 00:52:41,819


1282
00:52:41,819 --> 00:52:45,420


1283
00:52:45,420 --> 00:52:48,660
estrutura

1284
00:52:48,660 --> 00:52:50,339
do gráfico

1285
00:52:50,339 --> 00:52:52,440
então eu executo eu realizo uma experiência em

1286
00:52:52,440 --> 00:52:54,960
uh em um novo conjunto de dados, o que significa

1287
00:52:54,960 --> 00:52:56,460
chamar o novo conjunto de dados pode ser

1288
00:52:56,460 --> 00:52:58,500
demais é que eu o chamo de

1289
00:52:58,500 --> 00:53:01,440
conjunto de dados de dois meios no qual você tem o

1290
00:53:01,440 --> 00:53:04,319
ponto de entrada  é formado por duas

1291
00:53:04,319 --> 00:53:07,319
imagens diferentes e o rótulo depende apenas da

1292
00:53:07,319 --> 00:53:08,520
segunda imagem

1293
00:53:08,520 --> 00:53:10,800
da história da primeira imagem,

1294
00:53:10,800 --> 00:53:12,720
então a ideia aqui

1295
00:53:12,720 --> 00:53:15,079
é a estrutura do modelo a

1296
00:53:15,079 --> 00:53:18,540
ciclicidade anterior e coisas assim

1297
00:53:18,540 --> 00:53:20,819
capaz de reconhecer que a segunda metade

1298
00:53:20,819 --> 00:53:23,400
da imagem é  realmente sem sentido em

1299
00:53:23,400 --> 00:53:27,960
uh no desempenho no aprendizado no

1300
00:53:27,960 --> 00:53:31,140
desempenho classificação

1301
00:53:31,140 --> 00:53:33,119
como o treinamento se comporta em geral como,

1302
00:53:33,119 --> 00:53:36,480
por exemplo, temos este uh nó de entrada

1303
00:53:36,480 --> 00:53:39,000
nó de saída e apenas os nós estão

1304
00:53:39,000 --> 00:53:41,940
totalmente conectados e o modelo

1305
00:53:41,940 --> 00:53:43,740
converge para a

1306
00:53:43,740 --> 00:53:45,900
para uma estrutura hierárquica que é a

1307
00:53:45,900 --> 00:53:48,960
um que sabemos ter o melhor desempenho em

1308
00:53:48,960 --> 00:53:50,880
tarefas de classificação

1309
00:53:50,880 --> 00:53:53,520
bem, aqui está um exemplo de um

1310
00:53:53,520 --> 00:53:54,980
método de treinamento

1311
00:53:54,980 --> 00:53:59,280
executado em c0, que é o início do

1312
00:53:59,280 --> 00:54:00,720
treinamento,

1313
00:54:00,720 --> 00:54:03,000
temos este modelo aqui, então s0

1314
00:54:03,000 --> 00:54:05,819
corresponde ao aos sete, portanto

1315
00:54:05,819 --> 00:54:08,099
à primeira imagem  como um corresponde à

1316
00:54:08,099 --> 00:54:09,839
imagem de sete colunas novamente, temos o

1317
00:54:09,839 --> 00:54:12,300
rótulo Y e todas as variáveis ​​latentes x0

1318
00:54:12,300 --> 00:54:13,800
X1 X2

1319
00:54:13,800 --> 00:54:15,720
e o modelo está totalmente conectado, então a

1320
00:54:15,720 --> 00:54:17,040
matriz da agência

1321
00:54:17,040 --> 00:54:20,579
está cheia de uns, não há zeros,

1322
00:54:20,579 --> 00:54:23,720
temos loops automáticos e coisas assim

1323
00:54:23,720 --> 00:54:27,319
modelo por algumas épocas até

1324
00:54:27,319 --> 00:54:30,540
e o que sabemos imediatamente é que, por

1325
00:54:30,540 --> 00:54:31,920
exemplo, o modelo imediatamente

1326
00:54:31,920 --> 00:54:34,740
entende que os quatro não são necessários

1327
00:54:34,740 --> 00:54:36,839
para executar a classificação,

1328
00:54:36,839 --> 00:54:40,740
portanto, todos os nós de saída do

1329
00:54:40,740 --> 00:54:43,980
segundo cluster de entrada são removidos

1330
00:54:43,980 --> 00:54:45,900
e  algo que não entendemos é

1331
00:54:45,900 --> 00:54:48,660
que este cluster é aquele

1332
00:54:48,660 --> 00:54:50,400
relacionado à saída,

1333
00:54:50,400 --> 00:54:52,260
então

1334
00:54:52,260 --> 00:54:55,319
temos um mapa linear de s0 a Y

1335
00:54:55,319 --> 00:54:56,480
diretamente,

1336
00:54:56,480 --> 00:54:59,339
que é esta parte aqui,

1337
00:54:59,339 --> 00:55:01,160
mas sabemos que, na verdade, um mapa linear

1338
00:55:01,160 --> 00:55:04,740
não é o melhor  mapa para

1339
00:55:04,740 --> 00:55:07,200
realizar a classificação de médias então

1340
00:55:07,200 --> 00:55:08,700
precisamos de alguma hierarquia precisamos de alguma

1341
00:55:08,700 --> 00:55:11,579
profundidade para melhorar os resultados e como

1342
00:55:11,579 --> 00:55:14,220
você pode ver esta linha aqui é a

1343
00:55:14,220 --> 00:55:15,599
precisão

1344
00:55:15,599 --> 00:55:18,960
que até este ponto até C2 é

1345
00:55:18,960 --> 00:55:22,500
semelhante a um então é 91  que é

1346
00:55:22,500 --> 00:55:24,059
um pouco melhor do que a classificação linear,

1347
00:55:24,059 --> 00:55:25,500


1348
00:55:25,500 --> 00:55:28,740
mas depois que você continua com o treinamento,

1349
00:55:28,740 --> 00:55:30,660
o modelo entende que precisa de alguma

1350
00:55:30,660 --> 00:55:33,119
hierarquia para melhor ajustar os dados,

1351
00:55:33,119 --> 00:55:35,640
então você vê que essa seta começa

1352
00:55:35,640 --> 00:55:38,760
a ficar cada vez mais forte com o tempo

1353
00:55:38,760 --> 00:55:41,700
até entender que o linear

1354
00:55:41,700 --> 00:55:44,339
mapa não é realmente necessário e

1355
00:55:44,339 --> 00:55:45,920
o remove,

1356
00:55:45,920 --> 00:55:48,780
então o modelo com o qual você converge é um

1357
00:55:48,780 --> 00:55:51,000
modelo que começa do zero vai para um

1358
00:55:51,000 --> 00:55:53,760
nó oculto e depois vai para

1359
00:55:53,760 --> 00:55:57,180
o rótulo com um mapa linear muito fraco

1360
00:55:57,180 --> 00:55:59,700
que na verdade é removido se você se

1361
00:55:59,700 --> 00:56:02,760
você define um limite de uh se o

1362
00:56:02,760 --> 00:56:05,520
limite do vendedor for, por exemplo, 0,1 0,2 em algum

1363
00:56:05,520 --> 00:56:07,619
ponto, o mapa linear é esquecido e

1364
00:56:07,619 --> 00:56:10,680
tudo o que você acaba com é

1365
00:56:10,680 --> 00:56:13,319
com uma rede hierárquica

1366
00:56:13,319 --> 00:56:15,720
que é aquela uh, então ele aprendeu a

1367
00:56:15,720 --> 00:56:17,099
estrutura correta para executar

1368
00:56:17,099 --> 00:56:19,260
tarefas de classificação que são hierarquia

1369
00:56:19,260 --> 00:56:21,900
e também aprendeu que a segunda

1370
00:56:21,900 --> 00:56:25,020
imagem não desempenhou nenhum papel na definição

1371
00:56:25,020 --> 00:56:28,440
da precisão do teste e isso é tudo

1372
00:56:28,440 --> 00:56:30,420
isso é executado também todos esses

1373
00:56:30,420 --> 00:56:33,839
trabalhos são simplesmente executados por

1374
00:56:33,839 --> 00:56:36,599
um processo de minimização de energia livre, então

1375
00:56:36,599 --> 00:56:38,400
você inicializa o modelo você define a

1376
00:56:38,400 --> 00:56:40,859
energia livre você define os priors então

1377
00:56:40,859 --> 00:56:43,559
o sparse e o clique C antes de

1378
00:56:43,559 --> 00:56:45,780
você executar a minimização de energia e

1379
00:56:45,780 --> 00:56:47,400
você convergir para hierárquico para um

1380
00:56:47,400 --> 00:56:49,500
modelo hierárquico que é bem capaz de

1381
00:56:49,500 --> 00:56:51,839
realizar classificação em picado

1382
00:56:51,839 --> 00:56:54,000
e então se você  em seguida, faça alguns

1383
00:56:54,000 --> 00:56:55,800
ajustes finos e você alcançará resultados muito competitivos,

1384
00:56:55,800 --> 00:56:57,359
como em redes de feed forward

1385
00:56:57,359 --> 00:56:59,339
com a propagação de feedback,

1386
00:56:59,339 --> 00:57:01,260
mas acho que não é a

1387
00:57:01,260 --> 00:57:03,780
parte interessante, a parte interessante é que você gosta de

1388
00:57:03,780 --> 00:57:05,160
todo esse processo, esse processo

1389
00:57:05,160 --> 00:57:07,980
todo de intervenção e a

1390
00:57:07,980 --> 00:57:09,780
aciclicidade

1391
00:57:09,780 --> 00:57:11,700
permite  pegar uma rede totalmente conectada

1392
00:57:11,700 --> 00:57:12,660


1393
00:57:12,660 --> 00:57:15,119
e convergir para uma rede hierárquica

1394
00:57:15,119 --> 00:57:16,140
que é capaz de realizar

1395
00:57:16,140 --> 00:57:20,058
classificação com bons resultados

1396
00:57:20,760 --> 00:57:23,000
e sim é

1397
00:57:23,000 --> 00:57:26,280
basicamente isso estou agora oh sim uau já

1398
00:57:26,280 --> 00:57:29,220
falei muito e estou uh esta é a

1399
00:57:29,220 --> 00:57:32,160
conclusão  da palestra, que é

1400
00:57:32,160 --> 00:57:35,280
basicamente um pequeno resumo e

1401
00:57:35,280 --> 00:57:37,559
acho que a lição importante, se eu

1402
00:57:37,559 --> 00:57:39,300
tiver que dar a você em uma frase deste

1403
00:57:39,300 --> 00:57:40,980
artigo, é que a codificação preditiva é um

1404
00:57:40,980 --> 00:57:44,400
método de atualização de crenças que é capaz de

1405
00:57:44,400 --> 00:57:46,559
executar de ponta a  - finalize o aprendizado do primo para que

1406
00:57:46,559 --> 00:57:48,599
ele seja capaz de realizar intervenções para

1407
00:57:48,599 --> 00:57:51,420
aprender uma estrutura a partir de dados e, em seguida,

1408
00:57:51,420 --> 00:57:53,160
realizar intervenções e

1409
00:57:53,160 --> 00:57:56,058
contrafactuais

1410
00:57:56,700 --> 00:57:58,440
para inferência causal em outras

1411
00:57:58,440 --> 00:58:00,119
intervenções e modelar eficientemente,

1412
00:58:00,119 --> 00:58:01,680
simplesmente definindo o erro de previsão como

1413
00:58:01,680 --> 00:58:03,359
zero, por isso é uma técnica muito fácil

1414
00:58:03,359 --> 00:58:06,240
de executar  intervenções e

1415
00:58:06,240 --> 00:58:07,619
você simplesmente só tem que tocar um

1416
00:58:07,619 --> 00:58:08,940
neurônio você não tem que agir na

1417
00:58:08,940 --> 00:58:10,859
estrutura do gráfico

1418
00:58:10,859 --> 00:58:14,339
você pode usá-lo para executar para

1419
00:58:14,339 --> 00:58:16,140
criar modelos causais de estrutura que são

1420
00:58:16,140 --> 00:58:18,359
biologicamente plausíveis

1421
00:58:18,359 --> 00:58:20,819
é capaz de aprender a estrutura para  uh,

1422
00:58:20,819 --> 00:58:24,119
a partir dos dados, como eu disse talvez muitas vezes

1423
00:58:24,119 --> 00:58:26,940


1424
00:58:26,940 --> 00:58:28,740
e algumas frases sobre trabalhos futuros,

1425
00:58:28,740 --> 00:58:31,260


1426
00:58:31,260 --> 00:58:33,180
algo que seria bom fazer é

1427
00:58:33,180 --> 00:58:36,119
melhorar o desempenho do modelo que

1428
00:58:36,119 --> 00:58:38,460
definimos porque acho que ele

1429
00:58:38,460 --> 00:58:40,980
funciona razoavelmente bem em  um monte de

1430
00:58:40,980 --> 00:58:43,079
tarefas, então ele tem um desempenho razoavelmente bom no

1431
00:58:43,079 --> 00:58:45,780
aprendizado estrutural para mim,

1432
00:58:45,780 --> 00:58:48,119
intervenção e contrafactuais, mas,

1433
00:58:48,119 --> 00:58:49,440
na verdade, se você olhar para o modelo de última geração,

1434
00:58:49,440 --> 00:58:51,420
sempre há um

1435
00:58:51,420 --> 00:58:53,880
método muito específico que funciona melhor em

1436
00:58:53,880 --> 00:58:55,559
uma única tarefa,

1437
00:58:55,559 --> 00:58:58,260
então seria interessante ver  se

1438
00:58:58,260 --> 00:59:00,180
pudermos atingir esse nível de desempenho

1439
00:59:00,180 --> 00:59:03,599
em tarefas específicas adicionando alguns

1440
00:59:03,599 --> 00:59:05,599
truques ou alguns

1441
00:59:05,599 --> 00:59:10,260
ou alguns novos métodos de otimização e

1442
00:59:10,260 --> 00:59:12,839
generalizando-os para sistemas dinâmicos

1443
00:59:12,839 --> 00:59:14,280
que são realmente muito mais interessantes

1444
00:59:14,280 --> 00:59:17,220
os sistemas estáticos, como

1445
00:59:17,220 --> 00:59:20,099
modelos causais dinâmicos e ou  outras técnicas

1446
00:59:20,099 --> 00:59:22,200
que permitem realizar

1447
00:59:22,200 --> 00:59:25,200
inferência causal em sistemas que se movem, de modo que

1448
00:59:25,200 --> 00:59:27,799
uma ação executada em uma etapa de tempo específica

1449
00:59:27,799 --> 00:59:30,299
influencia outro nó em uma etapa de tempo posterior,

1450
00:59:30,299 --> 00:59:32,640
que é basicamente uma causalidade de grandeza

1451
00:59:32,640 --> 00:59:34,859


1452
00:59:34,859 --> 00:59:38,160
sim, é isso e

1453
00:59:38,160 --> 00:59:41,118
muito obrigado, obrigado

1454
00:59:47,460 --> 00:59:51,119


1455
00:59:51,119 --> 00:59:53,160
apresentação incrível e muito abrangente que foi realmente acho que

1456
00:59:53,160 --> 00:59:55,700
você está sem som,

1457
00:59:57,119 --> 00:59:59,700
desculpe sem som no Zoom, mas sim, obrigado pela

1458
00:59:59,700 --> 01:00:02,400


1459
01:00:02,400 --> 01:00:05,099
apresentação incrível e muito abrangente, havia muito

1460
01:00:05,099 --> 01:00:06,900
lá e também havia muitas

1461
01:00:06,900 --> 01:00:09,900
perguntas ótimas no bate-papo ao vivo, então talvez para

1462
01:00:09,900 --> 01:00:12,900
aquecer  nas perguntas como você

1463
01:00:12,900 --> 01:00:15,960
estudou este tópico onde você estudou

1464
01:00:15,960 --> 01:00:18,900
causalidade e achou a codificação preditiva

1465
01:00:18,900 --> 01:00:21,000
útil ou vice-versa ou como você

1466
01:00:21,000 --> 01:00:23,160
chegou a esta interseção

1467
01:00:23,160 --> 01:00:25,740
eu realmente tenho que dizer que a primeira

1468
01:00:25,740 --> 01:00:27,240
pessoa que veio com esta ideia foi

1469
01:00:27,240 --> 01:00:29,040
uh era o Baron

1470
01:00:29,040 --> 01:00:33,900
tão tipo eu acho que um ano e

1471
01:00:33,900 --> 01:00:36,660
meio atrás ainda mais ele trouxe uma

1472
01:00:36,660 --> 01:00:38,940
página com essa ideia e então ele foi

1473
01:00:38,940 --> 01:00:42,119
esquecido e ninguém pegou e uh

1474
01:00:42,119 --> 01:00:43,980
e no verão passado eu comecei a ficar

1475
01:00:43,980 --> 01:00:47,880
curioso sobre causalidade e o

1476
01:00:47,880 --> 01:00:50,339
um  Eu li, por exemplo, O Livro da Vida

1477
01:00:50,339 --> 01:00:52,440
enquanto ouvia podcasts, eu conheço a

1478
01:00:52,440 --> 01:00:53,760
maneira padrão pela qual você se interessa

1479
01:00:53,760 --> 01:00:54,900
por um tópico

1480
01:00:54,900 --> 01:00:57,480
e eu me lembro dessa ideia do

1481
01:00:57,480 --> 01:01:00,180
Baron e propus a ele e

1482
01:01:00,180 --> 01:01:03,180
eu pensei: por que não  nós o expandimos e uh

1483
01:01:03,180 --> 01:01:06,000
e realmente o tornamos um papel, então eu

1484
01:01:06,000 --> 01:01:07,319
envolvi algumas pessoas para me ajudar com

1485
01:01:07,319 --> 01:01:09,359
experimentos e uh e este é o

1486
01:01:09,359 --> 01:01:12,000
resultado final no final

1487
01:01:12,000 --> 01:01:14,160
incrível, legal sim,

1488
01:01:14,160 --> 01:01:15,240


1489
01:01:15,240 --> 01:01:17,400
muito a dizer Eu só vou para o

1490
01:01:17,400 --> 01:01:19,619
chat ao vivo  primeiro e abordar um monte de

1491
01:01:19,619 --> 01:01:21,240
perguntas diferentes e se alguém mais

1492
01:01:21,240 --> 01:01:22,440
quiser me adicionar, vou acender a luz

1493
01:01:22,440 --> 01:01:24,059
primeiro porque acho que estou ficando cada

1494
01:01:24,059 --> 01:01:28,440
vez mais no escuro sim,

1495
01:01:28,440 --> 01:01:30,720
quem disse que a inferência ativa não pode resolver  um

1496
01:01:30,720 --> 01:01:32,160
problema de quarto escuro

1497
01:01:32,160 --> 01:01:34,980
oh sim aqui estamos

1498
01:01:34,980 --> 01:01:37,020
então você diria que o interruptor de luz fez com que

1499
01:01:37,020 --> 01:01:39,299
ficasse mais claro

1500
01:01:39,299 --> 01:01:40,680
sim

1501
01:01:40,680 --> 01:01:42,240
acho que

1502
01:01:42,240 --> 01:01:43,980
não há problemas aqui

1503
01:01:43,980 --> 01:01:46,940
ok ml Dawn escreveu

1504
01:01:46,940 --> 01:01:49,559
já que na codificação preditiva todas as

1505
01:01:49,559 --> 01:01:52,020
distribuições são geralmente gaussianas as

1506
01:01:52,020 --> 01:01:53,760
mensagens de baixo para cima são

1507
01:01:53,760 --> 01:01:55,500
Previsão ponderada de precisão  erros em que

1508
01:01:55,500 --> 01:01:57,420
Precisão é o inverso da

1509
01:01:57,420 --> 01:02:00,000
covariância gaussiana e se distribuições não gaussianas

1510
01:02:00,000 --> 01:02:03,319
forem usadas

1511
01:02:03,780 --> 01:02:05,339
é

1512
01:02:05,339 --> 01:02:09,059
basicamente o método geral permanece

1513
01:02:09,059 --> 01:02:10,380
diferente a principal diferença é que

1514
01:02:10,380 --> 01:02:13,079
você não tem erros de previsão

1515
01:02:13,079 --> 01:02:15,480
que, como foi apontado corretamente, é

1516
01:02:15,480 --> 01:02:18,480
basicamente o  derivada da

1517
01:02:18,480 --> 01:02:20,819
energia livre virtual se você tiver suposições gaussianas

1518
01:02:20,819 --> 01:02:22,920


1519
01:02:22,920 --> 01:02:25,020
sim, você ainda tem essa quantidade única

1520
01:02:25,020 --> 01:02:27,960
para definir como zero e provavelmente

1521
01:02:27,960 --> 01:02:29,880
terá que agir na estrutura do

1522
01:02:29,880 --> 01:02:30,900
gráfico

1523
01:02:30,900 --> 01:02:34,020
para realizar intervenções

1524
01:02:34,020 --> 01:02:37,079
e também você e seus colegas tiveram um

1525
01:02:37,079 --> 01:02:39,900
artigo em 2022 preditivo  codificação Além das

1526
01:02:39,900 --> 01:02:41,880
distribuições gaussianas que olharam

1527
01:02:41,880 --> 01:02:43,859
para algumas dessas questões certo sim sim

1528
01:02:43,859 --> 01:02:46,260
exatamente então esse papel foi um

1529
01:02:46,260 --> 01:02:47,339
pouco

1530
01:02:47,339 --> 01:02:50,460
a ideia por trás desse papel é uh

1531
01:02:50,460 --> 01:02:53,220
e nós modelamos Transformers essa é a

1532
01:02:53,220 --> 01:02:54,420
maior motivação usando bastante

1533
01:02:54,420 --> 01:02:57,180
dificuldade e a resposta é uh não é

1534
01:02:57,180 --> 01:02:59,460
porque o  o mecanismo de atenção tem

1535
01:02:59,460 --> 01:03:02,099
um Max suave no final e chamadas de Max suaves

1536
01:03:02,099 --> 01:03:03,960
para uh

1537
01:03:03,960 --> 01:03:08,400
como não para distribuição gaussiana, mas para

1538
01:03:08,400 --> 01:03:11,280
sim para distribuição de Max suave o

1539
01:03:11,280 --> 01:03:13,440
Não entendi o nome agora, mas sim

1540
01:03:13,440 --> 01:03:16,079
e sim, isso é uma generalização,

1541
01:03:16,079 --> 01:03:19,140
é um pouco  complicado chamá-lo assim que

1542
01:03:19,140 --> 01:03:20,700
você remove a suposição de Gaston é um

1543
01:03:20,700 --> 01:03:22,319
pouco complicado chamá-lo de

1544
01:03:22,319 --> 01:03:24,059
codificação criativa,

1545
01:03:24,059 --> 01:03:26,400
então ele é um,

1546
01:03:26,400 --> 01:03:29,819
por exemplo, como falar com o carro

1547
01:03:29,819 --> 01:03:32,700
Freestone ou ele gosta de codificação criativa

1548
01:03:32,700 --> 01:03:35,160
é apenas se você tiver apenas gauss

1549
01:03:35,160 --> 01:03:37,680
e gaussiano  suposições,

1550
01:03:37,680 --> 01:03:39,720
mas sim, isso é mais um

1551
01:03:39,720 --> 01:03:42,660
debate filosófico do que

1552
01:03:42,660 --> 01:03:44,940
interessante e outro tópico que eu acho

1553
01:03:44,940 --> 01:03:46,740
que é definitivamente de grande

1554
01:03:46,740 --> 01:03:49,500
interesse são as semelhanças e diferenças

1555
01:03:49,500 --> 01:03:52,980
entre o aparato de atenção em

1556
01:03:52,980 --> 01:03:56,099
Transformers e a maneira como a atenção

1557
01:03:56,099 --> 01:03:58,440
é descrita de uma

1558
01:03:58,440 --> 01:04:00,180
perspectiva neurocognitiva e de um

1559
01:04:00,180 --> 01:04:03,240
processamento preditivo Precisão  ângulo de espera, o que

1560
01:04:03,240 --> 01:04:06,200
você acha disso?

1561
01:04:06,359 --> 01:04:08,700
Bem, a ideia é que,

1562
01:04:08,700 --> 01:04:12,359
sim, acho que, a partir de uma perspectiva de

1563
01:04:12,359 --> 01:04:15,000
processamento e também de

1564
01:04:15,000 --> 01:04:16,400
inferência operacional,

1565
01:04:16,400 --> 01:04:19,260
a atenção pode ser vista como um tipo de

1566
01:04:19,260 --> 01:04:21,299
problema de aprendizado estrutural.

1567
01:04:21,299 --> 01:04:23,040
artigo recente de uh do

1568
01:04:23,040 --> 01:04:25,680
grupo de Chris Buckley que mostra

1569
01:04:25,680 --> 01:04:26,339
que

1570
01:04:26,339 --> 01:04:28,079
deveria haver uma

1571
01:04:28,079 --> 01:04:30,420
reimpressão no arquivo em que basicamente

1572
01:04:30,420 --> 01:04:31,859
eles mostraram que o mecanismo de atenção

1573
01:04:31,859 --> 01:04:35,819
está simplesmente aprendendo a precisão nos

1574
01:04:35,819 --> 01:04:38,880
parâmetros de peso específicos para

1575
01:04:38,880 --> 01:04:41,040
outros pontos de dados, então esta precisão

1576
01:04:41,040 --> 01:04:43,200
não é um não é um parâmetro

1577
01:04:43,200 --> 01:04:45,540
que está na estrutura do modelo, portanto não é

1578
01:04:45,540 --> 01:04:47,579
um parâmetro específico do modelo

1579
01:04:47,579 --> 01:04:49,140
é um parâmetro de mudança rápida como os

1580
01:04:49,140 --> 01:04:51,660
nós de valor que são atualizados enquanto

1581
01:04:51,660 --> 01:04:53,760
minimizam a variação de energia livre

1582
01:04:53,760 --> 01:04:55,440
e uma vez que você  você minimizou

1583
01:04:55,440 --> 01:04:57,000
e calculou, então você joga fora

1584
01:04:57,000 --> 01:04:58,920
e para o próximo ponto de dados você tem que

1585
01:04:58,920 --> 01:05:00,780
recalculá-lo do zero,

1586
01:05:00,780 --> 01:05:03,299
então sim, eu acho que a analogia da

1587
01:05:03,299 --> 01:05:05,819
computação é uh, o

1588
01:05:05,819 --> 01:05:07,920
mecanismo de atenção pode ser visto como um tipo de

1589
01:05:07,920 --> 01:05:10,559
aprendizado de estrutura, mas um

1590
01:05:10,559 --> 01:05:13,020
aprendizado de estrutura que é específico de ponto de dados e

1591
01:05:13,020 --> 01:05:15,119
não específico de modelo

1592
01:05:15,119 --> 01:05:17,280
e acho que, se quisermos generalizar um

1593
01:05:17,280 --> 01:05:18,960
pouco e ir do

1594
01:05:18,960 --> 01:05:20,339
mecanismo de atenção em

1595
01:05:20,339 --> 01:05:21,900
Transformers para a ciência cognitiva do mecanismo de atenção,

1596
01:05:21,900 --> 01:05:24,180


1597
01:05:24,180 --> 01:05:28,020
sinto que provavelmente são dois diferentes para

1598
01:05:28,020 --> 01:05:31,260
gostar de desenhar semelhanças e  uh, acho que

1599
01:05:31,260 --> 01:05:33,359
a analogia do aprendizado estrutural

1600
01:05:33,359 --> 01:05:36,660
e a importância de uma conexão em

1601
01:05:36,660 --> 01:05:38,760
relação a outra provavelmente

1602
01:05:38,760 --> 01:05:41,900
faz o trabalho muito melhor

1603
01:05:42,000 --> 01:05:44,880
resposta cinza legal ok

1604
01:05:44,880 --> 01:05:49,200
ml Don pergunta em contrafactuais qual é

1605
01:05:49,200 --> 01:05:51,240
a diferença entre variáveis ​​ocultas

1606
01:05:51,240 --> 01:05:55,440
X e variáveis ​​não observadas U

1607
01:05:55,440 --> 01:05:59,180
a diferença é  que você pode

1608
01:05:59,540 --> 01:06:01,740
eu acho que o principal é que você não pode

1609
01:06:01,740 --> 01:06:03,599
observar o uso

1610
01:06:03,599 --> 01:06:05,819
você pode usá-los porque você pode

1611
01:06:05,819 --> 01:06:09,000
calculá-los e corrigi-los mas você não pode

1612
01:06:09,000 --> 01:06:10,559
a ideia é que você não tem controle

1613
01:06:10,559 --> 01:06:13,380
sobre eles então eles usam o uso deve ser

1614
01:06:13,380 --> 01:06:16,020
visto como um ambiente variáveis ​​específicas

1615
01:06:16,020 --> 01:06:18,540
que eles estão lá eles influenciam

1616
01:06:18,540 --> 01:06:21,240
seu processo ok porque o por

1617
01:06:21,240 --> 01:06:23,280
exemplo quando você volta no tempo o

1618
01:06:23,280 --> 01:06:25,079
ambiente é diferente então a ideia é

1619
01:06:25,079 --> 01:06:26,520
por exemplo se você

1620
01:06:26,520 --> 01:06:28,440
gosta de voltar para o para o exemplo

1621
01:06:28,440 --> 01:06:29,880
antes do

1622
01:06:29,880 --> 01:06:31,920
de  a renda esperada de uma pessoa com

1623
01:06:31,920 --> 01:06:34,619
uma inteligência específica de Educação uh

1624
01:06:34,619 --> 01:06:37,440
uh graduação

1625
01:06:37,440 --> 01:06:40,200
a ideia é que se eu quiser ver o

1626
01:06:40,200 --> 01:06:43,559
quanto vou aprender hoje com uh com um

1627
01:06:43,559 --> 01:06:45,359
com não sei com mestrado

1628
01:06:45,359 --> 01:06:47,339
é diferente com respeito  quanto eu

1629
01:06:47,339 --> 01:06:48,359
ganharia

1630
01:06:48,359 --> 01:06:50,819
20 anos atrás com um mestrado é

1631
01:06:50,819 --> 01:06:52,619
diferente por exemplo aqui na Itália em

1632
01:06:52,619 --> 01:06:55,440
relação a outros países e todas aquelas

1633
01:06:55,440 --> 01:06:57,000
variáveis ​​que não estão sob seu

1634
01:06:57,000 --> 01:06:58,859
controle você não pode modelá-las usando sua

1635
01:06:58,859 --> 01:07:00,359
rede de visão

1636
01:07:00,359 --> 01:07:03,480
mas elas estão lá bem então você  você

1637
01:07:03,480 --> 01:07:05,220
não pode ignorá-los quando você

1638
01:07:05,220 --> 01:07:07,559
quer tirar conclusões então ele é sim é

1639
01:07:07,559 --> 01:07:08,760
basicamente tudo que você

1640
01:07:08,760 --> 01:07:10,079
não pode controlar

1641
01:07:10,079 --> 01:07:13,079
você pode inferi-los então você pode

1642
01:07:13,079 --> 01:07:14,819
fazer uma

1643
01:07:14,819 --> 01:07:16,740
inferência contrafactual de volta no tempo e dizer oh 20

1644
01:07:16,740 --> 01:07:19,020
anos atrás eu teria merecido isso  muito

1645
01:07:19,020 --> 01:07:20,640
se

1646
01:07:20,640 --> 01:07:22,559
eu fosse tão inteligente que esse

1647
01:07:22,559 --> 01:07:24,599
diploma em média é claro

1648
01:07:24,599 --> 01:07:27,059
e mas não é que eu possa mudar as

1649
01:07:27,059 --> 01:07:30,720
políticas do governo em relação a empregos ou

1650
01:07:30,720 --> 01:07:32,819
coisas assim

1651
01:07:32,819 --> 01:07:35,099
é um contrafactual mais profundo

1652
01:07:35,099 --> 01:07:38,400
sim exatamente então sim esses são o uso

1653
01:07:38,400 --> 01:07:40,200
incrível tudo bem

1654
01:07:40,200 --> 01:07:42,480
tem  você implementou

1655
01:07:42,480 --> 01:07:45,660
coordenadas generalizadas na codificação preditiva

1656
01:07:45,660 --> 01:07:46,920
não, não,

1657
01:07:46,920 --> 01:07:50,039
nunca fiz isso, uh

1658
01:07:50,039 --> 01:07:52,680
sim, estudei, mas eu uh,

1659
01:07:52,680 --> 01:07:55,260
nunca implementei, sei que eles tendem a

1660
01:07:55,260 --> 01:07:57,599
ser instáveis ​​e uh

1661
01:07:57,599 --> 01:08:00,299
e é  muito difícil torná-los estáveis,

1662
01:08:00,299 --> 01:08:02,940
acho que foi isso

1663
01:08:02,940 --> 01:08:05,460
que aprendi conversando com pessoas que

1664
01:08:05,460 --> 01:08:08,359
os implementaram,

1665
01:08:08,400 --> 01:08:11,039
mas sim, sim, estou ciente de alguns

1666
01:08:11,039 --> 01:08:12,839
artigos publicados recentemente

1667
01:08:12,839 --> 01:08:15,599
sobre eles que foram testados em

1668
01:08:15,599 --> 01:08:18,000
alguma carga britânica  estilo do codificador, na verdade,

1669
01:08:18,000 --> 01:08:20,520
acho que ainda é do Baron,

1670
01:08:20,520 --> 01:08:22,979
há um artigo que saiu no

1671
01:08:22,979 --> 01:08:25,439
verão passado, mas não, eu nunca

1672
01:08:25,439 --> 01:08:26,580
os joguei com eles sozinho.

1673
01:08:26,580 --> 01:08:29,160


1674
01:08:29,160 --> 01:08:32,040


1675
01:08:32,040 --> 01:08:35,160


1676
01:08:35,160 --> 01:08:38,238


1677
01:08:38,939 --> 01:08:41,698
nível

1678
01:08:41,698 --> 01:08:43,439
em que sentido, porque o

1679
01:08:43,439 --> 01:08:45,779
problema de destruição é dado por Cycles, então basicamente

1680
01:08:45,779 --> 01:08:47,399
você fornece uma imagem

1681
01:08:47,399 --> 01:08:49,920
e o fato de que você tem uh

1682
01:08:49,920 --> 01:08:53,279
tão patches saindo da imagem indo

1683
01:08:53,279 --> 01:08:55,799
para os neurônios e então outras arestas

1684
01:08:55,799 --> 01:08:57,500
voltando

1685
01:08:57,500 --> 01:08:59,939
isso basicamente cria o fato de que  você

1686
01:08:59,939 --> 01:09:03,560
tem um erro de que basicamente

1687
01:09:03,560 --> 01:09:06,179
esses ajustes de entrada para os pixels

1688
01:09:06,179 --> 01:09:08,339
da imagem criam alguns

1689
01:09:08,339 --> 01:09:09,719
erros de previsão, então você tem alguns

1690
01:09:09,719 --> 01:09:12,140
erros de previsão que se espalham dentro do modelo

1691
01:09:12,140 --> 01:09:14,640
e isso é sim e esse problema eu acho que

1692
01:09:14,640 --> 01:09:16,979
é geral de ciclos e  provavelmente

1693
01:09:16,979 --> 01:09:21,439
não está relacionado à hierarquia em geral

1694
01:09:23,060 --> 01:09:25,140
para os pixels

1695
01:09:25,140 --> 01:09:26,759
se você não tiver arestas de entrada, você

1696
01:09:26,759 --> 01:09:27,660
não terá nenhum

1697
01:09:27,660 --> 01:09:30,540
problema de destruição mais

1698
01:09:30,540 --> 01:09:33,238
legal e a especificação da

1699
01:09:33,238 --> 01:09:35,939
rede acíclica através do operador de rastreamento

1700
01:09:35,939 --> 01:09:37,859


1701
01:09:37,859 --> 01:09:41,819
que é uma técnica muito interessante e

1702
01:09:41,819 --> 01:09:46,339
quando isso foi trazido  em jogo

1703
01:09:46,560 --> 01:09:49,140
uh, até onde eu sei, acho que ele saiu

1704
01:09:49,140 --> 01:09:52,380
com o artigo eu citei em 2018

1705
01:09:52,380 --> 01:09:54,360
eu não sei pelo menos na

1706
01:09:54,360 --> 01:09:56,940
literatura de inferência causal eu não tenho conhecimento

1707
01:09:56,940 --> 01:09:59,699
de nenhum método anterior eu diria não

1708
01:09:59,699 --> 01:10:01,860
porque isso  Quero dizer, esse é o

1709
01:10:01,860 --> 01:10:04,140
artigo altamente citado, então eu diria que eles

1710
01:10:04,140 --> 01:10:05,520
tiveram essa ideia,

1711
01:10:05,520 --> 01:10:07,980
uau, sim, é muito bom que

1712
01:10:07,980 --> 01:10:09,480
você possa fazer gradiente descendente e aprender

1713
01:10:09,480 --> 01:10:11,400
a estrutura.

1714
01:10:11,400 --> 01:10:14,219


1715
01:10:14,219 --> 01:10:15,840


1716
01:10:15,840 --> 01:10:17,640
quando diferentes

1717
01:10:17,640 --> 01:10:19,440
recursos de inferência bayesiana e

1718
01:10:19,440 --> 01:10:23,159
inferência causal se tornaram disponíveis,

1719
01:10:23,159 --> 01:10:25,620
é realmente notável, por que

1720
01:10:25,620 --> 01:10:28,500
isso não foi feito sob uma

1721
01:10:28,500 --> 01:10:30,719
estrutura de modelagem causal bayesiana?

1722
01:10:30,719 --> 01:10:32,760


1723
01:10:32,760 --> 01:10:36,659


1724
01:10:36,659 --> 01:10:39,960
e também

1725
01:10:39,960 --> 01:10:42,060
é relativamente técnico, então há

1726
01:10:42,060 --> 01:10:43,920
relativamente poucos grupos de pesquisa envolvidos

1727
01:10:43,920 --> 01:10:46,920
nisso e é

1728
01:10:46,920 --> 01:10:49,860
muito legal o que está permitindo

1729
01:10:49,860 --> 01:10:51,960
não sim sim exatamente quero dizer isso também

1730
01:10:51,960 --> 01:10:54,179
acho que a parte emocionante desse campo um

1731
01:10:54,179 --> 01:10:56,040
pouco isso é uh quero dizer

1732
01:10:56,040 --> 01:10:59,100
definitivamente há  avanços por aí que

1733
01:10:59,100 --> 01:11:01,020
ainda precisam ser descobertos e provavelmente

1734
01:11:01,020 --> 01:11:03,000
porque, por exemplo, tanto

1735
01:11:03,000 --> 01:11:05,300
quanto um avanço naquele papel,

1736
01:11:05,300 --> 01:11:07,800
eles encontraram uh

1737
01:11:07,800 --> 01:11:09,960
como se eles simplesmente descobrissem o

1738
01:11:09,960 --> 01:11:12,120
prior correto para estruturas acíclicas

1739
01:11:12,120 --> 01:11:14,040
ok é um

1740
01:11:14,040 --> 01:11:17,100
sim, quero dizer, eu não sei  exatamente, mas

1741
01:11:17,100 --> 01:11:19,080
pode ser uma ideia que você teve em uma

1742
01:11:19,080 --> 01:11:21,120
tarde, não sei sobre a história

1743
01:11:21,120 --> 01:11:23,040
de como os outros tiveram isso,

1744
01:11:23,040 --> 01:11:25,320
mas pode ser que eles

1745
01:11:25,320 --> 01:11:27,239
estejam lá no quadro branco, você fica

1746
01:11:27,239 --> 01:11:29,280
tipo, na verdade  funciona, é um

1747
01:11:29,280 --> 01:11:32,159
grande avanço e eu simplesmente

1748
01:11:32,159 --> 01:11:33,960
defini o anterior

1749
01:11:33,960 --> 01:11:36,739
e também muitos desses avanços,

1750
01:11:36,739 --> 01:11:40,500
eles não apenas empilham, não é como

1751
01:11:40,500 --> 01:11:44,280
uma torre de blocos, eles colocam em

1752
01:11:44,280 --> 01:11:47,640
camadas e compõem, então algo

1753
01:11:47,640 --> 01:11:50,159
será generalizado para um

1754
01:11:50,159 --> 01:11:52,140
coordenadas generalizadas ou sincronia generalizada ou

1755
01:11:52,140 --> 01:11:55,020
gráficos arbitrariamente grandes ou

1756
01:11:55,020 --> 01:11:57,239
um Sensor Fusion com entradas multimodais

1757
01:11:57,239 --> 01:12:00,679
e é como se todos se misturassem de

1758
01:12:00,679 --> 01:12:03,659
maneiras realmente satisfatórias e eficazes, então mesmo

1759
01:12:03,659 --> 01:12:05,640
pequenas coisas que novamente alguém pode

1760
01:12:05,640 --> 01:12:08,100
inventar em um momento

1761
01:12:08,100 --> 01:12:11,100
podem realmente ter um impacto

1762
01:12:11,100 --> 01:12:14,159
um  ok ml Dawn agradece muito por

1763
01:12:14,159 --> 01:12:16,199
fazer minhas perguntas e agradece um milhão

1764
01:12:16,199 --> 01:12:18,060
a Tomaso pela apresentação inspiradora

1765
01:12:18,060 --> 01:12:21,360
tão legal oh muito obrigado e então

1766
01:12:21,360 --> 01:12:23,280
Bert pergunta

1767
01:12:23,280 --> 01:12:25,560
como os modelos de linguagem que usam

1768
01:12:25,560 --> 01:12:27,179
codificação preditiva diferem daqueles que

1769
01:12:27,179 --> 01:12:30,260
usam Transformers

1770
01:12:31,679 --> 01:12:32,520
hum

1771
01:12:32,520 --> 01:12:35,340
ok, acho que na verdade  se eu tivesse que

1772
01:12:35,340 --> 01:12:36,659
construir hoje um modelo de linguagem

1773
01:12:36,659 --> 01:12:38,640
usando codificação preditiva, ainda usaria

1774
01:12:38,640 --> 01:12:40,020
os Transformers,

1775
01:12:40,020 --> 01:12:41,880
então a ideia é que, por exemplo, se você

1776
01:12:41,880 --> 01:12:42,780
tiver,

1777
01:12:42,780 --> 01:12:45,659
digamos, esse modelo gráfico hierárquico

1778
01:12:45,659 --> 01:12:48,440
dessa ou dessas

1779
01:12:48,440 --> 01:12:50,460
redes bayesianas hierárquicas que

1780
01:12:50,460 --> 01:12:53,100
defini no  os primeiros

1781
01:12:53,100 --> 01:12:55,380
slides uma seta para codificar uma função

1782
01:12:55,380 --> 01:12:57,300
que é o mapa linear

1783
01:12:57,300 --> 01:12:59,219
ok então uma hora foi simplesmente a

1784
01:12:59,219 --> 01:13:01,080
multiplicação de um do vetor

1785
01:13:01,080 --> 01:13:03,060
codificado nas variáveis ​​latentes vezes

1786
01:13:03,060 --> 01:13:06,300
esta matriz de peso que você pode então

1787
01:13:06,300 --> 01:13:08,580
tornar não linear e coisas assim  mas

1788
01:13:08,580 --> 01:13:09,960
isso pode ser realmente algo muito mais

1789
01:13:09,960 --> 01:13:12,179
complexo do que a função incluída na

1790
01:13:12,179 --> 01:13:14,880
seta pode ser uma convolução pode ser um

1791
01:13:14,880 --> 01:13:16,800
mecanismo de atenção

1792
01:13:16,800 --> 01:13:20,820
então, na verdade, como eu faria isso,

1793
01:13:20,820 --> 01:13:23,880
ainda usarei o que quero dizer, que é realmente

1794
01:13:23,880 --> 01:13:26,460
a maneira como fizemos em uh  no

1795
01:13:26,460 --> 01:13:28,860
Grupo Oxford no ano passado é que tínhamos

1796
01:13:28,860 --> 01:13:30,900
exatamente a estrutura que cada flecha é um

1797
01:13:30,900 --> 01:13:33,420
transformador agora, então um é o

1798
01:13:33,420 --> 01:13:35,159
mecanismo de atenção e o próximo é a

1799
01:13:35,159 --> 01:13:38,219
rede de alimentação como transformadores

1800
01:13:38,219 --> 01:13:40,020
e basicamente a única diferença que

1801
01:13:40,020 --> 01:13:41,640
você tem é que esses  variáveis ​​que você

1802
01:13:41,640 --> 01:13:43,739
deseja calcular o posterior e você

1803
01:13:43,739 --> 01:13:45,239
torna esses posteriores Independência

1804
01:13:45,239 --> 01:13:47,400
independente via aproximação de campo médio VIA,

1805
01:13:47,400 --> 01:13:49,560
então basicamente você segue

1806
01:13:49,560 --> 01:13:51,659
todas as etapas que permitem

1807
01:13:51,659 --> 01:13:53,520
convergir para a

1808
01:13:53,520 --> 01:13:56,520
energia livre de variação da codificação criativa, mas do

1809
01:13:56,520 --> 01:13:58,199
jeito que você  calcular previsões

1810
01:13:58,199 --> 01:14:01,199
e a maneira como você envia sinais de volta

1811
01:14:01,199 --> 01:14:04,739
é feito via Transformer,

1812
01:14:04,739 --> 01:14:07,560
então ainda usarei Transformers em

1813
01:14:07,560 --> 01:14:10,679
geral, quero dizer, eles funcionam tão bem que eu

1814
01:14:10,679 --> 01:14:12,840
não acho que podemos ser arrogantes

1815
01:14:12,840 --> 01:14:15,060
e dizer oh não, eu vou fazer isso  melhor por meio de

1816
01:14:15,060 --> 01:14:17,640


1817
01:14:17,640 --> 01:14:18,920
estruturas de codificação puramente preditivas,

1818
01:14:18,920 --> 01:14:21,480
mas ainda se aproximará dos Transformers

1819
01:14:21,480 --> 01:14:22,500
de qualquer maneira,

1820
01:14:22,500 --> 01:14:24,420
desculpe, você disse que o aprendizado da estrutura se

1821
01:14:24,420 --> 01:14:27,540
aproximaria da abordagem do Transformer

1822
01:14:27,540 --> 01:14:29,219
sim, o aprendizado da estrutura que mencionei

1823
01:14:29,219 --> 01:14:32,640
anteriormente em uh quando quando alguém uh pergunta

1824
01:14:32,640 --> 01:14:34,800
as semelhanças entre a codificação criativa

1825
01:14:34,800 --> 01:14:38,060
e o mecanismo de atenção

1826
01:14:38,280 --> 01:14:41,699
muito sim muito  interessante,

1827
01:14:41,699 --> 01:14:42,900


1828
01:14:42,900 --> 01:14:45,719
uma coisa que estou me perguntando sobre a Amazon,

1829
01:14:45,719 --> 01:14:47,640
não consegui ver o conceito de profundidade

1830
01:14:47,640 --> 01:14:49,380
nas redes de codificação preditiva que você

1831
01:14:49,380 --> 01:14:50,880
mencionou, provavelmente não entendi a

1832
01:14:50,880 --> 01:14:52,380
definição fornecida para

1833
01:14:52,380 --> 01:14:56,480
codificação preditiva envolvia o conceito de profundidade,

1834
01:14:56,640 --> 01:14:59,460
o que você quis dizer com profundidade

1835
01:14:59,460 --> 01:15:02,219
não, sim, é verdade  é uh porque a

1836
01:15:02,219 --> 01:15:04,980
definição padrão, como eu disse várias

1837
01:15:04,980 --> 01:15:06,960
vezes, é hierárquica, você tem

1838
01:15:06,960 --> 01:15:08,400
previsões indo em One Direction algum

1839
01:15:08,400 --> 01:15:09,719
erro de previsão indo na direção oposta

1840
01:15:09,719 --> 01:15:10,620


1841
01:15:10,620 --> 01:15:14,340
basicamente o que uh o que fizemos neste

1842
01:15:14,340 --> 01:15:16,320
artigo e também no último em uh

1843
01:15:16,320 --> 01:15:18,420
que é chamado  O aprendizado sobre

1844
01:15:18,420 --> 01:15:19,920
topologias de gráficos arbitrários que temos

1845
01:15:19,920 --> 01:15:22,260
codificação relativa é que podemos considerar a

1846
01:15:22,260 --> 01:15:25,620
profundidade uh como

1847
01:15:25,620 --> 01:15:28,380
independente uh

1848
01:15:28,380 --> 01:15:31,380
basicamente par de variável latente variável latente

1849
01:15:31,380 --> 01:15:33,239
e seta

1850
01:15:33,239 --> 01:15:34,739
e você tem previsões indo nessa

1851
01:15:34,739 --> 01:15:36,300
direção e a seta de previsão indo

1852
01:15:36,300 --> 01:15:38,340
com a outra, mas então você  pode compor

1853
01:15:38,340 --> 01:15:41,880
isso de quantas maneiras

1854
01:15:41,880 --> 01:15:45,239
você pode, então basicamente essa

1855
01:15:45,239 --> 01:15:47,040
composição não precisa ser

1856
01:15:47,040 --> 01:15:48,659
hierárquica no final

1857
01:15:48,659 --> 01:15:50,820
pode ter Ciclos então você pode, por

1858
01:15:50,820 --> 01:15:53,520
exemplo, conectar outra uh outra

1859
01:15:53,520 --> 01:15:55,440
variável latente à primeira  um e

1860
01:15:55,440 --> 01:15:57,540
depois conectar os outros e você pode

1861
01:15:57,540 --> 01:15:59,340
ter uma estrutura tão emaranhada

1862
01:15:59,340 --> 01:16:00,420
quanto você quiser,

1863
01:16:00,420 --> 01:16:02,699
por exemplo, no outro papel,

1864
01:16:02,699 --> 01:16:04,500
treinamos o

1865
01:16:04,500 --> 01:16:06,659
uh uma rede que tem a forma de uma

1866
01:16:06,659 --> 01:16:08,460
estrutura cerebral, então temos muitos

1867
01:16:08,460 --> 01:16:09,900
regiões do cérebro que estão esparsamente

1868
01:16:09,900 --> 01:16:12,239
conectadas por dentro e parcialmente

1869
01:16:12,239 --> 01:16:13,860
conectadas entre si

1870
01:16:13,860 --> 01:16:15,719
e não há nada

1871
01:16:15,719 --> 01:16:17,640
hierárquico lá no final, mas você

1872
01:16:17,640 --> 01:16:18,960
ainda pode treiná-lo minimizando a

1873
01:16:18,960 --> 01:16:20,699
energia livre operacional e

1874
01:16:20,699 --> 01:16:22,620
minimizando o erro total de previsão

1875
01:16:22,620 --> 01:16:25,159
da rede

1876
01:16:25,159 --> 01:16:27,360
para que você possa ter

1877
01:16:27,360 --> 01:16:31,980
para um determinado Motif em um gráfico emaranhado,

1878
01:16:31,980 --> 01:16:35,159
você pode ver três camadas sucessivas

1879
01:16:35,159 --> 01:16:37,560
que, quando você olhasse para elas sozinhas,

1880
01:16:37,560 --> 01:16:38,820
diria oh, é um prédio de três andares,

1881
01:16:38,820 --> 01:16:41,940
é um modelo de três camadas que diz

1882
01:16:41,940 --> 01:16:43,980
adaptável três, mas quando você tira uma

1883
01:16:43,980 --> 01:16:46,620
foto maior lá  não é como um

1884
01:16:46,620 --> 01:16:50,280
topo explícito ou um fundo explícito para

1885
01:16:50,280 --> 01:16:52,140
essa rede

1886
01:16:52,140 --> 01:16:54,360
sim exatamente e isso é basicamente dado

1887
01:16:54,360 --> 01:16:55,980
pelo fato de que toda operação

1888
01:16:55,980 --> 01:16:58,080
em redes preditivas coreanas é uh é

1889
01:16:58,080 --> 01:16:59,460
estritamente local,

1890
01:16:59,460 --> 01:17:01,739
então basicamente toda mensagem passando

1891
01:17:01,739 --> 01:17:03,000
toda previsão e todo

1892
01:17:03,000 --> 01:17:05,280
erro de previsão  que você envia, você envia apenas para

1893
01:17:05,280 --> 01:17:08,280
os neurônios muito próximos, ok e se

1894
01:17:08,280 --> 01:17:10,380
a estrutura global é realmente

1895
01:17:10,380 --> 01:17:13,380
hierárquica ou não, a única

1896
01:17:13,380 --> 01:17:16,940
mensagem que passa nem mesmo vê isso,

1897
01:17:17,460 --> 01:17:19,620
acho que é uma espécie de

1898
01:17:19,620 --> 01:17:22,820
esperança para aprender novas

1899
01:17:22,820 --> 01:17:27,739
arquiteturas de modelo é o espaço de  o que é

1900
01:17:27,739 --> 01:17:33,300
projetado de cima para baixo é muito pequeno e

1901
01:17:33,300 --> 01:17:36,480
muitos modelos em uso hoje, embora sejam

1902
01:17:36,480 --> 01:17:38,640
modelos super eficazes,

1903
01:17:38,640 --> 01:17:41,100
embora você possa perguntar sobre eficácia por

1904
01:17:41,100 --> 01:17:43,320
unidade de computação ou não, essa é uma

1905
01:17:43,320 --> 01:17:45,300
questão de segundo nível, mas muitos

1906
01:17:45,300 --> 01:17:47,580
modelos eficazes hoje não têm alguns desses

1907
01:17:47,580 --> 01:17:49,860
propriedades de redes de codificação preditiva,

1908
01:17:49,860 --> 01:17:52,739
como sua capacidade

1909
01:17:52,739 --> 01:17:55,520
de usar apenas computações locais, o

1910
01:17:55,520 --> 01:17:59,400
que fornece realismo biológico

1911
01:17:59,400 --> 01:18:02,880
ou apenas realismo espaço-temporal, mas

1912
01:18:02,880 --> 01:18:06,060
também pode fornecer muitas vantagens em

1913
01:18:06,060 --> 01:18:08,159


1914
01:18:08,159 --> 01:18:10,500
configurações de computação federada ou de computação distribuída

1915
01:18:10,500 --> 01:18:12,780
não sim exatamente concordo plenamente

1916
01:18:12,780 --> 01:18:14,520
porque concordo  acho que a ideia em geral é

1917
01:18:14,520 --> 01:18:16,679
essa e não sei se isso vai

1918
01:18:16,679 --> 01:18:18,540
ser uma vantagem, então acho que é muito

1919
01:18:18,540 --> 01:18:20,159
promissor exatamente pelas razões que você

1920
01:18:20,159 --> 01:18:20,880
disse

1921
01:18:20,880 --> 01:18:22,920
e uh e a razão é que a

1922
01:18:22,920 --> 01:18:25,380
cadeia de modelos de hoje com propagação reversa você

1923
01:18:25,380 --> 01:18:28,860
pode basicamente uh resumir  eles como

1924
01:18:28,860 --> 01:18:32,040
um monitoramento de propagação reversa é uma

1925
01:18:32,040 --> 01:18:34,080
função porque basicamente você tem um

1926
01:18:34,080 --> 01:18:36,120
mapa da entrada para a saída e a

1927
01:18:36,120 --> 01:18:39,600
propagação reversa basicamente espalha uh

1928
01:18:39,600 --> 01:18:41,699
informações de volta a partir de seu

1929
01:18:41,699 --> 01:18:44,340
gráfico computacional, então cada

1930
01:18:44,340 --> 01:18:45,960
modelo de rede neural de rede neural usado hoje

1931
01:18:45,960 --> 01:18:48,960
é uma função enquanto codificação preditiva

1932
01:18:48,960 --> 01:18:51,179
e outra codificação libertadora como a

1933
01:18:51,179 --> 01:18:53,820
antiga classe de funções que a classe de

1934
01:18:53,820 --> 01:18:56,040
métodos que treina usando

1935
01:18:56,040 --> 01:18:58,500
cálculos locais e realmente funciona

1936
01:18:58,500 --> 01:19:01,620
minimizando uma função de energia global,

1937
01:19:01,620 --> 01:19:03,840
eles não estão limitados a modelar funções

1938
01:19:03,840 --> 01:19:05,940
de entrada para saída, eles realmente modelam

1939
01:19:05,940 --> 01:19:07,739
algo que isso  meio que se assemelha a

1940
01:19:07,739 --> 01:19:10,080
sistemas físicos, então você tem um

1941
01:19:10,080 --> 01:19:13,500
sistema físico para o qual fixa alguns valores para

1942
01:19:13,500 --> 01:19:15,360
qualquer entrada que tenha e deixa o

1943
01:19:15,360 --> 01:19:17,280
sistema convergir e então lê algum

1944
01:19:17,280 --> 01:19:19,980
outro valor de uh neurônios ou variáveis

1945
01:19:19,980 --> 01:19:21,960
que deveriam ser saídas, mas este

1946
01:19:21,960 --> 01:19:24,120
sistema físico não  não precisa ser um

1947
01:19:24,120 --> 01:19:25,920
mapa de ajuste direto não precisa ser uma

1948
01:19:25,920 --> 01:19:28,260
função que tenha um espaço de entrada e

1949
01:19:28,260 --> 01:19:30,659
um espaço de saída e é isso,

1950
01:19:30,659 --> 01:19:32,580
então a classe de modelos que você pode

1951
01:19:32,580 --> 01:19:34,800
aprender é, basicamente, você pode ver

1952
01:19:34,800 --> 01:19:37,560
como modelos de feed forward  e funções

1953
01:19:37,560 --> 01:19:39,600
e, em seguida, uma classe muito maior que é

1954
01:19:39,600 --> 01:19:41,880
a de sistemas físicos se há

1955
01:19:41,880 --> 01:19:43,860
algo interessante aqui eu

1956
01:19:43,860 --> 01:19:45,659
ainda não sei porque as funções estão

1957
01:19:45,659 --> 01:19:47,460
funcionando extremamente bem estamos vendo

1958
01:19:47,460 --> 01:19:50,040
aqueles dias com propagação reversa é um

1959
01:19:50,040 --> 01:19:52,199
trabalho muito bom, mas então

1960
01:19:52,199 --> 01:19:53,460
sim  Não sei se há algo

1961
01:19:53,460 --> 01:19:56,040
interessante na parte grande, mas a

1962
01:19:56,040 --> 01:19:58,380
parte grande é bem grande, existem

1963
01:19:58,380 --> 01:20:00,480
muitos modelos que você

1964
01:20:00,480 --> 01:20:02,940
não pode trazer de volta a propagação e

1965
01:20:02,940 --> 01:20:04,679
pode treinar com codificação criativa

1966
01:20:04,679 --> 01:20:06,659
ou propagação de banheiro ou outros

1967
01:20:06,659 --> 01:20:07,860
métodos

1968
01:20:07,860 --> 01:20:10,440
isso é superinteressante certamente

1969
01:20:10,440 --> 01:20:12,719
sistemas biológicos sistemas físicos

1970
01:20:12,719 --> 01:20:15,900
resolvem todos os tipos de problemas interessantes,

1971
01:20:15,900 --> 01:20:17,100


1972
01:20:17,100 --> 01:20:19,380
mas ainda não há almoço grátis

1973
01:20:19,380 --> 01:20:21,540
em espécies de formigas que se dão muito bem

1974
01:20:21,540 --> 01:20:23,100
neste ambiente podem não se dar muito bem

1975
01:20:23,100 --> 01:20:25,679
em outro ambiente e assim por

1976
01:20:25,679 --> 01:20:28,260
aí no sertão

1977
01:20:28,260 --> 01:20:31,820
pode haver alguns algoritmos especiais realmente únicos

1978
01:20:31,820 --> 01:20:35,880
que não são bem descritos

1979
01:20:35,880 --> 01:20:38,460
por serem uma função,

1980
01:20:38,460 --> 01:20:42,060
mas ainda fornecem uma

1981
01:20:42,060 --> 01:20:46,679
maneira processual de implementar heurísticas

1982
01:20:46,679 --> 01:20:48,840
que podem ser extremamente

1983
01:20:48,840 --> 01:20:51,120
eficazes

1984
01:20:51,120 --> 01:20:53,880
não sim sim exatamente e uh sim qualquer coisa

1985
01:20:53,880 --> 01:20:55,679
isso tem sido a maior parte do meu

1986
01:20:55,679 --> 01:20:58,260
foco  de pesquisa durante meu doutorado, por

1987
01:20:58,260 --> 01:20:59,100
exemplo,

1988
01:20:59,100 --> 01:21:01,380
como encontrar este aplicativo que é

1989
01:21:01,380 --> 01:21:04,199
como aqui e não dentro das

1990
01:21:04,199 --> 01:21:06,739
funções legais,

1991
01:21:07,199 --> 01:21:08,820
bem, para

1992
01:21:08,820 --> 01:21:12,120
onde esse trabalho vai a partir daqui, como

1993
01:21:12,120 --> 01:21:14,520
quais direções você está animado

1994
01:21:14,520 --> 01:21:17,340
e como você vê as pessoas no

1995
01:21:17,340 --> 01:21:19,679
ecossistema de inferência ativa obtendo  envolvido

1996
01:21:19,679 --> 01:21:22,460
neste tipo de trabalho,

1997
01:21:22,500 --> 01:21:24,840
acho que provavelmente a

1998
01:21:24,840 --> 01:21:27,780
direção mais promissora, que é

1999
01:21:27,780 --> 01:21:30,060
algo que talvez eu gostaria de

2000
01:21:30,060 --> 01:21:33,060
explorar um pouco, como eu disse,

2001
01:21:33,060 --> 01:21:34,980
realmente há como ir atrás de

2002
01:21:34,980 --> 01:21:37,380
modelos estáticos, então tudo o que mostrei  O que

2003
01:21:37,380 --> 01:21:40,260
mostrei até agora é sobre dados estáticos,

2004
01:21:40,260 --> 01:21:42,840
então os dados não mudam com o tempo,

2005
01:21:42,840 --> 01:21:45,780
não há tempo dentro da definição de

2006
01:21:45,780 --> 01:21:48,000
codificação criativa, pois é como apresentei

2007
01:21:48,000 --> 01:21:49,080
aqui, no

2008
01:21:49,080 --> 01:21:50,940
entanto, você pode, por exemplo, generalizar a

2009
01:21:50,940 --> 01:21:53,280
codificação criativa para funcionar  com

2010
01:21:53,280 --> 01:21:55,800
dados temporais usando coordenadas generalizadas como

2011
01:21:55,800 --> 01:21:58,800
você mencionou anteriormente uh,

2012
01:21:58,800 --> 01:22:01,380
apresentando-o como um

2013
01:22:01,380 --> 01:22:04,140
modelo generativo de filtro de Kalman comum

2014
01:22:04,140 --> 01:22:08,040
e é aí que, por exemplo, a

2015
01:22:08,040 --> 01:22:09,900
direção de inferência causal pode ser muito

2016
01:22:09,900 --> 01:22:12,600
útil porque sim, esse modelo uh

2017
01:22:12,600 --> 01:22:14,400
naquele ponto talvez você possa  ser capaz de

2018
01:22:14,400 --> 01:22:17,880
modelar maior causalidade e uh e mais

2019
01:22:17,880 --> 01:22:21,780
complexa e útil uh

2020
01:22:21,780 --> 01:22:24,780
causa dinâmica de modelos basicamente

2021
01:22:24,780 --> 01:22:26,940
porque, em geral, o cálculo

2022
01:22:26,940 --> 01:22:28,560
e o ramo intervencional e

2023
01:22:28,560 --> 01:22:32,760
contrafactual da ciência são

2024
01:22:32,760 --> 01:22:36,000
desenvolvidos principalmente em modelos pequenos,

2025
01:22:36,000 --> 01:22:38,159
então é

2026
01:22:38,159 --> 01:22:40,739
como se você não  t fazer intervenções em

2027
01:22:40,739 --> 01:22:43,560
modelos gigantescos em geral, então se você

2028
01:22:43,560 --> 01:22:45,800
olhar para dados médicos, eles usam

2029
01:22:45,800 --> 01:22:50,159
redes de visão relativamente pequenas e,

2030
01:22:50,159 --> 01:22:51,179
claro, se você quiser ter um

2031
01:22:51,179 --> 01:22:54,900
modelo causal dinâmico que modela um

2032
01:22:54,900 --> 01:22:56,340
ambiente específico ou uma

2033
01:22:56,340 --> 01:22:58,620
realidade específica, você tem um  muitos neurônios dentro de

2034
01:22:58,620 --> 01:23:00,780
você tem muitas variáveis ​​latentes que

2035
01:23:00,780 --> 01:23:02,580
mudam com o tempo e uma intervenção

2036
01:23:02,580 --> 01:23:05,219
em algum momento cria um

2037
01:23:05,219 --> 01:23:07,560
efeito em uma etapa de tempo diferente, então talvez

2038
01:23:07,560 --> 01:23:09,239
na próxima etapa de tempo em 10

2039
01:23:09,239 --> 01:23:11,699
etapas de tempo diferentes depois e acho que isso

2040
01:23:11,699 --> 01:23:14,100
seria muito interessante desenvolver uma

2041
01:23:14,100 --> 01:23:16,380
forma biologicamente plausível de passar

2042
01:23:16,380 --> 01:23:17,699
informações

2043
01:23:17,699 --> 01:23:20,040
que também é capaz de modelar a

2044
01:23:20,040 --> 01:23:22,860
causalidade de grandeza basicamente

2045
01:23:22,860 --> 01:23:24,659
hmm

2046
01:23:24,659 --> 01:23:29,659
onde você vê ação nesses modelos

2047
01:23:30,840 --> 01:23:33,840
onde eu vejo ação

2048
01:23:33,840 --> 01:23:36,480
eu não pensei nisso

2049
01:23:36,480 --> 01:23:38,760
eu penso como as ações nesses modelos  modelos

2050
01:23:38,760 --> 01:23:41,460
talvez da mesma forma que eu, como você vê em

2051
01:23:41,460 --> 01:23:43,080
outros modelos, porque a

2052
01:23:43,080 --> 01:23:44,940
codificação criativa é basicamente um modelo de

2053
01:23:44,940 --> 01:23:46,260
percepção,

2054
01:23:46,260 --> 01:23:49,260
então uma ação é que você pode ver que há uma

2055
01:23:49,260 --> 01:23:52,739
consequência do que você está experimentando,

2056
01:23:52,739 --> 01:23:55,159
mudando a maneira como você está

2057
01:23:55,159 --> 01:23:57,840
experimentando algo, então você  pode

2058
01:23:57,840 --> 01:24:00,060
calcular talvez você possa simplesmente executar uma

2059
01:24:00,060 --> 01:24:01,800
ação mais inteligente agora que você tem mais

2060
01:24:01,800 --> 01:24:03,000
informações,

2061
01:24:03,000 --> 01:24:04,560
mas

2062
01:24:04,560 --> 01:24:06,960
sim, eu não acho que a ação seja muito

2063
01:24:06,960 --> 01:24:10,199
fácil, sim, eu não vejo nenhuma

2064
01:24:10,199 --> 01:24:12,540
consequência explícita das ações além do fato de

2065
01:24:12,540 --> 01:24:14,040
que isso pode permitir que você basicamente

2066
01:24:14,040 --> 01:24:15,960
talvez você

2067
01:24:15,960 --> 01:24:18,780
simplesmente tire conclusões melhores para eles

2068
01:24:18,780 --> 01:24:21,719
realizar ações no futuro

2069
01:24:21,719 --> 01:24:23,940
Vou adicionar algumas maneiras pelas quais as

2070
01:24:23,940 --> 01:24:25,920
pessoas falaram sobre

2071
01:24:25,920 --> 01:24:29,340
codificação preditiva e ação uh primeiro

2072
01:24:29,340 --> 01:24:33,960
ação interna ou ação secreta é atenção para que

2073
01:24:33,960 --> 01:24:36,120
possamos pensar sobre a percepção  como uma

2074
01:24:36,120 --> 01:24:37,980
ação interna que é uma abordagem

2075
01:24:37,980 --> 01:24:40,560
outra abordagem bastante micro são as

2076
01:24:40,560 --> 01:24:42,840
saídas de um determinado nó, podemos

2077
01:24:42,840 --> 01:24:45,780
entender esse nó como uma

2078
01:24:45,780 --> 01:24:48,780
coisa particular com seus próprios estados sensoriais cognitivos e de

2079
01:24:48,780 --> 01:24:52,080
ação e, nesse sentido,

2080
01:24:52,080 --> 01:24:54,960
a saída de um nó e, finalmente,

2081
01:24:54,960 --> 01:24:57,179
qual  nós exploramos um pouco na

2082
01:24:57,179 --> 01:24:59,940
transmissão ao vivo 43 sobre a revisão teórica sobre

2083
01:24:59,940 --> 01:25:02,100
codificação preditiva que estamos lendo até o

2084
01:25:02,100 --> 01:25:03,840
fim e era tudo sobre

2085
01:25:03,840 --> 01:25:05,460
percepção tudo sobre percepção e então

2086
01:25:05,460 --> 01:25:08,040
era como a seção 5.3

2087
01:25:08,040 --> 01:25:11,719
se você tem expectativas sobre ação

2088
01:25:11,719 --> 01:25:15,900
então ação é apenas  outra variável

2089
01:25:15,900 --> 01:25:18,120
nesta arquitetura e que está realmente

2090
01:25:18,120 --> 01:25:20,040
alinhada com a inferência inativa onde,

2091
01:25:20,040 --> 01:25:21,659
em vez de ter uma recompensa ou

2092
01:25:21,659 --> 01:25:24,000
função de utilidade que maximizamos,

2093
01:25:24,000 --> 01:25:26,699
selecionamos a ação com base em ser o

2094
01:25:26,699 --> 01:25:28,800
curso de ação mais provável, o caminho de

2095
01:25:28,800 --> 01:25:30,900
menor ação que é a mecânica bayesiana

2096
01:25:30,900 --> 01:25:33,300
e, na verdade, é muito  natural

2097
01:25:33,300 --> 01:25:36,420
trazer uma variável de ação e utilizá-

2098
01:25:36,420 --> 01:25:40,800
la essencialmente como se fosse uma

2099
01:25:40,800 --> 01:25:43,260
previsão sobre algo

2100
01:25:43,260 --> 01:25:45,540
mais receptivamente no mundo porque

2101
01:25:45,540 --> 01:25:48,480
também estamos esperando ação

2102
01:25:48,480 --> 01:25:50,820
não sim sim exatamente

2103
01:25:50,820 --> 01:25:52,860
não gosto muito da maneira de definir ações na

2104
01:25:52,860 --> 01:25:55,260
verdade e  uh e eu ainda acho

2105
01:25:55,260 --> 01:25:57,239
que, por exemplo, não há

2106
01:25:57,239 --> 01:26:01,139
tantos artigos que aplicam esse método,

2107
01:26:01,139 --> 01:26:03,239
acho que há alguns de uh de

2108
01:26:03,239 --> 01:26:05,100
Alexander ou robria faz algo

2109
01:26:05,100 --> 01:26:08,580
semelhante, mas na prática, como fora da

2110
01:26:08,580 --> 01:26:10,920
inferência ativa pura, como a aplicação de

2111
01:26:10,920 --> 01:26:13,260
codificação preditiva  e ações para

2112
01:26:13,260 --> 01:26:15,980
resolver problemas práticos não foram

2113
01:26:15,980 --> 01:26:19,280
muito explorados,

2114
01:26:19,679 --> 01:26:23,400
bem, obrigado por esta excelente

2115
01:26:23,400 --> 01:26:25,199
apresentação e discussão, há

2116
01:26:25,199 --> 01:26:27,659
mais alguma coisa que você queira dizer

2117
01:26:27,659 --> 01:26:30,300
ou apontar para as pessoas,

2118
01:26:30,300 --> 01:26:33,360
não, apenas um grande obrigado por

2119
01:26:33,360 --> 01:26:34,620
me convidar  e uh

2120
01:26:34,620 --> 01:26:36,120
foi muito divertido e espero

2121
01:26:36,120 --> 01:26:38,460
voltar em algum momento para alguns Future

2122
01:26:38,460 --> 01:26:40,199
Works

2123
01:26:40,199 --> 01:26:41,580
legais a

2124
01:26:41,580 --> 01:26:45,000
qualquer hora a qualquer hora obrigado Thomas então

2125
01:26:45,000 --> 01:26:49,820
obrigado Daniel até logo tchau tchau

