SPEAKER_00:
All right, hello and welcome everyone.

It is July 8th, 2024, and we're in Active Inference Art Stream number 2.1, a computational model of aesthetic value with Anne E. Brielman, and we'll have a presentation followed by a discussion.

So thank you very much for joining, to you for the presentation and looking forward to it.


SPEAKER_01:
Thanks so much for having me, Daniel.

I'm really, really thrilled to talk about a computational model of something that a lot of people still doubt that machine models can ever attempt to model, namely aesthetic value.

And that's been the work I've been doing for a couple of years.

And today, I don't necessarily want to talk so much about the concrete contents of this model, which I do a lot with my papers, and it's just as important.

I think what's also important and often gets left out of it from the conversation is the question of why we should even bother developing and applying a computational model to something so complex as aesthetic valuation.

So this is going to be a really high-level overview, and I'd be really stoked if we could have a discussion about this, because that's really what I'm trying to instigate here.

So stuff that I want to talk about, aesthetic value,

grandiose words with a rather intuitive, but also quite fuzzy meaning.

What I'm talking about personally, when I talk about aesthetic value or something actually quite mundane, it's the pleasure that we derive from any sort of sensory experiences.

And you all have felt that value and acted according to it.

When you decided to go to a concert or listen to a song,

when you went out into the mountains or any sort of landscape and just gazed at it, when you went out to a restaurant and decided what you want to eat and savored that taste, or even when you touched something or someone and it just felt so good, you wanted that touch to linger.

All these experiences of pleasure that are based on the sensory properties of the objects we interact with, I personally call aesthetic value.

And my mission for a couple of years has now been to find a computational model that can tell us something about how these values emerge and what they do to our behavior.

To answer that question, the most important foundation to me personally is to ask the inherently computational question, if we take it

to the original meaning of the word computational, of what this so-called aesthetic value is there for.

What does it do?

Why do we have an emotional affective reaction towards sensory properties?

And in the past, people have come up with two very different families of theories to explain these origins.

one of them i will in short dub fluency theories are very much about what i would call lazy brain saying that aesthetic value actually indicates to us that we are easily able to process the sensory stimuli and our brain likes that because it needs to do less work in a sense to simplify horribly and examples where that has shown up in the data is when we look at

symmetric stimuli so only one half has to be processed or when we look at the effects that we get from familiarity or exposure so the more often we see something the more we tend to like it and that might according to fluency be because we get to be able to process it more easily becoming more familiar with it and this is very much a evaluation of the

present moment, how good am I right now in dealing with my sensory environment?

This theory has very often been criticized for being overly simplistic and not very much looking into the future because it's so grounded in the present moment.

And so in came a different family of theories that I will summarize under an umbrella term of learning theories.

that very much rests on the assumption that aesthetic value is actually a signal for learning.

So not so much present moment adaptation, but rather a look into the future, gauging how well the current sensory environment can serve me in learning about the future sensory environment as well.

This is all about making inferences.

by recognizing errors in our perceptions and then reducing them.

So the value here comes from a reduction of processing errors of errors in making predictions about sensory environments.

And in that sense, we're here striving to adapt for better adaptation into the future.

So both theories have one big thing in common, and that is the underlying goal here is to make sensory

perception and processing good with different emphasis on the present moment in terms of fluency and the long-term future when it comes to learning.

When I discussed these theories with my then supervisor, Peter de Jaan, we were both kind of struck by a rather simple question about these theories.

Would we not want to have both?

Would we not want to simultaneously be good at processing the world as it currently is?

as well as learn about potential future.

So the model that we came up with wants to achieve both goals concurrently and has to weigh up between the two.

So the sensory system striving to both recognize what is in front of it right now, but also wanting to predict as best as possible what it is going to encounter in the future.

And you see that in everyday life too, right?

So if you want to work with your sensory system, just crossing the street, you want to both now be able to recognize what is in front of you.

Do I know this person?

Should I greet them?

But you also want to be able to make accurate predictions about whether or not that car is going to hit you the next second if you do proceed to cross the street.

This is a very, very prominent theme throughout most models of machine learning that are based on theories of reward learning.

There is an agent that right now decides its next action based on what is rewarding in this very moment, whilst taking into consideration whether its predictions and the action that resulted from that led to better or worse outcomes than expected,

So predicting the future, evaluating it right now, and then adjusting the behavior accordingly.

And what we now believe is, why should the sensory system and the value that comes from that, this aesthetic value, be any different from those?

With that thought in mind, we proceeded on building that.

But what does that look like?

So just taking one step back for those people here who

have not kind of sat in front of their computers and actually done something with these things, this is what a computational model looks like.

It is just a bunch of code, it's a bunch of mathematical formulas realized in reprogramming language you like.

And you can run it on simplified computer representations, numbers of the things you want to simulate and derive predictions from it.

And this particular one for aesthetic value

is implemented and you can download it from GitHub.

And I very much strive to keep that updated.

What is key for its usefulness for people like me, and I'm a psychologist by training, is that these expressions, the definitions, and the terms used in them are interpretable.

So every function here serves as a proposed mechanism.

This can be very high level, but it can in other cases go down to the functions of individual neurons that are being modeled here.

Most often, though, we see this interpretability in the parameters that are passed onto these functions.

So what are the settings under which these mechanisms operate?

And that is true in this particular model as well.

What our model does to gain this interpretability is that it has two sets of functions that interact with each other.

two parts of the model that do roughly represent this one family of theories of processing fluency.

And it also has one that represents the mechanism that represents learning from prediction errors, gives reward for prediction error reduction.

This looks like in a

Sorry, one second.

There was my speakers going up, my headphones going out.

And we can represent this in a comic-like way, where we can actually, at least in a simplified one-dimensional structure, represent what the model looks like.

So it is nothing more or less than the representation of the expectations of the inner system, so a probability distribution of what the system

expects to see right here, right now.

And it takes a readout of that probability.

So what are my predictions in terms of what we see here is we look at a dog.

One relevant feature of the dog is how long is its fur.

We have an expectation of how long it is.

We read out how well the current environment meets our expectations.

And that readout is one component.

So this is one of the functions that lets us know

the reward that we get out of here, the value from immediate processing fluency right now.

And we can do a similar thing illustrating how learning works in this model, how we actually bring in the first component of learning by shifting our expectations, as you see here, by shift in the distribution according to what's present right now.

So I see a dog with long fur, hence I expect dogs to have longer fur.

also expressed as a function.

And we can go on and then say, okay, how do I represent errors?

How can my current state of beliefs be in contradiction to an expected future?

And so we can simulate that by saying we have a mechanism that evaluates how different is my current expectation to my expectations of the future.

And we can then over time evaluate how these long-term expectations match up to the current learning process and whether the learning in and by itself gets us closer to long-term expectations or removes us further from them.

And that term then gives us what we call a reward of learning.

It's the development of the prediction error over time.

And that

I horribly glossed over, and I'm super happy to give you more details, but I really wanted to get to this one very important point, like telling you, okay, computational model is nothing fancy.

What is important is the idea that stands behind it and how we realize it.

But just as important to me as a researcher who very much does empirical work is ideas are good and well, but does it do anything?

And that's what I was very happy to work on with my master's students, where we took the model implemented in computer code and said, can it actually produce something, produce predictions that are anything like the behavior we see for people?

And here we looked at one particular finding first with simulations that we know very well.

Very many studies have looked at it.

It's called a mirror exposure effect.

And it's depicted here on the left-hand side.

And it basically looks at how much people like or enjoy something on the Y-axis as a function of how often they've experienced it.

And what we usually see is an inverted U-shaped curve where up to a certain point, more exposure, more familiarity leads to more liking, but eventually this trend is going to turn on itself and we get bored.

And our model

as you can see from the overlapping lines comparing the data to the model's prediction, is indeed able to replicate these findings.

And its settings, so its parameters and how they're expressed, can tell us something about how this effect came about.

And again, glossing over the details here, very happy to talk about it later, but it basically gives us a constellation

a geometry of settings that allow for this effect to occur, and very importantly, discards all other options.

And most surprisingly to me, what the model could do very well is, in a completely separate experiment with our own data, it was able to predict individual people's judgment on how much they liked images,

very well on an individual trial by trial level.

So we could say for individual trials that the model never saw in the sequence,

what a participant would rate them solely based on their other responses.

So the model was indeed able to mimic something that was able to produce the same responses as humans would do.

And again, our hope here is not to say, oh, great, now we can build the best recommendation algorithm for any internet platform you could imagine based on such a model.

um what we are excited about is that the parameter settings behind us tell us something about where these judgments actually came from um i'm just model performs better than

other more naive models.

So what you see here is a comparison on the y-axis of the error that our model makes versus on the x-axis, something that is very often still used in psychology, namely the assumption that everybody responds like everybody else on average.

And that always makes way greater errors in predicting people's responses than when we take a more complex but individualized approach to things.

And that's very reassuring for us.

Yes, so it does do more than these more naive methods in the sense that the difference in the parameters suggest reasons for differences.

So what is so very often said about how we do our evaluations of aesthetic experiences that they're in the eye of the beholder, there's now something to A, back up that these are not coincidental and B, something that suggests where they might be coming from.

And I think there's even more we can do with this kind of approach to even a subject as fuzzy and sometimes hard to study as aesthetic valuation, right?

So we can test different variations of this model against each other.

We can lesion the model, right?

So we're not hurting anyone here.

We're just removing parts of the code and see which elements of the model are

indeed essential to its functioning.

And again, find out more about the possible mechanisms that are indeed involved and crucial to this process.

We can, and this is to me exciting as somebody who does not come from the computer science world or the machine learning world, now compare this model to what I mentioned in the very beginning, the same architectures, but employed for decades to teach

machines how to learn and to understand why rats exhibit certain behaviors, right?

It's a theme architecture.

What does that imply about aesthetic valuation as a reward learning model?

And because it is so similar to the reward learning models that underlie machine vision and a lot of the deep convolutional neural nets we're using to process sensory stimuli, most often visual,

to translate them into machine language, we have a rationale to use these highly potent image processing architectures and use them to quantify what is in those images also in our research.

And it offers the possibility to simulate, right?

So we can now

make predictions before we even start an experiment about what people should do if our models were correct, if we have one like this.

And I will end this here for this particular presentation.

And I'd be super stoked to start a conversation with you.


SPEAKER_00:
All right.

Awesome.

Cool.

Okay, lots of ways to go.

I'm looking forward to discussing it.

And if anyone watching has a question, then they can type it and I'll ask it.

Let's just start with how did you come to be studying this intersection of questions and methods and theoretical perspectives?


SPEAKER_01:
Give you one second to put up my alarm that has started ringing in the background.

It's an amazing question.

So as I think for many people, my journey started a little bit coincidental.

So I was initially very interested going to art school, but that's very much disillusioned.

So I've always been very interested by aesthetics in the broadest term.

I play instruments, I paint, I draw.

And had a supervisor who very randomly asked me whether I would want to study that, but as a psychology PhD.

And that supervisor already was

in a place both in terms of colleagues as well as his own personal history that bound him very closely to computational methods.

So I studied at NYU with Dennis Paley, who is a mathematician by training.

And the psychology department there is very fond of very quantitative methods and building their own models to explain how the world works.

And that's how my journey started.

This perspective has never been forced on me, but it's the one that I was brought up with.

And I always found it very, very useful for the reasons that I just said, in terms of being able to integrate a field that is often a bit separated, right?

There's a lot of people by now doing research on aesthetic experiences, but often very removed from the rest of the world.

And I always thought, well, why not talk to the people?

We are talking about visually appreciating things.

So it's got to do something with how the entire visual apparatus works, right?

So why not use the methods of those people who do the more cognitive or quote unquote basic side of things and apply them to this more effective evaluative side of things?

And then, and via that, I became really interested in computational modeling because I started realizing that experiencing beauty or pleasure from something is not just something that is a nice, you know, it's not icing on the cake of life.

It's very ingrained in everything we do really, especially in the industrialized Western world.

I became very interested in this question.

How does this influence our decision-making?

Why do we spend a couple of hundred dollars and a lot of time and effort to travel somewhere to watch somebody play music for two hours?

It doesn't make any sense.

And then I went to tubing, worked with Peter Leon, who is somebody who's worked on reward learning models, very deeply computational models for a very, very long time.

And I came to him and said,

I have a hunch that these models apply to what I've been doing for five years, too.

Are you willing to work with me on that?

And luckily, he said yes.


SPEAKER_00:
Cool.

Thank you.

Yeah, it's interesting that aesthetics seems to sit in a way between perception and behavior and also philosophy in that it's often seen as a philosophical area, however, one that deals

quite explicitly with the perceptual system that might be addressed by psychology otherwise um okay you mentioned interpretability so that was in the context of the computational modeling

How do you think about interpretability of aesthetic models when we have this kind of dual interpretability from the inside, like our own interpretability of the underlying phenomena, and then we have this kind of external interpretability, whether that's observing somebody having aesthetic experience or doing modeling, like, how far can we get with interpretability?

And what does that look like here?


SPEAKER_01:
yeah that's a really good question so i think probably the furthest we can go and in aesthetics that might be a long way off is you know linking model components to physiological biological reality and being concretely able to say this function represents one neuron this

function represents how signals are transmitted along the axon and so on and so forth.

They really pinpoint every bit of the model to something that is both functionally important and physically observable.

But to me, interpretability in the stage where aesthetics at is the best when each

parameter in the model relates to something that is part of the theory that underlies it.

So that when the parameter changes or becomes irrelevant, that is probably the most crucial one, we have justifiable reasons to change our theory or adjust it.

So what in our model, for instance, we have

two parameters that weigh the two components against each other.

So one parameter scales how important the value is that is derived from this immediate fluency signal, and the other one scales how much value we derive from the prediction error reduction, from the reward of learning.

So if we see consistently over time that we can set one or

one or the other to zero and nothing much happens, that very clearly indicates that one component of the models is frankly obsolete and doesn't play a huge role.

And that to me is very valuable interpretability in that sense.


SPEAKER_00:
Interesting.

So we saw the inverted U exposure curve.

Are there phenomena that kind of buck that trend or are there maybe pieces or genres where we have like a step, like we enter into it and then we can see more or different?

Like how do we account for not just re-listening 25 times to the song, but you know, 2,500 times to the song?


SPEAKER_01:
Yeah, it's one of my favorite things to ponder about as well.

There are different ways that I've discussed it with different colleagues, and I believe that we someday might break it down to our internal models, just having slightly different settings.

But perhaps the easiest explanation for it is that there are some stimuli that just sit so very firmly

at the center of our expected future beliefs, right?

So that there is basically never a negative learning experience from them.

They are the prototype of what, for this type of stimuli at least, we expect the world to be and remain forevermore.

And so that then leads the model to predict not an inverted U shape, but an asymptote.

So you basically stick around with very high platters throughout, and it never goes down.

That's the easiest way of explaining it.

The more everyday explanation, if you will, one that we cannot test as easily in a lab setting, is that we never listen to the same song 25,000 times in a row without anything else getting in the way.

And if that is the case, you know, we can always kind of swing back with our expectations and then come back to it kind of with a reset.

So it's not that it's continuous exposure to the same thing all over again, but each time you come back to that song, you've changed a little bit, your expectations have changed a little bit.

And so you're learning anew.

And if it sits at the right place of your expectations about

world you're always learning something good and so you continue this infinite loop via short intermissions of being exposed to things that are you know less enjoyable or make you unlearn something that was actually beneficial that's very interesting it's like a smelling coffee cleansing the palette and then re-learning oh i like that food but also i'm kind of relearning it


SPEAKER_00:
um i i was also especially when when you connect the fluency theory of aesthetics to the expectations i was struck that there's the expected free energy construct for decision making and it has this pragmatic value element of preferences expectations and then the epistemic value with the learning

And so initially I was wondering, well, aesthetic value, which is what motivated the talk, would aesthetics be a third element in the consideration of

or it's it's almost more interesting that it exists across these two areas of expectations and that has more of an archetype of being like well it's this time so we hear this song

So that's the kind of like pragmatic side of aesthetics with a cultural scaffolding of expectations.

And then there's also this learning intrinsic novelty element.

So it kind of comes down just like action selection in the general case, it comes down to these kind of two complimentary, but non-convertible elements.

types of impact that the stimuli can have.


SPEAKER_01:
Yeah, I think you exactly captured the intuition of that.

It is debatable whether that is all that there is to it, and I personally do not think so.

I think this model does a very good job at capturing these two aspects.

But, you know, the more I think about it, of course, the more incomplete the model becomes.

So, yes, I think

there are these two archetypes of also aesthetic enjoyment.

I've also seen that across other completely other theories, like not psychological theories of aesthetics, but there's this kind of cinema, pop culture, entertainment aspect of, oh, this is easy and comfortable.

And then the more challenging, you know, fine arts aspect of aesthetics.

And I do see both of these discussed both jointly and independently.

What I think,

in terms of self-criticism, although the model is still lacking is, maybe that's what you meant with aesthetic, is a contextualization in terms of the sensory system does not exist in isolation in our brains.

It's also coupled with everything else.

So elements of nostalgia, of association of memories, that is something the model completely disregards.

It just doesn't have it baked into it.

And so it's completely and entirely possible we're missing an important ingredient still.

But again, you know, you cannot only lead in a model.

You can also amend it.

You can add another component to it.

So if anybody's up to it, could be very thrilled.


SPEAKER_00:
Looking for those residuals or looking at what factors matter where the model doesn't predict well, I was definitely thinking about, in light of that sort of pop art and decoration on through more epistemically challenging art,

Sometimes what changes isn't necessarily the medium, but often is sort of like the contextualization, like the museum setting.

You're about to be walking into this room where this is going to be there.

And then the object, as the sort of recent decades of art have shown, like that object can be anything and nothing.

And so then that is like, wasn't this about perception?

But then what is there to perceive in this blank wall?

Yet also that becomes kind of like the exception that proves the rule because it starts to tap into the more contextual elements and possibly reveal greater differences amongst people rather than something that like...


SPEAKER_01:
a ratio that strikes many as pleasant due to deeper priors about shape yeah yeah no definitely and you know you you can try and fit that into the model too you know you can go ahead and that's what we maintain where it might continue to be useful is that um context might bring about a drastic shift in parameter settings right so as soon as i go into the museum i'm no longer looking for something that is

immediately easy to process right now.

I'm voluntarily getting myself into a context where I know that there's more value to be found in learning and challenging myself.

And so that might be one way of saying, okay, that's how we can think of the model and not only modeling differences between individuals, because that's how it does that too, for instance, but also between contexts.

That being said,

There's also completely different shifts that might be more difficult to explain with that.

My most recent example is, it's reading me as a bit of a nerd, but the author of the Dragon Ball series recently died.

And I think along with a lot of other people, I revisited something from my childhood just without that lens added to it, wasn't very good.

hard to begin with, but got a different kind of appreciation for it with like a whole back layer of appreciation and historical importance.

And whether that is just parameter thefts that happen kind of snap in an instant, I don't know.

So maybe we're still missing something.


SPEAKER_00:
Yes, nostalgia and memory and a given stimuli having like a pragmatic value simply because it was learnt to be expected and so then it all things being equal is more likely to be part of the expectations going forward, just part of the historical learning.

Okay, so you mentioned probably an illusion that must be included in every such talk about beauty in the eye of the beholder.

And yet, what is in the eye of the beholder is in the mind of the beholder with their generative model.

how would you say like predictive processing predictive coding active inference how are these cognitive theories stepping into aesthetics in the modern era and like helping reform or or reinforce some of these more ancient sentiments on perception


SPEAKER_01:
I think in recent times, predictive coding has very much reinforced the notion of beauty in the eye of the beholder because it, in a sense, offers a very easy explanation as to why there is so much subjective variability with the notion that, you know, objectively what the world gives to us in terms of

physical stimulation is not what everybody experiences, right?

It's an active, constructive process.

Perception is not something passive that just happens.

And so for everybody, it creates something different.

So it should be logical then that we also appreciate things differently.

However, I think it's very healthy development in that with predictive coding, much as with other models, including all the computational models,

It's not this story of a hopeless, oh, well, everybody's different, so what are we going to do about it now?

We can't explain it, possibly.

It offers very good theoretical foundation for understanding differences, not as a nuisance or a measurement error, but as something that's actually at the heart of the process itself.

I think that's quite promising, and I think also

In that sense, that kind of scientific approach to aesthetics receives much more positive feedback and welcoming from the more artistic community because it does not want to take away from differences, does not want to explain them away as nuisance, but very much takes them seriously as something that is a justified result


SPEAKER_00:
of the underlying processes thank you yeah that's very interesting like the account of the painting is not seeking to explain away the differences in shading or color

the account of different people looking at the painting also would not want to explain those away, but rather like account for the distributions as they are and continue the investigation.

So you mentioned algorithms.

How would you say your work interfaces with algorithms and recommendations, especially in an era not just of recommendation of extant content, but generative and synthetic methods?


SPEAKER_01:
I mean, per se, this model represents pretty much everything that these

algorithms want to do.

It does not have a generative part yet, but its architecture makes it blatantly obvious how the generative part should be constructed.

You can construct a general adversarial network out of this, no problem.

You could train it in a tandem model with what we have right now.

And if you have enough data, sure, you could

do it the only thing that's not feasible about it is you would have to have complete surveillance over people and a good way of getting continuous output about their reactions and then you could have every platform stream yeah kind of continuously predicting what's that person gonna like best next and that's kind of scary in in that sense right but I also think it's helpful

In the sense that what current algorithms are doing is really not taking this into any consideration at all.

So at the heart of the model as we have it lies learning and lies the fact that we do not want to be stagnant.

We do not want the same experiences over and over and over again.

We do get bored.

The exposure effect does eventually turn negative.

And in that sense offers also always due to it not being this 1D comic I showed, but multidimensional, always many options of what, you know, would as next experience be rewarding and be valuable to you.

And in that sense, I always want to kind of build the model out in that way, because it would get away from the current state of the art, which is

very much cluster driven, putting people into, okay, you're this part of the cluster, you know?

Okay.

So you like rock, so you probably like hard rock and maybe country rock.

Let's try that.

Okay.

You didn't like that.

Maybe you're more of a hard rock person and then we keep you firmly and only recommend you artists in that corner instead of making a jump.

So yeah,

I think everybody who works with artificial intelligence in whichever capacity these days kind of has to ask this question, right?

What is the benefit?

What's the worst case scenario?

And in what way could it be helpful?

And that's the best I could come up with so far.


SPEAKER_00:
It is a dark but fascinating

like aesthetic panopticon with the biomarkers and the processing happening faster than the time scales of our own aesthetic judgments and then like updating with recommendations or with tweaking and modifying in in ways that that we don't necessarily even see but then it's like but what if that journey is taking us on these epistemic flights

And what if the learning rate is being calibrated to a kind of sensation that couldn't be provided by people making arts for each other?

And I wonder if that will be one of the technologies or kind of manifestations that will really clearly highlight that contextual elements because very salient stimuli will be arising from that kind of a process.

And then also there's going to be like the drawing that my friend made for me on the refrigerator, which is like static, but then it's going to have this


SPEAKER_01:
embeddedness and the connection and and then maybe that's gonna still be a thing to look at yeah absolutely i think this is also i i'm not a doomsday sale when it comes to um this ties into creativity a lot in my opinion right so what can we gain from generative art in any way sense and i not want to say it's all doom and gloom and it's all bad

But what you just mentioned, this kind of embedding of a work into a personal history, be it with the viewer or with the artist that we as viewers can then learn about, is something that kind of goes beyond the scope of what we're doing these days, where our modeling is very much reliant on

quantifying the objects and then trying to infer what is going on inside the viewer.

We're not quite there yet where, you know, we also kind of infer the underlying non-physical properties of the stimulus itself beyond what is provided by the viewer as well.

But maybe one day in the future, you know, we're going to have it solved and aesthetics is going to be trivially solved by science.


SPEAKER_00:
How would you represent the philosophical or psychological or computational developments on art recognition models in contrast with models of creating art or different medias and different ways of more actively constructing art?


SPEAKER_01:
It's a really good question.

I think

their approach right now from two very different groups of people.

So everything I think that we see these days in terms of generative approaches comes from, and I say that as a daughter of an engineer, comes from engineers and people who are very product focused, right?

Who want to give

have an output that can be practically used for something.

And as such, a lot of, by now very impressive black box models have emerged that can produce things that are very impressive.

Like 20 years ago, nobody would have guessed that we would be able to do this, but without any real understanding of how that emerged from, you know, tens of thousands of

example images that it was trained on.

On the other hand, these people have become less interested in something that is also still being done, and that is modeling people's responses.

So these algorithms are mostly really not good because they don't have enough data and not good, not high enough quality data.

best data sets you can get for training a model to, um, on a large machine scale model is from like an old page from a photo contest, um, for like five or so votes per image, which for psychologists, psychologists sounds like horrible, horrible, horrible sample size, the horribly biased sample.

Um, and so these efforts, I think by now have to stand back to

What is now more coming from the cognitive sciences, from psychology and neuroscience.

And those models are very different because their predictive quality is often not quite as good.

Like they're not as correct as models would, you know, 10,000 times the parameters, but they're very interpretable.

So I think there's two very different roles that also want to do very different things.

One wants to deliver a product.

and the other one wants to deliver more of an explanation.

The sad thing is I would very much love to see them come together, but I don't see that quite happening yet.


SPEAKER_00:
That's making me think about, again, with interpretability and our own observation of observing art.

or creating art and what factors we feel are associated with our own perceptual experiences and our own generative experiences.

Like a funny quotation from William Blake, he said, the difference between a bad artist and a good one is the bad artist seems to copy a great deal.

The good one really does copy a great deal.

and yet then I hear that the kind of synthetic methods that we have today are like glorified autocomplete or copying which kind of even scales back the conversation to like but then would that still be art and potentially even more art-like or would that somehow make it less art-like

And that conversation about what makes something aesthetic, what makes something decorative versus high art, how are these longer term trends in what is perceived or discussed as art, that is just like instantly we're just like back in the whole fabric of society and the complexity and the challenge of coming up with a neat account of like any phenomena.


SPEAKER_01:
Yeah, absolutely.

And it feels like we're back in the 18th, 19th century with that.

It really reminds me of this entire debate that we're having right now.

Is this art?

Oh my God, what is happening to art and artists at all?

It reminds me very much of the time when photography was invented in a way.

It feels like that is...

repeating itself in variations, which also art loves to do, right?

Repetition and variation.

I guess I took the easy way out with that in my approach.

I was really saying, I'm not even interested if you call it art.

I'm also not very interested if you call it aesthetic.

I'm very much interested in what you feel when you experience that and what that feeling makes you do.

And then

I love my philosophy colleagues.

I really do.

I love working with them, but I leave it absolutely up to them to discuss the fine semantics and terminology of when exactly that crosses the border from pretty to beautiful, to aesthetic, to transformative.

I'm perfectly fine sitting here saying I can at least predict that they're going to say they like it.


SPEAKER_00:
Hmm.

How do you think about that reported, unreported, revealed question?

Is there another kind of information or way that you look at what people say in light of other data?


SPEAKER_01:
Yeah, I mean, the way that I interpret your question is, you know, what

do we do with this plague of psychology when it comes to these very subjective experiences of, you know, how do we interpret what we're getting in terms of data, right?

That we're really getting at?

So my ideal that I strive towards, and I do have data that is just not good enough yet, right?

Didn't think it through a thousand percent, is looking at people's behavior and make inferences from these behaviors, because

If we only observe, for instance, the setup was like this, how long people will look at a given image before they decide that they want to go on to the next one, they do not really need to think about what we want them to say, and they don't really need to think about, oh, what's going to tell you about me that I say I like this image very much or not.

Because there's concrete behavioral consequences for them in the right here and right now, if they display a certain action.

So, you know, I can give them a fine art piece, and if I ask them to rate this and they recognize it and they're like, oh yeah, okay, this is a museum, I should probably like this, otherwise I'm horribly uncultured.

It's very easy to do that, right?

There's no negative consequences for them to experience, whether they mark a 1 or a 9 on a 1 to 10 scale, who cares?

But if I say, listen, I'm going to leave you here for 10 minutes, and the only thing you're allowed to do is look through these images, then there's the real consequence of looking at this fine art piece and deciding, oh, maybe should I really look?

I really, really don't like looking at this, but I should like it, right?

That's probably a better method, but it's also harder to pull off right.

So I do think behavior is harder to set up, but if set up right, the better, more direct measure of what's actually going on.

But for all intents and purposes, self-report, as long as you do not give people a reason to want to distort their reports,

is probably the most direct and easiest to do um and we're really lucky in aesthetics right like we do these kinds of experiments mostly with stuff that people are very happy to do right we all love to talk about our favorite music and our favorite movies and we like to give our opinions about these things they're important to us so we can do self-report easily

It's just not perfect.

Never going to be.


SPEAKER_00:
Interesting.

Also that that like in a way recapitulates the kind of epistemic foraging or optimal foraging type experiments.

Like there's a hundred trees, they have different quality.

And then you could just from the movement patterns, eventually parameterize a model like,

to what extent was the switching behavior driven by saturation of learning versus saturation of the preferences and then here it's again that aesthetic value has elements and then your model is like like a cornerstone for adding in some other considerations but at minimum it

fuses those two threads of theory and gives the kind of minimal playground to to start to explore like how those work and and also how those might work in minds very different than humans like looking at the response curves for training neural networks absolutely and oil boy have i been


SPEAKER_01:
sitting through, like, I can't tell you how many workshops and stuff I've been going on foraging behavior and trying to do that.

And then I got hung up on boredom.

That's how it sometimes goes, right?

And then we discovered this thing about getting bored about things.

And interestingly, boredom wasn't boring at all to think about.

And so I got sidetracked.

But I think what you said right about now is also so

cool to start thinking about.

And again, just making these connections with foraging behavior, because honestly, when I pick up my phone and decide what music I want to listen to for my bus ride to the office, that's kind of exactly what's going on.

I have this limited time window to get hopefully maximum enjoyment out of.

And it's exactly like, do I keep digging


SPEAKER_00:
in this corner of songs or like is it more rewarding now to kind of start something new and it's exactly that that problem so yeah that's yeah yeah it could be people in the museum like the physical location the diffusion and then there could be like um different i mean it's it's like a resource location and um

but it's very complex there's there might be like a more visible so that's where like that sort of like social thumb on the scale of aesthetics but then maybe somebody's aesthetics concept includes like performativity

At which point then it's not an illicit admixture to have the social value like stand-up comedy or some other kind of performativity where having other people's gaze is part of what is being constructed.

Whereas in other kinds of art, there's like, I mean, even evidenced by earlier in our discussion, like there's a feeling like we could isolate it to the viewer or to the experiencer, but then that is almost shown to be kind of like a contrived case, not the natural history of how the art is made and used.


SPEAKER_01:
Yeah, absolutely.

And that kind of,

I think it's also a goal that other people are working towards right now, which you mentioned is that these single agent models that we all very much rely on these days is also not telling the entire truth of the experience, right?

It's not just my entire social component as well.

If we're talking about these kinds of real life settings and experiences that also bring in

their part to the completed picture.


SPEAKER_00:
Okay, in the last little bit, if anyone wants to write a question, they can.

Otherwise, how do you see your work and research and everything unfolding or what ways are you excited to go?


SPEAKER_01:
My dream for all of this really is

to get a lot of people excited and trying out these kinds of models.

Of course, for me personally, most exciting thing would be people picking up what I've been doing and tweaking it and really thoroughly testing it and figuring out what is wrong with this model, because I'm sure there's something wrong.

Getting to a very solid core understanding of how it all

sort of relates.

Today I've painted very much a picture of what has basic visual but also other perception to do with the valuation of these experiences.

But that can be tied up so much further into how do these evaluations then impact our behaviours, how do these behaviours lead to changes of the experiences and really take seriously this

idea that there is no passivity in the perception of our world.

It's all a very much active process that keeps on changing.

And I think we can get a good understanding of that.

And I think we're very exciting times, especially for aesthetics to build these models in such a way, not only that they

can be useful tools, but really give us a good understanding of what aesthetic experience truly is.

So I hope to be able to continue working on that for very many years to come.


SPEAKER_00:
Awesome.

That idea of no passivity.

Kind of, period, is a big theme in Active Inference and it makes me revisit the beauty in the eye of the beholder and about the eye circading and about how with gaze tracking, the dwelling could be associated with our, like a local maxima.

looking at an interesting feature of an architecture or a specific location.

And then the Cicade Pattern, which few if any people can directly control, is driven by epistemic gain.

And that's this kind of like hierarchical locking in.

Like there's been a lot of experiments in active inference with facial

recognition and faces that are the right side up and upside down and the kind of epistemic trajectories that are taken so maybe that's one way that predictive processing also like revisits and enriches the beauty in the eye of the beholder because it brings action into that eye

instead of just to behold as a passive process, that'd be like, well, you know, the images in the lens of the photographer would be a passive stance, but then even the eye, which is kind of like a symbol or has a connotation of receptivity, but of course its action is passive.

so active and and ceaseless even on a simple scene and then maybe even um mysterious art like a solid color square that then becomes like this playground for the circadian and so that's like a kind of experience that start starts to um be revealing so that's kind of interesting


SPEAKER_01:
Yeah, it also really hones down something and really emphasized today to what you said about DIs really, you know, with their behavior actively changing what we do perceive, is that in line with learning also always comes this notion of things being dynamic and basically due to technology, technological advances finally at that stage where aesthetics can hopefully also move away from this, okay, we show you aesthetic picture and then we're taking this like,

the final say, right?

This picture, this response, and we're done with it.

But really looking at these things as dynamic processes, right?

Even looking at one singular image, this is not a one and done thing.

Your impressions change over time because your eyes move, because your understanding changes, because that understanding changes possibly where you're looking.

So it also changes what you're going to see, et cetera.

And that to me is much more interesting

exciting and interesting way of of looking at these topics right it's really just dynamic unfolding process so yeah thanks for mentioning that I think it's really important cool and also I feel like it puts action kicking off the process like I'm thinking of a food tasting like food is put into your mouth and you can report on it


SPEAKER_00:
Whereas if you have the menu, then the action kicks off something that is later the aesthetic experience.

You choose which museum to go to.

You choose where to look.

And so that kind of front loads this action element.

Whereas in the contrived setting, the action element may be controlled by the experimenter.

and the action that the person took was to sign up for a study, which is still a kind of action, but then that doesn't build the kind of arc that we actually, like you said, paid money and take time out of life to enjoy.

Cool.

Anything else you'd like to add?


SPEAKER_01:
I would like to add thank you for having me.

I said that very briefly in the beginning, but I think it's really cool to have these conversations.

I think it's also nice to have it out there in the open and I hope that I didn't use all too much jargon.

And I would also like to mention that people can very easily Google me by my name and you should be very free to get in touch with me if you're interested in any of these things.

I'm sometimes busy, but always interested in talking with people.

no matter where they're coming from.


SPEAKER_00:
Awesome.

Thank you again.

See you next time.


SPEAKER_01:
Thank you.