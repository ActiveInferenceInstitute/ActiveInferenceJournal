1
00:00:07,040 --> 00:00:10,320
Hello everybody welcome it is September

2
00:00:10,320 --> 00:00:12,080
26th

3
00:00:12,080 --> 00:00:15,120
2023 we are here kicking off a new

4
00:00:15,120 --> 00:00:17,119
stream series at the Active inference

5
00:00:17,119 --> 00:00:20,400
Institute this is the morph stream

6
00:00:20,400 --> 00:00:24,800
1.1 today we have David kapple and also

7
00:00:24,800 --> 00:00:27,960
this section and streams facilitated by

8
00:00:27,960 --> 00:00:31,320
Sarah Hamburg we're going to have a

9
00:00:31,320 --> 00:00:35,440
overview first presented by Sarah then

10
00:00:35,440 --> 00:00:38,040
David will share some work on

11
00:00:38,040 --> 00:00:40,520
neuromorphic Computing and then we'll

12
00:00:40,520 --> 00:00:42,879
have some time to discuss so thank you

13
00:00:42,879 --> 00:00:45,480
both for joining and Sarah to you for

14
00:00:45,480 --> 00:00:47,360
the first presentation and also to

15
00:00:47,360 --> 00:00:49,600
introduce yourself if you'd like yes

16
00:00:49,600 --> 00:00:51,000
that's a good idea thank you very much

17
00:00:51,000 --> 00:00:54,120
Daniel um so my name is Sarah um I'm a

18
00:00:54,120 --> 00:00:56,120
neuroscientist specializing intelligence

19
00:00:56,120 --> 00:00:57,280
currently working in the field of

20
00:00:57,280 --> 00:01:00,280
neuromorphic computing um at chef field

21
00:01:00,280 --> 00:01:02,480
Hal in the UK so I'm going to give you a

22
00:01:02,480 --> 00:01:04,400
high level overview of what neuromorphic

23
00:01:04,400 --> 00:01:06,720
Computing is and before we hear David's

24
00:01:06,720 --> 00:01:08,640
exciting talk in the first edition of

25
00:01:08,640 --> 00:01:11,320
this new series um just to let you know

26
00:01:11,320 --> 00:01:12,799
if you're watching on double time in the

27
00:01:12,799 --> 00:01:14,320
future I talk quite fast so you might

28
00:01:14,320 --> 00:01:17,080
not want to watch me on double time so

29
00:01:17,080 --> 00:01:19,400
this QR code um I put here will take you

30
00:01:19,400 --> 00:01:20,880
to a paper which I thought was a really

31
00:01:20,880 --> 00:01:23,520
nice introduction to the field um but

32
00:01:23,520 --> 00:01:25,520
neic Computing can be defined as

33
00:01:25,520 --> 00:01:27,000
Computing systems that are designed to

34
00:01:27,000 --> 00:01:28,680
mimic the structure and function of the

35
00:01:28,680 --> 00:01:30,720
nervous system so this doesn't have to

36
00:01:30,720 --> 00:01:32,680
be the human nervous system the field

37
00:01:32,680 --> 00:01:34,320
actually takes inspiration from all

38
00:01:34,320 --> 00:01:36,640
sorts of animals and insects um although

39
00:01:36,640 --> 00:01:38,159
the definitions online don't necessarily

40
00:01:38,159 --> 00:01:40,680
acknowledge that so some people are

41
00:01:40,680 --> 00:01:42,200
quite open with what constitutes

42
00:01:42,200 --> 00:01:43,920
neuromorphic while maybe others would

43
00:01:43,920 --> 00:01:46,119
prefer neuromorphic was reserved for

44
00:01:46,119 --> 00:01:48,600
Hardware instantiations of biological

45
00:01:48,600 --> 00:01:50,520
like neurons um which are sometimes

46
00:01:50,520 --> 00:01:53,280
referred to as non-run computers and I

47
00:01:53,280 --> 00:01:55,280
think that's what the paper that the QR

48
00:01:55,280 --> 00:01:58,320
code um will refers to it as in as their

49
00:01:58,320 --> 00:02:00,280
definition um so what I think is really

50
00:02:00,280 --> 00:02:01,200
interesting is a little bit of the

51
00:02:01,200 --> 00:02:02,920
context so like our current vuman

52
00:02:02,920 --> 00:02:04,479
computer architecture was also inspired

53
00:02:04,479 --> 00:02:06,439
by Neuroscience and particularly the

54
00:02:06,439 --> 00:02:08,840
Mull and pits 43 Neuron model um

55
00:02:08,840 --> 00:02:12,080
inspired Von y's first draft in 1945 so

56
00:02:12,080 --> 00:02:14,120
Neuroscience has a long history of um

57
00:02:14,120 --> 00:02:16,120
inspiring computer science and this also

58
00:02:16,120 --> 00:02:17,680
includes reinforcement learning which is

59
00:02:17,680 --> 00:02:19,440
based on theories about learning

60
00:02:19,440 --> 00:02:20,720
decision- making from behavioral

61
00:02:20,720 --> 00:02:22,480
psychology based on rewards and

62
00:02:22,480 --> 00:02:24,760
punishments and also heian learning

63
00:02:24,760 --> 00:02:26,519
principles of cells that fire together

64
00:02:26,519 --> 00:02:29,239
wire together um from 49 became

65
00:02:29,239 --> 00:02:31,680
foundational for unsupervised learning

66
00:02:31,680 --> 00:02:34,959
so first of all um hang on one

67
00:02:34,959 --> 00:02:37,640
second so um in order to understand the

68
00:02:37,640 --> 00:02:39,440
why of neuromorphic computing I really

69
00:02:39,440 --> 00:02:40,959
wanted to explain what's so great about

70
00:02:40,959 --> 00:02:44,120
the brain so uh here's some inspiration

71
00:02:44,120 --> 00:02:46,360
for light bulbs so I'm going to ask you

72
00:02:46,360 --> 00:02:47,280
a question I just want you to think

73
00:02:47,280 --> 00:02:49,159
about it for a second in terms of light

74
00:02:49,159 --> 00:02:51,239
bulbs how much energy do you think the

75
00:02:51,239 --> 00:02:53,879
brain uses do you think it's more or

76
00:02:53,879 --> 00:02:56,280
less energy than the bulbs lighting the

77
00:02:56,280 --> 00:02:58,040
room that you're in if you're in the

78
00:02:58,040 --> 00:02:59,560
future by all means PA this pause this

79
00:02:59,560 --> 00:03:01,200
if if you want to do some in-depth

80
00:03:01,200 --> 00:03:02,760
calculations but I'm going to skip to

81
00:03:02,760 --> 00:03:06,680
the answer the answer is here in the

82
00:03:06,680 --> 00:03:10,159
pink circle so it's 20 watts so that's

83
00:03:10,159 --> 00:03:12,200
the equivalent of one modern day energy

84
00:03:12,200 --> 00:03:14,519
efficient light bulb so that's probably

85
00:03:14,519 --> 00:03:16,280
what's above me now basically in my room

86
00:03:16,280 --> 00:03:18,840
here um this QR code should take you to

87
00:03:18,840 --> 00:03:20,040
quite an interesting paper on power

88
00:03:20,040 --> 00:03:21,239
consumption in the brain if you're

89
00:03:21,239 --> 00:03:23,080
interested in

90
00:03:23,080 --> 00:03:25,360
that so that works out about four

91
00:03:25,360 --> 00:03:28,519
Bananas a Day to power your brain and

92
00:03:28,519 --> 00:03:30,760
this is calculated by the way based on a

93
00:03:30,760 --> 00:03:32,840
calorie intake that the brain needs so

94
00:03:32,840 --> 00:03:35,200
for context the fastest supercomputer in

95
00:03:35,200 --> 00:03:36,720
Europe I think it's called Lumi in

96
00:03:36,720 --> 00:03:38,560
Finland um it's been called

97
00:03:38,560 --> 00:03:40,560
exceptionally green and its power

98
00:03:40,560 --> 00:03:43,640
consumption is 8.5 million Watts so

99
00:03:43,640 --> 00:03:45,840
that's around half a million light bulbs

100
00:03:45,840 --> 00:03:48,840
well your brain uses just one so then

101
00:03:48,840 --> 00:03:49,879
the question is well what does your

102
00:03:49,879 --> 00:03:52,280
brain do with that one light bulb or

103
00:03:52,280 --> 00:03:54,200
four

104
00:03:54,200 --> 00:03:57,599
bananas apparently it does 1,000 billion

105
00:03:57,599 --> 00:04:00,120
calculations per second so so there's

106
00:04:00,120 --> 00:04:01,879
lots of other massive estimates out

107
00:04:01,879 --> 00:04:03,599
there uh this wasn't even the largest by

108
00:04:03,599 --> 00:04:05,840
several orders of magnitude estimates

109
00:04:05,840 --> 00:04:07,799
are obviously very speculative um but

110
00:04:07,799 --> 00:04:09,519
they're all massive and they all tend to

111
00:04:09,519 --> 00:04:11,280
be based on the number of neurons their

112
00:04:11,280 --> 00:04:13,840
connections and firing rates um but I

113
00:04:13,840 --> 00:04:14,879
think it's really important for the

114
00:04:14,879 --> 00:04:17,040
context that supercomputers can't

115
00:04:17,040 --> 00:04:18,880
actually yet match you know our

116
00:04:18,880 --> 00:04:20,880
complexity of skills um or the

117
00:04:20,880 --> 00:04:23,400
adaptability of the human brain so we

118
00:04:23,400 --> 00:04:25,520
actually Excel Way Beyond supercomputers

119
00:04:25,520 --> 00:04:26,960
when it comes to things like complex

120
00:04:26,960 --> 00:04:29,120
decision- making uh learning from

121
00:04:29,120 --> 00:04:31,520
experience

122
00:04:31,520 --> 00:04:34,039
so how does your brain compare to AI um

123
00:04:34,039 --> 00:04:36,039
so I mentioned that modern AI is already

124
00:04:36,039 --> 00:04:38,199
brain inspired however artificial

125
00:04:38,199 --> 00:04:41,240
neurons are highly simplified they don't

126
00:04:41,240 --> 00:04:42,600
they don't capture the complexity of

127
00:04:42,600 --> 00:04:44,320
biological neurons or networks like not

128
00:04:44,320 --> 00:04:47,240
even close um individual neurons are

129
00:04:47,240 --> 00:04:49,520
actually more like networks themselves

130
00:04:49,520 --> 00:04:51,120
and research suggests that modeling one

131
00:04:51,120 --> 00:04:53,039
biological neuron requires a five to

132
00:04:53,039 --> 00:04:55,240
eight layer di deep artificial neuron

133
00:04:55,240 --> 00:04:57,080
Network made of around a thousand

134
00:04:57,080 --> 00:04:59,160
artificial neurons this QR code should

135
00:04:59,160 --> 00:05:02,160
take you to the paper for

136
00:05:02,160 --> 00:05:04,919
that you have 86 billion neurons in your

137
00:05:04,919 --> 00:05:07,120
brain uh they work together to form a

138
00:05:07,120 --> 00:05:09,160
highly energy efficient low latency

139
00:05:09,160 --> 00:05:11,560
supercomputer that works just above room

140
00:05:11,560 --> 00:05:13,759
temperature of the equivalent of about

141
00:05:13,759 --> 00:05:16,440
four Bananas a Day so hopefully I've

142
00:05:16,440 --> 00:05:17,680
given you a sense of how amazing your

143
00:05:17,680 --> 00:05:19,720
brain is um as if you didn't know that

144
00:05:19,720 --> 00:05:21,960
already and how it's already been used

145
00:05:21,960 --> 00:05:24,039
to inspire the I guess fairly basic AI

146
00:05:24,039 --> 00:05:25,560
that we have now compared to human

147
00:05:25,560 --> 00:05:27,360
intelligence so next I'm going to

148
00:05:27,360 --> 00:05:29,000
explain how key features of the brain

149
00:05:29,000 --> 00:05:31,319
are being implemented to catalyze our

150
00:05:31,319 --> 00:05:33,720
next generation of AI and Technology

151
00:05:33,720 --> 00:05:35,080
through the field of neuromorphic

152
00:05:35,080 --> 00:05:37,680
computing which is why you're all here

153
00:05:37,680 --> 00:05:39,960
so traditional vum and computers have

154
00:05:39,960 --> 00:05:42,039
physically separate Computing and memory

155
00:05:42,039 --> 00:05:45,039
units shown here on the left uh during

156
00:05:45,039 --> 00:05:47,280
computation data must transfer backwards

157
00:05:47,280 --> 00:05:49,000
and forwards like really fast so there's

158
00:05:49,000 --> 00:05:51,600
a bottleneck essentially for Speed and

159
00:05:51,600 --> 00:05:53,840
energy um whereas in neuromorphic

160
00:05:53,840 --> 00:05:55,160
architectures which are shown here on

161
00:05:55,160 --> 00:05:57,400
the right with the help of Dary

162
00:05:57,400 --> 00:05:59,639
Computing and memory occur in the same

163
00:05:59,639 --> 00:06:01,840
place so they're said to be

164
00:06:01,840 --> 00:06:03,880
collocated essentially individual

165
00:06:03,880 --> 00:06:06,080
neurons perform computation while

166
00:06:06,080 --> 00:06:07,759
memories represented by the strength of

167
00:06:07,759 --> 00:06:09,720
the connections the weights between

168
00:06:09,720 --> 00:06:13,000
neurons so the copses so chips like this

169
00:06:13,000 --> 00:06:15,440
might be created with components uh like

170
00:06:15,440 --> 00:06:17,919
mistas for example which can emulate

171
00:06:17,919 --> 00:06:20,840
synaptic weights and this architecture

172
00:06:20,840 --> 00:06:22,960
improves speed it reduces energy

173
00:06:22,960 --> 00:06:24,520
consumption and what's really

174
00:06:24,520 --> 00:06:26,319
interesting is it enables massively

175
00:06:26,319 --> 00:06:28,240
parallel processing meaning that

176
00:06:28,240 --> 00:06:30,080
multiple problems can be worked on at

177
00:06:30,080 --> 00:06:32,720
the same time so this is particularly

178
00:06:32,720 --> 00:06:34,680
important this architecture for various

179
00:06:34,680 --> 00:06:37,039
use cases but also because as we reach

180
00:06:37,039 --> 00:06:39,199
the end of Moos log which is the number

181
00:06:39,199 --> 00:06:41,520
of transistors you able to physically

182
00:06:41,520 --> 00:06:44,599
make tinier and tinier to fit on a chip

183
00:06:44,599 --> 00:06:46,759
and it's also important because Humanity

184
00:06:46,759 --> 00:06:48,560
needs to massively reduce its energy

185
00:06:48,560 --> 00:06:51,520
consumption against the backdrop drop of

186
00:06:51,520 --> 00:06:54,400
creating ever more powerful

187
00:06:54,400 --> 00:06:57,280
AI so artificial neurons uh typically

188
00:06:57,280 --> 00:06:59,560
use continuous activation shown on the

189
00:06:59,560 --> 00:07:01,599
left they're always on while

190
00:07:01,599 --> 00:07:03,560
neuromorphic neurons they're said to be

191
00:07:03,560 --> 00:07:05,720
spiking so they're on or they're off

192
00:07:05,720 --> 00:07:07,440
which is shown here on the right so

193
00:07:07,440 --> 00:07:09,759
similar to sort of an action potential

194
00:07:09,759 --> 00:07:12,000
so the benefits for this are again power

195
00:07:12,000 --> 00:07:14,160
efficiency um and also applications

196
00:07:14,160 --> 00:07:16,319
where timing is important and this is

197
00:07:16,319 --> 00:07:18,720
given that their event driven so

198
00:07:18,720 --> 00:07:21,160
essentially they have um the potential

199
00:07:21,160 --> 00:07:23,759
for spatial and temporal Dimensions

200
00:07:23,759 --> 00:07:25,759
which then enables added spatio temporal

201
00:07:25,759 --> 00:07:28,479
encoding and processing of information

202
00:07:28,479 --> 00:07:30,680
uh you might be wondering bit about gpus

203
00:07:30,680 --> 00:07:33,240
um which also enable parallel processing

204
00:07:33,240 --> 00:07:35,080
uh research suggests that gpus are

205
00:07:35,080 --> 00:07:37,319
suitable architectures for deploying

206
00:07:37,319 --> 00:07:39,599
spiking your networks um which I think

207
00:07:39,599 --> 00:07:41,280
makes this a really interesting time for

208
00:07:41,280 --> 00:07:43,199
the field given how highend gpus are

209
00:07:43,199 --> 00:07:46,159
becoming ever more

210
00:07:46,159 --> 00:07:49,479
pervasive um so the brain learn strength

211
00:07:49,479 --> 00:07:51,599
of synapsis between neurons this is

212
00:07:51,599 --> 00:07:53,560
based on pre and post synaptic firing

213
00:07:53,560 --> 00:07:55,240
patterns I think David's talk will talk

214
00:07:55,240 --> 00:07:57,680
a lot we'll go into a lot more depth on

215
00:07:57,680 --> 00:07:59,319
this but there are many different typ

216
00:07:59,319 --> 00:08:01,240
types and patterns of this across the

217
00:08:01,240 --> 00:08:03,720
brain depending on the types of synapses

218
00:08:03,720 --> 00:08:05,599
such as excitatory to inhibitory

219
00:08:05,599 --> 00:08:06,919
excitatory to

220
00:08:06,919 --> 00:08:09,159
excitatory um and the neurom market

221
00:08:09,159 --> 00:08:11,639
field is working to leverage these rules

222
00:08:11,639 --> 00:08:13,800
um because of benefits for on chip

223
00:08:13,800 --> 00:08:16,159
learning and also applications such as

224
00:08:16,159 --> 00:08:18,039
pattern recognition and Edge Computing

225
00:08:18,039 --> 00:08:19,599
as well Edge Computing being quite a

226
00:08:19,599 --> 00:08:21,680
huge use case for neuromorphic computing

227
00:08:21,680 --> 00:08:23,000
because of the sort of event driven

228
00:08:23,000 --> 00:08:26,240
nature and also the low energy usage and

229
00:08:26,240 --> 00:08:27,879
this QR code should take you to quite an

230
00:08:27,879 --> 00:08:31,839
interesting paper um on stdp that I

231
00:08:31,839 --> 00:08:34,799
found so what neuromorphic Solutions are

232
00:08:34,799 --> 00:08:36,159
available now you might just think it's

233
00:08:36,159 --> 00:08:38,320
s theoretical uh there are actually many

234
00:08:38,320 --> 00:08:40,200
different solutions out there which I'll

235
00:08:40,200 --> 00:08:41,559
just give you a really high level

236
00:08:41,559 --> 00:08:44,120
overview of so the human brain project

237
00:08:44,120 --> 00:08:45,760
has created several large scale

238
00:08:45,760 --> 00:08:48,120
neuromorphic computers including spica

239
00:08:48,120 --> 00:08:49,800
which is this one at the bottom this

240
00:08:49,800 --> 00:08:51,560
boards like maybe like I don't know the

241
00:08:51,560 --> 00:08:53,480
size of my face or something so that

242
00:08:53,480 --> 00:08:55,760
runs in real time um and it's comprised

243
00:08:55,760 --> 00:08:58,200
of multiple general purpose on

244
00:08:58,200 --> 00:09:00,279
microprocessors and there was also brain

245
00:09:00,279 --> 00:09:03,120
scales which is an accelerated analog

246
00:09:03,120 --> 00:09:05,399
architecture and it runs a thousand

247
00:09:05,399 --> 00:09:09,240
times real time so the um the board next

248
00:09:09,240 --> 00:09:11,120
to the blue one that's an actual credit

249
00:09:11,120 --> 00:09:13,240
card size um version of brain scales

250
00:09:13,240 --> 00:09:14,399
which they've recently made which I

251
00:09:14,399 --> 00:09:16,920
thought was pretty cool um and then

252
00:09:16,920 --> 00:09:18,399
there's also some big players in the

253
00:09:18,399 --> 00:09:21,000
space so this blue one here is Intel's

254
00:09:21,000 --> 00:09:23,640
Loi chip they're on to lii 2 now that's

255
00:09:23,640 --> 00:09:25,480
their neuromorphic chip and they have an

256
00:09:25,480 --> 00:09:27,000
open source software framework for that

257
00:09:27,000 --> 00:09:27,920
as well because they really want to

258
00:09:27,920 --> 00:09:29,480
catalyze the open source key Community

259
00:09:29,480 --> 00:09:32,079
to get involved with it so neuromorphic

260
00:09:32,079 --> 00:09:34,040
sensors also exist so this little blue

261
00:09:34,040 --> 00:09:35,000
thing in the middle is actually a

262
00:09:35,000 --> 00:09:36,800
neuromorphic camera it's maybe like this

263
00:09:36,800 --> 00:09:40,040
big um so they aim to recreate how our

264
00:09:40,040 --> 00:09:42,480
nervous system senses stimulate such as

265
00:09:42,480 --> 00:09:44,880
light so for example in a neuromorphic

266
00:09:44,880 --> 00:09:47,200
camera which is the one here each pixel

267
00:09:47,200 --> 00:09:49,560
works independently with a microsc

268
00:09:49,560 --> 00:09:52,120
resolution hopefully my GIF will work oh

269
00:09:52,120 --> 00:09:54,440
there we go so you can see each pixel

270
00:09:54,440 --> 00:09:56,680
working there which is pretty cool so

271
00:09:56,680 --> 00:09:58,760
compared to traditional digital cameras

272
00:09:58,760 --> 00:10:00,120
they have improved performance with

273
00:10:00,120 --> 00:10:02,920
motion and lower power consumption there

274
00:10:02,920 --> 00:10:05,120
was also a neuromorphic nose recently by

275
00:10:05,120 --> 00:10:07,079
Intel which was pretty cool um so it

276
00:10:07,079 --> 00:10:08,440
could learn the scent of a chemical

277
00:10:08,440 --> 00:10:10,959
after just one exposure um and then it

278
00:10:10,959 --> 00:10:12,480
could identify that scent even when it

279
00:10:12,480 --> 00:10:15,279
was masked by others and then finally

280
00:10:15,279 --> 00:10:17,959
this is a humanoid robot called an iub

281
00:10:17,959 --> 00:10:19,240
and what you can do is you can actually

282
00:10:19,240 --> 00:10:21,200
integrate neuromorphic sensors such as

283
00:10:21,200 --> 00:10:24,000
the camera and then neuromorphic chips

284
00:10:24,000 --> 00:10:27,000
maybe spa or brain scales into a

285
00:10:27,000 --> 00:10:28,440
humanoid device like this or other

286
00:10:28,440 --> 00:10:30,560
devices like a drone and then from that

287
00:10:30,560 --> 00:10:31,839
you can actually create embodied

288
00:10:31,839 --> 00:10:34,200
neuromorphic systems uh and this is

289
00:10:34,200 --> 00:10:35,839
something that we work on at the Smart

290
00:10:35,839 --> 00:10:37,519
interactive Technologies research lab in

291
00:10:37,519 --> 00:10:40,320
Sheffield in the

292
00:10:40,480 --> 00:10:42,600
UK this slide just highlights some of

293
00:10:42,600 --> 00:10:43,959
the potential applications of

294
00:10:43,959 --> 00:10:45,480
neuromorphic computing which I thought

295
00:10:45,480 --> 00:10:46,720
were quite interesting when you think

296
00:10:46,720 --> 00:10:49,120
about it so the understanding of context

297
00:10:49,120 --> 00:10:51,560
pattern recognition Advanced sensing few

298
00:10:51,560 --> 00:10:54,360
shot learning generalizing across tasks

299
00:10:54,360 --> 00:10:56,839
complex decision- making explainability

300
00:10:56,839 --> 00:10:59,519
and brain interfaces um so all these

301
00:10:59,519 --> 00:11:01,360
skills are really beneficial when you're

302
00:11:01,360 --> 00:11:03,399
thinking about human- centered realtime

303
00:11:03,399 --> 00:11:06,240
applications in Dynamic environments so

304
00:11:06,240 --> 00:11:07,839
things like self-driving cars for

305
00:11:07,839 --> 00:11:10,000
example and personally I think that

306
00:11:10,000 --> 00:11:12,800
neuromorphic systems um are also likely

307
00:11:12,800 --> 00:11:14,360
to be the future substrate of brain

308
00:11:14,360 --> 00:11:16,000
computer interfaces probably a bit

309
00:11:16,000 --> 00:11:17,959
biased because I'm a neuroscientist but

310
00:11:17,959 --> 00:11:19,959
um they're low energy they're real time

311
00:11:19,959 --> 00:11:22,000
and they also have architectures which

312
00:11:22,000 --> 00:11:24,839
match our own Hardware so I do think

313
00:11:24,839 --> 00:11:26,560
we'll soon see the BCI field being

314
00:11:26,560 --> 00:11:28,680
catalyzed by neuromorphic systems

315
00:11:28,680 --> 00:11:29,480
particular

316
00:11:29,480 --> 00:11:31,360
maybe for hybrids of hardware and and

317
00:11:31,360 --> 00:11:33,680
wetwear so maybe even potentially

318
00:11:33,680 --> 00:11:35,800
containing people's own um you know

319
00:11:35,800 --> 00:11:37,399
brain cells which you can actually grow

320
00:11:37,399 --> 00:11:40,160
just from a hair

321
00:11:40,360 --> 00:11:43,040
cell and the particular focus of our

322
00:11:43,040 --> 00:11:45,160
work is designing AI which learns in a

323
00:11:45,160 --> 00:11:47,120
similar way to a human so it has an

324
00:11:47,120 --> 00:11:48,959
innate sense of curiosity and it learns

325
00:11:48,959 --> 00:11:51,560
through interacting with the real world

326
00:11:51,560 --> 00:11:53,959
so in the 50s Alan Turing said instead

327
00:11:53,959 --> 00:11:56,079
of trying to produce a program to

328
00:11:56,079 --> 00:11:58,519
simulate the adult mind why not rather

329
00:11:58,519 --> 00:12:00,360
try to produce one which stimulates the

330
00:12:00,360 --> 00:12:02,760
child's brain If This Were then subject

331
00:12:02,760 --> 00:12:04,560
to an appropriate course of Education

332
00:12:04,560 --> 00:12:07,480
one would obtain the adult brain this is

333
00:12:07,480 --> 00:12:09,360
very much the philosophy behind the

334
00:12:09,360 --> 00:12:12,320
neurodevelopmental approach um to Ai and

335
00:12:12,320 --> 00:12:13,800
neuromorphic Computing which I just

336
00:12:13,800 --> 00:12:15,800
wanted to

337
00:12:15,800 --> 00:12:17,839
highlight um there are some challenges

338
00:12:17,839 --> 00:12:19,839
in the field these are very high level

339
00:12:19,839 --> 00:12:20,880
but I'll just give you a little bit of

340
00:12:20,880 --> 00:12:23,760
an idea of it so training spiking neural

341
00:12:23,760 --> 00:12:25,079
networks is more complex than

342
00:12:25,079 --> 00:12:27,199
traditional neural networks also

343
00:12:27,199 --> 00:12:28,560
designing Hardware which actually

344
00:12:28,560 --> 00:12:31,079
implement spiking neural networks stdp

345
00:12:31,079 --> 00:12:33,120
on a large scale is said to be fairly

346
00:12:33,120 --> 00:12:35,120
challenging and then also developing

347
00:12:35,120 --> 00:12:36,480
algorithms which can actually

348
00:12:36,480 --> 00:12:38,959
effectively leverage all these like

349
00:12:38,959 --> 00:12:41,440
Technologies so the hardware the stdp

350
00:12:41,440 --> 00:12:45,399
it's an ongoing active area of

351
00:12:45,399 --> 00:12:48,760
research um so if you're here you're

352
00:12:48,760 --> 00:12:50,959
probably interested in active inference

353
00:12:50,959 --> 00:12:52,560
so I wanted to highlight this actually

354
00:12:52,560 --> 00:12:53,839
someone put on the Discord today one of

355
00:12:53,839 --> 00:12:55,839
these studies which is pretty cool so a

356
00:12:55,839 --> 00:12:58,040
couple of recent Studies have um

357
00:12:58,040 --> 00:12:59,560
combined neuromorphic Computing with

358
00:12:59,560 --> 00:13:01,720
principles of active inference so active

359
00:13:01,720 --> 00:13:03,720
inference comes from neuroscience and I

360
00:13:03,720 --> 00:13:05,040
would argue that it lends itself very

361
00:13:05,040 --> 00:13:06,600
well to neuromorphic

362
00:13:06,600 --> 00:13:08,760
architectures um in a recent paper on

363
00:13:08,760 --> 00:13:10,680
embodied neuromorphic intelligence so

364
00:13:10,680 --> 00:13:12,320
not not it didn't really mention active

365
00:13:12,320 --> 00:13:14,279
inference in it the QR code on the top

366
00:13:14,279 --> 00:13:16,279
right here um it was suggested that a

367
00:13:16,279 --> 00:13:18,079
real breakthrough in neuromorphics will

368
00:13:18,079 --> 00:13:19,959
happen if the whole system design is

369
00:13:19,959 --> 00:13:21,839
based on biological computational

370
00:13:21,839 --> 00:13:23,800
principles with a tight into playay

371
00:13:23,800 --> 00:13:25,199
between the estimation of the

372
00:13:25,199 --> 00:13:27,360
surroundings and the robot's own State

373
00:13:27,360 --> 00:13:30,240
and decisionmaking planning and action

374
00:13:30,240 --> 00:13:31,600
so some of those themes might sound

375
00:13:31,600 --> 00:13:32,839
quite familiar to people interested in

376
00:13:32,839 --> 00:13:35,199
active inference and U I would suggest

377
00:13:35,199 --> 00:13:36,959
that active inference is well placed to

378
00:13:36,959 --> 00:13:39,160
meet these requirements and I just

379
00:13:39,160 --> 00:13:40,600
wanted to highlight a couple of recent

380
00:13:40,600 --> 00:13:43,079
studies here so this one on the left

381
00:13:43,079 --> 00:13:45,000
gandal FAL recently demonstrated

382
00:13:45,000 --> 00:13:47,519
plasticity and Rapid unsupervised

383
00:13:47,519 --> 00:13:50,240
learning in a neuromorphic system using

384
00:13:50,240 --> 00:13:52,560
active inference principles the author

385
00:13:52,560 --> 00:13:53,800
suggested that their experiments could

386
00:13:53,800 --> 00:13:55,560
be adopted to implement brain-like

387
00:13:55,560 --> 00:13:58,759
predictive capabilities in neuro neuro

388
00:13:58,759 --> 00:14:01,480
morphic robotic systems and then there

389
00:14:01,480 --> 00:14:03,000
was the dish frin paper which some of

390
00:14:03,000 --> 00:14:05,560
you may be familiar with by Kagan atal

391
00:14:05,560 --> 00:14:08,399
so this was a hybrid um wetwear Hardware

392
00:14:08,399 --> 00:14:10,399
neuromorphic system that the author's

393
00:14:10,399 --> 00:14:12,759
claimed was embodied the system showed

394
00:14:12,759 --> 00:14:14,480
rapid parent learning of the game of

395
00:14:14,480 --> 00:14:16,839
pong using the free energy principle for

396
00:14:16,839 --> 00:14:19,040
Learning and the authors claimed that

397
00:14:19,040 --> 00:14:20,720
the system exhibited synthetic

398
00:14:20,720 --> 00:14:21,959
biological

399
00:14:21,959 --> 00:14:24,320
intelligence so the field implementing

400
00:14:24,320 --> 00:14:25,920
active influence principles in

401
00:14:25,920 --> 00:14:28,480
neuromorphic systems is very nent and

402
00:14:28,480 --> 00:14:31,199
the idea behind this mream series is to

403
00:14:31,199 --> 00:14:33,480
create a space and a community to share

404
00:14:33,480 --> 00:14:36,079
knowledge ideas and expertise to

405
00:14:36,079 --> 00:14:38,240
catalyze the field um I think some

406
00:14:38,240 --> 00:14:40,560
really exciting technological leaps are

407
00:14:40,560 --> 00:14:42,839
probably going to come from this area so

408
00:14:42,839 --> 00:14:44,880
thank you for listening to my uh quick

409
00:14:44,880 --> 00:14:48,920
run through neuromorphic 101 um and next

410
00:14:48,920 --> 00:14:51,880
up we're gonna hear from David so David

411
00:14:51,880 --> 00:14:53,519
over to you if you want to introduce

412
00:14:53,519 --> 00:14:56,399
yourself please thank you

413
00:14:56,399 --> 00:14:59,639
Sarah um I would

414
00:14:59,639 --> 00:15:02,320
share my

415
00:15:03,320 --> 00:15:06,320
screen

416
00:15:10,820 --> 00:15:14,040
[Music]

417
00:15:14,040 --> 00:15:17,600
yeah can you see now

418
00:15:17,600 --> 00:15:21,240
my screen the presentation yeah okay

419
00:15:21,240 --> 00:15:24,240
perfect okay yeah hello my my name is

420
00:15:24,240 --> 00:15:27,639
David kle I'm a researcher and coup

421
00:15:27,639 --> 00:15:30,519
leader at The Institute for um M

422
00:15:30,519 --> 00:15:33,839
informatic at the University of bom um

423
00:15:33,839 --> 00:15:36,040
so I'm uh leading the group on

424
00:15:36,040 --> 00:15:37,920
sustainable machine learning and we have

425
00:15:37,920 --> 00:15:40,199
a very strong focus on neuromorphic

426
00:15:40,199 --> 00:15:41,800
Computing that's why I'm here

427
00:15:41,800 --> 00:15:44,360
today and I'm going to start with a very

428
00:15:44,360 --> 00:15:47,279
similar motivation than Sarah did which

429
00:15:47,279 --> 00:15:49,240
was really a great um inspiration for

430
00:15:49,240 --> 00:15:51,959
this talk I think um so probably most of

431
00:15:51,959 --> 00:15:54,560
you have seen this um this interesting

432
00:15:54,560 --> 00:15:57,120
recent result and I don't mean Germany

433
00:15:57,120 --> 00:15:59,120
winning the basketball championship ship

434
00:15:59,120 --> 00:16:03,880
but um this really big leap in uh in

435
00:16:03,880 --> 00:16:05,319
artificial intelligence that we have

436
00:16:05,319 --> 00:16:07,079
seen in the last years especially the

437
00:16:07,079 --> 00:16:08,959
last two or three years so this is a

438
00:16:08,959 --> 00:16:11,480
picture generated from a prompt by a

439
00:16:11,480 --> 00:16:14,360
doly network and it's it's really

440
00:16:14,360 --> 00:16:16,399
amazing and was considered science

441
00:16:16,399 --> 00:16:18,519
fiction like only two three years

442
00:16:18,519 --> 00:16:22,360
ago and this was essentially made uh

443
00:16:22,360 --> 00:16:24,120
possible by a neuromorphic approach

444
00:16:24,120 --> 00:16:26,680
which is deep neural networks and this

445
00:16:26,680 --> 00:16:28,079
these uh deep neural networks have

446
00:16:28,079 --> 00:16:31,120
become huge now but this comes also with

447
00:16:31,120 --> 00:16:33,839
a caveat so basically the flip side is

448
00:16:33,839 --> 00:16:36,639
that this um among other problems maybe

449
00:16:36,639 --> 00:16:40,360
these models may have they consume uh

450
00:16:40,360 --> 00:16:43,959
huge amounts of energy so models like um

451
00:16:43,959 --> 00:16:47,279
Dal or jet GPT they as Sarah already

452
00:16:47,279 --> 00:16:50,360
mentioned they they would consume um

453
00:16:50,360 --> 00:16:52,680
energy budgets that are comparable to

454
00:16:52,680 --> 00:16:56,759
houses or cars so training um jgpt a

455
00:16:56,759 --> 00:16:59,440
single time is like a giga hour

456
00:16:59,440 --> 00:17:02,680
approximately so that would be 300 tons

457
00:17:02,680 --> 00:17:07,160
of CO2 emission um and many times the

458
00:17:07,160 --> 00:17:09,760
which comes down to many times the life

459
00:17:09,760 --> 00:17:13,359
uh span of a of a typical car so this

460
00:17:13,359 --> 00:17:15,280
comes with two problems obviously uh

461
00:17:15,280 --> 00:17:17,880
this makes training these models only

462
00:17:17,880 --> 00:17:20,160
accessible to a very small number of

463
00:17:20,160 --> 00:17:21,799
very large players so essentially the

464
00:17:21,799 --> 00:17:24,599
big tech companies and secondly and

465
00:17:24,599 --> 00:17:26,319
maybe even more importantly this is not

466
00:17:26,319 --> 00:17:29,160
compatible with uh planet with uh

467
00:17:29,160 --> 00:17:31,880
limited resources so if the growth rate

468
00:17:31,880 --> 00:17:34,160
of AI continues like it did in the last

469
00:17:34,160 --> 00:17:35,360
years it will

470
00:17:35,360 --> 00:17:38,240
consume uh 133% of the global energy

471
00:17:38,240 --> 00:17:41,400
consumption by 20 30 and it will

472
00:17:41,400 --> 00:17:45,080
basically outrun um the transportation

473
00:17:45,080 --> 00:17:48,200
sector in in another five years or

474
00:17:48,200 --> 00:17:50,720
so so this raises the question does

475
00:17:50,720 --> 00:17:52,600
sustainable machine learning exist at

476
00:17:52,600 --> 00:17:55,080
all and obviously since I'm working in

477
00:17:55,080 --> 00:17:56,799
the group of sustainable machine

478
00:17:56,799 --> 00:17:59,039
learning I believe it does

479
00:17:59,039 --> 00:18:01,799
and why I think it does is because we

480
00:18:01,799 --> 00:18:04,960
know a system that um is very efficient

481
00:18:04,960 --> 00:18:08,600
and is still probably better than these

482
00:18:08,600 --> 00:18:11,039
these AI models which is the human brain

483
00:18:11,039 --> 00:18:13,000
which consumes as Sarah mentioned around

484
00:18:13,000 --> 00:18:14,039
20

485
00:18:14,039 --> 00:18:16,919
watts uh or four Bananas a

486
00:18:16,919 --> 00:18:21,400
Day uh and uh so it's it's many orders

487
00:18:21,400 --> 00:18:24,400
of magnitude more efficient than the AI

488
00:18:24,400 --> 00:18:26,200
models we have

489
00:18:26,200 --> 00:18:29,480
today uh but so far we don't know

490
00:18:29,480 --> 00:18:32,480
essentially how these networks work um

491
00:18:32,480 --> 00:18:34,520
and especially how to train them and

492
00:18:34,520 --> 00:18:37,080
basically our our goal is to transfer

493
00:18:37,080 --> 00:18:39,559
now mechanisms from machine learning

494
00:18:39,559 --> 00:18:41,679
that's so you have this nice picture

495
00:18:41,679 --> 00:18:44,679
here uh basically we start from the

496
00:18:44,679 --> 00:18:46,440
machine learning site where we already

497
00:18:46,440 --> 00:18:49,400
know our way around um so we have these

498
00:18:49,400 --> 00:18:51,280
models that are wonderful and that are

499
00:18:51,280 --> 00:18:53,120
quite that that give us really

500
00:18:53,120 --> 00:18:55,240
impressive results but they are not

501
00:18:55,240 --> 00:18:57,480
efficient and we want to trans transfer

502
00:18:57,480 --> 00:19:01,840
them to um new efficient uh AI

503
00:19:01,840 --> 00:19:04,120
generation and our ideas is to use

504
00:19:04,120 --> 00:19:07,520
inspiration from Neuroscience um that

505
00:19:07,520 --> 00:19:09,799
make this transfer faster and and

506
00:19:09,799 --> 00:19:12,240
possible in the first

507
00:19:12,240 --> 00:19:17,039
place okay so and actually biology is a

508
00:19:17,039 --> 00:19:19,679
great source of inspiration and always

509
00:19:19,679 --> 00:19:21,400
comes around the corner with very

510
00:19:21,400 --> 00:19:23,200
surprising results and one of these

511
00:19:23,200 --> 00:19:24,960
results that I stumbled Upon A couple of

512
00:19:24,960 --> 00:19:30,919
years ago is that the the ability of um

513
00:19:30,919 --> 00:19:33,559
copses in the brain so as you probably

514
00:19:33,559 --> 00:19:35,200
know neurons in your brain are connected

515
00:19:35,200 --> 00:19:36,159
for

516
00:19:36,159 --> 00:19:40,960
copses um but if you look at the so so

517
00:19:40,960 --> 00:19:43,480
this is a paper from

518
00:19:43,480 --> 00:19:45,919
2019 and they could actually identify

519
00:19:45,919 --> 00:19:47,320
individual Sy upses and they could

520
00:19:47,320 --> 00:19:49,400
trigger them to uh make a synoptic

521
00:19:49,400 --> 00:19:51,799
release like a single transmission but

522
00:19:51,799 --> 00:19:54,840
if you look at this um um at these

523
00:19:54,840 --> 00:19:57,799
measurements you see that this is really

524
00:19:57,799 --> 00:20:00,320
covered in and noise so essentially if

525
00:20:00,320 --> 00:20:02,960
you basically average over this and zoom

526
00:20:02,960 --> 00:20:04,720
this out you see here these typical

527
00:20:04,720 --> 00:20:06,679
synoptic traces which is the average

528
00:20:06,679 --> 00:20:09,240
white line here but below that you see

529
00:20:09,240 --> 00:20:12,080
this huge chitter so there's they really

530
00:20:12,080 --> 00:20:14,960
like go several um standard deviations

531
00:20:14,960 --> 00:20:16,120
up and

532
00:20:16,120 --> 00:20:18,640
down um and this is actually very

533
00:20:18,640 --> 00:20:21,000
surprising given that uh neurons are

534
00:20:21,000 --> 00:20:23,480
probably the single most costly cell

535
00:20:23,480 --> 00:20:25,559
type in your body in terms of energy

536
00:20:25,559 --> 00:20:28,840
consumption they really in or in

537
00:20:28,840 --> 00:20:32,000
comparison they they they consume quite

538
00:20:32,000 --> 00:20:34,159
a bit of energy in your body so you

539
00:20:34,159 --> 00:20:36,440
would expect that these transitions or

540
00:20:36,440 --> 00:20:38,720
Transmissions that are communicated

541
00:20:38,720 --> 00:20:41,480
between neurons which are very costly uh

542
00:20:41,480 --> 00:20:43,480
should be highly reliable so this is

543
00:20:43,480 --> 00:20:46,120
very counterintuitive this results and

544
00:20:46,120 --> 00:20:48,120
has been puzzling neuroscientists for

545
00:20:48,120 --> 00:20:50,039
quite a while

546
00:20:50,039 --> 00:20:53,600
now um and then there is

547
00:20:53,600 --> 00:20:58,080
a there is a second um puzzling observ

548
00:20:58,080 --> 00:21:00,120
obervation which is

549
00:21:00,120 --> 00:21:03,919
uh that the morphology of neurons looks

550
00:21:03,919 --> 00:21:05,480
some somewhat like this so this would be

551
00:21:05,480 --> 00:21:08,159
a typical pyramidal neuron you have in

552
00:21:08,159 --> 00:21:09,039
your

553
00:21:09,039 --> 00:21:12,880
cortex um but you see that this is

554
00:21:12,880 --> 00:21:15,919
actually for a cell quite quite big and

555
00:21:15,919 --> 00:21:18,039
elongated so this is this can be up to a

556
00:21:18,039 --> 00:21:21,039
millimeter in in the human brain uh

557
00:21:21,039 --> 00:21:23,000
which means that if a signups fires

558
00:21:23,000 --> 00:21:25,400
somewhere here uh it has a very hard

559
00:21:25,400 --> 00:21:27,200
time communicating with the cell body

560
00:21:27,200 --> 00:21:29,000
which is down here so electrical signals

561
00:21:29,000 --> 00:21:33,240
that are produced here uh May travel

562
00:21:33,240 --> 00:21:35,440
down here but the the signups up here

563
00:21:35,440 --> 00:21:38,480
has no way of measuring uh the actual

564
00:21:38,480 --> 00:21:40,520
voltages at the cell body and this is

565
00:21:40,520 --> 00:21:41,960
actually the interesting place because

566
00:21:41,960 --> 00:21:43,760
here are the action potentials formed so

567
00:21:43,760 --> 00:21:46,039
if the the signups would really like to

568
00:21:46,039 --> 00:21:48,240
know about what is going on in the cell

569
00:21:48,240 --> 00:21:50,120
body so that it can make predictions

570
00:21:50,120 --> 00:21:52,840
about how the uh neuron will behave and

571
00:21:52,840 --> 00:21:55,400
how it interacts with the world and this

572
00:21:55,400 --> 00:21:59,880
is another very puzzling um um or open

573
00:21:59,880 --> 00:22:02,120
problem in in Neuroscience how this

574
00:22:02,120 --> 00:22:04,120
communication actually works out in in

575
00:22:04,120 --> 00:22:07,320
single neurons between the cell body and

576
00:22:07,320 --> 00:22:10,720
the uh and the signups it is known that

577
00:22:10,720 --> 00:22:12,840
actually the action potentials can

578
00:22:12,840 --> 00:22:14,880
travel back up so they see kind of this

579
00:22:14,880 --> 00:22:18,000
binary variable when the uh when the

580
00:22:18,000 --> 00:22:20,240
neuron spikes but they cannot actually

581
00:22:20,240 --> 00:22:23,799
measure the membrane potential down here

582
00:22:23,799 --> 00:22:25,559
so only the most prominent electric

583
00:22:25,559 --> 00:22:27,159
signals can actually back propagate

584
00:22:27,159 --> 00:22:29,120
through this

585
00:22:29,120 --> 00:22:31,400
uh and this this suggests that the

586
00:22:31,400 --> 00:22:33,000
signups actually has very sparse

587
00:22:33,000 --> 00:22:34,799
information about what's going on with

588
00:22:34,799 --> 00:22:40,720
this um uh in the cell body and uh most

589
00:22:40,720 --> 00:22:43,000
models of synoptic plasticity don't

590
00:22:43,000 --> 00:22:44,159
cover this at

591
00:22:44,159 --> 00:22:48,279
all so and we were wondering um how do

592
00:22:48,279 --> 00:22:50,880
this uh how does this interaction work

593
00:22:50,880 --> 00:22:52,760
how can the

594
00:22:52,760 --> 00:22:55,679
um uh signups produce useful learning

595
00:22:55,679 --> 00:22:57,520
signals given this sparse information

596
00:22:57,520 --> 00:23:00,200
about this important state of the of the

597
00:23:00,200 --> 00:23:02,840
neuron and our idea was that essentially

598
00:23:02,840 --> 00:23:04,480
these two observations these high levels

599
00:23:04,480 --> 00:23:06,440
of noise and the signups and this um

600
00:23:06,440 --> 00:23:08,880
large distance between cell body and and

601
00:23:08,880 --> 00:23:10,640
signups say which give these high

602
00:23:10,640 --> 00:23:12,679
uncertainties these are actually the two

603
00:23:12,679 --> 00:23:15,480
sides of the same coin so our hypothesis

604
00:23:15,480 --> 00:23:18,840
was that um actually we could use the

605
00:23:18,840 --> 00:23:22,880
same models um that we know already from

606
00:23:22,880 --> 00:23:25,640
from the behavioral level uh how an

607
00:23:25,640 --> 00:23:29,559
agent can in uh can act and perform in

608
00:23:29,559 --> 00:23:31,760
an environment of high uncertainty and

609
00:23:31,760 --> 00:23:33,400
we just apply this

610
00:23:33,400 --> 00:23:37,760
to um uh to every signups and oh there's

611
00:23:37,760 --> 00:23:40,120
an error so every signups should utilize

612
00:23:40,120 --> 00:23:44,559
this um these same models

613
00:23:44,559 --> 00:23:47,679
basically and uh this model would

614
00:23:47,679 --> 00:23:49,159
immediately suggest that actually

615
00:23:49,159 --> 00:23:51,919
synoptic Trans Transmissions should be

616
00:23:51,919 --> 00:23:54,320
noisy and these levels of noise would

617
00:23:54,320 --> 00:23:56,880
Express uncertainty about the

618
00:23:56,880 --> 00:23:59,640
environment and then we can use this

619
00:23:59,640 --> 00:24:02,080
model to derive um learning rules and we

620
00:24:02,080 --> 00:24:04,600
can compare them side by side to

621
00:24:04,600 --> 00:24:06,520
biology and this is the first thing I

622
00:24:06,520 --> 00:24:08,960
want to show you so um I just give a

623
00:24:08,960 --> 00:24:10,880
very quick introduction to the free

624
00:24:10,880 --> 00:24:13,720
energy model uh because some some of you

625
00:24:13,720 --> 00:24:15,720
might not be that familiar with it but

626
00:24:15,720 --> 00:24:19,159
this is essentially um a model to

627
00:24:19,159 --> 00:24:21,000
describe a situation like this you have

628
00:24:21,000 --> 00:24:23,279
a person that is interacting with some

629
00:24:23,279 --> 00:24:25,039
environment and here I assumed very

630
00:24:25,039 --> 00:24:28,320
simple so this person tries to um ball

631
00:24:28,320 --> 00:24:31,799
to some Target and we as humans we are

632
00:24:31,799 --> 00:24:34,240
we are good in solving such tasks and we

633
00:24:34,240 --> 00:24:36,039
are also good in solving such tasks if

634
00:24:36,039 --> 00:24:37,840
there is high levels of uncertainty in

635
00:24:37,840 --> 00:24:41,960
this so if the person may receive the

636
00:24:41,960 --> 00:24:44,000
some visual feedback but a lot of this

637
00:24:44,000 --> 00:24:46,440
feedback may be hidden so I you can

638
00:24:46,440 --> 00:24:48,520
imagine this going on behind some

639
00:24:48,520 --> 00:24:52,600
wall and the person now still might want

640
00:24:52,600 --> 00:24:55,039
to predict what is the trajectory of

641
00:24:55,039 --> 00:24:56,679
this ball flying towards the target so

642
00:24:56,679 --> 00:25:00,960
that it can make an correct uh action so

643
00:25:00,960 --> 00:25:03,960
we will assign some variables to this uh

644
00:25:03,960 --> 00:25:05,600
these states here so we have essentially

645
00:25:05,600 --> 00:25:07,440
this feedback that this person can

646
00:25:07,440 --> 00:25:09,880
observe and we have this unobserved

647
00:25:09,880 --> 00:25:12,279
state of the ball flying here which we

648
00:25:12,279 --> 00:25:14,799
call U where the person doesn't have

649
00:25:14,799 --> 00:25:17,000
direct access to it would only see parts

650
00:25:17,000 --> 00:25:19,200
of it for example when the ball is at

651
00:25:19,200 --> 00:25:22,000
the corners of the wall appearing and

652
00:25:22,000 --> 00:25:25,000
then uh to to model this essentially or

653
00:25:25,000 --> 00:25:28,200
to to describe this uh Behavior the the

654
00:25:28,200 --> 00:25:31,240
person would uh have an internal

655
00:25:31,240 --> 00:25:33,360
description of this trajectory so an

656
00:25:33,360 --> 00:25:37,520
internal model of this um State

657
00:25:37,520 --> 00:25:41,480
U uh and the model this model would then

658
00:25:41,480 --> 00:25:45,679
be updated to match the observed

659
00:25:45,679 --> 00:25:48,120
feedback and this can be described very

660
00:25:48,120 --> 00:25:50,200
nicely in this beautiful mathematical

661
00:25:50,200 --> 00:25:52,320
framework of the free enery principle so

662
00:25:52,320 --> 00:25:55,159
the idea is that you would essentially

663
00:25:55,159 --> 00:25:57,279
um establish a model of your internal

664
00:25:57,279 --> 00:26:00,720
States so essentially how the um

665
00:26:00,720 --> 00:26:04,640
internal States and the uh state of the

666
00:26:04,640 --> 00:26:06,440
environment

667
00:26:06,440 --> 00:26:09,000
interact and you would have a model of

668
00:26:09,000 --> 00:26:11,720
the feedback so how the states and the

669
00:26:11,720 --> 00:26:14,240
feedback You observe interact and

670
00:26:14,240 --> 00:26:18,559
essentially you can then write down um a

671
00:26:18,559 --> 00:26:21,080
loss function that uh that measures the

672
00:26:21,080 --> 00:26:23,039
distance between this model of the

673
00:26:23,039 --> 00:26:24,679
internal State and this model of the

674
00:26:24,679 --> 00:26:29,600
feedback and the uh external state

675
00:26:29,960 --> 00:26:31,720
um

676
00:26:31,720 --> 00:26:35,120
and uh then by essentially minimizing

677
00:26:35,120 --> 00:26:37,799
this distance between the two you can

678
00:26:37,799 --> 00:26:41,799
derive all sorts of behavior relevant

679
00:26:41,799 --> 00:26:44,799
um can solve behaviorally relevant

680
00:26:44,799 --> 00:26:46,679
problems for example learning but you

681
00:26:46,679 --> 00:26:48,399
can also use this for other things like

682
00:26:48,399 --> 00:26:50,399
uh figuring out what are good actions

683
00:26:50,399 --> 00:26:53,440
for example so making inference about

684
00:26:53,440 --> 00:26:55,520
both the internal States and the actions

685
00:26:55,520 --> 00:26:58,440
for example and this is shell the free

686
00:26:58,440 --> 00:27:00,480
energy principle and this object here

687
00:27:00,480 --> 00:27:02,360
happens to be what is known as the

688
00:27:02,360 --> 00:27:04,760
variational free energy which is also

689
00:27:04,760 --> 00:27:06,960
just coincides with statistical physics

690
00:27:06,960 --> 00:27:08,480
and this is where this framework has its

691
00:27:08,480 --> 00:27:11,640
name from but you see that it's a all is

692
00:27:11,640 --> 00:27:13,159
probabilistic here so essentially you

693
00:27:13,159 --> 00:27:15,240
have two probability functions Q for the

694
00:27:15,240 --> 00:27:17,320
internal model and P for this

695
00:27:17,320 --> 00:27:19,640
interaction between uh States and

696
00:27:19,640 --> 00:27:22,120
observations and you have here uh a

697
00:27:22,120 --> 00:27:24,279
distance measure between them that you

698
00:27:24,279 --> 00:27:25,200
want to

699
00:27:25,200 --> 00:27:27,799
minimize so now if we look at the neuron

700
00:27:27,799 --> 00:27:29,640
and the signups and how they interact

701
00:27:29,640 --> 00:27:31,520
with each other we find a very similar

702
00:27:31,520 --> 00:27:35,440
picture so single signups um which we

703
00:27:35,440 --> 00:27:38,520
have here in green has um an inter

704
00:27:38,520 --> 00:27:41,120
internal state which we for Simplicity

705
00:27:41,120 --> 00:27:45,080
model only uh as the synoptic bait based

706
00:27:45,080 --> 00:27:46,960
on this the signups when it's triggered

707
00:27:46,960 --> 00:27:50,799
by a preoptic spike it would generate um

708
00:27:50,799 --> 00:27:53,200
a post synoptic current this would then

709
00:27:53,200 --> 00:27:56,320
propagate to the Som which is our uh

710
00:27:56,320 --> 00:27:57,760
external state which we can cannot

711
00:27:57,760 --> 00:27:59,799
directly observe because it's too far

712
00:27:59,799 --> 00:28:02,640
away from the cups but we can see a

713
00:28:02,640 --> 00:28:04,279
feedback which is this spe propagating

714
00:28:04,279 --> 00:28:05,880
action potential which is this binary

715
00:28:05,880 --> 00:28:07,200
variable that tells us whether the

716
00:28:07,200 --> 00:28:09,840
neuron has spiked or not so this is

717
00:28:09,840 --> 00:28:12,120
exactly the same framework if you if we

718
00:28:12,120 --> 00:28:13,679
write it down like that and we can just

719
00:28:13,679 --> 00:28:18,200
use the same mathematics to solve it um

720
00:28:18,200 --> 00:28:21,159
so to to solve it we only have to come

721
00:28:21,159 --> 00:28:24,320
up with a couple of of um we have to

722
00:28:24,320 --> 00:28:25,960
make a couple of assumptions so we have

723
00:28:25,960 --> 00:28:28,279
to uh write down a model for this guy

724
00:28:28,279 --> 00:28:32,240
here so this uh model of how the uh

725
00:28:32,240 --> 00:28:35,880
feedback and the and the external State

726
00:28:35,880 --> 00:28:38,159
interact uh but we have very good models

727
00:28:38,159 --> 00:28:40,519
for this this has been studied over many

728
00:28:40,519 --> 00:28:43,120
years so here you see how typically a

729
00:28:43,120 --> 00:28:45,880
model neuron behaves so you have here um

730
00:28:45,880 --> 00:28:47,440
the membrane potential of a leaky

731
00:28:47,440 --> 00:28:49,120
integrated fire neuron and you see that

732
00:28:49,120 --> 00:28:51,159
this is just uh going up and down so

733
00:28:51,159 --> 00:28:53,720
this neuron would receive uh a lot of

734
00:28:53,720 --> 00:28:56,440
preoptic input and maybe also noise and

735
00:28:56,440 --> 00:28:57,679
eventually at some point it hits a

736
00:28:57,679 --> 00:28:59,640
threshold it would generate a spike so

737
00:28:59,640 --> 00:29:01,760
that would be the Z that travels to the

738
00:29:01,760 --> 00:29:04,279
downstream neurons and also back to the

739
00:29:04,279 --> 00:29:07,120
cups uh and then it

740
00:29:07,120 --> 00:29:12,159
resets uh right um but now this's uh so

741
00:29:12,159 --> 00:29:13,799
we can write this down mathematically is

742
00:29:13,799 --> 00:29:16,399
a very simple um differential equation

743
00:29:16,399 --> 00:29:19,039
but the uh neuron doesn't have access to

744
00:29:19,039 --> 00:29:21,360
this state again so it's again behind

745
00:29:21,360 --> 00:29:24,440
this wall it only sees this Spike events

746
00:29:24,440 --> 00:29:26,440
but we can actually for this simple case

747
00:29:26,440 --> 00:29:28,320
of really integrated F neuron we can

748
00:29:28,320 --> 00:29:30,399
solve this analytically so we can write

749
00:29:30,399 --> 00:29:32,240
down what is the posterior distribution

750
00:29:32,240 --> 00:29:34,559
of membrane potentials given the spike

751
00:29:34,559 --> 00:29:37,480
times and what uh comes out of this is

752
00:29:37,480 --> 00:29:40,240
actually a so-called um stochastic

753
00:29:40,240 --> 00:29:44,159
Bridge model or in this case of a uh of

754
00:29:44,159 --> 00:29:45,960
a leak integr in fire neuron it's an

755
00:29:45,960 --> 00:29:48,240
orang Bridge model so this can be

756
00:29:48,240 --> 00:29:51,200
written down analytically and this U I

757
00:29:51,200 --> 00:29:53,880
mean it's not simple but it's it's

758
00:29:53,880 --> 00:29:56,760
doable uh and we can then just use this

759
00:29:56,760 --> 00:29:59,799
directly so this model that we have uh

760
00:29:59,799 --> 00:30:02,279
to again write down this uh free energy

761
00:30:02,279 --> 00:30:04,440
functional so we make here an assumption

762
00:30:04,440 --> 00:30:06,600
how the signups actually produces post

763
00:30:06,600 --> 00:30:08,600
synoptic currents and how they're

764
00:30:08,600 --> 00:30:11,000
integrated in the in the neuron but

765
00:30:11,000 --> 00:30:12,840
that's also given by The Leaky

766
00:30:12,840 --> 00:30:14,799
integrated fire neuron and actually the

767
00:30:14,799 --> 00:30:17,760
stochastic um inputs that the signups

768
00:30:17,760 --> 00:30:20,120
generates so in this for Simplicity we

769
00:30:20,120 --> 00:30:22,919
only assume here basically gausian Sy

770
00:30:22,919 --> 00:30:25,559
upses that would inject draw a gausian

771
00:30:25,559 --> 00:30:27,960
random variable and inject this to inte

772
00:30:27,960 --> 00:30:30,399
great and fire neuron and then all these

773
00:30:30,399 --> 00:30:31,960
ingredients actually can be solved in

774
00:30:31,960 --> 00:30:33,640
closed form and we can derive learning

775
00:30:33,640 --> 00:30:35,720
rules that would minimize this pre

776
00:30:35,720 --> 00:30:37,640
energy functional

777
00:30:37,640 --> 00:30:40,720
now uh and if we do that

778
00:30:40,720 --> 00:30:44,279
um uh this has a bunch of nice

779
00:30:44,279 --> 00:30:46,279
properties because this Onin lbeck

780
00:30:46,279 --> 00:30:48,480
bridge is completely determined by the

781
00:30:48,480 --> 00:30:51,480
preent uh by the back propagating Action

782
00:30:51,480 --> 00:30:54,480
potentials so basically the times of the

783
00:30:54,480 --> 00:30:57,000
post synoptic um spikes that arrive at

784
00:30:57,000 --> 00:30:57,310
the

785
00:30:57,310 --> 00:30:58,519
[Music]

786
00:30:58,519 --> 00:31:01,760
neuron um this shape that we get here

787
00:31:01,760 --> 00:31:03,440
only depends on two neighboring

788
00:31:03,440 --> 00:31:04,760
postoptic

789
00:31:04,760 --> 00:31:08,519
spikes um which means that we get here

790
00:31:08,519 --> 00:31:10,720
automatically uh a learning rule that

791
00:31:10,720 --> 00:31:12,880
looks like this so learning rule that

792
00:31:12,880 --> 00:31:15,480
only depends on the difference between

793
00:31:15,480 --> 00:31:17,320
two postoptic spikes which we call here

794
00:31:17,320 --> 00:31:18,159
Delta

795
00:31:18,159 --> 00:31:22,960
T2 um and uh the difference between the

796
00:31:22,960 --> 00:31:25,159
post synoptic Spike and the actual input

797
00:31:25,159 --> 00:31:27,240
that is triggered at some point uh on

798
00:31:27,240 --> 00:31:29,120
the preoptic

799
00:31:29,120 --> 00:31:32,720
side uh and we can basically make here

800
00:31:32,720 --> 00:31:35,919
this lookup table and just uh just

801
00:31:35,919 --> 00:31:38,200
compute what would be the update that

802
00:31:38,200 --> 00:31:40,960
these signups would need to make so that

803
00:31:40,960 --> 00:31:42,840
it learns optimally in terms of this

804
00:31:42,840 --> 00:31:44,760
free energy principle and this is the

805
00:31:44,760 --> 00:31:46,279
shape that we get out you see that there

806
00:31:46,279 --> 00:31:47,679
is a strong dependence on the post

807
00:31:47,679 --> 00:31:49,440
synoptic firing rate but there's also a

808
00:31:49,440 --> 00:31:52,720
dependence on basically this typical STP

809
00:31:52,720 --> 00:31:55,880
that Sarah mentioned before uh what is

810
00:31:55,880 --> 00:31:57,639
the relative positioning of of the pre

811
00:31:57,639 --> 00:31:59,080
and postoptic

812
00:31:59,080 --> 00:32:02,440
Spike so in a nutshell this model can

813
00:32:02,440 --> 00:32:04,760
now be split into essentially two

814
00:32:04,760 --> 00:32:08,279
Pathways so we have this atoc response

815
00:32:08,279 --> 00:32:11,000
which basically just whenever there is a

816
00:32:11,000 --> 00:32:13,880
preoptic spike that triggers an action

817
00:32:13,880 --> 00:32:16,080
in the cups he would draw from this

818
00:32:16,080 --> 00:32:18,039
scussion distribution and inject it into

819
00:32:18,039 --> 00:32:21,799
the um into the neuron and then there is

820
00:32:21,799 --> 00:32:22,880
this postt

821
00:32:22,880 --> 00:32:25,480
talk uh update where we where the

822
00:32:25,480 --> 00:32:28,720
signups would look up um in this orang

823
00:32:28,720 --> 00:32:30,360
and wenck Bridge what would have been

824
00:32:30,360 --> 00:32:33,600
the optimal um output that it should

825
00:32:33,600 --> 00:32:35,679
have generated so what would have been

826
00:32:35,679 --> 00:32:38,559
the optimal action and then it compares

827
00:32:38,559 --> 00:32:40,320
the actual action with this optimal

828
00:32:40,320 --> 00:32:41,880
action according to this free energy

829
00:32:41,880 --> 00:32:44,880
principle and then generates a delayed

830
00:32:44,880 --> 00:32:47,360
response response which is an update of

831
00:32:47,360 --> 00:32:49,399
the synoptic

832
00:32:49,399 --> 00:32:52,159
weight okay and importantly this uh

833
00:32:52,159 --> 00:32:54,519
internal model is only implicit it's

834
00:32:54,519 --> 00:32:57,960
encoded so to say into this um uh Spike

835
00:32:57,960 --> 00:33:00,399
time dependent plasticity

836
00:33:00,399 --> 00:33:02,880
rule uh so how do these rules then look

837
00:33:02,880 --> 00:33:04,639
and do they compare to how do they

838
00:33:04,639 --> 00:33:07,360
compare to biology and uh actually they

839
00:33:07,360 --> 00:33:09,240
the fit is quite nicely given that this

840
00:33:09,240 --> 00:33:11,519
is derived really from first principles

841
00:33:11,519 --> 00:33:13,880
without making any assumptions so this

842
00:33:13,880 --> 00:33:16,320
is the measurement in biology this is

843
00:33:16,320 --> 00:33:20,279
this um B at Al rule B and po very old

844
00:33:20,279 --> 00:33:23,279
work where they actually did this in uh

845
00:33:23,279 --> 00:33:26,519
in vro studies where they measured the

846
00:33:26,519 --> 00:33:29,120
injected pre and post synoptic um spikes

847
00:33:29,120 --> 00:33:30,880
and then they measured what is the

848
00:33:30,880 --> 00:33:32,679
weight change in the cops and this is

849
00:33:32,679 --> 00:33:35,320
the rule that is predicted by our uh

850
00:33:35,320 --> 00:33:37,799
model and you see that it at least in a

851
00:33:37,799 --> 00:33:39,559
first order approximation it gives us

852
00:33:39,559 --> 00:33:42,080
very similar shapes and this also makes

853
00:33:42,080 --> 00:33:43,519
sense because

854
00:33:43,519 --> 00:33:48,120
um the the signups wants to um change

855
00:33:48,120 --> 00:33:51,840
the most when it's close to a uh close

856
00:33:51,840 --> 00:33:54,559
to the pre and postoptic Spike times

857
00:33:54,559 --> 00:33:56,039
because this is where or or the

858
00:33:56,039 --> 00:33:57,919
postoptic spike times because this is

859
00:33:57,919 --> 00:34:00,240
where it knows the most about the state

860
00:34:00,240 --> 00:34:02,159
of the PO neuron the free energy

861
00:34:02,159 --> 00:34:05,600
principle would actually suggest uh this

862
00:34:05,600 --> 00:34:07,639
kind of cones

863
00:34:07,639 --> 00:34:11,359
U um with almost no assumption

864
00:34:11,359 --> 00:34:14,199
essentially but uh we also get because

865
00:34:14,199 --> 00:34:17,719
we have a not just the first order uh

866
00:34:17,719 --> 00:34:20,199
Spike time dependent plasticity rule but

867
00:34:20,199 --> 00:34:21,480
uh we also have this dependency on the

868
00:34:21,480 --> 00:34:24,119
postop firing rate we can also compare

869
00:34:24,119 --> 00:34:26,280
this to other results and this here is

870
00:34:26,280 --> 00:34:29,119
this old by gr and Brunel so this is

871
00:34:29,119 --> 00:34:31,159
actually a model but that was very

872
00:34:31,159 --> 00:34:35,839
detailed um describing the um the uh

873
00:34:35,839 --> 00:34:37,679
plasticity based on the pre and

874
00:34:37,679 --> 00:34:41,280
postoptic firing rate in uh in a signups

875
00:34:41,280 --> 00:34:42,960
and this is what our model predicts so

876
00:34:42,960 --> 00:34:44,639
if we inject random pre and post

877
00:34:44,639 --> 00:34:47,359
synoptic popik tra uh trains with

878
00:34:47,359 --> 00:34:50,040
different rates our model would predict

879
00:34:50,040 --> 00:34:52,639
this shape which again is not a perfect

880
00:34:52,639 --> 00:34:55,440
match but given that this is a u very

881
00:34:55,440 --> 00:34:58,359
idealistic model it's actually least the

882
00:34:58,359 --> 00:35:01,880
the main features that uh low firing

883
00:35:01,880 --> 00:35:04,160
rates on the postoptic side would lead

884
00:35:04,160 --> 00:35:07,560
to depression and higher to potentiation

885
00:35:07,560 --> 00:35:10,440
um are reflected in

886
00:35:10,440 --> 00:35:14,240
this okay uh I I assume I still have 10

887
00:35:14,240 --> 00:35:19,520
minutes right okay so I would um give a

888
00:35:19,520 --> 00:35:21,320
quick intermediate summary and then I

889
00:35:21,320 --> 00:35:23,400
want to show some other work where we

890
00:35:23,400 --> 00:35:27,320
actually apply this now to um to actual

891
00:35:27,320 --> 00:35:29,040
machine learning

892
00:35:29,040 --> 00:35:32,440
model um so what we have seen here is

893
00:35:32,440 --> 00:35:36,760
that um Sy upses are actually um are

894
00:35:36,760 --> 00:35:39,240
very stochastic and it was a very this

895
00:35:39,240 --> 00:35:42,599
was a big puzzle and we suggests that

896
00:35:42,599 --> 00:35:44,160
actually the

897
00:35:44,160 --> 00:35:47,680
um uh that the the synaptic noise is

898
00:35:47,680 --> 00:35:50,920
actually the signups is way of um

899
00:35:50,920 --> 00:35:52,640
reporting its own uncertainty about the

900
00:35:52,640 --> 00:35:54,079
environment where the environment is

901
00:35:54,079 --> 00:35:57,560
actually the um the POS synoptic neuron

902
00:35:57,560 --> 00:36:00,119
and it really interacts in this fashion

903
00:36:00,119 --> 00:36:02,160
of the free energy principle with this

904
00:36:02,160 --> 00:36:03,880
post synoptic neuron or that's a very

905
00:36:03,880 --> 00:36:06,720
nice way of describing it and uh if

906
00:36:06,720 --> 00:36:09,400
you're interested more there's a a paper

907
00:36:09,400 --> 00:36:13,480
a pre-print out you can read up on all

908
00:36:13,480 --> 00:36:16,359
this okay um so how does this now

909
00:36:16,359 --> 00:36:19,440
connect to neuromorphics and actually so

910
00:36:19,440 --> 00:36:21,160
we are not actually doing neuromorphic

911
00:36:21,160 --> 00:36:23,400
Hardware we are doing doing neuromorphic

912
00:36:23,400 --> 00:36:25,920
algorithms so we try to to bring these

913
00:36:25,920 --> 00:36:27,480
Inspirations now into actual machine

914
00:36:27,480 --> 00:36:30,319
learning models and we thought that this

915
00:36:30,319 --> 00:36:33,920
might be a good um attack angle to um

916
00:36:33,920 --> 00:36:35,599
solve a problem that is well known in

917
00:36:35,599 --> 00:36:40,880
machine learning so I I just um uh yeah

918
00:36:40,880 --> 00:36:43,640
Drew here a very simple um convolutional

919
00:36:43,640 --> 00:36:45,440
neur networks with various convolutional

920
00:36:45,440 --> 00:36:48,079
layers and then maybe some dense layers

921
00:36:48,079 --> 00:36:49,839
that you would have in your machine

922
00:36:49,839 --> 00:36:52,760
learning algorithm and the way this is

923
00:36:52,760 --> 00:36:54,599
trained as many of you know I guess is

924
00:36:54,599 --> 00:36:57,400
through um end to endend and arrowback

925
00:36:57,400 --> 00:36:59,480
propagation so the idea is that you have

926
00:36:59,480 --> 00:37:02,119
a training set which has inputs and uh

927
00:37:02,119 --> 00:37:04,079
targets so for example in a

928
00:37:04,079 --> 00:37:06,920
classification task this could be uh

929
00:37:06,920 --> 00:37:08,680
pictures of cats and dogs and you would

930
00:37:08,680 --> 00:37:12,440
have targets which are U class labels so

931
00:37:12,440 --> 00:37:15,160
to say so some there's there's actually

932
00:37:15,160 --> 00:37:17,119
artificial neurons in there and some one

933
00:37:17,119 --> 00:37:18,640
of these neuron may be active for cats

934
00:37:18,640 --> 00:37:20,240
and one may be active for

935
00:37:20,240 --> 00:37:23,440
dogs um and in your training that data

936
00:37:23,440 --> 00:37:25,400
you have exactly these labels um that

937
00:37:25,400 --> 00:37:27,119
were generated by human that were

938
00:37:27,119 --> 00:37:29,319
sitting down doing this by hand and then

939
00:37:29,319 --> 00:37:32,119
during training you show this examples

940
00:37:32,119 --> 00:37:34,520
to the network by propagating this

941
00:37:34,520 --> 00:37:37,040
inputs uh all the way from the input

942
00:37:37,040 --> 00:37:39,760
layer to the output layer then the

943
00:37:39,760 --> 00:37:42,560
output is here compared to the uh to

944
00:37:42,560 --> 00:37:44,960
these hand label targets and then the

945
00:37:44,960 --> 00:37:47,000
mismatch between the two is back

946
00:37:47,000 --> 00:37:48,839
propagated through all these layers back

947
00:37:48,839 --> 00:37:52,000
to the input and all the weights or the

948
00:37:52,000 --> 00:37:54,720
synoptic weights that are here uh in

949
00:37:54,720 --> 00:37:57,160
between uh inside this layer

950
00:37:57,160 --> 00:37:58,960
would then be updated accordingly so

951
00:37:58,960 --> 00:38:01,560
that after doing this many many times uh

952
00:38:01,560 --> 00:38:03,920
this network becomes good in telling a

953
00:38:03,920 --> 00:38:05,560
part C

954
00:38:05,560 --> 00:38:08,520
dos so this has a problem this this

955
00:38:08,520 --> 00:38:10,359
algorithm it works great in practice and

956
00:38:10,359 --> 00:38:12,960
it's it's the foundation of all these

957
00:38:12,960 --> 00:38:15,480
models we have talked about like D or J

958
00:38:15,480 --> 00:38:18,520
gbt but it is quite inefficient and the

959
00:38:18,520 --> 00:38:20,280
problem is this what is known in the

960
00:38:20,280 --> 00:38:22,880
literature as the Locking problem so if

961
00:38:22,880 --> 00:38:25,480
you would split up this network now into

962
00:38:25,480 --> 00:38:27,560
blocks which I already did before but

963
00:38:27,560 --> 00:38:30,839
this is arbitrary but for for

964
00:38:30,839 --> 00:38:32,400
implementing this efficiently in terms

965
00:38:32,400 --> 00:38:34,000
of a software algorithm it might be

966
00:38:34,000 --> 00:38:36,520
interesting to do that and now you would

967
00:38:36,520 --> 00:38:39,160
want these blocks ideally to to run in

968
00:38:39,160 --> 00:38:41,560
parallel so that you can basically uh

969
00:38:41,560 --> 00:38:44,359
show the first example and uh on this

970
00:38:44,359 --> 00:38:46,440
first block and then already train it

971
00:38:46,440 --> 00:38:48,839
while the second um block is doing

972
00:38:48,839 --> 00:38:50,760
something else but this is not really

973
00:38:50,760 --> 00:38:52,800
possible with um end to end back

974
00:38:52,800 --> 00:38:54,440
propagation because of this locking

975
00:38:54,440 --> 00:38:57,200
problem because the activ ation of the

976
00:38:57,200 --> 00:38:58,800
second block depends on the activation

977
00:38:58,800 --> 00:39:00,319
of the first block so you have to

978
00:39:00,319 --> 00:39:02,720
propagate it all the way to the end then

979
00:39:02,720 --> 00:39:04,319
you compute this error and you would

980
00:39:04,319 --> 00:39:06,680
then back propagate and only when this

981
00:39:06,680 --> 00:39:09,520
is done uh you can start the next Epoch

982
00:39:09,520 --> 00:39:14,359
where you show a new bunch of um of

983
00:39:14,359 --> 00:39:17,040
examples uh and you see that during all

984
00:39:17,040 --> 00:39:20,319
this time here the the threet that would

985
00:39:20,319 --> 00:39:23,319
run this first block maybe uh would be

986
00:39:23,319 --> 00:39:25,520
idle and has to wait essentially all the

987
00:39:25,520 --> 00:39:28,079
time and this obviously makes them very

988
00:39:28,079 --> 00:39:30,040
inefficient and now I our idea was that

989
00:39:30,040 --> 00:39:33,000
we use basically uh what we had learned

990
00:39:33,000 --> 00:39:36,680
from this earlier model on um on how

991
00:39:36,680 --> 00:39:39,440
sign upses communicate over these long

992
00:39:39,440 --> 00:39:42,079
distances for this free energy principle

993
00:39:42,079 --> 00:39:43,920
and also apply it just to a deep neuron

994
00:39:43,920 --> 00:39:46,200
Network and the ideas that you have here

995
00:39:46,200 --> 00:39:49,040
again this basically you have already

996
00:39:49,040 --> 00:39:50,880
this

997
00:39:50,880 --> 00:39:54,800
um this generation of inputs to some

998
00:39:54,800 --> 00:39:57,960
output but what what is missing to make

999
00:39:57,960 --> 00:39:59,440
it applicable to the free energy

1000
00:39:59,440 --> 00:40:01,359
principle is this feedback that you

1001
00:40:01,359 --> 00:40:03,920
always need the idea was that we put

1002
00:40:03,920 --> 00:40:06,960
here very lightweight um uh feedback

1003
00:40:06,960 --> 00:40:09,480
Network so essentially each of these

1004
00:40:09,480 --> 00:40:11,800
blocks now in this deep neural network

1005
00:40:11,800 --> 00:40:15,319
would uh be accompanied by a feedback

1006
00:40:15,319 --> 00:40:18,520
block uh that locally generates a Target

1007
00:40:18,520 --> 00:40:20,240
so we used to really in the simplest

1008
00:40:20,240 --> 00:40:21,760
case which we have so this is very

1009
00:40:21,760 --> 00:40:24,640
recent work we only used linear blocks

1010
00:40:24,640 --> 00:40:27,480
so far so these are single linear layers

1011
00:40:27,480 --> 00:40:29,160
and we would generate now these these

1012
00:40:29,160 --> 00:40:32,040
outputs here in these feedback blocks

1013
00:40:32,040 --> 00:40:34,040
and then use the free energy principle

1014
00:40:34,040 --> 00:40:38,119
to derve um uh a local loss that allows

1015
00:40:38,119 --> 00:40:40,920
us again to minimize both these uh

1016
00:40:40,920 --> 00:40:43,000
feedback weights that we have here and

1017
00:40:43,000 --> 00:40:45,119
also the weights in the forward

1018
00:40:45,119 --> 00:40:48,079
Network um so it's essentially the same

1019
00:40:48,079 --> 00:40:49,960
idea so we have here these outputs which

1020
00:40:49,960 --> 00:40:52,960
we interpret now as a parameters to a

1021
00:40:52,960 --> 00:40:54,800
probability function so we can apply

1022
00:40:54,800 --> 00:40:57,240
this probabilistic framework

1023
00:40:57,240 --> 00:40:59,040
uh but now the all the rest basically

1024
00:40:59,040 --> 00:41:01,359
rolls out the same way so we uh assume

1025
00:41:01,359 --> 00:41:04,040
that these outputs are essentially um

1026
00:41:04,040 --> 00:41:06,599
the internal states of this model and we

1027
00:41:06,599 --> 00:41:10,480
have this um uh this observations given

1028
00:41:10,480 --> 00:41:14,000
in the uh inputs and and the targets and

1029
00:41:14,000 --> 00:41:17,880
now we try to minimize basically uh P

1030
00:41:17,880 --> 00:41:19,640
would now be this feed forward Network

1031
00:41:19,640 --> 00:41:23,480
and Q would be now a function that uh

1032
00:41:23,480 --> 00:41:26,319
contains um features of both the

1033
00:41:26,319 --> 00:41:31,119
feedback and the uh and the feed forward

1034
00:41:31,119 --> 00:41:33,880
Network and the nice thing is that if we

1035
00:41:33,880 --> 00:41:36,160
um uh I don't have time to go into to

1036
00:41:36,160 --> 00:41:38,880
the details now but if you write this

1037
00:41:38,880 --> 00:41:43,200
out you see that um this actually uh

1038
00:41:43,200 --> 00:41:45,079
decomposes this lock term here

1039
00:41:45,079 --> 00:41:49,200
decomposes into local linear terms that

1040
00:41:49,200 --> 00:41:50,920
give you these local losses here so

1041
00:41:50,920 --> 00:41:52,960
essentially that you can minimize here

1042
00:41:52,960 --> 00:41:55,520
block local between B and the

1043
00:41:55,520 --> 00:41:59,560
corresponding feedback block um a loss

1044
00:41:59,560 --> 00:42:01,839
function and you can then actually do

1045
00:42:01,839 --> 00:42:05,680
this in parallel so because uh maybe the

1046
00:42:05,680 --> 00:42:07,800
picture is good to see here so what you

1047
00:42:07,800 --> 00:42:09,000
have to do now you have a bit of

1048
00:42:09,000 --> 00:42:10,720
overhead because you have this feedback

1049
00:42:10,720 --> 00:42:15,200
block so this would be the two uh uh

1050
00:42:15,200 --> 00:42:18,359
execution times of the uh feed forward

1051
00:42:18,359 --> 00:42:20,160
block and the feedback

1052
00:42:20,160 --> 00:42:23,359
block but in principle they can run in

1053
00:42:23,359 --> 00:42:25,920
parallel uh and once the forward block

1054
00:42:25,920 --> 00:42:28,400
is done the next forward block can start

1055
00:42:28,400 --> 00:42:30,079
propagating through this

1056
00:42:30,079 --> 00:42:33,079
network um but simultaneously already

1057
00:42:33,079 --> 00:42:34,880
the forward block because it already

1058
00:42:34,880 --> 00:42:37,880
received a Target here can start uh

1059
00:42:37,880 --> 00:42:40,520
updating the weights and when it's done

1060
00:42:40,520 --> 00:42:43,119
it's free to operate on the next Epoch

1061
00:42:43,119 --> 00:42:45,760
so there is no locking anymore in this

1062
00:42:45,760 --> 00:42:48,040
in this

1063
00:42:48,040 --> 00:42:50,880
framework okay so I'm pretty much done

1064
00:42:50,880 --> 00:42:53,119
I'm also out of time I think so how does

1065
00:42:53,119 --> 00:42:55,359
this perform of course we changed the

1066
00:42:55,359 --> 00:42:56,720
the learning algorithm now we have to

1067
00:42:56,720 --> 00:42:59,720
also go back and see if this is uh

1068
00:42:59,720 --> 00:43:03,280
still uh giving us the same performance

1069
00:43:03,280 --> 00:43:06,480
and actually for um so this as I said is

1070
00:43:06,480 --> 00:43:09,400
this is the first um results we have

1071
00:43:09,400 --> 00:43:15,559
here now and at least to um midscale uh

1072
00:43:15,559 --> 00:43:18,280
data sets like Cypher 10 or so this

1073
00:43:18,280 --> 00:43:20,440
seems to actually uh perform very well

1074
00:43:20,440 --> 00:43:22,160
so we are tried it for for standard

1075
00:43:22,160 --> 00:43:24,559
architectures fashion mnist with reset

1076
00:43:24,559 --> 00:43:29,880
15 and res 18 we worked mostly so far uh

1077
00:43:29,880 --> 00:43:32,160
for like small data sets like fashion

1078
00:43:32,160 --> 00:43:35,160
amist we we've applying free splits to

1079
00:43:35,160 --> 00:43:37,640
reset 50 we get basically the same

1080
00:43:37,640 --> 00:43:40,040
performance as standard backrop as

1081
00:43:40,040 --> 00:43:42,680
networks get deeper uh you see that

1082
00:43:42,680 --> 00:43:44,880
there's actually um the our problem that

1083
00:43:44,880 --> 00:43:47,079
we have now is actually overfitting

1084
00:43:47,079 --> 00:43:48,599
because we have these local targets it

1085
00:43:48,599 --> 00:43:50,280
seems that these smaller blocks actually

1086
00:43:50,280 --> 00:43:53,079
overfit to some extent this is not so

1087
00:43:53,079 --> 00:43:55,800
severe for still up to tasks like Cypher

1088
00:43:55,800 --> 00:43:58,839
t so we get quite close already but if

1089
00:43:58,839 --> 00:44:01,520
you go now for really large tasks um

1090
00:44:01,520 --> 00:44:04,480
there's still something missing we are

1091
00:44:04,480 --> 00:44:06,839
uh for for like single splits we're

1092
00:44:06,839 --> 00:44:09,000
getting there but we're not reaching all

1093
00:44:09,000 --> 00:44:11,559
the way up to back propagation but it's

1094
00:44:11,559 --> 00:44:13,119
still interesting to see that you can

1095
00:44:13,119 --> 00:44:18,240
apply this um this principle also uh to

1096
00:44:18,240 --> 00:44:21,160
this standard machine learning

1097
00:44:21,160 --> 00:44:23,599
algorithms okay this is my second

1098
00:44:23,599 --> 00:44:26,240
summary so actually we found that um

1099
00:44:26,240 --> 00:44:28,040
deep Nur networks are surprisingly good

1100
00:44:28,040 --> 00:44:31,720
in generalizing over probability spaces

1101
00:44:31,720 --> 00:44:33,839
this is how actually this work

1102
00:44:33,839 --> 00:44:36,760
started um and we we our idea was to

1103
00:44:36,760 --> 00:44:39,920
exploit this um and to utilize it for to

1104
00:44:39,920 --> 00:44:41,680
distribute learning in the in the same

1105
00:44:41,680 --> 00:44:44,040
fashion as um in the first project I

1106
00:44:44,040 --> 00:44:48,000
showed you um and to solve this credit

1107
00:44:48,000 --> 00:44:50,359
assignment Problem by generating these

1108
00:44:50,359 --> 00:44:52,160
feedback

1109
00:44:52,160 --> 00:44:55,760
networks um yeah that's basically it and

1110
00:44:55,760 --> 00:44:58,680
then um I want to acknowledge my my

1111
00:44:58,680 --> 00:45:01,000
co-workers and my students so I have two

1112
00:45:01,000 --> 00:45:05,480
very good um um PhD students KH and

1113
00:45:05,480 --> 00:45:08,400
cabel who is now here in in bom and

1114
00:45:08,400 --> 00:45:11,680
works um on this topic and I the first

1115
00:45:11,680 --> 00:45:14,760
um project I showed was B I did together

1116
00:45:14,760 --> 00:45:17,640
when I was in gutan with Christian TL

1117
00:45:17,640 --> 00:45:20,559
and uh this project the second project

1118
00:45:20,559 --> 00:45:22,800
is I work I worked closely with

1119
00:45:22,800 --> 00:45:24,880
Christian mea and Anan

1120
00:45:24,880 --> 00:45:26,599
supron

1121
00:45:26,599 --> 00:45:29,760
and yeah thank

1122
00:45:30,520 --> 00:45:32,920
you thank you very much David that was

1123
00:45:32,920 --> 00:45:35,040
absolutely fascinating I think it's

1124
00:45:35,040 --> 00:45:37,559
incredible how closely the sort of model

1125
00:45:37,559 --> 00:45:39,599
matched biology like considering you

1126
00:45:39,599 --> 00:45:41,359
derived it from first principles I think

1127
00:45:41,359 --> 00:45:43,760
that was really cool um I did have a

1128
00:45:43,760 --> 00:45:45,800
question just about the the last sort of

1129
00:45:45,800 --> 00:45:47,720
the bit you spoke about the

1130
00:45:47,720 --> 00:45:49,760
convolutional network and you know you

1131
00:45:49,760 --> 00:45:51,079
said traditionally has to go all the way

1132
00:45:51,079 --> 00:45:53,400
end to end which is really inefficient

1133
00:45:53,400 --> 00:45:54,960
and then you showed the results that you

1134
00:45:54,960 --> 00:45:57,240
got did you look at energy consumption

1135
00:45:57,240 --> 00:46:00,839
with with yours as well uh not yet so we

1136
00:46:00,839 --> 00:46:02,520
have uh we are actually currently

1137
00:46:02,520 --> 00:46:06,760
working on a so this um it's actually

1138
00:46:06,760 --> 00:46:09,040
not so easy to implement these things in

1139
00:46:09,040 --> 00:46:10,880
in standard machine learning uh

1140
00:46:10,880 --> 00:46:14,319
toolboxes we have a so Kal is currently

1141
00:46:14,319 --> 00:46:17,400
looking into this uh the PHD student in

1142
00:46:17,400 --> 00:46:20,160
Dron um he has an implementation now and

1143
00:46:20,160 --> 00:46:22,359
he's now evaluating

1144
00:46:22,359 --> 00:46:25,520
how uh how well we can make use of this

1145
00:46:25,520 --> 00:46:28,359
par ization in practice but we are

1146
00:46:28,359 --> 00:46:32,119
actually quite confident that this

1147
00:46:32,119 --> 00:46:36,640
um that's for paralyzing it uh it should

1148
00:46:36,640 --> 00:46:38,960
be there the question is how much you

1149
00:46:38,960 --> 00:46:41,400
save in terms of energy because um for

1150
00:46:41,400 --> 00:46:43,440
these smaller scale models that we use

1151
00:46:43,440 --> 00:46:47,720
now reset 18 reset 15 the the effect

1152
00:46:47,720 --> 00:46:50,319
might be not that huge so once we ramp

1153
00:46:50,319 --> 00:46:52,000
this up to really larger models the

1154
00:46:52,000 --> 00:46:54,400
effect should be bigger but yeah this is

1155
00:46:54,400 --> 00:46:56,480
ongoing work

1156
00:46:56,480 --> 00:46:58,920
very cool thank you um and then I was

1157
00:46:58,920 --> 00:47:00,760
just wondering as well like this this

1158
00:47:00,760 --> 00:47:03,119
local error back propagation is that

1159
00:47:03,119 --> 00:47:04,960
something that other people have tried

1160
00:47:04,960 --> 00:47:06,520
with these convolution neural networks

1161
00:47:06,520 --> 00:47:08,880
or is this quite a new way of of

1162
00:47:08,880 --> 00:47:11,680
implementing it uh there is a bunch of

1163
00:47:11,680 --> 00:47:14,280
approaches that do this so uh there is

1164
00:47:14,280 --> 00:47:16,000
for example I mean the closest I guess

1165
00:47:16,000 --> 00:47:18,040
is Target propagation which has been

1166
00:47:18,040 --> 00:47:20,440
proposed which essentially uses random

1167
00:47:20,440 --> 00:47:23,640
feedback weights uh to back propagate

1168
00:47:23,640 --> 00:47:25,359
here so these these guys would not be

1169
00:47:25,359 --> 00:47:27,720
trained

1170
00:47:28,000 --> 00:47:32,520
um and those as far as I know this works

1171
00:47:32,520 --> 00:47:35,559
this works nicely also for small scale

1172
00:47:35,559 --> 00:47:38,160
um uh problems but as far as I know they

1173
00:47:38,160 --> 00:47:40,280
don't perform that well even for for

1174
00:47:40,280 --> 00:47:42,319
Cipher 10 they they it already starts

1175
00:47:42,319 --> 00:47:43,599
breaking down because these random

1176
00:47:43,599 --> 00:47:46,160
feedback weights are just too coarse an

1177
00:47:46,160 --> 00:47:48,559
approximation I think and this is the

1178
00:47:48,559 --> 00:47:52,760
first um okay maybe I have to be careful

1179
00:47:52,760 --> 00:47:56,079
I think this is the first um method that

1180
00:47:56,079 --> 00:47:58,240
allows you to train this feedback

1181
00:47:58,240 --> 00:48:01,200
weights that is not a contrastive method

1182
00:48:01,200 --> 00:48:03,079
so there's a bunch of methods that use a

1183
00:48:03,079 --> 00:48:05,559
contrastive step

1184
00:48:05,559 --> 00:48:08,040
um so you have maybe seen this forward

1185
00:48:08,040 --> 00:48:10,800
forward algorithm and and all these

1186
00:48:10,800 --> 00:48:13,040
things but what they have to do always

1187
00:48:13,040 --> 00:48:14,830
is they send in

1188
00:48:14,830 --> 00:48:16,160
[Music]

1189
00:48:16,160 --> 00:48:19,319
uh uh they send in the actual input data

1190
00:48:19,319 --> 00:48:22,480
and then they send an kind of anti-

1191
00:48:22,480 --> 00:48:26,520
input so an anti- input that is uh

1192
00:48:26,520 --> 00:48:29,000
usually generated artificially so they

1193
00:48:29,000 --> 00:48:31,040
do some Distortion to the input to make

1194
00:48:31,040 --> 00:48:33,839
it uh and then they train the they have

1195
00:48:33,839 --> 00:48:36,960
to use both informations locally uh to

1196
00:48:36,960 --> 00:48:38,640
do the update so the network has to keep

1197
00:48:38,640 --> 00:48:41,440
in memory uh the input and the anti

1198
00:48:41,440 --> 00:48:44,440
input and the the responses and this

1199
00:48:44,440 --> 00:48:48,200
makes um this makes this approaches a

1200
00:48:48,200 --> 00:48:50,880
bit harder to parallelize in this and

1201
00:48:50,880 --> 00:48:54,280
the nice thing here is that we derive an

1202
00:48:54,280 --> 00:48:57,440
uh an upper bound to this uh variational

1203
00:48:57,440 --> 00:49:00,960
free energy loss that can be spelled out

1204
00:49:00,960 --> 00:49:03,680
completely by forward propagation and

1205
00:49:03,680 --> 00:49:05,960
that I think is new so that is the the

1206
00:49:05,960 --> 00:49:08,480
new bit of of this

1207
00:49:08,480 --> 00:49:11,550
[Music]

1208
00:49:11,680 --> 00:49:15,520
very that's

1209
00:49:15,720 --> 00:49:19,720
awesome well yeah few few comments one

1210
00:49:19,720 --> 00:49:21,640
piece that kind of between the two of

1211
00:49:21,640 --> 00:49:24,280
your talks that was at least a new

1212
00:49:24,280 --> 00:49:25,880
distinction to me which was is the

1213
00:49:25,880 --> 00:49:27,319
difference between the neuromorphic

1214
00:49:27,319 --> 00:49:29,920
hardware and the neuromorphic

1215
00:49:29,920 --> 00:49:33,640
algorithms so it's not just about new

1216
00:49:33,640 --> 00:49:35,520
hardware or

1217
00:49:35,520 --> 00:49:39,240
wetwear though that would be great to

1218
00:49:39,240 --> 00:49:40,760
see it's almost like there's this

1219
00:49:40,760 --> 00:49:45,839
intermediate or a bridge step with using

1220
00:49:45,839 --> 00:49:47,599
the

1221
00:49:47,599 --> 00:49:51,440
algorithms on the hardware we have

1222
00:49:51,440 --> 00:49:54,160
today that like Sarah mentioned the

1223
00:49:54,160 --> 00:49:56,240
spiking neural networks which are

1224
00:49:56,240 --> 00:49:59,880
amenable to gpus or just using

1225
00:49:59,880 --> 00:50:04,079
standardized um CPU multicore scheduling

1226
00:50:04,079 --> 00:50:07,000
approaches you can already do

1227
00:50:07,000 --> 00:50:09,799
more with what we

1228
00:50:09,799 --> 00:50:13,559
have using the neuromorphic algorithms

1229
00:50:13,559 --> 00:50:18,640
so it's not just um a material science

1230
00:50:18,640 --> 00:50:22,040
topic but also there's a lot at the

1231
00:50:22,040 --> 00:50:24,640
really micro scale that we can learn

1232
00:50:24,640 --> 00:50:26,920
related to noise processing scheduling

1233
00:50:26,920 --> 00:50:28,599
and then also even at higher levels of

1234
00:50:28,599 --> 00:50:30,559
abstraction probably learning from

1235
00:50:30,559 --> 00:50:32,720
biomimicry and cognitive systems more

1236
00:50:32,720 --> 00:50:34,839
generally but that was like that was a

1237
00:50:34,839 --> 00:50:37,240
distinction for

1238
00:50:37,240 --> 00:50:40,839
me yeah so maybe to to add um yeah so I

1239
00:50:40,839 --> 00:50:43,720
think that the problem becomes really

1240
00:50:43,720 --> 00:50:46,640
now more pressing as these uh

1241
00:50:46,640 --> 00:50:49,000
neuromorphic uh devices become Al the

1242
00:50:49,000 --> 00:50:51,119
hardware devices become more

1243
00:50:51,119 --> 00:50:53,839
mature and they usually cannot really

1244
00:50:53,839 --> 00:50:57,520
shine on this uh on these standard

1245
00:50:57,520 --> 00:50:59,119
machine learning algorithms because they

1246
00:50:59,119 --> 00:51:01,280
are really optimized for for

1247
00:51:01,280 --> 00:51:04,319
gpus so you need to think a little bit

1248
00:51:04,319 --> 00:51:06,079
so you have to take one step back and

1249
00:51:06,079 --> 00:51:08,680
think again about the algorithmic side

1250
00:51:08,680 --> 00:51:11,960
um to to really use them to to full

1251
00:51:11,960 --> 00:51:13,960
capacity and we also as you have seen

1252
00:51:13,960 --> 00:51:16,480
that we collaborate with um Professor

1253
00:51:16,480 --> 00:51:18,839
Maya who is doing this Spiner chip in

1254
00:51:18,839 --> 00:51:20,720
Dron but there's also other approaches

1255
00:51:20,720 --> 00:51:23,359
and like the L chip that Sarah mentioned

1256
00:51:23,359 --> 00:51:26,319
from Intel and so on um and they are

1257
00:51:26,319 --> 00:51:29,520
really looking into this now they also

1258
00:51:29,520 --> 00:51:31,960
from the algorithmic

1259
00:51:31,960 --> 00:51:34,520
side I I find it really useful it's kind

1260
00:51:34,520 --> 00:51:36,520
of like a mindset or a mental framework

1261
00:51:36,520 --> 00:51:38,839
when I'm thinking about computers or Ai

1262
00:51:38,839 --> 00:51:39,760
and I this is probably because I'm a

1263
00:51:39,760 --> 00:51:40,920
neuroscientist but I also have to

1264
00:51:40,920 --> 00:51:43,040
translate it to well how does the brain

1265
00:51:43,040 --> 00:51:44,680
work how does the information processing

1266
00:51:44,680 --> 00:51:46,880
work etc in the brain and and when I

1267
00:51:46,880 --> 00:51:48,480
came to sort of computer science and AI

1268
00:51:48,480 --> 00:51:49,920
after Neuroscience I found myself

1269
00:51:49,920 --> 00:51:51,720
naturally translating it but I feel like

1270
00:51:51,720 --> 00:51:53,760
the framework is is just a really useful

1271
00:51:53,760 --> 00:51:56,000
way of understanding comput at the end

1272
00:51:56,000 --> 00:51:57,319
of the day because our brains as I said

1273
00:51:57,319 --> 00:51:59,280
are just these massive supercomputers

1274
00:51:59,280 --> 00:52:01,079
and I'm constantly reading papers on

1275
00:52:01,079 --> 00:52:02,599
computer science or whatever and and

1276
00:52:02,599 --> 00:52:04,680
then once you you can conceptualize

1277
00:52:04,680 --> 00:52:07,520
anything really as well how close how

1278
00:52:07,520 --> 00:52:09,880
neuromorphic is this and then if you

1279
00:52:09,880 --> 00:52:11,440
start thinking about well how how could

1280
00:52:11,440 --> 00:52:12,520
you tweak it so it's slightly more

1281
00:52:12,520 --> 00:52:14,079
neuromorphic and is that then going to

1282
00:52:14,079 --> 00:52:15,839
give you these gains that we get with

1283
00:52:15,839 --> 00:52:17,040
the brain like is it going to give you

1284
00:52:17,040 --> 00:52:19,319
some like extra parallel computation or

1285
00:52:19,319 --> 00:52:20,559
is it going to give you some Energy

1286
00:52:20,559 --> 00:52:23,480
Efficiency so yeah I I find it NE like

1287
00:52:23,480 --> 00:52:24,599
the definitions when I was looking at

1288
00:52:24,599 --> 00:52:26,000
the definition is I think it really

1289
00:52:26,000 --> 00:52:27,520
depends your rights a definition and

1290
00:52:27,520 --> 00:52:30,079
because it's such a a dynamic area at

1291
00:52:30,079 --> 00:52:32,640
the moment as well um I think it's going

1292
00:52:32,640 --> 00:52:34,079
to be it has been changing and it will

1293
00:52:34,079 --> 00:52:35,559
be changing but for me I feel like

1294
00:52:35,559 --> 00:52:37,680
neuromorphic is more of a frame like a

1295
00:52:37,680 --> 00:52:39,559
mental framework where I look at things

1296
00:52:39,559 --> 00:52:42,240
through

1297
00:52:42,400 --> 00:52:44,119
conceptualize yeah I think it's it's

1298
00:52:44,119 --> 00:52:47,920
also not very well defined I mean uh in

1299
00:52:47,920 --> 00:52:50,319
you also mentioned that that actually

1300
00:52:50,319 --> 00:52:52,359
artificial neuron networks are a

1301
00:52:52,359 --> 00:52:54,880
neuromorphic uh concept if you want and

1302
00:52:54,880 --> 00:52:55,960
they were

1303
00:52:55,960 --> 00:52:58,119
from the first day and it's actually

1304
00:52:58,119 --> 00:53:00,160
it's a it's a big success story right if

1305
00:53:00,160 --> 00:53:02,400
you look into the 90s or so when these

1306
00:53:02,400 --> 00:53:04,960
support Vector machines and and these

1307
00:53:04,960 --> 00:53:08,200
these alternative models came up but

1308
00:53:08,200 --> 00:53:10,920
none of them have have outlived the the

1309
00:53:10,920 --> 00:53:13,440
new neuromorphic approaches so uh it's

1310
00:53:13,440 --> 00:53:14,880
actually very nice but still there is

1311
00:53:14,880 --> 00:53:17,040
this communic community that thinks that

1312
00:53:17,040 --> 00:53:19,119
there is more features from the brain

1313
00:53:19,119 --> 00:53:22,400
that you need to put in to uh to get get

1314
00:53:22,400 --> 00:53:23,599
to the real

1315
00:53:23,599 --> 00:53:26,960
thing yeah so I think this is a bit of a

1316
00:53:26,960 --> 00:53:30,799
it's not a very well defined term

1317
00:53:30,799 --> 00:53:33,040
actually and I think with your research

1318
00:53:33,040 --> 00:53:34,799
yours is almost like the smallest level

1319
00:53:34,799 --> 00:53:36,440
that I've seen people look at it on I

1320
00:53:36,440 --> 00:53:37,880
don't know if you've seen anything else

1321
00:53:37,880 --> 00:53:39,520
but we're not just talking about like a

1322
00:53:39,520 --> 00:53:41,400
cell level of of free energy and active

1323
00:53:41,400 --> 00:53:43,040
inference we're actually talking about

1324
00:53:43,040 --> 00:53:46,599
like a cell structure and then like so

1325
00:53:46,599 --> 00:53:48,319
then you think well how small does it go

1326
00:53:48,319 --> 00:53:49,960
are we going to talk about cell

1327
00:53:49,960 --> 00:53:51,559
subcellular structures you know

1328
00:53:51,559 --> 00:53:53,559
eventually like mitochondria using free

1329
00:53:53,559 --> 00:53:55,160
energy in a similar way with compound

1330
00:53:55,160 --> 00:53:56,760
compartments and yeah so I guess

1331
00:53:56,760 --> 00:53:57,920
actually' be interesting to get your

1332
00:53:57,920 --> 00:53:59,960
thoughts David on you know you talked at

1333
00:53:59,960 --> 00:54:02,520
the start about how sign upses are

1334
00:54:02,520 --> 00:54:05,319
compartmentalized um do you different

1335
00:54:05,319 --> 00:54:07,599
different sort of instantiations of this

1336
00:54:07,599 --> 00:54:09,480
in different compartments just in within

1337
00:54:09,480 --> 00:54:11,480
one signups almost like are you wanting

1338
00:54:11,480 --> 00:54:13,359
to sort of look at that granular level

1339
00:54:13,359 --> 00:54:14,880
or is it is it more now taking what

1340
00:54:14,880 --> 00:54:16,079
you've learned from this and putting it

1341
00:54:16,079 --> 00:54:17,760
back into how can we sort of you know

1342
00:54:17,760 --> 00:54:19,440
make the AI more

1343
00:54:19,440 --> 00:54:21,920
efficient uh yeah we are going much more

1344
00:54:21,920 --> 00:54:24,240
in this direction now that we we see how

1345
00:54:24,240 --> 00:54:28,040
we can build this back into um AI models

1346
00:54:28,040 --> 00:54:31,359
um so I think the the free energy so one

1347
00:54:31,359 --> 00:54:32,960
has to be a bit careful when using the

1348
00:54:32,960 --> 00:54:34,839
free energy principle because it's such

1349
00:54:34,839 --> 00:54:36,880
a powerful General framework that you

1350
00:54:36,880 --> 00:54:40,160
can apply it to basically

1351
00:54:40,160 --> 00:54:41,359
[Music]

1352
00:54:41,359 --> 00:54:45,680
anything um and it's not necessarily you

1353
00:54:45,680 --> 00:54:49,440
will come up with a useful result in the

1354
00:54:49,440 --> 00:54:53,680
end just applying just putting this

1355
00:54:53,680 --> 00:54:56,119
um and we basically I mean this started

1356
00:54:56,119 --> 00:54:58,040
actually as a side project this was my

1357
00:54:58,040 --> 00:55:03,760
kind of uh coid um pandemic lockdown um

1358
00:55:03,760 --> 00:55:06,480
project and I was just curious about

1359
00:55:06,480 --> 00:55:09,119
this and um whether you can actually

1360
00:55:09,119 --> 00:55:10,680
solve this because I thought the signups

1361
00:55:10,680 --> 00:55:12,839
is maybe simple enough that you because

1362
00:55:12,839 --> 00:55:15,520
when you when you go into the papers um

1363
00:55:15,520 --> 00:55:17,440
they have at some point to go into some

1364
00:55:17,440 --> 00:55:19,760
approximations they do some um meanfield

1365
00:55:19,760 --> 00:55:22,960
usually so they go for first modes and

1366
00:55:22,960 --> 00:55:25,240
then you can solve these guys for more

1367
00:55:25,240 --> 00:55:27,039
complex even for neurons it's hard

1368
00:55:27,039 --> 00:55:29,119
actually if you go to the neuron or

1369
00:55:29,119 --> 00:55:31,160
network level it's it's hard it's it's

1370
00:55:31,160 --> 00:55:35,160
very involved math but for a sinus is

1371
00:55:35,160 --> 00:55:36,599
simple enough actually so you can

1372
00:55:36,599 --> 00:55:38,559
actually do this and and spell

1373
00:55:38,559 --> 00:55:39,880
everything out if you make the right

1374
00:55:39,880 --> 00:55:42,640
assumptions and um and really just

1375
00:55:42,640 --> 00:55:44,559
derived these things and that was kind

1376
00:55:44,559 --> 00:55:47,079
of an just

1377
00:55:47,079 --> 00:55:52,480
an kind of a game I I I went into and

1378
00:55:52,480 --> 00:55:55,240
then it turned out to to work quite

1379
00:55:55,240 --> 00:55:58,720
nicely I think in the end yeah very

1380
00:55:58,720 --> 00:56:01,200
um I'm not sure if you I like

1381
00:56:01,200 --> 00:56:02,960
mitochondria or so I'm sure you could

1382
00:56:02,960 --> 00:56:04,640
apply the same principles but I'm not

1383
00:56:04,640 --> 00:56:08,599
sure if the results you get would be any

1384
00:56:08,599 --> 00:56:11,079
meaningful or would would help you in

1385
00:56:11,079 --> 00:56:12,240
any

1386
00:56:12,240 --> 00:56:14,960
way well that's that's always the the

1387
00:56:14,960 --> 00:56:16,839
risk you you invest so much time and

1388
00:56:16,839 --> 00:56:18,839
then in the end you get some results and

1389
00:56:18,839 --> 00:56:19,240
you don't

1390
00:56:19,240 --> 00:56:20,440
[Music]

1391
00:56:20,440 --> 00:56:23,000
know that was also something that I

1392
00:56:23,000 --> 00:56:25,599
thought was quite interesting which was

1393
00:56:25,599 --> 00:56:28,720
the synapse was the agent it's really

1394
00:56:28,720 --> 00:56:31,000
easy think oh we'll make a agent-based

1395
00:56:31,000 --> 00:56:34,240
model of a neural system first off that

1396
00:56:34,240 --> 00:56:36,480
tends to not include Gia or non- neural

1397
00:56:36,480 --> 00:56:39,240
cell types but it's almost like a doubly

1398
00:56:39,240 --> 00:56:41,480
unquestioned assumption that the cell

1399
00:56:41,480 --> 00:56:43,200
would be the

1400
00:56:43,200 --> 00:56:48,079
agent but then it was a great transition

1401
00:56:48,079 --> 00:56:50,319
from the person throwing the ball over

1402
00:56:50,319 --> 00:56:53,440
the wall that's an action Centric

1403
00:56:53,440 --> 00:56:56,000
approach where you only have partial

1404
00:56:56,000 --> 00:56:57,960
visibility of the

1405
00:56:57,960 --> 00:57:01,079
consequences and then that is the exact

1406
00:57:01,079 --> 00:57:03,640
scenario that the synapse finds itself

1407
00:57:03,640 --> 00:57:06,599
in in in a different way or it could

1408
00:57:06,599 --> 00:57:09,640
have been set up so that a neuron is the

1409
00:57:09,640 --> 00:57:12,319
agent we're building maps not

1410
00:57:12,319 --> 00:57:15,119
territories and so then just like you

1411
00:57:15,119 --> 00:57:17,000
said free energy principle it's a

1412
00:57:17,000 --> 00:57:19,359
principle for

1413
00:57:19,359 --> 00:57:22,720
everything and so just making principled

1414
00:57:22,720 --> 00:57:25,440
statements about things

1415
00:57:25,440 --> 00:57:27,319
is table

1416
00:57:27,319 --> 00:57:30,119
stakes and then I guess my question for

1417
00:57:30,119 --> 00:57:33,079
you is then what does make it useful or

1418
00:57:33,079 --> 00:57:35,119
in your learning and tinkering around

1419
00:57:35,119 --> 00:57:37,880
with these models what differentiated

1420
00:57:37,880 --> 00:57:39,760
situations where you applied free energy

1421
00:57:39,760 --> 00:57:42,000
principle or active inference and you

1422
00:57:42,000 --> 00:57:44,079
felt like it was providing a

1423
00:57:44,079 --> 00:57:46,440
contribution to your research Direction

1424
00:57:46,440 --> 00:57:47,960
versus where you played around and it

1425
00:57:47,960 --> 00:57:50,119
was like well that was to

1426
00:57:50,119 --> 00:57:52,480
logical um I think it the free energy

1427
00:57:52,480 --> 00:57:55,000
principle makes sense in in a context

1428
00:57:55,000 --> 00:57:58,160
where you have um incomplete

1429
00:57:58,160 --> 00:58:01,440
information so as soon as you so for

1430
00:58:01,440 --> 00:58:03,039
example in the signups case right the

1431
00:58:03,039 --> 00:58:05,520
question we started with was um this

1432
00:58:05,520 --> 00:58:07,039
problem that the signups has to solve

1433
00:58:07,039 --> 00:58:09,039
that it has incomplete information about

1434
00:58:09,039 --> 00:58:11,760
the um the state in the cell

1435
00:58:11,760 --> 00:58:15,359
body um because it only sees this uh

1436
00:58:15,359 --> 00:58:17,200
kind of or that's the Assumption at

1437
00:58:17,200 --> 00:58:19,400
least of the model and and also what we

1438
00:58:19,400 --> 00:58:22,119
get from the experimentalists that they

1439
00:58:22,119 --> 00:58:23,359
essentially only sees this spe

1440
00:58:23,359 --> 00:58:25,160
propagating action potential so sees a

1441
00:58:25,160 --> 00:58:28,440
single binary variable about um about

1442
00:58:28,440 --> 00:58:31,960
the state of the of the

1443
00:58:31,960 --> 00:58:35,440
Soma so essentially this is a problem of

1444
00:58:35,440 --> 00:58:39,480
uh of incomplete uh information and also

1445
00:58:39,480 --> 00:58:42,720
the second ingredient that you need an

1446
00:58:42,720 --> 00:58:45,599
agent that you need some form of agency

1447
00:58:45,599 --> 00:58:46,960
I think if you apply the free energy

1448
00:58:46,960 --> 00:58:50,119
principle to a a system without agency

1449
00:58:50,119 --> 00:58:52,440
so if something is not interacting with

1450
00:58:52,440 --> 00:58:55,440
an environment in a closed loop

1451
00:58:55,440 --> 00:58:57,880
uh then it becomes really sketchy and I

1452
00:58:57,880 --> 00:59:00,480
think already this model is is on the

1453
00:59:00,480 --> 00:59:03,000
edge when it comes because

1454
00:59:03,000 --> 00:59:05,319
the these these models don't really have

1455
00:59:05,319 --> 00:59:07,079
an agency but they at least produce an

1456
00:59:07,079 --> 00:59:09,359
output right so you can still think of

1457
00:59:09,359 --> 00:59:11,839
this as an as an interaction with an

1458
00:59:11,839 --> 00:59:14,760
environment but some as soon as you lose

1459
00:59:14,760 --> 00:59:17,599
that I think then there would be simpler

1460
00:59:17,599 --> 00:59:21,039
models that can just give you the

1461
00:59:22,400 --> 00:59:26,119
same yeah

1462
00:59:26,119 --> 00:59:27,839
actually in the signups in the signups

1463
00:59:27,839 --> 00:59:31,319
case the the agency is only this uh this

1464
00:59:31,319 --> 00:59:33,880
adding noise actually in the model

1465
00:59:33,880 --> 00:59:35,240
because the signups is triggered PR

1466
00:59:35,240 --> 00:59:38,640
synoptically and then it it adds this it

1467
00:59:38,640 --> 00:59:40,520
uses its internal state to add the right

1468
00:59:40,520 --> 00:59:41,480
amount of

1469
00:59:41,480 --> 00:59:44,000
noise which is probably already the

1470
00:59:44,000 --> 00:59:45,710
minimal agency you could

1471
00:59:45,710 --> 00:59:48,799
[Music]

1472
00:59:48,799 --> 00:59:51,119
imagine Sarah you want to ask a question

1473
00:59:51,119 --> 00:59:52,599
or I can ask a

1474
00:59:52,599 --> 00:59:54,920
question um yeah I was more just a

1475
00:59:54,920 --> 00:59:56,160
comment like I think it's quite

1476
00:59:56,160 --> 00:59:58,280
interesting like people talk about

1477
00:59:58,280 --> 01:00:00,440
biology some people say it's not real

1478
01:00:00,440 --> 01:00:02,400
science because it's all messy and noisy

1479
01:00:02,400 --> 01:00:04,359
but I think your it works really

1480
01:00:04,359 --> 01:00:06,039
interesting because it's like you say

1481
01:00:06,039 --> 01:00:07,559
the synaptic noise is actually a

1482
01:00:07,559 --> 01:00:10,000
reporting of uncertainty so in that

1483
01:00:10,000 --> 01:00:11,480
Essence it's actually probably quite

1484
01:00:11,480 --> 01:00:13,880
accurately reporting and and the messy

1485
01:00:13,880 --> 01:00:15,359
World rather than the biology itself

1486
01:00:15,359 --> 01:00:16,920
just being all messy but that's just

1487
01:00:16,920 --> 01:00:19,359
what I was thinking about um yeah I

1488
01:00:19,359 --> 01:00:20,480
think I was curious as well like you

1489
01:00:20,480 --> 01:00:21,880
said this was like your lockdown project

1490
01:00:21,880 --> 01:00:23,920
but I'm just interested in how you sort

1491
01:00:23,920 --> 01:00:25,960
of came to the free energy principle how

1492
01:00:25,960 --> 01:00:27,359
you came across it was it something you

1493
01:00:27,359 --> 01:00:29,240
were quite familiar with already or or

1494
01:00:29,240 --> 01:00:30,960
some of your network or peers were

1495
01:00:30,960 --> 01:00:32,359
talking about it or did you stumble

1496
01:00:32,359 --> 01:00:36,000
across it in a paper um I mean I was

1497
01:00:36,000 --> 01:00:37,839
when I was during my PhD I was

1498
01:00:37,839 --> 01:00:40,920
interested in um in variational methods

1499
01:00:40,920 --> 01:00:44,319
and and probabilistic methods um and

1500
01:00:44,319 --> 01:00:46,680
then I started reading about this and so

1501
01:00:46,680 --> 01:00:49,440
I read a bunch of um kristance papers

1502
01:00:49,440 --> 01:00:53,079
and I I found this interesting and

1503
01:00:53,079 --> 01:00:57,319
um actually my my PhD supervisor always

1504
01:00:57,319 --> 01:01:00,280
um encouraged me not to not to go in

1505
01:01:00,280 --> 01:01:01,520
that

1506
01:01:01,520 --> 01:01:03,880
direction uh and then after I finished

1507
01:01:03,880 --> 01:01:05,799
my PhD I thought okay now I I can do

1508
01:01:05,799 --> 01:01:08,079
what I want I try it

1509
01:01:08,079 --> 01:01:10,039
out so

1510
01:01:10,039 --> 01:01:12,400
yeah and then I I guess do you think it

1511
01:01:12,400 --> 01:01:15,319
would be worthwhile like next steps for

1512
01:01:15,319 --> 01:01:17,400
you or for the the field actually trying

1513
01:01:17,400 --> 01:01:19,799
to implement this on you know maybe some

1514
01:01:19,799 --> 01:01:21,960
of the more analog chips that are being

1515
01:01:21,960 --> 01:01:23,400
built in the space like the analog

1516
01:01:23,400 --> 01:01:25,119
neuromorphic chips which I know you can

1517
01:01:25,119 --> 01:01:28,200
have like some synaptic Dynamic synapses

1518
01:01:28,200 --> 01:01:29,799
and and things like do you think it' be

1519
01:01:29,799 --> 01:01:31,839
worthwhile um trying to implement own

1520
01:01:31,839 --> 01:01:34,839
hard Hardware or what your thoughts on

1521
01:01:34,839 --> 01:01:37,119
that um I mean the triplet rule that

1522
01:01:37,119 --> 01:01:39,799
comes out from this first work I showed

1523
01:01:39,799 --> 01:01:41,079
I think that would be interesting to

1524
01:01:41,079 --> 01:01:45,200
implement it um it is the nice feature

1525
01:01:45,200 --> 01:01:47,440
is that it it should in principle be

1526
01:01:47,440 --> 01:01:49,359
kind of this should have this self-

1527
01:01:49,359 --> 01:01:52,319
stabilizing picture because it's really

1528
01:01:52,319 --> 01:01:56,640
mimicking the uh the Dynamics of the the

1529
01:01:56,640 --> 01:01:59,839
membrane of the cell membrane so if the

1530
01:01:59,839 --> 01:02:02,640
if the neuromorphic hardware

1531
01:02:02,640 --> 01:02:04,640
would

1532
01:02:04,640 --> 01:02:08,079
uh so if if the the model in the signups

1533
01:02:08,079 --> 01:02:10,440
and and the Neuron model match up very

1534
01:02:10,440 --> 01:02:13,680
well the model should uh give you this

1535
01:02:13,680 --> 01:02:16,400
nice uh self stabilizing feature so that

1536
01:02:16,400 --> 01:02:19,160
neurons really not go into some

1537
01:02:19,160 --> 01:02:20,880
epileptic States or so and you get this

1538
01:02:20,880 --> 01:02:22,720
for free from this model that's what we

1539
01:02:22,720 --> 01:02:25,160
saw in the simulations at least

1540
01:02:25,160 --> 01:02:28,720
but um in the simulations of course we

1541
01:02:28,720 --> 01:02:30,960
we had full control over this Dynamics

1542
01:02:30,960 --> 01:02:33,000
matching up in the right way

1543
01:02:33,000 --> 01:02:36,680
so um that is probably a bit more tricky

1544
01:02:36,680 --> 01:02:39,200
for Hardware but it's probably solvable

1545
01:02:39,200 --> 01:02:41,039
so it would be interesting yeah then

1546
01:02:41,039 --> 01:02:42,480
what you get for it is that you have

1547
01:02:42,480 --> 01:02:44,520
this purely event based tools right

1548
01:02:44,520 --> 01:02:48,599
which only use um prepost spikes which

1549
01:02:48,599 --> 01:02:49,520
which is

1550
01:02:49,520 --> 01:02:53,000
nice very cool thank you yeah Daniel if

1551
01:02:53,000 --> 01:02:55,200
you had a question

1552
01:02:55,200 --> 01:02:58,559
well that's a great principle there

1553
01:02:58,559 --> 01:03:00,319
which is like if you can design the

1554
01:03:00,319 --> 01:03:03,240
neuromorphic algorithm so that it

1555
01:03:03,240 --> 01:03:06,599
harnesses a material feature like the

1556
01:03:06,599 --> 01:03:08,640
actual leaky permeability of a membrane

1557
01:03:08,640 --> 01:03:12,599
or actual spatial proximity if you can

1558
01:03:12,599 --> 01:03:15,640
leverage a material feature analog

1559
01:03:15,640 --> 01:03:19,000
feature that isn't virtualized then it's

1560
01:03:19,000 --> 01:03:20,119
already in

1561
01:03:20,119 --> 01:03:23,079
adjacency into future Hardware so that's

1562
01:03:23,079 --> 01:03:25,760
one great point and then to s's point

1563
01:03:25,760 --> 01:03:28,920
about like almost biology not being a

1564
01:03:28,920 --> 01:03:32,520
science which um there's a famous

1565
01:03:32,520 --> 01:03:34,480
quotation there will never be a Newton

1566
01:03:34,480 --> 01:03:36,839
for a blade of grass because some people

1567
01:03:36,839 --> 01:03:38,839
say yeah it's a different biology is

1568
01:03:38,839 --> 01:03:41,079
more like history because whether you

1569
01:03:41,079 --> 01:03:42,680
approach this from a development or

1570
01:03:42,680 --> 01:03:44,880
ecology or Evolution perspective biology

1571
01:03:44,880 --> 01:03:46,640
is a historical science it's not like a

1572
01:03:46,640 --> 01:03:49,480
real science and then that reminded me

1573
01:03:49,480 --> 01:03:53,000
of the cross country shirt that says our

1574
01:03:53,000 --> 01:03:55,000
sport is your punishment

1575
01:03:55,000 --> 01:03:58,319
so it's like well no like that your

1576
01:03:58,319 --> 01:04:02,760
noise is biology's signal and that's how

1577
01:04:02,760 --> 01:04:04,279
it

1578
01:04:04,279 --> 01:04:08,680
happens my question was about this

1579
01:04:08,680 --> 01:04:10,640
tension

1580
01:04:10,640 --> 01:04:14,039
between I guess neural and computational

1581
01:04:14,039 --> 01:04:16,760
ways of looking at the resources

1582
01:04:16,760 --> 01:04:19,440
associated with computation so from the

1583
01:04:19,440 --> 01:04:23,720
Von noyman Paradigm we have a lot of

1584
01:04:23,720 --> 01:04:27,720
shared reference points CPU Cycles Ram

1585
01:04:27,720 --> 01:04:30,559
capacity and all these kinds of things

1586
01:04:30,559 --> 01:04:34,520
and like even in your

1587
01:04:34,520 --> 01:04:36,559
introductions you conveyed like well

1588
01:04:36,559 --> 01:04:38,839
this is how many CPU Cycles it's going

1589
01:04:38,839 --> 01:04:41,799
through or this is how many parameters

1590
01:04:41,799 --> 01:04:43,920
would have to be stored or something

1591
01:04:43,920 --> 01:04:45,319
like

1592
01:04:45,319 --> 01:04:48,240
that however that's

1593
01:04:48,240 --> 01:04:53,160
referencing another Paradigm so what do

1594
01:04:53,160 --> 01:04:56,160
resource

1595
01:04:56,880 --> 01:05:01,640
descriptors or capacity descriptors look

1596
01:05:01,640 --> 01:05:04,319
like when we're outside the space of

1597
01:05:04,319 --> 01:05:05,559
okay yeah power consumption that's

1598
01:05:05,559 --> 01:05:07,039
something that you can put into a box

1599
01:05:07,039 --> 01:05:09,079
and just use a bomb calorimeter that's

1600
01:05:09,079 --> 01:05:12,520
kind of like a low hanging fruit but now

1601
01:05:12,520 --> 01:05:15,760
okay Beyond just the sheer energy or

1602
01:05:15,760 --> 01:05:16,960
caloric

1603
01:05:16,960 --> 01:05:19,319
requirements what can we say that is

1604
01:05:19,319 --> 01:05:21,880
like analogous to the way that we talk

1605
01:05:21,880 --> 01:05:25,200
about the processor the Ram or the hard

1606
01:05:25,200 --> 01:05:27,759
drive on a

1607
01:05:30,000 --> 01:05:32,839
computer I mean I'm yeah I I'd have to

1608
01:05:32,839 --> 01:05:34,279
think about that one some more I do

1609
01:05:34,279 --> 01:05:35,200
think there was some interesting

1610
01:05:35,200 --> 01:05:37,240
comments in the paper on that slide I

1611
01:05:37,240 --> 01:05:39,520
showed that talks about um the brain and

1612
01:05:39,520 --> 01:05:41,119
energy there was a paper I linked to

1613
01:05:41,119 --> 01:05:42,359
I'll have to get the reference and let

1614
01:05:42,359 --> 01:05:43,839
you know what it is because QR C's gone

1615
01:05:43,839 --> 01:05:46,520
now um but that had some interesting

1616
01:05:46,520 --> 01:05:48,920
ideas I think on what you're getting out

1617
01:05:48,920 --> 01:05:52,880
there but I yeah I'd have to defer to

1618
01:05:52,880 --> 01:05:55,279
the paper

1619
01:05:55,279 --> 01:05:57,200
I mean how do they describe what is

1620
01:05:57,200 --> 01:06:00,520
being designed do they say it has this

1621
01:06:00,520 --> 01:06:03,200
many of this type of component and then

1622
01:06:03,200 --> 01:06:05,720
that might do nothing though so how do

1623
01:06:05,720 --> 01:06:08,079
they describe or evaluate these

1624
01:06:08,079 --> 01:06:11,480
different designs or

1625
01:06:11,640 --> 01:06:13,520
algorithms I think it's all different

1626
01:06:13,520 --> 01:06:14,799
depending on the use case like that's

1627
01:06:14,799 --> 01:06:16,319
what I've found really like the language

1628
01:06:16,319 --> 01:06:18,520
is is different depending on you know if

1629
01:06:18,520 --> 01:06:20,440
it's written by someone maybe with more

1630
01:06:20,440 --> 01:06:21,480
of a neuroscience background or

1631
01:06:21,480 --> 01:06:23,799
engineering background and then you kind

1632
01:06:23,799 --> 01:06:25,279
of you said that some terms they're more

1633
01:06:25,279 --> 01:06:26,920
interchangeable than others but I do

1634
01:06:26,920 --> 01:06:29,400
think the terminology is something which

1635
01:06:29,400 --> 01:06:31,559
needs to be looked at a lot more closely

1636
01:06:31,559 --> 01:06:33,039
in the space because then I think that

1637
01:06:33,039 --> 01:06:35,599
will help everybody working in it to be

1638
01:06:35,599 --> 01:06:38,799
on the same page a little bit

1639
01:06:42,079 --> 01:06:44,359
closer cool

1640
01:06:44,359 --> 01:06:47,960
well any other thoughts or questions

1641
01:06:47,960 --> 01:06:51,440
David first and then Sarah also I'm very

1642
01:06:51,440 --> 01:06:55,480
curious what direction will this series

1643
01:06:55,480 --> 01:06:59,039
go but first David what are any other

1644
01:06:59,039 --> 01:07:02,119
kind of closing comments or directions

1645
01:07:02,119 --> 01:07:03,359
you want to

1646
01:07:03,359 --> 01:07:07,000
provide um not really um I mean I would

1647
01:07:07,000 --> 01:07:09,480
say thanks for for having me today was

1648
01:07:09,480 --> 01:07:11,279
really was really a pleasure to discuss

1649
01:07:11,279 --> 01:07:13,359
with

1650
01:07:13,359 --> 01:07:15,720
you thank you David it was amazing to

1651
01:07:15,720 --> 01:07:17,000
have you on I think your work's

1652
01:07:17,000 --> 01:07:19,079
absolutely fascinating and I think it's

1653
01:07:19,079 --> 01:07:20,880
going to be have lots of benefits in the

1654
01:07:20,880 --> 01:07:23,400
future for implementation which is

1655
01:07:23,400 --> 01:07:26,559
always nice to see as well um yeah so

1656
01:07:26,559 --> 01:07:27,760
what was the question where where do I

1657
01:07:27,760 --> 01:07:30,279
see the series going um hopefully we can

1658
01:07:30,279 --> 01:07:33,720
have a new guest each month um I think

1659
01:07:33,720 --> 01:07:36,240
it'd be kind of cool maybe next month to

1660
01:07:36,240 --> 01:07:38,680
do um to have someone who's building

1661
01:07:38,680 --> 01:07:40,319
Hardware so like maybe someone from the

1662
01:07:40,319 --> 01:07:42,079
brain scales team or spica team or

1663
01:07:42,079 --> 01:07:44,279
something like that would be pretty cool

1664
01:07:44,279 --> 01:07:46,880
um but yeah really I just want to have a

1665
01:07:46,880 --> 01:07:49,119
space for people who are interested in

1666
01:07:49,119 --> 01:07:52,359
this intersection to uh meet people who

1667
01:07:52,359 --> 01:07:54,079
and see talks and you know Reach Out

1668
01:07:54,079 --> 01:07:56,520
people who are also working in the space

1669
01:07:56,520 --> 01:07:59,319
because um it's pretty Niche but I think

1670
01:07:59,319 --> 01:08:01,920
it's pretty important um actually having

1671
01:08:01,920 --> 01:08:03,400
said that David could you let everybody

1672
01:08:03,400 --> 01:08:05,039
know like if they wanted to reach out to

1673
01:08:05,039 --> 01:08:08,359
you what's the best way for them to do

1674
01:08:08,359 --> 01:08:09,390
that

1675
01:08:09,390 --> 01:08:11,400
[Music]

1676
01:08:11,400 --> 01:08:13,960
um I'm not very active on this Discord

1677
01:08:13,960 --> 01:08:16,399
channel so maybe email is still the best

1678
01:08:16,399 --> 01:08:19,158
uh to reach out to me I

1679
01:08:19,158 --> 01:08:21,399
guess cool do you want to give your

1680
01:08:21,399 --> 01:08:22,839
email

1681
01:08:22,839 --> 01:08:27,560
just oh I think my email should be easy

1682
01:08:27,560 --> 01:08:28,960
enough to find but you can also get the

1683
01:08:28,960 --> 01:08:30,600
email out there

1684
01:08:30,600 --> 01:08:33,439
short people can check the papers and

1685
01:08:33,439 --> 01:08:36,000
then in the active inference Institute

1686
01:08:36,000 --> 01:08:40,080
Discord there's the neuromorphic

1687
01:08:41,120 --> 01:08:43,719
Channel all right thank you David and

1688
01:08:43,719 --> 01:08:47,198
Sarah really cool to see morph stream

1689
01:08:47,198 --> 01:08:49,158
kick off its developmental trajectory

1690
01:08:49,158 --> 01:08:52,799
this way so till next time thank you

1691
01:08:52,799 --> 01:08:54,109
bye

1692
01:08:54,109 --> 01:08:57,169
[Music]

1693
01:09:19,040 --> 01:09:22,040
fine

