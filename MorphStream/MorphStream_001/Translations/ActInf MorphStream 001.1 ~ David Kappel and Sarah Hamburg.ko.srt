1
00:00:07,040 --> 00:00:10,320
안녕하세요 여러분 환영합니다. 2023년 9월 26일입니다.

2
00:00:10,320 --> 00:00:12,080


3
00:00:12,080 --> 00:00:15,120


4
00:00:15,120 --> 00:00:17,119
Active inference Institute에서 새로운 스트림 시리즈를 시작합니다.

5
00:00:17,119 --> 00:00:20,400
이것은 모프 스트림

6
00:00:20,400 --> 00:00:24,800
1.1입니다. 오늘은 David kapple이 있고

7
00:00:24,800 --> 00:00:27,960
이 섹션과 Sarah Hamburg가 진행하는 스트림도 있을

8
00:00:27,960 --> 00:00:31,320
예정입니다.

9
00:00:31,320 --> 00:00:35,440
먼저 Sarah가 개요를 발표한 다음

10
00:00:35,440 --> 00:00:38,040
David가

11
00:00:38,040 --> 00:00:40,520
뉴로모픽 컴퓨팅에 대한 몇 가지 작업을 공유한 다음

12
00:00:40,520 --> 00:00:42,879
논의할 시간을 갖게 됩니다. 첫 번째 프레젠테이션에

13
00:00:42,879 --> 00:00:45,480
참석해 주신 Sarah와 Sarah 모두에게 감사드리며

14
00:00:45,480 --> 00:00:47,360


15
00:00:47,360 --> 00:00:49,600
원하시면 자신을 소개하겠습니다.

16
00:00:49,600 --> 00:00:51,000
그렇습니다.  좋은 생각이네요 정말 감사합니다

17
00:00:51,000 --> 00:00:54,120
Daniel 음 그래서 제 이름은 Sarah입니다 음 저는

18
00:00:54,120 --> 00:00:56,120


19
00:00:56,120 --> 00:00:57,280
현재

20
00:00:57,280 --> 00:01:00,280
뉴로모픽 컴퓨팅 분야에서 일하고 있는 지능 전문 신경과학자입니다. 음 영국의 Chef Field

21
00:01:00,280 --> 00:01:02,480
Hal에서

22
00:01:02,480 --> 00:01:04,400
높은 수준의 개요를 알려드리겠습니다.  뉴로모픽

23
00:01:04,400 --> 00:01:06,720
컴퓨팅이 무엇인지에 대해 그리고 이 새 시리즈의

24
00:01:06,720 --> 00:01:08,640
첫 번째 버전에서 David의 흥미진진한 강연을 듣기 전에

25
00:01:08,640 --> 00:01:11,320
음

26
00:01:11,320 --> 00:01:12,799
여러분이 앞으로 두 배의 시간을 시청하게 될지 알려드리기 위해 제가

27
00:01:12,799 --> 00:01:14,320
꽤 빠르게 이야기하므로 여러분이

28
00:01:14,320 --> 00:01:17,080
저를 보고 싶지 않을 수도 있습니다  두 배로,

29
00:01:17,080 --> 00:01:19,400
음 여기에 넣은 이 QR 코드는 제가

30
00:01:19,400 --> 00:01:20,880
생각하기에 이

31
00:01:20,880 --> 00:01:23,520
분야에 대한 정말 좋은 소개라고 생각했던 논문으로 여러분을 안내할 것입니다 음 하지만

32
00:01:23,520 --> 00:01:25,520
Neic 컴퓨팅은 신경계

33
00:01:25,520 --> 00:01:27,000


34
00:01:27,000 --> 00:01:28,680
의 구조와 기능을 모방하도록 설계된 컴퓨팅 시스템으로 정의될 수 있습니다

35
00:01:28,680 --> 00:01:30,720
따라서 이것이

36
00:01:30,720 --> 00:01:32,680
인간의 신경계일 필요는 없습니다. 현장은

37
00:01:32,680 --> 00:01:34,320
실제로 모든 종류의 동물과 곤충으로부터 영감을 얻습니다. 음

38
00:01:34,320 --> 00:01:36,640


39
00:01:36,640 --> 00:01:38,159
온라인 정의가 반드시

40
00:01:38,159 --> 00:01:40,680
이를 인정하지는 않지만 일부 사람들은

41
00:01:40,680 --> 00:01:42,200


42
00:01:42,200 --> 00:01:43,920
뉴로모픽을 구성하는 것에 상당히 개방적인 반면 다른 사람들은 선호할 수도 있습니다.

43
00:01:43,920 --> 00:01:46,119
뉴로모픽(neuromorphic)은

44
00:01:46,119 --> 00:01:48,600


45
00:01:48,600 --> 00:01:50,520
때로는

46
00:01:50,520 --> 00:01:53,280
실행되지 않는 컴퓨터라고도 불리는 뉴런과 같은 생물학적인 하드웨어 인스턴스화를 위해 예약되었습니다. 그리고 제 생각엔

47
00:01:53,280 --> 00:01:55,280
QR

48
00:01:55,280 --> 00:01:58,320
코드가 음

49
00:01:58,320 --> 00:02:00,280
정의로 언급할 논문에서 그런 것 같아요. 음 그래서 제가 생각하는 것은 정말

50
00:02:00,280 --> 00:02:01,200
흥미롭습니다.  약간의

51
00:02:01,200 --> 00:02:02,920
맥락이므로 현재의 vuman

52
00:02:02,920 --> 00:02:04,479
컴퓨터 아키텍처도

53
00:02:04,479 --> 00:02:06,439
신경과학, 특히

54
00:02:06,439 --> 00:02:08,840
Mull andpits 43 Neuron 모델에서 영감을 받은 것처럼 음

55
00:02:08,840 --> 00:02:12,080
1945년 Von y의 첫 초안에서 영감을 얻었습니다. 따라서

56
00:02:12,080 --> 00:02:14,120
신경과학은 음 영감을 주는 컴퓨터 과학의 오랜 역사를 가지고 있으며

57
00:02:14,120 --> 00:02:16,120
이것도 또한

58
00:02:16,120 --> 00:02:17,680


59
00:02:17,680 --> 00:02:19,440


60
00:02:19,440 --> 00:02:20,720
행동

61
00:02:20,720 --> 00:02:22,480
심리학에서 보상과

62
00:02:22,480 --> 00:02:24,760
처벌을 기반으로 의사결정을 학습하는 이론에 기초한 강화학습과 함께 연결되는 세포의 헤이안 학습 원리도 포함되어 있습니다.

63
00:02:24,760 --> 00:02:26,519


64
00:02:26,519 --> 00:02:29,239
음 49부터

65
00:02:29,239 --> 00:02:31,680
비지도 학습의 기초가 되었기

66
00:02:31,680 --> 00:02:34,959
때문에 우선 음 잠깐만 기다려주세요.

67
00:02:34,959 --> 00:02:37,640
음,

68
00:02:37,640 --> 00:02:39,440
뉴로모픽 컴퓨팅의 이유를 이해하기 위해 저는 뇌의

69
00:02:39,440 --> 00:02:40,959
장점이 무엇인지 정말로 설명하고 싶었습니다.

70
00:02:40,959 --> 00:02:44,120
그래서 전구에 대한 몇 가지 영감을 얻었으니

71
00:02:44,120 --> 00:02:46,360


72
00:02:46,360 --> 00:02:47,280
질문을 하나 하겠습니다. 잠시 생각해 보시기 바랍니다.

73
00:02:47,280 --> 00:02:49,159
두 번째, 전구에 관해서는

74
00:02:49,159 --> 00:02:51,239


75
00:02:51,239 --> 00:02:53,879
뇌가 얼마나 많은 에너지를 사용한다고 생각하시나요? 그것이 당신이 있는 방을 밝히는 전구보다 더 많거나 적다고 생각하시나요?

76
00:02:53,879 --> 00:02:56,280


77
00:02:56,280 --> 00:02:58,040
당신이 미래에 있다면

78
00:02:58,040 --> 00:02:59,560
꼭 PA 이 일시 중지하세요.

79
00:02:59,560 --> 00:03:01,200
좀 더 심층적인

80
00:03:01,200 --> 00:03:02,760
계산을 하고 싶지만 답변으로 건너뛰겠습니다.

81
00:03:02,760 --> 00:03:06,680
답변은 여기

82
00:03:06,680 --> 00:03:10,159
분홍색 원 안에 있으므로 20와트이므로 이는

83
00:03:10,159 --> 00:03:12,200
현대의 에너지 효율적인 전구 1개에 해당하므로

84
00:03:12,200 --> 00:03:14,519


85
00:03:14,519 --> 00:03:16,280
지금은 아마도 저보다 높을 것입니다.  기본적으로 여기 내 방에 있습니다.

86
00:03:16,280 --> 00:03:18,840
음, 이 QR 코드를 통해 뇌의

87
00:03:18,840 --> 00:03:20,040
전력 소비에 관한 꽤 흥미로운 논문을 볼 수 있습니다.

88
00:03:20,040 --> 00:03:21,239


89
00:03:21,239 --> 00:03:23,080


90
00:03:23,080 --> 00:03:25,360


91
00:03:25,360 --> 00:03:28,519
하루에 바나나 4개를 먹으면 뇌에 활력을 불어넣을 수 있으며

92
00:03:28,519 --> 00:03:30,760
이는 다음과 같이 계산됩니다.

93
00:03:30,760 --> 00:03:32,840
두뇌가 필요로 하는 칼로리 섭취량을 기준으로 한 것입니다.

94
00:03:32,840 --> 00:03:35,200


95
00:03:35,200 --> 00:03:36,720
유럽에서 가장 빠른 슈퍼컴퓨터입니다. 핀란드에서는 Lumi라고 하는 것 같아요.

96
00:03:36,720 --> 00:03:38,560
음,

97
00:03:38,560 --> 00:03:40,560
예외적으로 친환경적이라고 불렸으며 전력

98
00:03:40,560 --> 00:03:43,640
소비량은 850만 와트이므로

99
00:03:43,640 --> 00:03:45,840


100
00:03:45,840 --> 00:03:48,840
두뇌가 사용하는 전구는 약 50만 개에 해당합니다.  하나만 그렇다면

101
00:03:48,840 --> 00:03:49,879
문제는 당신의

102
00:03:49,879 --> 00:03:52,280
두뇌가 그 전구 하나나 바나나

103
00:03:52,280 --> 00:03:54,200
4개로 무엇을 하느냐는 것입니다.

104
00:03:54,200 --> 00:03:57,599
분명히

105
00:03:57,599 --> 00:04:00,120
초당 1조 개의 계산을 수행하므로

106
00:04:00,120 --> 00:04:01,879
다른 엄청난 추정치가 많이 있습니다.

107
00:04:01,879 --> 00:04:03,599
어 이것은 여러 순서로 가장 큰 것도 아니었습니다.

108
00:04:03,599 --> 00:04:05,840
크기 추정치는

109
00:04:05,840 --> 00:04:07,799
분명히 매우 추측에 불과하지만

110
00:04:07,799 --> 00:04:09,519
모두 방대하고 모두

111
00:04:09,519 --> 00:04:11,280
뉴런의 수와

112
00:04:11,280 --> 00:04:13,840
연결 및 발사 속도를 기반으로 하는 경향이 있습니다. 하지만

113
00:04:13,840 --> 00:04:14,879


114
00:04:14,879 --> 00:04:17,040
슈퍼컴퓨터가

115
00:04:17,040 --> 00:04:18,880
실제로 아직 일치할 수 없다는 맥락에서 이것이 정말 중요하다고 생각합니다.  우리의

116
00:04:18,880 --> 00:04:20,880
기술의 복잡성이나

117
00:04:20,880 --> 00:04:23,400
인간 두뇌의 적응성을 알기 때문에 우리는

118
00:04:23,400 --> 00:04:25,520
실제로 복잡한 의사 결정과 같은 일에 있어서 슈퍼컴퓨터를 넘어서는 Excel Way Beyond

119
00:04:25,520 --> 00:04:26,960


120
00:04:26,960 --> 00:04:29,120


121
00:04:29,120 --> 00:04:31,520
경험을 통해 학습합니다.

122
00:04:31,520 --> 00:04:34,039
그래서 당신의 두뇌는 AI와 어떻게 비교됩니까 음

123
00:04:34,039 --> 00:04:36,039
그래서 현대 AI는  이미

124
00:04:36,039 --> 00:04:38,199
뇌에서 영감을 얻었지만 인공

125
00:04:38,199 --> 00:04:41,240
뉴런은 매우 단순화되어 생물학적 뉴런이나 네트워크

126
00:04:41,240 --> 00:04:42,600
의 복잡성을 포착하지 못합니다. 음,

127
00:04:42,600 --> 00:04:44,320


128
00:04:44,320 --> 00:04:47,240
개별 뉴런은

129
00:04:47,240 --> 00:04:49,520
실제로 네트워크 자체와 더 비슷하며

130
00:04:49,520 --> 00:04:51,120
연구에 따르면 하나의

131
00:04:51,120 --> 00:04:53,039
생물학적 뉴런을 모델링하려면 5개의 뉴런이 필요합니다.

132
00:04:53,039 --> 00:04:55,240
8층 깊은 인공 뉴런

133
00:04:55,240 --> 00:04:57,080
약 천 개의

134
00:04:57,080 --> 00:04:59,160
인공 뉴런으로 구성된 네트워크 이 QR 코드는

135
00:04:59,160 --> 00:05:02,160


136
00:05:02,160 --> 00:05:04,919
당신의 뇌에 860억 개의 뉴런이 있다는 논문으로 여러분을 데려다줄 것입니다.

137
00:05:04,919 --> 00:05:07,120
어 그들은 함께 작동하여 바로 위에서 작동하는

138
00:05:07,120 --> 00:05:09,160
매우 에너지 효율적인 저지연

139
00:05:09,160 --> 00:05:11,560
슈퍼컴퓨터를 형성합니다.  실내

140
00:05:11,560 --> 00:05:13,759
온도는 하루에 약 4개의 바나나에 해당하므로 여러분

141
00:05:13,759 --> 00:05:16,440


142
00:05:16,440 --> 00:05:17,680
의 뇌가 얼마나 놀라운지,

143
00:05:17,680 --> 00:05:19,720
음, 마치 여러분이 아직 몰랐던 것처럼,

144
00:05:19,720 --> 00:05:21,960
그리고 꽤 기본적인 AI에 영감을 주기 위해 뇌가 어떻게 이미 사용되었는지 알려 드렸기를 바랍니다.

145
00:05:21,960 --> 00:05:24,039


146
00:05:24,039 --> 00:05:25,560
이제 인간 지능과 비교했으니

147
00:05:25,560 --> 00:05:27,360
다음에는 뉴로모픽 컴퓨팅 분야를 통해 차세대 AI 및 기술을 촉진하기 위해

148
00:05:27,360 --> 00:05:29,000
뇌의 주요 기능이 어떻게

149
00:05:29,000 --> 00:05:31,319
구현되고 있는지 설명하겠습니다.

150
00:05:31,319 --> 00:05:33,720


151
00:05:33,720 --> 00:05:35,080


152
00:05:35,080 --> 00:05:37,680
이것이 바로 여러분이 여기 모인 이유입니다.

153
00:05:37,680 --> 00:05:39,960
vum과 컴퓨터는

154
00:05:39,960 --> 00:05:42,039
물리적으로 분리된 컴퓨팅 및 메모리

155
00:05:42,039 --> 00:05:45,039
장치를 가지고 있습니다. 여기 왼쪽에 표시되어 있습니다. 어

156
00:05:45,039 --> 00:05:47,280
계산하는 동안 데이터는

157
00:05:47,280 --> 00:05:49,000
정말 빠르게 앞뒤로 전송되어야 하므로

158
00:05:49,000 --> 00:05:51,600
본질적으로 속도와 에너지에 병목 현상이 있습니다.

159
00:05:51,600 --> 00:05:53,840
음, 여기 오른쪽에 표시된 뉴로모픽 아키텍처에서는

160
00:05:53,840 --> 00:05:55,160


161
00:05:55,160 --> 00:05:57,400
Dary Computing의 도움

162
00:05:57,400 --> 00:05:59,639
과 메모리는 같은 장소에서 발생하므로

163
00:05:59,639 --> 00:06:01,840


164
00:06:01,840 --> 00:06:03,880
본질적으로 개별

165
00:06:03,880 --> 00:06:06,080
뉴런이 계산을 수행하고

166
00:06:06,080 --> 00:06:07,759
기억은 연결의 강도로 표시됩니다. 뉴런

167
00:06:07,759 --> 00:06:09,720
사이의 가중치

168
00:06:09,720 --> 00:06:13,000
그래서 경찰 그래서 이런 칩은

169
00:06:13,000 --> 00:06:15,440
구성 요소로 생성 될 수 있습니다 uh

170
00:06:15,440 --> 00:06:17,919
예를 들어 시냅스 가중치를 에뮬레이트할 수 있는 Mista와 같은

171
00:06:17,919 --> 00:06:20,840
아키텍처는

172
00:06:20,840 --> 00:06:22,960
속도를 향상시켜 에너지

173
00:06:22,960 --> 00:06:24,520
소비를 줄입니다. 그리고 정말

174
00:06:24,520 --> 00:06:26,319
흥미로운 점은 대규모

175
00:06:26,319 --> 00:06:28,240
병렬 처리가 가능하다는 것입니다. 즉,

176
00:06:28,240 --> 00:06:30,080
여러 문제를 동시에 처리할 수 있으므로

177
00:06:30,080 --> 00:06:32,720


178
00:06:32,720 --> 00:06:34,680
이 아키텍처는 다양한 용도에 특히 중요합니다.

179
00:06:34,680 --> 00:06:37,039
또한 칩에 맞게 물리적으로 더 작게 만들 수 있는 트랜지스터의 수인

180
00:06:37,039 --> 00:06:39,199
Moos 로그의 끝에 도달하면

181
00:06:39,199 --> 00:06:41,520


182
00:06:41,520 --> 00:06:44,599


183
00:06:44,599 --> 00:06:46,759
인류는 창조의 감소를 배경으로

184
00:06:46,759 --> 00:06:48,560
에너지 소비를 대폭 줄여야 하기 때문에 중요합니다.

185
00:06:48,560 --> 00:06:51,520


186
00:06:51,520 --> 00:06:54,400
훨씬 더 강력한

187
00:06:54,400 --> 00:06:57,280
AI이므로 인공 뉴런은 일반적으로

188
00:06:57,280 --> 00:06:59,560
왼쪽에 표시된 지속적인 활성화를 사용합니다.

189
00:06:59,560 --> 00:07:01,599
항상 켜져 있는 반면

190
00:07:01,599 --> 00:07:03,560
신경형 뉴런은

191
00:07:03,560 --> 00:07:05,720
급증하여 켜져 있거나 꺼져 있으며

192
00:07:05,720 --> 00:07:07,440
여기 오른쪽에 표시되어 있습니다.

193
00:07:07,440 --> 00:07:09,759
활동 전위를 정렬하여

194
00:07:09,759 --> 00:07:12,000
이에 대한 이점은 다시 전력

195
00:07:12,000 --> 00:07:14,160
효율성이고

196
00:07:14,160 --> 00:07:16,319
타이밍이 중요한 응용 분야이며 이는

197
00:07:16,319 --> 00:07:18,720
이벤트가 구동되므로

198
00:07:18,720 --> 00:07:21,160
본질적으로

199
00:07:21,160 --> 00:07:23,759
공간적 및 시간적 차원에 대한 잠재력이 있어

200
00:07:23,759 --> 00:07:25,759
추가 시공간 인코딩을 가능하게 한다는 점을 고려합니다.

201
00:07:25,759 --> 00:07:28,479
그리고 정보 처리

202
00:07:28,479 --> 00:07:30,680
어 당신은 GPU에 대해 조금 궁금할 것입니다 음

203
00:07:30,680 --> 00:07:33,240
병렬 처리도 가능합니다

204
00:07:33,240 --> 00:07:35,080
어 연구에 따르면 GPU는 네트워크 급증을

205
00:07:35,080 --> 00:07:37,319
배포하는 데 적합한 아키텍처라고 합니다

206
00:07:37,319 --> 00:07:39,599
음

207
00:07:39,599 --> 00:07:41,280


208
00:07:41,280 --> 00:07:43,199
고급 GPU가 얼마나

209
00:07:43,199 --> 00:07:46,159
발전하고 있는지를 고려하면 지금이 이 분야에서 정말 흥미로운 시간이 될 것 같습니다  음,

210
00:07:46,159 --> 00:07:49,479
뇌는

211
00:07:49,479 --> 00:07:51,599
뉴런 사이의 시냅스 강도를 학습합니다. 이것은

212
00:07:51,599 --> 00:07:53,560
시냅스 발사 전과 후의

213
00:07:53,560 --> 00:07:55,240
패턴을 기반으로 합니다. David의 강연에서 이에 대해

214
00:07:55,240 --> 00:07:57,680
더 자세히 다룰 것 같지만

215
00:07:57,680 --> 00:07:59,319
다양한 유형의 유형이 있으며  흥분성,

216
00:07:59,319 --> 00:08:01,240


217
00:08:01,240 --> 00:08:03,720


218
00:08:03,720 --> 00:08:05,599
억제성 흥분성,

219
00:08:05,599 --> 00:08:06,919


220
00:08:06,919 --> 00:08:09,159
흥분성 음과 같은 시냅스 유형에 따라 뇌 전체에 걸쳐 이러한 패턴이 있으며 뉴롬 시장

221
00:08:09,159 --> 00:08:11,639
분야에서는

222
00:08:11,639 --> 00:08:13,800
온칩

223
00:08:13,800 --> 00:08:16,159
학습 및

224
00:08:16,159 --> 00:08:18,039
패턴 인식 및 엣지 컴퓨팅과 같은 애플리케이션에 대한 이점 때문에 이러한 규칙을 활용하기 위해 노력하고 있습니다.

225
00:08:18,039 --> 00:08:19,599
또한 Edge Computing은

226
00:08:19,599 --> 00:08:21,680


227
00:08:21,680 --> 00:08:23,000
일종의 이벤트 기반

228
00:08:23,000 --> 00:08:26,240
특성과 낮은 에너지 사용량으로 인해 뉴로모픽 컴퓨팅의 매우 큰 사용 사례입니다.

229
00:08:26,240 --> 00:08:27,879
이 QR 코드는

230
00:08:27,879 --> 00:08:31,839
제가 찾은 stdp에 대한 매우 흥미로운 논문으로 여러분을 안내할 것입니다.

231
00:08:31,839 --> 00:08:34,799
그래서 뉴로모픽 솔루션은 무엇입니까?

232
00:08:34,799 --> 00:08:36,159
지금은 이론적이라고 생각할 수도 있겠지만

233
00:08:36,159 --> 00:08:38,320
실제로는 다양한 솔루션이 많이 있습니다. 이에 대해

234
00:08:38,320 --> 00:08:40,200


235
00:08:40,200 --> 00:08:41,559
매우 높은 수준의

236
00:08:41,559 --> 00:08:44,120
개요를 제공하겠습니다. 따라서 인간 두뇌 프로젝트에서는

237
00:08:44,120 --> 00:08:45,760


238
00:08:45,760 --> 00:08:48,120
스피카를 포함하여 여러 대의 대규모 신경모형 컴퓨터를 만들었습니다.

239
00:08:48,120 --> 00:08:49,800
바닥에 있는 이

240
00:08:49,800 --> 00:08:51,560
보드는 마치 내가

241
00:08:51,560 --> 00:08:53,480
내 얼굴의 크기를 모르거나

242
00:08:53,480 --> 00:08:55,760
실시간으로 실행되는 것 같은 것일 수도 있습니다. 음 마이크로프로세서

243
00:08:55,760 --> 00:08:58,200
에 대한 여러 범용으로 구성되어 있으며

244
00:08:58,200 --> 00:09:00,279


245
00:09:00,279 --> 00:09:03,120
가속 아날로그 아키텍처인 뇌 척도도 있어서

246
00:09:03,120 --> 00:09:05,399
실행됩니다.  천

247
00:09:05,399 --> 00:09:09,240
번 실시간으로 음 파란색 옆에 있는 보드는

248
00:09:09,240 --> 00:09:11,120
실제 신용

249
00:09:11,120 --> 00:09:13,240
카드 크기이고 음 그들이 최근에 만든 뇌 척도 버전인데 꽤

250
00:09:13,240 --> 00:09:14,399


251
00:09:14,399 --> 00:09:16,920
멋지다고 생각했는데 음 그리고

252
00:09:16,920 --> 00:09:18,399
그 공간에 큰 플레이어도 몇 명 있어서

253
00:09:18,399 --> 00:09:21,000
그래서  여기 파란색은 Intel의

254
00:09:21,000 --> 00:09:23,640
Loi 칩입니다. lii 2에 있는 것은

255
00:09:23,640 --> 00:09:25,480
그들의 뉴로모픽 칩이고 그들은

256
00:09:25,480 --> 00:09:27,000


257
00:09:27,000 --> 00:09:27,920


258
00:09:27,920 --> 00:09:29,480
오픈 소스 키를 촉진하기를 정말로 원하기 때문에 이를 위한 오픈 소스 소프트웨어 프레임워크도 가지고 있습니다.

259
00:09:29,480 --> 00:09:32,079


260
00:09:32,079 --> 00:09:34,040
센서도 존재하므로 중앙에 있는 이 작은 파란색

261
00:09:34,040 --> 00:09:35,000
것은 실제로

262
00:09:35,000 --> 00:09:36,800
뉴로모픽 카메라입니다. 이 정도 크기일 수도 있고

263
00:09:36,800 --> 00:09:40,040
음 그래서 그들은 우리의

264
00:09:40,040 --> 00:09:42,480
신경계가 빛과 같은 자극을 감지하는 방식을 재현하는 것을 목표로 합니다.

265
00:09:42,480 --> 00:09:44,880
예를 들어

266
00:09:44,880 --> 00:09:47,200
각 픽셀에 있는 뉴로모픽 카메라의 경우입니다.

267
00:09:47,200 --> 00:09:49,560
microsc 해상도로 독립적으로 작동하면

268
00:09:49,560 --> 00:09:52,120
내 GIF가 작동할 것입니다. 아,

269
00:09:52,120 --> 00:09:54,440
자, 각 픽셀이 작동하는 것을 볼 수 있습니다.

270
00:09:54,440 --> 00:09:56,680
꽤 멋지네요.

271
00:09:56,680 --> 00:09:58,760
기존 디지털 카메라에 비해

272
00:09:58,760 --> 00:10:00,120


273
00:10:00,120 --> 00:10:02,920
모션 성능이 향상되고 전력 소비가 낮아졌습니다.

274
00:10:02,920 --> 00:10:05,120
최근에는 뉴로모픽 코도 있었습니다.

275
00:10:05,120 --> 00:10:07,079
Intel의 제품은 꽤 멋졌는데,

276
00:10:07,079 --> 00:10:08,440


277
00:10:08,440 --> 00:10:10,959
음 단 한 번의 노출만으로 화학 물질의 냄새를 학습할 수 있었고, 음,

278
00:10:10,959 --> 00:10:12,480


279
00:10:12,480 --> 00:10:15,279
다른 사람이 가렸을 때에도 그 냄새를 식별할 수 있었고, 마지막으로

280
00:10:15,279 --> 00:10:17,959
이것은 iub라고 불리는 인간형 로봇입니다.

281
00:10:17,959 --> 00:10:19,240
실제로 카메라와

282
00:10:19,240 --> 00:10:21,200
같은 뉴로모픽 센서를 통합한

283
00:10:21,200 --> 00:10:24,000
다음 뉴로모픽 칩을

284
00:10:24,000 --> 00:10:27,000
스파나 두뇌 확장하여

285
00:10:27,000 --> 00:10:28,440
이와 같은 인간형 장치나

286
00:10:28,440 --> 00:10:30,560
드론과 같은 다른 장치에 통합한 다음

287
00:10:30,560 --> 00:10:31,839
실제로 구체화된

288
00:10:31,839 --> 00:10:34,200
뉴로모픽 시스템을 만들 수 있다는 것입니다.

289
00:10:34,200 --> 00:10:35,839
우리는 영국 셰필드에 있는 스마트 인터랙티브 기술 연구실에서 작업하고 있습니다.

290
00:10:35,839 --> 00:10:37,519


291
00:10:37,519 --> 00:10:40,320


292
00:10:40,480 --> 00:10:42,600
이 슬라이드는 뉴로모픽 컴퓨팅의

293
00:10:42,600 --> 00:10:43,959
잠재적인 응용 프로그램 중 일부를 강조하고 있습니다.

294
00:10:43,959 --> 00:10:45,480


295
00:10:45,480 --> 00:10:46,720
생각해 볼 때 매우 흥미롭다고 생각했기

296
00:10:46,720 --> 00:10:49,120
때문에 상황

297
00:10:49,120 --> 00:10:51,560
패턴 인식에 대한 이해 고급 감지 소수

298
00:10:51,560 --> 00:10:54,360
샷 학습  작업 전반에 걸쳐 일반화

299
00:10:54,360 --> 00:10:56,839
복잡한 의사 결정 설명 가능성

300
00:10:56,839 --> 00:10:59,519
및 두뇌 인터페이스 음 그래서 이러한 모든

301
00:10:59,519 --> 00:11:01,360
기술은 동적 환경에서

302
00:11:01,360 --> 00:11:03,399
인간 중심의 실시간 애플리케이션에 대해 생각할 때 정말 유익합니다.

303
00:11:03,399 --> 00:11:06,240


304
00:11:06,240 --> 00:11:07,839


305
00:11:07,839 --> 00:11:10,000
예를 들어 자율 주행 자동차와 같은 것 그리고 개인적으로 제 생각에는

306
00:11:10,000 --> 00:11:12,800
뉴로모픽 시스템 음  또한

307
00:11:12,800 --> 00:11:14,360
뇌 컴퓨터 인터페이스의 미래 기반이 될 가능성이 높습니다.

308
00:11:14,360 --> 00:11:16,000
아마도

309
00:11:16,000 --> 00:11:17,959
제가 신경과학자이기 때문에 약간 편향되어 있을 것입니다. 하지만 음

310
00:11:17,959 --> 00:11:19,959
에너지가 낮고 실시간

311
00:11:19,959 --> 00:11:22,000
이며

312
00:11:22,000 --> 00:11:24,839
우리 하드웨어와 일치하는 아키텍처도 있으므로 우리는 그렇게 생각합니다.

313
00:11:24,839 --> 00:11:26,560
곧 BCI 분야가 특히 하드웨어와 잠수복의 하이브리드에 의해

314
00:11:26,560 --> 00:11:28,680
뉴로모픽 시스템에 의해 촉매되는 것을 보게 될 것입니다.

315
00:11:28,680 --> 00:11:29,480


316
00:11:29,480 --> 00:11:31,360


317
00:11:31,360 --> 00:11:33,680
그래서 아마도 잠재적으로

318
00:11:33,680 --> 00:11:35,800
사람들 자신의 것을 포함할 수도 있을 것입니다. 음

319
00:11:35,800 --> 00:11:37,399
당신은 실제로 유모 세포에서 자랄 수 있는 뇌 세포를 알고

320
00:11:37,399 --> 00:11:40,160


321
00:11:40,360 --> 00:11:43,040
있으며 우리 작업의 특별한 초점은 다음과

322
00:11:43,040 --> 00:11:45,160
같습니다.  인간과 유사한 방식으로 학습하는 AI를 설계하여

323
00:11:45,160 --> 00:11:47,120


324
00:11:47,120 --> 00:11:48,959
타고난 호기심을 갖고

325
00:11:48,959 --> 00:11:51,560
현실 세계와의 상호작용을 통해 학습하므로

326
00:11:51,560 --> 00:11:53,959
50년대에 Alan Turing은 성인의 마음을 시뮬레이션하는

327
00:11:53,959 --> 00:11:56,079
프로그램을 제작하려고 하는 대신 오히려

328
00:11:56,079 --> 00:11:58,519
어떻다고 말했습니다.

329
00:11:58,519 --> 00:12:00,360


330
00:12:00,360 --> 00:12:02,760
어린이의 뇌를 자극하는 것을 생산하려고 노력하십시오. 이것이

331
00:12:02,760 --> 00:12:04,560
적절한 교육 과정을 거친다면

332
00:12:04,560 --> 00:12:07,480
성인의 뇌를 얻게 될 것입니다. 이것은 제가 강조하고 싶었던

333
00:12:07,480 --> 00:12:09,360


334
00:12:09,360 --> 00:12:12,320
Ai 및 신경형 컴퓨팅에 대한 신경 발달 접근 방식 뒤에 숨은 철학입니다. 음

335
00:12:12,320 --> 00:12:13,800


336
00:12:13,800 --> 00:12:15,800


337
00:12:15,800 --> 00:12:17,839
저기  현장의 몇 가지 과제는

338
00:12:17,839 --> 00:12:19,839
매우 높은 수준이지만

339
00:12:19,839 --> 00:12:20,880


340
00:12:20,880 --> 00:12:23,760
이에 대한 약간의 아이디어를 제공하므로 스파이킹

341
00:12:23,760 --> 00:12:25,079
신경망을 훈련하는 것은 기존 신경망보다 더 복잡하며

342
00:12:25,079 --> 00:12:27,199


343
00:12:27,199 --> 00:12:28,560


344
00:12:28,560 --> 00:12:31,079
스파이킹 신경망 표준을 실제로 구현하는 하드웨어를 설계합니다.

345
00:12:31,079 --> 00:12:33,120
대규모 작업은 상당히

346
00:12:33,120 --> 00:12:35,120
어려운 일이며

347
00:12:35,120 --> 00:12:36,480


348
00:12:36,480 --> 00:12:38,959
이러한 기술과 같은 모든 기술을 실제로 효과적으로 활용할 수 있는 알고리즘을 개발하는 것입니다.

349
00:12:38,959 --> 00:12:41,440
따라서 하드웨어와 stdp는

350
00:12:41,440 --> 00:12:45,399
진행 중인 활성

351
00:12:45,399 --> 00:12:48,760
연구 영역이므로 음, 여기 계시다면

352
00:12:48,760 --> 00:12:50,959
아마도 활성 추론에 관심이 있으실 것입니다.

353
00:12:50,959 --> 00:12:52,560
저는 실제로

354
00:12:52,560 --> 00:12:53,839
누군가가 오늘 Discord에 올린 이

355
00:12:53,839 --> 00:12:55,839
연구 중 하나를 강조하고 싶었습니다. 꽤 멋진 연구 중 하나입니다. 그래서

356
00:12:55,839 --> 00:12:58,040
최근의 몇 가지 연구에서는

357
00:12:58,040 --> 00:12:59,560
신경모형 컴퓨팅과

358
00:12:59,560 --> 00:13:01,720
능동 추론의 원리를 결합하여 능동

359
00:13:01,720 --> 00:13:03,720
추론이 신경 과학에서 비롯되었으며 저는

360
00:13:03,720 --> 00:13:05,040
그것이 도움이 된다고 주장하고 싶습니다.

361
00:13:05,040 --> 00:13:06,600
뉴로모픽 아키텍처에 아주 잘 맞습니다. 음,

362
00:13:06,600 --> 00:13:08,760


363
00:13:08,760 --> 00:13:10,680
구체화된 뉴로모픽 지능에 관한 최근 논문에서

364
00:13:10,680 --> 00:13:12,320
활성

365
00:13:12,320 --> 00:13:14,279
추론은 실제로 언급하지 않았지만 바로 여기 상단에 있는 QR 코드는

366
00:13:14,279 --> 00:13:16,279
음, 만약 전체가

367
00:13:16,279 --> 00:13:18,079
뉴로모픽의 진정한 돌파구가

368
00:13:18,079 --> 00:13:19,959
일어날 것이라고 제안했습니다.  시스템 설계는

369
00:13:19,959 --> 00:13:21,839


370
00:13:21,839 --> 00:13:23,800


371
00:13:23,800 --> 00:13:25,199


372
00:13:25,199 --> 00:13:27,360
주변 환경의 추정과 로봇 자체 상태,

373
00:13:27,360 --> 00:13:30,240
의사 결정 계획 및 행동 사이의 긴밀한 플레이 방식을 갖춘 생물학적 계산 원리를 기반으로 하므로

374
00:13:30,240 --> 00:13:31,600
이러한 테마 중 일부는 능동적 추론 및 U

375
00:13:31,600 --> 00:13:32,839
에 관심이 있는 사람들에게 매우 친숙하게 들릴 수 있습니다.

376
00:13:32,839 --> 00:13:35,199


377
00:13:35,199 --> 00:13:36,959
추론은

378
00:13:36,959 --> 00:13:39,160
이러한 요구 사항을 충족하기에 적합하며

379
00:13:39,160 --> 00:13:40,600


380
00:13:40,600 --> 00:13:43,079
여기에서 몇 가지 최근 연구를 강조하고 싶었습니다. 왼쪽

381
00:13:43,079 --> 00:13:45,000
간달 FAL의 이 연구는 최근

382
00:13:45,000 --> 00:13:47,519


383
00:13:47,519 --> 00:13:50,240


384
00:13:50,240 --> 00:13:52,560
저자가 실험에서 제안한 능동 추론 원리를 사용하여 뉴로모픽 시스템에서 가소성과 신속한 비지도 학습을 보여주었습니다.

385
00:13:52,560 --> 00:13:53,800


386
00:13:53,800 --> 00:13:55,560


387
00:13:55,560 --> 00:13:58,759
신경 신경

388
00:13:58,759 --> 00:14:01,480
모픽 로봇 시스템에서 뇌와 같은 예측 기능을 구현하기 위해 채택되었으며 Kagan atal이

389
00:14:01,480 --> 00:14:03,000
여러분 중 일부에게 친숙할 수 있는 접시 프린(dish frin) 논문이 있었습니다.

390
00:14:03,000 --> 00:14:05,560


391
00:14:05,560 --> 00:14:08,399
따라서 이것은 저자가 주장한 하이브리드 음 잠수복 하드웨어 신경

392
00:14:08,399 --> 00:14:10,399
모픽 시스템이었습니다.

393
00:14:10,399 --> 00:14:12,759
시스템은 학습을

394
00:14:12,759 --> 00:14:14,480


395
00:14:14,480 --> 00:14:16,839
위한 자유 에너지 원리를 사용하여 탁구 게임의 빠른 부모 학습을 보여 주었고

396
00:14:16,839 --> 00:14:19,040
저자는

397
00:14:19,040 --> 00:14:20,720
시스템이 합성

398
00:14:20,720 --> 00:14:21,959
생물학적

399
00:14:21,959 --> 00:14:24,320
지능을 나타내므로

400
00:14:24,320 --> 00:14:25,920


401
00:14:25,920 --> 00:14:28,480
뉴로모픽 시스템에서 능동 영향 원리를 구현하는 분야는 매우 드물며

402
00:14:28,480 --> 00:14:31,199
이 mream 시리즈의 아이디어는 다음과 같습니다.  분야를 촉진하기 위해 지식 아이디어와 전문 지식을

403
00:14:31,199 --> 00:14:33,480
공유할 수 있는 공간과 커뮤니티를 만들기 위해

404
00:14:33,480 --> 00:14:36,079


405
00:14:36,079 --> 00:14:38,240
음 제 생각엔

406
00:14:38,240 --> 00:14:40,560
정말 흥미로운 기술적 도약이

407
00:14:40,560 --> 00:14:42,839
아마도 이 분야에서 나올 것이라고 생각합니다.

408
00:14:42,839 --> 00:14:44,880
제 어

409
00:14:44,880 --> 00:14:48,920
뉴로모픽 101 음과 다음

410
00:14:48,920 --> 00:14:51,880
단계에 대한 빠른 실행을 들어주셔서 감사합니다.  David의 말을 들을 테니 자기

411
00:14:51,880 --> 00:14:53,519
소개를 하고 싶으시면 David에게 연락주세요

412
00:14:53,519 --> 00:14:56,399
감사합니다

413
00:14:56,399 --> 00:14:59,639
Sarah 음

414
00:14:59,639 --> 00:15:02,320


415
00:15:03,320 --> 00:15:06,320
화면을 공유하겠습니다

416
00:15:10,820 --> 00:15:14,040
[음악]

417
00:15:14,040 --> 00:15:17,600
그래 이제 내 화면에서 프레젠테이션을 볼 수 있나요 그래 알았어

418
00:15:17,600 --> 00:15:21,240


419
00:15:21,240 --> 00:15:24,240
완벽해 알았어 안녕 내 이름은 입니다

420
00:15:24,240 --> 00:15:27,639
David kle 저는 봄음대학교 산하

421
00:15:27,639 --> 00:15:30,519
Institute for um M informatic의 연구원이자 쿠데타 리더입니다.

422
00:15:30,519 --> 00:15:33,839


423
00:15:33,839 --> 00:15:36,040
그래서 저는

424
00:15:36,040 --> 00:15:37,920
지속 가능한 기계 학습에 대한 그룹을 이끌고 있으며 우리는

425
00:15:37,920 --> 00:15:40,199
뉴로모픽 컴퓨팅에 매우 중점을 두고 있습니다.

426
00:15:40,199 --> 00:15:41,800


427
00:15:41,800 --> 00:15:44,360
오늘은

428
00:15:44,360 --> 00:15:47,279
Sarah가 했던 것과 매우 유사한 동기로 시작하겠습니다. 이는

429
00:15:47,279 --> 00:15:49,240


430
00:15:49,240 --> 00:15:51,959
이 강연에 정말 큰 영감이 되었습니다. 음 아마도

431
00:15:51,959 --> 00:15:54,560
여러분 대부분이 이 흥미로운

432
00:15:54,560 --> 00:15:57,120
최근 결과를 보셨을 것입니다. 독일을 의미하는 것은 아닙니다.

433
00:15:57,120 --> 00:15:59,120
농구 챔피언십에서 우승했지만

434
00:15:59,120 --> 00:16:03,880
음

435
00:16:03,880 --> 00:16:05,319


436
00:16:05,319 --> 00:16:07,079
지난 몇 년, 특히

437
00:16:07,079 --> 00:16:08,959
지난 2~3년 동안 우리가 본 인공 지능의 정말 큰 도약입니다. 이것은

438
00:16:08,959 --> 00:16:11,480


439
00:16:11,480 --> 00:16:14,360
doly 네트워크의 프롬프트에서 생성된 사진인데 정말 놀랍습니다.

440
00:16:14,360 --> 00:16:16,399


441
00:16:16,399 --> 00:16:18,519
불과 2년

442
00:16:18,519 --> 00:16:22,360
전만 해도 공상 과학 소설로 여겨졌는데 이것은 본질적으로 심층 신경망인

443
00:16:22,360 --> 00:16:24,120
뉴로모픽 접근 방식으로 가능해졌습니다. 이

444
00:16:24,120 --> 00:16:26,680


445
00:16:26,680 --> 00:16:28,079
심층 신경망은

446
00:16:28,079 --> 00:16:31,120
이제 거대해졌지만 이것도

447
00:16:31,120 --> 00:16:33,839
주의 사항이 있으므로 기본적으로 반대면은 다음과 같습니다.

448
00:16:33,839 --> 00:16:36,639
음 다른 문제 중에서도

449
00:16:36,639 --> 00:16:40,360
이 모델은 어 엄청난 양의 에너지를 소비할 수 있으므로

450
00:16:40,360 --> 00:16:43,959
음

451
00:16:43,959 --> 00:16:47,279
Dal 또는 제트 GPT와 같은 모델은 Sarah가 이미

452
00:16:47,279 --> 00:16:50,360
언급했듯이 음

453
00:16:50,360 --> 00:16:52,680


454
00:16:52,680 --> 00:16:56,759
집이나 자동차에 필적하는 에너지 예산을 소비할 것이므로 훈련 음 jgpt a

455
00:16:56,759 --> 00:16:59,440
한 번의 시간은 대략 1기가 시간과 같으

456
00:16:59,440 --> 00:17:02,680
므로 이는 300톤

457
00:17:02,680 --> 00:17:07,160
의 CO2 배출량이 될 것입니다. 음 그리고 여러 번은

458
00:17:07,160 --> 00:17:09,760


459
00:17:09,760 --> 00:17:13,359
일반 자동차의 수명보다 여러 배로 줄어들기 때문에

460
00:17:13,359 --> 00:17:15,280
분명히 두 가지 문제가 발생합니다. 어

461
00:17:15,280 --> 00:17:17,880
이것은 훈련을 이렇게 만듭니다.

462
00:17:17,880 --> 00:17:20,160
매우 소수의

463
00:17:20,160 --> 00:17:21,799
매우 큰 플레이어만 액세스할 수 있는 모델이므로 본질적으로

464
00:17:21,799 --> 00:17:24,599
거대 기술 회사이고 두 번째로 그리고

465
00:17:24,599 --> 00:17:26,319
아마도 더 중요한 것은 이것은

466
00:17:26,319 --> 00:17:29,160
어 제한된 자원을 가진 어 행성과 호환되지 않으므로

467
00:17:29,160 --> 00:17:31,880


468
00:17:31,880 --> 00:17:34,160
AI의 성장률이 지난 것처럼 계속된다면  몇

469
00:17:34,160 --> 00:17:35,360
년 안에 그것은

470
00:17:35,360 --> 00:17:38,240
어 20 30년까지 전 세계 에너지 소비의 133%를 소비할 것이고

471
00:17:38,240 --> 00:17:41,400


472
00:17:41,400 --> 00:17:45,080


473
00:17:45,080 --> 00:17:48,200
앞으로 5년 정도 지나면 기본적으로 교통 부문을 능가할 것입니다.

474
00:17:48,200 --> 00:17:50,720
따라서

475
00:17:50,720 --> 00:17:52,600
지속 가능한 기계 학습이 실제로 존재하는지에 대한 의문이 제기됩니다.

476
00:17:52,600 --> 00:17:55,080


477
00:17:55,080 --> 00:17:56,799
지속 가능한 기계

478
00:17:56,799 --> 00:17:59,039
학습 그룹에서 나는 그렇게 믿고

479
00:17:59,039 --> 00:18:01,799
있으며 그렇게 생각하는 이유는

480
00:18:01,799 --> 00:18:04,960
음 매우 효율적

481
00:18:04,960 --> 00:18:08,600
이고 아마도 Sarah가 20년경에 언급한 것처럼 소비하는 인간 두뇌인 이러한 AI 모델보다 여전히 더 나은 시스템을 알고 있기 때문입니다.

482
00:18:08,600 --> 00:18:11,039


483
00:18:11,039 --> 00:18:13,000


484
00:18:13,000 --> 00:18:14,039


485
00:18:14,039 --> 00:18:16,919
와트 어 하루에 바나나 4개 어

486
00:18:16,919 --> 00:18:21,400
그리고 어 그래서 오늘날 우리가 가지고 있는

487
00:18:21,400 --> 00:18:24,400
AI 모델보다 훨씬 더 효율적입니다

488
00:18:24,400 --> 00:18:26,200


489
00:18:26,200 --> 00:18:29,480
어 하지만 지금까지 우리는

490
00:18:29,480 --> 00:18:32,480
이러한 네트워크가 어떻게 작동하는지, 음,

491
00:18:32,480 --> 00:18:34,520
특히 네트워크를 훈련시키는 방법과

492
00:18:34,520 --> 00:18:37,080
기본적으로 우리의 네트워크가 어떻게 작동하는지 알지 못합니다.  우리의 목표는

493
00:18:37,080 --> 00:18:39,559
기계 학습의 메커니즘을 이전하는 것입니다.

494
00:18:39,559 --> 00:18:41,679
그래서 여기에 멋진 그림이 있습니다.

495
00:18:41,679 --> 00:18:44,679
어 기본적으로 우리는

496
00:18:44,679 --> 00:18:46,440
이미

497
00:18:46,440 --> 00:18:49,400
우리의 길을 알고 있는 기계 학습 사이트에서 시작합니다.

498
00:18:49,400 --> 00:18:51,280


499
00:18:51,280 --> 00:18:53,120
우리는 정말

500
00:18:53,120 --> 00:18:55,240
인상적인 결과를 얻었지만 그것들은

501
00:18:55,240 --> 00:18:57,480
효율적이지 않으며 우리는

502
00:18:57,480 --> 00:19:01,840
그것을 음 새롭고 효율적인 어 AI

503
00:19:01,840 --> 00:19:04,120
세대로 변환하고 싶습니다. 그리고 우리의 아이디어는

504
00:19:04,120 --> 00:19:07,520
신경과학에서 영감을 얻어 음 우선 이

505
00:19:07,520 --> 00:19:09,799
변환을 더 빠르고

506
00:19:09,799 --> 00:19:12,240
가능하게 만드는 것입니다.

507
00:19:12,240 --> 00:19:17,039
그렇군요 그리고 실제로는 생물학입니다

508
00:19:17,039 --> 00:19:19,679
훌륭한 영감의 원천이며 항상

509
00:19:19,679 --> 00:19:21,400
매우 놀라운 결과를 가지고 모퉁이를 돌며

510
00:19:21,400 --> 00:19:23,200


511
00:19:23,200 --> 00:19:24,960
제가 몇

512
00:19:24,960 --> 00:19:30,919
년 전에 우연히 발견한 결과 중 하나는 음 경찰의 능력이

513
00:19:30,919 --> 00:19:33,559


514
00:19:33,559 --> 00:19:35,200
뇌의 뉴런을 알고 있듯이 뇌에 경찰이 있다는 것입니다.

515
00:19:35,200 --> 00:19:36,159


516
00:19:36,159 --> 00:19:40,960
경찰과 연결되어 있는데 음 그런데 이걸 보면

517
00:19:40,960 --> 00:19:43,480


518
00:19:43,480 --> 00:19:45,919
2019년 논문이고 실제로

519
00:19:45,919 --> 00:19:47,320
개별 Sy ups를 식별할 수 있고

520
00:19:47,320 --> 00:19:49,400


521
00:19:49,400 --> 00:19:51,799
단일 전송처럼 시놉틱 릴리스를 만들도록 촉발할 수 있지만

522
00:19:51,799 --> 00:19:54,840
이걸 보면 음 음  이

523
00:19:54,840 --> 00:19:57,799
측정에서 이것이 실제로

524
00:19:57,799 --> 00:20:00,320
덮여 있고 노이즈가 있다는 것을 알 수 있으므로 기본적

525
00:20:00,320 --> 00:20:02,960
으로 이것에 대해 평균을 내고

526
00:20:02,960 --> 00:20:04,720
이것을 축소하면 여기에

527
00:20:04,720 --> 00:20:06,679
평균 흰색 선인 전형적인 시놉틱 흔적이 표시되지만 그

528
00:20:06,679 --> 00:20:09,240
아래에는

529
00:20:09,240 --> 00:20:12,080
이 거대한 소음이 표시됩니다.  정말

530
00:20:12,080 --> 00:20:14,960
몇 음 표준 편차를 위아래로 이동하는 것과 같습니다

531
00:20:14,960 --> 00:20:16,120


532
00:20:16,120 --> 00:20:18,640
음 그리고

533
00:20:18,640 --> 00:20:21,000
어 뉴런이

534
00:20:21,000 --> 00:20:23,480
아마도 에너지 소비 측면에서 신체에서 가장 비용이 많이 드는 단일 세포

535
00:20:23,480 --> 00:20:25,559
유형이라는 점을 고려하면 실제로 매우 놀랍습니다.

536
00:20:25,559 --> 00:20:28,840


537
00:20:28,840 --> 00:20:32,000


538
00:20:32,000 --> 00:20:34,159
그래서 당신은

539
00:20:34,159 --> 00:20:36,440


540
00:20:36,440 --> 00:20:38,720


541
00:20:38,720 --> 00:20:41,480
매우 비용이 많이 드는 뉴런 사이에 전달되는 이러한 전환이나 전달이

542
00:20:41,480 --> 00:20:43,480
매우 신뢰할 만할 것이라고 기대할 것입니다. 따라서

543
00:20:43,480 --> 00:20:46,120
이것은 매우 직관에 반하는 결과이며

544
00:20:46,120 --> 00:20:48,120


545
00:20:48,120 --> 00:20:50,039


546
00:20:50,039 --> 00:20:53,600
지금 꽤 오랫동안 신경과학자들을 혼란스럽게 해왔습니다. 음 그리고 거기에

547
00:20:53,600 --> 00:20:58,080
a 두 번째 음 수수께끼 같은 관찰 관찰이 있습니다.

548
00:20:58,080 --> 00:21:00,120


549
00:21:00,120 --> 00:21:03,919
어, 뉴런의 형태가

550
00:21:03,919 --> 00:21:05,480
다소 이렇게 보인다는 것입니다. 그래서 이것은

551
00:21:05,480 --> 00:21:08,159
여러분의 피질에 있는 전형적인 피라미드형 뉴런이 될 것입니다.

552
00:21:08,159 --> 00:21:09,039


553
00:21:09,039 --> 00:21:12,880
음 하지만 여러분은 이것이

554
00:21:12,880 --> 00:21:15,919
실제로 꽤 꽤 크고

555
00:21:15,919 --> 00:21:18,039
길쭉해서 이것은 인간의 뇌에서 최대 1밀리미터까지 들어갈 수 있습니다

556
00:21:18,039 --> 00:21:21,039
uh

557
00:21:21,039 --> 00:21:23,000
즉 가입이

558
00:21:23,000 --> 00:21:25,400
여기 어딘가에서 실행되면 uh 여기 아래에 있는

559
00:21:25,400 --> 00:21:27,200
세포체와 통신하는 데 매우 어려움을 겪게 되므로

560
00:21:27,200 --> 00:21:29,000


561
00:21:29,000 --> 00:21:33,240
여기에서 생성되는 전기 신호 uh  여기로 내려갈 수도

562
00:21:33,240 --> 00:21:35,440
있지만 여기 위에 있는 등록자들은

563
00:21:35,440 --> 00:21:38,480
어 세포체의 실제 전압을 측정할 방법이 없습니다.

564
00:21:38,480 --> 00:21:40,520
이곳은

565
00:21:40,520 --> 00:21:41,960
실제로 흥미로운 곳입니다.

566
00:21:41,960 --> 00:21:43,760
여기에는 활동 전위가 형성되어 있기 때문에

567
00:21:43,760 --> 00:21:46,039
등록자들이 실제로

568
00:21:46,039 --> 00:21:48,240
무엇인지 알고 싶어한다면

569
00:21:48,240 --> 00:21:50,120


570
00:21:50,120 --> 00:21:52,840
어 뉴런이 어떻게 행동하고

571
00:21:52,840 --> 00:21:55,400
세상과 어떻게 상호 작용하는지에 대해 예측할 수 있도록 세포체에서 진행됩니다. 이것은

572
00:21:55,400 --> 00:21:59,880


573
00:21:59,880 --> 00:22:02,120
신경 과학에서 이

574
00:22:02,120 --> 00:22:04,120
통신이 실제로

575
00:22:04,120 --> 00:22:07,320
단일 뉴런에서 어떻게 작동하는지에 대한 또 다른 매우 수수께끼 같은 공개 문제입니다.  세포체와

576
00:22:07,320 --> 00:22:10,720
어 그리고 신호 사이에는

577
00:22:10,720 --> 00:22:12,840
실제로 활동 전위가 다시

578
00:22:12,840 --> 00:22:14,880
위로 이동할 수 있다는 것이 알려져 있으므로 뉴런이 급증할

579
00:22:14,880 --> 00:22:18,000
때 일종의 이진 변수를 볼 수

580
00:22:18,000 --> 00:22:20,240
있지만 실제로

581
00:22:20,240 --> 00:22:23,799
여기 아래의 막 전위를 측정할 수는 없습니다.

582
00:22:23,799 --> 00:22:25,559
가장 눈에 띄는 전기

583
00:22:25,559 --> 00:22:27,159
신호는 실제로 이것을 통해 역전파될 수 있습니다

584
00:22:27,159 --> 00:22:29,120


585
00:22:29,120 --> 00:22:31,400
어 그리고 이것은

586
00:22:31,400 --> 00:22:33,000
가입이 실제로 세포체에서 무슨 일이

587
00:22:33,000 --> 00:22:34,799
일어나고 있는지에 대한 정보가 매우 희박하다는 것을 암시합니다.

588
00:22:34,799 --> 00:22:40,720
그리고 어 대부분의

589
00:22:40,720 --> 00:22:43,000
시놉시스 가소성 모델은

590
00:22:43,000 --> 00:22:44,159
이것을 전혀 다루지 않습니다.

591
00:22:44,159 --> 00:22:48,279
그리고 우리는 음, 이것이 어떻게 이루어지는지, 어,

592
00:22:48,279 --> 00:22:50,880
이 상호 작용이 어떻게 작동하는지, 뉴런의 중요한 상태에 대한 희박한 정보가 주어졌을 때

593
00:22:50,880 --> 00:22:52,760


594
00:22:52,760 --> 00:22:55,679
가입이 어떻게 유용한 학습 신호를 생성할 수 있는지 궁금했습니다.

595
00:22:55,679 --> 00:22:57,520


596
00:22:57,520 --> 00:23:00,200


597
00:23:00,200 --> 00:23:02,840
우리의 생각은 본질적으로

598
00:23:02,840 --> 00:23:04,480
이 두 가지 관찰이 이러한 높은 수준

599
00:23:04,480 --> 00:23:06,440
의  소음과 등록 그리고

600
00:23:06,440 --> 00:23:08,880
세포체와 등록 사이의 이 큰 거리는

601
00:23:08,880 --> 00:23:10,640
이러한 높은 불확실성을 제공한다고 말하며

602
00:23:10,640 --> 00:23:12,679
실제로는

603
00:23:12,679 --> 00:23:15,480
동일한 동전의 양면이므로 우리의 가설은

604
00:23:15,480 --> 00:23:18,840
음 실제로 우리가 이미 알고 있는 동일한 모델을 사용할 수 있다는 것이었습니다.

605
00:23:18,840 --> 00:23:22,880


606
00:23:22,880 --> 00:23:25,640
행동 수준에서 어 어

607
00:23:25,640 --> 00:23:29,559
에이전트가 어 어떻게 불확실성이 높은 환경에서 행동하고 수행할 수 있는지

608
00:23:29,559 --> 00:23:31,760
그리고

609
00:23:31,760 --> 00:23:33,400
우리는 이것을

610
00:23:33,400 --> 00:23:37,760
모든 가입에 적용하고 아

611
00:23:37,760 --> 00:23:40,120
오류가 있으므로 모든 가입은 이것을 기본적으로 활용해야 합니다

612
00:23:40,120 --> 00:23:44,559
음 이 동일한 모델

613
00:23:44,559 --> 00:23:47,679
과 어  이 모델은

614
00:23:47,679 --> 00:23:49,159
실제로

615
00:23:49,159 --> 00:23:51,919
종관 전송이

616
00:23:51,919 --> 00:23:54,320
시끄러워야 하며 이러한 수준의 소음이 환경

617
00:23:54,320 --> 00:23:56,880
에 대한 불확실성을 표현한다는 것을 즉시 제안합니다.

618
00:23:56,880 --> 00:23:59,640
그런 다음 우리는 이 모델을 사용하여

619
00:23:59,640 --> 00:24:02,080
음 학습 규칙을 도출할 수 있고

620
00:24:02,080 --> 00:24:04,600


621
00:24:04,600 --> 00:24:06,520
이를 생물학과 나란히 비교할 수 있습니다.  가장 먼저

622
00:24:06,520 --> 00:24:08,960
보여드리고 싶은 것은 음

623
00:24:08,960 --> 00:24:10,880
자유 에너지 모델에 대해 아주 간단하게 소개하겠습니다.

624
00:24:10,880 --> 00:24:13,720
어 왜냐하면 여러분 중 일부는 그다지

625
00:24:13,720 --> 00:24:15,720
익숙하지 않을 수도 있지만

626
00:24:15,720 --> 00:24:19,159
이것은 본질적으로 음 이와

627
00:24:19,159 --> 00:24:21,000
같은 상황을 설명하는 모델이기 때문입니다.

628
00:24:21,000 --> 00:24:23,279
어떤 환경과 상호 작용하는 사람이고

629
00:24:23,279 --> 00:24:25,039
여기서는 매우 간단하다고 가정했기

630
00:24:25,039 --> 00:24:28,320
때문에 이 사람은

631
00:24:28,320 --> 00:24:31,799
일부 Target에 공을 맞추려고 시도하고 인간으로서 우리는

632
00:24:31,799 --> 00:24:34,240
그러한 작업을 잘 해결하고

633
00:24:34,240 --> 00:24:36,039


634
00:24:36,039 --> 00:24:37,840
높은 수준이 있는 경우 그러한 작업을 해결하는 데도 능숙합니다.  이에 대한 불확실성이 있으므로

635
00:24:37,840 --> 00:24:41,960
그 사람이

636
00:24:41,960 --> 00:24:44,000
시각적인 피드백을 받을 수 있지만 이 피드백의 대부분이

637
00:24:44,000 --> 00:24:46,440
숨겨져 있을 수 있으므로 벽

638
00:24:46,440 --> 00:24:48,520
뒤에서 이런 일이 진행되는 것을 상상할 수 있고

639
00:24:48,520 --> 00:24:52,600
그 사람은 여전히 ​​이 공

640
00:24:52,600 --> 00:24:55,039
의 궤적이 무엇인지 예측하고 싶어할 수 있습니다.

641
00:24:55,039 --> 00:24:56,679


642
00:24:56,679 --> 00:25:00,960
올바른 행동을 할 수 있도록 목표물을 향해 날아가는 것입니다. 그래서

643
00:25:00,960 --> 00:25:03,960
우리는 이것에 몇 가지 변수를 할당할 것입니다. 어

644
00:25:03,960 --> 00:25:05,600
여기에 있는 이러한 상태는 기본적으로

645
00:25:05,600 --> 00:25:07,440
이 사람이 관찰할 수 있는 피드백을 가지고

646
00:25:07,440 --> 00:25:09,880
있고

647
00:25:09,880 --> 00:25:12,279
여기에서 날아가는 공의 관찰되지 않은 상태를 우리는 이렇게

648
00:25:12,279 --> 00:25:14,799
부릅니다.  U 사람이 직접 접근할 수 없는 경우

649
00:25:14,799 --> 00:25:17,000


650
00:25:17,000 --> 00:25:19,200
예를 들어 공이 벽 모서리에 있을 때 그 일부만 볼 수 있으며

651
00:25:19,200 --> 00:25:22,000


652
00:25:22,000 --> 00:25:25,000
uh 이를 본질적으로 모델링하거나

653
00:25:25,000 --> 00:25:28,200
이를 설명하려면 uh

654
00:25:28,200 --> 00:25:31,240
사람의 행동  어

655
00:25:31,240 --> 00:25:33,360
이 궤적에 대한 내부 설명이 있으므로

656
00:25:33,360 --> 00:25:37,520
이 상태의 내부 모델이 있습니다.

657
00:25:37,520 --> 00:25:41,480
어 그리고 이 모델은

658
00:25:41,480 --> 00:25:45,679
관찰된 피드백과 일치하도록 업데이트될 것이며

659
00:25:45,679 --> 00:25:48,120
이는

660
00:25:48,120 --> 00:25:50,200


661
00:25:50,200 --> 00:25:52,320
자유 에너지 원리의 아름다운 수학적 프레임워크에서 매우 훌륭하게 설명될 수 있습니다.

662
00:25:52,320 --> 00:25:55,159
아이디어는 본질적으로 음

663
00:25:55,159 --> 00:25:57,279
내부 상태의 모델을 설정하여

664
00:25:57,279 --> 00:26:00,720
본질적으로 음

665
00:26:00,720 --> 00:26:04,640
내부 상태와 음 환경 상태가

666
00:26:04,640 --> 00:26:06,440


667
00:26:06,440 --> 00:26:09,000
상호 작용하는 방식과 피드백 모델을 갖게 되어

668
00:26:09,000 --> 00:26:11,720
상태와

669
00:26:11,720 --> 00:26:14,240
피드백이 상호 작용하고 관찰하는 방식을 갖게 된다는 것입니다.

670
00:26:14,240 --> 00:26:18,559
본질적으로 당신은 음,

671
00:26:18,559 --> 00:26:21,080


672
00:26:21,080 --> 00:26:23,039
이

673
00:26:23,039 --> 00:26:24,679
내부 상태 모델과 이

674
00:26:24,679 --> 00:26:29,600
피드백 모델, 그리고 어 외부 상태 사이의 거리를 측정하는 손실 함수를 기록할 수 있습니다.

675
00:26:29,960 --> 00:26:31,720
음

676
00:26:31,720 --> 00:26:35,120
그리고 어 그러면 본질적으로

677
00:26:35,120 --> 00:26:37,799
둘 사이의 거리를 최소화함으로써 모든 것을 도출할 수 있습니다.

678
00:26:37,799 --> 00:26:41,799
관련된 행동 종류는

679
00:26:41,799 --> 00:26:44,799
음 예를 들어 학습과 같은 행동 관련 문제를 해결할 수

680
00:26:44,799 --> 00:26:46,679
있지만

681
00:26:46,679 --> 00:26:48,399


682
00:26:48,399 --> 00:26:50,399
어 예를 들어 좋은 행동이 무엇인지 알아내는 것과 같은 다른 용도로도 사용할 수 있습니다. 예를 들어

683
00:26:50,399 --> 00:26:53,440


684
00:26:53,440 --> 00:26:55,520
내부 상태와 행동 모두에 대해 추론하는

685
00:26:55,520 --> 00:26:58,440
것은 쉘입니다.  자유

686
00:26:58,440 --> 00:27:00,480
에너지 원리와 여기에 있는 이 개체는

687
00:27:00,480 --> 00:27:02,360


688
00:27:02,360 --> 00:27:04,760


689
00:27:04,760 --> 00:27:06,960
통계 물리학과도 일치하는 변이 자유 에너지로 알려져 있으며

690
00:27:06,960 --> 00:27:08,480
이것이 바로 이 프레임워크의

691
00:27:08,480 --> 00:27:11,640
이름이 유래된 곳이지만 여기에서는 모든 것이

692
00:27:11,640 --> 00:27:13,159
확률적이므로 본질적으로 다음과 같습니다.

693
00:27:13,159 --> 00:27:15,240


694
00:27:15,240 --> 00:27:17,320
내부 모델에 대한 두 가지 확률 함수 Q와

695
00:27:17,320 --> 00:27:19,640
상태와 관찰 사이의 상호 작용에 대한 P

696
00:27:19,640 --> 00:27:22,120
그리고 여기에 최소화하려는

697
00:27:22,120 --> 00:27:24,279
그들 사이의 거리 측정이 있으므로

698
00:27:24,279 --> 00:27:25,200


699
00:27:25,200 --> 00:27:27,799
이제 뉴런

700
00:27:27,799 --> 00:27:29,640
과 가입 및 그들이 각각과 상호 작용하는 방식을 살펴보면

701
00:27:29,640 --> 00:27:31,520
다른 하나는 매우 유사한

702
00:27:31,520 --> 00:27:35,440
그림을 찾았기 때문에 음

703
00:27:35,440 --> 00:27:38,520
여기 녹색으로 표시된 단일 가입에는 음

704
00:27:38,520 --> 00:27:41,120
내부 상태가 있으며 단순성

705
00:27:41,120 --> 00:27:45,080
모델에만 사용됩니다. 어 이것을 기반으로 하는 시놉틱 미끼로서

706
00:27:45,080 --> 00:27:46,960


707
00:27:46,960 --> 00:27:50,799
사전 광학 스파이크에 의해 트리거될 때 가입이 생성됩니다 음

708
00:27:50,799 --> 00:27:53,200
포스트 시놉틱 전류는 컵에서 너무 멀리 떨어져 있기 때문에 직접 관찰

709
00:27:53,200 --> 00:27:56,320


710
00:27:56,320 --> 00:27:57,760
할 수 없는 외부 상태인 Som으로 전파됩니다.

711
00:27:57,760 --> 00:27:59,799


712
00:27:59,799 --> 00:28:02,640
그러나 우리는 이 이진 변수인 활동 전위를 전파하는 피드백을 볼 수 있습니다.

713
00:28:02,640 --> 00:28:04,279


714
00:28:04,279 --> 00:28:05,880


715
00:28:05,880 --> 00:28:07,200


716
00:28:07,200 --> 00:28:09,840
뉴런이 급증했는지 여부를 알려주므로

717
00:28:09,840 --> 00:28:12,120
우리가

718
00:28:12,120 --> 00:28:13,679
그렇게 적어서

719
00:28:13,679 --> 00:28:18,200
동일한 수학을 사용하여 문제를 해결할 수 있다면 이것은 정확히 동일한 프레임워크입니다.

720
00:28:18,200 --> 00:28:21,159


721
00:28:21,159 --> 00:28:24,320
몇 가지 음, 우리는

722
00:28:24,320 --> 00:28:25,960
몇 가지 가정을 해야 하기 때문에 어 여기

723
00:28:25,960 --> 00:28:28,279
이 사람에 대한 모델을 작성해야 합니다.

724
00:28:28,279 --> 00:28:32,240
그래서 이 어

725
00:28:32,240 --> 00:28:35,880
피드백과 외부 상태가 어떻게

726
00:28:35,880 --> 00:28:38,159
상호 작용하는지에 대한 모델은 어 하지만 우리는 이에 대한 매우 좋은 모델을 가지고 있습니다.

727
00:28:38,159 --> 00:28:40,519
이것은 수년에 걸쳐 연구되었기

728
00:28:40,519 --> 00:28:43,120
때문에 여기서 모델 뉴런이 어떻게 일반적으로 행동하는지 볼 수 있습니다. 음

729
00:28:43,120 --> 00:28:45,880


730
00:28:45,880 --> 00:28:47,440
누출된 통합 화재 뉴런의 막 전위가 있고

731
00:28:47,440 --> 00:28:49,120


732
00:28:49,120 --> 00:28:51,159
이것은 단지 어 위아래로 이동하므로

733
00:28:51,159 --> 00:28:53,720
이 뉴런은 어  많은

734
00:28:53,720 --> 00:28:56,440
전시각 입력과 노이즈도 있고

735
00:28:56,440 --> 00:28:57,679
결국 어느 시점에서 임계

736
00:28:57,679 --> 00:28:59,640
값에 도달하면 스파이크가 생성되어

737
00:28:59,640 --> 00:29:01,760


738
00:29:01,760 --> 00:29:04,279
다운스트림 뉴런으로 이동하고 컵으로 다시 돌아가는 Z가 됩니다.

739
00:29:04,279 --> 00:29:07,120
어 그런 다음

740
00:29:07,120 --> 00:29:12,159
재설정됩니다 어 그렇군요 음 하지만 지금은  이것은 어, 그래서

741
00:29:12,159 --> 00:29:13,799
우리가 이것을 수학적으로 적을 수 있는 것은

742
00:29:13,799 --> 00:29:16,399
매우 간단한 음 미분방정식

743
00:29:16,399 --> 00:29:19,039
이지만 어 뉴런은

744
00:29:19,039 --> 00:29:21,360
이 상태에 다시 접근할 수 없기 때문에 다시

745
00:29:21,360 --> 00:29:24,440
이 벽 뒤에 있습니다. 스파이크 이벤트만 볼

746
00:29:24,440 --> 00:29:26,440
수 있지만 실제로는 다음과 같은 간단한 경우에 대해 할 수 있습니다.

747
00:29:26,440 --> 00:29:28,320
실제로 통합된 F 뉴런 우리는

748
00:29:28,320 --> 00:29:30,399
이것을 분석적으로 해결할 수 있으므로

749
00:29:30,399 --> 00:29:32,240


750
00:29:32,240 --> 00:29:34,559
스파이크 시간이 주어졌을 때 막 전위의 사후 분포가

751
00:29:34,559 --> 00:29:37,480
무엇인지 기록할 수 있습니다. 그리고 여기서 나오는 것은

752
00:29:37,480 --> 00:29:40,240
실제로 소위 음 확률론적

753
00:29:40,240 --> 00:29:44,159
브리지 모델입니다. 또는 이 경우에는 어

754
00:29:44,159 --> 00:29:45,960
화재 뉴런의 누출 적분은

755
00:29:45,960 --> 00:29:48,240
오랑우탄 브리지 모델이므로

756
00:29:48,240 --> 00:29:51,200
분석적으로 기록할 수 있고 이 U는

757
00:29:51,200 --> 00:29:53,880
간단하지는 않지만 실행

758
00:29:53,880 --> 00:29:56,760
가능하다는 뜻입니다 어 그리고 우리는 이것을 직접 사용할 수 있으므로

759
00:29:56,760 --> 00:29:59,799
이 모델은 어

760
00:29:59,799 --> 00:30:02,279
다시 기록해야 합니다  이것은 어 자유 에너지

761
00:30:02,279 --> 00:30:04,440
기능이므로 여기에서

762
00:30:04,440 --> 00:30:06,600
가입이 실제로 시놉시스 후 전류를 생성하는 방법

763
00:30:06,600 --> 00:30:08,600
과

764
00:30:08,600 --> 00:30:11,000
뉴런에 통합되는 방법을 가정합니다. 그러나

765
00:30:11,000 --> 00:30:12,840
이는 또한 The Leaky

766
00:30:12,840 --> 00:30:14,799
통합 화재 뉴런과 실제로

767
00:30:14,799 --> 00:30:17,760
가입이 생성하는 확률론적 음 입력에 의해 제공됩니다.

768
00:30:17,760 --> 00:30:20,120
따라서 단순성을 위해

769
00:30:20,120 --> 00:30:22,919
여기서는 기본적으로 가우스 무작위 변수를 그려 주입하는 가우스 Sy upses만 가정하고

770
00:30:22,919 --> 00:30:25,559


771
00:30:25,559 --> 00:30:27,960
이를 주입하여

772
00:30:27,960 --> 00:30:30,399
뉴런을 점화하고 이러한 모든

773
00:30:30,399 --> 00:30:31,960
요소를 ​​실제로 닫힌 형식으로 풀 수

774
00:30:31,960 --> 00:30:33,640
있으며

775
00:30:33,640 --> 00:30:35,720
다음과 같은 학습 규칙을 도출할 수 있습니다.  이제 이 사전 에너지 기능을 최소화합니다

776
00:30:35,720 --> 00:30:37,640


777
00:30:37,640 --> 00:30:40,720
어 그리고 우리가 그렇게 하면 음

778
00:30:40,720 --> 00:30:44,279
어 이것은 많은 좋은 특성을 가지고 있습니다.

779
00:30:44,279 --> 00:30:46,279
왜냐하면 이 Onin lbeck

780
00:30:46,279 --> 00:30:48,480
브리지는 가정에 의해 완전히 결정되기 때문입니다.

781
00:30:48,480 --> 00:30:51,480
어 역전파 활동 전위에 의해

782
00:30:51,480 --> 00:30:54,480
기본적으로

783
00:30:54,480 --> 00:30:57,000
시놉틱 후 음 스파이크의 시간은

784
00:30:57,000 --> 00:30:57,310


785
00:30:57,310 --> 00:30:58,519
[음악]

786
00:30:58,519 --> 00:31:01,760
뉴런에 도달 음 우리가 얻는 이 모양은 인접한

787
00:31:01,760 --> 00:31:03,440
두 개의 시신경

788
00:31:03,440 --> 00:31:04,760
후

789
00:31:04,760 --> 00:31:08,519
스파이크에만 의존합니다 음 이는 우리가 자동으로 여기에 도달한다는 것을 의미합니다

790
00:31:08,519 --> 00:31:10,720
uh

791
00:31:10,720 --> 00:31:12,880
이와 같은 학습 규칙이므로 학습 규칙은

792
00:31:12,880 --> 00:31:15,480


793
00:31:15,480 --> 00:31:17,320
두 시시후 스파이크 사이의 차이에만 의존합니다  우리는 여기서

794
00:31:17,320 --> 00:31:18,159
Delta

795
00:31:18,159 --> 00:31:22,960
T2라고 부릅니다. 음 그리고 어

796
00:31:22,960 --> 00:31:25,159
시놉틱 후 스파이크와 시놉시스 전 측면의

797
00:31:25,159 --> 00:31:27,240
특정 지점에서 트리거되는 실제 입력 사이의 차이 어

798
00:31:27,240 --> 00:31:29,120


799
00:31:29,120 --> 00:31:32,720
그리고 우리는 기본적으로 여기서

800
00:31:32,720 --> 00:31:35,919
이 조회 테이블을 만들 수 있고 어 단지 어 단지

801
00:31:35,919 --> 00:31:38,200
무엇이 될지 계산할 수 있습니다.

802
00:31:38,200 --> 00:31:40,960
이러한 가입이 자유 에너지 원리

803
00:31:40,960 --> 00:31:42,840
측면에서 최적으로 학습할 수 있도록 업데이트해야 하며

804
00:31:42,840 --> 00:31:44,760
이것이

805
00:31:44,760 --> 00:31:46,279
우리가 내보내는 모양입니다.

806
00:31:46,279 --> 00:31:47,679


807
00:31:47,679 --> 00:31:49,440
시놉틱 후 발사 속도에 강한 의존성이 있지만

808
00:31:49,440 --> 00:31:52,720
기본적으로 다음에도 의존한다는 것을 알 수 있습니다.

809
00:31:52,720 --> 00:31:55,880
Sarah가 이전에 언급한 이 전형적인 STP 어 시준

810
00:31:55,880 --> 00:31:57,639
전 스파이크의 상대적 위치는 무엇입니까

811
00:31:57,639 --> 00:31:59,080


812
00:31:59,080 --> 00:32:02,440
? 간단히 말해서 이 모델은

813
00:32:02,440 --> 00:32:04,760
이제 본질적으로 두 개의

814
00:32:04,760 --> 00:32:08,279
경로로 분할될 수 있으므로 기본적으로 시전 스파이크가 있을 때마다 이 atoc 응답을 갖게 됩니다.

815
00:32:08,279 --> 00:32:11,000


816
00:32:11,000 --> 00:32:13,880


817
00:32:13,880 --> 00:32:16,080
그는 이 토론 분포에서 끌어낸 컵에서 작업을 촉발

818
00:32:16,080 --> 00:32:18,039
하고 이를

819
00:32:18,039 --> 00:32:21,799
음 뉴런에 주입한 다음

820
00:32:21,799 --> 00:32:22,880


821
00:32:22,880 --> 00:32:25,480


822
00:32:25,480 --> 00:32:28,720
가입이 음 이 오랑우탄과 웬크 브리지에서 찾아볼 수 있는 포스트 토크 어 업데이트가 있습니다.

823
00:32:28,720 --> 00:32:30,360


824
00:32:30,360 --> 00:32:33,600


825
00:32:33,600 --> 00:32:35,679
생성했어야 하는 최적의 출력, 즉

826
00:32:35,679 --> 00:32:38,559
최적의 동작이 무엇이었을지 그리고 이 자유 에너지 원리에 따라

827
00:32:38,559 --> 00:32:40,320
실제 동작과 이 최적의 동작을 비교한

828
00:32:40,320 --> 00:32:41,880


829
00:32:41,880 --> 00:32:44,880
다음 시놉틱 가중치

830
00:32:44,880 --> 00:32:47,360
의 업데이트인 지연된 응답 응답을 생성합니다.

831
00:32:47,360 --> 00:32:49,399


832
00:32:49,399 --> 00:32:52,159
그리고 중요하게도 이 어

833
00:32:52,159 --> 00:32:54,519
내부 모델은 암묵적으로만

834
00:32:54,519 --> 00:32:57,960
인코딩되어 있으므로 음 어 스파이크

835
00:32:57,960 --> 00:33:00,399
시간 의존 가소성

836
00:33:00,399 --> 00:33:02,880
규칙 어 그럼 이 규칙은 어떻게 보이고

837
00:33:02,880 --> 00:33:04,639


838
00:33:04,639 --> 00:33:07,360
생물학과 비교되는지 그리고 어 실제로는

839
00:33:07,360 --> 00:33:09,240
적합합니다  이것이 어떤 가정도 하지 않고

840
00:33:09,240 --> 00:33:11,519
실제로 첫 번째 원리에서 도출되었다는 점을 고려하면

841
00:33:11,519 --> 00:33:13,880
이것은

842
00:33:13,880 --> 00:33:16,320
생물학의 측정입니다. 이것은

843
00:33:16,320 --> 00:33:20,279
음 Al 규칙 B의 B이고 아주 오래된

844
00:33:20,279 --> 00:33:23,279
작업에서 실제로 이 작업을 수행한 곳은 어,

845
00:33:23,279 --> 00:33:26,519


846
00:33:26,519 --> 00:33:29,120
주입된 물질을 측정한 vro 연구에서였습니다.  시놉틱 전후에 음 스파이크가 발생

847
00:33:29,120 --> 00:33:30,880
하고

848
00:33:30,880 --> 00:33:32,679
경찰의 체중 변화가 무엇인지 측정했습니다. 이것이

849
00:33:32,679 --> 00:33:35,320
우리 모델에 의해 예측되는 규칙이며

850
00:33:35,320 --> 00:33:37,799
적어도

851
00:33:37,799 --> 00:33:39,559
1차 근사에서는

852
00:33:39,559 --> 00:33:42,080
매우 유사한 모양을 제공한다는 것을 알 수 있습니다.  또한

853
00:33:42,080 --> 00:33:43,519


854
00:33:43,519 --> 00:33:48,120
음 가입자들은

855
00:33:48,120 --> 00:33:51,840
음 시운전 전 스파이크 시간에 가까울 때 가장 많이 변경하기를 원하기 때문에 의미가 있습니다.

856
00:33:51,840 --> 00:33:54,559


857
00:33:54,559 --> 00:33:56,039
왜냐하면 이것이

858
00:33:56,039 --> 00:33:57,919
시신경 후 스파이크 시간이기 때문입니다. 왜냐하면 이것이

859
00:33:57,919 --> 00:34:00,240
상태에 대해 가장 잘 아는 곳이기 때문입니다.

860
00:34:00,240 --> 00:34:02,159
PO 뉴런의 자유 에너지

861
00:34:02,159 --> 00:34:05,600
원리는 실제로 어 이런 종류의 원뿔을 제안할 것입니다.

862
00:34:05,600 --> 00:34:07,639


863
00:34:07,639 --> 00:34:11,359
U 음 기본적으로 거의 가정이 없지만 어

864
00:34:11,359 --> 00:34:14,199
우리는 또한 1차가 아니기 때문에 얻습니다. 어

865
00:34:14,199 --> 00:34:17,719


866
00:34:17,719 --> 00:34:20,199
스파이크 시간 종속 가소성 규칙이지만

867
00:34:20,199 --> 00:34:21,480
어 우리는 또한 다음과 같은 의존성을 갖습니다.  수술 후

868
00:34:21,480 --> 00:34:24,119
발사 속도를

869
00:34:24,119 --> 00:34:26,280
다른 결과와 비교할 수도 있습니다. 이것은

870
00:34:26,280 --> 00:34:29,119
gr과 Brunel이 작성한 오래된 것입니다. 그래서 이것은

871
00:34:29,119 --> 00:34:31,159
실제로 모델이지만 음, 음, 어, 시력

872
00:34:31,159 --> 00:34:35,839


873
00:34:35,839 --> 00:34:37,679
전 및 후

874
00:34:37,679 --> 00:34:41,280
발사 속도를 기반으로 한 가소성을 설명하는 것이 매우 상세했습니다.  가입에서

875
00:34:41,280 --> 00:34:42,960
이것이 우리 모델이 예측하는 것입니다. 따라서

876
00:34:42,960 --> 00:34:44,639
만약 우리가 무작위 사전 및 사후 시놉틱 팝픽 트라 어

877
00:34:44,639 --> 00:34:47,359
기차에

878
00:34:47,359 --> 00:34:50,040
다른 비율을 주입한다면 우리 모델은

879
00:34:50,040 --> 00:34:52,639
이 모양을 예측할 것입니다. 이는 다시 완벽하게 일치하지는 않지만

880
00:34:52,639 --> 00:34:55,440
이것이 매우

881
00:34:55,440 --> 00:34:58,359
이상적인 모델이라는 점을 고려하면 실제로는  최소한

882
00:34:58,359 --> 00:35:01,880
어

883
00:35:01,880 --> 00:35:04,160
시신경 후의 낮은 발화율이

884
00:35:04,160 --> 00:35:07,560
우울증으로 이어지고 음 강화가 더 높다는 주요 특징은

885
00:35:07,560 --> 00:35:10,440
음 이것에 반영되어 있습니다

886
00:35:10,440 --> 00:35:14,240
알겠습니다 어 아직 10분 남았을 것 같아요 알겠습니다 음

887
00:35:14,240 --> 00:35:19,520


888
00:35:19,520 --> 00:35:21,320
빠른 중간 요약을 말씀드리고 그 다음에는

889
00:35:21,320 --> 00:35:23,400


890
00:35:23,400 --> 00:35:27,320
이제 이것을 실제로

891
00:35:27,320 --> 00:35:29,040
기계 학습

892
00:35:29,040 --> 00:35:32,440
모델에 적용하는 다른 작업을 보여주고 싶습니다. 음 여기서 우리가 본 것은

893
00:35:32,440 --> 00:35:36,760
음 Sy upses가 실제로 음

894
00:35:36,760 --> 00:35:39,240
매우 확률론적이라는 것입니다. 이것은 매우

895
00:35:39,240 --> 00:35:42,599
큰 퍼즐이었고 우리는 제안합니다

896
00:35:42,599 --> 00:35:44,160
실제로

897
00:35:44,160 --> 00:35:47,680
음 어 시냅스 잡음이

898
00:35:47,680 --> 00:35:50,920
실제로 가입이라는 것은 음

899
00:35:50,920 --> 00:35:52,640


900
00:35:52,640 --> 00:35:54,079
환경이

901
00:35:54,079 --> 00:35:57,560
실제로 음 POS 시놉틱 뉴런이고

902
00:35:57,560 --> 00:36:00,119


903
00:36:00,119 --> 00:36:02,160
자유 에너지 원리의 방식으로 이것과 상호 작용하는 환경에 대한 자체 불확실성을 보고하는 방식입니다.

904
00:36:02,160 --> 00:36:03,880
포스트 시놉틱 뉴런 또는 그것은

905
00:36:03,880 --> 00:36:06,720
그것을 설명하는 아주 좋은 방법이고 어

906
00:36:06,720 --> 00:36:09,400
더 관심이 있다면

907
00:36:09,400 --> 00:36:13,480
미리 인쇄된 논문이 있습니다. 이 모든 내용을 읽을 수 있습니다. 음

908
00:36:13,480 --> 00:36:16,359
그러면 이것이 이제

909
00:36:16,359 --> 00:36:19,440
뉴로모픽과 어떻게 연결되고 실제로

910
00:36:19,440 --> 00:36:21,160
우리는  실제로 뉴로모픽 하드웨어를 수행하는 것이 아니라

911
00:36:21,160 --> 00:36:23,400
뉴로모픽 알고리즘을 수행하고 있으므로

912
00:36:23,400 --> 00:36:25,920


913
00:36:25,920 --> 00:36:27,480
이제 이러한 영감을 실제 기계

914
00:36:27,480 --> 00:36:30,319
학습 모델에 적용하려고 노력하고 있으며 이것이 음 기계 학습에서 잘 알려진 문제를

915
00:36:30,319 --> 00:36:33,920
해결하는 데 좋은 공격 각도가 될 수 있다고 생각했습니다.

916
00:36:33,920 --> 00:36:35,599


917
00:36:35,599 --> 00:36:40,880
저는 그냥 음 어 예

918
00:36:40,880 --> 00:36:43,640
여기에 다양한 컨볼루셔널 레이어가 포함된 아주 간단한 음 컨벌루션

919
00:36:43,640 --> 00:36:45,440
신경망을 그렸습니다.

920
00:36:45,440 --> 00:36:48,079
그런 다음

921
00:36:48,079 --> 00:36:49,839
기계 학습 알고리즘에 있을 수 있는 조밀한 레이어가

922
00:36:49,839 --> 00:36:52,760
있고 이것이

923
00:36:52,760 --> 00:36:54,599
훈련되는 방식은 여러분 중 많은 분들이 아시다시피

924
00:36:54,599 --> 00:36:57,400
끝났을 것 같습니다.  endend 및 arrowback

925
00:36:57,400 --> 00:36:59,480
전파를 수행하려면

926
00:36:59,480 --> 00:37:02,119
입력과 어 목표가 있는 훈련 세트가 있어야 합니다.

927
00:37:02,119 --> 00:37:04,079
예를 들어

928
00:37:04,079 --> 00:37:06,920
분류 작업에서 이것은

929
00:37:06,920 --> 00:37:08,680
고양이와 개 사진이 될 수 있고

930
00:37:08,680 --> 00:37:12,440
U 클래스 레이블인 목표가 있을 것입니다.

931
00:37:12,440 --> 00:37:15,160
그래서 일부에는 실제로

932
00:37:15,160 --> 00:37:17,119
인공 뉴런이 있고

933
00:37:17,119 --> 00:37:18,640
이 뉴런 중 일부는 고양이에게 활성화될 수

934
00:37:18,640 --> 00:37:20,240
있고 다른 하나는 개에게 활성화될 수 있습니다.

935
00:37:20,240 --> 00:37:23,440
음 그리고 훈련에서 데이터는

936
00:37:23,440 --> 00:37:25,400
정확히 이러한 레이블을 가지고 있습니다. 음

937
00:37:25,400 --> 00:37:27,119


938
00:37:27,119 --> 00:37:29,319
앉아서 작업을 하고 있던 인간에 의해 생성된 것입니다.  이것을 직접 수행한 다음

939
00:37:29,319 --> 00:37:32,119
훈련하는 동안 이

940
00:37:32,119 --> 00:37:34,520


941
00:37:34,520 --> 00:37:37,040
입력을 입력

942
00:37:37,040 --> 00:37:39,760
레이어에서 출력 레이어까지 전파하여 네트워크에 이 예를 표시합니다. 그런 다음

943
00:37:39,760 --> 00:37:42,560
출력은 여기서

944
00:37:42,560 --> 00:37:44,960
핸드 라벨 대상과 비교되고 다음

945
00:37:44,960 --> 00:37:47,000
사이의 불일치가 발생합니다.  두 개는

946
00:37:47,000 --> 00:37:48,839
이 모든 레이어를 통해 입력으로 다시 전파되고

947
00:37:48,839 --> 00:37:52,000


948
00:37:52,000 --> 00:37:54,720
여기 어

949
00:37:54,720 --> 00:37:57,160
사이에 어 이 레이어 내부에 있는 모든 가중치 또는 시놉틱 가중치가 그에

950
00:37:57,160 --> 00:37:58,960
따라 업데이트되어

951
00:37:58,960 --> 00:38:01,560
이 작업을 여러 번 수행한 후에 어

952
00:38:01,560 --> 00:38:03,920
이 네트워크가 말하기에 적합해집니다.

953
00:38:03,920 --> 00:38:05,560
C 부분은

954
00:38:05,560 --> 00:38:08,520
문제가 있습니다. 이

955
00:38:08,520 --> 00:38:10,359
알고리즘은 실제로 훌륭하게 작동하며

956
00:38:10,359 --> 00:38:12,960


957
00:38:12,960 --> 00:38:15,480
D 또는 J gbt와 같이 우리가 이야기한 모든 모델의 기초이지만

958
00:38:15,480 --> 00:38:18,520
매우 비효율적이며

959
00:38:18,520 --> 00:38:20,280
문제는 이것이

960
00:38:20,280 --> 00:38:22,880
문학은 잠금 문제이므로

961
00:38:22,880 --> 00:38:25,480
이 네트워크를

962
00:38:25,480 --> 00:38:27,560
이전에 이미 했던 블록으로 분할한다면

963
00:38:27,560 --> 00:38:30,839
이는 임의적이지만 소프트웨어 알고리즘

964
00:38:30,839 --> 00:38:32,400
측면에서 이를 효율적으로 구현하기 위해 그렇게

965
00:38:32,400 --> 00:38:34,000


966
00:38:34,000 --> 00:38:36,520
하는 것이 흥미로울 수 있으며 이제

967
00:38:36,520 --> 00:38:39,160
다음을 원할 것입니다.  블록은 이상적으로는

968
00:38:39,160 --> 00:38:41,560
병렬로 실행되어 기본적으로 어

969
00:38:41,560 --> 00:38:44,359
첫 번째 예를 보여주고 어 이

970
00:38:44,359 --> 00:38:46,440
첫 번째 블록에 대해 이미 훈련한 다음

971
00:38:46,440 --> 00:38:48,839
두 번째 음 블록이 다른 작업을 수행하는 동안 이미 훈련할 수

972
00:38:48,839 --> 00:38:50,760
있지만

973
00:38:50,760 --> 00:38:52,800
음 엔드투엔드 역

974
00:38:52,800 --> 00:38:54,440
전파에서는 실제로 불가능합니다.  이 잠금 문제로 인해

975
00:38:54,440 --> 00:38:57,200


976
00:38:57,200 --> 00:38:58,800
두 번째 블록의 활성화는 첫 번째 블록의 활성화에 따라 달라지므로

977
00:38:58,800 --> 00:39:00,319


978
00:39:00,319 --> 00:39:02,720
이를 끝까지 전파해야 하고

979
00:39:02,720 --> 00:39:04,319
이 오류를 계산한 다음

980
00:39:04,319 --> 00:39:06,680
다시 전파하고 이 작업이 완료된 경우에만 가능합니다.

981
00:39:06,680 --> 00:39:09,520
어, 다음 에포크를 시작할 수 있습니다.

982
00:39:09,520 --> 00:39:14,359
여기서 새로운

983
00:39:14,359 --> 00:39:17,040
예를 보여줍니다. 어 그리고

984
00:39:17,040 --> 00:39:20,319
이 모든 시간 동안 여기에서

985
00:39:20,319 --> 00:39:23,319
이 첫 번째 블록을 실행할 3인조가 아마도 어

986
00:39:23,319 --> 00:39:25,520
유휴 상태이고 항상 기다려야 한다는 것을 알 수 있습니다.

987
00:39:25,520 --> 00:39:28,079
이것은 분명히 그것들을 매우

988
00:39:28,079 --> 00:39:30,040
비효율적으로 만들고 이제 우리의 생각은

989
00:39:30,040 --> 00:39:33,000
기본적으로 우리가 이 자유 에너지 원리에 대해 가입이

990
00:39:33,000 --> 00:39:36,680
어떻게 장거리에 걸쳐 통신하는지에 대한 이전 모델에서 배운 것을 사용하고

991
00:39:36,680 --> 00:39:39,440


992
00:39:39,440 --> 00:39:42,079


993
00:39:42,079 --> 00:39:43,920
또한 그것을 깊은 뉴런에만 적용한다는 것이었습니다.

994
00:39:43,920 --> 00:39:46,200
여기에 다시 있는 네트워크 및 아이디어는

995
00:39:46,200 --> 00:39:49,040
기본적으로 이미

996
00:39:49,040 --> 00:39:50,880


997
00:39:50,880 --> 00:39:54,800
음 일부 출력에 대한 이 세대의 입력을 가지고

998
00:39:54,800 --> 00:39:57,960
있지만

999
00:39:57,960 --> 00:39:59,440
자유 에너지 원리에 적용하기 위해 누락된 것은

1000
00:39:59,440 --> 00:40:01,359


1001
00:40:01,359 --> 00:40:03,920
항상 필요한 피드백입니다. 아이디어는 우리가

1002
00:40:03,920 --> 00:40:06,960
여기는 매우 가벼운 음 어 피드백

1003
00:40:06,960 --> 00:40:09,480
네트워크이므로 본질적으로

1004
00:40:09,480 --> 00:40:11,800
이 심층 신경망에 있는 이러한 각 블록에는

1005
00:40:11,800 --> 00:40:15,319


1006
00:40:15,319 --> 00:40:18,520
어 로컬에서 타겟을 생성하는 피드백 블록이 수반됩니다.

1007
00:40:18,520 --> 00:40:20,240
그래서 우리는 실제로 가장 간단한 경우에 사용했으므로

1008
00:40:20,240 --> 00:40:21,760
이것은 매우

1009
00:40:21,760 --> 00:40:24,640
최근입니다.  작업은 지금까지 선형 블록만 사용했기

1010
00:40:24,640 --> 00:40:27,480
때문에 이것이 단일 선형 레이어이고

1011
00:40:27,480 --> 00:40:29,160
이제

1012
00:40:29,160 --> 00:40:32,040
여기 피드백 블록에서 이러한 출력을 생성한

1013
00:40:32,040 --> 00:40:34,040
다음 자유 에너지 원리를 사용하여

1014
00:40:34,040 --> 00:40:38,119
음 uh 이

1015
00:40:38,119 --> 00:40:40,920
두 가지를 다시 최소화할 수 있는 로컬 손실을 도출합니다 uh

1016
00:40:40,920 --> 00:40:43,000
여기에 있는 피드백 가중치와

1017
00:40:43,000 --> 00:40:45,119
순방향

1018
00:40:45,119 --> 00:40:48,079
네트워크의 가중치 음 본질적으로 동일한

1019
00:40:48,079 --> 00:40:49,960
아이디어이므로 여기에 확률 함수에 대한

1020
00:40:49,960 --> 00:40:52,960
매개변수로 해석하는 이러한 출력이 있으므로

1021
00:40:52,960 --> 00:40:54,800


1022
00:40:54,800 --> 00:40:57,240
이 확률적 프레임워크를 적용할 수 있습니다.

1023
00:40:57,240 --> 00:40:59,040
어 하지만 이제 모든 것은  나머지는 기본적으로

1024
00:40:59,040 --> 00:41:01,359
같은 방식으로 롤아웃되므로 우리는

1025
00:41:01,359 --> 00:41:04,040
이러한 출력이 본질적으로

1026
00:41:04,040 --> 00:41:06,599
음 이 모델의 내부 상태라고 가정하고

1027
00:41:06,599 --> 00:41:10,480


1028
00:41:10,480 --> 00:41:14,000
음 입력 및 목표에 주어진 관찰 결과를 가지고 있으며

1029
00:41:14,000 --> 00:41:17,880
이제 기본적으로 최소화하려고 노력합니다 어 P

1030
00:41:17,880 --> 00:41:19,640
이제 이 피드 포워드 네트워크가 될 것이고

1031
00:41:19,640 --> 00:41:23,480
Q는 이제 uh

1032
00:41:23,480 --> 00:41:26,319


1033
00:41:26,319 --> 00:41:31,119
피드백과 어 및 피드 포워드

1034
00:41:31,119 --> 00:41:33,880
네트워크의 기능을 모두 포함하는 함수가 될 것입니다. 좋은 점은 우리가

1035
00:41:33,880 --> 00:41:36,160
um uh 들어갈 시간이 없다는 것입니다.

1036
00:41:36,160 --> 00:41:38,880
지금 자세히 설명하지만 이것을 작성하면

1037
00:41:38,880 --> 00:41:43,200
음 이것이 실제로 어 여기서 이

1038
00:41:43,200 --> 00:41:45,079
잠금 항을 분해하고 여기서 이러한 로컬 손실을 제공하는

1039
00:41:45,079 --> 00:41:49,200
로컬 선형 항으로 분해되므로

1040
00:41:49,200 --> 00:41:50,920


1041
00:41:50,920 --> 00:41:52,960
본질적으로 여기에서

1042
00:41:52,960 --> 00:41:55,520
B와

1043
00:41:55,520 --> 00:41:59,560
해당 피드백 블록 사이의 블록 로컬을 최소화할 수 있다는 것을 알 수 있습니다.  음, 손실

1044
00:41:59,560 --> 00:42:01,839
함수이고 실제로

1045
00:42:01,839 --> 00:42:05,680
이 작업을 병렬로 수행할 수 있습니다. 왜냐면 어 어쩌면

1046
00:42:05,680 --> 00:42:07,800
그림이 여기에서 보기에 좋을 수도 있으므로

1047
00:42:07,800 --> 00:42:09,000
지금 해야 할 일은

1048
00:42:09,000 --> 00:42:10,720
이 피드백 블록이 있기 때문에 약간의 오버

1049
00:42:10,720 --> 00:42:15,200
헤드가 있으므로 이것이 두 개가 될 것입니다. 어  어

1050
00:42:15,200 --> 00:42:18,359
피드 포워드

1051
00:42:18,359 --> 00:42:20,160
블록과 피드백

1052
00:42:20,160 --> 00:42:23,359
블록의 실행 시간은 원칙적으로 병렬로 실행될 수 있습니다

1053
00:42:23,359 --> 00:42:25,920
어 그리고 일단 포워드 블록이

1054
00:42:25,920 --> 00:42:28,400
완료되면 다음 포워드 블록은

1055
00:42:28,400 --> 00:42:30,079
이 네트워크를 통해 전파되기 시작할 수 있습니다

1056
00:42:30,079 --> 00:42:33,079
음 하지만 동시에 이미

1057
00:42:33,079 --> 00:42:34,880
포워드 블록이 수신되었기 때문에 이미 포워드 블록이 있습니다

1058
00:42:34,880 --> 00:42:37,880
여기 타겟은

1059
00:42:37,880 --> 00:42:40,520
가중치 업데이트를 시작할 수 있고 완료되면

1060
00:42:40,520 --> 00:42:43,119
다음 Epoch에서 자유롭게 작동할 수 있으므로

1061
00:42:43,119 --> 00:42:45,760
이 프레임워크에서는 더 이상 잠금이 없습니다.

1062
00:42:45,760 --> 00:42:48,040


1063
00:42:48,040 --> 00:42:50,880
알겠습니다. 거의 완료되었습니다.

1064
00:42:50,880 --> 00:42:53,119
또한 시간이 부족하다고 생각합니다.

1065
00:42:53,119 --> 00:42:55,359
이것이 어떻게 작동합니까? 물론 우리는

1066
00:42:55,359 --> 00:42:56,720
학습 알고리즘을 변경했습니다. 이제 우리는 다시

1067
00:42:56,720 --> 00:42:59,720
돌아가서 이것이 어

1068
00:42:59,720 --> 00:43:03,280
여전히 우리에게 동일한 성능을 제공하는지 확인해야 합니다. 그리고

1069
00:43:03,280 --> 00:43:06,480
실제로 음, 제가 말했듯이

1070
00:43:06,480 --> 00:43:09,400
이것이 우리가 얻은 첫 번째 결과입니다.

1071
00:43:09,400 --> 00:43:15,559
지금은 적어도 음,

1072
00:43:15,559 --> 00:43:18,280
Cypher 10과 같은 중간 규모의 데이터 세트 정도는

1073
00:43:18,280 --> 00:43:20,440
실제로는 매우 잘 수행되는 것 같아서

1074
00:43:20,440 --> 00:43:22,160
표준

1075
00:43:22,160 --> 00:43:24,559
아키텍처 패션 mnist에 대해 재설정

1076
00:43:24,559 --> 00:43:29,880
15 및 해상도 18을 사용하려고 시도했습니다. 우리는 지금까지 주로 작업했습니다.

1077
00:43:29,880 --> 00:43:32,160
작은 규모로 작업했습니다.  패션 애미스트와 같은 데이터 세트에서는

1078
00:43:32,160 --> 00:43:35,160


1079
00:43:35,160 --> 00:43:37,640
50을 재설정하기 위해 무료 분할을 적용했습니다. 네트워크가 깊어질수록 기본적으로

1080
00:43:37,640 --> 00:43:40,040
표준 백롭과 동일한 성능을 얻습니다.

1081
00:43:40,040 --> 00:43:42,680
음

1082
00:43:42,680 --> 00:43:44,880
실제로 음 우리가

1083
00:43:44,880 --> 00:43:47,079
겪고 있는 문제는 실제로 과적합입니다.

1084
00:43:47,079 --> 00:43:48,599
왜냐하면 이러한 로컬이 있기 때문입니다.  대상에서는

1085
00:43:48,599 --> 00:43:50,280
이 작은 블록이 실제로

1086
00:43:50,280 --> 00:43:53,079
어느 정도 과적합되는 것 같습니다. 이는

1087
00:43:53,079 --> 00:43:55,800
Cypher t와 같은 작업까지는 그다지 심각하지 않으므로

1088
00:43:55,800 --> 00:43:58,839
이미 꽤 가까워졌지만

1089
00:43:58,839 --> 00:44:01,520
지금 정말 큰 작업을 수행한다면

1090
00:44:01,520 --> 00:44:04,480


1091
00:44:04,480 --> 00:44:06,839
음 아직 뭔가 빠진 것이 있습니다.  단일 분할처럼 우리는

1092
00:44:06,839 --> 00:44:09,000
거기에 도달하고 있지만 백 전파까지 끝까지 도달하지는 않지만

1093
00:44:09,000 --> 00:44:11,559


1094
00:44:11,559 --> 00:44:13,119


1095
00:44:13,119 --> 00:44:18,240
이것을 적용할 수 있다는 점은 여전히 ​​흥미롭습니다. 음 이 원리는 또한

1096
00:44:18,240 --> 00:44:21,160
표준 기계 학습

1097
00:44:21,160 --> 00:44:23,599
알고리즘에도 적용할 수 있습니다. 좋습니다 이것이 제 두 번째

1098
00:44:23,599 --> 00:44:26,240
요약입니다.  실제로 우리는 음

1099
00:44:26,240 --> 00:44:28,040
깊은 Nur 네트워크가

1100
00:44:28,040 --> 00:44:31,720
확률 공간에 대한 일반화에 놀랍도록 훌륭하다는 것을 발견했습니다.

1101
00:44:31,720 --> 00:44:33,839
이것이 실제로 이 작업이 시작된 방법입니다.

1102
00:44:33,839 --> 00:44:36,760


1103
00:44:36,760 --> 00:44:39,920


1104
00:44:39,920 --> 00:44:41,680


1105
00:44:41,680 --> 00:44:44,040
첫 번째 프로젝트에서 제가

1106
00:44:44,040 --> 00:44:48,000
보여드린 것은 음 그리고

1107
00:44:48,000 --> 00:44:50,359
이러한 피드백 네트워크를 생성하여 이 학점 할당 문제를 해결하는 것입니다.

1108
00:44:50,359 --> 00:44:52,160


1109
00:44:52,160 --> 00:44:55,760
음 예, 기본적으로는 그게 다입니다.

1110
00:44:55,760 --> 00:44:58,680
그리고 음

1111
00:44:58,680 --> 00:45:01,000
동료와 학생들에게 감사를 표하고 싶기 때문에

1112
00:45:01,000 --> 00:45:05,480
아주 좋은 음 음 박사 과정 학생이 두 명 있습니다.

1113
00:45:05,480 --> 00:45:08,400
지금 여기 봄에 있는 KH와 Cabel이 음 이

1114
00:45:08,400 --> 00:45:11,680
주제로 작업하고 있는데 제가 처음으로

1115
00:45:11,680 --> 00:45:14,760
보여드린 음 프로젝트는 B였어요.

1116
00:45:14,760 --> 00:45:17,640
구탄에 있을 때 Christian TL과 함께 했고

1117
00:45:17,640 --> 00:45:20,559
어 이 프로젝트

1118
00:45:20,559 --> 00:45:22,800
는 제가 긴밀하게 작업했어요.

1119
00:45:22,800 --> 00:45:24,880
Christian mea와 Anan

1120
00:45:24,880 --> 00:45:26,599
supron

1121
00:45:26,599 --> 00:45:29,760
그리고 네 감사합니다

1122
00:45:30,520 --> 00:45:32,920
정말 감사합니다 David

1123
00:45:32,920 --> 00:45:35,040
정말 흥미로웠어요 첫 번째 원리에서 파생했다는 점을 고려하면

1124
00:45:35,040 --> 00:45:37,559
일종의 모델이 생물학과 얼마나 밀접하게 일치하는지 믿을 수 없을 것 같아요

1125
00:45:37,559 --> 00:45:39,599


1126
00:45:39,599 --> 00:45:41,359


1127
00:45:41,359 --> 00:45:43,760
정말 멋진 것 같아요 음 질문이 있어요  컨

1128
00:45:43,760 --> 00:45:45,800


1129
00:45:45,800 --> 00:45:47,720


1130
00:45:47,720 --> 00:45:49,760
볼루셔널 네트워크에 대해 마지막으로 말씀하신 부분에 대해 말씀하셨는데,

1131
00:45:49,760 --> 00:45:51,079
전통적으로 끝에서 끝까지 가야 한다고 말씀하셨는데,

1132
00:45:51,079 --> 00:45:53,400
이는 정말 비효율적입니다.

1133
00:45:53,400 --> 00:45:54,960
그런 다음

1134
00:45:54,960 --> 00:45:57,240
에너지 소비를 살펴보시며 얻은 결과를 보여 주셨습니다.

1135
00:45:57,240 --> 00:46:00,839
당신의 것도 어, 아직은 아니어서 우리는

1136
00:46:00,839 --> 00:46:02,520
어 실제로 현재

1137
00:46:02,520 --> 00:46:06,760
작업 중이므로 이것은 음 실제로

1138
00:46:06,760 --> 00:46:09,040


1139
00:46:09,040 --> 00:46:10,880
표준 기계 학습에서 이러한 것들을 구현하는 것이 그렇게 쉽지 않습니다.

1140
00:46:10,880 --> 00:46:14,319
우리가 가지고 있는 도구 상자 그래서 Kal은 현재

1141
00:46:14,319 --> 00:46:17,400
이것을 조사하고 있습니다 어 PHD  Dron의 학생,

1142
00:46:17,400 --> 00:46:20,160
음 그는 지금 구현을 가지고 있고

1143
00:46:20,160 --> 00:46:22,359
그는 이제

1144
00:46:22,359 --> 00:46:25,520
이 구문화를 실제로 얼마나 잘 사용할 수 있는지 평가하고 있습니다.

1145
00:46:25,520 --> 00:46:28,359
하지만 우리는

1146
00:46:28,359 --> 00:46:32,119
실제로 이

1147
00:46:32,119 --> 00:46:36,640
음이 그것을 마비시키기 위한 것이라고 확신합니다. 어

1148
00:46:36,640 --> 00:46:38,960
거기에 있어야 합니다. 문제는 얼마입니까?

1149
00:46:38,960 --> 00:46:41,400
에너지 측면에서 절약되는 이유는 음, 현재

1150
00:46:41,400 --> 00:46:43,440
사용하는 이러한 소규모 모델의 경우

1151
00:46:43,440 --> 00:46:47,720
효과가

1152
00:46:47,720 --> 00:46:50,319
그다지 크지 않을 수 있기 때문입니다. 따라서

1153
00:46:50,319 --> 00:46:52,000
이 모델을 실제로 더 큰 모델로 확장하면

1154
00:46:52,000 --> 00:46:54,400
효과는 더 커질 것입니다. 하지만 예,

1155
00:46:54,400 --> 00:46:56,480
현재 진행 중인 작업입니다.

1156
00:46:56,480 --> 00:46:58,920
아주 멋지군요 감사합니다 음 그리고 저는

1157
00:46:58,920 --> 00:47:00,760
이

1158
00:47:00,760 --> 00:47:03,119
로컬 오류 역전파가

1159
00:47:03,119 --> 00:47:04,960
다른 사람들이

1160
00:47:04,960 --> 00:47:06,520
이러한 컨볼루션 신경망으로 시도한 것인지

1161
00:47:06,520 --> 00:47:08,880
아니면 이것을 구현하는 완전히 새로운 방법인지 궁금했습니다.

1162
00:47:08,880 --> 00:47:11,680


1163
00:47:11,680 --> 00:47:14,280
이 작업을 수행하는 접근 방식은 어,

1164
00:47:14,280 --> 00:47:16,000
예를 들어 내 생각에 가장 가까운 것은

1165
00:47:16,000 --> 00:47:18,040


1166
00:47:18,040 --> 00:47:20,440
본질적으로 무작위 피드백 가중치를 사용하여 제안된 목표 전파입니다.

1167
00:47:20,440 --> 00:47:23,640
어 여기에서 역전파하므로

1168
00:47:23,640 --> 00:47:25,359
이 사람들은 훈련되지 않을 것입니다.

1169
00:47:25,359 --> 00:47:27,720


1170
00:47:28,000 --> 00:47:32,520
음 그리고 제가 아는 한 그것들은  이것은 작동합니다.

1171
00:47:32,520 --> 00:47:35,559
소규모 문제에도 잘 작동

1172
00:47:35,559 --> 00:47:38,160
하지만 제가 아는 한

1173
00:47:38,160 --> 00:47:40,280


1174
00:47:40,280 --> 00:47:42,319
Cipher 10의 경우에도 잘 수행되지 않습니다.

1175
00:47:42,319 --> 00:47:43,599
이러한 무작위

1176
00:47:43,599 --> 00:47:46,160
피드백 가중치가 너무 거친

1177
00:47:46,160 --> 00:47:48,559
근사치이기 때문에 이미 고장나기 시작했습니다.  그리고 이것이

1178
00:47:48,559 --> 00:47:52,760
첫 번째입니다 음 알겠습니다 아마도 조심해야 할 것

1179
00:47:52,760 --> 00:47:56,079
같습니다. 이것이 대조 방법이 아닌 이 피드백 가중치를 훈련할 수 있는 첫 번째 음 방법인 것 같습니다.

1180
00:47:56,079 --> 00:47:58,240


1181
00:47:58,240 --> 00:48:01,200


1182
00:48:01,200 --> 00:48:03,079
따라서 대조 단계를 사용하는 방법이 많이 있으므로 음

1183
00:48:03,079 --> 00:48:05,559


1184
00:48:05,559 --> 00:48:08,040
어쩌면 이

1185
00:48:08,040 --> 00:48:10,800
순방향 알고리즘과 이런 모든

1186
00:48:10,800 --> 00:48:13,040
것을 본 적이 있을 것입니다. 그러나 항상 해야 할 일은

1187
00:48:13,040 --> 00:48:14,830


1188
00:48:14,830 --> 00:48:16,160
[음악]을 전송하는 것입니다. 어

1189
00:48:16,160 --> 00:48:19,319
어 그들은 실제 입력 데이터를 보낸

1190
00:48:19,319 --> 00:48:22,480
다음 일종의

1191
00:48:22,480 --> 00:48:26,520
안티 입력을 보냅니다.  어

1192
00:48:26,520 --> 00:48:29,000
일반적으로 인위적으로 생성되므로

1193
00:48:29,000 --> 00:48:31,040
입력을 만들기 위해 약간의 왜곡을 수행합니다.

1194
00:48:31,040 --> 00:48:33,839
그런 다음

1195
00:48:33,839 --> 00:48:36,960
로컬에서 두 정보를 모두 사용해야 합니다.

1196
00:48:36,960 --> 00:48:38,640
업데이트를 수행하려면 네트워크가 메모리에 유지해야 합니다.

1197
00:48:38,640 --> 00:48:41,440
입력과 안티

1198
00:48:41,440 --> 00:48:44,440
입력 및  응답과 이로

1199
00:48:44,440 --> 00:48:48,200
인해 음 이로 인해 이 접근 방식이

1200
00:48:48,200 --> 00:48:50,880
병렬화하기가 조금 더 어려워지고

1201
00:48:50,880 --> 00:48:54,280
여기서 좋은 점은 순방향 전파로 완전히 설명할 수 있는

1202
00:48:54,280 --> 00:48:57,440
이 음 변형

1203
00:48:57,440 --> 00:49:00,960
자유 에너지 손실의 상한을 유도한다는 것입니다.

1204
00:49:00,960 --> 00:49:03,680


1205
00:49:03,680 --> 00:49:05,960
내 생각엔 새롭다고 생각하는데 그게 이 [음악]

1206
00:49:05,960 --> 00:49:08,480
의 새로운 부분이군요

1207
00:49:08,480 --> 00:49:11,550


1208
00:49:11,680 --> 00:49:15,520
아주

1209
00:49:15,720 --> 00:49:19,720
멋지군요 글쎄요 댓글이 거의 없습니다. 당신

1210
00:49:19,720 --> 00:49:21,640
의 두 강연 사이에 그런 종류의 한 곡이 있는데

1211
00:49:21,640 --> 00:49:24,280
그것은

1212
00:49:24,280 --> 00:49:25,880
저에게 적어도 새로운 차별점이었습니다. 그게

1213
00:49:25,880 --> 00:49:27,319
차이점이었습니다  뉴로모픽

1214
00:49:27,319 --> 00:49:29,920
하드웨어와 뉴로모픽

1215
00:49:29,920 --> 00:49:33,640
알고리즘 사이에는 새로운

1216
00:49:33,640 --> 00:49:35,520
하드웨어나

1217
00:49:35,520 --> 00:49:39,240
잠수복에 관한 것이 아니지만 Sarah가 언급한 것처럼 오늘날 우리가 가지고 있는 하드웨어의 알고리즘을

1218
00:49:39,240 --> 00:49:40,760


1219
00:49:40,760 --> 00:49:45,839
사용하는 데 중간 단계 또는 브리지 단계가 있다는 것을 알면 좋을 것입니다.

1220
00:49:45,839 --> 00:49:47,599


1221
00:49:47,599 --> 00:49:51,440


1222
00:49:51,440 --> 00:49:54,160


1223
00:49:54,160 --> 00:49:56,240


1224
00:49:56,240 --> 00:49:59,880
GPU를 사용하거나

1225
00:49:59,880 --> 00:50:04,079
표준화된 CPU 멀티코어 스케줄링

1226
00:50:04,079 --> 00:50:07,000
접근 방식을 사용하는 신경망은

1227
00:50:07,000 --> 00:50:09,799


1228
00:50:09,799 --> 00:50:13,559
뉴로모픽 알고리즘을 사용하여 이미 더 많은 작업을 수행할 수 있으므로 음

1229
00:50:13,559 --> 00:50:18,640
재료 과학

1230
00:50:18,640 --> 00:50:22,040
주제일 뿐만 아니라

1231
00:50:22,040 --> 00:50:24,640
실제로 미시적인 규모에서도 많은 작업을 수행할 수 있습니다.

1232
00:50:24,640 --> 00:50:26,920
소음 처리 스케줄링과 관련하여 학습할 수

1233
00:50:26,920 --> 00:50:28,599
있고 더 높은 수준의

1234
00:50:28,599 --> 00:50:30,559
추상화에서도 아마도

1235
00:50:30,559 --> 00:50:32,720
생체 모방 및 인지 시스템에서 더

1236
00:50:32,720 --> 00:50:34,839
일반적으로 학습할 수 있지만 그것은 저에게 구별되는 것 같았습니다.

1237
00:50:34,839 --> 00:50:37,240


1238
00:50:37,240 --> 00:50:40,839
그래 그래서 아마도 추가하는 것이 음 그래

1239
00:50:40,839 --> 00:50:43,720
그래서 문제가 될 것 같아요

1240
00:50:43,720 --> 00:50:46,640
이제 이러한 어

1241
00:50:46,640 --> 00:50:49,000
뉴로모픽 어 장치가 Al이 되면서

1242
00:50:49,000 --> 00:50:51,119
하드웨어 장치가 더욱

1243
00:50:51,119 --> 00:50:53,839
성숙해지고 일반적으로

1244
00:50:53,839 --> 00:50:57,520
이러한 표준

1245
00:50:57,520 --> 00:50:59,119
기계 학습 알고리즘에서는 실제로 빛을 발할 수 없습니다. 왜냐하면

1246
00:50:59,119 --> 00:51:01,280
실제로는 GPU에 최적화되어 있기 때문입니다.

1247
00:51:01,280 --> 00:51:04,319
따라서 조금 생각해야 합니다.

1248
00:51:04,319 --> 00:51:06,079
한 걸음 뒤로 물러서서

1249
00:51:06,079 --> 00:51:08,680
알고리즘 측면에 대해 다시 생각해야 합니다.

1250
00:51:08,680 --> 00:51:11,960
음 실제로 이를 최대

1251
00:51:11,960 --> 00:51:13,960
용량으로 사용하려면 우리는 또한 여러분이 보셨듯이

1252
00:51:13,960 --> 00:51:16,480
음 드론

1253
00:51:16,480 --> 00:51:18,839
에서 이 Spiner 칩을 수행하고 있는 Maya 교수와 협력하고 있지만

1254
00:51:18,839 --> 00:51:20,720
다른 것도 있습니다.

1255
00:51:20,720 --> 00:51:23,359
Sarah가 Intel 등에서 언급한 L 칩과 같은 접근 방식입니다.

1256
00:51:23,359 --> 00:51:26,319
음, 그들은

1257
00:51:26,319 --> 00:51:29,520
지금 이 문제를 실제로 조사하고 있습니다. 또한

1258
00:51:29,520 --> 00:51:31,960
알고리즘

1259
00:51:31,960 --> 00:51:34,520
측면에서도 저는 이것이 정말 유용하다고 생각합니다. 제가 생각할 때

1260
00:51:34,520 --> 00:51:36,520
사고방식이나 정신적 프레임워크와 같은 것입니다.

1261
00:51:36,520 --> 00:51:38,839
컴퓨터나 Ai

1262
00:51:38,839 --> 00:51:39,760
그리고 저는 이것은 아마도 제가

1263
00:51:39,760 --> 00:51:40,920
신경과학자이기 때문일 것입니다. 그러나 나는 또한

1264
00:51:40,920 --> 00:51:43,040
그것을 잘 번역해야 합니다. 뇌는 어떻게

1265
00:51:43,040 --> 00:51:44,680
작동합니까 뇌에서 정보 처리는 어떻게

1266
00:51:44,680 --> 00:51:46,880
작동합니까? 그리고 제가

1267
00:51:46,880 --> 00:51:48,480
일종의 컴퓨터 과학과 AI에 왔을 때

1268
00:51:48,480 --> 00:51:49,920
Neuroscience 이후에

1269
00:51:49,920 --> 00:51:51,720
자연스럽게 번역하게 되었지만

1270
00:51:51,720 --> 00:51:53,760
프레임워크는

1271
00:51:53,760 --> 00:51:56,000
결국 컴퓨팅을 이해하는 데 정말 유용한 방법이라고 생각합니다.

1272
00:51:56,000 --> 00:51:57,319
제가 말했듯이 우리의 두뇌는

1273
00:51:57,319 --> 00:51:59,280
단지 거대한 슈퍼컴퓨터일 뿐이고

1274
00:51:59,280 --> 00:52:01,079
저는 끊임없이 컴퓨터에 관한 논문을 읽고 있기 때문입니다.

1275
00:52:01,079 --> 00:52:02,599
과학이든 뭐든

1276
00:52:02,599 --> 00:52:04,680
일단 무엇이든 실제로 개념화할 수 있으면

1277
00:52:04,680 --> 00:52:07,520


1278
00:52:07,520 --> 00:52:09,880
이것이 얼마나 뉴로모픽에 가까운지, 그리고 잘

1279
00:52:09,880 --> 00:52:11,440
생각하기 시작하면 어떻게

1280
00:52:11,440 --> 00:52:12,520
조정하여 약간 더

1281
00:52:12,520 --> 00:52:14,079
뉴로모픽이 되고

1282
00:52:14,079 --> 00:52:15,839
이러한 이점을 얻을 수 있을까요?  우리가 뇌에 대해 얻는 것은

1283
00:52:15,839 --> 00:52:17,040


1284
00:52:17,040 --> 00:52:19,319
추가 병렬 계산과 같은 기능을 제공할 것인지, 아니면

1285
00:52:19,319 --> 00:52:20,559
에너지 효율성을 제공할 것인지에 대한 것입니다.

1286
00:52:20,559 --> 00:52:23,480
그래서 그래 저는 정의를

1287
00:52:23,480 --> 00:52:24,599
볼 때 정의와

1288
00:52:24,599 --> 00:52:26,000
마찬가지로 NE라고 생각합니다.

1289
00:52:26,000 --> 00:52:27,520
귀하의 권리는 정의이고

1290
00:52:27,520 --> 00:52:30,079


1291
00:52:30,079 --> 00:52:32,640
현재로서는 매우 역동적인 영역이기 때문에 음 제 생각엔 앞으로도

1292
00:52:32,640 --> 00:52:34,079
변하고 있고

1293
00:52:34,079 --> 00:52:35,559
변할 것입니다. 하지만 제게 있어서

1294
00:52:35,559 --> 00:52:37,680
뉴로모픽은

1295
00:52:37,680 --> 00:52:39,559
제가 정신적인 틀과 같은 프레임에 더 가깝다고 생각합니다.  개념화를 통해 사물을 살펴보세요.

1296
00:52:39,559 --> 00:52:42,240


1297
00:52:42,400 --> 00:52:44,119
네, 그것도

1298
00:52:44,119 --> 00:52:47,920
잘 정의되지 않은 것 같아요. 제 말은 어,

1299
00:52:47,920 --> 00:52:50,319
당신이 말하길, 실제로

1300
00:52:50,319 --> 00:52:52,359
인공 뉴런 네트워크는

1301
00:52:52,359 --> 00:52:54,880
뉴로모픽 어 개념이고

1302
00:52:54,880 --> 00:52:55,960
그들은

1303
00:52:55,960 --> 00:52:58,119
첫날부터 있었고 실제로는 그것은

1304
00:52:58,119 --> 00:53:00,160


1305
00:53:00,160 --> 00:53:02,400
90년대쯤에 이러한

1306
00:53:02,400 --> 00:53:04,960
지원 벡터 머신과

1307
00:53:04,960 --> 00:53:08,200
이러한 대체 모델이 등장했지만 그중

1308
00:53:08,200 --> 00:53:10,920
어느 것도

1309
00:53:10,920 --> 00:53:13,440
새로운 뉴로모픽 접근 방식보다 오래 지속되지 않았으므로 어

1310
00:53:13,440 --> 00:53:14,880
실제로 매우 훌륭하지만 여전히

1311
00:53:14,880 --> 00:53:17,040
이 커뮤니티가 있습니다.  그건

1312
00:53:17,040 --> 00:53:19,119
뇌에서 실제 사물에 도달하기 위해 입력해야 할 더 많은 기능이 있다고 생각합니다.

1313
00:53:19,119 --> 00:53:22,400


1314
00:53:22,400 --> 00:53:23,599


1315
00:53:23,599 --> 00:53:26,960
그래 그래서 내 생각엔 이것이 약간이라고 생각합니다.

1316
00:53:26,960 --> 00:53:30,799


1317
00:53:30,799 --> 00:53:33,040
실제로는 잘 정의된 용어가 아니며 귀하의 연구를 통해

1318
00:53:33,040 --> 00:53:34,799
귀하의 것으로 생각합니다  사람들이 보는 것 중 가장 작은 수준과 거의 비슷합니다.

1319
00:53:34,799 --> 00:53:36,440


1320
00:53:36,440 --> 00:53:37,880
다른 것을 본 적이 있는지는 모르겠지만

1321
00:53:37,880 --> 00:53:39,520


1322
00:53:39,520 --> 00:53:41,400


1323
00:53:41,400 --> 00:53:43,040
우리는 세포 수준의 자유 에너지와 능동적 추론에 대해서만 말하는 것이 아닙니다.  실제로

1324
00:53:43,040 --> 00:53:46,599
세포 구조에 대해 이야기하고 그런

1325
00:53:46,599 --> 00:53:48,319
다음 그것이 얼마나 작아지는지 잘 생각해보세요.

1326
00:53:48,319 --> 00:53:49,960
우리는

1327
00:53:49,960 --> 00:53:51,559


1328
00:53:51,559 --> 00:53:53,559
궁극적으로 복합 구획과 비슷한 방식으로 자유 에너지를 사용하는 미토콘드리아와 같은 세포 하위 구조에 대해 이야기할 것입니다.

1329
00:53:53,559 --> 00:53:55,160


1330
00:53:55,160 --> 00:53:56,760
예, 그래서 실제로 추측합니다

1331
00:53:56,760 --> 00:53:57,920
'

1332
00:53:57,920 --> 00:53:59,960
생각을 얻는 것이 흥미로울 것입니다 David는

1333
00:53:59,960 --> 00:54:02,520
처음에 가입이 어떻게 구분되는지에 대해 이야기했다는 것을 알고 있습니다.

1334
00:54:02,520 --> 00:54:05,319
음 당신은 거의 한 가입 내에서 다른 구획에서

1335
00:54:05,319 --> 00:54:07,599
이것에 대한 다른 종류의 인스턴스화를 보고

1336
00:54:07,599 --> 00:54:09,480


1337
00:54:09,480 --> 00:54:11,480
싶습니까?

1338
00:54:11,480 --> 00:54:13,359


1339
00:54:13,359 --> 00:54:14,880
아니면 세분화된 수준인가요, 아니면

1340
00:54:14,880 --> 00:54:16,079
여기서 배운 내용을 다시 적용하여

1341
00:54:16,079 --> 00:54:17,760


1342
00:54:17,760 --> 00:54:19,440
AI를 더욱

1343
00:54:19,440 --> 00:54:21,920
효율적으로 만드는 방법에 대한 것인가요? 예,

1344
00:54:21,920 --> 00:54:24,240
이제 우리는 이 방향으로 훨씬 더 나아가고 있습니다.

1345
00:54:24,240 --> 00:54:28,040
이것을 어떻게 AI 모델로 다시 구축할 수 있는지, 음,

1346
00:54:28,040 --> 00:54:31,359
자유 에너지라고 생각합니다. 따라서

1347
00:54:31,359 --> 00:54:32,960


1348
00:54:32,960 --> 00:54:34,839
자유 에너지 원리를 사용할 때는 약간 주의해야 합니다. 왜냐하면 자유 에너지 원리는

1349
00:54:34,839 --> 00:54:36,880


1350
00:54:36,880 --> 00:54:40,160
기본적으로

1351
00:54:40,160 --> 00:54:41,359
[음악]

1352
00:54:41,359 --> 00:54:45,680
무엇이든 적용할 수 있을 만큼 강력한 일반 프레임워크이기 때문입니다.  음 그리고 반드시 이것을 적용하기만 하면

1353
00:54:45,680 --> 00:54:49,440
결국 유용한 결과가 나올 필요는 없습니다.

1354
00:54:49,440 --> 00:54:53,680


1355
00:54:53,680 --> 00:54:56,119
음 그리고 기본적으로 이것은

1356
00:54:56,119 --> 00:54:58,040
실제로 사이드 프로젝트로 시작되었다는 뜻입니다. 이것은 제

1357
00:54:58,040 --> 00:55:03,760
종류의 어 코이드 음 전염병 봉쇄 음

1358
00:55:03,760 --> 00:55:06,480
프로젝트였고 저는 단지  이에 대해 궁금하고

1359
00:55:06,480 --> 00:55:09,119
음 실제로 이 문제를

1360
00:55:09,119 --> 00:55:10,680
해결할 수 있는지 여부가 궁금합니다. 왜냐하면 가입이

1361
00:55:10,680 --> 00:55:12,839
충분히 간단할 수 있다고 생각했기 때문입니다. 왜냐하면

1362
00:55:12,839 --> 00:55:15,520
귀하가 신문에 들어갈 때 음

1363
00:55:15,520 --> 00:55:17,440
그들은 어느 시점에서 대략적인 추정을 해야 하기 때문입니다.

1364
00:55:17,440 --> 00:55:19,760


1365
00:55:19,760 --> 00:55:22,960
첫 번째 모드로 가서

1366
00:55:22,960 --> 00:55:25,240


1367
00:55:25,240 --> 00:55:27,039
뉴런에 대해서도 더 복잡한 문제를 해결할 수 있습니다.

1368
00:55:27,039 --> 00:55:29,119
실제로 뉴런이나

1369
00:55:29,119 --> 00:55:31,160
네트워크 수준으로 가면 어렵습니다.

1370
00:55:31,160 --> 00:55:35,160
매우 복잡한 수학이지만 부비동의 경우

1371
00:55:35,160 --> 00:55:36,599
실제로 충분히 간단하므로

1372
00:55:36,599 --> 00:55:38,559
실제로 할 수 있습니다.  그리고

1373
00:55:38,559 --> 00:55:39,880
올바른

1374
00:55:39,880 --> 00:55:42,640
가정을 하면 모든 것을 설명하고 음, 실제로

1375
00:55:42,640 --> 00:55:44,559
이러한 것들을 파생시켰고 그것은

1376
00:55:44,559 --> 00:55:47,079


1377
00:55:47,079 --> 00:55:52,480
일종의 게임이었습니다. 저는 제가 들어갔고

1378
00:55:52,480 --> 00:55:55,240


1379
00:55:55,240 --> 00:55:58,720
결과적으로 꽤 잘 작동하는 것으로 나타났습니다.  응, 아주

1380
00:55:58,720 --> 00:56:01,200
음, 내가 미토콘드리아를 좋아하는지 잘 모르겠어.

1381
00:56:01,200 --> 00:56:02,960
그래서 너도 같은 원칙을 적용할 수 있을 거라 확신하지만,

1382
00:56:02,960 --> 00:56:04,640


1383
00:56:04,640 --> 00:56:08,599
네가 얻는 결과가 어떤

1384
00:56:08,599 --> 00:56:11,079
의미가 있을지, 어떤 식으로든 도움이 될지는 잘 모르겠어.

1385
00:56:11,079 --> 00:56:12,240


1386
00:56:12,240 --> 00:56:14,960
그것은 항상

1387
00:56:14,960 --> 00:56:16,839
위험입니다. 너무 많은 시간을 투자하고

1388
00:56:16,839 --> 00:56:18,839
결국에는 결과를 얻었지만

1389
00:56:18,839 --> 00:56:19,240


1390
00:56:19,240 --> 00:56:20,440
[음악] 그것도

1391
00:56:20,440 --> 00:56:23,000
제가

1392
00:56:23,000 --> 00:56:25,599
꽤 흥미롭다고 생각했던 것이었는데,

1393
00:56:25,599 --> 00:56:28,720
시냅스가 에이전트였기 때문에 정말

1394
00:56:28,720 --> 00:56:31,000
쉽다고 생각합니다.  아,

1395
00:56:31,000 --> 00:56:34,240
먼저

1396
00:56:34,240 --> 00:56:36,480
Gia 또는 비신경 세포 유형을 포함하지 않는 경향이 있는 신경 시스템의 에이전트 기반 모델을 만들겠습니다.

1397
00:56:36,480 --> 00:56:39,240
하지만 이는 세포가 에이전트가 될 것이라는 두 배로 의심할 여지가

1398
00:56:39,240 --> 00:56:41,480
없는 가정과 거의 비슷

1399
00:56:41,480 --> 00:56:43,200


1400
00:56:43,200 --> 00:56:48,079
하지만 이는 큰 전환이었습니다.

1401
00:56:48,079 --> 00:56:50,319


1402
00:56:50,319 --> 00:56:53,440
벽 위로 공을 던지는 사람의 행동 중심

1403
00:56:53,440 --> 00:56:56,000
접근 방식으로

1404
00:56:56,000 --> 00:56:57,960


1405
00:56:57,960 --> 00:57:01,079
결과를 부분적으로만 볼 수 있으며 이는

1406
00:57:01,079 --> 00:57:03,640
시냅스가 다른 방식으로 자신을 발견하는 정확한 시나리오이거나

1407
00:57:03,640 --> 00:57:06,599


1408
00:57:06,599 --> 00:57:09,640
그렇게 설정되었을 수 있습니다.  뉴런은

1409
00:57:09,640 --> 00:57:12,319
우리가 지도를 만드는 행위자이지

1410
00:57:12,319 --> 00:57:15,119
영토가 아닙니다. 그래서 당신이

1411
00:57:15,119 --> 00:57:17,000
말했듯이 자유 에너지 원칙은

1412
00:57:17,000 --> 00:57:19,359


1413
00:57:19,359 --> 00:57:22,720
모든 것에 대한 원칙입니다. 따라서

1414
00:57:22,720 --> 00:57:25,440
사물에 대해 원칙에 입각한 진술을 하는 것은 매우 중요한 일입니다.

1415
00:57:25,440 --> 00:57:27,319


1416
00:57:27,319 --> 00:57:30,119
그러면 당신을 위한 내 질문은

1417
00:57:30,119 --> 00:57:33,079
무엇을 하는가 하는 것입니다.  유용하게 만들거나 이러한 모델을

1418
00:57:33,079 --> 00:57:35,119
학습하고 조작할 때

1419
00:57:35,119 --> 00:57:37,880


1420
00:57:37,880 --> 00:57:39,760
자유 에너지

1421
00:57:39,760 --> 00:57:42,000
원리 또는 능동적 추론을 적용하고

1422
00:57:42,000 --> 00:57:44,079


1423
00:57:44,079 --> 00:57:46,440
연구에

1424
00:57:46,440 --> 00:57:47,960
기여하는 것처럼 느껴지는 차별화된 상황을 만들 수 있습니다.

1425
00:57:47,960 --> 00:57:50,119


1426
00:57:50,119 --> 00:57:52,480
논리적으로 음, 음 불완전한 정보가 있는 상황에서는 자유 에너지

1427
00:57:52,480 --> 00:57:55,000
원리가 타당하다고 생각합니다.

1428
00:57:55,000 --> 00:57:58,160


1429
00:57:58,160 --> 00:58:01,440


1430
00:58:01,440 --> 00:58:03,039
예를 들어 가입 사례에서

1431
00:58:03,039 --> 00:58:05,520
우리가 시작한 질문은 음

1432
00:58:05,520 --> 00:58:07,039
가입이 해결해야 하는 이 문제였습니다.

1433
00:58:07,039 --> 00:58:09,039


1434
00:58:09,039 --> 00:58:11,760
음 세포체의 상태에 대한 정보가 불완전하다는 것,

1435
00:58:11,760 --> 00:58:15,359
음 이런 종류의 것만 볼 수 있기 때문입니다. 또는 그것은

1436
00:58:15,359 --> 00:58:17,200


1437
00:58:17,200 --> 00:58:19,400
적어도 모델의 가정이고 그리고 또한 우리가

1438
00:58:19,400 --> 00:58:22,119
실험가들로부터 얻는 것은 그들이

1439
00:58:22,119 --> 00:58:23,359
본질적으로 이 특정

1440
00:58:23,359 --> 00:58:25,160
전파 활동만 본다는 것입니다.  잠재력은

1441
00:58:25,160 --> 00:58:28,440
음 소마의 상태에 대한 단일 이진 변수를 봅니다.

1442
00:58:28,440 --> 00:58:31,960


1443
00:58:31,960 --> 00:58:35,440
따라서 본질적으로 이것은

1444
00:58:35,440 --> 00:58:39,480
불완전한 음 정보의 문제이며 또한

1445
00:58:39,480 --> 00:58:42,720


1446
00:58:42,720 --> 00:58:45,599
에이전트가 필요한 두 번째 요소는 어떤 형태의 에이전시가 필요하다고

1447
00:58:45,599 --> 00:58:46,960
생각합니다.

1448
00:58:46,960 --> 00:58:50,119
대리인이 없는 시스템에 자유 에너지 원리를 적용합니다.

1449
00:58:50,119 --> 00:58:52,440
따라서 무언가가 폐쇄 루프의 환경과 상호 작용하지 않으면

1450
00:58:52,440 --> 00:58:55,440


1451
00:58:55,440 --> 00:58:57,880
어 그러면 정말 개략적이 되고 내

1452
00:58:57,880 --> 00:59:00,480
생각에 이 모델은 이미

1453
00:59:00,480 --> 00:59:03,000
위기에 처해 있습니다. 왜냐하면

1454
00:59:03,000 --> 00:59:05,319
이 모델은 그렇지 않기 때문입니다.  실제로

1455
00:59:05,319 --> 00:59:07,079
에이전시는 없지만 최소한

1456
00:59:07,079 --> 00:59:09,359
출력 권한을 생성하므로

1457
00:59:09,359 --> 00:59:11,839
이를 환경과의 상호 작용으로 생각할 수

1458
00:59:11,839 --> 00:59:14,760
있지만 일부는 이를 잃자마자

1459
00:59:14,760 --> 00:59:17,599


1460
00:59:17,599 --> 00:59:21,039
바로 제공할 수 있는 더 간단한 모델이 있을 것이라고 생각합니다.

1461
00:59:22,400 --> 00:59:26,119
예,

1462
00:59:26,119 --> 00:59:27,839
실제로 가입의

1463
00:59:27,839 --> 00:59:31,319
경우 가입에서 에이전시는 단지 이것뿐입니다 어 이것은

1464
00:59:31,319 --> 00:59:33,880


1465
00:59:33,880 --> 00:59:35,240
가입이 시놉시스적으로 PR을 트리거하기 때문에 실제로 모델에 노이즈를 추가한

1466
00:59:35,240 --> 00:59:38,640
다음 이를 추가하고

1467
00:59:38,640 --> 00:59:40,520
내부 상태를 사용하여 적절한

1468
00:59:40,520 --> 00:59:41,480
양의

1469
00:59:41,480 --> 00:59:44,000
노이즈를 추가합니다.  아마도 이미

1470
00:59:44,000 --> 00:59:45,710


1471
00:59:45,710 --> 00:59:48,799
[음악]

1472
00:59:48,799 --> 00:59:51,119
Sarah가 질문하고 싶다고 상상하거나

1473
00:59:51,119 --> 00:59:52,599
제가 질문할 수 있는 최소한의 에이전시일 것입니다.

1474
00:59:52,599 --> 00:59:54,920
음 그래 저는

1475
00:59:54,920 --> 00:59:56,160


1476
00:59:56,160 --> 00:59:58,280
사람들이 생물학에 관해 이야기하는 것처럼 꽤 흥미롭다고 생각하는 것 같은 단순한 코멘트일 뿐입니다.

1477
00:59:58,280 --> 01:00:00,440
어떤 사람들은 그것이 진짜가 아니라고 말합니다.

1478
01:00:00,440 --> 01:00:02,400
과학은 모두 지저분하고 시끄럽기 때문에

1479
01:00:02,400 --> 01:00:04,359
그것이 정말 흥미롭다고 생각합니다. 왜냐하면

1480
01:00:04,359 --> 01:00:06,039


1481
01:00:06,039 --> 01:00:07,559
시냅스 잡음이 실제로

1482
01:00:07,559 --> 01:00:10,000
불확실성의 보고라고 말하는 것과 같기 때문입니다. 따라서

1483
01:00:10,000 --> 01:00:11,480
Essence에서는 실제로 매우

1484
01:00:11,480 --> 01:00:13,880
정확하게 보고할 것이며

1485
01:00:13,880 --> 01:00:15,359
생물학 자체보다는 지저분한 세계가

1486
01:00:15,359 --> 01:00:16,920
단지  다 지저분한데 그게 바로

1487
01:00:16,920 --> 01:00:19,359
내가 생각하고 있던 거였어 음 네,

1488
01:00:19,359 --> 01:00:20,480
당신이 말한 것처럼 나도 궁금했던 것 같아요.

1489
01:00:20,480 --> 01:00:21,880
이것이 당신의 봉쇄 프로젝트와 비슷

1490
01:00:21,880 --> 01:00:23,920
하지만 나는 당신이

1491
01:00:23,920 --> 01:00:25,960
어떻게 자유 에너지 원리를

1492
01:00:25,960 --> 01:00:27,359
접하게 되었는지 궁금합니다.  그것은 당신이

1493
01:00:27,359 --> 01:00:29,240
이미 꽤 잘 알고 있는 것이었습니다. 아니면

1494
01:00:29,240 --> 01:00:30,960
당신의 네트워크나 동료 중 일부가

1495
01:00:30,960 --> 01:00:32,359
그것에 대해 이야기하고 있었습니까? 아니면

1496
01:00:32,359 --> 01:00:36,000
논문에서 우연히 발견했습니까? 음 제 말은

1497
01:00:36,000 --> 01:00:37,839
제가 박사 과정을 밟을 때

1498
01:00:37,839 --> 01:00:40,920
음 변형 방법에 관심이 있었습니다.

1499
01:00:40,920 --> 01:00:44,319
그리고 확률론적 방법 음 그리고

1500
01:00:44,319 --> 01:00:46,680
저는 이것에 대해 읽기 시작했고 그래서

1501
01:00:46,680 --> 01:00:49,440
음 크리스턴스 논문을 여러 권 읽었고

1502
01:00:49,440 --> 01:00:53,079
이것이 흥미로웠고

1503
01:00:53,079 --> 01:00:57,319
음 실제로 제 박사 학위 지도교수님은 항상 음

1504
01:00:57,319 --> 01:01:00,280


1505
01:01:00,280 --> 01:01:01,520
그런

1506
01:01:01,520 --> 01:01:03,880
방향으로 가지 말라고 격려해 주셨죠 어 그리고 그 후에는

1507
01:01:03,880 --> 01:01:05,799
박사 학위를 마쳤습니다. 이제 괜찮다고 생각했습니다. 내가

1508
01:01:05,799 --> 01:01:08,079
원하는 것을 할 수 있습니다. 시도해 보겠습니다.

1509
01:01:08,079 --> 01:01:10,039


1510
01:01:10,039 --> 01:01:12,400
그러면

1511
01:01:12,400 --> 01:01:15,319
다음 단계처럼 이것이 귀

1512
01:01:15,319 --> 01:01:17,400
하나 실제로

1513
01:01:17,400 --> 01:01:19,799
이것을 구현하려고 하는 현장에 가치가 있을 것이라고 생각하십니까?  내가 아는

1514
01:01:19,799 --> 01:01:21,960


1515
01:01:21,960 --> 01:01:23,400
아날로그 뉴로모픽 칩과 같은 공간에 구축되고 있는 더 많은 아날로그 칩 중 일부는

1516
01:01:23,400 --> 01:01:25,119


1517
01:01:25,119 --> 01:01:28,200
시냅스 동적 시냅스

1518
01:01:28,200 --> 01:01:29,799
와 같은 것을 가질 수 있으며 음

1519
01:01:29,799 --> 01:01:31,839
자체 하드 하드웨어를 구현하려고 노력하는 것이 가치 있다고 생각하십니까?

1520
01:01:31,839 --> 01:01:34,839


1521
01:01:34,839 --> 01:01:37,119
그에 대한 생각은 음 제가

1522
01:01:37,119 --> 01:01:39,799
보여드린 이 첫 번째 작업에서 나오는 삼중항 규칙을 의미합니다.

1523
01:01:39,799 --> 01:01:41,079


1524
01:01:41,079 --> 01:01:45,200
그것을 구현하면 흥미로울 것 같아요 음 좋은 특징은

1525
01:01:45,200 --> 01:01:47,440
원칙적으로

1526
01:01:47,440 --> 01:01:49,359
일종의 자체 안정화 기능을 가져야 한다는 것입니다.

1527
01:01:49,359 --> 01:01:52,319
그림은

1528
01:01:52,319 --> 01:01:56,640
어 세포막의 역학을 실제로 모방하기 때문입니다.

1529
01:01:56,640 --> 01:01:59,839
만약

1530
01:01:59,839 --> 01:02:02,640
뉴로모픽 하드웨어가 어 그렇다면

1531
01:02:02,640 --> 01:02:04,640


1532
01:02:04,640 --> 01:02:08,079
가입의 모델

1533
01:02:08,079 --> 01:02:10,440
과 Neuron 모델이 매우

1534
01:02:10,440 --> 01:02:13,680
잘 일치한다면 모델은 어 당신에게 제공해야 합니다  이

1535
01:02:13,680 --> 01:02:16,400
멋진 자가 안정화 기능은

1536
01:02:16,400 --> 01:02:19,160
뉴런이 실제로 간질 상태에 빠지지 않도록 하며

1537
01:02:19,160 --> 01:02:20,880


1538
01:02:20,880 --> 01:02:22,720
이 모델에서 무료로 얻을 수 있는 기능입니다.

1539
01:02:22,720 --> 01:02:25,160
적어도 우리가 시뮬레이션에서 본 것입니다.

1540
01:02:25,160 --> 01:02:28,720
하지만 음, 시뮬레이션에서는 물론 우리가

1541
01:02:28,720 --> 01:02:30,960
이것을 완전히 제어할 수 있었습니다.  역학이

1542
01:02:30,960 --> 01:02:33,000
올바른 방식으로 일치하므로

1543
01:02:33,000 --> 01:02:36,680
음 하드웨어에는 좀 더 까다로울 수 있지만

1544
01:02:36,680 --> 01:02:39,200
아마도 해결 가능하므로

1545
01:02:39,200 --> 01:02:41,039
흥미로울 것입니다. 예 그러면

1546
01:02:41,039 --> 01:02:42,480
얻을 수 있는 것은

1547
01:02:42,480 --> 01:02:44,520


1548
01:02:44,520 --> 01:02:48,599
음 프리포스트 스파이크만 사용하는 순전히 이벤트 기반 도구가 있다는 것입니다.

1549
01:02:48,599 --> 01:02:49,520


1550
01:02:49,520 --> 01:02:53,000
정말 멋지군요. 감사합니다. 네 다니엘

1551
01:02:53,000 --> 01:02:55,200
질문이 있으시다면 그것은

1552
01:02:55,200 --> 01:02:58,559
훌륭한 원리입니다.

1553
01:02:58,559 --> 01:03:00,319


1554
01:03:00,319 --> 01:03:03,240
뉴로모픽 알고리즘을 설계하여

1555
01:03:03,240 --> 01:03:06,599


1556
01:03:06,599 --> 01:03:08,640
멤브레인의 실제 누출 투과성

1557
01:03:08,640 --> 01:03:12,599
이나 실제 공간적 근접성과 같은 물질적 특성을 활용하는 것과 같습니다.

1558
01:03:12,599 --> 01:03:15,640


1559
01:03:15,640 --> 01:03:19,000
가상화되지 않은 아날로그 기능의 중요한 기능을 활용할 수 있다면 이는

1560
01:03:19,000 --> 01:03:20,119
이미

1561
01:03:20,119 --> 01:03:23,079
미래의 하드웨어에 인접해 있는 것이므로 이는

1562
01:03:23,079 --> 01:03:25,760
한 가지 좋은 점이며

1563
01:03:25,760 --> 01:03:28,920
거의 생물학이 과학이 아니라는 점에 대한 점입니다.

1564
01:03:28,920 --> 01:03:32,520
음 유명한

1565
01:03:32,520 --> 01:03:34,480
인용문은 절대 없을 것입니다.

1566
01:03:34,480 --> 01:03:36,839
풀잎에 대한 뉴턴 왜냐하면 일부 사람들은

1567
01:03:36,839 --> 01:03:38,839
그래 그것은 다른 생물학이라고 말하기 때문에

1568
01:03:38,839 --> 01:03:41,079


1569
01:03:41,079 --> 01:03:42,680
발달이나

1570
01:03:42,680 --> 01:03:44,880
생태학 또는 진화의 관점에서 접근하든 생물학은 역사

1571
01:03:44,880 --> 01:03:46,640
과학이고 실제 과학과 같지 않기 때문에 역사와 더 비슷합니다.

1572
01:03:46,640 --> 01:03:49,480


1573
01:03:49,480 --> 01:03:53,000
우리 스포츠가 당신의 처벌이라고 말하는 크로스 컨트리 셔츠는

1574
01:03:53,000 --> 01:03:55,000


1575
01:03:55,000 --> 01:03:58,319
당신의

1576
01:03:58,319 --> 01:04:02,760
소음이 생물학의 신호라는 것과는 전혀 같지 않으며 그것이 어떻게

1577
01:04:02,760 --> 01:04:04,279


1578
01:04:04,279 --> 01:04:08,680
일어나는지 제 질문은 계산과 관련된 자원을 보는

1579
01:04:08,680 --> 01:04:10,640


1580
01:04:10,640 --> 01:04:14,039
신경적 방법과 계산적 방법 사이의 긴장에 관한 것이었습니다.

1581
01:04:14,039 --> 01:04:16,760


1582
01:04:16,760 --> 01:04:19,440


1583
01:04:19,440 --> 01:04:23,720
Von noyman Paradigm에서 우리는 많은

1584
01:04:23,720 --> 01:04:27,720
공유 참조 포인트를 가지고 있습니다. CPU 사이클, RAM

1585
01:04:27,720 --> 01:04:30,559
용량 및 이러한 모든 종류의 것들

1586
01:04:30,559 --> 01:04:34,520
그리고

1587
01:04:34,520 --> 01:04:36,559
소개에서도 여러분이 전달한 것과 같이

1588
01:04:36,559 --> 01:04:38,839
이것이 얼마나 많은 CPU 사이클을

1589
01:04:38,839 --> 01:04:41,799
거치는지 또는 이것이 얼마나 많은 매개변수를

1590
01:04:41,799 --> 01:04:43,920
가질 것인지입니다.  저장 또는

1591
01:04:43,920 --> 01:04:45,319


1592
01:04:45,319 --> 01:04:48,240
그와 유사한 것 그러나 그것은

1593
01:04:48,240 --> 01:04:53,160
다른 패러다임을 참조하고 있으므로 우리가 공간 밖에 있을 때

1594
01:04:53,160 --> 01:04:56,160
리소스

1595
01:04:56,880 --> 01:05:01,640
설명자나 용량 설명자는 어떻게 보일까요?

1596
01:05:01,640 --> 01:05:04,319


1597
01:05:04,319 --> 01:05:05,559
예, 전력 소비는

1598
01:05:05,559 --> 01:05:07,039
상자에 넣고

1599
01:05:07,039 --> 01:05:09,079
폭탄 열량계를 사용할 수 있는 것입니다.

1600
01:05:09,079 --> 01:05:12,520
낮게 매달려 있는 과일과 비슷하지만 이제는

1601
01:05:12,520 --> 01:05:15,760
괜찮습니다. 순수한 에너지나

1602
01:05:15,760 --> 01:05:16,960
칼로리

1603
01:05:16,960 --> 01:05:19,319
요구 사항을 넘어서

1604
01:05:19,319 --> 01:05:21,880


1605
01:05:21,880 --> 01:05:25,200
프로세서, RAM 또는 컴퓨터의 하드 드라이브에 관해 이야기하는 방식과 유사하다고 말할 수 있는 것은 그렇습니다.

1606
01:05:25,200 --> 01:05:27,759


1607
01:05:30,000 --> 01:05:32,839
나는

1608
01:05:32,839 --> 01:05:34,279
그것에 대해 좀 더 생각해야 할 것입니다.

1609
01:05:34,279 --> 01:05:35,200


1610
01:05:35,200 --> 01:05:37,240
제가

1611
01:05:37,240 --> 01:05:39,520
보여드린 슬라이드의 논문에 음, 뇌와 에너지에 대해 이야기하는 흥미로운 의견이 있다고 생각합니다.

1612
01:05:39,520 --> 01:05:41,119
거기에 제가 연결한 논문이 있었습니다.

1613
01:05:41,119 --> 01:05:42,359


1614
01:05:42,359 --> 01:05:43,839
QR C가 이제 없어졌기 때문에 참조하고 그것이 무엇인지 알려주세요. 음

1615
01:05:43,839 --> 01:05:46,520
그런데 거기에 흥미로운

1616
01:05:46,520 --> 01:05:48,920
아이디어가 있었습니다. 당신이 거기에서 무엇을 얻고 있는지에 대해 생각하지만

1617
01:05:48,920 --> 01:05:52,880
네, 신문에 맡겨야 할 것

1618
01:05:52,880 --> 01:05:55,279


1619
01:05:55,279 --> 01:05:57,200
같아요. 내 말은 그들이 무엇을 어떻게 설명하는지 말이에요.

1620
01:05:57,200 --> 01:06:00,520
설계 중에

1621
01:06:00,520 --> 01:06:03,200
이런 유형의 구성 요소가 이렇게 많이 있다고 말하는데

1622
01:06:03,200 --> 01:06:05,720
아무 효과가 없을 수도 있으므로

1623
01:06:05,720 --> 01:06:08,079
이러한

1624
01:06:08,079 --> 01:06:11,480
다양한 디자인이나

1625
01:06:11,640 --> 01:06:13,520
알고리즘을 어떻게 설명하거나 평가합니까? 사용 사례에 따라 모두 다르다고 생각합니다.

1626
01:06:13,520 --> 01:06:14,799
그게 바로

1627
01:06:14,799 --> 01:06:16,319
제가 찾은 것입니다.  정말 언어는

1628
01:06:16,319 --> 01:06:18,520


1629
01:06:18,520 --> 01:06:20,440


1630
01:06:20,440 --> 01:06:21,480
신경과학적 배경이나

1631
01:06:21,480 --> 01:06:23,799
공학적 배경을 더 많이 가진 사람이 쓴 것인지에 따라 다릅니다. 그런 다음

1632
01:06:23,799 --> 01:06:25,279
어떤 용어는

1633
01:06:25,279 --> 01:06:26,920
다른 용어보다 더 상호 교환이 가능하다고 말씀하셨는데, 제

1634
01:06:26,920 --> 01:06:29,400
생각에는 용어가 다음과 같습니다.  공간에서

1635
01:06:29,400 --> 01:06:31,559
훨씬 더 자세히 살펴봐야 할 내용입니다.

1636
01:06:31,559 --> 01:06:33,039
그러면

1637
01:06:33,039 --> 01:06:35,599
작업하는 모든 사람이 같은 페이지에 있는 데 도움이 될 것이라고 생각합니다.

1638
01:06:35,599 --> 01:06:38,799


1639
01:06:42,079 --> 01:06:44,359


1640
01:06:44,359 --> 01:06:47,960
다른 생각이나 질문이 있으면

1641
01:06:47,960 --> 01:06:51,440
David가 먼저, 그 다음에는 Sarah도 마찬가지입니다.

1642
01:06:51,440 --> 01:06:55,480
이 시리즈가 어떤 방향으로

1643
01:06:55,480 --> 01:06:59,039
진행될지 매우 궁금합니다. 하지만 먼저 David에게 제공하고 싶은 다른

1644
01:06:59,039 --> 01:07:02,119
마무리 의견이나 방향은 무엇입니까? 음

1645
01:07:02,119 --> 01:07:03,359


1646
01:07:03,359 --> 01:07:07,000
그렇지는 않습니다. 음 제 말은

1647
01:07:07,000 --> 01:07:09,480
오늘 저를 만나주셔서

1648
01:07:09,480 --> 01:07:11,279
정말 즐거웠다고 말씀드리고 싶습니다.

1649
01:07:11,279 --> 01:07:13,359


1650
01:07:13,359 --> 01:07:15,720
고마워요 데이빗,

1651
01:07:15,720 --> 01:07:17,000
당신을 모시게 되어서 정말 놀랐습니다. 당신의 작업은

1652
01:07:17,000 --> 01:07:19,079
정말 흥미롭고

1653
01:07:19,079 --> 01:07:20,880
앞으로도 구현에 많은 이점이 있을 것이라고 생각합니다.

1654
01:07:20,880 --> 01:07:23,400


1655
01:07:23,400 --> 01:07:26,559
항상 보기에도 좋은데, 음 예,

1656
01:07:26,559 --> 01:07:27,760
어디에서 질문이 있었나요?

1657
01:07:27,760 --> 01:07:30,279
시리즈가 진행되는 것으로 보나요 음

1658
01:07:30,279 --> 01:07:33,720
매달 새로운 게스트를 만날 수 있으면 좋겠습니다 음 아마도

1659
01:07:33,720 --> 01:07:36,240
다음 달에는 하드웨어를

1660
01:07:36,240 --> 01:07:38,680
만드는 사람이 있으면 좋을 것 같아요.

1661
01:07:38,680 --> 01:07:40,319


1662
01:07:40,319 --> 01:07:42,079
뇌 확장 팀이나 스피카 팀 같은 사람이요.  아니면

1663
01:07:42,079 --> 01:07:44,279
그런 것 꽤 괜찮을 것 같은데

1664
01:07:44,279 --> 01:07:46,880
음 그런데 정말 저는 이 교차로

1665
01:07:46,880 --> 01:07:49,119
에 관심이 있는 사람들이 어

1666
01:07:49,119 --> 01:07:52,359
사람들을 만나고

1667
01:07:52,359 --> 01:07:54,079
대화를 나누는 것을 볼 수 있는 공간을 갖고 싶습니다. 그리고

1668
01:07:54,079 --> 01:07:56,520
그 공간에서 일하고 있는 사람들에게도 연락할 수 있기 때문입니다.

1669
01:07:56,520 --> 01:07:59,319
왜냐하면 음  그것은 꽤 틈새 시장이지만

1670
01:07:59,319 --> 01:08:01,920
꽤 중요하다고 생각합니다. 음 실제로

1671
01:08:01,920 --> 01:08:03,400
David가 당신에게 연락하고

1672
01:08:03,400 --> 01:08:05,039
싶다면 그들이 당신에게 연락

1673
01:08:05,039 --> 01:08:08,359
할 수 있는 가장 좋은 방법이 무엇인지 모두에게 알릴 수 있다고 말했지요.

1674
01:08:08,359 --> 01:08:09,390


1675
01:08:09,390 --> 01:08:11,400
[음악]

1676
01:08:11,400 --> 01:08:13,960
음 저는 이 일에 그다지 적극적이지 않습니다.  Discord

1677
01:08:13,960 --> 01:08:16,399
채널이니까 이메일이 여전히 최선일 것 같아요

1678
01:08:16,399 --> 01:08:19,158
uh 연락하기 좋은 것 같아요

1679
01:08:19,158 --> 01:08:21,399


1680
01:08:21,399 --> 01:08:22,839
이메일

1681
01:08:22,839 --> 01:08:27,560
만 주고 싶으신가요 아 제 이메일은 찾기 쉬울 것 같지만

1682
01:08:27,560 --> 01:08:28,960


1683
01:08:28,960 --> 01:08:30,600


1684
01:08:30,600 --> 01:08:33,439
다른 사람들이 확인할 수 있는 이메일도 얻을 수 있어요  논문과

1685
01:08:33,439 --> 01:08:36,000
활성 추론 연구소

1686
01:08:36,000 --> 01:08:40,080
Discord에 뉴로모픽

1687
01:08:41,120 --> 01:08:43,719
채널이 있습니다. 감사합니다. David와

1688
01:08:43,719 --> 01:08:47,198
Sarah가 모프 스트림이 이런 식으로 발달 궤적을 시작하는 것을 보니 정말 멋집니다.

1689
01:08:47,198 --> 01:08:49,158


1690
01:08:49,158 --> 01:08:52,799
다음 시간까지 감사합니다.

1691
01:08:52,799 --> 01:08:54,109
안녕히 계세요

1692
01:08:54,109 --> 01:08:57,169
[음악]

1693
01:09:19,040 --> 01:09:22,040
좋아요

