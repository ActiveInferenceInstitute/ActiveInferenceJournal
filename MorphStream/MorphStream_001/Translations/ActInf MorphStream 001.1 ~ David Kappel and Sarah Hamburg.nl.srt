1
00:00:07,040 --> 00:00:10,320
Hallo allemaal, welkom, het is 26 september

2
00:00:10,320 --> 00:00:12,080


3
00:00:12,080 --> 00:00:15,120
2023. We trappen hier een nieuwe

4
00:00:15,120 --> 00:00:17,119
streamserie af bij het Active Inference

5
00:00:17,119 --> 00:00:20,400
Institute. Dit is de morph stream

6
00:00:20,400 --> 00:00:24,800
1.1. Vandaag hebben we David Kapple en ook

7
00:00:24,800 --> 00:00:27,960
deze sectie en streams gefaciliteerd door

8
00:00:27,960 --> 00:00:31,320
Sarah Hamburg. We gaan een

9
00:00:31,320 --> 00:00:35,440
overzicht eerst gepresenteerd door Sarah, daarna

10
00:00:35,440 --> 00:00:38,040
zal David wat werk over

11
00:00:38,040 --> 00:00:40,520
neuromorfisch computergebruik delen en dan

12
00:00:40,520 --> 00:00:42,879
hebben we wat tijd om te bespreken, dus bedankt

13
00:00:42,879 --> 00:00:45,480
voor je deelname en Sarah voor jou voor

14
00:00:45,480 --> 00:00:47,360
de eerste presentatie en ook om

15
00:00:47,360 --> 00:00:49,600
jezelf voor te stellen als je dat wilt, ja

16
00:00:49,600 --> 00:00:51,000
dat is  een goed idee, heel erg bedankt

17
00:00:51,000 --> 00:00:54,120
Daniel, dus mijn naam is Sarah, ik ben een

18
00:00:54,120 --> 00:00:56,120
neurowetenschapper die gespecialiseerd is in intelligentie en

19
00:00:56,120 --> 00:00:57,280
momenteel werkzaam is op het gebied van

20
00:00:57,280 --> 00:01:00,280
neuromorfisch computergebruik, bij chef field

21
00:01:00,280 --> 00:01:02,480
Hal in Groot-Brittannië, dus ik ga je een

22
00:01:02,480 --> 00:01:04,400
overzicht op hoog niveau geven  over wat neuromorphic

23
00:01:04,400 --> 00:01:06,720
Computing is en voordat we de

24
00:01:06,720 --> 00:01:08,640
opwindende toespraak van David horen in de eerste editie van

25
00:01:08,640 --> 00:01:11,320
deze nieuwe serie, gewoon om je te laten weten

26
00:01:11,320 --> 00:01:12,799
of je in de toekomst dubbele tijd kijkt.

27
00:01:12,799 --> 00:01:14,320
Ik praat vrij snel, dus misschien

28
00:01:14,320 --> 00:01:17,080
wil je me niet zien  dubbele tijd, dus

29
00:01:17,080 --> 00:01:19,400
deze QR-code die ik hier plaats, brengt je

30
00:01:19,400 --> 00:01:20,880
naar een artikel waarvan ik dacht dat het een hele

31
00:01:20,880 --> 00:01:23,520
leuke introductie tot het vakgebied was, maar

32
00:01:23,520 --> 00:01:25,520
neic Computers kunnen worden gedefinieerd als

33
00:01:25,520 --> 00:01:27,000
computersystemen die zijn ontworpen om

34
00:01:27,000 --> 00:01:28,680
de structuur en functie van het

35
00:01:28,680 --> 00:01:30,720
zenuwstelsel na te bootsen  dus dit hoeft niet

36
00:01:30,720 --> 00:01:32,680
het menselijke zenuwstelsel te zijn, het veld

37
00:01:32,680 --> 00:01:34,320
haalt feitelijk inspiratie uit allerlei

38
00:01:34,320 --> 00:01:36,640
soorten dieren en insecten, hoewel

39
00:01:36,640 --> 00:01:38,159
de definities online dat niet noodzakelijkerwijs

40
00:01:38,159 --> 00:01:40,680
erkennen, dus sommige mensen zijn

41
00:01:40,680 --> 00:01:42,200
vrij open over wat

42
00:01:42,200 --> 00:01:43,920
neuromorfisch is, terwijl anderen misschien daar de

43
00:01:43,920 --> 00:01:46,119
voorkeur aan geven  neuromorf was gereserveerd voor

44
00:01:46,119 --> 00:01:48,600
hardware-instanties van biologische

45
00:01:48,600 --> 00:01:50,520
neuronen, die soms worden

46
00:01:50,520 --> 00:01:53,280
aangeduid als niet-gebruikte computers en ik

47
00:01:53,280 --> 00:01:55,280
denk dat dat is waar het artikel waarnaar de QR-

48
00:01:55,280 --> 00:01:58,320
code verwijst, naar verwijst in hun

49
00:01:58,320 --> 00:02:00,280
definitie, dus wat ik denk dat echt

50
00:02:00,280 --> 00:02:01,200
interessant is  is een klein beetje van de

51
00:02:01,200 --> 00:02:02,920
context, dus zoals onze huidige vuman-

52
00:02:02,920 --> 00:02:04,479
computerarchitectuur ook werd geïnspireerd

53
00:02:04,479 --> 00:02:06,439
door Neuroscience en in het bijzonder het

54
00:02:06,439 --> 00:02:08,840
Mull and pits 43 Neuron-model um

55
00:02:08,840 --> 00:02:12,080
inspireerde Von y's eerste ontwerp in 1945, dus

56
00:02:12,080 --> 00:02:14,120
Neuroscience heeft een lange geschiedenis van eh

57
00:02:14,120 --> 00:02:16,120
inspirerende computerwetenschap en dit ook

58
00:02:16,120 --> 00:02:17,680
omvat versterkend leren dat is

59
00:02:17,680 --> 00:02:19,440
gebaseerd op theorieën over het leren van

60
00:02:19,440 --> 00:02:20,720
besluitvorming uit de

61
00:02:20,720 --> 00:02:22,480
gedragspsychologie, gebaseerd op beloningen en

62
00:02:22,480 --> 00:02:24,760
straffen, en ook heian-

63
00:02:24,760 --> 00:02:26,519
leerprincipes van cellen die samen vuren,

64
00:02:26,519 --> 00:02:29,239
vanaf 49 werden ze

65
00:02:29,239 --> 00:02:31,680
fundamenteel voor leren zonder toezicht,

66
00:02:31,680 --> 00:02:34,959
dus eerst en vooral: wacht

67
00:02:34,959 --> 00:02:37,640
even  Dus om het

68
00:02:37,640 --> 00:02:39,440
waarom van neuromorfisch computergebruik te begrijpen, wilde ik heel graag

69
00:02:39,440 --> 00:02:40,959
uitleggen wat er zo geweldig is aan

70
00:02:40,959 --> 00:02:44,120
de hersenen, dus hier is wat inspiratie

71
00:02:44,120 --> 00:02:46,360
voor gloeilampen, dus ik ga je

72
00:02:46,360 --> 00:02:47,280
een vraag stellen. Ik wil dat je er even over nadenkt  ten

73
00:02:47,280 --> 00:02:49,159
tweede in termen van

74
00:02:49,159 --> 00:02:51,239
gloeilampen, hoeveel energie denk je dat de

75
00:02:51,239 --> 00:02:53,879
hersenen gebruiken? Denk je dat het meer of

76
00:02:53,879 --> 00:02:56,280
minder energie is dan de lampen

77
00:02:56,280 --> 00:02:58,040
die de kamer waarin je je bevindt verlichten als je in de

78
00:02:58,040 --> 00:02:59,560
toekomst bent? PA, pauzeer dit als als

79
00:02:59,560 --> 00:03:01,200
je wilt wat diepgaande

80
00:03:01,200 --> 00:03:02,760
berekeningen doen, maar ik ga verder met

81
00:03:02,760 --> 00:03:06,680
het antwoord. Het antwoord staat hier in de

82
00:03:06,680 --> 00:03:10,159
roze cirkel, dus het is 20 watt, dus dat is

83
00:03:10,159 --> 00:03:12,200
het equivalent van een moderne

84
00:03:12,200 --> 00:03:14,519
energiezuinige gloeilamp, dus dat is waarschijnlijk

85
00:03:14,519 --> 00:03:16,280
wat ik nu boven me heb  eigenlijk in mijn kamer

86
00:03:16,280 --> 00:03:18,840
hier, deze QR-code zou je naar

87
00:03:18,840 --> 00:03:20,040
een behoorlijk interessant artikel moeten leiden over het

88
00:03:20,040 --> 00:03:21,239
energieverbruik in de hersenen als je

89
00:03:21,239 --> 00:03:23,080
daarin geïnteresseerd bent,

90
00:03:23,080 --> 00:03:25,360
dus dat komt neer op ongeveer vier

91
00:03:25,360 --> 00:03:28,519
bananen per dag om je hersenen van stroom te voorzien en

92
00:03:28,519 --> 00:03:30,760
dit wordt trouwens berekend  gebaseerd op de

93
00:03:30,760 --> 00:03:32,840
calorie-inname die de hersenen nodig hebben, dus

94
00:03:32,840 --> 00:03:35,200
voor de context de snelste supercomputer van

95
00:03:35,200 --> 00:03:36,720
Europa. Ik denk dat hij in Finland Lumi heet,

96
00:03:36,720 --> 00:03:38,560
hij wordt

97
00:03:38,560 --> 00:03:40,560
uitzonderlijk groen genoemd en het

98
00:03:40,560 --> 00:03:43,640
stroomverbruik is 8,5 miljoen watt, dus

99
00:03:43,640 --> 00:03:45,840
dat zijn ongeveer een half miljoen gloeilampen,

100
00:03:45,840 --> 00:03:48,840
nou ja, je hersenen gebruiken  slechts één dus dan

101
00:03:48,840 --> 00:03:49,879
is de vraag: wat doen je

102
00:03:49,879 --> 00:03:52,280
hersenen met die ene gloeilamp of

103
00:03:52,280 --> 00:03:54,200
vier

104
00:03:54,200 --> 00:03:57,599
bananen, blijkbaar voert het 1.000 miljard

105
00:03:57,599 --> 00:04:00,120
berekeningen per seconde uit, dus er zijn nog

106
00:04:00,120 --> 00:04:01,879
veel meer enorme schattingen beschikbaar,

107
00:04:01,879 --> 00:04:03,599
dit was niet eens de grootste in

108
00:04:03,599 --> 00:04:05,840
verschillende bestellingen  schattingen van de omvang

109
00:04:05,840 --> 00:04:07,799
zijn duidelijk erg speculatief, maar

110
00:04:07,799 --> 00:04:09,519
ze zijn allemaal enorm en ze zijn allemaal

111
00:04:09,519 --> 00:04:11,280
gebaseerd op het aantal neuronen waarmee ze

112
00:04:11,280 --> 00:04:13,840
verbonden zijn en de vuursnelheid, maar ik

113
00:04:13,840 --> 00:04:14,879
denk dat het voor de context heel belangrijk is

114
00:04:14,879 --> 00:04:17,040
dat supercomputers

115
00:04:17,040 --> 00:04:18,880
je nog niet kunnen evenaren  ken onze

116
00:04:18,880 --> 00:04:20,880
complexiteit van vaardigheden, eh of het

117
00:04:20,880 --> 00:04:23,400
aanpassingsvermogen van het menselijk brein, dus we

118
00:04:23,400 --> 00:04:25,520
excelleren ver voorbij supercomputers

119
00:04:25,520 --> 00:04:26,960
als het gaat om zaken als complexe

120
00:04:26,960 --> 00:04:29,120
besluitvorming, eh, leren van

121
00:04:29,120 --> 00:04:31,520
ervaring,

122
00:04:31,520 --> 00:04:34,039
dus hoe verhouden je hersenen zich tot AI, eh,

123
00:04:34,039 --> 00:04:36,039
dus ik zei dat moderne AI is  al door de

124
00:04:36,039 --> 00:04:38,199
hersenen geïnspireerd, maar kunstmatige

125
00:04:38,199 --> 00:04:41,240
neuronen zijn sterk vereenvoudigd, ze vangen

126
00:04:41,240 --> 00:04:42,600
niet de complexiteit van

127
00:04:42,600 --> 00:04:44,320
biologische neuronen of netwerken op, zoals niet

128
00:04:44,320 --> 00:04:47,240
eens in de buurt. Individuele neuronen lijken

129
00:04:47,240 --> 00:04:49,520
eigenlijk meer op netwerken zelf

130
00:04:49,520 --> 00:04:51,120
en onderzoek wijst uit dat het modelleren van één

131
00:04:51,120 --> 00:04:53,039
biologisch neuron vijf tot

132
00:04:53,039 --> 00:04:55,240
acht lagen diep kunstmatige neuronen

133
00:04:55,240 --> 00:04:57,080
Netwerk gemaakt van ongeveer duizend

134
00:04:57,080 --> 00:04:59,160
kunstmatige neuronen. Deze QR-code zou

135
00:04:59,160 --> 00:05:02,160
je naar het papier moeten brengen,

136
00:05:02,160 --> 00:05:04,919
daarvoor heb je 86 miljard neuronen in je

137
00:05:04,919 --> 00:05:07,120
hersenen. Ze werken samen om een

138
00:05:07,120 --> 00:05:09,160
zeer energie-efficiënte supercomputer met lage latentie te vormen

139
00:05:09,160 --> 00:05:11,560
die net boven de

140
00:05:11,560 --> 00:05:13,759
kamertemperatuur van het equivalent van ongeveer

141
00:05:13,759 --> 00:05:16,440
vier bananen per dag, dus hopelijk heb ik

142
00:05:16,440 --> 00:05:17,680
je een idee gegeven van hoe geweldig je

143
00:05:17,680 --> 00:05:19,720
hersenen zijn, alsof je dat nog niet wist

144
00:05:19,720 --> 00:05:21,960
en hoe het al is gebruikt

145
00:05:21,960 --> 00:05:24,039
om de, denk ik, vrij eenvoudige AI te inspireren

146
00:05:24,039 --> 00:05:25,560
die we nu hebben vergeleken met menselijke

147
00:05:25,560 --> 00:05:27,360
intelligentie, dus nu ga ik

148
00:05:27,360 --> 00:05:29,000
uitleggen hoe de belangrijkste kenmerken van de hersenen worden

149
00:05:29,000 --> 00:05:31,319
geïmplementeerd om onze

150
00:05:31,319 --> 00:05:33,720
volgende generatie AI en technologie te katalyseren

151
00:05:33,720 --> 00:05:35,080
via het veld van neuromorfisch

152
00:05:35,080 --> 00:05:37,680
computergebruik. Daarom zijn jullie hier allemaal

153
00:05:37,680 --> 00:05:39,960
zo traditioneel  vum en computers hebben

154
00:05:39,960 --> 00:05:42,039
fysiek gescheiden computer- en

155
00:05:42,039 --> 00:05:45,039
geheugeneenheden, hier links weergegeven. Tijdens de

156
00:05:45,039 --> 00:05:47,280
berekening moeten gegevens

157
00:05:47,280 --> 00:05:49,000
heel snel heen en weer worden overgedragen, dus er is in

158
00:05:49,000 --> 00:05:51,600
wezen een knelpunt voor snelheid en

159
00:05:51,600 --> 00:05:53,840
energie, terwijl in neuromorfe

160
00:05:53,840 --> 00:05:55,160
architecturen die hier rechts worden weergegeven

161
00:05:55,160 --> 00:05:57,400
met de  hulp van Dary

162
00:05:57,400 --> 00:05:59,639
Computing en geheugen komen op dezelfde

163
00:05:59,639 --> 00:06:01,840
plaats voor, dus er wordt gezegd dat ze op één plek zijn

164
00:06:01,840 --> 00:06:03,880
geplaatst. In wezen individuele

165
00:06:03,880 --> 00:06:06,080
neuronen voeren berekeningen uit, terwijl

166
00:06:06,080 --> 00:06:07,759
herinneringen worden weergegeven door de sterkte van

167
00:06:07,759 --> 00:06:09,720
de verbindingen, de gewichten tussen

168
00:06:09,720 --> 00:06:13,000
neuronen, zodat de bosjes, zodat chips zoals deze

169
00:06:13,000 --> 00:06:15,440
kunnen worden gemaakt met componenten uh  zoals

170
00:06:15,440 --> 00:06:17,919
mistas die bijvoorbeeld

171
00:06:17,919 --> 00:06:20,840
synaptische gewichten kunnen emuleren en deze architectuur

172
00:06:20,840 --> 00:06:22,960
verbetert de snelheid, het vermindert het

173
00:06:22,960 --> 00:06:24,520
energieverbruik en wat echt

174
00:06:24,520 --> 00:06:26,319
interessant is, is dat het massaal

175
00:06:26,319 --> 00:06:28,240
parallelle verwerking mogelijk maakt, wat betekent dat er

176
00:06:28,240 --> 00:06:30,080
tegelijkertijd aan meerdere problemen kan worden gewerkt,

177
00:06:30,080 --> 00:06:32,720
dus dit is bijzonder

178
00:06:32,720 --> 00:06:34,680
belangrijk deze architectuur voor verschillende

179
00:06:34,680 --> 00:06:37,039
doeleinden  gevallen, maar ook omdat we, nu we

180
00:06:37,039 --> 00:06:39,199
het einde van het Moos-logboek bereiken, het aantal

181
00:06:39,199 --> 00:06:41,520
transistors zijn dat je fysiek steeds

182
00:06:41,520 --> 00:06:44,599
kleiner en kleiner kunt maken om op een chip te passen.

183
00:06:44,599 --> 00:06:46,759
Het is ook belangrijk omdat de mensheid

184
00:06:46,759 --> 00:06:48,560
haar energieverbruik enorm moet verminderen

185
00:06:48,560 --> 00:06:51,520
tegen de achtergrond van de daling van

186
00:06:51,520 --> 00:06:54,400
het creëren van energie.  steeds krachtigere

187
00:06:54,400 --> 00:06:57,280
AI, dus kunstmatige neuronen

188
00:06:57,280 --> 00:06:59,560
gebruiken doorgaans continue activering,

189
00:06:59,560 --> 00:07:01,599
links weergegeven, ze zijn altijd aan, terwijl van

190
00:07:01,599 --> 00:07:03,560
neuromorfe neuronen wordt gezegd dat ze

191
00:07:03,560 --> 00:07:05,720
pieken, dus ze zijn aan of ze zijn uit,

192
00:07:05,720 --> 00:07:07,440
wat hier aan de rechterkant zo

193
00:07:07,440 --> 00:07:09,759
vergelijkbaar is  om een ​​actiepotentiaal te vormen,

194
00:07:09,759 --> 00:07:12,000
dus de voordelen hiervan zijn weer energie-

195
00:07:12,000 --> 00:07:14,160
efficiëntie en ook toepassingen

196
00:07:14,160 --> 00:07:16,319
waarbij timing belangrijk is en dit wordt

197
00:07:16,319 --> 00:07:18,720
gegeven dat hun gebeurtenis zo

198
00:07:18,720 --> 00:07:21,160
wezenlijk wordt aangestuurd dat ze het potentieel hebben

199
00:07:21,160 --> 00:07:23,759
voor ruimtelijke en temporele dimensies

200
00:07:23,759 --> 00:07:25,759
die vervolgens toegevoegde spatio-temporele codering mogelijk maken

201
00:07:25,759 --> 00:07:28,479
en verwerking van informatie,

202
00:07:28,479 --> 00:07:30,680
u vraagt ​​zich misschien af ​​wat de GPU's zijn,

203
00:07:30,680 --> 00:07:33,240
die ook parallelle verwerking mogelijk maken.

204
00:07:33,240 --> 00:07:35,080
Onderzoek wijst uit dat GPU's

205
00:07:35,080 --> 00:07:37,319
geschikte architecturen zijn voor het inzetten van

206
00:07:37,319 --> 00:07:39,599
spiking in uw netwerken, wat volgens mij

207
00:07:39,599 --> 00:07:41,280
dit een heel interessante tijd voor

208
00:07:41,280 --> 00:07:43,199
het veld maakt, gezien hoe high-end GPU's aan het

209
00:07:43,199 --> 00:07:46,159
worden zijn  steeds

210
00:07:46,159 --> 00:07:49,479
doordringender, dus de hersenen leren de sterkte

211
00:07:49,479 --> 00:07:51,599
van de synapsis tussen neuronen. Dit is

212
00:07:51,599 --> 00:07:53,560
gebaseerd op pre- en post-synaptische

213
00:07:53,560 --> 00:07:55,240
ontstekingspatronen. Ik denk dat de toespraak van David veel zal vertellen.

214
00:07:55,240 --> 00:07:57,680
We zullen hier veel dieper op ingaan,

215
00:07:57,680 --> 00:07:59,319
maar er zijn veel verschillende

216
00:07:59,319 --> 00:08:01,240
typen en  patronen hiervan in de

217
00:08:01,240 --> 00:08:03,720
hersenen, afhankelijk van het soort synapsen,

218
00:08:03,720 --> 00:08:05,599
zoals prikkelend tot remmend,

219
00:08:05,599 --> 00:08:06,919
prikkelend tot

220
00:08:06,919 --> 00:08:09,159
prikkelend, en het

221
00:08:09,159 --> 00:08:11,639
neuroommarktveld werkt eraan om deze regels te benutten,

222
00:08:11,639 --> 00:08:13,800
vanwege de voordelen voor leren op de chip

223
00:08:13,800 --> 00:08:16,159
en ook voor toepassingen zoals

224
00:08:16,159 --> 00:08:18,039
patroonherkenning en Edge Computing

225
00:08:18,039 --> 00:08:19,599
ook is Edge Computing een behoorlijk

226
00:08:19,599 --> 00:08:21,680
groot gebruiksscenario voor neuromorf computergebruik

227
00:08:21,680 --> 00:08:23,000
vanwege het soort gebeurtenisgestuurde

228
00:08:23,000 --> 00:08:26,240
karakter en ook het lage energieverbruik, en

229
00:08:26,240 --> 00:08:27,879
deze QR-code zou je naar een behoorlijk

230
00:08:27,879 --> 00:08:31,839
interessant artikel over stdp moeten brengen dat ik heb

231
00:08:31,839 --> 00:08:34,799
gevonden, dus wat neuromorfe oplossingen zijn

232
00:08:34,799 --> 00:08:36,159
nu beschikbaar, je zou kunnen denken dat het

233
00:08:36,159 --> 00:08:38,320
theoretisch is, er zijn eigenlijk veel

234
00:08:38,320 --> 00:08:40,200
verschillende oplossingen die ik

235
00:08:40,200 --> 00:08:41,559
je een overzicht op heel hoog niveau zal geven,

236
00:08:41,559 --> 00:08:44,120
dus het menselijk breinproject

237
00:08:44,120 --> 00:08:45,760
heeft verschillende grootschalige

238
00:08:45,760 --> 00:08:48,120
neuromorfe computers gecreëerd, waaronder spica, en

239
00:08:48,120 --> 00:08:49,800
deze is deze  aan de onderkant

240
00:08:49,800 --> 00:08:51,560
lijkt dit misschien alsof ik de

241
00:08:51,560 --> 00:08:53,480
grootte van mijn gezicht niet weet of zoiets, dus dat

242
00:08:53,480 --> 00:08:55,760
draait in realtime en het bestaat

243
00:08:55,760 --> 00:08:58,200
uit meerdere algemene doeleinden op

244
00:08:58,200 --> 00:09:00,279
microprocessors en er waren ook

245
00:09:00,279 --> 00:09:03,120
hersenschalen, wat een versnelde analoge

246
00:09:03,120 --> 00:09:05,399
architectuur is en het draait  duizend

247
00:09:05,399 --> 00:09:09,240
keer realtime, dus het bord naast

248
00:09:09,240 --> 00:09:11,120
het blauwe, dat is een echt

249
00:09:11,120 --> 00:09:13,240
creditcardformaat, een versie van hersenschalen

250
00:09:13,240 --> 00:09:14,399
die ze onlangs hebben gemaakt, waarvan ik

251
00:09:14,399 --> 00:09:16,920
dacht dat het best cool was, eh, en dan

252
00:09:16,920 --> 00:09:18,399
zijn er ook een aantal grote spelers in de

253
00:09:18,399 --> 00:09:21,000
ruimte, dus  deze blauwe hier is de

254
00:09:21,000 --> 00:09:23,640
Loi-chip van Intel, ze zijn bezig met lii 2, dat is

255
00:09:23,640 --> 00:09:25,480
hun neuromorfe chip en ze hebben

256
00:09:25,480 --> 00:09:27,000
daar ook een open source softwareframework voor,

257
00:09:27,000 --> 00:09:27,920
omdat ze echt

258
00:09:27,920 --> 00:09:29,480
de open source-sleutelgemeenschap willen katalyseren om er mee

259
00:09:29,480 --> 00:09:32,079
betrokken te raken, zo neuromorf  Er

260
00:09:32,079 --> 00:09:34,040
bestaan ​​ook sensoren, dus dit kleine blauwe

261
00:09:34,040 --> 00:09:35,000
ding in het midden is eigenlijk een

262
00:09:35,000 --> 00:09:36,800
neuromorfe camera. Het is misschien zo'n

263
00:09:36,800 --> 00:09:40,040
grote, dus ze willen nabootsen hoe ons

264
00:09:40,040 --> 00:09:42,480
zenuwstelsel prikkels zoals

265
00:09:42,480 --> 00:09:44,880
licht waarneemt, dus bijvoorbeeld in een neuromorfe

266
00:09:44,880 --> 00:09:47,200
camera, die hier elke pixel is.

267
00:09:47,200 --> 00:09:49,560
werkt onafhankelijk met een microsc-

268
00:09:49,560 --> 00:09:52,120
resolutie, hopelijk werkt mijn GIF,

269
00:09:52,120 --> 00:09:54,440
daar gaan we, zodat je elke pixel daar kunt zien

270
00:09:54,440 --> 00:09:56,680
werken, wat best gaaf is, dus

271
00:09:56,680 --> 00:09:58,760
vergeleken met traditionele digitale camera's

272
00:09:58,760 --> 00:10:00,120
hebben ze verbeterde prestaties met

273
00:10:00,120 --> 00:10:02,920
beweging en een lager stroomverbruik. Er

274
00:10:02,920 --> 00:10:05,120
was onlangs ook een neuromorfe neus  door

275
00:10:05,120 --> 00:10:07,079
Intel, wat behoorlijk cool was, zodat het

276
00:10:07,079 --> 00:10:08,440
de geur van een chemische stof kon leren

277
00:10:08,440 --> 00:10:10,959
na slechts één blootstelling, en dan

278
00:10:10,959 --> 00:10:12,480
kon het die geur identificeren, zelfs als het

279
00:10:12,480 --> 00:10:15,279
door anderen werd gemaskeerd, en dan

280
00:10:15,279 --> 00:10:17,959
is dit uiteindelijk een mensachtige robot die een iub wordt genoemd

281
00:10:17,959 --> 00:10:19,240
en wat je kunt  wat je doet is dat je daadwerkelijk

282
00:10:19,240 --> 00:10:21,200
neuromorfe sensoren kunt integreren, zoals

283
00:10:21,200 --> 00:10:24,000
de camera en vervolgens neuromorfe chips,

284
00:10:24,000 --> 00:10:27,000
misschien spa- of hersenweegschalen, in een

285
00:10:27,000 --> 00:10:28,440
mensachtig apparaat als dit of andere

286
00:10:28,440 --> 00:10:30,560
apparaten zoals een drone, en van daaruit

287
00:10:30,560 --> 00:10:31,839
kun je feitelijk belichaamde

288
00:10:31,839 --> 00:10:34,200
neuromorfe systemen creëren, en dit is

289
00:10:34,200 --> 00:10:35,839
iets dat  waar we aan werken in het Smart

290
00:10:35,839 --> 00:10:37,519
Interactive Technologies-onderzoekslaboratorium in

291
00:10:37,519 --> 00:10:40,320
Sheffield in

292
00:10:40,480 --> 00:10:42,600
Groot-Brittannië. Deze dia belicht slechts enkele van

293
00:10:42,600 --> 00:10:43,959
de potentiële toepassingen van

294
00:10:43,959 --> 00:10:45,480
neuromorfisch computergebruik waarvan ik dacht dat ze

295
00:10:45,480 --> 00:10:46,720
behoorlijk interessant waren als je erover nadenkt,

296
00:10:46,720 --> 00:10:49,120
dus het begrijpen van

297
00:10:49,120 --> 00:10:51,560
contextpatroonherkenning Geavanceerde detectie van weinig

298
00:10:51,560 --> 00:10:54,360
schot leren  generaliseren over taken,

299
00:10:54,360 --> 00:10:56,839
complexe besluitvorming, uitlegbaarheid

300
00:10:56,839 --> 00:10:59,519
en herseninterfaces, dus al deze

301
00:10:59,519 --> 00:11:01,360
vaardigheden zijn echt nuttig als je

302
00:11:01,360 --> 00:11:03,399
denkt aan mensgerichte realtime

303
00:11:03,399 --> 00:11:06,240
toepassingen in dynamische omgevingen, bijvoorbeeld

304
00:11:06,240 --> 00:11:07,839
zaken als zelfrijdende auto's,

305
00:11:07,839 --> 00:11:10,000
en persoonlijk denk ik dat

306
00:11:10,000 --> 00:11:12,800
neuromorfe systemen, eh  zijn waarschijnlijk ook

307
00:11:12,800 --> 00:11:14,360
het toekomstige substraat van

308
00:11:14,360 --> 00:11:16,000
hersencomputerinterfaces, waarschijnlijk een beetje

309
00:11:16,000 --> 00:11:17,959
bevooroordeeld omdat ik een neurowetenschapper ben, maar

310
00:11:17,959 --> 00:11:19,959
ze hebben weinig energie, ze zijn realtime

311
00:11:19,959 --> 00:11:22,000
en ze hebben ook architecturen die

312
00:11:22,000 --> 00:11:24,839
passen bij onze eigen hardware, dus ik denk wel dat

313
00:11:24,839 --> 00:11:26,560
we '  We zullen binnenkort zien dat het BCI-veld wordt

314
00:11:26,560 --> 00:11:28,680
gekatalyseerd door neuromorfe systemen,

315
00:11:28,680 --> 00:11:29,480
met name

316
00:11:29,480 --> 00:11:31,360
misschien voor hybriden van hardware en

317
00:11:31,360 --> 00:11:33,680
natte kleding, dus misschien zelfs de

318
00:11:33,680 --> 00:11:35,800
eigen hersencellen van mensen, je kent wel

319
00:11:35,800 --> 00:11:37,399
hersencellen die je feitelijk kunt laten groeien

320
00:11:37,399 --> 00:11:40,160
uit slechts een

321
00:11:40,360 --> 00:11:43,040
haarcel, en de specifieke focus van ons

322
00:11:43,040 --> 00:11:45,160
werk is  het ontwerpen van AI die op een

323
00:11:45,160 --> 00:11:47,120
vergelijkbare manier leert als een mens, dus het heeft een

324
00:11:47,120 --> 00:11:48,959
aangeboren gevoel van nieuwsgierigheid en het leert

325
00:11:48,959 --> 00:11:51,560
door interactie met de echte wereld,

326
00:11:51,560 --> 00:11:53,959
dus in de jaren vijftig zei Alan Turing in plaats

327
00:11:53,959 --> 00:11:56,079
van te proberen een programma te produceren om

328
00:11:56,079 --> 00:11:58,519
de volwassen geest te simuleren, waarom niet liever

329
00:11:58,519 --> 00:12:00,360
probeer er een te produceren die de

330
00:12:00,360 --> 00:12:02,760
hersenen van het kind stimuleert. Als dit vervolgens

331
00:12:02,760 --> 00:12:04,560
aan een passende opleiding zou worden onderworpen,

332
00:12:04,560 --> 00:12:07,480
zou men de hersenen van volwassenen verkrijgen. Dit is

333
00:12:07,480 --> 00:12:09,360
in hoge mate de filosofie achter de

334
00:12:09,360 --> 00:12:12,320
neurologische ontwikkelingsbenadering van Ai en

335
00:12:12,320 --> 00:12:13,800
neuromorfisch computergebruik, die ik daar alleen maar

336
00:12:13,800 --> 00:12:15,800
wilde

337
00:12:15,800 --> 00:12:17,839
benadrukken.  zijn enkele uitdagingen

338
00:12:17,839 --> 00:12:19,839
in het veld, deze zijn van zeer hoog niveau,

339
00:12:19,839 --> 00:12:20,880
maar ik zal je er een klein

340
00:12:20,880 --> 00:12:23,760
idee van geven, dus het trainen van spiking neurale

341
00:12:23,760 --> 00:12:25,079
netwerken is complexer dan

342
00:12:25,079 --> 00:12:27,199
traditionele neurale netwerken. Ook het

343
00:12:27,199 --> 00:12:28,560
ontwerpen van hardware die feitelijk

344
00:12:28,560 --> 00:12:31,079
spiking neurale netwerken stdp implementeert

345
00:12:31,079 --> 00:12:33,120
op een  Er wordt gezegd dat grootschalige schaal behoorlijk

346
00:12:33,120 --> 00:12:35,120
uitdagend is en dan ook

347
00:12:35,120 --> 00:12:36,480
algoritmen ontwikkelen die

348
00:12:36,480 --> 00:12:38,959
al deze technologieën effectief kunnen gebruiken,

349
00:12:38,959 --> 00:12:41,440
dus de hardware, de stdp,

350
00:12:41,440 --> 00:12:45,399
het is een voortdurend actief

351
00:12:45,399 --> 00:12:48,760
onderzoeksgebied, dus als je hier bent, ben je

352
00:12:48,760 --> 00:12:50,959
waarschijnlijk geïnteresseerd in actieve gevolgtrekking,

353
00:12:50,959 --> 00:12:52,560
dus  Ik wilde dit benadrukken. Eigenlijk heeft

354
00:12:52,560 --> 00:12:53,839
iemand vandaag een van deze onderzoeken op de Discord gezet,

355
00:12:53,839 --> 00:12:55,839
wat best cool is, dus een

356
00:12:55,839 --> 00:12:58,040
paar recente onderzoeken hebben

357
00:12:58,040 --> 00:12:59,560
neuromorfe computertechnologie gecombineerd met

358
00:12:59,560 --> 00:13:01,720
principes van actieve inferentie, dus actieve

359
00:13:01,720 --> 00:13:03,720
inferentie komt uit de neurowetenschappen en ik

360
00:13:03,720 --> 00:13:05,040
zou zeggen dat het zich leent  heel

361
00:13:05,040 --> 00:13:06,600
goed voor neuromorfe

362
00:13:06,600 --> 00:13:08,760
architecturen, in een recent artikel over

363
00:13:08,760 --> 00:13:10,680
belichaamde neuromorfe intelligentie, dus

364
00:13:10,680 --> 00:13:12,320
niet, het vermeldde niet echt actieve

365
00:13:12,320 --> 00:13:14,279
gevolgtrekking daarin, de QR-code

366
00:13:14,279 --> 00:13:16,279
rechtsboven hier, er werd gesuggereerd dat er een

367
00:13:16,279 --> 00:13:18,079
echte doorbraak in neuromorfie zou

368
00:13:18,079 --> 00:13:19,959
plaatsvinden als het geheel  Het systeemontwerp is

369
00:13:19,959 --> 00:13:21,839
gebaseerd op biologische computationele

370
00:13:21,839 --> 00:13:23,800
principes met een nauw verband

371
00:13:23,800 --> 00:13:25,199
tussen de inschatting van de

372
00:13:25,199 --> 00:13:27,360
omgeving en de staat van de robot

373
00:13:27,360 --> 00:13:30,240
en de besluitvorming, planning en actie,

374
00:13:30,240 --> 00:13:31,600
dus sommige van deze thema's kunnen

375
00:13:31,600 --> 00:13:32,839
redelijk bekend in de oren klinken voor mensen die geïnteresseerd zijn in

376
00:13:32,839 --> 00:13:35,199
actieve gevolgtrekking en U. Ik zou willen voorstellen

377
00:13:35,199 --> 00:13:36,959
dat actieve  inferentie is goed geplaatst om aan

378
00:13:36,959 --> 00:13:39,160
deze vereisten te voldoen en ik

379
00:13:39,160 --> 00:13:40,600
wilde hier alleen een paar recente onderzoeken onder de aandacht brengen,

380
00:13:40,600 --> 00:13:43,079
dus deze aan de linkerkant.

381
00:13:43,079 --> 00:13:45,000
Gandal FAL demonstreerde onlangs

382
00:13:45,000 --> 00:13:47,519
plasticiteit en snel leren zonder toezicht

383
00:13:47,519 --> 00:13:50,240
in een neuromorf systeem met behulp van

384
00:13:50,240 --> 00:13:52,560
actieve inferentieprincipes. De auteur

385
00:13:52,560 --> 00:13:53,800
suggereerde dat hun experimenten zouden kunnen

386
00:13:53,800 --> 00:13:55,560
worden aangenomen om hersenachtige

387
00:13:55,560 --> 00:13:58,759
voorspellende vermogens te implementeren in neuro-

388
00:13:58,759 --> 00:14:01,480
neuromorfe robotsystemen en dan

389
00:14:01,480 --> 00:14:03,000
was er het gerecht frin-papier waar sommigen van

390
00:14:03,000 --> 00:14:05,560
jullie misschien bekend mee zijn door Kagan atal,

391
00:14:05,560 --> 00:14:08,399
dus dit was een hybride um wetwear Hardware

392
00:14:08,399 --> 00:14:10,399
neuromorfisch systeem waarvan de auteur

393
00:14:10,399 --> 00:14:12,759
beweerde dat het belichaamd was  het systeem liet zien dat

394
00:14:12,759 --> 00:14:14,480
ouders snel het pong-spel leerden

395
00:14:14,480 --> 00:14:16,839
met behulp van het vrije-energieprincipe voor

396
00:14:16,839 --> 00:14:19,040
leren en de auteurs beweerden dat

397
00:14:19,040 --> 00:14:20,720
het systeem synthetische

398
00:14:20,720 --> 00:14:21,959
biologische

399
00:14:21,959 --> 00:14:24,320
intelligentie vertoonde, dus het veld dat

400
00:14:24,320 --> 00:14:25,920
actieve invloedsprincipes implementeert in

401
00:14:25,920 --> 00:14:28,480
neuromorfe systemen is zeer actueel en

402
00:14:28,480 --> 00:14:31,199
het idee achter deze mream-serie is  om

403
00:14:31,199 --> 00:14:33,480
een ​​ruimte en een gemeenschap te creëren om

404
00:14:33,480 --> 00:14:36,079
kennisideeën en expertise te delen om

405
00:14:36,079 --> 00:14:38,240
het veld te katalyseren. Ik denk dat er waarschijnlijk een aantal

406
00:14:38,240 --> 00:14:40,560
echt opwindende technologische sprongen

407
00:14:40,560 --> 00:14:42,839
uit dit gebied zullen komen, dus

408
00:14:42,839 --> 00:14:44,880
bedankt voor het luisteren naar mijn uh snelle

409
00:14:44,880 --> 00:14:48,920
run door neuromorfe 101 eh en de

410
00:14:48,920 --> 00:14:51,880
volgende  we gaan van David horen, dus David komt

411
00:14:51,880 --> 00:14:53,519
naar jou toe als je jezelf wilt voorstellen,

412
00:14:53,519 --> 00:14:56,399
bedankt

413
00:14:56,399 --> 00:14:59,639
Sarah, ik zou

414
00:14:59,639 --> 00:15:02,320
mijn scherm delen

415
00:15:03,320 --> 00:15:06,320


416
00:15:10,820 --> 00:15:14,040
[Muziek]

417
00:15:14,040 --> 00:15:17,600
ja, kun je nu mijn

418
00:15:17,600 --> 00:15:21,240
scherm zien, de presentatie ja oké perfect

419
00:15:21,240 --> 00:15:24,240
oké ja hallo mijn mijn naam is

420
00:15:24,240 --> 00:15:27,639
David Kle Ik ben een onderzoeker en

421
00:15:27,639 --> 00:15:30,519
leider van de staatsgreep bij het Institute for um M

422
00:15:30,519 --> 00:15:33,839
informatica aan de Universiteit van bom um,

423
00:15:33,839 --> 00:15:36,040
dus ik leid de groep op het gebied van

424
00:15:36,040 --> 00:15:37,920
duurzaam machinaal leren en we hebben

425
00:15:37,920 --> 00:15:40,199
een zeer sterke focus op neuromorfe

426
00:15:40,199 --> 00:15:41,800
computers, daarom ben ik  hier

427
00:15:41,800 --> 00:15:44,360
vandaag en ik ga beginnen met een zeer

428
00:15:44,360 --> 00:15:47,279
vergelijkbare motivatie als Sarah, wat

429
00:15:47,279 --> 00:15:49,240
echt een geweldige inspiratie was voor

430
00:15:49,240 --> 00:15:51,959
deze lezing. Ik denk dat de meesten van

431
00:15:51,959 --> 00:15:54,560
jullie dit interessante

432
00:15:54,560 --> 00:15:57,120
recente resultaat hebben gezien en ik bedoel niet Duitsland

433
00:15:57,120 --> 00:15:59,120
het winnen van het basketbalkampioenschapsschip,

434
00:15:59,120 --> 00:16:03,880
maar een hele grote sprong in de

435
00:16:03,880 --> 00:16:05,319
kunstmatige intelligentie die we

436
00:16:05,319 --> 00:16:07,079
de afgelopen jaren hebben gezien, vooral de

437
00:16:07,079 --> 00:16:08,959
afgelopen twee of drie jaar, dus dit is een

438
00:16:08,959 --> 00:16:11,480
foto die is gegenereerd op basis van een prompt van een

439
00:16:11,480 --> 00:16:14,360
doly-netwerk en het is echt

440
00:16:14,360 --> 00:16:16,399
geweldig en  werd

441
00:16:16,399 --> 00:16:18,519
nog maar twee jaar

442
00:16:18,519 --> 00:16:22,360
geleden als science fiction beschouwd en dit werd in wezen

443
00:16:22,360 --> 00:16:24,120
mogelijk gemaakt door een neuromorfe benadering

444
00:16:24,120 --> 00:16:26,680
die bestaat uit diepe neurale netwerken en

445
00:16:26,680 --> 00:16:28,079
deze diepe neurale netwerken zijn

446
00:16:28,079 --> 00:16:31,120
nu enorm geworden, maar dit komt ook met

447
00:16:31,120 --> 00:16:33,839
een voorbehoud, dus eigenlijk is de keerzijde

448
00:16:33,839 --> 00:16:36,639
dat dit naast andere problemen misschien

449
00:16:36,639 --> 00:16:40,360
deze modellen kunnen hebben, ze verbruiken

450
00:16:40,360 --> 00:16:43,959
enorme hoeveelheden energie, dus modellen zoals um

451
00:16:43,959 --> 00:16:47,279
Dal of jet GPT, zoals Sarah al

452
00:16:47,279 --> 00:16:50,360
zei, ze zouden een

453
00:16:50,360 --> 00:16:52,680
energiebudget verbruiken dat vergelijkbaar is met

454
00:16:52,680 --> 00:16:56,759
huizen of auto's, dus training um jgpt a  een

455
00:16:56,759 --> 00:16:59,440
enkele keer is ongeveer een giga-uur,

456
00:16:59,440 --> 00:17:02,680
dus dat zou 300 ton

457
00:17:02,680 --> 00:17:07,160
CO2-uitstoot zijn, en vele malen,

458
00:17:07,160 --> 00:17:09,760
wat neerkomt op vele malen de levensduur

459
00:17:09,760 --> 00:17:13,359
van een typische auto, dus dit

460
00:17:13,359 --> 00:17:15,280
brengt uiteraard twee problemen met zich mee,

461
00:17:15,280 --> 00:17:17,880
dit maakt training deze  modellen die alleen

462
00:17:17,880 --> 00:17:20,160
toegankelijk zijn voor een heel klein aantal

463
00:17:20,160 --> 00:17:21,799
zeer grote spelers, dus in wezen de

464
00:17:21,799 --> 00:17:24,599
grote technologiebedrijven, en ten tweede en

465
00:17:24,599 --> 00:17:26,319
misschien nog belangrijker, dit is niet

466
00:17:26,319 --> 00:17:29,160
verenigbaar met een planeet met

467
00:17:29,160 --> 00:17:31,880
beperkte middelen, dus als de groeisnelheid

468
00:17:31,880 --> 00:17:34,160
van AI doorgaat zoals in de vorige eeuw  De komende

469
00:17:34,160 --> 00:17:35,360
jaren zal

470
00:17:35,360 --> 00:17:38,240
het 133% van het mondiale energieverbruik verbruiken

471
00:17:38,240 --> 00:17:41,400
in 20-30 en het zal

472
00:17:41,400 --> 00:17:45,080
in feite

473
00:17:45,080 --> 00:17:48,200
over nog eens vijf jaar de transportsector voorbijstreven,

474
00:17:48,200 --> 00:17:50,720
dus dit roept de vraag op of er

475
00:17:50,720 --> 00:17:52,600
überhaupt duurzaam machinaal leren bestaat,

476
00:17:52,600 --> 00:17:55,080
en natuurlijk omdat ik aan het werk ben  in

477
00:17:55,080 --> 00:17:56,799
de groep van duurzaam machinaal

478
00:17:56,799 --> 00:17:59,039
leren geloof ik van wel

479
00:17:59,039 --> 00:18:01,799
en de reden waarom ik denk van wel is omdat we

480
00:18:01,799 --> 00:18:04,960
een systeem kennen dat zeer efficiënt is

481
00:18:04,960 --> 00:18:08,600
en waarschijnlijk nog steeds beter is dan

482
00:18:08,600 --> 00:18:11,039
deze AI-modellen, namelijk het menselijk brein

483
00:18:11,039 --> 00:18:13,000
dat consumeert, zoals Sarah rond 20 zei.

484
00:18:13,000 --> 00:18:14,039


485
00:18:14,039 --> 00:18:16,919
watt uh of vier bananen per

486
00:18:16,919 --> 00:18:21,400
dag uh en uh dus het is vele ordes

487
00:18:21,400 --> 00:18:24,400
van grootte efficiënter dan de AI-

488
00:18:24,400 --> 00:18:26,200
modellen die we

489
00:18:26,200 --> 00:18:29,480
vandaag hebben uh maar tot nu toe weten we in

490
00:18:29,480 --> 00:18:32,480
essentie niet hoe deze netwerken werken eh

491
00:18:32,480 --> 00:18:34,520
en vooral hoe we ze moeten trainen en

492
00:18:34,520 --> 00:18:37,080
in principe onze  ons doel is om

493
00:18:37,080 --> 00:18:39,559
nu mechanismen van machinaal leren over te dragen,

494
00:18:39,559 --> 00:18:41,679
dus je hebt hier een mooie foto.

495
00:18:41,679 --> 00:18:44,679
Eigenlijk beginnen we vanaf de

496
00:18:44,679 --> 00:18:46,440
machine learning-site waar we de

497
00:18:46,440 --> 00:18:49,400
weg al kennen, dus we hebben deze

498
00:18:49,400 --> 00:18:51,280
modellen die geweldig zijn en die

499
00:18:51,280 --> 00:18:53,120
behoorlijk goed zijn  we hebben echt

500
00:18:53,120 --> 00:18:55,240
indrukwekkende resultaten, maar ze zijn niet

501
00:18:55,240 --> 00:18:57,480
efficiënt en we willen

502
00:18:57,480 --> 00:19:01,840
ze overbrengen naar een nieuwe, efficiënte uh AI-

503
00:19:01,840 --> 00:19:04,120
generatie en onze ideeën zijn om

504
00:19:04,120 --> 00:19:07,520
inspiratie uit de neurowetenschappen te gebruiken, die

505
00:19:07,520 --> 00:19:09,799
deze overdracht

506
00:19:09,799 --> 00:19:12,240
in de eerste

507
00:19:12,240 --> 00:19:17,039
plaats sneller en mogelijk maken, oké, en eigenlijk biologie  is een

508
00:19:17,039 --> 00:19:19,679
geweldige inspiratiebron en

509
00:19:19,679 --> 00:19:21,400
komt altijd om de hoek met zeer

510
00:19:21,400 --> 00:19:23,200
verrassende resultaten en een van deze

511
00:19:23,200 --> 00:19:24,960
resultaten die ik een paar

512
00:19:24,960 --> 00:19:30,919
jaar geleden tegenkwam, is dat het vermogen van eh

513
00:19:30,919 --> 00:19:33,559
bosjes in de hersenen, zoals je waarschijnlijk

514
00:19:33,559 --> 00:19:35,200
weet, neuronen in je hersenen  zijn verbonden

515
00:19:35,200 --> 00:19:36,159
voor

516
00:19:36,159 --> 00:19:40,960
copses, maar als je naar het artikel kijkt, dus

517
00:19:40,960 --> 00:19:43,480
dit is een artikel uit

518
00:19:43,480 --> 00:19:45,919
2019 en ze zouden

519
00:19:45,919 --> 00:19:47,320
individuele Sy-ups kunnen identificeren en ze kunnen

520
00:19:47,320 --> 00:19:49,400
ze ertoe aanzetten om een ​​synoptische

521
00:19:49,400 --> 00:19:51,799
release te maken zoals een enkele transmissie, maar

522
00:19:51,799 --> 00:19:54,840
als je hiernaar kijkt, um um  bij deze

523
00:19:54,840 --> 00:19:57,799
metingen zie je dat dit echt

524
00:19:57,799 --> 00:20:00,320
bedekt is met ruis, dus als

525
00:20:00,320 --> 00:20:02,960
je hier feitelijk het gemiddelde over neemt en

526
00:20:02,960 --> 00:20:04,720
uitzoomt, zie je hier deze typische

527
00:20:04,720 --> 00:20:06,679
synoptische sporen, wat hier de gemiddelde

528
00:20:06,679 --> 00:20:09,240
witte lijn is, maar daaronder zie je

529
00:20:09,240 --> 00:20:12,080
dit enorme gekwetter, dus daar zijn ze  echt

530
00:20:12,080 --> 00:20:14,960
leuk om verschillende standaardafwijkingen

531
00:20:14,960 --> 00:20:16,120
op en

532
00:20:16,120 --> 00:20:18,640
neer te gaan en dit is eigenlijk heel

533
00:20:18,640 --> 00:20:21,000
verrassend gezien het feit dat neuronen

534
00:20:21,000 --> 00:20:23,480
waarschijnlijk het duurste

535
00:20:23,480 --> 00:20:25,559
celtype in je lichaam zijn in termen van energieverbruik waar

536
00:20:25,559 --> 00:20:28,840
ze echt in zitten of in

537
00:20:28,840 --> 00:20:32,000
vergelijking daarmee verbruiken ze behoorlijk

538
00:20:32,000 --> 00:20:34,159
wat  van energie in je lichaam, dus je

539
00:20:34,159 --> 00:20:36,440
zou verwachten dat deze overgangen of

540
00:20:36,440 --> 00:20:38,720
transmissies die

541
00:20:38,720 --> 00:20:41,480
tussen neuronen worden gecommuniceerd en die erg kostbaar zijn,

542
00:20:41,480 --> 00:20:43,480
zeer betrouwbaar zouden moeten zijn, dus dit is

543
00:20:43,480 --> 00:20:46,120
zeer contra-intuïtief. Dit resultaat is een

544
00:20:46,120 --> 00:20:48,120
raadsel voor neurowetenschappers al

545
00:20:48,120 --> 00:20:50,039
een tijdje,

546
00:20:50,039 --> 00:20:53,600
eh, en dan is er

547
00:20:53,600 --> 00:20:58,080
a er is een tweede, raadselachtige

548
00:20:58,080 --> 00:21:00,120
observatie, namelijk

549
00:21:00,120 --> 00:21:03,919
dat de morfologie van neuronen er

550
00:21:03,919 --> 00:21:05,480
enigszins zo uitziet, dus dit zou

551
00:21:05,480 --> 00:21:08,159
een typisch piramidevormig neuron zijn dat je in

552
00:21:08,159 --> 00:21:09,039
je

553
00:21:09,039 --> 00:21:12,880
cortex hebt, maar je ziet dat dit

554
00:21:12,880 --> 00:21:15,919
eigenlijk voor een cel behoorlijk groot is en

555
00:21:15,919 --> 00:21:18,039
langwerpig, dus dit is dit kan tot een

556
00:21:18,039 --> 00:21:21,039
millimeter in het menselijk brein zitten,

557
00:21:21,039 --> 00:21:23,000
wat betekent dat als een aanmelding

558
00:21:23,000 --> 00:21:25,400
ergens hier wordt geactiveerd, het erg

559
00:21:25,400 --> 00:21:27,200
moeilijk is om te communiceren met het cellichaam

560
00:21:27,200 --> 00:21:29,000
dat zich hier beneden bevindt, dus elektrische signalen

561
00:21:29,000 --> 00:21:33,240
die hier worden geproduceerd uh  Kan

562
00:21:33,240 --> 00:21:35,440
hierheen reizen, maar de aanmeldingen hier

563
00:21:35,440 --> 00:21:38,480
hebben geen manier om de werkelijke

564
00:21:38,480 --> 00:21:40,520
spanningen op het cellichaam te meten en dit is

565
00:21:40,520 --> 00:21:41,960
eigenlijk de interessante plaats omdat

566
00:21:41,960 --> 00:21:43,760
hier de actiepotentialen worden gevormd, dus

567
00:21:43,760 --> 00:21:46,039
als de aanmeldingen echt willen

568
00:21:46,039 --> 00:21:48,240
weten wat er is  wat er in het cellichaam gebeurt,

569
00:21:48,240 --> 00:21:50,120
zodat het voorspellingen kan doen

570
00:21:50,120 --> 00:21:52,840
over hoe het neuron zich zal gedragen en

571
00:21:52,840 --> 00:21:55,400
hoe het met de wereld omgaat. Dit

572
00:21:55,400 --> 00:21:59,880
is weer een heel raadselachtig, eh of open

573
00:21:59,880 --> 00:22:02,120
probleem in de neurowetenschappen, hoe deze

574
00:22:02,120 --> 00:22:04,120
communicatie daadwerkelijk uitwerkt in

575
00:22:04,120 --> 00:22:07,320
afzonderlijke neuronen.  tussen het cellichaam en

576
00:22:07,320 --> 00:22:10,720
de uh en de aanmeldingen is het bekend dat

577
00:22:10,720 --> 00:22:12,840
de actiepotentialen feitelijk terug naar boven kunnen

578
00:22:12,840 --> 00:22:14,880
reizen, zodat ze een soort

579
00:22:14,880 --> 00:22:18,000
binaire variabele zien wanneer de uh wanneer het

580
00:22:18,000 --> 00:22:20,240
neuron piekt, maar ze kunnen

581
00:22:20,240 --> 00:22:23,799
het membraanpotentiaal hier niet echt meten,

582
00:22:23,799 --> 00:22:25,559
dus alleen de  de meest prominente elektrische

583
00:22:25,559 --> 00:22:27,159
signalen kunnen zich hierdoor daadwerkelijk voortplanten

584
00:22:27,159 --> 00:22:29,120


585
00:22:29,120 --> 00:22:31,400
en dit suggereert dat de

586
00:22:31,400 --> 00:22:33,000
aanmeldingen eigenlijk zeer schaarse

587
00:22:33,000 --> 00:22:34,799
informatie hebben over wat er aan de hand is met

588
00:22:34,799 --> 00:22:40,720
deze eh in het cellichaam en de meeste

589
00:22:40,720 --> 00:22:43,000
modellen van synoptische plasticiteit

590
00:22:43,000 --> 00:22:44,159
dekken dit

591
00:22:44,159 --> 00:22:48,279
helemaal niet, dus  en we vroegen ons af, hoe werkt

592
00:22:48,279 --> 00:22:50,880
dit, hoe werkt deze interactie,

593
00:22:50,880 --> 00:22:52,760
hoe kunnen de

594
00:22:52,760 --> 00:22:55,679
aanmeldingen nuttige leersignalen produceren,

595
00:22:55,679 --> 00:22:57,520
gegeven deze schaarse informatie

596
00:22:57,520 --> 00:23:00,200
over deze belangrijke toestand van het

597
00:23:00,200 --> 00:23:02,840
neuron, en ons idee was dat in wezen

598
00:23:02,840 --> 00:23:04,480
deze twee observaties deze hoge niveaus

599
00:23:04,480 --> 00:23:06,440
van  ruis en de aanmeldingen en deze

600
00:23:06,440 --> 00:23:08,880
grote afstand tussen het cellichaam en de

601
00:23:08,880 --> 00:23:10,640
aanmeldingen zeggen wat deze hoge

602
00:23:10,640 --> 00:23:12,679
onzekerheden geeft, dit zijn eigenlijk de twee

603
00:23:12,679 --> 00:23:15,480
kanten van dezelfde medaille, dus onze hypothese

604
00:23:15,480 --> 00:23:18,840
was dat we eigenlijk dezelfde modellen zouden kunnen gebruiken

605
00:23:18,840 --> 00:23:22,880
die we al kennen

606
00:23:22,880 --> 00:23:25,640
vanaf het gedragsniveau, uh, hoe een

607
00:23:25,640 --> 00:23:29,559
agent kan handelen en presteren in

608
00:23:29,559 --> 00:23:31,760
een omgeving van grote onzekerheid en

609
00:23:31,760 --> 00:23:33,400
we passen dit gewoon toe op

610
00:23:33,400 --> 00:23:37,760
eh, op elke aanmelding en oh, er is

611
00:23:37,760 --> 00:23:40,120
een fout, dus elke aanmelding zou

612
00:23:40,120 --> 00:23:44,559
dit eigenlijk dezelfde modellen moeten gebruiken

613
00:23:44,559 --> 00:23:47,679
en uh  dit model zou

614
00:23:47,679 --> 00:23:49,159
onmiddellijk suggereren dat

615
00:23:49,159 --> 00:23:51,919
synoptische transtransmissies eigenlijk luidruchtig zouden moeten zijn

616
00:23:51,919 --> 00:23:54,320
en deze ruisniveaus zouden

617
00:23:54,320 --> 00:23:56,880
onzekerheid over de

618
00:23:56,880 --> 00:23:59,640
omgeving uitdrukken en dan kunnen we dit

619
00:23:59,640 --> 00:24:02,080
model gebruiken om leerregels af te leiden en we

620
00:24:02,080 --> 00:24:04,600
kunnen ze naast elkaar vergelijken met de

621
00:24:04,600 --> 00:24:06,520
biologie en dit is de  Het eerste wat ik

622
00:24:06,520 --> 00:24:08,960
je wil laten zien, dus eh, ik geef gewoon een

623
00:24:08,960 --> 00:24:10,880
heel korte introductie tot het vrije

624
00:24:10,880 --> 00:24:13,720
energiemodel, uh, omdat sommigen van jullie er

625
00:24:13,720 --> 00:24:15,720
misschien niet zo bekend mee zijn, maar

626
00:24:15,720 --> 00:24:19,159
dit is in wezen een model om

627
00:24:19,159 --> 00:24:21,000
een ​​situatie als deze te beschrijven.

628
00:24:21,000 --> 00:24:23,279
persoon die interactie heeft met een bepaalde

629
00:24:23,279 --> 00:24:25,039
omgeving en hier ging ik heel

630
00:24:25,039 --> 00:24:28,320
eenvoudig vanuit, dus deze persoon probeert

631
00:24:28,320 --> 00:24:31,799
een doel te bereiken en wij als mensen

632
00:24:31,799 --> 00:24:34,240
zijn we goed in het oplossen van dergelijke taken en we

633
00:24:34,240 --> 00:24:36,039
zijn ook goed in het oplossen van dergelijke taken als er

634
00:24:36,039 --> 00:24:37,840
hoge niveaus zijn  van onzekerheid

635
00:24:37,840 --> 00:24:41,960
hierin, dus als de persoon

636
00:24:41,960 --> 00:24:44,000
wat visuele feedback krijgt, maar veel van deze

637
00:24:44,000 --> 00:24:46,440
feedback kan verborgen zijn, dus je kunt je

638
00:24:46,440 --> 00:24:48,520
voorstellen dat dit achter een

639
00:24:48,520 --> 00:24:52,600
muur gebeurt en de persoon nu misschien nog steeds wil

640
00:24:52,600 --> 00:24:55,039
voorspellen wat het traject van

641
00:24:55,039 --> 00:24:56,679
deze bal is  naar het doel vliegen

642
00:24:56,679 --> 00:25:00,960
zodat het een correcte uh-actie kan uitvoeren, dus

643
00:25:00,960 --> 00:25:03,960
we zullen hier enkele variabelen aan toewijzen, uh

644
00:25:03,960 --> 00:25:05,600
deze toestanden, dus we hebben in wezen

645
00:25:05,600 --> 00:25:07,440
deze feedback die deze persoon kan

646
00:25:07,440 --> 00:25:09,880
observeren en we hebben deze niet-geobserveerde

647
00:25:09,880 --> 00:25:12,279
toestand van de bal die hier vliegt, die we

648
00:25:12,279 --> 00:25:14,799
noemen  U waar de persoon er geen

649
00:25:14,799 --> 00:25:17,000
directe toegang toe heeft, zou alleen delen

650
00:25:17,000 --> 00:25:19,200
ervan zien, bijvoorbeeld wanneer de bal op

651
00:25:19,200 --> 00:25:22,000
de hoeken van de muur verschijnt en

652
00:25:22,000 --> 00:25:25,000
dan uh om dit in essentie te modelleren of

653
00:25:25,000 --> 00:25:28,200
om dit te beschrijven uh Gedrag dat de

654
00:25:28,200 --> 00:25:31,240
persoon zou doen  uh heb een interne

655
00:25:31,240 --> 00:25:33,360
beschrijving van dit traject, dus een

656
00:25:33,360 --> 00:25:37,520
intern model van deze eh staat

657
00:25:37,520 --> 00:25:41,480
U uh en het model, dit model zou dan

658
00:25:41,480 --> 00:25:45,679
worden bijgewerkt om te passen bij de waargenomen

659
00:25:45,679 --> 00:25:48,120
feedback en dit kan heel mooi worden beschreven

660
00:25:48,120 --> 00:25:50,200
in dit prachtige wiskundige

661
00:25:50,200 --> 00:25:52,320
raamwerk van het vrije-energieprincipe, dus

662
00:25:52,320 --> 00:25:55,159
het idee is dat je in wezen

663
00:25:55,159 --> 00:25:57,279
een model van je interne

664
00:25:57,279 --> 00:26:00,720
toestanden zou opstellen, dus in essentie hoe de

665
00:26:00,720 --> 00:26:04,640
interne toestanden en de toestand van de

666
00:26:04,640 --> 00:26:06,440
omgeving op

667
00:26:06,440 --> 00:26:09,000
elkaar inwerken, en je zou een model hebben van

668
00:26:09,000 --> 00:26:11,720
de feedback, dus hoe de toestanden en de

669
00:26:11,720 --> 00:26:14,240
feedback die je waarneemt op elkaar inwerken en

670
00:26:14,240 --> 00:26:18,559
in essentie kun je dan een

671
00:26:18,559 --> 00:26:21,080
verliesfunctie opschrijven die de

672
00:26:21,080 --> 00:26:23,039
afstand meet tussen dit model van de

673
00:26:23,039 --> 00:26:24,679
interne staat en dit model van de

674
00:26:24,679 --> 00:26:29,600
feedback en de externe toestand

675
00:26:29,960 --> 00:26:31,720
eh

676
00:26:31,720 --> 00:26:35,120
en dan kun

677
00:26:35,120 --> 00:26:37,799
je, door deze afstand tussen de twee in essentie te minimaliseren,

678
00:26:37,799 --> 00:26:41,799
alles afleiden  soorten gedrag dat relevant is,

679
00:26:41,799 --> 00:26:44,799
kan gedragsrelevante

680
00:26:44,799 --> 00:26:46,679
problemen oplossen, bijvoorbeeld leren, maar je

681
00:26:46,679 --> 00:26:48,399
kunt dit ook gebruiken voor andere dingen, zoals

682
00:26:48,399 --> 00:26:50,399
uitzoeken wat bijvoorbeeld goede acties zijn,

683
00:26:50,399 --> 00:26:53,440
dus gevolgtrekkingen maken over

684
00:26:53,440 --> 00:26:55,520
zowel de interne toestanden als de acties

685
00:26:55,520 --> 00:26:58,440
bijvoorbeeld, en dit is bijvoorbeeld de shell  het vrije-

686
00:26:58,440 --> 00:27:00,480
energieprincipe en dit object hier is

687
00:27:00,480 --> 00:27:02,360
toevallig wat bekend staat als de

688
00:27:02,360 --> 00:27:04,760
variatievrije energie, die ook

689
00:27:04,760 --> 00:27:06,960
gewoon samenvalt met de statistische fysica

690
00:27:06,960 --> 00:27:08,480
en dit is waar dit raamwerk zijn

691
00:27:08,480 --> 00:27:11,640
naam vandaan heeft, maar je ziet dat het

692
00:27:11,640 --> 00:27:13,159
hier allemaal probabilistisch is, dus in wezen

693
00:27:13,159 --> 00:27:15,240
heb je  twee waarschijnlijkheidsfuncties Q voor het

694
00:27:15,240 --> 00:27:17,320
interne model en P voor deze

695
00:27:17,320 --> 00:27:19,640
interactie tussen staten en

696
00:27:19,640 --> 00:27:22,120
observaties en je hebt hier een

697
00:27:22,120 --> 00:27:24,279
afstandsmaat daartussen die je

698
00:27:24,279 --> 00:27:25,200
wilt

699
00:27:25,200 --> 00:27:27,799
minimaliseren, dus als we nu naar het neuron

700
00:27:27,799 --> 00:27:29,640
en de aanmeldingen kijken en hoe ze

701
00:27:29,640 --> 00:27:31,520
met elkaar omgaan  andere vinden we een zeer vergelijkbaar

702
00:27:31,520 --> 00:27:35,440
beeld, dus enkele aanmeldingen, die we

703
00:27:35,440 --> 00:27:38,520
hier in het groen hebben, hebben een inter-

704
00:27:38,520 --> 00:27:41,120
interne status die we alleen voor het Simplicity-

705
00:27:41,120 --> 00:27:45,080
model gebruiken, als het synoptische lokaas op basis

706
00:27:45,080 --> 00:27:46,960
hiervan zouden de aanmeldingen, wanneer deze worden geactiveerd

707
00:27:46,960 --> 00:27:50,799
door een preoptische piek, eh genereren

708
00:27:50,799 --> 00:27:53,200
een post-synoptische stroom, dit zou zich dan

709
00:27:53,200 --> 00:27:56,320
voortplanten naar de Som, wat onze

710
00:27:56,320 --> 00:27:57,760
externe toestand is die we niet

711
00:27:57,760 --> 00:27:59,799
direct kunnen waarnemen omdat het te ver

712
00:27:59,799 --> 00:28:02,640
weg is van de cups, maar we kunnen een

713
00:28:02,640 --> 00:28:04,279
feedback zien die deze spe is die

714
00:28:04,279 --> 00:28:05,880
actiepotentiaal voortplant, wat deze binaire

715
00:28:05,880 --> 00:28:07,200
variabele is die  vertelt ons of het

716
00:28:07,200 --> 00:28:09,840
neuron is verrijkt of niet, dus dit is

717
00:28:09,840 --> 00:28:12,120
precies hetzelfde raamwerk als we

718
00:28:12,120 --> 00:28:13,679
het zo opschrijven en we kunnen gewoon

719
00:28:13,679 --> 00:28:18,200
dezelfde wiskunde gebruiken om het op te lossen,

720
00:28:18,200 --> 00:28:21,159
dus om het op te lossen hoeven we alleen maar

721
00:28:21,159 --> 00:28:24,320
met een te komen  We moeten

722
00:28:24,320 --> 00:28:25,960
een paar aannames doen, dus we moeten

723
00:28:25,960 --> 00:28:28,279


724
00:28:28,279 --> 00:28:32,240
hier een model voor deze man opschrijven, dus dit model van hoe de uh-

725
00:28:32,240 --> 00:28:35,880
feedback en de en de externe staat op

726
00:28:35,880 --> 00:28:38,159
elkaar inwerken, maar we hebben hier hele goede modellen

727
00:28:38,159 --> 00:28:40,519
voor  dit is gedurende vele

728
00:28:40,519 --> 00:28:43,120
jaren bestudeerd, dus hier zie je hoe typisch een

729
00:28:43,120 --> 00:28:45,880
modelneuron zich gedraagt, dus je hebt hier

730
00:28:45,880 --> 00:28:47,440
het membraanpotentiaal van een lekkend

731
00:28:47,440 --> 00:28:49,120
geïntegreerd vuurneuron en je ziet dat

732
00:28:49,120 --> 00:28:51,159
dit gewoon op en neer gaat, zodat

733
00:28:51,159 --> 00:28:53,720
dit neuron een uh een zou ontvangen  veel

734
00:28:53,720 --> 00:28:56,440
preoptische input en misschien ook ruis en

735
00:28:56,440 --> 00:28:57,679
uiteindelijk bereikt het op een gegeven moment een

736
00:28:57,679 --> 00:28:59,640
drempel, het zou een piek genereren, dus

737
00:28:59,640 --> 00:29:01,760
dat zou de Z zijn die naar de

738
00:29:01,760 --> 00:29:04,279
stroomafwaartse neuronen reist en ook terug naar de

739
00:29:04,279 --> 00:29:07,120
cups uh en dan wordt het

740
00:29:07,120 --> 00:29:12,159
gereset, uh juist, maar nu  dit is uh, dus

741
00:29:12,159 --> 00:29:13,799
we kunnen dit wiskundig opschrijven. Het is

742
00:29:13,799 --> 00:29:16,399
een heel eenvoudige differentiaalvergelijking,

743
00:29:16,399 --> 00:29:19,039
maar het uh-neuron heeft geen toegang

744
00:29:19,039 --> 00:29:21,360
meer tot deze toestand, dus het bevindt zich weer achter

745
00:29:21,360 --> 00:29:24,440
deze muur. Het ziet alleen deze Spike-gebeurtenissen,

746
00:29:24,440 --> 00:29:26,440
maar we kunnen dat eigenlijk wel doen voor dit eenvoudige geval

747
00:29:26,440 --> 00:29:28,320
van  echt geïntegreerd F-neuron kunnen we

748
00:29:28,320 --> 00:29:30,399
dit analytisch oplossen, zodat we kunnen opschrijven

749
00:29:30,399 --> 00:29:32,240
wat de posterieure verdeling

750
00:29:32,240 --> 00:29:34,559
van membraanpotentialen is, gegeven de

751
00:29:34,559 --> 00:29:37,480
piektijden en wat hieruit voortkomt is

752
00:29:37,480 --> 00:29:40,240
eigenlijk een zogenaamd um stochastisch

753
00:29:40,240 --> 00:29:44,159
brugmodel of in dit geval van een uh  van

754
00:29:44,159 --> 00:29:45,960
een lek geïntegreerd in vuurneuron, het is een

755
00:29:45,960 --> 00:29:48,240
orang-brugmodel, dus dit kan

756
00:29:48,240 --> 00:29:51,200
analytisch worden opgeschreven en deze U. Ik

757
00:29:51,200 --> 00:29:53,880
bedoel, het is niet eenvoudig, maar het is

758
00:29:53,880 --> 00:29:56,760
uitvoerbaar, uh en we kunnen dit dan gewoon

759
00:29:56,760 --> 00:29:59,799
direct gebruiken, dus dit model dat we

760
00:29:59,799 --> 00:30:02,279
moeten opnieuw opschrijven  deze uh vrije energie is

761
00:30:02,279 --> 00:30:04,440
functioneel, dus we gaan hier uit van een aanname

762
00:30:04,440 --> 00:30:06,600
hoe de aanmeldingen daadwerkelijk post-

763
00:30:06,600 --> 00:30:08,600
synoptische stromen produceren en hoe ze zijn

764
00:30:08,600 --> 00:30:11,000
geïntegreerd in het neuron, maar

765
00:30:11,000 --> 00:30:12,840
dat wordt ook gegeven door het Leaky

766
00:30:12,840 --> 00:30:14,799
geïntegreerde vuurneuron en feitelijk de

767
00:30:14,799 --> 00:30:17,760
stochastische um-invoer die de aanmeldingen

768
00:30:17,760 --> 00:30:20,120
genereren  Dus in dit verband gaan we er voor de eenvoud

769
00:30:20,120 --> 00:30:22,919
alleen maar van uit dat in principe Gausiaanse Sy-

770
00:30:22,919 --> 00:30:25,559
ups worden gebruikt die een Gausiaanse

771
00:30:25,559 --> 00:30:27,960
willekeurige variabele zouden injecteren en deze zouden injecteren in een

772
00:30:27,960 --> 00:30:30,399
groot en vurend neuron. Dan kunnen al deze

773
00:30:30,399 --> 00:30:31,960
ingrediënten feitelijk in

774
00:30:31,960 --> 00:30:33,640
gesloten vorm worden opgelost en kunnen we leerregels afleiden

775
00:30:33,640 --> 00:30:35,720
die dat zouden doen.  minimaliseer deze pre-

776
00:30:35,720 --> 00:30:37,640
energiefunctioneel

777
00:30:37,640 --> 00:30:40,720
nu, uh en als we dat doen,

778
00:30:40,720 --> 00:30:44,279
eh, dit heeft een aantal mooie

779
00:30:44,279 --> 00:30:46,279
eigenschappen omdat deze Onin Lbeck-

780
00:30:46,279 --> 00:30:48,480
brug volledig wordt bepaald door de

781
00:30:48,480 --> 00:30:51,480
preent uh door de achterwaarts voortplantende

782
00:30:51,480 --> 00:30:54,480
actiepotentialen, dus eigenlijk de tijden van de

783
00:30:54,480 --> 00:30:57,000
post-synoptische um-pieken die  arriveer bij

784
00:30:57,000 --> 00:30:57,310
het

785
00:30:57,310 --> 00:30:58,519
[Muziek]

786
00:30:58,519 --> 00:31:01,760
neuron um deze vorm die we hier krijgen

787
00:31:01,760 --> 00:31:03,440
hangt alleen af ​​van twee aangrenzende

788
00:31:03,440 --> 00:31:04,760
postoptische

789
00:31:04,760 --> 00:31:08,519
pieken eh wat betekent dat we hier

790
00:31:08,519 --> 00:31:10,720
automatisch komen uh een leerregel die er

791
00:31:10,720 --> 00:31:12,880
zo uitziet, dus een leerregel die

792
00:31:12,880 --> 00:31:15,480
alleen afhangt van het verschil tussen

793
00:31:15,480 --> 00:31:17,320
twee postoptische pieken  die we hier

794
00:31:17,320 --> 00:31:18,159
Delta

795
00:31:18,159 --> 00:31:22,960
T2 noemen, eh en uh, het verschil tussen de

796
00:31:22,960 --> 00:31:25,159
post-synoptische Spike en de feitelijke invoer

797
00:31:25,159 --> 00:31:27,240
die op een bepaald punt wordt geactiveerd, aan

798
00:31:27,240 --> 00:31:29,120
de preoptische

799
00:31:29,120 --> 00:31:32,720
kant, uh en we kunnen hier in feite

800
00:31:32,720 --> 00:31:35,919
deze opzoektabel maken en gewoon

801
00:31:35,919 --> 00:31:38,200
berekenen wat de  update die

802
00:31:38,200 --> 00:31:40,960
deze aanmeldingen zouden moeten doen zodat

803
00:31:40,960 --> 00:31:42,840
het optimaal leert in termen van dit

804
00:31:42,840 --> 00:31:44,760
vrije energieprincipe en dit is de

805
00:31:44,760 --> 00:31:46,279
vorm die we eruit krijgen. Je ziet dat er

806
00:31:46,279 --> 00:31:47,679
een sterke afhankelijkheid is van de post-

807
00:31:47,679 --> 00:31:49,440
synoptische vuursnelheid, maar er is in principe ook een

808
00:31:49,440 --> 00:31:52,720
afhankelijkheid van  deze typische STP

809
00:31:52,720 --> 00:31:55,880
die Sarah eerder noemde, wat is

810
00:31:55,880 --> 00:31:57,639
de relatieve positionering van de pre-

811
00:31:57,639 --> 00:31:59,080
en postoptische

812
00:31:59,080 --> 00:32:02,440
piek, dus in een notendop kan dit model

813
00:32:02,440 --> 00:32:04,760
nu in wezen in twee Pathways worden opgesplitst,

814
00:32:04,760 --> 00:32:08,279
dus we hebben deze atoc-reactie

815
00:32:08,279 --> 00:32:11,000
die eigenlijk alleen maar wanneer er een

816
00:32:11,000 --> 00:32:13,880
preoptische piek is die  veroorzaakt een actie

817
00:32:13,880 --> 00:32:16,080
in de cups die hij uit deze

818
00:32:16,080 --> 00:32:18,039
scussion-verdeling zou trekken en deze in

819
00:32:18,039 --> 00:32:21,799
de um in het neuron zou injecteren en dan is er

820
00:32:21,799 --> 00:32:22,880
deze postt

821
00:32:22,880 --> 00:32:25,480
talk uh-update waar we waar de

822
00:32:25,480 --> 00:32:28,720
aanmeldingen um zouden opzoeken in deze orang

823
00:32:28,720 --> 00:32:30,360
en wenck Bridge wat zou zijn geweest

824
00:32:30,360 --> 00:32:33,600
de optimale um-uitvoer die het had moeten

825
00:32:33,600 --> 00:32:35,679
genereren, dus wat zou

826
00:32:35,679 --> 00:32:38,559
de optimale actie zijn geweest en dan vergelijkt het

827
00:32:38,559 --> 00:32:40,320
de feitelijke actie met deze optimale

828
00:32:40,320 --> 00:32:41,880
actie volgens dit vrije-

829
00:32:41,880 --> 00:32:44,880
energieprincipe en genereert vervolgens een vertraagde

830
00:32:44,880 --> 00:32:47,360
responsreactie die een update is van

831
00:32:47,360 --> 00:32:49,399
het synoptische

832
00:32:49,399 --> 00:32:52,159
gewicht oké  en belangrijker nog, dit

833
00:32:52,159 --> 00:32:54,519
interne model is alleen impliciet, het is om

834
00:32:54,519 --> 00:32:57,960
zo te zeggen gecodeerd in deze uh Spike-

835
00:32:57,960 --> 00:33:00,399
tijdafhankelijke

836
00:33:00,399 --> 00:33:02,880
plasticiteitsregel, uh dus hoe zien deze regels er dan uit

837
00:33:02,880 --> 00:33:04,639
en vergelijken ze zich met hoe ze zich

838
00:33:04,639 --> 00:33:07,360
verhouden tot de biologie en eigenlijk

839
00:33:07,360 --> 00:33:09,240
passen ze behoorlijk  mooi gezien het feit dat dit

840
00:33:09,240 --> 00:33:11,519
echt is afgeleid van de eerste principes

841
00:33:11,519 --> 00:33:13,880
zonder enige aannames te doen, dus dit

842
00:33:13,880 --> 00:33:16,320
is de meting in de biologie, dit is

843
00:33:16,320 --> 00:33:20,279
deze um B bij Al-regel B en po heel oud

844
00:33:20,279 --> 00:33:23,279
werk waar ze dit feitelijk deden in uh

845
00:33:23,279 --> 00:33:26,519
in vro-studies waar ze de

846
00:33:26,519 --> 00:33:29,120
geïnjecteerde  pre- en post-synoptische um-pieken

847
00:33:29,120 --> 00:33:30,880
en vervolgens maten ze wat de

848
00:33:30,880 --> 00:33:32,679
gewichtsverandering is bij de politie en dit is

849
00:33:32,679 --> 00:33:35,320
de regel die wordt voorspeld door ons uh-

850
00:33:35,320 --> 00:33:37,799
model en je ziet dat het ons in ieder geval in een

851
00:33:37,799 --> 00:33:39,559
eerste orde benadering

852
00:33:39,559 --> 00:33:42,080
zeer vergelijkbare vormen geeft en dit  is ook

853
00:33:42,080 --> 00:33:43,519
logisch omdat

854
00:33:43,519 --> 00:33:48,120
de aanmeldingen

855
00:33:48,120 --> 00:33:51,840
het meest willen veranderen als het dicht bij een uh dichtbij

856
00:33:51,840 --> 00:33:54,559
de pre- en postoptische piektijden is,

857
00:33:54,559 --> 00:33:56,039
omdat dit is waar of of de

858
00:33:56,039 --> 00:33:57,919
postoptische piektijden omdat dit is

859
00:33:57,919 --> 00:34:00,240
waar het het meeste weet over de toestand

860
00:34:00,240 --> 00:34:02,159
van  het PO-neuron, het vrije

861
00:34:02,159 --> 00:34:05,600
energieprincipe, zou eigenlijk suggereren dat dit

862
00:34:05,600 --> 00:34:07,639
soort kegeltjes

863
00:34:07,639 --> 00:34:11,359
U eh zijn, met bijna geen aanname

864
00:34:11,359 --> 00:34:14,199
in wezen, maar we krijgen ook omdat

865
00:34:14,199 --> 00:34:17,719
we niet alleen een eerste orde uh

866
00:34:17,719 --> 00:34:20,199
Spike-tijdafhankelijke plasticiteitsregel hebben, maar

867
00:34:20,199 --> 00:34:21,480
we hebben ook deze afhankelijkheid van  de

868
00:34:21,480 --> 00:34:24,119
postop-vuursnelheid, we kunnen dit ook vergelijken

869
00:34:24,119 --> 00:34:26,280
met andere resultaten en dit hier is

870
00:34:26,280 --> 00:34:29,119
oud door gr en Brunel, dus dit is

871
00:34:29,119 --> 00:34:31,159
eigenlijk een model, maar dat was zeer

872
00:34:31,159 --> 00:34:35,839
gedetailleerd, eh, beschrijft de eh, uh-

873
00:34:35,839 --> 00:34:37,679
plasticiteit gebaseerd op de pre- en

874
00:34:37,679 --> 00:34:41,280
postoptische vuursnelheid in uh  in aanmeldingen

875
00:34:41,280 --> 00:34:42,960
en dit is wat ons model voorspelt, dus

876
00:34:42,960 --> 00:34:44,639
als we willekeurige pre- en post-

877
00:34:44,639 --> 00:34:47,359
synoptische popik tra uh-treinen met

878
00:34:47,359 --> 00:34:50,040
verschillende snelheden injecteren, zou ons model

879
00:34:50,040 --> 00:34:52,639
deze vorm voorspellen, wat opnieuw geen perfecte

880
00:34:52,639 --> 00:34:55,440
match is, maar gezien het feit dat dit een zeer

881
00:34:55,440 --> 00:34:58,359
idealistisch model is, is het eigenlijk  in ieder geval

882
00:34:58,359 --> 00:35:01,880
de belangrijkste kenmerken dat lage

883
00:35:01,880 --> 00:35:04,160
vuurpercentages aan de postoptische kant zouden leiden

884
00:35:04,160 --> 00:35:07,560
tot depressie en hoger tot potentiëring,

885
00:35:07,560 --> 00:35:10,440
worden hierin weerspiegeld,

886
00:35:10,440 --> 00:35:14,240
oké, ik neem aan dat ik nog steeds 10

887
00:35:14,240 --> 00:35:19,520
minuten goed heb, oké, dus ik zou een

888
00:35:19,520 --> 00:35:21,320
korte tussentijdse samenvatting geven en dan zou ik

889
00:35:21,320 --> 00:35:23,400
wil wat ander werk laten zien waarin we

890
00:35:23,400 --> 00:35:27,320
dit nu daadwerkelijk toepassen op een daadwerkelijk

891
00:35:27,320 --> 00:35:29,040
machine learning-

892
00:35:29,040 --> 00:35:32,440
model, dus wat we hier hebben gezien is

893
00:35:32,440 --> 00:35:36,760
dat eh Sy-ups eigenlijk

894
00:35:36,760 --> 00:35:39,240
erg stochastisch zijn en het was heel erg, dit

895
00:35:39,240 --> 00:35:42,599
was een grote puzzel en we suggereren  dat

896
00:35:42,599 --> 00:35:44,160
eigenlijk de

897
00:35:44,160 --> 00:35:47,680
eh dat de synaptische ruis

898
00:35:47,680 --> 00:35:50,920
eigenlijk de aanmeldingen is, een manier is om

899
00:35:50,920 --> 00:35:52,640
zijn eigen onzekerheid over de

900
00:35:52,640 --> 00:35:54,079
omgeving te rapporteren, waar de omgeving

901
00:35:54,079 --> 00:35:57,560
eigenlijk het eh het synoptische neuron van de POS is

902
00:35:57,560 --> 00:36:00,119
en het werkt echt op deze manier samen

903
00:36:00,119 --> 00:36:02,160
met het vrije energieprincipe hiermee

904
00:36:02,160 --> 00:36:03,880
post-synoptisch neuron of dat is een heel

905
00:36:03,880 --> 00:36:06,720
mooie manier om het te beschrijven en als

906
00:36:06,720 --> 00:36:09,400
je meer geïnteresseerd bent, er is een papier en een

907
00:36:09,400 --> 00:36:13,480
voorafdruk, je kunt dit allemaal lezen,

908
00:36:13,480 --> 00:36:16,359
oké, dus hoe sluit dit nu

909
00:36:16,359 --> 00:36:19,440
aan op neuromorfe wetenschappen en eigenlijk

910
00:36:19,440 --> 00:36:21,160
zijn we dat ook  we doen niet echt neuromorfe

911
00:36:21,160 --> 00:36:23,400
hardware, we doen neuromorfe

912
00:36:23,400 --> 00:36:25,920
algoritmen, dus we proberen deze

913
00:36:25,920 --> 00:36:27,480
inspiraties nu in daadwerkelijke machine

914
00:36:27,480 --> 00:36:30,319
learning-modellen te brengen en we dachten dat dit

915
00:36:30,319 --> 00:36:33,920
een goede aanvalshoek zou kunnen zijn om

916
00:36:33,920 --> 00:36:35,599
een ​​probleem op te lossen dat bekend is in

917
00:36:35,599 --> 00:36:40,880
machine learning, dus  Ik, ik heb

918
00:36:40,880 --> 00:36:43,640
hier een heel eenvoudig convolutioneel

919
00:36:43,640 --> 00:36:45,440
neuronetwerk getekend met verschillende convolutionele

920
00:36:45,440 --> 00:36:48,079
lagen en dan misschien enkele dichte lagen

921
00:36:48,079 --> 00:36:49,839
die je zou hebben in je machine

922
00:36:49,839 --> 00:36:52,760
learning-algoritme en de manier waarop dit wordt

923
00:36:52,760 --> 00:36:54,599
getraind, zoals velen van jullie weten, is volgens mij

924
00:36:54,599 --> 00:36:57,400
door het einde  om propagatie te beëindigen en terug te draaien,

925
00:36:57,400 --> 00:36:59,480
dus het idee is dat je

926
00:36:59,480 --> 00:37:02,119
een trainingsset hebt met invoer en

927
00:37:02,119 --> 00:37:04,079
doelen, dus bijvoorbeeld in een

928
00:37:04,079 --> 00:37:06,920
classificatietaak kunnen dit

929
00:37:06,920 --> 00:37:08,680
afbeeldingen van katten en honden zijn en je zou

930
00:37:08,680 --> 00:37:12,440
doelen hebben die als het ware U-klasse-labels zijn

931
00:37:12,440 --> 00:37:15,160
dus bij sommige zitten er eigenlijk

932
00:37:15,160 --> 00:37:17,119
kunstmatige neuronen in en bij sommige is een

933
00:37:17,119 --> 00:37:18,640
van deze neuronen mogelijk actief voor katten

934
00:37:18,640 --> 00:37:20,240
en een andere is mogelijk actief voor

935
00:37:20,240 --> 00:37:23,440
honden, en tijdens je training

936
00:37:23,440 --> 00:37:25,400
heb je die gegevens precies deze labels, die

937
00:37:25,400 --> 00:37:27,119
zijn gegenereerd door mensen die daar aan het

938
00:37:27,119 --> 00:37:29,319
zitten waren  dit met de hand en

939
00:37:29,319 --> 00:37:32,119
tijdens de training laat je deze voorbeelden

940
00:37:32,119 --> 00:37:34,520
aan het netwerk zien door deze

941
00:37:34,520 --> 00:37:37,040
invoer helemaal van de

942
00:37:37,040 --> 00:37:39,760
invoerlaag naar de uitvoerlaag door te geven, dan

943
00:37:39,760 --> 00:37:42,560
wordt de uitvoer hier vergeleken met de uh met

944
00:37:42,560 --> 00:37:44,960
deze handlabeldoelen en vervolgens de

945
00:37:44,960 --> 00:37:47,000
mismatch tussen de  twee wordt teruggepropageerd

946
00:37:47,000 --> 00:37:48,839
door al deze lagen terug

947
00:37:48,839 --> 00:37:52,000
naar de invoer en alle gewichten of de

948
00:37:52,000 --> 00:37:54,720
synoptische gewichten die zich hier

949
00:37:54,720 --> 00:37:57,160
tussen uh in deze laag bevinden,

950
00:37:57,160 --> 00:37:58,960
zouden dan dienovereenkomstig worden bijgewerkt,

951
00:37:58,960 --> 00:38:01,560
zodat na dit vele malen te hebben gedaan,

952
00:38:01,560 --> 00:38:03,920
dit netwerk goed wordt in het vertellen  een

953
00:38:03,920 --> 00:38:05,560
deel C

954
00:38:05,560 --> 00:38:08,520
dos, dus dit heeft een probleem. Dit

955
00:38:08,520 --> 00:38:10,359
algoritme werkt geweldig in de praktijk en

956
00:38:10,359 --> 00:38:12,960
het is de basis van al deze

957
00:38:12,960 --> 00:38:15,480
modellen waar we het over hebben gehad, zoals D of J

958
00:38:15,480 --> 00:38:18,520
GBT, maar het is behoorlijk inefficiënt en het

959
00:38:18,520 --> 00:38:20,280
probleem is dit wat bekend is in de

960
00:38:20,280 --> 00:38:22,880
literatuur als het Locking-probleem, dus als

961
00:38:22,880 --> 00:38:25,480
je dit netwerk nu in blokken zou opsplitsen,

962
00:38:25,480 --> 00:38:27,560
wat ik al eerder deed, maar

963
00:38:27,560 --> 00:38:30,839
dit is willekeurig, maar om

964
00:38:30,839 --> 00:38:32,400
dit efficiënt te implementeren in termen

965
00:38:32,400 --> 00:38:34,000
van een software-algoritme zou het interessant kunnen zijn

966
00:38:34,000 --> 00:38:36,520
om dat te doen en nu zou je

967
00:38:36,520 --> 00:38:39,160
deze willen hebben  blokken idealiter om

968
00:38:39,160 --> 00:38:41,560
parallel te lopen, zodat je in principe

969
00:38:41,560 --> 00:38:44,359
het eerste voorbeeld kunt laten zien en uh op dit

970
00:38:44,359 --> 00:38:46,440
eerste blok en het dan al kunt trainen

971
00:38:46,440 --> 00:38:48,839
terwijl het tweede um-blok

972
00:38:48,839 --> 00:38:50,760
iets anders doet, maar dit is niet echt

973
00:38:50,760 --> 00:38:52,800
mogelijk met um end-to-end back-

974
00:38:52,800 --> 00:38:54,440
propagatie  vanwege dit

975
00:38:54,440 --> 00:38:57,200
vergrendelingsprobleem, omdat de activering van het

976
00:38:57,200 --> 00:38:58,800
tweede blok afhangt van de activering

977
00:38:58,800 --> 00:39:00,319
van het eerste blok, dus je moet

978
00:39:00,319 --> 00:39:02,720
het helemaal tot het einde doorgeven,

979
00:39:02,720 --> 00:39:04,319
bereken je deze fout en je zou

980
00:39:04,319 --> 00:39:06,680
dan terug propageren en pas als dit

981
00:39:06,680 --> 00:39:09,520
is gebeurd  uh, u kunt het volgende tijdperk starten

982
00:39:09,520 --> 00:39:14,359
waar u een nieuwe reeks

983
00:39:14,359 --> 00:39:17,040
voorbeelden laat zien, uh en u ziet dat gedurende al

984
00:39:17,040 --> 00:39:20,319
die tijd hier de drie die

985
00:39:20,319 --> 00:39:23,319
dit eerste blok zouden runnen, misschien

986
00:39:23,319 --> 00:39:25,520
inactief zouden zijn en in wezen de hele

987
00:39:25,520 --> 00:39:28,079
tijd moeten wachten en  dit maakt ze duidelijk erg

988
00:39:28,079 --> 00:39:30,040
inefficiënt en nu was ons idee dat

989
00:39:30,040 --> 00:39:33,000
we in principe zouden gebruiken wat we hadden geleerd

990
00:39:33,000 --> 00:39:36,680
van dit eerdere model over hoe

991
00:39:36,680 --> 00:39:39,440
aanmeldingen over deze lange

992
00:39:39,440 --> 00:39:42,079
afstanden communiceren voor dit vrije energieprincipe

993
00:39:42,079 --> 00:39:43,920
en het ook alleen op een diep neuron toepassen

994
00:39:43,920 --> 00:39:46,200
Netwerk en de ideeën die je hier

995
00:39:46,200 --> 00:39:49,040
weer hebt, dit heb je eigenlijk al

996
00:39:49,040 --> 00:39:50,880


997
00:39:50,880 --> 00:39:54,800
deze generatie van input voor een bepaalde

998
00:39:54,800 --> 00:39:57,960
output, maar wat ontbreekt om

999
00:39:57,960 --> 00:39:59,440
het toepasbaar te maken op het vrije

1000
00:39:59,440 --> 00:40:01,359
energieprincipe is deze feedback die je

1001
00:40:01,359 --> 00:40:03,920
altijd nodig hebt. Het idee was dat we

1002
00:40:03,920 --> 00:40:06,960
hier een zeer lichtgewicht uh

1003
00:40:06,960 --> 00:40:09,480
feedbacknetwerk, dus in wezen zou elk van deze

1004
00:40:09,480 --> 00:40:11,800
blokken nu in dit diepe neurale netwerk

1005
00:40:11,800 --> 00:40:15,319
vergezeld gaan van een

1006
00:40:15,319 --> 00:40:18,520
feedbackblok uh dat lokaal een doel genereert,

1007
00:40:18,520 --> 00:40:20,240
dus dat deden we eigenlijk in het eenvoudigste

1008
00:40:20,240 --> 00:40:21,760
geval dat we hebben, dus dit is zeer

1009
00:40:21,760 --> 00:40:24,640
recent  werk, we hebben tot nu toe alleen lineaire blokken gebruikt,

1010
00:40:24,640 --> 00:40:27,480
dus dit zijn enkele lineaire lagen

1011
00:40:27,480 --> 00:40:29,160
en we zouden deze

1012
00:40:29,160 --> 00:40:32,040
outputs nu hier in deze feedbackblokken genereren

1013
00:40:32,040 --> 00:40:34,040
en dan het vrije energieprincipe gebruiken om

1014
00:40:34,040 --> 00:40:38,119
een ​​lokaal verlies te verkrijgen dat ons in staat stelt

1015
00:40:38,119 --> 00:40:40,920
beide te minimaliseren.

1016
00:40:40,920 --> 00:40:43,000
feedbackgewichten die we hier hebben en

1017
00:40:43,000 --> 00:40:45,119
ook de gewichten in het voorwaartse

1018
00:40:45,119 --> 00:40:48,079
netwerk, dus het is in wezen hetzelfde

1019
00:40:48,079 --> 00:40:49,960
idee, dus we hebben hier deze outputs die

1020
00:40:49,960 --> 00:40:52,960
we nu interpreteren als parameters voor een

1021
00:40:52,960 --> 00:40:54,800
waarschijnlijkheidsfunctie, zodat we

1022
00:40:54,800 --> 00:40:57,240
dit probabilistische raamwerk kunnen toepassen,

1023
00:40:57,240 --> 00:40:59,040
maar nu de alle  de rest rolt in principe op

1024
00:40:59,040 --> 00:41:01,359
dezelfde manier uit, dus we gaan ervan uit

1025
00:41:01,359 --> 00:41:04,040
dat deze outputs in wezen

1026
00:41:04,040 --> 00:41:06,599
de interne toestanden van dit model zijn en we

1027
00:41:06,599 --> 00:41:10,480
hebben deze um uh deze observaties gegeven

1028
00:41:10,480 --> 00:41:14,000
in de uh inputs en en de doelen en

1029
00:41:14,000 --> 00:41:17,880
nu proberen we in principe te minimaliseren uh P

1030
00:41:17,880 --> 00:41:19,640
zou nu dit feed forward-netwerk zijn

1031
00:41:19,640 --> 00:41:23,480
en Q zou nu een functie zijn die uh

1032
00:41:23,480 --> 00:41:26,319
kenmerken bevat van zowel de

1033
00:41:26,319 --> 00:41:31,119
feedback als de uh en de feed forward-

1034
00:41:31,119 --> 00:41:33,880
netwerk en het leuke is dat als we

1035
00:41:33,880 --> 00:41:36,160
eh uh ik geen tijd heb om erop in te gaan  naar

1036
00:41:36,160 --> 00:41:38,880
de details nu, maar als je dit

1037
00:41:38,880 --> 00:41:43,200
opschrijft, zie je dat dit eigenlijk de

1038
00:41:43,200 --> 00:41:45,079
vergrendelingsterm hier

1039
00:41:45,079 --> 00:41:49,200
ontleedt in lokale lineaire termen die

1040
00:41:49,200 --> 00:41:50,920
je deze lokale verliezen hier geven, zo

1041
00:41:50,920 --> 00:41:52,960
essentieel dat je hier het

1042
00:41:52,960 --> 00:41:55,520
lokale blok tussen B en het

1043
00:41:55,520 --> 00:41:59,560
overeenkomstige feedbackblok kunt minimaliseren  een

1044
00:41:59,560 --> 00:42:01,839
verliesfunctie en je kunt dit dan eigenlijk

1045
00:42:01,839 --> 00:42:05,680
parallel doen, dus omdat uh misschien

1046
00:42:05,680 --> 00:42:07,800
is de foto hier goed om te zien, dus wat je

1047
00:42:07,800 --> 00:42:09,000
nu moet doen, je hebt een beetje

1048
00:42:09,000 --> 00:42:10,720
overhead omdat je dit feedbackblok hebt,

1049
00:42:10,720 --> 00:42:15,200
dus dit zouden de twee zijn uh  uh

1050
00:42:15,200 --> 00:42:18,359
uitvoeringstijden van het uh feed forward

1051
00:42:18,359 --> 00:42:20,160
blok en het feedback

1052
00:42:20,160 --> 00:42:23,359
blok, maar in principe kunnen ze

1053
00:42:23,359 --> 00:42:25,920
parallel lopen uh en zodra het voorwaartse blok

1054
00:42:25,920 --> 00:42:28,400
klaar is, kan het volgende voorwaartse blok zich

1055
00:42:28,400 --> 00:42:30,079
door dit

1056
00:42:30,079 --> 00:42:33,079
netwerk gaan verspreiden, maar tegelijkertijd al

1057
00:42:33,079 --> 00:42:34,880
het voorwaartse blok omdat het al

1058
00:42:34,880 --> 00:42:37,880
ontvangen is  een doel hier kan beginnen met het

1059
00:42:37,880 --> 00:42:40,520
bijwerken van de gewichten en als het klaar is,

1060
00:42:40,520 --> 00:42:43,119
is het gratis om te werken in het volgende tijdperk,

1061
00:42:43,119 --> 00:42:45,760
dus er is geen vergrendeling meer in dit

1062
00:42:45,760 --> 00:42:48,040


1063
00:42:48,040 --> 00:42:50,880
raamwerk, oké, dus ik ben zo goed als klaar.

1064
00:42:50,880 --> 00:42:53,119
Ik heb ook geen tijd meer, ik denk het wel  hoe

1065
00:42:53,119 --> 00:42:55,359
presteert dit natuurlijk, we hebben het

1066
00:42:55,359 --> 00:42:56,720
leeralgoritme veranderd, nu moeten we

1067
00:42:56,720 --> 00:42:59,720
ook teruggaan en kijken of dit uh

1068
00:42:59,720 --> 00:43:03,280
nog steeds dezelfde prestaties levert

1069
00:43:03,280 --> 00:43:06,480
en eigenlijk voor eh, dus dit, zoals ik al zei,

1070
00:43:06,480 --> 00:43:09,400
is dit de eerste um-resultaten die we hebben

1071
00:43:09,400 --> 00:43:15,559
hier nu en in ieder geval tot de middenklasse uh

1072
00:43:15,559 --> 00:43:18,280
datasets zoals Cypher 10 of zo, dit

1073
00:43:18,280 --> 00:43:20,440
lijkt eigenlijk heel goed te presteren,

1074
00:43:20,440 --> 00:43:22,160
dus we hebben het uitgeprobeerd voor standaard

1075
00:43:22,160 --> 00:43:24,559
architecturen, mode-mnist met reset

1076
00:43:24,559 --> 00:43:29,880
15 en res 18, we hebben tot nu toe vooral gewerkt, uh

1077
00:43:29,880 --> 00:43:32,160
voor zo klein  datasets zoals

1078
00:43:32,160 --> 00:43:35,160
mode, we hebben gratis splitsingen toegepast om

1079
00:43:35,160 --> 00:43:37,640
50 te resetten, we krijgen in principe dezelfde

1080
00:43:37,640 --> 00:43:40,040
prestaties als de standaard backrop naarmate

1081
00:43:40,040 --> 00:43:42,680
netwerken dieper worden, u ziet dat

1082
00:43:42,680 --> 00:43:44,880
er eigenlijk een probleem is dat

1083
00:43:44,880 --> 00:43:47,079
we nu hebben, is eigenlijk overfitting

1084
00:43:47,079 --> 00:43:48,599
omdat we deze lokale hebben  doelen

1085
00:43:48,599 --> 00:43:50,280
lijkt het erop dat deze kleinere blokken eigenlijk

1086
00:43:50,280 --> 00:43:53,079
tot op zekere hoogte overpassen, dit is niet zo

1087
00:43:53,079 --> 00:43:55,800
ernstig voor nog steeds taken als Cypher

1088
00:43:55,800 --> 00:43:58,839
t, dus we komen al aardig dichtbij, maar als

1089
00:43:58,839 --> 00:44:01,520
je nu voor echt grote taken gaat,

1090
00:44:01,520 --> 00:44:04,480
er ontbreekt nog steeds iets waar we

1091
00:44:04,480 --> 00:44:06,839
voor staan  zoals enkele splitsingen

1092
00:44:06,839 --> 00:44:09,000
komen we daar, maar we bereiken niet

1093
00:44:09,000 --> 00:44:11,559
de hele voortplanting, maar het is

1094
00:44:11,559 --> 00:44:13,119
nog steeds interessant om te zien dat je

1095
00:44:13,119 --> 00:44:18,240
dit, dit principe, ook kunt toepassen op

1096
00:44:18,240 --> 00:44:21,160
deze standaard machine learning-

1097
00:44:21,160 --> 00:44:23,599
algoritmen. Oké, dit is mijn tweede

1098
00:44:23,599 --> 00:44:26,240
samenvatting, dus  eigenlijk ontdekten we dat

1099
00:44:26,240 --> 00:44:28,040
diepe Nur-netwerken verrassend goed zijn

1100
00:44:28,040 --> 00:44:31,720
in het generaliseren over waarschijnlijkheidsruimten.

1101
00:44:31,720 --> 00:44:33,839
Dit is hoe dit werk eigenlijk

1102
00:44:33,839 --> 00:44:36,760
begon, en ons idee was om

1103
00:44:36,760 --> 00:44:39,920
deze eh te exploiteren en te gebruiken om het

1104
00:44:39,920 --> 00:44:41,680
leren op dezelfde

1105
00:44:41,680 --> 00:44:44,040
manier te verspreiden als eh  in het eerste project

1106
00:44:44,040 --> 00:44:48,000
liet ik je zien eh en om deze creditopdracht op te lossen

1107
00:44:48,000 --> 00:44:50,359
Probleem door deze

1108
00:44:50,359 --> 00:44:52,160


1109
00:44:52,160 --> 00:44:55,760
feedbacknetwerken te genereren eh ja dat is het eigenlijk en

1110
00:44:55,760 --> 00:44:58,680
dan eh ik wil mijn

1111
00:44:58,680 --> 00:45:01,000
collega's en mijn studenten erkennen, dus ik heb twee

1112
00:45:01,000 --> 00:45:05,480
hele goede eh eh PhD-studenten  KH en

1113
00:45:05,480 --> 00:45:08,400
Cabel die nu hier in de buurt zijn en

1114
00:45:08,400 --> 00:45:11,680
aan dit onderwerp werken en ik, het eerste

1115
00:45:11,680 --> 00:45:14,760
um-project dat ik liet zien was B. Ik deed het samen

1116
00:45:14,760 --> 00:45:17,640
toen ik in Gutan was met Christian TL

1117
00:45:17,640 --> 00:45:20,559
en uh dit project, het tweede project waar

1118
00:45:20,559 --> 00:45:22,800
ik mee werk, heb nauw samengewerkt

1119
00:45:22,800 --> 00:45:24,880
Christian Mea en Anan

1120
00:45:24,880 --> 00:45:26,599
Supron

1121
00:45:26,599 --> 00:45:29,760
en ja,

1122
00:45:30,520 --> 00:45:32,920
heel erg bedankt David, dat was

1123
00:45:32,920 --> 00:45:35,040
absoluut fascinerend. Ik vind het

1124
00:45:35,040 --> 00:45:37,559
ongelooflijk hoe nauw het soort model

1125
00:45:37,559 --> 00:45:39,599
overeenkwam met de biologie, aangezien je

1126
00:45:39,599 --> 00:45:41,359
het hebt afgeleid van de eerste principes. Ik denk dat

1127
00:45:41,359 --> 00:45:43,760
dat echt cool was. Ik had wel een

1128
00:45:43,760 --> 00:45:45,800
vraag.  zo ongeveer het laatste soort

1129
00:45:45,800 --> 00:45:47,720
stukje dat je sprak over het

1130
00:45:47,720 --> 00:45:49,760
convolutionele netwerk en je weet dat je

1131
00:45:49,760 --> 00:45:51,079
zei dat het traditioneel helemaal van

1132
00:45:51,079 --> 00:45:53,400
begin tot eind moet gaan, wat echt inefficiënt is,

1133
00:45:53,400 --> 00:45:54,960
en toen liet je de resultaten zien die je

1134
00:45:54,960 --> 00:45:57,240
kreeg, heb je gekeken naar het energieverbruik

1135
00:45:57,240 --> 00:46:00,839
met  met die van jou ook nog niet, dus we

1136
00:46:00,839 --> 00:46:02,520
hebben uh we

1137
00:46:02,520 --> 00:46:06,760
werken momenteel aan een dus dit eh het is eigenlijk

1138
00:46:06,760 --> 00:46:09,040
niet zo eenvoudig om deze dingen te implementeren

1139
00:46:09,040 --> 00:46:10,880
in standaard machine learning uh

1140
00:46:10,880 --> 00:46:14,319
toolboxen we hebben een dus Kal

1141
00:46:14,319 --> 00:46:17,400
onderzoekt dit momenteel uh de PHD  student in

1142
00:46:17,400 --> 00:46:20,160
Dron, hij heeft nu een implementatie en

1143
00:46:20,160 --> 00:46:22,359
hij evalueert nu

1144
00:46:22,359 --> 00:46:25,520
hoe goed we deze

1145
00:46:25,520 --> 00:46:28,359
parisatie in de praktijk kunnen gebruiken, maar we zijn er

1146
00:46:28,359 --> 00:46:32,119
eigenlijk vrij zeker van dat deze

1147
00:46:32,119 --> 00:46:36,640
eh bedoeld is om het te verlammen. Het zou

1148
00:46:36,640 --> 00:46:38,960
er moeten zijn. De vraag is hoeveel  je

1149
00:46:38,960 --> 00:46:41,400
bespaart in termen van energie, want voor

1150
00:46:41,400 --> 00:46:43,440
deze kleinere schaalmodellen die we

1151
00:46:43,440 --> 00:46:47,720
nu gebruiken reset 18 reset 15 het effect

1152
00:46:47,720 --> 00:46:50,319
is misschien niet zo groot, dus zodra we dit

1153
00:46:50,319 --> 00:46:52,000
opvoeren naar echt grotere modellen

1154
00:46:52,000 --> 00:46:54,400
zou het effect groter moeten zijn, maar ja, dit is

1155
00:46:54,400 --> 00:46:56,480
voortdurend werk

1156
00:46:56,480 --> 00:46:58,920
heel cool, bedankt, en toen

1157
00:46:58,920 --> 00:47:00,760
vroeg ik me dit ook af. Deze

1158
00:47:00,760 --> 00:47:03,119
lokale fout-terug-propagatie is

1159
00:47:03,119 --> 00:47:04,960
iets dat andere mensen hebben geprobeerd

1160
00:47:04,960 --> 00:47:06,520
met deze convolutie-neurale netwerken

1161
00:47:06,520 --> 00:47:08,880
of is dit een vrij nieuwe manier om

1162
00:47:08,880 --> 00:47:11,680
het te implementeren. Uh, er zijn er een heleboel

1163
00:47:11,680 --> 00:47:14,280
benaderingen die dit doen, dus er is

1164
00:47:14,280 --> 00:47:16,000
bijvoorbeeld, ik bedoel, het dichtstbij denk ik dat het

1165
00:47:16,000 --> 00:47:18,040
Doelvoortplanting is,

1166
00:47:18,040 --> 00:47:20,440
die in wezen gebruik maakt van willekeurige

1167
00:47:20,440 --> 00:47:23,640
feedbackgewichten, uh om hier terug te propageren,

1168
00:47:23,640 --> 00:47:25,359
zodat deze jongens niet getraind zouden worden,

1169
00:47:25,359 --> 00:47:27,720


1170
00:47:28,000 --> 00:47:32,520
en die voor zover ik weet  dit werkt

1171
00:47:32,520 --> 00:47:35,559
dit werkt ook goed voor kleinschalige

1172
00:47:35,559 --> 00:47:38,160
problemen, maar voor zover ik weet

1173
00:47:38,160 --> 00:47:40,280
presteren ze niet zo goed, zelfs niet voor

1174
00:47:40,280 --> 00:47:42,319
Cipher 10, ze beginnen al

1175
00:47:42,319 --> 00:47:43,599
kapot te gaan omdat deze willekeurige

1176
00:47:43,599 --> 00:47:46,160
feedbackgewichten gewoon een te grove

1177
00:47:46,160 --> 00:47:48,559
benadering zijn, denk ik  en dit is de

1178
00:47:48,559 --> 00:47:52,760
eerste eh, oké, misschien moet ik voorzichtig zijn.

1179
00:47:52,760 --> 00:47:56,079
Ik denk dat dit de eerste um-methode is waarmee

1180
00:47:56,079 --> 00:47:58,240
je deze feedbackgewichten kunt trainen. Het

1181
00:47:58,240 --> 00:48:01,200
is geen contrastieve methode,

1182
00:48:01,200 --> 00:48:03,079
dus er zijn een aantal methoden die een

1183
00:48:03,079 --> 00:48:05,559
contrastieve stap gebruiken,

1184
00:48:05,559 --> 00:48:08,040
dus je hebt  misschien dit

1185
00:48:08,040 --> 00:48:10,800
voorwaartse algoritme gezien en al deze

1186
00:48:10,800 --> 00:48:13,040
dingen, maar wat ze altijd moeten doen

1187
00:48:13,040 --> 00:48:14,830
is dat ze

1188
00:48:14,830 --> 00:48:16,160
[muziek] insturen,

1189
00:48:16,160 --> 00:48:19,319
uh uh, ze sturen de daadwerkelijke invoergegevens in

1190
00:48:19,319 --> 00:48:22,480
en dan sturen ze een soort anti-

1191
00:48:22,480 --> 00:48:26,520
invoer, dus een anti-invoer die  wordt

1192
00:48:26,520 --> 00:48:29,000
meestal kunstmatig gegenereerd, dus ze

1193
00:48:29,000 --> 00:48:31,040
doen wat vervorming aan de invoer om het te maken,

1194
00:48:31,040 --> 00:48:33,839
en dan trainen ze de ze moeten

1195
00:48:33,839 --> 00:48:36,960
beide informatie lokaal gebruiken om

1196
00:48:36,960 --> 00:48:38,640
de update uit te voeren, zodat het netwerk

1197
00:48:38,640 --> 00:48:41,440
de invoer en de anti-invoer in het geheugen moet houden

1198
00:48:41,440 --> 00:48:44,440
en  de reacties en dit

1199
00:48:44,440 --> 00:48:48,200
maakt eh dit maakt deze benaderingen een

1200
00:48:48,200 --> 00:48:50,880
beetje moeilijker om hierin te parallelliseren en

1201
00:48:50,880 --> 00:48:54,280
het leuke hier is dat we een

1202
00:48:54,280 --> 00:48:57,440
uh een bovengrens afleiden voor dit uh

1203
00:48:57,440 --> 00:49:00,960
variatievrije energieverlies dat volledig kan worden beschreven

1204
00:49:00,960 --> 00:49:03,680
door voorwaartse voortplanting en

1205
00:49:03,680 --> 00:49:05,960
dat  Ik denk dat het nieuw is, dus dat is het

1206
00:49:05,960 --> 00:49:08,480
nieuwe deel van deze

1207
00:49:08,480 --> 00:49:11,550
[muziek]

1208
00:49:11,680 --> 00:49:15,520
heel dat is

1209
00:49:15,720 --> 00:49:19,720
geweldig, ja, een paar opmerkingen, een

1210
00:49:19,720 --> 00:49:21,640
stuk dat soort tussen de twee van

1211
00:49:21,640 --> 00:49:24,280
je toespraken, dat was op zijn minst een nieuw

1212
00:49:24,280 --> 00:49:25,880
onderscheid voor mij, wat het

1213
00:49:25,880 --> 00:49:27,319
verschil was  tussen de neuromorfe

1214
00:49:27,319 --> 00:49:29,920
hardware en de neuromorfe

1215
00:49:29,920 --> 00:49:33,640
algoritmen, dus het gaat niet alleen om nieuwe

1216
00:49:33,640 --> 00:49:35,520
hardware of

1217
00:49:35,520 --> 00:49:39,240
wetwear, maar dat zou geweldig zijn om te

1218
00:49:39,240 --> 00:49:40,760
zien dat het bijna lijkt alsof er een

1219
00:49:40,760 --> 00:49:45,839
tussenstap of een brugstap is bij het gebruik van

1220
00:49:45,839 --> 00:49:47,599
de

1221
00:49:47,599 --> 00:49:51,440
algoritmen op de hardware die we

1222
00:49:51,440 --> 00:49:54,160
vandaag hebben, zoals Sarah de

1223
00:49:54,160 --> 00:49:56,240
piek noemde  neurale netwerken die

1224
00:49:56,240 --> 00:49:59,880
geschikt zijn voor GPU's of gewoon gebruik maken van

1225
00:49:59,880 --> 00:50:04,079
gestandaardiseerde um CPU multicore

1226
00:50:04,079 --> 00:50:07,000
planningsbenaderingen, je kunt al

1227
00:50:07,000 --> 00:50:09,799
meer doen met wat we

1228
00:50:09,799 --> 00:50:13,559
hebben met behulp van de neuromorfe algoritmen,

1229
00:50:13,559 --> 00:50:18,640
dus het is niet alleen een materiaalwetenschappelijk

1230
00:50:18,640 --> 00:50:22,040
onderwerp, maar er is ook veel op de

1231
00:50:22,040 --> 00:50:24,640
echt microschaal dat we  kan leren

1232
00:50:24,640 --> 00:50:26,920
met betrekking tot de planning van ruisverwerking

1233
00:50:26,920 --> 00:50:28,599
en dan zelfs op hogere

1234
00:50:28,599 --> 00:50:30,559
abstractieniveaus, waarschijnlijk leren van

1235
00:50:30,559 --> 00:50:32,720
biomimicry en cognitieve systemen in het

1236
00:50:32,720 --> 00:50:34,839
algemeen, maar dat was alsof dat een

1237
00:50:34,839 --> 00:50:37,240
onderscheid voor

1238
00:50:37,240 --> 00:50:40,839
mij was, ja, dus misschien om toe te voegen, eh ja, dus ik

1239
00:50:40,839 --> 00:50:43,720
denk dat het probleem wordt

1240
00:50:43,720 --> 00:50:46,640
nu echt dringender naarmate deze uh

1241
00:50:46,640 --> 00:50:49,000
neuromorfe uh-apparaten worden. Al de

1242
00:50:49,000 --> 00:50:51,119
hardware-apparaten worden

1243
00:50:51,119 --> 00:50:53,839
volwassener en ze kunnen hier meestal niet echt op

1244
00:50:53,839 --> 00:50:57,520
schijnen, uh op deze standaard

1245
00:50:57,520 --> 00:50:59,119
machine learning-algoritmen, omdat ze

1246
00:50:59,119 --> 00:51:01,280
echt zijn geoptimaliseerd voor

1247
00:51:01,280 --> 00:51:04,319
GPU's, dus je moet er een beetje over nadenken

1248
00:51:04,319 --> 00:51:06,079
je moet een stap terug doen en

1249
00:51:06,079 --> 00:51:08,680
opnieuw nadenken over de algoritmische kant

1250
00:51:08,680 --> 00:51:11,960
om ze echt op volle

1251
00:51:11,960 --> 00:51:13,960
capaciteit te gebruiken en wij, zoals je hebt gezien,

1252
00:51:13,960 --> 00:51:16,480
werken samen met eh Professor

1253
00:51:16,480 --> 00:51:18,839
Maya die deze Spiner-chip in

1254
00:51:18,839 --> 00:51:20,720
Dron doet, maar er zijn ook andere  benaderingen

1255
00:51:20,720 --> 00:51:23,359
en zoals de L-chip die Sarah noemde

1256
00:51:23,359 --> 00:51:26,319
van Intel enzovoort, en ze

1257
00:51:26,319 --> 00:51:29,520
onderzoeken dit nu echt, ze ook

1258
00:51:29,520 --> 00:51:31,960
van de algoritmische

1259
00:51:31,960 --> 00:51:34,520
kant. Ik vind het erg nuttig, het is een

1260
00:51:34,520 --> 00:51:36,520
soort mentaliteit of een mentaal raamwerk

1261
00:51:36,520 --> 00:51:38,839
als ik erover nadenk  computers of Ai

1262
00:51:38,839 --> 00:51:39,760
en ik dit komt waarschijnlijk omdat ik een

1263
00:51:39,760 --> 00:51:40,920
neurowetenschapper ben maar ik moet

1264
00:51:40,920 --> 00:51:43,040
het ook goed vertalen hoe werken de hersenen

1265
00:51:43,040 --> 00:51:44,680
hoe werkt de informatieverwerking

1266
00:51:44,680 --> 00:51:46,880
etc in de hersenen en en toen

1267
00:51:46,880 --> 00:51:48,480
kwam ik bij een soort computerwetenschappen en AI

1268
00:51:48,480 --> 00:51:49,920
na Neuroscience merkte ik dat ik

1269
00:51:49,920 --> 00:51:51,720
het op natuurlijke wijze vertaalde, maar ik heb het gevoel dat

1270
00:51:51,720 --> 00:51:53,760
het raamwerk uiteindelijk gewoon een heel nuttige

1271
00:51:53,760 --> 00:51:56,000
manier is om computers te begrijpen,

1272
00:51:56,000 --> 00:51:57,319
omdat onze hersenen, zoals ik al zei,

1273
00:51:57,319 --> 00:51:59,280
gewoon deze enorme supercomputers zijn

1274
00:51:59,280 --> 00:52:01,079
en ik voortdurend papieren aan het lezen ben op de

1275
00:52:01,079 --> 00:52:02,599
computer  wetenschap of wat dan ook, en als

1276
00:52:02,599 --> 00:52:04,680
je dan eenmaal iets kunt conceptualiseren,

1277
00:52:04,680 --> 00:52:07,520
hoe dichtbij hoe

1278
00:52:07,520 --> 00:52:09,880
neuromorfisch is dit en als je er dan over

1279
00:52:09,880 --> 00:52:11,440
begint na te denken, hoe kun

1280
00:52:11,440 --> 00:52:12,520
je het dan aanpassen zodat het iets meer

1281
00:52:12,520 --> 00:52:14,079
neuromorfisch is en gaat dat

1282
00:52:14,079 --> 00:52:15,839
je dan deze winst opleveren?  dat we met

1283
00:52:15,839 --> 00:52:17,040
de hersenen krijgen, gaat het je

1284
00:52:17,040 --> 00:52:19,319
een soort extra parallelle berekening geven of

1285
00:52:19,319 --> 00:52:20,559
gaat het je wat energie-

1286
00:52:20,559 --> 00:52:23,480
efficiëntie geven, dus ja, ik vind het NE zoals

1287
00:52:23,480 --> 00:52:24,599
de definities toen ik naar

1288
00:52:24,599 --> 00:52:26,000
de definitie keek, ik denk dat het er echt van

1289
00:52:26,000 --> 00:52:27,520
afhangt  je rechten zijn een definitie en

1290
00:52:27,520 --> 00:52:30,079
omdat het op

1291
00:52:30,079 --> 00:52:32,640
dit moment ook zo'n dynamisch gebied is, ik denk dat het zal

1292
00:52:32,640 --> 00:52:34,079
veranderen en het zal

1293
00:52:34,079 --> 00:52:35,559
veranderen, maar voor mij heb ik het gevoel dat

1294
00:52:35,559 --> 00:52:37,680
neuromorfisch meer een frame is, zoals een

1295
00:52:37,680 --> 00:52:39,559
mentaal raamwerk waarin ik  kijk naar de dingen

1296
00:52:39,559 --> 00:52:42,240
door

1297
00:52:42,400 --> 00:52:44,119
te conceptualiseren ja ik denk dat het

1298
00:52:44,119 --> 00:52:47,920
ook niet erg goed gedefinieerd is. ik bedoel uh in

1299
00:52:47,920 --> 00:52:50,319
je zei ook dat die

1300
00:52:50,319 --> 00:52:52,359
kunstmatige neuronennetwerken eigenlijk een

1301
00:52:52,359 --> 00:52:54,880
neuromorf concept zijn als je wilt, en dat

1302
00:52:54,880 --> 00:52:55,960
waren ze

1303
00:52:55,960 --> 00:52:58,119
vanaf de eerste dag en het is eigenlijk een

1304
00:52:58,119 --> 00:53:00,160
het is een  groot succesverhaal, als

1305
00:53:00,160 --> 00:53:02,400
je naar de jaren 90 kijkt, toen deze

1306
00:53:02,400 --> 00:53:04,960
Vector-machines ondersteunden en

1307
00:53:04,960 --> 00:53:08,200
deze alternatieve modellen opkwamen, maar

1308
00:53:08,200 --> 00:53:10,920
geen van hen heeft de

1309
00:53:10,920 --> 00:53:13,440
nieuwe neuromorfe benaderingen overleefd, dus het is

1310
00:53:13,440 --> 00:53:14,880
eigenlijk heel leuk, maar er is nog steeds een

1311
00:53:14,880 --> 00:53:17,040
communicatiegemeenschap  dat denkt dat

1312
00:53:17,040 --> 00:53:19,119
er meer kenmerken van de hersenen zijn

1313
00:53:19,119 --> 00:53:22,400
die je moet invoeren om

1314
00:53:22,400 --> 00:53:23,599
tot het echte

1315
00:53:23,599 --> 00:53:26,960
werk te komen, ja dus ik denk dat dit een beetje een

1316
00:53:26,960 --> 00:53:30,799
term is die eigenlijk niet zo goed gedefinieerd is,

1317
00:53:30,799 --> 00:53:33,040
en ik denk dat met jouw onderzoek dat

1318
00:53:33,040 --> 00:53:34,799
van jou is  is bijna het kleinste niveau

1319
00:53:34,799 --> 00:53:36,440
waarop ik mensen ernaar heb zien kijken. Ik

1320
00:53:36,440 --> 00:53:37,880
weet niet of je nog iets anders hebt gezien,

1321
00:53:37,880 --> 00:53:39,520
maar we hebben het niet alleen over een

1322
00:53:39,520 --> 00:53:41,400
celniveau van vrije energie en actieve

1323
00:53:41,400 --> 00:53:43,040
gevolgtrekking.  eigenlijk praten over

1324
00:53:43,040 --> 00:53:46,599
een celstructuur en dan zo, dan

1325
00:53:46,599 --> 00:53:48,319
denk je, hoe klein gaat het,

1326
00:53:48,319 --> 00:53:49,960
gaan we praten over

1327
00:53:49,960 --> 00:53:51,559
subcellulaire celstructuren, je kent het

1328
00:53:51,559 --> 00:53:53,559
uiteindelijk, zoals mitochondriën, die vrije

1329
00:53:53,559 --> 00:53:55,160
energie op een vergelijkbare manier gebruiken met samengestelde

1330
00:53:55,160 --> 00:53:56,760
compartimenten en ja, dus ik denk

1331
00:53:56,760 --> 00:53:57,920
eigenlijk  'Het zou interessant zijn om je

1332
00:53:57,920 --> 00:53:59,960
gedachten te krijgen, David, je weet dat je in

1333
00:53:59,960 --> 00:54:02,520
het begin hebt gesproken over hoe aanmeldingen in compartimenten zijn

1334
00:54:02,520 --> 00:54:05,319
verdeeld. Heb je

1335
00:54:05,319 --> 00:54:07,599
verschillende soorten instantiaties hiervan

1336
00:54:07,599 --> 00:54:09,480
in verschillende compartimenten, gewoon binnen

1337
00:54:09,480 --> 00:54:11,480
één aanmelding, bijna alsof je er een

1338
00:54:11,480 --> 00:54:13,359
beetje naar wilt kijken?  dat granulaire niveau

1339
00:54:13,359 --> 00:54:14,880
of is het meer dat je nu neemt wat

1340
00:54:14,880 --> 00:54:16,079
je hiervan hebt geleerd en het

1341
00:54:16,079 --> 00:54:17,760
terugzet in hoe kunnen we

1342
00:54:17,760 --> 00:54:19,440
de AI efficiënter maken?

1343
00:54:19,440 --> 00:54:21,920
uh ja, we gaan veel meer

1344
00:54:21,920 --> 00:54:24,240
in deze richting nu we zien  hoe

1345
00:54:24,240 --> 00:54:28,040
we dit terug kunnen inbouwen in eh AI-modellen,

1346
00:54:28,040 --> 00:54:31,359
eh, dus ik denk dat het de vrije energie is, dus je

1347
00:54:31,359 --> 00:54:32,960
moet een beetje voorzichtig zijn bij het gebruik van het

1348
00:54:32,960 --> 00:54:34,839
vrije-energieprincipe, omdat het zo'n

1349
00:54:34,839 --> 00:54:36,880
krachtig algemeen raamwerk is dat je

1350
00:54:36,880 --> 00:54:40,160
het in principe op alles

1351
00:54:40,160 --> 00:54:41,359
[muziek] kunt toepassen

1352
00:54:41,359 --> 00:54:45,680
Ehm, en het is niet noodzakelijkerwijs dat je

1353
00:54:45,680 --> 00:54:49,440
uiteindelijk met een nuttig resultaat zult komen,

1354
00:54:49,440 --> 00:54:53,680
gewoon toepassen, gewoon dit zeggen, eh

1355
00:54:53,680 --> 00:54:56,119
en we bedoelen eigenlijk dat dit

1356
00:54:56,119 --> 00:54:58,040
eigenlijk begon als een bijproject, dit was mijn

1357
00:54:58,040 --> 00:55:03,760
soort uh coid um pandemisch lockdown um

1358
00:55:03,760 --> 00:55:06,480
project en ik was gewoon  Ik ben hier nieuwsgierig naar

1359
00:55:06,480 --> 00:55:09,119
en eh of je dit echt kunt

1360
00:55:09,119 --> 00:55:10,680
oplossen, omdat ik dacht dat de aanmeldingen

1361
00:55:10,680 --> 00:55:12,839
misschien eenvoudig genoeg zijn, want

1362
00:55:12,839 --> 00:55:15,520
als je de papieren ingaat, moeten

1363
00:55:15,520 --> 00:55:17,440
ze op een gegeven moment een aantal

1364
00:55:17,440 --> 00:55:19,760
benaderingen maken, ze doen meestal een eh gemeen veld,

1365
00:55:19,760 --> 00:55:22,960
dus ze  ga voor de eerste modi en

1366
00:55:22,960 --> 00:55:25,240
dan kun je deze jongens oplossen voor

1367
00:55:25,240 --> 00:55:27,039
complexer, zelfs voor neuronen. Het is

1368
00:55:27,039 --> 00:55:29,119
eigenlijk moeilijk als je naar neuron- of

1369
00:55:29,119 --> 00:55:31,160
netwerkniveau gaat, het is moeilijk. Het is

1370
00:55:31,160 --> 00:55:35,160
erg ingewikkelde wiskunde, maar voor een sinus is het

1371
00:55:35,160 --> 00:55:36,599
eigenlijk eenvoudig genoeg, dus je kunt het ook

1372
00:55:36,599 --> 00:55:38,559
daadwerkelijk doen  dit en en spel

1373
00:55:38,559 --> 00:55:39,880
alles uit als je de juiste

1374
00:55:39,880 --> 00:55:42,640
aannames doet en eh en heb

1375
00:55:42,640 --> 00:55:44,559
deze dingen eigenlijk gewoon afgeleid en dat was

1376
00:55:44,559 --> 00:55:47,079


1377
00:55:47,079 --> 00:55:52,480
een soort spel waar ik aan begon en

1378
00:55:52,480 --> 00:55:55,240
toen bleek het best goed te werken,

1379
00:55:55,240 --> 00:55:58,720
denk ik uiteindelijk  ja heel

1380
00:55:58,720 --> 00:56:01,200
eh, ik weet niet zeker of jij, ik hou van

1381
00:56:01,200 --> 00:56:02,960
mitochondriën of zo, ik weet zeker dat je

1382
00:56:02,960 --> 00:56:04,640
dezelfde principes zou kunnen toepassen, maar ik weet niet

1383
00:56:04,640 --> 00:56:08,599
zeker of de resultaten die je krijgt betekenisvol zouden zijn

1384
00:56:08,599 --> 00:56:11,079
of je op

1385
00:56:11,079 --> 00:56:12,240
wat voor

1386
00:56:12,240 --> 00:56:14,960
manier dan ook zouden helpen, nou dat is  dat is altijd het

1387
00:56:14,960 --> 00:56:16,839
risico dat je zoveel tijd investeert en

1388
00:56:16,839 --> 00:56:18,839
dan krijg je uiteindelijk wat resultaten en

1389
00:56:18,839 --> 00:56:19,240


1390
00:56:19,240 --> 00:56:20,440


1391
00:56:20,440 --> 00:56:23,000
weet je niet [Muziek] dat was ook iets waarvan ik

1392
00:56:23,000 --> 00:56:25,599
dacht dat het best interessant was, namelijk

1393
00:56:25,599 --> 00:56:28,720
de synaps was de agent, het is heel

1394
00:56:28,720 --> 00:56:31,000
gemakkelijk denk  oh, we zullen eerst een agent-gebaseerd

1395
00:56:31,000 --> 00:56:34,240
model van een neuraal systeem maken dat de

1396
00:56:34,240 --> 00:56:36,480
neiging heeft om Gia of niet-neurale celtypen niet te omvatten,

1397
00:56:36,480 --> 00:56:39,240
maar het is bijna een dubbel

1398
00:56:39,240 --> 00:56:41,480
onbetwiste veronderstelling dat de cel

1399
00:56:41,480 --> 00:56:43,200
de agent zou zijn,

1400
00:56:43,200 --> 00:56:48,079
maar toen was het een geweldige overgang

1401
00:56:48,079 --> 00:56:50,319
van de persoon die de bal over

1402
00:56:50,319 --> 00:56:53,440
de muur gooit, dat is een actie-centrische

1403
00:56:53,440 --> 00:56:56,000
aanpak waarbij je slechts gedeeltelijk

1404
00:56:56,000 --> 00:56:57,960
zicht hebt op de

1405
00:56:57,960 --> 00:57:01,079
gevolgen en dan is dat precies het

1406
00:57:01,079 --> 00:57:03,640
scenario waarin de synaps zich

1407
00:57:03,640 --> 00:57:06,599
op een andere manier bevindt of het had

1408
00:57:06,599 --> 00:57:09,640
zo kunnen zijn opgezet dat  een neuron is de

1409
00:57:09,640 --> 00:57:12,319
agent, we bouwen kaarten, geen

1410
00:57:12,319 --> 00:57:15,119
territoria, en dus, zoals je

1411
00:57:15,119 --> 00:57:17,000
zei, het vrije-energieprincipe, het is een

1412
00:57:17,000 --> 00:57:19,359
principe voor

1413
00:57:19,359 --> 00:57:22,720
alles en dus alleen maar principiële

1414
00:57:22,720 --> 00:57:25,440
uitspraken doen over dingen

1415
00:57:25,440 --> 00:57:27,319
is een

1416
00:57:27,319 --> 00:57:30,119
inzet en dan denk ik dat mijn vraag aan

1417
00:57:30,119 --> 00:57:33,079
jou is: wat doet dat dan?  maak het nuttig of

1418
00:57:33,079 --> 00:57:35,119
bij het leren en sleutelen

1419
00:57:35,119 --> 00:57:37,880
aan deze modellen, welke gedifferentieerde

1420
00:57:37,880 --> 00:57:39,760
situaties waarin je het vrije-

1421
00:57:39,760 --> 00:57:42,000
energieprincipe of actieve gevolgtrekking toepaste en je het

1422
00:57:42,000 --> 00:57:44,079
gevoel had dat het een

1423
00:57:44,079 --> 00:57:46,440
bijdrage leverde aan je onderzoek Richting

1424
00:57:46,440 --> 00:57:47,960
versus waar je mee speelde en het

1425
00:57:47,960 --> 00:57:50,119
was alsof dat zo was  te

1426
00:57:50,119 --> 00:57:52,480
logisch, ik denk dat het vrije

1427
00:57:52,480 --> 00:57:55,000
energieprincipe logisch is in een context

1428
00:57:55,000 --> 00:57:58,160
waarin je onvolledige

1429
00:57:58,160 --> 00:58:01,440
informatie hebt, dus zodra je dat bijvoorbeeld doet

1430
00:58:01,440 --> 00:58:03,039
in het geval van aanmeldingen,

1431
00:58:03,039 --> 00:58:05,520
was de vraag waarmee we begonnen, dit

1432
00:58:05,520 --> 00:58:07,039
probleem dat de aanmeldingen moeten oplossen

1433
00:58:07,039 --> 00:58:09,039
dat het onvolledige informatie heeft over

1434
00:58:09,039 --> 00:58:11,760
de toestand in het

1435
00:58:11,760 --> 00:58:15,359
cellichaam, omdat het alleen dit

1436
00:58:15,359 --> 00:58:17,200
soort dingen ziet, of dat is in

1437
00:58:17,200 --> 00:58:19,400
ieder geval de aanname van het model en ook wat we

1438
00:58:19,400 --> 00:58:22,119
van de experimentatoren krijgen dat ze in

1439
00:58:22,119 --> 00:58:23,359
wezen alleen deze spe-

1440
00:58:23,359 --> 00:58:25,160
voortplantende actie zien  potentieel ziet dus een

1441
00:58:25,160 --> 00:58:28,440
enkele binaire variabele over

1442
00:58:28,440 --> 00:58:31,960
de toestand van de

1443
00:58:31,960 --> 00:58:35,440
Soma, dus in wezen is dit een probleem

1444
00:58:35,440 --> 00:58:39,480
van onvolledige informatie en ook

1445
00:58:39,480 --> 00:58:42,720
het tweede ingrediënt dat je een

1446
00:58:42,720 --> 00:58:45,599
agent nodig hebt, dat je een vorm van keuzevrijheid nodig hebt.

1447
00:58:45,599 --> 00:58:46,960
Ik denk dat als je  pas het vrije

1448
00:58:46,960 --> 00:58:50,119
energieprincipe toe op een systeem zonder keuzevrijheid,

1449
00:58:50,119 --> 00:58:52,440
dus als iets geen interactie heeft met

1450
00:58:52,440 --> 00:58:55,440
een omgeving in een gesloten lus,

1451
00:58:55,440 --> 00:58:57,880
dan wordt het echt vaag en ik

1452
00:58:57,880 --> 00:59:00,480
denk dat dit model al op het

1453
00:59:00,480 --> 00:59:03,000
randje staat als het komt, omdat

1454
00:59:03,000 --> 00:59:05,319
deze modellen dat niet doen  Ik heb niet echt

1455
00:59:05,319 --> 00:59:07,079
een bureau, maar ze produceren in ieder geval een

1456
00:59:07,079 --> 00:59:09,359
output, dus je kunt dit nog steeds beschouwen

1457
00:59:09,359 --> 00:59:11,839
als een interactie met een

1458
00:59:11,839 --> 00:59:14,760
omgeving, maar sommige, zodra je dat verliest,

1459
00:59:14,760 --> 00:59:17,599
denk ik dat er eenvoudigere modellen zouden zijn

1460
00:59:17,599 --> 00:59:21,039
die je gewoon de mogelijkheid kunnen geven

1461
00:59:22,400 --> 00:59:26,119
hetzelfde ja

1462
00:59:26,119 --> 00:59:27,839
eigenlijk in de aanmeldingen in het

1463
00:59:27,839 --> 00:59:31,319
aanmeldingsgeval het bureau is alleen dit uh dit

1464
00:59:31,319 --> 00:59:33,880
voegt ruis toe eigenlijk in het model

1465
00:59:33,880 --> 00:59:35,240
omdat de aanmeldingen synoptisch PR worden geactiveerd

1466
00:59:35,240 --> 00:59:38,640
en dan voegt het dit toe, het

1467
00:59:38,640 --> 00:59:40,520
gebruikt zijn interne status om de juiste

1468
00:59:40,520 --> 00:59:41,480
hoeveelheid

1469
00:59:41,480 --> 00:59:44,000
ruis toe te voegen die  is waarschijnlijk al het

1470
00:59:44,000 --> 00:59:45,710
minimale agentschap dat je zou kunnen

1471
00:59:45,710 --> 00:59:48,799
[Muziek]

1472
00:59:48,799 --> 00:59:51,119
stel je Sarah voor, je wilt een vraag stellen

1473
00:59:51,119 --> 00:59:52,599
of ik kan een

1474
00:59:52,599 --> 00:59:54,920
vraag stellen, eh ja, ik was meer gewoon een

1475
00:59:54,920 --> 00:59:56,160
opmerking, zoals ik denk dat het best

1476
00:59:56,160 --> 00:59:58,280
interessant is, zoals mensen praten over

1477
00:59:58,280 --> 01:00:00,440
biologie, sommige mensen zeggen dat het niet echt is

1478
01:00:00,440 --> 01:00:02,400
wetenschap omdat het allemaal rommelig en lawaaierig is,

1479
01:00:02,400 --> 01:00:04,359
maar ik denk dat het heel

1480
01:00:04,359 --> 01:00:06,039
interessant werkt, omdat het is alsof je zegt dat

1481
01:00:06,039 --> 01:00:07,559
de synaptische ruis eigenlijk een

1482
01:00:07,559 --> 01:00:10,000
rapportage van onzekerheid is, dus in die

1483
01:00:10,000 --> 01:00:11,480
essentie rapporteert het eigenlijk waarschijnlijk vrij

1484
01:00:11,480 --> 01:00:13,880
nauwkeurig en de rommelige

1485
01:00:13,880 --> 01:00:15,359
wereld in plaats van de biologie zelf  het is

1486
01:00:15,359 --> 01:00:16,920
allemaal rommelig, maar dat is precies waar

1487
01:00:16,920 --> 01:00:19,359
ik aan dacht, eh ja, ik

1488
01:00:19,359 --> 01:00:20,480
denk dat ik ook nieuwsgierig was, zoals je

1489
01:00:20,480 --> 01:00:21,880
zei, dit was zoiets als je lockdown-project,

1490
01:00:21,880 --> 01:00:23,920
maar ik ben gewoon geïnteresseerd in hoe je

1491
01:00:23,920 --> 01:00:25,960
tot het principe van de vrije energie kwam, hoe

1492
01:00:25,960 --> 01:00:27,359
je tegenkwam  het was iets waar je

1493
01:00:27,359 --> 01:00:29,240
al behoorlijk bekend mee was, of een

1494
01:00:29,240 --> 01:00:30,960
deel van je netwerk of collega's hadden

1495
01:00:30,960 --> 01:00:32,359
het erover of kwam je

1496
01:00:32,359 --> 01:00:36,000
het tegen in een paper, eh, ik bedoel, dat was ik

1497
01:00:36,000 --> 01:00:37,839
toen ik tijdens mijn doctoraat was, ik was

1498
01:00:37,839 --> 01:00:40,920
geïnteresseerd in eh, in variatiemethoden

1499
01:00:40,920 --> 01:00:44,319
en probabilistische methoden, eh, en

1500
01:00:44,319 --> 01:00:46,680
toen begon ik hierover te lezen en dus

1501
01:00:46,680 --> 01:00:49,440
las ik een aantal um-kristance-artikelen

1502
01:00:49,440 --> 01:00:53,079
en ik vond dit interessant en

1503
01:00:53,079 --> 01:00:57,319
eh, eigenlijk moedigde mijn PhD-supervisor

1504
01:00:57,319 --> 01:01:00,280
me altijd aan om niet

1505
01:01:00,280 --> 01:01:01,520
die

1506
01:01:01,520 --> 01:01:03,880
kant op te gaan, en dan daarna  Ik ben

1507
01:01:03,880 --> 01:01:05,799
afgestudeerd. Ik dacht: oké, nu kan ik doen wat

1508
01:01:05,799 --> 01:01:08,079
ik wil. Ik probeer het

1509
01:01:08,079 --> 01:01:10,039
uit, dus

1510
01:01:10,039 --> 01:01:12,400
ja, en dan denk ik: denk je dat het

1511
01:01:12,400 --> 01:01:15,319
de moeite waard zou zijn, zoals de volgende stappen voor

1512
01:01:15,319 --> 01:01:17,400
jou of voor het veld dat dit daadwerkelijk probeert

1513
01:01:17,400 --> 01:01:19,799
te implementeren, weet je misschien  enkele

1514
01:01:19,799 --> 01:01:21,960
van de meer analoge chips die

1515
01:01:21,960 --> 01:01:23,400
in de ruimte worden gebouwd, zoals de analoge

1516
01:01:23,400 --> 01:01:25,119
neuromorfe chips waarvan ik weet dat je ze kunt

1517
01:01:25,119 --> 01:01:28,200
hebben, zoals een aantal synaptische, dynamische synapsen

1518
01:01:28,200 --> 01:01:29,799
en dingen als: denk je dat het de

1519
01:01:29,799 --> 01:01:31,839
moeite waard is om te proberen je eigen

1520
01:01:31,839 --> 01:01:34,839
harde hardware te implementeren of wat dan ook?  gedachten

1521
01:01:34,839 --> 01:01:37,119
daarover, eh, ik bedoel de tripletregel die

1522
01:01:37,119 --> 01:01:39,799
voortkomt uit dit eerste werk dat ik liet zien. Ik

1523
01:01:39,799 --> 01:01:41,079
denk dat dat interessant zou zijn om het te

1524
01:01:41,079 --> 01:01:45,200
implementeren.

1525
01:01:45,200 --> 01:01:47,440


1526
01:01:47,440 --> 01:01:49,359


1527
01:01:49,359 --> 01:01:52,319
foto omdat het echt

1528
01:01:52,319 --> 01:01:56,640
de dynamiek van het

1529
01:01:56,640 --> 01:01:59,839
membraan van het celmembraan nabootst, dus als

1530
01:01:59,839 --> 01:02:02,640
de neuromorfe hardware dat

1531
01:02:02,640 --> 01:02:04,640
zou doen, dus

1532
01:02:04,640 --> 01:02:08,079
als het model in de aanmeldingen

1533
01:02:08,079 --> 01:02:10,440
en het neuronmodel heel

1534
01:02:10,440 --> 01:02:13,680
goed bij elkaar passen, zou het model je moeten geven  deze

1535
01:02:13,680 --> 01:02:16,400
mooie uh zelfstabiliserende functie zodat

1536
01:02:16,400 --> 01:02:19,160
neuronen echt niet in een

1537
01:02:19,160 --> 01:02:20,880
epileptische toestand terechtkomen of zo en je krijgt dit

1538
01:02:20,880 --> 01:02:22,720
gratis van dit model dat is wat we

1539
01:02:22,720 --> 01:02:25,160
in de simulaties zagen,

1540
01:02:25,160 --> 01:02:28,720
maar in de simulaties hadden we natuurlijk de

1541
01:02:28,720 --> 01:02:30,960
volledige controle hierover  Dynamiek komt

1542
01:02:30,960 --> 01:02:33,000
op de juiste manier overeen,

1543
01:02:33,000 --> 01:02:36,680
dus dat is waarschijnlijk een beetje lastiger

1544
01:02:36,680 --> 01:02:39,200
voor hardware, maar het is waarschijnlijk oplosbaar,

1545
01:02:39,200 --> 01:02:41,039
dus het zou interessant zijn. Ja, wat

1546
01:02:41,039 --> 01:02:42,480
je ervoor krijgt, is dat je over

1547
01:02:42,480 --> 01:02:44,520
deze puur op gebeurtenissen gebaseerde tools beschikt

1548
01:02:44,520 --> 01:02:48,599
die alleen um prepost-spikes gebruiken

1549
01:02:48,599 --> 01:02:49,520
dat is

1550
01:02:49,520 --> 01:02:53,000
leuk, heel cool, bedankt ja Daniel, als

1551
01:02:53,000 --> 01:02:55,200
je een vraag had, dat

1552
01:02:55,200 --> 01:02:58,559


1553
01:02:58,559 --> 01:03:00,319
is een geweldig principe, bijvoorbeeld als je het

1554
01:03:00,319 --> 01:03:03,240
neuromorfe algoritme zo kunt ontwerpen dat het

1555
01:03:03,240 --> 01:03:06,599
een materieel kenmerk gebruikt, zoals de

1556
01:03:06,599 --> 01:03:08,640
daadwerkelijke lekkende permeabiliteit van een membraan

1557
01:03:08,640 --> 01:03:12,599
of daadwerkelijke ruimtelijke nabijheid  als je

1558
01:03:12,599 --> 01:03:15,640
een materiële functie kunt gebruiken, een analoge

1559
01:03:15,640 --> 01:03:19,000
functie die niet gevirtualiseerd is, dan bevindt deze zich

1560
01:03:19,000 --> 01:03:20,119
al in

1561
01:03:20,119 --> 01:03:23,079
de buurt van toekomstige hardware, dus dat is

1562
01:03:23,079 --> 01:03:25,760
een geweldig punt en dan het punt van s,

1563
01:03:25,760 --> 01:03:28,920
alsof bijna biologie geen

1564
01:03:28,920 --> 01:03:32,520
wetenschap is, en er is een beroemd

1565
01:03:32,520 --> 01:03:34,480
citaat dat er nooit zal zijn  een Newton

1566
01:03:34,480 --> 01:03:36,839
voor een grassprietje omdat sommige mensen

1567
01:03:36,839 --> 01:03:38,839
zeggen: ja, het is een andere biologie, het

1568
01:03:38,839 --> 01:03:41,079
lijkt meer op geschiedenis, want of je

1569
01:03:41,079 --> 01:03:42,680
dit nu vanuit een ontwikkelings- of

1570
01:03:42,680 --> 01:03:44,880
ecologie- of evolutieperspectief benadert, biologie

1571
01:03:44,880 --> 01:03:46,640
is een historische wetenschap, het is geen

1572
01:03:46,640 --> 01:03:49,480
echte wetenschap en dat deed me denken

1573
01:03:49,480 --> 01:03:53,000
aan  het crosscountry-shirt waarop staat dat onze

1574
01:03:53,000 --> 01:03:55,000
sport jouw straf is,

1575
01:03:55,000 --> 01:03:58,319
dus het is niet zo dat jouw

1576
01:03:58,319 --> 01:04:02,760
geluid het signaal van de biologie is en zo

1577
01:04:02,760 --> 01:04:04,279


1578
01:04:04,279 --> 01:04:08,680
gebeurt het. Mijn vraag ging over deze

1579
01:04:08,680 --> 01:04:10,640
spanning

1580
01:04:10,640 --> 01:04:14,039
tussen, denk ik, neurale en computationele

1581
01:04:14,039 --> 01:04:16,760
manieren om naar de bronnen te kijken die

1582
01:04:16,760 --> 01:04:19,440
verband houden met berekeningen, dus  vanuit het

1583
01:04:19,440 --> 01:04:23,720
Von Noyman-paradigma hebben we veel

1584
01:04:23,720 --> 01:04:27,720
gedeelde referentiepunten CPU-cycli Ram-

1585
01:04:27,720 --> 01:04:30,559
capaciteit en al dit soort dingen

1586
01:04:30,559 --> 01:04:34,520
en zelfs in je

1587
01:04:34,520 --> 01:04:36,559
inleidingen vertelde je:

1588
01:04:36,559 --> 01:04:38,839
dit is het aantal CPU-cycli dat het

1589
01:04:38,839 --> 01:04:41,799
doormaakt of dit is het aantal parameters dat

1590
01:04:41,799 --> 01:04:43,920
zou hebben  om te worden opgeslagen of iets

1591
01:04:43,920 --> 01:04:45,319
dergelijks,

1592
01:04:45,319 --> 01:04:48,240
maar dat

1593
01:04:48,240 --> 01:04:53,160
verwijst naar een ander paradigma, dus hoe

1594
01:04:53,160 --> 01:04:56,160


1595
01:04:56,880 --> 01:05:01,640
zien resourcedescriptors of capaciteitsdescriptors

1596
01:05:01,640 --> 01:05:04,319
eruit als we ons buiten de ruimte bevinden van

1597
01:05:04,319 --> 01:05:05,559
oké ja, stroomverbruik, dat is

1598
01:05:05,559 --> 01:05:07,039
iets dat je in een doos kunt stoppen

1599
01:05:07,039 --> 01:05:09,079
en gewoon een bomcalorimeter kunt gebruiken die dat is  een

1600
01:05:09,079 --> 01:05:12,520
beetje als laaghangend fruit, maar nu

1601
01:05:12,520 --> 01:05:15,760
oké. Naast alleen de pure energie- of

1602
01:05:15,760 --> 01:05:16,960


1603
01:05:16,960 --> 01:05:19,319
caloriebehoefte, wat kunnen we zeggen, dat is

1604
01:05:19,319 --> 01:05:21,880
analoog aan de manier waarop we praten

1605
01:05:21,880 --> 01:05:25,200
over de processor, de Ram of de harde

1606
01:05:25,200 --> 01:05:27,759
schijf op een

1607
01:05:30,000 --> 01:05:32,839
computer. Ik bedoel, ik ben ja  Ik zou

1608
01:05:32,839 --> 01:05:34,279
daar nog eens over moeten nadenken. Ik

1609
01:05:34,279 --> 01:05:35,200
denk dat er een aantal interessante

1610
01:05:35,200 --> 01:05:37,240
opmerkingen in het artikel op die dia stonden. Ik liet

1611
01:05:37,240 --> 01:05:39,520
zien dat er gesproken werd over de hersenen en de

1612
01:05:39,520 --> 01:05:41,119
energie. Er was een artikel waar ik naar linkte.

1613
01:05:41,119 --> 01:05:42,359
Ik moet de  referentie en laat

1614
01:05:42,359 --> 01:05:43,839
je weten wat het is, want QR C is

1615
01:05:43,839 --> 01:05:46,520
nu weg, eh, maar dat had een aantal interessante

1616
01:05:46,520 --> 01:05:48,920
ideeën. Ik denk na over wat je daar naar buiten brengt,

1617
01:05:48,920 --> 01:05:52,880
maar ik ja, ik zou moeten uitstellen tot

1618
01:05:52,880 --> 01:05:55,279
het papier.

1619
01:05:55,279 --> 01:05:57,200
Ik bedoel, hoe beschrijven ze wat is  terwijl ze worden

1620
01:05:57,200 --> 01:06:00,520
ontworpen, zeggen ze dat het

1621
01:06:00,520 --> 01:06:03,200
zoveel van dit soort componenten heeft en

1622
01:06:03,200 --> 01:06:05,720
dat doet misschien niets, dus hoe

1623
01:06:05,720 --> 01:06:08,079
beschrijven of evalueren ze deze

1624
01:06:08,079 --> 01:06:11,480
verschillende ontwerpen of

1625
01:06:11,640 --> 01:06:13,520
algoritmen. Ik denk dat het allemaal anders is,

1626
01:06:13,520 --> 01:06:14,799
afhankelijk van de gebruikscasus, alsof dat is

1627
01:06:14,799 --> 01:06:16,319
wat ik heb gevonden  echt leuk dat de taal

1628
01:06:16,319 --> 01:06:18,520
anders is, afhankelijk van of

1629
01:06:18,520 --> 01:06:20,440
het is geschreven door iemand met misschien

1630
01:06:20,440 --> 01:06:21,480
meer een neurowetenschappelijke of

1631
01:06:21,480 --> 01:06:23,799
technische achtergrond en toen

1632
01:06:23,799 --> 01:06:25,279
zei je dat sommige termen beter

1633
01:06:25,279 --> 01:06:26,920
uitwisselbaar zijn dan andere, maar ik

1634
01:06:26,920 --> 01:06:29,400
denk wel dat de terminologie dat is  iets waar

1635
01:06:29,400 --> 01:06:31,559


1636
01:06:31,559 --> 01:06:33,039
in de ruimte veel nauwkeuriger naar moet worden gekeken, want dan denk ik dat het

1637
01:06:33,039 --> 01:06:35,599
iedereen die erin werkt zal helpen om

1638
01:06:35,599 --> 01:06:38,799
op dezelfde pagina te komen, een beetje

1639
01:06:42,079 --> 01:06:44,359
dichterbij,

1640
01:06:44,359 --> 01:06:47,960
oké, alle andere gedachten of vragen

1641
01:06:47,960 --> 01:06:51,440
David eerst en dan Sarah ook ik'  Ik ben erg

1642
01:06:51,440 --> 01:06:55,480
benieuwd in welke richting deze serie zal

1643
01:06:55,480 --> 01:06:59,039
gaan, maar eerst David, wat zijn nog andere

1644
01:06:59,039 --> 01:07:02,119
slotopmerkingen of aanwijzingen die

1645
01:07:02,119 --> 01:07:03,359
je wilt

1646
01:07:03,359 --> 01:07:07,000
geven, niet echt, ik bedoel, ik bedoel,

1647
01:07:07,000 --> 01:07:09,480
bedankt dat je me vandaag had. Het

1648
01:07:09,480 --> 01:07:11,279
was echt een genoegen om mee te praten

1649
01:07:11,279 --> 01:07:13,359


1650
01:07:13,359 --> 01:07:15,720
bedankt David, het was geweldig om

1651
01:07:15,720 --> 01:07:17,000
je erbij te hebben. Ik vind je werk

1652
01:07:17,000 --> 01:07:19,079
absoluut fascinerend en ik denk dat het

1653
01:07:19,079 --> 01:07:20,880
in de toekomst veel voordelen zal hebben

1654
01:07:20,880 --> 01:07:23,400
voor de implementatie, wat

1655
01:07:23,400 --> 01:07:26,559
ook altijd leuk is om te zien, eh ja, dus

1656
01:07:26,559 --> 01:07:27,760
wat was de vraag waar waar  zie ik

1657
01:07:27,760 --> 01:07:30,279
de serie gaan, hopelijk kunnen we

1658
01:07:30,279 --> 01:07:33,720
elke maand een nieuwe gast hebben, ik denk dat

1659
01:07:33,720 --> 01:07:36,240
het best cool zou zijn, misschien volgende maand om

1660
01:07:36,240 --> 01:07:38,680
iemand te hebben die

1661
01:07:38,680 --> 01:07:40,319
hardware bouwt, bijvoorbeeld iemand van het

1662
01:07:40,319 --> 01:07:42,079
Brain Scales-team of het Spica-team  of

1663
01:07:42,079 --> 01:07:44,279
iets dergelijks zou best cool zijn,

1664
01:07:44,279 --> 01:07:46,880
maar ja, eigenlijk wil ik gewoon een

1665
01:07:46,880 --> 01:07:49,119
ruimte hebben voor mensen die geïnteresseerd zijn in

1666
01:07:49,119 --> 01:07:52,359
dit kruispunt om mensen te ontmoeten die

1667
01:07:52,359 --> 01:07:54,079
en gesprekken zien en je kent Reach Out-

1668
01:07:54,079 --> 01:07:56,520
mensen die ook in de ruimte werken,

1669
01:07:56,520 --> 01:07:59,319
omdat eh  het is behoorlijk niche, maar ik denk dat

1670
01:07:59,319 --> 01:08:01,920
het behoorlijk belangrijk is, eigenlijk heb ik

1671
01:08:01,920 --> 01:08:03,400
gezegd dat David, kun je iedereen laten

1672
01:08:03,400 --> 01:08:05,039
weten of ze contact met je willen opnemen,

1673
01:08:05,039 --> 01:08:08,359
wat de beste manier voor hen is om dat te doen

1674
01:08:08,359 --> 01:08:09,390


1675
01:08:09,390 --> 01:08:11,400
[Muziek],

1676
01:08:11,400 --> 01:08:13,960
ik ben hier niet erg actief mee  Discord-

1677
01:08:13,960 --> 01:08:16,399
kanaal, dus misschien is e-mail nog steeds het beste om contact

1678
01:08:16,399 --> 01:08:19,158
met mij op te nemen. Ik

1679
01:08:19,158 --> 01:08:21,399
denk dat het cool is, wil je je

1680
01:08:21,399 --> 01:08:22,839
e-mailadres geven,

1681
01:08:22,839 --> 01:08:27,560
oh ik denk dat mijn e-mailadres gemakkelijk genoeg moet zijn

1682
01:08:27,560 --> 01:08:28,960
om te vinden, maar je kunt de

1683
01:08:28,960 --> 01:08:30,600
e-mail ook daar krijgen,

1684
01:08:30,600 --> 01:08:33,439
korte mensen kunnen het controleren  de papieren en

1685
01:08:33,439 --> 01:08:36,000
dan in het actieve gevolgtrekking Instituut

1686
01:08:36,000 --> 01:08:40,080
Discord is er het neuromorfe

1687
01:08:41,120 --> 01:08:43,719
kanaal oké bedankt David en

1688
01:08:43,719 --> 01:08:47,198
Sarah echt gaaf om te zien dat morph stream

1689
01:08:47,198 --> 01:08:49,158
zijn ontwikkelingstraject op

1690
01:08:49,158 --> 01:08:52,799
deze manier begint, dus tot de volgende keer dank je wel

1691
01:08:52,799 --> 01:08:54,109


1692
01:08:54,109 --> 01:08:57,169
[Muziek]

1693
01:09:19,040 --> 01:09:22,040
prima

