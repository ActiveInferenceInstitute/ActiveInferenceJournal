1
00:00:07,040 --> 00:00:10,320
皆さん、こんにちは。2023 年 9 月 26 日です。

2
00:00:10,320 --> 00:00:12,080


3
00:00:12,080 --> 00:00:15,120


4
00:00:15,120 --> 00:00:17,119
アクティブ推論研究所で新しいストリーム シリーズを開始します。

5
00:00:17,119 --> 00:00:20,400
これはモーフ ストリーム

6
00:00:20,400 --> 00:00:24,800
1.1 です。今日は David kapple が参加します。また、

7
00:00:24,800 --> 00:00:27,960
このセクションとストリームは

8
00:00:27,960 --> 00:00:31,320
Sarah Hamburg が進行役を務めます。

9
00:00:31,320 --> 00:00:35,440
最初にサラが概要を提示し、その後

10
00:00:35,440 --> 00:00:38,040
デイビッドが

11
00:00:38,040 --> 00:00:40,520
ニューロモーフィック コンピューティングに関する研究を共有し、その後

12
00:00:40,520 --> 00:00:42,879
ディスカッションする時間があります。最初のプレゼンテーションに

13
00:00:42,879 --> 00:00:45,480
参加してくれたサラと二人に感謝します。

14
00:00:45,480 --> 00:00:47,360
また、

15
00:00:47,360 --> 00:00:49,600
よかったら自己紹介もしてください。

16
00:00:49,600 --> 00:00:51,000
良いアイデアですね、ありがとうございます

17
00:00:51,000 --> 00:00:54,120
ダニエル ええと、私の名前はサラです ええと、私は

18
00:00:54,120 --> 00:00:56,120


19
00:00:56,120 --> 00:00:57,280
現在

20
00:00:57,280 --> 00:01:00,280
ニューロモーフィック コンピューティングの分野で知能を専門とする神経科学者で、ええと

21
00:01:00,280 --> 00:01:02,480
英国のシェフ フィールド ハルで働いています。

22
00:01:02,480 --> 00:01:04,400
ニューロモーフィック

23
00:01:04,400 --> 00:01:06,720
コンピューティングとは何かについて説明し、この新しいシリーズの

24
00:01:06,720 --> 00:01:08,640
第 1 版でデイビッドのエキサイティングな話を聞く前に、

25
00:01:08,640 --> 00:01:11,320
ええと、

26
00:01:11,320 --> 00:01:12,799
今後 2 倍の時間で視聴する方にお知らせしたいのですが、

27
00:01:12,799 --> 00:01:14,320
私はかなり早口で話しているので、

28
00:01:14,320 --> 00:01:17,080
私を 2 倍の時間で視聴したくないかもしれません。 時間が倍になったので、

29
00:01:17,080 --> 00:01:19,400
ここに置いたこの QR コードは、この

30
00:01:19,400 --> 00:01:20,880


31
00:01:20,880 --> 00:01:23,520
分野への本当に素晴らしい入門書だと思った論文に移動します。えっと、

32
00:01:23,520 --> 00:01:25,520
neic コンピューティングは、神経系

33
00:01:25,520 --> 00:01:27,000


34
00:01:27,000 --> 00:01:28,680
の構造と機能を模倣するように設計されたコンピューティング システムとして定義できます。

35
00:01:28,680 --> 00:01:30,720
つまり、これは

36
00:01:30,720 --> 00:01:32,680
人間の神経系である必要はありません この分野は

37
00:01:32,680 --> 00:01:34,320
実際にあらゆる種類の動物や昆虫からインスピレーションを得ています うーん、

38
00:01:34,320 --> 00:01:36,640


39
00:01:36,640 --> 00:01:38,159
オンラインの定義は必ずしもそれを

40
00:01:38,159 --> 00:01:40,680
認めているわけではありません そのため、ニューロモーフィックとは何かについて

41
00:01:40,680 --> 00:01:42,200
非常にオープンな人もいれば、それを

42
00:01:42,200 --> 00:01:43,920


43
00:01:43,920 --> 00:01:46,119
好む人もいるかもしれません ニューロモーフィックは、

44
00:01:46,119 --> 00:01:48,600


45
00:01:48,600 --> 00:01:50,520


46
00:01:50,520 --> 00:01:53,280
非実行コンピューターとも呼ばれる、生物学的ニューロンのハードウェア インスタンス化のために予約されていました。QR

47
00:01:53,280 --> 00:01:55,280


48
00:01:55,280 --> 00:01:58,320
コードで

49
00:01:58,320 --> 00:02:00,280
定義として言及される論文では、これが定義として使われていると思います。非常に

50
00:02:00,280 --> 00:02:01,200
興味深いと思います。 これはコンテキストの一部な

51
00:02:01,200 --> 00:02:02,920
ので、現在の vuman コンピューター アーキテクチャと同様に、

52
00:02:02,920 --> 00:02:04,479


53
00:02:04,479 --> 00:02:06,439
神経科学、特に

54
00:02:06,439 --> 00:02:08,840
マルとピットの 43 ニューロン モデルに触発され、

55
00:02:08,840 --> 00:02:12,080
1945 年にフォン y の最初の草案に影響を与えたので、

56
00:02:12,080 --> 00:02:14,120
神経科学にはコンピューター サイエンスにインスピレーションを与えてきた長い歴史があり

57
00:02:14,120 --> 00:02:16,120
、これもまた これには、

58
00:02:16,120 --> 00:02:17,680


59
00:02:17,680 --> 00:02:19,440


60
00:02:19,440 --> 00:02:20,720


61
00:02:20,720 --> 00:02:22,480
報酬と罰に基づいた行動心理学からの学習意思決定に関する理論に基づいた強化学習が含まれます。

62
00:02:22,480 --> 00:02:24,760
また、

63
00:02:24,760 --> 00:02:26,519


64
00:02:26,519 --> 00:02:29,239
49 からの 49 番の細胞が互いに発火する平安学習原理が教師なし学習の基礎となった

65
00:02:29,239 --> 00:02:31,680


66
00:02:31,680 --> 00:02:34,959
ので、まず最初に 1 秒お待ちください

67
00:02:34,959 --> 00:02:37,640
それで、

68
00:02:37,640 --> 00:02:39,440
ニューロモーフィック コンピューティングの理由を理解するために、

69
00:02:39,440 --> 00:02:40,959


70
00:02:40,959 --> 00:02:44,120
脳の何がそんなに優れているのかを説明したかったので、電球のインスピレーションを得たので

71
00:02:44,120 --> 00:02:46,360
質問します。

72
00:02:46,360 --> 00:02:47,280
少し考えてもらいたいのですが、

73
00:02:47,280 --> 00:02:49,159
2番目は

74
00:02:49,159 --> 00:02:51,239
電球のことで、脳はどのくらいのエネルギーを

75
00:02:51,239 --> 00:02:53,879
使っていると思いますか? あなたが未来にいるとしたら、それはあなたがいる部屋を照らす電球よりも多いか少ないと思いますか?

76
00:02:53,879 --> 00:02:56,280


77
00:02:56,280 --> 00:02:58,040


78
00:02:58,040 --> 00:02:59,560
ぜひPA、これを一時停止してください。

79
00:02:59,560 --> 00:03:01,200
詳しい

80
00:03:01,200 --> 00:03:02,760
計算をしたいのですが、答えまで飛ばします。

81
00:03:02,760 --> 00:03:06,680
答えは

82
00:03:06,680 --> 00:03:10,159
ピンクの丸の中にあります。つまり、20 ワットです。つまり、

83
00:03:10,159 --> 00:03:12,200
現代のエネルギー効率の高い電球 1 個に相当します。

84
00:03:12,200 --> 00:03:14,519
つまり、これが

85
00:03:14,519 --> 00:03:16,280
今私が考えている以上のことでしょう。 基本的にここの私の部屋にあるのですが、

86
00:03:16,280 --> 00:03:18,840
この QR コードを読むと、脳の消費

87
00:03:18,840 --> 00:03:20,040
電力に関する非常に興味深い論文にアクセスできるはずです。

88
00:03:20,040 --> 00:03:21,239


89
00:03:21,239 --> 00:03:23,080
興味があれば、

90
00:03:23,080 --> 00:03:25,360


91
00:03:25,360 --> 00:03:28,519
脳に電力を供給するには 1 日に約 4 本のバナナを摂取することになります。

92
00:03:28,519 --> 00:03:30,760
ちなみに、これは次のように計算されます。

93
00:03:30,760 --> 00:03:32,840
脳が必要とするカロリー摂取量に基づいているので、文脈的には

94
00:03:32,840 --> 00:03:35,200


95
00:03:35,200 --> 00:03:36,720
ヨーロッパ最速のスーパーコンピューターだと思いますが、フィンランドでは Lumi と呼ばれています。

96
00:03:36,720 --> 00:03:38,560
えっと、

97
00:03:38,560 --> 00:03:40,560
例外的にグリーンと呼ばれています。消費電力は

98
00:03:40,560 --> 00:03:43,640
850 万ワットな

99
00:03:43,640 --> 00:03:45,840
ので、脳がよく使う電球は約 50 万個に相当します。

100
00:03:45,840 --> 00:03:48,840
1 つだけ それで

101
00:03:48,840 --> 00:03:49,879
問題は、あなたの

102
00:03:49,879 --> 00:03:52,280
脳がその 1 つの電球や

103
00:03:52,280 --> 00:03:54,200
4 本の

104
00:03:54,200 --> 00:03:57,599
バナナを使って何をしているかということです どうやら脳は 1 秒あたり 1 兆回の

105
00:03:57,599 --> 00:04:00,120
計算を行っているようです、だから他にも

106
00:04:00,120 --> 00:04:01,879
膨大な推定値がたくさんあります、

107
00:04:01,879 --> 00:04:03,599
えー、これは数桁も最大ではありませんでした

108
00:04:03,599 --> 00:04:05,840
規模の推定値は

109
00:04:05,840 --> 00:04:07,799
明らかに非常に推測的なものですが、

110
00:04:07,799 --> 00:04:09,519
それらはすべて大規模であり、

111
00:04:09,519 --> 00:04:11,280
ニューロンの

112
00:04:11,280 --> 00:04:13,840
接続数と発火率に基づいている傾向がありますが、

113
00:04:13,840 --> 00:04:14,879


114
00:04:14,879 --> 00:04:17,040
スーパーコンピューターが実際には

115
00:04:17,040 --> 00:04:18,880
まだあなたに匹敵することができないという状況では非常に重要だと思います 私たちの

116
00:04:18,880 --> 00:04:20,880
スキルの複雑さ、

117
00:04:20,880 --> 00:04:23,400
つまり人間の脳の適応力を知っているので、

118
00:04:23,400 --> 00:04:25,520


119
00:04:25,520 --> 00:04:26,960
複雑な

120
00:04:26,960 --> 00:04:29,120
意思決定や経験からの学習などに関しては、実際に私たちはスーパーコンピューターをはるかに超えています。では、

121
00:04:29,120 --> 00:04:31,520


122
00:04:31,520 --> 00:04:34,039
あなたの脳は AI とどのように比較されますか?

123
00:04:34,039 --> 00:04:36,039
それで、現代の AI は すでに

124
00:04:36,039 --> 00:04:38,199
脳にインスピレーションを得ていますが、人工

125
00:04:38,199 --> 00:04:41,240
ニューロンは非常に単純化されていますが、

126
00:04:41,240 --> 00:04:42,600


127
00:04:42,600 --> 00:04:44,320
生物学的ニューロンやネットワークの複雑さはまったく理解されていません。

128
00:04:44,320 --> 00:04:47,240
個々のニューロンは

129
00:04:47,240 --> 00:04:49,520
実際にはネットワークそのものに似ており、

130
00:04:49,520 --> 00:04:51,120
1 つの生物学的ニューロンをモデル化するには 5 つのプロセスが必要であることが研究で示唆されています。

131
00:04:51,120 --> 00:04:53,039


132
00:04:53,039 --> 00:04:55,240
8 層の深層人工ニューロン

133
00:04:55,240 --> 00:04:57,080
ネットワークは約 1,000 個の

134
00:04:57,080 --> 00:04:59,160
人工ニューロンで構成されています。この QR コードを読むと

135
00:04:59,160 --> 00:05:02,160
論文が表示されます。

136
00:05:02,160 --> 00:05:04,919
脳には 860 億個のニューロンがあり、

137
00:05:04,919 --> 00:05:07,120
これらが連携して、

138
00:05:07,120 --> 00:05:09,160


139
00:05:09,160 --> 00:05:11,560
そのすぐ上で動作する高エネルギー効率の低遅延スーパーコンピューターを形成します。 室温は 1

140
00:05:11,560 --> 00:05:13,759


141
00:05:13,759 --> 00:05:16,440
日あたり約 4 本のバナナに相当するので、

142
00:05:16,440 --> 00:05:17,680


143
00:05:17,680 --> 00:05:19,720
あなたがまだそれを知らなかったかのように、あなたの脳がどれほど素晴らしいかを感じていただければ幸いです、

144
00:05:19,720 --> 00:05:21,960
そしてそれがすでに

145
00:05:21,960 --> 00:05:24,039
かなり基本的な AI を刺激するためにどのように使用されているか

146
00:05:24,039 --> 00:05:25,560
人間の

147
00:05:25,560 --> 00:05:27,360
知能と比較したので、次に、ニューロモーフィック コンピューティングの分野を通じて次世代の AI とテクノロジーを促進するために、

148
00:05:27,360 --> 00:05:29,000
脳の主要な機能がどのように

149
00:05:29,000 --> 00:05:31,319
実装されているかを説明します。

150
00:05:31,319 --> 00:05:33,720


151
00:05:33,720 --> 00:05:35,080


152
00:05:35,080 --> 00:05:37,680
それが、皆さんがここに集まっている理由です。

153
00:05:37,680 --> 00:05:39,960
vum とコンピュータには

154
00:05:39,960 --> 00:05:42,039
物理的に分離されたコンピューティング ユニットとメモリ

155
00:05:42,039 --> 00:05:45,039
ユニットがあり、ここの左側に示されています。えー、

156
00:05:45,039 --> 00:05:47,280
計算中はデータを非常に高速に前後に転送する必要がある

157
00:05:47,280 --> 00:05:49,000
ため、

158
00:05:49,000 --> 00:05:51,600
本質的に速度とエネルギーにボトルネックがあります。

159
00:05:51,600 --> 00:05:53,840
一方、

160
00:05:53,840 --> 00:05:55,160
ここの右側に示されているニューロモーフィック アーキテクチャ

161
00:05:55,160 --> 00:05:57,400
では、  Dary Computing の助け

162
00:05:57,400 --> 00:05:59,639
とメモリは同じ場所で発生する

163
00:05:59,639 --> 00:06:01,840
ため、それらは

164
00:06:01,840 --> 00:06:03,880
併置されていると言われており、基本的に個々の

165
00:06:03,880 --> 00:06:06,080
ニューロンが計算を実行する一方、

166
00:06:06,080 --> 00:06:07,759
記憶は接続の強さ、

167
00:06:07,759 --> 00:06:09,720


168
00:06:09,720 --> 00:06:13,000
ニューロン間の重みで表されるため、雑木林が形成されるため、このようなチップは

169
00:06:13,000 --> 00:06:15,440
コンポーネントで作成される可能性があります。 たとえば、

170
00:06:15,440 --> 00:06:17,919


171
00:06:17,919 --> 00:06:20,840
シナプスの重みをエミュレートできるミスタのように、このアーキテクチャは

172
00:06:20,840 --> 00:06:22,960
速度を向上させ、エネルギー消費を削減します。

173
00:06:22,960 --> 00:06:24,520
そして本当に

174
00:06:24,520 --> 00:06:26,319
興味深いのは、大規模な

175
00:06:26,319 --> 00:06:28,240
並列処理が可能になることです。つまり、

176
00:06:28,240 --> 00:06:30,080
複数の問題に同時に取り組むことができるため、

177
00:06:30,080 --> 00:06:32,720


178
00:06:32,720 --> 00:06:34,680
このアーキテクチャはさまざまな用途に特に重要です。

179
00:06:34,680 --> 00:06:37,039
それはまた、

180
00:06:37,039 --> 00:06:39,199
Moos log の終わりに達するにつれて、

181
00:06:39,199 --> 00:06:41,520
物理的に

182
00:06:41,520 --> 00:06:44,599
チップに適合するようにどんどん小さくできるトランジスタの数が決まり、

183
00:06:44,599 --> 00:06:46,759
人類は

184
00:06:46,759 --> 00:06:48,560
エネルギー消費を大幅に削減する必要があるからでもあります。

185
00:06:48,560 --> 00:06:51,520


186
00:06:51,520 --> 00:06:54,400
ますます強力な

187
00:06:54,400 --> 00:06:57,280
AI なので、人工ニューロンは通常、

188
00:06:57,280 --> 00:06:59,560


189
00:06:59,560 --> 00:07:01,599
左側に示されている連続活性化を使用します。常にオンになっていますが、

190
00:07:01,599 --> 00:07:03,560
ニューロモーフィック ニューロンは

191
00:07:03,560 --> 00:07:05,720
スパイクしていると言われているため、右側に示されているようにオンまたはオフになっています。

192
00:07:05,720 --> 00:07:07,440


193
00:07:07,440 --> 00:07:09,759


194
00:07:09,759 --> 00:07:12,000
これによる利点は、やはり電力

195
00:07:12,000 --> 00:07:14,160
効率です。また、

196
00:07:14,160 --> 00:07:16,319
タイミングが重要なアプリケーションでもあり、

197
00:07:16,319 --> 00:07:18,720
イベント駆動型であるため

198
00:07:18,720 --> 00:07:21,160
本質的に

199
00:07:21,160 --> 00:07:23,759
空間的および時間的次元の可能性があり、追加の時

200
00:07:23,759 --> 00:07:25,759
空間エンコーディングが可能になります。

201
00:07:25,759 --> 00:07:28,479
情報の処理

202
00:07:28,479 --> 00:07:30,680
ええと、GPU について少し疑問に思っているかもしれませんが、

203
00:07:30,680 --> 00:07:33,240
並列処理も可能にします ええと、

204
00:07:33,240 --> 00:07:35,080
調査によると、GPU は

205
00:07:35,080 --> 00:07:37,319


206
00:07:37,319 --> 00:07:39,599
ネットワークをスパイクする展開に適したアーキテクチャであることが示唆されています ええと、ハイエンド GPU の普及状況を考えると、

207
00:07:39,599 --> 00:07:41,280
この分野にとっては非常に興味深い時期になっていると思います

208
00:07:41,280 --> 00:07:43,199


209
00:07:43,199 --> 00:07:46,159


210
00:07:46,159 --> 00:07:49,479
脳は

211
00:07:49,479 --> 00:07:51,599
ニューロン間のシナプシスの強さを学習するため、これは

212
00:07:51,599 --> 00:07:53,560
シナプス発火前後の

213
00:07:53,560 --> 00:07:55,240
パターンに基づいています。 David の講演では多くのことが語られると思います。

214
00:07:55,240 --> 00:07:57,680


215
00:07:57,680 --> 00:07:59,319
これについてはさらに詳しく説明しますが、多くの異なるタイプの

216
00:07:59,319 --> 00:08:01,240
タイプがあり、

217
00:08:01,240 --> 00:08:03,720
脳全体のパターンは、興奮性から抑制性などのシナプスの種類に応じて異なります。

218
00:08:03,720 --> 00:08:05,599


219
00:08:05,599 --> 00:08:06,919


220
00:08:06,919 --> 00:08:09,159
ニューロム市場

221
00:08:09,159 --> 00:08:11,639
分野では、

222
00:08:11,639 --> 00:08:13,800
オンチップ

223
00:08:13,800 --> 00:08:16,159
学習や

224
00:08:16,159 --> 00:08:18,039
パターン認識やエッジ コンピューティングなどのアプリケーションに利点があるため、これらのルールを活用することに取り組んでいます。

225
00:08:18,039 --> 00:08:19,599
また、エッジ コンピューティングは、

226
00:08:19,599 --> 00:08:21,680


227
00:08:21,680 --> 00:08:23,000
一種のイベント駆動型の

228
00:08:23,000 --> 00:08:26,240
性質と低エネルギー使用量により、ニューロモーフィック コンピューティングの非常に巨大なユース ケースです。

229
00:08:26,240 --> 00:08:27,879
この QR コードは、私が見つけた stdp に関する非常に興味深い論文に移動するはずです。

230
00:08:27,879 --> 00:08:31,839


231
00:08:31,839 --> 00:08:34,799
つまり、ニューロモーフィック ソリューションとは何ですか

232
00:08:34,799 --> 00:08:36,159
現在利用可能ですが、それは

233
00:08:36,159 --> 00:08:38,320
理論上のものだと思っているかもしれません。実際には

234
00:08:38,320 --> 00:08:40,200
さまざまなソリューションがたくさんあります。その概要を

235
00:08:40,200 --> 00:08:41,559
簡単に説明します。

236
00:08:41,559 --> 00:08:44,120
そのため、人間の脳プロジェクトは、

237
00:08:44,120 --> 00:08:45,760


238
00:08:45,760 --> 00:08:48,120


239
00:08:48,120 --> 00:08:49,800
これを含むいくつかの大規模なニューロモーフィック コンピューターを作成しました。 このボードの一番下は、

240
00:08:49,800 --> 00:08:51,560


241
00:08:51,560 --> 00:08:53,480
私の顔の大きさか何かが分からないようなもので、

242
00:08:53,480 --> 00:08:55,760
リアルタイムで実行されます。ええと、それはマイクロプロセッサ上の複数の汎用で構成されており、

243
00:08:55,760 --> 00:08:58,200


244
00:08:58,200 --> 00:09:00,279


245
00:09:00,279 --> 00:09:03,120
加速されたアナログ

246
00:09:03,120 --> 00:09:05,399
アーキテクチャである脳スケールもあり、それが実行されます

247
00:09:05,399 --> 00:09:09,240
リアルタイムで1000回です。それで、青いボードの隣にあるボードは、

248
00:09:09,240 --> 00:09:11,120
実際のクレジット

249
00:09:11,120 --> 00:09:13,240
カードサイズです。彼らが最近作った脳スケールのバージョンです。

250
00:09:13,240 --> 00:09:14,399


251
00:09:14,399 --> 00:09:16,920
とてもクールだと思いました。そして、

252
00:09:16,920 --> 00:09:18,399


253
00:09:18,399 --> 00:09:21,000
この分野には大手企業もいます。 この青いのは Intel の

254
00:09:21,000 --> 00:09:23,640
Loi チップで、現在 lii 2 に取り組んでいます。これが

255
00:09:23,640 --> 00:09:25,480
ニューロモーフィック チップで、

256
00:09:25,480 --> 00:09:27,000
そのためのオープンソース ソフトウェア フレームワークも持っています。

257
00:09:27,000 --> 00:09:27,920
なぜなら、彼らは

258
00:09:27,920 --> 00:09:29,480
オープン ソース キー コミュニティを促進して、

259
00:09:29,480 --> 00:09:32,079
ニューロモーフィックなそれに関与することを本当に望んでいるからです。

260
00:09:32,079 --> 00:09:34,040
センサーも存在するので、中央にあるこの小さな青い

261
00:09:34,040 --> 00:09:35,000
ものは、実際には

262
00:09:35,000 --> 00:09:36,800
ニューロモーフィック カメラです。おそらくこの

263
00:09:36,800 --> 00:09:40,040
大きなものに似ています。彼らは、私たちの神経系が光などの刺激をどのように感じるかを再現することを目的としています。

264
00:09:40,040 --> 00:09:42,480


265
00:09:42,480 --> 00:09:44,880
たとえば、

266
00:09:44,880 --> 00:09:47,200
ここにある各ピクセルのニューロモーフィック カメラでは、

267
00:09:47,200 --> 00:09:49,560
マイクロ解像度で独立して動作します、

268
00:09:49,560 --> 00:09:52,120
私のGIFが動作するといいのです

269
00:09:52,120 --> 00:09:54,440
が、それでは各ピクセルが

270
00:09:54,440 --> 00:09:56,680
そこで動作しているのがわかります。これは非常にクールなので、

271
00:09:56,680 --> 00:09:58,760
従来のデジタルカメラと比較して、

272
00:09:58,760 --> 00:10:00,120


273
00:10:00,120 --> 00:10:02,920
動きのあるパフォーマンスが向上し、消費電力が低くなりました。

274
00:10:02,920 --> 00:10:05,120
最近はニューロモーフィックな鼻もありました

275
00:10:05,120 --> 00:10:07,079
Intel のこれはかなりクールで、

276
00:10:07,079 --> 00:10:08,440
化学薬品の匂いを

277
00:10:08,440 --> 00:10:10,959
1 回暴露しただけで学習できるようになり、

278
00:10:10,959 --> 00:10:12,480


279
00:10:12,480 --> 00:10:15,279
他の人に隠されている場合でもその匂いを識別できるようになりました。そして最後に、

280
00:10:15,279 --> 00:10:17,959
これは iub と呼ばれる人型ロボットです。

281
00:10:17,959 --> 00:10:19,240
実際に、カメラなど

282
00:10:19,240 --> 00:10:21,200
のニューロモーフィック センサー

283
00:10:21,200 --> 00:10:24,000
と、

284
00:10:24,000 --> 00:10:27,000
スパやブレイン スケールなどのニューロモーフィック チップを、

285
00:10:27,000 --> 00:10:28,440
このような人型デバイスやドローンなどの他のデバイスに統合できます。

286
00:10:28,440 --> 00:10:30,560
そして、そこから

287
00:10:30,560 --> 00:10:31,839
実際に身体化された

288
00:10:31,839 --> 00:10:34,200
ニューロモーフィック システムを作成できます。これは、

289
00:10:34,200 --> 00:10:35,839
私たちは英国のシェフィールドにあるスマート インタラクティブ テクノロジー研究所で研究に取り組んでいます。

290
00:10:35,839 --> 00:10:37,519


291
00:10:37,519 --> 00:10:40,320


292
00:10:40,480 --> 00:10:42,600
このスライドは、ニューロモーフィック コンピューティングの潜在的な応用例のいくつかを強調しているだけです。これについて

293
00:10:42,600 --> 00:10:43,959


294
00:10:43,959 --> 00:10:45,480


295
00:10:45,480 --> 00:10:46,720
考えると非常に興味深いと思いました。つまり、

296
00:10:46,720 --> 00:10:49,120
コンテキスト

297
00:10:49,120 --> 00:10:51,560
パターン認識の理解、高度なセンシング、数

298
00:10:51,560 --> 00:10:54,360
ショット学習 タスク全体の一般化

299
00:10:54,360 --> 00:10:56,839
複雑な意思決定の説明可能性

300
00:10:56,839 --> 00:10:59,519
と脳のインターフェース えーっと、これらすべての

301
00:10:59,519 --> 00:11:01,360
スキルは、動的環境における人間中心のリアルタイム アプリケーションについて考えるときに非常に有益です。

302
00:11:01,360 --> 00:11:03,399


303
00:11:03,399 --> 00:11:06,240


304
00:11:06,240 --> 00:11:07,839
たとえば、自動運転車など、

305
00:11:07,839 --> 00:11:10,000
個人的には

306
00:11:10,000 --> 00:11:12,800
ニューロモーフィック システムだと思います。 これは

307
00:11:12,800 --> 00:11:14,360
将来の脳内コンピュータインターフェースの基板になる可能性も高いです。

308
00:11:14,360 --> 00:11:16,000


309
00:11:16,000 --> 00:11:17,959
私は神経科学者なので少し偏見があるかもしれませんが、

310
00:11:17,959 --> 00:11:19,959
うーん、それらは低エネルギーでリアルタイムであり、私たち

311
00:11:19,959 --> 00:11:22,000


312
00:11:22,000 --> 00:11:24,839
自身のハードウェアに適合するアーキテクチャも備えているので、私たちはそうだと思います

313
00:11:24,839 --> 00:11:26,560
。  BCI 分野は、おそらく

314
00:11:26,560 --> 00:11:28,680


315
00:11:28,680 --> 00:11:29,480


316
00:11:29,480 --> 00:11:31,360
ハードウェアと

317
00:11:31,360 --> 00:11:33,680
ウェットウェアのハイブリッドに特化したニューロモーフィック システムによって触媒されていることがすぐにわかります。そのため、潜在的に

318
00:11:33,680 --> 00:11:35,800
人々自身の

319
00:11:35,800 --> 00:11:37,399
脳細胞も含まれる可能性さえあります。ご存知のように、有毛細胞から実際に成長させることができる脳細胞であり

320
00:11:37,399 --> 00:11:40,160


321
00:11:40,360 --> 00:11:43,040
、私たちの研究の特に焦点

322
00:11:43,040 --> 00:11:45,160
は

323
00:11:45,160 --> 00:11:47,120
人間と同じような方法で学習する AI を設計することで、

324
00:11:47,120 --> 00:11:48,959
生来の好奇心を持ち、

325
00:11:48,959 --> 00:11:51,560
現実世界との対話を通じて学習するため、

326
00:11:51,560 --> 00:11:53,959
50 年代にアラン チューリングは、

327
00:11:53,959 --> 00:11:56,079


328
00:11:56,079 --> 00:11:58,519
大人の心をシミュレートするプログラムを作成しようとする代わりに、むしろそうすべきではないかと述べました。

329
00:11:58,519 --> 00:12:00,360


330
00:12:00,360 --> 00:12:02,760
子供の脳を刺激するものを作成してみてください。これが

331
00:12:02,760 --> 00:12:04,560
適切な教育課程の対象であれば、

332
00:12:04,560 --> 00:12:07,480
大人の脳を獲得するでしょう。これは

333
00:12:07,480 --> 00:12:09,360
まさに、

334
00:12:09,360 --> 00:12:12,320
Ai と

335
00:12:12,320 --> 00:12:13,800
ニューロモーフィック コンピューティングへの神経発達的アプローチの背後にある哲学であり、私は

336
00:12:13,800 --> 00:12:15,800


337
00:12:15,800 --> 00:12:17,839
そこで強調したいと思っていました。

338
00:12:17,839 --> 00:12:19,839
現場でのいくつかの課題は非常に高レベルです

339
00:12:19,839 --> 00:12:20,880
が、その概要を少しだけ説明します。その

340
00:12:20,880 --> 00:12:23,760
ため、スパイキング ニューラル ネットワークのトレーニングは、

341
00:12:23,760 --> 00:12:25,079


342
00:12:25,079 --> 00:12:27,199
従来のニューラル ネットワークよりも複雑です。また、

343
00:12:27,199 --> 00:12:28,560
実際に

344
00:12:28,560 --> 00:12:31,079
スパイク ニューラル ネットワークの stdp を実装するハードウェアの設計も必要です。

345
00:12:31,079 --> 00:12:33,120
大規模なものはかなり

346
00:12:33,120 --> 00:12:35,120
難しいと言われていますが、ハードウェアや標準技術などのテクノロジーを

347
00:12:35,120 --> 00:12:36,480
実際に

348
00:12:36,480 --> 00:12:38,959
効果的に活用できるアルゴリズムの開発も行われています。これは現在進行

349
00:12:38,959 --> 00:12:41,440


350
00:12:41,440 --> 00:12:45,399
中の活発な

351
00:12:45,399 --> 00:12:48,760
研究分野です。ここにいる人は、

352
00:12:48,760 --> 00:12:50,959
おそらく能動推論に興味があるでしょう。

353
00:12:50,959 --> 00:12:52,560
これを強調したいのですが、

354
00:12:52,560 --> 00:12:53,839
今日誰かが Discord にこれらの研究の 1 つを投稿しました。これは

355
00:12:53,839 --> 00:12:55,839
非常に素晴らしいもので、

356
00:12:55,839 --> 00:12:58,040
最近の研究の 2 つは

357
00:12:58,040 --> 00:12:59,560
ニューロモーフィック コンピューティングと

358
00:12:59,560 --> 00:13:01,720
能動推論の原理を組み合わせたもので、能動

359
00:13:01,720 --> 00:13:03,720
推論は神経科学から来ており、

360
00:13:03,720 --> 00:13:05,040
それが役立つと私は主張します。

361
00:13:05,040 --> 00:13:06,600
ニューロモーフィック アーキテクチャについては非常によく知られています。えー、

362
00:13:06,600 --> 00:13:08,760


363
00:13:08,760 --> 00:13:10,680
身体化されたニューロモーフィック インテリジェンスに関する最近の論文では、

364
00:13:10,680 --> 00:13:12,320
能動的推論についてはあまり言及されていませんでした。

365
00:13:12,320 --> 00:13:14,279
右上の QR コードを参照してください。

366
00:13:14,279 --> 00:13:16,279
えー、

367
00:13:16,279 --> 00:13:18,079
ニューロモーフィックにおける真のブレークスルーは、

368
00:13:18,079 --> 00:13:19,959
全体が実現されれば起こるだろうと示唆されていました。 システム設計は

369
00:13:19,959 --> 00:13:21,839
生物学的計算原理に基づいており、

370
00:13:21,839 --> 00:13:23,800


371
00:13:23,800 --> 00:13:25,199


372
00:13:25,199 --> 00:13:27,360
環境の推定とロボット自身の状態、

373
00:13:27,360 --> 00:13:30,240
意思決定の計画と行動の間の緊密な関係を備えている

374
00:13:30,240 --> 00:13:31,600
ため、これらのテーマのいくつかは、能動的な推論や U に

375
00:13:31,600 --> 00:13:32,839
興味がある人々には非常に馴染みのあるものに聞こえるかもしれません。

376
00:13:32,839 --> 00:13:35,199


377
00:13:35,199 --> 00:13:36,959
推論は

378
00:13:36,959 --> 00:13:39,160
これらの要件を満たすのに適した位置にあり、

379
00:13:39,160 --> 00:13:40,600


380
00:13:40,600 --> 00:13:43,079
ここでいくつかの最近の研究を強調したいと思います。左側の

381
00:13:43,079 --> 00:13:45,000
ガンダル FAL は最近、能動的推論原理を

382
00:13:45,000 --> 00:13:47,519


383
00:13:47,519 --> 00:13:50,240
使用したニューロモーフィック システムにおける可塑性と急速な教師なし学習を実証しました。

384
00:13:50,240 --> 00:13:52,560
著者は、

385
00:13:52,560 --> 00:13:53,800
彼らの実験が可能であることを示唆しました。 ニューロ・ニューロ・

386
00:13:53,800 --> 00:13:55,560


387
00:13:55,560 --> 00:13:58,759
モーフィック・ロボット・システムに脳のような予測機能を実装するために採用され

388
00:13:58,759 --> 00:14:01,480
、その後、

389
00:14:01,480 --> 00:14:03,000


390
00:14:03,000 --> 00:14:05,560
ケーガン・アタルによるディッシュ・フリン論文が登場しました。これは、皆さんの一部がよく知っているかもしれません。

391
00:14:05,560 --> 00:14:08,399
つまり、これは、

392
00:14:08,399 --> 00:14:10,399
著者が主張したハイブリッドとウェットウェア・ハードウェア・ニューロモーフィック・システムが

393
00:14:10,399 --> 00:14:12,759
具現化されたものでした。 このシステムは、学習の

394
00:14:12,759 --> 00:14:14,480


395
00:14:14,480 --> 00:14:16,839
ための自由エネルギー原理を使用したポンのゲームの急速な親学習を示し

396
00:14:16,839 --> 00:14:19,040
、著者らは、

397
00:14:19,040 --> 00:14:20,720
システムが合成

398
00:14:20,720 --> 00:14:21,959
生物学的

399
00:14:21,959 --> 00:14:24,320
知能を示したため、ニューロモーフィックシステム

400
00:14:24,320 --> 00:14:25,920
に能動的な影響原理を実装する分野は

401
00:14:25,920 --> 00:14:28,480
非常に不十分であり、

402
00:14:28,480 --> 00:14:31,199
この夢シリーズの背後にあるアイデアは次のとおりであると主張しました。 この

403
00:14:31,199 --> 00:14:33,480


404
00:14:33,480 --> 00:14:36,079


405
00:14:36,079 --> 00:14:38,240
分野を促進するための知識アイデアと専門知識を共有するためのスペースとコミュニティを作成します。ええと、

406
00:14:38,240 --> 00:14:40,560
本当にエキサイティングな技術的飛躍が

407
00:14:40,560 --> 00:14:42,839
おそらくこの分野から生まれると思います。それでは、

408
00:14:42,839 --> 00:14:44,880


409
00:14:44,880 --> 00:14:48,920
ニューロモーフィック 101 ええと

410
00:14:48,920 --> 00:14:51,880
次の話を聞いていただきありがとうございました デビッドから話を聞きますので、デビッド、

411
00:14:51,880 --> 00:14:53,519


412
00:14:53,519 --> 00:14:56,399
自己紹介をしたい場合は、よろしくお願いします、

413
00:14:56,399 --> 00:14:59,639
サラ、

414
00:14:59,639 --> 00:15:02,320


415
00:15:03,320 --> 00:15:06,320
画面を共有したいと思います

416
00:15:10,820 --> 00:15:14,040
[音楽]

417
00:15:14,040 --> 00:15:17,600
はい、今

418
00:15:17,600 --> 00:15:21,240
私の画面が見えますか、プレゼンテーション、はい、大丈夫、完璧です、

419
00:15:21,240 --> 00:15:24,240
はい、こんにちは、私の名前は

420
00:15:24,240 --> 00:15:27,639
David kle 私はボン大学の

421
00:15:27,639 --> 00:15:30,519
The Institute for um M informationatic の研究者でありクーデターのリーダーでもあり、

422
00:15:30,519 --> 00:15:33,839


423
00:15:33,839 --> 00:15:36,040


424
00:15:36,040 --> 00:15:37,920
持続可能な機械学習に関するグループを率いています。私たちは

425
00:15:37,920 --> 00:15:40,199
ニューロモーフィック コンピューティングに非常に重点を置いています。

426
00:15:40,199 --> 00:15:41,800
それが私がそうしている理由です。 今日ここに来て、

427
00:15:41,800 --> 00:15:44,360
私は

428
00:15:44,360 --> 00:15:47,279
サラと非常に似た動機から始めます。これは

429
00:15:47,279 --> 00:15:49,240


430
00:15:49,240 --> 00:15:51,959
この講演の本当に素晴らしいインスピレーションでした。おそらく皆さんのほとんどは

431
00:15:51,959 --> 00:15:54,560
これを見たことがあると思います、この興味深い

432
00:15:54,560 --> 00:15:57,120
最近の結果、ドイツのことを言っているわけではありません

433
00:15:57,120 --> 00:15:59,120
バスケットボールのチャンピオンシップで優勝しました

434
00:15:59,120 --> 00:16:03,880
が、ここ

435
00:16:03,880 --> 00:16:05,319


436
00:16:05,319 --> 00:16:07,079
数年、特に

437
00:16:07,079 --> 00:16:08,959
ここ 2 ～ 3 年で我々が見てきた人工知能におけるこの本当に大きな飛躍は、これが適切な

438
00:16:08,959 --> 00:16:11,480


439
00:16:11,480 --> 00:16:14,360
ネットワークによるプロンプトから生成された写真であり、本当に

440
00:16:14,360 --> 00:16:16,399
驚くべきものです。 わずか 2 3 年前までは SF だと思われていました

441
00:16:16,399 --> 00:16:18,519


442
00:16:18,519 --> 00:16:22,360
が、これは基本的に、ディープ ニューラル ネットワークである

443
00:16:22,360 --> 00:16:24,120
ニューロモーフィックなアプローチによって可能になりました。

444
00:16:24,120 --> 00:16:26,680


445
00:16:26,680 --> 00:16:28,079
これらのディープ ニューラル ネットワークは

446
00:16:28,079 --> 00:16:31,120
今では巨大になっていますが、これには

447
00:16:31,120 --> 00:16:33,839
注意事項もありますので、基本的には裏返しです。

448
00:16:33,839 --> 00:16:36,639
これは、おそらく他の問題の中でも特に、

449
00:16:36,639 --> 00:16:40,360
これらのモデルは膨大な量のエネルギーを消費する可能性があるため、

450
00:16:40,360 --> 00:16:43,959


451
00:16:43,959 --> 00:16:47,279
ダルやジェット GPT のようなモデルは、サラがすでに

452
00:16:47,279 --> 00:16:50,360
述べたように、家や車に

453
00:16:50,360 --> 00:16:52,680
匹敵するエネルギー予算を消費することになるため、トレーニング

454
00:16:52,680 --> 00:16:56,759
をする必要があります

455
00:16:56,759 --> 00:16:59,440
1 回の時間はおよそ 1 ギガ時間のようなものな

456
00:16:59,440 --> 00:17:02,680
ので、CO2 排出量は 300 トンになります。

457
00:17:02,680 --> 00:17:07,160
そして、多くの場合、これは

458
00:17:07,160 --> 00:17:09,760


459
00:17:09,760 --> 00:17:13,359
一般的な自動車の寿命の何倍にもなります。これには

460
00:17:13,359 --> 00:17:15,280
明らかに 2 つの問題が伴います。

461
00:17:15,280 --> 00:17:17,880
これによりトレーニングが必要になります。 モデルは

462
00:17:17,880 --> 00:17:20,160
非常に少数の非常に

463
00:17:20,160 --> 00:17:21,799
大規模なプレーヤーのみがアクセスできるため、基本的には

464
00:17:21,799 --> 00:17:24,599
大手テクノロジー企業、そして第二に、そして

465
00:17:24,599 --> 00:17:26,319
おそらくさらに重要なことに、これはリソースが限られている

466
00:17:26,319 --> 00:17:29,160
地球とは互換性がありません。

467
00:17:29,160 --> 00:17:31,880
したがって、もし

468
00:17:31,880 --> 00:17:34,160
AI の成長率が前回と同じように続くならば、

469
00:17:34,160 --> 00:17:35,360


470
00:17:35,360 --> 00:17:38,240


471
00:17:38,240 --> 00:17:41,400
20 30 年までに世界のエネルギー消費の 133% を消費し、

472
00:17:41,400 --> 00:17:45,080


473
00:17:45,080 --> 00:17:48,200
あと 5 年ほどで基本的に運輸部門を上回るでしょう。

474
00:17:48,200 --> 00:17:50,720
つまり、

475
00:17:50,720 --> 00:17:52,600
持続可能な機械学習はそもそも存在するのかという疑問が生じます。

476
00:17:52,600 --> 00:17:55,080
私が働いているのですから当然です。

477
00:17:55,080 --> 00:17:56,799
持続可能な機械

478
00:17:56,799 --> 00:17:59,039
学習のグループでは、私はそれができると信じています。

479
00:17:59,039 --> 00:18:01,799
なぜそう思うかというと、

480
00:18:01,799 --> 00:18:04,960
非常に効率的であり、サラが20歳頃に消費する人間の脳である

481
00:18:04,960 --> 00:18:08,600
これらのAIモデルよりもまだ優れているシステムを私たちが知っているからです。

482
00:18:08,600 --> 00:18:11,039


483
00:18:11,039 --> 00:18:13,000


484
00:18:13,000 --> 00:18:14,039


485
00:18:14,039 --> 00:18:16,919
ワット数、または 1 日あたりバナナ 4 本です。

486
00:18:16,919 --> 00:18:21,400
つまり、今日の

487
00:18:21,400 --> 00:18:24,400
AI モデルよりも何桁も効率的です。

488
00:18:24,400 --> 00:18:26,200


489
00:18:26,200 --> 00:18:29,480
でも、これまでのところ、

490
00:18:29,480 --> 00:18:32,480
これらのネットワークがどのように機能するか、

491
00:18:32,480 --> 00:18:34,520
特にそれらをトレーニングする方法は

492
00:18:34,520 --> 00:18:37,080
基本的にわかりません。 私たちの目標は、

493
00:18:37,080 --> 00:18:39,559
機械学習からメカニズムを移行することです。

494
00:18:39,559 --> 00:18:41,679
この素晴らしい写真が

495
00:18:41,679 --> 00:18:44,679
ここにあります。基本的に、

496
00:18:44,679 --> 00:18:46,440
私たちはすでに回避方法を知っている機械学習サイトから開始します。

497
00:18:46,440 --> 00:18:49,400
それで、

498
00:18:49,400 --> 00:18:51,280
素晴らしい、そして

499
00:18:51,280 --> 00:18:53,120
非常に優れたモデルができました。 本当に

500
00:18:53,120 --> 00:18:55,240
素晴らしい結果が得られましたが、

501
00:18:55,240 --> 00:18:57,480
効率的ではありません。

502
00:18:57,480 --> 00:19:01,840
それらを新しい効率的な AI

503
00:19:01,840 --> 00:19:04,120
生成に転送したいと考えています。私たちのアイデアは、

504
00:19:04,120 --> 00:19:07,520
神経科学からのインスピレーションを利用して、

505
00:19:07,520 --> 00:19:09,799
この転送をより速く、そして

506
00:19:09,799 --> 00:19:12,240
そもそも可能にすることです。

507
00:19:12,240 --> 00:19:17,039
それで、実際には生物学から これは

508
00:19:17,039 --> 00:19:19,679
素晴らしいインスピレーションの源であり、常に

509
00:19:19,679 --> 00:19:21,400
非常に

510
00:19:21,400 --> 00:19:23,200
驚くべき結果をもたらします。そして、

511
00:19:23,200 --> 00:19:24,960
数年前に私が偶然見つけた結果の 1 つは、

512
00:19:24,960 --> 00:19:30,919


513
00:19:30,919 --> 00:19:33,559
脳内の雑木林の能力です。皆さんもおそらく

514
00:19:33,559 --> 00:19:35,200
脳内のニューロンをご存知だと思いますが、 雑木林のためにつながっています

515
00:19:35,200 --> 00:19:36,159


516
00:19:36,159 --> 00:19:40,960
が、これを見てみると、

517
00:19:40,960 --> 00:19:43,480
これは

518
00:19:43,480 --> 00:19:45,919
2019 年の論文で、実際に

519
00:19:45,919 --> 00:19:47,320
個々のシステムを特定することができ、

520
00:19:47,320 --> 00:19:49,400


521
00:19:49,400 --> 00:19:51,799
単一の送信のような概要リリースを作成するトリガーになる可能性がありますが、

522
00:19:51,799 --> 00:19:54,840
これを見ると、ええと、 これらの測定では、

523
00:19:54,840 --> 00:19:57,799
これは本当に

524
00:19:57,799 --> 00:20:00,320
ノイズで覆われていることがわかります。基本

525
00:20:00,320 --> 00:20:02,960
的にこれを平均してズーム

526
00:20:02,960 --> 00:20:04,720
アウトすると、ここに平均的な白線である典型的な共観トレースが表示されます

527
00:20:04,720 --> 00:20:06,679


528
00:20:06,679 --> 00:20:09,240
が、その下に巨大なチッターが表示されます。 えー、

529
00:20:09,240 --> 00:20:12,080


530
00:20:12,080 --> 00:20:14,960
標準偏差が数回上下するのが好きです

531
00:20:14,960 --> 00:20:16,120


532
00:20:16,120 --> 00:20:18,640
、

533
00:20:18,640 --> 00:20:21,000
えー、ニューロンは、実際のエネルギー消費量、またはエネルギー消費量と比較した場合、おそらく体内で最も高価な細胞タイプであることを考えると、これは実際には非常に驚くべきことです。

534
00:20:21,000 --> 00:20:23,480


535
00:20:23,480 --> 00:20:25,559


536
00:20:25,559 --> 00:20:28,840


537
00:20:28,840 --> 00:20:32,000


538
00:20:32,000 --> 00:20:34,159
体内のエネルギーの量は非常に高価なので、

539
00:20:34,159 --> 00:20:36,440


540
00:20:36,440 --> 00:20:38,720


541
00:20:38,720 --> 00:20:41,480
非常に高価なニューロン間で伝達されるこれらの遷移または伝達は

542
00:20:41,480 --> 00:20:43,480
信頼性が高いはずであると予想されるため、これは

543
00:20:43,480 --> 00:20:46,120
非常に直観に反する結果であり、

544
00:20:46,120 --> 00:20:48,120


545
00:20:48,120 --> 00:20:50,039
かなり長い間神経科学者を困惑させてきました。

546
00:20:50,039 --> 00:20:53,600


547
00:20:53,600 --> 00:20:58,080
えー、2番目の不可解な観察があります。

548
00:20:58,080 --> 00:21:00,120
それは、

549
00:21:00,120 --> 00:21:03,919
ニューロンの形態がこれに似ているということです。つまり、

550
00:21:03,919 --> 00:21:05,480
これは皮質

551
00:21:05,480 --> 00:21:08,159
にある典型的な錐体ニューロンでしょう。

552
00:21:08,159 --> 00:21:09,039


553
00:21:09,039 --> 00:21:12,880
しかし、これは

554
00:21:12,880 --> 00:21:15,919
実際には非常に大きな細胞のものであることがわかります。

555
00:21:15,919 --> 00:21:18,039
細長いので、これは

556
00:21:18,039 --> 00:21:21,039
人間の脳の中で最大 1 ミリメートルになる可能性があります、

557
00:21:21,039 --> 00:21:23,000
つまり、

558
00:21:23,000 --> 00:21:25,400
ここのどこかでサインアップが発生すると、ここにある

559
00:21:25,400 --> 00:21:27,200
細胞体と通信するのが非常に困難になるため、

560
00:21:27,200 --> 00:21:29,000


561
00:21:29,000 --> 00:21:33,240
ここで電気信号が生成されます ここに移動する可能性があります

562
00:21:33,240 --> 00:21:35,440
が、ここの登録者には

563
00:21:35,440 --> 00:21:38,480


564
00:21:38,480 --> 00:21:40,520
細胞体の実際の電圧を測定する方法がありません。ここは

565
00:21:40,520 --> 00:21:41,960
実際に興味深い場所です。

566
00:21:41,960 --> 00:21:43,760
ここには活動電位が形成されているため、

567
00:21:43,760 --> 00:21:46,039
登録者が実際に

568
00:21:46,039 --> 00:21:48,240
何が起こっているのかを知りたい場合は、 これは、

569
00:21:48,240 --> 00:21:50,120


570
00:21:50,120 --> 00:21:52,840
ニューロンがどのように動作するか、ニューロンが

571
00:21:52,840 --> 00:21:55,400
世界と

572
00:21:55,400 --> 00:21:59,880
どのように相互作用するかについて予測できるようにするために細胞体内で起こっていることですが、これは、このコミュニケーションが単一のニューロンで実際にどのように機能するかという、神経科学におけるもう一つの非常に不可解な、または未解決の問題です。

573
00:21:59,880 --> 00:22:02,120


574
00:22:02,120 --> 00:22:04,120


575
00:22:04,120 --> 00:22:07,320
細胞体と細胞膜とサインアップの間では、

576
00:22:07,320 --> 00:22:10,720


577
00:22:10,720 --> 00:22:12,840
実際に活動電位が

578
00:22:12,840 --> 00:22:14,880
上に戻ることができるので、ニューロンがスパイクする

579
00:22:14,880 --> 00:22:18,000
ときにこの二値変数のようなものを見ることができることが知られていますが、

580
00:22:18,000 --> 00:22:20,240


581
00:22:20,240 --> 00:22:23,799
ここで実際に膜電位を測定することはできないので、

582
00:22:23,799 --> 00:22:25,559
ほとんどの顕著な電気

583
00:22:25,559 --> 00:22:27,159
信号は実際にこれを通って逆伝播する可能性があり、

584
00:22:27,159 --> 00:22:29,120


585
00:22:29,120 --> 00:22:31,400
これはサインアップが細胞体内でこれで何が起こっているかについて

586
00:22:31,400 --> 00:22:33,000
実際に非常にまばらな情報を持っていることを示唆しています。

587
00:22:33,000 --> 00:22:34,799


588
00:22:34,799 --> 00:22:40,720
そして、

589
00:22:40,720 --> 00:22:43,000
共観可塑性のほとんどのモデルはこれをまったくカバーしていません。

590
00:22:43,000 --> 00:22:44,159


591
00:22:44,159 --> 00:22:48,279
そして私たちは、ニューロンのこの重要な状態に関するこのまばらな情報を考慮して、えー、この相互作用は

592
00:22:48,279 --> 00:22:50,880


593
00:22:50,880 --> 00:22:52,760
どのように機能するのか、

594
00:22:52,760 --> 00:22:55,679
えー、サインアップはどのようにして有用な学習信号を生み出すことができるのか疑問に思っていました。

595
00:22:55,679 --> 00:22:57,520


596
00:22:57,520 --> 00:23:00,200


597
00:23:00,200 --> 00:23:02,840
そして、私たちの考えは、本質的に

598
00:23:02,840 --> 00:23:04,480
これら 2 つの観察はこれらの高レベルの情報であるということでした。

599
00:23:04,480 --> 00:23:06,440
ノイズとサインアップ、そして

600
00:23:06,440 --> 00:23:08,880
細胞体と

601
00:23:08,880 --> 00:23:10,640
サインアップの間のこの大きな距離が、これらの高い

602
00:23:10,640 --> 00:23:12,679
不確実性をもたらすと言いますが、これらは実際には

603
00:23:12,679 --> 00:23:15,480
同じコインの表裏なので、私たちの仮説は、

604
00:23:15,480 --> 00:23:18,840
えー、実際には、

605
00:23:18,840 --> 00:23:22,880
私たちがすでに知っているのと同じモデルを使用できるということでした。

606
00:23:22,880 --> 00:23:25,640
行動レベルから、えー、

607
00:23:25,640 --> 00:23:29,559


608
00:23:29,559 --> 00:23:31,760
不確実性の高い環境でエージェントがどのように行動し、実行できるか、

609
00:23:31,760 --> 00:23:33,400
これをすべてのサインアップに適用するだけで、

610
00:23:33,400 --> 00:23:37,760


611
00:23:37,760 --> 00:23:40,120
エラーが発生するため、すべてのサインアップは

612
00:23:40,120 --> 00:23:44,559
これを

613
00:23:44,559 --> 00:23:47,679
基本的に同じモデルを使用する必要があります。 このモデルは、

614
00:23:47,679 --> 00:23:49,159
実際には

615
00:23:49,159 --> 00:23:51,919
総観的な送信には

616
00:23:51,919 --> 00:23:54,320
ノイズが多く、これらのレベルのノイズは

617
00:23:54,320 --> 00:23:56,880
環境に関する不確実性を表現していることをすぐに示唆します。

618
00:23:56,880 --> 00:23:59,640
そして、このモデルを使用して

619
00:23:59,640 --> 00:24:02,080
学習ルールを導き出し、

620
00:24:02,080 --> 00:24:04,600
それらを生物学と並べて比較することができます。

621
00:24:04,600 --> 00:24:06,520
最初に

622
00:24:06,520 --> 00:24:08,960
お見せしたいので、

623
00:24:08,960 --> 00:24:10,880
フリー エネルギー モデルについて簡単に紹介します。

624
00:24:10,880 --> 00:24:13,720
なぜなら、あまり

625
00:24:13,720 --> 00:24:15,720
馴染みのない人もいるかもしれないからです。しかし、

626
00:24:15,720 --> 00:24:19,159
これは本質的に、

627
00:24:19,159 --> 00:24:21,000
このような状況を説明するためのモデルです。

628
00:24:21,000 --> 00:24:23,279
ある環境と対話している人で

629
00:24:23,279 --> 00:24:25,039
、ここでは非常に単純だと仮定しました。その

630
00:24:25,039 --> 00:24:28,320
ため、この人は何らかのターゲットにボールを投げようとしています。そして

631
00:24:28,320 --> 00:24:31,799
私たちは人間として、

632
00:24:31,799 --> 00:24:34,240
そのようなタスクを解決するのが得意であり、

633
00:24:34,240 --> 00:24:36,039


634
00:24:36,039 --> 00:24:37,840
高いレベルがある場合はそのようなタスクを解決することも得意です これには不確実性があり、

635
00:24:37,840 --> 00:24:41,960
その人が

636
00:24:41,960 --> 00:24:44,000
視覚的なフィードバックを受け取る可能性がありますが、このフィードバックの多くは

637
00:24:44,000 --> 00:24:46,440
隠さ

638
00:24:46,440 --> 00:24:48,520
れている可能性があるため、これが壁の後ろで起こっていると想像できますが、

639
00:24:48,520 --> 00:24:52,600
その人は今でもこのボール

640
00:24:52,600 --> 00:24:55,039
の軌道を予測したいと考えているかもしれません。

641
00:24:55,039 --> 00:24:56,679
ターゲットに向かって飛んで、

642
00:24:56,679 --> 00:25:00,960
正しいアクションができるように、

643
00:25:00,960 --> 00:25:03,960
この状態にいくつかの変数を割り当てます。

644
00:25:03,960 --> 00:25:05,600
つまり、基本的に

645
00:25:05,600 --> 00:25:07,440
この人が観察できるフィードバックがあり、

646
00:25:07,440 --> 00:25:09,880


647
00:25:09,880 --> 00:25:12,279
ここでボールが飛んでいる観察されていない状態を私たちが

648
00:25:12,279 --> 00:25:14,799
呼んでいます。 人が

649
00:25:14,799 --> 00:25:17,000
それに直接アクセスできない場合は、

650
00:25:17,000 --> 00:25:19,200
たとえばボールが壁の隅にあるときにその一部だけが表示され、

651
00:25:19,200 --> 00:25:22,000


652
00:25:22,000 --> 00:25:25,000
その後、これを本質的にモデル化するか、

653
00:25:25,000 --> 00:25:28,200
この行動を説明します。

654
00:25:28,200 --> 00:25:31,240
ええと、

655
00:25:31,240 --> 00:25:33,360
この軌道の内部記述があるので、

656
00:25:33,360 --> 00:25:37,520
このええと状態の内部モデル

657
00:25:37,520 --> 00:25:41,480
と、このモデルが

658
00:25:41,480 --> 00:25:45,679
観察されたフィードバックに一致するように更新されます。

659
00:25:45,679 --> 00:25:48,120
これは、自由エネルギー原理の

660
00:25:48,120 --> 00:25:50,200
この美しい数学的枠組みで非常にうまく説明できます。

661
00:25:50,200 --> 00:25:52,320


662
00:25:52,320 --> 00:25:55,159
アイデアは、基本的に、

663
00:25:55,159 --> 00:25:57,279
内部状態のモデルを確立し、

664
00:25:57,279 --> 00:26:00,720


665
00:26:00,720 --> 00:26:04,640
内部状態と環境の状態がどのように

666
00:26:04,640 --> 00:26:06,440


667
00:26:06,440 --> 00:26:09,000
相互作用するかということです。また、フィードバックのモデルを作成することで、

668
00:26:09,000 --> 00:26:11,720
状態と観察したフィードバックがどのように

669
00:26:11,720 --> 00:26:14,240
相互作用するかということです。

670
00:26:14,240 --> 00:26:18,559
本質的には、内部状態

671
00:26:18,559 --> 00:26:21,080


672
00:26:21,080 --> 00:26:23,039
のこのモデル

673
00:26:23,039 --> 00:26:24,679
とフィードバックのこのモデルと

674
00:26:24,679 --> 00:26:29,600
外部状態

675
00:26:29,960 --> 00:26:31,720


676
00:26:31,720 --> 00:26:35,120
との間の距離を測定する損失関数を書き留めることができます。その後、

677
00:26:35,120 --> 00:26:37,799
この 2 つの間の距離を本質的に最小化することで、すべてを導き出すことができます。

678
00:26:37,799 --> 00:26:41,799
行動に関連する種類の

679
00:26:41,799 --> 00:26:44,799


680
00:26:44,799 --> 00:26:46,679
学習など、行動に関連する問題を解決できますが、

681
00:26:46,679 --> 00:26:48,399
これを他のことにも使用できます。たとえば、

682
00:26:48,399 --> 00:26:50,399
何が良い行動かを理解するなど、

683
00:26:50,399 --> 00:26:53,440


684
00:26:53,440 --> 00:26:55,520
内部状態と行動の両方について推論することもできます

685
00:26:55,520 --> 00:26:58,440
。これはシェルです。 自由

686
00:26:58,440 --> 00:27:00,480
エネルギー原理であり、ここでのこのオブジェクトは、たまたま

687
00:27:00,480 --> 00:27:02,360


688
00:27:02,360 --> 00:27:04,760
変分自由エネルギーとして知られているものであり、

689
00:27:04,760 --> 00:27:06,960


690
00:27:06,960 --> 00:27:08,480
これは統計物理学とも一致しており、これがこのフレームワークの

691
00:27:08,480 --> 00:27:11,640
名前の由来ですが、

692
00:27:11,640 --> 00:27:13,159
ここではすべてが確率的であることがわかりますので、本質的には次のようになります。

693
00:27:13,159 --> 00:27:15,240
2 つの確率関数 Q は

694
00:27:15,240 --> 00:27:17,320
内部モデル、P は

695
00:27:17,320 --> 00:27:19,640
状態と

696
00:27:19,640 --> 00:27:22,120
観測値の間の相互作用で、ここには最小化したい

697
00:27:22,120 --> 00:27:24,279
それらの間の距離測定値があります。

698
00:27:24,279 --> 00:27:25,200


699
00:27:25,200 --> 00:27:27,799
それで、ニューロン

700
00:27:27,799 --> 00:27:29,640
とサインアップ、およびそれらがそれぞれとどのように相互作用するかを見てみましょう。

701
00:27:29,640 --> 00:27:31,520
他には非常によく似た画像が見つかりました。そのため、

702
00:27:31,520 --> 00:27:35,440
単一のサインアップは、ええと、

703
00:27:35,440 --> 00:27:38,520
緑色で示されている内部状態を持っています。

704
00:27:38,520 --> 00:27:41,120
単純化のために

705
00:27:41,120 --> 00:27:45,080
モデル化した内部状態です。これに基づいて、シナプティックベイトとしてのみ使用されます。

706
00:27:45,080 --> 00:27:46,960


707
00:27:46,960 --> 00:27:50,799
視索前スパイクによってトリガーされると、サインアップが生成されます。

708
00:27:50,799 --> 00:27:53,200
ポスト総観電流は、これが

709
00:27:53,200 --> 00:27:56,320
私たちの外部状態であるソムに伝播しますが、

710
00:27:56,320 --> 00:27:57,760


711
00:27:57,760 --> 00:27:59,799


712
00:27:59,799 --> 00:28:02,640
カップから遠すぎるため直接観察することはできませんが、

713
00:28:02,640 --> 00:28:04,279


714
00:28:04,279 --> 00:28:05,880
この二値変数である活動電位を伝播するこのスペーサであるフィードバックを見ることができます。

715
00:28:05,880 --> 00:28:07,200


716
00:28:07,200 --> 00:28:09,840
ニューロンがスパイクしたかどうかを教えてくれるので、これは

717
00:28:09,840 --> 00:28:12,120
まったく同じフレームワークです。

718
00:28:12,120 --> 00:28:13,679
このように書き留めると、

719
00:28:13,679 --> 00:28:18,200
同じ数学を使用してそれを解くことができます。

720
00:28:18,200 --> 00:28:21,159
つまり、それを解決するには、

721
00:28:21,159 --> 00:28:24,320
えー、いくつか

722
00:28:24,320 --> 00:28:25,960
の仮定を立てる必要があるので、

723
00:28:25,960 --> 00:28:28,279
この男のモデルを

724
00:28:28,279 --> 00:28:32,240
ここに書き留める必要があります。このモデルは、えー、

725
00:28:32,240 --> 00:28:35,880
フィードバックと外部状態がどのように

726
00:28:35,880 --> 00:28:38,159
相互作用するかのモデルですが、これについては非常に優れたモデルがあります。

727
00:28:38,159 --> 00:28:40,519
これは何年にもわたって研究されてきた

728
00:28:40,519 --> 00:28:43,120
ので、モデルニューロンが典型的にどのように

729
00:28:43,120 --> 00:28:45,880
動作するかがわかります。ここには

730
00:28:45,880 --> 00:28:47,440
漏れのある

731
00:28:47,440 --> 00:28:49,120
統合火災ニューロンの膜電位があり、

732
00:28:49,120 --> 00:28:51,159
これはちょうど上下していることがわかり、

733
00:28:51,159 --> 00:28:53,720
このニューロンはえー、 多くの

734
00:28:53,720 --> 00:28:56,440
視索前入力とおそらくノイズもあり、

735
00:28:56,440 --> 00:28:57,679
最終的にある時点で

736
00:28:57,679 --> 00:28:59,640
閾値に達するとスパイクが生成され、

737
00:28:59,640 --> 00:29:01,760
それが

738
00:29:01,760 --> 00:29:04,279
下流のニューロンに伝わりカップに戻る Z になります。

739
00:29:04,279 --> 00:29:07,120
そしてリセット

740
00:29:07,120 --> 00:29:12,159
されます。 これを

741
00:29:12,159 --> 00:29:13,799
数学的に書き留めることができるのは、

742
00:29:13,799 --> 00:29:16,399
非常に単純な微分方程式です

743
00:29:16,399 --> 00:29:19,039
が、ニューロンは再びこの状態にアクセスできない

744
00:29:19,039 --> 00:29:21,360
ため、再び

745
00:29:21,360 --> 00:29:24,440
この壁の後ろにあり、このスパイク イベントだけが表示されます

746
00:29:24,440 --> 00:29:26,440
が、この単純なケースでは実際にそれが可能です。

747
00:29:26,440 --> 00:29:28,320
本当に統合された F ニューロンなので、

748
00:29:28,320 --> 00:29:30,399
これを分析的に解くことができるので、

749
00:29:30,399 --> 00:29:32,240


750
00:29:32,240 --> 00:29:34,559
スパイク時間を考慮した膜電位の事後分布が何であるかを書き留めることができます。

751
00:29:34,559 --> 00:29:37,480
そして、ここから得られるものは、

752
00:29:37,480 --> 00:29:40,240
実際にはいわゆる確率的

753
00:29:40,240 --> 00:29:44,159
ブリッジ モデル、またはこの場合は うーん

754
00:29:44,159 --> 00:29:45,960
火災ニューロンのリーク積分のこれは

755
00:29:45,960 --> 00:29:48,240
オレンジ色のブリッジ モデルなので、これは

756
00:29:48,240 --> 00:29:51,200
分析的に書き留めることができ、この U

757
00:29:51,200 --> 00:29:53,880
つまり、単純ではありませんが、

758
00:29:53,880 --> 00:29:56,760
実行可能です。そして、これを直接使用できるので、

759
00:29:56,760 --> 00:29:59,799
このモデルを

760
00:29:59,799 --> 00:30:02,279
もう一度書き留める必要があります この自由エネルギー

761
00:30:02,279 --> 00:30:04,440
関数なので、ここでは、

762
00:30:04,440 --> 00:30:06,600
サインアップが実際に

763
00:30:06,600 --> 00:30:08,600
シナプティック後の電流をどのように生成し、それらが

764
00:30:08,600 --> 00:30:11,000
ニューロン内でどのように統合されるかを仮定しますが、

765
00:30:11,000 --> 00:30:12,840
それは、リーキー

766
00:30:12,840 --> 00:30:14,799
統合火災ニューロンと、実際に

767
00:30:14,799 --> 00:30:17,760
サインアップが生成する確率的入力によっても与えられます

768
00:30:17,760 --> 00:30:20,120
したがって、ここでは簡素化のために、

769
00:30:20,120 --> 00:30:22,919
ここでは基本的に

770
00:30:22,919 --> 00:30:25,559
ガウス確率変数を注入して描画し、

771
00:30:25,559 --> 00:30:27,960
これを inte

772
00:30:27,960 --> 00:30:30,399
great および fire ニューロンに注入するガウス Sy upses のみを想定します。その後、これらすべての

773
00:30:30,399 --> 00:30:31,960
要素は実際に

774
00:30:31,960 --> 00:30:33,640
閉じた形式で解決でき、学習ルールを導き出すことができます。

775
00:30:33,640 --> 00:30:35,720
このプレ

776
00:30:35,720 --> 00:30:37,640
エネルギー汎関数を

777
00:30:37,640 --> 00:30:40,720
今最小化します ええと、それを行うと、ええと、

778
00:30:40,720 --> 00:30:44,279
これには素晴らしい特性がたくさんあります。

779
00:30:44,279 --> 00:30:46,279
なぜなら、このオニン・ルベック

780
00:30:46,279 --> 00:30:48,480
ブリッジは、

781
00:30:48,480 --> 00:30:51,480
逆伝播する活動

782
00:30:51,480 --> 00:30:54,480
電位による事前のええと完全に決定されるためです。したがって、基本的に、

783
00:30:54,480 --> 00:30:57,000
総観後のええとスパイクの時間は、

784
00:30:57,000 --> 00:30:57,310


785
00:30:57,310 --> 00:30:58,519
[音楽]

786
00:30:58,519 --> 00:31:01,760
ニューロンに到着します えー、ここで得られるこの形状は

787
00:31:01,760 --> 00:31:03,440
2 つの隣接する

788
00:31:03,440 --> 00:31:04,760
視索後

789
00:31:04,760 --> 00:31:08,519
スパイクにのみ依存します えー、これは自動的にここに到達することを意味します えー、

790
00:31:08,519 --> 00:31:10,720
学習ルールは次のようなものです

791
00:31:10,720 --> 00:31:12,880
学習ルールは

792
00:31:12,880 --> 00:31:15,480


793
00:31:15,480 --> 00:31:17,320
2 つの視索後スパイクの差にのみ依存します ここではこれを

794
00:31:17,320 --> 00:31:18,159
デルタ

795
00:31:18,159 --> 00:31:22,960
T2 と呼びます。ええと、

796
00:31:22,960 --> 00:31:25,159
ポストシノプティック スパイクと、

797
00:31:25,159 --> 00:31:27,240
ある時点でトリガされる実際の入力との差です。えー、

798
00:31:27,240 --> 00:31:29,120
プレオプティック

799
00:31:29,120 --> 00:31:32,720
側で、基本的に

800
00:31:32,720 --> 00:31:35,919
このルックアップ テーブルを作成して、えー、

801
00:31:35,919 --> 00:31:38,200
何がなるかを計算するだけです。

802
00:31:38,200 --> 00:31:40,960


803
00:31:40,960 --> 00:31:42,840
この自由エネルギー原理に関して最適に学習できるように、これらのサインアップが行う必要のある更新を行います。

804
00:31:42,840 --> 00:31:44,760
これが

805
00:31:44,760 --> 00:31:46,279
私たちが得た形です。シノプティック

806
00:31:46,279 --> 00:31:47,679
後の発火率に強い依存性があることがわかります

807
00:31:47,679 --> 00:31:49,440
が、

808
00:31:49,440 --> 00:31:52,720
基本的には依存性もあります。 サラが前に述べたこの典型的な STP ええと、

809
00:31:52,720 --> 00:31:55,880


810
00:31:55,880 --> 00:31:57,639
視索前スパイクと視索後スパイクの相対的な位置は何ですか。

811
00:31:57,639 --> 00:31:59,080


812
00:31:59,080 --> 00:32:02,440
簡単に言うと、このモデルは

813
00:32:02,440 --> 00:32:04,760
本質的に 2 つの経路に分割できるようになりました。

814
00:32:04,760 --> 00:32:08,279
したがって、

815
00:32:08,279 --> 00:32:11,000
基本的に視索前スパイクがあるときはいつでもこの atoc 応答が得られます。

816
00:32:11,000 --> 00:32:13,880


817
00:32:13,880 --> 00:32:16,080
彼はこの衝撃分布から抽出したカップ内でアクションをトリガーし

818
00:32:16,080 --> 00:32:18,039
、それを

819
00:32:18,039 --> 00:32:21,799
ニューロンに注入します。その後、

820
00:32:21,799 --> 00:32:22,880


821
00:32:22,880 --> 00:32:25,480


822
00:32:25,480 --> 00:32:28,720
サインアップがこのオランとウェンクブリッジで検索するポストトークアップデートがあります。

823
00:32:28,720 --> 00:32:30,360


824
00:32:30,360 --> 00:32:33,600


825
00:32:33,600 --> 00:32:35,679
生成されるはずだった最適な um 出力、つまり

826
00:32:35,679 --> 00:32:38,559
最適なアクションは何だったのか、そしてこの自由エネルギー原理に従って

827
00:32:38,559 --> 00:32:40,320
実際のアクションとこの最適な

828
00:32:40,320 --> 00:32:41,880
アクションを比較し

829
00:32:41,880 --> 00:32:44,880
、シノプティック ウェイトの更新である遅延応答応答を生成します。

830
00:32:44,880 --> 00:32:47,360


831
00:32:47,360 --> 00:32:49,399


832
00:32:49,399 --> 00:32:52,159
そして重要なことに、この

833
00:32:52,159 --> 00:32:54,519
内部モデルは暗黙的であるだけで、

834
00:32:54,519 --> 00:32:57,960
いわばこの中にエンコードされています えー、スパイク

835
00:32:57,960 --> 00:33:00,399
時間依存可塑性

836
00:33:00,399 --> 00:33:02,880
ルール えー、では、これらのルールはどのように見えるのでしょうか、

837
00:33:02,880 --> 00:33:04,639


838
00:33:04,639 --> 00:33:07,360
生物学とどのように比較するのでしょうか、そして、実際、それらは

839
00:33:07,360 --> 00:33:09,240
かなり適合しています これが実際に何の仮定もせずに

840
00:33:09,240 --> 00:33:11,519
第一原理から導き出されたものであることを考えると、

841
00:33:11,519 --> 00:33:13,880
これは

842
00:33:13,880 --> 00:33:16,320
生物学における測定であり、これは

843
00:33:16,320 --> 00:33:20,279
AlルールBでのBであり、非常に古い

844
00:33:20,279 --> 00:33:23,279
研究で、彼らは注入された物質を測定したvro研究で実際にこれを行った

845
00:33:23,279 --> 00:33:26,519


846
00:33:26,519 --> 00:33:29,120
概要のスパイクの

847
00:33:29,120 --> 00:33:30,880
前後で

848
00:33:30,880 --> 00:33:32,679
警官の体重変化を測定しました。これが

849
00:33:32,679 --> 00:33:35,320
私たちのモデルによって予測されるルールであり、

850
00:33:35,320 --> 00:33:37,799
少なくとも

851
00:33:37,799 --> 00:33:39,559
一次近似では

852
00:33:39,559 --> 00:33:42,080
非常によく似た形状が得られることがわかります。 これも理にかなっています。

853
00:33:42,080 --> 00:33:43,519


854
00:33:43,519 --> 00:33:48,120
なぜなら、サインアップが最も変更したいのは、

855
00:33:48,120 --> 00:33:51,840


856
00:33:51,840 --> 00:33:54,559
視前および視後のスパイク時間に近いときです。

857
00:33:54,559 --> 00:33:56,039
ここが

858
00:33:56,039 --> 00:33:57,919
視眼後スパイク時間であるためです。これは、

859
00:33:57,919 --> 00:34:00,240
状態について最もよく知っている場所だからです。

860
00:34:00,240 --> 00:34:02,159
PO ニューロン 自由エネルギー

861
00:34:02,159 --> 00:34:05,600
原理は、実際にはこの

862
00:34:05,600 --> 00:34:07,639
種の錐体を示唆するでしょう ええと、

863
00:34:07,639 --> 00:34:11,359


864
00:34:11,359 --> 00:34:14,199
本質的にはほとんど何の仮定もありませんが、

865
00:34:14,199 --> 00:34:17,719
一次だけではなく、

866
00:34:17,719 --> 00:34:20,199
スパイク時間に依存する可塑性規則があるため、

867
00:34:20,199 --> 00:34:21,480
また、この依存関係もあります。

868
00:34:21,480 --> 00:34:24,119
事後発火率、これを他の結果と比較することもできます。

869
00:34:24,119 --> 00:34:26,280
これは

870
00:34:26,280 --> 00:34:29,119
gr と Brunel による古いものなので、

871
00:34:29,119 --> 00:34:31,159
実際にはモデルですが、非常に

872
00:34:31,159 --> 00:34:35,839
詳細に説明されています。ええと、

873
00:34:35,839 --> 00:34:37,679
ええと光学後発火率に基づくええと可塑性です。

874
00:34:37,679 --> 00:34:41,280
サインアップ

875
00:34:41,280 --> 00:34:42,960
で、これが私たちのモデルが予測するものです。したがって、

876
00:34:42,960 --> 00:34:44,639


877
00:34:44,639 --> 00:34:47,359


878
00:34:47,359 --> 00:34:50,040
異なるレートでランダムなシノプティックポピクトラレインを

879
00:34:50,040 --> 00:34:52,639
前後に注入すると、モデルはこの形状を予測しますが、

880
00:34:52,639 --> 00:34:55,440
これも完全には一致しませんが、これが非常に

881
00:34:55,440 --> 00:34:58,359
理想的なモデルであることを考えると、実際には一致します 少なくとも、

882
00:34:58,359 --> 00:35:01,880


883
00:35:01,880 --> 00:35:04,160
視後側の発火率が低いとうつ病につながり、発火率が

884
00:35:04,160 --> 00:35:07,560
高いと増強につながるという主な特徴は、

885
00:35:07,560 --> 00:35:10,440


886
00:35:10,440 --> 00:35:14,240
これに反映されています。わかりました。まだ 10 分あると思います。わかりました。

887
00:35:14,240 --> 00:35:19,520


888
00:35:19,520 --> 00:35:21,320
それでは、簡単な中間要約を述べてから、

889
00:35:21,320 --> 00:35:23,400


890
00:35:23,400 --> 00:35:27,320
これを実際の

891
00:35:27,320 --> 00:35:29,040
機械学習

892
00:35:29,040 --> 00:35:32,440
モデルに実際に適用する他の作業をいくつか示したいと思います。 えー、ここで見たことは、

893
00:35:32,440 --> 00:35:36,760
えー、システムは実際には

894
00:35:36,760 --> 00:35:39,240
非常に確率的であり、これは非常に

895
00:35:39,240 --> 00:35:42,599
大きなパズルでした。

896
00:35:42,599 --> 00:35:44,160
実際のところ、

897
00:35:44,160 --> 00:35:47,680
シナプスノイズは

898
00:35:47,680 --> 00:35:50,920
実際にはサインアップであるということは、環境

899
00:35:50,920 --> 00:35:52,640
についてのそれ自体の不確実性を報告する方法であり、

900
00:35:52,640 --> 00:35:54,079
環境は

901
00:35:54,079 --> 00:35:57,560
実際には POS シナプスニューロンであり

902
00:35:57,560 --> 00:36:00,119
、実際にはこの方法で自由エネルギー原理とこれと相互作用します。

903
00:36:00,119 --> 00:36:02,160


904
00:36:02,160 --> 00:36:03,880
ポストシノプティックニューロン、またはそれは

905
00:36:03,880 --> 00:36:06,720
それを説明する非常に良い方法です、そして、もし興味があるなら、事前に

906
00:36:06,720 --> 00:36:09,400


907
00:36:09,400 --> 00:36:13,480
印刷された論文があります、あなたはこれらすべてを読むことができます、わかりました、それで、

908
00:36:13,480 --> 00:36:16,359
これは

909
00:36:16,359 --> 00:36:19,440
ニューロモーフィクスにどのように接続されますか、そして実際に

910
00:36:19,440 --> 00:36:21,160
私たちはそうです 実際にニューロモーフィック ハードウェアを実行しているのではなく、ニューロモーフィック

911
00:36:21,160 --> 00:36:23,400


912
00:36:23,400 --> 00:36:25,920
アルゴリズムを実行しているので、これらの

913
00:36:25,920 --> 00:36:27,480
インスピレーションを実際の機械

914
00:36:27,480 --> 00:36:30,319
学習モデルに取り入れようとしています。これは、機械学習でよく知られている問題を

915
00:36:30,319 --> 00:36:33,920
解決するのに良い攻撃角度であるかもしれないと考えました。

916
00:36:33,920 --> 00:36:35,599


917
00:36:35,599 --> 00:36:40,880


918
00:36:40,880 --> 00:36:43,640
ここに、さまざまな畳み込み層を備えた非常に単純な畳み込み

919
00:36:43,640 --> 00:36:45,440
ニューラル ネットワーク

920
00:36:45,440 --> 00:36:48,079
と、おそらく機械学習アルゴリズムに含まれるいくつかの高密度層を描画しました。

921
00:36:48,079 --> 00:36:49,839


922
00:36:49,839 --> 00:36:52,760
これは、

923
00:36:52,760 --> 00:36:54,599
多くの人が知っているように、これが

924
00:36:54,599 --> 00:36:57,400
最後まで訓練される方法だと思います 伝播を終了してアローバックする

925
00:36:57,400 --> 00:36:59,480
ため、

926
00:36:59,480 --> 00:37:02,119
入力とターゲットを含むトレーニング セットがあるという考えです。

927
00:37:02,119 --> 00:37:04,079
たとえば

928
00:37:04,079 --> 00:37:06,920
分類タスクでは、これは

929
00:37:06,920 --> 00:37:08,680
猫と犬の写真であり、

930
00:37:08,680 --> 00:37:12,440
ターゲットはいわゆる U クラス ラベルになります。

931
00:37:12,440 --> 00:37:15,160
いくつかは実際に

932
00:37:15,160 --> 00:37:17,119
そこに人工ニューロンがあり、

933
00:37:17,119 --> 00:37:18,640
これらのニューロンのうちのいくつかは猫に対してアクティブである可能性があり

934
00:37:18,640 --> 00:37:20,240
、もう1つは犬に対してアクティブである可能性があります。そして、

935
00:37:20,240 --> 00:37:23,440
そのデータには、

936
00:37:23,440 --> 00:37:25,400
まさにこれらのラベルがあり、

937
00:37:25,400 --> 00:37:27,119


938
00:37:27,119 --> 00:37:29,319
座ってやっていた人間によって生成されました。 これを手動で行い、

939
00:37:29,319 --> 00:37:32,119
トレーニング中に

940
00:37:32,119 --> 00:37:34,520
この

941
00:37:34,520 --> 00:37:37,040
入力を入力

942
00:37:37,040 --> 00:37:39,760
層から出力層まで伝播することでこの例をネットワークに表示します。その後、

943
00:37:39,760 --> 00:37:42,560
出力が

944
00:37:42,560 --> 00:37:44,960
これらのハンド ラベル ターゲットと比較され、その後、

945
00:37:44,960 --> 00:37:47,000
2 は

946
00:37:47,000 --> 00:37:48,839
これらすべての層を通って入力に逆伝播され

947
00:37:48,839 --> 00:37:52,000
、ここにあるすべての重みまたは

948
00:37:52,000 --> 00:37:54,720
全体的な重みがそれに

949
00:37:54,720 --> 00:37:57,160
応じて

950
00:37:57,160 --> 00:37:58,960
更新されるため、

951
00:37:58,960 --> 00:38:01,560
これを何度も繰り返した後、

952
00:38:01,560 --> 00:38:03,920
このネットワークは適切に伝えることができるようになります。

953
00:38:03,920 --> 00:38:05,560
C の部分は

954
00:38:05,560 --> 00:38:08,520
これを行うため、これには問題があります。この

955
00:38:08,520 --> 00:38:10,359
アルゴリズムは実際にはうまく機能します。

956
00:38:10,359 --> 00:38:12,960
これは、

957
00:38:12,960 --> 00:38:15,480
D や J gbt など、これまで話してきたすべてのモデルの基礎ですが、

958
00:38:15,480 --> 00:38:18,520
非常に非効率であり、

959
00:38:18,520 --> 00:38:20,280
問​​題は、これが既知のことです。

960
00:38:20,280 --> 00:38:22,880
ロッキング問題として文献に記載されているので、

961
00:38:22,880 --> 00:38:25,480
このネットワークをブロックに分割します。

962
00:38:25,480 --> 00:38:27,560


963
00:38:27,560 --> 00:38:30,839
これは以前にすでに実行しましたが、これは任意ですが、

964
00:38:30,839 --> 00:38:32,400


965
00:38:32,400 --> 00:38:34,000
ソフトウェアアルゴリズムの観点からこれを効率的に実装するには、そうするのは興味深いかもしれません。

966
00:38:34,000 --> 00:38:36,520
そして、今、

967
00:38:36,520 --> 00:38:39,160
これらが必要になるでしょう。 ブロックは並列で実行するのが理想的で、

968
00:38:39,160 --> 00:38:41,560
基本的に

969
00:38:41,560 --> 00:38:44,359
最初の例を表示し、

970
00:38:44,359 --> 00:38:46,440
最初のブロックでそれをトレーニングし、

971
00:38:46,440 --> 00:38:48,839
2 番目のブロックが

972
00:38:48,839 --> 00:38:50,760
他のことを実行している間に実行できますが、これは

973
00:38:50,760 --> 00:38:52,800
エンドツーエンドのバック

974
00:38:52,800 --> 00:38:54,440
プロパゲーションでは実際には不可能です このロックの

975
00:38:54,440 --> 00:38:57,200
問題のため、

976
00:38:57,200 --> 00:38:58,800
2番目のブロックのアクティブ化は最初のブロックのアクティブ化に依存する

977
00:38:58,800 --> 00:39:00,319
ため、

978
00:39:00,319 --> 00:39:02,720
それを最後まで伝播する必要があり、それから

979
00:39:02,720 --> 00:39:04,319
この誤差を計算し、

980
00:39:04,319 --> 00:39:06,680
それが完了した場合にのみ逆伝播します。

981
00:39:06,680 --> 00:39:09,520
えー、次のエポックを開始して、

982
00:39:09,520 --> 00:39:14,359
新しいサンプルの束を表示します。

983
00:39:14,359 --> 00:39:17,040
そして、

984
00:39:17,040 --> 00:39:20,319
この間ずっと、

985
00:39:20,319 --> 00:39:23,319
この最初のブロックを実行する 3 つが

986
00:39:23,319 --> 00:39:25,520
アイドル状態になり、基本的に常に待機する必要があることがわかります。

987
00:39:25,520 --> 00:39:28,079
これは明らかにそれらを非常に

988
00:39:28,079 --> 00:39:30,040
非効率にします。そして今私たちのアイデアは、基本

989
00:39:30,040 --> 00:39:33,000
的に、このフリーエネルギー原理のためにサインアップがどの

990
00:39:33,000 --> 00:39:36,680
ように長距離で通信するかについて、この以前のモデルから学んだことを使用し

991
00:39:36,680 --> 00:39:39,440


992
00:39:39,440 --> 00:39:42,079


993
00:39:42,079 --> 00:39:43,920
、それをディープニューロンだけに適用するということでした。

994
00:39:43,920 --> 00:39:46,200
ネットワークとここにあるアイデアは、

995
00:39:46,200 --> 00:39:49,040
基本的にはすでに

996
00:39:49,040 --> 00:39:50,880


997
00:39:50,880 --> 00:39:54,800
この世代のインプットをいくつかの

998
00:39:54,800 --> 00:39:57,960
アウトプットに持っていますが、それを

999
00:39:57,960 --> 00:39:59,440
フリーエネルギー原理に適用するために欠けているのは、

1000
00:39:59,440 --> 00:40:01,359


1001
00:40:01,359 --> 00:40:03,920
常に必要となるこのフィードバックです。アイデアは私たちが入れたものです。

1002
00:40:03,920 --> 00:40:06,960
ここは非常に軽量で、ええとフィードバック

1003
00:40:06,960 --> 00:40:09,480
ネットワークですので、基本的に、

1004
00:40:09,480 --> 00:40:11,800
このディープ ニューラル ネットワーク内の各ブロックには、

1005
00:40:11,800 --> 00:40:15,319


1006
00:40:15,319 --> 00:40:18,520
ローカルでターゲットを生成するフィードバック ブロックが伴います。つまり、

1007
00:40:18,520 --> 00:40:20,240


1008
00:40:20,240 --> 00:40:21,760
私たちが持っている最も単純なケースでは、これは非常に

1009
00:40:21,760 --> 00:40:24,640
最近のことです。 これまで線形ブロックのみを使用していた

1010
00:40:24,640 --> 00:40:27,480
ので、これらは単一の線形層であり

1011
00:40:27,480 --> 00:40:29,160
、ここでこれらの

1012
00:40:29,160 --> 00:40:32,040
出力をこれらのフィードバック ブロックで生成し

1013
00:40:32,040 --> 00:40:34,040
、その後、自由エネルギー原理を使用して、

1014
00:40:34,040 --> 00:40:38,119
ああ、ローカル損失を導き出し、

1015
00:40:38,119 --> 00:40:40,920
これらの両方を再び最小限に抑えることができます。

1016
00:40:40,920 --> 00:40:43,000
ここにあるフィードバックの重みと、

1017
00:40:43,000 --> 00:40:45,119
フォワード

1018
00:40:45,119 --> 00:40:48,079
ネットワークの重みもそうです えー、基本的には同じ

1019
00:40:48,079 --> 00:40:49,960
考え方です。ここにこれらの出力があり、これを

1020
00:40:49,960 --> 00:40:52,960


1021
00:40:52,960 --> 00:40:54,800
確率関数のパラメーターとして解釈するので、

1022
00:40:54,800 --> 00:40:57,240
この確率的フレームワークを適用できます。

1023
00:40:57,240 --> 00:40:59,040
残りは基本的に

1024
00:40:59,040 --> 00:41:01,359
同じ方法で展開されるので、

1025
00:41:01,359 --> 00:41:04,040
これらの出力は本質的に

1026
00:41:04,040 --> 00:41:06,599
このモデルの内部状態であると仮定し、

1027
00:41:06,599 --> 00:41:10,480


1028
00:41:10,480 --> 00:41:14,000
入力とターゲットで与えられる観察結果を取得し、

1029
00:41:14,000 --> 00:41:17,880
基本的に P を最小化しようとします。

1030
00:41:17,880 --> 00:41:19,640
これで、このフィード フォワード ネットワークになり、

1031
00:41:19,640 --> 00:41:23,480
Q は、えー

1032
00:41:23,480 --> 00:41:26,319


1033
00:41:26,319 --> 00:41:31,119
、フィードバックとフィード フォワード

1034
00:41:31,119 --> 00:41:33,880
ネットワークの両方の機能を含む関数になります。

1035
00:41:33,880 --> 00:41:36,160


1036
00:41:36,160 --> 00:41:38,880
ここで詳細を説明しますが、これを書き出すと、

1037
00:41:38,880 --> 00:41:43,200
えーっと、これは実際に

1038
00:41:43,200 --> 00:41:45,079
このロック項を分解し、

1039
00:41:45,079 --> 00:41:49,200


1040
00:41:49,200 --> 00:41:50,920
ここでローカルな損失を与えるローカルな線形項に分解するので、

1041
00:41:50,920 --> 00:41:52,960
基本的に、ここで

1042
00:41:52,960 --> 00:41:55,520
B と

1043
00:41:55,520 --> 00:41:59,560
対応するフィードバック ブロックの間のローカルなブロックを最小化できることがわかります。 ええと、損失

1044
00:41:59,560 --> 00:42:01,839
関数で、これを実際に並行して行うことができます。

1045
00:42:01,839 --> 00:42:05,680
なぜなら、

1046
00:42:05,680 --> 00:42:07,800
絵はここで見るのが良いからです。それで、

1047
00:42:07,800 --> 00:42:09,000
今しなければならないことは、

1048
00:42:09,000 --> 00:42:10,720
このフィードバックブロックがあるため、少しオーバーヘッドがあります。

1049
00:42:10,720 --> 00:42:15,200
したがって、これは 2 つになります。 えー、

1050
00:42:15,200 --> 00:42:18,359
フィードフォワード

1051
00:42:18,359 --> 00:42:20,160
ブロックとフィードバック

1052
00:42:20,160 --> 00:42:23,359
ブロックの実行時間ですが、原理的には並行して実行できます。

1053
00:42:23,359 --> 00:42:25,920
えー、フォワードブロックが

1054
00:42:25,920 --> 00:42:28,400
完了すると、次のフォワードブロックがこのネットワークを介して伝播を開始できます。

1055
00:42:28,400 --> 00:42:30,079


1056
00:42:30,079 --> 00:42:33,079
ええと、同時に

1057
00:42:33,079 --> 00:42:34,880
フォワードブロックがすでに

1058
00:42:34,880 --> 00:42:37,880
受信されているため、 ここのターゲットは重みの更新を開始できます。

1059
00:42:37,880 --> 00:42:40,520
それが完了すると、

1060
00:42:40,520 --> 00:42:43,119
次のエポックで自由に操作できるようになります。そのため、

1061
00:42:43,119 --> 00:42:45,760
このフレーム

1062
00:42:45,760 --> 00:42:48,040


1063
00:42:48,040 --> 00:42:50,880
ワークではもうロックはありません。それで、ほぼ

1064
00:42:50,880 --> 00:42:53,119
完了しました。私も時間切れです。そう思います

1065
00:42:53,119 --> 00:42:55,359
これはどのように実行されますか

1066
00:42:55,359 --> 00:42:56,720
もちろん、学習アルゴリズムを変更しましたが、

1067
00:42:56,720 --> 00:42:59,720
戻って、これが

1068
00:42:59,720 --> 00:43:03,280
まだ同じパフォーマンスを提供しているかどうかを確認する必要があります。

1069
00:43:03,280 --> 00:43:06,480
そして、実際には、私が言ったように、

1070
00:43:06,480 --> 00:43:09,400
これが最初の結果です。

1071
00:43:09,400 --> 00:43:15,559
今ここにいて、少なくとも

1072
00:43:15,559 --> 00:43:18,280
Cypher 10などのミッドスケールのデータセットでは、これは

1073
00:43:18,280 --> 00:43:20,440
実際に非常にうまく機能するようですので、リセット

1074
00:43:20,440 --> 00:43:22,160


1075
00:43:22,160 --> 00:43:24,559


1076
00:43:24,559 --> 00:43:29,880
15と解像度18を備えた標準アーキテクチャのファッションマニスト用に試していますが、これまでのところほとんど作業していました。

1077
00:43:29,880 --> 00:43:32,160
ファッションアミストのようなデータセットです

1078
00:43:32,160 --> 00:43:35,160
無料の分割を適用して

1079
00:43:35,160 --> 00:43:37,640
50 をリセットします ネットワークが深くなるにつれて、基本的に

1080
00:43:37,640 --> 00:43:40,040
標準のバックロップと同じパフォーマンスが得られます えー、実際にあることがわかります

1081
00:43:40,040 --> 00:43:42,680
ええと、

1082
00:43:42,680 --> 00:43:44,880


1083
00:43:44,880 --> 00:43:47,079
私たちが現在抱えている問題は実際には過剰適合です

1084
00:43:47,079 --> 00:43:48,599
これらのローカルデータがあるため

1085
00:43:48,599 --> 00:43:50,280
これらの小さなブロックは、実際には

1086
00:43:50,280 --> 00:43:53,079
ある程度オーバーフィットしているようです。これは、

1087
00:43:53,079 --> 00:43:55,800
Cypher t のようなタスクまではそれほど深刻ではないので、すでに

1088
00:43:55,800 --> 00:43:58,839
かなり近づいていますが、ここで

1089
00:43:58,839 --> 00:44:01,520
本当に大きなタスクに取り組む場合は、

1090
00:44:01,520 --> 00:44:04,480


1091
00:44:04,480 --> 00:44:06,839
うーん、まだ何かが欠けています。 単一の分割のように、

1092
00:44:06,839 --> 00:44:09,000
そこには到達していますが、バックプロパゲーションまでは到達していませんが、

1093
00:44:09,000 --> 00:44:11,559


1094
00:44:11,559 --> 00:44:13,119


1095
00:44:13,119 --> 00:44:18,240
この原則を

1096
00:44:18,240 --> 00:44:21,160
この標準的な機械学習

1097
00:44:21,160 --> 00:44:23,599
アルゴリズムにも適用できることはまだ興味深いです。わかりました、これは私の 2 番目の

1098
00:44:23,599 --> 00:44:26,240
要約です。 実は私たちは、

1099
00:44:26,240 --> 00:44:28,040
ディープ Nur ネットワークが

1100
00:44:28,040 --> 00:44:31,720
確率空間の一般化に驚くほど優れていることを発見しました。

1101
00:44:31,720 --> 00:44:33,839
これが実際にこの研究が

1102
00:44:33,839 --> 00:44:36,760
始まった方法です。私たちのアイデアは、

1103
00:44:36,760 --> 00:44:39,920
これを活用して、

1104
00:44:39,920 --> 00:44:41,680
これと同じ方法で学習を分散するために利用することでした。

1105
00:44:41,680 --> 00:44:44,040
最初のプロジェクトでお

1106
00:44:44,040 --> 00:44:48,000
見せしたのは、フィードバック ネットワークを

1107
00:44:48,000 --> 00:44:50,359
生成することでこの単位割り当ての問題を解決するということです。

1108
00:44:50,359 --> 00:44:52,160


1109
00:44:52,160 --> 00:44:55,760
ええと、基本的にはこれで終わりです。

1110
00:44:55,760 --> 00:44:58,680
そして、

1111
00:44:58,680 --> 00:45:01,000
同僚と学生に感謝したいので、私には

1112
00:45:01,000 --> 00:45:05,480
とても優秀な博士課程の学生が 2 人います。  KHと

1113
00:45:05,480 --> 00:45:08,400
cabelは今bomに来ていて、

1114
00:45:08,400 --> 00:45:11,680
このテーマに取り組んでいます。そして私が最初に

1115
00:45:11,680 --> 00:45:14,760
見せたプロジェクトはBでした。

1116
00:45:14,760 --> 00:45:17,640
クリスチャンTLと一緒にグタンにいたときに一緒に行いました。

1117
00:45:17,640 --> 00:45:20,559
そして、このプロジェクトは

1118
00:45:20,559 --> 00:45:22,800
私が密接に協力した仕事です

1119
00:45:22,800 --> 00:45:24,880
クリスチャン・ミーとアナン・

1120
00:45:24,880 --> 00:45:26,599
スプロン、

1121
00:45:26,599 --> 00:45:29,760
そしてええ、

1122
00:45:30,520 --> 00:45:32,920
ありがとう、ありがとう、デヴィッド、本当に

1123
00:45:32,920 --> 00:45:35,040
興味深かったです、第一原理から導出したと考えると同じような

1124
00:45:35,040 --> 00:45:37,559
モデルが生物学とどれほど厳密に一致しているかは信じられないほどだと思います、

1125
00:45:37,559 --> 00:45:39,599


1126
00:45:39,599 --> 00:45:41,359


1127
00:45:41,359 --> 00:45:43,760
それは本当にクールだったと思います、ええと、質問がありました

1128
00:45:43,760 --> 00:45:45,800


1129
00:45:45,800 --> 00:45:47,720


1130
00:45:47,720 --> 00:45:49,760
畳み込みネットワークについて話した最後の部分ですが、

1131
00:45:49,760 --> 00:45:51,079
伝統的には

1132
00:45:51,079 --> 00:45:53,400
エンドツーエンドで最後まで実行する必要があり、それは非常に非効率的であると述べました。

1133
00:45:53,400 --> 00:45:54,960
その後、エネルギー消費を調べて得られた結果を示しました。

1134
00:45:54,960 --> 00:45:57,240


1135
00:45:57,240 --> 00:46:00,839
あなたも一緒に、えー、まだです、それで、

1136
00:46:00,839 --> 00:46:02,520
私たちは実際に現在

1137
00:46:02,520 --> 00:46:06,760
取り組んでいます、それで、これを、標準の機械学習、えー、ツールボックス

1138
00:46:06,760 --> 00:46:09,040
にこれらのことを実装するのは実際にはそれほど簡単ではありません、えー、

1139
00:46:09,040 --> 00:46:10,880


1140
00:46:10,880 --> 00:46:14,319
私たちが持っているので、カルは現在

1141
00:46:14,319 --> 00:46:17,400
これを検討しています、えー、PHD  Dron の学生

1142
00:46:17,400 --> 00:46:20,160
です、彼は現在実装を行っており、実際に

1143
00:46:20,160 --> 00:46:22,359


1144
00:46:22,359 --> 00:46:25,520
この解析をどの程度うまく活用できるかを評価中です

1145
00:46:25,520 --> 00:46:28,359
が、私たちは

1146
00:46:28,359 --> 00:46:32,119
実際にこの解析を

1147
00:46:32,119 --> 00:46:36,640
麻痺させるためのもので

1148
00:46:36,640 --> 00:46:38,960
あると確信しています。

1149
00:46:38,960 --> 00:46:41,400
エネルギーの面で節約できるのは、

1150
00:46:41,400 --> 00:46:43,440


1151
00:46:43,440 --> 00:46:47,720
現在使用している小規模なモデルの場合、リセット 18 リセット 15 です。効果は

1152
00:46:47,720 --> 00:46:50,319
それほど大きくないかもしれないので、

1153
00:46:50,319 --> 00:46:52,000
これを実際に大きなモデルに増やしたら、

1154
00:46:52,000 --> 00:46:54,400
効果はさらに大きくなるはずですが、はい、これは

1155
00:46:54,400 --> 00:46:56,480
進行中の作業です。

1156
00:46:56,480 --> 00:46:58,920
とてもクールです、ありがとうございます。それから私も疑問に

1157
00:46:58,920 --> 00:47:00,760
思ったのですが、この

1158
00:47:00,760 --> 00:47:03,119
ローカルエラー逆伝播は、

1159
00:47:03,119 --> 00:47:04,960
他の人が

1160
00:47:04,960 --> 00:47:06,520
畳み込みニューラルネットワークで試したことがあるものですか、

1161
00:47:06,520 --> 00:47:08,880
それともこれは非常に新しい実装方法なのでしょうか？

1162
00:47:08,880 --> 00:47:11,680


1163
00:47:11,680 --> 00:47:14,280
これを行うアプローチなので、

1164
00:47:14,280 --> 00:47:16,000
たとえば、最も近いのは

1165
00:47:16,000 --> 00:47:18,040
ターゲット伝播だと思います。これは

1166
00:47:18,040 --> 00:47:20,440
基本的にランダムなフィードバックの重みを使用して

1167
00:47:20,440 --> 00:47:23,640


1168
00:47:23,640 --> 00:47:25,359
ここで逆伝播するため、これらの人たちは

1169
00:47:25,359 --> 00:47:27,720
訓練されません、

1170
00:47:28,000 --> 00:47:32,520
ええと、私が知っている限りでは、これは提案されています これはうまくいきます

1171
00:47:32,520 --> 00:47:35,559
これは小規模な問題でもうまくいきます

1172
00:47:35,559 --> 00:47:38,160
が、私の知る限りでは、

1173
00:47:38,160 --> 00:47:40,280


1174
00:47:40,280 --> 00:47:42,319
暗号 10 の場合でもそれほどうまく機能しません。

1175
00:47:42,319 --> 00:47:43,599
これらのランダムな

1176
00:47:43,599 --> 00:47:46,160
フィードバックの重みは近似が粗すぎるため、すでに壊れ始めています

1177
00:47:46,160 --> 00:47:48,559
そして、これが

1178
00:47:48,559 --> 00:47:52,760
最初です ええと、まあ、多分注意する必要があります

1179
00:47:52,760 --> 00:47:56,079
これは、

1180
00:47:56,079 --> 00:47:58,240
このフィードバックの

1181
00:47:58,240 --> 00:48:01,200
重みをトレーニングできる、対照的な方法ではない最初の方法だと思います。

1182
00:48:01,200 --> 00:48:03,079


1183
00:48:03,079 --> 00:48:05,559
対照的なステップを使用する方法はたくさんあり

1184
00:48:05,559 --> 00:48:08,040
ます。 このフォワードフォワードアルゴリズムなどを見たかもしれません

1185
00:48:08,040 --> 00:48:10,800


1186
00:48:10,800 --> 00:48:13,040
が、彼らが常にしなければならないのは、

1187
00:48:13,040 --> 00:48:14,830


1188
00:48:14,830 --> 00:48:16,160
[音楽]を送信し、

1189
00:48:16,160 --> 00:48:19,319
実際の入力データを送信し

1190
00:48:19,319 --> 00:48:22,480
、それから一種のアンチ入力を送信する

1191
00:48:22,480 --> 00:48:26,520
ことです。 ああ、

1192
00:48:26,520 --> 00:48:29,000
通常は人工的に生成されるので、それを

1193
00:48:29,000 --> 00:48:31,040
作成するために入力に歪みを加えてから

1194
00:48:31,040 --> 00:48:33,839
トレーニングします。

1195
00:48:33,839 --> 00:48:36,960


1196
00:48:36,960 --> 00:48:38,640
更新を行うには両方の情報をローカルで使用する必要があるため、ネットワークは

1197
00:48:38,640 --> 00:48:41,440
入力とアンチ入力をメモリに保持する必要があります。

1198
00:48:41,440 --> 00:48:44,440
応答と

1199
00:48:44,440 --> 00:48:48,200
これにより、このアプローチを

1200
00:48:48,200 --> 00:48:50,880
並列化するのが少し難しくなります。

1201
00:48:50,880 --> 00:48:54,280
ここでの良い点は、順伝播によって完全に説明できる

1202
00:48:54,280 --> 00:48:57,440
変分

1203
00:48:57,440 --> 00:49:00,960
自由エネルギー損失の上限を導き出すことです。

1204
00:49:00,960 --> 00:49:03,680


1205
00:49:03,680 --> 00:49:05,960
新しいと思うので、それが

1206
00:49:05,960 --> 00:49:08,480
この[音楽]の新しい部分です、

1207
00:49:08,480 --> 00:49:11,550


1208
00:49:11,680 --> 00:49:15,520
とても

1209
00:49:15,720 --> 00:49:19,720
素晴らしいです、そうですね、コメントはほとんどありません、あなたの

1210
00:49:19,720 --> 00:49:21,640
2人の

1211
00:49:21,640 --> 00:49:24,280
話の間の1つの部分は、少なくとも

1212
00:49:24,280 --> 00:49:25,880
私にとっては新しい区別であり、それが

1213
00:49:25,880 --> 00:49:27,319
違いでした ニューロモーフィック

1214
00:49:27,319 --> 00:49:29,920
ハードウェアとニューロモーフィック

1215
00:49:29,920 --> 00:49:33,640
アルゴリズムの間にあるので、単に新しい

1216
00:49:33,640 --> 00:49:35,520
ハードウェアや

1217
00:49:35,520 --> 00:49:39,240
ウェットウェアに関するものではありませんが、サラがスパイクについて言及したように、今日

1218
00:49:39,240 --> 00:49:40,760


1219
00:49:40,760 --> 00:49:45,839


1220
00:49:45,839 --> 00:49:47,599


1221
00:49:47,599 --> 00:49:51,440
私たちが持っているハードウェア上のアルゴリズムを使用するこの中間または橋渡しのステップがあるように見えるのは素晴らしいことです

1222
00:49:51,440 --> 00:49:54,160


1223
00:49:54,160 --> 00:49:56,240


1224
00:49:56,240 --> 00:49:59,880
GPU に適したニューラル ネットワーク、または

1225
00:49:59,880 --> 00:50:04,079
標準化された CPU マルチコア スケジューリング

1226
00:50:04,079 --> 00:50:07,000
アプローチを使用するだけで、

1227
00:50:07,000 --> 00:50:09,799


1228
00:50:09,799 --> 00:50:13,559
ニューロモーフィック アルゴリズムを使用すると、すでに私たちが持っているものでさらに多くのことができる

1229
00:50:13,559 --> 00:50:18,640
ため、材料科学のトピックだけでなく、

1230
00:50:18,640 --> 00:50:22,040


1231
00:50:22,040 --> 00:50:24,640
本当にミクロなスケールで多くのことが可能になります。

1232
00:50:24,640 --> 00:50:26,920
ノイズ処理のスケジューリングに関連して学習でき

1233
00:50:26,920 --> 00:50:28,599
、より高い抽象レベルでも

1234
00:50:28,599 --> 00:50:30,559
おそらく

1235
00:50:30,559 --> 00:50:32,720
生体模倣や認知システムからより

1236
00:50:32,720 --> 00:50:34,839
一般的に学習できますが、それは

1237
00:50:34,839 --> 00:50:37,240


1238
00:50:37,240 --> 00:50:40,839
私にとって区別のようでした、そう、だからおそらく追加するかもしれません、それで

1239
00:50:40,839 --> 00:50:43,720
問題は次のようになると思います

1240
00:50:43,720 --> 00:50:46,640
これらの

1241
00:50:46,640 --> 00:50:49,000
ニューロモーフィックなデバイスがより成熟し、

1242
00:50:49,000 --> 00:50:51,119
ハードウェア デバイスがより

1243
00:50:51,119 --> 00:50:53,839
成熟するにつれて、

1244
00:50:53,839 --> 00:50:57,520
これらの標準的な

1245
00:50:57,520 --> 00:50:59,119
機械学習アルゴリズムでは通常、実際には GPU 用に

1246
00:50:59,119 --> 00:51:01,280
最適化されているため、実際に機能することができない

1247
00:51:01,280 --> 00:51:04,319
ため、少し考える必要があります。

1248
00:51:04,319 --> 00:51:06,079


1249
00:51:06,079 --> 00:51:08,680


1250
00:51:08,680 --> 00:51:11,960
それらを実際に最大限に活用するには、一歩下がってアルゴリズムの側面についてもう一度考える必要があります。

1251
00:51:11,960 --> 00:51:13,960
また、ご覧のとおり、

1252
00:51:13,960 --> 00:51:16,480


1253
00:51:16,480 --> 00:51:18,839


1254
00:51:18,839 --> 00:51:20,720
Dron でこの Spiner チップを開発しているマヤ教授と協力していることもわかりましたが、他にもあります。

1255
00:51:20,720 --> 00:51:23,359
サラがインテルなどの L チップについて言及したようなアプローチです。

1256
00:51:23,359 --> 00:51:26,319
彼らは

1257
00:51:26,319 --> 00:51:29,520
今これを真剣に検討しており、

1258
00:51:29,520 --> 00:51:31,960
アルゴリズムの

1259
00:51:31,960 --> 00:51:34,520
側面からも検討しています。これは非常に便利だと思います。これは、私が考えるときの

1260
00:51:34,520 --> 00:51:36,520
考え方や精神的なフレームワークのようなものです。

1261
00:51:36,520 --> 00:51:38,839
コンピューター、あるいは AI

1262
00:51:38,839 --> 00:51:39,760
と私 これはおそらく私が

1263
00:51:39,760 --> 00:51:40,920
神経科学者であるためですが、

1264
00:51:40,920 --> 00:51:43,040
脳はどのように機能するのか、

1265
00:51:43,040 --> 00:51:44,680


1266
00:51:44,680 --> 00:51:46,880
脳内での情報処理はどのように機能するのか、そして私が

1267
00:51:46,880 --> 00:51:48,480
コンピューター サイエンスと AI のようなものに出会ったのはいつなのかをうまく翻訳する必要があります。

1268
00:51:48,480 --> 00:51:49,920
神経科学の後、私は

1269
00:51:49,920 --> 00:51:51,720
自然にそれを翻訳していることに気づきましたが、このフレーム

1270
00:51:51,720 --> 00:51:53,760
ワークは、

1271
00:51:53,760 --> 00:51:56,000
結局のところ、コンピューターを理解するのに非常に役立つ方法だと感じています。

1272
00:51:56,000 --> 00:51:57,319
なぜなら、私たちの脳は、先ほども言ったように

1273
00:51:57,319 --> 00:51:59,280
巨大なスーパーコンピューターであり

1274
00:51:59,280 --> 00:52:01,079
、私は常にコンピューターで論文を読んでいるからです。

1275
00:52:01,079 --> 00:52:02,599
科学でも何でも、

1276
00:52:02,599 --> 00:52:04,680
それから実際に何かを概念化でき、

1277
00:52:04,680 --> 00:52:07,520


1278
00:52:07,520 --> 00:52:09,880
これがどの程度ニューロモーフィックに近いのかを概念化できます。次に、

1279
00:52:09,880 --> 00:52:11,440
どのように微

1280
00:52:11,440 --> 00:52:12,520
調整すればもう少しニューロ

1281
00:52:12,520 --> 00:52:14,079
モーフィックになれるのか、そしてそれによって

1282
00:52:14,079 --> 00:52:15,839
これらの利益が得られるのかをよく考え始めます。 私たちが脳で理解するのは、

1283
00:52:15,839 --> 00:52:17,040


1284
00:52:17,040 --> 00:52:19,319
追加の並列計算のようなものを提供するのか、それとも

1285
00:52:19,319 --> 00:52:20,559
エネルギー効率を提供するのかということです。

1286
00:52:20,559 --> 00:52:23,480
そう、

1287
00:52:23,480 --> 00:52:24,599
定義を見ていたら、

1288
00:52:24,599 --> 00:52:26,000
定義と同じだと思いました。それは本当に

1289
00:52:26,000 --> 00:52:27,520
依存すると思います あなたの権利は定義であり、

1290
00:52:27,520 --> 00:52:30,079
それは現時点でも非常にダイナミックな領域であるため、

1291
00:52:30,079 --> 00:52:32,640
ええと、それは

1292
00:52:32,640 --> 00:52:34,079
変化しており、今後も

1293
00:52:34,079 --> 00:52:35,559
変化すると思いますが、私にとって

1294
00:52:35,559 --> 00:52:37,680
ニューロモーフィックは、より

1295
00:52:37,680 --> 00:52:39,559
精神的なフレームワークのようなものであるように感じます 概念化を通じて物事を見てください、

1296
00:52:39,559 --> 00:52:42,240


1297
00:52:42,400 --> 00:52:44,119
ええ、それも

1298
00:52:44,119 --> 00:52:47,920
あまり明確に定義されていないと思いますつまり、

1299
00:52:47,920 --> 00:52:50,319


1300
00:52:50,319 --> 00:52:52,359
人工ニューロンネットワークは実際には

1301
00:52:52,359 --> 00:52:54,880
ニューロモーフィックな概念であるともおっしゃいましたが、お望みで

1302
00:52:54,880 --> 00:52:55,960
あれば、それらは

1303
00:52:55,960 --> 00:52:58,119
初日からのものであり、実際には

1304
00:52:58,119 --> 00:53:00,160
それです

1305
00:53:00,160 --> 00:53:02,400
これらが

1306
00:53:02,400 --> 00:53:04,960
Vector マシンをサポートし、

1307
00:53:04,960 --> 00:53:08,200
これらの代替モデルが登場した 90 年代あたりを見てみると、大成功の物語が正しいでしょう。しかし、

1308
00:53:08,200 --> 00:53:10,920
どれも

1309
00:53:10,920 --> 00:53:13,440
新しいニューロモーフィック アプローチを超えて生き残っていないので、

1310
00:53:13,440 --> 00:53:14,880
実際には非常に素晴らしいことですが、それでも

1311
00:53:14,880 --> 00:53:17,040
このコミュニケーション コミュニティが存在します。 それは、本物に到達するために、

1312
00:53:17,040 --> 00:53:19,119
脳にはもっと多くの機能を

1313
00:53:19,119 --> 00:53:22,400
組み込む必要があると考えています、

1314
00:53:22,400 --> 00:53:23,599


1315
00:53:23,599 --> 00:53:26,960
はい、だから、これは少し難しいと思います、

1316
00:53:26,960 --> 00:53:30,799


1317
00:53:30,799 --> 00:53:33,040
実際にはあまり明確に定義された用語ではありません、そしてあなたの研究から

1318
00:53:33,040 --> 00:53:34,799
あなたのものだと思います これは、私がこれまで人々が見てきた中で最も小さなレベルに近いものです。他に

1319
00:53:34,799 --> 00:53:36,440


1320
00:53:36,440 --> 00:53:37,880
何かを見たことがあるかどうかはわかりませんが、

1321
00:53:37,880 --> 00:53:39,520


1322
00:53:39,520 --> 00:53:41,400
自由エネルギーと能動推論の細胞レベルのようなことだけを話しているのではありません。

1323
00:53:41,400 --> 00:53:43,040
実際に

1324
00:53:43,040 --> 00:53:46,599
細胞構造のようなものについて話して、

1325
00:53:46,599 --> 00:53:48,319
それからそれがどのくらい小さいのかよく考えてください、私たちは

1326
00:53:48,319 --> 00:53:49,960


1327
00:53:49,960 --> 00:53:51,559


1328
00:53:51,559 --> 00:53:53,559
最終的にはあなたが知っているミトコンドリアのような細胞内構造について話します、

1329
00:53:53,559 --> 00:53:55,160
化合物コンパートメントと同様の方法で自由エネルギーを使用します、

1330
00:53:55,160 --> 00:53:56,760
そしてええ、

1331
00:53:56,760 --> 00:53:57,920
実際にはそう思います ' 意見を聞くのは興味深いです

1332
00:53:57,920 --> 00:53:59,960
デビッド、

1333
00:53:59,960 --> 00:54:02,520
最初にサインアップがどのように

1334
00:54:02,520 --> 00:54:05,319
区画化されているかについて話しましたが、

1335
00:54:05,319 --> 00:54:07,599
これを 1 つのサインアップ

1336
00:54:07,599 --> 00:54:09,480
内でさまざまなコンパートメントに異なる種類のインスタンス化することはできますか?

1337
00:54:09,480 --> 00:54:11,480


1338
00:54:11,480 --> 00:54:13,359
その粒度のレベルですか、それとも、

1339
00:54:13,359 --> 00:54:14,880


1340
00:54:14,880 --> 00:54:16,079
ここから学んだことを取り入れて、

1341
00:54:16,079 --> 00:54:17,760


1342
00:54:17,760 --> 00:54:19,440
AI をより

1343
00:54:19,440 --> 00:54:21,920
効率的にするにはどうすればよいかに戻します。ええと、

1344
00:54:21,920 --> 00:54:24,240
私たちは今、この方向にさらに進んでいます。

1345
00:54:24,240 --> 00:54:28,040
これを AI モデルに組み戻すにはどうしたらよいでしょう

1346
00:54:28,040 --> 00:54:31,359
か フリー エネルギーのことだと思います

1347
00:54:31,359 --> 00:54:32,960


1348
00:54:32,960 --> 00:54:34,839
フリー エネルギーの原理を使用するときは少し注意が必要です フリー エネルギーの原理は非常に

1349
00:54:34,839 --> 00:54:36,880
強力な一般的なフレームワークであり、

1350
00:54:36,880 --> 00:54:40,160
基本的に

1351
00:54:40,160 --> 00:54:41,359
[音楽] であれば

1352
00:54:41,359 --> 00:54:45,680
何にでも適用できます えーっと、

1353
00:54:45,680 --> 00:54:49,440


1354
00:54:49,440 --> 00:54:53,680
これをただ適用するだけで、最終的に有用な結果が得られるとは限りません えー、

1355
00:54:53,680 --> 00:54:56,119
基本的に、これは

1356
00:54:56,119 --> 00:54:58,040
実際にサイドプロジェクトとして始まったという意味ですが、これは私の

1357
00:54:58,040 --> 00:55:03,760
一種のパンデミックロックダウン

1358
00:55:03,760 --> 00:55:06,480
プロジェクトでした。 これについて興味があります。

1359
00:55:06,480 --> 00:55:09,119
そして、実際にこれを解決できるかどうかは、

1360
00:55:09,119 --> 00:55:10,680
サインアップは

1361
00:55:10,680 --> 00:55:12,839
おそらく十分に簡単だと思いますので、

1362
00:55:12,839 --> 00:55:15,520
書類に入るとき、

1363
00:55:15,520 --> 00:55:17,440
ある時点で

1364
00:55:17,440 --> 00:55:19,760
近似を行う必要があるため、通常は平均的なことを行うため、

1365
00:55:19,760 --> 00:55:22,960
最初のモードに進み、

1366
00:55:22,960 --> 00:55:25,240
その後、ニューロンであっても、より複雑な問題を解くことができます。

1367
00:55:25,240 --> 00:55:27,039


1368
00:55:27,039 --> 00:55:29,119
ニューロンまたは

1369
00:55:29,119 --> 00:55:31,160
ネットワークレベルに行くと、実際には困難です。

1370
00:55:31,160 --> 00:55:35,160
非常に複雑な数学ですが、洞の場合は実際には

1371
00:55:35,160 --> 00:55:36,599
十分に単純なので、

1372
00:55:36,599 --> 00:55:38,559
実際に実行できます これと、

1373
00:55:38,559 --> 00:55:39,880
正しい仮定を立てればすべてを詳しく説明します。そして、

1374
00:55:39,880 --> 00:55:42,640


1375
00:55:42,640 --> 00:55:44,559
これらのことを実際に導き出しただけで、それは

1376
00:55:44,559 --> 00:55:47,079


1377
00:55:47,079 --> 00:55:52,480
一種のゲームのようなものでした。私はそれを試してみましたが、

1378
00:55:52,480 --> 00:55:55,240


1379
00:55:55,240 --> 00:55:58,720
最終的には非常にうまく機能することが判明しました。 そうですね、そうですね、

1380
00:55:58,720 --> 00:56:01,200
あなたが

1381
00:56:01,200 --> 00:56:02,960
ミトコンドリアが好きなのかどうかはわかりませんが、あなたも

1382
00:56:02,960 --> 00:56:04,640
同じ原則を適用できると思いますが、

1383
00:56:04,640 --> 00:56:08,599
得られた結果が

1384
00:56:08,599 --> 00:56:11,079
意味のあるものになるかどうか、

1385
00:56:11,079 --> 00:56:12,240


1386
00:56:12,240 --> 00:56:14,960
または何らかの形で役立つかどうかはわかりません。

1387
00:56:14,960 --> 00:56:16,839
多くの時間を費やして、

1388
00:56:16,839 --> 00:56:18,839
最終的には何らかの結果が得られるのに、それが

1389
00:56:18,839 --> 00:56:19,240


1390
00:56:19,240 --> 00:56:20,440


1391
00:56:20,440 --> 00:56:23,000


1392
00:56:23,000 --> 00:56:25,599


1393
00:56:25,599 --> 00:56:28,720
常にリスクだ

1394
00:56:28,720 --> 00:56:31,000
ああ、

1395
00:56:31,000 --> 00:56:34,240
最初に、

1396
00:56:34,240 --> 00:56:36,480
Gia や非神経細胞タイプを含まない傾向にある神経システムのエージェントベースのモデルを作成しますが、

1397
00:56:36,480 --> 00:56:39,240


1398
00:56:39,240 --> 00:56:41,480
細胞がエージェントであるという二重の疑問の余地のない仮定のようなものですが、

1399
00:56:41,480 --> 00:56:43,200


1400
00:56:43,200 --> 00:56:48,079
その後、それは素晴らしい移行でした

1401
00:56:48,079 --> 00:56:50,319


1402
00:56:50,319 --> 00:56:53,440
壁を越えてボールを投げる人から見ると、それは結果の

1403
00:56:53,440 --> 00:56:56,000
部分的な可視化しかできないアクション中心のアプローチであり

1404
00:56:56,000 --> 00:56:57,960


1405
00:56:57,960 --> 00:57:01,079
、その後、それが

1406
00:57:01,079 --> 00:57:03,640
シナプスが

1407
00:57:03,640 --> 00:57:06,599
別の方法で陥っている正確なシナリオであるか、あるいは次の

1408
00:57:06,599 --> 00:57:09,640
ように設定されていた可能性があります。 ニューロンは、

1409
00:57:09,640 --> 00:57:12,319
私たちが地図を構築しているエージェントであり

1410
00:57:12,319 --> 00:57:15,119
、領域ではありません。したがって、あなたが

1411
00:57:15,119 --> 00:57:17,000
フリーエネルギー原則と述べたように、それは

1412
00:57:17,000 --> 00:57:19,359


1413
00:57:19,359 --> 00:57:22,720
すべての原則であり、

1414
00:57:22,720 --> 00:57:25,440
物事について原則に基づいた発言をすることだけが

1415
00:57:25,440 --> 00:57:27,319


1416
00:57:27,319 --> 00:57:30,119
賭けです。では、あなたへの私の質問は、

1417
00:57:30,119 --> 00:57:33,079
それでは何が起こるのかということだと思います それを役に立つようにしたり、

1418
00:57:33,079 --> 00:57:35,119


1419
00:57:35,119 --> 00:57:37,880
これらのモデルを学習したりいじったりする際に、

1420
00:57:37,880 --> 00:57:39,760
自由エネルギー

1421
00:57:39,760 --> 00:57:42,000
原理や能動推論を適用して、

1422
00:57:42,000 --> 00:57:44,079
それが研究の方向性に貢献していると感じた状況と、

1423
00:57:44,079 --> 00:57:46,440


1424
00:57:46,440 --> 00:57:47,960
遊んでいた状況で

1425
00:57:47,960 --> 00:57:50,119
うまくいったと感じた状況を区別しました。 論理的には、

1426
00:57:50,119 --> 00:57:52,480
フリーエネルギーの

1427
00:57:52,480 --> 00:57:55,000
原則は、

1428
00:57:55,000 --> 00:57:58,160
不完全な

1429
00:57:58,160 --> 00:58:01,440
情報を持っている状況では意味があると思います。つまり、

1430
00:58:01,440 --> 00:58:03,039
たとえばサインアップの場合は、すぐに

1431
00:58:03,039 --> 00:58:05,520
私たちが始めた質問は、

1432
00:58:05,520 --> 00:58:07,039
サインアップが解決しなければならないこの問題でした

1433
00:58:07,039 --> 00:58:09,039
それは、細胞体の状態について不完全な情報を持っているということです。

1434
00:58:09,039 --> 00:58:11,760


1435
00:58:11,760 --> 00:58:15,359
なぜなら、それは、この種のことしか見ていないからです。それは、

1436
00:58:15,359 --> 00:58:17,200


1437
00:58:17,200 --> 00:58:19,400
少なくともモデルの仮定であり、また、

1438
00:58:19,400 --> 00:58:22,119
実験者から得たものでは、彼らは

1439
00:58:22,119 --> 00:58:23,359
本質的にこの種の伝播作用だけを観察しているということです。

1440
00:58:23,359 --> 00:58:25,160
可能性があるので、

1441
00:58:25,160 --> 00:58:28,440
ソーマの状態についての単一のバイナリ変数が見えます。

1442
00:58:28,440 --> 00:58:31,960


1443
00:58:31,960 --> 00:58:35,440
したがって、本質的に、これは

1444
00:58:35,440 --> 00:58:39,480
不完全な情報の問題であり、エージェントが必要であるという

1445
00:58:39,480 --> 00:58:42,720
第二の要素でもあり、

1446
00:58:42,720 --> 00:58:45,599
何らかの形のエージェントが必要であると

1447
00:58:45,599 --> 00:58:46,960
思います。 フリーエネルギー

1448
00:58:46,960 --> 00:58:50,119
原理を主体性のないシステムに適用する

1449
00:58:50,119 --> 00:58:52,440
ので、閉ループで何かが環境と相互作用していない場合、

1450
00:58:52,440 --> 00:58:55,440


1451
00:58:55,440 --> 00:58:57,880
それは非常に大ざっぱになります。これらの

1452
00:58:57,880 --> 00:59:00,480


1453
00:59:00,480 --> 00:59:03,000


1454
00:59:03,000 --> 00:59:05,319
モデルは、これらのモデルがそうでないため、すでに危機に瀕していると思います。 実際にはエージェンシーはありません

1455
00:59:05,319 --> 00:59:07,079
が、少なくとも正しく

1456
00:59:07,079 --> 00:59:09,359
出力を生成するため、

1457
00:59:09,359 --> 00:59:11,839
これを環境との相互作用として考えることができますが、それを

1458
00:59:11,839 --> 00:59:14,760


1459
00:59:14,760 --> 00:59:17,599


1460
00:59:17,599 --> 00:59:21,039
失うとすぐに、

1461
00:59:22,400 --> 00:59:26,119
そう、

1462
00:59:26,119 --> 00:59:27,839
実際、サインアップの

1463
00:59:27,839 --> 00:59:31,319
場合も同じです。エージェンシーはこれだけです。えー、

1464
00:59:31,319 --> 00:59:33,880
実際にモデルにノイズを追加しているのは、

1465
00:59:33,880 --> 00:59:35,240
サインアップが

1466
00:59:35,240 --> 00:59:38,640
共観的に PR をトリガーし、これを

1467
00:59:38,640 --> 00:59:40,520
追加するためです。内部状態を使用して、適切な

1468
00:59:40,520 --> 00:59:41,480
量の

1469
00:59:41,480 --> 00:59:44,000
ノイズを追加します。 それはおそらくすでに

1470
00:59:44,000 --> 00:59:45,710
最小限のエージェンシーです あなたができる

1471
00:59:45,710 --> 00:59:48,799
[音楽] サラを

1472
00:59:48,799 --> 00:59:51,119
想像してみてください あなたが質問したいですか、それとも私が

1473
00:59:51,119 --> 00:59:52,599
質問してもいいです

1474
00:59:52,599 --> 00:59:54,920
ええと、私はただの

1475
00:59:54,920 --> 00:59:56,160
コメントでした、

1476
00:59:56,160 --> 00:59:58,280


1477
00:59:58,280 --> 01:00:00,440
人々が生物学について話すのと同じように、それは本物ではないと言う人もいるのと同じで、それは非常に興味深いと思います

1478
01:00:00,440 --> 01:00:02,400
科学というのはすべてがごちゃごちゃしていて騒がしいから

1479
01:00:02,400 --> 01:00:04,359
ですが、あなたのやり方は本当に面白いと思います。

1480
01:00:04,359 --> 01:00:06,039


1481
01:00:06,039 --> 01:00:07,559
シナプスノイズは実際には

1482
01:00:07,559 --> 01:00:10,000
不確実性を報告していると言っているようなものですから、その

1483
01:00:10,000 --> 01:00:11,480
本質ではおそらく実際には非常に

1484
01:00:11,480 --> 01:00:13,880
正確に報告しており、

1485
01:00:13,880 --> 01:00:15,359
生物学そのものではなく混乱した世界を報告しているのです。

1486
01:00:15,359 --> 01:00:16,920
めちゃくちゃなことになってるけど、それはただ

1487
01:00:16,920 --> 01:00:19,359
私が考えていたことだよ、ええと、あなたが

1488
01:00:19,359 --> 01:00:20,480


1489
01:00:20,480 --> 01:00:21,880
言ったように、これはロックダウンプロジェクトのようだと私も興味があったと思うけど、

1490
01:00:21,880 --> 01:00:23,920
私はただあなたがどのようにして

1491
01:00:23,920 --> 01:00:25,960
フリーエネルギーの原理にたどり着いたのか、どうやって

1492
01:00:25,960 --> 01:00:27,359
出会ったのかに興味があるの それはあなたが

1493
01:00:27,359 --> 01:00:29,240
すでによく知っていたものでしたか、

1494
01:00:29,240 --> 01:00:30,960
あなたのネットワークや同僚の一部が

1495
01:00:30,960 --> 01:00:32,359
それについて話していましたか、それとも

1496
01:00:32,359 --> 01:00:36,000
論文で偶然見つけましたか、つまり、

1497
01:00:36,000 --> 01:00:37,839
私は博士課程のときに

1498
01:00:37,839 --> 01:00:40,920
変分法に興味を持っていました。

1499
01:00:40,920 --> 01:00:44,319
それから確率論的手法について

1500
01:00:44,319 --> 01:00:46,680
読み始めて、

1501
01:00:46,680 --> 01:00:49,440
クリススタンスの論文をたくさん読みました。

1502
01:00:49,440 --> 01:00:53,079
そして、これは興味深いと思いました。

1503
01:00:53,079 --> 01:00:57,319
実際、私の博士課程の指導教官はいつも、

1504
01:00:57,319 --> 01:01:00,280


1505
01:01:00,280 --> 01:01:01,520
その

1506
01:01:01,520 --> 01:01:03,880
方向には行かないようにと私に勧めていました。 博士号を取得したので、これで

1507
01:01:03,880 --> 01:01:05,799
大丈夫だと思いました。

1508
01:01:05,799 --> 01:01:08,079
やりたいことができるようになりました。試してみてください。

1509
01:01:08,079 --> 01:01:10,039


1510
01:01:10,039 --> 01:01:12,400
それで、

1511
01:01:12,400 --> 01:01:15,319
次のステップとして、

1512
01:01:15,319 --> 01:01:17,400
あなたにとって、または実際に

1513
01:01:17,400 --> 01:01:19,799
これを実装しようとしている分野にとって、それが価値があると思いますか?

1514
01:01:19,799 --> 01:01:21,960


1515
01:01:21,960 --> 01:01:23,400
アナログ ニューロモーフィック チップのような、宇宙で構築されているアナログ

1516
01:01:23,400 --> 01:01:25,119
チップのいくつかです。

1517
01:01:25,119 --> 01:01:28,200
シナプスのダイナミック シナプスのような

1518
01:01:28,200 --> 01:01:29,799
ものを使用できることはわかっています。また、

1519
01:01:29,799 --> 01:01:31,839
独自のハードウェアを実装しようとすることに価値があると思いますか?

1520
01:01:31,839 --> 01:01:34,839


1521
01:01:34,839 --> 01:01:37,119
それについての考え ええと、

1522
01:01:37,119 --> 01:01:39,799
私が示したこの最初の作品から出てきたトリプレットルールのことを指します。

1523
01:01:39,799 --> 01:01:41,079


1524
01:01:41,079 --> 01:01:45,200
それを実装するのは興味深いと思います、ええと、それは素晴らしい機能です、

1525
01:01:45,200 --> 01:01:47,440
原理的には

1526
01:01:47,440 --> 01:01:49,359
これのようにあるべきであり、この自己

1527
01:01:49,359 --> 01:01:52,319
安定化が必要です この写真は本当に

1528
01:01:52,319 --> 01:01:56,640


1529
01:01:56,640 --> 01:01:59,839
細胞膜のダイナミクスを模倣しているので、

1530
01:01:59,839 --> 01:02:02,640
ニューロモーフィック ハードウェアがそうであれば、

1531
01:02:02,640 --> 01:02:04,640


1532
01:02:04,640 --> 01:02:08,079
サインアップのモデル

1533
01:02:08,079 --> 01:02:10,440
とニューロン モデルが非常に

1534
01:02:10,440 --> 01:02:13,680
よく一致する場合、そのモデルはあなたに与えるはずです。 この

1535
01:02:13,680 --> 01:02:16,400
素晴らしい自己安定化機能により、

1536
01:02:16,400 --> 01:02:19,160
ニューロンは実際にてんかん状態などに陥りません。

1537
01:02:19,160 --> 01:02:20,880


1538
01:02:20,880 --> 01:02:22,720
このモデルからこれを無料で入手できます。これは、

1539
01:02:22,720 --> 01:02:25,160
少なくともシミュレーションで確認されたものですが、

1540
01:02:25,160 --> 01:02:28,720
もちろんシミュレーションでは、

1541
01:02:28,720 --> 01:02:30,960
これを完全に制御できました ダイナミクスは

1542
01:02:30,960 --> 01:02:33,000
正しい方法で一致している

1543
01:02:33,000 --> 01:02:36,680
ので、

1544
01:02:36,680 --> 01:02:39,200
ハードウェアにとってはおそらくもう少しトリッキーですが、おそらく解決できるので

1545
01:02:39,200 --> 01:02:41,039
興味深いでしょう、そうすれば、

1546
01:02:41,039 --> 01:02:42,480
得られるものは、

1547
01:02:42,480 --> 01:02:44,520


1548
01:02:44,520 --> 01:02:48,599
プリポストスパイクのみを使用する純粋なイベントベースのツールを適切に使用できるということです それは

1549
01:02:48,599 --> 01:02:49,520


1550
01:02:49,520 --> 01:02:53,000
いいですね、とてもクールです、ありがとう、はい、ダニエル、

1551
01:02:53,000 --> 01:02:55,200
質問がありましたら、

1552
01:02:55,200 --> 01:02:58,559
それは素晴らしい原則です。これは、

1553
01:02:58,559 --> 01:03:00,319


1554
01:03:00,319 --> 01:03:03,240


1555
01:03:03,240 --> 01:03:06,599


1556
01:03:06,599 --> 01:03:08,640
膜の実際の漏洩透過性

1557
01:03:08,640 --> 01:03:12,599
や実際の空間的近接性などの物質的特徴を利用するようにニューロモーフィックアルゴリズムを設計できるかどうかに似ています。

1558
01:03:12,599 --> 01:03:15,640


1559
01:03:15,640 --> 01:03:19,000
仮想化されていないマテリアルのアナログ機能を活用できれば、それは

1560
01:03:19,000 --> 01:03:20,119
すでに

1561
01:03:20,119 --> 01:03:23,079
将来のハードウェアに隣接しているので、それは

1562
01:03:23,079 --> 01:03:25,760
1 つの素晴らしい点です。そして、

1563
01:03:25,760 --> 01:03:28,920
ほぼ生物学は科学ではないのと同様に、

1564
01:03:28,920 --> 01:03:32,520
有名な

1565
01:03:32,520 --> 01:03:34,480
引用がありますが、科学は決して存在しないということです。

1566
01:03:34,480 --> 01:03:36,839
草の葉にニュートンを、そう言う人もいるから、

1567
01:03:36,839 --> 01:03:38,839
それは違う生物学だという人もいるから、

1568
01:03:38,839 --> 01:03:41,079


1569
01:03:41,079 --> 01:03:42,680


1570
01:03:42,680 --> 01:03:44,880
生物学はむしろ歴史に似ている、なぜなら、これを開発や生態学、あるいは進化の観点からアプローチするかどうかに関係なく、生物学は

1571
01:03:44,880 --> 01:03:46,640
歴史科学であり、本当の科学とは似ていないのですが、

1572
01:03:46,640 --> 01:03:49,480
そのとき思い出したのが、

1573
01:03:49,480 --> 01:03:53,000
私たちのスポーツはあなたの罰であると書かれたクロスカントリーシャツだから、

1574
01:03:53,000 --> 01:03:55,000


1575
01:03:55,000 --> 01:03:58,319
あなたの

1576
01:03:58,319 --> 01:04:02,760
騒音が生物学の信号であり、それがどのように起こるかというと、それは似て非なるものであり、それがどのように

1577
01:04:02,760 --> 01:04:04,279


1578
01:04:04,279 --> 01:04:08,680
起こるか私の質問は、計算に関連するリソースを調べる

1579
01:04:08,680 --> 01:04:10,640


1580
01:04:10,640 --> 01:04:14,039
神経的方法と計算的方法の間の緊張についてのものでした。

1581
01:04:14,039 --> 01:04:16,760


1582
01:04:16,760 --> 01:04:19,440


1583
01:04:19,440 --> 01:04:23,720
フォン・ノイマンのパラダイムから、私たちは多くの共有基準点を持っています

1584
01:04:23,720 --> 01:04:27,720
CPU サイクル RAM

1585
01:04:27,720 --> 01:04:30,559
容量やその他すべての種類のこと、そして

1586
01:04:30,559 --> 01:04:34,520
あなたの紹介でも、これが

1587
01:04:34,520 --> 01:04:36,559


1588
01:04:36,559 --> 01:04:38,839
通過する CPU サイクルの数、

1589
01:04:38,839 --> 01:04:41,799
またはこれが持つパラメーターの数で

1590
01:04:41,799 --> 01:04:43,920
あることをよく伝えました

1591
01:04:43,920 --> 01:04:45,319


1592
01:04:45,319 --> 01:04:48,240
しかし、それは

1593
01:04:48,240 --> 01:04:53,160
別のパラダイムを参照しているので、

1594
01:04:53,160 --> 01:04:56,160


1595
01:04:56,880 --> 01:05:01,640


1596
01:05:01,640 --> 01:05:04,319


1597
01:05:04,319 --> 01:05:05,559


1598
01:05:05,559 --> 01:05:07,039
箱に入れて

1599
01:05:07,039 --> 01:05:09,079
爆弾熱量計を使用できるような消費電力の領域の外にいるとき、リソース記述子や容量記述子はどのように見えるのでしょうか？ 簡単に

1600
01:05:09,079 --> 01:05:12,520
実現できる果物のようなものだが、もう

1601
01:05:12,520 --> 01:05:15,760
大丈夫だ 純粋なエネルギーや

1602
01:05:15,760 --> 01:05:16,960
カロリー

1603
01:05:16,960 --> 01:05:19,319
要件を超えて、これはコンピューターの

1604
01:05:19,319 --> 01:05:21,880


1605
01:05:21,880 --> 01:05:25,200
プロセッサーやラム、ハード

1606
01:05:25,200 --> 01:05:27,759
ドライブについて話すのと似ていると言えるだろうか、

1607
01:05:30,000 --> 01:05:32,839
つまり、そうだ

1608
01:05:32,839 --> 01:05:34,279
それについてはもう少し考えなければなりません

1609
01:05:34,279 --> 01:05:35,200


1610
01:05:35,200 --> 01:05:37,240
私が見せたスライドの論文には、

1611
01:05:37,240 --> 01:05:39,520
脳とエネルギーについて話している興味深いコメントがいくつかあったと思います リンク先の

1612
01:05:39,520 --> 01:05:41,119
論文があり

1613
01:05:41,119 --> 01:05:42,359
ました 参照して、

1614
01:05:42,359 --> 01:05:43,839
それが何なのか教えてください。QR C がもうなくなってしまったからです。

1615
01:05:43,839 --> 01:05:46,520
えっと、でも、それにはいくつかの興味深い

1616
01:05:46,520 --> 01:05:48,920
アイデアがありました。あなたがそこに何を出しているかについては考えていますが、

1617
01:05:48,920 --> 01:05:52,880
そうですね、論文を待たなければなりません。つまり、何が

1618
01:05:52,880 --> 01:05:55,279


1619
01:05:55,279 --> 01:05:57,200
何であるかをどのように説明しているのでしょうか？

1620
01:05:57,200 --> 01:06:00,520
設計中、このタイプのコンポーネントがこれだけたくさんあると言っていますが、それは何も起こら

1621
01:06:00,520 --> 01:06:03,200


1622
01:06:03,200 --> 01:06:05,720


1623
01:06:05,720 --> 01:06:08,079


1624
01:06:08,079 --> 01:06:11,480


1625
01:06:11,640 --> 01:06:13,520
ないかもしれませんが、これらのさまざまな設計やアルゴリズムをどのように説明または評価しているのでしょうか。ユースケースに応じてすべて異なると思います。

1626
01:06:13,520 --> 01:06:14,799
それが

1627
01:06:14,799 --> 01:06:16,319
私が見つけたものです 言語の好みは、それが

1628
01:06:16,319 --> 01:06:18,520


1629
01:06:18,520 --> 01:06:20,440


1630
01:06:20,440 --> 01:06:21,480
神経科学のバックグラウンドを持つ人によって書かれたのか、それとも

1631
01:06:21,480 --> 01:06:23,799
エンジニアリングのバックグラウンドを持つ人によって書かれたのかによって異なります。そして、

1632
01:06:23,799 --> 01:06:25,279
いくつかの用語は

1633
01:06:25,279 --> 01:06:26,920
他の用語よりも互換性があるとおっしゃいましたが、

1634
01:06:26,920 --> 01:06:29,400
用語は同じだと思います そのスペースで

1635
01:06:29,400 --> 01:06:31,559
もっと詳しく検討する必要があるものです。

1636
01:06:31,559 --> 01:06:33,039
そうすれば、

1637
01:06:33,039 --> 01:06:35,599
そこで働いている全員が

1638
01:06:35,599 --> 01:06:38,799
同じ認識に少し

1639
01:06:42,079 --> 01:06:44,359
近づくのに役立つと思います。

1640
01:06:44,359 --> 01:06:47,960
その他の考えや質問はありますか。

1641
01:06:47,960 --> 01:06:51,440
最初にデビッド、次にサラも私です。」

1642
01:06:51,440 --> 01:06:55,480
このシリーズがどのような方向に

1643
01:06:55,480 --> 01:06:59,039
進むのか非常に興味がありますが、まずデビッド、その他に

1644
01:06:59,039 --> 01:07:02,119
締めくくりのコメントや指示があれば

1645
01:07:02,119 --> 01:07:03,359


1646
01:07:03,359 --> 01:07:07,000
教えてください。うーん、特にそうではありませんが、

1647
01:07:07,000 --> 01:07:09,480
今日は一緒に来てくれてありがとうと言いたいです。一緒に

1648
01:07:09,480 --> 01:07:11,279
話し合うことができて本当に楽しかったです。

1649
01:07:11,279 --> 01:07:13,359


1650
01:07:13,359 --> 01:07:15,720
ありがとう、デイビッド あなたに参加してもらえて本当によかったです

1651
01:07:15,720 --> 01:07:17,000
あなたの作品は

1652
01:07:17,000 --> 01:07:19,079
本当に魅力的だと思いますし、将来的

1653
01:07:19,079 --> 01:07:20,880
には実装に多くのメリットがあると思います、

1654
01:07:20,880 --> 01:07:23,400
それを

1655
01:07:23,400 --> 01:07:26,559
見るのはいつも嬉しいことです、ええと、それでは

1656
01:07:26,559 --> 01:07:27,760
質問は何でしたか、どこで

1657
01:07:27,760 --> 01:07:30,279
シリーズは続いていくのかな、できれば

1658
01:07:30,279 --> 01:07:33,720
毎月新しいゲストを迎えることができればいいのですが、

1659
01:07:33,720 --> 01:07:36,240
来月はハードウェアを

1660
01:07:36,240 --> 01:07:38,680
構築している人が参加できたらいいなと思います。

1661
01:07:38,680 --> 01:07:40,319


1662
01:07:40,319 --> 01:07:42,079
脳スケール チームかスピカ チームの誰かがいいかもしれません。 または

1663
01:07:42,079 --> 01:07:44,279
そのようなものはかなりクールだと思います

1664
01:07:44,279 --> 01:07:46,880
が、ええ、本当にこの交差点

1665
01:07:46,880 --> 01:07:49,119
に興味のある人々が、

1666
01:07:49,119 --> 01:07:52,359
えー、会ったり、

1667
01:07:52,359 --> 01:07:54,079
話を聞いたりするためのスペースを作りたいだけです。

1668
01:07:54,079 --> 01:07:56,520
そのスペースで働いている人たちに連絡してください。

1669
01:07:56,520 --> 01:07:59,319
かなりニッチだけど、これは

1670
01:07:59,319 --> 01:08:01,920
かなり重要なことだと思うんだけど、実際に

1671
01:08:01,920 --> 01:08:03,400
デヴィッドが言ってたんだけど、みんな

1672
01:08:03,400 --> 01:08:05,039
に連絡を取りたい場合はどうするのが

1673
01:08:05,039 --> 01:08:08,359
一番いいのかを伝えてもらえますか

1674
01:08:08,359 --> 01:08:09,390


1675
01:08:09,390 --> 01:08:11,400
[音楽]

1676
01:08:11,400 --> 01:08:13,960
えーっと、私はこれに関してはあまり積極的じゃないんです Discord

1677
01:08:13,960 --> 01:08:16,399
チャンネルなので、おそらくメールがまだ

1678
01:08:16,399 --> 01:08:19,158
私に連絡するのに最適です。

1679
01:08:19,158 --> 01:08:21,399


1680
01:08:21,399 --> 01:08:22,839
メールアドレスを教えていただけますか。

1681
01:08:22,839 --> 01:08:27,560
私のメールアドレスは簡単に

1682
01:08:27,560 --> 01:08:28,960
見つけられるはずですが、

1683
01:08:28,960 --> 01:08:30,600


1684
01:08:30,600 --> 01:08:33,439
短い人がチェックできるメールアドレスを公開することもできます。 論文、

1685
01:08:33,439 --> 01:08:36,000
そしてアクティブ推論研究所の

1686
01:08:36,000 --> 01:08:40,080
Discord にはニューロモーフィック

1687
01:08:41,120 --> 01:08:43,719
チャンネルがあります。はい、ありがとうデイビッドと

1688
01:08:43,719 --> 01:08:47,198
サラです。モーフ ストリームがこのように

1689
01:08:47,198 --> 01:08:49,158
発展軌道を開始するのを見るのは本当に素晴らしいです。

1690
01:08:49,158 --> 01:08:52,799
それでは次回まで、ありがとう、さようなら

1691
01:08:52,799 --> 01:08:54,109


1692
01:08:54,109 --> 01:08:57,169
[音楽]

1693
01:09:19,040 --> 01:09:22,040
いいです

