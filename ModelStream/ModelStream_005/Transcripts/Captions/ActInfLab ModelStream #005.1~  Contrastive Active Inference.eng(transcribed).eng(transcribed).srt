1
00:00:08,080 --> 00:00:09,120
okay

2
00:00:09,120 --> 00:00:12,080
hello and welcome everyone it is january

3
00:00:12,080 --> 00:00:13,080
28

4
00:00:13,080 --> 00:00:14,960
2022.

5
00:00:14,960 --> 00:00:17,600
we're here in academ lab model stream

6
00:00:17,600 --> 00:00:19,359
number 5.1

7
00:00:19,359 --> 00:00:22,800
with pietro mazzaglia and tim verbellen

8
00:00:22,800 --> 00:00:25,519
so this is going to be a model stream

9
00:00:25,519 --> 00:00:28,320
presentation and discussion on their

10
00:00:28,320 --> 00:00:31,199
recent work contrastive active inference

11
00:00:31,199 --> 00:00:33,360
we're going to have a presentation

12
00:00:33,360 --> 00:00:35,920
section and then a discussion

13
00:00:35,920 --> 00:00:38,480
so please feel free to ask any questions

14
00:00:38,480 --> 00:00:40,160
during the presentation that we can

15
00:00:40,160 --> 00:00:42,800
address in the discussion and tim and

16
00:00:42,800 --> 00:00:45,440
pietro thanks a ton we really appreciate

17
00:00:45,440 --> 00:00:48,320
you joining to share your work so please

18
00:00:48,320 --> 00:00:52,239
take it away and thanks again

19
00:00:52,399 --> 00:00:54,719
yeah thanks daniel for uh for inviting

20
00:00:54,719 --> 00:00:57,199
us as well so uh i'm timothy and

21
00:00:57,199 --> 00:00:58,640
together with the

22
00:00:58,640 --> 00:01:00,559
colleague pietro we'll talk on our work

23
00:01:00,559 --> 00:01:03,440
on contrastive active inference

24
00:01:03,440 --> 00:01:06,080
so maybe first to um

25
00:01:06,080 --> 00:01:08,240
set the scene why are we

26
00:01:08,240 --> 00:01:10,320
looking at active inference

27
00:01:10,320 --> 00:01:12,640
uh well basically our lab wants to build

28
00:01:12,640 --> 00:01:14,880
intelligent agents and so from that

29
00:01:14,880 --> 00:01:17,280
perspective we noticed early on if you

30
00:01:17,280 --> 00:01:19,200
want to build something intelligent

31
00:01:19,200 --> 00:01:21,600
it needs to be embodied it needs to be

32
00:01:21,600 --> 00:01:24,320
interacting with its environments

33
00:01:24,320 --> 00:01:27,439
and then it's a small step of course you

34
00:01:27,439 --> 00:01:28,960
know interactive inference where

35
00:01:28,960 --> 00:01:31,439
basically your your agent needs to

36
00:01:31,439 --> 00:01:33,119
understand the environment it's

37
00:01:33,119 --> 00:01:36,320
interacting with and and need to build

38
00:01:36,320 --> 00:01:37,840
the model basically

39
00:01:37,840 --> 00:01:39,680
so

40
00:01:39,680 --> 00:01:42,479
i'll first give an overview on on active

41
00:01:42,479 --> 00:01:44,320
inference and the way that that we

42
00:01:44,320 --> 00:01:45,840
approach this

43
00:01:45,840 --> 00:01:49,040
um a lot a lot of this material has also

44
00:01:49,040 --> 00:01:51,040
been covered uh in a previous model

45
00:01:51,040 --> 00:01:53,600
stream i think number number three uh so

46
00:01:53,600 --> 00:01:56,079
if you want more details you can pick up

47
00:01:56,079 --> 00:01:57,600
that one again

48
00:01:57,600 --> 00:02:00,880
um and so then afterwards um uh pieter

49
00:02:00,880 --> 00:02:03,520
will take over and he will um go into

50
00:02:03,520 --> 00:02:04,560
the

51
00:02:04,560 --> 00:02:07,520
details of the contrastive approach to

52
00:02:07,520 --> 00:02:11,120
active inference so let's get started

53
00:02:11,120 --> 00:02:12,560
so basically

54
00:02:12,560 --> 00:02:15,200
active inference it's a process theory

55
00:02:15,200 --> 00:02:16,480
of the brain

56
00:02:16,480 --> 00:02:18,800
and basically it says that your brain

57
00:02:18,800 --> 00:02:20,400
are the agents

58
00:02:20,400 --> 00:02:21,440
he builds

59
00:02:21,440 --> 00:02:23,920
or he builds generative model of the

60
00:02:23,920 --> 00:02:26,560
environment which is basically a joint

61
00:02:26,560 --> 00:02:29,520
probably distribution over observations

62
00:02:29,520 --> 00:02:33,519
so think that you can see or experience

63
00:02:33,519 --> 00:02:35,760
actions which we didn't know the scale

64
00:02:35,760 --> 00:02:39,680
and then um states or um

65
00:02:39,680 --> 00:02:40,640
yeah

66
00:02:40,640 --> 00:02:42,560
hidden states of the environment

67
00:02:42,560 --> 00:02:45,040
so basically you have your agent that is

68
00:02:45,040 --> 00:02:46,879
separate from the environment

69
00:02:46,879 --> 00:02:49,280
and it can do actions it can interact

70
00:02:49,280 --> 00:02:50,480
with the environment

71
00:02:50,480 --> 00:02:52,319
and this gives rise to new uh

72
00:02:52,319 --> 00:02:55,120
observations and so the idea of the

73
00:02:55,120 --> 00:02:56,959
generative model is biscuit agent

74
00:02:56,959 --> 00:02:58,319
figures out

75
00:02:58,319 --> 00:03:01,040
which are kind of the the hidden states

76
00:03:01,040 --> 00:03:02,080
that

77
00:03:02,080 --> 00:03:05,519
the change by my actions and that gave

78
00:03:05,519 --> 00:03:08,480
rise to my uh observations and if you

79
00:03:08,480 --> 00:03:11,360
can build such a model then basically uh

80
00:03:11,360 --> 00:03:14,720
this enables the agents to plan uh some

81
00:03:14,720 --> 00:03:15,840
actions

82
00:03:15,840 --> 00:03:18,480
to to bring the agent to some preferred

83
00:03:18,480 --> 00:03:20,959
observations or outcomes and support but

84
00:03:20,959 --> 00:03:21,840
so the

85
00:03:21,840 --> 00:03:25,120
crucial bits is basically how do you get

86
00:03:25,120 --> 00:03:27,680
this model um

87
00:03:27,680 --> 00:03:29,360
of what happens

88
00:03:29,360 --> 00:03:32,159
if i do my actions how does this

89
00:03:32,159 --> 00:03:34,000
influence the state and and how does

90
00:03:34,000 --> 00:03:38,000
this influence the outcomes that i see

91
00:03:38,000 --> 00:03:39,599
and so the crucial part connective

92
00:03:39,599 --> 00:03:41,680
inference is twofold so first of all it

93
00:03:41,680 --> 00:03:43,040
says okay

94
00:03:43,040 --> 00:03:44,560
this is what the agent does and it does

95
00:03:44,560 --> 00:03:47,120
so by optimizing so-called free energy

96
00:03:47,120 --> 00:03:48,959
which is an upper bound and surprise or

97
00:03:48,959 --> 00:03:50,570
prediction error so basically

98
00:03:50,570 --> 00:03:52,560
[Music]

99
00:03:52,560 --> 00:03:54,319
the generative model allows the agent to

100
00:03:54,319 --> 00:03:57,040
predict the outcomes that it will see

101
00:03:57,040 --> 00:03:58,480
that it will witness

102
00:03:58,480 --> 00:04:01,519
and um the better these match your

103
00:04:01,519 --> 00:04:04,080
actual observations the more happier you

104
00:04:04,080 --> 00:04:04,720
are

105
00:04:04,720 --> 00:04:06,400
as an agent

106
00:04:06,400 --> 00:04:09,280
and crucially you will also select the

107
00:04:09,280 --> 00:04:11,680
actions that will minimize

108
00:04:11,680 --> 00:04:13,840
the free energy you expect in the future

109
00:04:13,840 --> 00:04:14,959
and so we'll

110
00:04:14,959 --> 00:04:17,120
dig a bit into the mods

111
00:04:17,120 --> 00:04:18,399
um

112
00:04:18,399 --> 00:04:20,880
just to to set the scene uh on the one

113
00:04:20,880 --> 00:04:22,639
hand notation-wise so that we all know

114
00:04:22,639 --> 00:04:25,919
what folds and s's and a's are but also

115
00:04:25,919 --> 00:04:27,600
to then

116
00:04:27,600 --> 00:04:30,960
see the move that piet will make from

117
00:04:30,960 --> 00:04:34,320
the let's say valera active inference

118
00:04:34,320 --> 00:04:37,120
presentation towards a more contrastive

119
00:04:37,120 --> 00:04:38,880
formulation of of

120
00:04:38,880 --> 00:04:40,800
the active influence object reality

121
00:04:40,800 --> 00:04:42,960
objective

122
00:04:42,960 --> 00:04:45,600
so we start off with uh setting the c

123
00:04:45,600 --> 00:04:47,919
with a generative model so uh it's it's

124
00:04:47,919 --> 00:04:51,520
a bit laid out uh the the diagram of the

125
00:04:51,520 --> 00:04:53,680
agents and the environment that was on

126
00:04:53,680 --> 00:04:55,759
previous slides so basically this

127
00:04:55,759 --> 00:04:58,240
unfolds over time so you are in a

128
00:04:58,240 --> 00:05:00,560
certain state that gives rise to a

129
00:05:00,560 --> 00:05:03,039
certain observation and then given an

130
00:05:03,039 --> 00:05:04,479
action on your previous state you

131
00:05:04,479 --> 00:05:06,160
basically move ahead

132
00:05:06,160 --> 00:05:06,960
to

133
00:05:06,960 --> 00:05:08,639
the next state

134
00:05:08,639 --> 00:05:12,160
and this process unfolds over time

135
00:05:12,160 --> 00:05:15,840
and you can see um some of the um

136
00:05:15,840 --> 00:05:18,240
the circles are covered gray and these

137
00:05:18,240 --> 00:05:19,520
are basically the things that you can

138
00:05:19,520 --> 00:05:20,560
observe

139
00:05:20,560 --> 00:05:23,360
so you know the actions that you did up

140
00:05:23,360 --> 00:05:24,720
until now

141
00:05:24,720 --> 00:05:27,440
and you know the observations that you

142
00:05:27,440 --> 00:05:29,440
saw up until now

143
00:05:29,440 --> 00:05:31,520
and all the rest is basically for you to

144
00:05:31,520 --> 00:05:34,240
infer so you can only refer the hidden

145
00:05:34,240 --> 00:05:35,759
states until now

146
00:05:35,759 --> 00:05:38,479
but you can also try to infer the hidden

147
00:05:38,479 --> 00:05:40,639
states of the future the actions that

148
00:05:40,639 --> 00:05:42,720
you want to take or the observations

149
00:05:42,720 --> 00:05:44,960
that you will experience

150
00:05:44,960 --> 00:05:47,759
and so basically the um

151
00:05:47,759 --> 00:05:49,680
the so-called joint model or joint

152
00:05:49,680 --> 00:05:51,840
distribution over the sequence of

153
00:05:51,840 --> 00:05:54,240
observation states and action is then

154
00:05:54,240 --> 00:05:56,240
basically factorized as follows so you

155
00:05:56,240 --> 00:05:59,759
have a prior over actions

156
00:05:59,759 --> 00:06:02,240
uh you have a lightweight model so

157
00:06:02,240 --> 00:06:03,120
uh

158
00:06:03,120 --> 00:06:05,039
so yeah so you have prior over action so

159
00:06:05,039 --> 00:06:06,800
this basically determines yeah what is

160
00:06:06,800 --> 00:06:08,560
the probability you take certain actions

161
00:06:08,560 --> 00:06:09,759
certain time

162
00:06:09,759 --> 00:06:10,960
you have

163
00:06:10,960 --> 00:06:13,360
some transition probabilities so what is

164
00:06:13,360 --> 00:06:14,800
the probability that i

165
00:06:14,800 --> 00:06:17,120
i will transition to this next state

166
00:06:17,120 --> 00:06:19,039
given my previous state and the action i

167
00:06:19,039 --> 00:06:21,039
did and you have the likelihood model

168
00:06:21,039 --> 00:06:22,800
which basically says

169
00:06:22,800 --> 00:06:26,319
yeah given the state i am um

170
00:06:26,319 --> 00:06:28,960
which observation i will see and so this

171
00:06:28,960 --> 00:06:32,240
basically covers the so-called markov

172
00:06:32,240 --> 00:06:35,120
assumption that your observation that

173
00:06:35,120 --> 00:06:37,759
you see uh at this time step it only

174
00:06:37,759 --> 00:06:40,160
depends on your hidden state and it does

175
00:06:40,160 --> 00:06:42,880
not really directly depend on anything

176
00:06:42,880 --> 00:06:43,680
else

177
00:06:43,680 --> 00:06:45,520
uh because if you know your your your

178
00:06:45,520 --> 00:06:47,600
current in state then you know the

179
00:06:47,600 --> 00:06:49,919
observation you will see

180
00:06:49,919 --> 00:06:51,759
so that's basically what's but it's

181
00:06:51,759 --> 00:06:53,759
reflected here

182
00:06:53,759 --> 00:06:56,720
but of course as an agent

183
00:06:56,720 --> 00:06:58,960
having this generative model this allows

184
00:06:58,960 --> 00:07:00,639
you to to

185
00:07:00,639 --> 00:07:02,639
assess how likely is a sequence of

186
00:07:02,639 --> 00:07:04,400
observations for example and it allows

187
00:07:04,400 --> 00:07:06,240
you to predict

188
00:07:06,240 --> 00:07:08,880
given these actions what will happen but

189
00:07:08,880 --> 00:07:11,199
one crucial bit of course is still the

190
00:07:11,199 --> 00:07:13,360
inverse of this model like

191
00:07:13,360 --> 00:07:15,680
given that i saw these observations that

192
00:07:15,680 --> 00:07:17,520
i did these actions

193
00:07:17,520 --> 00:07:20,400
which is my current state um and and

194
00:07:20,400 --> 00:07:21,360
this is

195
00:07:21,360 --> 00:07:23,680
basically uh non-trivial

196
00:07:23,680 --> 00:07:26,319
so even if you have the exact strength

197
00:07:26,319 --> 00:07:29,199
model inverting this is typically

198
00:07:29,199 --> 00:07:30,479
intractable

199
00:07:30,479 --> 00:07:32,240
and so that's why why in active

200
00:07:32,240 --> 00:07:35,039
inference you uh you resort to variation

201
00:07:35,039 --> 00:07:36,800
inference and you just say okay

202
00:07:36,800 --> 00:07:39,759
i just assume that i can build a model

203
00:07:39,759 --> 00:07:42,400
the so-called bricks and posterior model

204
00:07:42,400 --> 00:07:44,639
and this is the thing that will uh tell

205
00:07:44,639 --> 00:07:47,039
me given certain observations

206
00:07:47,039 --> 00:07:48,800
what is my probability to be in a

207
00:07:48,800 --> 00:07:50,319
certain state

208
00:07:50,319 --> 00:07:52,639
so this is what's depicted here so yeah

209
00:07:52,639 --> 00:07:54,479
we introduce this q

210
00:07:54,479 --> 00:07:56,400
and q is basically a variational

211
00:07:56,400 --> 00:07:58,000
approximate here so can be any

212
00:07:58,000 --> 00:08:00,400
distribution you can choose it

213
00:08:00,400 --> 00:08:02,080
and you just say okay

214
00:08:02,080 --> 00:08:03,039
um

215
00:08:03,039 --> 00:08:05,440
given some observation i want to have

216
00:08:05,440 --> 00:08:07,440
the best estimate for

217
00:08:07,440 --> 00:08:09,520
the state i am in

218
00:08:09,520 --> 00:08:10,319
and

219
00:08:10,319 --> 00:08:12,800
the free energy principle genesis states

220
00:08:12,800 --> 00:08:14,720
if that's what you want then this is

221
00:08:14,720 --> 00:08:17,520
easy you just uh optimize the free

222
00:08:17,520 --> 00:08:19,599
energy which is the note f here and it's

223
00:08:19,599 --> 00:08:23,840
basically expectation over uh states uh

224
00:08:23,840 --> 00:08:25,520
generated by your

225
00:08:25,520 --> 00:08:27,919
personal posterior the expectation over

226
00:08:27,919 --> 00:08:29,840
the the difference between the local

227
00:08:29,840 --> 00:08:31,680
accuracy of your approximate posterior

228
00:08:31,680 --> 00:08:34,399
and look like of the gif model

229
00:08:34,399 --> 00:08:36,640
and if you can minimize that that

230
00:08:36,640 --> 00:08:38,719
basically means that you will have

231
00:08:38,719 --> 00:08:40,000
um

232
00:08:40,000 --> 00:08:41,760
the best explanation for the

233
00:08:41,760 --> 00:08:43,919
observations you see but at the same

234
00:08:43,919 --> 00:08:45,760
time you also have the best

235
00:08:45,760 --> 00:08:49,120
examples here for the true one and we're

236
00:08:49,120 --> 00:08:51,600
not going to go to the whole derivation

237
00:08:51,600 --> 00:08:52,320
of

238
00:08:52,320 --> 00:08:54,399
this flow but basically

239
00:08:54,399 --> 00:08:56,560
uh you can convert this to the the

240
00:08:56,560 --> 00:08:58,560
second equation line and this is the one

241
00:08:58,560 --> 00:09:01,920
that we we use most often

242
00:09:01,920 --> 00:09:03,680
in our models which is basically clear

243
00:09:03,680 --> 00:09:06,320
versions between

244
00:09:06,320 --> 00:09:07,519
this

245
00:09:07,519 --> 00:09:09,680
approximate posterior so basically what

246
00:09:09,680 --> 00:09:11,760
is the state i am given the observations

247
00:09:11,760 --> 00:09:12,800
i saw

248
00:09:12,800 --> 00:09:14,720
and um

249
00:09:14,720 --> 00:09:15,600
uh

250
00:09:15,600 --> 00:09:17,760
this briar that basically says

251
00:09:17,760 --> 00:09:20,320
this is my my guess

252
00:09:20,320 --> 00:09:22,399
that i am in the states given my

253
00:09:22,399 --> 00:09:23,839
previous state and action so i don't

254
00:09:23,839 --> 00:09:25,519
know the observation yet

255
00:09:25,519 --> 00:09:29,600
but i want to have uh the best guess uh

256
00:09:29,600 --> 00:09:32,080
without my observation and if i see the

257
00:09:32,080 --> 00:09:34,640
observation i don't want my beliefs to

258
00:09:34,640 --> 00:09:37,600
completely switch because then probably

259
00:09:37,600 --> 00:09:39,600
there's something wrong with my model

260
00:09:39,600 --> 00:09:41,279
and then you have the second term which

261
00:09:41,279 --> 00:09:42,959
is the uh

262
00:09:42,959 --> 00:09:45,279
the like return this is basically the

263
00:09:45,279 --> 00:09:48,080
accuracy of your model or how good are

264
00:09:48,080 --> 00:09:52,000
you at reconstructing the outcomes

265
00:09:52,000 --> 00:09:53,440
so

266
00:09:53,440 --> 00:09:55,200
um

267
00:09:55,200 --> 00:09:58,800
this is all for the past uh basically or

268
00:09:58,800 --> 00:10:00,800
up until your current time step so you

269
00:10:00,800 --> 00:10:03,360
know the observations you saw and you

270
00:10:03,360 --> 00:10:07,040
can evaluate the free energy and then

271
00:10:07,040 --> 00:10:09,200
you can basically update your model

272
00:10:09,200 --> 00:10:10,320
in order to

273
00:10:10,320 --> 00:10:11,200
uh

274
00:10:11,200 --> 00:10:13,440
to minimize this thing but of course you

275
00:10:13,440 --> 00:10:14,880
also need to know your actions you want

276
00:10:14,880 --> 00:10:16,640
to look into the future

277
00:10:16,640 --> 00:10:17,600
and so

278
00:10:17,600 --> 00:10:19,600
if you look into the future then we talk

279
00:10:19,600 --> 00:10:22,000
about the expected free energy

280
00:10:22,000 --> 00:10:25,040
and so here uh we didn't we we used by

281
00:10:25,040 --> 00:10:27,360
the shorthand for the sequence of

282
00:10:27,360 --> 00:10:30,399
actions into the future i also switched

283
00:10:30,399 --> 00:10:33,200
from d to daw just to denotes that we

284
00:10:33,200 --> 00:10:34,959
are talking about future time steps

285
00:10:34,959 --> 00:10:37,279
basically but other than that same but

286
00:10:37,279 --> 00:10:38,079
the

287
00:10:38,079 --> 00:10:39,600
important bit is now that in the

288
00:10:39,600 --> 00:10:41,279
expectation

289
00:10:41,279 --> 00:10:43,600
now you don't have expectations only

290
00:10:43,600 --> 00:10:47,200
over states but also over outcomes

291
00:10:47,200 --> 00:10:49,680
because you you couldn't sense

292
00:10:49,680 --> 00:10:50,560
uh

293
00:10:50,560 --> 00:10:52,399
your observations yet so you don't know

294
00:10:52,399 --> 00:10:54,800
them so you can just kind of

295
00:10:54,800 --> 00:10:56,880
do an expectation over anything that

296
00:10:56,880 --> 00:10:58,000
could happen

297
00:10:58,000 --> 00:10:59,360
and

298
00:10:59,360 --> 00:11:02,160
and then uh the move that

299
00:11:02,160 --> 00:11:04,480
is made in active inference

300
00:11:04,480 --> 00:11:06,959
is basically that uh

301
00:11:06,959 --> 00:11:09,600
you on the one hand form uh the term

302
00:11:09,600 --> 00:11:11,920
which they call or which we call the

303
00:11:11,920 --> 00:11:13,519
instrumental value

304
00:11:13,519 --> 00:11:16,000
or realizing preferences

305
00:11:16,000 --> 00:11:18,240
and it's basically stating that okay as

306
00:11:18,240 --> 00:11:21,519
an agent for future outcomes

307
00:11:21,519 --> 00:11:24,399
i have some prior that i think that i

308
00:11:24,399 --> 00:11:25,519
will

309
00:11:25,519 --> 00:11:27,680
regardless what happens that i think i

310
00:11:27,680 --> 00:11:29,839
will realize it's kind of your your

311
00:11:29,839 --> 00:11:32,240
preferred outcomes let's say you can

312
00:11:32,240 --> 00:11:34,560
also cause this more like homeostasis so

313
00:11:34,560 --> 00:11:37,680
i want my body temperature to be uh

314
00:11:37,680 --> 00:11:41,360
37 degrees celsius so my expectation

315
00:11:41,360 --> 00:11:43,200
before knowing anything is that it will

316
00:11:43,200 --> 00:11:44,399
be

317
00:11:44,399 --> 00:11:47,839
37 degrees and hence i will act in order

318
00:11:47,839 --> 00:11:49,839
to make it so so that's a bit reflected

319
00:11:49,839 --> 00:11:53,040
here like you you disregard

320
00:11:53,040 --> 00:11:56,000
the um the dependency on your future

321
00:11:56,000 --> 00:11:58,480
actions you just say okay my prior is

322
00:11:58,480 --> 00:12:00,720
that's this is what i expect

323
00:12:00,720 --> 00:12:02,959
uh so this becomes the instrumental

324
00:12:02,959 --> 00:12:03,920
value

325
00:12:03,920 --> 00:12:05,279
and then the second assumption is

326
00:12:05,279 --> 00:12:06,480
basically that

327
00:12:06,480 --> 00:12:08,959
your approximate posterior model

328
00:12:08,959 --> 00:12:11,680
is basically very very close to the true

329
00:12:11,680 --> 00:12:13,040
posterior so that you have a good

330
00:12:13,040 --> 00:12:15,839
approximation then you can

331
00:12:15,839 --> 00:12:17,120
rewrite

332
00:12:17,120 --> 00:12:18,720
it's in the second term

333
00:12:18,720 --> 00:12:20,240
which basically

334
00:12:20,240 --> 00:12:24,320
means that you have on the one hand and

335
00:12:24,320 --> 00:12:26,720
the third that says

336
00:12:26,720 --> 00:12:30,480
this is my belief or the state given

337
00:12:30,480 --> 00:12:32,160
the actions

338
00:12:32,160 --> 00:12:33,200
i will do

339
00:12:33,200 --> 00:12:35,040
and the other thing is

340
00:12:35,040 --> 00:12:37,680
also a belief about future states given

341
00:12:37,680 --> 00:12:40,399
the actions and some certain outcomes

342
00:12:40,399 --> 00:12:43,040
that i expect to see so basically it

343
00:12:43,040 --> 00:12:44,320
says

344
00:12:44,320 --> 00:12:47,680
what would be the information that i get

345
00:12:47,680 --> 00:12:48,560
from

346
00:12:48,560 --> 00:12:50,839
looking for certain

347
00:12:50,839 --> 00:12:53,519
outcomes and it's kind of an epistemic

348
00:12:53,519 --> 00:12:55,839
value or an information game

349
00:12:55,839 --> 00:12:57,839
which can drive you to to explore

350
00:12:57,839 --> 00:12:59,680
basically you want to have

351
00:12:59,680 --> 00:13:00,320
if

352
00:13:00,320 --> 00:13:01,920
if you don't know how to get to your

353
00:13:01,920 --> 00:13:04,480
preferred state at least you want to get

354
00:13:04,480 --> 00:13:06,639
to state to

355
00:13:06,639 --> 00:13:08,720
states that give you more information on

356
00:13:08,720 --> 00:13:11,200
on where you are

357
00:13:11,200 --> 00:13:12,320
go first

358
00:13:12,320 --> 00:13:14,399
often says it's like the owl that needs

359
00:13:14,399 --> 00:13:16,800
foods so what do you do do you eat first

360
00:13:16,800 --> 00:13:19,680
or do you search for prey first and so

361
00:13:19,680 --> 00:13:21,600
the epistemic value is basically

362
00:13:21,600 --> 00:13:24,079
searching for prey it's like where

363
00:13:24,079 --> 00:13:25,760
should i go to

364
00:13:25,760 --> 00:13:27,680
to to get more information on where the

365
00:13:27,680 --> 00:13:29,839
play is and then once you know where it

366
00:13:29,839 --> 00:13:33,040
is then you can realize your preferences

367
00:13:33,040 --> 00:13:34,240
and uh

368
00:13:34,240 --> 00:13:38,720
go towards the towers of free basically

369
00:13:39,199 --> 00:13:40,320
so

370
00:13:40,320 --> 00:13:42,880
how how does the action selection works

371
00:13:42,880 --> 00:13:45,199
then well basically you want to select

372
00:13:45,199 --> 00:13:47,199
the actions that minimize your expected

373
00:13:47,199 --> 00:13:49,440
free energy so at each time step

374
00:13:49,440 --> 00:13:51,120
first thing you do is you use your

375
00:13:51,120 --> 00:13:54,639
approximate model to uh to estimate your

376
00:13:54,639 --> 00:13:56,639
burn state it's like knowing

377
00:13:56,639 --> 00:13:59,519
in which state am i now given my latest

378
00:13:59,519 --> 00:14:01,120
observation

379
00:14:01,120 --> 00:14:03,600
then you can evaluate the expected free

380
00:14:03,600 --> 00:14:05,760
energy for uh

381
00:14:05,760 --> 00:14:07,199
for each

382
00:14:07,199 --> 00:14:09,760
pulse your plan so for

383
00:14:09,760 --> 00:14:12,079
any future sequence of actions you can

384
00:14:12,079 --> 00:14:13,279
evaluate

385
00:14:13,279 --> 00:14:16,079
and the expected free energy

386
00:14:16,079 --> 00:14:18,720
and then this basically results in a

387
00:14:18,720 --> 00:14:21,440
belief over policy so you basically

388
00:14:21,440 --> 00:14:24,560
take the the mind the negative expected

389
00:14:24,560 --> 00:14:26,720
free energy you multiply with this

390
00:14:26,720 --> 00:14:28,639
precision parameter which just states

391
00:14:28,639 --> 00:14:31,440
how yeah

392
00:14:31,440 --> 00:14:33,440
how how much confidence you have that

393
00:14:33,440 --> 00:14:35,279
your expected free energy is correct

394
00:14:35,279 --> 00:14:37,920
basically and then you use this the soft

395
00:14:37,920 --> 00:14:40,800
mix function so basically just

396
00:14:40,800 --> 00:14:42,160
it just says

397
00:14:42,160 --> 00:14:43,360
um

398
00:14:43,360 --> 00:14:44,639
the

399
00:14:44,639 --> 00:14:47,120
the policies that have low expected free

400
00:14:47,120 --> 00:14:49,360
energy are the ones that are most likely

401
00:14:49,360 --> 00:14:50,959
basically that's that's the only thing

402
00:14:50,959 --> 00:14:53,120
this formula says and then you refer the

403
00:14:53,120 --> 00:14:54,880
next action according to this you just

404
00:14:54,880 --> 00:14:58,079
select the next action for the sequence

405
00:14:58,079 --> 00:14:59,360
that you think

406
00:14:59,360 --> 00:15:01,120
will give you the

407
00:15:01,120 --> 00:15:03,680
the minimum the minimum expected 3mg and

408
00:15:03,680 --> 00:15:05,440
that's how it goes and then you you take

409
00:15:05,440 --> 00:15:07,600
this action you get a new observation

410
00:15:07,600 --> 00:15:08,970
and a process

411
00:15:08,970 --> 00:15:10,880
[Music]

412
00:15:10,880 --> 00:15:14,000
so one crucial point in in our work is

413
00:15:14,000 --> 00:15:14,800
that

414
00:15:14,800 --> 00:15:16,959
uh it all starts with this genetic model

415
00:15:16,959 --> 00:15:19,920
and it's approximate model and um

416
00:15:19,920 --> 00:15:22,000
typically um

417
00:15:22,000 --> 00:15:24,720
you can and you have a certain problem

418
00:15:24,720 --> 00:15:26,560
and you know how the problem

419
00:15:26,560 --> 00:15:28,720
uh looks like what what the observations

420
00:15:28,720 --> 00:15:30,720
are what the hidden state might be and

421
00:15:30,720 --> 00:15:33,279
then you can you can really pinpoint and

422
00:15:33,279 --> 00:15:35,839
write down the exact model and start

423
00:15:35,839 --> 00:15:38,639
optimizing but in our case this is often

424
00:15:38,639 --> 00:15:40,880
not true if you if you look at the robot

425
00:15:40,880 --> 00:15:43,199
that drives around and gets camera

426
00:15:43,199 --> 00:15:45,360
inputs for example yeah what is the

427
00:15:45,360 --> 00:15:48,480
state space that you need to um

428
00:15:48,480 --> 00:15:50,320
that you need to track how do you

429
00:15:50,320 --> 00:15:53,680
convert these pixels to the state space

430
00:15:53,680 --> 00:15:55,839
so all these things are yeah

431
00:15:55,839 --> 00:15:58,880
they're just not there yet and the goal

432
00:15:58,880 --> 00:16:01,120
in our work is that yeah can we

433
00:16:01,120 --> 00:16:03,040
can we completely start from scratch and

434
00:16:03,040 --> 00:16:04,399
learn this

435
00:16:04,399 --> 00:16:06,399
and for this we use

436
00:16:06,399 --> 00:16:09,120
deep neural networks to act as function

437
00:16:09,120 --> 00:16:12,800
approximators to actually um

438
00:16:12,800 --> 00:16:15,120
provide us with these these models and

439
00:16:15,120 --> 00:16:16,959
we optimize the parameters of these

440
00:16:16,959 --> 00:16:18,240
neural nets

441
00:16:18,240 --> 00:16:20,959
also by minimizing the free energy

442
00:16:20,959 --> 00:16:23,600
that's that's the core id that's it

443
00:16:23,600 --> 00:16:26,720
so how does it look like we call this

444
00:16:26,720 --> 00:16:29,360
an artificial word model so we start off

445
00:16:29,360 --> 00:16:31,600
with uh observations and actions so

446
00:16:31,600 --> 00:16:34,079
these can be

447
00:16:34,079 --> 00:16:36,720
pixels basically so uh an

448
00:16:36,720 --> 00:16:39,920
n by m matrix of numbers let's say

449
00:16:39,920 --> 00:16:42,000
and actions which could be any action

450
00:16:42,000 --> 00:16:44,000
factor it could be your velocity or

451
00:16:44,000 --> 00:16:46,720
whatever your agent can do

452
00:16:46,720 --> 00:16:48,480
and these numbers are put into a neural

453
00:16:48,480 --> 00:16:50,639
net which we call the encoder and this

454
00:16:50,639 --> 00:16:52,720
basically reflects this approximate

455
00:16:52,720 --> 00:16:55,199
posterior this is just saying given my

456
00:16:55,199 --> 00:16:56,480
previous state

457
00:16:56,480 --> 00:16:59,120
action and my current observation it

458
00:16:59,120 --> 00:17:00,800
outputs

459
00:17:00,800 --> 00:17:02,639
a probabilistic state representation

460
00:17:02,639 --> 00:17:04,880
which is basically the means and the

461
00:17:04,880 --> 00:17:08,079
variances of multivariate versions

462
00:17:08,079 --> 00:17:09,199
and then

463
00:17:09,199 --> 00:17:10,640
we have a second neural net which we

464
00:17:10,640 --> 00:17:12,480
call the transition model and this is

465
00:17:12,480 --> 00:17:14,720
then

466
00:17:15,750 --> 00:17:17,199
[Music]

467
00:17:17,199 --> 00:17:19,280
saying yeah what what will happen if i

468
00:17:19,280 --> 00:17:21,199
do a certain action how will my state

469
00:17:21,199 --> 00:17:24,400
evolve if i if i do a certain action

470
00:17:24,400 --> 00:17:26,720
now finally we also have the the decoder

471
00:17:26,720 --> 00:17:28,640
or the likelihood model that then

472
00:17:28,640 --> 00:17:31,679
outputs given states some observation so

473
00:17:31,679 --> 00:17:33,760
in case of an image for example this

474
00:17:33,760 --> 00:17:36,240
will generate you a new image

475
00:17:36,240 --> 00:17:39,840
and the goal is of course to

476
00:17:39,840 --> 00:17:42,080
have the best predictions

477
00:17:42,080 --> 00:17:43,760
possible so if you look at the free

478
00:17:43,760 --> 00:17:45,039
energy

479
00:17:45,039 --> 00:17:47,679
formula again in this case

480
00:17:47,679 --> 00:17:49,760
it's again you have this likelihood

481
00:17:49,760 --> 00:17:51,440
which basically just says

482
00:17:51,440 --> 00:17:52,320
and

483
00:17:52,320 --> 00:17:54,320
given the the output of the decoders or

484
00:17:54,320 --> 00:17:56,960
the generic image i just want to have

485
00:17:56,960 --> 00:17:59,360
this close to the actual image that you

486
00:17:59,360 --> 00:18:02,320
then uh see basically so it's just a

487
00:18:02,320 --> 00:18:04,799
reconstruction loss in terms of a neural

488
00:18:04,799 --> 00:18:06,000
net let's say

489
00:18:06,000 --> 00:18:08,160
and the second term

490
00:18:08,160 --> 00:18:09,039
sorry

491
00:18:09,039 --> 00:18:11,440
second term is a gal divergence between

492
00:18:11,440 --> 00:18:14,080
the distribution that you generate from

493
00:18:14,080 --> 00:18:15,600
the encoder

494
00:18:15,600 --> 00:18:17,200
and the distribution that you generate

495
00:18:17,200 --> 00:18:20,960
from the transition model basically

496
00:18:25,039 --> 00:18:28,080
so we apply this on a number of cases

497
00:18:28,080 --> 00:18:30,640
which also um

498
00:18:30,640 --> 00:18:32,640
were seen in the previous model stream

499
00:18:32,640 --> 00:18:35,200
so just to give you some intuition so

500
00:18:35,200 --> 00:18:37,200
first thing was uh the mounting core

501
00:18:37,200 --> 00:18:39,600
problems just which is a basic control

502
00:18:39,600 --> 00:18:41,520
problem so here

503
00:18:41,520 --> 00:18:43,679
the sensory input is the position you

504
00:18:43,679 --> 00:18:45,520
are with the card

505
00:18:45,520 --> 00:18:47,280
you basically have to infer

506
00:18:47,280 --> 00:18:49,200
not only the position you're in but also

507
00:18:49,200 --> 00:18:50,720
the momentum you have the velocity you

508
00:18:50,720 --> 00:18:53,039
have and so you can see that

509
00:18:53,039 --> 00:18:53,919
uh

510
00:18:53,919 --> 00:18:56,000
on the right you can see the model

511
00:18:56,000 --> 00:18:59,039
predicting all likely trajectories

512
00:18:59,039 --> 00:19:01,520
for going left or right and you can see

513
00:19:01,520 --> 00:19:03,600
how in the beginning it's not sure on

514
00:19:03,600 --> 00:19:06,160
the velocity so it's it's very spread

515
00:19:06,160 --> 00:19:07,360
out in

516
00:19:07,360 --> 00:19:09,360
in what it will predict but the more

517
00:19:09,360 --> 00:19:11,120
information it gets the more it kind of

518
00:19:11,120 --> 00:19:12,960
collapses to yeah i'm pretty sure that

519
00:19:12,960 --> 00:19:14,720
this is the behavior that will happen

520
00:19:14,720 --> 00:19:16,720
and then you can use this to

521
00:19:16,720 --> 00:19:19,120
to drive the agents towards

522
00:19:19,120 --> 00:19:21,840
a preferred state in this case the

523
00:19:21,840 --> 00:19:23,360
the flag

524
00:19:23,360 --> 00:19:24,720
the second one

525
00:19:24,720 --> 00:19:26,799
was using the

526
00:19:26,799 --> 00:19:28,559
car racer environment so here you get

527
00:19:28,559 --> 00:19:29,360
these

528
00:19:29,360 --> 00:19:30,240
uh

529
00:19:30,240 --> 00:19:32,559
observations are now just pixels from

530
00:19:32,559 --> 00:19:34,160
from this uh

531
00:19:34,160 --> 00:19:34,960
game

532
00:19:34,960 --> 00:19:36,799
and the preferred state of the car was

533
00:19:36,799 --> 00:19:39,120
to be in the center of the track

534
00:19:39,120 --> 00:19:40,720
and so you can see how it actually

535
00:19:40,720 --> 00:19:43,440
infers the actions that will bring it to

536
00:19:43,440 --> 00:19:46,320
uh to the center of the track uh

537
00:19:46,320 --> 00:19:48,559
and it might even cut corners in order

538
00:19:48,559 --> 00:19:51,120
to reach the preferred state a bit

539
00:19:51,120 --> 00:19:54,720
faster and finally we also did this on

540
00:19:54,720 --> 00:19:58,320
on the robots navigating our lab

541
00:19:58,320 --> 00:20:00,160
where we equipped it with

542
00:20:00,160 --> 00:20:02,000
a number of sensor modalities so you can

543
00:20:02,000 --> 00:20:04,320
see a camera but also

544
00:20:04,320 --> 00:20:07,520
a front facing lighter and also a radar

545
00:20:07,520 --> 00:20:09,760
range doppler so the radar range doppler

546
00:20:09,760 --> 00:20:11,280
basically gives you

547
00:20:11,280 --> 00:20:13,200
in the y-axis

548
00:20:13,200 --> 00:20:14,320
the range

549
00:20:14,320 --> 00:20:15,600
and in the

550
00:20:15,600 --> 00:20:19,039
x-axis the the velocity of the

551
00:20:19,039 --> 00:20:21,120
reflections basically

552
00:20:21,120 --> 00:20:22,240
and here you can see how in the

553
00:20:22,240 --> 00:20:23,360
beginning

554
00:20:23,360 --> 00:20:25,600
we feed it with a number of observations

555
00:20:25,600 --> 00:20:27,360
and then we basically let the model

556
00:20:27,360 --> 00:20:29,440
imagine what could happen so these are

557
00:20:29,440 --> 00:20:31,360
real observations and now

558
00:20:31,360 --> 00:20:34,000
it basically imagines what it will see

559
00:20:34,000 --> 00:20:36,080
if it turns around for example because

560
00:20:36,080 --> 00:20:38,480
it actually learns like basic uh

561
00:20:38,480 --> 00:20:40,480
dynamics basic behavior

562
00:20:40,480 --> 00:20:43,520
um of of all these sensor models so it's

563
00:20:43,520 --> 00:20:46,000
pretty cool

564
00:20:46,400 --> 00:20:49,360
okay so what are the limitations of this

565
00:20:49,360 --> 00:20:50,400
thing

566
00:20:50,400 --> 00:20:52,799
well there are two core limitations that

567
00:20:52,799 --> 00:20:55,120
we address uh in the work of pietro so

568
00:20:55,120 --> 00:20:56,400
the first one is

569
00:20:56,400 --> 00:20:57,760
we

570
00:20:57,760 --> 00:20:59,600
we use this this recon pixel wax

571
00:20:59,600 --> 00:21:00,880
reconstruction

572
00:21:00,880 --> 00:21:04,000
board to uh to learn the model but also

573
00:21:04,000 --> 00:21:07,360
to define your preferred state like this

574
00:21:07,360 --> 00:21:08,799
is the image that you want to see and

575
00:21:08,799 --> 00:21:10,720
try to make it happen

576
00:21:10,720 --> 00:21:12,159
but the problem is that means where

577
00:21:12,159 --> 00:21:15,280
error in pixel

578
00:21:15,280 --> 00:21:17,520
in terms of pixels is not really the

579
00:21:17,520 --> 00:21:20,400
best metric so for example if you have

580
00:21:20,400 --> 00:21:21,440
the

581
00:21:21,440 --> 00:21:23,520
the left image

582
00:21:23,520 --> 00:21:25,919
and you want to assess how good

583
00:21:25,919 --> 00:21:27,919
an image is similar to

584
00:21:27,919 --> 00:21:29,200
that one

585
00:21:29,200 --> 00:21:31,200
we have two examples here on the right

586
00:21:31,200 --> 00:21:33,280
and you can see that the the same image

587
00:21:33,280 --> 00:21:35,760
with some salt and pepper noise is

588
00:21:35,760 --> 00:21:38,320
actually scoring worse in terms of mean

589
00:21:38,320 --> 00:21:41,840
squared error than an image where the

590
00:21:41,840 --> 00:21:43,600
the two two

591
00:21:43,600 --> 00:21:46,400
joint arm is actually uh

592
00:21:46,400 --> 00:21:48,400
incorrect so

593
00:21:48,400 --> 00:21:49,440
although

594
00:21:49,440 --> 00:21:51,919
in terms of behavior the the left one is

595
00:21:51,919 --> 00:21:54,640
better in terms of means great error the

596
00:21:54,640 --> 00:21:56,880
the right one is better so that's of

597
00:21:56,880 --> 00:21:58,799
course problematic if you want to

598
00:21:58,799 --> 00:22:01,440
control the arm towards the goal

599
00:22:01,440 --> 00:22:03,760
and then the second limitation is that

600
00:22:03,760 --> 00:22:05,760
if you need to evaluate the expected

601
00:22:05,760 --> 00:22:08,080
free energy for a huge number of

602
00:22:08,080 --> 00:22:10,320
potential trajectories potential actions

603
00:22:10,320 --> 00:22:12,640
you can do then of course this becomes

604
00:22:12,640 --> 00:22:15,120
intractable as the number increases

605
00:22:15,120 --> 00:22:17,200
and so the the ways that we coped with

606
00:22:17,200 --> 00:22:19,440
this in in the contrastive work is on

607
00:22:19,440 --> 00:22:20,880
the one hand

608
00:22:20,880 --> 00:22:22,480
instead of using a pixel-wise

609
00:22:22,480 --> 00:22:24,159
reconstruction error is to use

610
00:22:24,159 --> 00:22:26,480
contrastive learning instead

611
00:22:26,480 --> 00:22:28,960
how exactly this works

612
00:22:28,960 --> 00:22:31,200
in the in the next few slides

613
00:22:31,200 --> 00:22:33,600
and then the second thing is instead of

614
00:22:33,600 --> 00:22:36,240
evaluating the expected free energy

615
00:22:36,240 --> 00:22:38,480
for all the policies

616
00:22:38,480 --> 00:22:40,320
we basically amortize the policy

617
00:22:40,320 --> 00:22:42,159
selection scheme so we also train neural

618
00:22:42,159 --> 00:22:45,280
net to output actions given during the

619
00:22:45,280 --> 00:22:46,240
stage

620
00:22:46,240 --> 00:22:47,840
and so with that

621
00:22:47,840 --> 00:22:49,600
uh we can now shift

622
00:22:49,600 --> 00:22:52,400
to ghetto who will talk about the

623
00:22:52,400 --> 00:22:54,880
contrastive formulation of the

624
00:22:54,880 --> 00:22:57,360
principle

625
00:23:02,320 --> 00:23:04,879
thank you tim

626
00:23:05,440 --> 00:23:07,760
alright so thank you daniel for having

627
00:23:07,760 --> 00:23:11,280
us and uh thank you team i hope you can

628
00:23:11,280 --> 00:23:14,080
hear me well

629
00:23:15,120 --> 00:23:17,200
okay so

630
00:23:17,200 --> 00:23:22,679
i'll try to share my screen now

631
00:23:24,559 --> 00:23:26,799
okay

632
00:23:26,799 --> 00:23:28,640
all right so

633
00:23:28,640 --> 00:23:31,280
now i will talk about our

634
00:23:31,280 --> 00:23:34,320
recent work contrastive active inference

635
00:23:34,320 --> 00:23:35,120
so

636
00:23:35,120 --> 00:23:37,200
this work was recently published that

637
00:23:37,200 --> 00:23:40,720
now rips 2021 so

638
00:23:40,720 --> 00:23:43,679
very recently it came out like

639
00:23:43,679 --> 00:23:46,080
last month and let's

640
00:23:46,080 --> 00:23:48,640
start delving into it

641
00:23:48,640 --> 00:23:50,720
so the

642
00:23:50,720 --> 00:23:53,919
the setting that we discuss in inactive

643
00:23:53,919 --> 00:23:55,520
inference is very similar to the

644
00:23:55,520 --> 00:23:57,440
reinforcement learning one

645
00:23:57,440 --> 00:23:58,799
with the difference that in

646
00:23:58,799 --> 00:24:00,400
reinforcement learning

647
00:24:00,400 --> 00:24:01,600
uh the

648
00:24:01,600 --> 00:24:04,559
all behavior learning is driven by

649
00:24:04,559 --> 00:24:08,400
rewards so the agent receive a reward

650
00:24:08,400 --> 00:24:09,440
function

651
00:24:09,440 --> 00:24:11,039
and

652
00:24:11,039 --> 00:24:13,840
positive rewards should reinforce

653
00:24:13,840 --> 00:24:16,720
positive behaviors while negative

654
00:24:16,720 --> 00:24:18,960
rewards should penalize

655
00:24:18,960 --> 00:24:21,360
the agent to avoid to the states and

656
00:24:21,360 --> 00:24:22,400
actions

657
00:24:22,400 --> 00:24:24,400
however one of the problems comes with

658
00:24:24,400 --> 00:24:26,400
reinforcement learning is that

659
00:24:26,400 --> 00:24:28,480
in order to actually learn from rewards

660
00:24:28,480 --> 00:24:31,200
you need a rework function and that's

661
00:24:31,200 --> 00:24:33,760
not always easy to have for instance a

662
00:24:33,760 --> 00:24:35,360
steam mentioned

663
00:24:35,360 --> 00:24:37,039
especially when the state is not known

664
00:24:37,039 --> 00:24:39,440
in advance so the agent doesn't exactly

665
00:24:39,440 --> 00:24:41,600
know it states it's difficult

666
00:24:41,600 --> 00:24:43,520
in that case to design a reward function

667
00:24:43,520 --> 00:24:45,600
because you're not sure of what the

668
00:24:45,600 --> 00:24:48,000
agent knows and how it can assess its

669
00:24:48,000 --> 00:24:51,600
performance compared to the environment

670
00:24:51,600 --> 00:24:53,039
so

671
00:24:53,039 --> 00:24:55,600
we instead focus on active inference in

672
00:24:55,600 --> 00:24:57,520
inactive inference the agent separates

673
00:24:57,520 --> 00:24:58,400
to the

674
00:24:58,400 --> 00:25:00,480
the principle of minimizing free energy

675
00:25:00,480 --> 00:25:02,159
as we we have just

676
00:25:02,159 --> 00:25:04,080
seen so

677
00:25:04,080 --> 00:25:06,159
the the principle of minimizing free

678
00:25:06,159 --> 00:25:08,880
energy actually enables two things the

679
00:25:08,880 --> 00:25:10,720
one thing is to learn

680
00:25:10,720 --> 00:25:13,360
uh a model of the word we we call this

681
00:25:13,360 --> 00:25:16,080
an artificial world model in our work a

682
00:25:16,080 --> 00:25:17,360
steam show

683
00:25:17,360 --> 00:25:20,240
and the other objective is to minimize

684
00:25:20,240 --> 00:25:22,080
the free energy in the future by trying

685
00:25:22,080 --> 00:25:23,200
to achieve

686
00:25:23,200 --> 00:25:23,919
uh

687
00:25:23,919 --> 00:25:26,320
some preferred outcomes of the agent so

688
00:25:26,320 --> 00:25:28,320
we assume that the agent does some

689
00:25:28,320 --> 00:25:30,320
preferred outcome distribution that he

690
00:25:30,320 --> 00:25:32,000
wants to achieve and

691
00:25:32,000 --> 00:25:33,520
this goal will be in the future to

692
00:25:33,520 --> 00:25:35,120
actually achieve these preferred

693
00:25:35,120 --> 00:25:37,600
outcomes

694
00:25:38,080 --> 00:25:39,200
so the

695
00:25:39,200 --> 00:25:41,760
the environment setting we discuss is

696
00:25:41,760 --> 00:25:44,000
that's one of our pndp so a partially

697
00:25:44,000 --> 00:25:46,400
observable marketplacing process

698
00:25:46,400 --> 00:25:49,840
so just to recap we have observation

699
00:25:49,840 --> 00:25:50,720
that

700
00:25:50,720 --> 00:25:53,039
the agent receives he has to infer the

701
00:25:53,039 --> 00:25:54,559
internal state of the environment which

702
00:25:54,559 --> 00:25:55,840
is not

703
00:25:55,840 --> 00:25:58,000
and then there's action which are

704
00:25:58,000 --> 00:26:00,080
actually known for the past but the

705
00:26:00,080 --> 00:26:03,200
agent should infer or

706
00:26:03,200 --> 00:26:05,039
somehow choose among

707
00:26:05,039 --> 00:26:08,799
a set of possible actions in the future

708
00:26:08,799 --> 00:26:11,200
so this is just a summary of what the

709
00:26:11,200 --> 00:26:13,679
the an artificial word model looks like

710
00:26:13,679 --> 00:26:15,600
so as as we've seen in the previous

711
00:26:15,600 --> 00:26:18,080
slides we have an encoder that encodes

712
00:26:18,080 --> 00:26:20,240
the information from an observation we

713
00:26:20,240 --> 00:26:22,880
focus on visual environments so

714
00:26:22,880 --> 00:26:25,279
here we have uh again an image which is

715
00:26:25,279 --> 00:26:27,679
basically n-by-n metrics so the encoder

716
00:26:27,679 --> 00:26:29,360
could be for instance a convolutional

717
00:26:29,360 --> 00:26:30,960
neural network

718
00:26:30,960 --> 00:26:33,600
in our case then we have uh the the

719
00:26:33,600 --> 00:26:36,320
hidden state model which which takes the

720
00:26:36,320 --> 00:26:38,880
previous state and the previous action

721
00:26:38,880 --> 00:26:40,960
and in particular in our case here we

722
00:26:40,960 --> 00:26:43,279
use some some form of recurrent neural

723
00:26:43,279 --> 00:26:46,000
network model in order to keep observing

724
00:26:46,000 --> 00:26:48,559
the history of the environment and then

725
00:26:48,559 --> 00:26:50,799
we have the decoder that

726
00:26:50,799 --> 00:26:53,200
computes reconstruction of the the

727
00:26:53,200 --> 00:26:54,720
observation of the current state so it

728
00:26:54,720 --> 00:26:57,760
tries to encode uh inside the hidden

729
00:26:57,760 --> 00:27:00,080
states of as much information as

730
00:27:00,080 --> 00:27:01,360
possible

731
00:27:01,360 --> 00:27:02,960
from what it comes from the from the

732
00:27:02,960 --> 00:27:04,880
observation

733
00:27:04,880 --> 00:27:07,840
so the problem with uh reconstruction is

734
00:27:07,840 --> 00:27:10,000
that computing them especially in visual

735
00:27:10,000 --> 00:27:12,240
environments is is quite complicated

736
00:27:12,240 --> 00:27:14,880
because you need

737
00:27:15,120 --> 00:27:17,279
big models that have a very good

738
00:27:17,279 --> 00:27:20,159
representational capacity and also the

739
00:27:20,159 --> 00:27:22,000
models cannot be a hundred percent

740
00:27:22,000 --> 00:27:24,880
accurate as in uh lowest low dimensional

741
00:27:24,880 --> 00:27:26,799
settings because

742
00:27:26,799 --> 00:27:28,640
for instance predicting

743
00:27:28,640 --> 00:27:31,600
an image pixel by pixel is practically

744
00:27:31,600 --> 00:27:35,279
very invisible so it very rarely happens

745
00:27:35,279 --> 00:27:38,240
so let's go on example here so a few a

746
00:27:38,240 --> 00:27:41,919
few weeks ago i was uh i was training uh

747
00:27:41,919 --> 00:27:44,559
bae like model so like uh

748
00:27:44,559 --> 00:27:46,559
a model similar to this one on the left

749
00:27:46,559 --> 00:27:48,640
so where we have the this

750
00:27:48,640 --> 00:27:51,440
encoder decoder architecture on uh on an

751
00:27:51,440 --> 00:27:52,960
atari game the

752
00:27:52,960 --> 00:27:54,480
breakout game

753
00:27:54,480 --> 00:27:59,279
and try to to learn an eden state to

754
00:28:00,159 --> 00:28:01,919
to learn action on top of the the

755
00:28:01,919 --> 00:28:04,399
interstate the problem is that

756
00:28:04,399 --> 00:28:07,360
the the reconstruction of the the vae so

757
00:28:07,360 --> 00:28:09,520
we're actually pretty bad in that they

758
00:28:09,520 --> 00:28:11,520
were losing very important information

759
00:28:11,520 --> 00:28:13,840
about the game so for instance

760
00:28:13,840 --> 00:28:15,200
it was

761
00:28:15,200 --> 00:28:17,440
kind of able so with some uncertainty to

762
00:28:17,440 --> 00:28:19,600
model where the puddle of the game is

763
00:28:19,600 --> 00:28:22,399
but it wasn't able uh to model where the

764
00:28:22,399 --> 00:28:24,720
ball is which is actually

765
00:28:24,720 --> 00:28:26,880
one of the two most important details in

766
00:28:26,880 --> 00:28:29,039
order to actually be able

767
00:28:29,039 --> 00:28:31,200
to play so even adding the reward

768
00:28:31,200 --> 00:28:35,039
function in this case so having the the

769
00:28:35,039 --> 00:28:38,159
the game score available uh the agent

770
00:28:38,159 --> 00:28:40,799
wasn't able to learn the task because of

771
00:28:40,799 --> 00:28:43,120
uh of the state which was lacking the

772
00:28:43,120 --> 00:28:45,760
most important information in order to

773
00:28:45,760 --> 00:28:47,600
to keep improving

774
00:28:47,600 --> 00:28:50,240
so this is one issue that we try to

775
00:28:50,240 --> 00:28:52,399
overcome in our work

776
00:28:52,399 --> 00:28:55,520
and the second part of active inference

777
00:28:55,520 --> 00:28:57,840
involves learning to pursue the

778
00:28:57,840 --> 00:28:59,600
preferred outcome

779
00:28:59,600 --> 00:29:01,919
so in order to pursue preferred outcomes

780
00:29:01,919 --> 00:29:03,600
active inference agent

781
00:29:03,600 --> 00:29:06,559
will do two things one try to minimize

782
00:29:06,559 --> 00:29:08,799
uh

783
00:29:08,799 --> 00:29:10,640
the distance with respect to these

784
00:29:10,640 --> 00:29:12,480
preferred outcomes but on the other way

785
00:29:12,480 --> 00:29:14,480
also minimize the ambiguity respect to

786
00:29:14,480 --> 00:29:16,960
the environment

787
00:29:16,960 --> 00:29:19,039
so normally this is done by trying to

788
00:29:19,039 --> 00:29:21,919
match uh these the two distributions or

789
00:29:21,919 --> 00:29:24,880
trying to to match as we saw with

790
00:29:24,880 --> 00:29:27,279
uh with a kill divergence try to match

791
00:29:27,279 --> 00:29:29,600
the distribution of the imagined outcome

792
00:29:29,600 --> 00:29:32,159
with the preferred outcomes distribution

793
00:29:32,159 --> 00:29:34,399
however again in a high-dimensional

794
00:29:34,399 --> 00:29:36,640
setting this can be quite complex

795
00:29:36,640 --> 00:29:38,399
because uh how do you define a

796
00:29:38,399 --> 00:29:41,279
distribution on a 9-dimensional image

797
00:29:41,279 --> 00:29:43,200
could it be for instance just a center

798
00:29:43,200 --> 00:29:45,200
gaussian around the

799
00:29:45,200 --> 00:29:47,440
pixel so with the

800
00:29:47,440 --> 00:29:49,360
with the mean being the pixel value and

801
00:29:49,360 --> 00:29:51,840
then some fixed standard deviation but

802
00:29:51,840 --> 00:29:54,799
in that case we we get into troubles

803
00:29:54,799 --> 00:29:56,480
because we have the same issue discussed

804
00:29:56,480 --> 00:29:58,799
before with for instance having this

805
00:29:58,799 --> 00:30:01,200
kind of call here and a noisy

806
00:30:01,200 --> 00:30:02,960
observation like this which actually

807
00:30:02,960 --> 00:30:05,520
adds an eye and higher mean square error

808
00:30:05,520 --> 00:30:07,679
compared to to an image that is very

809
00:30:07,679 --> 00:30:09,200
distant from the goal

810
00:30:09,200 --> 00:30:11,360
and this kind of situation especially

811
00:30:11,360 --> 00:30:13,840
when using reconstruction or in more

812
00:30:13,840 --> 00:30:16,159
realistic settings are very very likely

813
00:30:16,159 --> 00:30:17,919
because for instance you can you can

814
00:30:17,919 --> 00:30:19,360
think that the center

815
00:30:19,360 --> 00:30:20,320
image

816
00:30:20,320 --> 00:30:21,840
is actually just a reconstruction of the

817
00:30:21,840 --> 00:30:24,320
model which is not 100 accurate so that

818
00:30:24,320 --> 00:30:26,880
could be the case and indeed the agent

819
00:30:26,880 --> 00:30:28,480
will be confused and he will think that

820
00:30:28,480 --> 00:30:30,880
it's not achieving the goal compared to

821
00:30:30,880 --> 00:30:33,279
maybe for instance a past observation

822
00:30:33,279 --> 00:30:35,360
but if it seemed it was actually

823
00:30:35,360 --> 00:30:37,760
actually closer to the goal or again

824
00:30:37,760 --> 00:30:39,360
when there is some some noise in the

825
00:30:39,360 --> 00:30:41,600
environment in real world setup like

826
00:30:41,600 --> 00:30:44,399
also robotic we always add this noise

827
00:30:44,399 --> 00:30:47,039
into the observation so it's hard to

828
00:30:47,039 --> 00:30:50,159
uh to match a preferred outcome in a

829
00:30:50,159 --> 00:30:52,240
internet dimensional setting so we we

830
00:30:52,240 --> 00:30:53,440
also try to

831
00:30:53,440 --> 00:30:55,679
to overcome this issue here

832
00:30:55,679 --> 00:30:57,760
so what we do propose is to use

833
00:30:57,760 --> 00:30:59,360
contrastive learning

834
00:30:59,360 --> 00:31:02,320
uh contrastive learning is a

835
00:31:02,320 --> 00:31:04,640
is a mechanism popular in the

836
00:31:04,640 --> 00:31:07,039
unsupervised learning scene that we will

837
00:31:07,039 --> 00:31:09,360
discuss more in depth in a few moments

838
00:31:09,360 --> 00:31:11,360
so the the

839
00:31:11,360 --> 00:31:13,120
the objective that we want to to have

840
00:31:13,120 --> 00:31:14,960
with our method are to avoid

841
00:31:14,960 --> 00:31:16,480
reconstruction in

842
00:31:16,480 --> 00:31:18,720
learning the word model so we don't have

843
00:31:18,720 --> 00:31:20,799
any more the decoder here as we see on

844
00:31:20,799 --> 00:31:22,000
the right

845
00:31:22,000 --> 00:31:23,679
then we want to be able to match

846
00:31:23,679 --> 00:31:25,559
preferred outcomes in a lower

847
00:31:25,559 --> 00:31:28,000
dimensionality space because we have

848
00:31:28,000 --> 00:31:30,320
seen that uh net dimensionality that's

849
00:31:30,320 --> 00:31:33,200
problematic and also we

850
00:31:33,200 --> 00:31:35,120
we would like the this low dimensional

851
00:31:35,120 --> 00:31:37,120
state to be somehow representative of

852
00:31:37,120 --> 00:31:39,600
the task so that we when we match

853
00:31:39,600 --> 00:31:42,799
our goal in this low dimensional state

854
00:31:42,799 --> 00:31:45,200
we are actually doing something that

855
00:31:45,200 --> 00:31:47,440
actually brings us closer to the actual

856
00:31:47,440 --> 00:31:49,519
preferred outcome that we we want to

857
00:31:49,519 --> 00:31:53,200
achieve in the i dimensional setting

858
00:31:53,279 --> 00:31:54,399
so

859
00:31:54,399 --> 00:31:55,279
let's

860
00:31:55,279 --> 00:31:57,840
let's try to compare

861
00:31:57,840 --> 00:31:59,600
to see what are the difference in

862
00:31:59,600 --> 00:32:01,600
between using the likelihood active

863
00:32:01,600 --> 00:32:03,200
inference model and the contrastive

864
00:32:03,200 --> 00:32:04,480
model so

865
00:32:04,480 --> 00:32:06,159
the idea in the likelihood active

866
00:32:06,159 --> 00:32:07,440
inference model is that we want to

867
00:32:07,440 --> 00:32:10,480
maximize the accuracy of reconstruction

868
00:32:10,480 --> 00:32:12,480
so basically this this means that we

869
00:32:12,480 --> 00:32:15,360
have this decoder that maximizes this

870
00:32:15,360 --> 00:32:16,159
uh

871
00:32:16,159 --> 00:32:18,720
maximum likelihood of the the

872
00:32:18,720 --> 00:32:21,440
observation given the state so we want

873
00:32:21,440 --> 00:32:22,880
the state to

874
00:32:22,880 --> 00:32:23,919
to

875
00:32:23,919 --> 00:32:26,880
to maximize the information that it

876
00:32:26,880 --> 00:32:30,000
contains about the observation basically

877
00:32:30,000 --> 00:32:32,559
in contrasting learning we

878
00:32:32,559 --> 00:32:34,880
in contrasting active inference we do

879
00:32:34,880 --> 00:32:37,039
something different so instead of trying

880
00:32:37,039 --> 00:32:39,200
to reconstruct

881
00:32:39,200 --> 00:32:40,960
the current observation

882
00:32:40,960 --> 00:32:43,279
we try to

883
00:32:43,279 --> 00:32:46,640
compress with the encoder again this

884
00:32:46,640 --> 00:32:47,919
observation

885
00:32:47,919 --> 00:32:51,840
and compare it to all the other uh to

886
00:32:51,840 --> 00:32:53,919
not all the other as we'll see in a

887
00:32:53,919 --> 00:32:56,720
while because it's invisible but many

888
00:32:56,720 --> 00:32:57,600
many

889
00:32:57,600 --> 00:32:59,679
other samples that represent something

890
00:32:59,679 --> 00:33:01,679
different so that we in the in the

891
00:33:01,679 --> 00:33:04,559
latent space in this compressed space

892
00:33:04,559 --> 00:33:05,679
we want

893
00:33:05,679 --> 00:33:07,200
our

894
00:33:07,200 --> 00:33:10,000
state and the compressed image to be

895
00:33:10,000 --> 00:33:11,279
very close

896
00:33:11,279 --> 00:33:15,039
uh while uh this our state should be

897
00:33:15,039 --> 00:33:17,120
very distant from all the other images

898
00:33:17,120 --> 00:33:17,919
so

899
00:33:17,919 --> 00:33:18,720
we

900
00:33:18,720 --> 00:33:20,799
we are indeed maximizing the similarity

901
00:33:20,799 --> 00:33:21,919
with this

902
00:33:21,919 --> 00:33:23,840
with the corresponding sample this is

903
00:33:23,840 --> 00:33:25,679
here called the positive sample where we

904
00:33:25,679 --> 00:33:27,760
want to minimize the similarities to

905
00:33:27,760 --> 00:33:30,080
maximize the distance against all the

906
00:33:30,080 --> 00:33:32,559
other samples that are called negative

907
00:33:32,559 --> 00:33:33,600
samples

908
00:33:33,600 --> 00:33:35,760
in contrastive learning so as we'll see

909
00:33:35,760 --> 00:33:36,720
also in

910
00:33:36,720 --> 00:33:39,760
in a moment this this mechanism here

911
00:33:39,760 --> 00:33:41,679
maximizes the lower bound of the mutual

912
00:33:41,679 --> 00:33:43,840
information so we are basically trying

913
00:33:43,840 --> 00:33:46,480
to maximize the information in between

914
00:33:46,480 --> 00:33:47,919
corresponding

915
00:33:47,919 --> 00:33:49,600
observation and state

916
00:33:49,600 --> 00:33:50,559
while

917
00:33:50,559 --> 00:33:52,320
minimizing the information with respect

918
00:33:52,320 --> 00:33:56,399
to to all the other negative pairs

919
00:33:56,720 --> 00:33:59,039
so as we've seen uh

920
00:33:59,039 --> 00:34:00,960
before the the free energetic past can

921
00:34:00,960 --> 00:34:02,799
be summarized

922
00:34:02,799 --> 00:34:06,000
with this equation here so here i'm just

923
00:34:06,000 --> 00:34:07,200
uh

924
00:34:07,200 --> 00:34:10,239
talking about one time a one moment in

925
00:34:10,239 --> 00:34:12,719
discrete time steps so instead the

926
00:34:12,719 --> 00:34:14,800
team presented for all sequences by

927
00:34:14,800 --> 00:34:16,639
using the tilde notation well here we're

928
00:34:16,639 --> 00:34:19,520
just considering one time steps

929
00:34:19,520 --> 00:34:22,399
at a time so

930
00:34:22,399 --> 00:34:23,359
as we

931
00:34:23,359 --> 00:34:25,520
as we have seen the free energy is

932
00:34:25,520 --> 00:34:27,440
basically uh

933
00:34:27,440 --> 00:34:29,918
an upper bond on the surprisal

934
00:34:29,918 --> 00:34:32,000
information that we we want to to

935
00:34:32,000 --> 00:34:35,359
minimize so we minimize free energy in

936
00:34:35,359 --> 00:34:36,800
order to

937
00:34:36,800 --> 00:34:39,359
minimize the surprise of the agent and

938
00:34:39,359 --> 00:34:42,800
the ear is is actually evident that

939
00:34:42,800 --> 00:34:44,639
we have this evidence spawn so the the

940
00:34:44,639 --> 00:34:46,639
scale divergence is always greater or

941
00:34:46,639 --> 00:34:48,560
equal to zero we wanted to

942
00:34:48,560 --> 00:34:50,239
basically to

943
00:34:50,239 --> 00:34:52,399
to reach zero hypothetically in order to

944
00:34:52,399 --> 00:34:54,159
minimize this uh

945
00:34:54,159 --> 00:34:56,399
this evidence bound

946
00:34:56,399 --> 00:35:00,000
and uh this can also be rewritten uh in

947
00:35:00,000 --> 00:35:02,079
a way it is more practical to implement

948
00:35:02,079 --> 00:35:03,839
it so by having

949
00:35:03,839 --> 00:35:06,400
the the likelihood of the observation

950
00:35:06,400 --> 00:35:09,119
given the state which actually means the

951
00:35:09,119 --> 00:35:12,000
accuracy of our model and having again

952
00:35:12,000 --> 00:35:14,480
the complexity of the model which is

953
00:35:14,480 --> 00:35:17,200
the the kl divergence between

954
00:35:17,200 --> 00:35:19,520
our variational distribution q

955
00:35:19,520 --> 00:35:21,760
uh which we

956
00:35:21,760 --> 00:35:24,480
we we use q of f given o which is

957
00:35:24,480 --> 00:35:27,280
basically using the auto encoding uh

958
00:35:27,280 --> 00:35:31,359
variation of a variational uh posterior

959
00:35:31,359 --> 00:35:33,520
so this is uh

960
00:35:33,520 --> 00:35:36,320
as typical as is done in uh in

961
00:35:36,320 --> 00:35:38,800
variational encoders so when you

962
00:35:38,800 --> 00:35:40,960
when you try to infer the parameters of

963
00:35:40,960 --> 00:35:43,599
your posterior distribution by using the

964
00:35:43,599 --> 00:35:45,680
corresponding observation

965
00:35:45,680 --> 00:35:47,200
and then we we want to minimize the

966
00:35:47,200 --> 00:35:49,839
child divergence between this uh auto

967
00:35:49,839 --> 00:35:54,480
encoded posterior and the our prior

968
00:35:54,480 --> 00:35:55,599
about the

969
00:35:55,599 --> 00:35:57,119
about the

970
00:35:57,119 --> 00:35:59,119
the current or future state we can say

971
00:35:59,119 --> 00:36:02,079
given the the past state and actions

972
00:36:02,079 --> 00:36:04,000
and in our case in particular we

973
00:36:04,000 --> 00:36:05,280
generally

974
00:36:05,280 --> 00:36:08,160
learn this this prior so we don't just

975
00:36:08,160 --> 00:36:09,680
use a

976
00:36:09,680 --> 00:36:12,560
a uniform prior state but we will learn

977
00:36:12,560 --> 00:36:15,440
uh our priors to be predictive

978
00:36:15,440 --> 00:36:17,920
of what the state is given uh the past

979
00:36:17,920 --> 00:36:20,720
states so it can basically seem like

980
00:36:20,720 --> 00:36:23,119
for machine learning prediction as a as

981
00:36:23,119 --> 00:36:25,200
a conditional uh variation of the

982
00:36:25,200 --> 00:36:27,839
encoder

983
00:36:28,000 --> 00:36:30,320
with with contrastive learning what we

984
00:36:30,320 --> 00:36:33,680
try to do is as i said to maximize state

985
00:36:33,680 --> 00:36:36,079
similarity uh with

986
00:36:36,079 --> 00:36:37,839
the correct and corresponding

987
00:36:37,839 --> 00:36:40,000
observations of our positive sample

988
00:36:40,000 --> 00:36:42,800
while minimizing with the other

989
00:36:42,800 --> 00:36:43,760
this

990
00:36:43,760 --> 00:36:45,920
means again that we want to

991
00:36:45,920 --> 00:36:48,160
maximize the mutual information between

992
00:36:48,160 --> 00:36:49,760
the positive sample

993
00:36:49,760 --> 00:36:51,280
and the corresponding state and

994
00:36:51,280 --> 00:36:53,520
minimizing the information with the

995
00:36:53,520 --> 00:36:55,119
negative samples

996
00:36:55,119 --> 00:36:59,040
this can be written like this so

997
00:36:59,040 --> 00:37:00,240
the

998
00:37:00,240 --> 00:37:01,920
noise contrastive

999
00:37:01,920 --> 00:37:04,240
estimation so nch that's the

1000
00:37:04,240 --> 00:37:06,959
abbreviation

1001
00:37:07,359 --> 00:37:09,440
basically provides uh

1002
00:37:09,440 --> 00:37:12,640
again a lower bound on the mutual uh

1003
00:37:12,640 --> 00:37:16,079
information uh so where we where we see

1004
00:37:16,079 --> 00:37:18,000
that we basically have like like a soft

1005
00:37:18,000 --> 00:37:19,200
max so

1006
00:37:19,200 --> 00:37:22,720
over the over all the the

1007
00:37:22,720 --> 00:37:24,800
the observation state what does it mean

1008
00:37:24,800 --> 00:37:27,680
so uh for each a pair of state and

1009
00:37:27,680 --> 00:37:29,280
observation

1010
00:37:29,280 --> 00:37:32,560
we want uh this value so the value of

1011
00:37:32,560 --> 00:37:35,440
this critic this this critic function f

1012
00:37:35,440 --> 00:37:36,960
to be as

1013
00:37:36,960 --> 00:37:39,839
high as possible or we want it to be a

1014
00:37:39,839 --> 00:37:41,040
very low

1015
00:37:41,040 --> 00:37:42,800
respect to the other so that actually

1016
00:37:42,800 --> 00:37:45,760
the exponential of this

1017
00:37:45,760 --> 00:37:47,359
compared to the sum of all the other

1018
00:37:47,359 --> 00:37:48,960
exponential is higher with the

1019
00:37:48,960 --> 00:37:51,040
corresponding exhibition and

1020
00:37:51,040 --> 00:37:52,720
very low with the rest

1021
00:37:52,720 --> 00:37:55,359
so this is basically saying that uh that

1022
00:37:55,359 --> 00:37:58,240
you'd want matching pairs to be to be

1023
00:37:58,240 --> 00:38:00,720
very close and distant pairs to

1024
00:38:00,720 --> 00:38:03,280
to a very very low value

1025
00:38:03,280 --> 00:38:05,359
and the the

1026
00:38:05,359 --> 00:38:07,598
this

1027
00:38:08,000 --> 00:38:09,760
this lower bound

1028
00:38:09,760 --> 00:38:12,000
is is an approximation normally when we

1029
00:38:12,000 --> 00:38:12,960
take

1030
00:38:12,960 --> 00:38:15,760
a number of samples key from

1031
00:38:15,760 --> 00:38:18,400
a joint distribution that we define

1032
00:38:18,400 --> 00:38:22,320
uh between x and y in particular in our

1033
00:38:22,320 --> 00:38:25,359
case this x and y represent

1034
00:38:25,359 --> 00:38:29,040
our observation and our hidden states

1035
00:38:29,040 --> 00:38:32,800
so we define a priorities uh

1036
00:38:32,800 --> 00:38:34,560
this joint distribution to actually

1037
00:38:34,560 --> 00:38:36,960
represent the fact that this state

1038
00:38:36,960 --> 00:38:39,760
corresponds to this observation and we

1039
00:38:39,760 --> 00:38:41,359
want to maximize the information in

1040
00:38:41,359 --> 00:38:43,200
between them

1041
00:38:43,200 --> 00:38:45,839
and this

1042
00:38:45,839 --> 00:38:46,800
x y

1043
00:38:46,800 --> 00:38:48,079
again is a

1044
00:38:48,079 --> 00:38:50,079
so-called critic function

1045
00:38:50,079 --> 00:38:52,000
so what does it mean is a function that

1046
00:38:52,000 --> 00:38:54,400
should approximate this log density

1047
00:38:54,400 --> 00:38:56,800
ratio that we see here on the right i

1048
00:38:56,800 --> 00:38:58,640
won't go into the the mathematical

1049
00:38:58,640 --> 00:39:01,040
details of this but basically

1050
00:39:01,040 --> 00:39:04,000
it is a mapping of the

1051
00:39:04,000 --> 00:39:06,560
of two the two inputs so basically is a

1052
00:39:06,560 --> 00:39:10,320
mapping of our observation and our state

1053
00:39:10,320 --> 00:39:13,040
uh and we want this uh again these

1054
00:39:13,040 --> 00:39:16,160
outputs to be i for corresponding pairs

1055
00:39:16,160 --> 00:39:20,720
and and low for non-corresponding pairs

1056
00:39:20,720 --> 00:39:21,839
so

1057
00:39:21,839 --> 00:39:23,839
how do we transition from the free

1058
00:39:23,839 --> 00:39:26,560
energy of the path

1059
00:39:26,560 --> 00:39:28,320
that we have seen today to our

1060
00:39:28,320 --> 00:39:31,200
contrasting formulation

1061
00:39:31,200 --> 00:39:33,280
so what the

1062
00:39:33,280 --> 00:39:36,400
the first step that we do is adding to

1063
00:39:36,400 --> 00:39:38,800
the to the free energy functional

1064
00:39:38,800 --> 00:39:40,960
uh a term that we

1065
00:39:40,960 --> 00:39:43,520
we assume to be constant that is the

1066
00:39:43,520 --> 00:39:46,240
the entropy of the observation so how

1067
00:39:46,240 --> 00:39:48,000
can we assume that the entropy of the

1068
00:39:48,000 --> 00:39:49,760
observation is constant

1069
00:39:49,760 --> 00:39:52,400
so in machine learning we generally have

1070
00:39:52,400 --> 00:39:55,119
a data set from which we samples our

1071
00:39:55,119 --> 00:39:58,000
observation about the past so we assume

1072
00:39:58,000 --> 00:40:00,320
when we train that our

1073
00:40:00,320 --> 00:40:02,720
data set so that the distribution over

1074
00:40:02,720 --> 00:40:05,119
the observation is fixed

1075
00:40:05,119 --> 00:40:07,359
so the the entropy

1076
00:40:07,359 --> 00:40:09,599
of this distribution will always be a

1077
00:40:09,599 --> 00:40:13,119
constant because we cannot modify that

1078
00:40:13,119 --> 00:40:15,200
as opposed for instance to the states

1079
00:40:15,200 --> 00:40:17,200
which which we instead learn so the

1080
00:40:17,200 --> 00:40:18,800
distribution of our outcomes cannot be

1081
00:40:18,800 --> 00:40:20,800
modified and so its entropy is a

1082
00:40:20,800 --> 00:40:23,680
constant if we add this term to the free

1083
00:40:23,680 --> 00:40:25,280
energy functional

1084
00:40:25,280 --> 00:40:27,760
we can rewrite it as a as the child

1085
00:40:27,760 --> 00:40:30,560
divergence minus this

1086
00:40:30,560 --> 00:40:33,119
information gain or mutual information

1087
00:40:33,119 --> 00:40:35,599
term here between the states and the

1088
00:40:35,599 --> 00:40:37,680
observation

1089
00:40:37,680 --> 00:40:40,240
so given this we can now

1090
00:40:40,240 --> 00:40:41,440
apply

1091
00:40:41,440 --> 00:40:44,560
the fact that we did

1092
00:40:44,560 --> 00:40:48,079
contrastive learning uh

1093
00:40:48,079 --> 00:40:50,960
functional is a is a lower bound on the

1094
00:40:50,960 --> 00:40:53,119
mutual information to actually derive

1095
00:40:53,119 --> 00:40:55,680
the free energy of the past

1096
00:40:55,680 --> 00:40:59,119
we're expliciting all the terms out

1097
00:40:59,119 --> 00:41:02,400
according to the the previous slide math

1098
00:41:02,400 --> 00:41:04,880
we basically have again this kl

1099
00:41:04,880 --> 00:41:07,920
divergence term and then we have

1100
00:41:07,920 --> 00:41:10,560
this uh the value

1101
00:41:10,560 --> 00:41:11,920
of f

1102
00:41:11,920 --> 00:41:15,440
between o and s to maximize and then to

1103
00:41:15,440 --> 00:41:17,200
minimize all the

1104
00:41:17,200 --> 00:41:18,560
uh

1105
00:41:18,560 --> 00:41:21,280
again the

1106
00:41:21,280 --> 00:41:23,680
the the value of the functional with

1107
00:41:23,680 --> 00:41:27,919
respect to all the other negative pairs

1108
00:41:28,160 --> 00:41:29,599
so

1109
00:41:29,599 --> 00:41:32,560
this brings us to

1110
00:41:32,560 --> 00:41:35,040
to again an upper bound on the surprisal

1111
00:41:35,040 --> 00:41:38,079
term we see that the this upper bound is

1112
00:41:38,079 --> 00:41:38,960
actually

1113
00:41:38,960 --> 00:41:40,319
even

1114
00:41:40,319 --> 00:41:43,119
higher than the normal uh free energy

1115
00:41:43,119 --> 00:41:45,839
upper bound but as we'll see later these

1116
00:41:45,839 --> 00:41:46,880
are some

1117
00:41:46,880 --> 00:41:49,839
nice property that

1118
00:41:49,839 --> 00:41:52,319
explicitly help us to get rid of the

1119
00:41:52,319 --> 00:41:54,160
reconstruction and to learn a different

1120
00:41:54,160 --> 00:41:56,400
representational space that has some

1121
00:41:56,400 --> 00:41:58,560
advantages compared to the

1122
00:41:58,560 --> 00:42:00,240
to the likelihood

1123
00:42:00,240 --> 00:42:01,440
based uh

1124
00:42:01,440 --> 00:42:04,240
representation

1125
00:42:04,400 --> 00:42:05,520
so

1126
00:42:05,520 --> 00:42:08,960
let's now talk about how can we learn uh

1127
00:42:08,960 --> 00:42:11,599
to behave using contrasting vacuum

1128
00:42:11,599 --> 00:42:13,359
inference so in the likelihood based

1129
00:42:13,359 --> 00:42:14,960
active influence model

1130
00:42:14,960 --> 00:42:16,960
what we were trying to maximize was

1131
00:42:16,960 --> 00:42:19,680
again the likelihood of the future

1132
00:42:19,680 --> 00:42:21,599
observation but under the preferred

1133
00:42:21,599 --> 00:42:25,200
distribution so we want to

1134
00:42:25,200 --> 00:42:27,760
we want the imaging outcomes to be as

1135
00:42:27,760 --> 00:42:29,680
close as possible to the

1136
00:42:29,680 --> 00:42:33,119
to the outcomes that we prefer

1137
00:42:33,119 --> 00:42:34,079
uh

1138
00:42:34,079 --> 00:42:36,480
so this for visual environment implies

1139
00:42:36,480 --> 00:42:37,520
that we

1140
00:42:37,520 --> 00:42:39,520
we reconstruct what the

1141
00:42:39,520 --> 00:42:41,200
what we imagine will happen in the i

1142
00:42:41,200 --> 00:42:42,400
dimensional

1143
00:42:42,400 --> 00:42:43,440
uh

1144
00:42:43,440 --> 00:42:45,760
space so the image basically and then we

1145
00:42:45,760 --> 00:42:49,200
compare it to our uh preferred image for

1146
00:42:49,200 --> 00:42:50,400
instance

1147
00:42:50,400 --> 00:42:52,480
and uh as we see before we can for

1148
00:42:52,480 --> 00:42:54,560
instance use a max mean square there or

1149
00:42:54,560 --> 00:42:58,079
distance or we can just use like uh

1150
00:42:58,079 --> 00:42:59,599
we can use the condition and compute the

1151
00:42:59,599 --> 00:43:02,000
likelihood under the preferred

1152
00:43:02,000 --> 00:43:03,920
distribution

1153
00:43:03,920 --> 00:43:05,680
for contrastive active inference we

1154
00:43:05,680 --> 00:43:07,599
again instead use a contrasting

1155
00:43:07,599 --> 00:43:10,640
mechanism when we want now the

1156
00:43:10,640 --> 00:43:13,680
the future state to be corresponding

1157
00:43:13,680 --> 00:43:15,599
with our uh

1158
00:43:15,599 --> 00:43:17,440
samples from the preferred distribution

1159
00:43:17,440 --> 00:43:18,880
so we want the

1160
00:43:18,880 --> 00:43:20,960
the outcomes that we prefer to actually

1161
00:43:20,960 --> 00:43:21,839
be

1162
00:43:21,839 --> 00:43:24,000
uh close to the to the state that we

1163
00:43:24,000 --> 00:43:25,839
imagine so that now we don't need

1164
00:43:25,839 --> 00:43:28,000
anymore to reconstruct

1165
00:43:28,000 --> 00:43:30,640
what the what the outcome of our action

1166
00:43:30,640 --> 00:43:34,000
will look like but we can just say is

1167
00:43:34,000 --> 00:43:36,560
the the state that we imagine matching

1168
00:43:36,560 --> 00:43:38,079
with uh

1169
00:43:38,079 --> 00:43:39,839
the preferred outcome that they want to

1170
00:43:39,839 --> 00:43:40,720
achieve

1171
00:43:40,720 --> 00:43:42,240
and uh

1172
00:43:42,240 --> 00:43:44,240
that's that's what we we maximize

1173
00:43:44,240 --> 00:43:46,800
similarity with and again we also have

1174
00:43:46,800 --> 00:43:47,760
some

1175
00:43:47,760 --> 00:43:50,480
some form of ambiguity minimization or

1176
00:43:50,480 --> 00:43:52,720
epistemic value in trying to minimize

1177
00:43:52,720 --> 00:43:56,000
the similarity respect to other

1178
00:43:56,000 --> 00:43:59,280
outcomes so in this case minimizing

1179
00:43:59,280 --> 00:44:01,119
the similarity respect to

1180
00:44:01,119 --> 00:44:02,720
outcomes that are not in the preferred

1181
00:44:02,720 --> 00:44:04,880
distribution basically means that

1182
00:44:04,880 --> 00:44:07,119
you either want to go far from something

1183
00:44:07,119 --> 00:44:10,400
that you have already seen before

1184
00:44:10,400 --> 00:44:12,480
in order to maybe get closer to the to

1185
00:44:12,480 --> 00:44:15,359
the preferred outcomes or you either

1186
00:44:15,359 --> 00:44:16,800
just want to

1187
00:44:16,800 --> 00:44:18,560
minimize your ambiguity so you want to

1188
00:44:18,560 --> 00:44:20,720
be as far as possible from other

1189
00:44:20,720 --> 00:44:23,440
outcomes and as close as possible to the

1190
00:44:23,440 --> 00:44:25,280
to the actual preferred

1191
00:44:25,280 --> 00:44:27,359
outcome that you

1192
00:44:27,359 --> 00:44:30,000
that you're hoping for

1193
00:44:30,000 --> 00:44:31,040
so

1194
00:44:31,040 --> 00:44:33,119
as we've seen before the expected free

1195
00:44:33,119 --> 00:44:34,160
energy

1196
00:44:34,160 --> 00:44:35,920
can be summarized like this i i'll first

1197
00:44:35,920 --> 00:44:38,319
i like some difference in respect to

1198
00:44:38,319 --> 00:44:40,160
to the

1199
00:44:40,160 --> 00:44:42,160
equation the team presented so first of

1200
00:44:42,160 --> 00:44:45,440
all here we we take action to be part of

1201
00:44:45,440 --> 00:44:46,400
the

1202
00:44:46,400 --> 00:44:48,720
octave active inference process so the

1203
00:44:48,720 --> 00:44:51,040
inference process well uh

1204
00:44:51,040 --> 00:44:53,200
before we have seen that you can

1205
00:44:53,200 --> 00:44:54,560
you can have a distribution of our

1206
00:44:54,560 --> 00:44:57,520
policies and then you can you can sample

1207
00:44:57,520 --> 00:44:59,520
the action from the policy

1208
00:44:59,520 --> 00:45:01,760
and and compute the free energy of the

1209
00:45:01,760 --> 00:45:04,640
future uh given

1210
00:45:04,640 --> 00:45:06,400
a posterior

1211
00:45:06,400 --> 00:45:08,800
on your

1212
00:45:08,800 --> 00:45:10,960
on a policy on a given policy instead

1213
00:45:10,960 --> 00:45:13,599
here we we make the the actions part of

1214
00:45:13,599 --> 00:45:16,160
the degenerative model for the future

1215
00:45:16,160 --> 00:45:18,319
and we actually want the agent to to

1216
00:45:18,319 --> 00:45:20,800
infer the reaction from the future and

1217
00:45:20,800 --> 00:45:23,440
not just compute them as a

1218
00:45:23,440 --> 00:45:25,760
as a posterior over over some

1219
00:45:25,760 --> 00:45:28,400
distribution of the overhead policies

1220
00:45:28,400 --> 00:45:32,160
so we we have now in the posterior is uh

1221
00:45:32,160 --> 00:45:33,839
this 80

1222
00:45:33,839 --> 00:45:36,640
so we that we infer both the the

1223
00:45:36,640 --> 00:45:38,560
the the future state and the future

1224
00:45:38,560 --> 00:45:39,520
action

1225
00:45:39,520 --> 00:45:42,480
and also the the prior other over the

1226
00:45:42,480 --> 00:45:44,800
preferred outcomes that i indicate with

1227
00:45:44,800 --> 00:45:47,040
tilde i hope that's not confusing before

1228
00:45:47,040 --> 00:45:48,480
because before

1229
00:45:48,480 --> 00:45:50,400
the tilde was used to to indicate

1230
00:45:50,400 --> 00:45:51,920
sequences but

1231
00:45:51,920 --> 00:45:53,680
in the paper i actually used it to to

1232
00:45:53,680 --> 00:45:56,720
indicate the preferred outcomes so yeah

1233
00:45:56,720 --> 00:45:58,640
notation issues but uh i hope that's not

1234
00:45:58,640 --> 00:46:00,000
confusing so the till the year is

1235
00:46:00,000 --> 00:46:02,319
basically to say this is the preferred

1236
00:46:02,319 --> 00:46:05,760
uh distribution over observation state

1237
00:46:05,760 --> 00:46:08,400
and action so this is basically our

1238
00:46:08,400 --> 00:46:10,560
target distribution what we what we hope

1239
00:46:10,560 --> 00:46:12,400
to achieve in the future

1240
00:46:12,400 --> 00:46:15,680
and we can rewrite this as a

1241
00:46:15,680 --> 00:46:18,160
as the the sum of three terms so we have

1242
00:46:18,160 --> 00:46:19,280
this uh

1243
00:46:19,280 --> 00:46:21,359
uh so first of all i'm assuming that the

1244
00:46:21,359 --> 00:46:23,280
agent has

1245
00:46:23,280 --> 00:46:25,920
no prior preference on action so that

1246
00:46:25,920 --> 00:46:27,359
for him

1247
00:46:27,359 --> 00:46:29,119
any action that will bring it to the

1248
00:46:29,119 --> 00:46:32,720
preferred outcomes it's fine so yes

1249
00:46:32,720 --> 00:46:34,800
a uniform prior over action so the

1250
00:46:34,800 --> 00:46:35,760
action

1251
00:46:35,760 --> 00:46:37,760
doesn't really matter what it is as long

1252
00:46:37,760 --> 00:46:39,520
as it brings to the to the goal let's

1253
00:46:39,520 --> 00:46:40,480
say

1254
00:46:40,480 --> 00:46:43,680
and so this in this way uh we we obtain

1255
00:46:43,680 --> 00:46:46,160
an action entropy term and then uh the

1256
00:46:46,160 --> 00:46:49,440
rest the intrinsic value is the is the

1257
00:46:49,440 --> 00:46:51,599
same epistemic value that we've seen

1258
00:46:51,599 --> 00:46:53,920
before and uh

1259
00:46:53,920 --> 00:46:55,839
so the one that uh

1260
00:46:55,839 --> 00:46:58,079
should lead the agent to

1261
00:46:58,079 --> 00:47:00,000
to explore the environment more or

1262
00:47:00,000 --> 00:47:01,920
either to reduce its ambiguity about the

1263
00:47:01,920 --> 00:47:03,839
environment and then we have the

1264
00:47:03,839 --> 00:47:06,480
extrinsic value which is basically

1265
00:47:06,480 --> 00:47:09,119
rewards or uh

1266
00:47:09,119 --> 00:47:11,040
just uh

1267
00:47:11,040 --> 00:47:12,960
just a way to get closer to the to the

1268
00:47:12,960 --> 00:47:15,680
actual uh preferred outcomes so the the

1269
00:47:15,680 --> 00:47:17,839
value to pursue in order to

1270
00:47:17,839 --> 00:47:20,319
to minimize distance uh from the from

1271
00:47:20,319 --> 00:47:23,119
the preferred outcomes

1272
00:47:23,119 --> 00:47:26,559
in our contrastive expected free energy

1273
00:47:26,559 --> 00:47:30,000
uh we we again do a similar move as we

1274
00:47:30,000 --> 00:47:33,119
did from the past so here we assume

1275
00:47:33,119 --> 00:47:35,680
that we are taking expectation over our

1276
00:47:35,680 --> 00:47:37,680
preferred outcomes since we don't

1277
00:47:37,680 --> 00:47:39,680
imagine outcomes in the future we just

1278
00:47:39,680 --> 00:47:41,760
assume that the outcomes will

1279
00:47:41,760 --> 00:47:42,720
will be

1280
00:47:42,720 --> 00:47:44,079
according to the to the preferred

1281
00:47:44,079 --> 00:47:45,920
outcome distribution so that we can

1282
00:47:45,920 --> 00:47:47,520
again sum

1283
00:47:47,520 --> 00:47:50,400
the entropy over the our fixed uh

1284
00:47:50,400 --> 00:47:52,640
preferred outcome distribution

1285
00:47:52,640 --> 00:47:55,200
and then the steps are the same so we we

1286
00:47:55,200 --> 00:47:56,880
have again this

1287
00:47:56,880 --> 00:47:59,119
mutual information term between the

1288
00:47:59,119 --> 00:48:01,839
preferred outcomes and the the state

1289
00:48:01,839 --> 00:48:04,079
that we imagine in the future and the

1290
00:48:04,079 --> 00:48:06,960
the the action entropy term and

1291
00:48:06,960 --> 00:48:10,640
uh this scale divergence between

1292
00:48:10,640 --> 00:48:13,040
uh the posterior states and the prior of

1293
00:48:13,040 --> 00:48:14,720
states so

1294
00:48:14,720 --> 00:48:16,559
is uh

1295
00:48:16,559 --> 00:48:18,480
a complex term

1296
00:48:18,480 --> 00:48:20,640
i'll say because it basically

1297
00:48:20,640 --> 00:48:22,079
should represent

1298
00:48:22,079 --> 00:48:24,880
uh the difference between what the what

1299
00:48:24,880 --> 00:48:27,760
agent believes it will happen and

1300
00:48:27,760 --> 00:48:29,440
and what is supposed to happen in the

1301
00:48:29,440 --> 00:48:31,520
environment so normally in active

1302
00:48:31,520 --> 00:48:33,040
inference we assume

1303
00:48:33,040 --> 00:48:35,200
for the future that the the model of the

1304
00:48:35,200 --> 00:48:36,800
world is correct

1305
00:48:36,800 --> 00:48:39,599
so that the agent does not control over

1306
00:48:39,599 --> 00:48:42,240
over his world model so he cannot change

1307
00:48:42,240 --> 00:48:43,359
how the

1308
00:48:43,359 --> 00:48:45,520
the environment dynamics will transition

1309
00:48:45,520 --> 00:48:47,760
from one state to another so

1310
00:48:47,760 --> 00:48:50,319
i i'm assuming here that

1311
00:48:50,319 --> 00:48:52,559
this is this scale divergent term is

1312
00:48:52,559 --> 00:48:55,760
actually zero though i've seen that some

1313
00:48:55,760 --> 00:48:58,000
work this could also be be left there

1314
00:48:58,000 --> 00:49:00,160
are being greater than zero but then

1315
00:49:00,160 --> 00:49:03,040
then it's basically uh adding the agent

1316
00:49:03,040 --> 00:49:06,160
imagines that he can um it can violate

1317
00:49:06,160 --> 00:49:08,319
the the environment dynamics hoping for

1318
00:49:08,319 --> 00:49:10,559
a better dynamics that it will allow it

1319
00:49:10,559 --> 00:49:11,599
to

1320
00:49:11,599 --> 00:49:14,480
uh to be optimistic and think uh yeah

1321
00:49:14,480 --> 00:49:16,800
the thing that i imagine it will happen

1322
00:49:16,800 --> 00:49:18,640
it's actually gonna happen

1323
00:49:18,640 --> 00:49:21,440
so here we we don't allow the agent to

1324
00:49:21,440 --> 00:49:24,000
to modify all the environment move from

1325
00:49:24,000 --> 00:49:25,760
one state to another and we just assume

1326
00:49:25,760 --> 00:49:28,559
yeah the dynamics environment so our

1327
00:49:28,559 --> 00:49:30,559
posterior over the

1328
00:49:30,559 --> 00:49:31,839
the transition dynamics of the

1329
00:49:31,839 --> 00:49:33,599
environment is correct and so the scale

1330
00:49:33,599 --> 00:49:36,640
diverging in zero and then our objective

1331
00:49:36,640 --> 00:49:38,079
uh again

1332
00:49:38,079 --> 00:49:39,760
doing the

1333
00:49:39,760 --> 00:49:41,599
applying the the contrast if the

1334
00:49:41,599 --> 00:49:42,880
learning uh

1335
00:49:42,880 --> 00:49:46,240
lower bound translates into this when we

1336
00:49:46,240 --> 00:49:48,480
we have this uh contrastive mutual

1337
00:49:48,480 --> 00:49:50,079
information between the preferred

1338
00:49:50,079 --> 00:49:52,559
outcomes and these

1339
00:49:52,559 --> 00:49:55,440
this action entropy term so

1340
00:49:55,440 --> 00:49:57,760
if you write it out explicitly we again

1341
00:49:57,760 --> 00:50:00,319
have this uh this two term which kind of

1342
00:50:00,319 --> 00:50:02,960
reminds the two extrinsic value and

1343
00:50:02,960 --> 00:50:05,119
intrinsic value for

1344
00:50:05,119 --> 00:50:08,079
for the free energy so we have this uh

1345
00:50:08,079 --> 00:50:10,839
the term that actually

1346
00:50:10,839 --> 00:50:13,680
should minimize the similarity with the

1347
00:50:13,680 --> 00:50:16,559
with the negative sample that is doing

1348
00:50:16,559 --> 00:50:20,319
something similar uh to what the the

1349
00:50:20,319 --> 00:50:22,559
intrinsic value in inactive inference

1350
00:50:22,559 --> 00:50:24,319
should do so basically

1351
00:50:24,319 --> 00:50:27,920
trying to to be distant from

1352
00:50:27,920 --> 00:50:31,359
from previously seen uh outcomes is is

1353
00:50:31,359 --> 00:50:32,800
kind of similar to

1354
00:50:32,800 --> 00:50:34,960
explore the environment to minimize your

1355
00:50:34,960 --> 00:50:37,440
ambiguity so try to find something that

1356
00:50:37,440 --> 00:50:39,440
gives you more information not something

1357
00:50:39,440 --> 00:50:42,480
that you have already seen

1358
00:50:42,480 --> 00:50:43,680
and so

1359
00:50:43,680 --> 00:50:46,559
the the the world model can be

1360
00:50:46,559 --> 00:50:48,880
summarized in

1361
00:50:48,880 --> 00:50:50,000
these three

1362
00:50:50,000 --> 00:50:52,079
main components that we learn we have

1363
00:50:52,079 --> 00:50:55,599
our prior network that

1364
00:50:55,599 --> 00:50:58,400
as i said before is learned

1365
00:50:58,400 --> 00:51:00,640
and should learn the the transition

1366
00:51:00,640 --> 00:51:02,240
dynamics of the environment so trying to

1367
00:51:02,240 --> 00:51:04,160
predict future states

1368
00:51:04,160 --> 00:51:05,440
given

1369
00:51:05,440 --> 00:51:07,599
past states and actions

1370
00:51:07,599 --> 00:51:10,480
and then we have this gre self that is

1371
00:51:10,480 --> 00:51:12,640
shared between the the prior and the

1372
00:51:12,640 --> 00:51:14,400
posterior network and this is what

1373
00:51:14,400 --> 00:51:16,880
allows us to to brings our history with

1374
00:51:16,880 --> 00:51:17,680
us

1375
00:51:17,680 --> 00:51:19,839
so just not stop to the previous state

1376
00:51:19,839 --> 00:51:21,599
but also to include some information

1377
00:51:21,599 --> 00:51:23,440
about previous states

1378
00:51:23,440 --> 00:51:24,880
so that we have more

1379
00:51:24,880 --> 00:51:27,119
more information available in order to

1380
00:51:27,119 --> 00:51:29,359
infer what the current state is uh

1381
00:51:29,359 --> 00:51:30,640
actually is

1382
00:51:30,640 --> 00:51:33,280
then we have our posterior network which

1383
00:51:33,280 --> 00:51:38,160
also has access to the observation and

1384
00:51:38,160 --> 00:51:41,440
this posterior cnn as a as i mentioned

1385
00:51:41,440 --> 00:51:43,920
is a compositional neural network and

1386
00:51:43,920 --> 00:51:46,000
yeah here we have the actual layer

1387
00:51:46,000 --> 00:51:47,839
description for our environment which

1388
00:51:47,839 --> 00:51:48,559
are

1389
00:51:48,559 --> 00:51:51,680
64 by 64. but yeah that's that's less

1390
00:51:51,680 --> 00:51:53,119
important important thing is that we

1391
00:51:53,119 --> 00:51:55,119
have a convolutional model that

1392
00:51:55,119 --> 00:51:56,800
compresses the information from the

1393
00:51:56,800 --> 00:51:58,640
observation for us

1394
00:51:58,640 --> 00:52:00,720
and this same

1395
00:52:00,720 --> 00:52:02,960
convolutional network is also linked to

1396
00:52:02,960 --> 00:52:05,359
the to the representation model

1397
00:52:05,359 --> 00:52:06,559
that is uh

1398
00:52:06,559 --> 00:52:08,480
this

1399
00:52:08,480 --> 00:52:10,400
the the critic of the contrastive

1400
00:52:10,400 --> 00:52:12,960
learning mechanism so the function that

1401
00:52:12,960 --> 00:52:14,079
is indeed

1402
00:52:14,079 --> 00:52:18,079
matching states and the observation

1403
00:52:18,079 --> 00:52:20,079
in order to learn the

1404
00:52:20,079 --> 00:52:22,720
a good contrastive learning

1405
00:52:22,720 --> 00:52:25,040
representation

1406
00:52:25,040 --> 00:52:26,240
so

1407
00:52:26,240 --> 00:52:28,240
the the function that we minimize with

1408
00:52:28,240 --> 00:52:30,720
respect to the past is uh

1409
00:52:30,720 --> 00:52:32,480
is our contrasting free energy of the

1410
00:52:32,480 --> 00:52:34,640
past uh summed over

1411
00:52:34,640 --> 00:52:37,920
uh an arbitrary number of uh of discrete

1412
00:52:37,920 --> 00:52:41,839
time steps in the over past sequences

1413
00:52:41,839 --> 00:52:44,000
it is important to say that uh

1414
00:52:44,000 --> 00:52:46,319
for the past the negative samples that

1415
00:52:46,319 --> 00:52:47,520
we take

1416
00:52:47,520 --> 00:52:48,960
are uh

1417
00:52:48,960 --> 00:52:50,319
observation

1418
00:52:50,319 --> 00:52:53,119
uh of the

1419
00:52:53,119 --> 00:52:55,680
of the same sequence of the of the

1420
00:52:55,680 --> 00:52:57,680
corresponding observations so let's say

1421
00:52:57,680 --> 00:52:58,640
that we have

1422
00:52:58,640 --> 00:53:00,319
an observation in the states the

1423
00:53:00,319 --> 00:53:02,800
negative samples will be

1424
00:53:02,800 --> 00:53:04,800
uh all the other observations within the

1425
00:53:04,800 --> 00:53:06,960
same sequence that are not the same in

1426
00:53:06,960 --> 00:53:07,839
time

1427
00:53:07,839 --> 00:53:10,960
but also observation that come from from

1428
00:53:10,960 --> 00:53:12,800
other sequences so

1429
00:53:12,800 --> 00:53:15,280
so that we're basically contrasting

1430
00:53:15,280 --> 00:53:16,640
uh the

1431
00:53:16,640 --> 00:53:19,119
the current state with uh

1432
00:53:19,119 --> 00:53:21,359
different time steps so

1433
00:53:21,359 --> 00:53:23,760
uh what happened in different uh moment

1434
00:53:23,760 --> 00:53:26,720
of the same sequence of actions and what

1435
00:53:26,720 --> 00:53:28,640
happened in different situations or

1436
00:53:28,640 --> 00:53:30,400
different sequences

1437
00:53:30,400 --> 00:53:32,800
and that's how we

1438
00:53:32,800 --> 00:53:34,640
we try to

1439
00:53:34,640 --> 00:53:36,319
to foster our contrastive learning

1440
00:53:36,319 --> 00:53:38,400
mechanism

1441
00:53:38,400 --> 00:53:40,559
then we have the action model so for our

1442
00:53:40,559 --> 00:53:44,640
action model we have two uh networks one

1443
00:53:44,640 --> 00:53:46,720
is the so-called action network which

1444
00:53:46,720 --> 00:53:48,559
basically infers the

1445
00:53:48,559 --> 00:53:50,800
the action to to take

1446
00:53:50,800 --> 00:53:52,800
a given state and then we have this

1447
00:53:52,800 --> 00:53:55,599
expected utility network and this

1448
00:53:55,599 --> 00:53:57,839
helps us pursuing what

1449
00:53:57,839 --> 00:53:58,640
uh

1450
00:53:58,640 --> 00:54:00,720
team anticipated so that the fact that

1451
00:54:00,720 --> 00:54:02,000
we

1452
00:54:02,000 --> 00:54:04,079
we are

1453
00:54:04,079 --> 00:54:07,119
amortizing the action selection process

1454
00:54:07,119 --> 00:54:09,680
for a very

1455
00:54:09,680 --> 00:54:13,280
long-term sequences by using a

1456
00:54:13,280 --> 00:54:15,680
network that should

1457
00:54:15,680 --> 00:54:18,720
estimate what the value of a certain

1458
00:54:18,720 --> 00:54:21,280
state is in the future

1459
00:54:21,280 --> 00:54:23,599
so i'll try to be

1460
00:54:23,599 --> 00:54:24,640
more

1461
00:54:24,640 --> 00:54:26,800
more clear here so basically you have

1462
00:54:26,800 --> 00:54:30,240
the action network to

1463
00:54:30,240 --> 00:54:32,400
minimize this uh

1464
00:54:32,400 --> 00:54:34,640
this g lambda

1465
00:54:34,640 --> 00:54:37,599
t a functional that is basically

1466
00:54:37,599 --> 00:54:39,760
an estimate uh

1467
00:54:39,760 --> 00:54:42,160
that of uh

1468
00:54:42,160 --> 00:54:46,079
of how much value is in a certain states

1469
00:54:46,079 --> 00:54:48,960
and how do we get this this estimate

1470
00:54:48,960 --> 00:54:50,079
so

1471
00:54:50,079 --> 00:54:53,119
this estimate is is provided by this uh

1472
00:54:53,119 --> 00:54:56,480
formula here so basically at every step

1473
00:54:56,480 --> 00:54:57,280
uh

1474
00:54:57,280 --> 00:55:01,200
we provide the the actual uh expected uh

1475
00:55:01,200 --> 00:55:03,359
contrasting free energy for that state

1476
00:55:03,359 --> 00:55:04,559
and then

1477
00:55:04,559 --> 00:55:07,359
for the future uh

1478
00:55:07,359 --> 00:55:08,079
we

1479
00:55:08,079 --> 00:55:09,920
with some uh

1480
00:55:09,920 --> 00:55:12,319
we compromise in between uh an estimate

1481
00:55:12,319 --> 00:55:13,680
of what the what the network would

1482
00:55:13,680 --> 00:55:14,640
predict

1483
00:55:14,640 --> 00:55:16,000
uh it's gonna

1484
00:55:16,000 --> 00:55:18,240
it's gonna be the value in the future

1485
00:55:18,240 --> 00:55:21,520
and the the value itself that we are

1486
00:55:21,520 --> 00:55:22,720
that we are

1487
00:55:22,720 --> 00:55:25,200
computing with the with the functional

1488
00:55:25,200 --> 00:55:27,920
so that every step we basically

1489
00:55:27,920 --> 00:55:28,880
uh

1490
00:55:28,880 --> 00:55:31,200
sum the value that we we expect in that

1491
00:55:31,200 --> 00:55:32,240
step

1492
00:55:32,240 --> 00:55:33,040
uh

1493
00:55:33,040 --> 00:55:34,480
we bootstrap

1494
00:55:34,480 --> 00:55:36,079
this that's the way we normally say

1495
00:55:36,079 --> 00:55:38,079
reinforcement learning so we

1496
00:55:38,079 --> 00:55:40,079
we apply some form of dynamic uh

1497
00:55:40,079 --> 00:55:42,319
programming approach to

1498
00:55:42,319 --> 00:55:44,880
to sum this value with uh what we expect

1499
00:55:44,880 --> 00:55:46,559
will happen in the future

1500
00:55:46,559 --> 00:55:47,680
and uh

1501
00:55:47,680 --> 00:55:49,119
we use this

1502
00:55:49,119 --> 00:55:51,680
as our uh target for learning the

1503
00:55:51,680 --> 00:55:53,760
estimate so

1504
00:55:53,760 --> 00:55:55,839
we basically have the estimate and the

1505
00:55:55,839 --> 00:55:56,880
estimate

1506
00:55:56,880 --> 00:55:59,599
of the future plus the current value and

1507
00:55:59,599 --> 00:56:01,440
we compare the two and we want the the

1508
00:56:01,440 --> 00:56:04,480
the actual estimates to be close to what

1509
00:56:04,480 --> 00:56:06,319
is actually happening plus the the

1510
00:56:06,319 --> 00:56:09,200
future uh estimate

1511
00:56:09,200 --> 00:56:11,599
and this is this is actually what is

1512
00:56:11,599 --> 00:56:13,280
normally done in reinforcement learning

1513
00:56:13,280 --> 00:56:15,119
when you apply the

1514
00:56:15,119 --> 00:56:17,440
so-called bellman equation in order to

1515
00:56:17,440 --> 00:56:19,119
estimate what's going to happen in the

1516
00:56:19,119 --> 00:56:20,960
future by using uh

1517
00:56:20,960 --> 00:56:23,359
what you actually know so generally like

1518
00:56:23,359 --> 00:56:25,760
the rewards and in our case the

1519
00:56:25,760 --> 00:56:26,640
the

1520
00:56:26,640 --> 00:56:28,720
explicit uh

1521
00:56:28,720 --> 00:56:30,960
free energy value and what you you

1522
00:56:30,960 --> 00:56:34,799
already can estimate for the future

1523
00:56:35,760 --> 00:56:39,760
so in our experiments uh we compare to

1524
00:56:39,760 --> 00:56:43,520
we compare four flavors that

1525
00:56:43,520 --> 00:56:46,400
make for uh reinforcement learning uh

1526
00:56:46,400 --> 00:56:49,680
using likelihood model this is dreamer

1527
00:56:49,680 --> 00:56:52,559
the dreamer baseline so it does a likely

1528
00:56:52,559 --> 00:56:56,400
based uh learn the word model and uh

1529
00:56:56,400 --> 00:56:59,440
it uses rewards for learning action so

1530
00:56:59,440 --> 00:57:01,760
the the river function is uh

1531
00:57:01,760 --> 00:57:03,760
is already given to the agent and then

1532
00:57:03,760 --> 00:57:06,160
we compare with contrasting dreamer it

1533
00:57:06,160 --> 00:57:08,960
is a modification of trimmer using a

1534
00:57:08,960 --> 00:57:10,319
contrastive

1535
00:57:10,319 --> 00:57:11,920
learning for his world model instead of

1536
00:57:11,920 --> 00:57:14,319
reconstructions and then we compare the

1537
00:57:14,319 --> 00:57:17,200
two flavors of active inference uh the

1538
00:57:17,200 --> 00:57:18,960
standard let's say one with the

1539
00:57:18,960 --> 00:57:21,760
likelihood reconstruction model and our

1540
00:57:21,760 --> 00:57:25,040
contrastive formulation

1541
00:57:25,359 --> 00:57:26,400
so we use

1542
00:57:26,400 --> 00:57:28,000
similar architecture and training

1543
00:57:28,000 --> 00:57:30,720
routine for all the the four base lines

1544
00:57:30,720 --> 00:57:32,079
and the

1545
00:57:32,079 --> 00:57:35,119
the training routine can be summarized

1546
00:57:35,119 --> 00:57:37,920
as we see here in pseudocode

1547
00:57:37,920 --> 00:57:41,280
so for a certain uh for a certain amount

1548
00:57:41,280 --> 00:57:43,359
of number of training steps that we fix

1549
00:57:43,359 --> 00:57:46,000
intense we are going to train our world

1550
00:57:46,000 --> 00:57:48,960
model on the previous experience so now

1551
00:57:48,960 --> 00:57:50,799
on a replay buffer

1552
00:57:50,799 --> 00:57:52,799
that basically represents our data sets

1553
00:57:52,799 --> 00:57:55,359
of past experiences

1554
00:57:55,359 --> 00:57:57,280
then we are going to use the trained

1555
00:57:57,280 --> 00:57:59,920
world model to imagine some trajectories

1556
00:57:59,920 --> 00:58:01,359
in the future

1557
00:58:01,359 --> 00:58:03,520
by using

1558
00:58:03,520 --> 00:58:05,200
our action model

1559
00:58:05,200 --> 00:58:07,359
and the replay buffer as well which is

1560
00:58:07,359 --> 00:58:09,520
used because we we need to take this the

1561
00:58:09,520 --> 00:58:11,920
negative samples uh for the contrasting

1562
00:58:11,920 --> 00:58:14,000
free energy functional

1563
00:58:14,000 --> 00:58:16,559
uh and then on the imagine trajectories

1564
00:58:16,559 --> 00:58:18,799
we are gonna train our

1565
00:58:18,799 --> 00:58:22,400
our action model in order to actually

1566
00:58:22,400 --> 00:58:25,280
try to pursue the the preferred outcomes

1567
00:58:25,280 --> 00:58:27,200
uh better

1568
00:58:27,200 --> 00:58:29,119
and then we are going to go back to the

1569
00:58:29,119 --> 00:58:31,520
environment collect a new trajectory uh

1570
00:58:31,520 --> 00:58:34,160
using our word model to infer where the

1571
00:58:34,160 --> 00:58:36,480
with the hidden state of the of the

1572
00:58:36,480 --> 00:58:38,480
environment is at every time step and

1573
00:58:38,480 --> 00:58:40,319
using the action model to select the

1574
00:58:40,319 --> 00:58:42,240
action according to this data that we

1575
00:58:42,240 --> 00:58:43,359
inferred

1576
00:58:43,359 --> 00:58:45,359
and add the

1577
00:58:45,359 --> 00:58:47,760
just collected trajectory to the data

1578
00:58:47,760 --> 00:58:50,319
set and we do this continuously so train

1579
00:58:50,319 --> 00:58:52,960
the world model imagine uh some

1580
00:58:52,960 --> 00:58:54,319
trajectories

1581
00:58:54,319 --> 00:58:56,960
and uh train the action model and again

1582
00:58:56,960 --> 00:58:58,799
keep collecting so that we we

1583
00:58:58,799 --> 00:59:01,119
continuously improve both the data

1584
00:59:01,119 --> 00:59:03,520
collection process because the

1585
00:59:03,520 --> 00:59:05,760
the the word model and the action model

1586
00:59:05,760 --> 00:59:08,480
gets better and also our model indeed so

1587
00:59:08,480 --> 00:59:11,760
that we get closer to the goal

1588
00:59:11,920 --> 00:59:14,799
so one important insight that uh that

1589
00:59:14,799 --> 00:59:17,359
first introduced before that into an

1590
00:59:17,359 --> 00:59:19,280
empirical evaluation of the method is

1591
00:59:19,280 --> 00:59:20,480
the fact that

1592
00:59:20,480 --> 00:59:22,880
using contrastive learning strongly

1593
00:59:22,880 --> 00:59:25,359
reduces the the component requirements

1594
00:59:25,359 --> 00:59:26,720
of the model

1595
00:59:26,720 --> 00:59:28,240
so here i

1596
00:59:28,240 --> 00:59:30,960
i'm comparing the number of

1597
00:59:30,960 --> 00:59:33,440
multiply million multiplier combination

1598
00:59:33,440 --> 00:59:35,040
operation

1599
00:59:35,040 --> 00:59:36,960
for our models and the number of

1600
00:59:36,960 --> 00:59:40,079
parameters that we as we see these are

1601
00:59:40,079 --> 00:59:43,839
much lower when we use a contrastive

1602
00:59:43,839 --> 00:59:46,160
mechanism compared to to using a

1603
00:59:46,160 --> 00:59:48,000
likelihood model

1604
00:59:48,000 --> 00:59:49,040
and

1605
00:59:49,040 --> 00:59:51,359
this is also reflected in terms of

1606
00:59:51,359 --> 00:59:54,799
workload time so our model is is quite

1607
00:59:54,799 --> 00:59:57,760
faster compared to dreamer

1608
00:59:57,760 --> 00:59:59,839
that

1609
00:59:59,839 --> 01:00:02,559
trains the the likelihood based uh model

1610
01:00:02,559 --> 01:00:04,160
for the world that

1611
01:00:04,160 --> 01:00:06,880
uses uh just three words for learning

1612
01:00:06,880 --> 01:00:08,240
action and is

1613
01:00:08,240 --> 01:00:10,400
much much faster than the likelihood the

1614
01:00:10,400 --> 01:00:11,839
active inference model because the

1615
01:00:11,839 --> 01:00:14,160
likelihood active influence model other

1616
01:00:14,160 --> 01:00:15,200
than

1617
01:00:15,200 --> 01:00:17,359
having to to do the reconstruction

1618
01:00:17,359 --> 01:00:19,280
during the world model training also as

1619
01:00:19,280 --> 01:00:20,400
to imagine

1620
01:00:20,400 --> 01:00:22,000
uh the

1621
01:00:22,000 --> 01:00:23,920
the high dimensional outcomes in the

1622
01:00:23,920 --> 01:00:26,559
future so in that case you have even

1623
01:00:26,559 --> 01:00:28,079
more computation because for every

1624
01:00:28,079 --> 01:00:30,160
imagine trajectory you have to imagine

1625
01:00:30,160 --> 01:00:33,040
all the possible images in our context

1626
01:00:33,040 --> 01:00:34,000
that you are

1627
01:00:34,000 --> 01:00:35,599
you

1628
01:00:35,599 --> 01:00:37,680
you will get pursuing a certain a

1629
01:00:37,680 --> 01:00:39,200
certain policy

1630
01:00:39,200 --> 01:00:42,160
so it's our model is quite faster than

1631
01:00:42,160 --> 01:00:43,920
that

1632
01:00:43,920 --> 01:00:46,960
so the first arcs that i will discuss is

1633
01:00:46,960 --> 01:00:50,880
the a simple mini grid task so the agent

1634
01:00:50,880 --> 01:00:53,520
represents the red arrow who will

1635
01:00:53,520 --> 01:00:56,240
navigate a black read in order to reach

1636
01:00:56,240 --> 01:00:57,040
a

1637
01:00:57,040 --> 01:00:59,440
green square that is placed in one of

1638
01:00:59,440 --> 01:01:01,200
the corner of the grids

1639
01:01:01,200 --> 01:01:01,920
so

1640
01:01:01,920 --> 01:01:04,079
the environment is partially observed

1641
01:01:04,079 --> 01:01:06,720
because the agent doesn't know

1642
01:01:06,720 --> 01:01:08,799
what's in every pixel of the creed so in

1643
01:01:08,799 --> 01:01:11,520
order to find the goal first i should

1644
01:01:11,520 --> 01:01:13,839
you should explore the old grid and and

1645
01:01:13,839 --> 01:01:16,799
find the the green square or at least

1646
01:01:16,799 --> 01:01:19,280
be in a position that allows him to

1647
01:01:19,280 --> 01:01:20,319
to see

1648
01:01:20,319 --> 01:01:22,640
the green square in front of him

1649
01:01:22,640 --> 01:01:23,359
so

1650
01:01:23,359 --> 01:01:25,680
for the for the reward model of course

1651
01:01:25,680 --> 01:01:27,119
we have uh

1652
01:01:27,119 --> 01:01:29,359
we have the highest reward and the in

1653
01:01:29,359 --> 01:01:31,359
correspondence of the of the goal state

1654
01:01:31,359 --> 01:01:33,280
so when the when the agent is actually

1655
01:01:33,280 --> 01:01:34,160
on the

1656
01:01:34,160 --> 01:01:36,720
on the goal square it could receive a

1657
01:01:36,720 --> 01:01:38,480
reward of plus one

1658
01:01:38,480 --> 01:01:41,040
and this is a sparse reward task so for

1659
01:01:41,040 --> 01:01:43,839
all the other states the agent will just

1660
01:01:43,839 --> 01:01:45,920
receive zero rewards

1661
01:01:45,920 --> 01:01:48,480
so it will be just encouraged to to

1662
01:01:48,480 --> 01:01:50,480
reach the goal

1663
01:01:50,480 --> 01:01:53,200
well for active inference method uh the

1664
01:01:53,200 --> 01:01:54,799
way that i chose to define the preferred

1665
01:01:54,799 --> 01:01:57,280
outcome is to have an image of the agent

1666
01:01:57,280 --> 01:02:00,240
that is that sees himself on the goal so

1667
01:02:00,240 --> 01:02:02,160
basically the agent sees himself on the

1668
01:02:02,160 --> 01:02:04,480
goal and says this is the position that

1669
01:02:04,480 --> 01:02:07,039
they want to reach in the world

1670
01:02:07,039 --> 01:02:08,480
and

1671
01:02:08,480 --> 01:02:10,880
let's see what happens from a from a

1672
01:02:10,880 --> 01:02:12,160
qualitative

1673
01:02:12,160 --> 01:02:14,240
level so as i said before

1674
01:02:14,240 --> 01:02:17,200
the rewards for for this task it's just

1675
01:02:17,200 --> 01:02:20,880
a plus one in the right uh

1676
01:02:20,880 --> 01:02:23,359
in the right square in the goal square

1677
01:02:23,359 --> 01:02:25,520
what happens for the the active

1678
01:02:25,520 --> 01:02:27,440
inference model so what will the the

1679
01:02:27,440 --> 01:02:31,359
active inference uh model uh provides uh

1680
01:02:31,359 --> 01:02:33,760
as a volume of a certain states of the

1681
01:02:33,760 --> 01:02:35,839
agents in order to pursue the preferred

1682
01:02:35,839 --> 01:02:37,119
outcome

1683
01:02:37,119 --> 01:02:39,280
so we see that the likelihood active

1684
01:02:39,280 --> 01:02:41,440
inference when

1685
01:02:41,440 --> 01:02:42,240
uh

1686
01:02:42,240 --> 01:02:44,480
that is imagining the outcome and

1687
01:02:44,480 --> 01:02:47,359
comparing it to the preferred images is

1688
01:02:47,359 --> 01:02:49,280
actually giving a very high value for

1689
01:02:49,280 --> 01:02:50,960
the for the right

1690
01:02:50,960 --> 01:02:53,839
square so this

1691
01:02:53,839 --> 01:02:54,799
you know

1692
01:02:54,799 --> 01:02:56,319
in a scale from zero one we can say

1693
01:02:56,319 --> 01:02:58,559
that's that's a one oh sorry

1694
01:02:58,559 --> 01:03:01,039
we can say that's a one but other than

1695
01:03:01,039 --> 01:03:02,400
that the

1696
01:03:02,400 --> 01:03:04,480
the function it is providing is a bit

1697
01:03:04,480 --> 01:03:07,280
confusing because it is giving some

1698
01:03:07,280 --> 01:03:10,240
higher rewards in the centers uh

1699
01:03:10,240 --> 01:03:12,960
compared to the let's say the

1700
01:03:12,960 --> 01:03:14,079
uh

1701
01:03:14,079 --> 01:03:15,599
the

1702
01:03:15,599 --> 01:03:18,400
the last uh row and column that are the

1703
01:03:18,400 --> 01:03:21,359
one that at the least to the final goal

1704
01:03:21,359 --> 01:03:22,319
uh

1705
01:03:22,319 --> 01:03:25,039
the the the other corner are not even

1706
01:03:25,039 --> 01:03:28,000
close to the the gold one so he is just

1707
01:03:28,000 --> 01:03:30,559
uh he's just providing a perfect match

1708
01:03:30,559 --> 01:03:31,680
and we have no

1709
01:03:31,680 --> 01:03:33,520
no control over what the distance of the

1710
01:03:33,520 --> 01:03:35,839
goal is because for the perfect match

1711
01:03:35,839 --> 01:03:37,280
the goal that's

1712
01:03:37,280 --> 01:03:39,359
that is indeed the the correct value

1713
01:03:39,359 --> 01:03:41,119
that it is providing but other than that

1714
01:03:41,119 --> 01:03:41,839
we

1715
01:03:41,839 --> 01:03:44,480
it's difficult to understand what the

1716
01:03:44,480 --> 01:03:46,160
what the the likelihood of the influence

1717
01:03:46,160 --> 01:03:48,000
model is providing with the contrastive

1718
01:03:48,000 --> 01:03:49,440
active inference

1719
01:03:49,440 --> 01:03:52,160
we see that there is a different pattern

1720
01:03:52,160 --> 01:03:54,480
so the agent is providing

1721
01:03:54,480 --> 01:03:57,760
a very low volume for the center so it's

1722
01:03:57,760 --> 01:03:59,599
understanding that the center

1723
01:03:59,599 --> 01:04:02,799
is of course not what it wants to see

1724
01:04:02,799 --> 01:04:05,280
but then it's providing i values to all

1725
01:04:05,280 --> 01:04:06,559
the corners

1726
01:04:06,559 --> 01:04:08,720
and in particular the highest values

1727
01:04:08,720 --> 01:04:10,799
provided to the to the right corner so

1728
01:04:10,799 --> 01:04:12,480
the one with the goal because it is of

1729
01:04:12,480 --> 01:04:14,400
course the more the one that corresponds

1730
01:04:14,400 --> 01:04:16,400
the most with uh

1731
01:04:16,400 --> 01:04:18,480
we want what we want to achieve but then

1732
01:04:18,480 --> 01:04:20,720
all the other corners also have

1733
01:04:20,720 --> 01:04:23,760
a very high value and uh

1734
01:04:23,760 --> 01:04:25,119
the fact is that

1735
01:04:25,119 --> 01:04:27,680
from i i would say that the contrastive

1736
01:04:27,680 --> 01:04:29,440
active inference is is verbally

1737
01:04:29,440 --> 01:04:30,480
capturing

1738
01:04:30,480 --> 01:04:31,440
uh

1739
01:04:31,440 --> 01:04:32,319
more

1740
01:04:32,319 --> 01:04:34,160
i would say semantic information about

1741
01:04:34,160 --> 01:04:36,000
the environment so

1742
01:04:36,000 --> 01:04:38,480
in order to distinguish a corner

1743
01:04:38,480 --> 01:04:40,480
uh from from a center of tile is

1744
01:04:40,480 --> 01:04:43,119
actually a modeling the fact that there

1745
01:04:43,119 --> 01:04:45,760
is a corner in a certain state of the

1746
01:04:45,760 --> 01:04:46,960
environment

1747
01:04:46,960 --> 01:04:48,880
and uh when it when it looks at the

1748
01:04:48,880 --> 01:04:50,720
preferred outcome

1749
01:04:50,720 --> 01:04:52,880
image it actually says first of all this

1750
01:04:52,880 --> 01:04:54,880
is a corner and that's the way it

1751
01:04:54,880 --> 01:04:56,480
distinguishes and then there is the

1752
01:04:56,480 --> 01:04:58,400
green uh

1753
01:04:58,400 --> 01:05:01,280
the green tile in the in this in where

1754
01:05:01,280 --> 01:05:03,520
the where the agent is

1755
01:05:03,520 --> 01:05:05,599
so

1756
01:05:05,599 --> 01:05:07,760
from from a value perspective we can say

1757
01:05:07,760 --> 01:05:09,039
that

1758
01:05:09,039 --> 01:05:12,400
a corner is closer in semantics

1759
01:05:12,400 --> 01:05:15,119
uh respect to to a central tile to our

1760
01:05:15,119 --> 01:05:17,520
goal and then of course when you also

1761
01:05:17,520 --> 01:05:19,520
have the the green tile which represents

1762
01:05:19,520 --> 01:05:22,000
the goal then you are the closest

1763
01:05:22,000 --> 01:05:26,079
so this is of course a bit risky because

1764
01:05:26,079 --> 01:05:28,160
it can also lead to to sub-optimal

1765
01:05:28,160 --> 01:05:31,039
behavior in some cases but with with

1766
01:05:31,039 --> 01:05:33,119
good expression of the environment

1767
01:05:33,119 --> 01:05:35,440
it will uh for sure

1768
01:05:35,440 --> 01:05:37,280
lead to the optimal behavior because

1769
01:05:37,280 --> 01:05:40,000
still the the maximum value is still uh

1770
01:05:40,000 --> 01:05:41,760
provided correctly so it's still the

1771
01:05:41,760 --> 01:05:43,359
value for the right corner but if you

1772
01:05:43,359 --> 01:05:45,119
didn't see the other corner the agent

1773
01:05:45,119 --> 01:05:46,960
will will just go to another corner and

1774
01:05:46,960 --> 01:05:49,440
say okay this looks similar to the goal

1775
01:05:49,440 --> 01:05:51,920
so i'm trying to do something similar to

1776
01:05:51,920 --> 01:05:54,400
to what i i would like to do i if i

1777
01:05:54,400 --> 01:05:57,039
didn't see anything else disclosure this

1778
01:05:57,039 --> 01:05:58,319
is my

1779
01:05:58,319 --> 01:05:59,760
the best i can do

1780
01:05:59,760 --> 01:06:00,799
so this

1781
01:06:00,799 --> 01:06:02,559
these are lights how exploration is

1782
01:06:02,559 --> 01:06:04,400
important in order to

1783
01:06:04,400 --> 01:06:06,240
to achieve uh

1784
01:06:06,240 --> 01:06:08,240
preferred outcomes and i think that's

1785
01:06:08,240 --> 01:06:09,920
that also applies

1786
01:06:09,920 --> 01:06:12,079
to likelihood active influence as well

1787
01:06:12,079 --> 01:06:13,119
because in

1788
01:06:13,119 --> 01:06:14,640
if you didn't see the goal you just have

1789
01:06:14,640 --> 01:06:15,680
some

1790
01:06:15,680 --> 01:06:17,119
some noise

1791
01:06:17,119 --> 01:06:19,359
some noisy signal in the center so you

1792
01:06:19,359 --> 01:06:21,520
wouldn't be able to reach the goal as

1793
01:06:21,520 --> 01:06:23,680
well

1794
01:06:23,680 --> 01:06:24,640
and then

1795
01:06:24,640 --> 01:06:27,119
here we quantify the performance we see

1796
01:06:27,119 --> 01:06:29,039
that with the with the likelihood active

1797
01:06:29,039 --> 01:06:30,319
inference

1798
01:06:30,319 --> 01:06:33,599
uh the agent struggles to to reach the

1799
01:06:33,599 --> 01:06:35,200
goal uh

1800
01:06:35,200 --> 01:06:38,559
consistently while our our methods

1801
01:06:38,559 --> 01:06:40,559
uh leads to consistent performance that

1802
01:06:40,559 --> 01:06:42,000
are in line

1803
01:06:42,000 --> 01:06:44,160
with the reward based baselines of

1804
01:06:44,160 --> 01:06:45,760
course the reward base

1805
01:06:45,760 --> 01:06:48,880
baseline have an advantage because

1806
01:06:48,880 --> 01:06:50,559
during training they always have a

1807
01:06:50,559 --> 01:06:52,480
filtered objective so even if their

1808
01:06:52,480 --> 01:06:54,160
model is not correct they always have

1809
01:06:54,160 --> 01:06:56,240
this three-word function filtered

1810
01:06:56,240 --> 01:06:58,400
function that tells them yes this this

1811
01:06:58,400 --> 01:07:00,799
is where you need to go well our model

1812
01:07:00,799 --> 01:07:03,039
uh can take a little bit more time in

1813
01:07:03,039 --> 01:07:05,440
order to first have a good model and

1814
01:07:05,440 --> 01:07:08,240
then being able to match but uh

1815
01:07:08,240 --> 01:07:10,319
with the contrastive mechanism this

1816
01:07:10,319 --> 01:07:12,240
process is actually happens

1817
01:07:12,240 --> 01:07:14,559
uh fast and uh leads to consistent

1818
01:07:14,559 --> 01:07:16,480
performance where we with likely the

1819
01:07:16,480 --> 01:07:18,720
active inference we see that uh

1820
01:07:18,720 --> 01:07:21,039
it it will probably takes more time to

1821
01:07:21,039 --> 01:07:23,119
converge or

1822
01:07:23,119 --> 01:07:26,640
it just leads to to suboptimal behavior

1823
01:07:26,640 --> 01:07:28,960
so it's just inconsistent according to

1824
01:07:28,960 --> 01:07:30,559
our evaluation

1825
01:07:30,559 --> 01:07:32,720
and yeah these are two

1826
01:07:32,720 --> 01:07:34,000
different

1827
01:07:34,000 --> 01:07:36,000
grid environments but this one is

1828
01:07:36,000 --> 01:07:37,839
smaller one is bigger but yeah the

1829
01:07:37,839 --> 01:07:41,039
results are very similar in terms of

1830
01:07:41,039 --> 01:07:43,599
performance obtained

1831
01:07:43,599 --> 01:07:46,160
then the other task that we discuss is a

1832
01:07:46,160 --> 01:07:47,839
continuous control

1833
01:07:47,839 --> 01:07:49,839
task with uh

1834
01:07:49,839 --> 01:07:51,440
with a 2d

1835
01:07:51,440 --> 01:07:54,720
planar environment when we're a robotic

1836
01:07:54,720 --> 01:07:57,599
arm through the penetrate uh sphere gold

1837
01:07:57,599 --> 01:07:59,599
so the the red sphere

1838
01:07:59,599 --> 01:08:01,359
and

1839
01:08:01,359 --> 01:08:04,000
this sphere is bigger in the

1840
01:08:04,000 --> 01:08:05,359
the so-called the richer easy

1841
01:08:05,359 --> 01:08:07,599
environment which is the one for which

1842
01:08:07,599 --> 01:08:09,680
we see the preferred outcome on the left

1843
01:08:09,680 --> 01:08:11,440
and it is smaller for the for the

1844
01:08:11,440 --> 01:08:13,599
so-called richer art environment that is

1845
01:08:13,599 --> 01:08:15,839
the one that we we see in the on the

1846
01:08:15,839 --> 01:08:19,439
right so for a reward based

1847
01:08:19,439 --> 01:08:20,479
agent

1848
01:08:20,479 --> 01:08:22,000
we have

1849
01:08:22,000 --> 01:08:25,759
the reward function that provides

1850
01:08:25,759 --> 01:08:28,080
when the agent penetrates the

1851
01:08:28,080 --> 01:08:30,238
the sphere fully a reverse of one

1852
01:08:30,238 --> 01:08:32,158
otherwise when it's

1853
01:08:32,158 --> 01:08:35,120
uh off penetrating or just partially

1854
01:08:35,120 --> 01:08:37,040
penetrating the sphere it provides a

1855
01:08:37,040 --> 01:08:38,719
dense reward that

1856
01:08:38,719 --> 01:08:40,319
that tells you yeah you're getting

1857
01:08:40,319 --> 01:08:42,158
closer to the goal so

1858
01:08:42,158 --> 01:08:43,679
in this case the reward function is

1859
01:08:43,679 --> 01:08:45,040
actually helping

1860
01:08:45,040 --> 01:08:46,719
the agent a bit more because it is

1861
01:08:46,719 --> 01:08:48,158
telling him that he

1862
01:08:48,158 --> 01:08:49,520
is getting closer to the goal and he

1863
01:08:49,520 --> 01:08:51,759
should just try

1864
01:08:51,759 --> 01:08:54,000
in the neighbor area

1865
01:08:54,000 --> 01:08:56,479
while for active inference we we just

1866
01:08:56,479 --> 01:08:59,359
provide the the preferred

1867
01:08:59,359 --> 01:09:02,399
stating environment which is uh

1868
01:09:02,399 --> 01:09:04,238
the agent penetrating the goal sphere

1869
01:09:04,238 --> 01:09:05,040
and

1870
01:09:05,040 --> 01:09:08,560
let's see let's see what happens so

1871
01:09:08,560 --> 01:09:11,359
again we have a similar pattern

1872
01:09:11,359 --> 01:09:12,960
uh actually

1873
01:09:12,960 --> 01:09:14,880
yeah similar but different from the

1874
01:09:14,880 --> 01:09:18,000
previous one so in this case where the

1875
01:09:18,000 --> 01:09:19,839
the mean square there are

1876
01:09:19,839 --> 01:09:22,080
distance from the goal is actually more

1877
01:09:22,080 --> 01:09:24,399
confusing as we we've seen in previous

1878
01:09:24,399 --> 01:09:25,520
example

1879
01:09:25,520 --> 01:09:27,198
so the the likelihood the active

1880
01:09:27,198 --> 01:09:29,839
inference agent totally fails to to

1881
01:09:29,839 --> 01:09:32,399
reach the goal because it's probably all

1882
01:09:32,399 --> 01:09:33,920
the all the states look alike in the

1883
01:09:33,920 --> 01:09:35,439
environment because the background stays

1884
01:09:35,439 --> 01:09:38,080
the same so the background is not moving

1885
01:09:38,080 --> 01:09:39,679
as it was happening for instance for the

1886
01:09:39,679 --> 01:09:41,279
mini grid environment

1887
01:09:41,279 --> 01:09:43,359
uh the goal is always in the same

1888
01:09:43,359 --> 01:09:45,679
position so the difference between two

1889
01:09:45,679 --> 01:09:48,719
images is just provide given by the

1890
01:09:48,719 --> 01:09:51,198
the few yellow pixel that moves around

1891
01:09:51,198 --> 01:09:53,040
and if the model is not imagined

1892
01:09:53,040 --> 01:09:55,760
perfectly where this pixel goes it's

1893
01:09:55,760 --> 01:09:58,560
very difficult that it will provide some

1894
01:09:58,560 --> 01:10:01,280
some informative objective for the stars

1895
01:10:01,280 --> 01:10:02,400
instead

1896
01:10:02,400 --> 01:10:04,480
our contrastive active inference agent

1897
01:10:04,480 --> 01:10:07,679
is able to provide an informative goal

1898
01:10:07,679 --> 01:10:09,199
and

1899
01:10:09,199 --> 01:10:10,880
apparently the fact that he's providing

1900
01:10:10,880 --> 01:10:13,440
some semantic information about the task

1901
01:10:13,440 --> 01:10:15,120
is actually helping it to converge even

1902
01:10:15,120 --> 01:10:16,560
faster than the

1903
01:10:16,560 --> 01:10:18,480
then the reward based uh

1904
01:10:18,480 --> 01:10:21,280
a baseline because the reward based uh

1905
01:10:21,280 --> 01:10:23,760
agents uh have access to rewards just

1906
01:10:23,760 --> 01:10:25,760
when they are close to the to the goal

1907
01:10:25,760 --> 01:10:27,199
where the contractive active inference

1908
01:10:27,199 --> 01:10:29,280
provider reward function everywhere in

1909
01:10:29,280 --> 01:10:30,400
the environment

1910
01:10:30,400 --> 01:10:32,719
so when the when we see that the arm is

1911
01:10:32,719 --> 01:10:33,840
very far

1912
01:10:33,840 --> 01:10:36,320
we have the the mutual information term

1913
01:10:36,320 --> 01:10:37,679
that should basically take over and

1914
01:10:37,679 --> 01:10:40,159
tells you yeah you don't

1915
01:10:40,159 --> 01:10:42,320
want to stay there go elsewhere

1916
01:10:42,320 --> 01:10:44,719
and until we we eventually

1917
01:10:44,719 --> 01:10:46,800
find the the goal sphere and we converge

1918
01:10:46,800 --> 01:10:49,920
to the correct behavior so the the agent

1919
01:10:49,920 --> 01:10:51,840
is actually converging a bit faster than

1920
01:10:51,840 --> 01:10:53,840
the other baselines and then yeah the

1921
01:10:53,840 --> 01:10:55,920
the contrastive dreamer baseline is

1922
01:10:55,920 --> 01:10:57,920
converging a bit faster than dreamer one

1923
01:10:57,920 --> 01:10:59,920
because its model is

1924
01:10:59,920 --> 01:11:03,920
faster to learn because it's contrastive

1925
01:11:04,239 --> 01:11:06,560
so this is what actually happens these

1926
01:11:06,560 --> 01:11:09,199
are a gif on the right at some point

1927
01:11:09,199 --> 01:11:11,520
they show difficult reset so basically

1928
01:11:11,520 --> 01:11:14,400
we just see here that the task is uh

1929
01:11:14,400 --> 01:11:17,920
is correctly executed so that the agent

1930
01:11:17,920 --> 01:11:21,280
is uh is able to match the

1931
01:11:21,280 --> 01:11:24,000
the correct behavior so yeah it is

1932
01:11:24,000 --> 01:11:26,400
taking a bit longer than expected but

1933
01:11:26,400 --> 01:11:28,080
yeah you can see that

1934
01:11:28,080 --> 01:11:30,400
for instance in the in the art task the

1935
01:11:30,400 --> 01:11:32,560
agent oscillates around the current

1936
01:11:32,560 --> 01:11:35,280
behavior but it keeps saying okay here

1937
01:11:35,280 --> 01:11:36,719
we see it

1938
01:11:36,719 --> 01:11:38,880
so basically the the in the environment

1939
01:11:38,880 --> 01:11:42,480
is oscillating in a position that is uh

1940
01:11:42,480 --> 01:11:44,239
very close to the goal so it tries to

1941
01:11:44,239 --> 01:11:47,040
stay as much as possible to that uh that

1942
01:11:47,040 --> 01:11:50,080
point and uh not uh

1943
01:11:50,080 --> 01:11:51,280
not be

1944
01:11:51,280 --> 01:11:52,239
driven

1945
01:11:52,239 --> 01:11:55,280
far from the goal by the inertia of the

1946
01:11:55,280 --> 01:11:57,920
of the of the arm

1947
01:11:57,920 --> 01:12:00,640
then we we analyze qualitatively what's

1948
01:12:00,640 --> 01:12:02,560
what's happening in terms of uh the

1949
01:12:02,560 --> 01:12:05,120
value this provides the agent so what's

1950
01:12:05,120 --> 01:12:07,360
what is the the objective that is given

1951
01:12:07,360 --> 01:12:09,280
to the to the agent in order to learn

1952
01:12:09,280 --> 01:12:10,320
here

1953
01:12:10,320 --> 01:12:11,280
and

1954
01:12:11,280 --> 01:12:12,400
as

1955
01:12:12,400 --> 01:12:17,120
as i try to explain the reward is

1956
01:12:17,920 --> 01:12:20,320
is somewhere in the middle between 0 and

1957
01:12:20,320 --> 01:12:21,360
1

1958
01:12:21,360 --> 01:12:23,199
when the agent is partially penetrating

1959
01:12:23,199 --> 01:12:25,840
the goal and is totally one

1960
01:12:25,840 --> 01:12:27,440
when the agent is fully penetrating the

1961
01:12:27,440 --> 01:12:31,280
goal in all the other situations is zero

1962
01:12:31,280 --> 01:12:33,440
for the active inference likelihood base

1963
01:12:33,440 --> 01:12:36,239
model we see that the signal is very

1964
01:12:36,239 --> 01:12:37,280
close

1965
01:12:37,280 --> 01:12:38,880
for all

1966
01:12:38,880 --> 01:12:40,000
the

1967
01:12:40,000 --> 01:12:41,040
states

1968
01:12:41,040 --> 01:12:43,360
so the agent basically

1969
01:12:43,360 --> 01:12:44,880
thinks that there is

1970
01:12:44,880 --> 01:12:47,199
very little difference between

1971
01:12:47,199 --> 01:12:49,120
being very close to goal

1972
01:12:49,120 --> 01:12:51,920
and being actually very far off from the

1973
01:12:51,920 --> 01:12:53,679
goal and that's

1974
01:12:53,679 --> 01:12:54,560
uh

1975
01:12:54,560 --> 01:12:56,159
likely the reason why it's not

1976
01:12:56,159 --> 01:12:57,760
converging to the

1977
01:12:57,760 --> 01:13:00,080
to the optimal behavior for contrastive

1978
01:13:00,080 --> 01:13:02,480
active inference instead we see that the

1979
01:13:02,480 --> 01:13:05,120
agent is provided a

1980
01:13:05,120 --> 01:13:07,040
an objective value is

1981
01:13:07,040 --> 01:13:07,920
some

1982
01:13:07,920 --> 01:13:10,480
somewhat in between zero and one when

1983
01:13:10,480 --> 01:13:11,679
he's a

1984
01:13:11,679 --> 01:13:13,440
when he's

1985
01:13:13,440 --> 01:13:15,840
not close to the goal and something that

1986
01:13:15,840 --> 01:13:17,679
is very close to one when it's in the

1987
01:13:17,679 --> 01:13:19,520
goal and in particular when it when it's

1988
01:13:19,520 --> 01:13:22,159
closer to the goal the the value is

1989
01:13:22,159 --> 01:13:24,480
actually a bit higher than when it

1990
01:13:24,480 --> 01:13:26,239
when it's far off

1991
01:13:26,239 --> 01:13:28,080
so we see that there is some

1992
01:13:28,080 --> 01:13:30,000
again something semantic information

1993
01:13:30,000 --> 01:13:31,840
provided which is the the actual

1994
01:13:31,840 --> 01:13:34,000
distance of the arm

1995
01:13:34,000 --> 01:13:35,760
from the from the right

1996
01:13:35,760 --> 01:13:39,280
goal or we can just see it as a

1997
01:13:39,280 --> 01:13:41,520
okay the contrastive learning mechanism

1998
01:13:41,520 --> 01:13:44,480
saying okay this this pose of the arm is

1999
01:13:44,480 --> 01:13:46,080
actually very different from the one

2000
01:13:46,080 --> 01:13:48,239
that i that they opt to obtain so let's

2001
01:13:48,239 --> 01:13:50,640
try to move to a pose that is actually

2002
01:13:50,640 --> 01:13:52,480
closer

2003
01:13:52,480 --> 01:13:54,159
and uh

2004
01:13:54,159 --> 01:13:56,239
we indeed obtain higher values when the

2005
01:13:56,239 --> 01:13:57,920
when the pose is

2006
01:13:57,920 --> 01:14:00,239
similar to the to the one that we we

2007
01:14:00,239 --> 01:14:02,239
want to achieve

2008
01:14:02,239 --> 01:14:05,120
so we exploit the fact that uh some

2009
01:14:05,120 --> 01:14:07,440
semantic information is provided to the

2010
01:14:07,440 --> 01:14:09,760
agent by using contrastive

2011
01:14:09,760 --> 01:14:11,040
learning to

2012
01:14:11,040 --> 01:14:14,400
to work on a more difficult setup is the

2013
01:14:14,400 --> 01:14:16,719
richer distracting environment

2014
01:14:16,719 --> 01:14:17,679
so

2015
01:14:17,679 --> 01:14:20,080
in the research distracting task

2016
01:14:20,080 --> 01:14:21,679
we have the same

2017
01:14:21,679 --> 01:14:24,239
objective as before so we want the agent

2018
01:14:24,239 --> 01:14:24,960
to

2019
01:14:24,960 --> 01:14:26,480
to reach the goal

2020
01:14:26,480 --> 01:14:28,800
by penetrating the red sphere but now we

2021
01:14:28,800 --> 01:14:30,400
have varying backgrounds and we have

2022
01:14:30,400 --> 01:14:32,080
this structure in the environment which

2023
01:14:32,080 --> 01:14:34,400
could be just altered colors on the

2024
01:14:34,400 --> 01:14:36,239
tilted camera

2025
01:14:36,239 --> 01:14:38,880
and uh we still want to to achieve the

2026
01:14:38,880 --> 01:14:40,719
agent tool to penetrate the sphere

2027
01:14:40,719 --> 01:14:43,360
despite that so for the for the reward

2028
01:14:43,360 --> 01:14:45,120
based agents

2029
01:14:45,120 --> 01:14:48,400
the reward is same as before so

2030
01:14:48,400 --> 01:14:50,320
being provided for the agent penetrating

2031
01:14:50,320 --> 01:14:52,000
the goal sphere while for active

2032
01:14:52,000 --> 01:14:53,920
inference the goal here is

2033
01:14:53,920 --> 01:14:56,800
is actually a bit troublesome to define

2034
01:14:56,800 --> 01:14:58,719
because given the fact that the the

2035
01:14:58,719 --> 01:15:01,120
background is constantly boring across

2036
01:15:01,120 --> 01:15:02,640
different episodes

2037
01:15:02,640 --> 01:15:05,120
we cannot a priori

2038
01:15:05,120 --> 01:15:06,320
define

2039
01:15:06,320 --> 01:15:08,080
what's the

2040
01:15:08,080 --> 01:15:10,000
what the the preferred outcome looks

2041
01:15:10,000 --> 01:15:12,719
like so instead of doing that we

2042
01:15:12,719 --> 01:15:15,920
attempted providing a more natural uh

2043
01:15:15,920 --> 01:15:18,239
preferred outcome with the agencying

2044
01:15:18,239 --> 01:15:20,719
itself achieving the goal but with the

2045
01:15:20,719 --> 01:15:21,920
standard

2046
01:15:21,920 --> 01:15:22,880
task

2047
01:15:22,880 --> 01:15:25,280
background so we have this uh

2048
01:15:25,280 --> 01:15:27,199
the blue uh

2049
01:15:27,199 --> 01:15:29,199
just like uh

2050
01:15:29,199 --> 01:15:31,360
background uh with the with the arm

2051
01:15:31,360 --> 01:15:33,920
penetrating the goal and we we aim for

2052
01:15:33,920 --> 01:15:34,960
this

2053
01:15:34,960 --> 01:15:37,440
preferred outcome to transfer

2054
01:15:37,440 --> 01:15:38,800
to the

2055
01:15:38,800 --> 01:15:40,880
to the distracting setup this is of

2056
01:15:40,880 --> 01:15:42,719
course

2057
01:15:42,719 --> 01:15:44,960
pretty much impossible for

2058
01:15:44,960 --> 01:15:46,719
for the likelihood the active inference

2059
01:15:46,719 --> 01:15:49,120
model because of course he's trying to

2060
01:15:49,120 --> 01:15:50,640
match this in a

2061
01:15:50,640 --> 01:15:52,800
with a mean square there were like uh

2062
01:15:52,800 --> 01:15:55,920
function so of course the the the signal

2063
01:15:55,920 --> 01:15:58,400
provided will be very confusing

2064
01:15:58,400 --> 01:16:00,480
uh very interestingly we see heels that

2065
01:16:00,480 --> 01:16:02,480
also the dreamer method fails because

2066
01:16:02,480 --> 01:16:04,880
it's based on uh on a likelihood based

2067
01:16:04,880 --> 01:16:06,480
models and

2068
01:16:06,480 --> 01:16:09,600
as we'll see uh reconstructing all the

2069
01:16:09,600 --> 01:16:12,000
the variations in the environment it's

2070
01:16:12,000 --> 01:16:13,360
very difficult

2071
01:16:13,360 --> 01:16:16,320
so the the word the reconstruction based

2072
01:16:16,320 --> 01:16:18,239
word model struggles

2073
01:16:18,239 --> 01:16:20,480
uh to provide informative states of the

2074
01:16:20,480 --> 01:16:22,719
environment while uh the contrastive

2075
01:16:22,719 --> 01:16:24,880
learning based models succeed and in

2076
01:16:24,880 --> 01:16:26,560
particular it's it's very interesting

2077
01:16:26,560 --> 01:16:28,640
that our mother was able to

2078
01:16:28,640 --> 01:16:30,880
to actually achieves the goal here we

2079
01:16:30,880 --> 01:16:33,120
see less consistently than before so the

2080
01:16:33,120 --> 01:16:35,040
there is an iron variance but still the

2081
01:16:35,040 --> 01:16:36,000
agent

2082
01:16:36,000 --> 01:16:38,880
is often able to reach the correct

2083
01:16:38,880 --> 01:16:40,800
position despite all the difference in

2084
01:16:40,800 --> 01:16:42,560
the background and all the structure

2085
01:16:42,560 --> 01:16:44,719
present in the environment so we see

2086
01:16:44,719 --> 01:16:47,040
that this actually

2087
01:16:47,040 --> 01:16:48,800
the representation

2088
01:16:48,800 --> 01:16:50,560
uh is actually

2089
01:16:50,560 --> 01:16:52,239
learning what the

2090
01:16:52,239 --> 01:16:53,360
the pose

2091
01:16:53,360 --> 01:16:54,800
of the robot

2092
01:16:54,800 --> 01:16:57,199
should be and trying to match it

2093
01:16:57,199 --> 01:16:59,280
in the future

2094
01:16:59,280 --> 01:17:00,239
and then

2095
01:17:00,239 --> 01:17:02,480
here we see some some videos what's

2096
01:17:02,480 --> 01:17:05,280
happening so we see here indeed the day

2097
01:17:05,280 --> 01:17:07,840
the arm is oscillating a bit more so

2098
01:17:07,840 --> 01:17:09,440
it's actually a bit more difficult for

2099
01:17:09,440 --> 01:17:11,600
him to assess that he's doing

2100
01:17:11,600 --> 01:17:14,159
the right thing but still the

2101
01:17:14,159 --> 01:17:17,440
the behavior obtained it's still

2102
01:17:17,440 --> 01:17:19,199
quite good i will say so it's pretty

2103
01:17:19,199 --> 01:17:22,400
much achieving the goal

2104
01:17:22,880 --> 01:17:23,760
and

2105
01:17:23,760 --> 01:17:26,159
this shows why

2106
01:17:26,159 --> 01:17:28,320
a likely based model will fail in this

2107
01:17:28,320 --> 01:17:30,080
environment so here we compare the

2108
01:17:30,080 --> 01:17:31,280
ground roof

2109
01:17:31,280 --> 01:17:33,199
in the different uh

2110
01:17:33,199 --> 01:17:35,520
varying backgrounds and

2111
01:17:35,520 --> 01:17:37,520
what the dreamers

2112
01:17:37,520 --> 01:17:38,960
or the

2113
01:17:38,960 --> 01:17:41,280
the likelihood active inference model

2114
01:17:41,280 --> 01:17:43,760
stays through the reconstruction so we

2115
01:17:43,760 --> 01:17:44,640
see that

2116
01:17:44,640 --> 01:17:46,719
either reconstructing from the from the

2117
01:17:46,719 --> 01:17:49,520
presidio state or from the prior state

2118
01:17:49,520 --> 01:17:53,199
the agent cannot perfectly model uh

2119
01:17:53,199 --> 01:17:55,360
important information of the environment

2120
01:17:55,360 --> 01:17:57,120
which in this case is the

2121
01:17:57,120 --> 01:17:59,600
the arm pose so it sees where the the

2122
01:17:59,600 --> 01:18:01,920
first link of the the robot term is but

2123
01:18:01,920 --> 01:18:04,400
he is not able to see

2124
01:18:04,400 --> 01:18:06,159
normally where the second part of the

2125
01:18:06,159 --> 01:18:08,080
arm he is because he is very uncertain

2126
01:18:08,080 --> 01:18:09,280
about that

2127
01:18:09,280 --> 01:18:12,320
and then and that leads the agent to to

2128
01:18:12,320 --> 01:18:14,800
not being able to actually assess where

2129
01:18:14,800 --> 01:18:16,960
it is in the environment and to to

2130
01:18:16,960 --> 01:18:18,320
provide the

2131
01:18:18,320 --> 01:18:21,600
the right uh a value for uh for what's

2132
01:18:21,600 --> 01:18:23,440
going on so uh

2133
01:18:23,440 --> 01:18:24,400
using

2134
01:18:24,400 --> 01:18:26,400
reconstruction in this environment leads

2135
01:18:26,400 --> 01:18:28,480
to

2136
01:18:28,480 --> 01:18:30,480
this kind of problem where the agent is

2137
01:18:30,480 --> 01:18:32,000
not

2138
01:18:32,000 --> 01:18:34,400
certain about the the internal states

2139
01:18:34,400 --> 01:18:37,520
and so it's uncertain of what it should

2140
01:18:37,520 --> 01:18:38,239
do

2141
01:18:38,239 --> 01:18:39,600
next

2142
01:18:39,600 --> 01:18:41,360
because the signal

2143
01:18:41,360 --> 01:18:43,679
of the state is uncertain is confused

2144
01:18:43,679 --> 01:18:45,360
and

2145
01:18:45,360 --> 01:18:48,080
so it is also the the value provided by

2146
01:18:48,080 --> 01:18:49,120
the

2147
01:18:49,120 --> 01:18:52,320
to the agent by the model

2148
01:18:52,320 --> 01:18:53,600
and

2149
01:18:53,600 --> 01:18:56,239
that's it so i'll just briefly summarize

2150
01:18:56,239 --> 01:18:58,480
what we have seen and uh

2151
01:18:58,480 --> 01:19:00,880
so basically we use a contrastive model

2152
01:19:00,880 --> 01:19:05,600
uh to reduce the computation uh of uh

2153
01:19:05,600 --> 01:19:07,679
of active inference is also brought some

2154
01:19:07,679 --> 01:19:09,920
advantages in reinforcement learning but

2155
01:19:09,920 --> 01:19:11,679
yeah we focus on the

2156
01:19:11,679 --> 01:19:13,920
on the contract on the active inference

2157
01:19:13,920 --> 01:19:16,560
area where this model brought to

2158
01:19:16,560 --> 01:19:18,640
a twofold advantage both in learning the

2159
01:19:18,640 --> 01:19:21,040
the word model faster but also in

2160
01:19:21,040 --> 01:19:22,880
imagining footer trajectories faster

2161
01:19:22,880 --> 01:19:23,760
because you don't have the

2162
01:19:23,760 --> 01:19:26,000
reconstruction

2163
01:19:26,000 --> 01:19:27,520
then we saw that the contrast

2164
01:19:27,520 --> 01:19:28,960
representation learned features that

2165
01:19:28,960 --> 01:19:31,040
better capture relevant information for

2166
01:19:31,040 --> 01:19:33,280
the environment and this was key

2167
01:19:33,280 --> 01:19:36,560
in solving uh both the the richer tasks

2168
01:19:36,560 --> 01:19:38,880
and especially in the ritual distracting

2169
01:19:38,880 --> 01:19:41,120
task where without this

2170
01:19:41,120 --> 01:19:43,280
this feature we wouldn't be able to

2171
01:19:43,280 --> 01:19:46,000
solve the task

2172
01:19:46,000 --> 01:19:47,040
and then

2173
01:19:47,040 --> 01:19:49,520
we will show that

2174
01:19:49,520 --> 01:19:50,560
we can

2175
01:19:50,560 --> 01:19:51,840
we can use

2176
01:19:51,840 --> 01:19:54,480
this method uh to provide

2177
01:19:54,480 --> 01:19:56,080
performance that are similar to

2178
01:19:56,080 --> 01:19:58,000
engineering rewards

2179
01:19:58,000 --> 01:20:00,800
but in a much easier way so you can just

2180
01:20:00,800 --> 01:20:02,560
say okay this is what i want to achieve

2181
01:20:02,560 --> 01:20:04,320
in the environment provide the the

2182
01:20:04,320 --> 01:20:06,960
observation to the agent and the agent

2183
01:20:06,960 --> 01:20:09,040
will find itself a way

2184
01:20:09,040 --> 01:20:10,320
to reach that

2185
01:20:10,320 --> 01:20:12,000
that state without

2186
01:20:12,000 --> 01:20:14,320
actually having to provide

2187
01:20:14,320 --> 01:20:16,480
a reward function for every possible

2188
01:20:16,480 --> 01:20:18,960
states of the environment which

2189
01:20:18,960 --> 01:20:21,920
especially in realistic cases is is

2190
01:20:21,920 --> 01:20:22,910
usually unfeasible

2191
01:20:22,910 --> 01:20:24,800
[Music]

2192
01:20:24,800 --> 01:20:25,520
and

2193
01:20:25,520 --> 01:20:27,360
finally we have also seen that the

2194
01:20:27,360 --> 01:20:29,440
acceleration is very key

2195
01:20:29,440 --> 01:20:31,440
for our method to work because we don't

2196
01:20:31,440 --> 01:20:33,120
want the agent to

2197
01:20:33,120 --> 01:20:35,520
to convert to the sub optimal behavior

2198
01:20:35,520 --> 01:20:37,679
that looks like the

2199
01:20:37,679 --> 01:20:39,840
the right outcome the preferred outcome

2200
01:20:39,840 --> 01:20:42,480
so it's it's very important to wisely

2201
01:20:42,480 --> 01:20:45,600
explore the environment before actually

2202
01:20:45,600 --> 01:20:48,719
delving into learning the

2203
01:20:48,719 --> 01:20:50,880
our preferred policy

2204
01:20:50,880 --> 01:20:52,080
and

2205
01:20:52,080 --> 01:20:54,080
we aim to look more into this in the

2206
01:20:54,080 --> 01:20:56,159
future

2207
01:20:56,159 --> 01:20:59,120
so thank you very much

2208
01:20:59,120 --> 01:21:02,719
that that was it i don't know if there's

2209
01:21:02,719 --> 01:21:05,360
any question

2210
01:21:06,639 --> 01:21:08,960
thank you both very

2211
01:21:08,960 --> 01:21:11,199
interesting presentation so if anyone

2212
01:21:11,199 --> 01:21:14,719
watching live wants to ask a question

2213
01:21:14,719 --> 01:21:16,400
otherwise i

2214
01:21:16,400 --> 01:21:17,760
have a few

2215
01:21:17,760 --> 01:21:19,920
so

2216
01:21:19,920 --> 01:21:22,800
you mentioned a critic model

2217
01:21:22,800 --> 01:21:24,239
when you were describing the

2218
01:21:24,239 --> 01:21:26,800
architecture and that reminded me of

2219
01:21:26,800 --> 01:21:28,639
language learning like if someone says

2220
01:21:28,639 --> 01:21:30,239
repeat after me and then they give a

2221
01:21:30,239 --> 01:21:31,360
sound

2222
01:21:31,360 --> 01:21:32,800
you might be accurate or you might not

2223
01:21:32,800 --> 01:21:36,239
be but if someone said no it was

2224
01:21:36,639 --> 01:21:38,400
you have a negative and a positive

2225
01:21:38,400 --> 01:21:40,960
example so

2226
01:21:40,960 --> 01:21:42,639
what does that speak to perhaps the

2227
01:21:42,639 --> 01:21:45,920
biological basis of contrast of learning

2228
01:21:45,920 --> 01:21:49,120
or how these contrast of learning

2229
01:21:49,120 --> 01:21:51,600
settings active inference or not relate

2230
01:21:51,600 --> 01:21:56,040
to the ways that organisms learn

2231
01:21:58,239 --> 01:22:00,159
okay

2232
01:22:00,159 --> 01:22:03,440
i i will say that

2233
01:22:03,440 --> 01:22:05,760
the the contrasted learning mechanism

2234
01:22:05,760 --> 01:22:07,679
though it's not

2235
01:22:07,679 --> 01:22:08,800
completely

2236
01:22:08,800 --> 01:22:11,040
equal i was added somehow remember

2237
01:22:11,040 --> 01:22:13,120
resembles the abby and learning

2238
01:22:13,120 --> 01:22:15,360
mechanism where you

2239
01:22:15,360 --> 01:22:18,800
when when you have corresponding pairs

2240
01:22:18,800 --> 01:22:19,760
of

2241
01:22:19,760 --> 01:22:20,960
so the

2242
01:22:20,960 --> 01:22:23,199
things that should correspond

2243
01:22:23,199 --> 01:22:25,440
you actually want to to strengthen the

2244
01:22:25,440 --> 01:22:27,440
link and when you have stuff that

2245
01:22:27,440 --> 01:22:29,760
shouldn't uh be corresponding you

2246
01:22:29,760 --> 01:22:31,040
actually want to

2247
01:22:31,040 --> 01:22:32,560
to wake in the link

2248
01:22:32,560 --> 01:22:35,199
so you know i think that biologically we

2249
01:22:35,199 --> 01:22:37,920
could we could actually seeing

2250
01:22:37,920 --> 01:22:40,000
this way so when you have something that

2251
01:22:40,000 --> 01:22:40,880
you

2252
01:22:40,880 --> 01:22:42,480
you want to be

2253
01:22:42,480 --> 01:22:43,679
uh

2254
01:22:43,679 --> 01:22:46,000
you you want to link further in in our

2255
01:22:46,000 --> 01:22:48,320
case the thing that we want to to link

2256
01:22:48,320 --> 01:22:50,560
further so to reinforce is the fact that

2257
01:22:50,560 --> 01:22:52,639
this a certain observation correspond to

2258
01:22:52,639 --> 01:22:54,159
a certain state

2259
01:22:54,159 --> 01:22:55,840
uh then you you strengthen this

2260
01:22:55,840 --> 01:22:57,679
connection well when you

2261
01:22:57,679 --> 01:22:59,199
where you want

2262
01:22:59,199 --> 01:23:01,840
you want to to be far and that's where

2263
01:23:01,840 --> 01:23:04,080
where the contrast i think a bit differs

2264
01:23:04,080 --> 01:23:06,080
maybe from this from this biological

2265
01:23:06,080 --> 01:23:08,480
perspective we actually push it uh we

2266
01:23:08,480 --> 01:23:11,679
push it further which is not always

2267
01:23:11,679 --> 01:23:13,120
the case for regular learning because

2268
01:23:13,120 --> 01:23:15,280
normally you don't have this uh pushing

2269
01:23:15,280 --> 01:23:17,120
farther mechanism so

2270
01:23:17,120 --> 01:23:19,199
i would say this could be one one

2271
01:23:19,199 --> 01:23:20,639
possible

2272
01:23:20,639 --> 01:23:23,600
links and as you said yeah the critic

2273
01:23:23,600 --> 01:23:25,040
function is actually doing something

2274
01:23:25,040 --> 01:23:26,159
very

2275
01:23:26,159 --> 01:23:27,679
very similar to what you mentioned so

2276
01:23:27,679 --> 01:23:28,719
you have a

2277
01:23:28,719 --> 01:23:30,080
positive

2278
01:23:30,080 --> 01:23:32,080
samples and you reinforce so the critic

2279
01:23:32,080 --> 01:23:34,480
tells you yeah this is this is correct

2280
01:23:34,480 --> 01:23:36,080
and it sure tells you that this is

2281
01:23:36,080 --> 01:23:38,639
correct so it's trained to do that

2282
01:23:38,639 --> 01:23:41,520
uh we we do it with machine learning but

2283
01:23:41,520 --> 01:23:43,040
well if you have a good critic you could

2284
01:23:43,040 --> 01:23:44,320
use that

2285
01:23:44,320 --> 01:23:46,080
uh yeah it should tell you yeah this is

2286
01:23:46,080 --> 01:23:49,040
the the right samples while yeah for for

2287
01:23:49,040 --> 01:23:51,760
non-corresponding states and observation

2288
01:23:51,760 --> 01:23:52,639
uh

2289
01:23:52,639 --> 01:23:54,080
yeah this is not

2290
01:23:54,080 --> 01:23:56,239
what we want in our representation we

2291
01:23:56,239 --> 01:23:58,639
want this further

2292
01:23:58,639 --> 01:24:01,040
yeah so maybe to add on daniel

2293
01:24:01,040 --> 01:24:03,920
i think what you're hinting at at um

2294
01:24:03,920 --> 01:24:06,400
providing like it should be like this is

2295
01:24:06,400 --> 01:24:07,600
more like

2296
01:24:07,600 --> 01:24:08,960
a way to

2297
01:24:08,960 --> 01:24:11,360
uh to define preferred state so to speak

2298
01:24:11,360 --> 01:24:14,159
so and if you translate it to do what

2299
01:24:14,159 --> 01:24:17,120
we're doing it's basically saying

2300
01:24:17,120 --> 01:24:18,080
um

2301
01:24:18,080 --> 01:24:21,199
these observations are what you should

2302
01:24:21,199 --> 01:24:22,159
like

2303
01:24:22,159 --> 01:24:25,120
basically so so they come into place for

2304
01:24:25,120 --> 01:24:27,440
um for trading the action model like how

2305
01:24:27,440 --> 01:24:29,840
how do i get to these observations the

2306
01:24:29,840 --> 01:24:32,639
contrastive learning part is more like

2307
01:24:32,639 --> 01:24:34,320
um

2308
01:24:34,320 --> 01:24:36,159
being able to distinguish different

2309
01:24:36,159 --> 01:24:38,719
things basically um

2310
01:24:38,719 --> 01:24:41,600
and and it's it's more broke than

2311
01:24:41,600 --> 01:24:44,719
um than the different um well what you

2312
01:24:44,719 --> 01:24:46,880
what you what you like to what you like

2313
01:24:46,880 --> 01:24:48,960
to have so the contrastive learning just

2314
01:24:48,960 --> 01:24:50,560
learns to distinguish all kinds of

2315
01:24:50,560 --> 01:24:53,360
sounds even all the bad ones

2316
01:24:53,360 --> 01:24:57,199
and uh and you just now say okay but now

2317
01:24:57,199 --> 01:24:59,840
i really want to have this sound so

2318
01:24:59,840 --> 01:25:02,080
try to get there i think that's the

2319
01:25:02,080 --> 01:25:05,280
the difference here

2320
01:25:06,000 --> 01:25:08,239
that kind of sounds like paying

2321
01:25:08,239 --> 01:25:10,159
attention to the right details which we

2322
01:25:10,159 --> 01:25:11,600
saw with

2323
01:25:11,600 --> 01:25:13,360
multiple times like the breakout games

2324
01:25:13,360 --> 01:25:15,199
like how could you miss the ball humans

2325
01:25:15,199 --> 01:25:17,040
are watching that gif and we're watching

2326
01:25:17,040 --> 01:25:18,000
the ball

2327
01:25:18,000 --> 01:25:19,840
but we also have

2328
01:25:19,840 --> 01:25:22,159
a sense of how to pay attention to the

2329
01:25:22,159 --> 01:25:24,400
right details and then in terms of

2330
01:25:24,400 --> 01:25:28,080
action to have curiosity about the right

2331
01:25:28,080 --> 01:25:30,639
things so it definitely

2332
01:25:30,639 --> 01:25:32,400
starts to bridge into some very

2333
01:25:32,400 --> 01:25:34,800
interesting behavior

2334
01:25:34,800 --> 01:25:37,360
another question was about the action

2335
01:25:37,360 --> 01:25:38,800
entropy term

2336
01:25:38,800 --> 01:25:42,159
in the free energy calculations so maybe

2337
01:25:42,159 --> 01:25:44,960
could you restate what the action

2338
01:25:44,960 --> 01:25:46,880
entropy term is since it's one of the

2339
01:25:46,880 --> 01:25:49,040
major contributions and also what does

2340
01:25:49,040 --> 01:25:52,639
that say about adding terms

2341
01:25:52,639 --> 01:25:55,199
to the free energy calculation like the

2342
01:25:55,199 --> 01:25:56,960
action entropy is always greater than

2343
01:25:56,960 --> 01:25:58,000
zero

2344
01:25:58,000 --> 01:26:01,040
kind of like a kl divergence and so that

2345
01:26:01,040 --> 01:26:02,800
you mentioned gives some perhaps nice

2346
01:26:02,800 --> 01:26:05,360
properties about the boundedness of f

2347
01:26:05,360 --> 01:26:07,840
within a lower and an upper bound so

2348
01:26:07,840 --> 01:26:10,080
maybe just what is the action entropy

2349
01:26:10,080 --> 01:26:12,560
doing here can we just add other terms

2350
01:26:12,560 --> 01:26:14,639
that are bounded at zero to free energy

2351
01:26:14,639 --> 01:26:17,920
and use that in other ways

2352
01:26:19,600 --> 01:26:22,880
okay so i'll start with the

2353
01:26:22,880 --> 01:26:24,960
with the question about the

2354
01:26:24,960 --> 01:26:26,800
uh the action entropy term and then i

2355
01:26:26,800 --> 01:26:28,639
i'll also delve into the

2356
01:26:28,639 --> 01:26:30,960
using different bounds for for

2357
01:26:30,960 --> 01:26:33,280
uh the free energy term

2358
01:26:33,280 --> 01:26:35,520
so uh

2359
01:26:35,520 --> 01:26:37,679
here in this uh

2360
01:26:37,679 --> 01:26:39,520
in the way we casted the active

2361
01:26:39,520 --> 01:26:41,040
inference process for learning the

2362
01:26:41,040 --> 01:26:42,400
actions

2363
01:26:42,400 --> 01:26:45,920
uh the the key part is that we

2364
01:26:45,920 --> 01:26:48,719
the actions are now part of the

2365
01:26:48,719 --> 01:26:50,800
the future inference process

2366
01:26:50,800 --> 01:26:51,920
so

2367
01:26:51,920 --> 01:26:53,280
uh

2368
01:26:53,280 --> 01:26:54,800
i i could

2369
01:26:54,800 --> 01:26:56,480
i could also go back to the previous

2370
01:26:56,480 --> 01:26:59,040
life that's necessary but the the

2371
01:26:59,040 --> 01:27:00,719
normally the way that we see this

2372
01:27:00,719 --> 01:27:03,600
objective is without this a term here

2373
01:27:03,600 --> 01:27:07,199
and there but instead we have like

2374
01:27:07,199 --> 01:27:08,960
uh a conditional

2375
01:27:08,960 --> 01:27:11,679
on a policy on a certain policy

2376
01:27:11,679 --> 01:27:14,480
so normally that means that you

2377
01:27:14,480 --> 01:27:17,199
you have some set of policies already

2378
01:27:17,199 --> 01:27:20,560
and you're just trying to decide which

2379
01:27:20,560 --> 01:27:22,560
of them is better

2380
01:27:22,560 --> 01:27:23,840
so

2381
01:27:23,840 --> 01:27:26,159
this could be done like using a knock on

2382
01:27:26,159 --> 01:27:30,480
browser for no cameras at first and then

2383
01:27:30,480 --> 01:27:32,080
just assessing the the one that you

2384
01:27:32,080 --> 01:27:34,560
think are best or just assessing all of

2385
01:27:34,560 --> 01:27:36,960
them but it's that's impossible for

2386
01:27:36,960 --> 01:27:39,920
instance in a continuous action setup

2387
01:27:39,920 --> 01:27:42,639
where uh you cannot access all possible

2388
01:27:42,639 --> 01:27:45,120
uh policies because uh yeah the actions

2389
01:27:45,120 --> 01:27:46,880
are continuous a certain number is

2390
01:27:46,880 --> 01:27:48,639
infinite for every dimension so let's

2391
01:27:48,639 --> 01:27:51,360
make infinite by infinite and so on so

2392
01:27:51,360 --> 01:27:52,960
it's it's a huge

2393
01:27:52,960 --> 01:27:53,760
uh

2394
01:27:53,760 --> 01:27:55,840
it's a huge dimensionality

2395
01:27:55,840 --> 01:27:57,280
in space

2396
01:27:57,280 --> 01:27:58,159
so

2397
01:27:58,159 --> 01:28:01,120
instead here we we make the action part

2398
01:28:01,120 --> 01:28:03,360
of the of the inference process so we

2399
01:28:03,360 --> 01:28:06,080
want uh we want to have a

2400
01:28:06,080 --> 01:28:09,040
separate model that tells you to tell us

2401
01:28:09,040 --> 01:28:11,840
what's what's the action to to take at

2402
01:28:11,840 --> 01:28:13,280
every step

2403
01:28:13,280 --> 01:28:15,280
and uh

2404
01:28:15,280 --> 01:28:18,239
i i what i said that we obtain an action

2405
01:28:18,239 --> 01:28:22,400
entropy term uh and that's because we

2406
01:28:22,400 --> 01:28:25,679
in in choosing the the best action so in

2407
01:28:25,679 --> 01:28:28,880
in trying to to match our actions to the

2408
01:28:28,880 --> 01:28:32,560
one that we we should actually prefer we

2409
01:28:32,560 --> 01:28:34,800
we think it like we don't have a

2410
01:28:34,800 --> 01:28:38,400
preference this over action so we

2411
01:28:38,400 --> 01:28:42,639
so for instance i if i want to reach

2412
01:28:42,639 --> 01:28:44,639
a certain state in environment so if i

2413
01:28:44,639 --> 01:28:47,040
want to to go from this room to to the

2414
01:28:47,040 --> 01:28:48,239
kitchen

2415
01:28:48,239 --> 01:28:50,480
maybe i don't care what's the what's the

2416
01:28:50,480 --> 01:28:53,040
sharpest word the shorter path is i just

2417
01:28:53,040 --> 01:28:55,600
care about getting there at some point

2418
01:28:55,600 --> 01:28:57,520
or i don't care about

2419
01:28:57,520 --> 01:29:00,800
going left or going round right now

2420
01:29:00,800 --> 01:29:02,000
when i

2421
01:29:02,000 --> 01:29:04,320
when i get off of my chair i just want

2422
01:29:04,320 --> 01:29:05,679
to

2423
01:29:05,679 --> 01:29:08,320
to go where i need to go so we don't we

2424
01:29:08,320 --> 01:29:10,560
don't place a prior over the action we

2425
01:29:10,560 --> 01:29:13,600
just say uh whatever action is fine as

2426
01:29:13,600 --> 01:29:15,679
long as it brings you the fastest as

2427
01:29:15,679 --> 01:29:18,320
possible to the goal because the the the

2428
01:29:18,320 --> 01:29:20,239
fastest thing is not

2429
01:29:20,239 --> 01:29:22,239
given by the action itself but but by

2430
01:29:22,239 --> 01:29:24,480
minimizing the free energy so we don't

2431
01:29:24,480 --> 01:29:27,360
want a preference over the actions we

2432
01:29:27,360 --> 01:29:28,400
wanted

2433
01:29:28,400 --> 01:29:30,320
we want the free energy to this is the

2434
01:29:30,320 --> 01:29:31,760
fastest spot

2435
01:29:31,760 --> 01:29:34,000
and so the actions are we assume a

2436
01:29:34,000 --> 01:29:36,239
uniform distribution over them and what

2437
01:29:36,239 --> 01:29:39,840
remains is just an entropy so it will be

2438
01:29:39,840 --> 01:29:42,560
a child divergence between

2439
01:29:42,560 --> 01:29:43,840
the q

2440
01:29:43,840 --> 01:29:46,880
over action given the states and the

2441
01:29:46,880 --> 01:29:50,159
this p-80 which would basically becomes

2442
01:29:50,159 --> 01:29:52,800
uh an entropy value if you if you assume

2443
01:29:52,800 --> 01:29:54,239
this is a constant

2444
01:29:54,239 --> 01:29:56,000
because it's just subtracting a constant

2445
01:29:56,000 --> 01:29:57,280
to that

2446
01:29:57,280 --> 01:29:59,360
and uh yeah

2447
01:29:59,360 --> 01:30:02,719
switching to the to the other

2448
01:30:02,719 --> 01:30:04,960
part of the question so

2449
01:30:04,960 --> 01:30:07,199
what does it mean to us

2450
01:30:07,199 --> 01:30:10,719
this constant term here so

2451
01:30:10,719 --> 01:30:13,040
is having constant term

2452
01:30:13,040 --> 01:30:14,800
useful so

2453
01:30:14,800 --> 01:30:17,600
i don't know if there's any other

2454
01:30:17,600 --> 01:30:20,239
useful constant term that we call that

2455
01:30:20,239 --> 01:30:22,000
so

2456
01:30:22,000 --> 01:30:24,080
mathematically speaking having a

2457
01:30:24,080 --> 01:30:26,080
constant so

2458
01:30:26,080 --> 01:30:27,360
having gone up

2459
01:30:27,360 --> 01:30:29,360
an upper bound because of a constant

2460
01:30:29,360 --> 01:30:30,639
will then be our mean because you're

2461
01:30:30,639 --> 01:30:33,199
minimizing the same objective but then

2462
01:30:33,199 --> 01:30:34,480
on top of that

2463
01:30:34,480 --> 01:30:36,800
we apply the contrastive

2464
01:30:36,800 --> 01:30:39,040
er the contrastive

2465
01:30:39,040 --> 01:30:40,400
approximation

2466
01:30:40,400 --> 01:30:42,880
and that leads to another

2467
01:30:42,880 --> 01:30:45,360
upper bound and as i said there are some

2468
01:30:45,360 --> 01:30:47,360
implications of these we get

2469
01:30:47,360 --> 01:30:50,400
maybe a better representation but uh

2470
01:30:50,400 --> 01:30:52,239
are we getting farther from there from

2471
01:30:52,239 --> 01:30:55,600
the actual objective so

2472
01:30:55,600 --> 01:30:57,280
from my point of view

2473
01:30:57,280 --> 01:30:59,040
as long as

2474
01:30:59,040 --> 01:31:01,199
we achieve something that is actually

2475
01:31:01,199 --> 01:31:03,679
better it doesn't really matter how how

2476
01:31:03,679 --> 01:31:05,840
far are we from the actual surprise i'll

2477
01:31:05,840 --> 01:31:06,960
see now

2478
01:31:06,960 --> 01:31:08,480
so

2479
01:31:08,480 --> 01:31:10,400
in any case we will always

2480
01:31:10,400 --> 01:31:12,719
uh get some kind of uh

2481
01:31:12,719 --> 01:31:14,840
amortization or

2482
01:31:14,840 --> 01:31:17,920
approximation and we will probably never

2483
01:31:17,920 --> 01:31:18,719
get

2484
01:31:18,719 --> 01:31:19,440
a

2485
01:31:19,440 --> 01:31:22,320
100 percent close to the surprising

2486
01:31:22,320 --> 01:31:23,280
value

2487
01:31:23,280 --> 01:31:25,280
so because we don't have a perfect model

2488
01:31:25,280 --> 01:31:26,960
so a perfect model of the world doesn't

2489
01:31:26,960 --> 01:31:29,280
exist it's it's impossible to imagine

2490
01:31:29,280 --> 01:31:31,520
that we can model every details of the

2491
01:31:31,520 --> 01:31:34,000
environment even with uh with a billion

2492
01:31:34,000 --> 01:31:35,760
uh machine learning parameter and it's

2493
01:31:35,760 --> 01:31:38,480
impossible uh to think that we will

2494
01:31:38,480 --> 01:31:41,920
always act perfectly and always get in

2495
01:31:41,920 --> 01:31:44,639
the in the perfect route to go uh

2496
01:31:44,639 --> 01:31:47,679
using the the always uh optimal action

2497
01:31:47,679 --> 01:31:49,120
especially because there's always some

2498
01:31:49,120 --> 01:31:50,960
uncertainty in the environment

2499
01:31:50,960 --> 01:31:52,320
and there's a

2500
01:31:52,320 --> 01:31:53,600
a lot of

2501
01:31:53,600 --> 01:31:55,920
things that we we normally want to

2502
01:31:55,920 --> 01:31:58,880
ignore in our everyday life so a lot of

2503
01:31:58,880 --> 01:32:01,360
things here is not actually important to

2504
01:32:01,360 --> 01:32:04,080
to capture in the world model or

2505
01:32:04,080 --> 01:32:06,800
action-wise not always important to be a

2506
01:32:06,800 --> 01:32:09,199
hundred percent accurate in our uh

2507
01:32:09,199 --> 01:32:11,600
movements so in the action we take the

2508
01:32:11,600 --> 01:32:13,520
important things that we we get close to

2509
01:32:13,520 --> 01:32:16,239
the goal so i i will say yeah if if

2510
01:32:16,239 --> 01:32:18,560
there are any other term that we any

2511
01:32:18,560 --> 01:32:20,639
other constant term or just any other

2512
01:32:20,639 --> 01:32:22,719
modification that we could

2513
01:32:22,719 --> 01:32:24,560
do to the to the free energy function

2514
01:32:24,560 --> 01:32:27,040
that actually leads to better results

2515
01:32:27,040 --> 01:32:29,040
without compromising the original goal

2516
01:32:29,040 --> 01:32:31,760
of minimizing free energy i think that's

2517
01:32:31,760 --> 01:32:33,199
that would be

2518
01:32:33,199 --> 01:32:36,000
a good way to

2519
01:32:36,239 --> 01:32:38,880
to address some of the issues that we

2520
01:32:38,880 --> 01:32:40,639
that we currently have with uh with

2521
01:32:40,639 --> 01:32:42,480
active inference and that that could

2522
01:32:42,480 --> 01:32:44,000
also lead to

2523
01:32:44,000 --> 01:32:46,480
to improving uh the performance of the

2524
01:32:46,480 --> 01:32:48,400
the artificial implementation of active

2525
01:32:48,400 --> 01:32:49,920
inference uh

2526
01:32:49,920 --> 01:32:52,080
significantly so

2527
01:32:52,080 --> 01:32:54,800
that's also why i think that uh taking

2528
01:32:54,800 --> 01:32:56,320
advantage of some

2529
01:32:56,320 --> 01:32:58,480
lessons that that we learned from

2530
01:32:58,480 --> 01:33:00,800
reinforcement learning is actually a

2531
01:33:00,800 --> 01:33:02,639
useful inactive influence as well

2532
01:33:02,639 --> 01:33:03,920
because uh

2533
01:33:03,920 --> 01:33:05,840
there has been a ton of research about

2534
01:33:05,840 --> 01:33:08,480
uh way to amortize this thing or

2535
01:33:08,480 --> 01:33:10,800
approximate this thing better or

2536
01:33:10,800 --> 01:33:12,000
uh

2537
01:33:12,000 --> 01:33:13,920
train a better deep learning model for

2538
01:33:13,920 --> 01:33:16,639
some something some very specific aspect

2539
01:33:16,639 --> 01:33:17,360
and

2540
01:33:17,360 --> 01:33:20,000
i think which the the active inference

2541
01:33:20,000 --> 01:33:21,360
research should

2542
01:33:21,360 --> 01:33:23,199
benefit from this should take

2543
01:33:23,199 --> 01:33:25,440
inspiration from this

2544
01:33:25,440 --> 01:33:27,520
yeah maybe if i might ask peter can you

2545
01:33:27,520 --> 01:33:29,040
go back to the slide with the action

2546
01:33:29,040 --> 01:33:31,440
entry

2547
01:33:33,120 --> 01:33:34,800
this one

2548
01:33:34,800 --> 01:33:38,320
yeah so so maybe to um to make clear

2549
01:33:38,320 --> 01:33:40,000
here or

2550
01:33:40,000 --> 01:33:42,159
or maybe people that's that are less

2551
01:33:42,159 --> 01:33:44,480
familiar with reinforcement learning but

2552
01:33:44,480 --> 01:33:46,800
are coming from a more active influence

2553
01:33:46,800 --> 01:33:48,159
background so

2554
01:33:48,159 --> 01:33:52,719
in in terms of um active inference um as

2555
01:33:52,719 --> 01:33:55,440
score christian would would look at it

2556
01:33:55,440 --> 01:33:56,400
um

2557
01:33:56,400 --> 01:33:57,920
this is basically something that you

2558
01:33:57,920 --> 01:34:00,239
should not do uh

2559
01:34:00,239 --> 01:34:01,360
so

2560
01:34:01,360 --> 01:34:05,559
so basically um

2561
01:34:06,000 --> 01:34:08,480
what happens here is that we we see

2562
01:34:08,480 --> 01:34:10,480
action inference more like

2563
01:34:10,480 --> 01:34:13,920
a habitual thing like i i know i'm in

2564
01:34:13,920 --> 01:34:16,000
the states or i think i'm in the state

2565
01:34:16,000 --> 01:34:19,040
so therefore i can just

2566
01:34:19,040 --> 01:34:20,639
infer my action

2567
01:34:20,639 --> 01:34:23,520
without even planning it's kind of

2568
01:34:23,520 --> 01:34:26,719
you become habituated so i've planned

2569
01:34:26,719 --> 01:34:28,560
this hundreds of times and it's always

2570
01:34:28,560 --> 01:34:30,639
this outcome so i just stop planning and

2571
01:34:30,639 --> 01:34:33,679
i just amortize this action into an

2572
01:34:33,679 --> 01:34:35,280
amortized policy

2573
01:34:35,280 --> 01:34:37,040
so that's basically the kind of the

2574
01:34:37,040 --> 01:34:39,920
mechanism that that we apply here in

2575
01:34:39,920 --> 01:34:43,920
order to avoid planning um all the time

2576
01:34:43,920 --> 01:34:46,320
because that's that's the the the tricky

2577
01:34:46,320 --> 01:34:47,199
part

2578
01:34:47,199 --> 01:34:48,159
uh

2579
01:34:48,159 --> 01:34:50,159
we have too much options to plan so we

2580
01:34:50,159 --> 01:34:52,800
don't want to do this so we just say

2581
01:34:52,800 --> 01:34:55,280
let's amortize it from start

2582
01:34:55,280 --> 01:34:58,239
which basically means that this a this

2583
01:34:58,239 --> 01:35:00,320
this or queue or approximate posterior

2584
01:35:00,320 --> 01:35:02,400
is not only over states but also over

2585
01:35:02,400 --> 01:35:04,960
actions and then so the action entropy

2586
01:35:04,960 --> 01:35:09,280
just falls out by introducing the

2587
01:35:09,280 --> 01:35:11,280
the action in the queue there so it's

2588
01:35:11,280 --> 01:35:13,440
not that you that we magically add an

2589
01:35:13,440 --> 01:35:15,600
action action entry return to the

2590
01:35:15,600 --> 01:35:19,440
formulation it just comes out because of

2591
01:35:19,440 --> 01:35:20,480
having

2592
01:35:20,480 --> 01:35:23,199
the actions as part of our approximate

2593
01:35:23,199 --> 01:35:25,520
posterior but so keep in mind that this

2594
01:35:25,520 --> 01:35:27,679
also means that we have an approximate

2595
01:35:27,679 --> 01:35:30,800
to steer over our action selection and

2596
01:35:30,800 --> 01:35:32,080
this works

2597
01:35:32,080 --> 01:35:34,480
um in in these three force flowing

2598
01:35:34,480 --> 01:35:37,520
problems because there

2599
01:35:37,520 --> 01:35:40,800
yeah your goal is always the same

2600
01:35:40,800 --> 01:35:43,760
it does not shift uh it's it's not a

2601
01:35:43,760 --> 01:35:46,159
it's also another uh uh

2602
01:35:46,159 --> 01:35:47,199
um

2603
01:35:47,199 --> 01:35:49,199
if you if you think back on biological

2604
01:35:49,199 --> 01:35:50,639
agents it's not like a complex

2605
01:35:50,639 --> 01:35:52,800
distribution to maintain from your state

2606
01:35:52,800 --> 01:35:55,119
basically just yeah this is the reward

2607
01:35:55,119 --> 01:35:56,560
this is where you get it it's always the

2608
01:35:56,560 --> 01:35:59,760
same thing so this basically means that

2609
01:35:59,760 --> 01:36:02,159
your environments where in which we test

2610
01:36:02,159 --> 01:36:03,920
these agents and which also

2611
01:36:03,920 --> 01:36:06,080
reinforcement learning solutions test

2612
01:36:06,080 --> 01:36:08,320
their agents is exactly an environment

2613
01:36:08,320 --> 01:36:11,520
institute for

2614
01:36:11,520 --> 01:36:14,000
i can amortize whatever what i have to

2615
01:36:14,000 --> 01:36:16,639
do because if i know my state i know

2616
01:36:16,639 --> 01:36:19,119
what i have to do basically

2617
01:36:19,119 --> 01:36:21,600
things will change i guess if you have

2618
01:36:21,600 --> 01:36:24,159
another environment in which this is not

2619
01:36:24,159 --> 01:36:26,320
the case where you could be in a certain

2620
01:36:26,320 --> 01:36:28,880
state and you could still have multiple

2621
01:36:28,880 --> 01:36:32,880
options to do and you and you can only

2622
01:36:32,880 --> 01:36:35,280
you can only really know what to do by

2623
01:36:35,280 --> 01:36:37,199
planning ahead or by

2624
01:36:37,199 --> 01:36:38,030
first

2625
01:36:38,030 --> 01:36:40,000
[Music]

2626
01:36:40,000 --> 01:36:42,239
forage for information on on what's

2627
01:36:42,239 --> 01:36:43,840
happening and in these kind of

2628
01:36:43,840 --> 01:36:47,119
environments i i think that amortization

2629
01:36:47,119 --> 01:36:49,600
trick won't uh won't help you a lot or

2630
01:36:49,600 --> 01:36:50,800
you cannot do it

2631
01:36:50,800 --> 01:36:54,080
just by amortizing so it's it's a trick

2632
01:36:54,080 --> 01:36:56,719
we did to uh to allow it to work in

2633
01:36:56,719 --> 01:36:58,800
these kind of environments because yeah

2634
01:36:58,800 --> 01:37:01,199
we have to benchmark against uh some

2635
01:37:01,199 --> 01:37:02,480
things and

2636
01:37:02,480 --> 01:37:05,040
you have to be a bit on on on par there

2637
01:37:05,040 --> 01:37:07,280
but so

2638
01:37:07,280 --> 01:37:09,920
keep in mind it's not a silver bullet

2639
01:37:09,920 --> 01:37:12,560
that will always work uh we do

2640
01:37:12,560 --> 01:37:14,960
deviate from vanilla active inference

2641
01:37:14,960 --> 01:37:18,560
here we cost action inference as like we

2642
01:37:18,560 --> 01:37:20,400
just want to learn habits we don't want

2643
01:37:20,400 --> 01:37:21,760
to plan

2644
01:37:21,760 --> 01:37:23,679
but this also means that there might be

2645
01:37:23,679 --> 01:37:26,239
situations where it will not work

2646
01:37:26,239 --> 01:37:28,400
and then it's not due to active

2647
01:37:28,400 --> 01:37:30,400
inference or free energy principle

2648
01:37:30,400 --> 01:37:33,119
that's not working it's more like yeah

2649
01:37:33,119 --> 01:37:36,000
we did a crude approximation here by

2650
01:37:36,000 --> 01:37:40,320
which things might not work anymore

2651
01:37:40,560 --> 01:37:43,920
that's interesting um about which

2652
01:37:43,920 --> 01:37:46,239
training environments favor what kind of

2653
01:37:46,239 --> 01:37:48,159
algorithms and then how that shapes the

2654
01:37:48,159 --> 01:37:51,199
perception of different algorithms like

2655
01:37:51,199 --> 01:37:53,520
the navigation task what if there was a

2656
01:37:53,520 --> 01:37:56,000
fuel tank or there was a

2657
01:37:56,000 --> 01:37:57,040
um

2658
01:37:57,040 --> 01:37:58,639
larger space that was going to require

2659
01:37:58,639 --> 01:38:00,639
like multiple foraging information

2660
01:38:00,639 --> 01:38:02,880
foraging trips for example

2661
01:38:02,880 --> 01:38:04,080
and um

2662
01:38:04,080 --> 01:38:07,440
so then the sort of single-minded seeker

2663
01:38:07,440 --> 01:38:09,360
is going to

2664
01:38:09,360 --> 01:38:11,760
just die fast but then something that's

2665
01:38:11,760 --> 01:38:14,719
able to actually engage in planning

2666
01:38:14,719 --> 01:38:16,960
wouldn't so that was a little bit like

2667
01:38:16,960 --> 01:38:18,880
to those who are familiar with active

2668
01:38:18,880 --> 01:38:20,880
inference and then here's a variant on

2669
01:38:20,880 --> 01:38:22,639
what we've seen before

2670
01:38:22,639 --> 01:38:24,320
how about for those who are more

2671
01:38:24,320 --> 01:38:26,159
familiar with the dreamer

2672
01:38:26,159 --> 01:38:28,480
architecture or reinforcement learning

2673
01:38:28,480 --> 01:38:30,639
what makes active inference active

2674
01:38:30,639 --> 01:38:31,600
inference

2675
01:38:31,600 --> 01:38:34,880
and how is it different

2676
01:38:38,320 --> 01:38:39,600
well

2677
01:38:39,600 --> 01:38:41,410
i think

2678
01:38:41,410 --> 01:38:43,440
[Music]

2679
01:38:43,440 --> 01:38:44,400
they are

2680
01:38:44,400 --> 01:38:47,600
um they're largely uh similar let's say

2681
01:38:47,600 --> 01:38:49,280
i think that would be the starting point

2682
01:38:49,280 --> 01:38:50,400
because

2683
01:38:50,400 --> 01:38:52,560
of often people think about what's the

2684
01:38:52,560 --> 01:38:53,679
difference

2685
01:38:53,679 --> 01:38:54,400
but

2686
01:38:54,400 --> 01:38:57,040
but i think the the main point that we

2687
01:38:57,040 --> 01:39:00,080
should rather stress more as an active

2688
01:39:00,080 --> 01:39:02,000
entrance community is that there is a

2689
01:39:02,000 --> 01:39:04,159
lot more similarities between

2690
01:39:04,159 --> 01:39:06,320
reinforcement learning and active

2691
01:39:06,320 --> 01:39:08,239
influence i would say that active

2692
01:39:08,239 --> 01:39:09,920
entrance is a bit more general than

2693
01:39:09,920 --> 01:39:12,480
reinforcement learning in the sense that

2694
01:39:12,480 --> 01:39:13,920
on the one hand

2695
01:39:13,920 --> 01:39:16,239
um

2696
01:39:16,239 --> 01:39:19,280
we don't use a reward function per se

2697
01:39:19,280 --> 01:39:22,560
but we we relax that a bit as in we just

2698
01:39:22,560 --> 01:39:24,880
have a distribution over preferred

2699
01:39:24,880 --> 01:39:28,000
outcomes which is a bit more

2700
01:39:28,000 --> 01:39:28,960
general

2701
01:39:28,960 --> 01:39:30,159
i would say

2702
01:39:30,159 --> 01:39:32,080
and then the second thing is that

2703
01:39:32,080 --> 01:39:33,520
instead of

2704
01:39:33,520 --> 01:39:36,080
by starting off from the free energy

2705
01:39:36,080 --> 01:39:37,440
principle as in

2706
01:39:37,440 --> 01:39:39,199
this is the objective that we want to

2707
01:39:39,199 --> 01:39:40,639
minimize

2708
01:39:40,639 --> 01:39:43,760
you also get the

2709
01:39:43,760 --> 01:39:47,199
the extrinsic value term here which is

2710
01:39:47,199 --> 01:39:49,119
exactly the same thing as what the next

2711
01:39:49,119 --> 01:39:50,639
reinforcement learning agent would

2712
01:39:50,639 --> 01:39:53,920
optimize so if you only look at

2713
01:39:53,920 --> 01:39:56,880
extrinsic value your free energy agents

2714
01:39:56,880 --> 01:39:58,080
will also

2715
01:39:58,080 --> 01:39:59,119
do this

2716
01:39:59,119 --> 01:39:59,840
but

2717
01:39:59,840 --> 01:40:02,480
the the the

2718
01:40:02,480 --> 01:40:06,400
the added value i would say comes in the

2719
01:40:06,400 --> 01:40:08,880
information gain terms and

2720
01:40:08,880 --> 01:40:11,440
these will only give you an additional

2721
01:40:11,440 --> 01:40:12,560
benefit

2722
01:40:12,560 --> 01:40:14,239
in environments where there is

2723
01:40:14,239 --> 01:40:15,840
information to gain

2724
01:40:15,840 --> 01:40:18,719
uh and this is not your typical

2725
01:40:18,719 --> 01:40:20,880
reinforcement learning environment

2726
01:40:20,880 --> 01:40:22,480
but if you look at

2727
01:40:22,480 --> 01:40:23,679
for example

2728
01:40:23,679 --> 01:40:26,320
the the the the team mace mouse from

2729
01:40:26,320 --> 01:40:28,400
call of wisdom these are typical

2730
01:40:28,400 --> 01:40:29,840
environments where you can actually show

2731
01:40:29,840 --> 01:40:32,480
that if you only go for extrinsic value

2732
01:40:32,480 --> 01:40:33,280
yeah

2733
01:40:33,280 --> 01:40:35,679
you you won't you will be acting super

2734
01:40:35,679 --> 01:40:37,760
optimal so you can actually

2735
01:40:37,760 --> 01:40:38,639
prove

2736
01:40:38,639 --> 01:40:41,280
almost that in some environments

2737
01:40:41,280 --> 01:40:44,020
uh only looking at its extrinsic value

2738
01:40:44,020 --> 01:40:45,280
[Music]

2739
01:40:45,280 --> 01:40:47,280
given the correct model of the

2740
01:40:47,280 --> 01:40:49,520
environment active inference will win i

2741
01:40:49,520 --> 01:40:51,520
think the crucial uh

2742
01:40:51,520 --> 01:40:53,679
thing that we need to research on is how

2743
01:40:53,679 --> 01:40:56,480
do you get the the of the the correct or

2744
01:40:56,480 --> 01:40:59,600
the optimal model of your world in which

2745
01:40:59,600 --> 01:41:02,080
by optimizing uh your expected free

2746
01:41:02,080 --> 01:41:03,840
energy actually

2747
01:41:03,840 --> 01:41:05,840
you do the sensible planning

2748
01:41:05,840 --> 01:41:08,719
and this is still largely unresolved and

2749
01:41:08,719 --> 01:41:10,880
with our models we are

2750
01:41:10,880 --> 01:41:12,960
taking steps in that direction but as

2751
01:41:12,960 --> 01:41:15,199
you can see there are lots of

2752
01:41:15,199 --> 01:41:16,239
issues

2753
01:41:16,239 --> 01:41:17,280
to just

2754
01:41:17,280 --> 01:41:18,960
find the correct mole

2755
01:41:18,960 --> 01:41:20,880
because in in if you just look at the

2756
01:41:20,880 --> 01:41:23,040
mouth the likelihood based model should

2757
01:41:23,040 --> 01:41:25,840
be perfectly fine but by by the way you

2758
01:41:25,840 --> 01:41:27,520
optimize and practice then you see all

2759
01:41:27,520 --> 01:41:30,000
kinds of problems like okay this this

2760
01:41:30,000 --> 01:41:31,679
this little pixel is actually the most

2761
01:41:31,679 --> 01:41:34,159
important pixel of the uh of the thing

2762
01:41:34,159 --> 01:41:37,199
and that does not appear so in my loss

2763
01:41:37,199 --> 01:41:38,800
function so that's why everything

2764
01:41:38,800 --> 01:41:41,760
collapses so in theory every it should

2765
01:41:41,760 --> 01:41:43,600
work but there are a lot of practical

2766
01:41:43,600 --> 01:41:46,560
problems to to find the correct model

2767
01:41:46,560 --> 01:41:48,639
that pays attention to the correct

2768
01:41:48,639 --> 01:41:50,480
details or the correct aspects of your

2769
01:41:50,480 --> 01:41:52,800
observations and this is still that this

2770
01:41:52,800 --> 01:41:55,040
is something that is shared with

2771
01:41:55,040 --> 01:41:57,199
model-based reinforcement learning as

2772
01:41:57,199 --> 01:41:58,400
well as

2773
01:41:58,400 --> 01:42:00,960
active inference uh and and i think

2774
01:42:00,960 --> 01:42:04,000
there's a huge opportunity to find

2775
01:42:04,000 --> 01:42:05,360
new uh

2776
01:42:05,360 --> 01:42:08,480
techniques that can can put forward both

2777
01:42:08,480 --> 01:42:09,920
both fields

2778
01:42:09,920 --> 01:42:12,000
and we also show this like a contrastive

2779
01:42:12,000 --> 01:42:14,320
dreamer in the distracting environment

2780
01:42:14,320 --> 01:42:16,639
also

2781
01:42:17,199 --> 01:42:19,040
improved performance on the normal dream

2782
01:42:19,040 --> 01:42:22,400
so by by having a technique that

2783
01:42:22,400 --> 01:42:24,880
lets you build a better model any model

2784
01:42:24,880 --> 01:42:26,480
based

2785
01:42:26,480 --> 01:42:28,480
algorithm will work

2786
01:42:28,480 --> 01:42:30,880
and active inference has this special

2787
01:42:30,880 --> 01:42:32,239
notion of

2788
01:42:32,239 --> 01:42:35,119
also taking your accounts uh information

2789
01:42:35,119 --> 01:42:37,600
gain in environments where you might be

2790
01:42:37,600 --> 01:42:41,360
unsure unsure on on what your status

2791
01:42:41,360 --> 01:42:43,440
so that's that's where it can prevail

2792
01:42:43,440 --> 01:42:46,080
but uh i think in in most of the

2793
01:42:46,080 --> 01:42:47,679
benchmark environments that we've seen

2794
01:42:47,679 --> 01:42:50,400
nowadays especially in machine learning

2795
01:42:50,400 --> 01:42:52,480
uh you probably don't need these terms

2796
01:42:52,480 --> 01:42:54,960
you probably get away with uh just

2797
01:42:54,960 --> 01:42:58,480
maximizing rewards uh which is in in in

2798
01:42:58,480 --> 01:43:01,280
fact also an active inference uh agents

2799
01:43:01,280 --> 01:43:03,679
and to some sense if of course if it's

2800
01:43:03,679 --> 01:43:04,480
if it's

2801
01:43:04,480 --> 01:43:06,239
i'm talking to about a model-based

2802
01:43:06,239 --> 01:43:08,400
technique so like dreamer agent in this

2803
01:43:08,400 --> 01:43:10,880
case of course the model 3

2804
01:43:10,880 --> 01:43:12,800
ones are

2805
01:43:12,800 --> 01:43:15,040
these are a bit different as they

2806
01:43:15,040 --> 01:43:16,880
they don't need a model at all but at

2807
01:43:16,880 --> 01:43:18,400
least for model-based reinforcement

2808
01:43:18,400 --> 01:43:20,239
learning agents i think

2809
01:43:20,239 --> 01:43:21,840
it's pretty similar to what an active

2810
01:43:21,840 --> 01:43:23,760
influence agents would do

2811
01:43:23,760 --> 01:43:26,639
in these environments

2812
01:43:28,800 --> 01:43:30,960
thank you tim pietro anything you'd add

2813
01:43:30,960 --> 01:43:33,280
to that

2814
01:43:34,239 --> 01:43:35,119
yeah

2815
01:43:35,119 --> 01:43:36,000
i would

2816
01:43:36,000 --> 01:43:39,239
like to

2817
01:43:39,679 --> 01:43:41,440
to discuss

2818
01:43:41,440 --> 01:43:43,840
one aspect of dreamer that we

2819
01:43:43,840 --> 01:43:45,600
a little bit overlooked it is the fact

2820
01:43:45,600 --> 01:43:46,880
that

2821
01:43:46,880 --> 01:43:49,040
uh makes this

2822
01:43:49,040 --> 01:43:51,760
amortization similar and it's it's also

2823
01:43:51,760 --> 01:43:54,480
similar to what we have done so yeah the

2824
01:43:54,480 --> 01:43:57,520
this this is we learn a policy basically

2825
01:43:57,520 --> 01:43:59,360
we are an actual network that provides

2826
01:43:59,360 --> 01:44:01,600
the correct state

2827
01:44:01,600 --> 01:44:03,520
the correct action for every state but

2828
01:44:03,520 --> 01:44:04,960
uh

2829
01:44:04,960 --> 01:44:07,840
it is the key step that actually

2830
01:44:07,840 --> 01:44:09,920
brings us closer to the active inference

2831
01:44:09,920 --> 01:44:11,920
formulation is that we

2832
01:44:11,920 --> 01:44:14,960
we imagine uh several time steps in the

2833
01:44:14,960 --> 01:44:16,639
future so

2834
01:44:16,639 --> 01:44:21,920
it is true that we don't uh evaluate uh

2835
01:44:21,920 --> 01:44:24,800
long policies and over

2836
01:44:24,800 --> 01:44:27,360
over time that that we have this uh this

2837
01:44:27,360 --> 01:44:28,239
uh

2838
01:44:28,239 --> 01:44:29,360
prior

2839
01:44:29,360 --> 01:44:31,679
about action that is given by our action

2840
01:44:31,679 --> 01:44:33,119
network

2841
01:44:33,119 --> 01:44:34,080
but

2842
01:44:34,080 --> 01:44:35,920
it is also true that given the fact that

2843
01:44:35,920 --> 01:44:37,600
we

2844
01:44:37,600 --> 01:44:40,159
we evaluate the state we we expect to

2845
01:44:40,159 --> 01:44:42,239
see and then from there

2846
01:44:42,239 --> 01:44:46,879
uh we restart uh doing the

2847
01:44:47,199 --> 01:44:48,960
the action optimization process we

2848
01:44:48,960 --> 01:44:50,639
actually get closer

2849
01:44:50,639 --> 01:44:52,880
uh to to the optimization scheme of

2850
01:44:52,880 --> 01:44:54,639
active inference in particular there are

2851
01:44:54,639 --> 01:44:55,840
there is a

2852
01:44:55,840 --> 01:44:57,760
paper called sophisticated inference

2853
01:44:57,760 --> 01:44:59,840
that discuss this when you

2854
01:44:59,840 --> 01:45:01,360
when you actually

2855
01:45:01,360 --> 01:45:04,639
take an action and then you reimagine

2856
01:45:04,639 --> 01:45:06,639
from that step what's gonna up what's

2857
01:45:06,639 --> 01:45:08,400
gonna happen there are some implications

2858
01:45:08,400 --> 01:45:09,920
of this but uh

2859
01:45:09,920 --> 01:45:12,880
we are not completely drifting

2860
01:45:12,880 --> 01:45:15,280
away from the from the original active

2861
01:45:15,280 --> 01:45:17,440
influence theory because of this it's

2862
01:45:17,440 --> 01:45:19,920
just a different way of

2863
01:45:19,920 --> 01:45:22,560
doing the action selection process and

2864
01:45:22,560 --> 01:45:24,960
in that indeed the dreamer is also very

2865
01:45:24,960 --> 01:45:26,239
close to

2866
01:45:26,239 --> 01:45:30,280
to active inference itself

2867
01:45:32,159 --> 01:45:33,119
cool

2868
01:45:33,119 --> 01:45:34,080
thank you

2869
01:45:34,080 --> 01:45:36,159
i i wrote down if you don't know where

2870
01:45:36,159 --> 01:45:39,119
you prefer to go you are lost

2871
01:45:39,119 --> 01:45:41,360
drive fast if you know how to get there

2872
01:45:41,360 --> 01:45:43,199
figure it out if you don't and then

2873
01:45:43,199 --> 01:45:45,840
reassess continually

2874
01:45:45,840 --> 01:45:47,440
and i hope that conveys some of the

2875
01:45:47,440 --> 01:45:50,159
similarities and differences

2876
01:45:50,159 --> 01:45:54,239
do you have any final comments

2877
01:45:56,080 --> 01:45:57,679
this is a very

2878
01:45:57,679 --> 01:45:59,440
interesting line of research and we

2879
01:45:59,440 --> 01:46:02,400
really appreciate this model stream

2880
01:46:02,400 --> 01:46:04,960
hope to see you in the future or should

2881
01:46:04,960 --> 01:46:07,679
i say we expect and prefer it but thanks

2882
01:46:07,679 --> 01:46:09,600
again pietro and tim this is really

2883
01:46:09,600 --> 01:46:12,159
awesome

2884
01:46:12,159 --> 01:46:14,000
thanks for having us

2885
01:46:14,000 --> 01:46:15,679
thank you for having us have a good day

2886
01:46:15,679 --> 01:46:18,159
everyone see

