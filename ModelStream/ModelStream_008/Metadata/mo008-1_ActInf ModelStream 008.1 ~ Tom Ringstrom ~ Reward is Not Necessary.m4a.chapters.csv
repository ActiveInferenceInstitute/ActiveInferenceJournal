start	end	startTime	summary	headline	gist
1170	124282	00:01	Thomas Ringstrom will present on Reward is Not Necessary, a compositional theory of Self Preserving Agents with Empowerment gain maximization. There will be a presentation followed by a discussion.	Thomas Ringstrom will present on Reward is Not Necessary in active inference	Reasons Why Reward is Not Necessary in Inactive In
124416	470234	02:04	The problem is that you can't really represent explicitly these latent space transition operators that would dictate the dynamics of all these variables. What we really need are agents that have a kind of structured core ontology that it needs to maintain. And that's where empowerment will eventually come in.	Real world organisms and humans live in a high dimensional world	Planning an organism with a high-dimensional world
470272	524106	07:50	A state time feasibility function is an abstraction that's going to map us from initial state times to final state times. This will have some really nice properties that allow us to sort of reason in this high dimensional state space. I'm going to talk about this from just a dynamic programming point of view.	State time feasibility function can help us reason in dynamic programming	State-time feasibility functions
524208	848174	08:44	So let's just talk about transition operator composition. Imagine that you have PX, which is like a base state space to move around the world, and you have some internal state space or secondary state space PY. The effective state space exponentiates as you add on more state spaces that you can control.	So let's just talk about transition operator composition, because I said	Importance of product space operator composition
848302	1755652	14:08	State time feasibility function being the representation that I'm arguing for in this talk. If all of these sort of goal variables on the way to the lake are sort of the null goal variables, then you can define that as a Markov chain. You can build a jump operator that jumps you from your initial high dimensional state.	State time feasibility function is the representation that I'm arguing for in this talk	State Time Feasibility Functions
1755786	2644580	29:15	Empowerment is an intrinsic motivation metric which sort of represents controllability. It's formally defined as the Shannon channel capacity between your actuators or sequences of actions that you take and the resulting states. This is the object from the previous slides that sort of map us around the world.	The state time feasibility function says given that I start at X and T	Inertial Motivation Feasibility and the State Time
2646870	3075370	44:06	Empowerment is also a function of a transition operator. So if the structure of the world were different, then the feasibility functions that I could compute in different configurations would be different. And so that's a deep connection between Bellman equations and these intrinsic motivation metrics.	Bellman equations produce transition operators so we can compute their empowerment	Introspective motivation metrics and Bellman Equations
3077070	3308550	51:17	 intelligent systems operate in high dimensional product spaces, often with non stationary dynamics. Valence unifies a lot of distinct drives. It doesn't have to be multi objective with empowerment. And valence depends on the structure of the environment.	Intelligent systems operate in high dimensional product spaces, often with non stationary dynamics	Intelligent Systems with High-Dimensional Product Spaces
3309610	3429130	55:09	The idea that an organism could be organized around realizing something which is sort of virtual. Teleodynamics is the dynamical realization of final causality. It's a consequence organized dynamic that is its own consequence. And I think that's relevant to what I'm doing here.	Terrence Deakin wrote a lot about teleology from a thermodynamic perspective	Teleology, the science of nature
3429790	3476620	57:09	I'm very interested in what active inference theorists think about the potential for a sort of integrated view of empowerment. Those who are watching live, please feel free to add questions in the live chat.	I'm very interested in what active inference theorists think about empowerment	Active Inference Institute Live Chat
3478430	3519180	57:58	How did you come to this area of research? What brought you to control theory modeling and to the empowerment perspective specifically? Hold on, I'm just bringing up the YouTube stream so I can see comments. Mute that one.	How did you come to this area of research	Control Theory and the Empowerment Perspective
3520030	3665046	58:40	I've always been interested in how could animals interact in a world in a way that's so sample efficient. Another big influence was a guy named Nishith Srivastava who wrote an interesting paper about relativistic decision theory. How could you bring those kinds of intuitions into embodied planning?	I've always been interested in how animals interact in a world	In the Land of Empowerment
3665228	3807080	1:01:05	In my paper, reward is not necessary. Why the honey badger? My advisor showed me a YouTube video of a honeybadger named Staffel. It got me thinking, what is a good general intrinsic motivation function? And for mobile creatures, that's quite a good proxy for what we might want to care about, like living.	My advisor showed me a YouTube video of a honey badger named Staffel	Intro to Badger Motivation
3808330	3996850	1:03:28	The idea is that actual agent environment coupling figures in computing empowerment. Is there a fully internal proxy that can be optimized given information available internally? What about the desire to think freely and to move in cognitive spaces broadly?	Real agent environment coupling figures in computing empowerment, right? If so	Cognitive empowerment and the agent environment
4000970	4189090	1:06:40	You mentioned the generative model of active inference but you took a different approach there's, different model ontology. How would you structurally contrast the coupling of the agent and the environment in active inference and in what you've proposed?	How would you structurally contrast coupling between agent and environment in active inference	Inactive Inference vs. Generative Inference
4192470	4320460	1:09:52	How does it come to understand that this shiny object unlocks that door? How would you take a key and learn exactly how it's changing the dynamics? These preferences for various objects like a key or a dollar bill or things like this can sort of be stored and maybe models with utility theory.	You mentioned the key being obtained as inducing this change in the agent's ontology	Exploring the Dynamics of the Key
4321250	4457640	1:12:01	Empowerment is a Shannon information theoretic channel capacity between the actuators and the realization of the state. The channel capacity is the maximum possible mutual information between the actions you choose and the resulting states. It's very useful because it also leads to explainable AI.	Shannon channel capacity describes the information transfer between actuators and state	Shannon Channel Capacity and Empowerment
4458430	4944736	1:14:18	Is there any risk of an imperative that features its own empowerment in terms of an AI being able to then select action policies that might not be what anyone else expects or prefers? There's a lot of interesting work to do on multi agent empowerment.	You mentioned the AI topic, and is there any risk of an imperative	Is the Bellman Equation Secure?
4944928	5037940	1:22:24	There's this concept in RL called the successor representation which is often a hot topic in computational neuroscience. What it represents is expected state Occupancies under a policy. These are weighted by the discount factor. This makes them reusable composable.	There's a concept in RL called the successor representation	In the realm of RL, the successor representation
5038360	5393412	1:23:58	Gwen Carlo: To overcome the burden of a product space, you need to do local computations on individual state spaces in a sort of network of interconnected state spaces. And the act of composing or bringing new information in is expanding the implicit product space. From an RL standpoint, it's not so clear what a reward function on that product space is even supposed to be.	And I think you asked me about the decomposition and this decomposition	The burden of a product space
5393546	5713070	1:29:53	Is reward sufficient? I think that the reward enough hypothesis can account for all sort of artificial and sort of natural intelligence. But I don't think RL will rise to the challenge of being able to justify motivations in real time in a way that humans can.	Is reward sufficient for intelligence or what is necessary for what	Is Reward Enough for Natural Intelligence?
5714000	6216924	1:35:14	Expected free energy functional is predicated around helping the agent select policies that over expected futures. That ties active inference closely with perceptual control theory. There could be an interface between the two concepts. Could be a dual process in which the action side, the internal controllability side is dictating what kinds of generative models should be considered.	You discuss possible relationships between models of generative inference and active inference	Incendiary Inference and Active Inference
6217042	6275650	1:43:37	Can time be continuous, or is time always discrete, and is it finite or infinite? A so the operator Bellman equations are formalized as a finite horizon. I suppose they could be extended to infinite horizon and infinite or continuous time.	I guess one more question on the model and then we'll close	The Bellman Equations and their time horizon
6278590	6357380	1:44:38	I'm interested in getting this work into computational neuroscience problem. On the AI side, I want to put this in a world model. So I have a lot of work to do.	You're interested in getting this work into computational neuroscience problem	Computational Neuroscience and the Future of AI
6358470	6504100	1:45:58	Thomas: Galileo may have gotten in trouble less from insisting on a heliocentric universe than from insisting that purpose, value, and meaning be banished from science as connecting explanatory principles. Thomas, thank you again for joining the discord and really looking forward to seeing how this all continues.	Thomas Sutter: I like the discord. Everyone's very nice and enthusiastic	Active Inference Community
6504550	6512670	1:48:24	Excellent. All right, till next time. Great. Thank you. Bye.	Excellent. Great. Thank you. All right, till next time	BUSINESS SPOILER
