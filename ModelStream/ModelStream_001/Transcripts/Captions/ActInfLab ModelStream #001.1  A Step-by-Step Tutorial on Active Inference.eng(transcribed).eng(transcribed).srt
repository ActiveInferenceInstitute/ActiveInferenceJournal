1
00:00:07,279 --> 00:00:08,480
hello everyone

2
00:00:08,480 --> 00:00:11,599
welcome to the active inference lab this

3
00:00:11,599 --> 00:00:14,000
is the first active inference model

4
00:00:14,000 --> 00:00:17,039
stream active inference model stream 1.0

5
00:00:17,039 --> 00:00:19,039
and i'm really excited for today's

6
00:00:19,039 --> 00:00:20,400
conversation i'm

7
00:00:20,400 --> 00:00:22,880
daniel friedman and just to introduce

8
00:00:22,880 --> 00:00:24,960
the other participants today

9
00:00:24,960 --> 00:00:28,000
uh ryan go for it uh yep

10
00:00:28,000 --> 00:00:31,119
hi i'm uh ryan uh i'm from the florida

11
00:00:31,119 --> 00:00:34,160
institute of brain research

12
00:00:34,480 --> 00:00:37,120
hi i'm christopher i'm a phd student at

13
00:00:37,120 --> 00:00:37,840
the mrc

14
00:00:37,840 --> 00:00:39,440
cognition brain sciences unit which is

15
00:00:39,440 --> 00:00:42,960
based at the university of cambridge

16
00:00:42,960 --> 00:00:46,640
hi i'm max murphy i just completed my

17
00:00:46,640 --> 00:00:49,280
phd at university of kansas in

18
00:00:49,280 --> 00:00:50,480
bioengineering

19
00:00:50,480 --> 00:00:53,280
uh with a focus on neural engineering

20
00:00:53,280 --> 00:00:54,000
awesome

21
00:00:54,000 --> 00:00:56,399
thank you everyone for participating and

22
00:00:56,399 --> 00:00:57,680
for ryan and christopher

23
00:00:57,680 --> 00:01:00,079
two of the authors of this awesome work

24
00:01:00,079 --> 00:01:01,760
we're going to be exploring

25
00:01:01,760 --> 00:01:04,799
so this is the first in a several part

26
00:01:04,799 --> 00:01:07,119
series that is going to be highlighting

27
00:01:07,119 --> 00:01:08,560
several perspectives and

28
00:01:08,560 --> 00:01:10,799
addressing questions related to the

29
00:01:10,799 --> 00:01:12,960
active inference tutorial paper

30
00:01:12,960 --> 00:01:15,520
of smith at all called a step-by-step

31
00:01:15,520 --> 00:01:16,240
tutorial

32
00:01:16,240 --> 00:01:18,400
on active inference and its applications

33
00:01:18,400 --> 00:01:20,080
to empirical data

34
00:01:20,080 --> 00:01:22,720
so the idea here is for those who are

35
00:01:22,720 --> 00:01:24,479
working with empirical data

36
00:01:24,479 --> 00:01:26,400
to learn about active inference as a

37
00:01:26,400 --> 00:01:28,479
method and also for those in the active

38
00:01:28,479 --> 00:01:30,320
inference community to be learning about

39
00:01:30,320 --> 00:01:31,840
some of the methods that apply

40
00:01:31,840 --> 00:01:34,640
active inference if you're listening

41
00:01:34,640 --> 00:01:36,079
you're participating

42
00:01:36,079 --> 00:01:37,920
and if you have any questions during the

43
00:01:37,920 --> 00:01:40,000
live stream feel free to post it

44
00:01:40,000 --> 00:01:42,320
in the youtube live chat and we'll try

45
00:01:42,320 --> 00:01:43,439
to address it during

46
00:01:43,439 --> 00:01:46,320
or after this presentation that we're

47
00:01:46,320 --> 00:01:47,520
about to get

48
00:01:47,520 --> 00:01:49,600
if you have questions after the live

49
00:01:49,600 --> 00:01:52,079
stream please feel free to leave it

50
00:01:52,079 --> 00:01:54,560
in a comment form and we'll try to

51
00:01:54,560 --> 00:01:55,439
address it

52
00:01:55,439 --> 00:01:58,000
and integrate your input in future

53
00:01:58,000 --> 00:01:58,880
sessions

54
00:01:58,880 --> 00:02:01,280
and to learn more and to participate

55
00:02:01,280 --> 00:02:03,759
check out activeinference.org or any of

56
00:02:03,759 --> 00:02:05,119
the information in the video's

57
00:02:05,119 --> 00:02:06,000
description

58
00:02:06,000 --> 00:02:08,239
so that's all the information uh or

59
00:02:08,239 --> 00:02:10,160
metadata for this video

60
00:02:10,160 --> 00:02:12,000
the way this is gonna work today is

61
00:02:12,000 --> 00:02:14,080
we're going to do some introductory

62
00:02:14,080 --> 00:02:16,879
questions uh just sort of like asking

63
00:02:16,879 --> 00:02:18,720
what in general is this work about

64
00:02:18,720 --> 00:02:20,640
what motivated the authors to write the

65
00:02:20,640 --> 00:02:22,319
paper the way that they did

66
00:02:22,319 --> 00:02:24,640
and then both ryan and christopher are

67
00:02:24,640 --> 00:02:26,319
going to share their screens

68
00:02:26,319 --> 00:02:28,239
for part of the presentation and they're

69
00:02:28,239 --> 00:02:29,680
going to show us a few different things

70
00:02:29,680 --> 00:02:32,160
about the work that they've done and

71
00:02:32,160 --> 00:02:34,000
then we have a couple of questions

72
00:02:34,000 --> 00:02:35,519
prepared on our side

73
00:02:35,519 --> 00:02:37,360
but also we're going to be looking at a

74
00:02:37,360 --> 00:02:39,440
live chat if anyone has questions so

75
00:02:39,440 --> 00:02:40,560
just post it

76
00:02:40,560 --> 00:02:41,920
whenever you feel like it in the live

77
00:02:41,920 --> 00:02:44,080
chat and then we'll again try to address

78
00:02:44,080 --> 00:02:44,480
it

79
00:02:44,480 --> 00:02:47,280
so as i stated the intro questions and

80
00:02:47,280 --> 00:02:49,120
then we'll go to the presentations

81
00:02:49,120 --> 00:02:52,080
so first intro question to uh the

82
00:02:52,080 --> 00:02:52,640
authors

83
00:02:52,640 --> 00:02:55,360
is what is this work what is exciting

84
00:02:55,360 --> 00:02:56,400
about it what

85
00:02:56,400 --> 00:03:00,159
motivated you to work on it

86
00:03:00,319 --> 00:03:03,519
um okay so uh so just to kind of

87
00:03:03,519 --> 00:03:05,440
reintroduce myself a little bit more so

88
00:03:05,440 --> 00:03:08,959
i'm uh ryan smith so i'm an investigator

89
00:03:08,959 --> 00:03:10,560
at the laureate institute for brain

90
00:03:10,560 --> 00:03:12,959
research in tulsa oklahoma

91
00:03:12,959 --> 00:03:16,080
and the um the focus of our institute is

92
00:03:16,080 --> 00:03:19,440
um primarily on uh neuroimaging

93
00:03:19,440 --> 00:03:22,239
and sort of neuroscience approaches to

94
00:03:22,239 --> 00:03:23,280
understanding

95
00:03:23,280 --> 00:03:25,120
um psychology and psychiatry with a

96
00:03:25,120 --> 00:03:26,720
focus on sort of treating psychiatric

97
00:03:26,720 --> 00:03:27,760
disorders

98
00:03:27,760 --> 00:03:33,200
um and so for a while now there has been

99
00:03:33,200 --> 00:03:35,599
um the use of simpler computational

100
00:03:35,599 --> 00:03:36,319
models

101
00:03:36,319 --> 00:03:37,920
primarily reinforcement learning models

102
00:03:37,920 --> 00:03:39,519
or drift diffusion models things like

103
00:03:39,519 --> 00:03:40,400
that

104
00:03:40,400 --> 00:03:43,200
um out there for researchers for who are

105
00:03:43,200 --> 00:03:45,599
working with empirical data

106
00:03:45,599 --> 00:03:48,319
who so there are good resources out

107
00:03:48,319 --> 00:03:50,640
there for people to learn those methods

108
00:03:50,640 --> 00:03:52,959
um to apply them to data in their own

109
00:03:52,959 --> 00:03:54,000
research

110
00:03:54,000 --> 00:03:55,760
um however at the moment so active

111
00:03:55,760 --> 00:03:58,400
inference is a sort of much newer field

112
00:03:58,400 --> 00:04:01,040
especially it's sort of a formulation in

113
00:04:01,040 --> 00:04:02,159
terms of uh

114
00:04:02,159 --> 00:04:03,680
partially observable markov decision

115
00:04:03,680 --> 00:04:05,920
processes and

116
00:04:05,920 --> 00:04:09,519
there isn't really to date a really

117
00:04:09,519 --> 00:04:13,120
clear sort of combined place

118
00:04:13,120 --> 00:04:15,920
to learn the sort of practical methods

119
00:04:15,920 --> 00:04:18,160
to um to build these sorts of models

120
00:04:18,160 --> 00:04:21,358
and um to then sort of apply them

121
00:04:21,358 --> 00:04:25,440
to uh task behavior in empirical studies

122
00:04:25,440 --> 00:04:27,840
um so the kind of motivation for this

123
00:04:27,840 --> 00:04:29,680
paper this tutorial

124
00:04:29,680 --> 00:04:33,280
was to allow somebody you know so new

125
00:04:33,280 --> 00:04:35,199
students or somebody who's sort of like

126
00:04:35,199 --> 00:04:36,320
an early

127
00:04:36,320 --> 00:04:38,400
earlier you know junior faculty things

128
00:04:38,400 --> 00:04:39,759
like that who wants to

129
00:04:39,759 --> 00:04:42,240
go in this direction to give them the

130
00:04:42,240 --> 00:04:45,759
resources they need to do that

131
00:04:45,919 --> 00:04:48,240
as easily as you know and as thoroughly

132
00:04:48,240 --> 00:04:49,440
as possible so

133
00:04:49,440 --> 00:04:52,960
even if you start out not really

134
00:04:52,960 --> 00:04:55,919
having any background in this stuff the

135
00:04:55,919 --> 00:04:56,880
hope was

136
00:04:56,880 --> 00:04:58,720
that you know the the first section of

137
00:04:58,720 --> 00:05:00,320
the paper would

138
00:05:00,320 --> 00:05:01,600
allow you to kind of get enough of a

139
00:05:01,600 --> 00:05:04,320
background in theory

140
00:05:04,320 --> 00:05:06,240
such that you would understand how to

141
00:05:06,240 --> 00:05:08,639
then learn how to build these models

142
00:05:08,639 --> 00:05:10,880
specifically for empirical tasks and

143
00:05:10,880 --> 00:05:12,080
eventually

144
00:05:12,080 --> 00:05:14,720
to learn how to fit those models to uh

145
00:05:14,720 --> 00:05:15,919
to data

146
00:05:15,919 --> 00:05:17,759
um so that they could be used in your

147
00:05:17,759 --> 00:05:19,039
own sort of research

148
00:05:19,039 --> 00:05:21,840
um you know even you know for across

149
00:05:21,840 --> 00:05:22,840
many different

150
00:05:22,840 --> 00:05:25,039
fields so i would say what's what's

151
00:05:25,039 --> 00:05:26,479
exciting or motivating is

152
00:05:26,479 --> 00:05:29,039
is primarily just that if you're a new

153
00:05:29,039 --> 00:05:30,720
researcher and you're interested in this

154
00:05:30,720 --> 00:05:32,800
but you don't know how to do it

155
00:05:32,800 --> 00:05:34,320
you know the hope is is kind of going to

156
00:05:34,320 --> 00:05:36,080
be like a one-stop shop where if you can

157
00:05:36,080 --> 00:05:38,000
get beginning to end then you'll

158
00:05:38,000 --> 00:05:39,520
know how to do what you need to do to

159
00:05:39,520 --> 00:05:41,520
start using it in your own research

160
00:05:41,520 --> 00:05:43,680
so that's the major driving uh

161
00:05:43,680 --> 00:05:45,440
motivation

162
00:05:45,440 --> 00:05:48,800
awesome i love that one stop shop for a

163
00:05:48,800 --> 00:05:50,400
researcher who wants to apply the

164
00:05:50,400 --> 00:05:52,160
methods but doesn't really know

165
00:05:52,160 --> 00:05:53,840
where to start so that's really a great

166
00:05:53,840 --> 00:05:55,360
idea and

167
00:05:55,360 --> 00:05:57,759
you have version the document many times

168
00:05:57,759 --> 00:05:58,479
to really

169
00:05:58,479 --> 00:06:00,160
address people's input so it's cool how

170
00:06:00,160 --> 00:06:01,919
it's an evolving document as well

171
00:06:01,919 --> 00:06:03,680
so christopher what would you say in

172
00:06:03,680 --> 00:06:04,960
response to those

173
00:06:04,960 --> 00:06:09,120
intro questions um

174
00:06:09,120 --> 00:06:11,600
so i think there are two parts of my

175
00:06:11,600 --> 00:06:13,039
motivation for writing this the first

176
00:06:13,039 --> 00:06:14,639
was the selfish motivation in that i

177
00:06:14,639 --> 00:06:14,960
think

178
00:06:14,960 --> 00:06:16,880
if you want to understand something the

179
00:06:16,880 --> 00:06:18,400
best way to do it is actually to write a

180
00:06:18,400 --> 00:06:20,639
tutorial on it

181
00:06:20,639 --> 00:06:23,520
and so in when ryan asked me to do this

182
00:06:23,520 --> 00:06:24,479
tutorial with him

183
00:06:24,479 --> 00:06:26,240
i was jumped at the opportunity just

184
00:06:26,240 --> 00:06:27,360
because it would be an opportunity to

185
00:06:27,360 --> 00:06:28,880
kind of

186
00:06:28,880 --> 00:06:32,000
actually learn this stuff better myself

187
00:06:32,000 --> 00:06:33,520
and really get into some of the more

188
00:06:33,520 --> 00:06:35,280
technical details

189
00:06:35,280 --> 00:06:37,360
um and so then more broadly speaking

190
00:06:37,360 --> 00:06:39,199
though

191
00:06:39,199 --> 00:06:41,360
i think there are lots if in principle

192
00:06:41,360 --> 00:06:43,600
there's nothing kind of

193
00:06:43,600 --> 00:06:45,120
applying these models in practice is no

194
00:06:45,120 --> 00:06:46,240
more complicated than doing like

195
00:06:46,240 --> 00:06:48,080
model-based reinforcement learning

196
00:06:48,080 --> 00:06:50,560
and yet it's incredibly more common to

197
00:06:50,560 --> 00:06:52,160
see researchers working with

198
00:06:52,160 --> 00:06:55,039
various more sophisticated rl schemes

199
00:06:55,039 --> 00:06:55,759
and i think

200
00:06:55,759 --> 00:06:57,520
if you are a graduate student maybe

201
00:06:57,520 --> 00:06:59,280
starting in psychology or neuroscience

202
00:06:59,280 --> 00:07:00,080
you're like hey i'm

203
00:07:00,080 --> 00:07:02,160
interested in whatever it is uh decision

204
00:07:02,160 --> 00:07:03,840
making under uncertainty

205
00:07:03,840 --> 00:07:06,639
and i mean we have a finite time in this

206
00:07:06,639 --> 00:07:08,000
earth right and a fine amount of time to

207
00:07:08,000 --> 00:07:08,560
actually

208
00:07:08,560 --> 00:07:10,880
dedicate into learning things and so i

209
00:07:10,880 --> 00:07:12,319
think it would be perfectly rational if

210
00:07:12,319 --> 00:07:14,080
it's someone to look at active inference

211
00:07:14,080 --> 00:07:14,560
research

212
00:07:14,560 --> 00:07:16,720
like wow this is super technical i wish

213
00:07:16,720 --> 00:07:18,160
i could learn it but here's this other

214
00:07:18,160 --> 00:07:19,919
thing where i can go on euromatch i can

215
00:07:19,919 --> 00:07:21,759
read sutton and barto

216
00:07:21,759 --> 00:07:23,840
and really totally get up scratch and

217
00:07:23,840 --> 00:07:25,759
use my research fairly easily

218
00:07:25,759 --> 00:07:28,720
and there just wasn't something really

219
00:07:28,720 --> 00:07:29,520
accessible

220
00:07:29,520 --> 00:07:30,960
to help people actually apply in their

221
00:07:30,960 --> 00:07:33,039
own research um so that was kind of my

222
00:07:33,039 --> 00:07:36,160
yeah yeah i mean i should say just as a

223
00:07:36,160 --> 00:07:37,520
little background you know when i wanted

224
00:07:37,520 --> 00:07:38,880
to learn this stuff

225
00:07:38,880 --> 00:07:40,960
originally at the end of my postdoc

226
00:07:40,960 --> 00:07:42,000
before i took my current

227
00:07:42,000 --> 00:07:45,440
faculty position um i the only way to do

228
00:07:45,440 --> 00:07:45,759
it

229
00:07:45,759 --> 00:07:47,360
the only way that i could learn it was

230
00:07:47,360 --> 00:07:49,360
actually to go you know hang out at the

231
00:07:49,360 --> 00:07:49,759
phil

232
00:07:49,759 --> 00:07:51,440
in london with carl for about four

233
00:07:51,440 --> 00:07:52,879
months um

234
00:07:52,879 --> 00:07:54,800
and you know just ask people a ton of

235
00:07:54,800 --> 00:07:56,319
questions and

236
00:07:56,319 --> 00:07:58,319
sit there and that was the only way you

237
00:07:58,319 --> 00:08:00,160
know so without having to

238
00:08:00,160 --> 00:08:03,120
you know physically go to uh one

239
00:08:03,120 --> 00:08:04,800
location in the world i was very far

240
00:08:04,800 --> 00:08:06,240
away from you know my current

241
00:08:06,240 --> 00:08:07,280
institution

242
00:08:07,280 --> 00:08:08,639
and without doing that there really was

243
00:08:08,639 --> 00:08:11,120
no way for me to do it so i mean this is

244
00:08:11,120 --> 00:08:14,319
sort of a out of empathy for my past

245
00:08:14,319 --> 00:08:15,520
self

246
00:08:15,520 --> 00:08:16,800
that you know this is the sort of thing

247
00:08:16,800 --> 00:08:18,879
i wish i would have had available to me

248
00:08:18,879 --> 00:08:19,840
so i could learn this stuff

249
00:08:19,840 --> 00:08:21,599
independently

250
00:08:21,599 --> 00:08:25,039
cool so max um what is your

251
00:08:25,039 --> 00:08:26,639
background or what got you really

252
00:08:26,639 --> 00:08:29,039
excited to work through the paper and

253
00:08:29,039 --> 00:08:31,199
develop a lot of the examples out on

254
00:08:31,199 --> 00:08:33,200
your own um computer and everything so

255
00:08:33,200 --> 00:08:34,880
what what got you excited or where are

256
00:08:34,880 --> 00:08:36,880
you coming from today

257
00:08:36,880 --> 00:08:40,159
sure um yeah so uh maybe i'm kind of

258
00:08:40,159 --> 00:08:42,640
your target demographic in some sense

259
00:08:42,640 --> 00:08:44,399
uh i don't know that i could really be

260
00:08:44,399 --> 00:08:45,839
considered a junior investigator

261
00:08:45,839 --> 00:08:48,160
although i hope i could someday be that

262
00:08:48,160 --> 00:08:51,200
um and i'm interested in um i'm much

263
00:08:51,200 --> 00:08:51,920
more on the

264
00:08:51,920 --> 00:08:53,839
the motor motor system side of

265
00:08:53,839 --> 00:08:55,519
neuroscience as opposed to the decision

266
00:08:55,519 --> 00:08:56,640
making so this

267
00:08:56,640 --> 00:09:00,000
just the whole um lexicon it's a little

268
00:09:00,000 --> 00:09:00,560
different

269
00:09:00,560 --> 00:09:03,040
but i am seeing so many commonalities

270
00:09:03,040 --> 00:09:04,880
when i'm coming from a signal processing

271
00:09:04,880 --> 00:09:06,480
background i think of things

272
00:09:06,480 --> 00:09:09,279
um in terms of kalman formulation and

273
00:09:09,279 --> 00:09:10,800
trying to integrate sensory and motor

274
00:09:10,800 --> 00:09:12,480
information i see a lot of similarities

275
00:09:12,480 --> 00:09:14,080
there and so for somebody like

276
00:09:14,080 --> 00:09:16,080
myself then looking at some of fristen's

277
00:09:16,080 --> 00:09:17,519
work and seeing how

278
00:09:17,519 --> 00:09:20,000
he's described you know the the anatomy

279
00:09:20,000 --> 00:09:20,880
of uh

280
00:09:20,880 --> 00:09:23,200
inference and could this apply also in

281
00:09:23,200 --> 00:09:25,360
motor systems

282
00:09:25,360 --> 00:09:27,279
i'm very interested to see how this

283
00:09:27,279 --> 00:09:28,720
might apply in my

284
00:09:28,720 --> 00:09:31,760
own future research and work

285
00:09:31,760 --> 00:09:34,080
cool so let's just say that you were

286
00:09:34,080 --> 00:09:35,040
speaking

287
00:09:35,040 --> 00:09:37,680
ryan first and then christopher to that

288
00:09:37,680 --> 00:09:38,480
early

289
00:09:38,480 --> 00:09:41,200
investigator researcher of any age who

290
00:09:41,200 --> 00:09:42,080
is like okay

291
00:09:42,080 --> 00:09:44,720
i get it um in reinforcement learning

292
00:09:44,720 --> 00:09:46,959
it's about reward or reward-centric

293
00:09:46,959 --> 00:09:48,480
learning is about reward

294
00:09:48,480 --> 00:09:51,200
what is active inference how is it

295
00:09:51,200 --> 00:09:52,160
taking a different

296
00:09:52,160 --> 00:09:54,399
perspective on what it is that organisms

297
00:09:54,399 --> 00:09:55,600
are doing than

298
00:09:55,600 --> 00:09:58,399
that kind of classical account of reward

299
00:09:58,399 --> 00:09:59,920
based learning for example or whatever

300
00:09:59,920 --> 00:10:01,600
you'd like to contrast it with

301
00:10:01,600 --> 00:10:04,079
but what is the bridge from the kind of

302
00:10:04,079 --> 00:10:04,959
assumptions

303
00:10:04,959 --> 00:10:07,200
and implications that lead somebody to

304
00:10:07,200 --> 00:10:09,040
work on that classical framing

305
00:10:09,040 --> 00:10:11,440
versus what is the um difference in

306
00:10:11,440 --> 00:10:13,120
thinking that is active inference and

307
00:10:13,120 --> 00:10:16,320
how is that manifested in the model

308
00:10:16,320 --> 00:10:18,640
so i think this is actually a really

309
00:10:18,640 --> 00:10:20,000
important thing to bring up right from

310
00:10:20,000 --> 00:10:20,560
the start

311
00:10:20,560 --> 00:10:22,560
is that so there's a there's a kind of

312
00:10:22,560 --> 00:10:24,240
big distinction between

313
00:10:24,240 --> 00:10:26,560
um when people talk about the free

314
00:10:26,560 --> 00:10:28,399
energy principle broadly or the

315
00:10:28,399 --> 00:10:30,399
philosophy of the free energy principle

316
00:10:30,399 --> 00:10:33,120
and there's a very kind of uh you know

317
00:10:33,120 --> 00:10:35,519
somewhat wide chasm between that

318
00:10:35,519 --> 00:10:37,440
and what gets called active inference

319
00:10:37,440 --> 00:10:39,279
nowadays where active inference is a

320
00:10:39,279 --> 00:10:40,480
corollary

321
00:10:40,480 --> 00:10:43,760
of the free energy principle but um

322
00:10:43,760 --> 00:10:45,920
you know active inference as formulated

323
00:10:45,920 --> 00:10:47,760
in terms of partially observable

324
00:10:47,760 --> 00:10:49,440
partially observable markov decision

325
00:10:49,440 --> 00:10:51,040
processes is a

326
00:10:51,040 --> 00:10:52,800
quite a bit narrower right it's a very

327
00:10:52,800 --> 00:10:54,160
specific sort of

328
00:10:54,160 --> 00:10:57,760
discrete state-space generative model um

329
00:10:57,760 --> 00:10:59,200
and that has particular sorts of

330
00:10:59,200 --> 00:11:01,360
elements to it um

331
00:11:01,360 --> 00:11:04,720
and it it doesn't actually require

332
00:11:04,720 --> 00:11:06,399
knowing a lot of the things that people

333
00:11:06,399 --> 00:11:07,760
talk about with respect to the free

334
00:11:07,760 --> 00:11:09,760
energy principle more broadly

335
00:11:09,760 --> 00:11:13,120
um it appeals to um free energy and

336
00:11:13,120 --> 00:11:14,320
expected free energy

337
00:11:14,320 --> 00:11:17,440
as functions right as more or less cost

338
00:11:17,440 --> 00:11:18,640
functions for

339
00:11:18,640 --> 00:11:20,160
figuring out what the best choice to

340
00:11:20,160 --> 00:11:22,560
make is um

341
00:11:22,560 --> 00:11:24,800
and it but but at the end of the day i

342
00:11:24,800 --> 00:11:25,920
mean when you apply

343
00:11:25,920 --> 00:11:28,079
these sorts of models to behavioral

344
00:11:28,079 --> 00:11:30,800
tasks that they used in studies

345
00:11:30,800 --> 00:11:32,240
it's actually there's quite a bit of

346
00:11:32,240 --> 00:11:34,240
similarity i mean you can really see

347
00:11:34,240 --> 00:11:36,640
active inference models or at least the

348
00:11:36,640 --> 00:11:38,320
mdp formulation

349
00:11:38,320 --> 00:11:40,079
as as just a particular is kind of like

350
00:11:40,079 --> 00:11:42,320
what chris said is just a particular

351
00:11:42,320 --> 00:11:44,880
kind of flavor almost of model based

352
00:11:44,880 --> 00:11:46,240
reinforcement learning

353
00:11:46,240 --> 00:11:48,720
um you know so instead of i mean there's

354
00:11:48,720 --> 00:11:49,839
there's some sort of technical

355
00:11:49,839 --> 00:11:50,480
differences

356
00:11:50,480 --> 00:11:53,440
right where um the way that sort of carl

357
00:11:53,440 --> 00:11:56,000
and them have set it up

358
00:11:56,000 --> 00:11:58,320
what you're doing is kind of like it

359
00:11:58,320 --> 00:12:00,160
allows for kind of a fully unified

360
00:12:00,160 --> 00:12:03,440
bayesian way of doing

361
00:12:03,440 --> 00:12:05,440
reinforcement learning and decision

362
00:12:05,440 --> 00:12:07,600
making processes

363
00:12:07,600 --> 00:12:10,320
and you do that by instead of calling

364
00:12:10,320 --> 00:12:10,959
something

365
00:12:10,959 --> 00:12:13,200
a reward per se you define this

366
00:12:13,200 --> 00:12:14,720
probability distribution

367
00:12:14,720 --> 00:12:17,760
over observations that gets called a

368
00:12:17,760 --> 00:12:20,079
preference distribution

369
00:12:20,079 --> 00:12:23,519
and so reward then becomes a kind of

370
00:12:23,519 --> 00:12:25,040
probabilistic preference

371
00:12:25,040 --> 00:12:28,000
to observe some things over others um

372
00:12:28,000 --> 00:12:29,360
you know so if you call

373
00:12:29,360 --> 00:12:32,720
a particular observation a reward um

374
00:12:32,720 --> 00:12:35,360
then calling it a roar just amounts to

375
00:12:35,360 --> 00:12:36,000
having a

376
00:12:36,000 --> 00:12:39,120
precise preference distribution that has

377
00:12:39,120 --> 00:12:41,680
a precise

378
00:12:41,680 --> 00:12:44,160
high value over whatever that rewarding

379
00:12:44,160 --> 00:12:45,920
outcome is

380
00:12:45,920 --> 00:12:47,920
and then the agent is simply driven to

381
00:12:47,920 --> 00:12:49,839
make decisions that it thinks is most

382
00:12:49,839 --> 00:12:50,639
likely

383
00:12:50,639 --> 00:12:52,720
to get it to observe the thing it

384
00:12:52,720 --> 00:12:53,839
prefers

385
00:12:53,839 --> 00:12:55,519
right so this preference distribution is

386
00:12:55,519 --> 00:12:57,680
more or less a way of specifying what is

387
00:12:57,680 --> 00:12:59,680
rewarding to the agent right what the

388
00:12:59,680 --> 00:13:01,279
agent is seeking

389
00:13:01,279 --> 00:13:04,079
um one thing that is kind of nice about

390
00:13:04,079 --> 00:13:05,440
active inference that's a little

391
00:13:05,440 --> 00:13:06,399
different

392
00:13:06,399 --> 00:13:09,440
from reinforcement learning per se

393
00:13:09,440 --> 00:13:11,440
or there's a few things i should say one

394
00:13:11,440 --> 00:13:14,480
is that um

395
00:13:14,639 --> 00:13:16,639
making decisions based on trying to

396
00:13:16,639 --> 00:13:18,399
minimize expected free energy which

397
00:13:18,399 --> 00:13:20,959
chris will cover

398
00:13:20,959 --> 00:13:25,279
doesn't just try to maximize reward

399
00:13:25,279 --> 00:13:27,839
it also simultaneously tries to maximize

400
00:13:27,839 --> 00:13:30,399
information gain

401
00:13:30,399 --> 00:13:33,519
so so what will happen is you know say

402
00:13:33,519 --> 00:13:35,600
say an agent starts out in a dark room

403
00:13:35,600 --> 00:13:37,040
you know just to take a very kind of

404
00:13:37,040 --> 00:13:38,000
contentious

405
00:13:38,000 --> 00:13:40,399
you know philosophy of the fep sort of

406
00:13:40,399 --> 00:13:41,519
example

407
00:13:41,519 --> 00:13:43,680
right say an agent starts out in a dark

408
00:13:43,680 --> 00:13:45,040
room um

409
00:13:45,040 --> 00:13:47,040
which means that it doesn't know where

410
00:13:47,040 --> 00:13:48,240
anything is

411
00:13:48,240 --> 00:13:50,000
right so that means it has a lot of

412
00:13:50,000 --> 00:13:52,000
uncertainty over what state it's in

413
00:13:52,000 --> 00:13:54,639
um and let's say simultaneously in

414
00:13:54,639 --> 00:13:55,680
another room

415
00:13:55,680 --> 00:13:58,959
there's a fridge with some food in it um

416
00:13:58,959 --> 00:14:00,720
then there will be two different sorts

417
00:14:00,720 --> 00:14:02,320
of drives there right there'll be this

418
00:14:02,320 --> 00:14:03,360
epistemic drive

419
00:14:03,360 --> 00:14:05,519
to do whatever it thinks is gonna give

420
00:14:05,519 --> 00:14:07,440
it the most information gain

421
00:14:07,440 --> 00:14:10,079
right which will be go turn on the light

422
00:14:10,079 --> 00:14:11,600
right so then it'll know

423
00:14:11,600 --> 00:14:13,680
what state it's in right whether it's in

424
00:14:13,680 --> 00:14:14,959
room a or room b

425
00:14:14,959 --> 00:14:16,480
right or whether there's a couch in the

426
00:14:16,480 --> 00:14:18,079
room or whether there's a

427
00:14:18,079 --> 00:14:21,040
tv in the room or whatever right um and

428
00:14:21,040 --> 00:14:22,160
that's not

429
00:14:22,160 --> 00:14:25,199
reward per se that's just trying to make

430
00:14:25,199 --> 00:14:25,760
the app

431
00:14:25,760 --> 00:14:26,959
choose the action that's going to

432
00:14:26,959 --> 00:14:28,639
maximize the amount of information you

433
00:14:28,639 --> 00:14:30,639
get

434
00:14:30,639 --> 00:14:32,720
the other the other chunk of it though

435
00:14:32,720 --> 00:14:34,240
is to maximize

436
00:14:34,240 --> 00:14:37,040
observing preferred outcomes and so the

437
00:14:37,040 --> 00:14:38,959
agent will also be driven to just leave

438
00:14:38,959 --> 00:14:39,839
the room

439
00:14:39,839 --> 00:14:42,000
to go to the fridge you know to observe

440
00:14:42,000 --> 00:14:44,480
itself eating food um

441
00:14:44,480 --> 00:14:46,399
you know so in practice what will happen

442
00:14:46,399 --> 00:14:47,839
that typically won't happen

443
00:14:47,839 --> 00:14:50,160
at least in a standard reinforcement

444
00:14:50,160 --> 00:14:51,839
learning setting

445
00:14:51,839 --> 00:14:53,839
is that the agent won't just try to

446
00:14:53,839 --> 00:14:55,360
maximize reward directly

447
00:14:55,360 --> 00:14:57,440
a lot of times it will first choose the

448
00:14:57,440 --> 00:14:58,480
action that will

449
00:14:58,480 --> 00:15:00,720
help it figure out where it is so that

450
00:15:00,720 --> 00:15:02,639
it's more confident what to do

451
00:15:02,639 --> 00:15:06,160
to get the reward later so

452
00:15:06,160 --> 00:15:09,199
so it's so it's really not again in

453
00:15:09,199 --> 00:15:10,959
practice these models are

454
00:15:10,959 --> 00:15:13,440
are just a nice fully bayesian way to

455
00:15:13,440 --> 00:15:14,480
integrate

456
00:15:14,480 --> 00:15:18,320
perception learning and decision making

457
00:15:18,320 --> 00:15:20,240
where decision making is driven to both

458
00:15:20,240 --> 00:15:22,079
maximize information gain and maximize

459
00:15:22,079 --> 00:15:24,240
reward

460
00:15:24,240 --> 00:15:26,399
christopher thanks a lot anything else

461
00:15:26,399 --> 00:15:28,320
to add there

462
00:15:28,320 --> 00:15:30,560
um no not particularly i i think the

463
00:15:30,560 --> 00:15:31,680
only thing i would say and i'm going to

464
00:15:31,680 --> 00:15:32,720
say this in a little bit

465
00:15:32,720 --> 00:15:34,560
on a slide is if you're interested in

466
00:15:34,560 --> 00:15:36,000
the technical details what ryan just

467
00:15:36,000 --> 00:15:37,920
said there are two really good papers

468
00:15:37,920 --> 00:15:39,600
um maybe we can make these slides

469
00:15:39,600 --> 00:15:41,279
available afterwards as well

470
00:15:41,279 --> 00:15:44,079
um one's by norsajid and i'm not sure if

471
00:15:44,079 --> 00:15:44,800
i'm sorry if i'm

472
00:15:44,800 --> 00:15:46,720
butchered your name there um the other

473
00:15:46,720 --> 00:15:49,440
one's lancelot decosta

474
00:15:49,440 --> 00:15:50,800
and they have two excellent papers

475
00:15:50,800 --> 00:15:52,800
comparing it to reinforcement learning

476
00:15:52,800 --> 00:15:53,519
so

477
00:15:53,519 --> 00:15:57,040
formulations excellent um just to draw

478
00:15:57,040 --> 00:15:58,399
out a couple points

479
00:15:58,399 --> 00:16:01,199
ryan from what you said so one is that

480
00:16:01,199 --> 00:16:01,680
uh

481
00:16:01,680 --> 00:16:04,480
the active inference framework and

482
00:16:04,480 --> 00:16:05,680
specifically the

483
00:16:05,680 --> 00:16:08,959
po mdp the partially observable markov

484
00:16:08,959 --> 00:16:10,480
decision process

485
00:16:10,480 --> 00:16:12,959
instantiation of active inference is a

486
00:16:12,959 --> 00:16:13,920
corollary

487
00:16:13,920 --> 00:16:16,240
or like a derivative of the free energy

488
00:16:16,240 --> 00:16:17,040
principle

489
00:16:17,040 --> 00:16:18,720
and there's a lot of philosophy and

490
00:16:18,720 --> 00:16:20,480
contentiousness around different aspects

491
00:16:20,480 --> 00:16:22,480
of that we're going to read a paper in

492
00:16:22,480 --> 00:16:25,040
active inference stream 14 by mel

493
00:16:25,040 --> 00:16:26,399
andrews about

494
00:16:26,399 --> 00:16:28,240
the math is not the territory about the

495
00:16:28,240 --> 00:16:30,079
philosophy and the status so yes if you

496
00:16:30,079 --> 00:16:30,720
want to go

497
00:16:30,720 --> 00:16:32,320
that way there's a whole rabbit hole

498
00:16:32,320 --> 00:16:34,720
there but this is kind of like a tool

499
00:16:34,720 --> 00:16:36,240
like a linear regression

500
00:16:36,240 --> 00:16:38,079
you don't get caught up in the weeds on

501
00:16:38,079 --> 00:16:40,240
number theory or on the information

502
00:16:40,240 --> 00:16:41,519
space that it's about

503
00:16:41,519 --> 00:16:43,839
where the calculation is useful and

504
00:16:43,839 --> 00:16:44,560
tractable

505
00:16:44,560 --> 00:16:45,920
it's going to be a tool so that's kind

506
00:16:45,920 --> 00:16:47,600
of where we're coming at at least today

507
00:16:47,600 --> 00:16:50,399
and in this series another interesting

508
00:16:50,399 --> 00:16:50,800
thing

509
00:16:50,800 --> 00:16:53,279
and in contrast with reinforcement

510
00:16:53,279 --> 00:16:54,880
learning which is kind of like

511
00:16:54,880 --> 00:16:57,519
uh reinforce what works and don't

512
00:16:57,519 --> 00:16:59,360
reinforce what doesn't work that neurons

513
00:16:59,360 --> 00:17:01,040
that fire together wire together

514
00:17:01,040 --> 00:17:03,839
positive reinforcement schemes there is

515
00:17:03,839 --> 00:17:05,599
a reward preference built into that kind

516
00:17:05,599 --> 00:17:06,799
of model

517
00:17:06,799 --> 00:17:09,439
but when there's a basin of low reward

518
00:17:09,439 --> 00:17:11,199
it's often difficult for those models to

519
00:17:11,199 --> 00:17:11,919
latch on

520
00:17:11,919 --> 00:17:14,079
so we saw that in the paper of alec

521
00:17:14,079 --> 00:17:15,119
chance at all

522
00:17:15,119 --> 00:17:17,039
in active inference stream eight scaling

523
00:17:17,039 --> 00:17:18,160
active inference

524
00:17:18,160 --> 00:17:20,720
that kind of showed how even up against

525
00:17:20,720 --> 00:17:21,919
these very very

526
00:17:21,919 --> 00:17:24,880
large scale machine learning models like

527
00:17:24,880 --> 00:17:26,640
q reinforcement learning and things like

528
00:17:26,640 --> 00:17:27,359
that

529
00:17:27,359 --> 00:17:29,120
other state-of-the-art deep learning

530
00:17:29,120 --> 00:17:31,440
models that the active inference

531
00:17:31,440 --> 00:17:33,919
trolley car and control theory robots

532
00:17:33,919 --> 00:17:35,440
were able to work really well because

533
00:17:35,440 --> 00:17:36,880
first they did what you just described

534
00:17:36,880 --> 00:17:37,760
ryan which was

535
00:17:37,760 --> 00:17:40,960
they kind of went into an explore mode

536
00:17:40,960 --> 00:17:43,120
before going into a more fine-tuning

537
00:17:43,120 --> 00:17:45,280
mode and so in doing so they transcended

538
00:17:45,280 --> 00:17:46,080
the explore

539
00:17:46,080 --> 00:17:48,160
exploit simple trade-off it's not just a

540
00:17:48,160 --> 00:17:49,760
knob in this model

541
00:17:49,760 --> 00:17:51,120
it's not a coefficient to balance

542
00:17:51,120 --> 00:17:53,760
explore versus exploit i hope will draw

543
00:17:53,760 --> 00:17:55,520
out an understanding that they're

544
00:17:55,520 --> 00:17:57,600
actually related in a different way

545
00:17:57,600 --> 00:17:59,200
because there's something that's model

546
00:17:59,200 --> 00:18:01,520
based and generative that's happening

547
00:18:01,520 --> 00:18:02,240
and so

548
00:18:02,240 --> 00:18:05,200
really a ton of interesting stuff so at

549
00:18:05,200 --> 00:18:06,080
this point

550
00:18:06,080 --> 00:18:08,160
i would think we could go into the

551
00:18:08,160 --> 00:18:09,280
presentations

552
00:18:09,280 --> 00:18:11,840
if people have any questions that arise

553
00:18:11,840 --> 00:18:13,360
put them in the youtube chat and i'll be

554
00:18:13,360 --> 00:18:14,559
copying those out

555
00:18:14,559 --> 00:18:17,440
for addressing them later and um other

556
00:18:17,440 --> 00:18:18,960
than that let's just work through the

557
00:18:18,960 --> 00:18:20,240
presentations however

558
00:18:20,240 --> 00:18:22,160
ryan and christopher have set up and

559
00:18:22,160 --> 00:18:23,520
preferred

560
00:18:23,520 --> 00:18:25,520
cool okay go ahead and just share your

561
00:18:25,520 --> 00:18:27,280
screen chris you can just go ahead

562
00:18:27,280 --> 00:18:30,879
yeah it's like just kidding

563
00:18:30,960 --> 00:18:33,520
okay so i'm using a dual monitor setup

564
00:18:33,520 --> 00:18:34,960
we'll see how this goes

565
00:18:34,960 --> 00:18:37,280
um

566
00:18:41,360 --> 00:18:44,320
okay sorry i now have to open system

567
00:18:44,320 --> 00:18:45,280
preferences sorry

568
00:18:45,280 --> 00:18:48,720
to allow microsoft teams to use it sorry

569
00:18:48,720 --> 00:18:51,120
about that

570
00:18:54,840 --> 00:18:56,080
um

571
00:18:56,080 --> 00:19:02,240
okay should be with you momentarily

572
00:19:03,520 --> 00:19:05,760
cool

573
00:19:07,600 --> 00:19:11,520
good to digest really it's really

574
00:19:11,520 --> 00:19:13,440
it's interesting stuff and we're all

575
00:19:13,440 --> 00:19:14,559
learning by doing

576
00:19:14,559 --> 00:19:17,120
here so i just really appreciate and

577
00:19:17,120 --> 00:19:18,240
have just seen a lot of

578
00:19:18,240 --> 00:19:20,080
appreciation for this kind of work

579
00:19:20,080 --> 00:19:21,760
because in some ways it's like the

580
00:19:21,760 --> 00:19:22,400
missing

581
00:19:22,400 --> 00:19:25,200
piece between a lot of these

582
00:19:25,200 --> 00:19:27,760
hypothetical or abstract or scaffold

583
00:19:27,760 --> 00:19:28,640
models

584
00:19:28,640 --> 00:19:30,559
or what people have heard about with

585
00:19:30,559 --> 00:19:32,480
respect to what active inference is

586
00:19:32,480 --> 00:19:34,160
and then how it's deployed how it's

587
00:19:34,160 --> 00:19:36,320
enacted so to take the inactivist

588
00:19:36,320 --> 00:19:38,960
insight seriously as practitioners of

589
00:19:38,960 --> 00:19:40,160
science

590
00:19:40,160 --> 00:19:42,720
and as communicators as well it means

591
00:19:42,720 --> 00:19:44,640
making this kind of work and

592
00:19:44,640 --> 00:19:47,440
showing us how you do it as we all are

593
00:19:47,440 --> 00:19:48,320
trying to like

594
00:19:48,320 --> 00:19:50,400
figure out every level from literally

595
00:19:50,400 --> 00:19:52,320
the tech to

596
00:19:52,320 --> 00:19:54,880
the best way to make it rigorous and

597
00:19:54,880 --> 00:19:55,919
accessible

598
00:19:55,919 --> 00:19:58,799
the best ways to talk about it so yeah

599
00:19:58,799 --> 00:20:01,919
what what do you think about that ryan

600
00:20:01,919 --> 00:20:03,760
um yeah i mean i totally agree hold on

601
00:20:03,760 --> 00:20:04,960
to chris

602
00:20:04,960 --> 00:20:08,559
yeah actually i've never used um this

603
00:20:08,559 --> 00:20:10,000
there should be a little thing in the

604
00:20:10,000 --> 00:20:11,919
upright corner it's like an arrow

605
00:20:11,919 --> 00:20:16,080
pointing into us into like a square

606
00:20:16,559 --> 00:20:21,280
share content

607
00:20:21,280 --> 00:20:25,039
are you guys both on pcs yeah

608
00:20:25,039 --> 00:20:28,240
yeah okay so yeah so

609
00:20:28,240 --> 00:20:29,919
it should be upright corner like right

610
00:20:29,919 --> 00:20:33,360
next to the leave button

611
00:20:33,679 --> 00:20:37,760
okay um or ryan you could present

612
00:20:37,760 --> 00:20:41,600
first or yeah um

613
00:20:41,600 --> 00:20:43,280
i actually have a question i i have a

614
00:20:43,280 --> 00:20:44,559
question it will really work for me to

615
00:20:44,559 --> 00:20:46,240
present first i think i think

616
00:20:46,240 --> 00:20:48,080
you know yeah what i'm gonna do not

617
00:20:48,080 --> 00:20:49,919
gonna be so comprehensible before chris

618
00:20:49,919 --> 00:20:51,360
got it i actually have a question that

619
00:20:51,360 --> 00:20:52,880
will take a couple of minutes uh

620
00:20:52,880 --> 00:20:54,159
christopher while you're figuring it out

621
00:20:54,159 --> 00:20:54,960
is

622
00:20:54,960 --> 00:20:57,440
what tools would somebody need to follow

623
00:20:57,440 --> 00:20:58,000
along

624
00:20:58,000 --> 00:21:01,120
so what programming language or what

625
00:21:01,120 --> 00:21:02,080
interface

626
00:21:02,080 --> 00:21:04,720
do they need what background knowledge

627
00:21:04,720 --> 00:21:05,280
do they

628
00:21:05,280 --> 00:21:07,840
need is there a software to download is

629
00:21:07,840 --> 00:21:09,120
there a course

630
00:21:09,120 --> 00:21:11,520
what are the prerequisites for doing

631
00:21:11,520 --> 00:21:14,880
what we're about to basically jump into

632
00:21:14,880 --> 00:21:17,280
um yeah so i mean i'll just say that

633
00:21:17,280 --> 00:21:19,200
that you know a lot of this stuff was

634
00:21:19,200 --> 00:21:20,480
originally designed

635
00:21:20,480 --> 00:21:23,679
by carl fristen um and if you know

636
00:21:23,679 --> 00:21:26,960
a lot about carl um you know before he

637
00:21:26,960 --> 00:21:28,640
proposed a lot of this active inference

638
00:21:28,640 --> 00:21:30,000
stuff you know he

639
00:21:30,000 --> 00:21:33,440
was uh sort of most uh you know famous

640
00:21:33,440 --> 00:21:35,360
or his his biggest contribution was

641
00:21:35,360 --> 00:21:36,240
putting together

642
00:21:36,240 --> 00:21:40,480
uh sp spm within matlab spm is um

643
00:21:40,480 --> 00:21:42,480
like a it's called statistical

644
00:21:42,480 --> 00:21:44,960
parametric mapping software but it was

645
00:21:44,960 --> 00:21:48,159
more or less the original way of doing

646
00:21:48,159 --> 00:21:51,120
fmri so like analyzing functional and

647
00:21:51,120 --> 00:21:53,440
like neuroimaging data

648
00:21:53,440 --> 00:21:56,960
and so a lot of the scripts and dynamic

649
00:21:56,960 --> 00:21:58,400
puzzle modeling i should say which is a

650
00:21:58,400 --> 00:21:59,760
particular sort of approach to doing

651
00:21:59,760 --> 00:22:00,880
your imaging

652
00:22:00,880 --> 00:22:03,679
i mean so a lot of basically all the

653
00:22:03,679 --> 00:22:05,120
standard resources all the standard

654
00:22:05,120 --> 00:22:06,640
coding routines everything

655
00:22:06,640 --> 00:22:08,720
for actually building active inference

656
00:22:08,720 --> 00:22:10,240
models right now

657
00:22:10,240 --> 00:22:13,600
is primarily an spm which runs

658
00:22:13,600 --> 00:22:17,440
within matlab um so and all the

659
00:22:17,440 --> 00:22:20,080
kind of supplementary tutorial code that

660
00:22:20,080 --> 00:22:21,600
we've provided we've provided i think

661
00:22:21,600 --> 00:22:22,799
six

662
00:22:22,799 --> 00:22:25,679
six or seven different um different

663
00:22:25,679 --> 00:22:27,200
supplementary scripts

664
00:22:27,200 --> 00:22:28,240
where you can actually run the

665
00:22:28,240 --> 00:22:29,840
simulations and build these models

666
00:22:29,840 --> 00:22:31,919
yourself

667
00:22:31,919 --> 00:22:33,840
they are they are all they're all in

668
00:22:33,840 --> 00:22:35,679
matlab um

669
00:22:35,679 --> 00:22:38,080
so if you so if you have matlab then you

670
00:22:38,080 --> 00:22:40,320
need to have downloaded spm

671
00:22:40,320 --> 00:22:43,760
um and with matlab and spm you um

672
00:22:43,760 --> 00:22:45,440
you will have everything you need to do

673
00:22:45,440 --> 00:22:48,480
to open our supplementary code

674
00:22:48,480 --> 00:22:51,600
and to uh and to follow along so a lot

675
00:22:51,600 --> 00:22:54,080
of the tutorial is actually set up so

676
00:22:54,080 --> 00:22:56,400
it assumes that you're kind of have the

677
00:22:56,400 --> 00:22:57,200
paper open

678
00:22:57,200 --> 00:22:59,440
side by side with the code so you can

679
00:22:59,440 --> 00:23:01,280
actually click on

680
00:23:01,280 --> 00:23:03,120
you know different options to simulate

681
00:23:03,120 --> 00:23:04,960
and reproduce all the figures in the in

682
00:23:04,960 --> 00:23:07,440
the tutorial paper

683
00:23:07,440 --> 00:23:09,760
so it's uh yeah so the short answer is

684
00:23:09,760 --> 00:23:11,919
you need matlab and you need spm

685
00:23:11,919 --> 00:23:14,159
um thanks for that and you need to have

686
00:23:14,159 --> 00:23:15,360
some minimal

687
00:23:15,360 --> 00:23:18,559
ability to you know work with work with

688
00:23:18,559 --> 00:23:20,480
matlab

689
00:23:20,480 --> 00:23:22,799
just just to piggyback on to that for

690
00:23:22,799 --> 00:23:23,919
anybody's

691
00:23:23,919 --> 00:23:25,280
benefit watching this in the future

692
00:23:25,280 --> 00:23:28,000
whenever you're watching this uh

693
00:23:28,000 --> 00:23:30,400
once you get the spm folder you know

694
00:23:30,400 --> 00:23:32,559
you'll unzip that you'll get that folder

695
00:23:32,559 --> 00:23:33,679
you'll put that somewhere on your

696
00:23:33,679 --> 00:23:34,320
computer

697
00:23:34,320 --> 00:23:36,159
you'll want to make sure that you add

698
00:23:36,159 --> 00:23:38,559
path from your matlab workspace when

699
00:23:38,559 --> 00:23:39,919
you're in the supplementary code

700
00:23:39,919 --> 00:23:41,679
provided

701
00:23:41,679 --> 00:23:45,200
by uh ryan and christopher

702
00:23:45,200 --> 00:23:47,840
when you're in that workspace add path

703
00:23:47,840 --> 00:23:49,600
of that folder wherever you put it

704
00:23:49,600 --> 00:23:52,720
add path of that folder slash

705
00:23:52,720 --> 00:23:56,159
toolbox slash dem

706
00:23:56,159 --> 00:23:58,159
and then you should have access to the

707
00:23:58,159 --> 00:23:59,600
additional spm12

708
00:23:59,600 --> 00:24:01,600
scripts that you need in order to make

709
00:24:01,600 --> 00:24:04,640
use of the functions they've provided

710
00:24:04,640 --> 00:24:06,080
yeah no thank you very much i mean

711
00:24:06,080 --> 00:24:08,159
that's that yeah for someone who's never

712
00:24:08,159 --> 00:24:09,840
used matlab yes there's a few

713
00:24:09,840 --> 00:24:11,520
steps like that which are super

714
00:24:11,520 --> 00:24:13,360
important um

715
00:24:13,360 --> 00:24:14,720
yeah because basically all these scripts

716
00:24:14,720 --> 00:24:16,960
are actually within yeah within

717
00:24:16,960 --> 00:24:20,320
the dem toolbox um

718
00:24:20,320 --> 00:24:24,159
of spm um and uh all the scripts they've

719
00:24:24,159 --> 00:24:25,120
provided

720
00:24:25,120 --> 00:24:28,559
um call on uh sort of

721
00:24:28,559 --> 00:24:31,440
sub functions um within that are within

722
00:24:31,440 --> 00:24:32,640
spm

723
00:24:32,640 --> 00:24:36,320
um so so yeah it won't unfortunately

724
00:24:36,320 --> 00:24:38,080
uh none of them will work without

725
00:24:38,080 --> 00:24:39,679
without spm at the moment

726
00:24:39,679 --> 00:24:41,520
um although there are certainly efforts

727
00:24:41,520 --> 00:24:42,799
to try to make

728
00:24:42,799 --> 00:24:45,120
um some of these routines more sort of

729
00:24:45,120 --> 00:24:46,080
generally accessible

730
00:24:46,080 --> 00:24:49,039
and like free software um like alec alec

731
00:24:49,039 --> 00:24:50,080
chance for example

732
00:24:50,080 --> 00:24:52,000
is in the process of um i think writing

733
00:24:52,000 --> 00:24:53,520
a uh like a python

734
00:24:53,520 --> 00:24:56,720
version of the um of the main um

735
00:24:56,720 --> 00:24:59,200
active inference uh mdp script which is

736
00:24:59,200 --> 00:25:00,080
called the

737
00:25:00,080 --> 00:25:03,440
it's called uh uh spm

738
00:25:03,440 --> 00:25:05,760
underscore mdp underscore vb underscore

739
00:25:05,760 --> 00:25:06,559
x

740
00:25:06,559 --> 00:25:09,200
and that just corresponds that just mdp

741
00:25:09,200 --> 00:25:11,039
underscore vb underscore x corresponds

742
00:25:11,039 --> 00:25:12,559
to markov decision process

743
00:25:12,559 --> 00:25:15,760
underscore variational base underscore x

744
00:25:15,760 --> 00:25:17,600
which stands for factorized

745
00:25:17,600 --> 00:25:19,520
um and i'll i'll go over what

746
00:25:19,520 --> 00:25:20,799
factorization is

747
00:25:20,799 --> 00:25:23,039
um and how you actually code that in

748
00:25:23,039 --> 00:25:24,159
once we get to

749
00:25:24,159 --> 00:25:27,200
my section um

750
00:25:27,200 --> 00:25:29,760
okay i'm gonna ask a follow-up there so

751
00:25:29,760 --> 00:25:30,720
i have my

752
00:25:30,720 --> 00:25:33,600
desktop computer i have matlab and it's

753
00:25:33,600 --> 00:25:35,440
all working with referencing

754
00:25:35,440 --> 00:25:38,559
spm most updated version

755
00:25:38,559 --> 00:25:41,919
and i've run through the examples that

756
00:25:41,919 --> 00:25:43,520
we're going to be working through maybe

757
00:25:43,520 --> 00:25:45,200
today or the ones that are in the paper

758
00:25:45,200 --> 00:25:47,039
so i kind of hit enter and i got things

759
00:25:47,039 --> 00:25:47,600
to work

760
00:25:47,600 --> 00:25:50,480
everything's all the scripts are working

761
00:25:50,480 --> 00:25:52,000
fine

762
00:25:52,000 --> 00:25:54,559
what information from my system do i

763
00:25:54,559 --> 00:25:55,360
need to know

764
00:25:55,360 --> 00:25:58,000
like what measurements are going to be

765
00:25:58,000 --> 00:26:00,640
relevant for me to bring to the table

766
00:26:00,640 --> 00:26:02,720
if i'm going to do a t-test for whether

767
00:26:02,720 --> 00:26:04,000
two ant colonies are

768
00:26:04,000 --> 00:26:06,080
a different uh size you know i know what

769
00:26:06,080 --> 00:26:07,520
kind of machinery i'm going to need you

770
00:26:07,520 --> 00:26:08,799
know two columns

771
00:26:08,799 --> 00:26:10,960
in the excel spreadsheet or something

772
00:26:10,960 --> 00:26:12,640
but what kind of data

773
00:26:12,640 --> 00:26:15,520
or what attributes of the system are

774
00:26:15,520 --> 00:26:16,159
important

775
00:26:16,159 --> 00:26:17,919
to bring to the table for an

776
00:26:17,919 --> 00:26:19,840
investigator to utilize

777
00:26:19,840 --> 00:26:23,039
the examples that you're providing

778
00:26:23,039 --> 00:26:24,960
um yeah so i mean so i mean there's a

779
00:26:24,960 --> 00:26:26,320
couple things i mean so

780
00:26:26,320 --> 00:26:29,360
so first the um

781
00:26:29,360 --> 00:26:30,799
you know so the first goal is you know

782
00:26:30,799 --> 00:26:32,640
you take a particular

783
00:26:32,640 --> 00:26:35,600
behavioral task and you have to figure

784
00:26:35,600 --> 00:26:36,159
out

785
00:26:36,159 --> 00:26:39,039
what the right generative model is um

786
00:26:39,039 --> 00:26:40,480
for that task

787
00:26:40,480 --> 00:26:42,000
um and this is the sort of thing that

788
00:26:42,000 --> 00:26:43,679
i'll give an example of i can actually

789
00:26:43,679 --> 00:26:45,520
show you multiple examples of this

790
00:26:45,520 --> 00:26:47,919
um and so once you have this or

791
00:26:47,919 --> 00:26:49,600
generative model set up

792
00:26:49,600 --> 00:26:51,360
then you can run simulations and those

793
00:26:51,360 --> 00:26:53,279
simulations will generate

794
00:26:53,279 --> 00:26:57,120
observations and they'll generate

795
00:26:57,120 --> 00:27:00,159
expected actions um

796
00:27:00,159 --> 00:27:02,640
so so what you need then is you need

797
00:27:02,640 --> 00:27:03,679
data

798
00:27:03,679 --> 00:27:05,440
from an actual participant performing

799
00:27:05,440 --> 00:27:07,840
that task where you'll know

800
00:27:07,840 --> 00:27:10,400
on each trial um what the person

801
00:27:10,400 --> 00:27:12,159
observed right what the tasks amelia

802
00:27:12,159 --> 00:27:12,960
were

803
00:27:12,960 --> 00:27:14,480
and you'll know what action they

804
00:27:14,480 --> 00:27:17,200
actually chose

805
00:27:17,200 --> 00:27:20,640
and so then what you'll do ultimately is

806
00:27:20,640 --> 00:27:22,720
you'll do what's called parameter

807
00:27:22,720 --> 00:27:23,760
estimation

808
00:27:23,760 --> 00:27:25,600
which is and again this will be a lot

809
00:27:25,600 --> 00:27:26,880
more comprehensible

810
00:27:26,880 --> 00:27:28,799
once i actually show you but but

811
00:27:28,799 --> 00:27:30,799
basically what you try to do

812
00:27:30,799 --> 00:27:32,960
is you try to find the set of parameter

813
00:27:32,960 --> 00:27:34,399
values in the model

814
00:27:34,399 --> 00:27:36,960
that generates behavior that's most

815
00:27:36,960 --> 00:27:38,960
similar to what the participant actually

816
00:27:38,960 --> 00:27:41,039
did

817
00:27:41,039 --> 00:27:43,520
and so once you find the parameters you

818
00:27:43,520 --> 00:27:45,120
know say one has a value of two and the

819
00:27:45,120 --> 00:27:46,880
other has a value of four

820
00:27:46,880 --> 00:27:48,880
and that generates behavior that's

821
00:27:48,880 --> 00:27:50,159
identical to whatever a given

822
00:27:50,159 --> 00:27:51,520
participant did

823
00:27:51,520 --> 00:27:54,320
then those values of 2 and 4 you can use

824
00:27:54,320 --> 00:27:54,799
those

825
00:27:54,799 --> 00:27:57,200
as individual difference estimates you

826
00:27:57,200 --> 00:27:58,880
know so if you have those values for a

827
00:27:58,880 --> 00:28:00,640
bunch of different people who behaved in

828
00:28:00,640 --> 00:28:02,399
different ways on the task

829
00:28:02,399 --> 00:28:04,320
then you could say hey you know is there

830
00:28:04,320 --> 00:28:05,840
something different right about the

831
00:28:05,840 --> 00:28:07,760
people that have a parameter value of

832
00:28:07,760 --> 00:28:08,159
four

833
00:28:08,159 --> 00:28:10,960
versus a parameter value of eight right

834
00:28:10,960 --> 00:28:13,760
can i use that to predict for example

835
00:28:13,760 --> 00:28:15,200
you know how well somebody's going to

836
00:28:15,200 --> 00:28:17,360
respond to a particular treatment

837
00:28:17,360 --> 00:28:21,840
in in computational psychiatry um

838
00:28:22,320 --> 00:28:27,600
um hi chris twice yes

839
00:28:28,840 --> 00:28:30,960
um

840
00:28:30,960 --> 00:28:33,360
yeah but so but so but so that's that's

841
00:28:33,360 --> 00:28:34,399
kind of the idea

842
00:28:34,399 --> 00:28:36,880
um you know and i mean i can't i can

843
00:28:36,880 --> 00:28:38,960
share my screen in the meantime

844
00:28:38,960 --> 00:28:41,600
um i don't know well here i can i can

845
00:28:41,600 --> 00:28:42,720
perhaps go through

846
00:28:42,720 --> 00:28:44,720
some of this um so i'll just share my

847
00:28:44,720 --> 00:28:45,760
screen until

848
00:28:45,760 --> 00:28:48,399
i'm good yeah sorry that was this whole

849
00:28:48,399 --> 00:28:49,279
thing was

850
00:28:49,279 --> 00:28:52,720
um oh you're good okay

851
00:28:52,720 --> 00:28:54,399
i think i am at least can you guys see

852
00:28:54,399 --> 00:28:57,360
my screen uh yes perfect

853
00:28:57,360 --> 00:28:59,200
uh right here okay great sorry about

854
00:28:59,200 --> 00:29:00,480
that there was some a whole bunch of

855
00:29:00,480 --> 00:29:01,600
privacy issues

856
00:29:01,600 --> 00:29:04,799
um they had to enjoy the passwords there

857
00:29:04,799 --> 00:29:05,440
anyway

858
00:29:05,440 --> 00:29:13,840
okay we are here so

859
00:29:16,720 --> 00:29:18,240
okay so are you guys seeing my present

860
00:29:18,240 --> 00:29:20,480
of you or are you seeing the full thing

861
00:29:20,480 --> 00:29:22,320
looks uh we see the we see the full

862
00:29:22,320 --> 00:29:24,480
slide yeah just the slope awesome

863
00:29:24,480 --> 00:29:27,200
okay so this is just kind of part one um

864
00:29:27,200 --> 00:29:28,159
after i've done

865
00:29:28,159 --> 00:29:30,399
gone through this uh ryan's going to

866
00:29:30,399 --> 00:29:31,520
take over and go through some of the

867
00:29:31,520 --> 00:29:33,919
practical aspects of it

868
00:29:33,919 --> 00:29:35,600
um and so then just kind of reiterate

869
00:29:35,600 --> 00:29:37,200
the scope and purpose

870
00:29:37,200 --> 00:29:38,720
our target audience really is kind of

871
00:29:38,720 --> 00:29:39,919
researchers in neuroscience and

872
00:29:39,919 --> 00:29:42,080
psychology that don't have a strong

873
00:29:42,080 --> 00:29:43,840
kind of quantitative background in maths

874
00:29:43,840 --> 00:29:45,440
or ml in particular early career

875
00:29:45,440 --> 00:29:46,559
researchers

876
00:29:46,559 --> 00:29:47,679
and we just really want to provide

877
00:29:47,679 --> 00:29:50,559
people with a requisite background

878
00:29:50,559 --> 00:29:52,080
to actually apply this in the context of

879
00:29:52,080 --> 00:29:53,679
their own

880
00:29:53,679 --> 00:29:55,200
okay and then so just to quickly

881
00:29:55,200 --> 00:29:56,720
highlight some really fantastic other

882
00:29:56,720 --> 00:29:57,600
resources

883
00:29:57,600 --> 00:30:00,159
um the first paper is by lancelot de

884
00:30:00,159 --> 00:30:01,760
costa which is an incredible technical

885
00:30:01,760 --> 00:30:02,240
review

886
00:30:02,240 --> 00:30:04,399
just came out mathematical psychology um

887
00:30:04,399 --> 00:30:06,080
north has a really

888
00:30:06,080 --> 00:30:07,760
other incredible paper this came out

889
00:30:07,760 --> 00:30:09,120
neural computation

890
00:30:09,120 --> 00:30:12,960
and i think the um comparison to

891
00:30:12,960 --> 00:30:15,279
dynamic programming and bellman

892
00:30:15,279 --> 00:30:18,000
formulations um is still in pre-print if

893
00:30:18,000 --> 00:30:20,480
that's right ryan um but as well there's

894
00:30:20,480 --> 00:30:22,399
some really phenomenal

895
00:30:22,399 --> 00:30:25,760
informal tutorials with oleg solo shock

896
00:30:25,760 --> 00:30:27,120
i'm sorry if i butchered your name but

897
00:30:27,120 --> 00:30:28,000
anyway they're

898
00:30:28,000 --> 00:30:30,799
fantastic kind of informal tutorials on

899
00:30:30,799 --> 00:30:31,600
medium

900
00:30:31,600 --> 00:30:33,440
and then lastly is kind of the closest

901
00:30:33,440 --> 00:30:34,720
thing to what we're doing today

902
00:30:34,720 --> 00:30:37,440
is these lectures by philip

903
00:30:37,440 --> 00:30:38,159
schwartenbeck

904
00:30:38,159 --> 00:30:41,760
in the computational psychiatry

905
00:30:41,760 --> 00:30:44,399
summer school and these really are

906
00:30:44,399 --> 00:30:45,279
fantastic

907
00:30:45,279 --> 00:30:46,640
the only difference is that they work

908
00:30:46,640 --> 00:30:47,919
with to my knowledge i think they work

909
00:30:47,919 --> 00:30:49,760
with the unfactorized mdp scheme which

910
00:30:49,760 --> 00:30:51,200
is a little less flexible than what

911
00:30:51,200 --> 00:30:53,279
we're working with

912
00:30:53,279 --> 00:30:56,320
um okay and so

913
00:30:56,320 --> 00:30:57,440
there are a lot of ways of kind of

914
00:30:57,440 --> 00:30:59,840
motivating active inference

915
00:30:59,840 --> 00:31:01,120
i think kind of the way that's most

916
00:31:01,120 --> 00:31:02,159
intuitive to a lot of people in

917
00:31:02,159 --> 00:31:03,600
cognitive science or backgrounds in

918
00:31:03,600 --> 00:31:04,720
cognitive sciences to

919
00:31:04,720 --> 00:31:06,000
kind of start from perspective of the

920
00:31:06,000 --> 00:31:08,799
bayesian brain and so

921
00:31:08,799 --> 00:31:10,399
interrupting if anything's kind of

922
00:31:10,399 --> 00:31:12,000
moving too quickly or too slowly or

923
00:31:12,000 --> 00:31:13,600
anything like that but broadly speaking

924
00:31:13,600 --> 00:31:14,399
the idea is

925
00:31:14,399 --> 00:31:16,880
is that the brain encodes a generative

926
00:31:16,880 --> 00:31:18,159
model of the environment

927
00:31:18,159 --> 00:31:19,600
where this generative model is just kind

928
00:31:19,600 --> 00:31:21,919
of a joint probability distribution

929
00:31:21,919 --> 00:31:25,519
and then outside or in the outside world

930
00:31:25,519 --> 00:31:26,320
as it were

931
00:31:26,320 --> 00:31:28,880
there are states and observation states

932
00:31:28,880 --> 00:31:30,720
give rise to observations

933
00:31:30,720 --> 00:31:33,760
and we use the generative model in

934
00:31:33,760 --> 00:31:35,840
combination with bayesian updating

935
00:31:35,840 --> 00:31:38,320
to infer the hidden causes of our

936
00:31:38,320 --> 00:31:39,600
sensations

937
00:31:39,600 --> 00:31:42,799
from the observations and then we take

938
00:31:42,799 --> 00:31:44,080
actions based upon

939
00:31:44,080 --> 00:31:46,480
our kind of internal model of the world

940
00:31:46,480 --> 00:31:47,760
that couples us back

941
00:31:47,760 --> 00:31:49,440
to the generative process that if that

942
00:31:49,440 --> 00:31:51,360
makes sense and so there's this kind of

943
00:31:51,360 --> 00:31:52,000
perception

944
00:31:52,000 --> 00:31:55,200
action loop that's always going on so

945
00:31:55,200 --> 00:31:56,720
chris i think i think you might want to

946
00:31:56,720 --> 00:32:01,120
tell people just what the p o comma

947
00:32:03,279 --> 00:32:04,559
so that is a joint probability

948
00:32:04,559 --> 00:32:06,559
distribution over observations

949
00:32:06,559 --> 00:32:09,200
states and policies where policies are

950
00:32:09,200 --> 00:32:11,840
just actions or sequences of actions

951
00:32:11,840 --> 00:32:14,080
um that are available kind of all of the

952
00:32:14,080 --> 00:32:14,960
actions that

953
00:32:14,960 --> 00:32:18,720
are afforded to the agent essentially um

954
00:32:18,720 --> 00:32:21,760
okay and so then kind of

955
00:32:21,760 --> 00:32:23,919
just we start with like a re illustrate

956
00:32:23,919 --> 00:32:25,039
this we'll just give like a really

957
00:32:25,039 --> 00:32:27,039
really basic example

958
00:32:27,039 --> 00:32:28,799
and so you might be imagine being

959
00:32:28,799 --> 00:32:30,320
presented with

960
00:32:30,320 --> 00:32:33,039
kind of a shadowy shape like this and

961
00:32:33,039 --> 00:32:34,960
then you might and what you want to do

962
00:32:34,960 --> 00:32:38,080
is infer the causes of that shape based

963
00:32:38,080 --> 00:32:40,320
just based upon

964
00:32:40,320 --> 00:32:42,320
the observations but you don't just have

965
00:32:42,320 --> 00:32:43,360
observations right

966
00:32:43,360 --> 00:32:45,120
you have some prior knowledge about the

967
00:32:45,120 --> 00:32:46,399
world

968
00:32:46,399 --> 00:32:48,880
um and so we can specify that here so we

969
00:32:48,880 --> 00:32:50,000
might say

970
00:32:50,000 --> 00:32:52,000
where two possible causes in this very

971
00:32:52,000 --> 00:32:53,120
limited example

972
00:32:53,120 --> 00:32:56,000
there is we might say that the shadow is

973
00:32:56,000 --> 00:32:58,240
caused by a convex surface or a concave

974
00:32:58,240 --> 00:32:59,200
surface

975
00:32:59,200 --> 00:33:00,480
and they have fairly similar prior

976
00:33:00,480 --> 00:33:02,960
probabilities however we also have the

977
00:33:02,960 --> 00:33:04,640
structural prior that we've kind of

978
00:33:04,640 --> 00:33:06,320
acquired through a lifetime experience

979
00:33:06,320 --> 00:33:08,559
of just light emanating from above

980
00:33:08,559 --> 00:33:10,640
and under the kind of a structural pry

981
00:33:10,640 --> 00:33:12,720
that light emanates from above

982
00:33:12,720 --> 00:33:14,880
the likelihood of the observation of

983
00:33:14,880 --> 00:33:16,559
that particular shadow

984
00:33:16,559 --> 00:33:18,720
kind of conditional being concave is

985
00:33:18,720 --> 00:33:21,679
much much higher

986
00:33:21,919 --> 00:33:24,000
okay and so then we can then combine the

987
00:33:24,000 --> 00:33:26,960
two the prior and the likelihood

988
00:33:26,960 --> 00:33:29,440
to give us a joint distribution where

989
00:33:29,440 --> 00:33:31,120
this is just kind of conditional on a

990
00:33:31,120 --> 00:33:33,360
specific observation

991
00:33:33,360 --> 00:33:36,640
we can then and then we sum over

992
00:33:36,640 --> 00:33:40,320
the states in that likelihood to give us

993
00:33:40,320 --> 00:33:43,360
our marginal likelihood and then divide

994
00:33:43,360 --> 00:33:44,960
our joint distribution or our generative

995
00:33:44,960 --> 00:33:46,960
model by our

996
00:33:46,960 --> 00:33:48,320
marginal likelihood and that's called

997
00:33:48,320 --> 00:33:50,000
model inversion or is often

998
00:33:50,000 --> 00:33:53,279
colloquially called model inversion

999
00:33:53,279 --> 00:33:54,960
and from there we get our posterior

1000
00:33:54,960 --> 00:33:56,640
distribution this is the probability of

1001
00:33:56,640 --> 00:33:57,840
states

1002
00:33:57,840 --> 00:34:00,000
conditional on observations and so we

1003
00:34:00,000 --> 00:34:01,519
started with a prior

1004
00:34:01,519 --> 00:34:04,720
and a likelihood and got to a posterior

1005
00:34:04,720 --> 00:34:08,320
through bayes rule and that is kind of

1006
00:34:08,320 --> 00:34:11,599
formally speaking the optimal way to

1007
00:34:11,599 --> 00:34:13,280
infer

1008
00:34:13,280 --> 00:34:15,440
the probability of hidden causes given

1009
00:34:15,440 --> 00:34:16,800
observations

1010
00:34:16,800 --> 00:34:18,879
and the complication to all this is that

1011
00:34:18,879 --> 00:34:20,239
the marginal likelihood is generally

1012
00:34:20,239 --> 00:34:22,320
speaking computationally intractable

1013
00:34:22,320 --> 00:34:24,719
um so i in the case kind of these very

1014
00:34:24,719 --> 00:34:26,239
simple discrete distributions

1015
00:34:26,239 --> 00:34:27,599
the number of sums that you have to

1016
00:34:27,599 --> 00:34:29,599
perform scales exponentially with the

1017
00:34:29,599 --> 00:34:31,440
size of your hypothesis space so that's

1018
00:34:31,440 --> 00:34:34,480
extremely impractical um and

1019
00:34:34,480 --> 00:34:36,399
kind of more realistically when you're

1020
00:34:36,399 --> 00:34:38,800
working with in continuous state spaces

1021
00:34:38,800 --> 00:34:41,599
if you have non-gaussian or non-linear

1022
00:34:41,599 --> 00:34:42,960
um signals

1023
00:34:42,960 --> 00:34:44,000
they're just analytically the

1024
00:34:44,000 --> 00:34:45,119
distributions is analytically

1025
00:34:45,119 --> 00:34:46,399
interactable

1026
00:34:46,399 --> 00:34:48,719
so chris i think i think uh max had a

1027
00:34:48,719 --> 00:34:50,159
question yeah yeah sorry

1028
00:34:50,159 --> 00:34:52,000
yeah real quick uh just just to really

1029
00:34:52,000 --> 00:34:53,760
explicitly uh touch on

1030
00:34:53,760 --> 00:34:56,560
the idea of hidden hidden states and

1031
00:34:56,560 --> 00:34:57,599
hidden variables

1032
00:34:57,599 --> 00:35:00,480
in this particular context uh would it

1033
00:35:00,480 --> 00:35:02,160
be fair to say that it's not only

1034
00:35:02,160 --> 00:35:05,200
the convexity or concavity of the the

1035
00:35:05,200 --> 00:35:06,160
potential

1036
00:35:06,160 --> 00:35:07,920
you know thing that i'm looking at but

1037
00:35:07,920 --> 00:35:09,680
also i could think of

1038
00:35:09,680 --> 00:35:11,119
the light source the direction from

1039
00:35:11,119 --> 00:35:12,400
where the light source is as being

1040
00:35:12,400 --> 00:35:13,680
another hidden variable

1041
00:35:13,680 --> 00:35:15,520
and those things together would it be

1042
00:35:15,520 --> 00:35:17,280
fair to term those as under my

1043
00:35:17,280 --> 00:35:19,599
markov blanket or is that uh getting a

1044
00:35:19,599 --> 00:35:21,040
little too far out from where we want to

1045
00:35:21,040 --> 00:35:21,920
be talking right now

1046
00:35:21,920 --> 00:35:24,640
yeah so markov blankets don't really the

1047
00:35:24,640 --> 00:35:26,079
kind of markup blanket concept here

1048
00:35:26,079 --> 00:35:27,119
doesn't really

1049
00:35:27,119 --> 00:35:29,520
come in in in any really interesting way

1050
00:35:29,520 --> 00:35:30,960
i mean you can formulate it that way but

1051
00:35:30,960 --> 00:35:32,720
really the idea is just

1052
00:35:32,720 --> 00:35:34,640
you have this prior expectation so when

1053
00:35:34,640 --> 00:35:36,079
you're looking at the little gray disc

1054
00:35:36,079 --> 00:35:38,079
right there under observation

1055
00:35:38,079 --> 00:35:39,920
most people when you look at it even

1056
00:35:39,920 --> 00:35:41,359
though it's actually just a flat

1057
00:35:41,359 --> 00:35:42,880
shape with some you know it's just a

1058
00:35:42,880 --> 00:35:44,720
flat two-dimensional thing that has

1059
00:35:44,720 --> 00:35:46,240
a little bit of darkness in one place a

1060
00:35:46,240 --> 00:35:48,000
little bit of lightness in another

1061
00:35:48,000 --> 00:35:51,200
um you know if most people see that as

1062
00:35:51,200 --> 00:35:52,240
being concave

1063
00:35:52,240 --> 00:35:55,359
even though it's a flat 2d thing

1064
00:35:55,359 --> 00:35:58,240
right so the idea is is just that

1065
00:35:58,240 --> 00:35:59,280
there's a reason

1066
00:35:59,280 --> 00:36:01,680
right why people typically see it as

1067
00:36:01,680 --> 00:36:03,520
being concave as it's kind of like

1068
00:36:03,520 --> 00:36:05,440
popping in as opposed to out

1069
00:36:05,440 --> 00:36:07,280
and that's specifically because there's

1070
00:36:07,280 --> 00:36:08,880
this prior belief

1071
00:36:08,880 --> 00:36:12,079
that um that light sources tend to come

1072
00:36:12,079 --> 00:36:14,960
from above um so the the hidden states

1073
00:36:14,960 --> 00:36:15,359
here

1074
00:36:15,359 --> 00:36:18,400
are kind of there is a joint in the

1075
00:36:18,400 --> 00:36:20,160
likelihood which just means

1076
00:36:20,160 --> 00:36:22,160
that there's a in the upright where it

1077
00:36:22,160 --> 00:36:24,960
says likelihood there's a concave comma

1078
00:36:24,960 --> 00:36:27,440
light from above right so those are two

1079
00:36:27,440 --> 00:36:29,280
different hidden states

1080
00:36:29,280 --> 00:36:32,400
what it's saying is um if

1081
00:36:32,400 --> 00:36:34,800
the hidden states are concave and light

1082
00:36:34,800 --> 00:36:35,440
from above

1083
00:36:35,440 --> 00:36:37,200
if the combination of those things is

1084
00:36:37,200 --> 00:36:38,720
what's generating

1085
00:36:38,720 --> 00:36:40,800
the what i'm seeing with that gray disc

1086
00:36:40,800 --> 00:36:41,760
thing

1087
00:36:41,760 --> 00:36:44,960
um the probability of the shadow shape

1088
00:36:44,960 --> 00:36:47,760
that the shadow pattern that you see um

1089
00:36:47,760 --> 00:36:49,280
is 0.9

1090
00:36:49,280 --> 00:36:51,680
whereas if it was convex and light from

1091
00:36:51,680 --> 00:36:52,960
above if those were the two hidden

1092
00:36:52,960 --> 00:36:54,079
states

1093
00:36:54,079 --> 00:36:56,480
then the probability you get that shame

1094
00:36:56,480 --> 00:36:59,119
that same shadow pattern is only 0.1

1095
00:36:59,119 --> 00:37:01,040
right in other words it'd be really hard

1096
00:37:01,040 --> 00:37:02,400
to get that

1097
00:37:02,400 --> 00:37:05,680
pattern of shading if if the thing was

1098
00:37:05,680 --> 00:37:06,960
popping out

1099
00:37:06,960 --> 00:37:09,200
under the assumption that light's coming

1100
00:37:09,200 --> 00:37:10,320
from above

1101
00:37:10,320 --> 00:37:13,200
um so so the observation here is shadow

1102
00:37:13,200 --> 00:37:14,560
and the hidden states are

1103
00:37:14,560 --> 00:37:17,040
concave and light from a concave or

1104
00:37:17,040 --> 00:37:18,560
convex and light from above and like

1105
00:37:18,560 --> 00:37:19,680
from below

1106
00:37:19,680 --> 00:37:22,400
okay thanks yeah just one other quick

1107
00:37:22,400 --> 00:37:23,920
example there would be like the chess

1108
00:37:23,920 --> 00:37:24,640
board

1109
00:37:24,640 --> 00:37:27,760
with a shadow and a dark square it's

1110
00:37:27,760 --> 00:37:29,920
perceived under a deep cultural prior

1111
00:37:29,920 --> 00:37:31,920
that chessboards are regular

1112
00:37:31,920 --> 00:37:35,040
alternating grids it makes an ambiguous

1113
00:37:35,040 --> 00:37:37,280
shaded square appear as something that's

1114
00:37:37,280 --> 00:37:38,560
quite different than it is people can

1115
00:37:38,560 --> 00:37:39,359
look that up

1116
00:37:39,359 --> 00:37:41,040
and then another uh thing this reminds

1117
00:37:41,040 --> 00:37:43,760
me of is like using a t-test

1118
00:37:43,760 --> 00:37:46,160
to test whether group a versus b is

1119
00:37:46,160 --> 00:37:47,920
taller or something like that

1120
00:37:47,920 --> 00:37:50,400
it assumes but um it can be an

1121
00:37:50,400 --> 00:37:51,280
assumption that can be

1122
00:37:51,280 --> 00:37:53,760
slightly bent is it assumes that other

1123
00:37:53,760 --> 00:37:55,760
than the variable being considered

1124
00:37:55,760 --> 00:37:58,000
other things are sort of fixed or not

1125
00:37:58,000 --> 00:37:59,599
mattering otherwise your statistical

1126
00:37:59,599 --> 00:38:01,359
test is basically misleading

1127
00:38:01,359 --> 00:38:02,640
because it could be capturing some

1128
00:38:02,640 --> 00:38:04,640
totally confounding variable

1129
00:38:04,640 --> 00:38:07,440
in the framework you put it in and so

1130
00:38:07,440 --> 00:38:09,359
whenever you're talking about a real

1131
00:38:09,359 --> 00:38:11,839
biological organism you're talking about

1132
00:38:11,839 --> 00:38:14,400
conditioning on certain things

1133
00:38:14,400 --> 00:38:17,200
and then given what is totally

1134
00:38:17,200 --> 00:38:18,720
conditioned out of the picture

1135
00:38:18,720 --> 00:38:20,560
so i i kind of see where you're going

1136
00:38:20,560 --> 00:38:21,760
with the blanket but it's

1137
00:38:21,760 --> 00:38:24,079
not specifically in this place but a

1138
00:38:24,079 --> 00:38:25,200
good question

1139
00:38:25,200 --> 00:38:26,560
but it's like depending on the

1140
00:38:26,560 --> 00:38:28,880
irrelevancies that we can condition out

1141
00:38:28,880 --> 00:38:30,320
then we're looking at the conditional

1142
00:38:30,320 --> 00:38:32,400
relationships between different

1143
00:38:32,400 --> 00:38:35,200
observed states versus the hidden things

1144
00:38:35,200 --> 00:38:35,839
so

1145
00:38:35,839 --> 00:38:38,160
cool stuff and again in the live chat

1146
00:38:38,160 --> 00:38:39,440
people can post any

1147
00:38:39,440 --> 00:38:42,240
questions on it continue christopher

1148
00:38:42,240 --> 00:38:43,119
yeah thank you

1149
00:38:43,119 --> 00:38:46,480
um yeah thanks for covering that ryan um

1150
00:38:46,480 --> 00:38:49,520
okay so then the idea is is that the

1151
00:38:49,520 --> 00:38:50,800
marginal likelihood is generally

1152
00:38:50,800 --> 00:38:53,280
computationally intractable

1153
00:38:53,280 --> 00:38:55,040
but kind of borrowing some ideas from

1154
00:38:55,040 --> 00:38:56,800
statistical physics

1155
00:38:56,800 --> 00:38:58,320
what you can do is actually use some

1156
00:38:58,320 --> 00:39:00,320
approximation techniques and instead of

1157
00:39:00,320 --> 00:39:01,920
evaluating the marginal likelihood

1158
00:39:01,920 --> 00:39:03,040
directly

1159
00:39:03,040 --> 00:39:04,960
we can evaluate something that's always

1160
00:39:04,960 --> 00:39:07,280
provably greater than or equal to

1161
00:39:07,280 --> 00:39:10,320
the marginal likelihood i'm so going

1162
00:39:10,320 --> 00:39:10,960
through that

1163
00:39:10,960 --> 00:39:13,599
right now okay and so we're just going

1164
00:39:13,599 --> 00:39:14,960
to take the logs kind of for

1165
00:39:14,960 --> 00:39:16,400
mathematical convenience and the reason

1166
00:39:16,400 --> 00:39:18,079
we always work with logs or generally

1167
00:39:18,079 --> 00:39:19,920
speaking is because

1168
00:39:19,920 --> 00:39:22,640
log log algebra is just a lot easier

1169
00:39:22,640 --> 00:39:24,160
just because it turns multiplications

1170
00:39:24,160 --> 00:39:25,680
into arithmetic

1171
00:39:25,680 --> 00:39:28,000
um so things it's just easier to work

1172
00:39:28,000 --> 00:39:28,800
with essentially

1173
00:39:28,800 --> 00:39:31,280
so we'll take the negative log of our

1174
00:39:31,280 --> 00:39:32,640
marginal likelihood

1175
00:39:32,640 --> 00:39:34,079
um this is also sometimes called

1176
00:39:34,079 --> 00:39:35,680
bayesian model evidence and

1177
00:39:35,680 --> 00:39:36,880
when we have a negative log of a

1178
00:39:36,880 --> 00:39:38,880
probability it's also called surprise

1179
00:39:38,880 --> 00:39:40,640
and information theory which is kind of

1180
00:39:40,640 --> 00:39:42,160
the terminology i'm going to use the

1181
00:39:42,160 --> 00:39:44,160
rest of this kind of presentation

1182
00:39:44,160 --> 00:39:45,520
and so you can see on the right-hand

1183
00:39:45,520 --> 00:39:47,280
side of the equality this

1184
00:39:47,280 --> 00:39:49,040
is kind of the sum rule of probability

1185
00:39:49,040 --> 00:39:50,800
we can get back our surprise by just

1186
00:39:50,800 --> 00:39:51,680
summing over

1187
00:39:51,680 --> 00:39:54,079
kind of all of the states under our uh

1188
00:39:54,079 --> 00:39:55,520
joint distribution over states and

1189
00:39:55,520 --> 00:39:57,200
outcomes

1190
00:39:57,200 --> 00:39:59,119
and then we can kind of do a little bit

1191
00:39:59,119 --> 00:40:00,800
of a trick here so what i'm going to do

1192
00:40:00,800 --> 00:40:01,200
now

1193
00:40:01,200 --> 00:40:04,480
or show you is that we are going to

1194
00:40:04,480 --> 00:40:06,319
multiply this joint distribution or

1195
00:40:06,319 --> 00:40:08,560
generative model by some arbitrary

1196
00:40:08,560 --> 00:40:09,520
distribution

1197
00:40:09,520 --> 00:40:11,760
we multiply and divide by the same

1198
00:40:11,760 --> 00:40:12,720
distribution

1199
00:40:12,720 --> 00:40:14,240
and so nothing has changed here this

1200
00:40:14,240 --> 00:40:15,760
quality still holds

1201
00:40:15,760 --> 00:40:18,160
i could cancel these if we wanted to but

1202
00:40:18,160 --> 00:40:19,920
i don't want to

1203
00:40:19,920 --> 00:40:21,760
and that's in particular because i want

1204
00:40:21,760 --> 00:40:24,400
to take advantage of something called

1205
00:40:24,400 --> 00:40:27,280
jensen's inequality and that is that a

1206
00:40:27,280 --> 00:40:28,160
result showing that the

1207
00:40:28,160 --> 00:40:31,280
expectation of a logarithm is always

1208
00:40:31,280 --> 00:40:33,280
less than or equal to the logarithm of

1209
00:40:33,280 --> 00:40:35,280
an expectation

1210
00:40:35,280 --> 00:40:38,560
and so the idea is is that this sum

1211
00:40:38,560 --> 00:40:41,680
here where the logarithm is inside this

1212
00:40:41,680 --> 00:40:42,640
summation

1213
00:40:42,640 --> 00:40:44,160
where sorry so we're taking we're

1214
00:40:44,160 --> 00:40:46,640
summing over

1215
00:40:46,640 --> 00:40:49,040
this kind of difference between a

1216
00:40:49,040 --> 00:40:50,240
generative model

1217
00:40:50,240 --> 00:40:51,839
and this approximate or target

1218
00:40:51,839 --> 00:40:53,520
distribution

1219
00:40:53,520 --> 00:40:56,640
when the logarithm is inside that it is

1220
00:40:56,640 --> 00:40:58,960
always going to be and we're in kind of

1221
00:40:58,960 --> 00:41:00,000
negative territory

1222
00:41:00,000 --> 00:41:01,760
it's always going to be greater than

1223
00:41:01,760 --> 00:41:04,000
this quantity on the left-hand side

1224
00:41:04,000 --> 00:41:05,520
where this left-hand quantity is equal

1225
00:41:05,520 --> 00:41:07,599
to surprise because

1226
00:41:07,599 --> 00:41:10,240
the log is outside the sum we can cancel

1227
00:41:10,240 --> 00:41:12,079
these kind of approximate distributions

1228
00:41:12,079 --> 00:41:13,359
right and end up

1229
00:41:13,359 --> 00:41:15,599
back at surprise on the right hand side

1230
00:41:15,599 --> 00:41:17,200
we can't do that

1231
00:41:17,200 --> 00:41:19,359
this right hand side will only be equal

1232
00:41:19,359 --> 00:41:20,720
to surprise

1233
00:41:20,720 --> 00:41:22,720
when our generative distribution

1234
00:41:22,720 --> 00:41:24,640
perfectly matches our approximate

1235
00:41:24,640 --> 00:41:26,160
distribution

1236
00:41:26,160 --> 00:41:28,160
and so this quantity on the right hand

1237
00:41:28,160 --> 00:41:29,520
side here

1238
00:41:29,520 --> 00:41:32,560
this is variational free energy and so

1239
00:41:32,560 --> 00:41:33,520
the idea is

1240
00:41:33,520 --> 00:41:37,040
is that we find the probability

1241
00:41:37,040 --> 00:41:38,800
distribute this approximate probability

1242
00:41:38,800 --> 00:41:40,480
distribution which we make simplifying

1243
00:41:40,480 --> 00:41:42,400
assumptions about and so we can

1244
00:41:42,400 --> 00:41:45,440
kind of evaluate analytically

1245
00:41:45,440 --> 00:41:48,319
we make simplifying we find the value of

1246
00:41:48,319 --> 00:41:49,920
this distribution

1247
00:41:49,920 --> 00:41:53,359
that best minimizes f

1248
00:41:53,359 --> 00:41:55,599
where f is variational free energy does

1249
00:41:55,599 --> 00:41:57,599
that kind of make sense

1250
00:41:57,599 --> 00:41:59,680
hey chris just one thing are you like

1251
00:41:59,680 --> 00:42:01,040
trying to like move your mouse around to

1252
00:42:01,040 --> 00:42:02,240
point to things

1253
00:42:02,240 --> 00:42:05,599
no okay i'm actually putting my mouse

1254
00:42:05,599 --> 00:42:07,599
i'm scribbling my mouse a little bit on

1255
00:42:07,599 --> 00:42:08,800
the live stream they should be able to

1256
00:42:08,800 --> 00:42:09,440
see that

1257
00:42:09,440 --> 00:42:11,359
but christopher thank you for that

1258
00:42:11,359 --> 00:42:12,880
really awesome

1259
00:42:12,880 --> 00:42:15,119
example because it really clarified a

1260
00:42:15,119 --> 00:42:16,319
few things

1261
00:42:16,319 --> 00:42:18,079
any other notes to add here otherwise

1262
00:42:18,079 --> 00:42:20,880
this is cool to continue

1263
00:42:20,880 --> 00:42:24,640
yeah okay so then just kind of give a

1264
00:42:24,640 --> 00:42:26,720
really toy example of this

1265
00:42:26,720 --> 00:42:28,839
so we can define our approximate

1266
00:42:28,839 --> 00:42:30,079
posterior

1267
00:42:30,079 --> 00:42:31,520
kind of arbitrarily is a flat

1268
00:42:31,520 --> 00:42:34,319
distribution we'll have a true posterior

1269
00:42:34,319 --> 00:42:35,599
generally speaking we don't know what

1270
00:42:35,599 --> 00:42:37,440
this is but for illustration's sake

1271
00:42:37,440 --> 00:42:38,079
we're going to give

1272
00:42:38,079 --> 00:42:40,480
kind of give it to you and then we can

1273
00:42:40,480 --> 00:42:41,680
have a joint distribution

1274
00:42:41,680 --> 00:42:43,440
and an observation what the observation

1275
00:42:43,440 --> 00:42:45,280
will do is it's just going to select

1276
00:42:45,280 --> 00:42:47,680
a kind of a column from this joint

1277
00:42:47,680 --> 00:42:50,240
distribution

1278
00:42:52,480 --> 00:42:55,040
and so then we have we can now enter

1279
00:42:55,040 --> 00:42:56,400
this into the equation we saw on the

1280
00:42:56,400 --> 00:42:57,680
last slide

1281
00:42:57,680 --> 00:42:59,920
and we'll slowly but surely in each

1282
00:42:59,920 --> 00:43:01,280
update

1283
00:43:01,280 --> 00:43:04,400
nudge our posterior distribution

1284
00:43:04,400 --> 00:43:08,160
such that it minimizes f on each step

1285
00:43:08,160 --> 00:43:10,480
and at the third step you see what we

1286
00:43:10,480 --> 00:43:11,920
should see is that when f is at a

1287
00:43:11,920 --> 00:43:13,440
minimum

1288
00:43:13,440 --> 00:43:17,040
it is equal to surprise and when f is at

1289
00:43:17,040 --> 00:43:17,760
a minimum as well

1290
00:43:17,760 --> 00:43:20,240
it's at a minimum because the true

1291
00:43:20,240 --> 00:43:21,119
posterior

1292
00:43:21,119 --> 00:43:24,400
and our approximate posterior match

1293
00:43:24,400 --> 00:43:26,880
so that kind of makes sense um and so

1294
00:43:26,880 --> 00:43:28,319
the idea is is that

1295
00:43:28,319 --> 00:43:30,000
by performing bayesian inference and

1296
00:43:30,000 --> 00:43:31,920
having and kind of forcing

1297
00:43:31,920 --> 00:43:33,520
some arbitrary distribution to

1298
00:43:33,520 --> 00:43:36,240
approximate our posterior

1299
00:43:36,240 --> 00:43:38,640
we come up with an upper bound on

1300
00:43:38,640 --> 00:43:40,079
surprise or we come to

1301
00:43:40,079 --> 00:43:42,880
an upper bound on surprise let me kind

1302
00:43:42,880 --> 00:43:43,359
of just

1303
00:43:43,359 --> 00:43:45,760
walk through and just double check here

1304
00:43:45,760 --> 00:43:46,480
so q

1305
00:43:46,480 --> 00:43:50,560
of s is our estimate of whether the coin

1306
00:43:50,560 --> 00:43:53,440
is a fair coin 50 50 means that it's 50

1307
00:43:53,440 --> 00:43:56,160
50 and then 80 20 is the reality

1308
00:43:56,160 --> 00:43:58,720
on the table so to speak so it's almost

1309
00:43:58,720 --> 00:43:59,200
like

1310
00:43:59,200 --> 00:44:02,480
first we click from 50 50 we see heads

1311
00:44:02,480 --> 00:44:03,359
come up

1312
00:44:03,359 --> 00:44:04,800
and that contributes a little bit of

1313
00:44:04,800 --> 00:44:06,880
evidence that maybe heads is more likely

1314
00:44:06,880 --> 00:44:10,240
so we go from 50 50 to 60 40.

1315
00:44:10,240 --> 00:44:12,560
and then something happens again and we

1316
00:44:12,560 --> 00:44:14,640
click on the second update

1317
00:44:14,640 --> 00:44:19,920
to 7.7.3 we click eventually to 0.8.2

1318
00:44:19,920 --> 00:44:21,520
and then if we click all the way to

1319
00:44:21,520 --> 00:44:23,359
point nine point one

1320
00:44:23,359 --> 00:44:26,800
so again in 90 10 all of a sudden we go

1321
00:44:26,800 --> 00:44:30,319
uh back up from 0.693

1322
00:44:30,319 --> 00:44:33,440
back up so if we were to plot this final

1323
00:44:33,440 --> 00:44:35,680
estimated f we'd find that we're like

1324
00:44:35,680 --> 00:44:37,680
going downhill getting better

1325
00:44:37,680 --> 00:44:41,200
get to 0.693 in this discrete 0.1

1326
00:44:41,200 --> 00:44:43,599
movement space and then we pop up a

1327
00:44:43,599 --> 00:44:45,520
little bit too far we overshoot

1328
00:44:45,520 --> 00:44:47,760
and we get a little bit more surprised

1329
00:44:47,760 --> 00:44:49,280
by the distributions that we're

1330
00:44:49,280 --> 00:44:52,400
drawing yeah exactly that's perfect um

1331
00:44:52,400 --> 00:44:53,839
well the only the only thing that i

1332
00:44:53,839 --> 00:44:54,480
would say

1333
00:44:54,480 --> 00:44:56,319
that's i mean a little different just to

1334
00:44:56,319 --> 00:44:58,160
note is that there's nothing in this

1335
00:44:58,160 --> 00:44:59,920
example where you observe something over

1336
00:44:59,920 --> 00:45:01,760
and over again

1337
00:45:01,760 --> 00:45:03,599
this is this is just a single

1338
00:45:03,599 --> 00:45:05,440
observation once

1339
00:45:05,440 --> 00:45:08,319
and you're trying to figure out what

1340
00:45:08,319 --> 00:45:09,760
what is the you're trying to figure out

1341
00:45:09,760 --> 00:45:11,200
what the true posterior

1342
00:45:11,200 --> 00:45:12,880
is trying to get as close to it as

1343
00:45:12,880 --> 00:45:14,960
possible so all you're doing is saying

1344
00:45:14,960 --> 00:45:16,880
here's the single observation

1345
00:45:16,880 --> 00:45:18,640
and i'm going to try out a bunch of

1346
00:45:18,640 --> 00:45:20,319
different values for qs

1347
00:45:20,319 --> 00:45:21,599
a bunch of different values for that

1348
00:45:21,599 --> 00:45:23,359
approximate distribution

1349
00:45:23,359 --> 00:45:25,599
and i'm just going to find the one you

1350
00:45:25,599 --> 00:45:26,960
know through this kind of iterative

1351
00:45:26,960 --> 00:45:29,760
updating thing where i slowly move qs

1352
00:45:29,760 --> 00:45:32,319
you know to different values you just do

1353
00:45:32,319 --> 00:45:33,920
that for a single observation

1354
00:45:33,920 --> 00:45:36,960
you update until you find the minimum

1355
00:45:36,960 --> 00:45:39,599
free energy value which just tells you

1356
00:45:39,599 --> 00:45:41,680
that your approximate posterior the qs

1357
00:45:41,680 --> 00:45:43,119
thing is as close

1358
00:45:43,119 --> 00:45:45,760
is really close to the true posterior

1359
00:45:45,760 --> 00:45:47,440
that you couldn't figure out

1360
00:45:47,440 --> 00:45:48,960
on your own because the problem was too

1361
00:45:48,960 --> 00:45:50,640
tough to solve with exact bayesian

1362
00:45:50,640 --> 00:45:51,680
inference

1363
00:45:51,680 --> 00:45:54,319
um so this this is kind of corresponds

1364
00:45:54,319 --> 00:45:55,599
to what people might talk about as

1365
00:45:55,599 --> 00:45:57,440
prediction error minimization

1366
00:45:57,440 --> 00:46:00,079
right so you just see this observation

1367
00:46:00,079 --> 00:46:00,960
once

1368
00:46:00,960 --> 00:46:02,400
and the brain tries to minimize

1369
00:46:02,400 --> 00:46:04,480
prediction error by minimizing f

1370
00:46:04,480 --> 00:46:07,040
by just moving beliefs until it finds

1371
00:46:07,040 --> 00:46:07,920
the

1372
00:46:07,920 --> 00:46:11,200
the belief that minimizes f

1373
00:46:11,200 --> 00:46:13,359
which is the same thing as minimizing

1374
00:46:13,359 --> 00:46:14,640
prediction error

1375
00:46:14,640 --> 00:46:17,839
um look at that if that makes sense

1376
00:46:17,839 --> 00:46:19,599
let me clarify because i i think that

1377
00:46:19,599 --> 00:46:21,680
really helped me understand it and

1378
00:46:21,680 --> 00:46:23,200
at first i thought wait with one

1379
00:46:23,200 --> 00:46:25,200
observation because at first when i

1380
00:46:25,200 --> 00:46:26,800
described it i was thinking update was

1381
00:46:26,800 --> 00:46:29,119
tied to a new observation from the coin

1382
00:46:29,119 --> 00:46:30,640
but then i thought well if you're only

1383
00:46:30,640 --> 00:46:32,640
getting one observation the maximum

1384
00:46:32,640 --> 00:46:34,560
likelihood model is a coin that only

1385
00:46:34,560 --> 00:46:35,520
comes up heads

1386
00:46:35,520 --> 00:46:37,440
because you only have one observation

1387
00:46:37,440 --> 00:46:39,040
but it's not one-shot

1388
00:46:39,040 --> 00:46:42,880
parameter learning naive it's actually

1389
00:46:42,880 --> 00:46:45,920
a a tethered estimate that's tethered

1390
00:46:45,920 --> 00:46:48,960
even loosely but non-zero tethering to a

1391
00:46:48,960 --> 00:46:50,000
prior

1392
00:46:50,000 --> 00:46:52,400
0.5.5 some people will say uninformative

1393
00:46:52,400 --> 00:46:54,960
but all priors are informative

1394
00:46:54,960 --> 00:46:57,680
they're all what they are and then it's

1395
00:46:57,680 --> 00:46:59,920
almost like because of the logs

1396
00:46:59,920 --> 00:47:01,920
even though you only observed the coin

1397
00:47:01,920 --> 00:47:03,440
come up once it's like all right it's a

1398
00:47:03,440 --> 00:47:04,960
little too far to update

1399
00:47:04,960 --> 00:47:08,079
to 99 one just from seeing one coin flip

1400
00:47:08,079 --> 00:47:09,839
i would need extraordinary evidence for

1401
00:47:09,839 --> 00:47:10,960
extraordinary

1402
00:47:10,960 --> 00:47:13,680
updates and so it's like that one heads

1403
00:47:13,680 --> 00:47:14,400
observation

1404
00:47:14,400 --> 00:47:17,520
updates you from 50 50 to near

1405
00:47:17,520 --> 00:47:20,800
80 20 which does happen to be close

1406
00:47:20,800 --> 00:47:24,000
to the actual probability of the coin

1407
00:47:24,000 --> 00:47:26,079
and it also happens to navigate this

1408
00:47:26,079 --> 00:47:28,559
explore exploit in an interesting way

1409
00:47:28,559 --> 00:47:30,319
because it updates it but not all the

1410
00:47:30,319 --> 00:47:32,559
way so it's just kind of showing

1411
00:47:32,559 --> 00:47:35,359
how the bayesian updating brings some of

1412
00:47:35,359 --> 00:47:35,839
that

1413
00:47:35,839 --> 00:47:39,040
wisdom of multi-observation learning

1414
00:47:39,040 --> 00:47:42,079
like slow updating of parameters and

1415
00:47:42,079 --> 00:47:45,119
uh sequential uh updating to

1416
00:47:45,119 --> 00:47:48,240
a little bit of a different context so

1417
00:47:48,240 --> 00:47:49,200
yeah i mean

1418
00:47:49,200 --> 00:47:50,880
i do want to clarify here a little bit i

1419
00:47:50,880 --> 00:47:53,040
mean there's there's no actions here

1420
00:47:53,040 --> 00:47:55,119
so there can't really be explore exploit

1421
00:47:55,119 --> 00:47:56,079
right you can't

1422
00:47:56,079 --> 00:47:57,440
you can't choose to look over here

1423
00:47:57,440 --> 00:47:59,680
versus over there to gain information

1424
00:47:59,680 --> 00:48:01,839
right so explore exploit is you know

1425
00:48:01,839 --> 00:48:03,599
specifically in the realm of making

1426
00:48:03,599 --> 00:48:05,280
choosing actions that will minimize

1427
00:48:05,280 --> 00:48:06,480
uncertainty

1428
00:48:06,480 --> 00:48:09,839
versus maximize reward um this is this

1429
00:48:09,839 --> 00:48:11,599
is really more just

1430
00:48:11,599 --> 00:48:13,920
with with normal free energy right we're

1431
00:48:13,920 --> 00:48:15,520
not too expected free energy yet which

1432
00:48:15,520 --> 00:48:17,040
is the decision-making part

1433
00:48:17,040 --> 00:48:19,599
with normal free energy there's you can

1434
00:48:19,599 --> 00:48:21,440
think the simplest way to think about

1435
00:48:21,440 --> 00:48:25,119
um free energy is just in terms of

1436
00:48:25,119 --> 00:48:28,480
um complexity minus accuracy

1437
00:48:28,480 --> 00:48:30,800
which is equivalently complexity plus

1438
00:48:30,800 --> 00:48:32,160
prediction error

1439
00:48:32,160 --> 00:48:34,079
and all that all that ultimately means

1440
00:48:34,079 --> 00:48:35,839
is so the complexity thing is basically

1441
00:48:35,839 --> 00:48:37,760
how much you have to change your beliefs

1442
00:48:37,760 --> 00:48:41,520
um so it's basically saying what's the

1443
00:48:41,520 --> 00:48:44,800
minimum change in my beliefs that will

1444
00:48:44,800 --> 00:48:46,559
make my new beliefs as accurate as

1445
00:48:46,559 --> 00:48:48,480
possible right so i have to move my

1446
00:48:48,480 --> 00:48:50,559
beliefs as little as possible while also

1447
00:48:50,559 --> 00:48:53,200
minimizing prediction error

1448
00:48:53,200 --> 00:48:55,920
if that if that makes sense so this what

1449
00:48:55,920 --> 00:48:58,000
this generative model is saying is just

1450
00:48:58,000 --> 00:49:01,200
that the probability that we're in state

1451
00:49:01,200 --> 00:49:01,599
one

1452
00:49:01,599 --> 00:49:04,559
is point eight if i were to chew if if i

1453
00:49:04,559 --> 00:49:06,640
were to get this observation

1454
00:49:06,640 --> 00:49:08,800
where the probability of being in state

1455
00:49:08,800 --> 00:49:10,800
two is only point two where to get this

1456
00:49:10,800 --> 00:49:12,079
observation

1457
00:49:12,079 --> 00:49:15,200
right so so i mean the probably a better

1458
00:49:15,200 --> 00:49:16,559
example than the um

1459
00:49:16,559 --> 00:49:18,400
than the like heads and tails thing

1460
00:49:18,400 --> 00:49:19,680
would just be would just be something

1461
00:49:19,680 --> 00:49:21,760
like the concave complex example we gave

1462
00:49:21,760 --> 00:49:22,720
before

1463
00:49:22,720 --> 00:49:25,680
right there is some possibility where

1464
00:49:25,680 --> 00:49:27,280
where light from above

1465
00:49:27,280 --> 00:49:28,720
you know where light from below could

1466
00:49:28,720 --> 00:49:30,160
cause the shading pattern but it's just

1467
00:49:30,160 --> 00:49:31,599
much less likely

1468
00:49:31,599 --> 00:49:33,680
right so you're just trying to find the

1469
00:49:33,680 --> 00:49:34,720
the belief

1470
00:49:34,720 --> 00:49:36,880
right that it's convex and light from

1471
00:49:36,880 --> 00:49:38,079
above

1472
00:49:38,079 --> 00:49:39,920
that that is the one that most likely

1473
00:49:39,920 --> 00:49:42,319
generated what you're what you're seeing

1474
00:49:42,319 --> 00:49:43,680
and it might take a bunch of updates

1475
00:49:43,680 --> 00:49:46,640
like that given just what you see once

1476
00:49:46,640 --> 00:49:48,720
to kind of arrive at the best fitting

1477
00:49:48,720 --> 00:49:50,880
belief there's a related question

1478
00:49:50,880 --> 00:49:53,119
in the live chat that i'm just gonna ask

1479
00:49:53,119 --> 00:49:54,559
because it's on the topic

1480
00:49:54,559 --> 00:49:57,440
they asked is this approximate bayesian

1481
00:49:57,440 --> 00:49:58,319
inference thing

1482
00:49:58,319 --> 00:50:00,480
called something else in stats outside

1483
00:50:00,480 --> 00:50:02,480
of active inference or is this unique to

1484
00:50:02,480 --> 00:50:04,079
active inference because this isn't

1485
00:50:04,079 --> 00:50:06,079
sequential bayesian updating as you

1486
00:50:06,079 --> 00:50:06,800
mentioned

1487
00:50:06,800 --> 00:50:08,800
this isn't a standard bayesian filter

1488
00:50:08,800 --> 00:50:10,480
what is this called outside of the

1489
00:50:10,480 --> 00:50:12,240
active inference field

1490
00:50:12,240 --> 00:50:14,480
so yeah it's just variational bays

1491
00:50:14,480 --> 00:50:16,160
variational bays where does the

1492
00:50:16,160 --> 00:50:18,160
partially observable markov decision

1493
00:50:18,160 --> 00:50:20,079
process come into play

1494
00:50:20,079 --> 00:50:21,839
uh we'll cover that in a moment's time

1495
00:50:21,839 --> 00:50:23,119
actually yeah it doesn't

1496
00:50:23,119 --> 00:50:25,839
it doesn't yeah it doesn't come in yet

1497
00:50:25,839 --> 00:50:28,400
so i think one thing to say is kind of

1498
00:50:28,400 --> 00:50:29,839
writing this tutorial it's hard to

1499
00:50:29,839 --> 00:50:31,599
please everyone right like in going

1500
00:50:31,599 --> 00:50:33,599
through some of the feedback like we get

1501
00:50:33,599 --> 00:50:35,599
we got some feedback where people were

1502
00:50:35,599 --> 00:50:37,440
just like utterly confused

1503
00:50:37,440 --> 00:50:39,359
and wanting clear explanations and then

1504
00:50:39,359 --> 00:50:40,640
at the other end of the spectrum we

1505
00:50:40,640 --> 00:50:42,000
wanted there were people wanting much

1506
00:50:42,000 --> 00:50:43,520
more technical details like how does

1507
00:50:43,520 --> 00:50:44,640
this relate to things like gradient

1508
00:50:44,640 --> 00:50:45,280
descent

1509
00:50:45,280 --> 00:50:47,680
because this is just kind of a very

1510
00:50:47,680 --> 00:50:49,920
simplified cartoon example of something

1511
00:50:49,920 --> 00:50:50,960
called grading of

1512
00:50:50,960 --> 00:50:52,319
a gradient descent scheme where you're

1513
00:50:52,319 --> 00:50:54,000
doing a gradient descent

1514
00:50:54,000 --> 00:50:57,599
on free energy um and so i would just

1515
00:50:57,599 --> 00:50:58,960
say kind of the flag

1516
00:50:58,960 --> 00:51:02,240
of these issues is one i would say

1517
00:51:02,240 --> 00:51:04,079
if something's unclear in this

1518
00:51:04,079 --> 00:51:05,680
presentation read the paper because we

1519
00:51:05,680 --> 00:51:06,800
gave things

1520
00:51:06,800 --> 00:51:08,240
we cover things a lot more detail in the

1521
00:51:08,240 --> 00:51:10,160
paper and if that isn't technical enough

1522
00:51:10,160 --> 00:51:10,720
for you

1523
00:51:10,720 --> 00:51:13,040
actually go and just look at our code we

1524
00:51:13,040 --> 00:51:13,839
supply

1525
00:51:13,839 --> 00:51:17,280
a kind of standalone script where we

1526
00:51:17,280 --> 00:51:19,040
it's extreme and it's extremely well

1527
00:51:19,040 --> 00:51:20,880
commented and from there you should be

1528
00:51:20,880 --> 00:51:22,079
able to figure out everything that's

1529
00:51:22,079 --> 00:51:24,480
going on

1530
00:51:24,720 --> 00:51:26,000
so all of this stuff in this

1531
00:51:26,000 --> 00:51:27,520
presentation is kind of necessarily

1532
00:51:27,520 --> 00:51:28,880
simplified because you don't

1533
00:51:28,880 --> 00:51:31,280
really need those technical details to

1534
00:51:31,280 --> 00:51:32,079
kind of start

1535
00:51:32,079 --> 00:51:34,559
using the framework or start getting

1536
00:51:34,559 --> 00:51:36,880
intuition for how things work

1537
00:51:36,880 --> 00:51:38,559
but once you do have an intuition and

1538
00:51:38,559 --> 00:51:40,640
you want more just go and see the code

1539
00:51:40,640 --> 00:51:44,000
i would say um awesome

1540
00:51:44,000 --> 00:51:46,480
it's like you can use the anova package

1541
00:51:46,480 --> 00:51:47,280
in our

1542
00:51:47,280 --> 00:51:49,359
without going into the source code it's

1543
00:51:49,359 --> 00:51:51,520
helpful it's a tool for scientists

1544
00:51:51,520 --> 00:51:52,960
and then if you're curious about the

1545
00:51:52,960 --> 00:51:54,640
underpinnings of statistics

1546
00:51:54,640 --> 00:51:56,960
and perennial philosophical debates

1547
00:51:56,960 --> 00:51:58,079
there's a literature

1548
00:51:58,079 --> 00:52:00,640
and a search bar but today it's about

1549
00:52:00,640 --> 00:52:02,559
the applications of these methods

1550
00:52:02,559 --> 00:52:04,400
which is awesome so thanks for everyone

1551
00:52:04,400 --> 00:52:05,839
for the questions keep them coming but

1552
00:52:05,839 --> 00:52:06,559
this is great

1553
00:52:06,559 --> 00:52:09,599
discussion i really appreciate it

1554
00:52:09,599 --> 00:52:11,839
okay and so just kind of to recap there

1555
00:52:11,839 --> 00:52:13,200
i haven't covered action yet i'm going

1556
00:52:13,200 --> 00:52:14,880
to cover action a little bit

1557
00:52:14,880 --> 00:52:17,599
but just kind of to recap the idea is

1558
00:52:17,599 --> 00:52:18,960
under active inference

1559
00:52:18,960 --> 00:52:21,359
organisms are kind of we model them as

1560
00:52:21,359 --> 00:52:22,079
if

1561
00:52:22,079 --> 00:52:24,079
their phenotype is in their body and

1562
00:52:24,079 --> 00:52:25,440
their brain kind of embodies a

1563
00:52:25,440 --> 00:52:27,520
generative model of the environment

1564
00:52:27,520 --> 00:52:30,079
and organisms kind of invert a generated

1565
00:52:30,079 --> 00:52:31,200
model to arrive in

1566
00:52:31,200 --> 00:52:33,839
approximate posterior distribution over

1567
00:52:33,839 --> 00:52:35,599
the hidden causes of sensory input

1568
00:52:35,599 --> 00:52:36,960
and they do this by minimizing

1569
00:52:36,960 --> 00:52:39,280
variational free energy

1570
00:52:39,280 --> 00:52:40,800
so that should that much should

1571
00:52:40,800 --> 00:52:44,000
hopefully be clear by this point

1572
00:52:44,000 --> 00:52:46,000
and so then on to the generative model

1573
00:52:46,000 --> 00:52:47,760
and it is a very specific type of

1574
00:52:47,760 --> 00:52:48,640
generative model

1575
00:52:48,640 --> 00:52:50,000
namely it's a partially observable

1576
00:52:50,000 --> 00:52:51,839
markov decision process

1577
00:52:51,839 --> 00:52:53,359
and so there's kind of a graphical

1578
00:52:53,359 --> 00:52:55,280
representation of this as a bayesian

1579
00:52:55,280 --> 00:52:55,839
network

1580
00:52:55,839 --> 00:52:57,440
on the right-hand side and i'm not going

1581
00:52:57,440 --> 00:52:59,599
to kind of give give too much detail

1582
00:52:59,599 --> 00:53:00,000
about this

1583
00:53:00,000 --> 00:53:02,240
right now i will actually build it up

1584
00:53:02,240 --> 00:53:03,440
step by step

1585
00:53:03,440 --> 00:53:06,640
but just kind of prelude the idea with

1586
00:53:06,640 --> 00:53:07,839
pomdps

1587
00:53:07,839 --> 00:53:09,680
is that they describe transitions among

1588
00:53:09,680 --> 00:53:12,079
hidden unobservable variables

1589
00:53:12,079 --> 00:53:14,000
and the sensory data that's generated by

1590
00:53:14,000 --> 00:53:16,160
the variables whoops

1591
00:53:16,160 --> 00:53:20,319
so those arrows mapping from states

1592
00:53:20,319 --> 00:53:25,280
to observations are kind of give

1593
00:53:25,280 --> 00:53:26,880
information about the direction of

1594
00:53:26,880 --> 00:53:30,400
influence or conditional indepen

1595
00:53:30,400 --> 00:53:32,559
conditional influence so kind of the

1596
00:53:32,559 --> 00:53:34,240
arrow between the purple

1597
00:53:34,240 --> 00:53:37,760
node o and the green node s

1598
00:53:37,760 --> 00:53:40,480
is mediated by the a matrix which is a

1599
00:53:40,480 --> 00:53:41,520
likelihood

1600
00:53:41,520 --> 00:53:43,680
and the transitions between states are

1601
00:53:43,680 --> 00:53:44,720
mediated by a b

1602
00:53:44,720 --> 00:53:47,839
matrix which is a transition probability

1603
00:53:47,839 --> 00:53:49,920
and so the goal of active inference with

1604
00:53:49,920 --> 00:53:51,280
pomdps

1605
00:53:51,280 --> 00:53:54,880
is to infer states and action sequences

1606
00:53:54,880 --> 00:53:56,079
or policies

1607
00:53:56,079 --> 00:53:58,480
by minimizing various forms of

1608
00:53:58,480 --> 00:54:01,599
variational free energy

1609
00:54:01,599 --> 00:54:03,680
okay so start with a really really

1610
00:54:03,680 --> 00:54:04,720
simple example

1611
00:54:04,720 --> 00:54:07,920
we have static inference and the idea

1612
00:54:07,920 --> 00:54:09,599
with static inference

1613
00:54:09,599 --> 00:54:11,359
is this this is just a graphical

1614
00:54:11,359 --> 00:54:13,440
representation of

1615
00:54:13,440 --> 00:54:16,559
bayes rule essentially we have a

1616
00:54:16,559 --> 00:54:19,520
prior which is encoded in our d vector

1617
00:54:19,520 --> 00:54:21,200
we have a likelihood

1618
00:54:21,200 --> 00:54:23,520
encoded in our a matrix and we end up

1619
00:54:23,520 --> 00:54:25,119
with an update equation

1620
00:54:25,119 --> 00:54:26,960
which is a soft max function a softmax

1621
00:54:26,960 --> 00:54:28,800
function is a normalized exponential

1622
00:54:28,800 --> 00:54:31,200
whoops

1623
00:54:31,920 --> 00:54:33,920
and so i'm not going to kind of run

1624
00:54:33,920 --> 00:54:35,280
through that explanation

1625
00:54:35,280 --> 00:54:36,559
in detail i'm just going to kind of

1626
00:54:36,559 --> 00:54:37,839
leave the slide here so people can

1627
00:54:37,839 --> 00:54:39,200
figure it out for themselves and pause

1628
00:54:39,200 --> 00:54:40,720
and go back and convince themselves that

1629
00:54:40,720 --> 00:54:41,599
this is true

1630
00:54:41,599 --> 00:54:44,559
but for this very simple example uh the

1631
00:54:44,559 --> 00:54:45,920
active the inference scheme that we're

1632
00:54:45,920 --> 00:54:47,440
using here is formally equivalent it's

1633
00:54:47,440 --> 00:54:48,000
just an

1634
00:54:48,000 --> 00:54:51,040
exact inference scheme so

1635
00:54:51,040 --> 00:54:53,520
moving into dynamic models specifically

1636
00:54:53,520 --> 00:54:54,480
so where states

1637
00:54:54,480 --> 00:54:56,240
change over time these are also called

1638
00:54:56,240 --> 00:54:57,920
hidden markov models

1639
00:54:57,920 --> 00:54:59,599
this is when we have to start making

1640
00:54:59,599 --> 00:55:01,440
approximate or when things are no longer

1641
00:55:01,440 --> 00:55:03,920
equivalent to a prop

1642
00:55:03,920 --> 00:55:05,440
using active inference are no longer

1643
00:55:05,440 --> 00:55:07,520
equivalent to

1644
00:55:07,520 --> 00:55:10,880
exact inference and so

1645
00:55:10,880 --> 00:55:13,599
here we have our transition

1646
00:55:13,599 --> 00:55:15,280
probabilities encoded in a b

1647
00:55:15,280 --> 00:55:17,440
matrix and this is just essentially like

1648
00:55:17,440 --> 00:55:19,040
the probability of some state at t

1649
00:55:19,040 --> 00:55:21,280
plus one conditioned on the previous

1650
00:55:21,280 --> 00:55:22,559
state

1651
00:55:22,559 --> 00:55:24,079
and so you can see over here in terms of

1652
00:55:24,079 --> 00:55:26,079
the update equations we're now in we're

1653
00:55:26,079 --> 00:55:26,880
in log space

1654
00:55:26,880 --> 00:55:28,720
and this little sigma thing here is a

1655
00:55:28,720 --> 00:55:30,960
softmax function which just normalizes

1656
00:55:30,960 --> 00:55:32,079
this equation

1657
00:55:32,079 --> 00:55:34,319
and the idea is is that this is kind of

1658
00:55:34,319 --> 00:55:36,400
sorry my screen keeps flipping um

1659
00:55:36,400 --> 00:55:39,920
anyway uh the combination of d

1660
00:55:39,920 --> 00:55:42,160
and b so our two priors in addition to

1661
00:55:42,160 --> 00:55:44,000
our likelihood

1662
00:55:44,000 --> 00:55:46,240
will give us the approximate posterior

1663
00:55:46,240 --> 00:55:47,839
and the reason we have this one half in

1664
00:55:47,839 --> 00:55:48,559
front

1665
00:55:48,559 --> 00:55:50,559
is just because in practice the

1666
00:55:50,559 --> 00:55:52,000
approximation scheme that's used by

1667
00:55:52,000 --> 00:55:54,559
active inference namely

1668
00:55:54,559 --> 00:55:56,720
variational message passing tends to

1669
00:55:56,720 --> 00:55:58,079
overestimate

1670
00:55:58,079 --> 00:55:59,920
kind of the value of the posterior and

1671
00:55:59,920 --> 00:56:01,040
so this is kind of just a way of

1672
00:56:01,040 --> 00:56:02,480
compensating for that and so anyone's

1673
00:56:02,480 --> 00:56:03,920
kind of interested in technical details

1674
00:56:03,920 --> 00:56:04,400
there

1675
00:56:04,400 --> 00:56:06,160
see thomas parr has a really excellent

1676
00:56:06,160 --> 00:56:07,680
paper out in scientific reports on

1677
00:56:07,680 --> 00:56:09,520
neuronal message passing schemes

1678
00:56:09,520 --> 00:56:12,480
under various approximations to free

1679
00:56:12,480 --> 00:56:14,160
energy

1680
00:56:14,160 --> 00:56:16,000
okay and so then the form of the free

1681
00:56:16,000 --> 00:56:18,000
energy is just down here

1682
00:56:18,000 --> 00:56:20,000
um and so the idea is is that by

1683
00:56:20,000 --> 00:56:22,079
iteratively applying these

1684
00:56:22,079 --> 00:56:26,400
updates we minimize free energy

1685
00:56:26,480 --> 00:56:29,760
and you iteratively kind of every you

1686
00:56:29,760 --> 00:56:32,000
start you do a full round of updating

1687
00:56:32,000 --> 00:56:33,119
every time you get a new

1688
00:56:33,119 --> 00:56:35,680
observation

1689
00:56:36,480 --> 00:56:39,440
okay but what about policy selection so

1690
00:56:39,440 --> 00:56:41,359
the idea with policy selection is

1691
00:56:41,359 --> 00:56:42,640
roughly speaking

1692
00:56:42,640 --> 00:56:45,280
that policies are just state transitions

1693
00:56:45,280 --> 00:56:46,880
that the agent has control over

1694
00:56:46,880 --> 00:56:49,520
so imagine you are a psychophysics

1695
00:56:49,520 --> 00:56:50,480
experimenter

1696
00:56:50,480 --> 00:56:52,319
and you have just a very simple boring

1697
00:56:52,319 --> 00:56:54,559
example of someone kind of

1698
00:56:54,559 --> 00:56:57,440
uh say estimating the orientation of

1699
00:56:57,440 --> 00:56:59,040
some hard to see stimulus

1700
00:56:59,040 --> 00:57:01,040
and so the policy space there is tiny

1701
00:57:01,040 --> 00:57:02,720
it's two options it's left or right

1702
00:57:02,720 --> 00:57:04,000
let's say

1703
00:57:04,000 --> 00:57:05,920
or you could have an agent that you

1704
00:57:05,920 --> 00:57:07,040
could be simulating something more

1705
00:57:07,040 --> 00:57:08,400
interesting in psychophysics

1706
00:57:08,400 --> 00:57:09,680
you could be simulating an agent

1707
00:57:09,680 --> 00:57:12,000
navigating a maze and then the policy

1708
00:57:12,000 --> 00:57:13,440
space is much larger they could go

1709
00:57:13,440 --> 00:57:14,640
forward they could move forwards

1710
00:57:14,640 --> 00:57:15,359
backwards

1711
00:57:15,359 --> 00:57:18,799
left right et cetera et cetera

1712
00:57:18,880 --> 00:57:21,119
and so the idea is is that active

1713
00:57:21,119 --> 00:57:23,040
inference agents by definition

1714
00:57:23,040 --> 00:57:24,240
need to select policies that will

1715
00:57:24,240 --> 00:57:26,640
minimize variational free energy

1716
00:57:26,640 --> 00:57:29,680
but that relies upon

1717
00:57:29,680 --> 00:57:32,160
observations that have yet to come so

1718
00:57:32,160 --> 00:57:34,400
that's kind of a problem

1719
00:57:34,400 --> 00:57:36,160
but the way around this is to treat

1720
00:57:36,160 --> 00:57:38,799
observations as random variables

1721
00:57:38,799 --> 00:57:41,200
and then what you do is you minimize an

1722
00:57:41,200 --> 00:57:43,280
approximation not to surprise which is

1723
00:57:43,280 --> 00:57:45,200
variational for energy but to expected

1724
00:57:45,200 --> 00:57:46,079
surprise

1725
00:57:46,079 --> 00:57:48,000
and that approximation to expected

1726
00:57:48,000 --> 00:57:49,440
surprise

1727
00:57:49,440 --> 00:57:52,480
is expected free energy and so this

1728
00:57:52,480 --> 00:57:54,079
expected for energy has two

1729
00:57:54,079 --> 00:57:57,119
key components the first is the expected

1730
00:57:57,119 --> 00:57:57,920
cost

1731
00:57:57,920 --> 00:58:00,160
and this kind of minimize the idea here

1732
00:58:00,160 --> 00:58:02,079
is to minimize expected cost

1733
00:58:02,079 --> 00:58:03,680
you need to minimize the deviation

1734
00:58:03,680 --> 00:58:05,520
between our predicted and our preferred

1735
00:58:05,520 --> 00:58:06,240
outcomes

1736
00:58:06,240 --> 00:58:07,520
and so this is kind of what we were

1737
00:58:07,520 --> 00:58:08,480
talking about ryan was talking about

1738
00:58:08,480 --> 00:58:09,920
before so this c vector

1739
00:58:09,920 --> 00:58:12,000
encodes a distribution over an agent's

1740
00:58:12,000 --> 00:58:13,280
preferences

1741
00:58:13,280 --> 00:58:16,799
so for example policies that minimize

1742
00:58:16,799 --> 00:58:17,920
expected costs

1743
00:58:17,920 --> 00:58:19,839
are policies that kind of bring about

1744
00:58:19,839 --> 00:58:22,480
observations that the agent prefers

1745
00:58:22,480 --> 00:58:25,440
for example so if i prefer to kind of

1746
00:58:25,440 --> 00:58:26,000
have

1747
00:58:26,000 --> 00:58:27,760
my body temperature within a certain

1748
00:58:27,760 --> 00:58:29,680
range the policy would be

1749
00:58:29,680 --> 00:58:31,200
maybe staying inside because i live in

1750
00:58:31,200 --> 00:58:32,480
england and it's like negative one

1751
00:58:32,480 --> 00:58:33,920
outside

1752
00:58:33,920 --> 00:58:36,960
um for example now

1753
00:58:36,960 --> 00:58:40,160
expected ambiguity is a little bit this

1754
00:58:40,160 --> 00:58:42,160
this is kind of the epistemic drive or

1755
00:58:42,160 --> 00:58:43,839
the information gain term

1756
00:58:43,839 --> 00:58:46,480
this is kind of the expected entropy of

1757
00:58:46,480 --> 00:58:48,240
our likelihood distribution

1758
00:58:48,240 --> 00:58:50,319
so the idea here is that to minimize

1759
00:58:50,319 --> 00:58:51,839
ambiguity

1760
00:58:51,839 --> 00:58:53,599
you will have an a matrix right an a

1761
00:58:53,599 --> 00:58:54,880
matrix if

1762
00:58:54,880 --> 00:58:56,559
the idea is to minimize kind of

1763
00:58:56,559 --> 00:58:58,559
ambiguity you need to select

1764
00:58:58,559 --> 00:59:01,839
observations in that a matrix that

1765
00:59:01,839 --> 00:59:05,119
are maximally precise and so to return

1766
00:59:05,119 --> 00:59:05,599
to

1767
00:59:05,599 --> 00:59:08,559
or take actions even that will make

1768
00:59:08,559 --> 00:59:10,400
those things that a matrix maximally

1769
00:59:10,400 --> 00:59:11,440
precise

1770
00:59:11,440 --> 00:59:13,280
and so if i'm in a dark room to give an

1771
00:59:13,280 --> 00:59:15,520
example before the thing that will make

1772
00:59:15,520 --> 00:59:19,040
or select kind of met or policies that

1773
00:59:19,040 --> 00:59:20,480
will make that distribution maximally

1774
00:59:20,480 --> 00:59:21,119
precise

1775
00:59:21,119 --> 00:59:24,160
are policies like turning light on

1776
00:59:24,160 --> 00:59:26,240
and so then to minimize free energy as a

1777
00:59:26,240 --> 00:59:27,920
whole you have to minimize both of these

1778
00:59:27,920 --> 00:59:29,520
things

1779
00:59:29,520 --> 00:59:31,280
and you can do this in terms of one-step

1780
00:59:31,280 --> 00:59:33,280
policies just looking one step ahead

1781
00:59:33,280 --> 00:59:35,280
or you can do it look in using deep

1782
00:59:35,280 --> 00:59:38,880
policies looking many many steps ahead

1783
00:59:38,880 --> 00:59:40,000
hopefully that's pretty clear is there

1784
00:59:40,000 --> 00:59:41,200
anything you'd like to add to that ryan

1785
00:59:41,200 --> 00:59:42,160
or

1786
00:59:42,160 --> 00:59:45,440
daniel anyone else yeah i mean i guess

1787
00:59:45,440 --> 00:59:46,799
i'll i guess i'll just say i mean to

1788
00:59:46,799 --> 00:59:48,160
just to make it kind of as

1789
00:59:48,160 --> 00:59:50,640
as clear and explicit as possible for

1790
00:59:50,640 --> 00:59:52,400
people who don't have a background in

1791
00:59:52,400 --> 00:59:54,480
you know and what this whole thing you

1792
00:59:54,480 --> 00:59:55,599
know what the seclusion

1793
00:59:55,599 --> 00:59:58,319
means right so the idea is just if you

1794
00:59:58,319 --> 01:00:01,280
look at that term above expected cost

1795
01:00:01,280 --> 01:00:04,000
that's called a kl divergence and so

1796
01:00:04,000 --> 01:00:05,520
basically it's just a value

1797
01:00:05,520 --> 01:00:07,520
that encodes the difference between two

1798
01:00:07,520 --> 01:00:09,440
distributions or the dissimilarity

1799
01:00:09,440 --> 01:00:11,440
between two distributions

1800
01:00:11,440 --> 01:00:14,559
and so that first one that q o given pi

1801
01:00:14,559 --> 01:00:17,040
that's just saying what observations do

1802
01:00:17,040 --> 01:00:18,319
i expect

1803
01:00:18,319 --> 01:00:20,319
given that i choose to do this versus

1804
01:00:20,319 --> 01:00:22,240
that um

1805
01:00:22,240 --> 01:00:24,640
then that second one that p of o that's

1806
01:00:24,640 --> 01:00:27,040
the preferences

1807
01:00:27,040 --> 01:00:28,799
so basically what it's trying to do is

1808
01:00:28,799 --> 01:00:31,839
just minimize the difference between

1809
01:00:31,839 --> 01:00:34,480
your your preferred observations and the

1810
01:00:34,480 --> 01:00:36,559
observations that you expect

1811
01:00:36,559 --> 01:00:38,480
given that you choose to do you know

1812
01:00:38,480 --> 01:00:40,400
thing one versus thing two

1813
01:00:40,400 --> 01:00:42,000
um so it's really just choosing the

1814
01:00:42,000 --> 01:00:43,680
thing that's going to get you as close

1815
01:00:43,680 --> 01:00:45,119
to that you think is going to get you as

1816
01:00:45,119 --> 01:00:47,119
close to what you want as possible

1817
01:00:47,119 --> 01:00:49,119
it's very just you know reward seeking

1818
01:00:49,119 --> 01:00:50,720
more or less

1819
01:00:50,720 --> 01:00:52,000
and that second one the expected

1820
01:00:52,000 --> 01:00:54,160
ambiguity that each thing

1821
01:00:54,160 --> 01:00:57,280
stands for entropy and basically entropy

1822
01:00:57,280 --> 01:00:58,240
is just

1823
01:00:58,240 --> 01:01:00,720
the higher the entropy the flatter a

1824
01:01:00,720 --> 01:01:02,079
distribution is

1825
01:01:02,079 --> 01:01:03,680
so think of a distribution that's like

1826
01:01:03,680 --> 01:01:06,079
one is like 0.5.5 and the other one's

1827
01:01:06,079 --> 01:01:08,559
like 0.8.2

1828
01:01:08,559 --> 01:01:09,920
if you chose the state that would

1829
01:01:09,920 --> 01:01:11,680
generate 0.5.5

1830
01:01:11,680 --> 01:01:14,160
over observations then it wouldn't tell

1831
01:01:14,160 --> 01:01:15,040
you anything

1832
01:01:15,040 --> 01:01:17,280
because either observation you got it'd

1833
01:01:17,280 --> 01:01:18,240
tell you

1834
01:01:18,240 --> 01:01:20,880
there's a 0.5 probability that you're in

1835
01:01:20,880 --> 01:01:22,480
one state and a 0.5 probability you're

1836
01:01:22,480 --> 01:01:23,680
in the other state

1837
01:01:23,680 --> 01:01:26,079
right whereas the other state would

1838
01:01:26,079 --> 01:01:28,480
generate a 0.8 or a 0.2

1839
01:01:28,480 --> 01:01:30,559
then that one will give you a lot more

1840
01:01:30,559 --> 01:01:32,079
information because you observe if you

1841
01:01:32,079 --> 01:01:34,079
observe the thing that indicates 0.8

1842
01:01:34,079 --> 01:01:35,680
then you're really confident what state

1843
01:01:35,680 --> 01:01:37,520
you're in

1844
01:01:37,520 --> 01:01:39,200
and if or if you observe point two

1845
01:01:39,200 --> 01:01:40,319
you're really confident you're not in

1846
01:01:40,319 --> 01:01:41,200
that state

1847
01:01:41,200 --> 01:01:43,920
right so you're just seeking out the

1848
01:01:43,920 --> 01:01:44,480
thing

1849
01:01:44,480 --> 01:01:46,400
that you think will get you what you

1850
01:01:46,400 --> 01:01:48,319
want as much as possible

1851
01:01:48,319 --> 01:01:51,280
but also moving to the states that are

1852
01:01:51,280 --> 01:01:52,000
going to

1853
01:01:52,000 --> 01:01:53,440
give you the observation that's going to

1854
01:01:53,440 --> 01:01:56,480
tell you the most about where you are

1855
01:01:56,480 --> 01:01:58,480
if that if that if that makes sense so

1856
01:01:58,480 --> 01:02:00,400
just again just for people who

1857
01:02:00,400 --> 01:02:02,079
who aren't necessarily as familiar with

1858
01:02:02,079 --> 01:02:03,680
reading the the kind of

1859
01:02:03,680 --> 01:02:06,559
notation in these equations thank you

1860
01:02:06,559 --> 01:02:08,160
max

1861
01:02:08,160 --> 01:02:09,839
um yeah just one one point of

1862
01:02:09,839 --> 01:02:11,280
clarification and then i just wanted to

1863
01:02:11,280 --> 01:02:12,799
tie it back to what we the example we

1864
01:02:12,799 --> 01:02:13,920
discussed previously

1865
01:02:13,920 --> 01:02:15,520
so first i want to just make sure i'm

1866
01:02:15,520 --> 01:02:16,960
understanding correctly that the d

1867
01:02:16,960 --> 01:02:20,240
in that equation is the the kl

1868
01:02:20,240 --> 01:02:22,000
uh the diverge so that's the that's an

1869
01:02:22,000 --> 01:02:23,680
operator it's not the same as the d

1870
01:02:23,680 --> 01:02:25,760
that's in the figure uh in the block

1871
01:02:25,760 --> 01:02:26,960
diagram well that's

1872
01:02:26,960 --> 01:02:29,680
that's the kl divergence that's a yeah

1873
01:02:29,680 --> 01:02:31,119
that's kind of a standard way of

1874
01:02:31,119 --> 01:02:32,640
representing it in other papers that's

1875
01:02:32,640 --> 01:02:34,240
just kind of paste it in but

1876
01:02:34,240 --> 01:02:35,680
um it's not very clear that should be

1877
01:02:35,680 --> 01:02:37,920
the kl it has nothing to do with d

1878
01:02:37,920 --> 01:02:41,839
d sub n the d that's in this graphic

1879
01:02:41,839 --> 01:02:44,240
in the block diagram would that be

1880
01:02:44,240 --> 01:02:46,240
analogous in our previous example where

1881
01:02:46,240 --> 01:02:47,680
we were talking it when when we

1882
01:02:47,680 --> 01:02:49,680
illustrated step by step that would be

1883
01:02:49,680 --> 01:02:50,000
our

1884
01:02:50,000 --> 01:02:53,280
0.5 0.5 but it in this context could be

1885
01:02:53,280 --> 01:02:55,119
much more complicated than that

1886
01:02:55,119 --> 01:02:57,039
yeah in a simple example yeah it would

1887
01:02:57,039 --> 01:02:58,400
just be your your prior

1888
01:02:58,400 --> 01:03:01,280
right so if ahead of time you think that

1889
01:03:01,280 --> 01:03:02,240
like

1890
01:03:02,240 --> 01:03:05,039
ice cream is more likely than donuts

1891
01:03:05,039 --> 01:03:05,760
right

1892
01:03:05,760 --> 01:03:08,720
then that could just be like 0.8.2 you

1893
01:03:08,720 --> 01:03:09,440
know that's

1894
01:03:09,440 --> 01:03:11,039
or if you have no idea whether it's

1895
01:03:11,039 --> 01:03:12,400
going to be ice cream or donuts it could

1896
01:03:12,400 --> 01:03:13,920
be 0.5.5

1897
01:03:13,920 --> 01:03:17,359
and for and for anyone who is uh

1898
01:03:17,359 --> 01:03:19,520
like wanting to get into optimization

1899
01:03:19,520 --> 01:03:20,400
and how do we know

1900
01:03:20,400 --> 01:03:22,799
whether or not this is going to converge

1901
01:03:22,799 --> 01:03:24,400
when we do our message passage

1902
01:03:24,400 --> 01:03:26,400
our message passing algorithm back and

1903
01:03:26,400 --> 01:03:27,839
forth there was a

1904
01:03:27,839 --> 01:03:30,000
really good citation and that's the one

1905
01:03:30,000 --> 01:03:30,880
that was alluded to

1906
01:03:30,880 --> 01:03:32,880
at the beginning of this uh on the

1907
01:03:32,880 --> 01:03:34,960
slides right the technical papers is

1908
01:03:34,960 --> 01:03:36,000
that correct

1909
01:03:36,000 --> 01:03:38,000
uh so the citation to do with message

1910
01:03:38,000 --> 01:03:39,599
passing in particular is a paper by

1911
01:03:39,599 --> 01:03:41,039
thomas parr

1912
01:03:41,039 --> 01:03:45,520
so that is in scientific reports um

1913
01:03:45,520 --> 01:03:47,280
yeah we can i i think do you have show

1914
01:03:47,280 --> 01:03:49,119
notes i i assume we can yes

1915
01:03:49,119 --> 01:03:51,440
please i have a couple other general

1916
01:03:51,440 --> 01:03:52,720
questions from the

1917
01:03:52,720 --> 01:03:54,559
live chat but i think we'll take them at

1918
01:03:54,559 --> 01:03:56,960
the end of your presentation

1919
01:03:56,960 --> 01:03:58,400
as we turn towards some of the

1920
01:03:58,400 --> 01:04:00,480
neurobiology beginnings and

1921
01:04:00,480 --> 01:04:02,400
um a few other aspects so continue

1922
01:04:02,400 --> 01:04:04,559
christopher yeah cool thank you

1923
01:04:04,559 --> 01:04:07,520
um okay and so then kind of just to

1924
01:04:07,520 --> 01:04:10,160
close or just to briefly recap

1925
01:04:10,160 --> 01:04:12,880
so there are multiple stages to this to

1926
01:04:12,880 --> 01:04:14,000
policy selection

1927
01:04:14,000 --> 01:04:16,559
so under a generative model that has

1928
01:04:16,559 --> 01:04:17,839
multiple policies

1929
01:04:17,839 --> 01:04:19,920
you need to minimize you minimize your

1930
01:04:19,920 --> 01:04:22,400
free energy with respect to each policy

1931
01:04:22,400 --> 01:04:24,480
your variational free energy and so you

1932
01:04:24,480 --> 01:04:25,599
might think about this as

1933
01:04:25,599 --> 01:04:26,960
say you're coming to a set of traffic

1934
01:04:26,960 --> 01:04:29,200
lights and

1935
01:04:29,200 --> 01:04:30,480
you have a whole bunch you could turn

1936
01:04:30,480 --> 01:04:32,640
left right or go straight ahead

1937
01:04:32,640 --> 01:04:34,960
those actions are possible but you then

1938
01:04:34,960 --> 01:04:35,920
get

1939
01:04:35,920 --> 01:04:37,839
sensory input that says there's a no

1940
01:04:37,839 --> 01:04:39,680
left turn sign

1941
01:04:39,680 --> 01:04:42,319
so that would make that policy give an

1942
01:04:42,319 --> 01:04:44,559
extremely high free energy value

1943
01:04:44,559 --> 01:04:46,000
and so that would eliminate it from the

1944
01:04:46,000 --> 01:04:48,160
plausible policies that you can kind of

1945
01:04:48,160 --> 01:04:50,880
evaluate right

1946
01:04:50,880 --> 01:04:53,280
and so then expected fringe is what we

1947
01:04:53,280 --> 01:04:54,480
just talked about

1948
01:04:54,480 --> 01:04:56,720
and the posterior distribution is

1949
01:04:56,720 --> 01:04:57,599
actually

1950
01:04:57,599 --> 01:05:00,160
uh the net soft max function over both

1951
01:05:00,160 --> 01:05:02,000
of these and so this because

1952
01:05:02,000 --> 01:05:04,640
kind of this is these are both negatives

1953
01:05:04,640 --> 01:05:06,960
um

1954
01:05:06,960 --> 01:05:09,200
policies that best minimize both

1955
01:05:09,200 --> 01:05:10,880
variational free energy and expected

1956
01:05:10,880 --> 01:05:11,599
free energy

1957
01:05:11,599 --> 01:05:15,520
will have the highest posterior value

1958
01:05:15,520 --> 01:05:18,079
um and then kind of is that is that

1959
01:05:18,079 --> 01:05:19,760
clear there are a couple of caveats to

1960
01:05:19,760 --> 01:05:20,559
all of this

1961
01:05:20,559 --> 01:05:24,160
um but just wanting to make sure ryan do

1962
01:05:24,160 --> 01:05:25,440
you want to add a thing here

1963
01:05:25,440 --> 01:05:27,280
well i just say just just so anybody who

1964
01:05:27,280 --> 01:05:29,119
doesn't know like what a

1965
01:05:29,119 --> 01:05:32,000
what a soft max function is yeah so so

1966
01:05:32,000 --> 01:05:32,720
all that

1967
01:05:32,720 --> 01:05:34,960
all that means is that like for instance

1968
01:05:34,960 --> 01:05:35,760
when you take

1969
01:05:35,760 --> 01:05:38,720
minus f minus g um that's not going to

1970
01:05:38,720 --> 01:05:40,000
give you something that's a true

1971
01:05:40,000 --> 01:05:41,440
probability distribution

1972
01:05:41,440 --> 01:05:43,280
right it's not going to be a thing that

1973
01:05:43,280 --> 01:05:45,359
sums to 1 right where probabilities all

1974
01:05:45,359 --> 01:05:46,799
together sum to 1.

1975
01:05:46,799 --> 01:05:48,559
what it's going to do is give you this

1976
01:05:48,559 --> 01:05:49,920
negative you know a bunch of negative

1977
01:05:49,920 --> 01:05:50,799
numbers

1978
01:05:50,799 --> 01:05:54,319
right so the softmax function does is it

1979
01:05:54,319 --> 01:05:56,799
normalizes that which just means that it

1980
01:05:56,799 --> 01:05:58,960
takes the kind of relative values

1981
01:05:58,960 --> 01:06:00,720
you know of each of those things and

1982
01:06:00,720 --> 01:06:02,160
turns it into

1983
01:06:02,160 --> 01:06:04,319
a probability distribution that sums to

1984
01:06:04,319 --> 01:06:05,520
one so

1985
01:06:05,520 --> 01:06:08,960
so you end up with that bolded pi symbol

1986
01:06:08,960 --> 01:06:11,599
is just a a probability distribution

1987
01:06:11,599 --> 01:06:12,400
that's assigned

1988
01:06:12,400 --> 01:06:14,480
a pro that assigns a probability to each

1989
01:06:14,480 --> 01:06:16,960
possible policy

1990
01:06:16,960 --> 01:06:18,640
and a policy by the way is just a

1991
01:06:18,640 --> 01:06:20,240
sequence of actions

1992
01:06:20,240 --> 01:06:22,160
right so one policy might be like turn

1993
01:06:22,160 --> 01:06:23,920
left turn right and another policy might

1994
01:06:23,920 --> 01:06:25,680
be turn right turn left

1995
01:06:25,680 --> 01:06:29,520
um and so it's just saying that um

1996
01:06:29,520 --> 01:06:32,720
that that minus f minus g thing will

1997
01:06:32,720 --> 01:06:34,319
just be turned into a probability

1998
01:06:34,319 --> 01:06:35,520
distribution

1999
01:06:35,520 --> 01:06:37,440
and that probability distribution over

2000
01:06:37,440 --> 01:06:39,520
different policies is what the

2001
01:06:39,520 --> 01:06:41,920
uh agent will sample from right so if

2002
01:06:41,920 --> 01:06:42,559
the

2003
01:06:42,559 --> 01:06:45,119
if pi says this policy is 0.8 and this

2004
01:06:45,119 --> 01:06:47,039
other policy is 0.2

2005
01:06:47,039 --> 01:06:48,960
then the agent will be a lot more likely

2006
01:06:48,960 --> 01:06:50,960
to choose the policy that's 0.8

2007
01:06:50,960 --> 01:06:53,760
yeah maybe go to the last caveat slide

2008
01:06:53,760 --> 01:06:54,319
and then

2009
01:06:54,319 --> 01:06:55,839
i have a few other questions where we'll

2010
01:06:55,839 --> 01:06:57,520
just try to like have a question

2011
01:06:57,520 --> 01:06:59,760
simple answer question simple answer and

2012
01:06:59,760 --> 01:07:01,200
then we'll move into the part two screen

2013
01:07:01,200 --> 01:07:02,480
share

2014
01:07:02,480 --> 01:07:05,599
okay so the two caveats are just a there

2015
01:07:05,599 --> 01:07:08,319
are two extra components of the pl mdp

2016
01:07:08,319 --> 01:07:11,359
that is namely the e

2017
01:07:11,359 --> 01:07:13,440
vector which you can see is kind of

2018
01:07:13,440 --> 01:07:15,039
pointing to

2019
01:07:15,039 --> 01:07:17,119
or there's that e block that's pointing

2020
01:07:17,119 --> 01:07:18,720
to policies

2021
01:07:18,720 --> 01:07:20,160
and then there's our gamma as well

2022
01:07:20,160 --> 01:07:21,920
that's also pointing to policies

2023
01:07:21,920 --> 01:07:24,079
and so e is how generally speaking how

2024
01:07:24,079 --> 01:07:26,079
one models habit formation or one way of

2025
01:07:26,079 --> 01:07:27,760
modeling habit formation

2026
01:07:27,760 --> 01:07:28,799
and so i'm not going to talk about that

2027
01:07:28,799 --> 01:07:30,960
now i just kind of want to flag it

2028
01:07:30,960 --> 01:07:33,119
and then when we come up things come up

2029
01:07:33,119 --> 01:07:34,720
in learning you won't be surprised

2030
01:07:34,720 --> 01:07:36,480
there's now there's extra term in the

2031
01:07:36,480 --> 01:07:39,039
policies and get what gamma does gamma

2032
01:07:39,039 --> 01:07:40,799
is essentially weights the contribution

2033
01:07:40,799 --> 01:07:41,520
it's a

2034
01:07:41,520 --> 01:07:44,799
of g to policy selection and so the idea

2035
01:07:44,799 --> 01:07:47,039
is roughly speaking is that

2036
01:07:47,039 --> 01:07:50,160
g is essentially a you have your prior

2037
01:07:50,160 --> 01:07:51,599
distribution over policies

2038
01:07:51,599 --> 01:07:54,720
which doesn't take in f at all and then

2039
01:07:54,720 --> 01:07:55,119
you

2040
01:07:55,119 --> 01:07:56,240
take you have your posterior

2041
01:07:56,240 --> 01:07:58,319
distribution which takes in f

2042
01:07:58,319 --> 01:07:59,520
and then you look at the difference

2043
01:07:59,520 --> 01:08:01,440
between those and

2044
01:08:01,440 --> 01:08:02,960
if there's a large difference between

2045
01:08:02,960 --> 01:08:05,039
those roughly speaking

2046
01:08:05,039 --> 01:08:06,799
then gamma will go down it will

2047
01:08:06,799 --> 01:08:08,400
essentially down weight

2048
01:08:08,400 --> 01:08:11,680
the contribution of expected free energy

2049
01:08:11,680 --> 01:08:14,400
to your posterior over policies

2050
01:08:14,400 --> 01:08:16,560
and this is kind of linked to has some

2051
01:08:16,560 --> 01:08:18,319
really this is how we model dope

2052
01:08:18,319 --> 01:08:21,839
phasic dopamine spiking for example

2053
01:08:21,839 --> 01:08:22,880
i'm not going to get into any more

2054
01:08:22,880 --> 01:08:24,000
details there because i think it's

2055
01:08:24,000 --> 01:08:26,158
actually much easier to just have like a

2056
01:08:26,158 --> 01:08:27,920
fully worked example but i did just want

2057
01:08:27,920 --> 01:08:29,920
to flag all that stuff

2058
01:08:29,920 --> 01:08:32,080
okay so i think that was my last so

2059
01:08:32,080 --> 01:08:33,679
that's like this tightening

2060
01:08:33,679 --> 01:08:35,600
of strategy while things are effective

2061
01:08:35,600 --> 01:08:37,679
but not overfitting but a tightening

2062
01:08:37,679 --> 01:08:39,279
while things are working

2063
01:08:39,279 --> 01:08:42,000
and then during a mismatch a period of

2064
01:08:42,000 --> 01:08:43,920
high uncertainty or ambiguity

2065
01:08:43,920 --> 01:08:46,158
there's actually a movement towards more

2066
01:08:46,158 --> 01:08:47,759
exploratory behavior

2067
01:08:47,759 --> 01:08:50,479
um okay let me try to go through a

2068
01:08:50,479 --> 01:08:50,960
couple

2069
01:08:50,960 --> 01:08:52,479
of these questions so we'll just try to

2070
01:08:52,479 --> 01:08:54,719
have the like sort of clippable

2071
01:08:54,719 --> 01:08:56,158
one one further thing i just wanted to

2072
01:08:56,158 --> 01:08:57,839
clarify about that though is that

2073
01:08:57,839 --> 01:09:00,158
so so gamma thing and really you should

2074
01:09:00,158 --> 01:09:01,600
think about that as kind of like the

2075
01:09:01,600 --> 01:09:03,359
precision estimate for expected free

2076
01:09:03,359 --> 01:09:05,759
energy so so all it's doing

2077
01:09:05,759 --> 01:09:08,080
is just saying hey if things were super

2078
01:09:08,080 --> 01:09:08,960
different

2079
01:09:08,960 --> 01:09:10,640
than what i thought they were before

2080
01:09:10,640 --> 01:09:12,000
policy-wise

2081
01:09:12,000 --> 01:09:14,640
then i mean in some cases a little more

2082
01:09:14,640 --> 01:09:16,880
complex than that but but basically

2083
01:09:16,880 --> 01:09:18,799
i can't trust my expected free energy

2084
01:09:18,799 --> 01:09:20,399
estimate as much

2085
01:09:20,399 --> 01:09:22,399
right right so i should down weight i

2086
01:09:22,399 --> 01:09:24,000
should sort of down weight

2087
01:09:24,000 --> 01:09:25,759
how much me expected free energy

2088
01:09:25,759 --> 01:09:27,359
contributes to what i choose to do

2089
01:09:27,359 --> 01:09:30,319
because it's not as reliable right so

2090
01:09:30,319 --> 01:09:31,759
it's just saying how much should my

2091
01:09:31,759 --> 01:09:32,399
habits

2092
01:09:32,399 --> 01:09:34,080
and my current observations affect what

2093
01:09:34,080 --> 01:09:36,080
i do versus

2094
01:09:36,080 --> 01:09:38,399
what i expected ahead of time uh how

2095
01:09:38,399 --> 01:09:39,920
rewarding they were going to be

2096
01:09:39,920 --> 01:09:41,679
right so if the clock has always been

2097
01:09:41,679 --> 01:09:42,960
accurate and then you look at you're

2098
01:09:42,960 --> 01:09:44,560
like wow i didn't know it was 1pm

2099
01:09:44,560 --> 01:09:46,319
you're like i believe the clock but if

2100
01:09:46,319 --> 01:09:47,920
you know that the clock is inaccurate

2101
01:09:47,920 --> 01:09:49,359
then you think i thought it was noon i

2102
01:09:49,359 --> 01:09:50,960
looked at it it said one but you know

2103
01:09:50,960 --> 01:09:52,880
who knows with this clock these days

2104
01:09:52,880 --> 01:09:54,800
so that's about the confidence in the

2105
01:09:54,800 --> 01:09:56,320
observation okay

2106
01:09:56,320 --> 01:09:58,960
so policy selection two quick questions

2107
01:09:58,960 --> 01:09:59,520
on that

2108
01:09:59,520 --> 01:10:02,400
the first one is what is the time scale

2109
01:10:02,400 --> 01:10:03,679
of policy selection

2110
01:10:03,679 --> 01:10:05,360
and does this model assume any

2111
01:10:05,360 --> 01:10:08,880
particular temporal scale

2112
01:10:09,199 --> 01:10:12,000
um so i mean temporal temporal scales

2113
01:10:12,000 --> 01:10:13,360
are kind of just whatever you want them

2114
01:10:13,360 --> 01:10:13,840
to be

2115
01:10:13,840 --> 01:10:16,640
right so so like you know in the context

2116
01:10:16,640 --> 01:10:17,600
of a task

2117
01:10:17,600 --> 01:10:20,080
right you might just say here's time

2118
01:10:20,080 --> 01:10:21,600
point one which is where

2119
01:10:21,600 --> 01:10:22,960
you know a participant gets some

2120
01:10:22,960 --> 01:10:25,280
observation right and here's time point

2121
01:10:25,280 --> 01:10:26,640
two which is where

2122
01:10:26,640 --> 01:10:29,360
they choose an action right in which

2123
01:10:29,360 --> 01:10:30,640
case that would be a two

2124
01:10:30,640 --> 01:10:33,840
time step trial um

2125
01:10:33,840 --> 01:10:35,199
and i mean it doesn't really matter

2126
01:10:35,199 --> 01:10:37,040
right i mean it might the stimulus might

2127
01:10:37,040 --> 01:10:38,640
be on for five seconds

2128
01:10:38,640 --> 01:10:40,400
or it might be on for one second in the

2129
01:10:40,400 --> 01:10:42,000
first you know

2130
01:10:42,000 --> 01:10:45,120
time step in the trial um and maybe

2131
01:10:45,120 --> 01:10:46,560
their decision takes

2132
01:10:46,560 --> 01:10:48,480
half a second right so the time step two

2133
01:10:48,480 --> 01:10:49,920
could be half a second

2134
01:10:49,920 --> 01:10:51,760
or it could be like a minute right i

2135
01:10:51,760 --> 01:10:53,040
mean like so it's

2136
01:10:53,040 --> 01:10:54,880
time steps are kind of whatever you

2137
01:10:54,880 --> 01:10:58,880
define them to be relative to a task

2138
01:10:58,880 --> 01:11:00,400
in another session when we get to

2139
01:11:00,400 --> 01:11:02,719
hierarchical models you will have

2140
01:11:02,719 --> 01:11:05,120
um higher levels that operate on slower

2141
01:11:05,120 --> 01:11:06,320
time scales

2142
01:11:06,320 --> 01:11:08,159
than the lower levels but that's a kind

2143
01:11:08,159 --> 01:11:09,600
of more complex thing that we'll have to

2144
01:11:09,600 --> 01:11:10,960
cover later

2145
01:11:10,960 --> 01:11:14,640
okay another policy related question uh

2146
01:11:14,640 --> 01:11:17,040
is can you comment on different forms of

2147
01:11:17,040 --> 01:11:17,840
policies

2148
01:11:17,840 --> 01:11:20,800
such as plans from tau equals zero to

2149
01:11:20,800 --> 01:11:23,040
big time t so from the beginning till

2150
01:11:23,040 --> 01:11:27,120
t and then tau equals little t to big t

2151
01:11:27,120 --> 01:11:30,000
belief action policies research followed

2152
01:11:30,000 --> 01:11:31,760
by belief action policies

2153
01:11:31,760 --> 01:11:33,360
and then how is this related to

2154
01:11:33,360 --> 01:11:34,960
different constructs such as working

2155
01:11:34,960 --> 01:11:35,520
memory

2156
01:11:35,520 --> 01:11:38,719
and habits so maybe just first part of

2157
01:11:38,719 --> 01:11:40,320
the question was

2158
01:11:40,320 --> 01:11:42,320
how are different kinds of policy

2159
01:11:42,320 --> 01:11:44,239
estimation

2160
01:11:44,239 --> 01:11:46,560
undertaken and the second part is how is

2161
01:11:46,560 --> 01:11:47,840
that related to maybe different

2162
01:11:47,840 --> 01:11:49,360
constructs we have

2163
01:11:49,360 --> 01:11:52,560
with regular vocabulary like working

2164
01:11:52,560 --> 01:11:55,840
memory or habits

2165
01:11:56,080 --> 01:11:58,000
um do you want me to take that curse or

2166
01:11:58,000 --> 01:11:59,760
do you want to um yeah i'm happy to take

2167
01:11:59,760 --> 01:12:00,480
it i suppose

2168
01:12:00,480 --> 01:12:03,120
uh so you can have shallow policies or

2169
01:12:03,120 --> 01:12:04,320
you can have deep policies

2170
01:12:04,320 --> 01:12:06,400
where deep policies are just kind of

2171
01:12:06,400 --> 01:12:08,000
time point whatever time point one

2172
01:12:08,000 --> 01:12:10,320
to t and you're just summing over

2173
01:12:10,320 --> 01:12:12,080
basically all of

2174
01:12:12,080 --> 01:12:13,440
you basically it's the path integral

2175
01:12:13,440 --> 01:12:15,280
formally speaking just over

2176
01:12:15,280 --> 01:12:17,520
expected free energy and that is updated

2177
01:12:17,520 --> 01:12:19,360
at each time point

2178
01:12:19,360 --> 01:12:21,120
um or you can have shallow policies

2179
01:12:21,120 --> 01:12:22,719
whereas there's one time step

2180
01:12:22,719 --> 01:12:24,719
uh how does this relate to like things

2181
01:12:24,719 --> 01:12:26,480
like tree search and all that stuff

2182
01:12:26,480 --> 01:12:29,679
um well it depends so

2183
01:12:29,679 --> 01:12:32,000
i s i'm assuming that that question

2184
01:12:32,000 --> 01:12:32,960
means that you're kind of

2185
01:12:32,960 --> 01:12:34,640
familiar with like bellman formulations

2186
01:12:34,640 --> 01:12:36,719
and that kind of thing

2187
01:12:36,719 --> 01:12:40,080
so expected free energy is bellman

2188
01:12:40,080 --> 01:12:42,000
optimal for one-step policies

2189
01:12:42,000 --> 01:12:44,320
and it's sub it's not bellman optimal

2190
01:12:44,320 --> 01:12:45,920
for deep policies

2191
01:12:45,920 --> 01:12:47,679
but there are sophisticated what's

2192
01:12:47,679 --> 01:12:50,000
called a sophisticated inference scheme

2193
01:12:50,000 --> 01:12:51,600
which is is this correct ryan that's

2194
01:12:51,600 --> 01:12:53,440
formally equivalent to uh backward

2195
01:12:53,440 --> 01:12:54,560
induction

2196
01:12:54,560 --> 01:12:57,520
yeah yeah so yeah sophisticated version

2197
01:12:57,520 --> 01:12:58,880
of active inference

2198
01:12:58,880 --> 01:13:00,960
which is more sort of explicitly like a

2199
01:13:00,960 --> 01:13:01,920
deep tree search

2200
01:13:01,920 --> 01:13:04,080
um is is equivalent to backward

2201
01:13:04,080 --> 01:13:06,320
induction which is film and optimal yeah

2202
01:13:06,320 --> 01:13:08,480
exactly um and so there are forms of

2203
01:13:08,480 --> 01:13:10,239
this that do relate to kind of research

2204
01:13:10,239 --> 01:13:12,000
and in regard to working memory

2205
01:13:12,000 --> 01:13:13,440
uh depends on how you want to set up the

2206
01:13:13,440 --> 01:13:15,360
task so there are like models

2207
01:13:15,360 --> 01:13:18,960
of uh say working memory where you have

2208
01:13:18,960 --> 01:13:20,480
two level models where your model

2209
01:13:20,480 --> 01:13:22,080
working memory is kind of the thing that

2210
01:13:22,080 --> 01:13:22,719
has

2211
01:13:22,719 --> 01:13:25,679
stable maintenance uh you can then or

2212
01:13:25,679 --> 01:13:27,360
you can model it with kind of one level

2213
01:13:27,360 --> 01:13:28,159
models

2214
01:13:28,159 --> 01:13:30,239
uh it just it just depends on how you

2215
01:13:30,239 --> 01:13:32,159
want to set things up generally speaking

2216
01:13:32,159 --> 01:13:35,040
i think of

2217
01:13:35,280 --> 01:13:36,719
working memory as being functionally

2218
01:13:36,719 --> 01:13:39,360
defined there are lots of definitions i

2219
01:13:39,360 --> 01:13:40,960
won't put one out there right now but

2220
01:13:40,960 --> 01:13:41,440
like

2221
01:13:41,440 --> 01:13:45,040
something to do with maintenance right

2222
01:13:45,600 --> 01:13:47,520
and then it kind of just depends on what

2223
01:13:47,520 --> 01:13:48,560
you're trying to model about working

2224
01:13:48,560 --> 01:13:51,199
memory what type of model is appropriate

2225
01:13:51,199 --> 01:13:52,800
yeah i mean one one additional thing to

2226
01:13:52,800 --> 01:13:54,560
say is just really kind of basic is that

2227
01:13:54,560 --> 01:13:56,000
working memory is gonna

2228
01:13:56,000 --> 01:13:57,760
come down to what your transition

2229
01:13:57,760 --> 01:13:59,440
matrices look like

2230
01:13:59,440 --> 01:14:01,520
right so if you're if you're put into

2231
01:14:01,520 --> 01:14:02,719
state one

2232
01:14:02,719 --> 01:14:04,239
and you have a really strong belief in

2233
01:14:04,239 --> 01:14:05,840
your transition matrices that you're

2234
01:14:05,840 --> 01:14:07,440
gonna if you start in state one you're

2235
01:14:07,440 --> 01:14:08,960
gonna stay in state one

2236
01:14:08,960 --> 01:14:11,679
right then that more or less amounts to

2237
01:14:11,679 --> 01:14:13,600
that state remaining active

2238
01:14:13,600 --> 01:14:16,159
over over several time steps and if you

2239
01:14:16,159 --> 01:14:17,600
learn that at time step one

2240
01:14:17,600 --> 01:14:19,520
and then at time step four believing in

2241
01:14:19,520 --> 01:14:21,120
that same believing you're in that same

2242
01:14:21,120 --> 01:14:21,760
state

2243
01:14:21,760 --> 01:14:25,199
tells you what action to do then that's

2244
01:14:25,199 --> 01:14:28,400
a type of working memory so uh thomas

2245
01:14:28,400 --> 01:14:30,159
parr has a really awesome

2246
01:14:30,159 --> 01:14:31,520
prefrontal computation as active

2247
01:14:31,520 --> 01:14:33,199
inference where he kind of thinks

2248
01:14:33,199 --> 01:14:36,000
or use thinks about transition precision

2249
01:14:36,000 --> 01:14:36,640
in terms

2250
01:14:36,640 --> 01:14:40,400
of excitatory recurrent connections in

2251
01:14:40,400 --> 01:14:43,440
lateral pfc essentially which have been

2252
01:14:43,440 --> 01:14:46,719
linked to things like maintenance

2253
01:14:47,360 --> 01:14:50,640
cool one last quick take before we go to

2254
01:14:50,640 --> 01:14:53,520
ryan sharing your screen is related to

2255
01:14:53,520 --> 01:14:54,159
modeling

2256
01:14:54,159 --> 01:14:56,560
a given behavioral task what are the

2257
01:14:56,560 --> 01:14:57,600
criteria

2258
01:14:57,600 --> 01:14:59,760
for setting the factors where the model

2259
01:14:59,760 --> 01:15:01,360
will be embedded

2260
01:15:01,360 --> 01:15:04,880
so how do we just sort of operationalize

2261
01:15:04,880 --> 01:15:07,440
the kinds of things that we take into

2262
01:15:07,440 --> 01:15:08,960
account in this model

2263
01:15:08,960 --> 01:15:12,080
i believe is what the question is asking

2264
01:15:12,080 --> 01:15:15,120
um i mean there's in a lot of tasks

2265
01:15:15,120 --> 01:15:17,040
there's probably not one unique way

2266
01:15:17,040 --> 01:15:18,880
right i mean that's kind of the where

2267
01:15:18,880 --> 01:15:20,719
the the kind of creativity

2268
01:15:20,719 --> 01:15:23,280
problem solving aspect of this comes in

2269
01:15:23,280 --> 01:15:24,800
is because you know you kind of have to

2270
01:15:24,800 --> 01:15:25,679
figure out

2271
01:15:25,679 --> 01:15:28,800
right what what uh

2272
01:15:28,800 --> 01:15:30,400
factorization structure what generative

2273
01:15:30,400 --> 01:15:32,080
model structure whether it's factorized

2274
01:15:32,080 --> 01:15:33,120
or not

2275
01:15:33,120 --> 01:15:35,520
right or what different sets of ways to

2276
01:15:35,520 --> 01:15:37,199
set up a model

2277
01:15:37,199 --> 01:15:40,320
that can um generate

2278
01:15:40,320 --> 01:15:42,800
uh behavior that you would see in a task

2279
01:15:42,800 --> 01:15:44,000
right i mean i'll give you

2280
01:15:44,000 --> 01:15:46,159
i'll give you an example right when we

2281
01:15:46,159 --> 01:15:47,600
build this task

2282
01:15:47,600 --> 01:15:49,280
build this task model together in my

2283
01:15:49,280 --> 01:15:50,960
part here um

2284
01:15:50,960 --> 01:15:53,040
but you know general in a lot of cases

2285
01:15:53,040 --> 01:15:54,880
you can make something factorized or you

2286
01:15:54,880 --> 01:15:56,880
can make it not factorized

2287
01:15:56,880 --> 01:16:00,159
um and you know sometimes you can set

2288
01:16:00,159 --> 01:16:03,920
actions up so that uh it has to do with

2289
01:16:03,920 --> 01:16:06,239
um probabilities in the b matrix and

2290
01:16:06,239 --> 01:16:07,520
your transition beliefs and in other

2291
01:16:07,520 --> 01:16:09,040
cases you can set it up so it's in the

2292
01:16:09,040 --> 01:16:09,679
likelihood

2293
01:16:09,679 --> 01:16:12,560
in the a matrix um so it's not there

2294
01:16:12,560 --> 01:16:13,040
isn't

2295
01:16:13,040 --> 01:16:14,960
my point is there isn't one unique

2296
01:16:14,960 --> 01:16:16,159
solution always for

2297
01:16:16,159 --> 01:16:18,239
for what generative model to use and a

2298
01:16:18,239 --> 01:16:19,360
lot of times you might

2299
01:16:19,360 --> 01:16:20,960
try out multiple generative models and

2300
01:16:20,960 --> 01:16:22,560
then do model comparison to figure out

2301
01:16:22,560 --> 01:16:23,760
which one's best

2302
01:16:23,760 --> 01:16:26,159
yeah all right maybe while you're

2303
01:16:26,159 --> 01:16:27,840
setting up your

2304
01:16:27,840 --> 01:16:29,679
screen i'm going to ask one more

2305
01:16:29,679 --> 01:16:30,880
question

2306
01:16:30,880 --> 01:16:33,600
somebody wrote i'm still not exactly

2307
01:16:33,600 --> 01:16:35,600
clear on why you would want to maximize

2308
01:16:35,600 --> 01:16:38,880
information and minimize the difference

2309
01:16:38,880 --> 01:16:40,719
between your desired outcomes and your

2310
01:16:40,719 --> 01:16:42,239
expectation

2311
01:16:42,239 --> 01:16:44,640
what advantage is afforded by maximizing

2312
01:16:44,640 --> 01:16:45,440
information

2313
01:16:45,440 --> 01:16:47,600
if it doesn't enhance the likelihood of

2314
01:16:47,600 --> 01:16:50,880
receiving the desired outcome

2315
01:16:50,880 --> 01:16:53,199
uh well it won't it won't in that case

2316
01:16:53,199 --> 01:16:55,280
like typically what will happen is

2317
01:16:55,280 --> 01:16:58,480
is if there's so the agent i mean it

2318
01:16:58,480 --> 01:16:59,679
depends a little bit on the

2319
01:16:59,679 --> 01:17:01,520
exact task setup but what will usually

2320
01:17:01,520 --> 01:17:03,280
happen is that

2321
01:17:03,280 --> 01:17:05,440
if the agent knows what to do to get the

2322
01:17:05,440 --> 01:17:06,560
reward

2323
01:17:06,560 --> 01:17:09,199
then that just means that that cost term

2324
01:17:09,199 --> 01:17:11,679
or that kind of reward probability term

2325
01:17:11,679 --> 01:17:14,000
will just be the one that dominates like

2326
01:17:14,000 --> 01:17:15,360
the value of that will dominate the

2327
01:17:15,360 --> 01:17:16,000
thing will just

2328
01:17:16,000 --> 01:17:18,239
select reward automatically the

2329
01:17:18,239 --> 01:17:19,679
information seeking

2330
01:17:19,679 --> 01:17:21,679
will typically only have a high weight

2331
01:17:21,679 --> 01:17:23,199
if it's the case that the agent doesn't

2332
01:17:23,199 --> 01:17:24,719
know what to do yet

2333
01:17:24,719 --> 01:17:26,800
to get to get the reward you know that

2334
01:17:26,800 --> 01:17:27,760
reminds me a lot

2335
01:17:27,760 --> 01:17:29,679
it reminds me a lot of the game theory

2336
01:17:29,679 --> 01:17:31,840
uh strategy which is like tit for tat

2337
01:17:31,840 --> 01:17:34,159
but then you start out playing nice

2338
01:17:34,159 --> 01:17:36,320
it's like default to being cooperative

2339
01:17:36,320 --> 01:17:38,000
but then have a strategy

2340
01:17:38,000 --> 01:17:40,480
and so it's sort of like a meta approach

2341
01:17:40,480 --> 01:17:41,199
which is if it's

2342
01:17:41,199 --> 01:17:42,560
if it's in the room if you're winning

2343
01:17:42,560 --> 01:17:44,400
the game of go or chess

2344
01:17:44,400 --> 01:17:46,640
at whatever training level then what is

2345
01:17:46,640 --> 01:17:47,520
there to do

2346
01:17:47,520 --> 01:17:49,360
your strategy is working but then when

2347
01:17:49,360 --> 01:17:52,320
there isn't a victory observation

2348
01:17:52,320 --> 01:17:55,600
then it entails an exploratory search

2349
01:17:55,600 --> 01:17:57,520
that percolates through higher and

2350
01:17:57,520 --> 01:17:59,280
higher abstractions

2351
01:17:59,280 --> 01:18:02,239
of learning in the system so i hope that

2352
01:18:02,239 --> 01:18:02,800
we can

2353
01:18:02,800 --> 01:18:04,400
make that a little bit more tangible

2354
01:18:04,400 --> 01:18:06,400
with this session right here

2355
01:18:06,400 --> 01:18:09,040
so we have 40 minutes left and again

2356
01:18:09,040 --> 01:18:11,360
this is just part one of multiple

2357
01:18:11,360 --> 01:18:13,840
so let's go for you know 20 to 30

2358
01:18:13,840 --> 01:18:14,880
minutes followed by

2359
01:18:14,880 --> 01:18:17,520
10 to 20 minutes of wrap up and final

2360
01:18:17,520 --> 01:18:18,960
questions from the chat and a couple

2361
01:18:18,960 --> 01:18:20,320
other ones i have stored up

2362
01:18:20,320 --> 01:18:23,760
but thanks um and take it away ryan

2363
01:18:23,760 --> 01:18:25,360
okay so i want to just ask real quick

2364
01:18:25,360 --> 01:18:27,920
can you guys see my like mouse if i like

2365
01:18:27,920 --> 01:18:28,719
point to things

2366
01:18:28,719 --> 01:18:32,000
yes okay okay because i i i need to

2367
01:18:32,000 --> 01:18:33,360
point to things when i'm presenting this

2368
01:18:33,360 --> 01:18:33,679
stuff

2369
01:18:33,679 --> 01:18:36,960
so okay so so just kind of again to get

2370
01:18:36,960 --> 01:18:37,280
to

2371
01:18:37,280 --> 01:18:39,360
scope here i mean the end goal of the

2372
01:18:39,360 --> 01:18:41,120
tutorial is for people to be able to

2373
01:18:41,120 --> 01:18:42,719
actually do research with us with these

2374
01:18:42,719 --> 01:18:43,199
things

2375
01:18:43,199 --> 01:18:45,440
right so so the end goal here is to

2376
01:18:45,440 --> 01:18:47,040
learn how to build task models

2377
01:18:47,040 --> 01:18:50,159
for empirical studies and the basic idea

2378
01:18:50,159 --> 01:18:51,199
is that you're going to have

2379
01:18:51,199 --> 01:18:53,199
participants perform a task

2380
01:18:53,199 --> 01:18:55,120
and then what you want to do is find the

2381
01:18:55,120 --> 01:18:57,199
parameter values in the model

2382
01:18:57,199 --> 01:18:59,600
um say like values for precision or

2383
01:18:59,600 --> 01:19:00,880
values for prior

2384
01:19:00,880 --> 01:19:04,719
expectations or values for

2385
01:19:04,719 --> 01:19:07,199
habit distributions right that e thing

2386
01:19:07,199 --> 01:19:08,000
that um

2387
01:19:08,000 --> 01:19:10,080
i'm not gonna probably i won't use e

2388
01:19:10,080 --> 01:19:11,440
very in this

2389
01:19:11,440 --> 01:19:13,520
example but but just things like that

2390
01:19:13,520 --> 01:19:14,640
right where

2391
01:19:14,640 --> 01:19:16,480
different things in a model could take

2392
01:19:16,480 --> 01:19:17,920
on different values

2393
01:19:17,920 --> 01:19:20,000
and based on those values the agent will

2394
01:19:20,000 --> 01:19:21,040
act differently

2395
01:19:21,040 --> 01:19:23,600
it'll make different choices and so what

2396
01:19:23,600 --> 01:19:24,640
you want to do is

2397
01:19:24,640 --> 01:19:26,239
take the behavior of an actual

2398
01:19:26,239 --> 01:19:27,840
participant and then

2399
01:19:27,840 --> 01:19:30,159
find the values for those parameters

2400
01:19:30,159 --> 01:19:31,040
there is that

2401
01:19:31,040 --> 01:19:34,960
they'll best reproduce their behavior

2402
01:19:34,960 --> 01:19:38,080
um and uh so

2403
01:19:38,080 --> 01:19:39,760
and then once you have those parameters

2404
01:19:39,760 --> 01:19:41,440
that best reproduce

2405
01:19:41,440 --> 01:19:43,520
um a given person's behavior and you do

2406
01:19:43,520 --> 01:19:45,280
that for all the participants

2407
01:19:45,280 --> 01:19:47,360
then you can just use those values those

2408
01:19:47,360 --> 01:19:48,960
parameter values

2409
01:19:48,960 --> 01:19:50,719
as individual difference measures you

2410
01:19:50,719 --> 01:19:52,960
might say like if one person has a

2411
01:19:52,960 --> 01:19:54,640
higher precision

2412
01:19:54,640 --> 01:19:57,760
uh a higher a matrix precision

2413
01:19:57,760 --> 01:19:59,840
than another person you know does that

2414
01:19:59,840 --> 01:20:02,000
predict something about

2415
01:20:02,000 --> 01:20:03,440
for instance how well they're going to

2416
01:20:03,440 --> 01:20:04,960
respond to a treatment like in

2417
01:20:04,960 --> 01:20:06,719
computational psychiatry or

2418
01:20:06,719 --> 01:20:09,679
can that tell you something about um you

2419
01:20:09,679 --> 01:20:11,679
know some other cognitive function

2420
01:20:11,679 --> 01:20:14,639
or i mean you know et cetera et cetera

2421
01:20:14,639 --> 01:20:15,520
um

2422
01:20:15,520 --> 01:20:18,560
and um so the goal again is to

2423
01:20:18,560 --> 01:20:19,840
get people to that point where they can

2424
01:20:19,840 --> 01:20:21,679
do that um

2425
01:20:21,679 --> 01:20:24,000
and um like i said before this is the

2426
01:20:24,000 --> 01:20:25,199
kind of thing that people have been

2427
01:20:25,199 --> 01:20:26,560
doing for a long time

2428
01:20:26,560 --> 01:20:29,600
in reinforcement learning um but it's

2429
01:20:29,600 --> 01:20:30,000
new

2430
01:20:30,000 --> 01:20:32,159
it's a novel sort of not very common

2431
01:20:32,159 --> 01:20:34,080
thing yet to do an active inference

2432
01:20:34,080 --> 01:20:35,520
because not enough people know how to do

2433
01:20:35,520 --> 01:20:36,159
it

2434
01:20:36,159 --> 01:20:40,639
um and so you know i can give you uh

2435
01:20:40,639 --> 01:20:47,040
examples here if i can get my what the

2436
01:20:47,040 --> 01:20:50,960
uh it's um

2437
01:20:52,880 --> 01:20:55,120
i don't know why this is not letting me

2438
01:20:55,120 --> 01:20:56,000
advance

2439
01:20:56,000 --> 01:20:58,840
[Music]

2440
01:20:58,840 --> 01:21:01,040
um okay there

2441
01:21:01,040 --> 01:21:04,480
um so you know and these tasks and vary

2442
01:21:04,480 --> 01:21:06,080
you know in another session we'll

2443
01:21:06,080 --> 01:21:07,440
um you know walk you through how to

2444
01:21:07,440 --> 01:21:09,440
build like a perceptual task that's like

2445
01:21:09,440 --> 01:21:10,880
widely used for like

2446
01:21:10,880 --> 01:21:13,520
eeg research um as well as number

2447
01:21:13,520 --> 01:21:15,440
imaging research more broadly but

2448
01:21:15,440 --> 01:21:18,000
called like an oddball task which is

2449
01:21:18,000 --> 01:21:21,040
primarily a perception task

2450
01:21:21,040 --> 01:21:23,040
and there are also sorts of inferential

2451
01:21:23,040 --> 01:21:24,880
like prospective decision making tasks

2452
01:21:24,880 --> 01:21:26,159
that you can use that don't involve

2453
01:21:26,159 --> 01:21:27,120
learning

2454
01:21:27,120 --> 01:21:29,840
and then there are tasks that you know

2455
01:21:29,840 --> 01:21:30,239
that

2456
01:21:30,239 --> 01:21:32,000
use reinforcement learning or explore

2457
01:21:32,000 --> 01:21:33,520
exploit dynamics

2458
01:21:33,520 --> 01:21:36,000
um and then you can also use it with

2459
01:21:36,000 --> 01:21:36,960
neural imaging

2460
01:21:36,960 --> 01:21:39,040
right you could say like trial by trial

2461
01:21:39,040 --> 01:21:40,800
where are the prediction errors

2462
01:21:40,800 --> 01:21:42,239
you know in the brain what parts of the

2463
01:21:42,239 --> 01:21:43,600
brain look like they're doing the free

2464
01:21:43,600 --> 01:21:45,120
energy minimization

2465
01:21:45,120 --> 01:21:48,239
um you know trial by trial um so there's

2466
01:21:48,239 --> 01:21:51,440
things like that that you can do

2467
01:21:51,440 --> 01:21:55,440
why okay

2468
01:21:55,440 --> 01:21:58,560
and so sorry what just that that really

2469
01:21:58,560 --> 01:22:00,880
reminds me of just to pull back a level

2470
01:22:00,880 --> 01:22:02,639
making measurements of a biological

2471
01:22:02,639 --> 01:22:04,560
system like gene expression or

2472
01:22:04,560 --> 01:22:07,360
neuroimaging and then saying what gene

2473
01:22:07,360 --> 01:22:07,679
is

2474
01:22:07,679 --> 01:22:09,760
upregulated in people who have this

2475
01:22:09,760 --> 01:22:10,880
condition or

2476
01:22:10,880 --> 01:22:12,880
what brain region is activated in this

2477
01:22:12,880 --> 01:22:14,880
condition and we're taking that

2478
01:22:14,880 --> 01:22:17,520
beyond the simply descriptive beyond the

2479
01:22:17,520 --> 01:22:18,159
just

2480
01:22:18,159 --> 01:22:20,480
measure and do a t-test and we're

2481
01:22:20,480 --> 01:22:22,480
thinking about these observations

2482
01:22:22,480 --> 01:22:24,960
these behavioral phenotypes as being

2483
01:22:24,960 --> 01:22:26,480
emitted

2484
01:22:26,480 --> 01:22:29,199
often across tasks potentially or across

2485
01:22:29,199 --> 01:22:30,239
modalities

2486
01:22:30,239 --> 01:22:32,719
emitted by a generative model that has

2487
01:22:32,719 --> 01:22:33,760
these higher level

2488
01:22:33,760 --> 01:22:36,480
parameters that shape the way that the

2489
01:22:36,480 --> 01:22:38,320
person or the organism

2490
01:22:38,320 --> 01:22:41,280
responds to stimuli under a certain

2491
01:22:41,280 --> 01:22:42,800
specific framing

2492
01:22:42,800 --> 01:22:45,600
of a time and task dependent model just

2493
01:22:45,600 --> 01:22:47,280
to sort of pull back a level and give

2494
01:22:47,280 --> 01:22:50,159
that but continue right

2495
01:22:50,159 --> 01:22:52,320
so so i just want to say that you know

2496
01:22:52,320 --> 01:22:53,280
there are

2497
01:22:53,280 --> 01:22:55,920
this is kind of a new a new thing to do

2498
01:22:55,920 --> 01:22:57,760
not very many people have done it

2499
01:22:57,760 --> 01:23:00,960
um you know my lab has kind of

2500
01:23:00,960 --> 01:23:03,600
been uh trying to kind of get this

2501
01:23:03,600 --> 01:23:04,560
approach out there

2502
01:23:04,560 --> 01:23:07,280
more um and so i mean here's some

2503
01:23:07,280 --> 01:23:08,880
example papers

2504
01:23:08,880 --> 01:23:10,719
that just do each of the things that i

2505
01:23:10,719 --> 01:23:12,800
mentioned right so

2506
01:23:12,800 --> 01:23:15,840
this one on the right here so recent

2507
01:23:15,840 --> 01:23:18,880
plus computational biology paper

2508
01:23:18,880 --> 01:23:21,600
is using active inference primarily just

2509
01:23:21,600 --> 01:23:23,360
for a perceptual model

2510
01:23:23,360 --> 01:23:25,600
um and with that one we were just

2511
01:23:25,600 --> 01:23:27,199
looking at um actually uh

2512
01:23:27,199 --> 01:23:29,040
inter-receptive processes right so for

2513
01:23:29,040 --> 01:23:29,840
instance

2514
01:23:29,840 --> 01:23:32,880
um every time people feel a heartbeat

2515
01:23:32,880 --> 01:23:34,480
and then indicate by pushing a button

2516
01:23:34,480 --> 01:23:36,000
that they feel their heartbeat

2517
01:23:36,000 --> 01:23:38,480
you know who who does better than that

2518
01:23:38,480 --> 01:23:39,840
uh than others

2519
01:23:39,840 --> 01:23:43,040
and why right and some people might have

2520
01:23:43,040 --> 01:23:45,199
stronger prior expectations that they

2521
01:23:45,199 --> 01:23:47,760
are or not going to feel a heartbeat and

2522
01:23:47,760 --> 01:23:49,280
some people instead might just have

2523
01:23:49,280 --> 01:23:51,040
different levels of sensory precision

2524
01:23:51,040 --> 01:23:53,040
right like they treat the signal coming

2525
01:23:53,040 --> 01:23:54,400
up from their body as more or less

2526
01:23:54,400 --> 01:23:55,520
precise

2527
01:23:55,520 --> 01:23:58,639
right so that's like one example um

2528
01:23:58,639 --> 01:24:00,719
this paper uh in drug and alcohol

2529
01:24:00,719 --> 01:24:02,719
dependence was a learning

2530
01:24:02,719 --> 01:24:05,840
an action or a explore exploit

2531
01:24:05,840 --> 01:24:07,760
and reinforcement learning task that was

2532
01:24:07,760 --> 01:24:10,480
applied to people in substance use

2533
01:24:10,480 --> 01:24:13,520
and then this one in the lower left is

2534
01:24:13,520 --> 01:24:15,120
greater decision uncertainty

2535
01:24:15,120 --> 01:24:18,400
paper um is an example of

2536
01:24:18,400 --> 01:24:20,239
uh purely just sort of planning like

2537
01:24:20,239 --> 01:24:21,760
decision making inferential model

2538
01:24:21,760 --> 01:24:23,120
without learning

2539
01:24:23,120 --> 01:24:26,320
um and then philip schwartenbeck's paper

2540
01:24:26,320 --> 01:24:27,920
up here on the right is an example of

2541
01:24:27,920 --> 01:24:30,080
using active inference to

2542
01:24:30,080 --> 01:24:32,159
look for the neural correlates of

2543
01:24:32,159 --> 01:24:33,760
particular uh

2544
01:24:33,760 --> 01:24:36,400
model parameters um you know so for

2545
01:24:36,400 --> 01:24:37,679
instance with the

2546
01:24:37,679 --> 01:24:39,679
with the drug and alcohol dependence

2547
01:24:39,679 --> 01:24:40,719
paper

2548
01:24:40,719 --> 01:24:43,840
and just use this simple

2549
01:24:43,840 --> 01:24:45,360
exploit tasks where people had three

2550
01:24:45,360 --> 01:24:46,880
options they could push button one two

2551
01:24:46,880 --> 01:24:47,920
or three

2552
01:24:47,920 --> 01:24:49,840
and then you could either a green or red

2553
01:24:49,840 --> 01:24:51,280
ball would kind of fall

2554
01:24:51,280 --> 01:24:52,880
and green meant they won and red meant

2555
01:24:52,880 --> 01:24:54,800
they lost and initially

2556
01:24:54,800 --> 01:24:56,639
they didn't know you know what the

2557
01:24:56,639 --> 01:24:58,719
probability was of winning or losing for

2558
01:24:58,719 --> 01:24:59,040
each

2559
01:24:59,040 --> 01:25:01,440
winning or losing for each button um so

2560
01:25:01,440 --> 01:25:02,800
the first few choices they had to kind

2561
01:25:02,800 --> 01:25:03,040
of

2562
01:25:03,040 --> 01:25:05,199
explore right to figure out which one's

2563
01:25:05,199 --> 01:25:06,719
giving the most greens

2564
01:25:06,719 --> 01:25:08,719
i mean eventually they become confident

2565
01:25:08,719 --> 01:25:10,560
that one of them is best and they kind

2566
01:25:10,560 --> 01:25:13,199
of stick to that one

2567
01:25:13,199 --> 01:25:15,840
and i won't go through it but you know

2568
01:25:15,840 --> 01:25:18,320
you can specify a particular version

2569
01:25:18,320 --> 01:25:21,120
of the graphical models that uh chris

2570
01:25:21,120 --> 01:25:22,480
showed

2571
01:25:22,480 --> 01:25:26,480
that generate appropriate behavior like

2572
01:25:26,480 --> 01:25:29,440
participants do on this task

2573
01:25:29,440 --> 01:25:32,159
and again i won't really go through this

2574
01:25:32,159 --> 01:25:33,520
but this is what

2575
01:25:33,520 --> 01:25:36,320
the likelihood or a matrix would look

2576
01:25:36,320 --> 01:25:37,840
like

2577
01:25:37,840 --> 01:25:39,280
that they would where over time they

2578
01:25:39,280 --> 01:25:42,000
would learn these a zero values

2579
01:25:42,000 --> 01:25:44,639
to basically say if i choose a slot

2580
01:25:44,639 --> 01:25:46,480
machine one two or three

2581
01:25:46,480 --> 01:25:47,920
what's the probability that that's going

2582
01:25:47,920 --> 01:25:49,679
to generate uh

2583
01:25:49,679 --> 01:25:51,760
this row the observation for this row

2584
01:25:51,760 --> 01:25:53,679
which is a win or the observation for

2585
01:25:53,679 --> 01:25:56,400
this row which is a loss

2586
01:25:56,400 --> 01:25:58,960
and then the c vector here the one that

2587
01:25:58,960 --> 01:26:00,400
encodes reward

2588
01:26:00,400 --> 01:26:03,120
just says whatever this cr value is

2589
01:26:03,120 --> 01:26:04,480
which would be a positive number

2590
01:26:04,480 --> 01:26:07,520
just says i prefer winning versus losing

2591
01:26:07,520 --> 01:26:10,080
by some amount

2592
01:26:10,080 --> 01:26:11,360
and then this is the equation for

2593
01:26:11,360 --> 01:26:13,199
learning and then this is just showing

2594
01:26:13,199 --> 01:26:15,679
um this is just showing the expected

2595
01:26:15,679 --> 01:26:17,199
free energy equation

2596
01:26:17,199 --> 01:26:18,960
um and again this isn't the example i'm

2597
01:26:18,960 --> 01:26:20,320
going to work through

2598
01:26:20,320 --> 01:26:22,560
but what you could do i'll skip that is

2599
01:26:22,560 --> 01:26:23,840
you could find

2600
01:26:23,840 --> 01:26:26,320
that people with substance use showed

2601
01:26:26,320 --> 01:26:26,960
lower

2602
01:26:26,960 --> 01:26:28,560
action precision in other words the

2603
01:26:28,560 --> 01:26:30,400
behavior was a little more random

2604
01:26:30,400 --> 01:26:32,159
they showed higher learning rates for

2605
01:26:32,159 --> 01:26:33,440
wins

2606
01:26:33,440 --> 01:26:36,159
and lower and less slower learning rates

2607
01:26:36,159 --> 01:26:38,880
for losses compared to healthy people

2608
01:26:38,880 --> 01:26:40,159
right so you can tell this interesting

2609
01:26:40,159 --> 01:26:42,320
story about hey like if people with

2610
01:26:42,320 --> 01:26:43,840
substance use

2611
01:26:43,840 --> 01:26:45,920
learn more slowly whenever a bad thing

2612
01:26:45,920 --> 01:26:47,280
happens when they take the drug but they

2613
01:26:47,280 --> 01:26:47,920
learn more

2614
01:26:47,920 --> 01:26:49,840
you know more quickly every time they

2615
01:26:49,840 --> 01:26:51,600
feel good right after taking a drug

2616
01:26:51,600 --> 01:26:53,920
then um their behavior is going to have

2617
01:26:53,920 --> 01:26:55,520
a much harder time

2618
01:26:55,520 --> 01:26:59,679
stop stopping uh taking taking a a

2619
01:26:59,679 --> 01:27:02,239
drug um despite the fact that it has

2620
01:27:02,239 --> 01:27:04,080
negative consequences

2621
01:27:04,080 --> 01:27:07,360
um you know and so you can fit uh these

2622
01:27:07,360 --> 01:27:07,840
are just

2623
01:27:07,840 --> 01:27:09,360
group estimates just showing in a

2624
01:27:09,360 --> 01:27:11,040
bayesian way that

2625
01:27:11,040 --> 01:27:14,080
learning rate for losses was uh

2626
01:27:14,080 --> 01:27:17,520
different um in people with uh substance

2627
01:27:17,520 --> 01:27:20,320
use than healthy people

2628
01:27:20,320 --> 01:27:23,840
and uh the example for just uh

2629
01:27:23,840 --> 01:27:25,360
planning and decision making without

2630
01:27:25,360 --> 01:27:27,280
learning this was a

2631
01:27:27,280 --> 01:27:29,120
an approach avoidance conflict task

2632
01:27:29,120 --> 01:27:30,800
basically people just had to decide

2633
01:27:30,800 --> 01:27:32,639
where to move this little

2634
01:27:32,639 --> 01:27:35,679
avatar dude on uh along this little

2635
01:27:35,679 --> 01:27:36,320
runway

2636
01:27:36,320 --> 01:27:38,719
line and the closer they were to like

2637
01:27:38,719 --> 01:27:40,320
the sun

2638
01:27:40,320 --> 01:27:44,080
and uh and a bar that had lots of red

2639
01:27:44,080 --> 01:27:45,600
that mean meant they were going to see a

2640
01:27:45,600 --> 01:27:47,280
nice happy image and they were going to

2641
01:27:47,280 --> 01:27:49,679
win some points the more red and the

2642
01:27:49,679 --> 01:27:51,840
uh rectangle thing the more points they

2643
01:27:51,840 --> 01:27:52,800
would win

2644
01:27:52,800 --> 01:27:54,320
and the rainy cloud meant they were

2645
01:27:54,320 --> 01:27:56,000
going to see like a really

2646
01:27:56,000 --> 01:27:57,520
terrible picture and hear like a

2647
01:27:57,520 --> 01:27:59,040
terrible sound

2648
01:27:59,040 --> 01:28:01,440
um so in some cases they would need to

2649
01:28:01,440 --> 01:28:02,080
say okay

2650
01:28:02,080 --> 01:28:04,320
i'm willing to go through seeing this

2651
01:28:04,320 --> 01:28:05,520
really negative

2652
01:28:05,520 --> 01:28:09,199
uh aversive thing to win a lot of points

2653
01:28:09,199 --> 01:28:11,600
or not right so in this model it's just

2654
01:28:11,600 --> 01:28:12,719
trying to say

2655
01:28:12,719 --> 01:28:14,239
you know they start in the middle for

2656
01:28:14,239 --> 01:28:16,000
example you know

2657
01:28:16,000 --> 01:28:17,679
how close do they decide to get to one

2658
01:28:17,679 --> 01:28:19,440
side or the other which

2659
01:28:19,440 --> 01:28:22,159
um controls the probability of getting

2660
01:28:22,159 --> 01:28:23,840
what's on one side or the other

2661
01:28:23,840 --> 01:28:25,440
so it's just planning where to move

2662
01:28:25,440 --> 01:28:27,040
right there's no learning because they

2663
01:28:27,040 --> 01:28:28,080
already know exactly

2664
01:28:28,080 --> 01:28:31,520
what the rewards and punishments are um

2665
01:28:31,520 --> 01:28:33,520
and so in that case again i won't go

2666
01:28:33,520 --> 01:28:34,960
through this but you can specify a

2667
01:28:34,960 --> 01:28:36,719
generative model for this

2668
01:28:36,719 --> 01:28:38,560
um in a similar way you can run

2669
01:28:38,560 --> 01:28:40,719
simulations about what we people will do

2670
01:28:40,719 --> 01:28:43,600
under different um parameter values this

2671
01:28:43,600 --> 01:28:45,440
beta thing is the um

2672
01:28:45,440 --> 01:28:48,400
expected precision um for expected free

2673
01:28:48,400 --> 01:28:49,600
energy precision

2674
01:28:49,600 --> 01:28:52,960
um and ec here is just how much they

2675
01:28:52,960 --> 01:28:55,360
like the reward like the points relative

2676
01:28:55,360 --> 01:28:56,719
to how much they dislike the negative

2677
01:28:56,719 --> 01:28:57,600
images

2678
01:28:57,600 --> 01:29:00,320
and we just called that emotion conflict

2679
01:29:00,320 --> 01:29:01,040
um

2680
01:29:01,040 --> 01:29:02,639
that's just another way of presenting

2681
01:29:02,639 --> 01:29:04,000
the generative model i won't go through

2682
01:29:04,000 --> 01:29:04,639
that

2683
01:29:04,639 --> 01:29:07,679
but here again you can show for example

2684
01:29:07,679 --> 01:29:08,400
that

2685
01:29:08,400 --> 01:29:10,880
people with depression and people with

2686
01:29:10,880 --> 01:29:12,320
substance use

2687
01:29:12,320 --> 01:29:15,600
showed uh less emotion conflict than

2688
01:29:15,600 --> 01:29:16,639
healthy people

2689
01:29:16,639 --> 01:29:18,800
and they showed greater uh decision

2690
01:29:18,800 --> 01:29:20,560
uncertainty than healthy people they

2691
01:29:20,560 --> 01:29:21,600
showed they had

2692
01:29:21,600 --> 01:29:24,960
higher uh a lower expected free energy

2693
01:29:24,960 --> 01:29:25,920
precision

2694
01:29:25,920 --> 01:29:28,400
which corresponds to higher beta values

2695
01:29:28,400 --> 01:29:31,679
um so that's just another example

2696
01:29:31,679 --> 01:29:34,400
um i think one thing that uh from the

2697
01:29:34,400 --> 01:29:36,320
presenter view you can't see questions

2698
01:29:36,320 --> 01:29:37,840
but now that i'm not in presenter view i

2699
01:29:37,840 --> 01:29:39,920
can see that daniel had his hand up oh

2700
01:29:39,920 --> 01:29:43,120
sorry oh okay just just yes this is

2701
01:29:43,120 --> 01:29:43,760
great

2702
01:29:43,760 --> 01:29:45,520
stuff i just want to highlight a few

2703
01:29:45,520 --> 01:29:46,800
pieces here

2704
01:29:46,800 --> 01:29:49,520
so with that same task you can imagine a

2705
01:29:49,520 --> 01:29:51,280
purely descriptive model

2706
01:29:51,280 --> 01:29:53,440
and a paper being written on something

2707
01:29:53,440 --> 01:29:54,800
like people who have

2708
01:29:54,800 --> 01:29:58,080
x diagnosis are more likely to approach

2709
01:29:58,080 --> 01:29:59,760
when there's conflict or something

2710
01:29:59,760 --> 01:30:02,080
so that would be a purely descriptive

2711
01:30:02,080 --> 01:30:04,880
finding based upon the same exact data

2712
01:30:04,880 --> 01:30:08,080
now what this tutorial is about is using

2713
01:30:08,080 --> 01:30:10,480
the exact same behavioral data

2714
01:30:10,480 --> 01:30:13,199
within and across participants and then

2715
01:30:13,199 --> 01:30:14,159
modeling

2716
01:30:14,159 --> 01:30:16,719
underlying parameters that have a very

2717
01:30:16,719 --> 01:30:17,440
specific

2718
01:30:17,440 --> 01:30:20,719
graphical layout and relatedness so here

2719
01:30:20,719 --> 01:30:23,120
we're talking about a t-test basically

2720
01:30:23,120 --> 01:30:25,679
being used on a summary statistic

2721
01:30:25,679 --> 01:30:27,199
so they're not just different in the

2722
01:30:27,199 --> 01:30:28,719
descriptive outcomes

2723
01:30:28,719 --> 01:30:30,239
like this group was more likely to

2724
01:30:30,239 --> 01:30:31,840
gamble on red

2725
01:30:31,840 --> 01:30:34,080
this is like saying this group had a

2726
01:30:34,080 --> 01:30:34,880
higher

2727
01:30:34,880 --> 01:30:36,880
hidden state variable that we're going

2728
01:30:36,880 --> 01:30:38,320
to attach to what we're going to call

2729
01:30:38,320 --> 01:30:40,000
like gambling propensity

2730
01:30:40,000 --> 01:30:41,760
now that relates to a question from the

2731
01:30:41,760 --> 01:30:43,520
chat which is

2732
01:30:43,520 --> 01:30:46,159
um and a really important question how

2733
01:30:46,159 --> 01:30:47,679
are the neurobiological

2734
01:30:47,679 --> 01:30:50,080
interpretation of the agent's generative

2735
01:30:50,080 --> 01:30:51,360
model parameter

2736
01:30:51,360 --> 01:30:54,400
estimates done with respect to the

2737
01:30:54,400 --> 01:30:57,120
parameter model so how do we go from

2738
01:30:57,120 --> 01:31:00,840
a summary statistic or a graphical model

2739
01:31:00,840 --> 01:31:04,000
estimate to a neurobiological

2740
01:31:04,000 --> 01:31:07,440
interpretation let alone intervention

2741
01:31:07,440 --> 01:31:08,880
or anything like that but just mainly

2742
01:31:08,880 --> 01:31:11,520
the interpretation side

2743
01:31:11,520 --> 01:31:14,719
um so so we have a whole a whole section

2744
01:31:14,719 --> 01:31:16,960
in the tutorial on the neural process

2745
01:31:16,960 --> 01:31:18,480
theory that's associated with active

2746
01:31:18,480 --> 01:31:19,440
inference

2747
01:31:19,440 --> 01:31:21,760
um that's something that we're going to

2748
01:31:21,760 --> 01:31:23,920
uh that was we plan to talk about

2749
01:31:23,920 --> 01:31:26,719
in another session um probably in part

2750
01:31:26,719 --> 01:31:27,600
two

2751
01:31:27,600 --> 01:31:29,440
um so i'm probably going to hold off on

2752
01:31:29,440 --> 01:31:31,440
describing that in detail right now

2753
01:31:31,440 --> 01:31:34,960
but the the kind of quick version um

2754
01:31:34,960 --> 01:31:38,080
is that uh the the process the neural

2755
01:31:38,080 --> 01:31:39,440
process theory just makes certain

2756
01:31:39,440 --> 01:31:40,560
assumptions

2757
01:31:40,560 --> 01:31:44,400
about how uh neurons can be connected up

2758
01:31:44,400 --> 01:31:45,920
to do this kind of thing

2759
01:31:45,920 --> 01:31:49,199
um you know so for example um there's a

2760
01:31:49,199 --> 01:31:51,679
you can have different rates at which

2761
01:31:51,679 --> 01:31:52,880
your beliefs change

2762
01:31:52,880 --> 01:31:54,960
rates with which the with your

2763
01:31:54,960 --> 01:31:57,440
distribution over states

2764
01:31:57,440 --> 01:32:00,560
more or less precise um and

2765
01:32:00,560 --> 01:32:02,080
you know the the neural process theory

2766
01:32:02,080 --> 01:32:04,320
says that the for instance the the sorts

2767
01:32:04,320 --> 01:32:05,199
of erps

2768
01:32:05,199 --> 01:32:07,120
that you would measure right the changes

2769
01:32:07,120 --> 01:32:09,520
and the changes in uh the magnitude of

2770
01:32:09,520 --> 01:32:11,040
change in the uh

2771
01:32:11,040 --> 01:32:12,320
neural activation that you would see

2772
01:32:12,320 --> 01:32:14,639
would correspond to the rate of change

2773
01:32:14,639 --> 01:32:16,960
in in those beliefs essentially you can

2774
01:32:16,960 --> 01:32:18,480
think about it as how quickly prediction

2775
01:32:18,480 --> 01:32:19,920
error is being minimized

2776
01:32:19,920 --> 01:32:23,199
as well um whereas the

2777
01:32:23,199 --> 01:32:26,080
the updates to this beta thing um trial

2778
01:32:26,080 --> 01:32:27,120
by trial

2779
01:32:27,120 --> 01:32:31,440
um are uh modeled as the

2780
01:32:31,440 --> 01:32:33,760
as the phasic dopamine spikes that are

2781
01:32:33,760 --> 01:32:35,360
essentially updating

2782
01:32:35,360 --> 01:32:38,239
um how much the expected free energy

2783
01:32:38,239 --> 01:32:41,120
controls uh action slow you know policy

2784
01:32:41,120 --> 01:32:42,239
selection

2785
01:32:42,239 --> 01:32:44,719
um so there are there is just there's

2786
01:32:44,719 --> 01:32:46,560
just a neural process theory that

2787
01:32:46,560 --> 01:32:49,600
proposes one way in which the uh the

2788
01:32:49,600 --> 01:32:50,960
variational message passing that

2789
01:32:50,960 --> 01:32:52,960
otherwise these models

2790
01:32:52,960 --> 01:32:54,719
how that could be implemented in early

2791
01:32:54,719 --> 01:32:56,400
and therefore what sorts of signals

2792
01:32:56,400 --> 01:32:58,000
are you know you ought to measure in the

2793
01:32:58,000 --> 01:33:00,480
brain if that process theory was correct

2794
01:33:00,480 --> 01:33:01,600
but it's it's really important to

2795
01:33:01,600 --> 01:33:03,920
recognize that there are several

2796
01:33:03,920 --> 01:33:04,560
different

2797
01:33:04,560 --> 01:33:06,239
possible process theories that you could

2798
01:33:06,239 --> 01:33:08,639
come up with right so

2799
01:33:08,639 --> 01:33:11,360
there's there's many different ways you

2800
01:33:11,360 --> 01:33:11,920
you could

2801
01:33:11,920 --> 01:33:14,000
connect a bunch of neurons up together

2802
01:33:14,000 --> 01:33:16,159
to implement these sorts of models

2803
01:33:16,159 --> 01:33:17,679
so there's like a lot of different

2804
01:33:17,679 --> 01:33:20,239
levels of um

2805
01:33:20,239 --> 01:33:23,120
study here right there's what generative

2806
01:33:23,120 --> 01:33:25,600
model best describes task behavior

2807
01:33:25,600 --> 01:33:28,239
and then there's given that model what

2808
01:33:28,239 --> 01:33:29,760
of a bunch of different message passing

2809
01:33:29,760 --> 01:33:30,560
algorithms

2810
01:33:30,560 --> 01:33:33,840
is the one that is being used

2811
01:33:33,840 --> 01:33:35,679
and then there's the question about

2812
01:33:35,679 --> 01:33:37,840
given that it's method this message

2813
01:33:37,840 --> 01:33:39,600
passing algorithm

2814
01:33:39,600 --> 01:33:40,639
you know there's a bunch of different

2815
01:33:40,639 --> 01:33:42,320
possible ways the brain could implement

2816
01:33:42,320 --> 01:33:44,320
that so which one is the right one

2817
01:33:44,320 --> 01:33:45,840
right so there's many different levels

2818
01:33:45,840 --> 01:33:48,320
of of you know empirical questions that

2819
01:33:48,320 --> 01:33:50,159
that you can ask

2820
01:33:50,159 --> 01:33:51,360
at each of these different levels of

2821
01:33:51,360 --> 01:33:53,280
description yep

2822
01:33:53,280 --> 01:33:55,280
what i'll say to that is that the

2823
01:33:55,280 --> 01:33:56,719
relationship between the free energy

2824
01:33:56,719 --> 01:33:57,600
principle

2825
01:33:57,600 --> 01:33:59,760
and active inference again as a process

2826
01:33:59,760 --> 01:34:00,639
theory

2827
01:34:00,639 --> 01:34:02,480
it means something uh within the

2828
01:34:02,480 --> 01:34:04,000
philosophy of science literature

2829
01:34:04,000 --> 01:34:06,800
so check out the alias 2018 interview

2830
01:34:06,800 --> 01:34:07,120
with

2831
01:34:07,120 --> 01:34:10,159
carl fristen myself and marchand fortre

2832
01:34:10,159 --> 01:34:13,280
or the recent paper of mel andrews

2833
01:34:13,280 --> 01:34:15,280
because basically the process theory

2834
01:34:15,280 --> 01:34:16,480
makes specific

2835
01:34:16,480 --> 01:34:19,600
falsifiable testable hypotheses so

2836
01:34:19,600 --> 01:34:20,719
that's the kind of thing you could

2837
01:34:20,719 --> 01:34:23,120
actually then say dopamine use this kind

2838
01:34:23,120 --> 01:34:23,679
of tool

2839
01:34:23,679 --> 01:34:25,520
and you should expect to see this and

2840
01:34:25,520 --> 01:34:27,199
that's why this is a little bit more

2841
01:34:27,199 --> 01:34:28,080
towards the data

2842
01:34:28,080 --> 01:34:31,600
focused empirical end so continue right

2843
01:34:31,600 --> 01:34:33,360
yeah but like i said i mean we'll go

2844
01:34:33,360 --> 01:34:35,360
into it you know task models will make

2845
01:34:35,360 --> 01:34:36,800
specific predictions about

2846
01:34:36,800 --> 01:34:39,040
what kind of erps you know you would

2847
01:34:39,040 --> 01:34:40,080
measure in uh

2848
01:34:40,080 --> 01:34:43,440
eeg uh you know during certain tasks or

2849
01:34:43,440 --> 01:34:45,280
same thing with like fmri responses

2850
01:34:45,280 --> 01:34:47,040
and and so but anyway we'll we'll get

2851
01:34:47,040 --> 01:34:49,040
into that in another session

2852
01:34:49,040 --> 01:34:50,719
um so just uh you know so this is

2853
01:34:50,719 --> 01:34:52,080
another example again i'll walk you

2854
01:34:52,080 --> 01:34:53,199
through these really briefly

2855
01:34:53,199 --> 01:34:55,040
but that's what that's another

2856
01:34:55,040 --> 01:34:56,560
generative model we built for this

2857
01:34:56,560 --> 01:34:57,119
heartbeat

2858
01:34:57,119 --> 01:34:59,840
perception task and what we found here

2859
01:34:59,840 --> 01:35:01,040
was that

2860
01:35:01,040 --> 01:35:02,800
in a certain condition a certain high

2861
01:35:02,800 --> 01:35:04,320
arousal condition

2862
01:35:04,320 --> 01:35:07,440
healthy people showed higher precision

2863
01:35:07,440 --> 01:35:10,639
uh higher intraoceptive precision

2864
01:35:10,639 --> 01:35:12,080
whereas a bunch of different clinical

2865
01:35:12,080 --> 01:35:14,159
groups didn't show any change in

2866
01:35:14,159 --> 01:35:15,600
precision

2867
01:35:15,600 --> 01:35:17,199
so again it's just showing differences

2868
01:35:17,199 --> 01:35:19,520
here in the way the brain treats signals

2869
01:35:19,520 --> 01:35:21,119
coming up from the body

2870
01:35:21,119 --> 01:35:24,080
when in a high arousal state um or

2871
01:35:24,080 --> 01:35:25,360
really a state where they're having to

2872
01:35:25,360 --> 01:35:26,639
hold their breath for a long period of

2873
01:35:26,639 --> 01:35:28,719
time but um

2874
01:35:28,719 --> 01:35:30,639
and then that's you know you can also

2875
01:35:30,639 --> 01:35:32,480
estimate prior expectations those didn't

2876
01:35:32,480 --> 01:35:33,679
differ by group

2877
01:35:33,679 --> 01:35:37,920
um then finally this is an example of

2878
01:35:37,920 --> 01:35:39,679
doing uh using active inference for

2879
01:35:39,679 --> 01:35:40,960
neural imaging that

2880
01:35:40,960 --> 01:35:43,840
philip schortenbeck did and here he was

2881
01:35:43,840 --> 01:35:44,480
looking at

2882
01:35:44,480 --> 01:35:47,679
the the beta gamma updates the expected

2883
01:35:47,679 --> 01:35:49,440
free energy precision updates

2884
01:35:49,440 --> 01:35:51,199
and he showed that trial by trial those

2885
01:35:51,199 --> 01:35:53,920
did those updates did correlate

2886
01:35:53,920 --> 01:35:55,600
with these midbrain region with this

2887
01:35:55,600 --> 01:35:57,360
midbrain region um

2888
01:35:57,360 --> 01:35:59,760
that is where a chunk of that region is

2889
01:35:59,760 --> 01:36:00,800
is um

2890
01:36:00,800 --> 01:36:03,760
where a bunch of dopamine neurons are um

2891
01:36:03,760 --> 01:36:05,760
so sort of consistent with this kind of

2892
01:36:05,760 --> 01:36:06,800
idea that

2893
01:36:06,800 --> 01:36:08,639
phasic dopamine responses are the ones

2894
01:36:08,639 --> 01:36:10,480
encoding these changes and expected free

2895
01:36:10,480 --> 01:36:12,080
energy precision

2896
01:36:12,080 --> 01:36:14,400
um anyway so those are just a bunch of

2897
01:36:14,400 --> 01:36:15,840
examples of the way that this kind of

2898
01:36:15,840 --> 01:36:17,679
thing has been used

2899
01:36:17,679 --> 01:36:18,800
and i should point out that this is all

2900
01:36:18,800 --> 01:36:20,080
just within the last couple of years

2901
01:36:20,080 --> 01:36:21,440
this is very recent

2902
01:36:21,440 --> 01:36:24,400
um so the the task that um i'm going to

2903
01:36:24,400 --> 01:36:26,000
walk you through how to actually build

2904
01:36:26,000 --> 01:36:26,320
it

2905
01:36:26,320 --> 01:36:28,080
um and we'll see how much time we

2906
01:36:28,080 --> 01:36:30,159
actually have to go through this

2907
01:36:30,159 --> 01:36:33,600
um is a pretty simple task where

2908
01:36:33,600 --> 01:36:35,760
you just the participant just starts in

2909
01:36:35,760 --> 01:36:37,119
the start state

2910
01:36:37,119 --> 01:36:39,760
and initially they don't know anything

2911
01:36:39,760 --> 01:36:41,520
about they have to choose one of two

2912
01:36:41,520 --> 01:36:42,960
of these slot machines the one on the

2913
01:36:42,960 --> 01:36:44,719
left or the one on the right

2914
01:36:44,719 --> 01:36:46,480
um and they don't know you know i have

2915
01:36:46,480 --> 01:36:49,199
no idea to start with on trial one

2916
01:36:49,199 --> 01:36:52,639
what which one is more likely to uh to

2917
01:36:52,639 --> 01:36:53,760
give a reward

2918
01:36:53,760 --> 01:36:56,639
and if you're in the the left better

2919
01:36:56,639 --> 01:36:58,400
context then that means that

2920
01:36:58,400 --> 01:37:00,719
choosing the left slot machine will win

2921
01:37:00,719 --> 01:37:02,239
80 percent of the time

2922
01:37:02,239 --> 01:37:04,320
and if you're in the the right better

2923
01:37:04,320 --> 01:37:05,520
context

2924
01:37:05,520 --> 01:37:07,040
then choosing the right slot machine

2925
01:37:07,040 --> 01:37:08,639
will give you the reward

2926
01:37:08,639 --> 01:37:12,080
um eighty percent of the time um and so

2927
01:37:12,080 --> 01:37:13,280
crucially

2928
01:37:13,280 --> 01:37:15,119
if on the first time step they just

2929
01:37:15,119 --> 01:37:16,960
choose a slot machine

2930
01:37:16,960 --> 01:37:19,119
then uh they could they'll win four

2931
01:37:19,119 --> 01:37:21,119
dollars if they're right

2932
01:37:21,119 --> 01:37:22,880
um but the other things that'd be kind

2933
01:37:22,880 --> 01:37:24,320
of like the reward seeking thing you

2934
01:37:24,320 --> 01:37:26,400
know they want as much money as possible

2935
01:37:26,400 --> 01:37:28,960
um but what they can also do is they can

2936
01:37:28,960 --> 01:37:29,760
first

2937
01:37:29,760 --> 01:37:32,320
ask for this hint if they choose to ask

2938
01:37:32,320 --> 01:37:33,440
for the hint

2939
01:37:33,440 --> 01:37:35,679
it will tell them what context they're

2940
01:37:35,679 --> 01:37:37,040
in it will tell them whether it's left

2941
01:37:37,040 --> 01:37:38,400
better or write better

2942
01:37:38,400 --> 01:37:41,600
and then they can choose one of the two

2943
01:37:41,600 --> 01:37:44,159
slot machines and again they'll win 80

2944
01:37:44,159 --> 01:37:45,679
of the time

2945
01:37:45,679 --> 01:37:47,119
if they choose the right one based on

2946
01:37:47,119 --> 01:37:50,080
the hint but crucially

2947
01:37:50,080 --> 01:37:52,719
if they take the hint first then they'll

2948
01:37:52,719 --> 01:37:54,400
only win two dollars if they get it

2949
01:37:54,400 --> 01:37:54,880
right

2950
01:37:54,880 --> 01:37:56,400
instead of four so in other words taking

2951
01:37:56,400 --> 01:37:58,080
the hint is costly

2952
01:37:58,080 --> 01:38:01,600
um so so you can think of choosing one

2953
01:38:01,600 --> 01:38:03,600
of the slot machines right away as being

2954
01:38:03,600 --> 01:38:04,480
this kind of

2955
01:38:04,480 --> 01:38:06,880
reward seeking thing where it's also

2956
01:38:06,880 --> 01:38:07,840
risk seeking

2957
01:38:07,840 --> 01:38:09,199
because you don't know ahead of time

2958
01:38:09,199 --> 01:38:10,880
which one's the right one

2959
01:38:10,880 --> 01:38:12,719
or you can do this information seeking

2960
01:38:12,719 --> 01:38:14,719
thing where you choose the hint first

2961
01:38:14,719 --> 01:38:16,159
even though that'll get you less money

2962
01:38:16,159 --> 01:38:17,679
but you'll be more confident which one's

2963
01:38:17,679 --> 01:38:19,600
right

2964
01:38:19,600 --> 01:38:21,600
so it's set up specifically to have this

2965
01:38:21,600 --> 01:38:23,440
information gain component by choosing

2966
01:38:23,440 --> 01:38:24,320
the hint

2967
01:38:24,320 --> 01:38:26,000
and the reward seeking component by

2968
01:38:26,000 --> 01:38:29,199
choosing one of the two slot machines

2969
01:38:29,199 --> 01:38:30,480
so the question is how would you

2970
01:38:30,480 --> 01:38:32,320
actually in practice build a model of

2971
01:38:32,320 --> 01:38:34,159
this kind of task

2972
01:38:34,159 --> 01:38:37,199
now the first thing you know so so

2973
01:38:37,199 --> 01:38:38,560
there's going to be some basic steps to

2974
01:38:38,560 --> 01:38:39,600
do this

2975
01:38:39,600 --> 01:38:42,080
one is to define whatever your initial

2976
01:38:42,080 --> 01:38:43,520
state priors are

2977
01:38:43,520 --> 01:38:46,159
and that's going to be that d thing um

2978
01:38:46,159 --> 01:38:47,760
and just as a you know we'll go into

2979
01:38:47,760 --> 01:38:49,360
this more with the learning

2980
01:38:49,360 --> 01:38:52,000
but big d if you use both big d and

2981
01:38:52,000 --> 01:38:52,639
little d

2982
01:38:52,639 --> 01:38:54,159
big d is kind of like the true

2983
01:38:54,159 --> 01:38:56,639
generative process um you know the real

2984
01:38:56,639 --> 01:38:57,760
thing out in the world that are

2985
01:38:57,760 --> 01:38:59,679
generating the observations

2986
01:38:59,679 --> 01:39:02,960
um and little d if you use it is a

2987
01:39:02,960 --> 01:39:05,199
is what's in the generative model so the

2988
01:39:05,199 --> 01:39:06,719
the agent's beliefs

2989
01:39:06,719 --> 01:39:08,400
right and those two can be so big d and

2990
01:39:08,400 --> 01:39:10,159
little d can be different if big d and

2991
01:39:10,159 --> 01:39:12,080
little d are the same that means

2992
01:39:12,080 --> 01:39:15,199
that the agent's beliefs are accurate

2993
01:39:15,199 --> 01:39:18,239
um and so

2994
01:39:18,239 --> 01:39:20,960
if you want the agent to learn or to

2995
01:39:20,960 --> 01:39:22,800
have different prior expectations than

2996
01:39:22,800 --> 01:39:24,000
what the true ones are

2997
01:39:24,000 --> 01:39:26,400
then you have to use this little d thing

2998
01:39:26,400 --> 01:39:27,280
um

2999
01:39:27,280 --> 01:39:29,040
same thing here we have to define the

3000
01:39:29,040 --> 01:39:30,639
the likelihood or the state outcome

3001
01:39:30,639 --> 01:39:31,520
mapping

3002
01:39:31,520 --> 01:39:33,760
and that's going to be our big a and our

3003
01:39:33,760 --> 01:39:35,520
little a if we want it to

3004
01:39:35,520 --> 01:39:37,760
learn and have different beliefs than

3005
01:39:37,760 --> 01:39:39,840
the true ones

3006
01:39:39,840 --> 01:39:41,760
we have to define the preferences over

3007
01:39:41,760 --> 01:39:43,520
outcomes right so that's going to be the

3008
01:39:43,520 --> 01:39:46,400
c thing then we have to divide to find

3009
01:39:46,400 --> 01:39:47,920
the possible transitions

3010
01:39:47,920 --> 01:39:51,040
or actions um and so you know if there's

3011
01:39:51,040 --> 01:39:52,800
just one transition matrix for a factor

3012
01:39:52,800 --> 01:39:55,199
that just means the agent has no control

3013
01:39:55,199 --> 01:39:55,840
over

3014
01:39:55,840 --> 01:39:58,400
what it does but if there's a state

3015
01:39:58,400 --> 01:39:59,440
factor

3016
01:39:59,440 --> 01:40:01,280
that can have multiple possible

3017
01:40:01,280 --> 01:40:02,480
transitions

3018
01:40:02,480 --> 01:40:04,320
where each transition is like like an

3019
01:40:04,320 --> 01:40:06,159
action

3020
01:40:06,159 --> 01:40:09,520
then uh the agent can choose policies

3021
01:40:09,520 --> 01:40:11,040
that correspond to different

3022
01:40:11,040 --> 01:40:14,000
transition sequences um you know so for

3023
01:40:14,000 --> 01:40:14,880
instance

3024
01:40:14,880 --> 01:40:17,520
well i'll just show you um but then but

3025
01:40:17,520 --> 01:40:18,480
then for

3026
01:40:18,480 --> 01:40:20,480
v here the last thing you have to define

3027
01:40:20,480 --> 01:40:22,239
is policies which is

3028
01:40:22,239 --> 01:40:24,719
this thing v in the code and that's

3029
01:40:24,719 --> 01:40:26,239
going to be specifying different

3030
01:40:26,239 --> 01:40:28,320
sequences of b matrices different

3031
01:40:28,320 --> 01:40:29,360
sequences of

3032
01:40:29,360 --> 01:40:31,679
possible transitions that could happen

3033
01:40:31,679 --> 01:40:32,960
over the course of the trial and that

3034
01:40:32,960 --> 01:40:34,080
the agent could choose

3035
01:40:34,080 --> 01:40:39,360
one of those transition sequences um

3036
01:40:39,679 --> 01:40:41,840
yeah really really quickly for each of

3037
01:40:41,840 --> 01:40:43,280
those then if

3038
01:40:43,280 --> 01:40:44,960
if there's uh you know if i'm talking

3039
01:40:44,960 --> 01:40:46,560
about a different outcome modality i

3040
01:40:46,560 --> 01:40:47,520
would have

3041
01:40:47,520 --> 01:40:48,480
i would have to have one of those

3042
01:40:48,480 --> 01:40:50,320
parameters for each outcome modality is

3043
01:40:50,320 --> 01:40:51,520
that correct

3044
01:40:51,520 --> 01:40:54,000
um you would need to have so there's

3045
01:40:54,000 --> 01:40:54,800
going to be

3046
01:40:54,800 --> 01:40:59,119
one uh a matrix

3047
01:40:59,119 --> 01:41:02,239
for each outcome modality and that's

3048
01:41:02,239 --> 01:41:03,600
just going to say

3049
01:41:03,600 --> 01:41:05,840
what uh what outcomes are going to most

3050
01:41:05,840 --> 01:41:07,199
likely to be generated

3051
01:41:07,199 --> 01:41:10,800
um given each combination of of states

3052
01:41:10,800 --> 01:41:14,639
um so given the value of each of each uh

3053
01:41:14,639 --> 01:41:17,600
state factor um and and these are things

3054
01:41:17,600 --> 01:41:18,080
that are

3055
01:41:18,080 --> 01:41:19,679
that come up in experimental design

3056
01:41:19,679 --> 01:41:21,520
right so like the probability that a

3057
01:41:21,520 --> 01:41:23,600
given machine would dispense

3058
01:41:23,600 --> 01:41:25,840
a winning ticket or that's something i

3059
01:41:25,840 --> 01:41:27,119
should be thinking about as the

3060
01:41:27,119 --> 01:41:29,119
empirical person designing my experiment

3061
01:41:29,119 --> 01:41:29,760
right

3062
01:41:29,760 --> 01:41:32,880
yeah exactly so so i'll show you

3063
01:41:32,880 --> 01:41:35,600
um here but right so typically you can

3064
01:41:35,600 --> 01:41:37,119
do it other ways but typically

3065
01:41:37,119 --> 01:41:38,639
this likelihood thing is what would

3066
01:41:38,639 --> 01:41:41,600
define the um the reward probabilities

3067
01:41:41,600 --> 01:41:43,520
right so you'd say given that i'm in the

3068
01:41:43,520 --> 01:41:44,719
state of

3069
01:41:44,719 --> 01:41:48,480
uh you know having chosen the left

3070
01:41:48,480 --> 01:41:52,239
uh slot machine um that will generate

3071
01:41:52,239 --> 01:41:55,360
reward the reward observation with 0.8

3072
01:41:55,360 --> 01:41:58,239
and the not reward observation as point

3073
01:41:58,239 --> 01:41:59,119
as 0.2

3074
01:41:59,119 --> 01:42:01,040
for example such as saying the reward

3075
01:42:01,040 --> 01:42:02,719
probability is eighty percent

3076
01:42:02,719 --> 01:42:05,760
um and you know the agent would

3077
01:42:05,760 --> 01:42:07,119
if you want them to learn those word

3078
01:42:07,119 --> 01:42:08,480
probabilities then you'd specify one of

3079
01:42:08,480 --> 01:42:09,760
these little a things and then you'd

3080
01:42:09,760 --> 01:42:10,320
have it

3081
01:42:10,320 --> 01:42:13,280
learn it um over repeated observations

3082
01:42:13,280 --> 01:42:14,239
um

3083
01:42:14,239 --> 01:42:16,560
it's such a critical and and really

3084
01:42:16,560 --> 01:42:18,480
fascinating point that

3085
01:42:18,480 --> 01:42:20,960
reward isn't absent from the model

3086
01:42:20,960 --> 01:42:22,480
through the preference vector c

3087
01:42:22,480 --> 01:42:26,639
it's baked into how policy is calculated

3088
01:42:26,639 --> 01:42:29,040
and so it's like the agent is pursuing

3089
01:42:29,040 --> 01:42:30,239
precision

3090
01:42:30,239 --> 01:42:32,000
all things being equal through natural

3091
01:42:32,000 --> 01:42:33,360
selection you know

3092
01:42:33,360 --> 01:42:35,199
unsuccessful models are just not going

3093
01:42:35,199 --> 01:42:37,199
to exist and models that

3094
01:42:37,199 --> 01:42:39,600
don't see themselves performing behavior

3095
01:42:39,600 --> 01:42:41,280
are not going to be active for long

3096
01:42:41,280 --> 01:42:44,480
so under a model of a successful

3097
01:42:44,480 --> 01:42:47,040
preference then there's just a

3098
01:42:47,040 --> 01:42:48,880
convergence towards that with whatever

3099
01:42:48,880 --> 01:42:50,560
affordances are at hand

3100
01:42:50,560 --> 01:42:52,719
so it's just a really interesting way to

3101
01:42:52,719 --> 01:42:53,679
see how re

3102
01:42:53,679 --> 01:42:57,840
uh reinforcement learning situations

3103
01:42:57,840 --> 01:43:01,199
um can be adapted so

3104
01:43:01,199 --> 01:43:04,000
the atms some of the some of it gets a

3105
01:43:04,000 --> 01:43:05,840
little bit more into the kind of like

3106
01:43:05,840 --> 01:43:08,960
free energy philosophy stuff but but

3107
01:43:08,960 --> 01:43:12,159
i mean yes like the assumption is that

3108
01:43:12,159 --> 01:43:14,400
uh people inherit preferences that keep

3109
01:43:14,400 --> 01:43:15,520
them alive

3110
01:43:15,520 --> 01:43:18,239
um but uh but in in kind of like an

3111
01:43:18,239 --> 01:43:20,159
empirical task context you just use the

3112
01:43:20,159 --> 01:43:21,440
c vector to just

3113
01:43:21,440 --> 01:43:24,560
define what counts as the reward um

3114
01:43:24,560 --> 01:43:26,080
you know it could be it could be

3115
01:43:26,080 --> 01:43:27,840
anything right it could be winning money

3116
01:43:27,840 --> 01:43:28,800
it could be winning

3117
01:43:28,800 --> 01:43:30,880
points even if it doesn't give you money

3118
01:43:30,880 --> 01:43:31,920
right it could be like

3119
01:43:31,920 --> 01:43:34,159
seeing a positive image you know

3120
01:43:34,159 --> 01:43:35,760
anything like that you just define

3121
01:43:35,760 --> 01:43:38,159
what the preference distribution is um

3122
01:43:38,159 --> 01:43:39,840
and then usually you parameterize it so

3123
01:43:39,840 --> 01:43:40,560
you

3124
01:43:40,560 --> 01:43:42,000
fit that as a parameter to see

3125
01:43:42,000 --> 01:43:44,239
essentially how much does the person

3126
01:43:44,239 --> 01:43:44,800
like

3127
01:43:44,800 --> 01:43:47,199
you know winning two dollars for example

3128
01:43:47,199 --> 01:43:47,920
um

3129
01:43:47,920 --> 01:43:50,880
and i'll show you that in a second um

3130
01:43:50,880 --> 01:43:52,080
but uh but yeah

3131
01:43:52,080 --> 01:43:55,199
so so you're gonna need one c uh

3132
01:43:55,199 --> 01:43:57,920
c matrix uh for each so you need one a

3133
01:43:57,920 --> 01:43:59,760
matrix and one c matrix for each output

3134
01:43:59,760 --> 01:44:00,800
modality

3135
01:44:00,800 --> 01:44:03,600
um and you're gonna need one d vector

3136
01:44:03,600 --> 01:44:05,760
and at least one v matrix for each state

3137
01:44:05,760 --> 01:44:06,639
factor

3138
01:44:06,639 --> 01:44:10,000
um as the to answer your uh the original

3139
01:44:10,000 --> 01:44:11,040
question

3140
01:44:11,040 --> 01:44:14,480
um so so the first thing here

3141
01:44:14,480 --> 01:44:18,000
right is you the first so the way that

3142
01:44:18,000 --> 01:44:19,840
i decided to build the model for this

3143
01:44:19,840 --> 01:44:21,280
task is

3144
01:44:21,280 --> 01:44:24,560
the first hidden state factor is the

3145
01:44:24,560 --> 01:44:25,280
context

3146
01:44:25,280 --> 01:44:27,600
right so am i in the state where the

3147
01:44:27,600 --> 01:44:29,119
left one is better

3148
01:44:29,119 --> 01:44:30,960
or am i in the state where the right one

3149
01:44:30,960 --> 01:44:32,159
is better

3150
01:44:32,159 --> 01:44:34,560
and i started that out specifying this

3151
01:44:34,560 --> 01:44:36,080
little d here thing

3152
01:44:36,080 --> 01:44:38,400
um and the brackets just say the number

3153
01:44:38,400 --> 01:44:40,080
of the state factor so this is d

3154
01:44:40,080 --> 01:44:42,239
for state factor priors over states for

3155
01:44:42,239 --> 01:44:43,679
state factor one

3156
01:44:43,679 --> 01:44:45,199
and there's two different possible

3157
01:44:45,199 --> 01:44:47,679
states left better or write better

3158
01:44:47,679 --> 01:44:49,840
and i just specified these as two really

3159
01:44:49,840 --> 01:44:50,719
small numbers

3160
01:44:50,719 --> 01:44:54,239
which just says it's an even probability

3161
01:44:54,239 --> 01:44:56,320
that the it's going to be the left one

3162
01:44:56,320 --> 01:44:57,840
or the right one is better

3163
01:44:57,840 --> 01:44:59,520
but these are really small and so i'm

3164
01:44:59,520 --> 01:45:01,760
not confident at all

3165
01:45:01,760 --> 01:45:04,000
about you know whether that distribution

3166
01:45:04,000 --> 01:45:05,040
is right

3167
01:45:05,040 --> 01:45:06,960
um and i'll explain more about that when

3168
01:45:06,960 --> 01:45:08,080
we get to the learning

3169
01:45:08,080 --> 01:45:10,960
um because this is this will be soft

3170
01:45:10,960 --> 01:45:11,920
maxed

3171
01:45:11,920 --> 01:45:14,840
um during inference so this will become

3172
01:45:14,840 --> 01:45:16,560
0.5.5

3173
01:45:16,560 --> 01:45:19,520
during inference but when you learn you

3174
01:45:19,520 --> 01:45:20,239
sort of

3175
01:45:20,239 --> 01:45:22,159
build up the numbers here so they become

3176
01:45:22,159 --> 01:45:23,679
bigger numbers

3177
01:45:23,679 --> 01:45:25,440
which means the agent learns to be more

3178
01:45:25,440 --> 01:45:27,360
confident in what the distribution is

3179
01:45:27,360 --> 01:45:29,679
that it believes

3180
01:45:29,679 --> 01:45:31,760
but then i can also specify big d right

3181
01:45:31,760 --> 01:45:33,600
which is the generative process

3182
01:45:33,600 --> 01:45:35,280
and i just put this as one and zero

3183
01:45:35,280 --> 01:45:36,960
which means that the true context is

3184
01:45:36,960 --> 01:45:38,800
that the left one's better

3185
01:45:38,800 --> 01:45:42,400
um so that's what i would use to set up

3186
01:45:42,400 --> 01:45:45,760
the priors for uh state factor one

3187
01:45:45,760 --> 01:45:48,800
um state factor two here um if you can

3188
01:45:48,800 --> 01:45:49,360
see

3189
01:45:49,360 --> 01:45:52,480
at the bottom um so

3190
01:45:52,480 --> 01:45:55,280
hold on can you guys you guys see this

3191
01:45:55,280 --> 01:45:56,880
or can you guys see the bottom because

3192
01:45:56,880 --> 01:45:57,199
uh

3193
01:45:57,199 --> 01:45:59,360
for in mine i can see like my bottom the

3194
01:45:59,360 --> 01:46:00,320
like

3195
01:46:00,320 --> 01:46:03,440
we only see one line of code yeah the d2

3196
01:46:03,440 --> 01:46:06,320
bind yeah i'm just asking do you see

3197
01:46:06,320 --> 01:46:08,320
like this like search down here and all

3198
01:46:08,320 --> 01:46:09,040
that stuff

3199
01:46:09,040 --> 01:46:10,800
it's perfect it's perfect okay there now

3200
01:46:10,800 --> 01:46:12,159
it's gone okay

3201
01:46:12,159 --> 01:46:15,840
so so then d2 is the second

3202
01:46:15,840 --> 01:46:17,440
hidden state factor and that's the one

3203
01:46:17,440 --> 01:46:19,440
that corresponds to your choices

3204
01:46:19,440 --> 01:46:21,440
right so this is a one here which means

3205
01:46:21,440 --> 01:46:23,040
it always starts out in the

3206
01:46:23,040 --> 01:46:25,280
start states the first column here is

3207
01:46:25,280 --> 01:46:26,639
the start state

3208
01:46:26,639 --> 01:46:28,320
and then it can either transition into

3209
01:46:28,320 --> 01:46:30,239
the hint state right which is the second

3210
01:46:30,239 --> 01:46:32,239
one here i just define that

3211
01:46:32,239 --> 01:46:35,600
um and then the third one is the choose

3212
01:46:35,600 --> 01:46:36,239
the left

3213
01:46:36,239 --> 01:46:37,920
slot machine state and the fourth one is

3214
01:46:37,920 --> 01:46:40,960
choose the right slot machine state

3215
01:46:40,960 --> 01:46:43,600
so this is just says at time one my

3216
01:46:43,600 --> 01:46:44,239
prior

3217
01:46:44,239 --> 01:46:46,239
is with 100 certainty that i'm going to

3218
01:46:46,239 --> 01:46:47,280
start in the start take

3219
01:46:47,280 --> 01:46:50,159
of the task um so that's actually pretty

3220
01:46:50,159 --> 01:46:51,119
simple

3221
01:46:51,119 --> 01:46:53,119
right so then the next thing you're

3222
01:46:53,119 --> 01:46:54,880
going to do is you're going to have to

3223
01:46:54,880 --> 01:46:59,440
specify the likelihood so the a matrix

3224
01:46:59,440 --> 01:47:00,320
and i'm not going to show you the

3225
01:47:00,320 --> 01:47:01,920
complete one yet until we go into the

3226
01:47:01,920 --> 01:47:02,800
code i'm just going to show you the

3227
01:47:02,800 --> 01:47:04,159
parts that matter

3228
01:47:04,159 --> 01:47:08,639
um but so for the second state factor

3229
01:47:08,639 --> 01:47:11,280
so a2 so uh for the second outcome

3230
01:47:11,280 --> 01:47:12,480
modality

3231
01:47:12,480 --> 01:47:16,000
so the likelihood mapping for a two um

3232
01:47:16,000 --> 01:47:19,280
is going to be this thing where

3233
01:47:19,280 --> 01:47:21,360
the first row corresponds to null which

3234
01:47:21,360 --> 01:47:22,560
is just it hasn't won

3235
01:47:22,560 --> 01:47:24,960
or lost yet the second row is the

3236
01:47:24,960 --> 01:47:26,480
observation that it lost

3237
01:47:26,480 --> 01:47:28,719
and the third row is the observation

3238
01:47:28,719 --> 01:47:30,719
that it won

3239
01:47:30,719 --> 01:47:33,199
and each of the columns here correspond

3240
01:47:33,199 --> 01:47:34,000
to

3241
01:47:34,000 --> 01:47:35,760
the state factor values so the left

3242
01:47:35,760 --> 01:47:37,679
column here corresponds to

3243
01:47:37,679 --> 01:47:40,960
the d1 you know this thing you know

3244
01:47:40,960 --> 01:47:44,159
uh so the 0.25 here for left better for

3245
01:47:44,159 --> 01:47:45,520
the left better state

3246
01:47:45,520 --> 01:47:47,600
and the right one here is the one that

3247
01:47:47,600 --> 01:47:50,159
corresponds to the light better state

3248
01:47:50,159 --> 01:47:52,880
which maps onto column two here so the

3249
01:47:52,880 --> 01:47:55,119
way that you would read this matrix is

3250
01:47:55,119 --> 01:47:58,000
that if you were in the right state

3251
01:47:58,000 --> 01:47:58,880
right better

3252
01:47:58,880 --> 01:48:02,400
state then you would

3253
01:48:02,400 --> 01:48:05,679
win with this probability

3254
01:48:05,679 --> 01:48:09,040
and you would lose with this probability

3255
01:48:09,040 --> 01:48:11,760
um or if you were in the left one then

3256
01:48:11,760 --> 01:48:13,520
you would lose with that probability and

3257
01:48:13,520 --> 01:48:14,960
win with that probability

3258
01:48:14,960 --> 01:48:18,159
um the columns of that soft maxed

3259
01:48:18,159 --> 01:48:20,719
are those are those distributions yeah

3260
01:48:20,719 --> 01:48:22,320
the columns the columns are shaft maxed

3261
01:48:22,320 --> 01:48:24,560
yeah again if you're using i mean to get

3262
01:48:24,560 --> 01:48:26,400
a little technical if you're using

3263
01:48:26,400 --> 01:48:27,840
if you're using little a so these are

3264
01:48:27,840 --> 01:48:29,600
dirichlet distributions

3265
01:48:29,600 --> 01:48:31,840
then it will build up counts right so

3266
01:48:31,840 --> 01:48:33,600
these numbers could become like

3267
01:48:33,600 --> 01:48:37,520
you know like 50 25 8 you know whatever

3268
01:48:37,520 --> 01:48:39,600
but those that encode the confidence in

3269
01:48:39,600 --> 01:48:40,960
those distributions but yeah they'll get

3270
01:48:40,960 --> 01:48:44,080
soft max for inference

3271
01:48:44,840 --> 01:48:46,800
um so then

3272
01:48:46,800 --> 01:48:49,840
so then you'd have to also specify the c

3273
01:48:49,840 --> 01:48:50,639
matrix

3274
01:48:50,639 --> 01:48:54,159
for that state factor or i mean that

3275
01:48:54,159 --> 01:48:56,000
outcome modality sorry so c2

3276
01:48:56,000 --> 01:48:57,840
is going to correspond to a2 basically

3277
01:48:57,840 --> 01:48:59,119
it's for the sec they're both for the

3278
01:48:59,119 --> 01:49:00,880
second outcome modality

3279
01:49:00,880 --> 01:49:03,440
um and here again rows are going to be

3280
01:49:03,440 --> 01:49:04,880
observations

3281
01:49:04,880 --> 01:49:07,760
but here the uh the rows correspond to

3282
01:49:07,760 --> 01:49:08,719
time points

3283
01:49:08,719 --> 01:49:11,840
in the trial um so basically this is

3284
01:49:11,840 --> 01:49:12,560
just saying

3285
01:49:12,560 --> 01:49:16,639
that um at time 0 or at time 1

3286
01:49:16,639 --> 01:49:19,360
i have no preference for anything at

3287
01:49:19,360 --> 01:49:19,679
time

3288
01:49:19,679 --> 01:49:22,880
2 i have a negative preference for

3289
01:49:22,880 --> 01:49:23,599
losing

3290
01:49:23,599 --> 01:49:25,599
and i have a positive preference for

3291
01:49:25,599 --> 01:49:27,599
winning and this rs thing is just a

3292
01:49:27,599 --> 01:49:29,679
parameter right so we can say this la

3293
01:49:29,679 --> 01:49:31,199
thing so loss of version

3294
01:49:31,199 --> 01:49:33,360
is one so it doesn't want to lose with

3295
01:49:33,360 --> 01:49:34,560
negative one

3296
01:49:34,560 --> 01:49:38,080
right um and for rs we say rs equals

3297
01:49:38,080 --> 01:49:38,880
four

3298
01:49:38,880 --> 01:49:40,480
which is you could think of as the four

3299
01:49:40,480 --> 01:49:42,000
dollars right

3300
01:49:42,000 --> 01:49:44,719
and then so if it ch if it observes the

3301
01:49:44,719 --> 01:49:45,280
win

3302
01:49:45,280 --> 01:49:47,599
at time two then it's gonna prefer that

3303
01:49:47,599 --> 01:49:49,360
with a value of four

3304
01:49:49,360 --> 01:49:51,840
and if it's gets it at time three then

3305
01:49:51,840 --> 01:49:53,520
it's gonna be rs divided by two which

3306
01:49:53,520 --> 01:49:54,960
means at time three if it gets it it's

3307
01:49:54,960 --> 01:49:56,800
only gonna win two dollars

3308
01:49:56,800 --> 01:49:59,119
right or whatever the relative values

3309
01:49:59,119 --> 01:50:01,280
are for the person right you could fit

3310
01:50:01,280 --> 01:50:04,719
rs for a given person um to see how much

3311
01:50:04,719 --> 01:50:05,440
they

3312
01:50:05,440 --> 01:50:08,239
prefer four dollars over two for example

3313
01:50:08,239 --> 01:50:09,280
um

3314
01:50:09,280 --> 01:50:13,119
and um these also um in the code are

3315
01:50:13,119 --> 01:50:14,480
soft maxed and then

3316
01:50:14,480 --> 01:50:16,960
uh logged um so they become they become

3317
01:50:16,960 --> 01:50:18,000
long probabilities

3318
01:50:18,000 --> 01:50:21,040
um um so that's just saying

3319
01:50:21,040 --> 01:50:23,199
how much you dislike losing and how much

3320
01:50:23,199 --> 01:50:24,320
you want to win

3321
01:50:24,320 --> 01:50:25,520
and again you can set those as

3322
01:50:25,520 --> 01:50:28,080
parameters

3323
01:50:28,080 --> 01:50:31,119
and then for state outcome

3324
01:50:31,119 --> 01:50:34,239
for outcome modality one which is the

3325
01:50:34,239 --> 01:50:36,719
getting the hint right you can have no

3326
01:50:36,719 --> 01:50:37,440
hint

3327
01:50:37,440 --> 01:50:39,199
you can have the hint that the left

3328
01:50:39,199 --> 01:50:40,639
machine is better and the hint that the

3329
01:50:40,639 --> 01:50:42,000
right machine is better right so those

3330
01:50:42,000 --> 01:50:43,920
are both observations

3331
01:50:43,920 --> 01:50:46,960
and then you can say uh with this pha

3332
01:50:46,960 --> 01:50:48,880
thing you can say basically how

3333
01:50:48,880 --> 01:50:51,440
how informative is the hint right like

3334
01:50:51,440 --> 01:50:52,719
if i observe the machine

3335
01:50:52,719 --> 01:50:54,159
left hint does that tell me with

3336
01:50:54,159 --> 01:50:56,639
certainty that the left one's better or

3337
01:50:56,639 --> 01:50:57,760
does it just tell me with some

3338
01:50:57,760 --> 01:51:00,080
probability that the left one's better

3339
01:51:00,080 --> 01:51:02,239
um and here you could just set this as

3340
01:51:02,239 --> 01:51:03,760
uh being

3341
01:51:03,760 --> 01:51:05,760
you know like you could just set uh this

3342
01:51:05,760 --> 01:51:07,440
is like ones and zeroes

3343
01:51:07,440 --> 01:51:10,800
um to just to just tell you uh

3344
01:51:10,800 --> 01:51:13,440
basically that would just say uh if pha

3345
01:51:13,440 --> 01:51:14,960
was one then that would just say that

3346
01:51:14,960 --> 01:51:15,920
the uh

3347
01:51:15,920 --> 01:51:18,000
the thing is a hundred percent uh

3348
01:51:18,000 --> 01:51:18,960
accurate

3349
01:51:18,960 --> 01:51:20,719
um in telling you which one's better if

3350
01:51:20,719 --> 01:51:22,960
you observe one hit versus another

3351
01:51:22,960 --> 01:51:26,239
um and um

3352
01:51:26,239 --> 01:51:29,199
and so then the next thing right is you

3353
01:51:29,199 --> 01:51:31,520
have to consider the possible actions

3354
01:51:31,520 --> 01:51:33,199
or sequences of actions that are going

3355
01:51:33,199 --> 01:51:35,040
to correspond to policies

3356
01:51:35,040 --> 01:51:37,920
and so here the way to think about it is

3357
01:51:37,920 --> 01:51:39,199
so you're starting out

3358
01:51:39,199 --> 01:51:41,599
in state one first day factor two right

3359
01:51:41,599 --> 01:51:42,800
the like action

3360
01:51:42,800 --> 01:51:45,840
state factor and you can either

3361
01:51:45,840 --> 01:51:48,239
go from the start state immediately to

3362
01:51:48,239 --> 01:51:49,920
choosing the right

3363
01:51:49,920 --> 01:51:51,920
machine or you can go immediately from

3364
01:51:51,920 --> 01:51:54,239
the start to choosing the left machine

3365
01:51:54,239 --> 01:51:56,480
or you can choose to take the hint and

3366
01:51:56,480 --> 01:51:58,159
then go to the left one or to the right

3367
01:51:58,159 --> 01:51:59,920
one or take the hint and then go to the

3368
01:51:59,920 --> 01:52:01,679
left one

3369
01:52:01,679 --> 01:52:04,400
so those are like the the those

3370
01:52:04,400 --> 01:52:06,080
sequences of actions are the policies

3371
01:52:06,080 --> 01:52:07,119
that are gonna

3372
01:52:07,119 --> 01:52:08,719
matter right they're gonna encode what

3373
01:52:08,719 --> 01:52:10,960
the agent can do

3374
01:52:10,960 --> 01:52:14,080
um and so to do that you have to set up

3375
01:52:14,080 --> 01:52:15,840
different transition matrices different

3376
01:52:15,840 --> 01:52:17,360
b matrices

3377
01:52:17,360 --> 01:52:19,280
that encode each of these actions right

3378
01:52:19,280 --> 01:52:20,880
transitioning from one

3379
01:52:20,880 --> 01:52:22,800
to four transitioning from one to three

3380
01:52:22,800 --> 01:52:24,719
transitioning from one to two

3381
01:52:24,719 --> 01:52:26,639
transitioning from two to four and two

3382
01:52:26,639 --> 01:52:28,719
to three um

3383
01:52:28,719 --> 01:52:31,599
and so that's going to correspond to

3384
01:52:31,599 --> 01:52:34,159
these setting up these b matrices

3385
01:52:34,159 --> 01:52:37,520
which um here so b1

3386
01:52:37,520 --> 01:52:40,239
right which is the state factor for uh

3387
01:52:40,239 --> 01:52:41,199
the um

3388
01:52:41,199 --> 01:52:43,199
which one is which slot machine is

3389
01:52:43,199 --> 01:52:44,320
better um

3390
01:52:44,320 --> 01:52:45,679
this is just going to be an identity

3391
01:52:45,679 --> 01:52:48,880
matrix which basically just says

3392
01:52:48,880 --> 01:52:52,080
that the left better context is constant

3393
01:52:52,080 --> 01:52:53,520
across the trial

3394
01:52:53,520 --> 01:52:55,360
you know it's not as if from time point

3395
01:52:55,360 --> 01:52:56,960
one to time point two

3396
01:52:56,960 --> 01:52:59,040
the context is gonna change or something

3397
01:52:59,040 --> 01:53:00,880
like that right this just says the

3398
01:53:00,880 --> 01:53:01,760
belief is

3399
01:53:01,760 --> 01:53:04,480
and it is true that each trial has a

3400
01:53:04,480 --> 01:53:06,239
stable identity as being the left better

3401
01:53:06,239 --> 01:53:08,080
one or the right better one

3402
01:53:08,080 --> 01:53:12,320
um but for state factor two so

3403
01:53:12,320 --> 01:53:15,440
b2 here that's where you want the agent

3404
01:53:15,440 --> 01:53:18,000
to have different possible actions

3405
01:53:18,000 --> 01:53:21,840
right so b2 colon colon one

3406
01:53:21,840 --> 01:53:23,360
right so the third dimension being the

3407
01:53:23,360 --> 01:53:26,159
different uh different possible action

3408
01:53:26,159 --> 01:53:28,880
um the first one would be like this

3409
01:53:28,880 --> 01:53:30,719
which basically just says so columns

3410
01:53:30,719 --> 01:53:33,840
are states at time t

3411
01:53:33,840 --> 01:53:37,599
and rows are states at time t plus one

3412
01:53:37,599 --> 01:53:41,360
um so this just says i can start in any

3413
01:53:41,360 --> 01:53:42,080
state

3414
01:53:42,080 --> 01:53:45,199
so in any column and choose to move to

3415
01:53:45,199 --> 01:53:48,639
state one this one says i can start in

3416
01:53:48,639 --> 01:53:49,440
any column

3417
01:53:49,440 --> 01:53:52,960
and move to state two so taking the hint

3418
01:53:52,960 --> 01:53:54,639
this one says i can start in any column

3419
01:53:54,639 --> 01:53:56,159
so any state and move to

3420
01:53:56,159 --> 01:53:57,760
state three which is using the left

3421
01:53:57,760 --> 01:53:59,599
machine then same thing here for

3422
01:53:59,599 --> 01:54:00,239
changing the

3423
01:54:00,239 --> 01:54:01,599
to moving to the right machine so there

3424
01:54:01,599 --> 01:54:03,920
are four actions one two three and four

3425
01:54:03,920 --> 01:54:06,400
they correspond to four different third

3426
01:54:06,400 --> 01:54:07,599
dimensions

3427
01:54:07,599 --> 01:54:11,119
in the b matrix for state factor two

3428
01:54:11,119 --> 01:54:15,119
um and so then given those

3429
01:54:15,119 --> 01:54:19,040
um given those

3430
01:54:19,040 --> 01:54:22,080
we specify v which are the policies

3431
01:54:22,080 --> 01:54:25,040
um and here the third dimension

3432
01:54:25,040 --> 01:54:26,159
corresponds to

3433
01:54:26,159 --> 01:54:29,199
which state factor so for this one for

3434
01:54:29,199 --> 01:54:31,040
state factor one

3435
01:54:31,040 --> 01:54:32,560
there are no actions right it's just

3436
01:54:32,560 --> 01:54:34,239
this one v matrix and its identity

3437
01:54:34,239 --> 01:54:35,599
matrix

3438
01:54:35,599 --> 01:54:38,080
and here the rows are the action and the

3439
01:54:38,080 --> 01:54:39,599
columns are

3440
01:54:39,599 --> 01:54:41,280
sorry the rows are the time point and

3441
01:54:41,280 --> 01:54:42,880
the columns are the uh

3442
01:54:42,880 --> 01:54:45,920
the action or the policy sorry

3443
01:54:45,920 --> 01:54:49,920
um and so the row here just means action

3444
01:54:49,920 --> 01:54:52,239
moving from time one to time two

3445
01:54:52,239 --> 01:54:55,840
and the uh um and this second row

3446
01:54:55,840 --> 01:54:58,400
means the action from time to time three

3447
01:54:58,400 --> 01:54:59,360
um and so that

3448
01:54:59,360 --> 01:55:01,440
is useless right for state factor one

3449
01:55:01,440 --> 01:55:03,920
because there's just only one action

3450
01:55:03,920 --> 01:55:06,239
whereas for state factor two we have all

3451
01:55:06,239 --> 01:55:08,480
the different possible action sequences

3452
01:55:08,480 --> 01:55:10,800
right so policy one would just be if the

3453
01:55:10,800 --> 01:55:12,320
thing just decided to stay in the start

3454
01:55:12,320 --> 01:55:14,400
state the whole time right like to just

3455
01:55:14,400 --> 01:55:17,119
not do the trial um the other one would

3456
01:55:17,119 --> 01:55:18,880
be action two which is take the hint

3457
01:55:18,880 --> 01:55:20,800
and then and then take action three

3458
01:55:20,800 --> 01:55:22,159
which is move to the

3459
01:55:22,159 --> 01:55:25,360
left slot machine or take the hint

3460
01:55:25,360 --> 01:55:27,280
it to the third column take the hint and

3461
01:55:27,280 --> 01:55:29,040
then move to four which is the action of

3462
01:55:29,040 --> 01:55:31,040
choosing the right slot machine

3463
01:55:31,040 --> 01:55:33,520
um and then here this is just kind of a

3464
01:55:33,520 --> 01:55:34,880
little bit of a trick

3465
01:55:34,880 --> 01:55:38,239
but you can choose to at time from one

3466
01:55:38,239 --> 01:55:39,599
time to one to time two you can

3467
01:55:39,599 --> 01:55:41,840
immediately choose the left slot machine

3468
01:55:41,840 --> 01:55:43,840
and then move back to the start state so

3469
01:55:43,840 --> 01:55:44,960
three and then one

3470
01:55:44,960 --> 01:55:46,320
or same thing choose the right slot

3471
01:55:46,320 --> 01:55:47,840
machine and then again move back to

3472
01:55:47,840 --> 01:55:48,880
state one

3473
01:55:48,880 --> 01:55:50,159
and the only reason for that move back

3474
01:55:50,159 --> 01:55:52,880
to state one thing is is that um

3475
01:55:52,880 --> 01:55:55,040
if you let the thing stay in state three

3476
01:55:55,040 --> 01:55:56,080
and state four

3477
01:55:56,080 --> 01:55:58,080
then it's as if it won four dollars and

3478
01:55:58,080 --> 01:56:00,320
then won two dollars after that

3479
01:56:00,320 --> 01:56:02,159
so you have to kind of move it back out

3480
01:56:02,159 --> 01:56:04,880
of the state where it would win

3481
01:56:04,880 --> 01:56:08,560
um so so then

3482
01:56:08,560 --> 01:56:10,159
you know then you've built everything

3483
01:56:10,159 --> 01:56:12,000
really um

3484
01:56:12,000 --> 01:56:14,880
so you and you throw all of it in this

3485
01:56:14,880 --> 01:56:16,000
little mdp

3486
01:56:16,000 --> 01:56:18,800
structure um so i didn't mention this

3487
01:56:18,800 --> 01:56:20,159
but you have to specify

3488
01:56:20,159 --> 01:56:21,760
t which is the number of time points in

3489
01:56:21,760 --> 01:56:23,920
the trial so in this case it would be

3490
01:56:23,920 --> 01:56:27,119
uh three um so start take the hint

3491
01:56:27,119 --> 01:56:28,000
choose left

3492
01:56:28,000 --> 01:56:29,199
start take the hinge who's right et

3493
01:56:29,199 --> 01:56:31,119
cetera so there's three time points

3494
01:56:31,119 --> 01:56:34,159
um v is just v which is what we defined

3495
01:56:34,159 --> 01:56:36,000
um we'll ignore u for now but that's

3496
01:56:36,000 --> 01:56:38,080
what you would use if you wanted to

3497
01:56:38,080 --> 01:56:39,840
specify one step policies instead but

3498
01:56:39,840 --> 01:56:42,320
the thing doesn't look ahead at all um

3499
01:56:42,320 --> 01:56:45,280
you know and then a b c and d are just

3500
01:56:45,280 --> 01:56:47,199
the different matrices we specified and

3501
01:56:47,199 --> 01:56:48,239
we want it to learn

3502
01:56:48,239 --> 01:56:51,599
d um so we specify the little d um

3503
01:56:51,599 --> 01:56:52,960
and then these other things are just

3504
01:56:52,960 --> 01:56:55,040
different parameters that you can set

3505
01:56:55,040 --> 01:56:58,719
um so edda is the as a learning rate um

3506
01:56:58,719 --> 01:57:00,159
alpha is kind of like an action

3507
01:57:00,159 --> 01:57:02,000
precision so it's basically an inverse

3508
01:57:02,000 --> 01:57:03,440
temperature parameter it controls how

3509
01:57:03,440 --> 01:57:04,400
random someone's

3510
01:57:04,400 --> 01:57:06,320
choices are given the policy that they

3511
01:57:06,320 --> 01:57:08,320
choose um

3512
01:57:08,320 --> 01:57:10,239
beta is the expected free energy

3513
01:57:10,239 --> 01:57:12,639
precision that we talked about

3514
01:57:12,639 --> 01:57:14,639
and um these other two parameters i

3515
01:57:14,639 --> 01:57:16,239
won't really go into detail but they

3516
01:57:16,239 --> 01:57:18,159
just have to do with specifying

3517
01:57:18,159 --> 01:57:21,119
um the time constant so basically how

3518
01:57:21,119 --> 01:57:23,599
quickly evidence accumulates

3519
01:57:23,599 --> 01:57:26,239
after an observation and this erp thing

3520
01:57:26,239 --> 01:57:27,440
is um

3521
01:57:27,440 --> 01:57:29,679
basically it controls it controls

3522
01:57:29,679 --> 01:57:31,440
certain assumptions about

3523
01:57:31,440 --> 01:57:33,119
what ought to happen if you would make a

3524
01:57:33,119 --> 01:57:35,040
new observation each time with respect

3525
01:57:35,040 --> 01:57:36,000
to what sorts of

3526
01:57:36,000 --> 01:57:39,040
neural responses you would get um

3527
01:57:39,040 --> 01:57:40,480
and this is all explained in the code

3528
01:57:40,480 --> 01:57:42,400
but i think that's a

3529
01:57:42,400 --> 01:57:44,880
it's a perfect pause point so that we

3530
01:57:44,880 --> 01:57:47,040
can close within the hour

3531
01:57:47,040 --> 01:57:49,199
and leave people with excitement for

3532
01:57:49,199 --> 01:57:50,639
part two so

3533
01:57:50,639 --> 01:57:53,040
what can they look forward to in part

3534
01:57:53,040 --> 01:57:55,440
two and beyond in a minute

3535
01:57:55,440 --> 01:57:57,760
yeah so i mean i would just say that you

3536
01:57:57,760 --> 01:57:59,679
know once once you have this set up

3537
01:57:59,679 --> 01:58:02,320
then the next steps are to run this

3538
01:58:02,320 --> 01:58:03,520
structure through

3539
01:58:03,520 --> 01:58:06,159
this vbx underscore tutorial script and

3540
01:58:06,159 --> 01:58:07,840
that will actually run the model

3541
01:58:07,840 --> 01:58:09,280
and you know simulate the behavior the

3542
01:58:09,280 --> 01:58:11,679
neural responses and then we'll show you

3543
01:58:11,679 --> 01:58:12,639
how to

3544
01:58:12,639 --> 01:58:15,920
use um plotting scripts

3545
01:58:15,920 --> 01:58:19,199
to display and show how that behavior

3546
01:58:19,199 --> 01:58:20,960
show the behavior that uh was the

3547
01:58:20,960 --> 01:58:22,800
outcome of the simulation

3548
01:58:22,800 --> 01:58:24,239
and then we'll show you how the the kind

3549
01:58:24,239 --> 01:58:26,880
of structure the mdp structure works

3550
01:58:26,880 --> 01:58:29,360
um and then actually show you some

3551
01:58:29,360 --> 01:58:30,960
simulation results and how they work and

3552
01:58:30,960 --> 01:58:32,000
things like that

3553
01:58:32,000 --> 01:58:33,679
well and i actually probably walk you

3554
01:58:33,679 --> 01:58:35,440
through some of the actual code

3555
01:58:35,440 --> 01:58:38,480
um that was an amazing session

3556
01:58:38,480 --> 01:58:41,440
ryan christopher max thanks so much for

3557
01:58:41,440 --> 01:58:42,239
coming on

3558
01:58:42,239 --> 01:58:44,560
everybody who was watching live and in

3559
01:58:44,560 --> 01:58:45,760
replay also

3560
01:58:45,760 --> 01:58:48,719
very appreciated so please leave a

3561
01:58:48,719 --> 01:58:49,199
comment

3562
01:58:49,199 --> 01:58:51,440
if you have a question or feedback for

3563
01:58:51,440 --> 01:58:53,440
the authors or for anyone else

3564
01:58:53,440 --> 01:58:55,040
and stay in touch with us because we're

3565
01:58:55,040 --> 01:58:56,880
going to be making this a multi-part

3566
01:58:56,880 --> 01:58:58,800
series where we're going to be going

3567
01:58:58,800 --> 01:59:00,719
deeper into the technical aspects

3568
01:59:00,719 --> 01:59:03,440
and also highlighting use cases hearing

3569
01:59:03,440 --> 01:59:05,119
about people who are just learning

3570
01:59:05,119 --> 01:59:07,040
programming learning to apply it people

3571
01:59:07,040 --> 01:59:08,719
who are experts in other fields so

3572
01:59:08,719 --> 01:59:10,800
whatever your perspective is you're in

3573
01:59:10,800 --> 01:59:12,639
the right spot to be learning

3574
01:59:12,639 --> 01:59:15,679
so thanks again all of you for coming on

3575
01:59:15,679 --> 01:59:21,840
and we will see you another time

