1
00:00:24,124 --> 00:00:25,692
OK. I think we're live.

2
00:00:25,692 --> 00:00:26,793
OK. Yes.

3
00:00:26,793 --> 00:00:28,495
The screen was blocked out
for a second, but.

4
00:00:28,495 --> 00:00:29,629
Hello, everyone.

5
00:00:29,629 --> 00:00:31,831
Welcome to the Active Inference Lab.

6
00:00:32,165 --> 00:00:35,068
This is February 5th. 20, 21.

7
00:00:35,068 --> 00:00:40,840
And we are here in Model Stream 4.0
with Ryan Smith and Christopher White.

8
00:00:41,241 --> 00:00:42,409
I'm Daniel Freedman.

9
00:00:42,409 --> 00:00:44,310
I'm a post-doctoral researcher

10
00:00:44,310 --> 00:00:47,747
in California and a participant
in active inference lab.

11
00:00:48,748 --> 00:00:50,984
Maybe the two of you can just briefly
reintroduce yourself.

12
00:00:52,685 --> 00:00:54,587
Yes. For anybody who hasn't

13
00:00:54,587 --> 00:00:57,791
been watching the previous sessions,
I'm Brian Smith.

14
00:00:57,824 --> 00:01:00,827
I'm an investigator
at the Laureate Institute

15
00:01:00,827 --> 00:01:04,364
for Brain Research in Tulsa, Oklahoma.

16
00:01:04,764 --> 00:01:06,399
Hi. I'm Christopher Wyatt.

17
00:01:06,399 --> 00:01:07,901
I'm a Ph.D.

18
00:01:07,901 --> 00:01:11,404
student at the MRC Cognition Brain
Sciences Unit in Cambridge, England.

19
00:01:12,806 --> 00:01:13,339
Awesome.

20
00:01:13,339 --> 00:01:16,242
Well, we are here today in part four,

21
00:01:16,443 --> 00:01:19,345
which will be the last section
on this paper, hopefully

22
00:01:19,345 --> 00:01:22,415
not the last time
we get to speak together on any extreme,

23
00:01:22,682 --> 00:01:26,486
but it's part four of four on this paper,
a step by step

24
00:01:26,486 --> 00:01:30,590
tutorial on active inference
and its application to empirical data.

25
00:01:30,857 --> 00:01:32,459
You can find a link to the most

26
00:01:32,459 --> 00:01:35,929
updated version of that resource
in the video descriptions.

27
00:01:36,629 --> 00:01:40,467
And as far as points of process,
if you have any questions or comments

28
00:01:40,467 --> 00:01:43,703
or thoughts during the live stream,
you can type it into the live chat

29
00:01:43,903 --> 00:01:46,039
and we'll address it
when the time is right.

30
00:01:46,039 --> 00:01:49,509
If you have questions arising after this
live stream or you're watching it

31
00:01:49,509 --> 00:01:52,545
after it's occurred,
feel free to leave a comment and we'll

32
00:01:52,545 --> 00:01:56,349
try to address it in future sessions
because the model stream never ends.

33
00:01:56,916 --> 00:02:00,153
So to learn and participate
and learn about how to participate,

34
00:02:00,420 --> 00:02:02,222
go to active inference dot

35
00:02:02,222 --> 00:02:05,291
org that's where you'll find
more information on active inference.

36
00:02:06,159 --> 00:02:09,395
So today in our fourth session,
it's going to be pretty exciting

37
00:02:09,395 --> 00:02:11,264
because we've covered a lot
of the groundwork.

38
00:02:11,264 --> 00:02:13,600
And Daniel E for it, right? Yeah.

39
00:02:14,100 --> 00:02:16,136
We're not hearing anything. Daniel. Oh.

40
00:02:19,539 --> 00:02:20,373
Give me one sec.

41
00:02:20,373 --> 00:02:21,841
OK, do you hear me now?

42
00:02:23,977 --> 00:02:26,713
No. Yeah, you froze.

43
00:02:27,447 --> 00:02:28,047
All right.

44
00:02:28,047 --> 00:02:29,482
Give me a second.

45
00:02:30,517 --> 00:02:31,551
It's all good.

46
00:02:31,551 --> 00:02:35,488
This is how it happens
sometimes when live streaming.

47
00:02:36,689 --> 00:02:39,526
Let me go back to the events,

48
00:02:39,526 --> 00:02:42,829
and I will rejoin the events

49
00:02:45,598 --> 00:02:46,900
All right.

50
00:02:52,872 --> 00:02:53,673
Cool.

51
00:02:53,673 --> 00:02:55,375
Waiting. This is just how it is.

52
00:02:55,375 --> 00:02:58,611
Welcome to live streaming, everyone.

53
00:03:00,346 --> 00:03:01,114
Cool.

54
00:03:01,114 --> 00:03:03,783
Look at that ghost. Daniel Freedman.

55
00:03:03,783 --> 00:03:04,751
He can be kicked out.

56
00:03:04,751 --> 00:03:06,019
You're really quiet again.

57
00:03:06,019 --> 00:03:06,853
OK, ok. OK.

58
00:03:06,853 --> 00:03:10,390
Yes, due to do device settings

59
00:03:13,259 --> 00:03:15,695
OK. Yes.

60
00:03:15,695 --> 00:03:19,399
Thanks Microsoft's teams
for facilitating these conversations.

61
00:03:20,133 --> 00:03:22,468
It's still live and happening
it's just a little,

62
00:03:23,203 --> 00:03:26,105
little hiccup with teams that now
we've gotten that out of the way.

63
00:03:26,272 --> 00:03:27,607
So it's fixed.

64
00:03:27,607 --> 00:03:28,875
But they right in.

65
00:03:28,875 --> 00:03:32,745
I don't know if this other person
can be kicked out, but take it away.

66
00:03:32,812 --> 00:03:33,913
We're all good, though. Thank you.

67
00:03:35,582 --> 00:03:39,219
OK, maybe

68
00:03:40,053 --> 00:03:41,688
that one or.

69
00:03:41,688 --> 00:03:43,556
The ghost of Daniel's past.

70
00:03:43,556 --> 00:03:45,058
It's OK.

71
00:03:45,058 --> 00:03:50,463
It will auto drop them like after you
shared on share but it's all chill, ok?

72
00:03:50,463 --> 00:03:53,233
OK. Perfect. OK.

73
00:03:54,234 --> 00:03:55,902
I thought that worked.

74
00:03:55,902 --> 00:03:57,370
OK, so we are still.

75
00:03:57,370 --> 00:03:58,605
We are still alive and going.

76
00:03:58,605 --> 00:04:01,908
Yep. OK,

77
00:04:02,408 --> 00:04:03,042
All right.

78
00:04:03,042 --> 00:04:06,346
So question
just start or there anything else?

79
00:04:06,346 --> 00:04:08,114
You are kind of
in the middle saying something.

80
00:04:08,114 --> 00:04:13,086
Just if we could start with some recap
for those who probably have seen

81
00:04:13,086 --> 00:04:17,690
the first three sessions, just
where did we get to as of today?

82
00:04:17,690 --> 00:04:21,661
And then where does
that take us into the future?

83
00:04:21,661 --> 00:04:24,797
OK. So yeah, just as a quick recap,

84
00:04:25,932 --> 00:04:30,637
Daniel said the whole purpose
of this tutorial

85
00:04:31,170 --> 00:04:35,441
that we put out
was to try to make methods for actually

86
00:04:35,441 --> 00:04:39,512
building active inference models
and applying them to experimental data.

87
00:04:40,513 --> 00:04:40,913
We want

88
00:04:40,913 --> 00:04:44,751
to try to make those methods
more accessible to a broader audience

89
00:04:45,852 --> 00:04:48,254
because up until now, it's been fairly

90
00:04:48,254 --> 00:04:50,623
difficult to find sort of clear

91
00:04:51,324 --> 00:04:54,961
resources for beginners
to start learning these sorts of methods.

92
00:04:56,129 --> 00:04:59,098
And so the whole kind of the whole

93
00:05:00,099 --> 00:05:02,502
point of what we've covered
so far is kind of been building

94
00:05:02,502 --> 00:05:04,671
to this section

95
00:05:05,772 --> 00:05:07,440
if the focus again is going to be about

96
00:05:07,440 --> 00:05:10,443
being able to actually use these models
for experiments.

97
00:05:11,577 --> 00:05:13,546
So obviously the earlier sections

98
00:05:13,546 --> 00:05:16,449
could be useful on their own
if you want to do simulation work

99
00:05:17,050 --> 00:05:20,153
and there's lots of papers
reporting simulation work.

100
00:05:20,153 --> 00:05:24,157
But in terms of then applying the models

101
00:05:24,157 --> 00:05:26,426
and simulation work that you do to

102
00:05:27,960 --> 00:05:30,063
to actual experiments
to actually fit it to

103
00:05:30,797 --> 00:05:34,534
task behavior with participants
and, you know, predict things

104
00:05:34,534 --> 00:05:37,837
about like neural responses and MRI
studies and all that kind of stuff,

105
00:05:38,971 --> 00:05:41,641
then it all kind of boils down to what
we'll talk about today.

106
00:05:42,642 --> 00:05:45,611
So in earlier sections, we kind of
covered the basics of active inference.

107
00:05:45,611 --> 00:05:46,646
You know what for energy,

108
00:05:46,646 --> 00:05:49,382
what variational for energy
is what expected for energy is

109
00:05:49,716 --> 00:05:53,753
what the motivation is for doing active
inference, what the potential benefits

110
00:05:53,753 --> 00:05:57,824
are over traditional reinforcement
learning models,

111
00:05:58,991 --> 00:06:02,195
you know, things, things like things like
that is kind of the nuts and bolts.

112
00:06:02,195 --> 00:06:06,366
And then we covered how to build active
inference,

113
00:06:06,366 --> 00:06:08,935
partially observable
markup decision process models.

114
00:06:10,136 --> 00:06:13,573
And as an example, we built a

115
00:06:14,640 --> 00:06:18,111
simple kind of explore
exploit model, which I will or exploit.

116
00:06:18,111 --> 00:06:20,680
What test model should I say,

117
00:06:20,680 --> 00:06:24,317
as a as a just kind of a concrete example
of how you would build a model.

118
00:06:25,318 --> 00:06:26,386
And we showed some

119
00:06:26,386 --> 00:06:30,590
simulations both for perception
and decision making and for learning

120
00:06:31,691 --> 00:06:33,426
with that model.

121
00:06:33,526 --> 00:06:36,028
And so and then we also kind of

122
00:06:38,331 --> 00:06:40,133
took a took a break from that.

123
00:06:40,133 --> 00:06:41,267
We're going to return to that now.

124
00:06:41,267 --> 00:06:44,303
But we also took a break from that
a little bit to cover

125
00:06:44,904 --> 00:06:47,673
hierarchical models
and the neural process theory

126
00:06:49,375 --> 00:06:50,843
but now we're going to come back

127
00:06:50,843 --> 00:06:53,413
to using the Explore Exploit task model
because it's

128
00:06:54,747 --> 00:06:57,283
simpler and more straightforward in terms

129
00:06:57,283 --> 00:07:01,487
of what you do with participant behavior
and and how you fit it.

130
00:07:02,488 --> 00:07:06,893
So so all that, like I said, is
building up to using the task model

131
00:07:06,893 --> 00:07:09,929
we built as an example
for setting it to data.

132
00:07:11,864 --> 00:07:12,532
So, Christopher.

133
00:07:12,532 --> 00:07:13,833
I don't know that. Yeah.

134
00:07:13,833 --> 00:07:14,567
Great summary.

135
00:07:14,567 --> 00:07:16,936
Christopher,
what would be your perspective

136
00:07:16,936 --> 00:07:18,604
or what was something
that stood out to you.

137
00:07:20,373 --> 00:07:22,508
From the previous sessions? Yep.

138
00:07:22,809 --> 00:07:26,612
Because you're you're so both deep
in the game and actually producing

139
00:07:26,612 --> 00:07:30,783
this artifact that it's been fun for us
and for the audience just to be

140
00:07:31,350 --> 00:07:36,122
kind of talking through it because it
so what, what does it leave upon somebody

141
00:07:36,122 --> 00:07:40,059
who's been involved in the generation
of this artifact now to be talking.

142
00:07:40,059 --> 00:07:40,293
About

143
00:07:42,462 --> 00:07:46,065
interesting question, I suppose, and

144
00:07:46,065 --> 00:07:47,300
I thought I think it has made

145
00:07:47,300 --> 00:07:52,371
and I'm just so this is kind of
in the context I have I started my PhD

146
00:07:52,505 --> 00:07:55,741
four months ago, so this is all kind of
in the context of figuring out

147
00:07:56,709 --> 00:08:00,046
not just how to build these models
kind of for myself

148
00:08:01,881 --> 00:08:05,084
or sorry how to teach other people
how to build these models rather but

149
00:08:05,084 --> 00:08:08,087
actually how to build these models myself
and apply my own research questions

150
00:08:11,557 --> 00:08:15,027
and so I actually have never fitted them
to all of the stuff that I've done

151
00:08:15,027 --> 00:08:19,365
so far as been theory, essentially
just I've done a lot of simulation work,

152
00:08:19,365 --> 00:08:20,566
but no

153
00:08:21,100 --> 00:08:24,237
I don't think so.

154
00:08:24,871 --> 00:08:25,304
I don't know.

155
00:08:25,304 --> 00:08:28,374
I think that's actually the frontier
in active inference at the moment

156
00:08:28,374 --> 00:08:30,977
is actually figuring out
how to get these models to hit the road.

157
00:08:31,611 --> 00:08:34,547
And there's a really one, one really
tricky thing is most of the people

158
00:08:34,547 --> 00:08:37,650
who work on active inference
in a real way and your images.

159
00:08:38,818 --> 00:08:41,320
So for I for example,
I mean in your engine department,

160
00:08:42,421 --> 00:08:44,590
I know, Ryan, you're working your imaging

161
00:08:44,590 --> 00:08:45,391
as well.

162
00:08:47,827 --> 00:08:48,427
It's actually

163
00:08:48,427 --> 00:08:51,564
challenging to test these models
in the domain of neuro imaging.

164
00:08:51,998 --> 00:08:54,233
Your imaging is really hard, actually.

165
00:08:54,233 --> 00:08:57,303
I think many of the clearest predictions
actually in terms of the

166
00:08:57,303 --> 00:09:00,873
your process theory are actually things
that you could test really quite easily

167
00:09:00,873 --> 00:09:03,876
with optogenetics, not optogenetics
or anything like that's easy.

168
00:09:04,277 --> 00:09:07,680
But say predictions about micro
circuitry in PFC,

169
00:09:08,080 --> 00:09:10,116
which active inference certainly makes

170
00:09:11,384 --> 00:09:12,251
can very much

171
00:09:12,251 --> 00:09:15,922
be tested easily in a rodent model.

172
00:09:16,022 --> 00:09:18,891
But it's really difficult
to test it in a human.

173
00:09:20,459 --> 00:09:22,295
And so I think

174
00:09:24,230 --> 00:09:24,997
the point

175
00:09:24,997 --> 00:09:27,833
that I'm trying to in a rather
rambling way get to is

176
00:09:28,067 --> 00:09:31,437
I think we need to think
very deeply about when we build models

177
00:09:31,637 --> 00:09:34,040
about what it actually is
that we're trying to solve.

178
00:09:34,407 --> 00:09:36,576
Do we just want a directional hypothesis,

179
00:09:37,710 --> 00:09:40,947
in which case you don't necessarily
need to fit these things to data?

180
00:09:41,247 --> 00:09:43,215
You're just saying as the
it will be bigger than day,

181
00:09:43,215 --> 00:09:44,884
which is still better
than most psychology.

182
00:09:44,884 --> 00:09:46,986
Let's let's be honest

183
00:09:48,454 --> 00:09:48,988
yeah.

184
00:09:48,988 --> 00:09:50,389
It's really interesting.

185
00:09:50,389 --> 00:09:55,461
The neuroimaging case has a few specific
difficulties, massive amounts of data

186
00:09:55,861 --> 00:09:56,596
in a system

187
00:09:56,596 --> 00:10:01,200
that has massively complex internal
and external dynamics like the brain.

188
00:10:01,667 --> 00:10:05,738
And you're making a ton of data
with a very complex error profile.

189
00:10:05,738 --> 00:10:11,043
And in the SPM textbook it's
chapters and chapters of normalization

190
00:10:11,043 --> 00:10:13,779
and re warping
and all these different kinds of ways

191
00:10:13,779 --> 00:10:16,015
to deal with these very complex
data sets.

192
00:10:16,015 --> 00:10:18,351
And now we've almost built out
that framework.

193
00:10:18,351 --> 00:10:19,986
And now,
just like you said, where it's hitting

194
00:10:19,986 --> 00:10:22,488
the road is in being applied
to empirical data.

195
00:10:22,488 --> 00:10:23,823
And it's a little bit of a surprise.

196
00:10:23,823 --> 00:10:27,526
It, at least to me and probably others,
that maybe neural imaging although that's

197
00:10:27,526 --> 00:10:31,731
the home of SPM we're seeing,
it applies to systems beyond neuro

198
00:10:31,831 --> 00:10:36,035
imaging and even there's other systems
that help inform our neuroimaging quest.

199
00:10:36,035 --> 00:10:37,269
So pretty interesting stuff

200
00:10:41,273 --> 00:10:43,509
OK. So should we just get started then?

201
00:10:43,576 --> 00:10:45,344
It sounds good
and anyone in the live chat

202
00:10:45,344 --> 00:10:47,346
just drop a question
and we'll get to them.

203
00:10:47,346 --> 00:10:48,180
Thanks a lot.

204
00:10:48,914 --> 00:10:51,083
OK, so one

205
00:10:51,083 --> 00:10:55,755
brief thing that I did want to mention
is that a couple of times ago

206
00:10:56,222 --> 00:10:59,325
we we talked about we covered learning,

207
00:11:00,493 --> 00:11:03,963
but since then just wanted
to let people know

208
00:11:03,963 --> 00:11:08,868
we actually caught a little a small error
in the learning section

209
00:11:09,235 --> 00:11:11,237
in the previous version
that we've now corrected.

210
00:11:11,904 --> 00:11:15,541
And it has to do with the way
that you calculate the

211
00:11:16,242 --> 00:11:19,879
the novelty term and expected free energy
that gets added to

212
00:11:21,480 --> 00:11:24,150
you gets added to expected free energy
when you're doing learning.

213
00:11:24,150 --> 00:11:29,121
So that's what drives the parameter
exploration term expected for energy.

214
00:11:29,121 --> 00:11:34,894
It basically drives an agent to seek out
policies that will tell it more about,

215
00:11:35,861 --> 00:11:37,930
in this case, what the matrix looks like.

216
00:11:37,930 --> 00:11:41,367
So tell us more about
what the relationship is between states

217
00:11:41,367 --> 00:11:42,968
and observations.

218
00:11:42,968 --> 00:11:44,670
And there's equivalent terms
that could be added

219
00:11:44,670 --> 00:11:45,271
if you're trying to learn

220
00:11:45,271 --> 00:11:49,141
transition beliefs or other matrices
and vectors in the model.

221
00:11:49,475 --> 00:11:52,645
But so now just to kind of make
that clear,

222
00:11:54,013 --> 00:11:56,115
we actually have added

223
00:11:56,115 --> 00:12:01,053
two different additional work examples of
how of how to calculate

224
00:12:01,420 --> 00:12:04,390
the the novelty term,
just to make sure that's clear.

225
00:12:04,757 --> 00:12:09,295
So if anybody doesn't happen
to have the kind of most updated version

226
00:12:09,295 --> 00:12:12,298
and you're interested
in kind of knowing the kind

227
00:12:12,298 --> 00:12:15,000
of rigorous details
about how learning works

228
00:12:16,068 --> 00:12:20,172
in the in the formalism, then, you know,
it might be helpful

229
00:12:20,840 --> 00:12:23,676
to download the updated version
so that you can have

230
00:12:23,676 --> 00:12:26,345
additional work examples to
to get a better sense about that works.

231
00:12:27,213 --> 00:12:30,583
So I just wanted to make that clear.

232
00:12:30,583 --> 00:12:31,617
Like I said, it wasn't

233
00:12:31,617 --> 00:12:33,753
it's not like a big error,
but it's a small error

234
00:12:33,753 --> 00:12:36,355
that if you were to read
it it could be confusing.

235
00:12:37,823 --> 00:12:39,391
So I just wanted to make

236
00:12:39,391 --> 00:12:42,962
what I wanted
to highlight that for people.

237
00:12:42,962 --> 00:12:45,264
But today, like I mentioned,

238
00:12:45,264 --> 00:12:48,400
the focus is going to be on
actually building task models.

239
00:12:49,602 --> 00:12:51,637
So and applying them to data.

240
00:12:51,637 --> 00:12:54,673
And there's actually,
you know, it's probably, you know, this

241
00:12:54,673 --> 00:12:57,843
doesn't this isn't necessarily
like the only way you could break it up.

242
00:12:57,843 --> 00:12:59,211
But I've broken this up

243
00:12:59,211 --> 00:13:03,382
into kind of six steps that are probably
a good kind of heuristic,

244
00:13:04,150 --> 00:13:07,419
you know, roadmap or whatever
you want to call it

245
00:13:08,320 --> 00:13:10,356
for doing this kind of work.

246
00:13:11,257 --> 00:13:14,026
So the first thing is
that you have to have a task

247
00:13:14,026 --> 00:13:16,228
and you have to have participants perform
that task.

248
00:13:16,829 --> 00:13:21,333
And the second thing is
you have to build one

249
00:13:21,333 --> 00:13:25,404
or more models of that task
so one or more models

250
00:13:26,205 --> 00:13:27,540
in this case partially observable

251
00:13:27,540 --> 00:13:31,477
markup decision process models
in the act of inference formulation

252
00:13:32,545 --> 00:13:34,847
that can refer duse or generate

253
00:13:35,447 --> 00:13:39,151
simulated behavior for that task.

254
00:13:39,151 --> 00:13:41,086
And so once you do that,

255
00:13:41,086 --> 00:13:44,723
then the next thing you need to do is
you need to find somehow find

256
00:13:44,723 --> 00:13:48,794
parameter values in each of those models
that you construct constructs

257
00:13:49,261 --> 00:13:51,330
that can best reproduce

258
00:13:51,797 --> 00:13:54,733
each participant's behavior

259
00:13:54,733 --> 00:13:57,403
so for instance, under one model,
you might find

260
00:13:57,403 --> 00:14:00,873
that the first participant,
the model can reproduce

261
00:14:00,873 --> 00:14:05,477
the first participant's behavior,
the best if it has a particular,

262
00:14:06,512 --> 00:14:09,982
say, value
for how much they want the reward.

263
00:14:09,982 --> 00:14:12,852
So for instance, like the value of the

264
00:14:12,852 --> 00:14:16,322
or that you think about it as a precision
of the preference distribution.

265
00:14:17,489 --> 00:14:20,526
Or you might find that
for another participant

266
00:14:20,559 --> 00:14:23,295
you need a lower value for that
to reproduce their behavior.

267
00:14:23,295 --> 00:14:23,829
Well,

268
00:14:25,164 --> 00:14:26,332
and but they need

269
00:14:26,332 --> 00:14:28,434
something like a higher learning rate

270
00:14:29,401 --> 00:14:33,305
or a lower action precision value, right?

271
00:14:33,305 --> 00:14:36,642
There's all these different parameters
in these models we've been covering

272
00:14:37,042 --> 00:14:39,812
and different values
for those parameters are going to

273
00:14:41,113 --> 00:14:44,483
be better
different parameter value combinations.

274
00:14:44,483 --> 00:14:47,620
And these model is going to be better
at reproducing one person's behavior

275
00:14:47,620 --> 00:14:50,823
versus another on the task.

276
00:14:50,823 --> 00:14:54,560
And so what that requires is having
some kind of estimation algorithm,

277
00:14:55,327 --> 00:14:58,264
something that basically searches
through in some way

278
00:14:58,397 --> 00:15:03,302
different combinations of parameters
and checks how well it reproduces

279
00:15:03,969 --> 00:15:07,473
a given participants behavior.

280
00:15:07,473 --> 00:15:09,808
And so and so, like I said,
those called parameter estimation

281
00:15:09,808 --> 00:15:13,078
algorithms and there's a few
there's several different

282
00:15:14,313 --> 00:15:16,382
types that you can use.

283
00:15:16,382 --> 00:15:19,485
I'll briefly mention a few
and then we'll go into detail on

284
00:15:19,485 --> 00:15:22,021
the one
that is probably most consistent with

285
00:15:23,155 --> 00:15:23,822
the general kind

286
00:15:23,822 --> 00:15:26,558
of theme of active inference models,
which is

287
00:15:27,626 --> 00:15:30,362
a scheme called Variational Bayes.

288
00:15:30,596 --> 00:15:33,532
So once you've found for each model

289
00:15:34,900 --> 00:15:39,438
the parameter values that best describe
each participant, then you want to know,

290
00:15:39,438 --> 00:15:42,007
OK, well which of those models
is the best model?

291
00:15:43,008 --> 00:15:46,078
And so in that case,
you need some kind of way of comparing

292
00:15:46,578 --> 00:15:49,915
how well each model on average

293
00:15:49,915 --> 00:15:53,953
can reproduce the behavior
of the whole group of your participants.

294
00:15:55,220 --> 00:15:59,158
So each model is going to have their best
fit parameters for each participant,

295
00:15:59,558 --> 00:16:04,196
but still the best fit parameters
for one model might still do a better job

296
00:16:04,330 --> 00:16:06,966
than the best fit parameters
for another model.

297
00:16:08,534 --> 00:16:10,869
And again, we'll go into this

298
00:16:11,470 --> 00:16:15,541
and then once you've identified
what the the best model is

299
00:16:16,742 --> 00:16:19,712
then and this
is something that might not be obvious,

300
00:16:19,712 --> 00:16:22,681
but it's really important is
you have to somehow confirm

301
00:16:23,082 --> 00:16:25,150
that the parameters in the best model

302
00:16:26,318 --> 00:16:28,320
are recoverable.

303
00:16:28,320 --> 00:16:31,890
So you can hear the talk about this
as whether the model is identifiable

304
00:16:31,890 --> 00:16:34,593
or the parameters of the model
are recoverable.

305
00:16:35,761 --> 00:16:38,063
And that's something that again,
I'll expand on.

306
00:16:38,430 --> 00:16:41,266
But but the basic idea is or 11

307
00:16:41,266 --> 00:16:43,469
kind of simple way to think about it is

308
00:16:44,536 --> 00:16:47,473
what if it's the case that two different

309
00:16:47,673 --> 00:16:51,510
combinations of parameter values
are equally good

310
00:16:52,344 --> 00:16:54,580
at reproducing or explaining

311
00:16:54,580 --> 00:16:57,149
a given participant's behavior?

312
00:16:57,149 --> 00:16:59,585
If that were the case,
then there isn't any unique

313
00:17:00,786 --> 00:17:02,821
combination of parameter values.

314
00:17:02,821 --> 00:17:06,225
That is kind of the best set
of parameter values.

315
00:17:07,192 --> 00:17:09,328
And what that means is that

316
00:17:10,462 --> 00:17:11,230
you could take

317
00:17:11,230 --> 00:17:15,300
one set of parameter
values, generate behavior with it.

318
00:17:15,300 --> 00:17:17,936
But when you ran estimation on that,
you could get

319
00:17:18,303 --> 00:17:20,606
a very different set
of parameter estimates.

320
00:17:21,473 --> 00:17:24,309
And if that's the case,
then the parameter estimates

321
00:17:24,309 --> 00:17:27,079
that you're actually getting
for that model for a participant

322
00:17:28,080 --> 00:17:30,482
aren't necessarily a reliable or uniquely

323
00:17:30,482 --> 00:17:34,119
best description

324
00:17:34,119 --> 00:17:37,556
and so that means that parameters
aren't recoverable or there's no kind of

325
00:17:37,890 --> 00:17:40,993
uniquely best set of parameters

326
00:17:40,993 --> 00:17:42,795
under that model.

327
00:17:44,129 --> 00:17:48,300
So you need to do that to make sure
that's true for the winning model.

328
00:17:48,667 --> 00:17:51,603
And if it's not, then you might move down
to, say, the second best model

329
00:17:51,603 --> 00:17:53,172
and see if that's the case.

330
00:17:53,172 --> 00:17:53,372
All right.

331
00:17:53,372 --> 00:17:56,008
So you want to find the best
fitting model.

332
00:17:56,008 --> 00:17:58,710
Ideally,
you want to find the best fitting model

333
00:17:58,911 --> 00:18:03,549
that is also clearly recoverable,
that has clearly recoverable parameters

334
00:18:05,584 --> 00:18:08,587
and finally, once you have identified

335
00:18:08,987 --> 00:18:11,290
the winning recoverable model

336
00:18:13,025 --> 00:18:17,463
and you have this set of parameter
estimates that describe each person.

337
00:18:17,463 --> 00:18:19,698
So these are individual
different variables, right?

338
00:18:19,698 --> 00:18:23,469
One person has higher action precision
and then another one person

339
00:18:23,469 --> 00:18:26,371
has a more precise
preference distribution than another.

340
00:18:27,439 --> 00:18:29,842
And at this point,
you can take these up to the group level

341
00:18:30,275 --> 00:18:33,479
and you can say, OK,
you know, for instance,

342
00:18:33,812 --> 00:18:38,684
does a health group have different
parameter values on average

343
00:18:38,684 --> 00:18:42,254
than, say, a group with depression
or a group with anxiety?

344
00:18:42,921 --> 00:18:46,825
Or you can say, you know, do
parameter values

345
00:18:46,825 --> 00:18:50,229
predict something on a continuous,
you know, in a continuous way?

346
00:18:50,596 --> 00:18:50,929
Right.

347
00:18:50,929 --> 00:18:55,934
Maybe higher anxiety levels are
associated with lower action precision

348
00:18:57,169 --> 00:18:59,304
or something like that.

349
00:18:59,304 --> 00:19:02,141
And so I'll show you guys examples
of this kind of thing as well.

350
00:19:04,476 --> 00:19:05,377
So first, and

351
00:19:05,377 --> 00:19:07,813
you know, we've kind of already
covered this in previous sessions

352
00:19:08,413 --> 00:19:11,283
or just examples of it,
but there are lots of different

353
00:19:11,283 --> 00:19:13,719
kinds of tasks that you can model,

354
00:19:14,319 --> 00:19:17,489
which is kind of a nice perk of active
inference models,

355
00:19:17,956 --> 00:19:22,961
is that they're not just about decision
making as a main component.

356
00:19:22,961 --> 00:19:26,064
You can also use them to model
kind of simple perceptual tasks.

357
00:19:27,032 --> 00:19:30,569
So Christopher, in a previous session,

358
00:19:32,571 --> 00:19:35,140
showed how you could build a model

359
00:19:35,140 --> 00:19:39,178
of a simple perceptual oddball
or a local global task,

360
00:19:39,545 --> 00:19:42,881
which is almost entirely
about perception.

361
00:19:44,049 --> 00:19:47,419
You won't get necessarily interesting
individual differences

362
00:19:47,419 --> 00:19:51,823
in behavior in these tasks,
but you can show differences in, say,

363
00:19:51,990 --> 00:19:55,227
simulated event related
potentials in EEG studies.

364
00:19:55,727 --> 00:19:58,463
And in principle,
you could fit the ear piece

365
00:19:59,298 --> 00:20:01,333
to find the best parameters for a person.

366
00:20:03,101 --> 00:20:05,370
But you can also do

367
00:20:05,370 --> 00:20:08,640
inferential or inferential
or prospective decision making tasks

368
00:20:08,640 --> 00:20:11,810
like where you plan for the future
and make a decision

369
00:20:11,810 --> 00:20:14,880
based on what you expect
future outcomes to be,

370
00:20:14,880 --> 00:20:16,982
which is the kind of thing

371
00:20:17,916 --> 00:20:19,251
kind of like

372
00:20:19,418 --> 00:20:22,921
what I'll be showing you
or with the Explore Exploit task.

373
00:20:23,956 --> 00:20:27,159
But the Explore Exploit task
that we'll be showing is is kind of

374
00:20:27,559 --> 00:20:30,529
very similar to a standard
kind of reinforcement learning task.

375
00:20:30,529 --> 00:20:35,033
It just requires that you seek out
information before you can really know

376
00:20:35,033 --> 00:20:39,638
or even learn
what the right reward values are.

377
00:20:40,572 --> 00:20:43,508
And then lastly,
you could combine this with neuroimaging

378
00:20:44,142 --> 00:20:47,379
in the context of predictions
from the neural processing area,

379
00:20:47,379 --> 00:20:48,747
which is what we've talked about

380
00:20:48,747 --> 00:20:52,451
and what we covered in relation
to the hierarchical model that

381
00:20:52,451 --> 00:20:53,285
Christopher covered

382
00:20:55,020 --> 00:20:56,822
so I should say

383
00:20:56,822 --> 00:20:59,825
that this
is kind of a fairly new emerging field.

384
00:21:00,626 --> 00:21:03,362
And so there's not that many papers,

385
00:21:03,629 --> 00:21:05,797
empirical papers
that do this kind of thing.

386
00:21:07,466 --> 00:21:09,635
You know, it's
something that my lab has kind of been

387
00:21:09,635 --> 00:21:13,972
trying to make more common practice

388
00:21:14,673 --> 00:21:17,509
which is again, part of the motivation
for this tutorial is so that

389
00:21:18,210 --> 00:21:21,880
a larger number of researchers
can do this kind of thing.

390
00:21:23,615 --> 00:21:27,085
But so you know,
I mainly work in computational psychiatry

391
00:21:28,120 --> 00:21:31,023
and so, you know,
if this has been used to show, say,

392
00:21:31,023 --> 00:21:36,261
for instance, less, less precise lower
action, precision and substance

393
00:21:36,261 --> 00:21:40,232
use disorder
and also slower learning rates

394
00:21:40,232 --> 00:21:42,734
for negative outcomes
and substance use disorder,

395
00:21:44,069 --> 00:21:46,271
you know, we've shown things like that.

396
00:21:47,072 --> 00:21:50,442
Greater decision
uncertainty is associated with

397
00:21:51,209 --> 00:21:53,612
people with depression,
anxiety and substance use

398
00:21:53,612 --> 00:21:56,348
in the context of approach,
avoidance, conflict tasks.

399
00:21:56,982 --> 00:22:01,520
And most recently,
we also use kind of a simpler

400
00:22:01,820 --> 00:22:05,157
Bayesian perception
version of an active inference

401
00:22:05,791 --> 00:22:11,363
to show differences in the sensory
precision and in an intercept of context.

402
00:22:11,663 --> 00:22:12,864
So for instance, when people

403
00:22:14,433 --> 00:22:15,300
how, how

404
00:22:15,300 --> 00:22:18,270
precisely or accurately people
perceive their own heartbeats,

405
00:22:19,471 --> 00:22:22,140
an interesting differences there

406
00:22:22,140 --> 00:22:24,242
between, again, clinical and multiple

407
00:22:24,242 --> 00:22:27,279
clinical groups and healthy participants.

408
00:22:27,279 --> 00:22:31,616
And then lastly, and you know,
one of the first papers using this

409
00:22:31,616 --> 00:22:35,854
kind of approach was actually Phillips
quarterbacks paper where they looked at

410
00:22:37,356 --> 00:22:39,658
predictions about midbrain,

411
00:22:39,658 --> 00:22:41,893
midbrain, dopaminergic responses

412
00:22:43,562 --> 00:22:47,265
and changes
in the expected free energy perception

413
00:22:47,733 --> 00:22:50,736
term that we had talked
about in previous sessions.

414
00:22:51,436 --> 00:22:56,341
And I was able to show nice relationships
between these expected

415
00:22:56,341 --> 00:23:03,148
precision updates and and what
and neural responses using if MRI

416
00:23:03,148 --> 00:23:06,885
in a region of the midbrain
that is known to be rich

417
00:23:06,885 --> 00:23:09,421
in dopamine neurons.

418
00:23:10,088 --> 00:23:14,192
So this is just kind of
these are recent examples. But,

419
00:23:14,192 --> 00:23:17,596
you know, we're hoping other researchers
can and can, you know, build on.

420
00:23:20,132 --> 00:23:21,366
On that neuro slide.

421
00:23:21,366 --> 00:23:22,200
These examples.

422
00:23:22,200 --> 00:23:26,238
We're seeing a couple of examples
of different technologies like MRI.

423
00:23:26,271 --> 00:23:29,341
But we also heard it goes beyond
neuroimaging, the scope of these methods.

424
00:23:29,641 --> 00:23:34,112
And we're also seeing a couple
of biological questions or conditions

425
00:23:35,046 --> 00:23:37,182
related to your clinical experience.

426
00:23:37,616 --> 00:23:41,420
Let me compliment those two
axes of variation with the methods

427
00:23:41,420 --> 00:23:45,056
in the biological question
with this algorithmic dimension.

428
00:23:45,457 --> 00:23:48,593
And there's a question in the chat
that says what kinds of tasks

429
00:23:48,994 --> 00:23:51,630
reflect the relationship
between dynamic programing

430
00:23:51,630 --> 00:23:55,534
and active inference, for example, Belman
Optimal State Action Policies.

431
00:23:55,534 --> 00:23:56,935
Thanks for the elaboration.

432
00:23:56,935 --> 00:23:58,770
So how do we connect
some of these biological

433
00:23:58,770 --> 00:24:02,307
and methodological uses
and axes of variation

434
00:24:02,574 --> 00:24:05,944
to some of the algorithmic questions
about optimization, dynamic programing?

435
00:24:06,812 --> 00:24:09,047
So yes, I mean, that's a great question.

436
00:24:09,080 --> 00:24:14,152
We actually have a recent preprint
that lands to Costas first author on

437
00:24:15,554 --> 00:24:16,021
where he

438
00:24:16,021 --> 00:24:19,291
was able to come up with some proofs
to show

439
00:24:19,858 --> 00:24:23,195
when active inference is
and is not Belmont optimal.

440
00:24:24,362 --> 00:24:28,033
And in terms of one,
the the conclusion was in terms

441
00:24:28,033 --> 00:24:31,670
of one step policies act of inference

442
00:24:32,003 --> 00:24:34,406
is Belmont optimal in the context where

443
00:24:35,674 --> 00:24:39,744
the precision of the preference
distribution is maximal,

444
00:24:40,178 --> 00:24:42,914
it's maximally precise over
whatever the reward outcome is

445
00:24:44,115 --> 00:24:46,318
active inference models
in the kind of simple

446
00:24:46,318 --> 00:24:48,753
idea appeal MVP scheme
we've been talking about here

447
00:24:49,521 --> 00:24:52,290
they're not Belmont optimal
or they're not guaranteed to be

448
00:24:53,458 --> 00:24:55,427
in the context of multistep

449
00:24:55,427 --> 00:24:57,429
so like deep temporal qualities

450
00:24:58,563 --> 00:25:03,735
but whereas the more recent
sophisticated act of inference

451
00:25:03,735 --> 00:25:08,840
algorithms are Belmont
optimal for deep policies

452
00:25:09,374 --> 00:25:11,476
because they more or less correspond
to backward induction.

453
00:25:12,611 --> 00:25:14,779
So that's

454
00:25:14,779 --> 00:25:18,416
that's the probably shortest
answer I could give to that.

455
00:25:19,885 --> 00:25:20,585
Christopher, did you

456
00:25:20,585 --> 00:25:22,020
have something to add there?

457
00:25:23,755 --> 00:25:24,489
Uh, no,

458
00:25:24,489 --> 00:25:28,059
I yeah, I was just going to point to
the landslide, the cost of paper grade.

459
00:25:28,059 --> 00:25:31,396
I posted the cost of papers
that I think are relevant in the chat.

460
00:25:31,396 --> 00:25:33,665
So thanks for that question.
And continue.

461
00:25:34,866 --> 00:25:38,403
OK, so just to be clear,
this is a very specific paper

462
00:25:38,670 --> 00:25:41,640
that, you know, Lance
and I and, and a few other people

463
00:25:41,640 --> 00:25:44,476
put out as a preprint
just a couple of months ago.

464
00:25:45,510 --> 00:25:48,013
So so I'm talking about one particular
paper

465
00:25:48,346 --> 00:25:50,682
of, of Lance's.

466
00:25:51,149 --> 00:25:53,151
So I mean,
I can certainly that point that

467
00:25:53,151 --> 00:25:56,321
that specific one out and so people know
which one I'm talking about.

468
00:25:56,454 --> 00:25:57,822
The relationship between dynamic

469
00:25:57,822 --> 00:26:01,560
programing and active inference
to the discrete finite horizon case with.

470
00:26:01,560 --> 00:26:01,860
Yeah.

471
00:26:01,860 --> 00:26:02,427
That's the one.

472
00:26:02,427 --> 00:26:04,963
To caster power friction and Smith.

473
00:26:05,931 --> 00:26:09,267
Yep. OK, cool.

474
00:26:09,267 --> 00:26:09,768
All right.

475
00:26:09,768 --> 00:26:11,636
So hopefully that helps

476
00:26:13,772 --> 00:26:17,008
OK, so now I'll kind of be going through

477
00:26:17,475 --> 00:26:20,412
each of the,
the steps here that I was talking about

478
00:26:21,079 --> 00:26:24,583
kind of one by one, right,
with our explore exploit test example.

479
00:26:25,050 --> 00:26:29,588
So first step one is you have to have
participants perform a task, right?

480
00:26:29,588 --> 00:26:32,891
So in this case and I should say for
some of this, it's really going

481
00:26:32,891 --> 00:26:38,129
to be assumed that people were following
along with previous sessions at the time

482
00:26:38,129 --> 00:26:41,533
constraints just really don't allow us
to cover all the background and

483
00:26:42,601 --> 00:26:45,003
so that somebody could watch this one
without having seen

484
00:26:45,003 --> 00:26:47,439
the other ones and fully follow
everything I'll be talking about.

485
00:26:48,440 --> 00:26:51,343
So just just to make that clear,
if anything is kind of confusing

486
00:26:51,343 --> 00:26:53,545
then the previous sessions
are kind of necessary.

487
00:26:53,678 --> 00:26:58,049
We walk through the matrices and some of
the degrees of freedom in this set up.

488
00:26:58,383 --> 00:27:01,286
So I think it should be good
to check out the other videos if

489
00:27:01,286 --> 00:27:01,920
you haven't already.

490
00:27:03,722 --> 00:27:06,157
But but, you know, as a brief

491
00:27:06,925 --> 00:27:09,761
kind of refresher about the task
that we're talking about,

492
00:27:11,029 --> 00:27:15,533
the on each trial, the agent starts
in a start state and then it can either

493
00:27:15,533 --> 00:27:20,005
directly choose one of two slot machines
and if they're right, they'll win $4.

494
00:27:20,005 --> 00:27:24,409
But if they're wrong, they'll 10
and they start out not knowing,

495
00:27:24,709 --> 00:27:29,247
you know, like just flat prior over
whether the left or the right one is

496
00:27:29,581 --> 00:27:30,582
whether it's the context

497
00:27:30,582 --> 00:27:32,984
in which the left or the right
one is more likely to win.

498
00:27:33,685 --> 00:27:35,320
So it's just 5050.

499
00:27:35,320 --> 00:27:37,322
So it's pretty risky
to just pick one right away,

500
00:27:38,423 --> 00:27:41,426
at least before you've learned
if one of them is actually more likely

501
00:27:41,793 --> 00:27:46,064
if the context in which one is more
likely to win is more common.

502
00:27:47,132 --> 00:27:49,601
So instead,
the other thing that the agent can do

503
00:27:49,601 --> 00:27:53,772
is they can choose to get a hint
and the hint will tell them which

504
00:27:54,806 --> 00:27:57,809
whether it's a context
in which the left bandit is the one

505
00:27:57,809 --> 00:28:01,946
that is more likely to win
and when it's the right one

506
00:28:03,148 --> 00:28:07,052
and in each of the contacts in the left
in the context where the left one's

507
00:28:07,052 --> 00:28:11,556
better, it will payout 80% of the time
whereas in the context of the right one,

508
00:28:12,157 --> 00:28:14,859
the right one will pay out
80% of the time.

509
00:28:14,859 --> 00:28:17,295
But the catch is
if you choose to take the hint,

510
00:28:17,295 --> 00:28:21,633
then you'll only win $2
if you get the right one afterwards.

511
00:28:22,667 --> 00:28:26,838
So this trades off this kind of reward
seeking and information seeking,

512
00:28:27,272 --> 00:28:31,209
where if you seek information
first, you're more likely to win.

513
00:28:31,209 --> 00:28:35,346
But if you choose first right away,
then you'll get a higher reward

514
00:28:35,346 --> 00:28:36,047
if you're right.

515
00:28:37,449 --> 00:28:38,516
So it specifically trades

516
00:28:38,516 --> 00:28:41,019
off reward and uncertainty

517
00:28:42,854 --> 00:28:44,255
and this is where a lot of

518
00:28:44,255 --> 00:28:46,791
this is not going to make sense
unless you've seen the previous sessions,

519
00:28:48,093 --> 00:28:50,962
is that the second thing is
you have to build one

520
00:28:50,962 --> 00:28:53,798
or more models of the task
we just talked about.

521
00:28:54,699 --> 00:28:58,069
In our example, we'll use two different
variants of the model one where

522
00:28:58,069 --> 00:28:59,370
we're just going to fit

523
00:28:59,370 --> 00:29:03,141
the risk seeking parameter
and an action precision parameter

524
00:29:03,608 --> 00:29:07,278
and a second model where we also assume
that the agent has a learning rate

525
00:29:07,879 --> 00:29:10,982
or that there are differences
in learning right.

526
00:29:11,282 --> 00:29:14,352
So for those that don't remember,
the risk

527
00:29:14,352 --> 00:29:18,490
seeking parameter just corresponds
to the magnitude of this RC value.

528
00:29:19,891 --> 00:29:21,926
So at this says is at time

529
00:29:21,926 --> 00:29:25,396
two, if the agent observes
a win, Cicero's a win,

530
00:29:25,730 --> 00:29:29,400
then the value of that win will be Rs

531
00:29:30,435 --> 00:29:33,605
and if they instead wait and choose
the hint, they'll continue

532
00:29:33,605 --> 00:29:37,575
to observe this start thing at time,
two at a time, three.

533
00:29:37,942 --> 00:29:40,879
If they win, then the value they will win
will be

534
00:29:41,179 --> 00:29:44,315
this Rs value divided by two.

535
00:29:44,315 --> 00:29:46,151
So so whatever Rs ends up

536
00:29:46,151 --> 00:29:49,654
being the win at the third time point,
if they take the hint is half of that.

537
00:29:50,188 --> 00:29:53,358
I'm so going to be setting
for each person what that RS value is,

538
00:29:54,659 --> 00:29:58,229
which again stands for risk seeking,
which would be clear to anyone

539
00:29:58,229 --> 00:30:03,301
who's watched the previous sessions,
because the higher this value is, the

540
00:30:03,802 --> 00:30:06,538
the less exploratory drive
the agent will have

541
00:30:07,739 --> 00:30:11,209
and that means that they'll be
more likely to take the risk and just

542
00:30:12,377 --> 00:30:14,879
choose one of the slot machines randomly

543
00:30:14,879 --> 00:30:18,216
as opposed to taking the hint first
to be more confident in which ones right.

544
00:30:19,651 --> 00:30:22,086
So the second parameter

545
00:30:22,620 --> 00:30:25,156
is this action precision parameter alpha.

546
00:30:26,224 --> 00:30:31,262
And all this basically says
is the precision or the probability

547
00:30:31,262 --> 00:30:35,433
of selecting some action
given an alpha value corresponds to this.

548
00:30:36,267 --> 00:30:38,803
So our corresponds
to whatever the probability

549
00:30:38,803 --> 00:30:41,940
is of an action, given the given a policy

550
00:30:42,941 --> 00:30:47,412
scaled by this alpha thing
and then soft max to become a

551
00:30:47,812 --> 00:30:50,582
just a proper probability
distribution again.

552
00:30:50,582 --> 00:30:53,985
So it just controls how more or less
it controls how precise

553
00:30:53,985 --> 00:30:56,921
action selection
is given the choice of policy

554
00:30:58,890 --> 00:31:01,893
and then finally in the model,
in the second model,

555
00:31:01,893 --> 00:31:04,062
where we're also going to assume
an agent has a learning rate

556
00:31:06,297 --> 00:31:08,466
other than just the optimal learning
rate of one,

557
00:31:09,968 --> 00:31:12,270
then we're also going to be fitting
this thing

558
00:31:12,270 --> 00:31:13,905
ETA here, which is the learning rate.

559
00:31:14,906 --> 00:31:17,942
And this just says that your beliefs

560
00:31:18,443 --> 00:31:23,514
about the probability of the context
being that

561
00:31:23,514 --> 00:31:26,784
the left slot machine is better versus
at the right slot machine is better.

562
00:31:27,785 --> 00:31:32,857
Just updates
based on your beliefs about whatever the

563
00:31:33,291 --> 00:31:36,861
that state, whatever the winning state
was on the previous trial.

564
00:31:37,228 --> 00:31:39,998
Again, four times step one.

565
00:31:39,998 --> 00:31:42,367
So basically each trial,

566
00:31:42,367 --> 00:31:45,436
whatever the posterior beliefs were over
states,

567
00:31:46,771 --> 00:31:48,840
they the count for that just gets added

568
00:31:48,840 --> 00:31:52,744
to whatever
the prior of our initial states was at.

569
00:31:52,877 --> 00:31:57,215
That is at the next time point,
but it's scaled by this ETA thing.

570
00:31:57,548 --> 00:32:02,987
So, you know, if ETA is one,
then it'll talk on account of one again

571
00:32:03,021 --> 00:32:05,990
if if it knows with certainty
that it was in say like state one.

572
00:32:06,424 --> 00:32:09,060
But if ETA is 0.7,
that only at a count of point

573
00:32:09,060 --> 00:32:14,265
seven on each trial, given that
the posterior distribution was like 10

574
00:32:16,668 --> 00:32:18,970
so so that's

575
00:32:18,970 --> 00:32:21,673
the the basic set up
is we're going to fit either

576
00:32:21,673 --> 00:32:24,008
just RC and Alpha
or we're going to fit both of those.

577
00:32:24,008 --> 00:32:25,343
And ETA

578
00:32:27,145 --> 00:32:28,846
and one note on that, Ryan,

579
00:32:28,846 --> 00:32:32,016
I like the step to build one
or more models because we're thinking

580
00:32:32,016 --> 00:32:35,353
about active inference
as like this process theory.

581
00:32:35,353 --> 00:32:39,090
It's instrumental you know, the whole
instrumental ism versus realism question.

582
00:32:39,490 --> 00:32:41,192
We're using it as an instrument,

583
00:32:41,192 --> 00:32:43,628
and that means that
we're iterating over models

584
00:32:43,828 --> 00:32:46,931
or relating our models
to each other in specific ways, like

585
00:32:46,931 --> 00:32:50,001
make the simpler one and then make one
that just adds one more variable.

586
00:32:50,401 --> 00:32:54,472
And then it's not like you're asking
what is the active inference model here?

587
00:32:54,739 --> 00:32:59,143
It's here's the active inference
approach, and we're going to combine

588
00:32:59,143 --> 00:33:02,280
our perspectives and make multiple models
and we'll be comparing models.

589
00:33:02,280 --> 00:33:04,115
So the only limiting factor there is

590
00:33:04,115 --> 00:33:06,317
how many models can
we think of at the beginning

591
00:33:06,451 --> 00:33:09,320
and how wise can our model selection
process be?

592
00:33:09,587 --> 00:33:13,391
So it's just really like a pluralistic
but pragmatic way to go about it

593
00:33:13,758 --> 00:33:17,462
by saying construct one or more models
because then you're never going to fall

594
00:33:17,462 --> 00:33:18,262
in the trap of thinking.

595
00:33:18,262 --> 00:33:22,266
You're making the active inference model
because there isn't the model

596
00:33:22,266 --> 00:33:24,502
of anything. Statistically,
they're just instruments.

597
00:33:24,736 --> 00:33:26,637
So it's a really helpful perspective.

598
00:33:26,637 --> 00:33:30,274
And so this isn't just a little
convenience to make one or more models.

599
00:33:30,274 --> 00:33:34,445
It's something that reminds the scientist
or the modeler that they're actually

600
00:33:34,445 --> 00:33:37,982
making one of many or infinite
possible ways to think about a situation.

601
00:33:39,817 --> 00:33:42,186
Yeah, I mean, I mean, hopefully
you've really kind of

602
00:33:42,720 --> 00:33:46,391
thought deeply about what the most
plausible models that are given current

603
00:33:46,391 --> 00:33:50,495
theory and, you know, current, previous
or previous empirical research, right?

604
00:33:50,495 --> 00:33:53,531
So I mean, they should be informed
by. Yes.

605
00:33:53,531 --> 00:33:57,668
So you're just you're
trying to find the model that has the

606
00:33:58,436 --> 00:34:01,305
highest evidence that the observations
or the behavior provides

607
00:34:01,305 --> 00:34:03,341
the highest evidence for.

608
00:34:03,341 --> 00:34:05,610
And yes,
it is always possible that there's

609
00:34:05,610 --> 00:34:08,312
some other model that you haven't
thought of that would be better.

610
00:34:09,313 --> 00:34:13,851
But, you know, if you have a model
that explains behavior really well

611
00:34:13,851 --> 00:34:15,486
and it does
so better than any of the other ones

612
00:34:15,486 --> 00:34:19,590
you can think of, then it's
kind of a good bet as at least giving you

613
00:34:20,391 --> 00:34:23,795
interesting individual differences
to to again, bring up to our

614
00:34:23,828 --> 00:34:25,129
group level analysis

615
00:34:26,898 --> 00:34:29,801
so so OK, so,

616
00:34:30,301 --> 00:34:33,171
you know,
to get kind of a little nitty gritty

617
00:34:33,171 --> 00:34:36,941
in terms of the code and the MATLAB
structure, and everything, you know,

618
00:34:37,041 --> 00:34:40,144
the kind of thing you need to do
is you first.

619
00:34:40,344 --> 00:34:42,814
So you have a participant's
behavior, right?

620
00:34:42,814 --> 00:34:44,949
Like it shows the hint
and then slot machine

621
00:34:44,949 --> 00:34:47,185
one that shows the hint and then slot
machine two, OK,

622
00:34:47,218 --> 00:34:51,355
now that just shows the slot machine
right away or slot machine two right away

623
00:34:52,056 --> 00:34:53,191
and so forth.

624
00:34:53,191 --> 00:34:55,993
And those have to be coded in
right to each trial.

625
00:34:55,993 --> 00:34:58,596
And the MVP structure which which again

626
00:34:59,530 --> 00:35:02,233
previous sessions will explain.

627
00:35:02,433 --> 00:35:05,203
So the MVP structure in MATLAB

628
00:35:06,471 --> 00:35:09,373
for each so each

629
00:35:09,373 --> 00:35:11,943
each number
right inside these parentheses

630
00:35:11,943 --> 00:35:15,146
here will be the trial
that you're talking about.

631
00:35:15,146 --> 00:35:17,315
And the dot you hear is the,

632
00:35:18,716 --> 00:35:20,518
the matrix that describe that

633
00:35:20,518 --> 00:35:22,653
encodes
the actions that a participant took

634
00:35:24,355 --> 00:35:26,390
now if we remember

635
00:35:26,390 --> 00:35:30,161
so row one here corresponds to state
factor one, which is the context,

636
00:35:30,928 --> 00:35:35,032
whether it left or right is better
and there is no action for that.

637
00:35:35,066 --> 00:35:36,534
That's not something agent control.

638
00:35:36,534 --> 00:35:38,703
It's just stable within a trial.
Which one it is.

639
00:35:39,103 --> 00:35:42,273
So these just get ones
and there is no other possible action

640
00:35:43,441 --> 00:35:44,942
for the second row, though.

641
00:35:44,942 --> 00:35:48,246
So this is the state factor
that corresponded to action selection

642
00:35:50,181 --> 00:35:52,750
to, you know, action to corresponded

643
00:35:52,750 --> 00:35:55,853
to taking the hint and action
three corresponded to choosing left.

644
00:35:56,420 --> 00:35:59,390
So if that was what a participant
did on trial, one

645
00:35:59,757 --> 00:36:02,727
then you would have to feed in two
followed by three.

646
00:36:02,727 --> 00:36:05,229
Right. They chose the hint
and then they chose left on that trial.

647
00:36:06,297 --> 00:36:09,400
And so you just have to iterate
that over all the trials in the task

648
00:36:09,400 --> 00:36:13,137
so one to end trials, whatever they did.

649
00:36:14,305 --> 00:36:15,439
So that's MVP.

650
00:36:15,439 --> 00:36:16,307
And in this case, like I said,

651
00:36:16,307 --> 00:36:19,277
there are two actions or two columns
and there are two state factors

652
00:36:19,777 --> 00:36:22,146
where only the rows
which are on the second one is control

653
00:36:24,015 --> 00:36:27,752
so now p 00 is the observations.

654
00:36:28,853 --> 00:36:32,723
So again, if you're familiar with the M,

655
00:36:32,757 --> 00:36:37,895
the way we set up the model for this task
before, there are three different

656
00:36:38,429 --> 00:36:41,632
outcome modalities, three different types
of observations you can get.

657
00:36:42,133 --> 00:36:47,438
So the first observation modality,
what a hint or not.

658
00:36:48,239 --> 00:36:52,877
So in this case, one is just you're kind
of still observing the start observation

659
00:36:53,244 --> 00:36:57,615
if you observe two, that means you
get a hint that the left one is better.

660
00:36:57,615 --> 00:37:00,851
And if you observe a three, that's
the hint that the right one is better.

661
00:37:01,285 --> 00:37:04,121
So in this case, they got the observation
that the left one is better

662
00:37:04,121 --> 00:37:04,622
when they tell

663
00:37:08,192 --> 00:37:10,561
one to
one, because after they got the hint,

664
00:37:10,561 --> 00:37:14,031
they just returned back to observing
kind of the initial observation

665
00:37:14,398 --> 00:37:16,901
or the hint modality

666
00:37:16,934 --> 00:37:20,071
whereas for the second modality

667
00:37:20,071 --> 00:37:23,207
here, which is the wins losses

668
00:37:23,207 --> 00:37:25,209
for the first two time steps,
they just observe

669
00:37:25,209 --> 00:37:27,345
kind of the starting observation here

670
00:37:27,345 --> 00:37:29,313
because they chose the hint
at the second time point.

671
00:37:29,313 --> 00:37:31,816
So there was no win or loss.

672
00:37:31,816 --> 00:37:34,819
And then at time point three,
they observed a win.

673
00:37:34,819 --> 00:37:39,490
So winners encoded as a three in this
model, and two are losses encoded by two.

674
00:37:41,158 --> 00:37:44,428
And then the final outcome

675
00:37:44,428 --> 00:37:47,131
modality is just the agent
observing what it does.

676
00:37:47,565 --> 00:37:50,301
So in this case,
this just says start it and start state

677
00:37:50,635 --> 00:37:53,304
chose to take the
hint and then chose the left

678
00:37:54,472 --> 00:37:55,373
shows start

679
00:37:57,475 --> 00:37:58,409
it observed itself

680
00:37:58,409 --> 00:38:01,479
choosing the choice of the left
slot machine.

681
00:38:02,880 --> 00:38:03,547
So that's it.

682
00:38:03,547 --> 00:38:06,817
So all you have to do when you're instead

683
00:38:06,817 --> 00:38:08,853
of simulating behavior, you're actually

684
00:38:10,254 --> 00:38:13,324
sitting where you're actually feeding
in participant behavior

685
00:38:13,591 --> 00:38:16,961
to fit it to fit a model to it.

686
00:38:18,062 --> 00:38:20,131
Then you just have to, you know, sort of

687
00:38:20,131 --> 00:38:23,301
translate the behavior in the raw data
into a form like this

688
00:38:23,301 --> 00:38:26,370
that matches the action and outcome

689
00:38:26,370 --> 00:38:29,507
representations in the model.

690
00:38:29,807 --> 00:38:31,842
And, and so that's it.

691
00:38:32,310 --> 00:38:34,512
You first feed those in

692
00:38:34,512 --> 00:38:36,480
and then once you've done that,

693
00:38:36,480 --> 00:38:40,217
then you have to use
some kind of estimation algorithm,

694
00:38:40,651 --> 00:38:43,954
which basically means
the thing is going to somehow repeat

695
00:38:44,822 --> 00:38:46,891
simulating behavior in that model

696
00:38:47,325 --> 00:38:50,227
until it finds a model that maximizes

697
00:38:50,628 --> 00:38:54,332
the overlap between the probability
of choosing the participants

698
00:38:54,665 --> 00:38:57,702
of the probability
of choosing actions and what the

699
00:38:58,869 --> 00:39:00,771
participant actually chose.

700
00:39:00,771 --> 00:39:01,105
Right.

701
00:39:01,105 --> 00:39:06,077
So for instance, if it chose Hint
and then left band, it left slot

702
00:39:06,077 --> 00:39:10,681
machine on trial one and it's
going to find a set of parameters

703
00:39:11,015 --> 00:39:14,285
that apply across all trials
that maximize the probability

704
00:39:14,719 --> 00:39:17,955
that the simulated agent
also would choose the hand, followed

705
00:39:17,955 --> 00:39:21,759
by choosing the left slot machine.

706
00:39:21,759 --> 00:39:23,828
So there are a number of different
estimation

707
00:39:23,828 --> 00:39:26,530
algorithms that can be used.

708
00:39:27,598 --> 00:39:31,569
You know, the the simplest possible
one is just something like a grid search.

709
00:39:32,103 --> 00:39:34,705
So in this case,
say you just have two parameters

710
00:39:34,705 --> 00:39:36,907
which this is just arbitrary
called alpha and beta.

711
00:39:37,875 --> 00:39:41,011
You can kind of divide this up
into little grids, different combinations

712
00:39:41,011 --> 00:39:41,979
of parameter values.

713
00:39:41,979 --> 00:39:45,783
So for instance, like,
you know, parameter 0.24 alpha

714
00:39:46,117 --> 00:39:49,620
and parameter value 34 beta.

715
00:39:50,087 --> 00:39:53,924
And then you can just encode, for
example, what the probability

716
00:39:55,259 --> 00:39:55,993
of the

717
00:39:55,993 --> 00:39:58,829
model is given the participants actions.

718
00:40:00,030 --> 00:40:03,000
Or that would be the posterior,
which I'll talk about

719
00:40:03,000 --> 00:40:03,968
or just the probability

720
00:40:03,968 --> 00:40:06,871
a part has been behavior given the model
and those parameter values.

721
00:40:07,371 --> 00:40:10,441
I mean, so in this case, there's
this kind of clear nice result where

722
00:40:10,808 --> 00:40:14,044
this value right here, something like 0.3

723
00:40:14,178 --> 00:40:16,447
and for that

724
00:40:17,281 --> 00:40:20,651
is maximally and uniquely
the best set of parameters

725
00:40:20,651 --> 00:40:23,320
for reproducing
that participant's behavior.

726
00:40:25,356 --> 00:40:27,925
And and in this case,

727
00:40:27,925 --> 00:40:31,796
you're using something called
in this case you're using something

728
00:40:31,796 --> 00:40:36,400
called maximum likelihood
so maximum likelihood estimation,

729
00:40:37,067 --> 00:40:40,871
which just means again,
you're trying to find the model

730
00:40:40,871 --> 00:40:43,541
and set a parameters for or which the

731
00:40:44,675 --> 00:40:47,845
probability of the participants
behavior, given that model is highest,

732
00:40:48,879 --> 00:40:51,582
which is a type of likelihood, right?

733
00:40:51,582 --> 00:40:53,984
So you're trying to find the maximum
value for the likelihood,

734
00:40:55,619 --> 00:40:56,487
which you're just in this

735
00:40:56,487 --> 00:40:58,956
case, in code with this,
you know, redder colors

736
00:40:59,690 --> 00:41:03,327
equals higher likelihood

737
00:41:03,327 --> 00:41:03,928
of behavior.

738
00:41:03,928 --> 00:41:08,165
Again, in the model,
you can also do something a little bit.

739
00:41:09,099 --> 00:41:13,838
So to be clear, what we actually would
want right is is the inverse of this.

740
00:41:13,838 --> 00:41:16,140
We would want the probability of a model

741
00:41:16,140 --> 00:41:18,709
given participant behavior,
which is the posterior.

742
00:41:20,177 --> 00:41:24,181
But when you're doing maximum likelihood
estimation, you're just assuming here

743
00:41:24,181 --> 00:41:27,751
that you have essentially a flat prior
for what

744
00:41:27,751 --> 00:41:29,887
the probability over models is.

745
00:41:30,888 --> 00:41:34,291
So in this if that's the case,
then the probability of the model

746
00:41:34,291 --> 00:41:36,927
given person
behavior is just proportional to

747
00:41:38,128 --> 00:41:39,663
the likelihood.

748
00:41:40,097 --> 00:41:42,466
But another thing you can do

749
00:41:42,466 --> 00:41:47,104
is called on a posterior or map
estimates, which is the same thing,

750
00:41:47,505 --> 00:41:50,274
except it doesn't assume
that you have a flat prior

751
00:41:51,275 --> 00:41:53,210
or all right.

752
00:41:53,210 --> 00:41:56,380
So if you just start out
with a prior expectation that one model

753
00:41:56,380 --> 00:42:00,851
is better than another, then
you can incorporate that information into

754
00:42:01,886 --> 00:42:04,088
into parameter estimation.

755
00:42:04,088 --> 00:42:06,824
And this is kind of an example of this
where

756
00:42:07,625 --> 00:42:11,061
you might find this distribution
in terms of just the likelihood right

757
00:42:11,095 --> 00:42:12,530
the probability of data given the model

758
00:42:12,530 --> 00:42:16,433
where a parameter combination
right around here would be best.

759
00:42:16,967 --> 00:42:19,637
But then you might also have some reason
to have a prior

760
00:42:19,637 --> 00:42:22,373
expectation that models down here.

761
00:42:22,806 --> 00:42:25,142
Right, are actually more likely.

762
00:42:25,943 --> 00:42:27,511
And so if you combine
those guys together,

763
00:42:27,511 --> 00:42:31,081
you can get a posterior
that looks a little different right?

764
00:42:31,081 --> 00:42:35,953
Like a something very similar, a set,
very similar model wins in this case.

765
00:42:36,353 --> 00:42:39,590
But that's just because the behavior

766
00:42:40,190 --> 00:42:44,094
that's driving the the likelihood here
is just already a really good fit.

767
00:42:44,094 --> 00:42:47,264
So it kind of dominates
over over the influence of priors.

768
00:42:47,264 --> 00:42:48,599
But that's not
always going to be the case.

769
00:42:51,001 --> 00:42:53,070
So so those are two approaches.

770
00:42:54,371 --> 00:42:58,042
And and again, you can
you can do them with a simple grid search

771
00:42:58,943 --> 00:43:01,178
or you can do something.

772
00:43:01,612 --> 00:43:04,982
So I should say that the grid search
kind of thing, it only really works

773
00:43:05,416 --> 00:43:09,320
when you have a few parameters mean
you don't have very many.

774
00:43:10,020 --> 00:43:10,621
And the reason is

775
00:43:10,621 --> 00:43:13,958
because the more parameters
that you have, the higher dimensional

776
00:43:14,792 --> 00:43:19,663
this parameter space becomes
and it just becomes it takes sort of

777
00:43:19,663 --> 00:43:22,833
interactively long to do to search

778
00:43:22,833 --> 00:43:25,703
through every possible combination

779
00:43:26,337 --> 00:43:28,639
so what you do instead

780
00:43:28,639 --> 00:43:31,141
is you use some kind of gradient
descent process.

781
00:43:32,276 --> 00:43:35,579
Exactly
like the gradient descent on free energy

782
00:43:35,579 --> 00:43:38,582
that we've been talking about
for how active inference models

783
00:43:38,582 --> 00:43:42,353
arrive at posteriors over
states and posteriors or policies.

784
00:43:43,354 --> 00:43:44,555
So there's a

785
00:43:44,555 --> 00:43:48,859
really kind of interesting overlap
between the way that you estimate models,

786
00:43:49,727 --> 00:43:53,797
the gradient descent and the way
that you actually the way that active

787
00:43:53,797 --> 00:43:57,134
inference models update their beliefs
via gradient descent.

788
00:43:58,602 --> 00:43:59,803
So in this case.

789
00:43:59,803 --> 00:44:03,607
Or it's a very good point,
and I want to point out one similarity

790
00:44:03,607 --> 00:44:06,110
in difference, because people may have
heard about these graded descent

791
00:44:06,110 --> 00:44:09,713
algorithms for descriptive statistics
or for fitting descriptive models.

792
00:44:10,114 --> 00:44:14,652
So that's from going again from the data
that's empirical to a descriptive model

793
00:44:14,652 --> 00:44:17,821
or descriptive statistics
like regression coefficients.

794
00:44:18,355 --> 00:44:22,292
And if it's a multivariable regression,
you might need to use

795
00:44:22,292 --> 00:44:25,329
not just a grid search,
but that you can do a simple maximum

796
00:44:25,329 --> 00:44:28,165
likelihood approach like a least squares
approach or something like that.

797
00:44:28,499 --> 00:44:32,036
You need to use this kind of a complex,
multidimensional optimization

798
00:44:32,369 --> 00:44:34,538
to get to that descriptive statistic.

799
00:44:34,538 --> 00:44:37,741
And then there's this little twist
where actually in active inference,

800
00:44:38,175 --> 00:44:40,744
we might be using
those computational techniques,

801
00:44:41,111 --> 00:44:44,715
but we're estimating the parameters
of an underlying generative model

802
00:44:44,915 --> 00:44:48,452
and then there's this nice little return
where actually the generative model is

803
00:44:48,452 --> 00:44:49,520
implementing that as well.

804
00:44:51,955 --> 00:44:52,556
Yeah.

805
00:44:52,823 --> 00:44:55,492
So, so and so in this case,

806
00:44:56,760 --> 00:44:58,796
you you absolutely need

807
00:45:00,197 --> 00:45:03,033
some kind of prior value

808
00:45:03,033 --> 00:45:06,203
because with gradient descent,
you're not exploring every combination.

809
00:45:06,203 --> 00:45:07,337
What you're doing is you're starting

810
00:45:07,337 --> 00:45:10,441
at some starting point,
which is just go to by a here

811
00:45:11,408 --> 00:45:14,745
and then you're just like
when you're minimizing free energy

812
00:45:14,912 --> 00:45:20,384
and in an active inference model,
you're searching neighboring values

813
00:45:20,384 --> 00:45:24,254
and trying to find a value
that has a higher

814
00:45:24,888 --> 00:45:27,524
likelihood or lower for energy.

815
00:45:28,959 --> 00:45:31,862
And then you just kind of keep doing that
iteratively

816
00:45:32,196 --> 00:45:35,032
until you find some value

817
00:45:35,532 --> 00:45:38,702
that where the likelihood stops
getting bigger

818
00:45:38,936 --> 00:45:42,339
or for energy stops getting smaller

819
00:45:42,406 --> 00:45:44,475
and that then corresponds

820
00:45:44,475 --> 00:45:49,413
to your best estimate
or your posterior posterior

821
00:45:49,680 --> 00:45:53,550
estimate for the parameters

822
00:45:54,184 --> 00:45:57,354
for a given participant. And

823
00:45:58,589 --> 00:46:01,792
so when you're
doing this with when you're doing it

824
00:46:01,792 --> 00:46:08,065
with gradient descent for for energy,
then that ends up corresponding

825
00:46:08,332 --> 00:46:11,568
well to the actual approach
that we'll be talking about

826
00:46:12,369 --> 00:46:16,173
or actually using in our example,
which is variational base.

827
00:46:16,507 --> 00:46:18,342
So the variation base,
you do exactly this.

828
00:46:18,342 --> 00:46:21,478
You set prior mean value and a prior

829
00:46:21,478 --> 00:46:23,914
variance for each parameter,

830
00:46:24,915 --> 00:46:29,286
and then you do a gradient descent
until you find a set of parameters

831
00:46:29,520 --> 00:46:33,590
that minimize for energy, which is again

832
00:46:33,590 --> 00:46:36,426
an approximation to the model evidence

833
00:46:38,462 --> 00:46:40,564
so but, but it's important

834
00:46:41,098 --> 00:46:42,733
to keep in mind the potential limitations

835
00:46:42,733 --> 00:46:45,469
of this approach,
which is if you see here

836
00:46:45,469 --> 00:46:47,471
this parameter space

837
00:46:48,372 --> 00:46:51,308
it does look like
there is a kind of a nice single, right?

838
00:46:51,308 --> 00:46:53,644
Like local minimum, right?

839
00:46:53,644 --> 00:46:56,947
Local place
where the for energy is lowest or

840
00:46:57,748 --> 00:47:00,984
where the again,
it would be at a local maximum

841
00:47:00,984 --> 00:47:03,420
maybe like top of mountain in this
if you were talking about the

842
00:47:03,453 --> 00:47:04,388
highest likelihood

843
00:47:06,356 --> 00:47:07,658
they typically do

844
00:47:07,658 --> 00:47:09,827
log likelihoods
as opposed to likelihoods.

845
00:47:11,428 --> 00:47:14,731
And but one of the issues
is is this sort of

846
00:47:15,833 --> 00:47:20,437
the parameter space need not have a
landscape that's quite this clean.

847
00:47:21,572 --> 00:47:24,074
You might end up for instance
having a landscape

848
00:47:24,074 --> 00:47:25,642
just moving to a two dimensional case.

849
00:47:25,642 --> 00:47:29,413
Now that looks kind of like this
where if you start out say with a prior

850
00:47:29,413 --> 00:47:33,050
value with prior values
that you know, like this kind of red

851
00:47:33,217 --> 00:47:36,053
circle up here,
then if you do a gradient descent,

852
00:47:36,486 --> 00:47:40,090
you might end up getting stuck
on a little local minimum like this

853
00:47:41,625 --> 00:47:44,795
where you know, and then
and then the gradient descent algorithm

854
00:47:44,795 --> 00:47:47,998
would say hey, you know, actually,
you know, this seems like the best one

855
00:47:47,998 --> 00:47:52,135
because if I move in any direction,
then the free energy goes up

856
00:47:54,071 --> 00:47:54,571
whereas

857
00:47:54,571 --> 00:47:57,641
actually the global minimum,
the one that you would want to get to

858
00:47:57,641 --> 00:47:58,475
is this different one

859
00:47:58,475 --> 00:48:01,245
that's on the other side of this
little kind of free energy hill.

860
00:48:02,779 --> 00:48:05,816
And so you know, this is
this is an example where

861
00:48:06,783 --> 00:48:09,319
I'm choosing the right priors
as important

862
00:48:09,953 --> 00:48:13,624
to get the to be able
to get the the best parameter estimates.

863
00:48:14,424 --> 00:48:17,761
But also this speaks to the kind of thing
about parameter recovery

864
00:48:17,761 --> 00:48:20,597
that I was talking about earlier,
because it could be that

865
00:48:21,031 --> 00:48:24,434
if you set your parameters kind of right
on the top of this hill thing here,

866
00:48:24,968 --> 00:48:28,338
then even if the parameter
combination over here

867
00:48:28,338 --> 00:48:30,340
is the one that actually generated
the data,

868
00:48:31,341 --> 00:48:34,544
you could get stuck over in this one,
in which case the estimation algorithm

869
00:48:34,811 --> 00:48:37,781
would not give you the
right parameter estimates.

870
00:48:38,982 --> 00:48:39,483
So this is

871
00:48:39,483 --> 00:48:42,452
why what I mentioned earlier about

872
00:48:42,452 --> 00:48:45,322
assessing parameter
recoverability is really important.

873
00:48:46,857 --> 00:48:48,992
So although it's saying it's important

874
00:48:48,992 --> 00:48:52,029
to choose good priors
or to figure out what good priors are

875
00:48:52,896 --> 00:48:56,333
and there are there are interesting ways
to try to optimize that.

876
00:48:56,333 --> 00:48:58,702
So there are kind of hierarchical
Bayesian techniques.

877
00:48:58,702 --> 00:49:01,705
We don't talk about these explicitly,
but where you can kind of

878
00:49:02,706 --> 00:49:05,208
and these won't necessarily
solve this problem, but where you can

879
00:49:06,443 --> 00:49:09,246
more or less, you could think about it
as it estimates the parameters

880
00:49:09,246 --> 00:49:10,580
for each person

881
00:49:10,580 --> 00:49:14,685
and then it notices hey, you know,
looks like these are all shifted over.

882
00:49:14,851 --> 00:49:15,152
You know,

883
00:49:15,152 --> 00:49:18,055
the distribution of these looks like
they're all shifted over to the right,

884
00:49:18,422 --> 00:49:19,156
you know, so

885
00:49:19,156 --> 00:49:22,492
actually that looks like that
distribution is more kind of over here.

886
00:49:22,793 --> 00:49:23,460
And so then it might

887
00:49:24,594 --> 00:49:26,697
choose that

888
00:49:26,697 --> 00:49:30,000
choose
that that the kind of mean value of that

889
00:49:31,001 --> 00:49:33,070
as the new priors

890
00:49:34,171 --> 00:49:36,606
or for redoing the estimates

891
00:49:37,307 --> 00:49:39,409
until it finds values that

892
00:49:40,811 --> 00:49:42,713
that essentially it's it's

893
00:49:42,713 --> 00:49:45,482
helping you to find whatever
the optimal priors would be.

894
00:49:46,616 --> 00:49:49,486
But again, that won't they won't always

895
00:49:49,853 --> 00:49:53,223
solve this sort of problem
with that lumpy landscape.

896
00:49:53,423 --> 00:49:54,124
You know.

897
00:49:54,224 --> 00:49:58,128
One other little thought, it's actually
almost three layers with the red dot.

898
00:49:58,128 --> 00:50:00,797
So there's us as agents on a landscape.

899
00:50:00,797 --> 00:50:05,402
We actually need to come up with policy
as agents in our niche to get around

900
00:50:05,635 --> 00:50:09,206
local minima, like my door is closed,
I need to step away to open the door

901
00:50:09,206 --> 00:50:11,041
before I can move through it.

902
00:50:11,041 --> 00:50:13,710
Then how are we going to fit policies

903
00:50:13,710 --> 00:50:16,546
for ourself under pervasive uncertainty?

904
00:50:16,713 --> 00:50:21,385
Well, we're doing this state estimation
with a policy C so that we can actually

905
00:50:21,852 --> 00:50:24,421
then how are we going to converge
on those parameters

906
00:50:24,888 --> 00:50:29,926
using a little bit like a gradient
descent algorithm internally

907
00:50:30,360 --> 00:50:33,463
not internally sources,
just within the agents computationally.

908
00:50:33,797 --> 00:50:36,366
It just it's a very interesting
because people may have

909
00:50:36,633 --> 00:50:39,102
I'd imagine there's one
kind of person who sees this and says,

910
00:50:39,102 --> 00:50:41,972
Oh, we talked about optimization
for a year in my course.

911
00:50:42,272 --> 00:50:44,941
So I've heard all about non and convex,

912
00:50:44,941 --> 00:50:48,211
non convex optimization techniques
or rugged fitness landscapes.

913
00:50:48,578 --> 00:50:52,082
And there's another group of people for
whom actually this optimization theory

914
00:50:52,115 --> 00:50:57,721
might be quite novel because of how
they've looked at modeling before.

915
00:50:58,255 --> 00:51:01,425
So a very interesting
and to put into the fourth section like

916
00:51:01,425 --> 00:51:02,659
that really spoke a lot.

917
00:51:03,894 --> 00:51:04,594
So interesting stuff.

918
00:51:04,594 --> 00:51:04,828
Right.

919
00:51:04,828 --> 00:51:05,996
I just want to ask Christopher,

920
00:51:05,996 --> 00:51:09,599
you want to add anything
before we continue with us?

921
00:51:09,933 --> 00:51:12,369
No, this really is very much
Ryan's part of the paper.

922
00:51:13,904 --> 00:51:16,573
Yeah, I'm just here if you.

923
00:51:16,907 --> 00:51:19,276
Want more than a welcome to add thoughts
or if you have any other insights

924
00:51:19,276 --> 00:51:20,811
about technical aspects.

925
00:51:20,811 --> 00:51:23,180
No, no, nothing really.

926
00:51:23,180 --> 00:51:28,051
I would just I might ask some questions
if something if things come up because

927
00:51:28,051 --> 00:51:30,954
I'm going to be doing this at some point
in the next couple of months, but

928
00:51:32,222 --> 00:51:34,691
so yeah.

929
00:51:34,925 --> 00:51:35,392
Great.

930
00:51:35,392 --> 00:51:35,992
That's

931
00:51:37,060 --> 00:51:39,663
OK. So

932
00:51:40,030 --> 00:51:42,833
so like I said, the kind of detailed

933
00:51:42,833 --> 00:51:45,235
example that we are going to use
is variational base.

934
00:51:46,203 --> 00:51:51,408
And note that variational message
crashing is again, what agents are using

935
00:51:51,408 --> 00:51:52,776
within

936
00:51:53,410 --> 00:51:56,646
within active inference models,
which we talked about before.

937
00:51:56,980 --> 00:51:59,015
So now we're using something
very very similar to this

938
00:51:59,883 --> 00:52:02,018
or I mean, so technically I should say

939
00:52:02,018 --> 00:52:04,354
now it's using marginal message
passing in the latest versions.

940
00:52:04,354 --> 00:52:08,492
But again, we cover this is very similar
to variational message passing.

941
00:52:08,492 --> 00:52:09,693
It's just kind of a slight improvement,

942
00:52:10,927 --> 00:52:12,996
but so we're using

943
00:52:12,996 --> 00:52:15,866
the same sort of approach
to estimate parameters

944
00:52:16,600 --> 00:52:19,536
personally to estimate the parameters
that people are using,

945
00:52:20,270 --> 00:52:23,140
the parameters that are kind of,
you know, potentially kind of

946
00:52:23,406 --> 00:52:26,776
stored in their brain in some sense

947
00:52:27,144 --> 00:52:29,679
so so we're doing gradient descent

948
00:52:29,880 --> 00:52:32,816
on Variational for energy,
as I mentioned, and as I mentioned,

949
00:52:32,883 --> 00:52:36,786
need to specify prior means
and prior variances for each parameter

950
00:52:37,287 --> 00:52:40,390
and then you just move the prior values
in the direction

951
00:52:40,390 --> 00:52:43,727
of increasing action probabilities.

952
00:52:43,727 --> 00:52:47,063
But what you're doing
because it's a gradient descent

953
00:52:47,063 --> 00:52:50,767
on Variational for Energy is
you're not technically

954
00:52:51,067 --> 00:52:51,835
just trying

955
00:52:51,835 --> 00:52:55,238
to find the maximum likelihood value
like you're doing with like a grid search

956
00:52:55,739 --> 00:52:59,809
instead what you're trying to do
is you're trying to well,

957
00:52:59,809 --> 00:53:00,877
I should say that

958
00:53:00,877 --> 00:53:04,614
the Variational for energy, part of it
means that there's a complexity penalty

959
00:53:05,649 --> 00:53:06,917
and what that basically means is

960
00:53:06,917 --> 00:53:10,554
so if people remember from Variational
for Energy when we talked about it

961
00:53:10,554 --> 00:53:14,491
before, the simplest way or
kind of intuitive way to think about it

962
00:53:15,025 --> 00:53:17,761
is that it's just complexity
minus accuracy.

963
00:53:18,395 --> 00:53:18,962
Right?

964
00:53:18,962 --> 00:53:22,766
And what complexity means is
how much you have to change your beliefs.

965
00:53:24,334 --> 00:53:29,139
So if you start out with particular
prior values, then the farther

966
00:53:29,139 --> 00:53:33,510
you have to move those move
your beliefs from those prior values,

967
00:53:34,811 --> 00:53:37,013
the that's going to push

968
00:53:37,647 --> 00:53:40,083
variational for energy up,

969
00:53:40,584 --> 00:53:44,020
whereas at the same time
for Variational for Energy

970
00:53:44,020 --> 00:53:48,325
is going to go down
as the model predicts behavior better.

971
00:53:49,793 --> 00:53:51,328
So what it means is,

972
00:53:51,328 --> 00:53:54,831
for instance, you know,
if I start out with a prior value

973
00:53:54,831 --> 00:53:58,969
that say way down here, like around like,
I don't know, one in three,

974
00:53:59,536 --> 00:54:03,640
then it's going to have to move
from those prior values.

975
00:54:03,940 --> 00:54:09,379
A pretty long way before it gets to a set
of parameter values that fit well.

976
00:54:11,114 --> 00:54:12,916
Whereas say, if I started over

977
00:54:12,916 --> 00:54:15,819
here, it's
not going to have to move those as far.

978
00:54:17,287 --> 00:54:21,591
But if I were to do that,
then potentially instead of

979
00:54:22,092 --> 00:54:25,528
the posterior estimate
plus your parameter estimates

980
00:54:25,829 --> 00:54:28,832
actually settling on this thing
that has the maximum likelihood

981
00:54:29,165 --> 00:54:32,235
it might stop, say,
like around this one, right?

982
00:54:32,235 --> 00:54:34,838
A little lower than it or
something like that.

983
00:54:34,838 --> 00:54:38,541
Because that maximizes
that leads to high accuracy

984
00:54:38,541 --> 00:54:42,846
while also not having to move
the parameter values really, really far,

985
00:54:42,879 --> 00:54:45,915
not having to change beliefs too much
from what the

986
00:54:47,450 --> 00:54:49,586
informed prior belief was.

987
00:54:50,920 --> 00:54:53,189
So it's, you know, it's it's important,
right?

988
00:54:53,189 --> 00:54:54,291
To think that this assumes

989
00:54:54,291 --> 00:54:58,461
something that that the priors you have,
that you have them for a reason, right?

990
00:54:58,528 --> 00:55:01,464
That they're actually based on something
they're informing you

991
00:55:02,999 --> 00:55:05,969
so that so that is actually does
actually make sense

992
00:55:05,969 --> 00:55:08,672
not to move them too
far from prior values.

993
00:55:09,706 --> 00:55:11,941
And in practice,
the reason this is helpful

994
00:55:12,809 --> 00:55:17,147
is because one thing that often happens
when you're just doing maximum likelihood

995
00:55:18,181 --> 00:55:20,483
is that that maximum

996
00:55:20,483 --> 00:55:23,987
likelihood will be with respect
to your particular data set, right.

997
00:55:23,987 --> 00:55:27,691
Your particular set of parameter
or set of participants.

998
00:55:28,792 --> 00:55:31,661
But often if you choose
just the maximum likelihood value

999
00:55:32,062 --> 00:55:35,665
then that's kind of overfit
to just those participants

1000
00:55:36,099 --> 00:55:38,968
where if you were to say, apply
that exact same model

1001
00:55:39,002 --> 00:55:43,206
to a new set of participants,
it might not do as well

1002
00:55:43,773 --> 00:55:46,776
because it was fitting,
you know, specific things

1003
00:55:46,776 --> 00:55:49,512
that were not generalizable
about your data set in particular.

1004
00:55:50,647 --> 00:55:52,949
So by by,

1005
00:55:52,949 --> 00:55:56,886
by putting this kind of complexity
cost on it, it prevents overfitting,

1006
00:55:56,886 --> 00:56:01,358
which means that the predictions of that
model are more likely to generalize

1007
00:56:01,391 --> 00:56:04,928
to a new set of participants later,
so that it prevents overfitting,

1008
00:56:04,928 --> 00:56:08,732
which is a very common issue and just
standard frequentist statistics as well.

1009
00:56:12,168 --> 00:56:15,004
OK, so,
so that's so that's what you're doing.

1010
00:56:15,004 --> 00:56:17,407
A variational basis
is you're in this kind of complexity

1011
00:56:17,407 --> 00:56:20,610
minus accuracy thing where you're
preventing overfitting will also maximize

1012
00:56:21,111 --> 00:56:24,214
the accuracy of model predictions

1013
00:56:26,216 --> 00:56:29,052
OK, so then

1014
00:56:29,052 --> 00:56:31,888
like I mentioned, you need to do model
comparison to identify

1015
00:56:31,888 --> 00:56:34,758
what the best model is

1016
00:56:35,592 --> 00:56:38,228
now let's say.

1017
00:56:38,228 --> 00:56:42,332
So I just realized I should probably set
something in motion here

1018
00:56:43,900 --> 00:56:46,035
to see if I need to.

1019
00:56:46,035 --> 00:56:48,238
So when we actually go into the code
here in a minute,

1020
00:56:48,238 --> 00:56:52,175
one of these things takes a long time

1021
00:56:52,308 --> 00:56:53,009
let's say.

1022
00:56:53,009 --> 00:56:54,978
So I set it to store stuff.

1023
00:56:54,978 --> 00:56:57,013
I just want a triple check that
I shouldn't,

1024
00:56:58,047 --> 00:57:00,750
you know, set this thing

1025
00:57:01,885 --> 00:57:04,154
let's say.

1026
00:57:04,721 --> 00:57:07,590
Yeah, I about
I should double check this beforehand

1027
00:57:12,362 --> 00:57:15,064
yeah. So

1028
00:57:15,064 --> 00:57:15,965
cool though.

1029
00:57:15,965 --> 00:57:19,035
Really interesting.

1030
00:57:19,035 --> 00:57:21,938
And Christopher, you want to add anything
or maybe just a quick note?

1031
00:57:21,938 --> 00:57:23,440
Well, Ryan's figuring out like what is it

1032
00:57:23,440 --> 00:57:27,210
like to be learning these models
or what kind of skills do you wish

1033
00:57:27,210 --> 00:57:29,846
you had earlier
when you were learning the models

1034
00:57:31,314 --> 00:57:33,750
other than, of course, your own tutorial?

1035
00:57:33,750 --> 00:57:35,118
I mean,

1036
00:57:37,987 --> 00:57:39,055
I think everyone who did

1037
00:57:39,055 --> 00:57:42,792
undergrad psychology
is probably at some point in their I,

1038
00:57:42,892 --> 00:57:47,130
I did cognitive science as an undergrad,
but I took a lot of psychology classes.

1039
00:57:47,130 --> 00:57:48,431
I mean, take stuff psychology.

1040
00:57:48,431 --> 00:57:52,402
A lot of people read this Andy
Field textbook and he has a chapter on

1041
00:57:55,505 --> 00:57:56,306
some type of like

1042
00:57:56,306 --> 00:57:59,609
esoteric regression
and introductory sentences.

1043
00:57:59,609 --> 00:58:00,977
Like, I've never done this.

1044
00:58:00,977 --> 00:58:02,912
I don't see myself ever doing it,

1045
00:58:02,912 --> 00:58:06,082
but I wrote this chapter about it,
and if I ever need to do it,

1046
00:58:06,082 --> 00:58:08,251
I will be very impressed
by how much I seem to know.

1047
00:58:09,752 --> 00:58:10,420
So that may,

1048
00:58:10,420 --> 00:58:14,991
that probably will describe my experience
with this tutorial to a certain extent.

1049
00:58:16,826 --> 00:58:19,195
OK, so the results are real quick.

1050
00:58:19,195 --> 00:58:21,331
I'll just
I'm just going to jump to the code

1051
00:58:21,331 --> 00:58:23,466
and explain why
I should have started this. That

1052
00:58:24,501 --> 00:58:25,602
is. But

1053
00:58:26,102 --> 00:58:29,005
that so what if you set this thing to SIM
equals five,

1054
00:58:29,439 --> 00:58:33,243
then what it's going to do is it's going
to actually generate simulated behavior

1055
00:58:34,110 --> 00:58:36,880
for six hypothetical participants

1056
00:58:37,313 --> 00:58:39,983
where each participant
has a different combination

1057
00:58:39,983 --> 00:58:43,920
of parameter values that's generating
that simulated behavior.

1058
00:58:44,420 --> 00:58:47,423
And then what it's going to do
is it's going to

1059
00:58:48,258 --> 00:58:52,462
then apply the estimation algorithm
to the resulting simulated behavior

1060
00:58:53,596 --> 00:58:56,733
and it's
going to give you a set of results.

1061
00:58:57,834 --> 00:59:01,104
And then what it will do
is it's going to do a Bayesian model

1062
00:59:01,104 --> 00:59:04,908
comparison
on those to identify what the best model

1063
00:59:05,942 --> 00:59:09,779
is. And then I'm going to try to do this.

1064
00:59:11,281 --> 00:59:12,782
I'm going to try to set the

1065
00:59:12,782 --> 00:59:14,851
so I'll just say four or

1066
00:59:16,986 --> 00:59:21,090
for the purposes of, you know,
you actually

1067
00:59:21,090 --> 00:59:24,360
you guys are actually doing it
yourself at home.

1068
00:59:26,062 --> 00:59:29,365
I'm going to

1069
00:59:29,766 --> 00:59:31,935
I set this thing to 32 trials

1070
00:59:31,935 --> 00:59:35,672
for each simulate
for each set of simulated behavior.

1071
00:59:36,806 --> 00:59:39,542
But maybe if I set this to 16

1072
00:59:40,076 --> 00:59:42,645
then it will go faster.

1073
00:59:42,912 --> 00:59:44,314
Just to think about what's happening.

1074
00:59:44,314 --> 00:59:47,884
People looking through these equations
every time two matrices or two

1075
00:59:47,884 --> 00:59:50,653
numbers are getting multiplied
the computer has to do something.

1076
00:59:51,020 --> 00:59:53,990
So we're kind of nesting matrix
multiplications

1077
00:59:54,090 --> 00:59:55,758
inside of even bigger ones.

1078
00:59:55,758 --> 00:59:58,328
So if you want to time steps for two

1079
00:59:58,861 --> 01:00:02,131
larger time clicks for four models,
you know, for four participants,

1080
01:00:02,131 --> 01:00:05,501
it really starts to balloon rapidly,
especially when there's computationally

1081
01:00:05,501 --> 01:00:06,302
intensive steps.

1082
01:00:07,303 --> 01:00:07,704
Yeah.

1083
01:00:07,704 --> 01:00:08,471
So here just to

1084
01:00:08,471 --> 01:00:11,407
just to show you guys what's going
on, so I just started this thing

1085
01:00:11,874 --> 01:00:15,645
and if you look in the MATLAB window

1086
01:00:15,645 --> 01:00:18,881
here, it's calculating log likelihood.

1087
01:00:18,881 --> 01:00:20,850
So LX stands for log likelihood

1088
01:00:20,850 --> 01:00:23,853
over and over again under a particular
set of parameter values.

1089
01:00:24,187 --> 01:00:28,591
And in this case, it's -31
and it's trying to minimize that.

1090
01:00:28,591 --> 01:00:30,793
Or in this case, it's
moving it closer to zero.

1091
01:00:30,793 --> 01:00:33,863
So maximizing in a sense,
but bring it in closer to zero.

1092
01:00:34,263 --> 01:00:38,301
So now it move to a gradient descent
to a second set of parameter values

1093
01:00:39,235 --> 01:00:42,905
and now it's found that OK,
now the log likelihood is -22.

1094
01:00:42,905 --> 01:00:44,741
So we're even closer to zero.

1095
01:00:44,741 --> 01:00:48,011
And again, same thing now we're in -19
and it's going to keep going

1096
01:00:48,011 --> 01:00:50,546
until it settles on a stable value.

1097
01:00:50,546 --> 01:00:51,914
And in this graph

1098
01:00:53,116 --> 01:00:56,452
that will update every time,

1099
01:00:56,452 --> 01:00:58,254
which I'll show you here.

1100
01:00:58,254 --> 01:01:00,556
So this is just showing

1101
01:01:00,556 --> 01:01:02,759
ignore, I should say these.

1102
01:01:02,892 --> 01:01:05,862
So let me to explain as these routines
were originally designed

1103
01:01:05,862 --> 01:01:08,731
for DCM for dynamic causal
modeling with a primary.

1104
01:01:09,198 --> 01:01:13,503
So a lot of the bunch of these graphs
and also

1105
01:01:13,503 --> 01:01:17,140
the sorts of labels that they have
are don't really apply in this case.

1106
01:01:17,140 --> 01:01:19,442
They only apply to DCM.

1107
01:01:19,442 --> 01:01:22,378
So, you know,
so ignore all of the labels.

1108
01:01:22,378 --> 01:01:25,415
But the point here is, is that

1109
01:01:25,415 --> 01:01:28,718
each iteration as you go from left
to right, is a new estimate

1110
01:01:29,585 --> 01:01:32,522
of the log likelihood

1111
01:01:32,522 --> 01:01:34,791
for every

1112
01:01:34,791 --> 01:01:36,192
for the set of parameter values.

1113
01:01:36,192 --> 01:01:38,628
It's trying during gradient descent.

1114
01:01:40,196 --> 01:01:42,732
And so you'll see that after a while.

1115
01:01:42,732 --> 01:01:46,502
The thing is just going to kind of
play out, it'll converge onto a value.

1116
01:01:46,502 --> 01:01:51,107
So right now is it's like 17.35
and now it's like 17.16.

1117
01:01:51,107 --> 01:01:54,477
So the thing is kind of starting
to converge on a stable

1118
01:01:55,678 --> 01:01:56,679
minimum

1119
01:01:58,815 --> 01:02:00,616
log likelihood.

1120
01:02:01,284 --> 01:02:04,020
So now, you know, I found a site
that actually is still at 16.

1121
01:02:04,020 --> 01:02:06,856
So the thing is still going for a bit
to converge

1122
01:02:07,356 --> 01:02:10,326
and down here
these are the posterior deviations.

1123
01:02:10,626 --> 01:02:15,098
I'm going again, ignore the ignore
a lot of the units here,

1124
01:02:15,098 --> 01:02:18,935
but the way that you can read
this is just that zero here

1125
01:02:18,935 --> 01:02:21,604
corresponds to the prior values
that you set.

1126
01:02:22,705 --> 01:02:26,809
And if it's going
if the bar here is going down, then

1127
01:02:26,809 --> 01:02:32,482
that means that the posterior parameter
estimate is, is lower at this point.

1128
01:02:32,482 --> 01:02:35,852
It's gone down from the prior value
and this kind of red

1129
01:02:35,852 --> 01:02:38,221
pink thing around it,
that's the posterior variance.

1130
01:02:39,756 --> 01:02:41,324
So in this case and parameter

1131
01:02:41,324 --> 01:02:45,161
one here is the action precision
and parameter

1132
01:02:45,161 --> 01:02:49,599
two is the reward area for risk seeking.

1133
01:02:49,932 --> 01:02:52,335
I think I can double check
whether those are backwards or not.

1134
01:02:53,236 --> 01:02:55,071
But which part of those are.

1135
01:02:55,071 --> 01:02:57,540
But this is just saying that
whatever the first parameter is,

1136
01:02:59,041 --> 01:03:00,443
the, the posterior

1137
01:03:00,443 --> 01:03:04,380
mean estimate here is you know,
whatever that is that

1138
01:03:04,380 --> 01:03:08,551
actually corresponds to the real units
of the M of the parameter.

1139
01:03:08,918 --> 01:03:12,421
But it's not very confident
in that posterior mean estimate.

1140
01:03:12,789 --> 01:03:15,091
Whereas here the second parameter,

1141
01:03:16,359 --> 01:03:19,128
it's also this negative posterior
at the moment,

1142
01:03:19,428 --> 01:03:21,264
but it's very,
very confident in that post.

1143
01:03:21,264 --> 01:03:22,632
Your estimate

1144
01:03:24,600 --> 01:03:25,868
so so that's what that means.

1145
01:03:25,868 --> 01:03:28,738
And these will update
with each iteration.

1146
01:03:30,139 --> 01:03:33,176
But so now you can see that
actually the thing kept exploring

1147
01:03:33,543 --> 01:03:36,479
and now it's actually found

1148
01:03:36,479 --> 01:03:38,881
a set of parameter values that,

1149
01:03:39,215 --> 01:03:41,851
you know, continues
to actually explain the behavior

1150
01:03:41,884 --> 01:03:44,086
the simulated behavior
quite a bit better. Right?

1151
01:03:44,086 --> 01:03:46,122
So now it's at like -13.

1152
01:03:46,122 --> 01:03:48,357
So you can see this
ad almost kind of converge for a bit,

1153
01:03:48,357 --> 01:03:50,426
but now it's actually
kind of going back up

1154
01:03:52,428 --> 01:03:55,531
so eventually, eventually
it will converge, but it's just doing

1155
01:03:55,531 --> 01:04:00,469
really, really well at finding values
that explain behavior well.

1156
01:04:01,537 --> 01:04:04,807
One thing I should point out, though,
is that the actual values of these

1157
01:04:04,807 --> 01:04:07,109
the absolute value of these
are not really informative

1158
01:04:07,109 --> 01:04:09,846
because they're
they're they're basically the sums

1159
01:04:10,279 --> 01:04:13,549
of the action
probabilities for each trial.

1160
01:04:13,883 --> 01:04:16,686
So these numbers will be bigger
if the task has more trials.

1161
01:04:17,653 --> 01:04:20,690
So in and of themselves, it's only
the relative values that are meaningful.

1162
01:04:21,958 --> 01:04:25,928
This reminds me, I guess it reminds me
a lot of Bayesian methods

1163
01:04:26,028 --> 01:04:27,663
in follow genetics

1164
01:04:27,663 --> 01:04:31,267
where it's like, what is the likelihood
of this phylogenetic tree?

1165
01:04:32,401 --> 01:04:36,038
It's given some number by a program,
which sounds weird to think about

1166
01:04:36,038 --> 01:04:38,641
the state space of all the possible trees
or something like that.

1167
01:04:38,908 --> 01:04:42,178
But it turns out by doing this
kind of a gradient descent,

1168
01:04:42,478 --> 01:04:47,817
searching through all the possible trees,
you actually do converge on a tree

1169
01:04:47,817 --> 01:04:50,820
that is generative of the kinds of data
that are observed

1170
01:04:51,187 --> 01:04:53,489
and so it's just really interesting
to see how this is working,

1171
01:04:53,489 --> 01:04:55,825
and it's fun to watch
the number drop down too.

1172
01:04:57,693 --> 01:04:58,628
So, so

1173
01:04:58,628 --> 01:05:01,564
now so in this case, it converged
for the first person

1174
01:05:02,732 --> 01:05:05,167
and these were the posterior deviations.

1175
01:05:05,167 --> 01:05:08,037
And then here's the simulated behavior

1176
01:05:08,037 --> 01:05:10,773
of the participant
under those parameters.

1177
01:05:11,307 --> 01:05:16,345
So you can see that the parameters do
the behavior really well, right?

1178
01:05:16,345 --> 01:05:18,281
The probabilities are pretty high

1179
01:05:18,281 --> 01:05:21,417
under those parameters
for each for every action.

1180
01:05:21,851 --> 01:05:24,453
There are some little exceptions,
but but it does pretty well

1181
01:05:25,955 --> 01:05:26,589
right now.

1182
01:05:26,589 --> 01:05:29,392
It's just the it's
just moving on to the next person.

1183
01:05:29,392 --> 01:05:30,226
Sorry. Well.

1184
01:05:30,426 --> 01:05:33,462
It might just be helpful to describe
what the blue dots are this year.

1185
01:05:33,562 --> 01:05:34,430
Yeah, sorry.

1186
01:05:34,430 --> 01:05:37,433
I guess I'm assuming people
have watched the sessions.

1187
01:05:37,733 --> 01:05:40,803
So blue corresponds
to the actual chosen action

1188
01:05:42,204 --> 01:05:46,042
on the
at the first action for each participant.

1189
01:05:47,076 --> 01:05:51,714
So basically, this is saying
and so black means probability one.

1190
01:05:51,948 --> 01:05:54,450
And as it goes toward white,
that means probability zero.

1191
01:05:54,984 --> 01:05:58,921
So this is just saying basically 100%
probability under the model

1192
01:05:59,055 --> 01:06:02,158
that the agent would choose the hint
and the blue dot says

1193
01:06:02,158 --> 01:06:03,326
that's what they actually trials

1194
01:06:04,493 --> 01:06:05,561
and so on and so forth.

1195
01:06:05,561 --> 01:06:09,565
So any time that there's a light gray
you know,

1196
01:06:09,565 --> 01:06:11,834
that's on the part where the blue dot is,
that means the model

1197
01:06:11,834 --> 01:06:14,437
didn't really do that
well at predicting that behavior.

1198
01:06:16,072 --> 01:06:17,606
But you can see in this case

1199
01:06:17,606 --> 01:06:21,744
most it's pretty dark around
most of these blue dots.

1200
01:06:21,744 --> 01:06:24,113
So it does pretty good is the point.

1201
01:06:25,748 --> 01:06:28,017
So now like I said,
this is just going to iterate around

1202
01:06:28,017 --> 01:06:33,422
for the six agents that I mentioned
and it's just going to compare

1203
01:06:33,789 --> 01:06:38,728
and then it's going to compare the three,
the three that did have a learning rate

1204
01:06:38,728 --> 01:06:42,064
and the three that didn't have a learning
rate in the model is what it will do.

1205
01:06:43,632 --> 01:06:46,268
And so just to kind of summarize
what you said so far,

1206
01:06:46,268 --> 01:06:48,637
so the steps would be
something like you would actually

1207
01:06:48,637 --> 01:06:52,641
get your empirical task right
and think about how the sub the

1208
01:06:53,509 --> 01:06:56,712
the actions that the subject is actually
got all the participants actually going

1209
01:06:56,712 --> 01:07:00,783
to make relate to what the model is going
to make all the actions available.

1210
01:07:00,783 --> 01:07:04,520
The model, you come up with some mapping
and then you would then

1211
01:07:04,987 --> 01:07:10,226
presumably in this just translate them
in some way and plug those into your

1212
01:07:10,226 --> 01:07:14,697
you mdpd out you, which is the actions
participant chose and mdpd

1213
01:07:15,164 --> 01:07:18,501
which is the observations
that they actually saw.

1214
01:07:19,268 --> 01:07:19,769
Yeah.

1215
01:07:19,835 --> 01:07:22,738
And then you would
plug into the algorithm essentially. Yep.

1216
01:07:23,205 --> 01:07:26,509
You plug it into the algorithm and,
and then adjust

1217
01:07:27,009 --> 01:07:31,347
the algorithm just repeatedly computes
the sum of the log likelihoods

1218
01:07:31,347 --> 01:07:32,181
for each trial

1219
01:07:33,282 --> 01:07:35,751
and then and then tries to find a minimum
of that some.

1220
01:07:36,385 --> 01:07:41,057
OK and so in terms of
this is a something I've wondered about,

1221
01:07:41,791 --> 01:07:45,795
how do you choose what the best
trials are, what the best surprise

1222
01:07:45,928 --> 01:07:49,098
is, OK, just to kind of in silicone

1223
01:07:50,866 --> 01:07:52,234
simulate a bunch of things and just

1224
01:07:52,234 --> 01:07:54,303
say, hey, this, this seems reasonable.

1225
01:07:56,072 --> 01:07:57,706
In order and a lot of cases. Yes.

1226
01:07:57,706 --> 01:07:59,842
I mean,
so there's a couple of things to do.

1227
01:07:59,842 --> 01:08:03,345
One is you can
you can do the kind of model

1228
01:08:03,412 --> 01:08:05,581
after the recoverability stuff

1229
01:08:07,016 --> 01:08:10,086
you know, beforehand
and try to find a set of parameter

1230
01:08:10,086 --> 01:08:13,322
values, a set of prior values
for which the

1231
01:08:14,056 --> 01:08:16,492
the the parameter
estimates are recoverable.

1232
01:08:17,059 --> 01:08:17,660
Right.

1233
01:08:17,760 --> 01:08:20,396
So if you set one set of priors,
then maybe the thing does

1234
01:08:20,396 --> 01:08:21,464
get stuck in a local minima.

1235
01:08:21,464 --> 01:08:25,768
But if you have another set of priors,
then the generative parameters

1236
01:08:26,569 --> 01:08:29,538
actually do end up matching
the estimated parameters really well.

1237
01:08:29,939 --> 01:08:30,072
Yeah.

1238
01:08:31,474 --> 01:08:33,375
So, so there's
there's a couple of different things.

1239
01:08:33,375 --> 01:08:34,844
So one is, yeah,

1240
01:08:34,844 --> 01:08:38,647
do some of the simulation recoverability
stuff ahead of time to find good priors.

1241
01:08:39,115 --> 01:08:42,318
And another thing is, you know,
if you just,

1242
01:08:42,618 --> 01:08:45,988
you know, estimate participant behavior
and you start to see

1243
01:08:46,455 --> 01:08:50,192
that the posterior estimates tend
to be really far away from the priors,

1244
01:08:50,192 --> 01:08:51,327
you're setting

1245
01:08:51,627 --> 01:08:53,162
that that's kind of an indication
that you're probably

1246
01:08:53,162 --> 01:08:54,230
not setting very good priors.

1247
01:08:54,230 --> 01:08:54,930
So then you might like

1248
01:08:54,930 --> 01:08:58,734
try setting new priors that look closer
to where everybody's kind of moving.

1249
01:09:00,069 --> 01:09:00,302
Yeah.

1250
01:09:00,302 --> 01:09:03,305
So we do have we do have a footnote
about this in the paper from memory,

1251
01:09:03,839 --> 01:09:06,642
but be good to kind of make
that explicit.

1252
01:09:06,842 --> 01:09:11,113
Another way that I've seen that
in the field of evolutionary biology is

1253
01:09:11,347 --> 01:09:15,784
if you have wildly disparate priors,
like so a fallacy

1254
01:09:15,784 --> 01:09:19,221
is that the uniform
or the flat prior is like unbiased.

1255
01:09:19,622 --> 01:09:22,258
There's so much to say about that
I'm sure Ryan knows well.

1256
01:09:22,258 --> 01:09:24,894
But like if you have one prior
that stacked up against zero

1257
01:09:25,261 --> 01:09:27,429
and another prior
that stacked up against one,

1258
01:09:27,997 --> 01:09:30,966
and then they both converge
like from kind of multiple sides.

1259
01:09:30,966 --> 01:09:35,804
That's a simple example, but two
different families of priors and models

1260
01:09:35,804 --> 01:09:39,074
that are very pared down, ranging to ones

1261
01:09:39,074 --> 01:09:42,178
that have very complex error models.

1262
01:09:42,478 --> 01:09:46,582
If a lot of different layers
of complexity of the model and densities

1263
01:09:46,582 --> 01:09:50,419
that start stacked up versus one
end versus another, then of course

1264
01:09:50,419 --> 01:09:51,520
that's a difficult thing to manage.

1265
01:09:51,520 --> 01:09:54,657
But that at least means
that given the empirical data you have

1266
01:09:54,657 --> 01:09:57,893
and the task that you're modeling,
you have a really predictive model.

1267
01:09:58,194 --> 01:10:00,829
So again, we're not realists,
we're not actually getting at the truth

1268
01:10:00,829 --> 01:10:04,600
with these recursive and iterative
and multi perspectively models.

1269
01:10:04,900 --> 01:10:09,138
We're just fitting more and more of the
variance explained in our empirical data

1270
01:10:10,239 --> 01:10:10,906
yeah.

1271
01:10:11,006 --> 01:10:11,540
Yeah.

1272
01:10:11,540 --> 01:10:13,742
So just just
to kind of give you guys another example.

1273
01:10:13,742 --> 01:10:16,845
So you can see now for this
other set of parameter estimates,

1274
01:10:17,213 --> 01:10:19,982
you know, convergence took way
less time right?

1275
01:10:19,982 --> 01:10:23,452
It just took, you know, seven iterations
and it converges really quickly.

1276
01:10:23,852 --> 01:10:27,856
And one reason to see why is, is that
for this one, it doesn't have to move

1277
01:10:27,856 --> 01:10:31,360
values very far from priors
because this was an agent

1278
01:10:31,794 --> 01:10:35,231
whose behavior was generated
by parameters very close to priors.

1279
01:10:35,264 --> 01:10:38,400
One other point to those,
even if it looks flat for ten time steps,

1280
01:10:38,801 --> 01:10:41,870
it could still be trapped,
which is why things have to be seeded

1281
01:10:41,870 --> 01:10:43,772
and have really good randomness,

1282
01:10:43,772 --> 01:10:47,343
because there's no hard and fast rule
for when you terminate.

1283
01:10:47,610 --> 01:10:48,277
So, for example,

1284
01:10:48,277 --> 01:10:52,381
in a lot of the evolutionary simulations,
we would do you discard the first

1285
01:10:52,681 --> 01:10:57,686
like 10,000 or more timestamps,
like burn in, you just discard them

1286
01:10:57,686 --> 01:11:00,689
because you think that actually it's
too much reflecting your prior estimates.

1287
01:11:00,923 --> 01:11:02,224
And then even if it looks like it's

1288
01:11:02,224 --> 01:11:05,494
converging or as one of my professors
called it, a fuzzy caterpillar

1289
01:11:05,794 --> 01:11:07,830
because it's
kind of like the model of sampling

1290
01:11:08,397 --> 01:11:10,699
from the fullest possible
range of variables.

1291
01:11:11,000 --> 01:11:12,835
And it was still coming back home.

1292
01:11:12,835 --> 01:11:14,370
That's the fuzzy caterpillar.

1293
01:11:14,370 --> 01:11:16,405
But even then
it could look like a fuzzy caterpillar

1294
01:11:16,405 --> 01:11:17,673
for like a lot of time steps

1295
01:11:17,673 --> 01:11:21,110
and then just totally hit on a new
combination break into a new realm.

1296
01:11:21,644 --> 01:11:23,779
So it's really hard. And it just.

1297
01:11:24,680 --> 01:11:27,716
So, just so people know
that's actually not true in this case.

1298
01:11:27,716 --> 01:11:32,354
So a variational basis
is deterministic in the sense that you

1299
01:11:32,721 --> 01:11:35,557
you don't do this kind of,
you know, burden.

1300
01:11:35,557 --> 01:11:38,427
You don't write a sorry variability.

1301
01:11:38,427 --> 01:11:39,561
You just deterministic.

1302
01:11:39,561 --> 01:11:41,030
Like, if I ran this over and over again,

1303
01:11:41,030 --> 01:11:43,465
it would give me the exact same
parameter estimate each time.

1304
01:11:44,600 --> 01:11:47,069
So there is there is actually no variable

1305
01:11:47,303 --> 01:11:49,672
I mean, the kind of thing you're
talking about is more like Monte Carlo.

1306
01:11:50,072 --> 01:11:51,907
And it's going to say sort of approaches.

1307
01:11:51,907 --> 01:11:52,541
Yeah, sorry.

1308
01:11:52,541 --> 01:11:55,277
I didn't mean to say that
there was a burden.

1309
01:11:55,277 --> 01:11:56,078
I agree.

1310
01:11:56,078 --> 01:11:57,146
That was just.

1311
01:11:57,146 --> 01:11:59,315
Yeah, little analogy,
but thanks for clarifying.

1312
01:12:00,215 --> 01:12:03,752
So one advantage of Monte
Carlo sampling methods is that you over

1313
01:12:04,353 --> 01:12:08,691
given infinite time, you're guaranteed
to margin to approach the true posterior

1314
01:12:08,691 --> 01:12:13,295
or to obtain the true posterior it's
also extremely computationally expensive.

1315
01:12:14,730 --> 01:12:17,232
Variational Bayes is really quick.

1316
01:12:17,232 --> 01:12:17,733
Yeah.

1317
01:12:18,033 --> 01:12:20,235
Like you can run this stuff
on your laptop.

1318
01:12:20,235 --> 01:12:22,705
So the Monte Carlo is based
upon sampling.

1319
01:12:22,738 --> 01:12:25,607
That was the different domain
that I was referencing there.

1320
01:12:25,607 --> 01:12:27,910
You have to sample in cases
where you don't know

1321
01:12:27,910 --> 01:12:29,912
some of these distributions
don't have them defined.

1322
01:12:29,912 --> 01:12:34,283
So perfectly, but when you have access
to this level of specifying,

1323
01:12:34,516 --> 01:12:35,184
then there's

1324
01:12:35,184 --> 01:12:36,985
a whole new range of techniques,
which is why

1325
01:12:36,985 --> 01:12:39,321
it looks more like matrix multiplication.

1326
01:12:39,321 --> 01:12:43,792
And this sort of like convergence
to the variational free energy estimate

1327
01:12:44,093 --> 01:12:47,830
rather than just sampling endlessly
from a landscape that's unknown,

1328
01:12:48,163 --> 01:12:49,998
you know, anything else.
But yeah, thanks for that. Sorry.

1329
01:12:51,133 --> 01:12:52,501
So, so just take I mean,

1330
01:12:52,501 --> 01:12:55,771
so again, just to give you guys a sense,
so in this so this kind of participant,

1331
01:12:56,138 --> 01:13:00,175
you can see that it's pretty kind of
the distributions are a lot less precise.

1332
01:13:00,609 --> 01:13:04,113
And this is a person who has a much lower
action precision value.

1333
01:13:05,013 --> 01:13:08,984
So these were generated by a lower action
precision value agent

1334
01:13:09,385 --> 01:13:12,855
and the model is doing a pretty good job
just finding a low action

1335
01:13:12,855 --> 01:13:17,059
precision value that kind of spreads
the distributions flat enough around it

1336
01:13:17,059 --> 01:13:20,562
that it captures it provides
decent evidence for each action.

1337
01:13:22,164 --> 01:13:25,768
And so anyway, so just,
just to again, to,

1338
01:13:26,268 --> 01:13:28,537
to give you guys an intuition
for what's going on

1339
01:13:30,272 --> 01:13:32,341
but so once this is done,

1340
01:13:32,841 --> 01:13:36,178
then what will happen is we'll have these

1341
01:13:37,146 --> 01:13:40,082
the free energies of the winning model

1342
01:13:40,082 --> 01:13:43,051
for each person,
for each of the two models,

1343
01:13:44,186 --> 01:13:46,655
the one with
and the one without learning rate.

1344
01:13:46,655 --> 01:13:49,958
And so we want to do is
we want to do Bayesian model comparison,

1345
01:13:51,093 --> 01:13:53,862
which is where you're going to compare
the free energies

1346
01:13:53,862 --> 01:13:57,132
for each model, for each participant
to find the model with the lowest

1347
01:13:57,132 --> 01:14:00,402
free energy across participants

1348
01:14:00,402 --> 01:14:02,671
and the winning model.

1349
01:14:02,671 --> 01:14:06,141
So the the little spin function
that we include here,

1350
01:14:06,508 --> 01:14:09,645
it'll spit out several things
but the one that you want to focus on

1351
01:14:09,978 --> 01:14:12,981
just to keep things simple is

1352
01:14:12,981 --> 01:14:16,585
the one that has the highest what's
called the protected exceeds probability

1353
01:14:17,586 --> 01:14:21,390
and this is just the probability
that each model is the most likely model

1354
01:14:21,390 --> 01:14:24,393
across all subjects
while taking into account the null

1355
01:14:24,393 --> 01:14:28,063
possibility, the differences in model
evidence are did a chance.

1356
01:14:28,063 --> 01:14:32,434
So so it's like I said, it's
just it's just which is the best model

1357
01:14:33,735 --> 01:14:35,070
when taking into account

1358
01:14:35,070 --> 01:14:37,773
the null model as a possibility.

1359
01:14:39,208 --> 01:14:40,142
And I'll

1360
01:14:41,343 --> 01:14:42,778
show you that

1361
01:14:42,778 --> 01:14:45,380
in a second, let's say, is this thing

1362
01:14:45,380 --> 01:14:47,416
that's still going it's.

1363
01:14:48,851 --> 01:14:50,986
Yeah, OK, so on.

1364
01:14:50,986 --> 01:14:51,954
Hopefully it'll be done soon.

1365
01:14:51,954 --> 01:14:54,122
But so I'll keep
I'll keep moving through here

1366
01:14:54,122 --> 01:14:56,325
and then we can return to this once
it's done

1367
01:14:56,325 --> 01:14:58,260
it's actually gone pretty fast
since I made it.

1368
01:14:58,260 --> 01:14:59,928
So a few trials,

1369
01:15:00,662 --> 01:15:03,599
but so now so that's
what we're doing here.

1370
01:15:04,867 --> 01:15:07,636
And so now,

1371
01:15:07,636 --> 01:15:10,172
you know, we've
kind of already touched on this a bit,

1372
01:15:10,172 --> 01:15:14,810
but so now is the point
where we would confirm

1373
01:15:14,810 --> 01:15:19,214
that the best model is identifiable
or that the parameters are recoverable

1374
01:15:20,082 --> 01:15:21,650
and this is already mentioned this
a little bit.

1375
01:15:21,650 --> 01:15:23,151
But that, you know, it's,

1376
01:15:23,151 --> 01:15:25,921
it's clear that not all models
are necessarily going to have unique

1377
01:15:25,921 --> 01:15:27,689
parameter solutions, right?

1378
01:15:27,689 --> 01:15:29,758
So if you have a landscape like this,

1379
01:15:29,758 --> 01:15:32,494
you might start out priors
at very similar places

1380
01:15:33,061 --> 01:15:36,164
and gradient
descent would lead you to minima

1381
01:15:36,265 --> 01:15:40,002
different minima, you know, different
combinations of parameter values.

1382
01:15:40,002 --> 01:15:43,772
That are equally good
at reproducing a participant's behavior.

1383
01:15:45,908 --> 01:15:48,744
So so you always have to show

1384
01:15:49,278 --> 01:15:52,481
that whatever model you're using
and the priors that you're using

1385
01:15:53,515 --> 01:15:57,052
will give you the same parameters that

1386
01:15:58,053 --> 01:16:00,155
you fit in to generate

1387
01:16:00,155 --> 01:16:02,024
the data to begin with.

1388
01:16:04,026 --> 01:16:08,997
And so here again, we talked about this
a little bit, but step one is

1389
01:16:09,498 --> 01:16:11,166
you would specify multiple

1390
01:16:11,166 --> 01:16:13,502
sets of generative parameter values
which is what we're doing.

1391
01:16:15,037 --> 01:16:18,840
And this is important
as you should select values

1392
01:16:19,308 --> 01:16:23,812
that are the same or similar
to the actual parameter combinations

1393
01:16:24,212 --> 01:16:26,982
that you got in your
in your true participants,

1394
01:16:27,983 --> 01:16:30,953
because it can be the case that parameter
estimates are totally recoverable

1395
01:16:31,620 --> 01:16:33,956
for a certain parameter combinations,

1396
01:16:33,956 --> 01:16:36,925
but are not recoverable
for other parameter combinations.

1397
01:16:36,925 --> 01:16:40,128
So you care about the ones you're
actually getting for your participants.

1398
01:16:43,031 --> 01:16:45,901
So then you want to simulate behavior.

1399
01:16:46,168 --> 01:16:49,104
So generate simulated behavior
using each of those parameter

1400
01:16:49,104 --> 01:16:53,008
value combinations, run
that simulated behavior

1401
01:16:53,008 --> 01:16:56,111
through the estimation routine
just like you would for real data.

1402
01:16:56,712 --> 01:16:59,147
And then check
whether the generative parameters

1403
01:16:59,147 --> 01:17:02,751
and the estimated parameters
are highly correlated

1404
01:17:02,751 --> 01:17:06,622
so when I run this in advance,

1405
01:17:07,556 --> 01:17:11,627
you know, so without having to run it in
real time, like I'm doing right now,

1406
01:17:12,060 --> 01:17:14,863
then for this particular case
and bear in mind

1407
01:17:14,863 --> 01:17:18,900
this is one I'm using 32 trials,
not like the 16 or whatever I put in now

1408
01:17:19,735 --> 01:17:22,471
just to make things go faster

1409
01:17:22,471 --> 01:17:25,774
this is what I get for it,
for Alpha, for action, precision,

1410
01:17:25,774 --> 01:17:27,476
for the two parameter model.

1411
01:17:27,476 --> 01:17:32,414
So you can see even with only six people,
the correlation between the generative

1412
01:17:33,348 --> 01:17:37,319
action precision and the estimated
extra precision is pretty good. .81.

1413
01:17:37,319 --> 01:17:40,689
So even with six people,
right, it's significant

1414
01:17:43,925 --> 01:17:46,328
whereas for

1415
01:17:48,397 --> 01:17:52,200
I only have well anyway, I have,
I have a bunch of them.

1416
01:17:52,234 --> 01:17:55,103
I can, I can, I can pull
I can probably pull them up

1417
01:17:56,672 --> 01:17:57,472
let's see.

1418
01:17:57,472 --> 01:17:59,474
That's for a different thing.

1419
01:18:02,944 --> 01:18:06,181
Oh, that was very true.

1420
01:18:06,581 --> 01:18:07,916
Interesting.

1421
01:18:08,417 --> 01:18:09,251
Yes. Sorry.

1422
01:18:09,251 --> 01:18:11,353
I'm just trying to find

1423
01:18:11,920 --> 01:18:15,090
trying to find the figures

1424
01:18:15,090 --> 01:18:18,660
that I have probably here

1425
01:18:22,998 --> 01:18:23,532
well,

1426
01:18:23,532 --> 01:18:26,368
no, OK, it's not positive
work with them actually.

1427
01:18:26,868 --> 01:18:30,338
But if I can't find them here, then

1428
01:18:31,573 --> 01:18:34,876
it will, it will spit them out.

1429
01:18:34,876 --> 01:18:39,314
But, but point by point being, these are

1430
01:18:40,582 --> 01:18:43,285
in this case, even with the six values,

1431
01:18:43,285 --> 01:18:46,621
all of the parameters
tend to be really good.

1432
01:18:46,988 --> 01:18:47,222
Right.

1433
01:18:47,222 --> 01:18:49,291
In terms of recoverability, the,
you know,

1434
01:18:49,291 --> 01:18:52,928
the correlations between generative
and estimated parameters tend to be know

1435
01:18:53,061 --> 01:18:57,733
between point seven and 1.7 and point
nine something or other.

1436
01:18:58,667 --> 01:19:00,969
So there they're, they're good.

1437
01:19:00,969 --> 01:19:03,605
And so then so then finally,

1438
01:19:04,406 --> 01:19:08,076
the last thing that we want to do is once
we have

1439
01:19:08,610 --> 01:19:12,781
parameter estimates for each person
in a winning model that is recoverable,

1440
01:19:14,015 --> 01:19:16,051
then we can take those values

1441
01:19:16,051 --> 01:19:19,154
and we can put those parameter,
we can use those parameters

1442
01:19:19,921 --> 01:19:23,558
as individual difference measures
between subjects, you know.

1443
01:19:23,658 --> 01:19:26,461
And at that point, there's
a number of things that you can do.

1444
01:19:26,595 --> 01:19:31,500
So, you know, the kind of simple thing,
you know, if you if you want to kind of

1445
01:19:31,500 --> 01:19:34,569
fall back on, on frequentist statistics

1446
01:19:35,437 --> 01:19:37,739
is, you know, you can do standard tests.

1447
01:19:37,739 --> 01:19:39,808
ANOVA is correlations, regressions,
et cetera.

1448
01:19:41,309 --> 01:19:44,813
And then, you know,
I mean, you know, we've done that before.

1449
01:19:45,280 --> 01:19:48,817
It's fine in some cases
if you want to kind of stick

1450
01:19:49,284 --> 01:19:51,186
with the more kind of general Bayesian

1451
01:19:51,186 --> 01:19:54,556
theme of active inference,
then you can also do things like,

1452
01:19:55,557 --> 01:19:58,794
you know, do things
more like base factor analyzes

1453
01:19:59,795 --> 01:20:01,696
and you know,
both of these are often kind of used

1454
01:20:03,031 --> 01:20:05,967
or even used together.

1455
01:20:06,334 --> 01:20:08,970
And just to give you a couple examples,

1456
01:20:09,137 --> 01:20:12,474
I'm just going to triple check
that this thing is not done yet.

1457
01:20:12,674 --> 01:20:13,475
Still not done.

1458
01:20:13,475 --> 01:20:14,009
Just one note.

1459
01:20:14,009 --> 01:20:17,546
There's the SBM textbook
has many points of contact

1460
01:20:17,546 --> 01:20:21,516
between parametric and like standard

1461
01:20:21,783 --> 01:20:27,022
very classical statistical approaches
and then very Bayesian approaches

1462
01:20:27,022 --> 01:20:30,592
and mixed methods and it will switch out
or show it both ways.

1463
01:20:30,859 --> 01:20:33,595
So it really is pretty interesting
how it comes together here.

1464
01:20:35,430 --> 01:20:36,898
So so to kind of show

1465
01:20:36,898 --> 01:20:39,501
you guys a couple of examples
of how you would use

1466
01:20:39,968 --> 01:20:42,871
these kind of, you know, use parameters
at the group level.

1467
01:20:43,438 --> 01:20:47,242
And this is just I'll give you
a couple examples from from our papers

1468
01:20:48,210 --> 01:20:51,413
so in this in this one in Journal of
Psychiatry and Neuroscience,

1469
01:20:52,380 --> 01:20:53,582
what we did is we had

1470
01:20:53,582 --> 01:20:56,685
this simple kind of approach,
avoidance, conflict task, where

1471
01:20:57,152 --> 01:21:00,355
more or less the participant
had to kind of choose to move

1472
01:21:00,355 --> 01:21:04,960
this little avatar guy closer, farther
from one of these two ends

1473
01:21:05,093 --> 01:21:08,697
of this little kind of run away thing.

1474
01:21:08,730 --> 01:21:10,432
And they knew that

1475
01:21:10,732 --> 01:21:13,568
the closer they were to one side,
the higher the probability was that

1476
01:21:13,568 --> 01:21:17,005
they would get an outcome associated
with symbols on the left side.

1477
01:21:17,672 --> 01:21:18,306
And same goes

1478
01:21:18,306 --> 01:21:19,908
the closer are to the right,
the higher probability

1479
01:21:19,908 --> 01:21:22,577
of getting the outcomes
associated with the right side.

1480
01:21:22,577 --> 01:21:26,581
And here, rain cloud means
they heard like a really aversive sound

1481
01:21:26,581 --> 01:21:28,617
and saw like a really aversive picture.

1482
01:21:28,617 --> 01:21:31,987
You know, like it's like hearing girl
screaming and seeing a picture of her

1483
01:21:31,987 --> 01:21:35,657
being like pulled into a van,
you know, like really negative stuff.

1484
01:21:37,158 --> 01:21:39,661
And whereas
a something here and you kind of saw

1485
01:21:39,661 --> 01:21:41,897
this kind of like neutral,
maybe slightly happy thing

1486
01:21:43,565 --> 01:21:46,835
and you had this kind of red,
this kind of bar thing on the side.

1487
01:21:46,835 --> 01:21:51,139
And the more filled the red bar was,
the more points they would win.

1488
01:21:52,607 --> 01:21:53,942
So you have kind of clear cases, right?

1489
01:21:53,942 --> 01:21:56,011
Where it's
just if it's just rain cloud versus sun,

1490
01:21:56,144 --> 01:21:57,812
you should just go to the right.

1491
01:21:57,812 --> 01:22:01,149
If it's just sun and sun
plus some reward,

1492
01:22:01,283 --> 01:22:03,151
you should want to go to the right.

1493
01:22:03,151 --> 01:22:07,022
And then you have these conflict cases
where it's negative stuff.

1494
01:22:07,155 --> 01:22:10,525
Plus you get some reward negative stuff,
but you get it, plus you get even more

1495
01:22:10,525 --> 01:22:12,961
reward and negative stuff
and even more than that.

1496
01:22:14,562 --> 01:22:16,831
And so
and so that's how the task is structured.

1497
01:22:17,399 --> 01:22:21,169
And so you can make
a pretty simple model of this

1498
01:22:21,670 --> 01:22:25,040
where one state factor
is beliefs about the trial type.

1499
01:22:25,173 --> 01:22:26,174
Right. Whether it's

1500
01:22:27,309 --> 01:22:29,210
this kind of trial, this kind of trial,

1501
01:22:29,210 --> 01:22:33,114
this kind of trial, this control
or that kind of trial

1502
01:22:33,114 --> 01:22:34,449
and then you can have a state factor

1503
01:22:34,449 --> 01:22:38,253
corresponding to beliefs
about the runaway position, right?

1504
01:22:38,253 --> 01:22:41,423
So beliefs
about whether the avatar is in position

1505
01:22:41,423 --> 01:22:43,692
one, two, three, or four
or five et cetera.

1506
01:22:43,692 --> 01:22:44,526
That's it.

1507
01:22:44,759 --> 01:22:49,831
And then you just have you set up
likelihoods that generate the probability

1508
01:22:50,332 --> 01:22:53,301
of of each position

1509
01:22:53,702 --> 01:22:57,739
generating what sorts of outcomes
and what sorts of runaway

1510
01:22:57,739 --> 01:23:02,010
positions given beliefs about trial type
testimony here.

1511
01:23:02,010 --> 01:23:02,277
Right.

1512
01:23:02,277 --> 01:23:05,613
So you have it phrased
as they're being five trial types,

1513
01:23:06,281 --> 01:23:09,918
but would it be possible
to have like a model

1514
01:23:09,918 --> 01:23:13,288
where it was like a state estimate left
in a state estimate, right.

1515
01:23:13,722 --> 01:23:17,058
For the stimuli type and a state
estimate left and state estimate

1516
01:23:17,058 --> 01:23:18,860
right for the reward value,

1517
01:23:18,860 --> 01:23:21,429
because this frames it in
a very behavioral trial

1518
01:23:21,896 --> 01:23:26,034
centric way with doing estimate on
which one of the five scenarios are in.

1519
01:23:26,034 --> 01:23:28,303
But I'm just trying to think about cases
where you might not know

1520
01:23:28,303 --> 01:23:31,339
which scenario you're in or even what
the total set of scenarios is.

1521
01:23:31,673 --> 01:23:35,043
So you're just doing state
estimate on reward and on stimuli

1522
01:23:36,945 --> 01:23:37,579
yeah.

1523
01:23:37,579 --> 01:23:40,915
I mean, I mean, yes, I mean the well,
well, I guess it kind of depends, right?

1524
01:23:40,915 --> 01:23:44,019
So I mean, if you
if you were to give somebody sort

1525
01:23:44,019 --> 01:23:47,522
of uncertain cues about trial type

1526
01:23:47,522 --> 01:23:50,658
then, then I mean, presumably

1527
01:23:50,658 --> 01:23:53,595
you would just you would need to
I mean, you would just still have

1528
01:23:54,829 --> 01:23:58,133
if they know what the different trial
type possibilities are,

1529
01:23:58,133 --> 01:23:59,601
then you could just have uncertain cues.

1530
01:23:59,601 --> 01:24:03,605
They just don't have a precise belief
with that precise prior

1531
01:24:03,605 --> 01:24:06,274
belief over the different
over this state factor.

1532
01:24:07,876 --> 01:24:12,013
But if you didn't
if there wasn't any set beliefs

1533
01:24:12,013 --> 01:24:15,784
about trial types and there's just
any possible combination of,

1534
01:24:15,817 --> 01:24:19,387
you know, sun clouds, zero
points, two, four and six, then

1535
01:24:20,822 --> 01:24:24,359
I suppose you could do something
where you just have a kind of non factor.

1536
01:24:24,359 --> 01:24:28,029
I a state factor that has like
just every possible combination

1537
01:24:29,364 --> 01:24:31,099
or something like that.

1538
01:24:31,099 --> 01:24:33,368
You could do that. I mean, it would and.

1539
01:24:33,902 --> 01:24:36,237
There are reasons to actually build like
so there are

1540
01:24:37,572 --> 01:24:40,975
obviously time saving and model building

1541
01:24:40,975 --> 01:24:43,711
considerations that mean
you should use factor as distributions

1542
01:24:44,946 --> 01:24:48,216
but they're actual empirical
considerations, which means that I think

1543
01:24:48,216 --> 01:24:52,320
if you want to build a model, that's kind
of realistically how the brain works.

1544
01:24:52,420 --> 01:24:54,923
You should tend towards

1545
01:24:54,923 --> 01:24:58,526
in a lot of cases, you should tend
towards factories distributions.

1546
01:24:58,526 --> 01:25:01,729
So for example, there's good evidence
that there's a size representation

1547
01:25:01,729 --> 01:25:06,935
of task phase in PFC
and MTL is pretty good evidence.

1548
01:25:06,935 --> 01:25:11,406
So I mean the what versus where
streams and vision

1549
01:25:11,439 --> 01:25:13,741
that's a factor sized representation

1550
01:25:15,310 --> 01:25:17,645
so very.

1551
01:25:17,779 --> 01:25:18,379
Yeah.

1552
01:25:18,413 --> 01:25:21,716
So you're kind of using it in
like a course screening sense

1553
01:25:21,950 --> 01:25:24,953
to say
sometimes you don't want to even allow

1554
01:25:24,953 --> 01:25:27,755
for the all by all,
because it's more categorical

1555
01:25:28,056 --> 01:25:31,860
how the task is being modeled anywhere
like fight or flight.

1556
01:25:32,160 --> 01:25:35,697
You would want to have all combinations
of elbow and the movements.

1557
01:25:36,064 --> 01:25:39,334
You're fitting something that's kind of
at the wrong dimensionality.

1558
01:25:39,634 --> 01:25:42,704
And so for a lot of reasons,
not the least of which it seems like

1559
01:25:42,704 --> 01:25:44,706
that's what organisms would
do, would be at that high

1560
01:25:44,706 --> 01:25:47,108
dimensional manifold
or the factory's representation.

1561
01:25:48,543 --> 01:25:50,912
Yeah, well, and, and in this case, right.

1562
01:25:50,912 --> 01:25:52,680
I mean, just we have experimental

1563
01:25:52,680 --> 01:25:55,550
the experimental design is such
that they are they do know

1564
01:25:55,550 --> 01:25:58,786
ahead of time what the different possible
combinations are, right?

1565
01:25:58,786 --> 01:26:01,890
So I mean, they just they just already
know that there are these combinations

1566
01:26:03,158 --> 01:26:06,161
so it's it's
consistent with their beliefs

1567
01:26:06,161 --> 01:26:10,365
about the generative model that we have
given them via the instructions.

1568
01:26:11,733 --> 01:26:14,202
So and

1569
01:26:14,202 --> 01:26:16,671
so so in this case,

1570
01:26:16,671 --> 01:26:19,774
you know, we had a pretty typical,

1571
01:26:20,542 --> 01:26:24,345
you know, sort of sort of model,
graphical model with two parameters.

1572
01:26:24,345 --> 01:26:28,216
We had our beta here, which corresponds

1573
01:26:28,216 --> 01:26:31,753
to the expected for energy precision
here,

1574
01:26:32,220 --> 01:26:36,324
you know, just to be intuitive
for the clinical audience.

1575
01:26:36,691 --> 01:26:39,427
And we were going for
we just called this decision uncertainty.

1576
01:26:40,695 --> 01:26:41,829
And then we had a

1577
01:26:41,829 --> 01:26:44,832
and so that's just
this is again, this is the rate prior

1578
01:26:45,667 --> 01:26:48,536
or rate parameter
for a gamma distribution over

1579
01:26:49,704 --> 01:26:53,041
or this gamma term

1580
01:26:53,041 --> 01:26:56,778
and which again is a

1581
01:26:57,445 --> 01:27:00,481
a thing
that modulates the expected free energy

1582
01:27:00,815 --> 01:27:04,352
estimate over policies
so modulates this thing.

1583
01:27:05,253 --> 01:27:10,358
But then the other parameter we had
was this emotion conflict parameter,

1584
01:27:10,725 --> 01:27:16,097
which just said basically
how much they dislike

1585
01:27:16,331 --> 01:27:20,401
the negative stimulus, how how aversive
they expect the negative stimulus to be

1586
01:27:21,970 --> 01:27:24,806
and so you can kind of show
and simulation.

1587
01:27:24,806 --> 01:27:26,541
So each one of these

1588
01:27:26,841 --> 01:27:29,444
vertical bars here corresponds to beliefs

1589
01:27:29,444 --> 01:27:32,013
about what state
you are in on the runway.

1590
01:27:33,181 --> 01:27:37,318
So if theta equals one and the

1591
01:27:38,920 --> 01:27:41,289
and the emotion conflict equals one,

1592
01:27:41,689 --> 01:27:47,095
then you should expect that
if the good thing is on the it is OK.

1593
01:27:47,095 --> 01:27:51,833
And this is a
this is a conflict plus two points trial.

1594
01:27:52,967 --> 01:27:56,070
So basically
the thing will approach the reward,

1595
01:27:56,437 --> 01:27:59,307
even if it's going to see something
negative of this year's one

1596
01:27:59,307 --> 01:28:02,310
and it will do it deterministically

1597
01:28:02,310 --> 01:28:05,680
whereas if x three,
then it will fairly deterministically

1598
01:28:05,747 --> 01:28:10,752
choose to go away from the negative
stimulus even if they would get reward

1599
01:28:11,185 --> 01:28:13,855
whereas if they have higher,

1600
01:28:13,855 --> 01:28:16,758
higher values,
so more decision uncertainty, then

1601
01:28:16,758 --> 01:28:20,728
this distribution becomes they become
a lot less confident in this distribution

1602
01:28:21,062 --> 01:28:24,232
and in choosing these kinds of values
that are more like in the middle

1603
01:28:26,301 --> 01:28:29,470
and and the likelihood is

1604
01:28:29,470 --> 01:28:33,741
is pretty clear just in each trial type,
each of the different

1605
01:28:34,375 --> 01:28:36,477
each column
here is a different runaway position.

1606
01:28:36,811 --> 01:28:40,214
They will just generate the negative
stimulus with an increasing probability

1607
01:28:40,214 --> 01:28:43,685
as it goes left and the positive stimulus
with an increasing probability

1608
01:28:43,685 --> 01:28:44,452
as it goes right.

1609
01:28:45,520 --> 01:28:46,554
ET cetera.

1610
01:28:46,554 --> 01:28:50,925
The only confusing thing here is,
is that white means higher probability

1611
01:28:51,259 --> 01:28:54,162
in these, whereas black
it means higher probability here. But

1612
01:28:55,363 --> 01:28:56,964
but anyway, so that's that's it.

1613
01:28:56,964 --> 01:29:00,001
And just kind of et cetera, et cetera,
for the five trial types.

1614
01:29:00,535 --> 01:29:02,870
So in this case, what we found was

1615
01:29:03,304 --> 01:29:06,841
if you look at healthy control,
us versus people with depression

1616
01:29:06,841 --> 01:29:09,410
and anxiety versus people of substance
use disorders,

1617
01:29:11,112 --> 01:29:14,816
the emotion
conflict is actually interestingly higher

1618
01:29:14,816 --> 01:29:19,087
in healthy and lowest in substance
use disorder, whereas decision

1619
01:29:19,087 --> 01:29:22,557
uncertainty is highest
in substance use disorder

1620
01:29:23,624 --> 01:29:27,962
and kind of medium and depression,
anxiety and low and healthy controls.

1621
01:29:27,962 --> 01:29:30,598
And these are significantly different.

1622
01:29:30,598 --> 01:29:33,301
And that's true in a propensity
matched, propensity matched sample.

1623
01:29:33,301 --> 01:29:35,870
And at a larger sample.

1624
01:29:36,804 --> 01:29:39,374
So it's interesting thing
where it might be more of a

1625
01:29:39,707 --> 01:29:43,144
what might be more clinically relevant
as this kind of uncertainty over options

1626
01:29:43,144 --> 01:29:47,582
as opposed to just being more sensitive
to negative stimuli.

1627
01:29:49,050 --> 01:29:49,350
Right.

1628
01:29:49,350 --> 01:29:50,485
How would a. Second.

1629
01:29:50,485 --> 01:29:54,288
How would that shape just kind of curious
if it doesn't have a

1630
01:29:54,322 --> 01:29:58,326
if it's not known, but how would that
shape treatment or conversation

1631
01:29:58,326 --> 01:30:03,097
or approach in a given situation
from whichever role makes sense?

1632
01:30:03,097 --> 01:30:07,402
Like to say, oh, it's not actually
this psychological construct,

1633
01:30:07,402 --> 01:30:10,004
but it's actually related
to something like this.

1634
01:30:12,640 --> 01:30:14,942
I mean, in terms of like informing
treatment or something like that.

1635
01:30:15,276 --> 01:30:15,810
Sure.

1636
01:30:15,810 --> 01:30:19,380
Like treatment via any modality

1637
01:30:19,447 --> 01:30:19,714
yeah.

1638
01:30:19,714 --> 01:30:23,818
I mean, so I mean, typically the
the main sorts of things

1639
01:30:23,818 --> 01:30:26,487
you might want to do
is, you know, either talking about

1640
01:30:27,255 --> 01:30:31,058
so say, you know, baseline
before somebody starts treatment

1641
01:30:31,459 --> 01:30:34,629
what their beta value was, right?

1642
01:30:34,996 --> 01:30:37,665
It might be the case
you'd have to study to show this, but

1643
01:30:37,665 --> 01:30:40,968
it might be the case that given different
beta values at baseline,

1644
01:30:41,536 --> 01:30:45,940
you know, like people with high
beta values might respond well to CBT

1645
01:30:46,507 --> 01:30:49,610
cognitive behavioral therapy,
whereas people with low better values

1646
01:30:49,610 --> 01:30:53,214
might respond
better to act or might respond

1647
01:30:53,214 --> 01:30:57,218
better to an SSRI or,
you know, like something like that.

1648
01:30:57,685 --> 01:31:00,822
So either it's either it's something
I mean, that's kind of the ideal

1649
01:31:00,822 --> 01:31:03,925
thing is you want to say,
can I get this information?

1650
01:31:03,925 --> 01:31:06,294
And it will give me information
about how to treat a person

1651
01:31:07,929 --> 01:31:11,065
but there are there are lots of
other things you might do besides that.

1652
01:31:11,065 --> 01:31:15,136
But that's, that's like a primary kind
of, you know, like ultimate goal example.

1653
01:31:15,303 --> 01:31:15,536
Yeah.

1654
01:31:15,536 --> 01:31:19,006
It's, it's interesting how there's
probably a lot to be said and learned

1655
01:31:19,006 --> 01:31:22,977
about the actual application
of active inference clinically.

1656
01:31:23,311 --> 01:31:26,981
But even here on the beginning
of applying it

1657
01:31:27,281 --> 01:31:30,485
we can use it
as just a potential biomarker,

1658
01:31:30,751 --> 01:31:33,721
just like a summary statistic
related to a questionnaire

1659
01:31:33,721 --> 01:31:37,024
or some other thing that's estimated
from empirical clinical data

1660
01:31:37,425 --> 01:31:39,794
fitting a different kind of underlying
generative model.

1661
01:31:39,794 --> 01:31:42,497
So instead of doing a regression,
oh, people who have higher on this

1662
01:31:42,730 --> 01:31:44,999
end up doing better or worse
in this kind of a program.

1663
01:31:45,333 --> 01:31:48,002
Well, now we can just do that
same kind of parameter

1664
01:31:48,536 --> 01:31:51,172
testing in the context
of a different type of model.

1665
01:31:51,172 --> 01:31:53,341
It's an active inference
generative model.

1666
01:31:53,508 --> 01:31:55,076
So I think that those are just

1667
01:31:55,076 --> 01:31:57,345
some points of contact,
but it's really interesting stuff.

1668
01:31:58,246 --> 01:31:59,313
Yeah, definitely.

1669
01:31:59,313 --> 01:32:01,649
I mean, you can do lots of other
interesting things with these, right?

1670
01:32:01,649 --> 01:32:04,886
So this this beta parameter,
if you remember from previous sessions,

1671
01:32:04,886 --> 01:32:06,120
is what's associated with

1672
01:32:07,221 --> 01:32:07,955
it's proposed

1673
01:32:07,955 --> 01:32:10,291
to be associated with dopamine

1674
01:32:11,392 --> 01:32:13,494
dynamics in the brain.

1675
01:32:14,195 --> 01:32:17,899
And I'll show you briefly a study,
an example study later,

1676
01:32:18,799 --> 01:32:21,602
which we're fill up short and back,
like I mentioned before,

1677
01:32:22,103 --> 01:32:25,773
actually showed that
the trial by trial updates in beta

1678
01:32:25,773 --> 01:32:29,110
that are predicted by
the model were correlated with

1679
01:32:30,378 --> 01:32:33,648
both signal and F MRI

1680
01:32:33,648 --> 01:32:35,650
in in the midbrain in a midbrain

1681
01:32:35,650 --> 01:32:38,686
region that's associated with dopamine.

1682
01:32:38,686 --> 01:32:40,388
So whereas
whereas the way that we're doing this

1683
01:32:40,388 --> 01:32:43,391
here, we just have a stable
beta estimate for each person.

1684
01:32:43,891 --> 01:32:46,494
But you might look at

1685
01:32:46,527 --> 01:32:48,362
say, individual differences between

1686
01:32:48,362 --> 01:32:52,433
contrast values in an F MRI analysis
at the group level, you know,

1687
01:32:52,533 --> 01:32:55,736
so like people with higher
beta values have higher say

1688
01:32:56,871 --> 01:32:59,540
basal ganglia responses

1689
01:32:59,974 --> 01:33:02,777
to reward versus
no reward or something like that.

1690
01:33:03,277 --> 01:33:05,046
So you could do that
kind of thing as well.

1691
01:33:05,046 --> 01:33:07,548
So both both individual
level and group level

1692
01:33:08,583 --> 01:33:11,252
F MRI sorts of approaches

1693
01:33:11,252 --> 01:33:13,754
as well as much fancier things

1694
01:33:14,455 --> 01:33:17,792
but those are just
two kind of simple examples.

1695
01:33:17,825 --> 01:33:20,127
So as a, as another example of doing this

1696
01:33:20,361 --> 01:33:23,397
in the domain of perception
and sort of decision making,

1697
01:33:25,232 --> 01:33:29,570
you know, we we used this
in the context of a task where a person

1698
01:33:29,570 --> 01:33:33,240
is just told to push a button
every time they feel their heartbeat

1699
01:33:35,042 --> 01:33:37,678
and so in this model,

1700
01:33:37,678 --> 01:33:41,482
we don't even have like an explicit
policy selection part.

1701
01:33:42,149 --> 01:33:45,252
All we do is
they start with a precise belief

1702
01:33:45,252 --> 01:33:47,521
that they're
in this start state at Time one,

1703
01:33:47,521 --> 01:33:50,791
and then they have prior beliefs
about whether or not

1704
01:33:51,158 --> 01:33:54,228
they're going to transition into a state
of feeling their heartbeat versus not.

1705
01:33:54,228 --> 01:33:56,497
So probability of no heartbeat,
probably a heartbeat.

1706
01:33:57,398 --> 01:34:01,736
And those priors are encoded
in this in the B matrix here.

1707
01:34:01,736 --> 01:34:04,872
The transition matrix
where sort of the higher the B is,

1708
01:34:04,872 --> 01:34:08,743
the more they expect to feel a heartbeat,
you know, more often.

1709
01:34:08,743 --> 01:34:09,977
Right, on each trial.

1710
01:34:11,579 --> 01:34:12,647
And and

1711
01:34:12,647 --> 01:34:16,617
then also there's a precision value here
which corresponds to beliefs

1712
01:34:16,617 --> 01:34:20,521
about how precise the actual afferent
signal is coming up from the heart.

1713
01:34:21,622 --> 01:34:23,724
And so we can estimate this IPI

1714
01:34:23,724 --> 01:34:27,395
parameter is intercept of precision
and this prior of heartbeats,

1715
01:34:28,496 --> 01:34:28,863
I should say.

1716
01:34:28,863 --> 01:34:32,266
We also compared this to a model
that included learning in this task

1717
01:34:32,266 --> 01:34:34,702
and in this case, the model,
including learning, didn't win

1718
01:34:36,871 --> 01:34:38,172
and so what we found here

1719
01:34:38,172 --> 01:34:41,475
is and I should say
also that they do this task three times.

1720
01:34:41,475 --> 01:34:44,345
They do it once when they're told
they're allowed to guess once

1721
01:34:44,345 --> 01:34:45,980
and they're told
they're not allowed to guess

1722
01:34:45,980 --> 01:34:48,249
and only to press it
when they're sure they felt something.

1723
01:34:48,249 --> 01:34:51,385
And one where aside from in addition
to no guessing,

1724
01:34:51,385 --> 01:34:54,922
they're told to hold their breath,
which kind of makes it on average easier

1725
01:34:55,456 --> 01:34:56,290
to feel your heartbeat

1726
01:34:58,225 --> 01:34:59,493
and so it kind of

1727
01:34:59,493 --> 01:35:02,129
amplifies the afferent signal,
makes it more precise.

1728
01:35:02,697 --> 01:35:05,466
What we found was that in healthy people,
the breath hold

1729
01:35:05,466 --> 01:35:08,102
actually amplified
into receptive precision a lot.

1730
01:35:08,636 --> 01:35:11,972
Whereas in all the clinical groups,
anxiety, depression, co-morbid

1731
01:35:11,972 --> 01:35:14,742
depression, anxiety, eating disorders
and substance use disorders,

1732
01:35:15,643 --> 01:35:19,513
they just stayed flat, low interceptor
precision values

1733
01:35:20,314 --> 01:35:23,417
so that the actual changing, the

1734
01:35:23,718 --> 01:35:27,722
actual precision of the afferent signal
didn't have any effect on their beliefs.

1735
01:35:27,722 --> 01:35:30,257
About the precision of the signal.

1736
01:35:30,257 --> 01:35:30,524
Yeah.

1737
01:35:30,591 --> 01:35:34,929
So something like a like a rigidity
in the way that the brain treats afferent

1738
01:35:35,162 --> 01:35:38,566
intercepted signals and psychiatric
disorders trance diagnostically.

1739
01:35:39,400 --> 01:35:42,002
And so again,
this is just a again, kind of a standard

1740
01:35:42,002 --> 01:35:45,372
like mixed model sort of analysis.

1741
01:35:45,372 --> 01:35:47,508
Whereas if you compare, say,

1742
01:35:47,508 --> 01:35:50,778
estimates
for prior expectations, everybody

1743
01:35:51,746 --> 01:35:52,313
showed higher

1744
01:35:52,313 --> 01:35:56,884
prior values and the guessing condition
than in the other two conditions.

1745
01:35:56,884 --> 01:35:58,519
Which you would expect.

1746
01:35:59,086 --> 01:36:02,490
But there were no differences
between healthy and clinical groups.

1747
01:36:02,490 --> 01:36:03,657
So it's kind of interesting.

1748
01:36:03,657 --> 01:36:05,392
It says, hey,
maybe this is more a precision

1749
01:36:05,392 --> 01:36:06,994
issue than it is a prior expectation.

1750
01:36:06,994 --> 01:36:09,930
Issue in terms of clinical significance.

1751
01:36:10,231 --> 01:36:12,800
Or bias
or another task has to be explored.

1752
01:36:13,501 --> 01:36:13,734
I mean.

1753
01:36:13,734 --> 01:36:16,771
If I put in a plug,
I'll call that people as I mean, Faisal

1754
01:36:16,871 --> 01:36:19,440
being a lot of conceptual work on

1755
01:36:20,174 --> 01:36:23,611
interception and active inference,
and there's been a lot of discussion

1756
01:36:23,611 --> 01:36:26,447
about whether it's priors or precision
or anything like that,

1757
01:36:28,149 --> 01:36:31,185
and to my knowledge, I'm happy
to be corrected about this by Ryan,

1758
01:36:31,185 --> 01:36:35,322
but that was the first time
that it's really been tested empirically.

1759
01:36:35,322 --> 01:36:35,589
Right

1760
01:36:37,358 --> 01:36:38,092
yes or no?

1761
01:36:38,092 --> 01:36:42,196
There's no there's no other
there's no other like actual formal

1762
01:36:42,763 --> 01:36:46,867
fitting models to data studies
that I've tried that before.

1763
01:36:47,301 --> 01:36:48,869
So epic work. There.

1764
01:36:48,869 --> 01:36:52,139
There are there are papers
that have tested like more kind of like

1765
01:36:52,807 --> 01:36:56,343
quote unquote qualitative
or just kind of like go up versus down

1766
01:36:56,343 --> 01:36:57,111
sorts of predictions

1767
01:36:57,111 --> 01:37:01,482
that fall out of computational models,
but not actually fitting a model. Yes.

1768
01:37:01,482 --> 01:37:03,918
This is the first model
based analysis of this kind of thing.

1769
01:37:03,918 --> 01:37:04,351
Right.

1770
01:37:05,452 --> 01:37:07,288
Yeah. And we've and it's cool.

1771
01:37:07,288 --> 01:37:11,225
We've actually replicated the results in
healthy controls in a second sample now.

1772
01:37:11,225 --> 01:37:14,595
So it seems like they effect at least
the effect on health is is pretty robust.

1773
01:37:14,829 --> 01:37:18,632
We haven't been able to replicate
we haven't tried to replicate the

1774
01:37:19,133 --> 01:37:24,238
the lack of of an effect
in clinical populations yet.

1775
01:37:24,238 --> 01:37:25,372
But that's kind of in the works

1776
01:37:27,441 --> 01:37:27,975
cool.

1777
01:37:27,975 --> 01:37:32,613
So so so anyway, so this continues
this continues to go here,

1778
01:37:33,247 --> 01:37:35,583
but it should be
I think it should be almost done

1779
01:37:36,150 --> 01:37:39,053
pretty quick it's only took six people
surprised.

1780
01:37:39,954 --> 01:37:42,022
An interception question
and then one question from the chat

1781
01:37:42,022 --> 01:37:45,993
so what other intercept of methodologies
might exist.

1782
01:37:45,993 --> 01:37:49,096
So you did a heart rate estimation task.

1783
01:37:49,496 --> 01:37:52,433
What other intercepted
modalities might be amenable

1784
01:37:52,433 --> 01:37:55,502
to this kind of quantitative analysis?

1785
01:37:56,203 --> 01:37:58,372
So definitely,

1786
01:37:58,372 --> 01:38:02,910
definitely cardiac interception tasks are

1787
01:38:04,111 --> 01:38:06,213
our most common

1788
01:38:06,213 --> 01:38:09,683
just because it's it's
actually quite difficult.

1789
01:38:09,683 --> 01:38:13,621
The methodologies
is it's pretty difficult to use.

1790
01:38:13,821 --> 01:38:15,256
So for instance, envision, right?

1791
01:38:15,256 --> 01:38:18,392
You can like very tightly control
or in audition

1792
01:38:18,392 --> 01:38:21,228
you can really tightly control
the timing and magnitude.
