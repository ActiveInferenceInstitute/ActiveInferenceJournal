1
00:00:09,760 --> 00:00:10,320
hello

2
00:00:10,320 --> 00:00:13,519
everyone welcome to actin flab this

3
00:00:13,519 --> 00:00:17,600
is actin flab model stream number 3.1

4
00:00:17,600 --> 00:00:21,279
it's may 27th 2021

5
00:00:21,279 --> 00:00:23,680
and we're here with tim verbellen and

6
00:00:23,680 --> 00:00:25,039
ozone catal

7
00:00:25,039 --> 00:00:27,920
today we're going to have a model stream

8
00:00:27,920 --> 00:00:29,599
on some of their recent work

9
00:00:29,599 --> 00:00:31,679
on learning generative state-space

10
00:00:31,679 --> 00:00:33,360
models for active inference

11
00:00:33,360 --> 00:00:35,760
we're gonna have a presentation followed

12
00:00:35,760 --> 00:00:36,800
by some time

13
00:00:36,800 --> 00:00:39,520
for question and answer so please feel

14
00:00:39,520 --> 00:00:40,559
free to write

15
00:00:40,559 --> 00:00:43,040
any questions in the chat and we will

16
00:00:43,040 --> 00:00:44,160
get to them

17
00:00:44,160 --> 00:00:46,160
in the conversation so thanks again to

18
00:00:46,160 --> 00:00:47,360
tim and ozon for

19
00:00:47,360 --> 00:00:48,960
joining us today we're really looking

20
00:00:48,960 --> 00:00:50,800
forward to what you have to share

21
00:00:50,800 --> 00:00:54,480
so please take it away and thanks again

22
00:00:54,960 --> 00:00:58,719
so thank you daniel for having us um

23
00:00:58,719 --> 00:01:01,440
so i'm tim verde and together with uh

24
00:01:01,440 --> 00:01:02,800
rosencattel we will

25
00:01:02,800 --> 00:01:05,920
talk a bit on our paper on learning

26
00:01:05,920 --> 00:01:08,000
alternative state space models for

27
00:01:08,000 --> 00:01:10,880
active inference so we are both

28
00:01:10,880 --> 00:01:12,000
researchers at

29
00:01:12,000 --> 00:01:15,840
imek kent university in belgium

30
00:01:15,840 --> 00:01:18,080
if you want to know more about what we

31
00:01:18,080 --> 00:01:19,119
do you can

32
00:01:19,119 --> 00:01:21,920
read about it on our blog or follow us

33
00:01:21,920 --> 00:01:22,720
on twitter

34
00:01:22,720 --> 00:01:26,400
under under at the smart robots

35
00:01:26,400 --> 00:01:29,439
so before we

36
00:01:29,439 --> 00:01:32,560
dive in maybe a short introduction on on

37
00:01:32,560 --> 00:01:34,400
what we do what our goal is

38
00:01:34,400 --> 00:01:35,759
so basically we want to build

39
00:01:35,759 --> 00:01:38,159
intelligent robots so in our lab

40
00:01:38,159 --> 00:01:42,000
here in gans we have a really big

41
00:01:42,000 --> 00:01:43,840
pretty pretty large space where we have

42
00:01:43,840 --> 00:01:46,240
some room for robot manipulators on the

43
00:01:46,240 --> 00:01:47,920
one hand but also

44
00:01:47,920 --> 00:01:50,320
driving and flying robots on the other

45
00:01:50,320 --> 00:01:51,119
hand

46
00:01:51,119 --> 00:01:53,840
and we typically attach all kinds of

47
00:01:53,840 --> 00:01:55,520
sensors on these things

48
00:01:55,520 --> 00:01:58,399
and then we want to process the sensor

49
00:01:58,399 --> 00:01:59,200
information

50
00:01:59,200 --> 00:02:03,119
and infer some useful actions for these

51
00:02:03,119 --> 00:02:03,840
things and

52
00:02:03,840 --> 00:02:07,759
of course active inference is a cool

53
00:02:07,759 --> 00:02:09,280
methodology

54
00:02:09,280 --> 00:02:12,879
to try out and to

55
00:02:13,120 --> 00:02:15,760
further investigate and it's in this

56
00:02:15,760 --> 00:02:18,800
context that basically this this work

57
00:02:18,800 --> 00:02:22,080
is being done

58
00:02:22,080 --> 00:02:24,480
so why would you bother learning the

59
00:02:24,480 --> 00:02:27,280
state space so if you look at

60
00:02:27,280 --> 00:02:30,720
active inference papers from the

61
00:02:30,720 --> 00:02:34,000
recent years then typically you will

62
00:02:34,000 --> 00:02:35,200
find a figure

63
00:02:35,200 --> 00:02:38,640
like the ones that are on the slide

64
00:02:38,640 --> 00:02:40,480
so you have this figure of what is the

65
00:02:40,480 --> 00:02:42,879
kind of environments

66
00:02:42,879 --> 00:02:44,959
that that you're that you're modeling

67
00:02:44,959 --> 00:02:46,480
that you're investigating

68
00:02:46,480 --> 00:02:49,519
and then a whole description on how the

69
00:02:49,519 --> 00:02:50,640
model should look like

70
00:02:50,640 --> 00:02:54,560
so you define the state space and then

71
00:02:54,560 --> 00:02:57,200
possibly or in the case of discrete

72
00:02:57,200 --> 00:02:58,959
state spaces you you

73
00:02:58,959 --> 00:03:02,000
define the the so-called a b c and d

74
00:03:02,000 --> 00:03:03,360
matrix that's

75
00:03:03,360 --> 00:03:06,239
uh that defines the the likelihood model

76
00:03:06,239 --> 00:03:07,599
so what what is the

77
00:03:07,599 --> 00:03:09,440
likelihood to see a certain observation

78
00:03:09,440 --> 00:03:11,200
when you are in certain state

79
00:03:11,200 --> 00:03:13,760
or whether the transition models uh how

80
00:03:13,760 --> 00:03:15,200
do you transition from

81
00:03:15,200 --> 00:03:19,360
one state to another and so forth

82
00:03:19,360 --> 00:03:23,200
um and recently while we were doing this

83
00:03:23,200 --> 00:03:23,920
research

84
00:03:23,920 --> 00:03:26,720
research we saw some other people also

85
00:03:26,720 --> 00:03:27,599
thinking about

86
00:03:27,599 --> 00:03:31,680
yeah um can we do more

87
00:03:31,680 --> 00:03:34,080
learning using these these kind of novel

88
00:03:34,080 --> 00:03:35,760
deep learning techniques

89
00:03:35,760 --> 00:03:38,799
in these uh in these active inference

90
00:03:38,799 --> 00:03:41,440
methods so yet for example kai will

91
00:03:41,440 --> 00:03:42,400
suffer

92
00:03:42,400 --> 00:03:45,440
um who said uh you proposed to to

93
00:03:45,440 --> 00:03:48,480
basically learn kind of a state space

94
00:03:48,480 --> 00:03:48,799
for

95
00:03:48,799 --> 00:03:51,519
for the mountain car but then still he

96
00:03:51,519 --> 00:03:53,040
needed to

97
00:03:53,040 --> 00:03:55,599
explicitly encode some of the of the

98
00:03:55,599 --> 00:03:57,120
environment information

99
00:03:57,120 --> 00:04:00,159
in in the state vector

100
00:04:00,159 --> 00:04:02,319
there was also some work from from from

101
00:04:02,319 --> 00:04:04,080
baron millage

102
00:04:04,080 --> 00:04:08,000
who basically did some learning

103
00:04:08,000 --> 00:04:11,120
a bit more on learning the policy rather

104
00:04:11,120 --> 00:04:11,680
than

105
00:04:11,680 --> 00:04:15,280
the state space so um basically used um

106
00:04:15,280 --> 00:04:17,199
work of decision process with small

107
00:04:17,199 --> 00:04:18,959
state spaces where you could basically

108
00:04:18,959 --> 00:04:19,759
just

109
00:04:19,759 --> 00:04:22,880
deal with the the raw state space

110
00:04:22,880 --> 00:04:24,720
the the observations that the

111
00:04:24,720 --> 00:04:26,320
environment gave you where

112
00:04:26,320 --> 00:04:28,320
were basically suited as a state space

113
00:04:28,320 --> 00:04:29,840
and he could then

114
00:04:29,840 --> 00:04:32,560
he would then investigate how to learn

115
00:04:32,560 --> 00:04:32,880
the

116
00:04:32,880 --> 00:04:36,160
actions given given these states but so

117
00:04:36,160 --> 00:04:39,040
our work is basically on what if you

118
00:04:39,040 --> 00:04:40,720
don't know the state space what if your

119
00:04:40,720 --> 00:04:42,000
observations are

120
00:04:42,000 --> 00:04:45,199
high dimensional and you cannot really

121
00:04:45,199 --> 00:04:47,199
use this directly as your state space

122
00:04:47,199 --> 00:04:48,400
how do you define

123
00:04:48,400 --> 00:04:51,280
the model how you can come up with it

124
00:04:51,280 --> 00:04:53,360
and maybe as a concrete example suppose

125
00:04:53,360 --> 00:04:54,080
we have

126
00:04:54,080 --> 00:04:56,160
one of our driving robots in the lab so

127
00:04:56,160 --> 00:04:58,880
this this is a first-person view of the

128
00:04:58,880 --> 00:04:59,600
robots

129
00:04:59,600 --> 00:05:01,280
this is the kind of observation that you

130
00:05:01,280 --> 00:05:03,680
get is just a square of pixels

131
00:05:03,680 --> 00:05:05,919
and then yeah what's what is your state

132
00:05:05,919 --> 00:05:07,280
space in this case

133
00:05:07,280 --> 00:05:10,639
it might be an xy position on the map

134
00:05:10,639 --> 00:05:12,400
that might be something relevant for a

135
00:05:12,400 --> 00:05:13,759
robot

136
00:05:13,759 --> 00:05:16,800
as a state it might also be uh

137
00:05:16,800 --> 00:05:18,560
watch out you're approaching a cable

138
00:05:18,560 --> 00:05:20,400
getter so there might be a

139
00:05:20,400 --> 00:05:23,360
that might also be something useful

140
00:05:23,360 --> 00:05:25,039
maybe the items that are stored in your

141
00:05:25,039 --> 00:05:25,759
wrecks are

142
00:05:25,759 --> 00:05:28,400
are relevant for for whatever task you

143
00:05:28,400 --> 00:05:30,000
have so that might also be part of the

144
00:05:30,000 --> 00:05:31,360
state space

145
00:05:31,360 --> 00:05:33,440
maybe there are human workers that walk

146
00:05:33,440 --> 00:05:35,120
around that you also need to model these

147
00:05:35,120 --> 00:05:35,759
so

148
00:05:35,759 --> 00:05:38,479
depending on your robot and the use case

149
00:05:38,479 --> 00:05:40,240
you have it does get hands and what can

150
00:05:40,240 --> 00:05:42,400
happen in the environment

151
00:05:42,400 --> 00:05:45,759
it it becomes non-trivial to to define

152
00:05:45,759 --> 00:05:49,520
kind of a concise set of states that you

153
00:05:49,520 --> 00:05:50,639
want to track

154
00:05:50,639 --> 00:05:52,720
let alone that you need some model

155
00:05:52,720 --> 00:05:54,639
that's that's

156
00:05:54,639 --> 00:05:56,479
that models this like how do you get

157
00:05:56,479 --> 00:05:57,759
from pixels to

158
00:05:57,759 --> 00:05:59,840
your expired position so there are

159
00:05:59,840 --> 00:06:01,520
certain methods

160
00:06:01,520 --> 00:06:04,960
uh in robotics that's to do

161
00:06:04,960 --> 00:06:08,400
part of these things but none of them

162
00:06:08,400 --> 00:06:10,639
really just figure out what is the

163
00:06:10,639 --> 00:06:11,680
complete

164
00:06:11,680 --> 00:06:14,160
uh state space that you you need for for

165
00:06:14,160 --> 00:06:15,840
whatever you want to do

166
00:06:15,840 --> 00:06:18,479
and especially not in in kind of an

167
00:06:18,479 --> 00:06:22,000
active inference setting

168
00:06:22,080 --> 00:06:25,039
so before we go into our methods i'll

169
00:06:25,039 --> 00:06:27,520
briefly

170
00:06:27,759 --> 00:06:31,120
talk about active inference probably

171
00:06:31,120 --> 00:06:32,960
most of you are already familiar with

172
00:06:32,960 --> 00:06:34,720
the topic but i'll just

173
00:06:34,720 --> 00:06:37,840
rehearse some of the stuff even if it's

174
00:06:37,840 --> 00:06:41,520
just to to get accustomed to our way of

175
00:06:41,520 --> 00:06:43,520
of notation let's say because everybody

176
00:06:43,520 --> 00:06:45,440
has his own

177
00:06:45,440 --> 00:06:48,960
notation and it at least it will

178
00:06:48,960 --> 00:06:51,120
put us all in on the same page for for

179
00:06:51,120 --> 00:06:52,639
an expert

180
00:06:52,639 --> 00:06:56,080
so um it all starts with having an agent

181
00:06:56,080 --> 00:06:57,280
that needs to interact

182
00:06:57,280 --> 00:07:00,240
with the environment and the agent is

183
00:07:00,240 --> 00:07:02,160
assumed to be kind of separated

184
00:07:02,160 --> 00:07:04,160
from the environments from the so-called

185
00:07:04,160 --> 00:07:05,440
markov blankets

186
00:07:05,440 --> 00:07:08,319
so on the one hand the agents can come

187
00:07:08,319 --> 00:07:10,000
from actions

188
00:07:10,000 --> 00:07:12,960
these actions these will impact the

189
00:07:12,960 --> 00:07:15,039
environment which is kind of

190
00:07:15,039 --> 00:07:18,240
a generative process that has some

191
00:07:18,240 --> 00:07:21,840
some some hidden states and that provide

192
00:07:21,840 --> 00:07:23,599
you given your action

193
00:07:23,599 --> 00:07:25,039
it provides you with some sensory

194
00:07:25,039 --> 00:07:27,039
observation so in this case

195
00:07:27,039 --> 00:07:29,280
an action could be for the robot to

196
00:07:29,280 --> 00:07:30,400
drive around

197
00:07:30,400 --> 00:07:33,840
and put some currents on on the motors

198
00:07:33,840 --> 00:07:35,919
and observation could be some pixels

199
00:07:35,919 --> 00:07:37,520
from from the camera

200
00:07:37,520 --> 00:07:39,840
and then the goal of the agent is to

201
00:07:39,840 --> 00:07:41,280
build a generative model

202
00:07:41,280 --> 00:07:43,840
where he has his own uh he builds his

203
00:07:43,840 --> 00:07:45,520
own state space basically

204
00:07:45,520 --> 00:07:49,360
he derives how actions um

205
00:07:49,360 --> 00:07:51,919
have effects on on the states and how

206
00:07:51,919 --> 00:07:53,840
these states then then would generate

207
00:07:53,840 --> 00:07:55,919
these observations

208
00:07:55,919 --> 00:07:58,800
so the question is how can we build a

209
00:07:58,800 --> 00:07:59,919
generative model

210
00:07:59,919 --> 00:08:02,319
that actually comes up automatically

211
00:08:02,319 --> 00:08:05,680
with kind of a proper state space to

212
00:08:05,680 --> 00:08:09,599
learn this model so basically

213
00:08:09,599 --> 00:08:12,160
the generative model then looks like a

214
00:08:12,160 --> 00:08:14,319
probably be a partially observable

215
00:08:14,319 --> 00:08:17,759
markov decision process so it just means

216
00:08:17,759 --> 00:08:18,319
that

217
00:08:18,319 --> 00:08:21,520
we assume that that's the state at a

218
00:08:21,520 --> 00:08:22,879
given time step

219
00:08:22,879 --> 00:08:25,840
it only depends on the previous states

220
00:08:25,840 --> 00:08:27,680
and the action that's that

221
00:08:27,680 --> 00:08:30,960
you were doing and each state

222
00:08:30,960 --> 00:08:33,760
gives gives rise to a certain

223
00:08:33,760 --> 00:08:36,479
observation

224
00:08:36,719 --> 00:08:40,000
and so then we end up with the

225
00:08:40,000 --> 00:08:42,640
the so-called free energy principle that

226
00:08:42,640 --> 00:08:44,240
basically what we want to do

227
00:08:44,240 --> 00:08:47,200
is going to build a model uh that's that

228
00:08:47,200 --> 00:08:49,200
maximizes log evidence so here

229
00:08:49,200 --> 00:08:52,399
you see the formula for the free energy

230
00:08:52,399 --> 00:08:55,760
and you can unpack it in in several ways

231
00:08:55,760 --> 00:08:59,200
so the first uh uh way is basically by

232
00:08:59,200 --> 00:09:00,000
by

233
00:09:00,000 --> 00:09:02,800
stating that minimizing free energy is

234
00:09:02,800 --> 00:09:03,440
actually

235
00:09:03,440 --> 00:09:07,680
uh maximizing the uh

236
00:09:07,680 --> 00:09:10,560
evidence lower bound let's say and if

237
00:09:10,560 --> 00:09:11,279
you're

238
00:09:11,279 --> 00:09:13,760
uh at this free energy minimum then

239
00:09:13,760 --> 00:09:15,680
basically you have your approximate

240
00:09:15,680 --> 00:09:17,920
posterior that this is actually equals

241
00:09:17,920 --> 00:09:19,120
to your or

242
00:09:19,120 --> 00:09:22,320
very close to your your troops but then

243
00:09:22,320 --> 00:09:22,800
the

244
00:09:22,800 --> 00:09:25,120
the third line is basically what we

245
00:09:25,120 --> 00:09:26,240
typically use

246
00:09:26,240 --> 00:09:28,720
for optimizing our model which is

247
00:09:28,720 --> 00:09:29,839
basically on the one hand

248
00:09:29,839 --> 00:09:33,279
a complexity term you want to

249
00:09:33,279 --> 00:09:36,800
have your your states explain

250
00:09:36,800 --> 00:09:39,200
explain the way as simple as possible

251
00:09:39,200 --> 00:09:40,880
whereas you want to have the highest

252
00:09:40,880 --> 00:09:42,480
accuracy to predict

253
00:09:42,480 --> 00:09:44,959
whatever you're observing so in this

254
00:09:44,959 --> 00:09:45,839
case our

255
00:09:45,839 --> 00:09:48,000
variational approximate posterior is

256
00:09:48,000 --> 00:09:49,600
something that

257
00:09:49,600 --> 00:09:53,360
maps observations and actions into

258
00:09:53,360 --> 00:09:55,440
inferring your current your current

259
00:09:55,440 --> 00:09:57,760
state

260
00:09:58,000 --> 00:10:00,160
but what about the future so in in the

261
00:10:00,160 --> 00:10:01,600
past you basically knew

262
00:10:01,600 --> 00:10:03,680
which actions you were doing and you you

263
00:10:03,680 --> 00:10:05,360
saw the observations

264
00:10:05,360 --> 00:10:08,880
uh that came in so you could kind of

265
00:10:08,880 --> 00:10:12,079
infer which states would have given rise

266
00:10:12,079 --> 00:10:13,839
to the observations so

267
00:10:13,839 --> 00:10:15,440
that's basically the priority of the

268
00:10:15,440 --> 00:10:18,079
past but then in the future

269
00:10:18,079 --> 00:10:20,079
things change a bit because now you

270
00:10:20,079 --> 00:10:22,079
don't know what you will observe

271
00:10:22,079 --> 00:10:24,320
and also you have to select the actions

272
00:10:24,320 --> 00:10:25,680
you will do

273
00:10:25,680 --> 00:10:29,920
so the actions we will basically

274
00:10:29,920 --> 00:10:31,839
denote them as being generated by

275
00:10:31,839 --> 00:10:33,120
so-called policy

276
00:10:33,120 --> 00:10:35,279
but in in this case the policy is

277
00:10:35,279 --> 00:10:36,160
basically just

278
00:10:36,160 --> 00:10:39,279
yeah what is a certain sequence

279
00:10:39,279 --> 00:10:42,640
of actions basically um

280
00:10:42,640 --> 00:10:45,680
and you now have to create some

281
00:10:45,680 --> 00:10:46,640
expectations

282
00:10:46,640 --> 00:10:49,839
not only on future states but also on uh

283
00:10:49,839 --> 00:10:52,079
future observations so what

284
00:10:52,079 --> 00:10:54,160
which states do i think i will visit by

285
00:10:54,160 --> 00:10:55,360
doing some actions

286
00:10:55,360 --> 00:10:57,600
but also what kind of observations do i

287
00:10:57,600 --> 00:11:00,079
think that i will see if i visit these

288
00:11:00,079 --> 00:11:03,200
states so then

289
00:11:03,200 --> 00:11:05,040
the free energy becomes the so-called

290
00:11:05,040 --> 00:11:06,959
expected free energy

291
00:11:06,959 --> 00:11:10,240
and again you can unpack this

292
00:11:10,240 --> 00:11:14,000
this thing um as follows

293
00:11:14,000 --> 00:11:16,959
so basically what happens is again you

294
00:11:16,959 --> 00:11:17,279
have

295
00:11:17,279 --> 00:11:19,440
on the one hand your uh the love

296
00:11:19,440 --> 00:11:20,880
probability of your

297
00:11:20,880 --> 00:11:24,160
uh steer model minus log probability of

298
00:11:24,160 --> 00:11:24,720
your

299
00:11:24,720 --> 00:11:28,000
um uh of your gender

300
00:11:28,000 --> 00:11:31,440
model uh and now the difference is that

301
00:11:31,440 --> 00:11:33,760
um that you don't know yet the

302
00:11:33,760 --> 00:11:35,440
observations in the future

303
00:11:35,440 --> 00:11:37,839
so yeah you conditioned it on the policy

304
00:11:37,839 --> 00:11:39,600
so everything will depend on the

305
00:11:39,600 --> 00:11:42,800
actions you will do and you also have to

306
00:11:42,800 --> 00:11:45,440
take the expectation over all kinds of

307
00:11:45,440 --> 00:11:46,000
of

308
00:11:46,000 --> 00:11:48,959
outcomes you expect and then going to

309
00:11:48,959 --> 00:11:51,839
the second line you basically

310
00:11:51,839 --> 00:11:54,959
make the move that after

311
00:11:54,959 --> 00:11:56,560
if you if your model is sufficiently

312
00:11:56,560 --> 00:11:58,639
trained then basically

313
00:11:58,639 --> 00:11:59,900
um your

314
00:11:59,900 --> 00:12:01,839
[Music]

315
00:12:01,839 --> 00:12:05,360
your true your approximate posterior

316
00:12:05,360 --> 00:12:06,880
will be very close to the

317
00:12:06,880 --> 00:12:08,959
the true posterior and this then

318
00:12:08,959 --> 00:12:10,480
basically allows you to

319
00:12:10,480 --> 00:12:13,680
uh to rewrite the final term well i

320
00:12:13,680 --> 00:12:17,120
i see now that i uh that i

321
00:12:17,120 --> 00:12:19,279
wrote it in in a different way but you

322
00:12:19,279 --> 00:12:20,800
can you can rewrite this

323
00:12:20,800 --> 00:12:25,040
either as an information game on

324
00:12:25,040 --> 00:12:29,440
and moving towards preferred outcomes

325
00:12:29,440 --> 00:12:31,920
but you can also rewrite the way read it

326
00:12:31,920 --> 00:12:32,480
here

327
00:12:32,480 --> 00:12:34,480
where you basically state okay at some

328
00:12:34,480 --> 00:12:35,839
point in the future

329
00:12:35,839 --> 00:12:37,680
i will visit some states so this is the

330
00:12:37,680 --> 00:12:39,040
sloppy of s

331
00:12:39,040 --> 00:12:42,320
esta given the policy and you basically

332
00:12:42,320 --> 00:12:43,200
replace this

333
00:12:43,200 --> 00:12:46,240
by by some prior belief that regardless

334
00:12:46,240 --> 00:12:46,880
which

335
00:12:46,880 --> 00:12:49,680
policy i'm actually choosing i believe

336
00:12:49,680 --> 00:12:50,399
that

337
00:12:50,399 --> 00:12:52,320
some point in the future i will realize

338
00:12:52,320 --> 00:12:54,240
my preferences so that's why you lose

339
00:12:54,240 --> 00:12:54,720
the

340
00:12:54,720 --> 00:12:58,160
the conditioning on the policy uh

341
00:12:58,160 --> 00:13:00,399
in in the in the last equation so this

342
00:13:00,399 --> 00:13:02,399
then basically becomes a kl divergence

343
00:13:02,399 --> 00:13:03,279
that says

344
00:13:03,279 --> 00:13:06,720
okay i i want to find the policies that

345
00:13:06,720 --> 00:13:08,639
actually bring me close to the states

346
00:13:08,639 --> 00:13:09,279
that i

347
00:13:09,279 --> 00:13:12,240
that i prefer that i like to be into and

348
00:13:12,240 --> 00:13:14,000
then on the other hand you have this

349
00:13:14,000 --> 00:13:16,560
ambiguity term that says okay what i

350
00:13:16,560 --> 00:13:18,560
don't like is to visit states that can

351
00:13:18,560 --> 00:13:20,160
give me like any observation

352
00:13:20,160 --> 00:13:22,959
that i cannot predict so i don't like

353
00:13:22,959 --> 00:13:23,519
these

354
00:13:23,519 --> 00:13:25,519
ambiguous states where i don't really

355
00:13:25,519 --> 00:13:27,519
understand basically what's

356
00:13:27,519 --> 00:13:30,000
happening

357
00:13:30,720 --> 00:13:34,240
so that that brings us to the

358
00:13:34,240 --> 00:13:37,920
whole active inference scheme so at each

359
00:13:37,920 --> 00:13:38,880
time step

360
00:13:38,880 --> 00:13:41,040
you basically evaluate your expected

361
00:13:41,040 --> 00:13:42,079
free energy

362
00:13:42,079 --> 00:13:45,680
for each of your policies and you then

363
00:13:45,680 --> 00:13:48,399
basically assume that you will choose

364
00:13:48,399 --> 00:13:49,360
the policy

365
00:13:49,360 --> 00:13:51,279
that will actually minimize your

366
00:13:51,279 --> 00:13:53,519
expected free energy so you

367
00:13:53,519 --> 00:13:57,360
you take the softmax over uh minus g

368
00:13:57,360 --> 00:13:59,120
and you also weigh this with this gamma

369
00:13:59,120 --> 00:14:00,399
parameter which is just like the

370
00:14:00,399 --> 00:14:02,480
precision so if you have a high

371
00:14:02,480 --> 00:14:03,519
precision

372
00:14:03,519 --> 00:14:05,440
then basically you will you will have a

373
00:14:05,440 --> 00:14:07,199
very big

374
00:14:07,199 --> 00:14:09,279
output of a soft max function so the the

375
00:14:09,279 --> 00:14:10,959
softmax will basically

376
00:14:10,959 --> 00:14:14,639
become a max so you then

377
00:14:14,639 --> 00:14:17,360
definitely choose the policy with with

378
00:14:17,360 --> 00:14:17,920
lowest

379
00:14:17,920 --> 00:14:21,680
expected free energy if you relax the

380
00:14:21,680 --> 00:14:24,240
the precision a bit then basically you

381
00:14:24,240 --> 00:14:24,720
you

382
00:14:24,720 --> 00:14:28,480
allow for some or some more randomness

383
00:14:28,480 --> 00:14:31,519
in the system and then basically you end

384
00:14:31,519 --> 00:14:33,120
up inferring the next action

385
00:14:33,120 --> 00:14:36,399
according to what is the the the next

386
00:14:36,399 --> 00:14:37,600
action that i should

387
00:14:37,600 --> 00:14:39,839
take according to this policy but so

388
00:14:39,839 --> 00:14:42,000
when the forward follows

389
00:14:42,000 --> 00:14:44,240
the actual the action selection given

390
00:14:44,240 --> 00:14:45,839
the policy is basically

391
00:14:45,839 --> 00:14:48,560
just a deterministic mapping so the

392
00:14:48,560 --> 00:14:49,600
policies are just

393
00:14:49,600 --> 00:14:52,160
like certain sequence of actions so

394
00:14:52,160 --> 00:14:52,959
given

395
00:14:52,959 --> 00:14:54,720
once you choose the policy the the

396
00:14:54,720 --> 00:14:56,959
action is basically fixed but

397
00:14:56,959 --> 00:14:59,120
in theory you could also make this a

398
00:14:59,120 --> 00:15:02,000
probabilistic mapping

399
00:15:02,000 --> 00:15:05,279
so let's now go to the

400
00:15:05,279 --> 00:15:07,440
the real interesting parts of the work

401
00:15:07,440 --> 00:15:09,600
is is how how do we

402
00:15:09,600 --> 00:15:11,920
learn state spaces with deep neural

403
00:15:11,920 --> 00:15:13,279
networks in such an

404
00:15:13,279 --> 00:15:16,720
an active inference key

405
00:15:17,040 --> 00:15:19,920
well basically

406
00:15:20,079 --> 00:15:22,800
we have two components one is the

407
00:15:22,800 --> 00:15:24,639
generative model that

408
00:15:24,639 --> 00:15:27,680
i rehearse from the first

409
00:15:27,680 --> 00:15:30,399
slide and we have our approximate

410
00:15:30,399 --> 00:15:31,680
posterior model

411
00:15:31,680 --> 00:15:33,839
and basically you can see that there are

412
00:15:33,839 --> 00:15:34,720
three

413
00:15:34,720 --> 00:15:37,839
parts in these equations and the first

414
00:15:37,839 --> 00:15:38,240
part

415
00:15:38,240 --> 00:15:41,519
is basically a transition model so

416
00:15:41,519 --> 00:15:45,279
it's outputs the probability of

417
00:15:45,279 --> 00:15:48,399
your state given your previous states

418
00:15:48,399 --> 00:15:51,920
and the action you did in that state

419
00:15:51,920 --> 00:15:55,120
second part oh yeah and also the

420
00:15:55,120 --> 00:15:57,920
the initial state is basically uh also

421
00:15:57,920 --> 00:15:59,519
part of the transition model but then

422
00:15:59,519 --> 00:16:00,800
you just

423
00:16:00,800 --> 00:16:02,800
provide with a zero action for example

424
00:16:02,800 --> 00:16:06,000
just to bootstrap it

425
00:16:06,000 --> 00:16:07,839
the second part is under accurate model

426
00:16:07,839 --> 00:16:10,000
so given state you want to have a model

427
00:16:10,000 --> 00:16:10,399
that

428
00:16:10,399 --> 00:16:12,320
that predicts what kind of observation

429
00:16:12,320 --> 00:16:14,000
you will you will

430
00:16:14,000 --> 00:16:17,680
see and then finally you have the

431
00:16:17,680 --> 00:16:20,079
posterior model that's given the

432
00:16:20,079 --> 00:16:21,120
previous state

433
00:16:21,120 --> 00:16:23,920
action and your current observation also

434
00:16:23,920 --> 00:16:24,880
has to predict

435
00:16:24,880 --> 00:16:28,480
um which state your also has to infer

436
00:16:28,480 --> 00:16:29,680
which state you're in

437
00:16:29,680 --> 00:16:32,880
so basically the posterior model has to

438
00:16:32,880 --> 00:16:34,560
come up with the same thing as a

439
00:16:34,560 --> 00:16:36,560
transition model but in addition

440
00:16:36,560 --> 00:16:38,480
it has access to your circulation

441
00:16:38,480 --> 00:16:40,320
basically

442
00:16:40,320 --> 00:16:43,199
and again similar to a transition model

443
00:16:43,199 --> 00:16:44,800
to bootstrap this for the initial

444
00:16:44,800 --> 00:16:46,399
observation you don't have

445
00:16:46,399 --> 00:16:49,199
any action but it can be modeled by by

446
00:16:49,199 --> 00:16:50,079
the same thing

447
00:16:50,079 --> 00:16:53,120
as all these these three components we

448
00:16:53,120 --> 00:16:54,720
basically instance the ids

449
00:16:54,720 --> 00:16:57,540
as deep neural nets where

450
00:16:57,540 --> 00:16:58,800
[Music]

451
00:16:58,800 --> 00:17:02,560
they have to basically be trained

452
00:17:02,560 --> 00:17:05,760
to come up with these three

453
00:17:05,760 --> 00:17:09,119
modes so if we

454
00:17:09,119 --> 00:17:12,319
uh put it in a schematic we basically

455
00:17:12,319 --> 00:17:12,959
have

456
00:17:12,959 --> 00:17:16,160
something like this so given your state

457
00:17:16,160 --> 00:17:18,720
an action from the previous time step

458
00:17:18,720 --> 00:17:20,559
and the observation from the current

459
00:17:20,559 --> 00:17:21,599
time step

460
00:17:21,599 --> 00:17:24,000
you on the one hand provides the

461
00:17:24,000 --> 00:17:25,439
previous state and action to your

462
00:17:25,439 --> 00:17:26,959
transition model

463
00:17:26,959 --> 00:17:30,480
which will then output

464
00:17:30,480 --> 00:17:33,760
the distribution over the current state

465
00:17:33,760 --> 00:17:35,919
and in this case this distribution is

466
00:17:35,919 --> 00:17:36,880
basically

467
00:17:36,880 --> 00:17:39,360
modeled as a multivariate gaussian

468
00:17:39,360 --> 00:17:41,120
distribution so basically

469
00:17:41,120 --> 00:17:43,600
the output of the neural nets will be

470
00:17:43,600 --> 00:17:44,559
the means

471
00:17:44,559 --> 00:17:47,360
and the standard deviations of a

472
00:17:47,360 --> 00:17:48,240
gaussian

473
00:17:48,240 --> 00:17:50,160
and now you basically use this

474
00:17:50,160 --> 00:17:51,760
distribution to then

475
00:17:51,760 --> 00:17:54,480
generate samples for the next time step

476
00:17:54,480 --> 00:17:56,000
so the posterior model

477
00:17:56,000 --> 00:17:59,120
gets also as input to the state and the

478
00:17:59,120 --> 00:18:01,360
action from the previous time step

479
00:18:01,360 --> 00:18:03,679
but also in addition the current

480
00:18:03,679 --> 00:18:04,559
observation

481
00:18:04,559 --> 00:18:08,559
and it also does a prediction on the

482
00:18:08,559 --> 00:18:12,640
the current time step and after sampling

483
00:18:12,640 --> 00:18:14,160
you basically have the likelihood model

484
00:18:14,160 --> 00:18:16,320
that can then uh generate

485
00:18:16,320 --> 00:18:20,000
a prediction of the outcome

486
00:18:20,000 --> 00:18:23,520
and then this state is put into the

487
00:18:23,520 --> 00:18:26,160
next time step and this the story

488
00:18:26,160 --> 00:18:26,880
repeats

489
00:18:26,880 --> 00:18:29,360
so as i already mentioned the output of

490
00:18:29,360 --> 00:18:31,440
each of our neural nets is basically

491
00:18:31,440 --> 00:18:36,240
some mean and standard deviation of uh

492
00:18:36,240 --> 00:18:40,840
of a multivariate gaussian with

493
00:18:40,840 --> 00:18:43,280
um with the diagonal

494
00:18:43,280 --> 00:18:46,760
covariance matrix and we use the

495
00:18:46,760 --> 00:18:49,440
reparameterization trick to generate

496
00:18:49,440 --> 00:18:50,960
samples so basically

497
00:18:50,960 --> 00:18:54,000
we generate sample by uh having the the

498
00:18:54,000 --> 00:18:54,799
means

499
00:18:54,799 --> 00:18:57,280
and then adds the standard deviation

500
00:18:57,280 --> 00:18:57,840
times

501
00:18:57,840 --> 00:19:00,799
some standard normal noise and this

502
00:19:00,799 --> 00:19:02,480
basically allows you to

503
00:19:02,480 --> 00:19:05,360
back propagates gradients all the way

504
00:19:05,360 --> 00:19:06,320
through

505
00:19:06,320 --> 00:19:08,960
this neural net also if you if you draw

506
00:19:08,960 --> 00:19:12,640
samples from from the models

507
00:19:14,240 --> 00:19:16,240
and then of course for the next time

508
00:19:16,240 --> 00:19:18,240
step you just propagate the sample and

509
00:19:18,240 --> 00:19:22,000
then the story repeats basically

510
00:19:22,400 --> 00:19:25,280
so creating such a model is then

511
00:19:25,280 --> 00:19:26,240
basically

512
00:19:26,240 --> 00:19:29,520
first collecting the data sets of

513
00:19:29,520 --> 00:19:32,880
action observation sequences so you

514
00:19:32,880 --> 00:19:36,640
you take your your your agent you either

515
00:19:36,640 --> 00:19:39,679
let it randomly generate sequences in

516
00:19:39,679 --> 00:19:41,039
the environment or

517
00:19:41,039 --> 00:19:43,120
in case of a real robot for example you

518
00:19:43,120 --> 00:19:44,640
you drive it around yourself

519
00:19:44,640 --> 00:19:47,679
in the environments while you record the

520
00:19:47,679 --> 00:19:50,320
actions and the observations

521
00:19:50,320 --> 00:19:53,360
and while the models aren't converged

522
00:19:53,360 --> 00:19:56,400
you sample some subsequences from your

523
00:19:56,400 --> 00:19:57,679
data sets

524
00:19:57,679 --> 00:20:00,799
you um you estimate the

525
00:20:00,799 --> 00:20:03,200
states that are visited and you

526
00:20:03,200 --> 00:20:04,000
reconstruct

527
00:20:04,000 --> 00:20:06,640
all the observations and then you

528
00:20:06,640 --> 00:20:08,400
basically back propagates the free

529
00:20:08,400 --> 00:20:09,840
energy loss so

530
00:20:09,840 --> 00:20:12,480
this is the the same formula as the free

531
00:20:12,480 --> 00:20:14,400
energy in the start so on the one hand

532
00:20:14,400 --> 00:20:15,280
you have

533
00:20:15,280 --> 00:20:18,080
the kl divergence between the output of

534
00:20:18,080 --> 00:20:18,480
your

535
00:20:18,480 --> 00:20:21,120
posterior neural nets and your prior

536
00:20:21,120 --> 00:20:22,559
neural nets

537
00:20:22,559 --> 00:20:24,159
and on the other on the other hand you

538
00:20:24,159 --> 00:20:26,799
have this reconstruction error

539
00:20:26,799 --> 00:20:28,960
that basically scores how how good

540
00:20:28,960 --> 00:20:30,880
you're reconstructing the the actual

541
00:20:30,880 --> 00:20:31,840
service

542
00:20:31,840 --> 00:20:34,720
and using this loss function you just

543
00:20:34,720 --> 00:20:35,440
update

544
00:20:35,440 --> 00:20:38,960
the parameters of your real nets and

545
00:20:38,960 --> 00:20:41,919
you basically build a model that is able

546
00:20:41,919 --> 00:20:42,799
on the one hand

547
00:20:42,799 --> 00:20:46,000
to infer

548
00:20:46,000 --> 00:20:47,440
your current state given your

549
00:20:47,440 --> 00:20:50,640
observation that is able to

550
00:20:50,640 --> 00:20:53,679
generate new observations if you know

551
00:20:53,679 --> 00:20:54,960
which state you're in

552
00:20:54,960 --> 00:20:57,039
you can reconstruct these observations

553
00:20:57,039 --> 00:20:58,720
but also you have a transition model

554
00:20:58,720 --> 00:21:01,440
that you can then just use to

555
00:21:01,440 --> 00:21:04,559
in the state space plan ahead what would

556
00:21:04,559 --> 00:21:05,280
happen

557
00:21:05,280 --> 00:21:08,080
if i if i would do this action and it

558
00:21:08,080 --> 00:21:09,919
will give you a distribution over

559
00:21:09,919 --> 00:21:13,840
over the next state basically

560
00:21:13,919 --> 00:21:17,600
so then we come to uh the planning part

561
00:21:17,600 --> 00:21:19,440
so once you have this model how can you

562
00:21:19,440 --> 00:21:21,520
use it to let your agent do

563
00:21:21,520 --> 00:21:25,200
useful useful useful things so there we

564
00:21:25,200 --> 00:21:28,240
we will use monte carlo sampling so one

565
00:21:28,240 --> 00:21:29,200
of the things

566
00:21:29,200 --> 00:21:31,600
uh one of the limitations of these kind

567
00:21:31,600 --> 00:21:33,039
of architectures

568
00:21:33,039 --> 00:21:36,159
is that basically we only approximate

569
00:21:36,159 --> 00:21:38,320
the distribution for the next state so

570
00:21:38,320 --> 00:21:40,000
given the sample from

571
00:21:40,000 --> 00:21:42,559
uh from the previous state and given the

572
00:21:42,559 --> 00:21:43,840
action

573
00:21:43,840 --> 00:21:45,760
we approximate the distribution for the

574
00:21:45,760 --> 00:21:46,880
next stage but then

575
00:21:46,880 --> 00:21:49,200
we sample during training as well so we

576
00:21:49,200 --> 00:21:52,080
will never have like a

577
00:21:52,080 --> 00:21:54,720
good distribution for let's say 10 steps

578
00:21:54,720 --> 00:21:57,039
ahead

579
00:21:57,120 --> 00:21:59,919
so to predict them distributions for for

580
00:21:59,919 --> 00:22:01,280
further in the future

581
00:22:01,280 --> 00:22:03,679
we we approximate these by by doing

582
00:22:03,679 --> 00:22:04,320
multiple

583
00:22:04,320 --> 00:22:07,200
sampling so for each of the policies we

584
00:22:07,200 --> 00:22:08,240
we want to be

585
00:22:08,240 --> 00:22:11,600
uh we want to evaluate

586
00:22:11,600 --> 00:22:14,960
the sample and trajectories that uh

587
00:22:14,960 --> 00:22:17,360
that all do the same actions but that's

588
00:22:17,360 --> 00:22:18,880
due to the sampling might

589
00:22:18,880 --> 00:22:20,960
give us different results in terms of

590
00:22:20,960 --> 00:22:22,320
future states and

591
00:22:22,320 --> 00:22:24,880
and observations so for each time step

592
00:22:24,880 --> 00:22:26,880
we then have a bunch of states and a

593
00:22:26,880 --> 00:22:29,440
bunch of predicted observations

594
00:22:29,440 --> 00:22:31,679
we then fit a gaussian distribution

595
00:22:31,679 --> 00:22:32,559
using the

596
00:22:32,559 --> 00:22:35,760
sample means and variances and then we

597
00:22:35,760 --> 00:22:38,400
estimate the expected free energy as

598
00:22:38,400 --> 00:22:39,760
follows

599
00:22:39,760 --> 00:22:43,679
so on the one hand we have this

600
00:22:43,679 --> 00:22:46,159
scale divergence if you remember that

601
00:22:46,159 --> 00:22:47,120
scores

602
00:22:47,120 --> 00:22:50,240
how good your distribution of states

603
00:22:50,240 --> 00:22:53,760
is according to some some prior uh

604
00:22:53,760 --> 00:22:56,320
some prior preferences of states so you

605
00:22:56,320 --> 00:22:57,520
use this this

606
00:22:57,520 --> 00:22:59,280
this normal this is disgusting

607
00:22:59,280 --> 00:23:01,039
distribution to calculate the gel

608
00:23:01,039 --> 00:23:03,520
divergence with respect to these priors

609
00:23:03,520 --> 00:23:05,600
now on the other hand you have this

610
00:23:05,600 --> 00:23:06,880
entropy term

611
00:23:06,880 --> 00:23:10,080
that scores the the ambiguity of these

612
00:23:10,080 --> 00:23:10,720
states

613
00:23:10,720 --> 00:23:12,960
so here we basically use then the

614
00:23:12,960 --> 00:23:14,720
entropy of

615
00:23:14,720 --> 00:23:18,480
the observations uh generated

616
00:23:18,480 --> 00:23:21,280
in our trajectories and we also added a

617
00:23:21,280 --> 00:23:22,159
scale factor

618
00:23:22,159 --> 00:23:25,600
row to just kind of weigh two terms

619
00:23:25,600 --> 00:23:28,720
uh from one another

620
00:23:28,720 --> 00:23:32,559
which allows you to make an agent

621
00:23:32,640 --> 00:23:35,440
more risky let's say if it's it's more

622
00:23:35,440 --> 00:23:36,080
weight on

623
00:23:36,080 --> 00:23:39,280
realizing preferences early whether you

624
00:23:39,280 --> 00:23:40,640
could also

625
00:23:40,640 --> 00:23:42,640
make a more cautious agent let's say

626
00:23:42,640 --> 00:23:44,320
that's that's really

627
00:23:44,320 --> 00:23:47,360
does not want to end up in some

628
00:23:47,360 --> 00:23:51,520
ambiguous states and crucially here

629
00:23:51,520 --> 00:23:54,320
we also have kind of this recursive

630
00:23:54,320 --> 00:23:56,240
notion in here so

631
00:23:56,240 --> 00:23:59,279
we we do this rollout for k time steps

632
00:23:59,279 --> 00:24:00,400
ahead

633
00:24:00,400 --> 00:24:02,559
and then for the future you could kind

634
00:24:02,559 --> 00:24:05,840
of recursively

635
00:24:06,000 --> 00:24:08,240
look further into the future let's say

636
00:24:08,240 --> 00:24:10,400
and and aggregate

637
00:24:10,400 --> 00:24:13,279
also expectatory energies from from that

638
00:24:13,279 --> 00:24:14,240
point

639
00:24:14,240 --> 00:24:18,880
and make it a bit more clear um

640
00:24:18,880 --> 00:24:22,240
let's try to visualize it a bit better

641
00:24:22,240 --> 00:24:26,240
so suppose at some current time step d

642
00:24:26,240 --> 00:24:27,679
you're in the states

643
00:24:27,679 --> 00:24:29,919
then basically what you do is you use

644
00:24:29,919 --> 00:24:32,159
your transition model to

645
00:24:32,159 --> 00:24:35,919
say okay given that i follow or c1

646
00:24:35,919 --> 00:24:39,200
um what will be the the next

647
00:24:39,200 --> 00:24:41,440
state and you draw a sample from the

648
00:24:41,440 --> 00:24:43,279
distribution so this is then

649
00:24:43,279 --> 00:24:46,400
s d plus one by following paul c1

650
00:24:46,400 --> 00:24:48,720
and this thing you can repeat for k

651
00:24:48,720 --> 00:24:50,080
times so we

652
00:24:50,080 --> 00:24:52,799
we put in this this k to just have some

653
00:24:52,799 --> 00:24:53,520
kind of

654
00:24:53,520 --> 00:24:57,840
um some force grading of actions

655
00:24:57,840 --> 00:25:01,120
say for example in the case of a driving

656
00:25:01,120 --> 00:25:02,000
robot

657
00:25:02,000 --> 00:25:05,039
it might not make sense to switch action

658
00:25:05,039 --> 00:25:08,320
every uh 10 milliseconds let's say so if

659
00:25:08,320 --> 00:25:08,559
you

660
00:25:08,559 --> 00:25:10,720
if you decide to drive forward you want

661
00:25:10,720 --> 00:25:12,559
to keep on driving forward for at least

662
00:25:12,559 --> 00:25:14,159
some time so that's basically what

663
00:25:14,159 --> 00:25:16,240
where this this k comes from so you

664
00:25:16,240 --> 00:25:17,679
follow the same

665
00:25:17,679 --> 00:25:21,360
uh policy for for some time steps

666
00:25:21,360 --> 00:25:24,400
and you basically sample this end time

667
00:25:24,400 --> 00:25:25,039
so

668
00:25:25,039 --> 00:25:28,240
you you um you repeat

669
00:25:28,240 --> 00:25:31,520
this this process end time so you have

670
00:25:31,520 --> 00:25:35,760
now at each time step and samples for

671
00:25:35,760 --> 00:25:37,919
the kind of states you you think you

672
00:25:37,919 --> 00:25:40,320
will visit after following

673
00:25:40,320 --> 00:25:43,200
the first policy and then if you have a

674
00:25:43,200 --> 00:25:45,520
second policy you can do the same thing

675
00:25:45,520 --> 00:25:49,600
for that policy uh so in this case um

676
00:25:49,600 --> 00:25:53,360
we only consider two potential policies

677
00:25:53,360 --> 00:25:56,240
for instance uh go left or go right

678
00:25:56,240 --> 00:25:56,640
let's say

679
00:25:56,640 --> 00:25:58,400
[Music]

680
00:25:58,400 --> 00:26:01,919
and then of at this point so at

681
00:26:01,919 --> 00:26:04,400
time step t plus k we can basically

682
00:26:04,400 --> 00:26:05,600
repeat

683
00:26:05,600 --> 00:26:08,400
this procedure and say okay what if what

684
00:26:08,400 --> 00:26:10,080
if after k time steps i

685
00:26:10,080 --> 00:26:13,279
switch policy and maybe maybe i first

686
00:26:13,279 --> 00:26:14,480
have to go left and

687
00:26:14,480 --> 00:26:17,760
and before turning right

688
00:26:17,840 --> 00:26:20,880
or maybe i have to turn left twice

689
00:26:20,880 --> 00:26:22,400
so then basically you repeat this

690
00:26:22,400 --> 00:26:26,240
process and this you can basically

691
00:26:26,240 --> 00:26:29,520
keep on adding to the search tree for as

692
00:26:29,520 --> 00:26:30,960
long as

693
00:26:30,960 --> 00:26:33,440
your computation power allows you let's

694
00:26:33,440 --> 00:26:35,600
say

695
00:26:37,200 --> 00:26:39,600
so then how do we calculate the expected

696
00:26:39,600 --> 00:26:40,720
free energy from this

697
00:26:40,720 --> 00:26:44,559
so we we take our uh our formula

698
00:26:44,559 --> 00:26:46,799
so basically what we do is at each time

699
00:26:46,799 --> 00:26:47,600
step

700
00:26:47,600 --> 00:26:50,640
we first use likelihood model to also

701
00:26:50,640 --> 00:26:51,360
predict

702
00:26:51,360 --> 00:26:53,840
what are the observations that i expect

703
00:26:53,840 --> 00:26:55,679
in these states

704
00:26:55,679 --> 00:26:58,640
and you then um look at all your state

705
00:26:58,640 --> 00:27:00,640
samples from a certain time step

706
00:27:00,640 --> 00:27:03,520
and this then gives you this this uh

707
00:27:03,520 --> 00:27:04,240
approximate

708
00:27:04,240 --> 00:27:06,320
gaussian distribution for both the

709
00:27:06,320 --> 00:27:07,600
states and

710
00:27:07,600 --> 00:27:10,159
the observations so you plug these into

711
00:27:10,159 --> 00:27:11,279
the formula

712
00:27:11,279 --> 00:27:14,000
and this then gives you kind of a number

713
00:27:14,000 --> 00:27:15,440
that says this is the

714
00:27:15,440 --> 00:27:18,880
expected free energy if i think i will

715
00:27:18,880 --> 00:27:21,679
i am in states t plus k and i will

716
00:27:21,679 --> 00:27:23,840
follow along with policy

717
00:27:23,840 --> 00:27:26,880
one from uh thereafter and then

718
00:27:26,880 --> 00:27:28,240
basically you can

719
00:27:28,240 --> 00:27:30,559
do this for each each of these sub

720
00:27:30,559 --> 00:27:31,840
branches

721
00:27:31,840 --> 00:27:33,760
and this is then where the recursion

722
00:27:33,760 --> 00:27:36,640
comes in so then we basically

723
00:27:36,640 --> 00:27:39,520
state well i assume that's my active

724
00:27:39,520 --> 00:27:41,679
entrance agent also

725
00:27:41,679 --> 00:27:45,039
at at that time step will

726
00:27:45,039 --> 00:27:48,320
most likely choose the policy with the

727
00:27:48,320 --> 00:27:51,360
the the lowest free energy so basically

728
00:27:51,360 --> 00:27:53,120
we combine

729
00:27:53,120 --> 00:27:56,640
uh the the the free energy for policy

730
00:27:56,640 --> 00:27:57,120
one and

731
00:27:57,120 --> 00:28:00,080
policy two according to uh the rates

732
00:28:00,080 --> 00:28:01,440
that that are provided

733
00:28:01,440 --> 00:28:04,480
using this softmax function so if one of

734
00:28:04,480 --> 00:28:05,440
the

735
00:28:05,440 --> 00:28:09,200
if policy one has a very very low um

736
00:28:09,200 --> 00:28:11,520
expected free energy compared to pulse

737
00:28:11,520 --> 00:28:12,240
c2

738
00:28:12,240 --> 00:28:14,720
then basically only the expected free

739
00:28:14,720 --> 00:28:17,360
energy of policy one will be added

740
00:28:17,360 --> 00:28:20,480
um thereafter if they are kind of the

741
00:28:20,480 --> 00:28:20,880
same

742
00:28:20,880 --> 00:28:24,159
then they will both have kind of a

743
00:28:24,159 --> 00:28:26,960
0.5 weight or if the other one is the

744
00:28:26,960 --> 00:28:28,720
clear winner then it will mainly

745
00:28:28,720 --> 00:28:31,360
be the contribution of this thing but so

746
00:28:31,360 --> 00:28:34,719
we basically combine these

747
00:28:35,039 --> 00:28:37,440
assuming that your agent will at that

748
00:28:37,440 --> 00:28:39,200
point also select

749
00:28:39,200 --> 00:28:42,799
the the policy with the the least free

750
00:28:42,799 --> 00:28:43,360
energy

751
00:28:43,360 --> 00:28:45,679
so now we basically have an estimate of

752
00:28:45,679 --> 00:28:47,919
what will be the expected free energy

753
00:28:47,919 --> 00:28:50,080
for the future given that we are at time

754
00:28:50,080 --> 00:28:52,559
step d plus three

755
00:28:52,559 --> 00:28:55,440
and then we can further uh go up to

756
00:28:55,440 --> 00:28:56,240
three

757
00:28:56,240 --> 00:28:59,520
and so then for um for each branch again

758
00:28:59,520 --> 00:29:01,039
we will use the first part of the

759
00:29:01,039 --> 00:29:02,799
formula to

760
00:29:02,799 --> 00:29:05,440
estimate these these gaussians uh to

761
00:29:05,440 --> 00:29:07,200
calculate the gale divergence and the

762
00:29:07,200 --> 00:29:08,159
entropy term

763
00:29:08,159 --> 00:29:10,480
and then add this together with what we

764
00:29:10,480 --> 00:29:12,000
already had for the

765
00:29:12,000 --> 00:29:15,200
for the the the the remaining part of

766
00:29:15,200 --> 00:29:16,799
the tree basically

767
00:29:16,799 --> 00:29:19,600
and this is uh this is very similar i

768
00:29:19,600 --> 00:29:20,399
think to what

769
00:29:20,399 --> 00:29:23,760
uh uh call fristen uh proposes

770
00:29:23,760 --> 00:29:25,200
sophisticated

771
00:29:25,200 --> 00:29:28,399
uh inference paper so basically that's

772
00:29:28,399 --> 00:29:31,760
at each step in the future you you kind

773
00:29:31,760 --> 00:29:32,399
of

774
00:29:32,399 --> 00:29:35,600
only consider the the free energy of the

775
00:29:35,600 --> 00:29:36,480
branches

776
00:29:36,480 --> 00:29:39,520
that you think will basically be the the

777
00:29:39,520 --> 00:29:41,279
best ones

778
00:29:41,279 --> 00:29:43,520
so in the end you'll end up with an

779
00:29:43,520 --> 00:29:44,880
expected free energy for

780
00:29:44,880 --> 00:29:47,120
both of your policies and you then

781
00:29:47,120 --> 00:29:49,520
select

782
00:29:49,600 --> 00:29:52,840
the best one and start acting

783
00:29:52,840 --> 00:29:54,799
accordingly so

784
00:29:54,799 --> 00:29:57,679
i'll now turn to ozon who will give some

785
00:29:57,679 --> 00:29:59,600
more details on the various

786
00:29:59,600 --> 00:30:01,679
experiments that we did that hopefully

787
00:30:01,679 --> 00:30:03,840
give some more insights on how this

788
00:30:03,840 --> 00:30:08,240
can work in practice so take it away

789
00:30:08,240 --> 00:30:11,360
yeah hi um

790
00:30:11,360 --> 00:30:14,959
i have some echo on my um

791
00:30:15,679 --> 00:30:18,159
maybe it's resolved now yeah sounds fine

792
00:30:18,159 --> 00:30:18,880
thank you

793
00:30:18,880 --> 00:30:22,399
okay um so i'll go briefly

794
00:30:22,399 --> 00:30:24,480
through our initial experiences uh

795
00:30:24,480 --> 00:30:25,600
experiments so

796
00:30:25,600 --> 00:30:28,799
that these are the experiments we did in

797
00:30:28,799 --> 00:30:33,520
like the past one or two years

798
00:30:33,520 --> 00:30:35,919
and so one of the first experiments we

799
00:30:35,919 --> 00:30:38,480
did and reported on was the mountain car

800
00:30:38,480 --> 00:30:41,760
which is a a fairly well-known benchmark

801
00:30:41,760 --> 00:30:42,480
i think

802
00:30:42,480 --> 00:30:45,120
so the goal is to have this under

803
00:30:45,120 --> 00:30:46,960
actuated car so it has not does not have

804
00:30:46,960 --> 00:30:48,640
enough power to reach the top of

805
00:30:48,640 --> 00:30:50,880
the hand mountain but you want to reach

806
00:30:50,880 --> 00:30:52,159
it anyway

807
00:30:52,159 --> 00:30:56,559
so ideally your agent should learn here

808
00:30:56,559 --> 00:30:59,120
that it should first go back there to

809
00:30:59,120 --> 00:31:00,159
the left

810
00:31:00,159 --> 00:31:02,399
to gain momentum to gain enough momentum

811
00:31:02,399 --> 00:31:03,679
so it can

812
00:31:03,679 --> 00:31:06,480
climb the steeper mountain on the right

813
00:31:06,480 --> 00:31:06,960
and

814
00:31:06,960 --> 00:31:08,640
even though this is such a low

815
00:31:08,640 --> 00:31:10,080
dimensional problem it only has

816
00:31:10,080 --> 00:31:11,519
positions and velocities

817
00:31:11,519 --> 00:31:13,120
it is actually a very interesting

818
00:31:13,120 --> 00:31:14,559
benchmark to

819
00:31:14,559 --> 00:31:16,720
experiment upon because there's no

820
00:31:16,720 --> 00:31:19,039
greedy solution so any agent that is

821
00:31:19,039 --> 00:31:21,760
just wants to realize its preferences

822
00:31:21,760 --> 00:31:23,360
immediately will fail at this because it

823
00:31:23,360 --> 00:31:23,919
will always

824
00:31:23,919 --> 00:31:27,279
fail to drive up the mountain

825
00:31:27,279 --> 00:31:29,519
um now for our experiments we made it a

826
00:31:29,519 --> 00:31:32,080
bit more difficult

827
00:31:32,080 --> 00:31:34,559
we made the fully observable mountain

828
00:31:34,559 --> 00:31:36,799
car partially observable

829
00:31:36,799 --> 00:31:38,480
so what we did was we omitted the

830
00:31:38,480 --> 00:31:40,720
velocity information

831
00:31:40,720 --> 00:31:43,200
and only provided some noisy estimates

832
00:31:43,200 --> 00:31:44,640
of the actual position

833
00:31:44,640 --> 00:31:47,279
so the agent actually had to learn two

834
00:31:47,279 --> 00:31:49,120
things it had to learn first of all what

835
00:31:49,120 --> 00:31:49,519
its

836
00:31:49,519 --> 00:31:52,559
precise position was and then also how

837
00:31:52,559 --> 00:31:52,960
this

838
00:31:52,960 --> 00:31:56,080
position relates to the momentum by

839
00:31:56,080 --> 00:32:00,000
its uh velocity and then if we take

840
00:32:00,000 --> 00:32:02,240
if we start from the setup and we train

841
00:32:02,240 --> 00:32:03,039
the model that

842
00:32:03,039 --> 00:32:06,240
tim explained a bit earlier um

843
00:32:06,240 --> 00:32:09,600
in its most basic form you can actually

844
00:32:09,600 --> 00:32:10,480
learn

845
00:32:10,480 --> 00:32:14,240
a state space that closely mimics these

846
00:32:14,240 --> 00:32:17,919
physical constraints of the system

847
00:32:17,919 --> 00:32:20,880
by minimizing energy so if you look at

848
00:32:20,880 --> 00:32:21,519
the

849
00:32:21,519 --> 00:32:25,279
right utmost figure you'll see that

850
00:32:25,279 --> 00:32:28,880
um you see this sinusoidal uh

851
00:32:28,880 --> 00:32:31,919
state space dimensions and these

852
00:32:31,919 --> 00:32:35,679
closely mimic the actual observations of

853
00:32:35,679 --> 00:32:36,720
the real world

854
00:32:36,720 --> 00:32:39,360
in the lower image so as you can see in

855
00:32:39,360 --> 00:32:40,720
the lower image we have the

856
00:32:40,720 --> 00:32:42,960
ground truth in green which is an actual

857
00:32:42,960 --> 00:32:44,240
trajectory through

858
00:32:44,240 --> 00:32:47,440
its position of the cards and then also

859
00:32:47,440 --> 00:32:50,080
our state transition model estimate so

860
00:32:50,080 --> 00:32:54,159
our prior estimates on the position

861
00:32:54,159 --> 00:32:57,200
without observing and then also in the

862
00:32:57,200 --> 00:33:01,279
blue line which is a bit harder to see

863
00:33:01,279 --> 00:33:03,360
you can see the same estimate but now

864
00:33:03,360 --> 00:33:05,200
corrected with the observation so it's

865
00:33:05,200 --> 00:33:06,720
actually just the posterior model

866
00:33:06,720 --> 00:33:08,320
outputs

867
00:33:08,320 --> 00:33:10,399
and you can see these shapes returning

868
00:33:10,399 --> 00:33:11,919
in the state space

869
00:33:11,919 --> 00:33:14,399
which in itself does not say that much

870
00:33:14,399 --> 00:33:15,679
but it gives you at least

871
00:33:15,679 --> 00:33:18,720
an kind of vague idea that at least the

872
00:33:18,720 --> 00:33:20,559
state space is capturing something

873
00:33:20,559 --> 00:33:22,559
relevant for the problem i think there

874
00:33:22,559 --> 00:33:24,000
is one more

875
00:33:24,000 --> 00:33:27,120
animation on this yes so

876
00:33:27,120 --> 00:33:29,039
yeah it's the same conclusion as i said

877
00:33:29,039 --> 00:33:31,200
right now you can predict the future

878
00:33:31,200 --> 00:33:34,880
as you can see in the orange line and

879
00:33:34,880 --> 00:33:37,440
it appears to learn the velocity in its

880
00:33:37,440 --> 00:33:38,720
state space

881
00:33:38,720 --> 00:33:42,320
now if you can go to the next slides

882
00:33:43,200 --> 00:33:46,799
uh yeah um now we want to

883
00:33:46,799 --> 00:33:50,240
actually figure out how how we can use

884
00:33:50,240 --> 00:33:53,200
this model that we learned for active

885
00:33:53,200 --> 00:33:53,760
infants

886
00:33:53,760 --> 00:33:56,240
and typically in our audi would give

887
00:33:56,240 --> 00:33:57,279
some sparse

888
00:33:57,279 --> 00:33:59,919
reward for driving up the mountain but

889
00:33:59,919 --> 00:34:01,919
in our initial experiments we were more

890
00:34:01,919 --> 00:34:02,640
interested

891
00:34:02,640 --> 00:34:06,000
in how an agent could learn from

892
00:34:06,000 --> 00:34:09,440
human observation or demonstrations so

893
00:34:09,440 --> 00:34:12,480
we recorded seven i think yeah or five

894
00:34:12,480 --> 00:34:13,440
sorry

895
00:34:13,440 --> 00:34:16,399
five um human rollout in the environment

896
00:34:16,399 --> 00:34:18,079
just like driving around with the cards

897
00:34:18,079 --> 00:34:20,800
so you go first left and right

898
00:34:20,800 --> 00:34:24,000
and then we push these trajectories

899
00:34:24,000 --> 00:34:25,119
through our models

900
00:34:25,119 --> 00:34:27,760
together to our through our posterior

901
00:34:27,760 --> 00:34:28,960
model to get a preferred state

902
00:34:28,960 --> 00:34:30,159
distribution

903
00:34:30,159 --> 00:34:33,280
so here on this figure you can see the

904
00:34:33,280 --> 00:34:35,599
eight different dimensions how these

905
00:34:35,599 --> 00:34:36,480
evolve through

906
00:34:36,480 --> 00:34:39,520
time if you follow these trajectories

907
00:34:39,520 --> 00:34:41,359
so in the spread of course give gives

908
00:34:41,359 --> 00:34:43,040
you the standard deviation at each time

909
00:34:43,040 --> 00:34:44,800
point for

910
00:34:44,800 --> 00:34:49,520
for that state value and then

911
00:34:49,520 --> 00:34:52,560
if you use this these at this

912
00:34:52,560 --> 00:34:55,760
preferred state distribution and you

913
00:34:55,760 --> 00:35:00,400
calculate the g or this or even only the

914
00:35:00,400 --> 00:35:02,560
kl divergence between your posterior and

915
00:35:02,560 --> 00:35:03,839
your

916
00:35:03,839 --> 00:35:06,880
um preferred distribution for different

917
00:35:06,880 --> 00:35:08,320
trajectories through time

918
00:35:08,320 --> 00:35:11,359
so you hear every different color every

919
00:35:11,359 --> 00:35:13,200
different trajectory is a different

920
00:35:13,200 --> 00:35:16,240
rollout in the environment or imaginary

921
00:35:16,240 --> 00:35:17,680
rollout for the environment

922
00:35:17,680 --> 00:35:19,359
you can see that you can actually use

923
00:35:19,359 --> 00:35:21,520
this this prefer distribution to rank

924
00:35:21,520 --> 00:35:24,560
trajectories according to uh

925
00:35:24,560 --> 00:35:27,440
lowest free energy so you see that the

926
00:35:27,440 --> 00:35:28,720
blue

927
00:35:28,720 --> 00:35:31,200
curve is is the only one that reaches

928
00:35:31,200 --> 00:35:31,839
the top

929
00:35:31,839 --> 00:35:33,680
and is also the one that the model seems

930
00:35:33,680 --> 00:35:36,160
to prefer

931
00:35:36,720 --> 00:35:39,839
and then in the next slide yes

932
00:35:39,839 --> 00:35:43,040
um we experiment a bit what this means

933
00:35:43,040 --> 00:35:44,800
in terms of the actual free energy so

934
00:35:44,800 --> 00:35:48,720
also compensated with the entropy

935
00:35:48,960 --> 00:35:52,240
um and what we did here was we if

936
00:35:52,240 --> 00:35:55,040
we had the agent observe the world for

937
00:35:55,040 --> 00:35:56,880
one time step so we give it an initial

938
00:35:56,880 --> 00:35:59,119
observation to get a

939
00:35:59,119 --> 00:36:02,160
sort of bootstrap latent sample

940
00:36:02,160 --> 00:36:03,839
and then we will only use the prior

941
00:36:03,839 --> 00:36:06,240
model to imagine

942
00:36:06,240 --> 00:36:09,119
what will happen if you follow certain

943
00:36:09,119 --> 00:36:10,560
policies

944
00:36:10,560 --> 00:36:13,440
so here we considered three policies or

945
00:36:13,440 --> 00:36:13,760
like

946
00:36:13,760 --> 00:36:15,440
uh two possible policies that you can

947
00:36:15,440 --> 00:36:17,119
switch at three time steps

948
00:36:17,119 --> 00:36:19,760
so you either go left right right left

949
00:36:19,760 --> 00:36:20,880
right left at

950
00:36:20,880 --> 00:36:23,599
etc or you can start with right and then

951
00:36:23,599 --> 00:36:26,160
these are the blue curves

952
00:36:26,160 --> 00:36:27,839
and what we see that if there is no

953
00:36:27,839 --> 00:36:29,680
initial velocity

954
00:36:29,680 --> 00:36:33,200
then um you see that the

955
00:36:33,200 --> 00:36:35,920
agent imagines that the optimal policy

956
00:36:35,920 --> 00:36:37,359
which is left right right

957
00:36:37,359 --> 00:36:40,400
so first go as far up left and then just

958
00:36:40,400 --> 00:36:43,440
blast your way to the top um

959
00:36:43,440 --> 00:36:45,040
gives actually the left the least amount

960
00:36:45,040 --> 00:36:46,720
of spread and also he believes that this

961
00:36:46,720 --> 00:36:47,680
will

962
00:36:47,680 --> 00:36:49,440
reach the top earlier than any other

963
00:36:49,440 --> 00:36:51,280
policy

964
00:36:51,280 --> 00:36:54,160
inversely if you look at the policies

965
00:36:54,160 --> 00:36:54,400
that

966
00:36:54,400 --> 00:36:59,280
first go right um then you see that

967
00:36:59,280 --> 00:37:01,440
there is still a little and no doesn't

968
00:37:01,440 --> 00:37:02,480
close to no spreads

969
00:37:02,480 --> 00:37:04,640
due to the lack of initial velocity but

970
00:37:04,640 --> 00:37:06,320
the agent already knows that

971
00:37:06,320 --> 00:37:09,760
it's impossible to reach the top

972
00:37:09,760 --> 00:37:13,119
now if you go to the next slides

973
00:37:13,119 --> 00:37:15,200
uh the slide so here we do the exa the

974
00:37:15,200 --> 00:37:16,640
same experiment

975
00:37:16,640 --> 00:37:19,280
but we add some random initial velocity

976
00:37:19,280 --> 00:37:21,040
and again we let the agent observe the

977
00:37:21,040 --> 00:37:22,800
world for one time step

978
00:37:22,800 --> 00:37:24,800
and then let plan according to the same

979
00:37:24,800 --> 00:37:26,960
policies as before

980
00:37:26,960 --> 00:37:29,280
and first of all you see that the agents

981
00:37:29,280 --> 00:37:30,800
has a lot of

982
00:37:30,800 --> 00:37:32,960
much larger spread on its believed

983
00:37:32,960 --> 00:37:34,640
outcomes this is due to this

984
00:37:34,640 --> 00:37:38,160
external extra uncertainty on

985
00:37:38,160 --> 00:37:41,200
what the initial velocity is and also

986
00:37:41,200 --> 00:37:43,680
this initial velocity might render

987
00:37:43,680 --> 00:37:44,640
previously

988
00:37:44,640 --> 00:37:47,599
infeasible policies feasible as you can

989
00:37:47,599 --> 00:37:48,880
see at the bottom because

990
00:37:48,880 --> 00:37:51,119
now if the agent thinks yes my initial

991
00:37:51,119 --> 00:37:52,640
velocity is high enough

992
00:37:52,640 --> 00:37:55,680
even with the one of the more

993
00:37:55,680 --> 00:37:57,200
sub-optimal policies

994
00:37:57,200 --> 00:37:58,640
it might still be possible for me to

995
00:37:58,640 --> 00:38:01,200
reach the top

996
00:38:01,359 --> 00:38:04,640
um and if you go to the next slide

997
00:38:04,640 --> 00:38:06,320
please

998
00:38:06,320 --> 00:38:08,640
here we can then see this in action so

999
00:38:08,640 --> 00:38:10,320
this animation

1000
00:38:10,320 --> 00:38:13,839
we collapse the imagine trajectories to

1001
00:38:13,839 --> 00:38:14,400
the actual

1002
00:38:14,400 --> 00:38:18,560
trajectory and you see that

1003
00:38:18,560 --> 00:38:20,000
in the beginning if we can maybe play it

1004
00:38:20,000 --> 00:38:22,560
again in the beginning

1005
00:38:22,560 --> 00:38:24,400
it believes that more red policies will

1006
00:38:24,400 --> 00:38:26,160
reach the top and then

1007
00:38:26,160 --> 00:38:29,280
as it gains more momentum oh

1008
00:38:29,280 --> 00:38:30,960
it will believe that all blue policies

1009
00:38:30,960 --> 00:38:32,960
will reach the top and even it will know

1010
00:38:32,960 --> 00:38:34,160
that if i now

1011
00:38:34,160 --> 00:38:37,119
go left so i decelerate then i will less

1012
00:38:37,119 --> 00:38:37,680
likely

1013
00:38:37,680 --> 00:38:41,680
reach the top so i think yeah

1014
00:38:41,680 --> 00:38:43,839
so as you can see now he knows that red

1015
00:38:43,839 --> 00:38:46,720
will not reach the top

1016
00:38:46,720 --> 00:38:50,240
and yes

1017
00:38:50,400 --> 00:38:52,560
um then another experiment we did

1018
00:38:52,560 --> 00:38:53,760
building upon this was

1019
00:38:53,760 --> 00:38:56,880
what if we take this same approach but

1020
00:38:56,880 --> 00:38:57,680
now

1021
00:38:57,680 --> 00:39:00,240
we move to the task the kind of problems

1022
00:39:00,240 --> 00:39:01,760
we want to solve this so the high

1023
00:39:01,760 --> 00:39:02,960
dimensional

1024
00:39:02,960 --> 00:39:06,000
uh observations that you cannot model by

1025
00:39:06,000 --> 00:39:07,280
hands

1026
00:39:07,280 --> 00:39:09,280
so we took another opening agm

1027
00:39:09,280 --> 00:39:10,720
environments the

1028
00:39:10,720 --> 00:39:14,240
the car racer and here the goal is to

1029
00:39:14,240 --> 00:39:16,720
drive the red card as you can see on the

1030
00:39:16,720 --> 00:39:18,079
high resolution image on the right

1031
00:39:18,079 --> 00:39:21,599
left um on the road

1032
00:39:21,599 --> 00:39:25,040
for as long as you can and then we

1033
00:39:25,040 --> 00:39:28,480
trained our model on a handful of human

1034
00:39:28,480 --> 00:39:31,760
demonstrations of this and then you can

1035
00:39:31,760 --> 00:39:32,480
see that

1036
00:39:32,480 --> 00:39:34,000
in the reconstructed image on the right

1037
00:39:34,000 --> 00:39:36,800
it already it's even on a handful of

1038
00:39:36,800 --> 00:39:39,280
observations that can learn to predict

1039
00:39:39,280 --> 00:39:40,880
this

1040
00:39:40,880 --> 00:39:42,560
so we did exactly the same thing as

1041
00:39:42,560 --> 00:39:44,960
before and i think this is an animation

1042
00:39:44,960 --> 00:39:46,720
now

1043
00:39:46,720 --> 00:39:49,760
yeah so if you then use the exact

1044
00:39:49,760 --> 00:39:51,520
the the the planning tree that tim

1045
00:39:51,520 --> 00:39:53,119
explained on

1046
00:39:53,119 --> 00:39:55,440
this little card it will have learned to

1047
00:39:55,440 --> 00:39:56,160
that

1048
00:39:56,160 --> 00:39:58,240
the the road so the gray area is

1049
00:39:58,240 --> 00:40:01,200
important and it should stay on this

1050
00:40:01,200 --> 00:40:04,240
now the this agent is a bit more greedy

1051
00:40:04,240 --> 00:40:05,440
since it tries to

1052
00:40:05,440 --> 00:40:08,560
shortcut corners to get quicker on the

1053
00:40:08,560 --> 00:40:11,839
gray part as you can see here

1054
00:40:12,640 --> 00:40:15,440
okay if we can go to the next slide

1055
00:40:15,440 --> 00:40:16,960
maybe

1056
00:40:16,960 --> 00:40:20,079
so now and also an important point here

1057
00:40:20,079 --> 00:40:21,200
is that

1058
00:40:21,200 --> 00:40:24,400
our active entrance approach which is

1059
00:40:24,400 --> 00:40:25,760
model based

1060
00:40:25,760 --> 00:40:29,200
um seems to be a lot uh more data

1061
00:40:29,200 --> 00:40:30,400
efficient

1062
00:40:30,400 --> 00:40:32,319
it seems to be a lot more data efficient

1063
00:40:32,319 --> 00:40:33,839
than for example

1064
00:40:33,839 --> 00:40:37,280
uh a baseline rl agent so we took dqm

1065
00:40:37,280 --> 00:40:39,359
since this is also an off policy

1066
00:40:39,359 --> 00:40:40,480
algorithm

1067
00:40:40,480 --> 00:40:44,160
to be able to compare it kind of

1068
00:40:44,160 --> 00:40:46,560
similar to our approach and as you can

1069
00:40:46,560 --> 00:40:47,200
see in the

1070
00:40:47,200 --> 00:40:51,119
first graph so for the mounting car um

1071
00:40:51,119 --> 00:40:54,800
our model quickly um

1072
00:40:54,800 --> 00:40:58,160
so sorry our our models are in is the

1073
00:40:58,160 --> 00:40:59,440
orange

1074
00:40:59,440 --> 00:41:03,200
our mo quickly learns that at least some

1075
00:41:03,200 --> 00:41:04,720
method to reach the top and then

1076
00:41:04,720 --> 00:41:06,160
afterwards it just improves upon the

1077
00:41:06,160 --> 00:41:07,119
smiles

1078
00:41:07,119 --> 00:41:09,839
due to the sparseness of the rewards dqn

1079
00:41:09,839 --> 00:41:11,040
is not able to

1080
00:41:11,040 --> 00:41:14,560
learn as quickly and even after having

1081
00:41:14,560 --> 00:41:16,640
1000 times more thousand times more

1082
00:41:16,640 --> 00:41:17,920
observations itself

1083
00:41:17,920 --> 00:41:20,160
isn't capable of climbing the mountain

1084
00:41:20,160 --> 00:41:22,079
and even for the car racer it's even

1085
00:41:22,079 --> 00:41:22,560
worse

1086
00:41:22,560 --> 00:41:26,319
so here we trained on seven or ten

1087
00:41:26,319 --> 00:41:29,440
uh rollouts and immediately we're able

1088
00:41:29,440 --> 00:41:31,760
to get a reward of six hundreds

1089
00:41:31,760 --> 00:41:35,920
whilst dqn just fails to get that

1090
00:41:35,920 --> 00:41:38,079
same level of performance even after

1091
00:41:38,079 --> 00:41:39,359
thousands of

1092
00:41:39,359 --> 00:41:42,640
rollouts in the environment so if we can

1093
00:41:42,640 --> 00:41:43,680
go to the next slide

1094
00:41:43,680 --> 00:41:46,720
yeah and then a final experiment i want

1095
00:41:46,720 --> 00:41:49,440
to discuss today is a

1096
00:41:49,440 --> 00:41:52,560
the robotic navigation or like

1097
00:41:52,560 --> 00:41:55,680
maybe more accurately robotic control so

1098
00:41:55,680 --> 00:41:56,319
here we took

1099
00:41:56,319 --> 00:41:59,359
our kuka platform and we mounted some

1100
00:41:59,359 --> 00:42:01,200
sensors on top of it

1101
00:42:01,200 --> 00:42:03,839
and then also put on a laptop for good

1102
00:42:03,839 --> 00:42:06,800
measure to have some compute

1103
00:42:06,800 --> 00:42:09,680
um i don't think the sensors are really

1104
00:42:09,680 --> 00:42:11,200
relevant for what we're going to discuss

1105
00:42:11,200 --> 00:42:12,960
now so

1106
00:42:12,960 --> 00:42:15,119
then we drove around to the robot in our

1107
00:42:15,119 --> 00:42:16,800
lap as you can see on this movie just

1108
00:42:16,800 --> 00:42:19,040
like with the joystick and

1109
00:42:19,040 --> 00:42:22,720
captured a lot of data and we just drove

1110
00:42:22,720 --> 00:42:25,599
up and down the aisles

1111
00:42:25,599 --> 00:42:28,880
with robots now this environment is also

1112
00:42:28,880 --> 00:42:31,440
a bit challenging for robots since all

1113
00:42:31,440 --> 00:42:32,319
these aisles

1114
00:42:32,319 --> 00:42:36,160
are super similar like for a robot

1115
00:42:36,160 --> 00:42:38,400
knowing if it's an aisle one or two is

1116
00:42:38,400 --> 00:42:39,839
nearly the same thing it's very

1117
00:42:39,839 --> 00:42:41,359
difficult to comprehend for the

1118
00:42:41,359 --> 00:42:45,520
machine so then in this slide you see

1119
00:42:45,520 --> 00:42:47,359
what a recording might look like so you

1120
00:42:47,359 --> 00:42:49,200
have a rider a

1121
00:42:49,200 --> 00:42:52,400
lighter and radar feet and some images

1122
00:42:52,400 --> 00:42:54,960
yeah sorry tim this is now the correct

1123
00:42:54,960 --> 00:42:56,240
slide

1124
00:42:56,240 --> 00:42:59,280
and and then the goal is to

1125
00:42:59,280 --> 00:43:03,040
um again train a model that will be able

1126
00:43:03,040 --> 00:43:04,400
to generate

1127
00:43:04,400 --> 00:43:07,200
future observations for the robots i

1128
00:43:07,200 --> 00:43:08,319
don't know if there's an animation on

1129
00:43:08,319 --> 00:43:09,200
the slides

1130
00:43:09,200 --> 00:43:11,680
so yeah so you saw the first the high

1131
00:43:11,680 --> 00:43:12,880
resolution image was the real

1132
00:43:12,880 --> 00:43:13,839
observation

1133
00:43:13,839 --> 00:43:16,640
and this is then what the model thinks

1134
00:43:16,640 --> 00:43:17,760
will happen

1135
00:43:17,760 --> 00:43:20,079
if the robot first turns right and then

1136
00:43:20,079 --> 00:43:22,319
continues to drive

1137
00:43:22,319 --> 00:43:25,359
the little ghost artifact you saw a bit

1138
00:43:25,359 --> 00:43:28,560
a couple of frames ago so yeah we'll

1139
00:43:28,560 --> 00:43:28,960
first

1140
00:43:28,960 --> 00:43:32,000
look at it again so we drive and then it

1141
00:43:32,000 --> 00:43:33,760
will turn and suddenly you will see a

1142
00:43:33,760 --> 00:43:34,240
ghost

1143
00:43:34,240 --> 00:43:38,880
them appear um

1144
00:43:38,880 --> 00:43:41,920
this is because the model doesn't

1145
00:43:41,920 --> 00:43:43,599
actually know what will happen it can

1146
00:43:43,599 --> 00:43:44,240
only

1147
00:43:44,240 --> 00:43:47,440
try to guess based on its previously

1148
00:43:47,440 --> 00:43:49,520
learned experiences in the model and

1149
00:43:49,520 --> 00:43:51,119
there's a lot of people walking around

1150
00:43:51,119 --> 00:43:52,079
in the data set

1151
00:43:52,079 --> 00:43:54,880
so there was a some chance that somebody

1152
00:43:54,880 --> 00:43:56,079
would be walking there

1153
00:43:56,079 --> 00:43:58,720
so it just might imagine that there's

1154
00:43:58,720 --> 00:44:00,480
somebody there

1155
00:44:00,480 --> 00:44:04,319
then maybe if we go to the next slides

1156
00:44:04,319 --> 00:44:07,520
um this is also an animation

1157
00:44:07,520 --> 00:44:09,280
so here you can see for example how

1158
00:44:09,280 --> 00:44:12,160
these imaginary samples deviate

1159
00:44:12,160 --> 00:44:13,760
and this is also the reason why we need

1160
00:44:13,760 --> 00:44:16,319
this sampling and so the the different

1161
00:44:16,319 --> 00:44:18,240
sampling and the planning tree

1162
00:44:18,240 --> 00:44:20,640
four different outcomes so you see that

1163
00:44:20,640 --> 00:44:22,880
given the same starting position and

1164
00:44:22,880 --> 00:44:24,240
observation

1165
00:44:24,240 --> 00:44:26,720
the model learns that turning left might

1166
00:44:26,720 --> 00:44:28,319
have different outcomes depending where

1167
00:44:28,319 --> 00:44:29,040
it is in there

1168
00:44:29,040 --> 00:44:30,800
in which either this and we wear it in

1169
00:44:30,800 --> 00:44:33,200
the air for example the top right

1170
00:44:33,200 --> 00:44:35,440
then it the robot imagines that it is at

1171
00:44:35,440 --> 00:44:36,400
the end of the aisle

1172
00:44:36,400 --> 00:44:38,640
whilst in the bottom two it imagines

1173
00:44:38,640 --> 00:44:40,480
that it is in the aisle so it just

1174
00:44:40,480 --> 00:44:42,000
imagines some

1175
00:44:42,000 --> 00:44:44,880
stuff on the racks

1176
00:44:45,520 --> 00:44:49,119
then here is and how we can evaluate the

1177
00:44:49,119 --> 00:44:50,400
policies

1178
00:44:50,400 --> 00:44:52,640
so we typically we provided three

1179
00:44:52,640 --> 00:44:54,160
possible policies turn left fourth and

1180
00:44:54,160 --> 00:44:55,040
turn right

1181
00:44:55,040 --> 00:44:56,480
and then you can imagine what all these

1182
00:44:56,480 --> 00:44:59,839
things will do in the environments

1183
00:44:59,839 --> 00:45:05,440
and then similarly as before you can

1184
00:45:05,440 --> 00:45:08,480
calculate the g and select the one that

1185
00:45:08,480 --> 00:45:09,760
will most likely

1186
00:45:09,760 --> 00:45:14,960
bring you to your preferred sequences

1187
00:45:16,839 --> 00:45:18,720
um

1188
00:45:18,720 --> 00:45:21,839
yeah right so also the nice thing of our

1189
00:45:21,839 --> 00:45:22,880
model

1190
00:45:22,880 --> 00:45:26,480
is that you can

1191
00:45:26,480 --> 00:45:29,040
you can uh because of its because it's a

1192
00:45:29,040 --> 00:45:30,560
neural network you can put

1193
00:45:30,560 --> 00:45:33,359
multiple types of observation into your

1194
00:45:33,359 --> 00:45:35,200
posterior model you can fuse them

1195
00:45:35,200 --> 00:45:37,920
in various ways so what you can see here

1196
00:45:37,920 --> 00:45:38,800
is that

1197
00:45:38,800 --> 00:45:42,079
similar to the camera feeds the robot

1198
00:45:42,079 --> 00:45:43,920
will also learn the effect for example

1199
00:45:43,920 --> 00:45:47,359
in a lighter scan and also it will learn

1200
00:45:47,359 --> 00:45:49,280
the effects on the velocity bins in a

1201
00:45:49,280 --> 00:45:50,160
radar

1202
00:45:50,160 --> 00:45:53,599
scan and this gives you of course

1203
00:45:53,599 --> 00:45:55,599
extra robustness in your planning

1204
00:45:55,599 --> 00:45:56,720
because you can

1205
00:45:56,720 --> 00:46:00,560
now reason on multiple modalities

1206
00:46:00,560 --> 00:46:04,640
then maybe in the next slides um

1207
00:46:04,640 --> 00:46:06,720
there are of course still some

1208
00:46:06,720 --> 00:46:07,839
limitations to

1209
00:46:07,839 --> 00:46:10,240
using robotic to doing robotic control

1210
00:46:10,240 --> 00:46:11,440
this way

1211
00:46:11,440 --> 00:46:15,280
first of all our robot is extremely

1212
00:46:15,280 --> 00:46:19,040
short-sighted in time

1213
00:46:19,040 --> 00:46:22,240
it can only learn to predict as far

1214
00:46:22,240 --> 00:46:24,240
as the length of the sequences we

1215
00:46:24,240 --> 00:46:26,400
provided during training

1216
00:46:26,400 --> 00:46:29,040
and also the longer you roll out the

1217
00:46:29,040 --> 00:46:30,240
larger your

1218
00:46:30,240 --> 00:46:31,680
search tree becomes the more

1219
00:46:31,680 --> 00:46:33,680
computational

1220
00:46:33,680 --> 00:46:37,040
limits you will reach so

1221
00:46:37,040 --> 00:46:39,280
this is also then an area we are now

1222
00:46:39,280 --> 00:46:42,800
actively working on

1223
00:46:42,800 --> 00:46:46,160
um then currently our models still

1224
00:46:46,160 --> 00:46:48,240
require that we pre-record the data set

1225
00:46:48,240 --> 00:46:49,520
so

1226
00:46:49,520 --> 00:46:51,200
our models require that we drive around

1227
00:46:51,200 --> 00:46:52,640
ourselves and then

1228
00:46:52,640 --> 00:46:55,520
fit the model so there's also a point

1229
00:46:55,520 --> 00:46:55,920
we're

1230
00:46:55,920 --> 00:46:58,800
currently at this moment working on and

1231
00:46:58,800 --> 00:46:59,440
then

1232
00:46:59,440 --> 00:47:02,160
tying into this our models currently do

1233
00:47:02,160 --> 00:47:03,760
not really know how to explore

1234
00:47:03,760 --> 00:47:07,119
whilst there's probably a sensible way

1235
00:47:07,119 --> 00:47:08,720
to do exploration based

1236
00:47:08,720 --> 00:47:11,920
on the free energy principle since your

1237
00:47:11,920 --> 00:47:15,760
mobile uncertainty can be baked in

1238
00:47:15,839 --> 00:47:18,240
i think i don't know if you have any

1239
00:47:18,240 --> 00:47:21,439
more slides actually now

1240
00:47:21,520 --> 00:47:24,640
no desserts or maybe it's insane for

1241
00:47:24,640 --> 00:47:26,480
questions

1242
00:47:26,480 --> 00:47:30,079
awesome you can um unshare

1243
00:47:30,079 --> 00:47:33,280
and we can ask some questions so i

1244
00:47:33,280 --> 00:47:35,280
wrote down a bunch of stuff and also

1245
00:47:35,280 --> 00:47:36,800
anybody who's

1246
00:47:36,800 --> 00:47:40,160
watching live please ask some questions

1247
00:47:40,160 --> 00:47:43,280
so nice presentation though and

1248
00:47:43,280 --> 00:47:47,040
awesome very instructive videos

1249
00:47:47,040 --> 00:47:48,800
hopefully made us think made us laugh a

1250
00:47:48,800 --> 00:47:50,480
little bit when it cut

1251
00:47:50,480 --> 00:47:52,319
corners so maybe just a starting

1252
00:47:52,319 --> 00:47:53,599
question while people are

1253
00:47:53,599 --> 00:47:56,720
writing their question um what

1254
00:47:56,720 --> 00:47:59,839
brought you to be studying this topic

1255
00:47:59,839 --> 00:48:02,480
in this way were you coming from active

1256
00:48:02,480 --> 00:48:03,520
inference and saw

1257
00:48:03,520 --> 00:48:06,160
robotics as an interesting application

1258
00:48:06,160 --> 00:48:06,559
or

1259
00:48:06,559 --> 00:48:08,559
were you in the area of robotics and

1260
00:48:08,559 --> 00:48:10,240
then found active inference to be

1261
00:48:10,240 --> 00:48:13,040
a useful model

1262
00:48:13,359 --> 00:48:16,400
yeah so basically we were in the area of

1263
00:48:16,400 --> 00:48:20,480
um of robotics and reports of learning

1264
00:48:20,480 --> 00:48:24,960
and we were working on building

1265
00:48:24,960 --> 00:48:26,480
better low dimensional state

1266
00:48:26,480 --> 00:48:28,160
representations

1267
00:48:28,160 --> 00:48:31,760
to feed into a reinforcement learning

1268
00:48:31,760 --> 00:48:34,319
algorithm let's say that was our initial

1269
00:48:34,319 --> 00:48:34,960
idea

1270
00:48:34,960 --> 00:48:38,400
so just building representations

1271
00:48:38,400 --> 00:48:41,040
or for better reinforcement learning and

1272
00:48:41,040 --> 00:48:43,040
now we stumbled upon the

1273
00:48:43,040 --> 00:48:45,200
active inference framework which which

1274
00:48:45,200 --> 00:48:47,440
basically not only gave us a way

1275
00:48:47,440 --> 00:48:49,839
of

1276
00:48:50,559 --> 00:48:54,319
of how to uh to build degenerative

1277
00:48:54,319 --> 00:48:55,200
models because

1278
00:48:55,200 --> 00:48:58,960
basically we we found ourselves the

1279
00:48:58,960 --> 00:49:01,920
let's say the free energy of the that we

1280
00:49:01,920 --> 00:49:04,000
were basically already doing that

1281
00:49:04,000 --> 00:49:07,119
but we saw that it also gives us in the

1282
00:49:07,119 --> 00:49:09,839
same mathematical framework a way of

1283
00:49:09,839 --> 00:49:11,680
how to project these things to the

1284
00:49:11,680 --> 00:49:13,760
future and use these for planning

1285
00:49:13,760 --> 00:49:16,720
therefore resolving ambiguity and also

1286
00:49:16,720 --> 00:49:17,440
for

1287
00:49:17,440 --> 00:49:20,240
um scoring novelty and all these nice

1288
00:49:20,240 --> 00:49:22,400
properties that are basically lacking

1289
00:49:22,400 --> 00:49:25,599
in in rl so that's why we we basically

1290
00:49:25,599 --> 00:49:26,800
started

1291
00:49:26,800 --> 00:49:29,520
digging into this mathematical framework

1292
00:49:29,520 --> 00:49:30,880
to

1293
00:49:30,880 --> 00:49:33,040
go through all the the papers of call

1294
00:49:33,040 --> 00:49:34,079
and see how

1295
00:49:34,079 --> 00:49:36,480
all the ends are tied together and and

1296
00:49:36,480 --> 00:49:37,680
see whether this

1297
00:49:37,680 --> 00:49:40,559
would still work if you if you don't

1298
00:49:40,559 --> 00:49:41,359
have

1299
00:49:41,359 --> 00:49:44,000
your your state space defined the prompt

1300
00:49:44,000 --> 00:49:45,440
but you just learn it from

1301
00:49:45,440 --> 00:49:47,599
from data so that's how you start this

1302
00:49:47,599 --> 00:49:48,880
endeavor and that's

1303
00:49:48,880 --> 00:49:52,160
pretty much where we are at this point

1304
00:49:52,160 --> 00:49:56,799
and still investigating it further

1305
00:49:56,960 --> 00:49:59,119
awesome that was gonna be my second

1306
00:49:59,119 --> 00:50:00,000
question was like

1307
00:50:00,000 --> 00:50:02,640
what differences or advantages would you

1308
00:50:02,640 --> 00:50:04,240
describe for active inference

1309
00:50:04,240 --> 00:50:06,720
over reinforcement learning or other

1310
00:50:06,720 --> 00:50:08,319
machine learning frameworks

1311
00:50:08,319 --> 00:50:09,920
if you answered it in previously that's

1312
00:50:09,920 --> 00:50:11,599
great or do you want to add any other

1313
00:50:11,599 --> 00:50:16,000
thoughts yeah i think

1314
00:50:16,000 --> 00:50:18,410
i think the nice part is that

1315
00:50:18,410 --> 00:50:21,040
[Music]

1316
00:50:21,040 --> 00:50:24,480
you you automatically get the

1317
00:50:24,480 --> 00:50:27,200
the nice properties of of resolving

1318
00:50:27,200 --> 00:50:28,640
ambiguity and of

1319
00:50:28,640 --> 00:50:32,480
um potentially exploration if you also

1320
00:50:32,480 --> 00:50:34,800
um estimate posterior distributions over

1321
00:50:34,800 --> 00:50:36,640
your your parameters for example

1322
00:50:36,640 --> 00:50:40,559
so these are very interesting properties

1323
00:50:40,559 --> 00:50:44,160
uh mathematically however it's still

1324
00:50:44,160 --> 00:50:46,319
um it's there's still a gap to to

1325
00:50:46,319 --> 00:50:47,280
actually

1326
00:50:47,280 --> 00:50:50,480
um get this out of um

1327
00:50:50,480 --> 00:50:52,480
these real-world cases if you if you if

1328
00:50:52,480 --> 00:50:55,119
you don't have the degenerative model

1329
00:50:55,119 --> 00:50:57,760
uh predefined let's say so there are

1330
00:50:57,760 --> 00:50:59,119
still some challenges

1331
00:50:59,119 --> 00:51:01,760
but the theory at least this is is very

1332
00:51:01,760 --> 00:51:03,040
much appealing

1333
00:51:03,040 --> 00:51:05,920
um and i but i think if you look at

1334
00:51:05,920 --> 00:51:07,920
what's going on at the url side that we

1335
00:51:07,920 --> 00:51:09,040
refer to inside

1336
00:51:09,040 --> 00:51:12,079
then there's not that big of a gap

1337
00:51:12,079 --> 00:51:13,119
between

1338
00:51:13,119 --> 00:51:15,359
the two wheels i think because you get

1339
00:51:15,359 --> 00:51:17,760
all the curiosity bonuses that they try

1340
00:51:17,760 --> 00:51:18,800
to come up with

1341
00:51:18,800 --> 00:51:21,040
in in reinforcement learning and if you

1342
00:51:21,040 --> 00:51:22,720
look at the model based

1343
00:51:22,720 --> 00:51:24,400
stuff from like the niger hoffner with

1344
00:51:24,400 --> 00:51:26,319
this dreamer approach then everything is

1345
00:51:26,319 --> 00:51:27,520
kind of

1346
00:51:27,520 --> 00:51:30,240
similarly converging to it's a good idea

1347
00:51:30,240 --> 00:51:32,079
to build a model of your world

1348
00:51:32,079 --> 00:51:34,240
and get more sample efficiency and it

1349
00:51:34,240 --> 00:51:35,839
seems like a good idea to have some

1350
00:51:35,839 --> 00:51:37,119
planning in there

1351
00:51:37,119 --> 00:51:39,520
and maybe there is some and there's some

1352
00:51:39,520 --> 00:51:40,160
gaining

1353
00:51:40,160 --> 00:51:43,280
curiosity and so you you see that a lot

1354
00:51:43,280 --> 00:51:46,160
in a lot of different independent

1355
00:51:46,160 --> 00:51:47,599
research tracks

1356
00:51:47,599 --> 00:51:51,520
we all converge along the same lines and

1357
00:51:51,520 --> 00:51:54,240
i think what's what is so appealing to

1358
00:51:54,240 --> 00:51:56,240
active inference is that basically

1359
00:51:56,240 --> 00:51:58,319
it brings this all together from from a

1360
00:51:58,319 --> 00:51:59,520
single principle

1361
00:51:59,520 --> 00:52:02,640
which makes it a a very nice framework

1362
00:52:02,640 --> 00:52:03,599
to

1363
00:52:03,599 --> 00:52:06,800
work with i think anything to add on

1364
00:52:06,800 --> 00:52:08,480
that ozone

1365
00:52:08,480 --> 00:52:10,480
oh yeah i was before tim mentioned that

1366
00:52:10,480 --> 00:52:11,920
i was already thinking along the lines

1367
00:52:11,920 --> 00:52:12,160
of

1368
00:52:12,160 --> 00:52:15,680
the work of the ninja however so i mean

1369
00:52:15,680 --> 00:52:17,680
if you look at his models and i think

1370
00:52:17,680 --> 00:52:19,440
that is currently

1371
00:52:19,440 --> 00:52:21,119
almost state of the art and mobile based

1372
00:52:21,119 --> 00:52:22,880
rl then

1373
00:52:22,880 --> 00:52:24,960
you'll find that the models they are

1374
00:52:24,960 --> 00:52:27,359
building are very similar to the models

1375
00:52:27,359 --> 00:52:29,599
we are building or other active

1376
00:52:29,599 --> 00:52:31,760
infrastructures are building

1377
00:52:31,760 --> 00:52:34,640
so yeah i mean it makes sense that all

1378
00:52:34,640 --> 00:52:36,160
these

1379
00:52:36,160 --> 00:52:38,880
approaches converge on a single id of

1380
00:52:38,880 --> 00:52:41,680
the idea works

1381
00:52:42,160 --> 00:52:44,800
yep very interesting that like plan to

1382
00:52:44,800 --> 00:52:47,359
dream and dream or imagine so that you

1383
00:52:47,359 --> 00:52:48,160
can sample

1384
00:52:48,160 --> 00:52:51,119
appropriately why put that as a second

1385
00:52:51,119 --> 00:52:52,800
layer on the model or have to

1386
00:52:52,800 --> 00:52:53,760
incentivize it

1387
00:52:53,760 --> 00:52:56,800
in a sort of ad hoc way why not have

1388
00:52:56,800 --> 00:52:58,880
that be the basis of the model so that's

1389
00:52:58,880 --> 00:53:00,160
a very nice

1390
00:53:00,160 --> 00:53:03,440
point so dean in the chat

1391
00:53:03,440 --> 00:53:06,000
asks have the authors heard of the

1392
00:53:06,000 --> 00:53:07,599
missionary and cannibals

1393
00:53:07,599 --> 00:53:10,720
game slash problem which is moving um

1394
00:53:10,720 --> 00:53:13,200
two kinds of mutually incompatible

1395
00:53:13,200 --> 00:53:14,880
agents back and forth from

1396
00:53:14,880 --> 00:53:17,680
two sides of a river and um if they have

1397
00:53:17,680 --> 00:53:18,480
heard of this or

1398
00:53:18,480 --> 00:53:21,119
thought of any kind of analogous cases

1399
00:53:21,119 --> 00:53:24,640
do you see any applications

1400
00:53:26,960 --> 00:53:28,960
yeah and i haven't heard of the game

1401
00:53:28,960 --> 00:53:30,000
before i think

1402
00:53:30,000 --> 00:53:32,000
it's probably similar to the like

1403
00:53:32,000 --> 00:53:33,440
crossing the river with a chicken the

1404
00:53:33,440 --> 00:53:34,720
fox and a

1405
00:53:34,720 --> 00:53:36,559
goat or what yes what was it yeah

1406
00:53:36,559 --> 00:53:38,400
there's like animal versions there's all

1407
00:53:38,400 --> 00:53:39,839
kinds of versions of this one but

1408
00:53:39,839 --> 00:53:41,200
going back and forth with different

1409
00:53:41,200 --> 00:53:43,119
kinds of incompatible agents and you

1410
00:53:43,119 --> 00:53:44,079
need to sort of

1411
00:53:44,079 --> 00:53:46,559
go to the left before you can make it up

1412
00:53:46,559 --> 00:53:48,079
the hill but it's a little bit of a

1413
00:53:48,079 --> 00:53:49,520
different setting so what does that make

1414
00:53:49,520 --> 00:53:52,000
you think of

1415
00:53:52,559 --> 00:53:54,880
i haven't actually really considered it

1416
00:53:54,880 --> 00:53:57,920
for our models but it might be

1417
00:53:57,920 --> 00:53:59,520
if we find a way to mod in an

1418
00:53:59,520 --> 00:54:00,960
environment and maybe

1419
00:54:00,960 --> 00:54:04,240
collect some data on it yeah i think

1420
00:54:04,240 --> 00:54:06,960
this is a problem that is very nicely

1421
00:54:06,960 --> 00:54:08,480
suited for

1422
00:54:08,480 --> 00:54:11,119
for doing it let's say the the vanilla

1423
00:54:11,119 --> 00:54:12,400
way where you basically

1424
00:54:12,400 --> 00:54:14,880
write out all the different states that

1425
00:54:14,880 --> 00:54:16,000
can happen

1426
00:54:16,000 --> 00:54:17,920
and kind of observe the outcomes that

1427
00:54:17,920 --> 00:54:19,200
you can have

1428
00:54:19,200 --> 00:54:22,559
so i i think you could actually

1429
00:54:22,559 --> 00:54:25,599
formalize it in such a way and then

1430
00:54:25,599 --> 00:54:28,559
run an active instrument simulation on

1431
00:54:28,559 --> 00:54:29,359
on that

1432
00:54:29,359 --> 00:54:33,280
and see and see what happens so

1433
00:54:33,280 --> 00:54:36,880
that's less of our interest because

1434
00:54:36,880 --> 00:54:39,280
in our cases we are mainly interested in

1435
00:54:39,280 --> 00:54:40,319
what if your

1436
00:54:40,319 --> 00:54:42,240
observations are so high dimensional

1437
00:54:42,240 --> 00:54:43,359
that you cannot even

1438
00:54:43,359 --> 00:54:46,480
start thinking about writing out

1439
00:54:46,480 --> 00:54:49,520
the the joint model let's say and the

1440
00:54:49,520 --> 00:54:50,559
only thing you can do

1441
00:54:50,559 --> 00:54:53,119
is interact with your environment and

1442
00:54:53,119 --> 00:54:53,920
try to

1443
00:54:53,920 --> 00:54:56,960
try to learn it from from the data

1444
00:54:56,960 --> 00:55:01,040
which is a slightly different take on

1445
00:55:01,040 --> 00:55:05,280
on the on the active inference problem

1446
00:55:05,280 --> 00:55:08,640
great another question is

1447
00:55:08,640 --> 00:55:11,839
you are all deploying these models sort

1448
00:55:11,839 --> 00:55:12,160
of

1449
00:55:12,160 --> 00:55:15,680
real time with physical agents embodied

1450
00:55:15,680 --> 00:55:18,720
agents so what surprised you or what was

1451
00:55:18,720 --> 00:55:20,160
interesting to note

1452
00:55:20,160 --> 00:55:23,200
as far as going from the simulation only

1453
00:55:23,200 --> 00:55:25,040
where you can sort of put everything in

1454
00:55:25,040 --> 00:55:26,799
a box and know exactly what's going to

1455
00:55:26,799 --> 00:55:27,839
influence what

1456
00:55:27,839 --> 00:55:30,319
to the world of embodiment where i don't

1457
00:55:30,319 --> 00:55:32,400
know some dust could get into the robot

1458
00:55:32,400 --> 00:55:32,720
or

1459
00:55:32,720 --> 00:55:36,079
i saw a person walk by so what

1460
00:55:36,079 --> 00:55:39,119
comes into play when you actually deploy

1461
00:55:39,119 --> 00:55:41,359
physically and how does the model deal

1462
00:55:41,359 --> 00:55:43,680
with that

1463
00:55:43,839 --> 00:55:46,400
for me it's actually the thing i like

1464
00:55:46,400 --> 00:55:47,280
well first we

1465
00:55:47,280 --> 00:55:49,440
i played around a lot with the mountain

1466
00:55:49,440 --> 00:55:50,480
car and the car racer

1467
00:55:50,480 --> 00:55:52,640
but the first thing actually was a real

1468
00:55:52,640 --> 00:55:54,319
hurdle for me personally was

1469
00:55:54,319 --> 00:55:56,240
deploying it on a real robot you

1470
00:55:56,240 --> 00:55:58,079
suddenly have all these

1471
00:55:58,079 --> 00:56:00,160
uh hardware constraints like you can you

1472
00:56:00,160 --> 00:56:01,520
don't have infinite memory you don't

1473
00:56:01,520 --> 00:56:03,839
have server great compute anymore

1474
00:56:03,839 --> 00:56:07,599
and you all have to you have to yeah

1475
00:56:07,599 --> 00:56:10,480
fit it for example i think tim and i

1476
00:56:10,480 --> 00:56:12,160
spent a lot of time to make a demo

1477
00:56:12,160 --> 00:56:12,880
working

1478
00:56:12,880 --> 00:56:15,839
where we could roll this out real time

1479
00:56:15,839 --> 00:56:16,319
and

1480
00:56:16,319 --> 00:56:18,000
just the hardware constraints of doing

1481
00:56:18,000 --> 00:56:19,920
something as complex as active inference

1482
00:56:19,920 --> 00:56:20,880
real time

1483
00:56:20,880 --> 00:56:23,520
on a real power constraint robot is

1484
00:56:23,520 --> 00:56:24,480
another challenge

1485
00:56:24,480 --> 00:56:29,040
in and of itself yeah so i think

1486
00:56:29,040 --> 00:56:32,480
uh if if the question was what uh

1487
00:56:32,480 --> 00:56:34,960
what do you get from uh from doing it on

1488
00:56:34,960 --> 00:56:36,160
the real system well a lot of

1489
00:56:36,160 --> 00:56:38,240
frustration and pain i think is the

1490
00:56:38,240 --> 00:56:39,119
answer

1491
00:56:39,119 --> 00:56:41,520
but likewise if we then if it doesn't

1492
00:56:41,520 --> 00:56:43,040
works then the

1493
00:56:43,040 --> 00:56:46,079
gratitude is the satisfaction is so much

1494
00:56:46,079 --> 00:56:46,480
higher

1495
00:56:46,480 --> 00:56:49,760
so i i still remember ozone and me

1496
00:56:49,760 --> 00:56:52,079
cheering in the lab because we gave the

1497
00:56:52,079 --> 00:56:54,400
robot a preferred state of being like

1498
00:56:54,400 --> 00:56:56,240
nicely in the center of the ale

1499
00:56:56,240 --> 00:56:58,799
and it was actually moving along the ale

1500
00:56:58,799 --> 00:57:00,240
and then at the very end

1501
00:57:00,240 --> 00:57:02,640
they decided hmm this is not the center

1502
00:57:02,640 --> 00:57:04,720
of the animal and it just made a 360

1503
00:57:04,720 --> 00:57:05,440
degree turn

1504
00:57:05,440 --> 00:57:07,119
and started driving back and we were

1505
00:57:07,119 --> 00:57:09,920
like oh this is awesome

1506
00:57:09,920 --> 00:57:12,480
so i think the there's a lot of pain

1507
00:57:12,480 --> 00:57:14,640
frustration to get it work but then once

1508
00:57:14,640 --> 00:57:16,720
something comes out then then the

1509
00:57:16,720 --> 00:57:18,799
satisfaction is so much higher than

1510
00:57:18,799 --> 00:57:20,799
than when you see a mountain car which

1511
00:57:20,799 --> 00:57:22,640
reaches also

1512
00:57:22,640 --> 00:57:25,119
interesting you could set up a physical

1513
00:57:25,119 --> 00:57:26,000
valley

1514
00:57:26,000 --> 00:57:28,000
maybe make a physical mountain car

1515
00:57:28,000 --> 00:57:29,920
because there's so much comparison

1516
00:57:29,920 --> 00:57:33,359
of the software realization but

1517
00:57:33,359 --> 00:57:35,280
maybe that would be even taking it to

1518
00:57:35,280 --> 00:57:36,720
the next level

1519
00:57:36,720 --> 00:57:39,359
so another um thing that you talked

1520
00:57:39,359 --> 00:57:40,480
about repeatedly

1521
00:57:40,480 --> 00:57:43,280
maybe even in every example was actually

1522
00:57:43,280 --> 00:57:44,720
training the model

1523
00:57:44,720 --> 00:57:48,079
from just a handful of human cases like

1524
00:57:48,079 --> 00:57:49,520
you drove the car

1525
00:57:49,520 --> 00:57:51,440
you had people play the mountain car

1526
00:57:51,440 --> 00:57:52,640
game so

1527
00:57:52,640 --> 00:57:55,119
what exactly is happening there and how

1528
00:57:55,119 --> 00:57:56,000
does the model

1529
00:57:56,000 --> 00:57:58,000
like not over fit to the few

1530
00:57:58,000 --> 00:57:59,760
trajectories you show

1531
00:57:59,760 --> 00:58:01,760
or not just say hey you only gave me

1532
00:58:01,760 --> 00:58:03,200
three what's the deal

1533
00:58:03,200 --> 00:58:05,040
with these three totally different

1534
00:58:05,040 --> 00:58:07,440
trajectories like what exactly is being

1535
00:58:07,440 --> 00:58:09,680
learned or updated in the model when you

1536
00:58:09,680 --> 00:58:13,759
provide just a handful of human examples

1537
00:58:17,119 --> 00:58:18,400
i thought then we're going to answer

1538
00:58:18,400 --> 00:58:23,839
this one

1539
00:58:24,720 --> 00:58:27,839
yeah i think overfitting is is uh

1540
00:58:27,839 --> 00:58:32,000
is clearly an issue um

1541
00:58:32,000 --> 00:58:34,240
you you're no matter what you do you're

1542
00:58:34,240 --> 00:58:36,319
constrained kind of to the the data you

1543
00:58:36,319 --> 00:58:38,079
provide to the model so it cannot really

1544
00:58:38,079 --> 00:58:39,040
learn anything

1545
00:58:39,040 --> 00:58:42,160
else than than what it discovers so

1546
00:58:42,160 --> 00:58:44,240
that that's also what we pointed out at

1547
00:58:44,240 --> 00:58:46,160
the last slide that's a severe

1548
00:58:46,160 --> 00:58:47,839
limitation of our current

1549
00:58:47,839 --> 00:58:51,359
current work clearly but there is

1550
00:58:51,359 --> 00:58:54,640
um there is no other way when there is a

1551
00:58:54,640 --> 00:58:55,920
real robot involved

1552
00:58:55,920 --> 00:58:58,640
to get started say so that's the easier

1553
00:58:58,640 --> 00:59:01,040
way to get started so that's mainly the

1554
00:59:01,040 --> 00:59:03,359
driver but at the moment we're actually

1555
00:59:03,359 --> 00:59:05,280
working both in simulation but also on

1556
00:59:05,280 --> 00:59:06,720
real robots to see

1557
00:59:06,720 --> 00:59:09,280
can we actually get these systems to to

1558
00:59:09,280 --> 00:59:11,040
decide how to

1559
00:59:11,040 --> 00:59:14,400
um gather their own experience uh what

1560
00:59:14,400 --> 00:59:14,720
is

1561
00:59:14,720 --> 00:59:16,880
interesting to learn from because that's

1562
00:59:16,880 --> 00:59:18,240
actually one of the

1563
00:59:18,240 --> 00:59:21,280
to um shortcut to one of your previous

1564
00:59:21,280 --> 00:59:22,000
questions

1565
00:59:22,000 --> 00:59:24,559
what does active entrance give you well

1566
00:59:24,559 --> 00:59:26,000
that it actually can

1567
00:59:26,000 --> 00:59:27,839
can deal with these these kind of things

1568
00:59:27,839 --> 00:59:29,760
like my my robot needs to collect its

1569
00:59:29,760 --> 00:59:31,359
own experience what will you do that

1570
00:59:31,359 --> 00:59:32,880
would be always the same or

1571
00:59:32,880 --> 00:59:35,359
the explorer or this kind of thing so

1572
00:59:35,359 --> 00:59:36,480
these are really

1573
00:59:36,480 --> 00:59:39,359
some active areas of research but then

1574
00:59:39,359 --> 00:59:40,640
so to come back to

1575
00:59:40,640 --> 00:59:43,359
the overfitting problem so one thing

1576
00:59:43,359 --> 00:59:44,000
that

1577
00:59:44,000 --> 00:59:45,599
mitigates overfitting a bit is that the

1578
00:59:45,599 --> 00:59:47,040
the fact that you have all these

1579
00:59:47,040 --> 00:59:47,680
stochastics

1580
00:59:47,680 --> 00:59:49,839
even in the system it becomes sample

1581
00:59:49,839 --> 00:59:50,720
states

1582
00:59:50,720 --> 00:59:53,760
which makes it a bit more um but it

1583
00:59:53,760 --> 00:59:56,559
it's not like a classifier that that

1584
00:59:56,559 --> 00:59:57,440
always fits to

1585
00:59:57,440 --> 00:59:59,200
the test of let's say there's always

1586
00:59:59,200 --> 01:00:00,960
some kind of

1587
01:00:00,960 --> 01:00:05,040
noise in there but you're right um

1588
01:00:05,040 --> 01:00:07,839
it is in some sense overfitting the data

1589
01:00:07,839 --> 01:00:10,079
in the sense that it cannot predict

1590
01:00:10,079 --> 01:00:13,839
uh scenarios that it clearly hasn't seen

1591
01:00:13,839 --> 01:00:14,880
before

1592
01:00:14,880 --> 01:00:17,760
but so one of the one of the nice things

1593
01:00:17,760 --> 01:00:19,599
of having this uh

1594
01:00:19,599 --> 01:00:21,839
this expected energy formulation is that

1595
01:00:21,839 --> 01:00:23,680
you actually finish

1596
01:00:23,680 --> 01:00:27,520
um uh you're planning to

1597
01:00:27,520 --> 01:00:30,160
um with this entropy term which

1598
01:00:30,160 --> 01:00:31,680
basically means that

1599
01:00:31,680 --> 01:00:34,799
if you plan ahead in some space that

1600
01:00:34,799 --> 01:00:37,200
the the model wasn't trained on then

1601
01:00:37,200 --> 01:00:38,559
typically

1602
01:00:38,559 --> 01:00:41,040
you will have some more variation some

1603
01:00:41,040 --> 01:00:42,000
higher entropy

1604
01:00:42,000 --> 01:00:44,400
or that area because typically your your

1605
01:00:44,400 --> 01:00:45,680
observation becomes

1606
01:00:45,680 --> 01:00:49,520
very bad or um very blurry or

1607
01:00:49,520 --> 01:00:52,880
out of distribution and so so in some

1608
01:00:52,880 --> 01:00:53,440
sense the

1609
01:00:53,440 --> 01:00:56,079
the model is kind of robust against that

1610
01:00:56,079 --> 01:00:57,680
and it will also

1611
01:00:57,680 --> 01:01:01,359
if you then deploy a policy or like a

1612
01:01:01,359 --> 01:01:03,920
do the planning it will kind of try to

1613
01:01:03,920 --> 01:01:05,760
stay close to

1614
01:01:05,760 --> 01:01:07,760
where the model to the regime where the

1615
01:01:07,760 --> 01:01:09,760
model was restrained okay because there

1616
01:01:09,760 --> 01:01:10,000
you

1617
01:01:10,000 --> 01:01:12,640
basically get the the better predictions

1618
01:01:12,640 --> 01:01:13,359
so

1619
01:01:13,359 --> 01:01:16,240
uh in some sense that also mitigates the

1620
01:01:16,240 --> 01:01:17,040
the

1621
01:01:17,040 --> 01:01:22,160
problem also i want to add that

1622
01:01:22,240 --> 01:01:26,079
the by we we could use as

1623
01:01:26,079 --> 01:01:28,720
uh little of the uh rollouts as we did

1624
01:01:28,720 --> 01:01:29,599
because actually

1625
01:01:29,599 --> 01:01:32,480
if you had let a human do the rollout

1626
01:01:32,480 --> 01:01:32,880
you

1627
01:01:32,880 --> 01:01:34,559
solve the exploration problem for the

1628
01:01:34,559 --> 01:01:36,079
agent you already

1629
01:01:36,079 --> 01:01:39,119
get a very good coverage of the

1630
01:01:39,119 --> 01:01:41,599
relevant feasible state space you get

1631
01:01:41,599 --> 01:01:43,920
like for the car racer

1632
01:01:43,920 --> 01:01:45,920
if you let a random agent drive around

1633
01:01:45,920 --> 01:01:47,119
as exploration

1634
01:01:47,119 --> 01:01:49,839
99 of your day still just be grass and

1635
01:01:49,839 --> 01:01:50,720
the robot will

1636
01:01:50,720 --> 01:01:53,839
age will learn nothing about roads so by

1637
01:01:53,839 --> 01:01:54,640
having a human

1638
01:01:54,640 --> 01:01:56,880
human derive it you know okay this is

1639
01:01:56,880 --> 01:01:57,760
the road and

1640
01:01:57,760 --> 01:01:59,039
apparently this is important because

1641
01:01:59,039 --> 01:02:02,799
it's in every observation i've had

1642
01:02:02,799 --> 01:02:05,119
that almost makes me think of two ways

1643
01:02:05,119 --> 01:02:06,240
that we're seeing

1644
01:02:06,240 --> 01:02:08,240
these large models be trained with a

1645
01:02:08,240 --> 01:02:09,520
sort of mentor

1646
01:02:09,520 --> 01:02:11,359
like a human who says you know here's

1647
01:02:11,359 --> 01:02:12,880
the first places you want to be sampling

1648
01:02:12,880 --> 01:02:14,720
here's how you drive the first time

1649
01:02:14,720 --> 01:02:17,280
that's the driving instructor side by

1650
01:02:17,280 --> 01:02:18,000
side

1651
01:02:18,000 --> 01:02:19,680
and then there's the degenerative

1652
01:02:19,680 --> 01:02:21,680
adversarial approach

1653
01:02:21,680 --> 01:02:24,319
which is just the almost opposite like

1654
01:02:24,319 --> 01:02:26,160
we're going to be passing the model

1655
01:02:26,160 --> 01:02:29,520
the most confusing possible data

1656
01:02:29,520 --> 01:02:31,680
and so it's sort of like with this

1657
01:02:31,680 --> 01:02:33,359
carrot and the stick or the push in the

1658
01:02:33,359 --> 01:02:34,240
pole

1659
01:02:34,240 --> 01:02:37,039
these models from both of them maybe one

1660
01:02:37,039 --> 01:02:37,520
or maybe

1661
01:02:37,520 --> 01:02:40,319
both that they figure out how to be on

1662
01:02:40,319 --> 01:02:41,599
that razor's edge

1663
01:02:41,599 --> 01:02:44,960
and then in the race car example um

1664
01:02:44,960 --> 01:02:47,119
it was cutting corners so that just made

1665
01:02:47,119 --> 01:02:48,720
me wonder about

1666
01:02:48,720 --> 01:02:50,960
autonomous vehicles and you say okay

1667
01:02:50,960 --> 01:02:52,880
well the goal is to stay on the road

1668
01:02:52,880 --> 01:02:55,280
and to get there fast but then sometimes

1669
01:02:55,280 --> 01:02:56,559
get there fast

1670
01:02:56,559 --> 01:02:59,440
is gonna take priority and then all of a

1671
01:02:59,440 --> 01:03:01,680
sudden you're way off the road and maybe

1672
01:03:01,680 --> 01:03:03,520
now your car is ruined or something like

1673
01:03:03,520 --> 01:03:05,119
that so

1674
01:03:05,119 --> 01:03:07,280
if these were to be deployed like how

1675
01:03:07,280 --> 01:03:08,640
will we even know

1676
01:03:08,640 --> 01:03:11,920
what kind of preferences to

1677
01:03:11,920 --> 01:03:16,799
instantiate the model with

1678
01:03:16,799 --> 01:03:18,720
yeah that's a that's a very good point

1679
01:03:18,720 --> 01:03:20,000
in fact because

1680
01:03:20,000 --> 01:03:24,079
um how nice active entrance might look

1681
01:03:24,079 --> 01:03:27,440
in in theory i think there it doesn't

1682
01:03:27,440 --> 01:03:29,839
it's not a silver bullet to autonomous

1683
01:03:29,839 --> 01:03:31,039
agents because

1684
01:03:31,039 --> 01:03:33,839
a lot of the a lot of the civility is

1685
01:03:33,839 --> 01:03:35,520
still in how do you

1686
01:03:35,520 --> 01:03:37,839
how do you provide it with like the

1687
01:03:37,839 --> 01:03:39,039
preferred

1688
01:03:39,039 --> 01:03:42,079
prior distribution and that will be

1689
01:03:42,079 --> 01:03:45,839
crucial in a real world system

1690
01:03:45,839 --> 01:03:49,520
it's it's similar to

1691
01:03:49,520 --> 01:03:51,599
a reward basically it's a bit more

1692
01:03:51,599 --> 01:03:53,680
informative than just the scalar rewards

1693
01:03:53,680 --> 01:03:54,559
you know let's say

1694
01:03:54,559 --> 01:03:56,799
but it suffers from the same issues as

1695
01:03:56,799 --> 01:03:58,319
in um

1696
01:03:58,319 --> 01:04:01,359
if if it's gets a way to

1697
01:04:01,359 --> 01:04:05,200
do shortcuts um you get this preferred

1698
01:04:05,200 --> 01:04:07,440
state that you didn't envision before as

1699
01:04:07,440 --> 01:04:07,680
a

1700
01:04:07,680 --> 01:04:09,760
as a designer of the of the experiment

1701
01:04:09,760 --> 01:04:10,720
let's say

1702
01:04:10,720 --> 01:04:12,960
it basically has the same issues as as

1703
01:04:12,960 --> 01:04:14,240
reinforcements learning

1704
01:04:14,240 --> 01:04:17,039
so i don't see it as as a silver bullet

1705
01:04:17,039 --> 01:04:17,680
of

1706
01:04:17,680 --> 01:04:21,280
solving autonomy um but at least it has

1707
01:04:21,280 --> 01:04:22,000
some

1708
01:04:22,000 --> 01:04:27,680
um it has some um

1709
01:04:27,680 --> 01:04:29,680
burning knobs that you can you can you

1710
01:04:29,680 --> 01:04:30,880
can use to

1711
01:04:30,880 --> 01:04:33,760
at least avoid some cases like avoid

1712
01:04:33,760 --> 01:04:34,799
these ambiguity

1713
01:04:34,799 --> 01:04:38,720
ambiguous states or at least make it

1714
01:04:38,720 --> 01:04:42,079
first learn the model properly

1715
01:04:42,079 --> 01:04:44,960
so it has some nice properties but it's

1716
01:04:44,960 --> 01:04:45,280
not

1717
01:04:45,280 --> 01:04:47,760
a silver bullet to solving autonomous

1718
01:04:47,760 --> 01:04:50,480
systems i think

1719
01:04:51,119 --> 01:04:53,680
anything to add on that ozone i think

1720
01:04:53,680 --> 01:04:55,200
tim said it very well

1721
01:04:55,200 --> 01:04:57,839
yes the model is not a silver bullet

1722
01:04:57,839 --> 01:04:58,559
definitely

1723
01:04:58,559 --> 01:05:01,920
recognized what areas might be

1724
01:05:01,920 --> 01:05:03,440
interesting

1725
01:05:03,440 --> 01:05:06,160
shooting ranges first applications where

1726
01:05:06,160 --> 01:05:07,200
we can at least

1727
01:05:07,200 --> 01:05:10,240
explore it um are those the same use

1728
01:05:10,240 --> 01:05:11,200
cases that people

1729
01:05:11,200 --> 01:05:13,520
have been talking about just more

1730
01:05:13,520 --> 01:05:14,640
broadly

1731
01:05:14,640 --> 01:05:17,680
in terms of autonomous vehicles or might

1732
01:05:17,680 --> 01:05:18,319
there be

1733
01:05:18,319 --> 01:05:20,400
a sort of division of labor where active

1734
01:05:20,400 --> 01:05:21,760
inference is going to specialize like in

1735
01:05:21,760 --> 01:05:22,000
those

1736
01:05:22,000 --> 01:05:24,960
ambiguous scenarios or i just was

1737
01:05:24,960 --> 01:05:27,760
curious about that

1738
01:05:35,359 --> 01:05:38,160
okay so yeah i was i was also still

1739
01:05:38,160 --> 01:05:39,039
thinking but

1740
01:05:39,039 --> 01:05:42,160
like for us there i think the real next

1741
01:05:42,160 --> 01:05:43,839
application we're targeting

1742
01:05:43,839 --> 01:05:46,960
is just still the constrained navigation

1743
01:05:46,960 --> 01:05:49,440
and then for example a warehouse where

1744
01:05:49,440 --> 01:05:53,200
the impact of uh misplanning

1745
01:05:53,200 --> 01:05:56,480
is still fairly limited so actually more

1746
01:05:56,480 --> 01:05:57,680
realistic versions

1747
01:05:57,680 --> 01:05:59,200
of the situation we have in our lab

1748
01:05:59,200 --> 01:06:02,079
maybe it's also

1749
01:06:02,079 --> 01:06:05,200
the trajectory we're currently still on

1750
01:06:05,200 --> 01:06:07,119
so i think we still believe that there

1751
01:06:07,119 --> 01:06:08,480
is some value in

1752
01:06:08,480 --> 01:06:10,480
developing autonomous active entrance

1753
01:06:10,480 --> 01:06:11,599
agents

1754
01:06:11,599 --> 01:06:14,640
for this more industry-like settings

1755
01:06:14,640 --> 01:06:15,440
where you

1756
01:06:15,440 --> 01:06:17,920
can at least separate it the general

1757
01:06:17,920 --> 01:06:18,480
public

1758
01:06:18,480 --> 01:06:20,880
and more you right you have also some

1759
01:06:20,880 --> 01:06:24,160
level of control of the environment

1760
01:06:24,400 --> 01:06:27,520
yeah i think i i think you it's similar

1761
01:06:27,520 --> 01:06:27,920
to

1762
01:06:27,920 --> 01:06:31,200
to mitigating the same problem in your

1763
01:06:31,200 --> 01:06:33,599
learning is basically that you before

1764
01:06:33,599 --> 01:06:35,200
before you just let the system

1765
01:06:35,200 --> 01:06:37,200
randomly pick actions or pick any action

1766
01:06:37,200 --> 01:06:39,440
at once you kind of

1767
01:06:39,440 --> 01:06:41,200
or an environment where at least as a

1768
01:06:41,200 --> 01:06:42,960
human you can

1769
01:06:42,960 --> 01:06:46,400
you can shortcut the system and say okay

1770
01:06:46,400 --> 01:06:48,559
you want to drive forward into this rack

1771
01:06:48,559 --> 01:06:50,160
that's not a good idea so

1772
01:06:50,160 --> 01:06:52,640
you have at least some some ways of

1773
01:06:52,640 --> 01:06:54,640
defining some rules to keep it within

1774
01:06:54,640 --> 01:06:56,480
some safety range let's say

1775
01:06:56,480 --> 01:06:59,599
and within this boundary it can it can

1776
01:06:59,599 --> 01:07:01,680
for example

1777
01:07:01,680 --> 01:07:04,160
move autonomously but still then you you

1778
01:07:04,160 --> 01:07:05,920
might have the

1779
01:07:05,920 --> 01:07:08,319
nicer properties of the active inference

1780
01:07:08,319 --> 01:07:09,039
agent

1781
01:07:09,039 --> 01:07:12,640
that it if uh if you're driving around

1782
01:07:12,640 --> 01:07:14,319
in in some ales and somebody just

1783
01:07:14,319 --> 01:07:16,160
dropped dropped off the box in the

1784
01:07:16,160 --> 01:07:17,280
middle of the air

1785
01:07:17,280 --> 01:07:19,920
it will not freak out because the the

1786
01:07:19,920 --> 01:07:20,960
the slam map

1787
01:07:20,960 --> 01:07:24,240
is is uh it's no longer uh

1788
01:07:24,240 --> 01:07:26,319
consistent with with with how the robot

1789
01:07:26,319 --> 01:07:27,920
was programmed for example but we'll

1790
01:07:27,920 --> 01:07:28,240
just

1791
01:07:28,240 --> 01:07:31,119
say okay this is another case either it

1792
01:07:31,119 --> 01:07:33,200
experienced this before and it has in

1793
01:07:33,200 --> 01:07:33,520
his

1794
01:07:33,520 --> 01:07:36,319
in his world model an idea how to cope

1795
01:07:36,319 --> 01:07:36,880
with this

1796
01:07:36,880 --> 01:07:38,799
part will just be intrigued and start

1797
01:07:38,799 --> 01:07:40,960
learning on about this news information

1798
01:07:40,960 --> 01:07:43,359
so i think these are the nice properties

1799
01:07:43,359 --> 01:07:44,000
you have

1800
01:07:44,000 --> 01:07:47,280
in this agent and you kind of bypass the

1801
01:07:47,280 --> 01:07:50,960
all um um it's it's getting too greedy

1802
01:07:50,960 --> 01:07:53,760
to realize its preferences because you

1803
01:07:53,760 --> 01:07:54,480
kind of

1804
01:07:54,480 --> 01:07:57,440
shortcut these um these situations by by

1805
01:07:57,440 --> 01:07:58,400
having this

1806
01:07:58,400 --> 01:08:02,880
this based system in place that kind of

1807
01:08:02,880 --> 01:08:06,000
limits the the the

1808
01:08:06,000 --> 01:08:09,039
choice of actions in this game thanks

1809
01:08:09,039 --> 01:08:10,720
for the answer here's a

1810
01:08:10,720 --> 01:08:13,920
question from the chat as the code is

1811
01:08:13,920 --> 01:08:15,039
not disclosed

1812
01:08:15,039 --> 01:08:17,198
would you say sticking to what you write

1813
01:08:17,198 --> 01:08:18,158
in your paper

1814
01:08:18,158 --> 01:08:20,319
is sufficient to reproduce your results

1815
01:08:20,319 --> 01:08:22,719
or are there any further tricks you use

1816
01:08:22,719 --> 01:08:26,560
in designing and training the models

1817
01:08:29,040 --> 01:08:30,799
are you taking the art i'm sorry go

1818
01:08:30,799 --> 01:08:32,880
ahead tim first

1819
01:08:32,880 --> 01:08:34,799
yeah i think that together with the

1820
01:08:34,799 --> 01:08:36,238
appendices it should be

1821
01:08:36,238 --> 01:08:38,880
sufficient what do you think goes on

1822
01:08:38,880 --> 01:08:39,679
well i think

1823
01:08:39,679 --> 01:08:41,279
well we had some experience with that

1824
01:08:41,279 --> 01:08:43,279
where i tried to help somebody out who

1825
01:08:43,279 --> 01:08:43,759
was

1826
01:08:43,759 --> 01:08:47,839
trying to replicate our results um

1827
01:08:47,839 --> 01:08:50,799
i think them we had some tricks for the

1828
01:08:50,799 --> 01:08:51,679
planning

1829
01:08:51,679 --> 01:08:54,158
like that isn't as straightforward to

1830
01:08:54,158 --> 01:08:55,359
replicate but

1831
01:08:55,359 --> 01:08:58,399
the model prediction part

1832
01:08:58,399 --> 01:09:01,439
we explained the architectures and i uh

1833
01:09:01,439 --> 01:09:04,080
pretty detailed in the appendages so i

1834
01:09:04,080 --> 01:09:05,198
think

1835
01:09:05,198 --> 01:09:06,960
and we don't do any extra tricks for

1836
01:09:06,960 --> 01:09:09,040
example on on

1837
01:09:09,040 --> 01:09:12,479
data processing or our loss terms so

1838
01:09:12,479 --> 01:09:14,158
this should be easy to mimic but i think

1839
01:09:14,158 --> 01:09:15,520
the planning

1840
01:09:15,520 --> 01:09:17,600
is a bit more involved as we sometimes

1841
01:09:17,600 --> 01:09:19,920
ourselves have difficulties replicating

1842
01:09:19,920 --> 01:09:22,080
it

1843
01:09:22,319 --> 01:09:26,080
planning is hard yeah

1844
01:09:26,080 --> 01:09:29,120
um okay if anyone else has questions in

1845
01:09:29,120 --> 01:09:31,040
the live chat they can type that

1846
01:09:31,040 --> 01:09:32,960
um another piece that i thought was

1847
01:09:32,960 --> 01:09:34,319
really fascinating

1848
01:09:34,319 --> 01:09:36,880
in the mountain car example at least was

1849
01:09:36,880 --> 01:09:38,238
how you talked about

1850
01:09:38,238 --> 01:09:41,359
the noise allowing for the previously

1851
01:09:41,359 --> 01:09:44,479
implausible policies to become

1852
01:09:44,479 --> 01:09:47,520
possible like we saw a broader spread of

1853
01:09:47,520 --> 01:09:48,238
the

1854
01:09:48,238 --> 01:09:51,279
of the trajectories when there was noise

1855
01:09:51,279 --> 01:09:54,800
um how how is that being like

1856
01:09:54,800 --> 01:09:57,760
integrated in real time or how are the

1857
01:09:57,760 --> 01:09:58,640
noise

1858
01:09:58,640 --> 01:10:03,040
which are often very small how does that

1859
01:10:03,040 --> 01:10:04,960
change the model's understanding of

1860
01:10:04,960 --> 01:10:08,320
where it can go and what it should do

1861
01:10:11,199 --> 01:10:13,600
yeah so in the multi-car example there

1862
01:10:13,600 --> 01:10:16,000
are basically two sources of noise let's

1863
01:10:16,000 --> 01:10:16,880
say one is on

1864
01:10:16,880 --> 01:10:19,760
on the the noise on your observation

1865
01:10:19,760 --> 01:10:21,120
that you get so you get the

1866
01:10:21,120 --> 01:10:23,760
annoying estimate of your position and

1867
01:10:23,760 --> 01:10:24,960
so

1868
01:10:24,960 --> 01:10:28,080
this is typically not not so large

1869
01:10:28,080 --> 01:10:30,320
because yeah you need to have a

1870
01:10:30,320 --> 01:10:32,960
sufficient signal to noise ratio just to

1871
01:10:32,960 --> 01:10:36,480
learn anything let's say um

1872
01:10:36,480 --> 01:10:39,600
but the second part was

1873
01:10:39,600 --> 01:10:42,560
whether your agent starts with zero

1874
01:10:42,560 --> 01:10:44,000
velocity or with

1875
01:10:44,000 --> 01:10:46,640
a random velocity and these are

1876
01:10:46,640 --> 01:10:47,280
basically

1877
01:10:47,280 --> 01:10:50,400
two separately trained um models

1878
01:10:50,400 --> 01:10:53,280
so either you you have an agent always

1879
01:10:53,280 --> 01:10:54,080
starts with

1880
01:10:54,080 --> 01:10:56,400
a zero initial velocity and then

1881
01:10:56,400 --> 01:10:58,719
basically the model learns that

1882
01:10:58,719 --> 01:11:01,920
um the initial observation uh has

1883
01:11:01,920 --> 01:11:03,760
zero velocity and it's it basically

1884
01:11:03,760 --> 01:11:06,400
knows how to properly predict

1885
01:11:06,400 --> 01:11:08,560
from from the first observation on let's

1886
01:11:08,560 --> 01:11:09,520
say

1887
01:11:09,520 --> 01:11:11,199
if you train the model where the agent

1888
01:11:11,199 --> 01:11:12,560
constantly has

1889
01:11:12,560 --> 01:11:14,800
a random velocity then it basically

1890
01:11:14,800 --> 01:11:17,440
learns yeah from the first observation

1891
01:11:17,440 --> 01:11:19,920
still a lot of options can happen

1892
01:11:19,920 --> 01:11:21,600
depending on my velocity and

1893
01:11:21,600 --> 01:11:24,640
the more observations get in you see how

1894
01:11:24,640 --> 01:11:26,640
the model kind of

1895
01:11:26,640 --> 01:11:28,880
picks up okay this is now my velocity

1896
01:11:28,880 --> 01:11:29,920
and from then on

1897
01:11:29,920 --> 01:11:32,960
you see how the the wide range of

1898
01:11:32,960 --> 01:11:34,719
options collapses to

1899
01:11:34,719 --> 01:11:38,800
the most the most likely ones

1900
01:11:39,440 --> 01:11:41,760
anything on that or son well i was just

1901
01:11:41,760 --> 01:11:43,760
also thinking for example in the robotic

1902
01:11:43,760 --> 01:11:47,199
planning example we gave um

1903
01:11:47,199 --> 01:11:49,679
there you also see this spread but then

1904
01:11:49,679 --> 01:11:50,560
it's

1905
01:11:50,560 --> 01:11:53,840
more as in that the model learned that

1906
01:11:53,840 --> 01:11:54,800
at

1907
01:11:54,800 --> 01:11:57,840
different at similar state values

1908
01:11:57,840 --> 01:11:59,360
different outcomes are possible so it

1909
01:11:59,360 --> 01:12:01,520
will try to maybe

1910
01:12:01,520 --> 01:12:03,760
make the gaussian and the latent speeds

1911
01:12:03,760 --> 01:12:05,679
a bit wider so that if you sample from

1912
01:12:05,679 --> 01:12:06,239
it

1913
01:12:06,239 --> 01:12:08,480
you might get the slightly different

1914
01:12:08,480 --> 01:12:09,679
sample value

1915
01:12:09,679 --> 01:12:11,360
and that will then generate the

1916
01:12:11,360 --> 01:12:13,120
different outcome you want

1917
01:12:13,120 --> 01:12:16,000
you want to visualize so that's also so

1918
01:12:16,000 --> 01:12:17,120
even though the

1919
01:12:17,120 --> 01:12:18,960
standard normal you're sampling from

1920
01:12:18,960 --> 01:12:20,560
initially for your reparameterization

1921
01:12:20,560 --> 01:12:21,520
trick is

1922
01:12:21,520 --> 01:12:24,560
very as just standard normal the the

1923
01:12:24,560 --> 01:12:26,800
model can learn to inflate or deflate

1924
01:12:26,800 --> 01:12:30,480
this distribution so that you get a

1925
01:12:30,480 --> 01:12:33,520
wider coverage

1926
01:12:33,520 --> 01:12:35,360
for example you also saw in the in the

1927
01:12:35,360 --> 01:12:37,199
navigation example is that

1928
01:12:37,199 --> 01:12:39,840
basically the the model since we train

1929
01:12:39,840 --> 01:12:40,320
it on

1930
01:12:40,320 --> 01:12:43,760
on pretty short temporal subsequences of

1931
01:12:43,760 --> 01:12:44,239
like

1932
01:12:44,239 --> 01:12:47,360
i think one or two seconds in real time

1933
01:12:47,360 --> 01:12:52,159
um so it's not able to cause

1934
01:12:52,159 --> 01:12:54,640
to have a very consistent prediction for

1935
01:12:54,640 --> 01:12:56,320
for longer

1936
01:12:56,320 --> 01:12:59,440
times uh frames than that and also given

1937
01:12:59,440 --> 01:13:01,040
the fact that every ale

1938
01:13:01,040 --> 01:13:03,920
in the lab looks very similar it learns

1939
01:13:03,920 --> 01:13:05,760
the general structure like

1940
01:13:05,760 --> 01:13:07,520
there are wrecks left and right and

1941
01:13:07,520 --> 01:13:09,280
there might be boxes or

1942
01:13:09,280 --> 01:13:12,480
uh you saw that kind of the boxes or the

1943
01:13:12,480 --> 01:13:14,560
the stuff in the in this actually in the

1944
01:13:14,560 --> 01:13:16,880
racks is kind of very blurry and

1945
01:13:16,880 --> 01:13:20,239
it's kind of brownish uh blackish but

1946
01:13:20,239 --> 01:13:23,360
there's no real you don't really it

1947
01:13:23,360 --> 01:13:25,440
can identify what is in that wreck for

1948
01:13:25,440 --> 01:13:27,040
example and it's

1949
01:13:27,040 --> 01:13:30,000
so it has basically no spatial awareness

1950
01:13:30,000 --> 01:13:30,400
of

1951
01:13:30,400 --> 01:13:33,360
where in the wreck where in the air am i

1952
01:13:33,360 --> 01:13:35,040
am i at the very end or in the beginning

1953
01:13:35,040 --> 01:13:36,000
or in the middle

1954
01:13:36,000 --> 01:13:38,000
it has no idea that's why you saw if you

1955
01:13:38,000 --> 01:13:39,199
then say okay

1956
01:13:39,199 --> 01:13:42,719
turn right for a certain amount of time

1957
01:13:42,719 --> 01:13:44,800
and then it will either predict i'm in

1958
01:13:44,800 --> 01:13:46,000
the middle so the next

1959
01:13:46,000 --> 01:13:48,640
the if i turn 360 it will still be ale

1960
01:13:48,640 --> 01:13:49,280
after me

1961
01:13:49,280 --> 01:13:50,960
or i'm at the very end so if i turn

1962
01:13:50,960 --> 01:13:52,640
around i will see a wall

1963
01:13:52,640 --> 01:13:55,840
um so it it basically has no um

1964
01:13:55,840 --> 01:13:59,120
consistent knowledge of of where it is

1965
01:13:59,120 --> 01:14:02,159
and so the this is basically

1966
01:14:02,159 --> 01:14:05,360
model this kind of noise in the in

1967
01:14:05,360 --> 01:14:07,760
in distributions and if you if you draw

1968
01:14:07,760 --> 01:14:09,679
a different trajectory it will either

1969
01:14:09,679 --> 01:14:10,400
think

1970
01:14:10,400 --> 01:14:13,280
it's at the wall or it's facing the

1971
01:14:13,280 --> 01:14:15,360
other ale or there's a human passing by

1972
01:14:15,360 --> 01:14:16,560
so i see some

1973
01:14:16,560 --> 01:14:19,679
shady people-like structures so all

1974
01:14:19,679 --> 01:14:21,520
these kind of things are then

1975
01:14:21,520 --> 01:14:25,120
modeled as as as kind of uh

1976
01:14:25,120 --> 01:14:27,840
yeah noise in your in your distribution

1977
01:14:27,840 --> 01:14:28,239
that

1978
01:14:28,239 --> 01:14:32,000
just appears to be happening there

1979
01:14:32,000 --> 01:14:35,040
makes sense um what might be

1980
01:14:35,040 --> 01:14:37,600
helpful or required for long-term

1981
01:14:37,600 --> 01:14:38,159
planning

1982
01:14:38,159 --> 01:14:40,840
because the the tree that you had with a

1983
01:14:40,840 --> 01:14:43,280
multiple um

1984
01:14:43,280 --> 01:14:46,159
i guess bifurcations or whatever they

1985
01:14:46,159 --> 01:14:46,880
represented

1986
01:14:46,880 --> 01:14:48,640
that was very interesting how you had a

1987
01:14:48,640 --> 01:14:50,400
very fully fleshed out tree

1988
01:14:50,400 --> 01:14:51,920
and then you showed kind of how you

1989
01:14:51,920 --> 01:14:54,560
recursed to prune back down to make a

1990
01:14:54,560 --> 01:14:56,000
policy selection

1991
01:14:56,000 --> 01:14:59,760
so as you suggested that exponentially

1992
01:14:59,760 --> 01:15:03,199
explodes the computation what

1993
01:15:03,199 --> 01:15:05,920
might be helpful or how can long-term

1994
01:15:05,920 --> 01:15:06,640
planning be

1995
01:15:06,640 --> 01:15:10,560
achieved with reasonable hardware

1996
01:15:10,560 --> 01:15:14,400
yeah so so the the key thing here is

1997
01:15:14,400 --> 01:15:16,000
hierarchical models i think and that's

1998
01:15:16,000 --> 01:15:17,120
what we're

1999
01:15:17,120 --> 01:15:20,560
uh we're pushing very hard on now

2000
01:15:20,560 --> 01:15:24,480
is basically that you given your

2001
01:15:24,480 --> 01:15:27,280
even a model like we trade now you

2002
01:15:27,280 --> 01:15:28,320
basically put

2003
01:15:28,320 --> 01:15:31,440
a new model on top of that that now as

2004
01:15:31,440 --> 01:15:34,159
observations does not get uh does not

2005
01:15:34,159 --> 01:15:35,360
get pixels

2006
01:15:35,360 --> 01:15:37,280
but it gets state samples from this

2007
01:15:37,280 --> 01:15:38,880
model

2008
01:15:38,880 --> 01:15:41,440
and the the time step now is not to

2009
01:15:41,440 --> 01:15:42,480
predict

2010
01:15:42,480 --> 01:15:44,640
the next time step ahead but like to

2011
01:15:44,640 --> 01:15:46,800
predict 10 times at the head or

2012
01:15:46,800 --> 01:15:49,520
20 or whatever or however you want to

2013
01:15:49,520 --> 01:15:51,440
course grain basically

2014
01:15:51,440 --> 01:15:53,199
and once you're at that point then you

2015
01:15:53,199 --> 01:15:55,199
have basically a system that can

2016
01:15:55,199 --> 01:15:58,560
can plan um if you plan ten time steps

2017
01:15:58,560 --> 01:16:00,480
you're actually planning 100 time steps

2018
01:16:00,480 --> 01:16:02,480
for the lower level model and so this

2019
01:16:02,480 --> 01:16:05,520
way you can keep on course grading that

2020
01:16:05,520 --> 01:16:08,560
you only have to explore

2021
01:16:08,560 --> 01:16:11,360
a few policies at each level and then

2022
01:16:11,360 --> 01:16:13,120
down below

2023
01:16:13,120 --> 01:16:15,840
again you only have to predict for like

2024
01:16:15,840 --> 01:16:17,360
one second that happens because

2025
01:16:17,360 --> 01:16:19,440
the other plan was made for by the

2026
01:16:19,440 --> 01:16:20,560
models on top

2027
01:16:20,560 --> 01:16:23,840
and so this way you can you can easily

2028
01:16:23,840 --> 01:16:27,360
uh bypass the and scale down the

2029
01:16:27,360 --> 01:16:31,760
complexity of the planning procedure

2030
01:16:31,760 --> 01:16:34,080
it reminds me a lot of driving where it

2031
01:16:34,080 --> 01:16:35,199
will be like okay

2032
01:16:35,199 --> 01:16:38,320
in five streets take a right turn so

2033
01:16:38,320 --> 01:16:39,960
you're not

2034
01:16:39,960 --> 01:16:43,120
pre-saging the right turn on okay one

2035
01:16:43,120 --> 01:16:45,440
two three four all right now i should

2036
01:16:45,440 --> 01:16:46,400
get ready

2037
01:16:46,400 --> 01:16:49,520
um what about symbolic information

2038
01:16:49,520 --> 01:16:51,360
like what if the aisle had a color

2039
01:16:51,360 --> 01:16:52,560
gradient or

2040
01:16:52,560 --> 01:16:55,679
if it had one dot two dot three dot

2041
01:16:55,679 --> 01:16:59,280
could that be learnt in an unsupervised

2042
01:16:59,280 --> 01:17:02,640
way um a symbol in that pixel level

2043
01:17:02,640 --> 01:17:03,199
model

2044
01:17:03,199 --> 01:17:05,520
or is that where a hierarchical model

2045
01:17:05,520 --> 01:17:08,320
would come into play

2046
01:17:08,480 --> 01:17:11,040
well i think the problem currently is

2047
01:17:11,040 --> 01:17:11,719
for us

2048
01:17:11,719 --> 01:17:14,560
architecture-wise our model isn't

2049
01:17:14,560 --> 01:17:15,600
capable of

2050
01:17:15,600 --> 01:17:19,440
capturing very like low level

2051
01:17:19,440 --> 01:17:22,800
details about environments just because

2052
01:17:22,800 --> 01:17:25,360
we are based on a va approach and then

2053
01:17:25,360 --> 01:17:26,400
the

2054
01:17:26,400 --> 01:17:28,159
mean squared error objective we use for

2055
01:17:28,159 --> 01:17:30,800
reconstruction and the wavy sample is

2056
01:17:30,800 --> 01:17:33,360
already inhibiting for example

2057
01:17:33,360 --> 01:17:34,640
recognizing dots

2058
01:17:34,640 --> 01:17:38,159
in your inputs um

2059
01:17:38,159 --> 01:17:40,000
maybe actually i don't know what thing

2060
01:17:40,000 --> 01:17:41,600
10 things about it i think color

2061
01:17:41,600 --> 01:17:42,960
gradients is something

2062
01:17:42,960 --> 01:17:46,400
like the model might learn if given

2063
01:17:46,400 --> 01:17:49,520
enough data and incentive

2064
01:17:49,520 --> 01:17:52,080
yeah so i think there's a number of

2065
01:17:52,080 --> 01:17:53,600
problems

2066
01:17:53,600 --> 01:17:56,239
with um with the approach in the sense

2067
01:17:56,239 --> 01:17:57,120
that

2068
01:17:57,120 --> 01:18:00,159
we're now doing prediction in in in

2069
01:18:00,159 --> 01:18:02,239
pixel space let's say

2070
01:18:02,239 --> 01:18:05,199
and the way you you calculate the

2071
01:18:05,199 --> 01:18:06,320
likelihoods

2072
01:18:06,320 --> 01:18:09,040
uh you evaluate the likelihood and you

2073
01:18:09,040 --> 01:18:10,800
you calculate the

2074
01:18:10,800 --> 01:18:13,280
reconstruction error it basically means

2075
01:18:13,280 --> 01:18:14,239
that

2076
01:18:14,239 --> 01:18:16,159
you want to have each pixel

2077
01:18:16,159 --> 01:18:17,760
independently predicted

2078
01:18:17,760 --> 01:18:20,719
on average quite right which means that

2079
01:18:20,719 --> 01:18:22,000
if you have very fine

2080
01:18:22,000 --> 01:18:25,760
grained details it easily um

2081
01:18:25,760 --> 01:18:29,679
ignores this you also have the

2082
01:18:29,679 --> 01:18:32,320
the complexity term that basically says

2083
01:18:32,320 --> 01:18:34,080
okay i want to have the

2084
01:18:34,080 --> 01:18:37,120
the least complex representation for for

2085
01:18:37,120 --> 01:18:38,080
reconstruction

2086
01:18:38,080 --> 01:18:39,600
for reconstruction but this basically

2087
01:18:39,600 --> 01:18:42,239
also means that

2088
01:18:42,239 --> 01:18:45,360
depending on on how much you you you put

2089
01:18:45,360 --> 01:18:46,960
pressure on

2090
01:18:46,960 --> 01:18:49,440
restricting the complexity the less

2091
01:18:49,440 --> 01:18:51,600
information you will actually encode and

2092
01:18:51,600 --> 01:18:54,400
the more blurrier basically your uh your

2093
01:18:54,400 --> 01:18:56,400
your your reconstruction will become so

2094
01:18:56,400 --> 01:18:58,080
it's very similar to

2095
01:18:58,080 --> 01:19:00,400
the bed of the ie uh to those behavior

2096
01:19:00,400 --> 01:19:01,840
where you have this better parameter

2097
01:19:01,840 --> 01:19:02,320
that

2098
01:19:02,320 --> 01:19:05,040
detunes how much weight you put on the

2099
01:19:05,040 --> 01:19:05,520
gal

2100
01:19:05,520 --> 01:19:07,280
divergence term versus the

2101
01:19:07,280 --> 01:19:09,760
reconstruction term

2102
01:19:09,760 --> 01:19:12,480
and this also has his impact on on what

2103
01:19:12,480 --> 01:19:13,360
the model will

2104
01:19:13,360 --> 01:19:15,840
actually put in the state representation

2105
01:19:15,840 --> 01:19:17,679
and and which details will

2106
01:19:17,679 --> 01:19:20,719
will be will be ignored

2107
01:19:20,719 --> 01:19:23,040
so yeah i think a lot of these things

2108
01:19:23,040 --> 01:19:24,640
are very difficult for the model

2109
01:19:24,640 --> 01:19:27,760
straight now just because the way we we

2110
01:19:27,760 --> 01:19:28,239
built

2111
01:19:28,239 --> 01:19:31,839
and parameterize the lightweight model

2112
01:19:32,719 --> 01:19:37,360
very interesting um how might somebody

2113
01:19:37,360 --> 01:19:40,800
go about learning or exploring this

2114
01:19:40,800 --> 01:19:42,719
like is there a textbook or the

2115
01:19:42,719 --> 01:19:43,840
citations that

2116
01:19:43,840 --> 01:19:46,960
are in your paper or hands-on what

2117
01:19:46,960 --> 01:19:48,719
would you encourage somebody who is

2118
01:19:48,719 --> 01:19:50,480
curious about this and wanted to

2119
01:19:50,480 --> 01:19:53,360
over the next maybe a few years be

2120
01:19:53,360 --> 01:19:55,759
following

2121
01:19:59,360 --> 01:20:01,600
yeah i mean we had a lot of like in the

2122
01:20:01,600 --> 01:20:03,600
active infant sports i think

2123
01:20:03,600 --> 01:20:05,679
when we started out there wasn't that

2124
01:20:05,679 --> 01:20:07,440
much information on how to do active

2125
01:20:07,440 --> 01:20:08,320
inference so we

2126
01:20:08,320 --> 01:20:10,880
had to figure it out the hard way by

2127
01:20:10,880 --> 01:20:12,960
trying a lot and failing a lot

2128
01:20:12,960 --> 01:20:15,199
but now currently i think even in this

2129
01:20:15,199 --> 01:20:17,120
model stream there was some

2130
01:20:17,120 --> 01:20:18,880
cool information and accessible

2131
01:20:18,880 --> 01:20:21,440
information on active inference

2132
01:20:21,440 --> 01:20:25,040
so and i mean specific implementation

2133
01:20:25,040 --> 01:20:25,600
wise

2134
01:20:25,600 --> 01:20:29,120
if you want to build a model

2135
01:20:29,120 --> 01:20:31,520
like this i think the current state of

2136
01:20:31,520 --> 01:20:32,639
the art in rl

2137
01:20:32,639 --> 01:20:36,239
and active inference i learned active

2138
01:20:36,239 --> 01:20:37,120
inference is

2139
01:20:37,120 --> 01:20:40,080
all pretty similar

2140
01:20:40,400 --> 01:20:44,159
yeah i i agree so

2141
01:20:44,159 --> 01:20:46,960
a lot of uh things have changed

2142
01:20:46,960 --> 01:20:47,840
regarding

2143
01:20:47,840 --> 01:20:49,920
how accessible the information on on

2144
01:20:49,920 --> 01:20:51,520
active influence has become

2145
01:20:51,520 --> 01:20:54,239
if you look now at a tutorial from ryan

2146
01:20:54,239 --> 01:20:56,000
smith for example which was also

2147
01:20:56,000 --> 01:20:58,639
extensively covered in one of your

2148
01:20:58,639 --> 01:20:59,520
videos

2149
01:20:59,520 --> 01:21:01,679
so i think that really it really knows

2150
01:21:01,679 --> 01:21:03,679
the the the entry

2151
01:21:03,679 --> 01:21:06,639
uh bar to just get to know the theory

2152
01:21:06,639 --> 01:21:07,840
and how everything

2153
01:21:07,840 --> 01:21:10,239
works or should work and to play around

2154
01:21:10,239 --> 01:21:11,760
with some

2155
01:21:11,760 --> 01:21:14,159
small toy examples and simulations that

2156
01:21:14,159 --> 01:21:16,080
you can get some insights on

2157
01:21:16,080 --> 01:21:18,159
on what does this thing do and how does

2158
01:21:18,159 --> 01:21:19,199
it work

2159
01:21:19,199 --> 01:21:22,080
for the deep learning part let's say to

2160
01:21:22,080 --> 01:21:23,520
build these models

2161
01:21:23,520 --> 01:21:26,480
then probably the the resources to go to

2162
01:21:26,480 --> 01:21:27,199
are just like

2163
01:21:27,199 --> 01:21:29,840
tutorials on on variational auto

2164
01:21:29,840 --> 01:21:31,840
encoders i think these are the

2165
01:21:31,840 --> 01:21:34,639
the things in deep learning that are

2166
01:21:34,639 --> 01:21:35,600
most

2167
01:21:35,600 --> 01:21:38,320
relevant for for for the active

2168
01:21:38,320 --> 01:21:38,960
inference work

2169
01:21:38,960 --> 01:21:41,760
we discuss here and if you can build a

2170
01:21:41,760 --> 01:21:43,360
variational auto encoder

2171
01:21:43,360 --> 01:21:45,600
and you know how active inference work

2172
01:21:45,600 --> 01:21:46,880
and you put the two together

2173
01:21:46,880 --> 01:21:48,239
together with some details from our

2174
01:21:48,239 --> 01:21:50,800
paper for example i think it should be

2175
01:21:50,800 --> 01:21:53,040
pretty straightforward to get to the

2176
01:21:53,040 --> 01:21:57,120
first working example cool

2177
01:21:57,120 --> 01:22:00,159
any closing thoughts or even

2178
01:22:00,159 --> 01:22:03,199
questions for our lab or

2179
01:22:03,199 --> 01:22:06,239
just to leave um for people to be

2180
01:22:06,239 --> 01:22:08,560
thinking about as they dream in

2181
01:22:08,560 --> 01:22:11,840
preparation for action

2182
01:22:13,600 --> 01:22:18,800
um yeah maybe i just want to

2183
01:22:18,800 --> 01:22:20,719
continue a bit on what tim said earlier

2184
01:22:20,719 --> 01:22:22,159
that

2185
01:22:22,159 --> 01:22:23,280
for example if you want to build

2186
01:22:23,280 --> 01:22:26,000
hierarchical models

2187
01:22:26,000 --> 01:22:27,920
you don't have to build an active

2188
01:22:27,920 --> 01:22:29,280
inference model on top of an active

2189
01:22:29,280 --> 01:22:30,159
inference model

2190
01:22:30,159 --> 01:22:32,159
we experimented some we did some

2191
01:22:32,159 --> 01:22:33,760
preliminary experiments on

2192
01:22:33,760 --> 01:22:35,840
for example just using our active

2193
01:22:35,840 --> 01:22:37,520
inference model as

2194
01:22:37,520 --> 01:22:40,080
dynamics model for a slam algorithm and

2195
01:22:40,080 --> 01:22:41,760
then you also already get

2196
01:22:41,760 --> 01:22:45,120
hierarchical modeling and

2197
01:22:45,120 --> 01:22:48,239
some of the long-term benefits so

2198
01:22:48,239 --> 01:22:50,560
maybe that's also interesting like to

2199
01:22:50,560 --> 01:22:52,239
think about is how this

2200
01:22:52,239 --> 01:22:54,400
active infrastructure fits in in already

2201
01:22:54,400 --> 01:22:57,040
existing techniques

2202
01:22:57,040 --> 01:23:00,080
yeah so i think what uh

2203
01:23:00,080 --> 01:23:03,360
what ozone wants to say is that in in

2204
01:23:03,360 --> 01:23:04,320
this case we use

2205
01:23:04,320 --> 01:23:06,800
like these deep neural nets to to

2206
01:23:06,800 --> 01:23:08,000
compare eyes

2207
01:23:08,000 --> 01:23:11,679
this transition model likely model and

2208
01:23:11,679 --> 01:23:15,120
posterior model but you shouldn't

2209
01:23:15,120 --> 01:23:18,239
always revert automatically to

2210
01:23:18,239 --> 01:23:20,159
these learning techniques so these are

2211
01:23:20,159 --> 01:23:22,400
kind of very popular right now and very

2212
01:23:22,400 --> 01:23:26,960
very cool but um in some cases you might

2213
01:23:26,960 --> 01:23:29,120
it might be sufficient if you know your

2214
01:23:29,120 --> 01:23:30,560
environment then

2215
01:23:30,560 --> 01:23:32,159
yeah you shouldn't bother learning the

2216
01:23:32,159 --> 01:23:33,679
state-space model if you know the state

2217
01:23:33,679 --> 01:23:34,719
space model just

2218
01:23:34,719 --> 01:23:37,840
yeah use it uh i know we used

2219
01:23:37,840 --> 01:23:40,159
the mountain car example here this would

2220
01:23:40,159 --> 01:23:42,239
be a good example of

2221
01:23:42,239 --> 01:23:45,520
uh why we shouldn't just use uh the deep

2222
01:23:45,520 --> 01:23:47,120
learning approach this was basically

2223
01:23:47,120 --> 01:23:48,560
just that like a proof of

2224
01:23:48,560 --> 01:23:50,719
principle for for us to get some simple

2225
01:23:50,719 --> 01:23:51,920
example working

2226
01:23:51,920 --> 01:23:54,080
but it only pays off i think if you have

2227
01:23:54,080 --> 01:23:55,280
like these real

2228
01:23:55,280 --> 01:23:58,239
high dimensional observations uh and you

2229
01:23:58,239 --> 01:23:58,560
don't

2230
01:23:58,560 --> 01:24:00,239
you have no clue how to characterize

2231
01:24:00,239 --> 01:24:02,400
your space-based mode but it's not that

2232
01:24:02,400 --> 01:24:03,760
this is like the

2233
01:24:03,760 --> 01:24:06,639
the default way to go let's say and

2234
01:24:06,639 --> 01:24:08,800
we're also like kind of

2235
01:24:08,800 --> 01:24:12,080
evolving especially uh also that if you

2236
01:24:12,080 --> 01:24:14,400
move to these hierarchical models

2237
01:24:14,400 --> 01:24:16,880
then we're kind of looking at how can we

2238
01:24:16,880 --> 01:24:19,760
make a more kind of discrete style

2239
01:24:19,760 --> 01:24:23,600
um paragraph state space model on top

2240
01:24:23,600 --> 01:24:27,199
where where we basically um

2241
01:24:27,199 --> 01:24:30,800
try to fit the whole um state space into

2242
01:24:30,800 --> 01:24:31,760
discrete

2243
01:24:31,760 --> 01:24:33,280
parts and then have like a simple

2244
01:24:33,280 --> 01:24:35,120
transition model like you

2245
01:24:35,120 --> 01:24:36,960
you gave the example yourself danielle

2246
01:24:36,960 --> 01:24:38,639
if you if you think about

2247
01:24:38,639 --> 01:24:40,719
navigating yourself you're not thinking

2248
01:24:40,719 --> 01:24:42,080
about predicting

2249
01:24:42,080 --> 01:24:45,679
all the pixels of all the houses uh or

2250
01:24:45,679 --> 01:24:48,239
but you just think about i i need to go

2251
01:24:48,239 --> 01:24:50,400
forward now and then the second street

2252
01:24:50,400 --> 01:24:52,639
to the left so you basically chunk up

2253
01:24:52,639 --> 01:24:55,679
the whole continuously state space into

2254
01:24:55,679 --> 01:24:56,239
some

2255
01:24:56,239 --> 01:24:59,280
relevant parts and then your transition

2256
01:24:59,280 --> 01:24:59,679
model

2257
01:24:59,679 --> 01:25:02,719
also becomes like a very simple

2258
01:25:02,719 --> 01:25:04,239
matrix with with transition

2259
01:25:04,239 --> 01:25:06,400
probabilities um

2260
01:25:06,400 --> 01:25:09,440
so i think the future is in erectile

2261
01:25:09,440 --> 01:25:10,239
models

2262
01:25:10,239 --> 01:25:13,280
and the future is in a mixture of um

2263
01:25:13,280 --> 01:25:16,480
some learned parts but also some um

2264
01:25:16,480 --> 01:25:19,679
some very discretized um intuitively

2265
01:25:19,679 --> 01:25:23,520
comprehensible parts just

2266
01:25:23,520 --> 01:25:26,320
two points on that um one is something

2267
01:25:26,320 --> 01:25:27,760
that's always drawn me to active

2268
01:25:27,760 --> 01:25:28,719
inference is that

2269
01:25:28,719 --> 01:25:31,520
it's inference conditioned and about

2270
01:25:31,520 --> 01:25:32,560
action

2271
01:25:32,560 --> 01:25:35,760
so you're not going for that 4k

2272
01:25:35,760 --> 01:25:37,760
google street view what does every house

2273
01:25:37,760 --> 01:25:38,800
look like

2274
01:25:38,800 --> 01:25:41,280
and again when that's the input data

2275
01:25:41,280 --> 01:25:42,800
even if you have a generative model

2276
01:25:42,800 --> 01:25:44,480
that's the output data

2277
01:25:44,480 --> 01:25:45,920
so active inference is a really

2278
01:25:45,920 --> 01:25:48,000
principled way to just sort of reduce

2279
01:25:48,000 --> 01:25:49,199
what you're predicting

2280
01:25:49,199 --> 01:25:51,840
to like which way should my elbow move

2281
01:25:51,840 --> 01:25:52,239
not

2282
01:25:52,239 --> 01:25:53,920
what will the pixels look like when my

2283
01:25:53,920 --> 01:25:56,000
elbow moves which may be just

2284
01:25:56,000 --> 01:25:58,320
taking gigabytes of data but if it's

2285
01:25:58,320 --> 01:25:59,360
just reduced to

2286
01:25:59,360 --> 01:26:02,239
the state space then it's easier to

2287
01:26:02,239 --> 01:26:03,120
learn and that's why

2288
01:26:03,120 --> 01:26:06,239
it was such an interesting contribution

2289
01:26:06,239 --> 01:26:07,360
with your paper

2290
01:26:07,360 --> 01:26:10,000
to actually learn that state space in

2291
01:26:10,000 --> 01:26:11,120
the context of

2292
01:26:11,120 --> 01:26:13,360
high resolution and real time and

2293
01:26:13,360 --> 01:26:14,480
heterogeneous

2294
01:26:14,480 --> 01:26:16,800
sensors and then also it's something

2295
01:26:16,800 --> 01:26:17,920
that we've seen

2296
01:26:17,920 --> 01:26:20,480
many perspectives on in the lab and in

2297
01:26:20,480 --> 01:26:21,760
these discussions

2298
01:26:21,760 --> 01:26:24,239
is there's the philosophical discussion

2299
01:26:24,239 --> 01:26:25,600
map and territory

2300
01:26:25,600 --> 01:26:27,679
who's really an active inference agent

2301
01:26:27,679 --> 01:26:29,760
is it everything a dust particle

2302
01:26:29,760 --> 01:26:31,840
a bacteria you know is the world built

2303
01:26:31,840 --> 01:26:32,960
this way

2304
01:26:32,960 --> 01:26:34,960
and then there's this sort of

2305
01:26:34,960 --> 01:26:36,480
engineering approach

2306
01:26:36,480 --> 01:26:38,719
where you have your preferences for how

2307
01:26:38,719 --> 01:26:40,400
you want to see the robot work

2308
01:26:40,400 --> 01:26:42,560
and then whatever you can tinker and

2309
01:26:42,560 --> 01:26:44,800
cobble together

2310
01:26:44,800 --> 01:26:47,120
that satisfies you and it reduced your

2311
01:26:47,120 --> 01:26:48,960
uncertainty about performing the task

2312
01:26:48,960 --> 01:26:51,760
you're trying to perform so it's sort of

2313
01:26:51,760 --> 01:26:53,360
sidesteps but then

2314
01:26:53,360 --> 01:26:55,280
it sidesteps those questions in a way

2315
01:26:55,280 --> 01:26:56,960
that actually brings us

2316
01:26:56,960 --> 01:26:58,880
to a higher level of understanding

2317
01:26:58,880 --> 01:27:00,239
because i know that

2318
01:27:00,239 --> 01:27:04,000
many listeners who are not as advanced

2319
01:27:04,000 --> 01:27:06,480
in the machine learning will be inspired

2320
01:27:06,480 --> 01:27:07,199
and have

2321
01:27:07,199 --> 01:27:09,360
qualitative thoughts based upon what you

2322
01:27:09,360 --> 01:27:10,800
brought here today

2323
01:27:10,800 --> 01:27:13,760
so thanks again for this awesome

2324
01:27:13,760 --> 01:27:15,600
presentation and conversation

2325
01:27:15,600 --> 01:27:17,920
and we'll always appreciate hearing any

2326
01:27:17,920 --> 01:27:21,040
follow-up whenever the time is right

2327
01:27:21,040 --> 01:27:23,520
yeah thank you daniel for having us

2328
01:27:23,520 --> 01:27:25,199
really nice discussion

2329
01:27:25,199 --> 01:27:30,520
okay peace see you later see ya bye

2330
01:27:30,520 --> 01:27:33,520
bye

