1
00:00:02,940 --> 00:00:05,939
國外

2
00:00:17,359 --> 00:00:20,520
這是主動推理研究所

3
00:00:20,520 --> 00:00:22,400
，時間是 2022 年 11 月 15 日

4
00:00:22,400 --> 00:00:27,240
，我們在模型流 7.1 中，我們

5
00:00:27,240 --> 00:00:30,960
將討論 Pi mdp 一個

6
00:00:30,960 --> 00:00:33,840
用於在離散狀態空間中進行主動推理的 python 包，

7
00:00:33,840 --> 00:00:37,500
我們都會打個招呼，然後

8
00:00:37,500 --> 00:00:41,520
我們將傳遞給 Connor 對於演示

9
00:00:41,520 --> 00:00:43,860
之後的演示，我們將進行

10
00:00:43,860 --> 00:00:46,920
一些討論 看一下 Pi mdp

11
00:00:46,920 --> 00:00:49,140
腳本 回答

12
00:00:49,140 --> 00:00:52,500
實時聊天中出現的任何問題 所以

13
00:00:52,500 --> 00:00:54,660
感謝作者今天的加入，也

14
00:00:54,660 --> 00:00:57,180
感謝 Jacob 我們先打個

15
00:00:57,180 --> 00:01:00,360
招呼 所以我是 Daniel，我是

16
00:01:00,360 --> 00:01:02,399
加利福尼亞的一名研究員，我很高興能

17
00:01:02,399 --> 00:01:05,220
更多地了解 pi mdp 並

18
00:01:05,220 --> 00:01:07,560
了解如何應用主動推理

19
00:01:07,560 --> 00:01:11,460
，我會轉告

20
00:01:11,460 --> 00:01:14,220
jakub 大家好，我是 yakub，我是 我

21
00:01:14,220 --> 00:01:18,020
是英國的一名學生，也很高興聽到

22
00:01:18,020 --> 00:01:22,200
更多關於父母的信息，並討論最近的

23
00:01:22,200 --> 00:01:25,320
呃發展和未來

24
00:01:25,320 --> 00:01:30,500
發展的計劃我會把它傳遞給達芙妮

25
00:01:30,500 --> 00:01:33,180
嗨，我是達芙妮，

26
00:01:33,180 --> 00:01:36,659
嗯，我在倫敦工作，我用過

27
00:01:36,659 --> 00:01:39,780
小學 p 很多我

28
00:01:39,780 --> 00:01:42,000
在我的 Mas 上和 Connor 一起做的工作 ter 的論文以及

29
00:01:42,000 --> 00:01:43,380
我們從那時起一直在做的工作

30
00:01:43,380 --> 00:01:44,939


31
00:01:44,939 --> 00:01:46,680
所以我非常喜歡認為它是一個

32
00:01:46,680 --> 00:01:50,159
非常非常棒的包而且我很高興

33
00:01:50,159 --> 00:01:53,899
人們會開始使用它更

34
00:01:55,020 --> 00:01:57,540
優秀好吧康納非常感謝你

35
00:01:57,540 --> 00:02:00,360
加入接受它

36
00:02:00,360 --> 00:02:02,700
太棒了，謝謝你，謝謝你的邀請，

37
00:02:02,700 --> 00:02:05,700
我很高興，嗯，我們安排了這

38
00:02:05,700 --> 00:02:07,799
件事，這是一個很好的直播機會，

39
00:02:07,799 --> 00:02:10,020
我已經去過幾次

40
00:02:10,020 --> 00:02:12,660
了，所以回來總是很好，所以

41
00:02:12,660 --> 00:02:14,640
我不 有一張幻燈片介紹我自己

42
00:02:14,640 --> 00:02:16,860
所以我只想簡單地說一句

43
00:02:16,860 --> 00:02:19,920
關於我是誰所以我是 Connor 我是德國

44
00:02:19,920 --> 00:02:23,160
um the plug

45
00:02:23,160 --> 00:02:25,020
Institute for animal behavior

46
00:02:25,020 --> 00:02:28,020
and Constance 的生物學博士生，我的大部分工作

47
00:02:28,020 --> 00:02:30,120
是 關於

48
00:02:30,120 --> 00:02:33,360
在認知

49
00:02:33,360 --> 00:02:35,099
科學和復雜系統上應用主動推理和貝葉斯透鏡，將

50
00:02:35,099 --> 00:02:37,379
其應用於集體行為，如

51
00:02:37,379 --> 00:02:39,959
集體動物行為，但今天

52
00:02:39,959 --> 00:02:41,940
我要談論的是我的一個

53
00:02:41,940 --> 00:02:43,620
副博士項目，它一直在

54
00:02:43,620 --> 00:02:45,840
開發這個 Prime DP 包，它

55
00:02:45,840 --> 00:02:47,220
曾是

56
00:02:47,220 --> 00:02:49,739
與來自主動推理社區的一群人進行了非常多的協作小組努力，

57
00:02:49,739 --> 00:02:51,420


58
00:02:51,420 --> 00:02:52,200


59
00:02:52,200 --> 00:02:55,260
嗯，是的，讓我們

60
00:02:55,260 --> 00:02:58,080
深入研究該軟件包

61
00:02:58,080 --> 00:03:00,239
實際上已經發布了一段時間的論文，該

62
00:03:00,239 --> 00:03:02,519
論文於今年早些時候發表，

63
00:03:02,519 --> 00:03:04,800
嗯，它只是 我想首先

64
00:03:04,800 --> 00:03:06,599
強調 primevp 是一個非常重要的

65
00:03:06,599 --> 00:03:08,280
工作，儘管我們發布

66
00:03:08,280 --> 00:03:09,599
了一篇論文，它絕對像一個

67
00:03:09,599 --> 00:03:12,300
可用的獨立包，它

68
00:03:12,300 --> 00:03:15,239
總是有大量的東西需要繼續開發

69
00:03:15,239 --> 00:03:16,440
，在演示結束時我將

70
00:03:16,440 --> 00:03:18,000
談論 一些正在進行的

71
00:03:18,000 --> 00:03:19,620
開發在我看來真的很令人興奮

72
00:03:19,620 --> 00:03:21,959
，我們將真正

73
00:03:21,959 --> 00:03:23,700
開放軟件包的使用

74
00:03:23,700 --> 00:03:26,459
和可擴展性

75
00:03:26,459 --> 00:03:27,900
謝謝

76
00:03:27,900 --> 00:03:30,360
所以基本上我的意思是這是一個活躍的

77
00:03:30,360 --> 00:03:33,000
推理研究所播客或

78
00:03:33,000 --> 00:03:35,640
直播所以我不 必須花太多

79
00:03:35,640 --> 00:03:37,379
時間來激勵我不認為主動

80
00:03:37,379 --> 00:03:40,799
推理但簡而言之，pi MVP

81
00:03:40,799 --> 00:03:43,379
包是一個 python 包，用於

82
00:03:43,379 --> 00:03:45,299
模擬

83
00:03:45,299 --> 00:03:46,980
um 並

84
00:03:46,980 --> 00:03:49,739
以離散方式運行主動推理過程 狀態空間

85
00:03:49,739 --> 00:03:51,599
和離散狀態空間案例是一個

86
00:03:51,599 --> 00:03:53,879
經過充分研究的案例，

87
00:03:53,879 --> 00:03:55,560
嗯，它的特徵非常好，它

88
00:03:55,560 --> 00:03:57,360
在離散決策和規劃等決策模型中非常流行，

89
00:03:57,360 --> 00:03:58,980


90
00:03:58,980 --> 00:04:01,620
並且已經

91
00:04:01,620 --> 00:04:03,659
在神經科學中作為模型得到了很多應用

92
00:04:03,659 --> 00:04:05,159


93
00:04:05,159 --> 00:04:07,019


94
00:04:07,019 --> 00:04:10,700
例如人類或其他動物的離散決策行為，

95
00:04:11,819 --> 00:04:14,580
所以我將簡要介紹

96
00:04:14,580 --> 00:04:17,040
一下演示文稿，

97
00:04:17,040 --> 00:04:19,738
所以首先我將介紹

98
00:04:19,738 --> 00:04:21,839
從事 primevp 工作的團隊，

99
00:04:21,839 --> 00:04:23,699
我們是 primevp 的作者 這篇論文，但

100
00:04:23,699 --> 00:04:26,699
實際有效的團隊

101
00:04:26,699 --> 00:04:27,840
比這大得多，因為有很多

102
00:04:27,840 --> 00:04:29,460
人正在開發或

103
00:04:29,460 --> 00:04:31,020
使用它，並以他們自己的方式做出貢獻，但

104
00:04:31,020 --> 00:04:32,940
他們實際上並不是論文的合著者

105
00:04:32,940 --> 00:04:34,380


106
00:04:34,380 --> 00:04:35,820
，然後我將討論

107
00:04:35,820 --> 00:04:38,940
這個包的動機我將簡要

108
00:04:38,940 --> 00:04:40,680
概述離散狀態空間中的主動推理，

109
00:04:40,680 --> 00:04:44,580
但正如我所提到的，我

110
00:04:44,580 --> 00:04:47,340
認為這是一個非常好的

111
00:04:47,340 --> 00:04:48,960
討論關於 Palm DP 的場所，因為 我

112
00:04:48,960 --> 00:04:50,639
認為我不需要深入

113
00:04:50,639 --> 00:04:53,220
討論什麼是主動推理，這樣

114
00:04:53,220 --> 00:04:54,720
可以節省我們一些時間來

115
00:04:54,720 --> 00:04:58,080
更深入地了解池塘 DP

116
00:04:58,080 --> 00:04:59,400
嗯，我將討論現有

117
00:04:59,400 --> 00:05:00,960
的模擬主動

118
00:05:00,960 --> 00:05:03,240
推理代理的方法，例如 即在 Matlab 中

119
00:05:03,240 --> 00:05:05,400
使用 SPM，只是將

120
00:05:05,400 --> 00:05:08,400
Prime DP 與 SPM 進行比較和對比，並幫助

121
00:05:08,400 --> 00:05:10,440
我們理解 Prime

122
00:05:10,440 --> 00:05:12,479
DB

123
00:05:12,479 --> 00:05:15,139
的來源，嗯，就其在 SPM 中的起源而言，

124
00:05:15,139 --> 00:05:17,160
所以我們將討論一些

125
00:05:17,160 --> 00:05:18,840
功能 prime DP 及其通用

126
00:05:18,840 --> 00:05:20,820
包結構

127
00:05:20,820 --> 00:05:22,860
，然後我們將深入研究一些使用

128
00:05:22,860 --> 00:05:24,660
示例，其中我將展示一些

129
00:05:24,660 --> 00:05:27,600
模擬代理行為的類似輸出，

130
00:05:27,600 --> 00:05:29,520
然後是附帶的代碼，只是

131
00:05:29,520 --> 00:05:31,440
為了演示

132
00:05:31,440 --> 00:05:35,400
Pi mdp 的一般流程 看起來像，然後

133
00:05:35,400 --> 00:05:36,960
在最後我將只討論一些

134
00:05:36,960 --> 00:05:39,060
未來的方向和正在進行的

135
00:05:39,060 --> 00:05:42,060
um 活躍分支我猜 pine DP

136
00:05:42,060 --> 00:05:44,220
他們正在進行的開發工作，我

137
00:05:44,220 --> 00:05:47,400
認為這將使時間 EP 超級令人興奮

138
00:05:47,400 --> 00:05:48,600
和可擴展的

139
00:05:48,600 --> 00:05:50,880
um 到各種 新的用例，所以我對此感到

140
00:05:50,880 --> 00:05:53,699
非常興奮，現在，正如

141
00:05:53,699 --> 00:05:56,300
丹尼爾所說，如果有人想在任何時候

142
00:05:56,300 --> 00:05:59,400


143
00:05:59,400 --> 00:06:00,960
嗯，或者它有任何問題需要

144
00:06:00,960 --> 00:06:02,759
澄清，請隨時告訴

145
00:06:02,759 --> 00:06:04,199
我，我們可以詳細討論一些

146
00:06:04,199 --> 00:06:05,940
要點 更長的時間，

147
00:06:05,940 --> 00:06:08,639
嗯，好吧，所以我將首先介紹

148
00:06:08,639 --> 00:06:11,039
團隊，所以他們是

149
00:06:11,039 --> 00:06:13,440
我的論文版的合著

150
00:06:13,440 --> 00:06:15,900
者是米吉·達芙妮男爵讓我們今天在這裡，呃

151
00:06:15,900 --> 00:06:18,419
布倫南克萊因卡爾弗里斯頓伊恩堂兄

152
00:06:18,419 --> 00:06:21,360
和亞歷山大機會所以卡爾 伊恩是

153
00:06:21,360 --> 00:06:24,360
我的博士生導師

154
00:06:24,360 --> 00:06:27,020
，嗯，卡爾是 Matlab 中主動推理

155
00:06:27,020 --> 00:06:30,660
的 mdp 或離散狀態

156
00:06:30,660 --> 00:06:32,520
空間公式的原始祖先，

157
00:06:32,520 --> 00:06:34,080


158
00:06:34,080 --> 00:06:36,000
所以很高興得到他

159
00:06:36,000 --> 00:06:38,280
對我們在這裡的工作的認可

160
00:06:38,280 --> 00:06:41,220
，他有點 餘弦，

161
00:06:41,220 --> 00:06:43,680
然後我認為重要的是要

162
00:06:43,680 --> 00:06:45,840
強調這裡的每個人

163
00:06:45,840 --> 00:06:48,000
對包的重要性，這不僅僅是

164
00:06:48,000 --> 00:06:50,699
我做的，我猜大多數實際的

165
00:06:50,699 --> 00:06:52,080
軟件開發，但

166
00:06:52,080 --> 00:06:53,840
prime DP 的早期階段真的是

167
00:06:53,840 --> 00:06:56,639
之間的對話 我 Brennan 和

168
00:06:56,639 --> 00:07:00,000
Alec 早在 2019 年或什至更早的時候

169
00:07:00,000 --> 00:07:02,460
就需要一個進行主動推理的 python 包

170
00:07:02,460 --> 00:07:04,680
，我想

171
00:07:04,680 --> 00:07:05,819
當時其他人可能也有過

172
00:07:05,819 --> 00:07:07,440
類似的對話，

173
00:07:07,440 --> 00:07:10,080
但這是因為我們都走到了

174
00:07:10,080 --> 00:07:11,880
一起，所以我們 能夠

175
00:07:11,880 --> 00:07:14,699
在不太長的時間內構建這個東西我的

176
00:07:14,699 --> 00:07:16,979
意思是超過兩年而且

177
00:07:16,979 --> 00:07:18,660
如果我全職工作它可能會做得更快

178
00:07:18,660 --> 00:07:21,360
但它是嗯

179
00:07:21,360 --> 00:07:23,099
觀看進展真的很有趣

180
00:07:23,099 --> 00:07:25,319
然後正如達芙妮

181
00:07:25,319 --> 00:07:27,599
所說，她實際上

182
00:07:27,599 --> 00:07:30,240
是第

183
00:07:30,240 --> 00:07:32,520
一批在她自己的碩士論文中真正使用 um active Pi mdp 的人之一

184
00:07:32,520 --> 00:07:34,380
，不僅如此，而且在一個非常

185
00:07:34,380 --> 00:07:35,880
雄心勃勃的應用程序中，就像

186
00:07:35,880 --> 00:07:38,340
多代理集體行為有

187
00:07:38,340 --> 00:07:40,380
一堆松樹 DP 特工

188
00:07:40,380 --> 00:07:42,960
彼此互動以模擬

189
00:07:42,960 --> 00:07:45,060
Dynamics 和 Echo Chambers 以及

190
00:07:45,060 --> 00:07:46,680
社交網絡的那種觀點，這真的很令人興奮，

191
00:07:46,680 --> 00:07:49,139
所以與她一起工作真的很令人欣慰

192
00:07:49,139 --> 00:07:51,660
，嗯，是的，所以這

193
00:07:51,660 --> 00:07:53,400
真的很不錯 還要注意，Daphne 也是其中的一部分

194
00:07:53,400 --> 00:07:55,199
，因為它就像是

195
00:07:55,199 --> 00:07:57,960
pi mdp

196
00:07:57,960 --> 00:07:59,819
主動推理社區中先驅者的一個很好的例子，然後

197
00:07:59,819 --> 00:08:02,819
Baron 也是，呃，我，Alec 和 baron

198
00:08:02,819 --> 00:08:04,680
在開發一些

199
00:08:04,680 --> 00:08:06,360
更複雜的消息傳遞

200
00:08:06,360 --> 00:08:09,120
技術方面做了很多工作 inactive  Pym

201
00:08:09,120 --> 00:08:11,880
DP 和 uh Baron 中的推理

202
00:08:11,880 --> 00:08:15,120
在幫助我寫論文方面也非常重要，

203
00:08:15,120 --> 00:08:16,860
嗯，他非常擅長寫作和

204
00:08:16,860 --> 00:08:19,919
概念化，並且

205
00:08:19,919 --> 00:08:22,020
實際上還在他自己的一些

206
00:08:22,020 --> 00:08:24,360
關於後繼表示和主動

207
00:08:24,360 --> 00:08:27,060
推理的工作中使用了 privp，這是一種 很酷，

208
00:08:27,060 --> 00:08:27,599
嗯，

209
00:08:27,599 --> 00:08:30,240
好吧，我很清楚在座

210
00:08:30,240 --> 00:08:32,159
的每個人最重要的事情

211
00:08:32,159 --> 00:08:35,159
之一是

212
00:08:35,159 --> 00:08:37,700


213
00:08:37,700 --> 00:08:40,380
，在

214
00:08:40,380 --> 00:08:42,000
過去 10 年，尤其是最近

215
00:08:42,000 --> 00:08:43,979
5 年裡，人們對主動推理的流行和興趣要大得多，

216
00:08:43,979 --> 00:08:46,140
所以這很明顯 我們需要

217
00:08:46,140 --> 00:08:48,300
一些更通用的用戶友好

218
00:08:48,300 --> 00:08:49,860
框架，讓人們

219
00:08:49,860 --> 00:08:52,080


220
00:08:52,080 --> 00:08:53,700
首先從教學的角度

221
00:08:53,700 --> 00:08:54,959
以及 將其應用於他們自己的

222
00:08:54,959 --> 00:08:57,420
研究或工業應用，

223
00:08:57,420 --> 00:08:59,339
或者他們想用

224
00:08:59,339 --> 00:09:02,060
主動

225
00:09:02,100 --> 00:09:04,320
推理實際做

226
00:09:04,320 --> 00:09:05,880


227
00:09:05,880 --> 00:09:07,320
的任何

228
00:09:07,320 --> 00:09:08,880
事情

229
00:09:08,880 --> 00:09:10,680


230
00:09:10,680 --> 00:09:12,899


231
00:09:12,899 --> 00:09:14,580
軟件工程師

232
00:09:14,580 --> 00:09:17,820
和許多感興趣的領域，

233
00:09:17,820 --> 00:09:20,700
嗯，最主要的呃語言是

234
00:09:20,700 --> 00:09:23,880
python 所以當很多時候我

235
00:09:23,880 --> 00:09:25,200
聽到的是人們開始學習

236
00:09:25,200 --> 00:09:26,880
主動推理並且他們有

237
00:09:26,880 --> 00:09:28,500
python 或 r 或其他東西的背景

238
00:09:28,500 --> 00:09:29,880
他們發現這一切都在

239
00:09:29,880 --> 00:09:31,680
Matlab 中，他們有一種

240
00:09:31,680 --> 00:09:34,560
進入障礙，因為他們要么

241
00:09:34,560 --> 00:09:37,740
不知道 Matlab，要么

242
00:09:37,740 --> 00:09:39,959
很難解析 Matlab 代碼，特別是如果

243
00:09:39,959 --> 00:09:42,540
他們來自非數組編程

244
00:09:42,540 --> 00:09:44,339
框架，比如也許 他們是

245
00:09:44,339 --> 00:09:47,459
使用 uh JavaScript 之類的前端 Web 開發人員

246
00:09:47,459 --> 00:09:48,899
，他們

247
00:09:48,899 --> 00:09:50,220
實際上並不熟悉大型

248
00:09:50,220 --> 00:09:52,920
多維 數組編程

249
00:09:52,920 --> 00:09:55,200
嗯，這是

250
00:09:55,200 --> 00:09:57,180
專門製作一個執行主動推理的 python 包的另一個動機，

251
00:09:57,180 --> 00:10:01,019


252
00:10:01,019 --> 00:10:03,720
嗯，最後我們因為它在

253
00:10:03,720 --> 00:10:06,360
Python 中，這意味著我們現在正在

254
00:10:06,360 --> 00:10:08,940
創建一個可以與

255
00:10:08,940 --> 00:10:12,060
其他生態系統對話的生態系統，所以理想情況下

256
00:10:12,060 --> 00:10:14,459
primevp 不會 僅在

257
00:10:14,459 --> 00:10:16,860
僅使用 Pi mdp 的腳本中使用，它將

258
00:10:16,860 --> 00:10:19,500
與其他軟件包一起使用，其中一些軟件包

259
00:10:19,500 --> 00:10:20,760
與

260
00:10:20,760 --> 00:10:23,040
人工智能或網絡科學或

261
00:10:23,040 --> 00:10:24,420
各種相關的框架有關

262
00:10:24,420 --> 00:10:26,640
，因此您現在可以使用插件和

263
00:10:26,640 --> 00:10:29,220
與 piondp 代理一起玩並將它們放在

264
00:10:29,220 --> 00:10:31,080
開放式 AI 體育館等環境中以進行

265
00:10:31,080 --> 00:10:33,000
強化學習

266
00:10:33,000 --> 00:10:36,600
，呃，現在你可以

267
00:10:36,600 --> 00:10:39,000
在各種應用程序中使用主動推理，

268
00:10:39,000 --> 00:10:40,380
這對 python 來說真的很棒，因為

269
00:10:40,380 --> 00:10:43,019
python 的設計及其社區

270
00:10:43,019 --> 00:10:44,579
驅動的開發就是如此 許多

271
00:10:44,579 --> 00:10:46,860
不同的包都是

272
00:10:46,860 --> 00:10:49,140
為某些特定的東西構建得很好，所以現在

273
00:10:49,140 --> 00:10:51,540
它在 Python 中，你可以有點呃使用它

274
00:10:51,540 --> 00:10:54,240
與串聯 w 與所有其他

275
00:10:54,240 --> 00:10:57,079
python 包一樣，

276
00:10:58,079 --> 00:11:00,480
好的，現在簡要介紹主動推理，主動

277
00:11:00,480 --> 00:11:02,519
推理的基本

278
00:11:02,519 --> 00:11:05,640
範式是你

279
00:11:05,640 --> 00:11:07,500
考慮一個嵌入其環境中的代理，

280
00:11:07,500 --> 00:11:08,700


281
00:11:08,700 --> 00:11:11,519
而不像傳統的更

282
00:11:11,519 --> 00:11:15,540
被動的感知和

283
00:11:15,540 --> 00:11:18,540
行為方法，你有點 考慮

284
00:11:18,540 --> 00:11:20,880
環境為您提供信息，您進行

285
00:11:20,880 --> 00:11:22,560
一些感覺運動轉換，

286
00:11:22,560 --> 00:11:24,300
然後您執行一個動作

287
00:11:24,300 --> 00:11:26,279
活躍的嬰兒非常

288
00:11:26,279 --> 00:11:28,980
強調這樣一個事實，即推理或

289
00:11:28,980 --> 00:11:31,320
處理不確定性的問題是

290
00:11:31,320 --> 00:11:33,959
感知或我們

291
00:11:33,959 --> 00:11:36,000
所說的狀態估計或信念

292
00:11:36,000 --> 00:11:38,519
更新的特徵 作為

293
00:11:38,519 --> 00:11:40,500
主動推理部分

294
00:11:40,500 --> 00:11:42,300
發揮作用的行動，因此代理人不僅

295
00:11:42,300 --> 00:11:44,640
更新了他們對世界狀態

296
00:11:44,640 --> 00:11:46,320
的信念，還

297
00:11:46,320 --> 00:11:50,700
通過最小化這種

298
00:11:50,700 --> 00:11:52,620
被稱為自由能的驚喜所束縛的隱藏狀態，這

299
00:11:52,620 --> 00:11:55,380
就是這些 ham holsian

300
00:11:55,380 --> 00:11:58,500
感知作為推理的想法來自

301
00:11:58,500 --> 00:12:01,920
但你也在最小化驚喜

302
00:12:01,920 --> 00:12:05,279
或 一定會驚訝地選擇你的

303
00:12:05,279 --> 00:12:09,120
行動，所以推斷行動

304
00:12:09,120 --> 00:12:11,459
只是另一種推理

305
00:12:11,459 --> 00:12:13,740
問題，所以政策或

306
00:12:13,740 --> 00:12:15,839
行動序列被認為是潛在變量

307
00:12:15,839 --> 00:12:18,120
或隱藏狀態，然後你也

308
00:12:18,120 --> 00:12:21,000
對這些進行推斷並通過投下

309
00:12:21,000 --> 00:12:22,980
感知行動硬幣的兩面

310
00:12:22,980 --> 00:12:25,200
作為意外最小化的一個例子，

311
00:12:25,200 --> 00:12:27,899
你的事件是一種

312
00:12:27,899 --> 00:12:29,120
表現出

313
00:12:29,120 --> 00:12:32,940
有目的和好奇行為的代理人，

314
00:12:32,940 --> 00:12:35,519
並且非常像沒有關於主動推理的任何東西

315
00:12:35,519 --> 00:12:37,320
，這意味著你必須

316
00:12:37,320 --> 00:12:39,660
使用離散狀態空間或 Pi MVP

317
00:12:39,660 --> 00:12:42,720
，這只是一種特定類型或

318
00:12:42,720 --> 00:12:44,519
類別的生成 用於主動推理的模型，

319
00:12:44,519 --> 00:12:45,600


320
00:12:45,600 --> 00:12:49,320
但是嗯，Palm DP 離散狀態

321
00:12:49,320 --> 00:12:51,720
空間生成模型真的很

322
00:12:51,720 --> 00:12:53,279
容易與主動保險一起使用，

323
00:12:53,279 --> 00:12:54,899
因為當你處理 palm DPS 時，

324
00:12:54,899 --> 00:12:57,600
我在這裡展示的很多這些數量都非常容易

325
00:12:57,600 --> 00:12:59,040
計算

326
00:12:59,040 --> 00:13:00,660
或部分觀察到的標記

327
00:13:00,660 --> 00:13:02,820
決策過程，因此我們將

328
00:13:02,820 --> 00:13:04,800
稍微了解所有數學，

329
00:13:04,800 --> 00:13:06,600
但是 這只是

330
00:13:06,600 --> 00:13:08,820
主動推理代理和環境的基本範式

331
00:13:08,820 --> 00:13:11,100
試圖通過最小化意外來減少

332
00:13:11,100 --> 00:13:13,440
感知和行動的

333
00:13:13,440 --> 00:13:15,600
意外，

334
00:13:15,600 --> 00:13:17,100
嗯

335
00:13:17,100 --> 00:13:20,040
，只是為了

336
00:13:20,040 --> 00:13:22,079
對主動推理

337
00:13:22,079 --> 00:13:24,660
和離散狀態空間進行更深入的數學審查，即使用

338
00:13:24,660 --> 00:13:26,399
這些部分觀察到的馬爾可夫決策

339
00:13:26,399 --> 00:13:28,860
過程 我建議閱讀這篇

340
00:13:28,860 --> 00:13:31,620
論文，該論文在

341
00:13:31,620 --> 00:13:34,440
Lance Thomas

342
00:13:34,440 --> 00:13:38,040
Noor Sebastian victorita 和 Carl 撰寫的醫學心理學雜誌中非常出色，

343
00:13:38,040 --> 00:13:40,680
它只是

344
00:13:40,680 --> 00:13:42,899
從形式基礎上非常好的描述，說明我們如何

345
00:13:42,899 --> 00:13:44,459


346
00:13:44,459 --> 00:13:46,440
從最像形式的形式開始進行主動推理的更新方程式

347
00:13:46,440 --> 00:13:48,660
分類分佈和狄利克雷

348
00:13:48,660 --> 00:13:50,639
分佈的處理

349
00:13:50,639 --> 00:13:53,040
以及我們存檔的 pine DP 論文

350
00:13:53,040 --> 00:13:55,380
也有一堆

351
00:13:55,380 --> 00:13:58,079
附錄，這些附錄做了很多類似

352
00:13:58,079 --> 00:14:00,779
的數學運算，所以我也會推薦

353
00:14:00,779 --> 00:14:02,720
人們參考那個

354
00:14:02,720 --> 00:14:05,220
好吧，現在讓我們進入

355
00:14:05,220 --> 00:14:06,899
生成 在 Pym DP 中

356
00:14:06,899 --> 00:14:10,440
構成 uh 代理人大腦的麵包和黃油的模型

357
00:14:10,440 --> 00:14:13,139
本質上如此 Centr  al to

358
00:14:13,139 --> 00:14:14,760
active inferences writing down a

359
00:14:14,760 --> 00:14:16,800
generative model which is just

360
00:14:16,800 --> 00:14:19,139
an specification of an agent

361
00:14:19,139 --> 00:14:21,180
how believe its World Works 它

362
00:14:21,180 --> 00:14:22,980
的環境是

363
00:14:22,980 --> 00:14:24,839
如何運作的，嗯，它是如何相信它的環境

364
00:14:24,839 --> 00:14:27,540
會像世界的動態一樣影響自己，

365
00:14:27,540 --> 00:14:29,639
呃進步以及

366
00:14:29,639 --> 00:14:31,920
那些隱藏的如何 狀態動力學也會

367
00:14:31,920 --> 00:14:34,139
產生觀察結果，這些觀察結果全部編碼

368
00:14:34,139 --> 00:14:36,240
在我們稱之為生成模型或

369
00:14:36,240 --> 00:14:38,519
世界模型中，有些人也稱之為世界模型，

370
00:14:38,519 --> 00:14:39,839
因此

371
00:14:39,839 --> 00:14:43,199
在 Pine DP 中，我們只處理一種非常

372
00:14:43,199 --> 00:14:44,820
特定的性別模型，這些模型

373
00:14:44,820 --> 00:14:45,959
被稱為這些部分觀察到的

374
00:14:45,959 --> 00:14:48,600
馬爾可夫決策過程 所以這些是

375
00:14:48,600 --> 00:14:50,279


376
00:14:50,279 --> 00:14:52,380
不確定情況下連續決策和規劃的經典模型

377
00:14:52,380 --> 00:14:54,180
它們不是主動推理所獨有的

378
00:14:54,180 --> 00:14:57,480
人們使用 Palm DP 模型進行經典

379
00:14:57,480 --> 00:14:59,160
強化學習和各種

380
00:14:59,160 --> 00:15:01,620
決策問題

381
00:15:01,620 --> 00:15:03,480
嗯 它們被稱為馬爾可夫馬爾可夫

382
00:15:03,480 --> 00:15:05,279
決策過程 因為

383
00:15:05,279 --> 00:15:07,440
當前時間的狀態僅取決於

384
00:15:07,440 --> 00:15:09,060
前一時間狀態中的動作，

385
00:15:09,060 --> 00:15:10,740
因此這就是定義 在馬爾可夫

386
00:15:10,740 --> 00:15:12,420
過程中，它們有點具有這種淺

387
00:15:12,420 --> 00:15:14,339
時間依賴性

388
00:15:14,339 --> 00:15:15,800
，例如，非馬爾可夫

389
00:15:15,800 --> 00:15:18,120
過程不像

390
00:15:18,120 --> 00:15:20,279
具有長期或更深時間

391
00:15:20,279 --> 00:15:21,899
依賴性的過程那樣延伸

392
00:15:21,899 --> 00:15:23,579
到過去，

393
00:15:23,579 --> 00:15:25,680
嗯，Palm DPS 通常 但並不總是

394
00:15:25,680 --> 00:15:27,720
製定離散狀態空間和

395
00:15:27,720 --> 00:15:29,940
離散時間關於

396
00:15:29,940 --> 00:15:32,760
palmdp 這個詞沒有任何意義意味著它們必須是

397
00:15:32,760 --> 00:15:35,160
這些多項式或分類

398
00:15:35,160 --> 00:15:37,500
分佈但是當我們

399
00:15:37,500 --> 00:15:39,240
談論 Palm DPS 和主動影響時

400
00:15:39,240 --> 00:15:40,980
我們幾乎總是在談論這些

401
00:15:40,980 --> 00:15:43,760
離散的

402
00:15:43,800 --> 00:15:45,899
嗯 基本上你

403
00:15:45,899 --> 00:15:47,940
一次只能處於 K 個離散狀態

404
00:15:47,940 --> 00:15:50,279
之一，下一次你只能進入

405
00:15:50,279 --> 00:15:52,260
K 個離散狀態之一，所以

406
00:15:52,260 --> 00:15:53,699
一切都是離散的，但

407
00:15:53,699 --> 00:15:55,920
這些馬爾可夫

408
00:15:55,920 --> 00:15:57,240
決策過程本質上沒有什麼必須是

409
00:15:57,240 --> 00:15:59,040
離散的 I 我認為這值得

410
00:15:59,040 --> 00:16:00,420
一提，因為這

411
00:16:00,420 --> 00:16:02,820
是人們

412
00:16:02,820 --> 00:16:04,139
在看到 Palm DP um 時經常做出的一種重要混合

413
00:16:04,139 --> 00:16:05,699


414
00:16:05,699 --> 00:16:08,279
我們決定使用這個

415
00:16:08,279 --> 00:16:11,040
uh 離散 Palm DP 生成模型進行

416
00:16:11,040 --> 00:16:12,899
主動推理的原因不僅僅是因為

417
00:16:12,899 --> 00:16:15,899
它在順序決策和規劃中的應用，

418
00:16:15,899 --> 00:16:18,060
而且

419
00:16:18,060 --> 00:16:20,339


420
00:16:20,339 --> 00:16:24,240
自 2010 年到 2011 年以來已有大量關於

421
00:16:24,240 --> 00:16:26,760
使用 pom DPS 作為 用於

422
00:16:26,760 --> 00:16:28,079
決策測試的生成模型，所以用這些模型

423
00:16:28,079 --> 00:16:30,540
進行主動推理的所有數學

424
00:16:30,540 --> 00:16:32,699
都已經完成，所以我們

425
00:16:32,699 --> 00:16:34,860
不必發明任何新的數學或

426
00:16:34,860 --> 00:16:36,720
理論來實際編寫代碼，

427
00:16:36,720 --> 00:16:38,339
因為其中很多已經寫在

428
00:16:38,339 --> 00:16:41,040
論文中 就像 10 年這樣讓

429
00:16:41,040 --> 00:16:44,100
我們的生活更輕鬆開發它所以

430
00:16:44,100 --> 00:16:46,320
現在讓我們深入

431
00:16:46,320 --> 00:16:48,899
了解這些 Palm DPS 的主要組件

432
00:16:48,899 --> 00:16:51,480
呃我在這裡只列出四個主要

433
00:16:51,480 --> 00:16:54,360
組件但是

434
00:16:54,360 --> 00:16:55,980
如果有人感興趣我們可以討論其他組件

435
00:16:55,980 --> 00:16:58,560
但是 本質

436
00:16:58,560 --> 00:17:01,199
上，頂部的這一行是

437
00:17:01,199 --> 00:17:02,820
根據

438
00:17:02,820 --> 00:17:05,099


439
00:17:05,099 --> 00:17:08,640
Into the Fut 中隱藏狀態 s 和觀察值 o 的聯合分佈對生成模型的描述 是的

440
00:17:08,640 --> 00:17:11,939
，嗯，因為

441
00:17:11,939 --> 00:17:13,500
這個生成模型的馬爾可夫性質，你可以

442
00:17:13,500 --> 00:17:15,000
寫

443
00:17:15,000 --> 00:17:16,619
這個聯合分佈，這個

444
00:17:16,619 --> 00:17:20,339
分解的基本乘積是

445
00:17:20,339 --> 00:17:22,559
先驗和

446
00:17:22,559 --> 00:17:24,179
跨時間因式分解的可能性，所以這就是為什麼

447
00:17:24,179 --> 00:17:25,740
它們是隨著時間的推移在頂部的那些產品，

448
00:17:25,740 --> 00:17:27,839
但它

449
00:17:27,839 --> 00:17:29,640
現在理解數學並不重要，但

450
00:17:29,640 --> 00:17:31,440
我們將

451
00:17:31,440 --> 00:17:34,320
在一秒鐘內映射到示意圖上的主要組成部分是代理

452
00:17:34,320 --> 00:17:36,360
關於隱藏狀態如何

453
00:17:36,360 --> 00:17:38,940
引起觀察的信念，我們將其編碼在

454
00:17:38,940 --> 00:17:40,440
稱為觀察模型

455
00:17:40,440 --> 00:17:42,539
或似然映射的東西中 通常

456
00:17:42,539 --> 00:17:45,360
稱為 a 矩陣或 a 數組，所以這是

457
00:17:45,360 --> 00:17:47,820


458
00:17:47,820 --> 00:17:50,460
當前隱藏狀態如何影響

459
00:17:50,460 --> 00:17:52,559
或引起

460
00:17:52,559 --> 00:17:54,000
當前

461
00:17:54,000 --> 00:17:56,340
時間觀察的概率表示，我們有轉換或

462
00:17:56,340 --> 00:17:58,860
動態模型，這是另

463
00:17:58,860 --> 00:18:02,039
一種編碼的可能性 agent 對

464
00:18:02,039 --> 00:18:03,960
某一

465
00:18:03,960 --> 00:18:05,640
時刻的隱藏狀態如何與下一次的隱藏狀態相關的信念，

466
00:18:05,640 --> 00:18:08,100
所以這個 Maps

467
00:18:08,100 --> 00:18:09,960
um 這就是 agent 使用的 對

468
00:18:09,960 --> 00:18:12,539


469
00:18:12,539 --> 00:18:14,940
如果發生這種情況或發生那種情況世界將如何演變做出前瞻性預測

470
00:18:14,940 --> 00:18:17,100
，並根據我昨天所在的位置攜帶過去的

471
00:18:17,100 --> 00:18:19,080
信息或經驗先驗，

472
00:18:19,080 --> 00:18:22,080


473
00:18:22,080 --> 00:18:24,720
現在我必須在哪裡給出我

474
00:18:24,720 --> 00:18:26,400
對世界如何演變的信念 有時這

475
00:18:26,400 --> 00:18:28,860
一切都編碼在 B 數組或 B

476
00:18:28,860 --> 00:18:31,679
矩陣中，然後這最後兩個

477
00:18:31,679 --> 00:18:33,600
是先驗

478
00:18:33,600 --> 00:18:35,700
的，其中第一個非常重要

479
00:18:35,700 --> 00:18:38,880
，稱為 C 數組或 C

480
00:18:38,880 --> 00:18:41,340
向量，它編碼代理人的先驗

481
00:18:41,340 --> 00:18:43,679
信念可能是什麼觀察結果

482
00:18:43,679 --> 00:18:46,260
遇到，正如我們在一開始所說的那樣

483
00:18:46,260 --> 00:18:47,520
，主動推理就是

484
00:18:47,520 --> 00:18:49,980
將行動和感知都

485
00:18:49,980 --> 00:18:51,660
視為一個推理問題，

486
00:18:51,660 --> 00:18:54,900
因此主動推理作為一種框架

487
00:18:54,900 --> 00:18:56,880
，

488
00:18:56,880 --> 00:18:58,500


489
00:18:58,500 --> 00:19:00,480
通過說而不是獎勵來顛覆獎勵函數和強化學習的經典範式

490
00:19:00,480 --> 00:19:02,700
function 只是讓 agent 有

491
00:19:02,700 --> 00:19:04,559
一種樂觀的信念，相信

492
00:19:04,559 --> 00:19:07,140
將來我會看到這種數據，

493
00:19:07,140 --> 00:19:09,120
然後通過 resp 進行推理

494
00:19:09,120 --> 00:19:10,980
對於具有先驗信念的生成模型

495
00:19:10,980 --> 00:19:13,200
，代理人

496
00:19:13,200 --> 00:19:14,820
看起來像是在尋找

497
00:19:14,820 --> 00:19:16,919
符合其先驗的觀察結果，

498
00:19:16,919 --> 00:19:19,140
因此這符合這樣的

499
00:19:19,140 --> 00:19:21,419
想法，即主動推理是

500
00:19:21,419 --> 00:19:23,340
代理人相信我的自我實現預言的過程

501
00:19:23,340 --> 00:19:25,919
我或多或少可能會看到

502
00:19:25,919 --> 00:19:27,840
某些觀察結果，然後通過

503
00:19:27,840 --> 00:19:30,780
對具有這種

504
00:19:30,780 --> 00:19:32,580
偏向於生成模型的策略進行推理，代理人會

505
00:19:32,580 --> 00:19:34,740
有點使自己真正意識到

506
00:19:34,740 --> 00:19:37,799
其先驗偏好或這些

507
00:19:37,799 --> 00:19:40,020
關於觀察的先驗信念，

508
00:19:40,020 --> 00:19:42,660
因此所有這些都編碼在 C vector

509
00:19:42,660 --> 00:19:44,880
和 C Vector 你基本上可以

510
00:19:44,880 --> 00:19:48,000
認為是獎勵函數的貝葉斯翻譯

511
00:19:48,000 --> 00:19:49,340
，你實際上可以

512
00:19:49,340 --> 00:19:51,600
將 C Vector 的條目與

513
00:19:51,600 --> 00:19:53,220
兩個獎勵和強化

514
00:19:53,220 --> 00:19:55,080
學習聯繫起來，但我們不會，我們不必

515
00:19:55,080 --> 00:19:57,000
進入那個 現在，但

516
00:19:57,000 --> 00:20:00,000
如果有人感興趣，我可以分享論文，

517
00:20:00,000 --> 00:20:01,919
最後是隱藏狀態的先驗，

518
00:20:01,919 --> 00:20:04,200
這只是代理人

519
00:20:04,200 --> 00:20:07,559
對先驗 li 的信念

520
00:20:07,559 --> 00:20:09,539
每個隱藏狀態在模擬的第一個

521
00:20:09,539 --> 00:20:11,820
時間步的可能性，所以這

522
00:20:11,820 --> 00:20:14,160
在主動推理中並不是真正必要的事情，

523
00:20:14,160 --> 00:20:15,900
但通常當我們

524
00:20:15,900 --> 00:20:18,299
模擬代理時，我們

525
00:20:18,299 --> 00:20:20,039
使用具有開始時間

526
00:20:20,039 --> 00:20:23,280
和結束時間的有限時間範圍 所以如果你有一個

527
00:20:23,280 --> 00:20:25,200
有限的臨時地平線，這意味著

528
00:20:25,200 --> 00:20:27,240
你必須基本上插入一個

529
00:20:27,240 --> 00:20:29,100
關於世界

530
00:20:29,100 --> 00:20:31,740
在時間步長是什麼樣子的先驗信念，並且先驗信念

531
00:20:31,740 --> 00:20:34,940
被編碼在這個 d d 向量中

532
00:20:34,940 --> 00:20:38,460
，我們可以直觀地勾勒

533
00:20:38,460 --> 00:20:41,039
出 Palm DP 生成模型作為

534
00:20:41,039 --> 00:20:43,799
貝葉斯圖，其中如果節點

535
00:20:43,799 --> 00:20:45,720
彼此依賴，則節點通過這些箭頭的邊連接，

536
00:20:45,720 --> 00:20:47,280
因此這些紅色節點

537
00:20:47,280 --> 00:20:48,660
表示

538
00:20:48,660 --> 00:20:51,720
隨著時間的推移相互轉換的隱藏狀態

539
00:20:51,720 --> 00:20:53,700
，藍色節點 O 節點

540
00:20:53,700 --> 00:20:56,340
表示代理的信念 關於如何

541
00:20:56,340 --> 00:20:58,320
從這些隱藏狀態生成觀察結果，

542
00:20:58,320 --> 00:21:00,299
所以這只是

543
00:21:00,299 --> 00:21:02,760
Palm DP 的圖形表示

544
00:21:02,760 --> 00:21:05,580
和矩陣編碼，正如我們所說的

545
00:21:05,580 --> 00:21:07,020
代理人對那些隱藏狀態的信念 d

546
00:21:07,020 --> 00:21:09,120
節點隨時產生藍色節點，

547
00:21:09,120 --> 00:21:11,280
所以通常我們假設這個

548
00:21:11,280 --> 00:21:13,740
矩陣是時不變的，所以他們

549
00:21:13,740 --> 00:21:15,539
相信這個觀察映射

550
00:21:15,539 --> 00:21:18,120
本身並不依賴於時間，這

551
00:21:18,120 --> 00:21:19,980
至少是大多數 Palm DPS 中所做的假設

552
00:21:19,980 --> 00:21:21,840


553
00:21:21,840 --> 00:21:25,860
，然後 還有代理人時

554
00:21:25,860 --> 00:21:27,299
不變的信念，

555
00:21:27,299 --> 00:21:30,179
關於世界的轉換動態如何

556
00:21:30,179 --> 00:21:32,940
帶來時間 T 減去時間 1 的兩個狀態

557
00:21:32,940 --> 00:21:35,159


558
00:21:35,159 --> 00:21:38,280
en 然後政策選擇或

559
00:21:38,280 --> 00:21:41,760
行動通過將行動框架化為受控轉變在非主動推理中發揮

560
00:21:41,760 --> 00:21:43,559
作用，

561
00:21:43,559 --> 00:21:46,980
所以 B  Matrix

562
00:21:46,980 --> 00:21:49,020
不只是說它應該

563
00:21:49,020 --> 00:21:50,520
如何考慮到昨天的世界現在應該如何看，

564
00:21:50,520 --> 00:21:52,919


565
00:21:52,919 --> 00:21:55,320
而且考慮到昨天的情況

566
00:21:55,320 --> 00:21:57,720
以及我在時間 T 減一時採取這個行動的事實，它現在應該如何看待，

567
00:21:57,720 --> 00:21:59,820
所以 B Matrix 不僅是

568
00:21:59,820 --> 00:22:01,559
以過去的狀態為條件，也以

569
00:22:01,559 --> 00:22:04,320
以前的行為為條件，因此政策 Pi

570
00:22:04,320 --> 00:22:07,140
作為對這些行為的信念或分佈發揮

571
00:22:07,140 --> 00:22:10,020
作用，因此這些行為

572
00:22:10,020 --> 00:22:11,880
直接影響轉換，

573
00:22:11,880 --> 00:22:13,320
然後影響交易 狀態會影響狀態，

574
00:22:13,320 --> 00:22:14,520
所以這就是我們

575
00:22:14,520 --> 00:22:18,059
在許多 palm DP 場景和

576
00:22:18,059 --> 00:22:20,760
動作中考慮動作的方式，或者策略 Pi

577
00:22:20,760 --> 00:22:23,520
是動作序列或動作集合

578
00:22:23,520 --> 00:22:26,039
，然後我們有這個關鍵的目標

579
00:22:26,039 --> 00:22:28,380
函數，呃，稱為預期自由

580
00:22:28,380 --> 00:22:31,080
能，它決定 哪些行動

581
00:22:31,080 --> 00:22:33,299
比其他行動更有可能，因此通過最小化

582
00:22:33,299 --> 00:22:35,820
預期的自由能，我們優化了

583
00:22:35,820 --> 00:22:37,860
對政策的信念，然後

584
00:22:37,860 --> 00:22:39,659
預期的自由能本身是

585
00:22:39,659 --> 00:22:41,280
你的生成模型的函數你

586
00:22:41,280 --> 00:22:43,500
對世界的信念，其中包括

587
00:22:43,500 --> 00:22:45,539
關於你期望自己觀察什麼的偏見先驗信念

588
00:22:45,539 --> 00:22:47,580


589
00:22:47,580 --> 00:22:50,220
看到這種獎勵函數

590
00:22:50,220 --> 00:22:52,919
通過這種預期的自由能進入政策選擇

591
00:22:52,919 --> 00:22:54,240
，這就是為什麼我們仍然能夠

592
00:22:54,240 --> 00:22:57,000
將所有這些稱為

593
00:22:57,000 --> 00:22:58,559
推理問題的一種形式，因為我們正在

594
00:22:58,559 --> 00:23:00,780
最小化這種預期的

595
00:23:00,780 --> 00:23:03,600
驚喜界限 這樣做我們可以

596
00:23:03,600 --> 00:23:05,640
推斷出政策的分佈，

597
00:23:05,640 --> 00:23:08,400
然後我們從中抽樣以實際產生

598
00:23:08,400 --> 00:23:10,500
行動並改變

599
00:23:10,500 --> 00:23:12,539
世界 d 然後就像我說的那樣，D 向量

600
00:23:12,539 --> 00:23:14,340
基本上只是初始隱藏狀態分佈的先驗，

601
00:23:14,340 --> 00:23:17,959


602
00:23:18,179 --> 00:23:19,260


603
00:23:19,260 --> 00:23:22,679
所以總而言之，要構建一個 palmdp

604
00:23:22,679 --> 00:23:24,120
主動推理模型，

605
00:23:24,120 --> 00:23:26,700
你必須寫下或編碼

606
00:23:26,700 --> 00:23:29,460
這些 a b c 和 D，還有一些

607
00:23:29,460 --> 00:23:30,900
其他先驗 我們也可以

608
00:23:30,900 --> 00:23:33,000
像先驗策略一樣討論

609
00:23:33,000 --> 00:23:34,980
稱為 e Vector 但現在你

610
00:23:34,980 --> 00:23:37,200
可以認為

611
00:23:37,200 --> 00:23:39,780
主動推理中的大部分繁重工作包括

612
00:23:39,780 --> 00:23:41,039
寫下這些東西實際上

613
00:23:41,039 --> 00:23:43,620
編碼你的代理人

614
00:23:43,620 --> 00:23:46,320
對世界的看法 它存在於

615
00:23:46,320 --> 00:23:48,120
嗯，這些東西在這些分類離散分佈的情況下，

616
00:23:48,120 --> 00:23:50,520
它們

617
00:23:50,520 --> 00:23:53,159
最終看起來像矩陣和向量，

618
00:23:53,159 --> 00:23:54,900
因為一切都是分類

619
00:23:54,900 --> 00:23:57,059
分佈，你不是在

620
00:23:57,059 --> 00:23:59,100
處理連續的無限維

621
00:23:59,100 --> 00:24:01,200
空間，而是在處理

622
00:24:01,200 --> 00:24:02,940
具有離散數字的東西 諸如

623
00:24:02,940 --> 00:24:05,340
四乘四矩陣或五乘五

624
00:24:05,340 --> 00:24:07,260
矩陣之類的條目

625
00:24:07,260 --> 00:24:10,980
嗯是的我想在我們是之前所以

626
00:24:10,980 --> 00:24:12,299
下一部分我將討論

627
00:24:12,299 --> 00:24:14,760
像 Matlab py  thon

628
00:24:14,760 --> 00:24:17,340
um dialectic before we move on that

629
00:24:17,340 --> 00:24:19,200
though we should may pause if there are

630
00:24:19,200 --> 00:24:21,780
any questions

631
00:24:21,780 --> 00:24:25,080
foreign yeah 非常感謝

632
00:24:25,080 --> 00:24:28,020
Daphne 或 Jakob 你想提供

633
00:24:28,020 --> 00:24:31,879
任何想法或思考嗎？

634
00:24:35,000 --> 00:24:37,020
有一件事我一直

635
00:24:37,020 --> 00:24:38,340
有點困惑

636
00:24:38,340 --> 00:24:40,620
現在可能會很好地解決

637
00:24:40,620 --> 00:24:42,360
之前偏好的參數化，

638
00:24:42,360 --> 00:24:43,980


639
00:24:43,980 --> 00:24:47,640
你能解釋一下

640
00:24:47,640 --> 00:24:49,980
為什麼當你初始化它們時你只是

641
00:24:49,980 --> 00:24:52,760
用像

642
00:24:52,799 --> 00:24:55,679
um 整數一樣大於 1

643
00:24:55,679 --> 00:24:57,900
大於或等於 1 但

644
00:24:57,900 --> 00:25:00,299
你喜歡 soft maximum 稍後當你

645
00:25:00,299 --> 00:25:02,039
實際使用像為什麼

646
00:25:02,039 --> 00:25:04,559
我們不定義我們對這些概率的

647
00:25:04,559 --> 00:25:05,820


648
00:25:05,820 --> 00:25:08,460
偏好這樣的推理時，這是一個很好的，這是一個很好的

649
00:25:08,460 --> 00:25:13,380
點，也是一件值得提及的好事，

650
00:25:13,620 --> 00:25:15,960
所以通常在 Matlab 和

651
00:25:15,960 --> 00:25:17,940
python 實現中，所以在構建時

652
00:25:17,940 --> 00:25:22,559
Pi mdp 我們決定在對

653
00:25:22,559 --> 00:25:24,659
c Vector 進行編碼時做同樣的事情，

654
00:25:24,659 --> 00:25:27,299
而不是將其編碼為

655
00:25:27,299 --> 00:25:29,039
概率，它最終應該

656
00:25:29,039 --> 00:25:31,260
是你想要的 ally write down

657
00:25:31,260 --> 00:25:33,840
是 C Vector 的對數，所以你

658
00:25:33,840 --> 00:25:36,419
根據相對對數概率將其寫下來

659
00:25:36,419 --> 00:25:40,080
，這可能是一個

660
00:25:40,080 --> 00:25:41,580


661
00:25:41,580 --> 00:25:44,340
更直觀的參數化而

662
00:25:44,340 --> 00:25:46,080
不是直接根據概率寫下來的

663
00:25:46,080 --> 00:25:49,620
原因是因為概率的對數

664
00:25:49,620 --> 00:25:51,840
是 更像是實際的

665
00:25:51,840 --> 00:25:54,299
獎勵，所以如果我們回到這個

666
00:25:54,299 --> 00:25:56,220
生成模型，

667
00:25:56,220 --> 00:25:59,039
作為自由能的預期自由能

668
00:25:59,039 --> 00:26:01,559
實際上是

669
00:26:01,559 --> 00:26:02,220
um

670
00:26:02,220 --> 00:26:04,559
然後自由能是

671
00:26:04,559 --> 00:26:06,960
一種 KL 散度，

672
00:26:06,960 --> 00:26:08,820
它是用自然對數形式的比特編碼的

673
00:26:08,820 --> 00:26:10,320
空間

674
00:26:10,320 --> 00:26:13,620
所以如果你在日誌空間方面像之前那樣寫下來

675
00:26:13,620 --> 00:26:17,820
你

676
00:26:17,820 --> 00:26:21,059
知道如果我改變

677
00:26:21,059 --> 00:26:24,059
我之前的偏好中的日誌單位數量我

678
00:26:24,059 --> 00:26:26,400
有它它與預期免費的變化更線性相關

679
00:26:26,400 --> 00:26:28,380


680
00:26:28,380 --> 00:26:30,080
導致該觀察的策略的能量，

681
00:26:30,080 --> 00:26:32,220
而如果您

682
00:26:32,220 --> 00:26:35,760
根據概率空間寫先驗，那麼

683
00:26:35,760 --> 00:26:37,980
ex 預期

684
00:26:37,980 --> 00:26:39,779
自由能因改變某些東西而產生的變化

685
00:26:39,779 --> 00:26:43,320
概率空間中的 g 不會是

686
00:26:43,320 --> 00:26:45,120
線性的，它會是非線性的

687
00:26:45,120 --> 00:26:45,900
變化，

688
00:26:45,900 --> 00:26:48,659
所以如果我們將獎勵視為對數

689
00:26:48,659 --> 00:26:49,919
概率

690
00:26:49,919 --> 00:26:53,100
，就像一個額外的對數單位

691
00:26:53,100 --> 00:26:55,919
或一個自然對數，一個 Nat 或

692
00:26:55,919 --> 00:26:59,279
比另一個東西更有價值一點 這

693
00:26:59,279 --> 00:27:00,960
實際上會根據

694
00:27:00,960 --> 00:27:02,460


695
00:27:02,460 --> 00:27:04,799
看到事物一與事物二之間的預期自由能差異來反映自己，

696
00:27:04,799 --> 00:27:06,480
而如果我們

697
00:27:06,480 --> 00:27:08,340
根據概率對這兩件事進行編碼，那麼

698
00:27:08,340 --> 00:27:10,020
預期的自由能差異將不會

699
00:27:10,020 --> 00:27:12,299
那麼直觀，因為它不是

700
00:27:12,299 --> 00:27:13,740
線性的

701
00:27:13,740 --> 00:27:16,080
嗯，這就是為什麼

702
00:27:16,080 --> 00:27:18,659
我們決定在對數空間中編碼事物的一個快速原因，

703
00:27:18,659 --> 00:27:21,179
但是在數學上沒有

704
00:27:21,179 --> 00:27:23,039
任何必要的東西，你可以很容易地

705
00:27:23,039 --> 00:27:24,240


706
00:27:24,240 --> 00:27:26,580
直接用

707
00:27:26,580 --> 00:27:29,039
概率來寫先驗，它更像

708
00:27:29,039 --> 00:27:30,779
是一種方法 讓它

709
00:27:30,779 --> 00:27:32,460
更像真正的獎勵

710
00:27:32,460 --> 00:27:36,200
是的，這很有意義謝謝，

711
00:27:36,200 --> 00:27:39,860
謝謝雅各布

712
00:27:40,140 --> 00:27:43,260
是的，嗯，我想知道

713
00:27:43,260 --> 00:27:44,880


714
00:27:44,880 --> 00:27:49,860
amb 矩陣

715
00:27:49,860 --> 00:27:53,039
或張量是否有心臟要求是實際的 ly 編碼為

716
00:27:53,039 --> 00:27:56,279
分類矩陣，或者因為

717
00:27:56,279 --> 00:27:58,020
考慮像 a 矩陣的函數

718
00:27:58,020 --> 00:28:00,840
以及代理使用它

719
00:28:00,840 --> 00:28:03,000
從觀察中推斷其隱藏狀態的方式，我在

720
00:28:03,000 --> 00:28:05,340
考慮

721
00:28:05,340 --> 00:28:07,980
是否有可能將高

722
00:28:07,980 --> 00:28:09,720
維狀態空間編碼

723
00:28:09,720 --> 00:28:11,460
為神經網絡 網絡可以

724
00:28:11,460 --> 00:28:14,279
近似呃這些概率

725
00:28:14,279 --> 00:28:17,279
表示以及學習

726
00:28:17,279 --> 00:28:20,039
表示

727
00:28:20,039 --> 00:28:23,400
觀察和隱藏狀態之間關係的類型

728
00:28:23,400 --> 00:28:25,460


729
00:28:25,500 --> 00:28:29,460
嗯是的肯定是的所以基本上

730
00:28:29,460 --> 00:28:32,460
很抱歉可能會有類似的但

731
00:28:32,460 --> 00:28:34,080
基本上你是否認為這

732
00:28:34,080 --> 00:28:36,779
是可能的因為我我 感覺就像

733
00:28:36,779 --> 00:28:39,179
是 python 實現，我相信

734
00:28:39,179 --> 00:28:41,880
你會了解 python 相對於 Matlab 的優勢，

735
00:28:41,880 --> 00:28:43,980
嗯，

736
00:28:43,980 --> 00:28:46,799
它還提供了與

737
00:28:46,799 --> 00:28:51,919
其他庫和數據科學內部的互操作性，

738
00:28:51,919 --> 00:28:54,659
完全是的，這是一個很好的觀點，

739
00:28:54,659 --> 00:28:56,880
所以我在

740
00:28:56,880 --> 00:28:59,159
一開始就提到了我們 談到 Palm DPS

741
00:28:59,159 --> 00:29:01,020
沒有關於 Palm DPS 的內容，這

742
00:29:01,020 --> 00:29:02,520
意味著所有這些東西都必須是

743
00:29:02,520 --> 00:29:05,279
矩陣 在 EP 上定義的主要內容

744
00:29:05,279 --> 00:29:06,600
是它是部分

745
00:29:06,600 --> 00:29:09,419
可觀察的，因此代理只能

746
00:29:09,419 --> 00:29:11,820
看到藍色節點，並且它是

747
00:29:11,820 --> 00:29:14,100
一個馬爾可夫過程，因此隱藏狀態

748
00:29:14,100 --> 00:29:16,080
的記憶中有一個暫時的淺度，

749
00:29:16,080 --> 00:29:18,000
但你可以替換

750
00:29:18,000 --> 00:29:21,240
a 和 b 對於任何類型的參數化，

751
00:29:21,240 --> 00:29:23,279
它都必須是一個適當的似然

752
00:29:23,279 --> 00:29:26,159
函數，所以它必須具有像

753
00:29:26,159 --> 00:29:28,080
嗯適當的可能性的屬性，

754
00:29:28,080 --> 00:29:29,940
沒有什麼

755
00:29:29,940 --> 00:29:32,820
意味著它不能是多元高斯

756
00:29:32,820 --> 00:29:35,159
分佈或科西分佈或伯努利

757
00:29:35,159 --> 00:29:38,279
分佈或呃 是的，任何一種

758
00:29:38,279 --> 00:29:41,220
指數族或

759
00:29:41,220 --> 00:29:43,440


760
00:29:43,440 --> 00:29:46,140
類似人們在強化學習中經常使用的參數化神經網絡，

761
00:29:46,140 --> 00:29:47,399
就像他們會

762
00:29:47,399 --> 00:29:49,200
用一堆神經網絡參數化動力學模型

763
00:29:49,200 --> 00:29:51,720
，這些神經網絡說

764
00:29:51,720 --> 00:29:53,820
在時間 T 獲取時間狀態並將它們移動

765
00:29:53,820 --> 00:29:56,340
到狀態 在時間 t 加 1 時，

766
00:29:56,340 --> 00:29:58,799
存在困難的原因僅僅

767
00:29:58,799 --> 00:30:00,899
是因為不清楚

768
00:30:00,899 --> 00:30:03,000
如何計算諸如一旦你站起來後的預期

769
00:30:03,000 --> 00:30:06,059
自由能之類的東西 rt 進入

770
00:30:06,059 --> 00:30:07,320
這些

771
00:30:07,320 --> 00:30:10,020
um 表現不佳的分佈，

772
00:30:10,020 --> 00:30:12,539
所以這個

773
00:30:12,539 --> 00:30:14,580
框架是在離散

774
00:30:14,580 --> 00:30:17,220
分類狀態版本中開發的很多原因不僅

775
00:30:17,220 --> 00:30:19,260
是因為對低維任務建模，

776
00:30:19,260 --> 00:30:21,299
比如有人玩老虎

777
00:30:21,299 --> 00:30:23,880
機或決定向左或

778
00:30:23,880 --> 00:30:27,240
向右 a 在 y 迷宮中，很容易使用這些

779
00:30:27,240 --> 00:30:29,279
離散分佈來

780
00:30:29,279 --> 00:30:30,720
很好地描述這種行為，這是

781
00:30:30,720 --> 00:30:32,640
一回事，但實際上也是一種

782
00:30:32,640 --> 00:30:34,980
數學易處理性，原因

783
00:30:34,980 --> 00:30:37,080
是預期的自由能並不總是封閉形式的解決方案，

784
00:30:37,080 --> 00:30:38,820


785
00:30:38,820 --> 00:30:40,559
具體取決於那些那些

786
00:30:40,559 --> 00:30:42,899
分佈看起來像所以有一些

787
00:30:42,899 --> 00:30:45,000
工作要做，例如 Magnus

788
00:30:45,000 --> 00:30:48,480
cudall 有一篇關於熵的論文，他們

789
00:30:48,480 --> 00:30:50,760
計算線性動力系統中的預期自由能，

790
00:30:50,760 --> 00:30:52,559
基本上

791
00:30:52,559 --> 00:30:54,360
所有這些 A 和 B 都由高斯表示，

792
00:30:54,360 --> 00:30:57,059
所以他們稱之為

793
00:30:57,059 --> 00:30:59,940
線性可控 動力系統

794
00:30:59,940 --> 00:31:01,260
，他們還必須對

795
00:31:01,260 --> 00:31:03,120
這些行為如何

796
00:31:03,120 --> 00:31:05,039
影響 B 矩陣做出一些假設 它實際上不再是矩陣

797
00:31:05,039 --> 00:31:07,100
它更像是一個連續的

798
00:31:07,100 --> 00:31:10,080
高斯並且他們發現

799
00:31:10,080 --> 00:31:11,880
你得到的正常項與預期的

800
00:31:11,880 --> 00:31:13,559
自由能一樣信息增益

801
00:31:13,559 --> 00:31:15,720
那些

802
00:31:15,720 --> 00:31:17,760
當我們使用分類分佈時我們得到的很多有趣的東西那些

803
00:31:17,760 --> 00:31:19,740


804
00:31:19,740 --> 00:31:21,659
當我們使用高斯時，術語實際上消失了，所以你

805
00:31:21,659 --> 00:31:23,520
實際上不會得到像

806
00:31:23,520 --> 00:31:26,580
信息增益搜索或信息

807
00:31:26,580 --> 00:31:28,260
搜索術語這樣的好東西，你通常

808
00:31:28,260 --> 00:31:30,720
會通過使用分類得到，但還有

809
00:31:30,720 --> 00:31:32,460
其他方法可以解決這個問題，比如如果

810
00:31:32,460 --> 00:31:34,080
你使用神經網絡，你仍然可以

811
00:31:34,080 --> 00:31:36,600
使用 諸如

812
00:31:36,600 --> 00:31:39,240
計算預期自由能的採樣方法之類的

813
00:31:39,240 --> 00:31:40,919
東西，你基本上喜歡對

814
00:31:40,919 --> 00:31:42,600
一堆可能的軌跡

815
00:31:42,600 --> 00:31:44,820
進行採樣，然後你可以使用像蒙特卡羅風格這樣的樣本

816
00:31:44,820 --> 00:31:46,679
來計算預期的

817
00:31:46,679 --> 00:31:48,179
自由能，還有很多

818
00:31:48,179 --> 00:31:50,039
已經完成的

819
00:31:50,039 --> 00:31:52,620
小組，比如縮放 對深度

820
00:31:52,620 --> 00:31:54,539
神經網絡的主動推理他們已經使用了

821
00:31:54,539 --> 00:31:56,340
這種方法，所以像 Alec chances paper

822
00:31:56,340 --> 00:31:57,960
Scout scaling active infer  ence 做

823
00:31:57,960 --> 00:31:59,820
了很多類似的事情

824
00:31:59,820 --> 00:32:02,940
，比如 Tim verbalance group

825
00:32:02,940 --> 00:32:04,620
嗯，我不想離開任何我認為

826
00:32:04,620 --> 00:32:07,080
喜歡的人，也沒有做過很多

827
00:32:07,080 --> 00:32:08,700
North Vegeta 已經

828
00:32:08,700 --> 00:32:11,220
用深度神經網絡做了很多主動推理 一種

829
00:32:11,220 --> 00:32:12,720
病毒發現我們，就像很多

830
00:32:12,720 --> 00:32:13,919
人實際上在嘗試應用

831
00:32:13,919 --> 00:32:15,480
主動推理來保持神經網絡一樣，

832
00:32:15,480 --> 00:32:17,460
他們基本上必須想出一些方法

833
00:32:17,460 --> 00:32:18,960
來計算預期的自由能

834
00:32:18,960 --> 00:32:21,240
，這與

835
00:32:21,240 --> 00:32:23,279
在 pi MVP 中所做的不同，因為在 Pine BP 中 你

836
00:32:23,279 --> 00:32:25,200
可以準確地計算出預期的自由

837
00:32:25,200 --> 00:32:27,360
能，它最終只是

838
00:32:27,360 --> 00:32:29,159
一堆矩陣向量乘積，然後是

839
00:32:29,159 --> 00:32:30,179
求和，

840
00:32:30,179 --> 00:32:31,919
所以當你使用更複雜的分佈時它會變得更加困難，

841
00:32:31,919 --> 00:32:34,020


842
00:32:34,020 --> 00:32:36,480
但這絕不是

843
00:32:36,480 --> 00:32:37,100


844
00:32:37,100 --> 00:32:39,539
不可能的，你必須得

845
00:32:39,539 --> 00:32:40,980
來 有一些近似值，

846
00:32:40,980 --> 00:32:43,380
但我認為你可以通過一些方法來

847
00:32:43,380 --> 00:32:45,899
解決這個問題，這涉及我所說的

848
00:32:45,899 --> 00:32:48,539
人們一直稱之為混合

849
00:32:48,539 --> 00:32:50,159
模型的東西，你可能有深度神經

850
00:32:50,159 --> 00:32:53,100
網絡 f 在

851
00:32:53,100 --> 00:32:54,960
一些更高的層進入

852
00:32:54,960 --> 00:32:56,640
palm DP，然後像離散分類空間一樣進入 DP 空間，

853
00:32:56,640 --> 00:32:58,260
你仍然可以計算

854
00:32:58,260 --> 00:33:00,059
預期的自由能和自由能，

855
00:33:00,059 --> 00:33:03,000
但你仍然可以利用

856
00:33:03,000 --> 00:33:04,620
低層次的優勢，如高維

857
00:33:04,620 --> 00:33:07,260
神經網絡來投影你的數據

858
00:33:07,260 --> 00:33:09,720
進入這個低維空間，這樣你

859
00:33:09,720 --> 00:33:11,820
就可以在這個

860
00:33:11,820 --> 00:33:13,620
低維的 Palm DP 空間中進行所有有效的主動推理，在這個空間中

861
00:33:13,620 --> 00:33:15,600
一切都是準確的，但你仍然

862
00:33:15,600 --> 00:33:16,740
可以利用神經網絡良好的

863
00:33:16,740 --> 00:33:19,140
降維和特徵

864
00:33:19,140 --> 00:33:20,880
提取特性

865
00:33:20,880 --> 00:33:22,500
來首先像預處理

866
00:33:22,500 --> 00:33:24,419
觀察那樣 這是我將

867
00:33:24,419 --> 00:33:26,340
在最後討論的內容，因為我們在實現

868
00:33:26,340 --> 00:33:28,679
這一目標的第一步上取得了一些

869
00:33:28,679 --> 00:33:30,600
進展，這涉及

870
00:33:30,600 --> 00:33:32,580
基本上使所有 Pi mdp Auto 可

871
00:33:32,580 --> 00:33:34,080
微分，因此您可以喜歡訓練

872
00:33:34,080 --> 00:33:36,120
連接到

873
00:33:36,120 --> 00:33:38,700
抽取素數 T 的神經網絡 模型

874
00:33:38,700 --> 00:33:41,640
是的，這是一個很好的問題，雖然

875
00:33:41,640 --> 00:33:45,059
很棒我認為這就像

876
00:33:45,059 --> 00:33:48,779
生成模型的身體計劃，也許是什麼 它

877
00:33:48,779 --> 00:33:51,059
就像今天是明天的天線或

878
00:33:51,059 --> 00:33:53,580
延遲它變得更長或更厚

879
00:33:53,580 --> 00:33:56,159
有很多不同的方法可以換出和

880
00:33:56,159 --> 00:33:58,440
組成模型的不同部分所以

881
00:33:58,440 --> 00:34:00,600
謝謝繼續

882
00:34:00,600 --> 00:34:01,860
酷是的

883
00:34:01,860 --> 00:34:03,059


884
00:34:03,059 --> 00:34:04,980
嗯所以是的現在讓我們

885
00:34:04,980 --> 00:34:07,260
談談傳統軟件

886
00:34:07,260 --> 00:34:08,820
主動推理研究，我敢肯定

887
00:34:08,820 --> 00:34:10,020
現在通話中的每個人都

888
00:34:10,020 --> 00:34:11,820
熟悉它最初的

889
00:34:11,820 --> 00:34:15,540
完成方式基本上是卡爾弗里斯頓和

890
00:34:15,540 --> 00:34:17,760
其他一些人寫了一堆 Matlab

891
00:34:17,760 --> 00:34:20,879
腳本，SPM 包的一部分

892
00:34:20,879 --> 00:34:22,440
最初只是為了

893
00:34:22,440 --> 00:34:24,780
神經成像 數據分析和

894
00:34:24,780 --> 00:34:26,940
統計測試

895
00:34:26,940 --> 00:34:29,159
，還有一個稱為 Dem 或

896
00:34:29,159 --> 00:34:31,139
動態期望最大化的子包，

897
00:34:31,139 --> 00:34:33,000
它不僅用於主動推理，

898
00:34:33,000 --> 00:34:34,859
包括連續主動推理，

899
00:34:34,859 --> 00:34:36,599
而且就像廣義過濾

900
00:34:36,599 --> 00:34:39,300
和從經驗數據擬合非線性狀態空間

901
00:34:39,300 --> 00:34:41,879
模型一樣，

902
00:34:41,879 --> 00:34:43,679
所以我們在其中 有所有這種

903
00:34:43,679 --> 00:34:46,800
離散主動推理工具箱

904
00:34:46,800 --> 00:34:48,599
，其中大部分功能

905
00:34:48,599 --> 00:34:52,199
以 SPM 下劃線 Mt 為前綴 mdp 所以基本上完​​成

906
00:34:52,199 --> 00:34:53,879


907
00:34:53,879 --> 00:34:56,399
Pine MVP 所做的大部分事情的主要

908
00:34:56,399 --> 00:34:58,740
功能是包含一個名為 SPM

909
00:34:58,740 --> 00:35:02,339
mdp vbx 的功能，並且有點

910
00:35:02,339 --> 00:35:04,080
像我們經常

911
00:35:04,080 --> 00:35:06,420
開玩笑說 Pine DP 只是一個

912
00:35:06,420 --> 00:35:07,980
包 實現了那個函數，

913
00:35:07,980 --> 00:35:09,599
因為那個函數本質上是

914
00:35:09,599 --> 00:35:12,420
做主動推理和學習的，

915
00:35:12,420 --> 00:35:14,460
所有的消息都在一次

916
00:35:14,460 --> 00:35:16,440
調用中傳遞，這在很多方面都非常好，

917
00:35:16,440 --> 00:35:18,839
因為你只需要傳遞一個 mdp

918
00:35:18,839 --> 00:35:21,000
給它，然後它以一種 Black  Box

919
00:35:21,000 --> 00:35:23,339
way 為您提供了所有信念更新

920
00:35:23,339 --> 00:35:25,140
和動作歷史以及

921
00:35:25,140 --> 00:35:28,079
您需要的

922
00:35:28,079 --> 00:35:30,599
一切，儘管它很優雅，

923
00:35:30,599 --> 00:35:33,000
但它很有用，而且它實際上非常強大，

924
00:35:33,000 --> 00:35:35,760
因為您可以

925
00:35:35,760 --> 00:35:37,260
使用任何生成模型傳遞任何代理，而且

926
00:35:37,260 --> 00:35:38,579
它會很漂亮 很多

927
00:35:38,579 --> 00:35:40,859
工作問題是因為它只是一個單一的

928
00:35:40,859 --> 00:35:42,960
功能，它不是很模塊化，所以

929
00:35:42,960 --> 00:35:45,300
很難靈活地

930
00:35:45,300 --> 00:35:47,220
組成一個主動推理

931
00:35:47,220 --> 00:35:49,200
過程的不同子計算，所以如果你想做一些

932
00:35:49,200 --> 00:35:50,700
定制

933
00:35:50,700 --> 00:35:53,280
主動推理應用程序，就像

934
00:35:53,280 --> 00:35:55,859
哦，在我進入並進行隱藏狀態

935
00:35:55,859 --> 00:35:57,300
推理之前，我想更新

936
00:35:57,300 --> 00:35:58,859
矩陣的參數，我想以

937
00:35:58,859 --> 00:36:01,260
這種特殊的方式

938
00:36:01,260 --> 00:36:05,119
來做，在 SPM mdp vbx 中很難做到這一點，所以

939
00:36:05,119 --> 00:36:07,380
我經常看到 發生了，

940
00:36:07,380 --> 00:36:09,720
我在我的碩士研究中自己做了這件事，我

941
00:36:09,720 --> 00:36:11,220
最終得到

942
00:36:11,220 --> 00:36:13,140
了這個函數的五個不同版本，它們有一些

943
00:36:13,140 --> 00:36:15,960
像專家前綴的

944
00:36:15,960 --> 00:36:18,480
東西，用於我正在做的特定事情，然後

945
00:36:18,480 --> 00:36:21,119
最終就像呃，

946
00:36:21,119 --> 00:36:22,500
不是 高效，因為你正在

947
00:36:22,500 --> 00:36:24,060
創建一堆樣板代碼，

948
00:36:24,060 --> 00:36:26,400
然後你有一個函數可以執行你想在你的項目中探索的

949
00:36:26,400 --> 00:36:27,900
特定小版本的主動

950
00:36:27,900 --> 00:36:29,460
推理，

951
00:36:29,460 --> 00:36:32,220
所以

952
00:36:32,220 --> 00:36:34,680
即使在 Matlab 中，

953
00:36:34,680 --> 00:36:36,839
你也可以通過模塊化這個函數來做到這一點，呃 基本上

954
00:36:36,839 --> 00:36:38,579
使事情變得更加靈活並

955
00:36:38,579 --> 00:36:41,099
節省大量複製和粘貼

956
00:36:41,099 --> 00:36:43,280
代碼

957
00:36:43,500 --> 00:36:45,420
嗯另一個問題是推理和

958
00:36:45,420 --> 00:36:46,980
策略選擇是固定的所以你

959
00:36:46,980 --> 00:36:48,839
不能比較 e 並對比不同的

960
00:36:48,839 --> 00:36:51,060
消息傳遞方法和操作

961
00:36:51,060 --> 00:36:52,740
選擇例程，因此只有一種

962
00:36:52,740 --> 00:36:56,099
方法在 SPM vbx 中完成，稱為

963
00:36:56,099 --> 00:36:58,440
邊際消息傳遞

964
00:36:58,440 --> 00:37:01,079
嗯，所以很難比較它，

965
00:37:01,079 --> 00:37:02,339
就像如果你改變消息

966
00:37:02,339 --> 00:37:05,700
傳遞算法而在 uh Pi MVP 中一樣

967
00:37:05,700 --> 00:37:07,800
我們現在有兩個消息傳遞

968
00:37:07,800 --> 00:37:09,599
算法，你可以

969
00:37:09,599 --> 00:37:12,000
並排比較我的意思是我們希望在未來添加更多

970
00:37:12,000 --> 00:37:13,680
這很容易，因為

971
00:37:13,680 --> 00:37:16,920
它只是一個模塊化的東西，然後

972
00:37:16,920 --> 00:37:18,119
因為我們在開始時談論的內容

973
00:37:18,119 --> 00:37:21,000
僅僅因為

974
00:37:21,000 --> 00:37:22,859
它在 Matlab 中，就很難

975
00:37:22,859 --> 00:37:25,140
與其他框架進行合成，比如在

976
00:37:25,140 --> 00:37:27,839
強化學習開放 AI 健身房和

977
00:37:27,839 --> 00:37:29,099
深度神經網絡，如

978
00:37:29,099 --> 00:37:32,339
intensorflow 流或 Pi torture Jacks，

979
00:37:32,339 --> 00:37:34,380
所以它在 Matlab 中的事實

980
00:37:34,380 --> 00:37:36,660
已經受到限制，當然人們 已經

981
00:37:36,660 --> 00:37:39,420
找到了像跨語言

982
00:37:39,420 --> 00:37:41,700
跨平台

983
00:37:41,700 --> 00:37:44,400
um 代碼那樣做的方法，比如從 Julia 到 Matlab

984
00:37:44,400 --> 00:37:46,980
再到 Python 再回來，但它只是

985
00:37:46,980 --> 00:37:49,440
要重得多 li 參與其中

986
00:37:49,440 --> 00:37:52,440
然後我將列出一些

987
00:37:52,440 --> 00:37:55,619
Matlab 和 Python 的優點和缺點所以

988
00:37:55,619 --> 00:37:57,420
我喜歡 Matlab 的一件事

989
00:37:57,420 --> 00:37:59,339
是它很容易開始

990
00:37:59,339 --> 00:38:01,680
數組編程有一個很好的編輯器

991
00:38:01,680 --> 00:38:04,200
有很多 使用和歷史以及

992
00:38:04,200 --> 00:38:06,839
計算神經科學，就像去年

993
00:38:06,839 --> 00:38:09,720
我在計算精神病學課程上講這個教程一樣，

994
00:38:09,720 --> 00:38:11,400


995
00:38:11,400 --> 00:38:13,740
我認為大多數教程

996
00:38:13,740 --> 00:38:16,260
仍在使用 Matlab，所以仍然

997
00:38:16,260 --> 00:38:18,420
有充分的理由使用 Matlab，

998
00:38:18,420 --> 00:38:20,700
因為歷史和

999
00:38:20,700 --> 00:38:22,440
非常適合做

1000
00:38:22,440 --> 00:38:24,780
神經科學和心理物理學的東西的包的數量所以

1001
00:38:24,780 --> 00:38:26,280
有這種優勢就像

1002
00:38:26,280 --> 00:38:30,000
一種幾乎勢頭或遺留優勢

1003
00:38:30,000 --> 00:38:32,099
但當然有像專有的問題

1004
00:38:32,099 --> 00:38:33,480
我認為這是

1005
00:38:33,480 --> 00:38:35,520
你需要支付的

1006
00:38:35,520 --> 00:38:38,339
最大的一種方式或 另一個使用 Matlab

1007
00:38:38,339 --> 00:38:40,800
並且沒有那麼多社區驅動的

1008
00:38:40,800 --> 00:38:43,020
開發我的意思是有一些

1009
00:38:43,020 --> 00:38:44,880
像文件交換但它

1010
00:38:44,880 --> 00:38:47,400
與 Python 和 d 然後

1011
00:38:47,400 --> 00:38:49,740
python 可以與 Matlab 競爭，

1012
00:38:49,740 --> 00:38:51,420
因為它具有

1013
00:38:51,420 --> 00:38:53,700
numpy 形式的數組編程，當然它是開源的，

1014
00:38:53,700 --> 00:38:55,680
它已

1015
00:38:55,680 --> 00:38:57,660
被廣泛採用，

1016
00:38:57,660 --> 00:39:00,960
不僅是學術領域，還有

1017
00:39:00,960 --> 00:39:02,940
許多商業應用，並且有

1018
00:39:02,940 --> 00:39:05,099
很多社區提供驅動

1019
00:39:05,099 --> 00:39:08,940
以軟件包的形式進行開發，例如 Pi VP

1020
00:39:08,940 --> 00:39:11,280
um 但一個缺點是至少對我來說，

1021
00:39:11,280 --> 00:39:12,839
開始

1022
00:39:12,839 --> 00:39:14,520
使用 Matlab

1023
00:39:14,520 --> 00:39:17,460
um 不像使用 Matlab 那樣容易，因為您

1024
00:39:17,460 --> 00:39:19,079
經常需要安裝一堆

1025
00:39:19,079 --> 00:39:20,280
東西並學習 關於虛擬

1026
00:39:20,280 --> 00:39:21,540
環境，在開始使用 Python 之前，你必須喜歡

1027
00:39:21,540 --> 00:39:24,440
學習更多的編程知識

1028
00:39:24,440 --> 00:39:27,060
，

1029
00:39:27,060 --> 00:39:29,040
所以我認為這是

1030
00:39:29,040 --> 00:39:30,780
Matlab 實際上仍然作為一種

1031
00:39:30,780 --> 00:39:32,520
教學工具有用的原因之一，比如

1032
00:39:32,520 --> 00:39:33,960
從獲得 Matlab 到實際

1033
00:39:33,960 --> 00:39:36,960
進行編程之間的時間 它很短

1034
00:39:36,960 --> 00:39:39,660
，很好，

1035
00:39:39,660 --> 00:39:43,440
所以是的，這個包被稱為呃，它

1036
00:39:43,440 --> 00:39:46,020
在這個活躍的 GitHub

1037
00:39:46,020 --> 00:39:48,839
組織中，它被稱為 Pi MVP，你

1038
00:39:48,839 --> 00:39:50,700
可以 pip insta 它會像在

1039
00:39:50,700 --> 00:39:52,380
虛擬環境中或僅在 python 的基本

1040
00:39:52,380 --> 00:39:55,140
安裝中一樣

1041
00:39:55,140 --> 00:39:57,540
，然後一旦安裝了 piondp，

1042
00:39:57,540 --> 00:40:00,720
您就可以

1043
00:40:00,720 --> 00:40:03,599
以靈活的模塊化方式導入和使用所有

1044
00:40:03,599 --> 00:40:05,640
不同的子包或子模塊，

1045
00:40:05,640 --> 00:40:07,560
例如代理模塊，基本上

1046
00:40:07,560 --> 00:40:09,660
只是實現代理類，然後

1047
00:40:09,660 --> 00:40:11,579
有不同的模塊，例如推理

1048
00:40:11,579 --> 00:40:13,619
和控制以及學習，它們

1049
00:40:13,619 --> 00:40:15,119
實際上獨立於主動

1050
00:40:15,119 --> 00:40:16,440
推理代理，您可以只使用

1051
00:40:16,440 --> 00:40:19,200
它們為隱藏狀態推理進行消息傳遞

1052
00:40:19,200 --> 00:40:21,119
或計算

1053
00:40:21,119 --> 00:40:22,320


1054
00:40:22,320 --> 00:40:24,839
可能策略的預期自由能量或 計算

1055
00:40:24,839 --> 00:40:27,119
對參數的更新，這樣所有這些

1056
00:40:27,119 --> 00:40:29,640
東西都可以組合起來，並且可以靈活

1057
00:40:29,640 --> 00:40:31,800
地使用你可以

1058
00:40:31,800 --> 00:40:33,839
通過以你想要的定制方式組合所有這些東西來製作一種弗蘭肯斯坦主動推理代理

1059
00:40:33,839 --> 00:40:36,060


1060
00:40:36,060 --> 00:40:38,099


1061
00:40:38,099 --> 00:40:41,160
，其中很多是 pione P 的主要工作流程

1062
00:40:41,160 --> 00:40:43,260
細化到指定

1063
00:40:43,260 --> 00:40:45,060
生成模型和這些

1064
00:40:45,060 --> 00:40:47,640
離散數組的形式，然後將它們

1065
00:40:47,640 --> 00:40:49,680
插入代理的大腦中，

1066
00:40:49,680 --> 00:40:52,020
實例化一個代理，這樣它

1067
00:40:52,020 --> 00:40:54,119
幾乎被底部的這兩行封裝

1068
00:40:54,119 --> 00:40:57,000
從 Pine BP 導入代理

1069
00:40:57,000 --> 00:40:59,400
，然後你只需通過

1070
00:40:59,400 --> 00:41:02,220
插入 ABC 和 D 來構建一個代理對象，然後你就有了

1071
00:41:02,220 --> 00:41:04,619
這個代理對象，你可以用它來做

1072
00:41:04,619 --> 00:41:06,420
隱藏狀態 通過

1073
00:41:06,420 --> 00:41:08,099
類似於第一個狀態

1074
00:41:08,099 --> 00:41:10,560
推斷策略的方法進行推理，這是代理在

1075
00:41:10,560 --> 00:41:12,240
內部計算其策略的預期自由

1076
00:41:12,240 --> 00:41:14,760
能，然後您

1077
00:41:14,760 --> 00:41:17,400
最終可以對動作進行採樣，因此這

1078
00:41:17,400 --> 00:41:19,260
三行是

1079
00:41:19,260 --> 00:41:21,359
任何主動推理循環

1080
00:41:21,359 --> 00:41:24,660
狀態推理策略推理的主要參與者的類型

1081
00:41:24,660 --> 00:41:26,820
然後是動作選擇，你

1082
00:41:26,820 --> 00:41:30,320
只是把那些隨著時間的推移

1083
00:41:30,359 --> 00:41:32,339
循環起來，以實例化一個活躍的推理

1084
00:41:32,339 --> 00:41:35,460
過程，以及

1085
00:41:35,460 --> 00:41:37,079
動作感知

1086
00:41:37,079 --> 00:41:39,300
循環的循環與代理的輸入一起發揮

1087
00:41:39,300 --> 00:41:41,880
作用，這是它的觀察 以及

1088
00:41:41,880 --> 00:41:43,500
它的動作選擇的輸出，

1089
00:41:43,500 --> 00:41:45,960
其中圖表是它的動作，

1090
00:41:45,960 --> 00:41:48,000
當然你需要使用 Last Action

1091
00:41:48,000 --> 00:41:50,640
來獲得新的觀察結果，然後

1092
00:41:50,640 --> 00:41:53,520
你是不是通過將動作插入

1093
00:41:53,520 --> 00:41:55,980
某個環境來做到這一點，這在

1094
00:41:55,980 --> 00:41:57,480
主動推理文獻中也經常

1095
00:41:57,480 --> 00:41:59,400
被稱為生成過程，所以

1096
00:41:59,400 --> 00:42:00,960
外面的現實世界會

1097
00:42:00,960 --> 00:42:03,119
生成你的數據，所以這就是你將看到的

1098
00:42:03,119 --> 00:42:04,680
那種經典動作感知組

1099
00:42:04,680 --> 00:42:06,480
制定了任何主動推理

1100
00:42:06,480 --> 00:42:08,640
代理，這甚至不是

1101
00:42:08,640 --> 00:42:10,320
主動推理所獨有的，這就是

1102
00:42:10,320 --> 00:42:12,119
強化學習問題的

1103
00:42:12,119 --> 00:42:14,880
一般框架，就像 Open AI Jam

1104
00:42:14,880 --> 00:42:17,040
使用非常相似的

1105
00:42:17,040 --> 00:42:20,339
控制流程，我們有點像

1106
00:42:20,339 --> 00:42:24,020
嗯是的感覺電機循環

1107
00:42:24,440 --> 00:42:27,359
所以是的 這是一個例子，

1108
00:42:27,359 --> 00:42:30,359
嗯，就像導入代理一樣

1109
00:42:30,359 --> 00:42:31,980
設置生成模型，這是

1110
00:42:31,980 --> 00:42:33,720
最難的部分，所以我有點方便地

1111
00:42:33,720 --> 00:42:36,420
將省略號放在點之後，

1112
00:42:36,420 --> 00:42:37,500
但實際上大部分

1113
00:42:37,500 --> 00:42:38,640
代碼將要發生的地方是構建

1114
00:42:38,640 --> 00:42:41,220
生成模型 構建代理你

1115
00:42:41,220 --> 00:42:43,020
構建一些環境，你

1116
00:42:43,020 --> 00:42:45,599
可以將其作為存儲的 Pi mdp 環境之一導入，

1117
00:42:45,599 --> 00:42:47,820
或者你可以

1118
00:42:47,820 --> 00:42:50,040
從開放的 AI 健身房獲取它，或者你可以 d 只是

1119
00:42:50,040 --> 00:42:51,660
創建你自己的環境，所以

1120
00:42:51,660 --> 00:42:53,940
這些將是你的代碼，它實際上

1121
00:42:53,940 --> 00:42:55,920
描述了世界是如何運作

1122
00:42:55,920 --> 00:42:57,900
的，代理正在與之交互的世界

1123
00:42:57,900 --> 00:43:01,319
，然後你可以

1124
00:43:01,319 --> 00:43:02,940
用那幾行代碼實現主動推理的時間步驟

1125
00:43:02,940 --> 00:43:05,339
，並且

1126
00:43:05,339 --> 00:43:07,740
這些都是最後幾行，比如 8

1127
00:43:07,740 --> 00:43:09,240
到 15 那些會

1128
00:43:09,240 --> 00:43:10,560


1129
00:43:10,560 --> 00:43:14,000
隨著時間的推移被包裹在一個循環中

1130
00:43:14,640 --> 00:43:16,500
嗯是的這只是更多這樣的

1131
00:43:16,500 --> 00:43:19,260
例子這將是一個快速的方法在

1132
00:43:19,260 --> 00:43:20,880
這個例子中我們甚至沒有運行

1133
00:43:20,880 --> 00:43:22,920
主動 推理，但我們只是使用

1134
00:43:22,920 --> 00:43:25,079


1135
00:43:25,079 --> 00:43:28,380
Algos 子模塊中的一種消息傳遞算法來進行隱藏

1136
00:43:28,380 --> 00:43:31,020
狀態推理，所以在這種情況下，我只是

1137
00:43:31,020 --> 00:43:33,240
創建了一個隨機矩陣，我創建了一個

1138
00:43:33,240 --> 00:43:36,660
隨機觀察，我給出

1139
00:43:36,660 --> 00:43:39,240
了一個隨機先驗和 然後我可以

1140
00:43:39,240 --> 00:43:42,420
做一個類似虛構更新的代理人

1141
00:43:42,420 --> 00:43:43,619
在隱藏狀態推理期間可能正在做的事情

1142
00:43:43,619 --> 00:43:47,099
並優化 Qs 或

1143
00:43:47,099 --> 00:43:49,380
關於隱藏狀態的信念所以這是一個

1144
00:43:49,380 --> 00:43:50,520
你如何實際使用

1145
00:43:50,520 --> 00:43:53,160
Pond DP 到 j 的例子 只需對隱馬爾可夫模型進行通用推理，

1146
00:43:53,160 --> 00:43:55,380
您甚至不需要

1147
00:43:55,380 --> 00:43:58,020
在主動推理

1148
00:43:58,020 --> 00:44:00,900
循環中使用它，您可以使用它來使用我們

1149
00:44:00,900 --> 00:44:02,520


1150
00:44:02,520 --> 00:44:04,440
提供的特定算法對隱馬爾可夫模型進行統計推理

1151
00:44:04,440 --> 00:44:06,720


1152
00:44:06,720 --> 00:44:08,280
，然後 當然，

1153
00:44:08,280 --> 00:44:10,560
我在 SPM 上談到的優勢之一是您

1154
00:44:10,560 --> 00:44:12,180
可以創建自定義的主動推理

1155
00:44:12,180 --> 00:44:14,400
過程，代理類有很多類似的額外

1156
00:44:14,400 --> 00:44:16,200
參數，您

1157
00:44:16,200 --> 00:44:18,300
可以在其中打開和關閉

1158
00:44:18,300 --> 00:44:21,000
獎勵功能的不同部分或

1159
00:44:21,000 --> 00:44:23,819
預期的免費 agent 的能量，所以

1160
00:44:23,819 --> 00:44:26,339
例如在這個 agent 中，agent

1161
00:44:26,339 --> 00:44:28,619
沒有包含 uh expected utility

1162
00:44:28,619 --> 00:44:30,540
，這是一種獎勵

1163
00:44:30,540 --> 00:44:32,819
C Vector 驅動的動作選擇組件，

1164
00:44:32,819 --> 00:44:35,240
但 agent 確實使用狀態

1165
00:44:35,240 --> 00:44:37,800
信息增益和參數信息遊戲

1166
00:44:37,800 --> 00:44:39,480
，這是

1167
00:44:39,480 --> 00:44:42,119
預期的自由能，所以有很多

1168
00:44:42,119 --> 00:44:43,500
方法可以創建一個

1169
00:44:43,500 --> 00:44:45,619
定制的主動推理代理，

1170
00:44:45,619 --> 00:44:47,940
它不會以不同的方式表現

1171
00:44:47,940 --> 00:44:49,800
取決於 在

1172
00:44:49,800 --> 00:44:53,300
你提供的這些呃關鍵字參數上，

1173
00:44:54,060 --> 00:44:55,500
嗯，

1174
00:44:55,500 --> 00:44:57,660
是的，這裡只是更多的例子，比如在

1175
00:44:57,660 --> 00:44:58,920
這種情況下，我們使用主動推理

1176
00:44:58,920 --> 00:45:00,780
代理只是為了進行隱藏狀態推理

1177
00:45:00,780 --> 00:45:03,060
，根本沒有任何動作，所以代理

1178
00:45:03,060 --> 00:45:04,980
只是在推斷它正在

1179
00:45:04,980 --> 00:45:07,200
更新的隱藏狀態 它對 a 矩陣的

1180
00:45:07,200 --> 00:45:08,700
信念，它正在更新它對

1181
00:45:08,700 --> 00:45:11,099
D 向量或初始隱藏狀態的信念

1182
00:45:11,099 --> 00:45:12,960
，所以你可以知道，只要靈活地

1183
00:45:12,960 --> 00:45:14,640
把所有這些線放在一起

1184
00:45:14,640 --> 00:45:16,380
，就可以創建一個代理，它可以做任何你想做的事

1185
00:45:16,380 --> 00:45:17,940
，甚至不需要行動 在

1186
00:45:17,940 --> 00:45:19,940
世界上技術上

1187
00:45:19,940 --> 00:45:22,140
還可以，所以現在我要展示幾個

1188
00:45:22,140 --> 00:45:25,859
pine DP 的例子，

1189
00:45:25,859 --> 00:45:28,800
嗯，這是一篇經典的

1190
00:45:28,800 --> 00:45:31,020
主動推理論文，它是我

1191
00:45:31,020 --> 00:45:33,660
最喜歡的論文之一，嗯，我認為它

1192
00:45:33,660 --> 00:45:35,160
被稱為場景構建和主動

1193
00:45:35,160 --> 00:45:37,319
推理 它描述了代理人必須完成的任務

1194
00:45:37,319 --> 00:45:39,839
，這被

1195
00:45:39,839 --> 00:45:41,640
用來在心理物理學測試中實際模擬人類數據，

1196
00:45:41,640 --> 00:45:44,160
代理人必須偶然地

1197
00:45:44,160 --> 00:45:45,960


1198
00:45:45,960 --> 00:45:48,780
註視發現四個像限中的兩個

1199
00:45:48,780 --> 00:45:51,359
其中有特定的圖像，

1200
00:45:51,359 --> 00:45:53,579
嗯，總共有四個像限，其中

1201
00:45:53,579 --> 00:45:56,579
兩個有

1202
00:45:56,579 --> 00:45:59,460
感興趣的圖像，如果

1203
00:45:59,460 --> 00:46:02,640
在這種情況下的兩個圖像是一隻鳥和一隻貓的圖像

1204
00:46:02,640 --> 00:46:05,579
，那是跳蚤場景的一個例子，

1205
00:46:05,579 --> 00:46:07,380
所以亞洲人基本上或 人類必須

1206
00:46:07,380 --> 00:46:09,960
對潛在場景進行分類，該場景

1207
00:46:09,960 --> 00:46:12,300
簡單地由兩個

1208
00:46:12,300 --> 00:46:15,540
圖像的組合按順序定義，然後對場景進行分類，

1209
00:46:15,540 --> 00:46:16,859
因此它基本上是一個

1210
00:46:16,859 --> 00:46:20,040
分類任務，但代理需要

1211
00:46:20,040 --> 00:46:22,740


1212
00:46:22,740 --> 00:46:24,599
在知道該類別之前偶然發現一系列線索

1213
00:46:24,599 --> 00:46:27,720
是或者那個場景是什麼所以它

1214
00:46:27,720 --> 00:46:29,940
結合了

1215
00:46:29,940 --> 00:46:31,380
我們都知道和喜歡的關於主動

1216
00:46:31,380 --> 00:46:33,660
推理的認知成分試圖

1217
00:46:33,660 --> 00:46:36,180
通過主動採樣來揭示世界的隱藏狀態

1218
00:46:36,180 --> 00:46:38,400
所以在這種情況下他們

1219
00:46:38,400 --> 00:46:39,720
通過將他們的眼睛移到不同的地方來採樣世界

1220
00:46:39,720 --> 00:46:41,760
象限以揭示

1221
00:46:41,760 --> 00:46:44,760
它們背後的內容，然後

1222
00:46:44,760 --> 00:46:47,280
根據

1223
00:46:47,280 --> 00:46:49,020
它對世界的了解來實際選擇真正的類別，這就是它所在

1224
00:46:49,020 --> 00:46:50,160
的位置 試圖最大化

1225
00:46:50,160 --> 00:46:51,780
效用，因為有一些

1226
00:46:51,780 --> 00:46:55,140
與正確分類相關的獎勵，

1227
00:46:55,140 --> 00:46:57,180
所以這是一個

1228
00:46:57,180 --> 00:46:58,740
最初在 Matlab 中完成的例子，我剛剛

1229
00:46:58,740 --> 00:47:01,020
在 pi mdp 中重新實現

1230
00:47:01,020 --> 00:47:03,300
，這是另一個例子，

1231
00:47:03,300 --> 00:47:05,400
現在場景是

1232
00:47:05,400 --> 00:47:07,800
um feed 場景所以

1233
00:47:07,800 --> 00:47:09,780
在此示例中，提示位於下兩個像限，

1234
00:47:09,780 --> 00:47:12,359
因此代理必須環顧

1235
00:47:12,359 --> 00:47:14,099
不同的象限，它最終看到

1236
00:47:14,099 --> 00:47:15,839
右下角有一隻鳥，

1237
00:47:15,839 --> 00:47:17,700
左下角的種子，所以這

1238
00:47:17,700 --> 00:47:20,880
一定是飼料場景，

1239
00:47:20,880 --> 00:47:22,980
嗯，只是 呃展示一個例子，

1240
00:47:22,980 --> 00:47:24,359
說明在主動推理中實際是什麼樣子的，比如

1241
00:47:24,359 --> 00:47:25,740
代碼是什麼

1242
00:47:25,740 --> 00:47:27,780
樣子的，所以

1243
00:47:27,780 --> 00:47:29,160
你要做的第一件事

1244
00:47:29,160 --> 00:47:31,140
就是設置你的代理，然後再把它

1245
00:47:31,140 --> 00:47:33,720
扔進 a b c'  s 和 D 在這種

1246
00:47:33,720 --> 00:47:35,760
情況下，我使用了

1247
00:47:35,760 --> 00:47:36,960
一種稱為邊際消息

1248
00:47:36,960 --> 00:47:38,640
傳遞的特定消息傳遞算法，它與 Matlab 中使用的算法相同，

1249
00:47:38,640 --> 00:47:42,180
你設置了策略深度和

1250
00:47:42,180 --> 00:47:43,680
推理 Horizo​​n，有點

1251
00:47:43,680 --> 00:47:45,420
像 記憶，比如你考慮了多少過去的

1252
00:47:45,420 --> 00:47:48,119
觀察

1253
00:47:48,119 --> 00:47:50,700
，然後你設置了一個

1254
00:47:50,700 --> 00:47:52,980
環境，​​就像

1255
00:47:52,980 --> 00:47:55,500
代理將與之交互的外部世界，

1256
00:47:55,500 --> 00:47:57,420
在這種情況下，我稱之為場景

1257
00:47:57,420 --> 00:47:59,520
構建環境，

1258
00:47:59,520 --> 00:48:01,920
一旦 agent 將眼睛

1259
00:48:01,920 --> 00:48:03,300
移到某個地方，這

1260
00:48:03,300 --> 00:48:06,180
實際上是如何確定 agent

1261
00:48:06,180 --> 00:48:07,980
接下來看到的是什麼，你

1262
00:48:07,980 --> 00:48:09,720
知道它決定看的象限後面的任何東西

1263
00:48:09,720 --> 00:48:13,200
，所以這是主要的

1264
00:48:13,200 --> 00:48:14,819
兩件事，它們是動作的兩個方面

1265
00:48:14,819 --> 00:48:16,619
perception 循環代理

1266
00:48:16,619 --> 00:48:18,780
和環境

1267
00:48:18,780 --> 00:48:21,900
，然後通常要做的是

1268
00:48:21,900 --> 00:48:24,300


1269
00:48:24,300 --> 00:48:26,880
通過重置環境來進行初始初步觀察，這是

1270
00:48:26,880 --> 00:48:29,760
從 openai gym 借來的慣例，你

1271
00:48:29,760 --> 00:48:32,220
基本上做環境點重置，

1272
00:48:32,220 --> 00:48:33,960
就像吐出環境的方法

1273
00:48:33,960 --> 00:48:36,240
出最初的觀察結果，

1274
00:48:36,240 --> 00:48:37,619
然後在這些事情

1275
00:48:37,619 --> 00:48:39,359
中創建

1276
00:48:39,359 --> 00:48:41,819
在觀察索引之間具有映射關係的列表或字典通常很有用

1277
00:48:41,819 --> 00:48:43,800
這就像

1278
00:48:43,800 --> 00:48:46,319
零之間的整數，無論有多少

1279
00:48:46,319 --> 00:48:48,420
觀察結果，然後是

1280
00:48:48,420 --> 00:48:49,619
那些實際在語義上對應的東西，

1281
00:48:49,619 --> 00:48:51,720
所以這只是一種非常

1282
00:48:51,720 --> 00:48:54,000
常見的方式，因為所有的 Palm

1283
00:48:54,000 --> 00:48:56,700
DP 和環境都會

1284
00:48:56,700 --> 00:48:59,220
吐出，就像兩個和零和

1285
00:48:59,220 --> 00:49:00,780
所有這些都像離散索引，但是

1286
00:49:00,780 --> 00:49:02,700
擁有這些列表很有用，您可以使用這些列表

1287
00:49:02,700 --> 00:49:04,980
在語義上將

1288
00:49:04,980 --> 00:49:07,920
特定索引映射到

1289
00:49:07,920 --> 00:49:09,740
有意義的東西，例如

1290
00:49:09,740 --> 00:49:14,160
看到鳥類圖像或選擇

1291
00:49:14,160 --> 00:49:18,420
第一類與第二類

1292
00:49:18,420 --> 00:49:20,579
，然後一旦完成 你只是

1293
00:49:20,579 --> 00:49:23,400
隨著時間的推移編寫一個循環，你

1294
00:49:23,400 --> 00:49:25,260
基本上在執行主動推理

1295
00:49:25,260 --> 00:49:27,240
，其中包括隱藏狀態

1296
00:49:27,240 --> 00:49:29,460
估計和策略推理

1297
00:49:29,460 --> 00:49:32,700
你呃對一個動作

1298
00:49:32,700 --> 00:49:34,680
進行採樣，然後將其反饋到

1299
00:49:34,680 --> 00:49:37,079
環境中以產生另一個

1300
00:49:37,079 --> 00:49:38,819
觀察結果，然後隨著時間的推移發生這種情況，

1301
00:49:38,819 --> 00:49:39,900
所以這是 整個動作的

1302
00:49:39,900 --> 00:49:41,339
感知，

1303
00:49:41,339 --> 00:49:44,339
所以這是

1304
00:49:44,339 --> 00:49:45,720
嗯，是的

1305
00:49:45,720 --> 00:49:48,119
，

1306
00:49:48,119 --> 00:49:49,920
這看起來很簡單，看起來很短，但我有點像 glossi

1307
00:49:49,920 --> 00:49:51,359
討論我稍後要討論的事情，

1308
00:49:51,359 --> 00:49:53,880
這是我之前提到的，

1309
00:49:53,880 --> 00:49:55,619
就像這看起來一樣簡單，最難的部分

1310
00:49:55,619 --> 00:49:57,720
實際上是在任何這種情況發生之前完成的

1311
00:49:57,720 --> 00:49:59,520
，寫下 a b

1312
00:49:59,520 --> 00:50:02,760
c 和 D，這是迄今為止最多的時間

1313
00:50:02,760 --> 00:50:05,460


1314
00:50:05,460 --> 00:50:06,839
主動推理的密集和復雜部分實際上是

1315
00:50:06,839 --> 00:50:08,640
寫下生成模型，一旦你

1316
00:50:08,640 --> 00:50:10,680
寫下了生成模型，

1317
00:50:10,680 --> 00:50:12,780
那麼剩下的基本上就像發條一樣，你

1318
00:50:12,780 --> 00:50:15,060
只需要將代理與

1319
00:50:15,060 --> 00:50:17,160
環境聯繫起來，然後像

1320
00:50:17,160 --> 00:50:19,560
五六行一樣運行 真正實現

1321
00:50:19,560 --> 00:50:20,819
這個東西，但最困難的部分是

1322
00:50:20,819 --> 00:50:22,560
在開始時寫下那些 a b c 和 D

1323
00:50:22,560 --> 00:50:24,799


1324
00:50:25,260 --> 00:50:27,119
嗯我將展示另一個例子，我

1325
00:50:27,119 --> 00:50:28,079
有點

1326
00:50:28,079 --> 00:50:31,740
呃打電話給類固醇的隊友所以在

1327
00:50:31,740 --> 00:50:33,960
經典的 teamaze 任務

1328
00:50:33,960 --> 00:50:35,579
中我忘記了原來的內容 論文

1329
00:50:35,579 --> 00:50:36,900
是，但它

1330
00:50:36,900 --> 00:50:37,980
在主動推理

1331
00:50:37,980 --> 00:50:39,599
文獻中已經流行了一段時間，

1332
00:50:39,599 --> 00:50:41,460
呃，我認為 Carl 可能

1333
00:50:41,460 --> 00:50:44,700
在 2015 年或更早的時候想出，甚至你有一個

1334
00:50:44,700 --> 00:50:48,119
代理鼠標 必須訪問其環境中

1335
00:50:48,119 --> 00:50:51,180
獎勵或懲罰的兩個潛在來源，

1336
00:50:51,180 --> 00:50:53,160
並且它

1337
00:50:53,160 --> 00:50:55,619
不知道該隊友的哪隻手臂

1338
00:50:55,619 --> 00:50:58,020
包含獎勵，因此它必須先訪問一個

1339
00:50:58,020 --> 00:51:00,300
提示，然後才能知道哪隻手臂

1340
00:51:00,300 --> 00:51:02,700
有獎勵，哪隻手臂沒有

1341
00:51:02,700 --> 00:51:04,559
獎勵或像負面

1342
00:51:04,559 --> 00:51:07,200
刺激一樣的震驚我只是在

1343
00:51:07,200 --> 00:51:09,660
空間上擴展了隊友所以

1344
00:51:09,660 --> 00:51:12,119
代理現在必須訪問一系列

1345
00:51:12,119 --> 00:51:14,819
線索，每個線索都揭示

1346
00:51:14,819 --> 00:51:17,099
了下一個立方體的位置，以便

1347
00:51:17,099 --> 00:51:19,559
找出最終的線索 只是

1348
00:51:19,559 --> 00:51:22,619
奶酪相對於衝擊的位置

1349
00:51:22,619 --> 00:51:24,359
所以這是另一個例子，

1350
00:51:24,359 --> 00:51:26,520
代理首先去 q1 然後它

1351
00:51:26,520 --> 00:51:28,200
知道 Q2 在哪裡然後它知道

1352
00:51:28,200 --> 00:51:30,300
奶酪在哪裡所以我稱之為認知

1353
00:51:30,300 --> 00:51:32,099
鏈因為代理

1354
00:51:32,099 --> 00:51:34,740
實際上沒有 計劃它的根

1355
00:51:34,740 --> 00:51:37,020
一直到奶酪的最終位置，

1356
00:51:37,020 --> 00:51:38,940
它所要做的就是到達

1357
00:51:38,940 --> 00:51:41,280
下一個 q，然後顯示下一個

1358
00:51:41,280 --> 00:51:43,880
提示的位置，最終顯示獎勵的

1359
00:51:43,880 --> 00:51:47,099
隱藏位置在

1360
00:51:47,099 --> 00:51:49,440
哪裡 您是在某種程度上使用

1361
00:51:49,440 --> 00:51:53,040
認知價值或好奇心來允許

1362
00:51:53,040 --> 00:51:56,160
其他時間上淺薄的動物

1363
00:51:56,160 --> 00:51:58,800
計劃其方式來

1364
00:51:58,800 --> 00:52:00,839
獲得遠端獎勵或

1365
00:52:00,839 --> 00:52:03,300
無法計劃獲得的

1366
00:52:03,300 --> 00:52:05,640
東西我們的先驗

1367
00:52:05,640 --> 00:52:07,500
，這只是一個

1368
00:52:07,500 --> 00:52:09,059
例子 這看起來就像在 Pine DP

1369
00:52:09,059 --> 00:52:10,500
中，它基本上看起來完全

1370
00:52:10,500 --> 00:52:12,660
一樣，只是環境

1371
00:52:12,660 --> 00:52:14,579
和生成模型不同，但

1372
00:52:14,579 --> 00:52:16,859
代碼的一般流程總是

1373
00:52:16,859 --> 00:52:21,619
有這種經典的管道，

1374
00:52:21,839 --> 00:52:24,059
嗯，好吧，現在我會得到

1375
00:52:24,059 --> 00:52:25,619
對於最重要的部分，我認為

1376
00:52:25,619 --> 00:52:28,260


1377
00:52:28,260 --> 00:52:29,880
與主動推理混淆的最大來源是

1378
00:52:29,880 --> 00:52:31,500
最難的部分是生成模型

1379
00:52:31,500 --> 00:52:34,319
，所有的

1380
00:52:34,319 --> 00:52:36,599
複雜性都用於編碼

1381
00:52:36,599 --> 00:52:38,280
代理對世界的信念，所以

1382
00:52:38,280 --> 00:52:40,079
我該如何寫下

1383
00:52:40,079 --> 00:52:41,460


1384
00:52:41,460 --> 00:52:44,099
深度神經

1385
00:52:44,099 --> 00:52:47,960
網絡或無監督學習等範式中的 B、C 和 D，

1386
00:52:47,960 --> 00:52:50,280
您不必寫下現代

1387
00:52:50,280 --> 00:52:51,740


1388
00:52:51,740 --> 00:52:54,540
神經網絡通過

1389
00:52:54,540 --> 00:52:57,000
觀察負載和負載來學習模型 o  f 數據，所以

1390
00:52:57,000 --> 00:52:59,040
它的樣本效率較低，但你不必一

1391
00:52:59,040 --> 00:53:01,319
開始就編碼那麼多，所以

1392
00:53:01,319 --> 00:53:03,119
這

1393
00:53:03,119 --> 00:53:06,359
有點符合

1394
00:53:06,359 --> 00:53:08,220
模型 3 和基於模型的

1395
00:53:08,220 --> 00:53:10,140
方法之間更大的鴻溝，

1396
00:53:10,140 --> 00:53:12,619
你是你是 有效地

1397
00:53:12,619 --> 00:53:15,420
向樣本發布統計

1398
00:53:15,420 --> 00:53:17,220
複雜性，即必須

1399
00:53:17,220 --> 00:53:19,380
通過將

1400
00:53:19,380 --> 00:53:22,140
一堆非線性函數逼近器粘在一起來寫下模型，

1401
00:53:22,140 --> 00:53:24,240
然後

1402
00:53:24,240 --> 00:53:25,619
通過

1403
00:53:25,619 --> 00:53:27,480
用數據轟炸它來學習代理對世界的信念，同樣的事情也

1404
00:53:27,480 --> 00:53:29,339
適用 深度強化學習，

1405
00:53:29,339 --> 00:53:32,579
如主動推理中的 DQ 學習，

1406
00:53:32,579 --> 00:53:35,160
代理的樣本效率更高

1407
00:53:35,160 --> 00:53:36,300
，因為它們不需要

1408
00:53:36,300 --> 00:53:40,740
訓練數十億個數據向量，但

1409
00:53:40,740 --> 00:53:42,240
另一方面，

1410
00:53:42,240 --> 00:53:44,040
作為建模者，你的投資更多，因為你

1411
00:53:44,040 --> 00:53:45,900
有 明確地寫下

1412
00:53:45,900 --> 00:53:48,359
代理人對世界的信念是什麼

1413
00:53:48,359 --> 00:53:49,920
你不只是用

1414
00:53:49,920 --> 00:53:53,220
像卷積層這樣通用的

1415
00:53:53,220 --> 00:53:55,200
東西和一些評論和東西來裝備它 然後讓它

1416
00:53:55,200 --> 00:53:57,119
學習你實際上必須手動編寫代碼

1417
00:53:57,119 --> 00:53:59,400
，所以我認為這是

1418
00:53:59,400 --> 00:54:01,800
基於模型的強化學習之間最大的區別之一

1419
00:54:01,800 --> 00:54:03,059
，你

1420
00:54:03,059 --> 00:54:04,859
實際上編碼了世界的貝葉斯一般

1421
00:54:04,859 --> 00:54:07,020
生成模型

1422
00:54:07,020 --> 00:54:08,940
和更多的無模型或數據驅動的

1423
00:54:08,940 --> 00:54:11,099
方法但是 並不是這樣的

1424
00:54:11,099 --> 00:54:12,660
二分法，有一些方法可以

1425
00:54:12,660 --> 00:54:14,099
將兩者結合起來，

1426
00:54:14,099 --> 00:54:16,980
但只是為了

1427
00:54:16,980 --> 00:54:18,720
非常具體地展示，例如

1428
00:54:18,720 --> 00:54:21,780
在這個場景構建演示中，我

1429
00:54:21,780 --> 00:54:23,460
在幾張幻燈片前展示過，如果你

1430
00:54:23,460 --> 00:54:25,940
只看純粹的線條 代碼中

1431
00:54:25,940 --> 00:54:28,680
哪一個佔用了更多代碼，你可以

1432
00:54:28,680 --> 00:54:31,440
使用代碼行數

1433
00:54:31,440 --> 00:54:34,559
作為統計複雜性或

1434
00:54:34,559 --> 00:54:36,660
包含多少信息的代理，因此

1435
00:54:36,660 --> 00:54:38,339
運行主動

1436
00:54:38,339 --> 00:54:40,140
推理循環的模擬本身就像 15 行代碼

1437
00:54:40,140 --> 00:54:42,300
，就像和和 他們和代碼

1438
00:54:42,300 --> 00:54:44,220
本身已經非常通用，並不

1439
00:54:44,220 --> 00:54:46,319
特定於場景構建演示

1440
00:54:46,319 --> 00:54:48,359
編寫生成模型本身

1441
00:54:48,359 --> 00:54:49,920
，這是完成所有繁重工作的地方

1442
00:54:49,920 --> 00:54:51,119
這是所有

1443
00:54:51,119 --> 00:54:53,520
特定於該任務的信息都被

1444
00:54:53,520 --> 00:54:55,980
編碼的地方，例如，我只是看看我是

1445
00:54:55,980 --> 00:54:58,260
如何創建矩陣的，

1446
00:54:58,260 --> 00:55:00,540
關於

1447
00:55:00,540 --> 00:55:02,520
場景構建演示的觀察映射的信念，這已經是

1448
00:55:02,520 --> 00:55:05,460
比運行

1449
00:55:05,460 --> 00:55:07,859
整個主動推理更多的代碼 模擬所以

1450
00:55:07,859 --> 00:55:09,540
就像通過大量

1451
00:55:09,540 --> 00:55:11,220
代碼你已經可以告訴哦是

1452
00:55:11,220 --> 00:55:13,200
的有很多假設和

1453
00:55:13,200 --> 00:55:15,119
信息被烘焙到

1454
00:55:15,119 --> 00:55:16,559
生成模型中這就是

1455
00:55:16,559 --> 00:55:18,480
主動推理的大部分繁重工作

1456
00:55:18,480 --> 00:55:21,260
實際上來自

1457
00:55:21,300 --> 00:55:22,559
嗯是的所以我 只是認為

1458
00:55:22,559 --> 00:55:24,300
對此發表評論很重要，因為這是一件

1459
00:55:24,300 --> 00:55:26,640
非常關鍵的事情，我認為任何

1460
00:55:26,640 --> 00:55:28,440
想開始

1461
00:55:28,440 --> 00:55:30,599
在離散狀態

1462
00:55:30,599 --> 00:55:32,220
空間中使用主動推理模型的人

1463
00:55:32,220 --> 00:55:34,559
都應該考慮一下，模型完成了

1464
00:55:34,559 --> 00:55:36,420
大部分工作 對你來說，預期自由

1465
00:55:36,420 --> 00:55:38,040
能是一個非常有趣的

1466
00:55:38,040 --> 00:55:39,660
目標函數，它有很多

1467
00:55:39,660 --> 00:55:41,880
優點，但

1468
00:55:41,880 --> 00:55:44,700
主動推理的大部分功能 開始寫下

1469
00:55:44,700 --> 00:55:46,740
你的代理人對世界的信念

1470
00:55:46,740 --> 00:55:48,300
是什麼，然後一旦你有了它，

1471
00:55:48,300 --> 00:55:50,520
那麼剩下的一切都會

1472
00:55:50,520 --> 00:55:52,980
為你工作，因為 pi NDB 代碼

1473
00:55:52,980 --> 00:55:55,440
非常通用，不通用的是

1474
00:55:55,440 --> 00:55:56,880
你如何對關於世界的信念進行編碼

1475
00:55:56,880 --> 00:55:59,000
world

1476
00:55:59,400 --> 00:56:01,680
um okay so now I'm kind of finishing

1477
00:56:01,680 --> 00:56:03,960
maybe we should demember on that bit on

1478
00:56:03,960 --> 00:56:05,460
a second anyone have thoughts

1479
00:56:05,460 --> 00:56:08,579
or comments or questions about this

1480
00:56:08,579 --> 00:56:12,359
如果沒有，我可以繼續完成

1481
00:56:12,359 --> 00:56:16,460
達芙妮或雅各布，或者我會問 一個

1482
00:56:21,300 --> 00:56:23,520
我沒有任何問題

1483
00:56:23,520 --> 00:56:25,680
好吧你已經強調

1484
00:56:25,680 --> 00:56:28,079
了代理生成模型的規範

1485
00:56:28,079 --> 00:56:29,099


1486
00:56:29,099 --> 00:56:31,680
以及硬幣的另一面

1487
00:56:31,680 --> 00:56:34,740
如何我們如何指定生成過程

1488
00:56:34,740 --> 00:56:37,680
我們如何

1489
00:56:37,680 --> 00:56:40,399
為代理

1490
00:56:40,440 --> 00:56:41,880
指定真正的環境 好問題是的

1491
00:56:41,880 --> 00:56:44,520
基本上我所說的關於

1492
00:56:44,520 --> 00:56:46,680
生成

1493
00:56:46,680 --> 00:56:48,540
模型的所有內容都適用於生成

1494
00:56:48,540 --> 00:56:50,099
過程

1495
00:56:50,099 --> 00:56:53,520
除了代理的有趣行為

1496
00:56:53,520 --> 00:56:55,500
是的我的意思是你可以

1497
00:56:55,500 --> 00:56:57,059
想到生成過程 這也推動了

1498
00:56:57,059 --> 00:56:58,200
很多，

1499
00:56:58,200 --> 00:57:00,059
我猜瓶頸是

1500
00:57:00,059 --> 00:57:01,920
生成模型，因為如果你創建一個

1501
00:57:01,920 --> 00:57:04,140
非常複雜的生成過程，那麼一個

1502
00:57:04,140 --> 00:57:05,819
非常複雜的環境具有

1503
00:57:05,819 --> 00:57:08,579
各種奇特的非線性動力學，

1504
00:57:08,579 --> 00:57:10,319
但代理的世界模型是超級

1505
00:57:10,319 --> 00:57:12,420
超級的 簡單所以它只是相信

1506
00:57:12,420 --> 00:57:14,400
你知道有一個電燈開關

1507
00:57:14,400 --> 00:57:16,440
是開著還是關著

1508
00:57:16,440 --> 00:57:18,839
那麼你可以

1509
00:57:18,839 --> 00:57:22,200
從這樣一個簡單的代理人那裡得到的可能行為受到

1510
00:57:22,200 --> 00:57:23,880
其生成模型的複雜性的限制

1511
00:57:23,880 --> 00:57:28,020
所以一個非常複雜的生成器一個

1512
00:57:28,020 --> 00:57:29,760
非常簡單的生成模型將 仍然

1513
00:57:29,760 --> 00:57:33,000
沒有表現出非常有趣的行為，

1514
00:57:33,000 --> 00:57:34,619
即使它被嵌入到一個複雜的

1515
00:57:34,619 --> 00:57:37,079
生成過程中，但是

1516
00:57:37,079 --> 00:57:38,700
當你同時

1517
00:57:38,700 --> 00:57:40,500
擁有一個複雜的生成過程

1518
00:57:40,500 --> 00:57:44,040
和一個複雜的生成模型時，最豐富的動態顯然會發生所以

1519
00:57:44,040 --> 00:57:46,920
在構建

1520
00:57:46,920 --> 00:57:48,660
生成模型時我會做的所有工作 說的是

1521
00:57:48,660 --> 00:57:50,760
這裡的第一行也可以

1522
00:57:50,760 --> 00:57:52,319
通過

1523
00:57:52,319 --> 00:57:54,900
生成生成過程的大量工作來匹配，

1524
00:57:54,900 --> 00:57:56,760
在這種情況下是 是認知網格

1525
00:57:56,760 --> 00:57:58,319
世界環境，它只是一組

1526
00:57:58,319 --> 00:58:00,660
規則，說明當代理位於

1527
00:58:00,660 --> 00:58:03,000
隊列位置時向他們顯示隊列

1528
00:58:03,000 --> 00:58:04,920
身份，就像這樣相對

1529
00:58:04,920 --> 00:58:06,359
簡單

1530
00:58:06,359 --> 00:58:08,760
但值得思考的一件有趣的事情

1531
00:58:08,760 --> 00:58:10,920
，我相信丹尼爾和你一樣

1532
00:58:10,920 --> 00:58:13,260
想過 關於這個，當談到

1533
00:58:13,260 --> 00:58:15,000
嗯，你知道你在主動

1534
00:58:15,000 --> 00:58:17,099
推理和集體行為方面的工作是

1535
00:58:17,099 --> 00:58:18,960
關於多代理行為的有趣的事情，

1536
00:58:18,960 --> 00:58:21,300
在這種情況下，生成

1537
00:58:21,300 --> 00:58:25,020
過程是其他代理的行為，

1538
00:58:25,020 --> 00:58:26,819
所以生成過程我的生成

1539
00:58:26,819 --> 00:58:28,980
過程實際上是

1540
00:58:28,980 --> 00:58:31,020
另一個主動推理代理的輸出，所以這

1541
00:58:31,020 --> 00:58:32,819


1542
00:58:32,819 --> 00:58:34,500
是達芙妮和我在做的時候必須努力解決的最複雜的事情之一

1543
00:58:34,500 --> 00:58:36,720


1544
00:58:36,720 --> 00:58:38,339
毛澤東也是認知社區的第一作者

1545
00:58:38,339 --> 00:58:40,500
像

1546
00:58:40,500 --> 00:58:43,140
社交網絡迴聲室一樣工作 在

1547
00:58:43,140 --> 00:58:45,119
這種情況下，生成過程

1548
00:58:45,119 --> 00:58:47,880
有點困難，因為

1549
00:58:47,880 --> 00:58:49,980
該過程本身由

1550
00:58:49,980 --> 00:58:51,660
其他活躍的推理代理組成 我們

1551
00:58:51,660 --> 00:58:54,780
還採取行動，因此該代碼的控制流

1552
00:58:54,780 --> 00:58:55,980
看起來會有點不同

1553
00:58:55,980 --> 00:58:57,420
，您將不得不循環遍歷

1554
00:58:57,420 --> 00:59:00,599
所有代理，從中獲取操作，

1555
00:59:00,599 --> 00:59:02,400
然後使用這些操作來參數

1556
00:59:02,400 --> 00:59:03,720
化所有其他代理的觀察結果，

1557
00:59:03,720 --> 00:59:05,760
我的意思是這只是 一個

1558
00:59:05,760 --> 00:59:08,099
關於多智能體模擬

1559
00:59:08,099 --> 00:59:10,440
的一般性陳述，但是

1560
00:59:10,440 --> 00:59:12,240
當你考慮

1561
00:59:12,240 --> 00:59:14,400
智能體試圖對其他智能體建模時，它特別有趣，

1562
00:59:14,400 --> 00:59:16,740
因為幾乎每個活躍的

1563
00:59:16,740 --> 00:59:18,119
推理智能體都會有一個

1564
00:59:18,119 --> 00:59:20,400
關於世界如何運作的貧乏模型，

1565
00:59:20,400 --> 00:59:23,819
當世界如何運作時

1566
00:59:23,819 --> 00:59:25,500
是一堆交互的主動

1567
00:59:25,500 --> 00:59:27,000
推理代理，所以你將

1568
00:59:27,000 --> 00:59:29,819
不得不為每個代理

1569
00:59:29,819 --> 00:59:31,500
配備一個更簡化的生成模型，

1570
00:59:31,500 --> 00:59:33,660
除非你希望它們都具有

1571
00:59:33,660 --> 00:59:35,460
無限遞歸深度並且能夠

1572
00:59:35,460 --> 00:59:37,859
在它們自己的生成模型中模擬

1573
00:59:37,859 --> 00:59:39,480
每個其他

1574
00:59:39,480 --> 00:59:41,940
代理的生成模型所以是的，呃，我的意思是這

1575
00:59:41,940 --> 00:59:43,020
與

1576
00:59:43,020 --> 00:59:44,460
多代理案例有點切線，但我認為它' 考慮

1577
00:59:44,460 --> 00:59:46,619


1578
00:59:46,619 --> 00:59:49,140


1579
00:59:49,140 --> 00:59:51,119


1580
00:59:51,119 --> 00:59:52,680
生成模型複雜性和

1581
00:59:52,680 --> 00:59:54,480
生成過程複雜性之間的緊張關係，以及

1582
00:59:54,480 --> 00:59:56,579
它們如何相互約束彼此的

1583
00:59:56,579 --> 00:59:59,480
行為，這只是一個有趣的複雜問題，

1584
01:00:02,400 --> 01:00:04,799
好吧，我可以繼續嗎，嗯，是

1585
01:00:04,799 --> 01:00:06,540
的，最後兩張幻燈片我 think 是一種

1586
01:00:06,540 --> 01:00:09,720
令人興奮的東西，所以這裡列出了

1587
01:00:09,720 --> 01:00:11,099
我們希望在未來使用 prime DP 做的事情，

1588
01:00:11,099 --> 01:00:13,500


1589
01:00:13,500 --> 01:00:15,480
嗯，我將通過它們，然後

1590
01:00:15,480 --> 01:00:16,980
我將詳細介紹一些我認為

1591
01:00:16,980 --> 01:00:19,319
最重要的事情 很重要，所以一個是將 Pine DP

1592
01:00:19,319 --> 01:00:21,299
模型擬合到經驗數據，所以我

1593
01:00:21,299 --> 01:00:23,160
與來自計算精神病學社區的人進行了很多互動，

1594
01:00:23,160 --> 01:00:24,960
他們

1595
01:00:24,960 --> 01:00:26,460
有興趣實際創建

1596
01:00:26,460 --> 01:00:30,299
行為模型，通常是人類行為，

1597
01:00:30,299 --> 01:00:32,520
嗯，這是他們的 Palm DP 主動

1598
01:00:32,520 --> 01:00:34,740
推理模型和其中之一

1599
01:00:34,740 --> 01:00:37,020
我認為現在 pine DP 的最大局限性

1600
01:00:37,020 --> 01:00:40,319
是人們不能使用 pi mdp 來

1601
01:00:40,319 --> 01:00:42,900


1602
01:00:42,900 --> 01:00:44,819
推斷正在執行某些任務的人類主體的主動推理參數，而

1603
01:00:44,819 --> 01:00:47,220
這正是您可以在 S 中執行的任務 現在是 PM，

1604
01:00:47,220 --> 01:00:48,540
但不幸的是，你不能

1605
01:00:48,540 --> 01:00:51,540
在 Pion VP 中這樣做，所以這

1606
01:00:51,540 --> 01:00:53,339
在優先級列表中非常高，我認為

1607
01:00:53,339 --> 01:00:55,020
這將幫助主要 P 實際上

1608
01:00:55,020 --> 01:00:58,440
成為

1609
01:00:58,440 --> 01:00:59,640
有興趣

1610
01:00:59,640 --> 01:01:02,640
安裝 Pi mdp 模型的社區的 SPM 的競爭者 到數據，所以

1611
01:01:02,640 --> 01:01:03,780
這些就像計算精神病學等更經驗主義的

1612
01:01:03,780 --> 01:01:05,040
科學學科，

1613
01:01:05,040 --> 01:01:08,040


1614
01:01:08,040 --> 01:01:10,440
我認為我們現在需要一個

1615
01:01:10,440 --> 01:01:12,059
更好的接口來實際

1616
01:01:12,059 --> 01:01:13,859
生成和構建生成

1617
01:01:13,859 --> 01:01:17,460
模型，所有

1618
01:01:17,460 --> 01:01:19,559
涉及構建 A 和 B 矩陣的代碼真正

1619
01:01:19,559 --> 01:01:21,180
成為瓶頸 對於任何

1620
01:01:21,180 --> 01:01:23,280
試圖進行主動推理的人來說，在很大程度上是

1621
01:01:23,280 --> 01:01:25,319
因為為

1622
01:01:25,319 --> 01:01:27,839
複雜的慷慨模型構建這些數組真的

1623
01:01:27,839 --> 01:01:29,280
很讓人頭疼，你必須做所有這些奇怪

1624
01:01:29,280 --> 01:01:31,680
的多維索引，因為

1625
01:01:31,680 --> 01:01:33,000
就像你在世界上有一堆不同的

1626
01:01:33,000 --> 01:01:34,920
相互作用變量一樣 你

1627
01:01:34,920 --> 01:01:37,079
必須創建大量的多維

1628
01:01:37,079 --> 01:01:39,180
數組，這些數組具有不同數量的

1629
01:01:39,180 --> 01:01:41,160
額外維度，對應於 世界上所有

1630
01:01:41,160 --> 01:01:42,720
這些可能的意外事件

1631
01:01:42,720 --> 01:01:44,460
，它有點變成了一個巨大的

1632
01:01:44,460 --> 01:01:47,339
查找表，你必須對

1633
01:01:47,339 --> 01:01:49,680
變量之間的所有關係進行編碼，

1634
01:01:49,680 --> 01:01:51,480
所以我認為這可能是一個

1635
01:01:51,480 --> 01:01:52,859
雄心勃勃的項目，但可能有一些

1636
01:01:52,859 --> 01:01:55,619
方法可以實際創建類似

1637
01:01:55,619 --> 01:01:58,440
用戶的用戶界面 幫助人們建立

1638
01:01:58,440 --> 01:02:00,540
生成模型的界面，比如問他們

1639
01:02:00,540 --> 01:02:02,579
一系列問題，例如

1640
01:02:02,579 --> 01:02:04,200
你想讓這個變量影響那個

1641
01:02:04,200 --> 01:02:05,760
變量，然後根據他們的

1642
01:02:05,760 --> 01:02:08,339
回答，你可以

1643
01:02:08,339 --> 01:02:10,440
預先參數化矩陣的一部分

1644
01:02:10,440 --> 01:02:12,180
或其他東西，然後

1645
01:02:12,180 --> 01:02:13,740
矩陣草圖窗口的實際結構

1646
01:02:13,740 --> 01:02:15,900
下降到一系列關於世界上不同突發事件的是的

1647
01:02:15,900 --> 01:02:17,160
問題

1648
01:02:17,160 --> 01:02:19,740


1649
01:02:19,740 --> 01:02:21,900
另一件事是與 openai

1650
01:02:21,900 --> 01:02:24,119
gym 的接口我們已經完成了

1651
01:02:24,119 --> 01:02:26,099
就像有幾個例子我們已經

1652
01:02:26,099 --> 01:02:28,079
完成了這個 我還

1653
01:02:28,079 --> 01:02:31,020
沒有在 GitHub 上積極地將這些放在基礎設施上，

1654
01:02:31,020 --> 01:02:32,880
但這是一個開放的東西，

1655
01:02:32,880 --> 01:02:35,160
這是一件非常明顯和容易

1656
01:02:35,160 --> 01:02:37,500
做的事情 因為就像我們編寫

1657
01:02:37,500 --> 01:02:40,020
環境類一樣，就

1658
01:02:40,020 --> 01:02:42,240
好像它是基於健身房環境一樣，所以

1659
01:02:42,240 --> 01:02:43,859
一旦你這樣做了，它就會打開

1660
01:02:43,859 --> 01:02:45,780
比較主動推理代理與層次模型上

1661
01:02:45,780 --> 01:02:46,920
各種強化學習

1662
01:02:46,920 --> 01:02:48,000
算法

1663
01:02:48,000 --> 01:02:51,780
的大問題，所以

1664
01:02:51,780 --> 01:02:54,140
嗯，基本上允許你在彼此之間堆疊

1665
01:02:54,140 --> 01:02:56,099
分層活躍的推理代理

1666
01:02:56,099 --> 01:02:58,559
，就像是的

1667
01:02:58,559 --> 01:03:00,119
，你

1668
01:03:00,119 --> 01:03:02,579
可以通過將活躍的推理代理堆疊

1669
01:03:02,579 --> 01:03:05,160
到分層的事物中來獲得很多時間深度，比如

1670
01:03:05,160 --> 01:03:07,680
推理和計劃的時間尺度

1671
01:03:07,680 --> 01:03:10,200
在一個較慢的時間尺度上發生 比 a 慢

1672
01:03:10,200 --> 01:03:12,420
一個 sub 更快的時間尺度，

1673
01:03:12,420 --> 01:03:14,520
我們需要更多演示

1674
01:03:14,520 --> 01:03:16,140
參數學習的演示，這樣你就可以

1675
01:03:16,140 --> 01:03:19,020
更新 a b 和 d 數組我不

1676
01:03:19,020 --> 01:03:21,299
認為你到目前為止可以更新 C 我知道

1677
01:03:21,299 --> 01:03:22,740
這是丹尼爾你向我提到的東西

1678
01:03:22,740 --> 01:03:25,140
這是呃 你在

1679
01:03:25,140 --> 01:03:26,700
主動推理研究所的人通常

1680
01:03:26,700 --> 01:03:28,079
對

1681
01:03:28,079 --> 01:03:29,640
um 基本上更新關於

1682
01:03:29,640 --> 01:03:31,200
生成模型參數的信念感興趣

1683
01:03:31,200 --> 01:03:32,460
然後有事情 就像

1684
01:03:32,460 --> 01:03:34,319
複雜的推理，這是

1685
01:03:34,319 --> 01:03:36,000
一種更新版本的

1686
01:03:36,000 --> 01:03:37,440
主動推理

1687
01:03:37,440 --> 01:03:40,200
下的規劃，這很有趣，並且對它有一些

1688
01:03:40,200 --> 01:03:42,480
計算上的好處，然後

1689
01:03:42,480 --> 01:03:43,799
與復雜的推理攜手並進

1690
01:03:43,799 --> 01:03:45,839
，人們

1691
01:03:45,839 --> 01:03:47,700
已經開發出必須在

1692
01:03:47,700 --> 01:03:49,140
深度強化中處理的東西 學習一段時間

1693
01:03:49,140 --> 01:03:51,720
，你如何馴服組合

1694
01:03:51,720 --> 01:03:53,460
爆炸性政策空間，所以當你

1695
01:03:53,460 --> 01:03:56,280
隨著時間的推移進行深入規劃時，呃

1696
01:03:56,280 --> 01:03:58,200
，政策的

1697
01:03:58,200 --> 01:04:01,020
數量與你計劃的時間步數成指數關係，

1698
01:04:01,020 --> 01:04:03,720
所以有各種技術來

1699
01:04:03,720 --> 01:04:05,339
處理這個問題 就像蒙特卡洛樹

1700
01:04:05,339 --> 01:04:07,200
搜索，我認為有些人像

1701
01:04:07,200 --> 01:04:09,380
teofio Champions 和其他人已經

1702
01:04:09,380 --> 01:04:11,640
嘗試開始為 um 實施他們自己

1703
01:04:11,640 --> 01:04:14,700
的 palm DPS 實現

1704
01:04:14,700 --> 01:04:17,040
，所以沿著這些思路我

1705
01:04:17,040 --> 01:04:19,079
只想指出我們實際上非常

1706
01:04:19,079 --> 01:04:21,059
接近實現這個 現在工作，使

1707
01:04:21,059 --> 01:04:23,339
Pi mdp 模型與經驗數據相匹配，

1708
01:04:23,339 --> 01:04:25,980
所以有一個分支

1709
01:04:25,980 --> 01:04:27,420
，我和 Dimitri markovic 一直在工作 繼續

1710
01:04:27,420 --> 01:04:29,579
稱為代理 Jax Branch，我們

1711
01:04:29,579 --> 01:04:31,680
基本上已經為 pione p 和 Jax 編寫了一個後端

1712
01:04:31,680 --> 01:04:35,160
，它不僅讓我們使用來自 numpyro 的

1713
01:04:35,160 --> 01:04:37,319
一堆統計概率

1714
01:04:37,319 --> 01:04:39,420
推理技術

1715
01:04:39,420 --> 01:04:42,480
來反轉或

1716
01:04:42,480 --> 01:04:44,819
從類似數據推斷 Pi mdp 代理的參數 實例

1717
01:04:44,819 --> 01:04:47,280
計算呃從人類參與者那裡收集的，

1718
01:04:47,280 --> 01:04:49,920
但事實上它

1719
01:04:49,920 --> 01:04:52,440
也在 Jacks 中後端意味著 Pi mdp 現在是

1720
01:04:52,440 --> 01:04:54,299
完全自動可微的，

1721
01:04:54,299 --> 01:04:56,460
所以這意味著你可以在 pi VP 的矩陣層之前將深度

1722
01:04:56,460 --> 01:04:59,400
神經網絡層堆疊到類似的層上

1723
01:04:59,400 --> 01:05:01,799


1724
01:05:01,799 --> 01:05:03,420
agent，然後你可以使用

1725
01:05:03,420 --> 01:05:05,460
諸如變分自由能或任何

1726
01:05:05,460 --> 01:05:07,500
其他目標函數之類的東西來

1727
01:05:07,500 --> 01:05:09,660
自動訓練

1728
01:05:09,660 --> 01:05:11,880
鏈接到 pi VP agent 的神經網絡的參數，

1729
01:05:11,880 --> 01:05:14,280
所以我認為這只是

1730
01:05:14,280 --> 01:05:16,260
在後端重新實現它，比如 Pi

1731
01:05:16,260 --> 01:05:18,720
torch 和 Jacks 這就像一個巨大的好處，

1732
01:05:18,720 --> 01:05:20,700
因為這將真正允許您

1733
01:05:20,700 --> 01:05:22,680


1734
01:05:22,680 --> 01:05:25,640
通過將

1735
01:05:25,640 --> 01:05:28,260
深度神經網絡鏈接到各種

1736
01:05:28,260 --> 01:05:31,020
組件 o 將 pione P 擴展到更多的高維狀態空間 f agent 的身體，正如你

1737
01:05:31,020 --> 01:05:33,119
所描述的那樣，Daniel

1738
01:05:33,119 --> 01:05:34,619
嗯，所以我們最初這樣做只是為了

1739
01:05:34,619 --> 01:05:36,359
讓你可以擬合經驗

1740
01:05:36,359 --> 01:05:38,700
數據，但它有一個附帶的好處

1741
01:05:38,700 --> 01:05:41,280
，那就是允許你

1742
01:05:41,280 --> 01:05:43,619
像反向傳播梯度一樣區分和傳遞

1743
01:05:43,619 --> 01:05:45,559
你將用於 更新深度學習

1744
01:05:45,559 --> 01:05:48,119
模型，我認為這真的很令人興奮，

1745
01:05:48,119 --> 01:05:51,299
所以這就像快完成了我的意思是，是的，

1746
01:05:51,299 --> 01:05:53,579
就像我們非常接近建立一個

1747
01:05:53,579 --> 01:05:55,559
筆記本，如果你

1748
01:05:55,559 --> 01:05:57,180
現在看代理 Jack's Branch，它實際上是這樣做的，它

1749
01:05:57,180 --> 01:05:58,980
不是很有條理，但那東西

1750
01:05:58,980 --> 01:06:01,680
現在在那裡並實施了

1751
01:06:01,680 --> 01:06:04,799
另一件事也不是 Sajid，我實際上已經

1752
01:06:04,799 --> 01:06:07,020


1753
01:06:07,020 --> 01:06:09,480
從她的論文中實施了一些環境主動

1754
01:06:09,480 --> 01:06:11,339
推理揭秘比較我們

1755
01:06:11,339 --> 01:06:15,180
實際上已經在 openai 健身房使用 pi MVP 做到了，

1756
01:06:15,180 --> 01:06:16,980
就像在冰凍的湖面環境中一樣，這

1757
01:06:16,980 --> 01:06:19,380
是一個很受歡迎的環境 模擬 B 矩陣

1758
01:06:19,380 --> 01:06:20,640
學習

1759
01:06:20,640 --> 01:06:21,839
嗯，這

1760
01:06:21,839 --> 01:06:24,599
也是我們已經做到的事情，呃，我們

1761
01:06:24,599 --> 01:06:26,520
需要喜歡上傳那個，否則我不知道

1762
01:06:26,520 --> 01:06:28,079
寫一篇簡短的論文做一些 事情

1763
01:06:28,079 --> 01:06:29,700
是這樣的，因為有很多類似的

1764
01:06:29,700 --> 01:06:31,200
這些不同的捲須已經被

1765
01:06:31,200 --> 01:06:33,359
探索過，這只是一個

1766
01:06:33,359 --> 01:06:34,799
向前推進的問題，實際上把它們

1767
01:06:34,799 --> 01:06:37,500
放在松樹 BP repo

1768
01:06:37,500 --> 01:06:39,359
嗯是的，然後這些其他的事情

1769
01:06:39,359 --> 01:06:42,000
我想找時間做但是 我只是

1770
01:06:42,000 --> 01:06:43,799
沒有，但我的意思是，正如我在開始時所說的那樣

1771
01:06:43,799 --> 01:06:44,940
，這是一種非常

1772
01:06:44,940 --> 01:06:47,039
協作的努力，所以我也不想

1773
01:06:47,039 --> 01:06:48,660


1774
01:06:48,660 --> 01:06:50,700
成為一個喜歡做

1775
01:06:50,700 --> 01:06:52,380
所有這些的人，因為我認為它也

1776
01:06:52,380 --> 01:06:54,180
更健康

1777
01:06:54,180 --> 01:06:55,680
如果不同的人

1778
01:06:55,680 --> 01:06:57,480
在不同的事情上帶頭並

1779
01:06:57,480 --> 01:06:58,980
以他們自己的方式開發它，那麼包的開發

1780
01:06:58,980 --> 01:07:00,480
就是我通常也喜歡

1781
01:07:00,480 --> 01:07:03,059
鼓勵的事情是讓各種感興趣的

1782
01:07:03,059 --> 01:07:04,140
人參與

1783
01:07:04,140 --> 01:07:05,520
開發

1784
01:07:05,520 --> 01:07:08,339
，我不 不認為 Brennan 在這裡，嗯，但

1785
01:07:08,339 --> 01:07:11,000
Brennan Klein 也是東北大學網絡科學研究所

1786
01:07:11,000 --> 01:07:12,839
的博士後

1787
01:07:12,839 --> 01:07:13,920
和研究科學家，

1788
01:07:13,920 --> 01:07:15,240


1789
01:07:15,240 --> 01:07:17,880
他開始了這些 Pi

1790
01:07:17,880 --> 01:07:20,339
mdp 獎學金，所以他得到了

1791
01:07:20,339 --> 01:07:21,960
N 的資助 ortheastern 我認為還有 Templeton

1792
01:07:21,960 --> 01:07:24,420
基金會資助人們從事

1793
01:07:24,420 --> 01:07:26,400
Pine MVP 開發或主要 DP

1794
01:07:26,400 --> 01:07:28,619
相鄰項目我認為第一

1795
01:07:28,619 --> 01:07:30,839
輪申請已經結束，

1796
01:07:30,839 --> 01:07:32,099
但這只是一個很好

1797
01:07:32,099 --> 01:07:33,839
的宣傳機會，我認為

1798
01:07:33,839 --> 01:07:35,339
將會有

1799
01:07:35,339 --> 01:07:38,000
夏天的另一個隊列，所以這是一種

1800
01:07:38,000 --> 01:07:40,680
看似持續的資金來源，

1801
01:07:40,680 --> 01:07:42,359
所以很高興看到其他人

1802
01:07:42,359 --> 01:07:45,180
正在努力推動 Pine VP

1803
01:07:45,180 --> 01:07:47,339
朝著他們自己的方向發展，所以這只是一個

1804
01:07:47,339 --> 01:07:48,839
令人鼓舞的發展，我

1805
01:07:48,839 --> 01:07:52,319
想讓每個人都得到評價

1806
01:07:52,319 --> 01:07:54,299
嗯，哦，是的，然後我會

1807
01:07:54,299 --> 01:07:56,359


1808
01:07:57,240 --> 01:08:00,180
耐心地在閱讀文檔網站上結束，

1809
01:08:00,180 --> 01:08:01,740
這對於創建自動文檔非常有用

1810
01:08:01,740 --> 01:08:03,960
，所以我們在

1811
01:08:03,960 --> 01:08:05,460
那裡有很多演示，我們有不同的

1812
01:08:05,460 --> 01:08:07,440
教程，

1813
01:08:07,440 --> 01:08:09,539
嗯，我們有另一個新演示，它是

1814
01:08:09,539 --> 01:08:11,160
此處未列出，它只是

1815
01:08:11,160 --> 01:08:13,140
計算離散分類模型中自由能的變化，

1816
01:08:13,140 --> 01:08:15,480
該模型

1817
01:08:15,480 --> 01:08:17,939
基於 Ryan Smith 和

1818
01:08:17,939 --> 01:08:20,040
Christopher white 以及 Carl fursten 的

1819
01:08:20,040 --> 01:08:20,819
pap 的演示

1820
01:08:20,819 --> 01:08:23,698
嗯，呃，不像那篇關於主動推理的大教程論文，

1821
01:08:23,698 --> 01:08:26,100
所以我重新實現

1822
01:08:26,100 --> 01:08:28,319
了那篇論文中的一個演示，現在

1823
01:08:28,319 --> 01:08:31,020
它也在文檔中，

1824
01:08:31,020 --> 01:08:33,060
嗯，是的，所以你可以在協作中打開所有這些演示

1825
01:08:33,060 --> 01:08:35,100
筆記本，然後逐步

1826
01:08:35,100 --> 01:08:36,960
完成它們，嗯，它們 真的，您

1827
01:08:36,960 --> 01:08:38,880
甚至不需要

1828
01:08:38,880 --> 01:08:40,198
在計算機上安裝 python 就可以使用它們，您

1829
01:08:40,198 --> 01:08:42,600
只需打開協作中的鏈接並

1830
01:08:42,600 --> 01:08:44,460
逐步執行代碼，就像構建您自己的

1831
01:08:44,460 --> 01:08:46,259
主動推理

1832
01:08:46,259 --> 01:08:48,238
代理一樣，這對教學很有用，這

1833
01:08:48,238 --> 01:08:49,259
就是我提到的原因 如果你剛剛

1834
01:08:49,259 --> 01:08:50,880
開始，我肯定會建議

1835
01:08:50,880 --> 01:08:54,238
你去看文檔，

1836
01:08:54,238 --> 01:08:56,698
所以是的，嗯，謝謝大家的傾聽

1837
01:08:56,698 --> 01:08:59,640
，也謝謝你讓我有

1838
01:08:59,640 --> 01:09:01,799
機會說話，一如既往地來到這裡真是太好了

1839
01:09:01,799 --> 01:09:05,640
，我想 是的，

1840
01:09:05,640 --> 01:09:07,620
我在底部列出了下一個

1841
01:09:07,620 --> 01:09:08,939
直播流，我們可以瀏覽

1842
01:09:08,939 --> 01:09:10,738
一些演示筆記本，但

1843
01:09:10,738 --> 01:09:12,660
如果有時間，我們現在也可以瀏覽它們，也許

1844
01:09:12,660 --> 01:09:14,279
我們會先進行討論，然後再

1845
01:09:14,279 --> 01:09:15,179
看看

1846
01:09:15,179 --> 01:09:17,880
有沒有時間，

1847
01:09:17,880 --> 01:09:21,540
太棒了，謝謝你 嗯，讓我們來解決

1848
01:09:21,540 --> 01:09:25,140
達芙妮和雅各布的一些問題，我會

1849
01:09:25,140 --> 01:09:28,140
在實時聊天中問一些問題，然後也許

1850
01:09:28,140 --> 01:09:31,738
你可以

1851
01:09:31,738 --> 01:09:34,920
在閱讀文檔時分享一個或幾個例子

1852
01:09:34,920 --> 01:09:36,479
，我們可以從

1853
01:09:36,479 --> 01:09:40,140
結構上看一下解剖學和

1854
01:09:40,140 --> 01:09:42,899
生理學是什麼 一個筆記本所以首先

1855
01:09:42,899 --> 01:09:46,080
達芙妮或雅各布有任何

1856
01:09:46,080 --> 01:09:49,339
想法或問題

1857
01:09:52,679 --> 01:09:56,120
是的是的去吧

1858
01:09:56,400 --> 01:09:58,620
嗯我想知道在 Jacks

1859
01:09:58,620 --> 01:10:00,300
實現上

1860
01:10:00,300 --> 01:10:03,660
是否有任何關於

1861
01:10:03,660 --> 01:10:07,400
定義生成過程的要求

1862
01:10:07,500 --> 01:10:11,160
或者它只是關於定義

1863
01:10:11,160 --> 01:10:13,140


1864
01:10:13,140 --> 01:10:14,820
然後我們將生成模型擬合到實驗數據

1865
01:10:14,820 --> 01:10:16,199
，我想這也與

1866
01:10:16,199 --> 01:10:18,840
我在將這些模型擴展

1867
01:10:18,840 --> 01:10:21,780
到狀態空間或一般過程時遇到的另一個問題有關

1868
01:10:21,780 --> 01:10:24,179
，我們作為建模者沒有

1869
01:10:24,179 --> 01:10:27,000
自由來實際定義自己，但

1870
01:10:27,000 --> 01:10:28,699
我們想

1871
01:10:28,699 --> 01:10:31,159
部署和

1872
01:10:31,159 --> 01:10:34,739
在已經存在的一般流程中訓練這些代理人，

1873
01:10:34,739 --> 01:10:37,080
就像在在線

1874
01:10:37,080 --> 01:10:39,780
環境中一樣，您可以在其中獲得分類或

1875
01:10:39,780 --> 01:10:42,500


1876
01:10:42,600 --> 01:10:45,360
離散數據，

1877
01:10:45,360 --> 01:10:46,920
是的，

1878
01:10:46,920 --> 01:10:48,960
完全是

1879
01:10:48,960 --> 01:10:51,360
這樣 一個很好的問題，

1880
01:10:51,360 --> 01:10:54,659
嗯，我有一個計劃 BP 代理，它

1881
01:10:54,659 --> 01:10:56,159
附加了一堆深度神經網絡

1882
01:10:56,159 --> 01:10:59,580
，我想

1883
01:10:59,580 --> 01:11:01,320
在部署的環境中訓練它，所以它就像在

1884
01:11:01,320 --> 01:11:03,179
那裡，你知道，讓我們說它是一個代理

1885
01:11:03,179 --> 01:11:04,739
那是在股票市場上交易，或者

1886
01:11:04,739 --> 01:11:06,300


1887
01:11:06,300 --> 01:11:09,060
像下注購買加密貨幣一樣讓我們

1888
01:11:09,060 --> 01:11:09,960
說

1889
01:11:09,960 --> 01:11:12,659
在這種情況下以同樣的方式

1890
01:11:12,659 --> 01:11:14,280
在那種數據上訓練深度神經網絡

1891
01:11:14,280 --> 01:11:16,320
你不需要通過生成過程傳遞梯度

1892
01:11:16,320 --> 01:11:18,120
當然

1893
01:11:18,120 --> 01:11:20,159
你無法訪問你

1894
01:11:20,159 --> 01:11:22,320
在股票市場上交易所以從這個意義上說

1895
01:11:22,320 --> 01:11:24,420
沒有關於傳遞梯度的要求

1896
01:11:24,420 --> 01:11:27,300
或者編寫一個

1897
01:11:27,300 --> 01:11:30,060
也是自動可微分的生成過程

1898
01:11:30,060 --> 01:11:32,820
有一種情況你想要

1899
01:11:32,820 --> 01:11:34,739
的是

1900
01:11:34,739 --> 01:11:37,980
通常在經驗

1901
01:11:37,980 --> 01:11:40,800
上將 Pine DP 模型擬合到數據的情況下，通常

1902
01:11:40,800 --> 01:11:43,020
你想要做的一件事是你

1903
01:11:43,020 --> 01:11:45,000
有一堆就像你基本上有

1904
01:11:45,000 --> 01:11:47,219
一個人類參與者的行為和觀察的歷史，

1905
01:11:47,219 --> 01:11:49,679
你適合模型

1906
01:11:49,679 --> 01:11:52,140
t  pi VP 代理的參數

1907
01:11:52,140 --> 01:11:54,360
最能解釋你的參與者觀察到的行為

1908
01:11:54,360 --> 01:11:55,920
，你知道這些

1909
01:11:55,920 --> 01:11:57,120
觀察結果，因為你是一個

1910
01:11:57,120 --> 01:11:59,219
實驗者，喜歡決定這個

1911
01:11:59,219 --> 01:12:00,480
人將看到觀察序列，

1912
01:12:00,480 --> 01:12:02,400
所以你可以在

1913
01:12:02,400 --> 01:12:04,380
沒有可微分的情況下完成所有這些

1914
01:12:04,380 --> 01:12:07,380
生成過程或環境，但

1915
01:12:07,380 --> 01:12:09,000
貝葉斯推理中有一些東西

1916
01:12:09,000 --> 01:12:10,860
被稱為後驗

1917
01:12:10,860 --> 01:12:12,960
預測檢查，你說好吧，

1918
01:12:12,960 --> 01:12:16,620
鑑於我對 uh

1919
01:12:16,620 --> 01:12:18,840
pione P 代理的參數的推斷，然後我

1920
01:12:18,840 --> 01:12:20,520
想推出

1921
01:12:20,520 --> 01:12:23,100
這個代理的預期行為

1922
01:12:23,100 --> 01:12:25,560
給出我對這個

1923
01:12:25,560 --> 01:12:27,840
代理參數的最佳猜測，所以這被

1924
01:12:27,840 --> 01:12:29,640
稱為後驗預測密度

1925
01:12:29,640 --> 01:12:32,400
，你說給定我

1926
01:12:32,400 --> 01:12:34,500
對代理參數的後驗 um 估計

1927
01:12:34,500 --> 01:12:37,080


1928
01:12:37,080 --> 01:12:39,480
在這些後驗參數下它在未來會是什麼樣子

1929
01:12:39,480 --> 01:12:42,840
並在 使用 numpyro，它

1930
01:12:42,840 --> 01:12:45,420
是

1931
01:12:45,420 --> 01:12:47,699
使用 Jax 作為後端的概率推理框架，你會

1932
01:12:47,699 --> 01:12:49,800
想要一個生成器 過程

1933
01:12:49,800 --> 01:12:52,679
也是自動可微的，

1934
01:12:52,679 --> 01:12:54,659
但在那種情況下，我希望

1935
01:12:54,659 --> 01:12:56,400
編寫這些生成過程會

1936
01:12:56,400 --> 01:12:58,020
很容易，因為這將是在將

1937
01:12:58,020 --> 01:13:01,199
人類行為與實驗數據相匹配的情況

1938
01:13:01,199 --> 01:13:02,820
下，他們就像

1939
01:13:02,820 --> 01:13:05,159
在受控任務環境中一樣，所以如果它

1940
01:13:05,159 --> 01:13:07,739
是 嘗試擬合某人的

1941
01:13:07,739 --> 01:13:10,320
參數（例如他們的 C 向量的值）的情況，

1942
01:13:10,320 --> 01:13:12,420
並且他們正在執行

1943
01:13:12,420 --> 01:13:13,860
他們生病的場景構建任務，

1944
01:13:13,860 --> 01:13:15,300


1945
01:13:15,300 --> 01:13:17,040
您可以編寫生成過程，

1946
01:13:17,040 --> 01:13:18,840
因為您作為實驗或

1947
01:13:18,840 --> 01:13:21,480
開發了類似心理物理學的

1948
01:13:21,480 --> 01:13:22,739
任務 他們正在與您進行交互，

1949
01:13:22,739 --> 01:13:24,659
當您進行建模時，他們也可以在 Jax 中編寫這些內容，

1950
01:13:24,659 --> 01:13:26,460
這樣當您進行

1951
01:13:26,460 --> 01:13:28,620
這些後驗預測檢查時，您

1952
01:13:28,620 --> 01:13:30,300
知道這也是在 Jacks 中編寫的，

1953
01:13:30,300 --> 01:13:31,620
並且您可以計算這些

1954
01:13:31,620 --> 01:13:33,900
數量，但在已部署的設置中

1955
01:13:33,900 --> 01:13:35,460
你甚至無法在未來進行

1956
01:13:35,460 --> 01:13:37,140
任何類型的後驗預測檢查

1957
01:13:37,140 --> 01:13:39,179
，因為你不

1958
01:13:39,179 --> 01:13:41,219
知道環境實際上是如何工作的 ht

1959
01:13:41,219 --> 01:13:43,080
所以你必須告訴

1960
01:13:43,080 --> 01:13:44,940
你，那甚至不是

1961
01:13:44,940 --> 01:13:47,520
你一開始就嘗試做的事情，

1962
01:13:47,520 --> 01:13:48,540
嗯，但是是的，所以沒有什麼

1963
01:13:48,540 --> 01:13:52,020
內在地阻止你，

1964
01:13:52,020 --> 01:13:54,000
只要模型可以以

1965
01:13:54,000 --> 01:13:55,140
與它們相同的方式區分 深度神經

1966
01:13:55,140 --> 01:13:56,219
網絡 沒有什麼能阻止你

1967
01:13:56,219 --> 01:13:57,659
將它們扔到一個

1968
01:13:57,659 --> 01:13:58,980
你不知道世界規則如何運作的環境中

1969
01:13:58,980 --> 01:14:01,940


1970
01:14:02,640 --> 01:14:04,199


1971
01:14:04,199 --> 01:14:06,900


1972
01:14:06,900 --> 01:14:10,620


1973
01:14:10,620 --> 01:14:13,080


1974
01:14:13,080 --> 01:14:15,239
在

1975
01:14:15,239 --> 01:14:16,020
那裡

1976
01:14:16,020 --> 01:14:18,900
它要么會工作，要么不會

1977
01:14:18,900 --> 01:14:21,600
，如果它失敗了，它就會失敗，

1978
01:14:21,600 --> 01:14:23,940
計算環境允許我們

1979
01:14:23,940 --> 01:14:25,860
存在於這種灰色地帶，在這個灰色地帶

1980
01:14:25,860 --> 01:14:28,260
，計算代理可能

1981
01:14:28,260 --> 01:14:30,719
很難適應給定的部署

1982
01:14:30,719 --> 01:14:33,300
設置，但計算機程序

1983
01:14:33,300 --> 01:14:35,880
仍然會運行，但我們當然

1984
01:14:35,880 --> 01:14:38,300
對計算機程序運行

1985
01:14:38,300 --> 01:14:42,120
並且代理能夠像我們一樣發生某種

1986
01:14:42,120 --> 01:14:43,100


1987
01:14:43,100 --> 01:14:47,520
有意義甚至有用的行為的情況感興趣

1988
01:14:47,520 --> 01:14:49,860
我們能不能

1989
01:14:49,860 --> 01:14:52,620
想像非常簡單的 Prime DP 模型

1990
01:14:52,620 --> 01:14:54,420
在某些任務中會做得非常好

1991
01:14:54,420 --> 01:14:56,340
，就像一個具有兩個隱藏狀態的愚蠢模型一樣

1992
01:14:56,340 --> 01:14:57,960
，它認為它們只是

1993
01:14:57,960 --> 01:14:59,580
隨機地在彼此之間切換

1994
01:14:59,580 --> 01:15:02,340
，然後你給它一個任務，

1995
01:15:02,340 --> 01:15:05,520
呃，投資於 就像一個 10 隻

1996
01:15:05,520 --> 01:15:07,679
股票的投資組合，當然它的

1997
01:15:07,679 --> 01:15:10,739
模型不適合，但是

1998
01:15:10,739 --> 01:15:13,800
將大的深度函數逼近

1999
01:15:13,800 --> 01:15:15,780
器應用於 Prime DP 代理的不同端的承諾

2000
01:15:15,780 --> 01:15:18,179
意味著希望你可以

2001
01:15:18,179 --> 01:15:20,760
學習一個好的生成模型，然後

2002
01:15:20,760 --> 01:15:22,739
仍然將它與一些較低的

2003
01:15:22,739 --> 01:15:24,719
維度生成模型

2004
01:15:24,719 --> 01:15:26,400
可以通過主動推理進行所有好的推理和

2005
01:15:26,400 --> 01:15:28,380
規劃，但它

2006
01:15:28,380 --> 01:15:31,320
可以通過使用深度神經網絡處理高維或醜陋的

2007
01:15:31,320 --> 01:15:33,420
難以馴服的觀察和行動

2008
01:15:33,420 --> 01:15:36,360
空間，所以

2009
01:15:36,360 --> 01:15:39,000
我認為這真的是

2010
01:15:39,000 --> 01:15:40,800
在 同樣，深度學習

2011
01:15:40,800 --> 01:15:42,659
在很多情況下都能發揮作用，

2012
01:15:42,659 --> 01:15:45,120
這就是使用主要

2013
01:15:45,120 --> 01:15:48,120
DP 模型以及

2014
01:15:48,120 --> 01:15:50,940
Daphne 任何評論的方式 或者我會

2015
01:15:50,940 --> 01:15:53,719
在聊天中問一些問題，

2016
01:15:54,540 --> 01:15:55,920
嗯，我真的沒有任何問題，但

2017
01:15:55,920 --> 01:15:57,960
我確實認為這真的很有趣，

2018
01:15:57,960 --> 01:16:00,000
而且

2019
01:16:00,000 --> 01:16:02,040
我認為像你說的那樣去

2020
01:16:02,040 --> 01:16:06,300
學習生成模型真的很令人興奮

2021
01:16:06,300 --> 01:16:07,800
智能體學習它自己的生成

2022
01:16:07,800 --> 01:16:10,560
模型，就像一些真實世界的數據一樣

2023
01:16:10,560 --> 01:16:12,480
，想弄清楚它們是什麼，我想

2024
01:16:12,480 --> 01:16:14,040
就像你

2025
01:16:14,040 --> 01:16:15,600
所說的那樣，比如函數

2026
01:16:15,600 --> 01:16:18,480
逼近和 numpyro 之類的

2027
01:16:18,480 --> 01:16:22,140
東西仍然像你們一樣

2028
01:16:22,140 --> 01:16:24,239
仍然像從那個代碼庫一樣工作

2029
01:16:24,239 --> 01:16:27,360
，然後最終轉換那些或者

2030
01:16:27,360 --> 01:16:29,100
讓它從頭開始

2031
01:16:29,100 --> 01:16:31,320
是的，我們幾乎

2032
01:16:31,320 --> 01:16:33,659
從頭開始 pi DCM 的事情

2033
01:16:33,659 --> 01:16:35,400
我實際上不確定它的

2034
01:16:35,400 --> 01:16:37,260
IP 狀態是什麼，因為我們工作

2035
01:16:37,260 --> 01:16:39,060
在它上面作為嵌套我的一部分，所以

2036
01:16:39,060 --> 01:16:40,500
我無法再訪問該代碼，

2037
01:16:40,500 --> 01:16:43,260
但它更像是

2038
01:16:43,260 --> 01:16:46,739
變體 LaPlace 的實現，我們

2039
01:16:46,739 --> 01:16:48,900
在其中與變體 Applause 注入一起工作，

2040
01:16:48,900 --> 01:16:51,960
這是 wa 是的，

2041
01:16:51,960 --> 01:16:54,060


2042
01:16:54,060 --> 01:16:56,460
當你試圖做 um 推理

2043
01:16:56,460 --> 01:16:59,640
我們現在正在做的事情而不是

2044
01:16:59,640 --> 01:17:02,400
我們說你能重寫一個松樹 DP

2045
01:17:02,400 --> 01:17:03,600
模型，

2046
01:17:03,600 --> 01:17:06,600
這樣你就可以通過它傳遞梯度時，你可以對自由能進行梯度下降

2047
01:17:06,600 --> 01:17:09,420
Jacks like accelerated 梯度，

2048
01:17:09,420 --> 01:17:11,400
然後使用 numpyro 進行各種

2049
01:17:11,400 --> 01:17:13,020
擬合例程，不僅僅是變分

2050
01:17:13,020 --> 01:17:16,080
拉普拉斯，你可以使用 mcmc，你可以

2051
01:17:16,080 --> 01:17:18,540
像 numpower 一樣使用，你知道有一個巨大的

2052
01:17:18,540 --> 01:17:21,440
庫，包含不同的呃

2053
01:17:21,440 --> 01:17:24,179
概率近似貝葉斯

2054
01:17:24,179 --> 01:17:25,679
推理技術，所以你可以

2055
01:17:25,679 --> 01:17:28,380
把廚房的水槽扔掉

2056
01:17:28,380 --> 01:17:31,800
在主要 DP 模型中使用 numpyro 推理技術，

2057
01:17:31,800 --> 01:17:34,080
所以這裡的挑戰只是

2058
01:17:34,080 --> 01:17:36,239
重寫主要 DP 模型，這樣您就可以定義

2059
01:17:36,239 --> 01:17:38,280
一個似然函數，從

2060
01:17:38,280 --> 01:17:40,440
Palm DP 參數到

2061
01:17:40,440 --> 01:17:42,420
觀察結果，在這種情況下將

2062
01:17:42,420 --> 01:17:45,300
是代理的動作 為了

2063
01:17:45,300 --> 01:17:47,040
以某種方式做到這一點，以便

2064
01:17:47,040 --> 01:17:48,780
與 Jax 友好地玩耍，我們只需要確保

2065
01:17:48,780 --> 01:17:51,300


2066
01:17:51,300 --> 01:17:53,340
pine DP 代理的所有內部功能都像推理一樣

2067
01:17:53,340 --> 01:17:55,679
計劃行動選擇所有這些

2068
01:17:55,679 --> 01:17:58,199
都是用 Jacks 編寫的，這樣你就可以

2069
01:17:58,199 --> 01:18:00,000
在像似然梯度這樣的計算時有效地傳遞梯度

2070
01:18:00,000 --> 01:18:03,199


2071
01:18:03,199 --> 01:18:05,699
是的，這很有意義

2072
01:18:05,699 --> 01:18:07,380
是的，

2073
01:18:07,380 --> 01:18:09,900
好吧，我會從實時聊天中問幾個問題，

2074
01:18:09,900 --> 01:18:13,140
所以

2075
01:18:13,140 --> 01:18:15,360
首先 整個文獻中對主動推理的描述

2076
01:18:15,360 --> 01:18:17,100
都是用矩陣來寫的，

2077
01:18:17,100 --> 01:18:19,380
但是 Pi mdp 顯然

2078
01:18:19,380 --> 01:18:20,880
適用於張量，

2079
01:18:20,880 --> 01:18:23,340
當你將方程從矩陣推廣到張量時，你有一個很好的參考來說明

2080
01:18:23,340 --> 01:18:24,960
操作有何不同，

2081
01:18:24,960 --> 01:18:27,120


2082
01:18:27,120 --> 01:18:28,940


2083
01:18:28,940 --> 01:18:31,260
這是一個很好的觀點，

2084
01:18:31,260 --> 01:18:32,100
嗯，這是其中之一

2085
01:18:32,100 --> 01:18:33,840
當我第一次學習主動推理時，真正讓我很沮喪的

2086
01:18:33,840 --> 01:18:35,159


2087
01:18:35,159 --> 01:18:37,340
事情是我注意到這個人

2088
01:18:37,340 --> 01:18:40,260
問的是很多基本

2089
01:18:40,260 --> 01:18:42,000
操作

2090
01:18:42,000 --> 01:18:42,540
um

2091
01:18:42,540 --> 01:18:45,960
被寫成好像只有一

2092
01:18:45,960 --> 01:18:47,520
維隱藏狀態和一

2093
01:18:47,520 --> 01:18:50,580
維觀察所以一切

2094
01:18:50,580 --> 01:18:53,159
都是 就像他們說的 Matrix Vector products

2095
01:18:53,159 --> 01:18:54,840
和 Matrix math 但我們真正

2096
01:18:54,840 --> 01:18:57,239
做的是張量乘法和

2097
01:18:57,239 --> 01:19:00,239
張量積所以就

2098
01:19:00,239 --> 01:19:03,060
其工作原理的參考而言，

2099
01:19:03,060 --> 01:19:05,940
嗯，是的，所以從本質上講，我們在 pione P 中

2100
01:19:05,940 --> 01:19:07,800


2101
01:19:07,800 --> 01:19:10,260
所做的這些張量運算基本上沒有什麼超質的不同

2102
01:19:10,260 --> 01:19:12,600
，基本上只是

2103
01:19:12,600 --> 01:19:15,600
表達

2104
01:19:15,600 --> 01:19:17,880
矩陣乘法和的更奇特的方式，所以它

2105
01:19:17,880 --> 01:19:20,280
的數學是 所有仍然

2106
01:19:20,280 --> 01:19:22,380
標準的線性代數只是

2107
01:19:22,380 --> 01:19:24,060
我們表示這些高維

2108
01:19:24,060 --> 01:19:25,920
矩陣的方式，因為張量只是一種更

2109
01:19:25,920 --> 01:19:27,120
有效的表示方式，所以從

2110
01:19:27,120 --> 01:19:29,880
數學上講，這並沒有太瘋狂

2111
01:19:29,880 --> 01:19:32,340
，我了解它是如何工作的方式

2112
01:19:32,340 --> 01:19:34,800
只是通過盯著

2113
01:19:34,800 --> 01:19:37,260
Matlab 中的函數看了一年直到 我只是

2114
01:19:37,260 --> 01:19:38,820
弄明白了，但這並不容易，

2115
01:19:38,820 --> 01:19:41,580
現在肯定有更好的選擇，

2116
01:19:41,580 --> 01:19:42,900


2117
01:19:42,900 --> 01:19:45,600
嗯，嗯，我馬上

2118
01:19:45,600 --> 01:19:48,719
推薦的一個參考資料是 um Pi mdp 的附錄附錄

2119
01:19:48,719 --> 01:19:50,460
，

2120
01:19:50,460 --> 01:19:52,920
嗯，存檔文件

2121
01:19:52,920 --> 01:19:55,739
，這樣就像 我認為附錄 a

2122
01:19:55,739 --> 01:19:57,960
或所有這些附錄基本上處理

2123
01:19:57,960 --> 01:20:01,199
的是完整的張量因式分解版本

2124
01:20:01,199 --> 01:20:03,179
，它不處理矩陣，而是

2125
01:20:03,179 --> 01:20:05,100
我們實際上是在索引更高

2126
01:20:05,100 --> 01:20:09,120
維度的另一個維度，我認為

2127
01:20:09,120 --> 01:20:11,460
它最初討論的是張量

2128
01:20:11,460 --> 01:20:13,860
積，張量分解

2129
01:20:13,860 --> 01:20:16,500
在我認為主動

2130
01:20:16,500 --> 01:20:18,540
推理好奇心和洞察力的附錄中，這

2131
01:20:18,540 --> 01:20:19,679
是他們第一次談論的地方，比如

2132
01:20:19,679 --> 01:20:21,719
新穎性和參數信息增益

2133
01:20:21,719 --> 01:20:23,820
，這是一個 論文，

2134
01:20:23,820 --> 01:20:25,199
嗯，對不起，我不記得

2135
01:20:25,199 --> 01:20:27,900
它發表的年份是 2017 年還是 2018 年，但

2136
01:20:27,900 --> 01:20:30,420
我知道這篇論文的標題叫做主動

2137
01:20:30,420 --> 01:20:32,340
推理好奇心和洞察力，在

2138
01:20:32,340 --> 01:20:34,440
其中一個附錄中，他們實際上做

2139
01:20:34,440 --> 01:20:38,580
了完整的基於張量的數學和

2140
01:20:38,580 --> 01:20:41,820
最後，另一個很好的參考是

2141
01:20:41,820 --> 01:20:44,640
最近的一篇論文，我認為它是由 teofio Champion 領導的，

2142
01:20:44,640 --> 01:20:48,780
我只是想盡快

2143
01:20:48,780 --> 01:20:50,760
找到它，因為我

2144
01:20:50,760 --> 01:20:52,739
不想忘記它，

2145
01:20:52,739 --> 01:20:55,679
也許我會停止共享我的屏幕

2146
01:20:55,679 --> 01:20:58,800
，我停止了嗎？ 它停止了

2147
01:20:58,800 --> 01:20:59,580
嗯，

2148
01:20:59,580 --> 01:21:01,080
這是一個非常好的參考，它有

2149
01:21:01,080 --> 01:21:02,760
附錄

2150
01:21:02,760 --> 01:21:04,500
關於

2151
01:21:04,500 --> 01:21:07,920
嗯為主動推理做張量數學

2152
01:21:07,920 --> 01:21:11,600
特別是

2153
01:21:13,260 --> 01:21:15,600
我們最近還了解了

2154
01:21:15,600 --> 01:21:18,360
分支時間主動推理 w 這

2155
01:21:18,360 --> 01:21:20,040
談到了一些關於

2156
01:21:20,040 --> 01:21:24,480
計算複雜性的問題

2157
01:21:26,219 --> 01:21:27,840
，

2158
01:21:27,840 --> 01:21:29,699
好吧，是的，我應該提到

2159
01:21:29,699 --> 01:21:31,380
這可能是迄今為止最有前途的

2160
01:21:31,380 --> 01:21:33,960
方法，

2161
01:21:33,960 --> 01:21:37,080
關於嗯嗯，巧妙地處理

2162
01:21:37,080 --> 01:21:38,820
主動推理的計算複雜性，

2163
01:21:38,820 --> 01:21:41,400
所以是的，這是

2164
01:21:41,400 --> 01:21:44,580
teofio 的 Champions Mark gresh 我想

2165
01:21:44,580 --> 01:21:46,440
那是他的一位顧問，Howard

2166
01:21:46,440 --> 01:21:49,560
Bowman 是他的另一位顧問，這

2167
01:21:49,560 --> 01:21:51,600
就是我剛剛發布的多模態和多因素

2168
01:21:51,600 --> 01:21:53,400
分支時間主動推理，

2169
01:21:53,400 --> 01:21:55,620
所以我自己還沒有讀過，

2170
01:21:55,620 --> 01:21:57,000
但我從其他人那裡聽說

2171
01:21:57,000 --> 01:21:59,040
過 我認為 Alec chance 告訴

2172
01:21:59,040 --> 01:22:01,920
我附錄對

2173
01:22:01,920 --> 01:22:03,780
技術非常有用主動推理的全張量泛化

2174
01:22:03,780 --> 01:22:05,940


2175
01:22:05,940 --> 01:22:08,699
好吧太棒了好吧我已經將所有

2176
01:22:08,699 --> 01:22:09,540


2177
01:22:09,540 --> 01:22:12,239
提到的引用添加到 YouTube

2178
01:22:12,239 --> 01:22:13,920
實時聊天中

2179
01:22:13,920 --> 01:22:16,500
太棒了謝謝你我要問

2180
01:22:16,500 --> 01:22:19,560
Fausto

2181
01:22:19,560 --> 01:22:22,739
使用 Jax 後端提出的以下問題使得

2182
01:22:22,739 --> 01:22:24,020
包裝

2183
01:22:24,020 --> 01:22:28,800
pymc3 變得容易 圍繞它應用 MC3 EG 讓 pi

2184
01:22:28,800 --> 01:22:32,219
mdp 作為運算符在 pi MC3

2185
01:22:32,219 --> 01:22:35,580
模型中使用 有沒有計劃這樣做我問，

2186
01:22:35,580 --> 01:22:37,320
因為

2187
01:22:37,320 --> 01:22:41,880
圍繞 Pi MC3 的 Python 中有一個不斷增長的貝葉斯社區，

2188
01:22:41,880 --> 01:22:43,380
嗯，這真的很有趣，我不

2189
01:22:43,380 --> 01:22:46,199
知道實際上 Prime G3 也

2190
01:22:46,199 --> 01:22:48,719
有一個 Jacks，所以

2191
01:22:48,719 --> 01:22:51,600
我不知道 老實說，

2192
01:22:51,600 --> 01:22:52,980
我首先要說我不知道，

2193
01:22:52,980 --> 01:22:55,080
因為我

2194
01:22:55,080 --> 01:22:57,840
是通過 DME Dimitri markovic 介紹 Python 中的概率建模的，

2195
01:22:57,840 --> 01:23:00,300
他

2196
01:23:00,300 --> 01:23:02,880
基本上向我推銷了 numpyro numpyro

2197
01:23:02,880 --> 01:23:04,920
是未來的方式，我知道 numpyro

2198
01:23:04,920 --> 01:23:06,840
有一個 Jack 的後端，我認為

2199
01:23:06,840 --> 01:23:10,440
numpyro 和 Pi MC3 在 Python

2200
01:23:10,440 --> 01:23:13,199
的概率推理生態系統中佔據相似的位置，

2201
01:23:13,199 --> 01:23:16,020


2202
01:23:16,020 --> 01:23:18,300
嗯，我不知道

2203
01:23:18,300 --> 01:23:22,020
pi MC3 中的模型是如何指定的，我假設

2204
01:23:22,020 --> 01:23:24,300
它與 numpyro 中的外觀

2205
01:23:24,300 --> 01:23:26,520
並沒有太大不同，因為 所有低級後端

2206
01:23:26,520 --> 01:23:29,880
現在都是用 Jax 編寫的，我不能保證

2207
01:23:29,880 --> 01:23:31,860
這一點，但我假設你可以

2208
01:23:31,860 --> 01:23:34,140
只編寫一個 pi MC3 模型，

2209
01:23:34,140 --> 01:23:36,480
就像我們編寫一個 numpyro 模型一樣

2210
01:23:36,480 --> 01:23:40,500
，它包裝了 um Pi mdp 函數，但只有

2211
01:23:40,500 --> 01:23:43,620
pi MVP 實現 注入所以如果

2212
01:23:43,620 --> 01:23:46,020
Pine Z3 只依賴於

2213
01:23:46,020 --> 01:23:48,600
低級別的 Jax 那麼是的它肯定可以工作

2214
01:23:48,600 --> 01:23:50,699
但是我不知道這裡是否有其他

2215
01:23:50,699 --> 01:23:53,040
人有使用 pine G3 的經驗

2216
01:23:53,040 --> 01:23:55,320
並且可能知道

2217
01:23:55,320 --> 01:23:56,820
因為我只是不太了解

2218
01:23:56,820 --> 01:23:58,560
它

2219
01:23:58,560 --> 01:24:01,320
我使用了一點 YMC 但我認為

2220
01:24:01,320 --> 01:24:03,239
它就像你說的那樣

2221
01:24:03,239 --> 01:24:05,400
與 numpyro 非常相似我認為

2222
01:24:05,400 --> 01:24:07,560
你可能能夠

2223
01:24:07,560 --> 01:24:10,080
做與 numpirers 相同的事情，

2224
01:24:10,080 --> 01:24:12,480
比如在

2225
01:24:12,480 --> 01:24:15,540
pyro 上集成 pi MC3 以及

2226
01:24:15,540 --> 01:24:18,360
啊酷所以它是主要的嗯

2227
01:24:18,360 --> 01:24:19,800
後端是 Jax

2228
01:24:19,800 --> 01:24:21,239
是

2229
01:24:21,239 --> 01:24:25,099
嗯我實際上沒有那樣做

2230
01:24:25,620 --> 01:24:28,460
嗯我不知道是

2231
01:24:28,460 --> 01:24:31,980
的與 Matlab 的矩陣

2232
01:24:31,980 --> 01:24:35,219
乘法相比是

2233
01:24:35,219 --> 01:24:37,380
什麼讓你對概率感到興奮

2234
01:24:37,380 --> 01:24:40,980
編程方向以及

2235
01:24:40,980 --> 01:24:42,780


2236
01:24:42,780 --> 01:24:44,820
我們命名的所有這些包和方法，

2237
01:24:44,820 --> 01:24:48,179
概率編程與

2238
01:24:48,179 --> 01:24:51,420
僅僅寫出矩陣並

2239
01:24:51,420 --> 01:24:54,000
在紙上計算它們有何不同，為什麼

2240
01:24:54,000 --> 01:24:56,880
這對實現主動推理模型有一定的希望，

2241
01:24:56,880 --> 01:24:59,400


2242
01:24:59,400 --> 01:25:01,880
嗯，我覺得 k

2243
01:25:01,880 --> 01:25:03,780
概率

2244
01:25:03,780 --> 01:25:05,940
編程的最大優勢不一定是

2245
01:25:05,940 --> 01:25:08,400
模擬主動推理代理來

2246
01:25:08,400 --> 01:25:10,020
模擬主動推理代理

2247
01:25:10,020 --> 01:25:12,659
確保矩陣乘法

2248
01:25:12,659 --> 01:25:15,840
足夠在 Jax 中使其

2249
01:25:15,840 --> 01:25:18,480
更具可擴展性因此您可以使用

2250
01:25:18,480 --> 01:25:21,120
所有矢量化操作來運行

2251
01:25:21,120 --> 01:25:22,980
數十個 數以千計的活動推理

2252
01:25:22,980 --> 01:25:24,600
代理同時進行，因為您擁有

2253
01:25:24,600 --> 01:25:25,620
這些

2254
01:25:25,620 --> 01:25:28,440
高度優化的即時編譯

2255
01:25:28,440 --> 01:25:30,840
函數和 Jack，它們允許

2256
01:25:30,840 --> 01:25:32,280
您基本上將速度提高一個

2257
01:25:32,280 --> 01:25:34,860
數量級，但概率

2258
01:25:34,860 --> 01:25:36,540
編程角度不如

2259
01:25:36,540 --> 01:25:39,060
模擬活動推理過程那麼多

2260
01:25:39,060 --> 01:25:41,100
它用於對經驗數據進行推理

2261
01:25:41,100 --> 01:25:43,620
或將主動推理代理的模型擬合，

2262
01:25:43,620 --> 01:25:46,860
所以說

2263
01:25:46,860 --> 01:25:49,460
觀察動物或人

2264
01:25:49,460 --> 01:25:53,040
現在正在做我們可以做的事情，我們只能

2265
01:25:53,040 --> 01:25:55,440
做 SPM，但直到現在我們還不能在 Pine VP 中做

2266
01:25:55,440 --> 01:25:58,080
是我們可以採用

2267
01:25:58,080 --> 01:25:59,460
某人的一系列行為

2268
01:25:59,460 --> 01:26:02,699
，然後推斷

2269
01:26:02,699 --> 01:26:04,260
出主動推理模型的最佳參數

2270
01:26:04,260 --> 01:26:06,239
這解釋了他們的行為，所以

2271
01:26:06,239 --> 01:26:08,100
考慮到某人如何決定我可以說哦，

2272
01:26:08,100 --> 01:26:10,199
他們的矩陣必須看起來像這樣或者

2273
01:26:10,199 --> 01:26:12,780
他們的 C 向量必須具有這個 um

2274
01:26:12,780 --> 01:26:14,880
Precision 就像你可以推斷出

2275
01:26:14,880 --> 01:26:18,420
某人的風險敏感性或者他們的

2276
01:26:18,420 --> 01:26:21,239
風險厭惡給定他們的行為

2277
01:26:21,239 --> 01:26:22,500
和好事 關於使用

2278
01:26:22,500 --> 01:26:24,060
概率編程語言，在 Matlab 文獻

2279
01:26:24,060 --> 01:26:26,520
中有很多不同的方法

2280
01:26:26,520 --> 01:26:29,159
還沒有被很好地探索來

2281
01:26:29,159 --> 01:26:30,719
擬合主動推理模型，

2282
01:26:30,719 --> 01:26:31,860
因為幾乎

2283
01:26:31,860 --> 01:26:34,679
每個人都使用這種 um 變分

2284
01:26:34,679 --> 01:26:36,420
貝葉斯方法，你基本上

2285
01:26:36,420 --> 01:26:38,940
最小化自由能，你使用高斯

2286
01:26:38,940 --> 01:26:40,800
近似 對於後驗，它是一種

2287
01:26:40,800 --> 01:26:42,480
非常特殊

2288
01:26:42,480 --> 01:26:45,060
的變分推理類型，現在

2289
01:26:45,060 --> 01:26:48,480
它又出現在 numpyro 或 Pi mt3 中，

2290
01:26:48,480 --> 01:26:50,520
這將很快實現，它還沒有完全

2291
01:26:50,520 --> 01:26:52,560
實現，但我們將能夠拋出

2292
01:26:52,560 --> 01:26:54,480
各種具有不同優勢的概率

2293
01:26:54,480 --> 01:26:55,620
推理技術

2294
01:26:55,620 --> 01:26:57,780
缺點

2295
01:26:57,780 --> 01:27:00,300
是概率

2296
01:27:00,300 --> 01:27:04,620
推理中的一件大事是 um mcmc Monte C  arlo Markov

2297
01:27:04,620 --> 01:27:06,540
chain Monte Carlo 推理它

2298
01:27:06,540 --> 01:27:09,840
應該給出更少的偏見呃呃

2299
01:27:09,840 --> 01:27:11,280
後驗分佈就像

2300
01:27:11,280 --> 01:27:13,500
使用 mcmc 優於

2301
01:27:13,500 --> 01:27:16,260
變分方法來近似

2302
01:27:16,260 --> 01:27:18,360
基礎和推理的優勢以及

2303
01:27:18,360 --> 01:27:19,739
我沒有看到完成的一件事我很想

2304
01:27:19,739 --> 01:27:21,780
看到和很多

2305
01:27:21,780 --> 01:27:23,280
計算精神病學社區的人們

2306
01:27:23,280 --> 01:27:25,320
已經抱怨並告訴我他們

2307
01:27:25,320 --> 01:27:27,120
希望看到的是

2308
01:27:27,120 --> 01:27:30,440
對不同天數的並排比較，以推斷

2309
01:27:30,440 --> 01:27:33,840
Pi mdp 參數或 Palm DP 參數

2310
01:27:33,840 --> 01:27:37,199
與類似 mcmc 方法，所以一旦你

2311
01:27:37,199 --> 01:27:38,520
擁有了一切 一個概率

2312
01:27:38,520 --> 01:27:40,139
程序框架，你可以

2313
01:27:40,139 --> 01:27:42,360
在所有

2314
01:27:42,360 --> 01:27:44,159
不同的推理技術之間進行並排比較，

2315
01:27:44,159 --> 01:27:46,020


2316
01:27:46,020 --> 01:27:47,400
如果你受限於

2317
01:27:47,400 --> 01:27:49,460
只實現一種或兩種或三種

2318
01:27:49,460 --> 01:27:52,139
推理技術的語言，那麼

2319
01:27:52,139 --> 01:27:53,639
它基本上只是利用

2320
01:27:53,639 --> 01:27:55,340
人們在

2321
01:27:55,340 --> 01:27:57,780
numpyro 上所做的所有工作中，已經完成了所有

2322
01:27:57,780 --> 01:27:59,880
這些不同類型的推理方法

2323
01:27:59,880 --> 01:28:01,440
ods

2324
01:28:01,440 --> 01:28:04,440
yeah awesome and fausta followed

2325
01:28:04,440 --> 01:28:05,960
primary back end

2326
01:28:05,960 --> 01:28:11,040
uh for YMC is a Sarah 但新

2327
01:28:11,040 --> 01:28:13,620
版本可以使用 Jax 一旦 Jax 版本的 Pi mdp 穩定，我可能會

2328
01:28:13,620 --> 01:28:16,139
開始編寫 pi MC3 包裝器

2329
01:28:16,139 --> 01:28:18,420
，這

2330
01:28:18,420 --> 01:28:19,739
聽起來非常

2331
01:28:19,739 --> 01:28:21,659
可行，太棒了

2332
01:28:21,659 --> 01:28:23,639
如果你認為它很有可能

2333
01:28:23,639 --> 01:28:26,880
並且你有能力提供，那麼只需

2334
01:28:26,880 --> 01:28:28,860
最小化你的自由能量

2335
01:28:28,860 --> 01:28:30,719
，當你絕對這樣做時你不會感到驚訝

2336
01:28:30,719 --> 01:28:31,980


2337
01:28:31,980 --> 01:28:34,260
那太棒了這很有希望

2338
01:28:34,260 --> 01:28:35,940


2339
01:28:35,940 --> 01:28:38,760
嗯雅各布或達芙妮或者我現在可以問另一個

2340
01:28:38,760 --> 01:28:41,120
問題

2341
01:28:43,560 --> 01:28:45,600
對我來說這件事

2342
01:28:45,600 --> 01:28:47,460
好吧，你

2343
01:28:47,460 --> 01:28:51,780
在 Pi MGP 的上下文中多次提到了消息傳遞，

2344
01:28:51,780 --> 01:28:55,080
那麼什麼是消息傳遞

2345
01:28:55,080 --> 01:28:58,820
以及它是如何在 pi mdp 中使用的，

2346
01:28:58,820 --> 01:29:02,040
這是一個很好的問題，所以消息

2347
01:29:02,040 --> 01:29:04,199
傳遞通常描述為一

2348
01:29:04,199 --> 01:29:07,860
組算法，你可以使用它們來做一個

2349
01:29:07,860 --> 01:29:11,219
精確的 或近似貝葉斯推理

2350
01:29:11,219 --> 01:29:13,679
um 通常在對隱藏狀態進行貝葉斯推理的背景下使其變得

2351
01:29:13,679 --> 01:29:15,420
非常具體，

2352
01:29:15,420 --> 01:29:17,340


2353
01:29:17,340 --> 01:29:19,860
因此

2354
01:29:19,860 --> 01:29:21,179
主動推理代理

2355
01:29:21,179 --> 01:29:22,920
在 面對一些觀察，

2356
01:29:22,920 --> 01:29:25,800
他們必須組合消息，例如

2357
01:29:25,800 --> 01:29:28,500
一個消息對應於

2358
01:29:28,500 --> 01:29:30,900
感官信息，然後另一個

2359
01:29:30,900 --> 01:29:32,340
消息對應於他們

2360
01:29:32,340 --> 01:29:34,320
對世界的先前信念，他們使用

2361
01:29:34,320 --> 01:29:36,440
某種算法來組合這些消息

2362
01:29:36,440 --> 01:29:39,179
以優化對當前的信念

2363
01:29:39,179 --> 01:29:42,120
世界的隱藏狀態，所以在 pione P 中，

2364
01:29:42,120 --> 01:29:43,679
我們有一種非常樸素的

2365
01:29:43,679 --> 01:29:45,600
計算高效的

2366
01:29:45,600 --> 01:29:48,420
做事方式，我們稱之為樸素或

2367
01:29:48,420 --> 01:29:50,460
香草定點迭代，這

2368
01:29:50,460 --> 01:29:52,920
就像你能想到的最簡單的消息傳遞

2369
01:29:52,920 --> 01:29:54,420
方案，這就是

2370
01:29:54,420 --> 01:29:56,580
我

2371
01:29:56,580 --> 01:29:58,860
我使用我過去的先驗主動過濾隱藏狀態，所以我說

2372
01:29:58,860 --> 01:30:01,380
給定我在最後一個時間步驟的

2373
01:30:01,380 --> 01:30:03,780
位置，現在我應該在哪裡得到我的 B 矩陣

2374
01:30:03,780 --> 01:30:06,060
，然後我基本上將

2375
01:30:06,060 --> 01:30:08,300
它與我

2376
01:30:08,300 --> 01:30:10,739
傳入的感官信息結合起來，這

2377
01:30:10,739 --> 01:30:13,020
只是觀察 通過

2378
01:30:13,020 --> 01:30:15,239
似然矩陣 a 矩陣，然後

2379
01:30:15,239 --> 01:30:16,440
我將這兩個消息

2380
01:30:16,440 --> 01:30:19,080
組合在一起，結果就是我的

2381
01:30:19,080 --> 01:30:21,540
後驗分佈 考慮一下我

2382
01:30:21,540 --> 01:30:24,000
對隱藏狀態的後驗或最佳信念，這

2383
01:30:24,000 --> 01:30:25,679
就像最簡單的消息傳遞形式，

2384
01:30:25,679 --> 01:30:27,840
它具有這種暫時非常

2385
01:30:27,840 --> 01:30:28,920
淺薄的

2386
01:30:28,920 --> 01:30:31,920
當前證據，並結合之前

2387
01:30:31,920 --> 01:30:33,600
形成新的信念，它具有

2388
01:30:33,600 --> 01:30:35,639
這種貝葉斯風格

2389
01:30:35,639 --> 01:30:37,620
，而最佳後驗只是

2390
01:30:37,620 --> 01:30:40,739
可能性和先驗的產物，

2391
01:30:40,739 --> 01:30:41,520
嗯

2392
01:30:41,520 --> 01:30:43,139
，還有更高級的消息

2393
01:30:43,139 --> 01:30:45,480
傳遞技術，當你的信念本身更複雜時，就會使用這些技術，

2394
01:30:45,480 --> 01:30:46,980


2395
01:30:46,980 --> 01:30:48,480
所以

2396
01:30:48,480 --> 01:30:49,980


2397
01:30:49,980 --> 01:30:52,199
在 Matlab 版本中的主動推理的全面實施中，代理人

2398
01:30:52,199 --> 01:30:53,820
不只是相信什麼

2399
01:30:53,820 --> 01:30:56,179
當前隱藏狀態是他們對未來所有隱藏狀態和過去所有隱藏狀態具有完全

2400
01:30:56,179 --> 01:31:00,239
預測和後預測類型的

2401
01:31:00,239 --> 01:31:03,000
um 張量或信念立方體

2402
01:31:03,000 --> 01:31:04,860


2403
01:31:04,860 --> 01:31:07,020
進一步

2404
01:31:07,020 --> 01:31:09,179
條件我

2405
01:31:09,179 --> 01:31:11,219
可能採取或可能採取的所有政策

2406
01:31:11,219 --> 01:31:12,960
採取過去，所以你有這個巨大的

2407
01:31:12,960 --> 01:31:15,900
信念張量呃，它將延伸

2408
01:31:15,900 --> 01:31:17,940
到未來和過去的隱藏狀態，

2409
01:31:17,940 --> 01:31:21,060
呃更遠 r 由策略分解，當

2410
01:31:21,060 --> 01:31:22,800
您有那種需要更新的信念時，

2411
01:31:22,800 --> 01:31:24,600
您必須使用更

2412
01:31:24,600 --> 01:31:26,580
複雜的消息傳遞技術

2413
01:31:26,580 --> 01:31:28,920
，其中一種稱為邊際

2414
01:31:28,920 --> 01:31:30,659
消息傳遞，有一種叫做

2415
01:31:30,659 --> 01:31:32,880
變分消息傳遞的東西，所有

2416
01:31:32,880 --> 01:31:34,199
這些不同的消息傳遞

2417
01:31:34,199 --> 01:31:35,760
技術都只是

2418
01:31:35,760 --> 01:31:37,800


2419
01:31:37,800 --> 01:31:40,320
在時間上向前和向後傳遞消息以及在

2420
01:31:40,320 --> 01:31:42,600
表徵

2421
01:31:42,600 --> 01:31:44,159
隱藏狀態的不同變量之間基本一致，我們稱之為隱藏狀態

2422
01:31:44,159 --> 01:31:45,500
因素

2423
01:31:45,500 --> 01:31:48,060
，並且消息傳遞

2424
01:31:48,060 --> 01:31:49,739
算法基本上仍然

2425
01:31:49,739 --> 01:31:52,380
相當於將感官信息

2426
01:31:52,380 --> 01:31:55,199
與先驗信念相結合，但它們只是

2427
01:31:55,199 --> 01:31:57,360
有點

2428
01:31:57,360 --> 01:31:59,280
在過去的未來信念空間中有更複雜的軌跡，

2429
01:31:59,280 --> 01:32:02,400
我有一些

2430
01:32:02,400 --> 01:32:03,960
人比我能更好地解釋這一點

2431
01:32:03,960 --> 01:32:05,940
我已經在 pi mdp 中實現了其中的一些，

2432
01:32:05,940 --> 01:32:09,179
但我會推薦人們參考

2433
01:32:09,179 --> 01:32:12,060
有一篇非常好的 um 論文

2434
01:32:12,060 --> 01:32:14,280
我想你前幾天可能轉發了它，

2435
01:32:14,280 --> 01:32:16,440
Jacob，它是關於

2436
01:32:16,440 --> 01:32:16,980
嗯，

2437
01:32:16,980 --> 01:32:19,620
它叫做 mea  n field

2438
01:32:19,620 --> 01:32:21,719
oh yeah

2439
01:32:21,719 --> 01:32:24,360
um the paper comparing the mean field

2440
01:32:24,360 --> 01:32:27,179
and that they approximation and the best

2441
01:32:27,179 --> 01:32:28,679
air approximation neuronal message

2442
01:32:28,679 --> 01:32:30,719
passing using mean Fields Bethy and

2443
01:32:30,719 --> 01:32:32,400
marginal approximation

2444
01:32:32,400 --> 01:32:36,960
par Markovich kibel and friston 2019

2445
01:32:36,960 --> 01:32:38,820
um 這是一篇我們中的一些人

2446
01:32:38,820 --> 01:32:42,179
一直在看的論文

2447
01:32:42,179 --> 01:32:44,340
不同的自由能泛函

2448
01:32:44,340 --> 01:32:46,380
在不同的近似值下看起來有何不同

2449
01:32:46,380 --> 01:32:50,340
，它可能會成為 2023 年我們真正深入研究的焦點論文，

2450
01:32:50,340 --> 01:32:54,420


2451
01:32:54,420 --> 01:32:57,800
因為很多這些 um

2452
01:32:57,800 --> 01:33:03,020
vintage 讓我們說 2011 年到 2019 年的論文

2453
01:33:03,020 --> 01:33:06,360
現在包裝和發展方向，

2454
01:33:06,360 --> 01:33:08,400
例如 Pi  mdp

2455
01:33:08,400 --> 01:33:09,690
正在促進

2456
01:33:09,690 --> 01:33:11,880
[Music]

2457
01:33:11,880 --> 01:33:16,139
這些方法的實際使用，並且

2458
01:33:16,139 --> 01:33:18,600
存在大量

2459
01:33:18,600 --> 01:33:22,560
的概念可能性，它提出了

2460
01:33:22,560 --> 01:33:27,560


2461
01:33:27,840 --> 01:33:32,880
與其他類型的連接相關的啟發式令人興奮的用例，

2462
01:33:32,880 --> 01:33:33,480
嗯，

2463
01:33:33,480 --> 01:33:36,000
正如你之前提到的那樣

2464
01:33:36,000 --> 01:33:40,139
，Matlab 非常有可能將這些

2465
01:33:40,139 --> 01:33:43,440
類型的連接帶入 最後一英里

2466
01:33:43,440 --> 01:33:46,340
，尤其

2467
01:33:46,340 --> 01:33:50,480
是更細化或模塊化的

2468
01:33:50,480 --> 01:33:52,440
開發

2469
01:33:52,440 --> 01:33:54,960
是

2470
01:33:54,960 --> 01:33:58,800
在 t 的保護傘下 他的 SPM

2471
01:33:58,800 --> 01:34:00,840
vbx 阻止了它們

2472
01:34:00,840 --> 01:34:02,400


2473
01:34:02,400 --> 01:34:04,080


2474
01:34:04,080 --> 01:34:07,739
以真正的分佈式開放科學或去中心

2475
01:34:07,739 --> 01:34:10,080
化科學方式進行有意義的共享

2476
01:34:10,080 --> 01:34:12,060
，所以這就是為什麼我們當然

2477
01:34:12,060 --> 01:34:14,580
很高興與

2478
01:34:14,580 --> 01:34:17,460
Prime DP 合作並在其基礎上構建並更多地了解它，因為

2479
01:34:17,460 --> 01:34:20,280
這正是

2480
01:34:20,280 --> 01:34:23,639
主動推理代理

2481
01:34:23,639 --> 01:34:26,219
及其不同實現的

2482
01:34:26,219 --> 01:34:28,380
可組合性，它們將能夠以

2483
01:34:28,380 --> 01:34:30,840
大規模分佈式方式進行處理，有人可能會

2484
01:34:30,840 --> 01:34:33,000
指定一個非常有趣的矩陣，

2485
01:34:33,000 --> 01:34:34,860
其他人可能會指定一個

2486
01:34:34,860 --> 01:34:37,320
有趣的 B，其他人將把它們

2487
01:34:37,320 --> 01:34:39,300
鏈接在一起 一種新的

2488
01:34:39,300 --> 01:34:40,320
代理人，

2489
01:34:40,320 --> 01:34:42,540
其他人可以以不同的方式實現它

2490
01:34:42,540 --> 01:34:46,139
，所以它帶來了一種

2491
01:34:46,139 --> 01:34:49,139
自然而然的感覺，它分解

2492
01:34:49,139 --> 01:34:51,420
了開發這些算法的過程，

2493
01:34:51,420 --> 01:34:55,139
這些算法以前幾乎

2494
01:34:55,139 --> 01:34:57,719


2495
01:34:57,719 --> 01:35:00,000
總是完全是 Matlab

2496
01:35:00,000 --> 01:35:03,239
或和/或定制的

2497
01:35:03,239 --> 01:35:06,179
並且非常定制

2498
01:35:06,179 --> 01:35:09,300
並且適合給定的論文

2499
01:35:09,300 --> 01:35:13,320
但是 不一定沿著

2500
01:35:13,320 --> 01:35:15,840


2501
01:35:15,840 --> 01:35:18,360
人們想要用於現代

2502
01:35:18,360 --> 01:35:22,260
特別是 pythonic 設置的相關軸進行調整

2503
01:35:22,260 --> 01:35:24,480
完全我可以同意更多我的意思是，這也是一種

2504
01:35:24,480 --> 01:35:25,800
很好的思考方式，

2505
01:35:25,800 --> 01:35:28,500
就像我正在製作模塊化的靈活代碼

2506
01:35:28,500 --> 01:35:30,600
，這些代碼存在於其他包的生態系統中，

2507
01:35:30,600 --> 01:35:33,260
你本質上是在

2508
01:35:33,260 --> 01:35:35,580
分解手頭任務的集體思想

2509
01:35:35,580 --> 01:35:38,760
表示，

2510
01:35:38,760 --> 01:35:40,679
然後不同

2511
01:35:40,679 --> 01:35:42,420
可以處理該表示的某些部分，而

2512
01:35:42,420 --> 01:35:45,840
無需傳遞消息或考慮

2513
01:35:45,840 --> 01:35:47,520


2514
01:35:47,520 --> 01:35:50,159
整個分佈式工作人員網絡中發生的事情，因此

2515
01:35:50,159 --> 01:35:52,739
就像有人可以編寫自己的

2516
01:35:52,739 --> 01:35:54,239
消息傳遞算法一樣，您知道更好的消息傳遞

2517
01:35:54,239 --> 01:35:56,520
算法，然後將其插入

2518
01:35:56,520 --> 01:35:59,219
使用 pi MVP 而不必

2519
01:35:59,219 --> 01:36:01,320
了解 prime DP 的每個小方面是如何

2520
01:36:01,320 --> 01:36:04,320
工作的你知道所以是的這是一個

2521
01:36:04,320 --> 01:36:06,239
非常重要的我認為

2522
01:36:06,239 --> 01:36:08,820
關於開放科學和模塊化軟件

2523
01:36:08,820 --> 01:36:10,940
開發的事情

2524
01:36:10,940 --> 01:36:14,639
在我們的最後幾分鐘

2525
01:36:14,639 --> 01:36:17,940
當然很好 Jacob 或 Daphne 任何評論或

2526
01:36:17,940 --> 01:36:23,219
問題 還有任何開胃菜

2527
01:36:23,219 --> 01:36:26,540
人們對什麼樣的模型感到興奮

2528
01:36:26,540 --> 01:36:31,020
，或者我們在

2529
01:36:31,020 --> 01:36:33,900
以下直播中看到的可能意味著什麼 在

2530
01:36:33,900 --> 01:36:36,360
2023 年 1 月的

2531
01:36:36,360 --> 01:36:39,920
模型流 7.2 中，

2532
01:36:41,699 --> 01:36:43,320
我只想說，我

2533
01:36:43,320 --> 01:36:45,719
認為筆記本真的非常有用，

2534
01:36:45,719 --> 01:36:48,420
所以對於

2535
01:36:48,420 --> 01:36:50,100


2536
01:36:50,100 --> 01:36:52,020
那些試圖構建和建模並

2537
01:36:52,020 --> 01:36:53,580
理解

2538
01:36:53,580 --> 01:36:56,460
原生 IMDb 和我正在發生的事情的人來說，它是一個非常好的資源 認為

2539
01:36:56,460 --> 01:36:58,980


2540
01:36:58,980 --> 01:37:01,139
對那些還

2541
01:37:01,139 --> 01:37:02,360
討論

2542
01:37:02,360 --> 01:37:05,340
學習 A 和 B 矩陣的持續時間參數的筆記本進行擴展真的很酷

2543
01:37:05,340 --> 01:37:08,100
我認為

2544
01:37:08,100 --> 01:37:11,659
那真的

2545
01:37:13,320 --> 01:37:15,360
很酷非常感謝 Connor 你

2546
01:37:15,360 --> 01:37:17,219
想談談

2547
01:37:17,219 --> 01:37:19,020
即將到來，這是一個

2548
01:37:19,020 --> 01:37:20,100
非常好的觀點，這

2549
01:37:20,100 --> 01:37:22,199
是 Daniel

2550
01:37:22,199 --> 01:37:24,000
早些時候在電子郵件中也說過的，更新

2551
01:37:24,000 --> 01:37:26,639
A 和 B 就像它現在的記錄非常少

2552
01:37:26,639 --> 01:37:28,199


2553
01:37:28,199 --> 01:37:30,840
，我認為那是因為這

2554
01:37:30,840 --> 01:37:32,639
是學習生成的一種形式

2555
01:37:32,639 --> 01:37:33,960
模型

2556
01:37:33,960 --> 01:37:36,239
嗯，現在我們不這樣做，這不是

2557
01:37:36,239 --> 01:37:37,679
最複雜的方式，您仍然擁有

2558
01:37:37,679 --> 01:37:39,300
固定數量的行和列，因此您

2559
01:37:39,300 --> 01:37:41,460
可以做出一些假設，但這就像一種

2560
01:37:41,460 --> 01:37:42,960
靈活的方式，當 智能體

2561
01:37:42,960 --> 01:37:45,239
自己正在學習 b 和 a 矩陣，

2562
01:37:45,239 --> 01:37:46,679
所以

2563
01:37:46,679 --> 01:37:48,540
嗯，是的，我們絕對應該也許

2564
01:37:48,540 --> 01:37:50,280
這實際上是

2565
01:37:50,280 --> 01:37:52,260


2566
01:37:52,260 --> 01:37:54,719


2567
01:37:54,719 --> 01:37:57,300


2568
01:37:57,300 --> 01:37:59,639
在

2569
01:37:59,639 --> 01:38:01,920
一些 A 或 B 中學習並

2570
01:38:01,920 --> 01:38:03,780
展示它是如何工作的，

2571
01:38:03,780 --> 01:38:06,120
嗯，我會製作一個新的筆記本，最終將

2572
01:38:06,120 --> 01:38:08,360
它

2573
01:38:08,460 --> 01:38:12,600
用於教科書

2574
01:38:12,600 --> 01:38:15,659
和每篇論文

2575
01:38:15,659 --> 01:38:19,679
，如果能夠看到

2576
01:38:19,679 --> 01:38:21,239


2577
01:38:21,239 --> 01:38:24,719
代碼、分析表示和

2578
01:38:24,719 --> 01:38:27,900
圖形表示，那將是驚人的 和不同的

2579
01:38:27,900 --> 01:38:30,780
自然語言表示，

2580
01:38:30,780 --> 01:38:34,260
因為它們都是正式的，嗯，正式

2581
01:38:34,260 --> 01:38:37,080
連接的，它們都可以

2582
01:38:37,080 --> 01:38:40,080
這樣呈現，人們可能真的

2583
01:38:40,080 --> 01:38:42,239
希望增加

2584
01:38:42,239 --> 01:38:45,900
模型的可訪問性和嚴謹性

2585
01:38:45,900 --> 01:38:48,719
，幫助我們跨

2586
01:38:48,719 --> 01:38:51,060
不同領域進行組合和連接，歡迎和

2587
01:38:51,060 --> 01:38:52,679
認識許多不同種類的

2588
01:38:52,679 --> 01:38:55,760
學習和

2589
01:38:56,040 --> 01:38:57,840


2590
01:38:57,840 --> 01:38:59,580


2591
01:38:59,580 --> 01:39:02,540


2592
01:39:02,760 --> 01:39:05,880


2593
01:39:05,880 --> 01:39:09,060
建模 非常感謝精彩的

2594
01:39:09,060 --> 01:39:11,699
演示，我

2595
01:39:11,699 --> 01:39:14,820
對所有新興的

2596
01:39:14,820 --> 01:39:16,920
um

2597
01:39:16,920 --> 01:39:19,739
集成和用例感到非常興奮，這些集成和用例

2598
01:39:19,739 --> 01:39:22,679
無疑會湧現，我們

2599
01:39:22,679 --> 01:39:26,159
一直在，嗯，我們也開始探索 uh numpyro

2600
01:39:26,159 --> 01:39:30,300
，並討論如何

2601
01:39:30,300 --> 01:39:33,360
um 那可以 用於可擴展的主動

2602
01:39:33,360 --> 01:39:36,659
推理模型，我真的很興奮

2603
01:39:36,659 --> 01:39:40,199
primevp 將如何

2604
01:39:40,199 --> 01:39:41,540


2605
01:39:41,540 --> 01:39:44,420
與所有這些不同的集成進行互操作，使用

2606
01:39:44,420 --> 01:39:49,219
它會非常

2607
01:39:50,580 --> 01:39:54,320
令人興奮，

2608
01:39:56,159 --> 01:39:58,940
謝謝

2609
01:39:58,980 --> 01:40:03,239
Connor 任何倒數第二個詞，

2610
01:40:03,239 --> 01:40:05,820
我想也許只是

2611
01:40:05,820 --> 01:40:09,060
本著什麼精神 你是說我可以展示

2612
01:40:09,060 --> 01:40:11,699


2613
01:40:11,699 --> 01:40:14,340
下一次我們可以完成的事情的框架哦，太好了，我們看到了，

2614
01:40:14,340 --> 01:40:16,860
嗯，是的，好吧，它看起來

2615
01:40:16,860 --> 01:40:18,480
很棒，看起來很棒

2616
01:40:18,480 --> 01:40:20,760
所以

2617
01:40:20,760 --> 01:40:22,920
是的，基本上這是一個合作筆記本，

2618
01:40:22,920 --> 01:40:26,280
所以我鼓勵任何人去 到

2619
01:40:26,280 --> 01:40:28,380
um Pine DP 教程網站，

2620
01:40:28,380 --> 01:40:30,179
像 Daphne 這樣的每個筆記本都說

2621
01:40:30,179 --> 01:40:32,699
他們有他們的 I'm pretty useful and

2622
01:40:32,699 --> 01:40:34,860
they have collab links associated with

2623
01:40:34,860 --> 01:40:36,239
them

2624
01:40:36,239 --> 01:40:38,040
um and you can just open the link and

2625
01:40:38,040 --> 01:40:41,520
then ex 探索這個我認為是

2626
01:40:41,520 --> 01:40:43,139
代理

2627
01:40:43,139 --> 01:40:46,500
API 的一部分是的這是同一個除了我

2628
01:40:46,500 --> 01:40:48,060
最近在

2629
01:40:48,060 --> 01:40:49,679
計算精神病學課程上展示了這個所以我

2630
01:40:49,679 --> 01:40:51,060
更新了一點

2631
01:40:51,060 --> 01:40:53,340
所以我可以和

2632
01:40:53,340 --> 01:40:55,980
你丹尼爾分享這個然後你可以 要么

2633
01:40:55,980 --> 01:40:58,080
放在 Discord 上，要么放在這個

2634
01:40:58,080 --> 01:40:59,460
稍微更新一點的地方，但

2635
01:40:59,460 --> 01:41:01,739
這裡的基本內容仍然

2636
01:41:01,739 --> 01:41:03,900
存在，您可以在此處訪問，仍然會

2637
01:41:03,900 --> 01:41:04,980
顯示相同的內容，

2638
01:41:04,980 --> 01:41:07,560
但無論如何，問題是您只需

2639
01:41:07,560 --> 01:41:09,179
打開協作，您需要一個 Google 帳戶

2640
01:41:09,179 --> 01:41:12,060
這是使用這些的一個限制，

2641
01:41:12,060 --> 01:41:14,820
嗯，你可以在本地安裝基礎設施

2642
01:41:14,820 --> 01:41:17,219
Dash piondp

2643
01:41:17,219 --> 01:41:19,980
uh import numpy matplotlib 這裡只有

2644
01:41:19,980 --> 01:41:22,080
一些進口，然後這整個

2645
01:41:22,080 --> 01:41:23,880
這本筆記本的精神

2646
01:41:23,880 --> 01:41:25,380
基本上只是通過

2647
01:41:25,380 --> 01:41:27,480
設置生成模型的所有步驟

2648
01:41:27,480 --> 01:41:29,820
所以 創建你的隱藏狀態因子

2649
01:41:29,820 --> 01:41:31,020
，這是我們沒有真正討論的

2650
01:41:31,020 --> 01:41:33,360
事情，是在

2651
01:41:33,360 --> 01:41:35,460
Pi mdp 的上下文中分解表示，

2652
01:41:35,460 --> 01:41:36,480


2653
01:41:36,480 --> 01:41:40,139
構建 B 數組，它

2654
01:41:40,139 --> 01:41:41,940
不僅有

2655
01:41:41,940 --> 01:41:43,679
um 就像你可以 ju  st 自己做，但

2656
01:41:43,679 --> 01:41:45,060
也有這些隱藏的單元格，其中包含

2657
01:41:45,060 --> 01:41:47,580
對這些事情的解決方案，

2658
01:41:47,580 --> 01:41:49,139
然後在運行主動推理之前，本筆記本的主要衝擊

2659
01:41:49,139 --> 01:41:51,119
只是單

2660
01:41:51,119 --> 01:41:52,800
步執行並實際

2661
01:41:52,800 --> 01:41:54,480
初始化

2662
01:41:54,480 --> 01:41:58,320
um a b c 和 d 數組的條目

2663
01:41:58,320 --> 01:42:00,659
，下次我有 一些幻燈片

2664
01:42:00,659 --> 01:42:02,040
與此一起進行所以我們基本上可以

2665
01:42:02,040 --> 01:42:03,840
在幻燈片

2666
01:42:03,840 --> 01:42:06,360
和實際代碼之間切換

2667
01:42:06,360 --> 01:42:08,699
與數組相同的東西所以你喜歡

2668
01:42:08,699 --> 01:42:11,520
有一些表示你

2669
01:42:11,520 --> 01:42:13,440
想要的矩陣看起來像什麼然後

2670
01:42:13,440 --> 01:42:15,119
你進入代碼和 實際上構建

2671
01:42:15,119 --> 01:42:17,460
它，然後依次為生成模型的每個組件執行此操作，

2672
01:42:17,460 --> 01:42:19,020


2673
01:42:19,020 --> 01:42:20,820


2674
01:42:20,820 --> 01:42:21,540
嗯

2675
01:42:21,540 --> 01:42:23,460
，你正在沿途繪製它們，

2676
01:42:23,460 --> 01:42:25,920
這樣你就可以在構建它之後看到它的樣子

2677
01:42:25,920 --> 01:42:29,280
然後我們實際上

2678
01:42:29,280 --> 01:42:31,560
呃我們實際上實現了 在你

2679
01:42:31,560 --> 01:42:32,699
構建了通用模型之後，你

2680
01:42:32,699 --> 01:42:34,080
實際上將它插入到一個活躍的

2681
01:42:34,080 --> 01:42:35,340
推理代理中，

2682
01:42:35,340 --> 01:42:38,280
所以這第一件事就是

2683
01:42:38,280 --> 01:42:41,580
為一個通用的 um General 構建一個分解的 a 和 b

2684
01:42:41,580 --> 01:42:43,440
，我認為它只是一個 更

2685
01:42:43,440 --> 01:42:45,239
複雜的網格世界，但我們

2686
01:42:45,239 --> 01:42:47,100
實際上這是一種介紹性

2687
01:42:47,100 --> 01:42:48,600
任務，然後我們進入，我們實際上

2688
01:42:48,600 --> 01:42:50,940
為這個認知雙臂帶狀任務構建 A、B 和 C，這

2689
01:42:50,940 --> 01:42:53,219


2690
01:42:53,219 --> 01:42:55,560
基本上就像隊友一樣

2691
01:42:55,560 --> 01:42:56,460


2692
01:42:56,460 --> 01:43:00,300
，然後你構建 你知道

2693
01:43:00,300 --> 01:43:02,520
你正在寫

2694
01:43:02,520 --> 01:43:04,679
你的矩陣的所有小子矩陣，

2695
01:43:04,679 --> 01:43:06,420
這就是為什麼有這麼多單元格，就像我

2696
01:43:06,420 --> 01:43:07,739
說的那樣，這是最長的部分，

2697
01:43:07,739 --> 01:43:09,950
它實際上是在構建東西

2698
01:43:09,950 --> 01:43:10,500
[音樂]

2699
01:43:10,500 --> 01:43:11,100


2700
01:43:11,100 --> 01:43:13,619
嗯，C 向量基本上是獎勵

2701
01:43:13,619 --> 01:43:15,300
函數，它 Daphne 之前說過

2702
01:43:15,300 --> 01:43:16,800
你實際上是

2703
01:43:16,800 --> 01:43:20,100
根據相對對數概率進行編碼

2704
01:43:20,100 --> 01:43:23,040
然後最後你基本上執行

2705
01:43:23,040 --> 01:43:25,320
了我們在演示期間討論的那些步驟

2706
01:43:25,320 --> 01:43:27,980
你只需將你

2707
01:43:27,980 --> 01:43:30,360
精心生成的 A 和 B

2708
01:43:30,360 --> 01:43:32,639
插入你的

2709
01:43:32,639 --> 01:43:35,340
代理類中你希望不要太費力 生成兩個武裝

2710
01:43:35,340 --> 01:43:37,980
強盜認知到武裝強盜呃

2711
01:43:37,980 --> 01:43:39,840
環境這只是

2712
01:43:39,840 --> 01:43:42,719
關於世界如何運作的規則給定

2713
01:43:42,719 --> 01:43:45,360
代理人的行為和 th 然後你實際上

2714
01:43:45,360 --> 01:43:48,480
運行了這個主動推理循環，

2715
01:43:48,480 --> 01:43:51,900
正如我們所討論的那樣，

2716
01:43:51,900 --> 01:43:53,639
隨著時間的推移有效地運行一個循環，進行隱藏狀態

2717
01:43:53,639 --> 01:43:55,739
影響策略推理動作

2718
01:43:55,739 --> 01:43:58,440
採樣，然後逐步進入

2719
01:43:58,440 --> 01:44:00,480
環境以獲得新的觀察結果

2720
01:44:00,480 --> 01:44:02,159
，最後我只是這樣寫的

2721
01:44:02,159 --> 01:44:03,659
輔助函數，

2722
01:44:03,659 --> 01:44:05,699
基本上可以繪製出選擇和信念的歷史，

2723
01:44:05,699 --> 01:44:07,440


2724
01:44:07,440 --> 01:44:09,300
嗯，所以你在最後這

2725
01:44:09,300 --> 01:44:11,280
就像一個更有趣的實驗部分，

2726
01:44:11,280 --> 01:44:14,280
你可以弄亂

2727
01:44:14,280 --> 01:44:16,739
呃環境的參數

2728
01:44:16,739 --> 01:44:18,420
以及代理模型的參數

2729
01:44:18,420 --> 01:44:20,760
，然後開始 看看它是如何改變

2730
01:44:20,760 --> 01:44:22,260
行為的，

2731
01:44:22,260 --> 01:44:24,000
嗯，只是通過一種迭代運行的

2732
01:44:24,000 --> 01:44:25,380
主動推理模擬，並

2733
01:44:25,380 --> 01:44:28,020
繪製出所產生的選擇行為

2734
01:44:28,020 --> 01:44:29,699
和信念歷史，

2735
01:44:29,699 --> 01:44:31,320
所以這就是一般情況，這是一個小

2736
01:44:31,320 --> 01:44:33,480
預覽，我猜我們可以做什麼，我們

2737
01:44:33,480 --> 01:44:35,040
也可以在其中有一個小子模塊

2738
01:44:35,040 --> 01:44:36,780
在這裡，我們實際上是讓代理人

2739
01:44:36,780 --> 01:44:38,460
更新他們對 a 或 B 矩陣的信念，

2740
01:44:38,460 --> 01:44:42,500
這可能很酷，

2741
01:44:42,900 --> 01:44:46,260
很棒，看起來真的很令人興奮

2742
01:44:46,260 --> 01:44:49,500


2743
01:44:49,500 --> 01:44:52,800
在 SPM 教科書和實驗中的最終 SPM 筆記上，

2744
01:44:52,800 --> 01:44:54,840
有時會有這些令人難以置信的

2745
01:44:54,840 --> 01:44:59,159
灰度矩陣，它們總結

2746
01:44:59,159 --> 01:45:02,699
了 100 名參與者的多個實驗因素

2747
01:45:02,699 --> 01:45:06,900
，呃所以

2748
01:45:06,900 --> 01:45:09,360
看到

2749
01:45:09,360 --> 01:45:13,500
你如何用黑白

2750
01:45:13,500 --> 01:45:18,300
或灰度矩陣表示來展示真的很有趣

2751
01:45:18,300 --> 01:45:22,800
以及這如何

2752
01:45:22,800 --> 01:45:25,739
為我們一直在討論的其中一些主題提供視覺感受

2753
01:45:25,739 --> 01:45:27,960
，

2754
01:45:27,960 --> 01:45:30,600
當然，表示

2755
01:45:30,600 --> 01:45:33,420
形式與矩陣正式相關，但

2756
01:45:33,420 --> 01:45:36,060
有時只是說你有兩個

2757
01:45:36,060 --> 01:45:37,800
選擇，世界上有十​​個州

2758
01:45:37,800 --> 01:45:40,560
，可能性看起來 像這樣，

2759
01:45:40,560 --> 01:45:42,119
而不是像在灰度中

2760
01:45:42,119 --> 01:45:45,300
看到帶有數字的電子表格

2761
01:45:45,300 --> 01:45:49,040


2762
01:45:49,040 --> 01:45:52,560
那樣，提供了一種感覺

2763
01:45:52,560 --> 01:45:55,199
，它看起來非常好，所以它看起來

2764
01:45:55,199 --> 01:45:56,639
像一個很棒的

2765
01:45:56,639 --> 01:45:59,100
會議，我們將為 DOT Two 舉辦

2766
01:45:59,100 --> 01:46:01,260
，是的，你帶來的很有趣

2767
01:46:01,260 --> 01:46:03,360
就像我

2768
01:46:03,360 --> 01:46:05,580
一直在做的那樣，我認為這在

2769
01:46:05,580 --> 01:46:07,679
很大程度上是因為

2770
01:46:07,679 --> 01:46:10,320
我從閱讀中學到了所有這些 軟管

2771
01:46:10,320 --> 01:46:13,619
主動推理和 SPM 論文

2772
01:46:13,619 --> 01:46:15,480
嗯所以我非常只是

2773
01:46:15,480 --> 01:46:18,659
從他們那裡借用了可視化技術

2774
01:46:18,659 --> 01:46:20,400
嗯我有點認為這是理所當然的

2775
01:46:20,400 --> 01:46:22,139
但是很有趣它顯然

2776
01:46:22,139 --> 01:46:24,600
不是唯一的方法但我總是

2777
01:46:24,600 --> 01:46:25,980
發現它非常直觀 想想

2778
01:46:25,980 --> 01:46:28,560
概率，你可以給

2779
01:46:28,560 --> 01:46:30,420
它上色，因為數字

2780
01:46:30,420 --> 01:46:32,580
太具體了，它是顏色

2781
01:46:32,580 --> 01:46:34,199
，視覺方面真正喜歡的灰度，

2782
01:46:34,199 --> 01:46:35,940
只是表明這個東西

2783
01:46:35,940 --> 01:46:37,860
比這個東西更有可能

2784
01:46:37,860 --> 01:46:40,080
是的，

2785
01:46:40,080 --> 01:46:42,860
很酷，好吧，

2786
01:46:42,860 --> 01:46:46,020
達芙妮和康納 非常感謝這次

2787
01:46:46,020 --> 01:46:48,179
精彩的會議，

2788
01:46:48,179 --> 01:46:51,480
我們將在一個多月後與您見面，

2789
01:46:51,480 --> 01:46:54,000
因為第二點

2790
01:46:54,000 --> 01:46:55,560
非常感謝丹尼爾，

2791
01:46:55,560 --> 01:46:57,060
謝謝大家

2792
01:46:57,060 --> 01:46:58,260
和平

2793
01:46:58,260 --> 01:47:01,820
保重再見謝謝大家

