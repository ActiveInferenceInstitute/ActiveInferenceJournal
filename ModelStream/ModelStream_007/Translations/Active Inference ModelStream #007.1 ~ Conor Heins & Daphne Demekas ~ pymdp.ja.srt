1
00:00:02,940 --> 00:00:05,939
外国人

2
00:00:17,359 --> 00:00:20,520
これはアクティブな推論研究所

3
00:00:20,520 --> 00:00:22,400


4
00:00:22,400 --> 00:00:27,240
です 2022 年 11 月 15 日で、モデル ストリーム 7.1 にいます

5
00:00:27,240 --> 00:00:30,960
。Pi mdp について説明します。

6
00:00:30,960 --> 00:00:33,840
離散状態空間でのアクティブな推論のための python パッケージです。

7
00:00:33,840 --> 00:00:37,500
全員で挨拶し、

8
00:00:37,500 --> 00:00:41,520
Connor に渡します。 プレゼンテーションに

9
00:00:41,520 --> 00:00:43,860
続くプレゼンテーションでは

10
00:00:43,860 --> 00:00:46,920
、ディスカッションを行います Pi mdp スクリプトを調べます

11
00:00:46,920 --> 00:00:49,140


12
00:00:49,140 --> 00:00:52,500
ライブ チャットで出てくる質問をすべて受け付け

13
00:00:52,500 --> 00:00:54,660
ます 今日参加してくれた著者

14
00:00:54,660 --> 00:00:57,180
と Jacob に感謝します

15
00:00:57,180 --> 00:01:00,360
私はダニエルです。私はカリフォルニアの研究者

16
00:01:00,360 --> 00:01:02,399
です

17
00:01:02,399 --> 00:01:05,220
。pi mdp についてもう少し学び、

18
00:01:05,220 --> 00:01:07,560
アクティブな推論がどのように適用されるかを確認することに本当に興奮してい

19
00:01:07,560 --> 00:01:11,460
ます。皆さん、

20
00:01:11,460 --> 00:01:14,220
こんにちは、私はヤクブです。 英国の学生で

21
00:01:14,220 --> 00:01:18,020
、

22
00:01:18,020 --> 00:01:22,200
親のことをもっと聞いて、最近の

23
00:01:22,200 --> 00:01:25,320
開発と将来の開発計画について話し合うことに非常に興奮して

24
00:01:25,320 --> 00:01:30,500
います。ダフネに渡します。こんにちは、

25
00:01:30,500 --> 00:01:33,180


26
00:01:33,180 --> 00:01:36,659
ダフネです。ここロンドンで働いています。

27
00:01:36,659 --> 00:01:39,780
マスでコナーと一緒にやった仕事にたくさんの

28
00:01:39,780 --> 00:01:42,000
感謝を terの論文であり

29
00:01:42,000 --> 00:01:43,380
、それ以来私たちが行ってきた作業でもあります。

30
00:01:43,380 --> 00:01:44,939


31
00:01:44,939 --> 00:01:46,680
ええと、それは本当に本当に素晴らしいパッケージだと思います。

32
00:01:46,680 --> 00:01:50,159


33
00:01:50,159 --> 00:01:53,899
人々がより優れたものを使い始めてくれることを嬉しく思い

34
00:01:55,020 --> 00:01:57,540
ます。コナー

35
00:01:57,540 --> 00:02:00,360
、参加してくれてありがとう 離れ

36
00:02:00,360 --> 00:02:02,700


37
00:02:02,700 --> 00:02:05,700
てよかった 招待してくれてありがとう ええと、私たちがこれを手配してくれてうれしいです

38
00:02:05,700 --> 00:02:07,799


39
00:02:07,799 --> 00:02:10,020
ライブストリームに参加する良い機会のようです 私は今まで何度か行ってきました

40
00:02:10,020 --> 00:02:12,660
ので、戻ってくるのはいつもいいので、

41
00:02:12,660 --> 00:02:14,640
私はしません 自己紹介のスライドがある

42
00:02:14,640 --> 00:02:16,860
ので、私が誰であるかについて簡単な文章を言うだけな

43
00:02:16,860 --> 00:02:19,920
ので、私はコナーです。私はドイツ

44
00:02:19,920 --> 00:02:23,160
のプラグイン

45
00:02:23,160 --> 00:02:25,020
動物行動研究所

46
00:02:25,020 --> 00:02:28,020
とコンスタンスで生物学の博士号を取得しており、私の仕事のほとんど

47
00:02:28,020 --> 00:02:30,120
は 能動的推論と

48
00:02:30,120 --> 00:02:33,360
一種のベイジアンレンズを認知

49
00:02:33,360 --> 00:02:35,099
科学に適用すること

50
00:02:35,099 --> 00:02:37,379
と、それを動物の集団行動のような集団行動に適用する複雑なシステム

51
00:02:37,379 --> 00:02:39,959


52
00:02:39,959 --> 00:02:41,940
についてですが、今日は、

53
00:02:41,940 --> 00:02:43,620


54
00:02:43,620 --> 00:02:45,840
このPrime DPパッケージを開発している私のサイドPhDプロジェクトの1つについて話します。

55
00:02:45,840 --> 00:02:47,220
だった  アクティブな推論コミュニティの多くの人々との非常に共同的なグループの

56
00:02:47,220 --> 00:02:49,739
取り組み

57
00:02:49,739 --> 00:02:51,420


58
00:02:51,420 --> 00:02:52,200


59
00:02:52,200 --> 00:02:55,260
ええと、ええと、飛び込みましょう

60
00:02:55,260 --> 00:02:58,080
パッケージが

61
00:02:58,080 --> 00:03:00,239
実際にしばらく前に出された

62
00:03:00,239 --> 00:03:02,519
論文を見てみましょう。論文は今年初めに出ました。

63
00:03:02,519 --> 00:03:04,800


64
00:03:04,800 --> 00:03:06,599


65
00:03:06,599 --> 00:03:08,280


66
00:03:08,280 --> 00:03:09,599
論文を発表したにもかかわらず、primevp は非常に進行中の作業であることを強調することから始めたいと思います。それは間違いなく

67
00:03:09,599 --> 00:03:12,300
使用可能なスタンドアロン パッケージのようなものです。

68
00:03:12,300 --> 00:03:15,239
開発を続けなければならないことは常に山ほど

69
00:03:15,239 --> 00:03:16,440
あり、プレゼンテーションの最後に向けて

70
00:03:16,440 --> 00:03:18,000
お話しします。 私の意見では本当にエキサイティングな進行中の開発のいくつかは

71
00:03:18,000 --> 00:03:19,620


72
00:03:19,620 --> 00:03:21,959


73
00:03:21,959 --> 00:03:23,700


74
00:03:23,700 --> 00:03:26,459
、パッケージの使用法と拡張性を実際に開放します。

75
00:03:26,459 --> 00:03:27,900
ありがとうございます。

76
00:03:27,900 --> 00:03:30,360
基本的に、これはアクティブな

77
00:03:30,360 --> 00:03:33,000
推論研究所のポッドキャストまたはライブ

78
00:03:33,000 --> 00:03:35,640
ストリームであることを意味します。 動機付けに多くの時間を費やさ

79
00:03:35,640 --> 00:03:37,379
なければならないアクティブな推論ではないと思います

80
00:03:37,379 --> 00:03:40,799
が、要するに、pi MVP

81
00:03:40,799 --> 00:03:43,379
パッケージは、um を

82
00:03:43,379 --> 00:03:45,299
シミュレートし

83
00:03:45,299 --> 00:03:46,980
、アクティブな推論

84
00:03:46,980 --> 00:03:49,739
プロセスを個別に実行するための Python パッケージです。 状態空間

85
00:03:49,739 --> 00:03:51,599
と離散状態空間のケースは、非常に

86
00:03:51,599 --> 00:03:53,879
よく研究されたケースで

87
00:03:53,879 --> 00:03:55,560
あり、非常によく特徴付けられて

88
00:03:55,560 --> 00:03:57,360
おり、離散意思決定や計画などの意思決定モデルで非常に人気があり、モデル

89
00:03:57,360 --> 00:03:58,980


90
00:03:58,980 --> 00:04:01,620


91
00:04:01,620 --> 00:04:03,659
として神経科学で多くの応用が見られてい

92
00:04:03,659 --> 00:04:05,159
ます。

93
00:04:05,159 --> 00:04:07,019


94
00:04:07,019 --> 00:04:10,700
たとえば、人間や他の動物の個別の意思決定行動のようなものな

95
00:04:11,819 --> 00:04:14,580
ので、プレゼンテーションの概要を少し説明し

96
00:04:14,580 --> 00:04:17,040


97
00:04:17,040 --> 00:04:19,738
ます。最初に

98
00:04:19,738 --> 00:04:21,839
、primevp に取り組んできた人々のチームを紹介し

99
00:04:21,839 --> 00:04:23,699
ます。 しかし、

100
00:04:23,699 --> 00:04:26,699
実際の効果的なチームはそれよりもはるかに大きく

101
00:04:26,699 --> 00:04:27,840
なります。なぜなら、

102
00:04:27,840 --> 00:04:29,460


103
00:04:29,460 --> 00:04:31,020
それを開発または使用し、

104
00:04:31,020 --> 00:04:32,940
実際には論文の共著者ではなく、独自の方法で貢献している人がたくさんいるから

105
00:04:32,940 --> 00:04:34,380


106
00:04:34,380 --> 00:04:35,820
です。 パッケージの動機

107
00:04:35,820 --> 00:04:38,940


108
00:04:38,940 --> 00:04:40,680
個別の状態空間でのアクティブな推論の簡単な概要を説明し

109
00:04:40,680 --> 00:04:44,580
ますが、前述したように、

110
00:04:44,580 --> 00:04:47,340
これは Palm DP についてこの議論を行うのに非常に良い場所だと思います。

111
00:04:47,340 --> 00:04:48,960


112
00:04:48,960 --> 00:04:50,639


113
00:04:50,639 --> 00:04:53,220
アクティブな推論とは何かについてあまり深く議論する必要はないと思い

114
00:04:53,220 --> 00:04:54,720
ます。そうすれば時間を節約できるので

115
00:04:54,720 --> 00:04:58,080
、池 DP の深さについてもっと詳しく知ることができ

116
00:04:58,080 --> 00:04:59,400
ます。ええと、アクティブな推論エージェントをシミュレートする既存のアプローチについて話し

117
00:04:59,400 --> 00:05:00,960


118
00:05:00,960 --> 00:05:03,240
ます つまり、Matlab で

119
00:05:03,240 --> 00:05:05,400
SPM を使用し、

120
00:05:05,400 --> 00:05:08,400
Prime DP と SPM を比較対照し、SPM の起源に関して

121
00:05:08,400 --> 00:05:10,440
Prime DB がどこから来ているかを理解するのに役立ちます。

122
00:05:10,440 --> 00:05:12,479


123
00:05:12,479 --> 00:05:15,139
その

124
00:05:15,139 --> 00:05:17,160
ため、いくつかの機能について説明し

125
00:05:17,160 --> 00:05:18,840
ます プライム DP とその一般的な

126
00:05:18,840 --> 00:05:20,820
パッケージ構造の概要

127
00:05:20,820 --> 00:05:22,860
を説明した後、いくつかの使用

128
00:05:22,860 --> 00:05:24,660
例に飛び込み

129
00:05:24,660 --> 00:05:27,600
、シミュレートされたエージェントの動作のような出力をいくつか示し、

130
00:05:27,600 --> 00:05:29,520
それに付随するコードを

131
00:05:29,520 --> 00:05:31,440
示して、Pi mdp の一般的なフローがどのようなものかを示し

132
00:05:31,440 --> 00:05:35,400
ます。 のように見え

133
00:05:35,400 --> 00:05:36,960
、最後に、

134
00:05:36,960 --> 00:05:39,060
将来の方向性と進行中の進行中の

135
00:05:39,060 --> 00:05:42,060


136
00:05:42,060 --> 00:05:44,220


137
00:05:44,220 --> 00:05:47,400


138
00:05:47,400 --> 00:05:48,600


139
00:05:48,600 --> 00:05:50,880
ブランチについて説明します 新しいユースケースなので、私はそれ

140
00:05:50,880 --> 00:05:53,699
について本当に興奮しています

141
00:05:53,699 --> 00:05:56,300
.Danielが言っていたように、誰かがええと言い

142
00:05:56,300 --> 00:05:59,400
たいのです

143
00:05:59,400 --> 00:06:00,960
が、明確にするための質問がある場合は、

144
00:06:00,960 --> 00:06:02,759
遠慮なく私に知らせてください.

145
00:06:02,759 --> 00:06:04,199
いくつかの点にこだわることができます

146
00:06:04,199 --> 00:06:05,940


147
00:06:05,940 --> 00:06:08,639
では、チームの紹介から始めましょう。

148
00:06:08,639 --> 00:06:11,039
彼らは論文の共著者です。

149
00:06:11,039 --> 00:06:13,440
私にとっての版はバロン ミレージ

150
00:06:13,440 --> 00:06:15,900
ダフネで、今日ここにいる私たちを作りました。ええと、

151
00:06:15,900 --> 00:06:18,419
ブレナン クライン カール フリストン イアンのいとこ

152
00:06:18,419 --> 00:06:21,360
とアレクサンダー チャンスなので、カール Ian は

153
00:06:21,360 --> 00:06:24,360
私の共同博士の監督者で

154
00:06:24,360 --> 00:06:27,020
あり、ええと、Carl は

155
00:06:27,020 --> 00:06:30,660
MDP または MATLAB

156
00:06:30,660 --> 00:06:32,520
での能動的推論の離散状態空間定式化の最初

157
00:06:32,520 --> 00:06:34,080


158
00:06:34,080 --> 00:06:36,000


159
00:06:36,000 --> 00:06:38,280


160
00:06:38,280 --> 00:06:41,220
の祖先です。

161
00:06:41,220 --> 00:06:43,680


162
00:06:43,680 --> 00:06:45,840
ここにいる全員がパッケージに対していかに重要であるかを強調することが重要だ

163
00:06:45,840 --> 00:06:48,000
と思います。

164
00:06:48,000 --> 00:06:50,699
実際のソフトウェア開発のほとんどは私が行ったものではないと思い

165
00:06:50,699 --> 00:06:52,080
ますが、

166
00:06:52,080 --> 00:06:53,840
主要な DP の初期段階では

167
00:06:53,840 --> 00:06:56,639
、 ブレナンと

168
00:06:56,639 --> 00:07:00,000
アレックは 2019 年かそれ以前

169
00:07:00,000 --> 00:07:02,460
に、アクティブな推論を行う Python パッケージの必要性について

170
00:07:02,460 --> 00:07:04,680


171
00:07:04,680 --> 00:07:05,819


172
00:07:05,819 --> 00:07:07,440
話していました。おそらく他の人もその頃に同様の会話をしてい

173
00:07:07,440 --> 00:07:10,080
たと思いますが、私たちが

174
00:07:10,080 --> 00:07:11,880
集まったからこそ、

175
00:07:11,880 --> 00:07:14,699
それほど長い時間でこれを構築することができませんでした.

176
00:07:14,699 --> 00:07:16,979
つまり2年以上ということです.フルタイム

177
00:07:16,979 --> 00:07:18,660
で取り組んでいれば、おそらくもっと早くできたかもしれませんが

178
00:07:18,660 --> 00:07:21,360


179
00:07:21,360 --> 00:07:23,099
、進行状況を見るのは本当に楽しかったです.

180
00:07:23,099 --> 00:07:25,319
これについて、そしてダフネが

181
00:07:25,319 --> 00:07:27,599
言ったように、彼女は実際

182
00:07:27,599 --> 00:07:30,240


183
00:07:30,240 --> 00:07:32,520
に自分の修士

184
00:07:32,520 --> 00:07:34,380
論文だけでなく、松の束を持つマルチエージェント集団行動の

185
00:07:34,380 --> 00:07:35,880
ような非常に野心的なアプリケーションでアクティブな Pi mdp を実際に使用した最初の人の 1 人です。

186
00:07:35,880 --> 00:07:38,340


187
00:07:38,340 --> 00:07:40,380
DPエージェントは相互に対話し

188
00:07:40,380 --> 00:07:42,960
て、

189
00:07:42,960 --> 00:07:45,060
ダイナミクスとエコーチェンバー、

190
00:07:45,060 --> 00:07:46,680
ソーシャルネットワークのような意見をシミュレートします。これは本当にエキサイティングな

191
00:07:46,680 --> 00:07:49,139
ので、彼女と一緒に仕事ができて本当に嬉しかったです

192
00:07:49,139 --> 00:07:51,660


193
00:07:51,660 --> 00:07:53,400
ce また、Daphne が

194
00:07:53,400 --> 00:07:55,199
これに参加しているの

195
00:07:55,199 --> 00:07:57,960
は、pi mdp

196
00:07:57,960 --> 00:07:59,819
アクティブな推論コミュニティのパイオニアの非常に良い例のようなものだからです。また、

197
00:07:59,819 --> 00:08:02,819
Baron もええと、アレックとバロンは、非アクティブ

198
00:08:02,819 --> 00:08:04,680
なより洗練されたメッセージ パッシング テクニックのいくつかを開発するために多くの作業を行いました。

199
00:08:04,680 --> 00:08:06,360


200
00:08:06,360 --> 00:08:09,120
Pym

201
00:08:09,120 --> 00:08:11,880
DP と uh Baron での推論も

202
00:08:11,880 --> 00:08:15,120
、私が論文を書くのを助ける上で非常に重要

203
00:08:15,120 --> 00:08:16,860


204
00:08:16,860 --> 00:08:19,919


205
00:08:19,919 --> 00:08:22,020


206
00:08:22,020 --> 00:08:24,360


207
00:08:24,360 --> 00:08:27,060
でした.

208
00:08:27,060 --> 00:08:27,599


209
00:08:27,599 --> 00:08:30,240


210
00:08:30,240 --> 00:08:32,159


211
00:08:32,159 --> 00:08:35,159
ここにいる全員がよく知っている最大の理由の 1

212
00:08:35,159 --> 00:08:37,700


213
00:08:37,700 --> 00:08:40,380
つは、

214
00:08:40,380 --> 00:08:42,000
ここ 10 年間、特に過去

215
00:08:42,000 --> 00:08:43,979
5 年間で

216
00:08:43,979 --> 00:08:46,140
アクティブな推論に対する人気と関心が高まっていることです。

217
00:08:46,140 --> 00:08:48,300


218
00:08:48,300 --> 00:08:49,860
人々が実際にアクティブな推論について実際に学べるようにするための一般的なユーザーフレンドリーなフレームワークが

219
00:08:49,860 --> 00:08:52,080


220
00:08:52,080 --> 00:08:53,700
、教育的な観点から

221
00:08:53,700 --> 00:08:54,959
だけでなく、 独自の

222
00:08:54,959 --> 00:08:57,420
研究や産業用アプリケーション、またはアクティブな推論で

223
00:08:57,420 --> 00:08:59,339
実際にやりたいことは何でも適用できます。特定のコミュニティ

224
00:08:59,339 --> 00:09:02,060


225
00:09:02,100 --> 00:09:04,320


226
00:09:04,320 --> 00:09:05,880
からのアクティブな推論には、

227
00:09:05,880 --> 00:09:07,320


228
00:09:07,320 --> 00:09:08,880
神経科学だけでなく、

229
00:09:08,880 --> 00:09:10,680
機械学習、データ科学、

230
00:09:10,680 --> 00:09:12,899
エンジニアリング、ネットワーク科学、

231
00:09:12,899 --> 00:09:14,580
ソフトウェア開発などの分野で特に多くの関心が寄せられています。 ソフトウェア エンジニア

232
00:09:14,580 --> 00:09:17,820
と多くの関心のある分野

233
00:09:17,820 --> 00:09:20,700
ええと、最も支配的な言語は

234
00:09:20,700 --> 00:09:23,880
python です。私がよく

235
00:09:23,880 --> 00:09:25,200
耳にするのは、人々が能動的推論について学びに来て

236
00:09:25,200 --> 00:09:26,880


237
00:09:26,880 --> 00:09:28,500
、python や r などのバックグラウンドを持っているということです。

238
00:09:28,500 --> 00:09:29,880
そして、彼らはすべてがMatlabにあることを理解しています

239
00:09:29,880 --> 00:09:31,680
.Matlabを

240
00:09:31,680 --> 00:09:34,560


241
00:09:34,560 --> 00:09:37,740
知らないか、Matlabコードを解析するのに苦労しているため、

242
00:09:37,740 --> 00:09:39,959
特に

243
00:09:39,959 --> 00:09:42,540
非配列プログラミングフレームワークから来ている場合は、参入障壁のようなものがあります

244
00:09:42,540 --> 00:09:44,339
彼らは

245
00:09:44,339 --> 00:09:47,459
JavaScript か何かを使用するフロントエンド Web 開発者で

246
00:09:47,459 --> 00:09:48,899
あり、

247
00:09:48,899 --> 00:09:50,220
実際には大きな多次元のようなものに慣れていません。

248
00:09:50,220 --> 00:09:52,920
配列

249
00:09:52,920 --> 00:09:55,200
プログラミングええと、それがアクティブな推論を行う Python パッケージを具体的に作成するもう 1 つの動機でした。

250
00:09:55,200 --> 00:09:57,180


251
00:09:57,180 --> 00:10:01,019


252
00:10:01,019 --> 00:10:03,720
最後に、それは

253
00:10:03,720 --> 00:10:06,360
Python であるため

254
00:10:06,360 --> 00:10:08,940
、他のエコシステムと通信できるエコシステムを作成していることを意味します。

255
00:10:08,940 --> 00:10:12,060
理想的には、primevp

256
00:10:12,060 --> 00:10:14,459
は行われません

257
00:10:14,459 --> 00:10:16,860
Pi mdpのみを使用するスクリプトで使用するだけで

258
00:10:16,860 --> 00:10:19,500


259
00:10:19,500 --> 00:10:20,760
、人工

260
00:10:20,760 --> 00:10:23,040
知能やネットワーク科学、または

261
00:10:23,040 --> 00:10:24,420
関連するあらゆる種類のフレームワークに関係する他のソフトウェアパッケージで使用されるため、

262
00:10:24,420 --> 00:10:26,640
プラグアンドプレイのようなものにすることができます

263
00:10:26,640 --> 00:10:29,220
piondp エージェントで遊んで、たとえば強化学習用のオープン AI ジムのような環境にそれらを配置します。これで

264
00:10:29,220 --> 00:10:31,080


265
00:10:31,080 --> 00:10:33,000


266
00:10:33,000 --> 00:10:36,600


267
00:10:36,600 --> 00:10:39,000
、さまざまなアプリケーションでアクティブな推論を使用できるようになりまし

268
00:10:39,000 --> 00:10:40,380
た。これは Python にとって本当に素晴らしいことです。なぜなら

269
00:10:40,380 --> 00:10:43,019
、設計による Python とそのコミュニティ

270
00:10:43,019 --> 00:10:44,579
主導の開発によるものだからです。 いくつかの特定のもののため

271
00:10:44,579 --> 00:10:46,860
に非常にうまく構築された多くの異なるパッケージ

272
00:10:46,860 --> 00:10:49,140


273
00:10:49,140 --> 00:10:51,540
なので、Pythonになったので、タンデムで使用できます

274
00:10:51,540 --> 00:10:54,240
w 他のすべての

275
00:10:54,240 --> 00:10:57,079
pythonパッケージは

276
00:10:58,079 --> 00:11:00,480
大丈夫なので、アクティブ推論の簡単な紹介です。アクティブ

277
00:11:00,480 --> 00:11:02,519
推論の基本的な

278
00:11:02,519 --> 00:11:05,640
パラダイムは

279
00:11:05,640 --> 00:11:07,500
、エージェントがその環境に埋め込まれていると見なすことであり、

280
00:11:07,500 --> 00:11:08,700


281
00:11:08,700 --> 00:11:11,519


282
00:11:11,519 --> 00:11:15,540
知覚と行動に対する従来のより受動的なアプローチとは異なり

283
00:11:15,540 --> 00:11:18,540
ます

284
00:11:18,540 --> 00:11:20,880
環境があなたに情報を与えると考えて

285
00:11:20,880 --> 00:11:22,560
ください 感覚運動

286
00:11:22,560 --> 00:11:24,300
変換を行ってから行動を実行し

287
00:11:24,300 --> 00:11:26,279
ます 活発な乳児

288
00:11:26,279 --> 00:11:28,980
ええと、推論または

289
00:11:28,980 --> 00:11:31,320
不確実性に対処する問題が

290
00:11:31,320 --> 00:11:33,959
、知覚または私

291
00:11:33,959 --> 00:11:36,000
たちが状態推定または信念

292
00:11:36,000 --> 00:11:38,519
更新のように呼ぶものの両方を特徴付けるという事実を非常に強調します

293
00:11:38,519 --> 00:11:40,500
アクティブな推論部分が作用

294
00:11:40,500 --> 00:11:42,300
するアクションとして、エージェントは世界

295
00:11:42,300 --> 00:11:44,640
の状態についての信念を更新するだけでなく、

296
00:11:44,640 --> 00:11:46,320


297
00:11:46,320 --> 00:11:50,700


298
00:11:50,700 --> 00:11:52,620
自由エネルギーと呼ばれる驚きに縛られ

299
00:11:52,620 --> 00:11:55,380
たこの um を最小限に抑えることによって、そこに隠された状態を更新します。

300
00:11:55,380 --> 00:11:58,500
推論としての知覚のアイデアから

301
00:11:58,500 --> 00:12:01,920
来るだけでなく、驚き

302
00:12:01,920 --> 00:12:05,279
や また、驚きに基づいて行動を選択する

303
00:12:05,279 --> 00:12:09,120
ため、行動

304
00:12:09,120 --> 00:12:11,459
の推論は別の種類の推論

305
00:12:11,459 --> 00:12:13,740
問題になるため、ポリシーまたは一連の

306
00:12:13,740 --> 00:12:15,839
行動は潜在変数

307
00:12:15,839 --> 00:12:18,120
または隠れた状態

308
00:12:18,120 --> 00:12:21,000
と見なされ、それらについても推論

309
00:12:21,000 --> 00:12:22,980
を行い、知覚行動コインの両側をキャストすることによって

310
00:12:22,980 --> 00:12:25,200
驚きの最小化の例として、

311
00:12:25,200 --> 00:12:27,899
イベントは

312
00:12:27,899 --> 00:12:29,120


313
00:12:29,120 --> 00:12:32,940
意図的で好奇心旺盛な行動を示すエージェントで

314
00:12:32,940 --> 00:12:35,519
あり、

315
00:12:35,519 --> 00:12:37,320
アクティブな推論については何もないように見えます。つまり、

316
00:12:37,320 --> 00:12:39,660
離散状態空間またはジェネレーティブの

317
00:12:39,660 --> 00:12:42,720
特定のタイプまたはクラスの 1 つにすぎない Pi MVP を使用する必要があることを意味します。

318
00:12:42,720 --> 00:12:44,519
アクティブな推論のためのモデルです

319
00:12:44,519 --> 00:12:45,600


320
00:12:45,600 --> 00:12:49,320
が、ええと、Palm DP の離散状態

321
00:12:49,320 --> 00:12:51,720
空間生成モデルは

322
00:12:51,720 --> 00:12:53,279
、アクティブな保険を扱うのが本当に簡単です。

323
00:12:53,279 --> 00:12:54,899
なぜなら、ここで示しているこれらの量の多くは

324
00:12:54,899 --> 00:12:57,600


325
00:12:57,600 --> 00:12:59,040
、パーム DPS を扱っているときに計算するのが非常に簡単だからです。

326
00:12:59,040 --> 00:13:00,660
または部分的にマークアップの

327
00:13:00,660 --> 00:13:02,820
決定プロセスを観察したので、すべて

328
00:13:02,820 --> 00:13:04,800
の数学について少し説明しますが、

329
00:13:04,800 --> 00:13:06,600
これは、アクティブな推論エージェントと環境の基本的なパラダイムにすぎません。

330
00:13:06,600 --> 00:13:08,820


331
00:13:08,820 --> 00:13:11,100
驚きを最小限に抑えることで、知覚と行動の両方を行う驚きを最小限に抑えようとしてい

332
00:13:11,100 --> 00:13:13,440


333
00:13:13,440 --> 00:13:15,600


334
00:13:15,600 --> 00:13:17,100


335
00:13:17,100 --> 00:13:20,040


336
00:13:20,040 --> 00:13:22,079
ます。アクティブな推論

337
00:13:22,079 --> 00:13:24,660
と離散状態空間のより詳細な数学的レビュー、つまり

338
00:13:24,660 --> 00:13:26,399
これらの部分的に観察されたマルコフ決定プロセスを使用するだけ

339
00:13:26,399 --> 00:13:28,860
です。

340
00:13:28,860 --> 00:13:31,620


341
00:13:31,620 --> 00:13:34,440
ランス・トーマス・ヌール・セバスチャン・ヴィクトリータとカールによるジャーナル・オブ・メディカル・サイコロジーの優れたこの論文を読む

342
00:13:34,440 --> 00:13:38,040


343
00:13:38,040 --> 00:13:40,680
ことをお勧めします。これは、最も似た形式から始まるアクティブな推論

344
00:13:40,680 --> 00:13:42,899
の更新方程式に到達する方法の形式的な基礎からの本当に素晴らしい説明です。

345
00:13:42,899 --> 00:13:44,459


346
00:13:44,459 --> 00:13:46,440


347
00:13:46,440 --> 00:13:48,660
カテゴリカル分布とディリクレ分布の処理、

348
00:13:48,660 --> 00:13:50,639


349
00:13:50,639 --> 00:13:53,040
およびパイン DP 論文の

350
00:13:53,040 --> 00:13:55,380
アーカイブにあるバージョンには

351
00:13:55,380 --> 00:13:58,079
、このような種類の数学の多くを行う付録がたくさんある

352
00:13:58,079 --> 00:14:00,779
ので、

353
00:14:00,779 --> 00:14:02,720
人々にそれを参照すること

354
00:14:02,720 --> 00:14:05,220
もできます。

355
00:14:05,220 --> 00:14:06,899


356
00:14:06,899 --> 00:14:10,440
Pym DP のエージェントの頭脳のパンとバターを形成するモデルは、

357
00:14:10,440 --> 00:14:13,139
本質的にセント

358
00:14:13,139 --> 00:14:14,760


359
00:14:14,760 --> 00:14:16,800


360
00:14:16,800 --> 00:14:19,139
エージェントがその世界がどのように機能すると信じているかの仕様に過ぎない生成モデルを

361
00:14:19,139 --> 00:14:21,180
書き留めるアクティブな推論に加えて

362
00:14:21,180 --> 00:14:22,980
、環境が

363
00:14:22,980 --> 00:14:24,839
どのように機能するか、環境が世界

364
00:14:24,839 --> 00:14:27,540
のダイナミクスのように自分自身に影響を与えるとどのように信じる

365
00:14:27,540 --> 00:14:29,639
か、そして隠されたものはどのように進行するか

366
00:14:29,639 --> 00:14:31,920
状態ダイナミクスはまた、

367
00:14:31,920 --> 00:14:34,139


368
00:14:34,139 --> 00:14:36,240
私たちが生成モデルまたは世界モデルと呼ぶものにすべてエンコードされた観察を生じさせ

369
00:14:36,240 --> 00:14:38,519
ます

370
00:14:38,519 --> 00:14:39,839


371
00:14:39,839 --> 00:14:43,199
.Pine DPでは、

372
00:14:43,199 --> 00:14:44,820


373
00:14:44,820 --> 00:14:45,959
これらの部分的に観察された

374
00:14:45,959 --> 00:14:48,600
マルコフ決定プロセスと呼ばれる非常に特定の種類のモデルの性別のみを扱います. したがって、これらは不確実性の下

375
00:14:48,600 --> 00:14:50,279
での逐次的な意思決定と計画の古典的なモデルであり

376
00:14:50,279 --> 00:14:52,380


377
00:14:52,380 --> 00:14:54,180
、アクティブな推論に固有のものではありません。

378
00:14:54,180 --> 00:14:57,480
人々は、古典的な

379
00:14:57,480 --> 00:14:59,160
強化学習やあらゆる種類の

380
00:14:59,160 --> 00:15:01,620
意思決定の問題に

381
00:15:01,620 --> 00:15:03,480
Palm DP モデルを使用します。

382
00:15:03,480 --> 00:15:05,279


383
00:15:05,279 --> 00:15:07,440
現時点

384
00:15:07,440 --> 00:15:09,060
での状態は、前回の状態でのアクションにのみ依存する

385
00:15:09,060 --> 00:15:10,740
ため、それが定義です マルコフ

386
00:15:10,740 --> 00:15:12,420
プロセスでは、このような浅い

387
00:15:12,420 --> 00:15:14,339
時間的依存性

388
00:15:14,339 --> 00:15:15,800
があります。たとえば、非マルコフ

389
00:15:15,800 --> 00:15:18,120
プロセスには、過去にさかのぼる

390
00:15:18,120 --> 00:15:20,279
長期的またはより深い時間的

391
00:15:20,279 --> 00:15:21,899
依存性を持つプロセスはありません

392
00:15:21,899 --> 00:15:23,579


393
00:15:23,579 --> 00:15:25,680
。Palm DPS は多くの場合、 しかし、常に

394
00:15:25,680 --> 00:15:27,720
離散状態空間と離散時間を定式化するとは限りませ

395
00:15:27,720 --> 00:15:29,940
ん

396
00:15:29,940 --> 00:15:32,760
。palmdp という言葉には、それらが

397
00:15:32,760 --> 00:15:35,160
これらの多項分布またはカテゴリ

398
00:15:35,160 --> 00:15:37,500
分布でなければならないことを意味するものは何もありませんが、

399
00:15:37,500 --> 00:15:39,240
Palm DPS とアクティブな影響

400
00:15:39,240 --> 00:15:40,980
について話すときは、ほとんどの場合、これらの離散分布について話しています。

401
00:15:40,980 --> 00:15:43,760


402
00:15:43,800 --> 00:15:45,899
基本的

403
00:15:45,899 --> 00:15:47,940
に、一度に K 個の離散状態の 1 つにしか入ることができず、次回は K 個の離散

404
00:15:47,940 --> 00:15:50,279
状態の 1 つにしか進むことができない

405
00:15:50,279 --> 00:15:52,260
ため、

406
00:15:52,260 --> 00:15:53,699
すべてが離散的ですが

407
00:15:53,699 --> 00:15:55,920
、これらのマルコフ決定プロセスには本質的に離散的でなければならないものは何もありませ

408
00:15:55,920 --> 00:15:57,240


409
00:15:57,240 --> 00:15:59,040
ん。 それは言及する価値があると思います。

410
00:15:59,040 --> 00:16:00,420
なぜなら、

411
00:16:00,420 --> 00:16:02,820
それは人々

412
00:16:02,820 --> 00:16:04,139
が Palm DP という言葉を見たときによく作る重要な種類の混同だからです。

413
00:16:04,139 --> 00:16:05,699


414
00:16:05,699 --> 00:16:08,279
この

415
00:16:08,279 --> 00:16:11,040
個別の Palm DP 生成モデルを

416
00:16:11,040 --> 00:16:12,899
アクティブな推論に使用することにした理由は

417
00:16:12,899 --> 00:16:15,899
、逐次的な意思決定と計画への適用

418
00:16:15,899 --> 00:16:18,060
のためだけでなく

419
00:16:18,060 --> 00:16:20,339


420
00:16:20,339 --> 00:16:24,240
、2010 年から 2011 年にかけて

421
00:16:24,240 --> 00:16:26,760
、pom DPS を

422
00:16:26,760 --> 00:16:28,079
意思決定テストのための生成モデルであり

423
00:16:28,079 --> 00:16:30,540


424
00:16:30,540 --> 00:16:32,699
、これらのモデルでアクティブな推論を行うためのすべての数学はすでに行われているため、実際にこれをコード化するために

425
00:16:32,699 --> 00:16:34,860
新しい数学や理論を発明する必要はありません

426
00:16:34,860 --> 00:16:36,720


427
00:16:36,720 --> 00:16:38,339


428
00:16:38,339 --> 00:16:41,040
でした。  10年くらい経ったので、

429
00:16:41,040 --> 00:16:44,100
私たちの生活は楽になりました.それを開発するとき

430
00:16:44,100 --> 00:16:46,320


431
00:16:46,320 --> 00:16:48,899
は、これらのPalm DPSの主要なコンポーネントだけに飛び込みましょう.

432
00:16:48,899 --> 00:16:51,480
あー、ここでは4つの主要なものだけをリストしてい

433
00:16:51,480 --> 00:16:54,360
ますが

434
00:16:54,360 --> 00:16:55,980
、誰かが

435
00:16:55,980 --> 00:16:58,560
興味を持っているなら議論できる他のコンポーネントがあります. 本質的に、この

436
00:16:58,560 --> 00:17:01,199
一番上の行は

437
00:17:01,199 --> 00:17:02,820


438
00:17:02,820 --> 00:17:05,099


439
00:17:05,099 --> 00:17:08,640
、Into the Fut の隠れ状態 s と観測 o の結合分布に関する生成モデルの記述です。 この生成モデル

440
00:17:08,640 --> 00:17:11,939
のマルコフ的性質のために、

441
00:17:11,939 --> 00:17:13,500


442
00:17:13,500 --> 00:17:15,000


443
00:17:15,000 --> 00:17:16,619
この

444
00:17:16,619 --> 00:17:20,339
因数分解された基本的な事前

445
00:17:20,339 --> 00:17:22,559
確率と、時間をかけて因数分解する尤度の

446
00:17:22,559 --> 00:17:24,179


447
00:17:24,179 --> 00:17:25,740
積を使用した結合分布と書くことができます。

448
00:17:25,740 --> 00:17:27,839


449
00:17:27,839 --> 00:17:29,640
今すぐ数学を理解することは重要ではありませんが、すぐ

450
00:17:29,640 --> 00:17:31,440
に図式にマッピングする主

451
00:17:31,440 --> 00:17:34,320
なコンポーネントは、エージェントの

452
00:17:34,320 --> 00:17:36,360
信念であり、隠れた状態がどのように

453
00:17:36,360 --> 00:17:38,940
観察を引き起こすかについて

454
00:17:38,940 --> 00:17:40,440
、観察モデルまたは尤度マッピングと呼ばれるものにエンコードします

455
00:17:40,440 --> 00:17:42,539


456
00:17:42,539 --> 00:17:45,360
a 行列または a 配列と呼ばれることが多いため、これは

457
00:17:45,360 --> 00:17:47,820


458
00:17:47,820 --> 00:17:50,460
現在の時点での隠れた状態がどのように現在の時点で

459
00:17:50,460 --> 00:17:52,559
観測に影響を与えるか、または発生させる

460
00:17:52,559 --> 00:17:54,000


461
00:17:54,000 --> 00:17:56,340


462
00:17:56,340 --> 00:17:58,860
かを確率論的に表したものです。

463
00:17:58,860 --> 00:18:02,039
ある

464
00:18:02,039 --> 00:18:03,960


465
00:18:03,960 --> 00:18:05,640
時点での隠れた状態が次回の隠れた状態とどのように関連するかについてのエージェントの

466
00:18:05,640 --> 00:18:08,100


467
00:18:08,100 --> 00:18:09,960
信念。つまり、このマップは、エージェントが使用するものです。

468
00:18:09,960 --> 00:18:12,539


469
00:18:12,539 --> 00:18:14,940
これが起こった場合、またはそれが起こった場合に世界がどのように進化するかについて前向き

470
00:18:14,940 --> 00:18:17,100
な予測を行うことと、世界がどのように進化するか

471
00:18:17,100 --> 00:18:19,080


472
00:18:19,080 --> 00:18:22,080


473
00:18:22,080 --> 00:18:24,720
についての私の信念が今どこに与えられなければならないかを考えると、過去からの一種のメッセージまたは経験的事前情報を運ぶこと

474
00:18:24,720 --> 00:18:26,400
場合

475
00:18:26,400 --> 00:18:28,860
によっては、すべてが B 配列または B マトリックスにエンコードされ、

476
00:18:28,860 --> 00:18:31,679
これらの最後の 2 つは一種

477
00:18:31,679 --> 00:18:33,600
の事前確率

478
00:18:33,600 --> 00:18:35,700
であり、その最初のものは非常に重要

479
00:18:35,700 --> 00:18:38,880
であり、C 配列または C ベクトルと呼ばれ、

480
00:18:38,880 --> 00:18:41,340


481
00:18:41,340 --> 00:18:43,679
どの観測が

482
00:18:43,679 --> 00:18:46,260
可能性が高いかについてのエージェントの以前の信念をエンコードします 最初に述べたように

483
00:18:46,260 --> 00:18:47,520
、能動的推論

484
00:18:47,520 --> 00:18:49,980
は行動と知覚の両方

485
00:18:49,980 --> 00:18:51,660
を推論問題として投げかける

486
00:18:51,660 --> 00:18:54,900
ことであり、フレームワークとしての能動的推論

487
00:18:54,900 --> 00:18:56,880


488
00:18:56,880 --> 00:18:58,500


489
00:18:58,500 --> 00:19:00,480
は、報酬の代わりに言うことによって、報酬関数と強化学習の古典的なパラダイムをひっくり返すようなものです。

490
00:19:00,480 --> 00:19:02,700
関数は、エージェント

491
00:19:02,700 --> 00:19:04,559
に、

492
00:19:04,559 --> 00:19:07,140
将来この種のデータが表示されるという一種の楽観的な信念

493
00:19:07,140 --> 00:19:09,120
を与え、resp で推論を実行するだけです。

494
00:19:09,120 --> 00:19:10,980


495
00:19:10,980 --> 00:19:13,200
エージェントは、事前の信念に

496
00:19:13,200 --> 00:19:14,820


497
00:19:14,820 --> 00:19:16,919
一致する観測を探しているように

498
00:19:16,919 --> 00:19:19,140
見えるので、これは、

499
00:19:19,140 --> 00:19:21,419
能動的推論は

500
00:19:21,419 --> 00:19:23,340
エージェントが信じている予言を自己実現するプロセスであるというこの考えと一致しています。

501
00:19:23,340 --> 00:19:25,919
m 多かれ少なかれ

502
00:19:25,919 --> 00:19:27,840
特定の観測を目にする可能性が高く、その後、

503
00:19:27,840 --> 00:19:30,780


504
00:19:30,780 --> 00:19:32,580
生成モデルにそのような偏りのあるポリシーについて推論を行うことにより、エージェントは

505
00:19:32,580 --> 00:19:34,740
、実際に

506
00:19:34,740 --> 00:19:37,799
以前の好みまたはこれらの Pro

507
00:19:37,799 --> 00:19:40,020
観測に関するこれらの以前

508
00:19:40,020 --> 00:19:42,660
の信念を実際に実現するようになります。  Cベクトル

509
00:19:42,660 --> 00:19:44,880
とCベクトルは、基本的に

510
00:19:44,880 --> 00:19:48,000


511
00:19:48,000 --> 00:19:49,340
報酬関数のベイジアン変換と考えることができ、実際

512
00:19:49,340 --> 00:19:51,600
にはCベクトルのエントリを

513
00:19:51,600 --> 00:19:53,220
2つの報酬と強化

514
00:19:53,220 --> 00:19:55,080
学習に正確に関連付けることができますが、それについて説明する必要はありませ

515
00:19:55,080 --> 00:19:57,000
ん 今では、誰かが興味を持っている場合は論文を共有することができます.

516
00:19:57,000 --> 00:20:00,000
そして最後

517
00:20:00,000 --> 00:20:01,919
に、隠された状態に対する

518
00:20:01,919 --> 00:20:04,200


519
00:20:04,200 --> 00:20:07,559
事前確率があり、これは単に事前確率が何であるかについてのエージェントの信念です. シミュレーション

520
00:20:07,559 --> 00:20:09,539
の最初の時間ステップでの各隠れ状態のケリフッドな

521
00:20:09,539 --> 00:20:11,820
ので、これ

522
00:20:11,820 --> 00:20:14,160
はアクティブな推論では実際には必要なことではありませんが、

523
00:20:14,160 --> 00:20:15,900


524
00:20:15,900 --> 00:20:18,299
エージェントをシミュレートするときは

525
00:20:18,299 --> 00:20:20,039
、開始時間と終了時間で有限の時間的ホライズンを使用することがよくあります。

526
00:20:20,039 --> 00:20:23,280
したがって、

527
00:20:23,280 --> 00:20:25,200
有限の一時的な地平線のようなものがある

528
00:20:25,200 --> 00:20:27,240
場合、基本的に、タイムステップ 1 で

529
00:20:27,240 --> 00:20:29,100
世界がどのように見えるかについての事前の信念をプラグインする必要が

530
00:20:29,100 --> 00:20:31,740
あり、その事前の信念

531
00:20:31,740 --> 00:20:34,940
はこの d d ベクトルにエンコードされ、

532
00:20:34,940 --> 00:20:38,460
直感的にスケッチすることができます。

533
00:20:38,460 --> 00:20:41,039


534
00:20:41,039 --> 00:20:43,799
ベイジアン グラフとしての Palm DP 生成モデル。ノードが

535
00:20:43,799 --> 00:20:45,720
互いに依存している場合、これらの矢印によってノードがエッジで接続さ

536
00:20:45,720 --> 00:20:47,280
れているため、これらの赤いノード

537
00:20:47,280 --> 00:20:48,660
は、

538
00:20:48,660 --> 00:20:51,720
時間の経過とともに相互に遷移する隠れた状態を

539
00:20:51,720 --> 00:20:53,700
表し、青いノードは、O ノード

540
00:20:53,700 --> 00:20:56,340
がエージェントの信念を表します。

541
00:20:56,340 --> 00:20:58,320
これらの隠れた状態から観察がどのように生成されるかについて

542
00:20:58,320 --> 00:21:00,299


543
00:21:00,299 --> 00:21:02,760
、これは Palm DP の単なるグラフィカル表現であり、

544
00:21:02,760 --> 00:21:05,580


545
00:21:05,580 --> 00:21:07,020
これらがどのように再現されるかについてのエージェントの信念について述べたように、行列はエンコードされます。  d

546
00:21:07,020 --> 00:21:09,120
ノードはいつでも青いノードを生成する

547
00:21:09,120 --> 00:21:11,280
ため、通常、この a 行列は時不変であると想定している

548
00:21:11,280 --> 00:21:13,740
ため

549
00:21:13,740 --> 00:21:15,539
、この観測マッピング

550
00:21:15,539 --> 00:21:18,120
自体は、少なくともほとんどの Palm DPS で作成された仮定の時間に依存しないと考えられています。

551
00:21:18,120 --> 00:21:19,980


552
00:21:19,980 --> 00:21:21,840


553
00:21:21,840 --> 00:21:25,860
また

554
00:21:25,860 --> 00:21:27,299


555
00:21:27,299 --> 00:21:30,179
、世界の遷移ダイナミクスがどの

556
00:21:30,179 --> 00:21:32,940
ように状態をもたらすかについてのエージェントの時間不変の信念もあります 時間 T マイナス 1

557
00:21:32,940 --> 00:21:35,159
時間 t で 2 つの状態

558
00:21:35,159 --> 00:21:38,280
その後、制御された遷移としてアクションをフレーミングすることにより、ポリシーの選択またはアクション

559
00:21:38,280 --> 00:21:41,760
が非アクティブな推論で機能する

560
00:21:41,760 --> 00:21:43,559


561
00:21:43,559 --> 00:21:46,980
ため、B マトリックスは

562
00:21:46,980 --> 00:21:49,020
、

563
00:21:49,020 --> 00:21:50,520


564
00:21:50,520 --> 00:21:52,919
昨日がどうだったかを考えると、世界が今どのように見えるべきかを言うだけでなく、昨日がどうだったか

565
00:21:52,919 --> 00:21:55,320
、そして

566
00:21:55,320 --> 00:21:57,720
私がこのアクションをTから1を引いた時間に行ったという事実を考えると

567
00:21:57,720 --> 00:21:59,820
、Bマトリックスはそれだけではありません

568
00:21:59,820 --> 00:22:01,559
過去の状態だけでなく、

569
00:22:01,559 --> 00:22:04,320
以前の行動にも条件付けられるため、ポリシーPiはそれらの行動

570
00:22:04,320 --> 00:22:07,140
に対する信念または分布として

571
00:22:07,140 --> 00:22:10,020
作用するため、行動

572
00:22:10,020 --> 00:22:11,880
は遷移に直接影響し、次にトラに影響を与えます

573
00:22:11,880 --> 00:22:13,320
状態は状態に影響を与える

574
00:22:13,320 --> 00:22:14,520
ので

575
00:22:14,520 --> 00:22:18,059
、多くのパーム DP シナリオでアクションについてどのように考えるか、および

576
00:22:18,059 --> 00:22:20,760
アクションはポリシーです Pi は

577
00:22:20,760 --> 00:22:23,520
アクションのシーケンスまたはアクションのコレクション

578
00:22:23,520 --> 00:22:26,039
であり、この重要な目的

579
00:22:26,039 --> 00:22:28,380
関数があります。

580
00:22:28,380 --> 00:22:31,080
どの行動が

581
00:22:31,080 --> 00:22:33,299
他の行動よりも可能性が高いので、

582
00:22:33,299 --> 00:22:35,820
期待される自由エネルギーを最小化する

583
00:22:35,820 --> 00:22:37,860
ことで、ポリシーに関する信念を最適化し、

584
00:22:37,860 --> 00:22:39,659
期待される自由エネルギー自体が

585
00:22:39,659 --> 00:22:41,280
生成モデルの関数になります

586
00:22:41,280 --> 00:22:43,500
世界に関するあなたの信念には、

587
00:22:43,500 --> 00:22:45,539
この偏った事前の信念が含まれ

588
00:22:45,539 --> 00:22:47,580
ます あなたが自分自身に期待する観察について

589
00:22:47,580 --> 00:22:50,220
報酬関数の種類が、

590
00:22:50,220 --> 00:22:52,919
この期待される自由エネルギーを介して方策選択に入る

591
00:22:52,919 --> 00:22:54,240


592
00:22:54,240 --> 00:22:57,000


593
00:22:57,000 --> 00:22:58,559
ことがわかります。そのため、

594
00:22:58,559 --> 00:23:00,780
この予想される驚きの境界を最小化している

595
00:23:00,780 --> 00:23:03,600
ため、これらすべてを一種の推論問題と呼ぶことができます。 そうすることで

596
00:23:03,600 --> 00:23:05,640


597
00:23:05,640 --> 00:23:08,400
、実際に

598
00:23:08,400 --> 00:23:10,500
アクションを生成し、世界を変えるためにサンプリングするポリシーの分布を推測します

599
00:23:10,500 --> 00:23:12,539
。  d 言ったように、D ベクトルは

600
00:23:12,539 --> 00:23:14,340
基本的には最初の

601
00:23:14,340 --> 00:23:17,959
隠れた状態分布の前

602
00:23:18,179 --> 00:23:19,260


603
00:23:19,260 --> 00:23:22,679
確率です。つまり、palmdp アクティブ推論モデルを構築するには、

604
00:23:22,679 --> 00:23:24,120


605
00:23:24,120 --> 00:23:26,700


606
00:23:26,700 --> 00:23:29,460
これらの a b c と D を書き留めるかエンコードする必要があります。他にもいくつか

607
00:23:29,460 --> 00:23:30,900
の前確率があります。 また、e Vector

608
00:23:30,900 --> 00:23:33,000
と呼ばれるポリシーに対する事前確率のように話すことも

609
00:23:33,000 --> 00:23:34,980
できますが、今のところ、アクティブな推論

610
00:23:34,980 --> 00:23:37,200
の重労働のほとんどは、

611
00:23:37,200 --> 00:23:39,780


612
00:23:39,780 --> 00:23:41,039
これらのことを書き留めることで構成され

613
00:23:41,039 --> 00:23:43,620
、エージェントが世界について信じていることを実際にエンコードすることであると考えることができます。

614
00:23:43,620 --> 00:23:46,320
それはumに存在し

615
00:23:46,320 --> 00:23:48,120
、これらのものはこれらの

616
00:23:48,120 --> 00:23:50,520
カテゴリ離散分布の場合、

617
00:23:50,520 --> 00:23:53,159
行列とベクトルのように見え

618
00:23:53,159 --> 00:23:54,900


619
00:23:54,900 --> 00:23:57,059
ます.すべてがカテゴリ分布であるため

620
00:23:57,059 --> 00:23:59,100
、連続する無限次元

621
00:23:59,100 --> 00:24:01,200
空間を扱っているのではありません.離散数を持つものを扱っています.

622
00:24:01,200 --> 00:24:02,940


623
00:24:02,940 --> 00:24:05,340
4 x 4 マトリックスまたは 5 x 5

624
00:24:05,340 --> 00:24:07,260
マトリックスの

625
00:24:07,260 --> 00:24:10,980
ようなエントリのええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええええ

626
00:24:10,980 --> 00:24:12,299


627
00:24:12,299 --> 00:24:14,760


628
00:24:14,760 --> 00:24:17,340
先に進む前に弁証法を話しますが、他

629
00:24:17,340 --> 00:24:19,200
に質問がある場合は一時停止する必要があり

630
00:24:19,200 --> 00:24:21,780


631
00:24:21,780 --> 00:24:25,080
ます。ダフネまたはヤコブに感謝します。

632
00:24:25,080 --> 00:24:28,020
何か考えや反省を提供したいです

633
00:24:28,020 --> 00:24:31,879


634
00:24:35,000 --> 00:24:37,020


635
00:24:37,020 --> 00:24:38,340
か。 以前の設定

636
00:24:38,340 --> 00:24:40,620
のパラメータ化にある今解決するのがいいかもしれ

637
00:24:40,620 --> 00:24:42,360


638
00:24:42,360 --> 00:24:43,980


639
00:24:43,980 --> 00:24:47,640
ません.なぜ

640
00:24:47,640 --> 00:24:49,980
それらを初期化するときに

641
00:24:49,980 --> 00:24:52,760


642
00:24:52,799 --> 00:24:55,679
、1より大きい整数が1以上

643
00:24:55,679 --> 00:24:57,900
であるかのようにそれらを行うだけですが、

644
00:24:57,900 --> 00:25:00,299
あなたは好きです. ソフトマキシマム後で

645
00:25:00,299 --> 00:25:02,039
実際に推論を使用するときに、なぜ

646
00:25:02,039 --> 00:25:04,559
これらの確率の好みを定義しないのですか?

647
00:25:04,559 --> 00:25:05,820


648
00:25:05,820 --> 00:25:08,460
ええ、

649
00:25:08,460 --> 00:25:13,380
それは良いことです。良い点であり、言及するのは良いことです。

650
00:25:13,620 --> 00:25:15,960
通常、Matlab と

651
00:25:15,960 --> 00:25:17,940
Python の両方の実装で、ビルドするときに

652
00:25:17,940 --> 00:25:22,559
Pi mdp

653
00:25:22,559 --> 00:25:24,659


654
00:25:24,659 --> 00:25:27,299
では、c Vector を確率としてエンコードするのではなく、エンコードするときに同じこと

655
00:25:27,299 --> 00:25:29,039
を

656
00:25:29,039 --> 00:25:31,260
行うことにしました。  ally

657
00:25:31,260 --> 00:25:33,840
write down は C ベクトルの対数であるため

658
00:25:33,840 --> 00:25:36,419
、相対的な対数確率の観点から書き留めます。確率

659
00:25:36,419 --> 00:25:40,080


660
00:25:40,080 --> 00:25:41,580


661
00:25:41,580 --> 00:25:44,340


662
00:25:44,340 --> 00:25:46,080
の観点から直接書き留めるよりも、より直感的なパラメーター化

663
00:25:46,080 --> 00:25:49,620
になる可能性がある理由は

664
00:25:49,620 --> 00:25:51,840
、確率の対数が 実際の報酬に似ている

665
00:25:51,840 --> 00:25:54,299
ので、この生成モデルに戻ると

666
00:25:54,299 --> 00:25:56,220


667
00:25:56,220 --> 00:25:59,039
、自由エネルギーであると予想される自由

668
00:25:59,039 --> 00:26:01,559
エネルギーは実際に

669
00:26:01,559 --> 00:26:02,220
はええと

670
00:26:02,220 --> 00:26:04,559
、自由エネルギーは一種

671
00:26:04,559 --> 00:26:06,960
のKLダイバージェンスであり

672
00:26:06,960 --> 00:26:08,820
、自然に対数であるビットに関してエンコードされます

673
00:26:08,820 --> 00:26:10,320


674
00:26:10,320 --> 00:26:13,620


675
00:26:13,620 --> 00:26:17,820
スペースなので、対数スペースの観点から以前の

676
00:26:17,820 --> 00:26:21,059
ように書き留めている場合、以前の設定で対数ユニットの数を変更し

677
00:26:21,059 --> 00:26:24,059


678
00:26:24,059 --> 00:26:26,400
た場合、予想される空き時間の変化により直線的に関連していることがわかります。

679
00:26:26,400 --> 00:26:28,380


680
00:26:28,380 --> 00:26:30,080
その観測につながるポリシーのエネルギー

681
00:26:30,080 --> 00:26:32,220
です

682
00:26:32,220 --> 00:26:35,760
が、確率空間の観点から事前確率について書いている場合

683
00:26:35,760 --> 00:26:37,980
、

684
00:26:37,980 --> 00:26:39,779
何かを変更することによる予想される自由エネルギーの結果として生じる変化

685
00:26:39,779 --> 00:26:43,320
確率空間の g は

686
00:26:43,320 --> 00:26:45,120
線形ではなく、非線形の

687
00:26:45,120 --> 00:26:45,900
変化に

688
00:26:45,900 --> 00:26:48,659
なるので、報酬を対数確率として考えると、

689
00:26:48,659 --> 00:26:49,919


690
00:26:49,919 --> 00:26:53,100
1 つの余分な対数単位または 1 つの自然対数のようなもので、

691
00:26:53,100 --> 00:26:55,919
1 Nat または

692
00:26:55,919 --> 00:26:59,279
別のものよりも少し価値があります。 これ

693
00:26:59,279 --> 00:27:00,960
は実際には

694
00:27:00,960 --> 00:27:02,460
、モノ 1 とモノ 2 の間の予想される自由エネルギーの差の観点から反映されますが、

695
00:27:02,460 --> 00:27:04,799


696
00:27:04,799 --> 00:27:06,480
これら 2 つの

697
00:27:06,480 --> 00:27:08,340
ことを確率の観点からエンコードすると、

698
00:27:08,340 --> 00:27:10,020
予想される自由エネルギーの差は

699
00:27:10,020 --> 00:27:12,299
、直線的ではないという理由だけで直感的ではなくなります。

700
00:27:12,299 --> 00:27:13,740


701
00:27:13,740 --> 00:27:16,080
ええと、それ

702
00:27:16,080 --> 00:27:18,659
は私たちが対数空間で物事をエンコードすることを決定した理由の簡単な理由のようなものですが、

703
00:27:18,659 --> 00:27:21,179
数学的に

704
00:27:21,179 --> 00:27:23,039
必要なことは決してありません.確率に関して事前確率を直接簡単に書くことができます.

705
00:27:23,039 --> 00:27:24,240


706
00:27:24,240 --> 00:27:26,580


707
00:27:26,580 --> 00:27:29,039
それは

708
00:27:29,039 --> 00:27:30,779
単なる方法です. 本当にええのようにもっと報酬を与えてください。それ

709
00:27:30,779 --> 00:27:32,460
は非常

710
00:27:32,460 --> 00:27:36,200
に理にかなっています。

711
00:27:36,200 --> 00:27:39,860
ジェイコブに感謝し

712
00:27:40,140 --> 00:27:43,260


713
00:27:43,260 --> 00:27:44,880


714
00:27:44,880 --> 00:27:49,860
ますええええと、アンブ行列

715
00:27:49,860 --> 00:27:53,039
またはテンソルが実際であるためには、ええと心臓の要件があるのではないかと思っています カテゴリカル行列としてエンコードされる

716
00:27:53,039 --> 00:27:56,279
か、または

717
00:27:56,279 --> 00:27:58,020
行列の関数

718
00:27:58,020 --> 00:28:00,840
と、エージェントがそれを使用し

719
00:28:00,840 --> 00:28:03,000
て観測から隠れた状態を推測する方法について

720
00:28:03,000 --> 00:28:05,340
考えているため、ニューラルのようなもので

721
00:28:05,340 --> 00:28:07,980
高次元の状態空間をエンコードすることが可能かどうかを考えています

722
00:28:07,980 --> 00:28:09,720


723
00:28:09,720 --> 00:28:11,460


724
00:28:11,460 --> 00:28:14,279
ええと、これらの確率

725
00:28:14,279 --> 00:28:17,279
的表現も近似できるネットワークで

726
00:28:17,279 --> 00:28:20,039
あり、観察と隠れた状態の間の関係の種類を表現することを学習します

727
00:28:20,039 --> 00:28:23,400


728
00:28:23,400 --> 00:28:25,460


729
00:28:25,500 --> 00:28:29,460
ええ、ええ、基本的には

730
00:28:29,460 --> 00:28:32,460
申し訳ありませんが、そうかもしれません。

731
00:28:32,460 --> 00:28:34,080


732
00:28:34,080 --> 00:28:36,779


733
00:28:36,779 --> 00:28:39,179
Pythonの実装のように

734
00:28:39,179 --> 00:28:41,880
感じます.MatlabよりもPythonの利点を理解できると確信しています.

735
00:28:41,880 --> 00:28:43,980
ええと

736
00:28:43,980 --> 00:28:46,799
、

737
00:28:46,799 --> 00:28:51,919
他のライブラリとの相互運用性やデータサイエンス内での相互運用性も提供します.

738
00:28:51,919 --> 00:28:54,659


739
00:28:54,659 --> 00:28:56,880


740
00:28:56,880 --> 00:28:59,159
Palm DPS について話しました

741
00:28:59,159 --> 00:29:01,020
Palm DPS について

742
00:29:01,020 --> 00:29:02,520
は、これらすべてが行列でなければならないことを意味するものは何もありません。

743
00:29:02,520 --> 00:29:05,279


744
00:29:05,279 --> 00:29:06,600
EP を定義する主な点は

745
00:29:06,600 --> 00:29:09,419
、エージェントが青いノードのみを見ることができるように部分的に観察可能で

746
00:29:09,419 --> 00:29:11,820
あり、それ

747
00:29:11,820 --> 00:29:14,100
がマルコフのプロセスであるため、隠れ

748
00:29:14,100 --> 00:29:16,080
た状態の記憶に一時的な浅さのような

749
00:29:16,080 --> 00:29:18,000
ものが

750
00:29:18,000 --> 00:29:21,240
あるが、a と b を置き換えることができるということです。 あらゆる種類のパラメーター

751
00:29:21,240 --> 00:29:23,279
化されたもので、それは適切な尤度

752
00:29:23,279 --> 00:29:26,159
関数でなければならないので、それが尤度

753
00:29:26,159 --> 00:29:28,080
であるという適切な特性を持つ

754
00:29:28,080 --> 00:29:29,940


755
00:29:29,940 --> 00:29:32,820
必要があります。多変量ガウスまたはコッシー分布またはベルヌーイ分布またはええと、そうではないことを意味するものは何もありません

756
00:29:32,820 --> 00:29:35,159


757
00:29:35,159 --> 00:29:38,279
ええ、あらゆる種類の

758
00:29:38,279 --> 00:29:41,220
指数関数族や

759
00:29:41,220 --> 00:29:43,440


760
00:29:43,440 --> 00:29:46,140
、人々が強化学習でよく使用するパラメータ化されたニューラル ネットワークのようなものです。

761
00:29:46,140 --> 00:29:47,399


762
00:29:47,399 --> 00:29:49,200


763
00:29:49,200 --> 00:29:51,720


764
00:29:51,720 --> 00:29:53,820
時間 T で時間状態を取り、それらを状態に移動すると言う一連のニューラル ネットワークだけでダイナミクス モデルをパラメータ化します。

765
00:29:53,820 --> 00:29:56,340
時間 t に 1 を足す

766
00:29:56,340 --> 00:29:58,799
と、これが困難な理由は単純に

767
00:29:58,799 --> 00:30:00,899
、いったん sta に

768
00:30:00,899 --> 00:30:03,000
すると期待される自由エネルギーのようなものを計算する方法が不明確だから

769
00:30:03,000 --> 00:30:06,059
です。  rt は、

770
00:30:06,059 --> 00:30:07,320
これらの

771
00:30:07,320 --> 00:30:10,020
分布に移行すると、うまく動作しない

772
00:30:10,020 --> 00:30:12,539
ため、この

773
00:30:12,539 --> 00:30:14,580
フレームワークが離散

774
00:30:14,580 --> 00:30:17,220
カテゴリ状態バージョンで開発された理由の多くは、

775
00:30:17,220 --> 00:30:19,260


776
00:30:19,260 --> 00:30:21,299
誰かがスロット マシンをプレイしたり、

777
00:30:21,299 --> 00:30:23,880
左または右に移動することを決定したりするような低次元のタスクをモデル化するためだけではありません。

778
00:30:23,880 --> 00:30:27,240
y迷路では、これらの離散分布を使用して

779
00:30:27,240 --> 00:30:29,279


780
00:30:29,279 --> 00:30:30,720
、その動作を適切に説明する

781
00:30:30,720 --> 00:30:32,640
のは簡単ですが、これは文字通り

782
00:30:32,640 --> 00:30:34,980
数学的な扱いやすさの理由で

783
00:30:34,980 --> 00:30:37,080
もあります.

784
00:30:37,080 --> 00:30:38,820


785
00:30:38,820 --> 00:30:40,559


786
00:30:40,559 --> 00:30:42,899
分布は次のように見えるので、これを行うためのいくつかの作業があり

787
00:30:42,899 --> 00:30:45,000
ます。たとえば、Magnus

788
00:30:45,000 --> 00:30:48,480
cudall はエントロピーに関する論文を持っており、

789
00:30:48,480 --> 00:30:50,760


790
00:30:50,760 --> 00:30:52,559
基本的に

791
00:30:52,559 --> 00:30:54,360
これらすべての A と B が

792
00:30:54,360 --> 00:30:57,059
ガウスで表される線形動的システムで予想される自由エネルギーを計算するため、彼らはこれを線形可制御のように呼んでいます。

793
00:30:57,059 --> 00:30:59,940


794
00:30:59,940 --> 00:31:01,260
また、アクションが B マトリックスにどのように影響するかについて、いくつかの仮定を行う必要があります。

795
00:31:01,260 --> 00:31:03,120


796
00:31:03,120 --> 00:31:05,039
これはもはや行列ではなく、

797
00:31:05,039 --> 00:31:07,100
より連続的な

798
00:31:07,100 --> 00:31:10,080
ガウス分布に似ており、情報ゲインのよう

799
00:31:10,080 --> 00:31:11,880
な期待される自由エネルギーで得られる通常の項

800
00:31:11,880 --> 00:31:13,559


801
00:31:13,559 --> 00:31:15,720
は、

802
00:31:15,720 --> 00:31:17,760
カテゴリカル分布を使用するときに得られる多くの興味深いものであることがわかりました。

803
00:31:17,760 --> 00:31:19,740


804
00:31:19,740 --> 00:31:21,659
ガウスを使用すると用語は実際に消える

805
00:31:21,659 --> 00:31:23,520
ため、カテゴリカルを使用して通常取得する情報ゲインシークまたは情報シーク用語のような素晴らしいものは実際には得られませんが、

806
00:31:23,520 --> 00:31:26,580


807
00:31:26,580 --> 00:31:28,260


808
00:31:28,260 --> 00:31:30,720


809
00:31:30,720 --> 00:31:32,460


810
00:31:32,460 --> 00:31:34,080
ニューラルネットワークを使用する場合のように、それを回避する他の方法があり

811
00:31:34,080 --> 00:31:36,600
ます。

812
00:31:36,600 --> 00:31:39,240
期待される自由エネルギーを計算するためのサンプリング

813
00:31:39,240 --> 00:31:40,919
アプローチのようなものです。基本的に

814
00:31:40,919 --> 00:31:42,600
は、可能な軌道の束をサンプリングするのが好き

815
00:31:42,600 --> 00:31:44,820
です。次に、モンテカルロ スタイルのようなサンプルを使用して、

816
00:31:44,820 --> 00:31:46,679
期待される

817
00:31:46,679 --> 00:31:48,179
自由エネルギーと、スケーリングのような多くのグループ

818
00:31:48,179 --> 00:31:50,039
を計算でき

819
00:31:50,039 --> 00:31:52,620
ます。 ディープ ニューラル ネットワークへのアクティブな推論

820
00:31:52,620 --> 00:31:54,539
彼らはその種

821
00:31:54,539 --> 00:31:56,340
のアプローチを使用しており、アレック・チャンスの論文のように

822
00:31:56,340 --> 00:31:57,960
スカウトのスケーリング アクティブな推論

823
00:31:57,960 --> 00:31:59,820


824
00:31:59,820 --> 00:32:02,940
ence はそのようなことを行います Tim verbalance group のようなものからの多くのもの

825
00:32:02,940 --> 00:32:04,620
ええと、私が好きだと思う人を残したくないし

826
00:32:04,620 --> 00:32:07,080
、明らかに多くのことをしたこともありません

827
00:32:07,080 --> 00:32:08,700


828
00:32:08,700 --> 00:32:11,220


829
00:32:11,220 --> 00:32:12,720
ウイルスは、これらの

830
00:32:12,720 --> 00:32:13,919
人々の多くが実際に

831
00:32:13,919 --> 00:32:15,480
アクティブな推論を適用してニューラルネットを維持しようとし

832
00:32:15,480 --> 00:32:17,460
ているように私たちを発見しました.Pine BPでは、pi MVPで行われる方法とは異なる、予想される自由エネルギーを計算する方法を基本的に考え出す必要があります.

833
00:32:17,460 --> 00:32:18,960


834
00:32:18,960 --> 00:32:21,240


835
00:32:21,240 --> 00:32:23,279


836
00:32:23,279 --> 00:32:25,200
予想される自由エネルギーを正確に計算することができます。最終的

837
00:32:25,200 --> 00:32:27,360
には一連

838
00:32:27,360 --> 00:32:29,159
の行列ベクトル積と

839
00:32:29,159 --> 00:32:30,179
総和に

840
00:32:30,179 --> 00:32:31,919
なるだけなので、

841
00:32:31,919 --> 00:32:34,020
より複雑な分布を使用すると難しくなります

842
00:32:34,020 --> 00:32:36,480
が、決して

843
00:32:36,480 --> 00:32:37,100


844
00:32:37,100 --> 00:32:39,539
不可能ではありません。来なければなりません。

845
00:32:39,539 --> 00:32:40,980
ある種の近似値を使用し

846
00:32:40,980 --> 00:32:43,380
ますが

847
00:32:43,380 --> 00:32:45,899
、これを回避できる方法がいくつかあると思います

848
00:32:45,899 --> 00:32:48,539


849
00:32:48,539 --> 00:32:50,159


850
00:32:50,159 --> 00:32:53,100


851
00:32:53,100 --> 00:32:54,960
より高いレイヤーのようにパームDPにeedし、次に

852
00:32:54,960 --> 00:32:56,640
離散カテゴリ空間のようなインパウンドDPスペースにeedし

853
00:32:56,640 --> 00:32:58,260
ます。

854
00:32:58,260 --> 00:33:00,059
予想される自由エネルギーと自由エネルギーを計算

855
00:33:00,059 --> 00:33:03,000
できますが

856
00:33:03,000 --> 00:33:04,620
、高次元ニューラルネットワークのような低レベルで

857
00:33:04,620 --> 00:33:07,260
データを投影するために利用できます

858
00:33:07,260 --> 00:33:09,720
この低次元空間に

859
00:33:09,720 --> 00:33:11,820
すべての有効な推論を行うため、すべてが正確であるこの

860
00:33:11,820 --> 00:33:13,620
低次元の Palm DP 空間で

861
00:33:13,620 --> 00:33:15,600
すべての

862
00:33:15,600 --> 00:33:16,740
有効な推論を行いますが、ニューラル ネットワークの優れた

863
00:33:16,740 --> 00:33:19,140
次元削減と特徴

864
00:33:19,140 --> 00:33:20,880
抽出特性を利用

865
00:33:20,880 --> 00:33:22,500
して、観測を最初に前処理する

866
00:33:22,500 --> 00:33:24,419
ことができます。 それを可能

867
00:33:24,419 --> 00:33:26,340


868
00:33:26,340 --> 00:33:28,679
にするための最初のステップでいくつかの進歩を遂げたので、これについては最後にお話しします。

869
00:33:28,679 --> 00:33:30,600
これには、

870
00:33:30,600 --> 00:33:32,580
基本的に Pi mdp Auto のすべてを

871
00:33:32,580 --> 00:33:34,080
微分可能にすることが含まれます。

872
00:33:34,080 --> 00:33:36,120


873
00:33:36,120 --> 00:33:38,700
モデル

874
00:33:38,700 --> 00:33:41,640
はい、それは素晴らしい質問です

875
00:33:41,640 --> 00:33:45,059


876
00:33:45,059 --> 00:33:48,779


877
00:33:48,779 --> 00:33:51,059
今日は明日のアンテナのようなものです.

878
00:33:51,059 --> 00:33:53,580
それは長くなったり太くなったりし

879
00:33:53,580 --> 00:33:56,159
ます.モデルのさまざまな部分を交換して構成するにはさまざまな方法があります.

880
00:33:56,159 --> 00:33:58,440


881
00:33:58,440 --> 00:34:00,600


882
00:34:00,600 --> 00:34:01,860


883
00:34:01,860 --> 00:34:03,059


884
00:34:03,059 --> 00:34:04,980


885
00:34:04,980 --> 00:34:07,260


886
00:34:07,260 --> 00:34:08,820
アクティブな推論研究

887
00:34:08,820 --> 00:34:10,020
は、現在電話に出ている全員

888
00:34:10,020 --> 00:34:11,820
が元の方法に精通していると確信して

889
00:34:11,820 --> 00:34:15,540
います。基本的にはカール・フリストンと

890
00:34:15,540 --> 00:34:17,760
他の数人がSPMパッケージの一部であるMatlabスクリプトの束を書きました。

891
00:34:17,760 --> 00:34:20,879


892
00:34:20,879 --> 00:34:22,440


893
00:34:22,440 --> 00:34:24,780
データ分析と

894
00:34:24,780 --> 00:34:26,940
統計テスト

895
00:34:26,940 --> 00:34:29,159
、および Dem または動的期待値最大化と呼ばれるサブパッケージがあります。

896
00:34:29,159 --> 00:34:31,139
これ

897
00:34:31,139 --> 00:34:33,000
は

898
00:34:33,000 --> 00:34:34,859
、連続アクティブ推論を含むアクティブ推論

899
00:34:34,859 --> 00:34:36,599
だけでなく、一般化されたフィルタリング

900
00:34:36,599 --> 00:34:39,300
や

901
00:34:39,300 --> 00:34:41,879
経験的データからの非線形状態空間モデルのフィッティングにも使用されます。

902
00:34:41,879 --> 00:34:43,679
この種の離散アクティブ推論ツールボックスをすべて備えており、その

903
00:34:43,679 --> 00:34:46,800
ほとんど

904
00:34:46,800 --> 00:34:48,599
の機能の前

905
00:34:48,599 --> 00:34:52,199
に SPM アンダースコア Mt が付いています mdp したがって、

906
00:34:52,199 --> 00:34:53,879
基本的

907
00:34:53,879 --> 00:34:56,399
にPine MVPがほとんどの場合行うすべてのことを行う主な機能は、

908
00:34:56,399 --> 00:34:58,740
SPM mdp vbxと呼ばれる1つの機能を含む

909
00:34:58,740 --> 00:35:02,339


910
00:35:02,339 --> 00:35:04,080
ことであり

911
00:35:04,080 --> 00:35:06,420
、Pine DPは単なるパッケージであるとよく冗談を言っています。

912
00:35:06,420 --> 00:35:07,980


913
00:35:07,980 --> 00:35:09,599
その1つの関数は本質的に

914
00:35:09,599 --> 00:35:12,420
アクティブな推論と学習を行い、

915
00:35:12,420 --> 00:35:14,460
すべてのメッセージを1回の

916
00:35:14,460 --> 00:35:16,440
呼び出しで渡すため、その1つの関数を実装します。

917
00:35:16,440 --> 00:35:18,839
これは、mdpをそれに渡してから

918
00:35:18,839 --> 00:35:21,000
、一種のBlack  Box

919
00:35:21,000 --> 00:35:23,339
way は、すべての信念の更新

920
00:35:23,339 --> 00:35:25,140
とアクションの履歴、および

921
00:35:25,140 --> 00:35:28,079
必要なものすべてを提供します。

922
00:35:28,079 --> 00:35:30,599
その優雅さにもかかわらず、

923
00:35:30,599 --> 00:35:33,000
有用性と実際の堅牢性に似

924
00:35:33,000 --> 00:35:35,760


925
00:35:35,760 --> 00:35:37,260


926
00:35:37,260 --> 00:35:38,579
ています。 多くの作業

927
00:35:38,579 --> 00:35:40,859
の問題は、それが単一

928
00:35:40,859 --> 00:35:42,960
の関数であり、あまりモジュール化されていないため、アクティブな推論プロセスの

929
00:35:42,960 --> 00:35:45,300
さまざまなサブ計算を柔軟に構成することが非常に難しい

930
00:35:45,300 --> 00:35:47,220


931
00:35:47,220 --> 00:35:49,200
ためです。

932
00:35:49,200 --> 00:35:50,700


933
00:35:50,700 --> 00:35:53,280
アクティブな推論アプリケーションで、

934
00:35:53,280 --> 00:35:55,859
隠し状態の推論を行う前に、行列

935
00:35:55,859 --> 00:35:57,300
のパラメータを更新し

936
00:35:57,300 --> 00:35:58,859
たいのですが

937
00:35:58,859 --> 00:36:01,260
、この特定の方法でそれを行いたいの

938
00:36:01,260 --> 00:36:05,119
ですが、SPM mdp vbx でそれを行うのは非常に難しいので、

939
00:36:05,119 --> 00:36:07,380
よく目にするものです。 起こって、私は

940
00:36:07,380 --> 00:36:09,720
自分の修士の研究でこれを自分でやった.私

941
00:36:09,720 --> 00:36:11,220


942
00:36:11,220 --> 00:36:13,140
はこの関数の5つの異なるバージョンのようなものを持っている.

943
00:36:13,140 --> 00:36:15,960


944
00:36:15,960 --> 00:36:18,480


945
00:36:18,480 --> 00:36:21,119


946
00:36:21,119 --> 00:36:22,500


947
00:36:22,500 --> 00:36:24,060
一連のボイラープレート コードを作成しているため効率的

948
00:36:24,060 --> 00:36:26,400


949
00:36:26,400 --> 00:36:27,900


950
00:36:27,900 --> 00:36:29,460
であり、プロジェクトで調査したいアクティブな推論の特定の小さなバージョンを実行する関数が 1 つあるため、

951
00:36:29,460 --> 00:36:32,220


952
00:36:32,220 --> 00:36:34,680
Matlab 内でもこの 1 つの関数をモジュール化するだけで、

953
00:36:34,680 --> 00:36:36,839
これを行うことができます。 基本

954
00:36:36,839 --> 00:36:38,579
的に物事をより柔軟にし、コード

955
00:36:38,579 --> 00:36:41,099
のコピーと貼り付けの多くを節約し

956
00:36:41,099 --> 00:36:43,280
ます。

957
00:36:43,500 --> 00:36:45,420
別の問題は、推論と

958
00:36:45,420 --> 00:36:46,980
ポリシーの選択が固定されているため、比較できないことです。

959
00:36:46,980 --> 00:36:48,839
e と、異なる

960
00:36:48,839 --> 00:36:51,060
メッセージ パッシング アプローチとアクション

961
00:36:51,060 --> 00:36:52,740
選択ルーチンを対比するため

962
00:36:52,740 --> 00:36:56,099
、SPM vbx で実行される方法は 1 つしかありません。これは、

963
00:36:56,099 --> 00:36:58,440
限界メッセージ パッシング um と呼ばれます。

964
00:36:58,440 --> 00:37:01,079
そのため

965
00:37:01,079 --> 00:37:02,339
、メッセージ パッシング アルゴリズムを変更した場合のように、Pi MVP ではどうなるかを比較するのは難しいです。

966
00:37:02,339 --> 00:37:05,700


967
00:37:05,700 --> 00:37:07,800
現在、2 つのメッセージ パッシング

968
00:37:07,800 --> 00:37:09,599
アルゴリズムがあり、並べて比較することができます。つまり、将来

969
00:37:09,599 --> 00:37:12,000
さらに追加することを望ん

970
00:37:12,000 --> 00:37:13,680
でいるということです。これは

971
00:37:13,680 --> 00:37:16,920
単なるモジュール式のものであり

972
00:37:16,920 --> 00:37:18,119
、最初に話していたことのおかげで非常に簡単です。

973
00:37:18,119 --> 00:37:21,000


974
00:37:21,000 --> 00:37:22,859
これがMatlabにあるという理由だけ

975
00:37:22,859 --> 00:37:25,140
で、強化学習のような他のフレームワークと合成するのが難しくなり

976
00:37:25,140 --> 00:37:27,839
ますオープンAIジムや、

977
00:37:27,839 --> 00:37:29,099


978
00:37:29,099 --> 00:37:32,339
インテンソルフローフローやPi torture Jacksのような深いニューラルネットワークなど

979
00:37:32,339 --> 00:37:34,380
、Matlabにあるという事実だけで、

980
00:37:34,380 --> 00:37:36,660
コースの人々はすでに限られています JuliaからMatlab、Python、そしてその逆に移動する

981
00:37:36,660 --> 00:37:39,420
など、クロス言語

982
00:37:39,420 --> 00:37:41,700
クロスプラットフォーム

983
00:37:41,700 --> 00:37:44,400
umコードのようにする方法を見つけ

984
00:37:44,400 --> 00:37:46,980
ましたが、それは

985
00:37:46,980 --> 00:37:49,440
はるかに重いです それに関与している

986
00:37:49,440 --> 00:37:52,440
場合は

987
00:37:52,440 --> 00:37:55,619
、Matlab と Python の長所と短所をいくつか説明します。Matlab で

988
00:37:55,619 --> 00:37:57,420
気に入って

989
00:37:57,420 --> 00:37:59,339
いることの 1 つは、配列プログラミングを始めるのが非常に簡単であること

990
00:37:59,339 --> 00:38:01,680
です。優れたエディター

991
00:38:01,680 --> 00:38:04,200
があります。たくさんあります。 昨年

992
00:38:04,200 --> 00:38:06,839


993
00:38:06,839 --> 00:38:09,720
、計算精神医学のコースでこのチュートリアルを行ったときでさえ、使用と歴史と計算神経科学のよう

994
00:38:09,720 --> 00:38:11,400


995
00:38:11,400 --> 00:38:13,740
に、チュートリアルの大部分

996
00:38:13,740 --> 00:38:16,260
はまだMatlabを使用し

997
00:38:16,260 --> 00:38:18,420
ていたと思います。

998
00:38:18,420 --> 00:38:20,700


999
00:38:20,700 --> 00:38:22,440


1000
00:38:22,440 --> 00:38:24,780
神経科学や精神物理学を行うのに適した多くのパッケージがあるので

1001
00:38:24,780 --> 00:38:26,280


1002
00:38:26,280 --> 00:38:30,000
、ほとんどの勢いやレガシーアドバンテージのようなアドバンテージ

1003
00:38:30,000 --> 00:38:32,099
がありますが、もちろん、独自のような問題

1004
00:38:32,099 --> 00:38:33,480


1005
00:38:33,480 --> 00:38:35,520
があります。

1006
00:38:35,520 --> 00:38:38,339
もう1つはMatlabを使用する

1007
00:38:38,339 --> 00:38:40,800
ことで、コミュニティ主導の開発はそれほど多くありません。

1008
00:38:40,800 --> 00:38:43,020


1009
00:38:43,020 --> 00:38:44,880
つまり、ファイル交換のようなものがありますが、Pythonのようなものと同じレベルではありません.

1010
00:38:44,880 --> 00:38:47,400
dの場合、

1011
00:38:47,400 --> 00:38:49,740
pythonのようなものはMatlabと競合できます

1012
00:38:49,740 --> 00:38:51,420


1013
00:38:51,420 --> 00:38:53,700
.numpyの形式の配列プログラミングがあるため、もちろんオープンソース

1014
00:38:53,700 --> 00:38:55,680


1015
00:38:55,680 --> 00:38:57,660


1016
00:38:57,660 --> 00:39:00,960
です.学術的な分野だけでなく、多く

1017
00:39:00,960 --> 00:39:02,940
の商用アプリケーションで広く採用されており、

1018
00:39:02,940 --> 00:39:05,099
多くのコミュニティが主導しています.

1019
00:39:05,099 --> 00:39:08,940
Pi VP um のようなパッケージの形での開発ですが、

1020
00:39:08,940 --> 00:39:11,280
1 つの欠点は、少なくとも私にとっては、

1021
00:39:11,280 --> 00:39:12,839


1022
00:39:12,839 --> 00:39:14,520
Matlab um を使い始めるのは

1023
00:39:14,520 --> 00:39:17,460


1024
00:39:17,460 --> 00:39:19,079
Matlab の場合ほど簡単

1025
00:39:19,079 --> 00:39:20,280
ではなかったことです。 仮想

1026
00:39:20,280 --> 00:39:21,540
環境

1027
00:39:21,540 --> 00:39:24,440
については、Python を使い始める前にもっと多くのプログラミングについて学ぶ必要がある

1028
00:39:24,440 --> 00:39:27,060


1029
00:39:27,060 --> 00:39:29,040
ので、

1030
00:39:29,040 --> 00:39:30,780


1031
00:39:30,780 --> 00:39:32,520


1032
00:39:32,520 --> 00:39:33,960
Matlab を入手してから実際に

1033
00:39:33,960 --> 00:39:36,960
プログラミングを行うまでの時間のように、Matlab が教育ツールとして実際にまだ有用である理由の 1 つだと思います。 これは非常に短い

1034
00:39:36,960 --> 00:39:39,660


1035
00:39:39,660 --> 00:39:43,440
ので、ええと、パッケージはええと呼ばれてい

1036
00:39:43,440 --> 00:39:46,020
ます。これは、このインフラストラクチャ内にあり、積極的にGitHub

1037
00:39:46,020 --> 00:39:48,839
組織であり、Pi MVPと呼ばれ、

1038
00:39:48,839 --> 00:39:50,700
インスタをピップすることができます

1039
00:39:50,700 --> 00:39:52,380
仮想環境または

1040
00:39:52,380 --> 00:39:55,140
Pythonのベースインストールの

1041
00:39:55,140 --> 00:39:57,540
ように、piondpを

1042
00:39:57,540 --> 00:40:00,720
インストールしたら、基本的にエージェントモジュールの

1043
00:40:00,720 --> 00:40:03,599
ようなすべての異なるサブパッケージまたはサブモジュールを柔軟なモジュール式の方法でインポートして使用でき

1044
00:40:03,599 --> 00:40:05,640
ます

1045
00:40:05,640 --> 00:40:07,560


1046
00:40:07,560 --> 00:40:09,660
エージェントクラスを実装するだけで

1047
00:40:09,660 --> 00:40:11,579


1048
00:40:11,579 --> 00:40:13,619


1049
00:40:13,619 --> 00:40:15,119
、実際にアクティブな推論エージェントから独立した推論、制御、学習などのさまざまなモジュールがあり、

1050
00:40:15,119 --> 00:40:16,440


1051
00:40:16,440 --> 00:40:19,200
それらを使用して、隠れた状態推論のメッセージパッシングを実行し

1052
00:40:19,200 --> 00:40:21,119
たり

1053
00:40:21,119 --> 00:40:22,320


1054
00:40:22,320 --> 00:40:24,839
、可能なポリシーで予想される自由エネルギーを計算したり、

1055
00:40:24,839 --> 00:40:27,119
パラメータの更新を計算して、これらすべてを

1056
00:40:27,119 --> 00:40:29,640
構成し、柔軟に構成

1057
00:40:29,640 --> 00:40:31,800
できるようにします。これらすべてを希望するオーダーメイドの方法で構成することにより、一種のフランケンシュタインの

1058
00:40:31,800 --> 00:40:33,839
アクティブな推論エージェントを作成

1059
00:40:33,839 --> 00:40:36,060


1060
00:40:36,060 --> 00:40:38,099
できます。

1061
00:40:38,099 --> 00:40:41,160
その多くは、pione P のメイン ワークフローです

1062
00:40:41,160 --> 00:40:43,260


1063
00:40:43,260 --> 00:40:45,060
生成モデルとこれらの

1064
00:40:45,060 --> 00:40:47,640
離散配列の形式を指定し

1065
00:40:47,640 --> 00:40:49,680
、エージェントの頭脳にプラグインして、

1066
00:40:49,680 --> 00:40:52,020
エージェントをインスタンス化

1067
00:40:52,020 --> 00:40:54,119
して、一番下のこれらの 2 行でほぼカプセル化します

1068
00:40:54,119 --> 00:40:57,000
。Pine BP からエージェントをインポートし

1069
00:40:57,000 --> 00:40:59,400
ます。

1070
00:40:59,400 --> 00:41:02,220
次に、ABC と D をプラグインして

1071
00:41:02,220 --> 00:41:04,619
エージェント オブジェクトを作成するだけで、非表示の状態を実行するために使用できるこのエージェント オブジェクトが得られます。

1072
00:41:04,619 --> 00:41:06,420


1073
00:41:06,420 --> 00:41:08,099
最初の状態のような方法による

1074
00:41:08,099 --> 00:41:10,560
推論は、エージェントであるポリシーを推論します。これは、

1075
00:41:10,560 --> 00:41:12,240


1076
00:41:12,240 --> 00:41:14,760
そのポリシーの予想される自由エネルギーを内部的に計算します。次に、

1077
00:41:14,760 --> 00:41:17,400
最終的にアクションをサンプリングできるため、これらの

1078
00:41:17,400 --> 00:41:19,260
3 つの行は、

1079
00:41:19,260 --> 00:41:21,359
アクティブな推論の主要なプレーヤーの一種です。 ループ

1080
00:41:21,359 --> 00:41:24,660
状態の推論 ポリシーの推論

1081
00:41:24,660 --> 00:41:26,820
次に、アクションの選択と、アクティブな推論プロセスをインスタンス化するため

1082
00:41:26,820 --> 00:41:30,320
に、それらを時間の経過とともにループに結び付けるだけ

1083
00:41:30,359 --> 00:41:32,339


1084
00:41:32,339 --> 00:41:35,460


1085
00:41:35,460 --> 00:41:37,079
です。アクション認識の循環性

1086
00:41:37,079 --> 00:41:39,300
ループは、その観察であるエージェントへの入力で機能します。

1087
00:41:39,300 --> 00:41:41,880
そして

1088
00:41:41,880 --> 00:41:43,500
、チャートがそのアクションであるアクション選択の出力で

1089
00:41:43,500 --> 00:41:45,960
あり、

1090
00:41:45,960 --> 00:41:48,000
もちろん、最後のアクションを使用して新しい観測を取得する必要があります。

1091
00:41:48,000 --> 00:41:50,640


1092
00:41:50,640 --> 00:41:53,520
アクションを何らかの環境にプラグインすることで行い

1093
00:41:53,520 --> 00:41:55,980
ます。これは、生成プロセスと呼ばれる

1094
00:41:55,980 --> 00:41:57,480
ことが多いアクティブな推論の文献にも

1095
00:41:57,480 --> 00:41:59,400


1096
00:41:59,400 --> 00:42:00,960
あります。データを生成する実際の世界です。

1097
00:42:00,960 --> 00:42:03,119
これは、

1098
00:42:03,119 --> 00:42:04,680
古典的なアクション認識グループの一種

1099
00:42:04,680 --> 00:42:06,480
です。 任意のアクティブな推論エージェントを制定しました。

1100
00:42:06,480 --> 00:42:08,640
これはアクティブな推論に固有のものでもありません。

1101
00:42:08,640 --> 00:42:10,320
これは、

1102
00:42:10,320 --> 00:42:12,119
強化学習の問題が

1103
00:42:12,119 --> 00:42:14,880
一般的にどのように構成されているかです。つまり、オープン AI Jam

1104
00:42:14,880 --> 00:42:17,040
が非常によく似た

1105
00:42:17,040 --> 00:42:20,339
制御フローを使用しているように、私たちは

1106
00:42:20,339 --> 00:42:24,020
ええと感覚運動ループの

1107
00:42:24,440 --> 00:42:27,359
ようなものです。 これ

1108
00:42:27,359 --> 00:42:30,359
は、エージェントをインポートして生成モデルをセットアップするようなことを行っている例です。

1109
00:42:30,359 --> 00:42:31,980


1110
00:42:31,980 --> 00:42:33,720
これが最も難しい部分なので

1111
00:42:33,720 --> 00:42:36,420
、ドットドットの後に省略記号を都合よく配置し

1112
00:42:36,420 --> 00:42:37,500
ていますが、実際にはほとんどのコード

1113
00:42:37,500 --> 00:42:38,640
が発生する場所は生成モデルを構築することです

1114
00:42:38,640 --> 00:42:41,220
エージェントを構築

1115
00:42:41,220 --> 00:42:43,020


1116
00:42:43,020 --> 00:42:45,599
する 保存された Pi

1117
00:42:45,599 --> 00:42:47,820
mdp 環境の 1 つとしてインポートできる環境を構築するか、オープン AI ジムから取得するか、または可能性があり

1118
00:42:47,820 --> 00:42:50,040
ます d

1119
00:42:50,040 --> 00:42:51,660
独自の環境を作成するだけで、エージェントが対話している世界で世界が

1120
00:42:51,660 --> 00:42:53,940
どのように機能するかを実際に記述するコードになり、

1121
00:42:53,940 --> 00:42:55,920


1122
00:42:55,920 --> 00:42:57,900


1123
00:42:57,900 --> 00:43:01,319


1124
00:43:01,319 --> 00:43:02,940
その数行のコードでアクティブな推論の時間ステップを

1125
00:43:02,940 --> 00:43:05,339
すぐに実装できます。 それは

1126
00:43:05,339 --> 00:43:07,740
すべて8から15のような最後の行の

1127
00:43:07,740 --> 00:43:09,240
ようなものです.

1128
00:43:09,240 --> 00:43:10,560


1129
00:43:10,560 --> 00:43:14,000
時間の経過とともにループ内にラップされます.

1130
00:43:14,640 --> 00:43:16,500
ええと,これは

1131
00:43:16,500 --> 00:43:19,260


1132
00:43:19,260 --> 00:43:20,880
単なる例です.

1133
00:43:20,880 --> 00:43:22,920
推論ですが、Algos サブモジュール

1134
00:43:22,920 --> 00:43:25,079
のメッセージ パッシング アルゴリズムの 1 つを使用

1135
00:43:25,079 --> 00:43:28,380
して非表示の

1136
00:43:28,380 --> 00:43:31,020
State 推論を行っているだけなので、この場合

1137
00:43:31,020 --> 00:43:33,240
はランダムな行列を作成しました。

1138
00:43:33,240 --> 00:43:36,660


1139
00:43:36,660 --> 00:43:39,240
次に、隠れ状態の推論中に

1140
00:43:39,240 --> 00:43:42,420
エージェントが行っている可能性があることの架空の更新のようなものを実行し、

1141
00:43:42,420 --> 00:43:43,619


1142
00:43:43,619 --> 00:43:47,099
Q または隠れ状態に関する信念を最適化

1143
00:43:47,099 --> 00:43:49,380


1144
00:43:49,380 --> 00:43:50,520
することができます。これは、

1145
00:43:50,520 --> 00:43:53,160
Pond DP を実際に使用して j 隠れマルコフモデルで一般的な推論

1146
00:43:53,160 --> 00:43:55,380
を行う必要があり

1147
00:43:55,380 --> 00:43:58,020
ます。アクティブな推論

1148
00:43:58,020 --> 00:44:00,900
ループ内で使用する必要さえありません。提供された特定のアルゴリズムを使用して、隠れマルコフモデルで統計的推論のように使用することができます。

1149
00:44:00,900 --> 00:44:02,520


1150
00:44:02,520 --> 00:44:04,440


1151
00:44:04,440 --> 00:44:06,720


1152
00:44:06,720 --> 00:44:08,280
もちろん、私が SPM よりも優れている点の 1 つは、

1153
00:44:08,280 --> 00:44:10,560


1154
00:44:10,560 --> 00:44:12,180
カスタマイズされたアクティブな推論プロセスを作成できることです。

1155
00:44:12,180 --> 00:44:14,400


1156
00:44:14,400 --> 00:44:16,200
エージェント クラスに

1157
00:44:16,200 --> 00:44:18,300


1158
00:44:18,300 --> 00:44:21,000
は、報酬関数のさまざまな部分または

1159
00:44:21,000 --> 00:44:23,819
期待される無料をオンまたはオフにできるような追加の引数がたくさんあります。

1160
00:44:23,819 --> 00:44:26,339
たとえば、このエージェントでは、エージェントはアクション選択

1161
00:44:26,339 --> 00:44:28,619


1162
00:44:28,619 --> 00:44:30,540
の報酬 C ベクトル駆動コンポーネントの一種である期待効用を組み込んでい

1163
00:44:30,540 --> 00:44:32,819


1164
00:44:32,819 --> 00:44:35,240
ませんが、エージェントは状態

1165
00:44:35,240 --> 00:44:37,800
情報ゲインとパラメーター情報ゲームを使用します。

1166
00:44:37,800 --> 00:44:39,480
これらは他の 2 つのコンポーネントです。

1167
00:44:39,480 --> 00:44:42,119
自由エネルギーが期待されるため、さまざまな

1168
00:44:42,119 --> 00:44:43,500
方法で動作する

1169
00:44:43,500 --> 00:44:45,619
カスタムメイドのアクティブな推論エージェントを作成する方法はたくさんあります。

1170
00:44:45,619 --> 00:44:47,940


1171
00:44:47,940 --> 00:44:49,800


1172
00:44:49,800 --> 00:44:53,300
あなたが提供するこれらの種類の uh キーワード引数を使用します。

1173
00:44:54,060 --> 00:44:55,500


1174
00:44:55,500 --> 00:44:57,660
ええと、これは単なる例

1175
00:44:57,660 --> 00:44:58,920
です。この場合、アクティブな推論エージェントを使用

1176
00:44:58,920 --> 00:45:00,780
して、非表示の状態の推論を行うためだけに

1177
00:45:00,780 --> 00:45:03,060
アクションを実行しないため、エージェントは

1178
00:45:03,060 --> 00:45:04,980


1179
00:45:04,980 --> 00:45:07,200
更新中の非表示の状態を推論するだけです。  a行列についての信念

1180
00:45:07,200 --> 00:45:08,700
と、Dベクトルまたは初期の隠れ状態についての信念を更新している

1181
00:45:08,700 --> 00:45:11,099


1182
00:45:11,099 --> 00:45:12,960
ので

1183
00:45:12,960 --> 00:45:14,640
、これらすべての行を柔軟にまとめて、行動する必要さえ

1184
00:45:14,640 --> 00:45:16,380
ない、やりたいことを何でもするエージェントを作成することができます。

1185
00:45:16,380 --> 00:45:17,940


1186
00:45:17,940 --> 00:45:19,940
世界では技術的には

1187
00:45:19,940 --> 00:45:22,140
大丈夫ですので、マツ DP の動作例をいくつかお見せします。

1188
00:45:22,140 --> 00:45:25,859


1189
00:45:25,859 --> 00:45:28,800
これは古典的な

1190
00:45:28,800 --> 00:45:31,020
アクティブ推論ペーパーです。私のお気に入りのペーパーの 1 つです。

1191
00:45:31,020 --> 00:45:33,660
ええと

1192
00:45:33,660 --> 00:45:35,160
、シーン構築とアクティブ推論と呼ばれるものだと思います。

1193
00:45:35,160 --> 00:45:37,319


1194
00:45:37,319 --> 00:45:39,839
エージェントがしなければならないタスクを記述しており、これは精神物理学テスト

1195
00:45:39,839 --> 00:45:41,640
で人間のデータを実際にモデル化するために使用されました。

1196
00:45:41,640 --> 00:45:44,160


1197
00:45:44,160 --> 00:45:45,960


1198
00:45:45,960 --> 00:45:48,780


1199
00:45:48,780 --> 00:45:51,359
それらの中に特定の画像があり、

1200
00:45:51,359 --> 00:45:53,579
全部で 4 つの象限があり、その

1201
00:45:53,579 --> 00:45:56,579
うちの 2 つに関心のある画像が

1202
00:45:56,579 --> 00:45:59,460
あります。この場合の 2 つの

1203
00:45:59,460 --> 00:46:02,640
画像が鳥と猫の画像で

1204
00:46:02,640 --> 00:46:05,579
あり、それがノミのシーンの例である場合、

1205
00:46:05,579 --> 00:46:07,380
基本的にアジア人または 人間は

1206
00:46:07,380 --> 00:46:09,960


1207
00:46:09,960 --> 00:46:12,300
、2 つの画像を順番に組み合わせて単純に定義される潜在シーンを

1208
00:46:12,300 --> 00:46:15,540
分類し、次に

1209
00:46:15,540 --> 00:46:16,859
シーンを分類する必要があるため、基本的には分類

1210
00:46:16,859 --> 00:46:20,040
分類タスクですが、エージェントは

1211
00:46:20,040 --> 00:46:22,740
、

1212
00:46:22,740 --> 00:46:24,599
そのカテゴリが何であるかを知る前に、一連の手がかりを偶発的に発見する必要があり

1213
00:46:24,599 --> 00:46:27,720
ます。 つまり、そのシーンが何であるかということ

1214
00:46:27,720 --> 00:46:29,940
です。

1215
00:46:29,940 --> 00:46:31,380
アクティブな推論について私たち全員が知っていて愛している認識論的要素を組み合わせて、

1216
00:46:31,380 --> 00:46:33,660


1217
00:46:33,660 --> 00:46:36,180
積極的にサンプリングすることで世界の隠された状態を明らかにしようとする

1218
00:46:36,180 --> 00:46:38,400
ため、この場合、彼らは

1219
00:46:38,400 --> 00:46:39,720
目を別のものに動かして世界をサンプリングしています。

1220
00:46:39,720 --> 00:46:41,760


1221
00:46:41,760 --> 00:46:44,760
その背後にあるものを明らかにし

1222
00:46:44,760 --> 00:46:47,280


1223
00:46:47,280 --> 00:46:49,020
、世界について学んだことに基づいて真

1224
00:46:49,020 --> 00:46:50,160
のカテゴリが何であるかを実際に選択します。 正しく分類

1225
00:46:50,160 --> 00:46:51,780
することに関連する報酬があるため、ユーティリティを最大化しよう

1226
00:46:51,780 --> 00:46:55,140
としています。

1227
00:46:55,140 --> 00:46:57,180
これは、

1228
00:46:57,180 --> 00:46:58,740
もともとMatlabで行われた

1229
00:46:58,740 --> 00:47:01,020
ものの例であり、pi mdpで再実装したばかりです。

1230
00:47:01,020 --> 00:47:03,300
これは、シーンがフィードシーンである別の例です。

1231
00:47:03,300 --> 00:47:05,400


1232
00:47:05,400 --> 00:47:07,800
この例ではキュー

1233
00:47:07,800 --> 00:47:09,780
は下の 2 つの象限にある

1234
00:47:09,780 --> 00:47:12,359
ため、エージェントはさまざまな象限を見回す必要があります。

1235
00:47:12,359 --> 00:47:14,099
最終的には

1236
00:47:14,099 --> 00:47:15,839
、右下に鳥がいて、左下に

1237
00:47:15,839 --> 00:47:17,700
種があり、これ

1238
00:47:17,700 --> 00:47:20,880
がフィード シーンである必要があります。

1239
00:47:20,880 --> 00:47:22,980
ええと、

1240
00:47:22,980 --> 00:47:24,359
それがアクティブな推論で実際にどのように見えるかの例を示す

1241
00:47:24,359 --> 00:47:25,740


1242
00:47:25,740 --> 00:47:27,780
ために、そのコードはどのように見えるので、このために最初に

1243
00:47:27,780 --> 00:47:29,160
行うことは

1244
00:47:29,160 --> 00:47:31,140
、エージェントをセットアップすることです。

1245
00:47:31,140 --> 00:47:33,720
この場合の s と D

1246
00:47:33,720 --> 00:47:35,760


1247
00:47:35,760 --> 00:47:36,960


1248
00:47:36,960 --> 00:47:38,640
は、Matlab で使用されているものと同じ、マージナル メッセージ パッシングと呼ばれる特定のメッセージ パッシング アルゴリズムを使用しまし

1249
00:47:38,640 --> 00:47:42,180


1250
00:47:42,180 --> 00:47:43,680


1251
00:47:43,680 --> 00:47:45,420
た。 過去の

1252
00:47:45,420 --> 00:47:48,119
観察をどれだけ考慮

1253
00:47:48,119 --> 00:47:50,700
して環境をセットアップするかなどの記憶 これ

1254
00:47:50,700 --> 00:47:52,980
は

1255
00:47:52,980 --> 00:47:55,500
、エージェントがこの場合相互作用

1256
00:47:55,500 --> 00:47:57,420
する外部世界のようなものです 私はそれをシーン構築環境と呼んでい

1257
00:47:57,420 --> 00:47:59,520


1258
00:47:59,520 --> 00:48:01,920
ます エージェントは

1259
00:48:01,920 --> 00:48:03,300
特定の場所に目を移動します。

1260
00:48:03,300 --> 00:48:06,180
実際には、エージェントが次に見るものをどのように決定しますか。エージェントが

1261
00:48:06,180 --> 00:48:07,980
見る

1262
00:48:07,980 --> 00:48:09,720
ことを決定した象限の背後にあるものが何で

1263
00:48:09,720 --> 00:48:13,200


1264
00:48:13,200 --> 00:48:14,819


1265
00:48:14,819 --> 00:48:16,619
あるかがわかります。 知覚エージェントと環境をループしてから

1266
00:48:16,619 --> 00:48:18,780
、

1267
00:48:18,780 --> 00:48:21,900
一般的に行われるのは

1268
00:48:21,900 --> 00:48:24,300


1269
00:48:24,300 --> 00:48:26,880
、環境をリセットすることによって最初の初期観察を行うことです。これは、

1270
00:48:26,880 --> 00:48:29,760
openai gym から借用した慣例であり、

1271
00:48:29,760 --> 00:48:32,220
基本的には環境ドット リセットを実行します。これは

1272
00:48:32,220 --> 00:48:33,960
、吐き出す環境のメソッドのようなものです。

1273
00:48:33,960 --> 00:48:36,240
最初の観測を取り出して

1274
00:48:36,240 --> 00:48:37,619


1275
00:48:37,619 --> 00:48:39,359
から、観測インデックス間のマッピングを持つリストや辞書のようなものを作成すると、これらのことに役立つことがよくあり

1276
00:48:39,359 --> 00:48:41,819


1277
00:48:41,819 --> 00:48:43,800
ます これ

1278
00:48:43,800 --> 00:48:46,319
は、0 と多くの観測値の間の整数のような

1279
00:48:46,319 --> 00:48:48,420
ものであり、

1280
00:48:48,420 --> 00:48:49,619
それらが実際に意味的に対応するものです。

1281
00:48:49,619 --> 00:48:51,720
これは

1282
00:48:51,720 --> 00:48:54,000
、すべての Palm

1283
00:48:54,000 --> 00:48:56,700
DP と環境

1284
00:48:56,700 --> 00:48:59,220
が 2 と 0 の 1 のようなものになるため、非常に一般的な方法です。

1285
00:48:59,220 --> 00:49:00,780
これらはすべて個別のインデックスに似

1286
00:49:00,780 --> 00:49:02,700
ていますが、これらのリストを

1287
00:49:02,700 --> 00:49:04,980
使用し

1288
00:49:04,980 --> 00:49:07,920


1289
00:49:07,920 --> 00:49:09,740


1290
00:49:09,740 --> 00:49:14,160
て、鳥の画像を見たり

1291
00:49:14,160 --> 00:49:18,420
、カテゴリ 1 とカテゴリ 2

1292
00:49:18,420 --> 00:49:20,579
を選択したり、完了したら、特定のインデックスを意味のあるものにマッピングしたりするために使用できると便利です。

1293
00:49:20,579 --> 00:49:23,400


1294
00:49:23,400 --> 00:49:25,260
基本的に

1295
00:49:25,260 --> 00:49:27,240
、隠れ状態の

1296
00:49:27,240 --> 00:49:29,460
推定とポリシー推論

1297
00:49:29,460 --> 00:49:32,700
で構成されるアクティブな推論を実行するループを時間をかけて書くだけです。アクションをサンプリングし、

1298
00:49:32,700 --> 00:49:34,680
それが

1299
00:49:34,680 --> 00:49:37,079
環境にフィードバックされて別の

1300
00:49:37,079 --> 00:49:38,819
観察結果を生成し、それが

1301
00:49:38,819 --> 00:49:39,900
時間の経過とともに発生するので、 の全体的なアクションの

1302
00:49:39,900 --> 00:49:41,339
認識な

1303
00:49:41,339 --> 00:49:44,339
ので

1304
00:49:44,339 --> 00:49:45,720


1305
00:49:45,720 --> 00:49:48,119


1306
00:49:48,119 --> 00:49:49,920
、これはええとそうです。それは一見単純です。短いように見えますが、私は一種の光沢があります

1307
00:49:49,920 --> 00:49:51,359
後で話します

1308
00:49:51,359 --> 00:49:53,880
が、これは前に述べたのと同じくらい

1309
00:49:53,880 --> 00:49:55,619
簡単ですが、最も難しい部分は

1310
00:49:55,619 --> 00:49:57,720
、これが起こる前に実際に行われて

1311
00:49:57,720 --> 00:49:59,520


1312
00:49:59,520 --> 00:50:02,760
います。

1313
00:50:02,760 --> 00:50:05,460


1314
00:50:05,460 --> 00:50:06,839
アクティブな推論の集中的で複雑な部分

1315
00:50:06,839 --> 00:50:08,640
は、生成モデルを書き留めたら、実際に生成モデルを書き留めることです。

1316
00:50:08,640 --> 00:50:10,680


1317
00:50:10,680 --> 00:50:12,780
残りは基本的に時計仕掛けのようで

1318
00:50:12,780 --> 00:50:15,060
、エージェントを環境にリンクし、

1319
00:50:15,060 --> 00:50:17,160
5

1320
00:50:17,160 --> 00:50:19,560
行または6行のように実行するだけです 実際

1321
00:50:19,560 --> 00:50:20,819
に物事を実装するのは難しいのですが、最初に

1322
00:50:20,819 --> 00:50:22,560
これらの a b c と D を

1323
00:50:22,560 --> 00:50:24,799


1324
00:50:25,260 --> 00:50:27,119
書き留めることが最も難しい部分です。別の例を示します。

1325
00:50:27,119 --> 00:50:28,079


1326
00:50:28,079 --> 00:50:31,740
これは、チームメイトをステロイドで呼び出すようなものです。そのため、

1327
00:50:31,740 --> 00:50:33,960
古典的な teamaze タスクで

1328
00:50:33,960 --> 00:50:35,579
は、元の 論文

1329
00:50:35,579 --> 00:50:36,900
はありましたが、それ

1330
00:50:36,900 --> 00:50:37,980
は活発な推論の

1331
00:50:37,980 --> 00:50:39,599
文献でしばらくの間非常に人気のあるものでした

1332
00:50:39,599 --> 00:50:41,460
.カールはおそらく2015年かそれ以前に思いついたと思います.

1333
00:50:41,460 --> 00:50:44,700


1334
00:50:44,700 --> 00:50:48,119
エージェントにはマウスがあります. その環境で

1335
00:50:48,119 --> 00:50:51,180
報酬または罰の 2 つの潜在的なソースを訪問

1336
00:50:51,180 --> 00:50:53,160
する

1337
00:50:53,160 --> 00:50:55,619
必要があり、このチームメイトのどちらの腕に報酬が含まれているかがわからないため、どちらの腕に報酬があり、どちらの腕に報酬がないかを

1338
00:50:55,619 --> 00:50:58,020


1339
00:50:58,020 --> 00:51:00,300
知る前に、最初にキューにアクセスする必要があり

1340
00:51:00,300 --> 00:51:02,700
ます

1341
00:51:02,700 --> 00:51:04,559
報酬またはショックのようなもの 負の

1342
00:51:04,559 --> 00:51:07,200
刺激のようなもの

1343
00:51:07,200 --> 00:51:09,660
チームメイトを空間的に拡張しただけなので、

1344
00:51:09,660 --> 00:51:12,119
エージェントはキューのシーケンスにアクセスする必要があり

1345
00:51:12,119 --> 00:51:14,819
ます それぞれが

1346
00:51:14,819 --> 00:51:17,099
次のキューブの場所を明らかにし

1347
00:51:17,099 --> 00:51:19,559
、最終的なキューを把握します

1348
00:51:19,559 --> 00:51:22,619


1349
00:51:22,619 --> 00:51:24,359
これは、

1350
00:51:24,359 --> 00:51:26,520
エージェントが最初に q1 に移動し、次に

1351
00:51:26,520 --> 00:51:28,200
Q2 がどこにあるかを認識し、次にチーズがどこにあるかを認識する別の例です。

1352
00:51:28,200 --> 00:51:30,300


1353
00:51:30,300 --> 00:51:32,099
エージェントが実際に持っていないため、これを認識連鎖と呼び

1354
00:51:32,099 --> 00:51:34,740
ます。 その

1355
00:51:34,740 --> 00:51:37,020
ルートをチーズの最終的な場所に至るまで計画

1356
00:51:37,020 --> 00:51:38,940
するには、

1357
00:51:38,940 --> 00:51:41,280
次のqに到達するだけで、次の

1358
00:51:41,280 --> 00:51:43,880
キューがどこにあるのかが明らかになり、最終的に報酬の隠された場所がどこにあるのかが明らかになり

1359
00:51:43,880 --> 00:51:47,099
ます。

1360
00:51:47,099 --> 00:51:49,440
あなたは一種の

1361
00:51:49,440 --> 00:51:53,040
認識的価値や好奇心を利用して、

1362
00:51:53,040 --> 00:51:56,160
そうでなければ時間的に浅い動物が

1363
00:51:56,160 --> 00:51:58,800


1364
00:51:58,800 --> 00:52:00,839
遠くの報酬や私たちのアプリオリ

1365
00:52:00,839 --> 00:52:03,300
に到達することを計画できない何かへの道を計画できる

1366
00:52:03,300 --> 00:52:05,640


1367
00:52:05,640 --> 00:52:07,500
ようにして

1368
00:52:07,500 --> 00:52:09,059
います。 これは Pine DP のように見えますが、

1369
00:52:09,059 --> 00:52:10,500
基本的にはまったく

1370
00:52:10,500 --> 00:52:12,660
同じに見えます。環境

1371
00:52:12,660 --> 00:52:14,579
と生成モデルが異なるだけ

1372
00:52:14,579 --> 00:52:16,859
ですが、コードの一般的なフローには

1373
00:52:16,859 --> 00:52:21,619
常にこの種の古典的なパイプラインが

1374
00:52:21,839 --> 00:52:24,059
あります。

1375
00:52:24,059 --> 00:52:25,619
最も重要な部分

1376
00:52:25,619 --> 00:52:28,260
について

1377
00:52:28,260 --> 00:52:29,880
ですが、アクティブな推論に関する混乱の最大の原因は、

1378
00:52:29,880 --> 00:52:31,500
最も困難な部分は生成モデルである

1379
00:52:31,500 --> 00:52:34,319
という

1380
00:52:34,319 --> 00:52:36,599


1381
00:52:36,599 --> 00:52:38,280
ことだと思います。エージェントの世界に関する信念をエンコードする際に複雑さが生じる

1382
00:52:38,280 --> 00:52:40,079
のです。

1383
00:52:40,079 --> 00:52:41,460


1384
00:52:41,460 --> 00:52:44,099
深層ニューラル ネットワークや教師なし学習などのパラダイムでは、B と C と D

1385
00:52:44,099 --> 00:52:47,960


1386
00:52:47,960 --> 00:52:50,280
があり、最新のものを書き留める必要はありません。

1387
00:52:50,280 --> 00:52:51,740


1388
00:52:51,740 --> 00:52:54,540
ニューラル ネットワークは、

1389
00:52:54,540 --> 00:52:57,000
負荷と負荷を観察するだけでモデルを学習します。  f データな

1390
00:52:57,000 --> 00:52:59,040
ので、サンプル効率は低くなりますが、最初からエンコードする必要はありません。

1391
00:52:59,040 --> 00:53:01,319


1392
00:53:01,319 --> 00:53:03,119
これは

1393
00:53:03,119 --> 00:53:06,359


1394
00:53:06,359 --> 00:53:08,220
、モデル 3 と

1395
00:53:08,220 --> 00:53:10,140
、より深いニューラル ネットワークを使用したモデル ベースのアプローチの間の大きな差と一致するようなもの

1396
00:53:10,140 --> 00:53:12,619
です。 多数の非線形関数近似器をくっつけ

1397
00:53:12,619 --> 00:53:15,420


1398
00:53:15,420 --> 00:53:17,220
てモデルを書き留めなければならないという統計的複雑さをサンプルに効果的に発行

1399
00:53:17,220 --> 00:53:19,380


1400
00:53:19,380 --> 00:53:22,140


1401
00:53:22,140 --> 00:53:24,240
し、

1402
00:53:24,240 --> 00:53:25,619
エージェントがデータで攻撃するだけで世界について持っている信念を学習するだけ

1403
00:53:25,619 --> 00:53:27,480
です同じことが起こります

1404
00:53:27,480 --> 00:53:29,339


1405
00:53:29,339 --> 00:53:32,579
能動的推論における DQ 学習のような深層強化学習

1406
00:53:32,579 --> 00:53:35,160
エージェントは

1407
00:53:35,160 --> 00:53:36,300
、数十億のデータ ベクトルのようにトレーニングする必要がないという意味で、はるかにサンプル効率が高くなります

1408
00:53:36,300 --> 00:53:40,740
が

1409
00:53:40,740 --> 00:53:42,240
、その一方で

1410
00:53:42,240 --> 00:53:44,040
、モデル作成者としての投資はより多くなります。

1411
00:53:44,040 --> 00:53:45,900


1412
00:53:45,900 --> 00:53:48,359
世界に対するエージェントの信念を明示的に書き留めるために、畳み込み層やいくつかのレビューなどの

1413
00:53:48,359 --> 00:53:49,920
ような一般的なものを装備するだけではありません。

1414
00:53:49,920 --> 00:53:53,220


1415
00:53:53,220 --> 00:53:55,200
編では、

1416
00:53:55,200 --> 00:53:57,119
実際にコードをハンドリングする必要があることを学習させ

1417
00:53:57,119 --> 00:53:59,400
ます。これは、世界の

1418
00:53:59,400 --> 00:54:01,800


1419
00:54:01,800 --> 00:54:03,059


1420
00:54:03,059 --> 00:54:04,859
ベイジアン一般生成モデルを実際にエンコードするモデルベースの強化学習

1421
00:54:04,859 --> 00:54:07,020
と

1422
00:54:07,020 --> 00:54:08,940
、よりモデルフリーまたはデータ駆動型の

1423
00:54:08,940 --> 00:54:11,099
アプローチの種類との最大の違いの 1 つだと思いますが、 そのような

1424
00:54:11,099 --> 00:54:12,660
二分法はありません.2つを組み合わせる方法がありますが

1425
00:54:12,660 --> 00:54:14,099


1426
00:54:14,099 --> 00:54:16,980


1427
00:54:16,980 --> 00:54:18,720
、例えば

1428
00:54:18,720 --> 00:54:21,780
、私が数スライド前に示したこのシーン構築のデモで

1429
00:54:21,780 --> 00:54:23,460


1430
00:54:23,460 --> 00:54:25,940
、純粋な線の観点から見ると、それを非常に具体的に示すために.

1431
00:54:25,940 --> 00:54:28,680
どちらのコードがより多くのコードを

1432
00:54:28,680 --> 00:54:31,440
使用したか、コードの行数

1433
00:54:31,440 --> 00:54:34,559
を統計的な複雑さの代用として、または

1434
00:54:34,559 --> 00:54:36,660
含まれる情報の量を使用できるため

1435
00:54:36,660 --> 00:54:38,339
、アクティブな推論ループを実行するシミュレーション自体

1436
00:54:38,339 --> 00:54:40,140
は、15 行のコードのようでした。

1437
00:54:40,140 --> 00:54:42,300
彼らとそのコード

1438
00:54:42,300 --> 00:54:44,220
自体はすでに非常に一般的であり、生成モデル自体を作成

1439
00:54:44,220 --> 00:54:46,319
するシーン構築デモに固有のものではなく

1440
00:54:46,319 --> 00:54:48,359


1441
00:54:48,359 --> 00:54:49,920
、すべての重労働が

1442
00:54:49,920 --> 00:54:51,119
行われます。

1443
00:54:51,119 --> 00:54:53,520
そのタスクに固有のすべての情報が

1444
00:54:53,520 --> 00:54:55,980
エンコードされる場所です。たとえば、アクティブな推論全体を

1445
00:54:55,980 --> 00:54:58,260


1446
00:54:58,260 --> 00:55:00,540


1447
00:55:00,540 --> 00:55:02,520


1448
00:55:02,520 --> 00:55:05,460
実行するよりもはるかに多くのコードのように、シーン構築デモの観測マッピングに関する信念のマトリックスをどのように作成したかを確認するだけです。

1449
00:55:05,460 --> 00:55:07,859
シミュレーションの

1450
00:55:07,859 --> 00:55:09,540
ように、コードの膨大な量から

1451
00:55:09,540 --> 00:55:11,220
すでにわかるよう

1452
00:55:11,220 --> 00:55:13,200


1453
00:55:13,200 --> 00:55:15,119
に、生成モデルに焼き付けられている多くの仮定と情報が

1454
00:55:15,119 --> 00:55:16,559


1455
00:55:16,559 --> 00:55:18,480
あり、アクティブな推論の重労働のほとんどは

1456
00:55:18,480 --> 00:55:21,260
実際にはそこから来ている

1457
00:55:21,300 --> 00:55:22,559
ので、私は それについて言及することは重要だと思います。それは、離散状態空間でアクティブな推論モデルを使い始めたい

1458
00:55:22,559 --> 00:55:24,300


1459
00:55:24,300 --> 00:55:26,640
と思っている人なら誰でも頭を包み込むべきだと思う本当に重要なことだ

1460
00:55:26,640 --> 00:55:28,440


1461
00:55:28,440 --> 00:55:30,599


1462
00:55:30,599 --> 00:55:32,220


1463
00:55:32,220 --> 00:55:34,559
からです。モデルがほとんど

1464
00:55:34,559 --> 00:55:36,420
の作業を行うということです。 あなたにとって、期待される自由

1465
00:55:36,420 --> 00:55:38,040
エネルギーはい、多くの利点を持つ非常に興味深い

1466
00:55:38,040 --> 00:55:39,660
目的関数です

1467
00:55:39,660 --> 00:55:41,880
が、

1468
00:55:41,880 --> 00:55:44,700
能動的推論の力のほとんどは 世界

1469
00:55:44,700 --> 00:55:46,740
についてのあなたのエージェントの信念が何であるかを書き留めることに

1470
00:55:46,740 --> 00:55:48,300
なり、それが得られたら

1471
00:55:48,300 --> 00:55:50,520
、残りのすべて

1472
00:55:50,520 --> 00:55:52,980
の作業はあなたのために行われます.pi NDBコード

1473
00:55:52,980 --> 00:55:55,440
は非常に一般的であるため、一般的ではないのは

1474
00:55:55,440 --> 00:55:56,880
、

1475
00:55:56,880 --> 00:55:59,000
世界

1476
00:55:59,400 --> 00:56:01,680
ええと、大丈夫だから、今はちょっと終わっている

1477
00:56:01,680 --> 00:56:03,960
ところです。ちょっとその部分だけにこだわる必要があるかもしれません。これについて

1478
00:56:03,960 --> 00:56:05,460
考えやコメント、質問がある人はい

1479
00:56:05,460 --> 00:56:08,579
ますか？

1480
00:56:08,579 --> 00:56:12,359
もしそうでなければ、

1481
00:56:12,359 --> 00:56:16,460
ダフネやジェイコブを終わらせるか、尋ねます

1482
00:56:21,300 --> 00:56:23,520
質問はありません。

1483
00:56:23,520 --> 00:56:25,680


1484
00:56:25,680 --> 00:56:28,079
エージェントの生成モデルの仕様を強調しました

1485
00:56:28,079 --> 00:56:29,099


1486
00:56:29,099 --> 00:56:31,680
が、コインの反対側についてはどうですか。

1487
00:56:31,680 --> 00:56:34,740
生成プロセスを

1488
00:56:34,740 --> 00:56:37,680
どのように指定するのですか。エージェントの環境をどのように指定するのです

1489
00:56:37,680 --> 00:56:40,399


1490
00:56:40,440 --> 00:56:41,880
か。 いい質問ですね

1491
00:56:41,880 --> 00:56:44,520
基本的に私が生成モデルについて述べたことはすべて

1492
00:56:44,520 --> 00:56:46,680


1493
00:56:46,680 --> 00:56:48,540
生成

1494
00:56:48,540 --> 00:56:50,099
プロセスにも当てはまります

1495
00:56:50,099 --> 00:56:53,520
エージェントの興味深い行動を除いて

1496
00:56:53,520 --> 00:56:55,500
ええ 生成プロセスについて考えることができるということです

1497
00:56:55,500 --> 00:56:57,059
sもそれの多くを駆動するので

1498
00:56:57,059 --> 00:56:58,200


1499
00:56:58,200 --> 00:57:00,059
、ボトルネックは

1500
00:57:00,059 --> 00:57:01,920
生成モデルだと思います。なぜなら、

1501
00:57:01,920 --> 00:57:04,140
非常に複雑な生成プロセスを作成すると、

1502
00:57:04,140 --> 00:57:05,819
あらゆる種類の派手な非線形ダイナミクスを備えた非常に複雑な環境になります

1503
00:57:05,819 --> 00:57:08,579
が

1504
00:57:08,579 --> 00:57:10,319
、エージェントの世界モデルは超

1505
00:57:10,319 --> 00:57:12,420
スーパーです 単純なので、オンまたはオフ

1506
00:57:12,420 --> 00:57:14,400
のいずれかのライトスイッチを知っていると信じているだけです。その

1507
00:57:14,400 --> 00:57:16,440


1508
00:57:16,440 --> 00:57:18,839


1509
00:57:18,839 --> 00:57:22,200
ような単純なエージェントから取得できる可能な動作は

1510
00:57:22,200 --> 00:57:23,880
、その生成モデルの複雑さによって制限される

1511
00:57:23,880 --> 00:57:28,020
ため、非常に複雑な生成は

1512
00:57:28,020 --> 00:57:29,760
非常に単純な生成モデルになります。 複雑な生成プロセスに埋め込まれていても、まだ

1513
00:57:29,760 --> 00:57:33,000
非常に興味深い動作を示すわけではありません

1514
00:57:33,000 --> 00:57:34,619


1515
00:57:34,619 --> 00:57:37,079
が、最もリッチな

1516
00:57:37,079 --> 00:57:38,700
ダイナミクスは

1517
00:57:38,700 --> 00:57:40,500
、複雑な生成プロセス

1518
00:57:40,500 --> 00:57:44,040
と複雑な生成モデルの両方がある場合に明らかに発生するため

1519
00:57:44,040 --> 00:57:46,920
、生成モデルを構築する際のすべての作業

1520
00:57:46,920 --> 00:57:48,660
は

1521
00:57:48,660 --> 00:57:50,760
ここでの最初の行は、生成プロセス

1522
00:57:50,760 --> 00:57:52,319
を生成する際の多くの作業によっても一致する可能性が

1523
00:57:52,319 --> 00:57:54,900


1524
00:57:54,900 --> 00:57:56,760
あります。

1525
00:57:56,760 --> 00:57:58,319
これは

1526
00:57:58,319 --> 00:58:00,660
、エージェントがキューの場所にいるときに一連のルールである世界環境です。

1527
00:58:00,660 --> 00:58:03,000


1528
00:58:03,000 --> 00:58:04,920
このようなキュー ID を表示するのは比較的

1529
00:58:04,920 --> 00:58:06,359
単純です

1530
00:58:06,359 --> 00:58:08,760
が、考えると興味深いことが 1 つあり

1531
00:58:08,760 --> 00:58:10,920
ます。ダニエルが

1532
00:58:10,920 --> 00:58:13,260
考えたように、 これについては

1533
00:58:13,260 --> 00:58:15,000
、能動的推論に関するあなたの仕事を知っていると思います.

1534
00:58:15,000 --> 00:58:17,099
集団行動は

1535
00:58:17,099 --> 00:58:18,960
マルチエージェントの興味深い点です

1536
00:58:18,960 --> 00:58:21,300
行動はその場合、生成

1537
00:58:21,300 --> 00:58:25,020
プロセスは他のエージェントのアクションである

1538
00:58:25,020 --> 00:58:26,819
ため、生成プロセスは私の生成

1539
00:58:26,819 --> 00:58:28,980
プロセスは実際には

1540
00:58:28,980 --> 00:58:31,020
これ

1541
00:58:31,020 --> 00:58:32,819
は、

1542
00:58:32,819 --> 00:58:34,500
Daphne と私が and を行っているときに取り組まなければならなかった最も複雑なことの 1 つで

1543
00:58:34,500 --> 00:58:36,720
あり、Mao も

1544
00:58:36,720 --> 00:58:38,339
Mao は認識コミュニティの最初の著者であり、

1545
00:58:38,339 --> 00:58:40,500
これは

1546
00:58:40,500 --> 00:58:43,140
ソーシャル ネットワーク Echo Chamber のように機能します。

1547
00:58:43,140 --> 00:58:45,119
その文脈では

1548
00:58:45,119 --> 00:58:47,880


1549
00:58:47,880 --> 00:58:49,980
、プロセス自体が

1550
00:58:49,980 --> 00:58:51,660
他のアクティブな推論エージェントで構成されているため、生成プロセスはもう少し困難です。

1551
00:58:51,660 --> 00:58:54,780
また、そのコードの制御フローは、

1552
00:58:54,780 --> 00:58:55,980


1553
00:58:55,980 --> 00:58:57,420


1554
00:58:57,420 --> 00:59:00,599
すべてのエージェントをループしてそれらからアクションを取得し、

1555
00:59:00,599 --> 00:59:02,400
それらのアクションを使用

1556
00:59:02,400 --> 00:59:03,720
して他のすべてのエージェントの観察をパラメータ化する必要がある場合に、そのコードの制御

1557
00:59:03,720 --> 00:59:05,760
フローが少し異なるように見えます。 一般的な

1558
00:59:05,760 --> 00:59:08,099
マルチエージェント シミュレーションに関する

1559
00:59:08,099 --> 00:59:10,440
一般的なステートメントですが、

1560
00:59:10,440 --> 00:59:12,240


1561
00:59:12,240 --> 00:59:14,400
他のエージェントをモデル化しようとするエージェントについて考えると、特に興味深いことです。

1562
00:59:14,400 --> 00:59:16,740
なぜなら、ほとんどの場合、すべてのアクティブな

1563
00:59:16,740 --> 00:59:18,119
推論エージェントは

1564
00:59:18,119 --> 00:59:20,400
、世界がどのように機能するかについて貧弱なモデルを持って

1565
00:59:20,400 --> 00:59:23,819
いるからです。

1566
00:59:23,819 --> 00:59:25,500
相互作用するアクティブな推論エージェントの束で

1567
00:59:25,500 --> 00:59:27,000


1568
00:59:27,000 --> 00:59:29,819
あるため、すべてのエージェントに無限の再帰の深さを持たせ、独自の生成モデルでシミュレートできるようにする場合を除き、必然的に各エージェント

1569
00:59:29,819 --> 00:59:31,500
に、より単純化された生成モデルを装備する必要があります。

1570
00:59:31,500 --> 00:59:33,660


1571
00:59:33,660 --> 00:59:35,460


1572
00:59:35,460 --> 00:59:37,859


1573
00:59:37,859 --> 00:59:39,480
他のすべてのエージェントの生成モデルな

1574
00:59:39,480 --> 00:59:41,940
ので、ええと、それ

1575
00:59:41,940 --> 00:59:43,020
はマルチエージェントのケースについてのちょっとした接線だったということです

1576
00:59:43,020 --> 00:59:44,460
が、私はそれだと思います.

1577
00:59:44,460 --> 00:59:46,619


1578
00:59:46,619 --> 00:59:49,140


1579
00:59:49,140 --> 00:59:51,119


1580
00:59:51,119 --> 00:59:52,680
生成モデルの複雑さと

1581
00:59:52,680 --> 00:59:54,480
生成プロセスの複雑さの間の緊張関係と、

1582
00:59:54,480 --> 00:59:56,579
それらがお互いの動作を相互に制約する方法について考えるのは、非常に興味深い複合体です。

1583
00:59:56,579 --> 00:59:59,480


1584
01:00:02,400 --> 01:00:04,799
ええと、そうそう

1585
01:00:04,799 --> 01:00:06,540
、最後の 2 つのスライドを進めましょうか。

1586
01:00:06,540 --> 01:00:09,720
これはエキサイティングなことだと思うので、ここに

1587
01:00:09,720 --> 01:00:11,099


1588
01:00:11,099 --> 01:00:13,500
将来的にプライム

1589
01:00:13,500 --> 01:00:15,480
DP でやりたいことのリスト

1590
01:00:15,480 --> 01:00:16,980
を示します.

1591
01:00:16,980 --> 01:00:19,319
そのため、Pine DP

1592
01:00:19,319 --> 01:00:21,299
モデルを経験的データに

1593
01:00:21,299 --> 01:00:23,160


1594
01:00:23,160 --> 01:00:24,960


1595
01:00:24,960 --> 01:00:26,460


1596
01:00:26,460 --> 01:00:30,299


1597
01:00:30,299 --> 01:00:32,520
当てはめることは重要なので、Palm DP アクティブ

1598
01:00:32,520 --> 01:00:34,740
推論モデルである人間の行動のモデルを実際に作成することに関心のある計算精神医学コミュニティの人々と多くのやり取りをしました。

1599
01:00:34,740 --> 01:00:37,020
松DPの現在の最大の制限

1600
01:00:37,020 --> 01:00:40,319
は、pi mdpを使用して、Sでできるタスクを実行している人間の被験者

1601
01:00:40,319 --> 01:00:42,900
のようなアクティブな推論パラメーターを推論

1602
01:00:42,900 --> 01:00:44,819


1603
01:00:44,819 --> 01:00:47,220
できないことだと思います

1604
01:00:47,220 --> 01:00:48,540
現在PMですが、残念ながら

1605
01:00:48,540 --> 01:00:51,540
Pion VPではそれを行うことができないため、これは

1606
01:00:51,540 --> 01:00:53,339
優先順位リストの非常に高いものであり、

1607
01:00:53,339 --> 01:00:55,020


1608
01:00:55,020 --> 01:00:58,440


1609
01:00:58,440 --> 01:00:59,640


1610
01:00:59,640 --> 01:01:02,640
Pi mdpモデルの適合に関心のあるコミュニティにとって、プライマリPが実際にSPMと競合するようになるのに役立つと思います. つまり、これら

1611
01:01:02,640 --> 01:01:03,780
は計算精神医学のようなより経験的な

1612
01:01:03,780 --> 01:01:05,040
科学分野のような

1613
01:01:05,040 --> 01:01:08,040


1614
01:01:08,040 --> 01:01:10,440
ものです。他のことは、生成モデル

1615
01:01:10,440 --> 01:01:12,059
を実際に生成および構築するためのより良いインターフェースが必要だと思います

1616
01:01:12,059 --> 01:01:13,859


1617
01:01:13,859 --> 01:01:17,460


1618
01:01:17,460 --> 01:01:19,559
.AおよびBマトリックスの構築に関連するすべてのコードが実際

1619
01:01:19,559 --> 01:01:21,180
にボトルネックになります. アクティブな推論をしようとしている人にとって

1620
01:01:21,180 --> 01:01:23,280
、そして大部分は

1621
01:01:23,280 --> 01:01:25,319
、複雑で寛大なモデルのためにそれらの配列を構築

1622
01:01:25,319 --> 01:01:27,839
することは本当に

1623
01:01:27,839 --> 01:01:29,280
頭痛の種になる可能性があるため、この奇妙

1624
01:01:29,280 --> 01:01:31,680
な多次元インデックスをすべて実行

1625
01:01:31,680 --> 01:01:33,000
する必要が

1626
01:01:33,000 --> 01:01:34,920
あります。 対応する余分な次元の数が異なる

1627
01:01:34,920 --> 01:01:37,079
大規模な多次元配列を作成する必要があります

1628
01:01:37,079 --> 01:01:39,180


1629
01:01:39,180 --> 01:01:41,160


1630
01:01:41,160 --> 01:01:42,720


1631
01:01:42,720 --> 01:01:44,460
世界で起こりうるこれらすべての不測の事態は、変数間の

1632
01:01:44,460 --> 01:01:47,339
すべての関係をエンコードする必要がある大規模なルックアップテーブルになるため、

1633
01:01:47,339 --> 01:01:49,680


1634
01:01:49,680 --> 01:01:51,480
これは

1635
01:01:51,480 --> 01:01:52,859
野心的なプロジェクトである可能性があると思いますが、ユーザーの

1636
01:01:52,859 --> 01:01:55,619
ようなUIを実際に作成する方法があるかもしれません

1637
01:01:55,619 --> 01:01:58,440


1638
01:01:58,440 --> 01:02:00,540


1639
01:02:00,540 --> 01:02:02,579
たとえば一連の質問を

1640
01:02:02,579 --> 01:02:04,200


1641
01:02:04,200 --> 01:02:05,760


1642
01:02:05,760 --> 01:02:08,339


1643
01:02:08,339 --> 01:02:10,440


1644
01:02:10,440 --> 01:02:12,180
することで生成モデルを構築するのに役立つインターフェース

1645
01:02:12,180 --> 01:02:13,740
マトリックススケッチ

1646
01:02:13,740 --> 01:02:15,900
ウィンドウの実際の構造 世界のさまざまな不測の事態についてのはいいいえの質問のシーケンスへの

1647
01:02:15,900 --> 01:02:17,160


1648
01:02:17,160 --> 01:02:19,740


1649
01:02:19,740 --> 01:02:21,900
別のことは

1650
01:02:21,900 --> 01:02:24,119


1651
01:02:24,119 --> 01:02:26,099
、私たちがこれを行ったいくつかの例があるように、私たちがすでに

1652
01:02:26,099 --> 01:02:28,079
行っているopenaiジムとのインターフェースです 私はまだこれら

1653
01:02:28,079 --> 01:02:31,020
を GitHub のインフラに積極的に載せていませんが、これは公開されて

1654
01:02:31,020 --> 01:02:32,880
いるものであり、これは

1655
01:02:32,880 --> 01:02:35,160
非常に明白で簡単な

1656
01:02:35,160 --> 01:02:37,500
ことのようなものです。 とにかくジム環境である

1657
01:02:37,500 --> 01:02:40,020
かのように基づいているかのように環境クラスを書いた

1658
01:02:40,020 --> 01:02:42,240
ように、

1659
01:02:42,240 --> 01:02:43,859
一度それを行うと、

1660
01:02:43,859 --> 01:02:45,780
アクティブな推論エージェントを階層モデルのあらゆる

1661
01:02:45,780 --> 01:02:46,920
種類の強化学習

1662
01:02:46,920 --> 01:02:48,000
アルゴリズムと比較することができます。

1663
01:02:48,000 --> 01:02:51,780


1664
01:02:51,780 --> 01:02:54,140
基本的に、

1665
01:02:54,140 --> 01:02:56,099
階層的にアクティブな推論エージェント

1666
01:02:56,099 --> 01:02:58,559
を相互にスタックできるようにするので、アクティブな推論エージェントを階層的なものにスタック

1667
01:02:58,559 --> 01:03:00,119
することで、多くの時間的な深さを得ることができます。

1668
01:03:00,119 --> 01:03:02,579


1669
01:03:02,579 --> 01:03:05,160


1670
01:03:05,160 --> 01:03:07,680
たとえば、推論と計画の 1 つの時間スケールがより遅い時間スケールで

1671
01:03:07,680 --> 01:03:10,200
行われるようになります。  aサブよりも遅い より

1672
01:03:10,200 --> 01:03:12,420
速いタイムスケール パラメータ学習

1673
01:03:12,420 --> 01:03:14,520
を示すデモがもっと必要な

1674
01:03:14,520 --> 01:03:16,140
ので

1675
01:03:16,140 --> 01:03:19,020
、b配列とd配列の更新を行う

1676
01:03:19,020 --> 01:03:21,299
ことができます これまでのところCを更新できないと思いますが、

1677
01:03:21,299 --> 01:03:22,740
これはDanielが

1678
01:03:22,740 --> 01:03:25,140
私に言及したことです

1679
01:03:25,140 --> 01:03:26,700
アクティブな推論研究所の人々は、基本的に生成モデルのパラメーターに関する信念を更新することに一般的に

1680
01:03:26,700 --> 01:03:28,079
興味を持ってい

1681
01:03:28,079 --> 01:03:29,640


1682
01:03:29,640 --> 01:03:31,200
ます。

1683
01:03:31,200 --> 01:03:32,460


1684
01:03:32,460 --> 01:03:34,319
洗練された推論は

1685
01:03:34,319 --> 01:03:36,000
、アクティブな推論の下での計画の最新バージョンであり

1686
01:03:36,000 --> 01:03:37,440


1687
01:03:37,440 --> 01:03:40,200
、興味深いものであり、

1688
01:03:40,200 --> 01:03:42,480
計算上の利点が

1689
01:03:42,480 --> 01:03:43,799
あり、洗練された

1690
01:03:43,799 --> 01:03:45,839
推論と連携

1691
01:03:45,839 --> 01:03:47,700
して、人々が開発したこのことは、深い強化で対処する必要がありまし

1692
01:03:47,700 --> 01:03:49,140
た。 しばらくの間

1693
01:03:49,140 --> 01:03:51,720
、どのようにして組み合わせ

1694
01:03:51,720 --> 01:03:53,460
爆発的な政策空間を飼いならすかを学びます.

1695
01:03:53,460 --> 01:03:56,280
時間の経過とともに深い計画を立てているとき

1696
01:03:56,280 --> 01:03:58,200
、政策の数は

1697
01:03:58,200 --> 01:04:01,020
、計画する時間ステップの数で指数関数的であるため

1698
01:04:01,020 --> 01:04:03,720
、それに対処するためのさまざまな手法があります.

1699
01:04:03,720 --> 01:04:05,339
モンテカルロ ツリー

1700
01:04:05,339 --> 01:04:07,200
検索のように、teofio Champions などの一部の人々

1701
01:04:07,200 --> 01:04:09,380


1702
01:04:09,380 --> 01:04:11,640


1703
01:04:11,640 --> 01:04:14,700
は、パーム DPS の独自の実装をすでに実装しよ

1704
01:04:14,700 --> 01:04:17,040
う

1705
01:04:17,040 --> 01:04:19,079
としていると思います。

1706
01:04:19,079 --> 01:04:21,059


1707
01:04:21,059 --> 01:04:23,339
Pi mdp モデルを経験的データに当てはめている

1708
01:04:23,339 --> 01:04:25,980
ので、Dimitri

1709
01:04:25,980 --> 01:04:27,420
markovic と私が行ったブランチがあります。

1710
01:04:27,420 --> 01:04:29,579
エージェントの Jax Branch を呼び出して、

1711
01:04:29,579 --> 01:04:31,680
基本的に pione p と Jax のバックエンドを作成しました。

1712
01:04:31,680 --> 01:04:35,160
これにより、

1713
01:04:35,160 --> 01:04:37,319


1714
01:04:37,319 --> 01:04:39,420
numpyro などの一連の統計的確率論的推論手法を

1715
01:04:39,420 --> 01:04:42,480
使用して、Pi mdp エージェントのパラメータを反転または推論することができます。

1716
01:04:42,480 --> 01:04:44,819


1717
01:04:44,819 --> 01:04:47,280
人間の参加者から収集されたインスタンスの計算です

1718
01:04:47,280 --> 01:04:49,920
が、ジャックでもバックエンドであるという事実

1719
01:04:49,920 --> 01:04:52,440
は、Pi mdp

1720
01:04:52,440 --> 01:04:54,299
が完全に自動微分可能で

1721
01:04:54,299 --> 01:04:56,460
あることを意味するため、pi VP の行列レイヤーの前にディープ ニューラル ネットワーク レイヤーをスタックできることを意味します。

1722
01:04:56,460 --> 01:04:59,400


1723
01:04:59,400 --> 01:05:01,799


1724
01:05:01,799 --> 01:05:03,420
エージェントと

1725
01:05:03,420 --> 01:05:05,460
、変分自由エネルギーや

1726
01:05:05,460 --> 01:05:07,500
その他の目的関数のようなものを使用

1727
01:05:07,500 --> 01:05:09,660


1728
01:05:09,660 --> 01:05:11,880
して、pi VP エージェントにリンクされているニューラル ネットワークのパラメーターを自動的にトレーニング

1729
01:05:11,880 --> 01:05:14,280
できるので、これを

1730
01:05:14,280 --> 01:05:16,260
Pi torch や Jacks などのバックエンドに再実装するだけだと思います

1731
01:05:16,260 --> 01:05:18,720


1732
01:05:18,720 --> 01:05:20,700


1733
01:05:20,700 --> 01:05:22,680


1734
01:05:22,680 --> 01:05:25,640


1735
01:05:25,640 --> 01:05:28,260
深いニューラル ネットワークをさまざまな

1736
01:05:28,260 --> 01:05:31,020
コンポーネント o にリンクすることにより、pione P をより多くの高次元状態空間に拡張できるようになるため、これは大きな利点のようなものです。 あなた

1737
01:05:31,020 --> 01:05:33,119
が説明していた

1738
01:05:33,119 --> 01:05:34,619
ようにエージェントの体 ダニエルええと、もともと

1739
01:05:34,619 --> 01:05:36,359
経験的データのフィッティングを可能にするためにこれを行いました

1740
01:05:36,359 --> 01:05:38,700


1741
01:05:38,700 --> 01:05:41,280


1742
01:05:41,280 --> 01:05:43,619


1743
01:05:43,619 --> 01:05:45,559
が、使用するバックプロパゲート勾配のように微分して渡すことができるという副次的な利点があります ディープ ラーニング

1744
01:05:45,559 --> 01:05:48,119
モデルの更新は非常にエキサイティングだと思います

1745
01:05:48,119 --> 01:05:51,299
ので、ほぼ完了し

1746
01:05:51,299 --> 01:05:53,579
ています。つまり、実際にそれを行うノートブックの作成に非常に近づいているということです。

1747
01:05:53,579 --> 01:05:55,559


1748
01:05:55,559 --> 01:05:57,180
エージェントのジャックのブランチを見ると、

1749
01:05:57,180 --> 01:05:58,980
あまり組織化されていませんが、そのようなものです。

1750
01:05:58,980 --> 01:06:01,680
現在そこにあり、

1751
01:06:01,680 --> 01:06:04,799
別のことを実装しています サジドではなく、私は

1752
01:06:04,799 --> 01:06:07,020
実際に

1753
01:06:07,020 --> 01:06:09,480
彼女の論文のアクティブな推論からいくつかの環境を実装し、

1754
01:06:09,480 --> 01:06:11,339
比較

1755
01:06:11,339 --> 01:06:15,180
して分かりやすくしました。実際

1756
01:06:15,180 --> 01:06:16,980
に、凍った湖の環境のよう

1757
01:06:16,980 --> 01:06:19,380
に openai ジムで pi MVP を使用してそれを行いました。  Bマトリックスの学習をシミュレートしている

1758
01:06:19,380 --> 01:06:20,640


1759
01:06:20,640 --> 01:06:21,839
ので、それ

1760
01:06:21,839 --> 01:06:24,599
は私たちがやったのと同じようなものであり

1761
01:06:24,599 --> 01:06:26,520
、それをアップロードする必要があるか

1762
01:06:26,520 --> 01:06:28,079
、短い論文を書くかはわかりません。 それについては、調査

1763
01:06:28,079 --> 01:06:29,700


1764
01:06:29,700 --> 01:06:31,200
されたこれらのさまざまな巻きひげ

1765
01:06:31,200 --> 01:06:33,359
のようなものがたくさんあるので、それは単に

1766
01:06:33,359 --> 01:06:34,799
前進し、実際にそれら

1767
01:06:34,799 --> 01:06:37,500
を松のBP

1768
01:06:37,500 --> 01:06:39,359
レポに載せることの問題ですええ、そして私

1769
01:06:39,359 --> 01:06:42,000
がする時間を見つけたいと思っているこれらの他のことですが、 私はそうで

1770
01:06:42,000 --> 01:06:43,799
はありませんが、最初に言ったように

1771
01:06:43,799 --> 01:06:44,940
、これは非常に

1772
01:06:44,940 --> 01:06:47,039
共同作業であったため

1773
01:06:47,039 --> 01:06:48,660


1774
01:06:48,660 --> 01:06:50,700
、必ずしもこれらすべてを行うのが好きな人になりたくはありません。

1775
01:06:50,700 --> 01:06:52,380


1776
01:06:52,380 --> 01:06:54,180


1777
01:06:54,180 --> 01:06:55,680
さまざまな人々が

1778
01:06:55,680 --> 01:06:57,480
さまざまなことをリードし

1779
01:06:57,480 --> 01:06:58,980
て独自の方法で開発している場合のパッケージの開発。これは、

1780
01:06:58,980 --> 01:07:00,480
私が一般的に奨励したい

1781
01:07:00,480 --> 01:07:03,059
ことであり、あらゆる種類の関心のある

1782
01:07:03,059 --> 01:07:04,140
人々が開発に参加することを奨励しています。

1783
01:07:04,140 --> 01:07:05,520


1784
01:07:05,520 --> 01:07:08,339
ブレナンがここにいるとは思いませんが、ノースイースタン大学ネットワーク科学研究所

1785
01:07:08,339 --> 01:07:11,000
のポスドクおよび研究科学者でもあるブレナン・クライン

1786
01:07:11,000 --> 01:07:12,839


1787
01:07:12,839 --> 01:07:13,920


1788
01:07:13,920 --> 01:07:15,240
は、

1789
01:07:15,240 --> 01:07:17,880
これらの Pi mdp フェローシップを開始した

1790
01:07:17,880 --> 01:07:20,339
ため、N から資金を得ました。

1791
01:07:20,339 --> 01:07:21,960
ortheastern また、Templeton

1792
01:07:21,960 --> 01:07:24,420
Foundation は、

1793
01:07:24,420 --> 01:07:26,400
Pine MVP 開発またはプライム DP

1794
01:07:26,400 --> 01:07:28,619
隣接プロジェクトに取り組む人々に資金を提供すると思います。第 1

1795
01:07:28,619 --> 01:07:30,839
ラウンドのアプリケーションは終了したと思い

1796
01:07:30,839 --> 01:07:32,099
ますが、これは

1797
01:07:32,099 --> 01:07:33,839
宣伝する良い機会になると思い

1798
01:07:33,839 --> 01:07:35,339
ます。 夏に別のコホートが参加

1799
01:07:35,339 --> 01:07:38,000
するため、これは

1800
01:07:38,000 --> 01:07:40,680
一見継続的な資金源のように見えるので

1801
01:07:40,680 --> 01:07:42,359
、他の人

1802
01:07:42,359 --> 01:07:45,180
が Pine VP を自分の方向に押し進めようとしているのを見るのは素晴らしいことです。

1803
01:07:45,180 --> 01:07:47,339


1804
01:07:47,339 --> 01:07:48,839


1805
01:07:48,839 --> 01:07:52,319
ええと、

1806
01:07:52,319 --> 01:07:54,299
ええと、最後

1807
01:07:54,299 --> 01:07:56,359


1808
01:07:57,240 --> 01:08:00,180
に、

1809
01:08:00,180 --> 01:08:01,740
自動ドキュメントを作成するのに非常に便利なドキュメントWebサイトを読むことで、ええと患者で終わります。

1810
01:08:01,740 --> 01:08:03,960
そこにはたくさんの

1811
01:08:03,960 --> 01:08:05,460
デモがあります。さまざまなチュートリアルがあり

1812
01:08:05,460 --> 01:08:07,440


1813
01:08:07,440 --> 01:08:09,539
ます。別の新しいデモがあります

1814
01:08:09,539 --> 01:08:11,160


1815
01:08:11,160 --> 01:08:13,140


1816
01:08:13,140 --> 01:08:15,480


1817
01:08:15,480 --> 01:08:17,939
Ryan Smith と

1818
01:08:17,939 --> 01:08:20,040
Christopher white と Carl fursten の

1819
01:08:20,040 --> 01:08:20,819
pap のデモに基づいた離散カテゴリ モデルで自由エネルギーの変動を計算するだけの、ここには記載されていません。

1820
01:08:20,819 --> 01:08:23,698
ええと、アクティブな推論に関する大きなチュートリアル ペーパーとは異なり、

1821
01:08:23,698 --> 01:08:26,100


1822
01:08:26,100 --> 01:08:28,319
そのペーパーのデモの 1 つを再実装し

1823
01:08:28,319 --> 01:08:31,020
ました。これはドキュメントにも含まれている

1824
01:08:31,020 --> 01:08:33,060
ので、コラボでこれらすべてのデモ ノートブックを開いて、それらをステップ実行することができます。

1825
01:08:33,060 --> 01:08:35,100


1826
01:08:35,100 --> 01:08:36,960
「実際に

1827
01:08:36,960 --> 01:08:38,880
は

1828
01:08:38,880 --> 01:08:40,198
、コンピュータに Python をインストールして使用する必要は

1829
01:08:40,198 --> 01:08:42,600
ありません。collab でリンクを開いてコードをステップ実行

1830
01:08:42,600 --> 01:08:44,460
し、独自の

1831
01:08:44,460 --> 01:08:46,259
アクティブな推論エージェントを構築

1832
01:08:46,259 --> 01:08:48,238
するだけでよいので、教育学に役立ちます。その

1833
01:08:48,238 --> 01:08:49,259
ため、私は言及しました。 始めたばかりの場合は、ドキュメントにアクセスする

1834
01:08:49,259 --> 01:08:50,880
ことをお勧めします。

1835
01:08:50,880 --> 01:08:54,238


1836
01:08:54,238 --> 01:08:56,698
そうです、聞いてくれてありがとう

1837
01:08:56,698 --> 01:08:59,640
、そして話す機会を与えてくれてありがとう。

1838
01:08:59,640 --> 01:09:01,799


1839
01:09:01,799 --> 01:09:05,640
いつものようにここにいてよかったです。 ええ、

1840
01:09:05,640 --> 01:09:07,620
私は次のライブ ストリームの一番下にリストしまし

1841
01:09:07,620 --> 01:09:08,939


1842
01:09:08,939 --> 01:09:10,738
た。デモ ノートブックのいくつ

1843
01:09:10,738 --> 01:09:12,660
か

1844
01:09:12,660 --> 01:09:14,279
を確認できますが、時間があれば、最初にディスカッションを行ってから、時間があることを確認することもできます。

1845
01:09:14,279 --> 01:09:15,179


1846
01:09:15,179 --> 01:09:17,880


1847
01:09:17,880 --> 01:09:21,540


1848
01:09:21,540 --> 01:09:25,140
ダフネとジェイコブからのいくつかの質問に答えましょう。

1849
01:09:25,140 --> 01:09:28,140
ライブ チャットからいくつ

1850
01:09:28,140 --> 01:09:31,738
か質問します。それから、ドキュメントを

1851
01:09:31,738 --> 01:09:34,920
読んで 1 つまたはいくつかの例を共有してください。

1852
01:09:34,920 --> 01:09:36,479


1853
01:09:36,479 --> 01:09:40,140
解剖学と生理学が何であるかを構造的に見てみましょう。

1854
01:09:40,140 --> 01:09:42,899
ノートブックなので、まず

1855
01:09:42,899 --> 01:09:46,080
ダフネまたはジェイコブについて

1856
01:09:46,080 --> 01:09:49,339
考えや質問

1857
01:09:52,679 --> 01:09:56,120
をして

1858
01:09:56,400 --> 01:09:58,620
くださいええと、ええと、ジャックの実装について疑問に思ってい

1859
01:09:58,620 --> 01:10:00,300


1860
01:10:00,300 --> 01:10:03,660
ますが

1861
01:10:03,660 --> 01:10:07,400
、生成プロセスを定義するための要件

1862
01:10:07,500 --> 01:10:11,160
はまったくあるのでしょうか、それとも単に構造を定義するだけなのでしょうか?

1863
01:10:11,160 --> 01:10:13,140
これ

1864
01:10:13,140 --> 01:10:14,820


1865
01:10:14,820 --> 01:10:16,199


1866
01:10:16,199 --> 01:10:18,840
は、これらのモデルを状態空間または一般的なプロセスにスケーリングする際に私が持っていた別の質問にも関連していると思い

1867
01:10:18,840 --> 01:10:21,780
ます。

1868
01:10:21,780 --> 01:10:24,179
モデラーとして

1869
01:10:24,179 --> 01:10:27,000
、実際に自分自身を定義する自由はありませんが、

1870
01:10:27,000 --> 01:10:28,699


1871
01:10:28,699 --> 01:10:31,159
展開したい

1872
01:10:31,159 --> 01:10:34,739
これらのエージェントを、

1873
01:10:34,739 --> 01:10:37,080


1874
01:10:37,080 --> 01:10:39,780
カテゴリ別または

1875
01:10:39,780 --> 01:10:42,500
個別の

1876
01:10:42,600 --> 01:10:45,360
データが入ってくる

1877
01:10:45,360 --> 01:10:46,920
オンライン設定

1878
01:10:46,920 --> 01:10:48,960
のように

1879
01:10:48,960 --> 01:10:51,360
、すでに存在する一般的なプロセスでトレーニングします。 うーん、素晴らしい質問です。

1880
01:10:51,360 --> 01:10:54,659
私は、

1881
01:10:54,659 --> 01:10:56,159
多数のディープ ニューラル ネットワークが接続

1882
01:10:56,159 --> 01:10:59,580
されたプラン BP エージェントを持っていて、展開された設定でそれをトレーニングしたかった

1883
01:10:59,580 --> 01:11:01,320
ので

1884
01:11:01,320 --> 01:11:03,179
、エージェントだとしましょう。

1885
01:11:03,179 --> 01:11:04,739
それは株式市場で取引されているか

1886
01:11:04,739 --> 01:11:06,300


1887
01:11:06,300 --> 01:11:09,060
、暗号通貨のように購入するために賭けをするようなもの

1888
01:11:09,060 --> 01:11:09,960


1889
01:11:09,960 --> 01:11:12,659
です。その場合、同じように

1890
01:11:12,659 --> 01:11:14,280
、その種のデータでディープ ニューラル ネットワークをトレーニングするのと同じように

1891
01:11:14,280 --> 01:11:16,320


1892
01:11:16,320 --> 01:11:18,120
、生成プロセスに勾配を渡す必要はありません。 もちろん

1893
01:11:18,120 --> 01:11:20,159


1894
01:11:20,159 --> 01:11:22,320
、株式市場で取引している場合はアクセスできないので、その意味では、勾配

1895
01:11:22,320 --> 01:11:24,420
を渡すことや、自動微分可能な生成プロセスを作成することについての要件はありません。それが必要

1896
01:11:24,420 --> 01:11:27,300


1897
01:11:27,300 --> 01:11:30,060
な

1898
01:11:30,060 --> 01:11:32,820
場合が1つあります。

1899
01:11:32,820 --> 01:11:34,739


1900
01:11:34,739 --> 01:11:37,980
多くの場合、経験的に

1901
01:11:37,980 --> 01:11:40,800
Pine DP モデルをデータに適合させる場合、多くの場合、

1902
01:11:40,800 --> 01:11:43,020
やりたいことの 1 つ

1903
01:11:43,020 --> 01:11:45,000
は、基本的に人間の参加

1904
01:11:45,000 --> 01:11:47,219
者の行動と観察の履歴を持ち

1905
01:11:47,219 --> 01:11:49,679
、モデルに

1906
01:11:49,679 --> 01:11:52,140
適合させるようなものをたくさん持っていることです。 参加者

1907
01:11:52,140 --> 01:11:54,360
の観察されたアクションを最もよく説明する pi VP エージェントのパラメーター

1908
01:11:54,360 --> 01:11:55,920


1909
01:11:55,920 --> 01:11:57,120
。あなたは

1910
01:11:57,120 --> 01:11:59,219
実験者であり、この

1911
01:11:59,219 --> 01:12:00,480
人が観察のシーケンスを見ることを決定した

1912
01:12:00,480 --> 01:12:02,400
ので、微分可能性なしですべてを行うことができるため、観察を知っています。

1913
01:12:02,400 --> 01:12:04,380


1914
01:12:04,380 --> 01:12:07,380
生成プロセスまたは環境です

1915
01:12:07,380 --> 01:12:09,000
が、ベイジアン

1916
01:12:09,000 --> 01:12:10,860
推論には事後予測チェックのように呼ばれるもの

1917
01:12:10,860 --> 01:12:12,960
があります。

1918
01:12:12,960 --> 01:12:16,620
ピオーネ P エージェントのパラメーターに関する私の推論を考えると、

1919
01:12:16,620 --> 01:12:18,840


1920
01:12:18,840 --> 01:12:20,520


1921
01:12:20,520 --> 01:12:23,100
このエージェントの予想される動作をロールアウトしたいと思います。

1922
01:12:23,100 --> 01:12:25,560
このエージェントのパラメーターが何であるかについての私の最善の推測を考える

1923
01:12:25,560 --> 01:12:27,840
と

1924
01:12:27,840 --> 01:12:29,640
、それは事後予測密度のように呼ば

1925
01:12:29,640 --> 01:12:32,400
れます.エージェントのパラメーターに関する私の事後um推定が与えられると、

1926
01:12:32,400 --> 01:12:34,500


1927
01:12:34,500 --> 01:12:37,080


1928
01:12:37,080 --> 01:12:39,480
これらの事後パラメーターの下で将来どのように見えるでしょ

1929
01:12:39,480 --> 01:12:42,840
うか. バックエンドとして Jax を使用

1930
01:12:42,840 --> 01:12:45,420
する確率的推論フレームワークである numpyro を使用すると

1931
01:12:45,420 --> 01:12:47,699


1932
01:12:47,699 --> 01:12:49,800
、ジェネレーティブが必要になります。

1933
01:12:49,800 --> 01:12:52,679
自動微分可能なプロセスでもあります

1934
01:12:52,679 --> 01:12:54,659
が、その場合、

1935
01:12:54,659 --> 01:12:56,400
それらの生成プロセスを書くの

1936
01:12:56,400 --> 01:12:58,020
は簡単だと思います。なぜなら

1937
01:12:58,020 --> 01:13:01,199
、人間の行動を

1938
01:13:01,199 --> 01:13:02,820


1939
01:13:02,820 --> 01:13:05,159
制御されたタスク環境のような実験データに適合させる場合だ

1940
01:13:05,159 --> 01:13:07,739
からです。  Cベクトルの値のような誰かのパラメータに適合させようとする場合、

1941
01:13:07,739 --> 01:13:10,320


1942
01:13:10,320 --> 01:13:12,420


1943
01:13:12,420 --> 01:13:13,860
彼らは病気でそのシーン構築タスクを実行しています.

1944
01:13:13,860 --> 01:13:15,300


1945
01:13:15,300 --> 01:13:17,040
あなたは生成プロセスを書くことができます.

1946
01:13:17,040 --> 01:13:18,840


1947
01:13:18,840 --> 01:13:21,480


1948
01:13:21,480 --> 01:13:22,739


1949
01:13:22,739 --> 01:13:24,659


1950
01:13:24,659 --> 01:13:26,460
モデリングを行っているときにJaxでも書くことができるので、

1951
01:13:26,460 --> 01:13:28,620
これらの事後予測チェックを行っているときに

1952
01:13:28,620 --> 01:13:30,300
、それもJacksで書かれて

1953
01:13:30,300 --> 01:13:31,620
おり、それらの量を計算できる

1954
01:13:31,620 --> 01:13:33,900
が、展開された設定であることがわかります

1955
01:13:33,900 --> 01:13:35,460


1956
01:13:35,460 --> 01:13:37,140


1957
01:13:37,140 --> 01:13:39,179


1958
01:13:39,179 --> 01:13:41,219
環境が実際にどのように機能するかがわからないため、将来的にはあらゆる種類の事後予測チェックを行うことさえできなくなります。  ht

1959
01:13:41,219 --> 01:13:43,080
ですから

1960
01:13:43,080 --> 01:13:44,940
、それ

1961
01:13:44,940 --> 01:13:47,520
はそもそもあなたがやろうとしたことでさえないということをあなたに伝えなければなりませんが、

1962
01:13:47,520 --> 01:13:48,540
ええと

1963
01:13:48,540 --> 01:13:52,020


1964
01:13:52,020 --> 01:13:54,000
、モデルが

1965
01:13:54,000 --> 01:13:55,140
同じ方法で微分可能である限り、本質的にあなたを止めるものは何もありません. ディープニューラル

1966
01:13:55,140 --> 01:13:56,219
ネットワーク世界

1967
01:13:56,219 --> 01:13:57,659


1968
01:13:57,659 --> 01:13:58,980
のルールがどのように機能するかを知らない環境にそれらを投げ込むことを止めるものは何も

1969
01:13:58,980 --> 01:14:01,940


1970
01:14:02,640 --> 01:14:04,199


1971
01:14:04,199 --> 01:14:06,900
ありませんええ、自然

1972
01:14:06,900 --> 01:14:10,620
選択または自由エネルギー最小化または

1973
01:14:10,620 --> 01:14:13,080
単に非平衡システムの容赦ない論理は、

1974
01:14:13,080 --> 01:14:15,239
彼らが知っているかどうかに関係なく

1975
01:14:15,239 --> 01:14:16,020


1976
01:14:16,020 --> 01:14:18,900
うまくいくかうまくいかないかのどちらかで

1977
01:14:18,900 --> 01:14:21,600
あり、失敗すれば失敗し、

1978
01:14:21,600 --> 01:14:23,940
計算環境により

1979
01:14:23,940 --> 01:14:25,860
、この種のグレーゾーンに存在することができ

1980
01:14:25,860 --> 01:14:28,260


1981
01:14:28,260 --> 01:14:30,719


1982
01:14:30,719 --> 01:14:33,300
ます. は

1983
01:14:33,300 --> 01:14:35,880
引き続き実行されますが、もちろん

1984
01:14:35,880 --> 01:14:38,300
、コンピューター プログラムが実行さ

1985
01:14:38,300 --> 01:14:42,120
れ、エージェントが何らかの

1986
01:14:42,120 --> 01:14:43,100


1987
01:14:43,100 --> 01:14:47,520
意味のある、または有用でさえある動作を

1988
01:14:47,520 --> 01:14:49,860
、私たちとまったく同じようにイベントできる場合に関心があります。

1989
01:14:49,860 --> 01:14:52,620
非常に単純な Prime DP モデル

1990
01:14:52,620 --> 01:14:54,420
が、いくつかのタスクで非常にうまく機能することを想像でき

1991
01:14:54,420 --> 01:14:56,340
ますか? 2 つの

1992
01:14:56,340 --> 01:14:57,960
隠れた状態を持ち、

1993
01:14:57,960 --> 01:14:59,580
確率論的に互いに切り替わる

1994
01:14:59,580 --> 01:15:02,340
と信じているダムモデルのように、それに投資を行うというタスクを与えることができますか?

1995
01:15:02,340 --> 01:15:05,520
10

1996
01:15:05,520 --> 01:15:07,679
株のポートフォリオのように、もちろんそのモデル

1997
01:15:07,679 --> 01:15:10,739
は適合しません

1998
01:15:10,739 --> 01:15:13,800


1999
01:15:13,800 --> 01:15:15,780
が、Prime DPエージェントのさまざまな端に大きな深層関数近似器を適用するという約束

2000
01:15:15,780 --> 01:15:18,179
は、うまくいけば

2001
01:15:18,179 --> 01:15:20,760
、良い生成モデルを学び、

2002
01:15:20,760 --> 01:15:22,739
それをいくつかのより低いものと組み合わせることができることを意味します

2003
01:15:22,739 --> 01:15:24,719


2004
01:15:24,719 --> 01:15:26,400


2005
01:15:26,400 --> 01:15:28,380
アクティブな推論ですべての優れた推論と計画を実行

2006
01:15:28,380 --> 01:15:31,320
できる上に、次元の生成モデルを使用しますが、ディープ ニューラル ネットワークを使用することで、高次元または醜い

2007
01:15:31,320 --> 01:15:33,420
観察と行動空間を飼いならすのが難しい

2008
01:15:33,420 --> 01:15:36,360
ため

2009
01:15:36,360 --> 01:15:39,000
、それが本当に正しい方法だと思います。

2010
01:15:39,000 --> 01:15:40,800
深層学習が多くの場合に機能するようになったのと同じよう

2011
01:15:40,800 --> 01:15:42,659
に、これ

2012
01:15:42,659 --> 01:15:45,120
はプライムDPモデルと同様にそれを行う方法です

2013
01:15:45,120 --> 01:15:48,120


2014
01:15:48,120 --> 01:15:50,940
ダフネ任意の発言 または

2015
01:15:50,940 --> 01:15:53,719
、

2016
01:15:54,540 --> 01:15:55,920
チャットでいくつか質問します 質問はありませんが、

2017
01:15:55,920 --> 01:15:57,960
本当に魅力的だ

2018
01:15:57,960 --> 01:16:00,000


2019
01:16:00,000 --> 01:16:02,040
と思います。あなたが言った

2020
01:16:02,040 --> 01:16:06,300
ように、

2021
01:16:06,300 --> 01:16:07,800


2022
01:16:07,800 --> 01:16:10,560
現実世界のデータのように与えられた独自の生成モデルを学習するエージェント

2023
01:16:10,560 --> 01:16:12,480
は、それら

2024
01:16:12,480 --> 01:16:14,040
が何であるかを理解するのが

2025
01:16:14,040 --> 01:16:15,600
好きです。関数

2026
01:16:15,600 --> 01:16:18,480
近似やnumpyroなどで話していた

2027
01:16:18,480 --> 01:16:22,140
ことに関しては、あなたはまだ好きです

2028
01:16:22,140 --> 01:16:24,239
まだそのコードベースのように機能していて

2029
01:16:24,239 --> 01:16:27,360
、最終的にそれらを変換するか、

2030
01:16:27,360 --> 01:16:29,100
それをゼロから始めました。

2031
01:16:29,100 --> 01:16:31,320
ええ、ほとんどゼロから始めまし

2032
01:16:31,320 --> 01:16:33,659
た.pi DCMの

2033
01:16:33,659 --> 01:16:35,400
ことです。

2034
01:16:35,400 --> 01:16:37,260


2035
01:16:37,260 --> 01:16:39,060
ネストされた鉱山の一部としてそれを使用しているため、私は

2036
01:16:39,060 --> 01:16:40,500
もうそのコードにアクセスできませんが

2037
01:16:40,500 --> 01:16:43,260


2038
01:16:43,260 --> 01:16:46,739
、それは私たちが取り組んでいた変分 LaPlace のように実装されて

2039
01:16:46,739 --> 01:16:48,900
いました。

2040
01:16:48,900 --> 01:16:51,960
ええと、私たちが現在行っていることを推測しようとしているときに

2041
01:16:51,960 --> 01:16:54,060
、自由エネルギーで勾配降下を行うということでは

2042
01:16:54,060 --> 01:16:56,460


2043
01:16:56,460 --> 01:16:59,640
なく、勾配を通過できるように

2044
01:16:59,640 --> 01:17:02,400
マツDPモデルを書き直すことができると言っています。

2045
01:17:02,400 --> 01:17:03,600


2046
01:17:03,600 --> 01:17:06,600


2047
01:17:06,600 --> 01:17:09,420
グラデーションを作成し

2048
01:17:09,420 --> 01:17:11,400
、numpyro を使用して、

2049
01:17:11,400 --> 01:17:13,020
変分 LaPlace だけでなく、あらゆる種類のフィッティング ルーチンを実行し

2050
01:17:13,020 --> 01:17:16,080
ますが、numpower の

2051
01:17:16,080 --> 01:17:18,540
ように使用できる mcmc を使用できます

2052
01:17:18,540 --> 01:17:21,440


2053
01:17:21,440 --> 01:17:24,179


2054
01:17:24,179 --> 01:17:25,679


2055
01:17:25,679 --> 01:17:28,380


2056
01:17:28,380 --> 01:17:31,800
主要な DP モデルでの numpyro 推論手法

2057
01:17:31,800 --> 01:17:34,080
の課題であるため、主要な DP モデルを書き直すだけで

2058
01:17:34,080 --> 01:17:36,239


2059
01:17:36,239 --> 01:17:38,280


2060
01:17:38,280 --> 01:17:40,440
、Palm DP パラメーターのようなものから

2061
01:17:40,440 --> 01:17:42,420
観測値に至る尤度関数を定義することができます。この場合

2062
01:17:42,420 --> 01:17:45,300
、エージェントのアクションになります。 そして、Jax と友好的に

2063
01:17:45,300 --> 01:17:47,040
プレイできるような方法でそれ

2064
01:17:47,040 --> 01:17:48,780
を行うために、推論のような pine DP エージェントの

2065
01:17:48,780 --> 01:17:51,300
すべての内部機能を確認する必要がありました。

2066
01:17:51,300 --> 01:17:53,340


2067
01:17:53,340 --> 01:17:55,679
計画アクションの選択はすべて

2068
01:17:55,679 --> 01:17:58,199
Jacks で書かれているので、

2069
01:17:58,199 --> 01:18:00,000
勾配を渡すときに勾配を渡すことが

2070
01:18:00,000 --> 01:18:03,199


2071
01:18:03,199 --> 01:18:05,699


2072
01:18:05,699 --> 01:18:07,380


2073
01:18:07,380 --> 01:18:09,900
でき

2074
01:18:09,900 --> 01:18:13,140


2075
01:18:13,140 --> 01:18:15,360
ます 文献全体のアクティブな推論の説明

2076
01:18:15,360 --> 01:18:17,100


2077
01:18:17,100 --> 01:18:19,380
は行列の観点から書かれていますが、Pi mdp は明らか

2078
01:18:19,380 --> 01:18:20,880
にテンソルで動作

2079
01:18:20,880 --> 01:18:23,340
します。行列からテンソルへの方程式を一般化するときに操作がどのように異なるかについての良い参考文献はありますか?

2080
01:18:23,340 --> 01:18:24,960


2081
01:18:24,960 --> 01:18:27,120


2082
01:18:27,120 --> 01:18:28,940


2083
01:18:28,940 --> 01:18:31,260


2084
01:18:31,260 --> 01:18:32,100
これは本当に良い点です。これはその 1 つです。 私が

2085
01:18:32,100 --> 01:18:33,840


2086
01:18:33,840 --> 01:18:35,159
アクティブな推論について初めて学んだときに実際

2087
01:18:35,159 --> 01:18:37,340
に私を大いに苛立たせたのは、この人が尋ねたことに正確に気づい

2088
01:18:37,340 --> 01:18:40,260
たという

2089
01:18:40,260 --> 01:18:42,000


2090
01:18:42,000 --> 01:18:42,540


2091
01:18:42,540 --> 01:18:45,960


2092
01:18:45,960 --> 01:18:47,520


2093
01:18:47,520 --> 01:18:50,580
こと

2094
01:18:50,580 --> 01:18:53,159
です。 彼らが言ったように、行列ベクトル積

2095
01:18:53,159 --> 01:18:54,840
と行列数学ですが、実際に

2096
01:18:54,840 --> 01:18:57,239
行っているのはテンソル乗算と

2097
01:18:57,239 --> 01:19:00,239
テンソル積なので、それが

2098
01:19:00,239 --> 01:19:03,060
どのように機能するかについての参照に関しては、

2099
01:19:03,060 --> 01:19:05,940
そうです、基本的

2100
01:19:05,940 --> 01:19:07,800
に質的に異なるものは何もありません

2101
01:19:07,800 --> 01:19:10,260


2102
01:19:10,260 --> 01:19:12,600
。pione Pで行うこれらのテンソル演算は、基本的

2103
01:19:12,600 --> 01:19:15,600


2104
01:19:15,600 --> 01:19:17,880
に行列乗算の合計を表現するより洗練された方法であるため

2105
01:19:17,880 --> 01:19:20,280
、その数学があります すべての

2106
01:19:20,280 --> 01:19:22,380
標準的な線形代数は

2107
01:19:22,380 --> 01:19:24,060


2108
01:19:24,060 --> 01:19:25,920
、テンソルがより

2109
01:19:25,920 --> 01:19:27,120
効率的な表現であるため、これらの高次元行列を表現

2110
01:19:27,120 --> 01:19:29,880


2111
01:19:29,880 --> 01:19:32,340
する方法にすぎないため、数学的にはそれほど

2112
01:19:32,340 --> 01:19:34,800
クレイジーでは

2113
01:19:34,800 --> 01:19:37,260
ありません. 私はちょうど

2114
01:19:37,260 --> 01:19:38,820
それを理解しましたが、それは簡単ではありませんでしたし、

2115
01:19:38,820 --> 01:19:41,580
間違いなくより良いオプション

2116
01:19:41,580 --> 01:19:42,900
が今そこにあり

2117
01:19:42,900 --> 01:19:45,600
ます。

2118
01:19:45,600 --> 01:19:48,719


2119
01:19:48,719 --> 01:19:50,460


2120
01:19:50,460 --> 01:19:52,920


2121
01:19:52,920 --> 01:19:55,739
付録 a

2122
01:19:55,739 --> 01:19:57,960
またはこれらすべての付録では、基本的に、行列を

2123
01:19:57,960 --> 01:20:01,199
扱っていない完全なテンソル分解バージョンを扱っていると思います

2124
01:20:01,199 --> 01:20:03,179
が、

2125
01:20:03,179 --> 01:20:05,100
私たちは実際に高次元にインデックスを付けています.

2126
01:20:05,100 --> 01:20:09,120


2127
01:20:09,120 --> 01:20:11,460
最初はテンソル積について議論している

2128
01:20:11,460 --> 01:20:13,860
と思います.テンソル因数分解

2129
01:20:13,860 --> 01:20:16,500
は付録にあると思います.活発な

2130
01:20:16,500 --> 01:20:18,540
推論の好奇心と洞察力.

2131
01:20:18,540 --> 01:20:19,679


2132
01:20:19,679 --> 01:20:21,719


2133
01:20:21,719 --> 01:20:23,820
論文

2134
01:20:23,820 --> 01:20:25,199
申し訳ありませんが、発表された年は覚えていません

2135
01:20:25,199 --> 01:20:27,900
。2017 年か 2018 年のどちら

2136
01:20:27,900 --> 01:20:30,420
かですが、論文のタイトルがアクティブな推論の好奇心と洞察力と呼ばれていることは知って

2137
01:20:30,420 --> 01:20:32,340


2138
01:20:32,340 --> 01:20:34,440
います。

2139
01:20:34,440 --> 01:20:38,580


2140
01:20:38,580 --> 01:20:41,820
最後に、もう 1 つの良い参考文献は、テオフィオ チャンピオン

2141
01:20:41,820 --> 01:20:44,640
が率いると思われる最近の論文

2142
01:20:44,640 --> 01:20:48,780
です。これを

2143
01:20:48,780 --> 01:20:50,760
忘れたくないので、すぐに見つけようと思います。問題がなけれ

2144
01:20:50,760 --> 01:20:52,739


2145
01:20:52,739 --> 01:20:55,679
ば画面の共有をやめるかもしれません。

2146
01:20:55,679 --> 01:20:58,800
それは停止しました

2147
01:20:58,800 --> 01:20:59,580
ええと、

2148
01:20:59,580 --> 01:21:01,080
それは本当に良いリファレンスです。

2149
01:21:01,080 --> 01:21:02,760


2150
01:21:02,760 --> 01:21:04,500


2151
01:21:04,500 --> 01:21:07,920
ええと

2152
01:21:07,920 --> 01:21:11,600
、アクティブ推論のためにテンソル計算を行うことについての付録があります。特に

2153
01:21:13,260 --> 01:21:15,600
、分岐時間のアクティブ推論についても最近学びました

2154
01:21:15,600 --> 01:21:18,360
w これ

2155
01:21:18,360 --> 01:21:20,040
は、計算の複雑さに関するこれらの問題のいくつかについて語ってい

2156
01:21:20,040 --> 01:21:24,480
ます。そして

2157
01:21:26,219 --> 01:21:27,840
、

2158
01:21:27,840 --> 01:21:29,699
そうです、アクティブな推論の計算の複雑さを微調整するための、

2159
01:21:29,699 --> 01:21:31,380
おそらくこれまでで最も有望なアプローチのようなものであると言及する必要がありまし

2160
01:21:31,380 --> 01:21:33,960


2161
01:21:33,960 --> 01:21:37,080


2162
01:21:37,080 --> 01:21:38,820


2163
01:21:38,820 --> 01:21:41,400
た。そうです、これは teofio によるもの

2164
01:21:41,400 --> 01:21:44,580
です。 チャンピオン Mark gresh

2165
01:21:44,580 --> 01:21:46,440
それは彼のアドバイザーの 1 人であり、Howard

2166
01:21:46,440 --> 01:21:49,560
Bowman は彼のもう 1 つのアドバイザーであり

2167
01:21:49,560 --> 01:21:51,600


2168
01:21:51,600 --> 01:21:53,400


2169
01:21:53,400 --> 01:21:55,620
、私が投稿したばかりの multimodal and multi-factor branching time active inference と呼ばれているので、自分で読んだことはありませ

2170
01:21:55,620 --> 01:21:57,000
んが、次のような他の人から聞いたことがあります。

2171
01:21:57,000 --> 01:21:59,040
アレック チャンスは、付録は技術にとって非常に優れていると私に言ったと思います。

2172
01:21:59,040 --> 01:22:01,920


2173
01:22:01,920 --> 01:22:03,780


2174
01:22:03,780 --> 01:22:05,940
アクティブな推論の完全なテンソル一般化は

2175
01:22:05,940 --> 01:22:08,699
大丈夫です

2176
01:22:08,699 --> 01:22:09,540


2177
01:22:09,540 --> 01:22:12,239
。YouTube ライブ チャットに言及されたすべての引用を追加し

2178
01:22:12,239 --> 01:22:13,920


2179
01:22:13,920 --> 01:22:16,500
ました。ありがとうございます。質問します。

2180
01:22:16,500 --> 01:22:19,560


2181
01:22:19,560 --> 01:22:22,739
Jax バックエンドを使用する Fausto からの次の質問により、pi mc3 を

2182
01:22:22,739 --> 01:22:24,020
ラップして

2183
01:22:24,020 --> 01:22:28,800
MC3 を適用することが容易になります。

2184
01:22:28,800 --> 01:22:32,219
例えば、pi mdp を pi MC3 モデルで使用する演算子として持つことができます。

2185
01:22:32,219 --> 01:22:35,580
これを行う計画はありますか?Pi MC3 の周りに Python で

2186
01:22:35,580 --> 01:22:37,320
成長しているベイジアン コミュニティがあるので、私は尋ねます。

2187
01:22:37,320 --> 01:22:41,880


2188
01:22:41,880 --> 01:22:43,380
それは本当に興味深いこと

2189
01:22:43,380 --> 01:22:46,199
です。Prime G3 にも

2190
01:22:46,199 --> 01:22:48,719
ジャックが戻ってきたことを実際に

2191
01:22:48,719 --> 01:22:51,600
は知りませんでした。 正直

2192
01:22:51,600 --> 01:22:52,980
に言うと、Python での確率モデリングの

2193
01:22:52,980 --> 01:22:55,080
ようなものへの私の紹介

2194
01:22:55,080 --> 01:22:57,840


2195
01:22:57,840 --> 01:23:00,300


2196
01:23:00,300 --> 01:23:02,880
は、基本的に numpyro で私を売った DME Dimitri markovic を通してだったので、わかりません。

2197
01:23:02,880 --> 01:23:04,920


2198
01:23:04,920 --> 01:23:06,840
ジャックのバックエンドと

2199
01:23:06,840 --> 01:23:10,440
numpyro と Pi MC3 は、Python

2200
01:23:10,440 --> 01:23:13,199
の確率的推論のエコシステムで同様の場所を占めていると思います

2201
01:23:13,199 --> 01:23:16,020


2202
01:23:16,020 --> 01:23:18,300
ええと、モデルが pi MC3 でどのように指定されているかわかり

2203
01:23:18,300 --> 01:23:22,020
ません numpyro での外観とあまり似ていないと思います。

2204
01:23:22,020 --> 01:23:24,300


2205
01:23:24,300 --> 01:23:26,520
低レベルのバックエンド

2206
01:23:26,520 --> 01:23:29,880
はすべて Jax で記述され

2207
01:23:29,880 --> 01:23:31,860
ています。これを約束することはできませんが

2208
01:23:31,860 --> 01:23:34,140
、pi MC3 モデルを記述できると仮定します。同じように、

2209
01:23:34,140 --> 01:23:36,480


2210
01:23:36,480 --> 01:23:40,500
um Pi mdp 関数をラップする numpyro モデルを記述しましたが、

2211
01:23:40,500 --> 01:23:43,620
pi MVP の実装 注入するので、

2212
01:23:43,620 --> 01:23:46,020
Pine Z3が低低レベルのJaxにのみ依存している

2213
01:23:46,020 --> 01:23:48,600
場合、はい、確かに機能します

2214
01:23:48,600 --> 01:23:50,699
が、

2215
01:23:50,699 --> 01:23:53,040
松G3を使用した経験

2216
01:23:53,040 --> 01:23:55,320
があり、知っているかもしれない他の誰かがここにいるかどうか

2217
01:23:55,320 --> 01:23:56,820
はわかりません。

2218
01:23:56,820 --> 01:23:58,560


2219
01:23:58,560 --> 01:24:01,320
私はYMCを少し使用しましたが

2220
01:24:01,320 --> 01:24:03,239
、あなたが言ったように

2221
01:24:03,239 --> 01:24:05,400
、numpyroに非常に似ていると思います.おそらく

2222
01:24:05,400 --> 01:24:07,560


2223
01:24:07,560 --> 01:24:10,080


2224
01:24:10,080 --> 01:24:12,480
、numpyrerで行っているのと同じことができると思います。

2225
01:24:12,480 --> 01:24:15,540
pi MC3も

2226
01:24:15,540 --> 01:24:18,360
クールで、それが主要なバック

2227
01:24:18,360 --> 01:24:19,800
エンドです。Jax

2228
01:24:19,800 --> 01:24:21,239
は

2229
01:24:21,239 --> 01:24:25,099
、ええと、私は実際にそれをして

2230
01:24:25,620 --> 01:24:28,460
いませんでした。ええと、どちらも知りませんでした。Matlab

2231
01:24:28,460 --> 01:24:31,980
の行列乗算と比較して

2232
01:24:31,980 --> 01:24:35,219


2233
01:24:35,219 --> 01:24:37,380
、

2234
01:24:37,380 --> 01:24:40,980
確率論に興奮する理由 プログラミングの方向と、

2235
01:24:40,980 --> 01:24:42,780


2236
01:24:42,780 --> 01:24:44,820
名前を付けているこれらのパッケージとアプローチのすべて

2237
01:24:44,820 --> 01:24:48,179
確率的プログラミング

2238
01:24:48,179 --> 01:24:51,420
は、行列を書き出し

2239
01:24:51,420 --> 01:24:54,000
て紙に計算するだけとどう違うのですか?なぜ

2240
01:24:54,000 --> 01:24:56,880
それは

2241
01:24:56,880 --> 01:24:59,400
アクティブな推論モデルの

2242
01:24:59,400 --> 01:25:01,880
実装にある程度の見込みがあるのですか?  k 確率的プログラミングの最大の

2243
01:25:01,880 --> 01:25:03,780
利点は、

2244
01:25:03,780 --> 01:25:05,940
必ずしもアクティブな推論エージェントをシミュレートするためのものではありません。

2245
01:25:05,940 --> 01:25:08,400


2246
01:25:08,400 --> 01:25:10,020


2247
01:25:10,020 --> 01:25:12,659
行列の乗算が

2248
01:25:12,659 --> 01:25:15,840
十分であることを確認し

2249
01:25:15,840 --> 01:25:18,480
てください。Jax でそれを使用すると、はるかにスケーラブルになるため

2250
01:25:18,480 --> 01:25:21,120
、すべてのベクトル化された操作を使用して数十のように実行できます。

2251
01:25:21,120 --> 01:25:22,980


2252
01:25:22,980 --> 01:25:24,600


2253
01:25:24,600 --> 01:25:25,620
これらの

2254
01:25:25,620 --> 01:25:28,440
高度に最適化されたジャストインタイムでコンパイルされた

2255
01:25:28,440 --> 01:25:30,840
関数とジャックを使用できるため、何千ものアクティブな推論エージェントを同時に実行できます。これにより

2256
01:25:30,840 --> 01:25:32,280
、基本的に物事が桁違いに高速化

2257
01:25:32,280 --> 01:25:34,860
されますが、確率的

2258
01:25:34,860 --> 01:25:36,540
プログラミングの角度は、アクティブな推論プロセスをシミュレートするためのものではありません。

2259
01:25:36,540 --> 01:25:39,060


2260
01:25:39,060 --> 01:25:41,100
これは、推論を行うため、

2261
01:25:41,100 --> 01:25:43,620
またはアクティブな推論

2262
01:25:43,620 --> 01:25:46,860
エージェントのモデルを経験的データに適合させるためのものです。たとえば

2263
01:25:46,860 --> 01:25:49,460
、動物や人が何かをし

2264
01:25:49,460 --> 01:25:53,040
ているのを観察するとします。これ

2265
01:25:53,040 --> 01:25:55,440
は、SPM でしか実行できませんが、Pine VP ではまだ実行できません。

2266
01:25:55,440 --> 01:25:58,080
誰かの行動のシーケンスを取得して

2267
01:25:58,080 --> 01:25:59,460


2268
01:25:59,460 --> 01:26:02,699


2269
01:26:02,699 --> 01:26:04,260
、アクティブな推論モデルの最適な um パラメータを推論できますか?

2270
01:26:04,260 --> 01:26:06,239
それは彼らの行動を説明するので

2271
01:26:06,239 --> 01:26:08,100
、誰かがどのように決定したかを考えると

2272
01:26:08,100 --> 01:26:10,199
、彼らの行列はこのように見える

2273
01:26:10,199 --> 01:26:12,780
必要があるか、彼らのCベクトルはこの精度を持っている必要がある

2274
01:26:12,780 --> 01:26:14,880
と言えます.

2275
01:26:14,880 --> 01:26:18,420


2276
01:26:18,420 --> 01:26:21,239


2277
01:26:21,239 --> 01:26:22,500


2278
01:26:22,500 --> 01:26:24,060
確率的プログラミング言語で

2279
01:26:24,060 --> 01:26:26,520
あること

2280
01:26:26,520 --> 01:26:29,159
については、Matlab 文献でアクティブな推論モデルをフィッティングするために実際には十分に調査されていない非常に多くの異なる方法があるということ

2281
01:26:29,159 --> 01:26:30,719


2282
01:26:30,719 --> 01:26:31,860


2283
01:26:31,860 --> 01:26:34,679
です。そこにいるほとんどすべての人が

2284
01:26:34,679 --> 01:26:36,420
、基本的

2285
01:26:36,420 --> 01:26:38,940
に自由エネルギーを最小化するこの um 変分ベイズ アプローチを使用し、ガウス近似を使用するためです。

2286
01:26:38,940 --> 01:26:40,800
事後については、numpyro またはおそらく Pi mt3 にあるため、

2287
01:26:40,800 --> 01:26:42,480
非常に特殊な

2288
01:26:42,480 --> 01:26:45,060
タイプの変分推論です。

2289
01:26:45,060 --> 01:26:48,480


2290
01:26:48,480 --> 01:26:50,520
これはすぐに

2291
01:26:50,520 --> 01:26:52,560
実装されますが、完全には実装されていませんが、さまざまな利点を持つ

2292
01:26:52,560 --> 01:26:54,480
さまざまな種類の確率的

2293
01:26:54,480 --> 01:26:55,620
推論手法を使用できるようになります。

2294
01:26:55,620 --> 01:26:57,780
そして

2295
01:26:57,780 --> 01:27:00,300
、確率論的推論の大きな欠点のような欠点

2296
01:27:00,300 --> 01:27:04,620
は、um mcmc Monte C です。 アルロ・マルコフ

2297
01:27:04,620 --> 01:27:06,540
連鎖モンテカルロ推論は、

2298
01:27:06,540 --> 01:27:09,840
偏りの少ない事後分布を与えるはずです.ベースと推論

2299
01:27:09,840 --> 01:27:11,280


2300
01:27:11,280 --> 01:27:13,500


2301
01:27:13,500 --> 01:27:16,260
を近似する変分アプローチよりも

2302
01:27:16,260 --> 01:27:18,360
mcmcを使用する利点が

2303
01:27:18,360 --> 01:27:19,739


2304
01:27:19,739 --> 01:27:21,780
あるように.

2305
01:27:21,780 --> 01:27:23,280
計算精神医学コミュニティの人々

2306
01:27:23,280 --> 01:27:25,320
は、

2307
01:27:25,320 --> 01:27:27,120


2308
01:27:27,120 --> 01:27:30,440


2309
01:27:30,440 --> 01:27:33,840
Pi mdp パラメータまたは Palm DP パラメータ

2310
01:27:33,840 --> 01:27:37,199
と mcmc アプローチのよう

2311
01:27:37,199 --> 01:27:38,520
なものを推測するための変分日を並べて比較するようなものを見たいと不平を言い、私に言いました。 確率論的

2312
01:27:38,520 --> 01:27:40,139
プログラム フレームワークを使用

2313
01:27:40,139 --> 01:27:42,360


2314
01:27:42,360 --> 01:27:44,159
する

2315
01:27:44,159 --> 01:27:46,020
と

2316
01:27:46,020 --> 01:27:47,400


2317
01:27:47,400 --> 01:27:49,460
、1 つまたは 2 つまたは 3 つの

2318
01:27:49,460 --> 01:27:52,139
推論手法のみが実装されている言語に制限されている

2319
01:27:52,139 --> 01:27:53,639
場合、すべての異なる推論手法を並べて比較できるため、基本的にはそれを利用しているだけです。

2320
01:27:53,639 --> 01:27:55,340
人々がnumpyroに取り組んできたすべての作業の

2321
01:27:55,340 --> 01:27:57,780


2322
01:27:57,780 --> 01:27:59,880
うち、これらのさまざまな種類のええと推論方法をすべて実装するために行った

2323
01:27:59,880 --> 01:28:01,440


2324
01:28:01,440 --> 01:28:04,440
ええ、素晴らしいです。fausta はプライマリ バックエンドをフォローアップしました。

2325
01:28:04,440 --> 01:28:05,960


2326
01:28:05,960 --> 01:28:11,040
ええと、YMC は Sarah ですが、新しい

2327
01:28:11,040 --> 01:28:13,620
バージョンでは Jax を使用できます

2328
01:28:13,620 --> 01:28:16,139
。Pi mdp の Jax バージョンが安定したら、pi MC3 ラッパーを作成することになるかもしれません。

2329
01:28:16,139 --> 01:28:18,420


2330
01:28:18,420 --> 01:28:19,739


2331
01:28:19,739 --> 01:28:21,659


2332
01:28:21,659 --> 01:28:23,639
可能性が高く

2333
01:28:23,639 --> 01:28:26,880
、十分な余裕がある場合は、

2334
01:28:26,880 --> 01:28:28,860
自由エネルギーを最小限に抑えるだけで、絶対にそれ

2335
01:28:28,860 --> 01:28:30,719
を行っても驚かないでしょう。

2336
01:28:30,719 --> 01:28:31,980
それは

2337
01:28:31,980 --> 01:28:34,260
素晴らしいことです。それは素晴らしいこと

2338
01:28:34,260 --> 01:28:35,940
です。

2339
01:28:35,940 --> 01:28:38,760
ジェイコブまたはダフネ、または今私に別の質問をすることができます。

2340
01:28:38,760 --> 01:28:41,120


2341
01:28:43,560 --> 01:28:45,600


2342
01:28:45,600 --> 01:28:47,460


2343
01:28:47,460 --> 01:28:51,780
Pi MGP のコンテキストでメッセージ パッシングについて何度か言及した

2344
01:28:51,780 --> 01:28:55,080
ので、メッセージ パッシングとは何か

2345
01:28:55,080 --> 01:28:58,820
、pi mdp でどのように使用され

2346
01:28:58,820 --> 01:29:02,040
たのか、それは良い質問

2347
01:29:02,040 --> 01:29:04,199


2348
01:29:04,199 --> 01:29:07,860
です。

2349
01:29:07,860 --> 01:29:11,219
または近似ベイズ推論

2350
01:29:11,219 --> 01:29:13,679
ええと、隠れた状態についてベイジアン推論を行うコンテキストでそれを

2351
01:29:13,679 --> 01:29:15,420
非常に具体的にすることがよく

2352
01:29:15,420 --> 01:29:17,340
あります。

2353
01:29:17,340 --> 01:29:19,860


2354
01:29:19,860 --> 01:29:21,179


2355
01:29:21,179 --> 01:29:22,920
何らかの観察に直面

2356
01:29:22,920 --> 01:29:25,800


2357
01:29:25,800 --> 01:29:28,500
すると、あるメッセージ

2358
01:29:28,500 --> 01:29:30,900
は感覚情報に

2359
01:29:30,900 --> 01:29:32,340
対応し、別のメッセージ

2360
01:29:32,340 --> 01:29:34,320
は世界についての以前の信念に対応し

2361
01:29:34,320 --> 01:29:36,440
、アルゴリズムを使用してこれらのメッセージを組み合わせ

2362
01:29:36,440 --> 01:29:39,179
て、現在の信念を最適化します。

2363
01:29:39,179 --> 01:29:42,120
世界の隠された状態 ピオーネ

2364
01:29:42,120 --> 01:29:43,679
P では、非常に単純な種類の

2365
01:29:43,679 --> 01:29:45,600
計算効率の良い方法を使用

2366
01:29:45,600 --> 01:29:48,420
しています。これは、単にナイーブまたは

2367
01:29:48,420 --> 01:29:50,460
バニラ固定ポイント反復と呼ばれます。これは

2368
01:29:50,460 --> 01:29:52,920
、考えられる最も単純なメッセージ パッシング スキームのようなもの

2369
01:29:52,920 --> 01:29:54,420


2370
01:29:54,420 --> 01:29:56,580
です '

2371
01:29:56,580 --> 01:29:58,860
過去からの私の事前情報を使用して隠された状態を積極的にフィルタリングしているので

2372
01:29:58,860 --> 01:30:01,380
、最後の時間ステップ

2373
01:30:01,380 --> 01:30:03,780
でどこにいたかを考えると、今どこにBマトリックスを与えるべきかを言います.

2374
01:30:03,780 --> 01:30:06,060


2375
01:30:06,060 --> 01:30:08,300


2376
01:30:08,300 --> 01:30:10,739


2377
01:30:10,739 --> 01:30:13,020


2378
01:30:13,020 --> 01:30:15,239
尤度マトリックスaマトリックス

2379
01:30:15,239 --> 01:30:16,440
を通過し、これら2つのメッセージを結合するだけ

2380
01:30:16,440 --> 01:30:19,080
で、結果として得られるのは私の

2381
01:30:19,080 --> 01:30:21,540
事後分布です

2382
01:30:21,540 --> 01:30:24,000
隠された状態についての私の事後または最良の信念

2383
01:30:24,000 --> 01:30:25,679


2384
01:30:25,679 --> 01:30:27,840
は、この非常に時間的に

2385
01:30:27,840 --> 01:30:28,920
浅い

2386
01:30:28,920 --> 01:30:31,920
現在の証拠と新しい信念を形成する前に組み合わされたメッセージ

2387
01:30:31,920 --> 01:30:33,600


2388
01:30:33,600 --> 01:30:35,639
パッシングの最も単純な形式のようなもの

2389
01:30:35,639 --> 01:30:37,620
です。

2390
01:30:37,620 --> 01:30:40,739
可能性と以前の製品

2391
01:30:40,739 --> 01:30:41,520
ええと

2392
01:30:41,520 --> 01:30:43,139


2393
01:30:43,139 --> 01:30:45,480
、あなたの信念自体がより複雑な場合に使用されるより高度なメッセージパッシング技術もあり

2394
01:30:45,480 --> 01:30:46,980
ます。

2395
01:30:46,980 --> 01:30:48,480
そのため

2396
01:30:48,480 --> 01:30:49,980


2397
01:30:49,980 --> 01:30:52,199
、Matlab バージョンのエージェントにあるアクティブな推論の完全な実装では、エージェント

2398
01:30:52,199 --> 01:30:53,820
は何についての信念を持っているだけではありません。

2399
01:30:53,820 --> 01:30:56,179
現在の隠れた

2400
01:30:56,179 --> 01:31:00,239


2401
01:31:00,239 --> 01:31:03,000


2402
01:31:03,000 --> 01:31:04,860
状態は、将来のすべて

2403
01:31:04,860 --> 01:31:07,020
の隠れた状態と過去の

2404
01:31:07,020 --> 01:31:09,179
すべての隠れた状態に関する完全な予測的および事後予測

2405
01:31:09,179 --> 01:31:11,219
的な種類の um tensor または信念の立方体を持っていることです。

2406
01:31:11,219 --> 01:31:12,960
過去に取られたので、この大規模な同様の

2407
01:31:12,960 --> 01:31:15,900
信念テンソルがあり、それは

2408
01:31:15,900 --> 01:31:17,940
未来と過去の隠れた

2409
01:31:17,940 --> 01:31:21,060
状態に広がり、さらに遠くまで伸びます ポリシーによって因数分解され、更新

2410
01:31:21,060 --> 01:31:22,800
する必要があるという信念がある場合

2411
01:31:22,800 --> 01:31:24,600
は、より

2412
01:31:24,600 --> 01:31:26,580
洗練されたメッセージ パッシング手法を使用する必要があります。その

2413
01:31:26,580 --> 01:31:28,920
うちの 1 つは限界

2414
01:31:28,920 --> 01:31:30,659
メッセージ パッシングと呼ばれ、

2415
01:31:30,659 --> 01:31:32,880
変分メッセージ パッシングと呼ばれるものがあります。

2416
01:31:32,880 --> 01:31:34,199
これらのさまざまなメッセージ パッシング

2417
01:31:34,199 --> 01:31:35,760
手法はすべて、

2418
01:31:35,760 --> 01:31:37,800
メッセージ

2419
01:31:37,800 --> 01:31:40,320
を時間的に前後に渡すだけでなく

2420
01:31:40,320 --> 01:31:42,600
、

2421
01:31:42,600 --> 01:31:44,159
隠れた状態要因と呼ばれる隠れた状態を特徴付けるさまざまな変数全体で本質的に一貫して

2422
01:31:44,159 --> 01:31:45,500


2423
01:31:45,500 --> 01:31:48,060
おり、メッセージパッシングアルゴリズム

2424
01:31:48,060 --> 01:31:49,739
は基本的に

2425
01:31:49,739 --> 01:31:52,380
感覚情報

2426
01:31:52,380 --> 01:31:55,199
と以前の信念を組み合わせることになりますが

2427
01:31:55,199 --> 01:31:57,360
、

2428
01:31:57,360 --> 01:31:59,280


2429
01:31:59,280 --> 01:32:02,400
過去の未来の信念の空間を通るより複雑な軌跡 私は

2430
01:32:02,400 --> 01:32:03,960
これを私よりもはるかにうまく説明できる人がいます

2431
01:32:03,960 --> 01:32:05,940
私はこれらのいくつか

2432
01:32:05,940 --> 01:32:09,179
をpi mdpで実装しましたが、本当に素晴らしい論文があることを人々に紹介します

2433
01:32:09,179 --> 01:32:12,060


2434
01:32:12,060 --> 01:32:14,280
先日あなたがリツイートしたと思います

2435
01:32:14,280 --> 01:32:16,440
ジェイコブのことですそれ

2436
01:32:16,440 --> 01:32:16,980


2437
01:32:16,980 --> 01:32:19,620
はmeaと呼ばれています n フィールド

2438
01:32:19,620 --> 01:32:21,719
ああ、

2439
01:32:21,719 --> 01:32:24,360
ええと、平均フィールドを比較する論文と、

2440
01:32:24,360 --> 01:32:27,179
その近似と、平均フィールドを使用した最良の

2441
01:32:27,179 --> 01:32:28,679
空気近似ニューロン メッセージ

2442
01:32:28,679 --> 01:32:30,719
パッシング ベシーと

2443
01:32:30,719 --> 01:32:32,400
周辺近似は、

2444
01:32:32,400 --> 01:32:36,960
Markovich kibel と friston によって 2019

2445
01:32:36,960 --> 01:32:38,820
ええと、私たちの何人かが見て歩いてきた論文です。

2446
01:32:38,820 --> 01:32:42,179
さまざまな近似の下で

2447
01:32:42,179 --> 01:32:44,340
さまざまな自由エネルギー汎関数がどのように見えるかについて、

2448
01:32:44,340 --> 01:32:46,380


2449
01:32:46,380 --> 01:32:50,340
おそらく

2450
01:32:50,340 --> 01:32:54,420
2023年に私たちが実際に飛び込む重要な論文になる

2451
01:32:54,420 --> 01:32:57,800


2452
01:32:57,800 --> 01:33:03,020
でしょう.2011年から2019年の

2453
01:33:03,020 --> 01:33:06,360
論文の多くは、Piなどのパッケージと開発の方向性です.

2454
01:33:06,360 --> 01:33:08,400


2455
01:33:08,400 --> 01:33:09,690
mdp は

2456
01:33:09,690 --> 01:33:11,880
[音楽]

2457
01:33:11,880 --> 01:33:16,139
これらのメソッドを実際に使用することを促進しており

2458
01:33:16,139 --> 01:33:18,600


2459
01:33:18,600 --> 01:33:22,560
、概念的な可能性が非常に豊富にあり、ヒューリスティックを提案しました。

2460
01:33:22,560 --> 01:33:27,560


2461
01:33:27,840 --> 01:33:32,880
他の種類の接続に関連するエキサイティングなユースケース

2462
01:33:32,880 --> 01:33:33,480


2463
01:33:33,480 --> 01:33:36,000
です。先ほど

2464
01:33:36,000 --> 01:33:40,139
お話ししたように、これらの

2465
01:33:40,139 --> 01:33:43,440
種類の接続を ラストマイル

2466
01:33:43,440 --> 01:33:46,340
、そして

2467
01:33:46,340 --> 01:33:50,480
特により粒度の高い、またはモジュール化された

2468
01:33:50,480 --> 01:33:52,440
開発

2469
01:33:52,440 --> 01:33:54,960
は

2470
01:33:54,960 --> 01:33:58,800
、t の傘の下で行われました。  SPM vbx は

2471
01:33:58,800 --> 01:34:00,840
、それら

2472
01:34:00,840 --> 01:34:02,400


2473
01:34:02,400 --> 01:34:04,080


2474
01:34:04,080 --> 01:34:07,739
が真の分散型オープン サイエンスまたは

2475
01:34:07,739 --> 01:34:10,080
分散型サイエンスの方法

2476
01:34:10,080 --> 01:34:12,060
で有意義に共有されることを妨げていました。そのため、もちろん

2477
01:34:12,060 --> 01:34:14,580
、Prime DP と協力して構築し

2478
01:34:14,580 --> 01:34:17,460
、それについてさらに学ぶことに非常に興奮しています。

2479
01:34:17,460 --> 01:34:20,280


2480
01:34:20,280 --> 01:34:23,639
アクティブな推論エージェント

2481
01:34:23,639 --> 01:34:26,219
とそれらのさまざまな実装の一種の構成可能性

2482
01:34:26,219 --> 01:34:28,380
は、大規模に分散された方法で取り組むことができ

2483
01:34:28,380 --> 01:34:30,840


2484
01:34:30,840 --> 01:34:33,000
ます. 誰かが本当に興味深い行列を

2485
01:34:33,000 --> 01:34:34,860
指定するかもしれません.

2486
01:34:34,860 --> 01:34:37,320


2487
01:34:37,320 --> 01:34:39,300
新しい種類の

2488
01:34:39,300 --> 01:34:40,320
エージェントは、

2489
01:34:40,320 --> 01:34:42,540
他の誰かがそれを別の方法で実装できる

2490
01:34:42,540 --> 01:34:46,139
ため、

2491
01:34:46,139 --> 01:34:49,139


2492
01:34:49,139 --> 01:34:51,420


2493
01:34:51,420 --> 01:34:55,139
以前はほとんどの

2494
01:34:55,139 --> 01:34:57,719
場合

2495
01:34:57,719 --> 01:35:00,000
、完全に Matlab

2496
01:35:00,000 --> 01:35:03,239
またはオーダーメイド

2497
01:35:03,239 --> 01:35:06,179
で非常にカスタム

2498
01:35:06,179 --> 01:35:09,300
で特定の論文に適合していたこれらのアルゴリズムを開発するプロセスを因数分解するのが自然なことのようになります

2499
01:35:09,300 --> 01:35:13,320
が、 関連する軸に沿って必ずしも適応できるわけではなく

2500
01:35:13,320 --> 01:35:15,840


2501
01:35:15,840 --> 01:35:18,360
、現代の特にpythonic設定に使用したい

2502
01:35:18,360 --> 01:35:22,260


2503
01:35:22,260 --> 01:35:24,480
完全に私はもっと同意できます。つまり、

2504
01:35:24,480 --> 01:35:25,800
それについても素晴らしい考え方です。他のパッケージのエコシステムに存在する

2505
01:35:25,800 --> 01:35:28,500
モジュール式の柔軟なコードを作成しているようなもの

2506
01:35:28,500 --> 01:35:30,600


2507
01:35:30,600 --> 01:35:33,260
です。あなたは本質

2508
01:35:33,260 --> 01:35:35,580


2509
01:35:35,580 --> 01:35:38,760
的に、目の前のタスクの集合的な心の表現を因数分解しています。

2510
01:35:38,760 --> 01:35:40,679
その表現の一部は、

2511
01:35:40,679 --> 01:35:42,420


2512
01:35:42,420 --> 01:35:45,840
メッセージを渡したり、分散ワーカーのネットワーク

2513
01:35:45,840 --> 01:35:47,520
全体で何が起こっているかを考慮したりすることなく

2514
01:35:47,520 --> 01:35:50,159
作業

2515
01:35:50,159 --> 01:35:52,739
できます。そのため、誰かが独自のメッセージを書くことができるように、

2516
01:35:52,739 --> 01:35:54,239
より優れたメッセージ パッシング アルゴリズムを知っていて

2517
01:35:54,239 --> 01:35:56,520
、それを差し込んで使用することができ

2518
01:35:56,520 --> 01:35:59,219
ます。 プライム DP の

2519
01:35:59,219 --> 01:36:01,320
すべての小さな側面がどのように機能するかを学ぶ必要

2520
01:36:01,320 --> 01:36:04,320
のない pi MVP ですから、それは

2521
01:36:04,320 --> 01:36:06,239
非常に重要です。

2522
01:36:06,239 --> 01:36:08,820
オープン サイエンスとモジュラー ソフトウェア

2523
01:36:08,820 --> 01:36:10,940
開発

2524
01:36:10,940 --> 01:36:14,639
については、閉会の議事録でいいと思います。

2525
01:36:14,639 --> 01:36:17,940
もちろん、Jacob または Daphne の発言や

2526
01:36:17,940 --> 01:36:23,219
質問 また、どんな

2527
01:36:23,219 --> 01:36:26,540
種類のモデルが人々を興奮させて

2528
01:36:26,540 --> 01:36:31,020
いるのか、そして次のライブ ストリームで何を意味するのかについての前菜

2529
01:36:31,020 --> 01:36:33,900


2530
01:36:33,900 --> 01:36:36,360
2023 年 1 月の

2531
01:36:36,360 --> 01:36:39,920
モデル ストリーム 7.2

2532
01:36:41,699 --> 01:36:43,320
ええと

2533
01:36:43,320 --> 01:36:45,719
、ノートブックは本当に便利だと思う

2534
01:36:45,719 --> 01:36:48,420
ので、ネイティブ IMDb で何が起こって

2535
01:36:48,420 --> 01:36:50,100


2536
01:36:50,100 --> 01:36:52,020
いるのかを構築してモデル化し、理解しようとしている人々にとって本当に素晴らしいリソースだ

2537
01:36:52,020 --> 01:36:53,580


2538
01:36:53,580 --> 01:36:56,460
と思います。  A 行列と B 行列の持続時間パラメーターの学習

2539
01:36:56,460 --> 01:36:58,980


2540
01:36:58,980 --> 01:37:01,139
についても説明するノートブックの拡張機能

2541
01:37:01,139 --> 01:37:02,360


2542
01:37:02,360 --> 01:37:05,340


2543
01:37:05,340 --> 01:37:08,100
があれ

2544
01:37:08,100 --> 01:37:11,659


2545
01:37:13,320 --> 01:37:15,360
ば本当にクールだと思い

2546
01:37:15,360 --> 01:37:17,219


2547
01:37:17,219 --> 01:37:19,020
ます. 来て

2548
01:37:19,020 --> 01:37:20,100
くれて本当に良かったです。これは

2549
01:37:20,100 --> 01:37:22,199
、Daniel が

2550
01:37:22,199 --> 01:37:24,000
以前のメールで言っていたことですが、

2551
01:37:24,000 --> 01:37:26,639
A と B を更新することは、現在非常に

2552
01:37:26,639 --> 01:37:28,199
文書化され

2553
01:37:28,199 --> 01:37:30,840
ていないようなもので

2554
01:37:30,840 --> 01:37:32,639
あり、それは生成を学習するための形式であるためだと思います。

2555
01:37:32,639 --> 01:37:33,960


2556
01:37:33,960 --> 01:37:36,239
ええと、今のところそれは最も洗練された方法ではありません。

2557
01:37:36,239 --> 01:37:37,679


2558
01:37:37,679 --> 01:37:39,300
固定数の行と列をまだ持っているので

2559
01:37:39,300 --> 01:37:41,460
、いくつかの仮定を立てますが、それは柔軟な方法のようなものです。

2560
01:37:41,460 --> 01:37:42,960
エージェント

2561
01:37:42,960 --> 01:37:45,239
自身が b 行列と a 行列を学習しているので、

2562
01:37:45,239 --> 01:37:46,679


2563
01:37:46,679 --> 01:37:48,540


2564
01:37:48,540 --> 01:37:50,280
実際には a になる可能性があることは間違いないはず

2565
01:37:50,280 --> 01:37:52,260
です。それをノートブックに追加して、

2566
01:37:52,260 --> 01:37:54,719


2567
01:37:54,719 --> 01:37:57,300
これをある種の認識論的な

2568
01:37:57,300 --> 01:37:59,639
2 本腕のバンディット タスクのように見せることもできます。

2569
01:37:59,639 --> 01:38:01,920
一部のAまたはBでそれを学習し、それが

2570
01:38:01,920 --> 01:38:03,780
どのように機能するかを示すだけです。

2571
01:38:03,780 --> 01:38:06,120
ええと、最終的には教科書用にそのクールを使用する新しいノートを作成し、

2572
01:38:06,120 --> 01:38:08,360


2573
01:38:08,460 --> 01:38:12,600


2574
01:38:12,600 --> 01:38:15,659
すべての論文

2575
01:38:15,659 --> 01:38:19,679
で

2576
01:38:19,679 --> 01:38:21,239
、コードを

2577
01:38:21,239 --> 01:38:24,719
分析表現、

2578
01:38:24,719 --> 01:38:27,900
グラフィカル表現で見ることができれば素晴らしいでしょう。 さまざま

2579
01:38:27,900 --> 01:38:30,780
な自然言語表現

2580
01:38:30,780 --> 01:38:34,260
は、すべて正式に形式的に

2581
01:38:34,260 --> 01:38:37,080
接続されており、すべてそのようにレンダリング

2582
01:38:37,080 --> 01:38:40,080


2583
01:38:40,080 --> 01:38:42,239
できるため

2584
01:38:42,239 --> 01:38:45,900
、モデルのアクセシビリティと厳密さが向上し、

2585
01:38:45,900 --> 01:38:48,719
さまざまなドメイン間で構成および接続するのに役立つことが実際に期待されるかもしれません。

2586
01:38:48,719 --> 01:38:51,060


2587
01:38:51,060 --> 01:38:52,679
さまざまな種類の

2588
01:38:52,679 --> 01:38:55,760
学習とモデリングを

2589
01:38:56,040 --> 01:38:57,840


2590
01:38:57,840 --> 01:38:59,580


2591
01:38:59,580 --> 01:39:02,540


2592
01:39:02,760 --> 01:39:05,880


2593
01:39:05,880 --> 01:39:09,060
認識する すばらしいプレゼンテーションに大いに感謝します。

2594
01:39:09,060 --> 01:39:11,699
私は

2595
01:39:11,699 --> 01:39:14,820
、すべての新たな

2596
01:39:14,820 --> 01:39:16,920


2597
01:39:16,920 --> 01:39:19,739
統合とユースケース

2598
01:39:19,739 --> 01:39:22,679
に本当に興奮して

2599
01:39:22,679 --> 01:39:26,159


2600
01:39:26,159 --> 01:39:30,300


2601
01:39:30,300 --> 01:39:33,360
います. スケーラブルなアクティブな推論モデルに使用でき

2602
01:39:33,360 --> 01:39:36,659


2603
01:39:36,659 --> 01:39:40,199
ます.primevpが

2604
01:39:40,199 --> 01:39:41,540


2605
01:39:41,540 --> 01:39:44,420
これらのさまざまな統合のすべてとどのように相互運用

2606
01:39:44,420 --> 01:39:49,219
されるかを本当に楽しみにしてい

2607
01:39:50,580 --> 01:39:54,320
ます.Connorに

2608
01:39:56,159 --> 01:39:58,940


2609
01:39:58,980 --> 01:40:03,239
最後から2番目の言葉をありがとう.

2610
01:40:03,239 --> 01:40:05,820


2611
01:40:05,820 --> 01:40:09,060
あなたは、私

2612
01:40:09,060 --> 01:40:11,699
たちが

2613
01:40:11,699 --> 01:40:14,340
次に経験できる

2614
01:40:14,340 --> 01:40:16,860
ことのスケルトンを示すことができると言っ

2615
01:40:16,860 --> 01:40:18,480


2616
01:40:18,480 --> 01:40:20,760


2617
01:40:20,760 --> 01:40:22,920


2618
01:40:22,920 --> 01:40:26,280
ていました

2619
01:40:26,280 --> 01:40:28,380
ええと、Pine DP チュートリアル Web サイトにアクセスすると、

2620
01:40:28,380 --> 01:40:30,179
Daphne のようなノートブックのそれぞれに、

2621
01:40:30,179 --> 01:40:32,699
私は非常に便利で、

2622
01:40:32,699 --> 01:40:34,860
それらに関連付けられたコラボ リンクがあるとのことでした。

2623
01:40:34,860 --> 01:40:36,239


2624
01:40:36,239 --> 01:40:38,040


2625
01:40:38,040 --> 01:40:41,520
plore これはエージェント API の一部だと思い

2626
01:40:41,520 --> 01:40:43,139


2627
01:40:43,139 --> 01:40:46,500
ます。ええ、これは同じものですが、

2628
01:40:46,500 --> 01:40:48,060
最近

2629
01:40:48,060 --> 01:40:49,679
計算精神医学のコースでこれを示したので

2630
01:40:49,679 --> 01:40:51,060
、少し更新したので、

2631
01:40:51,060 --> 01:40:53,340


2632
01:40:53,340 --> 01:40:55,980
ダニエルと共有できます。

2633
01:40:55,980 --> 01:40:58,080
Discordに入れるか、

2634
01:40:58,080 --> 01:40:59,460
これがもう少し更新されているところならどこでも、

2635
01:40:59,460 --> 01:41:01,739
ここでアクセスできる基本的なものはまだ

2636
01:41:01,739 --> 01:41:03,900


2637
01:41:03,900 --> 01:41:04,980
同じものを表示し

2638
01:41:04,980 --> 01:41:07,560
ますが、いずれにせよ、

2639
01:41:07,560 --> 01:41:09,179
コラボレーションを開くだけで、Googleアカウントが必要です

2640
01:41:09,179 --> 01:41:12,060
それがこれらを使用するための

2641
01:41:12,060 --> 01:41:14,820


2642
01:41:14,820 --> 01:41:17,219
唯一の制限です ええと、アクティブにローカルにインストール

2643
01:41:17,219 --> 01:41:19,980


2644
01:41:19,980 --> 01:41:22,080


2645
01:41:22,080 --> 01:41:23,880


2646
01:41:23,880 --> 01:41:25,380
できます

2647
01:41:25,380 --> 01:41:27,480


2648
01:41:27,480 --> 01:41:29,820


2649
01:41:29,820 --> 01:41:31,020
私たちが実際に話していない隠し状態因子を作成すること

2650
01:41:31,020 --> 01:41:33,360
は、Pi mdp um のコンテキストで因数分解された表現で

2651
01:41:33,360 --> 01:41:35,460
あり

2652
01:41:35,460 --> 01:41:36,480


2653
01:41:36,480 --> 01:41:40,139
、B 配列を構築し

2654
01:41:40,139 --> 01:41:41,940


2655
01:41:41,940 --> 01:41:43,679
ます。  stは自分でやりますが

2656
01:41:43,679 --> 01:41:45,060


2657
01:41:45,060 --> 01:41:47,580
、これらのそれぞれに対する解決策を備えたこれらの隠しセルもあり

2658
01:41:47,580 --> 01:41:49,139
ます。アクティブな推論を実行する前のこのノートブックの主な問題は、

2659
01:41:49,139 --> 01:41:51,119


2660
01:41:51,119 --> 01:41:52,800
ステップスルーして実際

2661
01:41:52,800 --> 01:41:54,480


2662
01:41:54,480 --> 01:41:58,320
に a b c および d 配列のエントリを初期

2663
01:41:58,320 --> 01:42:00,659
化することです。 これに合わせていくつかのスライドを使用する

2664
01:42:00,659 --> 01:42:02,040
ので、基本的に

2665
01:42:02,040 --> 01:42:03,840
はスライド

2666
01:42:03,840 --> 01:42:06,360
と実際のコードの間を行き来でき

2667
01:42:06,360 --> 01:42:08,699
ます a 配列と同じことなので

2668
01:42:08,699 --> 01:42:11,520


2669
01:42:11,520 --> 01:42:13,440
、a マトリックスをどのように見せ

2670
01:42:13,440 --> 01:42:15,119
たいかを表現してから、コードに入り、 実際に

2671
01:42:15,119 --> 01:42:17,460
それを構築し、生成モデルの各コンポーネントに対して順番に実行し

2672
01:42:17,460 --> 01:42:19,020


2673
01:42:19,020 --> 01:42:20,820


2674
01:42:20,820 --> 01:42:21,540


2675
01:42:21,540 --> 01:42:23,460
、途中でそれらをプロットしている

2676
01:42:23,460 --> 01:42:25,920
ので、構築後にどのように見えるかを確認でき

2677
01:42:25,920 --> 01:42:29,280
ます。

2678
01:42:29,280 --> 01:42:31,560
実際に実装します

2679
01:42:31,560 --> 01:42:32,699
一般的なモデルを構築した後、

2680
01:42:32,699 --> 01:42:34,080
実際にそれをアクティブな推論エージェントにプラグインする

2681
01:42:34,080 --> 01:42:35,340


2682
01:42:35,340 --> 01:42:38,280
ので、これは最初に

2683
01:42:38,280 --> 01:42:41,580
因数分解された a と b を一般的な um General 用に構築する

2684
01:42:41,580 --> 01:42:43,440
ことです。 より

2685
01:42:43,440 --> 01:42:45,239
洗練されたグリッドの世界ですが、

2686
01:42:45,239 --> 01:42:47,100
実際にはそれは導入タスクのようなものであり、

2687
01:42:47,100 --> 01:42:48,600
実際

2688
01:42:48,600 --> 01:42:50,940
にこの

2689
01:42:50,940 --> 01:42:53,219
認識論的な 2 本腕のバンド付きタスクのために A と B と C を構築します。これは

2690
01:42:53,219 --> 01:42:55,560
基本的にチームメイトのようなもの

2691
01:42:55,560 --> 01:42:56,460


2692
01:42:56,460 --> 01:43:00,300
です。 つまり、マトリックスの

2693
01:43:00,300 --> 01:43:02,520
すべての小さなサブマトリックスに書き込んでいることを知っている

2694
01:43:02,520 --> 01:43:04,679


2695
01:43:04,679 --> 01:43:06,420
ので、私が言ったように非常に多くのセル

2696
01:43:06,420 --> 01:43:07,739
があるのは、

2697
01:43:07,739 --> 01:43:09,950
それが実際に物事を構築している最も長い部分のよう

2698
01:43:09,950 --> 01:43:10,500


2699
01:43:10,500 --> 01:43:11,100


2700
01:43:11,100 --> 01:43:13,619


2701
01:43:13,619 --> 01:43:15,300
です Daphne は

2702
01:43:15,300 --> 01:43:16,800
以前、相対対数確率の観点から実際にエンコードしていると言っていたのですが

2703
01:43:16,800 --> 01:43:20,100


2704
01:43:20,100 --> 01:43:23,040
、最終的には基本的

2705
01:43:23,040 --> 01:43:25,320
に、プレゼンテーション中に説明したこれらの手順を実行し

2706
01:43:25,320 --> 01:43:27,980


2707
01:43:27,980 --> 01:43:30,360


2708
01:43:30,360 --> 01:43:32,639


2709
01:43:32,639 --> 01:43:35,340
ます。  2 つの武装した

2710
01:43:35,340 --> 01:43:37,980
バンディットを生成する 認識論からアーム バンディットへの

2711
01:43:37,980 --> 01:43:39,840
環境は

2712
01:43:39,840 --> 01:43:42,719
、エージェントの行動と th が与えられたときに世界がどのように機能するかについての単なるルールです。

2713
01:43:42,719 --> 01:43:45,360
実際に

2714
01:43:45,360 --> 01:43:48,480
このアクティブな推論ループを実行します。これは

2715
01:43:48,480 --> 01:43:51,900
、

2716
01:43:51,900 --> 01:43:53,639
隠れた状態

2717
01:43:53,639 --> 01:43:55,739
影響ポリシー推論アクション

2718
01:43:55,739 --> 01:43:58,440
サンプリングを実行し、環境をステッピングし

2719
01:43:58,440 --> 01:44:00,480
て新しい観測

2720
01:44:00,480 --> 01:44:02,159
を取得し、最後にこれを次のように記述しただけです。

2721
01:44:02,159 --> 01:44:03,659


2722
01:44:03,659 --> 01:44:05,699
基本的に選択と信念の履歴をプロットできるヘルパー関数

2723
01:44:05,699 --> 01:44:07,440


2724
01:44:07,440 --> 01:44:09,300
ええと、最後にこれは

2725
01:44:09,300 --> 01:44:11,280


2726
01:44:11,280 --> 01:44:14,280
、

2727
01:44:14,280 --> 01:44:16,739
環境のパラメーター

2728
01:44:16,739 --> 01:44:18,420
とエージェントのモデルのパラメーターをいじって

2729
01:44:18,420 --> 01:44:20,760
から開始できる、より楽しい実験的な部分のようなものです

2730
01:44:20,760 --> 01:44:22,260


2731
01:44:22,260 --> 01:44:24,000


2732
01:44:24,000 --> 01:44:25,380
アクティブな推論シミュレーションを繰り返し実行し

2733
01:44:25,380 --> 01:44:28,020
、結果の選択動作

2734
01:44:28,020 --> 01:44:29,699
と信念の履歴をプロットするだけで、動作が

2735
01:44:29,699 --> 01:44:31,320


2736
01:44:31,320 --> 01:44:33,480
どのように

2737
01:44:33,480 --> 01:44:35,040
変化するかを確認します。

2738
01:44:35,040 --> 01:44:36,780
ここでは、実際にエージェントに

2739
01:44:36,780 --> 01:44:38,460
a または B マトリックスについての信念を更新

2740
01:44:38,460 --> 01:44:42,500
させて

2741
01:44:42,900 --> 01:44:46,260
います。  SPM 教科書の

2742
01:44:46,260 --> 01:44:49,500
最後の SPM

2743
01:44:49,500 --> 01:44:52,800
ノートと実験

2744
01:44:52,800 --> 01:44:54,840
では、

2745
01:44:54,840 --> 01:44:59,159


2746
01:44:59,159 --> 01:45:02,699
100 人の参加者にまたがる複数の実験要因のようにまとめられた信じられ

2747
01:45:02,699 --> 01:45:06,900
ないほどの

2748
01:45:06,900 --> 01:45:09,360


2749
01:45:09,360 --> 01:45:13,500
グレースケール マトリックスが時々あります。

2750
01:45:13,500 --> 01:45:18,300


2751
01:45:18,300 --> 01:45:22,800
そして、それ

2752
01:45:22,800 --> 01:45:25,739
が私たちが議論してきたこれらのトピックのいくつかに視覚的な感触をどのように提供するか、

2753
01:45:25,739 --> 01:45:27,960
そして

2754
01:45:27,960 --> 01:45:30,600
もちろん表現は

2755
01:45:30,600 --> 01:45:33,420
マトリックスと正式にリンクされていますが、

2756
01:45:33,420 --> 01:45:36,060
時には2つ

2757
01:45:36,060 --> 01:45:37,800
のオプションがあり、世界には10の状態が

2758
01:45:37,800 --> 01:45:40,560
あり、可能性が見えると言うだけです. グレースケールで数値を表示

2759
01:45:40,560 --> 01:45:42,119
するスプレッドシートのように見るのではなく、このように見ると、

2760
01:45:42,119 --> 01:45:45,300


2761
01:45:45,300 --> 01:45:49,040


2762
01:45:49,040 --> 01:45:52,560
ある種の感触が得

2763
01:45:52,560 --> 01:45:55,199
られます。それは本当に見栄えがよく

2764
01:45:55,199 --> 01:45:56,639


2765
01:45:56,639 --> 01:45:59,100
、DOT 2で行う素晴らしいセッションのように見えます。

2766
01:45:59,100 --> 01:46:01,260
ええ、あなたがそれをもたらすのは興味深いこと

2767
01:46:01,260 --> 01:46:03,360
です それは私がずっとやってきた

2768
01:46:03,360 --> 01:46:05,580


2769
01:46:05,580 --> 01:46:07,679


2770
01:46:07,679 --> 01:46:10,320
ことであり、読書からすべてを学んだので、それは非常に重要だと思います。 ホース

2771
01:46:10,320 --> 01:46:13,619
アクティブ推論と SPM の論文

2772
01:46:13,619 --> 01:46:15,480
ええと、私は

2773
01:46:15,480 --> 01:46:18,659
その視覚化手法を彼らから借りただけで、

2774
01:46:18,659 --> 01:46:20,400
ええと、当然のことだと思っていましたが、

2775
01:46:20,400 --> 01:46:22,139
興味深いことに、それが唯一の方法ではないことは明らかですが

2776
01:46:22,139 --> 01:46:24,600
、常に

2777
01:46:24,600 --> 01:46:25,980
非常に直感的であることがわかりました。 確率を考えると、

2778
01:46:25,980 --> 01:46:28,560


2779
01:46:28,560 --> 01:46:30,420
色を付けることができます。数値が具体的すぎるため、色を使用します。

2780
01:46:30,420 --> 01:46:32,580


2781
01:46:32,580 --> 01:46:34,199
視覚的な側面が本当に好きなグレースケール

2782
01:46:34,199 --> 01:46:35,940
の色です。これは、これよりも可能性が高いことを示しています

2783
01:46:35,940 --> 01:46:37,860


2784
01:46:37,860 --> 01:46:40,080


2785
01:46:40,080 --> 01:46:42,860


2786
01:46:42,860 --> 01:46:46,020
この

2787
01:46:46,020 --> 01:46:48,179
素晴らしいセッションをどうもありがとう

2788
01:46:48,179 --> 01:46:51,480
ございました。あと

2789
01:46:51,480 --> 01:46:54,000
1 か月ほどでドット 2 でお会いしましょ

2790
01:46:54,000 --> 01:46:55,560


2791
01:46:55,560 --> 01:46:57,060


2792
01:46:57,060 --> 01:46:58,260


2793
01:46:58,260 --> 01:47:01,820
う

