1
00:00:02,940 --> 00:00:05,939
extranjero,

2
00:00:17,359 --> 00:00:20,520
este es el instituto de inferencia activa

3
00:00:20,520 --> 00:00:22,400
, es el 15 de noviembre de

4
00:00:22,400 --> 00:00:27,240
2022 y estamos en el flujo modelo 7.1,

5
00:00:27,240 --> 00:00:30,960
vamos a discutir Pi mdp, un

6
00:00:30,960 --> 00:00:33,840
paquete de python para la inferencia activa en

7
00:00:33,840 --> 00:00:37,500
espacios de estado discretos, todos saludaremos y luego

8
00:00:37,500 --> 00:00:41,520
pasaremos a Connor  para una presentación

9
00:00:41,520 --> 00:00:43,860
después de la presentación, tendremos

10
00:00:43,860 --> 00:00:46,920
un debate, eche un vistazo a los scripts Pi mdp,

11
00:00:46,920 --> 00:00:49,140
responda cualquier pregunta

12
00:00:49,140 --> 00:00:52,500
que surja en el chat en vivo, así que gracias a

13
00:00:52,500 --> 00:00:54,660
los autores por unirse hoy y también

14
00:00:54,660 --> 00:00:57,180
a Jacob, comenzaremos

15
00:00:57,180 --> 00:01:00,360
saludando.  así que soy Daniel, soy investigador en

16
00:01:00,360 --> 00:01:02,399
California y estoy muy emocionado de

17
00:01:02,399 --> 00:01:05,220
aprender un poco más sobre pi mdp y

18
00:01:05,220 --> 00:01:07,560
ver cómo se aplica la inferencia activa

19
00:01:07,560 --> 00:01:11,460
y pasaré a jakub.

20
00:01:11,460 --> 00:01:14,220
hola a todos, soy yakub.  un estudiante en

21
00:01:14,220 --> 00:01:18,020
el Reino Unido y también muy emocionado de escuchar

22
00:01:18,020 --> 00:01:22,200
más sobre los padres y discutir los

23
00:01:22,200 --> 00:01:25,320
desarrollos recientes y los planes para el desarrollo futuro. Se

24
00:01:25,320 --> 00:01:30,500
lo pasaré a Daphne.

25
00:01:30,500 --> 00:01:33,180
Hola, soy

26
00:01:33,180 --> 00:01:36,659
Daphne. Estoy trabajando aquí en Londres. He usado la

27
00:01:36,659 --> 00:01:39,780
primaria.  p mucho por el trabajo que hice con

28
00:01:39,780 --> 00:01:42,000
Connor en mi Mas  la tesis de ter y también el

29
00:01:42,000 --> 00:01:43,380
trabajo que hemos estado haciendo desde

30
00:01:43,380 --> 00:01:44,939
entonces, así

31
00:01:44,939 --> 00:01:46,680
que definitivamente me gusta pensar que es un

32
00:01:46,680 --> 00:01:50,159
paquete realmente genial y estoy feliz de que la

33
00:01:50,159 --> 00:01:53,899
gente comience a usarlo de manera más

34
00:01:55,020 --> 00:01:57,540
excelente, está bien, Connor, muchas gracias

35
00:01:57,540 --> 00:02:00,360
por unirte, tómalo.  lejos

36
00:02:00,360 --> 00:02:02,700
genial gracias gracias por la invitación

37
00:02:02,700 --> 00:02:05,700
me alegro de que uh um arreglamos

38
00:02:05,700 --> 00:02:07,799
esto es como una buena oportunidad para ir a

39
00:02:07,799 --> 00:02:10,020
la transmisión en vivo en la que he estado un par de veces

40
00:02:10,020 --> 00:02:12,660
ahora así que siempre es bueno volver

41
00:02:12,660 --> 00:02:14,640
para no  tengo una diapositiva presentándome,

42
00:02:14,640 --> 00:02:16,860
así que solo diré una oración rápida

43
00:02:16,860 --> 00:02:19,920
sobre quién soy, así que soy Connor, soy un

44
00:02:19,920 --> 00:02:23,160
estudiante de doctorado en biología en um, el

45
00:02:23,160 --> 00:02:25,020
Instituto Plug para el comportamiento animal y

46
00:02:25,020 --> 00:02:28,020
Constance en Alemania, y la mayor parte de mi trabajo

47
00:02:28,020 --> 00:02:30,120
es  sobre la aplicación de la inferencia activa y una

48
00:02:30,120 --> 00:02:33,360
especie de lente bayesiana en la

49
00:02:33,360 --> 00:02:35,099
ciencia cognitiva y los sistemas complejos que se

50
00:02:35,099 --> 00:02:37,379
aplican al comportamiento colectivo como

51
00:02:37,379 --> 00:02:39,959
el comportamiento animal colectivo, pero hoy

52
00:02:39,959 --> 00:02:41,940
hablaré sobre uno de mis

53
00:02:41,940 --> 00:02:43,620
proyectos paralelos de doctorado que ha estado

54
00:02:43,620 --> 00:02:45,840
desarrollando este paquete Prime DP que

55
00:02:45,840 --> 00:02:47,220
estaba  en gran medida un

56
00:02:47,220 --> 00:02:49,739
esfuerzo de grupo colaborativo con un grupo de personas de la

57
00:02:49,739 --> 00:02:51,420
comunidad de inferencia activa

58
00:02:51,420 --> 00:02:52,200
um,

59
00:02:52,200 --> 00:02:55,260
así que sí, eh, profundicemos en

60
00:02:55,260 --> 00:02:58,080
ver el documento que el paquete en

61
00:02:58,080 --> 00:03:00,239
realidad ha estado disponible durante un tiempo y el

62
00:03:00,239 --> 00:03:02,519
documento salió a principios de este año

63
00:03:02,519 --> 00:03:04,800
um y es solo  si quiero comenzar

64
00:03:04,800 --> 00:03:06,599
enfatizando que primevp es en gran medida un

65
00:03:06,599 --> 00:03:08,280
trabajo en progreso a pesar de que publicamos

66
00:03:08,280 --> 00:03:09,599
un documento y definitivamente es como un

67
00:03:09,599 --> 00:03:12,300
paquete independiente utilizable, siempre hay

68
00:03:12,300 --> 00:03:15,239
mucho para seguir desarrollando y

69
00:03:15,239 --> 00:03:16,440
hacia el final de la presentación

70
00:03:16,440 --> 00:03:18,000
hablaré sobre  algunos de esos

71
00:03:18,000 --> 00:03:19,620
desarrollos en curso que son realmente emocionantes

72
00:03:19,620 --> 00:03:21,959
en mi opinión y realmente

73
00:03:21,959 --> 00:03:23,700
abriremos el uso

74
00:03:23,700 --> 00:03:26,459
um y la capacidad de extensión del paquete

75
00:03:26,459 --> 00:03:27,900
gracias,

76
00:03:27,900 --> 00:03:30,360
así que básicamente quiero decir que este es un

77
00:03:30,360 --> 00:03:33,000
podcast del Instituto de inferencia activa o una

78
00:03:33,000 --> 00:03:35,640
transmisión en vivo, así que no  tengo que pasar demasiado

79
00:03:35,640 --> 00:03:37,379
tiempo motivando, no creo que la

80
00:03:37,379 --> 00:03:40,799
inferencia activa pero, en resumen, el paquete pi MVP

81
00:03:40,799 --> 00:03:43,379
es un paquete de python para

82
00:03:43,379 --> 00:03:45,299
simular

83
00:03:45,299 --> 00:03:46,980
um y ejecutar

84
00:03:46,980 --> 00:03:49,739
procesos de inferencia activa en discre  Los espacios de estado y

85
00:03:49,739 --> 00:03:51,599
el caso de espacio de estado discreto es un caso muy

86
00:03:51,599 --> 00:03:53,879
bien

87
00:03:53,879 --> 00:03:55,560
estudiado y muy bien caracterizado, y ha

88
00:03:55,560 --> 00:03:57,360
sido muy popular en modelos similares de

89
00:03:57,360 --> 00:03:58,980
toma de decisiones, como la toma de decisiones discreta

90
00:03:58,980 --> 00:04:01,620
y la planificación, y ha tenido

91
00:04:01,620 --> 00:04:03,659
mucha aplicación en las neurociencias como

92
00:04:03,659 --> 00:04:05,159
modelos.  de como

93
00:04:05,159 --> 00:04:07,019
um comportamiento de toma de decisiones discretas en,

94
00:04:07,019 --> 00:04:10,700
por ejemplo, humanos u otros animales

95
00:04:11,819 --> 00:04:14,580
um así que daré un pequeño resumen de

96
00:04:14,580 --> 00:04:17,040
la presentación

97
00:04:17,040 --> 00:04:19,738
así que primero presentaré al equipo de

98
00:04:19,738 --> 00:04:21,839
uh personas que han trabajado en primevp y

99
00:04:21,839 --> 00:04:23,699
somos autores en  el documento, pero el

100
00:04:23,699 --> 00:04:26,699
equipo efectivo real es mucho más grande

101
00:04:26,699 --> 00:04:27,840
que eso porque hay muchas

102
00:04:27,840 --> 00:04:29,460
personas que lo están desarrollando o

103
00:04:29,460 --> 00:04:31,020
utilizando y contribuyendo a su

104
00:04:31,020 --> 00:04:32,940
manera que no eran en realidad coautores en

105
00:04:32,940 --> 00:04:34,380
el documento

106
00:04:34,380 --> 00:04:35,820
um y luego discutiré  la motivación

107
00:04:35,820 --> 00:04:38,940
para el paquete Daré una breve

108
00:04:38,940 --> 00:04:40,680
descripción de la inferencia activa en

109
00:04:40,680 --> 00:04:44,580
espacios de estado discretos pero, como mencioné, creo que

110
00:04:44,580 --> 00:04:47,340
este es un lugar muy agradable para tener

111
00:04:47,340 --> 00:04:48,960
esta discusión sobre Palm DP porque

112
00:04:48,960 --> 00:04:50,639
No creo que deba profundizar demasiado en

113
00:04:50,639 --> 00:04:53,220
discutir qué es la inferencia activa, por lo

114
00:04:53,220 --> 00:04:54,720
que nos ahorrará algo de tiempo para

115
00:04:54,720 --> 00:04:58,080
profundizar más en la profundidad del estanque DP

116
00:04:58,080 --> 00:04:59,400
um, hablaré sobre los

117
00:04:59,400 --> 00:05:00,960
enfoques existentes para simular

118
00:05:00,960 --> 00:05:03,240
agentes de inferencia activa como  es decir, en Matlab

119
00:05:03,240 --> 00:05:05,400
usando SPM y simplemente compare y

120
00:05:05,400 --> 00:05:08,400
contraste Prime DP con SPM y

121
00:05:08,400 --> 00:05:10,440
ayúdenos a comprender de dónde proviene Prime

122
00:05:10,440 --> 00:05:12,479


123
00:05:12,479 --> 00:05:15,139
DB en términos de sus orígenes en SPM,

124
00:05:15,139 --> 00:05:17,160
entonces hablaremos sobre algunas de las

125
00:05:17,160 --> 00:05:18,840
características.  de prime DP y su

126
00:05:18,840 --> 00:05:20,820
estructura de paquete general

127
00:05:20,820 --> 00:05:22,860
y luego nos sumergiremos en algunos

128
00:05:22,860 --> 00:05:24,660
ejemplos de uso donde mostraré algunos

129
00:05:24,660 --> 00:05:27,600
resultados similares del comportamiento del agente simulado y

130
00:05:27,600 --> 00:05:29,520
luego el código que lo acompaña solo

131
00:05:29,520 --> 00:05:31,440
para demostrar cuál es el

132
00:05:31,440 --> 00:05:35,400
flujo general de Pi mdp  parece y luego,

133
00:05:35,400 --> 00:05:36,960
al final, solo hablaré sobre algunas de las

134
00:05:36,960 --> 00:05:39,060
direcciones futuras y las

135
00:05:39,060 --> 00:05:42,060
ramas activas en curso, supongo que de Pine DP,

136
00:05:42,060 --> 00:05:44,220
sus esfuerzos de desarrollo en curso que

137
00:05:44,220 --> 00:05:47,400
creo que harán que Time EP sea súper emocionante

138
00:05:47,400 --> 00:05:48,600
y extensible,

139
00:05:48,600 --> 00:05:50,880
um a todo tipo de  nuevos casos de uso, así que estoy

140
00:05:50,880 --> 00:05:53,699
muy entusiasmado con eso y ahora, y como

141
00:05:53,699 --> 00:05:56,300
Daniel decía, si en algún momento

142
00:05:56,300 --> 00:05:59,400
alguien quiere

143
00:05:59,400 --> 00:06:00,960
um pero tiene preguntas para

144
00:06:00,960 --> 00:06:02,759
aclarar, no dude en hacérmelo

145
00:06:02,759 --> 00:06:04,199
saber y podemos detenernos en algunos

146
00:06:04,199 --> 00:06:05,940
puntos.  por más tiempo,

147
00:06:05,940 --> 00:06:08,639
bueno, entonces comenzaré presentando al

148
00:06:08,639 --> 00:06:11,039
equipo, así que son los coautores en la

149
00:06:11,039 --> 00:06:13,440
edición en papel para mí, fueron Baron Millage,

150
00:06:13,440 --> 00:06:15,900
Daphne para hacernos quién está aquí hoy,

151
00:06:15,900 --> 00:06:18,419
Brennan Klein, Carl friston, primo de Ian

152
00:06:18,419 --> 00:06:21,360
y Alexander chance, así que Carl  e Ian son

153
00:06:21,360 --> 00:06:24,360
mis co-directores de doctorado

154
00:06:24,360 --> 00:06:27,020
y um Carl es el

155
00:06:27,020 --> 00:06:30,660
progenitor original de mdp o

156
00:06:30,660 --> 00:06:32,520
formulación de espacio de estado discreto de inferencia activa en

157
00:06:32,520 --> 00:06:34,080
Matlab

158
00:06:34,080 --> 00:06:36,000
um así que es bueno tener su

159
00:06:36,000 --> 00:06:38,280
sello de aprobación en nuestro trabajo aquí

160
00:06:38,280 --> 00:06:41,220
y él es un poco  coseno en eso y luego

161
00:06:41,220 --> 00:06:43,680
solo creo que es importante

162
00:06:43,680 --> 00:06:45,840
enfatizar cuán críticos son todos aquí

163
00:06:45,840 --> 00:06:48,000
para el paquete y no fue realmente solo

164
00:06:48,000 --> 00:06:50,699
lo hice, supongo que la mayor parte del

165
00:06:50,699 --> 00:06:52,080
desarrollo de software real, pero las primeras

166
00:06:52,080 --> 00:06:53,840
etapas de Prime DP fueron realmente

167
00:06:53,840 --> 00:06:56,639
conversaciones entre  yo Brennan y

168
00:06:56,639 --> 00:07:00,000
Alec en 2019 o tal vez incluso

169
00:07:00,000 --> 00:07:02,460
antes sobre la necesidad de un paquete de python

170
00:07:02,460 --> 00:07:04,680
que haga inferencia activa y creo que

171
00:07:04,680 --> 00:07:05,819
probablemente otras personas estaban teniendo

172
00:07:05,819 --> 00:07:07,440
conversaciones similares en ese momento,

173
00:07:07,440 --> 00:07:10,080
pero fue porque todos nos

174
00:07:10,080 --> 00:07:11,880
unimos que estamos  capaz de construir

175
00:07:11,880 --> 00:07:14,699
esta cosa en no mucho tiempo, es

176
00:07:14,699 --> 00:07:16,979
decir, más de dos años y probablemente podría

177
00:07:16,979 --> 00:07:18,660
haberse hecho más rápido si hubiera estado

178
00:07:18,660 --> 00:07:21,360
trabajando a tiempo completo en ello, pero

179
00:07:21,360 --> 00:07:23,099
fue muy divertido ver la

180
00:07:23,099 --> 00:07:25,319
progresión.  de esto y luego, como

181
00:07:25,319 --> 00:07:27,599
dijo Daphne, en realidad es una de

182
00:07:27,599 --> 00:07:30,240
las primeras personas que realmente usó

183
00:07:30,240 --> 00:07:32,520
um active Pi mdp en su propia

184
00:07:32,520 --> 00:07:34,380
tesis de maestría y no solo eso, sino en una

185
00:07:34,380 --> 00:07:35,880
aplicación muy ambiciosa que es como

186
00:07:35,880 --> 00:07:38,340
Comportamiento colectivo de múltiples agentes con un

187
00:07:38,340 --> 00:07:40,380
montón de pino  Los agentes de DP interactúan

188
00:07:40,380 --> 00:07:42,960
entre sí para simular el tipo de

189
00:07:42,960 --> 00:07:45,060
opinión de Dynamics y Echo Chambers y

190
00:07:45,060 --> 00:07:46,680
las redes sociales, lo que es realmente emocionante,

191
00:07:46,680 --> 00:07:49,139
así que fue muy gratificante trabajar

192
00:07:49,139 --> 00:07:51,660
con ella en eso y, sí, es

193
00:07:51,660 --> 00:07:53,400
realmente ni  ce también que Daphne es parte de

194
00:07:53,400 --> 00:07:55,199
esto porque es como un muy buen

195
00:07:55,199 --> 00:07:57,960
ejemplo de un pionero en la

196
00:07:57,960 --> 00:07:59,819
comunidad de inferencia activa pi mdp y luego

197
00:07:59,819 --> 00:08:02,819
Baron también eh yo Alec y baron

198
00:08:02,819 --> 00:08:04,680
trabajaron mucho en el desarrollo de algunas de las

199
00:08:04,680 --> 00:08:06,360


200
00:08:06,360 --> 00:08:09,120
técnicas de paso de mensajes más sofisticadas inactivas  inferencia en Pym

201
00:08:09,120 --> 00:08:11,880
DP y uh Baron también fue realmente fundamental

202
00:08:11,880 --> 00:08:15,120
para ayudarme a escribir el artículo

203
00:08:15,120 --> 00:08:16,860
um y es excelente para escribir y

204
00:08:16,860 --> 00:08:19,919
conceptualizar, y también se usó

205
00:08:19,919 --> 00:08:22,020
realmente primevp en algunos de sus propios trabajos

206
00:08:22,020 --> 00:08:24,360
sobre representaciones sucesoras e inferencia activa,

207
00:08:24,360 --> 00:08:27,060
que es una especie de

208
00:08:27,060 --> 00:08:27,599
bueno,

209
00:08:27,599 --> 00:08:30,240
bueno, la motivación es

210
00:08:30,240 --> 00:08:32,159
una de las cosas más importantes de las que todos

211
00:08:32,159 --> 00:08:35,159
aquí son muy conscientes, es que

212
00:08:35,159 --> 00:08:37,700
hay mucha más popularidad e interés

213
00:08:37,700 --> 00:08:40,380
en la inferencia activa en estos días en los

214
00:08:40,380 --> 00:08:42,000
últimos 10 años y especialmente en los últimos

215
00:08:42,000 --> 00:08:43,979
cinco años

216
00:08:43,979 --> 00:08:46,140
, así que es un poco obvio.  que necesitamos

217
00:08:46,140 --> 00:08:48,300
algunos marcos generales más fáciles de usar

218
00:08:48,300 --> 00:08:49,860
para permitir que las personas

219
00:08:49,860 --> 00:08:52,080
aprendan sobre la inferencia activa, en primer

220
00:08:52,080 --> 00:08:53,700
lugar desde una perspectiva pedagógica,

221
00:08:53,700 --> 00:08:54,959
así como  aplicándolo en su propia

222
00:08:54,959 --> 00:08:57,420
investigación o aplicaciones industriales o

223
00:08:57,420 --> 00:08:59,339
lo que sea que quieran hacer con

224
00:08:59,339 --> 00:09:02,060
la inferencia activa,

225
00:09:02,100 --> 00:09:04,320
um, y hay mucho

226
00:09:04,320 --> 00:09:05,880
interés especial en la inferencia activa de

227
00:09:05,880 --> 00:09:07,320
ciertas comunidades, no solo la

228
00:09:07,320 --> 00:09:08,880
neurociencia, sino cosas como

229
00:09:08,880 --> 00:09:10,680
el aprendizaje automático, la ciencia de datos, la

230
00:09:10,680 --> 00:09:12,899
ingeniería, la ciencia de redes, incluso

231
00:09:12,899 --> 00:09:14,580
el desarrollo de software.  ingenieros de software

232
00:09:14,580 --> 00:09:17,820
y muchos de los campos interesados,

233
00:09:17,820 --> 00:09:20,700
um, el lenguaje más dominante es

234
00:09:20,700 --> 00:09:23,880
python, así que muchas veces lo que

235
00:09:23,880 --> 00:09:25,200
escuché es cuando las personas vienen a aprender sobre

236
00:09:25,200 --> 00:09:26,880
la inferencia activa y tienen

237
00:09:26,880 --> 00:09:28,500
experiencia en python o algo así.

238
00:09:28,500 --> 00:09:29,880
y se dan cuenta de que todo está en

239
00:09:29,880 --> 00:09:31,680
Matlab, tienen una especie de

240
00:09:31,680 --> 00:09:34,560
barrera de entrada porque

241
00:09:34,560 --> 00:09:37,740
no conocen Matlab o tienen

242
00:09:37,740 --> 00:09:39,959
dificultades para analizar el código de Matlab, especialmente

243
00:09:39,959 --> 00:09:42,540
si son de Frameworks de programación sin matrices

244
00:09:42,540 --> 00:09:44,339
como tal vez  son

245
00:09:44,339 --> 00:09:47,459
desarrolladores web front-end que usan uh

246
00:09:47,459 --> 00:09:48,899
JavaScript o algo así y en

247
00:09:48,899 --> 00:09:50,220
realidad no están familiarizados con grandes

248
00:09:50,220 --> 00:09:52,920
multidimensionales  programación de arreglos,

249
00:09:52,920 --> 00:09:55,200
um, así que esa fue otra motivación para

250
00:09:55,200 --> 00:09:57,180
hacer específicamente un paquete de python

251
00:09:57,180 --> 00:10:01,019
que hace inferencia activa,

252
00:10:01,019 --> 00:10:03,720
um y finalmente, porque está en

253
00:10:03,720 --> 00:10:06,360
Python, eso significa que ahora estamos

254
00:10:06,360 --> 00:10:08,940
creando un ecosistema que puede comunicarse con

255
00:10:08,940 --> 00:10:12,060
otros ecosistemas, por lo que idealmente

256
00:10:12,060 --> 00:10:14,459
primevp no va  para usarse en un script

257
00:10:14,459 --> 00:10:16,860
que solo usa Pi mdp, se

258
00:10:16,860 --> 00:10:19,500
usará con otros paquetes de software, algunos

259
00:10:19,500 --> 00:10:20,760
de los cuales tienen que ver con

260
00:10:20,760 --> 00:10:23,040
inteligencia artificial o ciencia de redes o todo

261
00:10:23,040 --> 00:10:24,420
tipo de marcos que son relevantes

262
00:10:24,420 --> 00:10:26,640
, por lo que ahora puede conectar y  juegue

263
00:10:26,640 --> 00:10:29,220
con agentes de piondp y colóquelos en

264
00:10:29,220 --> 00:10:31,080
entornos como un gimnasio de IA abierto para el

265
00:10:31,080 --> 00:10:33,000
aprendizaje de refuerzo, por ejemplo,

266
00:10:33,000 --> 00:10:36,600
y ahora puede trabajar con

267
00:10:36,600 --> 00:10:39,000
inferencia activa en diversas aplicaciones y

268
00:10:39,000 --> 00:10:40,380
eso es realmente genial para python porque

269
00:10:40,380 --> 00:10:43,019
python by Design y por su desarrollo impulsado por la comunidad

270
00:10:43,019 --> 00:10:44,579
tiene tanto  muchos

271
00:10:44,579 --> 00:10:46,860
paquetes diferentes que se construyeron muy

272
00:10:46,860 --> 00:10:49,140
bien para algo específico, así que ahora

273
00:10:49,140 --> 00:10:51,540
que está en Python, puede usarlo

274
00:10:51,540 --> 00:10:54,240
en conjunto con w  Con todos esos otros

275
00:10:54,240 --> 00:10:57,079
paquetes de python,

276
00:10:58,079 --> 00:11:00,480
um, está bien, ahora una breve introducción a la inferencia activa,

277
00:11:00,480 --> 00:11:02,519
por lo que el

278
00:11:02,519 --> 00:11:05,640
paradigma fundamental de la inferencia activa es que

279
00:11:05,640 --> 00:11:07,500
consideras un agente incrustado en su

280
00:11:07,500 --> 00:11:08,700
entorno

281
00:11:08,700 --> 00:11:11,519
y, a diferencia de los enfoques tradicionales más

282
00:11:11,519 --> 00:11:15,540
pasivos de la percepción y el

283
00:11:15,540 --> 00:11:18,540
comportamiento, donde tú tipo de  Considere que el

284
00:11:18,540 --> 00:11:20,880
entorno le brinda información.

285
00:11:20,880 --> 00:11:22,560
Realiza una transformación sensoriomotora y

286
00:11:22,560 --> 00:11:24,300
luego realiza una acción.

287
00:11:24,300 --> 00:11:26,279
Infantes activos. Enfatiza mucho

288
00:11:26,279 --> 00:11:28,980
el hecho de que la inferencia o

289
00:11:28,980 --> 00:11:31,320
el problema de lidiar con la incertidumbre

290
00:11:31,320 --> 00:11:33,959
caracteriza tanto la percepción como lo que

291
00:11:33,959 --> 00:11:36,000
llamamos estimación de estado o

292
00:11:36,000 --> 00:11:38,519
actualización de creencias.  como acción, que es

293
00:11:38,519 --> 00:11:40,500
donde entra en juego la parte de la inferencia activa,

294
00:11:40,500 --> 00:11:42,300
por lo que los agentes no solo

295
00:11:42,300 --> 00:11:44,640
actualizan sus creencias sobre los estados

296
00:11:44,640 --> 00:11:46,320
del mundo, los estados ocultos que existen

297
00:11:46,320 --> 00:11:50,700
al minimizar este um vinculado a una

298
00:11:50,700 --> 00:11:52,620
sorpresa llamada energía libre y ahí es

299
00:11:52,620 --> 00:11:55,380
donde este tipo de ham holsian  ideas de

300
00:11:55,380 --> 00:11:58,500
percepción como de donde provienen las inferencias,

301
00:11:58,500 --> 00:12:01,920
pero también estás minimizando la sorpresa o

302
00:12:01,920 --> 00:12:05,279
una  obligado por sorpresa también a elegir sus

303
00:12:05,279 --> 00:12:09,120
acciones, por lo que inferir acciones se

304
00:12:09,120 --> 00:12:11,459
convierte en otro tipo de problema de inferencia

305
00:12:11,459 --> 00:12:13,740
, por lo que las políticas o secuencias de

306
00:12:13,740 --> 00:12:15,839
acciones se consideran variables latentes

307
00:12:15,839 --> 00:12:18,120
o estados ocultos y luego también

308
00:12:18,120 --> 00:12:21,000
infiere sobre ellos y lanza

309
00:12:21,000 --> 00:12:22,980
ambos lados de la moneda de acción de percepción

310
00:12:22,980 --> 00:12:25,200
como ejemplo de minimización de sorpresas,

311
00:12:25,200 --> 00:12:27,899
sus eventos son agentes que

312
00:12:27,899 --> 00:12:29,120
muestran

313
00:12:29,120 --> 00:12:32,940
un comportamiento útil y curioso

314
00:12:32,940 --> 00:12:35,519
y es muy parecido a que no hay nada sobre

315
00:12:35,519 --> 00:12:37,320
la inferencia activa que signifique que tiene que

316
00:12:37,320 --> 00:12:39,660
usar espacios de estado discretos o Pi MVP

317
00:12:39,660 --> 00:12:42,720
que es solo un tipo particular o

318
00:12:42,720 --> 00:12:44,519
clase de generativo  modelos para inferencia activa,

319
00:12:44,519 --> 00:12:45,600


320
00:12:45,600 --> 00:12:49,320
pero los modelos generativos de espacio de estado discreto de Palm DP

321
00:12:49,320 --> 00:12:51,720
son realmente fáciles

322
00:12:51,720 --> 00:12:53,279
de trabajar con seguros activos

323
00:12:53,279 --> 00:12:54,899
porque muchas de estas cantidades que

324
00:12:54,899 --> 00:12:57,600
estoy mostrando aquí son muy fáciles de

325
00:12:57,600 --> 00:12:59,040
calcular cuando se trata de palm

326
00:12:59,040 --> 00:13:00,660
DPS  o

327
00:13:00,660 --> 00:13:02,820
procesos de decisión de marcado observados parcialmente, por lo que entraremos en todas

328
00:13:02,820 --> 00:13:04,800
las matemáticas en un momento, pero

329
00:13:04,800 --> 00:13:06,600
eso  Es solo un paradigma básico del

330
00:13:06,600 --> 00:13:08,820
agente de inferencia activa y el entorno.

331
00:13:08,820 --> 00:13:11,100
Intentar minimizar la sorpresa tanto en la

332
00:13:11,100 --> 00:13:13,440
percepción como en la acción minimizando la

333
00:13:13,440 --> 00:13:15,600
sorpresa.

334
00:13:15,600 --> 00:13:17,100


335
00:13:17,100 --> 00:13:20,040


336
00:13:20,040 --> 00:13:22,079


337
00:13:22,079 --> 00:13:24,660


338
00:13:24,660 --> 00:13:26,399


339
00:13:26,399 --> 00:13:28,860
Recomendaría leer este

340
00:13:28,860 --> 00:13:31,620
artículo que es excelente en el Journal

341
00:13:31,620 --> 00:13:34,440
of medical Psychology de Lance Thomas

342
00:13:34,440 --> 00:13:38,040
Noor Sebastian victorita y

343
00:13:38,040 --> 00:13:40,680
Carl, es una descripción realmente excelente

344
00:13:40,680 --> 00:13:42,899
desde una base formal de cómo llegamos a las

345
00:13:42,899 --> 00:13:44,459
ecuaciones de actualización para la inferencia activa a

346
00:13:44,459 --> 00:13:46,440
partir de lo más formal.

347
00:13:46,440 --> 00:13:48,660
el tratamiento de las distribuciones categóricas y de dirichlet

348
00:13:48,660 --> 00:13:50,639


349
00:13:50,639 --> 00:13:53,040
y también el papel pine DP, la versión

350
00:13:53,040 --> 00:13:55,380
que tenemos en el archivo también tiene un montón de

351
00:13:55,380 --> 00:13:58,079
apéndices que hacen mucho de este

352
00:13:58,079 --> 00:14:00,779
tipo de matemática similar, así que también recomendaría a las

353
00:14:00,779 --> 00:14:02,720
personas que lo

354
00:14:02,720 --> 00:14:05,220
vean bien, así que ahora entremos en el

355
00:14:05,220 --> 00:14:06,899
generativo  modelos que forman el pan

356
00:14:06,899 --> 00:14:10,440
y la mantequilla de los cerebros de los agentes

357
00:14:10,440 --> 00:14:13,139
en Pym DP esencialmente tan Centr  a

358
00:14:13,139 --> 00:14:14,760
las inferencias activas escribiendo un

359
00:14:14,760 --> 00:14:16,800
modelo generativo que es solo una

360
00:14:16,800 --> 00:14:19,139
especificación de cómo un agente cree que

361
00:14:19,139 --> 00:14:21,180
su mundo funciona cómo funciona

362
00:14:21,180 --> 00:14:22,980
su entorno

363
00:14:22,980 --> 00:14:24,839
um cómo cree que su entorno se

364
00:14:24,839 --> 00:14:27,540
influye a sí mismo como la dinámica

365
00:14:27,540 --> 00:14:29,639
del mundo uh progreso y cómo

366
00:14:29,639 --> 00:14:31,920
esos ocultos  State Dynamics también da

367
00:14:31,920 --> 00:14:34,139
lugar a observaciones que están codificadas

368
00:14:34,139 --> 00:14:36,240
en lo que llamamos un modelo generativo o un

369
00:14:36,240 --> 00:14:38,519
modelo mundial, algunas personas también lo llaman

370
00:14:38,519 --> 00:14:39,839
así

371
00:14:39,839 --> 00:14:43,199
en Pine DP solo tratamos con un tipo muy

372
00:14:43,199 --> 00:14:44,820
específico de género de modelo que

373
00:14:44,820 --> 00:14:45,959
se denominan estos

374
00:14:45,959 --> 00:14:48,600
procesos de decisión de Markov parcialmente observados  por lo tanto, estos son un

375
00:14:48,600 --> 00:14:50,279
modelo clásico de toma de decisiones secuenciales

376
00:14:50,279 --> 00:14:52,380
y planificación bajo incertidumbre,

377
00:14:52,380 --> 00:14:54,180
no son exclusivos de la inferencia activa, las

378
00:14:54,180 --> 00:14:57,480
personas usan modelos Palm DP para el

379
00:14:57,480 --> 00:14:59,160
aprendizaje por refuerzo clásico y todo tipo de

380
00:14:59,160 --> 00:15:01,620
problemas de toma de decisiones,

381
00:15:01,620 --> 00:15:03,480
um, se llaman

382
00:15:03,480 --> 00:15:05,279
proceso de decisión markoviano de Markov porque el  el estado en

383
00:15:05,279 --> 00:15:07,440
el momento actual solo depende de la

384
00:15:07,440 --> 00:15:09,060
acción en el estado en el momento anterior,

385
00:15:09,060 --> 00:15:10,740
así que esa es la definición  En un

386
00:15:10,740 --> 00:15:12,420
proceso de Markov, tienen esta dependencia temporal superficial,

387
00:15:12,420 --> 00:15:14,339


388
00:15:14,339 --> 00:15:15,800
um que, por ejemplo, un

389
00:15:15,800 --> 00:15:18,120
proceso no markoviano no tiene como un proceso que

390
00:15:18,120 --> 00:15:20,279
tiene un plazo más largo o dependencias temporales más profundas

391
00:15:20,279 --> 00:15:21,899
que se remontan más atrás

392
00:15:21,899 --> 00:15:23,579
en el pasado,

393
00:15:23,579 --> 00:15:25,680
um Palm DPS a menudo son  pero no siempre se

394
00:15:25,680 --> 00:15:27,720
formula el espacio de estado discreto y el

395
00:15:27,720 --> 00:15:29,940
tiempo discreto. No hay nada en la

396
00:15:29,940 --> 00:15:32,760
palabra palmdp que signifique que tienen que ser

397
00:15:32,760 --> 00:15:35,160
estas distribuciones multinomiales o categóricas,

398
00:15:35,160 --> 00:15:37,500
pero solo cuando hablamos

399
00:15:37,500 --> 00:15:39,240
de Palm DPS y la influencia activa

400
00:15:39,240 --> 00:15:40,980
, casi siempre estamos hablando de estos

401
00:15:40,980 --> 00:15:43,760
discretos,

402
00:15:43,800 --> 00:15:45,899
um que  tiene que ver básicamente con que

403
00:15:45,899 --> 00:15:47,940
solo puede estar en uno de los K estados discretos

404
00:15:47,940 --> 00:15:50,279
a la vez y solo progresa a uno

405
00:15:50,279 --> 00:15:52,260
de los K estados discretos la próxima vez, por lo que

406
00:15:52,260 --> 00:15:53,699
todo es discreto, pero no hay

407
00:15:53,699 --> 00:15:55,920
nada intrínseco sobre estos

408
00:15:55,920 --> 00:15:57,240
procesos de decisión de Markov que tiene que ser

409
00:15:57,240 --> 00:15:59,040
discreto I  creo que vale la pena

410
00:15:59,040 --> 00:16:00,420
mencionarlo porque ese es un

411
00:16:00,420 --> 00:16:02,820
tipo importante de fusión que la gente

412
00:16:02,820 --> 00:16:04,139
suele hacer cuando ve la palabra Palm

413
00:16:04,139 --> 00:16:05,699
DP

414
00:16:05,699 --> 00:16:08,279
um  y la razón por la que decidimos usar este

415
00:16:08,279 --> 00:16:11,040
modelo generativo discreto de Palm DP para

416
00:16:11,040 --> 00:16:12,899
la inferencia activa no es solo por

417
00:16:12,899 --> 00:16:15,899
las aplicaciones para la toma de decisiones secuenciales

418
00:16:15,899 --> 00:16:18,060
y la planificación, sino que también

419
00:16:18,060 --> 00:16:20,339
hay una gran cantidad de

420
00:16:20,339 --> 00:16:24,240
literatura de inferencia activa preexistente desde 2010 2011 sobre el

421
00:16:24,240 --> 00:16:26,760
uso de pom DPS como  modelos generativos para

422
00:16:26,760 --> 00:16:28,079
pruebas de toma de decisiones, por lo que todas las

423
00:16:28,079 --> 00:16:30,540
matemáticas para hacer inferencia activa

424
00:16:30,540 --> 00:16:32,699
con estos modelos ya están hechas, por lo que

425
00:16:32,699 --> 00:16:34,860
no tuvimos que inventar ninguna nueva matemática o

426
00:16:34,860 --> 00:16:36,720
teoría para codificar esto

427
00:16:36,720 --> 00:16:38,339
porque gran parte ya se ha escrito en

428
00:16:38,339 --> 00:16:41,040
artículos para  como 10 años, eso nos hizo

429
00:16:41,040 --> 00:16:44,100
la vida más fácil. Al desarrollarlo,

430
00:16:44,100 --> 00:16:46,320
ahora, um, profundicemos solo en los

431
00:16:46,320 --> 00:16:48,899
componentes principales de estos Palm DPS,

432
00:16:48,899 --> 00:16:51,480
eh, solo estoy enumerando los cuatro

433
00:16:51,480 --> 00:16:54,360
principales aquí, pero hay otros componentes

434
00:16:54,360 --> 00:16:55,980
que podemos discutir si alguien está

435
00:16:55,980 --> 00:16:58,560
interesado, pero  esencialmente esta

436
00:16:58,560 --> 00:17:01,199
línea en la parte superior es una descripción del

437
00:17:01,199 --> 00:17:02,820
modelo generativo en términos de una

438
00:17:02,820 --> 00:17:05,099
distribución conjunta sobre estados ocultos

439
00:17:05,099 --> 00:17:08,640
s y observaciones o en Into the Fut

440
00:17:08,640 --> 00:17:11,939
Claro, debido a la

441
00:17:11,939 --> 00:17:13,500
naturaleza markoviana de este modelo generativo, puede

442
00:17:13,500 --> 00:17:15,000
escribir

443
00:17:15,000 --> 00:17:16,619
um La distribución conjunta con este

444
00:17:16,619 --> 00:17:20,339
producto factorizado básicamente de

445
00:17:20,339 --> 00:17:22,559
um anteriores y probabilidades que se

446
00:17:22,559 --> 00:17:24,179
factoriza a lo largo del tiempo, por

447
00:17:24,179 --> 00:17:25,740
eso son esos productos a lo largo del tiempo en la

448
00:17:25,740 --> 00:17:27,839
parte superior, pero  No importa

449
00:17:27,839 --> 00:17:29,640
entender las matemáticas en este momento, pero los

450
00:17:29,640 --> 00:17:31,440
componentes principales que mapearemos en un

451
00:17:31,440 --> 00:17:34,320
esquema en un segundo son las

452
00:17:34,320 --> 00:17:36,360
creencias de los agentes sobre cómo los estados ocultos

453
00:17:36,360 --> 00:17:38,940
causan observaciones que codificamos en

454
00:17:38,940 --> 00:17:40,440
algo llamado modelo de observación

455
00:17:40,440 --> 00:17:42,539
o mapeo de probabilidad.  a menudo

456
00:17:42,539 --> 00:17:45,360
llamada matriz o arreglo, por lo que esta es una

457
00:17:45,360 --> 00:17:47,820
representación probabilística de cómo

458
00:17:47,820 --> 00:17:50,460
los estados ocultos en el momento actual afectan

459
00:17:50,460 --> 00:17:52,559
o dan lugar a observaciones en el

460
00:17:52,559 --> 00:17:54,000
momento actual. En

461
00:17:54,000 --> 00:17:56,340
segundo lugar, tenemos el

462
00:17:56,340 --> 00:17:58,860
modelo de transición o dinámico, que es otro tipo de

463
00:17:58,860 --> 00:18:02,039
probabilidad que codifica.  las creencias del agente

464
00:18:02,039 --> 00:18:03,960
acerca de cómo los estados ocultos en un

465
00:18:03,960 --> 00:18:05,640
momento se relacionan con los estados ocultos en la próxima

466
00:18:05,640 --> 00:18:08,100
vez, por lo que este mapa,

467
00:18:08,100 --> 00:18:09,960
um, esto es lo que usa el agente  para

468
00:18:09,960 --> 00:18:12,539
hacer predicciones futuras sobre cómo

469
00:18:12,539 --> 00:18:14,940
evolucionará el mundo si esto sucede o si

470
00:18:14,940 --> 00:18:17,100
sucede así como para transmitir tipos de

471
00:18:17,100 --> 00:18:19,080
mensajes o antecedentes empíricos del

472
00:18:19,080 --> 00:18:22,080
pasado dado dónde estaba ayer dónde

473
00:18:22,080 --> 00:18:24,720
debo estar ahora dadas mis creencias sobre

474
00:18:24,720 --> 00:18:26,400
cómo evoluciona el mundo  a veces todo eso está

475
00:18:26,400 --> 00:18:28,860
codificado en la matriz B o la

476
00:18:28,860 --> 00:18:31,679
Matriz B y luego estos dos últimos son una especie

477
00:18:31,679 --> 00:18:33,600
de uh previos,

478
00:18:33,600 --> 00:18:35,700
el primero de los cuales es muy importante

479
00:18:35,700 --> 00:18:38,880
y se llama la matriz C o el

480
00:18:38,880 --> 00:18:41,340
Vector C que codifica las creencias previas del agente

481
00:18:41,340 --> 00:18:43,679
sobre qué observaciones es

482
00:18:43,679 --> 00:18:46,260
probable  para encontrar y, como dijimos

483
00:18:46,260 --> 00:18:47,520
al principio, la inferencia activa se

484
00:18:47,520 --> 00:18:49,980
trata de presentar tanto la acción como la percepción

485
00:18:49,980 --> 00:18:51,660
como un problema de inferencia,

486
00:18:51,660 --> 00:18:54,900
por lo que la inferencia activa como marco de referencia

487
00:18:54,900 --> 00:18:56,880
da vuelta el Paradigma clásico de las funciones de recompensa

488
00:18:56,880 --> 00:18:58,500
y el aprendizaje por refuerzo

489
00:18:58,500 --> 00:19:00,480
al decir en lugar de una recompensa

490
00:19:00,480 --> 00:19:02,700
la función simplemente equipa al agente con una

491
00:19:02,700 --> 00:19:04,559
especie de creencia optimista de que en el

492
00:19:04,559 --> 00:19:07,140
futuro veré este tipo de datos y

493
00:19:07,140 --> 00:19:09,120
luego, al realizar inferencias con

494
00:19:09,120 --> 00:19:10,980
resp.  ecto a un modelo generativo que tiene

495
00:19:10,980 --> 00:19:13,200
esa creencia previa en él, el agente

496
00:19:13,200 --> 00:19:14,820
parecerá que está buscando

497
00:19:14,820 --> 00:19:16,919
observaciones que se ajusten a sus anteriores,

498
00:19:16,919 --> 00:19:19,140
por lo que esto va en línea con esta

499
00:19:19,140 --> 00:19:21,419
idea de que la inferencia activa es un proceso

500
00:19:21,419 --> 00:19:23,340
de profecía autocumplida, el agente

501
00:19:23,340 --> 00:19:25,919
cree que yo  Es más o menos probable que vea

502
00:19:25,919 --> 00:19:27,840
ciertas observaciones y luego, al hacer

503
00:19:27,840 --> 00:19:30,780
inferencias sobre políticas con tal

504
00:19:30,780 --> 00:19:32,580
sesgo hacia el modelo generativo, el agente

505
00:19:32,580 --> 00:19:34,740
llegará a darse cuenta de

506
00:19:34,740 --> 00:19:37,799
sus preferencias previas o estas

507
00:19:37,799 --> 00:19:40,020
creencias previas sobre las observaciones,

508
00:19:40,020 --> 00:19:42,660
por lo que todo está codificado en el

509
00:19:42,660 --> 00:19:44,880
Básicamente, puede pensar en el vector C y el vector C

510
00:19:44,880 --> 00:19:48,000
como la traducción bayesiana de la

511
00:19:48,000 --> 00:19:49,340
función de recompensa y, de hecho, puede

512
00:19:49,340 --> 00:19:51,600
relacionar exactamente las entradas del vector C con

513
00:19:51,600 --> 00:19:53,220
dos recompensas y

514
00:19:53,220 --> 00:19:55,080
aprendizaje de refuerzo, pero no lo haremos, no tenemos que

515
00:19:55,080 --> 00:19:57,000
entrar en eso.  ahora, pero puedo compartir documentos

516
00:19:57,000 --> 00:20:00,000
si alguien está interesado y

517
00:20:00,000 --> 00:20:01,919
finalmente está el anterior sobre los estados ocultos y

518
00:20:01,919 --> 00:20:04,200
esto es simplemente la creencia del agente

519
00:20:04,200 --> 00:20:07,559
sobre cuál es el anterior li  kelihood de

520
00:20:07,559 --> 00:20:09,539
cada estado oculto en el primer

521
00:20:09,539 --> 00:20:11,820
paso de tiempo de la simulación, por lo que esto

522
00:20:11,820 --> 00:20:14,160
no es realmente algo necesario en la inferencia activa,

523
00:20:14,160 --> 00:20:15,900
pero a menudo, cuando estamos

524
00:20:15,900 --> 00:20:18,299
simulando agentes, usamos un

525
00:20:18,299 --> 00:20:20,039
horizonte temporal finito con un tiempo de inicio y

526
00:20:20,039 --> 00:20:23,280
un tiempo final  Entonces, si tiene un

527
00:20:23,280 --> 00:20:25,200
horizonte temporal finito, significa

528
00:20:25,200 --> 00:20:27,240
que básicamente tiene que conectar una

529
00:20:27,240 --> 00:20:29,100
creencia previa sobre cómo se ve el mundo

530
00:20:29,100 --> 00:20:31,740
en el paso de tiempo uno y esa creencia previa

531
00:20:31,740 --> 00:20:34,940
está codificada en este vector d d

532
00:20:34,940 --> 00:20:38,460
y podemos esbozar intuitivamente

533
00:20:38,460 --> 00:20:41,039
el  el modelo generativo de Palm DP como un

534
00:20:41,039 --> 00:20:43,799
gráfico bayesiano donde los nodos están conectados

535
00:20:43,799 --> 00:20:45,720
por aristas mediante estas flechas si

536
00:20:45,720 --> 00:20:47,280
dependen unos de otros, por lo que estos nodos rojos

537
00:20:47,280 --> 00:20:48,660
representan los estados ocultos en

538
00:20:48,660 --> 00:20:51,720
transición entre sí a lo largo del tiempo

539
00:20:51,720 --> 00:20:53,700
um y los nodos azules los nodos O

540
00:20:53,700 --> 00:20:56,340
representan las creencias del agente  sobre cómo

541
00:20:56,340 --> 00:20:58,320
se generan las observaciones a partir de esos

542
00:20:58,320 --> 00:21:00,299
estados ocultos, por lo que es solo una

543
00:21:00,299 --> 00:21:02,760
representación gráfica de Palm DP

544
00:21:02,760 --> 00:21:05,580
y la matriz codifica, como dijimos

545
00:21:05,580 --> 00:21:07,020
, las creencias del agente sobre cómo esos  Los

546
00:21:07,020 --> 00:21:09,120
nodos d dan lugar a los nodos azules en cualquier

547
00:21:09,120 --> 00:21:11,280
momento, por lo que generalmente asumimos que esta

548
00:21:11,280 --> 00:21:13,740
matriz es invariable en el tiempo, por lo que

549
00:21:13,740 --> 00:21:15,539
creen que este mapeo de observación

550
00:21:15,539 --> 00:21:18,120
no depende del tiempo, al

551
00:21:18,120 --> 00:21:19,980
menos eso es lo que se supone en la mayoría de

552
00:21:19,980 --> 00:21:21,840
Palm DPS

553
00:21:21,840 --> 00:21:25,860
y luego  también están las

554
00:21:25,860 --> 00:21:27,299
creencias invariantes en el tiempo de los agentes acerca de cómo la

555
00:21:27,299 --> 00:21:30,179
dinámica de transición del mundo

556
00:21:30,179 --> 00:21:32,940
trae estados que el tiempo T menos uno dos

557
00:21:32,940 --> 00:21:35,159
estados en el tiempo t

558
00:21:35,159 --> 00:21:38,280
en y luego la selección de políticas o la acción

559
00:21:38,280 --> 00:21:41,760
entra en juego en la inferencia inactiva al

560
00:21:41,760 --> 00:21:43,559
enmarcar las acciones como

561
00:21:43,559 --> 00:21:46,980
transiciones controladas para que el B  Matrix no

562
00:21:46,980 --> 00:21:49,020
solo dice cómo debería

563
00:21:49,020 --> 00:21:50,520
verse el mundo ahora dado cómo era

564
00:21:50,520 --> 00:21:52,919
ayer, sino cómo debería verse ahora

565
00:21:52,919 --> 00:21:55,320
dado cómo fue ayer y el hecho de

566
00:21:55,320 --> 00:21:57,720
que tomé esta acción en el tiempo T menos

567
00:21:57,720 --> 00:21:59,820
uno, por lo que Matrix B no es solo

568
00:21:59,820 --> 00:22:01,559
condicionado a estados pasados ​​pero también a

569
00:22:01,559 --> 00:22:04,320
acciones previas, por lo que las políticas Pi entran

570
00:22:04,320 --> 00:22:07,140
en juego como una creencia o una distribución

571
00:22:07,140 --> 00:22:10,020
sobre esas acciones, por lo que las acciones

572
00:22:10,020 --> 00:22:11,880
influyen directamente en las transiciones y

573
00:22:11,880 --> 00:22:13,320
luego en las tra  nsitions afectan los estados,

574
00:22:13,320 --> 00:22:14,520
así es como pensamos acerca de la

575
00:22:14,520 --> 00:22:18,059
acción en muchos escenarios de Palm DP y las

576
00:22:18,059 --> 00:22:20,760
acciones son o políticas Pi son secuencias

577
00:22:20,760 --> 00:22:23,520
de acciones o colecciones de acciones

578
00:22:23,520 --> 00:22:26,039
y luego tenemos esta

579
00:22:26,039 --> 00:22:28,380
función objetivo crítica llamada la energía libre esperada

580
00:22:28,380 --> 00:22:31,080
que determina  qué acciones son

581
00:22:31,080 --> 00:22:33,299
más probables que otras, por lo que al minimizar

582
00:22:33,299 --> 00:22:35,820
la energía libre esperada optimizamos una

583
00:22:35,820 --> 00:22:37,860
creencia sobre las políticas y luego la

584
00:22:37,860 --> 00:22:39,659
energía libre esperada en sí misma es una

585
00:22:39,659 --> 00:22:41,280
función de su modelo generativo sus

586
00:22:41,280 --> 00:22:43,500
creencias sobre el mundo que incluye

587
00:22:43,500 --> 00:22:45,539
esta creencia previa sesgada sobre las

588
00:22:45,539 --> 00:22:47,580
observaciones que espera usted mismo  para ver si

589
00:22:47,580 --> 00:22:50,220
el tipo de función de recompensa ingresa a la

590
00:22:50,220 --> 00:22:52,919
selección de políticas a través de esta energía libre esperada

591
00:22:52,919 --> 00:22:54,240
y es por eso que aún podemos

592
00:22:54,240 --> 00:22:57,000
llamar a todo esto una forma de

593
00:22:57,000 --> 00:22:58,559
problema de inferencia porque estamos

594
00:22:58,559 --> 00:23:00,780
minimizando este límite esperado en la

595
00:23:00,780 --> 00:23:03,600
sorpresa, así y en  al hacerlo, inferimos una especie de

596
00:23:03,600 --> 00:23:05,640
distribución sobre las políticas de las que

597
00:23:05,640 --> 00:23:08,400
luego tomamos muestras para generar

598
00:23:08,400 --> 00:23:10,500
acciones y cambiar el

599
00:23:10,500 --> 00:23:12,539
mundo y  d entonces, como dije, el vector D es

600
00:23:12,539 --> 00:23:14,340
básicamente solo un anterior en esa

601
00:23:14,340 --> 00:23:17,959
distribución de estado oculta inicial,

602
00:23:18,179 --> 00:23:19,260
um,

603
00:23:19,260 --> 00:23:22,679
así que sí, en resumen, para construir un

604
00:23:22,679 --> 00:23:24,120
modelo de inferencia activo de palmdp,

605
00:23:24,120 --> 00:23:26,700
uh, tiene que escribir o codificar

606
00:23:26,700 --> 00:23:29,460
estos abc y D y hay algunos

607
00:23:29,460 --> 00:23:30,900
otros anteriores  también que podemos hablar

608
00:23:30,900 --> 00:23:33,000
como un anterior sobre políticas que se

609
00:23:33,000 --> 00:23:34,980
llama e Vector pero por ahora

610
00:23:34,980 --> 00:23:37,200
puede pensar que la mayor parte del trabajo pesado

611
00:23:37,200 --> 00:23:39,780
en la inferencia activa consiste en

612
00:23:39,780 --> 00:23:41,039
escribir estas cosas

613
00:23:41,039 --> 00:23:43,620
codificando lo que su agente cree sobre

614
00:23:43,620 --> 00:23:46,320
el mundo que  existe en

615
00:23:46,320 --> 00:23:48,120
um y estas cosas, en el caso de estas

616
00:23:48,120 --> 00:23:50,520
distribuciones discretas categóricas,

617
00:23:50,520 --> 00:23:53,159
terminan pareciendo matrices y vectores,

618
00:23:53,159 --> 00:23:54,900
ya que todo son

619
00:23:54,900 --> 00:23:57,059
distribuciones categóricas, no estás tratando

620
00:23:57,059 --> 00:23:59,100
con espacios continuos de infinitas dimensiones

621
00:23:59,100 --> 00:24:01,200
, estás tratando con cosas que

622
00:24:01,200 --> 00:24:02,940
tienen un número discreto.  de entradas como una

623
00:24:02,940 --> 00:24:05,340
matriz de cuatro por cuatro o una matriz de cinco por cinco,

624
00:24:05,340 --> 00:24:07,260


625
00:24:07,260 --> 00:24:10,980
sí, creo que antes de nosotros, sí, así

626
00:24:10,980 --> 00:24:12,299
que voy a hablar de la siguiente parte

627
00:24:12,299 --> 00:24:14,760
como Matlab py  thon

628
00:24:14,760 --> 00:24:17,340
um dialéctica antes de pasar a eso,

629
00:24:17,340 --> 00:24:19,200
aunque tal vez deberíamos hacer una pausa si hay

630
00:24:19,200 --> 00:24:21,780
alguna pregunta

631
00:24:21,780 --> 00:24:25,080
extranjera, sí, genial, gracias,

632
00:24:25,080 --> 00:24:28,020
Daphne o Jakob, ¿quieres proporcionar

633
00:24:28,020 --> 00:24:31,879
algún pensamiento o

634
00:24:35,000 --> 00:24:37,020


635
00:24:37,020 --> 00:24:38,340
reflexión?  podría

636
00:24:38,340 --> 00:24:40,620
ser bueno resolverlo ahora, que está en esa

637
00:24:40,620 --> 00:24:42,360
parametrización de las preferencias anteriores, ¿

638
00:24:42,360 --> 00:24:43,980


639
00:24:43,980 --> 00:24:47,640
puede explicar por qué exactamente es

640
00:24:47,640 --> 00:24:49,980
que cuando las inicializa, simplemente las

641
00:24:49,980 --> 00:24:52,760
hace como

642
00:24:52,799 --> 00:24:55,679
um, los enteros mayores que 1 son mayores

643
00:24:55,679 --> 00:24:57,900
o iguales a uno, pero luego

644
00:24:57,900 --> 00:25:00,299
te gusta?  máximo suave más adelante cuando en

645
00:25:00,299 --> 00:25:02,039
realidad usa una inferencia como por qué

646
00:25:02,039 --> 00:25:04,559
no definimos nuestra preferencia de esas

647
00:25:04,559 --> 00:25:05,820
probabilidades,

648
00:25:05,820 --> 00:25:08,460
sí, eso es bueno, es

649
00:25:08,460 --> 00:25:13,380
un buen punto y es bueno mencionarlo, por

650
00:25:13,620 --> 00:25:15,960
lo general, tanto en Matlab como en la

651
00:25:15,960 --> 00:25:17,940
implementación de python, así que al construir

652
00:25:17,940 --> 00:25:22,559
Pi mdp, tomamos la decisión de hacer

653
00:25:22,559 --> 00:25:24,659
lo mismo cuando está codificando ese vector c en

654
00:25:24,659 --> 00:25:27,299
lugar de codificarlo como

655
00:25:27,299 --> 00:25:29,039
probabilidades, lo que en última instancia debería

656
00:25:29,039 --> 00:25:31,260
ser lo que está buscando.  Escribir aliado es el registro

657
00:25:31,260 --> 00:25:33,840
del vector C, por lo que lo escribe en

658
00:25:33,840 --> 00:25:36,419
términos de probabilidades relativas de registro

659
00:25:36,419 --> 00:25:40,080
y la razón por la que es potencialmente una

660
00:25:40,080 --> 00:25:41,580


661
00:25:41,580 --> 00:25:44,340
parametrización más intuitiva en lugar

662
00:25:44,340 --> 00:25:46,080
de escribirlo directamente en términos

663
00:25:46,080 --> 00:25:49,620
de probabilidades es porque el registro de

664
00:25:49,620 --> 00:25:51,840
la probabilidad es  más como la recompensa real,

665
00:25:51,840 --> 00:25:54,299
así que si volvemos a este

666
00:25:54,299 --> 00:25:56,220
modelo generativo,

667
00:25:56,220 --> 00:25:59,039
la energía libre esperada que es una

668
00:25:59,039 --> 00:26:01,559
energía libre es en realidad

669
00:26:01,559 --> 00:26:02,220
um

670
00:26:02,220 --> 00:26:04,559
y luego una energía libre es una especie

671
00:26:04,559 --> 00:26:06,960
de divergencia KL, está codificada en términos

672
00:26:06,960 --> 00:26:08,820
de bits, que es naturalmente en un

673
00:26:08,820 --> 00:26:10,320
logarítmico  espacio, por

674
00:26:10,320 --> 00:26:13,620
lo que si está escribiendo como antes

675
00:26:13,620 --> 00:26:17,820
en términos de espacio de registro, sabe que

676
00:26:17,820 --> 00:26:21,059
si cambio la cantidad de unidades de registro

677
00:26:21,059 --> 00:26:24,059
en mis preferencias anteriores, lo

678
00:26:24,059 --> 00:26:26,400
tengo, es más linealmente relacionado con el

679
00:26:26,400 --> 00:26:28,380
cambio en el espacio libre esperado  energía para una

680
00:26:28,380 --> 00:26:30,080
política que conduce a esa observación,

681
00:26:30,080 --> 00:26:32,220
mientras que si está escribiendo sobre los antecedentes

682
00:26:32,220 --> 00:26:35,760
en términos de un espacio de probabilidad que, por

683
00:26:35,760 --> 00:26:37,980
ejemplo, el cambio resultante en la

684
00:26:37,980 --> 00:26:39,779
energía libre esperada de cambiar algo  g en el

685
00:26:39,779 --> 00:26:43,320
espacio de probabilidad no será

686
00:26:43,320 --> 00:26:45,120
um lineal, será un cambio no lineal

687
00:26:45,120 --> 00:26:45,900
,

688
00:26:45,900 --> 00:26:48,659
por lo que si pensamos en las recompensas como probabilidades logarítmicas,

689
00:26:48,659 --> 00:26:49,919


690
00:26:49,919 --> 00:26:53,100
algo que es como una unidad logarítmica adicional

691
00:26:53,100 --> 00:26:55,919
o un logaritmo natural, un Nat o un poco

692
00:26:55,919 --> 00:26:59,279
más valioso que otra cosa  eso en

693
00:26:59,279 --> 00:27:00,960
realidad se reflejará en términos de

694
00:27:00,960 --> 00:27:02,460
la diferencia de energía libre esperada

695
00:27:02,460 --> 00:27:04,799
entre ver la Cosa Uno y la cosa

696
00:27:04,799 --> 00:27:06,480
dos, mientras que si codificamos esas dos

697
00:27:06,480 --> 00:27:08,340
cosas en términos de probabilidades,

698
00:27:08,340 --> 00:27:10,020
la diferencia de energía libre esperada no será

699
00:27:10,020 --> 00:27:12,299
tan intuitiva simplemente porque no será

700
00:27:12,299 --> 00:27:13,740
lineal.

701
00:27:13,740 --> 00:27:16,080
um, esa es una razón rápida de por qué

702
00:27:16,080 --> 00:27:18,659
decidimos codificar cosas en el espacio de registro,

703
00:27:18,659 --> 00:27:21,179
pero no hay nada matemáticamente

704
00:27:21,179 --> 00:27:23,039
necesario de ninguna manera, podría fácilmente

705
00:27:23,039 --> 00:27:24,240


706
00:27:24,240 --> 00:27:26,580
escribir los anteriores directamente en términos de

707
00:27:26,580 --> 00:27:29,039
probabilidades, es más como

708
00:27:29,039 --> 00:27:30,779
una forma de  hacer que sea más una recompensa

709
00:27:30,779 --> 00:27:32,460
como realmente

710
00:27:32,460 --> 00:27:36,200
sí, eso tiene mucho sentido gracias,

711
00:27:36,200 --> 00:27:39,860
gracias, Jacob,

712
00:27:40,140 --> 00:27:43,260
sí, um, me pregunto si

713
00:27:43,260 --> 00:27:44,880
hay

714
00:27:44,880 --> 00:27:49,860
un requisito de corazón en las matrices amb

715
00:27:49,860 --> 00:27:53,039
o tensores para ser real.  codificados como

716
00:27:53,039 --> 00:27:56,279
matrices categóricas o porque

717
00:27:56,279 --> 00:27:58,020
pensando en la función de una matriz

718
00:27:58,020 --> 00:28:00,840
y la forma en que el agente la usa para inferir

719
00:28:00,840 --> 00:28:03,000
su estado oculto a partir de una observación, estoy

720
00:28:03,000 --> 00:28:05,340
pensando si

721
00:28:05,340 --> 00:28:07,980
sería posible codificar

722
00:28:07,980 --> 00:28:09,720
espacios de estado de alta dimensión en algo así

723
00:28:09,720 --> 00:28:11,460
como un neural  red que puede

724
00:28:11,460 --> 00:28:14,279
aproximar uh estas

725
00:28:14,279 --> 00:28:17,279
representaciones probabilísticas también uh y aprender a

726
00:28:17,279 --> 00:28:20,039
representar el tipo de relación

727
00:28:20,039 --> 00:28:23,400
entre las observaciones y los estados ocultos

728
00:28:23,400 --> 00:28:25,460
um,

729
00:28:25,500 --> 00:28:29,460
sí, definitivamente Sí, así que básicamente lo

730
00:28:29,460 --> 00:28:32,460
siento, podría haber un me gusta, pero sí,

731
00:28:32,460 --> 00:28:34,080
básicamente, si crees que eso

732
00:28:34,080 --> 00:28:36,779
sería posible y porque yo yo  se siente como

733
00:28:36,779 --> 00:28:39,179
la implementación de python, que estoy seguro de

734
00:28:39,179 --> 00:28:41,880
que obtendrá las ventajas de python

735
00:28:41,880 --> 00:28:43,980
sobre Matlab, uh,

736
00:28:43,980 --> 00:28:46,799
también ofrece la interoperabilidad con

737
00:28:46,799 --> 00:28:51,919
otras bibliotecas y dentro de la ciencia de datos

738
00:28:51,919 --> 00:28:54,659
totalmente, sí, ese es un buen punto,

739
00:28:54,659 --> 00:28:56,880
así que lo mencioné hacia el

740
00:28:56,880 --> 00:28:59,159
principio cuando  habló sobre Palm DPS,

741
00:28:59,159 --> 00:29:01,020
no hay nada sobre Palm DPS que

742
00:29:01,020 --> 00:29:02,520
signifique que todas estas cosas tienen que ser

743
00:29:02,520 --> 00:29:05,279
matrices  Lo principal que define

744
00:29:05,279 --> 00:29:06,600
a EP es que es parcialmente

745
00:29:06,600 --> 00:29:09,419
observable, por lo que el agente solo

746
00:29:09,419 --> 00:29:11,820
puede ver los nodos azules y que es

747
00:29:11,820 --> 00:29:14,100
un proceso markoviano, por lo que hay

748
00:29:14,100 --> 00:29:16,080
una superficialidad temporal en la memoria de

749
00:29:16,080 --> 00:29:18,000
los estados ocultos, pero podría reemplazar

750
00:29:18,000 --> 00:29:21,240
a y b  con cualquier tipo de

751
00:29:21,240 --> 00:29:23,279
parametrizado, tiene que ser una

752
00:29:23,279 --> 00:29:26,159
función de probabilidad adecuada, por lo que debe tener

753
00:29:26,159 --> 00:29:28,080
las propiedades de ser una

754
00:29:28,080 --> 00:29:29,940
probabilidad, no hay nada que signifique

755
00:29:29,940 --> 00:29:32,820
que no puede ser una distribución gaussiana

756
00:29:32,820 --> 00:29:35,159
o koshy multivariada o una distribución de Bernoulli

757
00:29:35,159 --> 00:29:38,279
o eh  sí, cualquier tipo de

758
00:29:38,279 --> 00:29:41,220
familia exponencial o alguna

759
00:29:41,220 --> 00:29:43,440
red neuronal parametrizada

760
00:29:43,440 --> 00:29:46,140
como esa que la gente usa a menudo en el

761
00:29:46,140 --> 00:29:47,399
aprendizaje por refuerzo como si

762
00:29:47,399 --> 00:29:49,200
parametrizaran un modelo de Dinámica solo con

763
00:29:49,200 --> 00:29:51,720
un montón de redes neuronales que dicen

764
00:29:51,720 --> 00:29:53,820
tomar el estado de tiempo en el tiempo T y moverlos

765
00:29:53,820 --> 00:29:56,340
al estado  en el tiempo t más uno, la razón por la que

766
00:29:56,340 --> 00:29:58,799
hay dificultades con eso es simplemente

767
00:29:58,799 --> 00:30:00,899
porque no está claro

768
00:30:00,899 --> 00:30:03,000
cómo calcular cosas como la

769
00:30:03,000 --> 00:30:06,059
energía libre esperada una vez que  rt moverse en

770
00:30:06,059 --> 00:30:07,320
estas

771
00:30:07,320 --> 00:30:10,020
um distribuciones que no se comportan tan bien,

772
00:30:10,020 --> 00:30:12,539
por lo que gran parte de la razón por la que este

773
00:30:12,539 --> 00:30:14,580
marco se desarrolló en la

774
00:30:14,580 --> 00:30:17,220
versión de estado categórica discreta no es solo

775
00:30:17,220 --> 00:30:19,260
porque para modelar

776
00:30:19,260 --> 00:30:21,299
tareas de baja dimensión como alguien jugando una

777
00:30:21,299 --> 00:30:23,880
máquina tragamonedas o decidiendo ir a la izquierda o a la derecha

778
00:30:23,880 --> 00:30:27,240
en  a en un laberinto y es fácil usar estas

779
00:30:27,240 --> 00:30:29,279
distribuciones discretas para dar una

780
00:30:29,279 --> 00:30:30,720
buena descripción de ese comportamiento que es

781
00:30:30,720 --> 00:30:32,640
una cosa pero también es literalmente una

782
00:30:32,640 --> 00:30:34,980
razón matemática por la que

783
00:30:34,980 --> 00:30:37,080
no siempre hay soluciones de forma cerrada para

784
00:30:37,080 --> 00:30:38,820
la energía libre esperada

785
00:30:38,820 --> 00:30:40,559
dependiendo de cuáles sean esos

786
00:30:40,559 --> 00:30:42,899
Las distribuciones parecen, por lo que hay algo de

787
00:30:42,899 --> 00:30:45,000
trabajo para hacer esto, por ejemplo, Magnus

788
00:30:45,000 --> 00:30:48,480
Cudall tiene un artículo sobre entropía donde

789
00:30:48,480 --> 00:30:50,760
calculan la energía libre esperada en

790
00:30:50,760 --> 00:30:52,559
sistemas dinámicos lineales, básicamente, donde

791
00:30:52,559 --> 00:30:54,360
todas estas A y B están representadas por

792
00:30:54,360 --> 00:30:57,059
gaussianas, por lo que lo llaman como un

793
00:30:57,059 --> 00:30:59,940
lineal controlable.  sistema dinámico

794
00:30:59,940 --> 00:31:01,260
y también tienen que hacer algunas

795
00:31:01,260 --> 00:31:03,120
suposiciones acerca de cómo las acciones afectan

796
00:31:03,120 --> 00:31:05,039
la Matriz B  que en realidad ya no es una matriz

797
00:31:05,039 --> 00:31:07,100
, es más como una

798
00:31:07,100 --> 00:31:10,080
gaussiana continua y descubren que los

799
00:31:10,080 --> 00:31:11,880
términos normales que se obtienen con la

800
00:31:11,880 --> 00:31:13,559
energía libre esperada, como la ganancia de información,

801
00:31:13,559 --> 00:31:15,720
son muchas de las cosas interesantes

802
00:31:15,720 --> 00:31:17,760
que obtenemos cuando usamos distribuciones categóricas.

803
00:31:17,760 --> 00:31:19,740
los términos en realidad

804
00:31:19,740 --> 00:31:21,659
desaparecen cuando usamos gaussiano, por lo que en

805
00:31:21,659 --> 00:31:23,520
realidad no obtiene los términos agradables como

806
00:31:23,520 --> 00:31:26,580
la búsqueda de ganancia de información o la

807
00:31:26,580 --> 00:31:28,260
búsqueda de información que normalmente

808
00:31:28,260 --> 00:31:30,720
obtendría al usar categóricos, pero hay

809
00:31:30,720 --> 00:31:32,460
otras formas de sortear eso, como

810
00:31:32,460 --> 00:31:34,080
si usa redes neuronales que aún puede

811
00:31:34,080 --> 00:31:36,600
usar  cosas como enfoques de muestreo para

812
00:31:36,600 --> 00:31:39,240
calcular las energías libres esperadas,

813
00:31:39,240 --> 00:31:40,919
donde básicamente te gusta muestrear un

814
00:31:40,919 --> 00:31:42,600
montón de posibles trayectorias y luego

815
00:31:42,600 --> 00:31:44,820
puedes usar las muestras como una especie de

816
00:31:44,820 --> 00:31:46,679
estilo Monte Carlo para calcular

817
00:31:46,679 --> 00:31:48,179
las energías libres esperadas y muchos de los grupos

818
00:31:48,179 --> 00:31:50,039
que han hecho,

819
00:31:50,039 --> 00:31:52,620
um, como escalar  inferencia activa a

820
00:31:52,620 --> 00:31:54,539
redes neuronales profundas que han usado ese tipo

821
00:31:54,539 --> 00:31:56,340
de enfoque, así como Alec chances paper

822
00:31:56,340 --> 00:31:57,960
Scout scaling active infer  ence hace

823
00:31:57,960 --> 00:31:59,820
cosas así, muchas de las cosas

824
00:31:59,820 --> 00:32:02,940
del grupo de Tim Verbalance,

825
00:32:02,940 --> 00:32:04,620
um, no quiero dejar a nadie en quien

826
00:32:04,620 --> 00:32:07,080
pienso ni ha hecho, obviamente, mucho de

827
00:32:07,080 --> 00:32:08,700
North Vegeta ha hecho muchas

828
00:32:08,700 --> 00:32:11,220
inferencias activas con redes neuronales profundas como  un

829
00:32:11,220 --> 00:32:12,720
virus nos encontró como muchas de estas

830
00:32:12,720 --> 00:32:13,919
personas en realidad estaban tratando de aplicar

831
00:32:13,919 --> 00:32:15,480
la inferencia activa para mantener las redes neuronales

832
00:32:15,480 --> 00:32:17,460
, básicamente tienen que encontrar formas

833
00:32:17,460 --> 00:32:18,960
de calcular la energía libre esperada

834
00:32:18,960 --> 00:32:21,240
que son diferentes a la forma en que se

835
00:32:21,240 --> 00:32:23,279
hace en pi MVP porque en Pine BP

836
00:32:23,279 --> 00:32:25,200
puede calcular exactamente la energía libre esperada

837
00:32:25,200 --> 00:32:27,360
que termina siendo solo un montón

838
00:32:27,360 --> 00:32:29,159
de productos Matrix Vector y luego una

839
00:32:29,159 --> 00:32:30,179
suma,

840
00:32:30,179 --> 00:32:31,919
por lo que se vuelve más difícil

841
00:32:31,919 --> 00:32:34,020
cuando usa distribuciones más complejas,

842
00:32:34,020 --> 00:32:36,480
pero de ninguna manera es

843
00:32:36,480 --> 00:32:37,100


844
00:32:37,100 --> 00:32:39,539
imposible, solo tiene que

845
00:32:39,539 --> 00:32:40,980
venir  con algún tipo de aproximación,

846
00:32:40,980 --> 00:32:43,380
pero creo que hay formas de

847
00:32:43,380 --> 00:32:45,899
sortear eso que involucran lo que yo llamo

848
00:32:45,899 --> 00:32:48,539
lo que la gente ha estado llamando

849
00:32:48,539 --> 00:32:50,159
modelos híbridos en los que podría tener redes neuronales profundas

850
00:32:50,159 --> 00:32:53,100
que f  Ingrese a un DP de palma

851
00:32:53,100 --> 00:32:54,960
en una capa superior y luego

852
00:32:54,960 --> 00:32:56,640
incaute el espacio DP como un

853
00:32:56,640 --> 00:32:58,260
espacio categórico discreto, aún puede calcular

854
00:32:58,260 --> 00:33:00,059
las energías libres esperadas y las energías libres,

855
00:33:00,059 --> 00:33:03,000
pero aún puede aprovechar en

856
00:33:03,000 --> 00:33:04,620
niveles más bajos como

857
00:33:04,620 --> 00:33:07,260
redes neuronales de alta dimensión para proyectar sus datos

858
00:33:07,260 --> 00:33:09,720
en este espacio de baja dimensión para que

859
00:33:09,720 --> 00:33:11,820
haga toda la inferencia activa de efe en este

860
00:33:11,820 --> 00:33:13,620
espacio de Palm DP de menor dimensión donde

861
00:33:13,620 --> 00:33:15,600
todo es exacto, pero aún puede

862
00:33:15,600 --> 00:33:16,740
aprovechar la

863
00:33:16,740 --> 00:33:19,140
reducción de dimensionalidad agradable y

864
00:33:19,140 --> 00:33:20,880
las propiedades de extracción de características de las redes neuronales

865
00:33:20,880 --> 00:33:22,500
para preprocesar primero las

866
00:33:22,500 --> 00:33:24,419
observaciones para que  eso es algo de lo que

867
00:33:24,419 --> 00:33:26,340
hablaré al final porque hemos

868
00:33:26,340 --> 00:33:28,679
progresado un poco en los primeros pasos para

869
00:33:28,679 --> 00:33:30,600
hacerlo posible, lo que implica

870
00:33:30,600 --> 00:33:32,580
básicamente hacer que todo Pi mdp Auto sea

871
00:33:32,580 --> 00:33:34,080
diferenciable para que pueda entrenar

872
00:33:34,080 --> 00:33:36,120
redes neuronales que están conectadas para

873
00:33:36,120 --> 00:33:38,700
bombear la T principal  modelos,

874
00:33:38,700 --> 00:33:41,640
sí, es una gran pregunta, aunque

875
00:33:41,640 --> 00:33:45,059
increíble. Veo esto como el plan corporal

876
00:33:45,059 --> 00:33:48,779
de los modelos generativos y tal vez lo que es  es

877
00:33:48,779 --> 00:33:51,059
como hoy es una antena mañana o se

878
00:33:51,059 --> 00:33:53,580
retrasa se vuelve más largo o más grueso

879
00:33:53,580 --> 00:33:56,159
hay muchas maneras diferentes de intercambiar y

880
00:33:56,159 --> 00:33:58,440
componer diferentes partes del modelo así que

881
00:33:58,440 --> 00:34:00,600
gracias sigan

882
00:34:00,600 --> 00:34:01,860
bien sí

883
00:34:01,860 --> 00:34:03,059
um

884
00:34:03,059 --> 00:34:04,980
así que sí ahora hablemos un poco

885
00:34:04,980 --> 00:34:07,260
sobre el software tradicional para

886
00:34:07,260 --> 00:34:08,820
la investigación de inferencia activa que estoy seguro de que

887
00:34:08,820 --> 00:34:10,020
todos en la llamada en este momento están

888
00:34:10,020 --> 00:34:11,820
familiarizados con la forma original en que se

889
00:34:11,820 --> 00:34:15,540
hizo básicamente fue Carl Friston y

890
00:34:15,540 --> 00:34:17,760
algunos otros escribieron un montón de scripts de Matlab que

891
00:34:17,760 --> 00:34:20,879
forman parte del paquete SPM

892
00:34:20,879 --> 00:34:22,440
que originalmente salió como

893
00:34:22,440 --> 00:34:24,780
neuroimágenes  análisis de datos y

894
00:34:24,780 --> 00:34:26,940
pruebas estadísticas,

895
00:34:26,940 --> 00:34:29,159
y hay un subpaquete llamado Dem o

896
00:34:29,159 --> 00:34:31,139
maximización dinámica de la expectativa que

897
00:34:31,139 --> 00:34:33,000
se usa no solo para la inferencia activa,

898
00:34:33,000 --> 00:34:34,859
incluida la inferencia activa continua,

899
00:34:34,859 --> 00:34:36,599
sino también para el filtrado generalizado

900
00:34:36,599 --> 00:34:39,300
y el ajuste de modelos de espacio de estado no lineales a

901
00:34:39,300 --> 00:34:41,879
partir de datos

902
00:34:41,879 --> 00:34:43,679
empíricos.  tener todo este tipo de

903
00:34:43,679 --> 00:34:46,800
caja de herramientas de inferencia activa discreta, la mayoría

904
00:34:46,800 --> 00:34:48,599
de las cuales tienen el

905
00:34:48,599 --> 00:34:52,199
prefijo SPM subrayado Mt  mdp, por lo que la

906
00:34:52,199 --> 00:34:53,879
función principal que básicamente hace todo lo

907
00:34:53,879 --> 00:34:56,399
que hace Pine MVP en su mayor parte

908
00:34:56,399 --> 00:34:58,740
es contener una función llamada SPM

909
00:34:58,740 --> 00:35:02,339
mdp vbx y, de una

910
00:35:02,339 --> 00:35:04,080
manera irónica, a menudo bromeamos con

911
00:35:04,080 --> 00:35:06,420
que Pine DP es solo un paquete

912
00:35:06,420 --> 00:35:07,980
que  implementa esa función

913
00:35:07,980 --> 00:35:09,599
porque esa función esencialmente

914
00:35:09,599 --> 00:35:12,420
hace inferencia activa y aprendizaje y

915
00:35:12,420 --> 00:35:14,460
todo el mensaje pasa solo en una

916
00:35:14,460 --> 00:35:16,440
llamada, lo que en muchos sentidos es muy bueno

917
00:35:16,440 --> 00:35:18,839
porque solo tiene que pasarle un

918
00:35:18,839 --> 00:35:21,000
mdp y luego en una especie de Black

919
00:35:21,000 --> 00:35:23,339
Boxway le brinda toda la actualización de creencias

920
00:35:23,339 --> 00:35:25,140
y el historial de acciones y todo

921
00:35:25,140 --> 00:35:28,079
lo que necesita,

922
00:35:28,079 --> 00:35:30,599
um, hay a pesar de su elegancia

923
00:35:30,599 --> 00:35:33,000
y es útil y cuán robusto en

924
00:35:33,000 --> 00:35:35,760
realidad es porque puede pasar cualquier

925
00:35:35,760 --> 00:35:37,260
agente con cualquier modelo generativo

926
00:35:37,260 --> 00:35:38,579
y será bastante  mucho trabajo,

927
00:35:38,579 --> 00:35:40,859
el problema se debe a que es solo una

928
00:35:40,859 --> 00:35:42,960
función, no es muy modular, por lo que es

929
00:35:42,960 --> 00:35:45,300
muy difícil componer de manera flexible diferentes

930
00:35:45,300 --> 00:35:47,220
subcálculos de un

931
00:35:47,220 --> 00:35:49,200
proceso de inferencia activo, por lo que si desea hacer algo a

932
00:35:49,200 --> 00:35:50,700
medida

933
00:35:50,700 --> 00:35:53,280
aplicación de inferencia activa donde como

934
00:35:53,280 --> 00:35:55,859
oh um antes de entrar y hacer

935
00:35:55,859 --> 00:35:57,300
inferencia de estado oculto Quiero actualizar los

936
00:35:57,300 --> 00:35:58,859
parámetros de una matriz y quiero

937
00:35:58,859 --> 00:36:01,260
hacerlo de esta manera particular, es muy

938
00:36:01,260 --> 00:36:05,119
difícil hacerlo en SPM mdp vbx así que lo

939
00:36:05,119 --> 00:36:07,380
que veo a menudo  ocurriendo y lo hice

940
00:36:07,380 --> 00:36:09,720
yo mismo en las investigaciones de mi Maestría,

941
00:36:09,720 --> 00:36:11,220
terminé teniendo como cinco versiones diferentes

942
00:36:11,220 --> 00:36:13,140
de esta función que tienen un pequeño

943
00:36:13,140 --> 00:36:15,960
prefijo de especialista para la

944
00:36:15,960 --> 00:36:18,480
cosa específica que estaba haciendo y luego

945
00:36:18,480 --> 00:36:21,119
eso termina siendo como, eh, algo

946
00:36:21,119 --> 00:36:22,500
así como no  eficiente porque está

947
00:36:22,500 --> 00:36:24,060
creando un montón de código repetitivo,

948
00:36:24,060 --> 00:36:26,400
entonces tiene una función que hace la

949
00:36:26,400 --> 00:36:27,900
pequeña versión particular de

950
00:36:27,900 --> 00:36:29,460
inferencia activa que desea explorar en

951
00:36:29,460 --> 00:36:32,220
su proyecto, por lo que simplemente modularizando

952
00:36:32,220 --> 00:36:34,680
esta función, incluso dentro de Matlab,

953
00:36:34,680 --> 00:36:36,839
podría hacer esto.  Básicamente,

954
00:36:36,839 --> 00:36:38,579
haga que las cosas sean mucho más flexibles y

955
00:36:38,579 --> 00:36:41,099
ahorre mucho copiar y pegar el

956
00:36:41,099 --> 00:36:43,280
código.

957
00:36:43,500 --> 00:36:45,420
Otro problema es que la inferencia y la

958
00:36:45,420 --> 00:36:46,980
selección de políticas están arregladas, por lo que no puede

959
00:36:46,980 --> 00:36:48,839
comparar.  e y contrastar diferentes

960
00:36:48,839 --> 00:36:51,060
enfoques de paso de mensajes y

961
00:36:51,060 --> 00:36:52,740
rutinas de selección de acciones, por lo que solo hay una

962
00:36:52,740 --> 00:36:56,099
forma en que se hace en SPM vbx, que se llama

963
00:36:56,099 --> 00:36:58,440
paso de mensajes marginales,

964
00:36:58,440 --> 00:37:01,079
um, por lo que es difícil compararlo

965
00:37:01,079 --> 00:37:02,339
como si cambia el

966
00:37:02,339 --> 00:37:05,700
algoritmo de paso de mensajes mientras que en uh Pi MVP

967
00:37:05,700 --> 00:37:07,800
ahora mismo tenemos dos algoritmos de paso de mensajes

968
00:37:07,800 --> 00:37:09,599
que puede comparar uno al lado del

969
00:37:09,599 --> 00:37:12,000
otro. Quiero decir, esperamos agregar más

970
00:37:12,000 --> 00:37:13,680
en el futuro, lo cual es muy fácil

971
00:37:13,680 --> 00:37:16,920
porque es solo una cosa modular y luego

972
00:37:16,920 --> 00:37:18,119
por lo que estábamos hablando

973
00:37:18,119 --> 00:37:21,000
al principio.  con él solo en virtud de

974
00:37:21,000 --> 00:37:22,859
que está en Matlab, es más difícil de

975
00:37:22,859 --> 00:37:25,140
sintetizar con otros marcos como en el

976
00:37:25,140 --> 00:37:27,839
aprendizaje reforzado, el gimnasio abierto de IA y

977
00:37:27,839 --> 00:37:29,099
las redes neuronales profundas como el

978
00:37:29,099 --> 00:37:32,339
flujo de intensorflow o Pi Torture Jacks, así

979
00:37:32,339 --> 00:37:34,380
que el hecho de que esté en Matlab um

980
00:37:34,380 --> 00:37:36,660
ya es limitado, por supuesto, la gente  he

981
00:37:36,660 --> 00:37:39,420
encontrado formas de hacer como el código um

982
00:37:39,420 --> 00:37:41,700
multiplataforma de lenguaje cruzado

983
00:37:41,700 --> 00:37:44,400
como pasar de Julia a Matlab

984
00:37:44,400 --> 00:37:46,980
a Python y viceversa, pero es

985
00:37:46,980 --> 00:37:49,440
mucho más pesado li  Estoy involucrado en eso

986
00:37:49,440 --> 00:37:52,440
y luego expondré algunas

987
00:37:52,440 --> 00:37:55,619
ventajas y desventajas de Matlab y Python, por lo que

988
00:37:55,619 --> 00:37:57,420
una de las cosas que me gustan de Matlab

989
00:37:57,420 --> 00:37:59,339
es que es muy fácil comenzar con la

990
00:37:59,339 --> 00:38:01,680
programación de matrices. Tiene un buen editor.

991
00:38:01,680 --> 00:38:04,200
Hay mucho.  de uso e historia y

992
00:38:04,200 --> 00:38:06,839
neurociencia computacional, incluso

993
00:38:06,839 --> 00:38:09,720
cuando di este tutorial en un curso sobre

994
00:38:09,720 --> 00:38:11,400
psiquiatría computacional el año pasado

995
00:38:11,400 --> 00:38:13,740
, creo que la mayoría de los

996
00:38:13,740 --> 00:38:16,260
tutoriales todavía usaban Matlab, por lo que todavía hay

997
00:38:16,260 --> 00:38:18,420
una buena razón para usar Matlab solo

998
00:38:18,420 --> 00:38:20,700
por la historia y el  una cantidad de

999
00:38:20,700 --> 00:38:22,440
paquetes que son adecuados para hacer

1000
00:38:22,440 --> 00:38:24,780
cosas de neurociencia y psicofísica, por lo que

1001
00:38:24,780 --> 00:38:26,280
existe esa ventaja, casi como

1002
00:38:26,280 --> 00:38:30,000
un impulso o una ventaja heredada,

1003
00:38:30,000 --> 00:38:32,099
pero, por supuesto, hay problemas como

1004
00:38:32,099 --> 00:38:33,480
propietario, creo que es el más

1005
00:38:33,480 --> 00:38:35,520
grande que debe pagar

1006
00:38:35,520 --> 00:38:38,339
um One Way o  Otra para usar Matlab

1007
00:38:38,339 --> 00:38:40,800
y no hay tanto desarrollo impulsado por la comunidad

1008
00:38:40,800 --> 00:38:43,020
, quiero decir, hay algo como

1009
00:38:43,020 --> 00:38:44,880
el intercambio de archivos, pero no está al mismo

1010
00:38:44,880 --> 00:38:47,400
nivel que algo como Python y  d entonces

1011
00:38:47,400 --> 00:38:49,740
python puede competir con Matlab

1012
00:38:49,740 --> 00:38:51,420
porque tiene programación de matrices en

1013
00:38:51,420 --> 00:38:53,700
forma de numpy, por supuesto, es de código abierto

1014
00:38:53,700 --> 00:38:55,680
, ha sido

1015
00:38:55,680 --> 00:38:57,660
ampliamente adoptado en toneladas de

1016
00:38:57,660 --> 00:39:00,960
campos, no solo académicos, sino también en

1017
00:39:00,960 --> 00:39:02,940
muchas aplicaciones comerciales y hay

1018
00:39:02,940 --> 00:39:05,099
mucha comunidad impulsada  desarrollo

1019
00:39:05,099 --> 00:39:08,940
en forma de paquetes como Pi VP

1020
00:39:08,940 --> 00:39:11,280
um pero una desventaja es que para mí al

1021
00:39:11,280 --> 00:39:12,839
menos no fue tan fácil comenzar

1022
00:39:12,839 --> 00:39:14,520
con Matlab

1023
00:39:14,520 --> 00:39:17,460
um como lo fue con Matlab porque a

1024
00:39:17,460 --> 00:39:19,079
menudo tendrá que instalar un montón de

1025
00:39:19,079 --> 00:39:20,280
cosas y aprender  sobre

1026
00:39:20,280 --> 00:39:21,540
entornos virtuales y tiene que aprender

1027
00:39:21,540 --> 00:39:24,440
sobre muchas más cosas de programación

1028
00:39:24,440 --> 00:39:27,060
antes de comenzar a usar python,

1029
00:39:27,060 --> 00:39:29,040
así que creo que esa es una de las razones por las que

1030
00:39:29,040 --> 00:39:30,780
Matlab sigue siendo útil como

1031
00:39:30,780 --> 00:39:32,520
herramienta pedagógica como el tiempo

1032
00:39:32,520 --> 00:39:33,960
entre obtener Matlab y realmente

1033
00:39:33,960 --> 00:39:36,960
hacer programación  es bastante corto, lo

1034
00:39:36,960 --> 00:39:39,660
cual es bueno,

1035
00:39:39,660 --> 00:39:43,440
así que sí, el paquete se llama eh, está

1036
00:39:43,440 --> 00:39:46,020
dentro de esta organización infraactiva de GitHub

1037
00:39:46,020 --> 00:39:48,839
, se llama Pi MVP y

1038
00:39:48,839 --> 00:39:50,700
puedes pip insta  Llénelo como en un

1039
00:39:50,700 --> 00:39:52,380
entorno virtual o simplemente en su

1040
00:39:52,380 --> 00:39:55,140
instalación base de python

1041
00:39:55,140 --> 00:39:57,540
y luego, una vez que tenga un

1042
00:39:57,540 --> 00:40:00,720
piondp instalado, puede importar y

1043
00:40:00,720 --> 00:40:03,599
usar de una manera modular flexible todos los

1044
00:40:03,599 --> 00:40:05,640
diferentes subpaquetes o submódulos

1045
00:40:05,640 --> 00:40:07,560
como el módulo de agente que básicamente

1046
00:40:07,560 --> 00:40:09,660
simplemente implementa la clase de agente y luego

1047
00:40:09,660 --> 00:40:11,579
hay diferentes módulos como inferencia

1048
00:40:11,579 --> 00:40:13,619
y control y aprendizaje que son

1049
00:40:13,619 --> 00:40:15,119
independientes de un

1050
00:40:15,119 --> 00:40:16,440
agente de inferencia activo y puede

1051
00:40:16,440 --> 00:40:19,200
usarlos para pasar mensajes para

1052
00:40:19,200 --> 00:40:21,119
la inferencia de estado oculto o para calcular

1053
00:40:21,119 --> 00:40:22,320
energías libres esperadas

1054
00:40:22,320 --> 00:40:24,839
en posibles políticas o para  calcule las

1055
00:40:24,839 --> 00:40:27,119
actualizaciones de los parámetros para que todas esas

1056
00:40:27,119 --> 00:40:29,640
cosas se puedan componer y, de manera flexible

1057
00:40:29,640 --> 00:40:31,800
, puede crear una especie de

1058
00:40:31,800 --> 00:40:33,839
agentes de inferencia activos de Frankenstein al componer todas

1059
00:40:33,839 --> 00:40:36,060
estas cosas de la manera personalizada que

1060
00:40:36,060 --> 00:40:38,099
desee

1061
00:40:38,099 --> 00:40:41,160
y mucho de eso, um, el flujo de trabajo principal de

1062
00:40:41,160 --> 00:40:43,260
pione P viene  hasta especificar el

1063
00:40:43,260 --> 00:40:45,060
modelo generativo y las formas de estas

1064
00:40:45,060 --> 00:40:47,640
matrices discretas y luego conectarlas

1065
00:40:47,640 --> 00:40:49,680
al cerebro del agente y

1066
00:40:49,680 --> 00:40:52,020
crear una instancia de un agente para que esté

1067
00:40:52,020 --> 00:40:54,119
prácticamente encapsulado por estas dos líneas en

1068
00:40:54,119 --> 00:40:57,000
la parte inferior, importe el agente de Pine BP

1069
00:40:57,000 --> 00:40:59,400
y luego simplemente cree uno

1070
00:40:59,400 --> 00:41:02,220
conectando el ABC y las D y luego tiene

1071
00:41:02,220 --> 00:41:04,619
este objeto de agente que puede usar para hacer

1072
00:41:04,619 --> 00:41:06,420
estado oculto  inferencia a través de métodos

1073
00:41:06,420 --> 00:41:08,099
como en First States

1074
00:41:08,099 --> 00:41:10,560
inferir políticas, donde el agente

1075
00:41:10,560 --> 00:41:12,240
calcula internamente la energía libre esperada

1076
00:41:12,240 --> 00:41:14,760
de sus políticas y luego,

1077
00:41:14,760 --> 00:41:17,400
finalmente, puede muestrear acciones, por lo que estas

1078
00:41:17,400 --> 00:41:19,260
tres líneas son el tipo de los principales

1079
00:41:19,260 --> 00:41:21,359
actores de cualquier inferencia activa

1080
00:41:21,359 --> 00:41:24,660
Inferencia de política de inferencia de estado de bucle  y

1081
00:41:24,660 --> 00:41:26,820
luego la selección de acciones y

1082
00:41:26,820 --> 00:41:30,320
simplemente las une en un bucle a lo largo del tiempo

1083
00:41:30,359 --> 00:41:32,339
para instanciar un

1084
00:41:32,339 --> 00:41:35,460
proceso de inferencia activo y el tipo de

1085
00:41:35,460 --> 00:41:37,079
circularidad del bucle de percepción de acción

1086
00:41:37,079 --> 00:41:39,300
entra en juego con las entradas

1087
00:41:39,300 --> 00:41:41,880
al agente que son sus observaciones.  y

1088
00:41:41,880 --> 00:41:43,500
los resultados de su selección de acción

1089
00:41:43,500 --> 00:41:45,960
donde los gráficos son sus acciones y, por

1090
00:41:45,960 --> 00:41:48,000
supuesto, debe usar la Última acción

1091
00:41:48,000 --> 00:41:50,640
para luego obtener una nueva observación y eso

1092
00:41:50,640 --> 00:41:53,520
Si lo hace conectando la acción a

1093
00:41:53,520 --> 00:41:55,980
algún entorno, esto también se encuentra en la

1094
00:41:55,980 --> 00:41:57,480
literatura de inferencia activa, a menudo

1095
00:41:57,480 --> 00:41:59,400
denominado proceso generativo, por lo que

1096
00:41:59,400 --> 00:42:00,960
el mundo real que existe

1097
00:42:00,960 --> 00:42:03,119
genera sus datos, por lo que este es el tipo

1098
00:42:03,119 --> 00:42:04,680
de grupo de percepción de acción clásico

1099
00:42:04,680 --> 00:42:06,480
que verá.  promulgó cualquier

1100
00:42:06,480 --> 00:42:08,640
agente de inferencia activo y esto ni siquiera es exclusivo

1101
00:42:08,640 --> 00:42:10,320
de la inferencia activa, así es como

1102
00:42:10,320 --> 00:42:12,119
se enmarcan genéricamente los problemas de aprendizaje por refuerzo,

1103
00:42:12,119 --> 00:42:14,880
por lo que, como AI Jam abierto,

1104
00:42:14,880 --> 00:42:17,040
usa un

1105
00:42:17,040 --> 00:42:20,339
flujo de control de um muy similar, somos como

1106
00:42:20,339 --> 00:42:24,020
um sí Sensory Motor Loop

1107
00:42:24,440 --> 00:42:27,359
así que sí  aquí hay un ejemplo de simplemente

1108
00:42:27,359 --> 00:42:30,359
hacer eso, como importar el agente, configurar

1109
00:42:30,359 --> 00:42:31,980
el modelo generativo y esa es la

1110
00:42:31,980 --> 00:42:33,720
parte más difícil, así que convenientemente

1111
00:42:33,720 --> 00:42:36,420
coloco puntos suspensivos después del punto, pero

1112
00:42:36,420 --> 00:42:37,500
ahí es donde la mayor parte del

1113
00:42:37,500 --> 00:42:38,640
código sucederá: construir el

1114
00:42:38,640 --> 00:42:41,220
modelo generativo  construya el agente,

1115
00:42:41,220 --> 00:42:43,020
construya un entorno que

1116
00:42:43,020 --> 00:42:45,599
puede importar como uno de los

1117
00:42:45,599 --> 00:42:47,820
entornos Pi mdp almacenados o puede obtenerlo

1118
00:42:47,820 --> 00:42:50,040
de un gimnasio AI abierto o puede  Simplemente

1119
00:42:50,040 --> 00:42:51,660
cree su propio entorno, por lo que

1120
00:42:51,660 --> 00:42:53,940
este sería su código que realmente

1121
00:42:53,940 --> 00:42:55,920
describe cómo funciona el mundo, el mundo con

1122
00:42:55,920 --> 00:42:57,900
el que interactúa el agente,

1123
00:42:57,900 --> 00:43:01,319
y luego puede implementar un

1124
00:43:01,319 --> 00:43:02,940
paso de tiempo de inferencia activa con esas pocas

1125
00:43:02,940 --> 00:43:05,339
líneas de código allí mismo y  todo eso

1126
00:43:05,339 --> 00:43:07,740
sería una especie de esas últimas líneas como 8

1127
00:43:07,740 --> 00:43:09,240
a 15, esas estarían

1128
00:43:09,240 --> 00:43:10,560
envueltas dentro de

1129
00:43:10,560 --> 00:43:14,000
un bucle a lo largo del tiempo,

1130
00:43:14,640 --> 00:43:16,500
um, sí, estos son solo más ejemplos de

1131
00:43:16,500 --> 00:43:19,260
como esta sería una forma rápida de que en

1132
00:43:19,260 --> 00:43:20,880
este ejemplo ni siquiera estamos

1133
00:43:20,880 --> 00:43:22,920
activos.  inferencia, pero solo estamos usando

1134
00:43:22,920 --> 00:43:25,079
uno de los algoritmos de paso de mensajes

1135
00:43:25,079 --> 00:43:28,380
del submódulo Algos para hacer una

1136
00:43:28,380 --> 00:43:31,020
inferencia de estado oculto, por lo que en este caso acabo de

1137
00:43:31,020 --> 00:43:33,240
crear una matriz aleatoria. Creé una

1138
00:43:33,240 --> 00:43:36,660
observación aleatoria y di e

1139
00:43:36,660 --> 00:43:39,240
inventé un anterior aleatorio y  entonces puedo hacer

1140
00:43:39,240 --> 00:43:42,420
una actualización ficticia de lo que un agente

1141
00:43:42,420 --> 00:43:43,619
podría estar haciendo durante la

1142
00:43:43,619 --> 00:43:47,099
inferencia de estado oculto y optimizar las Q o las creencias

1143
00:43:47,099 --> 00:43:49,380
sobre los estados ocultos, por lo que este es un

1144
00:43:49,380 --> 00:43:50,520
ejemplo de cómo podría usar

1145
00:43:50,520 --> 00:43:53,160
Pond DP para j  Solo debe hacer una inferencia genérica en

1146
00:43:53,160 --> 00:43:55,380
modelos ocultos de Markov, ni siquiera

1147
00:43:55,380 --> 00:43:58,020
necesita usarlo dentro de un

1148
00:43:58,020 --> 00:44:00,900
bucle de inferencia activo, solo puede usarlo para hacer

1149
00:44:00,900 --> 00:44:02,520
una inferencia estadística similar en un modelo oculto de Markov

1150
00:44:02,520 --> 00:44:04,440
con los algoritmos particulares

1151
00:44:04,440 --> 00:44:06,720
que hemos proporcionado

1152
00:44:06,720 --> 00:44:08,280
y luego de  Por supuesto, una de las ventajas de las

1153
00:44:08,280 --> 00:44:10,560
que hablé sobre el SPM es que

1154
00:44:10,560 --> 00:44:12,180
puede crear procesos de inferencia activos personalizados.

1155
00:44:12,180 --> 00:44:14,400
Hay muchos argumentos adicionales similares

1156
00:44:14,400 --> 00:44:16,200
a la clase de agente donde

1157
00:44:16,200 --> 00:44:18,300
puede activar y desactivar diferentes

1158
00:44:18,300 --> 00:44:21,000
partes de la función de recompensa o la función

1159
00:44:21,000 --> 00:44:23,819
gratuita esperada.  energía para un agente, por

1160
00:44:23,819 --> 00:44:26,339
ejemplo, en este agente, el agente

1161
00:44:26,339 --> 00:44:28,619
no incorpora la utilidad esperada,

1162
00:44:28,619 --> 00:44:30,540
que es el tipo de recompensa.

1163
00:44:30,540 --> 00:44:32,819
C Componente impulsado por el vector de selección de acción,

1164
00:44:32,819 --> 00:44:35,240
pero el agente usa la información de estado, la

1165
00:44:35,240 --> 00:44:37,800
ganancia y el juego de información de parámetros,

1166
00:44:37,800 --> 00:44:39,480
que son otros dos componentes del

1167
00:44:39,480 --> 00:44:42,119
energía libre esperada, por lo que hay muchas

1168
00:44:42,119 --> 00:44:43,500
maneras en que puede crear un

1169
00:44:43,500 --> 00:44:45,619
agente de inferencia activo a medida

1170
00:44:45,619 --> 00:44:47,940
que no se comporte de diferentes

1171
00:44:47,940 --> 00:44:49,800
maneras dependiendo  ing en este tipo de

1172
00:44:49,800 --> 00:44:53,300
argumentos de palabras clave que proporciona,

1173
00:44:54,060 --> 00:44:55,500
um,

1174
00:44:55,500 --> 00:44:57,660
sí, aquí hay solo más ejemplos, como en

1175
00:44:57,660 --> 00:44:58,920
este caso, estamos usando un

1176
00:44:58,920 --> 00:45:00,780
agente de inferencia activo solo para hacer una inferencia de estado oculto

1177
00:45:00,780 --> 00:45:03,060
y ninguna acción, por lo que el agente

1178
00:45:03,060 --> 00:45:04,980
solo infiere Estados ocultos que está

1179
00:45:04,980 --> 00:45:07,200
actualizando  sus creencias sobre la matriz a

1180
00:45:07,200 --> 00:45:08,700
y está actualizando sus creencias sobre el

1181
00:45:08,700 --> 00:45:11,099
vector D o el estado oculto inicial,

1182
00:45:11,099 --> 00:45:12,960
por lo que puede saber simplemente

1183
00:45:12,960 --> 00:45:14,640
juntar todas estas líneas de manera flexible y crear

1184
00:45:14,640 --> 00:45:16,380
un agente que haga lo que

1185
00:45:16,380 --> 00:45:17,940
quiera ni siquiera necesita estar actuando  en el

1186
00:45:17,940 --> 00:45:19,940
mundo técnicamente

1187
00:45:19,940 --> 00:45:22,140
está bien, así que ahora voy a mostrar algunos

1188
00:45:22,140 --> 00:45:25,859
ejemplos de Pine DP en acción,

1189
00:45:25,859 --> 00:45:28,800
este es uno que es un artículo clásico de

1190
00:45:28,800 --> 00:45:31,020
inferencia activa, es uno de mis

1191
00:45:31,020 --> 00:45:33,660
artículos favoritos, fue, creo que se

1192
00:45:33,660 --> 00:45:35,160
llama construcción de escenas e inferencia activa.

1193
00:45:35,160 --> 00:45:37,319
donde está describiendo una tarea

1194
00:45:37,319 --> 00:45:39,839
en la que un agente tiene que hacerlo y esto se usó

1195
00:45:39,839 --> 00:45:41,640
para modelar datos humanos en una

1196
00:45:41,640 --> 00:45:44,160
prueba de psicofísica, un agente tiene que mirar de manera

1197
00:45:44,160 --> 00:45:45,960
contingente para descubrir

1198
00:45:45,960 --> 00:45:48,780
dos de los cuatro cuadrantes que tienen

1199
00:45:48,780 --> 00:45:51,359
imágenes particulares en ellos

1200
00:45:51,359 --> 00:45:53,579
um y hay cuatro cuadrantes en total y

1201
00:45:53,579 --> 00:45:56,579
dos de ellos tienen uh las imágenes de

1202
00:45:56,579 --> 00:45:59,460
interés en ellos y si las dos imágenes

1203
00:45:59,460 --> 00:46:02,640
en este caso son una imagen de pájaro y un gato

1204
00:46:02,640 --> 00:46:05,579
y ese es un ejemplo de una escena de pulgas entonces

1205
00:46:05,579 --> 00:46:07,380
el asiático básicamente o  el ser humano tiene que

1206
00:46:07,380 --> 00:46:09,960
categorizar la escena latente, que se

1207
00:46:09,960 --> 00:46:12,300
define simplemente por la combinación de dos

1208
00:46:12,300 --> 00:46:15,540
imágenes en orden y luego categorizar la

1209
00:46:15,540 --> 00:46:16,859
escena, por lo que es básicamente una

1210
00:46:16,859 --> 00:46:20,040
tarea de categorización de categorización, pero el agente

1211
00:46:20,040 --> 00:46:22,740
necesita mirar de manera contingente y descubrir una secuencia

1212
00:46:22,740 --> 00:46:24,599
de señales antes de saber cuál es esa

1213
00:46:24,599 --> 00:46:27,720
categoría.  es o cuál es esa escena, por lo que

1214
00:46:27,720 --> 00:46:29,940
combina los componentes epistémicos que

1215
00:46:29,940 --> 00:46:31,380
todos conocemos y amamos sobre la

1216
00:46:31,380 --> 00:46:33,660
inferencia activa tratando de descubrir el

1217
00:46:33,660 --> 00:46:36,180
estado oculto del mundo muestreándolo activamente

1218
00:46:36,180 --> 00:46:38,400
, por lo que en este caso están muestreando el

1219
00:46:38,400 --> 00:46:39,720
mundo moviendo sus ojos a diferentes

1220
00:46:39,720 --> 00:46:41,760
cuadrantes para descubrir qué hay

1221
00:46:41,760 --> 00:46:44,760
detrás de ellos y luego elegir

1222
00:46:44,760 --> 00:46:47,280
cuál es la verdadera categoría en función de

1223
00:46:47,280 --> 00:46:49,020
lo que aprendió sobre el mundo y

1224
00:46:49,020 --> 00:46:50,160
ahí es donde está.  tratando de maximizar la

1225
00:46:50,160 --> 00:46:51,780
utilidad porque hay alguna recompensa

1226
00:46:51,780 --> 00:46:55,140
asociada con la categorización correcta,

1227
00:46:55,140 --> 00:46:57,180
por lo que este es un ejemplo de lo que se

1228
00:46:57,180 --> 00:46:58,740
hizo originalmente en Matlab y acabo de

1229
00:46:58,740 --> 00:47:01,020
volver a implementar en pi mdp

1230
00:47:01,020 --> 00:47:03,300
y este es otro ejemplo donde ahora

1231
00:47:03,300 --> 00:47:05,400
la escena es

1232
00:47:05,400 --> 00:47:07,800
um la escena de alimentación entonces  las señales están en

1233
00:47:07,800 --> 00:47:09,780
los dos cuadrantes inferiores en este ejemplo,

1234
00:47:09,780 --> 00:47:12,359
por lo que el agente tiene que mirar alrededor de los

1235
00:47:12,359 --> 00:47:14,099
diferentes cuadrantes y finalmente ve

1236
00:47:14,099 --> 00:47:15,839
que está bien, hay un pájaro en la parte inferior

1237
00:47:15,839 --> 00:47:17,700
derecha, semillas en la parte inferior izquierda, así que esta

1238
00:47:17,700 --> 00:47:20,880
debe ser la escena de alimentación

1239
00:47:20,880 --> 00:47:22,980
um y solo  uh, para mostrar un ejemplo de

1240
00:47:22,980 --> 00:47:24,359
cómo se ve eso realmente en

1241
00:47:24,359 --> 00:47:25,740
la inferencia activa, como qué aspecto tiene el código

1242
00:47:25,740 --> 00:47:27,780
para eso, así que lo primero que

1243
00:47:27,780 --> 00:47:29,160
harías para este es

1244
00:47:29,160 --> 00:47:31,140
configurar tu agente, que nuevamente solo

1245
00:47:31,140 --> 00:47:33,720
arrojas el a b c '  s y D en este

1246
00:47:33,720 --> 00:47:35,760
caso, utilicé un algoritmo de paso de mensajes en particular

1247
00:47:35,760 --> 00:47:36,960
llamado paso de mensajes marginales,

1248
00:47:36,960 --> 00:47:38,640
que es el mismo que se usa en

1249
00:47:38,640 --> 00:47:42,180
Matlab, configura una profundidad de política y un

1250
00:47:42,180 --> 00:47:43,680
horizonte de inferencia que es algo así como

1251
00:47:43,680 --> 00:47:45,420
un  memoria como la cantidad de

1252
00:47:45,420 --> 00:47:48,119
observaciones pasadas que tomas en cuenta

1253
00:47:48,119 --> 00:47:50,700
y luego configuras un entorno, esto

1254
00:47:50,700 --> 00:47:52,980
es como el mundo externo con el

1255
00:47:52,980 --> 00:47:55,500
que el agente interactuará,

1256
00:47:55,500 --> 00:47:57,420
en este caso lo llamo el

1257
00:47:57,420 --> 00:47:59,520
entorno de construcción The Scene, que solo

1258
00:47:59,520 --> 00:48:01,920
me dice una vez que el  el agente mueve sus ojos

1259
00:48:01,920 --> 00:48:03,300
a un lugar determinado, ¿cómo determina eso en

1260
00:48:03,300 --> 00:48:06,180
realidad lo que el agente

1261
00:48:06,180 --> 00:48:07,980
ve a continuación, que será lo que

1262
00:48:07,980 --> 00:48:09,720
sea que esté detrás del cuadrante que

1263
00:48:09,720 --> 00:48:13,200
decidió mirar, así que esas son las

1264
00:48:13,200 --> 00:48:14,819
dos cosas principales, esos son los dos lados de

1265
00:48:14,819 --> 00:48:16,619
la acción?  percepción Haga un bucle entre el agente y

1266
00:48:16,619 --> 00:48:18,780
el entorno

1267
00:48:18,780 --> 00:48:21,900
y, a menudo, lo que es común hacer

1268
00:48:21,900 --> 00:48:24,300
es obtener una observación inicial inicial

1269
00:48:24,300 --> 00:48:26,880
restableciendo el entorno, que es una

1270
00:48:26,880 --> 00:48:29,760
convención tomada de openai gym,

1271
00:48:29,760 --> 00:48:32,220
básicamente hace el entorno, no restablece, es

1272
00:48:32,220 --> 00:48:33,960
como un método del entorno que

1273
00:48:33,960 --> 00:48:36,240
escupe.  extraen las observaciones iniciales

1274
00:48:36,240 --> 00:48:37,619
y, a menudo, es útil en estas

1275
00:48:37,619 --> 00:48:39,359
cosas crear listas o diccionarios

1276
00:48:39,359 --> 00:48:41,819
que tengan un mapeo entre los

1277
00:48:41,819 --> 00:48:43,800
índices de observación  que son como

1278
00:48:43,800 --> 00:48:46,319
números enteros entre cero y cualquier cantidad de

1279
00:48:46,319 --> 00:48:48,420
observaciones que haya y luego a lo que

1280
00:48:48,420 --> 00:48:49,619
realmente corresponden

1281
00:48:49,619 --> 00:48:51,720
semánticamente, por lo que esta es solo una forma muy

1282
00:48:51,720 --> 00:48:54,000
común de gustar porque todo el Palm

1283
00:48:54,000 --> 00:48:56,700
DP y el entorno

1284
00:48:56,700 --> 00:48:59,220
escupirá son como unos en dos y ceros y

1285
00:48:59,220 --> 00:49:00,780
a todos estos les gustan los índices discretos, pero es

1286
00:49:00,780 --> 00:49:02,700
útil tener estas listas que puede

1287
00:49:02,700 --> 00:49:04,980
usar para mapear semánticamente

1288
00:49:04,980 --> 00:49:07,920
índices particulares a,

1289
00:49:07,920 --> 00:49:09,740
um, cosas que son significativas, como

1290
00:49:09,740 --> 00:49:14,160
ver la imagen del pájaro o elegir,

1291
00:49:14,160 --> 00:49:18,420
um, la categoría uno versus la categoría dos

1292
00:49:18,420 --> 00:49:20,579
y luego, una vez que haya terminado  que simplemente

1293
00:49:20,579 --> 00:49:23,400
escribe un bucle a lo largo del tiempo en el que

1294
00:49:23,400 --> 00:49:25,260
básicamente está realizando una inferencia activa

1295
00:49:25,260 --> 00:49:27,240
que consiste en la

1296
00:49:27,240 --> 00:49:29,460
estimación del estado oculto y la inferencia de políticas

1297
00:49:29,460 --> 00:49:32,700
, muestrea una acción

1298
00:49:32,700 --> 00:49:34,680
que luego se retroalimenta al

1299
00:49:34,680 --> 00:49:37,079
entorno para producir otra

1300
00:49:37,079 --> 00:49:38,819
observación y luego eso sucede con el

1301
00:49:38,819 --> 00:49:39,900
tiempo, así que eso es  toda la

1302
00:49:39,900 --> 00:49:41,339
percepción de la acción,

1303
00:49:41,339 --> 00:49:44,339
así que esto es,

1304
00:49:44,339 --> 00:49:45,720
um, sí, así que

1305
00:49:45,720 --> 00:49:48,119
es engañosamente simple, lo corto que

1306
00:49:48,119 --> 00:49:49,920
se ve, pero soy un poco brillante  ng sobre

1307
00:49:49,920 --> 00:49:51,359
algo de lo que hablaré más adelante,

1308
00:49:51,359 --> 00:49:53,880
que mencioné anteriormente, que es tan

1309
00:49:53,880 --> 00:49:55,619
fácil como parece, la parte más difícil en

1310
00:49:55,619 --> 00:49:57,720
realidad se hace mucho antes de que suceda algo de esto,

1311
00:49:57,720 --> 00:49:59,520
que es escribir el a, b,

1312
00:49:59,520 --> 00:50:02,760
c y D, eso es, con mucho, la mayor parte del tiempo

1313
00:50:02,760 --> 00:50:05,460
Una parte intensiva y compleja de

1314
00:50:05,460 --> 00:50:06,839
la inferencia activa es en realidad

1315
00:50:06,839 --> 00:50:08,640
escribir el modelo generativo una vez que tiene

1316
00:50:08,640 --> 00:50:10,680
el modelo generativo escrito,

1317
00:50:10,680 --> 00:50:12,780
el resto básicamente es como un reloj,

1318
00:50:12,780 --> 00:50:15,060
solo tiene que vincular el agente con el

1319
00:50:15,060 --> 00:50:17,160
entorno y luego ejecutar como cinco

1320
00:50:17,160 --> 00:50:19,560
o seis líneas solo  para implementar realmente

1321
00:50:19,560 --> 00:50:20,819
la cosa, pero la parte más difícil es

1322
00:50:20,819 --> 00:50:22,560
escribir esos a, b, c y D

1323
00:50:22,560 --> 00:50:24,799
al principio,

1324
00:50:25,260 --> 00:50:27,119
um, mostraré otro ejemplo al que

1325
00:50:27,119 --> 00:50:28,079


1326
00:50:28,079 --> 00:50:31,740
llamo compañeros de equipo con esteroides, así que en la

1327
00:50:31,740 --> 00:50:33,960
tarea clásica de Teamaze,

1328
00:50:33,960 --> 00:50:35,579
um, olvidé cuál era el original.  el papel

1329
00:50:35,579 --> 00:50:36,900
era, pero es algo que ha sido muy

1330
00:50:36,900 --> 00:50:37,980
popular en la

1331
00:50:37,980 --> 00:50:39,599
literatura de inferencia activa durante un tiempo

1332
00:50:39,599 --> 00:50:41,460
, creo que a Carl se le ocurrió tal vez

1333
00:50:41,460 --> 00:50:44,700
en 2015 o antes, incluso si tienes un

1334
00:50:44,700 --> 00:50:48,119
agente, un ratón que  tiene que visitar dos

1335
00:50:48,119 --> 00:50:51,180
fuentes potenciales de recompensa o

1336
00:50:51,180 --> 00:50:53,160
castigo en su entorno y

1337
00:50:53,160 --> 00:50:55,619
no sabe qué brazo de este compañero de equipo

1338
00:50:55,619 --> 00:50:58,020
contiene la recompensa, por lo que primero tiene que visitar una

1339
00:50:58,020 --> 00:51:00,300
señal antes de saber qué brazo tiene

1340
00:51:00,300 --> 00:51:02,700
la recompensa y cuál no tiene

1341
00:51:02,700 --> 00:51:04,559
recompensa o como un shock como un

1342
00:51:04,559 --> 00:51:07,200
estímulo negativo en este, simplemente

1343
00:51:07,200 --> 00:51:09,660
extendí espacialmente a los compañeros de equipo, por lo que el

1344
00:51:09,660 --> 00:51:12,119
agente ahora tiene que visitar una secuencia de

1345
00:51:12,119 --> 00:51:14,819
pistas, cada una de las cuales revela la ubicación

1346
00:51:14,819 --> 00:51:17,099
del siguiente cubo para descubrir

1347
00:51:17,099 --> 00:51:19,559
la pista final que  es solo la ubicación

1348
00:51:19,559 --> 00:51:22,619
del queso versus el choque,

1349
00:51:22,619 --> 00:51:24,359
por lo que este es otro ejemplo en el que el

1350
00:51:24,359 --> 00:51:26,520
agente primero va a q1, luego sabe

1351
00:51:26,520 --> 00:51:28,200
dónde está Q2 y luego sabe dónde está el

1352
00:51:28,200 --> 00:51:30,300
queso, así que lo llamo

1353
00:51:30,300 --> 00:51:32,099
encadenamiento epistémico porque el agente en

1354
00:51:32,099 --> 00:51:34,740
realidad no tiene  para planificar su raíz

1355
00:51:34,740 --> 00:51:37,020
hasta la ubicación final del

1356
00:51:37,020 --> 00:51:38,940
queso, todo lo que tiene que hacer es llegar a la

1357
00:51:38,940 --> 00:51:41,280
siguiente q, que luego revela dónde está la siguiente

1358
00:51:41,280 --> 00:51:43,880
señal, que finalmente revela dónde está la

1359
00:51:43,880 --> 00:51:47,099
ubicación oculta de la

1360
00:51:47,099 --> 00:51:49,440
recompensa.  estás usando el

1361
00:51:49,440 --> 00:51:53,040
valor epistémico o la curiosidad para permitir que un

1362
00:51:53,040 --> 00:51:56,160
animal temporalmente superficial

1363
00:51:56,160 --> 00:51:58,800
planee su camino hacia,

1364
00:51:58,800 --> 00:52:00,839
um, una recompensa distal o algo

1365
00:52:00,839 --> 00:52:03,300
que no puede planear para llegar a

1366
00:52:03,300 --> 00:52:05,640
um, nuestro priori

1367
00:52:05,640 --> 00:52:07,500
y nuevamente, esto es solo un ejemplo de

1368
00:52:07,500 --> 00:52:09,059
lo que  eso se vería en Pine DP

1369
00:52:09,059 --> 00:52:10,500
donde básicamente se ve exactamente

1370
00:52:10,500 --> 00:52:12,660
igual, es solo que el entorno y

1371
00:52:12,660 --> 00:52:14,579
el modelo generativo son diferentes, pero

1372
00:52:14,579 --> 00:52:16,859
el flujo general del código siempre

1373
00:52:16,859 --> 00:52:21,619
tiene este tipo de canalización clásica,

1374
00:52:21,839 --> 00:52:24,059
um y está bien, ahora lo conseguiré.  al tipo

1375
00:52:24,059 --> 00:52:25,619
de la parte más importante y creo que

1376
00:52:25,619 --> 00:52:28,260
la mayor fuente de

1377
00:52:28,260 --> 00:52:29,880
confusión con la inferencia activa es que la

1378
00:52:29,880 --> 00:52:31,500
parte más difícil es el modelo generativo

1379
00:52:31,500 --> 00:52:34,319
, toda la

1380
00:52:34,319 --> 00:52:36,599
complejidad entra en la codificación de las

1381
00:52:36,599 --> 00:52:38,280
creencias del agente sobre el mundo, así que

1382
00:52:38,280 --> 00:52:40,079
¿cómo escribo el  a B, C y

1383
00:52:40,079 --> 00:52:41,460
D

1384
00:52:41,460 --> 00:52:44,099
en paradigmas como redes neuronales profundas

1385
00:52:44,099 --> 00:52:47,960
o como aprendizaje no supervisado

1386
00:52:47,960 --> 00:52:50,280
, no tiene que escribir el modelo moderno,

1387
00:52:50,280 --> 00:52:51,740
la

1388
00:52:51,740 --> 00:52:54,540
red neuronal aprende el modelo simplemente

1389
00:52:54,540 --> 00:52:57,000
observando montones y montones de  f data, por

1390
00:52:57,000 --> 00:52:59,040
lo que es menos eficiente en la muestra, pero no

1391
00:52:59,040 --> 00:53:01,319
tiene que codificar tanto para empezar, por lo

1392
00:53:01,319 --> 00:53:03,119


1393
00:53:03,119 --> 00:53:06,359
que coincide con una división más grande

1394
00:53:06,359 --> 00:53:08,220
entre el modelo 3 y los enfoques basados ​​​​en modelos

1395
00:53:08,220 --> 00:53:10,140
con redes neuronales más profundas

1396
00:53:10,140 --> 00:53:12,619
.

1397
00:53:12,619 --> 00:53:15,420
emitir efectivamente la muestra la

1398
00:53:15,420 --> 00:53:17,220
complejidad estadística de tener que escribir el

1399
00:53:17,220 --> 00:53:19,380
modelo simplemente juntando un montón

1400
00:53:19,380 --> 00:53:22,140
de aproximadores de funciones no lineales y

1401
00:53:22,140 --> 00:53:24,240
luego simplemente aprendiendo las creencias que el

1402
00:53:24,240 --> 00:53:25,619
agente tiene sobre el mundo simplemente

1403
00:53:25,619 --> 00:53:27,480
bombardeándolo con datos lo mismo

1404
00:53:27,480 --> 00:53:29,339
ocurre  el aprendizaje de refuerzo profundo

1405
00:53:29,339 --> 00:53:32,579
como el aprendizaje DQ en la inferencia activa, los

1406
00:53:32,579 --> 00:53:35,160
agentes son mucho más eficientes en la muestra en

1407
00:53:35,160 --> 00:53:36,300
el sentido de que no necesitan entrenarse

1408
00:53:36,300 --> 00:53:40,740
en miles de millones de vectores de datos, pero

1409
00:53:40,740 --> 00:53:42,240
por otro lado, hay más inversión

1410
00:53:42,240 --> 00:53:44,040
de su parte como modelador porque

1411
00:53:44,040 --> 00:53:45,900
tiene  para escribir explícitamente cuáles son las

1412
00:53:45,900 --> 00:53:48,359
creencias del agente sobre el mundo

1413
00:53:48,359 --> 00:53:49,920
, no solo lo equipa con algo tan

1414
00:53:49,920 --> 00:53:53,220
genérico como una capa convolucional y

1415
00:53:53,220 --> 00:53:55,200
algunas revisiones y cosas y t  Luego, déjelo

1416
00:53:55,200 --> 00:53:57,119
aprender, en realidad tiene que codificar a mano,

1417
00:53:57,119 --> 00:53:59,400
así que creo que esta es una de las

1418
00:53:59,400 --> 00:54:01,800
mayores diferencias entre el aprendizaje por refuerzo basado en modelos,

1419
00:54:01,800 --> 00:54:03,059
en el que en

1420
00:54:03,059 --> 00:54:04,859
realidad codifica un

1421
00:54:04,859 --> 00:54:07,020
modelo generativo general bayesiano del mundo y una especie

1422
00:54:07,020 --> 00:54:08,940
de enfoques más libres de modelos o basados ​​en datos,

1423
00:54:08,940 --> 00:54:11,099
pero  no hay tal

1424
00:54:11,099 --> 00:54:12,660
dicotomía, hay formas de

1425
00:54:12,660 --> 00:54:14,099
combinar los dos,

1426
00:54:14,099 --> 00:54:16,980
pero solo para mostrar,

1427
00:54:16,980 --> 00:54:18,720
um, eso muy específicamente, por ejemplo,

1428
00:54:18,720 --> 00:54:21,780
en esta demostración de construcción de escena que

1429
00:54:21,780 --> 00:54:23,460
mostré hace unas diapositivas si solo

1430
00:54:23,460 --> 00:54:25,940
miras en términos de líneas puras  de código,

1431
00:54:25,940 --> 00:54:28,680
cuál tomó más código, puede

1432
00:54:28,680 --> 00:54:31,440
usar la cantidad de líneas de código como un

1433
00:54:31,440 --> 00:54:34,559
indicador de complejidad estadística o

1434
00:54:34,559 --> 00:54:36,660
cuánta información contiene, por lo que la

1435
00:54:36,660 --> 00:54:38,339
simulación en sí misma que ejecuta el

1436
00:54:38,339 --> 00:54:40,140
bucle de inferencia activo fue como 15 líneas de

1437
00:54:40,140 --> 00:54:42,300
código como y y  ellos y ese código en

1438
00:54:42,300 --> 00:54:44,220
sí ya es muy genérico y no

1439
00:54:44,220 --> 00:54:46,319
específico para la demostración de construcción de escena

1440
00:54:46,319 --> 00:54:48,359
escribiendo el modelo generativo en sí,

1441
00:54:48,359 --> 00:54:49,920
ahí es donde se hace todo el trabajo

1442
00:54:49,920 --> 00:54:51,119
pesado  Aquí es donde se codifica toda la información

1443
00:54:51,119 --> 00:54:53,520
que es específica para esa tarea,

1444
00:54:53,520 --> 00:54:55,980
así que, por ejemplo, solo miro

1445
00:54:55,980 --> 00:54:58,260
cómo creé una matriz, las creencias

1446
00:54:58,260 --> 00:55:00,540
sobre el mapeo de observación para la

1447
00:55:00,540 --> 00:55:02,520
demostración de construcción de escena que ya

1448
00:55:02,520 --> 00:55:05,460
es mucho más código que simplemente ejecutar

1449
00:55:05,460 --> 00:55:07,859
toda la inferencia activa.  simulación así que,

1450
00:55:07,859 --> 00:55:09,540
al igual que por la gran cantidad de

1451
00:55:09,540 --> 00:55:11,220
código, ya se puede decir, oh, sí,

1452
00:55:11,220 --> 00:55:13,200
hay muchas suposiciones e

1453
00:55:13,200 --> 00:55:15,119
información que se está integrando en el

1454
00:55:15,119 --> 00:55:16,559
modelo generativo y de ahí es de donde proviene la mayor

1455
00:55:16,559 --> 00:55:18,480
parte del trabajo pesado de la inferencia activa,

1456
00:55:18,480 --> 00:55:21,260


1457
00:55:21,300 --> 00:55:22,559
um, sí, así que yo  solo creo que es

1458
00:55:22,559 --> 00:55:24,300
importante comentar eso porque es algo

1459
00:55:24,300 --> 00:55:26,640
realmente clave que creo que cualquier persona que

1460
00:55:26,640 --> 00:55:28,440
quiera comenzar a trabajar con

1461
00:55:28,440 --> 00:55:30,599
modelos de inferencia activa en

1462
00:55:30,599 --> 00:55:32,220
espacios de estado discretos debería darse

1463
00:55:32,220 --> 00:55:34,559
cuenta de que el modelo hace la mayor

1464
00:55:34,559 --> 00:55:36,420
parte del trabajo  para ti la energía libre esperada

1465
00:55:36,420 --> 00:55:38,040
sí es una

1466
00:55:38,040 --> 00:55:39,660
función objetivo muy interesante que tiene muchas

1467
00:55:39,660 --> 00:55:41,880
ventajas pero la mayor parte del poder de

1468
00:55:41,880 --> 00:55:44,700
la inferencia activa  se trata de escribir

1469
00:55:44,700 --> 00:55:46,740
cuáles son las creencias de su agente sobre el

1470
00:55:46,740 --> 00:55:48,300
mundo y luego, una vez que tenga

1471
00:55:48,300 --> 00:55:50,520
eso, todo el resto simplemente hace

1472
00:55:50,520 --> 00:55:52,980
el trabajo por usted porque el código pi NDB

1473
00:55:52,980 --> 00:55:55,440
es muy genérico, lo que no es genérico es

1474
00:55:55,440 --> 00:55:56,880
cómo codifica las creencias sobre el

1475
00:55:56,880 --> 00:55:59,000
mundo,

1476
00:55:59,400 --> 00:56:01,680
um, está bien, ahora estoy terminando,

1477
00:56:01,680 --> 00:56:03,960
tal vez deberíamos detenernos solo en eso

1478
00:56:03,960 --> 00:56:05,460
por un segundo, ¿alguien tiene pensamientos,

1479
00:56:05,460 --> 00:56:08,579
comentarios o preguntas sobre esto?

1480
00:56:08,579 --> 00:56:12,359
Si no, puedo continuar y terminar con

1481
00:56:12,359 --> 00:56:16,460
Daphne o Jacob o preguntaré.  uno

1482
00:56:21,300 --> 00:56:23,520
, no tengo ninguna pregunta, está

1483
00:56:23,520 --> 00:56:25,680
bien, ha enfatizado la

1484
00:56:25,680 --> 00:56:28,079
especificación del modelo generativo del agente

1485
00:56:28,079 --> 00:56:29,099


1486
00:56:29,099 --> 00:56:31,680
y ¿qué hay del otro lado de la moneda?

1487
00:56:31,680 --> 00:56:34,740
¿cómo especificamos un proceso generativo?

1488
00:56:34,740 --> 00:56:37,680
¿cómo especificamos el entorno para

1489
00:56:37,680 --> 00:56:40,399
los agentes?

1490
00:56:40,440 --> 00:56:41,880
eso es realmente  buena pregunta, sí,

1491
00:56:41,880 --> 00:56:44,520
básicamente todo lo que dije sobre el

1492
00:56:44,520 --> 00:56:46,680
modelo generativo,

1493
00:56:46,680 --> 00:56:48,540
um, también se aplica al proceso generativo

1494
00:56:48,540 --> 00:56:50,099
,

1495
00:56:50,099 --> 00:56:53,520
excepto el comportamiento interesante del agente,

1496
00:56:53,520 --> 00:56:55,500
sí, quiero decir, puedes pensar en

1497
00:56:55,500 --> 00:56:57,059
el proceso generativo.

1498
00:56:57,059 --> 00:56:58,200


1499
00:56:58,200 --> 00:57:00,059
Creo que el cuello de botella es el

1500
00:57:00,059 --> 00:57:01,920
modelo generativo porque si creas un

1501
00:57:01,920 --> 00:57:04,140
proceso generativo realmente complejo, entonces un

1502
00:57:04,140 --> 00:57:05,819
entorno realmente complejo que tiene todo

1503
00:57:05,819 --> 00:57:08,579
tipo de dinámicas no lineales sofisticadas, pero

1504
00:57:08,579 --> 00:57:10,319
el modelo del mundo del agente es súper

1505
00:57:10,319 --> 00:57:12,420
súper.  simple, por lo que solo cree que

1506
00:57:12,420 --> 00:57:14,400
hay un interruptor de luz que

1507
00:57:14,400 --> 00:57:16,440
está encendido o apagado,

1508
00:57:16,440 --> 00:57:18,839
entonces el posible comportamiento que puede obtener

1509
00:57:18,839 --> 00:57:22,200
de un agente tan simple está limitado

1510
00:57:22,200 --> 00:57:23,880
por la complejidad de su

1511
00:57:23,880 --> 00:57:28,020
modelo generativo, por lo que un generativo muy complejo un

1512
00:57:28,020 --> 00:57:29,760
modelo generativo muy simple será  Todavía

1513
00:57:29,760 --> 00:57:33,000
no muestra un Comportamiento muy interesante,

1514
00:57:33,000 --> 00:57:34,619
incluso si está integrado en un

1515
00:57:34,619 --> 00:57:37,079
proceso generativo complejo, pero la Dinámica más rica

1516
00:57:37,079 --> 00:57:38,700
obviamente sucederá cuando

1517
00:57:38,700 --> 00:57:40,500
tenga un proceso generativo complejo

1518
00:57:40,500 --> 00:57:44,040
y un modelo generativo complejo, por lo que todo

1519
00:57:44,040 --> 00:57:46,920
el trabajo en um para construir el

1520
00:57:46,920 --> 00:57:48,660
modelo generativo que yo haría  Digamos que

1521
00:57:48,660 --> 00:57:50,760
la primera línea aquí también puede

1522
00:57:50,760 --> 00:57:52,319
combinarse con mucho trabajo para generar

1523
00:57:52,319 --> 00:57:54,900
el proceso generativo, que

1524
00:57:54,900 --> 00:57:56,760
en este caso es th  es un

1525
00:57:56,760 --> 00:57:58,319
entorno mundial de cuadrícula epistémica, que es solo un conjunto de

1526
00:57:58,319 --> 00:58:00,660
reglas que dice que cuando el agente está en la

1527
00:58:00,660 --> 00:58:03,000
ubicación de la cola, muéstreles la

1528
00:58:03,000 --> 00:58:04,920
identidad de la cola como esta, es relativamente

1529
00:58:04,920 --> 00:58:06,359
simple

1530
00:58:06,359 --> 00:58:08,760
pero es algo interesante en lo que pensar

1531
00:58:08,760 --> 00:58:10,920
y estoy seguro como usted Daniel ha

1532
00:58:10,920 --> 00:58:13,260
pensado  acerca de esto cuando se trata de

1533
00:58:13,260 --> 00:58:15,000
um, ya conoces tu trabajo sobre la

1534
00:58:15,000 --> 00:58:17,099
inferencia activa y el comportamiento colectivo es

1535
00:58:17,099 --> 00:58:18,960
lo interesante sobre el comportamiento de múltiples agentes,

1536
00:58:18,960 --> 00:58:21,300
en ese caso, el

1537
00:58:21,300 --> 00:58:25,020
proceso generativo son las acciones de otros agentes,

1538
00:58:25,020 --> 00:58:26,819
por lo que el proceso generativo mi proceso generativo

1539
00:58:26,819 --> 00:58:28,980
son en realidad los  salidas de

1540
00:58:28,980 --> 00:58:31,020
otro agente de inferencia activo, así que esa es

1541
00:58:31,020 --> 00:58:32,819
una de las cosas más complicadas con las

1542
00:58:32,819 --> 00:58:34,500
que Daphne y yo tuvimos que lidiar

1543
00:58:34,500 --> 00:58:36,720
cuando estábamos haciendo el y y Mao también

1544
00:58:36,720 --> 00:58:38,339
Mao fue el primer autor de las

1545
00:58:38,339 --> 00:58:40,500
comunidades epistémicas que funcionan como

1546
00:58:40,500 --> 00:58:43,140
una red social Cámara de eco  cosas en

1547
00:58:43,140 --> 00:58:45,119
ese contexto, el proceso generativo es un

1548
00:58:45,119 --> 00:58:47,880
poco más difícil porque

1549
00:58:47,880 --> 00:58:49,980
el proceso en sí mismo consiste en

1550
00:58:49,980 --> 00:58:51,660
otros agentes de inferencia activos que un

1551
00:58:51,660 --> 00:58:54,780
también está actuando, por lo que el flujo de control de ese

1552
00:58:54,780 --> 00:58:55,980
código se verá un poco diferente

1553
00:58:55,980 --> 00:58:57,420
donde tendrá que hacer un bucle sobre

1554
00:58:57,420 --> 00:59:00,599
todos los agentes, obtener acciones de ellos y

1555
00:59:00,599 --> 00:59:02,400
luego usar esas acciones para parametrizar

1556
00:59:02,400 --> 00:59:03,720
las observaciones de todos los demás

1557
00:59:03,720 --> 00:59:05,760
agentes. Quiero decir, eso es solo  una

1558
00:59:05,760 --> 00:59:08,099
declaración genérica sobre simulaciones de múltiples agentes

1559
00:59:08,099 --> 00:59:10,440
en general, pero es particularmente

1560
00:59:10,440 --> 00:59:12,240
interesante cuando piensas en

1561
00:59:12,240 --> 00:59:14,400
agentes que intentan modelar a otros agentes

1562
00:59:14,400 --> 00:59:16,740
porque casi necesariamente cada

1563
00:59:16,740 --> 00:59:18,119
agente de inferencia activo tendrá un

1564
00:59:18,119 --> 00:59:20,400
modelo empobrecido de cómo funciona el mundo

1565
00:59:20,400 --> 00:59:23,819
cuando la forma en que funciona el mundo

1566
00:59:23,819 --> 00:59:25,500
es un grupo de

1567
00:59:25,500 --> 00:59:27,000
agentes de inferencia activos que interactúan, por lo que tendrá

1568
00:59:27,000 --> 00:59:29,819
que equipar necesariamente a cada agente

1569
00:59:29,819 --> 00:59:31,500
con un modelo generativo más simplificado, a

1570
00:59:31,500 --> 00:59:33,660
menos que desee que todos tengan

1571
00:59:33,660 --> 00:59:35,460
una profundidad de recursión infinita y puedan

1572
00:59:35,460 --> 00:59:37,859
simular en su propio modelo generativo

1573
00:59:37,859 --> 00:59:39,480
el  modelos generativos de todos los demás

1574
00:59:39,480 --> 00:59:41,940
agentes, así que sí, eh, quiero decir que

1575
00:59:41,940 --> 00:59:43,020
fue una especie de tangente sobre el caso de

1576
00:59:43,020 --> 00:59:44,460
múltiples agentes, pero creo que es  Es solo

1577
00:59:44,460 --> 00:59:46,619
un

1578
00:59:46,619 --> 00:59:49,140
interesante um complejo interesante para pensar

1579
00:59:49,140 --> 00:59:51,119
en la tensión entre la

1580
00:59:51,119 --> 00:59:52,680
complejidad del modelo generativo y la

1581
00:59:52,680 --> 00:59:54,480
complejidad del proceso generativo y cómo

1582
00:59:54,480 --> 00:59:56,579
se restringen mutuamente el

1583
00:59:56,579 --> 00:59:59,480
comportamiento del otro

1584
01:00:02,400 --> 01:00:04,799
um, está bien, ¿debería continuar? Sí,

1585
01:00:04,799 --> 01:00:06,540
las dos últimas diapositivas.  creo que es el tipo

1586
01:00:06,540 --> 01:00:09,720
de cosas emocionantes, así que aquí hay una lista de

1587
01:00:09,720 --> 01:00:11,099
cosas que nos gustaría hacer con Prime

1588
01:00:11,099 --> 01:00:13,500
DP en el futuro

1589
01:00:13,500 --> 01:00:15,480
, simplemente las repasaré y luego

1590
01:00:15,480 --> 01:00:16,980
me detendré en algunas que creo que son las

1591
01:00:16,980 --> 01:00:19,319
más  importante, por lo que uno es ajustar los modelos Pine DP

1592
01:00:19,319 --> 01:00:21,299
a los datos empíricos, por lo que he

1593
01:00:21,299 --> 01:00:23,160
interactuado mucho con personas de la

1594
01:00:23,160 --> 01:00:24,960
comunidad de psiquiatría computacional que

1595
01:00:24,960 --> 01:00:26,460
están interesadas en crear

1596
01:00:26,460 --> 01:00:30,299
modelos de comportamiento, a menudo comportamiento humano,

1597
01:00:30,299 --> 01:00:32,520
um, que son sus

1598
01:00:32,520 --> 01:00:34,740
modelos de inferencia activa Palm DP y uno de los

1599
01:00:34,740 --> 01:00:37,020
Creo que la mayor limitación de pine DP en este momento

1600
01:00:37,020 --> 01:00:40,319
es que las personas no pueden usar pi mdp para inferir

1601
01:00:40,319 --> 01:00:42,900
los parámetros de inferencia activa de

1602
01:00:42,900 --> 01:00:44,819
un sujeto humano que está realizando alguna

1603
01:00:44,819 --> 01:00:47,220
tarea que es lo que puede hacer en S  PM en este

1604
01:00:47,220 --> 01:00:48,540
momento, pero desafortunadamente no puede hacer eso

1605
01:00:48,540 --> 01:00:51,540
en Pion VP, por lo que esto es realmente alto

1606
01:00:51,540 --> 01:00:53,339
en la lista de prioridades y creo que esto

1607
01:00:53,339 --> 01:00:55,020
es lo que ayudará a que el P primario sea

1608
01:00:55,020 --> 01:00:58,440
realmente competitivo para SPM para las

1609
01:00:58,440 --> 01:00:59,640
comunidades que están interesadas en

1610
01:00:59,640 --> 01:01:02,640
adaptarse a los modelos Pi mdp.  a los datos, por lo que

1611
01:01:02,640 --> 01:01:03,780
son como

1612
01:01:03,780 --> 01:01:05,040
disciplinas científicas más empíricas como

1613
01:01:05,040 --> 01:01:08,040
la psiquiatría computacional,

1614
01:01:08,040 --> 01:01:10,440
um, otras cosas, creo que necesitamos

1615
01:01:10,440 --> 01:01:12,059
mejores interfaces para

1616
01:01:12,059 --> 01:01:13,859
generar y construir modelos generativos en

1617
01:01:13,859 --> 01:01:17,460
este momento, todo ese código involucrado

1618
01:01:17,460 --> 01:01:19,559
en la construcción de matrices A y B que realmente se

1619
01:01:19,559 --> 01:01:21,180
convierte en el cuello de botella.  para cualquiera que

1620
01:01:21,180 --> 01:01:23,280
intente hacer una inferencia activa y en gran parte

1621
01:01:23,280 --> 01:01:25,319
porque construir esas matrices para

1622
01:01:25,319 --> 01:01:27,839
modelos complejos y generosos puede ser un verdadero

1623
01:01:27,839 --> 01:01:29,280
dolor de cabeza, tiene que hacer toda esta extraña

1624
01:01:29,280 --> 01:01:31,680
indexación multidimensional porque,

1625
01:01:31,680 --> 01:01:33,000
como si tuviera un montón de diferentes

1626
01:01:33,000 --> 01:01:34,920
variables que interactúan en el mundo

1627
01:01:34,920 --> 01:01:37,079
tienes que crear matrices multidimensionales masivas

1628
01:01:37,079 --> 01:01:39,180
que tengan diferentes números de

1629
01:01:39,180 --> 01:01:41,160
dimensiones adicionales que correspondan a  Todas

1630
01:01:41,160 --> 01:01:42,720
estas posibles contingencias en el

1631
01:01:42,720 --> 01:01:44,460
mundo se convierten en una

1632
01:01:44,460 --> 01:01:47,339
tabla de búsqueda masiva en la que tiene que codificar todas

1633
01:01:47,339 --> 01:01:49,680
las relaciones entre las variables,

1634
01:01:49,680 --> 01:01:51,480
por lo que creo que podría ser un

1635
01:01:51,480 --> 01:01:52,859
proyecto ambicioso, pero podría haber

1636
01:01:52,859 --> 01:01:55,619
formas de crear realmente una especie de

1637
01:01:55,619 --> 01:01:58,440
interfaz de usuario como usuario.  interfaces que ayudan a las personas a construir

1638
01:01:58,440 --> 01:02:00,540
modelos generativos haciéndoles una

1639
01:02:00,540 --> 01:02:02,579
secuencia de preguntas, por ejemplo,

1640
01:02:02,579 --> 01:02:04,200
si desea que esta variable afecte a esa

1641
01:02:04,200 --> 01:02:05,760
variable y luego, dependiendo de su

1642
01:02:05,760 --> 01:02:08,339
respuesta, puede

1643
01:02:08,339 --> 01:02:10,440
preparar parametrizar parte de una matriz

1644
01:02:10,440 --> 01:02:12,180
o algo así y luego el  la

1645
01:02:12,180 --> 01:02:13,740
estructura real de la ventana de boceto de una matriz

1646
01:02:13,740 --> 01:02:15,900
hasta una secuencia de tipo de preguntas de sí no

1647
01:02:15,900 --> 01:02:17,160
sobre las diferentes

1648
01:02:17,160 --> 01:02:19,740
contingencias en el mundo

1649
01:02:19,740 --> 01:02:21,900
otra cosa es la interfaz con openai

1650
01:02:21,900 --> 01:02:24,119
gym que ya hemos hecho

1651
01:02:24,119 --> 01:02:26,099
como hay algunos ejemplos donde hemos

1652
01:02:26,099 --> 01:02:28,079
hecho esto  Todavía no los he puesto

1653
01:02:28,079 --> 01:02:31,020
en el infraactivo en GitHub, pero

1654
01:02:31,020 --> 01:02:32,880
esto es algo que está abierto,

1655
01:02:32,880 --> 01:02:35,160
es algo muy obvio y

1656
01:02:35,160 --> 01:02:37,500
fácil de hacer.  porque, como escribimos nuestra

1657
01:02:37,500 --> 01:02:40,020
clase de entorno como si estuviera basada

1658
01:02:40,020 --> 01:02:42,240
en un entorno de gimnasio de todos modos,

1659
01:02:42,240 --> 01:02:43,859
una vez que lo haga, se abrirá para

1660
01:02:43,859 --> 01:02:45,780
comparar agentes de inferencia activos con todo

1661
01:02:45,780 --> 01:02:46,920
tipo de algoritmos de aprendizaje de refuerzo

1662
01:02:46,920 --> 01:02:48,000


1663
01:02:48,000 --> 01:02:51,780
en modelos jerárquicos.

1664
01:02:51,780 --> 01:02:54,140
um, básicamente, lo que le permite apilar

1665
01:02:54,140 --> 01:02:56,099
agentes de inferencia jerárquicamente activos

1666
01:02:56,099 --> 01:02:58,559
entre sí, así que sí, hay

1667
01:02:58,559 --> 01:03:00,119
mucha profundidad temporal que puede

1668
01:03:00,119 --> 01:03:02,579
obtener al apilar agentes de inferencia activos

1669
01:03:02,579 --> 01:03:05,160
en cosas jerárquicas, como una

1670
01:03:05,160 --> 01:03:07,680
escala de tiempo de inferencia y planificación que está

1671
01:03:07,680 --> 01:03:10,200
sucediendo en uno más lento  más lento que una

1672
01:03:10,200 --> 01:03:12,420
escala de tiempo submás rápida

1673
01:03:12,420 --> 01:03:14,520
, necesitamos más demostraciones que demuestren el

1674
01:03:14,520 --> 01:03:16,140
aprendizaje de parámetros para que pueda

1675
01:03:16,140 --> 01:03:19,020
actualizar las matrices ab y d. No

1676
01:03:19,020 --> 01:03:21,299
creo que pueda actualizar C hasta ahora y sé que

1677
01:03:21,299 --> 01:03:22,740
esto es algo que Daniel

1678
01:03:22,740 --> 01:03:25,140
me mencionó, que es uh  las personas en su

1679
01:03:25,140 --> 01:03:26,700
Instituto de inferencia activa generalmente están

1680
01:03:26,700 --> 01:03:28,079
interesadas en

1681
01:03:28,079 --> 01:03:29,640
actualizar las creencias sobre los

1682
01:03:29,640 --> 01:03:31,200
parámetros del modelo generativo básicamente

1683
01:03:31,200 --> 01:03:32,460
y luego están las cosas  como la

1684
01:03:32,460 --> 01:03:34,319
inferencia sofisticada, que es una especie

1685
01:03:34,319 --> 01:03:36,000
de versión más reciente de planificación bajo

1686
01:03:36,000 --> 01:03:37,440
inferencia activa

1687
01:03:37,440 --> 01:03:40,200
que es interesante y tiene algunos

1688
01:03:40,200 --> 01:03:42,480
beneficios computacionales y luego,

1689
01:03:42,480 --> 01:03:43,799
de la mano con la inferencia sofisticada,

1690
01:03:43,799 --> 01:03:45,839
va esto que la gente

1691
01:03:45,839 --> 01:03:47,700
ha desarrollado y ha tenido que lidiar con

1692
01:03:47,700 --> 01:03:49,140
el refuerzo profundo  aprendiendo por un tiempo

1693
01:03:49,140 --> 01:03:51,720
cuál es cómo domar

1694
01:03:51,720 --> 01:03:53,460
los espacios de políticas explosivas combinatorias, de modo que cuando

1695
01:03:53,460 --> 01:03:56,280
realiza una planificación profunda a lo largo del tiempo, la

1696
01:03:56,280 --> 01:03:58,200
cantidad de políticas es exponencial en la

1697
01:03:58,200 --> 01:04:01,020
cantidad de pasos de tiempo que planifica, por lo

1698
01:04:01,020 --> 01:04:03,720
que hay varias técnicas para

1699
01:04:03,720 --> 01:04:05,339
lidiar con eso  como la búsqueda de árbol de Monte Carlo,

1700
01:04:05,339 --> 01:04:07,200
que creo que a algunas personas les gusta

1701
01:04:07,200 --> 01:04:09,380
Teofio Champions y otras ya han

1702
01:04:09,380 --> 01:04:11,640
intentado comenzar a implementar sus propias

1703
01:04:11,640 --> 01:04:14,700
implementaciones de Palm DPS para

1704
01:04:14,700 --> 01:04:17,040
um y, en este sentido, solo quiero

1705
01:04:17,040 --> 01:04:19,079
señalar que en realidad estamos muy

1706
01:04:19,079 --> 01:04:21,059
cerca de obtener esto.  trabajando ahora para

1707
01:04:21,059 --> 01:04:23,339
ajustar los modelos Pi mdp a los datos empíricos,

1708
01:04:23,339 --> 01:04:25,980
por lo que hay una rama que um Dimitri

1709
01:04:25,980 --> 01:04:27,420
markovic y yo hemos estado trabajando  trabajando

1710
01:04:27,420 --> 01:04:29,579
llamado el agente Jax Branch,

1711
01:04:29,579 --> 01:04:31,680
básicamente hemos escrito un back-end para pione p

1712
01:04:31,680 --> 01:04:35,160
y Jax que no solo nos permite usar un

1713
01:04:35,160 --> 01:04:37,319
montón de

1714
01:04:37,319 --> 01:04:39,420
técnicas de inferencia probabilística estadística de como numpyro

1715
01:04:39,420 --> 01:04:42,480
para invertir o inferir los parámetros de los

1716
01:04:42,480 --> 01:04:44,819
agentes Pi mdp a partir de datos similares para

1717
01:04:44,819 --> 01:04:47,280
cómputo de instancia uh recopilado de participantes humanos,

1718
01:04:47,280 --> 01:04:49,920
pero el hecho de que también esté

1719
01:04:49,920 --> 01:04:52,440
respaldado en Jacks significa que Pi mdp

1720
01:04:52,440 --> 01:04:54,299
ahora es completamente diferenciable automáticamente,

1721
01:04:54,299 --> 01:04:56,460
por lo que significa que podría apilar una

1722
01:04:56,460 --> 01:04:59,400
capa de red neuronal profunda en similar

1723
01:04:59,400 --> 01:05:01,799
antes de una capa de matriz de un pi VP

1724
01:05:01,799 --> 01:05:03,420
y luego podría usar algo

1725
01:05:03,420 --> 01:05:05,460
como la energía libre variacional o cualquier

1726
01:05:05,460 --> 01:05:07,500
otra función objetiva para

1727
01:05:07,500 --> 01:05:09,660
entrenar automáticamente los parámetros de una

1728
01:05:09,660 --> 01:05:11,880
red neuronal que está vinculada a un agente pi VP

1729
01:05:11,880 --> 01:05:14,280
, así que creo que esto solo se

1730
01:05:14,280 --> 01:05:16,260
vuelve a implementar en back-ends como Pi

1731
01:05:16,260 --> 01:05:18,720
torch y Jacks  es como un gran beneficio

1732
01:05:18,720 --> 01:05:20,700
porque esto realmente le permitirá

1733
01:05:20,700 --> 01:05:22,680
extender pione P a muchos más

1734
01:05:22,680 --> 01:05:25,640
espacios de estado de alta dimensión al vincular

1735
01:05:25,640 --> 01:05:28,260
redes neuronales profundas a varios

1736
01:05:28,260 --> 01:05:31,020
componentes o  f el cuerpo del agente como lo

1737
01:05:31,020 --> 01:05:33,119
estabas describiendo, Daniel

1738
01:05:33,119 --> 01:05:34,619
um, y originalmente hicimos esto solo para

1739
01:05:34,619 --> 01:05:36,359
permitirte ajustar

1740
01:05:36,359 --> 01:05:38,700
datos empíricos, pero tiene el beneficio adicional

1741
01:05:38,700 --> 01:05:41,280
de permitirte diferenciar y

1742
01:05:41,280 --> 01:05:43,619
pasar gradientes de propagación hacia atrás

1743
01:05:43,619 --> 01:05:45,559
que usarías para  actualizar los

1744
01:05:45,559 --> 01:05:48,119
modelos de aprendizaje profundo, lo cual creo que es realmente emocionante,

1745
01:05:48,119 --> 01:05:51,299
así que está casi terminado, quiero decir,

1746
01:05:51,299 --> 01:05:53,579
sí, estamos muy cerca de poner un

1747
01:05:53,579 --> 01:05:55,559
cuaderno que realmente haga eso, si

1748
01:05:55,559 --> 01:05:57,180
miras en la sucursal de Jack del agente, ahora no está

1749
01:05:57,180 --> 01:05:58,980
muy organizado, pero esas cosas

1750
01:05:58,980 --> 01:06:01,680
ahora está allí e implementó

1751
01:06:01,680 --> 01:06:04,799
otra cosa no es ni Sajid y de

1752
01:06:04,799 --> 01:06:07,020
hecho he implementado algunos de los

1753
01:06:07,020 --> 01:06:09,480
entornos de su inferencia activa en papel

1754
01:06:09,480 --> 01:06:11,339
desmitificada en comparación y de hecho lo hemos

1755
01:06:11,339 --> 01:06:15,180
hecho con pi MVP en openai

1756
01:06:15,180 --> 01:06:16,980
gym como en el entorno del lago congelado

1757
01:06:16,980 --> 01:06:19,380
es popular para  simulando el aprendizaje de B Matrix

1758
01:06:19,380 --> 01:06:20,640


1759
01:06:20,640 --> 01:06:21,839
um, así que eso es algo que también es

1760
01:06:21,839 --> 01:06:24,599
como lo hemos hecho y uh,

1761
01:06:24,599 --> 01:06:26,520
necesitamos subir eso o no sé

1762
01:06:26,520 --> 01:06:28,079
escribir un artículo breve hacer algo  Algo con

1763
01:06:28,079 --> 01:06:29,700
eso porque hay muchos como

1764
01:06:29,700 --> 01:06:31,200
estos diferentes zarcillos que se han

1765
01:06:31,200 --> 01:06:33,359
explorado, es solo una cuestión de

1766
01:06:33,359 --> 01:06:34,799
seguir adelante y realmente ponerlos en

1767
01:06:34,799 --> 01:06:37,500
el repositorio de BP de pino,

1768
01:06:37,500 --> 01:06:39,359
um, sí, y luego estas otras cosas que me

1769
01:06:39,359 --> 01:06:42,000
gustaría encontrar tiempo para hacer, pero

1770
01:06:42,000 --> 01:06:43,799
Simplemente no lo he hecho, pero quiero decir, como dije

1771
01:06:43,799 --> 01:06:44,940
al principio, esto fue en gran medida un

1772
01:06:44,940 --> 01:06:47,039
esfuerzo de colaboración, así que tampoco

1773
01:06:47,039 --> 01:06:48,660
quiero ser,

1774
01:06:48,660 --> 01:06:50,700
um necesariamente, el que hace

1775
01:06:50,700 --> 01:06:52,380
todo esto porque creo que también es

1776
01:06:52,380 --> 01:06:54,180
más saludable para  el desarrollo del

1777
01:06:54,180 --> 01:06:55,680
paquete si diferentes personas

1778
01:06:55,680 --> 01:06:57,480
toman la iniciativa en diferentes cosas y lo

1779
01:06:57,480 --> 01:06:58,980
desarrollan a su manera, así que eso es

1780
01:06:58,980 --> 01:07:00,480
algo que generalmente también me gusta

1781
01:07:00,480 --> 01:07:03,059
alentar a todo tipo de

1782
01:07:03,059 --> 01:07:04,140
personas interesadas a involucrarse en el

1783
01:07:04,140 --> 01:07:05,520
desarrollo

1784
01:07:05,520 --> 01:07:08,339
y no  No creo que Brennan esté aquí, pero

1785
01:07:08,339 --> 01:07:11,000
Brennan Klein también es un

1786
01:07:11,000 --> 01:07:12,839


1787
01:07:12,839 --> 01:07:13,920
posdoctorado e investigador científico en

1788
01:07:13,920 --> 01:07:15,240
la Universidad del Noreste en el

1789
01:07:15,240 --> 01:07:17,880
Instituto de Ciencias de la red. Comenzó estas

1790
01:07:17,880 --> 01:07:20,339
becas Pi mdp, por lo que obtuvo fondos de

1791
01:07:20,339 --> 01:07:21,960
N.  ortheastern Creo que también Templeton

1792
01:07:21,960 --> 01:07:24,420
Foundation financiará a personas para trabajar en

1793
01:07:24,420 --> 01:07:26,400
el desarrollo de Pine MVP o en proyectos adyacentes principales de DP

1794
01:07:26,400 --> 01:07:28,619
Creo que la primera

1795
01:07:28,619 --> 01:07:30,839
ronda de solicitudes ha terminado,

1796
01:07:30,839 --> 01:07:32,099
pero sería una buena

1797
01:07:32,099 --> 01:07:33,839
oportunidad para anunciar que creo

1798
01:07:33,839 --> 01:07:35,339
que habrá  otra cohorte en

1799
01:07:35,339 --> 01:07:38,000
el verano, por lo que esta es una especie de

1800
01:07:38,000 --> 01:07:40,680
fuente de financiación aparentemente continua, por lo

1801
01:07:40,680 --> 01:07:42,359
que es agradable ver que otras personas

1802
01:07:42,359 --> 01:07:45,180
están tratando de empujar a Pine VP en

1803
01:07:45,180 --> 01:07:47,339
sus propias direcciones, por lo que es solo un

1804
01:07:47,339 --> 01:07:48,839
desarrollo alentador que quiero

1805
01:07:48,839 --> 01:07:52,319
mantener a todos informados  de

1806
01:07:52,319 --> 01:07:54,299
um oh sí y luego terminaré con

1807
01:07:54,299 --> 01:07:56,359
um

1808
01:07:57,240 --> 01:08:00,180
paciente en el sitio web de lectura de documentos,

1809
01:08:00,180 --> 01:08:01,740
que es realmente bueno para crear

1810
01:08:01,740 --> 01:08:03,960
documentación automática y tenemos un montón de

1811
01:08:03,960 --> 01:08:05,460
demostraciones allí arriba tenemos diferentes

1812
01:08:05,460 --> 01:08:07,440
tutoriales

1813
01:08:07,440 --> 01:08:09,539
um tenemos otra nueva demostración que es  no

1814
01:08:09,539 --> 01:08:11,160
enumerado aquí, que se trata simplemente de

1815
01:08:11,160 --> 01:08:13,140
calcular la variación de la energía libre

1816
01:08:13,140 --> 01:08:15,480
en modelos categóricos discretos, que se

1817
01:08:15,480 --> 01:08:17,939
basa en una demostración de Ryan Smith y

1818
01:08:17,939 --> 01:08:20,040
Christopher White y Carl fursten's

1819
01:08:20,040 --> 01:08:20,819
pap  er

1820
01:08:20,819 --> 01:08:23,698
en uh a diferencia de ese gran artículo de tutorial sobre

1821
01:08:23,698 --> 01:08:26,100
inferencia activa, así que volví a implementar una

1822
01:08:26,100 --> 01:08:28,319
de las demostraciones de ese artículo y ahora

1823
01:08:28,319 --> 01:08:31,020
eso también está en los documentos

1824
01:08:31,020 --> 01:08:33,060
um, sí, así que puedes abrir todos esos

1825
01:08:33,060 --> 01:08:35,100
cuadernos de demostración en colaboración y simplemente

1826
01:08:35,100 --> 01:08:36,960
recorrerlos um y ellos  realmente

1827
01:08:36,960 --> 01:08:38,880
no necesita tener Python instalado

1828
01:08:38,880 --> 01:08:40,198
en su computadora para usarlos,

1829
01:08:40,198 --> 01:08:42,600
simplemente puede abrir los enlaces en colaboración y

1830
01:08:42,600 --> 01:08:44,460
recorrer el código y crear sus propios

1831
01:08:44,460 --> 01:08:46,259
agentes de inferencia activos,

1832
01:08:46,259 --> 01:08:48,238
por lo que es útil para la pedagogía,

1833
01:08:48,238 --> 01:08:49,259
por eso lo mencioné.  si recién

1834
01:08:49,259 --> 01:08:50,880
está comenzando, definitivamente recomendaría

1835
01:08:50,880 --> 01:08:54,238
ir a la documentación,

1836
01:08:54,238 --> 01:08:56,698
así que sí, gracias a todos por escuchar

1837
01:08:56,698 --> 01:08:59,640
y por permitirme darme la oportunidad

1838
01:08:59,640 --> 01:09:01,799
de hablar, fue agradable estar aquí

1839
01:09:01,799 --> 01:09:05,640
como siempre y supongo que como  Sí,

1840
01:09:05,640 --> 01:09:07,620
yo enumeré en la parte inferior para la próxima

1841
01:09:07,620 --> 01:09:08,939
transmisión en vivo, podemos revisar algunos de

1842
01:09:08,939 --> 01:09:10,738
los cuadernos de demostración, pero también

1843
01:09:10,738 --> 01:09:12,660
podríamos revisarlos ahora, si hay tiempo, tal

1844
01:09:12,660 --> 01:09:14,279
vez hablemos primero y luego

1845
01:09:14,279 --> 01:09:15,179
veremos si

1846
01:09:15,179 --> 01:09:17,880
hay tiempo,

1847
01:09:17,880 --> 01:09:21,540
increíble, gracias.  eah, abordemos algunas

1848
01:09:21,540 --> 01:09:25,140
preguntas de Daphne y Jacob. Preguntaré

1849
01:09:25,140 --> 01:09:28,140
algunas del chat en vivo y luego tal

1850
01:09:28,140 --> 01:09:31,738
vez podría compartir

1851
01:09:31,738 --> 01:09:34,920
uno o algunos de los ejemplos en la lectura de

1852
01:09:34,920 --> 01:09:36,479
los documentos y podríamos ver

1853
01:09:36,479 --> 01:09:40,140
estructuralmente de qué se trata la anatomía y la

1854
01:09:40,140 --> 01:09:42,899
fisiología.  un cuaderno así que primero

1855
01:09:42,899 --> 01:09:46,080
Daphne o Jacob alguna

1856
01:09:46,080 --> 01:09:49,339
idea o pregunta,

1857
01:09:52,679 --> 01:09:56,120
sí, adelante,

1858
01:09:56,400 --> 01:09:58,620
um, me pregunto sobre la

1859
01:09:58,620 --> 01:10:00,300
implementación de Jacks,

1860
01:10:00,300 --> 01:10:03,660
¿hay algún requisito para definir

1861
01:10:03,660 --> 01:10:07,400
el proceso generativo

1862
01:10:07,500 --> 01:10:11,160
o se trata solo de definir

1863
01:10:11,160 --> 01:10:13,140
la estructura del  modelo generativo

1864
01:10:13,140 --> 01:10:14,820
que luego ajustamos a los datos experimentales

1865
01:10:14,820 --> 01:10:16,199
y supongo que esto también se relaciona con otra

1866
01:10:16,199 --> 01:10:18,840
pregunta que tuve al escalar estos modelos

1867
01:10:18,840 --> 01:10:21,780
a espacios de estado o procesos generales

1868
01:10:21,780 --> 01:10:24,179
que nosotros, como modeladores, no tenemos la

1869
01:10:24,179 --> 01:10:27,000
libertad para definirnos a nosotros mismos, pero

1870
01:10:27,000 --> 01:10:28,699
queremos

1871
01:10:28,699 --> 01:10:31,159
implementar y  capacite a

1872
01:10:31,159 --> 01:10:34,739
estos agentes en los procesos generales que

1873
01:10:34,739 --> 01:10:37,080
ya existen, como en un entorno en línea

1874
01:10:37,080 --> 01:10:39,780
donde obtiene datos categóricos o

1875
01:10:39,780 --> 01:10:42,500
discretos

1876
01:10:42,600 --> 01:10:45,360
que ingresan,

1877
01:10:45,360 --> 01:10:46,920
sí, totalmente,

1878
01:10:46,920 --> 01:10:48,960
um, así que del lado de

1879
01:10:48,960 --> 01:10:51,360
eso  una gran pregunta del lado de,

1880
01:10:51,360 --> 01:10:54,659
digamos que tenía un plan de agente BP que tenía un

1881
01:10:54,659 --> 01:10:56,159
montón de redes neuronales profundas

1882
01:10:56,159 --> 01:10:59,580
conectadas y quería entrenarlo en

1883
01:10:59,580 --> 01:11:01,320
un entorno implementado, así que es como si estuviera

1884
01:11:01,320 --> 01:11:03,179
ahí fuera, digamos que es un agente

1885
01:11:03,179 --> 01:11:04,739
eso es negociar en el mercado de valores o

1886
01:11:04,739 --> 01:11:06,300
algo así, es como hacer

1887
01:11:06,300 --> 01:11:09,060
apuestas para comprar criptomonedas, digamos

1888
01:11:09,060 --> 01:11:09,960


1889
01:11:09,960 --> 01:11:12,659
en ese caso, de la misma manera para entrenar una

1890
01:11:12,659 --> 01:11:14,280
red neuronal profunda en ese tipo de datos

1891
01:11:14,280 --> 01:11:16,320
, no necesita pasar gradientes a través

1892
01:11:16,320 --> 01:11:18,120
del proceso generativo, ¿cuál de  por

1893
01:11:18,120 --> 01:11:20,159
supuesto, no tiene acceso a usted, está negociando

1894
01:11:20,159 --> 01:11:22,320
en el mercado de valores, por lo que, en ese sentido, no

1895
01:11:22,320 --> 01:11:24,420
hay requisitos para pasar

1896
01:11:24,420 --> 01:11:27,300
gradientes o escribir un

1897
01:11:27,300 --> 01:11:30,060
proceso generativo que también sea diferenciable automáticamente,

1898
01:11:30,060 --> 01:11:32,820
hay un caso en el que querría

1899
01:11:32,820 --> 01:11:34,739
eso que es

1900
01:11:34,739 --> 01:11:37,980
a menudo, en el caso de empíricamente,

1901
01:11:37,980 --> 01:11:40,800
um ajuste de modelos Pine DP a datos, a menudo

1902
01:11:40,800 --> 01:11:43,020
una cosa que desea hacer es

1903
01:11:43,020 --> 01:11:45,000
tener un montón de como, básicamente, tiene

1904
01:11:45,000 --> 01:11:47,219
un historial de acciones y observaciones de

1905
01:11:47,219 --> 01:11:49,679
un participante humano que ajusta el modelo

1906
01:11:49,679 --> 01:11:52,140
t  Los parámetros del agente pi VP que

1907
01:11:52,140 --> 01:11:54,360
mejor explican las acciones observadas de

1908
01:11:54,360 --> 01:11:55,920
su participante y conoce las

1909
01:11:55,920 --> 01:11:57,120
observaciones porque es un

1910
01:11:57,120 --> 01:11:59,219
experimentador que decidió que esta

1911
01:11:59,219 --> 01:12:00,480
persona verá la secuencia de

1912
01:12:00,480 --> 01:12:02,400
observaciones para que pueda hacer todo eso

1913
01:12:02,400 --> 01:12:04,380
sin tener un diferenciable.

1914
01:12:04,380 --> 01:12:07,380
proceso o entorno generativo, pero

1915
01:12:07,380 --> 01:12:09,000
luego hay algo en la

1916
01:12:09,000 --> 01:12:10,860
inferencia bayesiana que se llama como una

1917
01:12:10,860 --> 01:12:12,960
verificación predictiva posterior donde dices Bien,

1918
01:12:12,960 --> 01:12:16,620
dada mi inferencia sobre el

1919
01:12:16,620 --> 01:12:18,840
parámetro del agente pione P, entonces me

1920
01:12:18,840 --> 01:12:20,520
gustaría implementar

1921
01:12:20,520 --> 01:12:23,100
el comportamiento esperado de este agente

1922
01:12:23,100 --> 01:12:25,560
dada mi mejor suposición de cuáles

1923
01:12:25,560 --> 01:12:27,840
son los parámetros de este agente, por lo que se llama

1924
01:12:27,840 --> 01:12:29,640
como una densidad predictiva posterior

1925
01:12:29,640 --> 01:12:32,400
donde usted dice dada

1926
01:12:32,400 --> 01:12:34,500
mi estimación posterior sobre los parámetros del agente,

1927
01:12:34,500 --> 01:12:37,080
cómo se vería en el futuro

1928
01:12:37,080 --> 01:12:39,480
bajo estos parámetros posteriores

1929
01:12:39,480 --> 01:12:42,840
y hacer eso en en  usando numpyro, que

1930
01:12:42,840 --> 01:12:45,420
es el marco de inferencia probabilística

1931
01:12:45,420 --> 01:12:47,699
que usa a Jax como back-end, le

1932
01:12:47,699 --> 01:12:49,800
gustaría tener un generativo  proceso que

1933
01:12:49,800 --> 01:12:52,679
también es autodiferenciable,

1934
01:12:52,679 --> 01:12:54,659
um, pero en ese caso espero que

1935
01:12:54,659 --> 01:12:56,400
escribir esos procesos generativos

1936
01:12:56,400 --> 01:12:58,020
sea fácil porque sería en el

1937
01:12:58,020 --> 01:13:01,199
caso de ajustar el comportamiento de un humano a

1938
01:13:01,199 --> 01:13:02,820
datos experimentales donde están como en

1939
01:13:02,820 --> 01:13:05,159
un entorno de tareas controladas, así que si

1940
01:13:05,159 --> 01:13:07,739
fuera  el caso de tratar de ajustar los parámetros de alguien

1941
01:13:07,739 --> 01:13:10,320
como el valor de su

1942
01:13:10,320 --> 01:13:12,420
vector C y están realizando esa

1943
01:13:12,420 --> 01:13:13,860
tarea de construcción de escena en la que están enfermos

1944
01:13:13,860 --> 01:13:15,300
dando

1945
01:13:15,300 --> 01:13:17,040
vueltas, podría escribir el proceso generativo

1946
01:13:17,040 --> 01:13:18,840
porque usted como el experimento o

1947
01:13:18,840 --> 01:13:21,480
desarrolló la tarea psicofísica

1948
01:13:21,480 --> 01:13:22,739
que  están interactuando con usted podría

1949
01:13:22,739 --> 01:13:24,659
escribir eso también en Jax cuando está haciendo

1950
01:13:24,659 --> 01:13:26,460
el modelado para que cuando esté haciendo

1951
01:13:26,460 --> 01:13:28,620
estas verificaciones predictivas posteriores

1952
01:13:28,620 --> 01:13:30,300
sepa que eso también está escrito en Jacks

1953
01:13:30,300 --> 01:13:31,620
y que puede calcular esas

1954
01:13:31,620 --> 01:13:33,900
cantidades pero en una configuración implementada

1955
01:13:33,900 --> 01:13:35,460
ni siquiera podrá hacer

1956
01:13:35,460 --> 01:13:37,140
ningún tipo de verificación predictiva posterior

1957
01:13:37,140 --> 01:13:39,179
en el futuro porque no sabe cómo

1958
01:13:39,179 --> 01:13:41,219
funciona realmente el entorno.

1959
01:13:41,219 --> 01:13:43,080
entonces

1960
01:13:43,080 --> 01:13:44,940
tendrías que pensar que eso ni siquiera sería algo

1961
01:13:44,940 --> 01:13:47,520
que intentaste hacer en primer lugar,

1962
01:13:47,520 --> 01:13:48,540
pero sí, así que no hay nada

1963
01:13:48,540 --> 01:13:52,020
que te impida inherentemente,

1964
01:13:52,020 --> 01:13:54,000
siempre y cuando los modelos sean diferenciables de

1965
01:13:54,000 --> 01:13:55,140
la misma manera que lo son con  redes neuronales profundas

1966
01:13:55,140 --> 01:13:56,219
, no hay nada que te

1967
01:13:56,219 --> 01:13:57,659
impida simplemente arrojarlas a un

1968
01:13:57,659 --> 01:13:58,980
entorno en el que no sabes cómo funcionan las

1969
01:13:58,980 --> 01:14:01,940
reglas del mundo,

1970
01:14:02,640 --> 01:14:04,199
sí,

1971
01:14:04,199 --> 01:14:06,900
la lógica inexorable de la

1972
01:14:06,900 --> 01:14:10,620
selección natural o la minimización de la energía libre o

1973
01:14:10,620 --> 01:14:13,080
simplemente los sistemas

1974
01:14:13,080 --> 01:14:15,239
que no están en equilibrio, ya sea que sepan o no lo que es  allá afuera,

1975
01:14:15,239 --> 01:14:16,020


1976
01:14:16,020 --> 01:14:18,900
o va a funcionar o no,

1977
01:14:18,900 --> 01:14:21,600
y si falla, falla y el

1978
01:14:21,600 --> 01:14:23,940
entorno computacional nos permite

1979
01:14:23,940 --> 01:14:25,860
existir en este tipo de zona gris donde

1980
01:14:25,860 --> 01:14:28,260
el agente computacional puede estar bastante

1981
01:14:28,260 --> 01:14:30,719
mal adaptado a una configuración implementada dada

1982
01:14:30,719 --> 01:14:33,300
, pero el programa de computadora

1983
01:14:33,300 --> 01:14:35,880
seguirá ejecutándose pero, por supuesto, nos interesan los

1984
01:14:35,880 --> 01:14:38,300
casos en los que el programa informático se ejecuta

1985
01:14:38,300 --> 01:14:42,120
y el agente puede realizar algún tipo

1986
01:14:42,120 --> 01:14:43,100
de

1987
01:14:43,100 --> 01:14:47,520
comportamiento significativo o incluso útil

1988
01:14:47,520 --> 01:14:49,860
exactamente como nosotros.  ¿podríamos todos

1989
01:14:49,860 --> 01:14:52,620
imaginar modelos Prime DP muy simples que funcionarían

1990
01:14:52,620 --> 01:14:54,420
terriblemente en algunas tareas,

1991
01:14:54,420 --> 01:14:56,340
justo como un modelo tonto que tiene dos

1992
01:14:56,340 --> 01:14:57,960
estados ocultos que cree que simplemente

1993
01:14:57,960 --> 01:14:59,580
cambian estocásticamente entre sí

1994
01:14:59,580 --> 01:15:02,340
y luego le das la tarea de

1995
01:15:02,340 --> 01:15:05,520
hacer inversiones en  como una

1996
01:15:05,520 --> 01:15:07,679
cartera de 10 acciones y, por supuesto, su

1997
01:15:07,679 --> 01:15:10,739
modelo no se ajusta, pero la promesa de

1998
01:15:10,739 --> 01:15:13,800
aplicar grandes aproximadores de funciones profundas

1999
01:15:13,800 --> 01:15:15,780
a diferentes extremos del agente Prime DP

2000
01:15:15,780 --> 01:15:18,179
significa que, con suerte, podría

2001
01:15:18,179 --> 01:15:20,760
aprender un buen modelo generativo y

2002
01:15:20,760 --> 01:15:22,739
luego combinarlo con algunos más bajos.

2003
01:15:22,739 --> 01:15:24,719
modelo generativo dimensional en la parte superior que

2004
01:15:24,719 --> 01:15:26,400
puede hacer toda la inferencia y la

2005
01:15:26,400 --> 01:15:28,380
planificación agradables con la inferencia activa, pero

2006
01:15:28,380 --> 01:15:31,320
puede lidiar con espacios de observación y acción de alta dimensión o feos y

2007
01:15:31,320 --> 01:15:33,420
difíciles de domesticar

2008
01:15:33,420 --> 01:15:36,360
mediante el uso de redes neuronales profundas, así

2009
01:15:36,360 --> 01:15:39,000
que creo que esa es realmente la forma de hacerlo solo

2010
01:15:39,000 --> 01:15:40,800
en el  De la misma manera que el aprendizaje profundo ha logrado

2011
01:15:40,800 --> 01:15:42,659
que funcione en muchos casos, esta es

2012
01:15:42,659 --> 01:15:45,120
la forma de hacerlo también con los modelos DP principales.

2013
01:15:45,120 --> 01:15:48,120


2014
01:15:48,120 --> 01:15:50,940
Daphne, ¿cualquier comentario?  o preguntaré algunas

2015
01:15:50,940 --> 01:15:53,719
del chat,

2016
01:15:54,540 --> 01:15:55,920
um, realmente no tengo ninguna pregunta, pero

2017
01:15:55,920 --> 01:15:57,960
creo que es realmente fascinante

2018
01:15:57,960 --> 01:16:00,000
y creo que es realmente emocionante

2019
01:16:00,000 --> 01:16:02,040
pensar en sí, como dijiste, como

2020
01:16:02,040 --> 01:16:06,300
aprender el modelo generativo de como un

2021
01:16:06,300 --> 01:16:07,800
agente aprendiendo su propio modelo generativo

2022
01:16:07,800 --> 01:16:10,560
dado como algunos datos del mundo real para

2023
01:16:10,560 --> 01:16:12,480
averiguar cómo son y supongo

2024
01:16:12,480 --> 01:16:14,040
que en términos de lo que estaban

2025
01:16:14,040 --> 01:16:15,600
hablando con las

2026
01:16:15,600 --> 01:16:18,480
aproximaciones de funciones y numpyro y esas cosas es

2027
01:16:18,480 --> 01:16:22,140
que todavía les gusta lo que son ustedes

2028
01:16:22,140 --> 01:16:24,239
Todavía funciona desde esa base de código

2029
01:16:24,239 --> 01:16:27,360
y luego finalmente los convierte o hace

2030
01:16:27,360 --> 01:16:29,100
que comience desde cero,

2031
01:16:29,100 --> 01:16:31,320
sí, prácticamente comenzamos desde

2032
01:16:31,320 --> 01:16:33,659
cero, lo de pi DCM.

2033
01:16:33,659 --> 01:16:35,400
En realidad, no estoy seguro de cuál es el

2034
01:16:35,400 --> 01:16:37,260
estado de IP porque trabajamos.

2035
01:16:37,260 --> 01:16:39,060
en él como parte del mío anidado, así que ya

2036
01:16:39,060 --> 01:16:40,500
no tengo acceso a ese código,

2037
01:16:40,500 --> 01:16:43,260
pero eso fue más una implementación como

2038
01:16:43,260 --> 01:16:46,739
LaPlace variacional en el que estabas,

2039
01:16:46,739 --> 01:16:48,900
trabajamos en eso junto con inyecciones de

2040
01:16:48,900 --> 01:16:51,960
aplausos variacionales, que es el wa  y que

2041
01:16:51,960 --> 01:16:54,060
haces un descenso de gradiente en energía libre

2042
01:16:54,060 --> 01:16:56,460
cuando intentas hacer una inferencia de

2043
01:16:56,460 --> 01:16:59,640
lo que estamos haciendo ahora en lugar de eso es

2044
01:16:59,640 --> 01:17:02,400
que estamos diciendo que puedes reescribir un modelo DP de pino de

2045
01:17:02,400 --> 01:17:03,600


2046
01:17:03,600 --> 01:17:06,600
modo que puedas pasar gradientes a través de

2047
01:17:06,600 --> 01:17:09,420
él Jacks como acelerado  gradientes y

2048
01:17:09,420 --> 01:17:11,400
luego use numpyro para hacer todo tipo de

2049
01:17:11,400 --> 01:17:13,020
rutinas de ajuste, no solo LaPlace variacional,

2050
01:17:13,020 --> 01:17:16,080
sino que podría usar mcmc, podría

2051
01:17:16,080 --> 01:17:18,540
usar como numpower, solo tiene una biblioteca masiva, ya

2052
01:17:18,540 --> 01:17:21,440
sabe, de diferentes

2053
01:17:21,440 --> 01:17:24,179


2054
01:17:24,179 --> 01:17:25,679
técnicas de inferencia bayesiana aproximada probabilística para que pueda

2055
01:17:25,679 --> 01:17:28,380
tirar el fregadero de la cocina  de

2056
01:17:28,380 --> 01:17:31,800
técnicas de inferencia numpyro en un modelo de DP principal,

2057
01:17:31,800 --> 01:17:34,080
por lo que el desafío es simplemente reescribir

2058
01:17:34,080 --> 01:17:36,239
un modelo de DP principal para que pueda definir como

2059
01:17:36,239 --> 01:17:38,280
una función de probabilidad que va

2060
01:17:38,280 --> 01:17:40,440
desde los parámetros de Palm DP hasta las

2061
01:17:40,440 --> 01:17:42,420
observaciones, que en este caso serían

2062
01:17:42,420 --> 01:17:45,300
las acciones del agente  y para

2063
01:17:45,300 --> 01:17:47,040
hacer eso de una manera que pueda jugar

2064
01:17:47,040 --> 01:17:48,780
amigablemente con Jax, solo teníamos que

2065
01:17:48,780 --> 01:17:51,300
asegurarnos de que todas las funciones internas del

2066
01:17:51,300 --> 01:17:53,340
agente de DP de pino como la inferencia  la

2067
01:17:53,340 --> 01:17:55,679
selección de la acción de planificación, todo eso

2068
01:17:55,679 --> 01:17:58,199
fue escrito en Jacks para que pueda

2069
01:17:58,199 --> 01:18:00,000
pasar gradientes a través de él cuando Compute

2070
01:18:00,000 --> 01:18:03,199
como gradientes de probabilidad de manera efectiva,

2071
01:18:03,199 --> 01:18:05,699
sí, eso tiene mucho sentido,

2072
01:18:05,699 --> 01:18:07,380
sí, está

2073
01:18:07,380 --> 01:18:09,900
bien, haré algunas preguntas

2074
01:18:09,900 --> 01:18:13,140
del chat en vivo, así que lo primero.

2075
01:18:13,140 --> 01:18:15,360
Las descripciones de la inferencia activa

2076
01:18:15,360 --> 01:18:17,100
en la literatura están escritas en

2077
01:18:17,100 --> 01:18:19,380
términos de matrices, pero Pi mdp claramente

2078
01:18:19,380 --> 01:18:20,880
funciona con tensores

2079
01:18:20,880 --> 01:18:23,340
. ¿Tiene una buena referencia sobre cómo las

2080
01:18:23,340 --> 01:18:24,960
operaciones son diferentes al

2081
01:18:24,960 --> 01:18:27,120
generalizar las ecuaciones de matrices

2082
01:18:27,120 --> 01:18:28,940
a tensores?

2083
01:18:28,940 --> 01:18:31,260


2084
01:18:31,260 --> 01:18:32,100
las cosas que

2085
01:18:32,100 --> 01:18:33,840
realmente me frustraron mucho cuando estaba

2086
01:18:33,840 --> 01:18:35,159
aprendiendo por primera vez sobre la inferencia activa

2087
01:18:35,159 --> 01:18:37,340
fue que noté exactamente lo que esta persona

2088
01:18:37,340 --> 01:18:40,260
preguntó es que muchas de las

2089
01:18:40,260 --> 01:18:42,000
operaciones básicas,

2090
01:18:42,000 --> 01:18:42,540
um,

2091
01:18:42,540 --> 01:18:45,960
están escritas como si solo hubiera

2092
01:18:45,960 --> 01:18:47,520
estados ocultos unidimensionales y

2093
01:18:47,520 --> 01:18:50,580
observaciones unidimensionales, por lo que todo

2094
01:18:50,580 --> 01:18:53,159
es  como dijeron productos Matrix Vector

2095
01:18:53,159 --> 01:18:54,840
y Matrix Math, pero lo que realmente estamos

2096
01:18:54,840 --> 01:18:57,239
haciendo son multiplicaciones de tensor y

2097
01:18:57,239 --> 01:19:00,239
productos tensoriales, así que en términos de

2098
01:19:00,239 --> 01:19:03,060
referencias sobre cómo funciona

2099
01:19:03,060 --> 01:19:05,940
eso, sí, así que esencialmente

2100
01:19:05,940 --> 01:19:07,800
no hay nada súper cualitativamente

2101
01:19:07,800 --> 01:19:10,260
diferente. Estas operaciones tensoriales

2102
01:19:10,260 --> 01:19:12,600
que hacemos en pione P son básicamente

2103
01:19:12,600 --> 01:19:15,600
formas más elegantes de expresar

2104
01:19:15,600 --> 01:19:17,880
sumas de multiplicación de matrices, así que ahí está

2105
01:19:17,880 --> 01:19:20,280
la matemática.  todo el

2106
01:19:20,280 --> 01:19:22,380
álgebra lineal estándar es solo la forma en

2107
01:19:22,380 --> 01:19:24,060
que representamos estas

2108
01:19:24,060 --> 01:19:25,920
matrices de alta dimensión como tensores es solo una

2109
01:19:25,920 --> 01:19:27,120
representación más eficiente, así que

2110
01:19:27,120 --> 01:19:29,880
matemáticamente no es nada demasiado loco,

2111
01:19:29,880 --> 01:19:32,340
la forma en que aprendí cómo funcionaba

2112
01:19:32,340 --> 01:19:34,800
fue simplemente mirando las funciones en

2113
01:19:34,800 --> 01:19:37,260
Matlab durante un año hasta que  Lo acabo de

2114
01:19:37,260 --> 01:19:38,820
descubrir, pero no fue fácil y

2115
01:19:38,820 --> 01:19:41,580
definitivamente hay mejores opciones disponibles

2116
01:19:41,580 --> 01:19:42,900
ahora,

2117
01:19:42,900 --> 01:19:45,600
um, así que, una referencia inmediata que

2118
01:19:45,600 --> 01:19:48,719
recomendaré es el apéndice, apéndices

2119
01:19:48,719 --> 01:19:50,460
de

2120
01:19:50,460 --> 01:19:52,920
um Pi mdp, uh, el papel, el papel de archivo,

2121
01:19:52,920 --> 01:19:55,739
para que eso sea así.  Creo que el apéndice a o

2122
01:19:55,739 --> 01:19:57,960
en todos esos apéndices básicamente tratan

2123
01:19:57,960 --> 01:20:01,199
con la versión factorizada de tensor completa

2124
01:20:01,199 --> 01:20:03,179
donde no se trata de matrices sino

2125
01:20:03,179 --> 01:20:05,100
en realidad estamos indexando en dimensiones más altas,

2126
01:20:05,100 --> 01:20:09,120
otro que creo que

2127
01:20:09,120 --> 01:20:11,460
originalmente analiza los

2128
01:20:11,460 --> 01:20:13,860
productos de tensor y la factorización de tensor está

2129
01:20:13,860 --> 01:20:16,500
en un apéndice de

2130
01:20:16,500 --> 01:20:18,540
curiosidad y perspicacia de inferencia activa, que es

2131
01:20:18,540 --> 01:20:19,679
donde hablaron por primera vez como

2132
01:20:19,679 --> 01:20:21,719
novedad y ganancia de información de parámetro,

2133
01:20:21,719 --> 01:20:23,820
eso es un  paper

2134
01:20:23,820 --> 01:20:25,199
um, lo siento, no recuerdo el año en

2135
01:20:25,199 --> 01:20:27,900
que salió, es 2017 o 2018, pero

2136
01:20:27,900 --> 01:20:30,420
sé que el título del artículo se llama inferencia activa,

2137
01:20:30,420 --> 01:20:32,340
curiosidad y perspicacia, y en

2138
01:20:32,340 --> 01:20:34,440
uno de los apéndices en realidad hacen

2139
01:20:34,440 --> 01:20:38,580
las matemáticas completas basadas en tensores y

2140
01:20:38,580 --> 01:20:41,820
luego, finalmente, otra buena referencia es un

2141
01:20:41,820 --> 01:20:44,640
artículo reciente que creo que fue encabezado por

2142
01:20:44,640 --> 01:20:48,780
Teofio Champion. Solo voy a tratar de

2143
01:20:48,780 --> 01:20:50,760
encontrarlo muy rápido porque no

2144
01:20:50,760 --> 01:20:52,739
quiero olvidar esto.

2145
01:20:52,739 --> 01:20:55,679
Tal vez deje de compartir mi pantalla

2146
01:20:55,679 --> 01:20:58,800
.  se detuvo,

2147
01:20:58,800 --> 01:20:59,580


2148
01:20:59,580 --> 01:21:01,080
um, es una muy buena referencia que tiene

2149
01:21:01,080 --> 01:21:02,760
apéndices

2150
01:21:02,760 --> 01:21:04,500
sobre,

2151
01:21:04,500 --> 01:21:07,920
um, hacer matemáticas de tensor

2152
01:21:07,920 --> 01:21:11,600
para inferencia activa en particular

2153
01:21:13,260 --> 01:21:15,600
, también recientemente aprendimos sobre la

2154
01:21:15,600 --> 01:21:18,360
inferencia activa de tiempo de ramificación w  Esto

2155
01:21:18,360 --> 01:21:20,040
habla de algunas de esas cuestiones de

2156
01:21:20,040 --> 01:21:24,480
complejidad computacional y,

2157
01:21:26,219 --> 01:21:27,840


2158
01:21:27,840 --> 01:21:29,699
bueno, sí, debería haber mencionado que

2159
01:21:29,699 --> 01:21:31,380
ese es probablemente el enfoque más prometedor

2160
01:21:31,380 --> 01:21:33,960
hasta la fecha sobre

2161
01:21:33,960 --> 01:21:37,080
el um uh para perfeccionar la

2162
01:21:37,080 --> 01:21:38,820
complejidad computacional de la inferencia activa,

2163
01:21:38,820 --> 01:21:41,400
así que sí, este es de

2164
01:21:41,400 --> 01:21:44,580
teofio  Campeones Mark Gresh Supongo

2165
01:21:44,580 --> 01:21:46,440
que es uno de sus asesores y Howard

2166
01:21:46,440 --> 01:21:49,560
Bowman su otro asesor y eso se

2167
01:21:49,560 --> 01:21:51,600
llama

2168
01:21:51,600 --> 01:21:53,400
inferencia activa de tiempo de bifurcación multimodal y multifactorial que

2169
01:21:53,400 --> 01:21:55,620
acabo de publicar, así que no lo he leído

2170
01:21:55,620 --> 01:21:57,000
yo mismo, pero lo he escuchado de otras personas

2171
01:21:57,000 --> 01:21:59,040
como  Creo que Alec me dijo por casualidad que

2172
01:21:59,040 --> 01:22:01,920
los apéndices son realmente buenos para la

2173
01:22:01,920 --> 01:22:03,780
tecnología, la generalización completa del tensor de

2174
01:22:03,780 --> 01:22:05,940
la inferencia activa, está

2175
01:22:05,940 --> 01:22:08,699
bien, increíble, he agregado todas

2176
01:22:08,699 --> 01:22:09,540
esas

2177
01:22:09,540 --> 01:22:12,239
citas mencionadas en el

2178
01:22:12,239 --> 01:22:13,920
chat en vivo de YouTube,

2179
01:22:13,920 --> 01:22:16,500
gracias, voy a preguntar.  una

2180
01:22:16,500 --> 01:22:19,560
siguiente pregunta de Fausto

2181
01:22:19,560 --> 01:22:22,739
usando un backend Jax hace que sea fácil

2182
01:22:22,739 --> 01:22:24,020
envolver

2183
01:22:24,020 --> 01:22:28,800
pymc3 aplicar MC3 a su alrededor EG para tener pi

2184
01:22:28,800 --> 01:22:32,219
mdp como operador para usar en un modelo pi MC3

2185
01:22:32,219 --> 01:22:35,580
¿Hay algún plan para hacer esto? Pregunto

2186
01:22:35,580 --> 01:22:37,320
porque hay una comunidad bayesiana

2187
01:22:37,320 --> 01:22:41,880
en crecimiento en Python alrededor de Pi MC3,

2188
01:22:41,880 --> 01:22:43,380
eso es realmente interesante.

2189
01:22:43,380 --> 01:22:46,199


2190
01:22:46,199 --> 01:22:48,719


2191
01:22:48,719 --> 01:22:51,600
para ser

2192
01:22:51,600 --> 01:22:52,980
honesto, comenzaré diciendo que no lo sé

2193
01:22:52,980 --> 01:22:55,080
porque mi introducción al

2194
01:22:55,080 --> 01:22:57,840
modelado probabilístico similar en Python fue a

2195
01:22:57,840 --> 01:23:00,300
través de DME Dimitri markovic, quien

2196
01:23:00,300 --> 01:23:02,880
básicamente me convenció de numpyro numpyro es

2197
01:23:02,880 --> 01:23:04,920
el camino hacia el futuro y sé que numpyro

2198
01:23:04,920 --> 01:23:06,840
tiene un  Jack's back-end y creo que

2199
01:23:06,840 --> 01:23:10,440
numpyro y Pi MC3 ocupan un

2200
01:23:10,440 --> 01:23:13,199
lugar similar en ese ecosistema de

2201
01:23:13,199 --> 01:23:16,020
inferencia probabilística en Python

2202
01:23:16,020 --> 01:23:18,300
um, no sé cómo se especifican los modelos

2203
01:23:18,300 --> 01:23:22,020
en pi MC3. Supongo que no es muy

2204
01:23:22,020 --> 01:23:24,300
diferente de cómo se ve en numpyro

2205
01:23:24,300 --> 01:23:26,520
y porque  todo el back-end de bajo nivel

2206
01:23:26,520 --> 01:23:29,880
ahora está escrito en Jax. No puedo prometer

2207
01:23:29,880 --> 01:23:31,860
esto, pero supongo que

2208
01:23:31,860 --> 01:23:34,140
podrías escribir un modelo pi MC3 y de la misma

2209
01:23:34,140 --> 01:23:36,480
manera que escribimos, escribimos un modelo numpyro

2210
01:23:36,480 --> 01:23:40,500
que envuelve las funciones um Pi mdp pero solo

2211
01:23:40,500 --> 01:23:43,620
la implementación pi MVP  inyecta, por lo que si

2212
01:23:43,620 --> 01:23:46,020
Pine Z3 solo depende de Jax en el

2213
01:23:46,020 --> 01:23:48,600
nivel bajo, entonces sí, ciertamente puede funcionar,

2214
01:23:48,600 --> 01:23:50,699
pero no sé si hay alguien más

2215
01:23:50,699 --> 01:23:53,040
aquí que tenga experiencia en el uso de Pine G3

2216
01:23:53,040 --> 01:23:55,320
y podría saberlo

2217
01:23:55,320 --> 01:23:56,820
porque simplemente no sé lo suficiente.

2218
01:23:56,820 --> 01:23:58,560


2219
01:23:58,560 --> 01:24:01,320
usé YMC un poco, pero

2220
01:24:01,320 --> 01:24:03,239
creo que sí, como dijiste, bastante

2221
01:24:03,239 --> 01:24:05,400
similar a numpyro, creo que probablemente

2222
01:24:05,400 --> 01:24:07,560
podrías

2223
01:24:07,560 --> 01:24:10,080
hacer las mismas cosas que estás haciendo

2224
01:24:10,080 --> 01:24:12,480
con numpirers, como integrar Pyro

2225
01:24:12,480 --> 01:24:15,540
pi MC3 también

2226
01:24:15,540 --> 01:24:18,360
ah genial y entonces es su principal um back-

2227
01:24:18,360 --> 01:24:19,800
end es Jax

2228
01:24:19,800 --> 01:24:21,239
es que

2229
01:24:21,239 --> 01:24:25,099
um en realidad no hice eso um

2230
01:24:25,620 --> 01:24:28,460
tampoco sabía que sí

2231
01:24:28,460 --> 01:24:31,980
en comparación con la

2232
01:24:31,980 --> 01:24:35,219
multiplicación de matriz de Matlab

2233
01:24:35,219 --> 01:24:37,380
lo que te emociona con la

2234
01:24:37,380 --> 01:24:40,980
probabilidad  Dirección de programación y

2235
01:24:40,980 --> 01:24:42,780
todos estos paquetes y enfoques

2236
01:24:42,780 --> 01:24:44,820
que estamos nombrando ¿En qué se

2237
01:24:44,820 --> 01:24:48,179
diferencia la programación probabilística de

2238
01:24:48,179 --> 01:24:51,420
simplemente escribir las matrices y

2239
01:24:51,420 --> 01:24:54,000
calcularlas en papel y por

2240
01:24:54,000 --> 01:24:56,880
qué tiene alguna promesa para implementar

2241
01:24:56,880 --> 01:24:59,400
modelos de

2242
01:24:59,400 --> 01:25:01,880
inferencia activos?  k la mayor

2243
01:25:01,880 --> 01:25:03,780
ventaja de la

2244
01:25:03,780 --> 01:25:05,940
programación probabilística no es necesariamente

2245
01:25:05,940 --> 01:25:08,400
para simular agentes de inferencia activos para

2246
01:25:08,400 --> 01:25:10,020
simular agentes de inferencia activos

2247
01:25:10,020 --> 01:25:12,659
seguro que las multiplicaciones de Matrix son

2248
01:25:12,659 --> 01:25:15,840
suficientes tenerlo en Jax lo hace

2249
01:25:15,840 --> 01:25:18,480
mucho más escalable para que pueda usar todas

2250
01:25:18,480 --> 01:25:21,120
las operaciones vectorizadas para ejecutar como

2251
01:25:21,120 --> 01:25:22,980
decenas de  miles de

2252
01:25:22,980 --> 01:25:24,600
agentes de inferencia activos simultáneamente porque tiene

2253
01:25:24,600 --> 01:25:25,620
estas

2254
01:25:25,620 --> 01:25:28,440


2255
01:25:28,440 --> 01:25:30,840
funciones compiladas justo a tiempo altamente optimizadas y Jacks que le

2256
01:25:30,840 --> 01:25:32,280
permiten básicamente acelerar las cosas en un orden

2257
01:25:32,280 --> 01:25:34,860
de magnitud, pero el

2258
01:25:34,860 --> 01:25:36,540
ángulo de programación probabilística no es tanto para

2259
01:25:36,540 --> 01:25:39,060
simular procesos de inferencia activos como

2260
01:25:39,060 --> 01:25:41,100
es para hacer inferencias

2261
01:25:41,100 --> 01:25:43,620
o ajustar modelos de

2262
01:25:43,620 --> 01:25:46,860
agentes de inferencia activos a datos empíricos, por ejemplo, observar a

2263
01:25:46,860 --> 01:25:49,460
un animal o una persona haciendo algo

2264
01:25:49,460 --> 01:25:53,040
ahora qué podemos hacer, lo cual solo podemos

2265
01:25:53,040 --> 01:25:55,440
hacer un SPM pero no podemos hacerlo en Pine VP todavía

2266
01:25:55,440 --> 01:25:58,080
hasta ahora  es que podemos tomar una secuencia del

2267
01:25:58,080 --> 01:25:59,460
comportamiento de alguien

2268
01:25:59,460 --> 01:26:02,699
y luego inferir los mejores

2269
01:26:02,699 --> 01:26:04,260
parámetros um de un

2270
01:26:04,260 --> 01:26:06,239
modelo de inferencia activa  eso explica su comportamiento,

2271
01:26:06,239 --> 01:26:08,100
dado que alguien decidió que puedo decir oh,

2272
01:26:08,100 --> 01:26:10,199
su matriz debe verse así o

2273
01:26:10,199 --> 01:26:12,780
su vector C debe tener esta

2274
01:26:12,780 --> 01:26:14,880
precisión, como si pudiera inferir

2275
01:26:14,880 --> 01:26:18,420
la sensibilidad al riesgo de alguien o su

2276
01:26:18,420 --> 01:26:21,239
aversión al riesgo dado su comportamiento y

2277
01:26:21,239 --> 01:26:22,500
lo bueno  sobre estar en

2278
01:26:22,500 --> 01:26:24,060
lenguajes de programación probabilísticos es que

2279
01:26:24,060 --> 01:26:26,520
hay tantos métodos diferentes que

2280
01:26:26,520 --> 01:26:29,159
no han sido realmente bien explorados para

2281
01:26:29,159 --> 01:26:30,719
ajustar modelos de inferencia activa en la

2282
01:26:30,719 --> 01:26:31,860
literatura de Matlab porque casi

2283
01:26:31,860 --> 01:26:34,679
todos usan este

2284
01:26:34,679 --> 01:26:36,420
enfoque de Bayes variacional donde básicamente

2285
01:26:36,420 --> 01:26:38,940
minimizas la energía libre usas una

2286
01:26:38,940 --> 01:26:40,800
aproximación gaussiana  para el posterior, es un

2287
01:26:40,800 --> 01:26:42,480


2288
01:26:42,480 --> 01:26:45,060
tipo muy específico de inferencia variacional ahora

2289
01:26:45,060 --> 01:26:48,480
que está en numpyro o quizás Pi mt3 nuevamente,

2290
01:26:48,480 --> 01:26:50,520
esto será muy pronto, no está completamente

2291
01:26:50,520 --> 01:26:52,560
implementado, pero podremos lanzar

2292
01:26:52,560 --> 01:26:54,480
todos los diferentes tipos de

2293
01:26:54,480 --> 01:26:55,620
técnicas de inferencia probabilística que tienen sus

2294
01:26:55,620 --> 01:26:57,780
diferentes ventajas.  y desventajas

2295
01:26:57,780 --> 01:27:00,300
como una gran cosa en las

2296
01:27:00,300 --> 01:27:04,620
inferencias probabilísticas es um mcmc Monte C  arlo Markov

2297
01:27:04,620 --> 01:27:06,540
chain Monte Carlo inference se

2298
01:27:06,540 --> 01:27:09,840
supone que proporciona distribuciones posteriores menos sesgadas uh uh

2299
01:27:09,840 --> 01:27:11,280
como si hubiera

2300
01:27:11,280 --> 01:27:13,500
ventajas en el uso de mcmc sobre

2301
01:27:13,500 --> 01:27:16,260
enfoques variacionales para aproximar la

2302
01:27:16,260 --> 01:27:18,360
base y la inferencia y una cosa que

2303
01:27:18,360 --> 01:27:19,739
no he visto hacer que me encantaría

2304
01:27:19,739 --> 01:27:21,780
ver y un montón de  las personas en la

2305
01:27:21,780 --> 01:27:23,280
comunidad de psiquiatría computacional se

2306
01:27:23,280 --> 01:27:25,320
han quejado y me han dicho que lo que les

2307
01:27:25,320 --> 01:27:27,120
gustaría ver es una comparación lado a lado

2308
01:27:27,120 --> 01:27:30,440
de días variacionales para inferir

2309
01:27:30,440 --> 01:27:33,840
parámetros Pi mdp o parámetros Palm DP

2310
01:27:33,840 --> 01:27:37,199
versus enfoques como mcmc, así que una vez que

2311
01:27:37,199 --> 01:27:38,520
tenga todo en  un

2312
01:27:38,520 --> 01:27:40,139
marco de programa probabilístico que puede hacer comparaciones lado a

2313
01:27:40,139 --> 01:27:42,360
lado entre todas las

2314
01:27:42,360 --> 01:27:44,159
diferentes técnicas de inferencia que

2315
01:27:44,159 --> 01:27:46,020
no necesariamente

2316
01:27:46,020 --> 01:27:47,400
tendría si estuviera limitado por un lenguaje

2317
01:27:47,400 --> 01:27:49,460
en el que solo se implementan una o dos o tres

2318
01:27:49,460 --> 01:27:52,139
técnicas de inferencia, por

2319
01:27:52,139 --> 01:27:53,639
lo que básicamente es solo aprovechar  de

2320
01:27:53,639 --> 01:27:55,340
todo el trabajo que la gente

2321
01:27:55,340 --> 01:27:57,780
ha hecho en numpyro para implementar todos

2322
01:27:57,780 --> 01:27:59,880
estos diferentes tipos de

2323
01:27:59,880 --> 01:28:01,440
metanfetaminas de inferencia  ods,

2324
01:28:01,440 --> 01:28:04,440
sí, increíble y fausta siguió el

2325
01:28:04,440 --> 01:28:05,960
back-end principal,

2326
01:28:05,960 --> 01:28:11,040
eh, para YMC es Sarah, pero la nueva

2327
01:28:11,040 --> 01:28:13,620
versión puede usar Jax.

2328
01:28:13,620 --> 01:28:16,139
Podría escribir el envoltorio pi MC3 una vez que la

2329
01:28:16,139 --> 01:28:18,420
versión Jax de Pi mdp sea estable.

2330
01:28:18,420 --> 01:28:19,739
Suena muy factible,

2331
01:28:19,739 --> 01:28:21,659
bueno, eso es increíble.

2332
01:28:21,659 --> 01:28:23,639
si lo ves como probable

2333
01:28:23,639 --> 01:28:26,880
y tienes la posibilidad, simplemente

2334
01:28:26,880 --> 01:28:28,860
minimiza tu energía libre

2335
01:28:28,860 --> 01:28:30,719
y no te sorprenderá cuando lo hagas

2336
01:28:30,719 --> 01:28:31,980


2337
01:28:31,980 --> 01:28:34,260
absolutamente eso es genial eso es prometedor

2338
01:28:34,260 --> 01:28:35,940
bueno

2339
01:28:35,940 --> 01:28:38,760
um Jacob o Daphne o puedo hacer otra

2340
01:28:38,760 --> 01:28:41,120


2341
01:28:43,560 --> 01:28:45,600
pregunta lo que me conviene ahora mismo

2342
01:28:45,600 --> 01:28:47,460
bueno, mencionó el paso de mensajes

2343
01:28:47,460 --> 01:28:51,780
varias veces en el contexto de Pi MGP,

2344
01:28:51,780 --> 01:28:55,080
entonces, ¿qué es el paso de mensajes

2345
01:28:55,080 --> 01:28:58,820
y cómo se usó en pi mdp?

2346
01:28:58,820 --> 01:29:02,040


2347
01:29:02,040 --> 01:29:04,199


2348
01:29:04,199 --> 01:29:07,860


2349
01:29:07,860 --> 01:29:11,219
o la inferencia bayesiana aproximada,

2350
01:29:11,219 --> 01:29:13,679
um, tan a menudo en el para hacerlo

2351
01:29:13,679 --> 01:29:15,420
muy concreto

2352
01:29:15,420 --> 01:29:17,340
en el contexto de hacer una

2353
01:29:17,340 --> 01:29:19,860
inferencia bayesiana sobre estados ocultos, entonces, ¿qué

2354
01:29:19,860 --> 01:29:21,179
tendrá que hacer un agente de inferencia activo

2355
01:29:21,179 --> 01:29:22,920
cuando esté  Ante alguna

2356
01:29:22,920 --> 01:29:25,800
observación, tendrán que combinar mensajes como si

2357
01:29:25,800 --> 01:29:28,500
un mensaje corresponde al mensaje de

2358
01:29:28,500 --> 01:29:30,900
la información sensorial y luego otro

2359
01:29:30,900 --> 01:29:32,340
mensaje corresponde a sus

2360
01:29:32,340 --> 01:29:34,320
creencias previas sobre el mundo y usan

2361
01:29:34,320 --> 01:29:36,440
algún algoritmo para combinar esos mensajes

2362
01:29:36,440 --> 01:29:39,179
para optimizar una creencia sobre el actual.

2363
01:29:39,179 --> 01:29:42,120
estado oculto del mundo, por lo que en pione P

2364
01:29:42,120 --> 01:29:43,679
tenemos una forma muy ingenua de hacer

2365
01:29:43,679 --> 01:29:45,600
computacionalmente eficiente de

2366
01:29:45,600 --> 01:29:48,420
hacer lo que simplemente llamamos

2367
01:29:48,420 --> 01:29:50,460
iteración de punto fijo ingenua o vainilla que es

2368
01:29:50,460 --> 01:29:52,920
como el esquema de paso de mensajes más simple

2369
01:29:52,920 --> 01:29:54,420
que se pueda imaginar, que es solo

2370
01:29:54,420 --> 01:29:56,580
yo  Estoy filtrando activamente estados ocultos

2371
01:29:56,580 --> 01:29:58,860
usando mis antecedentes del pasado, así que digo

2372
01:29:58,860 --> 01:30:01,380
dado dónde estaba en el último paso de tiempo,

2373
01:30:01,380 --> 01:30:03,780
dónde debería estar ahora, me dan mi Matriz B

2374
01:30:03,780 --> 01:30:06,060
y luego simplemente combiné

2375
01:30:06,060 --> 01:30:08,300
eso con mi

2376
01:30:08,300 --> 01:30:10,739
mensaje sensorial entrante, que es solo

2377
01:30:10,739 --> 01:30:13,020
la observación.  pasé a través de la

2378
01:30:13,020 --> 01:30:15,239
matriz de probabilidad, la matriz a y

2379
01:30:15,239 --> 01:30:16,440
luego simplemente combino esos dos

2380
01:30:16,440 --> 01:30:19,080
mensajes y el resultado es mi

2381
01:30:19,080 --> 01:30:21,540
distribución posterior  ion mi creencia posterior o

2382
01:30:21,540 --> 01:30:24,000
mejor acerca de los estados ocultos que es

2383
01:30:24,000 --> 01:30:25,679
como la forma más simple de

2384
01:30:25,679 --> 01:30:27,840
pasar un mensaje que tiene esta

2385
01:30:27,840 --> 01:30:28,920


2386
01:30:28,920 --> 01:30:31,920
evidencia actual superficial muy temporal combinada con anterior para

2387
01:30:31,920 --> 01:30:33,600
formar la nueva creencia tiene este mismo

2388
01:30:33,600 --> 01:30:35,639
tipo de sabor bayesiano justo

2389
01:30:35,639 --> 01:30:37,620
donde la mejor posterior es solo  un

2390
01:30:37,620 --> 01:30:40,739
producto de la probabilidad y el um anterior

2391
01:30:40,739 --> 01:30:41,520


2392
01:30:41,520 --> 01:30:43,139
, también hay

2393
01:30:43,139 --> 01:30:45,480
técnicas de paso de mensajes más avanzadas que se usan cuando

2394
01:30:45,480 --> 01:30:46,980
sus propias creencias son más

2395
01:30:46,980 --> 01:30:48,480
complicadas, por lo que en la

2396
01:30:48,480 --> 01:30:49,980
implementación completa de la inferencia activa

2397
01:30:49,980 --> 01:30:52,199
que está en la versión de Matlab, los agentes

2398
01:30:52,199 --> 01:30:53,820
no solo tienen una creencia sobre lo que el

2399
01:30:53,820 --> 01:30:56,179
estado oculto actual es que tienen un

2400
01:30:56,179 --> 01:31:00,239
tipo de

2401
01:31:00,239 --> 01:31:03,000
tensor um o cubo de creencias completamente predictivo y post-redictivo sobre todos

2402
01:31:03,000 --> 01:31:04,860
los estados ocultos en el futuro y todos

2403
01:31:04,860 --> 01:31:07,020
los estados ocultos en el pasado

2404
01:31:07,020 --> 01:31:09,179
condición adicional sobre todas las políticas que

2405
01:31:09,179 --> 01:31:11,219
potencialmente tomaré o podría tener  tomado en

2406
01:31:11,219 --> 01:31:12,960
el pasado, por lo que tiene este

2407
01:31:12,960 --> 01:31:15,900
tensor de creencias masivo que se extenderá

2408
01:31:15,900 --> 01:31:17,940
hacia estados ocultos futuros y pasados ​​​​y más

2409
01:31:17,940 --> 01:31:21,060
allá  r factorizado por la política y

2410
01:31:21,060 --> 01:31:22,800
cuando tiene ese tipo de creencia de que

2411
01:31:22,800 --> 01:31:24,600
necesita actualizar, tiene que usar

2412
01:31:24,600 --> 01:31:26,580
técnicas de paso de mensajes más sofisticadas,

2413
01:31:26,580 --> 01:31:28,920
una de las cuales se llama

2414
01:31:28,920 --> 01:31:30,659
paso de mensajes marginales, hay algo llamado

2415
01:31:30,659 --> 01:31:32,880
paso de mensajes variacional y todas

2416
01:31:32,880 --> 01:31:34,199
estas diferentes técnicas de paso de mensajes

2417
01:31:34,199 --> 01:31:35,760
son solo  esencialmente

2418
01:31:35,760 --> 01:31:37,800
consistente en pasar mensajes hacia adelante

2419
01:31:37,800 --> 01:31:40,320
y hacia atrás en el tiempo, así como a través de

2420
01:31:40,320 --> 01:31:42,600
diferentes variables que caracterizan el

2421
01:31:42,600 --> 01:31:44,159
estado oculto que llamamos factores de Estado Oculto

2422
01:31:44,159 --> 01:31:45,500


2423
01:31:45,500 --> 01:31:48,060
y los algoritmos de paso de mensajes

2424
01:31:48,060 --> 01:31:49,739
básicamente todavía

2425
01:31:49,739 --> 01:31:52,380
equivalen a combinar información sensorial

2426
01:31:52,380 --> 01:31:55,199
con creencias previas, pero solo tienen una

2427
01:31:55,199 --> 01:31:57,360
especie de  trayectorias más complicadas a

2428
01:31:57,360 --> 01:31:59,280
través del espacio de las creencias en el

2429
01:31:59,280 --> 01:32:02,400
futuro en el pasado hay

2430
01:32:02,400 --> 01:32:03,960
gente que puede explicar esto mucho mejor

2431
01:32:03,960 --> 01:32:05,940
que yo He implementado algunas de estas

2432
01:32:05,940 --> 01:32:09,179
en pi mdp pero recomendaría a la gente que

2433
01:32:09,179 --> 01:32:12,060
hay un muy buen um papel

2434
01:32:12,060 --> 01:32:14,280
Creo que puedes haberlo retuiteado el

2435
01:32:14,280 --> 01:32:16,440
otro día, Jacob, se trata de,

2436
01:32:16,440 --> 01:32:16,980
um,

2437
01:32:16,980 --> 01:32:19,620
se llama yo.  n field

2438
01:32:19,620 --> 01:32:21,719
oh sí,

2439
01:32:21,719 --> 01:32:24,360
um, el artículo que compara el campo medio

2440
01:32:24,360 --> 01:32:27,179
y su aproximación y la mejor

2441
01:32:27,179 --> 01:32:28,679
aproximación de aire que

2442
01:32:28,679 --> 01:32:30,719
pasa el mensaje neuronal usando los campos medios Bethy y

2443
01:32:30,719 --> 01:32:32,400
la aproximación marginal

2444
01:32:32,400 --> 01:32:36,960
por Markovich kibel y friston 2019

2445
01:32:36,960 --> 01:32:38,820
um, es un artículo que algunos de nosotros hemos

2446
01:32:38,820 --> 01:32:42,179
estado mirando  en cómo los

2447
01:32:42,179 --> 01:32:44,340
diferentes funcionales de energía libre se ven

2448
01:32:44,340 --> 01:32:46,380
diferentes bajo diferentes aproximaciones

2449
01:32:46,380 --> 01:32:50,340
y probablemente será un documento central en

2450
01:32:50,340 --> 01:32:54,420
2023 para que realmente nos

2451
01:32:54,420 --> 01:32:57,800
sumerjamos porque muchos de estos

2452
01:32:57,800 --> 01:33:03,020
documentos antiguos, digamos 2011 a 2019

2453
01:33:03,020 --> 01:33:06,360
ahora paquetes y direcciones de desarrollo

2454
01:33:06,360 --> 01:33:08,400
como Pi  mdp

2455
01:33:08,400 --> 01:33:09,690
están facilitando

2456
01:33:09,690 --> 01:33:11,880
[Música]

2457
01:33:11,880 --> 01:33:16,139
estos métodos para que se usen realmente y

2458
01:33:16,139 --> 01:33:18,600
hay una gran cantidad

2459
01:33:18,600 --> 01:33:22,560
de posibilidades conceptuales que propuso

2460
01:33:22,560 --> 01:33:27,560
heurísticas casos de uso emocionantes

2461
01:33:27,840 --> 01:33:32,880
relevantes para otros tipos de conexiones y,

2462
01:33:32,880 --> 01:33:33,480
um,

2463
01:33:33,480 --> 01:33:36,000
como mencionaste

2464
01:33:36,000 --> 01:33:40,139
anteriormente, estaba muy relacionado con Matlab para traer ese

2465
01:33:40,139 --> 01:33:43,440
tipo de conexiones a  la última milla

2466
01:33:43,440 --> 01:33:46,340
y luego especialmente

2467
01:33:46,340 --> 01:33:50,480
los desarrollos más granulares o modulares

2468
01:33:50,480 --> 01:33:52,440


2469
01:33:52,440 --> 01:33:54,960
estaban

2470
01:33:54,960 --> 01:33:58,800
bajo el paraguas de t  El SPM

2471
01:33:58,800 --> 01:34:00,840
vbx impidió que se

2472
01:34:00,840 --> 01:34:02,400


2473
01:34:02,400 --> 01:34:04,080
compartiesen de manera significativa

2474
01:34:04,080 --> 01:34:07,739
en una verdadera ciencia abierta distribuida o

2475
01:34:07,739 --> 01:34:10,080
ciencia descentralizada

2476
01:34:10,080 --> 01:34:12,060
y por eso, por supuesto, estamos

2477
01:34:12,060 --> 01:34:14,580
tan emocionados de trabajar y desarrollar

2478
01:34:14,580 --> 01:34:17,460
Prime DP y aprender más sobre él porque

2479
01:34:17,460 --> 01:34:20,280
este es exactamente el  tipo de

2480
01:34:20,280 --> 01:34:23,639
composición de los agentes de inferencia activos

2481
01:34:23,639 --> 01:34:26,219
y sus diferentes implementaciones en las

2482
01:34:26,219 --> 01:34:28,380
que se podrá trabajar de una

2483
01:34:28,380 --> 01:34:30,840
manera masivamente distribuida alguien podría

2484
01:34:30,840 --> 01:34:33,000
especificar una matriz a realmente interesante

2485
01:34:33,000 --> 01:34:34,860
alguien más podría especificar una

2486
01:34:34,860 --> 01:34:37,320
B interesante alguien más

2487
01:34:37,320 --> 01:34:39,300
los vinculará en  un nuevo tipo de

2488
01:34:39,300 --> 01:34:40,320
agente que

2489
01:34:40,320 --> 01:34:42,540
otra persona puede implementarlo de manera

2490
01:34:42,540 --> 01:34:46,139
diferente y, por lo tanto, trae como algo

2491
01:34:46,139 --> 01:34:49,139
natural que factoriza

2492
01:34:49,139 --> 01:34:51,420
el proceso de desarrollo de estos

2493
01:34:51,420 --> 01:34:55,139
algoritmos que anteriormente eran casi

2494
01:34:55,139 --> 01:34:57,719


2495
01:34:57,719 --> 01:35:00,000
siempre totalmente Matlab o hechos a

2496
01:35:00,000 --> 01:35:03,239
medida

2497
01:35:03,239 --> 01:35:06,179
y muy personalizados

2498
01:35:06,179 --> 01:35:09,300
y adecuados para un documento determinado,

2499
01:35:09,300 --> 01:35:13,320
pero  no necesariamente adaptable a lo largo de los

2500
01:35:13,320 --> 01:35:15,840
ejes relevantes

2501
01:35:15,840 --> 01:35:18,360
que uno querría usar para un

2502
01:35:18,360 --> 01:35:22,260
entorno moderno especialmente pitónico

2503
01:35:22,260 --> 01:35:24,480
totalmente, puedo estar más de acuerdo, quiero decir que también es una

2504
01:35:24,480 --> 01:35:25,800
excelente manera de pensar en ello, es

2505
01:35:25,800 --> 01:35:28,500
como si estuviera creando un código modular flexible

2506
01:35:28,500 --> 01:35:30,600
que existe en el ecosistema de otros

2507
01:35:30,600 --> 01:35:33,260
paquetes, esencialmente estás

2508
01:35:33,260 --> 01:35:35,580
factorizando la representación colectiva de Minds

2509
01:35:35,580 --> 01:35:38,760
de la tarea en cuestión o

2510
01:35:38,760 --> 01:35:40,679
luego diferente

2511
01:35:40,679 --> 01:35:42,420
Se puede trabajar en partes de esa representación sin

2512
01:35:42,420 --> 01:35:45,840
tener que pasar mensajes o tener en

2513
01:35:45,840 --> 01:35:47,520
cuenta lo que sucede en toda la

2514
01:35:47,520 --> 01:35:50,159
red de trabajadores distribuidos, por lo

2515
01:35:50,159 --> 01:35:52,739
que alguien puede escribir su

2516
01:35:52,739 --> 01:35:54,239
propio algoritmo de paso de mensajes, incluso mejor

2517
01:35:54,239 --> 01:35:56,520
, y luego simplemente insertarlo para

2518
01:35:56,520 --> 01:35:59,219
usarlo con  pi MVP sin haber tenido que

2519
01:35:59,219 --> 01:36:01,320
aprender cómo funciona cada pequeña faceta de

2520
01:36:01,320 --> 01:36:04,320
Prime DP, así que sí, eso es

2521
01:36:04,320 --> 01:36:06,239
realmente importante, creo que es algo sobre

2522
01:36:06,239 --> 01:36:08,820
ciencia abierta y desarrollo de software modular,

2523
01:36:08,820 --> 01:36:10,940


2524
01:36:10,940 --> 01:36:14,639
muy bien en nuestros minutos finales, por

2525
01:36:14,639 --> 01:36:17,940
supuesto, Jacob o Daphne, cualquier comentario o

2526
01:36:17,940 --> 01:36:23,219
pregunta.  y también cualquier aperitivo, qué

2527
01:36:23,219 --> 01:36:26,540
tipo de modelos emocionan a las personas

2528
01:36:26,540 --> 01:36:31,020
o qué podría significar, lo vemos en la

2529
01:36:31,020 --> 01:36:33,900
siguiente transmisión en vivo que será  en

2530
01:36:33,900 --> 01:36:36,360
enero de 2023

2531
01:36:36,360 --> 01:36:39,920
model stream 7.2

2532
01:36:41,699 --> 01:36:43,320
um Solo diría que creo que

2533
01:36:43,320 --> 01:36:45,719
los cuadernos son realmente muy útiles,

2534
01:36:45,719 --> 01:36:48,420
por lo que es un recurso realmente excelente para las

2535
01:36:48,420 --> 01:36:50,100
personas que

2536
01:36:50,100 --> 01:36:52,020
um están tratando de construir y modelar y

2537
01:36:52,020 --> 01:36:53,580
comprender lo que está sucediendo bajo

2538
01:36:53,580 --> 01:36:56,460
el IMDb nativo y yo  creo que

2539
01:36:56,460 --> 01:36:58,980
sería genial tener una

2540
01:36:58,980 --> 01:37:01,139
extensión para esos cuadernos que también

2541
01:37:01,139 --> 01:37:02,360
hable sobre

2542
01:37:02,360 --> 01:37:05,340
aprender los parámetros de duración para las

2543
01:37:05,340 --> 01:37:08,100
matrices A y B. Creo que eso

2544
01:37:08,100 --> 01:37:11,659
sería realmente genial

2545
01:37:13,320 --> 01:37:15,360
y muchas gracias, Connor,

2546
01:37:15,360 --> 01:37:17,219
querías hablar,

2547
01:37:17,219 --> 01:37:19,020
sí, gracias.  por venir, ese es un

2548
01:37:19,020 --> 01:37:20,100
muy buen punto y esto es algo

2549
01:37:20,100 --> 01:37:22,199
que Daniel también dijo

2550
01:37:22,199 --> 01:37:24,000
um anteriormente en el correo electrónico es que actualizar

2551
01:37:24,000 --> 01:37:26,639
A y B es como si estuviera muy poco

2552
01:37:26,639 --> 01:37:28,199
documentado en este momento

2553
01:37:28,199 --> 01:37:30,840
y creo que sería porque esa

2554
01:37:30,840 --> 01:37:32,639
es una forma de aprender el generativo

2555
01:37:32,639 --> 01:37:33,960
modelo

2556
01:37:33,960 --> 01:37:36,239
um que en este momento no lo hacemos, no es la

2557
01:37:36,239 --> 01:37:37,679
forma más sofisticada, todavía tiene un

2558
01:37:37,679 --> 01:37:39,300
número fijo de filas y columnas, por lo que

2559
01:37:39,300 --> 01:37:41,460
hace algunas suposiciones, pero eso es como una

2560
01:37:41,460 --> 01:37:42,960
forma flexible cuando el  los

2561
01:37:42,960 --> 01:37:45,239
propios agentes están aprendiendo las matrices b y a,

2562
01:37:45,239 --> 01:37:46,679
así

2563
01:37:46,679 --> 01:37:48,540
que sí, definitivamente deberíamos tal vez eso

2564
01:37:48,540 --> 01:37:50,280
pueda ser una

2565
01:37:50,280 --> 01:37:52,260
I. Puedo simplemente agregar eso en el cuaderno

2566
01:37:52,260 --> 01:37:54,719
que estaba planeando

2567
01:37:54,719 --> 01:37:57,300
mostrar esto como una especie de

2568
01:37:57,300 --> 01:37:59,639
tarea epistémica de Bandit de dos brazos que podemos simplemente agregar  en

2569
01:37:59,639 --> 01:38:01,920
algún A o B aprendiendo eso y solo

2570
01:38:01,920 --> 01:38:03,780
mostrar cómo funciona,

2571
01:38:03,780 --> 01:38:06,120
um, haría un nuevo cuaderno que use

2572
01:38:06,120 --> 01:38:08,360
ese

2573
01:38:08,460 --> 01:38:12,600
genial eventualmente para el libro de texto

2574
01:38:12,600 --> 01:38:15,659
y para cada

2575
01:38:15,659 --> 01:38:19,679
trabajo, sería increíble poder ver

2576
01:38:19,679 --> 01:38:21,239
el código,

2577
01:38:21,239 --> 01:38:24,719
la representación analítica, una

2578
01:38:24,719 --> 01:38:27,900
representación gráfica.  y diferentes

2579
01:38:27,900 --> 01:38:30,780
representaciones en lenguaje natural

2580
01:38:30,780 --> 01:38:34,260
porque todas están formalmente, uh, formalmente

2581
01:38:34,260 --> 01:38:37,080
conectadas y todas podrían representarse

2582
01:38:37,080 --> 01:38:40,080
como tales y eso

2583
01:38:40,080 --> 01:38:42,239
realmente podría esperar aumentar la

2584
01:38:42,239 --> 01:38:45,900
accesibilidad y el rigor de un modelo

2585
01:38:45,900 --> 01:38:48,719
y ayudarnos a componer y conectarnos a través de

2586
01:38:48,719 --> 01:38:51,060
diferentes dominios y simplemente dar la bienvenida y

2587
01:38:51,060 --> 01:38:52,679
reconozco muchos tipos diferentes de

2588
01:38:52,679 --> 01:38:55,760
aprendizaje y modelado

2589
01:38:56,040 --> 01:38:57,840
absolutamente

2590
01:38:57,840 --> 01:38:59,580
jakov cualquier

2591
01:38:59,580 --> 01:39:02,540
pensamiento o pregunta

2592
01:39:02,760 --> 01:39:05,880
um no hay preguntas en este punto pero uh

2593
01:39:05,880 --> 01:39:09,060
también solo eso  Muchas gracias por la increíble

2594
01:39:09,060 --> 01:39:11,699
presentación y estoy muy entusiasmado

2595
01:39:11,699 --> 01:39:14,820
con todas las

2596
01:39:14,820 --> 01:39:16,920
um

2597
01:39:16,920 --> 01:39:19,739
integraciones emergentes y los casos de uso

2598
01:39:19,739 --> 01:39:22,679
que, sin duda, surgirán.

2599
01:39:22,679 --> 01:39:26,159


2600
01:39:26,159 --> 01:39:30,300


2601
01:39:30,300 --> 01:39:33,360
se usará para

2602
01:39:33,360 --> 01:39:36,659
modelos de inferencia activos escalables y estoy muy emocionado de

2603
01:39:36,659 --> 01:39:40,199
cómo primevp

2604
01:39:40,199 --> 01:39:41,540


2605
01:39:41,540 --> 01:39:44,420
interoperará con todas estas

2606
01:39:44,420 --> 01:39:49,219
integraciones diferentes y será muy

2607
01:39:50,580 --> 01:39:54,320
emocionante de usar,

2608
01:39:56,159 --> 01:39:58,940
gracias

2609
01:39:58,980 --> 01:40:03,239
Connor, las penúltimas palabras

2610
01:40:03,239 --> 01:40:05,820
, supongo que tal vez solo en el espíritu

2611
01:40:05,820 --> 01:40:09,060
de lo que  estabas diciendo que puedo mostrar

2612
01:40:09,060 --> 01:40:11,699
un esqueleto de lo que podríamos pasar la

2613
01:40:11,699 --> 01:40:14,340
próxima vez, oh genial, está bien, lo vemos,

2614
01:40:14,340 --> 01:40:16,860
um, sí, es eso, está bien, se ve

2615
01:40:16,860 --> 01:40:18,480
genial, se ve genial,

2616
01:40:18,480 --> 01:40:20,760
así que

2617
01:40:20,760 --> 01:40:22,920
sí, básicamente, este es un cuaderno de

2618
01:40:22,920 --> 01:40:26,280
colaboración, así que animo a cualquiera a ir.  al

2619
01:40:26,280 --> 01:40:28,380
sitio web de tutoriales um Pine DP y cada uno de

2620
01:40:28,380 --> 01:40:30,179
los cuadernos como Daphne decía

2621
01:40:30,179 --> 01:40:32,699
que tenían su Soy bastante útil

2622
01:40:32,699 --> 01:40:34,860
y tienen enlaces de colaboración asociados con

2623
01:40:34,860 --> 01:40:36,239
ellos

2624
01:40:36,239 --> 01:40:38,040
um y puedes abrir el enlace y

2625
01:40:38,040 --> 01:40:41,520
luego ex  Explore este, creo que es parte de

2626
01:40:41,520 --> 01:40:43,139
la API del agente,

2627
01:40:43,139 --> 01:40:46,500
sí, este es el mismo, excepto que

2628
01:40:46,500 --> 01:40:48,060
mostré este recientemente en el curso

2629
01:40:48,060 --> 01:40:49,679
de psiquiatría computacional, así que lo

2630
01:40:49,679 --> 01:40:51,060
actualicé un poco

2631
01:40:51,060 --> 01:40:53,340
para poder compartir

2632
01:40:53,340 --> 01:40:55,980
esto contigo, Daniel, y luego podrías.  ya

2633
01:40:55,980 --> 01:40:58,080
sea en Discord o donde sea que

2634
01:40:58,080 --> 01:40:59,460
este esté un poco más actualizado, pero el

2635
01:40:59,460 --> 01:41:01,739
básico aquí seguirá siendo al

2636
01:41:01,739 --> 01:41:03,900
que puede acceder aquí y seguirá mostrando

2637
01:41:03,900 --> 01:41:04,980
lo mismo,

2638
01:41:04,980 --> 01:41:07,560
pero en cualquier caso, la cosa es que simplemente

2639
01:41:07,560 --> 01:41:09,179
abra la colaboración, necesita una cuenta de Google

2640
01:41:09,179 --> 01:41:12,060
esa es la única limitación para usar estos

2641
01:41:12,060 --> 01:41:14,820
um, puede instalar localmente de manera

2642
01:41:14,820 --> 01:41:17,219
infraactiva Dash piondp

2643
01:41:17,219 --> 01:41:19,980
uh import numpy matplotlib solo hay

2644
01:41:19,980 --> 01:41:22,080
algunas importaciones aquí y luego todo

2645
01:41:22,080 --> 01:41:23,880
esto, el espíritu de este cuaderno es

2646
01:41:23,880 --> 01:41:25,380
esencialmente seguir todos los

2647
01:41:25,380 --> 01:41:27,480
pasos para configurar el modelo generativo,

2648
01:41:27,480 --> 01:41:29,820
así que  crear sus factores de estado ocultos,

2649
01:41:29,820 --> 01:41:31,020
eso es algo de lo que realmente no hablamos,

2650
01:41:31,020 --> 01:41:33,360
son representaciones factorizadas en

2651
01:41:33,360 --> 01:41:35,460
el contexto de Pi mdp

2652
01:41:35,460 --> 01:41:36,480
um

2653
01:41:36,480 --> 01:41:40,139
construyendo la matriz B que

2654
01:41:40,139 --> 01:41:41,940
no solo tiene

2655
01:41:41,940 --> 01:41:43,679
um como usted puede ju  hágalo usted mismo, pero

2656
01:41:43,679 --> 01:41:45,060
también hay estas celdas ocultas con

2657
01:41:45,060 --> 01:41:47,580
soluciones para cada una de estas cosas y

2658
01:41:47,580 --> 01:41:49,139
luego la parte principal de este cuaderno

2659
01:41:49,139 --> 01:41:51,119
antes de ejecutar la inferencia activa es simplemente

2660
01:41:51,119 --> 01:41:52,800
avanzar paso a paso e

2661
01:41:52,800 --> 01:41:54,480


2662
01:41:54,480 --> 01:41:58,320
inicializar las entradas de las matrices a, b, c y d

2663
01:41:58,320 --> 01:42:00,659
y la próxima vez que tenga  algunas diapositivas para

2664
01:42:00,659 --> 01:42:02,040
acompañar esto, así que básicamente podemos ir

2665
01:42:02,040 --> 01:42:03,840
entre las diapositivas y

2666
01:42:03,840 --> 01:42:06,360
el código real,

2667
01:42:06,360 --> 01:42:08,699
lo mismo con la matriz a, por lo que le

2668
01:42:08,699 --> 01:42:11,520
gusta tener una representación de cómo

2669
01:42:11,520 --> 01:42:13,440
quiere que se vea la matriz a y

2670
01:42:13,440 --> 01:42:15,119
luego ingresa al código y  en realidad lo

2671
01:42:15,119 --> 01:42:17,460
construyes y lo haces secuencialmente para

2672
01:42:17,460 --> 01:42:19,020
cada uno de los componentes del modelo generativo

2673
01:42:19,020 --> 01:42:20,820


2674
01:42:20,820 --> 01:42:21,540
um

2675
01:42:21,540 --> 01:42:23,460
y los estás trazando a lo largo del camino

2676
01:42:23,460 --> 01:42:25,920
para que puedas ver cómo se ve después de

2677
01:42:25,920 --> 01:42:29,280
haberlo construido y luego

2678
01:42:29,280 --> 01:42:31,560
realmente implementamos  después de haber

2679
01:42:31,560 --> 01:42:32,699
creado el modelo general,

2680
01:42:32,699 --> 01:42:34,080
lo conecta a un

2681
01:42:34,080 --> 01:42:35,340
agente de inferencia activo,

2682
01:42:35,340 --> 01:42:38,280
por lo que esto es lo primero que se está construyendo

2683
01:42:38,280 --> 01:42:41,580
a y b factorizados para un

2684
01:42:41,580 --> 01:42:43,440
um general genérico que creo que es solo un

2685
01:42:43,440 --> 01:42:45,239
mundo de cuadrícula más sofisticado, pero en

2686
01:42:45,239 --> 01:42:47,100
realidad esa es una especie de

2687
01:42:47,100 --> 01:42:48,600
tarea introductoria y luego entramos y realmente

2688
01:42:48,600 --> 01:42:50,940
construimos las A, B y C para esta

2689
01:42:50,940 --> 01:42:53,219
tarea epistémica de dos brazos que es

2690
01:42:53,219 --> 01:42:55,560
básicamente como un compañero de equipo

2691
01:42:55,560 --> 01:42:56,460


2692
01:42:56,460 --> 01:43:00,300
um y luego tú construyes  que sabes

2693
01:43:00,300 --> 01:43:02,520
que estás escribiendo en todas las pequeñas

2694
01:43:02,520 --> 01:43:04,679
submatrices de tu matriz a,

2695
01:43:04,679 --> 01:43:06,420
es por eso que hay tantas celdas como

2696
01:43:06,420 --> 01:43:07,739
dije, es como si esa fuera la parte más larga

2697
01:43:07,739 --> 01:43:09,950
, en realidad está construyendo cosas

2698
01:43:09,950 --> 01:43:10,500
[Música]

2699
01:43:10,500 --> 01:43:11,100
um,

2700
01:43:11,100 --> 01:43:13,619
el vector C básicamente es la

2701
01:43:13,619 --> 01:43:15,300
función de recompensa que  Daphne dijo

2702
01:43:15,300 --> 01:43:16,800
antes que en realidad está codificando en

2703
01:43:16,800 --> 01:43:20,100
términos de probabilidades de registro relativas

2704
01:43:20,100 --> 01:43:23,040
y, finalmente, básicamente sigue

2705
01:43:23,040 --> 01:43:25,320
esos pasos que discutimos durante la

2706
01:43:25,320 --> 01:43:27,980
presentación.

2707
01:43:27,980 --> 01:43:30,360


2708
01:43:30,360 --> 01:43:32,639


2709
01:43:32,639 --> 01:43:35,340
generar el bandido de dos brazos,

2710
01:43:35,340 --> 01:43:37,980
el entorno epistémico para armar bandido

2711
01:43:37,980 --> 01:43:39,840
uh, que son solo las reglas

2712
01:43:39,840 --> 01:43:42,719
sobre cómo funciona el mundo dadas las

2713
01:43:42,719 --> 01:43:45,360
acciones del agente y th  En realidad,

2714
01:43:45,360 --> 01:43:48,480
ejecuta este ciclo de inferencia activo que,

2715
01:43:48,480 --> 01:43:51,900
como discutimos, es simplemente ejecutar

2716
01:43:51,900 --> 01:43:53,639
un ciclo de manera efectiva a lo largo del tiempo haciendo un muestreo de

2717
01:43:53,639 --> 01:43:55,739
acción de inferencia de política de influencia de estado oculto

2718
01:43:55,739 --> 01:43:58,440
y luego recorriendo el

2719
01:43:58,440 --> 01:44:00,480
entorno para obtener la nueva observación

2720
01:44:00,480 --> 01:44:02,159
y luego, al final, acabo de escribir

2721
01:44:02,159 --> 01:44:03,659
esto como  función de ayuda que

2722
01:44:03,659 --> 01:44:05,699
básicamente puede trazar el historial de elecciones

2723
01:44:05,699 --> 01:44:07,440
y creencias,

2724
01:44:07,440 --> 01:44:09,300
así que al final esto es

2725
01:44:09,300 --> 01:44:11,280
como una parte experimental más divertida

2726
01:44:11,280 --> 01:44:14,280
, puedes jugar con los parámetros del

2727
01:44:14,280 --> 01:44:16,739
entorno y también los parámetros

2728
01:44:16,739 --> 01:44:18,420
del modelo del agente

2729
01:44:18,420 --> 01:44:20,760
y luego comenzar  viendo cómo eso cambia el

2730
01:44:20,760 --> 01:44:22,260
comportamiento

2731
01:44:22,260 --> 01:44:24,000
simplemente ejecutando de forma iterativa

2732
01:44:24,000 --> 01:44:25,380
simulaciones de inferencia activa y

2733
01:44:25,380 --> 01:44:28,020
trazando el comportamiento de Elección resultante

2734
01:44:28,020 --> 01:44:29,699
y el historial de creencias,

2735
01:44:29,699 --> 01:44:31,320
así que eso es general, es una pequeña

2736
01:44:31,320 --> 01:44:33,480
vista previa, supongo, de lo que podemos hacer y

2737
01:44:33,480 --> 01:44:35,040
también podemos tener un pequeño submódulo en

2738
01:44:35,040 --> 01:44:36,780
aquí estamos dejando que los agentes

2739
01:44:36,780 --> 01:44:38,460
actualicen sus creencias sobre la

2740
01:44:38,460 --> 01:44:42,500
Matriz a o B, lo que podría ser genial,

2741
01:44:42,900 --> 01:44:46,260
asombroso, se ve realmente emocionante  y en una

2742
01:44:46,260 --> 01:44:49,500
nota final de

2743
01:44:49,500 --> 01:44:52,800
SPM en el libro de texto de SPM y en los experimentos, a

2744
01:44:52,800 --> 01:44:54,840
veces hay estas increíbles

2745
01:44:54,840 --> 01:44:59,159
matrices en escala de grises que se resumen como

2746
01:44:59,159 --> 01:45:02,699
múltiples factores experimentales en 100

2747
01:45:02,699 --> 01:45:06,900
participantes y, eh, es realmente

2748
01:45:06,900 --> 01:45:09,360
interesante ver cómo

2749
01:45:09,360 --> 01:45:13,500
se muestra también con esa

2750
01:45:13,500 --> 01:45:18,300
representación de Matrix en blanco y negro o en escala de grises.

2751
01:45:18,300 --> 01:45:22,800
y cómo eso proporciona una sensación visual

2752
01:45:22,800 --> 01:45:25,739
para algunos de estos temas que hemos estado

2753
01:45:25,739 --> 01:45:27,960
discutiendo y, por supuesto,

2754
01:45:27,960 --> 01:45:30,600
la representación está

2755
01:45:30,600 --> 01:45:33,420
vinculada formalmente con Matrix, pero a

2756
01:45:33,420 --> 01:45:36,060
veces simplemente dices que tienes dos

2757
01:45:36,060 --> 01:45:37,800
opciones y hay diez estados en el

2758
01:45:37,800 --> 01:45:40,560
mundo y las probabilidades parecen  así en

2759
01:45:40,560 --> 01:45:42,119
lugar de verlo como una

2760
01:45:42,119 --> 01:45:45,300
hoja de cálculo con números, verlos

2761
01:45:45,300 --> 01:45:49,040
en escala de grises

2762
01:45:49,040 --> 01:45:52,560
proporciona una especie de sensación

2763
01:45:52,560 --> 01:45:55,199
y se ve muy bien, por lo que

2764
01:45:55,199 --> 01:45:56,639
parece una

2765
01:45:56,639 --> 01:45:59,100
sesión increíble que tendremos para DOT dos,

2766
01:45:59,100 --> 01:46:01,260
sí, totalmente, es interesante que

2767
01:46:01,260 --> 01:46:03,360
traigas eso.  levantarme así es algo que

2768
01:46:03,360 --> 01:46:05,580
siempre he estado haciendo y creo que es

2769
01:46:05,580 --> 01:46:07,679
mucho porque

2770
01:46:07,679 --> 01:46:10,320
aprendí todo eso de la lectura de t

2771
01:46:10,320 --> 01:46:13,619
la inferencia activa de la manguera y los documentos de SPM,

2772
01:46:13,619 --> 01:46:15,480
um, así que tomé prestada

2773
01:46:15,480 --> 01:46:18,659
esa técnica de visualización de ellos,

2774
01:46:18,659 --> 01:46:20,400
um, y la di por sentada, pero

2775
01:46:20,400 --> 01:46:22,139
sí, es interesante, claramente no es

2776
01:46:22,139 --> 01:46:24,600
la única forma de hacerlo, pero siempre lo

2777
01:46:24,600 --> 01:46:25,980
encontré muy intuitivo.  para pensar en la

2778
01:46:25,980 --> 01:46:28,560
probabilidad, simplemente puedes

2779
01:46:28,560 --> 01:46:30,420
colorearlo, usa colores porque los números son

2780
01:46:30,420 --> 01:46:32,580
demasiado específicos, es el color, la

2781
01:46:32,580 --> 01:46:34,199
escala de grises que realmente le gusta al aspecto visual,

2782
01:46:34,199 --> 01:46:35,940
solo muestra que esto es más

2783
01:46:35,940 --> 01:46:37,860
probable que esto,

2784
01:46:37,860 --> 01:46:40,080
sí, sí,

2785
01:46:40,080 --> 01:46:42,860
genial, está bien

2786
01:46:42,860 --> 01:46:46,020
Daphne y Connor  muchas gracias por esta

2787
01:46:46,020 --> 01:46:48,179
increíble sesión y

2788
01:46:48,179 --> 01:46:51,480
nos vemos en poco más de

2789
01:46:51,480 --> 01:46:54,000
un mes para el punto dos

2790
01:46:54,000 --> 01:46:55,560
genial muchas gracias Daniel y gracias

2791
01:46:55,560 --> 01:46:57,060
a todos

2792
01:46:57,060 --> 01:46:58,260
paz

2793
01:46:58,260 --> 01:47:01,820
cuídense adiós gracias a todos

