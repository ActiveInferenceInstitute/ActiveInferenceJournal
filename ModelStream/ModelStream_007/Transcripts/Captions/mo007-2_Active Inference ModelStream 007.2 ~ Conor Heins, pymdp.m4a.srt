1
00:00:05,390 --> 00:00:08,206
DANIEL FRIEDMAN: Hello and welcome. This is model stream

2
00:00:08,238 --> 00:00:12,302
number 007.2. It's the 18 January

3
00:00:12,366 --> 00:00:16,638
2023. We're back in our second session

4
00:00:16,814 --> 00:00:19,650
on pymdp. Welcome back,

5
00:00:19,800 --> 00:00:22,674
Conor. Thanks for joining again. And off

6
00:00:22,712 --> 00:00:25,986
to you for a presentation that you will

7
00:00:26,008 --> 00:00:27,850
weave together with some some code

8
00:00:27,920 --> 00:00:30,166
examples. And the notebook that we'll

9
00:00:30,198 --> 00:00:32,266
use is in the video description. So

10
00:00:32,288 --> 00:00:36,074
thanks again, Conor. Off to you. 

11
00:00:36,112 --> 00:00:38,074
CONOR HEINS: Great. Thank you, Daniel. It's great to be back

12
00:00:38,112 --> 00:00:39,594
here again. I think I've been here maybe

13
00:00:39,632 --> 00:00:41,278
four or five times now. So it's always a

14
00:00:41,284 --> 00:00:43,774
pleasure to be with you all. So, yeah,

15
00:00:43,812 --> 00:00:47,390
as Daniel said, this is the second model

16
00:00:47,460 --> 00:00:50,298
stream in a two part series where we'll

17
00:00:50,314 --> 00:00:52,426
be discussing implementing active

18
00:00:52,458 --> 00:00:56,066
inference with PMDP. There is

19
00:00:56,088 --> 00:00:58,098
some background that I'm assuming you

20
00:00:58,184 --> 00:01:00,354
either know from your own research into

21
00:01:00,392 --> 00:01:02,258
active inference and palm DPS in

22
00:01:02,264 --> 00:01:04,446
particular, or because you've watched

23
00:01:04,478 --> 00:01:07,166
the first part of the series. So I'll

24
00:01:07,198 --> 00:01:08,546
just say that to start with. Like, if

25
00:01:08,568 --> 00:01:09,906
you want background, I would encourage

26
00:01:09,938 --> 00:01:11,766
you to go watch the first part where we

27
00:01:11,788 --> 00:01:14,406
talk about PMDP, the motivation for the

28
00:01:14,428 --> 00:01:17,206
package, what you can do with it in kind

29
00:01:17,228 --> 00:01:20,358
of sweeping terms. And then today we're

30
00:01:20,374 --> 00:01:22,314
actually going to go in and use it to

31
00:01:22,352 --> 00:01:24,362
code up an active inference agent

32
00:01:24,496 --> 00:01:26,726
performing a task, like a reinforcement

33
00:01:26,758 --> 00:01:29,978
learning style task that's very

34
00:01:30,064 --> 00:01:32,006
similar to classic active inference

35
00:01:32,038 --> 00:01:33,246
tasks that you can find in the

36
00:01:33,268 --> 00:01:36,686
literature. Yeah. So as Daniel said,

37
00:01:36,788 --> 00:01:39,758
I'm going to step through the slides. I

38
00:01:39,764 --> 00:01:41,614
have pauses for questions and stuff,

39
00:01:41,652 --> 00:01:45,506
but we also have pauses for code live

40
00:01:45,608 --> 00:01:48,318
coding or side by side coding. So I'll

41
00:01:48,334 --> 00:01:49,906
take a pause from the slides and I'll go

42
00:01:49,928 --> 00:01:53,454
over to the Collab notebook.

43
00:01:53,582 --> 00:01:55,138
The link is in the description of the

44
00:01:55,144 --> 00:01:58,454
YouTube video, and we'll kind of code

45
00:01:58,492 --> 00:02:00,406
up this agent based on things that we

46
00:02:00,428 --> 00:02:02,486
discuss in the slides. It's not that

47
00:02:02,508 --> 00:02:04,086
I'll be actually writing code. I'll just

48
00:02:04,108 --> 00:02:05,910
be running cell blocks.

49
00:02:07,950 --> 00:02:11,306
If anyone who's viewing wants to

50
00:02:11,328 --> 00:02:14,106
do it themselves, you can open the Co

51
00:02:14,128 --> 00:02:15,786
Lab notebook. Actually, let's start by

52
00:02:15,808 --> 00:02:16,620
doing that.

53
00:02:19,630 --> 00:02:21,206
So this should be the Collab notebook

54
00:02:21,238 --> 00:02:24,486
that you get brought to when you click

55
00:02:24,528 --> 00:02:27,594
on the link. And this is one caveat.

56
00:02:27,642 --> 00:02:29,166
You need to have a Google account to use

57
00:02:29,188 --> 00:02:30,926
this because co op is linked to your

58
00:02:30,948 --> 00:02:32,894
Google drive of your Google account. So

59
00:02:32,932 --> 00:02:36,878
if you're doing this on your own,

60
00:02:37,044 --> 00:02:40,306
this is a shared link. But it's not you

61
00:02:40,328 --> 00:02:41,906
can't edit it. You can't write to it.

62
00:02:41,928 --> 00:02:43,506
So what you have to do is go to file up

63
00:02:43,528 --> 00:02:45,810
here and then save a copy and drive.

64
00:02:45,960 --> 00:02:47,618
And then you'll get your own personal,

65
00:02:47,704 --> 00:02:49,986
private copy of the notebook. And I'll

66
00:02:50,018 --> 00:02:51,366
do that right now because I'll create a

67
00:02:51,388 --> 00:02:54,006
run copy where we can manipulate it all

68
00:02:54,028 --> 00:02:56,326
together in real time. So I'll just call

69
00:02:56,348 --> 00:02:57,590
it run. Copy.

70
00:03:00,270 --> 00:03:03,046
And I'll start by just installing

71
00:03:03,078 --> 00:03:06,438
Hinton, this colab environment. Pi MDP.

72
00:03:06,534 --> 00:03:08,806
So Colab is kind of like Jupiter's

73
00:03:08,838 --> 00:03:11,102
notebooks. It's an interactive cloud

74
00:03:11,156 --> 00:03:13,342
hosted notebook for running different

75
00:03:13,396 --> 00:03:15,920
kinds of code, but mainly Python code.

76
00:03:16,690 --> 00:03:18,734
So while that's installing, and I'll run

77
00:03:18,772 --> 00:03:21,166
that as well, we can start with the

78
00:03:21,188 --> 00:03:23,280
slides. Okay,

79
00:03:28,290 --> 00:03:30,322
so I'll just start with a quick review

80
00:03:30,376 --> 00:03:32,338
from last time, and again, go back to

81
00:03:32,344 --> 00:03:34,130
the video if you want to see the full

82
00:03:34,200 --> 00:03:35,954
picture of what we discussed. So the

83
00:03:35,992 --> 00:03:38,246
generative models, the kind of brains of

84
00:03:38,268 --> 00:03:39,926
the agents that will be constructing are

85
00:03:39,948 --> 00:03:41,922
these partially observed Markov decision

86
00:03:41,986 --> 00:03:45,554
processes or palm DPS. They have various

87
00:03:45,602 --> 00:03:47,206
parameters, and it's kind of up to you

88
00:03:47,228 --> 00:03:48,554
how to parameterize them. But under

89
00:03:48,592 --> 00:03:50,026
active inference, we typically have

90
00:03:50,048 --> 00:03:52,870
these four main components. There's

91
00:03:52,950 --> 00:03:55,546
fifth and 6th, depending on how

92
00:03:55,728 --> 00:03:57,258
complicated of a model you want to

93
00:03:57,264 --> 00:03:59,786
create. But these components kind of

94
00:03:59,808 --> 00:04:01,670
represents the agent's beliefs about the

95
00:04:01,680 --> 00:04:03,166
world that it's operating in. So these

96
00:04:03,188 --> 00:04:06,142
are usually hand designed or at least

97
00:04:06,276 --> 00:04:08,734
generally structured on a case by case

98
00:04:08,772 --> 00:04:11,626
basis, encoding to the behavioral task

99
00:04:11,658 --> 00:04:13,566
that you're trying to model. So we have

100
00:04:13,588 --> 00:04:16,926
the A matrix or A array, which encodes

101
00:04:16,958 --> 00:04:18,526
the agent's beliefs about how hidden

102
00:04:18,558 --> 00:04:20,514
states of the world that it's doing

103
00:04:20,552 --> 00:04:22,146
coherence about relate to the

104
00:04:22,168 --> 00:04:24,066
observations that it gets. You have the

105
00:04:24,088 --> 00:04:27,938
B array, which encoding beliefs

106
00:04:27,954 --> 00:04:29,654
about transitions or beliefs about

107
00:04:29,692 --> 00:04:31,666
dynamics. So how do hidden states relate

108
00:04:31,698 --> 00:04:34,758
to each other over time? You have the C

109
00:04:34,844 --> 00:04:38,006
vector or C array, which encodes agents

110
00:04:38,188 --> 00:04:40,330
prior preferences for seeing certain

111
00:04:40,400 --> 00:04:42,298
sorts of sensations. So this kind of

112
00:04:42,304 --> 00:04:44,502
plays the role of a quasi reward

113
00:04:44,566 --> 00:04:47,066
function, and it has the effect of

114
00:04:47,088 --> 00:04:49,562
biasing agents action selection such

115
00:04:49,616 --> 00:04:51,546
that it's more likely to visit states of

116
00:04:51,568 --> 00:04:54,702
affairs that a priority, expects to see

117
00:04:54,836 --> 00:04:57,406
I e. Goal directed behavior. It wants to

118
00:04:57,428 --> 00:04:59,758
achieve some goal. And then we have the

119
00:04:59,764 --> 00:05:01,722
D vector, which is kind of a baseline

120
00:05:01,786 --> 00:05:03,986
prior about what is the state of the

121
00:05:04,008 --> 00:05:07,822
world before I get any observations,

122
00:05:07,886 --> 00:05:09,922
like what do I believe the hidden state

123
00:05:09,976 --> 00:05:13,406
distribution is? And again, I'm glossing

124
00:05:13,438 --> 00:05:15,094
over this because I assume that you know

125
00:05:15,132 --> 00:05:16,354
about things like categorical

126
00:05:16,402 --> 00:05:17,590
distinctions.

127
00:05:20,250 --> 00:05:22,470
All the details of these different

128
00:05:22,540 --> 00:05:24,102
arrays are explained more in the first

129
00:05:24,156 --> 00:05:27,686
video. And just again, to show

130
00:05:27,708 --> 00:05:29,806
the graphical model, we have the A array

131
00:05:29,858 --> 00:05:31,706
relating hidden states in red to

132
00:05:31,728 --> 00:05:34,282
observations in Bleu. We have the B

133
00:05:34,336 --> 00:05:37,206
matrix or B array that relate hidden

134
00:05:37,238 --> 00:05:39,226
states to themselves over time. So how

135
00:05:39,248 --> 00:05:42,574
does the world chance? And then we have

136
00:05:42,612 --> 00:05:45,934
policies Pi, which are sequences or

137
00:05:45,972 --> 00:05:48,330
collections of actions that affect

138
00:05:48,410 --> 00:05:50,574
transitions and thereby change the state

139
00:05:50,612 --> 00:05:53,390
of the world. And then you have this

140
00:05:53,460 --> 00:05:56,770
critical quasi pseudovalue function to

141
00:05:56,840 --> 00:05:59,358
active inference in palmdp's. Active

142
00:05:59,374 --> 00:06:00,546
inference in general, which is the

143
00:06:00,568 --> 00:06:02,798
expected free energy. And the expected

144
00:06:02,814 --> 00:06:04,706
free energy is the thing you try to

145
00:06:04,728 --> 00:06:07,618
minimize as you optimize your beliefs

146
00:06:07,634 --> 00:06:10,086
about policies. So the best policies are

147
00:06:10,108 --> 00:06:13,320
those that minimize expected free energy

148
00:06:13,770 --> 00:06:15,110
and that has a bunch of interesting

149
00:06:15,180 --> 00:06:17,190
terms that lend active inference all of

150
00:06:17,260 --> 00:06:20,346
its interesting, curious, information

151
00:06:20,448 --> 00:06:23,302
seeking behavior. And then this prior

152
00:06:23,366 --> 00:06:25,834
over observations factors into the

153
00:06:25,872 --> 00:06:27,866
computation of that expected free

154
00:06:27,888 --> 00:06:30,686
energy. So if you have a particular

155
00:06:30,788 --> 00:06:32,254
prior preference to see some

156
00:06:32,292 --> 00:06:35,582
observations that will affect which

157
00:06:35,636 --> 00:06:37,854
policies get more or less expected free

158
00:06:37,892 --> 00:06:40,526
energy, and then you use that to

159
00:06:40,548 --> 00:06:43,058
actually choose a policy. And then of

160
00:06:43,064 --> 00:06:44,434
course, we have the D vector, which

161
00:06:44,472 --> 00:06:47,426
parameterizes the initial beliefs about

162
00:06:47,448 --> 00:06:51,118
his and states. So today we're

163
00:06:51,134 --> 00:06:53,634
going to actually dive in and write out

164
00:06:53,672 --> 00:06:56,600
our own ABCs and DS for particular

165
00:06:58,490 --> 00:07:00,146
generative model. We don't have to worry

166
00:07:00,178 --> 00:07:02,566
about writing out our own functions that

167
00:07:02,588 --> 00:07:05,366
do inference or do planning. All of that

168
00:07:05,388 --> 00:07:07,922
will be handled by the abstractions

169
00:07:07,986 --> 00:07:10,738
provided by prime VP, particularly in

170
00:07:10,764 --> 00:07:13,450
the agent class. So the agent class

171
00:07:13,520 --> 00:07:15,094
takes the components of the generative

172
00:07:15,142 --> 00:07:17,146
model. It gives you this very kind of

173
00:07:17,168 --> 00:07:19,882
black box API that you can just use to

174
00:07:19,936 --> 00:07:22,090
perform active inference.

175
00:07:23,790 --> 00:07:25,374
In the last video, we talked about

176
00:07:25,412 --> 00:07:27,086
different levels of abstraction. This is

177
00:07:27,108 --> 00:07:29,098
like the top level of abstraction in Pi

178
00:07:29,114 --> 00:07:31,166
MDP, where you're just passing a

179
00:07:31,188 --> 00:07:33,294
generative model to an agent and then

180
00:07:33,332 --> 00:07:36,942
kind of pressing go on the agent having

181
00:07:36,996 --> 00:07:38,830
to interact with the task environment.

182
00:07:38,910 --> 00:07:40,962
So typically this is another class,

183
00:07:41,016 --> 00:07:43,182
like an environment class or a task

184
00:07:43,326 --> 00:07:45,826
class. And then you just kind of string

185
00:07:45,858 --> 00:07:47,794
the two together in an action perception

186
00:07:47,842 --> 00:07:51,170
loop and you get a simulation

187
00:07:51,250 --> 00:07:53,510
of behavior under active inference.

188
00:07:54,890 --> 00:07:57,926
And this is a standard thing you'll see

189
00:07:57,948 --> 00:07:59,626
in like OpenAI gym or other

190
00:07:59,648 --> 00:08:01,958
reinforcement learning packages. You'll

191
00:08:01,974 --> 00:08:03,402
have usually like an environment class

192
00:08:03,456 --> 00:08:05,622
and an agent class, and they exchange

193
00:08:05,686 --> 00:08:07,930
actions and observations in a loop. So

194
00:08:08,080 --> 00:08:11,614
we designed the API of Pymdp, very much

195
00:08:11,812 --> 00:08:13,280
inspired by that.

196
00:08:15,330 --> 00:08:18,894
Okay, so before we start writing down

197
00:08:18,932 --> 00:08:21,358
the generative model so that A-B-C and

198
00:08:21,364 --> 00:08:24,642
D, I want to spend a little bit of time

199
00:08:24,696 --> 00:08:26,274
exploring the idea of factorized state

200
00:08:26,312 --> 00:08:28,898
spaces. And this is important because

201
00:08:28,984 --> 00:08:30,706
not only the model we're working today,

202
00:08:30,808 --> 00:08:32,274
it's important to understand

203
00:08:32,472 --> 00:08:34,514
factorization in both observations and

204
00:08:34,552 --> 00:08:37,970
hidden states, but for almost

205
00:08:38,040 --> 00:08:41,218
all the most interesting palmdp models

206
00:08:41,234 --> 00:08:43,218
you're going to want to build, it's

207
00:08:43,234 --> 00:08:45,442
going to be really crucial to factorize

208
00:08:45,506 --> 00:08:47,862
your system in some way. Not only

209
00:08:47,916 --> 00:08:49,402
because it becomes easier to reason

210
00:08:49,456 --> 00:08:51,786
about and work with when things are

211
00:08:51,808 --> 00:08:54,426
factorized, but also it handles a lot of

212
00:08:54,448 --> 00:08:56,986
computational explosions that happen if

213
00:08:57,008 --> 00:08:58,860
you don't factorize your state space.

214
00:09:02,030 --> 00:09:04,762
So it's often useful to categorically

215
00:09:04,826 --> 00:09:06,494
separate observations into different

216
00:09:06,532 --> 00:09:08,094
modalities and hidden states into

217
00:09:08,132 --> 00:09:10,126
different factors. So what this means is

218
00:09:10,148 --> 00:09:11,738
that when we get an observation, we're

219
00:09:11,754 --> 00:09:13,166
actually getting a collection of

220
00:09:13,188 --> 00:09:15,586
different observations, one coming from

221
00:09:15,688 --> 00:09:17,666
each distinct sensory modality or

222
00:09:17,688 --> 00:09:20,098
channel. So similarly for hidden states,

223
00:09:20,184 --> 00:09:22,066
at any given time, the hidden states are

224
00:09:22,088 --> 00:09:24,210
described by a distinct set of different

225
00:09:24,280 --> 00:09:26,102
features, or what we call hidden state

226
00:09:26,156 --> 00:09:28,566
factors. And so we refer to this as a

227
00:09:28,588 --> 00:09:30,758
factorized representation because the

228
00:09:30,764 --> 00:09:32,806
different modalities are independent of

229
00:09:32,828 --> 00:09:35,826
each other, and the different hidden

230
00:09:35,858 --> 00:09:38,666
states are also independent of each

231
00:09:38,688 --> 00:09:41,094
other. Their dynamics are so they evolve

232
00:09:41,142 --> 00:09:43,514
in time without affecting the other

233
00:09:43,552 --> 00:09:46,182
hidden state factors. So that's formally

234
00:09:46,246 --> 00:09:47,738
written down as follows. Like the

235
00:09:47,744 --> 00:09:51,626
modalities are conditionally

236
00:09:51,658 --> 00:09:53,038
independent of each other. Given the

237
00:09:53,044 --> 00:09:54,334
hidden states, that's what this

238
00:09:54,372 --> 00:09:56,254
factorization of the likelihood looks

239
00:09:56,292 --> 00:09:59,918
like. So you can think of

240
00:09:59,924 --> 00:10:01,294
the different modalities as different

241
00:10:01,332 --> 00:10:03,914
sensory channels like vision, audition,

242
00:10:04,042 --> 00:10:06,466
somata sensation, and they provide their

243
00:10:06,488 --> 00:10:08,466
own distinct type of information which

244
00:10:08,488 --> 00:10:10,082
are then integrated together during

245
00:10:10,136 --> 00:10:12,286
coherence. And factorizing the hidden

246
00:10:12,318 --> 00:10:14,162
states is like the idea that any given

247
00:10:14,216 --> 00:10:15,734
time the world can be described by

248
00:10:15,772 --> 00:10:18,310
independent features, like an object

249
00:10:18,380 --> 00:10:20,166
being described by both its location and

250
00:10:20,188 --> 00:10:24,214
space, as well as its identity and

251
00:10:24,252 --> 00:10:26,162
factorizing. The state's representations

252
00:10:26,226 --> 00:10:28,058
of the model in this way allows for a

253
00:10:28,064 --> 00:10:30,138
few different distinct advantages. One

254
00:10:30,144 --> 00:10:32,426
is computational efficiency, both in

255
00:10:32,448 --> 00:10:35,690
terms of memory and CPU.

256
00:10:36,190 --> 00:10:37,946
It simplifies the structure of

257
00:10:37,968 --> 00:10:39,994
generative model itself, so it lends it

258
00:10:40,032 --> 00:10:41,434
a bit of interpretability and

259
00:10:41,472 --> 00:10:43,422
transparency. So there's only certain

260
00:10:43,476 --> 00:10:45,198
sets of variables that represent the

261
00:10:45,204 --> 00:10:47,006
agent's beliefs about one feature of the

262
00:10:47,028 --> 00:10:48,814
environment, for instance. And then

263
00:10:48,852 --> 00:10:51,518
finally, some would argue it has a

264
00:10:51,524 --> 00:10:53,482
degree of neuronal or biological

265
00:10:53,546 --> 00:10:55,794
plausibility. And it's consistent with

266
00:10:55,832 --> 00:10:59,186
the idea of factorized what others would

267
00:10:59,208 --> 00:11:00,946
call modular representations in the

268
00:11:00,968 --> 00:11:03,646
brain. So this group of neuronal

269
00:11:03,678 --> 00:11:05,886
populations deals with representing

270
00:11:05,998 --> 00:11:07,766
where something is in space, and this

271
00:11:07,788 --> 00:11:09,878
group of neuronal populations deals with

272
00:11:09,964 --> 00:11:11,846
representing the identity or what the

273
00:11:11,868 --> 00:11:15,094
thing is. So that's kind of the reason

274
00:11:15,132 --> 00:11:16,470
we do this factorization.

275
00:11:19,710 --> 00:11:23,340
So one of the most classic examples of

276
00:11:23,950 --> 00:11:26,538
the early examples we do in Pinevp, and

277
00:11:26,544 --> 00:11:29,270
this can be found on the documentation

278
00:11:29,350 --> 00:11:32,270
and on the main page is this grid world

279
00:11:32,340 --> 00:11:34,240
example where the agent is kind of

280
00:11:36,370 --> 00:11:39,406
navigating in a 2D grid world space. In

281
00:11:39,428 --> 00:11:42,894
the notebooks online, we do like three

282
00:11:42,932 --> 00:11:44,354
by three grid world. So there's nine

283
00:11:44,392 --> 00:11:47,742
total locations. And in a fully

284
00:11:47,806 --> 00:11:49,474
unfactorized or what we call an

285
00:11:49,512 --> 00:11:51,790
enumerated state space representation,

286
00:11:51,950 --> 00:11:55,060
every location in grid world has its own

287
00:11:55,850 --> 00:11:59,126
particular identity or state. So we just

288
00:11:59,148 --> 00:12:01,890
arbitrary can label them like location

289
00:12:01,970 --> 00:12:04,422
zero all the way to location eight. And

290
00:12:04,556 --> 00:12:07,046
that covers all nine levels of

291
00:12:07,068 --> 00:12:11,130
gridworld. This is fine, but especially

292
00:12:11,200 --> 00:12:13,066
for a small state space like a three by

293
00:12:13,088 --> 00:12:16,694
three grid world. But it kind of taxes

294
00:12:16,742 --> 00:12:20,598
our memory and our interpretability

295
00:12:20,694 --> 00:12:22,362
a little bit because we have to remember

296
00:12:22,416 --> 00:12:27,406
exactly how our nine indices map to the

297
00:12:27,428 --> 00:12:29,246
different places in grid world. So if

298
00:12:29,268 --> 00:12:30,798
I'm in the middle of the grid, I need to

299
00:12:30,884 --> 00:12:33,074
have some kind of look up table to say,

300
00:12:33,112 --> 00:12:37,346
okay, location four is like

301
00:12:37,448 --> 00:12:39,874
zero or one comma one I e, the middle

302
00:12:39,912 --> 00:12:42,174
location in the grid. In a factorized

303
00:12:42,222 --> 00:12:45,090
representation, the grid could be

304
00:12:45,160 --> 00:12:47,586
represented as two orthogonal or

305
00:12:47,608 --> 00:12:49,894
independent hidden state factors. One is

306
00:12:49,932 --> 00:12:51,558
something like the x displacement or the

307
00:12:51,564 --> 00:12:54,054
horizontal displacement, which now just

308
00:12:54,092 --> 00:12:56,454
takes three values like which column of

309
00:12:56,492 --> 00:12:59,474
grid world are you in? And then vertical

310
00:12:59,522 --> 00:13:01,286
displacement or y position, which is

311
00:13:01,308 --> 00:13:03,698
something like which row of grid world

312
00:13:03,804 --> 00:13:07,146
M-I-N. And so now each hidden state is

313
00:13:07,168 --> 00:13:10,342
not a single nine dimensional vector,

314
00:13:10,406 --> 00:13:12,366
but it's actually a combination or a

315
00:13:12,388 --> 00:13:14,622
pair of two hidden states factors. So

316
00:13:14,676 --> 00:13:16,414
two, three vectors instead of a single

317
00:13:16,452 --> 00:13:19,834
nine vector. And then a given hidden

318
00:13:19,882 --> 00:13:21,838
states itself is picked out by a

319
00:13:21,844 --> 00:13:24,274
coincidence of these two hidden states

320
00:13:24,312 --> 00:13:28,066
factors. So if the x position is one and

321
00:13:28,088 --> 00:13:30,526
the y position is two, then it means I'm

322
00:13:30,558 --> 00:13:34,034
in one

323
00:13:34,072 --> 00:13:37,278
comma two. So like the middle bottom up

324
00:13:37,304 --> 00:13:40,534
the grid world. And then once

325
00:13:40,572 --> 00:13:42,374
you do this, so once we have a

326
00:13:42,412 --> 00:13:44,546
factorized hidden state representation,

327
00:13:44,738 --> 00:13:46,566
it has implication for the way we

328
00:13:46,588 --> 00:13:48,726
construct the generative model. So in a

329
00:13:48,748 --> 00:13:50,186
kind of simple generative model, you

330
00:13:50,208 --> 00:13:52,474
would just have one B array that in the

331
00:13:52,512 --> 00:13:55,466
original grid world example just is like

332
00:13:55,568 --> 00:13:57,994
nine possible hidden states, the nine

333
00:13:58,032 --> 00:14:00,218
possible locations of where I just was

334
00:14:00,384 --> 00:14:02,074
that maps to the nine possible

335
00:14:02,192 --> 00:14:03,902
subsequent hidden states. So the nine

336
00:14:03,956 --> 00:14:06,030
possible locations I could be going to.

337
00:14:06,180 --> 00:14:07,854
And then you'd have that nine by nine

338
00:14:07,892 --> 00:14:09,902
matrix conditioned on the different

339
00:14:09,956 --> 00:14:12,880
actions. So in the grid world demo,

340
00:14:13,650 --> 00:14:15,550
the actions are typically local like

341
00:14:15,620 --> 00:14:18,402
move up, move left, move down, move

342
00:14:18,456 --> 00:14:20,754
right. But once you factorize things,

343
00:14:20,792 --> 00:14:21,858
you're going to actually now have a

344
00:14:21,864 --> 00:14:24,066
collection of B matrices. And this is a

345
00:14:24,088 --> 00:14:26,818
consequence of the factorization across

346
00:14:26,904 --> 00:14:28,946
the transition models that we discussed

347
00:14:28,978 --> 00:14:30,518
a few slides ago. So you're going to

348
00:14:30,524 --> 00:14:33,490
have one B matrix or one set of B arrays

349
00:14:33,650 --> 00:14:36,726
for the X displacement. So how does the

350
00:14:36,748 --> 00:14:40,266
agent move in the X direction? These are

351
00:14:40,288 --> 00:14:43,770
what each of these X displacement

352
00:14:44,750 --> 00:14:46,746
B matrices look like, cognition on

353
00:14:46,768 --> 00:14:48,138
different actions. So this is what it

354
00:14:48,144 --> 00:14:50,186
looks like for moving left, this is what

355
00:14:50,208 --> 00:14:51,562
the B matrix looks like for moving

356
00:14:51,616 --> 00:14:53,246
right. And this is what it looks like

357
00:14:53,268 --> 00:14:55,006
for stay. And then similarly you have

358
00:14:55,028 --> 00:14:57,166
another B matrix that encodes the

359
00:14:57,188 --> 00:14:59,806
agent's abilities to move in the

360
00:14:59,908 --> 00:15:02,010
vertical direction or y displacement.

361
00:15:02,090 --> 00:15:03,394
And similarly they actually look

362
00:15:03,432 --> 00:15:07,394
identical because the world is

363
00:15:07,432 --> 00:15:09,186
like rotation and translation and

364
00:15:09,208 --> 00:15:12,914
variant and you'll have another

365
00:15:13,032 --> 00:15:15,806
smaller B array just for y movement.

366
00:15:15,918 --> 00:15:17,506
This is a very simple example. We're not

367
00:15:17,528 --> 00:15:18,802
going to actually do this in code

368
00:15:18,856 --> 00:15:20,198
because it's kind of trivial, but it's

369
00:15:20,204 --> 00:15:22,134
just an example of how instead of having

370
00:15:22,172 --> 00:15:24,258
a location fully enumerated

371
00:15:24,274 --> 00:15:25,686
representation, you can split that up

372
00:15:25,708 --> 00:15:28,390
into basically a y axis and an X axis.

373
00:15:29,130 --> 00:15:31,818
So now we're not going to simulate an

374
00:15:31,824 --> 00:15:33,146
active inference agent, but we're just

375
00:15:33,168 --> 00:15:34,522
going to play around with these data

376
00:15:34,576 --> 00:15:37,082
structures to get you used to the idea

377
00:15:37,136 --> 00:15:38,986
of factorized representations and how

378
00:15:39,008 --> 00:15:41,658
that manifests in the code. So now we'll

379
00:15:41,674 --> 00:15:45,102
go over to Colab. So if you've been

380
00:15:45,156 --> 00:15:46,654
running this on your own, disk should

381
00:15:46,692 --> 00:15:49,470
all be downloaded.

382
00:15:49,970 --> 00:15:53,194
So you've installed interactively PMDP,

383
00:15:53,242 --> 00:15:55,490
that's the whole name of the package

384
00:15:55,990 --> 00:15:58,386
that's now in your environment. And then

385
00:15:58,408 --> 00:16:00,494
you should also run this some basic

386
00:16:00,542 --> 00:16:03,586
imports like NumPy and pimedp, which is

387
00:16:03,608 --> 00:16:06,966
now in the environment. Okay? And so the

388
00:16:06,988 --> 00:16:09,894
basic variables that you'll see are

389
00:16:09,932 --> 00:16:13,378
things like there's a few variables

390
00:16:13,394 --> 00:16:15,814
that are almost always part of any time

391
00:16:15,852 --> 00:16:17,494
DP workflow. And this is very much

392
00:16:17,532 --> 00:16:20,186
mirrored on how it's done in SPM in the

393
00:16:20,208 --> 00:16:23,754
Dem tool box. So typically you'll have a

394
00:16:23,792 --> 00:16:27,014
list that specifies the dimensionalities

395
00:16:27,142 --> 00:16:29,146
or the number of different levels of

396
00:16:29,168 --> 00:16:31,914
each hidden state factor. So for our

397
00:16:32,032 --> 00:16:33,950
three by three grid world nine possible

398
00:16:34,020 --> 00:16:37,086
states, we have one x factor of three

399
00:16:37,268 --> 00:16:39,674
levels and one y factor of three levels.

400
00:16:39,802 --> 00:16:41,786
And then the length of that list tells

401
00:16:41,818 --> 00:16:43,474
us the total number of hidden state

402
00:16:43,512 --> 00:16:46,626
factors. So in this case, we have two

403
00:16:46,648 --> 00:16:49,490
hidden state factors. And then similarly

404
00:16:50,790 --> 00:16:52,366
you have hidden states are factorized,

405
00:16:52,398 --> 00:16:54,674
and then similarly you factorize your

406
00:16:54,712 --> 00:16:56,798
control states. So for every hidden

407
00:16:56,814 --> 00:16:58,190
state factor, there's also going to be a

408
00:16:58,200 --> 00:17:00,486
control state factor. And the fact that

409
00:17:00,508 --> 00:17:02,486
these are also three dimension each just

410
00:17:02,508 --> 00:17:04,502
basically means that the agent has three

411
00:17:04,556 --> 00:17:06,726
possible action in the x axis and three

412
00:17:06,748 --> 00:17:09,194
possible actions in the y axis. And then

413
00:17:09,232 --> 00:17:11,386
the number of control factors is also

414
00:17:11,568 --> 00:17:14,906
going to be two in that case. And so we

415
00:17:14,928 --> 00:17:17,386
have some nice utility functions that

416
00:17:17,408 --> 00:17:21,246
can quickly build a brain given the

417
00:17:21,268 --> 00:17:23,226
two things that are necessary, the numb

418
00:17:23,258 --> 00:17:25,406
states and NUM controls variables. So

419
00:17:25,428 --> 00:17:29,280
you just do initialize empty B

420
00:17:32,610 --> 00:17:35,906
NUM states and NUM controls, and then

421
00:17:35,928 --> 00:17:41,074
you'll have a B matrix that

422
00:17:41,112 --> 00:17:44,260
has the correct shapes and stuff.

423
00:17:45,290 --> 00:17:48,614
So three rows, three columns, and three

424
00:17:48,652 --> 00:17:50,454
possible actions for the x direction and

425
00:17:50,492 --> 00:17:52,086
similarly for the y direction. So this

426
00:17:52,108 --> 00:17:54,630
is just basic setting up your variables.

427
00:17:58,510 --> 00:18:00,294
And often we'll have these solution

428
00:18:00,342 --> 00:18:02,442
cells that are hidden underneath each

429
00:18:02,496 --> 00:18:04,198
little quasiexercise, so that's

430
00:18:04,214 --> 00:18:06,300
something you can do as well.

431
00:18:08,110 --> 00:18:11,286
Okay? And so that's just initializing

432
00:18:11,318 --> 00:18:12,618
and empty array, right? So we don't

433
00:18:12,634 --> 00:18:15,914
actually know what those contingencies

434
00:18:15,962 --> 00:18:18,398
are that we saw in the slides, but if we

435
00:18:18,404 --> 00:18:21,326
want to populate this thing, so this is

436
00:18:21,348 --> 00:18:24,946
what each factor specific V array looks

437
00:18:24,968 --> 00:18:26,226
like, then we have to go into these

438
00:18:26,248 --> 00:18:28,286
matrices and actually fill out the rows,

439
00:18:28,318 --> 00:18:32,002
columns and third order slices with

440
00:18:32,056 --> 00:18:34,494
numbers. So for instance, this loop

441
00:18:34,542 --> 00:18:36,434
where we loop over factors and we fill

442
00:18:36,472 --> 00:18:37,678
out the different entries of the B

443
00:18:37,704 --> 00:18:40,322
array. What this will do is just encode

444
00:18:40,386 --> 00:18:42,390
those local actions like move left,

445
00:18:42,460 --> 00:18:45,814
move right for the x factor, and then

446
00:18:45,852 --> 00:18:48,466
move up, move down for the y factor.

447
00:18:48,578 --> 00:18:49,938
And so once you've run that code,

448
00:18:49,964 --> 00:18:51,386
you've basically filled out all the

449
00:18:51,408 --> 00:18:53,658
numbers in that big empty B array that

450
00:18:53,664 --> 00:18:55,514
you started. And then you can use things

451
00:18:55,552 --> 00:18:57,882
like the plot likelihood function to

452
00:18:58,016 --> 00:19:00,454
plot these likelihood distributions,

453
00:19:00,502 --> 00:19:01,970
action conditioned likelihood

454
00:19:01,990 --> 00:19:05,070
distributions as matrices. So this is

455
00:19:05,140 --> 00:19:08,350
move left. For instance, if we're in the

456
00:19:08,420 --> 00:19:10,814
x hidden state factor, and if we change

457
00:19:10,852 --> 00:19:12,526
this to a one, we've changed the action

458
00:19:12,558 --> 00:19:16,162
index, then this is move right,

459
00:19:16,296 --> 00:19:18,162
and then similarly if we change this,

460
00:19:18,216 --> 00:19:22,562
this is move down

461
00:19:22,696 --> 00:19:25,460
if we're doing action one here.

462
00:19:31,170 --> 00:19:33,606
So darker colors, whether it's grayscale

463
00:19:33,658 --> 00:19:36,606
or red, or whatever, almost unanimously

464
00:19:36,638 --> 00:19:38,994
in prime DP, the darker colors represent

465
00:19:39,042 --> 00:19:40,070
more probability.

466
00:19:43,770 --> 00:19:46,070
So instead of having to display numbers,

467
00:19:46,140 --> 00:19:48,662
we'll just show darker numbers. Okay,

468
00:19:48,716 --> 00:19:51,066
so now let's go back to the slides and

469
00:19:51,088 --> 00:19:55,034
talk about the A arrays. So in our

470
00:19:55,072 --> 00:19:57,318
unfactorized, fully enumerated grid

471
00:19:57,334 --> 00:19:59,626
world example, and again, I'll refer you

472
00:19:59,648 --> 00:20:03,146
to the documentation of prime VP if you

473
00:20:03,168 --> 00:20:05,194
want to play around with that example.

474
00:20:05,392 --> 00:20:07,294
The hidden state factors, which are just

475
00:20:07,332 --> 00:20:10,634
these nine kind of Arbitrarily labeled

476
00:20:10,682 --> 00:20:13,674
locations map to an observation

477
00:20:13,722 --> 00:20:15,562
modality, which is like the agent's

478
00:20:15,706 --> 00:20:17,646
sensation of its own position, kind of

479
00:20:17,668 --> 00:20:20,330
appropriate GPS modality. You could

480
00:20:20,340 --> 00:20:21,806
think of it as like they're sensing

481
00:20:21,838 --> 00:20:24,562
where they are at any given time. And so

482
00:20:24,696 --> 00:20:26,814
there are various ways you could encode

483
00:20:26,862 --> 00:20:28,446
that. But let's just pretend that they

484
00:20:28,488 --> 00:20:31,682
have a very high fidelity GPS,

485
00:20:31,746 --> 00:20:35,218
so they're getting precise GPS readouts

486
00:20:35,234 --> 00:20:37,446
of where they are at any given time. So

487
00:20:37,628 --> 00:20:40,246
in a fully enumerated world, that a

488
00:20:40,268 --> 00:20:42,054
matrix, that likelihood modality would

489
00:20:42,092 --> 00:20:44,042
look like this. When we start

490
00:20:44,096 --> 00:20:46,234
factorizing things or splitting up the

491
00:20:46,272 --> 00:20:48,886
hidden state factors into an X factor

492
00:20:48,918 --> 00:20:51,674
and a Y factor, that choice not only

493
00:20:51,712 --> 00:20:53,514
manifests in the B arrays, but it also

494
00:20:53,552 --> 00:20:54,746
manifests in the structure of the

495
00:20:54,768 --> 00:20:56,158
arrays. And I think this is one of the

496
00:20:56,164 --> 00:20:58,686
most key things to understand, because

497
00:20:58,788 --> 00:21:00,366
when it comes to coding these things up

498
00:21:00,388 --> 00:21:02,826
yourself, understanding how these arrays

499
00:21:02,858 --> 00:21:04,766
are structured is really important to

500
00:21:04,788 --> 00:21:08,370
getting things working successfully,

501
00:21:09,510 --> 00:21:11,026
basically getting used to

502
00:21:11,048 --> 00:21:15,966
multidimensional indexing. So briefly,

503
00:21:16,158 --> 00:21:19,054
in summary, when you have multiple

504
00:21:19,102 --> 00:21:21,462
hidden state factors that manifests as

505
00:21:21,516 --> 00:21:24,582
extra Lagging dimensions or extra higher

506
00:21:24,636 --> 00:21:28,134
order dimensions in your, in your

507
00:21:28,172 --> 00:21:30,466
A array, so it's not really an A matrix

508
00:21:30,498 --> 00:21:32,566
anymore, it's an A tensor. So that means

509
00:21:32,588 --> 00:21:34,258
if you have two hidden state factors,

510
00:21:34,354 --> 00:21:36,542
the number of Lagging dimensions, ie.

511
00:21:36,626 --> 00:21:38,378
Excluding rows, that's what I mean when

512
00:21:38,384 --> 00:21:40,714
I say Lagging dimensions will be two.

513
00:21:40,752 --> 00:21:42,666
So you have columns and slices in

514
00:21:42,688 --> 00:21:44,794
addition to rows. So this is really

515
00:21:44,832 --> 00:21:46,282
important to understand when either

516
00:21:46,336 --> 00:21:49,662
using SPM or Pymdp to do palm DP based

517
00:21:49,716 --> 00:21:51,758
active inference. And another way of

518
00:21:51,764 --> 00:21:53,290
saying this is for each additional

519
00:21:53,370 --> 00:21:55,306
random variable that we're conditioning

520
00:21:55,338 --> 00:21:57,086
our observations on, we have an

521
00:21:57,108 --> 00:21:58,846
additional Lagging dimension in our

522
00:21:58,868 --> 00:22:01,026
array. So this is the same principle as

523
00:22:01,048 --> 00:22:03,170
with the B matrices because we condition

524
00:22:03,750 --> 00:22:06,450
the next state both on the past state

525
00:22:06,520 --> 00:22:08,274
and the past action. That's why the B

526
00:22:08,312 --> 00:22:10,534
arrays are also tensors. So we have two

527
00:22:10,572 --> 00:22:12,886
extra dimensions in the B array, one for

528
00:22:12,908 --> 00:22:14,614
each conditioning variable, past state

529
00:22:14,652 --> 00:22:18,486
and past action. So now in the X and

530
00:22:18,508 --> 00:22:21,274
Y factorized grid world, we have two

531
00:22:21,312 --> 00:22:22,762
Lagging dimensions where the first

532
00:22:22,816 --> 00:22:25,670
Lagging dimension, the columns in Bleu,

533
00:22:25,830 --> 00:22:29,082
index a particular X location, and the

534
00:22:29,136 --> 00:22:30,950
second Lagging dimension, the slices,

535
00:22:31,030 --> 00:22:33,774
if you will, index a particular Y

536
00:22:33,812 --> 00:22:37,054
location. So now what I'm going to do is

537
00:22:37,092 --> 00:22:38,826
unwrap these slices of the multi

538
00:22:38,858 --> 00:22:40,270
dimension A matrix.

539
00:22:43,890 --> 00:22:46,306
And so you can see that each slice of

540
00:22:46,328 --> 00:22:49,470
the A matrix, so that each purple

541
00:22:49,550 --> 00:22:52,146
indexed third order slice corresponds to

542
00:22:52,168 --> 00:22:54,034
conditioning on a particular setting of

543
00:22:54,072 --> 00:22:56,350
Y. So a particular conditional

544
00:22:56,430 --> 00:22:58,514
distribution over observations for the

545
00:22:58,552 --> 00:23:01,254
three settings of X for a fixed value of

546
00:23:01,292 --> 00:23:03,494
Y. So each slice is exactly this

547
00:23:03,532 --> 00:23:06,626
conditional distribution, where we're

548
00:23:06,658 --> 00:23:08,946
looking at the conditional distributions

549
00:23:08,978 --> 00:23:11,014
over observations for each setting of X.

550
00:23:11,052 --> 00:23:13,386
So those are the columns indexed by the

551
00:23:13,408 --> 00:23:16,326
Bleu numbers at the bottom, but we're

552
00:23:16,358 --> 00:23:19,066
fixing to one value of Y. So that's the

553
00:23:19,088 --> 00:23:20,826
conditional distribution over

554
00:23:21,008 --> 00:23:23,354
observations zero, one and two. So being

555
00:23:23,392 --> 00:23:26,286
in the top row, given that we're in the

556
00:23:26,308 --> 00:23:29,182
first row, y equals zero for the three

557
00:23:29,236 --> 00:23:31,534
possible settings of X. And then we move

558
00:23:31,572 --> 00:23:34,782
down to the next set of observations and

559
00:23:34,916 --> 00:23:36,834
the next slice of Y, and it looks like

560
00:23:36,872 --> 00:23:39,220
that and then finally like that.

561
00:23:40,870 --> 00:23:44,274
So this is the case where our

562
00:23:44,392 --> 00:23:47,694
GPS is noiseless and high fidelity,

563
00:23:47,742 --> 00:23:49,794
right? That's why we have like hyper

564
00:23:49,842 --> 00:23:52,166
dark cells and then everything else is

565
00:23:52,188 --> 00:23:54,226
white, is because the agent believes

566
00:23:54,258 --> 00:23:56,870
that its observations are high fidelity

567
00:23:58,250 --> 00:24:00,262
signals of the actual hidden state,

568
00:24:00,316 --> 00:24:03,946
namely the X comma y location. So then

569
00:24:03,968 --> 00:24:07,034
when we pat these back together, we see

570
00:24:07,072 --> 00:24:09,274
how this full a matrix or set of

571
00:24:09,312 --> 00:24:11,066
conditional distributions will be

572
00:24:11,088 --> 00:24:13,594
represented by a nine by three by three

573
00:24:13,632 --> 00:24:15,386
tensor, where again, each Lagrange

574
00:24:15,418 --> 00:24:17,406
dimension exists to encode the

575
00:24:17,428 --> 00:24:19,534
conditional dependencies between that

576
00:24:19,572 --> 00:24:21,626
particular hidden state factor indexed

577
00:24:21,658 --> 00:24:23,246
by the Lagging dimension and the

578
00:24:23,268 --> 00:24:26,494
observations for this modality. So when

579
00:24:26,532 --> 00:24:29,134
I index into the Ith column and the Jth

580
00:24:29,182 --> 00:24:32,078
slice of this a matrix or a tensor, I'm

581
00:24:32,094 --> 00:24:33,746
basically slicing out a particular

582
00:24:33,848 --> 00:24:35,234
conditional distribution over

583
00:24:35,272 --> 00:24:37,522
observations where I'm deciding what

584
00:24:37,576 --> 00:24:39,650
settings of the conditional

585
00:24:39,730 --> 00:24:42,706
distributions or the conditional random

586
00:24:42,738 --> 00:24:44,280
variables I'm interested in.

587
00:24:46,970 --> 00:24:49,842
Okay? So yeah, that's a kind of critical

588
00:24:49,906 --> 00:24:53,480
concept and to just make it more

589
00:24:55,050 --> 00:24:57,994
tangible and clear. And to be clear,

590
00:24:58,032 --> 00:25:00,134
this isn't the only way to encode

591
00:25:00,182 --> 00:25:03,014
conditional dependencies in categorical

592
00:25:03,062 --> 00:25:04,494
distributions, but it's just the way

593
00:25:04,532 --> 00:25:08,206
that was originally used in SPM to

594
00:25:08,228 --> 00:25:10,014
encode these dependencies. And then we

595
00:25:10,052 --> 00:25:11,454
just borrowed that convention when

596
00:25:11,492 --> 00:25:14,394
building Pine VP. And it's pretty useful

597
00:25:14,442 --> 00:25:16,526
because it makes generating things like

598
00:25:16,548 --> 00:25:18,430
conditional expectations pretty

599
00:25:18,580 --> 00:25:22,734
straightforward using linear

600
00:25:22,782 --> 00:25:26,286
algebra operations like higher order dot

601
00:25:26,318 --> 00:25:28,674
products and stuff like that. So we have

602
00:25:28,712 --> 00:25:32,334
this kind of unwrapped representation

603
00:25:32,382 --> 00:25:36,454
of the Ara here, and we can use this to

604
00:25:36,492 --> 00:25:38,006
refer back to when we're building our

605
00:25:38,028 --> 00:25:41,766
Ara. One thing I didn't mention that

606
00:25:41,788 --> 00:25:43,674
is also important is that in the same

607
00:25:43,712 --> 00:25:46,346
way we can factorize hidden states, we

608
00:25:46,368 --> 00:25:48,746
can factorize modalities. So we'll talk

609
00:25:48,768 --> 00:25:50,906
about that in a second. But just for

610
00:25:50,928 --> 00:25:53,254
now, let's assume we have one single GPS

611
00:25:53,382 --> 00:25:55,974
sensing modality of nine possible levels

612
00:25:56,022 --> 00:25:58,126
where I am in grid world. So it's just a

613
00:25:58,148 --> 00:26:00,606
list of one number nine, and then the

614
00:26:00,628 --> 00:26:02,174
number of modalities will trivially be

615
00:26:02,212 --> 00:26:04,606
one the length of that list. And then we

616
00:26:04,628 --> 00:26:08,202
can use similarly this utils initialized

617
00:26:08,266 --> 00:26:11,026
MTA array, which takes the number of

618
00:26:11,048 --> 00:26:12,306
observation modalities, their

619
00:26:12,328 --> 00:26:13,726
dimensions, and the number of hidden

620
00:26:13,758 --> 00:26:18,420
states and then it creates the

621
00:26:18,970 --> 00:26:21,766
A array with the proper dimensions and

622
00:26:21,788 --> 00:26:23,942
everything. So I've also created this

623
00:26:23,996 --> 00:26:26,498
combined list called a location dims,

624
00:26:26,674 --> 00:26:28,966
which is a combination of the number of

625
00:26:28,988 --> 00:26:31,670
observation modality dimensions and the

626
00:26:31,740 --> 00:26:32,990
number of hidden state factor

627
00:26:33,010 --> 00:26:34,714
dimensions. So that's, as we said,

628
00:26:34,752 --> 00:26:37,194
going to be nine, three, three. And so

629
00:26:37,232 --> 00:26:40,666
then we can populate the

630
00:26:40,688 --> 00:26:43,274
entry of our first modality in the A

631
00:26:43,312 --> 00:26:45,066
matrix, which is trivially here, the

632
00:26:45,088 --> 00:26:48,670
only modality with a matrix of zeros.

633
00:26:49,490 --> 00:26:51,102
This is actually what's happening under

634
00:26:51,156 --> 00:26:52,926
the hood in this thing. So we don't need

635
00:26:52,948 --> 00:26:56,354
to do it here. But then if we just run

636
00:26:56,392 --> 00:26:58,434
that, then we'll see that the shape of a

637
00:26:58,472 --> 00:27:01,490
zero is the same as a location dibs.

638
00:27:04,870 --> 00:27:06,706
Okay, so that's just initializing it.

639
00:27:06,728 --> 00:27:10,034
So we now have one A array that has one

640
00:27:10,072 --> 00:27:13,206
modality whose shape is nine by three by

641
00:27:13,228 --> 00:27:14,966
three. And then we just go and fill it

642
00:27:14,988 --> 00:27:17,618
out like we saw up here. So I'm filling

643
00:27:17,634 --> 00:27:19,542
it out under the assumption of this

644
00:27:19,596 --> 00:27:23,042
noiseless high, high quality GPS sensor.

645
00:27:23,186 --> 00:27:25,174
So you can see when I'm indexing into

646
00:27:25,212 --> 00:27:27,834
the Lagging dimension here, the the Y

647
00:27:27,872 --> 00:27:29,846
dimension, which is the third dimension

648
00:27:29,878 --> 00:27:31,914
of the tensor. I'm saying for this

649
00:27:31,952 --> 00:27:34,442
particular value of Y, which is when Y

650
00:27:34,496 --> 00:27:37,898
is zero, we're in the first row

651
00:27:37,914 --> 00:27:40,010
of grid world. Then the conditional

652
00:27:40,090 --> 00:27:41,806
distribution over the three settings of

653
00:27:41,828 --> 00:27:44,606
the GPS, given all the settings of X,

654
00:27:44,708 --> 00:27:46,702
is just an identity matrix. So I'm just

655
00:27:46,756 --> 00:27:48,834
coding that, that little chunk right

656
00:27:48,872 --> 00:27:50,946
there. And then we can go through each

657
00:27:50,968 --> 00:27:53,140
of the slices iteratively and do that.

658
00:27:54,310 --> 00:27:57,138
So, yeah, one of the things I think is a

659
00:27:57,144 --> 00:27:59,086
disadvantage currently of both Pine DP

660
00:27:59,118 --> 00:28:01,494
and the SPM is I think we need better

661
00:28:01,532 --> 00:28:04,920
ways to make people not have to do these

662
00:28:05,370 --> 00:28:07,494
multi dimension indexing operations to

663
00:28:07,532 --> 00:28:09,282
encode a particular conditional

664
00:28:09,346 --> 00:28:10,646
independency structure. And I've thought

665
00:28:10,668 --> 00:28:11,990
of ways to do that, but it's actually

666
00:28:12,060 --> 00:28:14,306
pretty hard to do that in a generic

667
00:28:14,338 --> 00:28:16,546
flexible way where people can just come

668
00:28:16,588 --> 00:28:18,134
to the table with their own semantics

669
00:28:18,182 --> 00:28:20,250
and then all this gets done for them.

670
00:28:20,320 --> 00:28:22,026
So for now, you still have to kind of do

671
00:28:22,048 --> 00:28:24,246
this by hand or write some algorithmic

672
00:28:24,278 --> 00:28:25,786
way to do it that's specific to your

673
00:28:25,808 --> 00:28:28,846
task. But yeah, that's just something to

674
00:28:28,868 --> 00:28:31,998
mention. It's not ideal that we have

675
00:28:32,164 --> 00:28:34,686
users doing this, but at the moment I

676
00:28:34,708 --> 00:28:35,966
can't really think of a better way to do

677
00:28:35,988 --> 00:28:39,610
it. And then once we've encoded that,

678
00:28:39,700 --> 00:28:41,230
we can look at our little conditional

679
00:28:41,310 --> 00:28:43,006
distributions given different settings

680
00:28:43,038 --> 00:28:44,978
of Y. And that's just one choice. We

681
00:28:44,984 --> 00:28:47,394
could also condition on X and look ant

682
00:28:47,432 --> 00:28:51,080
for all settings of Y, x equals zero.

683
00:28:53,770 --> 00:28:55,606
Like you can slice this up however you

684
00:28:55,628 --> 00:28:59,160
want, right? That's just

685
00:28:59,690 --> 00:29:01,270
a visualization choice.

686
00:29:06,760 --> 00:29:10,116
And these are our three collections of

687
00:29:10,138 --> 00:29:11,636
conditional distributions, one for each

688
00:29:11,658 --> 00:29:14,950
setting of Y. Okay,

689
00:29:17,160 --> 00:29:19,320
now let's go back to the slides.

690
00:29:21,100 --> 00:29:23,896
Yes. So one thing I didn't mention, or I

691
00:29:23,918 --> 00:29:27,256
said I would mention, is we just had a

692
00:29:27,278 --> 00:29:29,176
single observation modality. But just as

693
00:29:29,198 --> 00:29:32,836
for hidden states, we can factorize and

694
00:29:32,878 --> 00:29:34,476
we don't have to fully enumerate our

695
00:29:34,498 --> 00:29:36,536
observation space. So we could separate

696
00:29:36,568 --> 00:29:39,116
the grid GPS observations into an X and

697
00:29:39,138 --> 00:29:42,344
a Y GPS. So now you're observing a pair

698
00:29:42,392 --> 00:29:43,916
of different observations at any given

699
00:29:43,938 --> 00:29:46,784
time, one X observation and one Y. So

700
00:29:46,822 --> 00:29:48,736
just like we had a separate B array for

701
00:29:48,758 --> 00:29:51,216
each hidden state factor, similarly we

702
00:29:51,238 --> 00:29:53,264
now have a separate A array for each

703
00:29:53,302 --> 00:29:55,396
observation modality. So we would

704
00:29:55,418 --> 00:29:58,084
populate one big A object array with

705
00:29:58,122 --> 00:30:01,044
these different modality specific A

706
00:30:01,082 --> 00:30:04,532
arrays. So in this case, if we had X

707
00:30:04,586 --> 00:30:06,276
observations and Y observations, we

708
00:30:06,298 --> 00:30:08,756
would have two A sub arrays. Each one

709
00:30:08,778 --> 00:30:11,432
would have size three by three by three

710
00:30:11,486 --> 00:30:13,576
because three observations and then for

711
00:30:13,598 --> 00:30:16,996
the two possible states of the hidden

712
00:30:17,028 --> 00:30:20,468
states factors. So, yeah, that wraps

713
00:30:20,484 --> 00:30:25,056
up the slides I had on multifactor

714
00:30:25,108 --> 00:30:27,880
multimodality factorized representations

715
00:30:27,960 --> 00:30:31,576
and how that affects A and B arrays.

716
00:30:31,768 --> 00:30:35,084
So before we move on to the contextual

717
00:30:35,132 --> 00:30:37,984
multi arm bandit, let's open it up for

718
00:30:38,022 --> 00:30:40,464
questions or comments if anything was

719
00:30:40,502 --> 00:30:42,636
unclear and someone wants to contribute

720
00:30:42,668 --> 00:30:44,370
their own way of explaining something,

721
00:30:45,560 --> 00:30:47,510
happy to talk about that now.

722
00:30:49,720 --> 00:30:53,188
Awesome. Yakup. Ben, adam and Karl, if

723
00:30:53,194 --> 00:30:53,910
you'd like.

724
00:30:56,040 --> 00:30:58,968
JAKUB SMEKAL: Yeah, thanks a lot for the great

725
00:30:59,134 --> 00:31:01,370
overview. I had a question on

726
00:31:01,820 --> 00:31:04,408
initializing the B matrix. So in this

727
00:31:04,414 --> 00:31:07,850
case, we initialized it with the

728
00:31:08,700 --> 00:31:10,844
simplest policy, just all of the

729
00:31:10,962 --> 00:31:13,390
available actions the agent has.

730
00:31:16,320 --> 00:31:18,492
Would there be any particular use case

731
00:31:18,546 --> 00:31:20,876
in the grid world example where we would

732
00:31:20,898 --> 00:31:24,544
want to initialize it with a sequence of

733
00:31:24,742 --> 00:31:27,056
policies? And is that needed if we want

734
00:31:27,078 --> 00:31:29,996
to do planning of different temporal

735
00:31:30,028 --> 00:31:30,720
depth?

736
00:31:32,980 --> 00:31:35,452
So when you say sequence of policies,

737
00:31:35,516 --> 00:31:37,110
can you give me an example.

738
00:31:39,240 --> 00:31:43,060
Instead of conditioning

739
00:31:43,480 --> 00:31:48,004
it on, just move up, you would move

740
00:31:48,122 --> 00:31:52,196
up and down fixed

741
00:31:52,228 --> 00:31:54,440
sequences of actions.

742
00:31:55,740 --> 00:31:57,544
Right, right. That's interesting. Okay,

743
00:31:57,582 --> 00:32:00,072
so that's so, yes, typically when we are

744
00:32:00,126 --> 00:32:02,008
building these cognition likelihoods,

745
00:32:02,104 --> 00:32:04,028
this is more of a consequence of the

746
00:32:04,034 --> 00:32:07,916
fact that it's a palm pom DP with

747
00:32:07,938 --> 00:32:10,104
an emphasis on the M, so it's Markov.

748
00:32:10,232 --> 00:32:13,950
So if you want to encode something like

749
00:32:14,320 --> 00:32:16,552
what is the predicted next hidden state

750
00:32:16,626 --> 00:32:20,240
given I did move up and

751
00:32:20,310 --> 00:32:23,036
move down in the last two time steps?

752
00:32:23,228 --> 00:32:24,888
If I'm understanding correctly, you're

753
00:32:24,924 --> 00:32:28,116
like saying condition my B matrix, my

754
00:32:28,138 --> 00:32:30,228
next hidden state on a sequence of two

755
00:32:30,314 --> 00:32:33,776
possible past actions. Then we're

756
00:32:33,808 --> 00:32:35,956
breaking the Markov property of the

757
00:32:35,978 --> 00:32:37,956
dynamics because we're saying the next

758
00:32:37,978 --> 00:32:40,356
hidden states not just depends on what I

759
00:32:40,458 --> 00:32:42,776
did at the last time step and the state,

760
00:32:42,878 --> 00:32:45,416
but it depends on also what I did two

761
00:32:45,438 --> 00:32:47,800
time steps ago. So now you have a higher

762
00:32:47,870 --> 00:32:49,828
order temporal dependence, like a semi

763
00:32:49,844 --> 00:32:52,668
Markov model or yeah, really, just not a

764
00:32:52,674 --> 00:32:54,990
Markov model, but a higher order model.

765
00:32:55,520 --> 00:32:56,936
And that's not something that's

766
00:32:56,968 --> 00:32:59,468
currently supported in Pamdp. The

767
00:32:59,474 --> 00:33:01,244
natural way you get around that is by

768
00:33:01,282 --> 00:33:03,490
building a hierarchical model.

769
00:33:03,940 --> 00:33:06,850
So at each individual.

770
00:33:08,580 --> 00:33:10,288
Level of the hierarchical you have a

771
00:33:10,294 --> 00:33:13,488
palm DP, but then when you look at a

772
00:33:13,574 --> 00:33:15,604
single layer, like the bottom layer of

773
00:33:15,642 --> 00:33:18,416
this hierarchical model, it is a semi

774
00:33:18,448 --> 00:33:20,676
Markov model or non Markovian. If you

775
00:33:20,698 --> 00:33:22,484
take into account what all the other

776
00:33:22,522 --> 00:33:26,016
layers are doing, but that's

777
00:33:26,048 --> 00:33:28,596
not currently supported at the level of

778
00:33:28,618 --> 00:33:30,452
a single Markov model. Like you can't

779
00:33:30,516 --> 00:33:33,416
Bull a B matrix that's dependent on more

780
00:33:33,438 --> 00:33:35,064
than what happened at the last time

781
00:33:35,102 --> 00:33:38,216
step. You can't have an

782
00:33:38,238 --> 00:33:40,368
extra lagging dimension that encodes

783
00:33:40,484 --> 00:33:42,616
also what were they doing two time steps

784
00:33:42,648 --> 00:33:46,430
ago? So that's one

785
00:33:46,800 --> 00:33:49,468
interpretation of when you say policy

786
00:33:49,554 --> 00:33:52,780
like up down, I think of two actions

787
00:33:53,120 --> 00:33:57,040
that happened in sequence.

788
00:33:57,620 --> 00:34:00,112
But maybe another thing, and correct me

789
00:34:00,166 --> 00:34:03,088
if I'm reading too deeply into your

790
00:34:03,094 --> 00:34:04,916
question, another thing would be can I

791
00:34:04,938 --> 00:34:07,348
have actions in a different control

792
00:34:07,434 --> 00:34:11,012
state factor affect the dynamics of a

793
00:34:11,066 --> 00:34:13,124
particular hidden states factor? So say

794
00:34:13,162 --> 00:34:16,004
I had one hidden state factor which is

795
00:34:16,042 --> 00:34:20,756
move up, and another factor

796
00:34:20,788 --> 00:34:22,676
which is Y displacement, another factor

797
00:34:22,708 --> 00:34:24,728
that's X displacement. Can I have the

798
00:34:24,734 --> 00:34:27,032
dynamics of the Y factor not just depend

799
00:34:27,086 --> 00:34:30,460
on my Y action, but also on my X action?

800
00:34:31,520 --> 00:34:35,660
So that's the idea of basically breaking

801
00:34:39,040 --> 00:34:42,416
this independence property. Where is

802
00:34:42,438 --> 00:34:46,128
it? Here, let me find it.

803
00:34:46,214 --> 00:34:50,210
Here. So if you

804
00:34:52,100 --> 00:34:55,948
allowed the lower right shows that the

805
00:34:55,974 --> 00:34:57,684
state of one factor over time only

806
00:34:57,722 --> 00:35:00,596
depends on the state of that factor ant

807
00:35:00,618 --> 00:35:03,028
the previous time step. But if you said

808
00:35:03,194 --> 00:35:05,936
I could also make this conditionally

809
00:35:05,968 --> 00:35:09,512
dependent on not just

810
00:35:09,566 --> 00:35:13,672
factor F, but say factor I or

811
00:35:13,726 --> 00:35:17,210
Q at T minus one.

812
00:35:17,900 --> 00:35:19,672
This is something that's also not

813
00:35:19,726 --> 00:35:21,196
currently supported, but I think is an

814
00:35:21,218 --> 00:35:23,644
interesting idea, which is you would

815
00:35:23,682 --> 00:35:26,060
actually have interactions between maybe

816
00:35:26,130 --> 00:35:29,628
pairs of hidden states factors in in

817
00:35:29,714 --> 00:35:32,332
hidden states space. This actually can

818
00:35:32,386 --> 00:35:35,736
be accommodated under PMDP.

819
00:35:35,928 --> 00:35:37,720
Like mathematically I haven't built in

820
00:35:37,730 --> 00:35:39,376
the functionality to do it, but I think

821
00:35:39,398 --> 00:35:40,896
there's nothing that stops you in

822
00:35:40,918 --> 00:35:42,656
principle from doing this. So this would

823
00:35:42,678 --> 00:35:44,716
be as if I can have actions from

824
00:35:44,758 --> 00:35:46,948
different control factors all

825
00:35:47,114 --> 00:35:49,696
influencing the next state of one hidden

826
00:35:49,728 --> 00:35:52,916
state factor. And that is

827
00:35:52,938 --> 00:35:54,276
something that will probably make the

828
00:35:54,298 --> 00:35:57,510
message passing a little bit more,

829
00:35:57,960 --> 00:35:59,524
maybe not more complicated, but maybe

830
00:35:59,562 --> 00:36:01,176
its convergence properties wouldn't be

831
00:36:01,198 --> 00:36:02,728
as guaranteed. I don't know what it

832
00:36:02,734 --> 00:36:03,924
looks because you're introducing weird

833
00:36:03,972 --> 00:36:07,736
loops in your graph, but in the

834
00:36:07,758 --> 00:36:08,888
factory graph that represents the

835
00:36:08,894 --> 00:36:10,872
generative model. But that's something

836
00:36:10,926 --> 00:36:13,948
in theory could be entertained. But I

837
00:36:13,954 --> 00:36:15,116
don't know if that's actually what you

838
00:36:15,138 --> 00:36:16,684
had in mind. Maybe you had more in mind

839
00:36:16,722 --> 00:36:18,508
of breaking the Markov property when you

840
00:36:18,514 --> 00:36:22,110
say conditioning on. Yeah,

841
00:36:24,100 --> 00:36:25,648
thank you for the answer. It was more of

842
00:36:25,654 --> 00:36:28,044
a clarification also on the mathematical

843
00:36:28,092 --> 00:36:32,476
notation because pi

844
00:36:32,668 --> 00:36:35,584
is interpreted as policy, which I guess

845
00:36:35,622 --> 00:36:38,084
can mean both individual actions and

846
00:36:38,122 --> 00:36:40,180
sequences of actions.

847
00:36:41,080 --> 00:36:44,004
So just wanted to clarify that. Yeah,

848
00:36:44,042 --> 00:36:46,064
that's a good point. So when I said pi

849
00:36:46,112 --> 00:36:46,870
up here,

850
00:36:53,580 --> 00:36:56,936
if pi was a sequence of ActInf lab.

851
00:36:56,958 --> 00:36:58,836
Any given time, the B matrix that you're

852
00:36:58,868 --> 00:37:02,024
indexing out is conditioned on the

853
00:37:02,062 --> 00:37:04,716
action that's entailed by the policy at

854
00:37:04,738 --> 00:37:06,936
that particular time. But the B matrix

855
00:37:06,968 --> 00:37:09,484
will never be entailed on what's going

856
00:37:09,522 --> 00:37:12,332
on in the full policy. But just by okay,

857
00:37:12,466 --> 00:37:14,896
at time T, I take out this slice of the

858
00:37:14,918 --> 00:37:17,456
B matrix because at time T, this is the

859
00:37:17,478 --> 00:37:19,296
action entailed by this policy of

860
00:37:19,318 --> 00:37:22,480
sequence length h or something. But

861
00:37:22,550 --> 00:37:25,088
yeah, that's a good point. So in a

862
00:37:25,094 --> 00:37:27,424
trivial case, policy length is one and

863
00:37:27,462 --> 00:37:30,500
it's just one action that's the policy

864
00:37:30,570 --> 00:37:32,420
is just an action that comes down to

865
00:37:32,490 --> 00:37:34,100
slice out the B matrix.

866
00:37:35,880 --> 00:37:38,788
Thanks yakub adam, anything you like to

867
00:37:38,794 --> 00:37:40,856
add? Go for it. 

868
00:37:40,878 --> 00:37:42,584
ADAM GOLDSTEIN: Yeah, a couple of follow ups. Thank you for this very clear

869
00:37:42,622 --> 00:37:45,576
presentation, Conor. So first, just to

870
00:37:45,598 --> 00:37:48,344
follow on what Yakup just asked, it

871
00:37:48,382 --> 00:37:50,456
seems like another potential way if you

872
00:37:50,478 --> 00:37:52,510
wanted to do this sort of two times step

873
00:37:53,360 --> 00:37:56,556
model would be to actually condense or

874
00:37:56,658 --> 00:37:58,904
kind of permute those two time steps

875
00:37:58,952 --> 00:38:02,456
into a single variable.

876
00:38:02,648 --> 00:38:05,952
The same way that you could condense the

877
00:38:06,006 --> 00:38:08,272
row and column into a single nine

878
00:38:08,326 --> 00:38:11,536
dimension nine row vector, or you can

879
00:38:11,558 --> 00:38:13,296
break it down into two. Could you

880
00:38:13,318 --> 00:38:15,788
similarly Brea down the last two moves

881
00:38:15,804 --> 00:38:17,636
and sort of combine them into a

882
00:38:17,658 --> 00:38:19,556
permutation of all possibilities of the

883
00:38:19,578 --> 00:38:21,780
last two moves and have those be the

884
00:38:21,930 --> 00:38:25,236
hidden states? Yeah, you could do that

885
00:38:25,258 --> 00:38:27,432
as well. I haven't seen that actually

886
00:38:27,486 --> 00:38:29,624
done in practice. The only thing is

887
00:38:29,662 --> 00:38:31,640
you'd actually have to somehow change

888
00:38:31,710 --> 00:38:38,404
the scheduling,

889
00:38:38,452 --> 00:38:40,456
I guess, of the message passing and the

890
00:38:40,478 --> 00:38:42,490
action to accommodate the fact that

891
00:38:42,860 --> 00:38:44,904
before I determine what my last hidden

892
00:38:44,952 --> 00:38:47,644
state was, I need to wait two. Time

893
00:38:47,682 --> 00:38:49,896
steps so I can get not only the proximal

894
00:38:49,928 --> 00:38:51,944
action I did, but also have this memory

895
00:38:51,992 --> 00:38:55,008
of the action two time steps ago. Yeah,

896
00:38:55,014 --> 00:38:56,352
I was imagining that you'd have some

897
00:38:56,406 --> 00:39:00,096
special case for the first move where

898
00:39:00,118 --> 00:39:03,040
it's like undefined and then the last

899
00:39:03,110 --> 00:39:04,896
move, then after that you'd have the

900
00:39:04,918 --> 00:39:07,428
last two moves, a separate matrix for

901
00:39:07,434 --> 00:39:10,164
those or something. Yeah, like a moving

902
00:39:10,202 --> 00:39:11,750
window kind of so it's always

903
00:39:12,120 --> 00:39:14,340
remembering the last. Yeah, I could see

904
00:39:14,410 --> 00:39:18,128
that working. I think kind of

905
00:39:18,154 --> 00:39:21,544
the canonical active inference answer to

906
00:39:21,582 --> 00:39:23,816
that is instead of having to kind of

907
00:39:23,838 --> 00:39:26,184
manufacture this special way of

908
00:39:26,222 --> 00:39:28,596
basically baking memory into a Markovian

909
00:39:28,628 --> 00:39:30,876
system, the classical way to handle that

910
00:39:30,898 --> 00:39:32,460
is just to build a hierarchical model.

911
00:39:32,530 --> 00:39:34,504
Because the hierarchical model handles

912
00:39:34,552 --> 00:39:40,680
that memory easily by just having nested

913
00:39:40,840 --> 00:39:44,236
Markovian processes where if you were to

914
00:39:44,258 --> 00:39:46,016
look at a single process, it looks like

915
00:39:46,038 --> 00:39:47,792
it has memory, but that's just because

916
00:39:47,846 --> 00:39:50,160
its priors for its own Markovian process

917
00:39:50,310 --> 00:39:52,768
are evolving as a function of another

918
00:39:52,854 --> 00:39:54,524
palm DP that's operating at a slower

919
00:39:54,572 --> 00:39:58,160
timescale. So I could imagine doing that

920
00:39:58,310 --> 00:40:00,036
exact thing that you're talking about if

921
00:40:00,058 --> 00:40:02,996
you had a low level palm DP that was

922
00:40:03,018 --> 00:40:04,884
moving twice as fast as the top level

923
00:40:04,922 --> 00:40:06,756
palm DP. And so basically, what the top

924
00:40:06,778 --> 00:40:08,904
level palm DP is doing is setting an

925
00:40:08,942 --> 00:40:11,576
initial prior over one action that then

926
00:40:11,598 --> 00:40:14,184
allows this low level palm DP to

927
00:40:14,222 --> 00:40:17,736
condition whatever it does next on a

928
00:40:17,758 --> 00:40:19,656
belief that whatever I do next. I know

929
00:40:19,678 --> 00:40:22,876
that I just took this action two time

930
00:40:22,898 --> 00:40:24,636
steps ago, but you don't actually have

931
00:40:24,658 --> 00:40:26,670
to handcraft that. It's just by building

932
00:40:27,600 --> 00:40:30,216
one palm DP, like, within another palm

933
00:40:30,248 --> 00:40:32,796
DP. But I don't see that there's

934
00:40:32,828 --> 00:40:35,056
anything in principle going against what

935
00:40:35,078 --> 00:40:36,850
you're describing as well.

936
00:40:38,020 --> 00:40:39,730
I like your approach a lot better.

937
00:40:40,340 --> 00:40:43,744
Yeah. Essentially what I learned from

938
00:40:43,782 --> 00:40:45,804
working with Karl was that anytime

939
00:40:45,852 --> 00:40:47,844
you're trying to imbue a system with

940
00:40:47,962 --> 00:40:50,884
more complex non Markovian memory, full

941
00:40:50,922 --> 00:40:53,904
dynamics or higher order dependencies,

942
00:40:53,952 --> 00:40:56,068
that's when it's the natural move, is to

943
00:40:56,074 --> 00:40:58,696
go to a hierarchical model because it

944
00:40:58,718 --> 00:41:00,520
kind of handles it all naturally.

945
00:41:02,060 --> 00:41:06,424
So my next question is about what

946
00:41:06,462 --> 00:41:07,784
you were sort of tweaking in that

947
00:41:07,822 --> 00:41:09,512
formula just a couple of minutes ago,

948
00:41:09,566 --> 00:41:11,436
where you were suggesting the

949
00:41:11,458 --> 00:41:12,904
possibility that there could be feedback

950
00:41:12,952 --> 00:41:15,804
loops between the hidden states. In

951
00:41:15,842 --> 00:41:19,256
theory, but as currently implemented,

952
00:41:19,288 --> 00:41:21,756
if I understood correctly, that's not

953
00:41:21,778 --> 00:41:23,976
the case. The state of one of the hidden

954
00:41:24,008 --> 00:41:26,768
variables or the state of one of the

955
00:41:26,774 --> 00:41:29,170
hidden states depends only on.

956
00:41:30,980 --> 00:41:32,720
The. Previous state of that hidden state

957
00:41:32,790 --> 00:41:36,336
as currently hidden factor.

958
00:41:36,368 --> 00:41:38,036
What I want to make sure I understand is

959
00:41:38,058 --> 00:41:42,470
that is that also something about

960
00:41:43,160 --> 00:41:45,156
the Markovian assumption, or is that

961
00:41:45,178 --> 00:41:46,820
just sort of an implementation or design

962
00:41:46,890 --> 00:41:49,976
decision completely separate from the

963
00:41:49,998 --> 00:41:53,704
Markov? Yeah, that's a good

964
00:41:53,742 --> 00:41:54,888
question. That's separate from the

965
00:41:54,894 --> 00:41:58,036
Markov separate from the Markovian

966
00:41:58,068 --> 00:41:59,784
assumption. So that's something having

967
00:41:59,822 --> 00:42:02,168
to do with kind of just how the graph

968
00:42:02,264 --> 00:42:03,932
that represents the generative model,

969
00:42:03,986 --> 00:42:05,068
which you could think of as like a

970
00:42:05,074 --> 00:42:07,256
Bayesian graph, like a bunch of nodes

971
00:42:07,448 --> 00:42:11,420
that affect a layer of observations.

972
00:42:12,020 --> 00:42:13,744
So you say a bunch of hidden states

973
00:42:13,782 --> 00:42:18,176
nodes, that all

974
00:42:18,198 --> 00:42:19,932
the observation nodes conditionally

975
00:42:19,996 --> 00:42:21,916
depend on the state of all the hidden

976
00:42:21,948 --> 00:42:24,576
states factor nodes. By constructing it

977
00:42:24,598 --> 00:42:26,464
this way, you basically have a graph

978
00:42:26,512 --> 00:42:29,188
that it's very easy to do coherence on

979
00:42:29,274 --> 00:42:31,764
that has like, stationary fixed points,

980
00:42:31,802 --> 00:42:34,340
so the inference does not depend on

981
00:42:34,410 --> 00:42:36,816
individual conditions of the posteriors

982
00:42:36,848 --> 00:42:37,910
and things like that.

983
00:42:41,160 --> 00:42:42,856
The way the generative model is set up

984
00:42:42,878 --> 00:42:45,064
right now is like a bipartite graph that

985
00:42:45,102 --> 00:42:49,992
resembles a classic model

986
00:42:50,046 --> 00:42:51,116
for machine learning called like a

987
00:42:51,138 --> 00:42:53,116
restricted Bellman machine. So this is

988
00:42:53,138 --> 00:42:55,404
where all the hidden states can all

989
00:42:55,442 --> 00:42:59,064
affect one observation modality,

990
00:42:59,192 --> 00:43:01,244
but there's no interactions between the

991
00:43:01,282 --> 00:43:04,308
observation layers, so there's no lines

992
00:43:04,344 --> 00:43:06,064
going between observations within one

993
00:43:06,102 --> 00:43:08,188
modality, and there's also no lines

994
00:43:08,204 --> 00:43:10,624
going between hidden state factors. So

995
00:43:10,742 --> 00:43:13,696
that's kind of one of the advantages of

996
00:43:13,718 --> 00:43:15,488
this assumption, is when you have the

997
00:43:15,494 --> 00:43:17,936
hidden state factors be only dependent

998
00:43:17,968 --> 00:43:20,084
on their own past state and their own

999
00:43:20,122 --> 00:43:22,816
past action within that control factor,

1000
00:43:22,928 --> 00:43:24,848
then you're not introducing these loops

1001
00:43:24,864 --> 00:43:26,868
in the graph that make inference a

1002
00:43:26,874 --> 00:43:28,872
little bit harder. So you'll see this

1003
00:43:28,926 --> 00:43:31,096
structure when people are using like

1004
00:43:31,118 --> 00:43:33,096
restricted Bellman machines or other or

1005
00:43:33,118 --> 00:43:34,664
even deep neural networks, it's very

1006
00:43:34,702 --> 00:43:38,280
hard to get fixed point solutions for

1007
00:43:38,350 --> 00:43:40,984
the posteriors when you have

1008
00:43:41,022 --> 00:43:43,052
interactions between nodes in a single

1009
00:43:43,106 --> 00:43:45,564
layer. So it's not quite the same thing

1010
00:43:45,602 --> 00:43:48,988
as yeah, it's just not the same thing as

1011
00:43:49,154 --> 00:43:51,548
the Markov property has more having to

1012
00:43:51,554 --> 00:43:53,936
do with generating an acyclic graph so

1013
00:43:53,958 --> 00:43:57,036
you can do a fast, efficient and fixed

1014
00:43:57,068 --> 00:44:00,784
point coherence on it. That's my general

1015
00:44:00,982 --> 00:44:03,664
answer to that. Because if you actually

1016
00:44:03,702 --> 00:44:04,908
draw out the factor graph for these

1017
00:44:04,934 --> 00:44:08,116
things, it looks like that. But there

1018
00:44:08,138 --> 00:44:09,556
might be another reason this is done

1019
00:44:09,578 --> 00:44:12,404
that I'm actually not aware of. Maybe

1020
00:44:12,442 --> 00:44:16,340
that's something that Karl would know or

1021
00:44:16,410 --> 00:44:17,270
someone else.

1022
00:44:21,740 --> 00:44:23,764
If you want to add anything, Karl,

1023
00:44:23,812 --> 00:44:27,256
otherwise and then after this we'll head

1024
00:44:27,278 --> 00:44:29,336
into the script. Go for it, Karl. 

1025
00:44:29,358 --> 00:44:32,556
KARL FRISTON: Thank you. Yeah, I think everything that

1026
00:44:32,578 --> 00:44:34,172
needs to be said has already been said

1027
00:44:34,226 --> 00:44:37,212
very clearly and very usefully. But yes,

1028
00:44:37,346 --> 00:44:40,876
Conor, Heins absolutely right. So I

1029
00:44:40,898 --> 00:44:44,184
look at this in terms of the overall

1030
00:44:44,232 --> 00:44:46,396
architecture of the graphical model you

1031
00:44:46,418 --> 00:44:49,584
bring to the table and it can only have

1032
00:44:49,622 --> 00:44:51,504
a number of different attributes. How

1033
00:44:51,542 --> 00:44:53,456
deep is it? How many levels does it

1034
00:44:53,478 --> 00:44:56,032
have? We're not in this presentation

1035
00:44:56,096 --> 00:45:00,064
talking about deep MDP

1036
00:45:00,112 --> 00:45:02,100
or Joy to models based upon

1037
00:45:03,400 --> 00:45:06,816
hierarchically composed Markov

1038
00:45:06,848 --> 00:45:12,084
decision processes. But generally

1039
00:45:12,132 --> 00:45:14,456
you would think of any one level in the

1040
00:45:14,478 --> 00:45:16,664
context of the level above and the level

1041
00:45:16,702 --> 00:45:19,624
below, and that lends this attribute of

1042
00:45:19,662 --> 00:45:21,852
depth to any given generative model.

1043
00:45:21,986 --> 00:45:23,772
But probably more important, certainly

1044
00:45:23,826 --> 00:45:25,852
from the point of view of the current

1045
00:45:25,906 --> 00:45:28,844
discussion is the breadth. And the

1046
00:45:28,882 --> 00:45:30,540
breadth basically the number of

1047
00:45:30,610 --> 00:45:32,860
conditional independent factors.

1048
00:45:33,440 --> 00:45:35,109
In physics, this is simply known as the

1049
00:45:35,609 --> 00:45:38,016
mean field approximation. It's just a

1050
00:45:38,038 --> 00:45:40,156
factorization of a joint distribution.

1051
00:45:40,268 --> 00:45:43,584
In this instance, what we're aiming for

1052
00:45:43,622 --> 00:45:44,748
is an approximate post state

1053
00:45:44,774 --> 00:45:46,500
distribution. But it's a factorization

1054
00:45:46,840 --> 00:45:49,392
into conditionally independent factors

1055
00:45:49,536 --> 00:45:52,420
that incidentally, also induces certain

1056
00:45:52,490 --> 00:45:54,708
Markov blanket and resolves all of the

1057
00:45:54,714 --> 00:45:56,996
message passing and means that sort of

1058
00:45:57,018 --> 00:46:00,036
variational iterations are more robust.

1059
00:46:00,148 --> 00:46:03,784
But from the point of view of why do you

1060
00:46:03,822 --> 00:46:06,280
do that? Well, you do that because to

1061
00:46:06,430 --> 00:46:08,776
maximize the marginal likelihood of the

1062
00:46:08,798 --> 00:46:11,096
evidence for your generative model, you

1063
00:46:11,118 --> 00:46:13,356
have to carve the nature out there at

1064
00:46:13,378 --> 00:46:15,036
its joints in the right kind of way. So

1065
00:46:15,058 --> 00:46:17,384
if the world you're trying to navigate

1066
00:46:17,432 --> 00:46:20,748
or exchange with or explain does have

1067
00:46:20,834 --> 00:46:22,424
this factorization, these conditional

1068
00:46:22,472 --> 00:46:24,256
independences, it is carved in this way,

1069
00:46:24,278 --> 00:46:26,896
then your model has to comply in order

1070
00:46:26,918 --> 00:46:30,144
to have the maximum evidence. So when

1071
00:46:30,262 --> 00:46:32,220
learning that particular factorization

1072
00:46:32,300 --> 00:46:34,972
or that structure, you would normally

1073
00:46:35,036 --> 00:46:37,708
apply a process of basic model selection

1074
00:46:37,724 --> 00:46:39,124
or structure learning to get the number

1075
00:46:39,162 --> 00:46:41,444
of factors right, and that is getting

1076
00:46:41,482 --> 00:46:42,608
the right kind of meanwhile

1077
00:46:42,624 --> 00:46:46,164
approximation ant for this world and

1078
00:46:46,202 --> 00:46:48,368
these data. And the right factorization

1079
00:46:48,464 --> 00:46:50,000
will simply minimize the variation of

1080
00:46:50,010 --> 00:46:51,928
free energy and therefore minimize the

1081
00:46:51,934 --> 00:46:54,650
computational complexity and also the

1082
00:46:55,100 --> 00:46:57,528
computational complexity expressed in

1083
00:46:57,534 --> 00:46:59,496
terms of thermodynamics for example. So

1084
00:46:59,518 --> 00:47:01,548
it's a really important sort of thing.

1085
00:47:01,714 --> 00:47:04,824
Just a couple of little endorsement

1086
00:47:04,872 --> 00:47:05,580
comments.

1087
00:47:07,840 --> 00:47:11,164
Conditioning any one state with any one

1088
00:47:11,202 --> 00:47:12,952
factor on states and other factors

1089
00:47:13,016 --> 00:47:15,128
destroys that particular factorization.

1090
00:47:15,224 --> 00:47:16,608
So you don't have to worry about

1091
00:47:16,694 --> 00:47:18,988
introducing loops and things. All you're

1092
00:47:19,004 --> 00:47:20,272
doing is saying that particular

1093
00:47:20,326 --> 00:47:21,788
factorization has gone away, you've

1094
00:47:21,804 --> 00:47:23,596
coarse grained and you now have to lump

1095
00:47:23,628 --> 00:47:25,660
together all the elements of one factor

1096
00:47:25,740 --> 00:47:27,596
and the other factor into one bigger

1097
00:47:27,628 --> 00:47:29,356
factor. And now you've got a more coarse

1098
00:47:29,388 --> 00:47:32,150
grained factorization and a more

1099
00:47:32,760 --> 00:47:35,284
mathematically complex model because you

1100
00:47:35,322 --> 00:47:40,216
haven't done as many carvings to

1101
00:47:40,318 --> 00:47:42,132
leverage the conditional independences

1102
00:47:42,196 --> 00:47:45,576
that you're trying to model. And the

1103
00:47:45,598 --> 00:47:47,416
first question about the policies, that

1104
00:47:47,438 --> 00:47:49,336
was an interesting one, and I suspect it

1105
00:47:49,358 --> 00:47:53,116
may be an artifact of the way that we

1106
00:47:53,218 --> 00:47:55,596
condition everything on pie without sort

1107
00:47:55,618 --> 00:47:57,724
of forewarning people. Pi is actually

1108
00:47:57,762 --> 00:48:00,828
quite a complicated variable. First of

1109
00:48:00,834 --> 00:48:05,024
all, it's basically an index or a name

1110
00:48:05,142 --> 00:48:07,536
for quite a complicated combination of

1111
00:48:07,558 --> 00:48:10,610
things. So not only is it a sequence of

1112
00:48:11,380 --> 00:48:14,748
actions upon which you condition

1113
00:48:14,844 --> 00:48:17,284
each individual transition at any point

1114
00:48:17,322 --> 00:48:19,936
in time, over time, so it's a sequence

1115
00:48:19,968 --> 00:48:21,968
of action. So in answer to Yakub's

1116
00:48:21,984 --> 00:48:24,516
question, the whole point of the

1117
00:48:24,538 --> 00:48:27,108
expenditure energy is exploring lots and

1118
00:48:27,114 --> 00:48:28,628
lots of different sequences as you roll

1119
00:48:28,644 --> 00:48:29,770
out into the future,

1120
00:48:31,740 --> 00:48:35,220
but also induced by the factorization.

1121
00:48:35,380 --> 00:48:36,810
As Conor was saying,

1122
00:48:38,700 --> 00:48:42,524
that pie actually has to now entail an

1123
00:48:42,562 --> 00:48:46,108
action for every factor of a

1124
00:48:46,114 --> 00:48:49,196
fixed combination. So if you change the

1125
00:48:49,218 --> 00:48:51,032
combination of action, the two factors,

1126
00:48:51,096 --> 00:48:52,736
you now have a different policy even at

1127
00:48:52,758 --> 00:48:54,848
one time step, even for one step ahead.

1128
00:48:54,934 --> 00:48:57,168
So the notion of a policy as a

1129
00:48:57,254 --> 00:49:01,120
combination of actions is still in play

1130
00:49:01,270 --> 00:49:04,252
when you have a factorized.

1131
00:49:04,316 --> 00:49:06,316
Meanwhile, approximation of the hidden

1132
00:49:06,348 --> 00:49:09,760
states, it's a subtle point,

1133
00:49:09,910 --> 00:49:12,020
usually would resolve it by actually

1134
00:49:12,090 --> 00:49:14,756
explicitly writing down, using the

1135
00:49:14,778 --> 00:49:16,496
variable U, the thing that you're

1136
00:49:16,528 --> 00:49:18,404
conditioning the state transitions on.

1137
00:49:18,522 --> 00:49:21,656
And then U comes from

1138
00:49:21,678 --> 00:49:24,184
a family of combinations of use over

1139
00:49:24,222 --> 00:49:26,856
factors and over time. So you can have

1140
00:49:26,878 --> 00:49:28,228
deep and shallow policies, but you've

1141
00:49:28,244 --> 00:49:30,392
got very shallow policies one step ahead

1142
00:49:30,446 --> 00:49:32,344
and one look ahead policies. There's

1143
00:49:32,392 --> 00:49:35,564
still a subset of communication of

1144
00:49:35,602 --> 00:49:37,628
actions. So it could be that you can

1145
00:49:37,714 --> 00:49:41,756
either only move up or down

1146
00:49:41,938 --> 00:49:44,104
sorry, up or to the left, but you can't

1147
00:49:44,152 --> 00:49:47,536
move diagonally, for example, and that

1148
00:49:47,558 --> 00:49:50,480
will be placed in terms of priors over

1149
00:49:50,550 --> 00:49:54,320
pi, namely combinations of actions.

1150
00:49:56,420 --> 00:49:59,536
So one final, just for Adam's benefit,

1151
00:49:59,648 --> 00:50:03,060
that notion of putting

1152
00:50:03,130 --> 00:50:05,424
semimarkovian dynamics and Collins

1153
00:50:05,472 --> 00:50:06,550
absolutely right.

1154
00:50:09,800 --> 00:50:11,704
As a physicist, the way you do that is

1155
00:50:11,742 --> 00:50:13,608
by appealing to the depth of the

1156
00:50:13,614 --> 00:50:15,444
hierarchical model, which always entails

1157
00:50:15,492 --> 00:50:17,764
time. And that's an absolutely crucial

1158
00:50:17,812 --> 00:50:20,296
observation. There's no point in adding

1159
00:50:20,328 --> 00:50:23,372
depth to a generative model unless you

1160
00:50:23,426 --> 00:50:25,468
are mindful it is introducing a

1161
00:50:25,474 --> 00:50:28,284
separation temporal time skills. I think

1162
00:50:28,402 --> 00:50:31,944
that's a profound sort of structural

1163
00:50:31,992 --> 00:50:33,556
insight into the nature of generative

1164
00:50:33,608 --> 00:50:34,688
models and has all sorts of

1165
00:50:34,694 --> 00:50:37,984
implications. But then you're just

1166
00:50:38,022 --> 00:50:39,584
speaking to this notion of having

1167
00:50:39,622 --> 00:50:41,536
combinations or little histories or

1168
00:50:41,558 --> 00:50:45,500
little caches of legacy states as

1169
00:50:45,590 --> 00:50:48,176
if you like a superstate. Strictly

1170
00:50:48,208 --> 00:50:50,708
speaking, that is exactly what is done

1171
00:50:50,794 --> 00:50:52,852
effectively in continuous state space

1172
00:50:52,906 --> 00:50:55,044
model with Kalman filters. So you

1173
00:50:55,082 --> 00:50:57,556
actually have now two kinds of random

1174
00:50:57,588 --> 00:51:00,132
variables the position and the velocity.

1175
00:51:00,276 --> 00:51:02,516
So you've now got a sort of dual

1176
00:51:02,548 --> 00:51:04,484
representation. And if you generalize

1177
00:51:04,532 --> 00:51:05,876
that, you get to generalize quantum

1178
00:51:05,908 --> 00:51:10,280
motion. And technically

1179
00:51:11,100 --> 00:51:12,552
when you're doing variational message

1180
00:51:12,606 --> 00:51:13,996
passing, you now use something called a

1181
00:51:14,018 --> 00:51:15,996
chef, a free energy as opposed to which

1182
00:51:16,018 --> 00:51:18,190
is a variant of variation free energy.

1183
00:51:19,120 --> 00:51:20,924
However, when you move to discrete state

1184
00:51:20,962 --> 00:51:22,764
spaces, those generalized coordinates

1185
00:51:22,812 --> 00:51:25,410
now actually are replaced just by having

1186
00:51:26,100 --> 00:51:30,416
states that unfold in time over the

1187
00:51:30,438 --> 00:51:32,928
probability transition matrix. So that

1188
00:51:33,014 --> 00:51:34,988
you shouldn't in principle ever need to

1189
00:51:35,014 --> 00:51:37,716
do that. But you can now regard the

1190
00:51:37,738 --> 00:51:40,096
little local history, the little packet

1191
00:51:40,128 --> 00:51:43,248
or trajectory orbit the path that you're

1192
00:51:43,264 --> 00:51:45,376
taking at this point at this temporal

1193
00:51:45,408 --> 00:51:49,568
scale as sufficiently discrete and Clark

1194
00:51:49,584 --> 00:51:51,300
brain with the different probability

1195
00:51:51,380 --> 00:51:53,496
transition Atreides and then at the

1196
00:51:53,518 --> 00:51:54,808
slower tank scale, then it's a

1197
00:51:54,814 --> 00:51:56,884
succession of initial states. That's

1198
00:51:56,932 --> 00:51:58,584
normally how we would think about that,

1199
00:51:58,622 --> 00:52:01,324
but it's an interesting game to think

1200
00:52:01,362 --> 00:52:04,188
about Hohwy what kinds of structures in

1201
00:52:04,194 --> 00:52:07,320
these discrete states based models echo

1202
00:52:07,480 --> 00:52:09,852
the equivalent moves would have to make

1203
00:52:09,906 --> 00:52:13,276
in continuous state space modeling and

1204
00:52:13,298 --> 00:52:14,620
thinking here, particularly of

1205
00:52:14,690 --> 00:52:16,184
generalized filtering and Bayesian

1206
00:52:16,232 --> 00:52:18,448
smoothing and basic filtering and the

1207
00:52:18,454 --> 00:52:19,010
like.

1208
00:52:22,340 --> 00:52:24,496
Yeah, thank you. It's really nice to

1209
00:52:24,518 --> 00:52:27,092
have those afterthought because that

1210
00:52:27,146 --> 00:52:29,044
clarifies, I think, and justifies a lot

1211
00:52:29,082 --> 00:52:31,924
of the preceding slides, what Karl just

1212
00:52:31,962 --> 00:52:34,710
said. Yeah.

1213
00:52:35,640 --> 00:52:37,588
So you can kind of map the depths of the

1214
00:52:37,594 --> 00:52:39,748
hierarchy. Think of the depths of the

1215
00:52:39,754 --> 00:52:42,744
hierarchy as a discretion of what is

1216
00:52:42,782 --> 00:52:44,324
smoothly handled with generalized

1217
00:52:44,372 --> 00:52:45,928
filtering and generalized coordinates of

1218
00:52:45,934 --> 00:52:49,508
motion. So states evolving at this palm

1219
00:52:49,524 --> 00:52:52,212
DP are kind of like a quasi velocity

1220
00:52:52,276 --> 00:52:55,112
variable because they are evolving

1221
00:52:55,176 --> 00:52:57,304
slower than the position variable,

1222
00:52:57,432 --> 00:53:00,024
which is like the low level, quicker

1223
00:53:00,072 --> 00:53:03,712
clock palm DP. One just

1224
00:53:03,766 --> 00:53:07,008
tiny footnote there is it relates to the

1225
00:53:07,094 --> 00:53:10,000
continuum and differentiable free energy

1226
00:53:10,070 --> 00:53:13,232
landscape and the inclination that is

1227
00:53:13,286 --> 00:53:16,060
required on Modern digital hardware

1228
00:53:16,220 --> 00:53:19,160
around sampling and the inclination

1229
00:53:19,340 --> 00:53:22,880
problem on a continuous

1230
00:53:22,960 --> 00:53:26,676
but hidden function and the

1231
00:53:26,698 --> 00:53:28,136
approaches that we have to take to

1232
00:53:28,158 --> 00:53:31,400
discretize the continuous nature of time

1233
00:53:31,470 --> 00:53:32,090
especially.

1234
00:53:39,180 --> 00:53:43,372
Okay, so I

1235
00:53:43,426 --> 00:53:46,248
think we should proceed to the multi

1236
00:53:46,264 --> 00:53:49,388
armed bandit. Okay.

1237
00:53:49,474 --> 00:53:52,716
So now, having discussed these kind of

1238
00:53:52,738 --> 00:53:54,268
factorized representations, we're in a

1239
00:53:54,274 --> 00:53:56,628
position to build our multi factor

1240
00:53:56,664 --> 00:53:58,736
generative model for what I'm calling a

1241
00:53:58,758 --> 00:54:00,384
contextual two armed bandit or

1242
00:54:00,422 --> 00:54:02,528
contextual multi armed bandit. This is

1243
00:54:02,614 --> 00:54:05,204
coming from the reinforcement learning

1244
00:54:05,242 --> 00:54:07,488
literature. This term counterfactuals,

1245
00:54:07,664 --> 00:54:11,524
but it's based directly on a kind of

1246
00:54:11,562 --> 00:54:15,108
gambling task that was introduced in

1247
00:54:15,194 --> 00:54:17,904
Ryan Smith, Christopher White, Carls

1248
00:54:17,952 --> 00:54:20,296
Friston's, step by step tutorial and

1249
00:54:20,318 --> 00:54:22,008
active inference. So you basically have

1250
00:54:22,014 --> 00:54:23,928
a multi arm bandit, two arm bandit. But

1251
00:54:23,934 --> 00:54:27,130
you have to first find a clue or

1252
00:54:27,660 --> 00:54:29,864
forage information to figure out which

1253
00:54:29,902 --> 00:54:32,980
of the two slot machines or arms of the

1254
00:54:32,990 --> 00:54:35,484
bandit is more favorable. And this is

1255
00:54:35,522 --> 00:54:37,576
echoed as well in the original T Maze

1256
00:54:37,608 --> 00:54:39,996
example where you have a rat that has to

1257
00:54:40,018 --> 00:54:42,444
choose between two arms. One is more

1258
00:54:42,482 --> 00:54:43,896
rewarding than the other, but you don't

1259
00:54:43,928 --> 00:54:45,388
know which one is rewarding. So you have

1260
00:54:45,394 --> 00:54:48,512
to visit an informative Q state first

1261
00:54:48,566 --> 00:54:50,796
that tells you the left one is rewarding

1262
00:54:50,828 --> 00:54:52,364
right now or the right one is rewarding.

1263
00:54:52,412 --> 00:54:55,124
So I'm just kind of gathering all these

1264
00:54:55,162 --> 00:54:57,184
things into the term contextual bandit

1265
00:54:57,232 --> 00:54:59,540
because that's kind of the analogous

1266
00:55:00,280 --> 00:55:02,036
term for this problem that you'll find

1267
00:55:02,058 --> 00:55:03,750
in reinforcement learning world.

1268
00:55:05,160 --> 00:55:05,910
Okay,

1269
00:55:07,800 --> 00:55:10,768
so in the multi arm bandit or two armed

1270
00:55:10,784 --> 00:55:12,576
bandit task, an agent has to play,

1271
00:55:12,698 --> 00:55:14,836
choose to play one of two slot machines

1272
00:55:14,948 --> 00:55:16,696
and they can only play one at a time.

1273
00:55:16,798 --> 00:55:18,584
So one of the slot machines gives more

1274
00:55:18,622 --> 00:55:20,120
reward than the other, but the agent

1275
00:55:20,190 --> 00:55:21,928
doesn't know which is the better one.

1276
00:55:22,014 --> 00:55:23,736
So Anthony G. Chen time the agent can

1277
00:55:23,758 --> 00:55:25,324
choose to play the left or the right

1278
00:55:25,362 --> 00:55:27,036
machine. That's what we'll call them.

1279
00:55:27,218 --> 00:55:30,428
Or it can choose to ask for a hint. And

1280
00:55:30,514 --> 00:55:32,472
if it chooses to ask for a hint,

1281
00:55:32,536 --> 00:55:33,916
instead of playing the machine, it

1282
00:55:33,938 --> 00:55:36,048
receives information about which of the

1283
00:55:36,054 --> 00:55:38,864
two slot machines is better. So this

1284
00:55:38,902 --> 00:55:40,832
already sets up the basic dilemma of

1285
00:55:40,886 --> 00:55:42,988
tasks like this, the so called Explore

1286
00:55:43,004 --> 00:55:45,616
explore dilemma. So you first forage for

1287
00:55:45,638 --> 00:55:47,476
information that will ultimately lead to

1288
00:55:47,498 --> 00:55:49,536
getting more reward or do you gamble

1289
00:55:49,568 --> 00:55:51,952
immediately in order to get reward

1290
00:55:52,016 --> 00:55:53,764
sooner, but at the risk of not having

1291
00:55:53,802 --> 00:55:57,856
enough information to know which slot

1292
00:55:57,888 --> 00:56:00,264
machine I should actually play. So to

1293
00:56:00,302 --> 00:56:02,488
encode this task structure into a

1294
00:56:02,494 --> 00:56:04,584
generative models for a Palm DP, we

1295
00:56:04,622 --> 00:56:07,124
equip the agent with three observation

1296
00:56:07,172 --> 00:56:09,044
modalities. First, we have this hint

1297
00:56:09,092 --> 00:56:11,560
modality which is the sensory channel

1298
00:56:11,630 --> 00:56:14,076
the agent uses to perceive the hint. So

1299
00:56:14,098 --> 00:56:15,800
just what is the state of the hint?

1300
00:56:15,960 --> 00:56:18,364
Then there's a reward modality which

1301
00:56:18,402 --> 00:56:20,344
tells the agent whether it won or lost

1302
00:56:20,392 --> 00:56:22,376
at the selected machine. And then

1303
00:56:22,418 --> 00:56:24,416
finally there's a choice modality which

1304
00:56:24,438 --> 00:56:27,244
is just the agent's proprioceptive

1305
00:56:27,292 --> 00:56:30,016
conversation of its own choice. This is

1306
00:56:30,038 --> 00:56:32,736
equivalent to the GPS modality that we

1307
00:56:32,758 --> 00:56:35,616
were working with in gridworld. In terms

1308
00:56:35,638 --> 00:56:37,716
of hidden state factors, we first have a

1309
00:56:37,738 --> 00:56:39,584
context factor which is a binary

1310
00:56:39,632 --> 00:56:41,796
variable encoding which slot machine is

1311
00:56:41,818 --> 00:56:45,012
the more rewarding one. Either the left

1312
00:56:45,066 --> 00:56:46,608
machine is better or the right machine

1313
00:56:46,624 --> 00:56:48,228
is better. So those are the names of the

1314
00:56:48,234 --> 00:56:50,660
two context variables. You could just

1315
00:56:50,730 --> 00:56:52,792
arbitrary enable them like context A,

1316
00:56:52,846 --> 00:56:54,856
context B or something like that. And

1317
00:56:54,878 --> 00:56:56,264
then we have a choice hidden state

1318
00:56:56,302 --> 00:56:58,056
factor which is simply encoding the

1319
00:56:58,078 --> 00:56:59,908
choice state that the agent currently

1320
00:57:00,014 --> 00:57:04,044
occupies. And finally, as Karl was just

1321
00:57:04,082 --> 00:57:06,284
explaining, for each hidden state

1322
00:57:06,322 --> 00:57:08,344
factor, you also have a control factor.

1323
00:57:08,472 --> 00:57:11,512
So we'll have a context control factor,

1324
00:57:11,656 --> 00:57:13,616
which as we'll see, is trivial since the

1325
00:57:13,638 --> 00:57:16,720
agent can't control the context in this

1326
00:57:16,790 --> 00:57:20,124
particular simulation and a choice

1327
00:57:20,172 --> 00:57:22,032
control factor which is the control

1328
00:57:22,086 --> 00:57:23,632
factor that allows the agent to model

1329
00:57:23,686 --> 00:57:26,300
its own actions or choices.

1330
00:57:26,460 --> 00:57:29,584
So even for a shallow policy horizon,

1331
00:57:29,632 --> 00:57:32,676
as Karl was explaining, a policy will

1332
00:57:32,698 --> 00:57:35,124
still be comprised of two actions. So

1333
00:57:35,242 --> 00:57:36,836
there'll be a context action and a

1334
00:57:36,858 --> 00:57:39,284
choice action. But as we'll see, the

1335
00:57:39,322 --> 00:57:41,304
context action will always be to do

1336
00:57:41,342 --> 00:57:43,096
nothing or basically to not be able to

1337
00:57:43,118 --> 00:57:45,444
interfere in the dynamics of the context

1338
00:57:45,492 --> 00:57:47,160
hidden state factors. So basically

1339
00:57:47,310 --> 00:57:49,672
action selection comes down to just

1340
00:57:49,726 --> 00:57:52,100
choosing the state of the choice control

1341
00:57:52,190 --> 00:57:55,516
factor that you choice variable. So now

1342
00:57:55,538 --> 00:57:56,492
we're going to look at the different

1343
00:57:56,546 --> 00:57:59,980
levels of the hidden states factors. So

1344
00:58:00,050 --> 00:58:02,620
as we said, the context one is a binary

1345
00:58:03,040 --> 00:58:04,508
or you could think of it as like a

1346
00:58:04,514 --> 00:58:06,512
Bernoulli variable. So it's either left

1347
00:58:06,566 --> 00:58:08,016
better, right better, it's a

1348
00:58:08,038 --> 00:58:10,288
distribution over these two states of

1349
00:58:10,294 --> 00:58:12,336
the context and this is just the

1350
00:58:12,358 --> 00:58:13,936
unchanging state of the world for a

1351
00:58:13,958 --> 00:58:15,724
particular trial. Either left machine

1352
00:58:15,772 --> 00:58:17,936
has a better payoff probability or the

1353
00:58:17,958 --> 00:58:19,984
right one does. And then the choice

1354
00:58:20,032 --> 00:58:21,696
hidden state factor has four levels

1355
00:58:21,728 --> 00:58:23,220
which correspond to the four possible

1356
00:58:23,290 --> 00:58:25,156
choice states that the agent can be in.

1357
00:58:25,258 --> 00:58:26,784
So this can either be the neutral

1358
00:58:26,832 --> 00:58:29,796
starting location, the hint state which

1359
00:58:29,818 --> 00:58:32,868
is the location they occupy when they're

1360
00:58:32,884 --> 00:58:35,688
acquiring the hint, or they can be

1361
00:58:35,694 --> 00:58:37,256
playing the left machine or they can be

1362
00:58:37,278 --> 00:58:39,096
playing the right machine. And so now

1363
00:58:39,118 --> 00:58:42,024
for the control state factors. The

1364
00:58:42,062 --> 00:58:43,616
control state factor for the context

1365
00:58:43,668 --> 00:58:46,076
only has one level. You can call it do

1366
00:58:46,098 --> 00:58:48,044
nothing or it's just a trivial one

1367
00:58:48,082 --> 00:58:50,444
dimensional variable and the agent will

1368
00:58:50,482 --> 00:58:52,124
always take this action with 100%

1369
00:58:52,162 --> 00:58:54,576
probability. So in other words, the

1370
00:58:54,598 --> 00:58:57,488
agent has no control over the state of

1371
00:58:57,494 --> 00:58:59,680
the context and then the choice control

1372
00:58:59,750 --> 00:59:01,728
state has four levels corresponding to

1373
00:59:01,734 --> 00:59:06,140
the decision to change the S choice.

1374
00:59:06,220 --> 00:59:08,352
The hidden states factor for the choice

1375
00:59:08,416 --> 00:59:10,932
state in one of four different ways.

1376
00:59:10,986 --> 00:59:12,772
Either it can move to the start

1377
00:59:12,826 --> 00:59:14,784
location, it can move to the hint

1378
00:59:14,832 --> 00:59:17,136
location, it can play the left machine

1379
00:59:17,168 --> 00:59:19,064
or it can play the right machine. So

1380
00:59:19,102 --> 00:59:21,640
what choice state the agent is in is

1381
00:59:21,710 --> 00:59:23,396
kind of obviously under the agent's

1382
00:59:23,428 --> 00:59:26,136
control which is encoded by the fact

1383
00:59:26,158 --> 00:59:27,992
that this u choice variable has four

1384
00:59:28,046 --> 00:59:31,544
levels. So optimizing a posterior

1385
00:59:31,592 --> 00:59:35,180
distribution over this choice control

1386
00:59:35,250 --> 00:59:37,864
state factor, that's what action

1387
00:59:37,912 --> 00:59:39,916
selection and planning boils down to is

1388
00:59:39,938 --> 00:59:42,156
basically choosing what level of you

1389
00:59:42,178 --> 00:59:45,324
choice or inferring what the

1390
00:59:45,362 --> 00:59:47,344
distribution over you choices and then

1391
00:59:47,382 --> 00:59:49,696
sampling or taking the arg max of that

1392
00:59:49,718 --> 00:59:51,520
distribution to actually make an action.

1393
00:59:52,340 --> 00:59:53,776
Okay, so now let's review the

1394
00:59:53,798 --> 00:59:55,056
observation modalities and their

1395
00:59:55,078 --> 00:59:57,456
different levels. The first modality is

1396
00:59:57,478 --> 00:59:59,636
the hint modality which can either give

1397
00:59:59,658 --> 01:00:01,796
the outcomes of null like I'm not at the

1398
01:00:01,818 --> 01:00:04,064
hint state so I'm getting no sensory

1399
01:00:04,112 --> 01:00:06,644
information from that channel. A left is

1400
01:00:06,682 --> 01:00:09,736
better hint hint left or a right is

1401
01:00:09,758 --> 01:00:12,232
better hint and they're just named that

1402
01:00:12,286 --> 01:00:14,264
because we'll see in the A matrix how

1403
01:00:14,302 --> 01:00:16,376
seeing that observation relates to

1404
01:00:16,558 --> 01:00:20,200
seeing the, to the state of the context.

1405
01:00:21,980 --> 01:00:24,148
We have the no observation because as I

1406
01:00:24,174 --> 01:00:25,656
said, if the agent isn't in the choice

1407
01:00:25,688 --> 01:00:27,724
state of getting a hint, it still needs

1408
01:00:27,762 --> 01:00:29,836
to receive some information from that

1409
01:00:29,858 --> 01:00:32,216
modality. So that's why we often have in

1410
01:00:32,258 --> 01:00:33,964
both the SPM and the Pine VP

1411
01:00:34,012 --> 01:00:35,884
implementations we have this null

1412
01:00:35,932 --> 01:00:37,456
observation that just encodes an

1413
01:00:37,478 --> 01:00:40,784
observation that has no

1414
01:00:40,822 --> 01:00:43,490
information about hidden states within

1415
01:00:44,260 --> 01:00:47,476
some particular factor. And then we have

1416
01:00:47,498 --> 01:00:50,356
a reward modality which similarly has a

1417
01:00:50,378 --> 01:00:52,260
null observation for when the agent

1418
01:00:52,330 --> 01:00:54,036
isn't playing either slot machine and

1419
01:00:54,058 --> 01:00:56,272
then two possible reward observations,

1420
01:00:56,336 --> 01:00:59,348
either a loss or a reward. But this is a

1421
01:00:59,434 --> 01:01:02,228
choice that can depends on what you're

1422
01:01:02,244 --> 01:01:03,544
trying to do. You could also make O

1423
01:01:03,582 --> 01:01:05,204
reward have like ten different reward

1424
01:01:05,252 --> 01:01:07,736
levels that have different magnitudes of

1425
01:01:07,758 --> 01:01:10,344
reward. It's just a choice to call these

1426
01:01:10,382 --> 01:01:12,396
like loss and reward. The point being

1427
01:01:12,418 --> 01:01:14,428
that one is preferred relative to the

1428
01:01:14,434 --> 01:01:17,148
other. And then finally we have the

1429
01:01:17,234 --> 01:01:19,228
choice modality which just allows the

1430
01:01:19,234 --> 01:01:22,104
agent to unambiguously infer what choice

1431
01:01:22,152 --> 01:01:25,088
state it's in. So it just allows it to

1432
01:01:25,174 --> 01:01:27,056
infer what it's doing. And this is

1433
01:01:27,078 --> 01:01:28,576
important because remember active

1434
01:01:28,598 --> 01:01:30,224
inference lab, everything has to be

1435
01:01:30,262 --> 01:01:33,456
inferred. Everything is in the

1436
01:01:33,478 --> 01:01:36,070
game of minimizing free energy and

1437
01:01:37,320 --> 01:01:41,136
coming up with posteriors approximate

1438
01:01:41,168 --> 01:01:42,452
beliefs about the state of the world,

1439
01:01:42,506 --> 01:01:44,036
including your own choice state. So

1440
01:01:44,058 --> 01:01:46,148
that's why we often equip agent with a

1441
01:01:46,154 --> 01:01:49,188
proprietive sense of where I am like a

1442
01:01:49,194 --> 01:01:49,860
GPS.

1443
01:01:53,880 --> 01:01:55,828
That's the three observation by. We've

1444
01:01:55,844 --> 01:01:57,252
done the hidden states and the controls.

1445
01:01:57,316 --> 01:01:58,952
So now we're in a position to start

1446
01:01:59,006 --> 01:02:00,836
building the arrays for this agent's

1447
01:02:00,868 --> 01:02:03,412
generative model. So for each modality

1448
01:02:03,476 --> 01:02:05,196
specific array we're going to have as

1449
01:02:05,218 --> 01:02:07,484
many rows as there are levels of that

1450
01:02:07,522 --> 01:02:09,932
modality and then two columns and four

1451
01:02:09,986 --> 01:02:12,328
slices. And so why is it two columns,

1452
01:02:12,344 --> 01:02:13,884
four slices? Because each column

1453
01:02:13,932 --> 01:02:15,772
corresponds to a setting of the context

1454
01:02:15,836 --> 01:02:18,272
hidden state factor and each third order

1455
01:02:18,326 --> 01:02:20,336
slice corresponds to a setting of the

1456
01:02:20,358 --> 01:02:22,544
choice state hidden state factor. And

1457
01:02:22,582 --> 01:02:25,788
these lagging dimension of two columns,

1458
01:02:25,804 --> 01:02:27,844
four slices will be the same for every

1459
01:02:27,882 --> 01:02:30,116
single A matrix, not the values in them,

1460
01:02:30,138 --> 01:02:32,116
but that shape. So the only thing that

1461
01:02:32,138 --> 01:02:34,932
will change across modalities, the A

1462
01:02:35,066 --> 01:02:37,124
modality specific A arrays is the number

1463
01:02:37,162 --> 01:02:38,864
of rows, which is the number of

1464
01:02:39,002 --> 01:02:41,428
observation levels. So for the hint

1465
01:02:41,444 --> 01:02:44,084
modality, each slice of this A matrix

1466
01:02:44,132 --> 01:02:45,944
tells us the mapping between the two

1467
01:02:45,982 --> 01:02:47,896
possible context states and the

1468
01:02:47,918 --> 01:02:50,216
observations in the hint modality for a

1469
01:02:50,238 --> 01:02:51,896
fixed choice state that the agent could

1470
01:02:51,918 --> 01:02:54,056
be in. So, for instance, if the agent is

1471
01:02:54,078 --> 01:02:55,816
in the start choice state, what we're

1472
01:02:55,848 --> 01:02:57,548
seeing now regardless of whether the

1473
01:02:57,554 --> 01:02:58,684
left or the right mission is better,

1474
01:02:58,722 --> 01:03:00,152
the agent will always get the null

1475
01:03:00,216 --> 01:03:02,364
observation, which has zero information

1476
01:03:02,482 --> 01:03:04,188
about the state of the context, as you

1477
01:03:04,194 --> 01:03:07,436
can see, because given an observation

1478
01:03:07,468 --> 01:03:09,436
of the null observation in the hint

1479
01:03:09,468 --> 01:03:11,136
modality, you have no idea whether the

1480
01:03:11,158 --> 01:03:13,008
left is better or the right is better.

1481
01:03:13,174 --> 01:03:15,056
However, if the agent is in the visit a

1482
01:03:15,078 --> 01:03:17,956
hint state or acquire a hint state,

1483
01:03:18,058 --> 01:03:19,744
then the mapping between the concept

1484
01:03:19,792 --> 01:03:21,684
state and the two hint observations will

1485
01:03:21,722 --> 01:03:24,452
be informative. And when I say

1486
01:03:24,506 --> 01:03:26,276
informative, I just mean that the

1487
01:03:26,298 --> 01:03:29,248
columns of this matrix will be

1488
01:03:29,354 --> 01:03:30,936
independent from each other and they

1489
01:03:30,958 --> 01:03:33,192
will be low entropy. So another way of

1490
01:03:33,246 --> 01:03:34,824
saying that is that they'll be low

1491
01:03:34,862 --> 01:03:37,156
entropy in the observation conditioned

1492
01:03:37,188 --> 01:03:40,296
rows of the matrix. So briefly what

1493
01:03:40,318 --> 01:03:42,132
we're seeing here, where grayscale

1494
01:03:42,196 --> 01:03:44,360
darker colors means more probability,

1495
01:03:45,340 --> 01:03:47,612
if the slot less machine is better

1496
01:03:47,666 --> 01:03:49,516
that's the context, then the agent is

1497
01:03:49,538 --> 01:03:51,868
more likely to see the hint left

1498
01:03:51,954 --> 01:03:53,836
observation. And if the right machine is

1499
01:03:53,858 --> 01:03:55,852
better, they're more likely to see the

1500
01:03:55,986 --> 01:03:58,476
hint to right observation. So this slice

1501
01:03:58,508 --> 01:04:00,384
of the a matrix is what gives those

1502
01:04:00,422 --> 01:04:02,816
observation levels their meaning. The

1503
01:04:02,838 --> 01:04:04,208
very reason they're called hint left and

1504
01:04:04,214 --> 01:04:07,068
hint right is just because of the kind

1505
01:04:07,094 --> 01:04:09,268
of diagonal structure in this slice of

1506
01:04:09,274 --> 01:04:11,636
the matrix. And then finally for the

1507
01:04:11,658 --> 01:04:14,788
other states, if I'm playing the left or

1508
01:04:14,794 --> 01:04:16,276
the right machine, I'm never getting any

1509
01:04:16,298 --> 01:04:18,368
informative observations from this

1510
01:04:18,394 --> 01:04:21,784
modality. Okay?

1511
01:04:21,822 --> 01:04:23,764
And then we move on to the reward

1512
01:04:23,812 --> 01:04:25,976
modality. So again, two columns and four

1513
01:04:25,998 --> 01:04:28,632
slices like for all the arrays. But now

1514
01:04:28,686 --> 01:04:30,216
we're looking at the mapping between the

1515
01:04:30,238 --> 01:04:32,372
two context and the reward observation

1516
01:04:32,436 --> 01:04:35,672
levels. So Bull lost reward for each

1517
01:04:35,726 --> 01:04:37,356
possible choice state the agent could be

1518
01:04:37,378 --> 01:04:39,452
in. So as we can see if the agent is in

1519
01:04:39,506 --> 01:04:41,720
starting location or getting the hint,

1520
01:04:41,880 --> 01:04:44,604
they're not getting any reward

1521
01:04:44,652 --> 01:04:46,092
conversation, they get the trivial,

1522
01:04:46,156 --> 01:04:48,640
meaningless null observation. However,

1523
01:04:48,710 --> 01:04:50,208
if the agent is playing the left or the

1524
01:04:50,214 --> 01:04:53,676
right machine, there's a probabilistic

1525
01:04:53,708 --> 01:04:55,664
mapping between the context, the left

1526
01:04:55,702 --> 01:04:56,864
machine or the right machine being

1527
01:04:56,902 --> 01:05:00,676
better and the expected reward. So if

1528
01:05:00,698 --> 01:05:02,756
the context is left is better, then the

1529
01:05:02,778 --> 01:05:04,592
agent is more likely to see the reward

1530
01:05:04,736 --> 01:05:06,900
if and only if they're playing the left

1531
01:05:06,970 --> 01:05:09,796
machine. Likewise, if they're playing

1532
01:05:09,828 --> 01:05:12,888
the right machine, this matrix is the

1533
01:05:12,894 --> 01:05:14,456
same. So if you're playing right, then

1534
01:05:14,478 --> 01:05:17,064
you're more likely to see reward. So

1535
01:05:17,262 --> 01:05:20,228
this submatrix within this big a tensor

1536
01:05:20,244 --> 01:05:22,456
is what determines the payoff structure

1537
01:05:22,488 --> 01:05:26,572
of the task or

1538
01:05:26,626 --> 01:05:28,216
the agent's beliefs about that payoff

1539
01:05:28,248 --> 01:05:29,388
structure, I should say, because this is

1540
01:05:29,394 --> 01:05:31,916
the array, it's not the actual rules of

1541
01:05:31,938 --> 01:05:34,096
the game. So now we're finally up to the

1542
01:05:34,118 --> 01:05:36,304
choice modality which again is just

1543
01:05:36,342 --> 01:05:39,164
their observation of their own choice

1544
01:05:39,212 --> 01:05:42,096
state which you can see only depends on

1545
01:05:42,118 --> 01:05:44,908
the state of the choice that they're

1546
01:05:44,924 --> 01:05:46,356
making. It doesn't depend on the

1547
01:05:46,378 --> 01:05:48,336
context. So it just means that they'll

1548
01:05:48,368 --> 01:05:51,700
always unambiguously infer whether

1549
01:05:51,770 --> 01:05:53,444
they're playing the right machine or

1550
01:05:53,482 --> 01:05:56,180
they're in the start state or whatnot.

1551
01:05:56,520 --> 01:05:58,416
So this is just an example of going

1552
01:05:58,458 --> 01:05:59,752
through those slices and really seeing

1553
01:05:59,806 --> 01:06:02,936
how that looks. So now we can code this

1554
01:06:02,958 --> 01:06:05,736
up in Colab. And again, we won't be

1555
01:06:05,758 --> 01:06:06,810
doing it by hand,

1556
01:06:10,380 --> 01:06:12,584
we'll just be running some predefined

1557
01:06:12,632 --> 01:06:15,612
code. So one useful thing to do often

1558
01:06:15,666 --> 01:06:17,544
with control factors and observation

1559
01:06:17,592 --> 01:06:20,168
modalities is get some semantic labels

1560
01:06:20,264 --> 01:06:21,916
like create a list of strings for

1561
01:06:21,938 --> 01:06:24,476
instance. So the context names will have

1562
01:06:24,498 --> 01:06:25,904
these two states left better, right,

1563
01:06:25,942 --> 01:06:27,984
better choice names will have these four

1564
01:06:28,022 --> 01:06:29,744
possible states. And then we can

1565
01:06:29,782 --> 01:06:31,696
automatically create these lists of

1566
01:06:31,798 --> 01:06:33,712
dimensions that are needed to create

1567
01:06:33,766 --> 01:06:36,356
your A and B matrices just by looking at

1568
01:06:36,378 --> 01:06:38,596
things like the length of this list of

1569
01:06:38,618 --> 01:06:40,516
strings or the length of this list of

1570
01:06:40,538 --> 01:06:42,950
choice names. So if you run this,

1571
01:06:43,720 --> 01:06:47,504
then we'll have our NUM states variable,

1572
01:06:47,552 --> 01:06:51,748
which will be 24 two possible contexts

1573
01:06:51,764 --> 01:06:53,096
and four possible choice states. And

1574
01:06:53,118 --> 01:06:56,170
then you'll have numbs, which will be

1575
01:06:56,940 --> 01:06:58,920
three possible hints, three possible

1576
01:06:58,990 --> 01:07:02,504
rewards and four proprioceptive location

1577
01:07:02,632 --> 01:07:04,684
or choice state observations. And then

1578
01:07:04,722 --> 01:07:06,456
we can use this function to initialize

1579
01:07:06,488 --> 01:07:09,292
our empty A matrix and then the next few

1580
01:07:09,346 --> 01:07:12,476
chunks of code basically just fill out

1581
01:07:12,498 --> 01:07:14,108
these A matrices like we saw in the

1582
01:07:14,114 --> 01:07:17,388
slides. So one thing we'll

1583
01:07:17,404 --> 01:07:19,776
do is we'll have two parameters and this

1584
01:07:19,798 --> 01:07:21,696
is again arbitrary. You can choose to do

1585
01:07:21,718 --> 01:07:23,436
this however you want. We'll prioritize

1586
01:07:23,468 --> 01:07:25,356
the A matrix with a probability of hint

1587
01:07:25,388 --> 01:07:27,648
or a hint accuracy which will

1588
01:07:27,734 --> 01:07:29,856
effectively just fill out that slice of

1589
01:07:29,878 --> 01:07:32,636
the hint modality array that corresponds

1590
01:07:32,668 --> 01:07:36,800
to how accurately the hint signal

1591
01:07:37,820 --> 01:07:40,884
indicates the concept or lends evidence

1592
01:07:40,932 --> 01:07:44,056
to the concept. So if the Hinton is 1.0,

1593
01:07:44,078 --> 01:07:46,696
p hint is 1.0, it means whenever they

1594
01:07:46,718 --> 01:07:48,244
visit the hint state, they immediately

1595
01:07:48,292 --> 01:07:51,144
know, okay, the left arm is better, but

1596
01:07:51,182 --> 01:07:53,388
this doesn't have to be 100% right? The

1597
01:07:53,394 --> 01:07:55,116
hint itself could have some noise or

1598
01:07:55,138 --> 01:07:57,048
uncertainty associated with it. So we'll

1599
01:07:57,064 --> 01:07:58,236
parameterize that just with this

1600
01:07:58,258 --> 01:08:01,870
probability. So this is

1601
01:08:02,320 --> 01:08:05,756
the probability of the two hint types

1602
01:08:05,868 --> 01:08:07,536
for the two game states. And you see the

1603
01:08:07,558 --> 01:08:10,316
null has zero probability and then hint

1604
01:08:10,428 --> 01:08:13,404
left has more probably when the context

1605
01:08:13,452 --> 01:08:15,696
is left indicated by the column. And

1606
01:08:15,718 --> 01:08:17,128
then hint right has more probability

1607
01:08:17,164 --> 01:08:19,796
when the context is right. And then

1608
01:08:19,818 --> 01:08:21,284
we'll just go through and fill out this

1609
01:08:21,322 --> 01:08:25,440
chance stuff. Oh, the reward modality

1610
01:08:25,520 --> 01:08:27,184
will have a similar thing of P reward.

1611
01:08:27,232 --> 01:08:28,612
So this will determine the payoff

1612
01:08:28,676 --> 01:08:32,456
structure of both bandit arms. So if P

1613
01:08:32,478 --> 01:08:35,348
reward is high, it means if the context

1614
01:08:35,444 --> 01:08:38,184
is left is better and you're playing the

1615
01:08:38,222 --> 01:08:40,732
left slot machine, you'll have an 80%

1616
01:08:40,786 --> 01:08:43,036
chance of getting the reward. And this

1617
01:08:43,058 --> 01:08:47,016
thing itself can be changed to determine

1618
01:08:47,048 --> 01:08:49,544
basically how how rewarding the bandits

1619
01:08:49,592 --> 01:08:50,190
are.

1620
01:08:53,200 --> 01:08:55,596
So this is the payoff structure if

1621
01:08:55,618 --> 01:08:57,596
you're playing the left arm, the payoff

1622
01:08:57,628 --> 01:08:59,008
structure for the two contexts. And

1623
01:08:59,014 --> 01:09:00,508
there's an inverseness that I didn't

1624
01:09:00,524 --> 01:09:02,108
discuss. So if I'm playing the left arm

1625
01:09:02,124 --> 01:09:05,164
but the right arm is better, then I'm

1626
01:09:05,212 --> 01:09:07,904
also more likely symmetrically to get

1627
01:09:07,942 --> 01:09:09,828
punishment or negative reward with the

1628
01:09:09,834 --> 01:09:11,476
same probability that I would get

1629
01:09:11,498 --> 01:09:12,948
positive reward if I was playing the

1630
01:09:12,954 --> 01:09:15,396
right on so that's also a choice but

1631
01:09:15,418 --> 01:09:16,976
just to make this a single parameter.

1632
01:09:17,008 --> 01:09:19,784
That's how we did it here. And then

1633
01:09:19,822 --> 01:09:21,416
finally the choice observation by that

1634
01:09:21,438 --> 01:09:24,296
is just filling out that GPS high

1635
01:09:24,318 --> 01:09:26,040
fidelity GPS sensor.

1636
01:09:29,580 --> 01:09:33,332
If you slice it along any context

1637
01:09:33,396 --> 01:09:34,776
hidden states factor, since it doesn't

1638
01:09:34,808 --> 01:09:36,332
depend on context, this could be a zero

1639
01:09:36,386 --> 01:09:38,984
or a one. Then we'll get an identity

1640
01:09:39,032 --> 01:09:40,984
mapping which just allows them to infer

1641
01:09:41,032 --> 01:09:43,516
their choice state and then we wrap this

1642
01:09:43,538 --> 01:09:45,184
all into one function. So we just have

1643
01:09:45,222 --> 01:09:47,696
two parameters p Hinton, p reward and

1644
01:09:47,718 --> 01:09:49,584
then we can see once we start doing

1645
01:09:49,622 --> 01:09:51,056
simulations how manipulating those

1646
01:09:51,078 --> 01:09:53,200
things messes with their behavior.

1647
01:09:54,980 --> 01:09:57,040
So now we'll move on to the B arrays.

1648
01:09:58,280 --> 01:10:00,852
Oh yeah, so let me go here and talk

1649
01:10:00,906 --> 01:10:02,324
through some slides. This will be quick.

1650
01:10:02,362 --> 01:10:05,616
The brain are pretty simple so we're

1651
01:10:05,648 --> 01:10:07,696
going to mess with this later. But we're

1652
01:10:07,728 --> 01:10:10,184
going to start by saying that the

1653
01:10:10,302 --> 01:10:11,944
context hidden states factor is

1654
01:10:11,982 --> 01:10:14,120
stationary over time so they can't

1655
01:10:14,620 --> 01:10:18,024
change that hidden state factor and even

1656
01:10:18,062 --> 01:10:19,464
in the absence of their ambiguity to

1657
01:10:19,502 --> 01:10:23,016
intervene, it stays

1658
01:10:23,048 --> 01:10:24,716
in the same state over time. So we

1659
01:10:24,738 --> 01:10:26,620
parameterize this with like a p change

1660
01:10:26,690 --> 01:10:28,556
probability that just fills out the

1661
01:10:28,578 --> 01:10:31,832
diagonal of this kind of trivial

1662
01:10:31,896 --> 01:10:34,772
transition matrix with 100% probability.

1663
01:10:34,856 --> 01:10:36,704
But later on we can mess with that

1664
01:10:36,742 --> 01:10:38,496
parameter and decrease it. So they

1665
01:10:38,518 --> 01:10:39,952
believe that the concept can actually

1666
01:10:40,006 --> 01:10:41,744
change with some stochasticity over

1667
01:10:41,782 --> 01:10:45,244
time. But for now we just assume

1668
01:10:45,292 --> 01:10:47,270
they don't believe the context changes

1669
01:10:48,760 --> 01:10:51,124
and then this is their ability to so

1670
01:10:51,162 --> 01:10:53,188
unlike Grid World where you have local

1671
01:10:53,274 --> 01:10:55,044
actions, they can only move up, down,

1672
01:10:55,082 --> 01:10:57,716
left, right here. They can move from any

1673
01:10:57,738 --> 01:10:59,896
other state to any other state. So this

1674
01:10:59,918 --> 01:11:02,472
is like a signature or thing if you want

1675
01:11:02,606 --> 01:11:05,656
a controllable hidden state space. So

1676
01:11:05,678 --> 01:11:08,072
the agent can go anywhere from any other

1677
01:11:08,126 --> 01:11:11,252
place that will manifest as these dark

1678
01:11:11,316 --> 01:11:14,412
bands in your b matrix or bands of 100%

1679
01:11:14,466 --> 01:11:16,668
probability. So this is another way of

1680
01:11:16,674 --> 01:11:18,396
saying that the transition graph is

1681
01:11:18,418 --> 01:11:19,964
fully connected, that you can get

1682
01:11:20,002 --> 01:11:23,144
anywhere from anywhere. But that's

1683
01:11:23,192 --> 01:11:25,344
also not sure we could have made it such

1684
01:11:25,382 --> 01:11:27,232
that once they leave the start state

1685
01:11:27,286 --> 01:11:29,344
they can't return there. So that would

1686
01:11:29,382 --> 01:11:33,216
correspond to having the absence of one

1687
01:11:33,238 --> 01:11:37,092
of these. Like basically the start state

1688
01:11:37,146 --> 01:11:40,880
is a source but it can't also be a sync

1689
01:11:41,040 --> 01:11:44,356
or there's no in arrows going to it so

1690
01:11:44,378 --> 01:11:46,310
that would affect the structure of this.

1691
01:11:47,420 --> 01:11:49,624
Okay and then we can quickly code that

1692
01:11:49,662 --> 01:11:50,250
up.

1693
01:11:54,620 --> 01:11:57,576
So b zero is the concept hidden states

1694
01:11:57,598 --> 01:11:58,984
which as we said is just going to be

1695
01:11:59,022 --> 01:12:02,036
stationarity and then the choice hidden

1696
01:12:02,068 --> 01:12:05,244
states is fully controllable and then we

1697
01:12:05,282 --> 01:12:07,324
will parameterize this all as a create B

1698
01:12:07,362 --> 01:12:09,964
function which will for now have this p

1699
01:12:10,002 --> 01:12:12,508
change thing. So we can make the agent

1700
01:12:12,594 --> 01:12:14,956
belief about the stationary of the

1701
01:12:14,978 --> 01:12:17,724
context different. Like if the context

1702
01:12:17,772 --> 01:12:19,504
is likely to change, but for now, by

1703
01:12:19,542 --> 01:12:21,088
setting it to zero, it just means that

1704
01:12:21,094 --> 01:12:22,816
they believe the context is fixed for a

1705
01:12:22,838 --> 01:12:26,530
given trial or set of time points.

1706
01:12:26,980 --> 01:12:29,108
And then finally, very basic. Stuff.

1707
01:12:29,274 --> 01:12:31,476
This is just how we establish the

1708
01:12:31,498 --> 01:12:34,308
semantics of the reward modality. So the

1709
01:12:34,314 --> 01:12:36,196
reward modality is, as we said, the

1710
01:12:36,218 --> 01:12:38,744
null, the loss and the reward. And we

1711
01:12:38,782 --> 01:12:40,648
can encode the C vector, which is kind

1712
01:12:40,654 --> 01:12:42,730
of like the reward function,

1713
01:12:43,820 --> 01:12:45,832
the prior preferences or prior over

1714
01:12:45,886 --> 01:12:48,728
observations directly in terms of

1715
01:12:48,894 --> 01:12:51,676
relative log probabilities. So we can

1716
01:12:51,698 --> 01:12:54,440
encode punishment by having the prior

1717
01:12:54,600 --> 01:12:58,236
expectation about loss be much lower in

1718
01:12:58,258 --> 01:13:01,656
relative log in natural

1719
01:13:01,688 --> 01:13:04,872
log units. Much. Lower than the reward

1720
01:13:04,936 --> 01:13:06,588
observation within that modality. And

1721
01:13:06,594 --> 01:13:07,776
then the other ones are just going to be

1722
01:13:07,798 --> 01:13:09,504
uniform distribution, so you can leave

1723
01:13:09,542 --> 01:13:12,896
them empty. And this is just what

1724
01:13:12,918 --> 01:13:15,296
allows them to want to see reward as

1725
01:13:15,318 --> 01:13:17,380
opposed to loss or punishment.

1726
01:13:19,880 --> 01:13:21,830
I think we discussed this last time.

1727
01:13:22,200 --> 01:13:24,516
Daphne had a question about that. So why

1728
01:13:24,538 --> 01:13:27,524
do we encode things in relative log

1729
01:13:27,722 --> 01:13:29,984
probabilities rather than sheer

1730
01:13:30,032 --> 01:13:31,856
probabilities? It's just more analogous

1731
01:13:31,888 --> 01:13:33,256
to the reward construct from

1732
01:13:33,278 --> 01:13:34,504
reinforcement learning that's one

1733
01:13:34,542 --> 01:13:37,416
benefit and they're unbounded. They

1734
01:13:37,438 --> 01:13:38,664
don't have to be bounded between zero

1735
01:13:38,702 --> 01:13:40,296
and one. So if you just encode them that

1736
01:13:40,318 --> 01:13:43,532
way, it becomes easier to kind of make

1737
01:13:43,586 --> 01:13:47,308
one thing x times more rewarding or

1738
01:13:47,394 --> 01:13:50,156
punish or aversive than another thing.

1739
01:13:50,258 --> 01:13:52,476
And that directly relates to how kind of

1740
01:13:52,498 --> 01:13:55,416
reward is calculated in our expected

1741
01:13:55,448 --> 01:13:57,196
utility of the expected free energy is

1742
01:13:57,218 --> 01:13:59,460
because it's always kind of an expected

1743
01:13:59,560 --> 01:14:01,196
it's kind of like an entropy or a cross

1744
01:14:01,228 --> 01:14:04,816
entropy. So its units are

1745
01:14:04,838 --> 01:14:06,950
in natural log space.

1746
01:14:08,520 --> 01:14:11,696
Okay. And then the D vector.

1747
01:14:11,808 --> 01:14:13,876
Again, they can have prior beliefs about

1748
01:14:13,898 --> 01:14:16,116
which context is better. So that will

1749
01:14:16,138 --> 01:14:18,036
also be a collection of vectors, one

1750
01:14:18,058 --> 01:14:21,664
over the context factor and one over the

1751
01:14:21,722 --> 01:14:24,424
initial state of where they are, which

1752
01:14:24,462 --> 01:14:25,908
we can make it start, but it doesn't

1753
01:14:25,924 --> 01:14:27,332
really matter because they have precise

1754
01:14:27,396 --> 01:14:30,264
observations. And then that's very easy

1755
01:14:30,302 --> 01:14:33,484
to do in prime DP. We'll just create

1756
01:14:33,602 --> 01:14:35,852
some functions that parameterize how

1757
01:14:35,906 --> 01:14:38,076
rewarding the reward observation is and

1758
01:14:38,098 --> 01:14:40,104
how punishing the punishment observation

1759
01:14:40,152 --> 01:14:43,584
is. Then we can plot those and this

1760
01:14:43,622 --> 01:14:46,864
could be ten. Then the

1761
01:14:46,902 --> 01:14:50,672
reward is much more is much better

1762
01:14:50,726 --> 01:14:52,172
than the punishment, or the punishment

1763
01:14:52,236 --> 01:14:56,176
could be very bad, in which case the

1764
01:14:56,198 --> 01:14:57,876
punishment is much, much lower than both

1765
01:14:57,898 --> 01:15:01,316
the null and the reward. And here

1766
01:15:01,338 --> 01:15:04,484
I'm showing the prior directly in terms

1767
01:15:04,522 --> 01:15:06,608
of probabilities. So when you convert

1768
01:15:06,624 --> 01:15:07,984
the log probabilities to probabilities,

1769
01:15:08,032 --> 01:15:09,512
these things will become bounded between

1770
01:15:09,566 --> 01:15:13,016
zero and one. Okay?

1771
01:15:13,118 --> 01:15:14,696
And then the D vector simulator will

1772
01:15:14,718 --> 01:15:16,744
just create a quick function that

1773
01:15:16,782 --> 01:15:20,696
parameterizes how much they believe the

1774
01:15:20,718 --> 01:15:23,208
left is better. Context is true at the

1775
01:15:23,214 --> 01:15:25,148
beginning of the simulation. And if you

1776
01:15:25,154 --> 01:15:27,004
just set that to 0.5, it means they have

1777
01:15:27,042 --> 01:15:29,576
flat, unbiased, uninformed prior beliefs

1778
01:15:29,608 --> 01:15:31,340
about the concept.

1779
01:15:35,060 --> 01:15:36,530
Yes. Okay.

1780
01:15:41,860 --> 01:15:45,440
All right, so now I think we are good to

1781
01:15:45,590 --> 01:15:47,808
actually do this after all the build up.

1782
01:15:47,974 --> 01:15:51,588
So, like 95% of the work is encoding the

1783
01:15:51,594 --> 01:15:53,044
generative model. And this is something

1784
01:15:53,082 --> 01:15:55,796
Karl will tell you as well. SPM most of

1785
01:15:55,818 --> 01:15:57,376
the work is not actually running active

1786
01:15:57,408 --> 01:15:59,636
inference. Maybe computation wise it is,

1787
01:15:59,738 --> 01:16:01,384
but in terms of the time and the

1788
01:16:01,422 --> 01:16:03,864
intellectual energy spent, it all comes

1789
01:16:03,902 --> 01:16:05,588
down to the generative model. That's

1790
01:16:05,604 --> 01:16:07,304
where all the information is. The rest

1791
01:16:07,342 --> 01:16:10,552
is just optimization, basically. So

1792
01:16:10,606 --> 01:16:12,680
we've written down our ABCs and DS,

1793
01:16:12,760 --> 01:16:14,652
then we just basically plug them into

1794
01:16:14,706 --> 01:16:18,670
this agent API from Pinedp. And then we

1795
01:16:20,000 --> 01:16:22,716
create an environment class which could

1796
01:16:22,738 --> 01:16:26,592
be as something as ad hoc as I'm getting

1797
01:16:26,646 --> 01:16:29,596
a list of observations from some API

1798
01:16:29,628 --> 01:16:31,936
that's talking to the Internet or from a

1799
01:16:31,958 --> 01:16:34,624
robot sensors. Or you can actually write

1800
01:16:34,662 --> 01:16:37,200
down an environment class that generates

1801
01:16:37,360 --> 01:16:40,388
observations like another agent, for

1802
01:16:40,394 --> 01:16:43,188
instance. And then you plug the

1803
01:16:43,194 --> 01:16:44,852
observations from the environment into

1804
01:16:44,906 --> 01:16:46,976
the infer states function you do infer

1805
01:16:47,008 --> 01:16:49,332
policies. And then you sample an action

1806
01:16:49,476 --> 01:16:51,112
according to the expected free energy

1807
01:16:51,166 --> 01:16:53,530
stuff that we talked about last time.

1808
01:16:54,460 --> 01:16:57,512
Okay, so now we're actually going

1809
01:16:57,566 --> 01:17:01,284
to do this. So we have our nice nifty

1810
01:17:01,332 --> 01:17:03,836
functions for creating A-B-C and D. We

1811
01:17:03,858 --> 01:17:06,488
can just run those with desired levels

1812
01:17:06,504 --> 01:17:09,292
of P hint and P reward and then create

1813
01:17:09,346 --> 01:17:12,396
our agent. And this is something we

1814
01:17:12,418 --> 01:17:13,612
discussed last time, but an important

1815
01:17:13,666 --> 01:17:15,052
distinctions is the generative model

1816
01:17:15,106 --> 01:17:16,848
versus the generative process or the

1817
01:17:16,854 --> 01:17:18,864
environment. So the things we're putting

1818
01:17:18,902 --> 01:17:22,176
in A and B right now and C are just the

1819
01:17:22,198 --> 01:17:24,204
agent's beliefs about, for instance,

1820
01:17:24,252 --> 01:17:26,764
the hint accuracy or the payoff matrix

1821
01:17:26,812 --> 01:17:29,024
of reward that can be arbitrarily

1822
01:17:29,072 --> 01:17:31,236
different from the actual structure of

1823
01:17:31,258 --> 01:17:34,390
the environment. And we'll see how later

1824
01:17:34,920 --> 01:17:36,772
we'll see how you can adjust. The agent

1825
01:17:36,826 --> 01:17:38,672
can actually learn the correct reward

1826
01:17:38,736 --> 01:17:40,376
statistics through a process of

1827
01:17:40,398 --> 01:17:41,976
learning. So even if they start out with

1828
01:17:41,998 --> 01:17:43,784
the wrong generative model, they can

1829
01:17:43,822 --> 01:17:46,296
adapt their generative model online so

1830
01:17:46,318 --> 01:17:48,792
that they match the generative process

1831
01:17:48,846 --> 01:17:52,596
better. Okay, and then we'll define

1832
01:17:52,628 --> 01:17:54,928
this quick class, the two arm bandit,

1833
01:17:54,964 --> 01:17:56,508
which will be the generative process,

1834
01:17:56,594 --> 01:17:59,116
the real world for our agent. We're not

1835
01:17:59,138 --> 01:18:01,356
going to step through the code, but the

1836
01:18:01,378 --> 01:18:03,276
link is available. So if anyone wants to

1837
01:18:03,298 --> 01:18:04,700
look at this, this is basically just

1838
01:18:04,770 --> 01:18:06,576
encoding the rules of the game. So when

1839
01:18:06,598 --> 01:18:09,708
the agent is in the left arm, they'll

1840
01:18:09,724 --> 01:18:12,592
get reward or Costa, depending on the P

1841
01:18:12,646 --> 01:18:15,376
reward and P hint values. And as we

1842
01:18:15,398 --> 01:18:17,296
said, these values can be different than

1843
01:18:17,318 --> 01:18:19,044
the agent's beliefs about them, which

1844
01:18:19,082 --> 01:18:22,036
will be in their A matrix. So this is

1845
01:18:22,058 --> 01:18:23,508
the generative process, the actual

1846
01:18:23,594 --> 01:18:25,744
reward, and then the generative models

1847
01:18:25,792 --> 01:18:28,484
are the parameters you give to the A

1848
01:18:28,522 --> 01:18:29,540
Constructor.

1849
01:18:32,220 --> 01:18:34,696
And then we'll just have a function here

1850
01:18:34,878 --> 01:18:37,416
that runs the active inference loop. It

1851
01:18:37,438 --> 01:18:39,096
looks a little bit more complicated than

1852
01:18:39,118 --> 01:18:40,676
those three lines I showed on the slide,

1853
01:18:40,708 --> 01:18:42,024
but that's just because I'm storing

1854
01:18:42,072 --> 01:18:43,196
things like the history of their

1855
01:18:43,218 --> 01:18:45,900
choices, the history of their beliefs.

1856
01:18:46,720 --> 01:18:49,992
I'm having optional plotting of beliefs

1857
01:18:50,136 --> 01:18:52,316
things like that and plotting of

1858
01:18:52,338 --> 01:18:55,632
actions. But this function basically

1859
01:18:55,766 --> 01:18:58,896
the key things are you get an

1860
01:18:58,918 --> 01:19:01,856
observation from the you start with an

1861
01:19:01,878 --> 01:19:03,808
observation, which it will be from the

1862
01:19:03,814 --> 01:19:06,192
generative process. You do hidden state

1863
01:19:06,246 --> 01:19:08,096
inference using that observation to get

1864
01:19:08,118 --> 01:19:10,676
your posterior over hidden states. And

1865
01:19:10,698 --> 01:19:12,576
this you can return if you want to plot

1866
01:19:12,608 --> 01:19:14,676
it, but you don't have to. And then

1867
01:19:14,698 --> 01:19:16,996
you'll do inference about policy. So

1868
01:19:17,018 --> 01:19:19,624
this is optimization of a posterior over

1869
01:19:19,822 --> 01:19:21,636
policies, which then gets translated

1870
01:19:21,668 --> 01:19:23,880
into marginal posterior over control

1871
01:19:23,950 --> 01:19:26,090
states or action that you sample from

1872
01:19:27,340 --> 01:19:29,384
and you sample from them if this next

1873
01:19:29,422 --> 01:19:31,084
line with sample action. So the main

1874
01:19:31,122 --> 01:19:32,616
three lines of any active coherence

1875
01:19:32,648 --> 01:19:35,628
process are inference about states,

1876
01:19:35,714 --> 01:19:37,852
coherence about policies, and then

1877
01:19:37,906 --> 01:19:40,492
action selection, which can be either

1878
01:19:40,546 --> 01:19:42,844
deterministic or stochastic depending on

1879
01:19:42,962 --> 01:19:45,264
your application. And then the rest is

1880
01:19:45,302 --> 01:19:47,644
just basically code that converts

1881
01:19:47,692 --> 01:19:50,688
observations from the generative process

1882
01:19:50,774 --> 01:19:52,704
into the terms that the agent can

1883
01:19:52,742 --> 01:19:56,028
understand and vice versa. And then we

1884
01:19:56,054 --> 01:19:57,844
have this helper function that plots the

1885
01:19:57,882 --> 01:20:00,916
history of choices and beliefs and the

1886
01:20:00,938 --> 01:20:03,750
true context over time.

1887
01:20:04,600 --> 01:20:07,364
So, yeah, I just blaze through that

1888
01:20:07,402 --> 01:20:08,612
quickly because it's not very important,

1889
01:20:08,666 --> 01:20:11,016
but if anyone has questions, we can go

1890
01:20:11,038 --> 01:20:12,216
back and dissect that code a little

1891
01:20:12,238 --> 01:20:15,944
more. So now all we have to do

1892
01:20:16,062 --> 01:20:19,176
is define the yako. You have

1893
01:20:19,198 --> 01:20:21,210
your hand up, you'll ask. Something,

1894
01:20:21,840 --> 01:20:25,788
yeah, maybe this is

1895
01:20:25,874 --> 01:20:30,636
better suited for the end, but in

1896
01:20:30,738 --> 01:20:33,468
time DP, there's also modules that are

1897
01:20:33,554 --> 01:20:35,390
adjacent to the agent class.

1898
01:20:36,160 --> 01:20:38,220
So I was just wondering.

1899
01:20:41,220 --> 01:20:43,472
How we. Could make use of the different

1900
01:20:43,526 --> 01:20:46,420
modules in the action perception loop,

1901
01:20:47,320 --> 01:20:52,660
because I haven't seen many examples of

1902
01:20:52,730 --> 01:20:54,304
using, for instance, the inference

1903
01:20:54,352 --> 01:20:56,436
module or the learning module and how

1904
01:20:56,458 --> 01:21:00,288
that would augment the run active

1905
01:21:00,304 --> 01:21:01,912
infrastructure. Yeah, that's a great

1906
01:21:01,966 --> 01:21:05,496
question. So I have another demo that we

1907
01:21:05,518 --> 01:21:07,780
can maybe do another time that's

1908
01:21:07,940 --> 01:21:10,324
building a hierarchical model in PMDP.

1909
01:21:10,372 --> 01:21:12,616
So building a two layer model. It's a

1910
01:21:12,638 --> 01:21:14,604
visual foraging hierarchical model based

1911
01:21:14,642 --> 01:21:17,384
on a paper that we did back in 2018,

1912
01:21:17,432 --> 01:21:20,984
2019. And there you're

1913
01:21:21,032 --> 01:21:23,940
in this inner loop over time, you're

1914
01:21:23,960 --> 01:21:26,172
making use of these sub module

1915
01:21:26,236 --> 01:21:28,624
functions. So say you wanted to do some

1916
01:21:28,662 --> 01:21:31,456
special kind of inference that's not

1917
01:21:31,478 --> 01:21:34,576
just the standard infer states. You

1918
01:21:34,598 --> 01:21:36,176
could actually say, okay, I want to do

1919
01:21:36,198 --> 01:21:37,808
this particular weird thing that's

1920
01:21:37,824 --> 01:21:39,956
specific to this inference process. And

1921
01:21:39,978 --> 01:21:43,236
you would just add lines here like, I

1922
01:21:43,258 --> 01:21:45,556
want to take a function from the

1923
01:21:45,578 --> 01:21:48,608
inference module and run like, I don't

1924
01:21:48,624 --> 01:21:50,600
know, a different kind of message

1925
01:21:50,670 --> 01:21:54,216
passing on it, like run MMP or

1926
01:21:54,238 --> 01:21:56,484
something inference. Or there's an Algos

1927
01:21:56,532 --> 01:21:57,912
module too that has different message

1928
01:21:57,966 --> 01:22:00,056
passing algorithms. And then you could

1929
01:22:00,078 --> 01:22:01,624
optimize your hidden state belief,

1930
01:22:01,672 --> 01:22:03,480
updating that message passing algorithm,

1931
01:22:03,560 --> 01:22:07,996
and then set them equal to the

1932
01:22:08,178 --> 01:22:11,324
special thing you did just

1933
01:22:11,362 --> 01:22:12,190
with that.

1934
01:22:15,440 --> 01:22:18,080
So, yeah, there's no examples here,

1935
01:22:18,230 --> 01:22:21,596
but I haven't done that here, but it's

1936
01:22:21,628 --> 01:22:23,970
definitely something that can be done.

1937
01:22:26,260 --> 01:22:28,564
Or yeah, there's another example I did,

1938
01:22:28,602 --> 01:22:30,128
like simulating an active inference

1939
01:22:30,144 --> 01:22:31,872
equivalent of an evidence accumulation

1940
01:22:31,936 --> 01:22:34,756
drift diffusion style task where the

1941
01:22:34,778 --> 01:22:36,788
policy selection was done in a

1942
01:22:36,794 --> 01:22:38,372
particular way, where you're only using

1943
01:22:38,426 --> 01:22:40,116
certain components of the expected free

1944
01:22:40,138 --> 01:22:43,924
energy. And yes, so basically

1945
01:22:43,962 --> 01:22:45,716
there's other demos where you can,

1946
01:22:45,738 --> 01:22:47,352
like, zoom in and not use the Agent

1947
01:22:47,406 --> 01:22:49,556
class and use sub modules, but I haven't

1948
01:22:49,588 --> 01:22:53,044
written those in a publicly

1949
01:22:53,092 --> 01:22:55,864
accessible way yet, but the hierarchical

1950
01:22:55,912 --> 01:22:57,596
one I can just easily make public. I

1951
01:22:57,618 --> 01:22:58,908
just haven't had time to put it on the

1952
01:22:58,914 --> 01:23:01,516
dock yet. But yeah, that's a good

1953
01:23:01,538 --> 01:23:03,376
question because you're right, most of

1954
01:23:03,398 --> 01:23:05,596
the stuff right now is just the highest

1955
01:23:05,628 --> 01:23:07,490
level implementation with the Agent.

1956
01:23:09,620 --> 01:23:13,376
Okay? And now that to

1957
01:23:13,398 --> 01:23:15,410
just run the active inference process,

1958
01:23:16,100 --> 01:23:17,684
I've made a distinction between

1959
01:23:17,722 --> 01:23:20,196
generative process parameters, like how

1960
01:23:20,218 --> 01:23:23,456
accurate the hint is, how the payoff

1961
01:23:23,488 --> 01:23:25,412
structure is, and then generative model

1962
01:23:25,466 --> 01:23:27,456
parameters which are used when creating

1963
01:23:27,488 --> 01:23:30,004
the a matrix. So the p hint end is the

1964
01:23:30,042 --> 01:23:33,048
true hint accuracy p reward end is the

1965
01:23:33,054 --> 01:23:35,192
true payoff. And then just choose some

1966
01:23:35,246 --> 01:23:36,788
time horizon and run the active

1967
01:23:36,804 --> 01:23:38,708
inference soup with that time horizon

1968
01:23:38,884 --> 01:23:41,240
and then plot the history of beliefs.

1969
01:23:42,060 --> 01:23:43,710
Okay, so here's an example.

1970
01:23:46,160 --> 01:23:49,640
The top plot shows the Agent's behavior.

1971
01:23:49,720 --> 01:23:52,316
So white squares indicate what it was

1972
01:23:52,338 --> 01:23:55,548
doing at any given time. So time is on

1973
01:23:55,554 --> 01:23:57,328
the x axis. So you can see it start in

1974
01:23:57,334 --> 01:23:58,716
the start state. Then it gathered

1975
01:23:58,748 --> 01:24:01,040
information at the hint.

1976
01:24:02,580 --> 01:24:04,416
And the reason this wasn't immediate is

1977
01:24:04,438 --> 01:24:06,336
because its beliefs about accuracy were

1978
01:24:06,358 --> 01:24:08,304
only 0.7. So it needs to actually do

1979
01:24:08,342 --> 01:24:10,316
some evidence accumulation before it's

1980
01:24:10,428 --> 01:24:12,276
sure what active states is. Then it

1981
01:24:12,298 --> 01:24:14,656
played right. But as soon as it played

1982
01:24:14,688 --> 01:24:15,796
right, because that's what the hint was

1983
01:24:15,818 --> 01:24:17,396
telling it. As soon as it played right,

1984
01:24:17,418 --> 01:24:22,616
it probably had a

1985
01:24:22,638 --> 01:24:24,776
loss observation, which then messed up

1986
01:24:24,798 --> 01:24:26,376
its inference and made it go back to the

1987
01:24:26,398 --> 01:24:28,760
hint to accumulate evidence again before

1988
01:24:28,830 --> 01:24:30,504
being okay, the hint is really

1989
01:24:30,542 --> 01:24:32,152
suggesting that I should go, right? So

1990
01:24:32,206 --> 01:24:34,044
then it goes back, revisits the right

1991
01:24:34,082 --> 01:24:36,380
arm, and then over time, you see here,

1992
01:24:36,450 --> 01:24:38,744
the red dot is the actual true context,

1993
01:24:38,872 --> 01:24:41,176
and the gray scale indicates the Agent's

1994
01:24:41,208 --> 01:24:43,724
beliefs about the hidden states. So

1995
01:24:43,762 --> 01:24:46,064
here, the hidden states beliefs are now

1996
01:24:46,102 --> 01:24:49,104
converging to believing that the right

1997
01:24:49,142 --> 01:24:52,176
arm is better. And I know I said hit the

1998
01:24:52,198 --> 01:24:53,904
beginning that all probability would be

1999
01:24:53,942 --> 01:24:55,328
darker means higher probability, but

2000
01:24:55,334 --> 01:24:56,656
it's actually the opposite here, so

2001
01:24:56,678 --> 01:24:59,124
sorry, that's confusing. So yeah,

2002
01:24:59,162 --> 01:25:01,220
right. Better is higher probability,

2003
01:25:01,640 --> 01:25:03,524
and their beliefs get more and more

2004
01:25:03,562 --> 01:25:06,708
competent as they play. So this is the

2005
01:25:06,714 --> 01:25:07,828
exact same thing you'll see with the

2006
01:25:07,834 --> 01:25:10,456
teammates, right? They first forage for

2007
01:25:10,478 --> 01:25:11,864
information that's driven by this

2008
01:25:11,902 --> 01:25:13,576
epistemic value component to the

2009
01:25:13,598 --> 01:25:16,116
expected free energy. As their posterior

2010
01:25:16,148 --> 01:25:18,404
over hidden states becomes more precise,

2011
01:25:18,532 --> 01:25:22,220
epistemic value goes down, and then the

2012
01:25:22,370 --> 01:25:24,620
expected utility component goes up,

2013
01:25:24,690 --> 01:25:26,396
which is bolstered by the fact that they

2014
01:25:26,418 --> 01:25:28,172
now have confident beliefs about the

2015
01:25:28,226 --> 01:25:30,156
context. And then that drives them to

2016
01:25:30,178 --> 01:25:31,070
forge information.

2017
01:25:34,320 --> 01:25:37,008
And then so the kind of exercise that I

2018
01:25:37,014 --> 01:25:38,448
would have people do if this was like in

2019
01:25:38,454 --> 01:25:40,764
a classroom context is start messing

2020
01:25:40,812 --> 01:25:44,752
with the bandit probabilities and also

2021
01:25:44,806 --> 01:25:46,416
mess with the agent's sensitivity to

2022
01:25:46,438 --> 01:25:48,644
punishment. So up here, we made them

2023
01:25:48,682 --> 01:25:52,084
have plus two relative nats in their

2024
01:25:52,122 --> 01:25:54,244
reward function and minus four for

2025
01:25:54,282 --> 01:25:56,452
punishment. But if you made this even

2026
01:25:56,506 --> 01:25:58,204
lower, let's say you made it negative

2027
01:25:58,272 --> 01:26:00,330
six, what would happen?

2028
01:26:01,340 --> 01:26:03,508
So now, because they're more risk

2029
01:26:03,524 --> 01:26:07,112
Andersen the risk of getting

2030
01:26:07,166 --> 01:26:09,064
a loss observation, if I was to play,

2031
01:26:09,102 --> 01:26:12,376
immediately becomes higher. So now the

2032
01:26:12,398 --> 01:26:14,920
agent basically requires more confidence

2033
01:26:15,080 --> 01:26:17,916
before it's willing to actually play the

2034
01:26:17,938 --> 01:26:20,396
left arm, because the risk of getting it

2035
01:26:20,418 --> 01:26:22,220
wrong and getting a loss is too great

2036
01:26:22,290 --> 01:26:24,016
because their reward function is now

2037
01:26:24,118 --> 01:26:26,876
shaped more risk aversely.

2038
01:26:27,068 --> 01:26:29,570
And then if I decrease this even more

2039
01:26:31,540 --> 01:26:33,696
down to negative eight, you can see that

2040
01:26:33,718 --> 01:26:36,752
they never even go for playing. Because

2041
01:26:36,806 --> 01:26:38,516
even once they're very certain that the

2042
01:26:38,538 --> 01:26:40,404
left arm is better, it's still too

2043
01:26:40,442 --> 01:26:43,124
risky, given their beliefs about the

2044
01:26:43,162 --> 01:26:46,176
payoff structure because their beliefs

2045
01:26:46,208 --> 01:26:47,956
about the payoff structure are such that

2046
01:26:47,978 --> 01:26:49,560
they believe that there's still a 20%

2047
01:26:49,630 --> 01:26:51,496
chance that they'll get. Costa. But if

2048
01:26:51,518 --> 01:26:53,944
we change this and said what if their p

2049
01:26:53,982 --> 01:26:57,352
reward was 1.0 or,

2050
01:26:57,406 --> 01:26:59,130
say, zero point 99?

2051
01:27:03,360 --> 01:27:06,364
Then they're willing, even despite the

2052
01:27:06,482 --> 01:27:10,332
great risk of being punished because the

2053
01:27:10,466 --> 01:27:12,716
expected reward given, you know, the

2054
01:27:12,738 --> 01:27:15,552
context is high enough, they will still

2055
01:27:15,606 --> 01:27:18,608
end up risking it and they acquire the

2056
01:27:18,614 --> 01:27:19,824
hint for some time and then they start

2057
01:27:19,862 --> 01:27:23,712
risking it. But the observations will,

2058
01:27:23,846 --> 01:27:27,308
because peer is so high, their beliefs

2059
01:27:27,324 --> 01:27:28,716
about the payoff structure, their

2060
01:27:28,758 --> 01:27:30,356
beliefs will kind of oscillate as the

2061
01:27:30,378 --> 01:27:32,084
observations actually change, because

2062
01:27:32,122 --> 01:27:33,844
the true observations are generated much

2063
01:27:33,882 --> 01:27:35,796
more stochastically, because this is the

2064
01:27:35,818 --> 01:27:38,884
P reward of the bandit. So you can mess

2065
01:27:38,922 --> 01:27:41,476
around with this. And I would encourage,

2066
01:27:41,508 --> 01:27:44,600
if anyone listening now or afterwards

2067
01:27:45,660 --> 01:27:47,448
wants to mess with these parameters, I

2068
01:27:47,454 --> 01:27:49,048
would encourage you to just go crazy and

2069
01:27:49,054 --> 01:27:50,184
mess with parameters and see what

2070
01:27:50,222 --> 01:27:52,350
different kinds of behavior you can get.

2071
01:27:56,240 --> 01:27:59,390
Okay, so that pretty much wraps up the

2072
01:27:59,840 --> 01:28:02,140
main brunt of the entorhinal.

2073
01:28:03,040 --> 01:28:04,416
Let's pause there for questions because

2074
01:28:04,438 --> 01:28:06,528
I have additional material about

2075
01:28:06,614 --> 01:28:08,716
learning parameters that we discussed

2076
01:28:08,748 --> 01:28:12,144
last time would be good to get

2077
01:28:12,182 --> 01:28:13,388
into because that's something that's

2078
01:28:13,404 --> 01:28:14,896
really underdocumented right now with

2079
01:28:14,918 --> 01:28:18,244
PMDP. So we can move into

2080
01:28:18,282 --> 01:28:19,444
that. But I think we should first break

2081
01:28:19,482 --> 01:28:20,550
for some questions.

2082
01:28:23,080 --> 01:28:26,436
Awesome. Thank you. Jacob if you ant to

2083
01:28:26,458 --> 01:28:29,704
ask or Karl. Otherwise, I'm happy to

2084
01:28:29,742 --> 01:28:33,130
hear about learning. Cool.

2085
01:28:38,020 --> 01:28:39,936
Let's do learning and then we'll have

2086
01:28:39,958 --> 01:28:42,370
and closing questions at the end.

2087
01:28:43,240 --> 01:28:43,990
Perfect.

2088
01:28:46,760 --> 01:28:50,310
Okay, I'll have some quick slides. So

2089
01:28:51,800 --> 01:28:53,952
learning under active inference is cast

2090
01:28:54,016 --> 01:28:57,284
as updating beliefs about the generative

2091
01:28:57,332 --> 01:29:00,788
model parameters itself. So inference

2092
01:29:00,804 --> 01:29:02,072
is one thing. Inference is saying,

2093
01:29:02,126 --> 01:29:03,736
given my generative models, so my

2094
01:29:03,758 --> 01:29:06,696
beliefs about the way the world works,

2095
01:29:06,878 --> 01:29:08,956
what is the best explanation in the

2096
01:29:08,978 --> 01:29:10,940
sense of posterior over hidden states?

2097
01:29:11,010 --> 01:29:13,900
And policies that explains my actual

2098
01:29:13,970 --> 01:29:16,056
data. And you get that by minimizing

2099
01:29:16,088 --> 01:29:17,870
variational free energy. Learning

2100
01:29:19,040 --> 01:29:22,344
becomes much more complex but also more

2101
01:29:22,402 --> 01:29:23,776
interesting in the sense that if the

2102
01:29:23,798 --> 01:29:25,536
agent's generative model itself is

2103
01:29:25,558 --> 01:29:28,332
wrong, they can change the generative

2104
01:29:28,396 --> 01:29:31,184
model to also optimize variational free

2105
01:29:31,222 --> 01:29:33,456
energy. So learning and inference can

2106
01:29:33,478 --> 01:29:36,608
kind of cooperate or sometimes interfere

2107
01:29:36,624 --> 01:29:39,904
with each other as we'll see to minimize

2108
01:29:40,032 --> 01:29:42,276
variational free energy. So the way we

2109
01:29:42,298 --> 01:29:44,004
have to start by doing this is now

2110
01:29:44,122 --> 01:29:46,504
treating the parameters themselves. So

2111
01:29:46,542 --> 01:29:48,744
the parameters of the A array which are

2112
01:29:48,782 --> 01:29:51,464
categorical likelihood parameters, b

2113
01:29:51,502 --> 01:29:54,616
array, D array, CRA those themselves now

2114
01:29:54,638 --> 01:29:56,936
become random variables over which we

2115
01:29:56,958 --> 01:29:59,020
can have priors and of course

2116
01:29:59,090 --> 01:30:00,780
variational posteriors.

2117
01:30:02,240 --> 01:30:05,724
So we can go back to our original A or

2118
01:30:05,762 --> 01:30:08,476
palm DP representation. So now what we

2119
01:30:08,498 --> 01:30:10,776
see is in this third column next to

2120
01:30:10,818 --> 01:30:13,632
A-B-C and D we have parameters that are

2121
01:30:13,686 --> 01:30:16,960
priors over the categorical

2122
01:30:17,460 --> 01:30:20,624
parameters of the A-B-C and D. So a

2123
01:30:20,662 --> 01:30:23,376
natural prior for these sorts of

2124
01:30:23,398 --> 01:30:25,036
categorical variables is called the deer

2125
01:30:25,068 --> 01:30:28,516
schley distribution which is basically a

2126
01:30:28,538 --> 01:30:30,464
conjugate prior for a categorical

2127
01:30:30,512 --> 01:30:31,888
likelihood distribution. That's why it's

2128
01:30:31,904 --> 01:30:34,516
very nice and also the values of its

2129
01:30:34,538 --> 01:30:36,680
parameters have a very nice intuitive

2130
01:30:37,420 --> 01:30:40,360
feeling and interpretability to them.

2131
01:30:40,430 --> 01:30:42,904
So now the agents will have priors which

2132
01:30:42,942 --> 01:30:45,770
are updated by this p of Phi at the top.

2133
01:30:47,100 --> 01:30:49,336
And phi is just a collection of all

2134
01:30:49,358 --> 01:30:50,904
these deer schleich hyper parameters.

2135
01:30:50,952 --> 01:30:53,096
They're also called or prior parameters

2136
01:30:53,208 --> 01:30:55,868
and these are parameters or priors over

2137
01:30:55,954 --> 01:30:57,884
random variables that themselves are the

2138
01:30:57,922 --> 01:30:59,916
likelihood distinctions and priors of

2139
01:30:59,938 --> 01:31:02,556
the generative model. So we're just

2140
01:31:02,578 --> 01:31:05,152
going to do a few instances of learning

2141
01:31:05,206 --> 01:31:06,336
today. I don't know if we'll have time

2142
01:31:06,358 --> 01:31:08,576
to do B or D learning. We'll start with

2143
01:31:08,598 --> 01:31:11,776
a matrix learning but

2144
01:31:11,798 --> 01:31:13,536
the principle applies the same. So

2145
01:31:13,638 --> 01:31:15,128
here's an example of the deer slate

2146
01:31:15,164 --> 01:31:17,344
prior distribution over some categorical

2147
01:31:17,392 --> 01:31:20,436
parameters. So let's say our a matrix or

2148
01:31:20,458 --> 01:31:22,752
A array, let's just say it's a matrix.

2149
01:31:22,896 --> 01:31:25,364
So now the random variable itself are

2150
01:31:25,402 --> 01:31:28,820
the entries of the A matrix. A prior

2151
01:31:28,980 --> 01:31:31,288
over those entries is something called a

2152
01:31:31,294 --> 01:31:33,496
deer schley distribution which is just a

2153
01:31:33,518 --> 01:31:36,824
vector of positive real numbers. And

2154
01:31:36,862 --> 01:31:38,984
here we've reshaped it so that it has

2155
01:31:39,022 --> 01:31:41,724
the shape of an array. So let's say this

2156
01:31:41,762 --> 01:31:43,736
array represents like the payoff matrix

2157
01:31:43,768 --> 01:31:46,536
in our bandit task. So the two columns

2158
01:31:46,568 --> 01:31:47,996
or two possible hidden states are

2159
01:31:48,018 --> 01:31:51,216
context one, context two and then the

2160
01:31:51,238 --> 01:31:52,896
two observations are punishment and

2161
01:31:52,918 --> 01:31:56,448
reward. So if this is our prior which is

2162
01:31:56,534 --> 01:31:58,380
measured by these deer schley

2163
01:31:58,540 --> 01:32:02,444
parameters, the likelihood

2164
01:32:02,492 --> 01:32:04,252
distribution that they parameterisation

2165
01:32:04,396 --> 01:32:06,004
also you can express this as the

2166
01:32:06,042 --> 01:32:07,728
expected value of the deer sleigh

2167
01:32:07,744 --> 01:32:09,972
distribution is a categorical with these

2168
01:32:10,026 --> 01:32:12,644
values. So what you can see is that the

2169
01:32:12,682 --> 01:32:16,472
deer Shlay counts like the

2170
01:32:16,606 --> 01:32:18,468
kind of scalar magnitude of the deer

2171
01:32:18,484 --> 01:32:20,536
slate parameters kind of represent a

2172
01:32:20,558 --> 01:32:24,410
prior coherence about the probability of

2173
01:32:25,180 --> 01:32:27,748
of the different contingencies encoded

2174
01:32:27,764 --> 01:32:30,232
in the A matrix. So I made these, these

2175
01:32:30,286 --> 01:32:33,432
very simple here like the the

2176
01:32:33,486 --> 01:32:36,668
deer slate priors are nine counts for

2177
01:32:36,754 --> 01:32:38,796
seeing punishment given context and one

2178
01:32:38,818 --> 01:32:40,472
count for seeing reward given context

2179
01:32:40,536 --> 01:32:43,448
one. But you can change those to very

2180
01:32:43,554 --> 01:32:46,224
high numbers. So for instance, if that

2181
01:32:46,262 --> 01:32:48,048
nine on the left was changed to a

2182
01:32:48,054 --> 01:32:50,176
10,000, then on the right the

2183
01:32:50,198 --> 01:32:53,424
probabilities would become like 0.99 to

2184
01:32:53,462 --> 01:32:57,056
.00,001. So the scale of the deer

2185
01:32:57,088 --> 01:32:59,524
schley, also known as pseudo count

2186
01:32:59,562 --> 01:33:02,230
parameters, encodes something like a

2187
01:33:03,000 --> 01:33:04,804
belief about how many times that

2188
01:33:04,842 --> 01:33:06,656
particular coincidence of observation

2189
01:33:06,688 --> 01:33:08,564
and hidden state has been observed,

2190
01:33:08,692 --> 01:33:10,216
which you can also think of as like a

2191
01:33:10,238 --> 01:33:12,760
prior confidence about that contingency

2192
01:33:13,660 --> 01:33:15,896
and the expectation to create your A

2193
01:33:15,918 --> 01:33:18,388
matrix via this. Going from a deer slate

2194
01:33:18,404 --> 01:33:20,536
to an A array is very simple because you

2195
01:33:20,558 --> 01:33:23,324
just take each deer slate count and

2196
01:33:23,362 --> 01:33:25,884
divide it by the column wise sum, which

2197
01:33:25,922 --> 01:33:27,932
is this a not variable on the lower

2198
01:33:27,986 --> 01:33:29,756
right. So it's just that particular

2199
01:33:29,858 --> 01:33:33,520
value of the A array and divided by

2200
01:33:33,670 --> 01:33:36,748
the sum of the counts. So that's

2201
01:33:36,764 --> 01:33:38,544
how you go from a deer slate prior over

2202
01:33:38,582 --> 01:33:40,972
a categorical likelihood distribution

2203
01:33:41,036 --> 01:33:44,736
through the expectation and

2204
01:33:44,758 --> 01:33:46,308
then inference. And I'm not going to

2205
01:33:46,314 --> 01:33:48,528
guide into the variational posterior,

2206
01:33:48,544 --> 01:33:50,496
but it's very simple. So when you're

2207
01:33:50,528 --> 01:33:51,876
doing learning and you're trying to

2208
01:33:51,898 --> 01:33:54,276
actually update these Deer parameters as

2209
01:33:54,298 --> 01:33:56,436
a function of observations, what

2210
01:33:56,458 --> 01:33:58,724
essentially you have is a new posterior

2211
01:33:58,772 --> 01:34:00,648
that's now not over hidden states of the

2212
01:34:00,654 --> 01:34:02,036
world, but you have a variational

2213
01:34:02,068 --> 01:34:03,976
posterior over the parameters the

2214
01:34:03,998 --> 01:34:07,396
categorical or rather a variational

2215
01:34:07,428 --> 01:34:09,588
posterior over the deer distribution,

2216
01:34:09,684 --> 01:34:11,516
the deer slay distinctions that

2217
01:34:11,618 --> 01:34:14,136
parameterizes your a matrix. So that's

2218
01:34:14,168 --> 01:34:15,996
what's representing the lower right. So

2219
01:34:16,018 --> 01:34:18,508
let's assume that our beliefs about the

2220
01:34:18,514 --> 01:34:21,196
deer shay parameters were as it is now.

2221
01:34:21,218 --> 01:34:24,176
So your beliefs about the A matrix and

2222
01:34:24,198 --> 01:34:27,216
then we get an observation and let's say

2223
01:34:27,238 --> 01:34:28,912
that we saw the conversation of

2224
01:34:28,966 --> 01:34:31,516
punishment and that can be represented

2225
01:34:31,548 --> 01:34:34,496
by this one hot vector. Now we want to

2226
01:34:34,518 --> 01:34:37,552
update our beliefs about the A matrix

2227
01:34:37,616 --> 01:34:40,244
given the observation, but to do that,

2228
01:34:40,282 --> 01:34:42,164
what you also need is a hidden state or

2229
01:34:42,202 --> 01:34:44,336
a belief about hidden states. And let's

2230
01:34:44,368 --> 01:34:47,264
say that the agent was very confident

2231
01:34:47,312 --> 01:34:49,450
that the hidden state was concept one.

2232
01:34:49,980 --> 01:34:51,796
What ends up happening to the resulting

2233
01:34:51,828 --> 01:34:54,872
posterior over the A matrix is a very

2234
01:34:54,926 --> 01:34:57,716
simple associative, quasi associative

2235
01:34:57,748 --> 01:35:00,360
learning rule where the update to the

2236
01:35:00,510 --> 01:35:04,444
deer schley represented by this bold a

2237
01:35:04,482 --> 01:35:06,936
SUBQ becomes the prior over the deer

2238
01:35:06,968 --> 01:35:10,428
sleigh parameters plus the outer product

2239
01:35:10,514 --> 01:35:12,668
between the observation vector and the

2240
01:35:12,754 --> 01:35:16,560
hidden state belief vector. So this is

2241
01:35:16,630 --> 01:35:18,204
kind of like a form of coincidence

2242
01:35:18,252 --> 01:35:20,636
detection where you just see what parts

2243
01:35:20,668 --> 01:35:22,304
of the hidden states line up with what

2244
01:35:22,342 --> 01:35:23,824
parts of the observations and you

2245
01:35:23,862 --> 01:35:25,636
increment your beliefs about the A

2246
01:35:25,658 --> 01:35:28,084
matrix accordingly. So in this case, if

2247
01:35:28,122 --> 01:35:30,404
I really believe the concept was one and

2248
01:35:30,442 --> 01:35:32,724
I saw a punishment, then my belief about

2249
01:35:32,762 --> 01:35:35,300
that particular contingency seeing

2250
01:35:35,370 --> 01:35:37,088
punishment under context one would just

2251
01:35:37,114 --> 01:35:39,130
be incremented by a plus one.

2252
01:35:40,300 --> 01:35:42,328
And that's what this outer product at

2253
01:35:42,334 --> 01:35:44,484
the lower right calculates. It computes

2254
01:35:44,612 --> 01:35:47,496
a matrix that is the increment to your

2255
01:35:47,518 --> 01:35:49,576
beliefs about the A matrix. So in this

2256
01:35:49,598 --> 01:35:51,356
case, the matrix would be have one in

2257
01:35:51,378 --> 01:35:53,116
the upper left and then zeros in the

2258
01:35:53,138 --> 01:35:55,276
other three entries. And you use that to

2259
01:35:55,298 --> 01:35:58,460
kind of increment your A matrix.

2260
01:35:58,960 --> 01:36:00,664
Technically you're incrementing a deer

2261
01:36:00,712 --> 01:36:03,536
schley kind of conjugate prior over your

2262
01:36:03,558 --> 01:36:07,264
A matrix, but it's really

2263
01:36:07,302 --> 01:36:09,920
a variational deer schley posterior.

2264
01:36:10,260 --> 01:36:12,316
But you can imagine if your hidden

2265
01:36:12,348 --> 01:36:13,856
states are also contaminated with

2266
01:36:13,878 --> 01:36:17,268
uncertainty. So say you had 50%, you

2267
01:36:17,274 --> 01:36:18,996
were 50 50, whether it was concept one

2268
01:36:19,018 --> 01:36:21,524
or context two. Then similarly with this

2269
01:36:21,562 --> 01:36:23,924
a matrix update, the update would then

2270
01:36:23,962 --> 01:36:27,956
be spread over the two possible

2271
01:36:28,138 --> 01:36:30,196
contingencies. So if you saw an

2272
01:36:30,218 --> 01:36:31,636
observation but you weren't sure what

2273
01:36:31,658 --> 01:36:34,856
the hidden state was, then both just the

2274
01:36:34,878 --> 01:36:36,724
overall probability of seeing punishment

2275
01:36:36,772 --> 01:36:38,424
under your generative model would go up

2276
01:36:38,462 --> 01:36:39,720
because you would increment that entire

2277
01:36:39,790 --> 01:36:42,280
row of the A matrix within this case

2278
01:36:42,350 --> 01:36:45,196
0.5. So that's just an important thing

2279
01:36:45,218 --> 01:36:47,180
to note is that uncertainty in your own

2280
01:36:47,250 --> 01:36:49,644
hidden state beliefs will bleed into the

2281
01:36:49,762 --> 01:36:51,980
updates to the deer sleigh parameters

2282
01:36:53,200 --> 01:36:55,740
and oftentimes alongside,

2283
01:36:56,720 --> 01:36:59,884
I mean optimally alongside a matrix

2284
01:36:59,932 --> 01:37:02,796
learning or parameter learning. You're

2285
01:37:02,828 --> 01:37:05,392
also going to be augmenting your

2286
01:37:05,446 --> 01:37:07,216
expected free energy because your

2287
01:37:07,238 --> 01:37:08,628
generative models now different. So you

2288
01:37:08,634 --> 01:37:10,368
have these new priors and posteriors

2289
01:37:10,464 --> 01:37:12,516
with a so called parameter information

2290
01:37:12,618 --> 01:37:15,204
gain term or a novelty term. So while

2291
01:37:15,242 --> 01:37:17,064
you're pursuing learning, it also makes

2292
01:37:17,102 --> 01:37:20,072
sense to choose your policies such that

2293
01:37:20,206 --> 01:37:23,992
you'll maximize the

2294
01:37:24,046 --> 01:37:26,088
information you get based on the

2295
01:37:26,094 --> 01:37:28,388
consequences of your policies about the

2296
01:37:28,414 --> 01:37:30,604
parameters of the generative model. So

2297
01:37:30,722 --> 01:37:33,308
this expected KL divergence exactly

2298
01:37:33,394 --> 01:37:35,804
quantifies how much a given policy will

2299
01:37:35,842 --> 01:37:38,796
lead to a good Bayesian update of your

2300
01:37:38,818 --> 01:37:42,432
parameter beliefs. So intuitively this

2301
01:37:42,486 --> 01:37:45,776
quantity might be described as how much

2302
01:37:45,798 --> 01:37:47,616
do I expect the consequences of my

2303
01:37:47,638 --> 01:37:49,872
actions will update my beliefs about

2304
01:37:49,926 --> 01:37:52,044
parameters. So consequences of actions

2305
01:37:52,092 --> 01:37:55,104
is represented by that Q of O given pi,

2306
01:37:55,232 --> 01:37:59,188
the thing that the KL divergence is

2307
01:37:59,354 --> 01:38:01,956
taken under expectation of. And then the

2308
01:38:01,978 --> 01:38:04,164
actual KL divergence is saying how much

2309
01:38:04,202 --> 01:38:05,764
surprise will I get given these

2310
01:38:05,802 --> 01:38:09,412
observations relative to my current

2311
01:38:09,466 --> 01:38:11,268
beliefs about the parameters of the

2312
01:38:11,274 --> 01:38:12,836
generative model? So this is what's

2313
01:38:12,868 --> 01:38:14,292
called in the literature of the novelty

2314
01:38:14,356 --> 01:38:17,256
term and it's very easy to

2315
01:38:17,358 --> 01:38:19,384
experimentally turn off or on this

2316
01:38:19,422 --> 01:38:23,256
novelty term using simple flags in

2317
01:38:23,278 --> 01:38:25,148
the agent class. And this goes for the

2318
01:38:25,154 --> 01:38:26,876
other components of the variation or the

2319
01:38:26,898 --> 01:38:28,316
expected free energy as well. You can

2320
01:38:28,338 --> 01:38:30,796
kind of turn on flags that say do I want

2321
01:38:30,818 --> 01:38:32,424
to use this novelty or parameter

2322
01:38:32,472 --> 01:38:34,624
information gain? Do I want to use the

2323
01:38:34,662 --> 01:38:36,656
state info gain which is the same as the

2324
01:38:36,678 --> 01:38:39,692
epistemic value or the Bayesian surprise

2325
01:38:39,836 --> 01:38:41,452
and then do I want to use the utility?

2326
01:38:41,516 --> 01:38:43,584
So for the learning simulations, it

2327
01:38:43,622 --> 01:38:46,084
makes sense if you're doing learning to

2328
01:38:46,122 --> 01:38:47,616
make sure that this parameter is turned

2329
01:38:47,648 --> 01:38:51,124
on. Okay,

2330
01:38:51,162 --> 01:38:54,052
so. That's the kind of slides on

2331
01:38:54,186 --> 01:38:55,716
learning. And now we can actually get

2332
01:38:55,738 --> 01:38:57,940
into implementing this in Pinevp.

2333
01:39:01,340 --> 01:39:05,096
So we

2334
01:39:05,118 --> 01:39:07,300
first will create an A matrix and we'll

2335
01:39:07,380 --> 01:39:10,952
let the agent have very slight positive

2336
01:39:11,016 --> 01:39:13,820
beliefs about the reward contingencies.

2337
01:39:14,240 --> 01:39:16,536
And I'll explain later why this helps.

2338
01:39:16,568 --> 01:39:17,928
It helps with learning if they don't

2339
01:39:17,944 --> 01:39:20,344
have total ignorance about the reward

2340
01:39:20,392 --> 01:39:22,156
probabilities but they have some bias in

2341
01:39:22,178 --> 01:39:23,468
some direction. It doesn't actually have

2342
01:39:23,474 --> 01:39:24,848
to be zero point 51, it could be the

2343
01:39:24,854 --> 01:39:28,092
other way. And then there's utility

2344
01:39:28,156 --> 01:39:30,204
functions that allow you to create deer

2345
01:39:30,252 --> 01:39:32,592
schley variables that have the same

2346
01:39:32,646 --> 01:39:36,324
shape as some base A array. So here

2347
01:39:36,522 --> 01:39:40,672
this PA variable

2348
01:39:40,736 --> 01:39:44,112
is basically the prior that bold a SUBP

2349
01:39:44,176 --> 01:39:45,696
variable that represents the agent's

2350
01:39:45,728 --> 01:39:48,676
deer schleich prior over the A matrix.

2351
01:39:48,788 --> 01:39:50,548
So this is now a new variable that we're

2352
01:39:50,564 --> 01:39:54,296
going to pass in to the

2353
01:39:54,318 --> 01:39:56,376
agent Constructor. So if our A matrix is

2354
01:39:56,398 --> 01:40:05,312
like let's look at the reward

2355
01:40:05,396 --> 01:40:09,000
contingency, reward modality.

2356
01:40:09,080 --> 01:40:11,516
So that's a one. So this is the agent's

2357
01:40:11,548 --> 01:40:13,164
current beliefs about the payoff

2358
01:40:13,212 --> 01:40:17,520
structure, right? So under choose

2359
01:40:17,590 --> 01:40:19,504
left and choose right. Those are the two

2360
01:40:19,542 --> 01:40:21,116
contingencies. Given the two hidden

2361
01:40:21,148 --> 01:40:24,580
states, PA will have the same structure

2362
01:40:26,760 --> 01:40:29,172
except that it'll have those

2363
01:40:29,226 --> 01:40:31,696
contingencies encoded in terms of deer

2364
01:40:31,728 --> 01:40:33,830
sleigh pseudo counts. So if I made them

2365
01:40:34,600 --> 01:40:36,710
made the pseudo count scale ten,

2366
01:40:37,480 --> 01:40:41,320
then they're very relatively confident

2367
01:40:41,740 --> 01:40:43,864
that the payoff probabilities look like

2368
01:40:43,902 --> 01:40:46,120
this. But again, these are not

2369
01:40:46,190 --> 01:40:47,764
probabilities, they're deer slate

2370
01:40:47,812 --> 01:40:50,604
parameters that parameterize a

2371
01:40:50,802 --> 01:40:53,244
categorical likelihood. So you can use

2372
01:40:53,282 --> 01:40:55,196
the normalized distribution function to

2373
01:40:55,218 --> 01:40:57,336
actually then visualize the deer slate

2374
01:40:57,368 --> 01:40:58,732
distribution in terms of actual

2375
01:40:58,786 --> 01:41:02,012
categorical parameters. So taking

2376
01:41:02,066 --> 01:41:04,072
the expectation I e. The normalization

2377
01:41:04,136 --> 01:41:05,744
of the deer slay prior will give you

2378
01:41:05,782 --> 01:41:07,810
exactly this.

2379
01:41:09,860 --> 01:41:12,208
So if I say are these two things the

2380
01:41:12,214 --> 01:41:14,692
same? They should be the same. Okay,

2381
01:41:14,746 --> 01:41:16,896
maybe down to numerical differences,

2382
01:41:16,928 --> 01:41:17,670
they're not.

2383
01:41:22,200 --> 01:41:23,796
Okay? So yeah, that's how you

2384
01:41:23,818 --> 01:41:26,996
parameterize that. So we'll create this

2385
01:41:27,018 --> 01:41:28,656
is an important point that's also used

2386
01:41:28,698 --> 01:41:31,032
in SPM. Often we want certain

2387
01:41:31,086 --> 01:41:33,576
contingencies to be unavailable to

2388
01:41:33,598 --> 01:41:35,096
learning. So we assume these are

2389
01:41:35,118 --> 01:41:36,808
contingencies that are baked into the

2390
01:41:36,814 --> 01:41:38,356
agent's beliefs about the world and thus

2391
01:41:38,388 --> 01:41:40,956
not adaptable. So one way, and this is

2392
01:41:40,978 --> 01:41:42,636
just barred from the SPM way of doing

2393
01:41:42,658 --> 01:41:45,944
it, to encode that is to bake

2394
01:41:45,992 --> 01:41:49,944
in a kind of really precise

2395
01:41:50,072 --> 01:41:52,248
confidence or very high confidence that

2396
01:41:52,274 --> 01:41:54,976
certain contingencies are the case. And

2397
01:41:54,998 --> 01:41:56,576
you can just do that by adjusting the

2398
01:41:56,598 --> 01:41:58,780
scale parameter for particular indices.

2399
01:41:58,940 --> 01:42:01,504
For instance, by doing this I'm just

2400
01:42:01,542 --> 01:42:04,800
telling the agent that it essentially

2401
01:42:04,880 --> 01:42:07,824
doesn't learn the contingencies related

2402
01:42:07,872 --> 01:42:11,636
to the null modality. So for

2403
01:42:11,658 --> 01:42:15,350
instance, if you're in the

2404
01:42:15,720 --> 01:42:17,784
start state it believes with really high

2405
01:42:17,822 --> 01:42:19,288
confidence that you'll always get the

2406
01:42:19,294 --> 01:42:21,528
null observation. And we just

2407
01:42:21,694 --> 01:42:23,736
operationalize that by creating very

2408
01:42:23,838 --> 01:42:26,900
high pseudo count or deer sleigh priors

2409
01:42:26,980 --> 01:42:29,268
over that particular slice of the A

2410
01:42:29,294 --> 01:42:32,732
matrix. So that's an important point

2411
01:42:32,786 --> 01:42:35,804
to do. And then we'll just write all

2412
01:42:35,842 --> 01:42:37,644
this stuff. So this prior count about

2413
01:42:37,682 --> 01:42:39,928
the Bull observations and then the scale

2414
01:42:40,024 --> 01:42:42,184
that determines their general confidence

2415
01:42:42,232 --> 01:42:44,944
outside of this null thing. We'll write

2416
01:42:44,982 --> 01:42:46,368
that all into a function so that we can

2417
01:42:46,374 --> 01:42:49,856
then parameterize our PA. And then

2418
01:42:49,878 --> 01:42:52,384
we now write a new active inference with

2419
01:42:52,422 --> 01:42:54,870
learning loop where instead of just

2420
01:42:55,640 --> 01:42:57,876
storing the history of choices and

2421
01:42:57,898 --> 01:43:00,516
beliefs, we also store the history of

2422
01:43:00,538 --> 01:43:01,936
their beliefs about the Dean Shlay

2423
01:43:01,968 --> 01:43:06,004
parameters. And an important thing that

2424
01:43:06,042 --> 01:43:07,924
you can also do in PMDP, which is nice,

2425
01:43:07,962 --> 01:43:10,840
is you can say I only want to learn

2426
01:43:10,910 --> 01:43:13,064
particular modalities. So when you're

2427
01:43:13,102 --> 01:43:14,888
creating the agent class, there's a

2428
01:43:14,894 --> 01:43:16,376
bunch of arguments you can pass in, but

2429
01:43:16,398 --> 01:43:18,264
one of them is I only want to be

2430
01:43:18,302 --> 01:43:20,484
learning the reward payoff modality

2431
01:43:20,532 --> 01:43:22,668
right now. And this can change. You

2432
01:43:22,674 --> 01:43:25,304
could have them learn the hint accuracy

2433
01:43:25,352 --> 01:43:27,724
as well. But by passing in a list of

2434
01:43:27,762 --> 01:43:30,284
which of the modality indices that you

2435
01:43:30,322 --> 01:43:32,172
want them to learn, you turn off

2436
01:43:32,226 --> 01:43:34,044
learning on all the other modalities,

2437
01:43:34,172 --> 01:43:37,328
which normally in SPM or what we used to

2438
01:43:37,334 --> 01:43:39,456
have to do in pi MDP is. You just have

2439
01:43:39,478 --> 01:43:42,076
to turn up those deer slay pseudo counts

2440
01:43:42,108 --> 01:43:44,256
super high on all the modalities that

2441
01:43:44,278 --> 01:43:46,848
you don't want to learn. But if there

2442
01:43:46,854 --> 01:43:48,708
are other modalities that you don't want

2443
01:43:48,714 --> 01:43:50,676
to learn now you can just pass in this

2444
01:43:50,698 --> 01:43:52,116
list of modalities that you want to

2445
01:43:52,138 --> 01:43:54,608
learn and it'll only focus learning onto

2446
01:43:54,624 --> 01:43:57,030
that. So now I'm setting up an agent

2447
01:43:57,640 --> 01:44:00,504
that has these particular beliefs about

2448
01:44:00,622 --> 01:44:03,896
the world via A and now has a prior that

2449
01:44:03,918 --> 01:44:06,120
is going to update through doing

2450
01:44:06,190 --> 01:44:08,890
variational inference or learning.

2451
01:44:09,260 --> 01:44:11,396
And then so we'll create the generative

2452
01:44:11,428 --> 01:44:13,764
model here, including this new prior

2453
01:44:13,812 --> 01:44:16,216
over A and then we'll run the active

2454
01:44:16,248 --> 01:44:18,684
inference loop with learning which

2455
01:44:18,722 --> 01:44:21,164
involves creating an agent that can only

2456
01:44:21,202 --> 01:44:22,696
do learning on the payoff structure

2457
01:44:22,728 --> 01:44:24,352
modality. So we want the agent to now

2458
01:44:24,406 --> 01:44:28,048
learn which arm is best basically

2459
01:44:28,134 --> 01:44:29,936
because it doesn't know the payoffs and

2460
01:44:29,958 --> 01:44:31,616
then also to use parameter information

2461
01:44:31,718 --> 01:44:34,116
gain to motivate its decision. And

2462
01:44:34,138 --> 01:44:35,396
there's another thing I forgot to

2463
01:44:35,418 --> 01:44:37,476
mention, which is the learning rate,

2464
01:44:37,658 --> 01:44:39,876
which is how much they increment their

2465
01:44:39,898 --> 01:44:44,260
beliefs about the posterior

2466
01:44:45,160 --> 01:44:47,376
or about the A matrix using this update

2467
01:44:47,408 --> 01:44:48,868
rule. So there's something I didn't

2468
01:44:48,884 --> 01:44:50,264
mention. There's often a learning rate

2469
01:44:50,302 --> 01:44:52,596
that's added here that basically scales

2470
01:44:52,628 --> 01:44:56,424
how big this update is so that

2471
01:44:56,622 --> 01:44:58,716
you can experiment. It depends on the

2472
01:44:58,738 --> 01:45:01,036
application, what the scale of that is

2473
01:45:01,058 --> 01:45:02,910
going to be, but the default is one.

2474
01:45:05,120 --> 01:45:08,892
Okay, so in this example, the agent

2475
01:45:08,946 --> 01:45:11,230
gets the hint for one time step.

2476
01:45:13,380 --> 01:45:15,184
It's got the standard like negative four

2477
01:45:15,222 --> 01:45:18,336
punishment and then it goes straight to

2478
01:45:18,358 --> 01:45:21,692
the right because it believes the hint

2479
01:45:21,756 --> 01:45:24,544
is accurate. So it gets a reward is

2480
01:45:24,582 --> 01:45:26,908
right, then it goes and starts playing

2481
01:45:26,924 --> 01:45:30,016
the right arm and you see it's posterior

2482
01:45:30,048 --> 01:45:33,156
beliefs instantly go to right. And now

2483
01:45:33,258 --> 01:45:35,332
since what we've also spit out of this

2484
01:45:35,386 --> 01:45:36,836
active coherence group is the beliefs

2485
01:45:36,868 --> 01:45:40,932
about the A matrix in this QA

2486
01:45:41,076 --> 01:45:44,264
posterior over A history we can plot its

2487
01:45:44,302 --> 01:45:48,548
beliefs about the A matrix probability

2488
01:45:48,644 --> 01:45:50,600
over the contingency of seeing reward

2489
01:45:50,680 --> 01:45:54,156
given that I was in the right arm. And

2490
01:45:54,178 --> 01:45:55,644
what you see is that even though they

2491
01:45:55,682 --> 01:45:58,444
start with basically 50 50 beliefs as

2492
01:45:58,482 --> 01:46:01,736
they gather observations, their beliefs

2493
01:46:01,768 --> 01:46:04,192
about that posterior probability over

2494
01:46:04,246 --> 01:46:06,252
that particular energy of the A matrix

2495
01:46:06,316 --> 01:46:08,608
get bigger and bigger. An interesting

2496
01:46:08,694 --> 01:46:10,588
consequence of this is their beliefs

2497
01:46:10,604 --> 01:46:12,604
about the left arm contingencies don't

2498
01:46:12,652 --> 01:46:13,844
change because they don't ever

2499
01:46:13,882 --> 01:46:16,710
experience that state of the world.

2500
01:46:17,640 --> 01:46:20,596
So that's like an interesting, what you

2501
01:46:20,618 --> 01:46:23,430
might call in machine learning.

2502
01:46:24,920 --> 01:46:27,008
It's not really a bad bootstrap but it's

2503
01:46:27,024 --> 01:46:30,424
the idea of selective sampling. So you

2504
01:46:30,462 --> 01:46:33,304
only learn those contingencies that are

2505
01:46:33,342 --> 01:46:34,936
selective to the part of the world that

2506
01:46:34,958 --> 01:46:37,364
you're sampling so the agent doesn't

2507
01:46:37,412 --> 01:46:39,096
know what that other slice of the A

2508
01:46:39,118 --> 01:46:40,872
matrix looks like because it's never

2509
01:46:40,926 --> 01:46:42,556
experienced what it's like to be in the

2510
01:46:42,578 --> 01:46:45,788
left is better context and playing the

2511
01:46:45,794 --> 01:46:48,376
left arm. So it's posterior beliefs

2512
01:46:48,408 --> 01:46:50,104
about that part of the A matrix remain

2513
01:46:50,152 --> 01:46:52,316
the same but you can see that over time

2514
01:46:52,338 --> 01:46:53,976
its beliefs start to converge to zero

2515
01:46:54,018 --> 01:46:57,088
eight which is what we set in the

2516
01:46:57,094 --> 01:46:59,804
generative model. This is just basic

2517
01:46:59,852 --> 01:47:01,680
statistical learning, right? It's just

2518
01:47:01,830 --> 01:47:03,664
getting reward observations over time

2519
01:47:03,702 --> 01:47:06,356
and as it gets a sequence of reward and

2520
01:47:06,378 --> 01:47:09,264
punishment through this very associative

2521
01:47:09,312 --> 01:47:11,136
basic mechanism, it's just incrementing

2522
01:47:11,168 --> 01:47:13,328
its deer slay beliefs. And what I'm

2523
01:47:13,344 --> 01:47:14,832
showing is the normalized IED.

2524
01:47:14,896 --> 01:47:16,804
Expectation of those beliefs over time.

2525
01:47:16,842 --> 01:47:19,236
So you get something that's 0.8 but the

2526
01:47:19,258 --> 01:47:21,048
actual deer slay parameters themselves

2527
01:47:21,134 --> 01:47:24,376
will be growing like linearly in time

2528
01:47:24,478 --> 01:47:26,408
effectively depending on the

2529
01:47:26,414 --> 01:47:30,056
observations they get. Yeah, so that

2530
01:47:30,078 --> 01:47:32,556
is just the basic learning. And then

2531
01:47:32,578 --> 01:47:33,996
there's another thing you can do which

2532
01:47:34,018 --> 01:47:36,908
is take advantage of this change

2533
01:47:36,994 --> 01:47:39,064
probability. So now we allow the context

2534
01:47:39,112 --> 01:47:41,596
to change and this is one way to get

2535
01:47:41,618 --> 01:47:44,464
them to actually be able to explore and

2536
01:47:44,502 --> 01:47:46,604
learn more about both reward

2537
01:47:46,652 --> 01:47:48,224
probabilities in the landscape is allow

2538
01:47:48,262 --> 01:47:51,056
them to have not only to make the

2539
01:47:51,078 --> 01:47:52,400
environment change, but they also

2540
01:47:52,470 --> 01:47:55,810
entertain beliefs in their

2541
01:47:56,340 --> 01:47:58,508
B matrix that the environment can

2542
01:47:58,534 --> 01:47:59,956
change. So you could use this to do B

2543
01:47:59,978 --> 01:48:01,796
matrix learning as well by defining like

2544
01:48:01,818 --> 01:48:04,068
a PB variable but here we're just going

2545
01:48:04,074 --> 01:48:05,908
to have a matrix learning as we were

2546
01:48:05,914 --> 01:48:08,020
doing before. I've changed a little bit

2547
01:48:08,090 --> 01:48:10,104
the parameters to make things a little

2548
01:48:10,142 --> 01:48:12,536
more stable because sometimes you get

2549
01:48:12,558 --> 01:48:13,784
weird behavior. I mean that's something

2550
01:48:13,822 --> 01:48:15,976
we can play around with too. So now they

2551
01:48:15,998 --> 01:48:18,556
allow the environment itself can change

2552
01:48:18,578 --> 01:48:20,476
and they also in their B matrix they

2553
01:48:20,498 --> 01:48:22,588
think the environment can change. And

2554
01:48:22,594 --> 01:48:26,110
then I'll plot the history of

2555
01:48:26,480 --> 01:48:30,380
beliefs and choices. So now they

2556
01:48:30,450 --> 01:48:33,884
instantly go for playing the arms.

2557
01:48:33,932 --> 01:48:36,492
They kind of risk it. The parameter

2558
01:48:36,556 --> 01:48:38,368
information gain actually outweighs the

2559
01:48:38,374 --> 01:48:40,300
epistemic or state information gain.

2560
01:48:40,380 --> 01:48:41,804
They start playing, they gather

2561
01:48:41,852 --> 01:48:43,712
observations but they're not very

2562
01:48:43,766 --> 01:48:45,476
confident about what the state of the

2563
01:48:45,498 --> 01:48:48,180
world is because they only are getting

2564
01:48:48,250 --> 01:48:49,716
information about the hidden states from

2565
01:48:49,738 --> 01:48:51,556
the actual sequence of rewards and

2566
01:48:51,578 --> 01:48:54,628
losses. And then eventually they go to

2567
01:48:54,634 --> 01:48:57,440
the hint because probably the utility

2568
01:48:57,520 --> 01:48:59,316
becomes low because they don't know what

2569
01:48:59,338 --> 01:49:00,728
their reward probabilities are and

2570
01:49:00,734 --> 01:49:02,196
they're building their own beliefs.

2571
01:49:02,308 --> 01:49:04,696
Then they get the hint. Then the hint is

2572
01:49:04,718 --> 01:49:06,484
accurate. So they have very precise

2573
01:49:06,532 --> 01:49:07,816
beliefs about the hidden states of the

2574
01:49:07,838 --> 01:49:09,960
world and then the world actually

2575
01:49:10,030 --> 01:49:11,708
switches. So you see the red dot is the

2576
01:49:11,714 --> 01:49:13,228
actual switching statistics of the

2577
01:49:13,234 --> 01:49:15,784
bandit. And now they've kind of explored

2578
01:49:15,832 --> 01:49:18,264
both bandit arms while also updating

2579
01:49:18,312 --> 01:49:21,500
their beliefs about the bandits.

2580
01:49:22,160 --> 01:49:24,384
And you see that their beliefs about the

2581
01:49:24,422 --> 01:49:27,810
left arm are kind of bad because

2582
01:49:28,260 --> 01:49:29,756
it seems like they've probably mostly

2583
01:49:29,788 --> 01:49:31,408
gotten generative data while they're in

2584
01:49:31,414 --> 01:49:33,056
the left arm and they didn't explore it

2585
01:49:33,078 --> 01:49:36,964
very much. Or no,

2586
01:49:37,002 --> 01:49:38,356
I guess at the end they're exploring it

2587
01:49:38,378 --> 01:49:40,068
quite a bit, but their beliefs about to

2588
01:49:40,074 --> 01:49:41,748
go down because they have, I guess, a

2589
01:49:41,754 --> 01:49:43,350
bad experience with it.

2590
01:49:45,080 --> 01:49:46,408
Yeah, that's the left arm, that's the

2591
01:49:46,414 --> 01:49:48,904
right arm. But you can keep trying this

2592
01:49:48,942 --> 01:49:50,136
and mess around with different

2593
01:49:50,158 --> 01:49:51,992
parameters and you'll get different

2594
01:49:52,046 --> 01:49:55,160
sorts of beliefs.

2595
01:49:59,180 --> 01:50:01,804
So here in this example, there's some

2596
01:50:01,842 --> 01:50:03,608
switching going on. Their posteriors

2597
01:50:03,624 --> 01:50:05,644
aren't tracking very well until they

2598
01:50:05,682 --> 01:50:07,004
actually visit the hint and then their

2599
01:50:07,042 --> 01:50:08,830
posteriors start getting much more,

2600
01:50:10,480 --> 01:50:13,056
much more precise. And then at that

2601
01:50:13,078 --> 01:50:14,716
point they can start making more precise

2602
01:50:14,748 --> 01:50:18,464
beliefs. In this case, they ended up

2603
01:50:18,662 --> 01:50:21,424
kind of doing poorly on learning on both

2604
01:50:21,462 --> 01:50:23,664
of them because the true reward

2605
01:50:23,712 --> 01:50:25,990
probabilities are P eight. Yeah.

2606
01:50:27,720 --> 01:50:29,524
So everything I've talked about so far

2607
01:50:29,562 --> 01:50:31,572
is an example where learning can often

2608
01:50:31,626 --> 01:50:35,056
lead to suboptimal outcomes because it's

2609
01:50:35,088 --> 01:50:37,956
done in an online fashion. So this is an

2610
01:50:37,978 --> 01:50:41,028
interesting point of departure between

2611
01:50:41,114 --> 01:50:44,216
SPM and PMDP, but you can do all the

2612
01:50:44,238 --> 01:50:45,608
same things in SPM that you can do in

2613
01:50:45,614 --> 01:50:47,716
Pimdp. So here what I'm doing is I'm

2614
01:50:47,748 --> 01:50:49,816
updating the A matrix every time I get

2615
01:50:49,838 --> 01:50:52,676
an observation. So they do hidden state

2616
01:50:52,718 --> 01:50:54,700
coherence, they select policies,

2617
01:50:55,920 --> 01:50:58,476
they select actions, and then given the

2618
01:50:58,498 --> 01:51:00,136
last observation and the last hidden

2619
01:51:00,168 --> 01:51:02,812
state belief, they do one step of

2620
01:51:02,866 --> 01:51:04,864
parameter inference and then they use

2621
01:51:04,902 --> 01:51:07,612
the next A matrix. That's what's handled

2622
01:51:07,676 --> 01:51:10,032
in this update, a function of the agent

2623
01:51:10,086 --> 01:51:12,256
class. They update their beliefs about

2624
01:51:12,278 --> 01:51:13,776
the A matrix and they use that for

2625
01:51:13,798 --> 01:51:15,570
inference at the next time step.

2626
01:51:16,020 --> 01:51:17,956
Another way you could do this is you

2627
01:51:17,978 --> 01:51:21,104
could do an entire trial and then update

2628
01:51:21,152 --> 01:51:23,764
your A matrix at the very end of all the

2629
01:51:23,802 --> 01:51:25,968
time steps of action selection and

2630
01:51:25,994 --> 01:51:28,744
observation sampling and then use that A

2631
01:51:28,782 --> 01:51:31,096
matrix for another trial. So this is

2632
01:51:31,118 --> 01:51:34,536
kind of the difference between a

2633
01:51:34,558 --> 01:51:37,796
more em separation

2634
01:51:37,828 --> 01:51:39,844
of timescales em or expectation

2635
01:51:39,892 --> 01:51:42,100
maximization approach where given a set

2636
01:51:42,110 --> 01:51:44,524
of observations, then I update my model

2637
01:51:44,642 --> 01:51:47,144
and then I go back and I do more trials

2638
01:51:47,272 --> 01:51:49,148
without updating my model but using the

2639
01:51:49,154 --> 01:51:51,308
same fixed one. And then you can kind of

2640
01:51:51,314 --> 01:51:53,028
do that in epochs and that's typically

2641
01:51:53,064 --> 01:51:55,264
how it's done in SPM because you only do

2642
01:51:55,302 --> 01:51:57,570
parameter learning basically this part

2643
01:51:58,260 --> 01:52:01,088
outside this time loop. So you do it

2644
01:52:01,094 --> 01:52:03,636
like down here, but then what you do is

2645
01:52:03,658 --> 01:52:06,964
you run multiple trials. And the nice

2646
01:52:07,002 --> 01:52:08,804
thing about that is it kind of makes the

2647
01:52:08,842 --> 01:52:12,384
A matrix updates less likely

2648
01:52:12,432 --> 01:52:14,944
to in the moment bias your action

2649
01:52:14,992 --> 01:52:17,204
selection. So for a given set of time

2650
01:52:17,242 --> 01:52:19,896
steps, you're locked into what your A

2651
01:52:19,918 --> 01:52:22,104
matrix beliefs are and you don't do the

2652
01:52:22,142 --> 01:52:24,632
update until a set of time steps has

2653
01:52:24,686 --> 01:52:27,608
elapsed. For the purposes of this

2654
01:52:27,614 --> 01:52:29,208
entorhinal, I just did this online

2655
01:52:29,294 --> 01:52:30,984
learning thing. But as you can see,

2656
01:52:31,022 --> 01:52:32,936
that can lead to actually weirdly

2657
01:52:32,968 --> 01:52:34,616
suboptimal behavior where they don't

2658
01:52:34,648 --> 01:52:36,396
learn the true reward statistics very

2659
01:52:36,418 --> 01:52:39,228
well. And it depends on a bunch of

2660
01:52:39,234 --> 01:52:42,828
things too, like the learning rate. I

2661
01:52:42,834 --> 01:52:45,200
haven't explored this demo as much as I

2662
01:52:45,270 --> 01:52:47,136
would like, but there's a lot of

2663
01:52:47,158 --> 01:52:49,216
interesting kind of side effects. Like

2664
01:52:49,238 --> 01:52:50,992
here they're actually learning very

2665
01:52:51,046 --> 01:52:53,356
weird statistics about the bandit

2666
01:52:53,388 --> 01:52:55,392
landscape. They start kind of learning

2667
01:52:55,446 --> 01:52:57,792
it well, but then as their observations

2668
01:52:57,856 --> 01:52:59,652
keep going, they don't actually learn

2669
01:52:59,706 --> 01:53:02,016
very well here. They just avoid playing

2670
01:53:02,048 --> 01:53:03,252
because they have a bad early

2671
01:53:03,306 --> 01:53:05,028
experience. So this is an example of

2672
01:53:05,034 --> 01:53:07,092
like a bad bootstrap. And then they go

2673
01:53:07,146 --> 01:53:08,388
and just play the hint because they're

2674
01:53:08,404 --> 01:53:10,616
too scared of anything else, even though

2675
01:53:10,638 --> 01:53:12,504
their hidden states inference is perfect

2676
01:53:12,702 --> 01:53:14,664
because the hint perfectly tracks the

2677
01:53:14,702 --> 01:53:16,890
hidden state. So, yeah,

2678
01:53:17,660 --> 01:53:19,836
this is just kind of meant to be an

2679
01:53:19,858 --> 01:53:21,724
example of what you can do with

2680
01:53:21,762 --> 01:53:25,788
learning. But there's going

2681
01:53:25,794 --> 01:53:27,564
to be examples where learning actually

2682
01:53:27,682 --> 01:53:29,916
causes suboptimal behavior, but in an

2683
01:53:29,938 --> 01:53:32,700
interesting way. So here's an example

2684
01:53:32,770 --> 01:53:34,112
where they actually kind of are learning

2685
01:53:34,166 --> 01:53:36,304
the correct reward statistics. Things

2686
01:53:36,342 --> 01:53:38,352
are starting to converge to .8 for both

2687
01:53:38,406 --> 01:53:42,396
bandit arms, but it's very stochastic,

2688
01:53:42,428 --> 01:53:44,176
as you can see. And I also chose action

2689
01:53:44,208 --> 01:53:46,596
selection to be stochastic with

2690
01:53:46,618 --> 01:53:48,196
deterministic. I wonder what you would

2691
01:53:48,218 --> 01:53:51,572
get. Yeah,

2692
01:53:51,626 --> 01:53:53,412
you're there just arc maxing the

2693
01:53:53,466 --> 01:53:55,344
expected free energy or Marco mining.

2694
01:53:55,392 --> 01:53:58,724
So hint is always the most safest

2695
01:53:58,772 --> 01:54:00,376
option given their history of

2696
01:54:00,478 --> 01:54:01,480
observations.

2697
01:54:06,740 --> 01:54:10,208
If I can make one remark on that kind of

2698
01:54:10,374 --> 01:54:11,868
diversity of behaviors that we're

2699
01:54:11,884 --> 01:54:15,796
seeing, pymdp and

2700
01:54:15,818 --> 01:54:18,836
active inference are providing us a

2701
01:54:18,938 --> 01:54:22,940
space and and approach to composable

2702
01:54:23,120 --> 01:54:25,656
generative model construction that we

2703
01:54:25,678 --> 01:54:29,284
can then sift through and coevolve

2704
01:54:29,332 --> 01:54:31,528
with to find different strategies and

2705
01:54:31,534 --> 01:54:34,520
behaviors. Active inference lab or even

2706
01:54:34,590 --> 01:54:37,644
any specified generative model. It's not

2707
01:54:37,682 --> 01:54:39,980
an answer or a solution. For example,

2708
01:54:40,050 --> 01:54:42,716
to the explore explore dilemma. We see

2709
01:54:42,738 --> 01:54:45,496
this like empirically right now. Active

2710
01:54:45,528 --> 01:54:47,636
inference is not in general, resolving

2711
01:54:47,688 --> 01:54:51,024
Explore exploit. Any GM in general is

2712
01:54:51,062 --> 01:54:53,344
not resolving Explore exploit any

2713
01:54:53,382 --> 01:54:55,484
parameterization is not resolving

2714
01:54:55,532 --> 01:54:57,440
Explore exploit even for one

2715
01:54:57,510 --> 01:55:00,756
environment. It just is equivalent to

2716
01:55:00,778 --> 01:55:02,336
saying like, well, we have a linear

2717
01:55:02,448 --> 01:55:04,656
model of healthcare data, so we've

2718
01:55:04,688 --> 01:55:10,372
resolved the health care issue. And this

2719
01:55:10,426 --> 01:55:14,824
really shows the space that we build in

2720
01:55:14,942 --> 01:55:18,984
and what remains to be built is so

2721
01:55:19,102 --> 01:55:22,520
open yeah, absolutely. Yeah.

2722
01:55:22,590 --> 01:55:25,380
Because optimality is not really a

2723
01:55:25,390 --> 01:55:28,268
function of what the generative model is

2724
01:55:28,434 --> 01:55:31,516
or what the algorithm is. It's more

2725
01:55:31,538 --> 01:55:33,532
guaranteed to be optimal based on how

2726
01:55:33,586 --> 01:55:36,108
analogous the generative model and the

2727
01:55:36,114 --> 01:55:37,808
generative process are. So if the

2728
01:55:37,814 --> 01:55:39,776
generative model is a perfect model of

2729
01:55:39,798 --> 01:55:41,792
the generative process, then doing

2730
01:55:41,846 --> 01:55:44,336
Bayesian inference with respect to that

2731
01:55:44,358 --> 01:55:46,256
generative model, that is optimal for

2732
01:55:46,358 --> 01:55:49,984
everything. But how

2733
01:55:50,022 --> 01:55:51,756
you learn the generative model, that's

2734
01:55:51,788 --> 01:55:53,088
what we're seeing here. If you learn the

2735
01:55:53,094 --> 01:55:54,960
generative model in an online fashion,

2736
01:55:55,040 --> 01:55:57,012
it's not guaranteed to learn the right

2737
01:55:57,066 --> 01:55:58,436
generative model. In many cases, it

2738
01:55:58,458 --> 01:56:00,436
learns the wrong one. And this is

2739
01:56:00,458 --> 01:56:01,776
something that a lot of people in active

2740
01:56:01,808 --> 01:56:03,268
inference world have explore. For

2741
01:56:03,274 --> 01:56:05,384
instance, it's North Sajid, who's also a

2742
01:56:05,422 --> 01:56:08,232
student of Carl's, has explored a lot

2743
01:56:08,286 --> 01:56:11,976
the limitations and the boundaries of

2744
01:56:11,998 --> 01:56:13,336
parameter learning and things like

2745
01:56:13,358 --> 01:56:14,696
preference learning. Like what if you

2746
01:56:14,718 --> 01:56:16,424
were learning the C vector itself? How

2747
01:56:16,462 --> 01:56:18,536
can that be learned online in an

2748
01:56:18,558 --> 01:56:22,044
adaptive way? Yeah, and also Alec Chance

2749
01:56:22,082 --> 01:56:23,848
has that paper action Oriented models

2750
01:56:23,864 --> 01:56:25,672
where they're learning the B matrix.

2751
01:56:25,816 --> 01:56:27,448
And in that thing they're showing how

2752
01:56:27,474 --> 01:56:29,516
the agent learns kind of suboptimal

2753
01:56:29,548 --> 01:56:32,444
strategies depending on its exploration

2754
01:56:32,492 --> 01:56:35,520
of parameter space. But that also

2755
01:56:35,590 --> 01:56:39,010
actually is kind of one of the

2756
01:56:39,940 --> 01:56:41,792
benefits of active inference that paper

2757
01:56:41,846 --> 01:56:43,136
shows. Because it shows if you have an

2758
01:56:43,158 --> 01:56:45,268
agent that does have epistemic value,

2759
01:56:45,434 --> 01:56:47,316
the model it learns of the world is like

2760
01:56:47,338 --> 01:56:48,644
better than agents that don't have

2761
01:56:48,682 --> 01:56:50,976
epistemic value. But again, the models

2762
01:56:51,008 --> 01:56:52,368
are always action oriented. They're

2763
01:56:52,384 --> 01:56:54,744
always based on what parts of the full

2764
01:56:54,782 --> 01:56:56,456
state space is the agent driven to

2765
01:56:56,478 --> 01:56:57,240
sample.

2766
01:57:01,470 --> 01:57:04,138
Awesome. Yakup. Any closing comments and

2767
01:57:04,144 --> 01:57:05,706
then all the closing comment and then

2768
01:57:05,728 --> 01:57:07,420
Conor with the last word.

2769
01:57:09,330 --> 01:57:12,926
Yeah, well, thank you very much for

2770
01:57:13,108 --> 01:57:17,210
the great overview.

2771
01:57:17,370 --> 01:57:21,986
What particularly I

2772
01:57:22,008 --> 01:57:25,746
found particularly interesting was both

2773
01:57:25,768 --> 01:57:27,986
how you touched on how it could be

2774
01:57:28,088 --> 01:57:31,566
modified with the action perception

2775
01:57:31,598 --> 01:57:33,654
loop, could be modified with the other

2776
01:57:33,852 --> 01:57:37,254
modules, even though, as you mentioned,

2777
01:57:37,292 --> 01:57:39,542
there would be more opportunities to go

2778
01:57:39,596 --> 01:57:42,680
deeper in that, but also on the learning

2779
01:57:44,970 --> 01:57:49,340
the dershleigh parameters. And I

2780
01:57:49,870 --> 01:57:53,882
would be interested to see

2781
01:57:53,936 --> 01:58:01,226
how that also influences planning if

2782
01:58:01,248 --> 01:58:04,686
you would do kind of pseudo update of

2783
01:58:04,708 --> 01:58:08,074
your dirsh lay parameters when you're

2784
01:58:08,122 --> 01:58:09,890
calculating your expected free energy.

2785
01:58:09,960 --> 01:58:12,706
As in what would I'm calculating my

2786
01:58:12,728 --> 01:58:15,762
expected free energy whilst also taking

2787
01:58:15,816 --> 01:58:19,620
into account that my B would change on

2788
01:58:20,070 --> 01:58:23,750
each step and how that changes

2789
01:58:23,820 --> 01:58:27,478
like the optimality of the

2790
01:58:27,644 --> 01:58:29,586
temporal depths that we do planning

2791
01:58:29,618 --> 01:58:33,590
with. I think super interesting and

2792
01:58:33,740 --> 01:58:36,010
really looking forward to hopefully

2793
01:58:36,670 --> 01:58:39,130
another model stream.

2794
01:58:45,950 --> 01:58:47,566
Is it okay if I quickly respond? Yeah,

2795
01:58:47,588 --> 01:58:51,198
please. Yeah. That's a

2796
01:58:51,204 --> 01:58:52,766
very interesting point that you just

2797
01:58:52,788 --> 01:58:56,442
made about this fictive or imagined

2798
01:58:56,506 --> 01:59:01,194
update. Whereas this slide so that

2799
01:59:01,252 --> 01:59:03,522
term, that novelty term in theory that

2800
01:59:03,576 --> 01:59:05,682
does culture exactly what you're saying,

2801
01:59:05,736 --> 01:59:08,674
yakub, is that this thing says how would

2802
01:59:08,712 --> 01:59:11,506
my Dean sleep parameters update if I was

2803
01:59:11,528 --> 01:59:14,134
to take this policy pile? And then I use

2804
01:59:14,172 --> 01:59:16,134
that term to actually choose where to

2805
01:59:16,172 --> 01:59:19,846
explore next. So if I turn on the

2806
01:59:19,868 --> 01:59:21,446
parameter information gain term in the

2807
01:59:21,468 --> 01:59:23,720
agent class, they'll much more quickly

2808
01:59:24,090 --> 01:59:26,166
skip the hint and go directly to

2809
01:59:26,188 --> 01:59:27,938
sampling the bandits because they're

2810
01:59:27,954 --> 01:59:29,738
driven by novelty. I want to know what

2811
01:59:29,744 --> 01:59:31,578
the reward probabilities are, so I'm

2812
01:59:31,584 --> 01:59:33,594
going to go explore. However, what it

2813
01:59:33,632 --> 01:59:35,334
doesn't do and what I think you're

2814
01:59:35,382 --> 01:59:38,566
intimating with your comment is that if

2815
01:59:38,608 --> 01:59:41,934
I did like multi step planning two time

2816
01:59:41,972 --> 01:59:44,078
steps in the future, will I be able to

2817
01:59:44,084 --> 01:59:47,502
do my planning given how I think I

2818
01:59:47,556 --> 01:59:49,694
updated my parameters at the first time

2819
01:59:49,732 --> 01:59:52,338
step? So that's what the equivalent of

2820
01:59:52,424 --> 01:59:54,814
sophisticated inference, sophisticated

2821
01:59:54,862 --> 01:59:56,562
inference is saying, how would I plan

2822
01:59:56,616 --> 01:59:59,666
ant time step three given how I think my

2823
01:59:59,688 --> 02:00:01,890
beliefs would update up to time step

2824
02:00:01,960 --> 02:00:04,246
two? And that's done right now for

2825
02:00:04,268 --> 02:00:06,614
hidden states. But I haven't seen that

2826
02:00:06,652 --> 02:00:08,546
done for parameters. And I think there's

2827
02:00:08,578 --> 02:00:11,506
someone like a student of Ryan Smith's

2828
02:00:11,698 --> 02:00:15,334
is working on that now is like this

2829
02:00:15,532 --> 02:00:17,766
propagation of counterfactual beliefs

2830
02:00:17,798 --> 02:00:19,626
about how my parameter beliefs would

2831
02:00:19,648 --> 02:00:22,954
change in the future. And that's like a

2832
02:00:23,072 --> 02:00:24,806
really cutting edge, I think, active

2833
02:00:24,838 --> 02:00:26,454
inference. It's like not only novelty

2834
02:00:26,502 --> 02:00:29,426
but how would my perspective

2835
02:00:29,478 --> 02:00:31,214
sophistication about how your own

2836
02:00:31,252 --> 02:00:33,294
parameter beliefs will have evolved by

2837
02:00:33,332 --> 02:00:35,486
time point T and then using that to do

2838
02:00:35,508 --> 02:00:37,920
planning for time point T plus one,

2839
02:00:38,290 --> 02:00:40,094
that's like really sophisticated stuff.

2840
02:00:40,212 --> 02:00:42,586
I think getting just even bare Ronen

2841
02:00:42,618 --> 02:00:44,346
sophisticated inference with hidden

2842
02:00:44,378 --> 02:00:47,806
state counterfactual stuff in pinevp,

2843
02:00:47,838 --> 02:00:49,554
that would be a huge accomplishment too.

2844
02:00:49,592 --> 02:00:51,426
And then of course incorporating it to

2845
02:00:51,448 --> 02:00:55,014
be more with

2846
02:00:55,052 --> 02:00:57,158
the parameter sophistication as well.

2847
02:00:57,244 --> 02:00:59,190
And then another quick thing is I can

2848
02:00:59,260 --> 02:01:02,934
quickly show you an example of

2849
02:01:02,972 --> 02:01:08,706
one of those other let's

2850
02:01:08,738 --> 02:01:09,320
see.

2851
02:01:11,290 --> 02:01:14,426
Just while you're finding it, that last

2852
02:01:14,528 --> 02:01:17,946
discussion on sophisticated

2853
02:01:18,058 --> 02:01:20,926
planning. It's something that at the

2854
02:01:20,948 --> 02:01:23,470
semantic level we engage with every day.

2855
02:01:23,620 --> 02:01:26,510
What courses should I take this quarter

2856
02:01:26,850 --> 02:01:30,334
so that I can learn what I don't know

2857
02:01:30,372 --> 02:01:33,746
today so that next quarter I'll be able

2858
02:01:33,768 --> 02:01:35,614
to make a better plan for which classes

2859
02:01:35,662 --> 02:01:37,746
to take so that in three years when I

2860
02:01:37,768 --> 02:01:40,658
graduate DAG DA DA dot. But it's already

2861
02:01:40,744 --> 02:01:44,546
phrased at the semantic granularity

2862
02:01:44,738 --> 02:01:47,634
that these models are rapidly converging

2863
02:01:47,682 --> 02:01:49,778
towards and they're not converging

2864
02:01:49,794 --> 02:01:52,918
towards it by scaling is all you need.

2865
02:01:53,084 --> 02:01:55,642
They're converging towards it with a

2866
02:01:55,696 --> 02:01:58,982
factorized actually semantic approach

2867
02:01:59,046 --> 02:02:01,738
which is very exciting. Yeah, that's a

2868
02:02:01,744 --> 02:02:05,702
great analogy. If you were a naive

2869
02:02:05,766 --> 02:02:06,938
active inference agent without

2870
02:02:07,024 --> 02:02:09,598
sophistication you would never plan

2871
02:02:09,764 --> 02:02:11,946
with, like, a ten time step planning

2872
02:02:11,978 --> 02:02:14,190
horizon. You would never plan to take,

2873
02:02:14,260 --> 02:02:15,978
or let's say, a three semester plans

2874
02:02:15,994 --> 02:02:17,502
horizon. You never plan to take

2875
02:02:17,556 --> 02:02:20,462
multivariate calculus in your third

2876
02:02:20,516 --> 02:02:22,586
semester because you would not have

2877
02:02:22,628 --> 02:02:25,346
anticipated by the second semester I now

2878
02:02:25,368 --> 02:02:28,226
have enough linear algebra to take I

2879
02:02:28,248 --> 02:02:29,858
know that by the time I finish the

2880
02:02:29,864 --> 02:02:31,406
second semester, I will now know linear

2881
02:02:31,438 --> 02:02:33,314
algebra, so I'll be well suited to take

2882
02:02:33,352 --> 02:02:35,726
multivariable calculus. Whereas what we

2883
02:02:35,768 --> 02:02:37,526
as humans do is we do have that

2884
02:02:37,548 --> 02:02:39,846
parameter. Sophistication I can plan as

2885
02:02:39,868 --> 02:02:42,198
a freshman, as a first year to take in

2886
02:02:42,204 --> 02:02:44,198
my third or fourth semester some high

2887
02:02:44,284 --> 02:02:45,818
advanced physics because I know by that

2888
02:02:45,824 --> 02:02:48,022
time I will have the requisite

2889
02:02:48,086 --> 02:02:50,554
multivariable calculus or whatever. So

2890
02:02:50,672 --> 02:02:52,106
that's a really nice analogy that I

2891
02:02:52,128 --> 02:02:55,740
never I think that's a good example.

2892
02:02:56,670 --> 02:03:00,160
Welcome to active you. Yeah, exactly.

2893
02:03:02,530 --> 02:03:06,206
So here I just wanted to show

2894
02:03:06,228 --> 02:03:07,918
you yakub, here's an example of a

2895
02:03:07,924 --> 02:03:09,306
hierarchical hierarchical active

2896
02:03:09,338 --> 02:03:11,118
inference demo. I can share this too.

2897
02:03:11,204 --> 02:03:13,706
It's another collab notebook where we're

2898
02:03:13,738 --> 02:03:16,878
exactly doing we're composing two palm

2899
02:03:16,894 --> 02:03:18,606
DPS. So there's like a high level palm

2900
02:03:18,638 --> 02:03:21,918
DP and then there's a low level palm DP.

2901
02:03:22,094 --> 02:03:24,854
And for example, when you're doing a

2902
02:03:24,892 --> 02:03:27,238
step of updating the empirical priors at

2903
02:03:27,244 --> 02:03:29,526
the high level before you pass them down

2904
02:03:29,628 --> 02:03:31,942
to be empirical priors at the low level,

2905
02:03:32,076 --> 02:03:34,630
we use the control module, for example,

2906
02:03:34,700 --> 02:03:37,306
to do get expected states. We use the

2907
02:03:37,328 --> 02:03:39,706
high level beliefs, the high level B

2908
02:03:39,728 --> 02:03:42,006
matrix and then the high level chosen

2909
02:03:42,038 --> 02:03:44,698
action to propagate forward the next

2910
02:03:44,784 --> 02:03:47,066
postered beliefs at the high level. And

2911
02:03:47,088 --> 02:03:48,186
then those things themselves

2912
02:03:48,288 --> 02:03:51,174
parameterize a low level empirical prior

2913
02:03:51,222 --> 02:03:53,294
for this faster palm VP that's going on

2914
02:03:53,332 --> 02:03:56,110
at the low level. So this is an example

2915
02:03:56,180 --> 02:03:59,246
where you're composing like agent class

2916
02:03:59,348 --> 02:04:02,286
calls like this, but you're composing

2917
02:04:02,318 --> 02:04:04,402
them with functions that are built from

2918
02:04:04,456 --> 02:04:06,466
sub modules and adjacent modules of

2919
02:04:06,488 --> 02:04:10,066
PMDP. So that's an example of the thing

2920
02:04:10,088 --> 02:04:11,726
you were talking about. But yeah,

2921
02:04:11,768 --> 02:04:14,102
that's very brief. We can get into that

2922
02:04:14,236 --> 02:04:15,240
later on.

2923
02:04:17,050 --> 02:04:18,806
Ant a different stream or something like

2924
02:04:18,828 --> 02:04:21,030
that. Awesome.

2925
02:04:21,180 --> 02:04:24,506
Yes. Dot three, whenever the time

2926
02:04:24,528 --> 02:04:27,926
is right, I'll just give two closing

2927
02:04:28,038 --> 02:04:32,278
areas. Again, really appreciate

2928
02:04:32,454 --> 02:04:35,578
coming back on and sharing this

2929
02:04:35,744 --> 02:04:38,878
development in progress. Already it

2930
02:04:38,964 --> 02:04:43,070
feels more powerful and documented than

2931
02:04:43,220 --> 02:04:45,440
when we were in the dot one just a few

2932
02:04:45,810 --> 02:04:48,906
weeks or months ago. I think two areas

2933
02:04:48,938 --> 02:04:51,746
that are going to be really exciting to

2934
02:04:51,928 --> 02:04:53,966
discuss and see how they're implemented

2935
02:04:53,998 --> 02:04:56,018
and also the plurality of ways that

2936
02:04:56,024 --> 02:04:59,234
they're implemented. The first area is

2937
02:04:59,352 --> 02:05:02,290
structure learning on cognitive models

2938
02:05:02,450 --> 02:05:05,602
from the outside. So as an ethologist,

2939
02:05:05,666 --> 02:05:08,182
as a behavioral researcher, how do we do

2940
02:05:08,236 --> 02:05:11,030
structure learning on cognitive models

2941
02:05:11,530 --> 02:05:13,494
for systems that we actually know about

2942
02:05:13,532 --> 02:05:16,042
their cognitive architecture or not,

2943
02:05:16,176 --> 02:05:18,986
but also the view from the inside in

2944
02:05:19,008 --> 02:05:20,634
terms of structure learning and

2945
02:05:20,672 --> 02:05:23,722
metacognition. Like how should I change

2946
02:05:23,776 --> 02:05:26,234
the dimensionality of my B matrix or

2947
02:05:26,272 --> 02:05:29,006
should I turn on that flag to engage in

2948
02:05:29,028 --> 02:05:30,762
this kind of sophisticated inference?

2949
02:05:30,826 --> 02:05:32,714
So structure learning on cognitive

2950
02:05:32,762 --> 02:05:34,846
models, view from the outside, view from

2951
02:05:34,868 --> 02:05:37,886
the inside is one exciting area and the

2952
02:05:37,908 --> 02:05:41,346
second more experimental area is

2953
02:05:41,448 --> 02:05:44,962
statistical power analysis. Pre and

2954
02:05:45,016 --> 02:05:47,838
post hoc statistical power analysis

2955
02:05:48,014 --> 02:05:51,074
along the lines of the design matrix in

2956
02:05:51,112 --> 02:05:55,074
SPM so that you put 15 time

2957
02:05:55,112 --> 02:05:58,006
steps and zero 8.2 and punishment is

2958
02:05:58,028 --> 02:06:00,950
four. And then you could sweep across

2959
02:06:01,020 --> 02:06:02,966
parameters and learn about how well it

2960
02:06:02,988 --> 02:06:05,402
did. But if there was certain

2961
02:06:05,456 --> 02:06:08,022
interfaces, analytical or numerical

2962
02:06:08,086 --> 02:06:11,386
approaches to be like, yes,

2963
02:06:11,568 --> 02:06:15,194
with 25 time steps, we have this

2964
02:06:15,232 --> 02:06:17,790
much of an expectation of convergence,

2965
02:06:18,130 --> 02:06:21,166
or this differentiate in rewards should

2966
02:06:21,188 --> 02:06:24,350
be resolvable by an adaptive agent over

2967
02:06:24,420 --> 02:06:27,440
this long. And just understand,

2968
02:06:27,970 --> 02:06:30,994
how long should these experiments be?

2969
02:06:31,192 --> 02:06:33,906
Because there are such interesting

2970
02:06:34,008 --> 02:06:37,490
results with one shot learning and with

2971
02:06:37,640 --> 02:06:40,014
being able to generate someone's voice

2972
02:06:40,142 --> 02:06:42,194
from just 10 seconds of them talking,

2973
02:06:42,392 --> 02:06:44,946
or make a video of somebody as a deep

2974
02:06:44,978 --> 02:06:48,246
fake with just a still image. And so it

2975
02:06:48,268 --> 02:06:50,774
seems like it's possible to learn a lot

2976
02:06:50,812 --> 02:06:54,226
from a little. And if we can learn a lot

2977
02:06:54,268 --> 02:06:56,774
from a little and have a semantic

2978
02:06:56,822 --> 02:06:59,802
cognitive model, that would be quite

2979
02:06:59,856 --> 02:07:03,066
great. Absolutely.

2980
02:07:03,168 --> 02:07:06,806
Yeah. It's almost like hyper parameter

2981
02:07:06,838 --> 02:07:09,146
optimization on the landscape of active

2982
02:07:09,178 --> 02:07:11,982
inference models. Like, how do I choose

2983
02:07:12,036 --> 02:07:13,706
the parameters of an active inference

2984
02:07:13,738 --> 02:07:16,314
model? In a smart way? Yeah, there's

2985
02:07:16,362 --> 02:07:18,766
several methods for doing that that we

2986
02:07:18,788 --> 02:07:22,402
could definitely explore. Data

2987
02:07:22,456 --> 02:07:24,658
efficiency is the main thing, like you

2988
02:07:24,664 --> 02:07:26,418
said, making it so you don't have to

2989
02:07:26,424 --> 02:07:28,098
train it on a trillion images, like with

2990
02:07:28,104 --> 02:07:29,410
a deep neural network.

2991
02:07:31,910 --> 02:07:35,474
Perfect. End seven,

2992
02:07:35,592 --> 02:07:40,030
two. And whenever you want to join,

2993
02:07:40,110 --> 02:07:42,914
you and any colleagues are always

2994
02:07:42,952 --> 02:07:46,198
welcome to share the next spiral in Pi

2995
02:07:46,214 --> 02:07:49,434
MDP development. Awesome. Thank you so

2996
02:07:49,472 --> 02:07:51,642
much again for letting me come on and

2997
02:07:51,776 --> 02:07:54,826
listening. I hope it was helpful. Yeah,

2998
02:07:54,848 --> 02:07:56,486
and I'm glad that it's recorded. It's

2999
02:07:56,518 --> 02:07:58,314
really an amazing resource that you guys

3000
02:07:58,352 --> 02:08:01,020
are developing here. So thanks again.

3001
02:08:01,950 --> 02:08:03,450
Thank you. Till next time.


