1
00:00:07,839 --> 00:00:08,400
안녕하세요

2
00:00:08,400 --> 00:00:11,120
. 활성 추론 연구소에 오신 모든 분들을 환영합니다.

3
00:00:11,120 --> 00:00:12,160


4
00:00:12,160 --> 00:00:15,759
이것은

5
00:00:15,759 --> 00:00:18,960
2021년 4월 16일의 모델 스트림 번호 2.1입니다.

6
00:00:18,960 --> 00:00:20,720
오늘은 멋진

7
00:00:20,720 --> 00:00:22,400
모델 스트림이 될 것입니다. 우리는

8
00:00:22,400 --> 00:00:24,400
간단히 둘러보고

9
00:00:24,400 --> 00:00:25,920
자신을 소개한

10
00:00:25,920 --> 00:00:27,920
다음 방법에 대해 언급하겠습니다.  세션이

11
00:00:27,920 --> 00:00:30,000
오늘 실행되고 프레젠테이션을 위해

12
00:00:30,000 --> 00:00:33,200
noor에게 전달할 것이므로 저는 daniel

13
00:00:33,200 --> 00:00:35,120
이고 캘리포니아에서 박사후 연구원입니다.

14
00:00:35,120 --> 00:00:36,719
저는 philip에게 전달할 것

15
00:00:36,719 --> 00:00:39,040


16
00:00:40,000 --> 00:00:42,800


17
00:00:42,800 --> 00:00:43,280


18
00:00:43,280 --> 00:00:46,719
입니다.  제 2년차이자 네, 저는 이것이

19
00:00:46,719 --> 00:00:48,320
제가 박사 학위를 시작하기 전에 했던 일이라고 생각합니다.

20
00:00:48,320 --> 00:00:49,440


21
00:00:49,440 --> 00:00:52,640
현재

22
00:00:52,640 --> 00:00:53,600


23
00:00:53,600 --> 00:00:55,600
는 특히 강화 학습 내에서 데이터 효율성에 더 집중하고

24
00:00:55,600 --> 00:00:57,280


25
00:00:57,280 --> 00:00:58,960
있지만 능동 추론에 대한 지식과 같은 주제에

26
00:00:58,960 --> 00:01:00,879


27
00:01:00,879 --> 00:01:03,520
대해서는 분명히 그렇습니다.  그러한 연구 문제에 접근하는 데 유용합니다.

28
00:01:03,520 --> 00:01:06,239


29
00:01:06,240 --> 00:01:09,360


30
00:01:09,360 --> 00:01:12,000
안녕하세요. 저는 노아입니다. 저는 인간 신경 영상을 위한 환영 센터에서 이론 신경생물학 그룹의 3년차 박사 과정 학생

31
00:01:12,000 --> 00:01:13,840
입니다.

32
00:01:13,840 --> 00:01:15,200


33
00:01:15,200 --> 00:01:16,159


34
00:01:16,159 --> 00:01:18,799


35
00:01:18,799 --> 00:01:19,920


36
00:01:19,920 --> 00:01:22,720
음 그래서 내 박사는 적응과 관련된 이러한 아이디어에 초점을 맞추면서 자동차가 감독했습니다.

37
00:01:22,720 --> 00:01:23,920


38
00:01:23,920 --> 00:01:26,000
그 중 하나는 활성 추론을 사용하여

39
00:01:26,000 --> 00:01:27,759


40
00:01:27,759 --> 00:01:29,759
고정되지 않은 환경에서의 행동 적응에 대해 오늘 집중할 것입니다.

41
00:01:29,759 --> 00:01:32,000
참여해 주시고

42
00:01:32,000 --> 00:01:35,119


43
00:01:35,119 --> 00:01:38,159
이 프레젠테이션을 해주셔서 정말 감사합니다.  프레젠테이션

44
00:01:38,159 --> 00:01:38,720


45
00:01:38,720 --> 00:01:41,280
시간이 얼마나 되는지 아는 사람의 이야기를 듣게

46
00:01:41,280 --> 00:01:42,720


47
00:01:42,720 --> 00:01:44,399
될

48
00:01:44,399 --> 00:01:45,759
것이며 채팅에서 질문을 수집할

49
00:01:45,759 --> 00:01:48,240
것이므로 질문이 오는 대로 입력하세요.

50
00:01:48,240 --> 00:01:48,880


51
00:01:48,880 --> 00:01:51,119
그러면 마지막에 답변해 드리겠습니다.

52
00:01:51,119 --> 00:01:53,200
다시 한 번 감사드립니다.

53
00:01:53,200 --> 00:01:56,479
가져가세요 완벽합니다 감사합니다

54
00:01:56,479 --> 00:01:58,880
음 그래서 오늘은 토마스 파와 칼 프리스탄 음에게 들은 적이 있는 필립과 공동 작업한 작업을 보여드리겠습니다.

55
00:01:58,880 --> 00:01:59,520


56
00:01:59,520 --> 00:02:01,600


57
00:02:01,600 --> 00:02:03,119


58
00:02:03,119 --> 00:02:06,399


59
00:02:06,399 --> 00:02:08,800
제목은 능동 추론 어

60
00:02:08,800 --> 00:02:12,720
이해하기 쉽고 비교

61
00:02:13,599 --> 00:02:15,440
좋습니다.  알겠습니다.

62
00:02:15,440 --> 00:02:17,440
프레젠테이션이 다음과 같이 구성되어

63
00:02:17,440 --> 00:02:20,480
있습니다. 화면을 들을 수 있습니까?

64
00:02:20,480 --> 00:02:22,160
공유하고 있는 것 같습니까 아니면 당신

65
00:02:22,160 --> 00:02:23,840
이 볼 수 없는 것입니까? 나는 그것을 볼 수 없습니다.

66
00:02:23,840 --> 00:02:26,000
다시 공유할 수 있습니다. 예,

67
00:02:26,000 --> 00:02:28,640
확실히

68
00:02:29,920 --> 00:02:34,480
음 technolog  y 나는 당신에게

69
00:02:34,480 --> 00:02:36,800
거기에 간다고 말하고 그것을 자릅니다. 그래서 그것을 위해 가십시오

70
00:02:36,800 --> 00:02:38,720
감사합니다

71
00:02:38,720 --> 00:02:40,879
완벽합니다 감사합니다 그래서 프레젠테이션이

72
00:02:40,879 --> 00:02:42,239
구조화되었으며

73
00:02:42,239 --> 00:02:44,080
먼저 문제 설정에 간단히 동기를 부여하고

74
00:02:44,080 --> 00:02:45,280


75
00:02:45,280 --> 00:02:47,360


76
00:02:47,360 --> 00:02:49,920
오늘 고려 중인 특정 능동적 추론 인스턴스화에 대한 세부 사항을 제공

77
00:02:49,920 --> 00:02:51,519
할 것입니다.  이산 상태 공간

78
00:02:51,519 --> 00:02:52,319
설정

79
00:02:52,319 --> 00:02:54,160
및 프레젠테이션의 후반부

80
00:02:54,160 --> 00:02:55,599


81
00:02:55,599 --> 00:02:57,440


82
00:02:57,440 --> 00:02:59,360
에서는 능동적 영향 공식을

83
00:02:59,360 --> 00:03:00,720
강화 학습,

84
00:03:00,720 --> 00:03:03,599
특히 q 학습 및 베이지안

85
00:03:03,599 --> 00:03:04,959
모델 기반

86
00:03:04,959 --> 00:03:07,519
알고리즘과 비교하는 몇 가지 특정 예에 중점을 둘 것

87
00:03:07,519 --> 00:03:08,959
입니다.  활성 추론을 사용

88
00:03:08,959 --> 00:03:10,640
하려는 이유에 대한 특정 측면의

89
00:03:10,640 --> 00:03:14,080


90
00:03:14,080 --> 00:03:18,080
타당성 좋습니다. 그래서 활성 추론이란 무엇입니까?

91
00:03:18,080 --> 00:03:20,480


92
00:03:20,480 --> 00:03:21,599
생물학적

93
00:03:21,599 --> 00:03:23,920
또는 인공 에이전트가

94
00:03:23,920 --> 00:03:26,239
동적 비정상 설정

95
00:03:26,239 --> 00:03:28,560
에서 작동할 수 있는 방법에 대한 첫 번째 원칙 설명입니다.

96
00:03:28,560 --> 00:03:30,000


97
00:03:30,000 --> 00:03:31,680
항상성은

98
00:03:31,680 --> 00:03:34,560
엔트로피 또는 놀라움을 최소화하는

99
00:03:34,560 --> 00:03:36,239
상태를 끌어들이는 상태에 있습니다.

100
00:03:36,239 --> 00:03:38,000
우리가 보고 있는 이 과거의

101
00:03:38,000 --> 00:03:41,280
배고픈 에이전트

102
00:03:41,280 --> 00:03:42,879
가 작동하는 방식으로 냉장고

103
00:03:42,879 --> 00:03:44,959
를 여는

104
00:03:44,959 --> 00:03:46,480
특정한 예

105
00:03:46,480 --> 00:03:47,280


106
00:03:47,280 --> 00:03:50,080
는 집에서 먹을지 아니면 밖에서 먹을지, 아니면 집에서 먹을지 중에서 특정한 선택을 하고 싶어 냉장고를 바로 여는 이유와 같습니다.

107
00:03:50,080 --> 00:03:51,120
그렇게 하려면 현재 상황에 대한 자신의 불확실성을 해결할

108
00:03:51,120 --> 00:03:53,200
수 있는 최적의 조치가 무엇인지 결정해야

109
00:03:53,200 --> 00:03:55,040


110
00:03:55,040 --> 00:03:56,959
합니다.

111
00:03:56,959 --> 00:03:58,560


112
00:03:58,560 --> 00:04:00,799
음, 그러면 집에서 요리할 것인지 산책할 것인지 결정하는 데 도움이 될 것입니다.

113
00:04:00,799 --> 00:04:02,480


114
00:04:02,480 --> 00:04:04,400
레스토랑

115
00:04:04,400 --> 00:04:06,720
과 이 특정 사례

116
00:04:06,720 --> 00:04:08,560
로 인해 에이전트가 냉장고를 열어

117
00:04:08,560 --> 00:04:11,760
집에 음식이 있는지 확인하게 했습니다.

118
00:04:11,760 --> 00:04:13,519
능동적 추론

119
00:04:13,519 --> 00:04:15,519
의 장점은 다음을 지정하여

120
00:04:15,519 --> 00:04:16,959
이러한 문제 설정에 대해

121
00:04:16,959 --> 00:04:19,358
보다 공식적인 방식으로 생각할 수 있다는 것입니다.

122
00:04:19,358 --> 00:04:20,639
최적의 행동

123
00:04:20,639 --> 00:04:23,199
은

124
00:04:23,199 --> 00:04:24,639


125
00:04:24,639 --> 00:04:26,639
에이전트가 노출되고 있는 관찰의 성별 모델

126
00:04:26,639 --> 00:04:28,080


127
00:04:28,080 --> 00:04:30,400
및 이

128
00:04:30,400 --> 00:04:31,520
특정

129
00:04:31,520 --> 00:04:33,360
프레젠테이션에서 감각 입력인 증거를 평가하여 결정됩니다.  ion 우리가 할 일은 능동 추론을

130
00:04:33,360 --> 00:04:35,280
뒷받침하는 과정 이론에만 초점을 맞추고

131
00:04:35,280 --> 00:04:37,199
능동 추론 메시지 전달 방식

132
00:04:37,199 --> 00:04:38,240


133
00:04:38,240 --> 00:04:41,199
의 신경적 타당성에 대해 생물학적인 이야기를 하지 않는

134
00:04:41,199 --> 00:04:44,240


135
00:04:44,240 --> 00:04:47,280


136
00:04:47,280 --> 00:04:48,479
것입니다

137
00:04:48,479 --> 00:04:50,560
일반 강화 학습 알고리즘과 비교하여

138
00:04:50,560 --> 00:04:52,000


139
00:04:52,000 --> 00:04:52,800


140
00:04:52,800 --> 00:04:54,720
우리는 먼저

141
00:04:54,720 --> 00:04:56,080
활성

142
00:04:56,080 --> 00:04:57,759
추론을 통해

143
00:04:57,759 --> 00:04:59,600
순수한 믿음 기반 체계에 대한 이러한 약속

144
00:04:59,600 --> 00:05:01,600


145
00:05:01,600 --> 00:05:03,520


146
00:05:03,520 --> 00:05:06,000


147
00:05:06,000 --> 00:05:07,360
이 있다는

148
00:05:07,360 --> 00:05:10,240
것을 이해하는 것으로 시작해야 합니다.  선호도가 없는 경우에도 인식적 가치

149
00:05:10,240 --> 00:05:11,680


150
00:05:11,680 --> 00:05:14,000
추가로 활성 추론 에이전트는

151
00:05:14,000 --> 00:05:16,400
자체 보상 기능을 학습할 수

152
00:05:16,400 --> 00:05:19,120
있으며 이는 에이전트가 환경에서

153
00:05:19,120 --> 00:05:20,400


154
00:05:20,400 --> 00:05:23,199


155
00:05:23,199 --> 00:05:25,120
얻을 수 있는 것과는 반대로 스스로 볼 것으로 기대하는 행동 유형을 설명하는 데 도움

156
00:05:25,120 --> 00:05:28,000
이 됩니다.  강화 lea와 달리 두 가지

157
00:05:28,000 --> 00:05:29,600
특정 포인트가 정말 중요합니다

158
00:05:29,600 --> 00:05:30,800
.

159
00:05:30,800 --> 00:05:33,039


160
00:05:33,039 --> 00:05:35,680
표준 rl 설정에서 보상 기능

161
00:05:35,680 --> 00:05:38,160
은 에이전트

162
00:05:38,160 --> 00:05:39,360


163
00:05:39,360 --> 00:05:41,520
가 특정 환경 내에서 상호 작용하거나 행동

164
00:05:41,520 --> 00:05:42,560


165
00:05:42,560 --> 00:05:44,080
하는 방식을 정의하기 때문입니다. 그러나 보상 기능을 정의하는 것은

166
00:05:44,080 --> 00:05:46,000
처음에 에서 제공되는 특정 신호가 있다고 가정하기 때문에 매우 어렵습니다

167
00:05:46,000 --> 00:05:48,160


168
00:05:48,160 --> 00:05:49,520


169
00:05:49,520 --> 00:05:51,919
.  에이전트에게

170
00:05:51,919 --> 00:05:53,600
만장일치로 좋거나 나쁠

171
00:05:53,600 --> 00:05:56,160
수 있는 환경은

172
00:05:56,160 --> 00:05:56,800


173
00:05:56,800 --> 00:06:00,400
이러한 음

174
00:06:00,400 --> 00:06:02,319
환경 신호가 설정에 따라 변경될 수 있는 실제 설정에서 반드시 사실이 아닐 수 있습니다.

175
00:06:02,319 --> 00:06:03,919
예를

176
00:06:03,919 --> 00:06:05,680


177
00:06:05,680 --> 00:06:07,280
들어 아플 경우 아이스크림을 먹는 것이 항상 보람이 있는 것은 아닙니다.

178
00:06:07,280 --> 00:06:09,919
그리고 그것은 당신을 더 악화시킬 수 있습니다 음.

179
00:06:09,919 --> 00:06:11,199
그래서

180
00:06:11,199 --> 00:06:12,800


181
00:06:12,800 --> 00:06:15,199
처음에 이러한 보상 기능을 구성하는 것이 극도로 어렵고

182
00:06:15,199 --> 00:06:16,880


183
00:06:16,880 --> 00:06:19,360
rl 설정으로도 적절한 방식으로 구성하지

184
00:06:19,360 --> 00:06:21,680


185
00:06:21,680 --> 00:06:24,080
않으면 에이전트에 대해 차선의 행동을 초래할 수 있습니다

186
00:06:24,080 --> 00:06:26,000
음  능동 추론은

187
00:06:26,000 --> 00:06:27,520
우리가 실제로

188
00:06:27,520 --> 00:06:29,680


189
00:06:29,680 --> 00:06:31,360
기존의 보상 기능을 대체하거나 우회하고 있기 때문에 의미에서 정말 좋습니다.  당신

190
00:06:31,360 --> 00:06:31,919


191
00:06:31,919 --> 00:06:34,400


192
00:06:34,400 --> 00:06:34,960
은

193
00:06:34,960 --> 00:06:36,880
선호하는 결과에 대한 사전 신념

194
00:06:36,880 --> 00:06:39,039


195
00:06:39,039 --> 00:06:40,560


196
00:06:40,560 --> 00:06:43,840
이 있는 환경에서 자신을 보고 싶어하는 일종의 원하는 상태를 갖게 되며

197
00:06:43,840 --> 00:06:47,039


198
00:06:47,039 --> 00:06:48,400


199
00:06:48,400 --> 00:06:50,479
이는 보상이 없거나 보상이나 선호가 무엇인지에 대한 정말 부정확한 이해가 있는

200
00:06:50,479 --> 00:06:52,639
환경에서 중요해집니다.  설정은 다음과 같아야

201
00:06:52,639 --> 00:06:55,360
하고 이 시나리오에서 표준

202
00:06:55,360 --> 00:06:56,319
활성 영향

203
00:06:56,319 --> 00:06:58,160
이산 상태 공식화 내에서 우리가 할 수

204
00:06:58,160 --> 00:07:00,319
있는 것은

205
00:07:00,319 --> 00:07:01,599
이러한

206
00:07:01,599 --> 00:07:05,280
선호하는 결과에 대한 경험적 사전 분포를 학습하는 것입니다 음 및 고유 어

207
00:07:05,280 --> 00:07:07,199
죄송합니다 해당 에이전트의 내부 보상 기능

208
00:07:07,199 --> 00:07:07,599


209
00:07:07,599 --> 00:07:10,400
과 이런 종류는 저를 좋아하게 만듭니다

210
00:07:10,400 --> 00:07:11,120


211
00:07:11,120 --> 00:07:14,479


212
00:07:14,479 --> 00:07:17,919
RL 설정과 능동 추론 사이의 첫 번째 뚜렷한 um 개념화는

213
00:07:17,919 --> 00:07:20,639
능동 추론 내에서 보상이

214
00:07:20,639 --> 00:07:22,560
구별되지 않기

215
00:07:22,560 --> 00:07:24,560
때문에 에이전트

216
00:07:24,560 --> 00:07:26,800
가 환경에서 얻는 표준 관찰일 뿐인 반면

217
00:07:26,800 --> 00:07:27,840
rl에서는 에이전트

218
00:07:27,840 --> 00:07:32,160
가 적절한 조치를 취하는 데 매우 필요합니다.

219
00:07:32,160 --> 00:07:35,759


220
00:07:35,759 --> 00:07:38,960


221
00:07:38,960 --> 00:07:41,280
우리가 원했던 죄송합니다.  능동적인

222
00:07:41,280 --> 00:07:43,039
영향은 불확실성을 최소화하는

223
00:07:43,039 --> 00:07:44,080
인식론적

224
00:07:44,080 --> 00:07:46,160
탐구와 내재적 동기 부여에 대한 주요 설명을 제공

225
00:07:46,160 --> 00:07:48,160


226
00:07:48,160 --> 00:07:50,080
하고 다시 rl 설정 내에서 이것은

227
00:07:50,080 --> 00:07:51,440
매우 중요합니다. 왜냐하면

228
00:07:51,440 --> 00:07:53,759


229
00:07:53,759 --> 00:07:54,479


230
00:07:54,479 --> 00:07:57,759
우리 nrl에서 볼 수 있는 많은 새로운 알고리즘의 전제는 시도하고 시도하는 것이기 때문입니다.  탐색과 탐색

231
00:07:57,759 --> 00:07:58,000


232
00:07:58,000 --> 00:07:59,680
사이의 균형을 위해 적절한 절충안을 찾으십시오.

233
00:07:59,680 --> 00:08:02,000
따라서

234
00:08:02,000 --> 00:08:03,919


235
00:08:03,919 --> 00:08:05,599
에이전트가 한 번도 노출되지 않은 다양한 아이스크림 맛을 계속 선택해야 하는 경우 지정된 시점에 에이전트가 수행해야 하는 올바른 일련의 조치는 무엇입니까?

236
00:08:05,599 --> 00:08:06,400


237
00:08:06,400 --> 00:08:08,240


238
00:08:08,240 --> 00:08:10,160


239
00:08:10,160 --> 00:08:10,800


240
00:08:10,800 --> 00:08:13,520
음 겨자 같은 거 아  

241
00:08:13,520 --> 00:08:14,479


242
00:08:14,479 --> 00:08:16,879
면 항상 이걸 써야 하는 건지 아 죄송합니

243
00:08:16,879 --> 00:08:17,840


244
00:08:17,840 --> 00:08:20,000


245
00:08:20,000 --> 00:08:21,120
다 예전에 노출되었던 아이스크림 맛이 항상 똑  

246
00:08:21,120 --> 00:08:23,199
아서 예를 들어 헤이즐넛이나 누텔라처럼 정말 좋아하는

247
00:08:23,199 --> 00:08:25,199


248
00:08:25,199 --> 00:08:28,080
데 음 그래서 이건 음 RL의 눈에 띄는 문  

249
00:08:28,080 --> 00:08:28,560
입니

250
00:08:28,560 --> 00:08:30,800
다  베이지안

251
00:08:30,800 --> 00:08:32,958
프레임워크에서 능동 추론은

252
00:08:32,958 --> 00:08:36,159
자연스럽게 um을 사용하여 처리합니다. um을 사용

253
00:08:36,159 --> 00:08:37,760
하면 내가 순간에 올 것으로 예상되는 자유 에너지 공식을 사용할 수 있습니다.

254
00:08:37,760 --> 00:08:39,760


255
00:08:39,760 --> 00:08:42,799
m 그리고

256
00:08:42,799 --> 00:08:44,560
활성 추론 프레임워크에서 볼 수 있는 마지막

257
00:08:44,560 --> 00:08:46,080


258
00:08:46,080 --> 00:08:47,920
부분은 믿음

259
00:08:47,920 --> 00:08:48,560
업데이트

260
00:08:48,560 --> 00:08:51,839
프로세스의 일부로 불확실성

261
00:08:51,839 --> 00:08:54,959
을 자연스럽게 설명한다는 것입니다. 이제 활성 추론에

262
00:08:54,959 --> 00:08:57,200
대해 매우 흥미로운 세 가지를 정리했습니다

263
00:08:57,200 --> 00:08:58,640
영향력 체계

264
00:08:58,640 --> 00:09:00,640
를 rl과 비교하여 직관을 제공할 예정입니다.

265
00:09:00,640 --> 00:09:04,480


266
00:09:04,480 --> 00:09:08,000


267
00:09:08,000 --> 00:09:09,760
어째서 우리가 능동적인 영향력 공식화를 공식화할 수 있는지에 대한 몇 가지 동기를

268
00:09:09,760 --> 00:09:13,120


269
00:09:13,120 --> 00:09:17,040


270
00:09:17,200 --> 00:09:18,959
유감스럽게 생각하실 수 있습니다. 그래서 음 죄송합니다.

271
00:09:18,959 --> 00:09:20,480


272
00:09:20,480 --> 00:09:24,399
아니요 죄송합니다. 훌륭한 프레젠테이션

273
00:09:24,399 --> 00:09:27,519
예 감사합니다. 음으로 스크롤하겠습니다.

274
00:09:27,519 --> 00:09:32,000


275
00:09:32,000 --> 00:09:35,040
그래서 이전에

276
00:09:35,040 --> 00:09:36,399
활성 추론

277
00:09:36,399 --> 00:09:38,480
을 통해 에이전트가 놀라움

278
00:09:38,480 --> 00:09:40,320


279
00:09:40,320 --> 00:09:42,080
을 최소화하는 유치 상태에 거주함으로써 항상성을 유지한다고 명시했습니다.

280
00:09:42,080 --> 00:09:43,440


281
00:09:43,440 --> 00:09:44,880
그래서 당신은 생각하고 있었을 것입니다  놀라움이란 무엇인가

282
00:09:44,880 --> 00:09:46,560


283
00:09:46,560 --> 00:09:48,800
음 우리가 놀라움을 결과의 음의 로그 확률로 정의하는 방법

284
00:09:48,800 --> 00:09:50,080


285
00:09:50,080 --> 00:09:52,080
과 이를 위해 해당하는 하나의 랜덤 변수를 도입

286
00:09:52,080 --> 00:09:53,760


287
00:09:53,760 --> 00:09:55,760
합니다.  에이전트에 의해 수신된 특정 결과에 대한 ds

288
00:09:55,760 --> 00:09:57,440


289
00:09:57,440 --> 00:10:00,480
및 이 um은 모든 가능한 결과의 유한한 집합 내에 존재

290
00:10:00,480 --> 00:10:01,040


291
00:10:01,040 --> 00:10:03,600
하며 그게 o입니다.

292
00:10:03,600 --> 00:10:04,560


293
00:10:04,560 --> 00:10:06,720
um이 있는 첫 번째 방정식

294
00:10:06,720 --> 00:10:08,160
은 공식적으로 out

295
00:10:08,160 --> 00:10:10,240
이고 여기서 p는 결과에 대한 확률 분포를 나타냅니다.

296
00:10:10,240 --> 00:10:11,680


297
00:10:11,680 --> 00:10:14,239


298
00:10:15,839 --> 00:10:19,920
따라서 능동적 추론

299
00:10:19,920 --> 00:10:21,200
에서 에이전트가

300
00:10:21,200 --> 00:10:23,200
우리가 방금 통과한 이 놀라운 양을 실제로 최소화하는 방법

301
00:10:23,200 --> 00:10:24,959


302
00:10:24,959 --> 00:10:27,120
은 세계의 젠더 모델을 유지하는 것입니다.

303
00:10:27,120 --> 00:10:29,360
음, 이는

304
00:10:29,360 --> 00:10:31,040
특정 시점에서 에이전트가

305
00:10:31,040 --> 00:10:32,640
반드시 액세스할 수

306
00:10:32,640 --> 00:10:34,000
있는 것은 아니기 때문에 중요합니다.  세계의 현재

307
00:10:34,000 --> 00:10:36,000
상태에 대한 실제 측정값이므로

308
00:10:36,000 --> 00:10:37,600
여기에서

309
00:10:37,600 --> 00:10:39,600
볼 수 있는 이 특정 그래픽에서 환경과 에이전트

310
00:10:39,600 --> 00:10:41,200
음이 특정 방식으로 환경과 상호 작용하는 것을 볼 수 있습니다. 특정 방식으로 환경과 상호 작용

311
00:10:41,200 --> 00:10:42,320


312
00:10:42,320 --> 00:10:44,480
하는 것은 감각 신호에 노출

313
00:10:44,480 --> 00:10:46,480
되지만 무엇인지 모릅니다.

314
00:10:46,480 --> 00:10:49,600
o의 결과는 o

315
00:10:49,600 --> 00:10:51,760
를 통해서만 자신과

316
00:10:51,760 --> 00:10:52,959
주변 세계를 인식

317
00:10:52,959 --> 00:10:55,120
할 수 있도록 에 의해 재생성되었으며

318
00:10:55,120 --> 00:10:57,279
어떤 유형인지 추론해야 합니다.  상태

319
00:10:57,279 --> 00:11:00,959
또는 음의 진정한 원인 음

320
00:11:00,959 --> 00:11:03,279
은

321
00:11:03,279 --> 00:11:06,000
음이 노출되는 특정 감각 입력에 대한 책임

322
00:11:06,000 --> 00:11:08,959
이 있으며 이것이 바로 음

323
00:11:08,959 --> 00:11:10,240
이 문제를

324
00:11:10,240 --> 00:11:11,839
공식화할 때 능동적 추론에서 부분적으로 관찰 가능한 마르코프 결정 프로세스로 공식화하는

325
00:11:11,839 --> 00:11:13,519


326
00:11:13,519 --> 00:11:16,560
이유입니다.  에이전트가 결과를 추론하기 위해 사용할 내부 상태에 대한 이 내부 분포

327
00:11:16,560 --> 00:11:18,959
를 정의하는 성별 모델을 공식화할 수

328
00:11:18,959 --> 00:11:19,279


329
00:11:19,279 --> 00:11:22,160


330
00:11:22,160 --> 00:11:23,920


331
00:11:23,920 --> 00:11:26,399


332
00:11:26,399 --> 00:11:27,920
있으므로 실제 상태에 액세스

333
00:11:27,920 --> 00:11:28,399


334
00:11:28,399 --> 00:11:30,320
할 수 없지만 다음 상태에 대한 가설이나 믿음을 만들 수 있습니다.

335
00:11:30,320 --> 00:11:32,000


336
00:11:32,000 --> 00:11:32,640


337
00:11:32,640 --> 00:11:35,519
um에 노출되는 결과 공간이 특정 감각을 일으킬 수 있었고

338
00:11:35,519 --> 00:11:38,320


339
00:11:38,320 --> 00:11:40,800
이를 사용하여 에이전트는 특히 베이지안 모델 반전

340
00:11:40,800 --> 00:11:43,600


341
00:11:43,600 --> 00:11:45,839
을 역 매핑하는 프로세스를 사용하여 실제 상태에 대한 추론

342
00:11:45,839 --> 00:11:48,079


343
00:11:48,079 --> 00:11:49,680
을 만들고 이를 좀 더 구체적으로 만들기 위해

344
00:11:49,680 --> 00:11:52,000
무엇을  예를 들어

345
00:11:52,000 --> 00:11:55,680
숨겨진 상태를 위치 또는 색상으로 생각

346
00:11:55,680 --> 00:11:58,240


347
00:11:58,240 --> 00:12:00,079
하고 에이전트가 노출될 관찰 공간은

348
00:12:00,079 --> 00:12:00,560
다음과 같습니다.

349
00:12:00,560 --> 00:12:03,680
음 예를 들어 움직임의 속도

350
00:12:03,680 --> 00:12:04,480


351
00:12:04,480 --> 00:12:07,440
나 특정 보상이 음 또는

352
00:12:07,440 --> 00:12:10,959
행복한 얼굴처럼 그들이 노출되고 있다는 것이

353
00:12:10,959 --> 00:12:14,720
음 알았어 그래서 우리가

354
00:12:14,720 --> 00:12:16,320
이것을 조금 더 형식적으로 생각한다면

355
00:12:16,320 --> 00:12:19,920
그래서 우리는 부드러운 모델이 무엇인지

356
00:12:19,920 --> 00:12:21,760
신사 앞에 설명된 음은

357
00:12:21,760 --> 00:12:23,040


358
00:12:23,040 --> 00:12:25,200
이 활성 및 친구

359
00:12:25,200 --> 00:12:26,160


360
00:12:26,160 --> 00:12:29,040
공식 내에서 부분적으로 관찰 가능한 mdp입니다. 여기에서 우리가 고려하고 있는 단순화된 설정에 기반을 두고

361
00:12:29,040 --> 00:12:30,639
있습니다. 여기서

362
00:12:30,639 --> 00:12:32,240


363
00:12:32,240 --> 00:12:35,120
첫 번째는 우리가 논의한 o

364
00:12:35,120 --> 00:12:36,320
이고 두 번째

365
00:12:36,320 --> 00:12:39,680
는  s 여기서 s

366
00:12:39,680 --> 00:12:41,839
는 은닉 상태 또는 잠재

367
00:12:41,839 --> 00:12:44,079
상태를 나타내는 랜덤 변수이며 여기에서 대문자 s로 표시되는 모든 가능한 은닉 상태의 유한 집합 내에 존재하며

368
00:12:44,079 --> 00:12:45,760


369
00:12:45,760 --> 00:12:47,519


370
00:12:47,519 --> 00:12:49,279


371
00:12:49,279 --> 00:12:51,440


372
00:12:51,440 --> 00:12:52,399
o 및

373
00:12:52,399 --> 00:12:54,880
s를 극복할 이 공동 확률은 우도 함수로 인수분해될 수 있습니다.

374
00:12:54,880 --> 00:12:55,440


375
00:12:55,440 --> 00:12:59,120
이것은 주어진 s의 p이고 pss인

376
00:12:59,120 --> 00:13:01,360
내부 상태보다 우선

377
00:13:01,360 --> 00:13:02,720
순위가

378
00:13:02,720 --> 00:13:04,839
있으므로 다음 몇 개의 슬라이드에서 사용할 아주 멋진 공식을 제공합니다.

379
00:13:04,839 --> 00:13:06,240


380
00:13:06,240 --> 00:13:09,519


381
00:13:09,519 --> 00:13:11,839
그리고 제가

382
00:13:11,839 --> 00:13:12,720
묻고 싶었습니다.

383
00:13:12,720 --> 00:13:14,480
제가

384
00:13:14,480 --> 00:13:15,920
강조 표시할 때

385
00:13:15,920 --> 00:13:20,079
또는 제가 마우스를 볼 수 있는지 아니면 거기에 없을 때 제가 볼 수 있습니다. 예 오

386
00:13:20,079 --> 00:13:22,719
예 완벽합니다.

387
00:13:22,800 --> 00:13:24,560
그래서 에이전트가

388
00:13:24,560 --> 00:13:25,600
놀라움을 최소화하려면 모든 것을 주변화해야 할 필요가 있다는 것을 알고 있습니다.

389
00:13:25,600 --> 00:13:27,360


390
00:13:27,360 --> 00:13:29,040
주어진 결과로 이어질 수 있는 가능한 은닉 상태는

391
00:13:29,040 --> 00:13:29,760


392
00:13:29,760 --> 00:13:31,440


393
00:13:31,440 --> 00:13:33,440
내가 방금 우도와 사전 um을 언급한 인수분해를 사용하여 달성

394
00:13:33,440 --> 00:13:34,160


395
00:13:34,160 --> 00:13:37,360


396
00:13:37,360 --> 00:13:40,320
할 수 있지만 문제는

397
00:13:40,320 --> 00:13:42,399
은닉의 차원

398
00:13:42,399 --> 00:13:43,519
이  상태

399
00:13:43,519 --> 00:13:45,360
um은 매우 클 수 있으며

400
00:13:45,360 --> 00:13:47,120


401
00:13:47,120 --> 00:13:48,480
우리가 조금 후에 소개할 추가 확률 변수를 고려한다면

402
00:13:48,480 --> 00:13:50,240
이것은 훨씬 더 문제가 됩니다.

403
00:13:50,240 --> 00:13:51,600


404
00:13:51,600 --> 00:13:54,480
그래서 우리는 uh 다른 수량을 사용합니다.

405
00:13:54,480 --> 00:13:56,240


406
00:13:56,240 --> 00:13:57,199


407
00:13:57,199 --> 00:13:59,920
더 매력적

408
00:13:59,920 --> 00:14:01,920
이며 관심 있는 양 um을 추정

409
00:14:01,920 --> 00:14:05,839


410
00:14:05,839 --> 00:14:08,720
할 수 있으므로 um은 qua의 변형 근사치인 변형 자유 에너지에 대해 이야기하는 자연스러운 단계가 될 것

411
00:14:08,720 --> 00:14:10,160


412
00:14:10,160 --> 00:14:11,760


413
00:14:11,760 --> 00:14:12,800
입니다.

414
00:14:12,800 --> 00:14:15,519
관심의 ntity um 변형 자유 에너지란 무엇인가

415
00:14:15,519 --> 00:14:17,199
그래서 변형 자유 에너지는

416
00:14:17,199 --> 00:14:19,440
놀라움의 상한으로 정의됩니다.

417
00:14:19,440 --> 00:14:20,560
그래서 첫

418
00:14:20,560 --> 00:14:21,920
번째 정의 죄송합니다. 우리가 고려한 첫 번째 정의

419
00:14:21,920 --> 00:14:24,240
는 젠슨의 부등식을 사용하여 파생

420
00:14:24,240 --> 00:14:25,519


421
00:14:25,519 --> 00:14:27,600
되었으며 일반적으로 변형 추론에서 음의 증거 하한으로 알려져 있습니다.

422
00:14:27,600 --> 00:14:29,760


423
00:14:29,760 --> 00:14:32,480
문헌 그래서 우리

424
00:14:32,480 --> 00:14:34,240


425
00:14:34,240 --> 00:14:37,199
는 양변에 음의 로그를 도입하여 본 방정식 4에서 이것을 얻은

426
00:14:37,199 --> 00:14:37,760


427
00:14:37,760 --> 00:14:41,040
다음 이

428
00:14:41,040 --> 00:14:43,680
항에 본질적으로 s의 q에 대한 s의 q인 1을 곱하여 s의

429
00:14:43,680 --> 00:14:45,360


430
00:14:45,360 --> 00:14:48,560
q가 같을 수 없다고 가정합니다  0

431
00:14:48,560 --> 00:14:51,199
으로 설정하고 um을 사용하여 jensen의

432
00:14:51,199 --> 00:14:53,199
부등식을 적용하고 함수 내부로 로그를 이동

433
00:14:53,199 --> 00:14:54,000


434
00:14:54,000 --> 00:14:56,560
하고 여기에서 관심

435
00:14:56,560 --> 00:14:58,000


436
00:14:58,000 --> 00:15:00,079
의

437
00:15:00,079 --> 00:15:01,920
근사치 또는 변동

438
00:15:01,920 --> 00:15:05,040
uh 수량에 대한 관절의 로그에 대한 t of s에 대한 기대치를 갖게 됩니다.  우리

439
00:15:05,040 --> 00:15:07,120
는 부정적인 내부를 취하고

440
00:15:07,120 --> 00:15:07,839
그것을 뒤집을 수 있습니다.

441
00:15:07,839 --> 00:15:11,120
그리고 우리는 여기서 우리가 관심 있는 범위를 얻을 수 있는 첫 번째

442
00:15:11,120 --> 00:15:14,160
좋은 양의 관심을

443
00:15:14,160 --> 00:15:14,560
얻

444
00:15:14,560 --> 00:15:17,199
습니다.

445
00:15:17,199 --> 00:15:17,600


446
00:15:17,600 --> 00:15:20,720


447
00:15:20,720 --> 00:15:24,240


448
00:15:24,480 --> 00:15:25,920
이것을 좀 더 구체적으로 만들기 위해 우리가 할 수 있는 것은 근사값과 관절 사이의 꼬리 부분입니다.

449
00:15:25,920 --> 00:15:27,760
이제 우리가 할 수 있는

450
00:15:27,760 --> 00:15:29,279
것은 변형 자유 에너지를 더 조작하는

451
00:15:29,279 --> 00:15:29,759


452
00:15:29,759 --> 00:15:34,959


453
00:15:34,959 --> 00:15:38,720


454
00:15:38,720 --> 00:15:41,360
것입니다.

455
00:15:41,360 --> 00:15:43,120
우리가 우리가 가지고 있었던 증거를 모델화

456
00:15:43,120 --> 00:15:45,920
하고 놀라움과 변동 자유 에너지 사이

457
00:15:45,920 --> 00:15:47,519
의 연결에 대해 실제로 연마하기 위해 마지막 방정식을 재정렬할 수 있다는 증거

458
00:15:47,519 --> 00:15:48,959


459
00:15:48,959 --> 00:15:51,759
um

460
00:15:51,759 --> 00:15:52,320
그래서

461
00:15:52,320 --> 00:15:55,040
kl이 0보다

462
00:15:55,040 --> 00:15:56,720
작을 수 없음을 의미하는 발산이라는 것을 기억한다

463
00:15:56,720 --> 00:15:58,079


464
00:15:58,079 --> 00:16:01,519
면  음 그것은 항상 엄격하게 어 0보다 크

465
00:16:01,519 --> 00:16:03,440
거나 같음을 의미합니다. 즉

466
00:16:03,440 --> 00:16:06,399
, 근사값이 실제 사후값과 같을 때

467
00:16:06,399 --> 00:16:07,519


468
00:16:07,519 --> 00:16:09,600
자유 에너지

469
00:16:09,600 --> 00:16:10,720


470
00:16:10,720 --> 00:16:13,839
를 최소화하는

471
00:16:13,839 --> 00:16:15,839
것이 본질적으로

472
00:16:15,839 --> 00:16:18,320
젠더 모델을 최대화하는 것과 동일하다는 것을 의미하는 모델 증거와 동일한 변형 자유 에너지로 끝납니다.  증거

473
00:16:18,320 --> 00:16:23,839
음 알았어

474
00:16:25,279 --> 00:16:28,240
음 우리는

475
00:16:28,240 --> 00:16:29,600


476
00:16:29,600 --> 00:16:31,680


477
00:16:31,680 --> 00:16:33,040
변동 자유 에너지

478
00:16:33,040 --> 00:16:34,800
를 po의 함수로 표현하기 위해 um 방정식 10을 가졌다는 이전 방정식을 다시 쓸 수 있습니다

479
00:16:34,800 --> 00:16:36,079
여러 가지 다른 형태의 내재적 신념

480
00:16:36,079 --> 00:16:37,680


481
00:16:37,680 --> 00:16:40,000
이 있으므로 여기서는 복잡성

482
00:16:40,000 --> 00:16:42,800
에서 정확도를 뺀 방정식 12에 초점을 맞추겠습니다. 그래서 이것은 절충안

483
00:16:42,800 --> 00:16:45,440
입니다. 일반적

484
00:16:45,440 --> 00:16:48,839
으로 um

485
00:16:48,839 --> 00:16:50,160
복잡성 탐

486
00:16:50,160 --> 00:16:53,600
또는 복잡성 비용이 본질적으로  음

487
00:16:53,600 --> 00:16:57,120
당신의 케일 사이의 대략적인 um

488
00:16:57,120 --> 00:17:01,120
of s는 pi와 uh와 관련하여

489
00:17:01,120 --> 00:17:05,199
주어졌습니다. 여기서 pi는 um pi가 주어졌습니다. 여기에서 pi

490
00:17:05,199 --> 00:17:07,280
는 단지 귀하의 정책이며 이는

491
00:17:07,280 --> 00:17:09,280


492
00:17:09,280 --> 00:17:12,319
uh 대리인이 어떻게 행동할지에 대한 가설과 무관할 수 있습니다.

493
00:17:12,319 --> 00:17:14,079
하지만 제가 올게요  정책이 실제로 수반하는 것으로 돌아가지만

494
00:17:14,079 --> 00:17:15,679


495
00:17:15,679 --> 00:17:17,599
지금은 관심 있는 궤적의 시퀀스에 대한 자유 에너지를 조건화할 수 있는 용어로 간주

496
00:17:17,599 --> 00:17:19,919


497
00:17:19,919 --> 00:17:22,319


498
00:17:22,319 --> 00:17:23,679


499
00:17:23,679 --> 00:17:26,319
하고 두 번째 용어는

500
00:17:26,319 --> 00:17:27,599


501
00:17:27,599 --> 00:17:31,200
주어진 s의 로그 확률이므로 가능성이

502
00:17:31,200 --> 00:17:34,559
uh  a 정확도를 제공하는 s의 키와 관련

503
00:17:34,559 --> 00:17:37,200


504
00:17:37,200 --> 00:17:39,120
하여 생각할 수 있는 간단한 방법은

505
00:17:39,120 --> 00:17:42,240
음 이것이 바로 음 음 모델이 얼마나 정확한지,

506
00:17:42,240 --> 00:17:43,440
그리고 이것은 s

507
00:17:43,440 --> 00:17:45,919
를 만드는 페널티 항인 일부 정규화 항입니다.

508
00:17:45,919 --> 00:17:47,200


509
00:17:47,200 --> 00:17:49,280
우리의 초기 사전에서 너무 멀리 발산하지

510
00:17:49,280 --> 00:17:52,320


511
00:17:52,320 --> 00:17:55,679
않는지 확인합니다. 따라서 이 특정 양의

512
00:17:55,679 --> 00:17:56,960
변동 자유 에너지

513
00:17:56,960 --> 00:17:58,480
는 이 시점에서 에너지 변동에 대해 질문이 있습니다.

514
00:17:58,480 --> 00:18:01,039


515
00:18:01,039 --> 00:18:03,760
아직 감사하지 않습니다.

516
00:18:03,760 --> 00:18:05,360


517
00:18:05,360 --> 00:18:07,360
환경을 인식

518
00:18:07,360 --> 00:18:09,200


519
00:18:09,200 --> 00:18:11,039


520
00:18:11,039 --> 00:18:11,760


521
00:18:11,760 --> 00:18:14,240
하고 에이전트가 주어진 시점에서 상호 작용하는 주어진 세계에 대해 추론하는 능동적 영향 공식의 한 부분을 해결

522
00:18:14,240 --> 00:18:16,080


523
00:18:16,080 --> 00:18:16,880


524
00:18:16,880 --> 00:18:19,440
하지만 우리는 실제로

525
00:18:19,440 --> 00:18:20,320


526
00:18:20,320 --> 00:18:22,960
활성 부분을 설명하지 않았지만 이 특정

527
00:18:22,960 --> 00:18:23,600
에이전트

528
00:18:23,600 --> 00:18:25,679
처럼 우리는 가지고 있습니다.  능동 추론 공식 하에서

529
00:18:25,679 --> 00:18:26,880


530
00:18:26,880 --> 00:18:29,520
일련의 행동을 취하거나 환경과 상호 작용

531
00:18:29,520 --> 00:18:31,360


532
00:18:31,360 --> 00:18:34,240
하여 미래에 그 환경에 영향을 미칠 수 있습니다.

533
00:18:34,240 --> 00:18:34,960


534
00:18:34,960 --> 00:18:37,280
그래서 이것을 조금 더 동기를 부여하기

535
00:18:37,280 --> 00:18:38,880
위해 우리가 생각할 수 있는

536
00:18:38,880 --> 00:18:40,480
것은 최소화하려는 것뿐만 아니라  우리의 변형

537
00:18:40,480 --> 00:18:42,240
자유 에너지 우리는 또한 예상되는 자유 에너지라고 불리는 양을 최소화하기를 원합니다.

538
00:18:42,240 --> 00:18:44,320


539
00:18:44,320 --> 00:18:46,320


540
00:18:46,320 --> 00:18:48,240
미래

541
00:18:48,240 --> 00:18:50,799
의 미래 또는 미래에 대한 관찰과

542
00:18:50,799 --> 00:18:52,080
이

543
00:18:52,080 --> 00:18:54,480
특정 용어의 최소화를 통해 에이전트는 정책 세트에서 선택된 현재의 특정 조치

544
00:18:54,480 --> 00:18:56,400
를 취함으로써 미래에 영향을 미칠 수 있습니다.

545
00:18:56,400 --> 00:18:58,400


546
00:18:58,400 --> 00:19:00,080


547
00:19:00,080 --> 00:19:02,720
그래서 지금 몇 번 정책을 언급했습니다.

548
00:19:02,720 --> 00:19:03,520


549
00:19:03,520 --> 00:19:06,960
그래서 정책은

550
00:19:06,960 --> 00:19:09,280
시간

551
00:19:09,280 --> 00:19:10,240
tau

552
00:19:10,240 --> 00:19:12,240
에서 에이전트가 숨겨진 상태와 tau 사이를 전환할 수 있도록 하는 일련의 작업으로 정의할 수 있습니다.

553
00:19:12,240 --> 00:19:13,760


554
00:19:13,760 --> 00:19:17,520
여기서 tau는 본질적

555
00:19:17,520 --> 00:19:19,120
으로 특정 지평까지의 궤적 시퀀스

556
00:19:19,120 --> 00:19:21,039


557
00:19:21,039 --> 00:19:24,320


558
00:19:24,320 --> 00:19:25,679
로 정의

559
00:19:25,679 --> 00:19:27,760
됩니다.  특정 설정에서 고려하고 있는 단계

560
00:19:27,760 --> 00:19:29,280


561
00:19:29,280 --> 00:19:32,320
와 uh 정책을 적절하게 정의하려면

562
00:19:32,320 --> 00:19:33,919
두 개의

563
00:19:33,919 --> 00:19:35,440
추가 임의 변수를 도입해야 합니다.

564
00:19:35,440 --> 00:19:38,160
따라서 첫 번째 변수

565
00:19:38,160 --> 00:19:38,960


566
00:19:38,960 --> 00:19:43,039
는 여기에서 utau로 표시되는 tau를 조건으로 하는 작업

567
00:19:43,039 --> 00:19:46,160
이며 이는 유한 집합 내에 존재합니다.

568
00:19:46,160 --> 00:19:48,320
에이전트가 취할 수 있는 모든 가능한 조치

569
00:19:48,320 --> 00:19:49,200


570
00:19:49,200 --> 00:19:50,960
와 우리가 도입한 두 번째 랜덤 변수

571
00:19:50,960 --> 00:19:52,640


572
00:19:52,640 --> 00:19:54,559
는 우리가 논의한 파이인 어 정책입니다.

573
00:19:54,559 --> 00:19:55,919
ssed

574
00:19:55,919 --> 00:19:58,000
및 이것은 우리가 여기서 관심을 갖는 순차적 정책 최적화와 같은 의미에서

575
00:19:58,000 --> 00:19:58,960
가능한 모든

576
00:19:58,960 --> 00:20:02,000
uh 정책 음 또는 일련의 작업의 유한 집합 내에 존재

577
00:20:02,000 --> 00:20:04,640


578
00:20:04,640 --> 00:20:06,240


579
00:20:06,240 --> 00:20:08,240
하므로 조금 더

580
00:20:08,240 --> 00:20:09,520
구체적인 카이

581
00:20:09,520 --> 00:20:11,200
헤어 랜덤 변수가 될 수 있습니다.

582
00:20:11,200 --> 00:20:13,440


583
00:20:13,440 --> 00:20:16,559
특정 시간 지평선 tau에 걸쳐 일련의 작업으로 분해

584
00:20:16,559 --> 00:20:19,760


585
00:20:19,760 --> 00:20:23,280
되므로 u1 u2 및 um up to utah는 시점

586
00:20:23,280 --> 00:20:25,120
에서 uh 작업으로부터의 작업을 나타낼 것이며

587
00:20:25,120 --> 00:20:26,960
시점 2의 한 작업 등

588
00:20:26,960 --> 00:20:28,799


589
00:20:28,799 --> 00:20:31,360
을 고려할 때 링크는 명시적

590
00:20:31,360 --> 00:20:32,320
입니다.

591
00:20:32,320 --> 00:20:35,679
특정 시점에 정책을 고려한다면

592
00:20:35,679 --> 00:20:38,880


593
00:20:38,880 --> 00:20:41,840
당신이 얻는 행동은 그 행동이 될 것입니다.

594
00:20:41,840 --> 00:20:45,280
좋습니다.

595
00:20:45,280 --> 00:20:47,360


596
00:20:47,360 --> 00:20:49,120


597
00:20:49,120 --> 00:20:50,559


598
00:20:50,559 --> 00:20:53,520


599
00:20:53,520 --> 00:20:54,240


600
00:20:54,240 --> 00:20:56,640
그들이 정책을 말할 때 국가 행동 정책을 의미

601
00:20:56,640 --> 00:20:58,000


602
00:20:58,000 --> 00:20:59,840
하므로 내가 방금 언급한

603
00:20:59,840 --> 00:21:02,240
추론 행위 정책은 단순히

604
00:21:02,240 --> 00:21:04,159
시간에 따른 행동에 대한 선택의 시퀀스

605
00:21:04,159 --> 00:21:06,159
이며 순차 정책입니다.

606
00:21:06,159 --> 00:21:08,320
이것은 상태를 액션으로 매핑

607
00:21:08,320 --> 00:21:10,400
하는 강화 학습

608
00:21:10,400 --> 00:21:12,080
의 상태

609
00:21:12,080 --> 00:21:16,080
액션 정책과 다릅니다. 따라서

610
00:21:16,080 --> 00:21:16,720


611
00:21:16,720 --> 00:21:19,919
액션과 상태를 고려하는 RL 정책은 상태가

612
00:21:19,919 --> 00:21:20,799


613
00:21:20,799 --> 00:21:24,159
주어지고

614
00:21:24,159 --> 00:21:27,919
um 우리의 mdp 공식

615
00:21:27,919 --> 00:21:30,159
에서 액션의 정의가 주어진 액션의 확률입니다.  죄송합니다

616
00:21:30,159 --> 00:21:31,760
. rl의 정책 정의

617
00:21:31,760 --> 00:21:33,760
와 능동 추론은

618
00:21:33,760 --> 00:21:35,679


619
00:21:35,679 --> 00:21:37,679
tau가 1인 설정을 고려할 때 정확히 동일하므로 한 단계 앞서만 고려하고 있습니다. 좋습니다

620
00:21:37,679 --> 00:21:41,120


621
00:21:41,120 --> 00:21:45,120


622
00:21:45,120 --> 00:21:45,760


623
00:21:45,760 --> 00:21:49,039
.  양적

624
00:21:49,039 --> 00:21:50,960
관심 그들은 자유 에너지를 예상

625
00:21:50,960 --> 00:21:54,080
했습니다. 우리가 그것을 어떻게 유도합니까? 그것을 유도하려면

626
00:21:54,080 --> 00:21:56,240
먼저 몇 슬라이드 전에 이전에

627
00:21:56,240 --> 00:21:57,840
가졌던 변동적 자유 에너지 정의

628
00:21:57,840 --> 00:22:00,000
를 확장해야

629
00:22:00,000 --> 00:22:02,240
하며 이제는

630
00:22:02,240 --> 00:22:03,360


631
00:22:03,360 --> 00:22:06,799
시간과 tau 모두에 종속되도록 해야 합니다.  정책과 우리

632
00:22:06,799 --> 00:22:07,919
가 본질적으로 하고 있는 일은

633
00:22:07,919 --> 00:22:10,320
동일한 방정식을 취하고 특정 정책에 따라

634
00:22:10,320 --> 00:22:12,320
이전의 죄송한 이전 및 현재 시간 단계에 대해 분해하는 것입니다.

635
00:22:12,320 --> 00:22:14,320


636
00:22:14,320 --> 00:22:16,080


637
00:22:16,080 --> 00:22:18,080
이것이 우리가 컨디셔닝을 가지고 있는 이유

638
00:22:18,080 --> 00:22:20,480


639
00:22:20,480 --> 00:22:23,520
이며 방정식 15에서 um을 특정 방식으로 분해

640
00:22:23,520 --> 00:22:25,039
한 다음 방정식 16에서 행렬 공식을 작성하는 것입니다.

641
00:22:25,039 --> 00:22:27,360


642
00:22:27,360 --> 00:22:28,960
따라서 질문이 있지만 핵심 사항이 있는 경우 이

643
00:22:28,960 --> 00:22:31,039
질문으로 돌아올

644
00:22:31,039 --> 00:22:32,880
수 있습니다.

645
00:22:32,880 --> 00:22:35,039
슬라이드에서 벗어나 이제 우리는

646
00:22:35,039 --> 00:22:37,120


647
00:22:37,120 --> 00:22:40,799
에너지 um에 대한 변화에 대해 시간 um에 대한 기능적 종속성

648
00:22:40,799 --> 00:22:42,799
을 포함하고 있으며 이제

649
00:22:42,799 --> 00:22:45,120
예상되는 자유 에너지 공식

650
00:22:45,120 --> 00:22:47,280
um으로 이동할 수 있지만 여기서 주목해야 할 핵심

651
00:22:47,280 --> 00:22:49,360
은 우리가  시점 만 고려

652
00:22:49,360 --> 00:22:52,320
um 이전 시점과

653
00:22:52,320 --> 00:22:52,799
현재

654
00:22:52,799 --> 00:22:55,840
미래가 전혀 없으므로

655
00:22:58,000 --> 00:23:00,320


656
00:23:00,320 --> 00:23:01,440


657
00:23:01,440 --> 00:23:04,559
uh 예상 자유 에너지 um

658
00:23:04,559 --> 00:23:06,720
및 예상 자유 에너지가 무엇인지 도출하기 전에 자유 에너지 방정식을 사용하면 예상 자유

659
00:23:06,720 --> 00:23:08,320


660
00:23:08,320 --> 00:23:11,200
에너지 um 자유 에너지  미래

661
00:23:11,200 --> 00:23:12,159
궤적의 기능

662
00:23:12,159 --> 00:23:14,559
g 및 아직 관찰

663
00:23:14,559 --> 00:23:16,400


664
00:23:16,400 --> 00:23:18,240
되지 않은 결과를 기반으로 하는 그럴듯한 정책에 대한 증거를 효과적으로 평가

665
00:23:18,240 --> 00:23:19,760
하므로 이것이 핵심이므로

666
00:23:19,760 --> 00:23:20,640


667
00:23:20,640 --> 00:23:24,240
여론 조사 집합에 대해 추론하는 것입니다.

668
00:23:24,240 --> 00:23:26,000


669
00:23:26,000 --> 00:23:28,000


670
00:23:28,000 --> 00:23:30,640


671
00:23:30,640 --> 00:23:31,679


672
00:23:31,679 --> 00:23:34,159


673
00:23:34,159 --> 00:23:35,120
우리

674
00:23:35,120 --> 00:23:38,960
가 방정식 17에서 볼 수 있는 g 공식에 도달하기 위해 여기에 소개된 두 가지 발견적 방법이 있습니다. 첫 번째

675
00:23:38,960 --> 00:23:41,440
방법은 미래

676
00:23:41,440 --> 00:23:42,320
결과

677
00:23:42,320 --> 00:23:44,159
에 대한 믿음을 포함하는 것입니다.  여기

678
00:23:44,159 --> 00:23:46,000


679
00:23:46,000 --> 00:23:48,159


680
00:23:48,159 --> 00:23:50,000


681
00:23:50,000 --> 00:23:51,440
에서

682
00:23:51,440 --> 00:23:53,279
이 첫 번째 두

683
00:23:53,279 --> 00:23:54,880
항

684
00:23:54,880 --> 00:23:57,600
과 두 번째 항에 의해

685
00:23:57,600 --> 00:23:58,559


686
00:23:58,559 --> 00:24:00,799
주어진 예측 분포를 초래하는

687
00:24:00,799 --> 00:24:02,799
가능성으로 대략

688
00:24:02,799 --> 00:24:06,080
적인 사후 조건에서 기대를 보충합니다.  모델 음

689
00:24:06,080 --> 00:24:08,960
죄송합니다. 성별 모델 음 죄송합니다. 특정 정책

690
00:24:08,960 --> 00:24:10,159


691
00:24:10,159 --> 00:24:13,200
과 반대로 원하는 상황에 따라 달라집니다.

692
00:24:13,200 --> 00:24:14,880
따라서

693
00:24:14,880 --> 00:24:16,799
이는 에이전트가 가질 선호 유형을 제한

694
00:24:16,799 --> 00:24:17,440


695
00:24:17,440 --> 00:24:20,640
하고 우리가 만들고 있는 이

696
00:24:20,640 --> 00:24:21,200
두 가지

697
00:24:21,200 --> 00:24:22,720
움직임에 도움이 되는 것은 우리가 할 수 있다는 것입니다.

698
00:24:22,720 --> 00:24:24,480
이제

699
00:24:24,480 --> 00:24:27,200
실제로 관찰을 하기 전에 이 양을 평가

700
00:24:27,200 --> 00:24:28,240
하고 두 번째

701
00:24:28,240 --> 00:24:30,400
것은 g의 최소화가

702
00:24:30,400 --> 00:24:32,080
실제로  분노 정치

703
00:24:32,080 --> 00:24:35,440


704
00:24:35,440 --> 00:24:37,520
정책이 어 에이전트가 자신에게 기대하는 원하는 상태와 일치하도록 해야 합니다

705
00:24:37,520 --> 00:24:39,760


706
00:24:39,760 --> 00:24:41,600
음 저는 이것이 예상되는 자유 에너지

707
00:24:41,600 --> 00:24:44,240
를 도출하는 유일한 방법이 아니며

708
00:24:44,240 --> 00:24:45,679


709
00:24:45,679 --> 00:24:47,760
몇 가지 작업을 살펴보았다는 점을 간단히 언급할 것입니다.  다른

710
00:24:47,760 --> 00:24:48,960
공식에서

711
00:24:48,960 --> 00:24:52,240
uh

712
00:24:52,240 --> 00:24:53,600
예상 자유 에너지의 공식이

713
00:24:53,600 --> 00:24:55,919
다른 구조로 분해될 수 있는 carl

714
00:24:55,919 --> 00:24:58,799
um의 작업을 포함하여 누구든지 관심이

715
00:24:58,799 --> 00:25:02,480
있다면 나중에 우리가 그것을 살펴볼 수

716
00:25:02,640 --> 00:25:04,799
있지만 이 자유

717
00:25:04,799 --> 00:25:05,679
에너지는

718
00:25:05,679 --> 00:25:07,520
내가 방금 소개한 예상 자유 에너지가 될 수 있습니다

719
00:25:07,520 --> 00:25:10,320
특정 방식으로 분해되어 식 20과 21

720
00:25:10,320 --> 00:25:10,799
은

721
00:25:10,799 --> 00:25:13,200


722
00:25:13,200 --> 00:25:14,960
첫 번째 분해가 인식론적

723
00:25:14,960 --> 00:25:17,039
가치와 외재적 가치 거래자이고 두

724
00:25:17,039 --> 00:25:18,960
번째 분해가 예상되는

725
00:25:18,960 --> 00:25:22,320
비용과 모호성 항이라는 두 가지 다른 분해를 제공하므로

726
00:25:22,320 --> 00:25:23,360


727
00:25:23,360 --> 00:25:26,640
um을 고려하면 첫 번째 방정식

728
00:25:26,640 --> 00:25:28,080
이 방정식을 최소화하는 경우 관찰에서

729
00:25:28,080 --> 00:25:30,559
얻을 수 있는 정보 이득을 최대화하기 위해 이 명령을 포착하고 있다고 말할 수 있습니다.

730
00:25:30,559 --> 00:25:31,360


731
00:25:31,360 --> 00:25:33,760


732
00:25:33,760 --> 00:25:35,679
환경

733
00:25:35,679 --> 00:25:38,880
um 특정 은닉 상태에 대한 환경 um

734
00:25:38,880 --> 00:25:41,840


735
00:25:41,840 --> 00:25:43,360


736
00:25:43,360 --> 00:25:45,520


737
00:25:45,520 --> 00:25:46,559
여기서 로그 선호도 또는 외부 값에 의해 득점되는 예상 값을 최대화하므로

738
00:25:46,559 --> 00:25:48,159
이 특정 공식은 실제로

739
00:25:48,159 --> 00:25:50,320


740
00:25:50,320 --> 00:25:50,880


741
00:25:50,880 --> 00:25:53,200
um 사이의 매우 명확한 트레이드오프

742
00:25:53,200 --> 00:25:54,960
를 제공합니다.

743
00:25:54,960 --> 00:25:57,120


744
00:25:57,120 --> 00:25:59,760
에이전트

745
00:25:59,760 --> 00:26:00,799
가

746
00:26:00,799 --> 00:26:02,400


747
00:26:02,400 --> 00:26:04,960
환경에 대한 불확실성을 최소화

748
00:26:04,960 --> 00:26:07,520
하고 후자의 비트가 더 실용적이고

749
00:26:07,520 --> 00:26:08,400


750
00:26:08,400 --> 00:26:11,360


751
00:26:11,360 --> 00:26:13,360


752
00:26:13,360 --> 00:26:15,679
에이전트가 할 정책 유형에 대한 이러한 이해를 통해 착취적 행동을 장려하는 이러한 새로운 상태를 찾을 때 에이전트가 탐색을 통해 원하는 것입니다.

753
00:26:15,679 --> 00:26:16,720


754
00:26:16,720 --> 00:26:18,960
즉, 이러한 예상

755
00:26:18,960 --> 00:26:20,480
자유 에너지 공식

756
00:26:20,480 --> 00:26:23,200
과 같이 um에 도달하는 것을 선호하며 방정식 20에서 볼 수 있는 것은

757
00:26:23,200 --> 00:26:24,559
본질적으로

758
00:26:24,559 --> 00:26:26,640
탐색과 개발을

759
00:26:26,640 --> 00:26:28,240
동일한 문제를 해결하는 두 가지 다른 방법으로 취급

760
00:26:28,240 --> 00:26:28,799


761
00:26:28,799 --> 00:26:31,440


762
00:26:31,440 --> 00:26:34,720
하여 프레젠테이션 시작 부분에서 언급한 불확실성을 최소화하는 것입니다.

763
00:26:34,720 --> 00:26:37,120


764
00:26:37,120 --> 00:26:38,159


765
00:26:38,159 --> 00:26:41,279
여기서 두 번째 방정식을 생각할 수도 있습니다.  ich는 우리에게

766
00:26:41,279 --> 00:26:43,200


767
00:26:43,200 --> 00:26:45,360


768
00:26:45,360 --> 00:26:47,919
에이전트가 모호성

769
00:26:47,919 --> 00:26:50,000
과

770
00:26:50,000 --> 00:26:52,000
특정 정책에 따른 결과가

771
00:26:52,000 --> 00:26:55,039
사전 선호도에서 벗어나는 정도를 최소화하고자 하는 자유 기대 빈도에 대한 대안적인 관점을 제공할 뿐입니다. 따라서 여기서 모호성

772
00:26:55,039 --> 00:26:56,880
은 조건부

773
00:26:56,880 --> 00:26:58,880
엔트로피 또는

774
00:26:58,880 --> 00:27:01,600


775
00:27:01,600 --> 00:27:02,799
이 특정 설정에서 현재 정책에 따른 결과

776
00:27:02,799 --> 00:27:04,559
낮은 엔트로피는 결과

777
00:27:04,559 --> 00:27:06,240
가 매우 두드러지고

778
00:27:06,240 --> 00:27:08,320
숨겨진 상태에 대해 고유한 정보를 제공

779
00:27:08,320 --> 00:27:10,320
한다는

780
00:27:10,320 --> 00:27:11,760
것을 암시

781
00:27:11,760 --> 00:27:13,039


782
00:27:13,039 --> 00:27:14,720


783
00:27:14,720 --> 00:27:16,080
합니다.

784
00:27:16,080 --> 00:27:19,440
추가로

785
00:27:19,440 --> 00:27:20,880
에이전트는 선호하는 결과와 유사한 정책 의존적 결과를 추구하기를 원

786
00:27:20,880 --> 00:27:21,520


787
00:27:21,520 --> 00:27:23,760


788
00:27:23,760 --> 00:27:25,039


789
00:27:25,039 --> 00:27:27,120
하므로 여기에서 c에 의해 기부되며 이는 예측된 결과와 선호하는 결과 사이

790
00:27:27,120 --> 00:27:29,279
의 치료 차이가 있을 때 달성된다는 점에서 중요한 것을 만들지 않을 것입니다.

791
00:27:29,279 --> 00:27:31,039


792
00:27:31,039 --> 00:27:34,320


793
00:27:34,320 --> 00:27:37,679
특정 정책에 의해 최소화됩니다.

794
00:27:37,679 --> 00:27:40,880
그래 음 및 이러한 사전 신념은

795
00:27:40,880 --> 00:27:41,520
ut 미래

796
00:27:41,520 --> 00:27:42,960
결과는 에이전트에게

797
00:27:42,960 --> 00:27:44,960
목표 지향적 행동을 제공합니다.

798
00:27:44,960 --> 00:27:46,960
이것은

799
00:27:46,960 --> 00:27:48,320


800
00:27:48,320 --> 00:27:51,840
적극적인 영향력에서 정말 중요한 경우라고

801
00:27:51,840 --> 00:27:54,640
생각합니다. 그래서 일단 예상되는

802
00:27:54,640 --> 00:27:56,240
자유 에너지가 있으면 정책을 도출할 수 있습니다.

803
00:27:56,240 --> 00:28:00,159
um so

804
00:28:00,159 --> 00:28:02,240
um and this  예상 자유 에너지에

805
00:28:02,240 --> 00:28:04,080


806
00:28:04,080 --> 00:28:06,399
대해 소프트 맥스 함수를 적용하여 정책의 확률을 유도함으로써 실현되며

807
00:28:06,399 --> 00:28:08,480


808
00:28:08,480 --> 00:28:09,919
, 이러한 종류는 예상 자유 에너지를 낮추는

809
00:28:09,919 --> 00:28:11,760


810
00:28:11,760 --> 00:28:12,559


811
00:28:12,559 --> 00:28:14,559
모든 종류의 정책 또는 행동

812
00:28:14,559 --> 00:28:16,480
시퀀스가 더 많기 때문에 능동 추론의 자명한 행동을 보여줍니

813
00:28:16,480 --> 00:28:18,240


814
00:28:18,240 --> 00:28:21,520


815
00:28:21,520 --> 00:28:24,159
다.  예상되는 자유 에너지

816
00:28:24,159 --> 00:28:25,039
는 세상

817
00:28:25,039 --> 00:28:26,960


818
00:28:26,960 --> 00:28:28,640


819
00:28:28,640 --> 00:28:30,399
과 상호 작용할 때 포함하거나 고려하고 싶은 모든 유형의

820
00:28:30,399 --> 00:28:31,600
것들을 캡슐화하므로 탐색

821
00:28:31,600 --> 00:28:32,960
하고 싶고 이용하고 싶지만

822
00:28:32,960 --> 00:28:36,000
그 균형을 유지하고

823
00:28:36,000 --> 00:28:38,159
정책을 선택할 때 um

824
00:28:38,159 --> 00:28:39,600
에 가장 근접하게 만드는 일련의 조치를 결정하는 문제일 뿐입니다.

825
00:28:39,600 --> 00:28:40,159


826
00:28:40,159 --> 00:28:42,960


827
00:28:42,960 --> 00:28:44,000
특정 코어

828
00:28:44,000 --> 00:28:45,760
um 및 이것은 um 이전에 설명한 C 매트릭스에

829
00:28:45,760 --> 00:28:48,960
의해 정의된 매력적인 상태에 의해 정의될 수

830
00:28:48,960 --> 00:28:52,480


831
00:28:52,480 --> 00:28:55,200
있습니다. 그렇지 않은

832
00:28:55,200 --> 00:28:56,159
경우 um

833
00:28:56,159 --> 00:28:57,919
을 얻을 수 있는 무작위 탐색일 뿐입니다

834
00:28:57,919 --> 00:28:59,600


835
00:28:59,600 --> 00:29:01,600
. 온도 매개변수 베타도 포함할 수 있습니다.

836
00:29:01,600 --> 00:29:03,760
여기

837
00:29:03,760 --> 00:29:06,080
음, 여기에 초소수를 가짐으로써

838
00:29:06,080 --> 00:29:07,520


839
00:29:07,520 --> 00:29:09,440


840
00:29:09,440 --> 00:29:10,799
예상되는 자유 에너지

841
00:29:10,799 --> 00:29:14,720
어 공식화에 추가적인 복잡성 비용을 도입

842
00:29:14,720 --> 00:29:17,840


843
00:29:17,840 --> 00:29:20,880


844
00:29:20,880 --> 00:29:23,279


845
00:29:23,279 --> 00:29:24,159


846
00:29:24,159 --> 00:29:27,919
하여 정책 공간 음 키보다 선호하는 선호도가 얼마나 평평하거나 얼마나 확실하거나 정확하기를 원하는지 설명할 수 있습니다.

847
00:29:27,919 --> 00:29:31,279
참고할 점은 음

848
00:29:31,279 --> 00:29:33,039
단순성을 위해 최적화

849
00:29:33,039 --> 00:29:34,880


850
00:29:34,880 --> 00:29:37,200
방법에 대한 자세한 내용은

851
00:29:37,200 --> 00:29:37,919


852
00:29:37,919 --> 00:29:40,159
다루지 않을 것이지만

853
00:29:40,159 --> 00:29:41,919
예를 들어 능동 추론과 같은 여러 가지 방법으로 수행

854
00:29:41,919 --> 00:29:42,720


855
00:29:42,720 --> 00:29:45,039
할 수 있다는 점입니다.

856
00:29:45,039 --> 00:29:47,039
숨겨진 관심 상태 정책

857
00:29:47,039 --> 00:29:48,640
이 추론된 정밀도

858
00:29:48,640 --> 00:29:50,320
와 관련된 학습 절차를 통해 um을 통해 모델 매개변수를 최적화할 수도 있습니다.

859
00:29:50,320 --> 00:29:51,679


860
00:29:51,679 --> 00:29:53,919


861
00:29:53,919 --> 00:29:54,960


862
00:29:54,960 --> 00:29:58,080
음 하지만 그런 종류

863
00:29:58,080 --> 00:30:00,000
는 보고 있는 설정에 따라 다릅니다. 예를 들어

864
00:30:00,000 --> 00:30:01,600
변형 기반을 사용하는 경우

865
00:30:01,600 --> 00:30:02,559


866
00:30:02,559 --> 00:30:04,799


867
00:30:04,799 --> 00:30:06,559
수렴 또는 활성 추론이 될 때까지 이러한 함수 또는 목적 함수를 반복합니다.

868
00:30:06,559 --> 00:30:08,960
음은 그래디언트를 수행

869
00:30:08,960 --> 00:30:10,080


870
00:30:10,080 --> 00:30:12,000
하여 찾을 수 있습니다.  다시 흥미로운 충분한 통계

871
00:30:12,000 --> 00:30:13,919


872
00:30:13,919 --> 00:30:15,840


873
00:30:15,840 --> 00:30:18,080
는 보고 있는 공식 및 설정에 따라

874
00:30:18,080 --> 00:30:20,240
다르지만 여기서 주목해야 할 핵심

875
00:30:20,240 --> 00:30:21,679


876
00:30:21,679 --> 00:30:23,760
은 활성

877
00:30:23,760 --> 00:30:25,360
추론 알고리즘에 유용하고

878
00:30:25,360 --> 00:30:26,159


879
00:30:26,159 --> 00:30:28,960
이 특정에서 가져올 수 있는 세 가지 특정 측면이 있다는 것입니다.  uh

880
00:30:28,960 --> 00:30:29,679
프레임워크

881
00:30:29,679 --> 00:30:32,799
및 uh 다른 설정에 적용

882
00:30:32,799 --> 00:30:34,559
음 그래서 간단히 반복하고

883
00:30:34,559 --> 00:30:36,080
요약할

884
00:30:36,080 --> 00:30:38,000
것이므로 먼저 중요한 성별 모델이

885
00:30:38,000 --> 00:30:39,679
있으므로 에이전트가

886
00:30:39,679 --> 00:30:41,440
상호 작용하고 놀라움을 최소화

887
00:30:41,440 --> 00:30:43,520
하려면 세상의 부드러운 모델이 필요

888
00:30:43,520 --> 00:30:46,880
하고  그것은 단순히 내가

889
00:30:46,880 --> 00:30:48,640


890
00:30:48,640 --> 00:30:50,240
여기에 모델 매개 변수를 포함하지 않는 것이 아니라

891
00:30:50,240 --> 00:30:52,159
귀하의 결과를 귀하의 상태와

892
00:30:52,159 --> 00:30:53,679
정책으로

893
00:30:53,679 --> 00:30:56,960
가질 수 있다고 설명합니다.  음으로 분해됩니다.

894
00:30:56,960 --> 00:30:59,120
죄송합니다. 여기에 괄호가 있는 화살표가

895
00:30:59,120 --> 00:31:00,000
있지만

896
00:31:00,000 --> 00:31:03,120
이것들은

897
00:31:03,120 --> 00:31:04,720
이전 가능성과 전환

898
00:31:04,720 --> 00:31:05,760
기능

899
00:31:05,760 --> 00:31:07,840
으로 분해된 다음 이 생식기 모델이 있으면 설정

900
00:31:07,840 --> 00:31:10,000
합니다. 에이전트

901
00:31:10,000 --> 00:31:11,519
는 모델을 표본

902
00:31:11,519 --> 00:31:13,360
관찰에 맞춰 감소시킵니다.

903
00:31:13,360 --> 00:31:14,960
가격은 변동 자유

904
00:31:14,960 --> 00:31:17,279
에너지 최적화를 통해 이루어지므로

905
00:31:17,279 --> 00:31:19,120


906
00:31:19,120 --> 00:31:21,840
복잡성과 정확도 비용 사이

907
00:31:21,840 --> 00:31:22,240
에 특별한

908
00:31:22,240 --> 00:31:24,000
절충안이 있습니다. 두 번째로 죄송합니다. 이 알고리즘의 마지막 부분

909
00:31:24,000 --> 00:31:25,760
은 계획을 수립

910
00:31:25,760 --> 00:31:27,760
하여 불확실성을 최소화하는 조치를 선택하는 것

911
00:31:27,760 --> 00:31:29,200


912
00:31:29,200 --> 00:31:32,000
입니다.  예상되는 자유 에너지

913
00:31:32,000 --> 00:31:33,760
이고 이를 수행하는 방법은 여기에

914
00:31:33,760 --> 00:31:34,480


915
00:31:34,480 --> 00:31:37,600
있는 양의 음수에 대해 소프트 최대값

916
00:31:37,600 --> 00:31:39,120


917
00:31:39,120 --> 00:31:41,360
을

918
00:31:41,360 --> 00:31:42,720
설정한 다음 다음 사양을 선택하기 위해 다음 사양을 선택하기

919
00:31:42,720 --> 00:31:46,080


920
00:31:46,080 --> 00:31:49,600
위해 샘플링하는 것입니다.

921
00:31:49,600 --> 00:31:51,760
방대한 양의 활성 추론 문헌에 대해 자세히 살펴

922
00:31:51,760 --> 00:31:52,799


923
00:31:52,799 --> 00:31:53,600
보았지만 관심이 있다면 이

924
00:31:53,600 --> 00:31:55,120
세 가지 핵심 요소

925
00:31:55,120 --> 00:31:57,120
가

926
00:31:57,120 --> 00:31:59,279
이러한 알고리즘을 직접 구현하는 것은

927
00:31:59,279 --> 00:32:01,440
괜찮습니다. 이제

928
00:32:01,440 --> 00:32:02,720
기어를 조금 바꾸고 강화 학습

929
00:32:02,720 --> 00:32:04,080
과의 비교를

930
00:32:04,080 --> 00:32:07,679
살펴보겠습니다. 그래서 우리 작업에서 우리

931
00:32:07,679 --> 00:32:09,360
는 수정된 버전의

932
00:32:09,360 --> 00:32:10,320
개방형 ai

933
00:32:10,320 --> 00:32:12,880
체육관을 동결 호수 환경으로 고려하여 얼어붙은

934
00:32:12,880 --> 00:32:14,720
호수에 그리드가 있습니다.

935
00:32:14,720 --> 00:32:17,120
4개의 별개 패치가 있는 구조처럼

936
00:32:17,120 --> 00:32:18,399
시작점이

937
00:32:18,399 --> 00:32:22,000
합계이므로 여기에서 볼 수 있습니다. 음 죄송합니다.

938
00:32:22,000 --> 00:32:22,799
하지만 매우

939
00:32:22,799 --> 00:32:25,679
작아서 s가 여기에 있고

940
00:32:25,679 --> 00:32:26,640


941
00:32:26,640 --> 00:32:29,600
표면이 얼어붙어 f이므로 다시는 생각하지 않습니다.

942
00:32:29,600 --> 00:32:31,120
나는 단지 입을 움직이고 있기 때문에 구별할 수 있습니다.

943
00:32:31,120 --> 00:32:32,399


944
00:32:32,399 --> 00:32:36,080
음 확대하고 있습니다. 그들은 그것을 완벽하게 볼 수 있습니다.

945
00:32:36,080 --> 00:32:38,080
그래서 당신은 얼어붙은 f를 가지고 있고,

946
00:32:38,080 --> 00:32:39,760
그런 다음 당신은 전체

947
00:32:39,760 --> 00:32:42,240
를 가지고 있고, 마지막으로 당신은 목표를 가지고 있습니다. 그래서 g

948
00:32:42,240 --> 00:32:43,360
여기

949
00:32:43,360 --> 00:32:45,760
어디에  첫 번째 b가 있고

950
00:32:45,760 --> 00:32:48,000
이 특정 설정의 모든 패치

951
00:32:48,000 --> 00:32:50,320
는 에이전트가 h로 이동하면 부정적인 보상을 받는 홀을 제외하고 안전합니다.

952
00:32:50,320 --> 00:32:51,279
에이전트는

953
00:32:51,279 --> 00:32:54,640


954
00:32:54,640 --> 00:32:57,039
시작 위치인 첫 번째 um 위치에서 각 에피소드를

955
00:32:57,039 --> 00:32:57,679


956
00:32:57,679 --> 00:32:59,519
시작

957
00:32:59,519 --> 00:33:01,519
하고 거기에서 다음을 수행해야 합니다.

958
00:33:01,519 --> 00:33:03,200
FR에 도달  가능한

959
00:33:03,200 --> 00:33:07,279
한 최소한의 단계로 음의 isbe 위치를 지정

960
00:33:07,279 --> 00:33:08,000


961
00:33:08,000 --> 00:33:09,840
하고 이를 수행할 수 있는 방법은

962
00:33:09,840 --> 00:33:11,679
uh 4가지 다른 유형의

963
00:33:11,679 --> 00:33:12,799
작업을 수행하는 것입니다. 따라서

964
00:33:12,799 --> 00:33:15,840
왼쪽에서 오른쪽으로 또는 위로

965
00:33:15,840 --> 00:33:17,840
이동하면 에이전트가 얼어붙은 호수를 통해 계속 이동할 수 있습니다.

966
00:33:17,840 --> 00:33:18,960


967
00:33:18,960 --> 00:33:21,279
여러 번 다시 방문하여 다른 장소와 마찬가지로

968
00:33:21,279 --> 00:33:22,720
시작 위치로 돌아갈 수

969
00:33:22,720 --> 00:33:24,480


970
00:33:24,480 --> 00:33:26,960
있지만 각 에피소드는

971
00:33:26,960 --> 00:33:27,919


972
00:33:27,919 --> 00:33:31,600
홀이나 목표 위치에 도달하면 끝납니다.

973
00:33:31,600 --> 00:33:34,000
이러한 위치는 시뮬레이션에서 설정할 설정에 따라 다릅니다.

974
00:33:34,000 --> 00:33:35,120


975
00:33:35,120 --> 00:33:38,320


976
00:33:38,320 --> 00:33:40,720
하나는 음 전체의 위치가

977
00:33:40,720 --> 00:33:41,440


978
00:33:41,440 --> 00:33:43,840
8이고 목표가 6이고 다른 하나

979
00:33:43,840 --> 00:33:45,679
는 전체의 위치

980
00:33:45,679 --> 00:33:49,279
가 6이고

981
00:33:49,279 --> 00:33:51,919
음 목표가 8이고 목표

982
00:33:51,919 --> 00:33:53,679
는 내가 말한

983
00:33:53,679 --> 00:33:56,000
대로 몇 단계로 이상적으로 목표에 도달하는 것입니다.

984
00:33:56,000 --> 00:33:57,440
전체를 피하는 동안 가능합니다. 왜냐하면

985
00:33:57,440 --> 00:33:59,120


986
00:33:59,120 --> 00:34:00,880
그것이 목표에 도달하면 에피소드가 끝날 것이기 때문입니다. 어 목표에 도달하면

987
00:34:00,880 --> 00:34:02,559
100의 긍정적인 보상을

988
00:34:02,559 --> 00:34:05,600
받고 그렇지 않으면 부정적인 um을 얻습니다.

989
00:34:05,600 --> 00:34:07,840
여기서 주목해야 할 핵심은 이

990
00:34:07,840 --> 00:34:09,760
쿼리 메트릭이 실제로 우리에게 WA를 허용한다는 것입니다.  y

991
00:34:09,760 --> 00:34:11,280
능동 추론

992
00:34:11,280 --> 00:34:12,960
알고리즘을 강화 학습

993
00:34:12,960 --> 00:34:14,879
알고리즘과 비교하지만

994
00:34:14,879 --> 00:34:16,639
능동 추론

995
00:34:16,639 --> 00:34:18,839
알고리즘이

996
00:34:18,839 --> 00:34:22,000


997
00:34:22,000 --> 00:34:24,000
여전히 이동할 수

998
00:34:24,000 --> 00:34:26,639
있고 정보 게임 탭만 사용

999
00:34:26,639 --> 00:34:28,879
하여 외적 요소가 없기 때문에 보상 기능을 시작으로 갖는 것은 그다지 중요하지 않습니다.  가치

1000
00:34:28,879 --> 00:34:30,239
구성 요소

1001
00:34:30,239 --> 00:34:33,199
음 그리고 그것은 우리가 동화에서 그 결과를 볼 것이기 때문에 매우 흥미롭습니다.

1002
00:34:33,199 --> 00:34:35,040


1003
00:34:35,040 --> 00:34:36,960


1004
00:34:36,960 --> 00:34:39,599
이 특정 설정에 대해 우리

1005
00:34:39,599 --> 00:34:41,040
는 각 에피소드의 최대 시간 단계 수

1006
00:34:41,040 --> 00:34:42,320


1007
00:34:42,320 --> 00:34:45,679
를 15로 제한했습니다. 좋아,

1008
00:34:45,679 --> 00:34:47,918
그래서 내가 할 일은 먼저  활성 추론 공식

1009
00:34:47,918 --> 00:34:49,199
에 사용하는 생식기 모델을 통해 이야기합니다.

1010
00:34:49,199 --> 00:34:51,359


1011
00:34:51,359 --> 00:34:53,440
음, 여기

1012
00:34:53,440 --> 00:34:55,359
슬라이드에서 보고 있는

1013
00:34:55,359 --> 00:34:57,520
것은 활성 및 예를 들어 모델의 그래픽 표현

1014
00:34:57,520 --> 00:34:59,280
이므로 이 모델에는 4가지 동작 상태가 포함

1015
00:34:59,280 --> 00:35:00,800


1016
00:35:00,800 --> 00:35:03,920
됩니다.

1017
00:35:03,920 --> 00:35:06,400


1018
00:35:06,400 --> 00:35:08,240
숨겨진 상태 간 전환 기능을 제어합니다.

1019
00:35:08,240 --> 00:35:11,359
어 위치 사실. 예를

1020
00:35:11,359 --> 00:35:12,240
들어 위치

1021
00:35:12,240 --> 00:35:14,960
1에 있고 올바른 조치를 취하면

1022
00:35:14,960 --> 00:35:15,760
내가

1023
00:35:15,760 --> 00:35:20,000
2번 위치에 있거나

1024
00:35:20,000 --> 00:35:22,480
5번 위치에 있고 위로 동작을 취

1025
00:35:22,480 --> 00:35:24,240
하면 2번 위치에 있게 됩니다.

1026
00:35:24,240 --> 00:35:27,920


1027
00:35:27,920 --> 00:35:30,560
음 이 특정 설정에서

1028
00:35:30,560 --> 00:35:31,200


1029
00:35:31,200 --> 00:35:33,040
6번과 8번 위치는 모두 흡수 상태입니다.

1030
00:35:33,040 --> 00:35:34,320


1031
00:35:34,320 --> 00:35:36,480
에이전트가 해당 위치

1032
00:35:36,480 --> 00:35:37,680
로 이동

1033
00:35:37,680 --> 00:35:40,640
하면 밖으로 나갈 수 없으므로 에피소드가 종료

1034
00:35:40,640 --> 00:35:42,720
되고 에이전트가

1035
00:35:42,720 --> 00:35:44,480
이 특정 미로에서 예를 들어

1036
00:35:44,480 --> 00:35:45,040


1037
00:35:45,040 --> 00:35:47,200
위치 1에서 왼쪽으로 이동하려고 하면 불가능

1038
00:35:47,200 --> 00:35:50,000
하게 움직이면 그대로 유지됩니다.  그 위치

1039
00:35:50,000 --> 00:35:52,320
에서는 이 특정 음 성별 모델에서 움직이지 않을

1040
00:35:52,320 --> 00:35:53,920
것이므로 숨겨진 상태를 보고 있는 중입니다.

1041
00:35:53,920 --> 00:35:54,640


1042
00:35:54,640 --> 00:35:56,960
이제 두 요소 사이에 만성 음 전달 곱이

1043
00:35:56,960 --> 00:35:58,640
있으므로

1044
00:35:58,640 --> 00:36:00,720
여기에 위치와 컨텍스트가 있으므로

1045
00:36:00,720 --> 00:36:03,359
컨텍스트를 변경할 수 없습니다.  에이전트

1046
00:36:03,359 --> 00:36:04,000


1047
00:36:04,000 --> 00:36:05,680
가 있는 이유는 환경

1048
00:36:05,680 --> 00:36:07,040
에 의해 결정되고

1049
00:36:07,040 --> 00:36:08,160


1050
00:36:08,160 --> 00:36:10,079


1051
00:36:10,079 --> 00:36:12,800
전체 위치의 목표가 있는 위치를 결정하는 반면 위치

1052
00:36:12,800 --> 00:36:14,480
는 에이전트가 제어

1053
00:36:14,480 --> 00:36:16,160
할 수 있고 거기에 작업이 있기 때문입니다.

1054
00:36:16,160 --> 00:36:16,800


1055
00:36:16,800 --> 00:36:20,720
이 음에 대해 진술하므로 컨텍스트와 함께

1056
00:36:20,720 --> 00:36:21,839
두 가지 컨텍스트가 있습니다

1057
00:36:21,839 --> 00:36:25,599
. 첫 번째 컨텍스트는 목표가

1058
00:36:25,599 --> 00:36:28,560
8번 위치에 있고 복도가

1059
00:36:28,560 --> 00:36:29,839
6번 위치에

1060
00:36:29,839 --> 00:36:32,079
있고 두 번째 컨텍스트는 목표가

1061
00:36:32,079 --> 00:36:33,280


1062
00:36:33,280 --> 00:36:37,119
6번 위치에 있고 홀이 8번 위치에 있는 컨텍스트입니다.

1063
00:36:37,119 --> 00:36:41,119
각 시점에서 에이전트는

1064
00:36:41,119 --> 00:36:44,560
두 가지 결과를 관찰합니다. 하나는

1065
00:36:44,560 --> 00:36:46,800
이 특정 미로에서 자신의 위치

1066
00:36:46,800 --> 00:36:48,960
이고 두 번째는 에이전트가 얻을 수 있는 점수입니다

1067
00:36:48,960 --> 00:36:50,400


1068
00:36:50,400 --> 00:36:52,560
. 그리드 위치에 대한 가능성

1069
00:36:52,560 --> 00:36:54,720
은 전적으로 에이전트의 위치에 의해 결정

1070
00:36:54,720 --> 00:36:56,079


1071
00:36:56,079 --> 00:37:01,440
되고  점수 um

1072
00:37:01,599 --> 00:37:03,920
은 위치와 상황에 따라 결정

1073
00:37:03,920 --> 00:37:04,960


1074
00:37:04,960 --> 00:37:08,960
되므로 에이전트가 위치 6에

1075
00:37:08,960 --> 00:37:11,680
있고 컨텍스트 2에

1076
00:37:11,680 --> 00:37:13,119
있으면 긍정적인 보상을 받게 됩니다.

1077
00:37:13,119 --> 00:37:15,119
그렇지 않으면 위치에 따라 부정적인

1078
00:37:15,119 --> 00:37:16,320
또는 상호 보상을 받습니다.

1079
00:37:16,320 --> 00:37:20,320


1080
00:37:20,320 --> 00:37:22,640


1081
00:37:22,640 --> 00:37:24,079
강화 학습과의 비교를 시도하는

1082
00:37:24,079 --> 00:37:25,839
것을 기반으로 여기서 우리가 하고

1083
00:37:25,839 --> 00:37:28,560


1084
00:37:28,560 --> 00:37:29,119
있는

1085
00:37:29,119 --> 00:37:32,640
것은 에이전트가 음에 대해 플러스 4 음을 갖는 주요 선호도를 도입하는 것입니다.

1086
00:37:32,640 --> 00:37:36,320
긍정적인 보상 부정  ative 4 4

1087
00:37:36,320 --> 00:37:38,720
마이너스 4 부정적인 보상에 대해 그  

1088
00:37:38,720 --> 00:37:39,760
고 그렇지 않으면 첫  

1089
00:37:39,760 --> 00:37:42,240
째 단계에서 자신이 첫 번째 위치에 있을 것으로 예상하므

1090
00:37:42,240 --> 00:37:43,839


1091
00:37:43,839 --> 00:37:46,880


1092
00:37:47,440 --> 00:37:50,560
로 이 특정 성  

1093
00:37:50,560 --> 00:37:52,480
모델과 능동 추론 에  

1094
00:37:52,480 --> 00:37:53,760
전트를 두  

1095
00:37:53,760 --> 00:37:55,760
지 강화 학습 알고리즘과 비교하여

1096
00:37:55,760 --> 00:37:58,320
첫 번째 알고리즘은 다음과 같았습니다.  q

1097
00:37:58,320 --> 00:38:00,400
엡실론 탐욕 탐색을 사용한 학습

1098
00:38:00,400 --> 00:38:02,079
과 두 번째는

1099
00:38:02,079 --> 00:38:03,839


1100
00:38:03,839 --> 00:38:05,599
표준 톰슨

1101
00:38:05,599 --> 00:38:06,720
샘플링

1102
00:38:06,720 --> 00:38:08,560
과 톰슨 샘플링을 사용하는 베이지안 모델 기반 강화 학습 알고리즘이

1103
00:38:08,560 --> 00:38:10,320
여기에 적합한 절차

1104
00:38:10,320 --> 00:38:12,560
입니다. 이중 목표

1105
00:38:12,560 --> 00:38:15,920
보상 극대화 및 정보 획득의 최적화를 수반

1106
00:38:15,920 --> 00:38:17,440
하고 이 분포를 가짐으로써 달성되기 때문입니다.

1107
00:38:17,440 --> 00:38:19,440
특정 함수

1108
00:38:19,440 --> 00:38:20,960
에 대해 사전 분포를 가짐으로써 우선 순위를 매기는

1109
00:38:20,960 --> 00:38:22,720
것은

1110
00:38:22,720 --> 00:38:26,879


1111
00:38:27,119 --> 00:38:32,320
괜찮습니다.

1112
00:38:32,320 --> 00:38:35,760
그래서 두 개의 q 라이닝 알고리즘에 대해 우리

1113
00:38:35,760 --> 00:38:38,960
는 두 개의 엡실론 탐욕적인 uh 매개변수를 갖습니다.

1114
00:38:38,960 --> 00:38:41,680
하나는 고정 탐색

1115
00:38:41,680 --> 00:38:42,880
이 0.1

1116
00:38:42,880 --> 00:38:44,240
로 설정된 다음  우리가 하나

1117
00:38:44,240 --> 00:38:46,400
에서 시작하는 썩어가는 탐사가 있는 또 다른

1118
00:38:46,400 --> 00:38:49,920
하나  0으로 감소

1119
00:38:50,880 --> 00:38:54,000
하므로 먼저 보상이 변경되지

1120
00:38:54,000 --> 00:38:55,440
않는 고정된 환경에서 에이전트가

1121
00:38:55,440 --> 00:38:56,320


1122
00:38:56,320 --> 00:38:58,960
상호 작용하는 방식을 평가했습니다.

1123
00:38:58,960 --> 00:39:00,800
목표 위치는 항상 6이고

1124
00:39:00,800 --> 00:39:01,760
전체 위치는

1125
00:39:01,760 --> 00:39:04,240
항상 해당 연령이 되도록 한 다음 평가합니다.

1126
00:39:04,240 --> 00:39:06,000
에이전트의 성능 음 여기서 빼야 할 핵심

1127
00:39:06,000 --> 00:39:07,599


1128
00:39:07,599 --> 00:39:08,240
은

1129
00:39:08,240 --> 00:39:09,920
베이지안 RL과 능동 추론

1130
00:39:09,920 --> 00:39:11,680
에이전트가 모두

1131
00:39:11,680 --> 00:39:14,400
보상 위치가 어디인지 빠르게 학습

1132
00:39:14,400 --> 00:39:16,720
하고 최대화할 수 있다는 것

1133
00:39:16,720 --> 00:39:19,119
입니다. 이것이 바로 성능이

1134
00:39:19,119 --> 00:39:21,119
일관되게 표시된다는 것입니다.  비교에서 볼 수 있는 매우 엄격한

1135
00:39:21,119 --> 00:39:23,440
신뢰 범위에

1136
00:39:23,440 --> 00:39:26,960
의해 q 학습 에이전트는

1137
00:39:26,960 --> 00:39:30,480
음이므로 고정

1138
00:39:30,480 --> 00:39:31,680
탐색이 있는

1139
00:39:31,680 --> 00:39:34,640
경우 상당히 음 상당히 좋고

1140
00:39:34,640 --> 00:39:36,240
보상

1141
00:39:36,240 --> 00:39:38,480
이 있는 위치에 착륙할 수 있지만 음으로

1142
00:39:38,480 --> 00:39:40,320
표시되는 약간의 편차가 있습니다.

1143
00:39:40,320 --> 00:39:43,359
무작위 행동 um을 선택하는 10%인

1144
00:39:43,359 --> 00:39:46,320
반면 우리가 엡실론을 가지고 있는 q 학습

1145
00:39:46,320 --> 00:39:48,640
은 1과 같으며 0 um으로 성능을 얻는 것과 같

1146
00:39:48,640 --> 00:39:51,440
으며 성능은 가장 크지

1147
00:39:51,440 --> 00:39:53,119
않으며 null 모델의 경우

1148
00:39:53,119 --> 00:39:55,520
여기에서 보상이 없는 능동추론

1149
00:39:55,520 --> 00:39:57,680
에이전트는 무작위로 홀에

1150
00:39:57,680 --> 00:39:59,040
가고 무작위로 시간의 목표

1151
00:39:59,040 --> 00:40:02,560
50으로 이동하지만 주목해야 할 핵심

1152
00:40:02,560 --> 00:40:04,160
은 비모델을

1153
00:40:04,160 --> 00:40:07,040
제외하고 모든 모델이 꽤 잘하고 있고

1154
00:40:07,040 --> 00:40:07,760


1155
00:40:07,760 --> 00:40:09,760
고정된 설정 내에서

1156
00:40:09,760 --> 00:40:10,960


1157
00:40:10,960 --> 00:40:12,720
제대로 수행되므로 다음 일은 아니요.

1158
00:40:12,720 --> 00:40:14,319
이러한 실험에 대해서도 지적할 수

1159
00:40:14,319 --> 00:40:14,960
있습니다. 왜냐하면

1160
00:40:14,960 --> 00:40:16,640
그들은 또한

1161
00:40:16,640 --> 00:40:19,280
전통적인

1162
00:40:19,280 --> 00:40:22,480
RL에서 약간 벗어나기 때문에 그렇습니다.

1163
00:40:22,480 --> 00:40:24,000


1164
00:40:24,000 --> 00:40:25,760


1165
00:40:25,760 --> 00:40:27,040
훈련 시간과 테스트 시간

1166
00:40:27,040 --> 00:40:28,400
성능 사이에 모호함이 있고 일반적으로

1167
00:40:28,400 --> 00:40:29,440
q 학습

1168
00:40:29,440 --> 00:40:31,280
과 같은 것에서 q 함수에 대해 최대값을 달성하거나 q

1169
00:40:31,280 --> 00:40:32,640
함수

1170
00:40:32,640 --> 00:40:34,800
에 대한 검색과 같은 작업을 시도하는 정책이 있습니다.

1171
00:40:34,800 --> 00:40:35,680


1172
00:40:35,680 --> 00:40:39,440
주어진 상태처럼 최대값을 취하지만

1173
00:40:39,440 --> 00:40:40,720


1174
00:40:40,720 --> 00:40:42,480


1175
00:40:42,480 --> 00:40:44,960
데이터

1176
00:40:44,960 --> 00:40:45,920
를 수집할 때 환경에서 실수를

1177
00:40:45,920 --> 00:40:46,960
저지르는 것과 같은 일종의 인위적인 구분이 있습니다.  훈련 시간과 테스트 시간과 같은 차이가 실제로 없는 경우

1178
00:40:46,960 --> 00:40:48,640
실제 환경

1179
00:40:48,640 --> 00:40:49,280


1180
00:40:49,280 --> 00:40:51,280
과 공정한 비교를 하기

1181
00:40:51,280 --> 00:40:52,960


1182
00:40:52,960 --> 00:40:54,319


1183
00:40:54,319 --> 00:40:55,760


1184
00:40:55,760 --> 00:40:58,240


1185
00:40:58,240 --> 00:40:59,599
위해 q 학습 에이전트가 특히 q 학습 에이전트를 사용하는 이유는 바로 상호 작용입니다.

1186
00:40:59,599 --> 00:41:01,520
엡실론이

1187
00:41:01,520 --> 00:41:03,760
0.1이 절대 최적의 정책을 달성하지 못한다고 말하도록 고정되면

1188
00:41:03,760 --> 00:41:04,720


1189
00:41:04,720 --> 00:41:07,040
0.1 확률로

1190
00:41:07,040 --> 00:41:08,000
임의의 작업을 수행

1191
00:41:08,000 --> 00:41:09,280
하므로 기차와 테스트 시간 사이

1192
00:41:09,280 --> 00:41:11,359
에 일반적인 rl을 사용하는 것처럼 때때로 이러한 구분을 하지 않습니다.

1193
00:41:11,359 --> 00:41:11,839


1194
00:41:11,839 --> 00:41:13,520


1195
00:41:13,520 --> 00:41:14,960
훈련하고 테스트하는 것은 기본적으로

1196
00:41:14,960 --> 00:41:15,520
동일

1197
00:41:15,520 --> 00:41:17,520
하므로

1198
00:41:17,520 --> 00:41:19,280
세계와 상호 작용하기로 선택하는 것은 평가 방법

1199
00:41:19,280 --> 00:41:20,000


1200
00:41:20,000 --> 00:41:22,319
입니다. 그래서 처음

1201
00:41:22,319 --> 00:41:23,359
에는 이 소녀들을 보고 있을 수 있습니다.

1202
00:41:23,359 --> 00:41:24,880


1203
00:41:24,880 --> 00:41:25,359
하지만 음

1204
00:41:25,359 --> 00:41:27,599
네 그건

1205
00:41:27,599 --> 00:41:28,800
그냥 좀 더 친숙한 분들이 dprl

1206
00:41:28,800 --> 00:41:30,400


1207
00:41:30,400 --> 00:41:34,640
uh 실험 절차를

1208
00:41:34,640 --> 00:41:38,640
완벽하게 해주셔서 감사합니다.

1209
00:41:38,640 --> 00:41:41,200


1210
00:41:41,200 --> 00:41:41,920
그

1211
00:41:41,920 --> 00:41:43,520
이후로 환경을 약간 변경하여 몇 에피소드마다 재배치 변경을 시작할

1212
00:41:43,520 --> 00:41:45,200


1213
00:41:45,200 --> 00:41:46,480


1214
00:41:46,480 --> 00:41:48,480
때 베이지안 및 활성 추론

1215
00:41:48,480 --> 00:41:49,839
에이전트가 어려움을 겪을 수 있는지 여부를 확인하기가 조금 더 어렵습니다.

1216
00:41:49,839 --> 00:41:52,240


1217
00:41:52,240 --> 00:41:53,680


1218
00:41:53,680 --> 00:41:56,400
그래서 구체적으로

1219
00:41:56,400 --> 00:41:58,079
목표를 바꿨습니다.  그리고

1220
00:41:58,079 --> 00:42:01,119


1221
00:42:01,119 --> 00:42:04,319
시간 121 141

1222
00:42:04,319 --> 00:42:08,319
251 및 451에서 um의 전체 위치를 볼 수 있습니다. 따라서

1223
00:42:08,319 --> 00:42:10,319
이 그림에서 회색

1224
00:42:10,319 --> 00:42:12,000
선이 표시된 선을 볼 수 있습니다. 따라서 이 점

1225
00:42:12,000 --> 00:42:15,200
들은 첫 번째 고정 설정처럼 모든 위치가 뒤집힌 것입니다.

1226
00:42:15,200 --> 00:42:16,720


1227
00:42:16,720 --> 00:42:19,440
20번의 시도 모든 아시아인

1228
00:42:19,440 --> 00:42:20,000


1229
00:42:20,000 --> 00:42:22,480
은 예상대로 하고 있는 것 같으므로 베이지안

1230
00:42:22,480 --> 00:42:24,240
RL과 활성 추론 에이전트 모두

1231
00:42:24,240 --> 00:42:24,640


1232
00:42:24,640 --> 00:42:27,760
상당히 잘하고 있습니다. 음 고정 탐사 섹터 0.1과 함께 q 착륙

1233
00:42:27,760 --> 00:42:30,800


1234
00:42:30,800 --> 00:42:32,000


1235
00:42:32,000 --> 00:42:34,960
은 이전에 보았듯이 상당히 괜찮고 급성 학습

1236
00:42:34,960 --> 00:42:35,680


1237
00:42:35,680 --> 00:42:38,400
썩어가는 탐색은 이전과 같이 수행

1238
00:42:38,400 --> 00:42:39,520


1239
00:42:39,520 --> 00:42:42,640
되지만

1240
00:42:42,640 --> 00:42:44,240
목표 위치가

1241
00:42:44,240 --> 00:42:47,520
변경되도록 um 주위를 뒤집을 때 um을 알 수 있는

1242
00:42:47,520 --> 00:42:48,640
것은

1243
00:42:48,640 --> 00:42:52,079
베이지안 rl을 사용하는 것입니다.  gent 보상의 양

1244
00:42:52,079 --> 00:42:53,760
이나 그것이 얻는 점수

1245
00:42:53,760 --> 00:42:56,800
가 상당히 낮고 우리는

1246
00:42:56,800 --> 00:42:57,119


1247
00:42:57,119 --> 00:43:00,000


1248
00:43:00,000 --> 00:43:02,160


1249
00:43:02,160 --> 00:43:04,560


1250
00:43:04,560 --> 00:43:05,599


1251
00:43:05,599 --> 00:43:08,720
그것이 수행의 첫 번째 시도 직후에 즉시 전환되는 활성 추론 에이전트와 비교하여 최적의 정책으로 다시 전환되는 단계를 봅니다

1252
00:43:08,720 --> 00:43:10,560
.  잘못된 것은 활성으로 전환

1253
00:43:10,560 --> 00:43:12,960
할 수 있고 적절한 정책을 죄송합니다.

1254
00:43:12,960 --> 00:43:14,640


1255
00:43:14,640 --> 00:43:17,680
그 이유는

1256
00:43:17,680 --> 00:43:19,440
우리가 이를 학습 문제로 간주하는 이러한 url 설정에 대한 것

1257
00:43:19,440 --> 00:43:20,880


1258
00:43:20,880 --> 00:43:22,480


1259
00:43:22,480 --> 00:43:24,480
입니다. 여기서 먼저 보상 위치가 어디에 있는지 역으로 학습

1260
00:43:24,480 --> 00:43:26,720
하고 학습해야 합니다.  그런 다음 우리는 새로운 보상

1261
00:43:26,720 --> 00:43:28,720
위치를 배우

1262
00:43:28,720 --> 00:43:31,280
므로 다른

1263
00:43:31,280 --> 00:43:33,200
엡실론 탐욕 매개변수화

1264
00:43:33,200 --> 00:43:34,720
와 베이지안 rl 모두에 대해 q 학습에 대해

1265
00:43:34,720 --> 00:43:36,160
볼 수 있습니다

1266
00:43:36,160 --> 00:43:38,160
. 활성 추론 에이전트에

1267
00:43:38,160 --> 00:43:39,599
대해서는 다음과 같이 취급하기 때문에 일관되게 볼 수 있습니다.

1268
00:43:39,599 --> 00:43:41,599


1269
00:43:41,599 --> 00:43:42,960
이전 상태의 사후

1270
00:43:42,960 --> 00:43:45,359
가 상으로 이동

1271
00:43:45,359 --> 00:43:46,160
되고 사전으로 이동

1272
00:43:46,160 --> 00:43:49,200
되고 에이전트가 즉시

1273
00:43:49,200 --> 00:43:52,160
움을 깨달을 수 있는 추론 문제로서의 계획

1274
00:43:52,160 --> 00:43:52,960


1275
00:43:52,960 --> 00:43:55,200
이 시간 단계를 따르고 있던 현재 정책은 적합성

1276
00:43:55,200 --> 00:43:57,040
입니다. 다음 um에 대한 정책입니다.

1277
00:43:57,040 --> 00:44:00,480
다시

1278
00:44:00,480 --> 00:44:02,480
um null 모델은 예상대로

1279
00:44:02,480 --> 00:44:04,000
많은 작업을 수행

1280
00:44:04,000 --> 00:44:05,599
하지 않습니다.

1281
00:44:05,599 --> 00:44:08,160
또는 전체 위치

1282
00:44:08,160 --> 00:44:09,839
가

1283
00:44:09,839 --> 00:44:11,839
괜찮습니다 음 필 이것에 뭔가를 추가하시겠습니까

1284
00:44:11,839 --> 00:44:14,799
아니면

1285
00:44:15,440 --> 00:44:17,440
아니요 같은 점이 여기에 적용된다고 생각합니다

1286
00:44:17,440 --> 00:44:18,480


1287
00:44:18,480 --> 00:44:22,160
네 확실히 알겠습니다 음

1288
00:44:22,160 --> 00:44:23,760
그래서 이 두 가지

1289
00:44:23,760 --> 00:44:25,760
비교

1290
00:44:25,760 --> 00:44:29,440
를 끝내고 비 용접기 고정 설정

1291
00:44:29,440 --> 00:44:32,319
음 모두

1292
00:44:32,319 --> 00:44:34,160
베이지안 rl과 q-learning을 포함한 에이전트 유형은

1293
00:44:34,160 --> 00:44:36,400
사용하기에 합리적인 프레임워크가 될 수

1294
00:44:36,400 --> 00:44:39,280
있지만, 비 고정

1295
00:44:39,280 --> 00:44:40,480
확률적 설정

1296
00:44:40,480 --> 00:44:42,240
에서는 활성 추론 에이전트를 갖는 것이

1297
00:44:42,240 --> 00:44:44,079
변화하는 역학을 처리하는 적절한 방법일 수

1298
00:44:44,079 --> 00:44:45,200


1299
00:44:45,200 --> 00:44:47,359
있지만 이에 대한 주요 경고  불확실성을 처리하는 방법에 대해

1300
00:44:47,359 --> 00:44:48,480


1301
00:44:48,480 --> 00:44:50,480


1302
00:44:50,480 --> 00:44:53,119


1303
00:44:53,119 --> 00:44:55,599
일반적으로 허용하기 위해 베이지안 rl 또는 q 학습 또는 rl 프레임워크에 훨씬 더 많은 복잡성을 추가

1304
00:44:55,599 --> 00:44:56,560
할 수

1305
00:44:56,560 --> 00:44:58,800


1306
00:44:58,800 --> 00:44:59,760
있지만 wo

1307
00:44:59,760 --> 00:45:02,240
그것을 추가하는 것은 자연스러운 방법이 아닙니다

1308
00:45:02,240 --> 00:45:04,960


1309
00:45:04,960 --> 00:45:06,880
. 특정 방법으로 함수나 알고리즘을 보강

1310
00:45:06,880 --> 00:45:09,359
하여 정당화해야 할 것입니다.

1311
00:45:09,359 --> 00:45:12,319
음 좋습니다. 그래서 일단 이

1312
00:45:12,319 --> 00:45:15,040
비교를 수행한 후에 우리가 관심을 두었던 것은 음

1313
00:45:15,040 --> 00:45:16,960
입니다.  능동 추론을 사용하려면

1314
00:45:16,960 --> 00:45:19,200


1315
00:45:19,200 --> 00:45:22,079
음 때 세상에 대한 이해가 없거나 수행

1316
00:45:22,079 --> 00:45:22,880


1317
00:45:22,880 --> 00:45:25,440


1318
00:45:25,440 --> 00:45:27,040
할 수 있는 일의 유형에 대한 선호도가 없습니다

1319
00:45:27,040 --> 00:45:28,640
. 활성

1320
00:45:28,640 --> 00:45:30,240
추론 모델을 보았듯이 null 모델은

1321
00:45:30,240 --> 00:45:32,319
탐색 중이기 때문입니다.  그것은 실제로 많은 일을 하지 않고 있습니다.

1322
00:45:32,319 --> 00:45:34,720
그리고 그것은 우리를 프레젠테이션 시작 부분에서 소개한 초기 요점 중 하나로 우리를 인도

1323
00:45:34,720 --> 00:45:36,319
합니다. 즉

1324
00:45:36,319 --> 00:45:38,160


1325
00:45:38,160 --> 00:45:39,599
, 능동적 영향 프레임워크 내에서

1326
00:45:39,599 --> 00:45:41,200
우리는 우리가 배울 수 있는 보상 기능을 갖는 것에 대해 정말로 신경 쓰지 않는다는 것입니다.

1327
00:45:41,200 --> 00:45:42,560


1328
00:45:42,560 --> 00:45:45,920


1329
00:45:45,920 --> 00:45:48,640
환경과의 일부 상호 작용을 기반

1330
00:45:48,640 --> 00:45:52,240
으로 음

1331
00:45:52,240 --> 00:45:54,480
그래서 우리가 한 것은 몇 가지

1332
00:45:54,480 --> 00:45:56,160
다른 시뮬레이션을 수행하여

1333
00:45:56,160 --> 00:45:57,920
활성 추론 에이전트가 사전 p

1334
00:45:57,920 --> 00:45:59,520
가 없을 때 다른 유형의 정책을 선택할 수 있는 방법을 확인하는 것이었습니다.

1335
00:45:59,520 --> 00:46:02,079


1336
00:46:02,079 --> 00:46:04,560
이를 위해 우리는 시간이 지남에

1337
00:46:04,560 --> 00:46:05,280


1338
00:46:05,280 --> 00:46:08,160
따라

1339
00:46:08,160 --> 00:46:09,040
가능성

1340
00:46:09,040 --> 00:46:11,359
과 모든 결과 선호도를

1341
00:46:11,359 --> 00:46:12,240
학습하도록 허용한 세 가지 다른 실험을 수행

1342
00:46:12,240 --> 00:46:15,440


1343
00:46:15,440 --> 00:46:16,560


1344
00:46:16,560 --> 00:46:19,680
했으며 다양한 음 선호도에 대한 학습이

1345
00:46:19,680 --> 00:46:22,640


1346
00:46:22,640 --> 00:46:24,160
발생했을 때 에이전트가 어떻게 상호 작용했는지 확인했습니다.  어 공액 모델을 사용하고 있었나요? 이

1347
00:46:24,160 --> 00:46:26,960
모델

1348
00:46:26,960 --> 00:46:28,800
은 이산 상태 모델이기 때문에

1349
00:46:28,800 --> 00:46:30,800
모델 매개변수에 대한 범주형

1350
00:46:30,800 --> 00:46:31,839


1351
00:46:31,839 --> 00:46:33,760


1352
00:46:33,760 --> 00:46:34,880
분포가 있고 상단에 방향성 분포

1353
00:46:34,880 --> 00:46:36,960
를 하이브리드 가격으로 도입하고 그 하이퍼 가격을 학습

1354
00:46:36,960 --> 00:46:38,319


1355
00:46:38,319 --> 00:46:41,119
하여 세부 정보로 이동할 수 있습니다.

1356
00:46:41,119 --> 00:46:42,800
질문이 있는 사람이

1357
00:46:42,800 --> 00:46:46,400
있지만 간단하게 하기 위해

1358
00:46:46,400 --> 00:46:48,800
음 모든 디리클레 분포가

1359
00:46:48,800 --> 00:46:50,880
완전히 평평하게 설정되어

1360
00:46:50,880 --> 00:46:54,079
있고 에이전트가 서로 다른 상호 작용을 기반으로 착륙할 기회가 모두 주어졌다고 가정

1361
00:46:54,079 --> 00:46:54,800


1362
00:46:54,800 --> 00:46:57,359


1363
00:46:57,359 --> 00:46:58,400


1364
00:46:58,400 --> 00:47:00,160
하면 시뮬레이션과 같은 첫 번째 실험 세트  우리가

1365
00:47:00,160 --> 00:47:02,319
실행한

1366
00:47:02,319 --> 00:47:04,640
것은 에이전트가 현재 환경에 대한 불확실성을 줄이는 방법을 이해

1367
00:47:04,640 --> 00:47:05,520


1368
00:47:05,520 --> 00:47:07,280
하는 것이었습니다.  그래서

1369
00:47:07,280 --> 00:47:09,040
만약 그것이

1370
00:47:09,040 --> 00:47:12,319
얼어붙은 호수를 모른다면

1371
00:47:12,319 --> 00:47:14,720
그것이 어떻게 그 호수와 상호작용하거나 탐험할

1372
00:47:14,720 --> 00:47:15,599


1373
00:47:15,599 --> 00:47:18,880
것인가? 그리고 우리가 보는 것은

1374
00:47:18,880 --> 00:47:21,920
이 특정한 경우에 에이전트 um

1375
00:47:21,920 --> 00:47:23,680
이 탐험에 관심이 있었던 것입니다.

1376
00:47:23,680 --> 00:47:25,920
특별히 신경 쓰지 않았습니다

1377
00:47:25,920 --> 00:47:28,559
목표 또는 전체 위치

1378
00:47:28,559 --> 00:47:29,040
가

1379
00:47:29,040 --> 00:47:32,079
음이었고 이것은 우리가

1380
00:47:32,079 --> 00:47:35,119
보는 일련의 다른 탐색 um

1381
00:47:35,119 --> 00:47:36,800
궤적에서 강조 표시됩니다. 그래서 첫 번째

1382
00:47:36,800 --> 00:47:38,960
것은 에이전트가 홀에 떨어지는 곳

1383
00:47:38,960 --> 00:47:39,359


1384
00:47:39,359 --> 00:47:42,400
이고 다른 하나는 옴이

1385
00:47:42,400 --> 00:47:43,359


1386
00:47:43,359 --> 00:47:46,079
돌아서 끝나는 곳입니다.  두 번째 에피소드의 두 번째

1387
00:47:46,079 --> 00:47:48,160
에피소드는 목표 위치

1388
00:47:48,160 --> 00:47:50,079
와 어딘가에서 앞뒤로 이동하여

1389
00:47:50,079 --> 00:47:51,200
에피소드를 끝낼

1390
00:47:51,200 --> 00:47:52,960
뿐입니다. 그래서 이것은

1391
00:47:52,960 --> 00:47:54,800
단지 바닥 탐사일 뿐입니다.

1392
00:47:54,800 --> 00:47:58,000
음 더 이상 들을 것이 없습니다

1393
00:47:58,000 --> 00:48:01,440
. 다음

1394
00:48:01,440 --> 00:48:03,520
음 우리가 실행한 분석 또는 시뮬레이션 세트는 무엇을 보기 위한 것이었습니다.

1395
00:48:03,520 --> 00:48:05,440
에이전트가 세계에 대해 알고

1396
00:48:05,440 --> 00:48:07,599
있지만 자신이 기대하는 결과 유형에 대한 선호도가 없는 경우 발생할

1397
00:48:07,599 --> 00:48:08,480


1398
00:48:08,480 --> 00:48:12,160
수 있으며 이 um에

1399
00:48:12,160 --> 00:48:15,920
대해 여러 가지 다른 시뮬레이션

1400
00:48:15,920 --> 00:48:19,200
을 실행한 결과 um이 없는 경우 아무 것도 없음을 확인했습니다.

1401
00:48:19,200 --> 00:48:22,240
어떤 종류의 선호도

1402
00:48:22,240 --> 00:48:24,079
음 전체

1403
00:48:24,079 --> 00:48:25,599


1404
00:48:25,599 --> 00:48:28,480
가 먼저 마주치면 실제로 정말 매력적일 수 있습니다. 그래서

1405
00:48:28,480 --> 00:48:29,440


1406
00:48:29,440 --> 00:48:31,680
첫 번째 그림에서 에이전트가

1407
00:48:31,680 --> 00:48:34,000
복도에 숨어 있는 것을 선호

1408
00:48:34,000 --> 00:48:36,160
하는 것을 배우는 것과 두 번째 유형의 재판

1409
00:48:36,160 --> 00:48:38,000
에서 에이전트가

1410
00:48:38,000 --> 00:48:41,520
전시한 곳이었음을 알 수 있습니다.  실제로

1411
00:48:41,520 --> 00:48:43,359
목표 위치로 이동하는 선호도

1412
00:48:43,359 --> 00:48:45,200
는

1413
00:48:45,200 --> 00:48:47,680
인스턴스화 또는

1414
00:48:47,680 --> 00:48:49,119
에이전트가 처음에 노출되는 자극 유형에 전적으로 의존하며, 이는

1415
00:48:49,119 --> 00:48:51,119


1416
00:48:51,119 --> 00:48:52,319
괜찮게

1417
00:48:52,319 --> 00:48:55,200
학습할 선호도 유형을 결정한

1418
00:48:56,240 --> 00:48:59,520
다음 우리가 실행한 마지막 시뮬레이션 세트를 결정

1419
00:48:59,520 --> 00:49:01,520
합니다.

1420
00:49:01,520 --> 00:49:03,119
우리가 인식 명령과 상호 작용할 때 어떤 일이 일어날지 확인

1421
00:49:03,119 --> 00:49:04,640


1422
00:49:04,640 --> 00:49:06,640
하기 위해

1423
00:49:06,640 --> 00:49:08,000


1424
00:49:08,000 --> 00:49:09,440
에이전트가 실제로 상호

1425
00:49:09,440 --> 00:49:11,200


1426
00:49:11,200 --> 00:49:13,200
작용하는 환경

1427
00:49:13,200 --> 00:49:14,480
에 대한 불확실성을 실제로 해결

1428
00:49:14,480 --> 00:49:16,880


1429
00:49:16,880 --> 00:49:18,559


1430
00:49:18,559 --> 00:49:19,839
했습니다.

1431
00:49:19,839 --> 00:49:22,960
우리가 본 것은 우리가

1432
00:49:22,960 --> 00:49:25,520
충분한 수의 시련

1433
00:49:25,520 --> 00:49:27,040
을 통과하도록 허용한다면  s

1434
00:49:27,040 --> 00:49:28,640
이 특정 설정의 에이전트는 x개의 에피소드 후에

1435
00:49:28,640 --> 00:49:31,119
유감스럽게도 숨은 구멍을 타는 것을 선호

1436
00:49:31,119 --> 00:49:34,800
하지만

1437
00:49:34,800 --> 00:49:36,000


1438
00:49:36,000 --> 00:49:38,960


1439
00:49:38,960 --> 00:49:39,280


1440
00:49:39,280 --> 00:49:41,119


1441
00:49:41,119 --> 00:49:42,480
특정

1442
00:49:42,480 --> 00:49:46,400
uh 죄송합니다 특정 시점에 따라 예상되는 결과 유형에 대해 매우 뚜렷한

1443
00:49:46,400 --> 00:49:50,079
um 선호도를 가졌습니다.  그래서 그것이 저를 마지막

1444
00:49:50,079 --> 00:49:53,839
시뮬레이션으로 데려가서 저는

1445
00:49:53,839 --> 00:49:57,200
활성 추론에서 어떤 것을 마무리할 것입니다.

1446
00:49:57,200 --> 00:49:59,040
저는 프레젠테이션을 시작했습니다. 우리가 베이지안으로 작업

1447
00:49:59,040 --> 00:50:00,640


1448
00:50:00,640 --> 00:50:01,200


1449
00:50:01,200 --> 00:50:03,599
할 때 고려해야 할 아주 좋은 것들을 제공하는 특정 알고리즘이라고 말했습니다.

1450
00:50:03,599 --> 00:50:04,559


1451
00:50:04,559 --> 00:50:07,760
또는 믿음에 기반한

1452
00:50:07,760 --> 00:50:08,960
설정은

1453
00:50:08,960 --> 00:50:11,680
첫째

1454
00:50:11,680 --> 00:50:13,359


1455
00:50:13,359 --> 00:50:15,119
로 우리가 경험한

1456
00:50:15,119 --> 00:50:17,040
특정 예상 자유 에너지

1457
00:50:17,040 --> 00:50:19,440
분해에서 얻는 인식적 탐구와 내재적 동기의 주요 설명입니다.

1458
00:50:19,440 --> 00:50:20,400
두 번째

1459
00:50:20,400 --> 00:50:23,359
로 강조하고 싶은 것은

1460
00:50:23,359 --> 00:50:25,040
음 활성 추론 설정에서 우리

1461
00:50:25,040 --> 00:50:26,000
는 그렇지 않다는 것입니다.  에이전트가 자체 보상을 학습할 수 있는 두 번째 시뮬레이션 세트에서 마지막

1462
00:50:26,000 --> 00:50:28,240
으로 본 보상 기능을 명시적으로 지정해야 합니다

1463
00:50:28,240 --> 00:50:29,119


1464
00:50:29,119 --> 00:50:32,079


1465
00:50:32,079 --> 00:50:34,000


1466
00:50:34,000 --> 00:50:35,680
.  nd

1467
00:50:35,680 --> 00:50:37,359


1468
00:50:37,359 --> 00:50:39,839


1469
00:50:39,839 --> 00:50:41,440
환경의 신호가 무언가

1470
00:50:41,440 --> 00:50:42,319
나쁘다고 말하지만

1471
00:50:42,319 --> 00:50:44,160
에이전트의 내부 선호 동기로 인해 환경이 기대하는 것과 상당히 어긋나는 일

1472
00:50:44,160 --> 00:50:46,240
을 하도록 허용하는

1473
00:50:46,240 --> 00:50:48,559
rl 설정에서 상당히 반직관적인 무언가가 되는 것을 선호합니다.

1474
00:50:48,559 --> 00:50:50,319


1475
00:50:50,319 --> 00:50:51,359


1476
00:50:51,359 --> 00:50:53,599
그리고 마지막으로 이 믿음 때문에

1477
00:50:53,599 --> 00:50:55,280
침입 설정 불확실성

1478
00:50:55,280 --> 00:50:57,119
은 믿음

1479
00:50:57,119 --> 00:51:00,559
업데이트의 자연스러운 부분이므로

1480
00:51:00,559 --> 00:51:02,319
고정 설정 내에서 능동 추론

1481
00:51:02,319 --> 00:51:04,000
에이전트는 강화 학습 에이전트와 마찬가지로 수행

1482
00:51:04,000 --> 00:51:05,200


1483
00:51:05,200 --> 00:51:07,359
하지만 고정되지 않은 설정에서는

1484
00:51:07,359 --> 00:51:08,960


1485
00:51:08,960 --> 00:51:10,480
이 계획을 추론으로 수행하고

1486
00:51:10,480 --> 00:51:13,280


1487
00:51:13,280 --> 00:51:15,280
이것이 결정적인 진술은 아니지만

1488
00:51:15,280 --> 00:51:15,760


1489
00:51:15,760 --> 00:51:18,240


1490
00:51:18,240 --> 00:51:19,040


1491
00:51:19,040 --> 00:51:21,280


1492
00:51:21,280 --> 00:51:23,440


1493
00:51:23,440 --> 00:51:24,160


1494
00:51:24,160 --> 00:51:26,960
강화 학습과 동일한 유형의 환경에서 상호 작용하도록 활성 추론 에이전트를 확장하는 경우에 대해 생각하기 시작하는 좋은 방법이라고 생각합니다.  비정상성이나 이상한 점이

1495
00:51:26,960 --> 00:51:27,760


1496
00:51:27,760 --> 00:51:30,079
있기 때문에 해결하기가 조금 어려울 수 있는 에이전트

1497
00:51:30,079 --> 00:51:30,839


1498
00:51:30,839 --> 00:51:32,640


1499
00:51:32,640 --> 00:51:33,920


1500
00:51:33,920 --> 00:51:34,640
환경에서 발생하는 변동

1501
00:51:34,640 --> 00:51:36,240
과 활성 추론 에이전트는 이 계획

1502
00:51:36,240 --> 00:51:38,240
을 추론으로 설정하면 잠재적으로 꽤 잘 수행할 수 있습니다.

1503
00:51:38,240 --> 00:51:42,000


1504
00:51:42,079 --> 00:51:44,800
음, 그렇게 하면 프레젠테이션을 끝낼 수

1505
00:51:44,800 --> 00:51:46,480


1506
00:51:46,480 --> 00:51:48,240
있습니다. 그래서 톰이라고 하는 이 작업에 관련된 모든 사람에게 감사하고 싶습니다.

1507
00:51:48,240 --> 00:51:48,559


1508
00:51:48,559 --> 00:51:51,520
그리고 phil과

1509
00:51:51,520 --> 00:51:52,640
제가

1510
00:51:52,640 --> 00:51:55,920
제시한 이 흥미로운 아이디어를 생각할 수

1511
00:51:55,920 --> 00:51:58,079
있도록 도와주신 모든 분들, 그리고 들어주신 모든 분들도

1512
00:51:58,079 --> 00:51:59,920


1513
00:51:59,920 --> 00:52:04,400
감사합니다. 멋진 강연에 감사드립니다.

1514
00:52:04,400 --> 00:52:07,119
공유를 취소할 수 있고 몇 가지 질문을 할 수 있습니다.

1515
00:52:07,119 --> 00:52:08,000


1516
00:52:08,000 --> 00:52:09,599
그리고 라이브를 시청하는 사람이 질문을 하고 싶다면

1517
00:52:09,599 --> 00:52:11,359


1518
00:52:11,359 --> 00:52:14,400
그들은 환영합니다. 그래서 아마도 나는

1519
00:52:14,400 --> 00:52:16,160


1520
00:52:16,160 --> 00:52:18,000


1521
00:52:18,000 --> 00:52:20,480


1522
00:52:20,480 --> 00:52:21,280


1523
00:52:21,280 --> 00:52:22,880
강화 학습과

1524
00:52:22,880 --> 00:52:24,640
능동 추론 패러다임

1525
00:52:24,640 --> 00:52:27,040
을 얼마나 명확하게 구별했는지 보는 것이 굉장하다는 일반적인 요점으로 시작할 것

1526
00:52:27,040 --> 00:52:27,760


1527
00:52:27,760 --> 00:52:30,319
입니다.  하나의 시간 단계의 하나의 시간

1528
00:52:30,319 --> 00:52:31,599
지평은

1529
00:52:31,599 --> 00:52:33,359


1530
00:52:33,359 --> 00:52:34,960
강화 학습 접근 방식

1531
00:52:34,960 --> 00:52:36,640
과 능동적인 infe 사이에 동등함과 같았습니다.

1532
00:52:36,640 --> 00:52:38,640
이제 사람들은 불확실성

1533
00:52:38,640 --> 00:52:40,400


1534
00:52:40,400 --> 00:52:42,400
속에서 미래를 계획하기 위해 강화 학습을 사용하고 있습니다.

1535
00:52:42,400 --> 00:52:43,599


1536
00:52:43,599 --> 00:52:46,240
그래서 그들은 그러한

1537
00:52:46,240 --> 00:52:47,839
종류의 계획

1538
00:52:47,839 --> 00:52:50,400
을 어떻게 달성하고 있으며

1539
00:52:50,400 --> 00:52:51,440
능동적 추론

1540
00:52:51,440 --> 00:52:53,920
이 그러한

1541
00:52:53,920 --> 00:52:54,800
설정에 들어가

1542
00:52:54,800 --> 00:52:57,760
잠재적으로 더 잘할

1543
00:52:57,760 --> 00:52:58,480
수 있는 일부 상황은 어디에 있습니까?  질문

1544
00:52:58,480 --> 00:53:00,400
은 좋은 질문이며

1545
00:53:00,400 --> 00:53:02,720
내가 뭔가를 놓치면 자유롭게 뛰어들 수 있지만 음

1546
00:53:02,720 --> 00:53:04,720
그래서 내가 아는 것에서 URL 설정 내에서

1547
00:53:04,720 --> 00:53:07,040
그들이

1548
00:53:07,040 --> 00:53:09,280
1보다 큰 시간적 지평을 고려하고 있다면

1549
00:53:09,280 --> 00:53:10,960
계층적 rl

1550
00:53:10,960 --> 00:53:13,280
이 있거나 옵션이 있는 위치에 있습니다.

1551
00:53:13,280 --> 00:53:14,800


1552
00:53:14,800 --> 00:53:16,240


1553
00:53:16,240 --> 00:53:18,800


1554
00:53:18,800 --> 00:53:20,720


1555
00:53:20,720 --> 00:53:24,319
그들이 좋아하기 전에 전체 플레이 시퀀스를 고려할 수 있도록 하는 궤적을 고려하는

1556
00:53:24,319 --> 00:53:26,000


1557
00:53:26,000 --> 00:53:27,680
것보다

1558
00:53:27,680 --> 00:53:32,800
더 큰 궤적을 고려하면 um 매핑하는

1559
00:53:32,800 --> 00:53:34,880
대신에 특정 정책을 선택하면 롤아웃됩니다.

1560
00:53:34,880 --> 00:53:36,559
옵션으로 작업한 적이 별로 없을 것입니다. 아마도

1561
00:53:36,559 --> 00:53:39,119
phil 아시나요 음, 그래서 옵션은

1562
00:53:39,119 --> 00:53:41,280


1563
00:53:41,280 --> 00:53:45,119
이러한 종류의 다단계를 달성하는 한 가지 방법과 같습니다.

1564
00:53:45,119 --> 00:53:47,680
음의 종류는 거의 이 귀납적 편향과 같이 너무 큰

1565
00:53:47,680 --> 00:53:49,359


1566
00:53:49,359 --> 00:53:52,000
것 같습니다. 여러분의 선택은 하나 이상의 단계

1567
00:53:52,000 --> 00:53:54,079
와 같은 인접 블록이 될 것입니다.

1568
00:53:54,079 --> 00:53:55,520
반면에 일종의

1569
00:53:55,520 --> 00:53:57,280
정책 유형은 제가

1570
00:53:57,280 --> 00:53:58,720
한 단계를 밟고  그런 다음 나는 이런

1571
00:53:58,720 --> 00:53:59,359
종류의

1572
00:53:59,359 --> 00:54:02,720
다음 상태를 가질 것입니다.

1573
00:54:02,720 --> 00:54:04,240
하지만 명확하게 하는 것이 중요한 것은

1574
00:54:04,240 --> 00:54:06,000
실제로 모델 스타일을 계획할 수 있다는 것입니다.

1575
00:54:06,000 --> 00:54:07,440


1576
00:54:07,440 --> 00:54:09,119
능동적 추론을

1577
00:54:09,119 --> 00:54:10,880
일종의 모델 기반

1578
00:54:10,880 --> 00:54:13,680
으로 볼 수 있기 때문입니다.  당신은 rl 패러다임을 알고 있고

1579
00:54:13,680 --> 00:54:15,280
실제로 모델 기반 내

1580
00:54:15,280 --> 00:54:18,400


1581
00:54:18,400 --> 00:54:20,800


1582
00:54:20,800 --> 00:54:21,440


1583
00:54:21,440 --> 00:54:23,040
에서 능동 추론에서 수행되는 것과 유사한 계획 방법을 가질 수 있습니다. 그러나

1584
00:54:23,040 --> 00:54:24,480
여기서 주요 차이점

1585
00:54:24,480 --> 00:54:27,440
은 모델 기반 rl에서 계획을 수행할

1586
00:54:27,440 --> 00:54:27,760


1587
00:54:27,760 --> 00:54:29,920
때 단순히  일반적으로 교차 엔트로피 방법과

1588
00:54:29,920 --> 00:54:30,800


1589
00:54:30,800 --> 00:54:32,880
같은 일종의 미니 진화론적 방법과 같은

1590
00:54:32,880 --> 00:54:34,079


1591
00:54:34,079 --> 00:54:35,920


1592
00:54:35,920 --> 00:54:37,440
일종의 소송을 취하는 경향이 있습니다.

1593
00:54:37,440 --> 00:54:38,640


1594
00:54:38,640 --> 00:54:40,480
n 20단계 음이라는 지평선을 넘어

1595
00:54:40,480 --> 00:54:42,319
여러분의 종류의 보상을 최대화하는 시간

1596
00:54:42,319 --> 00:54:45,200


1597
00:54:45,200 --> 00:54:46,559
과 q 값 함수 음으로 종료할 수 있는 영리한 일을

1598
00:54:46,559 --> 00:54:48,880


1599
00:54:48,880 --> 00:54:51,280
할 수 있지만 근본적

1600
00:54:51,280 --> 00:54:52,799
으로 이러한 종류의

1601
00:54:52,799 --> 00:54:55,359
정의적 차이에서 멀어지지는 않습니다.

1602
00:54:55,359 --> 00:54:57,760
능동 추론에서 당신은 행동에 대한 이런

1603
00:54:57,760 --> 00:54:59,119
종류의 계획을 수행

1604
00:54:59,119 --> 00:55:00,480
하고 있습니다.

1605
00:55:00,480 --> 00:55:02,000


1606
00:55:02,000 --> 00:55:03,680
기본적으로 많은 행동을 그리는 것과 같이 표면적으로 유사해 보일 수 있지만

1607
00:55:03,680 --> 00:55:05,280


1608
00:55:05,280 --> 00:55:06,000


1609
00:55:06,000 --> 00:55:09,119
능동적 추론의 경우 모든

1610
00:55:09,119 --> 00:55:10,880
유용한 종류의 정보가 어떤 종류의 효용을 최대화하는지 보는 것과 같습니다.  그리고 탐색과 같은

1611
00:55:10,880 --> 00:55:12,559
음에 대한 원하는 비율

1612
00:55:12,559 --> 00:55:15,760
과 그것과 음

1613
00:55:15,760 --> 00:55:17,839
착취는 그

1614
00:55:17,839 --> 00:55:20,000
최대화에 싸여 있는 반면, rl

1615
00:55:20,000 --> 00:55:23,440


1616
00:55:23,440 --> 00:55:24,799
에서는 고전적인 의미에서 우리가

1617
00:55:24,799 --> 00:55:26,960
보상을 최대화하려고 노력하는 것처럼 음 이해하기가 조금 더 어렵습니다. 하지만 음

1618
00:55:26,960 --> 00:55:28,720
당신은 가질 수 있습니다  당신은 오라고

1619
00:55:28,720 --> 00:55:30,240
말하지만 아마도

1620
00:55:30,240 --> 00:55:31,200


1621
00:55:31,200 --> 00:55:33,359
모델 불확실성의 개념을 최대화하고

1622
00:55:33,359 --> 00:55:34,640


1623
00:55:34,640 --> 00:55:37,280
싶고 자연스럽게 통합하기가 조금 더 어렵다는 것을 알고 있습니다.

1624
00:55:37,280 --> 00:55:39,680
모든 접근 방식을 같은 것으로 평가

1625
00:55:39,680 --> 00:55:41,680


1626
00:55:41,680 --> 00:55:42,400


1627
00:55:42,400 --> 00:55:43,280


1628
00:55:43,280 --> 00:55:44,720


1629
00:55:44,720 --> 00:55:46,480


1630
00:55:46,480 --> 00:55:47,760


1631
00:55:47,760 --> 00:55:49,920
하십시오  그래서 예, 그런 종류의 차이

1632
00:55:49,920 --> 00:55:50,880
가 있다고 느끼는 부분입니다.

1633
00:55:50,880 --> 00:55:53,920


1634
00:55:54,000 --> 00:55:57,280
그리고 어떤 종류의 설정

1635
00:55:57,280 --> 00:56:00,640
이 있다고 생각하십니까?

1636
00:56:00,640 --> 00:56:03,200
추론과 같은 이러한 유형의 행동과 추론으로서의 계획은

1637
00:56:03,200 --> 00:56:04,240


1638
00:56:04,240 --> 00:56:06,960
어떤 종류의 데이터 세트 또는 질문처럼 활용될 수 있다고 생각하십니까?

1639
00:56:06,960 --> 00:56:08,880
컨텍스트

1640
00:56:08,880 --> 00:56:10,799
는 사람들이 현재 다른 유형

1641
00:56:10,799 --> 00:56:12,720
의 방법을 사용하고 있지만 능동적 추론이 역할을 하는 것을 보고 흥분됩니다. 제

1642
00:56:12,720 --> 00:56:17,839


1643
00:56:18,720 --> 00:56:21,280


1644
00:56:21,280 --> 00:56:23,520
생각에는 보상 기능이 없는 대부분 개방형 문제

1645
00:56:23,520 --> 00:56:26,640
라고 생각합니다.

1646
00:56:26,640 --> 00:56:30,079
왜냐하면 rl 에이전트가 어떻게 학습하는지

1647
00:56:30,079 --> 00:56:31,839
환경과 상호 작용

1648
00:56:31,839 --> 00:56:33,839
하는 것은 보상 기능을 통해서입니다.

1649
00:56:33,839 --> 00:56:36,079
그래서 당신이 정말로

1650
00:56:36,079 --> 00:56:37,280
그것을 가지고 있지 않거나 당신이

1651
00:56:37,280 --> 00:56:40,640
환경을 가지고

1652
00:56:40,640 --> 00:56:43,440
있는 모든 곳에서 음이 변하는 환경이 있다는 것을 알고 있습니다.

1653
00:56:43,440 --> 00:56:44,160


1654
00:56:44,160 --> 00:56:46,720


1655
00:56:46,720 --> 00:56:47,599


1656
00:56:47,599 --> 00:56:50,160
내적 동기나 내적

1657
00:56:50,160 --> 00:56:51,520
동기와 같은 일을 하는 rl 커뮤니티의

1658
00:56:51,520 --> 00:56:54,160
사람들은 그런 것들이

1659
00:56:54,160 --> 00:56:54,559


1660
00:56:54,559 --> 00:56:58,960
능동적인 영향 공식화 음

1661
00:56:58,960 --> 00:57:02,400
, 하지만 특정 패러다임과 겹치는 것 같아요. 제가 생각하기

1662
00:57:02,400 --> 00:57:04,640
에 능동적인 영향력의 더 흥미로운 측면은

1663
00:57:04,640 --> 00:57:06,079


1664
00:57:06,079 --> 00:57:09,440
시작할 때 사실에서 옵니다.  생물학적 작용제에 대해 생각

1665
00:57:09,440 --> 00:57:12,240


1666
00:57:12,240 --> 00:57:13,280


1667
00:57:13,280 --> 00:57:16,240
하고 정신분열증이 있는 환자나 누군가를 모델링하는 경우

1668
00:57:16,240 --> 00:57:18,079
이 베이지안 프레임워크를 사용

1669
00:57:18,079 --> 00:57:21,760
하여 사전을

1670
00:57:21,760 --> 00:57:24,960


1671
00:57:24,960 --> 00:57:27,920
변경할 수 있습니다

1672
00:57:27,920 --> 00:57:28,799


1673
00:57:28,799 --> 00:57:30,079
.  그들이 정책을 평가하는 방식

1674
00:57:30,079 --> 00:57:32,319
이 깨졌거나

1675
00:57:32,319 --> 00:57:35,599
다른 부분일 수

1676
00:57:35,599 --> 00:57:38,720
있지만 마술이나 체육관 환경과 같이 표준 게임 모드에서 벗어나고 시작하는 경우 rl 설정 내에서 생각

1677
00:57:38,720 --> 00:57:43,440


1678
00:57:43,440 --> 00:57:46,480


1679
00:57:46,480 --> 00:57:47,359


1680
00:57:47,359 --> 00:57:49,040


1681
00:57:49,040 --> 00:57:50,799
합니다.  더 개방적이고

1682
00:57:50,799 --> 00:57:52,480
보상이 없다면

1683
00:57:52,480 --> 00:57:54,160
적극적인 영향력이 잠재적으로 유용할 수

1684
00:57:54,160 --> 00:57:56,240
있지만

1685
00:57:56,240 --> 00:57:58,640
저는 약간 주저합니다.

1686
00:57:58,640 --> 00:57:59,599


1687
00:57:59,599 --> 00:58:02,640


1688
00:58:02,640 --> 00:58:05,040
모든 종류의

1689
00:58:05,040 --> 00:58:06,839
흥미로운 구성 요소

1690
00:58:06,839 --> 00:58:10,160
로 베이지안 rl을 보강하기 시작하면 어느 정도

1691
00:58:10,160 --> 00:58:13,680
확장된 um 앞에서 활성화되기 때문에 더 좋을지 여부를 말하십시오.

1692
00:58:13,680 --> 00:58:15,760
이는 잠재적으로 논쟁의 여지가

1693
00:58:15,760 --> 00:58:16,880


1694
00:58:16,880 --> 00:58:20,319
있지만 정확히 무엇에 달려 있다고 생각합니다

1695
00:58:20,319 --> 00:58:22,079
당신은 통합하고 있었고

1696
00:58:22,079 --> 00:58:23,920
이것이 이 특정

1697
00:58:23,920 --> 00:58:26,000
프레젠테이션과 우리 작업에

1698
00:58:26,000 --> 00:58:27,599
대해 강화 학습이 의미하는 바를 정의하는 데 매우 신중한

1699
00:58:27,599 --> 00:58:29,599
이유입니다.

1700
00:58:29,599 --> 00:58:31,760
즉, 이 보상 기능이 작동해야 하고 이 보상

1701
00:58:31,760 --> 00:58:33,280
기능

1702
00:58:33,280 --> 00:58:35,040


1703
00:58:35,040 --> 00:58:37,280
과 RL에 포함하는 모든 것을 최대화하려는 것입니다.

1704
00:58:37,280 --> 00:58:39,040
프레임워크는

1705
00:58:39,040 --> 00:58:42,000
그 목적이 있어야 하는 객체와 같은

1706
00:58:42,000 --> 00:58:44,000
것을 가져야 하지만

1707
00:58:44,000 --> 00:58:45,839
만약 당신이 그것들을 우회한다면 괜찮다고 말하겠습니다

1708
00:58:45,839 --> 00:58:47,040


1709
00:58:47,040 --> 00:58:48,480


1710
00:58:48,480 --> 00:58:51,200
. 알고리즘이나 에이전트를 만드는 방법을 만들기 위해 모든 종류의 흥미로운 구성 요소를 추가할 것입니다.

1711
00:58:51,200 --> 00:58:52,400


1712
00:58:52,400 --> 00:58:55,599
환경과 상호 작용합니다. 음

1713
00:58:55,599 --> 00:58:57,760
활성

1714
00:58:57,760 --> 00:58:59,119
추론 프레임워크와 비슷

1715
00:58:59,119 --> 00:59:02,000
하거나 훨씬 더 나은 것 같아요.

1716
00:59:02,000 --> 00:59:03,040


1717
00:59:03,040 --> 00:59:06,319
re rl

1718
00:59:06,319 --> 00:59:08,400
이 더 좋거나 적극적인 영향력

1719
00:59:08,400 --> 00:59:10,960
이 더 좋은 곳에서는 그런 것이 나에게 실제로 존재하지 않습니다.

1720
00:59:10,960 --> 00:59:12,559
왜냐하면 내

1721
00:59:12,559 --> 00:59:15,680
관점에서 두 커뮤니티는 순차적 의사 결정

1722
00:59:15,680 --> 00:59:16,079


1723
00:59:16,079 --> 00:59:17,599
과 같은 유사한 것들에서 일하고

1724
00:59:17,599 --> 00:59:19,440


1725
00:59:19,440 --> 00:59:20,400


1726
00:59:20,400 --> 00:59:23,760
있고 우리 작업은

1727
00:59:23,760 --> 00:59:26,000
대부분 uh 순차적 의사 결정과 관련이 있다고 생각하기 때문입니다.

1728
00:59:26,000 --> 00:59:27,520
불확실성의 얼굴

1729
00:59:27,520 --> 00:59:29,920
반면 우리 작업의 일부는

1730
00:59:29,920 --> 00:59:30,720


1731
00:59:30,720 --> 00:59:33,440
그것에 초점을 맞추지 않을 수 있으므로 경계를 그리기 시작할 때

1732
00:59:33,440 --> 00:59:33,920


1733
00:59:33,920 --> 00:59:35,359


1734
00:59:35,359 --> 00:59:37,119


1735
00:59:37,119 --> 00:59:40,079
사물이 분리되어 있는지 여부가 약간 흐릿해지는 것 같아요.

1736
00:59:40,079 --> 00:59:41,920
접선

1737
00:59:41,920 --> 00:59:45,760
음. 하지만

1738
00:59:45,760 --> 00:59:47,119


1739
00:59:47,119 --> 00:59:49,280


1740
00:59:49,280 --> 00:59:49,839


1741
00:59:49,839 --> 00:59:53,520


1742
00:59:53,520 --> 00:59:55,359


1743
00:59:55,359 --> 00:59:57,440


1744
00:59:57,440 --> 00:59:58,640


1745
00:59:58,640 --> 01:00:01,599
필  행동해야 합니다.

1746
01:00:01,599 --> 01:00:03,359


1747
01:00:03,359 --> 01:00:05,200
일종의 호기심이나 인식적

1748
01:00:05,200 --> 01:00:08,720
불확실성 감소 메커니즘

1749
01:00:08,720 --> 01:00:10,559
을 사용하는 rl 에이전트를 배치할 수 있다고 주장할 수 있습니다.

1750
01:00:10,559 --> 01:00:12,319


1751
01:00:12,319 --> 01:00:14,160
보상 기능보다 우선순위를 배우고 그것들을 배우는 것에 대해 일

1752
01:00:14,160 --> 01:00:14,640
하지만

1753
01:00:14,640 --> 01:00:17,920
나는 크게 인식하지 못하지만

1754
01:00:17,920 --> 01:00:19,280
음 이해하는 것이 중요한 것은

1755
01:00:19,280 --> 01:00:21,839


1756
01:00:21,839 --> 01:00:22,880


1757
01:00:22,880 --> 01:00:24,319
당신의 인식적 불확실성이 당신

1758
01:00:24,319 --> 01:00:26,319
처럼 전체 환경을 탐험하는 것과 같은 한계에 있다는

1759
01:00:26,319 --> 01:00:27,760
것입니다.  모든 것을 관찰했을 것이고

1760
01:00:27,760 --> 01:00:29,359
그 시점에서 RL 에이전트가 무엇을 할 것인지 확실하지 않습니다.

1761
01:00:29,359 --> 01:00:30,480
특히

1762
01:00:30,480 --> 01:00:31,280
당신은

1763
01:00:31,280 --> 01:00:33,680


1764
01:00:33,680 --> 01:00:35,839
행동을 취하는 방법을 매개변수화하는 심층 신경망

1765
01:00:35,839 --> 01:00:37,440


1766
01:00:37,440 --> 01:00:39,280
이

1767
01:00:39,280 --> 01:00:41,119
있다고 말합니다.  우리가 이

1768
01:00:41,119 --> 01:00:42,480
실험을

1769
01:00:42,480 --> 01:00:44,319
실행할 때 실제로

1770
01:00:44,319 --> 01:00:46,079
이전 선호도보다 우선 순위를 두었고 결국에는

1771
01:00:46,079 --> 01:00:46,480


1772
01:00:46,480 --> 01:00:48,960
최적이 아닐 수도 있는 행동 모드를 배우게

1773
01:00:48,960 --> 01:00:50,960
되지만 에이전트는 결국

1774
01:00:50,960 --> 01:00:53,040


1775
01:00:53,040 --> 01:00:54,480


1776
01:00:54,480 --> 01:00:56,000
전염병을 감소시키기 때문에 자기 충족적인 행동을 채택하는 법을 배웁니다.  불확실성이

1777
01:00:56,000 --> 01:00:58,400
있고 남은 것은 좋은 말을 하는 것뿐입니다.

1778
01:00:58,400 --> 01:00:59,520
저는 이것이 일종의

1779
01:00:59,520 --> 01:01:00,960
유용한 행동이라고 생각하거나 적어도 이것이

1780
01:01:00,960 --> 01:01:03,200
제가 세상에서 해야 할 행동이라고 생각합니다.  그리고

1781
01:01:03,200 --> 01:01:04,000
결국에는

1782
01:01:04,000 --> 01:01:05,680
상당히 반복적인 행동을 하게 되며

1783
01:01:05,680 --> 01:01:07,119


1784
01:01:07,119 --> 01:01:08,160


1785
01:01:08,160 --> 01:01:10,400


1786
01:01:10,400 --> 01:01:12,079
지능형 무언가가 실제로 세상에서 어떻게 행동할 수 있는지와 같은 정보가 없을

1787
01:01:12,079 --> 01:01:12,559


1788
01:01:12,559 --> 01:01:15,040


1789
01:01:15,040 --> 01:01:16,480
때 더 정확한 시뮬레이션이 될 수 있습니다.

1790
01:01:16,480 --> 01:01:17,599
가치가 어디에 있는지 그리고 확실히

1791
01:01:17,599 --> 01:01:18,480


1792
01:01:18,480 --> 01:01:20,160


1793
01:01:20,160 --> 01:01:22,319
그 시점에서 에이전트가 실제로 무엇을 하고 있는지와 같은 것을 찾지

1794
01:01:22,319 --> 01:01:24,240
못했지만 현재 내 문제

1795
01:01:24,240 --> 01:01:26,079
는 공식화에서처럼 행동하는

1796
01:01:26,079 --> 01:01:28,960
것이 이산 상태 공식화처럼 작동한다는 것입니다.

1797
01:01:28,960 --> 01:01:31,040
우리는

1798
01:01:31,040 --> 01:01:34,640
그 설정에서 정말 좋은 결과를

1799
01:01:34,640 --> 01:01:36,880
보았지만 확장하면 활성

1800
01:01:36,880 --> 01:01:38,240
추론 에이전트가

1801
01:01:38,240 --> 01:01:38,640


1802
01:01:38,640 --> 01:01:40,559
상각 추론이나 실제로 가능성 전환 기능을 근사화하는 것과 같은 것을 사용하는 경우 동일한 문제가

1803
01:01:40,559 --> 01:01:42,640


1804
01:01:42,640 --> 01:01:44,640


1805
01:01:44,640 --> 01:01:47,359


1806
01:01:47,359 --> 01:01:49,280
발생할 것이라고 생각합니다.  우리가 이 작은 규모에서 보고 있는 이 멋진 속성을 얻으십시오.

1807
01:01:49,280 --> 01:01:51,119


1808
01:01:51,119 --> 01:01:53,920
그래서 규모를 늘리는

1809
01:01:53,920 --> 01:01:55,200


1810
01:01:55,200 --> 01:01:57,119
것은 마치 흥미롭고 끝이 없는

1811
01:01:57,119 --> 01:01:58,720
문제인 것 같습니다.  e 순간

1812
01:01:58,720 --> 01:01:59,760


1813
01:01:59,760 --> 01:02:01,440


1814
01:02:01,440 --> 01:02:02,880
은 우리

1815
01:02:02,880 --> 01:02:05,280
가 이산 상태 공식화를

1816
01:02:05,280 --> 01:02:06,000
가지고 있는 이러한 공액 모델과 같이 포함할 수 있는 올바른 방식으로 확장되며 이것이 우리가

1817
01:02:06,000 --> 01:02:08,240


1818
01:02:08,240 --> 01:02:10,079


1819
01:02:10,079 --> 01:02:10,880


1820
01:02:10,880 --> 01:02:13,839
학습을 수행하기 전에 공액 사전을 도입하는 시뮬레이션의 마지막 세트를 수행하는 방식입니다.  이전 선호도

1821
01:02:13,839 --> 01:02:15,440
뿐 아니라 가능성도

1822
01:02:15,440 --> 01:02:17,839
음, 그래서 어떻게

1823
01:02:17,839 --> 01:02:18,720


1824
01:02:18,720 --> 01:02:21,680
하면 전체 신경망에 대해 하이퍼 사전이 있는 것처럼 학습

1825
01:02:21,680 --> 01:02:23,280


1826
01:02:23,280 --> 01:02:24,400
하는 방법이

1827
01:02:24,400 --> 01:02:27,760
약간 흐릿

1828
01:02:27,760 --> 01:02:29,039
해집니다.  그

1829
01:02:29,039 --> 01:02:31,520
영역에서 실제로

1830
01:02:31,520 --> 01:02:32,960


1831
01:02:32,960 --> 01:02:35,680
이러한 흥미로운

1832
01:02:35,680 --> 01:02:37,520
구성 요소를 가질 수 있다는 것이 적절하다는 것을 보여주기 위해서는 이러한 하이퍼 사전을 포함

1833
01:02:37,520 --> 01:02:40,079
하는 방법에 대해 생각하기 시작해야 합니다.

1834
01:02:40,079 --> 01:02:42,319


1835
01:02:42,319 --> 01:02:44,240
어, 하이브리드 사전을 가질 것이라고 말하는 것이 합리적이지 않기 때문입니다.

1836
01:02:44,240 --> 01:02:45,920


1837
01:02:45,920 --> 01:02:49,119
베타 하이퍼와 같은 매개변수 공간에

1838
01:02:49,119 --> 01:02:51,760


1839
01:02:51,760 --> 01:02:53,359


1840
01:02:53,359 --> 01:02:55,359


1841
01:02:55,359 --> 01:02:58,319
대해 에이전트가 자신의 행동을 선택하는 방식에 대해 해당 설정에서 충분할 감마보다 하이퍼 이전

1842
01:02:58,319 --> 01:03:00,319


1843
01:03:00,319 --> 01:03:02,640
그것은 모델 매개변수

1844
01:03:02,640 --> 01:03:03,440


1845
01:03:03,440 --> 01:03:06,559


1846
01:03:06,559 --> 01:03:08,559
를 넘어서야 하고 확장이 특정 모델 매개변수를 풀기 위한 좋은 방법을 잃는다는 것을 의미

1847
01:03:08,559 --> 01:03:10,400
한다면 그것은 매우 불확실해집니다

1848
01:03:10,400 --> 01:03:13,440


1849
01:03:13,440 --> 01:03:15,039
나는 그것이 저에게 열린 문제인지 모릅니다

1850
01:03:15,039 --> 01:03:16,559


1851
01:03:16,559 --> 01:03:18,640
멋지군요 예 제 생각에는  고차원

1852
01:03:18,640 --> 01:03:19,760
문제는

1853
01:03:19,760 --> 01:03:21,599
여전히 음이 상대적으로 어려운 것을 나타냅니다.

1854
01:03:21,599 --> 01:03:23,119


1855
01:03:23,119 --> 01:03:25,760
특히 여러분의 종류로

1856
01:03:25,760 --> 01:03:27,359
인해서 우리가 음과 같은 만에서 멀어질수록 더

1857
01:03:27,359 --> 01:03:29,680
적은 원칙이

1858
01:03:29,680 --> 01:03:30,640
되고 음, 음, 음은

1859
01:03:30,640 --> 01:03:34,960
그것이 마치 아주 가는 선과 같다는 것을 알고 있기 때문입니다.

1860
01:03:34,960 --> 01:03:37,520


1861
01:03:37,520 --> 01:03:38,720
rl

1862
01:03:38,720 --> 01:03:40,960
또는 능동 추론 패러다임 내에서 코어에

1863
01:03:40,960 --> 01:03:41,839
일종의

1864
01:03:41,839 --> 01:03:44,559
희소 뼈대가 있는지 여부에 대해 흥미롭고

1865
01:03:44,559 --> 01:03:45,520


1866
01:03:45,520 --> 01:03:48,799
때로는 이러한 다른 레이어

1867
01:03:48,799 --> 01:03:51,839
또는 조정이 필요

1868
01:03:51,839 --> 01:03:55,359
하고 배우는 데 꽤 흥미롭고

1869
01:03:55,359 --> 01:03:57,200


1870
01:03:57,200 --> 01:04:00,079
도전 과제에 대해 이전에 말한 내용  지역 환경이 바뀌도록 환경

1871
01:04:00,079 --> 01:04:01,839


1872
01:04:01,839 --> 01:04:03,920
을 이동하거나 게임을 하고 있는지 여부에 관계없이 피드백을 받을 때 순차적인 조치를 계획

1873
01:04:03,920 --> 01:04:05,440
하고 있습니다.

1874
01:04:05,440 --> 01:04:06,720


1875
01:04:06,720 --> 01:04:07,839


1876
01:04:07,839 --> 01:04:09,440
보드 게임을 하는 저에게 변화

1877
01:04:09,440 --> 01:04:10,880
가 생기거나 시장에서 순차적으로 거래를 하고 있는

1878
01:04:10,880 --> 01:04:13,359


1879
01:04:13,359 --> 01:04:15,280
중입니다

1880
01:04:15,280 --> 01:04:17,440
. 최소한 몇 가지 가정에 대해 생각하지

1881
01:04:17,440 --> 01:04:18,720


1882
01:04:18,720 --> 01:04:22,240
않고 1단계부터

1883
01:04:22,240 --> 01:04:24,559
100단계까지 계획할 수는 없습니다.

1884
01:04:24,559 --> 01:04:25,520
근본적인

1885
01:04:25,520 --> 01:04:27,680
불확실성이 있으므로 강화 학습 및 머신 러닝

1886
01:04:27,680 --> 01:04:30,160
의 동기와 접촉하는 많은 지점이

1887
01:04:30,160 --> 01:04:32,559


1888
01:04:32,559 --> 01:04:33,680


1889
01:04:33,680 --> 01:04:35,599
능동적 추론에 더 많은 빛을 가져다줄

1890
01:04:35,599 --> 01:04:37,440
것이며

1891
01:04:37,440 --> 01:04:39,920
방금 언급한 경계 중 일부를 밀어붙일 수 있을 것입니다.

1892
01:04:39,920 --> 01:04:40,960


1893
01:04:40,960 --> 01:04:42,720
그래서 질문이 있습니다

1894
01:04:42,720 --> 01:04:45,119
.  채팅도 질문을 할 수 있습니다

1895
01:04:45,119 --> 01:04:47,680
음 누군가가 이에 대해 배우고 싶어

1896
01:04:47,680 --> 01:04:48,160


1897
01:04:48,160 --> 01:04:51,280
하고 강화 학습 학습에 매혹되지 않았을 수도 있기 때문에 실제로 운이 좋은 초심자의 관점에 있다고 가정해 보겠습니다.

1898
01:04:51,280 --> 01:04:52,960


1899
01:04:52,960 --> 01:04:56,079


1900
01:04:56,079 --> 01:04:57,760


1901
01:04:57,760 --> 01:04:58,960


1902
01:04:58,960 --> 01:05:02,000
당신의

1903
01:05:02,000 --> 01:05:03,280
프리젠테이션

1904
01:05:03,280 --> 01:05:05,599
, 그래서 어떤 종류의 컴퓨터

1905
01:05:05,599 --> 01:05:06,720
언어

1906
01:05:06,720 --> 01:05:08,880
나 기술을 배우고 싶어하는지, 어떤

1907
01:05:08,880 --> 01:05:11,119
종류의 접근 방식이나 사고 방식을 원하는지 b  e

1908
01:05:11,119 --> 01:05:12,000
도움

1909
01:05:12,000 --> 01:05:13,680
이 되는 사람이

1910
01:05:13,680 --> 01:05:15,039


1911
01:05:15,039 --> 01:05:16,559
고전적인 기계 학습 관점에서 시작

1912
01:05:16,559 --> 01:05:18,400
하고 능동 추론을 배우는 것이

1913
01:05:18,400 --> 01:05:21,520
아니라 능동 추론으로 숙련도를 높이는

1914
01:05:21,520 --> 01:05:23,039
것이라면 두 사람 중 한 명에게 무엇을 추천하시겠습니까?

1915
01:05:23,039 --> 01:05:25,119


1916
01:05:25,119 --> 01:05:27,119


1917
01:05:27,119 --> 01:05:28,480
저는

1918
01:05:28,480 --> 01:05:30,640
일종의 잠재적인 사람을 보는 흥미로운 방법이라고 생각합니다.

1919
01:05:30,640 --> 01:05:32,079
왜냐하면

1920
01:05:32,079 --> 01:05:33,280
저는 옛날에 제가 노라

1921
01:05:33,280 --> 01:05:35,920
처럼 이 사람과 비슷하다고 느꼈고

1922
01:05:35,920 --> 01:05:36,799


1923
01:05:36,799 --> 01:05:38,079


1924
01:05:38,079 --> 01:05:39,520
능동적 추론에 대해 이러한 대화를 나누기 시작했을 때

1925
01:05:39,520 --> 01:05:41,440
음

1926
01:05:41,440 --> 01:05:44,640
, 그리고 저는  이 문서

1927
01:05:44,640 --> 01:05:45,680
는 기본적으로

1928
01:05:45,680 --> 01:05:47,680
제가 쓰고 있던 튜토리얼로 시작

1929
01:05:47,680 --> 01:05:48,960


1930
01:05:48,960 --> 01:05:51,359
했습니다. 저녁

1931
01:05:51,359 --> 01:05:53,280


1932
01:05:53,280 --> 01:05:54,799
에 추론 문학

1933
01:05:54,799 --> 01:05:57,440
의 행위를 통해 선별하는 것을

1934
01:05:57,440 --> 01:05:59,280
좋아하는 것에 대해 읽는 데 23개월을 보냈습니다.

1935
01:05:59,280 --> 01:05:59,920
밀도가

1936
01:05:59,920 --> 01:06:02,480
높고 읽기가 매우 어렵기 때문에

1937
01:06:02,480 --> 01:06:03,760
시도하지 않고도 알 수 있습니다.

1938
01:06:03,760 --> 01:06:06,079
그러나 나는

1939
01:06:06,079 --> 01:06:07,520
특히 이 원고를 읽는 것이 전체 목적과 같다고 생각합니다.

1940
01:06:07,520 --> 01:06:08,079


1941
01:06:08,079 --> 01:06:10,000
우리가 글을 쓰기 시작했을 때 철학

1942
01:06:10,000 --> 01:06:11,440


1943
01:06:11,440 --> 01:06:14,640
은 여기에서 무슨 일이 일어나고 있는지 정말 이해하는 것이었습니다.

1944
01:06:14,640 --> 01:06:16,160


1945
01:06:16,160 --> 01:06:17,760
예상되는 자유 에너지의 양은 무엇인지,

1946
01:06:17,760 --> 01:06:18,880
왜 우리가 그것에 대해 관심을 갖는지

1947
01:06:18,880 --> 01:06:21,359
일종의 이론적 관점에서 알 수 있습니다. 제

1948
01:06:21,359 --> 01:06:23,359
생각에는 이것이

1949
01:06:23,359 --> 01:06:26,160
개념에 대한 매우 명료한 프레젠테이션이므로 최소한

1950
01:06:26,160 --> 01:06:26,640


1951
01:06:26,640 --> 01:06:28,240


1952
01:06:28,240 --> 01:06:30,319
무슨 일이 일어나고 있는지에 대해

1953
01:06:30,319 --> 01:06:32,160
일종의 직관을 얻을 수 있습니다. 코딩 측면의 종류에 관해서는 정말 말할 수 없습니다.

1954
01:06:32,160 --> 01:06:33,760


1955
01:06:33,760 --> 01:06:35,760
그것은 꽤 잘 작동합니다

1956
01:06:35,760 --> 01:06:36,960


1957
01:06:36,960 --> 01:06:38,960
음 나는 그것이

1958
01:06:38,960 --> 01:06:40,000


1959
01:06:40,000 --> 01:06:41,920
사람의 주요 목표가 무엇

1960
01:06:41,920 --> 01:06:43,440
인지에 달려 있다고 말

1961
01:06:43,440 --> 01:06:46,559
하려고했습니다.

1962
01:06:46,559 --> 01:06:49,760
일종의 높은 수준의 개념적 아이디어를 이해

1963
01:06:49,760 --> 01:06:51,359
하거나 알고리즘으로 취급하는 것입니다.  왜냐하면

1964
01:06:51,359 --> 01:06:52,799
당신이 자유 에너지 원리에서 오는 경우

1965
01:06:52,799 --> 01:06:54,799
너무 능동적인 추론은

1966
01:06:54,799 --> 01:06:56,400
다른 이야기입니다. 또는 당신이

1967
01:06:56,400 --> 01:06:59,440
격리

1968
01:06:59,440 --> 01:07:01,839
된 특정한 종류의 순차적인

1969
01:07:01,839 --> 01:07:02,799
의사 결정을 내리는 능동적인 추론을 하는 경우

1970
01:07:02,799 --> 01:07:06,559
uh 체계 맞습니다 음 그래서 그것에 따라

1971
01:07:06,559 --> 01:07:06,880


1972
01:07:06,880 --> 01:07:09,599
일종의  차이  rs 어, 하지만 phil이

1973
01:07:09,599 --> 01:07:11,440
말했듯이 이 논문

1974
01:07:11,440 --> 01:07:15,359
은

1975
01:07:15,359 --> 01:07:16,960
모든 다른 개념을 시도하고 정의

1976
01:07:16,960 --> 01:07:18,720


1977
01:07:18,720 --> 01:07:21,920
하고 다양한 공식을 거치는 것과 같은 의미에서 확실히 정말 훌륭하다고 생각

1978
01:07:21,920 --> 01:07:25,440


1979
01:07:25,440 --> 01:07:26,559


1980
01:07:26,559 --> 01:07:29,520
합니다.  그것을 도출할 수 있는 방법의 레이아웃

1981
01:07:29,520 --> 01:07:30,880


1982
01:07:30,880 --> 01:07:34,079
음, 그러나

1983
01:07:34,079 --> 01:07:37,200
대략적인 밀도가 실제로 무엇을

1984
01:07:37,200 --> 01:07:40,319
수반하는지와 같은 특정 사항은 이해하기 위해 변형 추론 문헌에 뛰어들어야 하는 매우 어려운

1985
01:07:40,319 --> 01:07:41,200
질문

1986
01:07:41,200 --> 01:07:43,440


1987
01:07:43,440 --> 01:07:44,880


1988
01:07:44,880 --> 01:07:46,000


1989
01:07:46,000 --> 01:07:47,839
이므로 그 관점에서 누군가 추측합니다.

1990
01:07:47,839 --> 01:07:49,920
현장에 오고 있는 사람

1991
01:07:49,920 --> 01:07:51,440
은 변이 추론에 대해 생각하는 데 시간을 할애해야 합니다.

1992
01:07:51,440 --> 01:07:53,280


1993
01:07:53,280 --> 01:07:53,760


1994
01:07:53,760 --> 01:07:55,839


1995
01:07:55,839 --> 01:07:56,960


1996
01:07:56,960 --> 01:07:59,119
능동적 추론의 인식 부분

1997
01:07:59,119 --> 01:08:00,559


1998
01:08:00,559 --> 01:08:03,359
은 대부분의 경우

1999
01:08:03,359 --> 01:08:04,160
변이

2000
01:08:04,160 --> 01:08:07,119
추론 문헌 및 최적화

2001
01:08:07,119 --> 01:08:08,640
어 모델 증거와 정확히 동일하기 때문에 그것이 실제로 영향 공식화의 행위와 어떻게 연결되는지

2002
01:08:08,640 --> 01:08:12,240
어 또는 증거법칙을 극대화하는

2003
01:08:12,240 --> 01:08:13,200


2004
01:08:13,200 --> 01:08:15,599
것이 음 이것이 내가 하려고 했던 두 번째

2005
01:08:15,599 --> 01:08:16,399
것입니다  덧붙이

2006
01:08:16,399 --> 01:08:19,679


2007
01:08:19,679 --> 01:08:22,319
자면 음 lancelot de costa가 있는 논문은 모든 것을 스스로 도출

2008
01:08:22,319 --> 01:08:24,158
하기 위해 드릴다운하려는 사람에게 정말 좋습니다.

2009
01:08:24,158 --> 01:08:27,198


2010
01:08:27,198 --> 01:08:30,719
어 때로는 매우 기술적이어서 오늘 제가 살펴본 논문

2011
01:08:30,719 --> 01:08:31,198
이 바로 이

2012
01:08:31,198 --> 01:08:33,279
예술입니다.

2013
01:08:33,279 --> 01:08:35,359
어 phil과 tom,

2014
01:08:35,359 --> 01:08:36,080
carl

2015
01:08:36,080 --> 01:08:38,238
이 있는 논문은

2016
01:08:38,238 --> 01:08:40,080
수학에 익숙하지 않고

2017
01:08:40,080 --> 01:08:41,198


2018
01:08:41,198 --> 01:08:44,399
일반인의 요약을 얻고자 하는 사람에게 좋은 소개입니다. 어 반면에

2019
01:08:44,399 --> 01:08:46,560
이 논문은 lance의

2020
01:08:46,560 --> 01:08:48,080
첫 번째 저자가 제공하는 논문에서

2021
01:08:48,080 --> 01:08:50,960
자세한 파생과 많은

2022
01:08:50,960 --> 01:08:51,759
가정

2023
01:08:51,759 --> 01:08:53,679
이 있으므로 이해에서 비롯된 것입니다.

2024
01:08:53,679 --> 01:08:55,439


2025
01:08:55,439 --> 01:08:57,759
코딩 관점에서 이론 부분 음 그것은

2026
01:08:57,759 --> 01:08:59,759
최종 목표가 무엇인지에 전적으로 달려

2027
01:08:59,759 --> 01:09:00,640
있으므로

2028
01:09:00,640 --> 01:09:03,198
누군가가 이산 상태 공식으로 작업하기를 원한다면

2029
01:09:03,198 --> 01:09:04,479


2030
01:09:04,479 --> 01:09:07,679
matlab 코드 carl이 작성

2031
01:09:07,679 --> 01:09:10,719
했으며 많은

2032
01:09:10,719 --> 01:09:13,600
멋진 시뮬레이션과 예제로 수년간

2033
01:09:13,600 --> 01:09:14,319
작업했습니다.  사용할 수

2034
01:09:14,319 --> 01:09:17,439
있고 또한 우리의 코드가 온라인이고

2035
01:09:17,439 --> 01:09:18,479
액세스할 수

2036
01:09:18,479 --> 01:09:21,679
있으므로 소프트웨어 um 섹션의 종이 um에 링크

2037
01:09:21,679 --> 01:09:24,880
가 있습니다.

2038
01:09:24,880 --> 01:09:25,679


2039
01:09:25,679 --> 01:09:27,040
코드가 정확히 어디에 있으며

2040
01:09:27,040 --> 01:09:29,040


2041
01:09:29,040 --> 01:09:29,920


2042
01:09:29,920 --> 01:09:33,120
누군가가 음에 관심이 있는 경우 시뮬레이션이 어떻게 수행되었는지 확인할 수

2043
01:09:33,120 --> 01:09:36,719
있습니다. 음, 음에 대한 최근 작업이

2044
01:09:36,719 --> 01:09:39,120
있다는 활성 추론의 고차원 공식을 추측합니다.

2045
01:09:39,120 --> 01:09:42,799
음

2046
01:09:42,799 --> 01:09:46,399
zephyr zephyrus 음 so zeff 글꼴

2047
01:09:46,399 --> 01:09:48,799
은 다음과 같습니다.  첫 번째 저자 어, 우리는

2048
01:09:48,799 --> 01:09:50,080


2049
01:09:50,080 --> 01:09:52,479
그 작업을 위한 자식 리퍼를 가지고 있으며,

2050
01:09:52,479 --> 01:09:53,198


2051
01:09:53,198 --> 01:09:55,920


2052
01:09:55,920 --> 01:09:57,360


2053
01:09:57,360 --> 01:09:59,600
어 매우

2054
01:09:59,600 --> 01:10:01,280
짧은 인코더와 간단한

2055
01:10:01,280 --> 01:10:03,679
전환 네트워크를 사용하여 간단한 능동 추론 에이전트를 구현하는 방법에 대한 분석을 제공하므로 많은 것이 있습니다.

2056
01:10:03,679 --> 01:10:04,719
다른 영역과 비슷

2057
01:10:04,719 --> 01:10:06,400
하지만 처음 시작하는 사람

2058
01:10:06,400 --> 01:10:07,679


2059
01:10:07,679 --> 01:10:08,800
은

2060
01:10:08,800 --> 01:10:10,159
이론적 측면에 중점을 둘 것인지 또는

2061
01:10:10,159 --> 01:10:11,840
구현 측면에 중점을 둘

2062
01:10:11,840 --> 01:10:13,199


2063
01:10:13,199 --> 01:10:14,640
것인지를

2064
01:10:14,640 --> 01:10:16,000


2065
01:10:16,000 --> 01:10:17,920
이해해야 합니다.  그들이 코딩 측면에 초점을 맞추고 싶다면

2066
01:10:17,920 --> 01:10:18,239


2067
01:10:18,239 --> 01:10:19,600


2068
01:10:19,600 --> 01:10:21,760
그것이 연속적인지 또는

2069
01:10:21,760 --> 01:10:23,199
이산적인 상태 공식

2070
01:10:23,199 --> 01:10:25,199
인지 파악하기를 원합니다.

2071
01:10:25,199 --> 01:10:27,679


2072
01:10:27,679 --> 01:10:29,040
연속적인 경우

2073
01:10:29,040 --> 01:10:32,880
대부분이

2074
01:10:32,880 --> 01:10:34,800
자체적으로 동작 좌표를 작성하거나

2075
01:10:34,800 --> 01:10:36,960
관심의 연속 분포

2076
01:10:36,960 --> 01:10:40,640
를 근사하기 위해 신경망과 같은 일종의 음 음처럼 사용해야

2077
01:10:40,640 --> 01:10:42,480


2078
01:10:42,480 --> 01:10:43,280


2079
01:10:43,280 --> 01:10:45,520
합니다.  또는 carl이 작성한 이산 상태

2080
01:10:45,520 --> 01:10:46,400


2081
01:10:46,400 --> 01:10:49,199
음. 만일 그들이 이산 상태 음에 대해 질문이 있는 경우

2082
01:10:49,199 --> 01:10:50,480


2083
01:10:50,480 --> 01:10:53,679
저는 이메일도 받아 드리겠습니다.

2084
01:10:53,679 --> 01:10:54,080


2085
01:10:54,080 --> 01:10:57,040
누군가가 있다면 또는 연속

2086
01:10:57,040 --> 01:10:57,840
상태

2087
01:10:57,840 --> 01:11:01,679
음 상태 공간에 대해서도 감사를 표합니다.

2088
01:11:01,679 --> 01:11:04,960
차이점과 음 그것은

2089
01:11:04,960 --> 01:11:06,159


2090
01:11:06,159 --> 01:11:09,040
우리가 ryan smith와 함께 거쳐야 하는 matlab 코드

2091
01:11:09,040 --> 01:11:09,679
와

2092
01:11:09,679 --> 01:11:12,159


2093
01:11:12,159 --> 01:11:13,120


2094
01:11:13,120 --> 01:11:16,000
행렬 곱셈 등을 하는 christopher white 사이에 아주 큰 차이입니다. 그런 다음

2095
01:11:16,000 --> 01:11:17,920
여기에 신경망이 나타나며

2096
01:11:17,920 --> 01:11:20,880


2097
01:11:20,880 --> 01:11:23,120
높은 차원

2098
01:11:23,120 --> 01:11:26,159
과 연속성을 가진 새로운 기회와 같은 소리를 제공합니다.  변수뿐만 아니라

2099
01:11:26,159 --> 01:11:26,880
많은 새로운

2100
01:11:26,880 --> 01:11:30,320
도전 과제도 있으므로

2101
01:11:30,320 --> 01:11:33,360


2102
01:11:33,360 --> 01:11:37,440
매트릭스 형식과 더 많은

2103
01:11:37,440 --> 01:11:40,480
기계 학습 스타일이 공유하는

2104
01:11:40,480 --> 01:11:43,040
본질은 무엇입니까?  e 어떤 사람들에게는 음

2105
01:11:43,040 --> 01:11:43,920


2106
01:11:43,920 --> 01:11:46,480


2107
01:11:46,480 --> 01:11:47,840


2108
01:11:47,840 --> 01:11:49,120


2109
01:11:49,120 --> 01:11:51,760
,

2110
01:11:51,760 --> 01:11:54,800
생태 심리학이나 능동적인

2111
01:11:54,800 --> 01:11:57,600
철학적 또는 구체화된 수행

2112
01:11:57,600 --> 01:11:58,320
적 관점에서 능동적 추론에 대해 생각할 때 두 컴퓨터 언어 사이의 차이가 말 그대로 머리를 갈라놓을 수도 있습니다.

2113
01:11:58,320 --> 01:12:01,600
모든 배경은 능동적 추론에 수렴합니다.

2114
01:12:01,600 --> 01:12:02,880


2115
01:12:02,880 --> 01:12:05,440
머리카락 바깥에 있는 누군가에게

2116
01:12:05,440 --> 01:12:06,800


2117
01:12:06,800 --> 01:12:09,199


2118
01:12:09,199 --> 01:12:09,920


2119
01:12:09,920 --> 01:12:11,679
핵심 능동 추론

2120
01:12:11,679 --> 01:12:13,440


2121
01:12:13,440 --> 01:12:14,800
인 우리가 실제로 증류할 수 있는 것은 무엇

2122
01:12:14,800 --> 01:12:16,480


2123
01:12:16,480 --> 01:12:19,120
이며 Matlab 또는

2124
01:12:19,120 --> 01:12:20,840


2125
01:12:20,840 --> 01:12:22,960
python

2126
01:12:22,960 --> 01:12:24,640
um과 같은 신경망 모드로 전환하면 제

2127
01:12:24,640 --> 01:12:26,640
요약 슬라이드가 생각하는 방식으로 이어집니다.

2128
01:12:26,640 --> 01:12:28,159
따라서 능동적 추론은 핵심

2129
01:12:28,159 --> 01:12:29,679
구성 요소가 젠더

2130
01:12:29,679 --> 01:12:30,960
모델

2131
01:12:30,960 --> 01:12:32,480
을 공식화하고 여기에서 일반 모델을 공식화하는 것이 일반 모델

2132
01:12:32,480 --> 01:12:33,840
의 매개변수화입니다.

2133
01:12:33,840 --> 01:12:35,520
따라서

2134
01:12:35,520 --> 01:12:37,760
이산 단계 범주형 분포

2135
01:12:37,760 --> 01:12:38,719
를 사용

2136
01:12:38,719 --> 01:12:40,560
하거나 더 연속적인 상태 공식을 사용할 수 있습니다.

2137
01:12:40,560 --> 01:12:42,719


2138
01:12:42,719 --> 01:12:44,560
신경망 공식은 이에 대한

2139
01:12:44,560 --> 01:12:46,400
특정 인스턴스화

2140
01:12:46,400 --> 01:12:49,679


2141
01:12:49,679 --> 01:12:50,480


2142
01:12:50,480 --> 01:12:53,679
이므로 두 번째 방법은 재생

2143
01:12:53,679 --> 01:12:56,239
중인 목적 함수의 최적화

2144
01:12:56,239 --> 01:12:57,440


2145
01:12:57,440 --> 01:13:01,840
이므로 matlab 코드에서

2146
01:13:01,840 --> 01:13:04,239
평균 필드 메시지를 사용하여 보낼 그라디언트를 수행하고 있음을 구별하는 한 가지 방법입니다.

2147
01:13:04,239 --> 01:13:06,400


2148
01:13:06,400 --> 01:13:07,760


2149
01:13:07,760 --> 01:13:09,679
몇 가지 논문에서 소개된 특정 공식을 전달하는 알고리즘

2150
01:13:09,679 --> 01:13:11,440
을 구체적으로 다루지

2151
01:13:11,440 --> 01:13:12,880
않았거나

2152
01:13:12,880 --> 01:13:16,000
어,

2153
01:13:16,000 --> 01:13:17,280
실제로

2154
01:13:17,280 --> 01:13:20,320
또는 람다 분포를 계산하기 위해 역전파를 수행

2155
01:13:20,320 --> 01:13:21,760
한 다음

2156
01:13:21,760 --> 01:13:23,840
해당 분포를 해결하는 중입니다.

2157
01:13:23,840 --> 01:13:26,560
그것은 일종의

2158
01:13:26,560 --> 01:13:29,840
당신이 음과 같은 공식에 달려 있습니다. 그것은

2159
01:13:29,840 --> 01:13:32,400


2160
01:13:32,400 --> 01:13:33,840


2161
01:13:33,840 --> 01:13:35,600
암묵적인 전진 모델을 취하는 것과 같

2162
01:13:35,600 --> 01:13:37,600
거나 명시적인 젠더

2163
01:13:37,600 --> 01:13:39,199
모델을 취하는 것과 같은 목표를 최적화하는 방법에 달려 있습니다. 음

2164
01:13:39,199 --> 01:13:41,360
그리고 한 가지 언급하는 것을 잊었다는 것

2165
01:13:41,360 --> 01:13:42,480
입니다.  um

2166
01:13:42,480 --> 01:13:44,480
alex shams and connor hins 그들은

2167
01:13:44,480 --> 01:13:47,520


2168
01:13:47,520 --> 01:13:50,880
파이썬에서 um 능동 추론의 이산 상태 공식화 작업

2169
01:13:50,880 --> 01:13:53,360


2170
01:13:53,360 --> 01:13:55,280
을 해왔습니다.

2171
01:13:55,280 --> 01:13:56,239


2172
01:13:56,239 --> 01:13:58,960
더 고급 또는 고차원적인 것과 같은 일을 할 수 있는 하나의 특정 언어에 초점을 맞추고 싶습니다.

2173
01:13:58,960 --> 01:14:00,640


2174
01:14:00,640 --> 01:14:02,719
그리고 carl이 가지고 있는 이산 상태 공식화

2175
01:14:02,719 --> 01:14:03,920
는 음

2176
01:14:03,920 --> 01:14:05,760


2177
01:14:05,760 --> 01:14:08,719
, 누군가가 관심이 있는 경우 코드 기반에서 작업할 사람들을 찾고 있다는 것도 알고 있습니다.

2178
01:14:08,719 --> 01:14:09,840


2179
01:14:09,840 --> 01:14:13,520
활동을 유추해 보면 음, 하지만

2180
01:14:13,520 --> 01:14:17,760
관심이 있는 사람이 있으면 github에도 있습니다. 음, 두 사람 중 한 사람

2181
01:14:17,840 --> 01:14:21,760
의 마지막

2182
01:14:21,760 --> 01:14:25,280
생각이나 의견이 있으면

2183
01:14:27,440 --> 01:14:30,640
음 아니요. 저는 괜찮은 것 같아요.

2184
01:14:30,640 --> 01:14:33,440
그래서 어떻게 생각하세요

2185
01:14:34,880 --> 01:14:37,199
음

2186
01:14:38,560 --> 01:14:41,360
우리가 눈치채고 있는 것 같아요.  약간

2187
01:14:41,360 --> 01:14:42,239


2188
01:14:42,239 --> 01:14:45,679
음 활성 추론에 대한 관심 증가 로봇 공학과 같이 이전에는 능동

2189
01:14:45,679 --> 01:14:46,640
추론조차 고려되었을

2190
01:14:46,640 --> 01:14:48,560
수 있는 영역과 같은 예를 들면

2191
01:14:48,560 --> 01:14:49,840


2192
01:14:49,840 --> 01:14:51,040


2193
01:14:51,040 --> 01:14:53,840


2194
01:14:53,840 --> 01:14:55,360
이제 점점 더 많이 보기 시작

2195
01:14:55,360 --> 01:14:57,360
하고 있으므로 다음과 같이 생각합니다.

2196
01:14:57,360 --> 01:14:58,960
지금 참여하고 싶습니다. 특히

2197
01:14:58,960 --> 01:15:01,199
좋은 시간입니다.

2198
01:15:01,199 --> 01:15:04,400
필립에게 전화

2199
01:15:04,400 --> 01:15:07,199
하십시오.

2200
01:15:07,199 --> 01:15:08,880
우리가 논의하고 있는 우수한 논문을 다시 추천하겠습니다.

2201
01:15:08,880 --> 01:15:11,120
이 비디오의 설명에 있습니다. 참여해

2202
01:15:11,120 --> 01:15:12,719
주셔서 정말 감사합니다.

2203
01:15:12,719 --> 01:15:15,040
당신은 항상

2204
01:15:15,040 --> 01:15:16,480


2205
01:15:16,480 --> 01:15:18,239
당신이 저술한 논문에 대해 이야기하는 것을 환영합니다.

2206
01:15:18,239 --> 01:15:19,520
그러나

2207
01:15:19,520 --> 01:15:21,679
다시 한 번 nora와 phillip

2208
01:15:21,679 --> 01:15:23,679


2209
01:15:23,679 --> 01:15:24,239


2210
01:15:24,239 --> 01:15:27,679
에게 감사드립니다. 그리고 미래의 활발한 추론 스트림에서 다시 뵙기를

2211
01:15:27,679 --> 01:15:30,159
바랍니다. 초대해 주셔서 감사합니다.  안녕히

2212
01:15:30,159 --> 01:15:31,440
가세요 다니엘

2213
01:15:31,440 --> 01:15:34,000
피스 바이

2214
01:15:36,840 --> 01:15:39,280
굉장합니다 스트림 중지 멋진

2215
01:15:39,280 --> 01:15:41,040
대화 philip and noor 정말 감사합니다

2216
01:15:41,040 --> 01:15:43,840


