1
00:00:07,839 --> 00:00:08,400
Olá

2
00:00:08,400 --> 00:00:11,120
e bem-vindos a todos ao

3
00:00:11,120 --> 00:00:12,160
laboratório de inferência ativo,

4
00:00:12,160 --> 00:00:15,759
este é o fluxo de modelo número 2.1

5
00:00:15,759 --> 00:00:18,960
em 16 de abril de 2021

6
00:00:18,960 --> 00:00:20,720
e hoje será um

7
00:00:20,720 --> 00:00:22,400
fluxo de modelo incrível, vamos

8
00:00:22,400 --> 00:00:24,400
apenas dar uma volta e

9
00:00:24,400 --> 00:00:25,920
nos apresentar e

10
00:00:25,920 --> 00:00:27,920
depois mencionarei como  a sessão

11
00:00:27,920 --> 00:00:30,000
será realizada hoje e depois passaremos para

12
00:00:30,000 --> 00:00:33,200
noor para uma apresentação, então sou daniel

13
00:00:33,200 --> 00:00:35,120
e sou um pesquisador de pós-doutorado na

14
00:00:35,120 --> 00:00:36,719
califórnia vou passar para

15
00:00:36,719 --> 00:00:39,040
philip

16
00:00:40,000 --> 00:00:42,800
oi sim, atualmente sou estudante de doutorado em

17
00:00:42,800 --> 00:00:43,280
oxford

18
00:00:43,280 --> 00:00:46,719
em  meu segundo ano e sim, acho que esse

19
00:00:46,719 --> 00:00:48,320
é um trabalho que fiz antes de começar

20
00:00:48,320 --> 00:00:49,440
meu doutorado

21
00:00:49,440 --> 00:00:52,640
ao lado de nor e atualmente estou mais

22
00:00:52,640 --> 00:00:53,600
focado na

23
00:00:53,600 --> 00:00:55,600
eficiência de dados especificamente no

24
00:00:55,600 --> 00:00:57,280
aprendizado de reforço,

25
00:00:57,280 --> 00:00:58,960
mas acho que nesse tópico é obviamente um conhecimento

26
00:00:58,960 --> 00:01:00,879
de inferência ativa

27
00:01:00,879 --> 00:01:03,520
útil para abordar tais

28
00:01:03,520 --> 00:01:06,239
problemas de pesquisa

29
00:01:06,240 --> 00:01:09,360
quem e ou oi

30
00:01:09,360 --> 00:01:12,000
oi eu sou o noah sou um estudante de doutorado do terceiro ano

31
00:01:12,000 --> 00:01:13,840
no grupo de neurobiologia teórica no

32
00:01:13,840 --> 00:01:15,200
centro de boas-vindas para neuroimagem humana

33
00:01:15,200 --> 00:01:16,159


34
00:01:16,159 --> 00:01:18,799
um na ucl um então é a universidade de

35
00:01:18,799 --> 00:01:19,920
londres

36
00:01:19,920 --> 00:01:22,720
hum, então meu doutorado supervisionado por carros

37
00:01:22,720 --> 00:01:23,920
focou nessas ideias

38
00:01:23,920 --> 00:01:26,000
relacionadas à adaptação, uma das

39
00:01:26,000 --> 00:01:27,759
quais vou focar hoje, que é a

40
00:01:27,759 --> 00:01:29,759
adaptação comportamental em ambientes não estacionários

41
00:01:29,759 --> 00:01:32,000
usando inferência ativa,

42
00:01:32,000 --> 00:01:35,119
então obrigado incrível, obrigado por

43
00:01:35,119 --> 00:01:38,159
participar e por esta apresentação.  vai

44
00:01:38,159 --> 00:01:38,720


45
00:01:38,720 --> 00:01:41,280
ouvir uma apresentação de sabe-se lá quanto tempo

46
00:01:41,280 --> 00:01:42,720
de nem

47
00:01:42,720 --> 00:01:44,399
e então eu vou compilar

48
00:01:44,399 --> 00:01:45,759
perguntas do chat,

49
00:01:45,759 --> 00:01:48,240
então, por favor, apenas digite as perguntas à medida que elas

50
00:01:48,240 --> 00:01:48,880
chegarem a você

51
00:01:48,880 --> 00:01:51,119
e, em seguida, responderemos a elas no final,

52
00:01:51,119 --> 00:01:53,200
então obrigado novamente e nem  por favor

53
00:01:53,200 --> 00:01:56,479
tire isso perfeito obrigado

54
00:01:56,479 --> 00:01:58,880
hum, então hoje eu vou apresentar alguns trabalhos

55
00:01:58,880 --> 00:01:59,520
hum

56
00:01:59,520 --> 00:02:01,600
que eu fiz em colaboração com philip

57
00:02:01,600 --> 00:02:03,119
que você acabou de ouvir de

58
00:02:03,119 --> 00:02:06,399
Thomas Parr e Carl Fristan hum

59
00:02:06,399 --> 00:02:08,800
então é intitulado inferência ativa uh

60
00:02:08,800 --> 00:02:12,720
desmistificado e comparado

61
00:02:13,599 --> 00:02:15,440
ok ok perfeito  ok, então a

62
00:02:15,440 --> 00:02:17,440
apresentação está estruturada da seguinte forma

63
00:02:17,440 --> 00:02:20,480
você pode ouvir as telas

64
00:02:20,480 --> 00:02:22,160
eu acho que está compartilhando ou estava você

65
00:02:22,160 --> 00:02:23,840
não consegue ver eu não estou vendo

66
00:02:23,840 --> 00:02:26,000
você poderia apenas compartilhar novamente

67
00:02:26,000 --> 00:02:28,640
sim com certeza

68
00:02:29,920 --> 00:02:34,480
um technolog  y eu digo a você

69
00:02:34,480 --> 00:02:36,800
lá vamos nós e vou cortá-lo então vá

70
00:02:36,800 --> 00:02:38,720
em frente obrigado

71
00:02:38,720 --> 00:02:40,879
perfeito obrigado então a apresentação foi

72
00:02:40,879 --> 00:02:42,239
estruturada assim como

73
00:02:42,239 --> 00:02:44,080
primeiro vou motivar brevemente a configuração do problema

74
00:02:44,080 --> 00:02:45,280
e fornecer

75
00:02:45,280 --> 00:02:47,360
detalhes de uma instanciação de inferência ativa específica

76
00:02:47,360 --> 00:02:49,920
em consideração hoje

77
00:02:49,920 --> 00:02:51,519
que é  a configuração do espaço de estados discreto

78
00:02:51,519 --> 00:02:52,319


79
00:02:52,319 --> 00:02:54,160
e a segunda metade da

80
00:02:54,160 --> 00:02:55,599
apresentação serão focadas em alguns

81
00:02:55,599 --> 00:02:57,440
exemplos particulares comparando

82
00:02:57,440 --> 00:02:59,360
a formulação de influência ativa com

83
00:02:59,360 --> 00:03:00,720
aprendizado de reforço

84
00:03:00,720 --> 00:03:03,599
especificamente aprendizado q e algoritmo

85
00:03:03,599 --> 00:03:04,959
baseado em modelo bayesiano

86
00:03:04,959 --> 00:03:07,519
e então o que vou fazer

87
00:03:07,519 --> 00:03:08,959
é fornecer alguma face  validade de

88
00:03:08,959 --> 00:03:10,640
aspectos particulares de por que você gostaria

89
00:03:10,640 --> 00:03:14,080
de usar a inferência ativa

90
00:03:14,080 --> 00:03:18,080
ok, então o que é inferência

91
00:03:18,080 --> 00:03:20,480
ativa é uma conta de primeiros princípios de

92
00:03:20,480 --> 00:03:21,599
como

93
00:03:21,599 --> 00:03:23,920
agentes biológicos ou artificiais podem operar em

94
00:03:23,920 --> 00:03:26,239
configurações dinâmicas não estacionárias

95
00:03:26,239 --> 00:03:28,560
, estipula que esses agentes

96
00:03:28,560 --> 00:03:30,000
para manter  homeostase

97
00:03:30,000 --> 00:03:31,680
residem em atrair estados que

98
00:03:31,680 --> 00:03:34,560
minimizam sua entropia ou sua surpresa.

99
00:03:34,560 --> 00:03:36,239
este exemplo em particular

100
00:03:36,239 --> 00:03:38,000
que estamos vendo

101
00:03:38,000 --> 00:03:41,280
desse agente faminto abrindo a geladeira

102
00:03:41,280 --> 00:03:42,879
da maneira que funcionaria é como se você

103
00:03:42,879 --> 00:03:44,959
precisasse por que você abriria a geladeira

104
00:03:44,959 --> 00:03:46,480
corretamente para fazer uma

105
00:03:46,480 --> 00:03:47,280
escolha específica entre

106
00:03:47,280 --> 00:03:50,080
comer em casa ou fora e

107
00:03:50,080 --> 00:03:51,120
para fazer isso você

108
00:03:51,120 --> 00:03:53,200
tem que decidir qual é a

109
00:03:53,200 --> 00:03:55,040
ação ideal que lhe permitiria resolver

110
00:03:55,040 --> 00:03:56,959
sua própria incerteza sobre o

111
00:03:56,959 --> 00:03:58,560
estágio atual das coisas

112
00:03:58,560 --> 00:04:00,799
e isso o ajudaria a

113
00:04:00,799 --> 00:04:02,480
decidir se você quer cozinhar em casa

114
00:04:02,480 --> 00:04:04,400
ou se quer caminhar  para o restaurante

115
00:04:04,400 --> 00:04:06,720
e neste caso em particular isso

116
00:04:06,720 --> 00:04:08,560
levou o agente a abrir a geladeira para

117
00:04:08,560 --> 00:04:11,760
verificar se ainda tem comida em casa

118
00:04:11,760 --> 00:04:13,519
e o que é bom sobre a inferência ativa

119
00:04:13,519 --> 00:04:15,519
é que ela permite que você

120
00:04:15,519 --> 00:04:16,959
pense sobre essas configurações de problemas de uma

121
00:04:16,959 --> 00:04:19,358
maneira mais formal especificando que

122
00:04:19,358 --> 00:04:20,639
o comportamento ideal

123
00:04:20,639 --> 00:04:23,199
é determinado pela avaliação da evidência

124
00:04:23,199 --> 00:04:24,639
que é a entrada sensorial

125
00:04:24,639 --> 00:04:26,639
sob o modelo de gênero do agente de

126
00:04:26,639 --> 00:04:28,080
observações a que ele

127
00:04:28,080 --> 00:04:30,400
está sendo exposto e nesta

128
00:04:30,400 --> 00:04:31,520


129
00:04:31,520 --> 00:04:33,360
apresentação específica  ion o que faremos é focar

130
00:04:33,360 --> 00:04:35,280
apenas na teoria do processo que subscreve

131
00:04:35,280 --> 00:04:37,199
a inferência ativa e não falar através

132
00:04:37,199 --> 00:04:38,240
do biológico

133
00:04:38,240 --> 00:04:41,199
sobre a plausibilidade neural do

134
00:04:41,199 --> 00:04:44,240
esquema de passagem de mensagens de inferência ativa,

135
00:04:44,240 --> 00:04:47,280
mas para motivar adequadamente, por que

136
00:04:47,280 --> 00:04:48,479
gostaríamos de usar

137
00:04:48,479 --> 00:04:50,560
uma inferência ativa  em comparação com

138
00:04:50,560 --> 00:04:52,000


139
00:04:52,000 --> 00:04:52,800
algoritmos genéricos de aprendizado por reforço

140
00:04:52,800 --> 00:04:54,720
, precisamos primeiro começar com esse

141
00:04:54,720 --> 00:04:56,080
entendimento de que, com uma inferência ativa,

142
00:04:56,080 --> 00:04:57,759
há esse compromisso com um

143
00:04:57,759 --> 00:04:59,600
esquema baseado em crenças puras, o

144
00:04:59,600 --> 00:05:01,600
que significa que as funções de recompensa

145
00:05:01,600 --> 00:05:03,520
nem sempre são

146
00:05:03,520 --> 00:05:06,000
necessariamente desnecessárias, porque qualquer política

147
00:05:06,000 --> 00:05:07,360
que você

148
00:05:07,360 --> 00:05:10,240
teria  valor epistêmico mesmo na ausência

149
00:05:10,240 --> 00:05:11,680
de preferências,

150
00:05:11,680 --> 00:05:14,000
além disso, agentes de inferência ativos

151
00:05:14,000 --> 00:05:16,400
também podem aprender suas próprias funções de recompensa

152
00:05:16,400 --> 00:05:19,120
e isso ajuda o agente a descrever o

153
00:05:19,120 --> 00:05:20,400
tipo de comportamento

154
00:05:20,400 --> 00:05:23,199
que ele espera ver por si mesmo, em

155
00:05:23,199 --> 00:05:25,120
oposição a algo que ele

156
00:05:25,120 --> 00:05:28,000
obteria do ambiente e esses  dois

157
00:05:28,000 --> 00:05:29,600
pontos particulares são realmente importantes

158
00:05:29,600 --> 00:05:30,800
em contraste com o

159
00:05:30,800 --> 00:05:33,039
reforço lea  rning porque nas

160
00:05:33,039 --> 00:05:35,680
configurações rl padrão a função de recompensa

161
00:05:35,680 --> 00:05:38,160
uh definiria como o agente interage

162
00:05:38,160 --> 00:05:39,360
ou se comporta

163
00:05:39,360 --> 00:05:41,520
dentro de um ambiente específico,

164
00:05:41,520 --> 00:05:42,560
mas

165
00:05:42,560 --> 00:05:44,080
definir essa função de recompensa em

166
00:05:44,080 --> 00:05:46,000
primeiro lugar é bastante difícil

167
00:05:46,000 --> 00:05:48,160
porque assume que há um

168
00:05:48,160 --> 00:05:49,520
sinal específico que está sendo

169
00:05:49,520 --> 00:05:51,919
dado do  ambiente que pode ser

170
00:05:51,919 --> 00:05:53,600
unanimemente bom ou mau

171
00:05:53,600 --> 00:05:56,160
para o agente o que não seria

172
00:05:56,160 --> 00:05:56,800
necessariamente verdade

173
00:05:56,800 --> 00:06:00,400
num cenário real onde estes

174
00:06:00,400 --> 00:06:02,319
sinais ambientais podem mudar

175
00:06:02,319 --> 00:06:03,919
dependendo do cenário por exemplo

176
00:06:03,919 --> 00:06:05,680
comer gelado nem sempre

177
00:06:05,680 --> 00:06:07,280
será recompensador se estiver

178
00:06:07,280 --> 00:06:09,919
doente  e isso pode torná-lo pior e

179
00:06:09,919 --> 00:06:11,199
é por isso que

180
00:06:11,199 --> 00:06:12,800
construir essas funções de recompensa

181
00:06:12,800 --> 00:06:15,199
em primeiro lugar é extremamente difícil

182
00:06:15,199 --> 00:06:16,880
e se você não as estiver construindo de

183
00:06:16,880 --> 00:06:19,360
maneira apropriada, mesmo com uma configuração rl

184
00:06:19,360 --> 00:06:21,680
, pode resultar em um comportamento abaixo do ideal

185
00:06:21,680 --> 00:06:24,080
para seus agentes.

186
00:06:24,080 --> 00:06:26,000
a inferência ativa é realmente boa

187
00:06:26,000 --> 00:06:27,520
no sentido de que estamos

188
00:06:27,520 --> 00:06:29,680
substituindo ou ignorando a

189
00:06:29,680 --> 00:06:31,360
função de recompensa tradicional que você  você

190
00:06:31,360 --> 00:06:31,919
teria

191
00:06:31,919 --> 00:06:34,400
na configuração rl com crenças anteriores

192
00:06:34,400 --> 00:06:34,960
sobre

193
00:06:34,960 --> 00:06:36,880
resultados preferidos, então o tipo de

194
00:06:36,880 --> 00:06:39,039
estado de coisas desejado em que você deseja

195
00:06:39,039 --> 00:06:40,560
se

196
00:06:40,560 --> 00:06:43,840
ver e isso se torna importante

197
00:06:43,840 --> 00:06:47,039
em configurações onde não há recompensa ou

198
00:06:47,039 --> 00:06:48,400
há uma compreensão realmente imprecisa

199
00:06:48,400 --> 00:06:50,479
do que é uma recompensa ou

200
00:06:50,479 --> 00:06:52,639
preferência  configuração deve parecer

201
00:06:52,639 --> 00:06:55,360
e neste cenário dentro da

202
00:06:55,360 --> 00:06:56,319


203
00:06:56,319 --> 00:06:58,160
formulação de estado discreto de influência ativa padrão o que podemos

204
00:06:58,160 --> 00:07:00,319
fazer é aprender a distribuição prévia empírica

205
00:07:00,319 --> 00:07:01,599
sobre esses

206
00:07:01,599 --> 00:07:05,280
resultados preferidos um e intrínseco uh

207
00:07:05,280 --> 00:07:07,199
desculpe a função de recompensa interna

208
00:07:07,199 --> 00:07:07,599
desse

209
00:07:07,599 --> 00:07:10,400
agente e isso me leva a gostar

210
00:07:10,400 --> 00:07:11,120
a primeira

211
00:07:11,120 --> 00:07:14,479
conceituação distinta entre

212
00:07:14,479 --> 00:07:17,919
rl setting e inferência ativa porque

213
00:07:17,919 --> 00:07:20,639
na inferência ativa as recompensas

214
00:07:20,639 --> 00:07:22,560
não são nada distintas, elas são apenas uma

215
00:07:22,560 --> 00:07:24,560
observação padrão que o agente está

216
00:07:24,560 --> 00:07:26,800
obtendo do ambiente, enquanto em

217
00:07:26,800 --> 00:07:27,840
rl elas são bastante

218
00:07:27,840 --> 00:07:32,160
necessárias para ter uma ação

219
00:07:32,160 --> 00:07:35,759
apropriada que o agente  vai

220
00:07:35,759 --> 00:07:38,960
aprender o segundo ponto que queremos fazer

221
00:07:38,960 --> 00:07:41,280
desculpe o que queríamos  fazer foi que a

222
00:07:41,280 --> 00:07:43,039
influência ativa fornece uma explicação principal

223
00:07:43,039 --> 00:07:44,080
da

224
00:07:44,080 --> 00:07:46,160
exploração epistêmica e da motivação intrínseca como

225
00:07:46,160 --> 00:07:48,160
minimizando a incerteza

226
00:07:48,160 --> 00:07:50,080
e, novamente, dentro da configuração rl, isso é

227
00:07:50,080 --> 00:07:51,440
bastante crucial

228
00:07:51,440 --> 00:07:53,759
porque toda a premissa de muitos novos

229
00:07:53,759 --> 00:07:54,479
algoritmos que

230
00:07:54,479 --> 00:07:57,759
vemos em nosso nrl é tentar e  encontre o

231
00:07:57,759 --> 00:07:58,000


232
00:07:58,000 --> 00:07:59,680
compromisso certo para o equilíbrio entre a

233
00:07:59,680 --> 00:08:02,000
exploração e a exploração então

234
00:08:02,000 --> 00:08:03,919
qual é o conjunto correcto de acções que

235
00:08:03,919 --> 00:08:05,599
o agente deverá fazer num dado momento

236
00:08:05,599 --> 00:08:06,400


237
00:08:06,400 --> 00:08:08,240
devo continuar a escolher todos os

238
00:08:08,240 --> 00:08:10,160
diferentes sabores de gelado a que

239
00:08:10,160 --> 00:08:10,800


240
00:08:10,800 --> 00:08:13,520
nunca foi exposto  hum, como mostarda,

241
00:08:13,520 --> 00:08:14,479
etc.

242
00:08:14,479 --> 00:08:16,879


243
00:08:16,879 --> 00:08:17,840


244
00:08:17,840 --> 00:08:20,000


245
00:08:20,000 --> 00:08:21,120


246
00:08:21,120 --> 00:08:23,199


247
00:08:23,199 --> 00:08:25,199


248
00:08:25,199 --> 00:08:28,080


249
00:08:28,080 --> 00:08:28,560


250
00:08:28,560 --> 00:08:30,800
e sob uma

251
00:08:30,800 --> 00:08:32,958
estrutura bayesiana, a inferência ativa lida com isso

252
00:08:32,958 --> 00:08:36,159
naturalmente, usando a

253
00:08:36,159 --> 00:08:37,760
formulação de energia livre esperada, a qual chegarei em

254
00:08:37,760 --> 00:08:39,760
um momento.

255
00:08:39,760 --> 00:08:42,799
m e a última parte que você pode ver

256
00:08:42,799 --> 00:08:44,560
dentro da estrutura de inferência ativa é

257
00:08:44,560 --> 00:08:46,080
que ela naturalmente leva em conta a

258
00:08:46,080 --> 00:08:47,920
incerteza como parte do processo de

259
00:08:47,920 --> 00:08:48,560
atualização de crenças

260
00:08:48,560 --> 00:08:51,839
ok,

261
00:08:51,839 --> 00:08:54,959
então agora que eu expus as

262
00:08:54,959 --> 00:08:57,200
três coisas que são super interessantes

263
00:08:57,200 --> 00:08:58,640
sobre o ativo  esquema de influência em

264
00:08:58,640 --> 00:09:00,640
comparação com rl eu vou

265
00:09:00,640 --> 00:09:04,480
fornecer algumas intuições sobre por que

266
00:09:04,480 --> 00:09:08,000
você pode desculpar algumas motivações sobre

267
00:09:08,000 --> 00:09:09,760
por que podemos até formular a

268
00:09:09,760 --> 00:09:13,120
formulação de influência ativa do jeito que fazemos

269
00:09:13,120 --> 00:09:17,040
ok então

270
00:09:17,200 --> 00:09:18,959
desculpe, acabei de perceber que gosto de pular a

271
00:09:18,959 --> 00:09:20,480
frente

272
00:09:20,480 --> 00:09:24,399
não, não, desculpe, ótima apresentação

273
00:09:24,399 --> 00:09:27,519
sim, muito obrigado e deixe-me

274
00:09:27,519 --> 00:09:32,000
rolar para baixo para um

275
00:09:32,000 --> 00:09:35,040
ok, então eu afirmei anteriormente que, com uma

276
00:09:35,040 --> 00:09:36,399
inferência ativa

277
00:09:36,399 --> 00:09:38,480
, estipula que os agentes estão

278
00:09:38,480 --> 00:09:40,320
mantendo sua

279
00:09:40,320 --> 00:09:42,080
homostase residindo em estados de atração que

280
00:09:42,080 --> 00:09:43,440
minimizam a surpresa,

281
00:09:43,440 --> 00:09:44,880
então você deve estar pensando  o que é

282
00:09:44,880 --> 00:09:46,560
surpresa bem

283
00:09:46,560 --> 00:09:48,800
como definimos surpresa como uma probabilidade logarítmica negativa

284
00:09:48,800 --> 00:09:50,080
de resultados

285
00:09:50,080 --> 00:09:52,080
e para isso introduzimos uma

286
00:09:52,080 --> 00:09:53,760
variável aleatória que é

287
00:09:53,760 --> 00:09:55,760
o que corresponde  ds para um determinado

288
00:09:55,760 --> 00:09:57,440
resultado que é recebido por um

289
00:09:57,440 --> 00:10:00,480
agente e este um existe dentro de um

290
00:10:00,480 --> 00:10:01,040
conjunto finito de

291
00:10:01,040 --> 00:10:03,600
todos os resultados possíveis e isso é o aqui

292
00:10:03,600 --> 00:10:04,560
então uma

293
00:10:04,560 --> 00:10:06,720
primeira equação que temos apenas um

294
00:10:06,720 --> 00:10:08,160
afirma formalmente que fora

295
00:10:08,160 --> 00:10:10,240
e aqui p denota a

296
00:10:10,240 --> 00:10:11,680
distribuição de probabilidade sobre os

297
00:10:11,680 --> 00:10:14,239
resultados

298
00:10:15,839 --> 00:10:19,920
um ok  então, na inferência ativa, a maneira como

299
00:10:19,920 --> 00:10:21,200
o agente realmente

300
00:10:21,200 --> 00:10:23,200
minimizará essa quantidade surpresa que

301
00:10:23,200 --> 00:10:24,959
acabamos de ver é mantendo um

302
00:10:24,959 --> 00:10:27,120
modelo de gênero do mundo,

303
00:10:27,120 --> 00:10:29,360
e isso é importante porque

304
00:10:29,360 --> 00:10:31,040
em qualquer momento o agente não

305
00:10:31,040 --> 00:10:32,640
necessariamente teria acesso

306
00:10:32,640 --> 00:10:34,000
ao  medições verdadeiras do estado atual

307
00:10:34,000 --> 00:10:36,000
do mundo, então neste gráfico em particular

308
00:10:36,000 --> 00:10:37,600
que você vê aqui

309
00:10:37,600 --> 00:10:39,600
você tem o ambiente e o agente

310
00:10:39,600 --> 00:10:41,200
interagindo com o ambiente de uma

311
00:10:41,200 --> 00:10:42,320
maneira particular,

312
00:10:42,320 --> 00:10:44,480
ele está sendo exposto ao sinal sensorial,

313
00:10:44,480 --> 00:10:46,480
mas não sabe o que  o

314
00:10:46,480 --> 00:10:49,600
resultado do o foi regenerado por

315
00:10:49,600 --> 00:10:51,760
então ele só pode perceber a si mesmo e o

316
00:10:51,760 --> 00:10:52,959
mundo ao seu redor

317
00:10:52,959 --> 00:10:55,120
apenas através do o e precisa fazer

318
00:10:55,120 --> 00:10:57,279
inferências sobre que tipo  de estados

319
00:10:57,279 --> 00:11:00,959
ou as verdadeiras causas

320
00:11:00,959 --> 00:11:03,279
um foram responsáveis pela entra

321
00:11:03,279 --> 00:11:06,000
a sensorial particular a que está sendo exposto e é 

322
00:11:06,000 --> 00:11:08,959
or isso que em inferência ativa quand

323
00:11:08,959 --> 00:11:10,240
formulamos o problema nós o formu

324
00:11:10,240 --> 00:11:11,839
amos como um proce

325
00:11:11,839 --> 00:11:13,519
so de decisão de markov parcialmente observável porqu

326
00:11:13,519 --> 00:11:16,560
um desta forma nós  são capazes de

327
00:11:16,560 --> 00:11:18,959
formular um modelo de gênero que define

328
00:11:18,959 --> 00:11:19,279
essa

329
00:11:19,279 --> 00:11:22,160
distribuição interna sobre os

330
00:11:22,160 --> 00:11:23,920
estados internos que o agente

331
00:11:23,920 --> 00:11:26,399
usaria para inferir o resultado

332
00:11:26,399 --> 00:11:27,920
para que ele não tenha acesso ao estado verdadeiro,

333
00:11:27,920 --> 00:11:28,399


334
00:11:28,399 --> 00:11:30,320
mas possa fazer hipóteses ou crenças

335
00:11:30,320 --> 00:11:32,000
sobre os estados que  poderia ter dado

336
00:11:32,000 --> 00:11:32,640


337
00:11:32,640 --> 00:11:35,519
origem a um sentido particular uh

338
00:11:35,519 --> 00:11:38,320
espaço de resultados que está sendo exposto a

339
00:11:38,320 --> 00:11:40,800
um e usando isso o agente fará

340
00:11:40,800 --> 00:11:43,600
inferências sobre o verdadeiro estado

341
00:11:43,600 --> 00:11:45,839
usando um processo de mapeamento reverso

342
00:11:45,839 --> 00:11:48,079
especificamente inversão do modelo bayesiano

343
00:11:48,079 --> 00:11:49,680
e para tornar isso um pouco mais

344
00:11:49,680 --> 00:11:52,000
concreto o que  você pode fazer é pensar

345
00:11:52,000 --> 00:11:55,680
nos estados ocultos como locais ou cores,

346
00:11:55,680 --> 00:11:58,240
por exemplo, e o espaço de observação ao

347
00:11:58,240 --> 00:12:00,079
qual o agente seria exposto seria

348
00:12:00,079 --> 00:12:00,560


349
00:12:00,560 --> 00:12:03,680
por exemplo, a velocidade do

350
00:12:03,680 --> 00:12:04,480
movimento

351
00:12:04,480 --> 00:12:07,440
ou uma recompensa em particular, ou como um

352
00:12:07,440 --> 00:12:10,959
rosto feliz que eles estão sendo expostos a

353
00:12:10,959 --> 00:12:14,720
um, ok, então se pensarmos sobre

354
00:12:14,720 --> 00:12:16,320
isso um pouco mais formalmente,

355
00:12:16,320 --> 00:12:19,920
qual é o modelo gentil, então,  um

356
00:12:19,920 --> 00:12:21,760
descrito antes de um cavalheiro é um

357
00:12:21,760 --> 00:12:23,040


358
00:12:23,040 --> 00:12:25,200
mdp parcialmente observável dentro desta formulação active and friends

359
00:12:25,200 --> 00:12:26,160


360
00:12:26,160 --> 00:12:29,040
que se baseia em uma configuração simplificada que

361
00:12:29,040 --> 00:12:30,639
estamos considerando aqui, onde temos apenas

362
00:12:30,639 --> 00:12:32,240
duas variáveis aleatórias, a pri

363
00:12:32,240 --> 00:12:35,120
eira é o que discutimos e a s

364
00:12:35,120 --> 00:12:36,320
gun

365
00:12:36,320 --> 00:12:39,680
a é  s onde s denota um uma

366
00:12:39,680 --> 00:12:41,839
variável aleatória representando estados ocultos ou latentes

367
00:12:41,839 --> 00:12:44,079
e eles existem dentro de um

368
00:12:44,079 --> 00:12:45,760
conjunto finito de todos

369
00:12:45,760 --> 00:12:47,519
os estados ocultos possíveis que é denotado por

370
00:12:47,519 --> 00:12:49,279
s maiúsculo aqui

371
00:12:49,279 --> 00:12:51,440
e esta probabilidade conjunta de

372
00:12:51,440 --> 00:12:52,399
superarmos o e

373
00:12:52,399 --> 00:12:54,880
s pode ser fatorada na função de verossimilhança

374
00:12:54,880 --> 00:12:55,440


375
00:12:55,440 --> 00:12:59,120
que é p de o dado s e então você

376
00:12:59,120 --> 00:13:01,360
tem o prior sobre os estados internos

377
00:13:01,360 --> 00:13:02,720
que é pss

378
00:13:02,720 --> 00:13:04,839
então isso lhe dá uma formulação muito boa

379
00:13:04,839 --> 00:13:06,240
hum

380
00:13:06,240 --> 00:13:09,519
que vamos usar em

381
00:13:09,519 --> 00:13:11,839
alguns próximos slides  e eu só

382
00:13:11,839 --> 00:13:12,720
queria perguntar

383
00:13:12,720 --> 00:13:14,480
se você consegue ver meu mouse quando eu

384
00:13:14,480 --> 00:13:15,920
realço ou quando eu

385
00:13:15,920 --> 00:13:20,079
ou não está lá eu posso vê-lo sim oh

386
00:13:20,079 --> 00:13:22,719
sim perfeito

387
00:13:22,800 --> 00:13:24,560
então sabemos que para um agente minimizar

388
00:13:24,560 --> 00:13:25,600
sua surpresa precisaríamos

389
00:13:25,600 --> 00:13:27,360
marginalizar tudo  os possíveis

390
00:13:27,360 --> 00:13:29,040
estados ocultos que poderiam ter levado a um determinado

391
00:13:29,040 --> 00:13:29,760
resultado

392
00:13:29,760 --> 00:13:31,440
e isso pode ser alcançado usando a

393
00:13:31,440 --> 00:13:33,440
fatoração que acabei de mencionar a

394
00:13:33,440 --> 00:13:34,160
probabilidade

395
00:13:34,160 --> 00:13:37,360
e o anterior, mas

396
00:13:37,360 --> 00:13:40,320
o problema é que isso não é uma

397
00:13:40,320 --> 00:13:42,399
tarefa trivial porque a dimensionalidade

398
00:13:42,399 --> 00:13:43,519
do oculto  afirma que

399
00:13:43,519 --> 00:13:45,360
um pode ser extremamente grande e se você estiver

400
00:13:45,360 --> 00:13:47,120
considerando variáveis aleatórias adicionais que v

401
00:13:47,120 --> 00:13:48,480
mos intro

402
00:13:48,480 --> 00:13:50,240
uzir daqui a pouco, isso se torna ainda mais 

403
00:13:50,240 --> 00:13:51,600
roblemático e é 

404
00:13:51,600 --> 00:13:54,480
or isso que usamos uh outra quant

405
00:13:54,480 --> 00:13:56,240
dade uma aproximação variacional dessa

406
00:13:56,240 --> 00:13:57,199
quantidade uh p 

407
00:13:57,199 --> 00:13:59,920
e i que  é mais atraente e

408
00:13:59,920 --> 00:14:01,920
nos permite estimar as quantidades de

409
00:14:01,920 --> 00:14:05,839
interesse um

410
00:14:05,839 --> 00:14:08,720
então este será um passo natural para

411
00:14:08,720 --> 00:14:10,160
falar sobre a variação de energia livre

412
00:14:10,160 --> 00:14:11,760
que é essa aproximação variacional

413
00:14:11,760 --> 00:14:12,800
do qua  ntidade de

414
00:14:12,800 --> 00:14:15,519
interesse um então o que é

415
00:14:15,519 --> 00:14:17,199
energia livre variacional então a energia livre variacional é

416
00:14:17,199 --> 00:14:19,440
definida como o limite superior da surpresa

417
00:14:19,440 --> 00:14:20,560
então a primeira definição

418
00:14:20,560 --> 00:14:21,920
desculpe a primeira definição que nós

419
00:14:21,920 --> 00:14:24,240
consideramos é derivada usando a desigualdade de Jensen

420
00:14:24,240 --> 00:14:25,519
e

421
00:14:25,519 --> 00:14:27,600
é comumente conhecida como evidência negativa

422
00:14:27,600 --> 00:14:29,760
limite inferior na inferência variacional

423
00:14:29,760 --> 00:14:32,480
literatura, então obtemos isso da

424
00:14:32,480 --> 00:14:34,240
equação 4 que acabamos de

425
00:14:34,240 --> 00:14:37,199
ver introduzindo log negativo em ambos os

426
00:14:37,199 --> 00:14:37,760
lados

427
00:14:37,760 --> 00:14:41,040
e então um multiplicando este termo

428
00:14:41,040 --> 00:14:43,680
por 1 que é essencialmente q de s sobre q

429
00:14:43,680 --> 00:14:45,360
de s então estamos assumindo que

430
00:14:45,360 --> 00:14:48,560
q de s não pode ser igual  para zero e

431
00:14:48,560 --> 00:14:51,199
com isso um aplicamos a desigualdade de jensen

432
00:14:51,199 --> 00:14:53,199
e movemos o log para dentro

433
00:14:53,199 --> 00:14:54,000
da função

434
00:14:54,000 --> 00:14:56,560
e acabamos com nossa expectativa em

435
00:14:56,560 --> 00:14:58,000
relação a t de s

436
00:14:58,000 --> 00:15:00,079
para log da junta sobre a

437
00:15:00,079 --> 00:15:01,920


438
00:15:01,920 --> 00:15:05,040
quantidade aproximada ou variacional uh de interesse aqui e então

439
00:15:05,040 --> 00:15:07,120
pegamos o negativo para dentro e podemos invertê-

440
00:15:07,120 --> 00:15:07,839
lo

441
00:15:07,839 --> 00:15:11,120
e obtemos nossa primeira

442
00:15:11,120 --> 00:15:14,160
boa quantidade de interesse aqui, onde obtemos

443
00:15:14,160 --> 00:15:14,560


444
00:15:14,560 --> 00:15:17,199
o limite em que estamos interessados

445
00:15:17,199 --> 00:15:17,600
e

446
00:15:17,600 --> 00:15:20,720
mos  da cauda entre o aproximado

447
00:15:20,720 --> 00:15:24,240
e o conjunto que

448
00:15:24,480 --> 00:15:25,920
temos para tornar isso um pouco mais

449
00:15:25,920 --> 00:15:27,760
concreto o que podemos fazer agora é

450
00:15:27,760 --> 00:15:29,279
manipular ainda mais a energia livre variacional

451
00:15:29,279 --> 00:15:29,759


452
00:15:29,759 --> 00:15:34,959
convoca um para o matar entre o

453
00:15:34,959 --> 00:15:38,720
aproximado e o verdadeiro posterior

454
00:15:38,720 --> 00:15:41,360
menos o log  evidência de que nós a

455
00:15:41,360 --> 00:15:43,120
evidência do modelo que tínhamos

456
00:15:43,120 --> 00:15:45,920
e podemos reorganizar a última equação

457
00:15:45,920 --> 00:15:47,519
para realmente aprimorar a conexão

458
00:15:47,519 --> 00:15:48,959
entre

459
00:15:48,959 --> 00:15:51,759
surpresa e energia livre variacional um

460
00:15:51,759 --> 00:15:52,320
então

461
00:15:52,320 --> 00:15:55,040
se você se lembrar que kl é uma divergência o

462
00:15:55,040 --> 00:15:56,720
que significa que não pode ser menor que

463
00:15:56,720 --> 00:15:58,079
zero então

464
00:15:58,079 --> 00:16:01,519
hum é sempre estritamente uh maior

465
00:16:01,519 --> 00:16:03,440
ou igual a zero o que significa que

466
00:16:03,440 --> 00:16:06,399
quando a nossa aproximação é igual ao

467
00:16:06,399 --> 00:16:07,519
verdadeiro posterior

468
00:16:07,519 --> 00:16:09,600
acabamos com a variação de energia livre

469
00:16:09,600 --> 00:16:10,720
igual à evidência do modelo o

470
00:16:10,720 --> 00:16:13,839
que significa que minimizar a

471
00:16:13,839 --> 00:16:15,839
energia livre é essencialmente equivalente a

472
00:16:15,839 --> 00:16:18,320
maximizar o modelo de género  evidência

473
00:16:18,320 --> 00:16:23,839
hum ok

474
00:16:25,279 --> 00:16:28,240
hum podemos reescrever a equação anterior

475
00:16:28,240 --> 00:16:29,600
que tínhamos

476
00:16:29,600 --> 00:16:31,680
uma equação 10 para expressar a

477
00:16:31,680 --> 00:16:33,040
energia livre variacional

478
00:16:33,040 --> 00:16:34,800
em função de po  crenças interiores em

479
00:16:34,800 --> 00:16:36,079
várias formas diferentes,

480
00:16:36,079 --> 00:16:37,680
então vou me concentrar na equação

481
00:16:37,680 --> 00:16:40,000
12 aqui, que é a complexidade

482
00:16:40,000 --> 00:16:42,800
menos a precisão, então essa é uma troca uh

483
00:16:42,800 --> 00:16:45,440
que normalmente é usada quando

484
00:16:45,440 --> 00:16:48,839
os artigos que dizem essencialmente a

485
00:16:48,839 --> 00:16:50,160
complexidade tam

486
00:16:50,160 --> 00:16:53,600
ou custo de complexidade são essencialmente  um a

487
00:16:53,600 --> 00:16:57,120
sua couve entre o seu aproximado um

488
00:16:57,120 --> 00:17:01,120
de s dado pi em relação a

489
00:17:01,120 --> 00:17:05,199
uh seu p de s dado um pi e aqui pi

490
00:17:05,199 --> 00:17:07,280
são apenas suas apólices e estas podem ser

491
00:17:07,280 --> 00:17:09,280
independentemente da hipótese de

492
00:17:09,280 --> 00:17:12,319
como uh o agente vai agir

493
00:17:12,319 --> 00:17:14,079
mas eu vou  de volta ao que as políticas

494
00:17:14,079 --> 00:17:15,679
realmente implicam, mas por enquanto

495
00:17:15,679 --> 00:17:17,599
apenas considere-as como um termo que

496
00:17:17,599 --> 00:17:19,919
nos permite condicionar a energia livre

497
00:17:19,919 --> 00:17:22,319
em uma sequência de trajetórias de

498
00:17:22,319 --> 00:17:23,679
interesse

499
00:17:23,679 --> 00:17:26,319
e o segundo termo que temos é a

500
00:17:26,319 --> 00:17:27,599
probabilidade logarítmica

501
00:17:27,599 --> 00:17:31,200
de o dado s então a probabilidade uh

502
00:17:31,200 --> 00:17:34,559
com  a em relação à chave de s

503
00:17:34,559 --> 00:17:37,200
que lhe dá a precisão, então uma

504
00:17:37,200 --> 00:17:39,120
maneira simples de pensar sobre isso é que

505
00:17:39,120 --> 00:17:42,240
isso é apenas um quão preciso é o

506
00:17:42,240 --> 00:17:43,440
modelo e este é algum

507
00:17:43,440 --> 00:17:45,919
termo de regularização que é um

508
00:17:45,919 --> 00:17:47,200
termo de penalidade para fazer s  Certifique-se de que não está

509
00:17:47,200 --> 00:17:49,280
divergindo muito longe de nossas

510
00:17:49,280 --> 00:17:52,320
prioridades iniciais

511
00:17:52,320 --> 00:17:55,679
ok então esta quantidade particular de

512
00:17:55,679 --> 00:17:56,960
energia livre variacional

513
00:17:56,960 --> 00:17:58,480
há alguma dúvida neste momento

514
00:17:58,480 --> 00:18:01,039
sobre a variação de energia

515
00:18:01,039 --> 00:18:03,760
ainda não obrigado ok perfeito ok então

516
00:18:03,760 --> 00:18:05,360
a variação de energia está nos dando

517
00:18:05,360 --> 00:18:07,360
esta maneira de  percebendo o ambiente

518
00:18:07,360 --> 00:18:09,200
e aborda uma parte da

519
00:18:09,200 --> 00:18:11,039
formulação de influência ativa que está fazendo

520
00:18:11,039 --> 00:18:11,760
inferências

521
00:18:11,760 --> 00:18:14,240
sobre o mundo dado com o qual o agente está

522
00:18:14,240 --> 00:18:16,080
interagindo em um determinado ponto no

523
00:18:16,080 --> 00:18:16,880
tempo,

524
00:18:16,880 --> 00:18:19,440
no entanto, não consideramos

525
00:18:19,440 --> 00:18:20,320
a

526
00:18:20,320 --> 00:18:22,960
parte ativa, enquanto que, como esse agente específico

527
00:18:22,960 --> 00:18:23,600


528
00:18:23,600 --> 00:18:25,679
que temos  sob a

529
00:18:25,679 --> 00:18:26,880
formulação de inferência ativa podemos

530
00:18:26,880 --> 00:18:29,520
tomar uma série de ações ou interagir com

531
00:18:29,520 --> 00:18:31,360
o ambiente de tal forma que

532
00:18:31,360 --> 00:18:34,240
afete esse ambiente no futuro

533
00:18:34,240 --> 00:18:34,960


534
00:18:34,960 --> 00:18:37,280
um para motivar isso um pouco mais

535
00:18:37,280 --> 00:18:38,880
o que podemos pensar é que não só

536
00:18:38,880 --> 00:18:40,480
queremos minimizar  nossa variação de

537
00:18:40,480 --> 00:18:42,240
energia livre também queremos minimizar uma

538
00:18:42,240 --> 00:18:44,320
quantidade chamada energia livre esperada

539
00:18:44,320 --> 00:18:46,320
que depende da previsão

540
00:18:46,320 --> 00:18:48,240
observações sobre o futuro

541
00:18:48,240 --> 00:18:50,799
no futuro ou sobre o futuro e a

542
00:18:50,799 --> 00:18:52,080
minimização desses

543
00:18:52,080 --> 00:18:54,480
termos particulares permite que o agente

544
00:18:54,480 --> 00:18:56,400
influencie o futuro tomando

545
00:18:56,400 --> 00:18:58,400
ações específicas no presente

546
00:18:58,400 --> 00:19:00,080
que são selecionadas de um conjunto de

547
00:19:00,080 --> 00:19:02,720
políticas, então eu mencionei políticas algumas

548
00:19:02,720 --> 00:19:03,520
vezes agora,

549
00:19:03,520 --> 00:19:06,960
então o que são  elas podem ser

550
00:19:06,960 --> 00:19:09,280
definidas como uma sequência de ações no tempo

551
00:19:09,280 --> 00:19:10,240
tau

552
00:19:10,240 --> 00:19:12,240
que permitem que um agente faça a transição

553
00:19:12,240 --> 00:19:13,760
entre estados ocultos

554
00:19:13,760 --> 00:19:17,520
e tau aqui é essencialmente como uma

555
00:19:17,520 --> 00:19:19,120
sequência de trajetórias até um

556
00:19:19,120 --> 00:19:21,039
determinado horizonte

557
00:19:21,039 --> 00:19:24,320
uh cap que é um considerando o

558
00:19:24,320 --> 00:19:25,679
número total de

559
00:19:25,679 --> 00:19:27,760
tempo  etapas que você está considerando em uma

560
00:19:27,760 --> 00:19:29,280
configuração específica

561
00:19:29,280 --> 00:19:32,320
e para definirmos adequadamente a

562
00:19:32,320 --> 00:19:33,919
política de uh, precisamos introduzir duas

563
00:19:33,919 --> 00:19:35,440
variáveis aleatórias adicionais para 

564
00:19:35,440 --> 00:19:38,160
ue a primeira seja uma ação condi

565
00:19:38,160 --> 00:19:38,960
ionada a tau

566
00:19:38,960 --> 00:19:43,039
que é denotada por utau aqui e iss

567
00:19:43,039 --> 00:19:46,160
existe dentro de um conjunto finit

568
00:19:46,160 --> 00:19:48,320
de  todas as ações possíveis que os agentes podem

569
00:19:48,320 --> 00:19:49,200
realizar

570
00:19:49,200 --> 00:19:50,960
e a segunda variável aleatória que

571
00:19:50,960 --> 00:19:52,640
introduzimos é uh

572
00:19:52,640 --> 00:19:54,559
policy, que é o pi que

573
00:19:54,559 --> 00:19:55,919
discutimos  ssed

574
00:19:55,919 --> 00:19:58,000
e isso existe dentro de um conjunto finito de

575
00:19:58,000 --> 00:19:58,960
todas as

576
00:19:58,960 --> 00:20:02,000
políticas uh possíveis um ou uma sequência de ações

577
00:20:02,000 --> 00:20:04,640
em um sentido como a

578
00:20:04,640 --> 00:20:06,240
otimização de política sequencial que nos interessa

579
00:20:06,240 --> 00:20:08,240
aqui, para torná-la um pouco mais

580
00:20:08,240 --> 00:20:09,520
concreta

581
00:20:09,520 --> 00:20:11,200
, a variável aleatória pode ser

582
00:20:11,200 --> 00:20:13,440
decomposto em

583
00:20:13,440 --> 00:20:16,559
uma série de ações em um determinado

584
00:20:16,559 --> 00:20:19,760
horizonte de tempo tau

585
00:20:19,760 --> 00:20:23,280
então u1 u2 e um indo até utah

586
00:20:23,280 --> 00:20:25,120
denotariam a ação de

587
00:20:25,120 --> 00:20:26,960
uh ação no ponto de tempo um ação do

588
00:20:26,960 --> 00:20:28,799
ponto de tempo dois e assim por diante

589
00:20:28,799 --> 00:20:31,360
e o link é explícito quando você

590
00:20:31,360 --> 00:20:32,320
considera que

591
00:20:32,320 --> 00:20:35,679
se você considerar uma política em um determinado

592
00:20:35,679 --> 00:20:38,880
momento tão tau, então a ação que

593
00:20:38,880 --> 00:20:41,840
você obtém seria essa ação

594
00:20:41,840 --> 00:20:45,280
ok legal, então

595
00:20:45,280 --> 00:20:47,360
eu também queria destacar que essa

596
00:20:47,360 --> 00:20:49,120
definição de política é realmente bem

597
00:20:49,120 --> 00:20:50,559
diferente

598
00:20:50,559 --> 00:20:53,520
ou distinta de como ela é considerada em rl,

599
00:20:53,520 --> 00:20:54,240
que  é

600
00:20:54,240 --> 00:20:56,640
um quando dizem que política significa

601
00:20:56,640 --> 00:20:58,000
políticas de ação do estado,

602
00:20:58,000 --> 00:20:59,840
então, como acabei de mencionar, um ato de

603
00:20:59,840 --> 00:21:02,240
inferência, uma política é simplesmente uma sequência

604
00:21:02,240 --> 00:21:04,159
de escolhas de ações ao longo do tempo, que

605
00:21:04,159 --> 00:21:06,159
é uma política sequencial

606
00:21:06,159 --> 00:21:08,320
e  isso é diferente de uma política de ação de estado

607
00:21:08,320 --> 00:21:10,400
no aprendizado de reforço que

608
00:21:10,400 --> 00:21:12,080
é o mapeamento de estados para

609
00:21:12,080 --> 00:21:16,080
ações, então sua política de rl que leva em

610
00:21:16,080 --> 00:21:16,720
conta

611
00:21:16,720 --> 00:21:19,919
a ação e o estado é a probabilidade

612
00:21:19,919 --> 00:21:20,799
de sua

613
00:21:20,799 --> 00:21:24,159
ação dado o estado e sob

614
00:21:24,159 --> 00:21:27,919
nossa formulação de mdp

615
00:21:27,919 --> 00:21:30,159
a definição de ação oh  desculpe a

616
00:21:30,159 --> 00:21:31,760
definição de políticas em

617
00:21:31,760 --> 00:21:33,760
rl e a inferência ativa se tornam exatamente

618
00:21:33,760 --> 00:21:35,679
as mesmas quando consideramos a configuração em

619
00:21:35,679 --> 00:21:37,679
que tau é igual a um, então você está

620
00:21:37,679 --> 00:21:41,120
considerando apenas um passo à frente,

621
00:21:41,120 --> 00:21:45,120
ok, então, vou me mover um

622
00:21:45,120 --> 00:21:45,760
pouco

623
00:21:45,760 --> 00:21:49,039
e considerar uh o

624
00:21:49,039 --> 00:21:50,960
interesse quantitativo eles esperavam energia livre, que

625
00:21:50,960 --> 00:21:54,080
é como podemos derivá-la, então,

626
00:21:54,080 --> 00:21:56,240
para deduzi-la, primeiro precisamos estender

627
00:21:56,240 --> 00:21:57,840
a definição de energia livre variacional

628
00:21:57,840 --> 00:22:00,000
que tínhamos antes

629
00:22:00,000 --> 00:22:02,240
há alguns slides atrás e agora torná-la

630
00:22:02,240 --> 00:22:03,360
dependente do

631
00:22:03,360 --> 00:22:06,799
tempo tão tau quanto  política e o que estamos

632
00:22:06,799 --> 00:22:07,919
fazendo essencialmente

633
00:22:07,919 --> 00:22:10,320
é pegar essa mesma equação e apenas

634
00:22:10,320 --> 00:22:12,320
decompô-la para a

635
00:22:12,320 --> 00:22:14,320
etapa de tempo anterior e atual

636
00:22:14,320 --> 00:22:16,080
em uma política específica, dessa forma,

637
00:22:16,080 --> 00:22:18,080
é por isso que temos o condicionamento e

638
00:22:18,080 --> 00:22:20,480
então estamos decompondo-o de uma

639
00:22:20,480 --> 00:22:23,520
maneira específica hum na equação 15

640
00:22:23,520 --> 00:22:25,039
e depois escrevendo a formulação da matriz

641
00:22:25,039 --> 00:22:27,360
na equação 16.

642
00:22:27,360 --> 00:22:28,960
para que possamos voltar a isso se houver

643
00:22:28,960 --> 00:22:31,039
alguma dúvida,

644
00:22:31,039 --> 00:22:32,880
mas a chave a ser tomada  fora do

645
00:22:32,880 --> 00:22:35,039
slide é que agora estamos incluindo uma

646
00:22:35,039 --> 00:22:37,120
dependência funcional no tempo

647
00:22:37,120 --> 00:22:40,799
hum para a variação da energia hum

648
00:22:40,799 --> 00:22:42,799
e isso está nos permitindo agora passar para

649
00:22:42,799 --> 00:22:45,120
a formulação de energia livre esperada

650
00:22:45,120 --> 00:22:47,280
hum, mas o principal a notar aqui é

651
00:22:47,280 --> 00:22:49,360
que estamos  considerando apenas pontos de tempo

652
00:22:49,360 --> 00:22:52,320
um o ponto de tempo anterior e o

653
00:22:52,320 --> 00:22:52,799
presente

654
00:22:52,799 --> 00:22:55,840
não o futuro

655
00:22:58,000 --> 00:23:00,320
então usando a equação da energia livre antes de

656
00:23:00,320 --> 00:23:01,440
podermos derivar

657
00:23:01,440 --> 00:23:04,559
uh a energia livre esperada um

658
00:23:04,559 --> 00:23:06,720
e qual é a

659
00:23:06,720 --> 00:23:08,320
energia livre esperada então então a energia livre esperada

660
00:23:08,320 --> 00:23:11,200
é a energia livre  função de trajetórias futuras

661
00:23:11,200 --> 00:23:12,159


662
00:23:12,159 --> 00:23:14,559
g e efetivamente valoriza as evidências

663
00:23:14,559 --> 00:23:16,400
de políticas plausíveis

664
00:23:16,400 --> 00:23:18,240
baseadas em resultados que ainda não foram

665
00:23:18,240 --> 00:23:19,760
observados, então isso é o principal, então

666
00:23:19,760 --> 00:23:20,640
você está fazendo

667
00:23:20,640 --> 00:23:24,240
inferências sobre as pesquisas, o conjunto de

668
00:23:24,240 --> 00:23:26,000
trajetórias futuras que você não

669
00:23:26,000 --> 00:23:28,000
observou um

670
00:23:28,000 --> 00:23:30,640
e há duas heurísticas que são

671
00:23:30,640 --> 00:23:31,679
introduzidas

672
00:23:31,679 --> 00:23:34,159
aqui para chegar à formulação g

673
00:23:34,159 --> 00:23:35,120
que vemos

674
00:23:35,120 --> 00:23:38,960
na equação 17. a

675
00:23:38,960 --> 00:23:41,440
primeira é incluir crenças sobre resultados futuros

676
00:23:41,440 --> 00:23:42,320


677
00:23:42,320 --> 00:23:44,159
na expectativa que é nós'  está

678
00:23:44,159 --> 00:23:46,000
suplementando a expectativa

679
00:23:46,000 --> 00:23:48,159
sob o posterior aproximado com a

680
00:23:48,159 --> 00:23:50,000
probabilidade aqui

681
00:23:50,000 --> 00:23:51,440
que resulta em uma

682
00:23:51,440 --> 00:23:53,279
distribuição preditiva dada por esses dois primeiros

683
00:23:53,279 --> 00:23:54,880
termos aqui

684
00:23:54,880 --> 00:23:57,600
e o segundo é que estamos

685
00:23:57,600 --> 00:23:58,559
implicitamente

686
00:23:58,559 --> 00:24:00,799
ou acho que explicitamente condicionando as

687
00:24:00,799 --> 00:24:02,799
probabilidades conjuntas de estados

688
00:24:02,799 --> 00:24:06,080
e observações no gênero  modelo,

689
00:24:06,080 --> 00:24:08,960
desculpe, o modelo de gênero depende

690
00:24:08,960 --> 00:24:10,159


691
00:24:10,159 --> 00:24:13,200
do estado de coisas desejado, em oposição

692
00:24:13,200 --> 00:24:14,880
a uma política específica agora, então isso

693
00:24:14,880 --> 00:24:16,799
restringe o tipo de preferências que

694
00:24:16,799 --> 00:24:17,440
o agente

695
00:24:17,440 --> 00:24:20,640
teria e o que é útil com esses

696
00:24:20,640 --> 00:24:21,200
dois

697
00:24:21,200 --> 00:24:22,720
movimentos que estamos fazendo é que podemos

698
00:24:22,720 --> 00:24:24,480
agora avalie essa quantidade

699
00:24:24,480 --> 00:24:27,200
antes de realmente ter as observações

700
00:24:27,200 --> 00:24:28,240
e a segunda

701
00:24:28,240 --> 00:24:30,400
é que a minimização de g

702
00:24:30,400 --> 00:24:32,080
realmente encou  as políticas de raiva

703
00:24:32,080 --> 00:24:35,440
para serem consistentes com o

704
00:24:35,440 --> 00:24:37,520
estado de coisas desejado que o agente

705
00:24:37,520 --> 00:24:39,760
espera estar,

706
00:24:39,760 --> 00:24:41,600
vou apenas mencionar brevemente

707
00:24:41,600 --> 00:24:44,240
que esta não é a única maneira de obter a

708
00:24:44,240 --> 00:24:45,679
energia livre esperada e tem

709
00:24:45,679 --> 00:24:47,760
havido algum trabalho que foi observado  em outras

710
00:24:47,760 --> 00:24:48,960
formulações,

711
00:24:48,960 --> 00:24:52,240
uh, incluindo o trabalho de carl um, onde

712
00:24:52,240 --> 00:24:53,600
a formulação da energia livre esperada

713
00:24:53,600 --> 00:24:55,919
pode ser decomposta em diferentes

714
00:24:55,919 --> 00:24:58,799
estruturas, então, se alguém estiver

715
00:24:58,799 --> 00:25:02,480
interessado nisso, podemos passar por isso mais tarde,

716
00:25:02,640 --> 00:25:04,799
mas essa energia livre esperada energia livre

717
00:25:04,799 --> 00:25:05,679


718
00:25:05,679 --> 00:25:07,520
que acabei de introduzir pode ser  decomposto de

719
00:25:07,520 --> 00:25:10,320
certas maneiras um então as equações 20 e 21

720
00:25:10,320 --> 00:25:10,799
dão

721
00:25:10,799 --> 00:25:13,200
duas decomposições diferentes do

722
00:25:13,200 --> 00:25:14,960
primeiro sendo o epistêmico e o

723
00:25:14,960 --> 00:25:17,039
valor extrínseco e o

724
00:25:17,039 --> 00:25:18,960
segundo sendo o esperado e o

725
00:25:18,960 --> 00:25:22,320
uh custo e termo de ambiguidade então se

726
00:25:22,320 --> 00:25:23,360
considerarmos apenas o

727
00:25:23,360 --> 00:25:26,640
um a primeira equação  podemos dizer que, se

728
00:25:26,640 --> 00:25:28,080
estamos minimizando essa

729
00:25:28,080 --> 00:25:30,559
equação, estamos capturando esse imperativo para

730
00:25:30,559 --> 00:25:31,360
maximizar

731
00:25:31,360 --> 00:25:33,760
o ganho de informação que você teria

732
00:25:33,760 --> 00:25:35,679
ao observar  o ambiente

733
00:25:35,679 --> 00:25:38,880
um sobre estados ocultos particulares

734
00:25:38,880 --> 00:25:41,840
enquanto maximiza o valor esperado

735
00:25:41,840 --> 00:25:43,360
que é pontuado pelas

736
00:25:43,360 --> 00:25:45,520
preferências logarítmicas ou o valor extrínseco

737
00:25:45,520 --> 00:25:46,559
aqui, então

738
00:25:46,559 --> 00:25:48,159
esta formulação particular realmente

739
00:25:48,159 --> 00:25:50,320
nos dá um trade-off muito claro entre

740
00:25:50,320 --> 00:25:50,880
o

741
00:25:50,880 --> 00:25:53,200
um o primeiro componente que é o

742
00:25:53,200 --> 00:25:54,960
valor epistêmico que promove

743
00:25:54,960 --> 00:25:57,120
comportamento curioso, então é isso que você quer

744
00:25:57,120 --> 00:25:59,760
com a exploração incentivada à medida que o agente

745
00:25:59,760 --> 00:26:00,799
procura

746
00:26:00,799 --> 00:26:02,400
esses novos estados que minimizam a

747
00:26:02,400 --> 00:26:04,960
incerteza sobre o ambiente

748
00:26:04,960 --> 00:26:07,520
e o último bit é mais pragmático

749
00:26:07,520 --> 00:26:08,400
e incentiva o

750
00:26:08,400 --> 00:26:11,360
comportamento de exploração por meio desse

751
00:26:11,360 --> 00:26:13,360
entendimento do tipo de

752
00:26:13,360 --> 00:26:15,679
políticas que o agente faria

753
00:26:15,679 --> 00:26:16,720
prefiro chegar a

754
00:26:16,720 --> 00:26:18,960
um em outras palavras como esta

755
00:26:18,960 --> 00:26:20,480
formulação de energia livre esperada

756
00:26:20,480 --> 00:26:23,200
e que estamos vendo na equação 20 é

757
00:26:23,200 --> 00:26:24,559
essencialmente tratar a

758
00:26:24,559 --> 00:26:26,640
exploração e a exploração como duas

759
00:26:26,640 --> 00:26:28,240
maneiras diferentes de abordar o mesmo

760
00:26:28,240 --> 00:26:28,799


761
00:26:28,799 --> 00:26:31,440
problema, minimizando a incerteza mencionada

762
00:26:31,440 --> 00:26:34,720
no início da apresentação

763
00:26:34,720 --> 00:26:37,120
ok um  também podemos pensar na

764
00:26:37,120 --> 00:26:38,159
segunda equação

765
00:26:38,159 --> 00:26:41,279
aqui wh  ich está apenas nos oferecendo uma

766
00:26:41,279 --> 00:26:43,200
perspectiva alternativa sobre a

767
00:26:43,200 --> 00:26:45,360
frequência esperada livre que é um

768
00:26:45,360 --> 00:26:47,919
agente deseja minimizar a ambiguidade

769
00:26:47,919 --> 00:26:50,000
e o grau em que os resultados sob uma

770
00:26:50,000 --> 00:26:52,000
política particular se desviam das

771
00:26:52,000 --> 00:26:55,039
preferências anteriores, portanto, a ambiguidade aqui é

772
00:26:55,039 --> 00:26:56,880
a expectativa da

773
00:26:56,880 --> 00:26:58,880
entropia condicional ou a incerteza sobre

774
00:26:58,880 --> 00:27:01,600
os resultados sob a política actual

775
00:27:01,600 --> 00:27:02,799
neste cenário em particular, a

776
00:27:02,799 --> 00:27:04,559
baixa entropia sugeriria que os resultados

777
00:27:04,559 --> 00:27:06,240
são bastante salientes e exclusivamente

778
00:27:06,240 --> 00:27:08,320
informativos sobre os estados ocultos,

779
00:27:08,320 --> 00:27:10,320
por exemplo, as dicas visuais que

780
00:27:10,320 --> 00:27:11,760
poderá ver se a sala é realmente

781
00:27:11,760 --> 00:27:13,039
completamente difícil

782
00:27:13,039 --> 00:27:14,720
em comparação com se estiver bastante

783
00:27:14,720 --> 00:27:16,080
escuro  'não vai descobrir nada

784
00:27:16,080 --> 00:27:19,440
importante disso, além disso, o

785
00:27:19,440 --> 00:27:20,880
agente vai gostar de buscar resultados

786
00:27:20,880 --> 00:27:21,520
dependentes da política

787
00:27:21,520 --> 00:27:23,760
que se assemelhem aos seus resultados preferidos,

788
00:27:23,760 --> 00:27:25,039


789
00:27:25,039 --> 00:27:27,120
então é doado por c aqui e isso

790
00:27:27,120 --> 00:27:29,279
é alcançado quando os cuidados divergem

791
00:27:29,279 --> 00:27:31,039
entre os resultados previstos

792
00:27:31,039 --> 00:27:34,320
e os preferidos  é minimizado

793
00:27:34,320 --> 00:27:37,679
por uma política específica

794
00:27:37,679 --> 00:27:40,880
ok e essas crenças anteriores abo  mas

795
00:27:40,880 --> 00:27:41,520
os

796
00:27:41,520 --> 00:27:42,960
resultados futuros equipam o agente com

797
00:27:42,960 --> 00:27:44,960
um comportamento direcionado a objetivos

798
00:27:44,960 --> 00:27:46,960
que é uma das

799
00:27:46,960 --> 00:27:48,320
instâncias que eu acho que

800
00:27:48,320 --> 00:27:51,840
é realmente importante na influência ativa

801
00:27:51,840 --> 00:27:54,640
ok então assim que tivermos a

802
00:27:54,640 --> 00:27:56,240
energia livre esperada podemos derivar

803
00:27:56,240 --> 00:28:00,159
as políticas hum tanto

804
00:28:00,159 --> 00:28:02,240
e isso  é realizado derivando a

805
00:28:02,240 --> 00:28:04,080
probabilidade de qualquer política

806
00:28:04,080 --> 00:28:06,399
aplicando uma função soft max sobre a

807
00:28:06,399 --> 00:28:08,480
energia livre esperada

808
00:28:08,480 --> 00:28:09,919
e isso ilustra o

809
00:28:09,919 --> 00:28:11,760
comportamento auto-evidente da inferência ativa

810
00:28:11,760 --> 00:28:12,559


811
00:28:12,559 --> 00:28:14,559
porque qualquer tipo de política ou

812
00:28:14,559 --> 00:28:16,480
sequência de ação que resulta em menor

813
00:28:16,480 --> 00:28:18,240
energia livre esperada é mais  provavelmente

814
00:28:18,240 --> 00:28:21,520
e intuitivamente isso faria

815
00:28:21,520 --> 00:28:24,159
sentido porque a energia livre esperada

816
00:28:24,159 --> 00:28:25,039
está

817
00:28:25,039 --> 00:28:26,960
encapsulando todos os tipos de coisas

818
00:28:26,960 --> 00:28:28,640
que você deseja incluir

819
00:28:28,640 --> 00:28:30,399
ou considerar quando está interagindo com

820
00:28:30,399 --> 00:28:31,600
o mundo, então você deseja explorar,

821
00:28:31,600 --> 00:28:32,960
deseja explorar, mas deseja  tenha

822
00:28:32,960 --> 00:28:36,000
um equilíbrio disso e

823
00:28:36,000 --> 00:28:38,159
quando você estiver selecionando sua apólice

824
00:28:38,159 --> 00:28:39,600
, é apenas uma questão de determinar o

825
00:28:39,600 --> 00:28:40,159
conjunto de

826
00:28:40,159 --> 00:28:42,960
ações que o aproximam disso

827
00:28:42,960 --> 00:28:44,000


828
00:28:44,000 --> 00:28:45,760
um núcleo particular um e isso pode ser definido por um

829
00:28:45,760 --> 00:28:48,960
estado atraente que é definido por sua

830
00:28:48,960 --> 00:28:52,480
matriz c que

831
00:28:52,480 --> 00:28:55,200
descrevemos antes e se você não

832
00:28:55,200 --> 00:28:56,159
tiver

833
00:28:56,159 --> 00:28:57,919
isso, é apenas uma exploração aleatória que você

834
00:28:57,919 --> 00:28:59,600
obteria

835
00:28:59,600 --> 00:29:01,600
às vezes você também pode incluir um

836
00:29:01,600 --> 00:29:03,760
parâmetro de temperatura beta  aqui

837
00:29:03,760 --> 00:29:06,080
hum e tendo um hyper prime nisto

838
00:29:06,080 --> 00:29:07,520
você introduz um

839
00:29:07,520 --> 00:29:09,440
custo de complexidade adicional na formulação

840
00:29:09,440 --> 00:29:10,799
esperada de energia livre

841
00:29:10,799 --> 00:29:14,720
uh que lhe permite

842
00:29:14,720 --> 00:29:17,840
explicar o quão plano

843
00:29:17,840 --> 00:29:20,880
ou quão

844
00:29:20,880 --> 00:29:23,279
confiante ou preciso você deseja que suas

845
00:29:23,279 --> 00:29:24,159


846
00:29:24,159 --> 00:29:27,919
preferências sejam sobre o espaço de políticas

847
00:29:27,919 --> 00:29:31,279
hum a chave  uma coisa a notar é que,

848
00:29:31,279 --> 00:29:33,039
por uma questão de simplicidade, não

849
00:29:33,039 --> 00:29:34,880
vou passar por

850
00:29:34,880 --> 00:29:37,200
muitos detalhes sobre como eles são

851
00:29:37,200 --> 00:29:37,919
otimizados,

852
00:29:37,919 --> 00:29:40,159
mas você pode fazer isso de várias

853
00:29:40,159 --> 00:29:41,919
maneiras diferentes, por exemplo, na inferência ativa

854
00:29:41,919 --> 00:29:42,720


855
00:29:42,720 --> 00:29:45,039
, podemos otimizar a expectativa sobre o

856
00:29:45,039 --> 00:29:47,039
estados ocultos de interesse as políticas

857
00:29:47,039 --> 00:29:48,640
as precisões que são inferidas

858
00:29:48,640 --> 00:29:50,320
e então também podemos otimizar os parâmetros do

859
00:29:50,320 --> 00:29:51,679


860
00:29:51,679 --> 00:29:53,919
modelo através dos procedimentos de aprendizado

861
00:29:53,919 --> 00:29:54,960
envolvidos

862
00:29:54,960 --> 00:29:58,080
hum, mas isso difere dependendo

863
00:29:58,080 --> 00:30:00,000
da configuração que você está olhando, por exemplo,

864
00:30:00,000 --> 00:30:01,600
se você estiver usando a base de variação, você

865
00:30:01,600 --> 00:30:02,559
apenas

866
00:30:02,559 --> 00:30:04,799
iteraria essas funções ou

867
00:30:04,799 --> 00:30:06,559
funções objetivas até a convergência

868
00:30:06,559 --> 00:30:08,960
ou uma inferência ativa, você faz um

869
00:30:08,960 --> 00:30:10,080
gradiente

870
00:30:10,080 --> 00:30:12,000
ascendente para encontrar  as estatísticas suficientes de

871
00:30:12,000 --> 00:30:13,919
interesse novamente, isso depende

872
00:30:13,919 --> 00:30:15,840
exatamente de qual formulação e configuração

873
00:30:15,840 --> 00:30:18,080
você está olhando,

874
00:30:18,080 --> 00:30:20,240
mas o principal a notar aqui é

875
00:30:20,240 --> 00:30:21,679
que há

876
00:30:21,679 --> 00:30:23,760
três aspectos particulares para o

877
00:30:23,760 --> 00:30:25,360
algoritmo de inferência ativo que são úteis e

878
00:30:25,360 --> 00:30:26,159
podem ser

879
00:30:26,159 --> 00:30:28,960
retirados deste particular  uh

880
00:30:28,960 --> 00:30:29,679
framework

881
00:30:29,679 --> 00:30:32,799
e aplicado a uh outras configurações

882
00:30:32,799 --> 00:30:34,559
uh, então vou reiterar e

883
00:30:34,559 --> 00:30:36,080
resumi-las brevemente,

884
00:30:36,080 --> 00:30:38,000
então primeiro temos o modelo de gênero que é

885
00:30:38,000 --> 00:30:39,679
crucial, então para que um agente

886
00:30:39,679 --> 00:30:41,440
interaja e minimize sua surpresa, ele

887
00:30:41,440 --> 00:30:43,520
precisa de um modelo gentil do mundo

888
00:30:43,520 --> 00:30:46,880
e  isso é descrito como simplesmente não estou,

889
00:30:46,880 --> 00:30:48,640
não estou incluindo nenhum dos parâmetros do modelo

890
00:30:48,640 --> 00:30:50,240
aqui, mas você pode ter

891
00:30:50,240 --> 00:30:52,159
seus resultados, seus estados e suas

892
00:30:52,159 --> 00:30:53,679
políticas e

893
00:30:53,679 --> 00:30:56,960
isso  são decompostos em um

894
00:30:56,960 --> 00:30:59,120
sim desculpe há uma seta com os

895
00:30:59,120 --> 00:31:00,000
colchetes aqui mas

896
00:31:00,000 --> 00:31:03,120
estes são decompostos em

897
00:31:03,120 --> 00:31:04,720
sua probabilidade anterior e sua

898
00:31:04,720 --> 00:31:05,760
função de transição

899
00:31:05,760 --> 00:31:07,840
e então você define uma vez que você tenha este

900
00:31:07,840 --> 00:31:10,000
modelo genital o objetivo do agente

901
00:31:10,000 --> 00:31:11,519
é ajustar o modelo para amostrar

902
00:31:11,519 --> 00:31:13,360
observações para reduzir  o preço

903
00:31:13,360 --> 00:31:14,960
e isso é através

904
00:31:14,960 --> 00:31:17,279
da otimização de energia livre variacional, então esse

905
00:31:17,279 --> 00:31:19,120
trade-off específico que temos entre

906
00:31:19,120 --> 00:31:21,840
a complexidade e o custo de precisão e, em

907
00:31:21,840 --> 00:31:22,240
seguida,

908
00:31:22,240 --> 00:31:24,000
o segundo, desculpe, a última parte

909
00:31:24,000 --> 00:31:25,760
deste algoritmo é

910
00:31:25,760 --> 00:31:27,760
planejar, selecionar ações que minimizem a

911
00:31:27,760 --> 00:31:29,200
incerteza

912
00:31:29,200 --> 00:31:32,000
que hum isso  é a energia livre esperada

913
00:31:32,000 --> 00:31:33,760
e a maneira de fazer isso é tendo um

914
00:31:33,760 --> 00:31:34,480
soft max

915
00:31:34,480 --> 00:31:37,600
sobre esse uh g negativo de g a

916
00:31:37,600 --> 00:31:39,120
quantidade que temos aqui

917
00:31:39,120 --> 00:31:41,360
e, em seguida, amostrando isso para

918
00:31:41,360 --> 00:31:42,720
selecionar a próxima

919
00:31:42,720 --> 00:31:46,080
melhor ação das especificações, ok,

920
00:31:46,080 --> 00:31:49,600
então é uma rápida e  mergulhar profundamente em

921
00:31:49,600 --> 00:31:51,760
uma enorme quantidade de

922
00:31:51,760 --> 00:31:52,799
literatura de inferência ativa, mas eu só queria

923
00:31:52,799 --> 00:31:53,600
destacar que

924
00:31:53,600 --> 00:31:55,120
esses são os três ingredientes principais

925
00:31:55,120 --> 00:31:57,120
que, se você estiver interessado  na

926
00:31:57,120 --> 00:31:59,279
implementação desses algoritmos está

927
00:31:59,279 --> 00:32:01,440
bem, então agora vou mudar

928
00:32:01,440 --> 00:32:02,720
um pouco as marchas e fazer

929
00:32:02,720 --> 00:32:04,080
comparações com o

930
00:32:04,080 --> 00:32:07,679
aprendizado de reforço, então em nosso trabalho

931
00:32:07,679 --> 00:32:09,360
consideramos uma versão modificada do

932
00:32:09,360 --> 00:32:10,320


933
00:32:10,320 --> 00:32:12,880
ambiente de lago congelado de academias de IA aberta, então o

934
00:32:12,880 --> 00:32:14,720
lago congelado tem uma grade-  como uma estrutura

935
00:32:14,720 --> 00:32:17,120
com quatro remendos distintos por isso tem um

936
00:32:17,120 --> 00:32:18,399
ponto de partida que é

937
00:32:18,399 --> 00:32:22,000
s hum para que possamos vê-lo aqui desculpe

938
00:32:22,000 --> 00:32:22,799
mas é super

939
00:32:22,799 --> 00:32:25,679
pequeno então s está aqui e você tem a

940
00:32:25,679 --> 00:32:26,640


941
00:32:26,640 --> 00:32:29,600
superfície congelada que é f então de novo eu não

942
00:32:29,600 --> 00:32:31,120
acho  eu posso diferenciar porque eu estou

943
00:32:31,120 --> 00:32:32,399
apenas movendo minha boca

944
00:32:32,399 --> 00:32:36,080
hum estou ampliando eles podem ver isso

945
00:32:36,080 --> 00:32:38,080
perfeito então você tem o f congelado e

946
00:32:38,080 --> 00:32:39,760
então você tem o todo

947
00:32:39,760 --> 00:32:42,240
e então por último você tem o objetivo então g

948
00:32:42,240 --> 00:32:43,360
aqui

949
00:32:43,360 --> 00:32:45,760
onde o  primeiro b está localizado e todos os

950
00:32:45,760 --> 00:32:48,000
patches nesta configuração em particular

951
00:32:48,000 --> 00:32:50,320
são seguros exceto o hall onde se o

952
00:32:50,320 --> 00:32:51,279
agente for

953
00:32:51,279 --> 00:32:54,640
para h ele recebe uma recompensa negativa um

954
00:32:54,640 --> 00:32:57,039
o agente inicia cada episódio na

955
00:32:57,039 --> 00:32:57,679
primeira

956
00:32:57,679 --> 00:32:59,519
posição um que é a

957
00:32:59,519 --> 00:33:01,519
posição inicial e de lá ele precisa

958
00:33:01,519 --> 00:33:03,200
chegar ao f  isbee

959
00:33:03,200 --> 00:33:07,279
em um na menor quantidade de passos

960
00:33:07,279 --> 00:33:08,000
possível

961
00:33:08,000 --> 00:33:09,840
e a maneira que você pode fazer isso é

962
00:33:09,840 --> 00:33:11,679
executando uh quatro tipos diferentes de

963
00:33:11,679 --> 00:33:12,799
ações, então vá para a

964
00:33:12,799 --> 00:33:15,840
esquerda para baixo ou para cima e

965
00:33:15,840 --> 00:33:17,840
o agente pode continuar se movendo

966
00:33:17,840 --> 00:33:18,960
pelo lago congelado

967
00:33:18,960 --> 00:33:21,279
uh com  várias revisitas para que você possa

968
00:33:21,279 --> 00:33:22,720
voltar à posição inicial tendo

969
00:33:22,720 --> 00:33:24,480
como em outros lugares,

970
00:33:24,480 --> 00:33:26,960
mas cada episódio terminará quando

971
00:33:26,960 --> 00:33:27,919
chegar ao

972
00:33:27,919 --> 00:33:31,600
salão ou ao local da meta e

973
00:33:31,600 --> 00:33:34,000
esses locais diferem dependendo da

974
00:33:34,000 --> 00:33:35,120
configuração que

975
00:33:35,120 --> 00:33:38,320
teremos em nossas simulações, portanto

976
00:33:38,320 --> 00:33:40,720
,  um configurado um a posição do

977
00:33:40,720 --> 00:33:41,440
todo é

978
00:33:41,440 --> 00:33:43,840
oito e o objetivo é seis e outro

979
00:33:43,840 --> 00:33:45,679
configurado a posição do todo

980
00:33:45,679 --> 00:33:49,279
é seis e um

981
00:33:49,279 --> 00:33:51,919
o objetivo é oito e o objetivo é

982
00:33:51,919 --> 00:33:53,679
como eu disse atingir o objetivo

983
00:33:53,679 --> 00:33:56,000
idealmente em poucos passos  possível

984
00:33:56,000 --> 00:33:57,440
, evitando o todo, porque

985
00:33:57,440 --> 00:33:59,120
isso terminaria o episódio

986
00:33:59,120 --> 00:34:00,880
uh, se atingir a meta, obterá uma

987
00:34:00,880 --> 00:34:02,559
recompensa positiva de 100

988
00:34:02,559 --> 00:34:05,600
e negativa, caso contrário,

989
00:34:05,600 --> 00:34:07,840
o principal a notar aqui é que essa

990
00:34:07,840 --> 00:34:09,760
métrica de consulta realmente nos permite um wa  y para

991
00:34:09,760 --> 00:34:11,280
comparar os algoritmos de inferência ativos com os

992
00:34:11,280 --> 00:34:12,960
algoritmos de aprendizado de reforço

993
00:34:12,960 --> 00:34:14,879
, mas não é realmente

994
00:34:14,879 --> 00:34:16,639
importante para o algoritmo de inferência ativo

995
00:34:16,639 --> 00:34:18,839


996
00:34:18,839 --> 00:34:22,000
ter a função de recompensa como um começo,

997
00:34:22,000 --> 00:34:24,000
porque ele ainda pode se mover

998
00:34:24,000 --> 00:34:26,639
e usar apenas a guia do jogo de informações,

999
00:34:26,639 --> 00:34:28,879
para não ter o extrínseco  valor do

1000
00:34:28,879 --> 00:34:30,239
componente

1001
00:34:30,239 --> 00:34:33,199
hum e isso é bastante interessante

1002
00:34:33,199 --> 00:34:35,040
porque veremos as ramificações

1003
00:34:35,040 --> 00:34:36,960
disso em nossas assimilações

1004
00:34:36,960 --> 00:34:39,599
e para esta configuração em particular limitamos

1005
00:34:39,599 --> 00:34:41,040
o número máximo de passos de tempo para

1006
00:34:41,040 --> 00:34:42,320
cada episódio

1007
00:34:42,320 --> 00:34:45,679
a 15. ok,

1008
00:34:45,679 --> 00:34:47,918
então o que vou fazer é primeiro  fale

1009
00:34:47,918 --> 00:34:49,199
sobre o modelo genital que usamos

1010
00:34:49,199 --> 00:34:51,359
para a formulação de inferência ativa,

1011
00:34:51,359 --> 00:34:53,440
então aqui o que você está vendo no

1012
00:34:53,440 --> 00:34:55,359
slide é uma representação gráfica do

1013
00:34:55,359 --> 00:34:57,520
modelo ativo e por exemplo.

1014
00:34:57,520 --> 00:34:59,280


1015
00:34:59,280 --> 00:35:00,800


1016
00:35:00,800 --> 00:35:03,920


1017
00:35:03,920 --> 00:35:06,400
controlar a capacidade de transição

1018
00:35:06,400 --> 00:35:08,240
entre estados ocultos

1019
00:35:08,240 --> 00:35:11,359
uh fato de localização, por exemplo, se você

1020
00:35:11,359 --> 00:35:12,240
estiver na posição

1021
00:35:12,240 --> 00:35:14,960
um e fizer a ação certa,

1022
00:35:14,960 --> 00:35:15,760
você  eu acabo

1023
00:35:15,760 --> 00:35:20,000
na posição dois ou se você estiver na posição

1024
00:35:20,000 --> 00:35:22,480
cinco e você tomar uma ação para cima

1025
00:35:22,480 --> 00:35:24,240
você terminará na posição

1026
00:35:24,240 --> 00:35:27,920
dois também

1027
00:35:27,920 --> 00:35:30,560
neste cenário em particular ambas as

1028
00:35:30,560 --> 00:35:31,200
posições

1029
00:35:31,200 --> 00:35:33,040
seis e oito são estados absorventes

1030
00:35:33,040 --> 00:35:34,320
porque se você se lembrar

1031
00:35:34,320 --> 00:35:36,480
uma vez que o agente vai para esse local,

1032
00:35:36,480 --> 00:35:37,680
eles não podem

1033
00:35:37,680 --> 00:35:40,640
sair, então é quando o episódio termina

1034
00:35:40,640 --> 00:35:42,720
e se um agente fizer um movimento improvável

1035
00:35:42,720 --> 00:35:44,480
neste labirinto em particular, por exemplo, se

1036
00:35:44,480 --> 00:35:45,040
ele

1037
00:35:45,040 --> 00:35:47,200
tentar ir da posição um para a esquerda, ele

1038
00:35:47,200 --> 00:35:50,000
ficará  nesse local ele não se moverá

1039
00:35:50,000 --> 00:35:52,320
neste modelo de gênero específico, então

1040
00:35:52,320 --> 00:35:53,920
estou apenas olhando para os estados ocultos,

1041
00:35:53,920 --> 00:35:54,640
agora

1042
00:35:54,640 --> 00:35:56,960
temos um produto de transferência crônica

1043
00:35:56,960 --> 00:35:58,640
entre os dois fatores, portanto, temos

1044
00:35:58,640 --> 00:36:00,720
localização e contexto aqui,

1045
00:36:00,720 --> 00:36:03,359
o contexto não pode ser alterado por  o

1046
00:36:03,359 --> 00:36:04,000
agente

1047
00:36:04,000 --> 00:36:05,680
que temos um porque isso é

1048
00:36:05,680 --> 00:36:07,040
algo que é determinado pelo

1049
00:36:07,040 --> 00:36:08,160
ambiente e

1050
00:36:08,160 --> 00:36:10,079
isso determina onde está o objetivo de

1051
00:36:10,079 --> 00:36:12,800
todos os locais, enquanto o local

1052
00:36:12,800 --> 00:36:14,480
é algo sobre o qual o agente tem

1053
00:36:14,480 --> 00:36:16,160
controle e é aí que temos a ação

1054
00:36:16,160 --> 00:36:16,800
estados

1055
00:36:16,800 --> 00:36:20,720
sobre este um, então com o contexto temos

1056
00:36:20,720 --> 00:36:21,839
dois contextos

1057
00:36:21,839 --> 00:36:25,599
o primeiro é onde a meta está na

1058
00:36:25,599 --> 00:36:28,560
sua localização oito e os corredores na

1059
00:36:28,560 --> 00:36:29,839
localização seis

1060
00:36:29,839 --> 00:36:32,079
e o segundo contexto é onde a meta

1061
00:36:32,079 --> 00:36:33,280
está na localização

1062
00:36:33,280 --> 00:36:37,119
seis e o salão está na localização

1063
00:36:37,119 --> 00:36:41,119
oito  em cada ponto de tempo o agente

1064
00:36:41,119 --> 00:36:44,560
observará dois resultados, um seria sua

1065
00:36:44,560 --> 00:36:46,800
própria posição neste labirinto em particular

1066
00:36:46,800 --> 00:36:48,960
e o segundo seria a pontuação que

1067
00:36:48,960 --> 00:36:50,400
o agente obteria,

1068
00:36:50,400 --> 00:36:52,560
a probabilidade da posição da grade

1069
00:36:52,560 --> 00:36:54,720
ser inteiramente determinada pela localização

1070
00:36:54,720 --> 00:36:56,079
do agente

1071
00:36:56,079 --> 00:37:01,440
e  a pontuação um é determinada

1072
00:37:01,599 --> 00:37:03,920
pela localização e pelo contexto no

1073
00:37:03,920 --> 00:37:04,960
local, portanto,

1074
00:37:04,960 --> 00:37:08,960
se o agente estiver na localização seis

1075
00:37:08,960 --> 00:37:11,680
e estiver no contexto dois,

1076
00:37:11,680 --> 00:37:13,119
receberá uma recompensa positiva,

1077
00:37:13,119 --> 00:37:15,119
caso contrário, receberá uma

1078
00:37:15,119 --> 00:37:16,320
recompensa negativa ou mútua,

1079
00:37:16,320 --> 00:37:20,320
dependendo de onde estiver

1080
00:37:20,320 --> 00:37:22,640
com base na tentativa de fazer essa

1081
00:37:22,640 --> 00:37:24,079
comparação com o aprendizado de reforço,

1082
00:37:24,079 --> 00:37:25,839
o que estamos fazendo aqui

1083
00:37:25,839 --> 00:37:28,560
é introduzir as preferências principais

1084
00:37:28,560 --> 00:37:29,119
onde

1085
00:37:29,119 --> 00:37:32,640
o agente tem mais quatro para

1086
00:37:32,640 --> 00:37:36,320
uma recompensa positiva negativa  ativo quatro quatro

1087
00:37:36,320 --> 00:37:38,720
desculpe menos quatro para recompensa negativa e

1088
00:37:38,720 --> 00:37:39,760
caso contrário e

1089
00:37:39,760 --> 00:37:42,240
no primeiro estágio ele espera

1090
00:37:42,240 --> 00:37:43,839
estar no

1091
00:37:43,839 --> 00:37:46,880
primeiro local,

1092
00:37:47,440 --> 00:37:50,560
então comparamos um

1093
00:37:50,560 --> 00:37:52,480
modelo de gênero específico e o

1094
00:37:52,480 --> 00:37:53,760
agente de inferência ativo a

1095
00:37:53,760 --> 00:37:55,760
dois algoritmos de aprendizado por reforço, então

1096
00:37:55,760 --> 00:37:58,320
o primeiro foi o  q aprender usando a

1097
00:37:58,320 --> 00:38:00,400
exploração gananciosa epsilon

1098
00:38:00,400 --> 00:38:02,079
e o segundo foi o algoritmo de

1099
00:38:02,079 --> 00:38:03,839
aprendizado por reforço baseado em modelo bayesiano

1100
00:38:03,839 --> 00:38:05,599
usando amostragem thompson padrão

1101
00:38:05,599 --> 00:38:06,720


1102
00:38:06,720 --> 00:38:08,560
e amostragem thompson é um

1103
00:38:08,560 --> 00:38:10,320
procedimento apropriado aqui porque envolve a

1104
00:38:10,320 --> 00:38:12,560
otimização de objetivos duplos,

1105
00:38:12,560 --> 00:38:15,920
maximização de recompensa e ganho de informação

1106
00:38:15,920 --> 00:38:17,440
e isso é alcançado por ter essa

1107
00:38:17,440 --> 00:38:19,440
distribuição  sobre uma função particular

1108
00:38:19,440 --> 00:38:20,960
que nós primarizamos por

1109
00:38:20,960 --> 00:38:22,720
um a priori apenas por ter uma

1110
00:38:22,720 --> 00:38:26,879
distribuição a priori sobre ela que nós amostramos de

1111
00:38:27,119 --> 00:38:32,320
ok um

1112
00:38:32,320 --> 00:38:35,760
então para os dois algoritmos de alinhamento q

1113
00:38:35,760 --> 00:38:38,960
temos dois parâmetros gananciosos epsilon uh

1114
00:38:38,960 --> 00:38:41,680
então um onde é exploração fixa definida

1115
00:38:41,680 --> 00:38:42,880
para 0.1

1116
00:38:42,880 --> 00:38:44,240
e então  outro onde temos uma

1117
00:38:44,240 --> 00:38:46,400
exploração decadente que começa de

1118
00:38:46,400 --> 00:38:49,920
um  e decai para zero,

1119
00:38:50,880 --> 00:38:54,000
então primeiro avaliamos como os

1120
00:38:54,000 --> 00:38:55,440
agentes interagiam em um

1121
00:38:55,440 --> 00:38:56,320
ambiente estacionário onde a

1122
00:38:56,320 --> 00:38:58,960
recompensa não estava mudando, uh, de tal forma que o

1123
00:38:58,960 --> 00:39:00,800
local da meta era sempre às seis e

1124
00:39:00,800 --> 00:39:01,760
todo o local

1125
00:39:01,760 --> 00:39:04,240
sempre tinha essa idade e, em seguida, avaliamos o

1126
00:39:04,240 --> 00:39:06,000
desempenho dos agentes um o

1127
00:39:06,000 --> 00:39:07,599
principal a tirar daqui é que

1128
00:39:07,599 --> 00:39:08,240
tanto o

1129
00:39:08,240 --> 00:39:09,920
rl bayesiano quanto os

1130
00:39:09,920 --> 00:39:11,680
agentes de inferência ativos são capazes de

1131
00:39:11,680 --> 00:39:14,400
aprender rapidamente onde está o local da recompensa

1132
00:39:14,400 --> 00:39:16,720
e apenas maximizá-lo

1133
00:39:16,720 --> 00:39:19,119
e isso é um desempenho

1134
00:39:19,119 --> 00:39:21,119
consistente denotado  pelos

1135
00:39:21,119 --> 00:39:23,440
limites de confiança realmente apertados que vemos

1136
00:39:23,440 --> 00:39:26,960
em comparação, os agentes de aprendizado q são

1137
00:39:26,960 --> 00:39:30,480
um, então, para aquele em que temos

1138
00:39:30,480 --> 00:39:31,680


1139
00:39:31,680 --> 00:39:34,640
uh exploração fixa, é bastante bom e é capaz

1140
00:39:34,640 --> 00:39:36,240
de pousar onde a recompensa

1141
00:39:36,240 --> 00:39:38,480
está localizada, mas há algum

1142
00:39:38,480 --> 00:39:40,320
desvio indicado por  que

1143
00:39:40,320 --> 00:39:43,359
dez por cento de selecionar uma ação aleatória

1144
00:39:43,359 --> 00:39:46,320
um considerando q o aprendizado onde temos

1145
00:39:46,320 --> 00:39:48,640
epsilon é igual a um para ganhar a zero

1146
00:39:48,640 --> 00:39:51,440
um o desempenho não é o maior

1147
00:39:51,440 --> 00:39:53,119
e para o modelo nulo  a

1148
00:39:53,119 --> 00:39:55,520
inferência ativa onde não há recompensa aqui

1149
00:39:55,520 --> 00:39:57,680
o agente vai aleatoriamente para a sala e

1150
00:39:57,680 --> 00:39:59,040
vai aleatoriamente para o objetivo

1151
00:39:59,040 --> 00:40:02,560
50 vezes, mas o principal a notar

1152
00:40:02,560 --> 00:40:04,160
é que, além do não-modelo,

1153
00:40:04,160 --> 00:40:07,040
todos os modelos estão indo muito bem e

1154
00:40:07,040 --> 00:40:07,760
parecem  estar

1155
00:40:07,760 --> 00:40:09,760
funcionando bem dentro da

1156
00:40:09,760 --> 00:40:10,960
configuração estacionária,

1157
00:40:10,960 --> 00:40:12,720
então a próxima coisa que eu poderia

1158
00:40:12,720 --> 00:40:14,319
fazer sobre esses experimentos também

1159
00:40:14,319 --> 00:40:14,960
só porque

1160
00:40:14,960 --> 00:40:16,640
eles também se afastam um pouco

1161
00:40:16,640 --> 00:40:19,280
do rl tradicional, o

1162
00:40:19,280 --> 00:40:22,480
que é ótimo, então basicamente

1163
00:40:22,480 --> 00:40:24,000
como geralmente no ro, o que acontece é  você

1164
00:40:24,000 --> 00:40:25,760
meio que tem essa ambiguidade entre o

1165
00:40:25,760 --> 00:40:27,040
tempo de treinamento e o desempenho do tempo de teste

1166
00:40:27,040 --> 00:40:28,400
e geralmente especialmente

1167
00:40:28,400 --> 00:40:29,440
em algo como q aprendendo,

1168
00:40:29,440 --> 00:40:31,280
como você apenas atingiu o máximo na função q

1169
00:40:31,280 --> 00:40:32,640
ou tem uma política

1170
00:40:32,640 --> 00:40:34,800
que tenta fazer uma pesquisa sobre

1171
00:40:34,800 --> 00:40:35,680
a função q

1172
00:40:35,680 --> 00:40:39,440
e  leva esse máximo como dado um estado,

1173
00:40:39,440 --> 00:40:40,720
mas há uma espécie de

1174
00:40:40,720 --> 00:40:42,480
distinção artificial que é

1175
00:40:42,480 --> 00:40:44,960
como, obviamente, quando você está adquirindo dados,

1176
00:40:44,960 --> 00:40:45,920
está cometendo erros no

1177
00:40:45,920 --> 00:40:46,960
ambiente em que está intera  trabalhando com o

1178
00:40:46,960 --> 00:40:48,640
ambiente real, então, para

1179
00:40:48,640 --> 00:40:49,280
fazer essa

1180
00:40:49,280 --> 00:40:51,280
comparação justa entre aqui e a inferência ativa,

1181
00:40:51,280 --> 00:40:52,960
onde você realmente não tem

1182
00:40:52,960 --> 00:40:54,319
essa distinção entre o

1183
00:40:54,319 --> 00:40:55,760
tempo de treinamento e o tempo de teste, é tudo

1184
00:40:55,760 --> 00:40:58,240
apenas interação, essa é a razão

1185
00:40:58,240 --> 00:40:59,599
pela qual o agente de aprendizado q

1186
00:40:59,599 --> 00:41:01,520
especialmente  quando epsilon é fixado para dizer que

1187
00:41:01,520 --> 00:41:03,760
0,1 nunca atinge a política ideal,

1188
00:41:03,760 --> 00:41:04,720
simplesmente porque

1189
00:41:04,720 --> 00:41:07,040
também estamos com 0,1 de probabilidade de realizar uma

1190
00:41:07,040 --> 00:41:08,000
ação aleatória,

1191
00:41:08,000 --> 00:41:09,280
então não estamos fazendo essa distinção

1192
00:41:09,280 --> 00:41:11,359
como você faria às vezes com rl normal

1193
00:41:11,359 --> 00:41:11,839
entre

1194
00:41:11,839 --> 00:41:13,520
treinar e tempo de teste, estamos todos dizendo

1195
00:41:13,520 --> 00:41:14,960
treinar e testar alguns são basicamente a

1196
00:41:14,960 --> 00:41:15,520
mesma coisa

1197
00:41:15,520 --> 00:41:17,520
então no entanto você está escolhendo interagir

1198
00:41:17,520 --> 00:41:19,280
com o mundo é como você deve ser

1199
00:41:19,280 --> 00:41:20,000
avaliado

1200
00:41:20,000 --> 00:41:22,319
então é por isso que inicialmente olhando

1201
00:41:22,319 --> 00:41:23,359
para essas garotas você pode ficar tipo espera

1202
00:41:23,359 --> 00:41:24,880
como por que não está aprendendo a resolver isso

1203
00:41:24,880 --> 00:41:25,359
mas,

1204
00:41:25,359 --> 00:41:27,599
sim, isso é apenas para esclarecer algo,

1205
00:41:27,599 --> 00:41:28,800
se você estiver mais familiarizado, diga alguns dos

1206
00:41:28,800 --> 00:41:30,400


1207
00:41:30,400 --> 00:41:34,640
procedimentos experimentais dprl uh

1208
00:41:34,640 --> 00:41:38,640
perfeito obrigado ok

1209
00:41:38,640 --> 00:41:41,200
hum e então hum apenas fo  depois

1210
00:41:41,200 --> 00:41:41,920
disso,

1211
00:41:41,920 --> 00:41:43,520
mudamos um pouco o ambiente para

1212
00:41:43,520 --> 00:41:45,200
tornar um pouco mais difícil

1213
00:41:45,200 --> 00:41:46,480
ver se

1214
00:41:46,480 --> 00:41:48,480
os agentes bayesianos e de inferência ativos

1215
00:41:48,480 --> 00:41:49,839
podem ter problemas

1216
00:41:49,839 --> 00:41:52,240
quando começamos a mudar a realocação

1217
00:41:52,240 --> 00:41:53,680
após alguns

1218
00:41:53,680 --> 00:41:56,400
episódios, então especificamente trocamos o

1219
00:41:56,400 --> 00:41:58,079
objetivo  e toda a localização

1220
00:41:58,079 --> 00:42:01,119
em um no ponto 21

1221
00:42:01,119 --> 00:42:04,319
no tempo 121 141

1222
00:42:04,319 --> 00:42:08,319
251 e 451 para que você possa ver que

1223
00:42:08,319 --> 00:42:10,319
nestas figuras onde a linha as

1224
00:42:10,319 --> 00:42:12,000
linhas cinzas são mostradas para que esses

1225
00:42:12,000 --> 00:42:15,200
pontos sejam todos os locais invertidos, como a

1226
00:42:15,200 --> 00:42:16,720
configuração estacionária para o primeiro

1227
00:42:16,720 --> 00:42:19,440
20 tentativas todos os asiáticos parecem estar

1228
00:42:19,440 --> 00:42:20,000
fazendo

1229
00:42:20,000 --> 00:42:22,480
como você esperaria, então tanto o bayesian

1230
00:42:22,480 --> 00:42:24,240
rl quanto os agentes de inferência ativos estão

1231
00:42:24,240 --> 00:42:24,640
indo

1232
00:42:24,640 --> 00:42:27,760
razoavelmente bem uh o pouso q com

1233
00:42:27,760 --> 00:42:30,800
um o setor de exploração fixo 0.1 está

1234
00:42:30,800 --> 00:42:32,000
indo razoavelmente bem

1235
00:42:32,000 --> 00:42:34,960
como vimos antes e o aprendizado agudo

1236
00:42:34,960 --> 00:42:35,680
com a

1237
00:42:35,680 --> 00:42:38,400
exploração decadente está fazendo como

1238
00:42:38,400 --> 00:42:39,520
estava fazendo antes,

1239
00:42:39,520 --> 00:42:42,640
mas quando você o vira um de tal forma que

1240
00:42:42,640 --> 00:42:44,240
os locais dos objetivos

1241
00:42:44,240 --> 00:42:47,520
mudam o que você percebe é que com

1242
00:42:47,520 --> 00:42:48,640
o

1243
00:42:48,640 --> 00:42:52,079
rl bayesiano  gent a quantidade de

1244
00:42:52,079 --> 00:42:53,760
recompensa ou a pontuação que obtém

1245
00:42:53,760 --> 00:42:56,800
é bastante baixa e, em seguida, vemos uma fase

1246
00:42:56,800 --> 00:42:57,119
em

1247
00:42:57,119 --> 00:43:00,000
que ele faz a transição e se torna um para

1248
00:43:00,000 --> 00:43:02,160
a política ideal novamente

1249
00:43:02,160 --> 00:43:04,560
em comparação com o

1250
00:43:04,560 --> 00:43:05,599
agente de inferência ativo,

1251
00:43:05,599 --> 00:43:08,720
onde instantaneamente após a primeira tentativa de

1252
00:43:08,720 --> 00:43:10,560
fazer o  incorreto é capaz de

1253
00:43:10,560 --> 00:43:12,960
mudar para o ativo e desculpe a

1254
00:43:12,960 --> 00:43:14,640
política apropriada

1255
00:43:14,640 --> 00:43:17,680
e a razão para isso é para essas

1256
00:43:17,680 --> 00:43:19,440
configurações uh rl onde estamos considerando isso

1257
00:43:19,440 --> 00:43:20,880
como um problema de aprendizado,

1258
00:43:20,880 --> 00:43:22,480
você precisa primeiro reverter e

1259
00:43:22,480 --> 00:43:24,480
descobrir onde está o local da recompensa

1260
00:43:24,480 --> 00:43:26,720
e  então aprendemos o novo

1261
00:43:26,720 --> 00:43:28,720
local de recompensa, então você está vendo que para

1262
00:43:28,720 --> 00:43:31,280
q aprendendo uh para as diferentes

1263
00:43:31,280 --> 00:43:33,200
parametrizações gananciosas epsilon e

1264
00:43:33,200 --> 00:43:34,720
também para o rl bayesiano e estamos

1265
00:43:34,720 --> 00:43:36,160
vendo isso de forma consistente

1266
00:43:36,160 --> 00:43:38,160
enquanto para o agente de inferência ativo

1267
00:43:38,160 --> 00:43:39,599
porque estamos tratando isso como  um planejamento

1268
00:43:39,599 --> 00:43:41,599
como um problema de inferência onde os

1269
00:43:41,599 --> 00:43:42,960
posteriores do estado anterior são

1270
00:43:42,960 --> 00:43:45,359
movidos para o prêmio e movidos

1271
00:43:45,359 --> 00:43:46,160
como anteriores

1272
00:43:46,160 --> 00:43:49,200
e o agente é capaz de

1273
00:43:49,200 --> 00:43:52,160
perceber instantaneamente que o  a política atual que

1274
00:43:52,160 --> 00:43:52,960
estava

1275
00:43:52,960 --> 00:43:55,200
seguindo este passo de tempo é uma adequação

1276
00:43:55,200 --> 00:43:57,040
que é sua política para o próximo

1277
00:43:57,040 --> 00:44:00,480
um para o outro novamente

1278
00:44:00,480 --> 00:44:02,480
um modelo nulo como esperado não

1279
00:44:02,480 --> 00:44:04,000
faz muito porque está apenas

1280
00:44:04,000 --> 00:44:05,599
explorando não se importa

1281
00:44:05,599 --> 00:44:08,160
onde a recompensa  ou toda a localização

1282
00:44:08,160 --> 00:44:09,839
está

1283
00:44:09,839 --> 00:44:11,839
bem hum phil, você quer adicionar

1284
00:44:11,839 --> 00:44:14,799
algo a isso ou

1285
00:44:15,440 --> 00:44:17,440
não, eu acho que o mesmo ponto se aplica a

1286
00:44:17,440 --> 00:44:18,480
este

1287
00:44:18,480 --> 00:44:22,160
sim, definitivamente ok,

1288
00:44:22,160 --> 00:44:23,760
então apenas para encerrar com essas duas

1289
00:44:23,760 --> 00:44:25,760
comparações e

1290
00:44:25,760 --> 00:44:29,440
eu com a configuração estacionária não soldada

1291
00:44:29,440 --> 00:44:32,319
um tudo  tipos de agentes um incluindo o

1292
00:44:32,319 --> 00:44:34,160
bayesiano rl e o q-learning seriam

1293
00:44:34,160 --> 00:44:36,400
estruturas razoáveis para usar, enquanto que com o

1294
00:44:36,400 --> 00:44:39,280
uh com uma confi

1295
00:44:39,280 --> 00:44:40,480
uração estocástica não estacionária, ter u

1296
00:44:40,480 --> 00:44:42,240
agente de inferência ativo pode ser u

1297
00:44:42,240 --> 00:44:44,079
a maneira apropriada de lidar com mudanças dinâ

1298
00:44:44,079 --> 00:44:45,200
icas, mas a

1299
00:44:45,200 --> 00:44:47,359
principal ressalva com isso  é que

1300
00:44:47,359 --> 00:44:48,480
você pode

1301
00:44:48,480 --> 00:44:50,480
introduzir muito mais

1302
00:44:50,480 --> 00:44:53,119
complexidade adicional na rl bayesiana ou no

1303
00:44:53,119 --> 00:44:55,599
aprendizado q ou na estrutura rl em geral

1304
00:44:55,599 --> 00:44:56,560
para permitir

1305
00:44:56,560 --> 00:44:58,800
uma maneira de lidar com a incerteza,

1306
00:44:58,800 --> 00:44:59,760
mas  não seria

1307
00:44:59,760 --> 00:45:02,240
uma maneira natural de adicioná-lo, você

1308
00:45:02,240 --> 00:45:04,960
teria que aumentar a

1309
00:45:04,960 --> 00:45:06,880
função ou o algoritmo de

1310
00:45:06,880 --> 00:45:09,359
maneiras específicas para justificá-lo,

1311
00:45:09,359 --> 00:45:12,319
tudo bem, então, uma vez que fizemos essa

1312
00:45:12,319 --> 00:45:15,040
comparação, estávamos interessados,

1313
00:45:15,040 --> 00:45:16,960
por que você iria querer  para usar a inferência ativa

1314
00:45:16,960 --> 00:45:19,200


1315
00:45:19,200 --> 00:45:22,079
um quando você não tem uma compreensão

1316
00:45:22,079 --> 00:45:22,880
sobre o mundo

1317
00:45:22,880 --> 00:45:25,440
ou você não tem uma espécie de preferência

1318
00:45:25,440 --> 00:45:27,040
sobre o tipo de coisas que podem ser

1319
00:45:27,040 --> 00:45:28,640
feitas porque como vimos o

1320
00:45:28,640 --> 00:45:30,240
modelo de inferência ativa o modelo nulo está apenas

1321
00:45:30,240 --> 00:45:32,319
explorando  não está a fazer muito

1322
00:45:32,319 --> 00:45:34,720
hum e isso leva-nos a um dos

1323
00:45:34,720 --> 00:45:36,319
pontos iniciais que apresentei

1324
00:45:36,319 --> 00:45:38,160
no início da apresentação que

1325
00:45:38,160 --> 00:45:39,599
é que dentro de um

1326
00:45:39,599 --> 00:45:41,200
quadro de influência activa não nos importamos em

1327
00:45:41,200 --> 00:45:42,560
ter uma função de recompensa

1328
00:45:42,560 --> 00:45:45,920
podemos aprender podemos aprender  que com base em

1329
00:45:45,920 --> 00:45:48,640
alguma interação com o ambiente

1330
00:45:48,640 --> 00:45:52,240
um então para isso

1331
00:45:52,240 --> 00:45:54,480
o que fizemos foi realizar algumas

1332
00:45:54,480 --> 00:45:56,160
simulações diferentes para ver como o

1333
00:45:56,160 --> 00:45:57,920
agente de inferência ativo pode selecionar

1334
00:45:57,920 --> 00:45:59,520
diferentes tipos de políticas na

1335
00:45:59,520 --> 00:46:02,079
ausência de p prévio  referências

1336
00:46:02,079 --> 00:46:04,560
e para isso fizemos três experimentos diferentes

1337
00:46:04,560 --> 00:46:05,280


1338
00:46:05,280 --> 00:46:08,160
um onde permitimos que a

1339
00:46:08,160 --> 00:46:09,040
probabilidade

1340
00:46:09,040 --> 00:46:11,359
e todas as preferências de resultado fossem

1341
00:46:11,359 --> 00:46:12,240
aprendidas ao

1342
00:46:12,240 --> 00:46:15,440
longo do tempo e vimos como o agente

1343
00:46:15,440 --> 00:46:16,560
interagia quando

1344
00:46:16,560 --> 00:46:19,680
esse aprendizado sobre as diferentes

1345
00:46:19,680 --> 00:46:22,640
preferências ocorria e a

1346
00:46:22,640 --> 00:46:24,160
maneira como nós  foi usando

1347
00:46:24,160 --> 00:46:26,960
uh os modelos de conjugação onde uh porque

1348
00:46:26,960 --> 00:46:28,800
esses são modelos de estado discretos, temos

1349
00:46:28,800 --> 00:46:30,800
distribuições categóricas sobre nossos

1350
00:46:30,800 --> 00:46:31,839
parâmetros de modelo

1351
00:46:31,839 --> 00:46:33,760
e estamos introduzindo

1352
00:46:33,760 --> 00:46:34,880
distribuições direcionais no topo

1353
00:46:34,880 --> 00:46:36,960
como um preço híbrido e aprendendo esses

1354
00:46:36,960 --> 00:46:38,319


1355
00:46:38,319 --> 00:46:41,119
hiperpreços, podemos entrar nos detalhes de  isso se

1356
00:46:41,119 --> 00:46:42,800
alguém tiver alguma dúvida, mas

1357
00:46:42,800 --> 00:46:46,400
apenas para simplificar, apenas assuma que

1358
00:46:46,400 --> 00:46:48,800
todas as distribuições de dirichlet uh foram

1359
00:46:48,800 --> 00:46:50,880
definidas como planas completamente planas e

1360
00:46:50,880 --> 00:46:54,079
todos os agentes tiveram a oportunidade

1361
00:46:54,079 --> 00:46:54,800
de pousar com

1362
00:46:54,800 --> 00:46:57,359
base em diferentes interações que eles tiveram,

1363
00:46:57,359 --> 00:46:58,400
então o primeiro conjunto de

1364
00:46:58,400 --> 00:47:00,160
experimentos como as simulações  que

1365
00:47:00,160 --> 00:47:02,319
rodamos era para entender como

1366
00:47:02,319 --> 00:47:04,640
um agente reduziria a incerteza

1367
00:47:04,640 --> 00:47:05,520
sobre o

1368
00:47:05,520 --> 00:47:07,280
ambiente que está em  interagindo com isso,

1369
00:47:07,280 --> 00:47:09,040
se ele não

1370
00:47:09,040 --> 00:47:12,319
conhece o lago congelado,

1371
00:47:12,319 --> 00:47:14,720
como ele interagiria ou exploraria esse

1372
00:47:14,720 --> 00:47:15,599
lago,

1373
00:47:15,599 --> 00:47:18,880
e o que vemos é que

1374
00:47:18,880 --> 00:47:21,920
, neste caso em particular, o agente

1375
00:47:21,920 --> 00:47:23,680
estava apenas interessado em explorá-lo,

1376
00:47:23,680 --> 00:47:25,920
não se importou particularmente com

1377
00:47:25,920 --> 00:47:28,559
o local onde o objetivo ou todo o local

1378
00:47:28,559 --> 00:47:29,040
era

1379
00:47:29,040 --> 00:47:32,079
um e isso é destacado em

1380
00:47:32,079 --> 00:47:35,119
uma série de diferentes

1381
00:47:35,119 --> 00:47:36,800
trajetórias de exploração que vemos então a

1382
00:47:36,800 --> 00:47:38,960
primeira foi onde o agente cai no

1383
00:47:38,960 --> 00:47:39,359


1384
00:47:39,359 --> 00:47:42,400
hall e depois outra onde ele dá a

1385
00:47:42,400 --> 00:47:43,359
volta

1386
00:47:43,359 --> 00:47:46,079
e termina em  o segundo no segundo

1387
00:47:46,079 --> 00:47:48,160
episódio no local da meta

1388
00:47:48,160 --> 00:47:50,079
e em algum lugar ele apenas termina o

1389
00:47:50,079 --> 00:47:51,200
episódio

1390
00:47:51,200 --> 00:47:52,960
apenas indo e voltando, então isso é

1391
00:47:52,960 --> 00:47:54,800
apenas uma exploração do chão,

1392
00:47:54,800 --> 00:47:58,000
nada mais para ouvir

1393
00:47:58,000 --> 00:48:01,440
um o próximo conjunto de análises ou

1394
00:48:01,440 --> 00:48:03,520
simulações que executamos foi para ver o que

1395
00:48:03,520 --> 00:48:05,440
aconteceria se o agente soubesse sobre o

1396
00:48:05,440 --> 00:48:07,599
mundo, mas não tivesse preferências do tipo

1397
00:48:07,599 --> 00:48:08,480
de resultado que

1398
00:48:08,480 --> 00:48:12,160
ele esperava e, para

1399
00:48:12,160 --> 00:48:15,920
isso, executamos várias simulações diferentes

1400
00:48:15,920 --> 00:48:19,200
e vimos que, na ausência de

1401
00:48:19,200 --> 00:48:22,240
qualquer  tipo de preferências

1402
00:48:22,240 --> 00:48:24,079
um o todo pode realmente se tornar

1403
00:48:24,079 --> 00:48:25,599
realmente atraente

1404
00:48:25,599 --> 00:48:28,480
se for encontrado primeiro, então vemos que

1405
00:48:28,480 --> 00:48:29,440
na

1406
00:48:29,440 --> 00:48:31,680
primeira figura onde o agente aprende a

1407
00:48:31,680 --> 00:48:34,000
preferir se esconder nos corredores

1408
00:48:34,000 --> 00:48:36,160
e no segundo tipo de julgamento que

1409
00:48:36,160 --> 00:48:38,000
vimos foi onde o agente

1410
00:48:38,000 --> 00:48:41,520
exibiu o  preferência para realmente

1411
00:48:41,520 --> 00:48:43,359
ir para o local do objetivo, então isso

1412
00:48:43,359 --> 00:48:45,200
depende inteiramente da

1413
00:48:45,200 --> 00:48:47,680
instanciação ou do tipo de estímulo ao

1414
00:48:47,680 --> 00:48:49,119
qual o agente é exposto

1415
00:48:49,119 --> 00:48:51,119
inicialmente, que determina o tipo de

1416
00:48:51,119 --> 00:48:52,319
preferências que ele

1417
00:48:52,319 --> 00:48:55,200
aprenderia a ter

1418
00:48:56,240 --> 00:48:59,520
e, em seguida, o último conjunto de

1419
00:48:59,520 --> 00:49:01,520
simulações que executamos  era apenas

1420
00:49:01,520 --> 00:49:03,119
verificar o que aconteceria quando

1421
00:49:03,119 --> 00:49:04,640
interagimos com os

1422
00:49:04,640 --> 00:49:06,640
imperativos epistêmicos, de fato, resolvemos a

1423
00:49:06,640 --> 00:49:08,000
incerteza sobre o ambiente com o

1424
00:49:08,000 --> 00:49:09,440
qual o agente estava

1425
00:49:09,440 --> 00:49:11,200
interagindo especificamente o

1426
00:49:11,200 --> 00:49:13,200
mapeamento de probabilidade entre os resultados

1427
00:49:13,200 --> 00:49:14,480
dados os estados e

1428
00:49:14,480 --> 00:49:16,880
a incerteza sobre o estado

1429
00:49:16,880 --> 00:49:18,559
de coisas desejado que o agente esperava por

1430
00:49:18,559 --> 00:49:19,839
si mesmo.  estar dentro

1431
00:49:19,839 --> 00:49:22,960
e o que vimos foi que, se

1432
00:49:22,960 --> 00:49:25,520
permitíssemos um número suficiente de tentativas

1433
00:49:25,520 --> 00:49:27,040
para passar  é o agente

1434
00:49:27,040 --> 00:49:28,640
neste cenário em particular aprende a

1435
00:49:28,640 --> 00:49:31,119
preferir cavalgar

1436
00:49:31,119 --> 00:49:34,800
depois de um número x de episódios mas tinha uma preferência

1437
00:49:34,800 --> 00:49:36,000
muito distinta

1438
00:49:36,000 --> 00:49:38,960
sobre o tipo de resultados

1439
00:49:38,960 --> 00:49:39,280
que

1440
00:49:39,280 --> 00:49:41,119
esperava ter dependendo de

1441
00:49:41,119 --> 00:49:42,480


1442
00:49:42,480 --> 00:49:46,400
um determinado ponto de tempo em particular

1443
00:49:46,400 --> 00:49:50,079
um  isso me leva à última

1444
00:49:50,079 --> 00:49:53,839
simulação, então vou encerrar o

1445
00:49:53,839 --> 00:49:57,200
que é uma inferência ativa

1446
00:49:57,200 --> 00:49:59,040
. Comecei a apresentação dizendo

1447
00:49:59,040 --> 00:50:00,640
que é um algoritmo específico que nos dá

1448
00:50:00,640 --> 00:50:01,200


1449
00:50:01,200 --> 00:50:03,599
coisas muito boas a considerar quando

1450
00:50:03,599 --> 00:50:04,559
estamos

1451
00:50:04,559 --> 00:50:07,760
operando em um bayesiano  ou configuração baseada em crenças

1452
00:50:07,760 --> 00:50:08,960
, que é em

1453
00:50:08,960 --> 00:50:11,680
primeiro lugar a principal explicação da

1454
00:50:11,680 --> 00:50:13,359
exploração epistêmica e motivação intrínseca

1455
00:50:13,359 --> 00:50:15,119


1456
00:50:15,119 --> 00:50:17,040


1457
00:50:17,040 --> 00:50:19,440
que obtemos da decomposição de energia livre esperada particular pela qual passamos.

1458
00:50:19,440 --> 00:50:20,400


1459
00:50:20,400 --> 00:50:23,359


1460
00:50:23,359 --> 00:50:25,040


1461
00:50:25,040 --> 00:50:26,000
tem que

1462
00:50:26,000 --> 00:50:28,240
especificar explicitamente uma função de recompensa que vimos

1463
00:50:28,240 --> 00:50:29,119
no último

1464
00:50:29,119 --> 00:50:32,079
uh segundo conjunto de simulações onde

1465
00:50:32,079 --> 00:50:34,000
o agente também pode aprender sua própria recompensa

1466
00:50:34,000 --> 00:50:35,680
a  Prefiro se tornar algo que é

1467
00:50:35,680 --> 00:50:37,359
bastante contra-intuitivo a

1468
00:50:37,359 --> 00:50:39,839
partir de uma configuração rl onde o sinal

1469
00:50:39,839 --> 00:50:41,440
do ambiente está dizendo que algo é

1470
00:50:41,440 --> 00:50:42,319
ruim, mas as

1471
00:50:42,319 --> 00:50:44,160
motivações internas de

1472
00:50:44,160 --> 00:50:46,240
preferência do agente permitem que ele

1473
00:50:46,240 --> 00:50:48,559
faça algo que está bastante em desacordo

1474
00:50:48,559 --> 00:50:50,319
com o que o ambiente está esperando

1475
00:50:50,319 --> 00:50:51,359
fazer

1476
00:50:51,359 --> 00:50:53,599
e, por último, por causa dessa crença

1477
00:50:53,599 --> 00:50:55,280
, a incerteza do cenário de invasão é uma

1478
00:50:55,280 --> 00:50:57,119
parte natural da atualização da crença,

1479
00:50:57,119 --> 00:51:00,559
portanto, dentro das

1480
00:51:00,559 --> 00:51:02,319
configurações estacionárias, os

1481
00:51:02,319 --> 00:51:04,000
agentes de inferência ativos atuam tão bem quanto

1482
00:51:04,000 --> 00:51:05,200
os agentes de aprendizado por reforço,

1483
00:51:05,200 --> 00:51:07,359
no entanto, em configurações não estacionárias, eles

1484
00:51:07,359 --> 00:51:08,960
superam devido à sua capacidade de

1485
00:51:08,960 --> 00:51:10,480
realizar este planejamento como

1486
00:51:10,480 --> 00:51:13,280
inferência e é isso que eu acho que

1487
00:51:13,280 --> 00:51:15,280
mantém isso não é uma afirmação conclusiva,

1488
00:51:15,280 --> 00:51:15,760


1489
00:51:15,760 --> 00:51:18,240
mas é uma boa maneira de começar a pensar sobre

1490
00:51:18,240 --> 00:51:19,040
como,

1491
00:51:19,040 --> 00:51:21,280
se você estiver escalando

1492
00:51:21,280 --> 00:51:23,440
agentes de inferência ativos para interagir no mesmo tipo de

1493
00:51:23,440 --> 00:51:24,160
ambiente

1494
00:51:24,160 --> 00:51:26,960
que o aprendizado por reforço  agentes que

1495
00:51:26,960 --> 00:51:27,760
podem ser

1496
00:51:27,760 --> 00:51:30,079
um pouco difíceis de resolver porque

1497
00:51:30,079 --> 00:51:30,839
há alguma

1498
00:51:30,839 --> 00:51:32,640
não estacionaridade ou algum

1499
00:51:32,640 --> 00:51:33,920
as flutuações que acontecem no

1500
00:51:33,920 --> 00:51:34,640
ambiente

1501
00:51:34,640 --> 00:51:36,240
e os agentes de inferência ativos

1502
00:51:36,240 --> 00:51:38,240
podem funcionar muito bem se

1503
00:51:38,240 --> 00:51:42,000
tivermos esse planejamento como inferência configurado

1504
00:51:42,079 --> 00:51:44,800
e isso me leva ao final da

1505
00:51:44,800 --> 00:51:46,480
apresentação, então eu só quero agradecer a

1506
00:51:46,480 --> 00:51:48,240
todos que estiveram envolvidos com este trabalho

1507
00:51:48,240 --> 00:51:48,559


1508
00:51:48,559 --> 00:51:51,520
chamado tom  e phil e todos que

1509
00:51:51,520 --> 00:51:52,640
me ajudaram a pensar nessas

1510
00:51:52,640 --> 00:51:55,920
ideias interessantes que eu

1511
00:51:55,920 --> 00:51:58,079
apresentei e todos também por ouvirem

1512
00:51:58,079 --> 00:51:59,920


1513
00:51:59,920 --> 00:52:04,400
obrigado obrigado conversa incrível

1514
00:52:04,400 --> 00:52:07,119
para que você possa descompartilhar e nós podemos

1515
00:52:07,119 --> 00:52:08,000
fazer algumas perguntas

1516
00:52:08,000 --> 00:52:09,599
e se alguém que estiver assistindo ao vivo

1517
00:52:09,599 --> 00:52:11,359
gostaria de fazer perguntas  eles são

1518
00:52:11,359 --> 00:52:14,400
mais do que bem-vindos então talvez eu comece

1519
00:52:14,400 --> 00:52:16,160
com apenas um

1520
00:52:16,160 --> 00:52:18,000
ponto geral que foi incrível

1521
00:52:18,000 --> 00:52:20,480
ver como você diferenciou claramente

1522
00:52:20,480 --> 00:52:21,280
entre

1523
00:52:21,280 --> 00:52:22,880
a aprendizagem por reforço e o

1524
00:52:22,880 --> 00:52:24,640
paradigma de inferência ativa

1525
00:52:24,640 --> 00:52:27,040
e apenas uma pergunta que eu tinha foi você

1526
00:52:27,040 --> 00:52:27,760
mencionou isso

1527
00:52:27,760 --> 00:52:30,319
no caso  de um passo de tempo de um de um

1528
00:52:30,319 --> 00:52:31,599
horizonte de tempo de um

1529
00:52:31,599 --> 00:52:33,359
havia como uma equivalência entre

1530
00:52:33,359 --> 00:52:34,960
a abordagem de aprendizado por reforço e

1531
00:52:34,960 --> 00:52:36,640
a infeção ativa

1532
00:52:36,640 --> 00:52:38,640
agora as pessoas estão usando o

1533
00:52:38,640 --> 00:52:40,400
aprendizado de reforço

1534
00:52:40,400 --> 00:52:42,400
para planejar o futuro em meio à

1535
00:52:42,400 --> 00:52:43,599
incerteza,

1536
00:52:43,599 --> 00:52:46,240
então como eles estão realizando esses

1537
00:52:46,240 --> 00:52:47,839
tipos de planejamento

1538
00:52:47,839 --> 00:52:50,400
e onde estão algumas situações em que

1539
00:52:50,400 --> 00:52:51,440
a inferência ativa

1540
00:52:51,440 --> 00:52:53,920
pode ser capaz de entrar nessas

1541
00:52:53,920 --> 00:52:54,800
configurações e

1542
00:52:54,800 --> 00:52:57,760
potencialmente fazer melhor, acho que isso

1543
00:52:57,760 --> 00:52:58,480
já é  uma pergunta

1544
00:52:58,480 --> 00:53:00,400
uma boa pergunta e sinta-se à vontade para você

1545
00:53:00,400 --> 00:53:02,720
pular se eu perder alguma coisa, mas

1546
00:53:02,720 --> 00:53:04,720
dentro da configuração de url pelo que eu

1547
00:53:04,720 --> 00:53:07,040
sei, se eles estão considerando

1548
00:53:07,040 --> 00:53:09,280
horizontes temporais maiores que um,

1549
00:53:09,280 --> 00:53:10,960
eles têm rl hierárquico

1550
00:53:10,960 --> 00:53:13,280
ou têm opções onde estão

1551
00:53:13,280 --> 00:53:14,800
considerando trajetórias que são

1552
00:53:14,800 --> 00:53:16,240
maiores do que

1553
00:53:16,240 --> 00:53:18,800
uma que lhes permite considerar toda uma

1554
00:53:18,800 --> 00:53:20,720
sequência de jogo

1555
00:53:20,720 --> 00:53:24,319
hum antes de gostarem que é lançada

1556
00:53:24,319 --> 00:53:26,000
se eles selecionarem uma política específica em

1557
00:53:26,000 --> 00:53:27,680
vez de assim na verdade

1558
00:53:27,680 --> 00:53:32,800
uma única ação para mapear um estado

1559
00:53:32,800 --> 00:53:34,880
mas eu não sou eu  não trabalhei

1560
00:53:34,880 --> 00:53:36,559
muito com opções, talvez

1561
00:53:36,559 --> 00:53:39,119
phil, você sabe, sim, então as opções são

1562
00:53:39,119 --> 00:53:41,280
como uma maneira de

1563
00:53:41,280 --> 00:53:45,119
alcançar esse tipo de multi-passo s  ort of

1564
00:53:45,119 --> 00:53:47,680
hum como eu acho superdimensionado quase como

1565
00:53:47,680 --> 00:53:49,359
esse viés indutivo certo que

1566
00:53:49,359 --> 00:53:52,000
você vai gostar de suas escolhas serão meio que

1567
00:53:52,000 --> 00:53:54,079
blocos contíguos de

1568
00:53:54,079 --> 00:53:55,520
mais de um passo, enquanto um

1569
00:53:55,520 --> 00:53:57,280
tipo de política é como se eu

1570
00:53:57,280 --> 00:53:58,720
fosse dar um passo e  então eu terei esse

1571
00:53:58,720 --> 00:53:59,359
tipo de

1572
00:53:59,359 --> 00:54:02,720
próximo estado em que eu existo, mas acho

1573
00:54:02,720 --> 00:54:04,240
que é importante desambiguar

1574
00:54:04,240 --> 00:54:06,000
é que você pode planejar as

1575
00:54:06,000 --> 00:54:07,440
coisas do estilo do modelo porque

1576
00:54:07,440 --> 00:54:09,119
você pode ver a inferência ativa como um tipo

1577
00:54:09,119 --> 00:54:10,880
de modelo baseado

1578
00:54:10,880 --> 00:54:13,680
no tipo de  você conhece o paradigma rl e, de

1579
00:54:13,680 --> 00:54:15,280
fato, como dentro do modelo baseado,

1580
00:54:15,280 --> 00:54:18,400
como você pode ter

1581
00:54:18,400 --> 00:54:20,800
métodos de planejamento semelhantes ao que

1582
00:54:20,800 --> 00:54:21,440
é feito

1583
00:54:21,440 --> 00:54:23,040
na inferência ativa, no entanto, acho que

1584
00:54:23,040 --> 00:54:24,480
a principal distinção aqui é

1585
00:54:24,480 --> 00:54:27,440
quando você planeja no rl baseado em modelo,

1586
00:54:27,440 --> 00:54:27,760
você está

1587
00:54:27,760 --> 00:54:29,920
apenas tentando  você tende

1588
00:54:29,920 --> 00:54:30,800
a usar algum

1589
00:54:30,800 --> 00:54:32,880
tipo de naipe como um mini

1590
00:54:32,880 --> 00:54:34,079
método evolucionário geralmente algo como

1591
00:54:34,079 --> 00:54:35,920
o método de entropia cruzada e o que você está

1592
00:54:35,920 --> 00:54:37,440
fazendo é esse tipo de pesquisa sobre todas as

1593
00:54:37,440 --> 00:54:38,640
ações que você toma

1594
00:54:38,640 --> 00:54:40,480
em um determinado ponto i  n tempo que

1595
00:54:40,480 --> 00:54:42,319
maximiza seu tipo de recompensa

1596
00:54:42,319 --> 00:54:45,200
em um horizonte de digamos 20 passos hum

1597
00:54:45,200 --> 00:54:46,559
e você pode fazer algumas coisas inteligentes que você pode

1598
00:54:46,559 --> 00:54:48,880
terminar com uma função de valor q

1599
00:54:48,880 --> 00:54:51,280
hum mas fundamentalmente como se isso

1600
00:54:51,280 --> 00:54:52,799
não o afastasse desse tipo de

1601
00:54:52,799 --> 00:54:55,359
diferença de definição que é

1602
00:54:55,359 --> 00:54:57,760
na inferência ativa você está fazendo esse

1603
00:54:57,760 --> 00:54:59,119
tipo de planejamento sobre as ações mesmo

1604
00:54:59,119 --> 00:55:00,480
que elas possam parecer superficialmente

1605
00:55:00,480 --> 00:55:02,000
semelhantes como

1606
00:55:02,000 --> 00:55:03,680
basicamente como desenhar muitas ações

1607
00:55:03,680 --> 00:55:05,280
e ver quais maximizam algum tipo

1608
00:55:05,280 --> 00:55:06,000
de utilidade

1609
00:55:06,000 --> 00:55:09,119
no caso de inferência ativa todo o

1610
00:55:09,119 --> 00:55:10,880
tipo útil de informação  e o

1611
00:55:10,880 --> 00:55:12,559
rata desejado sobre

1612
00:55:12,559 --> 00:55:15,760
um tipo de exploração e sua

1613
00:55:15,760 --> 00:55:17,839
exploração estão envolvidos nessa

1614
00:55:17,839 --> 00:55:20,000
maximização, enquanto em

1615
00:55:20,000 --> 00:55:23,440
rl é um pouco mais difícil de entender um como

1616
00:55:23,440 --> 00:55:24,799
no sentido clássico, estamos apenas

1617
00:55:24,799 --> 00:55:26,960
tentando maximizar a recompensa, mas

1618
00:55:26,960 --> 00:55:28,720
você pode ter  heurísticas onde você diz oh,

1619
00:55:28,720 --> 00:55:30,240
mas talvez eu queira também maximizar alguma

1620
00:55:30,240 --> 00:55:31,200
noção de

1621
00:55:31,200 --> 00:55:33,359
incerteza do modelo e você sabe

1622
00:55:33,359 --> 00:55:34,640
que fica um pouco

1623
00:55:34,640 --> 00:55:37,280
mais difícil de integrar naturalmente  classifique

1624
00:55:37,280 --> 00:55:39,680
todas essas abordagens na mesma coisa

1625
00:55:39,680 --> 00:55:41,680
hum porque, como no exemplo da influência ativa,

1626
00:55:41,680 --> 00:55:42,400
porque tudo é uma

1627
00:55:42,400 --> 00:55:43,280
distribuição,

1628
00:55:43,280 --> 00:55:44,720
você apenas coloca um hiper antes, se

1629
00:55:44,720 --> 00:55:46,480
quiser, basta integrá-lo

1630
00:55:46,480 --> 00:55:47,760
se não quiser lidar com o

1631
00:55:47,760 --> 00:55:49,920
tipo de ajuste  então sim, é

1632
00:55:49,920 --> 00:55:50,880
aí que eu sinto que

1633
00:55:50,880 --> 00:55:53,920
há esse tipo de diferença

1634
00:55:54,000 --> 00:55:57,280
legal e que tipos de

1635
00:55:57,280 --> 00:56:00,640
configurações você acha que esses tipos de

1636
00:56:00,640 --> 00:56:03,200
ação como inferência e planejamento como

1637
00:56:03,200 --> 00:56:04,240
inferência podem ser

1638
00:56:04,240 --> 00:56:06,960
utilizados como que tipo de conjuntos de dados ou

1639
00:56:06,960 --> 00:56:08,880
perguntas ou  contextos

1640
00:56:08,880 --> 00:56:10,799
são pessoas atualmente usando outro tipo

1641
00:56:10,799 --> 00:56:12,720
de método, mas então você está animado para ver

1642
00:56:12,720 --> 00:56:17,839
a inferência ativa desempenhar um papel,

1643
00:56:18,720 --> 00:56:21,280
acho que principalmente problemas em aberto, onde

1644
00:56:21,280 --> 00:56:23,520
você realmente não tem uma função de recompensa,

1645
00:56:23,520 --> 00:56:26,640
acho, porque

1646
00:56:26,640 --> 00:56:30,079
a maneira como o agente rl está aprendendo como

1647
00:56:30,079 --> 00:56:31,839
interagir com o ambiente é através de

1648
00:56:31,839 --> 00:56:33,839
uma função de recompensa,

1649
00:56:33,839 --> 00:56:36,079
então qualquer coisa onde você realmente não

1650
00:56:36,079 --> 00:56:37,280
tem isso ou você tem

1651
00:56:37,280 --> 00:56:40,640
um ambiente que está mudando,

1652
00:56:40,640 --> 00:56:43,440
mas eu sei que há como um

1653
00:56:43,440 --> 00:56:44,160
ho  st de

1654
00:56:44,160 --> 00:56:46,720
uh pessoas dentro da comunidade rl

1655
00:56:46,720 --> 00:56:47,599
trabalhando como

1656
00:56:47,599 --> 00:56:50,160
motivação intrínseca ou motivação interna,

1657
00:56:50,160 --> 00:56:51,520


1658
00:56:51,520 --> 00:56:54,160
então esse tipo de coisa se sobrepõe à

1659
00:56:54,160 --> 00:56:54,559


1660
00:56:54,559 --> 00:56:58,960
formulação de influência ativa,

1661
00:56:58,960 --> 00:57:02,400
mas paradigmas particulares, eu acho que para mim

1662
00:57:02,400 --> 00:57:04,640
o aspecto mais interessante da

1663
00:57:04,640 --> 00:57:06,079
influência ativa vem do fato de

1664
00:57:06,079 --> 00:57:09,440
quando você começa  pensando em um

1665
00:57:09,440 --> 00:57:12,240
agente biológico e se você está modelando

1666
00:57:12,240 --> 00:57:13,280
um paciente

1667
00:57:13,280 --> 00:57:16,240
ou alguém com esquizofrenia você pode

1668
00:57:16,240 --> 00:57:18,079
com essa estrutura bayesiana você pode

1669
00:57:18,079 --> 00:57:21,760
mudar um os antecedentes para tentar ver

1670
00:57:21,760 --> 00:57:24,960
como a pessoa está interagindo

1671
00:57:24,960 --> 00:57:27,920
onde eu acho que pode ser que

1672
00:57:27,920 --> 00:57:28,799
sua política

1673
00:57:28,799 --> 00:57:30,079
como a  a maneira como eles estão valorizando suas

1674
00:57:30,079 --> 00:57:32,319
políticas estão quebradas ou podem ser

1675
00:57:32,319 --> 00:57:35,599
outras partes que são diferentes,

1676
00:57:35,599 --> 00:57:38,720
mas acho que dentro da configuração rl, se você

1677
00:57:38,720 --> 00:57:43,440
estiver saindo do um

1678
00:57:43,440 --> 00:57:46,480
o padrão, o modo de jogo certo, como

1679
00:57:46,480 --> 00:57:47,359


1680
00:57:47,359 --> 00:57:49,040
ambientes mágicos ou de academia e comece a entrar

1681
00:57:49,040 --> 00:57:50,799
neles  que são mais abertos e você

1682
00:57:50,799 --> 00:57:52,480
não tem nenhuma recompensa, então

1683
00:57:52,480 --> 00:57:54,160
a influência ativa pode ser potencialmente

1684
00:57:54,160 --> 00:57:56,240
útil, mas

1685
00:57:56,240 --> 00:57:58,640
estou um pouco hesitante em  diga

1686
00:57:58,640 --> 00:57:59,599
se será

1687
00:57:59,599 --> 00:58:02,640
melhor porque se você começar a

1688
00:58:02,640 --> 00:58:05,040
aumentar o bayesian rl com todos os tipos de

1689
00:58:05,040 --> 00:58:06,839
componentes interessantes

1690
00:58:06,839 --> 00:58:10,160
, até certo ponto ele estará

1691
00:58:10,160 --> 00:58:13,680
ativo na frente ampliado, o

1692
00:58:13,680 --> 00:58:15,760
que é potencialmente um ponto controverso,

1693
00:58:15,760 --> 00:58:16,880


1694
00:58:16,880 --> 00:58:20,319
mas acho que depende

1695
00:58:20,319 --> 00:58:22,079
exatamente do que  você estava incorporando e

1696
00:58:22,079 --> 00:58:23,920
é por isso que para esta

1697
00:58:23,920 --> 00:58:26,000
apresentação em particular e nosso trabalho fomos muito

1698
00:58:26,000 --> 00:58:27,599
cuidadosos ao definir o

1699
00:58:27,599 --> 00:58:29,599
que significava o aprendizado por reforço, que é

1700
00:58:29,599 --> 00:58:31,760
que você tem que ter essa

1701
00:58:31,760 --> 00:58:33,280
função de recompensa em jogo e deseja

1702
00:58:33,280 --> 00:58:35,040
maximizar essa função de recompensa

1703
00:58:35,040 --> 00:58:37,280
e qualquer coisa que você inclua no rl

1704
00:58:37,280 --> 00:58:39,040
framework tem que ter

1705
00:58:39,040 --> 00:58:42,000
isso uh que gosta do objeto que o

1706
00:58:42,000 --> 00:58:44,000
objetivo tem que estar lá, mas

1707
00:58:44,000 --> 00:58:45,839
se você meio que ignorá-los, diga ok,

1708
00:58:45,839 --> 00:58:47,040
eu vou adicionar todos os tipos de

1709
00:58:47,040 --> 00:58:48,480
componentes interessantes

1710
00:58:48,480 --> 00:58:51,200
para fazer o algoritmo ou a maneira como um

1711
00:58:51,200 --> 00:58:52,400
agente

1712
00:58:52,400 --> 00:58:55,599
interage com o ambiente hum,

1713
00:58:55,599 --> 00:58:57,760
eu acho que é semelhante a uma

1714
00:58:57,760 --> 00:58:59,119
estrutura de inferência ativa

1715
00:58:59,119 --> 00:59:02,000
ou talvez até melhor

1716
00:59:02,000 --> 00:59:03,040
do que você não faz

1717
00:59:03,040 --> 00:59:06,319
essa distinção fina entre onde  re rl

1718
00:59:06,319 --> 00:59:08,400
é melhor ou onde a influência ativa

1719
00:59:08,400 --> 00:59:10,960
é melhor meio que não está realmente lá

1720
00:59:10,960 --> 00:59:12,559
para

1721
00:59:12,559 --> 00:59:15,680
mim porque eu acho que ambas as comunidades da

1722
00:59:15,680 --> 00:59:16,079
minha

1723
00:59:16,079 --> 00:59:17,599
perspectiva estão trabalhando de

1724
00:59:17,599 --> 00:59:19,440
coisas semelhantes que é a tomada de decisão

1725
00:59:19,440 --> 00:59:20,400


1726
00:59:20,400 --> 00:59:23,760
sequencial e com o nosso trabalho é principalmente

1727
00:59:23,760 --> 00:59:26,000
com a tomada de decisão sequencial em

1728
00:59:26,000 --> 00:59:27,520
a face da incerteza

1729
00:59:27,520 --> 00:59:29,920
enquanto alguns dos nossos trabalhos, o meu trabalho rl

1730
00:59:29,920 --> 00:59:30,720
pode não estar

1731
00:59:30,720 --> 00:59:33,440
focado nisso, então acho que é quando você

1732
00:59:33,440 --> 00:59:33,920
começa a

1733
00:59:33,920 --> 00:59:35,359
traçar os limites, torna-se um

1734
00:59:35,359 --> 00:59:37,119
pouco nebuloso onde as

1735
00:59:37,119 --> 00:59:40,079
coisas são separadas ou não e acho que

1736
00:59:40,079 --> 00:59:41,920
subi um pouco  tangente,

1737
00:59:41,920 --> 00:59:45,760
mas phil, você quer adicionar

1738
00:59:45,760 --> 00:59:47,119
algo a isso em termos de

1739
00:59:47,119 --> 00:59:49,280
ambientes e paradigmas que

1740
00:59:49,280 --> 00:59:49,839
possam ser

1741
00:59:49,839 --> 00:59:53,520
úteis, sim, eu acho que se

1742
00:59:53,520 --> 00:59:55,359
um dos seus objetivos é dizer que você recebe um

1743
00:59:55,359 --> 00:59:57,440
ambiente no qual você simplesmente não tem

1744
00:59:57,440 --> 00:59:58,640
conhecimento prévio sobre

1745
00:59:58,640 --> 01:00:01,599
como você  deveria se comportar, você poderia argumentar

1746
01:00:01,599 --> 01:00:03,359
que poderia implantar um agente rl que

1747
01:00:03,359 --> 01:00:05,200
usa algum tipo de curiosidade ou

1748
01:00:05,200 --> 01:00:08,720
mecanismo de redução de incerteza epistêmica, mas

1749
01:00:08,720 --> 01:00:10,559
quero dizer, eu sei que sei que há um

1750
01:00:10,559 --> 01:00:12,319
pouquinho de  trabalho sobre aprender a priori

1751
01:00:12,319 --> 01:00:14,160
sobre funções de recompensa e aprendê-las,

1752
01:00:14,160 --> 01:00:14,640
mas

1753
01:00:14,640 --> 01:00:17,920
não sou muito consciente, mas

1754
01:00:17,920 --> 01:00:19,280
acho que o que é importante entender

1755
01:00:19,280 --> 01:00:21,839
está no limite de como explorar

1756
01:00:21,839 --> 01:00:22,880
todo o ambiente,

1757
01:00:22,880 --> 01:00:24,319
sua incerteza epistêmica

1758
01:00:24,319 --> 01:00:26,319
vai para zero, como você,

1759
01:00:26,319 --> 01:00:27,760
você  terá observado tudo e

1760
01:00:27,760 --> 01:00:29,359
então não está claro o que seu agente rl

1761
01:00:29,359 --> 01:00:30,480
fará naquele momento, especialmente você

1762
01:00:30,480 --> 01:00:31,280
diz que tem uma

1763
01:00:31,280 --> 01:00:33,680
rede neural profunda que

1764
01:00:33,680 --> 01:00:35,839
parametriza como você age,

1765
01:00:35,839 --> 01:00:37,440
enquanto no caso e eu acho que

1766
01:00:37,440 --> 01:00:39,280
este artigo foi realmente interessante

1767
01:00:39,280 --> 01:00:41,119
para mim  para ver como quando realizamos esses

1768
01:00:41,119 --> 01:00:42,480
experimentos foi

1769
01:00:42,480 --> 01:00:44,319
na verdade você apenas colocou uma prioridade sobre suas

1770
01:00:44,319 --> 01:00:46,079
preferências anteriores e eventualmente você

1771
01:00:46,079 --> 01:00:46,480
aprende

1772
01:00:46,480 --> 01:00:48,960
um modo de comportamento que pode não ser o ideal,

1773
01:00:48,960 --> 01:00:50,960
mas seu agente eventualmente

1774
01:00:50,960 --> 01:00:53,040
aprende a adotar um comportamento que é

1775
01:00:53,040 --> 01:00:54,480
auto-realizável porque reduz a

1776
01:00:54,480 --> 01:00:56,000
epidemia  incerteza

1777
01:00:56,000 --> 01:00:58,400
e então tudo o que resta é dizer bem, eu

1778
01:00:58,400 --> 01:00:59,520
acho que esses são

1779
01:00:59,520 --> 01:01:00,960
comportamentos úteis ou pelo menos são

1780
01:01:00,960 --> 01:01:03,200
comportamentos para eu fazer no mundo  e,

1781
01:01:03,200 --> 01:01:04,000
eventualmente,

1782
01:01:04,000 --> 01:01:05,680
você obtém um comportamento bastante repetitivo

1783
01:01:05,680 --> 01:01:07,119
e pode ser um tipo de simulação mais precisa

1784
01:01:07,119 --> 01:01:08,160


1785
01:01:08,160 --> 01:01:10,400
na ausência de qualquer informação,

1786
01:01:10,400 --> 01:01:12,079
como algo inteligente pode realmente

1787
01:01:12,079 --> 01:01:12,559
se comportar

1788
01:01:12,559 --> 01:01:15,040
em um mundo, enquanto no paradigma rl

1789
01:01:15,040 --> 01:01:16,480
é menos claro que você sabe quando reduz

1790
01:01:16,480 --> 01:01:17,599
tudo isso  epistêmico e certamente sobre

1791
01:01:17,599 --> 01:01:18,480
onde está o valor

1792
01:01:18,480 --> 01:01:20,160
e você não encontrou nada parecido com o que

1793
01:01:20,160 --> 01:01:22,319
seu agente está realmente fazendo naquele momento,

1794
01:01:22,319 --> 01:01:24,240
mas acho que meu problema no momento

1795
01:01:24,240 --> 01:01:26,079
com a atuação da

1796
01:01:26,079 --> 01:01:28,960
formulação é que isso funciona como uma

1797
01:01:28,960 --> 01:01:31,040
formulação de estado discreto certo  vimos

1798
01:01:31,040 --> 01:01:34,640
resultados muito bons nessa configuração,

1799
01:01:34,640 --> 01:01:36,880
mas acho que se você aumentar a escala, os

1800
01:01:36,880 --> 01:01:38,240
agentes de inferência ativos terão os

1801
01:01:38,240 --> 01:01:38,640
mesmos

1802
01:01:38,640 --> 01:01:40,559
problemas se você estiver usando como

1803
01:01:40,559 --> 01:01:42,640
inferência amortizada ou algo para

1804
01:01:42,640 --> 01:01:44,640
aproximar suas

1805
01:01:44,640 --> 01:01:47,359
funções de transição de probabilidade, o que significa que

1806
01:01:47,359 --> 01:01:49,280
você pode não  obtenha essas boas propriedades

1807
01:01:49,280 --> 01:01:51,119
que estamos vendo

1808
01:01:51,119 --> 01:01:53,920
nesta pequena escala, então aumentar é

1809
01:01:53,920 --> 01:01:55,200
como

1810
01:01:55,200 --> 01:01:57,119
um problema interessante e aberto

1811
01:01:57,119 --> 01:01:58,720
no th  No momento, escalando da

1812
01:01:58,720 --> 01:01:59,760
maneira certa, você pode

1813
01:01:59,760 --> 01:02:01,440
incluir como esses modelos de conjugação

1814
01:02:01,440 --> 01:02:02,880
que temos

1815
01:02:02,880 --> 01:02:05,280
em uma formulação de estado discreto e

1816
01:02:05,280 --> 01:02:06,000
é assim que

1817
01:02:06,000 --> 01:02:08,240
fazemos o último conjunto de simulações

1818
01:02:08,240 --> 01:02:10,079
onde introduzimos os priores conjugados

1819
01:02:10,079 --> 01:02:10,880
para fazer o

1820
01:02:10,880 --> 01:02:13,839
aprendizado sobre o  as preferências anteriores,

1821
01:02:13,839 --> 01:02:15,440
mas também a probabilidade

1822
01:02:15,440 --> 01:02:17,839
hum, então fica um pouco nebuloso

1823
01:02:17,839 --> 01:02:18,720
como aprender

1824
01:02:18,720 --> 01:02:21,680
como se eu tivesse um hiper prior em uma

1825
01:02:21,680 --> 01:02:23,280
rede neural inteira se você estiver aumentando

1826
01:02:23,280 --> 01:02:24,400
dessa maneira,

1827
01:02:24,400 --> 01:02:27,760
então eles devem gostar de um pouco de trabalho

1828
01:02:27,760 --> 01:02:29,039
a ser feito  nessa área

1829
01:02:29,039 --> 01:02:31,520
e para realmente mostrar que é

1830
01:02:31,520 --> 01:02:32,960
apropriado,

1831
01:02:32,960 --> 01:02:35,680
hum, que você possa ter esses

1832
01:02:35,680 --> 01:02:37,520
componentes interessantes, então você precisa

1833
01:02:37,520 --> 01:02:40,079
começar a pensar em como

1834
01:02:40,079 --> 01:02:42,319
incluir esses hiper prioritários,

1835
01:02:42,319 --> 01:02:44,240
porque não é razoável dizer

1836
01:02:44,240 --> 01:02:45,920
que você terá um prior híbrido

1837
01:02:45,920 --> 01:02:49,119
sobre o espaço do parâmetro,

1838
01:02:49,119 --> 01:02:51,760
como o beta hiper, de modo que o hiper

1839
01:02:51,760 --> 01:02:53,359
prior sobre o gama seria

1840
01:02:53,359 --> 01:02:55,359
suficiente nessas configurações

1841
01:02:55,359 --> 01:02:58,319
um hiper prior para a maneira como o agente está

1842
01:02:58,319 --> 01:03:00,319
selecionando suas ações

1843
01:03:00,319 --> 01:03:02,640
tem que ser sobre os parâmetros do modelo

1844
01:03:02,640 --> 01:03:03,440
e se

1845
01:03:03,440 --> 01:03:06,559
aumentar significa que você está perdendo essa

1846
01:03:06,559 --> 01:03:08,559
boa maneira de desembaraçar os

1847
01:03:08,559 --> 01:03:10,400
parâmetros do modelo específico, então se torna muito

1848
01:03:10,400 --> 01:03:13,440
incerto

1849
01:03:13,440 --> 01:03:15,039
eu não sei, é um

1850
01:03:15,039 --> 01:03:16,559
problema em aberto para mim

1851
01:03:16,559 --> 01:03:18,640
legal sim, eu acho  problemas de alta dimensão

1852
01:03:18,640 --> 01:03:19,760


1853
01:03:19,760 --> 01:03:21,599
ainda representam algo que é

1854
01:03:21,599 --> 01:03:23,119
relativamente difícil,

1855
01:03:23,119 --> 01:03:25,760
especialmente devido ao tipo de você sabe que

1856
01:03:25,760 --> 01:03:27,359
sabe quanto mais nos afastamos de baías

1857
01:03:27,359 --> 01:03:29,680
como um, menos princípio se torna

1858
01:03:29,680 --> 01:03:30,640
e você sabe

1859
01:03:30,640 --> 01:03:34,960
que é como se fosse uma linha muito tênue

1860
01:03:34,960 --> 01:03:37,520
interessante sobre como se

1861
01:03:37,520 --> 01:03:38,720
dentro do

1862
01:03:38,720 --> 01:03:40,960
paradigma rl ou de inferência ativa há uma

1863
01:03:40,960 --> 01:03:41,839
espécie de

1864
01:03:41,839 --> 01:03:44,559
esqueleto esparso, o esqueleto no

1865
01:03:44,559 --> 01:03:45,520
núcleo

1866
01:03:45,520 --> 01:03:48,799
e, às vezes, essas outras camadas

1867
01:03:48,799 --> 01:03:51,839
ou ajustes são necessários

1868
01:03:51,839 --> 01:03:55,359
e muito interessantes para aprender

1869
01:03:55,359 --> 01:03:57,200
e também o que você disse anteriormente

1870
01:03:57,200 --> 01:04:00,079
sobre como o desafio  está planejando

1871
01:04:00,079 --> 01:04:01,839
uma ação seqüencial

1872
01:04:01,839 --> 01:04:03,920
quando você está em feedback, seja apenas

1873
01:04:03,920 --> 01:04:05,440
movendo-se em um ambiente para que seu

1874
01:04:05,440 --> 01:04:06,720
ambiente local mude ou você esteja

1875
01:04:06,720 --> 01:04:07,839
jogando um ga  eu

1876
01:04:07,839 --> 01:04:09,440
com um jogo de tabuleiro vai mudar ou

1877
01:04:09,440 --> 01:04:10,880
você está negociando em uma

1878
01:04:10,880 --> 01:04:13,359
ação seqüencial de mercado, você não pode simplesmente planejar as

1879
01:04:13,359 --> 01:04:15,280
etapas de um a 100

1880
01:04:15,280 --> 01:04:17,440
sem pelo menos pensar em

1881
01:04:17,440 --> 01:04:18,720
algumas hipóteses

1882
01:04:18,720 --> 01:04:22,240
e depois ter acesso apenas a

1883
01:04:22,240 --> 01:04:24,559
dados observacionais e planejamento limitados

1884
01:04:24,559 --> 01:04:25,520


1885
01:04:25,520 --> 01:04:27,680
incerteza fundamental, então acho que muitos desses

1886
01:04:27,680 --> 01:04:30,160
pontos de contato com as motivações

1887
01:04:30,160 --> 01:04:32,559
do aprendizado por reforço e aprendizado de máquina

1888
01:04:32,559 --> 01:04:33,680


1889
01:04:33,680 --> 01:04:35,599
talvez tragam mais luz para a

1890
01:04:35,599 --> 01:04:37,440
inferência ativa e

1891
01:04:37,440 --> 01:04:39,920
um empurrar algumas dessas fronteiras que você acabou de

1892
01:04:39,920 --> 01:04:40,960
mencionar,

1893
01:04:40,960 --> 01:04:42,720
então eu tenho uma pergunta e qualquer outra pessoa

1894
01:04:42,720 --> 01:04:45,119
no  chat também pode fazer uma pergunta

1895
01:04:45,119 --> 01:04:47,680
, digamos que alguém está querendo aprender

1896
01:04:47,680 --> 01:04:48,160
sobre

1897
01:04:48,160 --> 01:04:51,280
isso e eles estão na verdade na

1898
01:04:51,280 --> 01:04:52,960
perspectiva da mente de um iniciante sortudo

1899
01:04:52,960 --> 01:04:56,079
porque eles podem não ter sido atraídos

1900
01:04:56,079 --> 01:04:57,760
pelo aprendizado de aprendizado por reforço,

1901
01:04:57,760 --> 01:04:58,960
mas ficaram curiosos

1902
01:04:58,960 --> 01:05:02,000
na inferência ativa e empolgados com  sua

1903
01:05:02,000 --> 01:05:03,280
apresentação

1904
01:05:03,280 --> 01:05:05,599
e que tipos de linguagens de computador

1905
01:05:05,599 --> 01:05:06,720
ou

1906
01:05:06,720 --> 01:05:08,880
habilidades eles podem querer aprender ou que

1907
01:05:08,880 --> 01:05:11,119
tipos de abordagens ou mentalidades  e

1908
01:05:11,119 --> 01:05:12,000
útil

1909
01:05:12,000 --> 01:05:13,680
se alguém, digamos, não estivesse vindo

1910
01:05:13,680 --> 01:05:15,039
de uma

1911
01:05:15,039 --> 01:05:16,559
perspectiva clássica de aprendizado de máquina

1912
01:05:16,559 --> 01:05:18,400
e aprendendo inferência ativa, mas sim um

1913
01:05:18,400 --> 01:05:21,520
tipo de aprimoramento em inferência ativa,

1914
01:05:21,520 --> 01:05:23,039
o que você recomendaria a qualquer um de vocês?

1915
01:05:23,039 --> 01:05:25,119


1916
01:05:25,119 --> 01:05:27,119


1917
01:05:27,119 --> 01:05:28,480
acho

1918
01:05:28,480 --> 01:05:30,640
que é uma maneira interessante de ver

1919
01:05:30,640 --> 01:05:32,079
esse tipo de pessoa em potencial, porque

1920
01:05:32,079 --> 01:05:33,280
eu meio que senti que

1921
01:05:33,280 --> 01:05:35,920
era como essa pessoa,

1922
01:05:35,920 --> 01:05:36,799


1923
01:05:36,799 --> 01:05:38,079
como nora, e eu estava começando a ter

1924
01:05:38,079 --> 01:05:39,520
essas conversas sobre inferência ativa,

1925
01:05:39,520 --> 01:05:41,440


1926
01:05:41,440 --> 01:05:44,640
e eu gosto do  este artigo

1927
01:05:44,640 --> 01:05:45,680
começou basicamente como um

1928
01:05:45,680 --> 01:05:47,680
tutorial que eu estava escrevendo depois de passar dois e

1929
01:05:47,680 --> 01:05:48,960
três meses

1930
01:05:48,960 --> 01:05:51,359
à noite lendo sobre tentar

1931
01:05:51,359 --> 01:05:53,280
gostar de peneirar

1932
01:05:53,280 --> 01:05:54,799
o ato de literatura de inferência e

1933
01:05:54,799 --> 01:05:57,440
eu acho que você sabe que é justo

1934
01:05:57,440 --> 01:05:59,280
dizer que às vezes é sem remorso

1935
01:05:59,280 --> 01:05:59,920
denso

1936
01:05:59,920 --> 01:06:02,480
e bastante difícil de ler, então você sabe

1937
01:06:02,480 --> 01:06:03,760
sem tentar saber

1938
01:06:03,760 --> 01:06:06,079
, mas eu acho que ler este

1939
01:06:06,079 --> 01:06:07,520
manuscrito em particular é o objetivo geral

1940
01:06:07,520 --> 01:06:08,079


1941
01:06:08,079 --> 01:06:10,000
filosofia quando gostamos quando começamos a

1942
01:06:10,000 --> 01:06:11,440
escrever isso era

1943
01:06:11,440 --> 01:06:14,640
realmente entender como o que está

1944
01:06:14,640 --> 01:06:16,160
acontecendo aqui como qual é esse tipo de

1945
01:06:16,160 --> 01:06:17,760
quantidade de energia livre esperada como por

1946
01:06:17,760 --> 01:06:18,880
que nos importamos com isso

1947
01:06:18,880 --> 01:06:21,359
então eu sei de um tipo de

1948
01:06:21,359 --> 01:06:23,359
perspectiva teórica eu acho que isso é  uma

1949
01:06:23,359 --> 01:06:26,160
apresentação muito lúcida do conceito para que pelo

1950
01:06:26,160 --> 01:06:26,640
menos

1951
01:06:26,640 --> 01:06:28,240
você possa ter algum tipo de intuição sobre o

1952
01:06:28,240 --> 01:06:30,319
que está acontecendo um quanto ao

1953
01:06:30,319 --> 01:06:32,160
tipo de codificação eu não posso realmente falar

1954
01:06:32,160 --> 01:06:33,760
com isso tenho certeza que nem

1955
01:06:33,760 --> 01:06:35,760
meio que tem  funcionou funciona um pouco com isso

1956
01:06:35,760 --> 01:06:36,960


1957
01:06:36,960 --> 01:06:38,960
hum eu ia dizer que

1958
01:06:38,960 --> 01:06:40,000
depende de

1959
01:06:40,000 --> 01:06:41,920
qual é o objectivo principal da pessoa

1960
01:06:41,920 --> 01:06:43,440
é uma

1961
01:06:43,440 --> 01:06:46,559
espécie de obter uma compreensão

1962
01:06:46,559 --> 01:06:49,760
das ideias conceptuais de alto nível ou

1963
01:06:49,760 --> 01:06:51,359
tratá-lo como um algoritmo  porque se

1964
01:06:51,359 --> 01:06:52,799
você está vindo de um princípio de energia livre,

1965
01:06:52,799 --> 01:06:54,799
inferência muito ativa é uma

1966
01:06:54,799 --> 01:06:56,400
história diferente ou se você está

1967
01:06:56,400 --> 01:06:59,440
fazendo inferências ativas de silos de

1968
01:06:59,440 --> 01:07:01,839
um tipo específico de esquema sequencial de

1969
01:07:01,839 --> 01:07:02,799
tomada de decisão

1970
01:07:02,799 --> 01:07:06,559
, certo, então, dependendo disso,

1971
01:07:06,559 --> 01:07:06,880
é

1972
01:07:06,880 --> 01:07:09,599
meio que  diferente  rs uh, mas como Phil estava

1973
01:07:09,599 --> 01:07:11,440
dizendo, eu acho que este artigo definitivamente

1974
01:07:11,440 --> 01:07:15,359
é muito bom no sentido de que

1975
01:07:15,359 --> 01:07:16,960
tenta definir todos os

1976
01:07:16,960 --> 01:07:18,720
conceitos diferentes e passa

1977
01:07:18,720 --> 01:07:21,920
pelas diferentes formulações, talvez não

1978
01:07:21,920 --> 01:07:25,440
com tantos detalhes, com as suposições

1979
01:07:25,440 --> 01:07:26,559
em jogo, dá a você

1980
01:07:26,559 --> 01:07:29,520
a  o layout de como você

1981
01:07:29,520 --> 01:07:30,880
pode derivá-lo,

1982
01:07:30,880 --> 01:07:34,079
mas certas coisas como o

1983
01:07:34,079 --> 01:07:37,200
que a densidade aproximada realmente

1984
01:07:37,200 --> 01:07:40,319
implica essas são perguntas muito uh difíceis

1985
01:07:40,319 --> 01:07:41,200


1986
01:07:41,200 --> 01:07:43,440
onde você teria que mergulhar na

1987
01:07:43,440 --> 01:07:44,880
literatura de inferência variacional para

1988
01:07:44,880 --> 01:07:46,000
entender,

1989
01:07:46,000 --> 01:07:47,839
então acho que dessa perspectiva alguém

1990
01:07:47,839 --> 01:07:49,920
quem está entrando no campo

1991
01:07:49,920 --> 01:07:51,440
deve gastar algum tempo pensando sobre

1992
01:07:51,440 --> 01:07:53,280
inferência variacional e como isso

1993
01:07:53,280 --> 01:07:53,760
realmente se

1994
01:07:53,760 --> 01:07:55,839
relaciona com a formulação do ato de influência

1995
01:07:55,839 --> 01:07:56,960


1996
01:07:56,960 --> 01:07:59,119
porque a parte da percepção da

1997
01:07:59,119 --> 01:08:00,559
inferência ativa é

1998
01:08:00,559 --> 01:08:03,359
na maioria dos casos exatamente a mesma que a

1999
01:08:03,359 --> 01:08:04,160


2000
01:08:04,160 --> 01:08:07,119
literatura de inferência variacional e

2001
01:08:07,119 --> 01:08:08,640
otimizando a evidência do modelo

2002
01:08:08,640 --> 01:08:12,240
uh ou a maximização da lei de evidências

2003
01:08:12,240 --> 01:08:13,200


2004
01:08:13,200 --> 01:08:15,599
é a segunda coisa que eu

2005
01:08:15,599 --> 01:08:16,399
ia  acrescentar

2006
01:08:16,399 --> 01:08:19,679
é um que o papel

2007
01:08:19,679 --> 01:08:22,319
com lancelot de costa é muito bom

2008
01:08:22,319 --> 01:08:24,158
para quem quer se aprofundar

2009
01:08:24,158 --> 01:08:27,198
em derivar tudo sozinho

2010
01:08:27,198 --> 01:08:30,719
uh às vezes é super técnico então

2011
01:08:30,719 --> 01:08:31,198
essa

2012
01:08:31,198 --> 01:08:33,279
arte que o papel que eu passei

2013
01:08:33,279 --> 01:08:35,359
hoje uh aquele com phil e tom e

2014
01:08:35,359 --> 01:08:36,080
carl

2015
01:08:36,080 --> 01:08:38,238
é  é uma boa introdução para alguém

2016
01:08:38,238 --> 01:08:40,080
que não está familiarizado com a matemática

2017
01:08:40,080 --> 01:08:41,198
e só quer

2018
01:08:41,198 --> 01:08:44,399
obter um resumo de um leigo uh, enquanto este é

2019
01:08:44,399 --> 01:08:46,560
o artigo onde o

2020
01:08:46,560 --> 01:08:48,080
primeiro autor de Lance fornece

2021
01:08:48,080 --> 01:08:50,960
as derivações detalhadas e muitas das

2022
01:08:50,960 --> 01:08:51,759
suposições

2023
01:08:51,759 --> 01:08:53,679
em vigor, então isso é como

2024
01:08:53,679 --> 01:08:55,439
compreensão  a parte

2025
01:08:55,439 --> 01:08:57,759
teórica da perspectiva da codificação

2026
01:08:57,759 --> 01:08:59,759
depende inteiramente de qual é o objetivo final,

2027
01:08:59,759 --> 01:09:00,640
então se eles querem que

2028
01:09:00,640 --> 01:09:03,198
alguém queira trabalhar com

2029
01:09:03,198 --> 01:09:04,479
formulações de estado discreto

2030
01:09:04,479 --> 01:09:07,679
, o código do matlab que carl escreveu

2031
01:09:07,679 --> 01:09:10,719
e são anos de trabalho com muitas

2032
01:09:10,719 --> 01:09:13,600
simulações e exemplos legais que

2033
01:09:13,600 --> 01:09:14,319
você  pode usar

2034
01:09:14,319 --> 01:09:17,439
e também nosso código está online e você pode

2035
01:09:17,439 --> 01:09:18,479
acessá-lo

2036
01:09:18,479 --> 01:09:21,679
então tem um link no papel um na

2037
01:09:21,679 --> 01:09:24,880
seção do software um que dá  onde está

2038
01:09:24,880 --> 01:09:25,679
exatamente

2039
01:09:25,679 --> 01:09:27,040
o código e você pode olhar por

2040
01:09:27,040 --> 01:09:29,040
isso e ver como as simulações foram

2041
01:09:29,040 --> 01:09:29,920
feitas

2042
01:09:29,920 --> 01:09:33,120
se alguém estiver interessado em um

2043
01:09:33,120 --> 01:09:36,719
mais eu acho que um de alta dimensional

2044
01:09:36,719 --> 01:09:39,120
formulações de inferência ativa que

2045
01:09:39,120 --> 01:09:42,799
um há algum trabalho recente com uh

2046
01:09:42,799 --> 01:09:46,399
zephyr zephyrus um so zeff fontes

2047
01:09:46,399 --> 01:09:48,799
as  primeiro autor uh, onde temos um

2048
01:09:48,799 --> 01:09:50,080
bom novamente, temos um

2049
01:09:50,080 --> 01:09:52,479
git reaper para esse trabalho também, que

2050
01:09:52,479 --> 01:09:53,198


2051
01:09:53,198 --> 01:09:55,920
fornece um detalhamento de como você

2052
01:09:55,920 --> 01:09:57,360
implementaria um

2053
01:09:57,360 --> 01:09:59,600
agente de inferência ativo simples usando

2054
01:09:59,600 --> 01:10:01,280
codificadores muito curtos e uma

2055
01:10:01,280 --> 01:10:03,679
rede de transição simples, então há muito  de

2056
01:10:03,679 --> 01:10:04,719


2057
01:10:04,719 --> 01:10:06,400
áreas diferentes, mas para alguém que está começando, eles

2058
01:10:06,400 --> 01:10:07,679
precisam entender se

2059
01:10:07,679 --> 01:10:08,800
querem se concentrar no

2060
01:10:08,800 --> 01:10:10,159
lado teórico ou se querem se

2061
01:10:10,159 --> 01:10:11,840
concentrar no lado da implementação. O

2062
01:10:11,840 --> 01:10:13,199
lado teórico

2063
01:10:13,199 --> 01:10:14,640
seria aprofundar a

2064
01:10:14,640 --> 01:10:16,000
influência variacional e a matemática

2065
01:10:16,000 --> 01:10:17,920
por trás disso e  se eles querem se concentrar no

2066
01:10:17,920 --> 01:10:18,239


2067
01:10:18,239 --> 01:10:19,600
aspecto de codificação, eles querem

2068
01:10:19,600 --> 01:10:21,760
descobrir se as

2069
01:10:21,760 --> 01:10:23,199
formulações de estado contínuo ou discreto estão

2070
01:10:23,199 --> 01:10:25,199
interessadas  sted e então

2071
01:10:25,199 --> 01:10:27,679
meio que se divide em se for

2072
01:10:27,679 --> 01:10:29,040
contínuo, então a

2073
01:10:29,040 --> 01:10:32,880
maior parte estaria escrevendo

2074
01:10:32,880 --> 01:10:34,800
as coordenadas dos próprios movimentos ou

2075
01:10:34,800 --> 01:10:36,960
eles teriam que usar algum tipo de

2076
01:10:36,960 --> 01:10:40,640
rede neural para

2077
01:10:40,640 --> 01:10:42,480
aproximar essa distribuição contínua

2078
01:10:42,480 --> 01:10:43,280
de

2079
01:10:43,280 --> 01:10:45,520
interesse  ou o estado discreto que Carl

2080
01:10:45,520 --> 01:10:46,400
escreveu

2081
01:10:46,400 --> 01:10:49,199
um e se eles tiverem dúvidas sobre

2082
01:10:49,199 --> 01:10:50,480
o estado discreto,

2083
01:10:50,480 --> 01:10:53,679
estou feliz em receber e-mails também,

2084
01:10:53,679 --> 01:10:54,080
então,

2085
01:10:54,080 --> 01:10:57,040
se alguém tiver ou o estado contínuo,

2086
01:10:57,040 --> 01:10:57,840


2087
01:10:57,840 --> 01:11:01,679
um espaço de estado também, obrigado pelo

2088
01:11:01,679 --> 01:11:04,960
distinção e hum, é uma diferença tão grande

2089
01:11:04,960 --> 01:11:06,159
entre o

2090
01:11:06,159 --> 01:11:09,040
código do Matlab que temos que percorrer

2091
01:11:09,040 --> 01:11:09,679
com

2092
01:11:09,679 --> 01:11:12,159
ryan smith e christopher white que

2093
01:11:12,159 --> 01:11:13,120
está fazendo a

2094
01:11:13,120 --> 01:11:16,000
multiplicação de matrizes e

2095
01:11:16,000 --> 01:11:17,920
aí vem as redes neurais

2096
01:11:17,920 --> 01:11:20,880
e está oferecendo sons como novas

2097
01:11:20,880 --> 01:11:23,120
oportunidades com alta dimensionalidade

2098
01:11:23,120 --> 01:11:26,159
e contínua  variáveis, mas também

2099
01:11:26,159 --> 01:11:26,880
muitos novos

2100
01:11:26,880 --> 01:11:30,320
desafios, então qual é

2101
01:11:30,320 --> 01:11:33,360
a essência compartilhada

2102
01:11:33,360 --> 01:11:37,440
pela forma matricial e por esse estilo mais de

2103
01:11:37,440 --> 01:11:40,480
aprendizado de máquina,

2104
01:11:40,480 --> 01:11:43,040
porque  e para algumas pessoas pode estar

2105
01:11:43,040 --> 01:11:43,920
dividindo um fio de

2106
01:11:43,920 --> 01:11:46,480
cabelo literalmente a diferença entre

2107
01:11:46,480 --> 01:11:47,840
duas linguagens de computador

2108
01:11:47,840 --> 01:11:49,120
quando estão pensando em

2109
01:11:49,120 --> 01:11:51,760
inferência ativa de uma

2110
01:11:51,760 --> 01:11:54,800
psicologia ecológica ou em uma perspectiva

2111
01:11:54,800 --> 01:11:57,600
filosófica ativa ou de performance incorporada

2112
01:11:57,600 --> 01:11:58,320


2113
01:11:58,320 --> 01:12:01,600
todos os antecedentes que convergem em

2114
01:12:01,600 --> 01:12:02,880
inferência ativa e assim

2115
01:12:02,880 --> 01:12:05,440
para alguém fora do fio de

2116
01:12:05,440 --> 01:12:06,800
cabelo o

2117
01:12:06,800 --> 01:12:09,199
que é que podemos realmente destilar

2118
01:12:09,199 --> 01:12:09,920
que é

2119
01:12:09,920 --> 01:12:11,679
a inferência ativa principal e escrevi

2120
01:12:11,679 --> 01:12:13,440
algumas coisas para

2121
01:12:13,440 --> 01:12:14,800
que você dissesse quais são as

2122
01:12:14,800 --> 01:12:16,480
peças principais que nos permitem

2123
01:12:16,480 --> 01:12:19,120
mergulhar no modo matriz com matlab ou

2124
01:12:19,120 --> 01:12:20,840
no modo de rede neural com como

2125
01:12:20,840 --> 01:12:22,960
python

2126
01:12:22,960 --> 01:12:24,640
um, então acho que se resume ao meu

2127
01:12:24,640 --> 01:12:26,640
slide de resumo do jeito que penso sobre isso,

2128
01:12:26,640 --> 01:12:28,159
então a inferência ativa os

2129
01:12:28,159 --> 01:12:29,679
ingredientes principais estão formulando o

2130
01:12:29,679 --> 01:12:30,960
modelo de gênero

2131
01:12:30,960 --> 01:12:32,480
e aqui formulando o modelo geral

2132
01:12:32,480 --> 01:12:33,840
é a parametrização do modelo geral

2133
01:12:33,840 --> 01:12:35,520
então ou você pode usar as

2134
01:12:35,520 --> 01:12:37,760
distribuições categóricas de estágio discreto

2135
01:12:37,760 --> 01:12:38,719
ou você pode usar

2136
01:12:38,719 --> 01:12:40,560
uma formulação de estado mais contínua e

2137
01:12:40,560 --> 01:12:42,719
novamente

2138
01:12:42,719 --> 01:12:44,560
a formulação da rede neural é uma

2139
01:12:44,560 --> 01:12:46,400
instanciação específica disso,

2140
01:12:46,400 --> 01:12:49,679
então essa seria uma maneira de

2141
01:12:49,679 --> 01:12:50,480
diferenciar

2142
01:12:50,480 --> 01:12:53,679
que a segunda é a

2143
01:12:53,679 --> 01:12:56,239
otimização das funções objetivo

2144
01:12:56,239 --> 01:12:57,440
em jogo,

2145
01:12:57,440 --> 01:13:01,840
então no código do matlab

2146
01:13:01,840 --> 01:13:04,239
estamos fazendo gradientes para enviar usando

2147
01:13:04,239 --> 01:13:06,400
mensagem de campo médio  algoritmo de passagem para

2148
01:13:06,400 --> 01:13:07,760
uma formulação tão específica que foi

2149
01:13:07,760 --> 01:13:09,679
introduzida em alguns artigos

2150
01:13:09,679 --> 01:13:11,440
e eu especificamente não passei por

2151
01:13:11,440 --> 01:13:12,880
isso ou

2152
01:13:12,880 --> 01:13:16,000
uh você está fazendo propagação de volta para

2153
01:13:16,000 --> 01:13:17,280
realmente

2154
01:13:17,280 --> 01:13:20,320
calcular as distribuições ou lambda

2155
01:13:20,320 --> 01:13:21,760
e então você está apenas

2156
01:13:21,760 --> 01:13:23,840
resolvendo essas distribuições que você

2157
01:13:23,840 --> 01:13:26,560
tem  isso depende de

2158
01:13:26,560 --> 01:13:29,840
qual formulação você

2159
01:13:29,840 --> 01:13:32,400
gosta, depende de como você otimiza

2160
01:13:32,400 --> 01:13:33,840
esses objetivos, ou você está

2161
01:13:33,840 --> 01:13:35,600
pegando o modelo implícito para frente

2162
01:13:35,600 --> 01:13:37,600
ou está pegando um modelo de gênero explícito,

2163
01:13:37,600 --> 01:13:39,199


2164
01:13:39,199 --> 01:13:41,360
e uma coisa que esqueci de mencionar é

2165
01:13:41,360 --> 01:13:42,480
que  um

2166
01:13:42,480 --> 01:13:44,480
alex shams e connor hines eles estão

2167
01:13:44,480 --> 01:13:47,520
trabalhando em uma formulação de estado discreto

2168
01:13:47,520 --> 01:13:50,880
de uma inferência ativa em python

2169
01:13:50,880 --> 01:13:53,360
que pode ser de interesse para pessoas

2170
01:13:53,360 --> 01:13:55,280
que  quero focar em uma linguagem específica

2171
01:13:55,280 --> 01:13:56,239


2172
01:13:56,239 --> 01:13:58,960
que possa fazer coisas mais sofisticadas ou de

2173
01:13:58,960 --> 01:14:00,640
alta dimensão

2174
01:14:00,640 --> 01:14:02,719
e a formulação de estado discreto que

2175
01:14:02,719 --> 01:14:03,920
carl tem um

2176
01:14:03,920 --> 01:14:05,760
eu sei que eles também estão procurando pessoas

2177
01:14:05,760 --> 01:14:08,719
para trabalhar na base de código, se alguém estiver

2178
01:14:08,719 --> 01:14:09,840
interessado, então é chamado

2179
01:14:09,840 --> 01:14:13,520
inferir atividade, eu acho, mas isso também está no

2180
01:14:13,520 --> 01:14:17,760
github, se alguém estiver interessado,

2181
01:14:17,840 --> 01:14:21,760
legal, qualquer tipo de último

2182
01:14:21,760 --> 01:14:25,280
pensamento ou comentário de qualquer um de vocês,

2183
01:14:27,440 --> 01:14:30,640
não, acho que estou bem,

2184
01:14:30,640 --> 01:14:33,440
então o que você acha,

2185
01:14:34,880 --> 01:14:37,199


2186
01:14:38,560 --> 01:14:41,360
acho que estamos percebendo um  um pouco de

2187
01:14:41,360 --> 01:14:42,239


2188
01:14:42,239 --> 01:14:45,679
um aumento no interesse em

2189
01:14:45,679 --> 01:14:46,640
inferência ativa como

2190
01:14:46,640 --> 01:14:48,560
apenas para lhe dar um exemplo como talvez

2191
01:14:48,560 --> 01:14:49,840
áreas onde

2192
01:14:49,840 --> 01:14:51,040
até mesmo a inferência ativa teria sido

2193
01:14:51,040 --> 01:14:53,840
considerada antes como a robótica

2194
01:14:53,840 --> 01:14:55,360
hum você está começando a ver cada vez

2195
01:14:55,360 --> 01:14:57,360
mais, então eu acho que se você  quero

2196
01:14:57,360 --> 01:14:58,960
me envolver nisso agora é um momento particularmente

2197
01:14:58,960 --> 01:15:01,199
bom

2198
01:15:01,199 --> 01:15:04,400
ótimo ligue para philip e eu vou

2199
01:15:04,400 --> 01:15:07,199
apenas recomendar novamente o excelente artigo

2200
01:15:07,199 --> 01:15:08,880
que estamos discutindo está na

2201
01:15:08,880 --> 01:15:11,120
descrição deste vídeo realmente

2202
01:15:11,120 --> 01:15:12,719
agradeço a participação de vocês dois

2203
01:15:12,719 --> 01:15:15,040
você é sempre bem-vindo para

2204
01:15:15,040 --> 01:15:16,480


2205
01:15:16,480 --> 01:15:18,239
falar sobre um artigo que você escreveu

2206
01:15:18,239 --> 01:15:19,520
ou não, mas

2207
01:15:19,520 --> 01:15:21,679
novamente muito obrigado uh a nora e

2208
01:15:21,679 --> 01:15:23,679
phillip e espero vê-lo novamente em um

2209
01:15:23,679 --> 01:15:24,239


2210
01:15:24,239 --> 01:15:27,679
fluxo de inferência ativo futuro

2211
01:15:27,679 --> 01:15:30,159
obrigado obrigado por nos convidar  tchau tchau até mais

2212
01:15:30,159 --> 01:15:31,440
daniel

2213
01:15:31,440 --> 01:15:34,000
paz tchau

2214
01:15:36,840 --> 01:15:39,280
incrível pare a transmissão ótima

2215
01:15:39,280 --> 01:15:41,040
conversa muito obrigado a philip e

2216
01:15:41,040 --> 01:15:43,840
noor realmente

