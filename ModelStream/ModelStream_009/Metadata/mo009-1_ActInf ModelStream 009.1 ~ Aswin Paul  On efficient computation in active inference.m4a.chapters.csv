start	end	startTime	summary	headline	gist
7210	40662	00:07	Aspen Paul: Today we're going to have a presentation and a discussion on efficient computation in active inference. If you're watching along live, please feel free to add comments or questions in the chat.	Aspen Paul will speak on efficient computation in active inference	Enabling efficient computation in Active Inference
40796	96266	00:40	The free energy principle is also known as active inference. The central concept is that an agent minimizes entropy of its observation to maintain homeostasis or survive in its environment. It gives us a systematic way of surprising or separating an agent from its environment and model purposeful behavior.	Marco Blankenship talks about efficient computation and active inference	Incomputation and Active Inference
96368	809886	01:36	How does an agent minimize entropy or know which observation is highly probabilistic and vice versa? So that is by maintaining a generative model. The focus of today or decision making is always on this belief that you have after you do the perception in active inference. But the policy space is simply intractable.	So how does an agent minimize entropy using a generative model	Minimizing entropy in machine learning
810068	1479538	13:30	In dynamic programming algorithm, you are doing your planning backwards, using tables. And given your planning horizon is sufficient enough for a problem, what we have seen is that the agent will be able to take optimal actions forward in time. We were able to scale up simulations for grid spaces which was previously intractable without neural networks.	In dynamic programming algorithm, you are doing your planning backwards using tables	Incentive based planning with backward planning
1479704	1607500	24:39	How did you come to work on this project? Were you studying active inference and you came to this question as being interesting. Then I faced this problem of scaling active inference, and then I started working on sophisticated inference.	How did you come to work on this project	Active Inference in neural network planning
1608670	1734830	26:48	ML. Don writes, I wonder, when it comes to computing the expected free energy over a time horizon, what kind of mean field approximation was used to factorize Q of S? Cool. We'll just probably discuss various aspects because there was a lot in your presentation.	Don writes a question about computing expected free energy over a time horizon	Estimating the expected free energy of a model
1735360	2068950	28:55	 preference learning is learning on C. It's about learning the mapping between observations and hidden states of the world. How does that preference learning reduce cognitive overhead or computational complexity?	Let's talk a little bit more generally about preference learning. And how does preference learning reduce cognitive overhead or computational complexity	Advantage Learning and Cognitive Efficiency
2070120	2567430	34:30	Dish Brain uses embodied learnings to simplify the structure of the problem. Compared to dynamic programming, it's increasing the complexity of planning radically. Testing this on the real world is definitely what we should do.	What real world situations or what real life situations do you kind of see this preference learning in	Inferring Prior Preferences with Dynamic Programming
2568120	2786030	42:48	Do you have ideas or developments on nested models where different scales could have different one time step ahead and speed of execution? How does this model play out in nested models? Can you mix and match with these different methods even within one simulation?	Do you have ideas on nested models where different scales could have different speed of execution	Inner-directed navigation in Nested Models
2786880	3210100	46:26	Z learning is a novelty with respect to the active inference field. It's a redefinition of decision making in terms of the state space rather than decisions being something else like left right and down up. And to connect this to the free energy principle and how it is playing out with active inference.	Z learning is a novelty with respect to the active inference field	Z Learning and Active Inference
3211590	3404714	53:31	What I want to do next is think about queue based exploration tasks. Also looking at other ways of making decisions in active instance. Should we even reconsider ways of decision making?	What are your next exciting steps or directions for this work	Decision-making with variational free energy
3404762	3577890	56:44	Daniel: How have you seen active inference develop in the time that you've been a PhD student? He wants to understand deep, active inference more than what he knows now. I hope people check out the paper and get in touch and replicate the code. See you next time.	Daniel: How have you seen active inference develop since you started your PhD	Deep Inference: The field's growth
