1
00:00:03,120 --> 00:00:06,120
extranjero,

2
00:00:08,480 --> 00:00:12,660
es el 15 de julio de 2023,

3
00:00:12,660 --> 00:00:15,900
estamos aquí en la secuencia de modelo de inferencia activa

4
00:00:15,900 --> 00:00:19,080
número 9.1 con Aspen Paul

5
00:00:19,080 --> 00:00:21,060
hoy vamos a tener una presentación

6
00:00:21,060 --> 00:00:24,180
y una discusión sobre

7
00:00:24,180 --> 00:00:27,000
computación eficiente en inferencia activa, así que si

8
00:00:27,000 --> 00:00:28,619
está viendo en vivo, siéntase

9
00:00:28,619 --> 00:00:30,840
libre de agregar  comentarios o preguntas en el

10
00:00:30,840 --> 00:00:33,059
chat, de lo contrario,

11
00:00:33,059 --> 00:00:36,120
muchas gracias por unirse hoy,

12
00:00:36,120 --> 00:00:38,820
espero con ansias su charla,

13
00:00:38,820 --> 00:00:41,640
gracias, Daniel, muchas gracias, como se mencionó hoy

14
00:00:41,640 --> 00:00:42,960


15
00:00:42,960 --> 00:00:44,700


16
00:00:44,700 --> 00:00:46,920


17
00:00:46,920 --> 00:00:49,500
.  Todos estamos familiarizados con esta idea del

18
00:00:49,500 --> 00:00:51,420
principio de energía libre, que también se

19
00:00:51,420 --> 00:00:53,820
conoce como inferencia activa, por lo que el

20
00:00:53,820 --> 00:00:55,800
concepto central es que un agente

21
00:00:55,800 --> 00:00:59,160
minimiza la entropía de su observación para

22
00:00:59,160 --> 00:01:01,140
mantener la homeostasis o sobrevivir en su

23
00:01:01,140 --> 00:01:03,719
entorno y aquí la entropía se

24
00:01:03,719 --> 00:01:05,580
define en la teoría de la información.

25
00:01:05,580 --> 00:01:08,520
sentido correcto, así que si una observación es

26
00:01:08,520 --> 00:01:10,200
altamente probabilística que es menos

27
00:01:10,200 --> 00:01:12,659
entrópica o menos sorprendente porque

28
00:01:12,659 --> 00:01:14,159
era de alta probabilidad y la esperábamos y

29
00:01:14,159 --> 00:01:16,560


30
00:01:16,560 --> 00:01:18,840
esa es la idea cuando esa es

31
00:01:18,840 --> 00:01:20,939
la base sobre la que construimos este marco de

32
00:01:20,939 --> 00:01:23,759
inferencia activa y esta idea de

33
00:01:23,759 --> 00:01:26,520
Marco Blanket uh, nos da una

34
00:01:26,520 --> 00:01:30,000
forma sistemática de sorprender uh o la

35
00:01:30,000 --> 00:01:32,580
forma esquemática de separar uh un agente

36
00:01:32,580 --> 00:01:34,439
de su entorno y modelar el

37
00:01:34,439 --> 00:01:37,320
Comportamiento con propósito, así que concentrémonos

38
00:01:37,320 --> 00:01:39,780
en esta idea de minimizar la entropía. Entonces, ¿

39
00:01:39,780 --> 00:01:41,700
cómo minimiza un agente la entropía o

40
00:01:41,700 --> 00:01:43,740
sabe qué observación es?  altamente

41
00:01:43,740 --> 00:01:46,020
probabilístico y viceversa,

42
00:01:46,020 --> 00:01:48,360
de modo que se mantiene un

43
00:01:48,360 --> 00:01:50,399
modelo generativo y el modelo generativo es

44
00:01:50,399 --> 00:01:52,020
básicamente un modelo de juguete del entorno

45
00:01:52,020 --> 00:01:56,340
que el agente construye en su cerebro y

46
00:01:56,340 --> 00:01:58,860
que se construye utilizando solo la observación

47
00:01:58,860 --> 00:02:00,540
que obtiene del entorno, por lo que

48
00:02:00,540 --> 00:02:03,420
no tiene  el acceso a los estados reales o a los

49
00:02:03,420 --> 00:02:04,740
estados ocultos del entorno

50
00:02:04,740 --> 00:02:07,920
está construyendo el modelo de juguete y, dado

51
00:02:07,920 --> 00:02:10,318
este modelo de juguete, tiene alcance o capacidad

52
00:02:10,318 --> 00:02:13,560
para calcular la probabilidad de una

53
00:02:13,560 --> 00:02:15,900
observación y, por lo tanto, tratar de minimizar

54
00:02:15,900 --> 00:02:18,660
la entropía, así que

55
00:02:18,660 --> 00:02:22,620
esa es la idea, pero  tiene un problema de

56
00:02:22,620 --> 00:02:25,800
um dimensionalidad cursiva como dado un

57
00:02:25,800 --> 00:02:27,239
modelo generativo, puede que no siempre sea posible

58
00:02:27,239 --> 00:02:30,120
calcular o marginar la

59
00:02:30,120 --> 00:02:32,099
probabilidad de las observaciones

60
00:02:32,099 --> 00:02:34,140
porque el espacio de estado puede

61
00:02:34,140 --> 00:02:37,020
volverse intratable rápidamente, pero la idea es que

62
00:02:37,020 --> 00:02:38,640
defina un límite superior en la

63
00:02:38,640 --> 00:02:41,580
sorpresa  usando la desigualdad de Jensen y

64
00:02:41,580 --> 00:02:43,560
también puede

65
00:02:43,560 --> 00:02:46,800
definir un nuevo término llamado Q, que es la

66
00:02:46,800 --> 00:02:49,500
creencia oculta o la creencia sobre los

67
00:02:49,500 --> 00:02:52,080
estados ocultos y esta cola

68
00:02:52,080 --> 00:02:54,000
será el foco de la toma de decisiones, así que

69
00:02:54,000 --> 00:02:57,060
si tiene una cola ruidosa y

70
00:02:57,060 --> 00:02:58,680
no tiene idea  lo que hay en el medio ambiente entonces

71
00:02:58,680 --> 00:03:00,840
no puedes tomar ni esperar tomar decisiones

72
00:03:00,840 --> 00:03:03,540
para controlar ese medio ambiente y es

73
00:03:03,540 --> 00:03:05,519
esta creencia acerca de los estados ocultos que

74
00:03:05,519 --> 00:03:07,560
usas y que se vuelve útil para tomar

75
00:03:07,560 --> 00:03:10,379
decisiones y esta cantidad total se

76
00:03:10,379 --> 00:03:13,019
llama, por supuesto, energía libre y  la

77
00:03:13,019 --> 00:03:14,420
energía libre variacional

78
00:03:14,420 --> 00:03:17,879
F se puede interpretar de varias maneras, por lo que

79
00:03:17,879 --> 00:03:19,560
la primera o la más común es la

80
00:03:19,560 --> 00:03:22,920
forma de aprendizaje automático de cómo es,

81
00:03:22,920 --> 00:03:25,200
um, tratando de minimizar la complejidad

82
00:03:25,200 --> 00:03:27,060
del modelo al mismo tiempo que trata de

83
00:03:27,060 --> 00:03:28,739
maximizar su precisión, así que ese es

84
00:03:28,739 --> 00:03:30,180
el  interpretación de aprendizaje automático de

85
00:03:30,180 --> 00:03:32,400
minimizar varias energías libres,

86
00:03:32,400 --> 00:03:34,140
también puede intentar

87
00:03:34,140 --> 00:03:34,739


88
00:03:34,739 --> 00:03:36,420
interpretar la energía libre en el

89
00:03:36,420 --> 00:03:38,940
término físico donde al mismo tiempo intenta

90
00:03:38,940 --> 00:03:41,760
minimizar la energía de su modelo pero al

91
00:03:41,760 --> 00:03:43,019
mismo tiempo intenta maximizar la

92
00:03:43,019 --> 00:03:45,120
entropía pero el enfoque de

93
00:03:45,120 --> 00:03:48,659
hoy  o la toma de decisiones siempre se basa en

94
00:03:48,659 --> 00:03:51,540
esta creencia que tienes después de hacer

95
00:03:51,540 --> 00:03:54,780
la percepción en la inferencia activa, entonces, ¿

96
00:03:54,780 --> 00:03:57,120
cómo haces la toma de decisiones vainilla o

97
00:03:57,120 --> 00:03:58,920
cuál es la idea más discutida de la

98
00:03:58,920 --> 00:04:00,659
toma de decisiones y la inferencia activa clásica

99
00:04:00,659 --> 00:04:03,540
? Entonces, si estás en un

100
00:04:03,540 --> 00:04:05,580
entorno.  y si eres un agente

101
00:04:05,580 --> 00:04:08,819
que está tratando de tomar decisiones, entonces

102
00:04:08,819 --> 00:04:10,620
tienes un

103
00:04:10,620 --> 00:04:13,319
espacio de acciones disponibles, así que en

104
00:04:13,319 --> 00:04:15,480
este modelo de juguete tienes tres

105
00:04:15,480 --> 00:04:19,738
acciones disponibles, eh, corre, salta o quédate, y

106
00:04:19,738 --> 00:04:22,199
dadas estas acciones, puedes esperar

107
00:04:22,199 --> 00:04:25,139
definir una política por parte de un pequeño Pi.  que es una

108
00:04:25,139 --> 00:04:28,320
secuencia de acciones en el tiempo y

109
00:04:28,320 --> 00:04:30,300
t mayúscula es el horizonte de tiempo de la planificación o

110
00:04:30,300 --> 00:04:32,660
esa es la duración de su

111
00:04:32,660 --> 00:04:36,540
póliza y tiene un espacio de póliza con

112
00:04:36,540 --> 00:04:39,419
muchas de esas pólizas, por lo que dado

113
00:04:39,419 --> 00:04:42,060
este espacio más grande y pequeño, puede

114
00:04:42,060 --> 00:04:44,220
intentar

115
00:04:44,220 --> 00:04:47,340
evaluar el espacio libre esperado  energía basada

116
00:04:47,340 --> 00:04:48,720
en las creencias que ha acumulado,

117
00:04:48,720 --> 00:04:50,580
así que aquí no está minimizando nada,

118
00:04:50,580 --> 00:04:52,860
ya tiene una creencia de variación

119
00:04:52,860 --> 00:04:55,080
de energía y solo está

120
00:04:55,080 --> 00:04:57,419
calculando o evaluando la

121
00:04:57,419 --> 00:04:59,520
energía libre esperada correspondiente a muchas

122
00:04:59,520 --> 00:05:02,759
pequeñas políticas que puede Definir

123
00:05:02,759 --> 00:05:05,699
y después  lo evalúa para todas

124
00:05:05,699 --> 00:05:07,440
las políticas, entonces sabe cuál es la

125
00:05:07,440 --> 00:05:09,180
política óptima a tomar y esa es la

126
00:05:09,180 --> 00:05:11,160
idea clásica de inferencia activa de la

127
00:05:11,160 --> 00:05:13,800
toma de decisiones correcta y

128
00:05:13,800 --> 00:05:16,020
esta energía libre esperada es realmente

129
00:05:16,020 --> 00:05:18,900
útil en el sentido de que está dirigida a un objetivo,

130
00:05:18,900 --> 00:05:21,720
por lo que el término de riesgo está dirigido a un objetivo.

131
00:05:21,720 --> 00:05:23,520
y luego tiene este

132
00:05:23,520 --> 00:05:25,919
término de ambigüedad esperado que lo obliga a

133
00:05:25,919 --> 00:05:27,960
explorar también, pero existe el problema

134
00:05:27,960 --> 00:05:30,539
de que este espacio de políticas puede volverse

135
00:05:30,539 --> 00:05:32,400
interactuable rápidamente y que siempre se ha mantenido

136
00:05:32,400 --> 00:05:35,280
como un cuello de botella al escalar la

137
00:05:35,280 --> 00:05:37,680
inferencia activa a

138
00:05:37,680 --> 00:05:40,500
um entornos comúnmente vistos, pero

139
00:05:40,500 --> 00:05:42,419
veamos cómo  se vuelve rápidamente interactuable,

140
00:05:42,419 --> 00:05:45,300
así que cuántas políticas se pueden definir, por

141
00:05:45,300 --> 00:05:47,940
ejemplo, para un horizonte temporal de 15, así que si

142
00:05:47,940 --> 00:05:50,340
está jugando, digamos Super Mario, es

143
00:05:50,340 --> 00:05:52,440
posible que desee planificar al menos, digamos, 10

144
00:05:52,440 --> 00:05:56,460
pasos de tiempo por delante, por lo que la primera política podría ser,

145
00:05:56,460 --> 00:05:58,380
um, la misma acción.  ejecute

146
00:05:58,380 --> 00:06:02,600
um apilados durante 15 pasos de tiempo y

147
00:06:02,600 --> 00:06:05,460
básicamente puede definir varias combinaciones de

148
00:06:05,460 --> 00:06:09,060
tales acciones y el espacio de políticas es

149
00:06:09,060 --> 00:06:10,139
simplemente

150
00:06:10,139 --> 00:06:13,860
um intratable, se vuelve uh demasiado grande

151
00:06:13,860 --> 00:06:16,380
para que pueda evaluar la energía libre esperada

152
00:06:16,380 --> 00:06:19,440
para todas esas políticas y en un

153
00:06:19,440 --> 00:06:21,900
entorno de problema estocástico donde

154
00:06:21,900 --> 00:06:24,419
um  el entorno en sí mismo es ruidoso,

155
00:06:24,419 --> 00:06:27,120
realmente no tiene un método para elegir un

156
00:06:27,120 --> 00:06:28,860
subconjunto de este espacio de políticas y hacer una

157
00:06:28,860 --> 00:06:30,840
inferencia activa clásica y este es

158
00:06:30,840 --> 00:06:32,340
claramente un problema interactivo computacional

159
00:06:32,340 --> 00:06:34,380
y es por eso que en la literatura

160
00:06:34,380 --> 00:06:36,360
siempre vemos cuadrículas pequeñas o

161
00:06:36,360 --> 00:06:38,880
entornos pequeños cuando discute  toma de decisiones

162
00:06:38,880 --> 00:06:41,520
en influencia activa, pero recientemente,

163
00:06:41,520 --> 00:06:43,860
eh, se propuso una nueva idea

164
00:06:43,860 --> 00:06:46,259
que se llama

165
00:06:46,259 --> 00:06:48,840
entrada sofisticada y, en inferencia sofisticada,

166
00:06:48,840 --> 00:06:51,600
no es realmente el espacio de políticas en el que

167
00:06:51,600 --> 00:06:52,800
en realidad estás,

168
00:06:52,800 --> 00:06:55,080
en tiempo real, tratando de

169
00:06:55,080 --> 00:06:58,139
pensar qué hacer, así que si tienes una creencia,

170
00:06:58,139 --> 00:07:00,000
entonces tú  están tratando de

171
00:07:00,000 --> 00:07:02,880
evaluar las acciones en base a eso, así que

172
00:07:02,880 --> 00:07:04,800
aquí no tenemos una secuencia de

173
00:07:04,800 --> 00:07:07,199
políticas o cosas que se vuelvan

174
00:07:07,199 --> 00:07:10,020
interactivas, aquí estamos haciendo

175
00:07:10,020 --> 00:07:12,600
básicamente una investigación en el sentido de que

176
00:07:12,600 --> 00:07:14,220
está tratando de evaluar la energía libre esperada

177
00:07:14,220 --> 00:07:16,500
de

178
00:07:16,500 --> 00:07:19,560
esta distribución conjunta.  de acciones y

179
00:07:19,560 --> 00:07:21,900
observaciones y para evaluar la

180
00:07:21,900 --> 00:07:23,940
energía libre esperada en algún momento uh

181
00:07:23,940 --> 00:07:26,340
pequeño T también necesitará la

182
00:07:26,340 --> 00:07:29,039
energía libre esperada en el siguiente paso de tiempo y para

183
00:07:29,039 --> 00:07:31,259
evaluar que necesitará la

184
00:07:31,259 --> 00:07:32,819
energía libre esperada del tiempo t más 2 y esto

185
00:07:32,819 --> 00:07:35,039
básicamente se convierte en  una investigación que se

186
00:07:35,039 --> 00:07:38,160
desarrolla en el tiempo y es una

187
00:07:38,160 --> 00:07:41,160
relación recursiva y

188
00:07:41,160 --> 00:07:43,259
aquí es fundamentalmente diferente

189
00:07:43,259 --> 00:07:45,539
del espacio de políticas que vimos en la última

190
00:07:45,539 --> 00:07:47,759
diapositiva a la derecha y

191
00:07:47,759 --> 00:07:49,680
es computacionalmente mejor en el

192
00:07:49,680 --> 00:07:51,780
sentido de que si tiene que planificar, digamos 10

193
00:07:51,780 --> 00:07:55,139
veces consejos  adelante de manera integral en la

194
00:07:55,139 --> 00:07:56,759
inferencia activa clásica vimos que

195
00:07:56,759 --> 00:07:58,380
los espacios de política

196
00:07:58,380 --> 00:07:59,460
um

197
00:07:59,460 --> 00:08:01,940
la cardinalidad del espacio de acción

198
00:08:01,940 --> 00:08:04,139
elevado a T, por lo que ese es el

199
00:08:04,139 --> 00:08:07,259
cuello de botella computacional si tiene que considerar

200
00:08:07,259 --> 00:08:10,199
todas las posibilidades, pero en la

201
00:08:10,199 --> 00:08:12,780
inferencia sofisticada es aún peor porque

202
00:08:12,780 --> 00:08:14,759
está considerando un  combinación de

203
00:08:14,759 --> 00:08:16,860
estado y acciones, por lo que es

204
00:08:16,860 --> 00:08:20,400
computacionalmente peor, de hecho, pero

205
00:08:20,400 --> 00:08:21,660
se propuso una solución en el

206
00:08:21,660 --> 00:08:23,520
sofisticado documento de referencia que

207
00:08:23,520 --> 00:08:26,400
podemos hacer poda de Esta investigación que

208
00:08:26,400 --> 00:08:29,639
podemos evitar algunos estados y acciones

209
00:08:29,639 --> 00:08:31,080
cuando haces esta investigación y eso

210
00:08:31,080 --> 00:08:33,000
se vuelve muy manejable computacionalmente

211
00:08:33,000 --> 00:08:36,059
así que veamos cómo funciona la poda en la

212
00:08:36,059 --> 00:08:38,940
inferencia sofisticada, por lo que esta cuadrícula se

213
00:08:38,940 --> 00:08:40,440
discutió en el documento de inferencia sofisticada original

214
00:08:40,440 --> 00:08:41,700


215
00:08:41,700 --> 00:08:44,580
y digamos para esta cuadrícula dado que

216
00:08:44,580 --> 00:08:47,100
tiene este tipo de distribución de preferencia previa,

217
00:08:47,100 --> 00:08:50,399
por lo que este cuadrado blanco, que

218
00:08:50,399 --> 00:08:52,140
es el estado objetivo, es el estado más preferido

219
00:08:52,140 --> 00:08:54,300
y  tiene una

220
00:08:54,300 --> 00:08:55,380


221
00:08:55,380 --> 00:08:58,140
preferencia uniformemente decreciente por

222
00:08:58,140 --> 00:09:00,779
estados que están lejos de ese

223
00:09:00,779 --> 00:09:03,240
estado dorado, entonces básicamente si se observa a

224
00:09:03,240 --> 00:09:05,480
sí mismo en alguna observación en el momento T,

225
00:09:05,480 --> 00:09:07,560
entonces básicamente lo que está haciendo es

226
00:09:07,560 --> 00:09:09,600
considerar la consecuencia de las

227
00:09:09,600 --> 00:09:12,779
acciones disponibles de esas observaciones

228
00:09:12,779 --> 00:09:17,760
y  básicamente, puede usar la proyección

229
00:09:17,760 --> 00:09:20,700
de su creencia y establecer un umbral para que

230
00:09:20,700 --> 00:09:22,620
esas creencias ignoren

231
00:09:22,620 --> 00:09:24,600
algunas acciones e ignoren algunas

232
00:09:24,600 --> 00:09:27,420
observaciones y lo que encontrará es

233
00:09:27,420 --> 00:09:30,120
que ya no está en la investigación,

234
00:09:30,120 --> 00:09:33,000
es un subconjunto de la investigación y es

235
00:09:33,000 --> 00:09:36,060
computacionalmente  uh eficiente que

236
00:09:36,060 --> 00:09:38,700
hacer toda la investigación correctamente, así que aquí

237
00:09:38,700 --> 00:09:40,680
ha evitado muchas combinaciones

238
00:09:40,680 --> 00:09:42,120
y esto se convierte en un

239
00:09:42,120 --> 00:09:45,420
problema computacionalmente atractivo, esto se debe a que ha

240
00:09:45,420 --> 00:09:47,880
decidido evitar algunas acciones y,

241
00:09:47,880 --> 00:09:49,620
um, la observación, por lo que dice esencialmente

242
00:09:49,620 --> 00:09:52,740
comprometer esas posibilidades que

243
00:09:52,740 --> 00:09:54,600
podrían darle una  recompensa más alta o que

244
00:09:54,600 --> 00:09:56,580
podría ser más óptima que la

245
00:09:56,580 --> 00:09:59,700
consecuencia de esta investigación parcial, pero

246
00:09:59,700 --> 00:10:02,820
funciona, por lo que esta simulación

247
00:10:02,820 --> 00:10:05,459
se presentó en el documento y funciona,

248
00:10:05,459 --> 00:10:09,959
el agente aprende a hacer

249
00:10:09,959 --> 00:10:12,300
lo que debe hacerse si planea en

250
00:10:12,300 --> 00:10:14,940
esta dirección hacia adelante  de planificar uh

251
00:10:14,940 --> 00:10:17,880
de forma recortada pero y

252
00:10:17,880 --> 00:10:19,200


253
00:10:19,200 --> 00:10:20,820
y básicamente puede

254
00:10:20,820 --> 00:10:23,519
demostrar computacionalmente que incluso para un umbral de búsqueda pequeño

255
00:10:23,519 --> 00:10:25,019


256
00:10:25,019 --> 00:10:27,180
um puede disminuir drásticamente la

257
00:10:27,180 --> 00:10:29,100
complejidad computacional, por lo que si

258
00:10:29,100 --> 00:10:31,500
decide hacer toda la investigación

259
00:10:31,500 --> 00:10:33,540
um con la profundidad de planificación uh el

260
00:10:33,540 --> 00:10:35,100
tiempo computacional es  exponencial y

261
00:10:35,100 --> 00:10:38,040
rápidamente, no puede hacer mucho al respecto,

262
00:10:38,040 --> 00:10:40,200
pero si decide en ese umbral,

263
00:10:40,200 --> 00:10:42,420
que es incluso muy pequeño, puede ver

264
00:10:42,420 --> 00:10:43,980
que este problema se vuelve

265
00:10:43,980 --> 00:10:46,620
computacionalmente atractivo y esta

266
00:10:46,620 --> 00:10:49,200
demostración en instancias sofisticadas está

267
00:10:49,200 --> 00:10:50,700
disponible en mi versión de mi mdp y

268
00:10:50,700 --> 00:10:52,860
es  va a ser integrado al

269
00:10:52,860 --> 00:10:55,380
original por mdp pronto,

270
00:10:55,380 --> 00:10:56,820
um,

271
00:10:56,820 --> 00:10:59,160
pero el punto clave es que la poda de

272
00:10:59,160 --> 00:11:01,920
esa investigación nos requiere una

273
00:11:01,920 --> 00:11:03,779
preferencia principal bien informada como esta

274
00:11:03,779 --> 00:11:06,060
en el sentido de que aquí el agente es

275
00:11:06,060 --> 00:11:09,360
consciente de lo deseable que nuestro vecino

276
00:11:09,360 --> 00:11:11,760
afirma que no  solo conoce el

277
00:11:11,760 --> 00:11:13,860
conjunto de objetivos finales, también conoce su

278
00:11:13,860 --> 00:11:16,440
estado vecino y, dada esa

279
00:11:16,440 --> 00:11:18,420
preferencia previa, podemos ver que para una

280
00:11:18,420 --> 00:11:20,399
profundidad de planificación de tres, el agente se

281
00:11:20,399 --> 00:11:23,820
queda atrapado básicamente en esta

282
00:11:23,820 --> 00:11:27,060
preferencia local de Máxima de prioridad, pero con

283
00:11:27,060 --> 00:11:30,480
suficiente profundidad de planificación es  es

284
00:11:30,480 --> 00:11:33,240
capaz de superar esta barrera y alcanzar

285
00:11:33,240 --> 00:11:35,579
el estado objetivo en este gran

286
00:11:35,579 --> 00:11:37,800
problema y

287
00:11:37,800 --> 00:11:39,600
la pregunta es qué pasa si el agente

288
00:11:39,600 --> 00:11:42,720
solo conoce este estado final, no tiene

289
00:11:42,720 --> 00:11:45,660
otro conocimiento sobre qué hacer y, en

290
00:11:45,660 --> 00:11:48,240
este caso, ¿qué hace el agente?  entonces este

291
00:11:48,240 --> 00:11:50,459
es el problema que estamos tratando de

292
00:11:50,459 --> 00:11:53,399
abordar y, en ausencia de

293
00:11:53,399 --> 00:11:55,740
una preferencia previa significativa como esta,

294
00:11:55,740 --> 00:11:58,200
el agente básicamente no tiene forma de

295
00:11:58,200 --> 00:12:00,720
alcanzar el estado objetivo,

296
00:12:00,720 --> 00:12:03,300
um, aparte de la exploración aleatoria,

297
00:12:03,300 --> 00:12:05,279
no tiene forma de planificar porque no

298
00:12:05,279 --> 00:12:08,040
puede  hacer uh planear ocho pasos de tiempo

299
00:12:08,040 --> 00:12:09,779
por delante porque es computacionalmente

300
00:12:09,779 --> 00:12:13,079
interactuable uh si elige hacer

301
00:12:13,079 --> 00:12:17,880
la investigación completa correctamente y si es

302
00:12:17,880 --> 00:12:21,000
así para una cuadrícula como esta, ¿qué hace

303
00:12:21,000 --> 00:12:22,500
si obtiene una preferencia de prueba escasa

304
00:12:22,500 --> 00:12:24,240
que no está bien informada

305
00:12:24,240 --> 00:12:28,079
y como se destaca?  en la diapositiva anterior,

306
00:12:28,079 --> 00:12:30,839
su investigación ahora es ciega, eh,

307
00:12:30,839 --> 00:12:33,000
no tiene forma de podar esa investigación y

308
00:12:33,000 --> 00:12:35,100
tiene que hacer la investigación completa en este

309
00:12:35,100 --> 00:12:36,300
escenario,

310
00:12:36,300 --> 00:12:38,880
así que, como podría haber pensado, um,

311
00:12:38,880 --> 00:12:40,200
hay dos soluciones para esto,

312
00:12:40,200 --> 00:12:42,959
o tiene que encontrar una  manera de hacer

313
00:12:42,959 --> 00:12:47,359
la planificación completa uh

314
00:12:49,579 --> 00:12:52,920
o tienes que aprender una preferencia significativa de Pride

315
00:12:52,920 --> 00:12:54,600
que te permitirá hacer

316
00:12:54,600 --> 00:12:57,480
uh esta investigación recortada, así que vamos

317
00:12:57,480 --> 00:12:59,760
a discutir estas dos soluciones uh en

318
00:12:59,760 --> 00:13:02,399
esta presentación uh para un

319
00:13:02,399 --> 00:13:03,839
escenario dado como este,

320
00:13:03,839 --> 00:13:06,420
así que el primero  la solución para hacer una

321
00:13:06,420 --> 00:13:08,639
investigación completa es básicamente usar

322
00:13:08,639 --> 00:13:11,399
programación dinámica y la programación dinámica es una

323
00:13:11,399 --> 00:13:13,800
idea muy conocida en la investigación de operaciones

324
00:13:13,800 --> 00:13:15,839
y la ingeniería industrial y en

325
00:13:15,839 --> 00:13:18,060
muchas ramas de la ingeniería y la

326
00:13:18,060 --> 00:13:19,920
idea básica es que primero

327
00:13:19,920 --> 00:13:21,959
resuelve las subpartes de un problema más grande

328
00:13:21,959 --> 00:13:24,000
y luego  luego intente integrar

329
00:13:24,000 --> 00:13:27,000
las soluciones de estos subproblemas para

330
00:13:27,000 --> 00:13:31,260
hacer una toma de decisiones óptima, así que

331
00:13:31,260 --> 00:13:33,779
en este escenario imagine que

332
00:13:33,779 --> 00:13:37,019
está tratando de planificar la última

333
00:13:37,019 --> 00:13:39,540
acción, así que antes comenzamos desde la

334
00:13:39,540 --> 00:13:41,760
primera acción, comenzamos desde el presente

335
00:13:41,760 --> 00:13:44,040
e intentamos predecir  lo que está sucediendo en

336
00:13:44,040 --> 00:13:46,320
el futuro, por lo que su dirección de

337
00:13:46,320 --> 00:13:47,940
planificación fue básicamente hacia adelante en el tiempo,

338
00:13:47,940 --> 00:13:49,920
pero imagine que está tratando de planificar

339
00:13:49,920 --> 00:13:51,959
solo para el último paso de tiempo en el que

340
00:13:51,959 --> 00:13:55,560
está cerca del estado objetivo y justo

341
00:13:55,560 --> 00:13:57,600
yendo a ese buen estado correcto para que

342
00:13:57,600 --> 00:13:59,519
están tratando de tomar una decisión para ese

343
00:13:59,519 --> 00:14:01,740
último paso de tiempo que es T mayúscula menos

344
00:14:01,740 --> 00:14:05,459
1 y sus proyecciones para el próximo

345
00:14:05,459 --> 00:14:08,880
paso de tiempo o el último estado objetivo se

346
00:14:08,880 --> 00:14:09,839


347
00:14:09,839 --> 00:14:11,880
pueden hacer porque tienen acceso a

348
00:14:11,880 --> 00:14:14,160
este modelo del mundo usando esta

349
00:14:14,160 --> 00:14:16,079
transición  Dynamics o la Matriz B en

350
00:14:16,079 --> 00:14:18,600
inferencia activa, por lo que para este único

351
00:14:18,600 --> 00:14:21,180
paso de tiempo que es un subproblema,

352
00:14:21,180 --> 00:14:24,060
en realidad está evaluando una tabla de

353
00:14:24,060 --> 00:14:26,100
energía libre esperada que le dice si está en,

354
00:14:26,100 --> 00:14:28,019
digamos, esta observación, qué se debe hacer,

355
00:14:28,019 --> 00:14:31,740
que es para el último  paso de tiempo y,

356
00:14:31,740 --> 00:14:34,440
básicamente, puedes hacer esto en el

357
00:14:34,440 --> 00:14:36,540
espacio de estado o en el espacio de observación, por lo que se puede

358
00:14:36,540 --> 00:14:39,120
hacer usando la matriz a y la

359
00:14:39,120 --> 00:14:41,699
matriz D juntas, donde puedes

360
00:14:41,699 --> 00:14:44,579
planificar de cualquier manera, así que la

361
00:14:44,579 --> 00:14:46,260
pregunta es

362
00:14:46,260 --> 00:14:48,839
si sabes qué hacer en el  los últimos

363
00:14:48,839 --> 00:14:50,940
pasos

364
00:14:50,940 --> 00:14:52,440
que podrías estar pensando ¿cómo sé que estoy en el último paso?  se trata de

365
00:14:52,440 --> 00:14:54,600


366
00:14:54,600 --> 00:14:58,699


367
00:15:09,720 --> 00:15:12,839


368
00:15:12,839 --> 00:15:15,540


369
00:15:15,540 --> 00:15:18,060


370
00:15:18,060 --> 00:15:19,860
imaginar, está

371
00:15:19,860 --> 00:15:22,139
bien, así que si hubo un problema de conexión,

372
00:15:22,139 --> 00:15:23,699
sí, solo por unos segundos, todo está

373
00:15:23,699 --> 00:15:25,199
bien, entonces ahora,

374
00:15:25,199 --> 00:15:28,260
oh, lo siento, pero

375
00:15:28,260 --> 00:15:30,899
lo que estoy tratando de decir es que

376
00:15:30,899 --> 00:15:32,880
estás tratando de imaginar lo que harías

377
00:15:32,880 --> 00:15:35,519
si  están en el tiempo T mayúscula menos uno,

378
00:15:35,519 --> 00:15:37,560
que es el último paso de tiempo para su

379
00:15:37,560 --> 00:15:40,260
horizonte de planificación y si está en ese

380
00:15:40,260 --> 00:15:42,199
paso de tiempo, ¿qué debo hacer? Esta tabla

381
00:15:42,199 --> 00:15:45,480
representa todos los escenarios que si

382
00:15:45,480 --> 00:15:49,800
digo en la observación 3 en el tiempo T menos

383
00:15:49,800 --> 00:15:52,680
uno qué  ¿Qué hago y esta cantidad aquí?

384
00:15:52,680 --> 00:15:54,720
Solo estoy considerando el término de riesgo o

385
00:15:54,720 --> 00:15:56,279
el término con propósito

386
00:15:56,279 --> 00:15:57,720
eh y

387
00:15:57,720 --> 00:16:01,560
este término representa esa política y

388
00:16:01,560 --> 00:16:03,540
qué pasa si hago esto

389
00:16:03,540 --> 00:16:06,180
um al revés hasta el tiempo T menos uno así que si

390
00:16:06,180 --> 00:16:08,699
sé qué hacer  en el momento uh

391
00:16:08,699 --> 00:16:12,300
T mayúscula menos 1, entonces esta tabla puede

392
00:16:12,300 --> 00:16:14,880
informar qué hacer en T mayúscula menos 2.

393
00:16:14,880 --> 00:16:16,920
Entonces, en lugar de planificar hacia adelante en el tiempo, lo

394
00:16:16,920 --> 00:16:19,320
que estoy haciendo es básicamente apilar

395
00:16:19,320 --> 00:16:22,019
muchas tablas juntas simplemente fijando una

396
00:16:22,019 --> 00:16:25,019
T mayúscula de planificación y

397
00:16:25,019 --> 00:16:29,279
dado que  Tengo todas esas tablas de pila,

398
00:16:29,279 --> 00:16:31,800
entonces, básicamente, lo que puedo hacer es usarlas

399
00:16:31,800 --> 00:16:33,899
para tomar decisiones hacia adelante en el tiempo y lo que

400
00:16:33,899 --> 00:16:35,940
hemos observado es que esta idea

401
00:16:35,940 --> 00:16:38,519
funciona,

402
00:16:38,519 --> 00:16:40,259
um, puedo calcular la energía libre esperada

403
00:16:40,259 --> 00:16:43,019
hacia atrás, paso a paso,

404
00:16:43,019 --> 00:16:46,920
considerándolos como subproblemas.  y

405
00:16:46,920 --> 00:16:49,079
la diferencia fundamental es que en la

406
00:16:49,079 --> 00:16:51,600
inferencia sofisticada, eh, para calcular

407
00:16:51,600 --> 00:16:54,959
la energía libre esperada en el tiempo T pequeño,

408
00:16:54,959 --> 00:16:57,540
no sabe cuál es la energía libre esperada

409
00:16:57,540 --> 00:16:59,880
en el tiempo equipo más uno, por lo que se

410
00:16:59,880 --> 00:17:01,920
convierte en una búsqueda de tres, por lo que

411
00:17:01,920 --> 00:17:04,319
debe calcular esto primero.  y para calcular

412
00:17:04,319 --> 00:17:06,839
t más 1 necesitas t más 2 y así sucesivamente,

413
00:17:06,839 --> 00:17:09,000
pero aquí, debido a que lo estás calculando

414
00:17:09,000 --> 00:17:11,339
hacia atrás en el tiempo, ya sabes cuál

415
00:17:11,339 --> 00:17:13,559
es la energía libre esperada para p

416
00:17:13,559 --> 00:17:16,020
más 1 y basas que es básicamente la

417
00:17:16,020 --> 00:17:17,520
misma ecuación, es solo que  lo está

418
00:17:17,520 --> 00:17:20,900
haciendo al revés en el tiempo y

419
00:17:20,900 --> 00:17:23,520
pictóricamente en una inferencia sofisticada que

420
00:17:23,520 --> 00:17:25,619
está tratando de hacer una investigación, pero en

421
00:17:25,619 --> 00:17:27,660
el algoritmo de programación dinámica está

422
00:17:27,660 --> 00:17:30,120
haciendo su planificación al revés usando

423
00:17:30,120 --> 00:17:32,940
tablas y dada su planificación Horizon

424
00:17:32,940 --> 00:17:35,520
es suficiente para un problema que

425
00:17:35,520 --> 00:17:38,160
tenemos  visto es que el agente

426
00:17:38,160 --> 00:17:40,860
podrá tomar acciones óptimas hacia adelante en el

427
00:17:40,860 --> 00:17:44,340
tiempo, por lo que en el documento también

428
00:17:44,340 --> 00:17:46,500
proponemos un algoritmo para

429
00:17:46,500 --> 00:17:49,020
DPS de forma secuencial usando esta

430
00:17:49,020 --> 00:17:50,880
planificación hacia atrás en el tiempo y

431
00:17:50,880 --> 00:17:54,059
pudimos escalar simulaciones para

432
00:17:54,059 --> 00:17:56,240
espacios de cuadrícula que fue  previamente interactuable

433
00:17:56,240 --> 00:17:59,340
sin redes neuronales

434
00:17:59,340 --> 00:18:01,080
um así que esa fue la primera solución

435
00:18:01,080 --> 00:18:03,840
entonces la segunda solución es esa

436
00:18:03,840 --> 00:18:06,000
um entonces en la primera solución se arregló

437
00:18:06,000 --> 00:18:07,980
que solo obtienes esta referencia privada pasada

438
00:18:07,980 --> 00:18:09,539
no obtienes ninguna otra

439
00:18:09,539 --> 00:18:10,919
información solo obtienes tu

440
00:18:10,919 --> 00:18:12,480
información sobre el  Estado de objetivo final

441
00:18:12,480 --> 00:18:15,120
y todo lo que obtiene es el modelo del

442
00:18:15,120 --> 00:18:18,240
entorno que aprendió y

443
00:18:18,240 --> 00:18:21,059
básicamente tiene que tomar decisiones, pero la

444
00:18:21,059 --> 00:18:22,799
segunda solución, por supuesto, es que, si se le

445
00:18:22,799 --> 00:18:24,600
permite, puede intentar aprender una

446
00:18:24,600 --> 00:18:26,100
preferencia de orgullo que sea significativa

447
00:18:26,100 --> 00:18:28,620
como la que nosotros  vi en las

448
00:18:28,620 --> 00:18:31,740
diapositivas anteriores que también tiene información sobre

449
00:18:31,740 --> 00:18:33,960
los otros estados, pero ¿cómo se

450
00:18:33,960 --> 00:18:35,400
aprende correctamente? Entonces

451
00:18:35,400 --> 00:18:38,039
hay un trabajo seminal de la

452
00:18:38,039 --> 00:18:40,440
literatura de control óptimo que habla sobre el

453
00:18:40,440 --> 00:18:43,380
cálculo eficiente de acciones óptimas

454
00:18:43,380 --> 00:18:45,900
y en ese trabajo hay una cantidad

455
00:18:45,900 --> 00:18:47,760
similar a nuestra  preferencia previa que se

456
00:18:47,760 --> 00:18:49,500
llama la función de deseabilidad, por

457
00:18:49,500 --> 00:18:52,200
ejemplo, en este mundo de cuadrícula,

458
00:18:52,200 --> 00:18:54,240
um aquí, los colores más oscuros son más preferidos,

459
00:18:54,240 --> 00:18:56,400
por lo que si esto cruza su oro final, indique

460
00:18:56,400 --> 00:18:58,740
qué está tratando de hacer el agente en este documento,

461
00:18:58,740 --> 00:19:01,980
o dicho método de aprendizaje en

462
00:19:01,980 --> 00:19:04,580
este documento es  intentar aprender esta

463
00:19:04,580 --> 00:19:06,900
función de deseabilidad de la manera más óptima

464
00:19:06,900 --> 00:19:09,059
posible y lo que se ha demostrado en este

465
00:19:09,059 --> 00:19:12,660
documento es que si intenta aprender la

466
00:19:12,660 --> 00:19:15,179
función de deseabilidad usando una

467
00:19:15,179 --> 00:19:18,120
regla de aprendizaje particular, es computacionalmente mucho

468
00:19:18,120 --> 00:19:20,340
más eficiente que incluso el aprendizaje Q,

469
00:19:20,340 --> 00:19:22,919
que es un bien-  conocido

470
00:19:22,919 --> 00:19:24,960
algoritmo de aprendizaje por refuerzo, por lo que el aprendizaje Q es un

471
00:19:24,960 --> 00:19:27,179


472
00:19:27,179 --> 00:19:29,520
algoritmo computacionalmente óptimo bien conocido, pero en este documento esa

473
00:19:29,520 --> 00:19:31,140
regla de aprendizaje particular para aprender

474
00:19:31,140 --> 00:19:32,880
este tipo de función de deseabilidad es

475
00:19:32,880 --> 00:19:35,539
mucho más rápida y esta aproximación

476
00:19:35,539 --> 00:19:38,460
representa qué tan diferente es de la

477
00:19:38,460 --> 00:19:40,559
función de deseabilidad óptima, por lo que esto

478
00:19:40,559 --> 00:19:42,480
la función de deseabilidad no es más que nuestra

479
00:19:42,480 --> 00:19:45,179
preferencia previa y,

480
00:19:45,179 --> 00:19:48,600
como se mencionó, el aprendizaje dicho es más

481
00:19:48,600 --> 00:19:50,100
eficiente que el aprendizaje de la

482
00:19:50,100 --> 00:19:53,039
función Q en el aprendizaje Q, por lo que

483
00:19:53,039 --> 00:19:55,860
esta es la regla de aprendizaje particular que

484
00:19:55,860 --> 00:19:57,600
depende de la recompensa que obtiene

485
00:19:57,600 --> 00:19:59,820
del entorno y en esta

486
00:19:59,820 --> 00:20:01,860
cuadrícula particular. Entorno mundial

487
00:20:01,860 --> 00:20:03,539
solo le estamos dando una recompensa en el último paso,

488
00:20:03,539 --> 00:20:05,220
que es similar a la preferencia de amigo escaso,

489
00:20:05,220 --> 00:20:08,580
el agente básicamente no obtiene ninguna

490
00:20:08,580 --> 00:20:11,400
recompensa hasta que alcanza ese

491
00:20:11,400 --> 00:20:14,760
objetivo final Estado y con esta regla de aprendizaje

492
00:20:14,760 --> 00:20:17,640
que tiene un parámetro ETA que

493
00:20:17,640 --> 00:20:20,100
controla qué tan rápido o lento

494
00:20:20,100 --> 00:20:22,980
esto  El aprendizaje sucede, así que básicamente

495
00:20:22,980 --> 00:20:24,200
tratamos de

496
00:20:24,200 --> 00:20:26,880
estudiar el efecto de este

497
00:20:26,880 --> 00:20:29,340
parámetro de aprendizaje Rita, pero lo que observamos es

498
00:20:29,340 --> 00:20:32,400
que es muy robusto, puede aprender la

499
00:20:32,400 --> 00:20:35,059
preferencia previa de manera confiable incluso con

500
00:20:35,059 --> 00:20:38,700
valores variables de este

501
00:20:38,700 --> 00:20:41,580
parámetro de aprendizaje y lo que vemos es que el

502
00:20:41,580 --> 00:20:43,620
agente es capaz  Para aprender un

503
00:20:43,620 --> 00:20:45,539
desempeño previo significativo a lo largo del tiempo muy rápido

504
00:20:45,539 --> 00:20:48,600
y usando una preferencia principal tan significativa,

505
00:20:48,600 --> 00:20:50,700
entonces el agente no tiene que

506
00:20:50,700 --> 00:20:53,580
planificar mucho, puede administrar un

507
00:20:53,580 --> 00:20:56,160
Comportamiento óptimo o un Comportamiento con un propósito con

508
00:20:56,160 --> 00:20:59,700
muy poco tiempo Horizontes de planificación y

509
00:20:59,700 --> 00:21:02,460
dadas estas dos soluciones podríamos

510
00:21:02,460 --> 00:21:04,679
escalar el algoritmo de inferencia activo para la

511
00:21:04,679 --> 00:21:07,919
toma de decisiones y hablar sobre la

512
00:21:07,919 --> 00:21:11,400
eficiencia computacional, vimos que

513
00:21:11,400 --> 00:21:13,320
el método de programación dinámica podría

514
00:21:13,320 --> 00:21:16,440
plantar 30 pasos de tiempo en el futuro,

515
00:21:16,440 --> 00:21:18,360
con solo una complejidad computacional

516
00:21:18,360 --> 00:21:21,120
de mil en comparación con, digamos, 10 elevado a

517
00:21:21,120 --> 00:21:23,700
68 para sofisticados  inferencia

518
00:21:23,700 --> 00:21:26,880
y el segundo método que aprende la

519
00:21:26,880 --> 00:21:29,580
preferencia previa, uh, que llamamos

520
00:21:29,580 --> 00:21:32,340
inferencia activa y solo necesita planificar un

521
00:21:32,340 --> 00:21:34,740
paso adelante, por lo que es mucho más

522
00:21:34,740 --> 00:21:36,919
eficiente desde el punto de vista computacional en ese sentido,

523
00:21:36,919 --> 00:21:39,659
pero tiene que aprender, por lo que en el

524
00:21:39,659 --> 00:21:41,640
método DPFE no estamos aprendiendo  estamos usando

525
00:21:41,640 --> 00:21:43,799
los lugares por preferencia y haciendo toda la

526
00:21:43,799 --> 00:21:44,520


527
00:21:44,520 --> 00:21:46,500
profundidad de la planificación y en el otro

528
00:21:46,500 --> 00:21:48,240
método estamos dejando que el agente aprenda

529
00:21:48,240 --> 00:21:50,280
esto por preferencia, pero luego podemos ahorrar

530
00:21:50,280 --> 00:21:53,280
mucho en la planificación porque sabe mucho de lo que tiene que

531
00:21:53,280 --> 00:21:57,299
hacer a tiempo de forma

532
00:21:57,299 --> 00:22:00,179
gráfica.  podemos ver que, um,

533
00:22:00,179 --> 00:22:01,799
el método DPFE es realmente

534
00:22:01,799 --> 00:22:04,020
eficiente desde el punto de vista computacional y cuando se

535
00:22:04,020 --> 00:22:06,600
representa contra el tiempo, uh, en el AI 50,

536
00:22:06,600 --> 00:22:08,520
igual a un método,

537
00:22:08,520 --> 00:22:10,740
um, es básicamente computacionalmente

538
00:22:10,740 --> 00:22:12,659
más barato

539
00:22:12,659 --> 00:22:16,220
y sí, por lo que escala, uh, muy

540
00:22:16,220 --> 00:22:19,860
fascinantemente bien, uh, con Higher and

541
00:22:19,860 --> 00:22:21,720
Higher y la

542
00:22:21,720 --> 00:22:24,120
complejidad del  entorno, así que lo

543
00:22:24,120 --> 00:22:27,600
probamos, eh, estos métodos en

544
00:22:27,600 --> 00:22:28,380
um,

545
00:22:28,380 --> 00:22:31,020
espacios de estado muy grandes, como digamos 900

546
00:22:31,020 --> 00:22:32,000
estados

547
00:22:32,000 --> 00:22:33,840
en comparación con

548
00:22:33,840 --> 00:22:36,120
um, espacios de estado que tienen una dimensión de,

549
00:22:36,120 --> 00:22:38,640
digamos, 5 o 10 en la literatura de influencia activa que se suele ver,

550
00:22:38,640 --> 00:22:40,559


551
00:22:40,559 --> 00:22:43,200
um, así que quiero enfatizar que

552
00:22:43,200 --> 00:22:44,760
somos  sin usar ninguna red neuronal

553
00:22:44,760 --> 00:22:47,039
aquí, estamos usando um

554
00:22:47,039 --> 00:22:49,740
agentes de inferencia activos explicables que están

555
00:22:49,740 --> 00:22:52,200
haciendo todas las multiplicaciones de matriz necesarias

556
00:22:52,200 --> 00:22:53,820
para que tengamos acceso

557
00:22:53,820 --> 00:22:55,140
y

558
00:22:55,140 --> 00:22:56,220
um

559
00:22:56,220 --> 00:22:58,620
explicabilidad a cada cálculo que

560
00:22:58,620 --> 00:23:00,179
se lleva a cabo en esto en estos

561
00:23:00,179 --> 00:23:02,280
algoritmos y cuando se prueba en estas

562
00:23:02,280 --> 00:23:04,559
cuadrículas primero validamos esto  en una

563
00:23:04,559 --> 00:23:06,780
cuadrícula más pequeña con subestimaciones y

564
00:23:06,780 --> 00:23:08,580
observamos que,

565
00:23:08,580 --> 00:23:11,220
en comparación con los

566
00:23:11,220 --> 00:23:12,780
algoritmos de aprendizaje por refuerzo de Benchmark, como el aprendizaje en cola

567
00:23:12,780 --> 00:23:15,059
y dynaq dynacy, es un

568
00:23:15,059 --> 00:23:17,760
algoritmo de aprendizaje por refuerzo basado en modelos y

569
00:23:17,760 --> 00:23:20,280
comparamos nuestros nuevos agentes propuestos, que

570
00:23:20,280 --> 00:23:24,419
son DPFE y aif, y vimos un rendimiento realmente bueno

571
00:23:24,419 --> 00:23:27,900
y  el agente aif es un poco

572
00:23:27,900 --> 00:23:29,220
peor y eso se debe a que solo está

573
00:23:29,220 --> 00:23:31,080
planificando un paso adelante, pero

574
00:23:31,080 --> 00:23:34,500
el agente DPFE que planifica a tiempo completo

575
00:23:34,500 --> 00:23:36,419
está funcionando tan bien como

576
00:23:36,419 --> 00:23:37,919
comparando algoritmos de aprendizaje personal

577
00:23:37,919 --> 00:23:41,039
y lo probamos con

578
00:23:41,039 --> 00:23:44,640
cuadrículas más grandes y más débiles y cuando

579
00:23:44,640 --> 00:23:47,100
introdujimos la estocasticidad en  el

580
00:23:47,100 --> 00:23:49,620
estado dorado en el sentido de que cuando el agente

581
00:23:49,620 --> 00:23:53,039
tuvo que navegar a

582
00:23:53,039 --> 00:23:54,480
un

583
00:23:54,480 --> 00:23:56,520
estado dorado estocástico, cambiamos los

584
00:23:56,520 --> 00:23:59,460
estados dorados cada 10 episodios y

585
00:23:59,460 --> 00:24:01,260
lo que observamos es que la cola de Dyna

586
00:24:01,260 --> 00:24:04,140
tomó más tiempo que nuestro agente bpfe para

587
00:24:04,140 --> 00:24:07,200
recuperarse y hacer  bueno, el

588
00:24:07,200 --> 00:24:09,059
agente DPFE en este entorno estocástico

589
00:24:09,059 --> 00:24:11,280
se desempeñó realmente bien incluso mejor que

590
00:24:11,280 --> 00:24:13,620
los agentes de la dinastía y también se pudo ver

591
00:24:13,620 --> 00:24:16,500
que la fase de IA se está recuperando

592
00:24:16,500 --> 00:24:19,140
más rápido, pero no tan bien como los otros

593
00:24:19,140 --> 00:24:22,500
agentes, así que básicamente ese fue el resultado

594
00:24:22,500 --> 00:24:25,200
en el papel y el  métodos Así que sí,

595
00:24:25,200 --> 00:24:27,960
gracias por escuchar y estoy abierto a las

596
00:24:27,960 --> 00:24:30,380
discusiones, está

597
00:24:31,640 --> 00:24:34,740
bien, guau, genial, está bien,

598
00:24:34,740 --> 00:24:36,360


599
00:24:36,360 --> 00:24:38,520


600
00:24:38,520 --> 00:24:43,200
justo cuando comenzamos la

601
00:24:43,200 --> 00:24:44,460
discusión,

602
00:24:44,460 --> 00:24:47,280
um, si alguien quiere agregar algo primero, ¿

603
00:24:47,280 --> 00:24:50,220
cómo llegaste a trabajar en este

604
00:24:50,220 --> 00:24:52,740
proyecto? ¿Estabas estudiando?

605
00:24:52,740 --> 00:24:54,720
inferencia activa y llegó a esta pregunta

606
00:24:54,720 --> 00:24:57,900
como interesante o estaba trabajando

607
00:24:57,900 --> 00:25:00,179
en la planificación y llegó a la

608
00:25:00,179 --> 00:25:03,059
inferencia activa como método,

609
00:25:03,059 --> 00:25:05,159
um sí, un poco de información sobre

610
00:25:05,159 --> 00:25:08,400
mí, así que estudié física tanto en mi

611
00:25:08,400 --> 00:25:11,340
licenciatura como en la publicación y hacia el

612
00:25:11,340 --> 00:25:13,080
final de  después de graduarme me

613
00:25:13,080 --> 00:25:15,120
interesé en cosas como la teoría de juegos

614
00:25:15,120 --> 00:25:17,880
y el aprendizaje reinponible y me uní a uh

615
00:25:17,880 --> 00:25:20,880
para un doctorado conjunto uh con el profesor Adil

616
00:25:20,880 --> 00:25:23,100
y el profesor Manoj, entonces el profesor

617
00:25:23,100 --> 00:25:25,200
Manoj es una persona de teoría de control y un

618
00:25:25,200 --> 00:25:28,140
trato es un neurocientífico y al

619
00:25:28,140 --> 00:25:30,600
comienzo de mi  Doctorado Empecé a leer

620
00:25:30,600 --> 00:25:34,020
literatura de inferencia activa y quería

621
00:25:34,020 --> 00:25:37,260
implementar eso en problemas y

622
00:25:37,260 --> 00:25:39,840
siempre me fascinó la

623
00:25:39,840 --> 00:25:42,720
inferencia activa explicable, eh, sobre esta idea de

624
00:25:42,720 --> 00:25:44,700
energía libre esperada tratando de minimizar el

625
00:25:44,700 --> 00:25:46,860
riesgo y la ambigüedad esperada.

626
00:25:46,860 --> 00:25:49,740


627
00:25:49,740 --> 00:25:52,020
también poder decir cómo funcionan es lo

628
00:25:52,020 --> 00:25:54,419
que me fascinó en la influencia activa

629
00:25:54,419 --> 00:25:56,820
e inicialmente trato de implementarlos

630
00:25:56,820 --> 00:26:00,179
y hay un artículo de conferencia que

631
00:26:00,179 --> 00:26:03,720
publicamos en el que lo comparamos para una

632
00:26:03,720 --> 00:26:06,419
tarea de cuadrícula similar y luego

633
00:26:06,419 --> 00:26:08,100
enfrenté este problema de escalar

634
00:26:08,100 --> 00:26:10,620
inferencia activa y luego comencé a trabajar en

635
00:26:10,620 --> 00:26:12,659
inferencias sofisticadas,

636
00:26:12,659 --> 00:26:15,539
um, sí, así que básicamente estos métodos surgieron

637
00:26:15,539 --> 00:26:17,580
de la necesidad de que quería escalar

638
00:26:17,580 --> 00:26:21,539
el mapa y siempre tuve un control constante

639
00:26:21,539 --> 00:26:22,919
al usar

640
00:26:22,919 --> 00:26:25,559
um, inferencia activa profunda porque,

641
00:26:25,559 --> 00:26:28,020
um, no quería usar  redes neuronales

642
00:26:28,020 --> 00:26:30,539
para hacer la planificación Porque el

643
00:26:30,539 --> 00:26:32,100
aprendizaje por refuerzo profundo en sí mismo es un

644
00:26:32,100 --> 00:26:34,140
campo enorme y,

645
00:26:34,140 --> 00:26:37,080
um, si solo se trata de escalar la

646
00:26:37,080 --> 00:26:39,240
inferencia activa, entonces tal vez solo haga un

647
00:26:39,240 --> 00:26:41,820
aprendizaje por refuerzo profundo y eso es lo que

648
00:26:41,820 --> 00:26:43,860
pensé, sí, así que eso es básicamente el

649
00:26:43,860 --> 00:26:45,659
trasfondo y sí,

650
00:26:45,659 --> 00:26:48,720
así es como funciona.  salió

651
00:26:48,720 --> 00:26:50,880
bien. Iré primero a una pregunta en

652
00:26:50,880 --> 00:26:52,559
el chat en vivo y

653
00:26:52,559 --> 00:26:54,779
probablemente discutiremos varios aspectos porque

654
00:26:54,779 --> 00:26:57,720
hubo mucho en su presentación, por lo que

655
00:26:57,720 --> 00:27:01,980
NL Dawn escribe: Me pregunto cuando se trata de

656
00:27:01,980 --> 00:27:04,620
calcular la energía libre esperada en

657
00:27:04,620 --> 00:27:07,679
un  Time Horizon, qué tipo de aproximación de campo medio

658
00:27:07,679 --> 00:27:11,039
se usó para factorizar Q de

659
00:27:11,039 --> 00:27:13,020
s

660
00:27:13,020 --> 00:27:16,100
store, así

661
00:27:19,980 --> 00:27:23,040
que asumo que la pregunta es sobre

662
00:27:23,040 --> 00:27:24,299
[Música]

663
00:27:24,299 --> 00:27:28,799
la energía libre esperada en DPFE y

664
00:27:28,799 --> 00:27:31,380
para calcular esto básicamente,

665
00:27:31,380 --> 00:27:32,159
um,

666
00:27:32,159 --> 00:27:35,279
así que en mis simulaciones uso la

667
00:27:35,279 --> 00:27:39,120
propagación de creencias para esto.  cola de creencias y

668
00:27:39,120 --> 00:27:41,460
también puede usar el paso de

669
00:27:41,460 --> 00:27:43,140
mensajes variacionales o el paso de mensajes marginales,

670
00:27:43,140 --> 00:27:47,279
eso no es un problema, pero

671
00:27:47,400 --> 00:27:50,580
una vez que tenga esta cola de creencias, ¿

672
00:27:50,580 --> 00:27:52,740


673
00:27:52,740 --> 00:27:55,340


674
00:27:56,940 --> 00:27:59,900


675
00:27:59,940 --> 00:28:04,260


676
00:28:04,260 --> 00:28:07,520
qué hace bien?  es un vector caliente, por lo que

677
00:28:07,520 --> 00:28:11,220
para tomar decisiones usa la creencia de

678
00:28:11,220 --> 00:28:13,260
que sale de su paso de percepción

679
00:28:13,260 --> 00:28:16,380
en inferencia activa, pero para imaginar que

680
00:28:16,380 --> 00:28:18,720
estas son tablas duras donde hay un

681
00:28:18,720 --> 00:28:22,020
vector caliente, por lo tanto, dado que tiene en su

682
00:28:22,020 --> 00:28:25,380
modelo generativo tiene 10 estados uh su

683
00:28:25,380 --> 00:28:27,900
las colas que usa son

684
00:28:27,900 --> 00:28:29,100


685
00:28:29,100 --> 00:28:32,220
pistas precisas para la planificación, pero para la

686
00:28:32,220 --> 00:28:33,840
toma de decisiones usa la

687
00:28:33,840 --> 00:28:36,299
cola de aproximación de campo medio impreciso impreciso

688
00:28:36,299 --> 00:28:38,460
que obtiene del paso de percepción, así que

689
00:28:38,460 --> 00:28:40,679
no sé si eso responde a la

690
00:28:40,679 --> 00:28:42,059
pregunta,

691
00:28:42,059 --> 00:28:44,880
pero tal vez yo también quiero pensar

692
00:28:44,880 --> 00:28:46,919
También necesito pensar más sobre las

693
00:28:46,919 --> 00:28:49,200
aproximaciones que pueden haber en los

694
00:28:49,200 --> 00:28:50,880
pasos,

695
00:28:50,880 --> 00:28:53,700
genial, sí, pueden escribir más

696
00:28:53,700 --> 00:28:56,460
si quieren, um, hablemos un poco

697
00:28:56,460 --> 00:29:00,419
más en general sobre el aprendizaje de preferencias,

698
00:29:00,419 --> 00:29:02,700
por lo que en el contexto del

699
00:29:02,700 --> 00:29:05,940
modelo generativo de inferencia activa,  tener una

700
00:29:05,940 --> 00:29:08,279
mediación entre las observaciones en los

701
00:29:08,279 --> 00:29:10,020
estados ocultos y el aprendizaje tiene

702
00:29:10,020 --> 00:29:12,480
mucho sentido se trata de aprender el

703
00:29:12,480 --> 00:29:14,220
mapeo entre las observaciones en los

704
00:29:14,220 --> 00:29:15,779
estados ocultos del mundo y luego tenemos

705
00:29:15,779 --> 00:29:18,240
blearning aprender las consecuencias de la

706
00:29:18,240 --> 00:29:20,399
acción y cómo cambian las cosas a través del

707
00:29:20,399 --> 00:29:21,419
tiempo

708
00:29:21,419 --> 00:29:24,659
y el aprendizaje de preferencias es aprender en  c

709
00:29:24,659 --> 00:29:27,960
c y ha resaltado que esta

710
00:29:27,960 --> 00:29:29,700
es una

711
00:29:29,700 --> 00:29:31,340


712
00:29:31,340 --> 00:29:34,320
variable muy interesante para aprender

713
00:29:34,320 --> 00:29:38,100
y tengo curiosidad por saber cómo aprendemos

714
00:29:38,100 --> 00:29:41,159
a aprender lo correcto cómo sabemos

715
00:29:41,159 --> 00:29:42,960
que estamos aprendiendo una preferencia adaptativa

716
00:29:42,960 --> 00:29:44,399


717
00:29:44,399 --> 00:29:46,200
y luego cómo  ¿Ese

718
00:29:46,200 --> 00:29:48,720
aprendizaje de preferencia reduce la sobrecarga cognitiva o la

719
00:29:48,720 --> 00:29:50,820
complejidad computacional?

720
00:29:50,820 --> 00:29:53,460
Sí, genial,

721
00:29:53,460 --> 00:29:54,480
entonces,

722
00:29:54,480 --> 00:29:57,179
si está tratando de aprender una

723
00:29:57,179 --> 00:29:59,940
preferencia de oración, eso supone que

724
00:29:59,940 --> 00:30:01,559
hay algo que Chase o hay

725
00:30:01,559 --> 00:30:04,500
algo que maximizar como una recompensa, así que

726
00:30:04,500 --> 00:30:06,779
en esto digamos uh en un

727
00:30:06,779 --> 00:30:08,340
aprendizaje de refuerzo  establecer que hay una recompensa clara

728
00:30:08,340 --> 00:30:09,840
que proviene del entorno que

729
00:30:09,840 --> 00:30:12,960
está tratando de maximizar y decir que para

730
00:30:12,960 --> 00:30:15,000
esta cuadrícula obtiene esa recompensa solo en

731
00:30:15,000 --> 00:30:17,220
el último paso, que es eso,

732
00:30:17,220 --> 00:30:19,020
eso es lo que hace que este problema sea difícil, así que

733
00:30:19,020 --> 00:30:22,500
si está obteniendo recompensas en cada

734
00:30:22,500 --> 00:30:25,140
paso de tiempo, entonces básicamente sabes qué hacer,

735
00:30:25,140 --> 00:30:28,020
solo tengo que buscar esa recompensa

736
00:30:28,020 --> 00:30:30,419
en cada paso de tiempo correcto, pero aquí es

737
00:30:30,419 --> 00:30:32,880
posible que tengas que dar 15 pasos de tiempo

738
00:30:32,880 --> 00:30:36,059
por delante para obtener esa recompensa y eso

739
00:30:36,059 --> 00:30:39,659
básicamente es difícil de hacer aquí um si  Lo estás

740
00:30:39,659 --> 00:30:41,520
intentando porque estoy tratando de

741
00:30:41,520 --> 00:30:43,020
aprender una preferencia previa.

742
00:30:43,020 --> 00:30:44,820
Debería haber una estructura de recompensas

743
00:30:44,820 --> 00:30:47,940
que exista en el entorno

744
00:30:47,940 --> 00:30:49,919
si al entorno no le importa lo que

745
00:30:49,919 --> 00:30:52,200
hago o si no puedo definir lo que es

746
00:30:52,200 --> 00:30:54,840
bueno o malo.  entonces no tiene sentido

747
00:30:54,840 --> 00:30:56,340
aprender la preferencia anterior, así que

748
00:30:56,340 --> 00:30:57,840
aquí,

749
00:30:57,840 --> 00:30:59,399
la recompensa es lo que controla el

750
00:30:59,399 --> 00:31:01,559
aprendizaje de la diferencia de Sprite y

751
00:31:01,559 --> 00:31:03,600
lo bueno es que incluso si solo

752
00:31:03,600 --> 00:31:06,539
obtengo la recompensa en el último paso,

753
00:31:06,539 --> 00:31:09,240
tengo mis matrices B y  Tengo

754
00:31:09,240 --> 00:31:11,340
experiencia en la transición de

755
00:31:11,340 --> 00:31:12,659
diferentes estados,

756
00:31:12,659 --> 00:31:14,760
um, que llegué a este estado dorado final

757
00:31:14,760 --> 00:31:16,860
y

758
00:31:16,860 --> 00:31:19,440
este algoritmo que estamos usando o la

759
00:31:19,440 --> 00:31:21,539
regla de aprendizaje que estamos usando es

760
00:31:21,539 --> 00:31:23,820
precisamente aprender algo similar en

761
00:31:23,820 --> 00:31:26,340
control óptimo ese documento que presenté

762
00:31:26,340 --> 00:31:27,539
que se llama la

763
00:31:27,539 --> 00:31:30,539
función de deseabilidad  y dado que tiene esta

764
00:31:30,539 --> 00:31:32,760
función de conveniencia, imagine que

765
00:31:32,760 --> 00:31:36,120
tal vez estoy comenzando desde este estado, entonces

766
00:31:36,120 --> 00:31:37,860
solo tengo que mirar a mis vecinos más cercanos

767
00:31:37,860 --> 00:31:40,399
para tomar una decisión

768
00:31:40,399 --> 00:31:44,279
si el

769
00:31:44,279 --> 00:31:46,620
estado indicado debajo del estado es más

770
00:31:46,620 --> 00:31:48,899
preferido que solo tengo que planificar uno

771
00:31:48,899 --> 00:31:50,520
tiempo por delante y esa es la

772
00:31:50,520 --> 00:31:52,380
decisión óptima que debo tomar,

773
00:31:52,380 --> 00:31:54,059
así que aprender esta preferencia de Pride

774
00:31:54,059 --> 00:31:55,919
reduce la carga cognitiva en el sentido de

775
00:31:55,919 --> 00:31:57,419
que solo ahora estoy mirando a los vecinos más cercanos.

776
00:31:57,419 --> 00:31:59,760
No tengo que planificar todo el

777
00:31:59,760 --> 00:32:01,799
camino hasta este buen estado final.

778
00:32:01,799 --> 00:32:04,799
y aprenderé esto de la manera más eficiente

779
00:32:04,799 --> 00:32:07,260
posible porque, en primer lugar, es un

780
00:32:07,260 --> 00:32:09,659
algoritmo garantizado, probamos su

781
00:32:09,659 --> 00:32:13,320
robustez y también está informado por

782
00:32:13,320 --> 00:32:14,580
la recompensa que obtengo del

783
00:32:14,580 --> 00:32:15,659
entorno y, en caso

784
00:32:15,659 --> 00:32:20,100
afirmativo, si hay alguna forma de

785
00:32:20,100 --> 00:32:22,860
definir.  lo que se prefiere, entonces

786
00:32:22,860 --> 00:32:24,840
tiene la garantía de aprender

787
00:32:24,840 --> 00:32:26,520
amigos privados que son significativos

788
00:32:26,520 --> 00:32:28,559
con este algoritmo,

789
00:32:28,559 --> 00:32:31,559
por lo que si solo se utilizan los vecinos más cercanos

790
00:32:31,559 --> 00:32:34,260
y la inferencia de un paso de tiempo, ¿

791
00:32:34,260 --> 00:32:37,320
qué evita que este tipo de

792
00:32:37,320 --> 00:32:39,360
agente de aprendizaje de preferencias se quede

793
00:32:39,360 --> 00:32:43,158
atrapado en un Optima local?

794
00:32:43,320 --> 00:32:47,520
no habrá Optimas locales

795
00:32:47,520 --> 00:32:50,340
aquí ese es el punto como

796
00:32:50,340 --> 00:32:52,860
um ¿por qué habría un Optima local eh

797
00:32:52,860 --> 00:32:57,059
si lo estoy aprendiendo usando recompensas eh

798
00:32:57,059 --> 00:33:00,120
sí entonces si hay Optima local entonces

799
00:33:00,120 --> 00:33:02,159
se quedará atascado en el

800
00:33:02,159 --> 00:33:05,460
Optima local pero ganó  't be one uh si

801
00:33:05,460 --> 00:33:07,440
estás aprendiendo de esta manera porque

802
00:33:07,440 --> 00:33:08,760
lo estás aprendiendo de tu propia

803
00:33:08,760 --> 00:33:11,940
experiencia y cómo obtuviste la recompensa en ese

804
00:33:11,940 --> 00:33:14,220
momento uh en algún momento y lo que hemos

805
00:33:14,220 --> 00:33:16,980
observado es que uh es muy

806
00:33:16,980 --> 00:33:17,760
um

807
00:33:17,760 --> 00:33:20,399
gradual y no hay fallas  u

808
00:33:20,399 --> 00:33:23,880
Optimas locales cuando aprendes, por lo que

809
00:33:23,880 --> 00:33:27,840
es como volver a llenar una

810
00:33:27,840 --> 00:33:30,179
preferencia

811
00:33:30,179 --> 00:33:33,539
para que pueda haber un camino suave,

812
00:33:33,539 --> 00:33:36,779
sí, hacia el objetivo distal,

813
00:33:36,779 --> 00:33:39,480
sí, así que en la animación hace que

814
00:33:39,480 --> 00:33:42,299
parezca una sensación de espalda, pero en

815
00:33:42,299 --> 00:33:44,279
realidad estás  aprendiendo de tu

816
00:33:44,279 --> 00:33:45,360
experiencia,

817
00:33:45,360 --> 00:33:46,620
um

818
00:33:46,620 --> 00:33:49,980
adelante en el tiempo, así que observé una

819
00:33:49,980 --> 00:33:51,480
recompensa cuando hice la transición de este

820
00:33:51,480 --> 00:33:53,100
estado a otro, así que esto debe ser bueno,

821
00:33:53,100 --> 00:33:55,860
eh, entonces en el siguiente paso de tiempo,

822
00:33:55,860 --> 00:33:58,559
digo, está bien, esta fecha es responsable de

823
00:33:58,559 --> 00:34:00,419
llevarme allí.  así que esto también podría ser bueno,

824
00:34:00,419 --> 00:34:03,120
pero no tan bueno como el otro,

825
00:34:03,120 --> 00:34:05,100
así que parece que está aprendiendo hacia atrás,

826
00:34:05,100 --> 00:34:07,799
pero en realidad está aprendiendo de la

827
00:34:07,799 --> 00:34:12,000
experiencia real um en t más uno, está bien, ya

828
00:34:13,500 --> 00:34:15,119


829
00:34:15,119 --> 00:34:16,980
sabes, de esa manera

830
00:34:16,980 --> 00:34:20,339
um no puedes tener Maximas locales porque

831
00:34:20,339 --> 00:34:21,300
um,

832
00:34:21,300 --> 00:34:24,119
sí, esta es la regla de aprendizaje que hace

833
00:34:24,119 --> 00:34:25,859
eso, así que no sé cómo responderla de manera

834
00:34:25,859 --> 00:34:29,219
más sistemática.

835
00:34:29,219 --> 00:34:33,000


836
00:34:33,000 --> 00:34:35,399


837
00:34:35,399 --> 00:34:37,560


838
00:34:37,560 --> 00:34:40,080


839
00:34:40,080 --> 00:34:41,159


840
00:34:41,159 --> 00:34:43,020
pregunta

841
00:34:43,020 --> 00:34:46,080
entonces, hay un artículo que salió de

842
00:34:46,080 --> 00:34:48,659
nuestro laboratorio donde las neuronas están

843
00:34:48,659 --> 00:34:51,359
aprendiendo el juego de pong

844
00:34:51,359 --> 00:34:52,980
um, así que si el artículo se

845
00:34:52,980 --> 00:34:55,260
llama dist brain eh y el dispositivo se

846
00:34:55,260 --> 00:34:57,000
llama tensión y lo que han

847
00:34:57,000 --> 00:34:58,740
logrado es que se las arreglan  para

848
00:34:58,740 --> 00:35:00,300
cultivar neuronas

849
00:35:00,300 --> 00:35:03,420
en un chip de silicio y le

850
00:35:03,420 --> 00:35:04,020


851
00:35:04,020 --> 00:35:08,520
dieron una buena señal de retroalimentación cuando

852
00:35:08,520 --> 00:35:11,400
abordó con éxito la pelota o

853
00:35:11,400 --> 00:35:13,880
jugó bien el juego y le dieron una

854
00:35:13,880 --> 00:35:15,720
sorpresa cuando

855
00:35:15,720 --> 00:35:18,119
cometió errores y lo que vimos es

856
00:35:18,119 --> 00:35:19,560
que

857
00:35:19,560 --> 00:35:22,260
en el papel lo que  ver es que

858
00:35:22,260 --> 00:35:24,140
aprende a jugar el juego con el tiempo correcto

859
00:35:24,140 --> 00:35:27,359
y en tal escenario imagina que

860
00:35:27,359 --> 00:35:29,880
si encuentro decir algo positivo en

861
00:35:29,880 --> 00:35:33,359
el mundo entonces podría asociar

862
00:35:33,359 --> 00:35:35,520
um lo que es bueno con los estados que

863
00:35:35,520 --> 00:35:37,380
observé en el pasado y así sucesivamente  así que

864
00:35:37,380 --> 00:35:38,880
aprendí

865
00:35:38,880 --> 00:35:39,660


866
00:35:39,660 --> 00:35:42,119
paso a paso lo que es bueno o malo y

867
00:35:42,119 --> 00:35:44,700
esa es una hipótesis razonable para hacer,

868
00:35:44,700 --> 00:35:46,619
así que

869
00:35:46,619 --> 00:35:47,220


870
00:35:47,220 --> 00:35:51,300
si quiero decir ponerme en forma, entonces podría

871
00:35:51,300 --> 00:35:53,280
asociar ir al gimnasio

872
00:35:53,280 --> 00:35:54,660


873
00:35:54,660 --> 00:35:57,000
como algo bueno, entonces también podría

874
00:35:57,000 --> 00:35:59,099
asociar caminar al gimnasio.  como

875
00:35:59,099 --> 00:36:01,260
algo bueno, entonces podría asociar, digamos,

876
00:36:01,260 --> 00:36:03,900
usar mis zapatos como algo bueno, así que

877
00:36:03,900 --> 00:36:04,920


878
00:36:04,920 --> 00:36:06,960
aprender la preferencia previa de esa manera tiene

879
00:36:06,960 --> 00:36:10,079
sentido, diría, pero sí, esta es una

880
00:36:10,079 --> 00:36:11,640


881
00:36:11,640 --> 00:36:12,480


882
00:36:12,480 --> 00:36:14,820
solución computacional para el problema de la maldición de la

883
00:36:14,820 --> 00:36:17,040
dimensionalidad, pero probando esto en el

884
00:36:17,040 --> 00:36:19,619
real  El mundo es definitivamente uh lo que

885
00:36:19,619 --> 00:36:21,599
debemos hacer y

886
00:36:21,599 --> 00:36:24,119
um, sí, también espero hacer

887
00:36:24,119 --> 00:36:25,800
eso, está

888
00:36:25,800 --> 00:36:27,660
bien, déjame, déjame intentar ejecutar una

889
00:36:27,660 --> 00:36:29,760
situación del mundo real por ti y ver si esto

890
00:36:29,760 --> 00:36:32,040
si esto se conecta,

891
00:36:32,040 --> 00:36:35,099
um, así que queremos, queremos entregarnos.  es

892
00:36:35,099 --> 00:36:38,280
recompensado al entregar un ensayo que

893
00:36:38,280 --> 00:36:39,900
obtiene una calificación alta

894
00:36:39,900 --> 00:36:42,599
y, por lo tanto, hay muchos pasos entre

895
00:36:42,599 --> 00:36:45,540
comenzar con la idea del ensayo y

896
00:36:45,540 --> 00:36:48,839
ver ese resultado escaso preferido

897
00:36:48,839 --> 00:36:51,180
que es la calificación

898
00:36:51,180 --> 00:36:53,520
um y nosotros hacemos todo tipo de cosas y

899
00:36:53,520 --> 00:36:55,260
luego aprendemos está bien

900
00:36:55,260 --> 00:36:57,079
um  este en el que obtuve una buena calificación,

901
00:36:57,079 --> 00:36:59,940
estaba bien formateado

902
00:36:59,940 --> 00:37:02,880
y luego ese tipo ahora

903
00:37:02,880 --> 00:37:05,460
expandes el paraguas de tu preferencia

904
00:37:05,460 --> 00:37:07,800
y luego lo que me llevó a

905
00:37:07,800 --> 00:37:10,140
obtenerlo bien formateado, lo hice a tiempo

906
00:37:10,140 --> 00:37:12,900
y luego trabajas  todo el camino hasta

907
00:37:12,900 --> 00:37:16,579
la fase de ideación para que en el futuro

908
00:37:16,579 --> 00:37:20,640
pueda hacer una inferencia de un paso, sí,

909
00:37:20,640 --> 00:37:23,099
exactamente, y tomarlo paso a paso como

910
00:37:23,099 --> 00:37:24,180
una habilidad

911
00:37:24,180 --> 00:37:26,400
en lugar de tener que hacer

912
00:37:26,400 --> 00:37:28,740
una inferencia de 15 pasos de tiempo

913
00:37:28,740 --> 00:37:31,740
sobre todas las estructuras de árbol posibles

914
00:37:31,740 --> 00:37:35,180
para que tenga  usó sus

915
00:37:35,180 --> 00:37:39,240
aprendizajes incorporados para simplificar la

916
00:37:39,240 --> 00:37:43,680
estructura del problema exactamente, sí,

917
00:37:43,680 --> 00:37:45,540
y podemos ver las complejidades computacionales,

918
00:37:45,540 --> 00:37:47,220


919
00:37:47,220 --> 00:37:51,078
um nuevamente, de todas ellas,

920
00:37:51,359 --> 00:37:54,300
así que aquí CIF representa la

921
00:37:54,300 --> 00:37:56,760
inferencia activa clásica y para hacer el

922
00:37:56,760 --> 00:37:58,560
Horizonte completo de planificación,

923
00:37:58,560 --> 00:38:00,660
um, está alrededor  10 a la potencia 18. así que

924
00:38:00,660 --> 00:38:03,180
esto es para este ejemplo particular de cuadrícula

925
00:38:03,180 --> 00:38:07,140
con 100 estados y cuatro

926
00:38:07,140 --> 00:38:09,960
acciones disponibles así que esto es para un caso especial

927
00:38:09,960 --> 00:38:12,119
y solo quería poner números para poner las

928
00:38:12,119 --> 00:38:14,400
cosas en perspectiva así que para este

929
00:38:14,400 --> 00:38:16,500
ejemplo particular si estás tratando de

930
00:38:16,500 --> 00:38:18,960
hágalo con el espacio de políticas

931
00:38:18,960 --> 00:38:20,640
um, tendrá que hacer

932
00:38:20,640 --> 00:38:22,440
um 10 a la potencia 18 cálculos para

933
00:38:22,440 --> 00:38:25,380
un paso de planificación o en un

934
00:38:25,380 --> 00:38:28,380
um instancia en inferencia sofisticada

935
00:38:28,380 --> 00:38:30,900
es aún peor porque, eh, ahí tiene

936
00:38:30,900 --> 00:38:34,560
el espacio de estado También importa eh y eso

937
00:38:34,560 --> 00:38:37,140
ganó  no funciona, por lo que se suponía que esta tercera línea

938
00:38:37,140 --> 00:38:39,540
mostraría que incluso por un

939
00:38:39,540 --> 00:38:40,500
tiempo,

940
00:38:40,500 --> 00:38:42,599
um o aumentar lo suficiente dos, es realmente difícil

941
00:38:42,599 --> 00:38:44,280
hacer inferencias sofisticadas si

942
00:38:44,280 --> 00:38:47,400
tiene que hacer la planificación completa pero con

943
00:38:47,400 --> 00:38:48,960
programación dinámica cuando está planificando

944
00:38:48,960 --> 00:38:50,579
hacia atrás,

945
00:38:50,579 --> 00:38:52,500
um, usted  puede intentar hacer el

946
00:38:52,500 --> 00:38:54,420
horizonte completo de planificación

947
00:38:54,420 --> 00:38:56,520
um y eso es solo mil

948
00:38:56,520 --> 00:38:58,800
cálculos pero con

949
00:38:58,800 --> 00:39:01,380
preferencia de aprendizaje es incluso bajo uh cuando lo hace

950
00:39:01,380 --> 00:39:04,520
solo una vez Avance wow

951
00:39:04,520 --> 00:39:06,440
esto es bastante

952
00:39:06,440 --> 00:39:06,839
[Música]

953
00:39:06,839 --> 00:39:08,220
um

954
00:39:08,220 --> 00:39:12,000
bastante Stark y en el tiempo de bifurcación

955
00:39:12,000 --> 00:39:15,480
inferencia activa  trabajo en un

956
00:39:15,480 --> 00:39:17,640
flujo de modelo anterior, también vimos algunas

957
00:39:17,640 --> 00:39:19,859
estimaciones de complejidad computacional, pero

958
00:39:19,859 --> 00:39:22,260
creo que estas son realmente claras, lo

959
00:39:22,260 --> 00:39:25,020
primero que me hizo pensar es que

960
00:39:25,020 --> 00:39:28,820
nadie dijo que la sofisticación era barata,

961
00:39:28,820 --> 00:39:32,940
quiero decir, es astronómico lo costoso

962
00:39:32,940 --> 00:39:35,099
que es para

963
00:39:35,099 --> 00:39:37,380
um, tal vez incluso solo en  dos o tres o

964
00:39:37,380 --> 00:39:38,880
cuatro o cinco

965
00:39:38,880 --> 00:39:41,940
potencialmente comienzan a ponerse al día, por lo que

966
00:39:41,940 --> 00:39:44,040
está aumentando la complejidad de la

967
00:39:44,040 --> 00:39:45,720
planificación

968
00:39:45,720 --> 00:39:50,040
radicalmente, por lo que es muy

969
00:39:50,040 --> 00:39:50,780


970
00:39:50,780 --> 00:39:52,460
interesante

971
00:39:52,460 --> 00:39:56,280
pedagógicamente, ya que pensamos en como

972
00:39:56,280 --> 00:39:57,660
imaginamos

973
00:39:57,660 --> 00:39:59,940


974
00:39:59,940 --> 00:40:01,560
arquitecturas de inteligencia de inferencia activa,

975
00:40:01,560 --> 00:40:04,500
pero

976
00:40:04,500 --> 00:40:07,079
esto deja bastante claro que no es

977
00:40:07,079 --> 00:40:09,060
algo que puede simplemente enumerar,

978
00:40:09,060 --> 00:40:10,859


979
00:40:10,859 --> 00:40:13,380
por lo que creo que es muy,

980
00:40:13,380 --> 00:40:15,240
muy creativo e importante lo que

981
00:40:15,240 --> 00:40:19,520
ha hecho al conectar esto con

982
00:40:19,520 --> 00:40:22,140
métodos basados ​​en principios de

983
00:40:22,140 --> 00:40:25,440
reducción de complejidad computacional en lugar de

984
00:40:25,440 --> 00:40:29,220
métodos potencialmente efectivos pero ad hoc

985
00:40:29,220 --> 00:40:31,320
de reducción de complejidad como

986
00:40:31,320 --> 00:40:33,359
redes neuronales que podrían funcionar  cuando funcionan,

987
00:40:33,359 --> 00:40:35,280
pero luego, una vez que comienzan a inflarse,

988
00:40:35,280 --> 00:40:38,940
ahora no tiene principios ni

989
00:40:38,940 --> 00:40:40,680
eficacia

990
00:40:40,680 --> 00:40:43,200
exactamente, sí, y una inferencia sofisticada.

991
00:40:43,200 --> 00:40:45,240
Debo señalar que tiene sus propios beneficios

992
00:40:45,240 --> 00:40:47,579
en comparación con la programación dinámica, eh,

993
00:40:47,579 --> 00:40:49,500
en el sentido de que cuando

994
00:40:49,500 --> 00:40:51,839
está  teniendo en

995
00:40:51,839 --> 00:40:53,520
cuenta todas las posibilidades,

996
00:40:53,520 --> 00:40:55,859
pero cuando planifica hacia atrás,

997
00:40:55,859 --> 00:40:58,380
digamos, por ejemplo, es como una exploración basada en señales,

998
00:40:58,380 --> 00:41:00,300


999
00:41:00,300 --> 00:41:02,280
como si tuviera que ir a algún lugar, obtener

1000
00:41:02,280 --> 00:41:03,839
una cola y luego navegar hasta el

1001
00:41:03,839 --> 00:41:05,640
estado de la piscina, entonces planificar hacia atrás podría no

1002
00:41:05,640 --> 00:41:06,960
funcionar, así que esto es lo que  este fue un

1003
00:41:06,960 --> 00:41:09,900
comentario que recibí y discutí el

1004
00:41:09,900 --> 00:41:10,980
trabajo con

1005
00:41:10,980 --> 00:41:13,920
algunas personas, así

1006
00:41:13,920 --> 00:41:16,260
que eso es algo a tener en cuenta sobre la

1007
00:41:16,260 --> 00:41:18,359
programación dinámica, pero el otro lugar donde

1008
00:41:18,359 --> 00:41:19,920
aprendes antes que tus amigos, creo que

1009
00:41:19,920 --> 00:41:22,320
no es un problema, pero sí, la

1010
00:41:22,320 --> 00:41:23,700
programación dinámica es computacionalmente barata, pero

1011
00:41:23,700 --> 00:41:26,460
también viene con sus propias limitaciones.

1012
00:41:26,460 --> 00:41:28,099
Debo señalar aquí

1013
00:41:28,099 --> 00:41:31,200
solo para reafirmar que en la

1014
00:41:31,200 --> 00:41:33,839
programación dinámica con una optimización de Bellman

1015
00:41:33,839 --> 00:41:36,420
estamos resolviendo hacia atrás y, por lo tanto, es

1016
00:41:36,420 --> 00:41:38,400
como si el Jaque Mate fuera lo que queremos,

1017
00:41:38,400 --> 00:41:40,440
por lo que ahora estamos trabajando hacia atrás hasta

1018
00:41:40,440 --> 00:41:43,440
el presente.  pero terminamos sin explorar

1019
00:41:43,440 --> 00:41:46,440


1020
00:41:46,440 --> 00:41:49,200
puntos finales contrafactuales, no trabajamos de regreso al

1021
00:41:49,200 --> 00:41:51,540
presente para puntos finales que no nos

1022
00:41:51,540 --> 00:41:52,980
interesan

1023
00:41:52,980 --> 00:41:55,619
exactamente, por eso es tan despiadado,

1024
00:41:55,619 --> 00:41:58,320
pero por otro lado es una búsqueda mucho más

1025
00:41:58,320 --> 00:42:00,420
restringida,

1026
00:42:00,420 --> 00:42:02,280


1027
00:42:02,280 --> 00:42:06,960
sí, sí  así que lo que estoy pensando

1028
00:42:06,960 --> 00:42:08,460
en estos días es que también deberíamos

1029
00:42:08,460 --> 00:42:11,700
considerar combinaciones de estos dos eh

1030
00:42:11,700 --> 00:42:14,160
donde puedo permitirme ignorar

1031
00:42:14,160 --> 00:42:17,400
tales cosas contrafactuales

1032
00:42:17,400 --> 00:42:19,680
um allí puedo hacer programación dinámica uh

1033
00:42:19,680 --> 00:42:23,040
y tal vez pueda hacer en dos pasos uh de

1034
00:42:23,040 --> 00:42:25,380
planificación, así que si se trata de una exploración basada en la cola,

1035
00:42:25,380 --> 00:42:28,980
digamos que llegar a la cola es

1036
00:42:28,980 --> 00:42:32,220
una tarea y de la cola a la recompensa es

1037
00:42:32,220 --> 00:42:34,619
la otra tarea, así que puedo separar estos

1038
00:42:34,619 --> 00:42:37,460
dos y usar programación dinámica para ellos

1039
00:42:37,460 --> 00:42:40,440
y eso es computacionalmente más barato pero

1040
00:42:40,440 --> 00:42:43,079
también preserva esta idea de

1041
00:42:43,079 --> 00:42:45,480
um, tengo que hacerlo, sí, pero todas estas son

1042
00:42:45,480 --> 00:42:48,119
cosas futuras en las que estoy pensando.

1043
00:42:48,119 --> 00:42:50,700
Genial o hacer otra pregunta del

1044
00:42:50,700 --> 00:42:54,359
chat que escribió Alex. ¿

1045
00:42:54,359 --> 00:42:57,599
Tiene ideas o desarrollos en

1046
00:42:57,599 --> 00:43:00,180
modelos anidados donde diferentes escalas

1047
00:43:00,180 --> 00:43:02,330
podrían tener diferente

1048
00:43:02,330 --> 00:43:02,640
[Música]

1049
00:43:02,640 --> 00:43:03,780
um,

1050
00:43:03,780 --> 00:43:06,540
un paso adelante y  velocidad de

1051
00:43:06,540 --> 00:43:07,800
ejecución,

1052
00:43:07,800 --> 00:43:09,960
entonces, ¿cómo se desarrolla este modelo en

1053
00:43:09,960 --> 00:43:11,579
modelos anidados

1054
00:43:11,579 --> 00:43:13,859
y cómo pensamos en esto

1055
00:43:13,859 --> 00:43:16,380
hacia adelante y hacia atrás en el tiempo en la

1056
00:43:16,380 --> 00:43:19,500
velocidad de ejecución y modelos anidados? Bueno, es

1057
00:43:19,500 --> 00:43:21,780
posible que necesite un poco más de

1058
00:43:21,780 --> 00:43:23,760
contexto aquí como

1059
00:43:23,760 --> 00:43:26,220
um cuando dices anidado  modelos um te

1060
00:43:26,220 --> 00:43:28,440
refieres a modelos jerárquicos sí

1061
00:43:28,440 --> 00:43:30,780
sí entonces tal vez

1062
00:43:30,780 --> 00:43:34,619
um algo como que hay una observación

1063
00:43:34,619 --> 00:43:38,760
avanzo a un ritmo rápido y hago algunas

1064
00:43:38,760 --> 00:43:41,160
inferencias sobre eso pero luego uso esta

1065
00:43:41,160 --> 00:43:45,180
inferencia uh para hacer o

1066
00:43:45,180 --> 00:43:48,000
tal vez uh y básicamente esta

1067
00:43:48,000 --> 00:43:49,500
inferencia  se convierte en la observación para

1068
00:43:49,500 --> 00:43:52,800
el siguiente estado y eso es lo que

1069
00:43:52,800 --> 00:43:55,980
significan los modelos anidados, sí, así que podría tener que

1070
00:43:55,980 --> 00:43:58,140
pensar en eso en términos de una

1071
00:43:58,140 --> 00:44:00,300
tarea y luego pensar en ello, pero

1072
00:44:00,300 --> 00:44:02,339
honestamente, no he

1073
00:44:02,339 --> 00:44:04,800
pensado cómo podría funcionar esto en ese

1074
00:44:04,800 --> 00:44:08,760
contexto, pero  digamos para una tarea

1075
00:44:08,760 --> 00:44:10,319
um

1076
00:44:10,319 --> 00:44:13,140
como uh, en términos de navegación, si lo

1077
00:44:13,140 --> 00:44:15,119
piensas, puedes pensar,

1078
00:44:15,119 --> 00:44:15,900
um,

1079
00:44:15,900 --> 00:44:19,800
digamos, el entorno de las habitaciones, ahí es donde uh, ese es

1080
00:44:19,800 --> 00:44:21,480
uno de los ejemplos en los que puedo pensar

1081
00:44:21,480 --> 00:44:24,000
dónde podemos aplicar esto, así que imagina que

1082
00:44:24,000 --> 00:44:27,720
tal vez tienes una colección  de habitaciones y

1083
00:44:27,720 --> 00:44:30,300
como agente, primero tiene que averiguar a

1084
00:44:30,300 --> 00:44:32,460
qué habitación ir y luego tiene que

1085
00:44:32,460 --> 00:44:35,760
navegar dentro de esa casa y básicamente

1086
00:44:35,760 --> 00:44:39,060
puede hacer uh inferencia en dos etapas o

1087
00:44:39,060 --> 00:44:41,940
toma de decisiones en dos etapas uh y tendrá que

1088
00:44:41,940 --> 00:44:43,140
separarse  sus

1089
00:44:43,140 --> 00:44:45,240
decisiones en esas etapas

1090
00:44:45,240 --> 00:44:47,460
dentro de la sala, puede hacer, digamos,

1091
00:44:47,460 --> 00:44:49,740
programación dinámica para navegar por su camino óptimo, eh,

1092
00:44:49,740 --> 00:44:52,980
pero siempre tendrá que

1093
00:44:52,980 --> 00:44:54,960
tener dos etapas de

1094
00:44:54,960 --> 00:44:57,300
toma de decisiones, um, y

1095
00:44:57,300 --> 00:45:00,420
tal vez diferentes métodos funcionen mejor en

1096
00:45:00,420 --> 00:45:04,260
diferentes etapas, pero esto sería  uh,

1097
00:45:04,260 --> 00:45:06,180
mejor si sabes, quiero decir que esta

1098
00:45:06,180 --> 00:45:08,460
discusión sería

1099
00:45:08,460 --> 00:45:09,420


1100
00:45:09,420 --> 00:45:12,060
mejor en una

1101
00:45:12,060 --> 00:45:14,400
tarea bien pensada. Diría que no

1102
00:45:14,400 --> 00:45:18,240
tengo una respuesta que pueda ser adecuada para

1103
00:45:18,240 --> 00:45:19,740
todo, pero

1104
00:45:19,740 --> 00:45:21,119
sí,

1105
00:45:21,119 --> 00:45:24,359
sí, hemos visto casi exactamente ese tipo

1106
00:45:24,359 --> 00:45:27,300
de

1107
00:45:27,300 --> 00:45:30,180
localización y mapeo simultáneos jerárquicos Slam en un

1108
00:45:30,180 --> 00:45:32,040
caso de robótica ha habido

1109
00:45:32,040 --> 00:45:33,900
modelos de inferencia activos en eso

1110
00:45:33,900 --> 00:45:37,140
um sí, ¿sería posible hacer

1111
00:45:37,140 --> 00:45:39,500


1112
00:45:40,079 --> 00:45:42,660
um uno de estos métodos

1113
00:45:42,660 --> 00:45:45,420
en un nivel del modelo anidado y

1114
00:45:45,420 --> 00:45:48,359
luego tener otro método computacional

1115
00:45:48,359 --> 00:45:50,280
aplicado a otro

1116
00:45:50,280 --> 00:45:51,960
um  o es como si quisieras las

1117
00:45:51,960 --> 00:45:54,480
ventajas de uno en un solo lugar, ¿

1118
00:45:54,480 --> 00:45:56,579
puedes mezclar y combinar estos diferentes

1119
00:45:56,579 --> 00:46:00,180
métodos incluso dentro de una simulación?

1120
00:46:00,180 --> 00:46:03,540


1121
00:46:03,540 --> 00:46:04,859


1122
00:46:04,859 --> 00:46:09,140


1123
00:46:09,180 --> 00:46:12,119
etapa, por lo que

1124
00:46:12,119 --> 00:46:14,819
no es un modelo jerárquico

1125
00:46:14,819 --> 00:46:17,220
y, pero creo firmemente que

1126
00:46:17,220 --> 00:46:19,260
también funcionaría en un modelo de patrimonio en el que

1127
00:46:19,260 --> 00:46:20,520
puede tener,

1128
00:46:20,520 --> 00:46:22,200
um, dos métodos de toma de decisiones

1129
00:46:22,200 --> 00:46:24,660
trabajando juntos, por ejemplo, para un

1130
00:46:24,660 --> 00:46:26,940
ejemplo de habitación que acabo de mencionar,

1131
00:46:26,940 --> 00:46:29,280
oh, ¿podría ir a la diapositiva?  El aprendizaje Z es

1132
00:46:29,280 --> 00:46:31,819


1133
00:46:35,640 --> 00:46:38,760
genial, sí, así que noté, um, aquí y en

1134
00:46:38,760 --> 00:46:41,220
el excelente artículo que tenía varias

1135
00:46:41,220 --> 00:46:45,240
citas en total, sí y así, y esta

1136
00:46:45,240 --> 00:46:48,060
introducción del aprendizaje Z es una

1137
00:46:48,060 --> 00:46:49,859
novedad con respecto al

1138
00:46:49,859 --> 00:46:52,260
campo de inferencia activa, ¿podría explicar un

1139
00:46:52,260 --> 00:46:53,760
poco más

1140
00:46:53,760 --> 00:46:55,920
qué?  es la Z

1141
00:46:55,920 --> 00:47:00,660
y qué es lo que permite una mejora tan

1142
00:47:00,660 --> 00:47:02,280
rápida

1143
00:47:02,280 --> 00:47:03,240


1144
00:47:03,240 --> 00:47:06,119
en la Z con respecto a la

1145
00:47:06,119 --> 00:47:06,900
Q,

1146
00:47:06,900 --> 00:47:10,619
sí, está bien, entonces, para dar algo de contexto, um,

1147
00:47:10,619 --> 00:47:13,079
contexto sobre este documento,

1148
00:47:13,079 --> 00:47:13,920
um,

1149
00:47:13,920 --> 00:47:16,260
habla de un

1150
00:47:16,260 --> 00:47:19,800
método lineal de toma de decisiones, uh, en un

1151
00:47:19,800 --> 00:47:21,720
particular  clase de mdp, dado que

1152
00:47:21,720 --> 00:47:23,940
tiene un proceso de decisión de Markov

1153
00:47:23,940 --> 00:47:27,240
en el que sus acciones pueden basarse en

1154
00:47:27,240 --> 00:47:29,220
estados y no en acentos, por lo que cuando piensa

1155
00:47:29,220 --> 00:47:31,560
en acciones en, por ejemplo, una

1156
00:47:31,560 --> 00:47:32,760
tarea cuadriculada,

1157
00:47:32,760 --> 00:47:35,160
piensa en izquierda derecha y

1158
00:47:35,160 --> 00:47:37,200
um Norte Sur derecha entonces  si tomo un

1159
00:47:37,200 --> 00:47:40,200
norte entonces eso tiene una consecuencia de uh

1160
00:47:40,200 --> 00:47:42,720
consecuencia en el espacio de estado pero en este

1161
00:47:42,720 --> 00:47:43,680
artículo

1162
00:47:43,680 --> 00:47:46,380
um están introduciendo una clase de mdp

1163
00:47:46,380 --> 00:47:48,839
donde la decisión es en sí misma en términos de

1164
00:47:48,839 --> 00:47:49,920
estados

1165
00:47:49,920 --> 00:47:54,180
así que si estoy diciendo State S1 mi decisión

1166
00:47:54,180 --> 00:47:56,280
será uh

1167
00:47:56,280 --> 00:47:58,740
dependiendo  sobre el otro estado, por lo que mi

1168
00:47:58,740 --> 00:48:00,000
decisión se basará en los otros

1169
00:48:00,000 --> 00:48:02,160
estados en los que quiero estar la próxima vez, así que

1170
00:48:02,160 --> 00:48:04,020


1171
00:48:04,020 --> 00:48:05,880
es una definición real de la

1172
00:48:05,880 --> 00:48:08,640
toma de decisiones en términos del espacio del estado

1173
00:48:08,640 --> 00:48:10,800
en lugar de que las decisiones sean algo

1174
00:48:10,800 --> 00:48:13,619
más como izquierda derecha y abajo arriba

1175
00:48:13,619 --> 00:48:15,300
Entonces, dado que

1176
00:48:15,300 --> 00:48:17,819
existe tal mdp donde puedo tomar

1177
00:48:17,819 --> 00:48:21,319
decisiones en términos de estados,

1178
00:48:21,319 --> 00:48:23,520
han demostrado que computacionalmente

1179
00:48:23,520 --> 00:48:27,000
puedes tomar decisiones en

1180
00:48:27,000 --> 00:48:30,900
complejidad lineal, sin importar cuán grande sea el problema para

1181
00:48:30,900 --> 00:48:33,480
permitir la

1182
00:48:33,480 --> 00:48:35,339
toma de decisiones en términos de Estados que deberías

1183
00:48:35,339 --> 00:48:38,579
tener.  un sentido de lo que es bueno y malo para

1184
00:48:38,579 --> 00:48:39,540
los estados,

1185
00:48:39,540 --> 00:48:43,619
así que en este ejemplo de gridward tienes

1186
00:48:43,619 --> 00:48:46,440
una función de deseabilidad que es C, entonces C

1187
00:48:46,440 --> 00:48:48,240
es la función de deseabilidad

1188
00:48:48,240 --> 00:48:50,700
que habla sobre cuán deseable es un

1189
00:48:50,700 --> 00:48:54,180
estado y si tengo una función c, entonces

1190
00:48:54,180 --> 00:48:56,579
lo que han mostrado  es que,

1191
00:48:56,579 --> 00:48:57,359
um,

1192
00:48:57,359 --> 00:48:59,280
puedo tomar decisiones con

1193
00:48:59,280 --> 00:49:01,079
complejidad computacional lineal para esta

1194
00:49:01,079 --> 00:49:03,540
clase particular de mdp, así que si mi mdp

1195
00:49:03,540 --> 00:49:05,640
me permite tomar decisiones en términos de

1196
00:49:05,640 --> 00:49:08,940
estados, es lineal, eh, es solo

1197
00:49:08,940 --> 00:49:11,700
complejidad lineal para esa cosa,

1198
00:49:11,700 --> 00:49:15,240
por lo que este gráfico básicamente compara cómo

1199
00:49:15,240 --> 00:49:19,260
puedes  aprende la deseabilidad uh mejor

1200
00:49:19,260 --> 00:49:22,200
o más rápido, así que Q learning si estás

1201
00:49:22,200 --> 00:49:23,880
familiarizado con Q learning es básicamente

1202
00:49:23,880 --> 00:49:28,319
un método basado en tablas uh donde tienes

1203
00:49:28,319 --> 00:49:30,780
um deseabilidad de acciones dado un estado,

1204
00:49:30,780 --> 00:49:33,000
así que dado un estado sabes qué hacer,

1205
00:49:33,000 --> 00:49:35,760
eso es básicamente la matriz de cola pero en

1206
00:49:35,760 --> 00:49:37,020
términos de C

1207
00:49:37,020 --> 00:49:40,380
uh o el método de aprendizaje C solo se

1208
00:49:40,380 --> 00:49:43,020
trata de Estados uh solo estás aprendiendo cuán

1209
00:49:43,020 --> 00:49:44,819
deseable es un estado no hay concepto

1210
00:49:44,819 --> 00:49:46,980
de acciones

1211
00:49:46,980 --> 00:49:49,560
y esto es exactamente lo que nuestra

1212
00:49:49,560 --> 00:49:51,839
preferencia previa uh es en inferencia activa

1213
00:49:51,839 --> 00:49:54,000
donde es una distribución que

1214
00:49:54,000 --> 00:49:55,560
cuantifica  cuán deseables o

1215
00:49:55,560 --> 00:49:57,960
no deseables son los estados

1216
00:49:57,960 --> 00:50:00,119
correctos,

1217
00:50:00,119 --> 00:50:02,579
dado que han demostrado que

1218
00:50:02,579 --> 00:50:05,099
puedes aprender la Matriz C más rápido y

1219
00:50:05,099 --> 00:50:07,980
eso es óptimo y es mucho más rápido que

1220
00:50:07,980 --> 00:50:10,079
incluso el aprendizaje Q, entonces pensé bien, ¿por qué

1221
00:50:10,079 --> 00:50:13,319
no intentar aprender C de la misma manera que  C se

1222
00:50:13,319 --> 00:50:16,400
aprende en este artículo y

1223
00:50:16,400 --> 00:50:19,319
al usar esto dice que hay una

1224
00:50:19,319 --> 00:50:21,839
regla de aprendizaje similar para aprender C que se

1225
00:50:21,839 --> 00:50:24,119
llama aprendizaje establecido en ese artículo y

1226
00:50:24,119 --> 00:50:25,800
cuando intenté aprender, lo que

1227
00:50:25,800 --> 00:50:28,200
vi es que aprende muy rápido, una

1228
00:50:28,200 --> 00:50:30,540
preferencia útil de Pride.  eso me permite

1229
00:50:30,540 --> 00:50:32,520
tomar decisiones o dejar que el

1230
00:50:32,520 --> 00:50:34,619
agente de influencia activo tome decisiones

1231
00:50:34,619 --> 00:50:38,460
um solo, digamos, un paso de tiempo de planificación

1232
00:50:38,460 --> 00:50:40,859
y sí, básicamente eso tomó la

1233
00:50:40,859 --> 00:50:42,240
historia, así que

1234
00:50:42,240 --> 00:50:43,440
um

1235
00:50:43,440 --> 00:50:47,460
esta idea de que C es fácil de aprender está

1236
00:50:47,460 --> 00:50:50,240
en ese documento,

1237
00:50:52,020 --> 00:50:54,780
está bien, déjame intentar um reafirmar  que dado que

1238
00:50:54,780 --> 00:50:56,420
creo que es un aumento muy interesante

1239
00:50:56,420 --> 00:50:59,099
de la inferencia activa,

1240
00:50:59,099 --> 00:51:02,280
vamos a aprender C

1241
00:51:02,280 --> 00:51:04,200
por todas las

1242
00:51:04,200 --> 00:51:06,480
razones que discutimos anteriormente,

1243
00:51:06,480 --> 00:51:09,619
vamos a aprender C de

1244
00:51:09,619 --> 00:51:13,740
manera análoga a cómo todorov presentó el

1245
00:51:13,740 --> 00:51:18,540
aprendizaje Z y en el aprendizaje Z

1246
00:51:18,540 --> 00:51:21,059
en lugar de aprender

1247
00:51:21,059 --> 00:51:23,460
um, por ejemplo, actualizó las

1248
00:51:23,460 --> 00:51:26,160
probabilidades posteriores de las acciones

1249
00:51:26,160 --> 00:51:28,380
y luego usó acciones para navegar

1250
00:51:28,380 --> 00:51:31,339
entre estados que emiten observaciones,

1251
00:51:31,339 --> 00:51:35,760
sí, vamos a hornear la

1252
00:51:35,760 --> 00:51:37,319
acción

1253
00:51:37,319 --> 00:51:39,300
en los estados

1254
00:51:39,300 --> 00:51:41,420
para que realmente estemos aprendiendo

1255
00:51:41,420 --> 00:51:44,280
transiciones entre estados

1256
00:51:44,280 --> 00:51:48,200
directamente

1257
00:51:51,540 --> 00:51:53,880
al

1258
00:51:53,880 --> 00:51:56,040
principio de energía libre y cómo se

1259
00:51:56,040 --> 00:51:57,660
desarrolla con la inferencia activa

1260
00:51:57,660 --> 00:51:59,220
aquí

1261
00:51:59,220 --> 00:52:00,559
um

1262
00:52:00,559 --> 00:52:03,780
C no es solo nuestra función de deseabilidad, esa es

1263
00:52:03,780 --> 00:52:05,280
una forma de pensar al respecto, por eso lo

1264
00:52:05,280 --> 00:52:07,559
llamamos preferencia, pero

1265
00:52:07,559 --> 00:52:11,640
también C es nuestra expectativa y eso es lo que

1266
00:52:11,640 --> 00:52:14,400
permite  nosotros, por un lado, usamos el

1267
00:52:14,400 --> 00:52:16,800
lenguaje familiar para recompensar y

1268
00:52:16,800 --> 00:52:18,960
preferir aprender como si el agente

1269
00:52:18,960 --> 00:52:21,900
terminara donde le gusta estar, pero también

1270
00:52:21,900 --> 00:52:25,500
la expectativa basada en la

1271
00:52:25,500 --> 00:52:27,780
definición de um de c estos son lo mismo

1272
00:52:27,780 --> 00:52:30,180
nos permite hablar de eso como un

1273
00:52:30,180 --> 00:52:32,760
camino de al menos  acción o como el

1274
00:52:32,760 --> 00:52:36,660
resultado más probable o el resultado menos sorprendente

1275
00:52:36,660 --> 00:52:39,900
y debido a que lo hemos definido

1276
00:52:39,900 --> 00:52:42,960
como el resultado menos sorprendente,

1277
00:52:42,960 --> 00:52:47,040
entonces podemos usar energía libre variacional

1278
00:52:47,040 --> 00:52:50,640
para rebotar la sorpresa, mientras que

1279
00:52:50,640 --> 00:52:54,000
no puede usar simplemente un método variacional para

1280
00:52:54,000 --> 00:52:56,579
limitar o  incluso necesariamente se aproxima a la

1281
00:52:56,579 --> 00:52:58,859
recompensa en sí misma,

1282
00:52:58,859 --> 00:53:01,079
pero si dices que

1283
00:53:01,079 --> 00:53:04,980
prefiero lo que espero

1284
00:53:04,980 --> 00:53:07,559
y lo que espero reduce mi sorpresa

1285
00:53:07,559 --> 00:53:09,859
y voy a equilibrar la sorpresa,

1286
00:53:09,859 --> 00:53:13,520
entonces obtienes ese tipo de

1287
00:53:13,520 --> 00:53:17,240
búsqueda de recompensa conductual

1288
00:53:17,240 --> 00:53:21,420
expresada en una sorpresa que limita la sorpresa que

1289
00:53:21,420 --> 00:53:25,579
minimiza el marco de la física,

1290
00:53:27,059 --> 00:53:28,740
sí, sí  esa es una manera hermosa de

1291
00:53:28,740 --> 00:53:31,619
decirlo, sí, gracias, ¿

1292
00:53:31,619 --> 00:53:35,160
cuáles son los siguientes

1293
00:53:35,160 --> 00:53:36,720


1294
00:53:36,720 --> 00:53:39,420
pasos o instrucciones emocionantes o de qué manera

1295
00:53:39,420 --> 00:53:41,640
quieres tomar este trabajo?

1296
00:53:41,640 --> 00:53:43,140


1297
00:53:43,140 --> 00:53:44,940


1298
00:53:44,940 --> 00:53:46,140


1299
00:53:46,140 --> 00:53:50,640
Lo siguiente que debe hacer es, eh,

1300
00:53:50,640 --> 00:53:53,099
pensar en tareas de exploración basadas en señales. En

1301
00:53:53,099 --> 00:53:55,200
primer lugar, aborde las limitaciones

1302
00:53:55,200 --> 00:53:58,980
de la programación dinámica, por lo que si

1303
00:53:58,980 --> 00:54:01,020
tiene que decir una cola para explorar en esta cuadrícula

1304
00:54:01,020 --> 00:54:03,660
primero y eso es más óptimo, quiero

1305
00:54:03,660 --> 00:54:06,780
ver cómo el término de ambigüedad esperado

1306
00:54:06,780 --> 00:54:10,319
en  la energía libre esperada es útil

1307
00:54:10,319 --> 00:54:12,240
y debe usarse en la programación dinámica

1308
00:54:12,240 --> 00:54:13,260


1309
00:54:13,260 --> 00:54:15,540
estrictamente en ese sentido,

1310
00:54:15,540 --> 00:54:18,000
pero en términos más generales, también estoy buscando

1311
00:54:18,000 --> 00:54:20,339
otras formas de tomar decisiones en la

1312
00:54:20,339 --> 00:54:23,040
influencia activa, como hay trabajos

1313
00:54:23,040 --> 00:54:24,900
del profesor

1314
00:54:24,900 --> 00:54:26,099
un verano

1315
00:54:26,099 --> 00:54:30,180
de CBS, creo que habla.  acerca de cómo es

1316
00:54:30,180 --> 00:54:33,059
Cómo las redes neuronales están haciendo

1317
00:54:33,059 --> 00:54:35,099
inferencia activa y básicamente la toma de decisiones

1318
00:54:35,099 --> 00:54:36,359
es

1319
00:54:36,359 --> 00:54:39,540
realmente más eficiente en el sentido

1320
00:54:39,540 --> 00:54:42,359
de que es como el aprendizaje en cola, por lo que

1321
00:54:42,359 --> 00:54:44,940
está haciendo un uso inteligente de la

1322
00:54:44,940 --> 00:54:47,520
energía libre de variación para aprender buenas

1323
00:54:47,520 --> 00:54:50,760
asignaciones de acción de estado y es  un

1324
00:54:50,760 --> 00:54:52,200


1325
00:54:52,200 --> 00:54:55,079
cambio muy drástico a lo que estamos acostumbrados en

1326
00:54:55,079 --> 00:54:56,520
términos de energía libre esperada, por lo que

1327
00:54:56,520 --> 00:54:59,220
no hay un concepto de energía libre esperada

1328
00:54:59,220 --> 00:55:01,740
en ese trabajo, se trata de aprender

1329
00:55:01,740 --> 00:55:03,599
qué es bueno y malo directamente de la

1330
00:55:03,599 --> 00:55:05,700
variación de la energía, así que creo que

1331
00:55:05,700 --> 00:55:08,099
también  fascinante, quiero

1332
00:55:08,099 --> 00:55:11,160
explorar eso más y ver cómo la

1333
00:55:11,160 --> 00:55:15,300
toma de decisiones de esta manera es mejor o peor

1334
00:55:15,300 --> 00:55:18,000
o debería pensarse si

1335
00:55:18,000 --> 00:55:20,220
incluso reconsideraramos las formas de toma de decisiones

1336
00:55:20,220 --> 00:55:22,200
porque la inferencia activa solo habla

1337
00:55:22,200 --> 00:55:23,700
de energía libre variacional y ese es

1338
00:55:23,700 --> 00:55:25,520
el principio central de todo.  otra cosa es

1339
00:55:25,520 --> 00:55:28,440
su interpretación de eso,

1340
00:55:28,440 --> 00:55:31,319
así que sí,

1341
00:55:31,319 --> 00:55:35,180
esa es otra dirección. Quiero trabajar en una

1342
00:55:35,640 --> 00:55:38,359
forma interesante de decirlo.

1343
00:55:38,359 --> 00:55:42,480


1344
00:55:42,480 --> 00:55:45,540


1345
00:55:45,540 --> 00:55:48,660


1346
00:55:48,660 --> 00:55:51,119


1347
00:55:51,119 --> 00:55:53,839


1348
00:55:53,839 --> 00:55:57,359
homeostasis en tiempo real como sí, ¿cómo tienen

1349
00:55:57,359 --> 00:55:59,760
sentido las cosas dado lo que creo y

1350
00:55:59,760 --> 00:56:01,619
los datos entrantes

1351
00:56:01,619 --> 00:56:04,740
y luego extender ese tipo de

1352
00:56:04,740 --> 00:56:07,020
marco de toma de sentido a la toma de decisiones?

1353
00:56:07,020 --> 00:56:10,020
Hemos visto muchos métodos diferentes.

1354
00:56:10,020 --> 00:56:13,740


1355
00:56:13,740 --> 00:56:16,260
pero, por ejemplo, ha

1356
00:56:16,260 --> 00:56:19,400
habido energía libre del futuro esperado

1357
00:56:19,400 --> 00:56:25,200
como eef y hay otras construcciones

1358
00:56:25,200 --> 00:56:29,760
que tienen diferentes métodos

1359
00:56:29,760 --> 00:56:31,380
um y luego señalas también el

1360
00:56:31,380 --> 00:56:33,599
trabajo del profesor samura

1361
00:56:33,599 --> 00:56:37,020
con um el tipo de

1362
00:56:37,020 --> 00:56:39,059
relación entre la

1363
00:56:39,059 --> 00:56:41,339
energía libre variacional en el gráfico base y el

1364
00:56:41,339 --> 00:56:43,680
función de pérdida en una red neuronal y

1365
00:56:43,680 --> 00:56:45,300
todas esas relaciones que

1366
00:56:45,300 --> 00:56:48,380
también es un trabajo muy emocionante,

1367
00:56:49,079 --> 00:56:51,660
supongo que para cerrar solo como una

1368
00:56:51,660 --> 00:56:53,460
última pregunta o pensé que se

1369
00:56:53,460 --> 00:56:55,559
está acercando al final de su

1370
00:56:55,559 --> 00:56:56,880
doctorado,

1371
00:56:56,880 --> 00:57:00,540
así que justo en el tiempo que ha estado  un

1372
00:57:00,540 --> 00:57:02,579
estudiante de doctorado, ¿

1373
00:57:02,579 --> 00:57:06,300
cómo ha visto cómo se desarrolla la inferencia activa

1374
00:57:06,300 --> 00:57:10,700
o qué se

1375
00:57:11,339 --> 00:57:14,280
siente diferente para usted hoy cerca del

1376
00:57:14,280 --> 00:57:17,400
final que cuando tenía los

1377
00:57:17,400 --> 00:57:19,980
ojos frescos y emocionado

1378
00:57:19,980 --> 00:57:21,119
hace varios años?

1379
00:57:21,119 --> 00:57:23,339
sí, esa es una gran

1380
00:57:23,339 --> 00:57:25,920
pregunta y también estoy muy emocionado

1381
00:57:25,920 --> 00:57:29,400
de cómo  el campo ha evolucionado y, francamente,

1382
00:57:29,400 --> 00:57:30,900
comencé con esta

1383
00:57:30,900 --> 00:57:32,400
base de aprendizaje por refuerzo y la

1384
00:57:32,400 --> 00:57:34,680
base de física, y cuando comencé a leer,

1385
00:57:34,680 --> 00:57:37,680
solo decía uno o dos artículos y

1386
00:57:37,680 --> 00:57:40,440
no entendía mucho de eso,

1387
00:57:40,440 --> 00:57:42,540
fue solo cuando comencé, uh, a implementarlo

1388
00:57:42,540 --> 00:57:44,700
usando  llamadas

1389
00:57:44,700 --> 00:57:46,980
um Guiones de Matlab Entendí

1390
00:57:46,980 --> 00:57:49,559
bien, esto tiene sentido y me gusta,

1391
00:57:49,559 --> 00:57:52,020
pero dentro de, digamos, uno o dos años, vi que

1392
00:57:52,020 --> 00:57:54,780
llegaban muchos documentos de

1393
00:57:54,780 --> 00:57:56,280
diferentes direcciones y que la gente también

1394
00:57:56,280 --> 00:57:58,740
comenzaba a usar redes neuronales y todo

1395
00:57:58,740 --> 00:58:02,460
esto se ampliaba.  llegué y en algún

1396
00:58:02,460 --> 00:58:04,319
momento también cuestioné la necesidad de la

1397
00:58:04,319 --> 00:58:07,260
inferencia activa, eh porque si tienes un

1398
00:58:07,260 --> 00:58:09,119
aprendizaje de refuerzo profundo que

1399
00:58:09,119 --> 00:58:10,980
puede hacer muchas cosas, entonces ¿por qué la inferencia activa profunda

1400
00:58:10,980 --> 00:58:14,040
y esa es la razón por la que

1401
00:58:14,040 --> 00:58:16,319
no me metí en eso, pero aún

1402
00:58:16,319 --> 00:58:18,359
lo encuentro fascinante?  Quiero

1403
00:58:18,359 --> 00:58:20,280
entender la inferencia activa profunda más

1404
00:58:20,280 --> 00:58:23,160
de lo que sé ahora, pero he visto

1405
00:58:23,160 --> 00:58:25,680
crecer el campo como algo en dos o

1406
00:58:25,680 --> 00:58:28,619
tres años y muchas cohortes de personas

1407
00:58:28,619 --> 00:58:31,859
comenzaron a trabajar y en poco tiempo fue un

1408
00:58:31,859 --> 00:58:36,359
campo que se tomó en serio.  que un campo

1409
00:58:36,359 --> 00:58:39,119
con, digamos, dos artículos sin que nadie

1410
00:58:39,119 --> 00:58:41,280
sepa realmente qué es, así que es realmente

1411
00:58:41,280 --> 00:58:43,440
emocionante, sí, así que realmente espero con ansias

1412
00:58:43,440 --> 00:58:47,040
cómo evoluciona el campo en el tiempo y también

1413
00:58:47,040 --> 00:58:52,140
qué puedo hacer después de mi doctorado y

1414
00:58:52,140 --> 00:58:55,319


1415
00:58:55,319 --> 00:59:00,359
así sucesivamente.  preferimos lo que esperamos sí,

1416
00:59:02,339 --> 00:59:04,140
cualquier otro

1417
00:59:04,140 --> 00:59:05,819
comentario o cualquier otra cosa que desee

1418
00:59:05,819 --> 00:59:07,200
agregar,

1419
00:59:07,200 --> 00:59:09,839
sí, así que hágame saber lo que

1420
00:59:09,839 --> 00:59:11,940
piensa sobre el documento y lo que piensa

1421
00:59:11,940 --> 00:59:14,400
sobre estas ideas, no dude en hacérmelo

1422
00:59:14,400 --> 00:59:16,200
saber, espero con ansias los

1423
00:59:16,200 --> 00:59:17,760
comentarios y

1424
00:59:17,760 --> 00:59:20,160
sí  Muchas gracias por esta oportunidad,

1425
00:59:20,160 --> 00:59:23,339
Daniel, y gracias por su tiempo,

1426
00:59:23,339 --> 00:59:26,160
fue increíble.

1427
00:59:26,160 --> 00:59:28,260


1428
00:59:28,260 --> 00:59:30,540


1429
00:59:30,540 --> 00:59:33,359


1430
00:59:33,359 --> 00:59:34,680


1431
00:59:34,680 --> 00:59:36,839
muchas gracias adios que

1432
00:59:36,839 --> 00:59:40,040
tengas un buen dia adios

