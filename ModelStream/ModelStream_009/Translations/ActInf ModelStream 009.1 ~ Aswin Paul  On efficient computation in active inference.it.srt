1
00:00:03,120 --> 00:00:06,120
straniero

2
00:00:08,480 --> 00:00:12,660
è il 15 luglio 2023

3
00:00:12,660 --> 00:00:15,900
siamo qui nel flusso del modello di inferenza attiva

4
00:00:15,900 --> 00:00:19,080
numero 9.1 con Aspen Paul

5
00:00:19,080 --> 00:00:21,060
oggi faremo una presentazione

6
00:00:21,060 --> 00:00:24,180
e una discussione sul

7
00:00:24,180 --> 00:00:27,000
calcolo efficiente nell'inferenza attiva quindi se

8
00:00:27,000 --> 00:00:28,619
stai guardando dal vivo non esitare

9
00:00:28,619 --> 00:00:30,840
ad aggiungere  commenti o domande nella

10
00:00:30,840 --> 00:00:33,059
chat altrimenti

11
00:00:33,059 --> 00:00:36,120
grazie mille per esserti unito oggi non

12
00:00:36,120 --> 00:00:38,820
vedo davvero l'ora del tuo discorso grazie

13
00:00:38,820 --> 00:00:41,640
Daniel grazie mille quindi come

14
00:00:41,640 --> 00:00:42,960
accennato oggi parlerò di

15
00:00:42,960 --> 00:00:44,700
calcolo efficiente e

16
00:00:44,700 --> 00:00:46,920
inferenza attiva e sì,

17
00:00:46,920 --> 00:00:49,500
iniziamo così  conosciamo tutti questa idea del

18
00:00:49,500 --> 00:00:51,420
principio dell'energia libera che è anche

19
00:00:51,420 --> 00:00:53,820
noto come inferenza attiva, quindi il

20
00:00:53,820 --> 00:00:55,800
concetto centrale è che un agente

21
00:00:55,800 --> 00:00:59,160
riduce al minimo l'entropia della sua osservazione per

22
00:00:59,160 --> 00:01:01,140
mantenere l'omeostasi o sopravvivere nel suo

23
00:01:01,140 --> 00:01:03,719
ambiente e qui l'entropia è

24
00:01:03,719 --> 00:01:05,580
definita nella teoria dell'informazione

25
00:01:05,580 --> 00:01:08,520
senso giusto quindi se un'osservazione è

26
00:01:08,520 --> 00:01:10,200
altamente probabilistica che è meno

27
00:01:10,200 --> 00:01:12,659
entropica o meno sorprendente perché

28
00:01:12,659 --> 00:01:14,159
era alta probabilità e ce lo

29
00:01:14,159 --> 00:01:16,560
aspettavamo e e

30
00:01:16,560 --> 00:01:18,840
e questa è l'idea quando questa è

31
00:01:18,840 --> 00:01:20,939
la base su cui costruiamo questo quadro di

32
00:01:20,939 --> 00:01:23,759
inferenza attiva e questa idea di

33
00:01:23,759 --> 00:01:26,520
Marco coperta uh ci dà un

34
00:01:26,520 --> 00:01:30,000
modo sistematico di sorprendere uh o il

35
00:01:30,000 --> 00:01:32,580
modo schematico di separare uh un agente

36
00:01:32,580 --> 00:01:34,439
dal suo ambiente e modellare un

37
00:01:34,439 --> 00:01:37,320
comportamento mirato giusto quindi concentriamoci

38
00:01:37,320 --> 00:01:39,780
su questa idea di minimizzare l'entropia quindi

39
00:01:39,780 --> 00:01:41,700
come fa un agente a minimizzare l'entropia o

40
00:01:41,700 --> 00:01:43,740
sapere quale osservazione è  altamente

41
00:01:43,740 --> 00:01:46,020
probabilistico e viceversa,

42
00:01:46,020 --> 00:01:48,360
cioè mantenendo un

43
00:01:48,360 --> 00:01:50,399
modello generativo e il modello generativo è

44
00:01:50,399 --> 00:01:52,020
fondamentalmente un modello giocattolo dell'ambiente

45
00:01:52,020 --> 00:01:56,340
che l'agente costruisce nel suo cervello e

46
00:01:56,340 --> 00:01:58,860
che viene costruito usando solo l'osservazione

47
00:01:58,860 --> 00:02:00,540
che ottiene dall'ambiente quindi

48
00:02:00,540 --> 00:02:03,420
non ha  l'accesso agli stati uh reali o agli

49
00:02:03,420 --> 00:02:04,740
stati nascosti dell'ambiente sta

50
00:02:04,740 --> 00:02:07,920
costruendo il modello giocattolo e dato

51
00:02:07,920 --> 00:02:10,318
questo modello giocattolo ha lo scopo o la capacità

52
00:02:10,318 --> 00:02:13,560
uh di calcolare la probabilità di

53
00:02:13,560 --> 00:02:15,900
un'osservazione e quindi cercare di minimizzare

54
00:02:15,900 --> 00:02:18,660
l'entropia giusto quindi

55
00:02:18,660 --> 00:02:22,620
questa è l'idea ma è  ha un problema di

56
00:02:22,620 --> 00:02:25,800
um dimensionalità corsiva come dato un

57
00:02:25,800 --> 00:02:27,239
modello generativo potrebbe non essere

58
00:02:27,239 --> 00:02:30,120
sempre possibile calcolare o emarginare la

59
00:02:30,120 --> 00:02:32,099
probabilità di osservazioni da esso

60
00:02:32,099 --> 00:02:34,140
perché lo spazio degli stati può

61
00:02:34,140 --> 00:02:37,020
diventare rapidamente intrattabile ma l'idea è che

62
00:02:37,020 --> 00:02:38,640
tu definisca un limite superiore sulla

63
00:02:38,640 --> 00:02:41,580
sorpresa  usando la disuguaglianza di Jensen e

64
00:02:41,580 --> 00:02:43,560
puoi anche

65
00:02:43,560 --> 00:02:46,800
definire un nuovo termine chiamato Q che è la

66
00:02:46,800 --> 00:02:49,500
credenza nascosta o la credenza sugli

67
00:02:49,500 --> 00:02:52,080
Stati nascosti e questa coda sarà

68
00:02:52,080 --> 00:02:54,000
al centro del processo decisionale giusto quindi

69
00:02:54,000 --> 00:02:57,060
se hai una coda rumorosa e

70
00:02:57,060 --> 00:02:58,680
non ne hai idea  cosa c'è nell'ambiente allora

71
00:02:58,680 --> 00:03:00,840
non puoi prendere o sperare di prendere decisioni

72
00:03:00,840 --> 00:03:03,540
per controllare quell'ambiente ed è

73
00:03:03,540 --> 00:03:05,519
questa convinzione sugli stati nascosti che

74
00:03:05,519 --> 00:03:07,560
usi e che diventa utile per prendere

75
00:03:07,560 --> 00:03:10,379
decisioni e tutta questa quantità è

76
00:03:10,379 --> 00:03:13,019
ovviamente chiamata energia libera e  l'

77
00:03:13,019 --> 00:03:14,420
energia libera variazionale

78
00:03:14,420 --> 00:03:17,879
F può essere interpretata in più modi, quindi

79
00:03:17,879 --> 00:03:19,560
il primo o il più comune è il

80
00:03:19,560 --> 00:03:22,920
modo di apprendimento automatico di come è

81
00:03:22,920 --> 00:03:25,200
um Cercare di ridurre al minimo la complessità

82
00:03:25,200 --> 00:03:27,060
del modello cercando allo stesso tempo di

83
00:03:27,060 --> 00:03:28,739
massimizzarne l'accuratezza, quindi questo è

84
00:03:28,739 --> 00:03:30,180
il  interpretazione dell'apprendimento automatico della

85
00:03:30,180 --> 00:03:32,400
riduzione al minimo di varie energie libere puoi

86
00:03:32,400 --> 00:03:34,140
anche provare a

87
00:03:34,140 --> 00:03:34,739


88
00:03:34,739 --> 00:03:36,420
interpretare l'energia libera nel

89
00:03:36,420 --> 00:03:38,940
termine fisico in cui allo stesso tempo cerchi di

90
00:03:38,940 --> 00:03:41,760
ridurre al minimo l'energia del tuo modello ma allo

91
00:03:41,760 --> 00:03:43,019
stesso tempo cerchi di massimizzare l'

92
00:03:43,019 --> 00:03:45,120
entropia ma l'obiettivo di

93
00:03:45,120 --> 00:03:48,659
oggi  o il processo decisionale è sempre su

94
00:03:48,659 --> 00:03:51,540
questa convinzione che hai dopo aver fatto

95
00:03:51,540 --> 00:03:54,780
la percezione nell'inferenza attiva, quindi

96
00:03:54,780 --> 00:03:57,120
come fai a prendere decisioni vanigliate o

97
00:03:57,120 --> 00:03:58,920
qual è l'idea più discussa del

98
00:03:58,920 --> 00:04:00,659
processo decisionale e dell'inferenza attiva classica

99
00:04:00,659 --> 00:04:03,540
uh quindi se sei in un

100
00:04:03,540 --> 00:04:05,580
ambiente uh  e se sei un agente

101
00:04:05,580 --> 00:04:08,819
che sta cercando di prendere decisioni, allora

102
00:04:08,819 --> 00:04:10,620
hai uno

103
00:04:10,620 --> 00:04:13,319
spazio di azioni disponibili, quindi in

104
00:04:13,319 --> 00:04:15,480
questo modello giocattolo hai tre

105
00:04:15,480 --> 00:04:19,738
azioni disponibili uh corri salta o resta e

106
00:04:19,738 --> 00:04:22,199
date queste azioni puoi sperare di

107
00:04:22,199 --> 00:04:25,139
definire una politica con il piccolo Pi  cheèuna

108
00:04:25,139 --> 00:04:28,320
sequenza di azioni nel tempo e la capitale

109
00:04:28,320 --> 00:04:30,300
tèl'Orizzonte temporale della pianificazione o

110
00:04:30,300 --> 00:04:32,660
questaèla lunghezza della tua

111
00:04:32,660 --> 00:04:36,540
politica e hai uno spazio politico con

112
00:04:36,540 --> 00:04:39,419
molte di queste politiche piccola torta quindi dato

113
00:04:39,419 --> 00:04:42,060
questo spazio più piccolo e più grande puoi

114
00:04:42,060 --> 00:04:44,220
tentare di

115
00:04:44,220 --> 00:04:47,340
valutare il libero previsto  energia basata

116
00:04:47,340 --> 00:04:48,720
sulle convinzioni che hai accumulato

117
00:04:48,720 --> 00:04:50,580
quindi qui non stai minimizzando nulla

118
00:04:50,580 --> 00:04:52,860
hai già una credenza dalla variazione

119
00:04:52,860 --> 00:04:55,080
per l'energia e tu stai solo

120
00:04:55,080 --> 00:04:57,419
calcolando o valutando l'

121
00:04:57,419 --> 00:04:59,520
energia libera prevista corrispondente a molte uh

122
00:04:59,520 --> 00:05:02,759
piccole politiche che puoi definire

123
00:05:02,759 --> 00:05:05,699
e dopo  lo valuti per tutte

124
00:05:05,699 --> 00:05:07,440
le politiche, quindi sai qual è la

125
00:05:07,440 --> 00:05:09,180
politica ottimale da adottare e questa è la

126
00:05:09,180 --> 00:05:11,160
classica idea di inferenza attiva del

127
00:05:11,160 --> 00:05:13,800
processo decisionale giusto e

128
00:05:13,800 --> 00:05:16,020
questa energia libera attesa è davvero

129
00:05:16,020 --> 00:05:18,900
utile nel senso che è

130
00:05:18,900 --> 00:05:21,720
diretta all'obiettivo quindi il termine di rischio è

131
00:05:21,720 --> 00:05:23,520
diretto all'obiettivo  e poi hai questo

132
00:05:23,520 --> 00:05:25,919
termine di ambiguità previsto che ti costringe

133
00:05:25,919 --> 00:05:27,960
anche a esplorare, ma c'è un problema

134
00:05:27,960 --> 00:05:30,539
che questo spazio politico può diventare rapidamente

135
00:05:30,539 --> 00:05:32,400
interagibile e che è sempre rimasto

136
00:05:32,400 --> 00:05:35,280
un collo di bottiglia nel ridimensionamento

137
00:05:35,280 --> 00:05:37,680
dell'inferenza attiva a

138
00:05:37,680 --> 00:05:40,500
um ambienti comunemente visti, ma

139
00:05:40,500 --> 00:05:42,419
vediamo come funziona  diventa rapidamente interagibile

140
00:05:42,419 --> 00:05:45,300
quindi quante politiche possono essere definite diciamo

141
00:05:45,300 --> 00:05:47,940
per un orizzonte temporale di 15 giusto quindi se

142
00:05:47,940 --> 00:05:50,340
stai giocando diciamo Super Mario uh

143
00:05:50,340 --> 00:05:52,440
potresti voler pianificare almeno diciamo 10

144
00:05:52,440 --> 00:05:56,460
passi avanti in modo che la prima politica potrebbe essere

145
00:05:56,460 --> 00:05:58,380
um la stessa azione  esegui

146
00:05:58,380 --> 00:06:02,600
um impilato per 15 fasi temporali e puoi

147
00:06:02,600 --> 00:06:05,460
sostanzialmente definire diverse combinazioni di

148
00:06:05,460 --> 00:06:09,060
tali azioni e lo spazio della politica è

149
00:06:09,060 --> 00:06:10,139
semplicemente

150
00:06:10,139 --> 00:06:13,860
um intrattabile diventa uh troppo grande

151
00:06:13,860 --> 00:06:16,380
per te per valutare l'energia libera prevista

152
00:06:16,380 --> 00:06:19,440
per tutte queste politiche e in un

153
00:06:19,440 --> 00:06:21,900
problema stocastico dove

154
00:06:21,900 --> 00:06:24,419
um  l'ambiente stesso è rumoroso

155
00:06:24,419 --> 00:06:27,120
non hai davvero un metodo per scegliere un

156
00:06:27,120 --> 00:06:28,860
sottoinsieme di questo spazio politico e fare l'

157
00:06:28,860 --> 00:06:30,840
inferenza attiva classica e questo è

158
00:06:30,840 --> 00:06:32,340
chiaramente un problema di interazione computazionale

159
00:06:32,340 --> 00:06:34,380
ed è per questo che in letteratura

160
00:06:34,380 --> 00:06:36,360
vediamo sempre piccole griglie o piccoli

161
00:06:36,360 --> 00:06:38,880
ambienti quando discuti  processo decisionale

162
00:06:38,880 --> 00:06:41,520
nell'influenza attiva ma recentemente

163
00:06:41,520 --> 00:06:43,860
uh è stata proposta una nuova idea

164
00:06:43,860 --> 00:06:46,259
che si chiama

165
00:06:46,259 --> 00:06:48,840
ingresso sofisticato e nell'inferenza sofisticata

166
00:06:48,840 --> 00:06:51,600
non è proprio lo spazio politico in cui

167
00:06:51,600 --> 00:06:52,800
sei in realtà

168
00:06:52,800 --> 00:06:55,080
um tempo reale cercando di

169
00:06:55,080 --> 00:06:58,139
pensare a cosa fare quindi se hai una convinzione

170
00:06:58,139 --> 00:07:00,000
allora tu  stiamo cercando di

171
00:07:00,000 --> 00:07:02,880
um valutare le azioni in base a ciò quindi

172
00:07:02,880 --> 00:07:04,800
qui non abbiamo una sequenza di

173
00:07:04,800 --> 00:07:07,199
politiche o cose che diventa

174
00:07:07,199 --> 00:07:10,020
interagibile uh qui stiamo facendo

175
00:07:10,020 --> 00:07:12,600
fondamentalmente ricerca nel senso che

176
00:07:12,600 --> 00:07:14,220
stai cercando di valutare l'energia libera prevista

177
00:07:14,220 --> 00:07:16,500
di um

178
00:07:16,500 --> 00:07:19,560
questa distribuzione congiunta  di azioni e

179
00:07:19,560 --> 00:07:21,900
osservazioni e per valutare l'

180
00:07:21,900 --> 00:07:23,940
energia libera attesa a un certo momento uh

181
00:07:23,940 --> 00:07:26,340
piccolo T avrai bisogno anche

182
00:07:26,340 --> 00:07:29,039
dell'energia libera attesa al passo temporale successivo e per

183
00:07:29,039 --> 00:07:31,259
valutare che avrai bisogno

184
00:07:31,259 --> 00:07:32,819
dell'energia libera attesa del tempo t + 2 e questo

185
00:07:32,819 --> 00:07:35,039
diventa fondamentalmente  una ricerca che si

186
00:07:35,039 --> 00:07:38,160
sviluppa nel tempo e uh è una

187
00:07:38,160 --> 00:07:41,160
relazione ricorsiva e

188
00:07:41,160 --> 00:07:43,259
qui è fondamentalmente diversa

189
00:07:43,259 --> 00:07:45,539
dallo spazio politico che abbiamo visto nell'ultima

190
00:07:45,539 --> 00:07:47,759
diapositiva a destra ed

191
00:07:47,759 --> 00:07:49,680
è computazionalmente migliore nel

192
00:07:49,680 --> 00:07:51,780
senso che se devi pianificare diciamo 10

193
00:07:51,780 --> 00:07:55,139
volte suggerimenti  avanti in modo completo

194
00:07:55,139 --> 00:07:56,759
nell'inferenza attiva classica abbiamo visto che

195
00:07:56,759 --> 00:07:58,380
gli spazi di policy

196
00:07:58,380 --> 00:07:59,460
um

197
00:07:59,460 --> 00:08:01,940
la cardinalità dello spazio di azione

198
00:08:01,940 --> 00:08:04,139
elevato a T quindi questo è il

199
00:08:04,139 --> 00:08:07,259
collo di bottiglia computazionale se devi uh considerare

200
00:08:07,259 --> 00:08:10,199
tutte le possibilità ma nell'inferenza sofisticata

201
00:08:10,199 --> 00:08:12,780
è anche peggio perché uh

202
00:08:12,780 --> 00:08:14,759
stai considerando un  combinazione di

203
00:08:14,759 --> 00:08:16,860
stato e azioni quindi è

204
00:08:16,860 --> 00:08:20,400
computazionalmente peggiore in realtà ma una

205
00:08:20,400 --> 00:08:21,660
soluzione è stata proposta nel

206
00:08:21,660 --> 00:08:23,520
sofisticato documento di riferimento che

207
00:08:23,520 --> 00:08:26,400
possiamo potare Questa ricerca che

208
00:08:26,400 --> 00:08:29,639
possiamo evitare alcuni stati e azioni uh

209
00:08:29,639 --> 00:08:31,080
quando fai questa ricerca e questo

210
00:08:31,080 --> 00:08:33,000
diventa computazionalmente molto trattabile

211
00:08:33,000 --> 00:08:36,059
quindi vediamo come funziona la potatura

212
00:08:36,059 --> 00:08:38,940
nell'inferenza sofisticata quindi questa griglia è stata

213
00:08:38,940 --> 00:08:40,440
discussa nel documento originale sull'inferenza sofisticata

214
00:08:40,440 --> 00:08:41,700


215
00:08:41,700 --> 00:08:44,580
e diciamo per questa griglia dato che

216
00:08:44,580 --> 00:08:47,100
hai questo tipo di distribuzione delle preferenze precedenti

217
00:08:47,100 --> 00:08:50,399
quindi questo quadrato bianco che

218
00:08:50,399 --> 00:08:52,140
è lo stato dell'obiettivo lo stato più preferito

219
00:08:52,140 --> 00:08:54,300
e  hai una

220
00:08:54,300 --> 00:08:55,380


221
00:08:55,380 --> 00:08:58,140
preferenza uniformemente decrescente per gli

222
00:08:58,140 --> 00:09:00,779
stati che sono lontani da quello

223
00:09:00,779 --> 00:09:03,240
stato dell'oro, quindi in pratica se ti osservi

224
00:09:03,240 --> 00:09:05,480
in ​​qualche osservazione all'istante T,

225
00:09:05,480 --> 00:09:07,560
in pratica quello che stai facendo è

226
00:09:07,560 --> 00:09:09,600
considerare la conseguenza delle

227
00:09:09,600 --> 00:09:12,779
azioni disponibili da quelle osservazioni

228
00:09:12,779 --> 00:09:17,760
e  fondamentalmente puoi usare la proiezione

229
00:09:17,760 --> 00:09:20,700
delle tue convinzioni e impostare una soglia per

230
00:09:20,700 --> 00:09:22,620
quelle convinzioni per forse ignorare

231
00:09:22,620 --> 00:09:24,600
alcune azioni e ignorare alcune

232
00:09:24,600 --> 00:09:27,420
osservazioni e quello che scoprirai è

233
00:09:27,420 --> 00:09:30,120
che non è più alla ricerca

234
00:09:30,120 --> 00:09:33,000
è un sottoinsieme della ricerca ed è un

235
00:09:33,000 --> 00:09:36,060
modo computazionale  uh efficiente che

236
00:09:36,060 --> 00:09:38,700
fare l'intera ricerca nel modo giusto quindi qui

237
00:09:38,700 --> 00:09:40,680
hai evitato molte combinazioni

238
00:09:40,680 --> 00:09:42,120
e questo diventa un

239
00:09:42,120 --> 00:09:45,420
problema computazionalmente attraente questo perché

240
00:09:45,420 --> 00:09:47,880
hai deciso di evitare alcune azioni e

241
00:09:47,880 --> 00:09:49,620
um osservazione quindi dici essenzialmente di

242
00:09:49,620 --> 00:09:52,740
scendere a compromessi su quelle possibilità che

243
00:09:52,740 --> 00:09:54,600
potrebbero darti un  ricompensa più alta o che

244
00:09:54,600 --> 00:09:56,580
potrebbe essere più ottimale della

245
00:09:56,580 --> 00:09:59,700
conseguenza di questa ricerca parziale ma

246
00:09:59,700 --> 00:10:02,820
funziona così questa simulazione

247
00:10:02,820 --> 00:10:05,459
è stata presentata nel documento e funziona

248
00:10:05,459 --> 00:10:09,959
l'agente uh impara a fare uh

249
00:10:09,959 --> 00:10:12,300
quello che deve essere fatto se pianifica in

250
00:10:12,300 --> 00:10:14,940
questa direzione in avanti  di pianificare uh

251
00:10:14,940 --> 00:10:17,880
in modo ridotto ma

252
00:10:17,880 --> 00:10:19,200


253
00:10:19,200 --> 00:10:20,820
e fondamentalmente puoi

254
00:10:20,820 --> 00:10:23,519
dimostrare computazionalmente che anche per una piccola soglia di ricerca

255
00:10:23,519 --> 00:10:25,019


256
00:10:25,019 --> 00:10:27,180
um puoi ridurre drasticamente la

257
00:10:27,180 --> 00:10:29,100
complessità computazionale quindi se

258
00:10:29,100 --> 00:10:31,500
decidi di fare l'intera ricerca

259
00:10:31,500 --> 00:10:33,540
um con la profondità di pianificazione uh il

260
00:10:33,540 --> 00:10:35,100
tempo di calcolo è  esponenziale e

261
00:10:35,100 --> 00:10:38,040
veloce non puoi farci molto allora

262
00:10:38,040 --> 00:10:40,200
ma se decidi a tale soglia

263
00:10:40,200 --> 00:10:42,420
che è anche molto piccola puoi vedere

264
00:10:42,420 --> 00:10:43,980
che questo problema diventa

265
00:10:43,980 --> 00:10:46,620
attrattivo dal punto di vista computazionale e questa

266
00:10:46,620 --> 00:10:49,200
demo uh su istanze sofisticate è

267
00:10:49,200 --> 00:10:50,700
disponibile nella mia versione del mio mdp ed

268
00:10:50,700 --> 00:10:52,860
è  presto sarà integrato

269
00:10:52,860 --> 00:10:55,380
all'originale da mdp

270
00:10:55,380 --> 00:10:56,820
ehm,

271
00:10:56,820 --> 00:10:59,160
ma il punto chiave è che la potatura di

272
00:10:59,160 --> 00:11:01,920
quella ricerca ci richiede una

273
00:11:01,920 --> 00:11:03,779
prima preferenza ben informata come questa,

274
00:11:03,779 --> 00:11:06,060
nel senso che qui l'agente è

275
00:11:06,060 --> 00:11:09,360
consapevole di quanto sia desiderabile il nostro vicino

276
00:11:09,360 --> 00:11:11,760
afferma che non  conosce solo l'

277
00:11:11,760 --> 00:11:13,860
obiettivo finale stabilito, conosce anche il suo

278
00:11:13,860 --> 00:11:16,440
stato vicino e data una tale preferenza a priori

279
00:11:16,440 --> 00:11:18,420
possiamo vedere che per una

280
00:11:18,420 --> 00:11:20,399
profondità di pianificazione di tre l'agente

281
00:11:20,399 --> 00:11:23,820
si blocca sostanzialmente in questo

282
00:11:23,820 --> 00:11:27,060
massimo locale di preferenza a priori, ma con una

283
00:11:27,060 --> 00:11:30,480
profondità di pianificazione sufficiente è  è

284
00:11:30,480 --> 00:11:33,240
in grado di superare questa barriera e raggiungere

285
00:11:33,240 --> 00:11:35,579
lo stato obiettivo uh in questo grande

286
00:11:35,579 --> 00:11:37,800
problema e

287
00:11:37,800 --> 00:11:39,600
la domanda è che cosa succede se l'agente

288
00:11:39,600 --> 00:11:42,720
conosce solo questo stato finale non ha

289
00:11:42,720 --> 00:11:45,660
altra conoscenza su cosa fare e in

290
00:11:45,660 --> 00:11:48,240
questo caso cosa fa l'agente  quindi questo

291
00:11:48,240 --> 00:11:50,459
è il problema che stiamo cercando di

292
00:11:50,459 --> 00:11:53,399
affrontare e in assenza di

293
00:11:53,399 --> 00:11:55,740
una preferenza precedente significativa come questa

294
00:11:55,740 --> 00:11:58,200
l'agente non ha praticamente alcun modo per

295
00:11:58,200 --> 00:12:00,720
raggiungere lo stato dell'obiettivo se non

296
00:12:00,720 --> 00:12:03,300
attraverso un'esplorazione casuale

297
00:12:03,300 --> 00:12:05,279
non ha modo di pianificare perché non

298
00:12:05,279 --> 00:12:08,040
può  uh pianifica otto passi

299
00:12:08,040 --> 00:12:09,779
avanti perché è interagibile dal punto di vista computazionale

300
00:12:09,779 --> 00:12:13,079
uh se sceglie di fare

301
00:12:13,079 --> 00:12:17,880
la ricerca completa nel modo giusto e quindi se è

302
00:12:17,880 --> 00:12:21,000
così per una griglia come questa cosa

303
00:12:21,000 --> 00:12:22,500
fai se ottieni una preferenza di prova scarsa

304
00:12:22,500 --> 00:12:24,240
che non è ben informata

305
00:12:24,240 --> 00:12:28,079
e come evidenziato  nella diapositiva precedente la

306
00:12:28,079 --> 00:12:30,839
tua ricerca è ora cieca uh

307
00:12:30,839 --> 00:12:33,000
non hai modo di potare quella ricerca e

308
00:12:33,000 --> 00:12:35,100
devi fare la ricerca completa in questo

309
00:12:35,100 --> 00:12:36,300
scenario

310
00:12:36,300 --> 00:12:38,880
quindi come potresti aver pensato

311
00:12:38,880 --> 00:12:40,200
um ci sono due soluzioni a questo

312
00:12:40,200 --> 00:12:42,959
o devi trovare un  modo per fare

313
00:12:42,959 --> 00:12:47,359
la pianificazione completa uh

314
00:12:49,579 --> 00:12:52,920
o devi imparare una preferenza Pride significativa

315
00:12:52,920 --> 00:12:54,600
che ti consentirà di fare

316
00:12:54,600 --> 00:12:57,480
uh questa ricerca ridotta quindi

317
00:12:57,480 --> 00:12:59,760
discuteremo queste due soluzioni uh in

318
00:12:59,760 --> 00:13:02,399
questa presentazione uh per un dato

319
00:13:02,399 --> 00:13:03,839
scenario come questo

320
00:13:03,839 --> 00:13:06,420
quindi il primo  soluzione uh per fare una

321
00:13:06,420 --> 00:13:08,639
ricerca completa è fondamentalmente usare la

322
00:13:08,639 --> 00:13:11,399
programmazione dinamica e la programmazione dinamica è

323
00:13:11,399 --> 00:13:13,800
un'idea ben nota nella ricerca operativa

324
00:13:13,800 --> 00:13:15,839
e nell'ingegneria industriale e molti in

325
00:13:15,839 --> 00:13:18,060
molti rami dell'ingegneria e l'

326
00:13:18,060 --> 00:13:19,920
idea di base è che prima

327
00:13:19,920 --> 00:13:21,959
risolvi le sottoparti di un problema più grande

328
00:13:21,959 --> 00:13:24,000
e poi  in seguito cerca di integrare

329
00:13:24,000 --> 00:13:27,000
le soluzioni di questi sottoproblemi uh

330
00:13:27,000 --> 00:13:31,260
per fare uh un processo decisionale ottimale quindi

331
00:13:31,260 --> 00:13:33,779
in questo scenario immagina di

332
00:13:33,779 --> 00:13:37,019
provare a pianificare l'ultima

333
00:13:37,019 --> 00:13:39,540
azione quindi prima siamo partiti dalla

334
00:13:39,540 --> 00:13:41,760
prima azione siamo partiti dal presente

335
00:13:41,760 --> 00:13:44,040
e proviamo a prevedere  ciò che sta accadendo

336
00:13:44,040 --> 00:13:46,320
in futuro, quindi la tua direzione di

337
00:13:46,320 --> 00:13:47,940
pianificazione era fondamentalmente in avanti nel tempo,

338
00:13:47,940 --> 00:13:49,920
ma immagina di provare a pianificare

339
00:13:49,920 --> 00:13:51,959
solo per l'ultimo passaggio temporale in cui

340
00:13:51,959 --> 00:13:55,560
sei proprio vicino allo stato obiettivo e stai

341
00:13:55,560 --> 00:13:57,600
andando proprio a quello stato buono, così tu

342
00:13:57,600 --> 00:13:59,519
stai cercando di prendere una decisione per

343
00:13:59,519 --> 00:14:01,740
quell'ultima fase temporale che è la T maiuscola meno

344
00:14:01,740 --> 00:14:05,459
1 e le tue proiezioni uh per la

345
00:14:05,459 --> 00:14:08,880
fase temporale successiva o l'ultimo stato obiettivo sarà

346
00:14:08,880 --> 00:14:09,839
um

347
00:14:09,839 --> 00:14:11,880
possibile perché hai accesso a

348
00:14:11,880 --> 00:14:14,160
questo modello del mondo uh usando questa

349
00:14:14,160 --> 00:14:16,079
transizione  Dynamics o la matrice B

350
00:14:16,079 --> 00:14:18,600
nell'inferenza attiva quindi per questo singolo

351
00:14:18,600 --> 00:14:21,180
passaggio temporale che è un sottoproblema uh stai

352
00:14:21,180 --> 00:14:24,060
effettivamente valutando una tabella di

353
00:14:24,060 --> 00:14:26,100
energia libera prevista che ti dice se stai

354
00:14:26,100 --> 00:14:28,019
dicendo questa osservazione cosa deve essere fatto

355
00:14:28,019 --> 00:14:31,740
che è per l'ultimo  passo temporale e

356
00:14:31,740 --> 00:14:34,440
fondamentalmente uh puoi farlo nello spazio degli stati

357
00:14:34,440 --> 00:14:36,540
o nello spazio di osservazione quindi questo può

358
00:14:36,540 --> 00:14:39,120
essere fatto uh usando la matrice a e la

359
00:14:39,120 --> 00:14:41,699
matrice D insieme dove puoi

360
00:14:41,699 --> 00:14:44,579
pianificare in entrambi i modi, quindi la

361
00:14:44,579 --> 00:14:46,260
domanda è che

362
00:14:46,260 --> 00:14:48,839
se sai cosa fare nel  passaggi dell'ultima volta a

363
00:14:48,839 --> 00:14:50,940


364
00:14:50,940 --> 00:14:52,440
cui potresti pensare come faccio a sapere

365
00:14:52,440 --> 00:14:54,600
che sono nell'ultimo passaggio del tempo si tratta solo di

366
00:14:54,600 --> 00:14:58,699
immaginare che ti sei

367
00:15:09,720 --> 00:15:12,839
scusato solo l'ultima cosa che abbiamo sentito per un

368
00:15:12,839 --> 00:15:15,540
secondo è stata che si tratta solo di immaginare

369
00:15:15,540 --> 00:15:18,060
sì, quindi riprendi da lì è  tutto

370
00:15:18,060 --> 00:15:19,860
sull'immaginazione va

371
00:15:19,860 --> 00:15:22,139
bene quindi se c'è stato un problema di connessione

372
00:15:22,139 --> 00:15:23,699
sì solo per pochi secondi va tutto

373
00:15:23,699 --> 00:15:25,199
bene poi ora

374
00:15:25,199 --> 00:15:28,260
oh scusa per quello ma quindi

375
00:15:28,260 --> 00:15:30,899
um quindi quello che sto cercando di dire è che

376
00:15:30,899 --> 00:15:32,880
stai cercando di immaginare cosa farai

377
00:15:32,880 --> 00:15:35,519
se tu  sono nella capitale temporale T meno uno

378
00:15:35,519 --> 00:15:37,560
che è l'ultimo passo temporale per il tuo

379
00:15:37,560 --> 00:15:40,260
orizzonte di pianificazione e se sei in quel

380
00:15:40,260 --> 00:15:42,199
passo temporale cosa devo fare questa tabella

381
00:15:42,199 --> 00:15:45,480
rappresenta tutti questi scenari che se

382
00:15:45,480 --> 00:15:49,800
dico all'osservazione 3 al tempo T meno

383
00:15:49,800 --> 00:15:52,680
uno cosa  lo faccio e questa quantità qui

384
00:15:52,680 --> 00:15:54,720
sto considerando solo il termine di rischio o

385
00:15:54,720 --> 00:15:56,279
il termine intenzionale

386
00:15:56,279 --> 00:15:57,720
uh e

387
00:15:57,720 --> 00:16:01,560
questo termine rappresenta quella politica e

388
00:16:01,560 --> 00:16:03,540
cosa succede se lo faccio

389
00:16:03,540 --> 00:16:06,180
um all'indietro fino all'ora T meno uno quindi se lo sono se so

390
00:16:06,180 --> 00:16:08,699
cosa fare  all'ora uh

391
00:16:08,699 --> 00:16:12,300
T maiuscola meno 1 allora questa tabella può

392
00:16:12,300 --> 00:16:14,880
indicare cosa fare con T maiuscola meno 2.

393
00:16:14,880 --> 00:16:16,920
quindi piuttosto che pianificare in anticipo quello che

394
00:16:16,920 --> 00:16:19,320
sto facendo è fondamentalmente impilare

395
00:16:19,320 --> 00:16:22,019
molti tavoli insieme semplicemente fissando una

396
00:16:22,019 --> 00:16:25,019
T maiuscola di pianificazione e

397
00:16:25,019 --> 00:16:29,279
dato che  Ho tutte queste tabelle di stack

398
00:16:29,279 --> 00:16:31,800
quindi fondamentalmente quello che posso fare è usarle

399
00:16:31,800 --> 00:16:33,899
per prendere decisioni in avanti nel tempo e quello che

400
00:16:33,899 --> 00:16:35,940
abbiamo osservato è che questa idea

401
00:16:35,940 --> 00:16:38,519
funziona che

402
00:16:38,519 --> 00:16:40,259
um posso calcolare l'energia libera prevista

403
00:16:40,259 --> 00:16:43,019
all'indietro uh passo dopo passo

404
00:16:43,019 --> 00:16:46,920
considerandoli come problemi secondari  e

405
00:16:46,920 --> 00:16:49,079
la differenza fondamentale è che

406
00:16:49,079 --> 00:16:51,600
nell'inferenza sofisticata uh per calcolare

407
00:16:51,600 --> 00:16:54,959
l'energia libera attesa all'istante T piccolo

408
00:16:54,959 --> 00:16:57,540
non sai qual è l'energia libera attesa

409
00:16:57,540 --> 00:16:59,880
all'istante team più uno quindi questa

410
00:16:59,880 --> 00:17:01,920
diventa una ricerca di tre quindi devi

411
00:17:01,920 --> 00:17:04,319
prima calcolarla  e per calcolare

412
00:17:04,319 --> 00:17:06,839
per t più 1 hai bisogno di t più 2 e così via

413
00:17:06,839 --> 00:17:09,000
ma qui perché lo stai calcolando

414
00:17:09,000 --> 00:17:11,339
all'indietro nel tempo sai già qual

415
00:17:11,339 --> 00:17:13,559
è uh l'energia libera prevista per p

416
00:17:13,559 --> 00:17:16,020
più 1 e basi che è fondamentalmente la

417
00:17:16,020 --> 00:17:17,520
stessa equazione è solo che

418
00:17:17,520 --> 00:17:20,900
lo stai facendo all'indietro nel tempo e

419
00:17:20,900 --> 00:17:23,520
visivamente in un'inferenza sofisticata

420
00:17:23,520 --> 00:17:25,619
stai cercando di fare una ricerca ma

421
00:17:25,619 --> 00:17:27,660
nell'algoritmo di programmazione dinamica stai

422
00:17:27,660 --> 00:17:30,120
facendo la tua pianificazione all'indietro uh usando le

423
00:17:30,120 --> 00:17:32,940
tabelle e data la tua pianificazione L'orizzonte

424
00:17:32,940 --> 00:17:35,520
è sufficiente per un problema quello che

425
00:17:35,520 --> 00:17:38,160
abbiamo  visto è che l'agente sarà in

426
00:17:38,160 --> 00:17:40,860
grado di intraprendere azioni ottimali in avanti nel

427
00:17:40,860 --> 00:17:44,340
tempo, quindi nel documento stiamo anche

428
00:17:44,340 --> 00:17:46,500
proponendo uh un algoritmo per

429
00:17:46,500 --> 00:17:49,020
DPS in forma sequenziale usando uh questa

430
00:17:49,020 --> 00:17:50,880
pianificazione a ritroso nel tempo e siamo stati

431
00:17:50,880 --> 00:17:54,059
in grado di aumentare le simulazioni per gli

432
00:17:54,059 --> 00:17:56,240
spazi della griglia che era  precedentemente interagibile

433
00:17:56,240 --> 00:17:59,340
senza reti neurali

434
00:17:59,340 --> 00:18:01,080
um quindi quella era la prima soluzione

435
00:18:01,080 --> 00:18:03,840
quindi la seconda soluzione è quella

436
00:18:03,840 --> 00:18:06,000
um quindi nella prima soluzione è stato corretto

437
00:18:06,000 --> 00:18:07,980
che ottieni solo questo riferimento privato passato

438
00:18:07,980 --> 00:18:09,539
non ottieni altre

439
00:18:09,539 --> 00:18:10,919
informazioni ottieni solo le tue

440
00:18:10,919 --> 00:18:12,480
informazioni sul  lo stato dell'obiettivo finale

441
00:18:12,480 --> 00:18:15,120
e tutto ciò che ottieni è il modello

442
00:18:15,120 --> 00:18:18,240
dell'ambiente che hai imparato e

443
00:18:18,240 --> 00:18:21,059
fondamentalmente devi prendere decisioni, ma la

444
00:18:21,059 --> 00:18:22,799
seconda soluzione ovviamente è che se ti

445
00:18:22,799 --> 00:18:24,600
è permesso puoi provare a imparare una

446
00:18:24,600 --> 00:18:26,100
preferenza di orgoglio che è significativa

447
00:18:26,100 --> 00:18:28,620
come quella che noi  visto nelle

448
00:18:28,620 --> 00:18:31,740
diapositive precedenti che contiene anche le informazioni sugli

449
00:18:31,740 --> 00:18:33,960
altri stati, ma come

450
00:18:33,960 --> 00:18:35,400
impari bene quindi

451
00:18:35,400 --> 00:18:38,039
c'è un lavoro seminale dalla

452
00:18:38,039 --> 00:18:40,440
letteratura sul controllo ottimale che parla del

453
00:18:40,440 --> 00:18:43,380
calcolo efficiente delle azioni ottimali

454
00:18:43,380 --> 00:18:45,900
e in quel lavoro c'è una quantità

455
00:18:45,900 --> 00:18:47,760
simile al nostro  preferenza prioritaria che si

456
00:18:47,760 --> 00:18:49,500
chiama funzione di desiderabilità quindi, ad

457
00:18:49,500 --> 00:18:52,200
esempio, in questa griglia World

458
00:18:52,200 --> 00:18:54,240
um qui i colori più scuri sono più preferiti

459
00:18:54,240 --> 00:18:56,400
quindi se questo attraversa il tuo stato d'oro finale

460
00:18:56,400 --> 00:18:58,740
ciò che l'agente in questo documento sta cercando

461
00:18:58,740 --> 00:19:01,980
di fare uh o il suddetto metodo di apprendimento in

462
00:19:01,980 --> 00:19:04,580
questo documento è  cercare di fare è apprendere questa

463
00:19:04,580 --> 00:19:06,900
funzione di desiderabilità nel modo più ottimale

464
00:19:06,900 --> 00:19:09,059
possibile e ciò che è stato dimostrato in questo

465
00:19:09,059 --> 00:19:12,660
documento è che se si tenta di apprendere la

466
00:19:12,660 --> 00:19:15,179
funzione di desiderabilità utilizzando una particolare

467
00:19:15,179 --> 00:19:18,120
regola di apprendimento, è computazionalmente molto

468
00:19:18,120 --> 00:19:20,340
più efficiente persino dell'apprendimento Q

469
00:19:20,340 --> 00:19:22,919
che è un buon  noto

470
00:19:22,919 --> 00:19:24,960
algoritmo di apprendimento per rinforzo, quindi l'apprendimento Q è un

471
00:19:24,960 --> 00:19:27,179
noto algoritmo computazionalmente ottimale,

472
00:19:27,179 --> 00:19:29,520
ma in questo documento quella

473
00:19:29,520 --> 00:19:31,140
particolare regola di apprendimento per l'apprendimento

474
00:19:31,140 --> 00:19:32,880
di questo tipo di funzione di desiderabilità è

475
00:19:32,880 --> 00:19:35,539
molto più veloce e questo approssimato

476
00:19:35,539 --> 00:19:38,460
rappresenta quanto sia diverso dalla

477
00:19:38,460 --> 00:19:40,559
funzione di desiderabilità ottimale, quindi questo

478
00:19:40,559 --> 00:19:42,480
la funzione di desiderabilità non è altro che la nostra

479
00:19:42,480 --> 00:19:45,179
preferenza precedente e,

480
00:19:45,179 --> 00:19:48,600
come accennato, l'apprendimento ha detto che i confini di

481
00:19:48,600 --> 00:19:50,100
grandezza sono efficienti rispetto all'apprendimento della

482
00:19:50,100 --> 00:19:53,039
funzione Q nell'apprendimento Q, quindi

483
00:19:53,039 --> 00:19:55,860
questa è la particolare regola di apprendimento che

484
00:19:55,860 --> 00:19:57,600
dipende dalla ricompensa che ottiene

485
00:19:57,600 --> 00:19:59,820
dall'ambiente e in questa

486
00:19:59,820 --> 00:20:01,860
particolare griglia Ambiente mondiale  gli stiamo

487
00:20:01,860 --> 00:20:03,539
solo dando una ricompensa all'ultimo passaggio

488
00:20:03,539 --> 00:20:05,220
che è simile alla scarsa

489
00:20:05,220 --> 00:20:08,580
preferenza di un amico l'agente praticamente non ottiene alcuna

490
00:20:08,580 --> 00:20:11,400
ricompensa fino a quando non raggiunge lo

491
00:20:11,400 --> 00:20:14,760
stato dell'obiettivo finale e con questa regola di apprendimento

492
00:20:14,760 --> 00:20:17,640
che ha un parametro ETA che

493
00:20:17,640 --> 00:20:20,100
controlla quanto velocemente o lentamente

494
00:20:20,100 --> 00:20:22,980
questo  Learning Happens quindi fondamentalmente

495
00:20:22,980 --> 00:20:24,200
proviamo a

496
00:20:24,200 --> 00:20:26,880
studiare l'effetto di questo

497
00:20:26,880 --> 00:20:29,340
parametro di apprendimento Rita, ma ciò che abbiamo osservato è

498
00:20:29,340 --> 00:20:32,400
che è molto robusto può apprendere la

499
00:20:32,400 --> 00:20:35,059
preferenza precedente in modo affidabile anche con

500
00:20:35,059 --> 00:20:38,700
valori variabili di questo uh

501
00:20:38,700 --> 00:20:41,580
parametro di apprendimento e ciò che vediamo è che l'

502
00:20:41,580 --> 00:20:43,620
agente è in grado  per apprendere una

503
00:20:43,620 --> 00:20:45,539
prestazione precedente significativa nel tempo molto velocemente

504
00:20:45,539 --> 00:20:48,600
e utilizzando una preferenza Prime così significativa,

505
00:20:48,600 --> 00:20:50,700
allora l'agente non deve

506
00:20:50,700 --> 00:20:53,580
pianificare molto, può gestire un

507
00:20:53,580 --> 00:20:56,160
comportamento ottimale o un comportamento mirato con

508
00:20:56,160 --> 00:20:59,700
orizzonti temporali molto bassi di pianificazione e

509
00:20:59,700 --> 00:21:02,460
date queste due soluzioni potremmo

510
00:21:02,460 --> 00:21:04,679
aumentare l'algoritmo di inferenza attiva per il

511
00:21:04,679 --> 00:21:07,919
processo decisionale e parlare

512
00:21:07,919 --> 00:21:11,400
dell'efficienza computazionale uh abbiamo visto che

513
00:21:11,400 --> 00:21:13,320
il metodo di programmazione dinamica potrebbe

514
00:21:13,320 --> 00:21:16,440
piantare 30 passi temporali nel futuro uh

515
00:21:16,440 --> 00:21:18,360
con solo dire una complessità computazionale

516
00:21:18,360 --> 00:21:21,120
di mille rispetto a dire 10

517
00:21:21,120 --> 00:21:23,700
alla potenza 68 per sofisticati  inferenza

518
00:21:23,700 --> 00:21:26,880
e il secondo metodo che apprende la

519
00:21:26,880 --> 00:21:29,580
preferenza precedente uh che chiamiamo

520
00:21:29,580 --> 00:21:32,340
inferenza attiva e deve solo pianificare un

521
00:21:32,340 --> 00:21:34,740
passo avanti, quindi è molto più

522
00:21:34,740 --> 00:21:36,919
efficiente dal punto di vista computazionale in quel senso,

523
00:21:36,919 --> 00:21:39,659
ma deve imparare così nel

524
00:21:39,659 --> 00:21:41,640
metodo DPFE che non stiamo imparando  stiamo usando

525
00:21:41,640 --> 00:21:43,799
gli spot di preferenza e facendo l'

526
00:21:43,799 --> 00:21:44,520
intera

527
00:21:44,520 --> 00:21:46,500
profondità della pianificazione e nell'altro

528
00:21:46,500 --> 00:21:48,240
metodo stiamo lasciando che l'agente lo impari

529
00:21:48,240 --> 00:21:50,280
di preferenza, ma poi possiamo risparmiare

530
00:21:50,280 --> 00:21:53,280
molto sulla pianificazione perché sa molto di

531
00:21:53,280 --> 00:21:57,299
cosa fare in tempo giusto così

532
00:21:57,299 --> 00:22:00,179
graficamente  possiamo vedere che um

533
00:22:00,179 --> 00:22:01,799
il metodo DPFE è davvero

534
00:22:01,799 --> 00:22:04,020
efficiente dal punto di vista computazionale e quando

535
00:22:04,020 --> 00:22:06,600
tracciato contro il tempo uh nell'AI 50

536
00:22:06,600 --> 00:22:08,520
uguale a un metodo

537
00:22:08,520 --> 00:22:10,740
um è fondamentalmente

538
00:22:10,740 --> 00:22:12,659
più economico dal punto di vista computazionale

539
00:22:12,659 --> 00:22:16,220
e sì, quindi si adatta in modo molto

540
00:22:16,220 --> 00:22:19,860
affascinante uh con Higher and

541
00:22:19,860 --> 00:22:21,720
Higher e

542
00:22:21,720 --> 00:22:24,120
complessità del  ambiente quindi l'abbiamo

543
00:22:24,120 --> 00:22:27,600
testato uh questi metodi in

544
00:22:27,600 --> 00:22:28,380
um

545
00:22:28,380 --> 00:22:31,020
spazi statali molto enormi come diciamo 900

546
00:22:31,020 --> 00:22:32,000
stati

547
00:22:32,000 --> 00:22:33,840
rispetto a

548
00:22:33,840 --> 00:22:36,120
um spazi statali che ha dimensioni

549
00:22:36,120 --> 00:22:38,640
diciamo 5 o 10 nella letteratura sull'influenza attiva solitamente vista

550
00:22:38,640 --> 00:22:40,559


551
00:22:40,559 --> 00:22:43,200
um quindi voglio sottolineare che

552
00:22:43,200 --> 00:22:44,760
siamo  non stiamo usando alcuna rete neurale

553
00:22:44,760 --> 00:22:47,039
qui stiamo usando

554
00:22:47,039 --> 00:22:49,740
agenti di inferenza attiva spiegabili stanno

555
00:22:49,740 --> 00:22:52,200
facendo tutte le moltiplicazioni di matrici necessarie

556
00:22:52,200 --> 00:22:53,820
in modo da avere accesso

557
00:22:53,820 --> 00:22:55,140
e

558
00:22:55,140 --> 00:22:56,220


559
00:22:56,220 --> 00:22:58,620
spiegabilità a ogni calcolo che

560
00:22:58,620 --> 00:23:00,179
sta avvenendo in questo in questi

561
00:23:00,179 --> 00:23:02,280
algoritmi e quando testato su queste

562
00:23:02,280 --> 00:23:04,559
griglie prima lo abbiamo convalidato  su una

563
00:23:04,559 --> 00:23:06,780
griglia più piccola con understates e abbiamo

564
00:23:06,780 --> 00:23:08,580
osservato che

565
00:23:08,580 --> 00:23:11,220
rispetto agli

566
00:23:11,220 --> 00:23:12,780
algoritmi di apprendimento per rinforzo di Benchmark come l'apprendimento in coda

567
00:23:12,780 --> 00:23:15,059
e dynaq dynacy è un

568
00:23:15,059 --> 00:23:17,760
algoritmo di apprendimento per rinforzo basato su modello e abbiamo

569
00:23:17,760 --> 00:23:20,280
confrontato i nostri agenti appena proposti che

570
00:23:20,280 --> 00:23:24,419
sono DPFE e aif e abbiamo visto prestazioni davvero buone

571
00:23:24,419 --> 00:23:27,900
e  l'agente aif è leggermente

572
00:23:27,900 --> 00:23:29,220
peggiore ed è perché sta

573
00:23:29,220 --> 00:23:31,080
pianificando solo una volta un passo avanti giusto, ma

574
00:23:31,080 --> 00:23:34,500
l'agente DPFE che pianifica a tempo pieno

575
00:23:34,500 --> 00:23:36,419
si sta comportando bene come il

576
00:23:36,419 --> 00:23:37,919
benchmarking degli algoritmi di apprendimento personale

577
00:23:37,919 --> 00:23:41,039
e l'abbiamo testato con um

578
00:23:41,039 --> 00:23:44,640
griglie più grandi e più deboli e quando abbiamo

579
00:23:44,640 --> 00:23:47,100
introdotto la stocasticità in  lo

580
00:23:47,100 --> 00:23:49,620
stato dell'oro nel senso che quando l'agente

581
00:23:49,620 --> 00:23:53,039
doveva navigare verso

582
00:23:53,039 --> 00:23:54,480
uno

583
00:23:54,480 --> 00:23:56,520
stato dell'oro stocastico, quindi abbiamo cambiato gli

584
00:23:56,520 --> 00:23:59,460
stati dell'oro ogni 10 episodi e

585
00:23:59,460 --> 00:24:01,260
ciò che abbiamo osservato è che la coda Dyna

586
00:24:01,260 --> 00:24:04,140
ha impiegato più tempo del nostro agente bpfe per

587
00:24:04,140 --> 00:24:07,200
recuperare e fare  beh, quindi l'

588
00:24:07,200 --> 00:24:09,059
agente DPFE in questo ambiente stocastico si è

589
00:24:09,059 --> 00:24:11,280
comportato davvero bene anche meglio degli

590
00:24:11,280 --> 00:24:13,620
agenti dinamici e puoi anche vedere

591
00:24:13,620 --> 00:24:16,500
che la fase AI e si sta riprendendo

592
00:24:16,500 --> 00:24:19,140
più velocemente ma non così bene come gli altri

593
00:24:19,140 --> 00:24:22,500
agenti, quindi in pratica questo è stato il risultato

594
00:24:22,500 --> 00:24:25,200
nel documento e il  metodi Quindi sì,

595
00:24:25,200 --> 00:24:27,960
grazie per l'ascolto e sono aperto alle

596
00:24:27,960 --> 00:24:30,380
discussioni

597
00:24:31,640 --> 00:24:34,740
va bene fantastico

598
00:24:34,740 --> 00:24:36,360
wow

599
00:24:36,360 --> 00:24:38,520
molto bello ok

600
00:24:38,520 --> 00:24:43,200
bene proprio mentre iniziamo la

601
00:24:43,200 --> 00:24:44,460
discussione

602
00:24:44,460 --> 00:24:47,280
um se qualcuno vuole aggiungere qualcosa prima

603
00:24:47,280 --> 00:24:50,220
come sei arrivato a lavorare su questo

604
00:24:50,220 --> 00:24:52,740
progetto uh stavi studiando

605
00:24:52,740 --> 00:24:54,720
inferenza attiva e sei arrivato a questa domanda

606
00:24:54,720 --> 00:24:57,900
come interessante o stavi lavorando

607
00:24:57,900 --> 00:25:00,179
alla pianificazione e sei arrivato

608
00:25:00,179 --> 00:25:03,059
all'inferenza attiva come metodo

609
00:25:03,059 --> 00:25:05,159
um sì così un po 'di background su

610
00:25:05,159 --> 00:25:08,400
me stesso quindi ho studiato fisica sia durante la mia

611
00:25:08,400 --> 00:25:11,340
laurea e post che e verso la

612
00:25:11,340 --> 00:25:13,080
fine di  dopo la laurea mi sono

613
00:25:13,080 --> 00:25:15,120
interessato a cose come la teoria dei giochi

614
00:25:15,120 --> 00:25:17,880
e l'apprendimento riutilizzabile e mi sono unito a uh

615
00:25:17,880 --> 00:25:20,880
per un dottorato di ricerca congiunto con il professor Adil

616
00:25:20,880 --> 00:25:23,100
e il professor Manoj e quindi il professor

617
00:25:23,100 --> 00:25:25,200
Manoj è una persona di teoria del controllo e un

618
00:25:25,200 --> 00:25:28,140
accordo è un neuroscienziato e

619
00:25:28,140 --> 00:25:30,600
all'inizio del mio  Dottorato di ricerca Ho iniziato a leggere la

620
00:25:30,600 --> 00:25:34,020
letteratura sull'inferenza attiva e volevo

621
00:25:34,020 --> 00:25:37,260
implementarla nei problemi e sono

622
00:25:37,260 --> 00:25:39,840
sempre stato affascinato

623
00:25:39,840 --> 00:25:42,720
dall'inferenza attiva spiegabile uh su questa idea di

624
00:25:42,720 --> 00:25:44,700
energia libera attesa cercando di minimizzare

625
00:25:44,700 --> 00:25:46,860
il rischio e l'ambiguità attesa,

626
00:25:46,860 --> 00:25:49,740
inoltre non è solo far funzionare gli agenti ma

627
00:25:49,740 --> 00:25:52,020
anche essere in grado di raccontare come funzionano è

628
00:25:52,020 --> 00:25:54,419
ciò che mi ha affascinato nell'influenza attiva

629
00:25:54,419 --> 00:25:56,820
e inizialmente cerco di implementarli

630
00:25:56,820 --> 00:26:00,179
e c'è un documento della conferenza che abbiamo

631
00:26:00,179 --> 00:26:03,720
pubblicato in cui lo confrontiamo per un

632
00:26:03,720 --> 00:26:06,419
compito simile alla griglia e che poi ho

633
00:26:06,419 --> 00:26:08,100
affrontato questo problema di ridimensionamento

634
00:26:08,100 --> 00:26:10,620
inferenza attiva e poi ho iniziato a lavorare su

635
00:26:10,620 --> 00:26:12,659
un'inferenza sofisticata

636
00:26:12,659 --> 00:26:15,539
um sì, quindi in pratica questi metodi sono

637
00:26:15,539 --> 00:26:17,580
nati dalla necessità che volevo

638
00:26:17,580 --> 00:26:21,539
ridimensionare la mappa e ho sempre tenuto il bus attento

639
00:26:21,539 --> 00:26:22,919
nell'usare

640
00:26:22,919 --> 00:26:25,559
um inferenza attiva profonda perché

641
00:26:25,559 --> 00:26:28,020
um non volevo usare  reti neurali

642
00:26:28,020 --> 00:26:30,539
per fare la pianificazione Perché

643
00:26:30,539 --> 00:26:32,100
l'apprendimento per rinforzo profondo di per sé è un

644
00:26:32,100 --> 00:26:34,140
campo enorme e

645
00:26:34,140 --> 00:26:37,080
um se tu se stai solo ridimensionando

646
00:26:37,080 --> 00:26:39,240
l'inferenza attiva allora forse fai solo

647
00:26:39,240 --> 00:26:41,820
l'apprendimento per rinforzo profondo ed è quello che ho

648
00:26:41,820 --> 00:26:43,860
pensato sì quindi questo è fondamentalmente lo

649
00:26:43,860 --> 00:26:45,659
sfondo e

650
00:26:45,659 --> 00:26:48,720
sì è così  è successo

651
00:26:48,720 --> 00:26:50,880
tutto bene Andrò prima a una domanda

652
00:26:50,880 --> 00:26:52,559
nella chat dal vivo e

653
00:26:52,559 --> 00:26:54,779
probabilmente discuteremo di vari aspetti perché

654
00:26:54,779 --> 00:26:57,720
c'era molto nella tua presentazione quindi

655
00:26:57,720 --> 00:27:01,980
NL Dawn scrive mi chiedo quando si tratta di

656
00:27:01,980 --> 00:27:04,620
calcolare l'energia libera prevista su

657
00:27:04,620 --> 00:27:07,679
un  Time Horizon che tipo di approssimazione del campo medio

658
00:27:07,679 --> 00:27:11,039
è stata utilizzata per fattorizzare Q di

659
00:27:11,039 --> 00:27:13,020
s

660
00:27:13,020 --> 00:27:16,100
store

661
00:27:19,980 --> 00:27:23,040
quindi presumo che la domanda riguardi

662
00:27:23,040 --> 00:27:24,299
[Musica]

663
00:27:24,299 --> 00:27:28,799
l'energia libera prevista in DPFE e

664
00:27:28,799 --> 00:27:31,380
per calcolarla fondamentalmente

665
00:27:31,380 --> 00:27:32,159
um

666
00:27:32,159 --> 00:27:35,279
quindi nelle mie simulazioni uso la

667
00:27:35,279 --> 00:27:39,120
propagazione delle convinzioni per questo  coda di convinzioni e

668
00:27:39,120 --> 00:27:41,460
puoi anche usare il passaggio di

669
00:27:41,460 --> 00:27:43,140
messaggi variazionali o il passaggio di messaggi marginali

670
00:27:43,140 --> 00:27:47,279
non è un problema, ma

671
00:27:47,400 --> 00:27:50,580
quindi una volta che hai questa coda di convinzioni

672
00:27:50,580 --> 00:27:52,740
um cosa fai bene quindi

673
00:27:52,740 --> 00:27:55,340


674
00:27:56,940 --> 00:27:59,900
sì, quindi

675
00:27:59,940 --> 00:28:04,260
quando dico che immagini Q per un po ', allora

676
00:28:04,260 --> 00:28:07,520
quello che uso principalmente  è un vettore caldo quindi

677
00:28:07,520 --> 00:28:11,220
per prendere decisioni usi la convinzione

678
00:28:11,220 --> 00:28:13,260
di uscire dalla tua fase di percezione

679
00:28:13,260 --> 00:28:16,380
nell'inferenza attiva ma per immaginare che

680
00:28:16,380 --> 00:28:18,720
questi siano tavoli difficili in cui sono un

681
00:28:18,720 --> 00:28:22,020
vettore caldo quindi supponiamo che tu abbia nel tuo

682
00:28:22,020 --> 00:28:25,380
modello generativo ha 10 stati uh il tuo

683
00:28:25,380 --> 00:28:27,900
le code che usi sono

684
00:28:27,900 --> 00:28:29,100


685
00:28:29,100 --> 00:28:32,220
segnali precisi per la pianificazione ma per il processo

686
00:28:32,220 --> 00:28:33,840
decisionale usi la

687
00:28:33,840 --> 00:28:36,299
coda di approssimazione del campo medio imprecisa

688
00:28:36,299 --> 00:28:38,460
che ottieni dalla fase di percezione quindi

689
00:28:38,460 --> 00:28:40,679
non so se questo risponde alla

690
00:28:40,679 --> 00:28:42,059
domanda

691
00:28:42,059 --> 00:28:44,880
um ma forse voglio anche pensare

692
00:28:44,880 --> 00:28:46,919
Devo anche pensare di più alle

693
00:28:46,919 --> 00:28:49,200
approssimazioni che potrebbero esserci nei

694
00:28:49,200 --> 00:28:50,880
passaggi

695
00:28:50,880 --> 00:28:53,700
figo sì possono possono scrivere di più

696
00:28:53,700 --> 00:28:56,460
se vogliono um parliamo un po'

697
00:28:56,460 --> 00:29:00,419
più in generale dell'apprendimento delle preferenze

698
00:29:00,419 --> 00:29:02,700
quindi nel contesto del

699
00:29:02,700 --> 00:29:05,940
modello generativo di inferenza attiva noi  avere una

700
00:29:05,940 --> 00:29:08,279
mediazione tra le osservazioni negli

701
00:29:08,279 --> 00:29:10,020
stati nascosti e l'apprendimento ha

702
00:29:10,020 --> 00:29:12,480
molto senso si tratta di imparare la

703
00:29:12,480 --> 00:29:14,220
mappatura tra le osservazioni negli

704
00:29:14,220 --> 00:29:15,779
stati nascosti del mondo e poi abbiamo

705
00:29:15,779 --> 00:29:18,240
bimparare l'apprendimento delle conseguenze

706
00:29:18,240 --> 00:29:20,399
dell'azione e di come le cose cambiano nel

707
00:29:20,399 --> 00:29:21,419
tempo

708
00:29:21,419 --> 00:29:24,659
e l'apprendimento delle preferenze sta imparando su  c

709
00:29:24,659 --> 00:29:27,960
c e hai evidenziato che questa

710
00:29:27,960 --> 00:29:29,700
è una variabile molto um

711
00:29:29,700 --> 00:29:31,340
sai

712
00:29:31,340 --> 00:29:34,320
interessante da imparare

713
00:29:34,320 --> 00:29:38,100
e sono curioso di sapere come impariamo

714
00:29:38,100 --> 00:29:41,159
a imparare la cosa giusta come sappiamo

715
00:29:41,159 --> 00:29:42,960
che stiamo imparando una preferenza adattiva

716
00:29:42,960 --> 00:29:44,399


717
00:29:44,399 --> 00:29:46,200
e poi come  l'

718
00:29:46,200 --> 00:29:48,720
apprendimento delle preferenze riduce il sovraccarico cognitivo o la

719
00:29:48,720 --> 00:29:50,820
complessità computazionale

720
00:29:50,820 --> 00:29:53,460
sì fantastico

721
00:29:53,460 --> 00:29:54,480
umquindi

722
00:29:54,480 --> 00:29:57,179
se stai cercando di imparare una

723
00:29:57,179 --> 00:29:59,940
preferenza di preghiera allora presuppone che ci

724
00:29:59,940 --> 00:30:01,559
sia qualcosa da inseguire o c'è

725
00:30:01,559 --> 00:30:04,500
qualcosa da massimizzare come una ricompensa quindi

726
00:30:04,500 --> 00:30:06,779
in questo diciamo uh in un

727
00:30:06,779 --> 00:30:08,340
apprendimento di rinforzo  impostando c'è una chiara ricompensa

728
00:30:08,340 --> 00:30:09,840
che proviene dall'ambiente che

729
00:30:09,840 --> 00:30:12,960
stai cercando di massimizzare e dì che per

730
00:30:12,960 --> 00:30:15,000
questa griglia ottieni quella ricompensa solo

731
00:30:15,000 --> 00:30:17,220
nell'ultimo passaggio che è quello che è ciò

732
00:30:17,220 --> 00:30:19,020
che rende difficile questo problema quindi

733
00:30:19,020 --> 00:30:22,500
se ricevi ricompense ad ogni

734
00:30:22,500 --> 00:30:25,140
passo temporale quindi fondamentalmente sai cosa fare

735
00:30:25,140 --> 00:30:28,020
che devo solo perseguire quella ricompensa

736
00:30:28,020 --> 00:30:30,419
ad ogni passo giusto, ma qui

737
00:30:30,419 --> 00:30:32,880
potresti dover fare 15 passi

738
00:30:32,880 --> 00:30:36,059
avanti per ottenere quella ricompensa e che

739
00:30:36,059 --> 00:30:39,659
fondamentalmente è difficile farlo qui um se  stai

740
00:30:39,659 --> 00:30:41,520
provando perché sto cercando di

741
00:30:41,520 --> 00:30:43,020
imparare una preferenza precedente

742
00:30:43,020 --> 00:30:44,820
um dovrebbe esserci una struttura di ricompensa

743
00:30:44,820 --> 00:30:47,940
che esiste nell'ambiente

744
00:30:47,940 --> 00:30:49,919
se l'ambiente non si preoccupa di

745
00:30:49,919 --> 00:30:52,200
quello che faccio o se non riesco a definire cosa è

746
00:30:52,200 --> 00:30:54,840
buono o cattivo  quindi non ha senso

747
00:30:54,840 --> 00:30:56,340
imparare la preferenza precedente, quindi

748
00:30:56,340 --> 00:30:57,840
qui

749
00:30:57,840 --> 00:30:59,399
um la ricompensa è ciò che controlla l'

750
00:30:59,399 --> 00:31:01,559
apprendimento della differenza Sprite e

751
00:31:01,559 --> 00:31:03,600
la cosa buona è che anche se solo

752
00:31:03,600 --> 00:31:06,539
ottengo la ricompensa all'ultimo passo temporale

753
00:31:06,539 --> 00:31:09,240
um ho le mie matrici B e  Ho

754
00:31:09,240 --> 00:31:11,340
esperienza di transizione da

755
00:31:11,340 --> 00:31:12,659
stati diversi

756
00:31:12,659 --> 00:31:14,760
um che ho raggiunto questo stato d'oro finale

757
00:31:14,760 --> 00:31:16,860
e

758
00:31:16,860 --> 00:31:19,440
questo algoritmo che stiamo usando o la

759
00:31:19,440 --> 00:31:21,539
regola di apprendimento che stiamo usando sta

760
00:31:21,539 --> 00:31:23,820
proprio imparando una cosa simile nel

761
00:31:23,820 --> 00:31:26,340
controllo ottimale quel documento che ho introdotto

762
00:31:26,340 --> 00:31:27,539
che si chiama

763
00:31:27,539 --> 00:31:30,539
funzione di desiderabilità  e dato che hai questa

764
00:31:30,539 --> 00:31:32,760
funzione di desiderabilità, quindi immagina che

765
00:31:32,760 --> 00:31:36,120
forse sto partendo da questo stato, allora

766
00:31:36,120 --> 00:31:37,860
devo solo guardare i miei vicini più vicini

767
00:31:37,860 --> 00:31:40,399
per prendere una decisione

768
00:31:40,399 --> 00:31:44,279
se lo

769
00:31:44,279 --> 00:31:46,620
Stato um dichiarato al di sotto dello stato è più

770
00:31:46,620 --> 00:31:48,899
preferito di quanto devo solo pianificarne uno

771
00:31:48,899 --> 00:31:50,520
tempo invece avanti e questa è la

772
00:31:50,520 --> 00:31:52,380
decisione ottimale che devo prendere,

773
00:31:52,380 --> 00:31:54,059
quindi imparare questa preferenza Pride

774
00:31:54,059 --> 00:31:55,919
riduce il carico cognitivo, nel senso

775
00:31:55,919 --> 00:31:57,419
che sto guardando solo ora i vicini più vicini

776
00:31:57,419 --> 00:31:59,760
Non devo pianificare tutto

777
00:31:59,760 --> 00:32:01,799
fino a questo buono stato finale

778
00:32:01,799 --> 00:32:04,799
e lo imparerò nel modo più efficiente

779
00:32:04,799 --> 00:32:07,260
possibile perché uno era un

780
00:32:07,260 --> 00:32:09,659
algoritmo garantito, ne abbiamo testato la

781
00:32:09,659 --> 00:32:13,320
robustezza ed è anche informato

782
00:32:13,320 --> 00:32:14,580
dalla ricompensa che ottengo

783
00:32:14,580 --> 00:32:15,659
dall'ambiente e

784
00:32:15,659 --> 00:32:20,100
se sì, quindi se c'è un modo uh per

785
00:32:20,100 --> 00:32:22,860
definire  cosa è preferito uh, allora

786
00:32:22,860 --> 00:32:24,840
sei sicuro di imparare un

787
00:32:24,840 --> 00:32:26,520
amico privato che è significativo

788
00:32:26,520 --> 00:32:28,559
da questo algoritmo,

789
00:32:28,559 --> 00:32:31,559
quindi se vengono utilizzati solo i vicini più vicini

790
00:32:31,559 --> 00:32:34,260
e l'inferenza di un passo temporale,

791
00:32:34,260 --> 00:32:37,320
allora cosa impedisce a questo tipo di

792
00:32:37,320 --> 00:32:39,360
agente di apprendimento delle preferenze di rimanere

793
00:32:39,360 --> 00:32:43,158
bloccato in un Optima locale

794
00:32:43,320 --> 00:32:47,520
um sì così  non ci saranno Optima locali

795
00:32:47,520 --> 00:32:50,340
qui questo è il punto come

796
00:32:50,340 --> 00:32:52,860
um perché dovrebbe esserci un Optima locale uh se lo

797
00:32:52,860 --> 00:32:57,059
sto imparando usando i premi uh

798
00:32:57,059 --> 00:33:00,120
sì quindi se c'è Optima locale allora

799
00:33:00,120 --> 00:33:02,159
rimarrà bloccato nell'Optima locale

800
00:33:02,159 --> 00:33:05,460
ma lì ha vinto  non essere uno uh se

801
00:33:05,460 --> 00:33:07,440
stai imparando è in questo modo perché

802
00:33:07,440 --> 00:33:08,760
lo stai imparando dalla tua

803
00:33:08,760 --> 00:33:11,940
esperienza e come hai ottenuto la ricompensa a

804
00:33:11,940 --> 00:33:14,220
volte uh a volte e quello che abbiamo

805
00:33:14,220 --> 00:33:16,980
osservato è che uh è molto

806
00:33:16,980 --> 00:33:17,760
um

807
00:33:17,760 --> 00:33:20,399
graduale e non ci sono difetti  o

808
00:33:20,399 --> 00:33:23,880
Optimas locali quando impari come

809
00:33:23,880 --> 00:33:27,840
quindi è una specie di riempimento posteriore di una

810
00:33:27,840 --> 00:33:30,179
preferenza

811
00:33:30,179 --> 00:33:33,539
in modo che possa esserci un percorso regolare

812
00:33:33,539 --> 00:33:36,779
sì verso l'obiettivo distale

813
00:33:36,779 --> 00:33:39,480
sì quindi nell'animazione fa

814
00:33:39,480 --> 00:33:42,299
sembrare una sensazione posteriore ma

815
00:33:42,299 --> 00:33:44,279
um in realtà sei  imparandolo dalla tua

816
00:33:44,279 --> 00:33:45,360
esperienza

817
00:33:45,360 --> 00:33:46,620
um

818
00:33:46,620 --> 00:33:49,980
avanti nel tempo giusto quindi ho osservato una

819
00:33:49,980 --> 00:33:51,480
ricompensa quando sono passato da questo

820
00:33:51,480 --> 00:33:53,100
stato allo stato quindi questo deve essere buono

821
00:33:53,100 --> 00:33:55,860
uh allora nel prossimo passo temporale

822
00:33:55,860 --> 00:33:58,559
dico ok questa data è responsabile per

823
00:33:58,559 --> 00:34:00,419
portarmi lì  quindi anche questo potrebbe essere buono

824
00:34:00,419 --> 00:34:03,120
ma non buono come l'altro

825
00:34:03,120 --> 00:34:05,100
quindi sembra che stia imparando all'indietro

826
00:34:05,100 --> 00:34:07,799
ma in realtà sta imparando dal vero

827
00:34:07,799 --> 00:34:12,000
um in t più un'esperienza

828
00:34:13,500 --> 00:34:15,119
okay lo

829
00:34:15,119 --> 00:34:16,980
sai quindi in quel modo

830
00:34:16,980 --> 00:34:20,339
um non puoi avere Maxim locali perché

831
00:34:20,339 --> 00:34:21,300
um

832
00:34:21,300 --> 00:34:24,119
sì questa è la regola di apprendimento che lo fa,

833
00:34:24,119 --> 00:34:25,859
quindi non so come rispondere in modo

834
00:34:25,859 --> 00:34:29,219
più sistematico sì sì

835
00:34:29,219 --> 00:34:33,000
um quali situazioni del mondo reale o o

836
00:34:33,000 --> 00:34:35,399
quali situazioni della vita reale

837
00:34:35,399 --> 00:34:37,560
vedi questo tipo di apprendimento delle preferenze

838
00:34:37,560 --> 00:34:40,080
accadere in

839
00:34:40,080 --> 00:34:41,159
sì

840
00:34:41,159 --> 00:34:43,020
fantastico  domanda quindi

841
00:34:43,020 --> 00:34:46,080
quindi c'è un documento che è uscito dal

842
00:34:46,080 --> 00:34:48,659
nostro laboratorio in cui i neuroni stanno

843
00:34:48,659 --> 00:34:51,359
imparando il gioco del pong

844
00:34:51,359 --> 00:34:52,980
um quindi c'era quindi se il documento si

845
00:34:52,980 --> 00:34:55,260
chiama dist brain uh e il dispositivo si

846
00:34:55,260 --> 00:34:57,000
chiama strain e ciò che hanno

847
00:34:57,000 --> 00:34:58,740
ottenuto è che riescono  per

848
00:34:58,740 --> 00:35:00,300
coltivare i neuroni

849
00:35:00,300 --> 00:35:03,420
su un chip di silicio e gli hanno

850
00:35:03,420 --> 00:35:04,020


851
00:35:04,020 --> 00:35:08,520
dato un buon segnale di feedback quando ha

852
00:35:08,520 --> 00:35:11,400
affrontato con successo la palla o ha

853
00:35:11,400 --> 00:35:13,880
giocato bene il gioco e gli hanno dato uno shock

854
00:35:13,880 --> 00:35:15,720
uh quando ha

855
00:35:15,720 --> 00:35:18,119
fatto degli errori e quello che abbiamo visto è

856
00:35:18,119 --> 00:35:19,560
che

857
00:35:19,560 --> 00:35:22,260
nel giornale quello che abbiamo  vedere è che

858
00:35:22,260 --> 00:35:24,140
impara a giocare nel tempo giusto

859
00:35:24,140 --> 00:35:27,359
e in uno scenario del genere immagina che

860
00:35:27,359 --> 00:35:29,880
se incontro una cosa positiva

861
00:35:29,880 --> 00:35:33,359
nel mondo, allora potrei associare

862
00:35:33,359 --> 00:35:35,520
um ciò che è buono con gli stati che ho

863
00:35:35,520 --> 00:35:37,380
osservato in passato e così via giusto  quindi

864
00:35:37,380 --> 00:35:38,880
ho imparato

865
00:35:38,880 --> 00:35:39,660
um

866
00:35:39,660 --> 00:35:42,119
passo dopo passo cosa è buono o cattivo e

867
00:35:42,119 --> 00:35:44,700
questa è un'ipotesi ragionevole da fare

868
00:35:44,700 --> 00:35:46,619
quindi se

869
00:35:46,619 --> 00:35:47,220
um

870
00:35:47,220 --> 00:35:51,300
se voglio dire "mettiti in forma" allora potrei

871
00:35:51,300 --> 00:35:53,280
associare andare in palestra

872
00:35:53,280 --> 00:35:54,660
um

873
00:35:54,660 --> 00:35:57,000
come una buona cosa allora potrei anche

874
00:35:57,000 --> 00:35:59,099
associare andare in palestra a piedi  come una buona

875
00:35:59,099 --> 00:36:01,260
cosa allora potrei associare uh dire

876
00:36:01,260 --> 00:36:03,900
indossare le mie scarpe come una buona cosa quindi

877
00:36:03,900 --> 00:36:04,920
um

878
00:36:04,920 --> 00:36:06,960
imparare la preferenza precedente in quel modo ha

879
00:36:06,960 --> 00:36:10,079
senso direi ma sì questa è una

880
00:36:10,079 --> 00:36:11,640


881
00:36:11,640 --> 00:36:12,480
um

882
00:36:12,480 --> 00:36:14,820
soluzione computazionale al problema della maledizione della

883
00:36:14,820 --> 00:36:17,040
dimensionalità ma testarla sul

884
00:36:17,040 --> 00:36:19,619
reale  il mondo è decisamente uh quello che

885
00:36:19,619 --> 00:36:21,599
dovremmo fare e

886
00:36:21,599 --> 00:36:24,119
um sì, anch'io non vedo l'ora di farlo

887
00:36:24,119 --> 00:36:25,800


888
00:36:25,800 --> 00:36:27,660
ok fammi provare a gestire una

889
00:36:27,660 --> 00:36:29,760
situazione del mondo reale da te e vedere se questo

890
00:36:29,760 --> 00:36:32,040
se questo si connette

891
00:36:32,040 --> 00:36:35,099
um quindi vogliamo che vogliamo consegnare noi '  sei

892
00:36:35,099 --> 00:36:38,280
ricompensato consegnando un saggio che

893
00:36:38,280 --> 00:36:39,900
ottiene un voto alto

894
00:36:39,900 --> 00:36:42,599
e quindi ci sono molti passaggi tra

895
00:36:42,599 --> 00:36:45,540
iniziare l'idea del saggio e

896
00:36:45,540 --> 00:36:48,839
vedere quel risultato scarso preferito

897
00:36:48,839 --> 00:36:51,180
che è il voto

898
00:36:51,180 --> 00:36:53,520
um e noi facciamo ogni genere di cose e

899
00:36:53,520 --> 00:36:55,260
poi impariamo bene bene

900
00:36:55,260 --> 00:36:57,079
um  questo in cui ho preso un buon voto

901
00:36:57,079 --> 00:36:59,940
era ben formattato

902
00:36:59,940 --> 00:37:02,880
e poi quel tipo ora

903
00:37:02,880 --> 00:37:05,460
espandi l'ombrello delle tue preferenze

904
00:37:05,460 --> 00:37:07,800
e poi cosa mi ha portato a farlo

905
00:37:07,800 --> 00:37:10,140
ben formattato bene l'ho fatto in tempo

906
00:37:10,140 --> 00:37:12,900
e poi hai tipo di lavoro  fino alla

907
00:37:12,900 --> 00:37:16,579
fase di ideazione in modo che in futuro

908
00:37:16,579 --> 00:37:20,640
tu possa fare un'inferenza di un passo sì

909
00:37:20,640 --> 00:37:23,099
esattamente e prenderla passo dopo passo come

910
00:37:23,099 --> 00:37:24,180
un'abilità

911
00:37:24,180 --> 00:37:26,400
invece di dover fare

912
00:37:26,400 --> 00:37:28,740


913
00:37:28,740 --> 00:37:31,740
un'inferenza di 15 passi temporali su tutte le possibili

914
00:37:31,740 --> 00:37:35,180
strutture ad albero così hai  in un certo senso hai usato i tuoi

915
00:37:35,180 --> 00:37:39,240
apprendimenti incarnati per semplificare

916
00:37:39,240 --> 00:37:43,680
esattamente la struttura del problema sì

917
00:37:43,680 --> 00:37:45,540
e possiamo guardare

918
00:37:45,540 --> 00:37:47,220


919
00:37:47,220 --> 00:37:51,078
di nuovo alle complessità computazionali um di tutti loro

920
00:37:51,359 --> 00:37:54,300
quindi qui CIF sta per l'

921
00:37:54,300 --> 00:37:56,760
inferenza attiva classica e per fare l'intero

922
00:37:56,760 --> 00:37:58,560
orizzonte della pianificazione

923
00:37:58,560 --> 00:38:00,660
um è intorno  10 alla potenza 18. quindi

924
00:38:00,660 --> 00:38:03,180
questo è per questo particolare esempio di griglia

925
00:38:03,180 --> 00:38:07,140
con 100 stati e quattro

926
00:38:07,140 --> 00:38:09,960
azioni disponibili quindi questo è per un caso speciale

927
00:38:09,960 --> 00:38:12,119
e volevo solo mettere i numeri per mettere

928
00:38:12,119 --> 00:38:14,400
le cose in prospettiva quindi per questo

929
00:38:14,400 --> 00:38:16,500
particolare esempio se stai cercando di

930
00:38:16,500 --> 00:38:18,960
fallo con la cosa dello spazio delle politiche

931
00:38:18,960 --> 00:38:20,640
um dovrai fare

932
00:38:20,640 --> 00:38:22,440
um 10 alla potenza 18 calcoli per

933
00:38:22,440 --> 00:38:25,380
un passaggio della pianificazione o in

934
00:38:25,380 --> 00:38:28,380
un'istanza di inferenza sofisticata

935
00:38:28,380 --> 00:38:30,900
è anche peggio perché uh ecco

936
00:38:30,900 --> 00:38:34,560
lo spazio degli stati Conta anche uh e questo

937
00:38:34,560 --> 00:38:37,140
ha vinto  non funziona quindi questa terza riga avrebbe

938
00:38:37,140 --> 00:38:39,540
dovuto mostrare che anche per un

939
00:38:39,540 --> 00:38:40,500
tempo

940
00:38:40,500 --> 00:38:42,599
um o aumentare abbastanza due è davvero difficile

941
00:38:42,599 --> 00:38:44,280
fare un'inferenza sofisticata se

942
00:38:44,280 --> 00:38:47,400
devi fare la pianificazione completa ma con la

943
00:38:47,400 --> 00:38:48,960
programmazione dinamica quando stai pianificando

944
00:38:48,960 --> 00:38:50,579
all'indietro

945
00:38:50,579 --> 00:38:52,500
um tu  puoi tentare di fare l'intero

946
00:38:52,500 --> 00:38:54,420
orizzonte della pianificazione

947
00:38:54,420 --> 00:38:56,520
um e questo è solo un migliaio di

948
00:38:56,520 --> 00:38:58,800
calcoli ma con la

949
00:38:58,800 --> 00:39:01,380
preferenza di apprendimento è anche basso uh quando lo fai

950
00:39:01,380 --> 00:39:04,520
solo una volta Step Ahead

951
00:39:04,520 --> 00:39:06,440
wow questo è abbastanza

952
00:39:06,440 --> 00:39:06,839
[Musica]

953
00:39:06,839 --> 00:39:08,220
um

954
00:39:08,220 --> 00:39:12,000
abbastanza Stark e nel tempo di ramificazione

955
00:39:12,000 --> 00:39:15,480
inferenza attiva  lavorare in un precedente

956
00:39:15,480 --> 00:39:17,640
flusso di modelli abbiamo anche visto alcune

957
00:39:17,640 --> 00:39:19,859
stime di complessità computazionale ma

958
00:39:19,859 --> 00:39:22,260
penso che queste siano davvero chiare

959
00:39:22,260 --> 00:39:25,020
um la prima cosa a cui mi ha fatto pensare è che

960
00:39:25,020 --> 00:39:28,820
nessuno ha detto che la sofisticazione fosse economica

961
00:39:28,820 --> 00:39:32,940
Voglio dire è astronomico quanto

962
00:39:32,940 --> 00:39:35,099
è costoso per

963
00:39:35,099 --> 00:39:37,380
um forse anche solo a  due o tre o

964
00:39:37,380 --> 00:39:38,880
quattro o cinque

965
00:39:38,880 --> 00:39:41,940
potenzialmente stanno iniziando ad alzarsi quindi

966
00:39:41,940 --> 00:39:44,040
sta aumentando radicalmente la complessità della

967
00:39:44,040 --> 00:39:45,720
pianificazione

968
00:39:45,720 --> 00:39:50,040
quindi è molto

969
00:39:50,040 --> 00:39:50,780


970
00:39:50,780 --> 00:39:52,460
interessante dal punto di

971
00:39:52,460 --> 00:39:56,280
vista pedagogico mentre pensiamo a come

972
00:39:56,280 --> 00:39:57,660
immaginiamo

973
00:39:57,660 --> 00:39:59,940


974
00:39:59,940 --> 00:40:01,560
architetture di intelligenza di inferenza attiva

975
00:40:01,560 --> 00:40:04,500
ma

976
00:40:04,500 --> 00:40:07,079
questo rende abbastanza chiaro che non lo è

977
00:40:07,079 --> 00:40:09,060
qualcosa che puoi semplicemente elencare

978
00:40:09,060 --> 00:40:10,859


979
00:40:10,859 --> 00:40:13,380
e quindi penso che sia molto

980
00:40:13,380 --> 00:40:15,240
um molto creativo e importante quello che

981
00:40:15,240 --> 00:40:19,520
hai fatto collegando questo a

982
00:40:19,520 --> 00:40:22,140
metodi di principio di

983
00:40:22,140 --> 00:40:25,440
riduzione della complessità computazionale piuttosto che

984
00:40:25,440 --> 00:40:29,220
metodi potenzialmente efficaci ma ad hoc

985
00:40:29,220 --> 00:40:31,320
di riduzione della complessità come le

986
00:40:31,320 --> 00:40:33,359
reti neurali che potrebbero funzionare  quando funzionano

987
00:40:33,359 --> 00:40:35,280
ma poi una volta che quelli iniziano a gonfiarsi

988
00:40:35,280 --> 00:40:38,940
ora non hai principi e nessuna

989
00:40:38,940 --> 00:40:40,680
efficacia

990
00:40:40,680 --> 00:40:43,200
esattamente sì e un'inferenza sofisticata devo

991
00:40:43,200 --> 00:40:45,240
notare che ha i suoi vantaggi

992
00:40:45,240 --> 00:40:47,579
rispetto alla programmazione dinamica uh

993
00:40:47,579 --> 00:40:49,500
nel senso che quando pianifichi

994
00:40:49,500 --> 00:40:51,839
in avanti sei  prendendo in

995
00:40:51,839 --> 00:40:53,520
considerazione tutte le possibilità,

996
00:40:53,520 --> 00:40:55,859
ma quando stai pianificando all'indietro,

997
00:40:55,859 --> 00:40:58,380
ad esempio, è come un'esplorazione basata su segnali,

998
00:40:58,380 --> 00:41:00,300


999
00:41:00,300 --> 00:41:02,280
come se dovessi andare da qualche parte, prendere

1000
00:41:02,280 --> 00:41:03,839
una coda e poi navigare nello

1001
00:41:03,839 --> 00:41:05,640
stato del pool, quindi pianificare all'indietro potrebbe non

1002
00:41:05,640 --> 00:41:06,960
funzionare, quindi questo è ciò che  questo è stato un

1003
00:41:06,960 --> 00:41:09,900
feedback che ho ricevuto e ho discusso uh del

1004
00:41:09,900 --> 00:41:10,980
lavoro con

1005
00:41:10,980 --> 00:41:13,920
alcune persone quindi

1006
00:41:13,920 --> 00:41:16,260
è una cosa da notare sulla

1007
00:41:16,260 --> 00:41:18,359
programmazione dinamica ma l'altro posto in cui

1008
00:41:18,359 --> 00:41:19,920
impari prima degli amici credo che

1009
00:41:19,920 --> 00:41:22,320
non sia un problema ma sì la

1010
00:41:22,320 --> 00:41:23,700
programmazione dinamica è computazionalmente economica ma

1011
00:41:23,700 --> 00:41:26,460
ha anche i suoi limiti

1012
00:41:26,460 --> 00:41:28,099
Devo notare qui

1013
00:41:28,099 --> 00:41:31,200
solo per ribadire che nella

1014
00:41:31,200 --> 00:41:33,839
programmazione dinamica con un'ottimalità di Bellman

1015
00:41:33,839 --> 00:41:36,420
stiamo risolvendo all'indietro e quindi è un po '

1016
00:41:36,420 --> 00:41:38,400
come lo scacco matto è ciò che vogliamo

1017
00:41:38,400 --> 00:41:40,440
e quindi ora stiamo lavorando all'indietro fino

1018
00:41:40,440 --> 00:41:43,440
al presente  ma finiamo per non esplorare

1019
00:41:43,440 --> 00:41:46,440


1020
00:41:46,440 --> 00:41:49,200
punti finali controfattuali non torniamo al

1021
00:41:49,200 --> 00:41:51,540
presente per punti finali che non ci

1022
00:41:51,540 --> 00:41:52,980
interessano

1023
00:41:52,980 --> 00:41:55,619
esattamente, ecco perché è così spietato

1024
00:41:55,619 --> 00:41:58,320
ma d'altra parte è una ricerca molto più

1025
00:41:58,320 --> 00:42:00,420
limitata

1026
00:42:00,420 --> 00:42:02,280
um

1027
00:42:02,280 --> 00:42:06,960
sì così sì  quindi quello a cui sto pensando in

1028
00:42:06,960 --> 00:42:08,460
questi giorni è che dovremmo anche

1029
00:42:08,460 --> 00:42:11,700
considerare uh combinazioni di questi due uh

1030
00:42:11,700 --> 00:42:14,160
dove posso permettermi di ignorare

1031
00:42:14,160 --> 00:42:17,400
tali cose controfattuali

1032
00:42:17,400 --> 00:42:19,680
um lì posso fare programmazione dinamica uh

1033
00:42:19,680 --> 00:42:23,040
e forse posso fare come due passaggi uh di

1034
00:42:23,040 --> 00:42:25,380
pianificare quindi se si tratta di un'esplorazione basata sulla coda

1035
00:42:25,380 --> 00:42:28,980
uh diciamo che raggiungere la coda uh è

1036
00:42:28,980 --> 00:42:32,220
un compito e dalla coda alla ricompensa è

1037
00:42:32,220 --> 00:42:34,619
l'altro compito quindi posso separare questi

1038
00:42:34,619 --> 00:42:37,460
due e usare la programmazione dinamica per loro

1039
00:42:37,460 --> 00:42:40,440
e questo è computazionalmente più economico ma

1040
00:42:40,440 --> 00:42:43,079
preserva anche questa idea di

1041
00:42:43,079 --> 00:42:45,480
um doverlo fare sì ma queste sono

1042
00:42:45,480 --> 00:42:48,119
tutte cose future a cui sto pensando

1043
00:42:48,119 --> 00:42:50,700
bene o fare un'altra domanda dalla

1044
00:42:50,700 --> 00:42:54,359
chat che Alex ha scritto

1045
00:42:54,359 --> 00:42:57,599
hai idee o sviluppi su

1046
00:42:57,599 --> 00:43:00,180
modelli nidificati in cui diverse scale

1047
00:43:00,180 --> 00:43:02,330
potrebbero avere diverse

1048
00:43:02,330 --> 00:43:02,640
[musica]

1049
00:43:02,640 --> 00:43:03,780
um

1050
00:43:03,780 --> 00:43:06,540
una volta un passo avanti e  velocità di

1051
00:43:06,540 --> 00:43:07,800
esecuzione

1052
00:43:07,800 --> 00:43:09,960
quindi come funziona questo modello nei

1053
00:43:09,960 --> 00:43:11,579
modelli nidificati

1054
00:43:11,579 --> 00:43:13,859
e come pensiamo a questo

1055
00:43:13,859 --> 00:43:16,380
avanti e indietro nel tempo nella

1056
00:43:16,380 --> 00:43:19,500
velocità di esecuzione e nei modelli nidificati

1057
00:43:19,500 --> 00:43:21,780
ok quindi potrei aver bisogno di un po 'più di

1058
00:43:21,780 --> 00:43:23,760
contesto qui come

1059
00:43:23,760 --> 00:43:26,220
um quando dici nidificato  modelli um

1060
00:43:26,220 --> 00:43:28,440
intendi modelli gerarchici sì

1061
00:43:28,440 --> 00:43:30,780
sì quindi forse

1062
00:43:30,780 --> 00:43:34,619
um qualcosa del tipo c'è un'osservazione che

1063
00:43:34,619 --> 00:43:38,760
vado a un ritmo veloce e faccio qualche

1064
00:43:38,760 --> 00:43:41,160
inferenza su questo ma poi uso questa

1065
00:43:41,160 --> 00:43:45,180
inferenza uh per fare

1066
00:43:45,180 --> 00:43:48,000
o forse uh e che fondamentalmente questa

1067
00:43:48,000 --> 00:43:49,500
inferenza  diventa l'osservazione per

1068
00:43:49,500 --> 00:43:52,800
lo stato successivo ed è quello che

1069
00:43:52,800 --> 00:43:55,980
significano i modelli nidificati, sì, quindi potrei doverci

1070
00:43:55,980 --> 00:43:58,140
davvero pensare in termini di

1071
00:43:58,140 --> 00:44:00,300
attività e poi pensarci, ma

1072
00:44:00,300 --> 00:44:02,339
onestamente non ho

1073
00:44:02,339 --> 00:44:04,800
pensato a come potrebbe funzionare in quel

1074
00:44:04,800 --> 00:44:08,760
contesto ma  diciamo per un compito

1075
00:44:08,760 --> 00:44:10,319
um

1076
00:44:10,319 --> 00:44:13,140
come uh quindi in termini di navigazione se ci

1077
00:44:13,140 --> 00:44:15,119
pensi puoi pensare a

1078
00:44:15,119 --> 00:44:15,900
um

1079
00:44:15,900 --> 00:44:19,800
diciamo ambiente delle stanze quindi è lì che uh

1080
00:44:19,800 --> 00:44:21,480
questo è uno degli esempi a cui posso pensare

1081
00:44:21,480 --> 00:44:24,000
dove possiamo applicare questo quindi immagina

1082
00:44:24,000 --> 00:44:27,720
forse di avere una collezione  di stanze e

1083
00:44:27,720 --> 00:44:30,300
come agente devi prima capire in

1084
00:44:30,300 --> 00:44:32,460
quale stanza andare e poi devi

1085
00:44:32,460 --> 00:44:35,760
navigare all'interno di quella casa e fondamentalmente

1086
00:44:35,760 --> 00:44:39,060
puoi fare uh inferenza in due fasi o

1087
00:44:39,060 --> 00:44:41,940
prendere decisioni in due fasi uh e devi

1088
00:44:41,940 --> 00:44:43,140
separarti  le tue

1089
00:44:43,140 --> 00:44:45,240
decisioni in quelle fasi

1090
00:44:45,240 --> 00:44:47,460
all'interno della stanza puoi dire

1091
00:44:47,460 --> 00:44:49,740
programmazione dinamica per navigare nel tuo percorso uh ottimale

1092
00:44:49,740 --> 00:44:52,980
ma dovrai sempre

1093
00:44:52,980 --> 00:44:54,960
avere due fasi del

1094
00:44:54,960 --> 00:44:57,300
processo decisionale e um

1095
00:44:57,300 --> 00:45:00,420
forse metodi diversi funzionano meglio in

1096
00:45:00,420 --> 00:45:04,260
fasi diverse ma questo sarebbe  uh

1097
00:45:04,260 --> 00:45:06,180
meglio in sai voglio dire che questa

1098
00:45:06,180 --> 00:45:08,460
discussione sarebbe meglio per

1099
00:45:08,460 --> 00:45:09,420
um

1100
00:45:09,420 --> 00:45:12,060
meglio in un

1101
00:45:12,060 --> 00:45:14,400
compito ben ponderato direi che non

1102
00:45:14,400 --> 00:45:18,240
ho una risposta che potrebbe essere adatta a

1103
00:45:18,240 --> 00:45:19,740
tutto ma sì sì

1104
00:45:19,740 --> 00:45:21,119


1105
00:45:21,119 --> 00:45:24,359
abbiamo visto quasi esattamente quel tipo

1106
00:45:24,359 --> 00:45:27,300
di  localizzazione gerarchica simultanea

1107
00:45:27,300 --> 00:45:30,180
e mappatura Slam in un

1108
00:45:30,180 --> 00:45:32,040
caso di robotica ci sono stati

1109
00:45:32,040 --> 00:45:33,900
modelli di inferenza attivi su quello

1110
00:45:33,900 --> 00:45:37,140
um sì sarebbe possibile fare

1111
00:45:37,140 --> 00:45:39,500


1112
00:45:40,079 --> 00:45:42,660
uno di questi metodi

1113
00:45:42,660 --> 00:45:45,420
a un livello del modello annidato e

1114
00:45:45,420 --> 00:45:48,359
quindi avere un altro metodo computazionale

1115
00:45:48,359 --> 00:45:50,280
applicato a un altro

1116
00:45:50,280 --> 00:45:51,960
um  o è come se volessi i

1117
00:45:51,960 --> 00:45:54,480
vantaggi di uno in un posto come

1118
00:45:54,480 --> 00:45:56,579
puoi mescolare e abbinare questi diversi

1119
00:45:56,579 --> 00:46:00,180
metodi anche all'interno di una simulazione

1120
00:46:00,180 --> 00:46:03,540
sì I I Penso sicuramente che sia

1121
00:46:03,540 --> 00:46:04,859
possibile

1122
00:46:04,859 --> 00:46:09,140
um ma sì, forse dovremo provare

1123
00:46:09,180 --> 00:46:12,119
quindi tutti i miei metodi sono um uno  fase quindi

1124
00:46:12,119 --> 00:46:14,819
non è un modello gerarchico

1125
00:46:14,819 --> 00:46:17,220
e ma io credo fermamente che

1126
00:46:17,220 --> 00:46:19,260
funzionerebbe anche in un modello immobiliare in cui

1127
00:46:19,260 --> 00:46:20,520
puoi avere

1128
00:46:20,520 --> 00:46:22,200
um due metodi di processo decisionale che

1129
00:46:22,200 --> 00:46:24,660
lavorano insieme diciamo per un

1130
00:46:24,660 --> 00:46:26,940
esempio di stanza che ho appena menzionato

1131
00:46:26,940 --> 00:46:29,280
oh potresti andare alla diapositiva su  Z

1132
00:46:29,280 --> 00:46:31,819
learning

1133
00:46:35,640 --> 00:46:38,760
cool yeah quindi ho notato um qui e

1134
00:46:38,760 --> 00:46:41,220
nell'ottimo documento che hai avuto diverse

1135
00:46:41,220 --> 00:46:45,240
citazioni in totale sì e così e questa

1136
00:46:45,240 --> 00:46:48,060
introduzione dell'apprendimento Z è una

1137
00:46:48,060 --> 00:46:49,859
novità rispetto al

1138
00:46:49,859 --> 00:46:52,260
campo di inferenza attiva quindi potresti spiegare un

1139
00:46:52,260 --> 00:46:53,760
po 'di più

1140
00:46:53,760 --> 00:46:55,920
cosa  è la Z

1141
00:46:55,920 --> 00:47:00,660
e cos'è che consente un così

1142
00:47:00,660 --> 00:47:02,280
rapido

1143
00:47:02,280 --> 00:47:03,240
um

1144
00:47:03,240 --> 00:47:06,119
Miglioramento della Z rispetto alla

1145
00:47:06,119 --> 00:47:06,900
Q

1146
00:47:06,900 --> 00:47:10,619
sì ok quindi uh per dare un po' di contesto

1147
00:47:10,619 --> 00:47:13,079
um contesto su questo documento

1148
00:47:13,079 --> 00:47:13,920
um

1149
00:47:13,920 --> 00:47:16,260
parla di un

1150
00:47:16,260 --> 00:47:19,800
metodo lineare di processo decisionale uh in un

1151
00:47:19,800 --> 00:47:21,720
particolare  classe di mdp, quindi dato che

1152
00:47:21,720 --> 00:47:23,940
stai avendo un processo decisionale di Markov

1153
00:47:23,940 --> 00:47:27,240
in cui le tue azioni possono essere basate su

1154
00:47:27,240 --> 00:47:29,220
Stati e non accenti, quindi quando pensi

1155
00:47:29,220 --> 00:47:31,560
alle azioni in una parola, ad esempio in

1156
00:47:31,560 --> 00:47:32,760
un'attività griglia,

1157
00:47:32,760 --> 00:47:35,160
pensi a sinistra a destra e

1158
00:47:35,160 --> 00:47:37,200
um Nord Sud a destra così  se prendo un

1159
00:47:37,200 --> 00:47:40,200
nord, ciò ha una conseguenza di uh

1160
00:47:40,200 --> 00:47:42,720
conseguenza sullo spazio degli stati, ma in questo

1161
00:47:42,720 --> 00:47:43,680
documento

1162
00:47:43,680 --> 00:47:46,380
ehm stanno introducendo una classe di mdp

1163
00:47:46,380 --> 00:47:48,839
in cui la decisione è essa stessa in termini di

1164
00:47:48,839 --> 00:47:49,920
stati,

1165
00:47:49,920 --> 00:47:54,180
quindi se dico Stato S1 la mia decisione

1166
00:47:54,180 --> 00:47:56,280


1167
00:47:56,280 --> 00:47:58,740
dipenderà uh  sull'altro stato quindi la mia

1168
00:47:58,740 --> 00:48:00,000
decisione sarà basata sugli altri

1169
00:48:00,000 --> 00:48:02,160
stati in cui voglio essere la prossima volta quindi

1170
00:48:02,160 --> 00:48:04,020
uh

1171
00:48:04,020 --> 00:48:05,880
è davvero una definizione del processo

1172
00:48:05,880 --> 00:48:08,640
decisionale uh in termini di spazio dello stato

1173
00:48:08,640 --> 00:48:10,800
piuttosto che le decisioni sono

1174
00:48:10,800 --> 00:48:13,619
qualcos'altro come sinistra destra e giù su

1175
00:48:13,619 --> 00:48:15,300
quindi, dato che

1176
00:48:15,300 --> 00:48:17,819
esiste un tale mdp in cui posso prendere

1177
00:48:17,819 --> 00:48:21,319
decisioni in termini di stati,

1178
00:48:21,319 --> 00:48:23,520
hanno dimostrato che dal punto di vista computazionale

1179
00:48:23,520 --> 00:48:27,000
puoi prendere uh decisioni in

1180
00:48:27,000 --> 00:48:30,900
complessità lineare per quanto grande sia il problema per quello

1181
00:48:30,900 --> 00:48:33,480
per consentire il

1182
00:48:33,480 --> 00:48:35,339
processo decisionale in termini di Stati che dovresti

1183
00:48:35,339 --> 00:48:38,579
avere  un senso di ciò che è buono e cattivo per

1184
00:48:38,579 --> 00:48:39,540
gli stati

1185
00:48:39,540 --> 00:48:43,619
quindi in questo esempio gridward uh hai

1186
00:48:43,619 --> 00:48:46,440
una funzione di desiderabilità che è C quindi C

1187
00:48:46,440 --> 00:48:48,240
è la funzione di desiderabilità

1188
00:48:48,240 --> 00:48:50,700
che parla di quanto sia desiderabile uno

1189
00:48:50,700 --> 00:48:54,180
stato e se ho una funzione c allora

1190
00:48:54,180 --> 00:48:56,579
quello che hanno mostrato  è che um

1191
00:48:56,579 --> 00:48:57,359


1192
00:48:57,359 --> 00:48:59,280
posso prendere decisioni con

1193
00:48:59,280 --> 00:49:01,079
complessità computazionale lineare per questa

1194
00:49:01,079 --> 00:49:03,540
particolare classe di mdp quindi se il mio mdp

1195
00:49:03,540 --> 00:49:05,640
mi permette di prendere decisioni in termini di

1196
00:49:05,640 --> 00:49:08,940
Stati è linearmente uh è solo

1197
00:49:08,940 --> 00:49:11,700
complessità lineare per quella cosa

1198
00:49:11,700 --> 00:49:15,240
quindi questo grafico sta sostanzialmente confrontando come

1199
00:49:15,240 --> 00:49:19,260
puoi  impara la desiderabilità uh meglio

1200
00:49:19,260 --> 00:49:22,200
o più velocemente giusto quindi Q learning se hai

1201
00:49:22,200 --> 00:49:23,880
familiarità con Q learning è fondamentalmente

1202
00:49:23,880 --> 00:49:28,319
un metodo basato su tabelle uh dove hai

1203
00:49:28,319 --> 00:49:30,780
um desiderabilità delle azioni dato uno stato

1204
00:49:30,780 --> 00:49:33,000
quindi dato uno stato sai cosa fare

1205
00:49:33,000 --> 00:49:35,760
che è fondamentalmente la coda Matrix ma in

1206
00:49:35,760 --> 00:49:37,020
termini di C

1207
00:49:37,020 --> 00:49:40,380
uh o del metodo di apprendimento C si tratta solo

1208
00:49:40,380 --> 00:49:43,020
di stati uh stai solo imparando quanto sia

1209
00:49:43,020 --> 00:49:44,819
desiderabile uno stato non c'è il concetto

1210
00:49:44,819 --> 00:49:46,980
di azioni

1211
00:49:46,980 --> 00:49:49,560
e questo è esattamente ciò che la nostra

1212
00:49:49,560 --> 00:49:51,839
preferenza precedente uh è nell'inferenza attiva

1213
00:49:51,839 --> 00:49:54,000
dove è una distribuzione che

1214
00:49:54,000 --> 00:49:55,560
quantifica  quanto gli stati desiderabili o

1215
00:49:55,560 --> 00:49:57,960
non desiderabili siano

1216
00:49:57,960 --> 00:50:00,119
giusti, quindi

1217
00:50:00,119 --> 00:50:02,579
dato che hanno dimostrato che

1218
00:50:02,579 --> 00:50:05,099
puoi imparare la matrice C più velocemente ed

1219
00:50:05,099 --> 00:50:07,980
è ottimale ed è molto più veloce

1220
00:50:07,980 --> 00:50:10,079
persino dell'apprendimento di Q, allora ho pensato che va bene perché

1221
00:50:10,079 --> 00:50:13,319
non provare a imparare C allo stesso modo di  C viene

1222
00:50:13,319 --> 00:50:16,400
appreso in questo documento e

1223
00:50:16,400 --> 00:50:19,319
usando questo diciamo quindi c'è una

1224
00:50:19,319 --> 00:50:21,839
regola di apprendimento simile per l'apprendimento di C che si

1225
00:50:21,839 --> 00:50:24,119
chiama set learning in quel documento e

1226
00:50:24,119 --> 00:50:25,800
quando ho tentato di imparare guarda quello che ho

1227
00:50:25,800 --> 00:50:28,200
visto è che impara molto velocemente

1228
00:50:28,200 --> 00:50:30,540
un'utile preferenza Pride  che mi consente di

1229
00:50:30,540 --> 00:50:32,520
prendere decisioni o lasciare che l'

1230
00:50:32,520 --> 00:50:34,619
agente di influenza attivo prenda decisioni

1231
00:50:34,619 --> 00:50:38,460
um solo dicendo una fase temporale della pianificazione

1232
00:50:38,460 --> 00:50:40,859
e sì, quindi in pratica ha preso la

1233
00:50:40,859 --> 00:50:42,240
storia quindi

1234
00:50:42,240 --> 00:50:43,440
um

1235
00:50:43,440 --> 00:50:47,460
questa idea di C che è facilmente apprendibile è

1236
00:50:47,460 --> 00:50:50,240
in quel documento

1237
00:50:52,020 --> 00:50:54,780
ok fammi provare a um riformulare  che poiché

1238
00:50:54,780 --> 00:50:56,420
penso che sia un aumento molto interessante

1239
00:50:56,420 --> 00:50:59,099
dell'inferenza attiva, quindi

1240
00:50:59,099 --> 00:51:02,280
impareremo C

1241
00:51:02,280 --> 00:51:04,200
per tutti i

1242
00:51:04,200 --> 00:51:06,480
motivi che abbiamo discusso in precedenza,

1243
00:51:06,480 --> 00:51:09,619
impareremo C in

1244
00:51:09,619 --> 00:51:13,740
modo analogo a come todorov ha presentato l'

1245
00:51:13,740 --> 00:51:18,540
apprendimento Z e nell'apprendimento Z

1246
00:51:18,540 --> 00:51:21,059
invece dell'apprendimento

1247
00:51:21,059 --> 00:51:23,460
um per esempio aggiornate le

1248
00:51:23,460 --> 00:51:26,160
probabilità a posteriori sulle azioni

1249
00:51:26,160 --> 00:51:28,380
e quindi utilizzando le azioni per navigare

1250
00:51:28,380 --> 00:51:31,339
tra gli stati che emettono osservazioni

1251
00:51:31,339 --> 00:51:35,760
sì, inseriremo l'

1252
00:51:35,760 --> 00:51:37,319
azione

1253
00:51:37,319 --> 00:51:39,300
negli stati

1254
00:51:39,300 --> 00:51:41,420
in modo che in realtà stiamo imparando

1255
00:51:41,420 --> 00:51:44,280


1256
00:51:44,280 --> 00:51:48,200
direttamente le transizioni tra gli stati sì

1257
00:51:51,540 --> 00:51:53,880
e e per collegare questo  al

1258
00:51:53,880 --> 00:51:56,040
principio di energia libera e come sta

1259
00:51:56,040 --> 00:51:57,660
giocando con l'inferenza attiva

1260
00:51:57,660 --> 00:51:59,220
qui

1261
00:51:59,220 --> 00:52:00,559
um

1262
00:52:00,559 --> 00:52:03,780
C non è solo la nostra funzione di desiderabilità

1263
00:52:03,780 --> 00:52:05,280
questo è un modo di pensarci

1264
00:52:05,280 --> 00:52:07,559
ecco perché la chiamiamo preferenza ma

1265
00:52:07,559 --> 00:52:11,640
anche C è la nostra aspettativa e quindi questo è

1266
00:52:11,640 --> 00:52:14,400
ciò che consente  da un lato usare il

1267
00:52:14,400 --> 00:52:16,800
linguaggio familiare per premiare e

1268
00:52:16,800 --> 00:52:18,960
preferire l'apprendimento come se l'agente

1269
00:52:18,960 --> 00:52:21,900
finisse dove gli piace essere ma anche

1270
00:52:21,900 --> 00:52:25,500
la

1271
00:52:25,500 --> 00:52:27,780
definizione um basata sull'aspettativa di c queste sono la stessa

1272
00:52:27,780 --> 00:52:30,180
cosa ci permette di parlarne come un

1273
00:52:30,180 --> 00:52:32,760
percorso di minimo  azione o come il

1274
00:52:32,760 --> 00:52:36,660
risultato più probabile o il risultato meno sorprendente

1275
00:52:36,660 --> 00:52:39,900
e poiché l'abbiamo definito

1276
00:52:39,900 --> 00:52:42,960
ciò che vogliamo come il risultato meno sorprendente,

1277
00:52:42,960 --> 00:52:47,040
allora possiamo usare l'energia libera variazionale

1278
00:52:47,040 --> 00:52:50,640
per far rimbalzare la sorpresa mentre

1279
00:52:50,640 --> 00:52:54,000
non puoi usare semplicemente un metodo variazionale per

1280
00:52:54,000 --> 00:52:56,579
limitare o  anche la ricompensa necessariamente approssimativa

1281
00:52:56,579 --> 00:52:58,859
stessa,

1282
00:52:58,859 --> 00:53:01,079
ma se dici che

1283
00:53:01,079 --> 00:53:04,980
preferisco ciò che mi aspetto

1284
00:53:04,980 --> 00:53:07,559
e ciò che mi aspetto riduce la mia sorpresa

1285
00:53:07,559 --> 00:53:09,859
e ho intenzione di bilanciare la sorpresa,

1286
00:53:09,859 --> 00:53:13,520
allora ottieni sia quel tipo di

1287
00:53:13,520 --> 00:53:17,240
ricompensa comportamentale che cerca

1288
00:53:17,240 --> 00:53:21,420
espressa in una sorpresa che limita la sorpresa

1289
00:53:21,420 --> 00:53:25,579
minimizzando il quadro fisico

1290
00:53:27,059 --> 00:53:28,740
sì sì  è un bel modo di

1291
00:53:28,740 --> 00:53:31,619
dirlo sì grazie

1292
00:53:31,619 --> 00:53:35,160
quali sono i tuoi prossimi uh

1293
00:53:35,160 --> 00:53:36,720


1294
00:53:36,720 --> 00:53:39,420
passi o indicazioni entusiasmanti o in che modo

1295
00:53:39,420 --> 00:53:41,640
vuoi portare questo lavoro sì fantastico

1296
00:53:41,640 --> 00:53:43,140
sì quindi

1297
00:53:43,140 --> 00:53:44,940
um se stai parlando solo di questo

1298
00:53:44,940 --> 00:53:46,140
lavoro

1299
00:53:46,140 --> 00:53:50,640
um quello che voglio  la prossima cosa da fare è uh

1300
00:53:50,640 --> 00:53:53,099
pensare alle attività di esplorazione basate su cue

1301
00:53:53,099 --> 00:53:55,200
Prima di tutto affronto i limiti

1302
00:53:55,200 --> 00:53:58,980
della programmazione dinamica quindi è se

1303
00:53:58,980 --> 00:54:01,020
hai detto prima una coda da esplorare in questa griglia

1304
00:54:01,020 --> 00:54:03,660
ed è più ottimale Voglio

1305
00:54:03,660 --> 00:54:06,780
vedere come il termine di ambiguità previsto

1306
00:54:06,780 --> 00:54:10,319
in  l'energia libera prevista è utile

1307
00:54:10,319 --> 00:54:12,240
e dovrebbe essere utilizzata nella programmazione dinamica

1308
00:54:12,240 --> 00:54:13,260


1309
00:54:13,260 --> 00:54:15,540
rigorosamente in quel senso,

1310
00:54:15,540 --> 00:54:18,000
ma più in generale sto anche esaminando

1311
00:54:18,000 --> 00:54:20,339
altri modi di prendere decisioni nell'influenza

1312
00:54:20,339 --> 00:54:23,040
attiva come ci sono opere

1313
00:54:23,040 --> 00:54:24,900
del professore

1314
00:54:24,900 --> 00:54:26,099
un'estate

1315
00:54:26,099 --> 00:54:30,180
dalla CBS mi sa che parla  su com'è

1316
00:54:30,180 --> 00:54:33,059
Come le reti neurali stanno facendo

1317
00:54:33,059 --> 00:54:35,099
l'inferenza attiva e fondamentalmente il processo decisionale

1318
00:54:35,099 --> 00:54:36,359
c'è

1319
00:54:36,359 --> 00:54:39,540
um uh davvero più efficiente nel senso

1320
00:54:39,540 --> 00:54:42,359
che è come l'apprendimento in coda quindi

1321
00:54:42,359 --> 00:54:44,940
lì sta facendo un uso intelligente

1322
00:54:44,940 --> 00:54:47,520
dell'energia libera dalla variazione per apprendere buone

1323
00:54:47,520 --> 00:54:50,760
mappature di azioni di stato ed è è  un

1324
00:54:50,760 --> 00:54:52,200


1325
00:54:52,200 --> 00:54:55,079
cambiamento molto drastico rispetto a ciò a cui siamo abituati in

1326
00:54:55,079 --> 00:54:56,520
termini di energia libera attesa, quindi

1327
00:54:56,520 --> 00:54:59,220
non c'è alcun concetto di energia libera attesa uh

1328
00:54:59,220 --> 00:55:01,740
in quel lavoro si tratta solo di imparare

1329
00:55:01,740 --> 00:55:03,599
ciò che è buono e cattivo direttamente dalla

1330
00:55:03,599 --> 00:55:05,700
variazione dell'energia, quindi lo trovo

1331
00:55:05,700 --> 00:55:08,099
anche  affascinante Voglio

1332
00:55:08,099 --> 00:55:11,160
esplorarlo di più e vedere come il

1333
00:55:11,160 --> 00:55:15,300
processo decisionale uh in questo modo sia migliore o peggiore

1334
00:55:15,300 --> 00:55:18,000
o dovrebbe essere pensato dovremmo

1335
00:55:18,000 --> 00:55:20,220
anche riconsiderare i modi del processo decisionale

1336
00:55:20,220 --> 00:55:22,200
perché l'inferenza attiva parla solo

1337
00:55:22,200 --> 00:55:23,700
di energia libera variazionale e questo è

1338
00:55:23,700 --> 00:55:25,520
il principio centrale tutto  altrimenti la

1339
00:55:25,520 --> 00:55:28,440
tua interpretazione è giusta

1340
00:55:28,440 --> 00:55:31,319
quindi sì,

1341
00:55:31,319 --> 00:55:35,180
questa è un'altra direzione Voglio lavorare in

1342
00:55:35,640 --> 00:55:38,359
modo interessante per dirlo um sicuramente

1343
00:55:38,359 --> 00:55:42,480
l'energia libera variazionale che è un

1344
00:55:42,480 --> 00:55:45,540
funzionale della nostra

1345
00:55:45,540 --> 00:55:48,660
distribuzione variazionale um q e i dati y

1346
00:55:48,660 --> 00:55:51,119
l'energia libera variazionale è un po '

1347
00:55:51,119 --> 00:55:53,839
come il  omeostasi in tempo reale

1348
00:55:53,839 --> 00:55:57,359
come sì, come hanno

1349
00:55:57,359 --> 00:55:59,760
senso le cose dato ciò in cui credo e

1350
00:55:59,760 --> 00:56:01,619
i dati in arrivo

1351
00:56:01,619 --> 00:56:04,740
e quindi per estendere quel tipo di

1352
00:56:04,740 --> 00:56:07,020
struttura sensata nel

1353
00:56:07,020 --> 00:56:10,020
processo decisionale abbiamo visto molti

1354
00:56:10,020 --> 00:56:13,740
metodi diversi previsti l'energia libera è

1355
00:56:13,740 --> 00:56:16,260
um comune  ma per esempio c'è

1356
00:56:16,260 --> 00:56:19,400
stata l'energia libera del futuro atteso

1357
00:56:19,400 --> 00:56:25,200
come eef e ci sono altre costruzioni

1358
00:56:25,200 --> 00:56:29,760
che hanno metodi diversi

1359
00:56:29,760 --> 00:56:31,380
um e poi lo indichi anche al

1360
00:56:31,380 --> 00:56:33,599
lavoro del professor samura

1361
00:56:33,599 --> 00:56:37,020
con um il tipo di uh

1362
00:56:37,020 --> 00:56:39,059
relazione tra l'

1363
00:56:39,059 --> 00:56:41,339
energia libera variazionale sul grafico di base e il

1364
00:56:41,339 --> 00:56:43,680
funzione di perdita in una rete neurale e

1365
00:56:43,680 --> 00:56:45,300
tutte quelle relazioni che sono anche un

1366
00:56:45,300 --> 00:56:48,380
lavoro molto eccitante

1367
00:56:49,079 --> 00:56:51,660
ehm immagino che in chiusura come

1368
00:56:51,660 --> 00:56:53,460
ultima domanda o pensassi che

1369
00:56:53,460 --> 00:56:55,559
ti stai avvicinando alla fine del tuo

1370
00:56:55,559 --> 00:56:56,880
dottorato di ricerca,

1371
00:56:56,880 --> 00:57:00,540
quindi proprio nel tempo in cui sei stato  uno

1372
00:57:00,540 --> 00:57:02,579
studente di dottorato

1373
00:57:02,579 --> 00:57:06,300
come hai visto svilupparsi l'inferenza attiva

1374
00:57:06,300 --> 00:57:10,700
o cosa

1375
00:57:11,339 --> 00:57:14,280
ti sembra diverso oggi verso la

1376
00:57:14,280 --> 00:57:17,400
fine rispetto a quando eri

1377
00:57:17,400 --> 00:57:19,980
sì con gli occhi freschi ed eccitato diversi

1378
00:57:19,980 --> 00:57:21,119
anni fa

1379
00:57:21,119 --> 00:57:23,339
sì, questa è davvero una bella

1380
00:57:23,339 --> 00:57:25,920
domanda e uh sono anche molto entusiasta

1381
00:57:25,920 --> 00:57:29,400
di come  il campo si è evoluto e francamente

1382
00:57:29,400 --> 00:57:30,900
sono partito da questo

1383
00:57:30,900 --> 00:57:32,400
background di apprendimento per rinforzo e dal

1384
00:57:32,400 --> 00:57:34,680
background di fisica e quando ho iniziato a leggere

1385
00:57:34,680 --> 00:57:37,680
era solo diciamo uno o due articoli e

1386
00:57:37,680 --> 00:57:40,440
non ne ho capito molto uh è

1387
00:57:40,440 --> 00:57:42,540
stato solo quando ho iniziato a implementarlo

1388
00:57:42,540 --> 00:57:44,700
usando  chiama

1389
00:57:44,700 --> 00:57:46,980
um script Matlab in un certo senso ho capito

1390
00:57:46,980 --> 00:57:49,559
okay questo ha senso e mi piace e

1391
00:57:49,559 --> 00:57:52,020
ma entro uh diciamo uno o due anni ho visto

1392
00:57:52,020 --> 00:57:54,780
molti documenti arrivare uh da

1393
00:57:54,780 --> 00:57:56,280
direzioni diverse e anche le persone hanno

1394
00:57:56,280 --> 00:57:58,740
iniziato a usare le reti neurali e tutto

1395
00:57:58,740 --> 00:58:02,460
questo ridimensionamento  è venuto e io ad un certo

1396
00:58:02,460 --> 00:58:04,319
punto ho anche messo in dubbio la necessità

1397
00:58:04,319 --> 00:58:07,260
dell'inferenza attiva uh perché se hai un

1398
00:58:07,260 --> 00:58:09,119
apprendimento per rinforzo profondo

1399
00:58:09,119 --> 00:58:10,980
può fare molte cose allora perché l'inferenza attiva profonda

1400
00:58:10,980 --> 00:58:14,040
ed è per

1401
00:58:14,040 --> 00:58:16,319
questo che non ci sono entrato ma lo trovo comunque

1402
00:58:16,319 --> 00:58:18,359
affascinante  Voglio capire in qualche modo l'

1403
00:58:18,359 --> 00:58:20,280
inferenza attiva profonda più

1404
00:58:20,280 --> 00:58:23,160
di quello che so ora, ma ho visto il

1405
00:58:23,160 --> 00:58:25,680
campo crescere come qualsiasi altra cosa in due o

1406
00:58:25,680 --> 00:58:28,619
tre anni e molte coorti di persone hanno

1407
00:58:28,619 --> 00:58:31,859
iniziato a lavorare e in pochissimo tempo è stato un

1408
00:58:31,859 --> 00:58:36,359
campo seriamente preso altro  di un campo

1409
00:58:36,359 --> 00:58:39,119
con diciamo due documenti con nessuno che

1410
00:58:39,119 --> 00:58:41,280
sappia effettivamente cosa sia, quindi è davvero

1411
00:58:41,280 --> 00:58:43,440
eccitante sì, quindi non vedo davvero l'ora di

1412
00:58:43,440 --> 00:58:47,040
come il campo si evolve nel tempo e anche

1413
00:58:47,040 --> 00:58:52,140
cosa posso fare dopo il mio dottorato di ricerca e così

1414
00:58:52,140 --> 00:58:55,319
via avanti nel tempo indietro nel tempo

1415
00:58:55,319 --> 00:59:00,359
cosa  preferiamo quello che ci aspettiamo sì

1416
00:59:02,339 --> 00:59:04,140
qualsiasi altro

1417
00:59:04,140 --> 00:59:05,819
commento o qualsiasi altra cosa tu voglia

1418
00:59:05,819 --> 00:59:07,200
aggiungere

1419
00:59:07,200 --> 00:59:09,839
sì quindi per favore fammi sapere cosa ne

1420
00:59:09,839 --> 00:59:11,940
pensi del documento e cosa pensi

1421
00:59:11,940 --> 00:59:14,400
di queste idee sentiti libero di farmelo

1422
00:59:14,400 --> 00:59:16,200
sapere Non vedo davvero l'ora del

1423
00:59:16,200 --> 00:59:17,760
feedback e

1424
00:59:17,760 --> 00:59:20,160
sì  grazie mille per questa opportunità

1425
00:59:20,160 --> 00:59:23,339
Daniel e grazie per il tuo tempo

1426
00:59:23,339 --> 00:59:26,160
è stato fantastico

1427
00:59:26,160 --> 00:59:28,260


1428
00:59:28,260 --> 00:59:30,540


1429
00:59:30,540 --> 00:59:33,359


1430
00:59:33,359 --> 00:59:34,680


1431
00:59:34,680 --> 00:59:36,839
grazie mille ciao

1432
00:59:36,839 --> 00:59:40,040
buona giornata ciao

