1
00:00:03,120 --> 00:00:06,120
国外，

2
00:00:08,480 --> 00:00:12,660
2023 年 7 月 15 日，

3
00:00:12,660 --> 00:00:15,900
我们今天与 Aspen Paul 一起参加主动推理模型

4
00:00:15,900 --> 00:00:19,080
流 9.1，

5
00:00:19,080 --> 00:00:21,060
我们将就主动推理中的

6
00:00:21,060 --> 00:00:24,180
高效计算进行演示和讨论，

7
00:00:24,180 --> 00:00:27,000
因此，如果

8
00:00:27,000 --> 00:00:28,619
您正在观看直播，请

9
00:00:28,619 --> 00:00:30,840
随时添加 聊天中的评论或问题，

10
00:00:30,840 --> 00:00:33,059
否则

11
00:00:33,059 --> 00:00:36,120
非常感谢您今天的加入，非常

12
00:00:36,120 --> 00:00:38,820
期待您的演讲，

13
00:00:38,820 --> 00:00:41,640
谢谢丹尼尔，非常感谢您，正如

14
00:00:41,640 --> 00:00:42,960
今天提到的，我将讨论

15
00:00:42,960 --> 00:00:44,700
高效计算和主动

16
00:00:44,700 --> 00:00:46,920
推理，是的，让我们开始吧，

17
00:00:46,920 --> 00:00:49,500
所以我们' 我们都熟悉

18
00:00:49,500 --> 00:00:51,420
自由能原理的概念，也

19
00:00:51,420 --> 00:00:53,820
称为主动推理权，因此

20
00:00:53,820 --> 00:00:55,800
中心概念是代理

21
00:00:55,800 --> 00:00:59,160
最小化其观察到的熵以

22
00:00:59,160 --> 00:01:01,140
维持稳态或在其环境中生存

23
00:01:01,140 --> 00:01:03,719
，这里的熵是

24
00:01:03,719 --> 00:01:05,580
在信息论中定义的

25
00:01:05,580 --> 00:01:08,520
感觉是对的，所以如果一个观察结果是

26
00:01:08,520 --> 00:01:10,200
高概率的，

27
00:01:10,200 --> 00:01:12,659
那么熵较小或不那么令人惊讶，因为它

28
00:01:12,659 --> 00:01:14,159
是高概率的，我们

29
00:01:14,159 --> 00:01:16,560
期待着它，

30
00:01:16,560 --> 00:01:18,840


31
00:01:18,840 --> 00:01:20,939


32
00:01:20,939 --> 00:01:23,759
这就是我们构建主动推理框架的基础的想法。

33
00:01:23,759 --> 00:01:26,520
Marco 毯子呃，它为我们提供了一种

34
00:01:26,520 --> 00:01:30,000
令人惊讶的系统方法，或者是一种将

35
00:01:30,000 --> 00:01:32,580
代理

36
00:01:32,580 --> 00:01:34,439
与其环境分离的示意性方法，并对

37
00:01:34,439 --> 00:01:37,320
有目的的行为进行建模，所以让我们关注

38
00:01:37,320 --> 00:01:39,780
最小化熵的想法，那么

39
00:01:39,780 --> 00:01:41,700
代理如何最小化熵或

40
00:01:41,700 --> 00:01:43,740
知道哪个观察是 高

41
00:01:43,740 --> 00:01:46,020
概率性，反之亦然，

42
00:01:46,020 --> 00:01:48,360
因此这是通过维护生成

43
00:01:48,360 --> 00:01:50,399
模型而生成模型基本上是

44
00:01:50,399 --> 00:01:52,020


45
00:01:52,020 --> 00:01:56,340
代理在其大脑中构建的环境玩具模型，并且

46
00:01:56,340 --> 00:01:58,860
仅使用

47
00:01:58,860 --> 00:02:00,540
从环境中获得的观察来构建，因此它

48
00:02:00,540 --> 00:02:03,420
没有 访问真实的呃状态或

49
00:02:03,420 --> 00:02:04,740
环境的隐藏状态，

50
00:02:04,740 --> 00:02:07,920
它正在构建玩具模型，并且给定

51
00:02:07,920 --> 00:02:10,318
这个玩具模型，它具有计算观察概率的范围或能力，

52
00:02:10,318 --> 00:02:13,560


53
00:02:13,560 --> 00:02:15,900
因此尝试最小化

54
00:02:15,900 --> 00:02:18,660
熵，

55
00:02:18,660 --> 00:02:22,620
这就是想法，但它 有

56
00:02:22,620 --> 00:02:25,800
一个草书维度的问题，就像给定一个

57
00:02:25,800 --> 00:02:27,239
生成模型一样，它可能不可能

58
00:02:27,239 --> 00:02:30,120
总是计算或边缘化

59
00:02:30,120 --> 00:02:32,099
观察的概率，

60
00:02:32,099 --> 00:02:34,140
因为状态空间很快就会

61
00:02:34,140 --> 00:02:37,020
变得棘手，但想法是

62
00:02:37,020 --> 00:02:38,640
你定义一个

63
00:02:38,640 --> 00:02:41,580
惊喜的上限 使用 Jensen 不等式，

64
00:02:41,580 --> 00:02:43,560
您还可以

65
00:02:43,560 --> 00:02:46,800
定义一个名为 Q 的新术语，它是

66
00:02:46,800 --> 00:02:49,500
隐藏信念或关于

67
00:02:49,500 --> 00:02:52,080
隐藏状态的信念，并且该队列将

68
00:02:52,080 --> 00:02:54,000
成为正确决策的焦点，因此

69
00:02:54,000 --> 00:02:57,060
如果您有一个嘈杂的队列并且您

70
00:02:57,060 --> 00:02:58,680
不知道 环境中有什么，那么

71
00:02:58,680 --> 00:03:00,840
你就无法或希望做出决定

72
00:03:00,840 --> 00:03:03,540
来控制该环境，正是

73
00:03:03,540 --> 00:03:05,519
这种关于你使用的隐藏状态的信念，对

74
00:03:05,519 --> 00:03:07,560
做出决定变得有用

75
00:03:07,560 --> 00:03:10,379
，这整个量

76
00:03:10,379 --> 00:03:13,019
当然称为自由能，

77
00:03:13,019 --> 00:03:14,420
变分自由能

78
00:03:14,420 --> 00:03:17,879
F 可以用多种方式解释，所以

79
00:03:17,879 --> 00:03:19,560
第一个或最常见的是

80
00:03:19,560 --> 00:03:22,920
机器学习方式，

81
00:03:22,920 --> 00:03:25,200
尝试最小化模型的复杂性，

82
00:03:25,200 --> 00:03:27,060
同时尝试

83
00:03:27,060 --> 00:03:28,739
最大化模型的准确性，这就是

84
00:03:28,739 --> 00:03:30,180


85
00:03:30,180 --> 00:03:32,400
最小化各种自由能的机器学习解释您

86
00:03:32,400 --> 00:03:34,140
也可以尝试用

87
00:03:34,140 --> 00:03:34,739


88
00:03:34,739 --> 00:03:36,420
物理术语解释自由能，

89
00:03:36,420 --> 00:03:38,940
您同时尝试

90
00:03:38,940 --> 00:03:41,760
最小化模型的能量，但

91
00:03:41,760 --> 00:03:43,019
同时尝试最大化

92
00:03:43,019 --> 00:03:45,120
熵，但今天的焦点

93
00:03:45,120 --> 00:03:48,659
或者决策总是基于

94
00:03:48,659 --> 00:03:51,540
这样的信念，

95
00:03:51,540 --> 00:03:54,780
即在进行主动推理中的感知之后，

96
00:03:54,780 --> 00:03:57,120
您如何进行普通决策，或者

97
00:03:57,120 --> 00:03:58,920


98
00:03:58,920 --> 00:04:00,659
决策和经典主动

99
00:04:00,659 --> 00:04:03,540
推理​​中讨论最多的想法是什么，所以如果您处于一个

100
00:04:03,540 --> 00:04:05,580
环境中，呃 如果你是一个

101
00:04:05,580 --> 00:04:08,819
试图做出决定的代理，那么

102
00:04:08,819 --> 00:04:10,620
你有一个

103
00:04:10,620 --> 00:04:13,319
可用的操作空间，所以在

104
00:04:13,319 --> 00:04:15,480
这个玩具模型中，你有三个可用的

105
00:04:15,480 --> 00:04:19,738
操作，呃，跑，跳跃或停留，

106
00:04:19,738 --> 00:04:22,199
考虑到这些操作，你可以希望

107
00:04:22,199 --> 00:04:25,139
通过小 Pi 来定义策略 这是

108
00:04:25,139 --> 00:04:28,320
时间和资本上的一系列行动

109
00:04:28,320 --> 00:04:30,300
t 是计划的时间范围，或者

110
00:04:30,300 --> 00:04:32,660
是你的政策的长度，

111
00:04:32,660 --> 00:04:36,540
你有一个政策空间，里面有

112
00:04:36,540 --> 00:04:39,419
许多这样的政策小饼，所以给定

113
00:04:39,419 --> 00:04:42,060
这个更大的最小空间，你可以

114
00:04:42,060 --> 00:04:44,220
尝试

115
00:04:44,220 --> 00:04:47,340
评估预期的免费 基于

116
00:04:47,340 --> 00:04:48,720
你积累的信念的能量，

117
00:04:48,720 --> 00:04:50,580
所以在这里你不会最小化任何

118
00:04:50,580 --> 00:04:52,860
你已经拥有的来自能量变化的信念，你

119
00:04:52,860 --> 00:04:55,080
只是

120
00:04:55,080 --> 00:04:57,419
计算或评估

121
00:04:57,419 --> 00:04:59,520
与许多呃

122
00:04:59,520 --> 00:05:02,759
小政策相对应的预期自由能，你可以定义

123
00:05:02,759 --> 00:05:05,699
和之后 你对所有策略进行评估，

124
00:05:05,699 --> 00:05:07,440
然后你就知道采取哪个是

125
00:05:07,440 --> 00:05:09,180
最佳策略，这是

126
00:05:09,180 --> 00:05:11,160


127
00:05:11,160 --> 00:05:13,800
决策正确的经典主动推理​​思想，

128
00:05:13,800 --> 00:05:16,020
这种预期的自由能非常

129
00:05:16,020 --> 00:05:18,900
有用，因为它是目标

130
00:05:18,900 --> 00:05:21,720
导向的，因此风险项是目标

131
00:05:21,720 --> 00:05:23,520
导向的 然后你就有了这个预期的

132
00:05:23,520 --> 00:05:25,919
模糊性术语，它迫使你去

133
00:05:25,919 --> 00:05:27,960
探索，但有一个问题

134
00:05:27,960 --> 00:05:30,539
，这个策略空间可以很快变得

135
00:05:30,539 --> 00:05:32,400
可交互，并且一直是将

136
00:05:32,400 --> 00:05:35,280
主动推理扩展

137
00:05:35,280 --> 00:05:37,680
到

138
00:05:37,680 --> 00:05:40,500
常见环境的瓶颈，但让我们

139
00:05:40,500 --> 00:05:42,419
看看它是如何实现的 变得可以快速交互，

140
00:05:42,419 --> 00:05:45,300
因此可以定义多少个策略，比如

141
00:05:45,300 --> 00:05:47,940
时间范围为 15，所以如果你

142
00:05:47,940 --> 00:05:50,340
正在玩超级马里奥，你

143
00:05:50,340 --> 00:05:52,440
可能需要提前计划至少 10 个时间

144
00:05:52,440 --> 00:05:56,460
步长，这样第一个策略可能是

145
00:05:56,460 --> 00:05:58,380
相同的操作 运行

146
00:05:58,380 --> 00:06:02,600
um stacked 15 个时间步长，你

147
00:06:02,600 --> 00:06:05,460
基本上可以定义这些动作的几种组合，

148
00:06:05,460 --> 00:06:09,060
而策略空间

149
00:06:09,060 --> 00:06:10,139
只是

150
00:06:10,139 --> 00:06:13,860
um 棘手，它变得呃太大了，

151
00:06:13,860 --> 00:06:16,380
你无法评估

152
00:06:16,380 --> 00:06:19,440
所有这些策略的预期自由能，并且在

153
00:06:19,440 --> 00:06:21,900
随机问题设置中

154
00:06:21,900 --> 00:06:24,419
um 环境本身很嘈杂，你

155
00:06:24,419 --> 00:06:27,120
实际上没有一种方法来选择

156
00:06:27,120 --> 00:06:28,860
这个策略空间的子集并进行

157
00:06:28,860 --> 00:06:30,840
经典的主动推理，这

158
00:06:30,840 --> 00:06:32,340
显然是一个计算可交互的

159
00:06:32,340 --> 00:06:34,380
问题，这就是为什么在文献中，当你讨论时我们

160
00:06:34,380 --> 00:06:36,360
总是看到小网格或小

161
00:06:36,360 --> 00:06:38,880
环境 决策

162
00:06:38,880 --> 00:06:41,520
具有积极的影响力，但最近

163
00:06:41,520 --> 00:06:43,860


164
00:06:43,860 --> 00:06:46,259
提出了一个新的想法，称为复杂的

165
00:06:46,259 --> 00:06:48,840
入口，在复杂的推理中，

166
00:06:48,840 --> 00:06:51,600
它实际上并不是政策空间，你

167
00:06:51,600 --> 00:06:52,800
实际上是

168
00:06:52,800 --> 00:06:55,080
实时尝试

169
00:06:55,080 --> 00:06:58,139
思考该怎么做，如果你有一个信念，

170
00:06:58,139 --> 00:07:00,000
那么你 试图

171
00:07:00,000 --> 00:07:02,880
评估基于此的行动，所以

172
00:07:02,880 --> 00:07:04,800
这里我们没有一系列

173
00:07:04,800 --> 00:07:07,199


174
00:07:07,199 --> 00:07:10,020
可交互的政策或事物，呃这里我们正在进行

175
00:07:10,020 --> 00:07:12,600
基本上的研究，从某种意义上说，你

176
00:07:12,600 --> 00:07:14,220
正在尝试评估

177
00:07:14,220 --> 00:07:16,500


178
00:07:16,500 --> 00:07:19,560
这个联合分布的预期自由能 的行动和

179
00:07:19,560 --> 00:07:21,900
观察，并评估

180
00:07:21,900 --> 00:07:23,940
某个时间 uh 小 T 的预期自由能，

181
00:07:23,940 --> 00:07:26,340
您还需要

182
00:07:26,340 --> 00:07:29,039
下一个时间步的预期自由能，并

183
00:07:29,039 --> 00:07:31,259
评估您将需要

184
00:07:31,259 --> 00:07:32,819
时间 t 加 2 的预期自由能，这

185
00:07:32,819 --> 00:07:35,039
基本上变成 一项

186
00:07:35,039 --> 00:07:38,160
及时推出的研究，呃，这是一个

187
00:07:38,160 --> 00:07:41,160
递归关系，

188
00:07:41,160 --> 00:07:43,259
这里它与

189
00:07:43,259 --> 00:07:45,539
我们在上一张幻灯片中看到的政策空间有根本的不同，从

190
00:07:45,539 --> 00:07:47,759


191
00:07:47,759 --> 00:07:49,680
某种意义上说，它在计算上更好，

192
00:07:49,680 --> 00:07:51,780
如果你必须计划说 10

193
00:07:51,780 --> 00:07:55,139
次提示 在

194
00:07:55,139 --> 00:07:56,759
经典主动推理​​中，我们看到

195
00:07:56,759 --> 00:07:58,380
策略空间

196
00:07:58,380 --> 00:07:59,460
和

197
00:07:59,460 --> 00:08:01,940
动作空间的基数

198
00:08:01,940 --> 00:08:04,139
提升到 T，因此

199
00:08:04,139 --> 00:08:07,259
如果您必须考虑

200
00:08:07,259 --> 00:08:10,199
所有可能性，那么这就是计算瓶颈，但在复杂的

201
00:08:10,199 --> 00:08:12,780
推理中，情况更糟，因为

202
00:08:12,780 --> 00:08:14,759
您正在考虑

203
00:08:14,759 --> 00:08:16,860
状态和动作的组合，所以

204
00:08:16,860 --> 00:08:20,400
实际上在计算上更糟糕，但是

205
00:08:20,400 --> 00:08:21,660
在

206
00:08:21,660 --> 00:08:23,520
复杂的参考论文中提出了一个解决方案，我们

207
00:08:23,520 --> 00:08:26,400
可以对这项研究进行修剪，

208
00:08:26,400 --> 00:08:29,639


209
00:08:29,639 --> 00:08:31,080
当你进行这项研究时，我们可以避免一些状态和动作，并且在

210
00:08:31,080 --> 00:08:33,000
计算上变得非常容易处理

211
00:08:33,000 --> 00:08:36,059
所以让我们看看剪枝在

212
00:08:36,059 --> 00:08:38,940
复杂推理中是如何工作的，所以这个网格

213
00:08:38,940 --> 00:08:40,440
在原始的复杂推理论文中进行了讨论，

214
00:08:40,440 --> 00:08:41,700


215
00:08:41,700 --> 00:08:44,580
并且对于这个网格来说，假设你

216
00:08:44,580 --> 00:08:47,100
有这种先验偏好

217
00:08:47,100 --> 00:08:50,399
分布，所以这个白色方块

218
00:08:50,399 --> 00:08:52,140
是目标状态最优选的状态

219
00:08:52,140 --> 00:08:54,300
， 你对远离黄金状态的状态有一个

220
00:08:54,300 --> 00:08:55,380


221
00:08:55,380 --> 00:08:58,140
均匀递减的偏好，

222
00:08:58,140 --> 00:09:00,779


223
00:09:00,779 --> 00:09:03,240
那么基本上如果你

224
00:09:03,240 --> 00:09:05,480
在时间 T 的某个观察中观察自己，

225
00:09:05,480 --> 00:09:07,560
那么基本上你正在做的是

226
00:09:07,560 --> 00:09:09,600
你正在考虑

227
00:09:09,600 --> 00:09:12,779
该观察中可用行动的结果，

228
00:09:12,779 --> 00:09:17,760
并且 基本上，你可以使用

229
00:09:17,760 --> 00:09:20,700
你的信念的投影，并为这些信念设定一个阈值，

230
00:09:20,700 --> 00:09:22,620
以某种方式忽略

231
00:09:22,620 --> 00:09:24,600
某些行动并忽略某些

232
00:09:24,600 --> 00:09:27,420
观察，你会发现

233
00:09:27,420 --> 00:09:30,120
它不再是研究，

234
00:09:30,120 --> 00:09:33,000
它是研究的一个子集，并且是

235
00:09:33,000 --> 00:09:36,060
计算方式 嗯，

236
00:09:36,060 --> 00:09:38,700
比做整个研究更有效率，所以在这里

237
00:09:38,700 --> 00:09:40,680
你已经避免了很多组合

238
00:09:40,680 --> 00:09:42,120
，这成为一个计算上

239
00:09:42,120 --> 00:09:45,420
有吸引力的问题，这是因为你

240
00:09:45,420 --> 00:09:47,880
决定避免一些行动和

241
00:09:47,880 --> 00:09:49,620
嗯观察，所以你说本质上是

242
00:09:49,620 --> 00:09:52,740
在这种可能性上妥协，这

243
00:09:52,740 --> 00:09:54,600
可能会给你一个 更高的奖励，或者

244
00:09:54,600 --> 00:09:56,580
可能比

245
00:09:56,580 --> 00:09:59,700
部分研究的结果更优化，但是

246
00:09:59,700 --> 00:10:02,820
这是有效的，因此

247
00:10:02,820 --> 00:10:05,459
论文中提出了这个模拟，并且它有效，

248
00:10:05,459 --> 00:10:09,959


249
00:10:09,959 --> 00:10:12,300
如果代理朝着

250
00:10:12,300 --> 00:10:14,940
这个前进方向计划，它会学习做需要做的事情 以

251
00:10:14,940 --> 00:10:17,880
修剪的方式规划呃，但是

252
00:10:17,880 --> 00:10:19,200


253
00:10:19,200 --> 00:10:20,820
基本上你可以通过计算

254
00:10:20,820 --> 00:10:23,519
表明，即使对于一个小的搜索

255
00:10:23,519 --> 00:10:25,019
阈值，

256
00:10:25,019 --> 00:10:27,180
你也可以大大降低

257
00:10:27,180 --> 00:10:29,100
计算复杂度，所以如果你

258
00:10:29,100 --> 00:10:31,500
决定用规划深度进行整个研究，

259
00:10:31,500 --> 00:10:33,540


260
00:10:33,540 --> 00:10:35,100
计算时间是 指数级的并且

261
00:10:35,100 --> 00:10:38,040
很快你就无法做太多事情，

262
00:10:38,040 --> 00:10:40,200
但是如果你决定在这样的阈值

263
00:10:40,200 --> 00:10:42,420
（甚至非常小）你可以看到

264
00:10:42,420 --> 00:10:43,980
这个问题在计算上变得有

265
00:10:43,980 --> 00:10:46,620
吸引力，并且这个关于

266
00:10:46,620 --> 00:10:49,200
复杂实例的演示可以

267
00:10:49,200 --> 00:10:50,700
在我的 mdp 版本中找到，

268
00:10:50,700 --> 00:10:52,860
它是 很快就会被 mdp 整合到

269
00:10:52,860 --> 00:10:55,380
原始版本中，

270
00:10:55,380 --> 00:10:56,820


271
00:10:56,820 --> 00:10:59,160
但是关键点是，

272
00:10:59,160 --> 00:11:01,920
该研究的修剪需要我们有一个

273
00:11:01,920 --> 00:11:03,779
像这样消息灵通的主要偏好，

274
00:11:03,779 --> 00:11:06,060
因为这里的代理

275
00:11:06,060 --> 00:11:09,360
知道我们的邻居

276
00:11:09,360 --> 00:11:11,760
声明它是多么可取 只知道最终

277
00:11:11,760 --> 00:11:13,860
目标集，它还知道其

278
00:11:13,860 --> 00:11:16,440
邻近状态，并且考虑到这样的先验

279
00:11:16,440 --> 00:11:18,420
偏好，我们可以看到，对于

280
00:11:18,420 --> 00:11:20,399
三的规划深度，智能体

281
00:11:20,399 --> 00:11:23,820
基本上陷入了

282
00:11:23,820 --> 00:11:27,060
先验偏好的本地最大值，但具有

283
00:11:27,060 --> 00:11:30,480
足够的规划深度，它是 它

284
00:11:30,480 --> 00:11:33,240
能够克服这个障碍并达到

285
00:11:33,240 --> 00:11:35,579
这个大问题中的目标状态

286
00:11:35,579 --> 00:11:37,800
，

287
00:11:37,800 --> 00:11:39,600
问题是，如果代理

288
00:11:39,600 --> 00:11:42,720
只知道这个最终状态，它

289
00:11:42,720 --> 00:11:45,660
不知道要做什么，在

290
00:11:45,660 --> 00:11:48,240
这种情况下代理会做什么 所以这就是

291
00:11:48,240 --> 00:11:50,459
我们正在努力

292
00:11:50,459 --> 00:11:53,399
解决的问题，在没有

293
00:11:53,399 --> 00:11:55,740
像这样的有意义的先验偏好的情况下，

294
00:11:55,740 --> 00:11:58,200
代理基本上没有办法

295
00:11:58,200 --> 00:12:00,720
达到目标状态，

296
00:12:00,720 --> 00:12:03,300
除了随机探索之外，

297
00:12:03,300 --> 00:12:05,279
它没有办法计划，因为它

298
00:12:05,279 --> 00:12:08,040
不能 呃，提前规划八个时间步骤，

299
00:12:08,040 --> 00:12:09,779
因为它在计算上是可

300
00:12:09,779 --> 00:12:13,079
交互的，呃，如果它选择

301
00:12:13,079 --> 00:12:17,880
正确地进行完整的研究，那么如果是

302
00:12:17,880 --> 00:12:21,000
这样的话，对于这样的网格，

303
00:12:21,000 --> 00:12:22,500
如果你得到一个稀疏的尝试偏好，而

304
00:12:22,500 --> 00:12:24,240
这个偏好没有得到充分的信息

305
00:12:24,240 --> 00:12:28,079
和突出显示，你会怎么做 在上一张幻灯片中，

306
00:12:28,079 --> 00:12:30,839
你的研究现在是盲目的，呃，你

307
00:12:30,839 --> 00:12:33,000
无法修剪该研究，你

308
00:12:33,000 --> 00:12:35,100
必须在这种情况下进行全面的研究，

309
00:12:35,100 --> 00:12:36,300


310
00:12:36,300 --> 00:12:38,880
所以你可能会认为，

311
00:12:38,880 --> 00:12:40,200
嗯，有两种解决方案，

312
00:12:40,200 --> 00:12:42,959
要么你必须找到一个 进行

313
00:12:42,959 --> 00:12:47,359
全面深度规划的方法呃，

314
00:12:49,579 --> 00:12:52,920
或者你必须学习一个有意义的骄傲

315
00:12:52,920 --> 00:12:54,600
偏好，这将使你能够进行

316
00:12:54,600 --> 00:12:57,480
这个经过修剪的研究，所以我们将

317
00:12:57,480 --> 00:12:59,760
在本演示文稿中讨论这两个解决方案

318
00:12:59,760 --> 00:13:02,399
呃对于这样的给定

319
00:13:02,399 --> 00:13:03,839
场景，

320
00:13:03,839 --> 00:13:06,420
所以第一个 解决方案呃，做全面的

321
00:13:06,420 --> 00:13:08,639
研究基本上是使用动态

322
00:13:08,639 --> 00:13:11,399
规划，动态规划是

323
00:13:11,399 --> 00:13:13,800
运筹学

324
00:13:13,800 --> 00:13:15,839
和工业工程以及

325
00:13:15,839 --> 00:13:18,060
许多工程分支中的一个众所周知的想法，

326
00:13:18,060 --> 00:13:19,920
基本思想是

327
00:13:19,920 --> 00:13:21,959


328
00:13:21,959 --> 00:13:24,000
先解决一个更大问题的子部分，然后再解决 稍后尝试整合

329
00:13:24,000 --> 00:13:27,000
这些子问题的解决方案，以

330
00:13:27,000 --> 00:13:31,260
做出最佳决策，因此

331
00:13:31,260 --> 00:13:33,779
在这种情况下，想象一下

332
00:13:33,779 --> 00:13:37,019
您正在尝试计划最后一个

333
00:13:37,019 --> 00:13:39,540
行动，所以早些时候，

334
00:13:39,540 --> 00:13:41,760
我们从现在开始的第一个行动开始，

335
00:13:41,760 --> 00:13:44,040
并尝试预测 未来会发生什么，

336
00:13:44,040 --> 00:13:46,320
所以你的

337
00:13:46,320 --> 00:13:47,940
计划方向基本上是及时向前的，

338
00:13:47,940 --> 00:13:49,920
但想象一下，你试图

339
00:13:49,920 --> 00:13:51,959
只为最后一个时间步骤进行计划，此时你

340
00:13:51,959 --> 00:13:55,560
正接近目标状态，并且正

341
00:13:55,560 --> 00:13:57,600
朝着那个良好的状态前进，所以你

342
00:13:57,600 --> 00:13:59,519
正在尝试为

343
00:13:59,519 --> 00:14:01,740
最后一个时间步长（大写 T 减

344
00:14:01,740 --> 00:14:05,459
1）做出决定，并且您对下一个

345
00:14:05,459 --> 00:14:08,880
时间步长或最后一个目标状态的预测

346
00:14:08,880 --> 00:14:09,839


347
00:14:09,839 --> 00:14:11,880
可以完成，因为您可以

348
00:14:11,880 --> 00:14:14,160
使用此

349
00:14:14,160 --> 00:14:16,079
转换访问这个世界模型 主动推理中的动力学或 B 矩阵，

350
00:14:16,079 --> 00:14:18,600
因此对于这个单一时间

351
00:14:18,600 --> 00:14:21,180
步骤，这是一个子问题，呃，您

352
00:14:21,180 --> 00:14:24,060
实际上正在评估一个预期

353
00:14:24,060 --> 00:14:26,100
自由能表，该表告诉您，如果您处于

354
00:14:26,100 --> 00:14:28,019
这个观察中，则要做什么，

355
00:14:28,019 --> 00:14:31,740
这是最后一个 时间步长，

356
00:14:31,740 --> 00:14:34,440
基本上呃，你可以在状态

357
00:14:34,440 --> 00:14:36,540
空间或观察空间中做到这一点，所以这可以通过

358
00:14:36,540 --> 00:14:39,120


359
00:14:39,120 --> 00:14:41,699
一起使用 a 矩阵和 D 矩阵来完成，你可以以

360
00:14:41,699 --> 00:14:44,579
正确的方式进行规划，所以

361
00:14:44,579 --> 00:14:46,260
问题是，

362
00:14:46,260 --> 00:14:48,839
如果你知道在

363
00:14:48,839 --> 00:14:50,940


364
00:14:50,940 --> 00:14:52,440
你可能会想的最后一个步骤，我怎么知道

365
00:14:52,440 --> 00:14:54,600
我处于最后一个时间步骤，这一切

366
00:14:54,600 --> 00:14:58,699
都是为了想象你已经

367
00:15:09,720 --> 00:15:12,839
抱歉，我们听到的最后一件事是，

368
00:15:12,839 --> 00:15:15,540
这一切都是为了想象，

369
00:15:15,540 --> 00:15:18,060
是的，所以从那里开始吧 所有

370
00:15:18,060 --> 00:15:19,860
关于想象

371
00:15:19,860 --> 00:15:22,139
好吧，如果出现连接问题，

372
00:15:22,139 --> 00:15:23,699
是的，只要几秒钟，

373
00:15:23,699 --> 00:15:25,199
那么现在一切都很好哦，对此感到

374
00:15:25,199 --> 00:15:28,260
抱歉，但是所以

375
00:15:28,260 --> 00:15:30,899
嗯，所以我想说的是，你

376
00:15:30,899 --> 00:15:32,880
正在尝试想象如果你会做什么

377
00:15:32,880 --> 00:15:35,519
时间资本 T 减一，

378
00:15:35,519 --> 00:15:37,560
这是您规划范围的最后一个时间步骤

379
00:15:37,560 --> 00:15:40,260
，如果您处于该

380
00:15:40,260 --> 00:15:42,199
时间步骤，我该怎么做，所以这张表

381
00:15:42,199 --> 00:15:45,480
代表了所有这样的场景，如果我

382
00:15:45,480 --> 00:15:49,800
说在时间 T 的观察 3 减

383
00:15:49,800 --> 00:15:52,680
一什么 我这样做，这里的数量

384
00:15:52,680 --> 00:15:54,720
我只考虑风险项或

385
00:15:54,720 --> 00:15:56,279
有目的的项

386
00:15:56,279 --> 00:15:57,720
呃，

387
00:15:57,720 --> 00:16:01,560
这个项代表该政策，

388
00:16:01,560 --> 00:16:03,540
如果我向后做这个

389
00:16:03,540 --> 00:16:06,180
直到时间 T 减一，所以如果

390
00:16:06,180 --> 00:16:08,699
我知道该怎么做 在时间呃

391
00:16:08,699 --> 00:16:12,300
大写 T 负 1 那么这个表可以

392
00:16:12,300 --> 00:16:14,880
告诉在大写 T 负 2 时做什么。

393
00:16:14,880 --> 00:16:16,920
所以我所做的不是及时计划，而是

394
00:16:16,920 --> 00:16:19,320


395
00:16:19,320 --> 00:16:22,019
通过固定

396
00:16:22,019 --> 00:16:25,019
计划的大写 T 将许多表堆叠在一起，并

397
00:16:25,019 --> 00:16:29,279
考虑到 我有所有这样的堆栈表，

398
00:16:29,279 --> 00:16:31,800
那么基本上我能做的就是使用它们

399
00:16:31,800 --> 00:16:33,899
及时做出决策，

400
00:16:33,899 --> 00:16:35,940
我们观察到这个想法是有效的，

401
00:16:35,940 --> 00:16:38,519


402
00:16:38,519 --> 00:16:40,259
嗯我可以逐步向后计算预期的

403
00:16:40,259 --> 00:16:43,019
自由能呃将

404
00:16:43,019 --> 00:16:46,920
它们视为子问题

405
00:16:46,920 --> 00:16:49,079
根本区别在于，在

406
00:16:49,079 --> 00:16:51,600
复杂的推理中，要计算

407
00:16:51,600 --> 00:16:54,959
小 T 时的预期自由能，

408
00:16:54,959 --> 00:16:57,540
您不知道团队加一时的预期自由能是多少，

409
00:16:57,540 --> 00:16:59,880
因此这

410
00:16:59,880 --> 00:17:01,920
变成了三搜索，因此您必须

411
00:17:01,920 --> 00:17:04,319
首先计算它 要计算

412
00:17:04,319 --> 00:17:06,839
t 加 1，您需要 t 加 2 等等，

413
00:17:06,839 --> 00:17:09,000
但在这里，因为您是

414
00:17:09,000 --> 00:17:11,339
在时间上向后计算它，所以您已经知道

415
00:17:11,339 --> 00:17:13,559
p 加 1 的预期自由能是多少，

416
00:17:13,559 --> 00:17:16,020
并且您的基础是基本上

417
00:17:16,020 --> 00:17:17,520
相同的方程，只是这样 你正在

418
00:17:17,520 --> 00:17:20,900
时间上倒退，并以复杂的推理

419
00:17:20,900 --> 00:17:23,520
方式进行图像化，

420
00:17:23,520 --> 00:17:25,619
你正在尝试进行一项研究，但在

421
00:17:25,619 --> 00:17:27,660
动态规划算法中，你正在

422
00:17:27,660 --> 00:17:30,120
使用表格向后进行

423
00:17:30,120 --> 00:17:32,940
规划，并且考虑到你的规划地平线

424
00:17:32,940 --> 00:17:35,520
足以解决

425
00:17:35,520 --> 00:17:38,160
我们所面临的问题 可以看出，代理将

426
00:17:38,160 --> 00:17:40,860
能够及时采取最佳行动，

427
00:17:40,860 --> 00:17:44,340
因此在本文中，我们还

428
00:17:44,340 --> 00:17:46,500
提出了一种

429
00:17:46,500 --> 00:17:49,020
使用这种向后规划的顺序形式 DPS 算法，

430
00:17:49,020 --> 00:17:50,880
并且我们

431
00:17:50,880 --> 00:17:54,059
能够扩大对网格

432
00:17:54,059 --> 00:17:56,240
空间的模拟，即 以前可以在

433
00:17:56,240 --> 00:17:59,340
没有神经网络的情况下进行交互，

434
00:17:59,340 --> 00:18:01,080
嗯，所以这是第一个解决方案，所以

435
00:18:01,080 --> 00:18:03,840
第二个解决方案是，

436
00:18:03,840 --> 00:18:06,000
嗯，所以在第一个解决方案中，它被修复了，

437
00:18:06,000 --> 00:18:07,980
你只能得到这个过去的私人

438
00:18:07,980 --> 00:18:09,539
参考，你不会得到任何其他

439
00:18:09,539 --> 00:18:10,919
信息，你只能得到

440
00:18:10,919 --> 00:18:12,480
有关的信息 最终目标状态

441
00:18:12,480 --> 00:18:15,120
和你得到的只是

442
00:18:15,120 --> 00:18:18,240
你学到的环境模型，你

443
00:18:18,240 --> 00:18:21,059
基本上必须做出决定，但

444
00:18:21,059 --> 00:18:22,799
第二个解决方案当然是，如果你

445
00:18:22,799 --> 00:18:24,600
被允许，你可以尝试学习一种

446
00:18:24,600 --> 00:18:26,100
自豪偏好，这是有意义的，

447
00:18:26,100 --> 00:18:28,620
就像我们的那样 在之前的幻灯片中看到，

448
00:18:28,620 --> 00:18:31,740
其中也包含有关

449
00:18:31,740 --> 00:18:33,960
其他状态的信息，但是如何

450
00:18:33,960 --> 00:18:35,400
正确学习它，因此

451
00:18:35,400 --> 00:18:38,039
最优控制文献中有一篇开创性的工作，

452
00:18:38,039 --> 00:18:40,440
讨论了

453
00:18:40,440 --> 00:18:43,380
最佳动作的有效计算，

454
00:18:43,380 --> 00:18:45,900
并且在该工作中，有一个

455
00:18:45,900 --> 00:18:47,760
类似于我们的数量 先验偏好，

456
00:18:47,760 --> 00:18:49,500
称为意愿函数，

457
00:18:49,500 --> 00:18:52,200
例如，在这个网格世界中，

458
00:18:52,200 --> 00:18:54,240
这里较暗的颜色更受欢迎，

459
00:18:54,240 --> 00:18:56,400
所以如果这跨越了你的最终黄金状态，

460
00:18:56,400 --> 00:18:58,740
本文中的代理正在尝试

461
00:18:58,740 --> 00:19:01,980
做什么，或者本文中的所述学习方法

462
00:19:01,980 --> 00:19:04,580
是 尝试做的就是尽可能

463
00:19:04,580 --> 00:19:06,900
最佳地学习这个意愿函数，

464
00:19:06,900 --> 00:19:09,059
本文已经表明，

465
00:19:09,059 --> 00:19:12,660
如果你尝试

466
00:19:12,660 --> 00:19:15,179
使用特定的

467
00:19:15,179 --> 00:19:18,120
学习规则来学习意愿函数，那么它在计算上

468
00:19:18,120 --> 00:19:20,340
比 Q 学习要高效得多，Q 学习

469
00:19:20,340 --> 00:19:22,919
是一种很好的学习方法。 已知的强化

470
00:19:22,919 --> 00:19:24,960
学习算法，所以 Q 学习是一种

471
00:19:24,960 --> 00:19:27,179
众所周知的计算最优

472
00:19:27,179 --> 00:19:29,520
算法，但在本文中，

473
00:19:29,520 --> 00:19:31,140
学习

474
00:19:31,140 --> 00:19:32,880
这种意愿函数的特定学习规则要

475
00:19:32,880 --> 00:19:35,539
快得多，并且这种近似

476
00:19:35,539 --> 00:19:38,460
表示它与

477
00:19:38,460 --> 00:19:40,559
最优意愿函数有多么不同，所以这

478
00:19:40,559 --> 00:19:42,480
意愿函数只不过是我们的

479
00:19:42,480 --> 00:19:45,179
先验偏好，

480
00:19:45,179 --> 00:19:48,600
正如前面提到的，

481
00:19:48,600 --> 00:19:50,100
学习比

482
00:19:50,100 --> 00:19:53,039
在 Q 学习中学习 Q 函数效率更高，所以

483
00:19:53,039 --> 00:19:55,860
这是特定的学习规则，具体

484
00:19:55,860 --> 00:19:57,600
取决于它

485
00:19:57,600 --> 00:19:59,820
从环境和这个

486
00:19:59,820 --> 00:20:01,860
特定的网格世界环境中获得的奖励 我们

487
00:20:01,860 --> 00:20:03,539
只在最后一步给予它奖励，

488
00:20:03,539 --> 00:20:05,220
这类似于稀疏的朋友

489
00:20:05,220 --> 00:20:08,580
偏好，在达到最终目标状态之前，代理基本上不会获得

490
00:20:08,580 --> 00:20:11,400
奖励，

491
00:20:11,400 --> 00:20:14,760
并且使用这个学习规则，其中

492
00:20:14,760 --> 00:20:17,640
有一个参数 ETA

493
00:20:17,640 --> 00:20:20,100
控制这个速度的快慢

494
00:20:20,100 --> 00:20:22,980
学习发生所以基本上我们

495
00:20:22,980 --> 00:20:24,200
尝试

496
00:20:24,200 --> 00:20:26,880
研究这个学习

497
00:20:26,880 --> 00:20:29,340
参数 Rita 的效果，但我们观察到

498
00:20:29,340 --> 00:20:32,400
它非常强大，

499
00:20:32,400 --> 00:20:35,059
即使

500
00:20:35,059 --> 00:20:38,700
这个呃学习参数的值可变，它也可以可靠地学习先验偏好

501
00:20:38,700 --> 00:20:41,580
，我们看到的是

502
00:20:41,580 --> 00:20:43,620
代理能够

503
00:20:43,620 --> 00:20:45,539
随着时间的推移，要非常快速地学习有意义的先验表现

504
00:20:45,539 --> 00:20:48,600
，并使用如此有意义的 Prime

505
00:20:48,600 --> 00:20:50,700
偏好，那么智能体就不必进行

506
00:20:50,700 --> 00:20:53,580
大量计划，它可以用非常短的规划时间范围来管理最佳

507
00:20:53,580 --> 00:20:56,160
行为或有目的的行为，

508
00:20:56,160 --> 00:20:59,700
并且

509
00:20:59,700 --> 00:21:02,460
考虑到这两种解决方案，我们可以

510
00:21:02,460 --> 00:21:04,679
扩大用于决策的主动推理算法

511
00:21:04,679 --> 00:21:07,919
并讨论

512
00:21:07,919 --> 00:21:11,400
计算效率我们看到

513
00:21:11,400 --> 00:21:13,320
动态规划方法可以将

514
00:21:13,320 --> 00:21:16,440
30 个时间步植入未来，而

515
00:21:16,440 --> 00:21:18,360
计算复杂度仅为 1000，而复杂的计算复杂度

516
00:21:18,360 --> 00:21:21,120
为 10 的

517
00:21:21,120 --> 00:21:23,700
68 次方 推理

518
00:21:23,700 --> 00:21:26,880
和第二种学习先验

519
00:21:26,880 --> 00:21:29,580
偏好的方法，我们称之为主动

520
00:21:29,580 --> 00:21:32,340
推理，它只需要提前计划一个

521
00:21:32,340 --> 00:21:34,740
时间步骤，因此

522
00:21:34,740 --> 00:21:36,919
从这个意义上说，它的计算效率更高，

523
00:21:36,919 --> 00:21:39,659
但它必须学习，所以在 DPFE

524
00:21:39,659 --> 00:21:41,640
方法中我们没有学习 我们

525
00:21:41,640 --> 00:21:43,799
优先使用这些点并进行

526
00:21:43,799 --> 00:21:44,520
整个

527
00:21:44,520 --> 00:21:46,500
深度的规划，在另一种

528
00:21:46,500 --> 00:21:48,240
方法中，我们让智能体

529
00:21:48,240 --> 00:21:50,280
优先学习这一点，但这样我们就可以节省

530
00:21:50,280 --> 00:21:53,280
很多规划，因为它知道很多

531
00:21:53,280 --> 00:21:57,299
要做什么，及时正确，如此

532
00:21:57,299 --> 00:22:00,179
图形化 我们可以看到，嗯，

533
00:22:00,179 --> 00:22:01,799
DPFE 方法确实

534
00:22:01,799 --> 00:22:04,020
计算效率很高，并且当

535
00:22:04,020 --> 00:22:06,600
在 AI 50 中绘制相对于时间的 uh

536
00:22:06,600 --> 00:22:08,520
等于一种方法时，嗯，

537
00:22:08,520 --> 00:22:10,740
它基本上在计算上更

538
00:22:10,740 --> 00:22:12,659
便宜，是的，

539
00:22:12,659 --> 00:22:16,220
所以它的扩展性非常

540
00:22:16,220 --> 00:22:19,860
好，呃，随着越来越

541
00:22:19,860 --> 00:22:21,720
高和

542
00:22:21,720 --> 00:22:24,120
复杂性 所以我们

543
00:22:24,120 --> 00:22:27,600
在

544
00:22:27,600 --> 00:22:28,380


545
00:22:28,380 --> 00:22:31,020
非常巨大的状态空间（比如 900 个

546
00:22:31,020 --> 00:22:32,000
状态）中测试了这些方法，而

547
00:22:32,000 --> 00:22:33,840


548
00:22:33,840 --> 00:22:36,120


549
00:22:36,120 --> 00:22:38,640
在通常看到的积极影响文献中，状态空间的维度为 5 或 10，

550
00:22:38,640 --> 00:22:40,559


551
00:22:40,559 --> 00:22:43,200
所以我想强调一下，

552
00:22:43,200 --> 00:22:44,760
我们是 这里不使用任何神经网络，

553
00:22:44,760 --> 00:22:47,039
我们使用

554
00:22:47,039 --> 00:22:49,740
可解释的主动推理代理

555
00:22:49,740 --> 00:22:52,200
进行所有必要的矩阵

556
00:22:52,200 --> 00:22:53,820
乘法，以便我们可以访问

557
00:22:53,820 --> 00:22:55,140
和

558
00:22:55,140 --> 00:22:56,220


559
00:22:56,220 --> 00:22:58,620
解释

560
00:22:58,620 --> 00:23:00,179
这些算法中发生的每个计算，

561
00:23:00,179 --> 00:23:02,280
并且当首先在这些网格上进行测试时，

562
00:23:02,280 --> 00:23:04,559
我们验证了这一点 在一个

563
00:23:04,559 --> 00:23:06,780
较小的网格上，我们

564
00:23:06,780 --> 00:23:08,580
观察到，与

565
00:23:08,580 --> 00:23:11,220


566
00:23:11,220 --> 00:23:12,780
队列学习

567
00:23:12,780 --> 00:23:15,059
和 dynaq 等基准强化学习算法相比，dynaq 是一种基于模型的

568
00:23:15,059 --> 00:23:17,760
强化学习算法，我们

569
00:23:17,760 --> 00:23:20,280
比较了我们新提出的代理（

570
00:23:20,280 --> 00:23:24,419
DPFE 和 aif），我们看到了非常好的

571
00:23:24,419 --> 00:23:27,900
性能和 aif 代理稍微

572
00:23:27,900 --> 00:23:29,220
差一些，这是因为它只

573
00:23:29,220 --> 00:23:31,080
提前规划一步，但是

574
00:23:31,080 --> 00:23:34,500
进行全职规划的 DPFE 代理的

575
00:23:34,500 --> 00:23:36,419
性能与

576
00:23:36,419 --> 00:23:37,919
基准个人学习

577
00:23:37,919 --> 00:23:41,039
算法一样好，我们使用

578
00:23:41,039 --> 00:23:44,640
更大和更弱的网格对其进行了测试，当我们

579
00:23:44,640 --> 00:23:47,100
在 黄金

580
00:23:47,100 --> 00:23:49,620
状态是指当代理

581
00:23:49,620 --> 00:23:53,039
必须导航到

582
00:23:53,039 --> 00:23:54,480


583
00:23:54,480 --> 00:23:56,520
随机黄金状态时，我们

584
00:23:56,520 --> 00:23:59,460
每 10 集更改一次黄金状态，

585
00:23:59,460 --> 00:24:01,260
我们观察到 Dyna 队列

586
00:24:01,260 --> 00:24:04,140
比我们的 bpfe 代理花费更多时间来

587
00:24:04,140 --> 00:24:07,200
恢复和执行操作 好吧，所以 DPFE

588
00:24:07,200 --> 00:24:09,059
代理在这种随机环境中

589
00:24:09,059 --> 00:24:11,280
表现得非常好，甚至比

590
00:24:11,280 --> 00:24:13,620
动态代理更好，你还可以看到

591
00:24:13,620 --> 00:24:16,500
AI 阶段恢复得

592
00:24:16,500 --> 00:24:19,140
更快，但不如其他代理那么好，

593
00:24:19,140 --> 00:24:22,500
所以基本上这就是

594
00:24:22,500 --> 00:24:25,200
论文和 方法 所以是的，

595
00:24:25,200 --> 00:24:27,960
谢谢你的聆听，我愿意参与

596
00:24:27,960 --> 00:24:30,380
讨论，

597
00:24:31,640 --> 00:24:34,740
好吧，

598
00:24:34,740 --> 00:24:36,360


599
00:24:36,360 --> 00:24:38,520
太棒了，非常酷，

600
00:24:38,520 --> 00:24:43,200
好吧，就在我们开始

601
00:24:43,200 --> 00:24:44,460
讨论的时候，

602
00:24:44,460 --> 00:24:47,280
嗯，如果有人想先添加任何内容，那么

603
00:24:47,280 --> 00:24:50,220
你是如何开始从事这个

604
00:24:50,220 --> 00:24:52,740
项目的，你在学习吗？ 主动

605
00:24:52,740 --> 00:24:54,720
推理，你觉得这个问题

606
00:24:54,720 --> 00:24:57,900
很有趣，或者你正在做

607
00:24:57,900 --> 00:25:00,179
规划，并把主动

608
00:25:00,179 --> 00:25:03,059
推理作为一种方法，

609
00:25:03,059 --> 00:25:05,159
嗯，是的，

610
00:25:05,159 --> 00:25:08,400
我对自己的背景了解很少，所以我在本科时学习了物理，

611
00:25:08,400 --> 00:25:11,340
并在接近

612
00:25:11,340 --> 00:25:13,080
结束时发布了它。 毕业后，我对

613
00:25:13,080 --> 00:25:15,120
博弈论

614
00:25:15,120 --> 00:25:17,880
和可重用学习之类的东西感兴趣，我

615
00:25:17,880 --> 00:25:20,880
与 Adil 教授

616
00:25:20,880 --> 00:25:23,100
和 Manoj 教授联合攻读博士学位，所以

617
00:25:23,100 --> 00:25:25,200
Manoj 教授是一个控制理论专家，而 a

618
00:25:25,200 --> 00:25:28,140
deal 是一名神经科学家，在

619
00:25:28,140 --> 00:25:30,600
我的研究开始时 博士期间，我开始阅读

620
00:25:30,600 --> 00:25:34,020
主动推理文献，我想

621
00:25:34,020 --> 00:25:37,260
在问题中实现这一点，我

622
00:25:37,260 --> 00:25:39,840
总是着迷于可解释的

623
00:25:39,840 --> 00:25:42,720
主动推理，呃关于

624
00:25:42,720 --> 00:25:44,700
预期自由能的想法试图最小化

625
00:25:44,700 --> 00:25:46,860
风险以及预期的模糊性，它

626
00:25:46,860 --> 00:25:49,740
不仅使代理工作，而且

627
00:25:49,740 --> 00:25:52,020
能够告诉我它们是如何工作的，这也是让

628
00:25:52,020 --> 00:25:54,419
我着迷的积极影响力，

629
00:25:54,419 --> 00:25:56,820
最初我尝试实现它们，

630
00:25:56,820 --> 00:26:00,179
我们发表了一篇会议论文，

631
00:26:00,179 --> 00:26:03,720
其中我们将其与

632
00:26:03,720 --> 00:26:06,419
类似的网格任务进行了比较，然后我

633
00:26:06,419 --> 00:26:08,100
遇到了扩展问题 主动

634
00:26:08,100 --> 00:26:10,620
推理，然后我开始研究

635
00:26:10,620 --> 00:26:12,659
复杂的推理，

636
00:26:12,659 --> 00:26:15,539
嗯，是的，所以基本上这些方法是

637
00:26:15,539 --> 00:26:17,580
出于我想要

638
00:26:17,580 --> 00:26:21,539
放大地图的需要，并且我总是

639
00:26:21,539 --> 00:26:22,919
在使用

640
00:26:22,919 --> 00:26:25,559
嗯深主动推理时使用总线保持，因为嗯，

641
00:26:25,559 --> 00:26:28,020
我不想使用

642
00:26:28,020 --> 00:26:30,539
因为深度

643
00:26:30,539 --> 00:26:32,100
强化学习本身就是一个

644
00:26:32,100 --> 00:26:34,140
巨大的领域，

645
00:26:34,140 --> 00:26:37,080
如果你只是想扩展

646
00:26:37,080 --> 00:26:39,240
主动推理，那么也许就做深度

647
00:26:39,240 --> 00:26:41,820
强化学习，这就是我的

648
00:26:41,820 --> 00:26:43,860
想法，是的，这基本上就是

649
00:26:43,860 --> 00:26:45,659
背景，是的，

650
00:26:45,659 --> 00:26:48,720
这就是它的方式

651
00:26:48,720 --> 00:26:50,880
一切顺利，我将首先在实时聊天中提出一个问题

652
00:26:50,880 --> 00:26:52,559
，我们

653
00:26:52,559 --> 00:26:54,779
可能会讨论各个方面，因为

654
00:26:54,779 --> 00:26:57,720
您的演示中有很多内容，因此

655
00:26:57,720 --> 00:27:01,980
NL Dawn 写道，我想知道何时

656
00:27:01,980 --> 00:27:04,620
计算预期自由能

657
00:27:04,620 --> 00:27:07,679
时间范围使用什么样的平均

658
00:27:07,679 --> 00:27:11,039
场近似来分解 s 存储的 Q，

659
00:27:11,039 --> 00:27:13,020


660
00:27:13,020 --> 00:27:16,100


661
00:27:19,980 --> 00:27:23,040
所以我假设问题是关于

662
00:27:23,040 --> 00:27:24,299
[音乐]

663
00:27:24,299 --> 00:27:28,799
DPFE 中的预期自由能并

664
00:27:28,799 --> 00:27:31,380
基本上计算这个，

665
00:27:31,380 --> 00:27:32,159


666
00:27:32,159 --> 00:27:35,279
所以在我的模拟中我使用置信

667
00:27:35,279 --> 00:27:39,120
传播来实现这一点 信念队列，

668
00:27:39,120 --> 00:27:41,460
你也可以使用变分

669
00:27:41,460 --> 00:27:43,140
消息传递或边际消息

670
00:27:43,140 --> 00:27:47,279
传递，这不是问题，

671
00:27:47,400 --> 00:27:50,580
但是一旦你有了这个信念队列，

672
00:27:50,580 --> 00:27:52,740
你会做什么，

673
00:27:52,740 --> 00:27:55,340
所以是的，

674
00:27:56,940 --> 00:27:59,900
所以

675
00:27:59,940 --> 00:28:04,260
当我说你想象一下 Q 时，

676
00:28:04,260 --> 00:28:07,520
我主要使用什么 是一个热门向量，所以

677
00:28:07,520 --> 00:28:11,220
要做出决定，你需要相信

678
00:28:11,220 --> 00:28:13,260
你

679
00:28:13,260 --> 00:28:16,380
在主动推理中摆脱了感知步骤，但想象一下

680
00:28:16,380 --> 00:28:18,720
这些是硬表，它们是一个

681
00:28:18,720 --> 00:28:22,020
热门向量，所以假设你的

682
00:28:22,020 --> 00:28:25,380
生成模型中有 10 个状态，呃你的

683
00:28:25,380 --> 00:28:27,900
您使用的队列是用于

684
00:28:27,900 --> 00:28:29,100


685
00:28:29,100 --> 00:28:32,220
规划的精确提示，但对于

686
00:28:32,220 --> 00:28:33,840
决策，您使用

687
00:28:33,840 --> 00:28:36,299


688
00:28:36,299 --> 00:28:38,460
从感知步骤中获得的令人印象深刻的不精确平均场近似队列，所以

689
00:28:38,460 --> 00:28:40,679
我不知道这是否回答了

690
00:28:40,679 --> 00:28:42,059
问题，

691
00:28:42,059 --> 00:28:44,880
但也许我也想思考 我

692
00:28:44,880 --> 00:28:46,919
还需要更多地考虑

693
00:28:46,919 --> 00:28:49,200


694
00:28:49,200 --> 00:28:50,880
步骤中可能存在的近似值，

695
00:28:50,880 --> 00:28:53,700
很酷，是的，如果他们愿意，他们可以写更多内容，嗯，让我们

696
00:28:53,700 --> 00:28:56,460


697
00:28:56,460 --> 00:29:00,419
更笼统地谈谈偏好学习，

698
00:29:00,419 --> 00:29:02,700
所以在主动推理

699
00:29:02,700 --> 00:29:05,940
生成模型的背景下，我们 在

700
00:29:05,940 --> 00:29:08,279
隐藏状态的观察之间进行调解，

701
00:29:08,279 --> 00:29:10,020
学习

702
00:29:10,020 --> 00:29:12,480
很有意义，它是关于学习世界

703
00:29:12,480 --> 00:29:14,220
隐藏状态中的观察之间的映射，

704
00:29:14,220 --> 00:29:15,779
然后我们通过学习

705
00:29:15,779 --> 00:29:18,240
学习行动的后果

706
00:29:18,240 --> 00:29:20,399
以及事物如何随着时间而变化，

707
00:29:20,399 --> 00:29:21,419


708
00:29:21,419 --> 00:29:24,659
而偏好学习正在学习

709
00:29:24,659 --> 00:29:27,960
cc，你强调这

710
00:29:27,960 --> 00:29:29,700
是一个非常

711
00:29:29,700 --> 00:29:31,340


712
00:29:31,340 --> 00:29:34,320
有趣的变量，

713
00:29:34,320 --> 00:29:38,100
我很好奇我们如何学习

714
00:29:38,100 --> 00:29:41,159
正确的东西，我们如何知道

715
00:29:41,159 --> 00:29:42,960
我们正在学习适应性

716
00:29:42,960 --> 00:29:44,399
偏好

717
00:29:44,399 --> 00:29:46,200
，然后如何 偏好

718
00:29:46,200 --> 00:29:48,720
学习是否会减少认知开销或

719
00:29:48,720 --> 00:29:50,820
计算复杂性是的，

720
00:29:50,820 --> 00:29:53,460
很好，

721
00:29:53,460 --> 00:29:54,480
所以

722
00:29:54,480 --> 00:29:57,179
如果你想学习祈祷

723
00:29:57,179 --> 00:29:59,940
偏好，那么假设

724
00:29:59,940 --> 00:30:01,559
有一些东西可以追逐，或者有

725
00:30:01,559 --> 00:30:04,500
一些东西可以最大化，比如奖励，所以

726
00:30:04,500 --> 00:30:06,779
在强化学习中说呃

727
00:30:06,779 --> 00:30:08,340
设置

728
00:30:08,340 --> 00:30:09,840
来自

729
00:30:09,840 --> 00:30:12,960
您试图最大化的环境的明确奖励，并说对于

730
00:30:12,960 --> 00:30:15,000
这个网格，您仅在最后一步中获得该奖励，这

731
00:30:15,000 --> 00:30:17,220
就是

732
00:30:17,220 --> 00:30:19,020
这使得这个问题变得困难，所以

733
00:30:19,020 --> 00:30:22,500
如果您每次都获得奖励 时间

734
00:30:22,500 --> 00:30:25,140
步那么基本上你知道该怎么做，

735
00:30:25,140 --> 00:30:28,020
我只需要

736
00:30:28,020 --> 00:30:30,419
在每个时间步都追求那个奖励，但在这里你

737
00:30:30,419 --> 00:30:32,880
可能需要提前 15 个时间步

738
00:30:32,880 --> 00:30:36,059
才能获得那个奖励，而这

739
00:30:36,059 --> 00:30:39,659
基本上很难在这里做到，嗯，如果

740
00:30:39,659 --> 00:30:41,520
你正在尝试，因为我正在尝试

741
00:30:41,520 --> 00:30:43,020
学习先验偏好，

742
00:30:43,020 --> 00:30:44,820
嗯，

743
00:30:44,820 --> 00:30:47,940


744
00:30:47,940 --> 00:30:49,919
如果环境不关心

745
00:30:49,919 --> 00:30:52,200
我所做的事情或者我无法定义什么是

746
00:30:52,200 --> 00:30:54,840
好或坏，那么环境中应该存在一个奖励结构 那么

747
00:30:54,840 --> 00:30:56,340
学习先验偏好就没有意义了，所以

748
00:30:56,340 --> 00:30:57,840
这里

749
00:30:57,840 --> 00:30:59,399
奖励是控制

750
00:30:59,399 --> 00:31:01,559
精灵差异学习的东西，

751
00:31:01,559 --> 00:31:03,600
好处是即使我只

752
00:31:03,600 --> 00:31:06,539
在最后一个时间步骤获得奖励，

753
00:31:06,539 --> 00:31:09,240
我也有 B 矩阵 我有

754
00:31:09,240 --> 00:31:11,340
从不同状态过渡的经验，

755
00:31:11,340 --> 00:31:12,659


756
00:31:12,659 --> 00:31:14,760
我达到了最终的黄金状态，

757
00:31:14,760 --> 00:31:16,860


758
00:31:16,860 --> 00:31:19,440
我们正在使用的算法或

759
00:31:19,440 --> 00:31:21,539
我们正在使用的学习规则正是在

760
00:31:21,539 --> 00:31:23,820


761
00:31:23,820 --> 00:31:26,340
我介绍的论文中学习最优控制中类似的东西，

762
00:31:26,340 --> 00:31:27,539
称为合意性

763
00:31:27,539 --> 00:31:30,539
函数 考虑到你有这个

764
00:31:30,539 --> 00:31:32,760
愿望函数，所以想象一下，

765
00:31:32,760 --> 00:31:36,120
也许我从这个州开始，那么

766
00:31:36,120 --> 00:31:37,860
我只需要看看我最近的

767
00:31:37,860 --> 00:31:40,399
邻居就可以做出决定，

768
00:31:40,399 --> 00:31:44,279
如果

769
00:31:44,279 --> 00:31:46,620
该州下面的州

770
00:31:46,620 --> 00:31:48,899
比我只需要计划一个州更受欢迎

771
00:31:48,899 --> 00:31:50,520
时间而不是提前，这是

772
00:31:50,520 --> 00:31:52,380
我必须做出的最佳决定，

773
00:31:52,380 --> 00:31:54,059
因此学习这种骄傲偏好会

774
00:31:54,059 --> 00:31:55,919
减少认知负担，

775
00:31:55,919 --> 00:31:57,419
因为我现在只关注最近的

776
00:31:57,419 --> 00:31:59,760
邻居，我不必一直计划

777
00:31:59,760 --> 00:32:01,799
到最终的良好状态

778
00:32:01,799 --> 00:32:04,799
我会尽可能有效地学习这一点，

779
00:32:04,799 --> 00:32:07,260
因为它是一种

780
00:32:07,260 --> 00:32:09,659
有保证的算法，我们测试了它的

781
00:32:09,659 --> 00:32:13,320
鲁棒性，它也通过

782
00:32:13,320 --> 00:32:14,580
我从环境中获得的奖励来告知，

783
00:32:14,580 --> 00:32:15,659


784
00:32:15,659 --> 00:32:20,100
如果是的话，如果有某种方式可以

785
00:32:20,100 --> 00:32:22,860
定义 首选什么呃那么

786
00:32:22,860 --> 00:32:24,840
你一定会通过这个算法学习到一个

787
00:32:24,840 --> 00:32:26,520
有意义的私人朋友，

788
00:32:26,520 --> 00:32:28,559


789
00:32:28,559 --> 00:32:31,559
所以如果只使用最近邻

790
00:32:31,559 --> 00:32:34,260
和一次推理，

791
00:32:34,260 --> 00:32:37,320
那么什么可以防止这种

792
00:32:37,320 --> 00:32:39,360
偏好学习代理

793
00:32:39,360 --> 00:32:43,158
陷入本地最优状态，

794
00:32:43,320 --> 00:32:47,520
嗯，所以 这里不会有本地 Optima，

795
00:32:47,520 --> 00:32:50,340
这就是问题所在，

796
00:32:50,340 --> 00:32:52,860
嗯，为什么会有本地 Optima 呃，

797
00:32:52,860 --> 00:32:57,059
如果我使用奖励来学习它，

798
00:32:57,059 --> 00:33:00,120
呃，是的，所以如果有本地 Optima，那么

799
00:33:00,120 --> 00:33:02,159
它会卡在本地

800
00:33:02,159 --> 00:33:05,460
Optima 中，但赢了 如果

801
00:33:05,460 --> 00:33:07,440
你以这种方式学习，那么就不是一个，因为

802
00:33:07,440 --> 00:33:08,760
你是从自己的

803
00:33:08,760 --> 00:33:11,940
经验以及你如何在

804
00:33:11,940 --> 00:33:14,220
某个时候获得奖励来学习的，我们

805
00:33:14,220 --> 00:33:16,980
观察到，这是非常

806
00:33:16,980 --> 00:33:17,760


807
00:33:17,760 --> 00:33:20,399
渐进的，没有任何问题 或者

808
00:33:20,399 --> 00:33:23,880
当你学习时，

809
00:33:23,880 --> 00:33:27,840
它是一种回填

810
00:33:27,840 --> 00:33:30,179
偏好，

811
00:33:30,179 --> 00:33:33,539
这样就可以有一条

812
00:33:33,539 --> 00:33:36,779
通往远端目标的平滑路径是的，

813
00:33:36,779 --> 00:33:39,480
所以它在动画中

814
00:33:39,480 --> 00:33:42,299
看起来像是一种后退的感觉，但

815
00:33:42,299 --> 00:33:44,279
嗯，你实际上是 从你的经验中学习，

816
00:33:44,279 --> 00:33:45,360


817
00:33:45,360 --> 00:33:46,620


818
00:33:46,620 --> 00:33:49,980
嗯，及时前进，所以

819
00:33:49,980 --> 00:33:51,480
当我从这个

820
00:33:51,480 --> 00:33:53,100
状态过渡到这个状态时，我观察到了奖励，所以这一定很好，

821
00:33:53,100 --> 00:33:55,860
呃，然后在下一个时间步骤中，

822
00:33:55,860 --> 00:33:58,559
我说好吧，这个日期负责

823
00:33:58,559 --> 00:34:00,419
带我去那里 所以这可能

824
00:34:00,419 --> 00:34:03,120
也不错，但不如另一个好，

825
00:34:03,120 --> 00:34:05,100
所以它看起来像是向后学习，

826
00:34:05,100 --> 00:34:07,799
但实际上是从真实的

827
00:34:07,799 --> 00:34:12,000
嗯学习到加一种体验

828
00:34:13,500 --> 00:34:15,119
好吧，

829
00:34:15,119 --> 00:34:16,980
你知道，这样

830
00:34:16,980 --> 00:34:20,339
你就不能拥有本地马克西玛斯，因为

831
00:34:20,339 --> 00:34:21,300
嗯，

832
00:34:21,300 --> 00:34:24,119
是的，这就是这样做的学习规则，

833
00:34:24,119 --> 00:34:25,859
所以我不知道如何

834
00:34:25,859 --> 00:34:29,219
更系统地回答它是的，是的，嗯，

835
00:34:29,219 --> 00:34:33,000
现实世界的情况或

836
00:34:33,000 --> 00:34:35,399
现实生活中的情况是什么，你

837
00:34:35,399 --> 00:34:37,560
看到这种偏好学习

838
00:34:37,560 --> 00:34:40,080
发生在

839
00:34:40,080 --> 00:34:41,159
是的，

840
00:34:41,159 --> 00:34:43,020
太棒了 问题

841
00:34:43,020 --> 00:34:46,080
所以，我们实验室发表了一篇论文，

842
00:34:46,080 --> 00:34:48,659
其中神经元正在

843
00:34:48,659 --> 00:34:51,359
学习乒乓球游戏，

844
00:34:51,359 --> 00:34:52,980
所以如果这篇论文被

845
00:34:52,980 --> 00:34:55,260
称为“dist Brain”呃，该设备被

846
00:34:55,260 --> 00:34:57,000
称为“应变”，那么他们所

847
00:34:57,000 --> 00:34:58,740
取得的成就就是他们管理 在

848
00:34:58,740 --> 00:35:00,300


849
00:35:00,300 --> 00:35:03,420
硅芯片上培养神经元，

850
00:35:03,420 --> 00:35:04,020


851
00:35:04,020 --> 00:35:08,520
当它成功接球或打得很好时，他们给它一个很好的反馈信号，

852
00:35:08,520 --> 00:35:11,400


853
00:35:11,400 --> 00:35:13,880


854
00:35:13,880 --> 00:35:15,720
当

855
00:35:15,720 --> 00:35:18,119
它犯错误时，他们给它一个震惊，我们

856
00:35:18,119 --> 00:35:19,560


857
00:35:19,560 --> 00:35:22,260
在论文中看到的是我们 看到的是，

858
00:35:22,260 --> 00:35:24,140
随着时间的推移，它学会了玩游戏，

859
00:35:24,140 --> 00:35:27,359
在这种情况下，想象一下，

860
00:35:27,359 --> 00:35:29,880
如果我遇到说世界上积极的事情，

861
00:35:29,880 --> 00:35:33,359
那么我可能会将

862
00:35:33,359 --> 00:35:35,520
嗯，什么是好的与我

863
00:35:35,520 --> 00:35:37,380
过去观察到的状态等等联系起来，对吧 所以

864
00:35:37,380 --> 00:35:38,880
我

865
00:35:38,880 --> 00:35:39,660


866
00:35:39,660 --> 00:35:42,119
一步一步地了解到什么是好什么是坏，

867
00:35:42,119 --> 00:35:44,700
这是一个合理的假设，

868
00:35:44,700 --> 00:35:46,619
所以如果

869
00:35:46,619 --> 00:35:47,220
嗯，如果

870
00:35:47,220 --> 00:35:51,300
我想说变得更健康，那么我可能会将

871
00:35:51,300 --> 00:35:53,280
去健身房

872
00:35:53,280 --> 00:35:54,660


873
00:35:54,660 --> 00:35:57,000
视为一件好事，那么我也可能会将

874
00:35:57,000 --> 00:35:59,099
步行去健身房联系起来 作为一件

875
00:35:59,099 --> 00:36:01,260
好事，那么我可能会将

876
00:36:01,260 --> 00:36:03,900
穿鞋视为一件好事，所以嗯，以这种

877
00:36:03,900 --> 00:36:04,920


878
00:36:04,920 --> 00:36:06,960
方式学习先验偏好是

879
00:36:06,960 --> 00:36:10,079
有道理的，我会说，但是，是的，这是

880
00:36:10,079 --> 00:36:11,640


881
00:36:11,640 --> 00:36:12,480


882
00:36:12,480 --> 00:36:14,820
解决

883
00:36:14,820 --> 00:36:17,040
维数诅咒问题的计算嗯解决方案，但要在真实的环境中进行测试

884
00:36:17,040 --> 00:36:19,619
世界绝对是我们

885
00:36:19,619 --> 00:36:21,599
应该做的，

886
00:36:21,599 --> 00:36:24,119
嗯，是的，我也期待这样做，

887
00:36:24,119 --> 00:36:25,800


888
00:36:25,800 --> 00:36:27,660
好吧，让我尝试由你来运行一个真实

889
00:36:27,660 --> 00:36:29,760
世界的情况，看看

890
00:36:29,760 --> 00:36:32,040
这是否连接起来，

891
00:36:32,040 --> 00:36:35,099
所以我们想要我们想要上交我们'

892
00:36:35,099 --> 00:36:38,280
通过提交一篇获得高分的论文来获得奖励，

893
00:36:38,280 --> 00:36:39,900


894
00:36:39,900 --> 00:36:42,599
因此在

895
00:36:42,599 --> 00:36:45,540
开始论文的想法和

896
00:36:45,540 --> 00:36:48,839
看到首选的稀疏结果（即

897
00:36:48,839 --> 00:36:51,180


898
00:36:51,180 --> 00:36:53,520
分数）之间有很多步骤，我们做了各种各样的事情，

899
00:36:53,520 --> 00:36:55,260
然后我们学得很好

900
00:36:55,260 --> 00:36:57,079
嗯 这一次我确实得到了很好的成绩，

901
00:36:57,079 --> 00:36:59,940
它的格式很好，

902
00:36:59,940 --> 00:37:02,880
然后就是这样，现在你可以

903
00:37:02,880 --> 00:37:05,460
扩展你的偏好范围，然后是

904
00:37:05,460 --> 00:37:07,800
什么让我得到

905
00:37:07,800 --> 00:37:10,140
很好的格式，我按时完成了，

906
00:37:10,140 --> 00:37:12,900
然后你就工作了 一直到

907
00:37:12,900 --> 00:37:16,579
构思阶段，这样将来

908
00:37:16,579 --> 00:37:20,640
您就可以准确地进行一步推理，并将

909
00:37:20,640 --> 00:37:23,099
其作为一项技能一步一步地进行，

910
00:37:23,099 --> 00:37:24,180


911
00:37:24,180 --> 00:37:26,400
而不需要

912
00:37:26,400 --> 00:37:28,740


913
00:37:28,740 --> 00:37:31,740
对所有可能的树

914
00:37:31,740 --> 00:37:35,180
结构进行 15 个时间步的推理，这样您就可以 有点用你的

915
00:37:35,180 --> 00:37:39,240
具体学习来简化

916
00:37:39,240 --> 00:37:43,680
问题的结构，是的，

917
00:37:43,680 --> 00:37:45,540
我们可以再次看看所有这些的计算

918
00:37:45,540 --> 00:37:47,220
复杂性

919
00:37:47,220 --> 00:37:51,078
吗？

920
00:37:51,359 --> 00:37:54,300
所以这里 CIF 代表经典的

921
00:37:54,300 --> 00:37:56,760
主动推理，并进行全面的

922
00:37:56,760 --> 00:37:58,560
规划，嗯，

923
00:37:58,560 --> 00:38:00,660
它是围绕的 10 的 18 次方。所以

924
00:38:00,660 --> 00:38:03,180
这是这个特定的网格示例，

925
00:38:03,180 --> 00:38:07,140
有 100 个状态和四个可用

926
00:38:07,140 --> 00:38:09,960
操作，所以这是一个特殊情况，

927
00:38:09,960 --> 00:38:12,119
我只是想用数字来正确地看待

928
00:38:12,119 --> 00:38:14,400
事物，所以对于这个

929
00:38:14,400 --> 00:38:16,500
特定的示例，如果您想

930
00:38:16,500 --> 00:38:18,960
用策略空间来做这件事，

931
00:38:18,960 --> 00:38:20,640
嗯，你将必须进行

932
00:38:20,640 --> 00:38:22,440
10 的 18 次方计算，以进行

933
00:38:22,440 --> 00:38:25,380
一步规划，或者在

934
00:38:25,380 --> 00:38:28,380
复杂推理的一个实例中，

935
00:38:28,380 --> 00:38:30,900
情况更糟，因为呃，你去

936
00:38:30,900 --> 00:38:34,560
状态空间也很重要，呃，那

937
00:38:34,560 --> 00:38:37,140
赢了 不起作用，所以第三行

938
00:38:37,140 --> 00:38:39,540
应该表明，即使有一段

939
00:38:39,540 --> 00:38:40,500
时间

940
00:38:40,500 --> 00:38:42,599
或者上升足够多的时间，

941
00:38:42,599 --> 00:38:44,280
如果你

942
00:38:44,280 --> 00:38:47,400
必须进行完整的规划，那么也很难进行复杂的推理，但是

943
00:38:47,400 --> 00:38:48,960
当你向后规划时，使用动态编程

944
00:38:48,960 --> 00:38:50,579


945
00:38:50,579 --> 00:38:52,500
嗯你 可以尝试进行完整的

946
00:38:52,500 --> 00:38:54,420
规划，

947
00:38:54,420 --> 00:38:56,520
嗯，这只有一千次

948
00:38:56,520 --> 00:38:58,800
计算，但随着学习

949
00:38:58,800 --> 00:39:01,380
偏好，它甚至很低呃，当你只做

950
00:39:01,380 --> 00:39:04,520
一次时一步一步哇，

951
00:39:04,520 --> 00:39:06,440
这相当

952
00:39:06,440 --> 00:39:06,839
[音乐]

953
00:39:06,839 --> 00:39:08,220
嗯

954
00:39:08,220 --> 00:39:12,000
相当斯塔克，并且在分支时间

955
00:39:12,000 --> 00:39:15,480
主动推理 在之前的

956
00:39:15,480 --> 00:39:17,640
模型流中，我们还看到了一些

957
00:39:17,640 --> 00:39:19,859
计算复杂性估计，但我

958
00:39:19,859 --> 00:39:22,260
认为这些非常清楚，嗯，

959
00:39:22,260 --> 00:39:25,020
它让我想到的第一件事是，

960
00:39:25,020 --> 00:39:28,820
没有人说复杂性很便宜，

961
00:39:28,820 --> 00:39:32,940
我的意思是，它的成本是天文数字，嗯，

962
00:39:32,940 --> 00:39:35,099


963
00:39:35,099 --> 00:39:37,380
甚至可能只在 两个或三个或

964
00:39:37,380 --> 00:39:38,880
四个或五个

965
00:39:38,880 --> 00:39:41,940
可能开始达到，所以

966
00:39:41,940 --> 00:39:44,040
它从根本上增加了规划的复杂性，

967
00:39:44,040 --> 00:39:45,720


968
00:39:45,720 --> 00:39:50,040
所以从教学上来说这是非常

969
00:39:50,040 --> 00:39:50,780


970
00:39:50,780 --> 00:39:52,460
有趣的，因为

971
00:39:52,460 --> 00:39:56,280
我们像

972
00:39:56,280 --> 00:39:57,660
我们想象的

973
00:39:57,660 --> 00:39:59,940
主动推理智能

974
00:39:59,940 --> 00:40:01,560
架构一样思考，

975
00:40:01,560 --> 00:40:04,500


976
00:40:04,500 --> 00:40:07,079
但这很清楚地表明它不是

977
00:40:07,079 --> 00:40:09,060
你可以列举一些东西

978
00:40:09,060 --> 00:40:10,859


979
00:40:10,859 --> 00:40:13,380
，所以我认为

980
00:40:13,380 --> 00:40:15,240


981
00:40:15,240 --> 00:40:19,520
通过将其与减少

982
00:40:19,520 --> 00:40:22,140
计算复杂性的原则方法联系起来，

983
00:40:22,140 --> 00:40:25,440
而不是

984
00:40:25,440 --> 00:40:29,220
潜在有效但临时的

985
00:40:29,220 --> 00:40:31,320
复杂性减少方法（例如可能有效的神经

986
00:40:31,320 --> 00:40:33,359
网络），你所做的事情非常非常有创意且重要 当它们起作用时，

987
00:40:33,359 --> 00:40:35,280
但是一旦它们开始变得臃肿，

988
00:40:35,280 --> 00:40:38,940
现在你就没有原则，没有

989
00:40:38,940 --> 00:40:40,680
功效了，是的，

990
00:40:40,680 --> 00:40:43,200
还有复杂的推理，

991
00:40:43,200 --> 00:40:45,240
我必须指出，与动态编程相比，它有它自己的好处，

992
00:40:45,240 --> 00:40:47,579
呃，

993
00:40:47,579 --> 00:40:49,500
从某种意义上说，当你向前规划时，

994
00:40:49,500 --> 00:40:51,839
你是 考虑到

995
00:40:51,839 --> 00:40:53,520
所有的可能性，

996
00:40:53,520 --> 00:40:55,859
但是当你向后规划时，

997
00:40:55,859 --> 00:40:58,380
例如，这就像基于提示的

998
00:40:58,380 --> 00:41:00,300
探索，

999
00:41:00,300 --> 00:41:02,280
嗯，就像如果你必须去某个地方

1000
00:41:02,280 --> 00:41:03,839
排队，然后导航到池

1001
00:41:03,839 --> 00:41:05,640
状态，那么向后规划可能

1002
00:41:05,640 --> 00:41:06,960
不起作用，所以这就是什么 这是

1003
00:41:06,960 --> 00:41:09,900
我得到的一个反馈，我和一些人讨论了这项

1004
00:41:09,900 --> 00:41:10,980
工作，

1005
00:41:10,980 --> 00:41:13,920
所以

1006
00:41:13,920 --> 00:41:16,260
这是关于动态编程的一个值得注意的事情，

1007
00:41:16,260 --> 00:41:18,359
但是

1008
00:41:18,359 --> 00:41:19,920
你在朋友之前学习的另一个地方我相信

1009
00:41:19,920 --> 00:41:22,320
这不是问题，但是动态

1010
00:41:22,320 --> 00:41:23,700
编程的计算成本很低，但是

1011
00:41:23,700 --> 00:41:26,460
它也有其自身的局限性，我

1012
00:41:26,460 --> 00:41:28,099
必须在这里指出，

1013
00:41:28,099 --> 00:41:31,200
只是为了重申一下，在具有

1014
00:41:31,200 --> 00:41:33,839
贝尔曼最优性的动态规划中，

1015
00:41:33,839 --> 00:41:36,420
我们正在向后求解，所以这

1016
00:41:36,420 --> 00:41:38,400
有点像“将死”就是我们想要的，

1017
00:41:38,400 --> 00:41:40,440
所以现在我们正在向后工作到

1018
00:41:40,440 --> 00:41:43,440
现在 但我们最终没有探索

1019
00:41:43,440 --> 00:41:46,440
反事实的

1020
00:41:46,440 --> 00:41:49,200
终点，我们不会回到

1021
00:41:49,200 --> 00:41:51,540
现在的终点，我们完全不

1022
00:41:51,540 --> 00:41:52,980
感兴趣，

1023
00:41:52,980 --> 00:41:55,619
这就是为什么它如此无情，

1024
00:41:55,619 --> 00:41:58,320
但另一方面，这是一个更加

1025
00:41:58,320 --> 00:42:00,420
受限的

1026
00:42:00,420 --> 00:42:02,280
嗯

1027
00:42:02,280 --> 00:42:06,960
搜索，是的，是的 所以我

1028
00:42:06,960 --> 00:42:08,460
这些天在想的是，我们还应该

1029
00:42:08,460 --> 00:42:11,700
考虑这两个的组合，

1030
00:42:11,700 --> 00:42:14,160
我可以忽略

1031
00:42:14,160 --> 00:42:17,400
这些反事实的事情，

1032
00:42:17,400 --> 00:42:19,680
我可以做动态编程，

1033
00:42:19,680 --> 00:42:23,040
也许我可以做两个步骤

1034
00:42:23,040 --> 00:42:25,380
因此，如果这是基于队列的

1035
00:42:25,380 --> 00:42:28,980
探索，那么说到达队列是

1036
00:42:28,980 --> 00:42:32,220
一项任务，从队列到奖励是

1037
00:42:32,220 --> 00:42:34,619
另一项任务，所以我可以将这

1038
00:42:34,619 --> 00:42:37,460
两个任务分开并为它们使用动态编程，

1039
00:42:37,460 --> 00:42:40,440
这在计算上更便宜，但

1040
00:42:40,440 --> 00:42:43,079
也保留了这种想法 嗯，

1041
00:42:43,079 --> 00:42:45,480
必须这样做，是的，但这些都是

1042
00:42:45,480 --> 00:42:48,119
未来的事情，我正在考虑

1043
00:42:48,119 --> 00:42:50,700
很酷，或者从亚历克斯写的聊天中问另一个问题，

1044
00:42:50,700 --> 00:42:54,359


1045
00:42:54,359 --> 00:42:57,599
你对嵌套模型有想法或发展吗，

1046
00:42:57,599 --> 00:43:00,180
其中不同的尺度

1047
00:43:00,180 --> 00:43:02,330
可能有不同的

1048
00:43:02,330 --> 00:43:02,640
[音乐]

1049
00:43:02,640 --> 00:43:03,780
嗯，

1050
00:43:03,780 --> 00:43:06,540
领先一步， 执行速度

1051
00:43:06,540 --> 00:43:07,800


1052
00:43:07,800 --> 00:43:09,960
那么这个模型在嵌套模型中如何发挥作用

1053
00:43:09,960 --> 00:43:11,579


1054
00:43:11,579 --> 00:43:13,859
以及我们如何

1055
00:43:13,859 --> 00:43:16,380
在

1056
00:43:16,380 --> 00:43:19,500
执行速度和嵌套模型中及时考虑这个向前和向后的问题

1057
00:43:19,500 --> 00:43:21,780
好吧，所以我可能需要更多的

1058
00:43:21,780 --> 00:43:23,760
上下文，就像

1059
00:43:23,760 --> 00:43:26,220
嗯，当你说嵌套时 模型，嗯，你的

1060
00:43:26,220 --> 00:43:28,440
意思是层次模型是的，是的，

1061
00:43:28,440 --> 00:43:30,780
所以也许

1062
00:43:30,780 --> 00:43:34,619
嗯，

1063
00:43:34,619 --> 00:43:38,760
我快速进行了一次观察，我对此做了一些

1064
00:43:38,760 --> 00:43:41,160
推论，但然后我用这个

1065
00:43:41,160 --> 00:43:45,180
推论呃来做

1066
00:43:45,180 --> 00:43:48,000
或者也许呃，基本上就是这个

1067
00:43:48,000 --> 00:43:49,500
推论 成为

1068
00:43:49,500 --> 00:43:52,800
下一个状态的观察，这就是嵌套

1069
00:43:52,800 --> 00:43:55,980
模型的含义，是的，所以我可能必须

1070
00:43:55,980 --> 00:43:58,140
从任务的角度实际考虑这一点，

1071
00:43:58,140 --> 00:44:00,300
然后考虑它，但

1072
00:44:00,300 --> 00:44:02,339
老实说，我还没有

1073
00:44:02,339 --> 00:44:04,800
想过这在这种情况下如何工作，

1074
00:44:04,800 --> 00:44:08,760
但是 比如说一个任务，

1075
00:44:08,760 --> 00:44:10,319


1076
00:44:10,319 --> 00:44:13,140
嗯，所以在导航方面，如果你

1077
00:44:13,140 --> 00:44:15,119
考虑一下，你可以考虑一下

1078
00:44:15,119 --> 00:44:15,900


1079
00:44:15,900 --> 00:44:19,800
房间环境，这就是

1080
00:44:19,800 --> 00:44:21,480
其中一个例子，我可以

1081
00:44:21,480 --> 00:44:24,000
考虑我们可以在哪里应用这个，所以想象一下，

1082
00:44:24,000 --> 00:44:27,720
也许你有一个集合 作为

1083
00:44:27,720 --> 00:44:30,300
一个代理人，你必须首先弄清楚

1084
00:44:30,300 --> 00:44:32,460
要去哪个房间，然后你必须

1085
00:44:32,460 --> 00:44:35,760
在那个房子里导航，基本上

1086
00:44:35,760 --> 00:44:39,060
你可以在两个阶段进行推理或

1087
00:44:39,060 --> 00:44:41,940
在两个阶段做出决策，然后

1088
00:44:41,940 --> 00:44:43,140
你就必须分开 你

1089
00:44:43,140 --> 00:44:45,240
在房间内这些阶段的决定

1090
00:44:45,240 --> 00:44:47,460
你可以说动态

1091
00:44:47,460 --> 00:44:49,740
编程来导航你的最佳呃

1092
00:44:49,740 --> 00:44:52,980
路径，但你总是必须

1093
00:44:52,980 --> 00:44:54,960
有两个阶段的

1094
00:44:54,960 --> 00:44:57,300
嗯决策，嗯

1095
00:44:57,300 --> 00:45:00,420
也许不同的方法在

1096
00:45:00,420 --> 00:45:04,260
不同的阶段效果更好，但这将是 呃，

1097
00:45:04,260 --> 00:45:06,180
你知道更好，我的意思是，这个

1098
00:45:06,180 --> 00:45:08,460
讨论会更好，嗯，

1099
00:45:08,460 --> 00:45:09,420


1100
00:45:09,420 --> 00:45:12,060
在一个经过

1101
00:45:12,060 --> 00:45:14,400
深思熟虑的任务中更好，我想说，我

1102
00:45:14,400 --> 00:45:18,240
没有一个可能适合

1103
00:45:18,240 --> 00:45:19,740
所有事情的答案，但是

1104
00:45:19,740 --> 00:45:21,119
是

1105
00:45:21,119 --> 00:45:24,359
的，我们已经看到了几乎完全一样的那种

1106
00:45:24,359 --> 00:45:27,300


1107
00:45:27,300 --> 00:45:30,180
在机器人技术案例中，分层同步定位和映射 Slam

1108
00:45:30,180 --> 00:45:32,040
已经有了主动

1109
00:45:32,040 --> 00:45:33,900
推理模型，

1110
00:45:33,900 --> 00:45:37,140
嗯，是的，是否可以

1111
00:45:37,140 --> 00:45:39,500


1112
00:45:40,079 --> 00:45:42,660


1113
00:45:42,660 --> 00:45:45,420
在嵌套模型的一个级别上对其中一种方法进行排序，

1114
00:45:45,420 --> 00:45:48,359
然后将另一种计算方法

1115
00:45:48,359 --> 00:45:50,280
应用于另一个

1116
00:45:50,280 --> 00:45:51,960
嗯 或者就像如果你想要

1117
00:45:51,960 --> 00:45:54,480
一处一处的优势，比如

1118
00:45:54,480 --> 00:45:56,579
你可以在一次模拟中混合和匹配这些不同的

1119
00:45:56,579 --> 00:46:00,180
方法是的我我我

1120
00:46:00,180 --> 00:46:03,540
绝对认为这是

1121
00:46:03,540 --> 00:46:04,859
可能的

1122
00:46:04,859 --> 00:46:09,140
嗯但是是的我们可能必须尝试

1123
00:46:09,180 --> 00:46:12,119
所以我所有的方法都是嗯一种 所以

1124
00:46:12,119 --> 00:46:14,819
它不是一个分层模型

1125
00:46:14,819 --> 00:46:17,220
，但我坚信它

1126
00:46:17,220 --> 00:46:19,260
也适用于房地产模型，在这种模型中，

1127
00:46:19,260 --> 00:46:20,520
您可以让

1128
00:46:20,520 --> 00:46:22,200
两种决策方法

1129
00:46:22,200 --> 00:46:24,660
一起工作，例如

1130
00:46:24,660 --> 00:46:26,940
我刚才提到的房间示例哦，

1131
00:46:26,940 --> 00:46:29,280
您可以转到幻灯片吗 Z

1132
00:46:29,280 --> 00:46:31,819
学习

1133
00:46:35,640 --> 00:46:38,760
很酷，是的，所以我注意到，嗯，在这篇

1134
00:46:38,760 --> 00:46:41,220
伟大的论文中，您总共被引用了好几次，

1135
00:46:41,220 --> 00:46:45,240
是的，所以

1136
00:46:45,240 --> 00:46:48,060
Z 学习的介绍

1137
00:46:48,060 --> 00:46:49,859
对于主动

1138
00:46:49,859 --> 00:46:52,260
推理领域来说是一个新颖的东西，所以您能再解释一下

1139
00:46:52,260 --> 00:46:53,760


1140
00:46:53,760 --> 00:46:55,920
什么吗？  Z 是

1141
00:46:55,920 --> 00:47:00,660
什么，是什么使得

1142
00:47:00,660 --> 00:47:02,280


1143
00:47:02,280 --> 00:47:03,240


1144
00:47:03,240 --> 00:47:06,119
Z 相对于 Q 能够如此快速地改进 是的，

1145
00:47:06,119 --> 00:47:06,900


1146
00:47:06,900 --> 00:47:10,619
所以呃，给一些关于

1147
00:47:10,619 --> 00:47:13,079
这篇论文的背景，

1148
00:47:13,079 --> 00:47:13,920
嗯，

1149
00:47:13,920 --> 00:47:16,260
它谈论的是

1150
00:47:16,260 --> 00:47:19,800
在特定情况下的线性决策方法。

1151
00:47:19,800 --> 00:47:21,720
mdp 类，因此考虑到

1152
00:47:21,720 --> 00:47:23,940
您正在进行马尔可夫决策过程，

1153
00:47:23,940 --> 00:47:27,240
其中您的行动可以基于

1154
00:47:27,240 --> 00:47:29,220
状态而不是重音，因此当您

1155
00:47:29,220 --> 00:47:31,560
考虑例如网格任务中的行动时，

1156
00:47:31,560 --> 00:47:32,760


1157
00:47:32,760 --> 00:47:35,160
您会考虑左右和

1158
00:47:35,160 --> 00:47:37,200
嗯北南右，所以 如果我取

1159
00:47:37,200 --> 00:47:40,200
北，那么这会对

1160
00:47:40,200 --> 00:47:42,720
状态空间产生呃后果，但是在本文中，

1161
00:47:42,720 --> 00:47:43,680


1162
00:47:43,680 --> 00:47:46,380
嗯，他们引入了一类 mdp，

1163
00:47:46,380 --> 00:47:48,839
其中决策本身就是状态，

1164
00:47:48,839 --> 00:47:49,920


1165
00:47:49,920 --> 00:47:54,180
所以如果我说的是状态 S1，我的决策

1166
00:47:54,180 --> 00:47:56,280
将是呃

1167
00:47:56,280 --> 00:47:58,740
取决于 取决于另一个状态，所以我的

1168
00:47:58,740 --> 00:48:00,000
决定将基于

1169
00:48:00,000 --> 00:48:02,160
我下次想要进入的其他状态，所以

1170
00:48:02,160 --> 00:48:04,020
呃，

1171
00:48:04,020 --> 00:48:05,880
这是一个真正的决策定义，呃，

1172
00:48:05,880 --> 00:48:08,640
根据状态空间

1173
00:48:08,640 --> 00:48:10,800
而不是

1174
00:48:10,800 --> 00:48:13,619
像左、右、下、上这样的决策

1175
00:48:13,619 --> 00:48:15,300
因此，鉴于

1176
00:48:15,300 --> 00:48:17,819
存在这样的 mdp，我可以

1177
00:48:17,819 --> 00:48:21,319
根据状态做出决策，

1178
00:48:21,319 --> 00:48:23,520
他们已经表明，通过计算，

1179
00:48:23,520 --> 00:48:27,000
您可以以线性复杂度做出呃决策，

1180
00:48:27,000 --> 00:48:30,900
无论问题有多大，

1181
00:48:30,900 --> 00:48:33,480
以便能够根据

1182
00:48:33,480 --> 00:48:35,339
您应该

1183
00:48:35,339 --> 00:48:38,579
拥有的状态做出决策 对各州有利和不利的感觉，

1184
00:48:38,579 --> 00:48:39,540


1185
00:48:39,540 --> 00:48:43,619
所以在这个 gridward 示例中，您有

1186
00:48:43,619 --> 00:48:46,440
一个合意性函数，即 C，所以 C

1187
00:48:46,440 --> 00:48:48,240
是合意性函数，

1188
00:48:48,240 --> 00:48:50,700
它讨论一个州的合意程度

1189
00:48:50,700 --> 00:48:54,180
，如果我有一个 c 函数，那么

1190
00:48:54,180 --> 00:48:56,579
它们所显示的内容 是，

1191
00:48:56,579 --> 00:48:57,359
嗯，

1192
00:48:57,359 --> 00:48:59,280
我可以针对

1193
00:48:59,280 --> 00:49:01,079
这一

1194
00:49:01,079 --> 00:49:03,540
特定类别的 mdp 以线性计算复杂度做出决策，因此，如果我的 mdp

1195
00:49:03,540 --> 00:49:05,640
允许我根据状态做出决策，那么它

1196
00:49:05,640 --> 00:49:08,940
是线性的，呃，这只是

1197
00:49:08,940 --> 00:49:11,700
该事物的线性复杂度，

1198
00:49:11,700 --> 00:49:15,240
所以这张图基本上是比较如何

1199
00:49:15,240 --> 00:49:19,260
学习意愿呃更好

1200
00:49:19,260 --> 00:49:22,200
或更快，所以Q学习如果你

1201
00:49:22,200 --> 00:49:23,880
熟悉Q学习，它基本上是

1202
00:49:23,880 --> 00:49:28,319
一个基于表格的方法呃，你有给定

1203
00:49:28,319 --> 00:49:30,780
一个状态的行动的意愿，

1204
00:49:30,780 --> 00:49:33,000
所以给定一个状态你知道该怎么做，

1205
00:49:33,000 --> 00:49:35,760
这基本上是队列矩阵，但在

1206
00:49:35,760 --> 00:49:37,020
就 C

1207
00:49:37,020 --> 00:49:40,380
uh 或 C 学习方法而言，它只与

1208
00:49:40,380 --> 00:49:43,020
状态 uh 有关，你只是学习

1209
00:49:43,020 --> 00:49:44,819
状态有多理想，没有

1210
00:49:44,819 --> 00:49:46,980
动作的概念，

1211
00:49:46,980 --> 00:49:49,560
这正是我们

1212
00:49:49,560 --> 00:49:51,839
在主动推理中的优先偏好 uh，

1213
00:49:51,839 --> 00:49:54,000
它是一种量化的分布

1214
00:49:54,000 --> 00:49:55,560
理想状态或非

1215
00:49:55,560 --> 00:49:57,960
理想状态是

1216
00:49:57,960 --> 00:50:00,119
正确的，所以

1217
00:50:00,119 --> 00:50:02,579
鉴于他们已经表明

1218
00:50:02,579 --> 00:50:05,099
你可以更快地学习 C 矩阵，

1219
00:50:05,099 --> 00:50:07,980
这是最佳的，它

1220
00:50:07,980 --> 00:50:10,079
甚至比 Q 学习还要快，那么我想好吧，为什么

1221
00:50:10,079 --> 00:50:13,319
不尝试以与 C

1222
00:50:13,319 --> 00:50:16,400
在这篇论文中被学习，并

1223
00:50:16,400 --> 00:50:19,319
使用这个说法，所以有一个类似的

1224
00:50:19,319 --> 00:50:21,839
学习 C 的学习规则，

1225
00:50:21,839 --> 00:50:24,119
在那篇论文中被称为集合学习，

1226
00:50:24,119 --> 00:50:25,800
当我尝试学习时，我

1227
00:50:25,800 --> 00:50:28,200
看到的是它学得非常快，一个

1228
00:50:28,200 --> 00:50:30,540
有用的 Pride 偏好 这让我可以

1229
00:50:30,540 --> 00:50:32,520
做出决定，或者让积极的

1230
00:50:32,520 --> 00:50:34,619
影响力代理人做出决定，

1231
00:50:34,619 --> 00:50:38,460
嗯，只需要说一次计划步骤，是的，

1232
00:50:38,460 --> 00:50:40,859
基本上就是

1233
00:50:40,859 --> 00:50:42,240


1234
00:50:42,240 --> 00:50:43,440


1235
00:50:43,440 --> 00:50:47,460
这个故事，所以嗯，C 很容易学习的想法

1236
00:50:47,460 --> 00:50:50,240
在那篇论文中，

1237
00:50:52,020 --> 00:50:54,780
好吧，让我尝试一下重述一下 因为

1238
00:50:54,780 --> 00:50:56,420
我认为这是

1239
00:50:56,420 --> 00:50:59,099
主动推理的一个非常有趣的增强，所以

1240
00:50:59,099 --> 00:51:02,280
我们将学习 C，

1241
00:51:02,280 --> 00:51:04,200
出于

1242
00:51:04,200 --> 00:51:06,480
我们之前讨论的所有原因，

1243
00:51:06,480 --> 00:51:09,619
我们将学习 C，

1244
00:51:09,619 --> 00:51:13,740
类似于托多洛夫如何提出 Z

1245
00:51:13,740 --> 00:51:18,540
学习，并且在 Z 学习中而

1246
00:51:18,540 --> 00:51:21,059
不是学习

1247
00:51:21,059 --> 00:51:23,460
嗯，例如更新动作的后验

1248
00:51:23,460 --> 00:51:26,160
概率，

1249
00:51:26,160 --> 00:51:28,380
然后使用动作在

1250
00:51:28,380 --> 00:51:31,339
发出观察结果的状态之间导航是

1251
00:51:31,339 --> 00:51:35,760
的，我们将把动作烘焙

1252
00:51:35,760 --> 00:51:37,319


1253
00:51:37,319 --> 00:51:39,300
到状态中，

1254
00:51:39,300 --> 00:51:41,420
以便我们真正直接学习

1255
00:51:41,420 --> 00:51:44,280
状态之间的转换是的，

1256
00:51:44,280 --> 00:51:48,200


1257
00:51:51,540 --> 00:51:53,880
并将其连接起来 自由

1258
00:51:53,880 --> 00:51:56,040
能原理，以及它是如何

1259
00:51:56,040 --> 00:51:57,660
通过主动推理发挥作用的，

1260
00:51:57,660 --> 00:51:59,220


1261
00:51:59,220 --> 00:52:00,559
嗯

1262
00:52:00,559 --> 00:52:03,780
C 不仅仅是我们的意愿函数，这

1263
00:52:03,780 --> 00:52:05,280
是思考它的一种方式，

1264
00:52:05,280 --> 00:52:07,559
这就是为什么我们称之为偏好，而且

1265
00:52:07,559 --> 00:52:11,640
C 是我们的期望，所以这就是

1266
00:52:11,640 --> 00:52:14,400
允许 我们一方面使用

1267
00:52:14,400 --> 00:52:16,800
熟悉的语言来奖励和

1268
00:52:16,800 --> 00:52:18,960
偏好学习，就像代理

1269
00:52:18,960 --> 00:52:21,900
最终到达它喜欢的地方一样，但也

1270
00:52:21,900 --> 00:52:25,500
基于期望的

1271
00:52:25,500 --> 00:52:27,780
um 定义 c 这些是相同的

1272
00:52:27,780 --> 00:52:30,180
事情，允许我们将其作为一条

1273
00:52:30,180 --> 00:52:32,760
最少的路径来讨论 行动或作为最

1274
00:52:32,760 --> 00:52:36,660
可能的结果或最不令人惊讶的

1275
00:52:36,660 --> 00:52:39,900
结果，因为我们已经将其定义为

1276
00:52:39,900 --> 00:52:42,960
我们想要的最不令人惊讶的

1277
00:52:42,960 --> 00:52:47,040
结果，那么我们可以使用变分自由能

1278
00:52:47,040 --> 00:52:50,640
来反弹惊喜，而你

1279
00:52:50,640 --> 00:52:54,000
不能简单地使用变分方法来

1280
00:52:54,000 --> 00:52:56,579
限制或 甚至必然近似

1281
00:52:56,579 --> 00:52:58,859
奖励本身，

1282
00:52:58,859 --> 00:53:01,079
但如果你说

1283
00:53:01,079 --> 00:53:04,980
我更喜欢我的期望，

1284
00:53:04,980 --> 00:53:07,559
而我的期望减少了我的惊喜，

1285
00:53:07,559 --> 00:53:09,859
我将平衡惊喜，

1286
00:53:09,859 --> 00:53:13,520
那么你就会得到这种

1287
00:53:13,520 --> 00:53:17,240
行为奖励

1288
00:53:17,240 --> 00:53:21,420
寻求，以惊喜限制惊喜

1289
00:53:21,420 --> 00:53:25,579
最小化物理框架是的，

1290
00:53:27,059 --> 00:53:28,740
是的 这是一种美丽的

1291
00:53:28,740 --> 00:53:31,619
表达方式是的谢谢

1292
00:53:31,619 --> 00:53:35,160
你接下来的

1293
00:53:35,160 --> 00:53:36,720


1294
00:53:36,720 --> 00:53:39,420
步骤或方向是什么令人兴奋或者

1295
00:53:39,420 --> 00:53:41,640
你想以什么方式完成这项工作是的很好是的

1296
00:53:41,640 --> 00:53:43,140
所以

1297
00:53:43,140 --> 00:53:44,940
嗯如果你只谈论这项

1298
00:53:44,940 --> 00:53:46,140
工作

1299
00:53:46,140 --> 00:53:50,640
嗯我想要什么 接下来要做的是呃

1300
00:53:50,640 --> 00:53:53,099
考虑基于提示的探索任务

1301
00:53:53,099 --> 00:53:55,200
我首先解决

1302
00:53:55,200 --> 00:53:58,980
动态编程的局限性所以如果你

1303
00:53:58,980 --> 00:54:01,020
说一个队列首先在这个网格中探索

1304
00:54:01,020 --> 00:54:03,660
那是更优化的我想看看

1305
00:54:03,660 --> 00:54:06,780
呃预期的歧义项如何

1306
00:54:06,780 --> 00:54:10,319
预期的自由能是有用的

1307
00:54:10,319 --> 00:54:12,240
，应该

1308
00:54:12,240 --> 00:54:13,260


1309
00:54:13,260 --> 00:54:15,540
严格在这个意义上在动态规划中使用，

1310
00:54:15,540 --> 00:54:18,000
嗯，但更一般地说，我也在寻找

1311
00:54:18,000 --> 00:54:20,339
其他积极影响决策的方法，

1312
00:54:20,339 --> 00:54:23,040
就像

1313
00:54:23,040 --> 00:54:24,900


1314
00:54:24,900 --> 00:54:26,099


1315
00:54:26,099 --> 00:54:30,180
哥伦比亚广播公司夏天教授的作品认为他在讲话 关于

1316
00:54:30,180 --> 00:54:33,059
神经网络是如何进行主动

1317
00:54:33,059 --> 00:54:35,099
推理和基本决策的，

1318
00:54:35,099 --> 00:54:36,359


1319
00:54:36,359 --> 00:54:39,540
从某种意义上说，它确实更高效，

1320
00:54:39,540 --> 00:54:42,359
就像队列学习一样，因此

1321
00:54:42,359 --> 00:54:44,940
他巧妙地利用

1322
00:54:44,940 --> 00:54:47,520
变化自由能来学习良好的

1323
00:54:47,520 --> 00:54:50,760
状态动作映射，这就是

1324
00:54:50,760 --> 00:54:52,200


1325
00:54:52,200 --> 00:54:55,079
我们习惯的

1326
00:54:55,079 --> 00:54:56,520
预期自由能发生了很大的变化，所以在那项工作中

1327
00:54:56,520 --> 00:54:59,220
没有预期自由能的概念，

1328
00:54:59,220 --> 00:55:01,740
这都是关于

1329
00:55:01,740 --> 00:55:03,599
直接从能量变化中学习什么是好什么是坏，

1330
00:55:03,599 --> 00:55:05,700
所以我发现这

1331
00:55:05,700 --> 00:55:08,099
也是 令人着迷的是，我想

1332
00:55:08,099 --> 00:55:11,160
更多地探索这一点，看看以

1333
00:55:11,160 --> 00:55:15,300
这种方式做出的决策是更好还是更差，

1334
00:55:15,300 --> 00:55:18,000
或者应该考虑我们是否应该

1335
00:55:18,000 --> 00:55:20,220
重新考虑决策方式，

1336
00:55:20,220 --> 00:55:22,200
因为主动推理只讨论

1337
00:55:22,200 --> 00:55:23,700
变分自由能，这是

1338
00:55:23,700 --> 00:55:25,520
一切的中心原则 否则是

1339
00:55:25,520 --> 00:55:28,440
你对这一点的解释，

1340
00:55:28,440 --> 00:55:31,319
所以是的，

1341
00:55:31,319 --> 00:55:35,180
这是另一个方向，我想用

1342
00:55:35,640 --> 00:55:38,359
有趣的方式来表达，这绝对是

1343
00:55:38,359 --> 00:55:42,480
变分自由能，它是

1344
00:55:42,480 --> 00:55:45,540
我们变分

1345
00:55:45,540 --> 00:55:48,660
um分布q和数据y的函数，

1346
00:55:48,660 --> 00:55:51,119
变分自由能有点像

1347
00:55:51,119 --> 00:55:53,839
实时

1348
00:55:53,839 --> 00:55:57,359
稳态，是的，

1349
00:55:57,359 --> 00:55:59,760
考虑到我所相信的和

1350
00:55:59,760 --> 00:56:01,619
输入的数据，事情是如何有意义的，

1351
00:56:01,619 --> 00:56:04,740
然后将这种

1352
00:56:04,740 --> 00:56:07,020
有意义的框架扩展到决策

1353
00:56:07,020 --> 00:56:10,020
制定中，我们已经看到了很多不同的

1354
00:56:10,020 --> 00:56:13,740
方法，预期自由能是

1355
00:56:13,740 --> 00:56:16,260
一种常见的方法 但例如，

1356
00:56:16,260 --> 00:56:19,400
存在预期未来的自由能

1357
00:56:19,400 --> 00:56:25,200
eef，还有其他

1358
00:56:25,200 --> 00:56:29,760
具有不同方法的结构，

1359
00:56:29,760 --> 00:56:31,380
然后你也将其指向

1360
00:56:31,380 --> 00:56:33,599
samura 教授的工作，

1361
00:56:33,599 --> 00:56:37,020
即

1362
00:56:37,020 --> 00:56:39,059


1363
00:56:39,059 --> 00:56:41,339
基本图上的变分自由能与

1364
00:56:41,339 --> 00:56:43,680
神经网络中的损失函数以及

1365
00:56:43,680 --> 00:56:45,300
所有这些关系也是非常

1366
00:56:45,300 --> 00:56:48,380
令人兴奋的工作，

1367
00:56:49,079 --> 00:56:51,660
嗯我想就像

1368
00:56:51,660 --> 00:56:53,460
最后一个问题一样结束，或者认为

1369
00:56:53,460 --> 00:56:55,559
你即将完成

1370
00:56:55,559 --> 00:56:56,880
博士学位，

1371
00:56:56,880 --> 00:57:00,540
所以就在你已经完成的时候 作为一名

1372
00:57:00,540 --> 00:57:02,579
博士生，

1373
00:57:02,579 --> 00:57:06,300
您如何看待主动推理的

1374
00:57:06,300 --> 00:57:10,700
发展，或者

1375
00:57:11,339 --> 00:57:14,280
今天接近

1376
00:57:14,280 --> 00:57:17,400
尾声时您的感觉与

1377
00:57:17,400 --> 00:57:19,980
几年前您的新鲜感和兴奋感有何不同，是的，

1378
00:57:19,980 --> 00:57:21,119


1379
00:57:21,119 --> 00:57:23,339
这是一个非常好的

1380
00:57:23,339 --> 00:57:25,920
问题，呃，我也很兴奋

1381
00:57:25,920 --> 00:57:29,400
这个领域已经发展了，坦率地说，

1382
00:57:29,400 --> 00:57:30,900
我从强化

1383
00:57:30,900 --> 00:57:32,400
学习背景和物理

1384
00:57:32,400 --> 00:57:34,680
背景开始，当我开始阅读时，

1385
00:57:34,680 --> 00:57:37,680
只说了一两篇论文，我

1386
00:57:37,680 --> 00:57:40,440
不太理解其中的大部分内容，

1387
00:57:40,440 --> 00:57:42,540
直到我开始

1388
00:57:42,540 --> 00:57:44,700
使用它来实现它 调用

1389
00:57:44,700 --> 00:57:46,980
um Matlab 脚本 我有点理解，

1390
00:57:46,980 --> 00:57:49,559
好吧，这是有道理的，我喜欢它，

1391
00:57:49,559 --> 00:57:52,020
但是在一两年内，我看到

1392
00:57:52,020 --> 00:57:54,780
很多来自

1393
00:57:54,780 --> 00:57:56,280
不同方向的论文，人们也

1394
00:57:56,280 --> 00:57:58,740
开始使用神经网络和所有

1395
00:57:58,740 --> 00:58:02,460
这些扩展 我来了，我在某个

1396
00:58:02,460 --> 00:58:04,319
时候也质疑

1397
00:58:04,319 --> 00:58:07,260
主动推理的必要性，呃，因为如果你

1398
00:58:07,260 --> 00:58:09,119
有深度强化学习，它

1399
00:58:09,119 --> 00:58:10,980
可以做很多事情，那么为什么需要深度主动

1400
00:58:10,980 --> 00:58:14,040
推理，这就是为什么我

1401
00:58:14,040 --> 00:58:16,319
没有进入这一领域的原因，但我仍然觉得

1402
00:58:16,319 --> 00:58:18,359
它很有趣 我想比我现在所知道的

1403
00:58:18,359 --> 00:58:20,280
更多地理解深度主动推理，

1404
00:58:20,280 --> 00:58:23,160
但我看到这个

1405
00:58:23,160 --> 00:58:25,680
领域在两三年内像任何事情一样发展，

1406
00:58:25,680 --> 00:58:28,619
许多人

1407
00:58:28,619 --> 00:58:31,859
开始工作，很快它就成为一个

1408
00:58:31,859 --> 00:58:36,359
认真对待的领域 比一个只有

1409
00:58:36,359 --> 00:58:39,119
两篇论文的领域没有人真正

1410
00:58:39,119 --> 00:58:41,280
知道它是什么所以这真的很

1411
00:58:41,280 --> 00:58:43,440
令人兴奋是的所以我真的很期待

1412
00:58:43,440 --> 00:58:47,040
这个领域如何随着时间的推移而发展以及

1413
00:58:47,040 --> 00:58:52,140
我在获得博士学位后可以做什么等等

1414
00:58:52,140 --> 00:58:55,319
在时间上向前冷却

1415
00:58:55,319 --> 00:59:00,359
什么 我们更喜欢我们所期望的 是的

1416
00:59:02,339 --> 00:59:04,140
任何其他

1417
00:59:04,140 --> 00:59:05,819
评论或您想添加的任何其他内容

1418
00:59:05,819 --> 00:59:07,200


1419
00:59:07,200 --> 00:59:09,839
是的，所以请让我知道您

1420
00:59:09,839 --> 00:59:11,940
对这篇论文的看法以及您

1421
00:59:11,940 --> 00:59:14,400
对这些想法的看法 请随时告诉我，

1422
00:59:14,400 --> 00:59:16,200
我真的很期待

1423
00:59:16,200 --> 00:59:17,760
反馈，

1424
00:59:17,760 --> 00:59:20,160
是的 非常感谢丹尼尔给我这个机会，

1425
00:59:20,160 --> 00:59:23,339
谢谢你的宝贵时间，

1426
00:59:23,339 --> 00:59:26,160
这太棒了，我希望人们

1427
00:59:26,160 --> 00:59:28,260
查看这篇论文，并联系并

1428
00:59:28,260 --> 00:59:30,540
复制代码，并按照

1429
00:59:30,540 --> 00:59:33,359
自己的指示进行操作，谢谢下次再见，

1430
00:59:33,359 --> 00:59:34,680


1431
00:59:34,680 --> 00:59:36,839
下次再见 非常感谢你，再见，祝你

1432
00:59:36,839 --> 00:59:40,040
有美好的一天，再见

