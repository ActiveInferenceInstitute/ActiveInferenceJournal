1
00:00:03,120 --> 00:00:06,120
外国人、

2
00:00:08,480 --> 00:00:12,660
2023 年 7 月 15 日です。

3
00:00:12,660 --> 00:00:15,900


4
00:00:15,900 --> 00:00:19,080


5
00:00:19,080 --> 00:00:21,060
今日は Aspen Paul とアクティブ推論モデル ストリーム番号 9.1 に来ています。アクティブ推論における

6
00:00:21,060 --> 00:00:24,180
効率的な計算に関するプレゼンテーションとディスカッションを行う予定です。

7
00:00:24,180 --> 00:00:27,000


8
00:00:27,000 --> 00:00:28,619
ライブで視聴している場合は、

9
00:00:28,619 --> 00:00:30,840
お気軽に追加してください。 それ以外の場合はチャットでコメントや質問をしてください。

10
00:00:30,840 --> 00:00:33,059


11
00:00:33,059 --> 00:00:36,120
今日はご参加いただきありがとうございます。

12
00:00:36,120 --> 00:00:38,820
講演を楽しみにしています。

13
00:00:38,820 --> 00:00:41,640
ダニエルさん、ありがとうございます。

14
00:00:41,640 --> 00:00:42,960
今日はお話ししたように、

15
00:00:42,960 --> 00:00:44,700
効率的な計算と能動推論についてお話します

16
00:00:44,700 --> 00:00:46,920
。それでは、始めましょ

17
00:00:46,920 --> 00:00:49,500
う。 皆さんは能動推論としても知られるこの

18
00:00:49,500 --> 00:00:51,420
自由エネルギー原理の考え方に精通していると思います

19
00:00:51,420 --> 00:00:53,820
が、その

20
00:00:53,820 --> 00:00:55,800
中心となる概念は、エージェントが

21
00:00:55,800 --> 00:00:59,160


22
00:00:59,160 --> 00:01:01,140
ホメオスタシスを維持したり

23
00:01:01,140 --> 00:01:03,719
環境で生き残るために観察結果のエントロピーを最小化するというものであり、ここでエントロピーは

24
00:01:03,719 --> 00:01:05,580
情報理論で定義されています。 それは

25
00:01:05,580 --> 00:01:08,520
正しいと思います。つまり、観察が

26
00:01:08,520 --> 00:01:10,200
高確率である場合、

27
00:01:10,200 --> 00:01:12,659
エントロピーが低く、驚くべきことではありません。なぜなら、それは

28
00:01:12,659 --> 00:01:14,159
高確率であり、私たちは

29
00:01:14,159 --> 00:01:16,560
それを期待しており、

30
00:01:16,560 --> 00:01:18,840
それが

31
00:01:18,840 --> 00:01:20,939
この能動推論のフレームワークとこのアイデアを構築するベースであるため、それが

32
00:01:20,939 --> 00:01:23,759
アイデアであるということです。

33
00:01:23,759 --> 00:01:26,520
マルコブランケット、それは私たちに

34
00:01:26,520 --> 00:01:30,000
驚くべき系統的な方法、または

35
00:01:30,000 --> 00:01:32,580
エージェントをその環境から分離し、目的のある行動をモデル化する概略的な方法を提供します。

36
00:01:32,580 --> 00:01:34,439


37
00:01:34,439 --> 00:01:37,320
それでは、

38
00:01:37,320 --> 00:01:39,780
エントロピーを最小化するというこのアイデアに焦点を当てましょう。それで、

39
00:01:39,780 --> 00:01:41,700
エージェントはどのようにエントロピーを最小化するか、または

40
00:01:41,700 --> 00:01:43,740
どの観察がどのようなものであるかを知ることができますか

41
00:01:43,740 --> 00:01:46,020
確率が高く、その逆も同様

42
00:01:46,020 --> 00:01:48,360
です。つまり、生成モデルを維持することによって行われます。

43
00:01:48,360 --> 00:01:50,399
生成モデルは

44
00:01:50,399 --> 00:01:52,020
基本的に、

45
00:01:52,020 --> 00:01:56,340
エージェントが脳内に構築する環境のおもちゃのモデルであり、

46
00:01:56,340 --> 00:01:58,860


47
00:01:58,860 --> 00:02:00,540
環境から得られる観察のみを使用して構築されます。

48
00:02:00,540 --> 00:02:03,420
現実の状態または

49
00:02:03,420 --> 00:02:04,740
環境の隠れた状態にアクセスする

50
00:02:04,740 --> 00:02:07,920
おもちゃのモデルを構築しており、

51
00:02:07,920 --> 00:02:10,318
このおもちゃのモデルが与えられると、観察の確率を計算する範囲または能力があり

52
00:02:10,318 --> 00:02:13,560


53
00:02:13,560 --> 00:02:15,900
、したがってエントロピーを最小化しようとするのは

54
00:02:15,900 --> 00:02:18,660
正しいので、

55
00:02:18,660 --> 00:02:22,620
それがアイデアですが、 与え

56
00:02:22,620 --> 00:02:25,800
られた生成モデルのような筆記次元の問題があります。

57
00:02:25,800 --> 00:02:27,239


58
00:02:27,239 --> 00:02:30,120


59
00:02:30,120 --> 00:02:32,099


60
00:02:32,099 --> 00:02:34,140
状態空間はすぐに

61
00:02:34,140 --> 00:02:37,020
扱いにくくなる可能性があるため、そこから観測の確率を計算したり周辺化したりすることが常に可能であるとは限りませんが、アイデアは、驚き

62
00:02:37,020 --> 00:02:38,640
の上限を定義することです

63
00:02:38,640 --> 00:02:41,580
ジェンセンの不等式を使用して、

64
00:02:41,580 --> 00:02:43,560


65
00:02:43,560 --> 00:02:46,800


66
00:02:46,800 --> 00:02:49,500
隠れた信念または隠れた州についての信念である Q と呼ばれる新しい用語を定義することもできます。

67
00:02:49,500 --> 00:02:52,080
このキューが

68
00:02:52,080 --> 00:02:54,000
適切な意思決定の焦点になる

69
00:02:54,000 --> 00:02:57,060
ため、騒々しいキューがあり、何もわからない場合は、

70
00:02:57,060 --> 00:02:58,680
環境の中に何があるかというと、

71
00:02:58,680 --> 00:03:00,840


72
00:03:00,840 --> 00:03:03,540
その環境を制御するための決定を下したり、行うことを望むことはできません。そして、

73
00:03:03,540 --> 00:03:05,519
隠れた状態についてのこの信念が、

74
00:03:05,519 --> 00:03:07,560
あなたが使用し、決定を下すのに役立ちます。

75
00:03:07,560 --> 00:03:10,379
この全量は、

76
00:03:10,379 --> 00:03:13,019
もちろん、フリーエネルギーと呼ばれ、

77
00:03:13,019 --> 00:03:14,420
変分自由エネルギー

78
00:03:14,420 --> 00:03:17,879
F は複数の方法で解釈できます。そのため、

79
00:03:17,879 --> 00:03:19,560
最初の、または最も一般的なのは、モデル

80
00:03:19,560 --> 00:03:22,920


81
00:03:22,920 --> 00:03:25,200
の精度を最大化すると同時に、モデルの複雑さを最小限に抑えようとする機械学習の方法です。

82
00:03:25,200 --> 00:03:27,060


83
00:03:27,060 --> 00:03:28,739


84
00:03:28,739 --> 00:03:30,180


85
00:03:30,180 --> 00:03:32,400
さまざまな自由エネルギーを最小化する機械学習の解釈

86
00:03:32,400 --> 00:03:34,140
また、

87
00:03:34,140 --> 00:03:34,739


88
00:03:34,739 --> 00:03:36,420


89
00:03:36,420 --> 00:03:38,940


90
00:03:38,940 --> 00:03:41,760
モデルのエネルギーを最小化しようとすると同時に、エントロピーを

91
00:03:41,760 --> 00:03:43,019
最大化しようとする物理用語で自由エネルギーを解釈しようとすることもできますが、

92
00:03:43,019 --> 00:03:45,120


93
00:03:45,120 --> 00:03:48,659
今日の焦点です または、意思決定は常に、

94
00:03:48,659 --> 00:03:51,540


95
00:03:51,540 --> 00:03:54,780
能動推論で知覚を行った後に得られる信念に基づいています。それでは、

96
00:03:54,780 --> 00:03:57,120
バニラの意思決定をどのように行うか、または

97
00:03:57,120 --> 00:03:58,920


98
00:03:58,920 --> 00:04:00,659
意思決定と古典的な能動

99
00:04:00,659 --> 00:04:03,540
推論について最も議論されているアイデアは何ですか、つまり、あなたが環境にいる場合は、

100
00:04:03,540 --> 00:04:05,580
ええと そして、あなたが意思決定をしようとしているエージェントであれば、

101
00:04:05,580 --> 00:04:08,819


102
00:04:08,819 --> 00:04:10,620


103
00:04:10,620 --> 00:04:13,319
利用可能なアクションの余地があるため、

104
00:04:13,319 --> 00:04:15,480
このおもちゃのモデルでは、実行、ジャンプまたは滞在の 3 つの利用可能なアクションがあり、

105
00:04:15,480 --> 00:04:19,738


106
00:04:19,738 --> 00:04:22,199
これらのアクションを考慮すると、

107
00:04:22,199 --> 00:04:25,139
小さな Pi によってポリシーを定義できます。 これは、

108
00:04:25,139 --> 00:04:28,320
時間と資本における一連のアクションです。

109
00:04:28,320 --> 00:04:30,300
t は、計画の時間軸です。または、

110
00:04:30,300 --> 00:04:32,660


111
00:04:32,660 --> 00:04:36,540
ポリシーの長さです。この

112
00:04:36,540 --> 00:04:39,419
ようなポリシーが多数含まれるポリシー スペースは小さいパイであるため、

113
00:04:39,419 --> 00:04:42,060
このより大きな最小スペースを考慮して、

114
00:04:42,060 --> 00:04:44,220


115
00:04:44,220 --> 00:04:47,340
期待される無料の評価を試みることができます。 エネルギーは、

116
00:04:47,340 --> 00:04:48,720
あなたが蓄積してきた信念に基づいている

117
00:04:48,720 --> 00:04:50,580
ため、ここでは、エネルギーの

118
00:04:50,580 --> 00:04:52,860
変動からすでに持っている信念を最小化することはなく、

119
00:04:52,860 --> 00:04:55,080


120
00:04:55,080 --> 00:04:57,419


121
00:04:57,419 --> 00:04:59,520


122
00:04:59,520 --> 00:05:02,759
定義できる多くの非常に小さなポリシーに対応する予想される自由エネルギーを計算

123
00:05:02,759 --> 00:05:05,699
または評価しているだけです。 すべてのポリシーについてそれを評価する

124
00:05:05,699 --> 00:05:07,440
と、どの

125
00:05:07,440 --> 00:05:09,180
ポリシーを採用するのが最適であるかがわかります。これが正しい

126
00:05:09,180 --> 00:05:11,160


127
00:05:11,160 --> 00:05:13,800
意思決定に関する古典的な能動推論のアイデアです。

128
00:05:13,800 --> 00:05:16,020
この期待される自由エネルギーは、

129
00:05:16,020 --> 00:05:18,900
目標

130
00:05:18,900 --> 00:05:21,720
指向であるため、リスク項も目標

131
00:05:21,720 --> 00:05:23,520
指向であるという意味で非常に役立ちます。 そして、予想される

132
00:05:23,520 --> 00:05:25,919
あいまいな用語があるため、

133
00:05:25,919 --> 00:05:27,960
同様に探索する必要がありますが、

134
00:05:27,960 --> 00:05:30,539
このポリシー空間がすぐに

135
00:05:30,539 --> 00:05:32,400
対話可能になる可能性があるという問題があり、それが

136
00:05:32,400 --> 00:05:35,280
アクティブ推論を一般的に見られる環境に拡張する際のボトルネックとして常に存在します。

137
00:05:35,280 --> 00:05:37,680


138
00:05:37,680 --> 00:05:40,500


139
00:05:40,500 --> 00:05:42,419
すぐに対話可能になる

140
00:05:42,419 --> 00:05:45,300
ので、たとえば時間軸が 15 の場合にいくつのポリシーを定義できるかという

141
00:05:45,300 --> 00:05:47,940
と、たとえば

142
00:05:47,940 --> 00:05:50,340
スーパー マリオをプレイしている場合は、

143
00:05:50,340 --> 00:05:52,440
少なくともたとえば 10 時間

144
00:05:52,440 --> 00:05:56,460
ステップ先を計画して、最初のポリシーが

145
00:05:56,460 --> 00:05:58,380
同じアクションになるようにする必要があるかもしれません。

146
00:05:58,380 --> 00:06:02,600
15 タイム ステップのスタックを実行すると、

147
00:06:02,600 --> 00:06:05,460
基本的にそのようなアクションのいくつかの組み合わせを定義できます。

148
00:06:05,460 --> 00:06:09,060
政策空間は

149
00:06:09,060 --> 00:06:10,139
単純に手に負えません。

150
00:06:10,139 --> 00:06:13,860


151
00:06:13,860 --> 00:06:16,380


152
00:06:16,380 --> 00:06:19,440
そのようなすべての政策に対して期待される自由エネルギーを評価するには巨大すぎるため、

153
00:06:19,440 --> 00:06:21,900
確率的問題設定で評価することはできません。

154
00:06:21,900 --> 00:06:24,419
環境自体はノイズが多いため、

155
00:06:24,419 --> 00:06:27,120


156
00:06:27,120 --> 00:06:28,860
このポリシー空間のサブセットを選択して

157
00:06:28,860 --> 00:06:30,840
古典的な能動推論を実行する方法は実際にはありません。これは

158
00:06:30,840 --> 00:06:32,340
明らかに計算的に対話可能な

159
00:06:32,340 --> 00:06:34,380
問題です。そのため、議論するときに文献で

160
00:06:34,380 --> 00:06:36,360
常に小さなグリッドまたは小さな環境が表示されます。

161
00:06:36,360 --> 00:06:38,880
意思

162
00:06:38,880 --> 00:06:41,520
決定は積極的な影響力の中で行われますが、最近、

163
00:06:41,520 --> 00:06:43,860


164
00:06:43,860 --> 00:06:46,259
洗練された入り口と呼ばれる新しいアイデアが提案されました。洗練

165
00:06:46,259 --> 00:06:48,840
された推論では、

166
00:06:48,840 --> 00:06:51,600
それは実際には政策空間ではありません。

167
00:06:51,600 --> 00:06:52,800
実際に

168
00:06:52,800 --> 00:06:55,080


169
00:06:55,080 --> 00:06:58,139
何をすべきかを考えようとしているのはリアルタイムです。信念があるなら、 ええと、

170
00:06:58,139 --> 00:07:00,000


171
00:07:00,000 --> 00:07:02,880
それに基づいてアクションを評価しようとしているので、

172
00:07:02,880 --> 00:07:04,800
ここでは相互作用できる一連の

173
00:07:04,800 --> 00:07:07,199
ポリシーや物事はありません、

174
00:07:07,199 --> 00:07:10,020
ええと、この共同分布の予想される自由エネルギーを評価しようとしているという

175
00:07:10,020 --> 00:07:12,600
意味で、私たちは基本的に研究を行っています

176
00:07:12,600 --> 00:07:14,220


177
00:07:14,220 --> 00:07:16,500


178
00:07:16,500 --> 00:07:19,560
アクションと

179
00:07:19,560 --> 00:07:21,900
観測の予測を行い、

180
00:07:21,900 --> 00:07:23,940
ある時点での期待される自由エネルギーを評価するには、

181
00:07:23,940 --> 00:07:26,340
小さな T ですが、

182
00:07:26,340 --> 00:07:29,039
次のタイム ステップでの期待される自由エネルギーも必要になります。また、

183
00:07:29,039 --> 00:07:31,259


184
00:07:31,259 --> 00:07:32,819
時間 t に 2 を加えた期待される自由エネルギーが必要であることを評価するには、これは

185
00:07:32,819 --> 00:07:35,039
基本的に次のようになります。 研究は

186
00:07:35,039 --> 00:07:38,160
時間内に展開されます。それは

187
00:07:38,160 --> 00:07:41,160
再帰的な関係です。

188
00:07:41,160 --> 00:07:43,259
ここでは、

189
00:07:43,259 --> 00:07:45,539
最後のスライドで見た政策空間とは根本的に異なります。

190
00:07:45,539 --> 00:07:47,759


191
00:07:47,759 --> 00:07:49,680


192
00:07:49,680 --> 00:07:51,780
計画を立てる必要がある場合、たとえば 10

193
00:07:51,780 --> 00:07:55,139
倍のヒントを必要とするという意味では、計算的に優れています。

194
00:07:55,139 --> 00:07:56,759
古典的な能動的推論では、

195
00:07:56,759 --> 00:07:58,380
ポリシー空間、つまり

196
00:07:58,380 --> 00:07:59,460


197
00:07:59,460 --> 00:08:01,940
アクション空間のカーディナリティーが

198
00:08:01,940 --> 00:08:04,139
T に引き上げられることがわかりました。したがって、

199
00:08:04,139 --> 00:08:07,259


200
00:08:07,259 --> 00:08:10,199
すべての可能性を考慮する必要がある場合、それが計算のボトルネックになります。しかし、洗練された

201
00:08:10,199 --> 00:08:12,780
推論では、それはさらに悪いことです。

202
00:08:12,780 --> 00:08:14,759


203
00:08:14,759 --> 00:08:16,860
状態とアクションの組み合わせなので、

204
00:08:16,860 --> 00:08:20,400
実際には計算的にはさらに悪いですが、

205
00:08:20,400 --> 00:08:21,660


206
00:08:21,660 --> 00:08:23,520
洗練された参考論文で解決策が提案されており、

207
00:08:23,520 --> 00:08:26,400
枝刈りを行うことができます。この研究では、

208
00:08:26,400 --> 00:08:29,639
一部の状態とアクションを回避でき、

209
00:08:29,639 --> 00:08:31,080
この研究を行うと、

210
00:08:31,080 --> 00:08:33,000
計算的に非常に扱いやすくなります。

211
00:08:33,000 --> 00:08:36,059


212
00:08:36,059 --> 00:08:38,940
洗練された推論で剪定がどのように機能するかを見てみましょう。このグリッドは

213
00:08:38,940 --> 00:08:40,440
元の洗練された推論論文で説明されています。

214
00:08:40,440 --> 00:08:41,700


215
00:08:41,700 --> 00:08:44,580
このグリッドについて、

216
00:08:44,580 --> 00:08:47,100
この種の事前優先分布があると仮定して、

217
00:08:47,100 --> 00:08:50,399


218
00:08:50,399 --> 00:08:52,140
目標ステータスであるこの白い四角形が最も優先される状態であるとします。

219
00:08:52,140 --> 00:08:54,300
あなたは、その黄金状態から遠く離れた状態

220
00:08:54,300 --> 00:08:55,380


221
00:08:55,380 --> 00:08:58,140
への優先度を均一に減少させています。

222
00:08:58,140 --> 00:09:00,779


223
00:09:00,779 --> 00:09:03,240
そして、基本的に、あなたが

224
00:09:03,240 --> 00:09:05,480
時間 T における何らかの観察で自分自身を観察した場合、

225
00:09:05,480 --> 00:09:07,560
基本的にあなたがしていることは、

226
00:09:07,560 --> 00:09:09,600


227
00:09:09,600 --> 00:09:12,779
その観察から得られる行動の結果を考慮しているということです。

228
00:09:12,779 --> 00:09:17,760
基本的に、

229
00:09:17,760 --> 00:09:20,700
自分の信念の投影を使用して、それらの信念にしきい値を設定して、

230
00:09:20,700 --> 00:09:22,620
おそらく

231
00:09:22,620 --> 00:09:24,600
一部の行動を無視したり、いくつかの観察を無視したりすることが

232
00:09:24,600 --> 00:09:27,420
できます。そうすれば、

233
00:09:27,420 --> 00:09:30,120
それはもはや研究

234
00:09:30,120 --> 00:09:33,000
段階ではなく、研究のサブセットであり、

235
00:09:33,000 --> 00:09:36,060
計算上の方法であることがわかります。 えーっと、

236
00:09:36,060 --> 00:09:38,700
調査全体を正しく行うよりも効率的です。そこで、ここでは

237
00:09:38,700 --> 00:09:40,680
多くの組み合わせを避けていますが、

238
00:09:40,680 --> 00:09:42,120
これは計算上

239
00:09:42,120 --> 00:09:45,420
魅力的な問題になります。これは、

240
00:09:45,420 --> 00:09:47,880
いくつかのアクションと

241
00:09:47,880 --> 00:09:49,620
観察を避けることにしたためです。そのため、本質的に

242
00:09:49,620 --> 00:09:52,740
その可能性を妥協していると言っています。

243
00:09:52,740 --> 00:09:54,600
より高い報酬か、

244
00:09:54,600 --> 00:09:56,580


245
00:09:56,580 --> 00:09:59,700
それともこの部分的な研究の結果よりも最適であるかはわかりませんが、これは

246
00:09:59,700 --> 00:10:02,820
機能するので、このシミュレーションは

247
00:10:02,820 --> 00:10:05,459
論文で提示され、機能します。

248
00:10:05,459 --> 00:10:09,959
エージェントは、えー、この順方向に

249
00:10:09,959 --> 00:10:12,300
計画する場合に何をする必要があるかを学習します。

250
00:10:12,300 --> 00:10:14,940
えー、枝

251
00:10:14,940 --> 00:10:17,880
刈りされた方法で計画を立てますが、

252
00:10:17,880 --> 00:10:19,200


253
00:10:19,200 --> 00:10:20,820
基本的には、

254
00:10:20,820 --> 00:10:23,519
検索しきい値が小さい場合でも、計算の複雑さを

255
00:10:23,519 --> 00:10:25,019


256
00:10:25,019 --> 00:10:27,180
大幅に減らすことができることを計算で示すことができます。そのため、

257
00:10:27,180 --> 00:10:29,100


258
00:10:29,100 --> 00:10:31,500
調査全体を

259
00:10:31,500 --> 00:10:33,540
計画の深さで行うことにした場合、

260
00:10:33,540 --> 00:10:35,100
計算時間は 指数関数的で

261
00:10:35,100 --> 00:10:38,040
急速にそれについてはあまりできません

262
00:10:38,040 --> 00:10:40,200
が、非常に小さいしきい値で決定すると、

263
00:10:40,200 --> 00:10:42,420


264
00:10:42,420 --> 00:10:43,980
この問題が

265
00:10:43,980 --> 00:10:46,620
計算的に魅力的になることがわかります。

266
00:10:46,620 --> 00:10:49,200
洗練されたインスタンスに関するこのデモは、

267
00:10:49,200 --> 00:10:50,700
私のバージョンの mdp で利用できます。

268
00:10:50,700 --> 00:10:52,860


269
00:10:52,860 --> 00:10:55,380
すぐにMDPによってオリジナルに統合される予定です

270
00:10:55,380 --> 00:10:56,820


271
00:10:56,820 --> 00:10:59,160
が、重要な点は、この調査の枝刈りには、

272
00:10:59,160 --> 00:11:01,920


273
00:11:01,920 --> 00:11:03,779


274
00:11:03,779 --> 00:11:06,060
エージェントが

275
00:11:06,060 --> 00:11:09,360
近隣の州がどれほど望ましいものでは

276
00:11:09,360 --> 00:11:11,760
ないかを認識しているという意味で、このような十分な情報に基づいた主要な優先順位が必要であるということです 最終的な目標セットについてのみ知っており、

277
00:11:11,760 --> 00:11:13,860
その

278
00:11:13,860 --> 00:11:16,440
隣接する状態についても知っており、そのような事前

279
00:11:16,440 --> 00:11:18,420
優先度が与えられると、

280
00:11:18,420 --> 00:11:20,399
計画の深さが 3 の場合、エージェントは

281
00:11:20,399 --> 00:11:23,820
基本的に事前優先度のこの局所的な最大値で行き詰まっていることがわかりますが、

282
00:11:23,820 --> 00:11:27,060


283
00:11:27,060 --> 00:11:30,480
十分な計画深度があれば、

284
00:11:30,480 --> 00:11:33,240
この障壁を乗り越えて、この大きな問題の目標状態に到達することができます。

285
00:11:33,240 --> 00:11:35,579


286
00:11:35,579 --> 00:11:37,800


287
00:11:37,800 --> 00:11:39,600
問題は、エージェントが

288
00:11:39,600 --> 00:11:42,720
この最終状態だけを知っている場合はどうなるのか

289
00:11:42,720 --> 00:11:45,660
、何をすべきかについて他の知識がない場合は

290
00:11:45,660 --> 00:11:48,240
どうなるのかということです。この場合、エージェントは何をするのかということです。 これが

291
00:11:48,240 --> 00:11:50,459
私たちが対処しようとしている問題であり、

292
00:11:50,459 --> 00:11:53,399


293
00:11:53,399 --> 00:11:55,740
このような意味のある事前設定が存在しない場合、

294
00:11:55,740 --> 00:11:58,200
エージェントは基本的に

295
00:11:58,200 --> 00:12:00,720
目標に到達する方法がありません。

296
00:12:00,720 --> 00:12:03,300
ランダムな探索以外に、

297
00:12:03,300 --> 00:12:05,279
計画を立てる方法がありません。

298
00:12:05,279 --> 00:12:08,040
計算上対話可能なので、8 時間ステップ先の計画を立ててください。

299
00:12:08,040 --> 00:12:09,779


300
00:12:09,779 --> 00:12:13,079


301
00:12:13,079 --> 00:12:17,880
完全な調査を正しく実行することを選択した場合、

302
00:12:17,880 --> 00:12:21,000
このようなグリッドの場合、

303
00:12:21,000 --> 00:12:22,500


304
00:12:22,500 --> 00:12:24,240
十分な情報がなく、強調表示されているようにまばらな試行設定を取得した場合はどうしますか

305
00:12:24,240 --> 00:12:28,079
前のスライドでは、

306
00:12:28,079 --> 00:12:30,839
あなたの研究は盲目になりました、えー、

307
00:12:30,839 --> 00:12:33,000
その研究を切り詰める方法はなく、

308
00:12:33,000 --> 00:12:35,100
このシナリオでは完全な研究を行う必要があります。

309
00:12:35,100 --> 00:12:36,300


310
00:12:36,300 --> 00:12:38,880
したがって、お考えかもしれませんが、

311
00:12:38,880 --> 00:12:40,200
これには 2 つの解決策があるか、

312
00:12:40,200 --> 00:12:42,959
どちらかを見つける必要があります。

313
00:12:42,959 --> 00:12:47,359
徹底的な計画を立てる方法 えー、そうでない場合は、

314
00:12:49,579 --> 00:12:52,920


315
00:12:52,920 --> 00:12:54,600


316
00:12:54,600 --> 00:12:57,480
この剪定された調査を実行できるようにするための有意義なプライド設定を学ぶ必要があります。そこで、

317
00:12:57,480 --> 00:12:59,760
この 2 つのソリューションについて

318
00:12:59,760 --> 00:13:02,399
このプレゼンテーションで説明します。このような特定のシナリオに対して、

319
00:13:02,399 --> 00:13:03,839


320
00:13:03,839 --> 00:13:06,420
最初の 完全な研究を行うための解決策は、

321
00:13:06,420 --> 00:13:08,639
基本的に動的

322
00:13:08,639 --> 00:13:11,399
計画法を使用することです。動的計画法は、

323
00:13:11,399 --> 00:13:13,800
オペレーション リサーチ

324
00:13:13,800 --> 00:13:15,839
と生産工学、および

325
00:13:15,839 --> 00:13:18,060
工学のさまざまな分野でよく知られているアイデアです。

326
00:13:18,060 --> 00:13:19,920
基本的な考え方は、最初に

327
00:13:19,920 --> 00:13:21,959
大きな問題の部分部分を解決し、

328
00:13:21,959 --> 00:13:24,000
その後で解決するというものです。 後で、

329
00:13:24,000 --> 00:13:27,000
これらのサブ問題の解決策を統合してみます えー、

330
00:13:27,000 --> 00:13:31,260
最適な意思決定を行うため

331
00:13:31,260 --> 00:13:33,779
このシナリオでは、最後のアクションを計画しようとしていると想像してください。そのため、

332
00:13:33,779 --> 00:13:37,019


333
00:13:37,019 --> 00:13:39,540


334
00:13:39,540 --> 00:13:41,760
最初のアクションから開始し、現在から開始し、

335
00:13:41,760 --> 00:13:44,040
予測を試みます 将来何が起こっているのかということは、

336
00:13:44,040 --> 00:13:46,320


337
00:13:46,320 --> 00:13:47,940
計画の方向性は基本的には時間的に前向きです

338
00:13:47,940 --> 00:13:49,920
が、

339
00:13:49,920 --> 00:13:51,959


340
00:13:51,959 --> 00:13:55,560
目標状態のすぐ近くにいて、

341
00:13:55,560 --> 00:13:57,600
その良い状態に向かっていく最後の時間ステップだけを計画しようとしていると想像してください。

342
00:13:57,600 --> 00:13:59,519


343
00:13:59,519 --> 00:14:01,740
大文字 T マイナス 1 である最後のタイム ステップについて決定を下そうとしていますが、次

344
00:14:01,740 --> 00:14:05,459
の

345
00:14:05,459 --> 00:14:08,880
タイム ステップまたは最後の目標状態への予測は、

346
00:14:08,880 --> 00:14:09,839


347
00:14:09,839 --> 00:14:11,880


348
00:14:11,880 --> 00:14:14,160
この遷移を使用して世界のこのモデルにアクセスできるため、完了できます。

349
00:14:14,160 --> 00:14:16,079


350
00:14:16,079 --> 00:14:18,600
能動的推論におけるダイナミクスまたは B 行列なので、

351
00:14:18,600 --> 00:14:21,180
サブ問題であるこの単一のタイム ステップについて、えー、

352
00:14:21,180 --> 00:14:24,060
実際に期待される自由エネルギーの表を評価していることになります。これにより、

353
00:14:24,060 --> 00:14:26,100
たとえばこの観測が行われている場合に、

354
00:14:26,100 --> 00:14:28,019


355
00:14:28,019 --> 00:14:31,740
最後に何を行うべきかを示します。 時間ステップと

356
00:14:31,740 --> 00:14:34,440
基本的には、状態空間または観測空間でこれを行うことができます。

357
00:14:34,440 --> 00:14:36,540
したがって、これは、

358
00:14:36,540 --> 00:14:39,120
a 行列と D

359
00:14:39,120 --> 00:14:41,699
行列を一緒に使用して行うことができます。どちらの

360
00:14:41,699 --> 00:14:44,579
方法でも計画を正しく

361
00:14:44,579 --> 00:14:46,260


362
00:14:46,260 --> 00:14:48,839
行うことができます。問題は、 あなたが考えているかもしれない最後の時間の

363
00:14:48,839 --> 00:14:50,940
ステップ、

364
00:14:50,940 --> 00:14:52,440


365
00:14:52,440 --> 00:14:54,600
私が最後の時間のステップにいるとどうやってわかるのですか、それはあなたが

366
00:14:54,600 --> 00:14:58,699


367
00:15:09,720 --> 00:15:12,839
ごめんなさいと想像することだけですちょうど最後に私たちが一瞬聞いたのは、

368
00:15:12,839 --> 00:15:15,540
すべては想像することです、

369
00:15:15,540 --> 00:15:18,060
はい、だからそこから始めてください、それは すべては

370
00:15:18,060 --> 00:15:19,860
想像すること

371
00:15:19,860 --> 00:15:22,139
です。それで、接続に問題があったとしても、

372
00:15:22,139 --> 00:15:23,699
数秒だけなら大丈夫です。

373
00:15:23,699 --> 00:15:25,199
それから、ああ、

374
00:15:25,199 --> 00:15:28,260
申し訳ありませんが、それで、

375
00:15:28,260 --> 00:15:30,899
私が言いたいのは、あなたは、

376
00:15:30,899 --> 00:15:32,880


377
00:15:32,880 --> 00:15:35,519
もし接続に問題があったらどうするかを想像しようとしているということです。 計画地平線の最後のタイム ステップであるタイムキャピタル T マイナス 1 にいます。

378
00:15:35,519 --> 00:15:37,560


379
00:15:37,560 --> 00:15:40,260
そのタイム ステップにいる場合は

380
00:15:40,260 --> 00:15:42,199
どうすればよいですか。この表は、その

381
00:15:42,199 --> 00:15:45,480
ようなすべてのシナリオを表しています。つまり、

382
00:15:45,480 --> 00:15:49,800
時刻 T マイナス 1 の観測 3 に私がいた場合、

383
00:15:49,800 --> 00:15:52,680
何が起こるかということです。 私はやりますか、そしてこの量はここにあります、

384
00:15:52,680 --> 00:15:54,720
私はリスク項または目的の項だけを考えています、

385
00:15:54,720 --> 00:15:56,279


386
00:15:56,279 --> 00:15:57,720
えー、そして

387
00:15:57,720 --> 00:16:01,560
この項はその方針を表します、そして

388
00:16:01,560 --> 00:16:03,540
これを

389
00:16:03,540 --> 00:16:06,180
時間 T マイナス 1 まで逆方向に実行したら

390
00:16:06,180 --> 00:16:08,699
どうなるでしょうか。 時刻がああ、

391
00:16:08,699 --> 00:16:12,300
大文字 T マイナス 1 の場合、このテーブルは

392
00:16:12,300 --> 00:16:14,880
大文字 T マイナス 2 で何をすべきかを知らせることができます。

393
00:16:14,880 --> 00:16:16,920
つまり、

394
00:16:16,920 --> 00:16:19,320
私がやっていることは、時間をかけて計画を立てるのではなく、基本的に、計画の大文字 T を

395
00:16:19,320 --> 00:16:22,019
固定するだけで多くのテーブルを積み重ねることです。

396
00:16:22,019 --> 00:16:25,019


397
00:16:25,019 --> 00:16:29,279
このようなスタックテーブルをすべて持っている

398
00:16:29,279 --> 00:16:31,800
ので、基本的に私にできることは、それらを使用して

399
00:16:31,800 --> 00:16:33,899
時間の経過とともに意思決定を進めることです。そして

400
00:16:33,899 --> 00:16:35,940
私たちが観察したことは、このアイデアが

401
00:16:35,940 --> 00:16:38,519
機能するということです。

402
00:16:38,519 --> 00:16:40,259
えー、予想される自由エネルギーを逆方向に計算できます。えー、

403
00:16:40,259 --> 00:16:43,019


404
00:16:43,019 --> 00:16:46,920
それらをサブ問題として考慮して段階的に実行できます。

405
00:16:46,920 --> 00:16:49,079
基本的な違いは、

406
00:16:49,079 --> 00:16:51,600
高度な推論では、

407
00:16:51,600 --> 00:16:54,959
時間小さい T での期待される自由エネルギーを計算する場合、

408
00:16:54,959 --> 00:16:57,540


409
00:16:57,540 --> 00:16:59,880
時間チームに 1 を加えたときの期待される自由エネルギーがわからないため、これが

410
00:16:59,880 --> 00:17:01,920
3 つの検索になるため、

411
00:17:01,920 --> 00:17:04,319
これを最初に計算する必要があるということです。

412
00:17:04,319 --> 00:17:06,839
t プラス 1 を計算するには t プラス 2 などが必要です

413
00:17:06,839 --> 00:17:09,000
が、ここでは時間を逆算して計算しているため、

414
00:17:09,000 --> 00:17:11,339


415
00:17:11,339 --> 00:17:13,559
p プラス 1 の予想される自由エネルギーが何かはすでにわかっており

416
00:17:13,559 --> 00:17:16,020
、基本的には

417
00:17:16,020 --> 00:17:17,520
同じ方程式であることがわかります。 あなたは

418
00:17:17,520 --> 00:17:20,900
それを時間を逆行して、

419
00:17:20,900 --> 00:17:23,520
洗練された推論で絵的に

420
00:17:23,520 --> 00:17:25,619
研究しようとしていますが、

421
00:17:25,619 --> 00:17:27,660
動的計画法アルゴリズムでは、

422
00:17:27,660 --> 00:17:30,120


423
00:17:30,120 --> 00:17:32,940
テーブルを使用して逆方向に計画を実行しており、計画を考慮すると、

424
00:17:32,940 --> 00:17:35,520


425
00:17:35,520 --> 00:17:38,160
私たちが持っている問題にはHorizo​​nで十分です エージェントが時間内

426
00:17:38,160 --> 00:17:40,860
に前方に最適なアクションを実行できることがわかりました。

427
00:17:40,860 --> 00:17:44,340
そのため、この論文では、

428
00:17:44,340 --> 00:17:46,500


429
00:17:46,500 --> 00:17:49,020
この

430
00:17:49,020 --> 00:17:50,880
時間内後方計画を使用したシーケンシャル形式 DPS 用の 1 つのアルゴリズムも提案しています。また、

431
00:17:50,880 --> 00:17:54,059
グリッド スペースのシミュレーションをスケールアップすることができました。

432
00:17:54,059 --> 00:17:56,240
以前は

433
00:17:56,240 --> 00:17:59,340
ニューラル ネットワークなしで対話可能でした

434
00:17:59,340 --> 00:18:01,080
えーっと、それが最初の解決策だったので、

435
00:18:01,080 --> 00:18:03,840
2 番目の解決策は、

436
00:18:03,840 --> 00:18:06,000
えー、最初の解決策では、

437
00:18:06,000 --> 00:18:07,980
この過去のプライベート

438
00:18:07,980 --> 00:18:09,539
参照のみを取得するように修正されました。他の

439
00:18:09,539 --> 00:18:10,919
情報は取得できません。

440
00:18:10,919 --> 00:18:12,480
最終的な目標は状態であり、

441
00:18:12,480 --> 00:18:15,120
得られるのはあなた

442
00:18:15,120 --> 00:18:18,240
が学んだ環境のモデルだけであり、

443
00:18:18,240 --> 00:18:21,059
基本的には決断を下す必要がありますが、もちろん

444
00:18:21,059 --> 00:18:22,799
2 番目の解決策は、許可されている場合は、私たちが経験したような意味のあるプライドの好みを

445
00:18:22,799 --> 00:18:24,600
学ぼうとすることです。

446
00:18:24,600 --> 00:18:26,100


447
00:18:26,100 --> 00:18:28,620
前のスライドで見たように、

448
00:18:28,620 --> 00:18:31,740


449
00:18:31,740 --> 00:18:33,960
他の状態に関する情報も含まれていますが、

450
00:18:33,960 --> 00:18:35,400
それを正しく学ぶにはどうすればよいでしょうか。つまり、

451
00:18:35,400 --> 00:18:38,039
最適制御の文献からの独創的な研究で、

452
00:18:38,039 --> 00:18:40,440


453
00:18:40,440 --> 00:18:43,380
最適なアクションの効率的な計算について説明されており

454
00:18:43,380 --> 00:18:45,900
、その研究には、

455
00:18:45,900 --> 00:18:47,760
私たちの研究と同様の量が含まれています。 事前の好みは

456
00:18:47,760 --> 00:18:49,500
好感度関数と呼ばれます。

457
00:18:49,500 --> 00:18:52,200
たとえば、このグリッド ワールドでは、

458
00:18:52,200 --> 00:18:54,240
暗い色のほうが優先されます。

459
00:18:54,240 --> 00:18:56,400
つまり、これが最終的なゴールド状態を超えた場合、

460
00:18:56,400 --> 00:18:58,740
この論文のエージェントが

461
00:18:58,740 --> 00:19:01,980
やろうとしていること、または

462
00:19:01,980 --> 00:19:04,580
この論文の前述の学習方法は次のとおりです。 やろうとしているのは、この

463
00:19:04,580 --> 00:19:06,900
満足度関数を

464
00:19:06,900 --> 00:19:09,059
可能な限り最適に学習することです。この論文で示されたことは、

465
00:19:09,059 --> 00:19:12,660


466
00:19:12,660 --> 00:19:15,179
特定の学習ルールを使用して満足度関数を学習しようとすると、

467
00:19:15,179 --> 00:19:18,120
計算的には、優れた

468
00:19:18,120 --> 00:19:20,340
Q 学習よりもはるかに効率的であるということです。

469
00:19:20,340 --> 00:19:22,919
強化学習アルゴリズムはよく知られている

470
00:19:22,919 --> 00:19:24,960
ため、Q 学習は

471
00:19:24,960 --> 00:19:27,179
計算的に最適なアルゴリズムとしてよく知られています

472
00:19:27,179 --> 00:19:29,520
が、この論文では、

473
00:19:29,520 --> 00:19:31,140


474
00:19:31,140 --> 00:19:32,880
この種の満足度関数を学習するための特定の学習ルールの方がはるかに

475
00:19:32,880 --> 00:19:35,539
高速であり、この近似

476
00:19:35,539 --> 00:19:38,460
値は最適満足度関数との違いを表しています。

477
00:19:38,460 --> 00:19:40,559


478
00:19:40,559 --> 00:19:42,480
望ましさ関数は私たちの事前の好みに他ならず、

479
00:19:42,480 --> 00:19:45,179


480
00:19:45,179 --> 00:19:48,600
前述したように、学習は

481
00:19:48,600 --> 00:19:50,100
Q学習でQ関数を学習するよりもはるかに効率的である

482
00:19:50,100 --> 00:19:53,039
ため、

483
00:19:53,039 --> 00:19:55,860
これは

484
00:19:55,860 --> 00:19:57,600


485
00:19:57,600 --> 00:19:59,820
環境およびこの

486
00:19:59,820 --> 00:20:01,860
特定のグリッドワールド環境から得られる報酬に応じた特定の学習ルールです。

487
00:20:01,860 --> 00:20:03,539
最後のステップでのみ報酬を与えますが、

488
00:20:03,539 --> 00:20:05,220
これはまばらな友人の好みと同様で、

489
00:20:05,220 --> 00:20:08,580
エージェントは基本的に、

490
00:20:08,580 --> 00:20:11,400
最終目標状態に到達するまで報酬を受け取りません。

491
00:20:11,400 --> 00:20:14,760
この学習ルールには、

492
00:20:14,760 --> 00:20:17,640


493
00:20:17,640 --> 00:20:20,100


494
00:20:20,100 --> 00:20:22,980
この速度の速さや遅さを制御するパラメーター ETA があります。 学習が発生するので、基本的に

495
00:20:22,980 --> 00:20:24,200


496
00:20:24,200 --> 00:20:26,880
この学習パラメーター Rita の効果を研究しようとします

497
00:20:26,880 --> 00:20:29,340
が、観察されたことは、

498
00:20:29,340 --> 00:20:32,400


499
00:20:32,400 --> 00:20:35,059


500
00:20:35,059 --> 00:20:38,700
この学習パラメーターが非常に堅牢であり、この学習パラメーターの値が変動しても以前の好みを確実に学習できるということです。

501
00:20:38,700 --> 00:20:41,580


502
00:20:41,580 --> 00:20:43,620
有意義な

503
00:20:43,620 --> 00:20:45,539
過去のパフォーマンスを時間の経過とともに非常に速く学習し

504
00:20:45,539 --> 00:20:48,600
、そのような有意義なプライム設定を使用すると、

505
00:20:48,600 --> 00:20:50,700
エージェントは

506
00:20:50,700 --> 00:20:53,580
多くの計画を立てる必要がなく、非常に短い時間で最適な

507
00:20:53,580 --> 00:20:56,160
行動または目的のある行動を管理できます

508
00:20:56,160 --> 00:20:59,700
計画の範囲と

509
00:20:59,700 --> 00:21:02,460
これら 2 つのソリューションがあれば、次のことが可能です 意思決定の

510
00:21:02,460 --> 00:21:04,679
ためのアクティブ推論アルゴリズムをスケールアップし

511
00:21:04,679 --> 00:21:07,919
、

512
00:21:07,919 --> 00:21:11,400
計算効率について話します えー、

513
00:21:11,400 --> 00:21:13,320
動的計画法が

514
00:21:13,320 --> 00:21:16,440
30 のタイム ステップを将来に植え付けることができることがわかりました えー、

515
00:21:16,440 --> 00:21:18,360


516
00:21:18,360 --> 00:21:21,120


517
00:21:21,120 --> 00:21:23,700
高度な計算の 10 の 68 乗と比較すると、わずか 1,000 の計算量で済みます 推論

518
00:21:23,700 --> 00:21:26,880
と、事前の優先順位を学習する 2 番目の方法は、

519
00:21:26,880 --> 00:21:29,580
アクティブ

520
00:21:29,580 --> 00:21:32,340
推論と呼ばれるもので、1 ステップ先を計画するだけでよいため、

521
00:21:32,340 --> 00:21:34,740


522
00:21:34,740 --> 00:21:36,919
その意味では計算効率がはるかに高くなります

523
00:21:36,919 --> 00:21:39,659
が、学習する必要があるため、DPFE

524
00:21:39,659 --> 00:21:41,640
メソッドでは学習していません。 私たちは

525
00:21:41,640 --> 00:21:43,799
好みに応じてスポットを使用し、徹底的な計画を実行します。

526
00:21:43,799 --> 00:21:44,520


527
00:21:44,520 --> 00:21:46,500
もう 1 つの方法では、

528
00:21:46,500 --> 00:21:48,240
エージェントに

529
00:21:48,240 --> 00:21:50,280
好みに応じてこれを学習させますが、エージェントは時間内に何をすべきかを非常にグラフィカルに正確に

530
00:21:50,280 --> 00:21:53,280
認識しているため、計画を大幅に節約できます。

531
00:21:53,280 --> 00:21:57,299


532
00:21:57,299 --> 00:22:00,179
えー、

533
00:22:00,179 --> 00:22:01,799
DPFE メソッドは非常に

534
00:22:01,799 --> 00:22:04,020
計算効率が高く、

535
00:22:04,020 --> 00:22:06,600
時間に対してプロットすると、AI 50 で

536
00:22:06,600 --> 00:22:08,520
1 つのメソッドと同等であることがわかります。

537
00:22:08,520 --> 00:22:10,740
えー、基本的に計算量が

538
00:22:10,740 --> 00:22:12,659
安く、

539
00:22:12,659 --> 00:22:16,220
ええ、そのため、非常に魅力的にうまくスケールされます。

540
00:22:16,220 --> 00:22:19,860


541
00:22:19,860 --> 00:22:21,720


542
00:22:21,720 --> 00:22:24,120
環境で

543
00:22:24,120 --> 00:22:27,600
テストしたので、これらのメソッドは、

544
00:22:27,600 --> 00:22:28,380


545
00:22:28,380 --> 00:22:31,020
たとえば 900 の州のような非常に巨大な州空間で、

546
00:22:31,020 --> 00:22:32,000


547
00:22:32,000 --> 00:22:33,840


548
00:22:33,840 --> 00:22:36,120


549
00:22:36,120 --> 00:22:38,640
通常よく見られるアクティブな影響力に関する文献でたとえば 5 または 10 の次元を持つ州空間と比較して、

550
00:22:38,640 --> 00:22:40,559


551
00:22:40,559 --> 00:22:43,200
ええと、

552
00:22:43,200 --> 00:22:44,760
私たちがしていることを強調したいと思います。 ここではニューラル ネットワークを使用していません。

553
00:22:44,760 --> 00:22:47,039


554
00:22:47,039 --> 00:22:49,740
説明可能なアクティブ推論エージェントが

555
00:22:49,740 --> 00:22:52,200
必要なすべての行列乗算を行っている

556
00:22:52,200 --> 00:22:53,820
ため、

557
00:22:53,820 --> 00:22:55,140


558
00:22:55,140 --> 00:22:56,220


559
00:22:56,220 --> 00:22:58,620


560
00:22:58,620 --> 00:23:00,179
これらの

561
00:23:00,179 --> 00:23:02,280
アルゴリズムで行われているすべての計算にアクセスでき、説明可能です。最初にこれらのグリッドでテストしたときに、

562
00:23:02,280 --> 00:23:04,559
これを検証しました。

563
00:23:04,559 --> 00:23:06,780
アンダーステートのある小さなグリッド上で、

564
00:23:06,780 --> 00:23:08,580


565
00:23:08,580 --> 00:23:11,220


566
00:23:11,220 --> 00:23:12,780
キュー学習

567
00:23:12,780 --> 00:23:15,059
や dynaq dynacy などのベンチマーク強化学習アルゴリズムと比較すると、モデルベースの

568
00:23:15,059 --> 00:23:17,760
強化学習アルゴリズムであることがわかりました。

569
00:23:17,760 --> 00:23:20,280
新しく提案されたエージェントで

570
00:23:20,280 --> 00:23:24,419
ある DPFE と aif を比較したところ、非常に優れたパフォーマンスが確認されました

571
00:23:24,419 --> 00:23:27,900
。  aif エージェントの方がわずかに

572
00:23:27,900 --> 00:23:29,220
劣っています。これは、

573
00:23:29,220 --> 00:23:31,080
1 ステップ先を計画しているだけだからです。しかし、

574
00:23:31,080 --> 00:23:34,500
フルタイムで計画を行う DPFE エージェントは、

575
00:23:34,500 --> 00:23:36,419


576
00:23:36,419 --> 00:23:37,919
個人学習

577
00:23:37,919 --> 00:23:41,039
アルゴリズムのベンチマークと同じくらい優れたパフォーマンスを示しています。より

578
00:23:41,039 --> 00:23:44,640
大きくて弱いグリッドでテストし、

579
00:23:44,640 --> 00:23:47,100
確率論を導入したときに、

580
00:23:47,100 --> 00:23:49,620
エージェントが

581
00:23:49,620 --> 00:23:53,039


582
00:23:53,039 --> 00:23:54,480


583
00:23:54,480 --> 00:23:56,520
確率的なゴールド ステートに移動する必要があるという意味でのゴールド ステートなので、

584
00:23:56,520 --> 00:23:59,460
10 エピソードごとにゴールド ステートを変更しました。

585
00:23:59,460 --> 00:24:01,260
観察したところ、Dyna キューは

586
00:24:01,260 --> 00:24:04,140
bpfe エージェントよりも回復して実行するのに時間がかかることがわかりました。

587
00:24:04,140 --> 00:24:07,200


588
00:24:07,200 --> 00:24:09,059
この確率的環境における DPFE エージェントは、

589
00:24:09,059 --> 00:24:11,280


590
00:24:11,280 --> 00:24:13,620
ダイナシー エージェントよりも優れたパフォーマンスを示しました。また、

591
00:24:13,620 --> 00:24:16,500
AI フェーズと回復が非常に

592
00:24:16,500 --> 00:24:19,140
速くなっていることがわかりますが、他のエージェントほどではない

593
00:24:19,140 --> 00:24:22,500
ので、基本的にはそれが論文の結果であり、

594
00:24:22,500 --> 00:24:25,200
メソッド それでは、はい、

595
00:24:25,200 --> 00:24:27,960
ご清聴ありがとうございました。ディスカッションにオープンです。わかりました、

596
00:24:27,960 --> 00:24:30,380


597
00:24:31,640 --> 00:24:34,740
素晴らしい、すごい、

598
00:24:34,740 --> 00:24:36,360


599
00:24:36,360 --> 00:24:38,520
とてもクールです、それでは

600
00:24:38,520 --> 00:24:43,200
ディスカッションを始めますが、

601
00:24:43,200 --> 00:24:44,460


602
00:24:44,460 --> 00:24:47,280
誰かが最初に何か追加したい場合は、

603
00:24:47,280 --> 00:24:50,220
どのようにしてこのプロジェクトに取り組むようになったのですか、

604
00:24:50,220 --> 00:24:52,740
えー、勉強していましたか 能動

605
00:24:52,740 --> 00:24:54,720
推論で、この質問は

606
00:24:54,720 --> 00:24:57,900
興味深いと思いましたか、それとも

607
00:24:57,900 --> 00:25:00,179
計画に取り組んでいて、方法として能動推論に行き着いたのでしょうか。

608
00:25:00,179 --> 00:25:03,059


609
00:25:03,059 --> 00:25:05,159
ええと、私自身についての背景を少し説明します。

610
00:25:05,159 --> 00:25:08,400


611
00:25:08,400 --> 00:25:11,340
それで、私は学部時代と大学卒業後の両方で物理学を勉強しました。

612
00:25:11,340 --> 00:25:13,080
卒業後、私は

613
00:25:13,080 --> 00:25:15,120
ゲーム理論

614
00:25:15,120 --> 00:25:17,880
や再実行可能学習などに興味を持ち、

615
00:25:17,880 --> 00:25:20,880
アディル教授

616
00:25:20,880 --> 00:25:23,100
とマノージ教授と共同博士号取得のために参加しました。

617
00:25:23,100 --> 00:25:25,200
マノージ教授は制御理論の人で、

618
00:25:25,200 --> 00:25:28,140
神経科学者との取引がありました。

619
00:25:28,140 --> 00:25:30,600
PhD 私は

620
00:25:30,600 --> 00:25:34,020
能動推論の文献を読み始めて、

621
00:25:34,020 --> 00:25:37,260
それを問題に実装したいと思っていました。

622
00:25:37,260 --> 00:25:39,840
説明可能な能動推論に常に魅了されていました。えー、

623
00:25:39,840 --> 00:25:42,720


624
00:25:42,720 --> 00:25:44,700


625
00:25:44,700 --> 00:25:46,860
リスクと予期される曖昧さを最小限に抑えようとする期待される自由エネルギーのこのアイデアについては、

626
00:25:46,860 --> 00:25:49,740
エージェントを機能させるだけでなく、

627
00:25:49,740 --> 00:25:52,020
また、それらがどのように機能するかを知ることができるということは、

628
00:25:52,020 --> 00:25:54,419
アクティブな影響力において私を魅了したものであり、

629
00:25:54,419 --> 00:25:56,820
最初はそれらを実装しようとしましたが、

630
00:25:56,820 --> 00:26:00,179


631
00:26:00,179 --> 00:26:03,720


632
00:26:03,720 --> 00:26:06,419
同様のグリッドタスクと比較するカンファレンス論文が出版されており、その後、

633
00:26:06,419 --> 00:26:08,100
スケーリングの問題に直面しました。 アクティブ

634
00:26:08,100 --> 00:26:10,620
推論、そして洗練された推論に取り組み始めました。

635
00:26:10,620 --> 00:26:12,659


636
00:26:12,659 --> 00:26:15,539
ええと、基本的にこれらのメソッドは、マップを

637
00:26:15,539 --> 00:26:17,580
スケールアップしたいという必要性から生まれました。

638
00:26:17,580 --> 00:26:21,539
そして、深いアクティブ推論を使用する際には常にバスキープティカルを使用していました。

639
00:26:21,539 --> 00:26:22,919


640
00:26:22,919 --> 00:26:25,559


641
00:26:25,559 --> 00:26:28,020
ええと、使いたくなかったので

642
00:26:28,020 --> 00:26:30,539
計画を立てるためのニューラル ネットワーク 深層

643
00:26:30,539 --> 00:26:32,100
強化学習自体は

644
00:26:32,100 --> 00:26:34,140
巨大な分野なので、能動推論を

645
00:26:34,140 --> 00:26:37,080
スケーリングするだけなら、

646
00:26:37,080 --> 00:26:39,240
深層

647
00:26:39,240 --> 00:26:41,820
強化学習を行うだけでよいでしょう。それが私が

648
00:26:41,820 --> 00:26:43,860
考えたことです。そう、それが基本的な

649
00:26:43,860 --> 00:26:45,659
背景であり、そう、

650
00:26:45,659 --> 00:26:48,720
それがその方法です 結果はわかりました。

651
00:26:48,720 --> 00:26:50,880
最初にライブ チャットで質問に行きます

652
00:26:50,880 --> 00:26:52,559
。

653
00:26:52,559 --> 00:26:54,779


654
00:26:54,779 --> 00:26:57,720
あなたのプレゼンテーションには多くの内容が含まれていたため、おそらくさまざまな側面について話し合うことになります。NL

655
00:26:57,720 --> 00:27:01,980
ドーンは次のように書いています。

656
00:27:01,980 --> 00:27:04,620


657
00:27:04,620 --> 00:27:07,679
時間軸 ストアの Q を因数分解するためにどのような平均場

658
00:27:07,679 --> 00:27:11,039
近似が使用されましたか?

659
00:27:11,039 --> 00:27:13,020


660
00:27:13,020 --> 00:27:16,100


661
00:27:19,980 --> 00:27:23,040
それで、質問は

662
00:27:23,040 --> 00:27:24,299
[音楽]

663
00:27:24,299 --> 00:27:28,799
DPFE で期待される自由エネルギーに関するものだと思います。

664
00:27:28,799 --> 00:27:31,380
基本的にこれを計算する

665
00:27:31,380 --> 00:27:32,159


666
00:27:32,159 --> 00:27:35,279
ため、私のシミュレーションではこれに信念伝播を使用します。

667
00:27:35,279 --> 00:27:39,120
信念キュー、

668
00:27:39,120 --> 00:27:41,460
変分

669
00:27:41,460 --> 00:27:43,140
メッセージ パッシングやマージナル メッセージ

670
00:27:43,140 --> 00:27:47,279
パッシングを使用することもできますが、それは問題ではありませんが、

671
00:27:47,400 --> 00:27:50,580
この信念キューを手に入れたら、

672
00:27:50,580 --> 00:27:52,740
どうすればよいでしょう

673
00:27:52,740 --> 00:27:55,340


674
00:27:56,940 --> 00:27:59,900
か。

675
00:27:59,940 --> 00:28:04,260
それでは、しばらく Q を想像すると言うと、

676
00:28:04,260 --> 00:28:07,520
私が主に使用するものになります。 は 1 つのホット ベクトルなので、

677
00:28:07,520 --> 00:28:11,220
意思決定を行うには、能動推論の知覚ステップから抜け出すという信念を使用しますが、

678
00:28:11,220 --> 00:28:13,260


679
00:28:13,260 --> 00:28:16,380
想像してみると、

680
00:28:16,380 --> 00:28:18,720
これらは 1 つのホット ベクトルであるハード テーブルです。したがって、

681
00:28:18,720 --> 00:28:22,020


682
00:28:22,020 --> 00:28:25,380
生成モデルに 10 の状態があるとすると、ええと、あなたの

683
00:28:25,380 --> 00:28:27,900
あなたが使用するキューは、

684
00:28:27,900 --> 00:28:29,100


685
00:28:29,100 --> 00:28:32,220
計画のための正確な手がかりですが、

686
00:28:32,220 --> 00:28:33,840
意思決定には、認識ステップから得られる印象的な

687
00:28:33,840 --> 00:28:36,299
不正確な平均場近似キューを使用するので、

688
00:28:36,299 --> 00:28:38,460


689
00:28:38,460 --> 00:28:40,679
それが質問に答えているかどうかはわかりませんが、

690
00:28:40,679 --> 00:28:42,059


691
00:28:42,059 --> 00:28:44,880
おそらく私も考えたいです

692
00:28:44,880 --> 00:28:46,919
また、ステップに含まれる可能性のある近似についてさらに考える必要があります。

693
00:28:46,919 --> 00:28:49,200


694
00:28:49,200 --> 00:28:50,880


695
00:28:50,880 --> 00:28:53,700
そう、できます。必要に応じて、さらに詳しく書くこともできます。ええと、

696
00:28:53,700 --> 00:28:56,460


697
00:28:56,460 --> 00:29:00,419
好みの学習についてもう少し一般的に話しましょう。

698
00:29:00,419 --> 00:29:02,700
そこで、能動推論生成モデルのコンテキストで、次のようにします。

699
00:29:02,700 --> 00:29:05,940


700
00:29:05,940 --> 00:29:08,279
隠れた状態での観察の間の仲介があり

701
00:29:08,279 --> 00:29:10,020
、学習は

702
00:29:10,020 --> 00:29:12,480
非常に意味があります。それは世界の

703
00:29:12,480 --> 00:29:14,220
隠れた状態での観察の間のマッピングを学習することであり、

704
00:29:14,220 --> 00:29:15,779
その後、

705
00:29:15,779 --> 00:29:18,240


706
00:29:18,240 --> 00:29:20,399
行動の結果と物事が時間と好みによってどのように変化するかを学ぶことになります。

707
00:29:20,399 --> 00:29:21,419


708
00:29:21,419 --> 00:29:24,659
c

709
00:29:24,659 --> 00:29:27,960
c そして、これが非常に興味深い変数であることを強調しましたが、

710
00:29:27,960 --> 00:29:29,700


711
00:29:29,700 --> 00:29:31,340


712
00:29:31,340 --> 00:29:34,320


713
00:29:34,320 --> 00:29:38,100
私はどのようにして正しいことを学ぶのか、

714
00:29:38,100 --> 00:29:41,159


715
00:29:41,159 --> 00:29:42,960
適応的な好みを学習していることをどのようにして知ることができるのか、

716
00:29:42,960 --> 00:29:44,399


717
00:29:44,399 --> 00:29:46,200
そしてどのようにして学ぶのかに興味があります。 その好みの

718
00:29:46,200 --> 00:29:48,720
学習は認知的なオーバーヘッドや計算の複雑さを軽減しますか、

719
00:29:48,720 --> 00:29:50,820


720
00:29:50,820 --> 00:29:53,460
はい、素晴らしいですね、それで

721
00:29:53,460 --> 00:29:54,480


722
00:29:54,480 --> 00:29:57,179
祈りの好みを学ぼうとしているのであれば、それは

723
00:29:57,179 --> 00:29:59,940


724
00:29:59,940 --> 00:30:01,559
追いかけるべき何かがあるか、

725
00:30:01,559 --> 00:30:04,500
報酬のような最大化すべき何かがあることを前提としているので、

726
00:30:04,500 --> 00:30:06,779
これは強化

727
00:30:06,779 --> 00:30:08,340
学習で言えます 最大化しようとしている環境から来る明確な報酬があると設定し、

728
00:30:08,340 --> 00:30:09,840


729
00:30:09,840 --> 00:30:12,960


730
00:30:12,960 --> 00:30:15,000
このグリッドでは最後のステップでのみその報酬を得ると言いますが、

731
00:30:15,000 --> 00:30:17,220


732
00:30:17,220 --> 00:30:19,020
それがこの問題を難しくし

733
00:30:19,020 --> 00:30:22,500
ているものです。 時間

734
00:30:22,500 --> 00:30:25,140
ステップであれば、基本的に何をすべきかはわかります。

735
00:30:25,140 --> 00:30:28,020


736
00:30:28,020 --> 00:30:30,419
すべての時間ステップでその報酬を正しく追求

737
00:30:30,419 --> 00:30:32,880
するだけです。しかし、ここでは、その 1 つの報酬を得るために、たとえば 15 時間ステップ先に進む必要があるかもしれません。

738
00:30:32,880 --> 00:30:36,059
それは

739
00:30:36,059 --> 00:30:39,659
基本的に難しいことです。

740
00:30:39,659 --> 00:30:41,520
あなたがそうしているのは、私が

741
00:30:41,520 --> 00:30:43,020
事前の好みを学ぼうとしているからです

742
00:30:43,020 --> 00:30:44,820
ええと、環境が私が何をするか

743
00:30:44,820 --> 00:30:47,940


744
00:30:47,940 --> 00:30:49,919
気にしない場合

745
00:30:49,919 --> 00:30:52,200
、または私ができない場合には、環境に存在する報酬構造があるはずです 何が

746
00:30:52,200 --> 00:30:54,840
良いか悪いかを定義します その場合、

747
00:30:54,840 --> 00:30:56,340
事前の優先順位を正しく学習することに意味はありません。したがって、

748
00:30:56,340 --> 00:30:57,840
ここでは、

749
00:30:57,840 --> 00:30:59,399
報酬が

750
00:30:59,399 --> 00:31:01,559
スプライトの差の学習を制御するものであり、

751
00:31:01,559 --> 00:31:03,600
良いことに、たとえ

752
00:31:03,600 --> 00:31:06,539
最後のタイムステップでのみ報酬を取得したとしても、

753
00:31:06,539 --> 00:31:09,240
私には B 行列があり、 私はさまざまな状態

754
00:31:09,240 --> 00:31:11,340
から移行した経験があり、

755
00:31:11,340 --> 00:31:12,659


756
00:31:12,659 --> 00:31:14,760
最終的なゴールド状態に到達しました。

757
00:31:14,760 --> 00:31:16,860


758
00:31:16,860 --> 00:31:19,440
私たちが使用しているこのアルゴリズム、または

759
00:31:19,440 --> 00:31:21,539
使用している学習ルールは、

760
00:31:21,539 --> 00:31:23,820


761
00:31:23,820 --> 00:31:26,340
私が紹介した論文と同様の、

762
00:31:26,340 --> 00:31:27,539
望ましさ

763
00:31:27,539 --> 00:31:30,539
関数と呼ばれるものを最適制御で正確に学習しています。 この

764
00:31:30,539 --> 00:31:32,760
望ましさ関数があると仮定すると、

765
00:31:32,760 --> 00:31:36,120
おそらくこの状態から開始することを想像してください。その場合は、州を

766
00:31:36,120 --> 00:31:37,860


767
00:31:37,860 --> 00:31:40,399


768
00:31:40,399 --> 00:31:44,279


769
00:31:44,279 --> 00:31:46,620


770
00:31:46,620 --> 00:31:48,899
計画するだけでなく、その州の下にある指定された州の方が好ましいかどうかを決定するために最も近い隣人を確認するだけで済みます。

771
00:31:48,899 --> 00:31:50,520
代わりに時間を先に進め、それが

772
00:31:50,520 --> 00:31:52,380
私が取るべき最適な決断なので、

773
00:31:52,380 --> 00:31:54,059
このプライドの好みを学ぶことで、

774
00:31:54,059 --> 00:31:55,919


775
00:31:55,919 --> 00:31:57,419
今は最も近いものだけを見ているという意味で認知的負荷が軽減され、

776
00:31:57,419 --> 00:31:59,760


777
00:31:59,760 --> 00:32:01,799
この最終的な良好な状態まで計画を立てる必要がなくなりました

778
00:32:01,799 --> 00:32:04,799
そして、私はこれをできるだけ効率的に学びます。

779
00:32:04,799 --> 00:32:07,260
なぜなら、それは私たちが

780
00:32:07,260 --> 00:32:09,659
その堅牢性をテストした保証されたアルゴリズムであり

781
00:32:09,659 --> 00:32:13,320
、

782
00:32:13,320 --> 00:32:14,580
環境から得られる報酬によっても通知されるからです。

783
00:32:14,580 --> 00:32:15,659


784
00:32:15,659 --> 00:32:20,100
そうであれば、何か定義する方法があるのなら

785
00:32:20,100 --> 00:32:22,860
何が優先されますか、そうすると、

786
00:32:22,860 --> 00:32:24,840


787
00:32:24,840 --> 00:32:26,520


788
00:32:26,520 --> 00:32:28,559
このアルゴリズムによって意味のあるプライベートな友達を学習することが保証されます。したがって、

789
00:32:28,559 --> 00:32:31,559
最近傍

790
00:32:31,559 --> 00:32:34,260
とワンタイムステップ推論のみが

791
00:32:34,260 --> 00:32:37,320
使用されている場合、この種の

792
00:32:37,320 --> 00:32:39,360
優先学習エージェントが

793
00:32:39,360 --> 00:32:43,158
ローカル最適化にスタックするのを何が妨げるのでしょう

794
00:32:43,320 --> 00:32:47,520
か

795
00:32:47,520 --> 00:32:50,340
ここにはローカル オプティマはありません それが重要です ええと、

796
00:32:50,340 --> 00:32:52,860
なぜローカル オプティマがあるのでしょうか

797
00:32:52,860 --> 00:32:57,059
報酬を使用して学習している場合

798
00:32:57,059 --> 00:33:00,120
ええと、ローカル オプティマがある場合、

799
00:33:00,120 --> 00:33:02,159
ローカル オプティマでスタックすることになりますが、

800
00:33:02,159 --> 00:33:05,460
勝ちました ああ、

801
00:33:05,460 --> 00:33:07,440
あなたが学んでいるとしたら、これはこの方法です、なぜなら、

802
00:33:07,440 --> 00:33:08,760
あなたは自分自身の

803
00:33:08,760 --> 00:33:11,940
経験と、そのときの報酬をどのように得たかから学んでいるからです。

804
00:33:11,940 --> 00:33:14,220


805
00:33:14,220 --> 00:33:16,980


806
00:33:16,980 --> 00:33:17,760


807
00:33:17,760 --> 00:33:20,399
または、

808
00:33:20,399 --> 00:33:23,880
ローカルのオプティマなどを学習するときは、

809
00:33:23,880 --> 00:33:27,840


810
00:33:27,840 --> 00:33:30,179


811
00:33:30,179 --> 00:33:33,539


812
00:33:33,539 --> 00:33:36,779
遠位の目標へのスムーズなパスを確保できるように、環境設定をバックフィルするようなものです。

813
00:33:36,779 --> 00:33:39,480
アニメーションではバック

814
00:33:39,480 --> 00:33:42,299
フィーリングのように見えますが、

815
00:33:42,299 --> 00:33:44,279
実際はそうです。 あなたの経験からそれを学びました、

816
00:33:44,279 --> 00:33:45,360


817
00:33:45,360 --> 00:33:46,620


818
00:33:46,620 --> 00:33:49,980
ええと、時間的には正しいので、

819
00:33:49,980 --> 00:33:51,480
この状態から状態に移行したときに報酬を観察しました、

820
00:33:51,480 --> 00:33:53,100


821
00:33:53,100 --> 00:33:55,860
それでこれは良いに違いありません、それでは次のタイムステップで

822
00:33:55,860 --> 00:33:58,559
私はオーケーと言います、この日付は

823
00:33:58,559 --> 00:34:00,419
私をそこに連れて行く責任があります これも良いかもしれませんが、

824
00:34:00,419 --> 00:34:03,120
他のものほど良いわけではないので、逆方向に

825
00:34:03,120 --> 00:34:05,100
学習しているように見えますが、実際

826
00:34:05,100 --> 00:34:07,799


827
00:34:07,799 --> 00:34:12,000


828
00:34:13,500 --> 00:34:15,119


829
00:34:15,119 --> 00:34:16,980
には、実際のええと t プラス 1 の経験から学習しています。

830
00:34:16,980 --> 00:34:20,339


831
00:34:20,339 --> 00:34:21,300


832
00:34:21,300 --> 00:34:24,119
ええと、これはそれを行う学習ルールな

833
00:34:24,119 --> 00:34:25,859
ので、もっと体系的に答える方法がわかりません、ええと、ええと、

834
00:34:25,859 --> 00:34:29,219


835
00:34:29,219 --> 00:34:33,000
現実世界の状況や現実の

836
00:34:33,000 --> 00:34:35,399
どのような状況で、

837
00:34:35,399 --> 00:34:37,560
この種の好みの学習が

838
00:34:37,560 --> 00:34:40,080
起こっていると思いますか、

839
00:34:40,080 --> 00:34:41,159
ええ、

840
00:34:41,159 --> 00:34:43,020
素晴らしいです 質問そうです

841
00:34:43,020 --> 00:34:46,080
か、私たちの研究室から出た論文が 1 つあります。

842
00:34:46,080 --> 00:34:48,659
ニューロンが

843
00:34:48,659 --> 00:34:51,359
ポンウムのゲームを学習しているところです。その

844
00:34:51,359 --> 00:34:52,980
論文が

845
00:34:52,980 --> 00:34:55,260
ディストブレインと呼ばれ、その装置が

846
00:34:55,260 --> 00:34:57,000
ストレインと呼ばれる場合、そして彼らが

847
00:34:57,000 --> 00:34:58,740
達成したことは、彼らが管理するということです。

848
00:34:58,740 --> 00:35:00,300


849
00:35:00,300 --> 00:35:03,420
シリコンチップ上でニューロンを培養し、

850
00:35:03,420 --> 00:35:04,020


851
00:35:04,020 --> 00:35:08,520


852
00:35:08,520 --> 00:35:11,400
ボールにうまくタックルしたとき、または

853
00:35:11,400 --> 00:35:13,880
ゲームをうまくプレイしたときに、良いフィードバック信号を与え、

854
00:35:13,880 --> 00:35:15,720


855
00:35:15,720 --> 00:35:18,119
ミスをしたときにショックを与えました。そして、私たちが見たのは、

856
00:35:18,119 --> 00:35:19,560


857
00:35:19,560 --> 00:35:22,260
論文に書かれているものです。 見てください、それは

858
00:35:22,260 --> 00:35:24,140
時間の経過とともに正しくゲームをプレイすることを学習します、

859
00:35:24,140 --> 00:35:27,359
そしてそのようなシナリオで

860
00:35:27,359 --> 00:35:29,880
私が世界で肯定的なことを言うことに出会ったら、私はうーん、

861
00:35:29,880 --> 00:35:33,359


862
00:35:33,359 --> 00:35:35,520
何が良いのか、私が

863
00:35:35,520 --> 00:35:37,380
過去に観察した状態などと関連付けることができるかもしれないと想像してください。 それで

864
00:35:37,380 --> 00:35:38,880
私は、

865
00:35:38,880 --> 00:35:39,660


866
00:35:39,660 --> 00:35:42,119
何が良いのか悪いのかを段階的に学びました。

867
00:35:42,119 --> 00:35:44,700
それは合理的な仮説です。だから、

868
00:35:44,700 --> 00:35:46,619


869
00:35:46,619 --> 00:35:47,220


870
00:35:47,220 --> 00:35:51,300
健康になりたいと言うのであれば、

871
00:35:51,300 --> 00:35:53,280
ジムに行くことを

872
00:35:53,280 --> 00:35:54,660


873
00:35:54,660 --> 00:35:57,000
良いことだと考えるかもしれません。それなら、

874
00:35:57,000 --> 00:35:59,099
ジムに歩くことも連想するかもしれません。 良い

875
00:35:59,099 --> 00:36:01,260
こととして、靴を履くことは良いことだと連想するかもしれません。だから、

876
00:36:01,260 --> 00:36:03,900


877
00:36:03,900 --> 00:36:04,920


878
00:36:04,920 --> 00:36:06,960
そのようにして事前の好みを学習することは

879
00:36:06,960 --> 00:36:10,079
理にかなっていると思いますが、これは次元の呪いの

880
00:36:10,079 --> 00:36:11,640


881
00:36:11,640 --> 00:36:12,480


882
00:36:12,480 --> 00:36:14,820
問題に対する計算上の解決策です

883
00:36:14,820 --> 00:36:17,040
が、これを実際の環境でテストしてください

884
00:36:17,040 --> 00:36:19,619
世界は間違いなく、ああ、私たちが何を

885
00:36:19,619 --> 00:36:21,599
すべきか、そして

886
00:36:21,599 --> 00:36:24,119
ええと、私もそれをするのを楽しみにしています、わかりました、

887
00:36:24,119 --> 00:36:25,800


888
00:36:25,800 --> 00:36:27,660


889
00:36:27,660 --> 00:36:29,760
あなたと一緒に現実世界の状況を実行してみて、これがつながるかどうかを確認させてください、

890
00:36:29,760 --> 00:36:32,040


891
00:36:32,040 --> 00:36:35,099
それで私たちは出頭したいのですが」

892
00:36:35,099 --> 00:36:38,280


893
00:36:38,280 --> 00:36:39,900
高い評価を獲得したエッセイを提出することで報酬が得られる

894
00:36:39,900 --> 00:36:42,599
ので、

895
00:36:42,599 --> 00:36:45,540
エッセイのアイデアを開始してから、

896
00:36:45,540 --> 00:36:48,839
望ましいまばらな結果

897
00:36:48,839 --> 00:36:51,180
である評価を確認するまでには多くのステップがあります。まあ、

898
00:36:51,180 --> 00:36:53,520
私たちはあらゆる種類のことを行い、

899
00:36:53,520 --> 00:36:55,260
その後、まあまあ学びます

900
00:36:55,260 --> 00:36:57,079
これは私が良い成績をとったもので、

901
00:36:57,079 --> 00:36:59,940
よくフォーマットされていました。それから、

902
00:36:59,940 --> 00:37:02,880
あなたは

903
00:37:02,880 --> 00:37:05,460
自分の好みの傘を広げて

904
00:37:05,460 --> 00:37:07,800
、

905
00:37:07,800 --> 00:37:10,140
それをうまくフォーマットすることができたのはなぜでしょうか。私は時間通りにそれをやりました。

906
00:37:10,140 --> 00:37:12,900
そして、あなたはそのような仕事をしてくれました。 これにより、

907
00:37:12,900 --> 00:37:16,579
将来的には、

908
00:37:16,579 --> 00:37:20,640


909
00:37:20,640 --> 00:37:23,099


910
00:37:23,099 --> 00:37:24,180


911
00:37:24,180 --> 00:37:26,400


912
00:37:26,400 --> 00:37:28,740


913
00:37:28,740 --> 00:37:31,740
考えられるすべてのツリー構造に対して 15 タイム ステップの推論を行う必要がなくなり、1 ステップの推論を正確に実行し、スキルとしてステップバイステップで実行できるようになります。

914
00:37:31,740 --> 00:37:35,180
あなたの

915
00:37:35,180 --> 00:37:39,240
身体化された学習を使って、

916
00:37:39,240 --> 00:37:43,680
問題の構造を正確に単純化しました。それで、

917
00:37:43,680 --> 00:37:45,540
計算の複雑さをもう一度見てもいいですか。

918
00:37:45,540 --> 00:37:47,220


919
00:37:47,220 --> 00:37:51,078


920
00:37:51,359 --> 00:37:54,300
そこで、CIF は古典的な能動

921
00:37:54,300 --> 00:37:56,760
推論の略で、計画の完全な地平線を実行します。

922
00:37:56,760 --> 00:37:58,560


923
00:37:58,560 --> 00:38:00,660
10 の 18 乗です。つまり、

924
00:38:00,660 --> 00:38:03,180
これは

925
00:38:03,180 --> 00:38:07,140
100 の州と 4 つの利用可能な

926
00:38:07,140 --> 00:38:09,960
アクションを含むこの特定のグリッドの例です。つまり、これは特殊なケース用であり

927
00:38:09,960 --> 00:38:12,119
、物事を大局的に理解するために数字を入れたかっただけなので、

928
00:38:12,119 --> 00:38:14,400
この

929
00:38:14,400 --> 00:38:16,500
特定の例では、

930
00:38:16,500 --> 00:38:18,960
それをポリシー空間でやります

931
00:38:18,960 --> 00:38:20,640
ええと、

932
00:38:20,640 --> 00:38:22,440


933
00:38:22,440 --> 00:38:25,380
計画の 1 ステップまたは

934
00:38:25,380 --> 00:38:28,380
高度な推論の 1 つのインスタンスで 10 乗 18 回の計算を実行する必要があります。

935
00:38:28,380 --> 00:38:30,900
ええと、状態空間を使用するため、さらに悪いことになります。 うまく

936
00:38:30,900 --> 00:38:34,560


937
00:38:34,560 --> 00:38:37,140
いかないので、この 3 行目は、

938
00:38:37,140 --> 00:38:39,540


939
00:38:39,540 --> 00:38:40,500


940
00:38:40,500 --> 00:38:42,599


941
00:38:42,599 --> 00:38:44,280


942
00:38:44,280 --> 00:38:47,400
完全な計画を立てなければならないのに、動的

943
00:38:47,400 --> 00:38:48,960
プログラミングを使用すると、たとえ一時的にでも、十分に 2 時間かかっても、高度な推論を行うのは非常に難しいということを示すはずでした。

944
00:38:48,960 --> 00:38:50,579


945
00:38:50,579 --> 00:38:52,500


946
00:38:52,500 --> 00:38:54,420
計画の全範囲を試行できます

947
00:38:54,420 --> 00:38:56,520
ええと、それはわずか 1,000 回の

948
00:38:56,520 --> 00:38:58,800
計算ですが、学習

949
00:38:58,800 --> 00:39:01,380
優先ではさらに低くなります ええと、

950
00:39:01,380 --> 00:39:04,520
1 回だけ実行すると、ステップ・アヘッド うわー、

951
00:39:04,520 --> 00:39:06,440
これはかなり

952
00:39:06,440 --> 00:39:06,839
[音楽] ええと、

953
00:39:06,839 --> 00:39:08,220


954
00:39:08,220 --> 00:39:12,000
かなりスタークで、分岐時間では

955
00:39:12,000 --> 00:39:15,480
アクティブな推論です 以前のモデルストリームでの作業で、

956
00:39:15,480 --> 00:39:17,640
いくつかの

957
00:39:17,640 --> 00:39:19,859
計算複雑さの推定も見ましたが、

958
00:39:19,859 --> 00:39:22,260
これらは非常に明確だと思います、

959
00:39:22,260 --> 00:39:25,020
えー、最初に考えたのは、

960
00:39:25,020 --> 00:39:28,820
高度化が安いとは誰も言っていないということです つまり、

961
00:39:28,820 --> 00:39:32,940
それがどれほど高価であるかは天文学的です、

962
00:39:32,940 --> 00:39:35,099


963
00:39:35,099 --> 00:39:37,380
ええと、おそらくたったの 2 つ、3 つ、

964
00:39:37,380 --> 00:39:38,880
4 つ、5 つが

965
00:39:38,880 --> 00:39:41,940
潜在的に取り組み始めているので、

966
00:39:41,940 --> 00:39:44,040


967
00:39:44,040 --> 00:39:45,720
計画の複雑さが

968
00:39:45,720 --> 00:39:50,040
根本的に増加しています。つまり、私たちが能動的推論インテリジェンスのアーキテクチャを想像するのと

969
00:39:50,040 --> 00:39:50,780


970
00:39:50,780 --> 00:39:52,460


971
00:39:52,460 --> 00:39:56,280
同じように考えると、教育学的には非常に興味深いものです

972
00:39:56,280 --> 00:39:57,660


973
00:39:57,660 --> 00:39:59,940


974
00:39:59,940 --> 00:40:01,560


975
00:40:01,560 --> 00:40:04,500
が、

976
00:40:04,500 --> 00:40:07,079
このことはそうではないことをかなり明確にします これを

977
00:40:07,079 --> 00:40:09,060
列挙するだけでできるものな

978
00:40:09,060 --> 00:40:10,859


979
00:40:10,859 --> 00:40:13,380
ので、機能する可能性があるニューラルネットワークのような、潜在的に効果的だがアドホックな複雑さ削減方法ではなく、これを計算複雑さ削減の原則的な方法に結び付けることであなたが行ったことは、非常に

980
00:40:13,380 --> 00:40:15,240
非常に創造的で重要だと思います

981
00:40:15,240 --> 00:40:19,520


982
00:40:19,520 --> 00:40:22,140


983
00:40:22,140 --> 00:40:25,440


984
00:40:25,440 --> 00:40:29,220


985
00:40:29,220 --> 00:40:31,320


986
00:40:31,320 --> 00:40:33,359
機能しているときは機能しますが、いったん

987
00:40:33,359 --> 00:40:35,280
肥大化し始めると、

988
00:40:35,280 --> 00:40:38,940
原則も

989
00:40:38,940 --> 00:40:40,680
有効性もありません。まさにそうです。

990
00:40:40,680 --> 00:40:43,200
洗練された推論です。

991
00:40:43,200 --> 00:40:45,240


992
00:40:45,240 --> 00:40:47,579
動的プログラミングと比較すると、それ自体の利点があることに注意しなければなりません。ええと、

993
00:40:47,579 --> 00:40:49,500


994
00:40:49,500 --> 00:40:51,839
将来の計画を立てるときに、

995
00:40:51,839 --> 00:40:53,520
すべての可能性を

996
00:40:53,520 --> 00:40:55,859
正しく考慮していますが、逆方向に計画している場合、

997
00:40:55,859 --> 00:40:58,380
たとえば、キュ​​ーベースの探索のようなものです。

998
00:40:58,380 --> 00:41:00,300


999
00:41:00,300 --> 00:41:02,280
ええと、どこかに行って

1000
00:41:02,280 --> 00:41:03,839
キューを取得してからプール状態に移動する必要がある場合は、逆

1001
00:41:03,839 --> 00:41:05,640
方向に計画してもうまくいかない可能性があるため、

1002
00:41:05,640 --> 00:41:06,960
これが何を意味しますか これは

1003
00:41:06,960 --> 00:41:09,900
私が受け取ったフィードバックの 1 つで、その

1004
00:41:09,900 --> 00:41:10,980
作業について

1005
00:41:10,980 --> 00:41:13,920
何人かの人たちと話し合ったので、それは

1006
00:41:13,920 --> 00:41:16,260
動的プログラミングについて注意すべきことですが、

1007
00:41:16,260 --> 00:41:18,359


1008
00:41:18,359 --> 00:41:19,920
友人よりも先に学ぶもう 1 つの場所です。

1009
00:41:19,920 --> 00:41:22,320
それは問題ないと思いますが、そう、動的

1010
00:41:22,320 --> 00:41:23,700
プログラミングは計算コストが低いですが、

1011
00:41:23,700 --> 00:41:26,460
それには独自の制限も伴います。

1012
00:41:26,460 --> 00:41:28,099


1013
00:41:28,099 --> 00:41:31,200


1014
00:41:31,200 --> 00:41:33,839
ベルマン最適性を使用した動的プログラミングでは

1015
00:41:33,839 --> 00:41:36,420
逆方向に解決しているので、

1016
00:41:36,420 --> 00:41:38,400
チェックメイトが必要なもののようなもので、

1017
00:41:38,400 --> 00:41:40,440
現在に向かって逆方向に作業していることをここで注意しなければなりません。

1018
00:41:40,440 --> 00:41:43,440
しかし、私たちは最終的に

1019
00:41:43,440 --> 00:41:46,440
反事実の

1020
00:41:46,440 --> 00:41:49,200
終点を探求することはありません 私たちが正確には興味

1021
00:41:49,200 --> 00:41:51,540
のない終点まで現在に遡ることはしません それが

1022
00:41:51,540 --> 00:41:52,980


1023
00:41:52,980 --> 00:41:55,619
それが非常に冷酷である理由ですが、

1024
00:41:55,619 --> 00:41:58,320
その一方で、それははるかに

1025
00:41:58,320 --> 00:42:00,420
制約的です うーん、はい、

1026
00:42:00,420 --> 00:42:02,280


1027
00:42:02,280 --> 00:42:06,960
はい、はい それで、私が最近考えているのは、

1028
00:42:06,960 --> 00:42:08,460


1029
00:42:08,460 --> 00:42:11,700
これら 2 つの組み合わせも考慮する必要があるということです、ああ、

1030
00:42:11,700 --> 00:42:14,160


1031
00:42:14,160 --> 00:42:17,400
そのような反事実的なことを無視する余裕がある場合は、

1032
00:42:17,400 --> 00:42:19,680
動的プログラミングを行うことができ

1033
00:42:19,680 --> 00:42:23,040
、おそらく 2 つのステップとして実行できるかもしれません。

1034
00:42:23,040 --> 00:42:25,380
計画を立てているので、それがキューベースの

1035
00:42:25,380 --> 00:42:28,980
探索である場合、キューに到達するのが

1036
00:42:28,980 --> 00:42:32,220
1 つのタスクで、キューから報酬までが

1037
00:42:32,220 --> 00:42:34,619
もう 1 つのタスクであるため、これら 2 つを分離して

1038
00:42:34,619 --> 00:42:37,460
動的プログラミングを使用できます。そのほうが計算

1039
00:42:37,460 --> 00:42:40,440
コストが安くなりますが、

1040
00:42:40,440 --> 00:42:43,079
このアイデアは維持されます。

1041
00:42:43,079 --> 00:42:45,480
ええと、そうしなければなりませんが、これらは

1042
00:42:45,480 --> 00:42:48,119
すべて将来のことです。

1043
00:42:48,119 --> 00:42:50,700
クールなことを考えているか、アレックスが書いたチャットから別の質問をしてください。

1044
00:42:50,700 --> 00:42:54,359


1045
00:42:54,359 --> 00:42:57,599


1046
00:42:57,599 --> 00:43:00,180
スケールが異なると異なる[音楽]ができるネストされたモデルに関するアイデアや開発はありますか?

1047
00:43:00,180 --> 00:43:02,330


1048
00:43:02,330 --> 00:43:02,640


1049
00:43:02,640 --> 00:43:03,780


1050
00:43:03,780 --> 00:43:06,540


1051
00:43:06,540 --> 00:43:07,800
実行速度です。では、

1052
00:43:07,800 --> 00:43:09,960
このモデルは

1053
00:43:09,960 --> 00:43:11,579
ネストされたモデルでどの

1054
00:43:11,579 --> 00:43:13,859
ように機能するのでしょうか。また、

1055
00:43:13,859 --> 00:43:16,380


1056
00:43:16,380 --> 00:43:19,500
実行速度とネストされたモデルの時間の前後でどのように考えればよいでしょうか。

1057
00:43:19,500 --> 00:43:21,780
それでは、ここでネストされたと言うときのような、もう少しコンテキストが必要になるかもしれません。

1058
00:43:21,780 --> 00:43:23,760


1059
00:43:23,760 --> 00:43:26,220
モデル ええと、

1060
00:43:26,220 --> 00:43:28,440
階層モデルのことですか はい、はい、それで多分、

1061
00:43:28,440 --> 00:43:30,780


1062
00:43:30,780 --> 00:43:34,619
観察のようなものです

1063
00:43:34,619 --> 00:43:38,760
私は速いペースに乗って、

1064
00:43:38,760 --> 00:43:41,160
それについて推論をしますが、その後、この

1065
00:43:41,160 --> 00:43:45,180
推論を使用して、ええと、ある種のことを行うか、多分

1066
00:43:45,180 --> 00:43:48,000
ええと、基本的にはこの

1067
00:43:48,000 --> 00:43:49,500
推論を使用します は

1068
00:43:49,500 --> 00:43:52,800
次の状態の観測値になり、それがネストされた

1069
00:43:52,800 --> 00:43:55,980
モデルの意味です。はい、実際にそれをタスクの観点から考えてから考える必要があるかもしれませんが、

1070
00:43:55,980 --> 00:43:58,140


1071
00:43:58,140 --> 00:44:00,300


1072
00:44:00,300 --> 00:44:02,339
正直なところ、

1073
00:44:02,339 --> 00:44:04,800
これがそのコンテキストでどのように機能するかは考えていませんでしたが、

1074
00:44:04,800 --> 00:44:08,760
タスクについて言えば、

1075
00:44:08,760 --> 00:44:10,319


1076
00:44:10,319 --> 00:44:13,140
ええと、ナビゲーションの観点から

1077
00:44:13,140 --> 00:44:15,119
考えると、部屋の環境について考えることができます。それが、

1078
00:44:15,119 --> 00:44:15,900


1079
00:44:15,900 --> 00:44:19,800
ええと、

1080
00:44:19,800 --> 00:44:21,480


1081
00:44:21,480 --> 00:44:24,000
これをどこに適用できるかを考えることができる例の 1 つです。

1082
00:44:24,000 --> 00:44:27,720
おそらくコレクションがあると想像してください。 エージェントとしては、

1083
00:44:27,720 --> 00:44:30,300
最初に

1084
00:44:30,300 --> 00:44:32,460
どの部屋に行くかを決めなければなりません。それから、

1085
00:44:32,460 --> 00:44:35,760
その家の中を移動する必要があります。基本的には、

1086
00:44:35,760 --> 00:44:39,060
推論を 2 段階で行うか、

1087
00:44:39,060 --> 00:44:41,940
意思決定を 2 段階で行うことができます。そうすると、

1088
00:44:41,940 --> 00:44:43,140
分離する必要があります。

1089
00:44:43,140 --> 00:44:45,240


1090
00:44:45,240 --> 00:44:47,460
部屋の中のこれらの段階での意思決定は、最適なパスをナビゲートするために動的プログラミングと言うことができます

1091
00:44:47,460 --> 00:44:49,740


1092
00:44:49,740 --> 00:44:52,980
が、常に

1093
00:44:52,980 --> 00:44:54,960
2 段階の

1094
00:44:54,960 --> 00:44:57,300
意思決定が必要で、

1095
00:44:57,300 --> 00:45:00,420
おそらく異なる方法が異なる段階でより効果的に機能します

1096
00:45:00,420 --> 00:45:04,260
が、これは次のとおりです。

1097
00:45:04,260 --> 00:45:06,180
ええと、ご存知のとおり、この

1098
00:45:06,180 --> 00:45:08,460
議論はよく考えられたタスクのほうが良いでしょう、

1099
00:45:08,460 --> 00:45:09,420


1100
00:45:09,420 --> 00:45:12,060


1101
00:45:12,060 --> 00:45:14,400


1102
00:45:14,400 --> 00:45:18,240


1103
00:45:18,240 --> 00:45:19,740
すべてに当てはまるかもしれない答えはありませんが、

1104
00:45:19,740 --> 00:45:21,119


1105
00:45:21,119 --> 00:45:24,359
ええ、私たちはほぼ正確にそのようなものを見てきたと思います。

1106
00:45:24,359 --> 00:45:27,300
階層的な同時

1107
00:45:27,300 --> 00:45:30,180
位置特定とマッピング

1108
00:45:30,180 --> 00:45:32,040
ロボット工学の場合は、アクティブな推論モデルが存在します。

1109
00:45:32,040 --> 00:45:33,900


1110
00:45:33,900 --> 00:45:37,140
そうですね、

1111
00:45:37,140 --> 00:45:39,500


1112
00:45:40,079 --> 00:45:42,660
これらの方法の 1 つを

1113
00:45:42,660 --> 00:45:45,420
入れ子になったモデルの 1 つのレベルで実行し、

1114
00:45:45,420 --> 00:45:48,359
別の計算方法を

1115
00:45:48,359 --> 00:45:50,280
別の

1116
00:45:50,280 --> 00:45:51,960
レベルに適用することは可能でしょうか。 または、1 つの場所で 1 つの利点を享受したい場合は、

1117
00:45:51,960 --> 00:45:54,480


1118
00:45:54,480 --> 00:45:56,579


1119
00:45:56,579 --> 00:46:00,180
1 つのシミュレーション内でもこれらのさまざまなメソッドを組み合わせて組み合わせることができますか、

1120
00:46:00,180 --> 00:46:03,540
はい、私は間違いなくそれが可能だと思います、うーん、

1121
00:46:03,540 --> 00:46:04,859


1122
00:46:04,859 --> 00:46:09,140
でもええ、おそらく試してみる必要があるので、

1123
00:46:09,180 --> 00:46:12,119
私のメソッドはすべて 1 つです ステージなので

1124
00:46:12,119 --> 00:46:14,819
階層モデルではありません

1125
00:46:14,819 --> 00:46:17,220
が、

1126
00:46:17,220 --> 00:46:19,260
不動産モデルでも機能すると強く信じています。たとえば、

1127
00:46:19,260 --> 00:46:20,520


1128
00:46:20,520 --> 00:46:22,200


1129
00:46:22,200 --> 00:46:24,660


1130
00:46:24,660 --> 00:46:26,940
先ほど述べた部屋の例で 2 つの意思決定方法を連携させることができます。

1131
00:46:26,940 --> 00:46:29,280
ああ、次のスライドに進んでいただけますか Z

1132
00:46:29,280 --> 00:46:31,819
学習は

1133
00:46:35,640 --> 00:46:38,760
クールですね、それで、ここと

1134
00:46:38,760 --> 00:46:41,220
素晴らしい論文で、あなたが合計でいくつか引用されていることに気付きました。

1135
00:46:41,220 --> 00:46:45,240
それで、この

1136
00:46:45,240 --> 00:46:48,060
Z 学習の導入は、

1137
00:46:48,060 --> 00:46:49,859
能動

1138
00:46:49,859 --> 00:46:52,260
推論分野に関しては目新しいものです。そのため、もう少し詳しく説明していただけますか

1139
00:46:52,260 --> 00:46:53,760


1140
00:46:53,760 --> 00:46:55,920
は Z

1141
00:46:55,920 --> 00:47:00,660
で、そのような

1142
00:47:00,660 --> 00:47:02,280
迅速な えー Q

1143
00:47:02,280 --> 00:47:03,240


1144
00:47:03,240 --> 00:47:06,119
に対する Z の改善を可能にするものは何ですか

1145
00:47:06,119 --> 00:47:06,900


1146
00:47:06,900 --> 00:47:10,619
はい、わかりました。それでは、

1147
00:47:10,619 --> 00:47:13,079
この論文についての文脈を説明します えー、

1148
00:47:13,079 --> 00:47:13,920


1149
00:47:13,920 --> 00:47:16,260
それは特定の分野

1150
00:47:16,260 --> 00:47:19,800
における意思決定の直線的な方法について話しています

1151
00:47:19,800 --> 00:47:21,720
mdp のクラスなので、

1152
00:47:21,720 --> 00:47:23,940


1153
00:47:23,940 --> 00:47:27,240
アクションが

1154
00:47:27,240 --> 00:47:29,220
アクセントではなく状態に基づいているマルコフ決定プロセスがあるとすると、たとえばグリッド タスクで発言のアクションを考えるときは、

1155
00:47:29,220 --> 00:47:31,560


1156
00:47:31,560 --> 00:47:32,760


1157
00:47:32,760 --> 00:47:35,160
左と右、そして北と

1158
00:47:35,160 --> 00:47:37,200
南と右について考えることになります。 私が北を取ると、

1159
00:47:37,200 --> 00:47:40,200
それは

1160
00:47:40,200 --> 00:47:42,720
状態空間に結果をもたらしますが、この論文では、

1161
00:47:42,720 --> 00:47:43,680


1162
00:47:43,680 --> 00:47:46,380


1163
00:47:46,380 --> 00:47:48,839
決定自体が状態に関する mdp のクラスを導入しているので、

1164
00:47:48,839 --> 00:47:49,920


1165
00:47:49,920 --> 00:47:54,180
私が状態 S1 と言っている場合、私の決定はそれに

1166
00:47:54,180 --> 00:47:56,280


1167
00:47:56,280 --> 00:47:58,740
依存します。 他の州に基づいて、私の

1168
00:47:58,740 --> 00:48:00,000
決定は次回私が行きたい他の州に基づいて行われるので、

1169
00:48:00,000 --> 00:48:02,160


1170
00:48:02,160 --> 00:48:04,020


1171
00:48:04,020 --> 00:48:05,880
これは本当に意思決定の定義です、ええと、

1172
00:48:05,880 --> 00:48:08,640


1173
00:48:08,640 --> 00:48:10,800


1174
00:48:10,800 --> 00:48:13,619
左、右、下、上のような他のものによる決定ではなく、州空間の観点からの意思決定です その

1175
00:48:13,619 --> 00:48:15,300


1176
00:48:15,300 --> 00:48:17,819
ようなMDPが存在し、

1177
00:48:17,819 --> 00:48:21,319
州に関して意思

1178
00:48:21,319 --> 00:48:23,520


1179
00:48:23,520 --> 00:48:27,000
決定を行うことができることを考えると、

1180
00:48:27,000 --> 00:48:30,900
問題がどんなに大きくても、計算的には線形複雑さで意思

1181
00:48:30,900 --> 00:48:33,480
決定を行うことができることが証明されました。そのためには、州に関して意思決定を行うことができるように

1182
00:48:33,480 --> 00:48:35,339


1183
00:48:35,339 --> 00:48:38,579
する必要があります 州にとって何が良いのか悪いのかを把握する

1184
00:48:38,579 --> 00:48:39,540


1185
00:48:39,540 --> 00:48:43,619
ため、このグリッドの例では、

1186
00:48:43,619 --> 00:48:46,440
C である望ましさ関数があります。C は、

1187
00:48:46,440 --> 00:48:48,240


1188
00:48:48,240 --> 00:48:50,700


1189
00:48:50,700 --> 00:48:54,180
状態がどれほど望ましいかを示す望ましさ関数であり、c 関数がある場合は、州が

1190
00:48:54,180 --> 00:48:56,579
示したことを示します。 それは、

1191
00:48:56,579 --> 00:48:57,359


1192
00:48:57,359 --> 00:48:59,280


1193
00:48:59,280 --> 00:49:01,079


1194
00:49:01,079 --> 00:49:03,540
MDP のこの特定のクラスについては線形の計算複雑さで意思決定を行うことができるため、MDP で状態に関して意思決定を行うことができる場合、

1195
00:49:03,540 --> 00:49:05,640


1196
00:49:05,640 --> 00:49:08,940
それは線形です、ええと、

1197
00:49:08,940 --> 00:49:11,700
そのことについては線形の複雑さだけです。

1198
00:49:11,700 --> 00:49:15,240
したがって、このグラフは基本的に、どのように実行できるかを比較しています。

1199
00:49:15,240 --> 00:49:19,260
望ましさの学習はより良い

1200
00:49:19,260 --> 00:49:22,200
、またはより速く行われます。つまり、Q 学習です。Q

1201
00:49:22,200 --> 00:49:23,880
学習に慣れている場合は、基本的にテーブルベースの

1202
00:49:23,880 --> 00:49:28,319
方法です。

1203
00:49:28,319 --> 00:49:30,780
状態が与えられたアクションの望ましさがあるので、状態が与えられたら

1204
00:49:30,780 --> 00:49:33,000
何をすべきかがわかります。

1205
00:49:33,000 --> 00:49:35,760
これは基本的にキュー行列ですが、

1206
00:49:35,760 --> 00:49:37,020
C の用語、

1207
00:49:37,020 --> 00:49:40,380
または C の学習方法

1208
00:49:40,380 --> 00:49:43,020
についてのみです えー、状態がどれほど望ましいかを学習しているだけです

1209
00:49:43,020 --> 00:49:44,819


1210
00:49:44,819 --> 00:49:46,980
アクションの概念はありません、

1211
00:49:46,980 --> 00:49:49,560
これはまさに私たちの事前の

1212
00:49:49,560 --> 00:49:51,839
好みです えー、能動推論

1213
00:49:51,839 --> 00:49:54,000
では、

1214
00:49:54,000 --> 00:49:55,560
数値化する分布です 望ましい

1215
00:49:55,560 --> 00:49:57,960
状態と望ましくない状態がどの

1216
00:49:57,960 --> 00:50:00,119
ように正しいのか、

1217
00:50:00,119 --> 00:50:02,579


1218
00:50:02,579 --> 00:50:05,099
C マトリックスをより速く学習できることが証明されたことを考えると、

1219
00:50:05,099 --> 00:50:07,980
それが最適であり、Q を学習するよりもはるかに速いのであれば、

1220
00:50:07,980 --> 00:50:10,079


1221
00:50:10,079 --> 00:50:13,319
同じ方法で C を学習してみてもいいのではないかと思いました。  C は

1222
00:50:13,319 --> 00:50:16,400
この論文で学習されており、

1223
00:50:16,400 --> 00:50:19,319
これを使用すると、

1224
00:50:19,319 --> 00:50:21,839
C の学習にも同様の学習ルールがあり、

1225
00:50:21,839 --> 00:50:24,119
その論文では集合学習と呼ばれています。

1226
00:50:24,119 --> 00:50:25,800
学習しようとしたところ、

1227
00:50:25,800 --> 00:50:28,200


1228
00:50:28,200 --> 00:50:30,540
有用な Pride 設定を非常に速く学習することが分かりました。 それは私に

1229
00:50:30,540 --> 00:50:32,520
決定を下させるか、アクティブな

1230
00:50:32,520 --> 00:50:34,619
影響力のあるエージェントに決定を下させます

1231
00:50:34,619 --> 00:50:38,460
ええと、計画の 1 つのタイムステップだけで、ええと、

1232
00:50:38,460 --> 00:50:40,859
基本的にはそれで

1233
00:50:40,859 --> 00:50:42,240
話が進んだので、ええと、

1234
00:50:42,240 --> 00:50:43,440


1235
00:50:43,440 --> 00:50:47,460
C が簡単に学習できるというこのアイデアは

1236
00:50:47,460 --> 00:50:50,240
その論文にあります、わかりました、

1237
00:50:52,020 --> 00:50:54,780
ええともう一度言いましょう これは能動推論の

1238
00:50:54,780 --> 00:50:56,420
非常に興味深い拡張だと思うので、

1239
00:50:56,420 --> 00:50:59,099


1240
00:50:59,099 --> 00:51:02,280


1241
00:51:02,280 --> 00:51:04,200


1242
00:51:04,200 --> 00:51:06,480
前に説明したすべての理由から C を学習するつもりです。トドロフが

1243
00:51:06,480 --> 00:51:09,619


1244
00:51:09,619 --> 00:51:13,740
Z 学習を提示した方法と同様に、

1245
00:51:13,740 --> 00:51:18,540


1246
00:51:18,540 --> 00:51:21,059
学習の代わりに Z 学習で C を学習するつもりです。

1247
00:51:21,059 --> 00:51:23,460
ええと、たとえば、アクションの事後確率を更新し、

1248
00:51:23,460 --> 00:51:26,160


1249
00:51:26,160 --> 00:51:28,380
アクションを使用して

1250
00:51:28,380 --> 00:51:31,339
観測値を出力する状態間を移動します。

1251
00:51:31,339 --> 00:51:35,760
そうですね、

1252
00:51:35,760 --> 00:51:37,319
アクションを状態

1253
00:51:37,319 --> 00:51:39,300
に焼き付ける

1254
00:51:39,300 --> 00:51:41,420
ので、実際に

1255
00:51:41,420 --> 00:51:44,280
状態間の遷移を

1256
00:51:44,280 --> 00:51:48,200
直接学習します。そう、

1257
00:51:51,540 --> 00:51:53,880
そしてこれを接続します フリー

1258
00:51:53,880 --> 00:51:56,040
エネルギー原理と、それが

1259
00:51:56,040 --> 00:51:57,660
能動推論でどのように作用するかについて、

1260
00:51:57,660 --> 00:51:59,220


1261
00:51:59,220 --> 00:52:00,559
ええと、

1262
00:52:00,559 --> 00:52:03,780
C は、それについての 1 つの考え方である単なる望ましさ関数ではなく、

1263
00:52:03,780 --> 00:52:05,280


1264
00:52:05,280 --> 00:52:07,559
それが選好と呼ばれる理由ですが、

1265
00:52:07,559 --> 00:52:11,640
C は私たちの期待でもあり、それが

1266
00:52:11,640 --> 00:52:14,400
可能にするものです 私たちは一方で、エージェントが行きたい場所に到達するような

1267
00:52:14,400 --> 00:52:16,800
報酬と好みの学習に慣れた言語を使用します

1268
00:52:16,800 --> 00:52:18,960


1269
00:52:18,960 --> 00:52:21,900
が、

1270
00:52:21,900 --> 00:52:25,500
期待に基づいた

1271
00:52:25,500 --> 00:52:27,780
C の定義も同じです。これにより、

1272
00:52:27,780 --> 00:52:30,180


1273
00:52:30,180 --> 00:52:32,760
最小のパスとしてそれについて話すことができます。 アクション、または最も

1274
00:52:32,760 --> 00:52:36,660
可能性の高い結果、または最も驚くべき

1275
00:52:36,660 --> 00:52:39,900
結果として定義しており、それを

1276
00:52:39,900 --> 00:52:42,960
最も驚くべき

1277
00:52:42,960 --> 00:52:47,040
結果として定義しているため、変分自由

1278
00:52:47,040 --> 00:52:50,640
エネルギーを使用して驚きを跳ね返すことができますが、

1279
00:52:50,640 --> 00:52:54,000
単純に変分法を使用して境界や驚きを跳ね返すことはできません。

1280
00:52:54,000 --> 00:52:56,579


1281
00:52:56,579 --> 00:52:58,859
報酬自体は必ずしも近似値である必要があります

1282
00:52:58,859 --> 00:53:01,079
が、もしあなたが私が

1283
00:53:01,079 --> 00:53:04,980
期待しているものを好み、私が

1284
00:53:04,980 --> 00:53:07,559
期待しているものが私の驚きを減らし、驚きの

1285
00:53:07,559 --> 00:53:09,859
バランスを取るつもりだと言うなら、

1286
00:53:09,859 --> 00:53:13,520
あなたは両方の

1287
00:53:13,520 --> 00:53:17,240
行動的報酬を求める行動的報酬を、物理的枠組みを最小限に抑えた

1288
00:53:17,240 --> 00:53:21,420
驚きの限界の驚きの中に詰め込むことになります。

1289
00:53:21,420 --> 00:53:25,579


1290
00:53:27,059 --> 00:53:28,740
それは美しい

1291
00:53:28,740 --> 00:53:31,619
言い方ですね、はい、ありがとうございます、

1292
00:53:31,619 --> 00:53:35,160
次は何ですか、

1293
00:53:35,160 --> 00:53:36,720
エキサイティングな

1294
00:53:36,720 --> 00:53:39,420
ステップや方向性、あるいはこの仕事をどのような方法で

1295
00:53:39,420 --> 00:53:41,640
進めていきたいですか、ええ、素晴らしいですね、それでは、

1296
00:53:41,640 --> 00:53:43,140


1297
00:53:43,140 --> 00:53:44,940
この仕事だけについて話しているのであれば、

1298
00:53:44,940 --> 00:53:46,140


1299
00:53:46,140 --> 00:53:50,640
ええと私が望んでいることは何ですか 次にやるべきことは、

1300
00:53:50,640 --> 00:53:53,099
キューベースの探索タスクについて考えます。

1301
00:53:53,099 --> 00:53:55,200
まず第一に、動的プログラミングの制限に対処します。

1302
00:53:55,200 --> 00:53:58,980
つまり、最初に

1303
00:53:58,980 --> 00:54:01,020
このグリッド内で探索するキューがある場合です。

1304
00:54:01,020 --> 00:54:03,660
それがより最適です。 えー、

1305
00:54:03,660 --> 00:54:06,780
期待される曖昧さの項がどのように計算されるかを確認したいと思います

1306
00:54:06,780 --> 00:54:10,319
期待される自由エネルギーは有用であり

1307
00:54:10,319 --> 00:54:12,240
、厳密にその意味で動的計画法で利用されるべきです、

1308
00:54:12,240 --> 00:54:13,260


1309
00:54:13,260 --> 00:54:15,540


1310
00:54:15,540 --> 00:54:18,000
ええと、しかしより一般的には、CBSの夏の教授の作品があるように、積極的な影響

1311
00:54:18,000 --> 00:54:20,339
で意思決定を行う他の方法も検討しています、

1312
00:54:20,339 --> 00:54:23,040


1313
00:54:23,040 --> 00:54:24,900


1314
00:54:24,900 --> 00:54:26,099


1315
00:54:26,099 --> 00:54:30,180
彼は話していると思います それがどのようになっているのかについて

1316
00:54:30,180 --> 00:54:33,059
ニューラルネットワークがどのように能動的な

1317
00:54:33,059 --> 00:54:35,099
推論と基本的な意思決定を行っているのか キュー

1318
00:54:35,099 --> 00:54:36,359


1319
00:54:36,359 --> 00:54:39,540


1320
00:54:39,540 --> 00:54:42,359
学習のような意味で非常に効率的です そこで

1321
00:54:42,359 --> 00:54:44,940
彼は、変動自由エネルギーを賢く利用して、

1322
00:54:44,940 --> 00:54:47,520
優れた

1323
00:54:47,520 --> 00:54:50,760
状態アクションマッピングを学習しています

1324
00:54:50,760 --> 00:54:52,200


1325
00:54:52,200 --> 00:54:55,079


1326
00:54:55,079 --> 00:54:56,520
期待される自由エネルギーという点で私たちが慣れ親しんでいるものに対する非常に劇的な変化なので、

1327
00:54:56,520 --> 00:54:59,220
期待される自由エネルギーという概念はありません

1328
00:54:59,220 --> 00:55:01,740
あの研究では、エネルギーの変化

1329
00:55:01,740 --> 00:55:03,599
から直接何が良いのか悪いのかを学ぶことがすべてなので、

1330
00:55:03,599 --> 00:55:05,700
私もそれがわかります

1331
00:55:05,700 --> 00:55:08,099
興味深いですね、

1332
00:55:08,099 --> 00:55:11,160
それをもっと探求して、

1333
00:55:11,160 --> 00:55:15,300
このような意思決定がどのように良いのか悪いの

1334
00:55:15,300 --> 00:55:18,000
か、あるいは

1335
00:55:18,000 --> 00:55:20,220
意思決定の方法を再考する必要があるのか​​を見てみたいと思います。なぜなら、

1336
00:55:20,220 --> 00:55:22,200
能動的推論は

1337
00:55:22,200 --> 00:55:23,700
変分自由エネルギーについてのみ話しており、それが

1338
00:55:23,700 --> 00:55:25,520
すべての中心的な教義だからです。 そうでなければ、

1339
00:55:25,520 --> 00:55:28,440
それはあなたの解釈です、

1340
00:55:28,440 --> 00:55:31,319
そう、

1341
00:55:31,319 --> 00:55:35,180
それは別の方向です。私はそれを面白い方法で言いたいと思っています、

1342
00:55:35,640 --> 00:55:38,359
確かに

1343
00:55:38,359 --> 00:55:42,480
変分自由エネルギーは

1344
00:55:42,480 --> 00:55:45,540
変分

1345
00:55:45,540 --> 00:55:48,660
分布 q とデータ y の関数です。

1346
00:55:48,660 --> 00:55:51,119
変分自由エネルギーは次のようなものです。

1347
00:55:51,119 --> 00:55:53,839
リアルタイムの

1348
00:55:53,839 --> 00:55:57,359
ホメオスタシスはそうですね、

1349
00:55:57,359 --> 00:55:59,760
私が信じていることと

1350
00:55:59,760 --> 00:56:01,619
入ってくるデータを考慮する

1351
00:56:01,619 --> 00:56:04,740
と、物事はどのように意味をなすのでしょうか。そして、そのような

1352
00:56:04,740 --> 00:56:07,020
意味を作るフレームワークを意思決定に拡張するには、

1353
00:56:07,020 --> 00:56:10,020
さまざまな

1354
00:56:10,020 --> 00:56:13,740
方法を見てきましたが、フリーエネルギーが

1355
00:56:13,740 --> 00:56:16,260
一般的なものであると予想されます しかし、たとえば、

1356
00:56:16,260 --> 00:56:19,400
期待される将来の自由エネルギーは

1357
00:56:19,400 --> 00:56:25,200
eef として存在し、さまざまな方法を持つ他の構造もあります。

1358
00:56:25,200 --> 00:56:29,760


1359
00:56:29,760 --> 00:56:31,380
それから、それを沙村

1360
00:56:31,380 --> 00:56:33,599
教授の研究についても指摘しています。つまり、

1361
00:56:33,599 --> 00:56:37,020


1362
00:56:37,020 --> 00:56:39,059


1363
00:56:39,059 --> 00:56:41,339
ベース グラフ上の変分自由エネルギーと

1364
00:56:41,339 --> 00:56:43,680
ニューラル ネットワークの損失関数や、

1365
00:56:43,680 --> 00:56:45,300
非常にエキサイティングな関係性もすべて機能します。えーっと、

1366
00:56:45,300 --> 00:56:48,380


1367
00:56:49,079 --> 00:56:51,660


1368
00:56:51,660 --> 00:56:53,460
最後の質問として締めくくりたいと思います。または、博士課程

1369
00:56:53,460 --> 00:56:55,559
の終わりに近づいていると思いましたので、

1370
00:56:55,559 --> 00:56:56,880


1371
00:56:56,880 --> 00:57:00,540
ちょうど今までの期間に

1372
00:57:00,540 --> 00:57:02,579
博士課程の学生です

1373
00:57:02,579 --> 00:57:06,300
能動的推論の展開をどのように見てきましたか、

1374
00:57:06,300 --> 00:57:10,700
または、数年前に新鮮な目で興奮していたときと、

1375
00:57:11,339 --> 00:57:14,280
終わり近くになった今日のあなたにとって何が違うように感じますか、

1376
00:57:14,280 --> 00:57:17,400


1377
00:57:17,400 --> 00:57:19,980


1378
00:57:19,980 --> 00:57:21,119


1379
00:57:21,119 --> 00:57:23,339
それは本当に素晴らしい

1380
00:57:23,339 --> 00:57:25,920
質問です。そして、私もその方法に非常に興奮しています

1381
00:57:25,920 --> 00:57:29,400
この分野は進化しており、率直に言って、

1382
00:57:29,400 --> 00:57:30,900
私はこの強化

1383
00:57:30,900 --> 00:57:32,400
学習の背景と物理学の

1384
00:57:32,400 --> 00:57:34,680
背景から始めましたが、読み始めたときはまだ

1385
00:57:34,680 --> 00:57:37,680
1 ～ 2 件の論文しかなく、

1386
00:57:37,680 --> 00:57:40,440
ほとんど理解できませんでした。それは、

1387
00:57:40,440 --> 00:57:42,540


1388
00:57:42,540 --> 00:57:44,700
それを実装し始めたときだけでした。  Matlab スクリプトを呼び出します。

1389
00:57:44,700 --> 00:57:46,980


1390
00:57:46,980 --> 00:57:49,559
これはなんとなく理解できました。これは理にかなっていて、気に入っています。

1391
00:57:49,559 --> 00:57:52,020
しかし、たとえば 1 ～ 2 年以内に、

1392
00:57:52,020 --> 00:57:54,780


1393
00:57:54,780 --> 00:57:56,280
さまざまな方向から多くの論文が送られてくるのを目にしました。人々も

1394
00:57:56,280 --> 00:57:58,740
ニューラル ネットワークを使い始め、このすべてが

1395
00:57:58,740 --> 00:58:02,460
スケールアップしています。 私もある

1396
00:58:02,460 --> 00:58:04,319
時点で、能動推論の必要性について疑問を持ちました。

1397
00:58:04,319 --> 00:58:07,260


1398
00:58:07,260 --> 00:58:09,119
深層強化学習を使って

1399
00:58:09,119 --> 00:58:10,980
多くのことができるのであれば、なぜ深層能動

1400
00:58:10,980 --> 00:58:14,040
推論なのか、それが私がそこに

1401
00:58:14,040 --> 00:58:16,319
踏み込まなかった理由ですが、それでも

1402
00:58:16,319 --> 00:58:18,359
魅力的だと思います 私は

1403
00:58:18,359 --> 00:58:20,280
ディープアクティブ推論について、

1404
00:58:20,280 --> 00:58:23,160
今知っていることよりも理解したいと思っていますが、この

1405
00:58:23,160 --> 00:58:25,680
分野がここ 2 ～ 3 年で他のものと同様に成長し、

1406
00:58:25,680 --> 00:58:28,619
多くの人々が

1407
00:58:28,619 --> 00:58:31,859
取り組み始めているのを見てきました。そして、すぐにそれが

1408
00:58:31,859 --> 00:58:36,359
真剣に取り上げられる分野になりました。 実際にそれが何なのか

1409
00:58:36,359 --> 00:58:39,119
誰も知らない、たとえば 2 つの論文がある分野よりも、

1410
00:58:39,119 --> 00:58:41,280
本当に

1411
00:58:41,280 --> 00:58:43,440
エキサイティングです、そうですね、その

1412
00:58:43,440 --> 00:58:47,040
分野が時間の経過とともにどのように進化するか、

1413
00:58:47,040 --> 00:58:52,140
そして博士号取得後に何ができるかなどを本当に楽しみにしています。 私たちは

1414
00:58:52,140 --> 00:58:55,319


1415
00:58:55,319 --> 00:59:00,359
期待しているものを好みます はい、

1416
00:59:02,339 --> 00:59:04,140
その他の

1417
00:59:04,140 --> 00:59:05,819
コメントや追加したいことは何でもあります

1418
00:59:05,819 --> 00:59:07,200


1419
00:59:07,200 --> 00:59:09,839
はい、なので、

1420
00:59:09,839 --> 00:59:11,940


1421
00:59:11,940 --> 00:59:14,400
この論文についてどう思うか、これらのアイデアについてどう思うかを教えてください、お気軽に

1422
00:59:14,400 --> 00:59:16,200
お知らせください、フィードバックを本当に楽しみにしています

1423
00:59:16,200 --> 00:59:17,760


1424
00:59:17,760 --> 00:59:20,160
この機会を本当にありがとう

1425
00:59:20,160 --> 00:59:23,339
ダニエル、そして時間を割いていただきありがとうございます

1426
00:59:23,339 --> 00:59:26,160
素晴らしかったです 人々が

1427
00:59:26,160 --> 00:59:28,260
論文をチェックして、連絡して

1428
00:59:28,260 --> 00:59:30,540
コードを複製し、

1429
00:59:30,540 --> 00:59:33,359
独自の方向に進んでくれることを願っています ありがとう、また会い

1430
00:59:33,359 --> 00:59:34,680


1431
00:59:34,680 --> 00:59:36,839
ましょう、また次回 本当にありがとう、さようなら、

1432
00:59:36,839 --> 00:59:40,040
良い一日を。

