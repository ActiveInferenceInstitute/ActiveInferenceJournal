1
00:00:03,120 --> 00:00:06,120
외국

2
00:00:08,480 --> 00:00:12,660
2023년 7월 15일

3
00:00:12,660 --> 00:00:15,900
우리는 오늘

4
00:00:15,900 --> 00:00:19,080
Aspen Paul과 함께 능동적 추론 모델 스트림 번호 9.1에 있습니다.

5
00:00:19,080 --> 00:00:21,060


6
00:00:21,060 --> 00:00:24,180


7
00:00:24,180 --> 00:00:27,000
능동적 추론의 효율적인 계산에 대한 프레젠테이션과 토론을 할 예정이니

8
00:00:27,000 --> 00:00:28,619
라이브로 시청하시는 분들은

9
00:00:28,619 --> 00:00:30,840
자유롭게 추가해주세요.  그렇지 않으면 채팅에 댓글이나 질문이 있습니다.

10
00:00:30,840 --> 00:00:33,059
그렇지 않으면

11
00:00:33,059 --> 00:00:36,120
오늘 참여해 주셔서 감사합니다.

12
00:00:36,120 --> 00:00:38,820
대화를 기대하고 있습니다.

13
00:00:38,820 --> 00:00:41,640
다니엘 감사합니다.

14
00:00:41,640 --> 00:00:42,960
오늘 언급한 대로 매우 감사합니다.

15
00:00:42,960 --> 00:00:44,700
효율적인 계산과 능동적

16
00:00:44,700 --> 00:00:46,920
추론에 대해 이야기하겠습니다. 시작하겠습니다.

17
00:00:46,920 --> 00:00:49,500


18
00:00:49,500 --> 00:00:51,420


19
00:00:51,420 --> 00:00:53,820
활성 추론 권리라고도 하는 자유 에너지 원리에 대한 이 아이디어에 모두 익숙하므로

20
00:00:53,820 --> 00:00:55,800
중심 개념은 에이전트가

21
00:00:55,800 --> 00:00:59,160


22
00:00:59,160 --> 00:01:01,140
항상성을 유지하거나 환경에서 생존하기 위해 관찰의 엔트로피를 최소화하는 것입니다.

23
00:01:01,140 --> 00:01:03,719
여기서 엔트로피는

24
00:01:03,719 --> 00:01:05,580
정보 이론에서 정의됩니다.

25
00:01:05,580 --> 00:01:08,520
관찰이

26
00:01:08,520 --> 00:01:10,200


27
00:01:10,200 --> 00:01:12,659
엔트로피가 적거나 덜 놀랍고

28
00:01:12,659 --> 00:01:14,159
확률이 높고 우리가

29
00:01:14,159 --> 00:01:16,560
예상하고 있었기 때문에 관찰이 매우 확률적이라면

30
00:01:16,560 --> 00:01:18,840
그것이

31
00:01:18,840 --> 00:01:20,939
우리가 능동적 추론의 프레임워크를 구축하는 기반이 될 때의 아이디어입니다.

32
00:01:20,939 --> 00:01:23,759


33
00:01:23,759 --> 00:01:26,520
마르코 블랭킷 어 그것은 우리에게

34
00:01:26,520 --> 00:01:30,000
놀라움을 주는 체계적인 방법을 제공합니다 어 또는

35
00:01:30,000 --> 00:01:32,580
어 에이전트를 환경에서 분리하는 도식적인 방법을 제공

36
00:01:32,580 --> 00:01:34,439
하고

37
00:01:34,439 --> 00:01:37,320
목적이 있는 행동을 올바르게 모델링합니다. 따라서

38
00:01:37,320 --> 00:01:39,780
엔트로피를 최소화하는 이 아이디어에 초점을 맞추자

39
00:01:39,780 --> 00:01:41,700
에이전트가 엔트로피를 최소화하거나

40
00:01:41,700 --> 00:01:43,740
어떤 관찰이  매우

41
00:01:43,740 --> 00:01:46,020
확률적이며 그 반대의 경우도 마찬가지입니다.

42
00:01:46,020 --> 00:01:48,360
즉, 생성 모델을 유지하는 것입니다.

43
00:01:48,360 --> 00:01:50,399
생성 모델은

44
00:01:50,399 --> 00:01:52,020
기본적으로

45
00:01:52,020 --> 00:01:56,340
에이전트가 뇌에 구축하고 환경에서 얻은

46
00:01:56,340 --> 00:01:58,860
관찰만 사용하여 구축되는 환경의 장난감 모델입니다.

47
00:01:58,860 --> 00:02:00,540


48
00:02:00,540 --> 00:02:03,420
실제 uh 상태 또는

49
00:02:03,420 --> 00:02:04,740
환경의 숨겨진 상태에 대한 액세스

50
00:02:04,740 --> 00:02:07,920
장난감 모델을 구축하고 있으며

51
00:02:07,920 --> 00:02:10,318
이 장난감 모델이 주어지면 관찰 확률을 계산할 수 있는 범위 또는 능력이 있으므로

52
00:02:10,318 --> 00:02:13,560


53
00:02:13,560 --> 00:02:15,900


54
00:02:15,900 --> 00:02:18,660
엔트로피 권리를 최소화하려고 합니다.  주어진

55
00:02:18,660 --> 00:02:22,620


56
00:02:22,620 --> 00:02:25,800


57
00:02:25,800 --> 00:02:27,239
생성 모델과 같은 필기체 차원의 문제가 있습니다. 상태 공간이 빠르게 다루기 어려워질 수 있기 때문에 관측 확률을

58
00:02:27,239 --> 00:02:30,120
항상 계산하거나 주변화하는 것이 가능하지 않을 수

59
00:02:30,120 --> 00:02:32,099


60
00:02:32,099 --> 00:02:34,140


61
00:02:34,140 --> 00:02:37,020
있지만 아이디어는 놀라움에

62
00:02:37,020 --> 00:02:38,640
대한 상한선을 정의한다는 것입니다.

63
00:02:38,640 --> 00:02:41,580
Jensen의 부등식을 사용하여

64
00:02:41,580 --> 00:02:43,560


65
00:02:43,560 --> 00:02:46,800


66
00:02:46,800 --> 00:02:49,500
숨겨진 믿음 또는

67
00:02:49,500 --> 00:02:52,080
숨겨진 상태에 대한 믿음인 Q라는 새로운 용어를 정의할 수도 있습니다. 이 대기열은 올바른 의사

68
00:02:52,080 --> 00:02:54,000
결정의 초점이 될 것입니다.

69
00:02:54,000 --> 00:02:57,060


70
00:02:57,060 --> 00:02:58,680
환경에 있는 것은

71
00:02:58,680 --> 00:03:00,840


72
00:03:00,840 --> 00:03:03,540
그 환경을 제어하기 위한 결정을 내리거나 내리기를 희망할 수 없습니다. 그리고

73
00:03:03,540 --> 00:03:05,519


74
00:03:05,519 --> 00:03:07,560
당신이 사용하고 결정을 내리는 데 유용하게 되는 것은 숨겨진 상태에 대한 이 믿음입니다.

75
00:03:07,560 --> 00:03:10,379
이 전체 양은

76
00:03:10,379 --> 00:03:13,019
물론 자유 에너지라고 불립니다.

77
00:03:13,019 --> 00:03:14,420
변형 자유 에너지

78
00:03:14,420 --> 00:03:17,879
F는 여러 가지 방법으로 해석될 수 있으므로

79
00:03:17,879 --> 00:03:19,560
첫 번째 또는 가장 일반적인 방법은

80
00:03:19,560 --> 00:03:22,920
기계 학습 방법입니다

81
00:03:22,920 --> 00:03:25,200
음 모델의 복잡성을 최소화하는

82
00:03:25,200 --> 00:03:27,060
동시에

83
00:03:27,060 --> 00:03:28,739
모델의 정확도를 최대화하려고 합니다.

84
00:03:28,739 --> 00:03:30,180


85
00:03:30,180 --> 00:03:32,400
다양한 자유 에너지를 최소화하는 기계 학습 해석 당신은

86
00:03:32,400 --> 00:03:34,140
또한

87
00:03:34,140 --> 00:03:34,739


88
00:03:34,739 --> 00:03:36,420


89
00:03:36,420 --> 00:03:38,940
당신이 동시에

90
00:03:38,940 --> 00:03:41,760
모델의 에너지를 최소화하려고 노력하면서

91
00:03:41,760 --> 00:03:43,019
동시에 엔트로피를 최대화하려고 노력하지만

92
00:03:43,019 --> 00:03:45,120


93
00:03:45,120 --> 00:03:48,659
오늘날의 초점인 물리학 용어로 자유 에너지를 해석하려고 시도할 수 있습니다.  또는 의사 결정은 능동적 추론에서 인식을

94
00:03:48,659 --> 00:03:51,540
수행한 후 가지고 있는 이 믿음에 항상 있습니다.

95
00:03:51,540 --> 00:03:54,780
따라서

96
00:03:54,780 --> 00:03:57,120
바닐라 의사 결정을 어떻게 수행하거나

97
00:03:57,120 --> 00:03:58,920


98
00:03:58,920 --> 00:04:00,659
의사 결정 및 고전적 능동

99
00:04:00,659 --> 00:04:03,540
추론에 대해 가장 많이 논의되는 아이디어는 무엇입니까

100
00:04:03,540 --> 00:04:05,580
?  그리고 당신이 결정을 내리려는 에이전트라면

101
00:04:05,580 --> 00:04:08,819


102
00:04:08,819 --> 00:04:10,620


103
00:04:10,620 --> 00:04:13,319
사용 가능한 작업 공간이 있으므로

104
00:04:13,319 --> 00:04:15,480
이 장난감 모델에는 세 가지 사용 가능한

105
00:04:15,480 --> 00:04:19,738
작업이 있습니다. 점프 실행 또는 유지 그리고

106
00:04:19,738 --> 00:04:22,199
이러한 작업이 주어지면

107
00:04:22,199 --> 00:04:25,139
작은 파이로 정책을 정의할 수 있습니다.  이것은

108
00:04:25,139 --> 00:04:28,320
시간과 자본의 일련의 작업입니다.

109
00:04:28,320 --> 00:04:30,300
t는 계획의 시간 범위 또는

110
00:04:30,300 --> 00:04:32,660


111
00:04:32,660 --> 00:04:36,540
정책의 길이이며

112
00:04:36,540 --> 00:04:39,419
이러한 정책이

113
00:04:39,419 --> 00:04:42,060
많은 정책 공간이 있습니다.

114
00:04:42,060 --> 00:04:44,220


115
00:04:44,220 --> 00:04:47,340


116
00:04:47,340 --> 00:04:48,720
당신이 축적한 믿음에 기반한 에너지

117
00:04:48,720 --> 00:04:50,580
그래서 여기에서 당신은

118
00:04:50,580 --> 00:04:52,860
이미 에너지에 대한 변화로부터 믿음을 가지고 있는 어떤 것도 최소화하지 않고 있고

119
00:04:52,860 --> 00:04:55,080
당신은 단지 당신이 정의할 수 있는

120
00:04:55,080 --> 00:04:57,419


121
00:04:57,419 --> 00:04:59,520
많은 작은 정책들에 상응하는 예상 자유 에너지를 계산하거나 평가하고 있을 뿐입니다.

122
00:04:59,520 --> 00:05:02,759


123
00:05:02,759 --> 00:05:05,699
모든 정책에 대해 평가하면

124
00:05:05,699 --> 00:05:07,440
어떤 것이

125
00:05:07,440 --> 00:05:09,180
최적의 정책인지 알 수 있습니다. 이것이 올바른 의사

126
00:05:09,180 --> 00:05:11,160


127
00:05:11,160 --> 00:05:13,800
결정에 대한 고전적인 능동적 추론 아이디어이고

128
00:05:13,800 --> 00:05:16,020
이 예상 자유 에너지는

129
00:05:16,020 --> 00:05:18,900
목표 지향적이라는 점에서 정말 유용합니다.

130
00:05:18,900 --> 00:05:21,720
따라서 위험 조건은 목표

131
00:05:21,720 --> 00:05:23,520
지향적입니다.  그런 다음 탐색을 강요하는 이 예상되는

132
00:05:23,520 --> 00:05:25,919
모호성 용어가

133
00:05:25,919 --> 00:05:27,960
있지만

134
00:05:27,960 --> 00:05:30,539
이 정책 공간이 빠르게 상호 작용할 수

135
00:05:30,539 --> 00:05:32,400
있고 일반적으로 볼 수 있는 환경에 대한

136
00:05:32,400 --> 00:05:35,280
능동적 추론을 확장하는 데 항상 병목 현상으로 남아 있다는 문제가 있지만

137
00:05:35,280 --> 00:05:37,680


138
00:05:37,680 --> 00:05:40,500


139
00:05:40,500 --> 00:05:42,419
어떻게 되는지 봅시다.  신속하게 상호 작용할 수 있으므로

140
00:05:42,419 --> 00:05:45,300


141
00:05:45,300 --> 00:05:47,940
Time Horizon 15에 대해 얼마나 많은 정책을 정의할 수 있는지 예를 들어

142
00:05:47,940 --> 00:05:50,340
Super Mario와 같이 플레이하는 경우

143
00:05:50,340 --> 00:05:52,440
적어도 10

144
00:05:52,440 --> 00:05:56,460
단계 앞서 계획하여 첫 번째 정책이 음

145
00:05:56,460 --> 00:05:58,380
동일한 작업이 될 수 있도록 할 수 있습니다.  실행

146
00:05:58,380 --> 00:06:02,600
음은 15개의 시간 단계에 대해 누적되며

147
00:06:02,600 --> 00:06:05,460
기본적으로 이러한 작업의 여러 조합을 정의할 수

148
00:06:05,460 --> 00:06:09,060
있으며 정책 공간은

149
00:06:09,060 --> 00:06:10,139
단순히

150
00:06:10,139 --> 00:06:13,860
음 다루기 어렵습니다. 이러한 모든 정책에 대해

151
00:06:13,860 --> 00:06:16,380
예상되는 자유 에너지를 평가하기에는 너무 거대해지며

152
00:06:16,380 --> 00:06:19,440


153
00:06:19,440 --> 00:06:21,900
확률론적 문제 설정에서

154
00:06:21,900 --> 00:06:24,419
음  환경 자체가 시끄럽습니다.

155
00:06:24,419 --> 00:06:27,120


156
00:06:27,120 --> 00:06:28,860
이 정책 공간의 하위 집합을 선택하고

157
00:06:28,860 --> 00:06:30,840
고전적인 능동적 추론을 수행할 수 있는 방법이 실제로 없습니다. 이것은

158
00:06:30,840 --> 00:06:32,340
분명히 계산 상호 작용 가능한

159
00:06:32,340 --> 00:06:34,380
문제이며, 이것이 문헌에서 토론할 때

160
00:06:34,380 --> 00:06:36,360
항상 작은 그리드 또는 작은 환경을 보는 이유입니다.

161
00:06:36,360 --> 00:06:38,880


162
00:06:38,880 --> 00:06:41,520
적극적인 영향력에서 의사결정을 하지만 최근에

163
00:06:41,520 --> 00:06:43,860
어 정교한 입구라는 새로운 아이디어가 제안되었고

164
00:06:43,860 --> 00:06:46,259


165
00:06:46,259 --> 00:06:48,840
정교한 추론에서는

166
00:06:48,840 --> 00:06:51,600


167
00:06:51,600 --> 00:06:52,800
실제로 정책 공간이 아닙니다. 실제로

168
00:06:52,800 --> 00:06:55,080
음 실시간으로 무엇을 해야할지 생각하려고 노력합니다.  음

169
00:06:55,080 --> 00:06:58,139


170
00:06:58,139 --> 00:07:00,000


171
00:07:00,000 --> 00:07:02,880
그것을 기반으로 행동을 평가하려고 노력하고 있습니다. 그래서

172
00:07:02,880 --> 00:07:04,800
여기에는 일련의

173
00:07:04,800 --> 00:07:07,199
정책이나

174
00:07:07,199 --> 00:07:10,020
상호 작용할 수 있는 것이 없습니다. 어 여기서 우리는

175
00:07:10,020 --> 00:07:12,600
기본적으로 당신이 음 이 공동 분포의

176
00:07:12,600 --> 00:07:14,220
예상 자유 에너지를 평가하려고 한다는 의미에서 연구를 하고 있습니다.

177
00:07:14,220 --> 00:07:16,500


178
00:07:16,500 --> 00:07:19,560
행동 및 관찰의

179
00:07:19,560 --> 00:07:21,900


180
00:07:21,900 --> 00:07:23,940
예상 자유 에너지를 평가하려면 어

181
00:07:23,940 --> 00:07:26,340
작은 T

182
00:07:26,340 --> 00:07:29,039
다음 시간 단계에서도 예상 자유 에너지가 필요하고

183
00:07:29,039 --> 00:07:31,259


184
00:07:31,259 --> 00:07:32,819
시간 t + 2의 예상 자유 에너지가 필요하다는 것을 평가하려면

185
00:07:32,819 --> 00:07:35,039
기본적으로  제

186
00:07:35,039 --> 00:07:38,160
시간에 롤아웃되는 연구이고 어 그것은

187
00:07:38,160 --> 00:07:41,160
재귀 관계이고

188
00:07:41,160 --> 00:07:43,259
여기서는

189
00:07:43,259 --> 00:07:45,539
마지막 슬라이드 오른쪽에서 본 정책 공간과 근본적으로 다르며

190
00:07:45,539 --> 00:07:47,759


191
00:07:47,759 --> 00:07:49,680


192
00:07:49,680 --> 00:07:51,780
계획을 세워야 한다면 10

193
00:07:51,780 --> 00:07:55,139
배 팁을  고전적 능동적 추론에서 종합적으로 앞서

194
00:07:55,139 --> 00:07:56,759
우리는

195
00:07:56,759 --> 00:07:58,380
정책 공간

196
00:07:58,380 --> 00:07:59,460
음

197
00:07:59,460 --> 00:08:01,940
행동 공간의 카디널리티가

198
00:08:01,940 --> 00:08:04,139
T로 올라간다는 것을 보았습니다. 그래서 모든 가능성을

199
00:08:04,139 --> 00:08:07,259
고려해야 하는 경우 계산 병목 현상이 발생

200
00:08:07,259 --> 00:08:10,199
하지만 정교한

201
00:08:10,199 --> 00:08:12,780
추론에서는 더욱 악화됩니다.

202
00:08:12,780 --> 00:08:14,759


203
00:08:14,759 --> 00:08:16,860
상태와 행동의 조합이므로

204
00:08:16,860 --> 00:08:20,400
실제로는 계산적으로 더 나쁩니다. 하지만

205
00:08:20,400 --> 00:08:21,660


206
00:08:21,660 --> 00:08:23,520
정교한 참조 문서에서 우리가

207
00:08:23,520 --> 00:08:26,400
가지치기를 할 수 있는 해결책이 제안되었습니다.

208
00:08:26,400 --> 00:08:29,639


209
00:08:29,639 --> 00:08:31,080


210
00:08:31,080 --> 00:08:33,000


211
00:08:33,000 --> 00:08:36,059
따라서 가지치기가 정교한 추론에서 어떻게 작동하는지 봅시다.

212
00:08:36,059 --> 00:08:38,940
이 그리드는

213
00:08:38,940 --> 00:08:40,440
원래의 정교한 추론 논문에서 논의되었으며

214
00:08:40,440 --> 00:08:41,700


215
00:08:41,700 --> 00:08:44,580


216
00:08:44,580 --> 00:08:47,100
이러한 종류의 사전 선호도

217
00:08:47,100 --> 00:08:50,399
분포가 있으므로 목표 상태인 이 흰색 사각형이

218
00:08:50,399 --> 00:08:52,140
가장 선호되는 상태

219
00:08:52,140 --> 00:08:54,300
이고  당신은 그 황금 상태에서 멀리 떨어진 상태에

220
00:08:54,300 --> 00:08:55,380


221
00:08:55,380 --> 00:08:58,140
대해 균일하게 감소하는 선호도를 가지고 있습니다.

222
00:08:58,140 --> 00:09:00,779


223
00:09:00,779 --> 00:09:03,240
기본적으로 당신이

224
00:09:03,240 --> 00:09:05,480
시간 T에서 어떤 관찰에서 자신을 관찰한다면

225
00:09:05,480 --> 00:09:07,560
기본적으로 당신이 하고 있는 것은

226
00:09:07,560 --> 00:09:09,600
당신이

227
00:09:09,600 --> 00:09:12,779
그 관찰에서 가능한 행동의 결과를 고려하는 것입니다.

228
00:09:12,779 --> 00:09:17,760
기본적으로 당신은

229
00:09:17,760 --> 00:09:20,700
당신의 믿음의 투사를 사용할 수 있고 그러한 믿음에 대한 임계값을 설정하여

230
00:09:20,700 --> 00:09:22,620


231
00:09:22,620 --> 00:09:24,600
일부 행동을 무시하고 일부

232
00:09:24,600 --> 00:09:27,420
관찰을 무시할 수 있습니다. 그리고 당신이 발견하게 될 것은

233
00:09:27,420 --> 00:09:30,120
그것이 더 이상 연구에 있지 않다는 것입니다.

234
00:09:30,120 --> 00:09:33,000


235
00:09:33,000 --> 00:09:36,060


236
00:09:36,060 --> 00:09:38,700
전체 연구를 바로 수행하는 것보다 효율적이므로 여기에서

237
00:09:38,700 --> 00:09:40,680
많은 조합을 피했고

238
00:09:40,680 --> 00:09:42,120
이것은 계산적으로

239
00:09:42,120 --> 00:09:45,420
매력적인 문제가 됩니다. 이것은 당신이

240
00:09:45,420 --> 00:09:47,880
일부 행동과

241
00:09:47,880 --> 00:09:49,620
음 관찰을 피하기로 결정했기 때문에 당신에게

242
00:09:49,620 --> 00:09:52,740


243
00:09:52,740 --> 00:09:54,600
더 높은 보상 또는

244
00:09:54,600 --> 00:09:56,580


245
00:09:56,580 --> 00:09:59,700
이 부분 연구의 결과보다 더 최적일 수 있지만

246
00:09:59,700 --> 00:10:02,820
이것은 작동하므로 이 시뮬레이션이

247
00:10:02,820 --> 00:10:05,459
논문에 제시되었고 에이전트가 작동합니다.  가지

248
00:10:05,459 --> 00:10:09,959


249
00:10:09,959 --> 00:10:12,300


250
00:10:12,300 --> 00:10:14,940


251
00:10:14,940 --> 00:10:17,880
치기된 방식으로 계획을 세우지만

252
00:10:17,880 --> 00:10:19,200


253
00:10:19,200 --> 00:10:20,820
기본적으로

254
00:10:20,820 --> 00:10:23,519
작은 검색

255
00:10:23,519 --> 00:10:25,019
임계값에 대해서도 계산 복잡성을

256
00:10:25,019 --> 00:10:27,180
크게 줄일 수 있다는 것을 계산적으로 보여줄 수 있습니다.

257
00:10:27,180 --> 00:10:29,100
따라서

258
00:10:29,100 --> 00:10:31,500


259
00:10:31,500 --> 00:10:33,540
계획 깊이로 전체 연구를 수행하기로 결정하면

260
00:10:33,540 --> 00:10:35,100
계산 시간은  기하급수적이며

261
00:10:35,100 --> 00:10:38,040
신속하게 그것에 대해 많은 것을 할 수 없지만

262
00:10:38,040 --> 00:10:40,200


263
00:10:40,200 --> 00:10:42,420
매우 작은 임계값에서 결정하면

264
00:10:42,420 --> 00:10:43,980
이 문제가

265
00:10:43,980 --> 00:10:46,620
계산적으로 매력적이라는 것을 알 수 있으며

266
00:10:46,620 --> 00:10:49,200
정교한 인스턴스에 대한 이 데모는

267
00:10:49,200 --> 00:10:50,700
내 mdp 버전에서 사용할 수 있습니다.

268
00:10:50,700 --> 00:10:52,860


269
00:10:52,860 --> 00:10:55,380
곧 mdp에 의해 원본에 통합될 예정입니다.

270
00:10:55,380 --> 00:10:56,820


271
00:10:56,820 --> 00:10:59,160
하지만 요점은 해당 연구를 가지치기하려면

272
00:10:59,160 --> 00:11:01,920


273
00:11:01,920 --> 00:11:03,779


274
00:11:03,779 --> 00:11:06,060
여기에서 에이전트가

275
00:11:06,060 --> 00:11:09,360
우리의 이웃 상태가 얼마나 바람직한지 알고 있다는 의미에서 이와 같이 잘 알려진 주요 선호도가 필요하다는 것입니다.

276
00:11:09,360 --> 00:11:11,760
최종 목표 세트에 대해서만 알고 있으며

277
00:11:11,760 --> 00:11:13,860


278
00:11:13,860 --> 00:11:16,440
인접 상태에 대해서도 알고 있으며 이러한 사전 선호도가 주어지면

279
00:11:16,440 --> 00:11:18,420


280
00:11:18,420 --> 00:11:20,399
계획 깊이가 3인 경우 에이전트가

281
00:11:20,399 --> 00:11:23,820
기본적으로

282
00:11:23,820 --> 00:11:27,060
사전 선호도의 로컬 최대값에 갇히지만

283
00:11:27,060 --> 00:11:30,480
계획 깊이가 충분하다는 것을 알 수 있습니다.

284
00:11:30,480 --> 00:11:33,240
이 장벽을 극복하고 목표 상태에 도달할 수 있습니다.

285
00:11:33,240 --> 00:11:35,579


286
00:11:35,579 --> 00:11:37,800


287
00:11:37,800 --> 00:11:39,600
문제는 에이전트가

288
00:11:39,600 --> 00:11:42,720
이 최종 상태만 알면

289
00:11:42,720 --> 00:11:45,660
무엇을 해야 하는지에 대한 다른 지식이 없고

290
00:11:45,660 --> 00:11:48,240
이 경우 에이전트는 무엇을 하느냐입니다.  그래서 이것은

291
00:11:48,240 --> 00:11:50,459
우리가 해결하려고 하는 문제이고

292
00:11:50,459 --> 00:11:53,399


293
00:11:53,399 --> 00:11:55,740
이와 같은 의미 있는 사전 선호도가 없는 경우

294
00:11:55,740 --> 00:11:58,200
에이전트는 기본적으로

295
00:11:58,200 --> 00:12:00,720
목표 상태에 도달할 방법이 없습니다. 음

296
00:12:00,720 --> 00:12:03,300
무작위 탐색 외에는

297
00:12:03,300 --> 00:12:05,279
계획할 방법이 없습니다.

298
00:12:05,279 --> 00:12:08,040


299
00:12:08,040 --> 00:12:09,779
계산적으로

300
00:12:09,779 --> 00:12:13,079
상호 작용할 수 있기 때문에 8단계를 미리 계획하십시오.

301
00:12:13,079 --> 00:12:17,880
전체 조사를 올바르게 수행하기로 선택한 경우

302
00:12:17,880 --> 00:12:21,000
이와 같은 그리드에 대해 잘

303
00:12:21,000 --> 00:12:22,500


304
00:12:22,500 --> 00:12:24,240
알지 못하고 강조

305
00:12:24,240 --> 00:12:28,079
표시되는 희박한 시도 기본 설정을 얻으면 어떻게 합니까?  이전 슬라이드에서

306
00:12:28,079 --> 00:12:30,839
귀하의 연구는 이제 맹목적입니다. 어 귀하는

307
00:12:30,839 --> 00:12:33,000
해당 연구를 정리할 방법이 없으며

308
00:12:33,000 --> 00:12:35,100
이 시나리오에서 전체 조사를 수행해야 하므로

309
00:12:35,100 --> 00:12:36,300


310
00:12:36,300 --> 00:12:38,880


311
00:12:38,880 --> 00:12:40,200


312
00:12:40,200 --> 00:12:42,959
음 여기에 대한 두 가지 해결책이 있습니다.

313
00:12:42,959 --> 00:12:47,359
전체 심층 계획을 수행하는 방법 어

314
00:12:49,579 --> 00:12:52,920
또는 의미 있는 프라이드 선호도를 배워야 합니다.

315
00:12:52,920 --> 00:12:54,600


316
00:12:54,600 --> 00:12:57,480
이렇게 정리된 연구를 수행할 수 있습니다. 그래서 우리는 이 프레젠테이션

317
00:12:57,480 --> 00:12:59,760
에서 이 두 가지 솔루션에 대해 논의할 것입니다.

318
00:12:59,760 --> 00:13:02,399
어,

319
00:13:02,399 --> 00:13:03,839
이와 같은 주어진 시나리오에 대해

320
00:13:03,839 --> 00:13:06,420
첫 번째  솔루션 전체

321
00:13:06,420 --> 00:13:08,639
연구를 수행하려면 기본적으로 동적

322
00:13:08,639 --> 00:13:11,399
프로그래밍을 사용하고 동적 프로그래밍은

323
00:13:11,399 --> 00:13:13,800
운영 연구

324
00:13:13,800 --> 00:13:15,839
및 산업 공학과

325
00:13:15,839 --> 00:13:18,060
많은 공학 분야에서 잘 알려진 아이디어이며

326
00:13:18,060 --> 00:13:19,920
기본 아이디어는

327
00:13:19,920 --> 00:13:21,959
더 큰 문제의 하위 부분을

328
00:13:21,959 --> 00:13:24,000
먼저 해결한 다음  나중에

329
00:13:24,000 --> 00:13:27,000
이러한 하위 문제의 솔루션을 통합하려고 어 어

330
00:13:27,000 --> 00:13:31,260
최적의 의사 결정을 하기 위해

331
00:13:31,260 --> 00:13:33,779
이 시나리오에서

332
00:13:33,779 --> 00:13:37,019
여러분이 마지막 행동을 계획하려고 한다고 상상해보십시오.

333
00:13:37,019 --> 00:13:39,540


334
00:13:39,540 --> 00:13:41,760


335
00:13:41,760 --> 00:13:44,040


336
00:13:44,040 --> 00:13:46,320
미래에 무슨 일이 일어나고 있는지

337
00:13:46,320 --> 00:13:47,940
계획의 방향은 기본적으로 시간을 앞당겼지만

338
00:13:47,940 --> 00:13:49,920


339
00:13:49,920 --> 00:13:51,959


340
00:13:51,959 --> 00:13:55,560
목표 상태에 바로 근접한 마지막 시간 단계에 대해서만 계획하려고 하고

341
00:13:55,560 --> 00:13:57,600
좋은 상태로 바로 이동한다고 상상해 보십시오.

342
00:13:57,600 --> 00:13:59,519


343
00:13:59,519 --> 00:14:01,740
자본 T 빼기 1인 마지막 시간 단계에 대한 결정을 내리려고 노력하고

344
00:14:01,740 --> 00:14:05,459
있으며 다음

345
00:14:05,459 --> 00:14:08,880
시간 단계 또는 마지막 목표 상태에 대한 예측은

346
00:14:08,880 --> 00:14:09,839


347
00:14:09,839 --> 00:14:11,880


348
00:14:11,880 --> 00:14:14,160
이 전환을 사용하여 이 세계 모델에 액세스할 수 있기 때문에 수행할 수 있습니다.

349
00:14:14,160 --> 00:14:16,079


350
00:14:16,079 --> 00:14:18,600
활성 추론의 역학 또는 B 매트릭스 따라서 하위 문제인 이 단일 시간

351
00:14:18,600 --> 00:14:21,180
단계에 대해 어

352
00:14:21,180 --> 00:14:24,060


353
00:14:24,060 --> 00:14:26,100
당신이 이 관찰에 있는지 여부를 알려주는 예상 자유 에너지 테이블을 실제로 평가하고 있습니다.

354
00:14:26,100 --> 00:14:28,019


355
00:14:28,019 --> 00:14:31,740
시간 단계와

356
00:14:31,740 --> 00:14:34,440
기본적으로 어 상태

357
00:14:34,440 --> 00:14:36,540
공간이나 관찰 공간에서 이것을 할 수 있습니다. 그래서 이것은

358
00:14:36,540 --> 00:14:39,120
a 행렬과 D 행렬을 함께 사용하여

359
00:14:39,120 --> 00:14:41,699


360
00:14:41,699 --> 00:14:44,579
어느 쪽이든 계획을 세울 수 있습니다.

361
00:14:44,579 --> 00:14:46,260


362
00:14:46,260 --> 00:14:48,839


363
00:14:48,839 --> 00:14:50,940


364
00:14:50,940 --> 00:14:52,440
당신이 생각할 수 있는 마지막 단계

365
00:14:52,440 --> 00:14:54,600
내가 마지막 단계에 있다는 것을 내가 어떻게 알 수 있습니까 그것은

366
00:14:54,600 --> 00:14:58,699
당신이 미안하다고 상상하는 것에 관한 것입니다.

367
00:15:09,720 --> 00:15:12,839
우리가 잠시 마지막으로 들었던 것은

368
00:15:12,839 --> 00:15:15,540
그것이 모두 상상에 관한 것이라는 것입니다.

369
00:15:15,540 --> 00:15:18,060
예 그래서 거기에서 선택하십시오.  상상에 대한 모든 것

370
00:15:18,060 --> 00:15:19,860


371
00:15:19,860 --> 00:15:22,139
좋아 그래서 연결 문제가 있었다면

372
00:15:22,139 --> 00:15:23,699
예 몇 초 동안은 괜찮습니다. 그러면

373
00:15:23,699 --> 00:15:25,199
지금 오

374
00:15:25,199 --> 00:15:28,260
미안하지만 그래서

375
00:15:28,260 --> 00:15:30,899
음 그래서 내가 말하려는 것은 당신이 만약

376
00:15:30,899 --> 00:15:32,880
당신이 할 일을 상상하려고한다는 것입니다.

377
00:15:32,880 --> 00:15:35,519


378
00:15:35,519 --> 00:15:37,560
당신의 계획 지평선을 위한 마지막 시간 단계인 시간 자본 T 빼기 1에 있고

379
00:15:37,560 --> 00:15:40,260
당신이 그

380
00:15:40,260 --> 00:15:42,199
시간 단계에 있다면

381
00:15:42,199 --> 00:15:45,480


382
00:15:45,480 --> 00:15:49,800


383
00:15:49,800 --> 00:15:52,680
어떻게 해야 할까요?  내가 해야 할 일과 여기서 이 양은

384
00:15:52,680 --> 00:15:54,720
위험 조건이나 목적이 있는 조건만 고려하고 있습니다.

385
00:15:54,720 --> 00:15:56,279


386
00:15:56,279 --> 00:15:57,720
어 그리고

387
00:15:57,720 --> 00:16:01,560
이 조건은 그 정책을 나타내며 음

388
00:16:01,560 --> 00:16:03,540


389
00:16:03,540 --> 00:16:06,180
시간 T-1까지 거꾸로 하면 어떻게 됩니까?

390
00:16:06,180 --> 00:16:08,699
시간 어

391
00:16:08,699 --> 00:16:12,300
자본 T 빼기 1에서 이 테이블은

392
00:16:12,300 --> 00:16:14,880
자본 T 빼기 2에서 무엇을 해야 하는지 알려줄 수 있습니다.

393
00:16:14,880 --> 00:16:16,920
따라서 시간을 미리 계획하기보다는

394
00:16:16,920 --> 00:16:19,320
기본적으로

395
00:16:19,320 --> 00:16:22,019


396
00:16:22,019 --> 00:16:25,019
계획의 대문자 T를 고정하고

397
00:16:25,019 --> 00:16:29,279
주어진 시간에 많은 테이블을 함께 쌓는 것입니다.  나는 그런 모든 스택 테이블을 가지고

398
00:16:29,279 --> 00:16:31,800
있고 기본적으로 내가 할 수 있는 것은 그것들을 사용하여

399
00:16:31,800 --> 00:16:33,899
시간을 앞당기는 결정을 내리는 것입니다.

400
00:16:33,899 --> 00:16:35,940
우리가 관찰한 것은 이 아이디어가

401
00:16:35,940 --> 00:16:38,519
작동한다는 것입니다 음

402
00:16:38,519 --> 00:16:40,259
예상되는 자유

403
00:16:40,259 --> 00:16:43,019
에너지를 거꾸로 계산할 수 있습니다 어

404
00:16:43,019 --> 00:16:46,920
하위 문제로 고려하여 단계별로  그리고

405
00:16:46,920 --> 00:16:49,079
근본적인 차이점은

406
00:16:49,079 --> 00:16:51,600
정교한 추론에서 어

407
00:16:51,600 --> 00:16:54,959
시간 작은 T에서 예상되는 자유 에너지를 계산하려면

408
00:16:54,959 --> 00:16:57,540


409
00:16:57,540 --> 00:16:59,880
시간 팀 플러스 1에서 예상되는 자유 에너지가 무엇인지 모르기 때문에 이것은

410
00:16:59,880 --> 00:17:01,920
3개의 검색이 되어

411
00:17:01,920 --> 00:17:04,319
이것을 먼저 계산해야 한다는 것입니다.  그리고

412
00:17:04,319 --> 00:17:06,839
t 더하기 1을 계산하려면 t 더하기 2 등이 필요

413
00:17:06,839 --> 00:17:09,000
하지만 여기서는 시간을 거슬러 계산하기 때문에

414
00:17:09,000 --> 00:17:11,339


415
00:17:11,339 --> 00:17:13,559
p 더하기 1에 대해 예상되는 자유 에너지가 무엇인지 이미 알고

416
00:17:13,559 --> 00:17:16,020
있고 기본적으로

417
00:17:16,020 --> 00:17:17,520
동일한 방정식입니다.  당신은

418
00:17:17,520 --> 00:17:20,900
그것을 시간을 거꾸로 하고 있고

419
00:17:20,900 --> 00:17:23,520
정교한 추론에서 그림으로

420
00:17:23,520 --> 00:17:25,619
당신은 연구를 하려고 하지만

421
00:17:25,619 --> 00:17:27,660
동적 프로그래밍 알고리즘에서 당신은

422
00:17:27,660 --> 00:17:30,120
당신의 계획을 거꾸로 하고 있습니다 어

423
00:17:30,120 --> 00:17:32,940
테이블을 사용하고 당신의 계획이 주어졌을 때 지평선은

424
00:17:32,940 --> 00:17:35,520


425
00:17:35,520 --> 00:17:38,160
우리가 가진 문제에 대해 충분합니다  에이전트는 시간

426
00:17:38,160 --> 00:17:40,860
에 따라 최적의 조치를 취할 수 있으므로

427
00:17:40,860 --> 00:17:44,340


428
00:17:44,340 --> 00:17:46,500


429
00:17:46,500 --> 00:17:49,020
이 백워드 계획을 사용하여 순차 형식 DPS에 대한 하나의 알고리즘을 제안

430
00:17:49,020 --> 00:17:50,880
하고

431
00:17:50,880 --> 00:17:54,059
그리드 공간에 대한 시뮬레이션을 확장할 수 있었습니다.

432
00:17:54,059 --> 00:17:56,240
이전에는 신경망 없이 상호 작용할 수 있었습니다

433
00:17:56,240 --> 00:17:59,340


434
00:17:59,340 --> 00:18:01,080
음 이것이 첫 번째 솔루션이었으므로

435
00:18:01,080 --> 00:18:03,840
두 번째 솔루션은

436
00:18:03,840 --> 00:18:06,000
음 첫 번째 솔루션에서

437
00:18:06,000 --> 00:18:07,980
이 과거의 개인

438
00:18:07,980 --> 00:18:09,539
참조만 얻을 수 있도록 수정되었습니다. 다른 정보는 얻지 않고

439
00:18:09,539 --> 00:18:10,919


440
00:18:10,919 --> 00:18:12,480
다음에 대한 정보만 얻습니다.  최종 목표 상태

441
00:18:12,480 --> 00:18:15,120
와 당신이 얻는 모든 것은

442
00:18:15,120 --> 00:18:18,240
당신이 배운 환경의 모델이고 당신은

443
00:18:18,240 --> 00:18:21,059
기본적으로 결정을 내려야 하지만 물론

444
00:18:21,059 --> 00:18:22,799
두 번째 해결책은 당신이

445
00:18:22,799 --> 00:18:24,600
허용된다면 당신이 우리가 하는 것과 같은 의미 있는 자부심 선호도를 배우려고 시도할 수 있다는 것입니다.

446
00:18:24,600 --> 00:18:26,100


447
00:18:26,100 --> 00:18:28,620


448
00:18:28,620 --> 00:18:31,740


449
00:18:31,740 --> 00:18:33,960
다른 상태에 대한 정보가 있는 이전 슬라이드에서도 보았지만 올바른 방법을

450
00:18:33,960 --> 00:18:35,400
배우려면

451
00:18:35,400 --> 00:18:38,039
최적의 동작의 효율적인 계산에

452
00:18:38,039 --> 00:18:40,440
대해 이야기하는 최적 제어 문헌의 주요 작업이 있으며

453
00:18:40,440 --> 00:18:43,380


454
00:18:43,380 --> 00:18:45,900
그 작업에는

455
00:18:45,900 --> 00:18:47,760
우리와 유사한 양이 있습니다.

456
00:18:47,760 --> 00:18:49,500
선호도 함수라고 하는 사전 선호도입니다.

457
00:18:49,500 --> 00:18:52,200
예를 들어 이 그리드 세계에서

458
00:18:52,200 --> 00:18:54,240
어두운 색상이 더 선호되므로

459
00:18:54,240 --> 00:18:56,400
이것이 최종 골드 상태를 통과하면

460
00:18:56,400 --> 00:18:58,740
이 문서의

461
00:18:58,740 --> 00:19:01,980
에이전트가 하려고 하는 것 또는 이 문서의 학습 방법은 다음과

462
00:19:01,980 --> 00:19:04,580
같습니다.  하려고 하는 것은 이

463
00:19:04,580 --> 00:19:06,900
바람직함 함수를

464
00:19:06,900 --> 00:19:09,059
가능한 한 최적으로 학습하는 것입니다. 이 백서에서 보여준

465
00:19:09,059 --> 00:19:12,660
것은

466
00:19:12,660 --> 00:19:15,179
특정 학습 규칙을 사용하여 바람직함 함수를 학습하려고 하면

467
00:19:15,179 --> 00:19:18,120
계산적으로 훨씬

468
00:19:18,120 --> 00:19:20,340
더 효율적이라는 것입니다.

469
00:19:20,340 --> 00:19:22,919
강화

470
00:19:22,919 --> 00:19:24,960
학습 알고리즘은 잘 알려져 있으므로 Q 학습은

471
00:19:24,960 --> 00:19:27,179
잘 알려진 계산 최적

472
00:19:27,179 --> 00:19:29,520
알고리즘이지만 이 논문에서는

473
00:19:29,520 --> 00:19:31,140


474
00:19:31,140 --> 00:19:32,880
이러한 종류의 바람직함 함수를 학습하기 위한 특정 학습 규칙이

475
00:19:32,880 --> 00:19:35,539
훨씬 빠르고 이 근사값은

476
00:19:35,539 --> 00:19:38,460
그것이 최적 바람직함 함수와 얼마나 다른지를 나타냅니다.

477
00:19:38,460 --> 00:19:40,559


478
00:19:40,559 --> 00:19:42,480
바람직함 함수는 우리의

479
00:19:42,480 --> 00:19:45,179
사전 선호도일 뿐이며

480
00:19:45,179 --> 00:19:48,600
언급한 바와 같이 학습은 Q 학습에서

481
00:19:48,600 --> 00:19:50,100
Q 함수를 학습하는 것보다 훨씬 효율적이므로

482
00:19:50,100 --> 00:19:53,039


483
00:19:53,039 --> 00:19:55,860


484
00:19:55,860 --> 00:19:57,600


485
00:19:57,600 --> 00:19:59,820
환경과 이

486
00:19:59,820 --> 00:20:01,860
특정 그리드 세계 환경에서 얻는 보상에 따라 특정 학습 규칙입니다.

487
00:20:01,860 --> 00:20:03,539


488
00:20:03,539 --> 00:20:05,220
희박한 친구

489
00:20:05,220 --> 00:20:08,580
선호도와 유사한 마지막 단계에서만 보상을 제공합니다. 에이전트는 기본적으로

490
00:20:08,580 --> 00:20:11,400
최종 목표 상태에 도달할 때까지 보상을 받지 못합니다.

491
00:20:11,400 --> 00:20:14,760
이 학습 규칙을 사용하면

492
00:20:14,760 --> 00:20:17,640


493
00:20:17,640 --> 00:20:20,100
얼마나 빠르거나 느린지 제어하는 ​​매개변수 ETA가 있습니다.

494
00:20:20,100 --> 00:20:22,980
Learning Happens 그래서 기본적으로 우리는

495
00:20:22,980 --> 00:20:24,200


496
00:20:24,200 --> 00:20:26,880
이 학습

497
00:20:26,880 --> 00:20:29,340
매개변수 Rita의 효과를 연구하려고 시도하지만 우리가 관찰한 것은

498
00:20:29,340 --> 00:20:32,400
매우 견고하다는 것입니다.

499
00:20:32,400 --> 00:20:35,059


500
00:20:35,059 --> 00:20:38,700
이 학습 매개변수의 변수 값으로도 안정적으로 이전 선호도를 학습할 수

501
00:20:38,700 --> 00:20:41,580
있으며 우리가 본 것은

502
00:20:41,580 --> 00:20:43,620
에이전트가 할 수 있다는 것입니다.

503
00:20:43,620 --> 00:20:45,539
시간이 지남에 따라 의미 있는 이전 성능을 매우 빠르게 학습

504
00:20:45,539 --> 00:20:48,600
하고 이러한 의미 있는 프라임 기본 설정을 사용하면 에이전트가

505
00:20:48,600 --> 00:20:50,700


506
00:20:50,700 --> 00:20:53,580
많은 계획을 세울 필요가 없습니다. 최적의

507
00:20:53,580 --> 00:20:56,160
행동 또는 목적이 있는 행동을

508
00:20:56,160 --> 00:20:59,700
매우 짧은 시간에 관리할 수 있습니다.

509
00:20:59,700 --> 00:21:02,460


510
00:21:02,460 --> 00:21:04,679


511
00:21:04,679 --> 00:21:07,919
의사 결정을 위한 활성 추론 알고리즘을 확장하고 계산 효율성에 대해 이야기합니다

512
00:21:07,919 --> 00:21:11,400
어 우리는

513
00:21:11,400 --> 00:21:13,320
동적 프로그래밍 방법이

514
00:21:13,320 --> 00:21:16,440
미래에 30개의 시간 단계를 심을 수 있다는 것을 보았습니다.

515
00:21:16,440 --> 00:21:18,360


516
00:21:18,360 --> 00:21:21,120


517
00:21:21,120 --> 00:21:23,700
추론

518
00:21:23,700 --> 00:21:26,880
및 두 번째 방법은

519
00:21:26,880 --> 00:21:29,580
우리가 능동적 추론이라고 부르는 사전 선호도를 학습

520
00:21:29,580 --> 00:21:32,340
하고 한 단계만 앞서 계획하면 되므로

521
00:21:32,340 --> 00:21:34,740


522
00:21:34,740 --> 00:21:36,919
그런 의미에서 훨씬 더 계산적으로 효율적이지만

523
00:21:36,919 --> 00:21:39,659


524
00:21:39,659 --> 00:21:41,640
우리가 배우지 않는 DPFE 방법에서 그렇게 배워야 합니다.  우리는

525
00:21:41,640 --> 00:21:43,799
선호도에 따라 지점을 사용하고

526
00:21:43,799 --> 00:21:44,520


527
00:21:44,520 --> 00:21:46,500
계획의 전체 깊이를 수행하고 다른

528
00:21:46,500 --> 00:21:48,240
방법에서는 에이전트가

529
00:21:48,240 --> 00:21:50,280
선호도에 따라 이를 배우도록 하지만 제 시간에 수행해야 할 작업을 그래픽으로

530
00:21:50,280 --> 00:21:53,280
많이 알고 있기 때문에 계획을 많이 절약할 수 있습니다.

531
00:21:53,280 --> 00:21:57,299


532
00:21:57,299 --> 00:22:00,179
우리는 음

533
00:22:00,179 --> 00:22:01,799
DPFE 방법이 정말

534
00:22:01,799 --> 00:22:04,020
계산적으로 효율적이라는 것을 볼 수 있습니다.

535
00:22:04,020 --> 00:22:06,600
어, AI 50에서

536
00:22:06,600 --> 00:22:08,520
하나의 방법과 동일하게 시간에 대해 플롯할 때

537
00:22:08,520 --> 00:22:10,740
음, 기본적으로 계산적으로

538
00:22:10,740 --> 00:22:12,659


539
00:22:12,659 --> 00:22:16,220
더 저렴하고 그렇습니다.

540
00:22:16,220 --> 00:22:19,860


541
00:22:19,860 --> 00:22:21,720


542
00:22:21,720 --> 00:22:24,120
환경에서 우리는

543
00:22:24,120 --> 00:22:27,600
이 방법을 테스트했습니다. 일반적으로 활성 영향 문헌에서 볼 수 있는 차원이 5 또는 10인 상태 공간과 비교하여

544
00:22:27,600 --> 00:22:28,380


545
00:22:28,380 --> 00:22:31,020
900개 상태와 같은 매우 거대한 상태 공간에서 이러한 방법을 테스트했습니다. 음

546
00:22:31,020 --> 00:22:32,000


547
00:22:32,000 --> 00:22:33,840


548
00:22:33,840 --> 00:22:36,120


549
00:22:36,120 --> 00:22:38,640


550
00:22:38,640 --> 00:22:40,559


551
00:22:40,559 --> 00:22:43,200
그래서 저는

552
00:22:43,200 --> 00:22:44,760
우리가  여기서는 신경망을 사용하지 않고

553
00:22:44,760 --> 00:22:47,039
음

554
00:22:47,039 --> 00:22:49,740
설명 가능한 활성 추론 에이전트를 사용하고 있습니다.

555
00:22:49,740 --> 00:22:52,200
필요한 모든 행렬

556
00:22:52,200 --> 00:22:53,820
곱셈을 수행하여 이러한 알고리즘에서 발생하는

557
00:22:53,820 --> 00:22:55,140


558
00:22:55,140 --> 00:22:56,220


559
00:22:56,220 --> 00:22:58,620
모든 계산에 액세스하고 음 설명할 수

560
00:22:58,620 --> 00:23:00,179


561
00:23:00,179 --> 00:23:02,280
있으며 이러한 그리드에서 먼저 테스트했을 때

562
00:23:02,280 --> 00:23:04,559
우리는 이것을 검증했습니다.

563
00:23:04,559 --> 00:23:06,780
understates가 있는 더 작은 그리드에서

564
00:23:06,780 --> 00:23:08,580


565
00:23:08,580 --> 00:23:11,220


566
00:23:11,220 --> 00:23:12,780
Queue learning

567
00:23:12,780 --> 00:23:15,059
및 dynaq dynacy와 같은 Benchmark 강화 학습 알고리즘과 비교했을 때 모델 기반

568
00:23:15,059 --> 00:23:17,760
강화 학습 알고리즘과

569
00:23:17,760 --> 00:23:20,280


570
00:23:20,280 --> 00:23:24,419
DPFE 및 aif인 새로 제안된 에이전트를 비교한 결과 정말 좋은

571
00:23:24,419 --> 00:23:27,900
성능과  aif 에이전트는 약간

572
00:23:27,900 --> 00:23:29,220
더 나쁩니다. 그것은 단지

573
00:23:29,220 --> 00:23:31,080
한 단계 앞서 계획하기 때문입니다. 하지만

574
00:23:31,080 --> 00:23:34,500


575
00:23:34,500 --> 00:23:36,419
계획을 풀타임으로 수행하는 DPFE 에이전트는

576
00:23:36,419 --> 00:23:37,919
개인 학습

577
00:23:37,919 --> 00:23:41,039
알고리즘을 벤치마킹하는 것만큼 좋은 성능을 발휘합니다.

578
00:23:41,039 --> 00:23:44,640


579
00:23:44,640 --> 00:23:47,100
골드

580
00:23:47,100 --> 00:23:49,620
상태는 에이전트가

581
00:23:49,620 --> 00:23:53,039


582
00:23:53,039 --> 00:23:54,480
음

583
00:23:54,480 --> 00:23:56,520
확률적 골드 상태로 이동해야 했을 때

584
00:23:56,520 --> 00:23:59,460
매 10개의 에피소드마다 골드 상태를 변경했으며

585
00:23:59,460 --> 00:24:01,260
Dyna 대기열이

586
00:24:01,260 --> 00:24:04,140
bpfe 에이전트보다 일종의 복구 및 수행에 더 많은 시간이 걸린다는 것을 관찰했습니다.

587
00:24:04,140 --> 00:24:07,200


588
00:24:07,200 --> 00:24:09,059
이 확률론적 환경에서 DPFE 에이전트는

589
00:24:09,059 --> 00:24:11,280


590
00:24:11,280 --> 00:24:13,620
dynacy 에이전트보다 훨씬 더 잘 수행되었으며

591
00:24:13,620 --> 00:24:16,500
AI 단계와 회복이 음

592
00:24:16,500 --> 00:24:19,140
더 빠르지만 다른 에이전트만큼 좋지는 않다는 것을 알 수 있습니다.

593
00:24:19,140 --> 00:24:22,500


594
00:24:22,500 --> 00:24:25,200
방법 그럼 네

595
00:24:25,200 --> 00:24:27,960
경청해주셔서 감사합니다 그리고 저는 토론을 위해 열려있습니다 좋습니다

596
00:24:27,960 --> 00:24:30,380


597
00:24:31,640 --> 00:24:34,740


598
00:24:34,740 --> 00:24:36,360


599
00:24:36,360 --> 00:24:38,520
굉장합니다 와우 아주 좋습니다 좋습니다 좋습니다

600
00:24:38,520 --> 00:24:43,200


601
00:24:43,200 --> 00:24:44,460
토론을 시작할 때

602
00:24:44,460 --> 00:24:47,280
음 누가 먼저 추가하고 싶은 것이 있으면

603
00:24:47,280 --> 00:24:50,220
어떻게 이 프로젝트를 작업하게 되었습니까

604
00:24:50,220 --> 00:24:52,740
어 공부하고 있었습니까  능동적

605
00:24:52,740 --> 00:24:54,720
추론 그리고 당신은 이 질문이

606
00:24:54,720 --> 00:24:57,900
흥미롭다고 생각했거나 아니면 당신이

607
00:24:57,900 --> 00:25:00,179
계획을 세우고 있었고 방법으로 능동적 추론을 하게 되었나요 음 그래

608
00:25:00,179 --> 00:25:03,059


609
00:25:03,059 --> 00:25:05,159


610
00:25:05,159 --> 00:25:08,400
나에 대한 약간의 배경 지식이 있어서

611
00:25:08,400 --> 00:25:11,340
학부와 포스트 그리고

612
00:25:11,340 --> 00:25:13,080
끝날 무렵 물리학을 공부했습니다.  졸업 후 저는

613
00:25:13,080 --> 00:25:15,120
게임 이론 및 재사용 가능한 학습과 같은 것에 관심을 갖게 되었고

614
00:25:15,120 --> 00:25:17,880


615
00:25:17,880 --> 00:25:20,880
Adil 교수 및 Manoj 교수와 공동 박사 학위를 위해 uh에 합류했습니다.

616
00:25:20,880 --> 00:25:23,100
그래서

617
00:25:23,100 --> 00:25:25,200
Manoj 교수는 제어 이론 사람이고

618
00:25:25,200 --> 00:25:28,140
거래는 신경 과학자이며

619
00:25:28,140 --> 00:25:30,600
제 초기에는  PhD 저는 활성 추론 문헌을 읽기 시작했고

620
00:25:30,600 --> 00:25:34,020


621
00:25:34,020 --> 00:25:37,260
문제에서 구현하고 싶었고

622
00:25:37,260 --> 00:25:39,840
항상 설명 가능한

623
00:25:39,840 --> 00:25:42,720
활성 추론에 매료되었습니다. 어

624
00:25:42,720 --> 00:25:44,700
예상된 자유 에너지가

625
00:25:44,700 --> 00:25:46,860
위험과 예상되는 모호성을 최소화하려는 아이디어에 대해 그것은

626
00:25:46,860 --> 00:25:49,740
또한 에이전트를 작동하게 만드는 것 뿐만 아니라

627
00:25:49,740 --> 00:25:52,020
또한 그들이 어떻게 작동하는지 말할 수 있다는 것이

628
00:25:52,020 --> 00:25:54,419
적극적인 영향에 대해 저를 매료시켰고

629
00:25:54,419 --> 00:25:56,820
처음에는 그것들을 구현하려고 노력했고

630
00:25:56,820 --> 00:26:00,179
우리가 출판한 회의 논문이 있습니다.

631
00:26:00,179 --> 00:26:03,720


632
00:26:03,720 --> 00:26:06,419


633
00:26:06,419 --> 00:26:08,100
능동적

634
00:26:08,100 --> 00:26:10,620
추론을 한 다음 정교한 추론 작업을 시작했습니다

635
00:26:10,620 --> 00:26:12,659


636
00:26:12,659 --> 00:26:15,539
음 예 그래서 기본적으로 이러한 방법은 맵을

637
00:26:15,539 --> 00:26:17,580
확장하고 싶었던 필요성에서 나왔고

638
00:26:17,580 --> 00:26:21,539
항상

639
00:26:21,539 --> 00:26:22,919


640
00:26:22,919 --> 00:26:25,559


641
00:26:25,559 --> 00:26:28,020
사용하고 싶지 않았기 때문에 음 깊은 능동적 추론을 사용하는 버스를 유지했습니다.

642
00:26:28,020 --> 00:26:30,539
계획을 수행할 신경망 심층

643
00:26:30,539 --> 00:26:32,100
강화 학습 자체가

644
00:26:32,100 --> 00:26:34,140
거대한 분야이기 때문에 음

645
00:26:34,140 --> 00:26:37,080


646
00:26:37,080 --> 00:26:39,240
능동적 추론을 확장하려는 경우 심층

647
00:26:39,240 --> 00:26:41,820
강화 학습을 수행할 수 있습니다. 그게 제가

648
00:26:41,820 --> 00:26:43,860
생각한 것입니다. 예, 기본적으로

649
00:26:43,860 --> 00:26:45,659
배경이고 예, 그렇게 됩니다.

650
00:26:45,659 --> 00:26:48,720
괜찮았습니다.

651
00:26:48,720 --> 00:26:50,880
먼저 라이브 채팅에서 질문으로 이동

652
00:26:50,880 --> 00:26:52,559
하고 프레젠테이션에 많은

653
00:26:52,559 --> 00:26:54,779
내용이 있었기 때문에 아마도 다양한 측면에 대해 논의할 것입니다.

654
00:26:54,779 --> 00:26:57,720
그래서

655
00:26:57,720 --> 00:27:01,980
NL Dawn은

656
00:27:01,980 --> 00:27:04,620


657
00:27:04,620 --> 00:27:07,679
다음과 같이 씁니다.  Time Horizon 어떤 종류의 평균 필드

658
00:27:07,679 --> 00:27:11,039
근사화가 s 저장소의 Q를 인수분해하는 데 사용되었으므로

659
00:27:11,039 --> 00:27:13,020


660
00:27:13,020 --> 00:27:16,100


661
00:27:19,980 --> 00:27:23,040
문제는

662
00:27:23,040 --> 00:27:24,299
[음악]

663
00:27:24,299 --> 00:27:28,799
DPFE에서 예상되는 자유 에너지에 관한 것으로 가정하고

664
00:27:28,799 --> 00:27:31,380
기본적으로 이를 계산하기 위해

665
00:27:31,380 --> 00:27:32,159
음

666
00:27:32,159 --> 00:27:35,279
그래서 내 시뮬레이션에서 나는

667
00:27:35,279 --> 00:27:39,120
이것을 위해 믿음 전파를 사용합니다.  믿음 대기열을 사용할 수도 있고

668
00:27:39,120 --> 00:27:41,460
변형

669
00:27:41,460 --> 00:27:43,140
메시지 전달이나 한계 메시지

670
00:27:43,140 --> 00:27:47,279
전달을 사용할 수도 있습니다. 문제는 아니지만

671
00:27:47,400 --> 00:27:50,580
일단 이 믿음 대기열이 있으면

672
00:27:50,580 --> 00:27:52,740
어떻게 해야 합니까?

673
00:27:52,740 --> 00:27:55,340


674
00:27:56,940 --> 00:27:59,900
예 그래서

675
00:27:59,940 --> 00:28:04,260
제가 Q를 상상한다고 말할 때

676
00:28:04,260 --> 00:28:07,520
제가 주로 사용하는 것입니다.  하나의 핫 벡터이므로

677
00:28:07,520 --> 00:28:11,220
결정을 내리기 위해 활성 추론에서

678
00:28:11,220 --> 00:28:13,260
인식 단계에서 벗어났다는 믿음을 사용

679
00:28:13,260 --> 00:28:16,380
하지만

680
00:28:16,380 --> 00:28:18,720
이것이 하나의 핫 벡터인 하드 테이블이라고 상상하기 위해

681
00:28:18,720 --> 00:28:22,020


682
00:28:22,020 --> 00:28:25,380
생성 모델에 10개의 상태가 있다고 가정합니다.

683
00:28:25,380 --> 00:28:27,900
당신이 사용하는 대기열은

684
00:28:27,900 --> 00:28:29,100


685
00:28:29,100 --> 00:28:32,220
계획을 위한 정확한 단서이지만 의사

686
00:28:32,220 --> 00:28:33,840
결정을 위해 인식 단계에서 얻은 인상 깊은

687
00:28:33,840 --> 00:28:36,299
부정확한 평균 필드 근사 대기열을 사용하므로

688
00:28:36,299 --> 00:28:38,460


689
00:28:38,460 --> 00:28:40,679
질문에 대한 답변인지는 모르겠지만

690
00:28:40,679 --> 00:28:42,059


691
00:28:42,059 --> 00:28:44,880
음 하지만 어쩌면 나는 또한 생각하고 싶습니다.

692
00:28:44,880 --> 00:28:46,919
또한 단계에 있을 수 있는 근사치에 대해 더 많이 생각해야 합니다.

693
00:28:46,919 --> 00:28:49,200


694
00:28:49,200 --> 00:28:50,880


695
00:28:50,880 --> 00:28:53,700
예, 원하는 경우 더 작성할 수 있습니다. 음

696
00:28:53,700 --> 00:28:56,460


697
00:28:56,460 --> 00:29:00,419
선호도 학습에 대해 좀 더 일반적으로 이야기하겠습니다.

698
00:29:00,419 --> 00:29:02,700
능동적

699
00:29:02,700 --> 00:29:05,940
추론 생성 모델의 맥락에서 우리는

700
00:29:05,940 --> 00:29:08,279
은닉 상태에서 관찰 사이를 중재

701
00:29:08,279 --> 00:29:10,020
하고 학습은 세계의 은닉 상태에서 관찰 사이의 매핑을

702
00:29:10,020 --> 00:29:12,480
학습하는 것에 대해 많은 의미가 있습니다.

703
00:29:12,480 --> 00:29:14,220


704
00:29:14,220 --> 00:29:15,779
그런 다음 우리는

705
00:29:15,779 --> 00:29:18,240


706
00:29:18,240 --> 00:29:20,399
행동의 결과와 사물이 시간을 통해 어떻게 변하는지 학습

707
00:29:20,399 --> 00:29:21,419


708
00:29:21,419 --> 00:29:24,659
하고 선호 학습은 위에서 학습합니다.  c

709
00:29:24,659 --> 00:29:27,960
c 그리고 당신은 이것이

710
00:29:27,960 --> 00:29:29,700
매우 음

711
00:29:29,700 --> 00:29:31,340
당신이

712
00:29:31,340 --> 00:29:34,320
배울 수 있는 흥미로운 변수라고 강조했습니다.

713
00:29:34,320 --> 00:29:38,100
저는 우리가 올바른 것을 배우는 법을 어떻게 배울 수 있는지 궁금합니다.

714
00:29:38,100 --> 00:29:41,159


715
00:29:41,159 --> 00:29:42,960
우리가 적응형 선호도를 배우고 있다는 것을

716
00:29:42,960 --> 00:29:44,399


717
00:29:44,399 --> 00:29:46,200
어떻게 알 수 있습니까?  그 선호도

718
00:29:46,200 --> 00:29:48,720
학습은 인지 오버헤드나 계산 복잡성을 줄여줍니까?

719
00:29:48,720 --> 00:29:50,820


720
00:29:50,820 --> 00:29:53,460
그래 대단해

721
00:29:53,460 --> 00:29:54,480
음그래서

722
00:29:54,480 --> 00:29:57,179
만약 당신이 기도 선호도를 배우려고 한다면 그것은

723
00:29:57,179 --> 00:29:59,940


724
00:29:59,940 --> 00:30:01,559
추적할 것이 있거나

725
00:30:01,559 --> 00:30:04,500
보상처럼 최대화할 것이 있다고 가정합니다.

726
00:30:04,500 --> 00:30:06,779


727
00:30:06,779 --> 00:30:08,340


728
00:30:08,340 --> 00:30:09,840


729
00:30:09,840 --> 00:30:12,960
최대화하려는 환경에서 오는 명확한 보상이 있다고 설정하고

730
00:30:12,960 --> 00:30:15,000
이 그리드에 대해 마지막 단계에서만 그 보상을 얻는다는 것이

731
00:30:15,000 --> 00:30:17,220


732
00:30:17,220 --> 00:30:19,020
이 문제를 어렵게 만드는 것입니다.

733
00:30:19,020 --> 00:30:22,500
타임

734
00:30:22,500 --> 00:30:25,140
스텝은 기본적으로 무엇을 해야 하는지 알고 있습니다.

735
00:30:25,140 --> 00:30:28,020


736
00:30:28,020 --> 00:30:30,419
매 타임 스텝마다 그 보상을 추구해야 하지만 여기서는

737
00:30:30,419 --> 00:30:32,880


738
00:30:32,880 --> 00:30:36,059
한 가지 보상을 얻기 위해 15 타임 스텝을 앞서야 할 수 있으며

739
00:30:36,059 --> 00:30:39,659
기본적으로 여기서 그렇게 하기가 어렵습니다.

740
00:30:39,659 --> 00:30:41,520


741
00:30:41,520 --> 00:30:43,020


742
00:30:43,020 --> 00:30:44,820


743
00:30:44,820 --> 00:30:47,940


744
00:30:47,940 --> 00:30:49,919
환경이 내가 하는 일에 관심이 없거나

745
00:30:49,919 --> 00:30:52,200
무엇이

746
00:30:52,200 --> 00:30:54,840
좋은지 나쁜지 정의할 수 없는 경우 환경에 존재하는 보상 구조가 있어야 합니다.  그런 다음

747
00:30:54,840 --> 00:30:56,340
이전 선호도를 학습하는 것은 의미가 없습니다. 그래서

748
00:30:56,340 --> 00:30:57,840
여기서

749
00:30:57,840 --> 00:30:59,399
보상은 Sprite 차이의 학습을 제어하는 ​​것이고

750
00:30:59,399 --> 00:31:01,559


751
00:31:01,559 --> 00:31:03,600
좋은 점은 내가

752
00:31:03,600 --> 00:31:06,539
마지막 단계에서 보상을 얻더라도

753
00:31:06,539 --> 00:31:09,240
음 내 B 행렬이 있다는 것입니다.  나는

754
00:31:09,240 --> 00:31:11,340


755
00:31:11,340 --> 00:31:12,659


756
00:31:12,659 --> 00:31:14,760
이 최종 골드 상태에 도달한 다른 상태에서 전환한 경험이

757
00:31:14,760 --> 00:31:16,860
있으며

758
00:31:16,860 --> 00:31:19,440
우리가 사용하고 있는 이 알고리즘 또는

759
00:31:19,440 --> 00:31:21,539
우리가 사용하고 있는 학습 규칙은

760
00:31:21,539 --> 00:31:23,820


761
00:31:23,820 --> 00:31:26,340
제가 소개한 논문에서 바람직함 함수라고 하는 최적 제어에서 유사한 것을 정확하게 학습하고 있습니다.

762
00:31:26,340 --> 00:31:27,539


763
00:31:27,539 --> 00:31:30,539
그리고 당신이 이

764
00:31:30,539 --> 00:31:32,760
바람직함 함수를 가지고 있다는 것을 감안할 때,

765
00:31:32,760 --> 00:31:36,120
아마도 내가 이 상태에서 시작한다고 상상해보세요. 그러면 상태

766
00:31:36,120 --> 00:31:37,860


767
00:31:37,860 --> 00:31:40,399


768
00:31:40,399 --> 00:31:44,279


769
00:31:44,279 --> 00:31:46,620
아래에 명시된 um 상태가

770
00:31:46,620 --> 00:31:48,899
내가 하나만 계획하는 것보다 더 선호되는지 결정을 내리기 위해 가장 가까운 이웃을 살펴봐야 합니다.

771
00:31:48,899 --> 00:31:50,520
대신 시간이 걸리고 그것이

772
00:31:50,520 --> 00:31:52,380
내가 취해야 할 최적의 결정이므로

773
00:31:52,380 --> 00:31:54,059
이 프라이드 선호도를 배우면

774
00:31:54,059 --> 00:31:55,919


775
00:31:55,919 --> 00:31:57,419
가장 가까운 이웃만 보고 있다는 점에서 인지 부하가 ​​줄어듭니다.

776
00:31:57,419 --> 00:31:59,760


777
00:31:59,760 --> 00:32:01,799
이 마지막 좋은 상태까지 계획을 세울 필요가 없습니다.

778
00:32:01,799 --> 00:32:04,799
그리고 나는 이것을 가능한 한 효율적으로 배울 것입니다.

779
00:32:04,799 --> 00:32:07,260
왜냐하면 그것은

780
00:32:07,260 --> 00:32:09,659
우리가 그것의 견고성을 테스트한 보장된 알고리즘

781
00:32:09,659 --> 00:32:13,320
이고 또한

782
00:32:13,320 --> 00:32:14,580
내가 환경에서 얻는 보상에 의해 알려지기 때문입니다.

783
00:32:14,580 --> 00:32:15,659


784
00:32:15,659 --> 00:32:20,100


785
00:32:20,100 --> 00:32:22,860
무엇이 선호되는가 어 그러면

786
00:32:22,860 --> 00:32:24,840


787
00:32:24,840 --> 00:32:26,520


788
00:32:26,520 --> 00:32:28,559
이 알고리즘에 의해 의미 있는 개인 친구를 학습하는 것이 보장됩니다.

789
00:32:28,559 --> 00:32:31,559
따라서 가장 가까운 이웃

790
00:32:31,559 --> 00:32:34,260
과 한 번 단계 추론만

791
00:32:34,260 --> 00:32:37,320
사용되는 경우 이러한 종류의

792
00:32:37,320 --> 00:32:39,360
선호도 학습 에이전트가

793
00:32:39,360 --> 00:32:43,158
로컬 Optima에 갇히지 않도록 방지하는 것은

794
00:32:43,320 --> 00:32:47,520
음 그래 그래서  여기에 로컬 옵티마가 없을 것입니다.

795
00:32:47,520 --> 00:32:50,340


796
00:32:50,340 --> 00:32:52,860
음, 왜 로컬 옵티마가 있을 까요?

797
00:32:52,860 --> 00:32:57,059
보상을 사용하여 학습하는 경우 어

798
00:32:57,059 --> 00:33:00,120
그래, 로컬 옵티마가 있으면

799
00:33:00,120 --> 00:33:02,159
로컬 옵티마에 갇히게 되지만 이겼습니다.

800
00:33:02,159 --> 00:33:05,460
하나가 아닙니다 어 만약

801
00:33:05,460 --> 00:33:07,440
당신이 배우는 것이 이런 식이라면

802
00:33:07,440 --> 00:33:08,760
당신은 당신 자신의

803
00:33:08,760 --> 00:33:11,940
경험과 어떻게 시간에 대한 보상을 얻었는지

804
00:33:11,940 --> 00:33:14,220
어 언젠가 그리고 우리가

805
00:33:14,220 --> 00:33:16,980
관찰한 것은 어 그것이 매우

806
00:33:16,980 --> 00:33:17,760


807
00:33:17,760 --> 00:33:20,399
점진적이고 결함이 없다는 것입니다  또는

808
00:33:20,399 --> 00:33:23,880
로컬 옵티마는 학습할 때 기본 설정을

809
00:33:23,880 --> 00:33:27,840
다시 채우는 것이므로

810
00:33:27,840 --> 00:33:30,179


811
00:33:30,179 --> 00:33:33,539


812
00:33:33,539 --> 00:33:36,779
원위 목표까지 부드러운 경로가 있을 수 있습니다.

813
00:33:36,779 --> 00:33:39,480
예 그래서 애니메이션에서는 등

814
00:33:39,480 --> 00:33:42,299
느낌처럼 보이지만

815
00:33:42,299 --> 00:33:44,279
실제로는  당신의 경험에서 그것을 배우는

816
00:33:44,279 --> 00:33:45,360


817
00:33:45,360 --> 00:33:46,620
음

818
00:33:46,620 --> 00:33:49,980
앞으로 바로 그래서 내가

819
00:33:49,980 --> 00:33:51,480
이 상태에서 상태로 전환했을 때 보상을 관찰했습니다

820
00:33:51,480 --> 00:33:53,100
그래서 이것은 좋을 것입니다

821
00:33:53,100 --> 00:33:55,860
어 그럼 다음 단계에서

822
00:33:55,860 --> 00:33:58,559
나는 괜찮다고 말합니다 이 날짜는

823
00:33:58,559 --> 00:34:00,419
저를 그곳으로 데려다 줄 책임이 있습니다  그래서 이것은 또한 좋을 수도

824
00:34:00,419 --> 00:34:03,120
있지만 다른 것만큼 좋지는 않습니다.

825
00:34:03,120 --> 00:34:05,100
그래서 그것은 거꾸로 학습하는 것처럼 보이지만

826
00:34:05,100 --> 00:34:07,799
실제로는 실제

827
00:34:07,799 --> 00:34:12,000
um에서 t 더하기 하나의 경험으로 배우는 것입니다.

828
00:34:13,500 --> 00:34:15,119
알다시피

829
00:34:15,119 --> 00:34:16,980
그런 식으로

830
00:34:16,980 --> 00:34:20,339
음 로컬 최대값을 가질 수 없기 때문에

831
00:34:20,339 --> 00:34:21,300
음

832
00:34:21,300 --> 00:34:24,119
그래 이게 그렇게 하는 학습 규칙이라

833
00:34:24,119 --> 00:34:25,859


834
00:34:25,859 --> 00:34:29,219
좀 더 체계적으로 대답하는 방법을 모르겠어 그래 그래 음

835
00:34:29,219 --> 00:34:33,000
어떤 실제 상황이나 또는

836
00:34:33,000 --> 00:34:35,399
어떤 실제 상황에서

837
00:34:35,399 --> 00:34:37,560
이런 종류의 선호도 학습이 일어나는 것을 볼 수 있어

838
00:34:37,560 --> 00:34:40,080


839
00:34:40,080 --> 00:34:41,159
그래

840
00:34:41,159 --> 00:34:43,020
대단해  질문

841
00:34:43,020 --> 00:34:46,080
그래서 뉴런이 pongum의 게임을 배우고 있는 우리 연구실에서 나온 논문이 하나 있습니다.

842
00:34:46,080 --> 00:34:48,659


843
00:34:48,659 --> 00:34:51,359


844
00:34:51,359 --> 00:34:52,980
논문이

845
00:34:52,980 --> 00:34:55,260
dist brain이라고 하고 장치가

846
00:34:55,260 --> 00:34:57,000
strain이고 그들이

847
00:34:57,000 --> 00:34:58,740
성취한 것은 그들이 관리한다는 것입니다.

848
00:34:58,740 --> 00:35:00,300


849
00:35:00,300 --> 00:35:03,420
실리콘 칩에서 뉴런을 배양하고

850
00:35:03,420 --> 00:35:04,020


851
00:35:04,020 --> 00:35:08,520


852
00:35:08,520 --> 00:35:11,400
공을 성공적으로 태클하거나

853
00:35:11,400 --> 00:35:13,880
게임을 잘 했을 때 음 좋은 피드백 신호를 주고 충격을 주었습니다

854
00:35:13,880 --> 00:35:15,720
음

855
00:35:15,720 --> 00:35:18,119
실수를 했을 때 우리가 본 것은

856
00:35:18,119 --> 00:35:19,560


857
00:35:19,560 --> 00:35:22,260
종이에서 우리가

858
00:35:22,260 --> 00:35:24,140
시간이 지남에 따라 게임을 하는 법을 배우고

859
00:35:24,140 --> 00:35:27,359
그런 시나리오에서

860
00:35:27,359 --> 00:35:29,880
내가 세상에서 긍정적인 말을 하면

861
00:35:29,880 --> 00:35:33,359
내가

862
00:35:33,359 --> 00:35:35,520


863
00:35:35,520 --> 00:35:37,380
과거에 관찰한 상태와 좋은 것을 연관시킬 수 있다고 상상해 보세요.  그래서

864
00:35:37,380 --> 00:35:38,880
나는

865
00:35:38,880 --> 00:35:39,660
음

866
00:35:39,660 --> 00:35:42,119
무엇이 좋고 나쁨을 단계별로 배웠고

867
00:35:42,119 --> 00:35:44,700
그것은 합리적인 가설입니다

868
00:35:44,700 --> 00:35:46,619
그래서 만약

869
00:35:46,619 --> 00:35:47,220
음

870
00:35:47,220 --> 00:35:51,300
제가 더 건강해지라고 말하고 싶다면

871
00:35:51,300 --> 00:35:53,280
체육관에 가는 것을 좋은 것으로 연관시킬 수 있고

872
00:35:53,280 --> 00:35:54,660


873
00:35:54,660 --> 00:35:57,000


874
00:35:57,000 --> 00:35:59,099
체육관에 걷는 것도 연관시킬 수 있습니다  좋은

875
00:35:59,099 --> 00:36:01,260
일로 그럼 나는

876
00:36:01,260 --> 00:36:03,900
내 신발을 좋은 것으로 신는다고 말할 수 있으므로

877
00:36:03,900 --> 00:36:04,920
음

878
00:36:04,920 --> 00:36:06,960
사전 선호도를 배우는 것이

879
00:36:06,960 --> 00:36:10,079
말이 되지만 예 이것은 차원의

880
00:36:10,079 --> 00:36:11,640


881
00:36:11,640 --> 00:36:12,480


882
00:36:12,480 --> 00:36:14,820
저주 문제에 대한 계산적인 음 솔루션이지만

883
00:36:14,820 --> 00:36:17,040
이것을

884
00:36:17,040 --> 00:36:19,619
실제 테스트  세상은 확실히 어 우리가

885
00:36:19,619 --> 00:36:21,599
해야 할 일이고

886
00:36:21,599 --> 00:36:24,119
음 그래 나도 그렇게 하기를 기대해 좋아

887
00:36:24,119 --> 00:36:25,800


888
00:36:25,800 --> 00:36:27,660


889
00:36:27,660 --> 00:36:29,760
너가 실제 상황을 실행해보고 이게 연결되는지 보자

890
00:36:29,760 --> 00:36:32,040


891
00:36:32,040 --> 00:36:35,099
음 그래서 우리는 우리가 켜고 싶어  높은 점수를 받은

892
00:36:35,099 --> 00:36:38,280
에세이를 제출함으로써 다시 보상을 받습니다.

893
00:36:38,280 --> 00:36:39,900


894
00:36:39,900 --> 00:36:42,599
그래서

895
00:36:42,599 --> 00:36:45,540
에세이의 아이디어를 시작하는 것과 성적이라는

896
00:36:45,540 --> 00:36:48,839
선호하는 드문 결과를 보는 것 사이에는 많은 단계가 있습니다.

897
00:36:48,839 --> 00:36:51,180


898
00:36:51,180 --> 00:36:53,520


899
00:36:53,520 --> 00:36:55,260


900
00:36:55,260 --> 00:36:57,079
이것은 내가 좋은 성적을 받았던 곳에서

901
00:36:57,079 --> 00:36:59,940
형식이 잘 지정되었고

902
00:36:59,940 --> 00:37:02,880
그런 종류의 이제

903
00:37:02,880 --> 00:37:05,460
선호도의 우산을 확장한

904
00:37:05,460 --> 00:37:07,800
다음

905
00:37:07,800 --> 00:37:10,140
형식을 잘 지정하게 된 이유는 제 시간에 완료한

906
00:37:10,140 --> 00:37:12,900
다음 작업을 수행한 것입니다.  관념화 단계까지 모든 방법을 통해

907
00:37:12,900 --> 00:37:16,579
미래에

908
00:37:16,579 --> 00:37:20,640


909
00:37:20,640 --> 00:37:23,099
정확하게 한 단계 추론을 수행할 수 있고

910
00:37:23,099 --> 00:37:24,180


911
00:37:24,180 --> 00:37:26,400


912
00:37:26,400 --> 00:37:28,740


913
00:37:28,740 --> 00:37:31,740
가능한 모든 트리 구조에 대해 15번의 시간 단계 추론을 수행할 필요 없이 기술로 단계적으로 수행할 수 있습니다.

914
00:37:31,740 --> 00:37:35,180


915
00:37:35,180 --> 00:37:39,240
구현된 학습을 사용하여

916
00:37:39,240 --> 00:37:43,680
문제의 구조를 정확히 단순화했습니다. 예,

917
00:37:43,680 --> 00:37:45,540


918
00:37:45,540 --> 00:37:47,220


919
00:37:47,220 --> 00:37:51,078
모든 계산 복잡성을 다시 볼 수 있습니까?

920
00:37:51,359 --> 00:37:54,300
여기에서 CIF는 고전적인

921
00:37:54,300 --> 00:37:56,760
능동적 추론을 나타내며 계획의 전체 지평을 수행합니다.

922
00:37:56,760 --> 00:37:58,560


923
00:37:58,560 --> 00:38:00,660
음 주변에 있습니다.  10의 제곱 18. 그래서

924
00:38:00,660 --> 00:38:03,180
이것은

925
00:38:03,180 --> 00:38:07,140
100개의 상태와 4개의 사용 가능한

926
00:38:07,140 --> 00:38:09,960
작업이 있는 이 특정 그리드 예를 위한 것이므로 이것은 특별한 경우를 위한 것이며

927
00:38:09,960 --> 00:38:12,119


928
00:38:12,119 --> 00:38:14,400
사물을 원근감 있게 보기 위해 숫자를 입력하고 싶었습니다.

929
00:38:14,400 --> 00:38:16,500


930
00:38:16,500 --> 00:38:18,960
정책 공간으로 하세요

931
00:38:18,960 --> 00:38:20,640
음

932
00:38:20,640 --> 00:38:22,440


933
00:38:22,440 --> 00:38:25,380
계획의 한 단계 또는

934
00:38:25,380 --> 00:38:28,380
정교한 추론의 한 인스턴스에 대해 음 10의 18승 계산을 수행해야 합니다

935
00:38:28,380 --> 00:38:30,900
어 거기

936
00:38:30,900 --> 00:38:34,560
상태 공간도 중요하기 때문에 어 그리고 그것이

937
00:38:34,560 --> 00:38:37,140
이겼습니다  작동하지 않으므로 이 세 번째 줄은

938
00:38:37,140 --> 00:38:39,540
한 시간 동안이라도

939
00:38:39,540 --> 00:38:40,500


940
00:38:40,500 --> 00:38:42,599


941
00:38:42,599 --> 00:38:44,280


942
00:38:44,280 --> 00:38:47,400
전체 계획을 수행해야 한다면 정교한 추론을 수행하기가 정말 어렵다는 것을 보여주어야 했습니다. 하지만 거꾸로

943
00:38:47,400 --> 00:38:48,960
계획할 때는 동적 프로그래밍을 사용하면 음

944
00:38:48,960 --> 00:38:50,579


945
00:38:50,579 --> 00:38:52,500


946
00:38:52,500 --> 00:38:54,420
계획의 전체 지평선을 시도할 수 있습니다.

947
00:38:54,420 --> 00:38:56,520
음, 계산은 천 개에 불과

948
00:38:56,520 --> 00:38:58,800
하지만 학습

949
00:38:58,800 --> 00:39:01,380
선호도를 사용하면 훨씬 낮습니다.

950
00:39:01,380 --> 00:39:04,520
한 번만 수행하면

951
00:39:04,520 --> 00:39:06,440


952
00:39:06,440 --> 00:39:06,839


953
00:39:06,839 --> 00:39:08,220


954
00:39:08,220 --> 00:39:12,000
훨씬 낮습니다.

955
00:39:12,000 --> 00:39:15,480
이전

956
00:39:15,480 --> 00:39:17,640
모델 스트림에서 작업하면서 몇 가지

957
00:39:17,640 --> 00:39:19,859
계산 복잡도 추정치를 보았지만

958
00:39:19,859 --> 00:39:22,260
이것이 정말 분명하다고 생각합니다

959
00:39:22,260 --> 00:39:25,020
음 첫 번째로 생각하게 된 것은

960
00:39:25,020 --> 00:39:28,820
정교함이 저렴하다고 말한 사람이 없다는

961
00:39:28,820 --> 00:39:32,940
것입니다.

962
00:39:32,940 --> 00:39:35,099


963
00:39:35,099 --> 00:39:37,380
2, 3, 4,

964
00:39:37,380 --> 00:39:38,880
5개는 잠재적으로

965
00:39:38,880 --> 00:39:41,940
일어나기 시작하므로

966
00:39:41,940 --> 00:39:44,040


967
00:39:44,040 --> 00:39:45,720
계획의 복잡성이

968
00:39:45,720 --> 00:39:50,040
급격하게 증가하므로 능동 추론 지능 아키텍처를 상상하는 것과

969
00:39:50,040 --> 00:39:50,780


970
00:39:50,780 --> 00:39:52,460


971
00:39:52,460 --> 00:39:56,280
같이 생각하는 것처럼 교육학적으로 매우 흥미롭지

972
00:39:56,280 --> 00:39:57,660


973
00:39:57,660 --> 00:39:59,940


974
00:39:59,940 --> 00:40:01,560


975
00:40:01,560 --> 00:40:04,500
만

976
00:40:04,500 --> 00:40:07,079
이것이 그렇지 않다는 것이 꽤 분명합니다.

977
00:40:07,079 --> 00:40:09,060
그냥 열거할 수 있는 것이므로 작동할 수 있는

978
00:40:09,060 --> 00:40:10,859


979
00:40:10,859 --> 00:40:13,380


980
00:40:13,380 --> 00:40:15,240


981
00:40:15,240 --> 00:40:19,520


982
00:40:19,520 --> 00:40:22,140


983
00:40:22,140 --> 00:40:25,440


984
00:40:25,440 --> 00:40:29,220


985
00:40:29,220 --> 00:40:31,320


986
00:40:31,320 --> 00:40:33,359
신경망과 같이 잠재적으로 효과적이지만 임시방편의 복잡성 감소 방법이 아니라 계산 복잡성 감소의 원칙적인 방법에 이것을 연결하여 수행한 작업이 매우 음 매우 창의적이고 중요하다고 생각합니다.  그들이 작동

987
00:40:33,359 --> 00:40:35,280
하지만 일단 부풀어 오르기 시작하면

988
00:40:35,280 --> 00:40:38,940
이제 원칙도없고

989
00:40:38,940 --> 00:40:40,680
효능도

990
00:40:40,680 --> 00:40:43,200
정확히 없습니다 예 그리고 정교한 추론

991
00:40:43,200 --> 00:40:45,240


992
00:40:45,240 --> 00:40:47,579
동적 프로그래밍과 비교할 때 고유 한 이점이 있다는 점에 유의해야합니다. 어 당신이

993
00:40:47,579 --> 00:40:49,500


994
00:40:49,500 --> 00:40:51,839
앞으로 계획 할 때 당신은

995
00:40:51,839 --> 00:40:53,520
모든 가능성을

996
00:40:53,520 --> 00:40:55,859
올바르게 고려하지만 거꾸로 계획할 때

997
00:40:55,859 --> 00:40:58,380
예를 들어 큐 기반 탐색과 같다고 말하면

998
00:40:58,380 --> 00:41:00,300


999
00:41:00,300 --> 00:41:02,280
어딘가에 가야 하는 경우

1000
00:41:02,280 --> 00:41:03,839
대기열을 얻은 다음 풀 상태로 이동한

1001
00:41:03,839 --> 00:41:05,640
다음 거꾸로 계획하는 것이 작동하지 않을 수 있으므로

1002
00:41:05,640 --> 00:41:06,960
이것이 무엇입니까  이것은

1003
00:41:06,960 --> 00:41:09,900
내가 받은 하나의 피드백이었고 나는 음 어떤 사람들과 작업에 대해 논의했습니다.

1004
00:41:09,900 --> 00:41:10,980


1005
00:41:10,980 --> 00:41:13,920
그래서

1006
00:41:13,920 --> 00:41:16,260
음 그것은 동적 프로그래밍에 대해 주목해야 할 사항이지만

1007
00:41:16,260 --> 00:41:18,359


1008
00:41:18,359 --> 00:41:19,920
친구보다 먼저 배우는 다른 곳은

1009
00:41:19,920 --> 00:41:22,320
문제가 아니라고 생각하지만 동적

1010
00:41:22,320 --> 00:41:23,700
프로그래밍은 계산적으로 저렴하지만

1011
00:41:23,700 --> 00:41:26,460
그것은 또한 고유한 한계가 있습니다.

1012
00:41:26,460 --> 00:41:28,099


1013
00:41:28,099 --> 00:41:31,200


1014
00:41:31,200 --> 00:41:33,839
Bellman 최적성을 사용하는 동적 프로그래밍에서

1015
00:41:33,839 --> 00:41:36,420
우리는 거꾸로 해결하고 있으므로

1016
00:41:36,420 --> 00:41:38,400
Checkmate가 우리가 원하는 것과 비슷하므로

1017
00:41:38,400 --> 00:41:40,440
이제 우리는 현재까지 거꾸로 작업하고 있음을 다시 언급하기 위해 여기서 주목해야 합니다.

1018
00:41:40,440 --> 00:41:43,440
하지만 우리는

1019
00:41:43,440 --> 00:41:46,440
반사실적인

1020
00:41:46,440 --> 00:41:49,200
끝점을 탐색하지 않고 우리가 정확히 관심이 없는 끝점까지 현재로 돌아가 작업하지 않기

1021
00:41:49,200 --> 00:41:51,540


1022
00:41:51,540 --> 00:41:52,980


1023
00:41:52,980 --> 00:41:55,619
때문에 너무 무자비

1024
00:41:55,619 --> 00:41:58,320
하지만 다른 한편으로는 훨씬 더

1025
00:41:58,320 --> 00:42:00,420
제한적인

1026
00:42:00,420 --> 00:42:02,280
음

1027
00:42:02,280 --> 00:42:06,960
검색입니다.  그래서 요즘 제가 생각하고 있는 것은

1028
00:42:06,960 --> 00:42:08,460
우리가 어,

1029
00:42:08,460 --> 00:42:11,700
이 두 가지의 조합을 고려해야 한다는 것입니다. 어,

1030
00:42:11,700 --> 00:42:14,160


1031
00:42:14,160 --> 00:42:17,400
그런 반사실적인 것들을 무시할 수 있는 여유가 있고, 음

1032
00:42:17,400 --> 00:42:19,680
거기에서 동적 프로그래밍을 할 수 있고

1033
00:42:19,680 --> 00:42:23,040
, 아마도 두 단계로 할 수 있습니다.

1034
00:42:23,040 --> 00:42:25,380
대기열 기반 탐색인 경우

1035
00:42:25,380 --> 00:42:28,980
대기열에 도달하는 것이

1036
00:42:28,980 --> 00:42:32,220
하나의 작업이고 대기열에서 보상으로 가는 것이

1037
00:42:32,220 --> 00:42:34,619
다른 작업이므로 이

1038
00:42:34,619 --> 00:42:37,460
둘을 분리하고 동적 프로그래밍을 사용할 수 있습니다.

1039
00:42:37,460 --> 00:42:40,440


1040
00:42:40,440 --> 00:42:43,079


1041
00:42:43,079 --> 00:42:45,480
음 해봐야겠네요 네, 하지만 이것들은

1042
00:42:45,480 --> 00:42:48,119
모두 제가 생각하고 있는 미래의 일입니다.

1043
00:42:48,119 --> 00:42:50,700
또는 Alex가 쓴 채팅에서 다른 질문을 해보세요.

1044
00:42:50,700 --> 00:42:54,359


1045
00:42:54,359 --> 00:42:57,599


1046
00:42:57,599 --> 00:43:00,180
서로 다른 스케일이 다를 수 있는 중첩 모델에 대한 아이디어나 개발이 있습니까?

1047
00:43:00,180 --> 00:43:02,330


1048
00:43:02,330 --> 00:43:02,640
[음악]

1049
00:43:02,640 --> 00:43:03,780
음

1050
00:43:03,780 --> 00:43:06,540
한 단계 앞서서  실행 속도

1051
00:43:06,540 --> 00:43:07,800


1052
00:43:07,800 --> 00:43:09,960
그래서 이 모델이 중첩된 모델에서 어떻게 작동하는지

1053
00:43:09,960 --> 00:43:11,579


1054
00:43:11,579 --> 00:43:13,859
그리고

1055
00:43:13,859 --> 00:43:16,380


1056
00:43:16,380 --> 00:43:19,500
실행 속도와 중첩된 모델의 시간에 대해 어떻게 앞뒤로 생각하는지 어떻게 생각합니까

1057
00:43:19,500 --> 00:43:21,780
그래서 중첩이라고 말할 때 음과 같이 여기에서 좀 더 많은 컨텍스트가 필요할 수 있습니다.

1058
00:43:21,780 --> 00:43:23,760


1059
00:43:23,760 --> 00:43:26,220
모델 음

1060
00:43:26,220 --> 00:43:28,440
계층적 모델을 의미하는 건가요 예 예

1061
00:43:28,440 --> 00:43:30,780
그래서 아마도 음 제가

1062
00:43:30,780 --> 00:43:34,619


1063
00:43:34,619 --> 00:43:38,760
빠른 속도로 얻는 관찰이 있고

1064
00:43:38,760 --> 00:43:41,160
그것에 대해 약간의 추론을 하지만 그런 다음 이

1065
00:43:41,160 --> 00:43:45,180
추론을 사용하여 어 일종의 수행

1066
00:43:45,180 --> 00:43:48,000
또는 아마도 어 그리고 기본적으로 이

1067
00:43:48,000 --> 00:43:49,500
추론  다음 상태에 대한 관찰이 되고 그것이

1068
00:43:49,500 --> 00:43:52,800
중첩

1069
00:43:52,800 --> 00:43:55,980
모델이 의미하는 바입니다. 예 그래서

1070
00:43:55,980 --> 00:43:58,140
실제로 작업의 관점에서 그것에 대해

1071
00:43:58,140 --> 00:44:00,300
생각한 다음 그것에 대해 생각해야 할 수도 있지만

1072
00:44:00,300 --> 00:44:02,339
솔직히 저는

1073
00:44:02,339 --> 00:44:04,800
이것이 그 맥락에서 어떻게 작동할지 생각하지 못했습니다.

1074
00:44:04,800 --> 00:44:08,760
작업에 대해

1075
00:44:08,760 --> 00:44:10,319
음

1076
00:44:10,319 --> 00:44:13,140
음과 같이 탐색 측면에서

1077
00:44:13,140 --> 00:44:15,119
생각해 보면

1078
00:44:15,119 --> 00:44:15,900


1079
00:44:15,900 --> 00:44:19,800
음 방 환경에 대해 생각할 수 있습니다 그래서

1080
00:44:19,800 --> 00:44:21,480
그것이 어디에 적용할 수 있는지 생각할 수 있는 예 중 하나이므로

1081
00:44:21,480 --> 00:44:24,000


1082
00:44:24,000 --> 00:44:27,720
컬렉션이 있다고 상상해보십시오.

1083
00:44:27,720 --> 00:44:30,300
에이전트로서 먼저

1084
00:44:30,300 --> 00:44:32,460
어느 방으로 가야 하는지 파악한 다음

1085
00:44:32,460 --> 00:44:35,760
그 집 내부를 탐색해야 합니다. 기본적으로

1086
00:44:35,760 --> 00:44:39,060
두 단계로 추론하거나

1087
00:44:39,060 --> 00:44:41,940
두 단계로 의사 결정을 할 수 있으며

1088
00:44:41,940 --> 00:44:43,140
분리해야 합니다.  방 안의

1089
00:44:43,140 --> 00:44:45,240
그 단계에서 당신의 결정은

1090
00:44:45,240 --> 00:44:47,460


1091
00:44:47,460 --> 00:44:49,740
최적의 어 경로를 탐색하기 위해 동적 프로그래밍을 할 수

1092
00:44:49,740 --> 00:44:52,980
있지만 항상 일종의

1093
00:44:52,980 --> 00:44:54,960
두 단계의

1094
00:44:54,960 --> 00:44:57,300
음 의사 결정이 있어야 하고 음

1095
00:44:57,300 --> 00:45:00,420
아마도 다른 방법이 다른 단계에서 더 잘 작동할 수

1096
00:45:00,420 --> 00:45:04,260
있지만 이것은  어,

1097
00:45:04,260 --> 00:45:06,180
당신이 알다시피 이

1098
00:45:06,180 --> 00:45:08,460
토론은 잘 생각한 작업에서 더 나을 것입니다.

1099
00:45:08,460 --> 00:45:09,420


1100
00:45:09,420 --> 00:45:12,060


1101
00:45:12,060 --> 00:45:14,400
나는 모든 것에

1102
00:45:14,400 --> 00:45:18,240
적합할 수 있는 대답이 없다고 말하고 싶지만

1103
00:45:18,240 --> 00:45:19,740


1104
00:45:19,740 --> 00:45:21,119
예

1105
00:45:21,119 --> 00:45:24,359
예 우리는 거의 정확히 그런 종류

1106
00:45:24,359 --> 00:45:27,300
의 것을 보았습니다.  계층적 동시

1107
00:45:27,300 --> 00:45:30,180
현지화 및 매핑

1108
00:45:30,180 --> 00:45:32,040
로봇 사례에서 Slam에는 활성

1109
00:45:32,040 --> 00:45:33,900
추론 모델이 있습니다

1110
00:45:33,900 --> 00:45:37,140
음 예

1111
00:45:37,140 --> 00:45:39,500


1112
00:45:40,079 --> 00:45:42,660


1113
00:45:42,660 --> 00:45:45,420
중첩 모델의 한 수준에서 이러한 방법 중 하나를 정렬한

1114
00:45:45,420 --> 00:45:48,359
다음 다른 계산 방법을

1115
00:45:48,359 --> 00:45:50,280
다른 계산 방법에 적용하는 것이 가능할까요?

1116
00:45:50,280 --> 00:45:51,960
또는

1117
00:45:51,960 --> 00:45:54,480
한 곳에서 하나의 장점을 원한다면 하나의 시뮬레이션 내에서도

1118
00:45:54,480 --> 00:45:56,579
이러한 다양한 방법을 혼합하고 일치시킬 수 있습니까?

1119
00:45:56,579 --> 00:46:00,180


1120
00:46:00,180 --> 00:46:03,540
예 나는 확실히 가능하다고 생각합니다

1121
00:46:03,540 --> 00:46:04,859


1122
00:46:04,859 --> 00:46:09,140
음 하지만 그래 우리는 시도해야 할 것이므로

1123
00:46:09,180 --> 00:46:12,119
내 모든 방법은 음 하나입니다.  단계이므로

1124
00:46:12,119 --> 00:46:14,819
계층적 모델은 아니지만

1125
00:46:14,819 --> 00:46:17,220


1126
00:46:17,220 --> 00:46:19,260


1127
00:46:19,260 --> 00:46:20,520


1128
00:46:20,520 --> 00:46:22,200


1129
00:46:22,200 --> 00:46:24,660


1130
00:46:24,660 --> 00:46:26,940
방금 언급한 방의 예에서 두 가지 의사 결정 방법이 함께 작동할 수 있는 부동산 모델에서도 작동할 것이라고 강력하게 믿습니다.

1131
00:46:26,940 --> 00:46:29,280
Z

1132
00:46:29,280 --> 00:46:31,819
학습

1133
00:46:35,640 --> 00:46:38,760
멋진 예 그래서 저는 여기와

1134
00:46:38,760 --> 00:46:41,220
훌륭한 논문에서 총 인용이 여러 개 있다는 것을 알았습니다.

1135
00:46:41,220 --> 00:46:45,240
예,

1136
00:46:45,240 --> 00:46:48,060
Z 학습의 도입은

1137
00:46:48,060 --> 00:46:49,859
활성 추론 필드와 관련하여 참신한 것이므로

1138
00:46:49,859 --> 00:46:52,260


1139
00:46:52,260 --> 00:46:53,760


1140
00:46:53,760 --> 00:46:55,920
무엇을 조금 더 설명해 주시겠습니까?  Z는

1141
00:46:55,920 --> 00:47:00,660
무엇이며 Q와

1142
00:47:00,660 --> 00:47:02,280


1143
00:47:02,280 --> 00:47:03,240


1144
00:47:03,240 --> 00:47:06,119
관련하여 Z에서 이렇게 빠른 음 개선을 가능하게 하는 것은 무엇입니까? 예

1145
00:47:06,119 --> 00:47:06,900


1146
00:47:06,900 --> 00:47:10,619
좋습니다 그래서 음 이 문서에 대한 컨텍스트를 제공하기 위해

1147
00:47:10,619 --> 00:47:13,079


1148
00:47:13,079 --> 00:47:13,920


1149
00:47:13,920 --> 00:47:16,260


1150
00:47:16,260 --> 00:47:19,800
음 그것은 선형 의사 결정 방법에 대해 이야기합니다.

1151
00:47:19,800 --> 00:47:21,720
mdp의 클래스는

1152
00:47:21,720 --> 00:47:23,940


1153
00:47:23,940 --> 00:47:27,240
여러분의 행동이

1154
00:47:27,240 --> 00:47:29,220
악센트가 아닌 상태를 기반으로 할 수 있는 Markov 결정 프로세스를 가지고 있기 때문에

1155
00:47:29,220 --> 00:47:31,560
예를 들어

1156
00:47:31,560 --> 00:47:32,760


1157
00:47:32,760 --> 00:47:35,160
왼쪽 오른쪽과

1158
00:47:35,160 --> 00:47:37,200
음 북쪽 남쪽 오른쪽에 대해 생각하는 그리드 작업과 같은 말에서 행동에 대해 생각할 때 그래서  북쪽을 취하면

1159
00:47:37,200 --> 00:47:40,200


1160
00:47:40,200 --> 00:47:42,720
상태 공간에 대한 결과가 있지만 이 문서에서는

1161
00:47:42,720 --> 00:47:43,680


1162
00:47:43,680 --> 00:47:46,380


1163
00:47:46,380 --> 00:47:48,839
결정 자체가

1164
00:47:48,839 --> 00:47:49,920
상태인 mdp 클래스를 도입하고 있으므로

1165
00:47:49,920 --> 00:47:54,180
상태 S1이라고 말하면 내 결정은

1166
00:47:54,180 --> 00:47:56,280
어 의존할 것입니다.

1167
00:47:56,280 --> 00:47:58,740
다른 상태에 따라서 내

1168
00:47:58,740 --> 00:48:00,000
결정은

1169
00:48:00,000 --> 00:48:02,160
내가 다음에 있고 싶은 다른 상태를 기반으로 할 것입니다. 그래서

1170
00:48:02,160 --> 00:48:04,020
어

1171
00:48:04,020 --> 00:48:05,880
그것은 의사 결정의 진정한 정의입니다. 의사

1172
00:48:05,880 --> 00:48:08,640


1173
00:48:08,640 --> 00:48:10,800
결정이

1174
00:48:10,800 --> 00:48:13,619
왼쪽 오른쪽 및 아래 위로와 같은 다른 것이 아니라 상태 공간 측면에서 어.

1175
00:48:13,619 --> 00:48:15,300
그래서

1176
00:48:15,300 --> 00:48:17,819
그러한 mdp가 존재한다는 점을 감안할 때 내가 상태 측면에서 결정을 내릴 수 있는 곳에

1177
00:48:17,819 --> 00:48:21,319


1178
00:48:21,319 --> 00:48:23,520
그들은 계산적으로

1179
00:48:23,520 --> 00:48:27,000
당신이 선형 복잡성에서 어 결정을 내릴 수 있다는 것을 보여주었지만

1180
00:48:27,000 --> 00:48:30,900
문제가

1181
00:48:30,900 --> 00:48:33,480
크더라도 상태

1182
00:48:33,480 --> 00:48:35,339
측면에서 의사 결정을 가능하게 하려면

1183
00:48:35,339 --> 00:48:38,579


1184
00:48:38,579 --> 00:48:39,540
상태에 대한 좋고 나쁨에 대한 감각

1185
00:48:39,540 --> 00:48:43,619
그래서 이 격자형 예에서 어 당신은

1186
00:48:43,619 --> 00:48:46,440
C인 바람직함 함수를 가지고 있으므로 C

1187
00:48:46,440 --> 00:48:48,240
는 상태가

1188
00:48:48,240 --> 00:48:50,700
얼마나 바람직한지에 대해 말하는 바람직함 함수이고

1189
00:48:50,700 --> 00:48:54,180
내가 c 함수를 가지고 있다면

1190
00:48:54,180 --> 00:48:56,579
그들이 보여준 것은 무엇입니까?

1191
00:48:56,579 --> 00:48:57,359
음,

1192
00:48:57,359 --> 00:48:59,280


1193
00:48:59,280 --> 00:49:01,079


1194
00:49:01,079 --> 00:49:03,540
mdp의 이 특정 클래스에 대해 선형 계산 복잡성으로 결정을 내릴 수 있다는 것입니다. 따라서 내 mdp가

1195
00:49:03,540 --> 00:49:05,640


1196
00:49:05,640 --> 00:49:08,940
상태 측면에서 결정을 내릴 수 있도록 허용한다면 그것은 선형적입니다. 어 그것은 단지

1197
00:49:08,940 --> 00:49:11,700
선형 복잡성이므로

1198
00:49:11,700 --> 00:49:15,240
이 그래프는 기본적으로

1199
00:49:15,240 --> 00:49:19,260
당신이 할 수 있는 방법을 비교하고 있습니다.  바람직함을 배우십시오.

1200
00:49:19,260 --> 00:49:22,200
Q 학습에 익숙하다면 Q

1201
00:49:22,200 --> 00:49:23,880
학습은 기본적으로

1202
00:49:23,880 --> 00:49:28,319
테이블 기반 방법입니다. 어 주어진

1203
00:49:28,319 --> 00:49:30,780
상태에서 행동이 바람직하므로

1204
00:49:30,780 --> 00:49:33,000
상태가 주어지면 무엇을 해야할지 알 수 있습니다. 그것은

1205
00:49:33,000 --> 00:49:35,760
기본적으로 대기열 매트릭스이지만

1206
00:49:35,760 --> 00:49:37,020
C의 용어

1207
00:49:37,020 --> 00:49:40,380
또는 C 학습 방법 그것은

1208
00:49:40,380 --> 00:49:43,020
상태에 관한 것입니다 어 당신은

1209
00:49:43,020 --> 00:49:44,819
상태가 얼마나 바람직한지 배우는 것입니다 행동의 개념이 없으며

1210
00:49:44,819 --> 00:49:46,980


1211
00:49:46,980 --> 00:49:49,560
이것은 정확히 우리의 사전

1212
00:49:49,560 --> 00:49:51,839
선호도입니다 어 능동적 추론에서

1213
00:49:51,839 --> 00:49:54,000


1214
00:49:54,000 --> 00:49:55,560
정량화하는 분포입니다  얼마나 바람직하거나

1215
00:49:55,560 --> 00:49:57,960
바람직하지 않은 상태가

1216
00:49:57,960 --> 00:50:00,119
옳은지

1217
00:50:00,119 --> 00:50:02,579
그들이

1218
00:50:02,579 --> 00:50:05,099
당신이 C 매트릭스를 더 빨리 배울 수 있고

1219
00:50:05,099 --> 00:50:07,980
그것이 최적이며

1220
00:50:07,980 --> 00:50:10,079
Q 학습보다 훨씬 빠르다는 것을 보여 주었다면 나는 괜찮다고 생각했습니다.

1221
00:50:10,079 --> 00:50:13,319
C는

1222
00:50:13,319 --> 00:50:16,400
이 백서에서 배웠고

1223
00:50:16,400 --> 00:50:19,319
이 말을 사용하여

1224
00:50:19,319 --> 00:50:21,839
C를 학습하기 위한 유사한 학습 규칙이 있습니다.

1225
00:50:21,839 --> 00:50:24,119
해당 백서에서 집합 학습이라고 합니다.

1226
00:50:24,119 --> 00:50:25,800
내가 본 것을 배우려고 시도했을 때

1227
00:50:25,800 --> 00:50:28,200


1228
00:50:28,200 --> 00:50:30,540
유용한 Pride 기본 설정을 정말 빠르게 학습한다는 것입니다.  내가

1229
00:50:30,540 --> 00:50:32,520
결정을 내리거나 능동적

1230
00:50:32,520 --> 00:50:34,619
영향력 행사자가 결정을 내리게 하는 것은

1231
00:50:34,619 --> 00:50:38,460
음 계획의 한 단계에 의해서만

1232
00:50:38,460 --> 00:50:40,859


1233
00:50:40,859 --> 00:50:42,240
결정을 내리게 하고 네 그래서 기본적으로 이야기를 가져왔기 때문에 음

1234
00:50:42,240 --> 00:50:43,440


1235
00:50:43,440 --> 00:50:47,460
C가 쉽게 배울 수 있다는 아이디어가

1236
00:50:47,460 --> 00:50:50,240
그 논문에 있습니다

1237
00:50:52,020 --> 00:50:54,780
좋습니다 음 다시 말하겠습니다

1238
00:50:54,780 --> 00:50:56,420


1239
00:50:56,420 --> 00:50:59,099
능동적 추론의 매우 흥미로운 증가라고 생각하기 때문에

1240
00:50:59,099 --> 00:51:02,280


1241
00:51:02,280 --> 00:51:04,200


1242
00:51:04,200 --> 00:51:06,480
앞에서 논의한 모든 이유로 C를 배울 것입니다. 우리는

1243
00:51:06,480 --> 00:51:09,619


1244
00:51:09,619 --> 00:51:13,740
todorov가 Z 학습을 제시한 방법과 유사하게 C를 배우고 학습 대신

1245
00:51:13,740 --> 00:51:18,540
Z 학습에서 할 것입니다.

1246
00:51:18,540 --> 00:51:21,059


1247
00:51:21,059 --> 00:51:23,460
음, 예를 들어 액션에 대한 사후 확률을 업데이트한

1248
00:51:23,460 --> 00:51:26,160


1249
00:51:26,160 --> 00:51:28,380
다음 액션을 사용하여

1250
00:51:28,380 --> 00:51:31,339
관찰을 방출하는 상태 사이를 탐색합니다.

1251
00:51:31,339 --> 00:51:35,760
예 우리는

1252
00:51:35,760 --> 00:51:37,319
액션을

1253
00:51:37,319 --> 00:51:39,300
상태로 베이킹하여

1254
00:51:39,300 --> 00:51:41,420
실제로

1255
00:51:41,420 --> 00:51:44,280
상태 간 전환을

1256
00:51:44,280 --> 00:51:48,200
직접 배우고

1257
00:51:51,540 --> 00:51:53,880
이를 연결합니다.  자유

1258
00:51:53,880 --> 00:51:56,040
에너지 원리와 그것이

1259
00:51:56,040 --> 00:51:57,660
능동적 추론과 어떻게 작용하는지

1260
00:51:57,660 --> 00:51:59,220


1261
00:51:59,220 --> 00:52:00,559
음

1262
00:52:00,559 --> 00:52:03,780
C는 그것에 대해 생각하는 한 가지 방법인 우리의 바람직함 함수일

1263
00:52:03,780 --> 00:52:05,280


1264
00:52:05,280 --> 00:52:07,559
뿐만 아니라 우리가 그것을 선호라고 부르는 이유이기도 하지만

1265
00:52:07,559 --> 00:52:11,640
C는 우리의 기대이고 그래서 그것이

1266
00:52:11,640 --> 00:52:14,400
허용하는 것입니다.  우리는 한편으로

1267
00:52:14,400 --> 00:52:16,800


1268
00:52:16,800 --> 00:52:18,960
에이전트가

1269
00:52:18,960 --> 00:52:21,900
좋아하는 곳에서 끝나는 것처럼 보상 및 선호도 학습에 익숙한 언어를 사용하지만

1270
00:52:21,900 --> 00:52:25,500


1271
00:52:25,500 --> 00:52:27,780
c에 대한 기대 기반 음 정의는 동일한

1272
00:52:27,780 --> 00:52:30,180
것으로 우리가

1273
00:52:30,180 --> 00:52:32,760
최소한의 경로로 이야기할 수 있게 합니다.  행동 또는 가장

1274
00:52:32,760 --> 00:52:36,660
가능성이 높은 결과 또는 가장 덜 놀라운

1275
00:52:36,660 --> 00:52:39,900
결과로 우리가

1276
00:52:39,900 --> 00:52:42,960
원하는 것을 가장 덜 놀라운

1277
00:52:42,960 --> 00:52:47,040
결과로 정의했기 때문에 변형 자유

1278
00:52:47,040 --> 00:52:50,640
에너지를 사용하여 놀라움을 튀길 수 있지만

1279
00:52:50,640 --> 00:52:54,000
단순히 변형 방법을 사용할 수는 없습니다.

1280
00:52:54,000 --> 00:52:56,579
대략적인 보상 자체도 필요

1281
00:52:56,579 --> 00:52:58,859


1282
00:52:58,859 --> 00:53:01,079
하지만

1283
00:53:01,079 --> 00:53:04,980
내가 기대하는 것을 선호

1284
00:53:04,980 --> 00:53:07,559
하고 내가 기대하는 것이 내 놀라움을 줄이고

1285
00:53:07,559 --> 00:53:09,859
놀라움의 균형을 잡을 것이라고 말하면

1286
00:53:09,859 --> 00:53:13,520


1287
00:53:13,520 --> 00:53:17,240


1288
00:53:17,240 --> 00:53:21,420


1289
00:53:21,420 --> 00:53:25,579
물리적 프레임 워크를 최소화하는 놀라운 경계 놀라움에 포함된 일종의 행동 보상 추구

1290
00:53:27,059 --> 00:53:28,740
예 예  아름다운

1291
00:53:28,740 --> 00:53:31,619
말이네요 네 감사합니다

1292
00:53:31,619 --> 00:53:35,160
음 다음 단계는 어

1293
00:53:35,160 --> 00:53:36,720
흥미진진한

1294
00:53:36,720 --> 00:53:39,420
단계나 방향이 무엇인지 또는

1295
00:53:39,420 --> 00:53:41,640
이 작업을 어떤 방법으로 수행하고 싶은지 예 좋습니다 그래 그래서 음

1296
00:53:41,640 --> 00:53:43,140


1297
00:53:43,140 --> 00:53:44,940
이 작업에 대해서만 이야기하는 경우

1298
00:53:44,940 --> 00:53:46,140


1299
00:53:46,140 --> 00:53:50,640
음 내가 원하는 것  다음으로 할 일은

1300
00:53:50,640 --> 00:53:53,099
큐 기반 탐색 작업에 대해 생각하는 것입니다.

1301
00:53:53,099 --> 00:53:55,200
먼저

1302
00:53:55,200 --> 00:53:58,980
동적 프로그래밍의 한계를 해결하므로

1303
00:53:58,980 --> 00:54:01,020
이 그리드에서 먼저 탐색할 대기열을 말하고

1304
00:54:01,020 --> 00:54:03,660
그것이 더 최적입니다.

1305
00:54:03,660 --> 00:54:06,780
어 예상되는 모호성 용어가

1306
00:54:06,780 --> 00:54:10,319
예상되는 자유 에너지는 유용하며

1307
00:54:10,319 --> 00:54:12,240
동적 프로그래밍에서

1308
00:54:12,240 --> 00:54:13,260


1309
00:54:13,260 --> 00:54:15,540
엄격하게 그런 의미에서 사용되어야 합니다

1310
00:54:15,540 --> 00:54:18,000
음 그러나 더 일반적으로 나는 또한 CBS 교수의 작업이 있는 것처럼 적극적인 영향에서

1311
00:54:18,000 --> 00:54:20,339
결정을 내리는 다른 방법을 찾고 있습니다.

1312
00:54:20,339 --> 00:54:23,040


1313
00:54:23,040 --> 00:54:24,900


1314
00:54:24,900 --> 00:54:26,099


1315
00:54:26,099 --> 00:54:30,180


1316
00:54:30,180 --> 00:54:33,059
신경망이 능동적

1317
00:54:33,059 --> 00:54:35,099
추론을 수행하고 기본적으로 의사 결정을 내리는 방법에 대해

1318
00:54:35,099 --> 00:54:36,359


1319
00:54:36,359 --> 00:54:39,540


1320
00:54:39,540 --> 00:54:42,359
대기열 학습과 같은 의미에서 음 정말 더 효율적입니다. 그래서

1321
00:54:42,359 --> 00:54:44,940
거기에서 그는

1322
00:54:44,940 --> 00:54:47,520
변형이 없는 에너지를 영리하게 사용하여 좋은

1323
00:54:47,520 --> 00:54:50,760
상태 동작 매핑을 학습하고 있습니다.

1324
00:54:50,760 --> 00:54:52,200


1325
00:54:52,200 --> 00:54:55,079


1326
00:54:55,079 --> 00:54:56,520
예상되는 자유 에너지 측면에서 우리가 익숙한 것에 대한 매우 과감한 변화이므로

1327
00:54:56,520 --> 00:54:59,220
예상되는 자유 에너지에 대한 개념이 없습니다. 어

1328
00:54:59,220 --> 00:55:01,740
그 작업에서 그것은 에너지의 변화에서

1329
00:55:01,740 --> 00:55:03,599
직접 좋고 나쁨을 배우는 것에 관한 것입니다.

1330
00:55:03,599 --> 00:55:05,700


1331
00:55:05,700 --> 00:55:08,099
매혹적인 나는 좀

1332
00:55:08,099 --> 00:55:11,160
더 탐구하고 싶고

1333
00:55:11,160 --> 00:55:15,300
이런 식으로 의사 결정이 어떻게 더 좋거나 나쁜지 확인하고 싶거나

1334
00:55:15,300 --> 00:55:18,000


1335
00:55:18,000 --> 00:55:20,220


1336
00:55:20,220 --> 00:55:22,200
능동적 추론은

1337
00:55:22,200 --> 00:55:23,700
변형 자유 에너지에 대해서만 이야기하기 때문에 의사 결정 방법을 재고해야 하는지 생각해야 합니다.

1338
00:55:23,700 --> 00:55:25,520
다른 것은

1339
00:55:25,520 --> 00:55:28,440
그 권리에 대한 당신의 해석입니다.

1340
00:55:28,440 --> 00:55:31,319
그래서

1341
00:55:31,319 --> 00:55:35,180
그것은 또 다른 방향입니다. 제가

1342
00:55:35,640 --> 00:55:38,359
말하고 싶은 흥미로운 방법은 음 확실히

1343
00:55:38,359 --> 00:55:42,480


1344
00:55:42,480 --> 00:55:45,540
우리의 변동

1345
00:55:45,540 --> 00:55:48,660
음량 분포 q와 데이터 y의 기능인

1346
00:55:48,660 --> 00:55:51,119
변동 자유 에너지입니다. 변동 자유 에너지는 다음과

1347
00:55:51,119 --> 00:55:53,839
같습니다.  예를 들어 실시간

1348
00:55:53,839 --> 00:55:57,359
항상성은

1349
00:55:57,359 --> 00:55:59,760
내가 믿는 것과 들어오는 데이터를 감안할 때 상황이 어떻게 이해가 가는지

1350
00:55:59,760 --> 00:56:01,619


1351
00:56:01,619 --> 00:56:04,740
그리고 그런 종류의

1352
00:56:04,740 --> 00:56:07,020
이해 프레임워크를 의사 결정으로 확장하기 위해

1353
00:56:07,020 --> 00:56:10,020
우리는 많은 다른

1354
00:56:10,020 --> 00:56:13,740
방법을 보았고 예상되는 자유 에너지는

1355
00:56:13,740 --> 00:56:16,260
음 일반적인 것입니다.  그러나 예를 들어

1356
00:56:16,260 --> 00:56:19,400


1357
00:56:19,400 --> 00:56:25,200
eef로 예상되는 미래의 자유 에너지가 있고 다른 방법을 가진 다른 구성이 있습니다

1358
00:56:25,200 --> 00:56:29,760


1359
00:56:29,760 --> 00:56:31,380
음 그리고 당신은 또한

1360
00:56:31,380 --> 00:56:33,599


1361
00:56:33,599 --> 00:56:37,020


1362
00:56:37,020 --> 00:56:39,059


1363
00:56:39,059 --> 00:56:41,339
기본 그래프의 변동 자유 에너지와

1364
00:56:41,339 --> 00:56:43,680
신경망의 손실 함수와

1365
00:56:43,680 --> 00:56:45,300
매우 흥미로운 작업인 모든 관계도

1366
00:56:45,300 --> 00:56:48,380


1367
00:56:49,079 --> 00:56:51,660
음 제 생각에는

1368
00:56:51,660 --> 00:56:53,460
마지막 질문으로 마치는 것 같거나 박사 과정이 거의 끝나가고 있다고 생각했기

1369
00:56:53,460 --> 00:56:55,559


1370
00:56:55,559 --> 00:56:56,880


1371
00:56:56,880 --> 00:57:00,540
때문에 지금까지

1372
00:57:00,540 --> 00:57:02,579
박사 과정 학생이

1373
00:57:02,579 --> 00:57:06,300
능동적 추론이 발전하는 것을 어떻게 보셨는지

1374
00:57:06,300 --> 00:57:10,700
또는

1375
00:57:11,339 --> 00:57:14,280


1376
00:57:14,280 --> 00:57:17,400


1377
00:57:17,400 --> 00:57:19,980
몇 년 전에 신선하고 흥분했을 때와 끝 무렵에 오늘 여러분에게 어떤 느낌이 다른지

1378
00:57:19,980 --> 00:57:21,119


1379
00:57:21,119 --> 00:57:23,339
예 그것은 정말 좋은

1380
00:57:23,339 --> 00:57:25,920
질문입니다. 어 저도

1381
00:57:25,920 --> 00:57:29,400
어떻게  이 분야는 발전했고 솔직히

1382
00:57:29,400 --> 00:57:30,900
나는 이 강화

1383
00:57:30,900 --> 00:57:32,400
학습 배경과 물리학

1384
00:57:32,400 --> 00:57:34,680
배경에서 시작했고 읽기 시작했을 때 그것은

1385
00:57:34,680 --> 00:57:37,680
단지 한두 개의 논문이라고 말했고 나는

1386
00:57:37,680 --> 00:57:40,440
그것의 많은 부분을 잘 이해하지 못했습니다.

1387
00:57:40,440 --> 00:57:42,540


1388
00:57:42,540 --> 00:57:44,700


1389
00:57:44,700 --> 00:57:46,980
음 Matlab 스크립트를 호출합니다. 저는

1390
00:57:46,980 --> 00:57:49,559
이 말이 맞고 마음에 들지만 어,

1391
00:57:49,559 --> 00:57:52,020
1~2년 안에 다른 방향에서

1392
00:57:52,020 --> 00:57:54,780
많은 논문이 들어오는 것을 보았고

1393
00:57:54,780 --> 00:57:56,280
사람들도

1394
00:57:56,280 --> 00:57:58,740
신경망을 사용하기 시작했고

1395
00:57:58,740 --> 00:58:02,460
이 모든 확장을 확장했습니다.  왔고 저는 어느 시점에서

1396
00:58:02,460 --> 00:58:04,319


1397
00:58:04,319 --> 00:58:07,260
능동적 추론의 필요성에 의문을 제기했습니다. 어 왜냐하면

1398
00:58:07,260 --> 00:58:09,119


1399
00:58:09,119 --> 00:58:10,980
많은 일을 할 수 있는 심층 강화 학습이 있다면 왜 깊은 능동적

1400
00:58:10,980 --> 00:58:14,040
추론이 필요한지 그리고 그것이 내가

1401
00:58:14,040 --> 00:58:16,319
그것에 들어가지 않은 이유이지만 여전히 매력적이라고 ​​생각합니다.

1402
00:58:16,319 --> 00:58:18,359
나는 지금 내가 아는 것보다

1403
00:58:18,359 --> 00:58:20,280
심층 능동적 추론을 좀 더 이해하고 싶지만

1404
00:58:20,280 --> 00:58:23,160


1405
00:58:23,160 --> 00:58:25,680
2~3년 만에 그 분야가 아무렇게나 성장하는 것을 보았고

1406
00:58:25,680 --> 00:58:28,619
많은 집단의 사람들이

1407
00:58:28,619 --> 00:58:31,859
일하기 시작했고 곧

1408
00:58:31,859 --> 00:58:36,359
진지하게 받아들여지는 분야가 되었습니다.

1409
00:58:36,359 --> 00:58:39,119
아무도 실제로

1410
00:58:39,119 --> 00:58:41,280
그것이 무엇인지 알지 못하는 두 개의 논문이 있는 분야보다 정말

1411
00:58:41,280 --> 00:58:43,440
흥미진진합니다. 그래서 저는 이

1412
00:58:43,440 --> 00:58:47,040
분야가 시간이 지남에 따라 어떻게 발전하고

1413
00:58:47,040 --> 00:58:52,140
박사 학위를 취득한 후 무엇을 할 수 있을지 정말 기대됩니다.

1414
00:58:52,140 --> 00:58:55,319


1415
00:58:55,319 --> 00:59:00,359
우리는 우리가 기대하는 것을 선호합니다 예

1416
00:59:02,339 --> 00:59:04,140
다른

1417
00:59:04,140 --> 00:59:05,819
의견이나 추가하고 싶은 다른 것

1418
00:59:05,819 --> 00:59:07,200


1419
00:59:07,200 --> 00:59:09,839
예 그래서

1420
00:59:09,839 --> 00:59:11,940
논문에 대한 당신의 생각과

1421
00:59:11,940 --> 00:59:14,400
이러한 아이디어에 대한 생각을 자유롭게 알려주세요

1422
00:59:14,400 --> 00:59:16,200
나는 피드백을 정말 기대

1423
00:59:16,200 --> 00:59:17,760
하고

1424
00:59:17,760 --> 00:59:20,160
예  이 기회를 주셔서 정말 감사합니다.

1425
00:59:20,160 --> 00:59:23,339
Daniel과 시간을 내주셔서 감사합니다.

1426
00:59:23,339 --> 00:59:26,160
놀랍습니다. 사람들이

1427
00:59:26,160 --> 00:59:28,260
음 종이를 확인하고 연락하여

1428
00:59:28,260 --> 00:59:30,540
코드를 복제하고

1429
00:59:30,540 --> 00:59:33,359
자신의 방향을 따르기를 바랍니다. 감사합니다.

1430
00:59:33,359 --> 00:59:34,680
다음에 뵙겠습니다.

1431
00:59:34,680 --> 00:59:36,839
다음에 뵙겠습니다.  정말 감사합니다 안녕히 계세요

1432
00:59:36,839 --> 00:59:40,040
좋은 하루 되세요 안녕

