SPEAKER_00:
Hello everyone and welcome back to the show.

Today I'm extremely pleased to be speaking with Chris DeLega.

Chris is a postdoctoral fellow working in the Centre for Research in Cognition and Neurosciences in Brussels.

He focuses on computational models of cognitive functions, mental representations and consciousness, as well as broader topics prominent in philosophy of computation, philosophy and ethics of AI, metacognition and philosophy of science.

Chris, thank you ever so much for joining me.


SPEAKER_02:
Thanks for the invitation.


SPEAKER_00:
Oh, it's an absolute pleasure.

People have been asking for a bit more of a, you know, critical voices on Active Inference, which, and you're the perfect person to go to.

But before we get there, we were talking a little bit off air about Dan Dennett.

Dan passed away unfortunately last week at the time of this recording, I believe it was.

And he was your PhD supervisor.

So clearly a great deal of your work has been influenced by Dan.

I wanted to talk about your 2015 paper discussing the Cartesian theatre and its sort of place or lack of, you know, it's sort of ought to lack of place in predictive processing or perhaps not.

But before we go there, I know you want to say a couple of things about Dan and it would be great just to discuss his sort of influence on you more broadly.


SPEAKER_02:
Sure, thank you.

So, yeah, so this is a really sad moment because Dan has...

I think it's easy to say defined in large, in many ways defined the shape of philosophy of mind in the 20th century up to today.

And it's a really great loss to...

to see him go.

And I guess I mentioned to you when we were setting up this meeting that I would like to spend a little bit of time discussing him because I think that Dan is in some ways a kind of a philosopher who should be

followed in the way that he approached philosophy of mind.

And I think that it's worth focusing on that.

That's one thing that I find really interesting and important about him.

And the other thing is that I had a personal relationship with him.

I did two extended research stays with him during my PhD, and we've met at many occasions at different conferences.

And over the past weekend, there were a lot of obituaries that showed up about Dan.

And he clearly was a lot of things to many people.

And it's actually astonishing to see how many people he has influenced across multiple disciplines.

But I think it's also worth remembering that he was just an extremely kind person.

uh nice guy he was just a he was just a joy to to be around um and so that's the second thing that i sometimes feel is missing from contemporary philosophy so so the way he did philosophy is that he tended to focus on science right and he thought that there's no philosophy free science

And similarly, he thought that philosophy of mind should be informed by our best state of scientific knowledge.

And sometimes I feel philosophers forget that it's very easy to stay within the boundaries of our discipline and not reach out and not try to have a peek what's going outside of the boundaries of the ivory tower of philosophy of mind.

And I think it's really important to remember that if there's a legacy to Dan's work,

it's that philosophy can be informed by science and it's actually very productive and important for philosophers to engage with scientists and it's a kind of a two-way exchange of ideas where both sides can benefit productively and then the second thing is that philosophers can be extremely serious about themselves and about their work and about really entrenched in their positions and very combative

And yeah, kind of hard headed.

And I think that Dan

Although we cannot say that he had a small personality, he was definitely a flamboyant personality as well.

But he was really a person who was very kind towards junior scholars.

He would always find time to engage with younger researchers and students.

He was very curious of what other people might say about his work, even if it was critical.

And he did not take himself entirely seriously.

And I think this is something that's also worth remembering, right?

So he was happy to sometimes concede that maybe he didn't think something through.

and he thought that first philosophy first and foremost should be a great intellectual adventure and not some kind of dogmatic

holy war.

And I think that's, that's something worth remembering.

I don't know if you would like to ask anything else about then or?


SPEAKER_00:
Well, I am.

Yeah, I mean, firstly, to echo everything you just said, I mean, I never met Dan, I guess I'm, I'm not currently at that place in my career where that would have been viable.

I mean, I only left school what, you know, in 2017.

But you know, even studying philosophy at school,

dan's name was pervasive right i mean interestingly pervasive across sure philosophy of mind which we studied but even quest you know broader questions of epistemology um and ontology dan's name would come up in a way that other philosophers wouldn't and so he always seemed like a kind of grandfather of modern philosophy

in, you know, and so he's one of, for me, one of these sort of icons who I've never met and I've never spoken with, but are incredibly influential, even if, as you say, not, I don't agree necessarily with everything I think Dan thinks or thought, but yeah, incredibly important.

And you're absolutely right.

I mean, just,

being on Twitter or X or whatever this weekend.

It was unbelievable.

I mean, maybe in some ways this is just because I follow so many academics, but just the timeline was absolutely replete with obituaries and condolences.

And it was quite remarkable.

So clearly he touched a lot of people both as a human being and also as an intellect.

Yeah, I'm curious, what was he?

What was he like, sort of during your PhD?

I mean, I guess this is a personal question, because that's what I want to be embarking on, you know, this year.

But what was he sort of like as a guide and a mentor?


SPEAKER_02:
So he was extremely kind, as I said before.

So very encouraging.

He was eager to learn.

So something that I've heard from other people who have done postdoc appointments with him or have been his PhD students in the past was that

When someone came to him with expertise in a field that he wasn't very familiar with, he was really eager to learn from them.

So when I was working on my dissertation, which was on predictive processing, and that was a new topic back then, he was very interested in learning about the models and discussing with me formal papers.


UNKNOWN:
Right.


SPEAKER_02:
about different modeling algorithms, for example, which was super nice.

Yeah.

And one thing that was really special about him as an academic mentor was that he was extremely well rounded.

So I feel that today

in academia, I mean, it's not a product of the last ten years, but we have very narrow focuses.

We value specialization and Dan explored everything.

So a lot of people don't remember this about

him, but he was able to code, for example.

He has done work with programming in the past.

He was very skilled in many domains, and that would often come back because his curiosity and his abilities in multiple areas

would allow him to draw connections between different fields of work.

So he was very quick in suggesting readings, for example, that you wouldn't get as standard recommendations from people working on a particular topic because they would often seem

Like they are very removed from what you're interested in.

But later on you would follow up and you would find out that there are actually connections between these ideas and that certain ideas surfaced in many different places in many different disciplines in academia over time in different guises.

So that was extremely valuable.

And yeah, he was just fun to be around.

So he was obviously very busy.

He was still quite generous with his time, despite how many appointments he had and how many people were always kind of fighting for his attention and trying to get a bit of his time.

But one of the best pieces of advice I ever got from him was when I was visiting him and I was writing a paper, I was working on a paper.

And as I was halfway through this paper, I don't know, three quarters in, someone else published a paper that was extremely similar to my paper to the point where I kind of thought, okay, I have to abandon this project because

There's no way to publish this right now because it's just similar.

And I was pissed.

I was irritated.

I was kind of angry.

I can imagine.

I sunk a lot of time into that project.

And I went to him and I said, yeah, I'm pissed.

This just happened.

What am I supposed to do?

And he said,

To me, something that I try to remember every time I feel scooped by someone with a paper or...

Someone is publishing like crazy on some topic that I'm interested in, and I don't feel like I can catch up sometimes with the literature, which has happened with predictive processing quite a bit.

Because that literature exploded at the time.

But he told me this.

He said, Philosopher is arguing about who came up with an idea first.

are like sailors squabbling over who was the first one to notice that the wind has changed.

And I thought that's very good advice because the reason we all got into philosophy

wasn't probably because we wanted to be a superstar of philosophy.

It isn't because we hopefully it isn't because we have humongous egos and we think that we are right and everyone else is wrong, but it's just because we appreciated thinking about certain problems.

And at the end of the day, it's a collaborative endeavor.

And science, philosophy,

building knowledge is a project in which we should engage collaboratively.

And despite being a giant that he was, he was also, Dan, I mean, he was always very

in his writings and talking to him, he was always very much against the idea of a singular genius.

So this idea, which philosophy often suffers from even today, this myth of a single author that can lift a whole field.

It's a bit ironic that Dan was the person who was against this idea, given how much influence he had over the field.

And this is visible in several of his books and writings.

He didn't like this idea of a singular genius.

He thought that really certain ideas

start to kind of brew in the right conditions.

And then there's just someone who makes the discovery or who catches wind of what's happening.

But he always thought of himself as standing on the shoulders of giants like Quine and other people.


SPEAKER_00:
Yeah, that's a beautiful quote.

It makes me think there's one by Carl Jung where he says, people don't have ideas.

Ideas have people.

Yeah.

Jung was thinking about in a slightly different way than Dan was, but it's in some psychoanalytic manner.

But the sort of sentiment is the same.


SPEAKER_02:
Yes.

And it's actually extremely close to some of the ideas that he presented from Bacteria to Bach and Bach.

So when he talks in the chapters where he talks about memes,

Yeah, it sometimes goes extremely close to that line of thinking that I was doing my first research stay when he was finishing that book.

And I had the privilege of going through the drafts and discussing the drafts with him and Martin Baudry, who was a postdoc at the time with him.

Also a visiting postdoc.

And I remember that we sat one evening and we had this conversation where we picked a passage from the book, from the chapter about memes.

And we said, Dan, are you sure this is what you want to say here?

Because it starts to sound like...

uh humans are just you know material vehicles for memes and is this it sounds very extreme and i remember he was sitting there quietly for a second thinking and he said you know what maybe you're right maybe my pros got the better of me so um yeah so so as you say right people always uh praised him for his pros i um famously a kind of


SPEAKER_00:
very well, prosaic is a derogatory word, but I mean it here in a sort of praiseworthy way that some philosophy is very snooze worthy, let's be honest.

But you know, the things I read of Dan are certainly not and that itself is quite remarkable.

You know, the ideas aside, of course, which are very potent and influential, to be able to write about something otherwise deeply complex and

Otherwise, for a certain audience, extremely boring.

And to make that come alive is an incredible skill in and of itself.

Yeah, go ahead.


SPEAKER_02:
I just wanted to say on that point that I completely agree with you.

And he definitely had his own voice as a writer, which was remarkably close to the way he would speak in conversations.

But what's really interesting is that that way of writing that he introduced into philosophy,

gained praise over time i think late in especially in his later years but initially it was a bit of a problem for him so when he wrote his first book content and consciousness which i believe came out in 1969 that book got some negative reviews because of the way in which it was written and it wasn't a fully

actualized the Netian narrative yet, but you could still get some of his kind of Massachusetts sensibilities in there.

And what was really interesting is that some people really recalled from that style of writing at the time.


SPEAKER_00:
Well, I think

Yes, I sense there's been a change in that, right?

I mean, the underlying sociological reasons for why that's the case, whether it is just people copying someone like Dan, is an open question.

But I do think that

Well, duty might be a strong word, but we do have an obligation in some sense to make our works legible.

Even if it's not for the lay audience, even if it's being published in philosophy journals, we can't be talking into the end of one chamber that is just our own minds.

And Dan, again, of the stuff that I read from him and also his contemporaries, people like

Ned Block and David Chalmers.

And then some of my favorites, you know, Evan Thompson, who I know was a postdoc with dad.

It's, it's fun to read.

And it makes people like me want to do philosophy.

And again, this is no shot at anyone who was working 120 years ago, whose pros might make you want to fall asleep.

But I yeah, I guess there's a broader, broader thing there that we do have a we do have a duty to transmit our ideas in a


SPEAKER_02:
legible intelligible manner and dan epitomized that definitely and he was also i mean he was also a he had a style of his own which was very entertaining which i think is another thing yeah yeah a lot of a lot of academics could learn from him uh he's not the only example of that um

But of being able to write in an entertaining way while also transmitting very complex ideas.


SPEAKER_00:
I love this idea of an author having their own style.

I think Carl is one of them.

I mean, it's fitting that we're on this podcast, right?

I've been accused at certain points in my writing of writing in Fristanese.

I love a reviewer's comments where they mention Fristanese, because I can't help, you know, having read so much of Fristan's work, of Carl's work, I can't help but use the word evince.


SPEAKER_02:
I feel like it's a bit of a dog whistle.

If someone uses the word Vince in their paper, especially when you're reviewing a paper, you can see who they've been reading a lot.

So I feel like Vince is this kind of mark of someone who has read a lot of Friston.

If Vince appears in your own writings, it might be because you've been reading a lot of Friston.

Moving away from Dan a little bit and towards what you wanted to talk about in terms of papers, I reread some of my older papers or this meeting because some of them are seven years old and I don't remember what I wrote there.

uh i was yeah definitely it's a journey for me as a non-native speaker to develop some kind of style and and i read some of the sentences i wrote in the past and i wouldn't put those ideas in that way today but you know


SPEAKER_00:
Well, I've got to say that I didn't have that impression.

The one I read, I think it was yesterday, was the curtain call for the Cartesian Theatre, which was 2015, which feels... I mean, yeah, I was...

doing my GCSEs for people in England, you know, I was doing my sort of, I was 16 or whatever.

But I didn't feel that way at all.

And clearly, there's a lot of Donetti and influence there in that paper.

But what I like about it, I was gonna say this in reference to Dan is, you know, you mentioned his kind of openness, his curiosity, his epistemic humility, fundamentally, you know, I mean,

We don't know.

With a lot of things in life, we really don't know.

And that's the beauty.

I mean, we would all be out of jobs if we knew.

And life itself, there would be no information transfer.

Arguably, there would be no life at least worth living.

And I felt that in that paper, you very much evinced, if you pardon me the word, a great deal of epistemic humility, which I really liked.

I mean, you're critiquing the Fristonian, in this case, the Fristonian-Hobbesian model of... Hobbesonian model of...

their sort of invocation of the Cartesian theatre and what Dan called Cartesian materialism when it comes to, I believe you call it action orientated predictive processing, but I guess we call it active inference now.

Yes.

But you know, you didn't say, but this is the fundamental way in which consciousness appears, or this is the way the representations work.

So I enjoyed that.

I mean, for people who haven't read that paper, what

again, it comes back to dad, what is Cartesian materialism?

What kind of role does it have to play in terms of predictive processing?

And then what's the what's the problem with it?


SPEAKER_02:
You know?

Okay.

Nice.

So we're really starting at the beginning.

So that's a paper, me and my good friend Joe, with whom I studied in Edinburgh before studying my PhD.

We studied in Edinburgh, where we read

a draft of Andy Clark's Surfing Uncertainty in one of our master seminars.


SPEAKER_00:
Wow.


SPEAKER_02:
And that's how we got into predictive processing.

So that's a paper we wrote early on, and it was a kind of a knee jerk reaction to a paper by Carl Friston and Hobson.

in which they invoke the notion of cartesian theater so cartesian materialism is this term that was coined by dan dennett to describe a certain view of consciousness which he thought was very a kind of a residue from the from the ideas of descartes and you know the idea that there is a certain point in the brain

where information needs to reach and then it somehow needs to be re-rendered in the medium of consciousness.

So for Descartes, that was, of course, the pineal gland, which was this point of interaction between mechanistic mind

uh and the soul and there was a there was a certain in his view of the mind and his of the brain also there were these humors right there were these uh different liquids in the brain that would create pressures on the on the pineal gland and depending on which part of the pineal gland they would put pressure on there would be a certain experience

that would appear in the soul and in consciousness.

uh so so what dennett criticized about this view of consciousness is that it requires a certain type of double trans transduction he called it so it's not only that there's sense that it's not only that there are forces impinging on our sensory periphery from the environment which are then transduced into the medium of neuronal spikes and you know um hormone secretions and so on all the things that are happening mechanistically in the brain

But then it seems to imply that there is a certain point in which in the processing of information where

the medium information needs to be transduced again from the medium of neuronal spikes and all the mechanistic happenings in the brain into the medium of consciousness.

So he sometimes referred the product or this substance of the second transduction, he called it figment, right?

By analogy with pigment.

So figment is this

thing that needs to be put onto your representations of the world in order to imbue them with qualitative properties.

Because presumably, as most dualists and non-reductive physicalists would tell us, there are phenomenal properties and there are dispositional or functional properties.

And these are two different types of properties, right?

All anti reductionists about consciousness will claim that phenomenal properties are not reducible to functional properties.

And then said, well, if that's the case, then it seems to be that we end up with this picture of the mind where information hits the retina.

Let's say in the case of vision, it's transduced into the medium of neuronal spikes.

that information is those neuronal spikes are propagated through the cortical hierarchies.

And then we have to ask, where is this point in the brain where we put on the figment onto the visual information, right?

So it seems like we need to apply the mental paint

as Block would put it again, even though I would like to say that here, as I'm talking about mental pain, that's a slight abuse of the term as Block uses it.

But the point is that you seem to require adding something into the workings of the brain in order to render information conscious.

And that's something that he really wanted to reject.

So his point

wasn't that there's a... His point wasn't that there cannot be some aspect of the brain which is privileged in terms of bringing about conscious experience.

It's rather that there's nothing extra, metaphysically extra or ontologically extra added into the information

when it becomes conscious, right?

It's just that you process information unconsciously and then it can become conscious at any particular time, given that it was processed enough through the cortical hierarchy and so on, right?

So there's no mysterious properties that need to be applied again or added back into the information that is being processed by the physical system.

So the name Cartesian materialism is supposed to suggest that there's a materialist picture of the brain, but there's this much like in the case of the pineal gland, in the case of Descartes dualism,

In Cartesian materialism, there's a particular location in the brain that information needs to reach in order to become conscious.

And this particular center in the brain is this one area that serves as the Cartesian theater, kind of as a place which serves as the screen of consciousness.

And that's something that he wanted to reject because he believed that there's no one particular place in the brain

where information needs to be processed in order to for it to be conscious it's rather that there's a collection of different functions that need to be in place simultaneously trading information in order for information to be conscious right and that's also why in many disorders of consciousness such as i don't know visual for magnesia

uh or blindside we see that conscious experience undergoes a kind of graceful degradation where people lose certain aspects of conscious experience but that doesn't mean that they are rendered somehow entirely unconscious or something like that right it's it's rather that you can knock out different modules if you want to talk about that and this in those ways are different systems out but as long as there's some kind of


SPEAKER_00:
wider commerce of information going on throughout the brain consciousness is still in place so i feel like the rebuttal to this would be the argument that okay but i guess the cartesian theater in some ways has multiple reference in the sense that one thinks of as you say the screen of consciousness i mean the word theater brings out to mind very vividly

And one thinks also of the homunculus who's watching the screen and this sort of little man who's watching.

And that's obviously got a number of problems, most strikingly the infinite regress of the homunculus.

But then there's also this separate, more mechanistic point about the locus of consciousness and this sort of singular physical point.

I guess the rebuttal to that would be, well, even if you adopt a more distributed idea of the brain as a network and you're talking more in terms of functional connections,

there still seems to be either, you know, either we're saying, well, there is no consciousness, right?

Well, let's disparage with that just for the meantime.

But let's say there is consciousness.

Well, we don't want to say that necessarily the sound waves or the visual information itself is conscious.

So there does seem to be a transduction at some point from matter into phenomenal space.

Now, that sounds like to me that there needs to be a moment at which, just by necessity, that information enters into, in a metaphorical use, that phenomenal space.

Now, it might not be the case that that's the same for every experience.

It might not be the case that it's the same in every place for every experience.

But it does seem to be this case that even in a diverse range of networks, there is a moment at which the lights come on, so to speak.

Would Dan or yourself have a problem with that weaker form of the Cartesian materialism or Cartesian theatre?


SPEAKER_02:
All right.

So that's a good question.

You're pinpointing exactly the main issue.

So Dan,

I think would have a problem with that because especially so he explicitly wanted to leave behind this metaphor of a screen or this metaphor of some kind of special properties in consciousness.

So a lot of people attack him these days for being an eliminativist about consciousness.

And he was very adamant that he's not in that camp.

precisely because he would always claim, you know, there is something it is like to be Dan Dennett and it's different from what it's like to be me and it's different from what it's like to be you.

So there is a subjective perspective on the world that you have that is different from mine and that was different from his.

uh and uh so he didn't want to deny that but he wanted to change the way we speak about these things so so this is why he together with keith frankish they coined the term illusionism because they wanted to to stop talking about phenomenal properties as things that we have to find a place for in our ontology

Now, yeah, so that's one thing.

And I think that he would also have a bit of a problem with that because

of his multiple drafts model.

So his idea was that he was very much informed by bars and the work on global workspace.

So this idea that there are these long range projections in the brain which connect different areas and there's a kind of exchange of information going on.

But on his view of consciousness,

there isn't one particular system that is the consciousness system, right?

So it's likely that I think he would agree with the claim that a weak claim that there is a number of cognitive functions that need to be in place in order for something to have consciousness like ours or sufficiently similar to ours.

But I think he would reject the claim that any one of these systems is somehow privileged over the others.

That's one thing.

And then the multiple drafts idea is that there are multiple competing streams of information in all of these systems that are necessary for consciousness.

And which stream you're

conscious of which stream of your experiencing is kind of up to one, how much cloud it has in the system.

So how strong, how much control it has over the rest of the cognitive economy, what he coined as fame in the brain.

And then the other thing is the kind of probes that you encounter.

So kind of either external

um external situations with which are stimuli that that that require solicits a certain response from you or internal probes like you know if you're if you're sitting there and you're really thinking about your

X, or if you're really thinking about focusing, trying to be mindful about the experience of eating an apple, that's also a way of privileging certain streams of sensory information or memory traces over other streams of information in the brain.

Okay, so that's, I think, what he would want to say probably about this.

Now, for me, I guess I'm less

I'm less convinced of, I like the multiple drafts model, but I'm not completely on board.

because a lot of the work in science of consciousness these days focuses on higher order systems, on this division between lower order systems and lower order processing and higher order processing, metacognition.

And I think that

I'm leaning more towards some kind of higher order theory of mind these days.

And I do think that there might be a certain privileged set of processes or systems that are necessary.

And in some sense, they might

they're not exactly I wouldn't want to slide back into Cartesian materialism by saying like, oh, information needs to go there in order to be conscious.

But they do play an important functional role.

And I think that because I subscribe to some version of the higher order view, I think that means that I have to be a little bit weaker on the Cartesian materialist critique these days because

I do separate the system into two levels and where one level seems to be privileged over the other in terms of the role it plays in bringing about consciousness.


SPEAKER_00:
Okay, cool.

We can go there.

That's, that's interesting.

That's an interesting development, because I'm aware of these higher order theories of consciousness with respect to self awareness.

You know, there are these so called pre reflective states of self awareness or self a subject which you can sort of deflate just the subjectivity, let's say, and the whole the whole principle of these, you know,

phenomenologically and ontologically is that no one there is nothing that is aware of them.

They offer the texture, the background to the objects of consciousness, but they never are in turned into an intentional object.

Obviously, his work goes back to Sartre, Merleau-Ponty, Husserl and so on.

Now,

This kind of poses an issue for the higher order theories of consciousness, because for them, these states or these experiences, which in turn are not reflected upon, it seems a bit problematic because they propose that actually there are higher order states which take these pre-reflective states as their object.

So there is no such thing as the pre-reflective or non-reflective self-awareness.

Rather, it's sort of hidden.

These higher order intentionalizers are hidden from us.

And then the rebuttal comes and says, well, how are these not conscious?

Surely I should be aware of these higher order states which have as their object my pre-reflective states of self-awareness.

And the higher order consciousness theorists come along and say, well, they're not conscious and they intend the pre-reflective states of self-awareness without themselves being conscious.

And then you have just the ontological question, well, how does that work?

And so I guess the question would be, we seem to have these, it doesn't have to be self-awareness, we seem to have these phenomenal, I guess the words coming to mind again is textures, right?

I mean, what people traditionally would have called qualia or quail, which is sort of what, you know, seems to constitute the what it is likeness of consciousness.

So the redness of red or the apple-ness of eating an apple and so on.

And

Um, these seem to be constitutive of my experience, even if I don't necessarily have to reify them.

And that's the same with sort of my own subjectivity or my own intentionality.

How do you, as a kind of leaning towards a higher order theory of consciousness, how do you deal with these otherwise seemingly irreducible ineffable intrinsic features, which at least on the surface seems to seem to belie, um, becoming an intentional object, a sort of overt reflective object.


SPEAKER_02:
All right.

Wow.

No, that's a good question.

So I must say that I'm not that familiar with the literature on the pre reflective self consciousness.

I'm getting more into it because I was recently interested

My recent work is more interested in affect and affective experiences.

So that's what I work on in Brussels now.

And some people postulate that, for example, in order to have emotional experiences, you need to have a

an explicit involvement of the self.

So Joe Ledoux, for example, is a higher order theorist who claims that in order to undergo an emotional experience, you not only need to activate what he calls an emotional schema,

uh which conceptualizes your the sub the subcortical processing in the amygdala and so on but also you need to have an active self schema so you kind of his big big catchphrases no self no emotion so unless you you are aware that it's to you that something is scary then you just don't feel fear right previously he called like the smaller

claim was no self no fear so you can only fear something if you realize that it's dangerous to you or you fear that thing that object so I'm not yet that familiar with that literature and I know also that even if we leave the self aside there's this whole literature on minimal phenomenal experiences which is something that Thomas Metzinger is now very interested in

Precisely because in deep meditative states you can let go of the self, right?

And you can presumably have these pure phenomenal experiences which are supposedly relaxing this idea that there's a self which is the anchor for the point of view on the world.

And I think that you're right, that both minimal pre-reflective experiences and minimal phenomenal states, they do put pressure on higher order theorists.

And so I think that there's...

two ways in which we can respond.

So one way is I think the way that would be taken by someone like David Rosenthal.

So David Rosenthal talks about qualitative spaces and he very much wants to

reclaim the word qualitative property from the hands of of strong phenomenal realists and say look there's nothing mysterious about qualitative properties as such qualitative properties as such

are not some kind of mysterious properties.

We know about qualitative properties.

We talk about qualitative properties in science, and we can think of the brain as representing qualitative properties.

That's not the problem.

Regular, scientifically understood qualitative properties are not

problematic on their own in a deeper metaphysical way, unless you conflate them with qualia, which are supposed to be not only qualitative, but also

know they're supposed to be ineffable they're supposed to be private and so intrinsic and so on and so forth so what he's trying to do is he's trying to separate the notion of qualitative property from the notion of intrinsic property and once you do that you can actually claim that on the first level you will have representations of qualitative properties and then you need this kind of higher

order process that targets or picks out or re-represents, depending who you are, these lower order states in order to have qualitative experiences,

And that's one way you can go about it.

I agree that this might not be satisfying to you because the problem then is, well, okay, so what about these states where we seemingly undergo ego, the solution and where the self mainly doesn't play any role?

It seems to me that in those cases,

traditional higher order theorists will have to claim that, well, you're kind of under an illusion that there's no self.

Perhaps the narrative self falls away, but there might be this kind of minimal notion of a self that's still in place.

For example, presumably, if you're in a deep meditative state,

uh you're still deploying your attention in some way or controlling your attention in some way there's some kind of process of attentional monitoring happening and

the system which is controlling the allocation or the flow of attention, if you want to call it that, that's the system which is actually responsible for this minimal self.

That's where the minimal self resides.

And Michael Graziano, as you probably know, has built a whole view of consciousness around the idea that the control model for attention is the

the representation that we introspect when we're experiencing things.

And then the second way.

So that's one way to do it.

The other way would be to say, well, how many higher order levels are there?

Right.

So you can always this is

it's as much of an objection as an argument in favor, right?

So you can always claim that there's an extra level of representation.

And it's not that things have to be represented on the second level.

There's a higher level.

And so, for example, in Graziano's model, to go back to that, as I understand his picture these days,

We have some first order perceptual or other processes.

Then we have the attentional model, which we represent these systems in a kind of way where they are distorted.

And then when we introspect, there's actually a higher order model yet that is

picking out the contents of the attentional control model.

At least that's one way to understand his claim.

And so in that picture, we would have these kind of three layers of the higher order model, right?

Then we could claim, for example, that when we're having these pure minimal experiences,

that the higher level that this introspective level, which renders things as for me experiences is dropping out.

But the control model again is still there in place.

And so what we're experiencing is just these representations in the control model, but there's no explicit level of introspection.

So the self is kind of sidelined.

I'm kind of spitballing here right now.

First of all, I don't have a complete theory of consciousness, and I would be, I hope, the last person to claim that maybe one day.

I will feel more confident in claiming some piece of the cake for myself.

And as I said, I'm interested in these minimal states of either pre-reflective self-awareness or minimal states of phenomenal experience, but I don't know enough about them right now to give you a very strong position about them.


SPEAKER_00:
Yeah, I mean, to be fair, I was somewhat spitballing as well.

I am not an expert in higher order theories of consciousness.

I mean, I'm aware of David Rosenthal and others who have proposed things akin to a higher order theories of consciousness.

I don't really believe in sort of monolithic, these kind of categories, right?

Everyone's got their own idiosyncratic way of viewing these things.

I came across it, I'm very, I am interested in pre reflective self awareness, kind of phenomenologically, more than anything, I mean, the ontological metaphysical ground of it is an interesting question.

I mean, just to state my claim, at least on something like subjectivity, I think there's a, it's absolutely viable to take a kind of more sartrean or Merleau-Ponty position that it's actually just imminent, it's intrinsic in all experience.

So even in minimal, phenomenal experiences, there's still the for me-ness.

And then I mean, this feeds into my kind of skepticism over higher order theories, because even in this notion of a kind of higher order representation, there is already inbuilt into that the four meanness that is supposed to be being represented, which seems to be kind of begging the question or, you know, putting the cart before the horse.

And I would, again, I mean, this idea that it's just intrinsic to experience, and then in some ways, you're saying, well,

experience is intrinsic, fundamentally, and there is just this irreducibility, of course, that comes with its own problems, right?

I mean, I mean, how, first and foremost, I mean, unless you're just a dualist out the, you know, out the can, like, so, so no, these are interesting metaphysical questions, I guess, um, it was probably it was probably a bit misguided than me to bring in the notion of qualia, because

I guess this is an interesting question.

When I was thinking about it, I was thinking about the way it sort of pre-reflectively structures our experience.

Again, I don't really know if this is true.

Do I need to reflect on the taste of coffee to experience the taste of coffee?

In the same sense, seemingly phenomenologically, I don't need to reflect on myself as an object to experience myself as a subject.

And so that's kind of why I bought in qualia.

But I think probably the higher order theories have a better chance of dealing with qualia, right?

It's just a representatum of some representing scheme.

Yes, I mean, these are deep rooted philosophical problems that we're not going to be able to solve on this podcast.

But I think an interesting question here is,

bringing it into a Bayesian account.

So you mentioned sort of fame in the brain there, another one of your papers or fame in the Bayesian brain.

The question I think that comes up just to mind is, if we took Dennett's multiple draft models seriously, and it seems, well, in some, it seems incredibly convergent with predictive processing and active inference in the sense that we're running multiple hypotheses of the underlying cause of our sensory data.

the thing is, is that we, in principle, you're never reaching the kind of infinite peak of a Gaussian, you're never coming up to a, you know, no hypothesis, in principle, statistically should occupy a one, 100% certainty, because this is just statistical distributions, right?

Yeah, if we're taking a very bare bones approach to Bayesian, the Bayesian brain hypothesis.

So

I mean, I've been reading this in terms of people like Andy Clark and Kate Knave have spoken about kind of seeming in the fact that perceptual experience seems determinate, albeit seemingly, if we take the Bayesian brain hypothesis seriously underpinned by indeterminate probabilistic processes.

I'm curious about how one can skirt this problem.

I mean, Kate has her own solution, which is a consciousness, in some sense, is indeterminate, although not in the way that people naturally think of indeterminate, she thinks there's a sort of singular reality, nonetheless.

People like Jakob Hovey will talk about distrusting the hypothesis.

And so there's this constant temporal flow.

I'm curious about how you can get how you think we can get from

a predictive processing picture of multiple hypotheses being entertained to a singular, seemingly singular, coherent gestalt of conscious perception?


SPEAKER_02:
Yeah, that's a that's, again, a very good question.

So I think I would start this by saying that

I don't so I'm very much interested in the Bayesian brain hypothesis from a kind of anti-realist stance.


SPEAKER_01:
Right.


SPEAKER_02:
So my stance towards these models is kind of

disengaged in a certain sense ontologically.

So I suspend my belief in them as actual descriptions of what's happening in our heads.

And I think that I take this removed position of all models are wrong.

Some models are useful.

Some models are interesting.

And I think that actually probabilistic models have a lot going for them, but it's just one of the possible ways of capturing what's going on in our heads.

And so if you approach them from this point of view, then first of all, it relaxes a little bit your commitment to finding the one true solution.

So you can say, oh, we could model this in this way or we could model it in that way.

We make some modeling choices that in the end determine how we're going to think about it or how we're going to model the behavior of the system.

And in some ways they are useful, but in some ways they can also be misleading, right?

So that's kind of to preface my answer here.

So that's the first thing.

Following from that, one of the big decisions that you have to make when you're deciding how to model the Bayesian brain, if you assume that the brain is doing something like Bayesian inference,

Then, of course, the question is, how are you going to model the process by which it's doing it?

We know that it's highly unlikely that it's running exact Bayesian inference, so it needs to use some kind of method of approximation.

So Carl and people in his camp have settled on variational Bayesian inference as the most likely solution here.

But there are other options as well, right?

Think about sampling, for example, which is another way.

And if you had a model based on sampling, you wouldn't actually have to be like the problem of determinacy is gone in many ways, because if you think that you're sampling from some kind of distribution and then you're experiencing a sample,

Then you're experiencing a sample.

It's a determinate point and the information is determinate, right?

Even though it comes from a probabilistic distribution.

So that's one way you could get around this.

The other thing that I wanted to point out is that in Jakob's picture of how things work.

So Jakob talks about probability density functions, of course.

And he talks about some kind of, as you said, uncertainty about the exact hypothesis that you're entertaining because you're never getting a kind of a point wise estimate.

You're always getting some kind of interval.

And that's also a way to get out of it.

Another way to get out of it is to, for example, bring into the picture some kind of dual coding hypothesis.

So you could think that on certain levels of the predictive hierarchy, things are being coded

in continuous spaces and in others they are discretized.

Right.

So some levels of the hierarchy are operating on probability density functions.

And there are parts of the hierarchy that are operating on probability mass functions where you can actually pick out one hypothesis as the currently winning hypothesis.

The reason why you might think that's the case is because of how concepts have been typically handled in philosophy, right?

So concepts are supposed to be these kind of distinct categories, at least traditionally.

Nowadays, a lot has changed in the way we think about concepts, but you could think that as you're bringing something into a conceptual frame, that conceptual frame is somehow constraining your experience.

You could think that, well, when I'm perceiving colors, of course, the space of my color perception is continuous.

But then as I'm recognizing colors, as I'm applying certain concepts to them, I'm discretizing my experience in certain ways.

The problem, of course, with that is that

there seems to be a lot more variety in our perceptual experience than our conceptual apparatus allows for.

So we both agree on what red is, but we could find multiple examples of objects that we would categorize as we would disagree about whether they should be categorized as red or not.

Right.

And there seems to be a lot of

perceptual experiences that fall under the concept of redness for both of us.

And we would agree that there is variability in what we call in the experiences we would label with the term red.

So that's then a problem.

And

I guess another option.

Sorry, I'm kind of layering different ways you could think about it.

And finally, there's another option, which is that even though you have multiple distributions that are kind of indeterminate,

or have these kind of intervals where you're modeling things with probability density functions.

So you're just picking out intervals.

You might think that if you have some process, higher order process, for example, that takes information from multiple processing stages, then there's a possibility that all of this is somehow collapsed.

into each other in a way where you do get actually very narrowly defined hypotheses, right?

And again, you might think that this would happen in some kind of discrete medium that doesn't have to be connected to concepts necessarily.

uh so so so i think there's plenty of ways in which you can you can get around this problem for me personally i think that nowadays i'm actually kind of removing myself from this this debate and i just think that well there are those are multiple ways in which you could model

conscious experience and build models of perception, for example, and categorization of perceptual experiences and so on.

And what's interesting is really whether these models can inform new predictions or new hypotheses that can be tested empirically.


SPEAKER_00:
Right.

We will come to the scientific realism versus instrumentalism thing, because I'm sure people want to hear your take on that.

in greater depth.


SPEAKER_02:
Sorry, can I just add one more thing?

So another reason why you just to kind of

again just talk about this you know why would there be one hypothesis that's winning uh one reason for that is nicely given by jacob hubi and francesco marci in their paper i don't 2020 i want to say i don't remember when it came out yeah i will have a uh but yeah

But they kind of, they subscribe to kind of Jesse Prince's view of mid-levels of the hierarchy relevant for consciousness.

but they have actually a very good answer to why there might be perceptual experience or experience in general is not kind of indeterminate, but is kind of rather fixed in a certain temporal window, right?

Because what's also relevant here is that when we're thinking about experience, we often tend to leave out time, but time is actually...

And a really, really important aspect of our perceptual experience and our experience in general, consciousness in general, we know that there is a certain integration window where stimuli that are presented in the same time will be integrated into one percept, for example.

So the reason they give for why there might be a certain deterministic quality to our perceptual experiences and experience in general is that

actions are actually not indeterminate, right?

Yeah.

Every action you have to take in your environment is a kind of determinate situation in which you're putting your body and the way you're changing your environment by acting on it.

You're moving things around and things kind of can either be here or there.

I can lift my arm and I can lower my arm, right?

And I'm in between two

uh states there might be some gradation between these two states but if i do one thing i can every state or every action i take or every state i put my body into that limits my possibilities it constrains them in a certain way and my body can be only in one state at a time

So when I'm performing actions, when I'm planning actions, I need to kind of experience the world in a way where I don't experience myself doing five things.

I'm doing one thing.

And that's actually perhaps there were organisms further on.

If we think that the Bayesian brain hypothesis is true, perhaps there were organisms that had a more indeterministic experiences of the world, and presumably they would have died out because indeterminacy.


SPEAKER_00:
yeah yeah exactly but yes yeah that's absolutely that makes perfect sense i mean again i'm

I point people in the direction of Kate knaves work as well.

I mean, she was just on.

Yeah.

And she sort of piggybacks off Jacob and Marquis work on this sort of in what they call it sort of intermediate processing, right?

Like, these are all and again, and perfectly chimes with things like affordances.

And the fact that perception is enslaved by action to some degree, I guess, well, multiple things that come to mind.

I mean, one is, it seems to me like a lot of this is a

comes down to the question of attention.

Because we make the claim that the world is determinate, the perceptual world is determinate.

But I would propose, and again, this is riding off what Kate thinks, that the world is determinate in the very sort of focalized purview of my determinate world.

Now, if I'm looking at my periphery, it is not determinate at all.

I think if to also build onto this action-based picture, it's because I only really act on what I pay attention to.

So do you think it's viable to say that you're talking about this higher order process, which collapses the probabilistic densities into a kind of... We can think of it doing kind of a Dirac delta function.

It just collapses it into a single value.

is how much of that would be that that is actually just attention, right?

That higher order process is attentionally homing in on a singular, you know, derives a singular percept.

And then we can say, well, that's because attention is in many ways a slave of action.


SPEAKER_02:
I think that's very plausible.

So this is more or less the view that we defended with Joe in the Fame in the Brain paper, right?

we kind of put attention in the forefront of consciousness there.

This is also a view.

I defended a similar view in my dissertation, and I do think that attention is extremely important for consciousness.

And Jacob actually also thinks that, right?

So he points out that on predictive or the active inference stories about the brain,

consciousness cannot be entirely separated from attention because attention is precision optimization, right?

And precision optimization or expected precision optimization happens on multiple stages in the system, happens on multiple stages of the

processing stages of the system simultaneously.

Really, there's never a time where the attentional mechanism is completely off, so to speak, in the brain.

There's always some kind of biasing, attentional biasing in terms of expected precision weighing off prediction errors happening somewhere in the system.

attention seems to be necessary for consciousness at least on the on the active inference predictive processing story uh so yeah i i find kate's suggestion uh


SPEAKER_00:
very palatable.

How much does this feed into broader questions of agency?

teleology, if you want to go all the way there, and, and relevance, I mean, I'm interested in theories of relevance or relevance, realization, John Vivecki, this kind of idea, the idea that attention in many ways is the kind of driver or the product of a organism which needs to, you

you know, enact relevance realization.

It needs to be able to disambiguate that which is relevant to it and that which is irrelevant to it.

And that, I think I've made this argument.

I wrote this paper.

It's currently in review about how I think that attention is ultimately the slave of preferences.

And I think you could say attention is, and that means that attention is ultimately slave of preferences.

relevance because it's not random what I pay attention to, obviously.

And also the very fact that I can pay attention is itself an act of prioritization.

It takes a kind of flattened world and creates peaks of salience.

So how much do you think that we can build in values, relevance,

meaning, and so on, into this kind of more stripped back mechanistic perceptual picture.


SPEAKER_02:
That's a really nice question.

And if you don't mind, I would like to read that draft if you don't mind, too, because this is something that I'm working on now in Brussels with Axel Clermont.

And actually, Axel has done some research years ago on attention and salience in addicts.

So he has shown he and other people that his co authors, they've shown that

So attention is driven by preferences, as you said, in the sense that addicts do pay more attention to things that are triggering their addiction.

So if you're a gambling addict and I show you pictures of poker chips or cards,

those are much more salient to you than kind of neutral stimuli.

So that's the first point.

So I think you're onto something there.

And I just want to also say that

Yeah, this is evidence coming from humans.

But if we go to a much more basic level, I think that attention is doing basically prioritizing certain information streams over other information streams.

Yeah.

And what that means is just as you said,

organisms that have attention are probably organisms that live in environments complex enough where they have to do some kind of motivational trade offs or they have to trade off acting on one piece of information against another piece of information.

Right.

So there seems to be attending to one stimulus against another stimulus.

So you have to prioritize

what you're going to do.

And so if attention is in the business of prioritizing processing of or trading off processing of certain things over other things, then that's exactly very similar to motivational trade-offs, right?

Where you're responding to a certain stimulus over another stimulus.

Because even though one stimulus, for example, will yield you rewards immediately, another stimulus will yield you greater rewards in a window of removed time.

And these two things seem to be quite connected in the sense that if you want to

apply yourself to pursue a stimulus that will yield greater rewards that are removed in time, it seems that it would be useful if you had some kind of a very rudimentary perhaps system of prioritizing information about that stimulus.

and kind of making you direct yourself away from the immediately rewarding stimulus, right?

I think these things are extremely connected.

And in fact, if we look at the literature on addiction and evidence that comes from rodents, so work of people like Kent Barrage on mice,

the main driver of what they call incentive salience so what has been labeled in the literature as the wanting signals so signals which which code prefers the preference for stimuli or the drive for certain stimuli these uh these signals have been linked to dopamine which has also been linked to

to attentional control, at least in humans and other mammals.

Exactly.

So I think that there's a very strong relationship here between attention and some kind of

I'm not sure.

I always worry about the word preference because I worry that people will misunderstand what we mean by that.

Because when scientists work, scientists working on reinforcement learning,

or rodents or some kind of simple animals.

They talk about preference.

It's clear that they're talking about preferences, but they don't talk about some kind of conscious, intentional states the way we think of them in everyday life.

And I sometimes worry that, especially in philosophy of mind, where people often

come from this armchair position where they think first about how things seem to them from the first person perspective, for example.

And then they look at the empirical evidence.

I sometimes worry that there might be some confusion.

And I'm a little bit squeamish about talking about meaning here, because I think that meaning is a very big word.

So I really like this term incentive salience because I think it connects precisely what you're interested in, which is salience.

So the fact that some stimulus is salient to an organism with the idea of an incentive.

So the idea that the reason why it's salient is because it is associated by the organism with some expected reward.

And that's what's driving the organism's behavior.

Behavior and also, I mean, inert and overt behavior.

So paying attention to something might be a kind of covert behavior, right?


SPEAKER_00:
Yeah.

Yeah.

Yeah.


SPEAKER_02:
Conceptualized as a kind of covert behavior.


SPEAKER_00:
Right.

Yeah.

I certainly view it as such a sort of mental action.

Yeah, exactly.

Like down exactly the same sort of the same base graph if you wanted to, the same C and E matrix if you wanted to.

Yeah, so there's plenty of things out.

I mean, one is you're absolutely right.

I think it needs to, you know, we always need to say we're talking about preferences in the Bayesian belief sense of that neurons have preferences, the atoms have preferences, but they, they have Bayesian preferences, they have attractor sets, they have so on, or at least they look as they can be described as if and so on.

And we've had this conversation.

And we'll cut we can come to this, of course.

When I talk about meaning, the reason why I do so is because I think the

the way that preferences in slave action is encoded in a hierarchically deep fashion, such that the certain things that we can claim make our lives meaningful are those which seem to have this trickle-down effect, such that they... One way of thinking about it is in terms of metastability, the deepest wells in which the other attractor wells are kind of subsumed.

So I've been thinking about this in terms of okay, you know, maybe my ultimate view of what makes my life meaningful is, you know, for evolutionary reasons is being a social adaptive member of society.

Now, I pay attention to although it's indirect, and implicit and covert, is often a manifestation of that.

So why am you know, why am I writing a paper because I want to get a PhD, why don't want to get a PhD, because I want people to think I'm impressive.

And eventually, in some sort of Aristotelian fashion, you ground out

for me in these kind of hyper priors, which seems to have this kind of deep filtration into our very low level attentional schema.

One question that I've been thinking about as a kind of follow up is I think it's very reasonable to say that, you know, when I'm hungry, because it's a very deep rooted prior, it kind of has a standardly high precision waiting that prior such that if when there's deviation,

Well, maybe not.

Maybe it's when there's deviation from that prior, there's an action policy that grants it high precision waiting, I should say, because we're not always hungry or aware of our hunger levels.

So there's a slight nuance there.

But you know, we can just say this, you know, for lack of a better word, it's kind of an important deep prior.


SPEAKER_01:
Mm hmm.


SPEAKER_00:
I think it's fair to say that when that's the case, I'm obviously I'm far more drawn to food, right?

Of course, I'm drawn to the fridge, I'm drawn to adverts of food now.

But I've been thinking, is that is it the case, therefore, the preferences and that which is afforded in terms of basing preferences are high precision weight at that moment, literally change our perception.

in such a way as it's sort of like a Sapir-Whorf hypothesis for perception?

Or is it the case that our perception is uniform?

And what ends up happening, of course, our attention isn't uniform, but our perception is uniform.

And what ends up happening is we kind of overlay our perception with the kind of conceptual schema and

but also kind of the attentional schema, but actually in the sort of fundamental aspects, the intrinsic aspects of our experience, the colors, the sounds and so on.

Things remain the same.

Have you got any kind of intuition on that question?


SPEAKER_02:
This is a good question because I think

So I'm kind of torn on this question.

So if you're thinking in terms of these hierarchical Bayesian models and active inference where there's cascading predictions constraining the activity on the levels below, it seems like there should be some form of influence.

your global states, for example, over your local states.

So being hungry is a kind of a

state of deprivation, which seems to be a kind of a state which I would maybe label it as a global state in the sense that it pertains to your organismic functions.

And if it's not satisfied, you will eventually die.

Right.

So it's kind of a state of global importance to the cognitive system, so to speak, because the existence of the cognitive system is contingent

uh on keeping that state within certain bounds so and then there's a question of like whether there's a way in which through as you said saliency maps and attentional modulation and all these things and as you said conceptual overlay for example there's a possibility in which this

higher order, well, let's call it global state again, would constrain the space of possible hypotheses or possible models in such a way that it would have determinate effect on your conscious experience.

And I think it definitely can have an effect on your conscious experience overall, because if you think of your affective experiences,

know we have the term hangry which clearly indicates that you can your affective state is changing and and you can go into a certain mood because you're in this global state of deprivation and then your your fuse gets shorter and you get irritable and so on whether it changes your perceptual states i think that under some models people should be committed to claiming that it does

I am not so sure about that because this is and we're here getting to the second kind of part of this dilemma for me because there's this whole literature about cognitive penetrability and whether our beliefs influence how we perceive the world qualitatively, whether the beliefs influence perception.

And from my understanding,

for example, the work of Chas Firestone and Brian Shaw, the evidence for that is very, very limited.

So it seems that our beliefs can, for example, influence our actions very easily, but they do not change our...

perception as readily as it might seem intuitive.

And so here I would probably try to be a little bit cautious now with one caveat.

And that's something that I'm working on now, which is the effective ladedness of perception.

As you know, and as many people at this point might suspect, being a student of Dan Dennett, I'm no fan of qualia and phenomenal properties seem to me metaphysically suspect, and I would like to exercise them or at least deflate them as much as possible in our ontology.

So I think that a lot of problems related to ineffability and a kind of intuitions of

phenomenal states being somehow mysterious comes from the fact that in our perceptual experience, for example, let's take vision as a simple experience.

A lot of information gets compounded and compressed in a way where we are unable to track all the information that's being

packed into a perceptual representation by our perceptual systems.

So one example is that colors appear to be intrinsic properties of objects to us, even though we know that they are actually bundles of complex relational properties that depend not only on the surface properties of the object, but also the source of light.

viewing conditions, context, our past experiences, the state of our ocular system, and also how our visual system is processing it.

So there's a complex nexus of conditions that obtain outside and inside of us that make colors appear in a certain way.

And yet all this stuff is kind of flattened into this perception of colors as properties of objects that are out there in the world.

and i think that so that's part of the story but even if we if even if i present to you you know the best state-of-the-art knowledge about color perception you will say like yeah but there's something ineffable missing there's this qualitative of of phenomenal experience and i think that this is perhaps because in our perception there are pathways for example to subcortical areas which might be

imbuing our perceptual experience with, as you said, some kind of slight emotional salience or something like that.

So what people have called in the literature as microvalence.

So I find this picture attractive.

especially I find attractive the idea that somehow affect might play a role here.

But I think that at this point in time, at least we have very limited evidence for that.

So this is something that we're doing now in Brussels, trying to find out more about the effective ladenness of perception.

And also it's worth

taking into consideration just finally kind of as a reconciliatory note the fact that you know even if perceptual states as such sensory states are not penetrated or somehow imbued with affective or other types of information from other area brain areas or brain processes that doesn't mean that our perceptual experiences as a complex cannot bring all these things together right so

perceptual experiences are extremely complex.

So it's not just about sensory properties.

Dretzky has, for example, written a lot about how concepts structure our perceptual experiences.

So there are sensory properties in our perceptual experience, but it seems that there's much more happening than just the sensory properties alone.

And that's something I'm happy to concede.

And I think it's highly plausible.

But the claim that, you know,

I see the candy bar wrapper as brighter because I'm hungry.

I would be very cautious about this type of claim.


SPEAKER_00:
You see, that's the kind of paradigmatic example, right?

Because I think you're absolutely right.

We need to bracket off the domains from which perception might be influenced.

So affect is clearly permeating perception.

And clearly the preferences or the priors or the hypotheses are affecting that, right?

So as you say, hangriness is a perfect example such that there is this prediction error or free energy spiking with respect to this one homeostatic priors and that permeates my experience.

That becomes a kind of just all pervasive experience.

The other thing that clearly is the wrong word, pervasive, but is intrinsic to my experience is the attentional modulations, the rivets and the peaks of my prioritization.

And clearly, as I say, and I outline this paper, preferences are shaping that such that I'm hungry.

the candy bar is going to draw my attention.

I think this is fair enough to say more than it would when I'm full, right?

Like I had this experience yesterday.

I went out for lunch.

I was really, I was with friends.

I was really hungry.

And there, you know, music, you know, newsagent shops or whatever, selling food.

And you're in that state of hunger drawn to that.

And then I leave and I'm like, I don't care.

I don't want to see it.

But yeah, exactly.

The point would be, does that actually alter the fundamental character, the qualities of that experience?

Now, I think an interesting contribution to this question is psychedelics, because there's something about psychedelics, which if we take a kind of rebus or Albus approach, loosens those priors.

at some level right i'm not saying the the sort of preference priors but the priors over let's say um i don't know like it's kind of like in dreams right like you might have a prior that um i can't sort of dissolve through walls i don't know like there's clearly there's probably no but something like that and clearly something is like dreams and psychedelics that gets loosened such that in perception i seem in the dream to be able to sort of blend through walls and so on

Now, there does seem to be a relaxing of a mechanistic prior that permits changes in my visual experience in this case.

I guess the question here is slightly different.

Could there be changes also in my sort of preference priors, such that if I was...

if I was super hungry and then took psilocybin, would would it literally change my visual perception?

Or is it just that the mechanistic part of that is changed?

So there's kind of two different priors or preferences that we need to be talking about as well.

can you can you sorry can you repeat the last part so if you took psilocybin it would change what because i think that you lost me there at the very end so i guess what i'm saying is you know the way people talk about well the rebus hypothesis related to psychedelics is somewhat vague about which it's a kind of narrative account of priors it just relaxes and i think carl has said this himself i'm sure robin would as well

there are different types of priors so one would be a kind of mechanistic prior okay what do i expect to appear in my perceptual experience so i do not expect uh you know two things to be in one place at the same time i don't expect for things to move through solid objects but then there's also the kind of what you know you could call phenotypic or preference priors which is

defining of the organism, I expect to be satiated, I expect my blood glucose level to be a certain level, I expect my temperature to be a certain level.

Now, it seems to me that what psilocybin is doing is relaxing those mechanistic priors, such that you can start seeing things go through walls, and the same in dreams and whatnot.

But I don't know how strong the evidence is that it changes the preference priors, right?

So my thought experiment was if I was really hungry,

and then took psilocybin, I can imagine it would hijack my attentional apparatus such that I would start homing in on all the food around me.

But would it literally would my steak start glistening with my candy bar?

I don't know.

I guess at that point it's kind of hard to say what part of the system is being altered.

But that was kind of the thought experiment.


SPEAKER_02:
Okay.

I see now.

yeah so well it's clear that psychedelics can induce synesthetic experiences right so so they can

alter how we perceptually experience the world dramatically.

And they can make us experience certain this kind of modality mixing states.

Right.

So you see the music, for example, stuff like that.

So that seems to be a very deep

change in how you experience the world in a sensory way.

So that's one thing.

I totally agree with you about the mechanistic priors and the fact that this seems to happen on drugs a lot and that just as you mentioned, as in dreaming, they seem to be relaxed.

So you're entertaining hypotheses that would otherwise be outside

of the hypothesis space that you could entertain and what's also interesting about dreams and hallucinations is that at least from a philosophical perspective that philosophers often kind of

create this strawman idea of hallucinations as something that's you know you're you're suddenly in a state where you don't know that you're hallucinating and you're confusing hallucination for reality this is actually extremely rare given given current evidence and it seems that people under the influence of psychedelics very often are aware that they are hallucinating

Just as sometimes people undergoing lucid dreaming, they can enter a lucid dream by realizing, kind of having this moment of aha, of oh my God, this is completely unrealistic.

Yeah.

Which is in itself also interesting because that means that you're relaxing a prior on certain levels of the hierarchy or in certain parts of the system.

But at the same time, there might be aspects of the system that are still kind of monitoring what's going on.

and are able to say this is this is not reality this is we're on drugs now right um that's one thing and then finally going to these preference or you know typical priors i think that's an open question one thing that's for sure is that and i don't know anything about the literature

that speaks about this change in preference priors during these psychedelic experiences.

But there is a lot of evidence that psychedelic experiences do change people's preferences and behaviors long term.

So there's this famous effect that people who have undergone

a psychedelic experience are for months afterwards scoring higher on openness and lower on neuroticism and these kinds of personality traits which would i would at least correct me if i'm wrong i would ascribe to a change precisely in these phenotypic priors where you're kind of changing your behavior or your attitude towards the world and people

yeah uh because of that experience so perhaps within the experience it's also possible now you know whether whether there would be this permeation of perceptually or sensory experiences by your preferences that's a very interesting question and uh i mean we're in the kind of golden age of psychedelic research these days so i'm sure that sooner or later someone is gonna control the

conditions of their experiment in a way where they will be able to show that this happens, or it doesn't happen.


SPEAKER_00:
Right?

Well, I guess, yeah, it's super important to unpick exactly what the hypothesis would be in that in that experiment.

Because as you say, clearly, as you Yeah, I mean, there's overwhelming evidence that, of course, you get these longer term effects.

And they're modulating perception and conscious experience in interesting ways.

But

again, the question is still there, which is, okay, what part of your conscious experience is it modulating?

So, okay, you're more open, you're less neurotic, it's going to be changing your attentional schema is going to be changing your effective schema, right?

The things that used to piss you off are probably going to piss you off a little bit less, you might be less reactive.

So you might have more space between the concept and the response.

But

is again i mean i mean they're really really the kind of fundamental question here is how much of conscious experience is there beyond all of that you know like how much is color these kind of supposedly intrinsic things that are not um overlays even though we know mechanistically they might be over there it's for sure like to what degree do they

Are they just part of all of those things?

I mean, the evidence kind of my intuition is that they're not because I could pay attention to something, but that doesn't change it.

It changes the way that I am living with it, right?

Same with affect.

It doesn't change.

I mean, I don't know.

It's hard to say, you know.


SPEAKER_02:
No, no, no, no.

This is not an argument that has not like this argument has been made before.

Straight off intuition.

When you're paying attention to something, it changes the quality of your relationship to that thing.

It's like with a camera, you're looking through the lens of a camera and you're adjusting the focus, but it doesn't change the object or the contents of what you're seeing, right?

So people have argued against kind of predictive processing stories that attention

might be kind of narrowing the distribution, making it more precise, but it's not changing fundamentally what you're perceiving.

If it was red, it's still red.

Yeah.


SPEAKER_00:
I guess the thing here is it's not changing what you're saying.

Again, we kind of have to distinguish between the noumenal and the phenomenal.

I don't think anyone would argue that unless you think that you have some quantum mechanics and you think there's observer, like parkalling of that, Newtonian mechanics.

Of course, if I look at my computer, apart from the very sort of potential photon changes, I'm not morphing it into something that it wasn't.

sure but phenomenally the con as you say the contents of my experience i don't know i'm a little i'm a little i'm a little less secure on that front um i mean i'm just noticing things i didn't notice before which in a sense is changing the content but whether it's changing the content as it pertains to the object itself is a slightly different question


SPEAKER_02:
Right.

So, for example, one way to think about it is so we have to kind of, I think, separate several things.

Yeah.

So one thing is that my claim and the claim that Joe has made together with me in our paper is that attention is kind of modulated, is corresponding to what

what block labels access consciousness, right?

So attention is not supposed to give you a full account of phenomenal qualities.

That's one thing.

And I think most people, most higher order theorists agree with this, that you can probably do more than you expect with just this kind of story about introspection or some kind of higher order, lower order relationship.

So people tend to think that you cannot get any qualitative information there.

That's not entirely true.

And Andy Clark has actually a very good paper, I think from 2000 or 2003 called Access Implies Quality.

I don't remember the title now.

It's a very nice paper.


SPEAKER_00:
Is it a case where access implies qualia?


SPEAKER_02:
Yes.


SPEAKER_00:
Yeah.


SPEAKER_02:
So that's a nice paper also that shows that the distinction between access and phenomenal consciousness might not be as clear cut as Block and his supporters would like.

But just to be clear, on our picture, attention is just this kind of probing mechanism in the Netian terms.

It's this access to information mechanism.

So that's one thing.

Now, the second thing is, as you said, that

that the claim about whether it changes the content drastically, whether paying attention to something changes the content of your experience.

And here again, we have to be very careful because something can change

your experience can change in some qualitative ways without the content changing per se.

So Dretzky has this very nice example where he compares two situations, one in which I show you a piece of paper on which I drew 30 dots.

And I just kind of show it to you like this.

And then in another case, I show you the same piece of paper, but there are 31 dots.

So technically speaking, the number of dots has changed between the two pictures.

So the content of your experience has changed.

At least that's the point that he would like to make.

In my view, unless you notice that there's an extra dot, the content of your experience has not changed.

And it's only through sharpening of attention could you actually notice that there was a difference between the two percepts.

So I think that there are these cases where indeed paying attention can change the quality of your experience, even though it might not change explicitly the contents of your experience.


SPEAKER_00:
Interesting.

That's an interesting division, right?

Because I think most people would view those as isomorphic.

They would view contents of experience and the phenomenal qualities of experience as isomorphic.


SPEAKER_02:
Yes.

So I think it's useful to maybe think of... Oops, I think I'm getting... No, sun is starting to shine into the office.

So you might think about this in terms of modes of presentation of content, right?

So attention seems to...

attention is not only picking out what you're aware of but it can change the mode of presentation of what you're aware of to some extent just as i said earlier with the metaphor of sharpening the the focus on the camera lens yeah that does the subject in the picture doesn't change but what's changes is kind of the way you're capturing the picture with your camera

And I think this kind of talk of modes of presentation might be useful as a useful kind of intermediate step between the content itself.

So what is represented the way it's represented, right?

this mode of presentation, that distinction might be useful here as well.


SPEAKER_00:
Do you think there's a strict, do you think one can draw a strict line there between contents and mode?

Do you think that's feasible?

I mean, is there a kind of taxonomy of modes in which things can be perceived?

Or can my mode in some ways become opaque and become a content?

I think the latter can probably happen.


SPEAKER_02:
There's not many people in philosophy of mind these days talking about modes of presentation.

So Chalmers is, I guess, the main figure when it comes to that.

Hilla Jacobson talks actually about something similar when it comes to effective coloring of perception.

um and some other people do as well but it's a very small group of people these days that talk about modes of presentation as distinct from contents but i definitely think that there is a there is a there are cases where we conflate the the way we experience things or the way they are presented to us an experience with what they are so i think i think so gila jacobson has for example a very nice

example that she uses in her paper as part of her argument which is that the same object the same food item can look delicious and disgusting to two people yeah and so what seems to they they are looking at the same thing right so so the sensory properties do not change presumably or we can even assume that the sensory properties don't change between their two experiences

But the effective mode of presentation of these two sensory experiences can be dramatically different.

And a simple example that I used in my talks, kind of hijacking Hila's argument, is a piece of licorice.

Because people often think that people can have strong reactions to different food items.

And licorice is a piece of sweet that almost... Or marmite would be another example.

Those are two things that people have very, very strong opinions about.

And they have very strong reactions to.

But the...

a jar of Marmite or a stick of licorice are not by themselves repulsive to us.

And yet people just perceive them as disgusting or delicious.

And they can have this kind of different ways of engaging with that content.

So maybe that's another way of thinking about mode of presentation as this kind of way in which you engage with the content of your experience.


SPEAKER_00:
Right.

What's Shakespeare?

There's nothing good or bad, but only thinking makes it so.

Yeah, yeah.

That's Hamlet.

Yes.

I mean, Shakespeare, I guess wasn't thinking about whether.

Yeah, I guess.

I would have, of course, I have no issue with the idea that licorice might look words fail us, it might look disgusting or look attractive to people.

But I guess the question is, do they look disgusting and look attractive to people?

Are we overlaying that?

Or is it suffusing?

I mean, even if it's not overlaying, it might be suffusing our experience.

The question there, as we were talking about, is are the sensory properties being altered?

But I guess it's an experimental question, ultimately.

How you could do that without qualitative rapport, which might be quite limited.

I'm not sure.

Because again, language fails us here.


SPEAKER_02:
So this is what we're interested in here in Brussels right now.

And one way you could think about it is, well, do you see changes

in the sensory processing areas when you're putting people in a brain scan, right?

Do you see changes in their activity depending on the valence of the stimulus that they're showing them?

So a common stimulus used in experiments on affect are smiling and unhappy or frowning faces.

or angry faces, right?

So you show them two types of faces.

They distinguish whether they are happy or not.

And then the question is, where do you see the difference between the happy and the frowning faces, right?

Is the difference represented in some

area of the brain that's associated, for example, with processing value.

Yeah.

Some kind of one of the frontal areas.

Or is it maybe or whether we can find the differences already on the level of perceptual processing?

So this is something that we're aiming to test here.

And the available evidence is kind of equivocal, I would say.

So there are some papers that

show differences in perceptual areas.

There is also some work that's been done in Nicholas Krieges-Corte's lab, which seems to show that there are actually it's not that the differences are represented in sensory modalities, but there is a sensory modality specific coding for the valence of the stimulus.

So you could think that there's a universal code for value in the brain.

But in order to compare where you have to bring two different stimuli, right?

So if I show you a happy face and a monetary reward, something like that, if I give you two different types of stimuli, if you have to do some kind of a trading off between them, you have to bring them into some kind of a common neural currency.


SPEAKER_01:
Yeah.


SPEAKER_02:
So there's Krikus Cortis lab has shown that there might be this universal value coding, but before items are brought into this universal value coding for comparison, there is also a modality specific coding of value in the brain that is not sensory per se, but there are differences in how values are coded

depending on the modality from which the information comes, which would seem to be this kind of intermediate state where your perceptual experience might be effectively laden, even if the sensory properties stay the same, because there's something that's being added on top of sensory properties.

It's not changing how the hue and the brightness and the color that you're perceiving, but

that there's something else that's overlaid on that, as you suggested earlier, that is changing the character of the overall perceptual experience.

And this is precisely Hilla Jacobson's view.

And also Frederic de Vinemont has a recent paper where she also adopts a view like that.


SPEAKER_00:
So much to read.

So much to read.

I'm writing down notes.

I mean, I'm very impressed.

It's funny that we still haven't resolved these issues

since 1983, when Jerry Fodor wrote Modularity of the Mind.

If he was still here, he would have loved to have listened to this conversation because I'm sure he'd have lots of opinions.


SPEAKER_01:
Perhaps, or maybe he would love to, or maybe he would be extremely frustrated.


SPEAKER_00:
Well, I'm sure.

Again, I never met Jerry, of course, but I'm sure he would.

Whatever it was, I heard he was an opinionated man.

I mean, for good or for bad.

Okay, cool.

That was super interesting.

I mean, I love that.

I read Modularity of the Mind when I was at uni and loved it.

I mean, I loved it as an intellectual endeavor.

I mean, I had no skin in the game, but I thought it was...


SPEAKER_02:
I also think there's a lot you can learn about writing clearly and precisely from Fodor and from Dretsky.


SPEAKER_00:
I've never read any Dretsky.

I mean, he's come up over and over again.

I had a little foray into I read one of the radical and activist books

Okay.

I'll remember who wrote it.

And there's a lot of sort of Drexkian and Millikan sort of critiques, as in they're critiquing them because they don't think that any, you know, only represent the only representations of those which are socially scaffolding.


SPEAKER_02:
Oh, so it's the second book by Dan Hutto.


SPEAKER_00:
Thank you, Hutto and Mayan.

Yeah.


SPEAKER_02:
And Eric, mine, the basic minds evolved.


SPEAKER_00:
I read one of them.

And again, it's not really my argument, but it was interesting enough.

I should read Milliken and Dretzky, but life is short.


SPEAKER_02:
But they're highly recommended.

Knowledge and the flow of information, especially if you're working on predictive processing and these topics.

I think it's a really beautiful book.

That probably is the first philosophy of mind book that took information theory seriously, even though there are some distortions and he at some point develops his own kind of version of Shannon's communication theory, kind of a mongrel view in the end.

But it's a beautiful book and it's an extremely funny fact that that book was published in 81, I think.

So 30 something years after Shannon's mathematical theory of communication became a thing.

And this kind of shows you how long it sometimes takes for philosophers to catch wind of what's happening in science.


SPEAKER_00:
This is a kind of historical question.

Did Chomsky ever reference Shannon?

Do you know if Chomsky was aware of Shannon?


SPEAKER_02:
I think it would be strange if he wasn't given that he was, you know, where he was working and that would be surprising to me.

However, I don't actually know.

So, so I've read Chomsky, uh, but a long time ago, like his linguistic writings a long time ago.

And I mostly, the last things I've read were mostly about, um,

about mental representations oh really yeah so so he has a very very deflationist view of mental representations you can probably find him you can also Francis Egan in some of her papers okay takes his minimal view of what she calls ersatz representationalism as a kind of uh Target


SPEAKER_00:
yeah i did uh i did linguistics as my undergrad oh okay so i i read chomsky from you know um syntactic structures all the way to minimalism uh but again this was all very sort of biological linguistics about and you know the question of whether linguistics there's you know a lad

an innate linguistic device or things like this.

So slightly different.

But yeah, I was just wondering because obviously he was writing in the 60s, 70s.

Yeah.

Okay.

On the question of representations.

I mean, actually, it's funny because both people I've had on who are expert in representations, you and Alex Kiefer have both recommended me.


SPEAKER_02:
And Alex's work on representation is great.


SPEAKER_00:
So I am a big fan of his work.

you I really liked your moderate predictive processing paper.

It was challenging, because I feel I kind of made me realise like, oh, I've been taking the vanilla predictive processing because I'm not personally my own writing.

I'm not

wedded to any particular architecture, whether it's discrete state space, continuous state space, I take the vanilla position, I run with it, and so on.

But it made me think like, oh, there's so much more for me to learn exactly about predictive coding, predictive processing schema.

What I found really interesting was this idea of, well, this ambiguity more broadly in the literature about what is being represented at different layers of the predictive processing hierarchy.

So you say, and I can quote, there's an ambiguity between levels which perform the function of standing in for features of the environment and those which act only as meta representations by standing in for the features of levels downstream.

So there's this idea that obviously the higher layers are predicting, I mean, all layers are predicting, but they're predicting the layer beneath them and the prediction error is rising up and there's kind of this meeting in the middle and this horizontal explaining way of prediction error.

But I thought it's a really nice observation, which is where does the external world come in?

Because there seems to be this equivocation where we say, okay, we're predicting the external states across the Markov blanket.

But then in this predictive processing scheme, we're actually only predicting the layer below.

And so there might only be one layer, which is actually receiving the sensory input.

So this was 2017, you wrote this paper.

Where have your thoughts now evolved to with respect to the architecture of predictive processing?


SPEAKER_02:
Yeah, so just on that quote, right?

So just to be clear about what I was kind of attacking there.

So what I was attacking is this ambiguity in how people answer the question about what is the function of a layer.

in a predictive coding hierarchy.

So is it representing the world, as some people will say, or is it predicting what's happening just below, on the level below?

And a lot of people, when I first encountered predictive coding and was very informed by Mark Sprivak, who was my master thesis supervisor in Edinburgh, and the way he presented it to us initially was,

uh in saying that the brain is just minimizing the story is that the brain is minimizing prediction errors and that's all it cares about and then it turns out that the best way to minimize prediction errors is actually to represent the world right so so so to kind of

have the brain become a kind of distorted, of course, but a mirror of nature in some ways.

And that this is the reason why predictive processing offers a kind of a story about the organism building up its own model of the world is because by building the process of building up your own model of the world is just the best strategy for long term prediction error minimization.

And so my problem in that paper was that different people want to link to different interpretations of what a single layer in the hierarchy is doing, depending on what serves their wider philosophical projects.

So people who are anti-representationalist will say like, oh, you know, the function of a layer is just to predict

what's happening on the layer below.

And other people will say the function of a layer is to represent the regularities in the environment at a certain level of abstraction and in a certain time window.

And both of these interpretations can be true according to predictive processing.

It's just that which one you're emphasizing seems to depend on your external, let's call them, or at least external to the framework, philosophical assumptions and convictions.

And this is why when I wrote that paper, it was already becoming apparent that, for example, Carl

is amiable to different interpretations of predictive processing or predictive coding or active inference, whatever you want to call it, depending on who he's co-authoring a paper with.

So if he's co-authoring with an activist, he will take a more an activist stance where he will try to avoid talking about internal representations or building up an internal model of the environment.

When he's writing with someone who's coming from a more cognitivist Fodorian persuasion, then he will lean more into the representational talk.

So it seems that there was this ambiguity about what's happening in the framework.

And today, I think I'm kind of...

So I used to think that maybe there's a definite answer to this question, which interpretation is correct.

Today, I'm actually thinking that the semantics maybe are kind of

disconnected from the formal layer.

So at least when it comes to predictive processing, I think there is no definitive answer whether we should think of the generative models, for example, as representations or not.

I think that this will depend on your other commitments about what the representation is, for example.

on the wider goal of what explanatory project you're engaging in.

I think those are the things that will actually determine which interpretation you will apply to predictive processing.

But I'm not really committed to either of the interpretations.

And this goes a little bit back to attention in the sense that I think what you are attending to

in the predictive processing story might influence how you will want to interpret the framework.

I'm sorry if this is kind of a satisfying answer.


SPEAKER_00:
I'm the same.

Despite being a host and I feel like part of being a host of an active inference podcast is in some ways you should be wedded to certain ideas.

I'm pretty ambivalent about or not even ambivalent.

I'm open.

I'm epistemically open.

I don't know.

that might frustrate some people but i don't know uh and also this isn't really i really have an area of expertise yet so so i appreciate that i appreciate the epistemic humility i mean it's an open question i mean i mean fundamentally one of the issues is no one really knows what representations are

I mean, as you say, all philosophical theories have their miracles, they have their axioms, right?

So are you a Dretskyan?

Are you a Millikan follower?

Do you think that there needs to be a strict isomorphism between that which is representing and that which is represented, and so on and so forth?

I'm wondering whether even...

if we park the sort of what is being predicted, whether it's the layer below or whether it's the world, what are the sort of unifying features, therefore, that we've come to in terms of a predictive processing landscape.

So for example, there's this idea that the priors of one level are the posterior furnished from the layer above.

Yeah, now,

What does that really mean?

Is that what people talk about when they're talking about predictions coming down the hierarchy?

And then I guess the question here is, and I said this to Alex as well.

I mean, I struggle visually, conceptually to really imagine a predictive processing hierarchy because I always view it as in time, right?

Dynamically unrolling.

So actually you have these, I mean, at a very vanilla level, fine.

Prediction errors coming up, predictions coming down, and they get canceled at some point.

You get a hypothesis, woo, the world appears.

Like, great.

But when you actually start thinking about, okay, mathematically, formally, what are the architectures that we're setting up in place, it becomes very tricky for me to imagine because I think of a layer that is simultaneously predicting and being predicted and explaining away prediction error.

So

just a very broad level is that for myself and for other people listening and watching a way of like formally disambiguating what might be happening or should we just say this is some dynamic system and you can kind of get by with the vanilla approach


SPEAKER_02:
i think you're putting me in a position where which is you know way above my pay grade here no but um uh yeah you that paper you do cover quite a lot of technical ground a little bit but i must say that also i'm not entirely sure how well you know my technical grasp

So whether I was that correct in the things that I was writing.


SPEAKER_00:
Did anyone send you an angry email?


SPEAKER_02:
No, never.

I'll answer your question first, and then I'll tell you one anecdote about this paper.

So you're right that there's a lot of variability when it comes to how you can implement.

the general predictive coding scheme.

And Michael Spratling has a very nice paper from 2007 called An Overview of Predictive Coding Algorithms, where he compares first of all, he gives a kind of a brief historical overview of linear predictive coding and where it came from.

And then he talks about the three major varieties of predictive coding as applied to hierarchical networks.

which is Rao and Ballard's original 1999 model, Carl's free energy minimization model and his own predictive coding through biased division modulation.

I believe that's the name of his algorithm.

So he compares these three algorithms and Michael Spratting is actually a guy from London who has done

a lot of work on modeling neural populations using predictive coding and building very large neural networks, performing different cognitive tasks by implementing predictive coding.

And so one of the problems that paper highlights is that because there are many different ways of doing predictive coding, it's not stable from one algorithm to another.

what the prediction error is right and you know what is propagated upwards what what is propagated downwards even how to delineate a layer of the hierarchy oh quite yeah so so there's a lot of and that's what i also touch that's what i also touch on and that's 2017 paper moderate predictive processing so

there seems to be a number of possible ways of doing predictive coding.

And depending which model or algorithm, rather, I should say, you'll pick, there will be certain differences and what counts as what.

So in the end, when I was writing my PhD, I actually decided to go to a higher level of abstraction.

And I looked at the work of Iris Van Rooij and Johan Quisthout from Radboud University in Nijmegen in the Netherlands.

So they have a bunch of papers in which they formalize predictive coding in a more coarse grained way by using basically Bayesian graphs and imagining each layer of the hierarchy as a Bayesian graph

with certain dependencies and connections between variables.

So in their model, they assume that each layer of the hierarchy, very much like in Friston's models, each layer of the hierarchy, which will have a set of hidden variables and a set of prediction variables.

Right.

And these variables will correspond to

Yeah, so these two types of variables will correspond to kind of the latent variables and the so-called observed variables in a way where the latent variables are the hidden variables that get inputs from the observed variables on the level above when predictions are generated.

and this will be integrated.

And then at the same time, we'll issue predictions.

So we'll influence the state of their own observed variables, and these will kind of cascade down.

So they imagine this kind of simple probabilistic graphs that are connected one to another, and they kind of operate in this kind of two stages, right?

So they either do inference or they

um, observe what's happening.

And I think that's a very, uh, general, this is probably the most general way in which you can think of predictive coding or predictive processing because it leaves out error units.

So they don't talk about how errors are propagated into the system, where the, where the errors should be connected to, to things and stuff like that.

And that's, I think really an important abstraction because.

the way errors are processed are dramatically different between different predictive coding algorithms.

And their very abstract and very general way of formalizing predictive coding has the one crucial benefit that it abstracts away from different algorithms so that you could still capture the general similarities between these algorithms without talking about

or getting bogged down from my perspective into the minutia of how each of the algorithms is implemented exactly.

Now there's a trade off in going via that route because by

going for a higher level of abstraction you're of course losing detail and if you're losing detail sometimes you might actually find out that you cannot disambiguate certain claims about predictive coding on that higher level of abstraction so people who have for example very demanding views of mental representations as structural representations that are capable of action guidance and error correction and stand in some kind of

homomorphic relationship to their targets in the environment, well, it becomes very difficult to disambiguate whether these

abstractly captured predictive coding layers are working as structural representations because you've left out so much detail on the table that you're just not able to exactly adjudicate whether they fulfill all the criteria or not right so so the fact that an abstract abstracted and idealized description doesn't fulfill these criteria that these people have for mental representation doesn't mean that a particular model like spreadlings

network or Friston's network wouldn't fulfill these criteria on its own when it's properly implemented with a greater level of detail.

That's, again, not a very satisfying answer, I feel.


SPEAKER_00:
No, I mean, I'm glad, personally, that other people find it confusing.

And I can go to Spratling or Karl.

Remind me of the two Netherlands, the two Dutch people who you were influenced by.


SPEAKER_02:
Iris van Rooij.

Iris, the way you would write it in English.

Van and Rooij is R-O-O-I-J.

Yeah.


SPEAKER_00:
and johann christ out okay perfect thank you so highly recommended uh very good very good patients no that's and this is uh i like because i think part of um part of my role here is to point people in certain directions right um so i'm seeing here cognitive cognition and intractability


SPEAKER_02:
So they worked a lot on cognition and intractability.

I think the paper I'm thinking of or where the formalization appears is something like to be precise, the details don't matter.

There's free energy minimization and information gain.

The devil is in the details.

Might be that.

Yeah, that's, I think, a commentary on Carl's paper where he mixes discrete and continuous variables.

So I'm thinking of 2017 Johan Quisthout, Harold Beckering and Iris Van Roy.

To be precise, the details don't matter on predictive processing, precision and level of detail of predictions.

That's in brain and cognition.

Okay, fantastic.


SPEAKER_00:
Well, thank you.


SPEAKER_02:
It's a paper that definitely influenced a lot of my thinking about

about attention in the excellent.


SPEAKER_00:
I mean, it's a shame that I wrote this paper.


SPEAKER_02:
It's difficult to keep up with all the literature because also the literature has ballooned.

So I started my PhD in 2014 and at some point I was just getting

Like there were 20 papers coming every month on the topics that I was working on just from people working on predictive processing.

So in five months I had 100 papers to read, which is kind of unmanageable, right?

So at some point the literature just exploded.


SPEAKER_00:
I'd like to know your anecdote about this.


SPEAKER_02:
So the anecdote, since this is a public facing podcast, or at least hopefully the academically facing podcast, the story about this paper is that I wrote it.

I guess it came out in 2017.

It was written somewhere between March 2017.

It came out.

So it was written mostly in 2016.

So the early days of my PhD, in fact.

And

And it was hot on the heels of Andy Clark's Radical Predictive Processing, which the title is supposed to be a reference to, and the debate between radical and conservative predictive processing, so precisely this

representation light or representation heavy interpretations of predictive processing.

And I made a terrible mistake when naming this paper because it's called Moderate Predictive Processing.

And to me at the time it was very clear what the title refers to and what it is about.


SPEAKER_01:
Yeah.


SPEAKER_02:
um and i thought you know it appeared in this collection of papers philosophical papers on predictive processing edited by thomas metzinger and vania visa and so i thought like everyone will know like this will be obvious that if you're reading like if you're googling stuff about mental representation and predictive processing people will just find this paper no problem and it actually turned out that because the title wasn't immediately informative

people just didn't know what this paper is about.

So I was meeting people four years later or three years later who had no idea that this paper came out and I was sitting in talks and people were talking to me about these things and they had no idea that this paper came out.

And at the time, it was one of the very few papers about mental representation and predictive processing.

But because

It was just badly named.

It didn't show up in searches.

So I would advise especially junior people to be mindful of how you title your work.


SPEAKER_00:
Yes.


SPEAKER_02:
That actually can change the discoverability of your work quite significantly.


SPEAKER_00:
Yeah.

They thought you were making a political point.

They thought you were.

Very good.

Yeah, no, you're absolutely right.

Just like fill the title with buzzwords, right?

Just free energy.

Make sure the word free energy is in there or active inference.

Yeah, well, discussing public facing work, people are gonna be surprised if I don't mention the Emperor's new mark of blankets, but I don't want to spend too much time we've been going for a while as well.

And I'm aware, you've probably got dinner, I've got dinner and so on.

But it's sort of your I mean, again, this is not this was not your solo project.

This was actually I don't know whether did Kelly Brunerberg lead this or was his name just first up?


SPEAKER_02:
uh so the way that project came about is because yele came to bochum where i was at the time just fresh after my phd and he gave a talk about mark of blankets which is also by the way a topic which plays prominently in the previous paper we discussed in the 2017 paper about mental representations where i talk about the insulation

of the mark of black with a mark of blanket between different layers of the hierarchy so after my after my after i finished my phd yele came to bochum and he gave a talk with his where he was just trying to understand the difference between mark of blankets as they're described in the literature on probabilistic modeling and and

in literature on Bayesian inference and how they are used and described in free energy modeling.

And so he was very confused.

I was very confused.

And so that was a paper that was a talk where he credited it to Manuel Baltierian himself.

That was something that there was a project that they were discussing and working on.

He gave the talk.

later told him like, yeah, I love this project because I've been trying to figure out how they understand Mark of Blankets for a while now.

And it was something that I kind of bumped into during my PhD.

And it wasn't entirely clear what is the correspondence between the way that Friston describes Mark of Blankets and how Pearl describes Mark of Blankets during my PhD.

I bought Pearl's 1990 book, I believe.

probabilistic inference in thinking machines i don't remember the whole title but it's the book in which he which is often credited as the source in which he introduced the notion of a mark of blanket so i bought the book i read the whole book and i still didn't understand how it's supposed to gel with the free energy stuff and then for half a year or something like that you know i was like okay yellow and manuel wrote the paper it's all good

I don't know, half a year more probably passed and I was talking to Joe and we were talking about something completely unrelated, a paper that Joe was writing at the time, which also had some probabilistic modeling elements in it.

And we talked again about Markov blankets because we were talking about this topic.

I said, hey, I got a great reference for you because I wanted to write something about this, but Jelle and Manuel, I think, already wrote a paper about this.

So I'm going to ask Jelle if he has a draft and I'll send it to you.

And so I contacted Jelle and it turned out that they haven't written the paper, that the paper kind of, you know, they didn't have the time to figure everything out.

It kind of laid in the...

that was locked in a closet, so to speak, where it was kind of sitting, waiting for a better time.

And somehow we just proposed that, hey, maybe we could collaborate on this.

Maybe we could help you bring the paper back.

So we discussed this stuff and we started writing a paper.

Then we started thinking, okay, so where should we try to pitch this paper?

What journal are we writing for?

And I think it might have been me, although I'm not entirely sure who said, hey, how about BBS?

Because it's getting a little bit annoying.

These people in the free energy literature, they're starting to claim that a bacterium has a mark of blanket, a brain has a mark of blanket, a person has a mark of blanket.

The Earth has a mark of blanket, right?

There are all these papers about the biosphere or the climate as a planetary mark of blanket.

And so maybe given how important and how prominent Carl's work in computational neuroscience is these days, maybe we can pitch it to BBS.

And so we wrote the whole draft.

We sent it to BBS and the rest is kind of history.

So we had eight reviewers.

I can tell you more about that.


SPEAKER_00:
Yeah, that is crazy.

I've had three.

That's a lot.

Eight is, I mean, obviously, I haven't got anything out yet.

So these are all in process.

Three felt like a lot.

Eight is outrageous.


SPEAKER_02:
Well, the good thing is that the more reviewers you have, the more of an arena it becomes where you can try to pitch them against each other in your responses, right?

And we did have in our reviews, we did get reviews where one reviewer said,

cut this out, this is irrelevant.

And the other reviewer said, oh, I find this bit really nice.

I'm really happy that it's there.


SPEAKER_00:
Right.

Well, okay.

So, I mean, this paper, I mean, I feel like when I read this paper, I view it in concert with the Markov blanket trick.

So I view these as kind of coupled critiques of active inference or predictive processing.

Critiques, I actually think is, it probably is a critique

I read these as more like speculative.

They're not speculative in a derogatory way, but they're calling into question.

They're saying, okay, let's get clear on the terms that we're using.

For example, a distinction that you draw here is between a so-called Markov blanket and a Friston blanket.

Precisely.

What, just in sort of layman's terms, without getting into the granularities of Pearl, and I'm going to ask who did the maths in that paper because I'm kind of amazed.

I looked at the list because sometimes you see there's like five philosophers and a mathematician and you know they've done all the formulae.

And I was like, oh no, there's four philosophers here.

This is really cool that they've also done this.

Without getting into the granularities of the variables, what is the difference between a Friston blanket and a Markov blanket, in short?


SPEAKER_02:
Yeah.

Okay.

So in very short terms, without going into the details of Perl's work.

So the main idea in Bayesian graphical models, I should say, in Bayesian directed graphical models,

is that you have a number of variables that are related by some dependency, probabilistic dependency relations, and that's usually expressed by there being kind of arrows between the

between the variables, right?

So you have variables that influence other variables.

And then if a variable is dependent, probabilistically dependent on another variable, there will be an arrow that connects them pointing kind of in the direction in which the influence goes.

So if there's variable A up here that's modulating the behavior of variable B down here, there will be an arrow pointing from one variable to another.

And that will mean if there's an arrow connecting the two variables, it will mean that the dependent variable is conditionally sorry, I shouldn't say conditionally, but it's dependent on the

on the variable which is influencing it.

And so a Markov blanket in very simple terms is that if you have a graph structure where there are different variables connected and dependent to each other in different ways, a Markov blanket identifies a set of variables which render some variable of interest, a variable in which the state of which we're interested in.

It renders that variable of interest conditionally independent from other variables in the model.

So basically it's a set of variables that render the variable of interest conditionally independent from the rest of the model.

So what that means practically is that you have some variable that you're investigating and you're interested in learning everything you can about that variable.

That means that all you have to know

about the rest of the system are the states of the variables in its Markov blanket.

And that because that Markov blanket is kind of shielding that variable from the rest of the system.

So if you know the states of the Markov blanket variables, you know everything there is to do that is needed to make an inference about the variable of inference.

And that's basically all that Markov blankets are right.

So Markov blankets are basically a way to partition

the variables in a directed graphical model, probabilistic graphical model, partition them in a way where you will be able to efficiently and effectively do inference about some variable in that model.

And so what's important about this is that

the original formulation of a Markov blanket by Perl doesn't ascribe any kind of special relationships there or special functions to the variables in the Markov blanket.

I mean, all of the variables in the Markov blanket, they can be connected in different ways, of course, probabilistically to the variable of interest, but none of them are kind of more important than the others, so to speak.

And you cannot learn anything about the functions they play in the model just from their positioning in the Markov blanket.

And now here's where the innovation of Carl Fristen comes in, which is that Carl Fristen has partitioned the variables in the Markov blanket.

So first of all, he partitions them in two ways.

So he calls them the internal variable and the external variable.

So he assumes that the Markov blanket is kind of separating or shielding the internal variable, which will used to be our variable of interest in Perl's terms, from the rest of the system, which is external to the blanket, so to speak.

And now the second innovation is that apart from talking about internal and external variables, he also starts talking about he starts to talk about sorry.

And now I have to actually refresh my memory because it's been a while since we wrote that paper.


SPEAKER_00:
I assume sensory and active.


SPEAKER_02:
Yeah, exactly.

I was just wondering what is exactly the term.

So not sensory states and active states.

Right.

The states in the variables in the Markov blanket itself can take kind of a sensory function or they can take an active function.

And the difference between these two is that some states, some variables in the Markov blanket will take information from outside of the blanket and these will be the sensory states.

And there are some variables in the Markov blanket can influence what's happening outside of the blanket.

So they have kind of these probabilistic arrows in the model coming out from the blanket and influencing external states.

And these will be active states.

And it seems at first as a kind of innocuous

Distinction.

Yeah, sure.

So what you're telling me you could say.

So what you just told me is that what Carl noticed is that some variables in the blanket are influenced by external variables and some variables in the blanket are influencing the external variables.

Right.

And that would be all fine.

If it wasn't that this partitioning into active and sensory and internal and external wasn't playing an important role in active inference and that it is taken to delineate a minimal active inference agent.

And this is kind of the sleep from calculating or delineating a blanket.

and going into giving it an interpretation of an agent that has some internal states and is interacting with the external environment via its perceptual and active states.

That move from one to another is actually a huge leap because in Pearl's original formulation of Markov blankets,

you can specify a Markov blanket for any variable in your probabilistic directed acyclical graph.

So every variable in the model

will have its own Markov blanket.

And these will be partially overlapping, of course, in terms of the variables that make up the blanket.

But what's important is that no variable is kind of privileged in relationship to the other variables in the model in terms of how it's treated.

So every variable has a Markov blanket is just a way for Perl.

It's a formal tool for

learning something about the dependencies in the model nothing more and now and doing inference of course over the states of interest so it's kind of just a tool that's deployed in a purely pragmatic way and in friston's interpretation it becomes something more because suddenly there's this whole layer interpretive layer that's added to the mark of blanket formalism

which implies that variables of interest are somehow and blankets are constitutive of agents.

And then implies that there are these agents and the way that Friston often kind of formulates his models.

There's an agent that's interacting with the environment.

And so the interpretation of the Markov blanket under the free energy principle and in free energy models doesn't seem to be sorry, seems to privilege

a certain way of looking at what the model is supposed to be doing.

So it's kind of a built in assumption that we're modeling an agent and this agent is doing something in our case, minimizing free energy.


SPEAKER_00:
Right?

Yeah.

This is interesting.

This is a conversation that's come up a lot in this podcast.

I wonder whether as a result of papers like yours, as well as the Markov blanket trick, as well as Mel Andrews's paper, Van Eyre's, I wonder where there's been a general attitude shift towards a, well, at least a recognition of this issue.

So I've read the responses as well, and the commentary to the responses, and you draw a distinction.

I think this is interesting between literalism

realism and let me just check i don't instrumentalism realism and literalism and i like you there's a graph i don't know maybe it's because i like graphs there's a nice graph where you sort of put everyone on the spectrum um

Indeed, where what can you in brief, I mean, I'm sure people Okay, so like instrumentalism, I'm sure in part, you know, in short, we can say, okay, the Markov blanket is a tool for us scientists.

But it's not actually making any claim to ontologically say what's going on in the world.

And then realism or literalism would be well, no, the Markov blanket literally

is a partition in the physical world.

What is the addition of realism there?

So that's a kind of the spectrum.

And then you've got realism in the middle.

How does realism carve up that space?


SPEAKER_01:
Well, so I guess the way I would think about realism is that that


SPEAKER_02:
that they identify... So the real is what we kind of a position, intermediate position where you say, well, there are cases where in which Markov blankets

do align with or can be used to identify real features of the world, right?

So are set to identify boundaries in the world.

The difference to literalism is that in this interpretation, a Markov blanket is still a tool, kind of a way to capture a real difference in the world.

Right.

But you cannot... Someone who's a realist, at least in my understanding, and maybe my co-authors would have a different understanding.

Also, time has passed.

Yeah, yeah, yeah.

But my understanding here would be that literalism is this type of claim that at some point appeared in the literature that

an organism has a Markov blanket.

I think that if you say an organism has a Markov blanket, you're committing a kind of category mistake because Markov blankets are formal properties of models and not of organisms.

And so a more moderate position from that is to say, well, there's a boundary, there's a real boundary in the world, and

we can delineate that boundary, represent that boundary using a Markov blanket, right?

And that under some conditions, and this is really important because I think we got a lot of pushback for that.

So we never kind of argued against the view that you can create a model system where under some conditions,

there will be boundaries in this emergent boundaries in the behavior of the system such that you can model these boundaries with Markov blankets effectively.

And I think this would be a kind of a realist position.

What we kind of argued against is that some people have claimed in the literature before we wrote that paper that all this talk about agents

having boundaries separating them from the environment and having internal external states and so on.

All this talk falls naturally from the math, from the math of probabilistic inference and variational free energy minimization.

And what we wanted to show is that

that's not actually true if it falls from something it falls from some extra assumptions that you bring into the picture it wasn't you know it's a result of assumptions that you build into your models sometimes and that's fine if you're transparent about that there's no problem with that

But it's not that you just have a system where you can delineate probabilistic graph, you can partition the variables and suddenly you show that, oh, my God, there's an agent in there, right?

It just doesn't follow in this straight way.

And so I think this would be the

the clear difference here between instrumentalism also and literalism where instrumentalism is you know just being as non-committal as possible saying we're just doing modeling we're not claiming that what we're modeling needs to correspond in any uh in any truth-preserving way to what's out there in the world then there's realism where we say we are doing modeling but we do claim that we're

tracking something real in the environment using this formalism.

And then literalism is saying the model is what is being modeled, right?

The medium is the message, so to speak.

So the blanket, Markov blankets are something that organisms have that are boundaries in the world that we can talk about boundaries in the world as Markov blankets being out there.

And that's just nonsense, in my opinion, at least.


SPEAKER_00:
So

okay okay so yeah so this is the point right is it that's the last point that last point i think is the really critical one uh why is it nonsense

that a coupled agent arena relationship has a markup blanket like what what is the part so there's one argument which is that it's a tool so it started off being a tool it would be as you say it's a category mistake to confuse the map with the territory in this case so to confuse the tool with the actual on the thing that exists now that itself is not an argument against the thing that exists

the thing exists being isomorphic to the map, the map being the territory.

It's just saying, hold on, be careful.

It's just caution.

Now, it takes a further step to go, well, actually, I think that it's nonsense that the map is the territory.

And I think this goes a little bit to what Vicente Raja and his colleagues spoke about, that there are certain systems, at least in his perception, that it's not just the case that the tools that we bring to bear on these systems, you have to be cautious when you apply them and say that there's something ontologic happening.

He's saying that the tool is insufficient, right?

whatever the tool is doing, it's in no way matter.

There's no way we can even, it doesn't even make sense to say that something like that is going on in the real world.

And he has the example of a candle flame, right?

And this idea of the candle flame is that the flickering of it implies that this marker blanket is kind of shifting in and out of existence.

There are further arguments.

I mean, they won't really pose as arguments, but Andy Clark's things about metamorphosis, using marker blanket, marker blanket, super interesting papers, my work on butterflies and caterpillars, like

questions of identity, very philosophical questions.

But I'm kind of curious about how you go from saying, okay, it's an instrumental tool.

Now, I could be agnostic about how much the map should be conflated with the territory.

But it's a tool and it should be treated as a tool and we should have a different name for what's actually going on in reality.

And it might be the same thing, but let's use a different name.

So these are just very scientific questions.

it's a dip.

Why is it?

Why do you take the further step to say, actually, no, it's not just that it's a tool and we shouldn't apply it for scientific reasons.

But actually, the tool, it's literally not the territory.


SPEAKER_02:
Yeah, so.

Okay, so

I think there are two things I would like to say about that.

So first would be like an intuition pump, right?

So me saying that I have a mark of blankets would be something as ridiculous as me saying that I have number two.

What does it mean that I have number two, right?

So if I tell you I have number two,

You're going to say in what way, in what sense do you have number two?

Do you mean that you possess the concept of number two or that you can calculate with number two or you have something that is shaped like number, like the Arabic numeral or I have two items that essentially, what do you mean by that?

And I think that

So the intuition here would be saying that you have a Markov blanket is very similar to claiming that you have number two.

It cannot be said without further qualification.

So in this sense, it's nonsense because you have to say something more.

You can't just stop there.

So that's one point.

And now the second point is, I guess,

Yeah, so the mark of blanket trick is a very good paper.

And I must admit that I personally, I am not equipped in terms of my knowledge of physics and modeling to assess the arguments that they use there to

to claim that the tool is completely useless for the task that it's supposed to do in the active inference framework.

Sorry.

But I think we would all agree here, speaking for my co-authors, I think that what we would say about this is something like this.

So what we would say here is, well,

We have demonstrated that Markov blankets as such are formal instruments that do not privilege between any element of a graphical probabilistic model.

So every element, every variable in a probabilistic directed graphical model

can be described as having its Markov blanket or a Markov blanket.

It's better to say a Markov blanket of that variable can be identified.

Yeah.

And so if this tool does not disambiguate between or does not privilege any of the variables in the model,

That means that when you're moving in the realist direction and when you're claiming that there's a boundary in the environment that you will model and capture using this notion, it means that you're building in some assumptions which will help you privilege certain variables over other variables in your model.

And that's as long as I said before, as long as you're staying honest about that, there's nothing wrong with that.

Scientists do that all the time.

Basically building any model that requires you to say like, hey, we're going to build in some assumptions and that's fine.

And now I guess what I find troubling and where the problematic jump would be is to say, okay,

If you're honest about the fact that you're building a representation of a certain object in the world, and you're honest about the assumptions, so the idealizations and the kind of falsities and simplifications that you've built into that model, if you're honest about that,

it's near impossible to make the jump into literalism and claiming that you have to be... So in order to be a good realist, let's call them,

has to be honest about the assumptions that go into their model and has to be honest about the fact that all models lie in a way, in some way.

And then in order to jump from there to literalism, you have to become a kind of a dishonest realist.

So you have to abandon, hide all the assumptions in order to be able to do that, because

Because otherwise, I think at least to my mind, it's just this kind of epistemic jump is impossible to make if you're taking in all the assumptions and all the idealizations and all the simplifications.

If you're stating them explicitly in the premises and you're clear that there are simplifications and idealizations, then it's just basically impossible to make this final move to claim that the map is the territory because you just admitted that it's a map.


SPEAKER_00:
right so so you you kind of um yeah so okay so yeah i understand that in terms of a strict literalism the world is always too complicated in some sense it always eludes us uh and so when we're modeling it we always have to build in our assumptions but it still seems to me that there's a difference between assumptions that lie and assumptions that simplify right so i can i can take a very coarse grained uh model of reality which never nevertheless

has a faithful, reliable mapping to that reality, like a map, right?

And so maybe I end up having a kind of telionomic analysis of my map that it serves me, right?

Like my GPS serves me.

It isn't the world, but it serves me.

Now that seems very different from a map, a mapping which lies, right?

A map which says that I'm in Paris when I'm in London.

Now that's just one that's totally useless.

And to like, it's literally wrong.

It's not just that it's a well, it's not just it's a compression.

It's a compression, which in its ISO, you know, which in its mapping is wrong.

Right?

I'm not saying that the mapping I'm not saying that of course, a compression is right.

Of course, there's not a strict isomorphic mapping between the map and the territory.

Nevertheless,

I still think I'm curious about whether you could, whether you might be open to the idea, let's say, that nonetheless, we build in our assumptions, they're simplifying, so we can't adopt a strict literalism.

Nevertheless, there is a way in which we could build out of that model that we end up having

Given the assumptions that we've had and we inflate it all and we end up with a picture of reality, like an actual true faithful picture of reality.

And that follows Bayesian mechanics.

Okay.

Well, it's worth I have no invested in this game, right?

I'm just asking questions.

So just on the table, I just think this stuff is interesting.


SPEAKER_02:
Yeah, no, this is a perfectly fine question, and I think it's great that you're asking it.

It's just that I'm trying to figure out.

So your question basically is,

Well, so I think we have to ask ourselves, what is the end goal here?

Maybe this is what we could start with.

So literalism would be a view that kind of like in the Borges famous short story about the Empire and the map of the Empire, literalism would be a view where

you blow up the models, you kind of build up, build up, build up, build up.

You describe more and more phenomena using those models.

And suddenly it turns out that it's the world.

Exactly.

So there would be a one to one correspondence between the model and the world.

And I think that first of all, that's not really feasible.

It's not a model.


SPEAKER_00:
Exactly.


SPEAKER_02:
It stops being a model.

And then the second thing is that

it stops having any use, so to speak, right?

So it becomes useless.

So as soon as the map of the Empire spans the whole Empire, it cannot perform its function as a map.


SPEAKER_00:
Do you think there are people in the active inference community who think that adopt such a radical literalism?


SPEAKER_02:
No.

I'm sure that the literature has exploded, expanded so much that I'm pretty sure that any position you can imagine in that literature has been taken by someone.

But people do talk about organisms having Markov blankets, and I find this very puzzling.

So this is just what we are attacking.

This, as we said earlier, category mistake.

now the the interesting question here the there's a second possibility here which i think you're pointing to which is that we're building we're starting with a model of the world which you know is not not an exact replica of the world it's a it's a model and then we kind of expand this model and we end up with something that is not an exact replica of the world because it shouldn't be but it's a complete system

that corresponds in interesting ways or in relevant ways or some truth-preserving ways to how things are in the world.

So we kind of get this model that tracks things in a realistic way.

And I think that's...

I'm not close to this possibility.

I just don't entirely see right now how you could get there, so to speak, with the Markov blankets and active inference at this point in time.

So one of my worries that we don't mention in the paper, I think I don't remember now exactly, but I don't think it's in the paper.

One of my worries is that

you can have two types of explanations, right?

So you can have this kind of horizontal view of explanation where you're explaining, you're covering a huge ground and you're bringing a lot of phenomena in under one kind of shallow umbrella where,

you're creating this kind of spreading structure that connects many often very distant disciplines by using a kind of lingua franca of some formalism.

And this seems to be the project of active inference right now.

So there's more and more fields that are kind of brought under the umbrella of free energy.

More and more phenomena are described as versions or as ways of doing active inference.

and that's very interesting it's an interesting unificatory project where you're trying to unify many different branches and many different domains of science but there's another model of explanation in science which is not about unification but is about vertical integration right so you're kind of trying to study one phenomenon on different scales

And you're doing it in a very kind of narrow kind of window of focus.

So you're really trying to understand how one mechanism is realized on different levels of organization.

So neuronal spiking, right?

For example, you can study the ion channels and then you can study protein folding and all these kind of different aspects of how a neuron operates.

And you're just interested in one piece of

The brain, you're interested in how a single neuron responds to stimuli, but you can study that on ever more fine-grained levels of description.

And in the end, hopefully you have this kind of vertical integration where you understand how the brain works, starting from a very subcellular level onto the level of the whole brain, or at least an area of the brain or a network.

and i'm not entirely sure that these two models of explanation are compatible so i think that active inference and the free energy principle is doing an interesting interesting work bringing in different domains of inquiry into a common framework in which they can start to interact so suddenly you know it's it used to be the case that people doing

reinforcement learning, we're very far from people doing, I don't know, something like

Yeah, for example.

Yeah.

Or doing perceptual modeling.

And suddenly there is a possibility that these two people, these two groups of people will interact and will be talking to each other.

And that's extremely valuable.

However, I'm not entirely sure that the free energy principle and the active infant stuff is very good at providing this kind of vertical integration precisely because as you're trying to describe everything using the same tool, it might turn out that on different levels of description,

there are better suited, more accurate ways of modeling things that don't conform to the assumptions of the free energy principle or the assumptions of the active inference framework in general, whatever you want to call it.

So there might be kind of

in different domains of inquiry, kind of these vertical domains where people are trying to study a particular phenomenon at an ever finer level of detail, there might be domain specific or level specific ways of modeling certain phenomena or processes which are better suited for that purpose than the free energy formulation using Markov blankets.

And then the problem becomes kind of that

Well, should we abandon that in favor of this overarching structure that connects everything?

I think we can be kind of pluralist about that.

So we can think of the free energy principle or the active inference framework as this high level abstract unifying layer while not diminishing the work that's being done in very particular areas.

And the reason sorry, just I lost track a little bit because I'm getting tired.


SPEAKER_01:
Yeah.


SPEAKER_02:
But the reason why I'm not sure that active inference can do this vertical integration is because precisely it's trying to re-describe every phenomenon on every level of fineness of grain as doing the same thing.

And that's actually a problem, right?

Because if you find out that a single neuron is doing the same thing that, I don't know, an ion channel is doing, you might have a problem here.

And I think that's maybe my general qualm here.


SPEAKER_00:
Yeah, so I'm getting tired as well.

So we will wrap up imminently.

But there are just several things that come to mind.

I mean, one is that I think it's probably not the case, at least in most recent formulations, that active inference would say that the neuron is doing the same thing as a planet.

It's just that the neuron looks like it's doing the same thing as a planet or can be described as if it's doing the same thing as a planet.

And then I guess all of these concerns get deflated in some ways, which is which I mean, look, given my again, you've been in this game a lot longer than I have.

But even my first encounters of active inference is very much being on this looks as if line.

So I think we're not really going to have any problems with that.

And even in your commentary, your response to the 35 people who got in touch, you very much say, you know, in response to Inez and Maxwell and Thomas Van Aers, like,

We don't really disagree.

Instrumentalism deflates all of this.

I guess the thing is, you said something really interesting in there, and I'm wondering whether you meant to say it, which is one is that there may be tools which are better at modeling.

So I actually hear this a lot from RL people where I work at Royal Holloway, which is active inference as if it's very good.

It's very interesting.

It's cool that you can get from basic physics to

uh a as if physics of life like it's cool it's interesting however uh we have to do model comparison and if active inference models uh are better than rl then we'll use it but if rl is better than active inference we'll use that now that's that's one thing and like i think everyone in the scientific world is interested in that and and should probably advocate for that because why not right like it has better downstream uh effects when it comes to whatever therapeutic goals

But you also said something that is that sometimes those models, those RL models, again, someone can go back and check the tape, but it was something akin to, and you can correct me, they may actually break the assumptions of active inference.

Now, that seems a different problem.


SPEAKER_02:
That's true.


SPEAKER_00:
Well, I guess my question here is, is it a different problem?

So if I break the assumption of a theory, does it turn out that that theory is wrong?

So if, for example, active inference rests on, I don't know, whatever it rests on.

I mean, maybe it does.

Again, I think another issue here is, are we talking about the free energy principle?

Are we talking about active inference as predictive processing, active inference as policy?

So I've actually been thinking this in my own case.

Active inference is a very loose term.

When I write it, I say it's a corollary of the free energy principle, because Carl says it's a corollary, and I know what that means.

But

And then they say active inference is a process theory.

I mean, that 2017 Friston paper is active inference as a process theory.

Now, the free energy principle is not a process theory.

So active inference is kind of this weird middle ground of bridging the free energy principle with predictive processing and POMDP schema.

But, you know, that said, I guess the question is, right, if I take one of these deep assumptions of active inference, for example, we are doing, there's a KL divergence.

So rather than doing Monte Carlo sampling, we use the KL divergence.

If I break that, do I in turn break active inference and how deep does that rot go?

Because in my estimation, I've said this on this podcast, Carl said it to me, the free energy principle is quite shallow.

It's very deep and shallow in an interesting way.

It's deflationary.

It doesn't really tell you anything that exists and then you build out of it.

I'm wondering whether you say, okay, RL breaks a core assumption.

I don't know what that would look like, but let's say it breaks a core assumption.

How deep does that rot go?


SPEAKER_02:
Okay.

So what I was thinking about specifically is that if you want to be a realist about Markov blankets, you have to bring some assumptions on board, right?

Yeah.

It's not like it all falls out of using variational base.

You have to assume some extra stuff.

And so in the past, one of these assumptions was ergodicity.


SPEAKER_00:
I was going to say ergodicity.


SPEAKER_02:
And so ergodicity is a good example where if you have a model in some domain, there was a time.

I don't know what it is now because I kind of work on other stuff now.

So I have been paying less attention to the development in the literature.

I know that people have been moving away from the ergodicity assumption in the active inference literature, but ergodicity is a good example because there was a time where ergodicity was kind of baked in to what people thought active inference and the free energy principle are supposed to be.

And then if you break that assumption, so if you don't have that assumption in your model,

then it would seem that you're incompatible on a very important assumption with what was happening at the time in the active inference.

And so the question would be then, does that completely invalidate your model or whether that completely invalidates the free energy principle?

And I think I would be rather reconciliatory here by saying that

know you don't expect all the models to have all the same assumptions because models are representations of reality so what you probably want to do is like there's some phenomenon that you're trying to describe and the more complex the phenomenon like life itself

the more angles you want to look at it from.

So you probably want to have this plurality of models.

And I think that's all fine, right?

The other thing is and then if you're a pluralist in this way, I guess the problem you might encounter is that why would you need a single principle like the free energy principle, right?


SPEAKER_00:
Yes.


SPEAKER_02:
And

that kind of raises different questions.

And again, if you're a pluralist, if you're a kind of a perspectivalist, where you think that there are multiple perspectives to look at single phenomenon that can be all equally informative, depending on your explanatory interests or pragmatic interests, then I would say, well, it starts to be difficult to see why you would want to claim that there's this overarching principle.

yeah unless you're looking at this principle as just a means as i said before of building this super structure right which is just you know as if doing free energy minimization story which is supposed to create these bridges between very distant disciplines or the wains bringing them into together into into


SPEAKER_00:
conversation which is pragmatically very valuable let's yeah but it's it's it might not be the be-all end-all of you know science no no i mean i mean yeah there's an interesting kind of meta sociological point about why people want a grand unifying theory of anything i mean

It's definitely satisfying in some primordial sense.

But beyond that, it may be wise to rest among plurality, as you say.


SPEAKER_02:
And there's also the argument from the pessimistic meta induction, which is that every theory up till now.

So we have certain set of scientific theories we think are

best right now but every theory that preceded them in each of the fields has been discarded as false or as you know missing some important aspects so why should we assume that our current theories are true if

history of science is layered with husks of abandoned theories.

And one more thing that I just wanted to mention, you earlier said about the incompatibility of different theories in science, and I immediately thought about the incompatibility of quantum mechanics and Newtonian mechanics.

And what's interesting about that case is that even though we don't really know how to make the two compatible,

We haven't abandoned either, right?

So there's a possibility that you will have on different levels of description of reality, you will have different models with different assumptions describing different phenomena.

And that's actually okay.

Maybe that's just how it is.


SPEAKER_00:
Yeah, I'd like to get a philosopher, philosopher of science on here, because I think this isn't really well, this isn't my area of expertise.

But I think there are slight differences between the models employed by the free energy principle and the models that Newton employed.

And I think one of them is that when I write down F equals ma, right,

the, of course, I make the assumption of, you know, I do that school, and I they say, Okay, what's the acceleration of the car, and it's got this mass, I then make the assumption of wind resistance, and the lack of wind resistance, tire friction and everything.

But it seems to me that

in principle, Newton could have recognised those assumptions and built them into his model, and he gets a closer approximation of the truth.

The question therefore, and we'll leave it here, because we go for three hours, and that is whether the free energy principle is like Newtonian mechanics, such that it can act as the base, a true ontological base, because I think if you ask Newton, he would say, literally, F equals ma.

It's not just I say it and it looks as if things are doing F equals MA.

It's not just if I know M and I know A, I'm going to know F. That's a law of the universe inscribed in the universe.

Now, I'm not a philosopher of science.

I'm also not a physicist, so I might be wrong here.

But it seems to me that that therefore acts as a base on which you can build in friction, you can build in air resistance, and so on.

And you get a closer approximation on the truth.

And that doesn't make his theory false, right?

It idealizes, it just makes it a base, right?

And it just means it's pragmatically useful, but it doesn't make it false.

The real question here, therefore,

and I'm not going to answer it today because I'm out of caffeine and I'm out of energy, is whether the free energy principle is that base as well.

And I guess time will tell on that front.

But ultimately...

epistemic humility, I do think is the way, right?

I mean, I think I think if we can talk about one recurrent thing that's been very useful in the history of science is epistemic humility, plurality, listening to the other side.

And so that's why you know, I very much appreciate you coming on the show.

Because well, it's not a lion's den.

I mean, I've had this.

I've had all sorts of people don't think most people are partial to active inference, but it's not really a strict active inference fan club.

But no, I mean, I really do appreciate the openness and the expertise and the Danette and curiosity.

No, it's it's been amazing.

I mean, three hours and five minutes have flown by.


SPEAKER_02:
Thanks.

Yeah, it's sorry that I wore you out so much.


SPEAKER_00:
You should be apologizing if you didn't wear me out.


SPEAKER_02:
Yeah, just to close up, you asked me at some point who wrote the maths in the Markov blanket paper.

So it was first and foremost, Manuel Baltieri, because he has background in machine learning, so he knows a lot of this stuff.

And then I was helping him.

I think that would be the correct way to.


SPEAKER_00:
Okay, yeah.

I'm always super impressed.

I mean, it's just it's kind of a project that I'm trying to undertake myself as well, albeit having that and then simultaneously battling the kind of fears like no, this is just an instrumental tool, get back to consciousness, get back to consciousness, like that's not like, you know, at least that exists and so on.

And there's an interesting

sort of pulling and throwing in different directions.

And I guess active inference does that it bridges, as you say, these multiple domains, but I'm very glad personally, people might disagree with me, I'm very glad that philosophers have brought to bear their expertise.

I think, as you know, in the modern world, we probably are a bit disenchanted by philosophy.

But I think with the prominence of active inference, it's kind of shown its strength and power to say, hold on a second,

think about your presuppositions, think about your axioms.

And I'm personally a really big fan of the fact that phenomenology and consciousness is also kind of returned.

I mean, it's not that, you know, it returned in 1995.

Or, you know, Thomas Nagel, but like, this feels like a real renaissance of this question.

So, you know, long live philosophy, I think is the

is the final note.

But yeah, Chris.

Amazing.

I think this is much.

Well, I think this is the longest podcast.

No, no, no, no.

Well, call it that way.

Call went for about three hours.

Julian Kiverstein went for about three hours.

So you're in good company.

Okay, thank you.

This was really, really fun.

I really enjoyed it.

So thank you so much.


SPEAKER_02:
All right.

Thank you so much for your time.

Again, sorry for wearing you out.

Sorry if I was maybe a little bit incoherent at times, which sometimes happens when you're going for so long.

Please send me the draft of your paper.


SPEAKER_00:
You have my email, so I would love to read that.

That's very kind.

And also, before you leave and before we end the show, please let people know where they can find you, what you've got coming up, your work with Axel, like anything that you want to say in terms of self...


SPEAKER_02:
Right.


SPEAKER_00:
Everyone hates this bit.


SPEAKER_02:
Yeah, I get it.

That's how it works.

So my website is Chris dolega.xyz.

That's where you can kind of track my publications and stuff.

And if you look for Chris Dolega spelled in the same way on Twitter or Blue Sky and Mastodon, I think that will also pop up.

And yeah, together with Axel, we're organizing a symposium at this year's ASSC in Tokyo.

Nice.

So that's something that if you're in Tokyo at the time and visiting for the ASSC, you can come to.

It's on unconscious affect.

And finally, I will be also giving a talk which will be online in something called the Tokyo Analytic Philosophy Forum.


SPEAKER_01:
Let me just check if I remember the date.


SPEAKER_00:
I will make sure all of this is in the...


SPEAKER_02:
So it's Tokyo Forum for Analytic Philosophy.

It's a series of talks that's hosted at the Tokyo University.

And I will be speaking on the 19th of July, actually about something that we touched on briefly here.

So about effective modes of presentation and perceptual experience.

If you're interested in that, you can join.

That will be online.


SPEAKER_00:
This will be going in the description.

ASSC will be going in the description.

I'll put the website in there as well.

Okay.

Cool.

We've done three hours and ten minutes.

Okay.


SPEAKER_02:
Amazing.


SPEAKER_00:
Thank you so much.


SPEAKER_02:
Thanks a lot.

Have a good evening and take care.