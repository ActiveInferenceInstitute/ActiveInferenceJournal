SPEAKER_00:
Welcome back everybody to the sixth episode of Active Inference Insights.

I am back today with another fantastic guest, Adam Saffron.

Adam is a postdoctoral research fellow at Johns Hopkins Center for Psychedelic and Consciousness Research.

With deep roots in the active inference framework, Adam's work has explored the nature of preferences and motivation, mindfulness, consciousness, agency, and psychedelics.

In addition to this, he might well be our only guest thus far who has written a paper titled What is Orgasm?

And deadlifted 280 kilos for multiple reps.

In sandals, might I add.

Note, by the way, that these two domains need not be related.

Adam, thank you so much for joining me and welcome to the show.

So good to see you.

And I'm really glad you could join us.

And as I said, I mean, I'm always blown away by the diversity of interests and research topics that our guests bring to the table.

So it'd be great because I think we're going to have a wealth of things to cover.

The first thing I wanted to ask

is about the body.

You write in one of your papers, bodies represent near ideal initial systems for learning and inference with this prototypical object and causal system providing basis for further modeling.

I wanted to ask, was I being interested in what Jacob Howie called the evidential boundary?

Where can we kind of circle off the internal and the external with respect to Markov blankets and active inference?

So I wanted to get your take on whether you thought that, what do you think of the body?

Is it a prior that we could say the mind, the cognitive system, it's incorporating in its sort of predictive schema?

Or is it itself an object of inference that the mind, you know, conducts probabilistic reasoning over?

Yes?


SPEAKER_01:
To which one?

In that particular paper, I'm trying to provide a count of basically how core knowledge gets loaded into mind.

We need something like core knowledge, but what's a biologically plausible account of how we might arrive at it?

And so then the idea is you're basically using the body as basically a way of structuring learning curricula to make them tractable for a computationally bound system with limited learning opportunities, like making the most with the least.

And the idea is you create basically the body acts as a near ideal training wheel system to figure out where the conditions for inference are fruitfully constrained.

And then you can use that in the structural learning process.

Sure.

And so you can think of it as, so the body would be both in a way an evolutionary prior

And that the specific ways in which it's some, you know, like for instance, like the Rolf Pfeiffer, I think speaks really well to this in terms of like the way that the limited shoulder, the range of what the mobility of the shoulder joint, for instance, already would make your arm go out in front of you.

and then like be more likely to grab things and where they're like well look right there at the right distance for me to both manipulate them and to observe them and so those would be the kind of like evolutionary priors you might expect but it's like in the bootstrapping process would be um

You could also think of it, though, as like core knowledge to get to there.

It would be maybe not necessarily an evolutionary prior, but a very reliably learnable posterior.

So, or an empirical prior.

So, you know, I think depending on like, but it might be so reliably learned and so canonized eight ways from Sunday that it might as well be an evolutionary prior, even though there is like this mediation by the learning that takes place, but it's basically in the bag because you did it because nature did it so well.

um so whether you would call it a prior or a posterior um depends on your perspective and some other people who've um kind of talked to the body as a prior like uh micah allen had a good paper uh the the body is prior talking about the way in which for instance um our interoceptive states as particularly stubborn predictions would help to make sure that like the whole like generative model is basically uh orbiting around allostasis and so like so yeah


SPEAKER_00:
Does it make intellectual sense to you to carve a dividing line like an evidential boundary, or is it more elegant to just say it's philosophically vague?


SPEAKER_01:
So I guess like in that tradition of like the, so like the body as first prior, um, there's also like the work with like, um, uh, Anna Chianitsa and, um, others where it's like us starting like mentalizing homeostasis where it's like you're, um,

part of this learning curriculum is multi-agent and coupled.

Like we're starting within someone else's bodies and then even when we're on the outside, we might as well be because we're so dependent.

And so like,

And within also this Rolf Pfeifferian context, or this roboticist and the overlap with Rodney Brooks also, similar kind of thinking, but the world is its own best model, or like emergencies and a lot of the lifting being done by morphological intelligence.

You know, even when you're on the outside of the womb, you're intensely coupling with others in an extended mind sense.

So it's like...

It seems like you definitely, you can't just take it like at the body boundary, then the mind stops.


SPEAKER_00:
Yeah, this is a really interesting avenue.

I've been thinking about Clark and Chalmers' 98 Extended Mind Hypothesis paper in the lens of active inference.

And I've been sort of informed in my thinking by two people.

I've already mentioned one of them on the earlier podcast, which is Manuel de Landa.

and his most recent book, what's it called?

Material Phenomenology.

He gives a sort of mechanistic account of vision.

And he critiques the inactivist tradition on this count that basically what they want to call an intrinsic relation, i.e.

the coupling itself is constitutive of the identity.

So in the coupling between agent and arena, you actually form the definition of agent arena.

He criticizes that, that what actually that really is is a causal extrinsic relationship.

So that's one strand.

And then the other is Thomas Metzinger.

And Thomas did a podcast with Professor Friston.

And he spoke about how the notion of inaction might be quite misleading because it kind of implies that there might be a subtle reivocation of a Cartesian ego where you have A enacting B.

So I want to kind of pick your brain on that because it's interesting you brought up extended cognition and the fact that the mind might, its identity might go beyond the remits of the body.

Are we in danger there of invoking what Delander calls an intrinsic relation where really what we're looking at is just causal connections and we shouldn't actually be mistaking that for identity relations?


SPEAKER_01:
I'm not sure.

In that paper, I imagine I antagonize more than a few people and actually going Neo-Cartesian in a way.

quasi-homuncular and Peter-esque as essential ways of understanding agents and their relations to the world in terms of the way they're situated, and that having an internalized representation

pegged according to this reference frame of an observer from an egocentric perspective would do a lot of heavy lifting in the process of structure learning and making things tractable.

The, yeah, so it's like, I guess, yeah, you might have to like loop around a few times, you know, in terms of getting me to doc properly.

But, uh, I guess the way I'm thinking it's like, like mind as model has to be like extended and it's like the, um,

The ways in which the affordance landscape is so dependent on these couplings to go to internalists is, in a way, missed the point about what lets you do anything.

But I do have sympathies for the internalist account in terms of making room for things like...

re-presentation so that you can do things like offline learning and imaginative planning and like, you know, basically like the world is its own best model.

Whenever possible, it's morphological compute, you know, emergent, you know, from the

the couplings of the organism and its environment.

Don't just push your predictions down to the lowest level of the brain.

Push them out into the environment.


SPEAKER_00:
Yeah, yeah, yeah.

That, I guess, was the question I wanted to come to.

So it's all very nicely interwoven.

You're right.

You evoke this notion of the kind of quasi-homuncular systems.

And you mentioned the frame problem, which is a really interesting problem to me, which is kind of

How can we be intelligent in an ignorant manner?

How can we zero in on personal information in the world, given the preponderance of sense data?


SPEAKER_01:
Intelligent in an ignorant manner.

I love that.


SPEAKER_00:
Thanks.

It's not mine.

I'll shout out John Verveke.

I mean, he's the one who's kind of outlined the frame problem to me more than anyone else.

This is kind of a leading question because I have a sense of how you're going to answer it, given what you just said.

But can the frame problem be solved by just kind of a single conscious homunculus at the tip of the prefrontal cortex?

And if not, how deep do these, or how deep do you imagine that these quasi-homuncular or all these mindless cognitive agents, as Manuel de Landa would call them,

How deep do they go towards the skin?

I'm sorry, I know I've gone right into the deep end on these, but why not?


SPEAKER_01:
No, no, it's good.

So it seems like the extended and active nature of

of minds helps to curtail like frame problems and that you're always like in the world in particular ways.

And if like you're coupling with the environment is creating basically like is basically like

in a way, creating an enslaving center manifold for the whole system that you always have to keep coming back to to stay on top of this action perception cycle and on top of this interchange.

The full scope of relevance is if you're always being brought back home and grounded in this common task of cybernet control, that seems to take some of the... I don't know if it quite defangs the frame problem, but it helps to curtail it a bit.

But in terms of also taking the range of...

you know potential relevant affordances it's still you know a big space um but still you know the idea of like orbiting it around um an agent's model of itself and its interaction with the world um

don't know how far um homuncular for instance representation gets you with respect to that but in a way it um the idea of like basically one of the core things that you're modeling is the livid body the idea of the center of your experience this um uh you know so the homunculi i guess we will so i guess unpack homunculi so like the the thing that people are worried about would be right a homuncular regress where just like

there's a little man in the head that's doing the observing and he'd explain things.

The reason I start to push on this issue of trying to resurrect homunculi and things like Cartesian theaters is the idea is that the folk intuition is coupled to the phenomenology in a way that actually might reflect the data structures, might actually reflect the principles of the controller.

And so the importance of taking your perception and giving it a coherent perspectival reference frame.

So something theater-esque in terms of having the right geometric relations of the things of the world and their relationship to you.

But then also, for instance, though, the idea of an observer that helps, that watches the screen, the sense of your embodiment as a central data structure, being in close communication with basically the systems by which you would do visual perceptual synthesis.

Because what your body is doing will inform what you're likely to be, what it means, what's coming in on your retina.

Or the visuospatial, the somatospatial should tell you about the visuospatial and vice versa.

And it's interesting that in robotics, these are actually the primary data structures they use.

So like in the collaborations I've done with like Tim Verbeelen and Ozan Katal, like in their latent SLAM systems, one of the primary things for situating the robot in the world is basically a conjunction of views and poses.

And they're almost like one data structure in that it's one of the best

Where I'm looking, where my sensors are oriented are going to be highly informative for what I'm looking at.

And also just the way my body is configured.

I don't think this isn't quite brought into their systems, but the range of relevant affordances.

What am I likely to be seeing?

Well, what your body is doing will be highly relevant to that also.

And so the mutual information should be very strong, closely coupled.

Right.


SPEAKER_00:
Yeah, it kind of brings me back to the first question, I guess, which is, I mean, I could probably reword that now using the terms you've just said.

I mean, I think internal and external and active inference can be considered a kind of relative misnomer.

Because, you know, I like Maxwell's rewording of it as tracking and tracked or modeling and modeled.

I think that's quite an effective way of reshifting the focus here.

So I guess the way of rewording that question is,

You know, are we, in invoking a homunculus in the Cartesian theater, are we a risk therefore of kind of thinking that there's a genuine ontological homunculus, which is conducting variational Bayesian inference and has a model over which it does computations.

I think like that rubs a lot of people the wrong way, because for a lot of people, it's just dynamical systems.

And so, you know, do these kinds of questions actually call into question the more fundamental dichotomy of tracking and tracked and distinct ontologies, distinct entities in the world?

Potentially.


SPEAKER_01:
And so, yeah, maybe I'm asking for too much, but I want to have it all.

I want to have, I don't know what you say.

I don't know.

inactive couplings in the streets and like revisions and a couple of good sheets you know like um the you know to the extent possible like you know there's even no need to appeal to like some sort of model representation for much of what i'm describing this like mutual contextualization of like these different sensory systems in terms of they're already coordinated just by having a certain situation on the body itself and in the world and the way like the

The information is cascading in the context of the inactive coupling.

And so there's a sense, you know, the model of the agent is extended into the world.

Its mind is extended already there.

And a lot of like the work I'm talking about, like the homunculus is the body itself.

There's no need for like an initial representation of it.

I do, though, suggest we might have, though, such basically a data structure, you would say, and maybe even potentially involving... I put this forward basically as a kind of prediction that nothing rides on in the sense of...

If I'm wrong, sure.

But if I'm right, could be interesting.

But the specific idea is that there might be subnetworks of the brain that actually have a geometric organization about them in terms of you would even have within cortical hub structures potentially a...

geometric correspondences through the manifold activity in those networks and what's being represented.

So you could even get like homuncular in terms of like the network is almost little person-like on some portions.

And the reason you might want to do this is that within geometric deep learning, like if you give a network the same geometry, essentially not so like a physical network in terms of like

Well, I guess it would be there in the connective intervention, but it could be just like a dynamic emergent pattern of effective connectivity.

But if the network, though, has the same structure as that which it is representing or modeling or trying to track, you end up getting potentially orders of magnitude greater efficiency.

Yeah, that's really cool.

That's really cool.

So it's possible that there could be, in addition to most of what we're doing is effortless mastery, and the long killer story, you never need representation, you never need internalized model, and you would want that too.

That's quicker, more efficient.

But you might also, on top of that, for the sake of things like imaginative planning, things like having more nuanced control of the sensory motor engagement,

you might also have re-presentations of this and potentially even shockingly Cartesian accounts, like in terms of highly centralized and even kind of looking with a geometry

that would be of a similar shape to the body itself.


SPEAKER_00:
Yeah, that's fascinating.

I mean, these strange loops, as Hofstadter would call them, are seemingly never-ending, the body having loops of itself, the body having loops of the world.

I mean, it comes back to, I think, kind of the cybernetic good regulator theorem.

And like, is that saying, you know, there's this kind of confusion is out saying that all good regulators have a model of the world or are a model of the world.

And I think, I think.

I don't know.

I mean, I don't know whether you think that's still a live question in active inference.

I mean, to be honest, to be completely candid and yes, I'm a relative layman with a year's experience of thinking about active inference and not understanding the maths and the physics, but that's okay.

I think there's still a kind of question there, which is, and Carl, to be honest, was quite neutral on it when I asked him, which is like, what is it?

What are internal states?

Um, yes, internal.

So it makes sense that internal states have or embody, have embodied beliefs about the external states.

I mean, that is at the heart of like a likelihood mapping.

So fine.

But is that it?

Uh, is that when we're going to give them is these beliefs and what is it to embody a sub personal belief?

Is it just an instantiate?

Like, I think people find it very difficult to.

basically move away from the physical mechanics to the statistical mechanics.

And I think there needs to be a bridging mechanism.

So I don't know if you had any thoughts just on like the broader way that a sort of layman audience, including myself could make those intuitive or those non-intuitive distances between statistics and physics or the physical material world a bit more intuitive.


SPEAKER_02:
Yeah.


SPEAKER_01:
to, it's like, we're working with this account of like, you know, blankets of blankets of blankets and, um, I guess the way I'm interpreting is like, um,

Internal states, coarse-graining external states, and then nested within their internal states, coarse-graining external states, so on and so forth, in a hierarchy or a heterarchy of nested-blanketed structures, giving you these multiple levels of resolution that you can unpack as needed.

And so I guess the thing I'm wondering is whether, like,

I wonder whether it seems like none of it works without the inactivist principles, without the structuring of what's happening by intelligent morphologies.

Or without just the nature of the coupling of the system and its world providing the grounding and the semantics and the interest, none of it gets off the ground.

But the story still, it can be told just at the level of the system and its extended phenotype as this one single...

model and like where do you draw this boundary what's internal what's external it's like it depends on the scale you're thinking about it right um and so i guess the place where i wonder is we're gonna need internalism is when we get to consciousness yes like like so so like so i you know i guess you might even call me like a kind of like panpsychist of a stripe in psyche in terms of understood as like mind

But then when you get to basically consciousness in terms of something like a system where we might say there is something that it feels like to be that system, and that can do things like imagine, for instance, and dream.

For that and those elements of experience, it seems like we're going to have to at some point invoke enough... We're going to need a blanket of...

a set of attractors that are internal and can basically break free of the immediate engagement with the world because that's part of our experience.

And so like for people, I think to actually like account for phenomenology, to account for like

you know, like a lot of the things that matter to us, you know, eventually getting to, you know, things like agency, even like free will, we're going to need to, at some point, go internalist.

But like in that process, though, you know, it's just, but still the story for most of evolution, you know, but still like if you go in that direction, though,

and you lose sight of the inactivist principles, well, then you basically find yourself in the same places that I guess you could say the mainstream machine learning goes astray sometimes.

You think you're going to handle the problem just with scale or raw compute, or you don't understand the kinds of learning curriculum you would need to bootstrap intelligent systems or how they would need to be deployed to

achieve goals in the world um so uh yeah so i again like i think i end up like occupying a very awkward position that's like you know the um radical and activists will be like you know you don't need to invoke these things and like um uh uh

Cognitiveness might be like, you're leaning way too hard in saying that embodiment is necessary.

But I think that is the case, though.

I think everyone was kind of right in just emphasizing the count of what's going on.


SPEAKER_00:
Yeah, yeah, yeah.

I mean, I haven't staked my personal claim, but I don't disagree.

And I think that nuance is always going to be right in some fundamental sense.

all theories are wrong because they're just wrong to different degrees all metaphors are wrong some metaphors are useful right exactly I mean I was wondering you know it's funny that it's not funny it's interesting that you say that the inactivist principles are necessary it'd be great to have like a pure internal although I can't label people but like someone like Jakob Howie who you know if he was here might again I'm not putting words in his mouth so be curious to see what he thinks might ask whether it's

conceivable that a kind of compute only system could do variational Bayesian inference given its priors.

I mean, I think another useful distinction actually to unpack for our audience and something that I found really, really useful is this distinction between having a sort of epistemically viable model of the world

So you are actually, you know, it's descriptive.

It accounts for the sensations that it's observing or its sensations it's receiving.

And the normatively viable model of the world, i.e.

one where you aren't just dispersing into the heat bath, but you can maintain your own sort of autopoetic organization.

And I'm wondering whether you think it's conceivable to any degree, whether both sides of that equation could be fulfilled by

a kind of sheltered off super intelligent homunculus.

Sheltered off and never comes into contact?

Well, I mean, so it comes into contact vicariously through the Markov blanket.

So I'll permit active and sensory states.

But again, vicariously, it has to do this kind of variational Bayesian inference based on its model.

And we can kind of get into the maths of that a little bit, of where that model comes from in the first place.


SPEAKER_01:
Might not be quite what I think we're driving at, but one thing I would wonder in terms of saying, no, you don't need...

um you know things like uh active learning to be like intel to you don't need to like invoke things like extended mind concepts you don't need to invoke things like niche construction but like in theory like you could do everything just from like uh

A smart enough Bayesian observer, I guess, would that be like the complete class theorem is like, well, yes, almost has to be the case, but that in theory, you could do it, that the inactivist elements that are being appealed to

Like if you were going like in theory, if you want to like build like a, like an AGI or something, uh, you wouldn't need to, but then I guess the question is like, if that in theory, though, like in theory, like a three layer neural network can compute anything, right?

It just might have to be so big.

It doesn't fit in like the universe.

And so it's like, if that in theory can't become in practice,

given available compute available to systems we would feasibly be able to create, that it becomes, I think, a little bit moot, although still interesting, about that case of, is it a matter of in principle or in practice?


SPEAKER_00:
Yeah, it's where philosophy has its limits, perhaps, where conceivability arguments have their limits.

A question that popped up into my mind is,

bootstrapping up intelligent or, you know, kind of in vitro intelligence.

I think one question I've always had is,

the priors that are encoded in a genitive model kind of make sense in this normatively viable sense.

So people just think of homeostasis.

We have these kinds of prior expectations about the states that we expect to be in and we'll act accordingly to confirm that model.

I think people might have a bit of a difficulty applying the same logic to perceptual inference.

So perceptual inference, you know, this idea that basically you're inverting Bayes, you are trying to derive the state from the observation.

I guess the question that I have is if that's a sort of P of X given Y, your probability of the state given the observation, obviously that's done

through some form of the variational bays, people might be asking, well, where does the P of X comes from?

Where does your prior of states before observations, I think what might be the detensor in POMDPs, where does that come from?

Is that encoded in the phenotype in the same way that homeostatic imperatives might be?


SPEAKER_02:
Hmm.


SPEAKER_00:
Or is it the, the D matrix or the, like, you know, I think it's the, yeah, I think it's the D matrix.


SPEAKER_01:
Again, I'm not a computationist, but your specific initialization within the environment and like getting the ball rolling.

Yes, exactly.

Exactly.

So it's like,

It seems like we know that without the inductive biases, none of it works.

The structural learning is just impossible.

Without the evolutionary priors, without some sort of intelligent initialization, I guess the place where I tend to have a heterodox view

And it's like, well, I grant we need something like core knowledge.

We need, basically, those are our priors to lean on.

I tend to think that natural selection had fat fingers when it came to doing the design, both in terms of potential complexity mismatches between inherited information and then what comes afterwards, but also due to not just in

People will sometimes refer to the difference in complexity between the genome and the connectome, for instance.

But obviously, the genome, the epigenome, and there's a lot more inheritance in that, just in the cell.

There's a lot of heritable elements that go on.

But even then, there does seem to be some difference.

You've squeezed through the bottleneck of an ovum,

And so from this one cell, you've reconstituted the rest in this kind of like auto-encoding, like you get to pass through a bottleneck here.

And somehow, but from this, you're now going to reconstitute a network of functional relations and effective connections, like a full brain's connectome.

And is there enough in there to specify things the way you might need to?

Um, the way I tend to like, kind of think about it as like, so one heuristic is, um, you know, the more, so like what, um, kind of knowledge might, what might be needs, what might be the nature of the representation or just the instantiation of the algebra, then the more complex it is, the less likely it is that that is in a more direct sense, uh, uh, specified.

Yeah.

So it's like, yeah.

If we're talking about, for instance, you can think of, there's a prior encoded, for instance, in the frog brain of the superior colliculus of, potentially, based on sensitivities to luminance, it might help people zoom in on eyes, potentially.

That could be an example of something.

or the priors about where you expect light to be coming from in general, and this helps to make things trackable.

But then let's say you're talking about some of good old-fashioned evolutionary psychology, like at the other extreme, like a cheater detection module.

well, how the heck would you do that, right?

Yeah, yeah, yeah.

So it's like how likely is it that you could basically, in this learning curriculum, have these lessons occur and have this knowledge be acquired early enough, and the simpler it is, the more likely it could be there early, that there's a meaningful degree of canalization that is actually part of natural selection.

Right, right, right.

In general, the...

Another claim I've been making is that in order to pull this off, a lot of it was indirect, even for a lot of the core knowledge people will appeal to, that you basically just needed to create a tractable learning curriculum to get there.

And what natural selection was primarily doing was sculpting learning curricula.

using the body and its positioning as a large source of leverage on this to help reliably acquire the knowledge you need.

But it's still though acquired.

And how much the adaptation is able to do that would be the simpler it is, the more likely you could meaningfully make that a canalization pathway.


SPEAKER_00:
Yeah.

Yeah.

That that's awesome.

That's a, that's a great way of looking at it.

It's funny.

I, my undergrad was in linguistics, um, and linguistics was the, was the hotbed for all of this stuff.

You know, I mean, Chomsky really, um, Chomsky and Chomsky Darwin's Darwin problem.

I mean, this is like what he was talking about in the nineties and he had to sort of pare down what universal grammar was because the big question was, okay, you can account for, you know, perhaps principles and parameters can account for the complexity.

and creativity of language learning, but how the hell are these hundreds of parameters going to be encoded in the genome?


SPEAKER_01:
In the versions of Chomsky and thinking where he's going minimalist, talking about something like... Yeah, recursion, yeah.

But then if it's just something like merge, it's like, well, sure, that seems very plausible, right?

Right, right, right.

Even quickly in evolution, the ways that's been suggested, and part of what corresponds to these phase transitions we see where all of a sudden new orders are coming on pretty compressed intervals.

Yeah.

But, but yeah, but if you're going to like, you know, at the other limit, like things like, I guess like, uh, I don't know, Pinkerian, like, so then it's like, Oh, I, that I'm not sure biology can do that.


SPEAKER_00:
Well, I think he may, I think he made that concession.

Um, Chomsky at least, I'm not sure about Steven Pinker, but Chomsky certainly does.

And as you say, as the minimus program with merge, um,

But yeah, I think a lot of linguists might argue that he's kind of abandoned that nativist project.

But anyway, we need not go in there.

I'll try and get him on the pod, actually.

Sticking on sort of

evolution my background is not in evolutionary biology or psychology so i'm super keen to learn um again just to take a quote of yours um you say much of the functional significance of specific connections in complex neural networks may be inherently difficult to predict due to the sensitivity of brackets chaotic self-organizing systems to initial conditions so when i hear that

I think, sure, like it certainly makes sense in terms of initial volatility, probably having more of an effect on self-organization than once you have a kind of robust phenotype.

But why, therefore, is there a convergence within a species, a phenotype to kind of a homogeneity if there is this kind of vulnerability to chaos?


SPEAKER_01:
It seems like a good amount of it.

I mean, that a good, you know, to get, so you're having a system which has, that's massively recurrent in terms of like, it's like in the system as it develops, it feeds back on itself.

And then that influences how it feeds back on itself and that influences.

And so there's this potential for amplifications to take you

in a lot of different directions, but natural selection doesn't want you to go in any given direction.

It wants that homogeneity.

It wants you to be like well fit to be, you know, to have high fitness.

It wants you to be fit to your, the niches you're likely to be encountering and to be able to, you know, survive and,

proliferate your forms in those circumstances.

And so, you know, you don't want to be just like open-ended.

You want that homogeneity.

But the process, because it feeds back on the self, will be, it should have this potential for astronomical bifurcation.

So how do you like rein it in?

You know, there seems like

And so, you know, you could just say like, you know, well, that's what the inductive biases are.

And so, you know, let there be inductive biases and it was good.

Right.

But well, which ones and how, and so I wonder the extent to which like a choke points for, um, coordination among sub elements of the system.

such as, for instance, any kind of place you could identify something like a bow tie motif, any place where you can get something like a large sale convergence divergence, which in general you would expect because you need small worldness for the sake of just efficiently getting a system to be integrated or to have a system be integrated at all.

You want to be able to

have the different components function together.

But if everything's connected to everything, that's both chaos and it's very inefficient.

So the idea of these places where things from broad extents will pass through and then providing basically an opportunity for enslavement.

Some of this could just be network motifs.

You look at, for instance, convergence onto hub structures that have high centrality, but also things like if you take the value signals, things like dopamine or serotonin, and you have those also have the conditions of their release correspond to organism scale events.

then that could help basically give coordination to the overall system in reliable ways for this task of helping the organism make it through the world, helping the system to function.

So it's like these codependencies and choke points, these places where you'll get functional convergence,

I suspect that's important for keeping that divergence from happening too much, this integration into organismic significance with respect to cybernetic control of the agent pursuing his goals.

And if that basically, by virtue of whether we're talking about value signals that would then shape connections,

or the structure of the architecture itself, if that is positioned such that the whole system can be so enslaved, that should basically help these bifurcations in a way be not bugs, but features.

and that it's certainly sources of solenoidal flow and explorations and engaging local pockets of high-temperature search, but then you rein it back in for staying on top of the action-perception cycle.

To come back to consciousness, for me, it's basically iterative state estimation

with the goal being basically I want to know a rough and ready estimate of the relationship between the system and the world generated quickly enough that I can meaningly inform and be informed by action perception cycles on the time scale of their formation.

And so I can nuance that engagement, provide some extra skillful control and surfing uncertainty.

So it's like

If the primary task of the system is this inactive coupling, I feel like that helps to tame and harness chaos rather than having a thing bifurcate in all the hyper-astronomical number of dimensions it could go.


SPEAKER_00:
Cool.

Yeah.

Yeah.

There's a lot that, I mean, yeah, let's, uh, let's do the consciousness thing.

Um, I was going to jump psychedelics, but why don't we start even more fundamental consciousness?

Uh, anyone who's watched the first five episodes or four episodes knows that I love consciousness.

Uh, it was kind of my foray into all of this.

So what you've given me there is a function of consciousness.

It's guiding action perception loops.

It's, it's, it's kind of a likelihood mapping state estimation.

Okay, but as you can imagine, the follow-up question is going to be why does it come with its phenomenal characteristics?

Is there something that's intrinsic?

Is there something that's adaptive to those phenomenal characteristics which facilitate, improve, augment the function that you just laid out?


SPEAKER_01:
I think, you know, people could still, you know, like, you know, uh,

Why can't these functions all take place in the dark?

Why must they feel like anything at all?

I don't think that concern is removed.

I think it loses some of its force if the nature of the data structure is considered as being specifically the generation of a visuospatial and somatospatial field of experience

precision weighted or having like with biases rather like different areas of salience and emphasis based on organismic need and like if you're basically taking like basically the the the thing you are estimating is the sensorium itself

It's sort of like, well, it feels like something because like the emphasis on the feels, like what the data structure is is specifically an inversion of a generative model over the sensorium of an embodied embedded agent.

So that's actually what the process is specifically doing.

Now you can still say, well, why couldn't you do the state estimation of the system in the world in the dark?

Exactly.

You know, I think it's that objection, though.

So the claim is that that objection holds more for theories of consciousness that forget we have bodies.

So you could still levy it, but I think it's like slightly addressed by making the primary explanandum the appearance of a world to a lived body.

If that is the primary explanatum and you're specifically saying, how might dynamics compute that?

Then I think it takes that on a little bit more, the why should there be something it feels like?

Because what you're specifically trying to explain is the feels itself.


SPEAKER_00:
Right.

They sound to me quite convergent with Mark Soames' sort of affects driven account of qualia.

this being that sort of these fundamental effective states are sort of guides in a way to allostatic behavior.

So whether that's the resolution of uncertainty,

um information gain um testing model parameters or actually just minimizing variational free energy see that for me was one of the first functional explanations of consciousness that really made me think oh that's that's kind of viable because i can't conceive of a feeling without it being felt um and so what i've been looking for is these kind of um

it's almost like a synthetic a priori of consciousness.

It's almost like a transcendental argument for consciousness.

Does anything like circle back on itself so as to make consciousness a prerequisite for the function?

And I think where you and Mark are converging here is quite promising, which is that now someone like David, what, someone like 1995 David Chalmers might go, well, you could just have like an offline signal that says things are uncertain and let's resolve that uncertainty.

Granted,

But then I take quite seriously this older phenomenological Heideggerian idea that we're beings that take a stance on our own existence.

And that's got to be felt to some degree.

So I'm wondering what you think of that spiel and perhaps where there's points of convergence with Marx's theories.


SPEAKER_01:
I'd say very strong points of convergence, but also divergence.

The convergence is like he's bringing in life-mind continuity.

He's bringing in the necessary interestedness of the system and also the primary nature of

of affect and of saying like, and like you're saying like this synthetic opera, like, like what do we need to even co coherently conceive of this thing where like, what's foundational or like, if you were to doubt it, the whole like game falls apart.

Exactly.

Yeah.

So unless you have, like, unless we get the fields in there, we're not getting anywhere.

And unless we get like the, um, you know, and so the, the, I guess the thing I would suggest is,

as a point of divergence would be, I wonder if the specific systems, so I guess like for me, I don't necessarily take unconscious feelings to be an oxymoron, but, you know, so we can use words differently, but sometimes I'll think of like one way of thinking of like emotions and feelings, almost like a very abstract action perception cycle

Whereas the emotions are the global state changes.

I think by the time you get to that level of abstraction, the difference between action and perception falls apart.

But in a way though, the change in organismic mode to be adaptive for a particular class of situations

Whatever that is, that seems to be roughly something like emotion would correspond to this and where the organismic mode could extend beyond the organism in terms of the emotion and just like contained within it.

But the feeling part potentially being some sort of inference on top of that process, some sort of tracking of that.

Now, we can use words in any way, but like I would personally, so that's the way I think of it and the way I describe thinking of it in that entropy paper.

And then I wonder whether we can have both unconscious and conscious feelings and emotions.

So like a level where like, you know, we go back down to the individual cell and the cell is like changing into like a sporulated mode.

And maybe that's like it becoming afraid or something.

Or it like extends a pillus to like exchange a chromosome with someone else.

You know, or rather that chromosome, a chromatid.

And that's like maybe like a lust mode.

Or like it releases, you know, exotoxins.

Or that's like an aggression mode or something, like a rage mode.

And so I like the idea of the work of Damasio, who Mark engaged with in beautiful ways.

I love this idea.

I think it's essential for understanding the actual cybernetic significance of feelings and emotions to actually be coherent about them.

to actually talk about life-mind continuity and to recognize this is an older story than even nervous systems in terms of the harmonics or the eigenmodes of the organism to be adaptive, having those to give them an overall coherent shape.

But for the specific systems that Mark talks about, I wonder whether they have what it takes

to do the kind of like re-presentation game, whether they're potentially doing their functioning.

So he'll emphasize like the pericardial ductal gray and as being this

integration around organismic need and the way that affects in order for these eigenmode shifts to be coherent so that you're not eating and doing care at the same time.

That would be a bad idea in a lot of circumstances.

You don't want mothers to eat their pups.

You don't want this

picking and the, I think, I don't know if he says color coding, but this like categorical breakdown.

Yes.

I'm totally with him functionally, but it still seems like those could happen in the dark.

Right.

And so the thing I'm wondering is in order for them to be given something like phenomenality that we experienced with the conscious feelings, I'm wondering whether that requires something like, um,

basically a re-representation into cortical circuits.

And maybe even within somatospatial and visuospatial modalities.

So I make what's considered to be a bizarre claim,

that those might actually be all we have and all other modalities are basically kind of synesthetically cross-mapped into those to be given spatial and temporal spatial coherence so that they actually can be modeled and you can do this like state estimation.

So the idea is like your interoceptive states might actually be to be experienced have to be spatialized as a kind of like

texture or as a kind of like, I feel I have to temporalize and spatialize that information.

And maybe part of the way you do it is to enfold them into another modality as part of the inference.

So, but the, yes, I guess the difference with Mark is I'm wondering whether his account is like,

like right on on the functional level, but the systems though, that would actually, but still though, the systems he's emphasizing would be necessary but not sufficient conditions.

In order to obtain sufficiency, they need to basically enslave cortical circuits and that those might actually be the constitutive causal, the constitutive realizers.

of experience potentially by virtue of the fact that like and again we i guess we get to like things like small worldness um networks that are basically co-located enough that they can converge on attractors and achieve coherence on the right time scale the idea of like if you're like way so the idea is like if you're way far away from like let's say like some sort of rhythmic attractor

is established that's calculating something like your sensorium or is entailing something like the inversion of your sensorium, on the timescales at which that sensorium is inverted, there might be an in and an out in terms of who is able to get their message in at a time.

And it's possible that the systems he's identifying could be on the outside of it in terms of the timescales at which that causal closure occurs while still being completely necessary for their functioning.

I just don't think we know.

And so the evidence is, you know, he would then push back and then say like, you know, oh, well, um, the, uh, let's see, uh, well, no, you know, I, I lesioned the insula and the emotions are still there.

So there's your, and it's like, yes.

Um, but, uh,

I guess in a way, you might say that somewhat supports that quasi-synesthetics account I just said, but I find the lines of evidence that are cited to be notable, but none of them are quite convincing to me.

So for instance,

uh, like hydrocephalic, uh, children.

Like, you know, they're still showing these rich emotive displays, but the issue is though, uh, we don't know.

Yeah.

Like it could be unconscious emotional.

Yeah.

We can't ask them.

We don't know what it's like from the inside.

Or then you might point to like, um, like decorticate rodents showing like, you know, rich, like, you know, adaptive emotional, uh, responses and, and sophisticated behaviors.

But once again, we don't know.

Yeah.

Or you might like drop an electrode and then stimulate these subcortical areas and then you get experience and the person reports to them.

But then the problem is, well, the cortex is intact then.

And so how do you know if when you drop that electrode, like you stimulate the hypothalamus and then you got some sort of rage response or a lust response,

Was it that that was the realizer?

Or is it, as I'm suggesting, that that was basically part of, you know, it was causally important for the whole thing to work, but not necessarily constitutive of the process that computes or realizes the quails.

This is cool.

This is cool.


SPEAKER_00:
Yeah, I feel like there are two things going on, and I'd like to sort of see if we can converge them.

So one is a kind of structural functional description, which is augmenting or just providing color to Mark's view, which is that we need these kind of recursive loops back to the cortex.

It needs to enslave, you know, these subcortical structures need to enslave the cortex.

Now, someone listening might go, but that's just a further description.

functional structural anatomical explanation on the other hand you invoke kind of proto back to the homunculi these kind of proto-conscious agents we've got like whether that's a cell a cluster of cells and so on and you've spoken as well about how you know one of your your account of consciousness you know can be cast as a convergence of

active inference, and integrated information theory.

Integrated information theory got some, well, it got some bad press earlier this year for being pseudoscience.

For those listening just on audio, I am doing speech marks.

But one of the claims was that it was pandering in some sense to panpsychism.

And perhaps an acute listener might be thinking, oh, Adam is maybe pandering a touch to panpsychism with his idea of lustful neurons.

Where do your sympathies lie if we take this sort of broader philosophical position?

Where do your sympathies lie with panpsychism and let's just say more kind of, I think they're called conscious realist positions such as that of Donald Hoffman, for example?


SPEAKER_01:
I'll regret saying this, but I think you could call me a panpsychist of sorts still in that of the sense of anything that somehow managed to think, and coming back to the good regulator theorem, on some level had to entail some sort of modeling information, whether it was the system and its interaction with the environment was the model or is a model that within it has models, but has to have some sort of tracking or predictive information

that allows it to basically resist the most temporarily, defy the second law while serving in everything it does.

But basically that, you know, you getting all mixed up and becoming maximally probable, a maximum entry distribution.

Like, how'd you do that?

You did something to do that.

Sort of intelligence, some sort of thing like Amali, some sort of predictive information had to have been there

For you to pull off something a little bit like Maxwell Demon-esque, you know, to do that.

And so, in that sense, I'd say I'm a pan-psychist in that, like, anytime we're pointing to things, anytime there's attractors, you might want to say there's something mind-like going on, something a little bit intelligent.

But the...

And you might even want to say some psychological kinds.

We were talking about the individual cells, rage or lust.

Even those might be good ways of thinking about them in terms of describing their cybernetic significance.

It's a coherent global change of state with a certain semantics that's linked to this modeling.

And so if you think of mind as modeling,

And then as modeling with interest in a value-laden way, you might call that sentience then.

But I guess I want to reserve this word consciousness for the, it feels like something.

And there's something that it feels like from the inside to be that system.

And so all these systems would have a kind of dual aspect part to them because they would entail an information geometry.

and so you can say it's like well you know maybe everything that exists it's just like that's the way of describing the dual aspect nature of them um i think you can make a case for that but i still want though like um basically um okay so in and so in greater world modeling theory the the thing i attempted

was to take the major theories, specifically focusing on integrated information theory and the global workspace theory, and then basically use, you could say, probability theory or machine learning or the free energy principle with this idea of the system modeling its environment probabilistically as now providing the semantics and removing the question begging from these theories in terms of, or some of it, of why there should be something that it's like to be a complex of integrated information.

or to have fame in the brain and to be within a global workspace.

And so why?

Well, if what that global workspace is doing is it's something like a very efficient architecture for some auto-encoding hierarchy, if it's like an arena for Bayesian model selection allowing for this iterative state estimation, well, then the questions are somewhat less bagged.

Or if integrated information theory is describing

The nature of networks that can do interesting forms of compute, it's like, okay.

Necessary conditions, likely this integrated information theory, they have these axioms that they look at that apply purportedly to all conscious experiences.

And then they try to identify these, they postulate mechanisms that could realize them.

And then the idea is if you start out going from these axioms that Kersh has all experience, you then create a precise and specific mapping to particular mechanisms that would allow for their realization.

Now you can say this system's conscious and that one isn't.

And maybe even this system is conscious in that way and not that way.

And I think it's really promising, but the issue I take is basically losing the explanandum of

our sensorium, our sense world, our embodied experience.

And so if what a complex of integrated information is doing is it's basically describing a system set up for a certain type of dynamics within it that could enable a certain type of message passing and inference and belief propagation and inference.

And specifically with the thing being entailed by such a system would be the

efficient inversion of a generative model over the sensorium of an body about an agent, now we're getting somewhere.

So the idea is saying, okay, so I guess I'm sympathetic to both sides in viewing integrated information theory as having some elements which are unsatisfactory.

But, you know, I don't think it was particularly, I don't think what happened was particularly helpful in terms of neuroscience and, you know,

for a variety of reasons.

So the basic approach is this.

What if you take the existing theories, the major ones, cross-reference their claims, look for points of overlap, and try to use basically degree of convergence and the forms of convergence and the coherence of those stories to adjudicate among different claims?

And so that was the basic method.

And so you could think of, for instance, integrated information theory will talk about potentially there's a posterior hot zone.

as the substrate of consciousness.

And, you know, for instance, I say that sounds about right.

That for instance, like, you know, if basically the posterior, if you take these different sensory hierarchies all coming together into one multimodal hierarchy, and if you can get basically across that system, its ability to loop back on itself in a very powerful way, in a very, you know, both integrated but also differentiated way,

then you could think of that as basically that that could entail the inversion of a generative model over the sensorium of an embodied by the agent.

Maybe that's what's going on.

You could also potentially think of this complex of information that has both integration where the network properties are set up to facilitate both integration and differentiation.

That actually has a lot of correspondences to workspaces, which balance integrated segregated functioning.

And so the ideas like that post-Seer hot zone could be thought of as a fairly global workspace.

And with devils in details of exactly the kind of workspace it is.

And with me having some specific proposals.

So then like, for instance, OK, so the workspace theory, they might come in with the claim like, no, no, you need the front of the brain.

And so the question is, well, what are we talking about exactly?

Are we talking about

phenomenal consciousness, like the actual generation of your experiences from moment to moment.

Or are we talking about your knowledge of experience, your knowledge of your experience, your awareness of your ability to report on them and contextualize it in different ways?

Well, then you're probably right.

The Bobo workspace theory is probably right.

You need to get the frontal lobe in the mix to do that.

Although at that point, though, by the time you're talking about things like that, you might even need more than the frontal lobe.

We actually might be in an extended mind account in terms of what actually goes in to be self-reflective.

We use the environment to offload memory.

The global workspace or play space might not even be Skullbound.

But still, the

The approach I took was basically to say that the different theories were bringing important contributions that all these brilliant people, these are all brilliant people who've given a lot of thought and have something important to say.

Then the question is, are they maybe using words differently?

In that debate earlier between integrated information theory and the global workspace theory, you had this recent adversarial collaboration signal.

Yeah.

But it's not clear they were using the word consciousness in the same way.

Integrated information theory is talking about experience and phenomenality.

Global workspace theory, sometimes it's like illusionist.

Sometimes it's more of like a higher order thought type theory.

And they're oftentimes, not necessarily, but it's usually they're talking about, you'd say like conscious access as opposed to phenomenal consciousness.

So then the idea is that if you try to be more like, what are the precise claims that people are making?

And you dig into them, a lot of the conflict might just be people not communicating enough.

and say like oh i meant this by that term and you meant that oh and instead there'd be just like one way we use words it might be that like the different ways we were using words had different trade-offs and maybe like to come together we have to like add qualifiers so instead of like we try to say this one word means this one thing maybe we use like um we need to use like two or three words to specify which world we're in and what we're talking what what our reference are

And then the claim I make is that once you do that, a good amount of the conflict actually is not as much as it seems like it needs to be.

Like you're actually significantly, like these different theories are actually to an important degree and a useful degree talking about different things.


SPEAKER_00:
Right.

Right.

Yeah.

Well, you know, maybe there's a psychological account of the fact that scientists like, you know, they might pretend that they believe in collaborative thinking.

work but there is there's a tendency or an inclination towards adversarial boundaries which are often incredibly constraining so no it's a good point and I think it's a good point as well about

much language really shapes again i don't mean this in some sapir wolf deterministic way but shapes the way that we view these um these models the way we view these debates i mean i think the most i think for me it comes back to to what you're talking about like right at the beginning that i could look at a rock and say well there's something kind of intelligent going on there it's tracking something you know it's doing some kind of variational bayesian inference

I think the two most important words for someone coming into the free energy principle depends on the definition of free energy principle you like.

But my two favorite are looks like.

So anything that has a Markov blanket and a non-equilibrium steady state attractor will look like it's conducting Bayesian inference.

And the question of

what it is doing the process theory really gets opened up once you go oh the free energy principle is just you know it might well just be a descriptive tool and then we talk about active inference predictive processing variational message passing but i think this this looks like notion is often um forgotten and it's important to keep it in the back of our mind that

yes there is something quite miraculous about the coherence of a stone um but i guess every theory has its miracles um and the frailty principle is not it's it's not devoid of its axioms do you think that's a kind of reasonable thing to say


SPEAKER_01:
I think so.

In general, what we're trying to do is minimize the number of deus ex machina, as we need to call it, and the number of miracles.

You mentioned there were synthetic operatory categories.

You need something to build with.

Also, in terms of what we're talking about with evolutionary priors and inductive biases, you need to start somewhere.

Something must be granted.

you know but but like but let's try to like do the most we can with the least and so um and but but still those things that you um are granted you know in a way like there's a sense in which like you know they might be like they're the preconditions for proceeding at all and those are the miracles we need to go on and so there's like we end up like uh

It's like for the case of like, yeah, like a rock and you get to say like, you know, yeah, it looks, yeah, I had a section I put into like the, like original and, and, and left it in there.

Maybe unfortunately, like the, like the, like the IWMT paper.

And I, I felt crazy writing it, but you know, and I think like, if I like emphasize this, like looks as if like, it feels less crazy and then say the rock is engaging in Bayesian inference to exist, you know?

I guess you could say there's a sense in which that's how it is.

At that point, I guess you're almost in a quasi-tautology.

Here's the phase-space description of the rock.

I guess you could say if you keep looking at it, well, I guess the rock, though, it might be we need something like

It might not work for the rock.

You need something where that density of the thing, that you can point to it, and there's a combination of the solenoidal flow and gradient flow where the thing is picking itself back together.

Like a drop of oil.

Yeah, like a drop of oil that grabs itself.

Yeah, that, yeah.

So once you do that, isn't that kind of like, I guess that's Carl's 2019 paper.

Then it's like a sense of like, you can say like, well, that actually is Bayesian inference.

And there's like where you expect to find it.

There's a thing like as a probability distribution.

And then if you just look at its action, it's doing Bayesian inference.

And then either like, well, is that a tautology?

Maybe.

But it's a damn interesting tautology.

Yeah.


SPEAKER_00:
Yeah, yeah, no, it's, uh, I remember hearing Carl first on Lex Friedman's podcast talking about a drop of oil, kind of my first proper exposure to free energy.

And I just, I just couldn't think, I didn't believe that drops of oil or rocks or molecules could be so interesting.

And you're right, science, I don't know who said it, but science is about making the familiar unfamiliar.

And we're certainly making rocks and drops of oil pretty unfamiliar when we're talking about them conducting variational Bayesian inference.


SPEAKER_01:
There's somebody who might be interesting to talk to.

He wrote a paper on the world as neural network.

And so I think he would potentially get to this issue of...

Is there just, like, a way in which, like, you could just make, like, the ontological claim, like, the rock is... Like, he would do, I think, a good job of, like, making a case for that potential.


SPEAKER_00:
Okay, cool.

I'll check out the paper.

I mean, yeah, I mean, for me, this... The question that I literally started this podcast with still stands, which is if we take the drop of oil...

it's it's it's kind of yes can be seen as calculating a posterior um

But what does that mean?

Like, what does that mean?

Like, what is doing the calculation and what's it doing a, like, what's the P of itself given its environment is just really high.

I mean, once you sort of break that down, it just becomes, it seems to me to just return back to a descriptive account.

Yeah.

rather than a process theory of what the drop of oil is actually doing.

So I think where a lot of active influence confusion comes from is that we struggle conceptually to get away from a Cartesian ego model when we're thinking about how we are and how the world is.

So it's, it's tempting perhaps to think that there's a little homunculus within the drop of oil, grabbing itself together and maximizing model evidence for itself.

But that was, by the way, I'm not saying that either, but it's, um, it might be tempting for some let's, um, let's get psychedelics because you're at Johns Hopkins, which is.

the kind of place to be in terms of psychedelic research i think a useful place to start not only for myself but for our audience is people might have a sense of the history of psychedelics in science um and the long history and the taboo and the fact that now these experimental studies are taking place and the taboo is lifting

Perhaps you could kind of give a brief history, if possible, of the history of psychedelics in science.

You don't have to go back to shamanic cultures, but if you feel so inclined, I shan't stop you.


SPEAKER_01:
I mean, that actually is a

I'm working on a paper right now of the deep history of psychedelics, going both back to shamanic cultures but before in terms of the evolution of the signaling systems that they appear to primarily act upon, in particular the 5-HT2A serotonin receptors.

Psilocybin is an agonist of that receptor.

That particular receptor class.

There's a paper I just recently revised and resubmitted called ALBIS, or Altered Beliefs Under Psychedelics, which basically it's providing, I guess you might say, a heterodox account of psychedelics with an active inference.

I read the preprint, so I'm familiar.

Yeah.

So I guess we'll get to that in a bit, but that's where the focus has been.

But the current paper would be like, why is it that we have psychedelic experiences?

You might say, maybe in a deflationary sense, you could say like Pinker would talk about music is cognitive cheesecake.

If you try to look for an adaptive story about music, you could try, but it's just like, no, there isn't really one that's that meaningful.

The adaptive story of cheesecake is like, it's a super stimulus that's created because of this, this, and the other.

But there is no evolutionary account of cheesecake.

It's a latecomer to the scene.

And so it's a deflationary account of music would be like, there's no specific music adaptations.

It's just like a super stimulus we create for ourselves.

you know, because of other things that we need and other aspects of our cognition.

And so with psychedelics, you could say like, you know, these drugs just happen to be like, you know, a super stimulus that's like created, you know, maybe by plants to defend themselves against predators in terms of, you know, you don't want to quite, you know, you have to, you know,

either repel, and so maybe breaking the good regulation, like making the thing do anomalous inference could be a good way of repelling your predators.

Or you might want to potentially entice in terms of there's some symbioses that exist in terms of things like that.

Was it reindeer?

I don't know if this has been established, but like, you know, possibly like by consuming things like, was it like, was it lichen?

I forget what it is, but like fungi, like it might like help them to be more like exploratory in certain parts of their like seasonal cycle.

And so then there's like a symbiotic relationship and you're actually enticing the organism to come in.

But actually, that's a very live question of the deep history of psychedelics.

And the place I'm trying to go in this upcoming paper is to argue that it seems like the receptor system itself might have evolved, I'm claiming, actually in a way.

So the count of psychedelics

in the free energy principle that I think that's most well known would be called the Rebus model.

Relaxed beliefs under psychedelics.

And the idea being that psychedelics are relaxing your Bayesian priors.

And so with your prior expectations relaxed, you are now free to think different thoughts and be updated by the world, experience it more profoundly, and be changed by it more profoundly.

And so I've been trying to nuance that account and saying that that might be...

part of what happens as part of like very high degrees of 5H2A agonism, and that you do get something like that.

But that might not be the cybernetic significance of the 5H2A system as a control parameter.

In many ways, it might actually be exactly the opposite.

They first evolved with a gene duplication event around the Cambrian explosion, around with the advent of jawed fishes.

One of the speculations I make is actually, and this might be predator-prey arms races, where someone can basically, if you can specifically bite, then this now adds fuel to...

a certain fire of like, I can now go up and precisely swim and bite and kill.

And now you have an interest in being able to have that strong prediction that you use to basically enslave your inaction and achieve that goal.

And the stronger you can get a prediction, the more, you know, potentially within limits, the more reliably you'll converge on that goal as opposed to doing something else.

But then you might also have an interest on the side of prey of not being the person bitten.

And so this idea of like turbocharging the organism, doubling down on the priors potentially as a way of allowing for specific goal pursuit, that might've been the original story.

But where does this like rebus account come in?

One of the speculations I'm making, it's a paper I'm writing in collaboration with Sue Carter, who studies oxytocin mechanisms, and there's a follow-up paper I'm writing before the other one is published with Matt Johnson, but is that actually orgasm and birthing might have been the original psychedelic experiences.

And that actually, so you're basically relaxing the priors about the bounds of yourself and having greatly elevated plasticity and capacity for updating.

Why would you want something like this?

Those would be two cases where you'd want it, whether it's basically allowing a mother to care for the child long enough to help it to get past these early milestones, and also allowing potentially mating pairs to stay together long enough to help these hungry children to the next generation.


SPEAKER_00:
shit okay let's get into that then so what would the the kind so there's some coupling going on here in terms of this kind of turbo charging it's psych it's in a sense it's kind of psychologically adaptive to have really relaxed belief over yourself over kind of your self-model maybe even your autobiographical self-model um so as to facilitate um the advent of

another person into your life right so like people just qualitatively talk about how they now feel like this child is their purpose they're kind of secondary to this child in their life so what's the kind of what's the causal pathway and what's the chronology in this is it is it a genetic adaptation that um

occurs kind of simultaneously with like modern childbirth is or whatever that looks like or is it um does it predate it and then get sort of exacted by um birthing start yeah birthing or does it come later down the line i don't know actually how you would examine that but what are you kind of claiming in that regard


SPEAKER_01:
So the specific mechanistic pathways that were catalyzed in which ways, we got no idea.

So for instance, there's all sorts of things that could contribute, like for instance,

There seems to be, for instance, the 2A receptor.

In general, it's actually fairly insensitive relative to something like the 1A receptor.

But if you take it and expose it to reduced blood pH or elevated acidity through something like hyperventilation or things like carbon dioxide or lactic acid accumulating,

then it gets potentiated.

And so, for instance, during sexual activity, during birth, there will be a lot of heavy breathing over an extended period.

And is that actually an accumulation of carbon dioxide?

And actually, that's part of a mechanism of potentiating these receptors.

Maybe.

We have no idea.

Could it involve something like endogenous DMT?

Maybe.

We have no idea.

Could it involve, as Sue is arguing, oxytocin and vasopressin in different combinations?

Quite possibly.

But we're just beginning that now in terms of the specific pathways.

But in terms of when this might have occurred and some more things that could have been important...

I'm wondering if there were a couple waves of strong selection, one probably with the advent of mammalian reproduction and mammalian care.

So once you're now having to, like we were going to earlier, don't eat your child, care for it.

And you've seen a lot of rodent species, it's actually a little bit tenuous.

That process, right?

Like the runt of the litter often gets eaten.

You're not that far from the atavistic state of kind of like, eh.

So to get this interest, I think Pat Churchland will actually talk about an extension of self-grooming.

So for instance, you can maybe think of actually relaxing body maps

and then making them plastic for a time on the occasion of birthing or like for instance like during nursing and then like basically if you then include um the pup into the body or your offspring your body maps like that could get an account like that off the ground

Or then once, for instance, to the degree you get parental investment, but this would then be like a mammalian story.

In any of those species, there might have been strong selection on these proto-psychedelic pathways.

And then for humans, it would be like all the things coming together in terms of having these big brains, extremely vulnerable, hungry offspring, which you have to care for for a long time.

Oftentimes also needing more than one because part of it also of the care is providing protection within the social hierarchy, teaching them things, two heads being better than one.

And so having the bonding of the parents for the child and the parents to each other, now the selection pressure might be really strong.

What was selected?

Something involving oxytocin, potentially, in connection with DMT, with other couples.

We got no idea.

But wow.

And then I guess the one more thing that could happen, not just in humans, but maybe particularly in humans,

It's our ability to, like, what is it?

Jonathan talks about, like, the hive mind switch.

like our ability to actually have collective effervescence and to come into a group, a sense of group identity for the sake of basically doing things according to fashion, including beating out other groups.

And so there seems to have been strong selection on that in the human case also.

And so the claim would be that these basically pressures for intersubjective coupling being particularly strong in humans might have been a source of why, for instance,

psychedelic experiences, we're probably not the only species to have them.

But the idea being that at least the reasons that we know that we are sensitive to them, some of that could be because of that history of selection, because of those challenges of bonding between mating pairs, between parents and children, and potentially between tribe.


SPEAKER_00:
Yeah, that is really...

um it brings two things to mind um one is i don't know whether you've ever heard of the obstetrical dilemma um which is basically this idea that when humans went from being quadrupedal to bipedal the hips of the mother narrowed and what was happening is that there was a lot of uh stillborn deaths a lot of childbirth deaths because the hips were narrowing but the size of the baby's head stayed the same so a lot of children were dying and

childbirth.

A lot of mothers are dying in childbirth.

And so there was an evolutionary trade-off between early birth and

bipediality and so what actually happens is that children start to get born younger pregnancy is reduced in time to permit the narrowness of the hips that allows for bipediality which in turn sets the stage for caregiving and the fact that a child can't just pop out of the womb like a gazelle and go running so that's the one thing that comes to mind I'm going to include that in the next paper

Or give me a shout out.

Um, and then the second, and then the second thing that makes me think of is maybe this care domain, this fundamental need to expand body models, self models could be this kind of consciousness, synthetic a priori we were looking at.

Maybe there's an adaptive pressure.

to feel this kind of selfless love, agape, whatever you want to call it towards your offspring.

So as you know, for evolutionary reasons, so that you are a caring altruistic caregiver.


SPEAKER_01:
That's I think potentially very important for like, so this

In the evolution of cognitive modernity, there seems to be a kind of like chicken egg story or a slight dilemma where, you know, so like Chomsky, like, you know, talks about language for the service of thought.

But like, and so I guess that he somewhat sidesteps his dilemma by saying like language is just useful for structuring thought right from the get-go.

But let's say you aren't quite thinking that way, and language is about communication at first, or you think you need that to get language use off the ground.

Well, then the question is, but if you need language use, who are you communicating to?

Something that could basically scaffold

So in terms of the elaboration of forms of consciousness and maybe even potentially the precision and the, I don't know if you'd say richness, but even consciousness, phenomenal consciousness in its qualities, its ability to represent precise things, it seems like in kind of

It seems like if there's a use to being able to feel your feelings in a way where you can reflect on them, in a way where they can meaningfully impact your behavior, if that is helping to basically provide some of the selection

for certain, I don't know if this thought works, but for certain complexifications of consciousness, that that could potentially help other places where you might have chicken egg problems.

Like it's a source of pre-adaptation.


SPEAKER_00:
I guess is what I'm wondering.

Yeah, exactly.

I think that's exactly the line I was kind of shooting down.

I mean, this is, yeah, wonderful, wonderful ideas.

I guess another question that comes to mind is when people think about psychedelics, they probably don't think about relaxed Bayesian priors.

They think about

tripping for want of a better word the thing about hallucinations visions auditory um hallucinations as well so in terms of the sort of adaptive self-organizational um yeah uh functional utility of psychedelics that all makes sense where on earth do uh the sort of uh magic dwarves or uh recurrent patterns or

whatever Terence McKenna was talking about.

What's going on there, and how does that complexify this story?


SPEAKER_01:
So before we get to machine elves, part of the heterodox psychological view, rather the heterodox active inference view on psychedelics, would be that potentially those types of phenomena as hallucinations or some forms of, you might say, psychotomimetic cognition, or like the

You know, the entertaining of a thought that you would not normally entertain.

You might think to be crazy under other circumstances, but that is there live in your mind that you can maybe think of.

In some ways, it seems to have like almost the shape of a schizophrenic delusion or like a proto psychotic delusion.

So, you could potentially argue for these as a relaxation of high-level constraining beliefs, allowing those to be free-form.

But you could also think of those as particularly strong priors also.

that you're imposing onto the world and not rather you're now saying, I think this is there, this is my expectation and I am not gonna let that be contradicted by sense data.

And so there's an interpretation also in terms of a strengthening of belief of those phenomena you mentioned.

And one of the points I'm trying to make in the paper is I don't think we know how to think about this.

It's probably some complex admixture of relaxed and strengthened beliefs, both directly and indirectly, in different combinations, where I'm trying to say that rather than ever saying psychedelics do X,

I want to replace that with this psychedelic, this particular compound at roughly this range of doses does this to this kind of person with these kinds of settings.

And the idea of saying that like, but the idea of like taking inspiration from Rebus is like relaxably speaking an essential feature in some ways and looking to adjusting of your priors and your mind is this like belief ecosystem as a fruitful way of like contextualizing psychedelic functions.

but then saying moving beyond relaxed beliefs, talking about both strengthened and relaxed in direct and indirect ways.

But to come along to DMT elves, that would be like an example of like, so you can say, you can maybe think of that in a relaxed belief story and that for instance, elves do not exist.

And now I've relaxed certain aspects of my ontology, and now I've made room for these imaginings to arrive in a vivid form because I relaxed beliefs at this high level of certain core schemas that tell me what I should expect in the world.

Now I've made room for psychedelic elves, for instance, or entities.

You could also tell a story, though, that these are actually kind of coming back to core knowledge.

Things like agenthood or agency are things like

but maybe not even core knowledge, like just early lessons in the learning curriculum and ongoing ones of just, we expect agents in the world because that's the primary thing we're encountering.

That's our primary niche is each other.

And so then basically for the beliefs, so like in a strengthened account, you could say, let's say you're strengthening your beliefs.

Maybe that you're getting a direct strengthening of these priors for agency detection.

Are they evolutionary priors?

Are they developmental priors?

We have no idea.

In my thinking, they tend to be more developmental, but it's a spectrum of how much evolution shaping went into them.


SPEAKER_00:
As our conversation earlier.

Um, yeah, also I, I stumbled across, uh, you saying just these words, which really caught my eye archetypes as core priors.

And I thought, oh, that's fantastic.

What a lovely way to put it.

I mean, okay.

So I, this is just, this is really, really cool.

Um, really exciting, I guess.

So, so just to piece together the scaffold together, the chronology, the causality, the phenomenology.

Let's just try and put it all back together.

So if the original psychedelic experience, let's say, was childbirth or orgasm, how does this end up... Is it just a coincidence that this ends up in plants?

And if it is...

is it informative that it was happening in childbirth or, um, orgasm, or is that just kind of a, as I was saying, like a coincidental feature of the activation of this receptor?

Um,

Because the argument that you said there was earlier, which is that it's a kind of defense mechanism or a kind of attractor towards symbiosis is quite convincing.

I guess we have to fold into all of this, the shamanic cultures, and then the kind of more modern therapeutic lens on psychedelics.

Is there a way of coalescing those seemingly disparate strands?


SPEAKER_01:
So for plants, there's the impact that these signaling molecules, these different ones, would have on the plant itself and then on the other systems that would interact with them.

So for instance, the 1A and the 2A receptors will tend to have different impacts on cytoskeleton dynamics.

And so let's say you want to do something like a phototaxis.

That actually, it seems, will involve some, if I'm remembering correctly, I should remember this precisely, but there might even be like, you can think of it like changing the cytoskeleton dynamics to allow for greater fluidity.

You can maybe think of that as like a kind of belief relaxation for morphogenetic inference of the plant.

So it's like, you can, you can think of the plant as like, you know, you know, doing a photo taxes and you say, no, I'm here now I'm there.

You know, maybe you think of that as like a kind of like, um, uh, updating for the plant itself.

And maybe that's even part, very speculatively, of why you fight it in something like a cactus, where that's actually kind of a harder thing because you're blockier and something like that.

But then the other aspect would be the defense.

Another reason you might have it in something like a cactus is because if you're in the middle of the desert and you're juicy, you're extra tasty.

There isn't a lot of game.

There aren't a lot of...

know contenders in town for things to eat there's actually plenty everywhere but still you're you're a target and you're stationary um by and large you know so then like you know the which predators were they targeting it's like like insects um you know oh what's happening to the belief dynamics in the insect and so you know at that level you know maybe you know it's largely a uh um

a rebus account of these 5C2A agonists for the insects, potentially in terms of changing their normal behavior.

I'm not sure how you would think of it there, but the idea of someone nibbles on you,

It might be good for them to go away, become more exploratory, and maybe even mate like crazy.

You actually see stuff like this in locusts.

They're colonized by hallucinogenic fungi, which can be part of their mating cycle and is part of this period of intense mating they undergo.

And so, you know, the question is like, why not just poison them?

You know, maybe it's just like, this was like the best poison you came up with.

It was good enough and it just did the job and it arrived by some means.

And just the form of poisoning is taking the model the organism has by which it is adaptive.

You relax that model, but that's not necessarily a good thing for that insect, especially, you know, with its body weight, you know, it's eating a lot of it.

And so the idea of that insect, if its models are really altered,

And if those models are trying to constrain all the different ways that system can bifurcate to be more homogenous as response in adaptive ways, you don't come out necessarily ahead by doing that adaptively.

And so that's just the way insects figured out or their plants figured out how to protect themselves.

And the point is the attack.

But maybe it's not even an attack.

Maybe it's like you want...

It's fine if you nibble on me, just don't nibble too much, but just go away.

And then if we have this nice relationship of you don't bother me too much,

you know, maybe I even like you to be around.

Maybe I even like that I facilitated your mating.

And I like that your genes are more prevalent than the next generation.

So yeah, I guess, and then coming to, you know, shamans.


SPEAKER_00:
Well, before, before you do just, I'm curious about what you think about this.

Cause just like add maybe a technical instance.

I'm curious about what you think from a rebus account in the, in this case.

Because you mentioned exploratory behavior there, or epistemic foraging, which I thought was really an interesting allusion.

Because in both cases you offered there, there's a move towards epistemic behavior, either whether it's mating, or go away in an aversive manner, or go away and, like the reindeer example, spread me around, basically, in a kind of weird way.

right yeah yeah well that's worse go forth right and what that screams to me is so it's just in in the sense of like the actual computational modeling in pom dp schemes is an emphasis over expected utility would be sort of high precision over your b and c schema um

and an E as well, your priors over action, your habits, basically.

And maybe what's happening here, again, it's a completely nascent thought that I haven't given much, obviously, fall to, is that you're relaxing your prior beliefs about the consequences of your action, thereby making every single possible action policy equal in terms of epistemic utility.

which means that you then do some sort of Janesian maximization of entropy, which makes the best, in terms of just the expected free energy formula, makes the best action policy that which maximizes information gain and or test model parameters.

So I'm wondering whether that speaks to you in terms of a kind of technical unpacking of what might be happening at a very low level here with insects and cacti.


SPEAKER_01:
It would fit well with changing migration patterns.

I think it would fit really well with that.

In terms of thinking of human use cases, it seems like it's a mixture.

For instance, sometimes specifically would be for...

you know, breaking out of some state you're caught in, like you go to the shaman and this is part of it.

But, but oftentimes it would be like with a very specific interest in mind, like, um, who someone cursed my cow, who is it?

You know, or, or like, but, or, or sometimes it would be like, um, uh, uh,

So sometimes it seems like it is a good amount about like the epistemics in terms of like trying to maximize learning and breaking you free from like the thing that is usually owning you from within, you know, like your usual way of achieving your goals, keeping you stuck in a certain pattern.

And then it's like, you need to learn something different, but how are you gonna learn something different if you're always doing the same thing again and again?

And so I think that fits for a lot of the, like a lot of the healing uses

that accompany like an ayahuasca ceremony, that seems like a good description.

But there are like other use cases, like for instance, like in these Amazonian tribes, like it's actually like specifically pragmatic in that like they do it to get the hunting party together.

And like they're about to go to war with a specific other tribe.

Well, then you could also make a case of like, you know, is it that like

their like their goal of what they want to do when they encounter the other tribe you want that to be presented in a very vivid form that imagining you want that counterfactual to be hyper precise so that becomes actual or is it um more like a matter of like this kind of collective effervescence from earlier and you actually want to read this account so that before you go into battle you

You're basically, you know, all one body coordinating together, fighting, you know, having each other's backs or both.

And you want, you know, an early stage of something rebus-like and then maybe a later stage of something more involving belief strengthening.

So it's like sometimes you're letting go of the pragmatics and sometimes you're actually like holding it on to the pragmatic values specifically zooming into it.

It seems like, at least in the human case, there is no singular account, but in terms of what you're saying about things like the case of migration patterns and an animal being changed, that seems like relaxing the pragmatics and allowing the epistemics to more optimization for that, that could be a really important part of that, I think.


SPEAKER_00:
Cool.

Amazing.

Yeah, I mean, we haven't got too much time left, but I guess two more questions.

One, totally trivial.

The other one, not trivial at all.

So I'll start with the non-trivial one.

At Johns Hopkins, you're really at the heart of the current uptick in psychedelic research.

Are you, well, just to frame this, I sense from an external perspective, there was a great deal of excitement.

you know, starting five, six, seven years ago.

And maybe now there's a slight conservatism that's crept in and saying, okay, the psychedelics might not be the panacea that we hoped it might have been seven or eight years ago.

Again, I'm not on the inside.

I don't know, but that's just my instinct.

What are your kind of predictions, expectations, level of optimism with respect to psychedelic therapy in the next 10, 20, 30 years?


SPEAKER_01:
Um, I have some, uh,

So if we can avoid the very live possibility of backlash as adverse outcomes happen inevitably and they will be more notable, like with driverless cars, even if on net they're saving lives, you will note those cases where it just slams into a person and that'll change everything.

And so it doesn't take many people to have some really bad experiences.

um they even see like with the recent like uh matthew perry like what happened with him oh yeah and that really is um actually really deeply responsible for everyone involved because um i don't want to say that you know like ketamine's you know uh not a mixed uh like it's powerful medicine and but uh and in that case like um you see the shape of it there's already like people are interpreting this as oh ketamine is dangerous and already this is causing people to call for more

of a pullback, but he was also on a good dose of an opiate, probably had some drinking system, and was in a hot tub.

So it's like, did he die of respiratory depression and then drown?

So things like that could happen, and it doesn't take many of those for the psychedelic renaissance to really be pulled back.

and try to make these potential life-changing medicines and interventions.

Oh, by the way, whenever I'm speaking, it's outside of a Hopkins position.

So speaking from the outside, they have a particular role, I'd say, in the psychedelic renaissance of doing largely conservative work within a mainstream medical model and trying to say, can we push forward that?

And how can we approach these medicines safely and responsibly

And so they tend to be, I'd say, more conservative in what they're doing.

And it's a very valuable function.

And in general, they try to be very careful.

I'm a little less careful.

So some of the open questions and challenges we have is what...

I guess you say business models or how can we scale psychedelic therapy?

So one of the problems with like a psilocybin intervention is they're amazingly expensive.

And so the question is like, how can we get like broad access to them?

You need some sort of like group therapy and like a different model than the ones we currently use just to make the economics work.

to make this an available one, a widely available intervention.

The other question is if you remove some of the expectancy effects you would get from the places where these interventions were done and having it done at Johns Hopkins or the Good Friday experiment in Harvard, there's a certain trust and authority which is interacting with this as part of leading up to it.

That's part of the expectation that you will be so changed.

And so if you then try to have clinics opening up everywhere, do you get the same effect?

Because you'll have the reports as some of the five most meaningful experiences in a person's life.

A few sessions, your life has changed.

And to what extent can we still get outcomes like that as we move into basically scaling and having more institutions and more context and do so safely?

One of the things I'm actually very excited about is I have some friends in

pharmaceuticals who are basically creating analogs of these psychedelic compounds to try to change their properties slightly.

And so one of them is like, for instance, shortening their duration of action.

Like, well, why'd you want to do that?

Well, let's say like you could show up for a therapist and you can do basically MDMA therapy and be sober again in two hours.

And so that would both allow you basically to do it more flexibly, and do it more times potentially, and with less risk from the dose.

Because things like excitotoxicity will be a function of both the dose and the duration of effect.

And so if you reduce that duration of effect, things like metabolic strains, you would reduce it.

So those advances, I think, are going to be a complete game changer.

these short-acting, powerful compounds, I think psychiatry will not be the same once those are on the scene, and just countless lives will be saved and transformed.

Fantastic.

So, yeah, and so there's a lot of, like, things are very fraught, right?

You know, we could have something like a couple bad outcomes could cause, like, a chill on the whole thing.

But the promise, if we could just make it through this crucible, I think it's unbelievable.


SPEAKER_00:
Amazing.

Well, that's exciting.

And then my super trivial question, especially even more trivial given that response, is ayahuasca is famously kind of an enigma because it's... You may correct me on my biochemistry here, but isn't it...

DMT mixed with a plant among the hundreds of thousands of plants that are found or could be found in the Amazon.

What's your Joe Rogan-esque thoughts on how on earth they managed to synthesize ayahuasca?


SPEAKER_01:
You have your edible TMT, but that'll be broken down in a hot minute.

And so you need to find basically this monominoxidase inhibitor to keep it going.

But among all the different things you could have tried, how did they find the right one?

The shamans will totally tell you the plants told us.

That's how they did it.

That doesn't help.

I guess, you know, I'm hoping, I don't know, maybe we should get like Joe Heinrich on the job and like basically some sort of computational model of like the process of like trying out the permutations of like what shamans do normally.

Yeah.

uh maybe it's actually tractable in terms of like if you see just what they're doing it's like yeah they were going to find that given what they were doing in like over over 200 years you would expect this percent that they found it so i would expect something kind of like that or maybe the plants told them or maybe the plants told me yeah maybe adam that was that was amazing


SPEAKER_00:
I'm kind of mind blown.

That was awesome.

Thank you so much.

I mean, with every guest, I always feel like I learn just infinite sums of new information, which makes this so much fun for me.

But no, I really thank you.

I know you're a busy man.

And so I'm very grateful for you giving me two hours of your time.


SPEAKER_01:
It was a pleasure.


SPEAKER_00:
We're going to keep digging away at these questions.

But yeah, for me and the Institute, yeah, it was an absolute pleasure on my part.

So thank you again.

Thank you.

All right.