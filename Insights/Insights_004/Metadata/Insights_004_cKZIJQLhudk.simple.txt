SPEAKER_01:
Welcome everybody to the fourth episode of Active Inference Insights.

I'm your host, Darius Parvizi-Wayne, and today I have the pleasure of hosting Inez Hipolito.

Inez is a lecturer of philosophy of artificial intelligence at Macquarie University in Australia.

Her research focuses on 4E cognition, which holds that cognition is embodied, embedded, enacted, and extended beyond the brain,

and she studies how this framework can help us understand and build other systems that exhibit a form of augmented cognition, including brain-computer interfaces, neurotechnologies, and smart environments.

In addition to this, she co-founded the International Society of the Philosophy of the Sciences of the Mind, Ugualti Eropicini,

And she is currently the ethics advisor in artificial intelligence versus the cognitive computing company, which implements active inference into artificial intelligence agents.

Inez, thank you so much for joining me.

It's an absolute pleasure.


SPEAKER_00:
Thank you so much for having me.

The pleasure is mine.


SPEAKER_01:
And we were just discussing off air that we're doing this across many oceans.

So Nez is in Australia, I'm in London, but we managed to sync it up, which is fantastic.

Excellent.

So I wanted to start with Markov blankets.

All things start with Markov blankets.

Markov blankets really play a fundamental role in active inference and in the framework that we apply to artificial intelligence, to cognition more generally, and also just the underlying physics and maths of active inference.

And a lot of your work has focused on Markov blankets and the scaling up of Markov blankets.

So maybe a good place to start for our audience would be if you could just give a simple overview of exactly what a Markov blanket is, and then we can go from there.


SPEAKER_00:
Yeah, fantastic.

You're absolutely right when you say that everything starts with a Markov blanket.

Everything that is a thing has got a Markov blanket.

And that does not necessarily mean that a Markov blanket is going to correspond to a certain kind of like physical boundary that one can see, right?

A Markov blanket is a theoretical formal construct that what it does is it tells you

how or what things are going to be influencing a certain state to be the case.

So it is a statistical tool precisely to understand something really important, which is how a certain thing is coupled

within or with its environment.

So everything does start, everything has its Markov blanket, does start with the Markov blanket because it is a way in which we can capture

two very important aspects, and these two aspects are that a thing, typically an open system as a thing, is both thermodynamically open and operationally closed.

So this is quite crucial because it is what allows the thing to persist, not to perish, not to succumb to the second law of thermodynamics.

So Markov blankets really come very useful because, to my understanding, they allow us to capture simultaneously these two features.

being both operationally closed and thermodynamically open.

Because what happens is the system is situated in the environment in a way that is open to the environment.

It must be coupled with the environment, otherwise it is perishing.

It will not maintain itself, but it also has a certain boundary that allows it to maintain its coherent form.

So the Markov blankets become really interesting because they allow us to capture those two dimensions of an open system.

And what is an open system?

An open system is mostly everything that we see.

We don't really come across closed systems.


SPEAKER_01:
Excellent.

Yeah, that's great.

I'm wondering whether you could give us a sort of overview of exactly how that coupling works.

So people may have seen that the Markov blanket is essentially composed of active states and sensory states.

That makes sense if we're talking kind of about physical boundaries like actuators, arms, legs, and so on.

But on the understanding of the Markov blanket as a statistical entity,

What really are active states and sensory states in the theoretical way?


SPEAKER_00:
Well, there are many ways to answer this question.

It will depend on how much you want to connect then the active inference framework and formalism with other theories that we find in physics or in neuroscience.

So there are many different ways in which one can answer this question.

But for the sake of remaining,

with the kind of like more skill-free application of Markov blankets and not reducing it to immediately to the brain, I will keep the formalism as something that we can apply to understand the statistical relations or influences between a system, an open system and its environment, right?

So then what you have is you have the possibility of understanding

how a certain system is in a particular state.

So you understand that.

And then what you can also understand is you can make predictions about future states in which you may find the system by virtue of using this kind of formalism.

So then what you have is you employ or define that the level or aspects of scientific interest are going to be your internal states.

And then your next question is going to be, okay, how do I find this system in this precise time and space in this particular state?

What are the states in which the system is situated that are going to be crucial for me to find the system in this particular state?

And therefore I understand the system and potentially, ideally, I can make some nice predictions about future states.

So these would be our internal states.

So then what we need to get on is then we need to get to define what are the external states.

And those are, like I said, the states that are going to be immediately influential for the system to be in a specific kind of internal states.

Now.

This is all done.

The next step is to understand that internal and external states, they mutually influence one another.

That's what it means about something being an open system, right?

Is that there is exchange of matter and energy such that the system is remaining in a certain state and, for example, is not going into a phase space such as...

perishing or towards death.

So then what you get is an understanding of what I was just saying, which is how the system is coupled and in this permanent continuous

exchange of matter and energy in order to remain alive and push back on the second law of thermodynamics, right?

So you get this operationally closed and open system at the same time that is very well captured by these internal and external states.

And I did say that they influence one another.

But it is important to understand that they do not directly influence one another.

They need a second set of states.

So basically, internal and external states are conditionally independent, and they will require the intervention of a second set of states, which is very much what you asked, the active and the sensory states.

So these are going to be the ones that are doing the direct communication, if you will, between each other,

where hopefully and ideally we have a balanced influence between sensory and active states, right?

And these direct influences between sensory and active states are going to play a crucial role in order for us to mathematically track down and understand the coupling of the system in the environment, which is the system being internal states, the environment being external states.

So this is just like the overview of the Markov blanket and the active inference formalism that we could apply to anything that is an open system.


SPEAKER_01:
Wonderful.

Yeah, that's great.

That's a really useful explication of the framework.

I think it's, as I kind of hinted to in my initial question, it's rather easy to think of it as a physical boundary.

So we can think of cell boundaries or the blood-bane barrier or the boundaries of my body.

And then when we do that, the notion of sensory active states really becomes intuitive in the sense that in the case of my body, all it is, is an action perception loop.

And that's been known to be critical to intelligence or cognition for a very long time.

So.

That said, there's also a very strong position, which is that it's actually just a statistical description of the way things act, the way things persist through time.

That leads me to ask the question of, should we consider the Markov blanket to be interpreted in an instrumentalist way, in the sense that it's a tool that we can use in modeling objects, open systems, or should we be interpreting it in a realistic way, i.e.

there is actually something

is ontologically a Markov blanket that is truly out there as a Markov blanket embedded within lots of other Markov blankets of course


SPEAKER_00:
Yes, I'm really glad that you asked that question.

It's a live question.

And there are many ways to answer this question.

So the way that I decided to answer the previous question was in a way that one understands that a Markov blanket is a tool, is a statistical tool, it's a formalism, it's a mathematical construct, right?

And I also did not go immediately into the brain or an organism with actions and sensations because I'm trying to avoid precisely the literature that tends to reduce the framework to thinking that active states and sensory states are going to be action and sensation.

That is not the case.

A Markov blanket formalism from active inference can be applied to anything that is an open system.

There are many examples of this in the literature, such as, for example, I can think of the example of when you have a set of pendulums in a room or a set of clocks in the same room.

What's going to happen is that eventually they will synchronize.

And you can use this framework to capture, to predict that synchronization.

So it is important to understand that this is a mathematical construct that you can employ to precisely understand patterns of behavior in the natural world.

So we've done that.

We understood that.

So then we can think about it.

You can use this framework to develop, for example, simulation models, which allow you to understand the phenomenon of scientific interest, as well as hopefully, it's a good model, it's going to give you some prediction power over future states of the thing, which doesn't have to be anything to do with cognition, can be something that is situated in the natural world.

Right, then a certain phenomenon happens specifically in cognitive science.

When we notice that specifically in cognitive science, even if you apply a certain computational framework, doesn't have to be active inference, a certain computational framework is applied to model, simulate and get some predictive power about, for example, black holes.

let's say black holes, right?

And you use that kind of like mathematical framework.

And then you employ the same kind of mathematical framework, the same kind of like computationalism to understand the brain, because after all, both a black hole and a brain are complex systems.

What does that mean?

It means that it is extremely difficult for us to model it.

Why is it extremely difficult to model it?

Because it is very high in dimension.

So it's really hard for us, we don't have the computational power to model it, which is why we need to incorporate something called dimensionality reduction, because we don't have the tractability to precisely do that.

Keeping up with what I was saying, in cognitive science specifically, a phenomenon happens.

So imagine this, we use the same computational strategy to model things from the natural world all the way to the brain, right?

And then what happens is that we would never say that the black hole or something that is not part of a living system would have specifically a Markov blanket or would engage in literally active inference.

we would understand very clearly that this is a computational strategy that we are developing and employing for epistemic purposes to understand the phenomenon and to get some predictive power.

That's what we're doing.

And we are happy with it.

If we get some predictive power, that's success in science.

And then once we do this move and apply exactly the same formalisms into, for example, the brain or an organism, right?

We tend to anthropomorphize it, right?

So we tend to say, okay, so then the brain is acting precisely literally by engaging in active inference.

or in other realms engaging in predictive coding, right?

So we lose track of understanding that, okay, these were the tools that we started off with, and we were very happy when we were modeling black holes with these tools.

We were happy that we had some predictive power, but now it's not enough.

We want more.

Well, now we want to go from the epistemic virtue into an ontological predictor.

Now we want to say that the thing that we are modeling, trying to understand, the

developing models for epistemic gain is precisely has the properties or the ontological properties that the model, the computational model has, right?

And that's when you get into making a realist or taking a realist stance on and upon active inference.

Right?

You don't have to, you can do it, but then you're going to have to defend that position in a way that, okay, you're going to have to answer.

So if you are applying the question that you need to answer then is, if you're applying exactly the same framework to model and predict black holes that you are to do the same with brains.

Do you get to say that brains engage literally in active inference in ways that black holes don't?

And why?

So that's the realism take and the problems that you find and where you would be led to.

Or you remain in the more cautious kind of position, which is the instrumentalist or non-realist position, in which case the position is there are things in the world with a real existence, right?

And those things behave in ways that we would develop models to understand that behavior in terms of patterns, patterns of behavior.

The things exist in themselves.

They interact with the world in themselves.

The patterns of behavior are our scientific constructs.

So then we talk and then we can start talking about, okay, so I can pattern behavior through, for example, employing, developing a model on the basis of Markov blankets, active inference, and then I pattern the behavior.

What did I did?

What I did was I found patterns and therefore an explanation for a behavior.

And this explanation is something that I didn't have before.


SPEAKER_01:
Right, right, right, right.

Well, I'm going to take us towards the realist position now, because I think people will find it interesting about the ontological claims, ontological implications that active inference has, especially within the cognitive science and the neuroscience community.

And I guess when you were taking a realist stance on the Markov blanket, that there are these structures which have some kind of embedded nature in the brain, right, and

People have probably heard for us and talk about how this is actually reflected in the phenotype phenotypic nature of the brain and its hierarchies.

Um, it makes me think about modularity.

So modularity for people who don't know was introduced by Jerry photo, um, in 1983.

And the basic idea is that modules are these kinds of, um, innate neural structures, which have kind of very specific functions.

And Fodor in 83 laid out certain category, certain functions that a modular system would have to obey by.

So domain specificity, the fact that modules have to operate on a very specific type of input.

There's also informational encapsulation, this idea that like, at least how we portrayed it in 1983, that these modules are encapsulated with respect to higher order beliefs.

That notion got sort of, you know, weakened over time, let's say, and then there were further about the actual neural architecture would have to be involved in modules.

But anyway, people can get the basic idea of a module.

We might have a visual module, a

hearing module or module for language, which is an idea clearly taken up or that Chomsky found a lot of joy in.

All that to say, what does active inference have to say about this picture of the mind as being modular to any interesting degree?

And does this notion of kind of, at least for a predictive coding position,

a hierarchy in which you have feedback loops in which the top down affects the bottom, the top layers affect the bottom layers and vice versa.

Does that actually really have anything to say about modularity and more generally the architecture of the brain?


SPEAKER_00:
Yes, well, I'm really glad that you're taking us there.

We do have a couple of papers that do engage a little bit with the modularity of the mind.

One of them is Markov blankets in the brain.

And that paper and the other one is parcels and particles.

And in there, we do briefly mention

reasons why thinking or patterning the brain behavior, the brain activity in terms of Markov blankets would be useful for many reasons, for applications that go all the way to DCM, dynamical causal modeling in neuroimaging.

But I'm going to set that to the side and I'm going to specifically speak to the modularity of the mind.

You very well said the modularity of the mind is one of those theories that we've been having in philosophy of mind that has been very foundational for cognitive science and for the ways in which we ask questions, for the ways in which we look for things in the brain and has been as influential as it has been refuted.

So very few people today, I can think of three people, that would endorse good old school Fedorian modularity of the mind.

And there are philosophical reasons for that and there are scientific reasons for that.

Philosophically, there's been made very substantial, solid, strong arguments against it.

And scientifically, evidence shows neuroplasticity, shows neural reuse in ways that would contradict the modularity of the mind.

I will make here just a bracketing of a little bit of history of philosophy of mind just before I get into the active inference understanding of cognitive slash brain activity and dynamics.

Just to say that it's interesting to see that we have this tendency.

So I'll do a little bit of philosophy of mind here.

we have been having this tendency in philosophy of mind, or at least analytic philosophy of mind, which is to look at, and this is a point that has been made by many influential philosophers, for example, Frances Egan, she has made this very clever point, and I think she's absolutely right, when we look into, we philosophers of mind, look into what is happening in computer science, and then we adopt the best computer science at the time to

establish a kind of like a metaphor to how the mind supposed to work.

At the time, as you said, in 83, Jerry Fodor looked at Turing machines and he asked the question, what would happen if one would conceive the mind as if it were a Turing machine?

And then he writes the book, right?

What happened is that what starts off as being like sort of like metaphorical thinking, right, it eventually starts becoming a very ontological claim that the mind is ontologically modular.

And that is very important for us to look back in history so that we know what to do and what not to do in the future, right?

Because what happens is then you set off cognitive science to look for those modules in the brain.

As you set up experiments, as you set up simulations, computational simulations, you set off

to look for and find those very, then you have all of those sets of properties that are supposed to be the model.

So there's the automaticity, there's the domain specificity, there's the information encapsulation, there's the top-down information, sorry, the bottom-up information going all the way up to cognition, cognition means.

all of that framework that was a theoretical framework adopted from computer science then is defining the whole cognitive science field and what we should look for, right?

So it's quite interesting and important for us to know our history, to know how things really happen in a way that, well, you look back and you see how it then science came back and said, well, it kind of actually doesn't make sense

that the mind is modular in that way.

So not only philosophically we have refuted it in ways that we have forced the modularity of the mind to reinvent itself, to revise itself, to survive, really.

And what happened was because the problems were coming to arise from philosophy and from neuroscience, what happened was we started having to revise the modularity of the mind because the novelties were coming up.

But we did not want to let go of the modularity of the mind.

So we start revising the basic pillars and then we start having to let go of basic pillars.

And that's when you have Massive Modularity by Peter Carreras, for example.

And still challenges continue to come up, right?

So then you start going into this other

this other field, which was known at the time, cognitive penetrability.

So now what you allow is you revise modularity to the point that it's not just bottom-up information going up, but now you allow for bottom-up and top-down.

So that's cognitive penetrability, right?

And then it comes up around 2010.

and stays until 2020 still is a little bit here because as we sort of like explored a little bit in a special issue that we just had out this year with Michael Kishoff, it's a special issue in consciousness and cognition.

And it's about the Bayesian brain and how or whether the Bayesian brain predictive coding

is compatible to the modularity of the mind and specifically to the one that allows this traffic going up and down, such as cognitive penetrability.

And there are still a few people that are very engaged in defending that kind of modularity of the mind that is

quite agreeable and compatible with predictive coding.

And examples of that are, for example, more conservative approaches within predictive processing theories of the mind.

For example, predictive mind prediction error minimization, mostly developed and headed by Jakob Huy.

there would be one that you can find as having some agreement with modularity of the mind.

Of course, the revised version of it, which is the one in which it allows traffic to go up and down.

And that's, of course, you can see the parallel as it being predictions

coming down, prediction errors coming up, and the traffic being very contentful in nature.

Therefore, you have a version that has got this compatibility between modularity of the mind and the predictive brain.

What happens is, and I'll just wrap this up and go then to active inference, what happened there, if you think about it, is

You let go of two things that were very precious for Jerry Fuller.

You let go of horizontal boundaries and vertical boundaries.

And once you let go of that, you really have to ask the question, what is left of the modularity of the mind?

Why should we keep it in place at all whatsoever?

Because what happened was you let go of one thing.

there was the basic pillar of the modularity of the mind, which was the boundary that was distinguishing or dividing cognition on top and modules at the bottom.

This boundary doesn't, you don't have this boundary anymore because now you have predictions coming down.

So you let go of this boundary.

Jerry doesn't get that.

And they have the vertical boundaries as well, which were very precious because those were about information encapsulation such that different modules are the main specific and they do not talk to each other, right?

So what you do is you get rid of those vertical boundaries.


SPEAKER_01:
There's an interesting historical point here.

Sorry to interrupt, but there's an interesting chronology here, which I actually learned during my undergrad when I was looking at whether language comprehension was fundamentally modular.

So it was related.

That's hence why I brought up Noam Chomsky.

In 83, Fodor has very distinct definitions of information encapsulation and domain specificity.

So domain specificity is actually, we just spoke about that.

There's a proprietary database that each module works on, right?

So visual, the visual module work on, uh, photons or whatever, you know, or the language module works on syntactic nodes.

And informational encapsulation in 83 was top-down beliefs, expectations doesn't affect the workings of those modules.

Interestingly, in 2000, so he writes another book or article about modularity in the year 2000.

He kind of conflates, and again, I don't want to speak ill of Jerry Fodor.

He's very important, and he's also not here anymore, so he can't defend himself.

But he seems to confuse information encapsulation with domain specificity.

Because he talks about, and this is a quote, that a module is encapsulated if its function is restricted to what its proprietary database contains.

So I think what's interesting there is practically what you're talking about in terms of horizontality and verticality.

He kind of abandons the verticality there.

Yeah, he abandons the verticality in the sense that...

By sort of omission, he concedes that maybe we should let go of this idea that top-down beliefs, expectations don't influence lower levels.

But he does keep the...

The horizontality, which is let's keep these as distinct systems working on discrete languages or data for want of a better term.

So it's just an interesting historical fact there that I think if he was here, if Frodo might, he could obviously offer some clarification, but may also go back on his original 83 position of the restriction for top-down information to flow into modules.


SPEAKER_00:
Yes, absolutely.

And I think that this is also how you are absolutely right in specifically the point about the conflation between information encapsulation and domain specificity.

These are two different things.

And one of the aspects that I think would need to be abandoned and that we abandoned in our Markov blankets in the brain is precisely that notion of information.

Because you can have domain specificity without relying on this notion of information encapsulation and things not conversing with each other.

Because again, to my perspective, that is anthropomorphizing the brain and brain activity.

We're talking about dynamics and activities of the biology kind in the brain.

And there is an anthropomorphization that I don't think it's necessary.

And again, it proves itself unnecessary.

But we learn so much from learning the history of where these ideas come from.

And they have a place, of course.

And I think it's important for us to precisely learn where they come from, such that we start improving and advancing our understanding of the brain and cognition in different ways.

So there is definitely a place for Jerry Fodor.

And I think that this is the place is to get us into other advancements in the field.

And what we have been able to see and through scientific evidence in neuroscience is precisely that that kind of way of thinking that may have started as a metaphor

doesn't really hold, right?

And that there may be domain specificity.

I think you put it in a very nice way.

There may be domain specificity without it being information encapsulation, right?

And once you start having to let go of all of these basic pillars of modularity, it's gone.

We can try to salvage it and then call it something and brand it something else, but it's gone.

And that's when then you also see in the history, well, we have now new computational capacity or strategies such as parallel distributed processing.

What shall we do?

Let's try to apply the same thing that we did, which is what if we would think about the mind as if you were a parallel distributed processing system?

And then you have the networks and predictive processing theory start rising up on the basis of that analogy as well.

I am careful.

about going over and above it being a metaphor, right?

Because I always think about the brain as a very biological kind of system as opposed to a full agent with full capacities that thinks and reasons and models as if it were a scientist.

So I push back on that.

I'm careful about that.

So the way from that position on, then the way in which we theorize Markov blankets as being useful was

You start from those understandings that the brain is a dynamical complex system, right?

That it changes over time.

That the ways in which a full agent engages with the environment is going to have significant impacts on the ways in which pathways are strengthened or are weakened in the ways in which the brain is going to develop itself as an organ, right?

So you start from that very neurobiology kind of understanding of the brain, that it is a complex system, meaning that it is a coupled system.

It is situated in a body, it is situated within other organs in the organism, and this organism is situated in the environment, right?

So we completely abandon the view of the brain as being a predictive machine there.

even though you can, and there's literature on building upon the idea of the brain, which of the brain being a predictive machine, which comes from Helmholtz.

And more recently you can theorize it.

And I've been presenting on that as you can theorize it as the low road or the high road to active inference, which we can talk about later.

But the view is you can take that pathway.

That's not the one that we took.

We took the pathway of the very neurobiology kind of way of the brain being a highly situated organ within a larger system, the larger system being situated in an environment.

And all of these influences and interactions are going to have an effect on the state that you're going to find the brain in a specific point in time and space.

So then starting from that understanding, as opposed to the brain being a machine, right?

So then we ask the question of whether or not, because this is crucial, this is the crucial point, which is why I started by describing Markov blankets as this scientific construct that you can apply skill-free, come skill-free,

that you can apply to anything that is a thing, that is an open system.

You can apply it.

You can also apply it to the brains.

But then once you do that, you have to test it out, right?

You have to look into, okay, does this really make sense?

Can we find...

patterns of activity that would be explainable through the application of Markov blankets at different levels of organization within the brain itself.

So then in that particular paper, what we did was we start from a standpoint where we reject the modularity of the mind because we do not think that there are reasons, scientific reasons, to think that

The brain is organized in very strict, rigid ways, call it modules, whatever we want to call it, but in very strict, rigid ways.

We do not think that that's the case because there is scientific reason not to take that path.

and the brain being a very dynamic and changing system, then the question that you have is, how do we make sense of it?

How do we find patterns in such a dynamical system, in such a coupled system?

How do we find those patterns?

Can we find those patterns?

So then let's apply this Markov blanket formalism at different levels.

given the data that we have coming from DCM, coming from Dynamical Causal Modeling of the brain.

So basically, in very, very simple terms, the view here is that we put the brains in scanners, we get the data out of the scanner, and then we look at that and it's just vast data that we can't make sense of it, can't even start to think about how to make sense of that.

you employ DCM as a model to make sense of that data.

And what you would get from that is a nice causal topology about how connections are made and dynamics are formed.

So you get a nice pattern of that if the model is suitable and useful, then that's what you get.

So then from that kind of like scientific point, we grab all of that, all of those nice models from DCM and we see, we look at whether or not we could apply the Markov blanket formalism.

So the two sets of states, internal and external, active and sensory states, in order to get an explanation of those pattern dynamics at different scales.

So we start off with the scale of a single neuron, and then we have a cortical column, and then we have regions, right?

And what is the take-home message from this?

Because, of course, if anybody's interested in the details, then the paper is out there.

But what is the take-home message there?

Is that we do find the same patterns of behavior across scales by virtue of employing this formalism.

And that is really good.

That's already quite important because that means that you can get what we started off our conversation with.

you can get understandings of activity that is occurring in the brain at different scales, where each of those scales is both operationally closed and thermodynamically open.

So then what you get is you let completely go of that rigid systems that you had with the modularity of the mind.

You completely let go of that.

And what you get is an understanding of how certain neurons in specific environments, you can think about it in a very simple way as like a cell in a cell tissue.

how a cell in a cell tissue is interacting and engaging with the tissue in order to do what it needs to do.

So you can think about, you can use this formalism to precisely understand how that particular system is behaving according to the environment that it is at.

So then you find these patterns of behaviors of like certain neurons firing given certain conditions, and then you get all of this nice understanding of this coupled behavior being situated that is highly dynamic and it really is dependent on the environment that it is situated at.

What you also realize is that there are certain parts of the brain, there are certain

specific parts of the brain that you can see that they may be insulated, that they do not conform to active inference, they do not exchange.

And that's

In a way, if you wanted to say that would be what Jerry Fodor had in mind as a modularity of the mind, you could say that.

But all that happens there is a very simple biology process, which is the system already knows what to do without needing to know what is going on in the environment.

It is what we say as it is set by evolution.

It's been working so well that way that it doesn't need to know

or get to know feedback from its environment, right?

So those would be the ones in which you would say, oh, it's encapsulated.

But it's informationally encapsulated?

I wouldn't say so.


SPEAKER_01:
Right, right, right, right.

Yeah, there's a lot of that.

There's a lot of that.

Cool.

I mean, you also gave a really nice description of 4E cognitive science there.

So exactly as I said in my introduction before,

He's, for those who can't remember, embodied, extended, see if I remember, enacted, extended.

You get all of them?

Yeah.

And I'm enjoying the history lesson as well.

So, because I do, as you said, I think the chronology is really important here, just to get a picture of the philosophical foundations on which this work is being done.

But eight years after Jerry Fodor releases The Modularity of the Mind, a very important book comes out, which is The Embodied Mind of Rela Thompson and Roche.

Before we go there, because you work, I guess, within that framework of, as you said, Fourier cognitive science and the embodied mind.

I think listeners will be curious about, you mentioned scientific evidence refuting modularity.

I was just wondering if you could provide us maybe just with one example of a module which is not exhibiting

the typical features that Fodor laid out, which would make it fundamentally modular.

So what makes it open, let's say, to its environment?


SPEAKER_00:
Yeah, one very clear example comes from all the research in neural reuse.

So that would itself already sort of like move us away, or I would say it's strong reasons to move away from that rigidity of modules that do not change, that are, as Jerry Fodor would conceive of it, they are hardwired in that way.

So another feature that you lose is the automaticity, right?

So the idea with the automaticity is that

Modules in a way are silly, right?

They don't know really what's going on.

They are hardwired to automatically process the information that they are domain specific to.

Right.

So that's the automaticity.

They don't really have a say in the matter, so to speak, even though I'm completely anthropomorphizing this story as one with the modularity of the mind.

So you do lose that with the large evidence on neural reuse.

where you see, which is extremely compelling and it's absolutely fascinating that you see certain neurons that were used to be neurons for vision to become neurons for something else like auditory system, for example, depending on the necessity of the whole overall system.

So what you see is the neural reuse cases where, well, it really challenges the basic aspects or properties that would make a module a module, right?

Domain specific, well, is it domain specific?

If it becomes domain specific to something else, the automaticity as well.

The neural reuse, I think would be, it's a great challenge.

Another one is of course, neuroplasticity.

So the studies in neuroplasticity do challenge, again, the rigidity of the non-changeability of this hardwired system.


SPEAKER_01:
Yeah, absolutely.

Okay, great.

That's really useful.

Yeah, I always think about, I think I got a tour about the McGurk effect.

when I was learning about modularity of mind, which is this auditory visual illusion that when people, yeah.

People can search up or do the McGurk effect.

But again, that brings into question this encapsulated idea that modules can't speak to each other.

Okay, excellent.

Well, as I said, what became very popular after these kinds of rigid computational accounts of the mind was inactivist embodied models.

following Varela Thompson and Rush.

And Varela was of course a biologist.

And so, and he introduced the term autoparesis, which kind of means this central organization that we now speak of or self-evidencing before 1991.

So, as you were saying, we are inclined now to look at the brain as a biotic thing, as a biological system.

And this is very much full grounded in embodied cognition.

Maybe it would be useful for everyone if we could just go through the four E's firstly.

It doesn't have to be super, it's a very rich history.

So, you know, as long as short as is suitable, that maybe we could go one by one and think about where is the evidence or where is the philosophy or where's the intuition that this is true?

And we can start, I guess, with the first one, which is embodiment.

What does embodiment mean?

And kind of what is the research around the embodied brain?

What does it focus on?

What does it center on?


SPEAKER_00:
All right, very, very good.

So embodiment is something that is a concept that comes from phenomenology, from the existentialist philosophy, from phenomenology.

It's a very rich concept and it is fundamental to understand a lot of confusion in the field.

Because we need to distinguish between weak and strong embodiment.

I will call strong embodiment the one that comes from phenomenology and existentialist philosophy, such as the one that, for example, Simone de Beauvoir had in mind.

The body that one has that grounds our experience of the world.

That's the kind of embodiment from Simone de Beauvoir or Maudle Pontique.

And then within the E-frameworks, within the E-framework, you have different theories.

And while they do agree with, let's say, a couple of principles, they are going to disagree within certain more nuanced aspects of their own theories.

And I think the embodiment is one that is mostly useful for us to understand the state of affairs in the field and the theory and the confusions, right?

So let's say that it is very reasonable to think that most people in the field of cognitive science today are not going to reject that the body plays a role.

to understand the brain, that the body plays a role to understand cognition.

Very few people would disagree with this, right?

The follow up question is, how do you understand the body?

And I will get to that.

I will just say that only those that would conceive of cognition as encapsulated in the brain as a computer system, such as the prediction error minimization accounts,

for example, Jakob Huy's kind of conservative account, that there he says very clearly you can't throw away the body, the world, and other people because the brain sufficiently as a machine takes care of the cognitive business.

So that would be the only account that I know of that would not bring in the body to play a fundamental role.

All other accounts do agree.

I think we have come to that agreement that the body plays a fundamental role, embodiment plays a fundamental role.

Now the question, the follow-up question is how do you conceive of embodiment?

And then you have two ways, the weak and the strong.

Weak embodiment is the one that is endorsed, for example, by predictive processing theories, such as Andy Clark as the visionary behind it.

What happens there is that Andy Clark, in his account, invites the body to play a causal role in cognition.

And this is important because also with the body, you can interact with a world that is technological, where there are things that then give you the extended mind.

But I'll get to that if we have the time.

Anyway, so it's weak embodiment.

What does this mean?

This means that cognition is a predictive processing that takes place in the brain.

So this agrees with more conservative predictive error minimization accounts, but not only in the brain.

Predictions, the prediction processing machine includes the body.

What does this mean?

This means that the body is seen as part of the predictive machine.

The body is seen as computational.

Cognition is computational.

So that's why this is weak embodiment.

So Andy Clark does not endorse the embodiment that Merleau-Ponty or Simone de Beauvoir had in mind.

He endorses a very computationalist kind of embodiment.

So this is why you can kind of like to understand the e-cognitive science, you kind of have to spread it out within a range.

And then you get like the more conservative ones and the more radical ones, right?

The more conservative ones are the ones that I'm going to say that cognition is...

computational, the more radical ones are going to say that cognition is not computation.

And then you have a spread out of the question that you can ask to help navigate the e-cognition literature is, how radical do you want to be?

Because if you want to say that cognition is computational, you're not radical at all.

And radical doesn't have anything to do with original.

Radical just means how radical you are in comparison to all theories such as the computational theory of mind.

What is the computational theory of mind?

It's everything we've been talking about with the modularity of the mind and predictive processing theories.

This is all computational theory of mind.

How radical are you in relation to the computational theory of mind?

where the basic assumptions are two, that cognition comes down to computational processes of information processing, that's computational theory of mind, and that the mark of the mental is mental representation.

There would be more nuanced things to say, but these would be two that you can ask yourself, and then you can ask how radical am I away from these two assumptions, right?

So that's the view.

And then you get like this weak embodiment, which is very close to, or if not, it is kind of like right in the border between computational theory of mind and e-cognition.

almost like shouldn't be there if you would conceive that cognition within the E umbrella is not computational, right?

So that's the very weak embodiment.

And then you have the strong embodiment, which is any theory

that explains cognition by grounding cognition very much within the embodiment, the experience that one has of the world.

Of course, here, what we are talking about is the level of analysis and understanding that people working in that field are looking at is about the

full agent that is situated in an environment.

We are not talking about neurons.

Of course, we take that into consideration in the sense of the causal relations that I mentioned before, which is how is it that the experience of the world is going to affect and influence the bodily biological processes and in there you also find the brain.

So that's kind of like the strong embodiment for Marloponti, Husserl and all of that kind of thing that we have and mostly applied to psychotherapy and psychological analysis.

And then you get into, let's say, inactivism.

Right, and then in inactivism, you find different kinds again.

But let's say that both strong embodiment and inactivism, they reject these two things.

They reject that cognition is a computational process of information processing, and they reject that the mark of the mental is mental representation.

So they reject these two things, right?

They're rejecting kind of like different ways, but not non-compatible, but they want to reject these two assumptions.

So the inactivist has different ways in which you can also formulate of it.

So you have the Varela, Thompson and Roche, so Varela and Maturana starting the autopoietic inactivism, which is a very rich literature, very based in biology and extremely compelling and very well formed.

And then, of course, others more recently pick up on autopoietic inactivism, and they have developed more recently the framework towards sense-making inactivism.

Now, I want to just stop here to go to autopoiesis just to make the bridge with active inference, where you can, or at least where I find that it's reasonable to make that bridge.

Autopoetic inactivism brings out, and a lot of recent work by inactivists, they also stress that out, they bring out the understanding of crucial aspects of leaving systems from bacteria to us as having those two aspects as being thermodynamically open and as being operationally closed.

And those two aspects launch the system into a state of precariousness.

So these are main concepts within the autopoetic inactivism.

And what this can then mean that we can think of is that what does it mean for a system to be precarious?

Well, what it means is that the system must, must interact with the environment in order to remain alive.

What does this mean?

Well, this means that the system is coupled with the environment.

Now again, what does this mean?

This means that the system, the living being cannot be encapsulated from the environment.

What this would refute is the conservative computationalist views that cognition comes down to being encapsulated in the brain and we can't throw away the body, the world and other people.

So that's kind of like what these means.

So that's why the question is, how radical are you from the view that cognition comes down to computations in the brain, right?

How radical are you?

So we're making our way towards a more radical one.

And then once you find these ideas of like operationally closed, thermodynamically open, therefore a state of precariousness, therefore must be coupled, otherwise it dies, then you say, well,

And this Active Inference Framework actually captures that very nicely because I get conditional independency from internal and external states that would allow me to get the operationally closure, but I also get the direct influence of being thermodynamically open that comes from active and sensory states.

So then it really nicely captures that state of precariousness as a tool.

So that's nice, I think.

And then you can go as radical as you want, which is to completely push back on any views or kinds of theories or ways of thinking that would bring out cognition and cognitive systems from bacteria to more sophisticated, inculturated systems like us as being computational of any kind.

And this is something that I've been presenting as augmented cognition in the sense of the kinds of like computational models that we develop and mathematical thinkings that we develop, they are our cultural practices, right?

So in that sense, we developed these very sophisticated ways of making sense of the natural world of which

Brains are part of, living systems are part of, right?

We develop all of those very highly sophisticated systems and computational capacity to make sense of the world around us.

And what I'm very, very careful is not to make that last step, which would bring me back to the computational theory of mind to say that those computational strategies are ontological predictors of what the brain is or of what the living system is.

So I am very careful about that.

That maybe put me in the very radical position.

because I reject all of the computational theory of mind view.

So that's how you kind of like make your way within the e-cognition is by asking how radical are you in respect to computational theory of mind.


SPEAKER_01:
Excellent.

Great.

I think we have two more E's, but we basically touched upon them.

One is embedded and the next one is extended.

Do you want to give a brief word to that?


SPEAKER_00:
Absolutely.

So the embedded one is the one that, as I was spreading it out in range, and I was saying that, well, you have here very close, you have a boundary with the computational theory of mind, and here you have the radical stuff.

So embedded is here, close to the computational theory of mind.

And this is the E that I mentioned before when I explained that

Very few people in cognitive science in the field would reject that the brain is embedded in the body and the body is embedded in the environment.

Very few people would reject that.

So that's the embedded.

That's why this can be seen as almost close to the weak embodiment.

That's the embeddedness.

Very few people will talk about encapsulation.

Only with that exception of the one that is the prediction error minimization

by Yakov who can throw away the world and the body and other people.

So that's the embeddedness.

It's just the claim that the brain is situated in the body, the body is situated in the environment.

Now then, how you are going to explain that situatedness is where you are going to fall in different ease, in the strong embodiment, in the different kinds of inactivism, the radical inactivism or the more sense-making inactivism.

how you are going to explain that the embeddedness is what's going to make the difference on how radical you go.

And then you have the extended, which I briefly mentioned.

So the extended comes as a part of like a package with Radical Predictive Processing by Andy Clark.

So the package is that it is radical in relation and in comparison with prediction error minimization or conservative one.

It's radical in relation to that, but it's not radical in relation to other E's.

So what happens is that what you have is an understanding of cognition as being a computational process.

that takes place where?

Well, not only in the brain, but also in the body, right?

The body plays a causal role for that information processing, predictive processing to occur and to happen in the ways that it does.

Now, you can also incorporate objects, tools from the environment that are going to play a causal role of the same kind as your body plays.

So then you have a whole system that is distributed.

It is a computational system.

We're still talking about computational theory of mind.

It is a computational system that involves brain, body, and tools.

And that's the extended mind.


SPEAKER_01:
Great.

And yeah, I always feel the need to kind of refer people to where these ideas come from.

So, Extended Mind Hypothesis, Clark and Chalmers, classic paper, and definitely worth checking out.

I think...

When I hear these stronger and activist or stronger 4E cognition perspectives, which refute representation as the mark of the mental or mark of cognition, it makes me think, where does consciousness fit into all of this?

Because as a cautious being with a subjective stance upon the world, I have some sympathy for the entire of this view.

Because I think it feeds into some intuitions that this mind is privileged and can be divorced in some sense from the world upon which it does some computational work.

So if really we take the privilege away from representation, which I think is also a kind of one, so we don't have to get into exactly what is a representation, but maybe we can go there.

What's the kind of realm of qualia, subjectivity, intentionality, and the kind of features of consciousness?


SPEAKER_00:
Oh, thank you for that question.

I always feel like when we go that path, the mental representation being the mark of the mental, it feels like we are getting to watch a TV show halfway through, like in season two, right?

Because we don't ask the questions where the representations and content comes from, right?

So that's the hard problem of content.

So I know that we want to get that because that would allow us, because we already are in the place where we do have, we can engage and develop and more and more sophisticated mental representations.

That's part of what we are doing here is engaging in ways in which we are involving and employing mental representations such that we can understand each other, right?

So it's like we're already half season, halfway through the TV show.

We are already like in season three.

But there was a beginning of the TV show, right?

Well, you didn't have any of this.

You as a baby, as an infant could not be communicated with me in this way about these things.

Where does that come from?

That comes from something called inculturation, right?

So I think before we start explaining things as if they were always like that, we need to understand that there is a trajectory in cognition, in cognitive development that we shall not forget.

So all of those things had to be acquired unless you want to defend nativism.

that also could be very close to Jerry Fodor as well, because you already have these starter packs, you already have this very much in place machinery that would allow you to have all of these semantic content already ready to use that you could start making sense.

Now, if you reject Fodor, you reject it all.

Now you have to answer the question, how can we do this?

Where does this come from?

You've rejected Fuller, right?

So you have a story to tell.

Now, the way that I see it, and many activists do see it, and by the way, also very much compatible then with mathematical frameworks of dynamical and complex systems theory, and that is employed in a lot of psychology empirical research.

as opposed to the computational theory of mind, even though that's the mainstream in cognitive psychology, it's not the only one.

And the way in which you can think about it is that you... So I'll start by saying this.

I've heard many times, people ask me, but how is it possible that there's cognition but there is no mental representations?

No one is saying that.

So that's not a claim.

That's not a claim from an activist.

An activist don't say that there aren't mental representations.

What they want to tell you is that mental representations do not come for free.

You are not born with them.

You had to do things in the environment in order to acquire them.

You have to develop it as a skill.

So we give you a story about a hard problem of content, where does that come from when it does not come as within a nice starter pack that Cherry Folder or Descartes would tell you that it comes from.

So once you get rid of that, you have a story to tell and the story is,

that it depends on enculturation.

So basically as you start as an infant, as a baby, we come into the world and we start interacting with the world.

This world is, and this is the key point, this world is already social.

It's already a social cultural setting.

There is no baby that is born and is developing within a setting that is not social already.

So it is in the ways in which the baby interacts with

their caregivers, the parents, the caregivers, and the world around them that is going to gradually allow them to build simpler concepts, simple ways of using concepts, and then scaffolding that into a numerical system, in a conceptual framework,

and then later on in being able to engage in logical thinking and reasoning, and then being able to express some sophisticated ideas, and maybe even becoming a scientist and contribute to developing highly sophisticated computational models that study black holes.

So it's an enculturated process.

Of course, as we are here doing this interaction, what we are using is we are making the best use of our most skilled till so far, and I'm sure that we'll keep going in a trajectory, but our best skills of explaining ideas and discussing, so we are using and making the best use of our best mental representations,

But I also have to say that this interaction does not reduce to those mental representations.

There is an embodiment aspect of the situation that we are at.

A very clear example of that is that the interaction is different whether or not we are having interaction in person or we are having the interaction online.

We'll make things different because we don't share the same physical space.

So this is just an example of how embodiment here would play out.

But the idea is that eventually you'll start developing the capacity to develop and engage in mental representations also as you talk to other people and you make sense of the world around you.


SPEAKER_01:
Okay, cool.

I'm not going to play devil's advocate, but I also don't want to make you commit to any position, nor am I asking you to solve the hard problem of consciousness, because that's not going to happen, and it's also not the purpose of the podcast.

I understand in that sense that mental representations are kind of downstream on enacted behavior on socio-cultural norms, right?

As you say, there's a lot of evidence to suggest that it's not some hardwired Chomskyian module, right?

We can take that as kind of axiomatic.

I guess my question here is that kind of makes sense in terms of mental representations per se.

Let's say they develop out of this inactivist way of being that we have.

What it doesn't necessarily answer is the kind of characteristic features and the idiosyncratic features of consciousness.

So the actual fundamental what it is like to be me, what it is like to be you, to use Thomas Nagel's terms.

So I guess my question here is, again, not trying to pin you down.

I understand there's a lot of nuance here.

Would the inactivist be sort of, would they be attracted to the notion that consciousness is epiphenomenal?

And by that I mean, for people who don't know, epiphenomenal consciousness is the idea that consciousness is like the steam coming off a steam train.

So it's caused by neural physiological behavior, but does it actually have any causal effect?

on those mechanisms.

So it happens, it's there, right?

And it kind of depends on what philosophy of mind theory you subscribe to.

But would they say that consciousness has no causal role?

I'm imagining that there aren't many substance dualists and activists, but what kind of considerations have they made of the role of consciousness?


SPEAKER_00:
Right.

So I'll just bring something in so that...

So when we talk about qualia, epiphenomenalism, and what it is like to be a bat, like Thomas Nagel, or the whole problem of consciousness, when we talk about that, we are within a certain conceptual toolkit.

We are already within what Wittgenstein would call a bottle, a theory.

And it's important to understand that when we start making our way within a theoretical path, it's like we're building blocks of a house and then we're getting a certain kind of house by virtue of the belief system, thoughts and the path that we are doing.

That's the kind of like conceptual machinery that you get once you play that game.

So, and by playing that game, I'm here referring to or having in mind Wittgenstein's language games.

So you can tell the story of...

or you can do the epistemology of understanding how cognition comes around and about and works by playing different games.

And that is the traditional analytic philosophy of mind game.

And that game is very associated with the computational theory of mind.

So what I'm trying to say here is that once you put on certain goggles, there are certain things that you're going to see, and there are certain things that you cannot see.

So once you start on that path of thinking journey, those are the problems that you're gonna find.

Those are the problems that like the heart problem of consciousness is a problem that you're gonna find because then what you get is how do we study both the easy problem and the hard problem?

So you necessarily, when you start going in that direction, you find those problems and then you have the explanatory gap.

Now, how do we close the gap?

So these are problems that come up within

The computational theory, thinking, language game.

So those are the goggles, right?

And of course, we can try to make these theories talk to each other.

But it's very important to understand that it's almost like axiomatic in the sense that you start solving an equation in one way, the equation will look a certain way.

You start solving the equation in a different way, the equation will look in a different way, right?

So that's almost what we are talking about, right?

Because we are not starting from the point, any cognition doesn't start from the point of view of the brain.

in the other more traditional computational theory of Maya, of course it does.

So once you do start from the brain being a machine, note what questions come up.

Okay, so if the brain is a machine, then how is it that it gives rise?

So it's a scaling up problem.

How is it that it gives a rise to consciousness?

How does this machine give rise to consciousness?

Because there is evidence that there's consciousness.

That is what it is like to be a bat.

There's qualia.

There's a hard problem of consciousness.

This is within that kind of thing, because you start by the brain being a machine, and then you ask, how do we get to the good stuff?

And then you get all of that.

From within the more radical e-cognitive science, you don't start from the brain being a machine.

That's the first thing you reject, right?

And that's also in dynamical and complex systems theory, the case.

They have phenomenal work by Van Helder and other people that precisely reject that cognition has anything to do of being anywhere, or we should use any conceptual, any concept from a computational scientist perspective toolkit, right?

So then you don't start from there.

You start from the point of view that living systems are precarious and they engage with the world to maintain themselves.

The brain is part of the story, but you don't start there, right?

So in this engagement, what happens is you have, you engage with the world because you have certain goals.

Usually the goals have to do in a more minimalistic biology way is that you don't want to die.

It's the precariousness of pushing back on the second law of thermodynamics.

So you engage in the world for that reason, because you want to remain alive.

Typically, this is the most basic biology.

There's much more than that, but let's just stay with that.

So then what happens is you start exploring the world.

And in exploring the world, you do that by exploring your body.

So that's when the body comes in as the body is the means by which you have access and explore the world and respond to the world's invitations to exploration.

So it is in these interactions with the world that are extremely embodied and limited.

They're both constrained and possible by the body that whatever you do, it's cognitive behavior.

And this cognitive behavior is what are the goods that we want to understand in cognitive science.

And we do that by explaining them through patterns of behavior, right?

So it's completely different goggles.


SPEAKER_01:
Yeah, I am going to push back because I think it's good.

It's not adversarial, it's collaborative.

I just sense, or I just kind of believe that the Wittgensteinian relativism has its limits, right?

It has its points where you say, well, there are certain things that maybe aren't relative in a language game.

And maybe one of those are the fundamental aspects of my experience that I can attest to, regardless of if I'm in a Breda Levat or

if an evil demon is tricking me, right?

Like, unless I adopt some illusionism about consciousness, which I'm not willing to do, but again, like, it's not that it's not a viable position to do, but I'm going to take it for granted that, like, even radical illusionists wouldn't say that qualia doesn't exist.

It's just not what we think it is.

And I'm thinking of Keith Frankish and Dennett.

So for me, like the Wittgensteinian relativism, that qualia is itself part of a paradigm, to use a term of Thomas Kuhn, or it's part of a bottle, it's part of a theory.

Yes, in the sense of the linguistic aspect of it, but the fundamental phenomenon is, at least for what I can tell, is real.

So what is the alternative?

I guess is my question, right?

I don't, I'm not refuting the notion that our cognition is in some way constrained and opened up impossibility by having a body, by being embedded in the social context and so on.

in my opinion, we still have to grasp with the fundamental facts of phenomenal experience.

So I'm sorry if I sound like David Chalmers and David Chalmers and Parrot, but it seems to me that I can't get away from the explanatory gap, and I don't think that that's a problem in my theoretical framing of the problem.

I think that's

because the phenomena associated with consciousness is so radically different from anything else in the physical universe.


SPEAKER_00:
Yeah, and I must say that there are very good points that are made by David Chalmers in that respect that I very much agree with.

Now, to go back to that and to link that in a way that would be compatible within my view of inactivism, I would say that, and also Wittgenstein,

There is a real world that you don't have access to.

So I completely agree with what you said, right?

I completely agree that there is a limit to relativism.

Yes, that's the limit.

The limit is the limits of my view.

I'm not going to say the limits of my language as Wittgenstein did in the first book in Tractatus because he overcame that.

So I'm just going to, I'm going to dare to reformulate that for him and say the limits of my perspective are my world.

So there are aspects of the world that I will not have access to.

And that's just the way things are.

I will not have access to your experience of the world because, and here's the inactivist bit coming in, because my experience is determined by the set of past interactions that I've had

with the world and this moment right here where this experience is taking place.

And everything else outside of this, I don't have access to.

That's the beetle in the box, right?

The idea is not the rejection of other perspectives.

And that's precisely Wittgenstein's point is understanding that there are, it's the humility of understanding that there are other perspectives in the world and you do not have access to them.

You only have access to your own very specific kind of perspective to the world.

Now, another thing that he adds that it may be useful is to say that for him, these are

seen in terms of aspects of the world.

You see the world through the aspects that are made relevant to you right here, right now, given what?

Given your past experiences, your past interactions of the world.

That's why certain things will become salient in this particular moment in the environment, which, connecting to the other theory, you would call the what it is like to be me, the what it is like.


SPEAKER_01:
See, I don't know if I would.

Well, to me, I wouldn't, right?

I mean, the salience of my environment, I completely agree, is shaped by my body.

It's shaped by my homeostatic requirements.

It's shaped by my sociocultural upbringing status and so on.

But the fact of the matter is, is that

Things we could describe things as being salient without necessarily invoking.

Well, that's a good question, I guess, whether we could invoke salience of out consciousness.

But I guess, I mean, as a force experiment, you can.

In a sense, I had John Verveke on last week and he was talking about relevance realization.

And so it's all very sort of still fresh in my mind.

I said my reading of this would be that salience is just a manifestation of the conscious experience itself.

But are we going to get any closer to the actual fundamental characteristics, right?

Like whether it's salience or visual perception or auditory perception.

I mean, like the charmer's problem is still there, right?


SPEAKER_00:
Let me just go back to the initial thing because otherwise I'll lose it that you said.

Note that the difference between the frameworks, it's quite this simple thing, which is things become relevant and salient and experienced in a certain way.

within e-cognition because of the embodied experiences that you've had in the past.

Within a computational theory of mind, you might say the same.

You might say things are relevant, what it is like to be me.

Why?

Well, because of the way that information has been processed in the brain as a machine.

So these are different explanations for the same kind of phenomenon.

They are completely different.

So this is where they are apart, right?

Now, as to the problem of the heart, I think when you said Chalmers problem, you meant the heart problem of consciousness.

Right.

Okay.

So it may be the case, and this is also a Wittgenstein move, so I'm not going to take credit for that.

It may be the case, and this is very in line with David Chalmers, which is why I think there are certain features of Chalmers' thinking that I really like and agree with.

Wittgenstein makes this point.

Not everything that is there to be understood about the mind can be understood through the scientific method.

And this is the hard problem of consciousness that Chalmers talks about, right?

And I think that he makes a good point there.

I think that he is very clever and very, very correct.

And I completely agree with three points that he makes, which is that many

people are falling on the trap of claiming to study consciousness and experience and first person, however you want to call it, depending on the theory you're coming from, embodiment, if you like.

They claim to study embodiment and conscious experience and all of those kind of like good things that really make us by going to the brain alone, by studying easy stuff.

And that is a theoretical trap.

It's a fallacy.

And that's where I really agree with, oh, it's a David Chalmers work.

Which is why I'm doing what I'm doing in eCognition precisely because I do not want to get into that trap, which I think it's a trap as well.

I agree with it.


SPEAKER_01:
Great.

Wonderful.

Well, that's all, that's our convergence point.

And again, it's not so much that we need to solve the hard problem, but I'm just curious about whether it retains its problematic nature in 4E.

So that's good to get some clarity on that.

I wonder, it's a difficult question, but again, I'm not trying to get you to solve the hard problem.

I'm just curious about your thoughts on this.

I said I had John Verveke on last week, and he's got this idea that getting more precise on the function of consciousness would help us in resolving the nature of consciousness, the hard problem.

Do you see any viability in that link?


SPEAKER_00:
You can get something by the function.

Within the frameworks that I work on, active inference and activism, within these frameworks, I'm going to give the answer within these frameworks.

You can get some explanatory traction, you can get some epistemic virtue out of thinking function, but it doesn't get you all the way through.

It gets you to understand the precariousness and why systems behave in the way that they do.

It's because the function is that they want to push back on the second law of thermodynamics.

They want to remain alive.

But then you think about a point that Simone de Beauvoir made, which is also a very clever point, which is if all there is to life is to not to perish, then what is it that makes us different to vegetation?

Right?

So function gives you as much as it's interesting and relevant to the point that it explains or it gives you as far as across life explanation.

So one thing that you get is the function is all life does not want to die.

Typically.

That's the law.

That's the free energy principle.

That's the law.

But it gets you as far as that.

And you want more.

because you want to get to the goods of like embodied experience, right?

Why people behave in the way that they do, right?

So here, I think that

You can bring in also again Simone de Beauvoir, I think is a good segue into making this point, which is very under the EAM umbrella.

But I think she makes this point in a way that here it's going to make the point clearer, which is that if, again, going back to the point, if all there is to life is not to perish, then what makes us different from vegetation?

What makes us different from vegetation is that we are in a kind of cognitive development trajectory that will become enculturated.

We are situated in sociocultural environments.

And once that happens, we start behaving in ways that not only do we get the conceptual toolkits, the reasoning, et cetera, but we also have access and contribute and co-construct those social environments from the very embodied situation that we are at.

So in a way, the biological body constrains the access and co-construction that you do with the world, as well as the social, culturally developed embodiment also plays a role in the participation that you have or not have within the environment that you navigate.

Now, she puts this in terms of

the living being between its condition, between freedom and facticity, which see how compatible this is with what we were saying about pushing back on the second law of thermodynamics.

You want to remain alive, but you don't want to remain alive within an encapsulated environment.

You want to remain alive and do really well in a social cultural environment.

Which is why we are more than simple vegetation that just wants to live.

We want to live well, we want to live good, we want to do things that are good for us.

So we start now entering the realm of reasons, like reasons that we need to give for the things that we do in the ways that we act.

So now we start to become very sophisticated, start to get to this mental representation, if you will, but it doesn't come for free.

It's not a commodity.

Now we start getting into season three, which is things start to get really interesting.

So then you can explain...

embodied experience as being socioculturally situated that is dependent on the embodiment that you have.

And that embodiment that you have is what is going to somehow determine where you are navigating continuously between freedoms and facticity.

And she puts it even more precisely between agency and objectification.

And then you start giving reasons to how you navigate the social cultural world.


SPEAKER_01:
Wonderful.

Yeah, yeah, yeah.

It's the first time I've had Simone de Beauvoir brought up in an active inference conversation, but that's great.

Yeah, it's a wonderful segue actually into existentialism and phenomenology.

And we're big fans of Merleau-Ponty and Heidegger and Dreyfus on this podcast as well.

I thought what you said was interesting, which is that

As you said correctly, the free energy principle is a principle.

It's like Hamiltonian's principle of least action, right?

It's the first principle's ontological explanation of just like what, in the case of the free energy principle, what things have to do if they're going to continue through time to persist.

But active inference, or in certain cases, predictive processing, or in certain cases, computational theories of mind, or in certain cases, inactivist theories of mind, are what we call process theories.

So if we take the free energy principle just to be axiomatically true,

In the sense that it's kind of, and I think Carl would say this himself, if you actually put it down to its nuts and bolts, it doesn't say too much, right?

It's things do what things have to do to continue to be the things that they are, really.

And there's a lot of fun maths, but it's really about how it's implemented in us or artificial intelligence or whatever it is.

Those process theories become falsifiable.

So predictive processing might not be the right account of continuous state space, active inference, or perhaps the mind is fundamentally downstream on the body in a radically embodied way.

I guess because it's falsifiable,

A question that came to my mind when you were speaking about activism and the history as well of cognitive science is, as you say, there's very few people who will adopt a radical computational position these days, a la Descartes, a la John Searle, for example.

But for me, cognitive science is very popular, to put it simply.

Can you envisage a future where future science and future philosophy tell us that viewing the mind as embodied, enacted, embedded... What was the last one?

Go on, Wikipedia.


SPEAKER_00:
Yeah.


SPEAKER_01:
Is not the right way to view it as we now look back on the computational picture and think it's incomplete.


SPEAKER_00:
Yeah, okay.

So I'm going to go back to the goggles.

It seems that...

So science is built on first steps, on the goggles that you put, and then you end up with certain kinds of theories that now you have.

And now what do I do with this?

I test it.

I see if it makes sense.

In the case that it doesn't make sense, we don't know, but it is about putting these goggles.

A lot of what is done still in cognitive psychology is very Descartes, is very starting in season three in like, okay, minds are mental representation.

So nobody cares about things that, or about experiments or setting up experiments or thinking or reasoning about how did it come to be?

where we should put more effort on how it came to be, which is what, by the way, dynamical and complex systems theory applied to psychology does.

That's all they do.

All they do is to focus on the developmental trajectories to understand how they evolve and develop, how states change into developing and evolving.

And much of what is done in cognitive psychology is starting in season three.

The mind is representational.

And now we got to find that not only in our cognitive psychology experiments as we design our experiments, right?

Is with that assumption in place.

And that's why this is so...

It may be the case that one is right to think that the mark of the mental is mental representation, but not criticizing it and not having a critical point of view about it.

What it means is that everything that we do within cognitive science, within setting up experiments, within setting up computational models, simulations, it's going to be starting with the assumption that the mark of the mental is mental representation and that the brain is an information processing machine.

So this is going to be defining for everything that we do.

And all that I'm saying is that let's take a step back and go to the beginning of the series as opposed to starting in season three and question these things.

And if they still make sense, great, we've done a very good job.

So that's the point of view.

And I think that what e-cognition, the more radical view does is it takes away those toys.

and puts you into, okay, when you have to start from the very beginning, what do you have and how do you build?

So it puts things into pressure on whether that is the case, because when you do the bit of the history of philosophy of mind, and you realize that a lot of it has been done by borrowing conceptual toolkits from computational science, then you ask the question, what is left

for philosophy of mind.

Is there a philosophy of mind?

Or is there a borrowing conceptual toolkit from computer science?


SPEAKER_01:
Now that is a, that's a provocative question.

I'm not going to, I'm not going to try and answer it.

It's cool the way you talk about the scientific theories.

It reminds me, we had Mal Al-Barassad on as our second guest.

And actually on the day of us recording this, the podcast just came out.

So everyone should definitely go watch it.

But we had a long chat about epistemic communities and the kind of silos that people end up in.

And that's actually very much akin to what you were saying, that people can really end up stuck in their scientific paradigm.

And I'm really hoping that doesn't happen to me.

In fact, I think it kind of happening already.

I mean, it makes me think the, my, my sort of philosophy of science is not as good as it should be.

And it should get better that I'm aware of Thomas Coon and this idea of the paradigm, the way it sounds to me is that like, I don't know, I'm adopting a kind of moral Hegelian perspective where.

you've got the computational theory of the mind and inactivism, like radical inactivism as your thesis and your sort of antithesis.

And you have this dialectical relationship, right?

And then what you might end up with is a synthesis.

And that might, I don't know, it's a very broad question, but do you see science unfolding in that manner?

Or is it kind of more of a incremental pursuit towards a higher or getting closer to truth?


SPEAKER_00:
So, yeah, you do have those two different paradigms and I would answer that in a very clear way.

I think that all that we have in the computational theory of mind is our human socioculturally situated experience as a human species best efforts to understand a phenomenon in the natural world.

So we develop all of this computational machinery, strategies, models, et cetera, because this is what makes us human.

We want to understand the world around us.

And part of the world around us is human beings, right?

So then we have all of that as a reflection or as telling or as a manifestation of what we can do as a species when we come down to being epistemic communities.

And these epistemic communities are, and Mao was absolutely right, are completely socioculturally situated.

So science itself, like our own individual experience of the world, does not occur in an encapsulated manner.

We could aim...

for an ideal bird's eye view perspective of doing science in a way that is completely objective.

But as Wittgenstein already told us, we don't have that.

We cannot get out of the trajectory that brought us here.

We cannot have access to that other perspective, only our own, and that is going to be biased.

And overlooking that, it's dangerous.

Because one would claim that that is possible.

And that's not, that's why our best capacity as a human species is these epistemic communities where we can exchange ideas, test ideas with each other, give feedback to each other and improve each other's thinkings and experiments such that we improve in a collective effort that is scientific.


SPEAKER_01:
Wonderful.

I like that.

It's spiriting.

I don't write the idea that we're just stepping on the toes of our ancestors.

Maybe they did have something good to tell us and we can build together.

But maybe never get there because we're blinded in some sense.

I mean, obviously, where one cannot speak, therefore one must be silent.

In this case...

we could go on forever and i do want to make it clear that your work is incredibly broad and diverse and touches on a wonderful range of things so we could have spoken about religion you have a wonderful paper on religion from an active influence perspective um autism among other things uh we didn't even touch upon artificial intelligence agents um so there's gonna have to be around two i suppose

It has, where can people find your work?

What are you working on?

What have you got coming out?

Where can people find you?

Because I'm sure they'll want to know more about what you're doing.


SPEAKER_00:
Yeah, just on my website, that's usually what is updated, which is www.EnergyPolito.com.

So usually there you got the links to other places like publications, et cetera.

And on Twitter as well, I'm usually active.

So anything that comes out, any conference that I'm organizing, I'm participating or papers that are out, I always share them on my Twitter.

So that's usually the places.


SPEAKER_01:
Super.

Great.

Okay, that's wonderful.

Well, it's half past 11 UK PM.

So I need to dash off to bed.

But this has been an absolute pleasure.

Ines, thank you so much for your time.

And yeah, as I said, we should definitely do this again.


SPEAKER_00:
Oh, thank you so much.

What a terrific, exciting conversation.

Thank you so much.

And definitely up for round two.


SPEAKER_01:
Wonderful.

Thank you.


SPEAKER_00:
Thank you.