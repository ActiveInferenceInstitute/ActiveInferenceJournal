SPEAKER_02:
Hello everyone, and welcome back to Active Inference Insights.

I'm your host, Darius Parvizi-Wayne, and today I'm absolutely thrilled to be speaking with Professor Chris Frith.

Chris is a neuropsychologist and a pioneer in the application of brain imaging to the study of mental processes.

He has contributed more than 500 papers to peer-reviewed scientific journals, and is known especially for his work on agency, schizophrenia, and social cognition.

Within this latter field, he has worked extensively with his wife, Professor Uta Frith.

Together, they have published seminal papers on theory of mind and social signaling.

And last year, they published the book, What Makes Us Social?

Again, it is no overstatement to say that Chris possesses a legendary status in the spheres of psychology and neuroscience.

And so it is a real honor on my part to be chatting to him today.

Chris, thank you so much for joining me and welcome to the show.

Well, thanks for those nice words.

You're welcome.

Are you in London currently?

It's a beautiful day.

Yes.

albeit a bit frosty.

Excellent.

So as I mentioned in my introduction, you root many, or you ground many of our social capacities in mentalizing, which requires theory of mind.

Now, some of our audience might not, we, our audience is diverse, you know, brings in people from maths, physics, all sorts.

They might not have a psychology background, so they might not be aware of what mentalizing or theory of mind actually is.

So it might be worth just setting the stage and giving a brief exposition of what those terms mean, if possible.


SPEAKER_00:
Right.

Yes, theory of mind is a rather misleading phrase, because it's not a theory of how the mind works, and it's probably not even a theory.

So mentalizing is a slightly better term, I think.

But the idea is that one way into this is to say we're trying to predict

is useful to be able to predict what people are going to do and to understand why they're doing it.

And theory of mind originally said people do things because of their hidden mental states, such as beliefs and intentions.

So if somebody takes an umbrella with them, this doesn't mean that it's raining.

It means that they believe it is raining or is going to rain.

And the key, um,

to the experiments on people's ability to understand these hidden mental states is the impact of false beliefs.

Because if you know it's not raining and this person goes out with an umbrella, then you can say he has a false belief that it's going to rain, and his belief is different from mine, and I have to take this into account when I predict what he is going to do.

So that's basically what mentalizing is about.

That's the process of predicting what other people's mental states are.

And mental states meaning things like intentions, beliefs and desires.

And we think that this is probably different from understanding people's emotions.


SPEAKER_02:
Yes, I can imagine a lot of people make that conflation.

I guess a further thing to unpack there is

when people hear about sort of mentalizing, they might think of autism and the associated difficulties in mentalizing that seem to be associated with autism.

But over time, uh, many autistic people use heuristics or tricks or social cues to mentalize.

Is there a difference?

Because behaviorally they might manifest similarly permit kind of harmonious social interaction.

Oh, it's theory of mind or mentalizing committed to saying that, uh,

those who are mentalizing actually have a mental representation, a kind of recursive mental representation of what the other person is thinking.


SPEAKER_00:
Well, that's what I think.

I don't think everybody agrees with that.

There is, I mean, more recently, there is evidence that there are two, I mean, depends on how you decide to talk about it, two levels of mentalizing, which some people say the lower one is not really mentalizing, but that is to say some sometimes called behavior reading.

that you can make many of these predictions without needing to know about other people's mental states.

And it's also, in some sense, automatic.

So it happens you don't have to think about it, you just know this is the right way to behave next in this interaction.

And in relation to autism, there's some suggestion that it's this lower level part that they find difficult and that the heuristics, as you call them, are in fact something that we all use.

So there's this thing called folk psychology, which is supposed to be inferior, but I think is actually very important, which is that we know

This is the idea that people do indeed behave because of their beliefs and desires.

And that's how we can predict their behavior.

And this is a cultural phenomenon.

So in different cultures, you may have different ideas about how folk psychology works.

And in particular, there's some anthropological work on the certain people who come from the Pacific Rim, which includes

Mayas in Mexico and Fiji and these various other places where they There's a cultural Attitude that it's impossible to know what other people's mental states are.

Mm-hmm And that you shouldn't bother to try and in fact children are brought up not you know You shouldn't be doing this sort of thing.

You just look at their behavior and it even extends to sort of interesting semi-legal situations where in the West

we're very concerned that it's the intention that counts.

The intention is more important than the outcome.

Whereas in these other cultures, the outcome is all that matters.

And even if it's an accident, you'll be punished equally.

So there's an interesting level of, I think, cultural effects on some of these mentalising stories.


SPEAKER_02:
Yes, philosophically, I certainly have issues with that, but we won't go into that too much.

Yes, that's interesting.

I guess because it also maps onto our scientific institutions and our way of actually viewing what's going on mentally.

I can't help but notice that we are presupposing mental representations even when I ask that question.

And I've been sort of delving into the world of radical inactivist cognition.

And they would say, well, there are no representations.

There is no content.

All we have are these dynamic relationships between or these dynamic couplings between agent and arena.

Does that

Is that, does theory of mind collapse if we just permit that these are, I guess they talk about sort of perceiving correlations in the environment.

That's something that they're very excited about, but actually this isn't a, you know, this isn't necessarily a representation or intentional stance.

Does it, does it, is it compatible with these sort of ramped up versions of an activist cognition?

Hello, everyone.

And I do apologize for interrupting the flow of the conversation with Chris.

I wanted to add this little bit because I realized upon watching the conversation that I had with Chris, at this juncture, I did misspeak and misconstrue and overgeneralize the claims of REC, at least explicated by Hato and Mayan.

So I made it out as if they say that all cognition is contentless.

This is not actually what they say.

They say that basic mind or basic cognition is contentless.

whereby basic cognition means all cognitive activities except those involving public language and cultural symbol systems so again they do not say that all cognition is contentless because they because there are also these higher order forms of cognition which might be content involving and again those require public symbols social practices of symbolic uh communication so they're therefore governed by semantic norms and these correctness conditions

So where the theory of mind is that, that higher order form or lower order form, I guess, is for you to decide.

But you'll see later on, I speak about these kind of scaffolded developmental capacities, which might involve content as if it wasn't part of the theory of heart and mind, but it is.

And so I really wanted to clarify that before this goes, before this podcast goes live again, just more broadly.

I do want to take responsibility as your podcast host for saying things are accurate and truthful and owning up when I make mistakes.

This was one of those places I would have edited out, but it really would have messed up the flow of the conversation.

So I thought it was easier for me to just come on here and clarify that I made a mistake and hopefully clear up any confusion.

Again, I don't mind too much if I mess up describing what I think because they're my thoughts, but I know that authors far more senior than me have put a lot of time and a lot of effort into their accounts, and so it would be doing a disservice to them, a disservice to you, if I misconstrue or misspeak when describing their thoughts and their writings.

So when I do this again, because, you know, in the heat of the moment, in the moment, I will make mistakes as I did here.

And again, it's just because these are live conversations I'm having to think on my feet.

But when I do it again, because unfortunately I'm fallible, please do tell me.

I will always look out for it.

I'm happy that I spotted this one.

But again, I feel a very strong responsibility to be as accurate as possible.

So that relies on you as well.

So please do inform me when I make a mistake.

And I will not keep you any longer, because this is a cracking conversation with Chris, and I hope you enjoy the rest of it.


SPEAKER_00:
Yeah, I'm not very keen on these ramped-up versions.

It's conceivable that this might be a useful way of looking at the sort of automatic mentalising, but I think the sort of cultural folk psychology story

very much depends on representations.

I mean, we almost were talking about them.

There's a philosopher called Davidson, and I can't remember precisely what he said, but it's all about applying rational arguments to what we believe are these mental states.

So you're saying if he believes that the chocolate is in the cupboard, he will go and look in the cupboard.

It's the sort of philosophical approach to this.


SPEAKER_02:
Yeah.

I mean, no, as you say, I mean, these are, uh, sort of an activist cognition on steroids.

Um, that of course people, and I don't think you would disagree with them that recognize that if there are representational schema, those are built off scaffolds that occur from social cognition, developmental psychology, being with others.

And I don't think you would disagree with that.

And that is something that I want to touch upon, um, in terms of self modeling and self perception.

But yeah.

Um,

Actually, I'll backtrack.

I don't think they would say that cognition is non-intentional, just that it's non-contentful or non-representational.

But there are obviously quite severe critiques of that.

And there probably are of representation as well, as they make clear in their works.

So now expanding that out to away from didactic or not didactic, dyadic interactions into broader social contexts.

Why going beyond just

the coupled duo?

Why is theory of mind or mentalizing so important just for social institutions more broadly?


SPEAKER_00:
Well, I would claim that we don't think that necessarily.

We think that

that some people seem to equate social cognition with theory of mind.

Right.

And we do not.


SPEAKER_02:
Sure.

Okay.


SPEAKER_00:
Let's clarify that.

Yeah.

So we think there are all sorts of social cognitive processes that are not to do with representing mental states or whatever.

And many of those might be more relevant to larger group interactions.

And we talked about having what's and the original paper that we read,

in 1999, I think, which is sort of starting in social cognition.

We had mentalizing on one side and we had mirror neurons on the other side because they had only recently been confirmed.

And mirror neurons are all about how we can imitate others and how we get, what's the word, contagion from others.

So for example,

emotions are contagious.

We tend to feel the emotions that other people are expressing.

We tend to do what other people do.

We imitate their actions.

And one very important aspect of human sociality is over-imitation.

Do you know about that?


SPEAKER_02:
Yes, I've seen some of it in sort of linguistic innovation, where a language learner learning another's language will over-imitate.

And so there'll be sort of

They'll all speak in RP, for example, even though no one's spoken in RP since 1910.


SPEAKER_00:
Yes, but I haven't thought about it so much in that respect.

It's more to do with simple actions like shaking hands.

And you have to do it in the right way.

And the early experiments where they had these puzzle boxes which you have to solve by going through a series of maneuvers.

And the trainer puts in a couple of maneuvers that are not actually necessary to open the box.

But the children all imitate these as part of the, that's the over-imitation bit, so that they do them even though they're not necessary.

And the interesting thing is that chimpanzees don't.


SPEAKER_02:
interesting so this is we're imitating not to get to the reward we're imitating to show that we are doing it properly we are part of the group we are the people who behave like this and they're all yes yeah so it's kind of in a sense directed at what in active inference terms kind of a higher a higher order prior uh yes that's very interesting yeah i mean um i guess to

return to my initial question.

Yes, I recognize it might be an overextension of theory of mind.

I didn't mean it in terms of everything is theory of mind.

Clearly not the case, because then it would be sort of serious cognitive overload if I was just mentalizing everyone and everything.

And it sounds borderline schizophrenic to be thinking that, you know, my chair has intentions.

But it seems to me that

even in making or acting to confirm that higher order prior that, uh, I am like you.

And so you're going to like me and we're going to be able to establish this recursive relationship.

I need to have at the very fundamental of that, a notion that you are an intentional conscious agent, which kind of seems to me to be a very low level form of theory of mind.

It might be implicit in our interactions, but that still seems to be present.


SPEAKER_00:
Yes.

That's a very interesting idea.

Um, one of the things that we've written about is sort of addressing this question.

How do we know when we're wanting to in competitive situations and which usually means you're playing an economic game like hide and seek.


SPEAKER_01:
Yeah.


SPEAKER_00:
Um,

you need to know what sort of agent you're competing against.

Sure.

And, um, if it's a very, you know, it could be a completely random agent that just is biased.

So it's very easy to beat one of those, or it could be a simple learning agent that, um, depends on what's, you know, the pattern of reward in the past.

And it's fairly easy to beat one of those.


SPEAKER_01:
Hmm.


SPEAKER_00:
And the most difficult ones to beat are the ones that are intentional and are trying to predict what you're going to do as well as the same time as you're trying to predict what they're going to do.


SPEAKER_02:
Like rock, paper, scissors or something like that.


SPEAKER_00:
Yes, and then that's where you get into this infinite recursion where you say, does he have a representation of what I think he's going to do next?

Yeah, yeah, yeah, yeah, yeah.

And what is interesting, at least the bits of information I have, it's very difficult to work out that you're competing against an intentional agent from their behaviour.

And therefore we tend to depend on our prior.

If we think it's an intentional agent, we'll behave in such and such a way.

If we think it's not, we won't.

And there's this nice experience from...

John Donizzo's group in Paris, where he has people, he has artificial agents that can do recursive tom.

And he has people playing against them, you know, at various levels.

You can have zero tom, one tom, two tom, and so on, in terms of recursion.

And if you tell them they're playing against a one-armed bandit, they assume that it's not intentional and they lose.

when the agent is functioning at two levels of recursion, even though they have several hundred files.

If they think it's a person, they will adopt the high-level strategy.

And of course, this is reasonable because

this high level mentalizing is extremely cognitively demanding.


SPEAKER_02:
Yes.


SPEAKER_00:
So you're going to avoid going to that level if you can.


SPEAKER_02:
Yes.


SPEAKER_00:
And there's this nice, and they do know about the beauty contest game, which is a nice example of this suit.


SPEAKER_02:
I don't.


SPEAKER_00:
Ah, this is invented by John Maynard Keynes.

Anyway, the task is you're part of a group,

everybody has to produce a number between one and a hundred and the person who produces half the mean production will win.

Okay.

Key Keynes called it a beauty contest game because when you have to say who is the most beautiful person is not who is the most beautiful person, but who people think is the most beautiful person.

Anyway, the argument is you have to think about what the other people are going to do.

And you think if they're completely stupid, then 50 will be the average number and therefore you'll win with 25.

If they're not completely stupid, they think it's going to be 25, therefore you'll win with 12.5.

if you've read about Nash equilibrium, you think everybody's super rational and you're saying one, so you always lose.

Um, and the average, I mean, there've been huge experiments on this in newspapers where they get thousands of people to take part.

And the average number of level of recursion is two and a half.


SPEAKER_02:
Interesting.

Yes.

It has to be a cutoff.


SPEAKER_00:
This is what we call, I think Carl would call it bounded rationality.

Yes.


SPEAKER_02:
Yeah.

Yeah, well, yes, I guess it's also, I guess in some sense to do with the depth of your temporal hierarchy, um, because each recursive step seems to me at least to be kind of a, an N plus one in your kind of information space.

And so you'll just go into the next one and it has to be an end at some point.

We can't plan forever.

That's fascinating.

Okay.

That's fascinating.


SPEAKER_00:
Yeah, no, that's, that's the other game I'm interested in is the, um, stag hunt game.

Yeah, I know the fact.


SPEAKER_02:
Yep.

Yep.


SPEAKER_00:
And that's, again, seems to be recursive, because if I'm going to hunt stags, I have to believe that you're going to hunt stags, and I have to believe that you think that I'm going to hunt stags.

And it seems to me the heuristic there that solves all this to say, we are cooperative people.

And I don't have to worry about this.


SPEAKER_02:
Yeah, a couple of things come to mind there.

I mean, Dennett, as I'm sure you know, has this notion of an intentional stance.

You think that maps

ontologically onto our sort of priors, in some sense that we, we start off with the notion that things are intentional, animate, conscious, however you want to term it, and then we start pruning?

Or is it the other way?


SPEAKER_00:
I think it's, I think it's the other way around.

We want to start with the idea that it's all very easy.

Yes, yeah, yes.

But we do have, I think we have a prior that people are intentional.


SPEAKER_02:
And would that be, and would we get that evidence from the phenotype of people, so to speak?

So, so if you have a similar body to me, you move in a similar way to me, you speak in a similar way to me.

That is evidence to confirm that prior, but I guess it has to be an evolutionary prior, quite a non.

conceptual level, because evolution doesn't work like that.

It's not gonna say if you've got if you're six foot, you're an agent, right?

It's, it needs to be a little bit more subtle than that.


SPEAKER_00:
Yeah.

But certainly, there's this somewhat discouraging work on in groups and out groups.

Yeah, groups are considered to be less intentional.


SPEAKER_02:
Gosh, yeah, that's quite terrifying.

Yeah.

Yeah.

But that said, I mean, we do have it makes me think of the fusiform facial area.

And the fact that

That certainly constitutes some kind of perceptual prior, at least.

Excellent.

That's very good.

I mean, I was listening to an interview that you and Uta did with, I think it was the dissenter.

It would have been about a month ago.

And I think I just was listening to the beginning and Uta, I think it was Uta mentioned that we could consider cognition all, like entirely social cognition.

So all cognition is social cognition.

It makes me think my master's thesis was exploring what's called social baseline theory.

And I wonder what you thought about it.

I'm not sure you're aware of social business.

So this is a kind of, the experimental work for it started in sort of 2006, 2007.

And then the theory was fleshed out sort of early last decade.

So this is people like James Cohen.

I think it's Cohen.

It might be Cohen, Elizabeth Gross.

These are people that the audience can search up.

But the notion is, is that the primary ecological niche we find ourselves in is social.

Yes.

And so what that means is that the human brain for adaptive reasons expects social resources because it, and in doing so it, that acts to mitigate risk and also preserve energy expenditure.

Yes.

So what they then say, and why it's called social baseline theory is that being with others constitutes a cognitive baseline.

So that when we actually put people in an FMRI scanner and we get them to do a task alone, which is the standard in cognitive psychology.

we're actually viewing them as a deficit because they have to engage in all of this self-regulatory processes that they would be doing to a lesser degree if they were trusted others.

How does that sound to you as a theory?


SPEAKER_00:
Oh, I love that.

I'm very sad that I didn't know about it until now.


SPEAKER_02:
There's these really beautiful experimental studies.

I think the most famous one is that people perceive a hill to be less steep if they're with someone else.


SPEAKER_01:
Oh, yeah.


SPEAKER_02:
Because I think the...

perception in some ways, I guess it feeds into a broader question about to what degree is perception influenced by top down factors?

Is it modular?

I mean, I come from active inference something no, like it's definitely influenced.

But I think notion is a perceptual.

Yeah, a percept is influenced by your notion of how much effort is going to be in some sense, the affordance, how much effort is going to be to exploit that affordance.

So being with others reduces our efforts.


SPEAKER_00:
No, I think that I would entirely agree with that.

And there's other experiments that we did talk about in the book, which I didn't know how they relate to this.

And I'm not sure whether the baseline people know about it.

This is about affordance.

This is this business.

If you have a table with mugs on it, you can show that

you will get, when the mug appears, as it were, if it's within your reach, you will get activity in motor cortex.

And there's a social version of this.

If there's a second person sitting at the table,

Even a mug that's out of your reach but in his reach will activate the motor system so that you're treating this as sort of group affordance.

I call it the we mode.

It's within our reach.

And that seems to happen automatically.

So that's entirely consistent with this.


SPEAKER_02:
That is wonderful.

I guess in some sense, from an active influence perspective, it's worth predicting others' actions as if they were our own because their actions are so...

influential on personal outcomes.


SPEAKER_00:
But I was thinking more, it's like the monkey and the rake, we can use this person as a tool to get Yes.


SPEAKER_02:
Ah, yes.

Ah, okay.

So mine was a bit more generous.

I guess it was a little bit more altruistic.

Okay, okay.

Cool.

Yeah, that's, that's, that's an interesting.

That's an interesting stance on it.

I guess.


SPEAKER_00:
I mean, the answer, you know, a test of that would be for the other person sitting at the table is your enemy.

Would it would you then not get the affordance from the things?

Yeah.

Has someone done that experiment?


SPEAKER_02:
I don't think so.

worthwhile.

An interesting experiment for experiment that I think you've used and Carl has used is let's say we're on some exoplanet and it's just me.


SPEAKER_00:
Yeah.


SPEAKER_02:
I don't I want to leave the questions about agency and sense of self for a bit.

Because I do want to get there.

That's kind of more my

Speciality, the work that I focus on is more to do with self modeling, but we say, okay, all cognition is social cognition.

It's built into us.

It's, it's our baseline.

We have social priors.

Therefore, what happens when we start denying evidence for those priors?

If I'm in the planet, which was just end of one.

And I guess, are there differences there for, if that was always the case versus I've just been plopped there and I've now I have a memory.

in some sense, of being a social creature, which is now being denied to me.


SPEAKER_00:
I think, yes, there would be a huge difference.

If you just drop there, it's a bit like being put into solitary confinement.

I'm sure you will start thinking about the past or making up stories or about social interactions and so on.

And I was thinking also your nice point about being an MRI scanner all by yourself.

I suspect what most people do when they're an MRI scanner all by myself are thinking about what on earth is the experimenter doing this for?


SPEAKER_02:
Sure.

I think that when I get x-rays, actually, I'm like, why are they doing this with the blocks of lead and stuff?


SPEAKER_00:
Yes.

If you'd never had social interactions, I would think you would be, well, in the extreme, I had a strange interaction long ago with Christophe Koch talking about

I was trying to talk about, you know, what's the function of consciousness and I was putting down with it's all social.

So my argument would be if you were never had interactions with other people, you would not be conscious.


SPEAKER_02:
I think Carl has a similar.

Yeah.

Yes.

And what was Christoph's response to that?


SPEAKER_00:
Consciousness is in these special neurons.


SPEAKER_02:
I don't think that one's got very far.

Sorry, Christoph.

You're far more senior than me, but I don't think that one's got very far.

And he lost that bet to David Chalmers.

I think he had to give him that case of wine.

So I think he lost.

Well, that's a really interesting point.

Let's go there then, because as I said, this is really where I want to go is this self-modeling.

I'm thinking, and again, this is something that I've spoken to Carl about and I've heard Carl mention, which is that we need in some sense to be able to infer the agency of others or their self-model to be able to apply to ourselves a self-model.

Um, there's a wonderful paper.

I like shouting out papers here so that people can go read and also just to give credit where it's due by Jacob Howie.

Um, and I think his last name is Michael.

I'm not sure what his first name is and it's called, why does anybody have a self it's any body too much.

And they talk about sort of cultural imitation as really being foundational to the development of a sense of agency in the sense that I'm going to shape myself model on what I see as kind of optimal agentic behavior on the part of others.

Yeah.

So.

I guess the question here is how necessary is this capacity for inference of the agentic state of another or the mental states of another for our own formation of agency and selfhood?


SPEAKER_00:
I certainly think that selfhood depends on interacting with others.

Though I think you could get quite a long way without doing mentalizing.

It could be based on behavior to a certain extent.

But one of the things that we talk about quite a lot in our book is reputation, which is very important economically.

Adam Smith, who invented economics, talked about

he didn't call it reputation, I can't quite remember, the esteem with which other people hold you in was more important than wealth.

And what the main driving factor in human behaviour is to get the esteem of others, to have a good reputation in other words.

Though sometimes money can be a sort of marked proxy for this.

And there are all sorts of interesting experiments on this because if you have a good reputation then people will trust you, they will choose to work with you, and they will invest money in you and all that sort of thing.

And then you have a very interesting arms race.

with the free riders, because you want to have a good reputation, but you want to cheat people at the same time, and then you have to, that's why being anonymous is jolly useful for this sort of competitive situation, because no one, you don't have a reputation that carries with you.

And it seems to me that reputation is an important aspect of the self.

And of course, the reputation is not in you, it's in the minds of others.


SPEAKER_02:
Yes, exactly.

But in some sense, it then gets transferred onto you.

I mean, I think it's quite classic literary trope in some sense.

I've mentioned Luigi Pirandello before.

I don't know why, but he's come up again here.

He's got a very peculiar book called

Uno Nessuno Cento Mila, one, no one, 100,000.

The notion is that these are different ways of modeling oneself.

And what he goes around doing in this book, his protagonist, is he goes around trying to spot himself in mirrors so that he can perceive himself not... So he's trying to catch himself looking at himself not as others would perceive him, but sort of in this raw moment of self-perception.

And he eventually dissolves or goes a bit mental.

Yeah, that's one thing that came up into mind.

This is a far more folk or popular culture thing.

There's a very interesting show on the BBC right now called The Traitors, which I highly recommend.

It's about sort of 20 people in a castle and three of them are traitors and 17 of them are so-called faithfuls.

And they have to kind of guess who's who.

And if the traitors stay in, they win all the money.

If the faithfuls stay in, they win all the money.

So there's some trash reality element to it.

it's a very interesting psychological recursive thing where there's lots of triple quadruple bluffings going on so that's really that in inaction and reputation yes plays a very big role in in trustworthiness and you're watching that as the objective sort of god-like figure and say well how could you not see that this person is so maligned um but you're not there in some sense okay that's that's interesting i guess

A further question I had, and this is actually something I would love to explore personally.

Um, cause I don't think anyone's done that much work on this.

Um, so I've, I put this down as a sort of thing that I might want to explore in the PhD, which is that we seemingly have homogeneity in self-modeling.

Um, so there are certain things that just come out of the literature here.

I'm thinking about people like Danza, Danza Harvey and Sean Gallagher and, um, Yakob that it's in some way in the rational, in some ways it's, uh, epistemic.

It's somewhat coherent.

Um, again, this goes all the way back to like people like Derek Parfit.

Um, but it's, and that is homogenous across us.

I was wondering, do you think that that is a, quite a thought I had is that that's rooted in the fact that we all engage in similar processes to arrive at that self modeling, to arrive at that self conception, namely inference about others.


SPEAKER_00:
Does that seem reasonable?

Yes, I'm not sure.

I mean, I would have thought that there's a I mean, I'm not sure are you saying that because of our in inherent individual cognitive processes being similar to others, we arrive at the same end result, in some sense, but it's a little bit more specific in the sense that, let's say I'm a, I'm a child, and I watch my parents enact


SPEAKER_02:
presumably agentic behavior.


SPEAKER_01:
Yeah.


SPEAKER_02:
My model of agentic behavior therefore starts to align with theirs.

And what I do is I in according to active inference, I act in order to provide evidence for that prior.

And so you see this kind of convergence over time on a self model of course, there's going to be variety, but these core features are present.


SPEAKER_00:
I would think that that certainly has a role, but I think there's also a role of a sort of top-down cultural effects.

So you're told this is what agents, how agents behave.

Right.

As I was saying, you're told, I mean, even the very simple level, you're told that people, you know, when people are, if people are eating a lot, it means they're hungry.

I mean, even at this simple level, our behavior is determined by our desires.

is something that to some extent is top-down imposed.

But I was thinking, you were mentioning all these various people.

There's an interesting Galen Strawson objects to this narrative story.

Yes, he does.

And I'm inclined to, I think there are different individual differences in this.

I have no idea.

I don't have a plan.

I never had a plan for my life as it were.

Me neither, yeah.

And I might be a quite different person next week.


SPEAKER_02:
Yeah.

So, so yeah, Galen's critique is very apt here.

And here, I guess he's kind of actually criticizing Dennett because Dennett is quite keen on talking about the linguistic form of this narrational sense of self.

Jacob Howie's got a similar point there, which is that maybe we can replace the word narrational with it's not as catchy, but something like a predictive coherence or hierarchical

constraints or something like that in the sense that the higher levels of your uh generative hierarchy are tracking lower levels and so your preferences right like i like ice cream is going to dictate my behavior in the moment that i'm more likely to go get ice cream and that feeds back and forward right i think that maybe we could just i i don't know what that term would be um but no i think it's a reasonable critique cool that's interesting yeah let's um

Let's go to consciousness then, because it was something that you brought up.

Um, so there were two quotes that I'll read back to you, if I may, that you've said, and I'm curious about what you think these are from papers.

I haven't just, I was a completely different person then.

Yes.

Yes.

Yeah.

That's right.

Yeah.

Very dark profit.

There are lots of you.

Um,

In 1995, this is a while ago, in a very, I like the title of this paper, consciousness is for other people.

You wrote, the primary function of consciousness is to permit high level interactions with other conscious beings.

And then this is, so that's about function.

And then in another paper you wrote, phenomenological consciousness is necessary for taking an intentional stance towards other agents.

To do this, we have to be able to treat ourselves as agents also.

I think we can just break off that second sentence, because we kind of touched upon that.

there's there's one point where it's function is interactions and the second one is almost nature the necessity for uh intent the necessity for consciousness to take an intentional stance i don't know which order you want to take that in but it would be really interesting to unpick both of those well i think


SPEAKER_00:
we've taken that a bit further actually start with the first one sure so this is a study on metacognition with various people particularly nick shea and cecilia hayes and the idea is and it but it comes from originally from our the work with bahadur which is about people working together you know this study i'm sure so people are working together to detect a weak visual signal

And we show that two people working together and coming up with a consensus answer are more accurate than the more accurate person working on their own in the right context at least.

And the reason that this happens is that they're able to tell each other how confident they are in their belief.

And on a trial by trial basis, you choose the answer of the more confident person.

So in other words, it depends on them telling each other about the phenomenal state, if you like.


SPEAKER_02:
Why?

I've come across as David Chalmers as parrot on many times in this in this podcast, and I'm going to do it again.

Why?

why is that necessarily the case?

So why could it not, why could it not just be an offline computation whereby we have two probability distributions that are just done completely like offline, non-phenomenal, they're just numbers.

Um, and you know, you have a higher order agent or, or one of them, you know, there's just a, there's just a algorithm.

If choose the higher one and none of this is done online, why do the lights need to be on, um, for that, um,

that successful interaction the information has to get from one mind to the other yes yes if if we presuppose that uh well what for adaptive behavior in this example yeah yes could that not be achieved also

with offline minds, I guess is my point.

Why do we need to invoke intentionality, qualia, subjectivity, all the fundamental tenets of consciousness?


SPEAKER_00:
I don't really quite understand.


SPEAKER_02:
So Chalmers in 1995 speaks about how you can give me a function of consciousness.

So whether it's like a global workspace, or whether it's binding, or whether it's this, and

But you can never tell me about how that function maps onto its phenomenal nature and why that function couldn't happen.


SPEAKER_00:
I think what's wrong with that is he's talking about the individual brain and I'm talking about interactions between two people.

And the key thing of the interaction is that they have to communicate with each other.

In this case, confidence.


SPEAKER_02:
Yes.

But could we not have something like an artificial agent, which has precision, which could be a proxy for confidence?

And they're not conscious, they just have done some mathematical computations, the inverse entropy, and this is my confidence.

You could have that with a large language model, for example.


SPEAKER_00:
So you would have to have, so your argument would be if you had two artificial agents, they could also get better than one working on their own.


SPEAKER_01:
Precisely.

In this situation.

Yeah, that would be my contention.


SPEAKER_02:
Not that...

I again, that doesn't discount the that doesn't discount the putative role of consciousness.

It just discounts or calls into question the necessity for consciousness, I guess.


SPEAKER_00:
Right.

But I mean, on the on the basis of that sort of experiment, we went a bit further, and started talking about do we actually learn from each other, how to interpret these

in the states that we have.

Um, and again, it becomes very intentional and the intro and I'm not sure if this is relevant or not, but when we talk to each other about how confident we are, we can actually, then you get in competitive situations, we can express more confidence than is actually justified in order to

in this experiment was to become an advisor.

So people would want to take your advice because you seem to be more confident about it.


SPEAKER_02:
That seems Yeah, yes.

My only concern, I guess, is that there are these interesting works coming out about sort of extended trust in mind robot interactions or mind artificial agent interactions.

And if I have a belief that even a robot is extremely

predictable and reliable and productive, I can offload a lot of my capacities to that robot.

And actually, if we were in this kind of task, I could very happily take its interpretation of the events or its position as my own, and I might receive great outcomes.

But I don't need to invoke in that any representational space within that robot.

Does that

in some ways not called into question, even something like confidence, metacognition, whatever it is.

Again, I'm not doing that.

I'm not calling into question the fact that it might be this.

It's more the necessity of it.

Anyway, it's an interesting little rabbit hole.

Consciousness does this.

Everywhere I've had on and we talk about consciousness, it leads into these rabbit holes.


SPEAKER_00:
We had an interesting discussion on Tuesday at the Institute of Philosophy, because they're all obsessed with large language models.

Yes.

And they were talking about, does it mean, does it understand what it's saying?

And it was interesting that the presenter was finishing up by saying, there is meaning, but it doesn't mean what it says.

So basically they decided that

together, the proper you had to have intentionality.

Right?

Yes, large language models don't currently have.


SPEAKER_02:
How much of this is sort of rooted in John Searle's work, Chinese room and excellent.

Yeah, it's good.

I like to see that

80s philosophy still has its role.

This is why I was sort of brought up on.

Excellent.

Let's now, it's not a jump, because I think the wonderful thing about your work is that although it seems diverse, they all sort of trickle down into these fundamental questions of agency and selfhood.

I want to talk about schizophrenia.

Yes.

And maybe we can start with the

very interesting symptom, which is delusions of control.

Yes.

So you spoke, you wrote very extensively on delusions of control.

So, again, people who are not schizophrenic or don't have a psychological or psychiatric background might not know what I mean by delusions of control.

So it might be worthwhile starting there, just outlining what that phrase means.


SPEAKER_00:
So this is where the patient says, it is not me,

causing these actions, there's some external agent making me do these things.

And they could be quite trivial things like combing my hair, or they could be more dangerous things like attacking people or something.

And this is interesting because there's a delusion

typically is considered to be a belief.

So you can say that they believe that external agents are causing their actions.

But it seems more likely, and the early psychiatrists had more or less stated this, is it's not so much that I believe that external agents are causing my actions, it's I feel as if external agents are causing my actions.

It's not just a belief in the sort of philosophical senses, something stronger than that.


SPEAKER_02:
Well, that's interesting.

So it goes beyond the propositional in some sense.


SPEAKER_00:
And there is part of a whole slew of symptoms called passivity phenomena, whereby you can say it's not my emotion, it's being implanted in me.

And the most perplexing one of all, they're not my thoughts.

Yes, I wanted to get to that.


SPEAKER_02:
That is very weird.

It might be worth, um, distinguishing the, uh, delusions of control from something like an alien hand syndrome, just so people don't be aware of this notion of a wandering hand.


SPEAKER_00:
So the alien hand syndrome is typically caused by a brain lesion.

And that's where the hand starts moving by itself.

And the patient says, I'm not controlling it.

Oh, I don't have control over it.

It's doing these things that I don't want it to do.

But typically the patient doesn't really say there's some alien force making it do these things.

And they try to stop it.

I mean, the classic, it's a strange love in the film.

If you do,


SPEAKER_02:
I actually haven't seen it.

I know.

I know.

I'm going to get shout to that in the comments.


SPEAKER_00:
Um, Peter is playing amongst many other characters as Dr. Strangelove, who's an ex-Nazi scientific advisor in a wheelchair.

And he keeps making these.


SPEAKER_02:
Well, it seems to have some strange overlap, perhaps with Tourette's.

Um, I'm working on, again, don't come at me.

I'm not saying they're the same, but it seems like that, um,

I've come up with this term called oppositional self-modeling, which is that at one level of some prior, at one lower level of generative hierarchy, you have a habitual action policy.

So you'll just do it, right?

So there's got to be some part of your motor loop where you will move your hand or you will do a tick, but then you have a higher conceptual level where you really don't want to do it because you want the type of agent that does ticks or does move your hand randomly.

So that's what I mean by the overlap there with Tourette's.


SPEAKER_00:
There's also utilization behavior after frontal lesions where people make these habitual responses in situations where they shouldn't, they can no longer inhibit them.


SPEAKER_02:
Okay.

Interesting.

Yes.

So in terms of delusions of control, perhaps you could explain to people where the model that you proposed for where this might come from, at least some of the versions of it in terms of the inverse modeling and forward modeling.


SPEAKER_00:
Yeah.

Well, I guess it goes back to Helmholtz who noted that when we move our eyes, obviously the image on the retina jumps about, but we don't perceive it jumping about.

And the idea is that we use what's so-called corollary discharge so that when you send the message to move your eye, you also send the message to the visual system saying,

there's going to be movement now, but it's not caused by something happening in the outside world.

It's due to my own eye movement.

And that applies to all sorts of movements.

And more recently, particularly associated with Daniel Wolpert, you have this idea of inverse and forward models.

So it says, when I move my arm, I actually have a forward model that tells me what, what,

where my arm is going to be when the movement is finished and what sort of sensations are going to be accompanying the movement.

And because I can predict them, I can discount them.


SPEAKER_02:
Yes.

So sensory attenuation.


SPEAKER_00:
Yeah.

And, um,

This is the difference between a passive movement and an active movement.

So in a passive movement, when somebody else moves my arm, I feel all these sensations because there's no discounting and that's why you can't tickle yourself.


SPEAKER_02:
Yes.


SPEAKER_00:
And the idea was that in schizophrenia, perhaps something went wrong with this system of control.

So it literally was the case that when they moved their arm, it felt as if somebody else was moving it.


SPEAKER_02:
Yes.


SPEAKER_00:
Yeah, and we showed, Sarah Jane Blatmore showed that they could tickle themselves.


SPEAKER_02:
Oh, really?

I didn't actually see, I didn't see that.

I'm aware of her work.

I know you've got, you three all did wonderful work in this, in this domain.

Maybe it's worth, um, unpicking exactly what that looks like.

Technically.

It's a shame that I can't get up all of the nice diagrams because there are some really nice diagrams, but it might be worth, um, talking about.

So people might think, um,

Okay, I want to move my hand to grip this mug.


SPEAKER_01:
Yeah.


SPEAKER_02:
This I love Dante mug, oddly enough, because I'm a bit of a Dante acolyte.

That's beside the point.

And I can just, I just know what motor action to employ and I just do it.

Yes.

I think you term that, I think that might be termed the inverse problem.

Why is that?

Why is that sort of folk psychology notion not possible for cognitive creatures like us?


SPEAKER_00:
As far as I understand it, the inverse problem is that whenever you have a goal of your action, which is to reach that mug in the appropriate way,

but there are an infinite number of different ways in which the movement could proceed.

And the question is, how do you decide which one to use?

And there are various arguments like, do you minimize the energy requirement or the distance?

Or I think, um, Daniel Walpert, I don't know whether he still thinks this thinks what you minimize is the end point error.


SPEAKER_01:
Hmm.


SPEAKER_00:
And they're always, so that's the sort of argument about, and also there are always different muscles you can use and it's all very complicated and luckily we don't have to think about it.

We just do it.

Yeah.

But underlying, there is something underlying all that and certain kinds of lesions you can becomes extremely difficult to grasp things.


SPEAKER_02:
Interesting.

So, so, so there are,

potentially infinite ways of choosing a suite of motor movements to achieve a goal.

So it's computationally intractable to find a unique sequence or a singular sequence.

However, we can predict the outcome of good sequences.

Now, that's a different point.


SPEAKER_00:
Yes, that is the critical idea with the inverse model.

is intractable to work out what's the best thing to do with a forward model.

Once you have given a set of instructions, you can predict precisely where you're going to finish up.


SPEAKER_02:
Okay, excellent.

So we've got the inverse problem, the forward model now, and if we then fold in what's going to be another kind of inverse type, which is the efference copy, what's the role of the efference copy here?


SPEAKER_00:
as far as I understand it, the inference copy is just a way of saying we can predict what sensations are going to arise from this movement.

And that's the thing that enables you to stop the image currently moving about because you're, you know what the movement is going to be.

And if the outcome is the real outcome matches the predicted outcome and everything is fine.

Yes.

But if it, in the case of schizophrenia, the prediction is wrong.

So it doesn't match the outcome.

So we explain this prediction error.

And one way of explaining the prediction error is saying somebody moved my arm.


SPEAKER_02:
I see.

And this, and does this require us in some ways to go to fourth insertion to say that action.


SPEAKER_00:
in some ways many people believe that thought is thinking is an activity this goes right back to luria i think in russian psychology um but this philosophically becomes very complicated because you can say um you have to say i intended to have a thought

Yes, and that's definitely, the Buddhists might have a problem with that.

If you're thinking about a problem, you would have some idea of what sort of outcome you want to have as you work your way through this problem.

And so there is room there for, you know, metacognitive approach to thinking.

So you could certainly say this, I have not succeeded in my thinking task.

yes exactly say i think i have a good even when you begin you can say i have a good chance of achieving this thinking task and i guess one might relate that to tip of the tongue phenomena where you say i can't remember at this moment but i'm pretty sure if i try a bit harder i should get there so these would be examples of putting thinking into a sort of active framework


SPEAKER_02:
Yes, there are some very nice metacognitive models, actually, or meta awareness models with an active inference.

So there's one by Lars Sandberg Smith 2021, which is very beautiful.

And these really rich base graphs with these hierarchical layers.

How so I believe there are, I believe there's good evidence that people with schizophrenia do not have major problems in motor control.

How is this accounted for?


SPEAKER_00:
Oh, yes.

Well, that's exactly right.

There's always a proper schizophrenic.

Whenever you come up with a serious schizophrenia, they should be much worse than they actually are.


SPEAKER_02:
Yes.

Yes.


SPEAKER_00:
But the, um, they do have, they have eye movement abnormalities sort of smooth pursuit and things like that, which would be consistent with failing to predict properly the consequences of eye movements.

I can't, there's a, there was a nice experience from Germany.

You can do strain.

How is this work?

You can do experiments where you have to track a moving target.

And this means that you, your expression is that the target stays in the middle of your field of view and the background moves.

No, it's the target that's moving in the background is stationary.

And you can, so you obviously have to correct for the sort of the moving background as it were.

And you can measure how much, how successfully people make these corrections and schizophrenia patients are less good at doing that.

So there are some subtle effects that you can see.


SPEAKER_02:
Yes.

Interesting.

Does this,

actually, I've got one more question before we go to delusions and hallucinations, because I sense those are slightly different.

I mean, this is in some sense a delusional belief.

So there's some interesting stuff.

There's some very, there's some very adjacent or actually overlapping work in active inference about agency.

And it's very much a offshoot of the comparator models and what we've been talking about.

So

And a lot of this is actually now being focused on depersonalization.


SPEAKER_01:
Yes.


SPEAKER_02:
So the idea I really like comes from George Dean.

He's got this idea of an allostatic control model.

And what that means is that if I can predict the sensory outcomes of my actions, very similar to what you were saying, and I get a sort of non-prediction error, I get the results that I expect, I can start to develop the inference that there is an agent in my generative model that does these things.


SPEAKER_00:
Right.


SPEAKER_02:
And what happens is let's say, let's say now that that's an inference and I need to keep providing evidence for that inference to keep it high precision.

Let's say now let's say I'm in a torture chamber.

This is an example.

Uh, torture is a very reliable, uh, producer of symptoms of depersonalization.

Right.

I'm now getting tortured.

I have a prior that I am the type of agent that should be able to do things to confirm evidence for my own model of the world.

in the torture situation, I might have a desired action, but I'm not able to actually do it and therefore provide sensory evidence for it.

And so what you start seeing here is the disentangling of that very inference that there is some, some agent, uh, at the heart of my generative model.

Does that, how does that sound to you?

Does it sound very much aligned with the way you think about agency?


SPEAKER_00:
Yes, I know.

I think that's very interesting.

Um,

I mean, I've been very interested in the feeling of being in control.

And there are experiments on that.

And I guess the torture situation is where you're totally not in control, which we luckily don't normally experience.

Yes.

I'm just trying to think.

Yes, I love this.

Go on, please.

I mean, it's a very Bayesian story that the feeling in control of being in control depends not only on the intention to do something, but also on the outcome.

Yes, exactly.

Exactly.


SPEAKER_02:
Yeah.

Yeah.

I I've been writing with car and others on so-called flow states.

Yeah.

Uh, flow states, uh, surfing, rock climbing, playing musical instrument in there.

Although you don't have this rich sense of self, this epistemic agent model, this propositional agent, you do feel in control.

And that is exactly as you say, because you have this alignment between the predicted consequences of your action and the actual sensory outcomes.

And there's very tight motor loops.

And I think it's worth folding in this notion of interoceptive inference as well.

So this is people like Anil Seth and Lisa Feldman Barrett.

This notion that at the very core, what Thomas Metzinger would call your minimal phenomenal self,

They've argued that this is rooted in successful interoceptive inference, either through autonomic reflex or eating, some actual volitional action.

And I guess something else there is that torture would also deny the possibility for successful interoceptive inference.

If I'm not getting fed, I am weakening, I am unable, that prior that I need to have a certain level of glucose is not going anywhere.

So I think what happens there is that the agentic model itself dissolves rather than the homeostatic requirements.

So there's some really beautiful work being done here.

Excellent.

Before we go on to delusions and hallucinations, I wanted to ask...

So my sort of forays into psychiatry are limited.

I'm more adept at cognitive science.

But I did read over the summer R.D.

Lange's The Divided Self.

I was curious, he's famous for sort of instituting a more, I would say, empathetic and understanding approach to psychiatry, that these people are not just crazy, right?

But they are what we would now say are actually base optimal, just confirming priors that don't really correspond to what we would see as adaptive behavior.

I was just curious about what your opinions are of whether you have any of Adi Lange and what he puts forward in The Divided Self.


SPEAKER_00:
I had no, I didn't have a very high opinion of RD Lang, but then this is mostly due to interacting with other psychiatrists.

Um, and I, I don't think I might've read the divide itself, but I don't think I did the idea.

I mean, put it into that Bayesian story is quite interesting because

That seems a very good idea.

That is to say they have the wrong prize, but they're behaving.

I mean, certainly all the stuff on delusions is the suggests that the original idea was that they're irrational.


SPEAKER_02:
Yep.


SPEAKER_00:
Whatever that means, whatever that means.

And that in other words, they are not arguing, you know, they're not appropriately arguing from the evidence and, um, all the experiments that ever been done show they're extremely rational.

They're probably more rational than other people.

And as you say, it's just that they start with the wrong priors.


SPEAKER_02:
Yes, there's something in Bayesian modeling called the complete class for a theorem, which is that any, any action perception can be cast as Bayes optimal, just given a certain set of priors.

It's slightly worrying, you know, slightly worrying, but it counts for things.

it comes for all I mean, basically all phenomena, because if you speak to call, but actually wouldn't go that far.

But you could cast it all as this kind of variational Bayesian inference.

So it's always optimal, and everything is based on.

But I guess the the flip side of that the positive side of that is that maybe it does license a more humanistic approach to psychiatric patients, insofar as there's this interesting argument, I don't know if it's an argument is an interesting point, which is that maybe something like this going slightly away from

schizophrenia, but it's relevant.

Something like PTSD, or OCD, or general anxiety disorder, actually is, could be quite adaptive in a certain ecological niche.

Absolutely.

If I'm in a war zone, being, you know, having hyper salience, and being really, you know, having very high precision over the likelihood of some sensory input and downweighting priors, like, you know, arguably in PTSD is actually really useful.

It's just not adaptive in


SPEAKER_00:
modern you know calm london on leafy regents park so how do you think in your experience in psychiatry this work has altered the way that we view psychiatric patients yes i think it has um i mean in psychiatry in reality of course it's very difficult because there aren't enough of them and there's no money and they can't find any drugs at work but i mean that's the

how that really operates.

But going back to the slightly earlier question, people like, gosh, I can't remember his name.

There is the idea that the symptoms of schizophrenia are not understandable, which is another, they have nothing to do with reality or our lives.

And I guess one of my,

aims in the sort of story of delusion is control is to say they are understandable.

It literally does feel as if somebody was moving my arm.


SPEAKER_02:
And, and how much would you say this has come from your, would you say Schneider?

Yeah.

Yeah.

Do you sense that this, um, empathy that you have in the, in the very literal sense of empathy that you can, that it's understandable comes from direct work directly working with these people.


SPEAKER_00:
Oh, to some extent.

Yes.

I mean, when I was with the medical research council, my lab so-called was in the middle of the acute psychiatric ward.

So I was interacting with them every day.

And it was quite good because they were actually very bored.

So they would come and knock on the door and say, have you got another experiment for me to do?


SPEAKER_02:
Yes.

I think, I think, uh, that's where Cole started was in psychiatric rotations.


SPEAKER_01:
Yeah.

Yeah.


SPEAKER_02:
Well, how did you guys first meet?

If I may ask, was it at UCL?


SPEAKER_00:
No, we met at the, um, the cyclotron units at the hospital where we had, uh,

there was a project, I think, run by Peter Little to basically start scanning patients with schizophrenia to test various theories.

And if I remember rightly, Carl was appointed because he had the psychiatric background to work on this project.

And that was in the very early days before we knew how to analyze brain imaging data.


SPEAKER_02:
Yes.


SPEAKER_00:
So he was given the task of analyzing the brain imaging data.

And the rest is history, as they say, quite quite.


SPEAKER_02:
What was it like?

What was your your most cited paper on ever is the statistical parametric mapping?

Yeah, what you did?

Again, we're going a little bit off pace.

But this is the beauty of this podcast.

Like, you know, we can go wherever we want.

What was it like?

Be again, I don't know how SPM works.

I don't know how

I'm not a brain scanner, so maybe one day, um, or voxel based morphometry or any of these things.

But I'm just curious about what it was like.


SPEAKER_00:
No, it was very exciting.

And I think what was wonderful about Carl is that, I mean, there's lots of other people doing imaging for the first time and they were tending to invent new ways of analyzing the data.

Yes.

Whereas Carl very sensibly said, but there are all these statistical paradigms already there.

Yeah.

These are what we should be using.

And that's.


SPEAKER_02:
Yes.

I've always kind of wondered how Carl knew about them in the first place.

Um, but I, I sense that your work on, uh, forward modeling, um, sure.

I, I, you know, I was reading.

had the joy of going not obviously through the entire catalog of your works because that would take me until next year but going for a couple of them again and some of them are sort of canonicals i've read them before um and it's what struck me almost like reading thomas metzinger i've said this before about thomas metzinger how incredibly full like in retrospect it just seems like you're speaking the same language as we're saying what we're saying now in active inference

landscapes quite but nearly quite but well, there's a lot of overlap.

And it's incredibly influential.

And I would say that for you and Sarah Jane and someone like Thomas Metzinger, it's really remarkable.

How you know how much was how much how in conversation were you with Carl when he was beginning to develop the free energy?


SPEAKER_00:
No, all the time we share an office.

Nice.

I have lots of passive smoking experience.


SPEAKER_02:
Yeah, he does like a cigarette.

Fair enough.

I think he's I think he's warranted one.

And have you given much thought I guess we are on the active inference podcast.

So I ought to ask something more specific.

I know we spoke before an email and you said, you know, this is not directly your line of work.

But you were around for when

The 2010 paper was released.

The 2009 paper was released.

I think 2005 might be the sort of beginnings.

What were your kind of experiences around then and how did you contribute?


SPEAKER_00:
Well, I'm not quite sure.

Yes, Carl has this habit of putting my name on papers from time to time.

And I guess I contribute to some extent by saying we need more independent references or something like that.

sometimes change the wording a bit.

And what I was particularly interested in, I was very keen, and it really goes right back to Richard Gregory and people like that, the approach to perception and the idea that we, if there's a prediction error, we have to update our model of the world.

And I thought that was very exciting and wrote about that in my previous book.

And so I was particularly excited with active inference, because that gave you the other side of the picture.

And when we get a prediction error, we don't have to update our model of the world, we can change the world instead.

Isn't that amazing?

That was wonderful.


SPEAKER_02:
I know it is wonderful.

What were your thoughts?

So this is kind of what if anyone's familiar, this is what we would call the low road to active inference.

Yeah, this is

Predictive coding, Helmholtzian perception and the like, and action as inference, I guess you could say.

Yeah.

Have you given any thought to the so-called high road?

And by that, I mean, dynamical stochastic systems and no.


SPEAKER_00:
That's too difficult for me.


SPEAKER_02:
I'm trying to learn the maths.

Yeah.

You're not wrong.

You're not wrong.

It is rather tricky.

Excellent.

Okay, so I said we will talk about hallucinations and delusions.

I think delusions we've somewhat touched upon, which is kind of this fixity of priors that is not allowing for updating.

But I read, you know, Kapoor's work on sort of the dope aberrant salience model.

I never thought that any of this stuff really accounted for hallucinations.


SPEAKER_00:
where to the best of your knowledge do you think hallucinations might come from well i i'm with paul fetcher we wrote a paper which we're basically saying there's no fundamental difference between hallucinations and delusions okay if you take a bayesian approach yes yes because the hallucinations are

It's just about perception rather than beliefs, but in both cases, it's all about whether you update and where the evidence comes from.

But the thing you have to remember about schizophrenia is these hallucinations are predominantly auditory and they're predominantly hearing voices.

And one symptom is so-called thought broadcast.

I hear my thoughts as if they're being spoken aloud.

And you can even have a sort of very similar story with the forward model and there's work on this so that when you speak, you hear your own voice, but you suppress it.

And there's some evidence that when patients speak that again, the suppression system seems to go wrong in relation to speaking as well.

And you have inner speech and all these sorts of things.

So one idea is that they're perceiving their own inner speech as if it was from an external source, which is not that far away from a delusion of control.


SPEAKER_02:
Yes.

I sometimes think how

true is that if one meditates, for example, if one is doing Vipassana, it does seem like those thoughts are coming from not from you.

So this might be looping back into our sort of humanistic approach to psychiatric disorders.


SPEAKER_00:
So don't tell that to your psychiatrist.


SPEAKER_02:
Yeah.

Yes, yeah, yeah, I won't.

It's true.

There's these very odd overlaps between Buddhism and psychiatry and ego death and all of these kinds of things.

Do you think that this notion that self-talk, let's say, let's stick with that because it's very interesting, is self-talk?

From a very raw Buddhist perspective, that doesn't get off the ground because there is no self.

These thoughts are just popping into awareness.

And it's all process.

It's process ontology.

There's no substance there.

It's coming and going.

It's just the field of awareness.

So is it just an adaptive tool for us to presume or have this illusion that it's self generated?

I guess that depends what you mean by self generated generated, but it's self talk mean then that maybe that's because it's yes.

I mean, clearly it's not, I'm not intention intentionally saying these things per se, but I'm perceiving them as belonging to me.


SPEAKER_00:
Yes.

So they're not coming from outside.


SPEAKER_02:
Yeah, sure.

But what's in this, in this way, we have to kind of ask, well, what is inside and outside?


SPEAKER_00:
Yeah.

So, so, well, that's, I mean, that's a common one.

I mean, one quite dominant theory of schizophrenia, they'd lost the boundary between outside.


SPEAKER_02:
That's really interesting.

They've lost their Markov blanket.


SPEAKER_00:
Yes.


SPEAKER_02:
Yeah.

Yes.

But I guess, I guess the reality is you never lose a Markov blanket.

I mean, this, this, to be honest, it points to quite, it points to theoretical difficulties in active inference.

which is something that's been brought up in this podcast before and in other works, which is where do you even cast the Markov blanket?

And what is it to say that you have internal states and external states?

Really what those actually mean, and I give credit to Maxwell Ramstein for pointing this out to me, is that internal you can just say are tracking and external are tracked.

But that said, you have someone like Andy Clark who might say, well, in my tracking mechanism, I might have my telephone or my notepad.

And then you have Jacob Howie who says, no, no, no.

The evidential boundary is the mind, and even the body is being predicted.

Does any of those dichotomies or debates inform something like what we've been talking about, self-talk and delusions of control?


SPEAKER_00:
Well, self-talk, inner speech, people used to call it.

Yes.

And that is great.

And again, the Russian psychologist, I mean, Vygotsky, I think, and there's some evidence for this, that young children, particularly doing difficult tasks, what one might call frontal tasks, you actually talk aloud, I must now do this and I must now do this, and this becomes internalised, so you're doing that internally.

And I think for some difficult tasks and things like mental arithmetic, there is indeed inner speech.

which is being used to control what you're doing.

And, um, some schizophrenic hallucinations where the, where they hear a voice commenting on their actions.

So now he's going to do this.

And then why is he doing that?

And it's all very weird what they, but how you can see a sort of,

thread coming through this.

I mean, that's what I would call self-talk.

And the fourth is not important.


SPEAKER_02:
I wonder whether there is some, uh, some space for a predictive model here in so far as if we're going to talk about what we meant by self, self generated and agency, we were talking about, uh, deploying some prediction.

And having in association with that prediction, I don't just deploy an action policy, I also have precise predictions about the sensory outcomes I'm expecting to receive.

And perhaps we can talk about self-talk in a similar way, which is that at the inception of my self-talk, let's say I'm predicting the sensory, in speech marks, consequences of an action policy of saying this at T plus one.

And then I receive that back and that seems self-generated.

And I guess if that mechanism itself is disrupted through synaptic problems, precision weighting problems, then that is not only just going to be motor action, but also mental action.

Yeah.

Is that appropriate?

Absolutely.

Yeah.

Oh, maybe I should be a psychiatrist.

Mental action is a good term.

Yeah, mental action is a very good term.

Well, I mean, all of this, it's kind of become very clear to me that all

such a plethora of behavior in active inference is mental action.

I mean, the very deployment of precision over what now we're using these Bayesian graphs, these so-called POMDP schemes.

So you have your sensory expectations, your C matrix, your state transitions, your B matrix.

Deploying precisions over those are all mental actions.

Okay.

Excellent.

Okay.

That's, that's okay.

Interesting.

Okay.

That's very, that's very cool.

Um, I was wondering, so there's a, uh, I believe he was a philosopher called Louis SAS, or maybe he was a psychologist and he wrote a book called madness and modernity.

Yes.


SPEAKER_00:
It wasn't even more modernism.


SPEAKER_02:
It might be, it might be, it's been a while since I read it.

Yeah.

Please, please educate me.


SPEAKER_00:
I mean, I read it too, but it was a very long time ago.

So, I mean, it's a removal of sort of structures and standard procedures.

Right.

Yeah.

stream and how does this stuff and how does that feed into schizophrenia is sort of the etiology of schizophrenia somewhat linked to having an unstable lifestyle yes I mean there's an interest this is very unlikely to be true but there's interesting stuff on volatility so with when the when the environment is volatile you should have a faster learning rate yes

And I think that somehow interacts with the dopamine system.

Okay.

So you could, and there is some evidence that children brought up in very volatile environments are more at risk.

And one wonders whether, and then you've got this dopamine aspect coming in as well.

If you've got too much dopamine, so you get the,

There's that sort of story and the modernism in the sense is increasing the volatility because you no longer rely on cultural givens.

Currently an interesting idea in relation to schizophrenia, which is bringing the cultural thing is that most of our beliefs at this high level are constrained by interactions with other people and culture more generally.

And you could argue that what's odd about what the reason that schizophrenic beliefs don't update is because they're no longer constrained by this high level cultural and what other people say.


SPEAKER_02:
So these are yes, your work is all coalescing.

That's cool.

That's nice.

Yeah, that's very, yes.

It's interesting, isn't it?

Because we think of ourselves as these, we live in the rather individualistic society where we think of ourselves as these atomistic beings and we're not, and we're not, that's terrifying.

Good.

Excellent.

So, so the book came out last year.

Yes.

What's on the, what's on the horizon for Chris Frith, Uta Frith, the Friths?


SPEAKER_00:
Well, um,

We're in our eighties now.

You wouldn't be able to tell.

We haven't got a major project in line.

We have a quite exciting interaction with our friends in Aarhus in Denmark.

Yes.

Where they have uploaded all our papers and are trying to construct a large language model.

Just interesting who we really are.

Yeah.

Interesting.


SPEAKER_02:
Uh, is this Andreas?


SPEAKER_00:
Well, no, it's in his.


SPEAKER_02:
Yeah.

Yeah.

Cause I, you have a, you have a partnership with him or is that still going?


SPEAKER_00:
We visit every year.

Yes.

Yes.


SPEAKER_02:
Excellent.

He's got, I think he might be coming on.


SPEAKER_00:
Um, certainly talk to him now.


SPEAKER_02:
I'm extremely interested in this one.

Chris, this was, um, this was a delight.

It's been a delight on my part to go back and read your texts.

I mean, I did finish my master's just background about myself in case you didn't.

I finished my master's at UCL in experimental psychology last year.

And I would say sort of your presence and Carl's presence

sort of lingers in a positive way, not in a sort of ghoulish way through the corridors.

So thank you.

My pleasure.

It's been an absolute pleasure.

All right.

Excellent.