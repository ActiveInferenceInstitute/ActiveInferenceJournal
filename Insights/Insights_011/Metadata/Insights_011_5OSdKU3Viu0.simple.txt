SPEAKER_01:
Hello everyone and welcome back to the show.

Today I am joined by Julian Kiverstein, Senior Researcher in the Department of Psychiatry at Amsterdam Medical Research.

Professor Kiverstein's work is fascinating and deeply important as he has developed phenomenologically informed answers to a number of questions in cognitive science, including time perception, conceptual thinking, empathy, free will, consciousness and the self.

In doing so, he has become a leading intellectual in the world of 4E cognitive science.

As he puts it, cognitive scientists once shared a vision of mind as a kind of logic engine carrying out rule based operations on symbolic representations.

Today, this view is rapidly being replaced by an alternative vision of brain, body and world as dynamically interacting equal partners, sharing the load in our day to day problem solving behavior.

Professor Kiverstein's work has also been highly impactful on my own thinking in these domains.

So honestly, I am really, really excited to speak to you today.

Professor Kiverstein, Julian, thank you so much for joining me.

As I said, it really is a privilege.


SPEAKER_00:
Thanks so much for inviting me.

Looking forward to our discussion very much.


SPEAKER_01:
As am I. And I think, you know, I've read some of your papers multiple times and I adore them.

I think some of them are absolute gems in the 4E sort of lineage.


SPEAKER_00:
Thank you.


SPEAKER_01:
And you sort of propose this notion of ecological inactive cognition.

for ecog Psi, inactive cognition has a very rich history.

And it's worthwhile, I'm picking what some of these terms mean, because I can imagine people are going to get confused, because they're rather niche terms, at least they can sound so.

So it'd be good to get maybe just some definitions off the ground.

Perhaps we could start with autonomy, versus heteronormative heteronormative.

Yeah.

What does it mean to be a kind of autonomous being?


SPEAKER_00:
Yeah, so that is an excellent starting point.

Well, autonomy is like a very rich concept with a long history.

But the way that it's used in the context of philosophy of cognitive science is by drawing on ideas about biological autonomy.

So autonomy is like a form of self-organization.

that a living system has when it is both self-producing, so that's basic to the idea of self-organization, that the organization is something that emerges.

So the structure, the form that the living system has is something that's emergent.

but also that autonomous systems are able to keep themselves going, so maintain their organization.

And that requires them to be self-individuating in a particular way, so distinguishing themselves from their environment.

Um, so I think those are the two key features that we need to have in view, the self distinction, uh, self production or self individuation, as I called it.


SPEAKER_01:
Sure.

I've been, uh, I've been sort of perusing Evan Thompson's 2007 mind in life, which is just cracking, but also super long.

So I'm working my way for it slowly.

And here's a bit where he says, well, autonomy.

it's sometimes quite tricky to say when something is explicitly autonomous, rather than heteronymous.

I think that's the right way of saying it.

Do you subscribe to that notion that this is kind of a spectrum or that these can be cast these sharp dividing lines?


SPEAKER_00:
Yeah.

So there's a, there's a technical discussion about whether autopoiesis is necessary and sufficient for autonomy.

I think maybe that's what you're thinking about.

So autopoiesis is this idea that the organization is self produced.

Um, and there's some questions about, well, is that enough on its own to get autonomy?

And Evan argues it isn't.

So you need, and so does Ezekiel DePaulo, you need this extra condition of adaptivity, as they call it.

In my work with Michael Kirchhoff, we connect that idea of adaptivity to active inference.

yes so we discussed this in in the context of an issue that's come up quite a few times on your your podcast about what to say about pebbles or yes swinging pendulums that seem to behave as if they are minimizing free energy

But it still seems like, well, if free energy principle is so general as to apply to the behavior of those kinds of physical systems, how is it going to be useful to use the mathematics of the free energy principle to understand life and mind?


SPEAKER_01:
So perhaps before we get there, it'd be worthwhile just so people are aware, what does someone like Evan Thompson mean by adaptivity?


SPEAKER_00:
Yeah, sorry, so adaptivity is this ability of living systems to regulate their encounters with the environment.

It requires a sensitivity to tendencies that can be sensed in the environment, where those tendencies could be threatening to the precarious organization of the living being, of the agent.

So adaptivity is like moving towards dynamical tendencies that are going to sustain the organization of the system and away from tendencies that are threatening, are going to lead to disintegration or collapse.


SPEAKER_01:
And this sounds to me like this implies some necessary coupling with the environment whereby, to use active inference terms, you are, there's some conditional dependencies via Markov blanket, let's say.

I mean, that's interesting because, as you know, this Weisingen tests with some of the earlier formulations of autonomy.

So Varela, for example, in 79 writes, the environmental elements intervening between the effector and the sensory surface of the organism is irrelevant because the nervous system can be redefined as a network of neuronal interactions in terms of the interactions of its component neurons, regardless of intervening elements.

So that brings in this notion of operational or organizational closure.

Perhaps it's worth explaining to the audience why, at least on first glance, that might seem like it engenders some notion of internalism.


SPEAKER_00:
Yeah, so certainly the way that Varela defines autonomy in that 1979 quote he just gave us is,

would entail a very strong form of internalism where the environment is just providing perturbations to the autonomous organization of the living system.

I don't think in the end that is what Varela intended, but there are places where he certainly sounds like it's a view where the meaning that we find in the world is something that's projected by the living organism onto the environment.

It can be read as a kind of solipsism or idealism without some careful handling.

Matriana and Varela had this metaphor of the submarine where you're underwater and all that you have in terms of access to the external world is through the periscope.

This sounds very similar to some of the things that we hear in active inference quite a lot.

There are hidden causes out in the world and we have to infer from our sensory states what it is that are causing those sensory states because we have no direct or immediate access to those hidden causes.

I think the quote that you just read really fits with that view of life and autonomy.

But I think that at the same time, we can think of the Markov blanket as coupling us to the environment.

This is something that came up in your discussion with Innes.

It separates us from our surroundings.

If we think of the Markov blanket around the organism, we can, of course, talk about where to place the Markov blanket.

That's one of the things that has also come up many times in your discussions.

But focusing on the Markov blanket around the biologically autonomous system, we can think of that as separating or enforcing some kind of separation between the organism and the environment.

But we can also think of it as coupling the organism to the environment via the active states of the organism.

yes yeah when i was going in in saying well what's the difference between the the pebble the the pendulums that are kind of oscillating together and an autonomous system an agent i think a key difference is that in the case of the agent there is this adaptivity or what michael and i call adaptive active inference

So there's mere active inference, which is what you see in pebbles or in the pendulums.

But there's also what we call adaptive active inference, where that requires that the organism is able to select actions, select policies that are going to minimize expected free energy or expected prediction errors.


SPEAKER_01:
Yes, yes, indeed.

I mean, again, for me, this fits very nicely into the kind of dissection that people make of the variational free energy equation between the so-called KL divergence with your recognition density and your posterior.

So what's the difference between what you think is the posterior and what the true posterior is?

That's just perceptual inference.

But the key thing here, at least for humans, is this capacity to maximize model evidence.

So this is the probability of Y given your model.

And that seems to me to be, well, I think this is strongly put within the active inference community that that's reserved for animate active beings.


SPEAKER_00:
Those anima active beings have what we're calling autonomy here.

So that's a characterization of the organization of those systems that goes beyond just a mere operational closure where the opponents are reciprocally dependent on each other for their production.

That's what operational closure means.

What autonomy adds to that is this idea of

of self-evidencing, as we would put it in active inference terms, would probably disagree with me describing it in that way.

But the project here is to try to bring together active inference, the free energy principle with these ideas about inaction from the inactive community.

Sure.

Yeah.

I think a lot of these problems have come very well once we

make this distinction between systems that minimize variational free energy and those are abundant in the physical world, systems that do this adaptively because of their autonomy, because of their agency.


SPEAKER_01:
Yes.

Yeah.

I think a lot of the dichotomies or debates in active inference really come down to this fundamental issue.

I mean, in many ways, it depends on what your lens of analysis is.

You have some people who focus heavily on the internal states.

you have some people focus on what's called the particle state.

So that includes the blanket states.

And then you have some people like a Maxwell Ramsey, who says, Well, really, the currency is about the Markov across the Markov blanket, the internal and external.

And that you can almost cost us, you know, we talked about nested Markov blankets, well, that itself is a Markov blanket, which leads me to question, you know, in the classical literature about autopoiesis and operational closure, people talk about the cells production of its cell membrane.

which relies on the metabolic activity of the cell.

But the metabolic activity of the cell can only happen if there is a coherent cell membrane that separates it from its environment.

But that again gives us this very internalist view.

Is it misspeaking to say that why don't we just say that operational closure can expand beyond the skin and we could just be operationally closed in some sense with our eco niche?

Is that reasonable or is that just stretching the meaning of these terms?


SPEAKER_00:
Well, let's back up to what you said about perceptual inference and the KL divergence and think about how to understand that part of the free energy mathematics.

So in the work that I did with Yala Brownaber, we tried to understand the difference between the actual posterior and your inferred posterior in terms of the disattunement, as we describe it, between the internal dynamics and the external dynamics of the environment.

So the actual posterior there is describing the external dynamics,

and your inferred posterior is corresponding to the internal dynamics.

So then we can unpack what KL divergence is within this larger agent environment system in terms of this mismatch between the internal and external dynamics.

So I think it's a consequence of that.

And Carl sometimes says this explicitly when he's writing about niche construction.

that not only is the agent a model of its environment, but it applies the other way around as well, that the environment is a model of agents that inhabit it.

So when we're thinking about the environment side of things, obviously we can't focus on an individual agent because that would then lead to some kind of solipsism that actually you talked about in your discussion with Carl.

But so we shouldn't think about the environment as predicting agents just by focusing on single agents.

We should instead think of groups, communities, practices and so on as where or how the niche is constructed.

And then thinking about the niche that's constructed through cultural evolution in part, through practices, you could start to see how there's a symmetry so that the environment could have a kind of dynamics, an external dynamics, which begins to predict what individual agents are doing.

Yeah.


SPEAKER_01:
Yeah, it's very nice.

Yeah.

this makes me think that number of things that come into my head.

One is, there's this thing called, for some reason, I've been getting kind of into the maths.

To my, you know, I shouldn't be but I am.

But as I recently spoke to Lance, and there was a lot of mass preparation I needed to do for that.

I stumbled across something called an Fisher information metric.

You familiar what a Fisher information metric is?

no because you're very much like no but you'll really like this the fisher information metric basically it's very simple it tracks how your kl divergence is doing over time so i think this fits in very nicely of what you're talking about with attunement because you talk about you and mark and eric talk about prediction error uh sorry aerodynamics aerodynamics exactly yeah but that that implies over some oh you know some diachronic over timeness

And this Fisher information metric basically tracks that in mathematical terms, which is how much, you know, how great or how much bigger or how much smaller is your KL divergence becoming over time.

So I thought you would enjoy that.


SPEAKER_00:
Wonderful.

Let's go there eventually.

Yes.

Yeah, we will.

Yeah, because that's going to connect with some other things we wanted to talk about later on about play and intrinsic motivation, foraging.

Right.


SPEAKER_01:
So the other thing that Yeah, so the other thing that came into my mind is a proposal that I made to jump a vacay.

This this one, again, this is an this is sort of a live question.

It was a philosophical pondering, but I quite like it, which is that our intuitions tell us that we self evidence given are the observations we make of the environment.

So and that includes interoceptive observations, extra receptive and so on.

My proposal is that certain aspects of the environment also self evidence given the observations that they make of us.

And the example that I give of that is the rock is the climbing wall.

So my idea here is that sure, the climbing wall provides the necessary affordances for the agent to self evidence as a rock climber.

But the rock climber provides the necessary affordances for the climbing wall to self evidence as a climbing wall.

Now, this might be

some it might sound highfalutin and actually be quite dull.

But I think in that it touches upon what you were saying about the environment in being shaped through niche construction, as you say, can begin to manifest prediction dynamics of the actual agents within it.


SPEAKER_00:
Yeah.

I mean, the key thing about niche construction is that we're actively modifying, changing our environment in ways that contribute to prediction error, free energy mobilization.


SPEAKER_01:
And we put these footholds in place in the climbing wall and these finger holds.

And in many ways, that permits a wall that in its own evolution would never be a climbing wall to become a climbing wall.

Yeah.

Yeah.

Yeah.

I, I really liked this notion.


SPEAKER_00:
Well, it is a, you know, it can be seen as a, as predicting the trajectory of the agents movements up the climbing wall.

Right.

Right.


SPEAKER_01:
Yes.


SPEAKER_00:
I, I guess the issue that a lot of people have here is structured in a way that, that does predict well, that does some of the work.

that otherwise would have to be done by the brain.

So this is like a classic way of thinking about the extended mind.

You asked me about the four E's and how to understand the four E's and we started with autonomy, but we could move to extended mind here.


SPEAKER_01:
Yeah, sure.


SPEAKER_00:
In that one of the ways in which extended mind is classically understood is by thinking about the offloading

of computation that would otherwise need to be done by the the brain onto structures in the environment that's then simplified the kinds of inferences computations that the brain has to perform so your climbing wall example i think is an excellent example of this kind of um offloading of computation onto the structure in the environment


SPEAKER_01:
Yes, I so extended, I've been thinking about the extended mind hypothesis, quite a bit, I plan on doing some writing over it.

And I think the big debate here is where we cost what Jakob Harry would call the evidential boundary.

So his notion is, is that, in a very internalist way, what you might say is that the mind is doing the prediction, and everything else is being predicted.

That's why you cost your evidential boundary, because it can't be the case that the body is both predicted, predicting and predicted.

And then you have someone like Andy Clark who goes, well, um, you know, the parity principle, if my notebook is doing as good a job as my hippocampus and that acts, you know, as part of my cognition and, and in terms of active inference, we could say, well, that becomes part of my predictive schema.

Do you take a particular, do you adopt a kind of fine line or a bright line as to where you cost your evidential boundary?


SPEAKER_00:
Well, this goes back to the Varela quote again, actually, interestingly, because what Jacob is saying is that we should put the Markov blanket around the dorsal horn.

And that's the candidate that he gives for where the Markov blanket might be relative to which self-evidencing then takes place.

So that would then imply that anything that I'm describing as offloading is...

an example of self-evidencing where the structure of the environment is causally very important, but it isn't actually part of what's doing the self-evidencing.

So the way to think about that is in terms of this notion of embedding rather than extending the mind or extending cognition.

Nice.

So, so Jakob could well agree that, um, that the environment here is causally very important and the way that the environment is structured, but all of the inference is now going to be done, uh, uh, through processes that, that are mediated by exchanges between the brain and the body at the dorsal horn.

And, you know, well, there's many things to say about that.

So, um,

One thing I want to point to is a paper in Synthesa and also the book that I wrote with Michael Kirchhoff where we argue that

there's reasons to think that the self-evidencing system is an agent again, and that that agent can incorporate into its body resources that are external to the body so that they become part of what's doing the self-evidencing or what's doing the inference.

If you think, going back to where we started, that the free energy minimizing system is an agent, an agent that has this property of biological autonomy rather than heteronomy, and I didn't answer your question of what heteronomy is, so we'll come back to that in a minute.

But if you think that the free energy minimizing system is biologically autonomous,

then that system can begin to have an organization that incorporates resources that are external to the organism in the environment.

And those resources can include things like the structure of the climbing wall or the white lines that are painted onto the road that you use to simplify your driving behavior.

You just follow the white lines.

That gives you a very simple heuristic that you can use for minimizing free energy.


SPEAKER_01:
Yes.

One paper that's really informed my thoughts on this is Andy Clark's How to Knit Your Own Markov Blanket.

It's a wonderful kind of deflation of all the tensions in this area because you can just say, well, the Markov blanket

is an abstraction in the sense that it's always embedded within another Markov blanket, which is always embedded within another Markov blanket.

And where you choose to cast that Markov blanket, as we've discussed many times on this podcast can be often just an instrumental tool.

But more importantly, that is, if we do take it seriously, that there is a Markov blanket, it doesn't need to be fixed.

So we can have a process ontology rather than a substance ontology, whereby when I'm in my car,

For me to self-evidence, I incorporate the car's dynamics so that me and the car, it's sort of recursive.

My sort of A and B becomes a new A. And we can scale this way all the way up to social or global dynamics.

But I think the important point is no one's asking anyone to find the one Markov blanket.


SPEAKER_00:
No.

There's going to be a nesting of Markov blankets.

That's absolutely right.

And once you start to see how Markov blankets are nested, then you can start to think about, well, what's the relationship between the Markov blankets?

And that's where we've argued you can get an account of how to formalize autonomy using the Markov blanket concept, because you can start to think about how the

the sensory and active states that are forming the Markov blanket enter into these kind of reciprocal relations of dependence that the organization of the system then depends on.

So you can start to get a formalization of operational closure out of the relationship between the different Markov blankets in a system that has a nested Markov blanket organization.

So that's one thing that you can do.

And also do what we've been talking about here of thinking about how some of the Markov blankets in this complex system are going to be located outside of the boundaries of the organism.

So the sensory and active states that are forming the Markov blanket could start to be outside of the sensorium.

So think about a spider and its web.

That's the example that Michael used as a very intuitive example of this, that the spider can start to use the movements in the web as its sensory and active states to catch prey, for instance.

So then the web and the spider are forming a single system.

There's a kind of extended phenotype that forms between the spider and the web.

And also his notebook can also be described in this way.

So the sensory and active states that form the boundary of the extended cognitive system could now involve the notebook and the writing down of things in the notebook, the looking up of information in the notebook and so on.


SPEAKER_01:
Yes.

Yeah.

See, the thing is, I like that.

My only sort of naive reticence

is because we're conscious.

And this is such a sticking point.

But I think where some of the corticocentrism comes from is the kind of presumption that- I know you've said this before, but you know that Michael and I argue for extended consciousness.


SPEAKER_00:
So maybe we get there a bit later on.

There's one more thing I want to say about the extended mind and how active inference is relevant to the extended mind discussions.

And this relates to the idea of recruitment of external resources and how recruitment works.

So for a long time, Andy Clark's argued that the brain is a kind of lazy brain that tries to simplify its computations as much as possible for evolutionary reasons.

So you could relate it to the principle of least action, probably this idea of efficient computation.

And sometimes to efficiently compute, it makes sense to offload that computation onto the environment.

So this is classic kind of situated cognition idea that goes back to the 1990s, maybe even further back than that.

So how do you then weigh up what's going to be the most efficient way to solve a problem?

Do you solve the problem just by relying on your onboard biological hardware or do you offload the problem solving onto the world and recruit external resources?

So this is called the recruitment problem because it's a problem about how you soft assemble a cognitive system on the fly in such a way as to, as efficiently as possible, compute a solution to a problem.

And what Andy Clark's been arguing in recent work is that the recruitment problem is solved by your imperative to minimize prediction error over time, to minimize expected prediction error or expected free energy.

So we can give a kind of account of how it is that

cognitive systems whose boundaries extend beyond the organism come to recruit certain external resources to solve problems in terms of free energy minimization or in terms of expected free energy minimization that can become a policy that's inferred that

The most efficient way to solve a problem is by recruiting external resources that simplify the computations that would otherwise have to be done inside of the hedge.


SPEAKER_01:
That's really, really nice.

I'm writing that down because I really like that.

Cool.

That's awesome.

Okay.


SPEAKER_00:
Yeah.

There's a paper that we can link you to in the Australasian Journal of Philosophy that Andy published, I think, last year.

Please.

There's a reply to Jakob Hoey as well called Busting Out.

Yes.

That also makes these same sorts of arguments.

And in that paper, Andy ties it to...

uh, precision and to precision as kind of sculpting the effective connectivity of the brain in a context sensitive way.

So he has the idea that when you're computing precision, sometimes those computations will lead you to, to increase the game on, um, on,

Well, I'm going to put it in terms of the sensory and active states that are external to the body and that relate to the structure in the environment.

So then, as you put it before, the Markov blanket is not fixed.

It kind of extends to include those resources in the external environment.


SPEAKER_01:
Although, that said, there's a way of modeling sort of a...

Bayesian graph, for example, or POMDP scheme, whereby that which you deploy precision waiting over is not necessarily incorporated into your own Markov blanket.

So there's a really nice paper by MIT and colleagues 2019, where they talk about selective attention, and how selective attention needs to be governed by the capacity for cognizers to, to pay or to down regulate task irrelevant

objects, let's say.

But that doesn't mean that the task irrelevant objects are automatically incorporated within the self Markov blanket.

It's just that they have gain control, or there's gain control over them.


SPEAKER_00:
No, but I was thinking about a different case where it's not so much the task irrelevant objects that you are now disattending to, but the task relevant objects that you're attending to, and how the precision mechanism can be what

explains how those task relevant objects get to become a part of an extended cognitive system so it's the opposite of the case that you were describing where they were describing how task irrelevant objects are not selected yeah now i'm thinking about the case where a task relevant object that is external to the body like the book or

spiders web are now attended to because they are precisely because they're task relevant they allow you to to solve a problem in a much more efficient way than you would if you just relied on your brain to clarify um i i was sort of introducing it as the kind of down rating of task irrelevant um objects but it's it's a zero-sum game

So yeah.


SPEAKER_01:
Oh, I see.

Okay.


SPEAKER_00:
I guess it's all relative on the task relevant stuff.


SPEAKER_01:
Sure.

Sure.

I think I won't misspeak.

People can see it themselves, but the outcome is the same in the sense that it's all relative.

So precision is a zero sum game.

So if it goes down here, it's going to go up here.


SPEAKER_00:
What I'm saying is you don't want to include the task irrelevant stuff.


SPEAKER_01:
Yeah.

So that's exactly that point.


SPEAKER_00:
Yeah.

you do want to include the task relevant stuff that's what the soft assembly of the cognitive system is it's the it's the selecting what's relevant to your problem solving in this context


SPEAKER_01:
I guess my question here is, does it make a difference whether we downregulate task-irrelevant objects?

Because in doing so, if we just think of a landscape where everything is equal, in pressing these down, you get relative gain on those which have not been suppressed versus actively inflating the precision of task-relevant objects.

Do we not get the same outcome just in relative terms?


SPEAKER_00:
So I think what's super interesting here is that precision turns out to be doing what

John Vivecki calls relevance realization.

So the model that you've just been talking about is which prediction errors should be treated as salient or reliable so that they get to influence future processing.

And so you are focusing on the error signals which are downweighed, so not treated as salient because they're task irrelevant.

I've been talking about the error signals, which, where you turn up the gain because they are salient.

Sure.

They are relevant.

So this is part of the problem of how, as Viveky calls it, how do we solve the, in a particular context, the problem of what's relevant and what's irrelevant.


SPEAKER_01:
Yeah.

The frame problem.

Yeah, yeah, yeah.

Yes.

No, you might.

Indeed, you might well be right.

The mere turtle.

2019 with Frist and frame it that way.

Again, it's been a while since I read it, but it converges on the same point, which is that the human organism, the cognizer has the capacity, even before it even glances over, even before it does the ISA card to have this disambiguation, which I just think is stunning.

And I think you can scale that up towards the fact that in the classical bias competition theory,

Desimone and Duncan basically just postulate that goal representations inflate the stimuli that correlate with the goal.

So if I'm looking for my ginger friend, I have this template of ginger and everything orange or ginger starts increasing in game control.

What active inference gives you is a really nice

I think it gives you a really nice way of modeling that although I don't think it's been done yet, which relies on sort of deep parametric modeling, and about mental action yielding precision waiting over sensory expectations, I might have a mental action, okay, I want to have high precision over anything that's ginger.

And then in turn, I'm going to act so as to confirm that.

I think the other thing just for the audiences and something that has really become quite clear to me is there's a difference between precision and precision weighting.

And this is something that I think needs to be articulated a little bit more in the active inference literature.

Insofar as precision is just the inverse entropy of a probability distribution, or you can just say it's standard deviation.

But precision weighting is actually the deployment of, well, it could be considered gain control.

But gain control is not just based on the precision of a signal.

People talk about attention being the optimization of what's called the A matrix, which is the likelihood distribution.

So given a state, what's the likelihood of this observation?

But just having a really strong one-to-one mapping between those two doesn't mean you're going to pay attention just to that.

Because if I'm looking for my ginger friend, there might be loads of things out there which have very precise mappings to their causes, but I'm ignoring them.

So they might be very precise observations, but they don't matter.

So that's just to say that I think at least it needs to become more articulated within the literature exactly what this difference is.

Although, as I said, the deep parametric modeling of it hasn't been done yet, as far as I'm aware.

So there's plenty of work to be done there.

But yeah, John, this is right up John's street.


SPEAKER_00:
Okay.

What you said there about it, if you're interested in finding your friend with ginger hair, that's the thing that matters to you.

So that's vision.

that's really in an important point because it makes the connection between attention and uh and your goals yep yeah and it also makes the link between attention and what you care about so what matters to you and yeah as an agent and so finding your friend matters to you that's something that you care about yeah yeah yeah friend so there's a link here between precision and an emotion

which I think in the work I've been doing with Mark Miller, we would argue leads to an embodied view.

So going back to the E's, now we could think about the E of embodiment.

We can also think about the E of extendedness some more here, but thinking about the E of embodiment, the reason that we should think of precision as embodied is because

And what you care about is sculpting, modulating what is given precision in a particular context.

So in your example, what's given precision is finding your friend.

And that's given precision because that matters to you, because that's important to you, because you care about your friend.


SPEAKER_01:
Because we're autonomous, because we act according to our own norms and values, which we've made.


SPEAKER_00:
That's right.

That's part of it.

So people talk about autonomy as then entailing sense making or meaning making, because

based on your autonomy, there are then norms, meanings, values that become intrinsic to your biological organization.

So in this case, the value of your friend, your caring about your friend, can be thought of as something that falls out of the free energy minimizing machinery, because that machinery is the machinery of an autonomous being.

values, meaning and so on become intrinsic to the sustaining, the maintaining of the organization of that being.

Sure.


SPEAKER_01:
I'm going to spitball an idea and I'm curious about what you think about it.

So people take this idea of the relationship between attention and values.

and inflate it quite strongly.

And I don't mean that in a disparaging way, because I think some of the work is very powerful, but for example, someone like a Jordan Peterson or Jonathan Pajot, or even John Vivecki might say, well, what is sacred?

The term sacred is that which you pay most attention to, or that which captains or that which governs your attentional schema.

So for example, you could have a hierarchy of values.

So why do I want to earn money?

because I want to go on holiday.

Why do I want to go on holiday?

Because I want to be happy.

Why do I want to be happy?

And then Aristotle would say, well, that's it.

You got it.

Do you think that's a viable way of recapturing the idea of the sacred, if that means anything to you, in terms of computational attentional mechanisms?


SPEAKER_00:
Wow, that's a big question.

I know.

So how do we get to wisdom and the sacred and so on from this kind of computational machinery?

I think there's an interesting story to be told about that.

And I think we can get there.

But it requires a number of different steps along the way to connect attention as it's modeled using precision to attentional schemes, as you just described them, that could be shaped by religious beliefs, for instance, and beliefs in the sacred and so on.

And no, I think we can go there because,

This free energy principle, once you think of Markov blankets as nested, can be applied to very complex groups, communities, by thinking about how the...

agents that make up that group are now part of collective systems where it makes sense to think of those collective systems as also minimizing expected free energy.

So one of the routes I would go here would be to think about cultural ecosystems and think about what you just called the sacred and the sorts of attentional schemas that are involved there.

in terms of these, these larger collective, um, free energy minimizing systems.

Yes.

Yeah, exactly.

And then going back to the individual, um, and how,

and an individual may have an experience of the sacred, how to make sense of that.

Well, you're getting into very deep aspects of consciousness when you think about subjective experiences of the sacred.

and very deep notions of meaning-making.

And your friend example that got us into this was an example of a source of meaning in people's lives which comes from the social connectedness between people.

That's a source of meaning.

But obviously the sacred is also a profound source of meaning for people.

But it's a very thick concept.

So how to make sense of the kind of meaning that people get from the sacred and the meaning in life that that gives people using these ideas of predictive processing would require a much more complex story than how the value that we place in our connectedness to one another.

Um, that could be traced back to something that's more, I think, to do with primary emotions, our basic emotions to go to the emotion literature, something that we see in animals as well.

And that probably is tied to neurotransmitters, but the sacred, um, the kind of meaning that people find in the sacred to account for the way that that gives meaning to people's lives in terms of predictive processing.

I think can be done, but it requires a much more complex story.


SPEAKER_01:
Yes, I think some of that story will come, one, from your notion of nested affordances, but not that these nested affordances are separate from one another.

There's a very important idea in predictive coding literature that the higher levels of the predictive coding hierarchy contextualize and constrain the activity at the lower levels.

So for example, I have a and the higher levels track longer term regularities.

So they're slower, they're more entrenched.

And they constrain and contextualize what happens with the tracking of slower, faster fluctuations.

To give an example.

I might I've written this actually in this new paper that I've written.

So

my beliefs that i want to go to france in june is based off a higher order belief that summer in france is quite a nice experience and that is going to constrain every action that i do so it's going to constrain the way that i go on skyscanner and book my flight but then the other important thing is that those lower levels also interact with the higher levels so i again i give this example if it rains every day in june in nice

I'm probably going to take out an umbrella on July 1st, despite the fact that I had this high order belief that it's always sunny in France in the summer.

So I think this trickling prediction down and the cascading or the movement up of prediction error is maybe where this answer is going to lie.

why, as you say, why we get this notion of meaning in life or the sacred or this particular phenomenological essence, I think is up for grabs.

I don't think anyone knows as of yet.

But I think it is going to be done in this kind of deep in the modeling sense is deep parametric modeling.

So something akin to what


SPEAKER_00:
I think what I like about what you just said was that when you think about the experience of the sacred, it seems that there's a whole rich story to be told there about what the sacred is exactly.

So you're looking at a narrative of some sort.

And there's a good argument for thinking at least in terms of the self model.


SPEAKER_01:
Yeah.


SPEAKER_00:
what you find that the the higher layers of the self model are going to be narrative type structures that connect your self in the past to who you are in the present where you're going in the future so where are you going on holiday in your example so it's the there's a narrative structure to uh

both to the experiences of the sacred, I would argue, and to what you're doing when you're planning your summer holiday.

And so how would we think about a narrative?

Well, you could think about that just within the individual in terms of, for instance, the mental time travel idea, the mode network that is involved both in imagining the future and in remembering the past.

So you could think of the process of constructing a narrative as just something that happens within the individual.

Or you can think, no, when it comes to very complex experiences like the experience of the sacred,

The construction of the narrative there is something that involves a much larger system, a collective system, where the beliefs about the sacred that are used to make inferences, for instance, are ones that we need to explain in terms of some dynamics of a larger collective system.

Uh, so what's at the top, I think is what I'm asking.

You have the idea that the top layers of the generative model are constraining, um, the.

decision making the selection inference of policies at the lower levels and that's that's absolutely right but what's at the top can be thought of using the idea of andreas rubstorff and uh and chris frith in terms of what they call uh top top interactions so they can be thought of in terms of interactions that take place within cultural systems or within a cultural ecosystem

And so to make sense of this kind of experience in terms of the inferential processes that minimize free energy, we need to look at a much larger collective system here, not just a system inside of the individual.

And that's another way of thinking about extended mind, where we're thinking of mind here as distributed over a cultural ecosystem, not

as something that's inside of individuals.


SPEAKER_01:
Yes, that's wonderful.

That's wonderful.

Yeah.

So I've been thinking a lot about these self models.

But I think you're absolutely right, the sacred taps into self evidencing of almost a world model.

A world model that is not not for one, but for what you call what Wittgenstein and you guy and you call a way of life.

Life.


SPEAKER_00:
form of life way of life i love as well but a form of life form of life i was literally thinking i'm not going to mess that one up okay a form of life in the sense that a form of life isn't it's connected with a way of life certainly the sacred is connected with the way of life sure but yeah yeah go ahead form of life where we define that as um as a a regular pattern of activity that can be found within a a group or a community right

So perhaps the notion that scales, but you can apply it at a collective level.

That's the key idea that's relevant here as a species, as a form of life or as members of that form of life.

So individuals as forms of life.

And when we think about autonomy, again, biological autonomy, that's, that's a way of thinking about what form of a form of life is at the scale of an individual organism.

So it's a scaling notion.

Like the Markov blanket is a scaling notion because it can be applied to very big things like economies and ecosystems, and it can be applied to very small things like cells or molecules, particles.


SPEAKER_01:
Yeah, this is super interesting.

Again, yeah, exactly.

Scale is really the relevant thing here.

The question is, what is at the highest level of the form of life's generative model?

And there are answers that some people have posited.

I mean, consciousness?

There's this idea, at least, I don't think they would have expanded this to a panpsychist view, but it certainly lends, I would say, some, it leans quite heavily on panpsychism.

Maxwell Ramstein and Mal Albaraz in this notion that consciousness is the uppermost Markov blanket in the brain.

Well, this is not too dissimilar to someone like Jordan Peterson, who says that the voice of God is actually the voice of consciousness, and that's the guiding spirit.

So again, we're postulating, but I think there's a really interesting framework set up there for anyone who wants to get into that, which is what is the fundamental thing that's constraining us and contextualizing us.

And I don't, I just don't think it's survival.

I don't think it can just be biological imperatives.

I think maybe it's just me being romantic, but I sense that it transcends that.


SPEAKER_00:
There are two things I want to say on that before you move on.

Sure, please.

The first is that going back to the Ropestorff and Frith paper about the top-top interactions, what they were interested in that paper is the idea that what you have at the top in top-down control, they were thinking about executive functions, for instance.

is something in the prefrontal cortex, for instance, that might be the source of will or willpower or agency.

And they were arguing that actually it makes sense to think that the executive functions could be unfolding not within individuals but within larger groups or within dyads or within social systems.

So the role of executive functioning or top-down control would then be done in interaction with other people rather than as something that unfolds within individuals.

And so that's a way of thinking about what's at the top in terms of top-down control or executive functioning, where we think that the executive functioning is now the control processes are in the sense of the thing that might be doing willpower is something that is social and involves social interactions rather than something that

happens inside of the head.

Oh, that's so nice.


SPEAKER_01:
Oh, that's, yeah, I like that.

Okay.

That's, yeah, that's really good.


SPEAKER_00:
That's one thing I want to say about that.

And then the consciousness being at the top in top down control.

Well, again, we have this idea of willpower as conscious intention making or something like that.

And then there's all of the arguments about whether the will is epiphenomenal or is it just an illusion like Daniel Wegner's work?


UNKNOWN:
And


SPEAKER_00:
And then people that want to say no, the will is tied to consciousness.

Or people who want to say no, all intentional action is just generated unconsciously and there isn't really any work for the will to do anymore based on like Libet-type arguments.

So there is a connection between consciousness and this idea of executive functioning.

Uh, not, it's a bit different from what Maxwell and Mauer are doing.

I think that there is a connection there.

Maybe it ties more closely with what Adam Saffron tries to do, where he tries to bring this like homunculus ideas together with free will.

And that's part of his work.


SPEAKER_01:
Yes.

I mean, I mean, Varela said, well, that we're composed of micro identities.

Um, I think there's always an open question about how seriously you take this notion of, uh,

self-construction once you start getting to the very the very top of the very bottom level of the generative hierarchy so what a minimal self model might look like um but that's that's that's a different question maybe we'll come to self-modeling so we wanted to finish the thought on the will and consciousness sorry because i didn't get to the end of it but yeah the thought that the path i was on was that um


SPEAKER_00:
Well, it's going to take us back to narrative again, actually.

So if we think about the narrative layers of the self-model, I think there's a good reason to think that they might be where you need to look to understand will, for instance, willpower.

So Elizabeth Pashery in her work on intention makes this distinction between

present-directed and future-directed intentions, which are like what we call plans in Active Inference, the future-directed intentions.

And those you can think of as coming from your narrative about who you are, those future-directed intentions, like your example of going on holiday to France.

That's a future-directed intention that then sculpts the decisions that you make when you go on to your flight booking schedule.

Oh, sorry.

Let me just pause a minute.

Sorry about that.


SPEAKER_01:
So we're talking about present directiveness and future directiveness.


SPEAKER_00:
Exactly.

And how the narrative might be what connects together your present intentions with your future intentions and your past experiences.

I think your example of holidaying in France illustrated that very well.

So you have the past experiences of France being beautiful in the summer, and that then feeds into your plans for the future, leading you to form particular intentions in the present.

Absolutely.

So the narrative we can think of as at the higher level, doing the work of controlling planning in a way that you might think of gets you intentional action.

So actions where you could think that the intention is the cause of your actions, which is what we're looking for when we think about free will.


SPEAKER_01:
That's excellent.

Yeah, absolutely.

I completely agree.

Yeah, there'd be some wonderful ideas here.

Um, so just want to point people in the direction of, uh, Jakub Limanowski's work with Karl.

They sort of point to, uh, the depth of temporal modeling.

Karl has done this in his solo work as well to be.

really what underlies the construction or the generation of what they call an epistemic agent model.

And this is something that I spoke about in the paper, which is that an epistemic agent model can use past experience, past knowledge to inform allostasis, counterfactual reasoning, and all these things we associate with planning.

But that all comes from this really wonderful work that Karl has done with people like Jakub Lewinowski.

Okay, that's excellent.

Wonderful.

Okay.

we're talking exactly the same language, which is which is awesome.

Now, I want to go on to something maybe a little different.

And I'm going to make a I'm going to say a quote, firstly, just to frame the conversation.

So Lauren Shapiro, who you'll be very, you know, you'll be very aware of his work.

He says,

I challenge anyone to explain how I managed recently to travel from Madison to Cologne purely in terms of my sensitive responding to natural signs.

Now he says this in response in a review of Hato and Mayans books.

So the 2013 and the 2017 book now I just finished the 2013 book.

And I've been delving a little bit into the sorts of critiques, so Evans' critiques, Lawrence's critiques.

But again, I'm not an expert.

In my conversation with Chris, I actually had to go back and sort of clarify.

But Hato and Maya make this basic point that basal or basic cognition is contentless, representation free.

But you do have these higher order forms of cognition, which are scaffolded of social interactions, symbolic systems, developmental schema, which are basically about public language use.

Now, you, if I speak correctly, have a scepticism of this distinction between higher and lower forms of cognition.

And you, in your paper on affordances 2014, say, we suggest instead, so you say, we find this commonly made distinction between lower and higher forms of cognition unhelpful.

We suggest instead that the relevant distinction is better marked by differences in level of ability or expertise in doing things with the affordances of the environment.

So my first question is,

Do you think that cognition is representation free?

And if so, to what degree?

Is it all of it?

Is it just a lower order, the basic cognition?


SPEAKER_00:
What are your thoughts in that domain?

representations.

We're going to go into representations now.


SPEAKER_01:
I've been getting really into it.

And I know it's a very hot area and people get angry at each other.

So no one's going to get angry.

And feel free.

We don't have to go into it.


SPEAKER_00:
No, I'm not going to get angry.

Certainly not.

It doesn't make me angry.

But the issue comes up when we think about the generative model and what exactly Bayesian priors are.

So there's this purely statistical understanding of what Bayesian priors are.

what they turn out to be in the generative model and that i think we can unpack without bringing in anything like representations or content um this is a controversial position so most people would think as soon as you've got an internal model of the world

then that internal model has to be a representation because they think, well, it meets all of the conditions for representation.

Like, for instance, there's a structural isomorphism between the model and the environment where that isomorphism can be exploited.

So made use of by downstream processes to infer, to make decisions and so on.

So it looks like the internal model, the generative model, meets all of the conditions for being a representation, a full-fledged representation.

And I think it doesn't.

I think it's just a mathematical construct, the generative model.

that can be used to model autonomy.

And we can think of the agent not as having a model, but as instantiating a model of the internal, sorry, a model of the external dynamics in its internal dynamics.


SPEAKER_01:
Yeah, that's what I've been saying.


SPEAKER_00:
Yeah.

but rather as just a mathematical construct that describes the dynamics, the self-organizing dynamics of the agent in its coupling with the environment.

So we can give a contentless, content-free, representation-free account of what the generative model is.

That's part of what I want to say here.


SPEAKER_01:
Mm-hmm.


SPEAKER_00:
Now, you ask me, does that then commit me to something like Hato and Mayan's distinction between basic and cognition, which is non-representational, doesn't involve representations, and non-basic cognition, which is content involving or representation involving?

And to answer that question, we need to know what representations are because they clearly exist.

So it's just the issue is whether it makes sense to think of the brain as having content-bearing states.

So where exactly do representations come in?

And there I think we need to look at classic kinds of examples of what representations are in human life.

So we find representations when we use pictures and images and diagrams.

And those are...

coming from cultural practices like the use of diagrams to do science or the use of figures in writing articles or the use of

Pictures when we're doing art that can be traced back to making paintings on cave walls.

So these are representation-based practices, but they come from culture.

They don't come from what the brain is doing.

So that's one example of what a representation is, that it's an image or a picture.

A second example of what a representation might be is a state that carries semantic content.

So what is semantic content?

Well, it's a type of meaning where there's a determinacy to that meaning such that you can specify truth conditions, conditions of satisfaction.

that the state that's carrying that semantic content can be evaluated for.

So the state can be correct or incorrect.

It can be evaluated as correct or incorrect, true or false, and so on.

And the problem with the kinds of states that we find within a generative model is that they don't have the kind of determinate contents that map onto semantic meanings.

So when it comes to making the translation from Shannon information, is semantic information, where semantic information has this determinacy, this specificity to it, there's a mismatch.

We have to explain how to get from what is mere co-variation or correlation, which is what you're dealing with when you're thinking about Shannon information,

information that's specific enough that you can start to say that the organism could be wrong in how it's taking the world to be, or wrong in the way that it states are states that have meaning for the organism.

So it's that mismatch that makes me think, no, it's just not right to think of the generative model in terms of representation.

We can just make sense of it as a mathematical object that is tracking statistical patterns captured by the sorts of variables, parameters that we use to write down the generative model.

Long answer, but hopefully it gets some of the issues on the table for us.


SPEAKER_01:
No, it's wonderful.

It frames it very nicely.

And that is precisely, actually, in that 2013 book, at least, what Hato and Mayan say.

Just to repeat what you said, that it seems impossible to go from covariance to content.

And I think they actually have a principle for it because why not?


SPEAKER_00:
Of course, lots of philosophers don't agree with them about that.

So Nick Shay, who's a good colleague of Chris Frith, and they've worked together.

He has a whole book where he lays out how you can get

semantic meaning from adding some extra conditions to co-variation.

Right.

He thinks you need both indicators, so that's what Shannon Information gets you, and also consumers of those states that indicate something very roughly.

So once you have a richer account, he thinks that you can give an argument for thinking, well, no, there is real semantic meaning here, not just

Um, but that's one thing he wants to say, this like more nuanced picture where there's just different kinds of content that we need to bring in.

And, uh, how to a Mayan really focus on a very rich, demanding sort of content finding language.

That's a paradigm example of representation.

And what, what Shay tries to do is show, well, there's more, um, there's less demanding notions, weaker notions, which still qualify as content.


SPEAKER_01:
Yes.

Okay.

Well, yeah.

So, and Chris didn't have too much time for the radical and activists.


SPEAKER_00:
Um, no, most, most, uh, cognitive neuroscientists have no time for radical in activists and, and it's their own fault because the radical and activists are so kind of polarizing in how they engage in this discussion.

Right.


SPEAKER_01:
So yeah, exactly.

So I, I have no skin in the game, so I'm not gonna, I have no passion there, but I think

I think so.

I think Hato and Mayan obviously spend a lot of time criticizing this notion of cognition as content or the mark of the cognitive being representation.

Where I think there are viable critiques of their book and their work is the alternative is somewhat

not particularly, at least, explicated in any great depth.

They say, for example, they want to endorse the idea that organisms are informationally sensitive, i.e.

that they exploit correspondences in their environments to adaptively guide their actions, while denying that it follows that they take in, store, or process informational content.

This notion of exploiting correspondences sounds very much like there's a function there which indicates something else.

Now that is representation, right?

Under a Dretschian account of what representation is.

Now, on the other hand, if they say, well, no, all we're talking about here is just the responsivity of the organism, the adaptivity, the good jobs that they do by responding to stimuli.

Well, then I think this is the point that Shapiro makes, or maybe it's heaven.

Their teleosemiotics, what they call their teleosemiotics, is no different from behaviorism.

And actually, it's even more radical than the behaviorists, because all the behaviorists said was, well, it's just not really part of the scientific purview to talk about internal states, because all we can observe are behavioral action.

They didn't necessarily deny

um content bearing states they just thought it wasn't worth the examination until mr chomsky and so do you like is there a way out of this um conundrum that one is we find it very difficult to get content out of covariance and there is covariance but then the other hand it's very difficult to account for adaptive behavior solely in terms of covariance


SPEAKER_00:
so uh on the behaviorist thing and i think hato and mayan well certainly mayan is willing to just bite the bullet on behavior really yeah fantastic so behaviorism is often depicted as this like devilish position that nobody should hold anymore since the cognitive revolution but sure some caricatures and straw men about what behaviorism is exactly yeah

that I think the Mayan at least is in the business of, and also Louise Barrett and some of the work that she's done.

They're trying to correct for mistaken interpretations of what behaviorism actually means.

So that is part of the radical inactive project.

At least some people are pursuing that within radical inactivism.

um so how to go well why is indication that serves a particular function not sufficient for

for content according to Hato and Mayan.

Why couldn't we use that model and just have a completely contentless explanation of behavior?

Well, they think it's not sufficient because it doesn't get us the specific take on the world that's required to say that an organism could be mistaken.


UNKNOWN:
Yeah.


SPEAKER_00:
And any definition of content or meaning requires that the state that's carrying the content could be mistaken.

It could be misrepresenting how things are in terms of that state's particular take on the world.

So when we try to build in specificity and get that out of function, there's longstanding problems that that project has run into.

Again, it fails to get us the specificity that we require.

So where the debates kind of got to, and this is Nick Shay's position, is that you just need to have a more relaxed view of what specificity is, such that it depends on your question that you're asking, what kinds of questions you have in doing psychology or cognitive neuroscience.

will dictate whether you need more or less specificity.

So relative to your questions, you can get the kind of specificity you need to talk about content.

We shouldn't think that there's one-size-fits-all picture that's going to answer all of the different questions that we might have because each question might require a different level of granularity or specificity.


SPEAKER_01:
Sure.

We'll also try and offer a one-size-fits-all, but I'm curious about

your position.

So moving on.


SPEAKER_00:
Sorry, I've been saying what's been going on and elsewhere and discussions.


SPEAKER_01:
No, not at all.

That's my fault as well.

It's all the framing, which is excellent.

And I also wanted to backtrack on the heart and mind thing because it was it was dealt with quite briefly in my conversation with Chris, and there were certain things I had to go in and clarify post hoc.

So it's useful to people, you know, are aware of these clarifications.


SPEAKER_00:
So what do I think about all of this?

Well, I'm sympathetic to the idea that when we think about what representations and content is,

then this is where my phenomenological background comes in.

We need to go back to lived experience, which is where the notion of intentionality was first introduced by Brentano and Husserl and other phenomenologists.

So intentionality has its origins in lived experience.

And then when we try to deploy this notion in doing science,

And then we've taken up a particular attitude towards the world, the scientific attitude.

But the notion of content and meaning itself derives from our perception and thoughts as conscious beings.

So there's a bigger question here about how to make phenomenology fit together with the naturalistic worldview that we get when we start to do cognitive neuroscience.

and um yeah this goes back to another one of the ease the ease of the inactive camp where going back to the embodied mind of varela thompson and roche from 1991 the critique that they made of

Cognitivist cognitive science of cognitive science that thinks just cognition is information processing of some kind was that it doesn't have room for human experience.

If you think of of cognition as information processing, how do we then account for the what's described phenomenologically when we think of intentionality as a structure of human experience?

So intentionality here means the directedness of the mind upon objects.

And the idea of intentionality is that you're always working with a kind of relation between subject and object.

So intentionality is supposed to be describing a mode of experience that involves a central relationality between subjects and their world.

Heidegger went on to talk about this in terms of being in the world in a beautiful episode.


SPEAKER_01:
Thank you.

That was wonderful.

Yeah.

There's loads of things that come up here.

I mean, so firstly, you're not going to find an enemy of

Yes, please go ahead.

If you go.


SPEAKER_00:
Yeah.

Just where I look for intentionality and meaning is in lived experience.

And then that raises the question of how to bring together, how to make room for what was described in phenomenology when they were describing the human mind.

in cognitive neuroscience.

And Varela, Thomson and Roche put forward this idea of mutual constraints, that what is described phenomenologically is a constraint on the kinds of explanations that we give in cognitive science.

And what's described in cognitive science likewise, constraints, that's why this is a mutual constraint,

what we can make sense of phenomenologically.

So there's a kind of what's described by Varela in terms

a, what's the term he uses now?

Maxwell also uses this in one of his papers on computational neuro phenomenon.


SPEAKER_01:
Yeah.


SPEAKER_00:
It's, um, there's a kind of generative, um, passage between phenomenology and cognitive science that, that you get from this mutual constraint.


SPEAKER_01:
Yes.

Yeah.

Yeah.

Yeah.

Uh, yeah.

So I was saying, yes, he says from generative models to generative passages.


SPEAKER_00:
Exactly.

Yeah, so you're not going to find generative, but the idea is that we ought to be able to have this kind of passage, so bridge that goes between phenomenology, which was not describing anything in a scientific way, but trying to go back to lived experience.

There ought to be like a bridge that takes us from phenomenology to what we can now model computationally using the free energy principle.

That's the idea of generative passage.

Well, that's the game that I'm in and enjoying.

That's the game I'm in as well.

It's fun.

Yeah.

I'm enjoying it.

So involved in this within the active inference community.


SPEAKER_01:
Yes, it gives a wonderful way of doing it.


SPEAKER_00:
Back to the original embodied mind idea.

That book, The Embodied Mind, was what

I found as an undergraduate that brought me into this field.

And it's very inspiring.

It tries to bring together phenomenology, Buddhism, and cognitive science through this idea of inaction.

I still think it's a brilliant book.

I would recommend it to everybody.

Evan wrote it when he was young and Varela was at a later stage in his career.

So some of the ideas I think are developed much better in, in mind and life, which you also mentioned earlier.

Um, but, but just because of its kind of broad brushstrokes, it makes it very readable.

And, and so everybody can kind of get on board with the project at least.


SPEAKER_01:
Sure.

Yeah.

I'm very much enjoying mind and life.

Um, yeah.

So as you know, you're not going to find an enemy of phenomenology here.

Um, I like my Heidegger and Hussle and Merleau-Ponty.

I particularly like Dreyfus.

Um, and Dreyfus has a, Dreyfus I think is an important addition to this conversation because I hate to go back to them, but I don't hate to go back to them, but Hutto and Mayer actually mentioned Dreyfus.

Dreyfus's notion of skillful coping, skillful action as exhibiting intentionality.

And bear in mind, yes, it's not basic cognition according to them is not contentful, but it is still intentional in some sense it's targeting.

But they use Dreyfus to say, well, there are no mental representations or content.

And I build off some of this in this notion of flow states, which I think are a really interesting example of which taps into some of these ideas.

But the problem with this is that Dreyfus, I don't think, and I think this is the point that actually Evan Thompson made, that Dreyfus wouldn't say that those states are contentless.

And I wouldn't say those states are contentless.

Rather, they're intentionally contentful, but in a way that's not representational, in a way that it's not like there's a representation which stands for something precise in the world to which you can attribute, well, that function, you could attribute a truth claim.

Rather, there are these norms that are governed by perception and action loops and this biological autonomy that we've been discussing.

And but right, but there's still this intentional content, which he would call skillful coping.

And I think you could consider to be this kind of auto tellicity that comes out of flow.

So what does what what does the what do the phenomenologist contribute more broadly beyond Dreyfus, although he does rest his arguments a lot of Merleau Ponty about the role of content?


SPEAKER_00:
Yeah.

So, um, let's first of all, go back to the, the categories of the ready to hand and the present at hand.

The Dreyfus really focuses on in his, uh, in his work, uh, interpreting division one of Heidegger's being and time.

Um, so when we're dealing with the ready to hand, uh,

We're behaving in a way that our actions are drawn from us by the solicitations of the world.

That's the kind of phrasing that he often gives and that we, Eric Rietveld and I, and Jelle Brouneberg, the three of us have been very much inspired by Dreyfus's reading of the Ready to Hand.

So it's this responsiveness to the solicitations.

So solicitations are, for us, affordances which stand out from the surroundings as relevant or meaningful, salient to what the agent is doing.

So the classic example that Heidegger uses, which you know from the conversation with Marilyn, is the

the hammer and nails.

And you're a little bit worried about that example, actually.


SPEAKER_01:
Well, just the target to flow every day.

Yeah, but it's fine.

It will do.


SPEAKER_00:
Yeah.

So no, but we can think about my just reaching for my coffee cup.

Yeah, want to take a drink of coffee.

The coffee cup solicits my behavior, it draws my hand towards it.

So

Um, so my actions are kind of drawn from me in my forming an equilibrium state with, uh, the, the environment.

Um, so in our, in our work with yellow and Eric, we tried to argue that this tending towards an optimal grip can be thought of as a consequence of, uh, of what we were then calling variational free energy minimization.

And now I think since then, that paper was written in 2016.

So the field has moved on enormously.

Now we would think about those sorts of examples of tending towards a good grip, tending towards an improved grip in terms of expected free energy minimization.

But the idea there was that this kind of tending towards the right sort of optimal relationship with the environment,

is a consequence of what we can model in terms of free energy minimization.

Now, is that representational?

Well, I've been saying, no, it's not, because the generative model is not something that the organism has.

It's something that the organism embodies.

We can think about what are the dynamics that the organism instantiates, and do we need to bring in content or representations to explain the internal states that the organism instantiates?

And that's where I think the idea of inactive inference that Ramstad and Carl and Michael introduced in their adaptive behavior paper

And Carl talks about embodied inference sometimes.

These are all ways of unpacking how active inference might be understood, where you think, no, the organism is a model, and so it doesn't need to represent anything.

It can just be thought of in terms of states that carry Shannon information about the world, where that's not semantic.

So that's one thing I want to say,

the translation from the ready to hand via this notion of solicitation tending towards an optimal grip, those notions can be unpacked in a way that maybe we can characterize in terms of content, a content to be motor intentionality as Melo Ponti was describing it or comportment towards the ready to hand as Heidegger would describe it.

If that's what you're calling content, fine.

It's okay to talk about content here.

Why?

Because the content here is traced back in the end to something that we can describe in lived experience.

Sure.

I wouldn't call it representational.

nor would I call it semantic meaning.

Right.


SPEAKER_01:
Dreyfus wouldn't either, in the sense of those satisfaction conditions.


SPEAKER_00:
Maxwell does.

So Maxwell has this paper where he's trying to give an account with Innes, actually.

Strangely, Innes is a non-representational inactive theorist.

But they have this paper together where they try to give a formal semantics for

and they tried to derive a formal semantics out of Bayesian mechanics.


SPEAKER_01:
Yes.


SPEAKER_00:
And no, that formal semantics, if you think you can get formal semantics out of Bayesian mechanics, I think that that's really a representation is program that you're on there.

Sure.

Yeah.

I think what they do is kind of, it goes into this instrumentalist realist thing again that you've talked about before.

There's a little bit of as if stuff going on or looks like.

You've got to read carefully.

You've got to read through the lines.

So perhaps if you go instrumentalist here, then you can hold on to Innes' kind of inactive take on where representations come from, that they only come from practices.

They're not something that you find

or they come from the science of making models.

So scientists make models.

Those models can then be interpreted instrumentally as useful tools for representing dynamics and so on.

So you can start to think of where representations come in through scientific practices or without thinking that the brain is doing operations over semantic bearing, content bearing states.


SPEAKER_01:
Sure.

I mean, I still find it a slight challenge, that distinction, because I think there's a question about, well, how does public language become exacted into internal language such that you can even speak of internal representations?

But I think that's a separate question.


SPEAKER_00:
I think the thing to say there as well, and this is something I've argued with Eric as well, that if you think that the generative model is non-representational,

It doesn't thereby become representational just through a process of reenacting or reusing states that are content-bearing, like when we engage in inner speech and we make use of language to think with.

That's very much a phenomenological experience that we have of thinking in language.

But we shouldn't infer from that that when we're explaining inner speech in terms of neural processes, then there's inference over semantic bearing states going on.

Right.

Yes.


SPEAKER_01:
Yeah, I intuitively...


SPEAKER_00:
separating those phenomenal and content but maybe that's just me there's the modeling which is something that can be characterized in purely mathematical statistical terms just in terms of shannon information and then there's the interpretation the gloss that we give of the model as scientists where we may be able to interpret what

We're modeling in terms of meaning and representation, but that's something that we're doing as scientists who are making use of representations to interpret their models.


SPEAKER_01:
And yet there is still, unless you're an illusionist about the whole thing, phenomenal experience.

And so I find it difficult just personally to separate content from phenomenal experience.


SPEAKER_00:
so yes that's what i was arguing as well in trying to connect to motor intentionality in in phenomenology in yes or to the ready to hand okay dealings with the ready to hand so yeah okay okay that okay i see that okay those are notions of intentionality and content and meaning yes without without truth and accuracy being built in

yeah and then they're not their descriptions of lived experience of human beings and so when we're describing lived experience i agree it makes total sense to bring in the notion of intentionality as a structure of lived experience and if we try to read that back into what we're modeling when we use a generative model or um or into the target system that we're modeling the brain yes

there's an extra move that's being made there that we can go from the notion of intentionality as it's used to understand lived experience to whatever we're doing as scientists when we use a model, model a target system, the brain.

So there are three things there.

There's lived experience, there's the model and the Bayesian beliefs that we use to write down a generative model.

And then there's the target system, the brain that we're using the generative model to make inferences about in the end.

And where do we bring in intentionality?

Well, for me, only in lived experience.

And then we can use the model, the Bayesian beliefs, Bayesian mechanics to...

explain, in the terms of cognitive neuroscience, lived experience.

That's the generative passage from phenomenology to cognitive neuroscience that's made possible by Bayesian mechanics.

But we shouldn't think that then we're going to read back straight from the phenomenology intentionality into the Bayesian mechanics.

Bayesian mechanics is just mathematics and statistics.


SPEAKER_01:
Yes.


SPEAKER_00:
What's described in phenomenology because of the generative passage.

But we need to be careful not to just conflate the two and match the two together because they're not the same thing, the Bayesian mechanics and intentionality.


SPEAKER_01:
No, it's a very useful disambiguation.

I guess the only question that, well, one of the only questions that comes, one of the questions that comes to mind, because I have plenty, is about perception, because perception is cast as

resulted, again, it's quite, it's not particularly well sketched out, but resulting from Bayesian mechanics, in the sense that perceptual adequacy is just the minimization of the KL divergence, the recognition density and the true posterior.

So this leads us quite nicely into affordances, because you have in your 2014 paper, you have, I believe the section is called affordances for higher cognition.

And you talk about this example of a nettle and mint leaves, which

I would like to read out because I think it would be a very useful framing.

So you say, does he quote Gibson, who says that the affordances of human behavior is staggering, because it's in the whole domain of social significance.

And then you give this example, you say, for instance, when we are out looking for mint leaves to make mint tea and a friend incorrectly reaches for a nettle, we can stop him or her by making the judgment that is not a mint leaf, that is a nettle.

In doing so, we are skillfully engaging with the affordances the nettle leaf has in our form of life.

The leaf affords judging correctly that it is a nettle in our form of life.

You see, for me,

For me, I just cast that as a that just for me is just what one person's model is perceptually adequate and the others isn't.

And for me, that's pure Bayesian mechanics about the reduction of the KL divergence.

But that yields that doesn't necessarily yield me an affordance in terms of public language use.

It just yields perception.

So maybe you could explain, because people might hear that and go, well, I don't think that the seeing of the nettle is in and of itself encapsulated in the notion of an affordance to inform your friend that it's a nettle.

Rather, this is just perception, right?

And the role of perception is purely just to achieve what I've been calling descriptive adequacy.

Whereas action, the maximization of model evidence gives us normative viability, normative

Yeah, normative explanations.

So it seems to me that you're kind of slotting perception into norms and in some sense, the maximization of model evidence, i.e.

I need to be a good social actor in this situation.


SPEAKER_00:
Well, one thing that's important about that example is that it's supposed to be an example of discursive

thoughts so the person judges that's not a a nettle sorry that's not a a nettle that's a mint leaf or is it the other way around i can't remember no it's not a net it's not a mint leaf it's a nettle

But the point is that it's a demonstrative judgment that's being made, a judgment about the type of leaf that the person's just picked.

So there's a perceptual categorization going on that might make it look like it's just a perceptual phenomena that's being described here.

But it was being introduced as an example of perception serving as a reason for making a judgment, a particular kind of demonstrative judgment.

about the type of leaf that you're looking for and whether this is that type of leaf or not.

So it was being given as an example of higher cognition because people think that higher cognition is reason responsive.

So you're in the space of reasons, you're not just in the space of causes anymore, to use a distinction from Wilfrid Sellers.

So if you can make this kind of demonstrative judgment based on your perception, that's because you're responsive to what the reasons are here.

So there's a kind of rationality in play in this example of perception.

And then the question is, well, you were pushing the idea, well, it's just about the Bayesian mechanics, this kind of using of perception to make judgments.

And there I think we need to be careful to distinguish personal level explanation.

which is explanation in terms of reasons from sub-personal processes, which are being described by Bayesian mechanics, where the inferential processes here are supposed to be just a matter of mechanics, just a matter of Bayesian mechanics.

And we want to, in the end, connect up

we're appealing to in our personal level explanations this is the bridging idea with what can be described sub-personally in terms of bayesian mechanics but how do you go from the personal level explanation which is reason giving kind of explanations to sub-personal explanation

There's an interface problem, as it's sometimes called here.

How do you get your reasons to interface with the causes, which is what you're interested in when you're thinking about Bayesian mechanics?

And I think what you were doing was saying, well, you were missing that there's an interface that we need here that allows us to move from personal level explanations to sub-personal explanations.

We shouldn't lose that interface.


SPEAKER_01:
No.

No, I agree with that.

I've said on paper that I think there is an issue how perception, let's say, just gets chucked out of KL divergences.

That's an issue.

I'm not denying that.


SPEAKER_00:
I guess my question here was... Going back to the phenomenology discussions again, the way we were thinking about this was the kind of intentionality that perception has where

That can be thought of just in terms of what Husserl called passive and active synthesis.

So there's a kind of constitution that we can appeal to at work in perception that is pre-predicative, comes before any categories are introduced.

And then there's a kind of intentionality which is distinctive of thought and judgment.

where that is uh predicative it's categorized so you're bringing in some kind of subject object distinction you're dealing with the present at hand yeah um and this example was supposed to be like an example of that moves from the ready to hand to the present at hand because there's some sort of breakdown that happens there's a mistake that's made um

that gets corrected and that pushes you to start to think and make judgments.

And so you're not any longer dealing with just being drawn by, well, actually we want to say you are, because we bring in this idea of affordances that come from language, but, um,

But what's important is that we're dealing with a discursive, propositional, predicative form of intentionality in the judgment that's being made here, not just a pre-predicative, subject, objectless form of intentionality.

Sure.


SPEAKER_01:
Yeah, I guess part of my point was...

we have to integrate the ready-to-handedness form of intentionality with the present at-handedness intentionality.

And I think maybe one reading of this would just be like, oh, we're just skipping over the fact that there's some concept-free perception going on in the first place.

And I just wanted to get clarity that that's not what you're saying.

There is still the perceptual act prior to the categorization that language grants us.


SPEAKER_00:
So I agree with you that we need some way of integrating the ready to hand and the present at hand.

That's what you just said.

That's absolutely right.

That takes us back to this question of higher and lower cognition and how we want to call into question that distinction in the end.

So you could think there's still a distinction to be made here.

So looking at the paper by Andrew Corcoran and Jacob Hoy, Giovanni Pizzulo, they have this beautiful picture where you can go from homeostasis to allostasis to planning deep temporal models.

you might think that that underwrites a distinction between higher cognition, which is where you find planning and deep temporal models, and lower cognition, where it's just about homeostasis or about chemotaxis, like in the Shantz and colleagues model of chemotaxis.

So there's this differentiation that you get where higher cognition emerges in these deep temporal models.

And what we want to say is, well, that's the kind of approach where you try to get to higher cognition vertically by building up from lower cognition.

mere homeostasis to higher cognition deep active inference parameter deep parametric active inference as last sanford smith calls it quite yeah yeah now we want to do something that's different from that which is to horizontalize the whole thing so instead of trying to build up to higher cognition vertically in the generative models

through temporal depth we want to look at the horizon in which we engage with the environment and think that spatially and temporally there can be more or less distal engagements with the environment that are made possible by us being by our cultural practices so this goes back to

where we actually started on the question of cultural ecosystems, niche construction, and how once we have in view the idea that the environment predicts agents as much as agents predict the environment, then we can start to have a picture where instead of thinking of temporal depth as coming from

the hierarchy in the deep temporal generative model, we can think of temporal depth as coming from the ecosystems in which we're situated and the way that those ecosystems make possible dealing with distal states of affairs that are currently absent from us.

That's what I think we get from language, from being able to

engage in propositional type reasoning, reasoning where we're using predicative forms of intentionality.


SPEAKER_01:
This is how you sort of end up swallowing up.


SPEAKER_00:
To do perceptual judgment, to do thinking about what is currently absent, dealing with the distal and so on, where people normally bring in representations.


SPEAKER_01:
Yeah, so this is how you swallow up, if you pardon the pun, representation hungry cognition, whereby you sort of refute offline cognition as being distinct, but rather this, quote, more complex form of coordinating nested states of action readiness and activities to multiple relevant affordances.

Such a process is complex because of the nesting of the activities and their increasing reach through time, which I guess gives us

Well, at least your answer to Shapiro's challenge, which is not going to be convinced by that.


SPEAKER_00:
I mean, you already said, well, yes, natural signs.

Don't explain how you can navigate from Madison to wherever.


SPEAKER_01:
Yes.

I guess my question here is, why can't we have both?

And so what I mean by that is, you also give another example from Shapiro, reenacting his past experiences going to his household, his former house in New Jersey.

And you say that, you know, him pretending to engage in those activities of being there is in itself a act of coordinating to multiple relevant affordances.

But my question is, why can't we?

Why can't we

sort of have our cake and eat it too, in the sense that we can accept that.

And we can accept that when I'm trying to get my train from, or my plane from Madison to Cologne, that's me reacting to the affordance of going to Cologne and what that might afford me.

Why can't we also say that to even kick off that process, I have this kind of offline representation, which frames my nested activities, I want to go to Cologne.

Or is that permitted?

Because you want to reframe representation-hungry cognition.

You say you give the, quote, possibility of a positive alternative, namely whether representation-hungry cognition might be achieved by other means by, for example, skillfully coordinated, complexly structured nested activities to multiple affordances, such that episodic memory imagining can be given in these terms.

I just don't see why we can't have both.

We have the benefits of saying, okay, these are representational, so they include content, they include public language or private language in this case, and also they're a response to affordances.

Why do we need one rather than the other?


SPEAKER_00:
So it goes back to a number of things that we've been talking about already.

So one is where does intentionality originate from?

Where does content meaning originate from?

And so

I've been contending that the source of intentionality is lived experience.

Sure.

So the reason why I want to appeal to practices in the form of life,

like how language is used within communities following a Wittgensteinian model, is because that traces meaning back to something human, to what human beings do when they are speakers of English, say.

What they are able to do then is to articulate certain thoughts, but they're also able to revisit past experiences by constructing narratives about those past experiences.

So that connects us to the narrative topic again.

And I think the way that you were describing things was to suggest that narratives can be modeled at the higher layers of these deep temporal models.

That's absolutely right.

They can be modeled in that way.

But does that mean then that the narratives just are the processes of inference that take place within these deep temporal models?

And that's where I would say, no, we shouldn't make an identity between the narrative and the

and what we're modeling using a generative model, because the modeling practice is being done by a scientist.

And those models that the scientist is constructing are what we use then to explain some target phenomena, which is the cognitive process of constructing narratives, but can also be understood in terms of the actions of scientists

normatively regulating your linguistic behaviors so that they fit with how other speakers of your language behave.

That's something which is very much a cultural communal activity.

So yes, generative models capture these processes.

They give us ways of explaining them in the terms of the free energy principle and cognitive neuroscience.

Should we then take the phenomena that we're modeling to be nothing over and above what can be modeled using these generative processes?

So we simply identify the behaviors of constructing narratives, thinking about our past experiences, being a master of linguistic practices.

Can we just identify those behaviors

behaviors with what we're modeling when we use generative models that's where i say no because there's a lot more to the linguistic behaviors there are the practices the what people do when they belong to communities now interestingly and this connects to where we started from those practices and communal behaviors can also be modeled using

Bayesian mechanics, where we think that the system now is a collective system that has maybe collective intelligence and is made up of lots of interacting agents.

So we can also model that system using Bayesian mechanics.

But should we then say that the collective system just is a free energy minimizer?

No, because the target system here

is one that can also be described by doing social science by doing linguistics and it can be described using lots of different explanatory frameworks and all of those explanatory frameworks can be made to um bridge can be bridged to from bayesian mechanics that's super interesting but we shouldn't then try to do a reduction of all of these other explanations to bayesian mechanics

So what I'm resisting here is a kind of reductionism where everything can just be taken back to physics again.

Sure.

I want to say no.

There are social dynamics, cultural dynamics where we need the tools of social science, where we need to do ethnography, for instance, or anthropology, or where we need to do phenomenology to understand these dynamics and

And those also give us very good ways of interpreting and understanding what human beings are doing as agents.


SPEAKER_01:
Yes.

Yeah, I don't think it's a reductive claim, the relationship between the phenomenal and the physics.

When I've written about it, I've used words like,

emergent or causally downstream from, and I know these are problematic words and whether it's supervenient or not, these are obviously very tricky and philosophically, um, deep questions.

I guess my, my only point here about was if it doesn't need to be reductive to say that representations, at least in this, uh, episodic memory imagining.

might have a role or may play a part.

I'm not saying it's the whole picture.

I'm not saying that it replaces the Bayesian mechanics.


SPEAKER_00:
I think representations do play a role in episodic memory because there are forms of episodic memory which are

are such that we can articulate and we can express linguistically what we're remembering.

And that process of putting it into words, of articulating it, is part of the construction, the reconstruction of that memory.


SPEAKER_01:
Okay, yeah, that's exactly right.

So then my question really was, why are we considering this?

You posit the

framing of offline representations as nested activities governed by the affordances that the environment grants us as a positive alternative to representation hungry cognition.

But it sounds like you're also permitting there to be some representational schema in place.


SPEAKER_00:
The difference is that we don't think of the representations as something that's part of the information processing.

representations get involved, but not via the generative model.

Because the generative model for us is just a mathematical model.

It's just pure statistics.

It's not bringing in... I mean, you can then give interpretations of that statistics using constructs like Bayesian belief and inference over beliefs and inference of posteriors and so on.

But that's all a gloss on something that is just mathematics and statistics.

so where do the representations come in when we're trying to understand and explain in terms of cognitive neuroscience episodic memory they don't come in through the brain they come in through the coupling between the agent and an environment that is structured by social cultural linguistic practices so we talk about affordances in our more recent work as in languaged

Andy Clark talks about material symbols.

He has very interesting work with, um, um, trying to think of the name, the guy's name, Gary Lupian about how, uh, material symbols, for instance, can scope precision expectations.

Um, but they're doing that work, not, uh, internally, but, uh,

as material symbols that are in the environment, that are situated in the environment.

So this example of language sculpting attention, sculpting precision, is an example of a looping through the world where the material symbols are being taken up and included in the precision estimation process, in the sculpting of precision.

as something that is located in the environment, something where the agent is coupling with a with an environmental structure.

In this case, real symbols.


SPEAKER_01:
Yeah, that makes it a lot clearer for me, I guess the question that going back to Shapiro's episodic memory imagining.

So

What would that look like in this kind of worldly loop?

So just to provide the example, he imagines going back to his family parent house in New Jersey.

And he say, how on earth could that be part of, you know, how on earth can that be representation for you?

But you're not saying that's representation for you.

You're saying it's just that that representation is yielded from the action, uh, the agent arena relationship.

And it's not actually part of the Bayesian mechanics.

Okay.


SPEAKER_00:
Well, what does, what does that mean for this Asian mechanics?

Because I want the Bayesian mechanics story to apply to extended systems as well.

Sure.

Sure.

Internal to the brain anymore there.

Part of this that's getting the representations involved is the coupling with representational practices.

So being a language speaker who can articulate and put into words a past experience like the poster that was hanging on your bedroom wall as a child.

Yes, Jimi Hendrix.

Being able to remember that poster is something that you can do because you're a language speaker who can describe, can make sense of linguistically past experiences that you've had.


SPEAKER_01:
Is it wrong to say that just because that capacity is scaffolded from my development and the culture in which I've been raised, that that hasn't become internalized?

Are you permitting that?

Because you're saying it's not in the brain.

My intuition is telling me that fine, language didn't... I mean, we're not going to go into nativism and Chomsky because it's not really that relevant.

But fine, language comes from exposure to data and societal norms and so on.

But at a certain point, I can use language in the absence of social contexts.

Like in the case of my EM imagining, Shapiro's EM imagining.

So it seems like in that case, it has been internalized to some degree.

It's just that it was the presence of a previous social dynamic was necessary for its internalization.


SPEAKER_00:
Yeah, so that's really interesting.

And the key question there is how to think about what internalization means exactly in the case of episodic imagining.

So in keeping with the ecological inactive approach, what we try to do is say, well, what conceptual framework do you need for making sense of

episodic imagining in terms of Bayesian mechanics.

So is it a representational conceptual framework, or can we instead use the tools of ecological inactive cognitive science, what we call the skilled intentionality framework, to make sense of the Bayesian mechanics that's involved in that example of episodic imagining?

And we would argue that you can make sense of what's happening in that case by thinking of it not vertically, i.e.

looking at the top layers of the generative model and then saying that's where episodic imagining happens.

It happens in a kind of mental time travel that is made possible by deep active inference.

But instead thinking that the cognitive system here is an agent environment system.

episodic imagining, internalization of linguistic abilities is a matter of skills that you have as a language user.

And those skills are then, well, the kind of meaning that's involved here is accounted for in terms of responsiveness to affordances.

So this all just sounds very philosophical and not interesting to scientists.

So I'm not sure how much your listeners are going to get out.


SPEAKER_01:
Oh, they're philosophers.

They love it.


SPEAKER_00:
I mean, there's so much, yeah.

To go to agent environment system and to try to understand horizontally in terms of the dynamics within the agent environment system, what could be going on when somebody can revisit their past experiences and construct that kind of experience of the poster on their wall.

So horizontally, what's going on there, we think is that you're using your skills as a language user.

So as a master of English, I can then make sense of my past experiences and interpret them as the experiences of this poster of Jimi Hendrix, let's say.

Yeah.

Yeah.

Okay.

Cultural stuff that's packed into that.

Yes.

And that stems from our skills as speakers of a language.

Sure.


SPEAKER_01:
Okay.

To cap off this profound conversation into affordances, which I'm sure has taken many people into the weeds.

They're probably sick of us talking about it.

I guess the question is, the overarching question therefore is, so these representational states are scaffolds yielded from language learning in a cultural setting.

In terms of the actual act, therefore, of reimagining, do the presence of those representations have a causal role, or are they just epiphenomenal over the affordance exploitation?


SPEAKER_00:
But the representations just are affordances for us.

Now we try to have an ecology, a cultural ecosystem that is populated by affordances that, that grow out of our linguistic practices.

So the representation, external representations, we think that there are no internal mental representations because

Those are scientific constructs in internal mental representation that require you to be able to solve this hard problem of content that we were talking about earlier on.

Um, we don't think that representations are not real.

There are real representations, but they're just not internal mental representations.

They're not internal to the brain.

They come from our cultural systems, like our linguistic practices, our systems of making pictures and images and diagrams.

Um, we couple to those practices as participants in those practices.

And that's what allows us to engage in, uh,

in representational style cognition by making use of these external resources in our environment.


SPEAKER_01:
Okay.

And I guess the people's worry might be the sort of standard objection that this position means that affordances can't have any objective quality, which undermines Gibson's original realism.

But I believe you have a response to that in terms of

the fact that we also have to take in the material reality of the affordances too into account not only our socio-cultural practices again the paper the 2014 paper is cracking so everyone can just go there um i mean how long have we been going for two hours and five minutes okay we'll wrap up in a bit in a sec there's so many things i want to ask about um we didn't even really touch on you can you can like figure it out in the editing right yeah yeah yeah it's always all in the editing in the end i don't edit them that much um

I do want to so there's, there's a paper that you have about mindness.

So about self modeling and mindless.

Which I thought was really interesting as I'm fascinated.

This is slightly further down on your Google Scholar, but I saw it and I thought I have to have a bit of that because I love the self modeling is entirely why I'm fixated on them or not entirely.

And you say,

In line with the arguments of the phenomenologists, I will claim that every feeling must be felt by someone.

It must have mindfulness built into it if it is to feel a particular way.

Some people might go, well, I thought that Anil Seth and...

absence of curious said that mindfulness came from interoceptive inference.

And that is the sort of seat of the so called minimal phenomenal self.

And if that disbands, so does the notion that the experiences the feelings the affect that I have a mind.

Maybe it's worth just separating your perspective or your position from theirs.


SPEAKER_00:
Yeah, so this goes back to, again, generative passage between phenomenology and free energy principle, cognitive neuroscience.

Because the mindness construct is a phenomenological construct.

It's describing a structure of consciousness whereby every conscious state is also experienced at the same time as it is an experience.

Mindness is capturing the relationality that is part of the experience, whereby it's an experience of mine or yours.

Sometimes this is called sense of ownership, that each experience is owned by a subject.

And then when you have phenomena like depersonalization or derealization,

That can be thought of in terms of a loss of this experience of mindness.

We can debate whether that is entirely lost or not.

So Anna Chaunica says it's not.

It's just disturbed in some way.

So there's still this phenomenological structure that's present.

But the phenomena of depersonalization, derealization is a disturbance of that structure of experience.

And I think that's right.

So then what we need to try to do is to take the phenomenological structure and bridge to how we could think about that in terms of active inference.

And that's where the idea of interceptive inference or multisensory integration understood in terms of integrating interceptive predictions with extraceptive predictions.

That becomes then a construct within active inference that we can use to build that bridge from the phenomenology, the idea of mindness as a phenomenological structure to cognitive neuroscience.


SPEAKER_01:
Okay, so...

Okay, so so yeah, Anna doesn't say that it completely disbands the sense of ownership.

I don't know if you've read George Dean's paper on where he's got two papers wonderful, but one on derealization, the other on psychedelics.

Yeah, self dissolution.

He goes a bit further.

And I made this point at the end of my paper that I think they're talking about two separate parts of the derealization process.

And I think Anna's is just a bit more moderate, whereas George's is a bit more severe.


SPEAKER_00:
Um,

It's a good, good difference that you pick up on there.

That's definitely a divergence, an interesting divergence.


SPEAKER_01:
Just talking about my from, I think it's very explicable that divergence, but I think they're just talking about two different phenomenological states.


SPEAKER_00:
But George would say, she would be a really good guest.


SPEAKER_01:
She has spoken to plenty of times, I think, yes, I think she might well be coming on.

But I guess the question here is, okay, so

I'm from the school of people who say, well, mindless is emergent from the computational processes.

It's emergent from the interoceptive inferences, from the integration, the multisensory integration.

So what that means is that if that breaks, so for example, George Dean gives an example of torture.

And I mentioned this to Chris as well, that if you're in a torture chamber,

you're going to be very unlikely to be able to succeed in suppressing interoceptive prediction error.

And torture is a very reliable instigator of depersonalization.

But there are still experiences.

There are still feelings.

But the sense of ownership has gone.

But you said, I will claim that every feeling must be felt by someone.

So who are those feelings being felt by?


SPEAKER_00:
So what's lost is the transparency in that case of

um ordinarily our uh our sense of mindness the experiential self is not something that gets in the way uh something that was conspicuous in our experiences rather transparent we look through it to the world and that notion of transparency is then modeled using uh

disattending sensory attenuation.

Thomas Metzinger and all that.

Yeah.

Yeah.

So what happens in the torture example, I think, is that what would normally be transparent becomes opaque.


SPEAKER_01:
Mm-hmm.


SPEAKER_00:
and then becomes very conspicuous to you and your way of dealing with the prediction errors that come with the pain experience, and we've done some work on pain, is by dissociating from it.

Okay, that's interesting.


SPEAKER_01:
So it's

Yes, I mean, people do talk about derealization, for example, as this kind of bubble wrap.

That's there as a function to dissociate from pain and from the anxiety of being eaten by a tiger or whatever in the savannah.

So okay, that's the kind of not off the pain.

You're arguing that the minus is still there.

It's just somewhat clouded by this objectification or opacity of what normally would be transparent.


SPEAKER_00:
So go back to Melo Ponti's example of the two hands touching, which he uses to illustrate how the body is both an object and a subject of experience.

And ordinarily there's this, what he calls a chiasm, so an intertwining of the subject and the object in the body.

And what happens in...

depersonalization, derealization is that this intertwining of subject and object now breaks down.

You have now a kind of distancing of the subject from their body.

And that's necessary in the torture example.

It's necessary to, in some way, disidentify with the pain experiences, to treat them as some kind of object that's separate from you if you're to be able to deal with the pain.

So the derealization is a kind of adaptive response to what would otherwise be overwhelming, where you can gain a distance from it and relate to it as if it were not you that this was happening to, as if it were an object that was separate from you.


SPEAKER_01:
Yes, this is this is this is very much Anna's account.

And it feeds into this notion of kind of hyper precision over beliefs about the self model, which leads to this kind of dissociation.

But again, like the way that I was writing about it was not only that, but also what Dean and colleagues spoke about in 2020, which is, they use this quote from a writer called Lofthouse 2014, saying,

first time i remember feeling like the first time i can remember feeling like i didn't exist i was 15. i was sitting on a train and all of a sudden i felt like i'd been dropped into someone else's bodies my memories experiences and feelings uh and feelings the things that make up my intrinsic sense of meanness projected across my mind like phantasmagoria but i felt like they belonged to someone else like i was experiencing life in the third person so this seems slightly different


SPEAKER_00:
But I think the key thing to pull out from that quote is I felt like these experiences belong to somebody else that I felt there is that still the presence of mindness.

So it's me that this is happening to similarly in examples of ego dissolution.

Yes.

That's what I was going to ask about as well.

Yeah.

Psychedelics that George talks about in the losing ourselves paper.

And also in another paper about ego dissolution, I forget what it's called.


SPEAKER_01:
There are a couple on there, yeah.


SPEAKER_00:
So you might think, well, ego dissolution is a kind of egoless experience.

This is how Raphael Millier describes ego dissolution in

in extreme examples that there's just this complete loss of ego, of self.

But I think rather what happens in those examples is that there's you that's undergoing these very strange experiences.

You're still present as the subject of them.

It's still me that this is happening to.

I've taken the psychedelic.

And now I'm undergoing this experience of loss of boundary between me and the world or this kind of feeling of union and connectedness with nature.

And that's an experience that I'm having.

So there's still that mindness that's part of the experience.

But there's something that's lost as well, which is this higher narrative layer of the self.

Instead of identifying with who I have been in the past and then that identity being brought into the framing of my experience, I think George is right that there's this kind of loss of temporal depth.

So influence of the narrative on your experience of who you are at that moment is now stripped away

But still, what's in place is the core or minimal self, the mindless.


SPEAKER_01:
And for you, that's just intrinsic to the experience?


SPEAKER_00:
it's part of the structure of the experience it's a phenomenological structure interesting as you saw described it called it ipsaity and of course disturbed in in uh psychopathologies like schizophrenia or uh depersonalization derealization depression these are all disturbances of the self yes

of that ipsaity, which is part of our experience.

It's our perspective on the Welsh.


SPEAKER_01:
So I guess my thinking here is that maybe I'm wrong, that where I've divorced Dean George's and Anna's accounts, they can actually be tied under the single banner of distancing, opacity, hyper-precision over self-models.

so on not that dean that not that george's account implies the total uh dissolving of the self-model uh well you know there's there's some debate about this isn't there about whether the self-model is entirely dissolved or not and


SPEAKER_00:
George, I think just talks about it in terms of the shrinking of the temporal depth, this diminution of the temporal depth.

So you could ask, well, is there still something that is left of the self once that temporal depth is lost?

I would tend to think about it in terms of different layers of the self model and the temporal, the loss of temporal depth is describing the,

the narrative layer of the self model.

That could leave in place the bodily core minimal self, which is what is accounting for mindness.


SPEAKER_01:
But it isn't in and of itself, according to you, sufficient for mindness in the sense that mindness is just part of the structure of experience.

So as well, is there a distinction here between mindless and self modeling such that you could have dissolved entirely dissolved self models, but you would still have experiences that by necessity are owned by someone?


SPEAKER_00:
It goes back to the same question about the relationship between phenomenology, personal level explanation, sub-personal processes, Bayesian mechanics.

And the way I think about that relationship is using the idea of generative passage from Varela.

So mindness and phenomenal selfhood, I don't think are identical with the generative model and the processes that are described using Bayesian mechanics.

Those processes explain in the sense of they give us a model that will allow us to bridge to phenomenology.

But they don't reduce.

You can't reduce the first-person experience, which is where we start from, the lived experience, to what can then be described, modeled in third-person terms using Bayesian mechanics.


SPEAKER_01:
But if I were to say that, I guess what I'm getting up to here is you could claim, there have been claims, for example, that interoceptive inference underwrites the minimal self model, such that if interoceptive inference falls apart, if it's just completely unsuccessful, such as in the torture chamber, the minimal self model itself will dissolve.

If you just grant me that causal relationship,


SPEAKER_00:
But the construct of the minimal self model is a construct introduced by Metzinger in order to make sense of cognitive neuroscientific models of lived experience, of phenomenal selfhood.

And of course, Metzinger thinks that we should be strong realists about the phenomenal self model as described in cognitive neuroscience.

And we should say that

that what we learn from cognitive neuroscience is there's no self and that mindness is just a construct of the brain.

It's hallucinated actually in the end.

It's a controlled hallucination, but in the end you can lose it entirely because it depends on and is identical with

inferential processes that are taking place in the brain.

Whereas my view is different from Thomas's in that I don't start from cognitive neuroscience and what can be modeled within cognitive neuroscience.

I take as my starting point, and this is what Varela meant when he said,

um that cognitive science should always go back to find a way back to lived experience because lived experience is where we start from and it's what we must always return to and this is from um his paper on um neurophenomenology so so that the idea there is that what's basic what we start from is lived experience

And then we have to try to find a way to explain that in the terms of cognitive neuroscience.

And that's what the phenomenal self-model gives us and what Bayesian mechanics give us.

They give us a way of explaining in naturalistic cognitive science terms what is described in phenomenology.

But what's real, what's most real here, what we start from is lived experience.


SPEAKER_01:
Would you say that Thomas says that the phenomenal self model is identical to the inferences that the brain makes or is emergent over the inferential mechanics that are occurring in the brain?

As in one is causally related, the other one's an identity?


SPEAKER_00:
Depends what you mean by emergent there.

So emergence can be understood in like a weak sense of epistemically, we can't really predict from

the lower level, the properties that we find at the higher level because of non-linearity, because there's something non-additive about the causes.

That means you get something qualitatively new once you move to the higher level.

And that can just be understood in a purely epistemic way.

Or it can be understood ontologically that there's something new that's brought into existence, a self that you get from, or a phenomenal self-model, which is just a construct of the brain, but it's a higher-level construct that emerges out of lower-level processing as something ontologically new.

And then you could say, well, what's the relationship between the phenomenal self-model and the experience of being somebody or the experience of mindness?

And Thomas's answer to that last question is that the experience of being someone is an illusion.

It's a, a, the outcome of, um, the phenomenal self modeling process, which is in turn the outcome of inference and Bayesian modeling.

He would now say, I guess, um, so, um, emergence,

answer your question can be understood in like a weak sense or it can be understood in a stronger ontological sense and the stronger ontological notion doesn't decide in favor of the reality of the self because you could still believe that this phenomenal self model is strongly emergent even though in the end it's just an inferential construct of the brain and

So whether you say emergence gets you a real self or just gets you and lose reconstruct, as Thomas argues, I think doesn't fall out of the concept of emergence on its own.


SPEAKER_01:
Okay, that's, that's really, that's real food for thought.


SPEAKER_00:
I'm gonna have to differentiate out my position and the position of other people that are trying to do neuro phenomenology from, from Thomas's position, because we think, I'll speak for myself, I think that the Varelian project of generative passage,

means that what's real here is being in the world or lived experience, the body subject.

And then the task for anyone that is doing 4E cognition that comes out of the inactive strand of 4E cognition is to try to build a bridge back from lived experience to what can be described scientifically.

So thereby making room for lived experience within science.

And that can then take a more elaborate form like John Vavakey's project of not only just trying to build room for lived experience within cognitive science, but these richer notions like wisdom and the sacred and meeting in life and so on.


SPEAKER_01:
But yeah, it's, it's at least according to your, your own phenomenological camp, I might say that the reduction to the science is a false move.


SPEAKER_00:
Yeah, I take 4E cognition to be non-reductive.

Sometimes that non-reduction move is cashed out in terms of a strong notion of emergence, so that connects to what I think you were trying to do.

So Evan Thompson will talk about neurophenomenology as committed to circular causality, where at the

the higher levels that are to do with consciousness and lived experience loop back down and change the lower level dynamics.

So that's a kind of downward causation or a strong form of emergence that he thinks you get from neurodynamics, from self-organization, from autonomy, which is where we started from.

Um, so neuro phenomenology then would, would get you a kind of metaphysics where, uh, there's a strong form of emergence and consciousness can actually make a difference to, um, neural dynamics too.

Yeah.

As a higher level property, it can loop back down and change the faster changing processes in the brain.


SPEAKER_01:
Yes.

Well, this, this has its resonance.

to use a relevant term with active inference.

But yeah, as you say, it does.


SPEAKER_00:
There's this idea of enslaving and synergetics that Carl has been influenced by that comes from Herman Harkin, where there's ensemble dynamics that unfold over slower timescales.

and loop back and change the faster time scales.

So causation that's being described there.


SPEAKER_01:
Get away from the analytic philosophy, just more colloquially.

Would you ever use the term self modeling?

For you?

Does it?

Does it?

Does it make sense in terms of the phenomenological starting point to even talk about self models?

Or is it, does it, does it make more sense to talk about intentionality and mindless and so on?


SPEAKER_00:
So I, again, we have this necessity to, to keep apart the phenomenology, which we're trying to bridge to where I think notions like mindless and intentionality are have their home and the, the, the modeling that we're doing when we use active inference models to explain, uh,

there i don't okay yeah where we also talk about models and um we talk about a generative model and and we then give intentional semantic glosses on that generative model but that last move i resist making and i say no that intentionality always belongs within lived experience which we can then explain using bayesian mechanics which is non-intentional and non-representational


SPEAKER_01:
I meant more, maybe I should have said more, this is like metacognition.

Because metacognition in a way is, it feels like a form of intentional self modeling, or phenomenological self modeling in the sense of in lived experience, you are reflecting on yourself.

Yeah, is that self model, which is grounded in phenomenological intentionality?


SPEAKER_00:
So using Thomas's framework, we can talk about the phenomenal self-model and we can say within that there's a minimal self and then there's the epistemic agent model.

So these are all ways of talking about the self-model.

within active inference.

Of course, I don't deny that we can talk about the self-model there.

In fact, in the paper you talked about, I do something that no one else has picked up on and no one else seems to like, which is to say that all generative models are actually self-models because what's being modeled by a generative model is an agent.

So going back to the agent is a model of its environment and the greatest theorem and so on.

And the agent in active cognitive science, in active philosophy, is a point of view, a perspective on the world relative to which you can make sense of the world and make distinctions between what's good for me, what's bad for me.

So I want to argue that right at the core of all generative modeling, because the generative model, at least when it's applied to life,

is the model of an agent, a minimal agent, is a self-model.

So generative models are always self-models, I want to argue.

It's not that there's some part of a generative model at the higher layers of it where we can start to say, well, that's the self-model, or an interceptive inference, say, and say that's the self-model.

Micah Allen and Manos Sekiris have a beautiful figure, actually, where they have the self-model right at the core of active inference.

And that, to me, is right.

And they talk about the first prior.


SPEAKER_01:
Yeah, the body is the first prior.


SPEAKER_00:
Yeah, Anna Chaunaker and Catalina also talk about the... And Manos also talk about the self as a first prior, but they understand the self...

model here in a more relational way into subjective, so thinking about attachment dynamics, for instance.

But all of that work, for me, indicates that you can't really take the idea of the agent as a model of its environment without thinking that the model there is a self-model.

So I'm very serious.

I think the self-model construct is extremely important in thinking about how the agent could be a model of its environment.

But the move that Thomas makes then of just reducing the self as a phenomenological experience to the self-modelling, I want to resist because I don't like his reductionism.

And I certainly don't like his move of saying the self doesn't exist, the self is not real.

I don't think Buddhism really, uh, substantiates that idea.

And I don't think, uh, cognitive science supports it either.

So I would resist a kind of move to a no self theory.


SPEAKER_01:
Okay.

I'm gonna call, I'm gonna say that that's, that's good for me because, uh, we've covered so much ground and we could go on for hours more, but yeah.


SPEAKER_00:
That's enough.


SPEAKER_01:
There's so much to think about.

To be candid, I'm coming out of the Metzinger school, which is informed active inference.

So it's difficult at a personal level to real time shift one's paradigm because maybe some of the


SPEAKER_00:
bear in mind that there's, there are other ways of using active inference here that don't necessarily leads to a no self theory.


SPEAKER_01:
Well, yeah, I mean, I wouldn't.

Is there a difference between the no self and the constructed self?


SPEAKER_00:
uh yes and that you can think that constructions are real and whereas thomas wants to say no if the self is constructed inferentially yeah then you should infer from that that that no one ever was or had a self


SPEAKER_01:
Yes, I've seen him say that.


SPEAKER_00:
I agree that the self is a construct.

Evan Thompson has this very nice idea in his work on Eastern philosophy.


SPEAKER_01:
Why I am not a Buddhist.


SPEAKER_00:
yeah where he thinks that the self is a construct but the layers of the self that construct the self come from things like the body from our intersubjective relations like katarina and manosagi from our uh being uh members of a culture where other people can understand us in a particular way so

and then we can take on board how we're perceived or understood by others so these are all layers that lead to the construction of the self um but we shouldn't then infer that the self isn't real just because it's constructed or that no one ever was or had a self that just doesn't follow

And I don't want to go on the side of instrumentalists here and say, if it's a modeling tool, then what's being modeled is not anything real.

So Michael and I have done work on this with Ian Robertson, where we say that that amounts to making what we call the literalist fallacy.

So the fallacy of thinking that in order for a model to be a model of something real,

The model has to be taken literally as describing what is literally happening in the world.

And that's not true.

You can be a realist about these models without thinking that what's being described is something that's literally real.

So models involve you making all kinds of imaginative leaps from what you're modeling to the target phenomena.


SPEAKER_01:
Yeah, that's really useful.

I feel like I've been slightly converging on this in my own thinking that there's a

something that I've been coming to find is that there's a difference, this might be not entirely the same, but it's adjacent.

There's a difference between maybe what the Bayesian mechanics permits, and I use that word knowing that it's probably the wrong word, but permits in terms of the phenomenology.

And there's an actual, but there's a difference between that and the actual phenomenology itself.

And I think that might be akin to


SPEAKER_00:
Yeah, that's exactly what I'm saying.

So there's the model that we use as scientists, and then there's the target system that we're modeling, which is the system as just, well, phenomenologists wouldn't call it a system, but lived experience as it's described, which is what we're trying to do.

And we're trying to build this generative passage from the modeling to phenomenology.

And those are different.

One is the model, the other is the target of the model.

The target could be phenomenology or it can be the brain because these are both targets that we're trying to use the generative modeling to capture.

But the relationship here is between the model and the target system.


SPEAKER_01:
Oh, that's so useful.

That's so useful.

Again, it's not helped by the fact that it's called a phenomenal self model, is it?

I mean, that's a way of really deflating that gap.


SPEAKER_00:
But of course, for Metzinger, he does that for a good reason because he thinks no one ever was or had a self.

So all there is to the self is the phenomenal self model.

Whereas I'm saying no, phenomenologically, the self belongs in phenomenology and it's real because that's where it comes from.


SPEAKER_01:
Isn't it a bit odd to call it a phenomenal self model and then say there's nothing, there's no self given that it's phenomenal?

Does that not strike you as a slight contradiction?

Because we take the phenomenal reality to be real in and of itself, regardless of how we end up demarcating it and reifying it.

We take lived experiences.


SPEAKER_00:
The idea of the ego tunnel, right?

And it's a bit like the Plato's cave myth.

So, yes, the self appears to us.

It appears to be real.

But the argument is then it's just an appearance.

And where does that appearance come from?

It comes from the construction of this phenomenal self model.


SPEAKER_01:
That's enough for me.

That still seems to be like what you're talking about in terms of mindness, subjectivity, intentionality, which for me seem to be the things that matter in the end.


SPEAKER_00:
yeah interesting what this comes back to is whether you're a physicalist or not so if you if you think that reality fundamentally is just what can be described and explained by physics which i think thomas would in the end endorse yes uh the phenomenal self model

is going to be reducible to neurobiological processes.

And those are going to, in the end, come back to something physical.

Whereas phenomenologists are not physicalists, they're non-reductive naturalists.

They try to have a softer form of naturalism.

John Faveke talks about transcendent naturalism in some of his work.

That's because he has in view trying to get to the wisdom traditions in the end from these ideas.

But these softer forms of naturalism, I think, are alive possibilities for us as well when we're using active inference and the free energy principle.

We don't have to be physicalists, whereas Alex, Jacob, Hoey,

You know, they're long time on card-holding physicalists.

And the free energy principle goes nicely with physicalism because there's so many of these ideas are coming from physics.

And so you might think, well, it follows from where all of these ideas are being drawn from that we should end up being physicalists about anything that's described in phenomenology, which means being reductionists.

But I just don't think that that's right.

So...


SPEAKER_01:
Going forward, in your present work and past work and forward work, what words would one use to talk about bridging this gap?

Because we want to keep the Bayesian mechanics and we want to keep the phenomenology and we want to find an explanation that's non-reductive.

This is taking you back to philosophy when I was at school.

What are the relations that we're trying to describe here?

Are these causal relations?

They're not epiphenomenal, but what's the best way of talking about them from your perspective?


SPEAKER_00:
Well, I see myself as doing neuro phenomenology.

So what that means is that I think there's a necessity

when we're explaining phenomena that are tied to lived experience like consciousness, the self, and disturbances that can happen in mental illness, of making reference to first, second-person experience.

And that then means using methods for studying first-person experience like

phenomenology but also uh contemplative methods like meditation mindfulness because they involve something that is akin to the phenomenological reduction as it was practiced by phenomenology so what we need to try to do is to find ways of bridging between what can be described in first person terms and what can be described third person what's the relationship between those well the reductionist would say that the first person reduces to the third person

Whereas I try to have a metaphysics where it's non-reductive.

So what does that look like?

Well, I don't think there's anything outside of science that we're dealing with here.

So it's nothing like metaphysically spooky being introduced here, I wouldn't want to say.

But we need a more relaxed naturalism.

And what is the metaphysics of that going to involve?

Well, it involves having a richer notion of causality, for instance, than just efficient causality, because we're thinking about self-organizing systems now.

So we need to have what Alicia in her book

um context matters for everything or something right constraints yeah enabling constraints yeah yeah yeah so we need that we need a notion of enabling constraints for instance here um we need self-organization we need to have a kind of teleology here and so in discussions of the free energy principle people sometimes wonder about um what's the reality of uh

of what Spinoza called the conatus.

It is part of what we're looking at when we try to model agents as free energy minimizing systems.

And Axel has said, no, it's not, because the existence of the agent is a consequence of free energy minimization.

You don't get an explanation of why agents exist out of free energy minimization.

I want to say something different from Axel there, that living systems do indeed have this drive to maintain themselves, this conatus.

So the metaphysics that we need here is something that looks a lot like Spinoza's metaphysics, that you've got a substance.

I don't really like substance talks or that part of it.

I would try and resist and go to processes.

But you do need this idea of a canatus, I think, in accounting for what makes the difference between a pebble and a living system.

And that we can make sense of in terms of free energy minimization as well.

So the metaphysics that comes out of this is not physicalist metaphysics.

It's something that has room for there being a difference between living systems and pebbles.

And that we can make sense of.


SPEAKER_01:
Beyond just the physics.


SPEAKER_00:
In terms of Bayesian mechanics.

So look at the paper about strange particles, for instance.

And look at the work that Michael and I did about the difference between mere active inference and adaptive active inference.

And there's an account there, a print support account that comes out of active inference about the difference between a mere physical system and a living system, a biological agent.

This goes loops back to where we started with autonomy.


SPEAKER_01:
Of course.

I'm just so aware that Carl would just say, well, this is Justin.

I'm using his hand signals.

This is the depth of temporal planning.

Again, what you're saying, that's the Bayesian mechanics, but that's not everything.

There's a non reductive phenomenology on top of it.


SPEAKER_00:
yeah so i do want to say that that's uh that it isn't just about the the temporal depth of the generative model this difference between the a being that has a canatus a drive to maintain itself and uh yeah because the model here is just a model of that kind of thing and that kind of being yeah


SPEAKER_01:
Julian, gosh, I've learned so much.

I thought I came in knowing roughly what I was talking about.

And I've left ever so confused and in doubt with myself.

But nonetheless, it's been wonderful.

And

or inspiring and incredibly informative.


SPEAKER_00:
They should just leave you in a bit of a confused state where you then try and sort through your confusions and make sense of them.


SPEAKER_01:
No, not at all.

It's been incredibly useful.

I feel like I've kind of cheated my way six months ahead of my education in three hours.

So that's no bad thing.

It's just super informative.

What can people look forward to in terms of your upcoming work?


SPEAKER_00:
Yeah.

So something we didn't get to talk about at all, which is a shame is the work we've been doing on play and playfulness.


SPEAKER_01:
Yes.

I know.

Yes.

Yeah.


SPEAKER_00:
Yeah.

Aerodynamics came up very briefly.

So I've been working with Mark Miller in Aarhus University with Mark Anderson there.

We've been developing ideas around why it's fun and pleasurable to learn through play activities.

So together with Mark Anderson, we have a paper that's now under revision with topics in cognitive science.

in a special issue about development of models of the world.

And we talk about the contribution of play in child development in that paper, using our ideas about aerodynamics and carrying on our account of why it is fun to learn through play.

So that's one of the things that we're working on.

And then together with my colleague Damian Denise here in Amsterdam, we're starting a new center on this interface between psychiatry, psychotherapy and philosophy.

My work as part of that will be using active inference to try to understand psychotherapy, say in the context of psychedelic psychotherapy, for instance.

So I'm doing work on psychedelics that come out of that.

but also trying to apply active inference to make sense of mental illness more generally.

And finally, how things can go well for people.

So that's the work that I've been doing with Mark Miller on wellbeing and meaning in life.

That's gonna continue to be a strand of research to try to make sense of how people can be happy and be well using these tools of active inference.


SPEAKER_01:
wonderful well i'm gonna need to go take a nap because i've had my world view just demolished and i didn't even know that it was problematic but it's fine um i'm sure we'll stay in touch um i'd love to i mean you're a true inspiration and the wealth of knowledge is just unbelievable so thank you again for giving me free hours which has felt like 15 minutes

My final question is a tongue-in-cheek one, but I'm giving you three phenomenologists and you have to choose one.

Herschel, Heidegger, Merleau-Ponty.


SPEAKER_00:
Wow.

I'm going to go for Merleau-Ponty because he's like a combination of Husserl and Heidegger.


SPEAKER_01:
He's underrated.


SPEAKER_00:
Both of them.

And he's French, so coming back to your theory.

your Franco file comment earlier on everything from France is wonderful, including French philosophy.


SPEAKER_01:
So apart from that, it rains in June, according to my model.


SPEAKER_00:
She's a French rather than German.

yes yeah absolutely uh and a bit more legible of course but yes uh the style is just so much more uh pleasurable to engage with of his writing than you know heidegger he has his own style but it's uh it's much harder and husal is uh he's a mathematician so there's fewer hyphens in merleau-ponty despite the hyphen in the name


SPEAKER_01:
yes julian thank you so much um i think we probably there's been a couple of wi-fi on and off but this is the beauty of editing is i will go in and scrub it all out but um genuinely on my part it's been an absolute pleasure um i know daniel and the rest of the inference uh clear enough you're able to follow it all make a story out of it

I hope so.

But yes, for me and the rest of the team here at the Institute.

Thank you so much.


SPEAKER_00:
My pleasure.