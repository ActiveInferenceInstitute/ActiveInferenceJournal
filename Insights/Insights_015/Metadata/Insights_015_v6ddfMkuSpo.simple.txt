SPEAKER_02:
Hello everyone, and welcome back to Active Inference Insights.

I'm your host, Darius Parvizi-Wayne, and today I feel extremely lucky to be able to interview two exceptional researchers.

Dr. Michael Levin is a distinguished professor of biology at Tufts University, serving as director of the Allen Discovery Center at Tufts and the Tufts Center for Regenerative and Developmental Biology.

His lab studies anatomical and behavioral decision-making at multiple scales of biological, artificial, and hybrid systems.

Franz Kuchling is Mike's postdoc at Tufts with a special interest in the physics of life and how cells adapt to changes in their physical environment.

Guys, welcome to the show.

Thank you so much for joining me.

It's an absolute pleasure and an honor.

You're kind of, you know, everyone in Active Inference has a foray into theoretical biology, but I would say you guys are the first out and out biologists that we've had on the show.

So I'm super excited to learn.

But you may have to excuse some of my more layman ideas that come from the British schooling system.

What I want to decide is probably just putting in some groundwork for the audience who might be unaware of certain terms that get used in the papers that you guys write.

I want to start with morphogenesis.

What is morphogenesis?

And in what kind of, you talk about morphospace, what is morphospace and how do those two things relate?


SPEAKER_00:
Yeah.

I don't know who wants to take it.

I guess I'll start and then Frans can give his view.

So thanks for having us.

It's a pleasure to be here and to talk to you.

There's a fundamental fact of biology, which is that complex shape and functional structure are self-assembled.

So let's just think about embryonic development.

We all start life as a single cell, and eventually that single cell has to give rise to a complex organism of different types.

and so this not only during development but also during regeneration so for example a salamander loses a limb those cells have to not only uh restore the entire structure but then also know to stop when it's done okay and uh there are other examples of this of course metamorphosis so when the caterpillar gets to a butterfly or something like that so there are numerous examples where the biological

the hardware is basically reconstructing itself.

And so this is broadly conceived.

This is the notion of morphogenesis.

Now, one way to look at this is as a sort of open loop process, meaning that there are a set of rules that are executed in parallel.

lots of molecule cells and so on are following these rules.

And then there's a process of emergence and something complex comes out the other end.

You know, this is the standard story of cellular automata or other ways to think about emergent complexity.

And that's true.

I mean, that does happen.

And then certainly part of the story.

But the more interesting part of the story

is that morphogenesis, whether developmental, regenerative, or in the context of cancer suppression or remodeling or any of those kinds of examples, one of the amazing things that it can do is get to its target morphology despite various perturbations.

So if you want to dig in, I can give you all kinds of interesting examples where

Not only the environment changes, not only injury, but actually the components themselves, the amount of DNA, the type of DNA, the number of cells, the size of cells, all of these things can change.

And certain morphogenetic systems are amazing at getting where they're going despite all of these things.

In fact, they will often take novel paths to do it, which is William James's definition of intelligence, right?

Same goal by different means.

So then the question is, what conceptual tools can we bring to bear to understand this process?

And what we have settled on, or at least what we've been pursuing for the last some years, is this idea of navigation, that what's actually happening here

is that you have a collective intelligence.

It's basically a set of processes hierarchically organized from molecules to cells to tissues and so on.

And what they're all doing is navigating the space of all possible outcomes.

So there's a huge space of diverse morphologies that they can achieve.

And what they're doing is like any agent navigating its environment, they are trying to get to where they're going.

And sometimes they have interesting competencies to do it, even when things go wrong.

So now we can bring to bear all of the tools of behavior science of, of, uh, control theory, all this, you know, cybernetics, all this stuff that's used to design, um, autonomous vehicles, you know, all of these kinds of things to ask, how does the system know where it is?

How does it remember where it's going?

And, uh, what competencies does it have to get there?

So that's, that's, that's why we use the notion of more for space because it allows us to make testable specific hypotheses about the policies that, that are involved in this process.


SPEAKER_02:
Wonderful.

That's a really nice background from which we can kind of explore these ideas.

Yeah, it seems, when you put it that way, very consonant with the ideas of active inference, which is obviously something that you guys have written about before.

So Franz, maybe I'll come to you now.

There's this idea in these, so people think of priors in sort of statistical space or more broadly about the organism as a whole, you know, what are the priors of the organism to be well fed, to eat and so on.

But we could also talk about a cell's prior and a cell's posterior and Bayesian unfolding, Bayesian processes within the cell.

In this idea of navigation and self-organization, what would you say the cell's prior is?

Is it purely to reach a kind of target morphology or is there anything more than that?


SPEAKER_01:
I would say there's a lot more than that, but that's the simplest to kind of formulate because more of a space, like Mike was explaining, is something that we have much more access to as a developmental biologist, right?

So the challenge is you can formulate all kinds of priors and belief expectations for a cell, but if you have no way to estimating how that's even being achieved, then that's hard to really put in any theory that's experimentally accessible.

But for one thing, kind of to point out that the idea of a morpher space or cells navigating spaces is only challenging for people that are not involved in this field because we are so used to spatial dimension as that being the space, right?

But you can have all kinds of dimensions to a cell and we do this for humans all the time.

The idea of characters in the plot being multidimensional is something that is very much applicable to cells as well.

To answer your question more succinctly, so what happens in terms of expectations of a cell it might have, you have to really go into what is it constantly achieving that has any relevance for future states.

So a lot of this can be transcriptional states, so what kind of genes are being expressed at any point in time.

And that is being informed not just by the structure of the DNA, so by millions of years of evolution, it's also being informed by past events, not just in that individual cell, but in its parent cells and going on.

So that's what we call the epigenetic landscape.

So which genes are actually even accessible for the transcription machinery and which genes are being activated to really transcribe and make certain proteins down the line.

And so that really is something where a lot of the prior expectations are going into that we at least now in the lab are really investigating of.

what kind of prescription profiles do we see, but then also in terms of its transmembrane potential, you know, in the lab that studies bioelectric potentials a lot, that's something that, of course, for neuroscience is much more familiar.

We talk a lot about action potentials.

We don't have those in non-neuronal cells, but every cell has a memory potential, electric potential, and those are informative and they are causing

a lot of downstream events that we can get more down to and online, but that's part of what I think is part of the prior belief and expectations that a cell is constantly having.


SPEAKER_02:
Excellent.

Yeah.

I think there's a really important point there, which is kind of something that I noticed reading your papers, which is that morphogenesis, the very idea of physical space seems to be prioritized.

It's self-organization in space.

Is that the only way, just in terms of conceptualization, is that the only way that we could think of a cell reaching a posterior that aligns with its prior?

Does it have to be in accordance with some kind of self-organization in space?

Or is there another way that a cell could kind of reach a homeostatic set point?

Absolutely.


SPEAKER_01:
It doesn't have to be just space, right?

So even if you have a cell just somewhere in the body already differentiated, already kind of has its type of morphology achieved, it has to maintain that morphology, first of all, but then also it has to perform a certain function, right?

Your kidney cells, your liver cells, they have very different functions, even though they're all fixed in space and physical space.

So prior beliefs are, you know, in this case, for example, for a kidney cell is what kind of changes in the blood am I being exposed to?

parts in the liver, same thing.

If you have cells in the brain, it's different.

I have expectations about action potentials.

So that space and again, more space isn't just spatial dimension, right?

It's also traversing because every cell in your body is an important point.

Every cell in your body has exact same DNA, more or less, right?

But what's actually being expressed, that's the difference between all of them.

So they are vastly different in the actual proteins, but also in the genes that are being expressed constantly.

So when we say traversing and navigating the amorphous space, we really talk a lot, not just about that physical space, but how are they changing, which genes are being expressed, which genes are being turned on and off, which really makes the cell identity in the end.


SPEAKER_02:
Excellent.

Yeah, that's absolutely

really, really useful to integrate function and space there.

And I guess those two, they, they feel to me inextricable, but actually perhaps I'm wrong there, Mike, is it how, so, so reading kind of the active inference account of morphogenesis, we talk about the external states of the Markov blanket for a cell being other cells.

And in the case of developmental processes, it turns, they end up being other specific type of cells that they then joined together with in morpho space.

How necessary is the presence of specific other cells in the Bayesian unfolding for a particular cell?

Or could you imagine that a cell's prior might be confirmed absent a specific collection of external cells?


SPEAKER_00:
Yeah.

I mean, this is a great question and it's part of a very emerging research program because it really isn't super clear yet what precisely cells are paying attention to and what their internal models of the outside world are.

What we do know is that in, for example, let's just take early development.

So you have a blastoderm and there are

I don't know, 50,000 cells there.

And at some point, we as external observers will look at that and we'll say, well, there's an embryo, there's one embryo.

Well, what is there one of, right?

And if you wanna think about an embryo, the thing you're really counting when you say one is,

you're counting the fact that all of the cells have bought into the same picture of the outside world and what their goal is.

So they are all going to cooperate to build a particular thing.

What binds them together into being one larger scale emergent individual is commitment to a particular model of where they...

where they belong where the boundary is between them and and some other embryo because you can you can make by putting in little little scratches into that blastoderm you can make twins triplets you know there are multiple individuals that can come from that blastoderm so every cell has to be part of some in that scenario has to be part of some network and that network has to make decisions about where it ends and where the outside world begins because that has to do with size control and and you know left right asymmetry and all kinds of things so

it's really critical to understand what exactly the cells are paying attention to, what exactly the tissue is paying attention to.

So the cell network, because I actually think that there are agents here at every level.

So even actually, even to take a step back,

even molecular networks within cells.

I don't even think you have to get to the level of a cell before you can start talking about beliefs and expectations and so on, because as we see, even gene regulatory networks can learn from experience.

They can do something like five or six different kinds of learning, including Pavlovian conditioning.

And so you can ask that question about what does the world look like from the perspective of a gene regulatory network before it's been trained or after it's been trained and so on, right?

So this is all, of course, very, very active areas of investigation.

So so we don't know all the answers.

But but I think I think it's very important to start taking the perspective of the things that we are modeling and asking, what do they see and what are they measuring?

What are they paying attention to?

How do they remap information into salient compressions for them, you know, and how that affects decision making and so on?


SPEAKER_02:
How does that then integrate with a kind of

idea of telos or teleonomy.

Because you know, the way if we take the perspective of a cell, or a collection of cells that are parametricizing beliefs over external states, it sounds purposive, it sounds like, as you say, there's agency there.

And even the word beliefs people associate with propositional philosophical beliefs.

How far should we take that metaphor literally?


SPEAKER_00:
Well, okay.

So, so the first thing I would say about that is just this kind of a ground ground rules.

I don't believe in the dichotomy of literally versus metaphorically.

Okay.

I think all we have in science is metaphor and, and, and what, what, you know, when people talk about molecular pathways,

I mean, talk about a metaphor, right?

The pathway relative to what's actually going.

I mean, this is completely metaphorical.

So all of these things are metaphors.

The real question, of course, is what set of tools does that metaphor give you to make progress?

What does it help you discover?

What does it facilitate?

So to me, all of this gets settled empirically to the point that if you have a particular metaphor, so maybe you talk about cells as having beliefs or maybe you don't.

And the real question is, what does that worldview allow you to do?

I think that's the final judge of it.

I don't really put a lot of weight into sort of philosophical pre-commitments about what goals and beliefs have to be.

It's a question of portability of tools.

So now having said that, so I think that these kind of...

uh these kind of tools are extremely useful and they're again not binary because even even as early as the 40s already uh wiener rosenbluth and bigelow gave us a um kind of a scale of different types of different goals of different complexity right so it's a very simple kinds of passive matter and then active matter and then their homeostatic various kinds of homeostats and second order metacognition and so you can

You can sort of go up and up.

And it's an empirical question, which of these are the most useful for any of the contexts that you study?

But I think it is absolutely reasonable to see all of these things as having some position on that scale.

And it's important to say that back before, I don't know, let's say before the 30s and 40s,

The problem with teleology was that we didn't have a way of thinking about machines with goals.

Most people would assume that humans have goals, but other than that, we really had no idea how to cash that out.

But it's really critical to say that we're past that now.

We have a good rigorous science of what it means for mechanisms to have goals.

It's fine.

It's not magical anymore.

We don't have to be afraid of it.

And so I guess the last thing I want to say is the difference between teleology and teleonomy.

So one definition of teleonomy is apparent goal directedness, apparent teleology.

And a lot of times people use that as a hedge, as a way of softening the concept.

They say, well, look, it's not real teleology.

It just looks like teleology.

And that's a way so we don't have to really

commit to be, to being teleologists, we're just gonna say, it just looks that way.

So, so I like the word teleonomy, but for the opposite reason, I, I am not trying to soften the concept.

I, I, I'm, you know, not in, in, in no way, um, kind of, uh, hesitant about using teleology.

I think it absolutely works.

What I think is, uh, useful about the concept of teleonomy is that by putting the word apparent in there,

What it does is it focuses on an observer's point of view, apparent to whom.

And I think that is a really critical question to ask in almost all of the stuff that we talk about here, which is not some sort of objective, universal truth about these things, but from the perspective of some particular observer.

Now, that might be a human scientist.

That might be a parasite.

That might be a subcomponent of the system.

That might be some sort of superset of the system.

That might be the system itself, right?

We all, you know, systems observe themselves too.

And so what that says is that there is some perspective from which the system acts as a goal-directed agent, and then can be used with tools that belong to that.

So that's what I think is the most useful term of the sense of teleonomy.

Franz, I was wondering what you thought about this, because


SPEAKER_02:
I think it's a natural inclination, maybe it's a romantic fiction that we want to ascribe some telos to smaller, let's say, or less complex entities like cells or processes within cells.

There's an interesting thing that Mike said that I wanted to pick up on, which is that basically everything in science is a metaphor.

I guess where I might slightly push back on that is the science of lived experience and phenomenology, which we can't help...

we have to take in some ways literally because it's the one thing that we're intimately aware of and there's a lovely paper by Anthony Jack and Andreas Ropestoff ages ago 2002 I think where they argue that basically you can take sort of every psychological construct and say well every the way that we you know coalesce on what attention means or memory means really is because of what we how we experience it so I was wondering whether there's a kind of uh


SPEAKER_01:
tie there i mean or an association between when we talk about ourselves beliefs ourselves attention ourselves memory is there any way we can think of that without bringing in our own phenomenal experience it's tough i mean um like especially initially when i earlier in my in my research when i you know wasn't as deep into a lot of the the metaphysics behind it and all that i tried to really avoid it and i tried to really focus the my audience on on just the

mechanical aspects, mechanistic aspects, the cellular aspects.

But I found that it was almost impossible to do that because all the words we use are so loaded with everything we have from psychology.

But that being said, nowadays, I think really the important part is to do that transversion, that transversing those two fields.

in both ways, because the claim we're making, I think, is not that like a cell is doing the same thing on the same level, on the same scale.

Like, you know, Mike really mentioned, right, there's a certain gradient there as a human being.

But we're trying to understand where the origin of all these phenomena are coming from and are there, and more importantly, are the fundamental principles shared between a cell and a more classical act of differentiation like a human being.

So things like beliefs, right?

When you say that it's always a belief, people are like, oh, well, you're talking about having religious beliefs.

And then you get really fastly trapped into these loopholes.

But nowadays, I try to counter this argument by saying, well, what is a belief?

And where does it come from?

A human being has to come from certain expectations, right?

So you really have to then go down to how do you, once you have to define it, you have

have to develop it.

And so active inference is nice because there you have very precise definitions of what a belief actually is.

And so once the kind of trick you can do is can people also, okay, let's talk about active inference, human being, you make a certain process, you know, you have a general model, general process, you define the Markov blanket, so separation between what's outside that you can't see, and then yourself, so an internal state.

And then you have the separation of those two by the active and sensory inputs you can get.

You have sensory inputs and then you can act upon the environment to change what those sensory inputs, your eyes, your ears, are perceiving over time.

That's actually what agency really is about.

It's about controlling.

You can't really control the environment if you can't perceive it.

What you're actually controlling is how you perceive the environment.

But of course, you're doing that by acting on the environment.

That's what agency is.

Sure.

Now, once you put it in such a formative framework, then I think transferring that to sales becomes much more, much more easier and much less controversial, I think.


SPEAKER_02:
Yeah, I sense that that sort of less philosophically laden, more deflationary account of agency is definitely possible.

It's just control in line with prior expectations or, you know, self-organized principles of self-organization.

I think one thing that

perhaps at active inference also hasn't got very clear on, but certainly isn't clear in psychology, is selfhood.

And in some ways, I feel like it's very fundamental to this question of morphogenesis and self-organization in biological space, because it's morphogenesis for who, right?

So, Mike, you sort of noted that in many ways, well, we're talking about that we have, it's all observer-relative.

But also in some ways, it's also internal relative because they are self-organizing for the sake of their own integrity.

So, well, again, that might be ascribing a telos that's unwarranted, but it could be described like that.

What is biological selfhood?

And I guess for people who think of the self as one monolithic thing, how does it

How can it be distinguished from more complex forms of selfhood, like metacognitive selfhood or epistemic selfhood and so on?


SPEAKER_00:
Um...

I think that the issue of morphogenesis for whom is actually really important because a really defective frog embryo might be a very nice zebrafish embryo.

And so this whole notion of mutation and just in general evolutionary change and what exactly is a birth defect is really important and interesting.

Chemistry doesn't make mistakes.

So there's no such thing as a mistake in chemistry.

But there is potentially a mistake in carrying out developmental biology, depending on what perspective you're looking at.

So it's something very interesting is, you know, the ability to make mistakes is a hallmark of a cognitive system, right?

Because because that suggests that you had certain expectations that were not met and so on.

So just the very nature of a birth defect is interesting.

So now now the notion of a self, of course, there are many ways to think about it.

I'll give you what how I've been thinking about it.

One of the things that I really wanted to do early on is to come up with a framework to directly think about and compare agents of very diverse structure and provenance.

So we're talking about conventional beings like us and animals.

I mean, those are also, of course, collective intelligences, right?

We're all made of cells and so on.

but also new synthetic things that are going to be created, robots, AI, hybrids, cyborgs, all kinds of mixed things, potential exobiological life and so on.

What do they all have in common?

What do all agents have in common, no matter how they're made and no matter how they got here, what their origin story is?

So what I settled on, and so now you see, I'm super into the whole teleology thing.

So what I settled on is this notion of the size of their goals.

In other words, I define this notion of a cognitive light cone, which is, it's not the distance that you can sense or act.

It's the size of the goals that you're able to maintain.

The biggest goal that you could possibly maintain is the size of your cognitive light.

So, you know, so, so every, every agent has some degree of memory going backwards, maybe large, maybe small, some predictive of power forward and some spatial area of concern over which its goals play out.

And, um,

And so so now now the thing about that is that that is the determination of a cognitive light cone by an observer.

For example, here you as a scientist are given a new system.

You don't really know how it works and you want to do some behavioral experiments and you find out that here are the things that it can possibly care about.

That that is a third person investigation of its agency.

And we say this is an agent.

What I think of as a useful definition of the self is exactly that process in first person.

So a self is what how that process plays out for the system itself.

So the system itself also has to be able to coarse grain the outside world and not only tell agential stories about

things in its environment that do things, right?

Because no system can afford to track microstates.

Laplace's demon isn't going to, you'll be eaten and dead long before you calculate anything.

So every agent in the real world has to coarse grain and they tell these stories about

you know, agents, other agents doing things.

But you also have to tell that story about yourself to some extent.

You can't avoid it because if you don't have a compact self model, you are not going to be very good at controlling your own parts and making things happen.

It's just right.

That's part of being effective in the real world.

And so I think what we mean when we say self is the internal first person view of a system about its own.

So there's kind of a bundle of things you need to have.

You need to have a sense of boundary between you and the outside world.

So which are the things that I think are actually me versus not me?

You need to have some representation of some space that you think you're operating in.

You need to have some sense of your own sensors and effectors.

What can I actually do?

What am I actually sensing?

And so on.

We, as third person observer scientists, try to tell those stories about other things that we work with, but agents tell them about themselves.

And so do parasites and conspecifics and various potential mates and prey and cheaters and all of these things.

Everybody's hacking everybody else.

And in order to hack other agents, to hack yourself and your own parts, to have control over your own parts requires that sense of selfhood.

And it might be, as Francis said, the point isn't to say that every rock has human level hopes and dreams.

That isn't the point.

The point is that

There's a huge range in how much processing is, how much sort of meta processing is done about all of this.

You can roll all this forward in a very kind of minimal way, or you can have all kinds of loops where you're actually monitoring your own progress on certain goals and you have the ability to change your goals and to pick new goals.

I mean, you can layer stuff on and on.


SPEAKER_02:
That's yeah, that's really great.

That's a really lovely explanation.

Yeah.

It really deeply aligns with the way that I think about selfhood, which is fundamentally from a sort of Metzingerian, um, phenomenal self-modeling aspect.

And that's exactly what Thomas would say, which is that self-modeling is the capacity to recapitulate or re simulate the actual data structures of your own body in a kind of coarse grain space.

So it's, you know, the one thing that came to mind is talking about the cognitive light cone is.

in terms of the extent of your goal, yes, it's in space, but it's also in time.

And that feels like a very relevant thing here.

When I've spoken to Carl, and when I've seen the direction of active inference, it's very much going in time to in, you know, the direction of temporal planning, deep temporal planning, which arguably relates to the depth of your generative hierarchy, because the deeper your generative hierarchy, you know, the highest level is going to be tracking the most invariant and

long term fluctuations in the external environment.

So friends, I'm just curious if you're, I mean, this is just a thought experiment.

Is there a way where perhaps if you have a cyborg or tadpole, or you know, some entity that you're examining, and you're trying to get to the its cognitive infrastructure is looking, I don't know whether this would be behaviorally or anatomically is looking at its capacity for planning, which might well just be it's the depth of its generative hierarchy.

Does that give us an insight into its actual

know, existential or experiential life?


SPEAKER_01:
I think it does.

And it relates back to the, your question about what are its actual beliefs, you know, what, on what level are, are its beliefs being expressed?

And so I just gave you a couple examples.

What I've left out is, you know, that of course, like you just said, what's important is the hierarchy of that.

How are these different, different beliefs organized in a certain hierarchy of, of spatial and temporal scale?

And also to, I really like the point Mike made earlier about chemistry not making mistakes, right?

So what that means is the conclusion of that idea is that any purely chemical system is not going to change much.

It's going to be highly predictable.

It's not going to push back on anything in the environment.

It's just going to have a certain, it's going to come to an equilibrium pretty fast usually, and then that's it.

And so another way to form this question of how does a cell, how can we test agency, to answer your question, how do we test

um having a certain certain ability to form a hierarchy and form beliefs we have to understand of how much pushback can it can it give you can it give to an environment over over long times and so the way i would probe this hypothetical cyborg or tadpole in terms of like what kind of um expectations what kind of planning is it doing is you have to really see how these different

parts of that generative hierarchical model are interacting.

So you will have a, you have a quick first response, which could be, you know, purely physical, but then very often on, it turns very active in most biological system.

That's the active inference part is really what makes life, life tick.

You know, it's, it is entirely active and it's active very quickly, but also over long timescales.

And so, um, what we're trying to show in this one paper about medical admission with Chris Fields and Mike,

was that that's a drive that got selected for very early on in evolution.

And so the way the profi system is really looking, having different reporters genetically, but also just having certain dyes in a system that will give you readouts of its active states.

Like what is it making?

What kind of proteins is it making?

Is it changing its later potential?

And then you try to relate those things.

Are they completely independent?

Are they just, you know, in a non-living system,

very predictable dynamic reoccurrences of patterns.

But now living systems, they're going to change and they're going to change depending on the scale.

So one scale is going to affect the other one and it's going to continue to doing that.

And that's, I think, how the planning is achieved by that

temporal in the independent intent interdependence between those different aspects of a cell if they were independent there would be no planning but if they're dependent on each other then the cell is basically going to be using its long-term processes to redirect and inform its its active points at any moment in time nice yeah yeah and speaks to a kind of almost predictive coding hierarchy um where you have these kind of trickle-down predictions mike did you want to add


SPEAKER_00:
Yeah, I just want to go back for a second to something you said before, which I think is quite interesting, about the non-metaphorical nature of our phenomenal experience.

And I take your point, and I think phenomenal experience is really important, but there's the issue that we change.

Right.

And so and so how you so so I mean, for us, so let's say puberty is a is an example, right, where where a lot of valence changes and things that you thought were really important suddenly not important at all.

But all this other stuff is now important.

And the example that I really find kind of meaningful for all this is the caterpillar to butterfly transition.

So what happens there is you've got this soft-bodied creature that lives in a two-dimensional world, and it crawls around, and it has a particular controller for that kind of soft-body actuation, so it's got a certain kind of brain.

And then it has to be transformed into a completely different creature that's a hard-bodied kind of vehicle.

It flies.

It lives in a three-dimensional world and so on.

and so so it has a completely different brain and during that that process the brain is basically mostly broken down most of the cells are killed off um and then reassembled you know it grows it grows a new brain so so there's a there's sort of three levels of interesting things here the first level is that that aspect of phenomenal experience like what's it never mind what's it like to be a butterfly but what's it like to be a caterpillar becoming a butterfly

and how much of the right and how much of the um the metaphors the the how much of the things that the caterpillar took very seriously the butterfly things were total metaphors at this point right if it could i mean i'm not saying that's how it thinks about these things but but right thing things that were quite um quite concrete for the for the for the caterpillar are no longer so for the butterfly that's the first thing the second thing is that

um we know there's continuity so you know if you if you like um the stability of memories as a criterion for selfhood which a lot of philosophers like uh we know that the butterfly remembers things that the caterpillar learned so there is some continuity here even though the the brain the cognitive system and the body of all of that stuff is radically changed but there's some continuity

And so the next kind of question you think about is, okay, where the heck is this memory that survives total brain refactoring?

But the third thing that I find even more important about all of this comes from the simple fact that the way they test these memories is, well, one way to do it is you feed the caterpillar leaves on a particular color disc, and then what you find is that, so it forms the association, and then you find that the butterfly goes back to that disc to feed, right?

But the key thing here is that butterflies and caterpillars don't eat the same stuff.

The caterpillar eats leaves.

The butterfly doesn't care about leaves.

The butterfly wants nectar.

So now something very important.

You cannot just persistence of the self in terms of memories.

What you can't do is just keep the memories constant because you'll lose the salience.

Those memories will make no sense to the butterfly.

And in fact, what you have to do is something very interesting.

You can't learn leaves on this color.

You have to generalize to the higher category of food.

And then you have to remap.

So this is the part that I'm super interested about in terms of moving memories around and transplants of memories and personal identity and all that.

You have to take the deep lessons of your past life and sort of reinterpret them for your new life, which is, by the way, completely different anatomy and all of that.

But there are some things you learn that are still pretty useful, just not exactly in the way, right?

It's not the details that matter now.

It's the kind of the generic concept that matters.

so so re remapping right remapping that information onto a new exp onto a new um embodiment for for for that for that being that's that's why i think the concept of metaphors is still super strong even for the phenomenal stuff because because you can't take any of it literally because you're not going to be the same later i mean you know as certainly for some animals it's more than more than so than others but you you have to understand the deep metaphor of what you learn not the not the specific details of your experience


SPEAKER_02:
Yes.

Yes, that's really good.

That's really nice.

There's a lot there.

Yeah, again, it's converging with some of the stuff that I've been thinking about.

I'm writing a little bit in draft, which is I'm kind of, I'm coming to this idea that the self in some ways is a is a relevance filter, a salience filter, such that because I think at a very deep phenomenal level, everything that finds its way into attention or awareness is relevant.

It wouldn't really make sense.

And so

I would say that the one non metaphorical thing that although you have the higher order concept of food is relevance, and relevant and meaning making to me.

And maybe what I it's interesting, you say, you know, we're trying to go up in abstraction up the generative hierarchy.

The one thing that the butterfly and the caterpillar share is the imperative for nutrition.

And maybe that's maybe so when we can start linking things in some kind of map of similarity, maybe the thing that unifies them is preferences.

So the caterpillar, and that maybe links us with the caterpillar and the butterfly, right, we have this unified goal.

That said, the thing you said about the fact that they return to the same kind of leaf is very interesting, because it does seem to be a idiosyncratic maintenance of memory.

which I can't quite account for.

It made me think of Andy Clark's paper, Knitting Your Own Markov Blanket, where he talks about the metamorphosis of Markov blankets and how we can kind of get around this problem of when is one thing another thing by adopting a process ontology rather than a substance ontology.

But friends, whoever's got an idea on this,

Is it possible that it's just a false move to say that the butterfly and the caterpillar are the same thing?

That's the same organism.

Could we not just say that there actually does become this division or this separation, and it's philosophically vague as to when it happens, but there was one thing and there now is another.


SPEAKER_00:
So I think the way to avoid these kind of philosophical traps is by being very practical and asking, why do you need to know?

So if the reason you need to know is because you want to predict how much crawling around there's going to be, then it's absolutely two different things because there's going to be zero crawling around afterwards.

But if what you're trying to predict is, so what color substrate will it like to feed on?

then you need to understand that it's the same thing because you will have less predictive power if you don't understand that it keeps memories.

So it's just, again, I think we're back to, again, the perspective of, you know, what question are you asking as the observer?


SPEAKER_02:
Yeah.

Okay, cool.

Let's park that there.

I think something that you've worked on, Mike, but also, Franz, you mentioned and I want to pick up on is the difference between neural and non-neural structures.

There's a

There's a kind of neural bias in psychology, neuroscience, a cortico bias.

Franz, one, why is that the case, do you think?

And two, why should it not be the case?

If it shouldn't be the case, maybe it should be the case.


SPEAKER_01:
Yeah.

I mean, one...

We're human-centric because we are humans, but more fundamentally, the reason that we are so confined on the idea of neural circuits being the only one not doing any inference is because they're just very fast, right?

Action potentials are fast.

It's a highly optimal, optimized network.

Optimized from what, right?

Neurons didn't come from nothing.

Action potentials didn't come from nothing.

Electric potentials were being used by cells way before the innovation of neurons.

So that is, I think, the reason why now we're trying to look at what about in your organisms and just cells of having the same properties and more.

And I think other than just that being kind of transition was also really interesting is Mike and I both.

It's one of my favorite past daytime activities is asking neuroscientists what what about your theory is specific to neurons.

And it's a question that none of us have gotten a good answer to yet because a lot of it, of course, you know, there are certain certain time periods it takes.

If you're looking at MRI imaging, you're looking at the oxygenated blood flow in the brain.

So you have to know those those time constant.

How fast does it take?

If you're looking at if you're actually measuring the neuron, you need to know all these transition times to really make your model tick.

But if you change those time constants and you're compensated for that in your model, it will still work.

So as far as we know so far, we're happy to get proven wrong on here.

But so as far as we know, there's nothing that specific about neurons that you need to make any of those models, including actual inference, actually work.

They are highly optimized and they have completely different behaviors, of course, because those timings do matter, but they're not necessary for it because they're not necessary.

They're not in the actual inference framework, right?

It's not necessary to have a brain to have Markov blanket.

It's not necessary to have a brain to have generative model.

So once all the actual assumptions that go into a model can be applied to any of those systems, then you're good to go and you should apply it to those systems as well.


SPEAKER_02:
Yeah, I guess another biased mapping here is between cognition and the brain.

And I feel like there's been a movement towards, obviously in terms of embodied cognition and

the kind of dynamic, the agent arena dynamic that was happening, but also more recently, Mike, your paper with Anna, uh, the brain is not mental.

You sort of, I think you look at the immune system and sort of say how the immune system contributes as well as the neural system in subserving, um, adaptive control, self-organization, perhaps you could just speak to that and, and say, you know, well, I mean, it's a, it's a, it's a, guess it's a thought experiment.

What would it look like if we didn't have the immune system?

If we were just trying to self-organize purely in terms of neural dynamics?


SPEAKER_00:
Yeah, I mean, we certainly, there are knockout mice where the immune system is taken out and all that kind of stuff.

And a lot of self-organization does happen before the immune system kicks in.

I think the idea is simply that there are many, many different kinds of systems that go into this collective that we see when we say it's a human or whatever.

And all of them are potentially important contributors to the process.

As Fran said, it's a really interesting experience to ask people what a neuron is and watch them list things that are basically every cell in the body does this.

And then and then, you know, so I have another thought experiment that I sometimes do is like like back in the, you know, back in the day when when when the idea of neural networks was first being worked out.

Right.

I wonder if if if we had come along to to some of the some of the greats in that in that field and we said, oh, by the way, just just FYI, the biologists got it wrong.

Thinking is in the liver, not the brain.

so so there's two there's two ways they could have gone right one way is they could have said i don't care what you say we've got models of cognition and they require it to be to be neural so you guys must be wrong or they could say fine what do we care are this what you know the the basic calculus of you know mcculloch pits all that stuff the the basic calculus of it doesn't require it doesn't care what it is so fine it'll be liver right so so i i tend to think it would be i tend to think it would be the latter you know i don't see really anything in the in the deep in the deep lessons of


SPEAKER_02:
um behavioral neuroscience that's really about neurons per se you know it's about multi-scale control it's about active inference it's about all these kind of deep things that go far beyond brains and they're applicable to all sorts of stuff stuff but are there certain processes which are reserved for the brain i mean i think someone listening to this probably a psychologist or a neuroscientist will say well take the brain out good luck take the liver out you know i mean still good luck but you might have a better chance thinking

Right.


SPEAKER_00:
For for a short amount of time.

I mean, take the take the mitochondria out and and you're done for pretty much at the same rate as the brain.

Look, the bottom line, like nobody's arguing that the brain isn't unique and interesting in certain ways.

Right.

Like we you know, as much as we

find protocognitive capacities elsewhere.

I've never made the claim that language or long-term planning is in there.

We've not found it.

Could be.

I wouldn't be terribly shocked if it were found, but we haven't found it, so we don't make the claim.

So clearly brains are interesting and they do interesting things.

But I think it's important to make a distinction between

between having found unique features and told a very specific predictive story that that of why that is versus just this generic gut feeling that everybody has that that i have real you know real feelings and plans and this thing is a slime mold that i mean i don't know how many times people have said to me well that's a slime mold that's not a real decision it's just physics

And it drives me up a wall because you don't think we could tell a physics story about you?

Of course we could.

It wouldn't be a very good story, but neither is it about the slime mold.

And the fact that you can tell that story doesn't mean anything.

There's always a physics story to be told about anything.

And so I think it's fine to have specific theories about what it is the brain that's doing differently than other structures.

That's great.

But a lot of the resistance to the kind of continuum views that France and I are talking about comes from a kind of closet dualism.

It's people really, you know, they just really feel they're different and and and they have to accept the fact that the physics are not different.

So, well, now what is it then?

Right.

It's like this.

Then there's something else.

And I think not even that I'm particularly against that.

I just think it should be like, you know, dragged out into the light.

And let's just say, like, say what you think the difference is.

You know, I think I think that's really critical.


SPEAKER_02:
See, I'm not sure the difference.

I'm not sure the dualism really fundamentally is a brain body dualism.

I think it's an awareness body dualism or consciousness.

I mean, like a traditional Cartesian dualism, I think is really at play here.

It's just we've been persuaded that consciousness is rooted in the brain.

And so once you make that association, then you go, well, obviously my brain is special because it generates consciousness.

Consciousness is special.

I can, in principle, imagine myself being conscious without my liver, my leg, my arm, and so on.

And so that's the special part.

What am I missing there?


SPEAKER_00:
No, I think you're right.

But I think what people are missing there is when they say conscious of my liver, that isn't the question here.

So right now, your left hemisphere and my left hemisphere are having a delightful discussion about why consciousness is in the brain and how important the brain is for consciousness.

That's fine.

Then I will say, and I don't have a new theory of consciousness, by the way.

So I'm not like, I usually don't talk about consciousness at all.

But since we're here, I'll just say that I have said that for the same reasons we think that the brain can support consciousness, we ought to take seriously that other parts of bodies also support consciousness.

Now, at that point, people say exactly what you just said, which is, well, I don't feel like my liver is conscious, but that's a huge mistake.

Of course you don't.

But you also don't feel that I'm conscious, right?

That's exactly right.

So it's nice that the left hemisphere is eloquent and it has language and it can tell stories to other left hemispheres about how conscious it is.

But that doesn't mean that what you don't have spread throughout different regions of your body is a non-verbal, non-linguistic consciousness that is not for us to access any more than we can access each other's.

And the fact that you don't feel it is no surprise.

There's no surprise there.

um, you have to take its perspective and ask, what do you think that's going on in your brain?

And so, so literally, um, uh, a student and I have, have been, uh, we have this, um, we have this table that, that has rows for the main theories of consciousness.

And for each theory, there is something specific, you know, so, so, so Stu Hameroff will say it's microtubules.

Somebody else will say it's, you know, my electromagnetic field.

Somebody else will say it's,

you know, integrated information, like whatever it is.

And then we just look and say, okay, given that, where does that occur in the body?

And the answer for almost all of them is everywhere.

And so none of these theories, as far as I can tell, can distinguish.

And some of them try to rescue it.

So IAT has this postulate that says, okay, but we're just going to say there's only one, right?

That's a postulate you sort of add on to things, right?

So that's the issue is that it's not about you feeling your liver being conscious.

It's the first person perspective, which may or may not be there.


SPEAKER_02:
Yeah, there's plenty there.

Yeah, I'm reticent to dive into consciousness because all my podcasts end up being about consciousness.

And I have biologists on, you know.

But...

Yeah, it's, it's, it's interesting.

I mean, obviously, a lot of this has been, we have to take as a kind of axiom that, at least for this conversation, that consciousness is what generated in the brain, whether that's in a property dualist, or whether it's in a reductive way.

And I also do just want to give a shout out to slightly more esoteric forms of idealism, conscious realism, and so on.

But it also makes me think about

let's if we just get away from consciousness in terms of first person perspective and just talk about basal intelligence in in terms of morphogenesis it also makes me think well it's this is a term for consciousness but people will talk about being where the conscious can be is multiply realizable has multiple realizability i.e if i put you know uh you know china you know if i had a chinese nation that blocks idea with exactly the same functions as my brain exactly the same synapses because there's the same you know those connections would be the same between the members of

the Chinese populace and my brain, would I have consciousness?

Okay.

If we get away from consciousness, I guess my question is, is morphogenesis itself, can it be, is it multiply realizable in the sense that we're now talking less about the human body?

Is there something sort of, or more towards like cyborgs or robots?

What, you know, people have this intuition, I think as well, that there is a life force and they land VTOW.

that leads maybe to this self-organization, right?

There's like, there's gotta be something that like, or else why, why are these things resisting entropy?

Why are they self-organizing?

And I think the idea is like, well, if I just stuck some sort of priors in the robot, why on earth would that end up being self?

Like, why would that work?

to use very reductive language.

Franz, I'm just curious, is there like an added ingredient, at least it might be a metaphor, but an added ingredient that we have to put into a non-carbon based thing in this case to give it the chance to self-organize?


SPEAKER_01:
Yeah, probably I would have to name would be Evolvability.

That would be one part.

And it doesn't have to be evolution of its actual components that can be evolution of its programming as well.

But that would be an important point to it.

The one thing I'd like to point out for that question is I've talked a lot about in this podcast about one of my biggest interests is really understanding of where that drive for an agency comes from.

But that's not just a kind of philosophical interest.

It's actually really once you find sufficient evidence for that being a fundamental drive in evolution, then you have to accept the

to combine that fact with the idea that, well, if any part of your body or any robot that you're putting into this is going to strive to maximize its agency with respect to its environment, that is the real reason why, if it turns out the liver is not conscious right now, then the answer would be, if you accept the fact that, well, the driver is fundamentally an evolution, any life system is going to try to maximize its predictability and its agency over its environment.

then the answer would be, well, its environment isn't very interesting.

So the liver probably didn't have any reason to maximize that drive.

If you were to put the liver or you were to put a robot into an environment that's very active, very much changing, very volatile, and you give it enough

either enough time to evolve if you come out of the vulnerability or you just put in a high degree autonomy over its own beliefs, then over time with that drive, it should be able to to to maximize that.

The problem right now is that the way we program robots is it's very much right.

It's a very clear algorithm.

We don't allow any adaptiveness to it.

And so that's how you would have to go about it, I think.

And you may not want to do that, just FYI, because the problem is, you know, we talk about one of my favorite examples of why, what differences between machines and the brain is that a calculator is infinitely better than you at calculating, you know, adding numbers together, multiplying.

I mean, you know, and it's the dumbest thing ever.

Like it's so simple.

And we've had these things for decades now.

But so if you want to have a predictable, reliable answer, it's always correct.

You know, the human is not the best way to do this.

That is the reason why we're not, even if we had the theoretical framework to make a really intelligent system for what we want them to do, which is really make our lives easier by making the same thing every day reliably, you wouldn't want to do that.

But if your goal was to create a new intelligent cognitive agent, then you would have to go about it differently.


SPEAKER_02:
Yes, that's an interesting little paradox, isn't it?

I mean, like the most robust thing in the world might be a calculator, but it's quite useless.

It's like the more useful you become, the more precarious your existence is.

Mike, I was wondering if you had any thoughts on that kind of multiple realisability question.

And I guess what I'm going at with that is it is a philosophical question, but I think it's interesting for biologists, which is why would evolution

would evolution prioritize self-organization?

I mean, there's just a fundamental question there in terms of entropy.

I mean, why do we have these pockets of neg entropy entities?

Um, is there a biological answer to that beyond just, well, to be a biological entity, you are neg entropy.

Is there anything, can we get anywhere beyond that?


SPEAKER_00:
Yeah.

A couple of things I think are interesting, and I wanna be careful here because I did a little while ago, I started writing a paper on what exactly is missing from our technology to provide true agency, because I think we can actually say what some of those things are.

And it quickly sort of dawned on me that to whatever extent I was onto something,

that would actually lead to a massive creation of new beings that matter in the moral sense.

And I'm not too interested in being responsible for that.

Some other people will do it, I'm sure, but I don't want to do it.

But I can say a few things.

I think when we make the distinction between life and robotics, even aside from all the hybrids and cyborgs that show us that it's like a continuum, but even aside from all that, when we make that distinction, here's what I hear.

I think life is what we call things that are good at scaling up goals.

so so you know when you have very when you have a bunch of subunits that have very basal competencies you know maybe all they can do is follow least action laws or like like really simple things when when when you've got a pile of them and the pile has basically exactly the same cognitive light cone as the comp the components we say well that's not living that's a rock that's just you know

But life is what we call things where there are special... I've also called it a cognitive glue.

There are these special policies by which the parts relate to each other such that the collective has a bigger cognitive lichen in new spaces that the parts couldn't have.

And that's what we call life.

Now, under that way of thinking about it, could you make that out of other things?

I'm sure you could.

And I tend to think that in the wide universe, I tend to think that there's probably...

lots of extremely diverse examples, most of which we wouldn't even recognize of that happening.

And I think specifically, I think what happens is that the evolutionary process really, I don't really think it makes specific solutions to specific problems the way that we do when we do genetic algorithms and things like this.

I think what biological evolution does is it makes problem solving machines

And that's because if you over-train on your evolutionary priors and you really take seriously what expectations that you might have about what genes you have, what the environment is like, if you take that too seriously, you're done for.

Because guaranteed, and this is why I also think that regeneration is not really about repair of physical damage, like external damage.

I think fundamentally regeneration is about knowing for a fact that your own parts are going to change.

Evolution just means the fact that you have some kind of a lineage that's subject to mutation, whatever.

You know your stuff is going to change.

If you don't accept that, you're never going to survive long term.

So what ends up surviving are architectures that in particular are these multi-scale architectures where the individual components have agendas and then they make up systems that have other agendas and on and on.

Our current robotics, by and large, is very flat.

So you hope your robot is intelligent, but the parts it's made of are not.

They don't really tend to do anything.

They don't have their own agendas.

And I've given a talk called Why Robots Don't Get Cancer.

And this is why.

It's because they're made of parts that don't have their own little goals in other spaces, and there's no danger of them defecting, unlike biology, where it happens all the time.

So I think what's happening here is that we end up with these architectures that are by virtue of cooperation and competition of parts that end up having a larger cognitive light cone.

You end up with this kind of intelligence ratchet.

And I could tell you stories about how that type of thinking explains planarian, the amazing facts of planarian regeneration and so on.

This idea that what evolution, I think, really selects for is the plasticity to... And it works out in different types of animals to different degrees, but overall, the plasticity to deal with novelty.

This idea that when you emerge into the...

uh into the world you don't know for a fact what you are what you have is your genome the same as it was are your cells the right shape or size do you have yeah you in the same environment you don't know any of these things you you have to um do your best in putting together a model of what that that's why life is so interoperable that's why we can make anthropobots and xenobots and interface living tissue with crazy nanomaterials and make these hybrids that are just sort of totally cobbled together it's because by and large

It's already bought into, you know, the, the life we see today has already bought into the fact that, um, like, like, you know, everything changes, you know, and you don't, and you can't, you can't depend on these things.

You have to figure them out in real time.


SPEAKER_02:
Yeah.

Yeah.

Great.

It, you know, when you mentioned the word cognitive glue, it made me realize that.

there's one thing that we haven't even touched upon at all, I haven't even mentioned, which is electricity, and bioelectricity.

So I think actually, you had a paper my day knew last year, two years ago, about bioelectricity being the glue of the cognitive mind.

So from physiology all the way up to the mind.

And obviously, this is very much, you know, a seminal piece of your work is the processes of bioelectrical processes in cells and outside of cells and in terms of self organization.

And I think

At least to my very layman biological is electricity almost has the, the kind of center of, uh, a kind of thing that, you know, animates things.

And maybe, you know, I'm thinking about Frankenstein, um, either one of you, I don't mind whoever wants to start.

What, you know, actually friends, it was something that you mentioned, which is maybe one of these ways that we can conflate the neural non-neural dividers.

The fact that both of them have for them a fundamentally electrical.


SPEAKER_01:
what what is it about that electrical ontology that animates or might animate intelligence or morphogenesis so when i was writing my phd thesis i was trying to answer the introduction the question of where does where does a neuron even come from and the best paper i found that was answering that question was looking into this very small organism that had just a bunch of little cilia around its surface

and it was a marine organism that was living on the bottom of the ocean.

And it was trying to center to environments and the database by small changes in electrical fields that they were having around it.

And that was causing like many, I won't say actual potential, but it was causing basically many vibrations and could use that to change this movement.

So the reason I think why that would, you know, why the electricity is that so important here is very, it's a very simple mechanism to have that is physically a lot more accessible to all parts of the body.

That's actually the primary reason why I joined Mike's lab and why I'm become a biologist.

I was a physicist before.

So I was looking for something in biology that would be all these that would not be subject to

completely different mechanisms if you switch organisms.

So like the molecular pathways we are typically investigating as a health anthropologist, they are, as they were before, they are now still very important and they're directing all these different functions of the cell and organisms.

But they're somewhat unsatisfactory for a physicist because it's just so messy, right?

You can't really make heads or tails of it.

And there is no clear field of potential that is just one number essentially, right?

You want to use it to something very simple.

The beauty of using bioticity is that you can have one number, one potential, like a member potential that you can describe to a cell.

It's still made up of all the individual parts.

There's many ion channels involved in this.

All the molecular properties are still making up, all feeding into that one number, that one member potential.

But what's more interesting is the readout part, right?

If you have to constantly compare the millions of different molecules in a cell, that's not going to be good

good formulation for achieving consciousness, even doing any smart behavior, having something that comes from constantly having a surface, almost like a space they can read it, they can write onto and read out to.

I think that was makes electric potentials so appealing that the only question then is like, why wasn't it out of the physical fields?

like mechanics, they are, of course, very involved as well in developmental biology and regeneration as well.

But mechanics don't have this neat feature where it's not as fast and it's not as localized.

So basically, the way I see it, the potentials have a beautiful trade-off between being physical, having a broad readability on a cell or even a tissue level,

but are confined enough that they can be modulated enough to actually form active behavior, which you can't say for most of the other physical fields that we would think about in this context.


SPEAKER_02:
Great.

Mike, you want to add?

Yeah.


SPEAKER_00:
Yeah, a couple of things.

One thing to add is that if you think about one of the really powerful things about bioelectricity is that imagine an ion channel, specifically a voltage-sensitive ion channel.

So as soon as evolution discovers a voltage-sensitive ion channel, what you have there is an element with historicity.

It means that

uh, the current state is a function of what was going on before.

And it means that what you really have is a voltage gated current conductance, AKA a transistor.

And so, so, so, you know, we know once you have that, then you can do anything.

And so, uh,

Electricity is really good for these kinds of feedback loops, right, both positive and negative.

It's good for representing information across time and space.

It's good for functionally integrating a system across distance.

Some of the really cool early evolutionary data on this come from bacterial biofilms.

And this is Gurul Soel's amazing work.

Basically, he's got a paper called Brain-like Signaling in Bacterial Biofilms.

And the idea is that already in a mat of bacteria, so like a really long time ago, evolution already hit on to this idea that

by using electrical signaling to integrate activity among competent subunits, you can get gains at the collective level.

So they take turns, it's used for nutrient sharing and things like this, but you get these collective dynamics.

And so I think it's a very convenient modality for it that was found a long time, long before neurons picked it up.

It was used for that kind of thing.

But no doubt there are other ways to do it.

Somewhere out in the universe, I'm sure there are other kinds of cognitive glues out there.

But here, electricity works really well.


SPEAKER_02:
Cool.

And so I know we need to wrap up relatively soon.

And I guess...

it's a kind of dark pun, but us wrapping up kind of soon makes me think about aging and death and decay and whatnot.

And there's a, there's a massive fuss about aging and longevity at the moment.

Um, and David Sinclair and this notion of epigenetic scratches.

And it kind of makes me think of the inverse of that, which might be regenerative biology and the capacity to reestablish self-organization, reestablish, uh,

the kind of priors that we've been discussing in terms of the functional priors, the preference priors, the ones that, you know, are seeking a certain sort of a external state or seeking a certain probability distribution so as to be able to fulfill its function, so to speak.

Um, what, Mike, what is the kind of lay of the land in your world as to aging?

Um,

How seriously should we take this kind of epigenetic approach?

I won't ask about the moral aspect of it because it's a completely different question about whether we should live longer or not.

But having localized morphogenesis and self-organization is really the currency of biological systems.

How viable is it that we can reestablish that in something where self-organization is ailing and rather feeble?


SPEAKER_00:
Yeah, I think, well, the first thing is I do just want to say something about the moral question, because it also gets to the issue of regenerative medicine more broadly and beyond regenerative medicine, human augmentation and all of these kinds of things.

So the one thing I want to point out is

If it were the case that we were in some way optimized by some intelligence that shared our values, then one could make the argument, hey, let's not push too far off of that, right?

You're screwing up the planet.

And I get a lot of these emails from people saying, well, things are great, but you scientists better not mess it up.

And I just want to be clear that

There is no basis for this view.

Our health span, our aging, our susceptibility to all kinds of dumb diseases and our lower back pain and astigmatism, all this stuff is not in any way...

optimized for any of the things we care about.

That's just where evolution happens to have dropped us off at this point.

That's it.

And so there's nothing magical about this lifespan.

People who are worried about augmenting this lifespan, well, what if it had been 20?

or 30 you know then what and you say well you know that's too short why is that too short it could have been anything it's but my point is it's completely arbitrary and so and so let's not um base our decisions about what um what ought to be on where the process of random mutation and selection has has dumped us so that's the you know i kind of i think that's important to say um beyond that

I mean, we're certainly involved in some research on aging and the role of bioelectricity in aging and kind of the degradation of bioelectric patterning information with age and all that.

But I think more importantly is

My weather vane for all of this stuff is planaria.

So I think planaria basically, I think, hold the answer to all of life's big questions.

And so, I mean, the asexual form of planaria that we have, they do not age.

There is no evidence of an old planarian.

They simply they can go forever.

So these ideas that it's some sort of inevitable accumulation of errors or it's telomeres or it's clearly there are ways around it.

That's the one thing that we have an existence proof that and then there's a few other animals that do it.

But planarian, I think, are the most interesting.

Uh, th there, there is obviously a strategy that gets around it.

And I think it's on us to figure out why that is.

And I think it's absolutely not a coincidence that plenary are also extremely regenerative.

In addition to being immortal, they're extremely regenerative.

They're cancer resistant and they have an incredibly noisy genome because they don't clean their genome in every generation.

Like we do, they write somatic mutations.

Just if you, if it doesn't kill the cell, it just basically expands into the next generation.

Blenaria can be mixed deployed.

Every cell could have a different number of chromosomes.

They're just a complete mess.

And those are the animals that are highly regenerative, cancer resistant, and immortal.

Isn't that amazing?

Isn't that right?

Yeah.

And so finally, after years of feeling scandalized about this, the importance of the genome and all that, and why is the animal with the craziest genome also have all these amazing capacities?

I think we actually finally have a lead on what's going on there.

But I think that's what we need to look at in terms of aging.

I think if the question of regenerative medicine were solved, aging would be solved as a byproduct.


SPEAKER_02:
Excellent.

Yeah.

It makes me think in some ways, I don't know about the function of planaria worms.

People can search up pictures of planaria.

But it makes me think that in many ways, let's just take ourselves, for example.

What makes a human a human is in some ways the fact that the preference priors that we have or our functionality is limited.

I am not going to be at 39, 38, 37, and 36 degrees centigrade with equal probability.

But it sounds to me like Polinaria able to sort of metamorphosize in some ways, some of their preferences, because as you say, their genome is shaping.

Is that kind of a misconstrual of what's going on?

Is it that with the multiplicity of the genome, the messy genome, comes a multitude of function?

Or is it that the function is still constrained?


SPEAKER_00:
Yeah, I'm going to give you, and unfortunately we have to run in a couple of minutes, but I'll just give you a very quick story of what I think is going on in Planaria.

I think, and this is, Steve Frank told me an interesting analogy to this.

Apparently, when RAID arrays became popular, so computer disks that make copies of themselves so that if something goes wrong, he basically said that when RAID arrays became popular, the quality of disk media went down.

because it wasn't as important anymore to have your hardware be super reliable because you've got this system on top of it.

I think what's happened in Plenary in that lineage is that it has really come to grips with the fact that the hardware might be junk.

and that all the evolutionary effort went into cranking the algorithm.

Basically, the idea that we're going to assume from the beginning that you're full of mutations, you're unreal, it's unreliable hardware, and we're going to assume it's unreliable.

And so what we're going to do is do our best to have a system that is so highly regenerative that no matter what's going on, we can we have stand a pretty good chance of making a good planarian.

The development of planarian is called chaotic mode, where it's a total mess and then it sorts itself out into a proper worm.

I think, and here's why I think it happened, and we have computational models that show how this works.

Imagine that you have certain competencies to fix defects.

For example, like in the frog, we know that if the mouth is moved off a little bit in development, it'll soon make its way back to where it needs to be.

It sort of fixes itself.

So in evolution, if you have a system that has a little bit of competency to fix itself,

When that individual comes up for selection and selection sees that, okay, this is a great individual.

What selection doesn't know is, is it great because the genome was amazing or is it great because the genome was actually so-so, but it fixed itself?

You don't know.

Once you don't know, it becomes really difficult to reward for the best genomes.

What you can reward is for the best phenotypic fitness, for the best outcomes.

And as soon as you do that, that makes the problem worse because then the competency goes up.

Then it becomes even harder to know what your genome was.

So you start off with this ratchet, with this positive feedback loop.

And I think in planaria, it went all the way.

And in other species, not so far.

And in some like C. elegans, maybe not at all.

But that idea that the more competency of kind of reparative, regenerative developmental process, you can eventually, if you take it to its logical conclusion, you can say, fine, we're going to assume that the structural genome is going to be all kinds of noise.

And we're going to come up with an algorithm that can keep the morphology clean, assuming that that's the case.

And I think Planaria just like crank that knob all the way and salamanders sort of do it.

And maybe nematodes don't do it much.


SPEAKER_02:
That is very, very cool.

It makes me want to be a biologist.

Because the question, if we have more time, and I know we don't, is, well, where on earth is that regenerative mechanism coming from if it's not encoded in the genome somewhere?

But we won't go into it.

It just sounds to me like there are other ways to maximize model evidence, to use these active influence words, to maximize model evidence or to return to an attractor state beyond genomic stability.

And that's really fascinating because I think people think, well, the priors, the so-called phenotypic priors, are just what evolution has endowed us in terms of our DNA.


SPEAKER_00:
Yeah.

And so if we wanted to have another discussion, this is where we would talk about xenobots and anthrobots and these things that have never been under selection at the organism level in the history.


SPEAKER_02:
I've also been, I'll finish up here, but I've been reading a little bit of Evan Thompson in Mind and Life, and he talks about how, well,

the auto poetic coupled system is not going, you can't discover that dynamic in the genome.

Because there are things that are also selected over time, which, which refer to the external dynamic, and which refer to the world in which we are born and thrown into.

And that's really important as well.

And I wonder whether what that interplay means in terms of regeneration and, and morphogenesis.

But as

as you're all aware, and I'm aware, we're limited in time.

So we should I'd absolutely love to do this again.

I mean, it was absolutely fascinating.

Guys, thank you.

Just if you have a minute, it'd be great to know where people can find your details and also like what you guys have got coming up in the pipeline that people can be aware of.

France, you wanna go first?


SPEAKER_01:
Sure.

I mean, you can basically look at our names on Scola and get some of our papers.

We have a great website for the Levin Lab that has a bunch of our research come culminated.

My papers coming up will actually look at some of these questions in an annual organism in Wolvox.

That's going to be happening soon.

I'm very excited about that.

um because all the works published for me right now is a lot of the theoretical simulations and talking about the concepts where i'm so excited about most of my phd work was trying to apply this to an animal organism and see


SPEAKER_00:
not there's anything there um fantastic mike yeah so so the lab website is at drmike11.org one word drmike11.org and so that's where all the peer-reviewed stuff the the papers the protocols um data sets software everything is is there and then kind of a little bit uh more uh out there some thoughts are at a blog called thoughtforms.life and that's just my that's just my personal one


SPEAKER_02:
I'll make sure everything goes in the video description so people can check it out there.

But guys, thank you again.


SPEAKER_00:
Thank you so much.

Yeah, great conversation.

Thank you so much.


SPEAKER_02:
Thank you.


UNKNOWN:
Pleasure.