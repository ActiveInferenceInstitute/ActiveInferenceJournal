SPEAKER_00:
Hello, everyone, and welcome back to Active Inference Insights.

I'm your host, Darius Parvizi-Wayne, and today I have the pleasure to chat to Alexander Orobija.

Professor Orobija is an assistant professor of computer science at Rochester Institute of Technology, where he directs the Neural Adaptive Computing Laboratory.

His work focuses on developing new learning procedures and computational architectures that embody various properties, biological neurocircuitry, and are guided by theories of mind and brain functionality.

Last year, he published the paper Mortal Computation, a Foundation for Biomimetic Intelligence with Carl Friston, which grounded the mortal computation thesis in the active inference framework, in which they argued that active inference might prove useful in guiding the construction of computational systems.

Alex, thank you so much for joining me.

It's been a little while since we've done one of these, so I'm going to be a little bit rusty, as exemplified by my pronunciation of the word laboratory.

Lab.

I normally just go for lab.

How are you?


SPEAKER_01:
I'm doing great.

Thank you for having me on.

No, you're very welcome.

You can call it laboratory.

It sounds nice and formal.


SPEAKER_00:
I like it.

Yeah, laboratory, lab.

Great.

Well, before we dive into that paper, I wanted to ask, you're kind of coming from a computational background.

I've never actually asked this question first up to a guest, but it struck me that I probably should, which is how did you come across Active Inference as a framework?


SPEAKER_01:
Oh, that's a nice question.

Well, it was a few years ago, and the short compressed version of that is that I was working with some colleagues in the imaging science department here at RIT.

They do eye tracking and cognitive science research.

I also have a cognitive science background or partial background in my grad school years.

And so as we were talking about building computational models for

eye tracking problems we we ended up settling on this reinforcement learning dynamic control formulation of the particular problem we were solving and i had been long thinking about biological process models for reinforcement learning control and so i was already aware

for a very long time of the free energy principle.

Because I'm a predictive coding researcher, I like to also pitch that as something I have quite a body of work, been building a body of work on.

And so active inference is like an extension of that.

It's basically, let me put action into this process and actively sample the environment to facilitate my self-evidencing.

And so it just kind of made sense that we would maybe look at the free energy principle.

Originally, we wanted to build predictive coding models of our reinforcement learning system.

And then we said, well, wait a minute.

Exploration is going to be a difficult component here.

And that's what active inference brings.

One of the big things it brings to the table, to use Carl's phrase, which is this epistemic forging.

The idea that we're doing intelligent exploration

driven by our surprisal and so it just kind of made sense to investigate this framework in a in a further further way uh and then since then what was nice about that group is that uh my my colleagues uh weren't very familiar with uh predictive coding so i gave them a talk and then we wanted to

understand active inference.

We had a little reading group that we established with the grad students and the other faculty.

We forced ourselves to dive a bit deeper into, for example, Carl's work, Chris Buckley's work as well.

I was already familiar with Chris even before I actually got to meet him.

uh years later um and then one of uh one of my primary grad students uh george he was uh actually building some active inference models uh and then we effectively settled on a version of that in our eye tracking problem and actually that led to a really nice article about last year with george in frontiers of computational neuroscience where we actually published a little model that did very simple active inference

in a gaze modeling task and a very simple tracking task.

So it was really nice.

And yeah, and then I guess to wrap up that story without waxing too much about my past, because of that,

and my fascination with predictive coding circuitry and biological modeling, I sort of branched off in parallel to, well, George was working on that project, to say, why isn't active inference, even though Carl has presented it in several ways, in terms of predictive coding, why aren't we building things in this very, very raw, low-level model, right?

Because the idea is a lot of active inference is back propagation of errors,

deep neural networks great idea gets you to scale it up um but i have a long history of being at odds with back propagation and uh in the non-biological ways we do deep learning and so i had a series of papers over the last few years where uh i was saying uh let's do active inference uh completely wholesale in terms of predictive coding and so that that eventually accumulated in a robotic control paper i believe that got published beginning of last year too

And that was really nice because that's like completely done in terms of predictive coding.

So that's, I think I'll stop there.

That's sort of how I found my way into the deep active inference corollary of the free energy principle, which I've already danced over the years by saying that the models that I build are doing like an approximate version of their original free energy minimization.


SPEAKER_00:
Right?

Yeah, you bought, there's a lot there.

I think it's interesting.

Yeah, you know, in the in the best way possible.

There's a lot there in so far as I guess, free, free energy principle and active inference is kind of hierarchical in and of itself as a theoretical framework.

Because yes, we're minimizing our variational free energy.

But the way that we're doing that is kind of still up for grabs, whether it's predictive processing, in continuous state spaces, whether it's a kind of

more message passing scheme, like a POMDP scheme.

And I think people don't realize that those debates or those theoretical frameworks are still getting fleshed out.

So it makes sense why it is totally viable to push in one direction, maybe against back propagation and pro predictive coding, for example.

You also brought up reinforcement learning.

I'd like to backtrack to that later on in the conversation, because I'm sure you'll know far more than I do

There's kind of this live debate, again, still whether reinforcement learning is going to get us there.

And we can talk about the developments in that domain.

But as I mentioned in my introduction, really what I want to speak about is this paper, Mortal Computation, a Foundation for Biomimetic Intelligence.

which I got to say, I really, really loved.

A reason why I wanted to have you on is because I really, really enjoyed that paper.

I'm coming at this from a sort of cognitive science philosophy background, and I thought it was really impressive the way that you managed to integrate loads of different frameworks from sort of pure machine learning and physics to philosophy, phenomenology, and cognitive science.

So there's going to be loads for us to talk about.

Before we sort of dive into the details, I'm sure plenty of people

have heard the, out of the how many words are there in this title?

Seven.

They might be a bit confused about a couple of them.

So two questions, feel free to take them in whatever order you wish.

The first is, what do you mean by mortal computation?

And what is biomimetic intelligence?


SPEAKER_01:
Okay.

Yeah, that's a good way to start.

These terms might not be thrown around enough in enough fields.

um so biomimetic intelligence you some might have heard of biomimicry right which is the idea we're copying uh that is that which is biotic or biological or natural and the idea is that we look to

natural organisms maybe animals humans even very very simple life forms as you know you brought up in the paper um there's we use a lot of different examples to exemplify concepts and the idea of biomimetic intelligence as we say well for example an animal is intelligent is able to engage in certain behavior it is able to adapt to certain aspects of its environment it's able to forage it's able to

uh do a whole variety of cognitive tasks and um the idea of biomimetic intelligence is that in the sciences of the artificial with an art uh what do you call it a technological artifact uh something that isn't maybe naturally we would argue biotic it is in silico uh or uh you know non-biological material can we get this object to emulate or simulate

various properties and aspects of that biotic organism's behavior.

So that is where the biomimicry comes.

We are sort of copying that which we have observed in nature, something that is natural, and trying to instill this in some mechanical computational fashion in a technological artifact that is not grounded in that natural biotic kind of setting.

So that's broadly what you could say is biomimetic intelligence.

And of course, you could also take that another step further and think of artificial intelligence in its own very word.

Artificial means we are really building something that is essentially divorced from what we would call natural or biological.

This is in the in silico systems that we have today.

Today, biometric intelligence says, well, maybe we should move a little towards what we would call naturalistic artificial intelligence, something that draws its inspiration at the very least, if not maybe faithfully modeling, because there's also different degrees of how close you get to biology and nature.

And can we construct artificial systems that are intelligent and adaptive that maybe, for example, emulate what a cat would do when it's in its natural environment and trying to, for example, hunt for mice or hunt for food.

And then just as a quick fun word to tag on that, because we also use that in the paper,

Bionic engineering is actually the application of biomimetic intelligence or the idea of actually formulating this and solving a real-world task or problem.

That can also start to bleed and it's interesting.

Part of the other fun of writing this paper is learning a little bit of the history and the origins of words and who defines this.

Everyone has a different definition of these, but bionic intelligence would bleed into hybrid systems like

oh, human augmented systems, maybe we're creating cyborgs or enhancing a natural organism in some way that they don't have with their own actual body or form.

So bionic engineering is a little bit broader, but I just like to tag that on because we also kind of abbreviate them.

Sometimes Carl and I will say biomimetics, but that's just biomimetic intelligence, at least the way we refer to it.

And then bionics is bionic engineering.

So I think that'll stop there because we could keep going on.

There's a lot of history behind biomimetic intelligence and bionic engineering.

Some mortal computation, which is at the heart and core of this paper,

i mean obviously it takes the entire paper just sort of scope it out i i will first pay homage in respect to my uh my friend jeff jeff hinton he's actually the one that introduced that very phrase uh beginning of december of last year if i recall correctly um in one of his papers so again i work a lot in biological credit assignment how do we train neural systems in a

biologically inspired fashion.

And so Jeff had a paper on the forward-forward algorithm.

And so I was in correspondence with him about that not too long after that came out and worked on some things of my own.

But he introduced in that paper in about a paragraph or two, just talking about moral computation as just this kind of concept of hardware and the relationship to software and how those two, you know, we treat them in computer science specifically.

And I'm going to

Fold hopefully no one that might watch this might you know get angry at this, but I also fold computer science with cybernetics because you know there's all the computational components and There's a lot of entanglement if you look at their history, too so the idea is that we treat in many sense software as Immortal that means it can be run on

On any platform, it doesn't really matter the hardware or substrate that it is instantiated on.

And again, we tie it in this paper to machine learning and deep learning, which is just effectively a program that is data-driven and tries to adapt based on input that we give to the system.

And those are no different.

They're like any other computer program.

You could take, for example, ChatGPT or any of the big transformers of today.

And if your GPU server falls apart, you can just take that program that you've saved on disk elsewhere and run it on another one, and it will behave roughly the same.

And so that's what makes it immortal.

You can copy this anywhere you want.

Mortal Computation says, well, we should consider the fact, and again, this is just a little bit based on, and we fleshed this out a little bit more than I think Jeff at least wanted to at the time, which is that Mortal Computation bounds or entangles the software with the hardware.

We shouldn't be thinking of them as two separate and distinct entities.

And so that's where the phrase sort of originates.

And one of the core motivations is that

we get a certain energy efficiency.

Because one of the biggest criticisms of transformers and neural models today that characterize artificial intelligence is that they are greatly energy inefficient.

They require a lot of compute.

And while the costs are going down, and I'm seeing some of those trends pop up, they leave a pretty big carbon footprint.

And so there's also a fun and another vein of research that got into this paper of my own is I've been studying green AI versus red AI.

And, you know, just like we talk about green initiatives because we care about global climate change and our concerns of what's happening to our planet and our environment.

um that's green ai we would want to build intelligent systems that don't leave such a big carbon footprint uh red ai is what we currently have and there were some really nice studies emma strugle many many years ago put out one of the first uh measurements of these language large language models um and so mortal computation uh is one way to address this great inefficiency um beyond a lot of other things but that's kind of where at least jeff uh was coming at this from

What's kind of funny, just as a quick side note, because I obviously track Jeff's work, and while he in December, you know, sort of went down the route of, you know, we should, you know, get rid of backprop, we should go to some biological form of learning, and here's my

really wonderful idea.

And mortal computation is sort of one of those goals.

Later, he sort of, I noticed, used that as an interesting counter argument to talk about the dangers of immortal computation, as he's talking today about, you know, the

potential threats uh that immortal systems like chat gpt and transformers like them and other models not just these large language models posed to humanity and it's bringing up an interesting discussion and thoughts about you know ex existential crisis for humanity and

worthy things to be talking about but he sort of steered into the direction i noticed he uses moral computation sort of as like a well that's what you know we would say maybe the brain and you know biological organisms do uh but the models that we have today don't do that and actually that gives them sort of like superpowers and some dangerous abilities that we can't do with humans and that's worthy of discussion but we obviously don't go into that in this paper um so that's where it sort of originated and then

just to sort of quickly cap it off, because I know you said you wanted to talk more about the paper, because the whole paper goes into what would it mean to be mortal computation.

I also really liked in one of the talks that my friend Carl gave or had with someone else that was interviewing him about this work too, and he said that

uh this paper's form of mortal computation is sort of like another take on the concept so again like what i explained was sort of what jeff meant by it um and then that was his launching point for a set of other arguments um this one says well wait a minute that entanglement can we characterize that and dig into that a lot deeper

and so the idea is that that gets us to the origins of life right of how we ourselves you and me darius are mortal computers in effect right right if we don't mind calling ourselves that and you know not trying to remove our humanity and so that's what sort of this survey paper ends up becoming is it says well okay if we wanted to really go down that rabbit hole if you will what does it mean to define a mortal computer

and do other domains of science have possible definitions?

And that's what the other fun thing about this paper is.

I know you didn't ask about its motivations, but what's nice about it is that it is an echo of a lot of already great ideas by people way smarter than myself over the last century, talking about essentially what you could call the mortal computation ranging from physics and biology to physiology.

uh to even cognitive science has already some wonderful theoretical frameworks that we sort of just sharpened or highlighted or there's a little section in there where uh carl and i extend one of the cognitive theories maybe we'll talk about that later i like that you know the we have it called the 5e cognitive theory yes yeah yeah cool yeah that's fantastic um okay perfect so there's


SPEAKER_00:
Yeah, again, lots I want to unpick there.

So before we fold into inactive inference more technically and talk about how that is a framework in which we can ground mortal computation, I want to ask a question about the motivations about this energy efficiency.

Because people might be listening and saying, well, immortal computation sounds kind of nice.

It's kind of there and I can take it and it's substrate independent.

And so

my commitments are fewer.

Why?

Why does it make more sense to turn to a different form of computation rather than just refining something which clearly works?

And maybe, in the long run, it seems to me at least more efficient in the sense that it's just more transferable across different domains.


SPEAKER_01:
Yeah, that in that we mentioned that a little bit in the beginning of our paper, why would we want to commit ourselves to mortal computation?

It's rather brittle, as you pointed out.

So, um, so again, there's

many different reasons for why we would want a mortal computer but you said the energy efficiency so to let's just pick at that little bit of the argument so near the start of the paper we we talk about the thermodynamic motivations for mortal computers and there's some really nice ideas from physics and information theory i mean there's

even probably more that we don't properly scope.

And two of them that we can just briefly mention are the Landauer limit and Jarzynski inequality.

In a nutshell, without getting technical about them, because I actually made a point to flesh out those equations just so readers would be like, if they're not familiar, they can look at them.

But really, at the end of the day, those two concepts say there is a bound on the amount of work or the thermodynamic cost that a system can have to write and store information.

So again, in a computer, the idea is that we're using bits to store things in memory.

And so basically what those two say

is that uh there's a point where we're not going to get any more thermodynamic efficiently about you know the cost of actually racing a bit i believe that's what the lander limit or sorry yeah the lander limit and there's this inequality partially touched on they also talk about random fluctuations and averaging things to get a system to an equilibrium state but at the end of the day it's all just about that there's going to be a lower bound that we can't breach any further and what does that actually imply

for computer science.

Actually, computer scientists have written about these physical limits and the thermodynamic costs.

And it says that it might mean that we want to reach something called in-memory computation.

So in memory computing basically just says that we want to conduct the mathematical computational calculations.

Let's say those that characterize neuronal simulations directly at the chip.

All right.

So the idea is that we have processing and we have it organized, let's say, in a crossbar and a neuromorphic chip.

And we use that as like one of our little examples.

and we can actually essentially construct the neural model in that memory crossbar and so like the neurons are arranged in a particular way physically actually in this little chip and the synapses relate you know are related to for example memristors right and the idea is that we transmit information across these and that will be at the lower limit or the the bound on computation

Why is this different than what we do today?

Well, today, Transformers and the like

regardless of the value of GPUs and even what they call TPUs, Tensor Processing Units, and the speed that they have afforded us, and that's actually partially one of the core reasons of the catalyst of the deep learning revolution, is that we use von Neumann architecture.

So the idea in that is that there's a greater cost associated just fundamentally by simulating these neural models on a von Neumann architecture,

And that's because you could look at, for example, the memory organization of a computer.

So beyond, you know, like, let's just call it slow long term memory systems, which you know, you can write and this will preserve your information when you turn off your computer and turn it on later.

kind of want that versus volatile memory, which is something that is really fast, doesn't give you much of a cost to store things, but it's volatile.

So obviously, if you turn things off that you can't guarantee that your information is stored on there.

And then there's different types of intermediate memory.

And so the way of unemployment architecture sort of structured is it arranges this memory in a hierarchical fashion, and the CPU lives or the GPU, if you will, but let's just say the CPU specifically lives on top of this memory hierarchy.

That's where your computer programming lives.

That's where our neural network is being executed by the compiler, which talks to the assembler and talks to the bits at the very low level of the computer.

And so that's where your mathematical model is.

But it needs data.

It needs information.

It needs the matrices or tensors that store the synaptic weights, right?

Let's just think of our traditional neural network.

It's just a bunch of matrix multiplications and some nonlinearities.

Well, you need to retrieve that weak matrix for the first layer.

Well, that lives at the very, very bottom of this hierarchy.

So there needs to be some transfer process.

And that's already exhibiting a great thermodynamic cost.

They've quantified that.

I remember putting in the paper like certain measurements of joules at different layers.

So already fundamentally, we are not operating as close to the lower limit on thermodynamic costs as we could be.

And so that's already right there.

That explains a great deal of the thermodynamic inefficiency of deep neural networks and intelligence systems that we have today.

One of the motivations you can use the

the idea of in-memory compute is that it gets you to something like edge computing.

If you have something in robotics, which I'm very fascinated by robotic systems or even autonomous vehicles, you're not going to be able to transmit to servers very easily.

You're not going to be offloading your intelligence somewhere else because then you have the communication costs to pay off transmitting information.

you're going to want your system to live in the device that you're using so in a robotic system you have limited power you have limited uh compute resources so you're gonna want to work with in-memory computing like for example a great uh in-memory system would be like a neuromorphic chip just in case the audience is like well what would be examples of that um and one that has fascinated me which is where the realm of spiking neural nets comes into play and i've done research in

as well, and that's what gets you to neuromorphic chips, which does rest on this principle of in-memory computing, right?

So the actual spiking neuronal models are actually laid out in these neuromorphic chips and computation happens directly on there.

So I think that's sort of like

an energy kind of argument for why we would want this, this would be quite useful for edge computing cases.

And you'd say, well, okay, well, that's just a few examples, right?

We're doing a lot of intelligence without that, but most of robotics is going to be edge computing.

If we want an intelligent,

humanoid or non-humanoid like robotic system, we're not going to be running them on big supercomputers or GPUs.

And again, I'm not trying here to attack those that maybe are for like hive mind intelligence where we do communication across servers and we can pay that cost.

But if we want these organic like robotic systems, this is where I think mortal computation really is a path forward for those types of applications.

And there's a lot of other applications that you could argue have edge computing.

So I think I'll stop there because that just centers only on the thermodynamic argument.

um i'll just quickly before i forget it tag on uh the other part of is that when we get to that lower limit on thermodynamic costs uh there's a nice equivalence to the variational free energy minimization process because uh while again i

i did tend to focus a little bit more on the thermodynamics the physics side of things uh you know i liked how carl and i sort of connected it to the information theoretic idea that uh to be base optimal right we want to actually get close to that limit and so there's it's sort of like there it's saying the same thing actually the nice thing about the variational free energy principle sorry

variational free energy minimization process is it is also actually optimizing that thermodynamic cost in organic systems.

We are operating at that lower limit.

That's what it means to be Bayes optimal free energy perspective.

And I'll stop there, but I like that.

I just want to make that connection because that kind of tags a little bit in that argument.

And then it starts to bleed into the other motivations you could say for moral computation.


SPEAKER_00:
Yeah, no, I let's actually stick on that.

Because I think that's a really interesting point.

I think people some, you know, it's actually possible to kind of do the free energy principle without taking into account thermodynamics, right?

You can just do the statistical mechanics and the information theory, just do Shannon information and just say, you know, we're reducing self information.

So people might be curious, actually how this ties to thermodynamics.

I'm curious about ties to thermodynamics.

I'm not a physicist.

So

to minimize variational free energy is to be sort of operating at this lower bound in terms of thermodynamic energy.

What does that look like?

And I think you talk in your paper about kind of exchanging energy or the work needed to maintain yourself at this bound.

What does that look like in terms of the mapping between information, theoretic terms and thermodynamic?


SPEAKER_01:
Well, first of all, I'm not a physicist.

We should be clear here as well.

I am a computer scientist and cognitive scientist.

So again, it goes back to like what I have my paper here just to remind myself if I need to.

But like I said, it goes to the Jarzynski inequality and the Landauer limit.

So I guess maybe I want to ask a little bit of a clarification.

What do you mean?

What does it look like?

Just to help me out here to trigger that I'm not.


SPEAKER_00:
So just in terms of that kind of isomorphism, that minimizing variational free energy just is operating at this thermodynamic lower bound, just in very, it can be very simple, because it's gonna have to be very simple for me.

Because they don't teach you this stuff in cognitive science.


SPEAKER_01:
Yeah.


SPEAKER_00:
What does

I mean, what does that mean in terms of our sort of thermodynamic exchanges with the environment?

Because, you know, I think a stumbling block for a lot of people when they hear about free energy is there are lots of ways of talking about energy.

So it's kind of being able to do the mapping between all the different aspects, whether we're talking about kind of Shannon information, or whether we're talking about thermodynamic energy, or we're talking about whatever, whatever, you know,

whatever framework you want to come, you want to work with.

So it just in very simple terms, what does the minimization of I mean, we can put it very generally, what does the minimization of variational free energy beyond beyond mortal computation beyond computers?

Very simply, what does the minimization, minimization of variational free energy look like, in terms of operating at this thermodynamic lower bound?


SPEAKER_01:
Well, I guess it gets a little confusing because now I'm thinking about the actual implementation.

So again, I could approach it from a predictive coding point of view because that's what I usually appeal to when I think of minimizing variational free energy.

So I guess at the end of the day,

Kind of goes into the, I guess the problem with your question, I think it makes me think of the other arguments we get into metabolic efficiency and the idea of resources that the organism is acquiring.

Okay.

I think I know where I want to go with this.

So it's actually kind of later in the paper where we touch back on the free energy principle and we get into this concept.

So what does this look like?

It looks like the concept of the, what do you call it?

The non-equilibrium steady state, the NESP.

So what does this mean more generally for even artificial and biological organisms?

The idea is that we want to reach a point that we are far from thermodynamic equilibrium.

And so, yeah, I got to charge my memory here a little bit of certain parts of the paper.

So apologize for the delay there.

So the second law of thermodynamics is that, you know, that entropy must increase right in a closed system.

And so we are tending towards higher entropy and we are reaching, you know, systems will reach equilibrium.

And actually, that's not what living systems are doing.

Living systems live at what I just said earlier, non equilibrium.

And you'd say, well, wait a minute, are we trying to adhere to the second law of thermodynamics?

And this is part of what was interesting about this paper in understanding the history of things.

There is an interpretation of thermodynamics and biology, and they call it the first law of thermo, the first law of biological thermodynamics.

At least this is what I had found in my, you know, search.

uh through the info through the literature and the idea is that organisms do want to stand far away from equilibrium because equilibrium means death equilibrium means dissolution or disintegration into a heat bath into your environment your identity ceases to exist and that allows me to poke and touch another concept of why mortal computation is so important it's a process of identity constitution and preservation

And so where that connection comes into play is that organisms, they have a goal.

And according to the free energy principle, organisms have the idea that their dynamics wants to make them stand away from this equilibrium.

And so they're going to need energy and resources to allow themselves to do that.

And then there's another part to that.

And actually, I do want to remind myself so I don't steer the audience wrong because I liked how I pitched it or how I put it in the paper.

there are two principles before you got into the markov blanket discussion oh no uh okay i remember what yeah so again it does connect to the markup blanket but the idea is that these dynamics in the cis the internal states of the organism are conditionally independent of their environment the external states right and that's what the markup blanket formalism tries to formalize that more strongly and the that we have those density dynamics they are conditionally independent however you are still

weekly coupled to the environment through the Markov blanket interface.

And so again, I apologize for introducing those words later in case you wanted me to flesh those out.

But the idea is that because we are coupled to our environment, that also gets us to the connections of active inference and why we must act to move about our environment so as to prevent or to keep ourselves at

The non-equilibrium steady state and the free energy principle says that if you are a living organism or an entity, you will return to this NES and your actions and your goals and behavior lead you back to the NES.

the other concept is and this is the part two of the free energy principles the concept of continual self-evidencing right the idea is that you're trying to maximize the data for your own internal generative model which is connects to the other component of the paper where we brought in cybernetics and like the good regulator theorem which

We can talk about that later if you want.

So I think that's what it looks like.

Right.

And it manifests itself in this this continuous goal of trying to stay in non-equilibrium.

You're avoiding equilibrium, which is dissolution into your environment, death, which also means the end of your identity.

And so that's what a mortal computer is constantly engaged in.

And that's what the thermodynamics kind of gets you to.

It walks you to that, which is another way that the free energy principle states that.

Right.

And so I look at it from the like the information theoretic quantity of like, oh, I'm

you know dealing with gnats or bits right but the idea is that at the end of the day you're trying to stay in your nest any essence yeah yeah and you're continuously self-evidencing uh and you're dealing with this weekly coupled a weak coupling to your environment and you're interacting through your markup blanket i'll leave that black box for now in case you want to poke at it no no that that's great i mean that that's much more my language

By the way, that's what I think it looks like.

That's where thermodynamics really gets you into the biological thermodynamics, the first law of biological, which is really what that is sort of restating, remanipulating.

It's basically all talking about that non-equilibrium.

that we want to live at which then you can and the nice thing about the biological first law of thermodynamics is it sort of deals with the fact that you're saying well we don't violate the second law of thermodynamics entropy will still go up it's just not in the organism system itself it's an open system that lives in a closed system which is the greater like in eco-niche uh organism pairing right and so

entropy will go up according to the second law in the entire system but inside this system this explains why entropy can go down and that's what you know and that's what i liked about that because that was a great source of confusion i saw even in the literature um you know how are we dealing with the actual second law of thermodynamics well we're not fighting we are really adhering to the biological first law of thermodynamics

which that's what any SS and the free energy principle sort of at least one dimension or the dimensions that I'm more familiar with tackle.


SPEAKER_00:
Yeah, so that great.

So that latter point is kind of where I was heading with my rubbish physics vocabulary.

But the nest when you try to set it stuff is all perfect for us.

So don't worry, you haven't opened Pandora's box because this is a language at least that I'm speaking these days and this institute is speaking.

But that's exactly the point I was making.

Because it's kind of all about the scope of one's analysis, right?

Like equilibrium for whom?

Because I think people get confused that they think of free energy minimization as homeostasis, which they learned at school as equilibrium.

But then they're saying that we're far from equilibrium.

So it's non equilibrium with respect to the universe, or with respect to the way the universe wants to be, which is dissipative fundamentally, but it's equilibrium for ourselves.

in terms of our internal dynamics, given our steady state, you know, given our attractor set.


SPEAKER_01:
And I should add a word that just compliments what you said, because you're correct.

Homeostasis is actually kind of confusing.

And we introduced another word, and I thank Carl for pointing me in this direction, because he had us, you know, highlight this.

Hormeohesis, I think.

Yes, I saw that.

Because it handles this, and we could talk about that if we want.


SPEAKER_00:
Sure.


SPEAKER_01:
That's the word people should learn.

But I never learned that when I was much younger.

I only learned that in the context of formulating this framework with Carl.


SPEAKER_00:
So yeah, and then people, I guess there's a great deal of emphasis on allostasis as well within active infants, which we can touch on, we'll, we should probably unpick those three.


SPEAKER_01:
Yeah.

And don't forget autopoiesis as autopoiesis.


SPEAKER_00:
I've been reading a lot about autopoiesis.

Great.

Okay, cool.

Yeah, I mean, should I keep perusing down this area?

I think it's interesting, because it's like, so we're minimizing entropy within our own bound within our own system, whatever that looks like, because those boundaries, it's hard to kind of cast a limit.

But that, according to the second law from dynamic thermodynamics means that we have to be creating entropy elsewhere.

just so that the system itself is abiding by the second law.

How do we do that?

How does anything do that?

Where are we creating entropy?


SPEAKER_01:
Okay.

Well, let me make sure that I zoom in on the right component that touches on

So I think the problem is there's all these slices to mortal computation, as you're familiar with the paper.

And I think a piece of one of the other interpretations is a

more approachable way to understand how we increase entropy, which is the idea of inactivism.

So I'm borrowing from, so just for the audience that maybe hasn't read the paper, we sort of have a pathway that we talk about the mortal computation thesis.

We talk about biophysics.

We talk about the cybernetics interpretation.

We talk about the cognitive science framing, right?

Even though they don't use these words, they're essentially saying these ideas.

and then we lead into sort of a free energy definition and a markov blanket formulation with uh other things and then we lead to a definition so that's so when i say slices that third of that one portion of the paper on cognitive science is where we borrow uh from

uh well what's normally called 40 cognitive theory which you know and one of those e's is inactive the first one's embodiment which we can touch on that one as well but uh inactive is about your relationship to your environment and so uh and how that interacts with you there's like a bi-directional relationship

We act on our environment, and that effectively means we are authors of the information that we will end up using and the resources that come into us, right?

In terms of our foraging, in terms of our survival.

Remember, not to forget, our goal is to stay in non-equilibrium, right?

Not in equilibrium, steady state.

And so that's essentially how we're going to end up creating entropy, right?

Because we are going to manipulate the environment.

idea that where the active portion the active inference element comes into play nice and so we are uh what's the right word that we use in the in the paper that others have used as well uh we are engaged in niche construction right indeed yeah so because we manipulate the environment using the affordances that it brings us and we do things to allow ourselves to again

you could tie this for those that maybe don't like any ss as the goal but say we want to survive survival and identity continuance right is essentially living in this non-equilibrium steady state uh we enact our environment we change it when then that information of course we're then gathering that and so the environment affects us right it's a bi-directional relationship

The environment constrains us, puts problems on us.

We have to deal with that, but we change the environment.

So we are creating disorder.

And that's a key element is that through the actions that you take, through any animal that they take, through any organism that they do to manipulate and change something about their environment so that way they can continue to get resources, matter and energy back.

uh those are the two the fuels of the universe right uh we we essentially create that disorder right and so that's how the second law of thermodynamics gets satisfied because that's what biological or biotic entities and i'll just zoom in on them for now because you know again i want to be careful not to step on physicist toes or biophysicist toes as well because i'm not in those domains i've just read enough of that work to synthesize right

But that's how you're creating your entropy is that you are inactive, right?

And so this is the concept of inactive cognition.

You said you're reading about autopoiesis.

There's also this thing called, what is it?

Autopoetic inactivism as well.


SPEAKER_00:
Yeah, Evan Thompson.


SPEAKER_01:
Yeah, exactly.


SPEAKER_00:
Yeah, I'm rereading Mind and Life, which is Evan Thompson's kind of massive magnum opus from 2007, which is cracking.

Okay.

Um, I like pointing people in directions of readings that they can do.

Um, so yeah, that's a great one.


SPEAKER_01:
Thompson's someone everyone should read.

I think.


SPEAKER_00:
Yeah.

Yeah.

So yeah.

Beautiful stuff.

Um, obviously Varela, Russian Thompson, 91, um, the embodied mind and all the stuff that Varela did with Matarano in 1980 or to priestess or wonderful work.

Yeah.

In mind in life, he talks about the fact that inactive, uh, entities are

uh, what does he say?

He says operationally closed, um, but sense-making and by sense-making, I think what he means is this kind of yet thermo dynamically open.

Um, so we're in the game of autopoiesis, but that, that doesn't deny that doesn't negate the possibility of obviously of, of interacting with the environment.

In fact, we have to integrate the environment into our model or into our, uh, action policies,

to use an active inference term, in order to get like do autoprocess, you're not going to last very long if you're an entirely closed off system.

It's funny, because, again, it just makes me think about how scale, how scale is really a very important kind of currency in this discussion.

And it might just be philosophically interesting, but I'm sure it's interesting for physicists, too.

Because it makes me think that like, whatever we are, whatever the bounds of us as an identity is,

kind of pockets of the universe where entropy is decreasing but then there's nothing kind of a priori stopping that process expanding to let's say societies or worlds right or galaxies or milky ways and and i guess the question is is uh where

where does the where does what was the what's the overarching closed system?

Because, you know, I get I know you're this is this might not be your the question that you want to answer waxing with your thinking, you know, speculating seems to me that and again, this is not an argument from design.

I think interestingly, there seems to be a sort of resurgence perhaps of an argument from design.

I know Philip golfers just released his book why which is um,

a kind of philosophical argument for, I wouldn't say it's designed per se, maybe it is from a probabilistic perspective.

I think relying on, actually I won't say it because I haven't had Philip on, but the universe has its space at least for entropy reduction, but we still have the second law of thermodynamics operating in these closed systems.

I guess the question I would ask to a physicist is, what if it's just open systems all the way up?


SPEAKER_01:
Well, yeah, I would love to have, it would be fun to pair up with a physicist here and ask literally that question.

All I will say in my non-physicist hat is that at least when I was constructing this framework with Carl, and it'd be fun to get Carl's thought on that as well.

Yeah, sure, welcome.

Oh, wow.


SPEAKER_00:
You know, future.

Yeah, yeah, future call.


SPEAKER_01:
In the future.

But I like to think that there is some outer closed system.

And so I guess when I was writing this in a perhaps ignorant way, I was thinking of the entirety of the universe as the entire system, right?

That is the closed system because I thought you were going to ask a different question.

And I have an answer for that one.


SPEAKER_00:
No, go ahead.


SPEAKER_01:
about cosmic bodies and all the other entities in this universe right um uh but but just to to stick to your your your comment um I think the entire universe is the closed system and that's where the entropy is going up because you know you probably have heard about uh at least it's I believe it's still like more of a physics theory but the eventual heat death of the

Everything.

Increasing heat, increasing energy.

Isaac Asimov has written wonderful stories about it.

And so I thought of the entirety of the universe and every other entity that is in it.

Some of them could be living in that non-equilibrium steady state, but everything eventually is tending towards the heat death of the universe.

so the closed system there is an outer bound i just haven't picked it specifically and that's where a physicist would be much more qualified to draw that boundary the tiny question that i was wondering because it's set you were almost walked yourself there which was when you brought out other bodies and i'll even throw in electrons in here too because

I thought you were going to say, are cosmic bodies mortal computers?

Are electrons mortal computers?

And I do have an answer for that one.

Again, I'm not going to pretend that I have the physicist's answer, but I think Carl has actually eloquently addressed this, again, in other discussions related to this paper, because someone did ask him, well, is the moon cognitive, right?

Yeah.

They would also, you could argue that they're following certain dynamics as well.

Why didn't we include other objects?

Because we have actually examples in the paper, very specific, like

these entities serve as wonderful examples of mortal computers, we can chat about them if you like.

But I like how Carl said, Why does the moon not necessarily think or at least we wouldn't call it cognitive.

And he talks about these dynamics, the flow, right?

You can decompose flow in physics.

And again, I'll put it in the lightest interpretation.

So that way, I don't miss maybe misspeak.

But you can decompose

dynamics according to Helmholtz CND composition.

So there is something called solenoidal flow or conservative flow.

And then there's this thing called dissipative flow or the random fluctuations, as Carl has mentioned.

And the idea is that

uh random fluctuations uh that's the stochasticity of any system that you must deal with and when you get close to quantum which i am not a quantum person but i understand that the random fluctuations are so high the amplitude of them that they dominate the dynamics right and so that's why in quantum mechanics you specify things in terms of probability distributions um but then as you move all the way up in increase in

And Carl's also been very careful to avoid saying space, which is constant, but rather just the size of the objects that we're considering as we get up to macroscope, meso, macro, and cosmological scales, because you mentioned scales earlier.

The idea is that the...

flow becomes more dominated actually almost entirely if not completely solenoidal right which is this conservative flow it's time dependent flow dependent on the states because again i should mention too when we're talking about flow we're talking about the states of a system right and they change with time everything is dynamic and evolving um and so the dissipative random fluctuations get averaged out because as you get bigger and bigger in scale

you average out fluctuations and the amplitude goes down, right?

So as you progressively get bigger, you progressively average out the noise to the point where when you get to the cosmic bodies, all that's going on is solenoidal flow, whereas a quantum or the very, very small scales, it's mostly dissipative random fluctuations.

So how does that connect back to mortal computation or cognition or sentience or anything of that form?

Well, Carl has used this phrase, the Goldilocks regime.

So we didn't write about it in the paper, but I thought it was a nice, it's a good thing to think about that there is this regime of being big enough, but not too big and not too small.

You know, that's the Goldilocks regime, right?

Such that you have a balance or you have a combination of dissipative

flow and solenoidal flow because the idea is that you need that dissipative flow in order to minimize your variational free energy the idea is that we need that dynamics we need something to be surprised to uh drive our continual self-evidencing but you need that solenoidal flow which by the solenoidal flow can be like rotational flow very like a carl used another example just because i remember seeing this and it's stuck in my mind about water and flowing towards a drain or a or a

open plug and as it rotates around it doesn't go down that would be the dissipative part it's going down the gradient just the circular rotational movement right so that's what you know these bodies at the cosmic scale they collapse to newtonian or lagrangian mechanics or classical mechanics right and the idea is that they're just following this conservative flow but there's no dissipative random fluctuations

Whereas electrons and quantum objects as well.

Right.

They're just dealing with all this dissipative stream noise or stochasticity.

So electrons don't think and the moon does not think because, again, you need sort of this balance between these two flows in order to essentially.

promote this self-evidencing in a structured way too.

Because again, if everything's just so completely random, it's obviously hard to form, what is it, steady patterns.

Oh, and the other component to this is the cycle.

And that's where I think the mortal part comes into play.

The solenoidal flow or the rotational or the predictable patterns or the conservative patterns, that's where you get things that repeat or a periodic.

And so that's what gets you the life cycle.

So there's a lot of wonderful examples like breathing is actually an example of that solenoidal flow or cycles and language or the fact that you and I die.

Right.

And there's the cycle of death and rebirth.

um those cycles are more of that conservative flow uh and that's the part what makes creates this mortality right and that mortality the other take by the way i sort of skipping around a bit the other motivation for moral computation is that that cycle that life cycle adds a pressure to these entities right that would not normally be there because again if you're immortal and you don't have to worry about death you might act a different way right

So that that life cycle thing comes from that other aspect of the flow.

But again, when you get but you need that sort of stochasticity right to, you know, engender that continual self-evidencing that wouldn't be happening at like the cosmic scale, which is just essentially all those random fluctuations are averaged out.

So I think you didn't ask that question, but you almost and I thought you were.

Yeah, yeah, yeah.

But I should answer that because I think that's something that's not really addressed in the paper.

and I was surprised to see a couple different places that that question comes up.

So no, electrons don't think, and the moon does not think, at least in accordance to the way we were thinking about mortal computation.

There is possibly a Goldilocks regime, but what are the bounds of those regimes?

I'm not sure.


SPEAKER_00:
Yeah, yeah, yeah.

In the first episode of this podcast, Carlo and I go quite deep into that.


SPEAKER_01:
Oh, so you've worked on that already.


SPEAKER_00:
Okay, yeah.

Well, it goes pretty, you know, we start talking about

information geometry spaces and, and indeed, these flows.

Yeah, so just for everyone called as a big exposition of that in the first episode.

And, and yeah, it's beautiful, because it ties together as well, like this, what I've been speaking about with phenomenologists, especially people interested in Heidegger,

this kind of future orientated nature that we have, because we're always at risk of being dispersed.

So we always have to be acting for our self organization, not only at time t, but also for t plus one.

Yeah, which which feeds into this kind of notion of our stasis.

So we've done, we've done a huge cosmic overview without even talking about the paper.

But I do want to ask one more question about immortal computation going all the way back to what adverse is mortal computation going all the way back to what we were talking about at the beginning.

So

The way that Jeff, so Jeff, Jeffrey Hinton, super important guy in machine learning.

And I know him and Carl and Pete Diane, there's, you know, they were working together in the 90s.

So this is a very long history.


SPEAKER_01:
The Gatsby unit, right?


SPEAKER_00:
Yeah, yeah, yeah.

At the Gatsby, exactly.

And, you know, this casting of immortal versus mortal as being a software hardware dichotomy.

So in mortal computation, the software is kind of bound to the hardware like us, right?

At least the way that we would, uh, you know, most materialists would think of cognition and the brain where software is, um, substrate independent in the sense that you can take something like chat GBT and play on my computer, put it on your computer.

Um,

So that, in my mind, again, because I'm coming at this from a philosophical perspective, makes me think of functionalism as a kind of philosophical theory of mind, which, at least in its kind of very raw form, is substrate independent.

And an argument which comes from Ned Block, which is a kind of argument ad absurdio, is that...

if you take that idea of substrate independence seriously, what you might end up with is what he called the Chinese brain, which is let's have a system where every neuron in the brain is replaced with a person from China because the number of neurons in the brain region

map onto the number of people in China.

And if they do all the flagging, if they do all the synaptic integration, then we would have to be compelled, if it was completely isomorphic, to say that that brain was conscious.

And he goes, well, this is just clearly wrong.

And you do have functionists who will say, well, actually, that brain would be conscious.

Sorry, that Chinese nation would be conscious.

I guess I say all of this to ask just purely on intuition,

Does the notion of a kind of boundlessly immortal computer or software really, does that really make sense?

Because it seems to me that yes, you can access ChatGBT and I can access ChatGBT, but that is contingent on the fact that you and I are working on at least relatively similar hardwares.

So I'm just wondering whether the notion of immortal software is itself a slight red herring or an overshoot.


SPEAKER_01:
Possibly.

I mean, I guess... I guess the way to think about what the argument for immortal computation really says, right, is that... Well, so... I gotta think this one through, because, yeah, I've not heard about, you know, the actual problems with immortal computation, per se.

So...

Are you referring to maybe perhaps the limitations of it?


SPEAKER_00:
Well, I'm just kind of bringing into question the very dichotomy that is supposedly at the heart of the problem, which is that you have hardware systems that are prey to dissipative forces, whether it's the metal in my laptop or silicon or whatever it is.

And then you have the software, which, which arguably is substrate independent, right?

I mean, that's the very dichotomy that set up my point is.

is that the in the substrate independence is a bit of a misnomer.

It's not necessarily the case, because all the all the evidence we have for substrate independence are relying on very similar substrates, right?

Like, we all have very similar.


SPEAKER_01:
Yeah, you're saying that, because at the end of the day, we are effectively using the same type of substrate, right?

You and I were executing this.

So the fact that we aren't, we aren't really testing the

the independence component, right?

Running it on an entirely different substrate.


SPEAKER_00:
Write it on the population of China and see.


SPEAKER_01:
Like you said, create the Chinese room style, the system, right?

Could we construct that?

Possibly.

I mean, it is possible that it is a misnomer.

I guess maybe what people think about, and again, you could probably even find minor criticisms or minor issues with this, is like when you change the particulars of the hardware.

So when we run, for example, ChatGPT or Transformer, we're using something like a GPU system, right?

Maybe multiple GPUs.

Well, I could say, well, wouldn't changing the hardware mean I run it on a set of, let's say I have a lot of CPUs lying around, right?

That is different hardware.

They have similar properties, like let's say physical properties are in Silico, right?

But they are different constructs to run, you know, the same thing.

And the idea is that, you know, ChatGPT would run just fine on a set of CPUs, to my knowledge, I haven't necessarily.

tested it, but you can run multi CPU systems.

Same thing with a TPU.

They might just have different speeds, right?

They give you maybe the speed of training, the convergence properties might change, but at the same time, they will, again, if we're not doing learning, I would imagine the program runs the same

way.

And I would even imagine that you can run let's say you had a really, really good like device that isn't a multi GPU system, you pre trained your model, and now you run it on there, it'll behave roughly the same.

However, I could see the argument that even then, there's going to be differences, right?

Because there's the properties of just the actual system that you're simulating on.

You can even talk about, for example, seed generation.

So, you know, when we write a program, we have a computer seed, right?

You control the noise or you control the level of determinism in your computer simulation.

And you can use wall clock time, for example, to generate seeds.

Well, if you change the system, well, you're not going to have access to the exact properties that instantiated that seed on my computer.

Already your computer's on a different stochastic trajectory if it, let's say, uses noise.

Transformers might not be the ultimate best example, but any system that's like a noisy neural model would already be behaving a little bit differently.

Maybe on average, they would behave the same if we averaged out those fluctuations.

There is a little bit of difference across hardware platforms.

It could possibly be a misnomer.

Again, to use your example of

the Chinese room style neurons.

And we simulate GPT, right?

But with these particular with humans serving those neurons.

Yeah, I would I don't know if I can really comment on whether or not that could perhaps be a way to break the complete immortality of the system.

I think what moral computation just to make sure that I don't get lost in the plot here

is that mortal computation really wants to emphasize that at the end of the day, well,

The way that we design our programs, they really are eternal.

I mean, they might not necessarily run exactly the same, like you're pointing out, there could be some problems, but we are not designing our intelligence systems with any or very little, what do you call it, constraint or informative information about

the substrate it's going to run on.

Like when I write my neural simulation, I run it on a server, maybe I run it on my desktop.

I don't think about, oh, is this device actually going to affect the characteristics of my program?

Like that's sort of what Mortal Computation even touches on, which is like the particular quirks of an entity

are very substrate it's like almost like once you build one particular neuro robot you would also get what in cognitive science there's this term coming up cognitive diversity right so if i built a different neural robot let's say i it has very similar structure right you would say okay well these two mortal computers i i tried to design them exactly the same i run the same program well because they are two separate entities and the way they interact with their environment they are going to have their own

eccentricities, their own quirks, their own particular knowledge, from self evidencing them particular selves, right.

So the idea that this neural robot, this neural robot, while they have very similar hardware style, they're still going to be two very different systems, whereas chat GPT, which was, let's say, or a transformer, let's not pick on chat GPT, but any of these big neural models that was, let's say, pre trained, and then, you know, consolidate and said, I'm going to clone you into these systems.

maybe their inference system, their inferences might lead them to uncover different data.

But at the end of the day, the particularities and quirks of the software, they're kind of tied to the same origin point.

So I think that amount of adaptivity and the essence of how we, again, find ourselves towards the NESS, the non-equilibrium steady state, is really dictated by

that particular knowledge and information that's encoded in your body and so that's where we can touch on and i know you're familiar with the embodiment thesis or embodied cognition i think that's the other part to mortal computation that's important is that the body offloads some of this cognition whereas again even in the the chinese room version of chat gpt or whatever uh

we're not necessarily using bodily non-neural like components to sort of offload this cognition.

So that blending and that combination is not there in those types of systems.

So perhaps that's where I think maybe I just wanna remind that

The immortal computation really refers to that entanglement, that co-design of the software with the hardware, the substrate, and the intelligent algorithm that you design, if that makes sense.


SPEAKER_00:
Nice.

Yeah, yeah.

That makes perfect sense.

And yeah, it brings in embodiment very nicely.

Yeah, so let's go into our triple stasis words, acis and where the limit stops.

So I think people will be aware of what homeostasis is.

It's this, you know, this description of the fact that biotic organisms have certain bounds that they have to retain, you know, remain within in order for their survival to be viable.

So you know, we actually will learn this at school.

But you can think of glucose levels, or you can think of temperature.

Something a bit more foreign to people is allostasis, which is actually quite simple.

It's just the idea that cognizers capable of greater temporal planning can take prospective action to minimize future homeostatic problems.

So if I look outside of my window and I see it's snowing,

I can plan in advance and put on a coat before I go because I know if I go out there, I'm going to have these dis homeostatic outcomes because I'm going to freeze to death.

But maybe my dog, although they love my dogs, they love the snow.

They don't really mind.

But let's say they did.

They might freeze to death.

Actually, they probably wouldn't.

But it's fuzzy who has what.

But then you introduced this third term, you and Carl.

Homeoresis.

Thank you.


SPEAKER_01:
Homeoresis.


SPEAKER_00:
Wonderful.

Homeoresis.

Let's just start with what does that mean?


UNKNOWN:
Sure.


SPEAKER_01:
So the really simple way to think about it, so that way those that are familiar with homeostasis, so you could state homeostasis as there's a set point or a particular, there's kind of flavors of it, a number, an average number or a range.

you want to keep like your temperature again so that we avoid leaving the non-equilibrium steady state and dying um so we want to keep things within a range and we want to keep things relatively constant right that's what homeostasis ultimately says um and then you built on it home allostasis is predictive homeostasis right it's trying to serve homeostasis to prevent that hormiohesis one way you could take it is it's time varying homeostasis so that's

the first place you could move to, which is what if that set point was changing with time, right?

It was dynamical.

So in that sense, that almost gets you roughly to hormiohesis.

A better way to, so that's one way to build on the audience's knowledge.

Another way to state hormiohesis is that instead of it being like,

or a process returns to a set point or constant value or within a range, you are returning to a trajectory.

So that's, it's where it's like, it's a random dynamical systems view of homeostasis.

Whereas homeostasis is talking about constant return to a constant point.

Here we are returning to a trajectory.

So this, that's very cool.

The time evolution.

And I think that to me made more sense.

So I'd say that would be hormiohesis.

Oh, and then by the way, a fun variation to it.

And again, you won't find these too common around is hormiohetic.


UNKNOWN:
Okay.


SPEAKER_01:
So if you want to say something is homeostatic, you would also say it's homeohetic or a homeo process.

Try saying that a few times.


SPEAKER_00:
Yes.

I think Carl just peruses the dictionary and just manages to- It's amazing.

It is amazing.

It is amazing.

Okay.

That's really interesting because, so again, this is kind of converging with a lot of the reading that I've been doing.

I've been trawling back through Andy Clark's work.

And he has a wonderful, wonderful paper called knitting your own Markov blanket.

Yeah, which is fantastic.

And he talks about how, and I think this is a reasonable critique that was leveraged at the free energy principle and active inference in its original inception, is that it kind of took the Markov blanket as a fixed statistical entity, let's say.

And therefore, the particle, the internal states and the external states, they didn't really allow for, you know, dynamical

the unfolding of what dynamical systems theory predicts, which are trajectories, as you said.

So Andy Clark says, well, let's take less of a substantial ontology and think more process ontologies.

So in the same way as a butterfly is not the same thing through the course of its lifespan, we can still identify the butterfly through a process ontology.

Now, there's a really interesting part of your paper that I, you know, there's actually, I'm really glad that we touched on this because you say a morphogenetic system from a cybernetics point of view is one that maintains its continuity and integrity by altering essential aspects of its organization and or structure.

And I thought this was just like,

really interesting, because no one I think would have expected the word altering there.

They would have thought that continuity and integrity is going to be the maintenance of its organization and structure.

So I've written here, at what point does a morphogenetic system change its identity?

And what is the distinction between identity and organization?

Because we can have, as you say, on the arc of a lifespan, on the trajectory, we have different points at which we can say,

Self-organization, according to this statistical dynamics is happening.

But 10 years later, there's a whole different scope of self-organization, but it's still self-organizing.

That process is still going on.

But we don't want to call these two distinct entities, right?

The caterpillar and the butterfly or the baby and the adult, because there seems to be some

integrity or continuity to use your language.

Is that just an illusion?

Right?

You know, I come from this from the works of people like Derek Parfit, who say that, well, there is no single substantial self, it's psychological continuity.

But in a sense, you can almost bracket that psychological continuity off again, we're talking about lens of analysis and say, Okay, well, that's the system.

Yeah, that the self, right?

That's what that's what matters.

in the same way you can say okay we're no longer really concerned about the difference between the caterpillar and the butterfly what we're talking about is the fact that butterflies follow because of genetic reasons this path and we can identify the path now as what a butterfly caterpillar is so all of that to say

how do you resolve this tension between identity and organization?

Because it seems to capture reality, we really do have to integrate this dynamism and this in this, these flows over time and these changes.


SPEAKER_01:
Wonderful example of the butterfly in the catapult.


SPEAKER_00:
I think it's Andy's.


SPEAKER_01:
Yeah, I've read that somewhere too.

I know Carl refers to it in one of his works as well.

Probably Andy, I don't I don't

um so there's a lot to unpack there but the one concept i'll just say to start before i forget it is that the butterfly and the caterpillar example you'd say well okay are they different right you know i consider that and this is where again since we did start earlier with hormeohesis which was

returning to a trajectory rather than returning to a constant value, you can sort of borrow that idea of time evolving systems and just saying that the fact that that butterfly is a projection or a continuation of that caterpillar's identity, the fact that evolution, that change is the caterpillar butterfly system.

That is the one object.

And so that's kind of like that evolution.

And I do think I touch on it in here in some way or another about that, that changes you, right?


SPEAKER_00:
That evolution changes you.


SPEAKER_01:
Because again, because we are hormeohedic,

your, your, the variables and the right critical ranges and things will change with time as well, you'd say, well, the way aren't you aren't what aren't all organisms defined by this very specific set point, the idea is that you have to remember, you are an open system, and you live in an environment that itself changes with time.

So the idea is that because that is evolving as well,

And also it's changing because of you.

You remember we talked earlier about niche construction.

We are acting and changing our environment.

So we need to constantly be changing.

So that evolutionary process I think of is your identity.

And I could have swore it might have been Andy or Carl in reference to Andy or someone that was referring to his work about that.

you can look at metamorphosis as still that, that is part of your, it's also part of your identity preservation because it's like an adaptation, right?

An activity to a time evolving universe.

You also asked earlier, so to make sure I connect.

So that's the simple answer is that I still see the, the butterfly as the caterpillar.

It's just not called a caterpillar.

It's a, it's the identity is still there, but the structural form,

has been right in part of that trajectory that it's so the cat and again, though, we can also say caterpillars generally always end up metamorphic into a butterfly trajectory.

So that is distinct.

That is that particular insect.

Right.

Same thing with a human has a different trajectory in the same way you could use your favorite animals like your dogs.

You mentioned your dog earlier was a puppy, right?

Puppy the same as the full grown dog.

Well, there was a trajectory.

It was the growth.

Growth is part of the mortal computation framework, and we did make sure to put that in there.

And there's different ways to characterize growth, regeneration and decay in death.

uh but you said earlier about identity and organization um so i want to be a little careful because there's also the world of i am familiar with philosophy of mind but i don't want to get too much in there and start angering philosophers we've already probably angered a little bit with our ignorance on physics so let's not try to step on too many toes but

So the way I thought about it in Mortal Computation is there's this idea of organization and structure.

You did bring up morphism, so this will help connect all those parts for the audience that heard these words.

And I think of them as sort of two different complementary things.

Then I'll tell you where identity comes into this picture.

Organization from a self-organizing dynamical systems cybernetics perspective is the parts and the relationships between them.

A human might say, you could say, well, we have two arms and two legs.

we are organized according to this way our cells are arranged and you know have certain relationships to each other structure is the instantiation of the organization it is that specific you Darius are very different than me in your instantiation in this universe right you and I are both humans right we both have rough organization of parts but our physical embodiment our

actual instantiation into this moment in time is that organization expressed right in a biological form.

But again, you could talk about as in silico entities as well.

And so the nice thing about thinking about organization

And this is where, again, like that idea of like organizational closure.

We use that in our mission as well.

As long as you have sort of these arrangement of parts and these relationships between them.

Right.

And it's very abstract.

It's kind of like it doesn't want to tell you exactly what you need to create to create this, for example, animal.

That's the identity, right?

It is these rough relationships.

So that's where I want to, I don't particularly divorce the idea of the identity, that rough organization of parts.

And I say rough because, you know, again, we think of it as an evolving trajectory as well.

The structure itself is different.

And that's what's kind of nice is that changes on a faster time scale, if anything else.

So the fact that you and I started as babies and we are now adults, right?

That is because cells are growing, cells are being born, cells are dying.

There's also pre-programmed cell or sorry, programmed cell death.

Apoptosis, I believe was another word we threw in there as well.

And so ultimately, our structure is constantly taking damage from the environment.

And it's also saying, okay, well, I want to repair that damage.

And that's where the morphogenetic, morphogenesis kind of concepts come into play.

You and I, I think a better example, you can even think about neurons in the brain.

Neurons live for a certain time scale.

Synapses live on a much less time scale.

Many synapses die within so many minutes or seconds and cells die every day, but then they're grown and reborn.

So you and I are no longer the same exact collection of cells that we were a few days ago.

We are different physical embodiment, yet you're still Darius.

Your identity is still roughly there, even if maybe you have a few more cells and you're growing and adapting to your environment.

I think that's an important kind of concept is to think about the difference between organization and structure.

They're not actually the same thing, which again, if you're not familiar with distinction, you might assume, well, aren't I the same structure?

No, you're not.

That's kind of like the actual component.

The physical substrate itself is in a constant process of death and birth.

and repair and damage and even the processes themselves.

And at some point or another in the paper, we talk about that even the processes of repair are repairing themselves or decay.

So there's this constant.

So this is where, again, although all that blabbing that I just did goes back to, again, that trajectory, right?

You are a trajectory rather than a fixed set of things that need to maintain them.

exactly as they were, because your dissolution into the environment is that trajectory no longer being there, right?

You're not able to actually maintain your hormiohesis, which is returning to that.

And I like, hormiohesis is such a great word because it really just reflects the idea of what we said earlier, the non-equilibrium steady state, right?

We always want to return to that, but that state, right?

Whatever that might be to ensure your continued organization, your continued identity is changing with time, right?

Because

the condition the environment are changing you are in a naturally evolving system just by basis of you yourself acting on it so everything is constantly evolving so i guess there might be a tension i have i guess in perhaps i entered the the chat entered the discussion uh late enough that uh i don't see i don't see a problem with the metamorphosis i see that as that is the fact that you are your you are a trajectory

And so entity still continues.

It's just your physical structure might be different, right?

And that explains growth.

There is one final tiny point I'll add to it.

And I got to be careful where I use the word.

when we were talking about the cybernetics it's funny how biophysics and cybernetics they sort of have similar word different words for the same kind of concept uh i think that uh yeah that that's a tata almost tautological kind of way of you know viewing it but um

One thing that they have in cybernetics is called self-replication, which is what we used in the cybernetics backend of the mortal computer in this paper to explain that systems will produce more of those parts as they organize, and you can think of them as cells growing or dying.

And if you add mutation to the self-replication, you get reproduction.

So that is where you get this concept of, okay, well, what if, for example, you have offspring one day?

You have a daughter or a son, and they are a continuance also of your identity in a way.

Because they are still subject to all the conditions that you were subject to.

They still need to find their non-equilibrium steady state.

They need to preserve their organizational closure, their identity with an evolving structure or a morphological instantiation.

In a way, your identity is carried on through them.

And then Carl had this really nice it was, again, one of those interviews he had in the past that it's also a way of getting what's called optimal Bayesian forgetting, where as you get older,

you get more set in your ways you become wise but you're less able to change and so that's the the cycle part the evolutionary uh evolutions kind of answer to saying that okay you are not adapting as well as you could or as effectively because the optimal thing would be is you say okay let me start over let me this would be related to like your neural information but you know let me start over again well you kind of can't right you

You have continuously self-evidenced to a point that things are more easily predictable for your internal generative model, which is one way of looking at your identity.

And you are now kind of rigid.

You're less likely to change.

You have certain heuristics that you've established, right?

So that's why you have offspring.

then you have you know you're the next generation and they don't have the same constraints they're more flexible they're more plastic they're more able to change whereas you were less able to however your identity still continues it might not continue directly obviously you know if you have let's say a son not exactly they're not darius but they have elements of you in there right you know the things you've interacted with them

the knowledge that you imparted with them.

So you could even think of I'm going a little a little beyond the rails here of the paper, but we do touch on just like reproduction is just the mutated self-replication concept.

And, you know, once you have that, you know, that's how you preserve your identity and project it even further into the future in a somewhat more abstract way.

I also think and at risk of blabbing any further, I'll stop here is that,

it connects nicely to one of the other motivations towards the beginning of the paper.

We only briefly and I don't want that to be kind of like a sticking point, touch on the philosophy of life and death or existential, which is a lot broader, and it touches on a lot of other bigger concepts than I think, mortal computation, but

We borrowed this idea, the fact that, and you said it earlier as well, the fact that, oh, because you brought up Heidegger and being entitled.

The fact that we know that there is an end and that we project towards the end, we sort of act because of that.

And that's where I connected back to the reproduction.

we impart information we teach right we express ourselves through music or art um i think it's a nice kind of cultural connection uh from the idea of even mortal computation which is that that's how you pass on your knowledge you're encoding your information

in your offspring and giving them somewhat of a prior, right?

And then, of course, they'll obviously adapt and, you know, can do their self-evidencing and modify their posterior according to the data they acquire from the environment.

But that's your way or your identity still carries on in perhaps a direct way.

But that's a projection far beyond your own physical end in death.

So I thought that was a nice thing we did is that we touched on

Because there's naturalist philosophy, which is, I think, a little bit closer to what motivates the idea of mortal computation, but that existentialism is kind of there under the hood, and you sort of realize, well, okay, that's why we act the way we do.

We know that this isn't going to continue forever, which stands in stark contrast to the artificial intelligence systems that we have today, which, in principle, they don't have a known end, right?

They theoretically keep running, being copied on to a different system.


SPEAKER_00:
So I think I'll stop.

Yeah, or at least they wouldn't know, right?

I mean, yeah, I mean, a whole branch of therapy and philosophy, terror management theory, Ernst Becker, denial of death, points exactly to what you're saying, which is that we are motivated by finality.

Whether that's as strong as Ernst Becker, that everything we do is governed by the specter of death, you know, we create works of art for a legacy, we have children and so on.

I like the Heideggerian view, which is that there's this very sort of subtle future orientation in all of our actions.

It doesn't have to be as concrete as creating a masterpiece.

But it's just the fact that, and this actually might point to the incapacity for presentness in some sense, is that we always have to be thinking, even if it's implicit, right?

Because self-organization is always for T plus one.

because T's already been taken care of.

You're there.

Yeah.

Yeah, it's all really cool.

I love that.

There's some really amazing work that's being done on existentialist philosophy and active inference on Heidegger and Husserl and stuff.

Yeah, there was a couple of things that came to mind that I think is worth contributing.

I think one is a notion of philosophical vagueness that's often forgotten, which is that

some questions are just open right at what point system a becomes system b or what point it retains its anus yeah derek parfit who again i mentioned is really influential he just says it's an open question there is no answer right and you know it's it's uh theseus's ship or it's sorry it's paradox at what point does the grain of sand the accumulation of the grain of sand become the heap well depends on who you ask and that's fine i mean it might just be our proclivity to have um

binary results, right?

We just want a yes or a no.

The other thing that came to my mind was that, yeah, you know, we're talking a lot here about change.

I guess the one thing that remains is the mechanism to be able to say that you are a thing has to be the same.

Now, whether you call that self-evidencing or self-organization or the fact that you are matching operational closure with thermodynamic openness or sense-making, whether you're the caterpillar or the butterfly,

you're still abiding by those laws.

And so I think that's where Carl's stressing that the free energy principle doesn't tell you what's going to be there.

It doesn't tell you what's going to be there now or in the past or in the future.

It might come to that because I know they're doing things about scaling up Markov blankets and now we're having dynamic Markov blankets and wheat Markov blankets, but it's very raw form.

It just tells you if something is here now,

And if it's going to be there at T plus one, then we're going to say they're the same thing axiomatically.

They must be minimizing free energy just on pure, quite boring maths.

And so it made me think that.

All of this stuff hinges on the fact that there is some level of self-evidencing going on.

The mechanism itself stays the same.


SPEAKER_01:
Yes.


SPEAKER_00:
I thought that was interesting.

All right, cool.


SPEAKER_01:
You're still interacting with your environment through your Markov blanket.

The morphological substrate instantiation of it evolves with time.

It's still a market blanket.

You're still interacting with sensory and active states.


SPEAKER_00:
You're sense-making.

What's cool about Evan Thompson's work and the inactive tradition is that

the autopoiesis is is is also so it's not just that sense make is happening, but also autopoiesis is happening.

It just depends on your scale of analysis, right?

So you have cell autopoiesis as well as cell sense making, but that's embedded.

It's not it's not distinct, it's embedded within the auto poetic sense making of a nervous system, which itself is doing sense making because it's got action, it's got sensory motor relations going on.

So

It's not just that this is transformative of X to Y, it's also recursive.

That you could have A and B bracketed within A or whatever.

It's like language in many ways.

We've just got loads of relative clauses and these are embedded Markov blankets.


SPEAKER_01:
We also do that in the paper.

We also have a, I don't know if you caught that, Mortal Computers within Mortal Computers.

We had a C subunit, because I did talk about it.


SPEAKER_00:
Yeah, yeah, yeah, yeah.


SPEAKER_01:
Yeah, and one Mortal Computer sets the set point of another Mortal Computer.

So you get that recursive, beautiful construction that you just mentioned there.

You can have that in the framework as well.

I like that.


SPEAKER_00:
Yeah, yeah, yeah.

It's wonderful.

So I wanted to ask one more kind of specific technical thing about the paper and then a couple final more, you know, more general questions.


SPEAKER_01:
Sure.


SPEAKER_00:
I thought this notion I'd never come across before.

And I was really, I really liked it was cybernetic variety.

Ah, I thought this was really cool.

And the law of requisite variety.

I thought these were really, really fascinating additions to the paper.

By the way, for people wondering, because, you know, this is in the paper, this in the paper, the paper is brilliant.

big and bold and it's got a lot in it.

And it has an appendix too.

And it has an appendix.

I didn't read.

You didn't need to.

You didn't need to.

The paper's fantastic, but yeah, it has a lot in it.

And I really enjoyed this bit on cybernetic variety.

So maybe just for our audience, if you could explain what that means.


SPEAKER_01:
Sure.

And I remember too reading that there was, even in cybernetics, confusion as to what variety was.

But I think...

The simplest way to look at it is that it's the number of states in an entire system.

So the cardinality of the state space.

So very specifically, it's actually the log base two of the cardinality of the state space to give it.

So we got to give... So the thing I...

We got to give Ross Ashby, who's the author of things like the law of requisite variety and the good regulator theorem.

Actually, one of the one of the many core contributors to the field of cybernetics.

We got to talk about Wiener and the other wonderful guys that were cybernetics as well.

But Ross Ashby made some really wonderful contributions and.

So variety effectively is like I said, the different number of different states.

And I was thinking about this last night in preparation for this meeting just to remind myself.

So one thing you can think of it is that you have the number of distinct kind of configurations and you could think of I'll use an example.

I think it's better to explain it.

Let's say you're trying to debug

the fact that your light's not turning on.

You have one component you could look at, which is the light switch.

The light switch itself has two states, on or off.

It's binary.

The variety of that's actually log base two of two, which is one.

There's one difference or distinction

and that's right one that's where the word variety i believe really gets it um but no one really quite says it except ross ashby in his textbook you can find it somewhat described in there um there's one distinction between the on and the off seat and that's by the way that is variety right there and it's wholesale but

One way to think about you're trying to debug why your light's not turning on.

So you identify, oh, the problem is in the light switch.

So this will help us understand the law of requisite variety.

You had one controllable changeable aspect of the environment, which was one thing.

And you had one hypothesis or one kind of thought internally about how to fix that.

And so one, you had internal variety of one and the environment.


SPEAKER_00:
Ah, yes, I see where you're going.


SPEAKER_01:
Nice.

Just to help us connect parts together.

Variety is useful to understand the cybernetic principles.

Okay, so that's great.

Internal variety was one, external variety was one.

Now, let's say that it wasn't the problem, the light switch is not the reason why it's not broken.

So now you have to figure out something else in the system.

So there's also, let's say, I don't know, a battery or an internal component that's really, I'm not going to give us the right electronics engineering, but there's another component that you figure out.

It's either broken or not broken.

It had these two possible states or let's say it's either this or it's that.

You figure out that was the source of the problem.

Well, your variety is two because it's a sum of these independent components that make up the system.

You had two binary states and you just sum up these independent components that are not necessarily we're going to act as if they are directly jointly distributed.

They are independent components.

you solve the problem, your internal variety was two, the external variety was two, you solve the problem.

Because solving the problem, by the way, is that you found stability, right?

You fix the issue that you don't want to be in a dark room, right?

That's kind of against your life, right?

That's sort of like you want the room to be lit up.

So that was the other thing.

And so then you could continue extending this out and finding chains of things that are problematic, and you keep summing up the log base two of the number of distinct states that these components have.

But let's say that you just did those two and that wasn't the problem.

And that's it.

Those are the only two things you can think of from your internal model of the environment.

You're like, well, there's a light switch, and I know there's a power source to that light switch.

I've looked at both those things.

They're not broken.

I still have a dark room.

Well, now the environment has greater variety than you.

It turns out that if you had known there's actually a power breaker outside, all you had to do was flip it on and off, and you would have had to turn it back on.

But you never get to that.

So the external variety is three, but your internal variety is two.

You have now failed or you are violating the law of requisite variety in the sense that you are not going to be able to solve your problem.

You won't survive.

And you could then connect this problem solving back to homeostasis or homeoesis where you're trying to

block or protect these life-critical variables or metabolic variables, which Ashby does talk about them.

He doesn't maybe always call them metabolic things, but he does use the word homeostasis, which is another way of saying in cybernetics ultra-stability.

You're able to very quickly go back to that optimal configuration or that good configuration you have currently found.

And so...

So that's like the law of requisite variety and helping you define variety all at once.

I think it's good to just connect the two varieties useful, though, for like a ton of other principles.

And I think you probably you mentioned law of requisite variety and the good regulator theorem.

There's a lot of other and there's even more.

There's a few others that I didn't include in the paper.

about they're all driven by variety like for example blind selection and retention and order through noise because this touches on I noticed chaotic systems and random dynamical systems there's a lot of relationships and overlap between modern-day cybernetics in those principles but like the idea in terms of variety is that

there are all these states in the environment and what you want to do is you want to try to reduce that variety you want to find configurations where there is less variety because then that will your ultimate goal and we uh carl and i sort of reframed a little bit cybernetics it were reorganized it into these pillars so one of them is what's your goal which is you want ultra stability not just stability ultra stability which is there your ease in which you can self-organize or get back into that condition where again

Your internal variety is balanced to the external variety.

You're able to continue your homeostasis.

You are not going to dissolve or disintegrate.

The other one that we had was, what was it?

Regulation or was it?

No, it was growth.

Sorry, I got to remember there were three.

The one is growth.

Of course, the idea and cybernetics just talk about this is where I said earlier about the principle of self replication.

There are two other principles I just want to tag in there.

The principle of auto catalytic growth.

and the principle of recursive systems which is that um you know the idea is that once you start to find the right resources right and assuming that there are enough you're going to grow and grow bigger and bigger and bigger because the idea is that you want to preserve your configuration you want to continue um and then recursive systems just talks about the fact that well these little building blocks as they you know stabilize into configurations and replicate and

know you get more of them they start to connect to each other and this is how you get complex systems right you can build heterarchical or hierarchical systems and this gets into herbert simon he wrote some nice papers about this so you get more and this is you could relate that to cells like for example single cells organizing and combining together create multicellular structures

which eventually give rise to organs, which give rise to subsystems and gives rise to complex entities like animals.

And then the final part is regulation, which we just talked about, law of requisite variety.

And I should mention too, you want noise in this process.

This is one of the other pillars that helps us search through the space.

This gets a little bit like reinforcement learning for exploration.

You need noise and then that's how you get order.

It's called the signal to order process.

And then the final component is, like you said, law of requisite variety, the good regulator theorem.

I don't know if you wanted to make the audience clear on that, but it just basically says in order to be a controller of your environment or something that controls its environment is a model of its environment.

Yes.

First to its internal generative model.

And so in order to be good at manipulating and doing niche construction, right, you need to have a good internal generative model.

And what better generative model than to be a model of your environment or the.

Exactly.

And then there's one last one is called model of internal model controller IMC principle.

I just wanted to give that guy that principle credit.

It's not fair.

Sometimes you see like, oh, it's only Ashby.

It's like, no, there are a lot of other wonderful scientists there.

And that just basically talks about, uh, we talk about a synthesis of a controller and environment, and we want to deem it to be, uh, stable from what's called a closed loop point of view.

Um, because that's where feedback is introduced.

And so there's this basically just an extension of like the good regulator theorem.

Uh, I'm trying to remember his name.

This is what makes me feel bad because I wanted to highlight his principle, but he worked actually with Ashby on the good regulator is Conan and Ashby.

Yeah, Conan, that's the name I wanted.

And he had another principle, the model principle, internal model control, which just talked about, you want us to be you want it to be structurally stable from a closed loop perspective.

And that that's another component that you would like in your system.

So I think that gives you your definition of right.


SPEAKER_00:
That's nice.

I got to get more into my cybernetics.

Yeah, yeah, really cool.

There are several things that popped into my head there.

I mean, one is

I think there's a really nice mapping between the law of requisite variety and Bayesian inference in the sense that to be able to conduct a posterior, I need my states and I need to conduct, okay, what's the probability of the state given an observation, but that itself is making the inference of that state is there in the world.

So I have to have a kind of isomorphism between the states in my generative model and the states that I know, or my expected states and the states are in the world.

That said, something that I was thinking is,

going back to our conversation about entropy and again i'm not going to annoy the physicists but as i reduce my internal variety i'm bringing entropy down which thermodynamically means that i have to be introducing some variety in the environment yeah so i think what's interesting there is i think it's just in the term and i think it's very clever term law of requisite variety it's not like the law of identical variety

Because I have to have enough that I can do sufficient tracking of the environment.

But that doesn't mean that that is sufficient, that I have enough.

But where am I going with this?

You know where I'm going with this.


SPEAKER_01:
I was fine.


SPEAKER_00:
Yeah, I lost myself.

But in the sense that, yeah, as I

bring, it doesn't mean that the external system and the internal system are always the same, because it just depends on sort of your, again, everything comes back to the kind of lens of analysis.

You might be causing entropy elsewhere.

But you just need enough variety so that you can account for your little niche over here.


SPEAKER_01:
Exactly.


SPEAKER_00:
I think I got that.


SPEAKER_01:
No, I thought that's where you were going because it was talking about your local environment.


SPEAKER_00:
Right.

Exactly.


SPEAKER_01:
Because you're not all over the universe.


SPEAKER_00:
Yeah.


SPEAKER_01:
Exist in this, as we said earlier, in our least offensive way.

The entire universe is the complete closed system.

So that's what allows us to be happy and reconcile the second law of thermodynamics.

But you and I, while we are in the entire universe, we actually really care about and we are working and operating in this very local component of the local eco-diche.

We're not everywhere on the planet because, you know, we could talk about the collective, but just talking about you.

And I think that's where I think you were going.

Yeah, yeah, yeah.

Your law of requisite variety really was really about your local eco niche related to you at this moment in time.


SPEAKER_00:
Yeah, exactly, exactly.


SPEAKER_01:
We're not talking about the variety of the entire universe.


SPEAKER_00:
precisely precisely yeah i guess the optimal thing is just to dump my entropy elsewhere and just run back to my bed you know exactly throw that entropy away yeah yeah okay cool that's really good i just wanted to uh ask i guess a very theoretical question which i think is a kind of yes or no which is that if so with your life i thought your light bulb example was really really useful if let's say uh

So in terms of the external variety, let's say there are multiple binary things that might be causing the light bulb to not be working.

So the switch, the battery, the fuse, whatever.

But I get it right the first time.

But I've only got the knowledge of the thing that I got right the first time.

So let's say I go for the battery.

And I think, oh, I don't know anything about light bulbs.

I'm four years old.

I only know about batteries.

Let me go look at the battery.

Oh, it was the battery was dead.

Right.

has the four year old in that example?

Like, what are they intelligent?

It's a kind of it's a kind of Getty a problem.

I'm not sure whether you're aware of Getty a problems.

Getty a was a M and Getty was a French philosopher, I believe, who basically, since Plato knowledge was defined as justified true belief.

So how do I know it's raining?

Well, I can look outside

and I believe that it's raining, it's true that it's raining, and I have a justified belief it's raining because I can see that it's raining.

But if, let's say, my curtains were closed and I said, and it was raining, and do I know that it's raining?

I say it's raining, I believe that it's raining, but I'm not justified in my belief.

So that was kind of, since Plato, what people thought knowledge was.

Edmond Gettier comes up and basically says, for example, it's like the same way that a wrong clock is right two times a day.

I can look at that clock

And it might be accidentally true that it's that time.

But is it justified because I'm using a clock?

It's true.

And I believe it.

But do I know that it's that time because I've looked at that clock?

Well, so that's the philosophical background.

I can't remember where I was going with this.

Oh, yeah.

But the four-year-old who's got less, who is not obeying the law of requisite variety, who's got fewer sort of internal states than the actual volatility in the external world,

How does cybernetics deal with that individual?


SPEAKER_01:
At that moment in time, your internal variety is less than the external variety, so you're in trouble.

But the other component, at least where I'm going for, is that we're forgetting too that there's an evolution in time adaptation to the system.

So that four-year-old at that moment failed to identify the problem, but that doesn't mean that they can't explore

And like you said earlier, I think you gave me sort of a piece of the answer.

You said, well, they'd look up batteries or you looked up a battery and you learned how that works.

You might later learn about the circuit breaker.

So the cybernetics, you got to understand that you are in the process of reducing your variety.

And so you are changing your configuration.

the configuration or changing your state means that earlier principle I mentioned, the principle of order from noise, I think is important because it always tells you, we are trying to find attractors in our state space, right?

It's an optimization problem.

And we want to find an attractor or a pullback attractor is what people say, where it's like something you'd like, which again, connects nicely to any SS, but without repeating ourselves, you're trying to find these attractors and to reach again, like I said,

ultimate goal is ultra stability you want to be really good at solving this light problem you want to understand your generative model sorry you want to understand your world which requires you to update your generative model there's a learning component an evolving adaptivity process and that's where like the good regulator theorem says well you know you if you're a good controller of your environment you're a model of that environment but you might not start out that

You need to adapt, you need to acquire information.

So exploration and exploitation is actually in cybernetics, even though we typically nowadays think, oh, that's just the reinforcement learning concept.

No, they talked about exploitation, which is, I like my particular tractor, I'd like to stay there and it's not very easy to leave it.

However, that noise is what pushes us out and learns to find a better configuration.

There is also some other principles in the law of requisite variety, the law of asymmetric transitions, which says,

that it's less likely for you to go from a lower variety area to a higher variety area.

That means we're always looking for those spaces where we have less variety.

Again, we could use what you and I discussed earlier, your local eco-niche.

You want to find such that you have the least amount of external variety so that you can match it to satisfy the law of requisite variety.

But the other part is the order to noise principle.

And then there's the selective retention principle.

And I'm going to mess these up, even though I made sure to carefully outline all of them in the paper.

So I do recommend to read that to see their interrelated components.

But the idea is that selective retention and blind selection is the idea that

You're more likely to stick to better configurations or states that you find in your optimization process.

But that means you have to be changing.

You have to leave where you currently are, especially if it's a suboptimal configuration.

So I think that four-year-old that you talked about earlier will eventually, I mean, it might be a little difficult for, you know, in this practical example, you're going to figure out what a circuit breaker is.

But maybe they're looking up things on the internet.

They're learning things about electronics because they're like, I really don't want a dark house.

And they're not going to just give up.

Let's assume that they are going to want to tend because they want to survive and the light represents the survival.

They're going to learn about the circuit breaker.

And so ultimately, they are evolving to a different configuration.

And now they have a better generative model of their environment, or it's more close to the actual environment, right?

Because this was a factor, a causal factor that they just hadn't identified.

But once you learn about that circuit breaker, now that's back into your system.

Now you understand its amount of states.

And now you can match the external variety of your local eco niche or the components of the local eco niche that are related to the problem you're trying to solve.

Because I think we could probably cut up the niche in different ways and say, I have different goals.

Like the light only requires these pieces of the environment.

The other parts are not relevant to this problem.

So we don't have to even account, like we said earlier, for that variety.

We only need the variety that's related to the circuit breaker.

And you just need to uncover through intelligent exploration, which connects back.

Now we can even say, oh, that justifies active inference.

We need to actively sample our environment so that way you can learn more about how the electronic system works.

So that way you can turn the lights back on.


SPEAKER_00:
Does that make sense?

Very much so it was thank you for doing the active inference spin, I was gonna do it.

We're maximizing our Bayesian surprise where we're doing our KL divergences between our priors and posteriors about future states, but no, it's fine.

But no, very good.

Exactly.

It's not it can't all just be pragmatic value.

There are epistemic affordances that we need to not exploit, but we need to access to be self evidencing.

that's all in the equations for people who are wondering for the call has derived in terms of expected free energy in this case.

Excellent.

Okay, so we're coming up to two hours, I've got a couple final questions.

One is very well, you can take it as long as short as you want.

But I was just interested to see I've taken this habit of when I read papers, I love reading the reference list.

Because you know, they have numbers.

So you know, you either put the names or you put the numbers, I love looking at the numbers.

you have a lot of numbers in yours and i couldn't help but stumble across um donald hoffman i don't know if that was you or carl um let me just look at what the title was because i didn't it would have been his what's it called um oh i can't remember the name of his paper in any case it doesn't really matter um it's just he has a very funky theory about what reality is um

And anyone who knows about Donald Hoffman, I have to ask about Donald Hoffman.

But let's skip that then.

Final question is,

there's a big hubbub, I would say, still your thunder here.


SPEAKER_01:
But yeah, because it says the interface theory of perception.

So can you briefly remind me because I feel like that'll help trigger why I included him in the ref.


SPEAKER_00:
Yeah, so Hoffman has this idea that we are evolved, there's multiple points of convergence here, but basically that we're evolved

not for veridical perception, but for survival.

And so what we actually perceive is not what's really out there, but fitness payoffs.

And what he says is, so that's not particularly controversial.

You have that in indirect realism.

You have that going all the way back to Bertrand Russell and even prior.

But what becomes sort of radical about Hoffman is he says, well, time and space itself are part of that interface.

And he derives a lot of this from theories of physics where he says, Okay, now, physics, modern physics, I believe the Nobel Prize in 2022 was one for something along this area is showing that there are these symmetries outside of space and time.

And he has these extremely funky, Greek derived names, which I won't even try and pronounce.

And he's very popular on in academia and in popular academia.

So whenever I see his name come up, because I've read his book and I'm interested in his work, I like asking people.

But in any case, it doesn't matter.


SPEAKER_01:
I think it's the first component of what you explained is why at least I remember.

I know Carl and I had different references, but I remember that resonating with the survival component of the argument.

That's probably the piece of his work that we thought resonated in this work.

I don't have anything to say about the other part, although I should dig a little bit further and see if there might be something that changes.


SPEAKER_00:
Well, he's got plenty of podcasts out there and his book is very good.

What's it called?

Anyway, you're writing his name on Google.

So the final thing I wanted to ask is a kind of more broad sociological thing, which is that there's a huge hubbub going on at the moment about AGI, Artificial General Intelligence, and the fact that Sam Altman came out and said that neural nets or large language models are not going to get us there.

And I think people have thought that, people have had their suspicions since the 90s, since inactive, you know, inactivist cognition, 4E cognition, because where are your action perception loops, right?

Where's your grounding in the world and so on.

And so then we have a company like Versys, which is trying to implement active inference intelligence into, you know, in silico.

Just as a computer scientist, I can't help but ask you, you know,

what do you think is going to be the trajectory?

And do you think mortal computation in the form of active inference is going to get us there?


SPEAKER_01:
Oh, this is a this is a good one.

And I feel like I should be a little careful with my answer.

Because there's that not with you, but there's politics and yeah, I'm worried about what we think might be the future.

So I guess I'll say one thing about the paper, because the paper does sort of touch on this, right?

It actually has a section towards the end that talks about the need to reconsider the path of machine intelligence.

I think you remember we talked, so Carl and I mentioned in there about tool-centric AI.

So in that regard, just from the broader perspective, I'll decouple the versus thing in just a minute and I'll address the active inference component.

While I don't feel if mortal computation is the only path, we do say it's one possible viable stepping stone

to a different path.

And I do think it's a reconsideration of how we build intelligence systems.

And I think that that's kind of it's another.

So even though it's a survey, right, because it's trying to survey all these wonderful ideas from brilliant thinkers and engineers,

theoreticians and engineers and scientists across all these different domains, we're trying to say this echoes a direction that we want to build our adaptive systems, right?

And we don't have that right now.

I mean, we do have...

the, what do you call flickers of it?

And the other piece I just want to point to the audience is towards the end, we give examples of what we would consider viable mortal computers that are not even necessarily all in silico.

Ross Ashby does deserve a little more love and attention.

He has the homeostat, which is,

we actually have a little pseudo taxonomy and we call that a homeostatic mortal computer although it can kind of be allostatic depending on the later innovations other scientists made on his homeostat um we also talk about these biotic uh mortal computers like fungal systems we talk about uh organoids which even though i haven't had the pleasure to work with them i'm deeply fascinated by

Or the sentient organoid, as Carl has called them, and Smirnova and those that have done this wonderful microphysiological construction of these little entities that can play Atari, even if it's for a short time span.

It's still fascinating to me that we can use stem cells to do this.

Also, we got to get Michael Levin some wonderful attention.

We celebrate the Xenobot.

and the xenobot swarm which can do these wonderful things so i think those are examples of the type of intelligence that we would want to strive to emphasize and build more like because they can do things like self-repair and self-damaging they are truly adaptive in the sense that i don't think the robotics that we have today

can do right so things are very brittle it's very hard you want to i i tell some of my colleagues you want to sober up about the state of ai because you know there's a lot of wonderful things that current models and systems can do but there's a lot that they can't do i say go to a robotics conference and you'll see instantly

how far we are from AGI or even just really powerful AI, narrow AI, like to get a robot to get you a cup of coffee.

Although there's some nice recent advancements in robotics, but we still have a long ways to go, I think.

And those are the types of problems that I think emphasize where mortal computation might play an important role.

it really gets into this other domain of robotics that i've been fascinated with which is neuro robotics and neuro robotics says very shortly i just try to distill it is um we want to build an intelligence system like a like a brain if you will something that's biological within the robot it must learn and do inference and engage with this environment

inside the body of the robot.

There is no simulation.

You must have physical hardware to do this.

Otherwise, it's not neuro robotics research.

You're just doing simulated stuff, as I have done.

And so I think mortal computation sort of emphasizes and celebrates those domains that really require this entanglement.

We want our neural adaptive systems to actually work in noisy, uncertain environments.

And the tools that we have today with back propagation of errors

reinforcement learning and modern-day deep neural nets they're not always the best they're not best suited sometimes to these particular problems so think that's me waxing about the general problem I will comment that while transformers and the models that we have today are doing some really wonderful things and there's no dismissing of that I do not believe that the the

Key to artificial general intelligence lies in that they are very still tool oriented.

And while that's important instance to make wonderful impacts and healthcare and other aspects of humanity, that's not going to get us to the dreams of original AI, right to build cognitively viable, functional, generally intelligent systems that can act even like I'd see even at the level of a simple animal, forget about humanoid intelligence.

So I do think mortal computation says maybe we should consider these concepts and here's we even give a definition in the paper.

It's not perhaps the most perfect definition and it'll probably change if more people work on this.

But it gives you some ideas about how origins of life tie into mind and how maybe what are the design principles we should be considering to actually build this because

Another under the hood of my lab coat, if you will, is I'm an engineer.

And someone that I should mention did some light reviewing and nice feedback for me, not light reviewing, was my father, which you might see in the acknowledgments, Alexander Robius Sr.

So it's not me thanking myself, it's me thanking my dad.

And he had told me in one of the very earliest drafts of this, he says, you should probably emphasize, how do you build this?

I mean, obviously, we don't give you the final answer, but that's where the engineering takes are in there, where I try to explain, well, okay, this is where the sensory motor dependencies might exist on metabolism, homeostasis, allostasis.

And you notice that, so that's where, to encourage the audience, read the paper, because we talk about where autopesis fits in this framework and poiesis.

So I think that's kind of one general answer about AGI.

And I don't think the current path we have will get us there.

I could be wrong.

Carl and I could be wrong.

Now to address versus AI and active inference, I do believe active inference is very promising.

Again, it might not be the complete story.

It might not be all that we need.

And I do think that it is, but it is important that we make advancements in active inference.

I think that

uh you were you said very early in this interview that your discussion that you were talking about you were going to mention reinforcement learning right so may i can help bring that little tiny sprinkle in here and say that um

I think it's important that active inference seems to get a little overshadowed by reinforcement learning.

If you can design a really good reward function, you can build a sufficiently operating system and we're good enough.

But they're very brittle.

They don't work very well in the continual learning setting.

They catastrophically

forget.

It's very hard to train them online.

They're sample inefficient.

I could go on and on about all the problems with RL.

And I think active inference stands to say, wait a minute, maybe we should turn this problem on its head.

And as long as we have some definition of a prior preference, which I think is one of the more difficult components of active inference to get right, that's the inductive bias that evolution would give us.

So at least it's got the connection to

biology, active inference really emphasizes that intelligent exploration.

And there's some nice results that I've seen out there that, you know, reduce the number of samples that you need to learn a good policy.

So I think active inference represents a really nice alternative to reinforcement learning.

And it even has some really nice bio neuro biological and cognitive connection.

So it gives you that like process theory, it's often called a neuro biological process theory for adaptation.

So

I do think that's important, and I'm happy that Versus AI is pushing along that path.

And obviously, I might be a little biased because I work with Carl.

I work with Tomaso Salvatore.

He's also there, and Chris Buckley.

So even though I'm not part of Versus AI and I don't speak for them in any capacity, obviously, I'm going to be biased because I collaborate with a lot of the people that are there.


SPEAKER_00:
Yeah, yeah.

I thought that was...

very diplomatic.


SPEAKER_01:
I'm watching there's no no saying who's wrong or right.

But I do.

I do want to say I urge everyone to consider mortal computation.

And perhaps fleshing that out further, because I think there's still this is a stepping stone paper.

I do not by any means think we said, Oh, just do what we say.

It's like, to get you thinking, right?


SPEAKER_00:
Yeah, yeah.

Well, hopefully, you know, in addition to the paper, this has got a lot of people thinking,

Um, but it's got me thinking I'm going to, and I'm going to go and practice the pronunciation of home or homey or he says homey or he says, and apparently also laboratory.

Um, I didn't know that one was a problem.

Um, Alex, thank you so much.

Um, it's been an absolute joy.

Um, just for people wanting to know more about you, what have you, you know, what work have you got coming up?

And if people have got questions, can they reach out to you?

How should they reach out to you?


SPEAKER_01:
Please?

Well, first of all, I want to thank you for having me.

This was a very welcome discussion.

I very much enjoyed talking with you about mortal computation and AGI.

And even poking at the holes in my knowledge, there was a few points there.

I was like, Oh, no, I'm not a physicist.

And I should be clear here.

By the way, wonderful.

In terms of how to reach me, I mean, there's my email contact.

I'm also on LinkedIn.

Apparently that's becoming sort of more the social science platform I've noticed, as opposed to Twitter X, as they call it nowadays.

So you can look me up there.

And I do now start to engage with information that people are posting.

And I made my first announcement on there about one work that

I would like to highlight here.

So while Carl and I did this wonderful survey on mortal computation and kind of provide a definition, another massive survey of mine.

So if you thought this was long, I have a longer one.

It came out at the end of December.

It's called Brain Inspired Machine Intelligence, a survey of neurobiological credit assignment, where I also review over the last several decades as much as I possibly could.

I know for a fact I'd probably still miss something.

All the different approaches that have been neurobiologically inspired to training neural networks or constructing new neural models that are more biologically faithful and just don't do it with back

So basically everything that's wrong with backprop and we look at everything ranging from like Boltzmann machines to recirculant autoencoders all the way up to modern day stuff, including Jeff's work on forward-forward only learning and some other flavors of signal propagation.

Nice thing.

i really really urge that one i like to pull uh plug that work because i also think it's a nice resource for uh phd students and postdocs who want to maybe engage in uh alternatives to the modern days we do ai and i think that gives you a lot of uh historical context and it makes you pay proper credit assignment to the wonderful minds so many researchers over the decades you know sometimes get overlooked in this uh you know

rapidly moving information age.

So that's one paper.

There is one more survey that I also recommend.

So last year was the year of surveys for me.

Another survey on predictive coding.

I know you and I didn't really touch a whole lot on it, but Tomaso Salvatore is my friend and he and I sort of in Ankar Mali, we set up this wonderful survey.

Carl's on there, Rajesh Rao.

one of the most important figures in predictive coding, Chris Buckley's on there, Thomas Lukowitz.

I recommend people look up.

It's like brain inspired computational intelligence via predictive coding.

And that reviews everything that's happened in predictive coding as much as we could over the last several years for machine intelligence.

So I think I'd like to those two specific ones.

They're very important.


SPEAKER_00:
And well, we'll put them in the we'll put them in the video description.

so people have direct access to it as well as the mortal computation paper we've been discussing today perfect and you can reach me by my email i should last point i i don't know if you want to give that in the link to the video or so feel free to take it now so that you know um sure ago at cs.rit.edu you can reach me there cool i'm sure that's on the internet as well um everything's on the internet

Alex, thank you again so much.

It's been really, really fun and super informative.

So thank you from me and from the Institute as well.